From dmurdoch@pair.com  Sun Dec  1 17:58:03 2002
From: dmurdoch@pair.com (Duncan Murdoch)
Date: Sun Dec  1 17:58:03 2002
Subject: [Rd] Samples of external code with various compilers?
Message-ID: <qbfkuuc5r24t71k2kle2ecpufk597aa9e9@4ax.com>

R can run external code in C, C++, Fortran, Delphi, etc., but the R
extensions manual only gives limited documentation for anything but C
and C++.  It would be useful to have a collection of sample code
showing how to dyn.load functions written in other languages, if
necessary for a variety of different compilers, in case that makes a
difference.

Does such a collection already exist?  If not, would it be better to
put it into the R extensions manual as a series of appendices, or just
have a web page about it?

I'd volunteer to maintain the web page to hold the samples.

Duncan Murdoch


From jfox@mcmaster.ca  Sun Dec  1 18:00:03 2002
From: jfox@mcmaster.ca (John Fox)
Date: Sun Dec  1 18:00:03 2002
Subject: [Rd] generating contrast names
Message-ID: <5.1.0.14.2.20021201114748.01dcd870@mcmail.cis.mcmaster.ca>

Dear R-devel list members,

I'd like to suggest a more flexible procedure for generating contrast 
names. I apologise for a relatively long message -- I want my proposal to 
be clear.

I've never liked the current approach. For example, the names generated by 
contr.treatment paste factor to level names with no separation between the 
two; contr.sum simply numbers contrasts (I recall an exchange on the list 
about this question); none of contr.* explicitly indicates what kind of 
contrasts are generated. There are ways around these problems -- e.g., 
beginning level names with an uppercase character -- but in my experience 
it's common to see things like "regionmidwest".

I propose that the current behaviour remain the default, but that the 
contr.* functions use optional "prefix" and "suffix" characters around 
level names (or their equivalent) and an optional identifier string to 
indicate what kind of contrasts are generated. As well, I propose that 
contr.sum optionally identify contrasts by level names. All of these 
behaviours could be controlled by options which, if unset, would produce 
the current behaviour. There might be problems with my implementation of 
these ideas, or with the ideas themselves -- but I expect that these will 
arise in discussion. (Of course, there's nothing to prevent me from using 
the functions that I show below, but I thought that these questions might 
be of more general interest.)

Here, for example, are rewrites of contr.treatment and contr.sum (renamed 
contr.Treatment and contr.Sum because of name-space issues) that implement 
my suggestions, together with illustrations of their use:

------------------------------------------------------------------------------------------------------------------------------

     contr.Treatment <- function (n, base = 1, contrasts = TRUE) {
         if (is.numeric(n) && length(n) == 1)
             levs <- 1:n
         else {
             levs <- n
             n <- length(n)
         }
         lev.opt <- getOption("decorate.factor.levels")
         pre <- if (is.null(lev.opt)) "" else lev.opt[1]
         suf <- if (is.null(lev.opt)) "" else lev.opt[2]
         dec <- getOption("decorate.contr.Treatment")
         dec <- if (is.null(dec)) "" else dec
         contr.names <- paste(pre, dec, levs, suf, sep="")
         contr <- array(0, c(n, n), list(levs, contr.names))
         diag(contr) <- 1
         if (contrasts) {
             if (n < 2)
                 stop(paste("Contrasts not defined for", n - 1, "degrees of 
freedom"))
             if (base < 1 | base > n)
                 stop("Baseline group number out of range")
             contr <- contr[, -base, drop = FALSE]
         }
         contr
     }

     contr.Sum <- function (n, contrasts = TRUE)
     {
         if (length(n) <= 1) {
             if (is.numeric(n) && length(n) == 1 && n > 1)
                 levels <- 1:n
             else stop("Not enough degrees of freedom to define contrasts")
         }
         else levels <- n
         lenglev <- length(levels)
         lev.opt <- getOption("decorate.factor.levels")
         pre <- if (is.null(lev.opt)) "" else lev.opt[1]
         suf <- if (is.null(lev.opt)) "" else lev.opt[2]
         dec <- getOption("decorate.contr.Sum")
         dec <- if (is.null(dec)) "" else dec
         show.lev <- getOption("contr.Sum.show.levels")
         contr.names <- if ((!is.null(show.lev)) && show.lev) paste(pre, 
dec, levels, suf, sep="")
         if (contrasts) {
             cont <- array(0, c(lenglev, lenglev - 1), list(levels,
                 contr.names[-lenglev]))
             cont[col(cont) == row(cont)] <- 1
             cont[lenglev, ] <- -1
         }
         else {
             cont <- array(0, c(lenglev, lenglev), list(levels, levels))
             cont[col(cont) == row(cont)] <- 1
         }
         cont
     }

     > library(car)
        . . .

     > data(Prestige)
     > attach(Prestige)
     > contrasts(type) <- "contr.Treatment"
     >
     > lm(prestige ~ (income + education)*type) # default behaviour

     Call:
     lm(formula = prestige ~ (income + education) * type)

     Coefficients:
         (Intercept)              income           education 
typeprof              typewc
             2.275753            0.003522            1.713275 
15.351896          -33.536652
     income:typeprof       income:typewc  education:typeprof 
education:typewc
             -0.002903           -0.002072            1.387809 
4.290875

     >
     > options(decorate.factor.levels=c("[", "]")) # using brackets
     > lm(prestige ~ (income + education)*type)

     Call:
     lm(formula = prestige ~ (income + education) * type)

     Coefficients:
             (Intercept)                income             education 
     type[prof]              type[wc]
                 2.275753              0.003522              1.713275 
       15.351896            -33.536652
     income:type[prof]       income:type[wc]  education:type[prof] 
education:type[wc]
             -0.002903             -0.002072              1.387809 
     4.290875

     >
     > options(decorate.contr.Treatment="T.") # naming contrast type
     > lm(prestige ~ (income + education)*type)

     Call:
     lm(formula = prestige ~ (income + education) * type)

     Coefficients:
             (Intercept)                  income               education 
         type[T.prof]
                 2.275753                0.003522                1.713275 
             15.351896
                 type[T.wc]     income:type[T.prof]       income:type[T.wc] 
  education:type[T.prof]
                 -33.536652               -0.002903               -0.002072 
                1.387809
     education:type[T.wc]
                 4.290875

     >
     > options(decorate.contr.Treatment=NULL)
     > options(decorate.factor.levels=c("#", "")) # alternate style, using hash
     > lm(prestige ~ (income + education)*type)

     Call:
     lm(formula = prestige ~ (income + education) * type)

     Coefficients:
             (Intercept)               income            education 
   type#prof              type#wc
             2.275753             0.003522             1.713275 
15.351896           -33.536652
     income:type#prof       income:type#wc  education:type#prof 
education:type#wc
             -0.002903            -0.002072             1.387809 
  4.290875

     >
     > lm(prestige ~ (income + education)*type, 
contrasts=list(type="contr.Sum")) # default behaviour

     Call:
     lm(formula = prestige ~ (income + education) * type, contrasts = 
list(type = "contr.Sum"))

     Coefficients:
         (Intercept)           income        education            type1 
        type2     income:type1     income:type2
         -3.785832         0.001864         3.606169         6.061585 
  21.413481         0.001658        -0.001244
     education:type1  education:type2
         -1.892895        -0.505086

     >
     > options(contr.Sum.show.levels=TRUE)
     > options(decorate.factor.levels=c("[", "]"))
     > options(decorate.contr.Sum="S.")  # showing levels, brackets, 
contrast type
     > lm(prestige ~ (income + education)*type, 
contrasts=list(type="contr.Sum"))

     Call:
     lm(formula = prestige ~ (income + education) * type, contrasts = 
list(type = "contr.Sum"))

     Coefficients:
             (Intercept)                  income               education 
           type[S.bc]
                 -3.785832                0.001864                3.606169 
               6.061585
             type[S.prof]       income:type[S.bc]     income:type[S.prof] 
  education:type[S.bc]
                 21.413481                0.001658               -0.001244 
              -1.892895
     education:type[S.prof]
                 -0.505086

------------------------------------------------------------------------------------------------------------------------------

I look forward to people's comments.
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox@mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From Mark.Bravington@csiro.au  Mon Dec  2 00:57:03 2002
From: Mark.Bravington@csiro.au (Mark.Bravington@csiro.au)
Date: Mon Dec  2 00:57:03 2002
Subject: [Rd] Samples of external code with various compilers?
Message-ID: <A8877251964B294BAB5BA1FC58B43FED025B43EA@molly.tas.csiro.au>

Documentation for other languages would be great. Perhaps a web page
referred to in the manual would be most appropriate, as that avoids the need
for the R team to have to vet advice concerning languages they neither know
nor care about.

I'd be happy to contribute some examples for Delphi-- a wonderfully
well-organized Pascal-derived language that works on Windows and Linux
(Intel platforms only).

Although I merrily and perpetually write Delphi functions invoked via .C, I
haven't completely figured out how to Delphi-fy the  headers that would be
needed if I wanted to write .Call functions. I almost had this going at some
point-- I did write an automatic header translator in 2001 that seemed to
produce something sensible for the (rather nasty) S6 header files-- but have
lost the thread since then. Would anyone else be interested in having a
Delphi unit that provides matches for the R header files? Would this be
useful for a web page?

cheers
Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington@csiro.au 

#-----Original Message-----
#From: Duncan Murdoch [mailto:dmurdoch@pair.com]
#Sent: Monday, 2 December 2002 3:57 AM
#To: r-devel@stat.math.ethz.ch
#Subject: [Rd] Samples of external code with various compilers?
#
#
#R can run external code in C, C++, Fortran, Delphi, etc., but the R
#extensions manual only gives limited documentation for anything but C
#and C++.  It would be useful to have a collection of sample code
#showing how to dyn.load functions written in other languages, if
#necessary for a variety of different compilers, in case that makes a
#difference.
#
#Does such a collection already exist?  If not, would it be better to
#put it into the R extensions manual as a series of appendices, or just
#have a web page about it?
#
#I'd volunteer to maintain the web page to hold the samples.
#
#Duncan Murdoch
#
#______________________________________________
#R-devel@stat.math.ethz.ch mailing list
#http://www.stat.math.ethz.ch/mailman/listinfo/r-devel
#


From ripley@stats.ox.ac.uk  Mon Dec  2 09:08:06 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec  2 09:08:06 2002
Subject: [Rd] Samples of external code with various compilers?
In-Reply-To: <qbfkuuc5r24t71k2kle2ecpufk597aa9e9@4ax.com>
Message-ID: <Pine.LNX.4.31.0212020753570.1625-100000@gannet.stats>

On Sun, 1 Dec 2002, Duncan Murdoch wrote:

> R can run external code in C, C++, Fortran, Delphi, etc., but the R
> extensions manual only gives limited documentation for anything but C
> and C++.  It would be useful to have a collection of sample code
> showing how to dyn.load functions written in other languages, if
> necessary for a variety of different compilers, in case that makes a
> difference.

I think there is information and lots of examples already for Fortran. I
am not sure what more there is to say in `Writing R Extensions'. We could
point at an example in the R code I you think it would be helpful.  But
I'm puzzled here as to what you find lacking. (Fortran is supported both
via .Fortran and by some of the functions described in the section on the
R API.)

> Does such a collection already exist?  If not, would it be better to
> put it into the R extensions manual as a series of appendices, or just
> have a web page about it?

Base R has only interfaces for C and Fortran (and that via C-style
linkage): SJava adds .Java.  So is the issue how to write in other
languages to use a C interface?  `how to dyn.load functions' is easy: you
just create an appropriate compiled object, a shared library, a DLL or (on
MacOS X as I understand it) a module.  The issues seem to be to export the
symbols correctly, and even more to import ones from R correctly,

I will be interested to hear if there are any other (than Java) candidate
languages that are widely available.  Delphi as I understand it is
Windows-only (and the related Kylix is Linux-only?).  Information on using
Delphi would be very helpful in the R for Windows documentation, but you
are one of the experts there.

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Torsten.Hothorn@rzmail.uni-erlangen.de  Mon Dec  2 09:40:07 2002
From: Torsten.Hothorn@rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon Dec  2 09:40:07 2002
Subject: [Rd] generating contrast names
In-Reply-To: <5.1.0.14.2.20021201114748.01dcd870@mcmail.cis.mcmaster.ca>
Message-ID: <Pine.LNX.4.21.0212020931530.485-100000@artemis>


> Dear R-devel list members,
> 
> I'd like to suggest a more flexible procedure for generating contrast 
> names. I apologise for a relatively long message -- I want my proposal to 
> be clear.
> 
> I've never liked the current approach. For example, the names generated by 
> contr.treatment paste factor to level names with no separation between the 
> two; contr.sum simply numbers contrasts (I recall an exchange on the list 
> about this question); none of contr.* explicitly indicates what kind of 
> contrasts are generated. There are ways around these problems -- e.g., 
> beginning level names with an uppercase character -- but in my experience 
> it's common to see things like "regionmidwest".
> 
> I propose that the current behaviour remain the default, but that the 
> contr.* functions use optional "prefix" and "suffix" characters around 
> level names (or their equivalent) and an optional identifier string to 
> indicate what kind of contrasts are generated. As well, I propose that 
> contr.sum optionally identify contrasts by level names. All of these 
> behaviours could be controlled by options which, if unset, would produce 
> the current behaviour. There might be problems with my implementation of 
> these ideas, or with the ideas themselves -- but I expect that these will 
> arise in discussion. (Of course, there's nothing to prevent me from using 
> the functions that I show below, but I thought that these questions might 
> be of more general interest.)
> 

very interesting suggestion. We had the same problem within the multcomp
package and we decided to paste the factor names, levels and kind of
contrasts used into one single name where possible, for example Dunnett: 

> ci <- simint(minutes ~ blanket, data=recovery, conf.level=0.9,
+       alternative="less",eps=0.0001)
> summary(ci)

        Simultaneous 90% confidence intervals: Dunnett contrasts

Call: 
simint.formula(formula = minutes ~ blanket, data = recovery,
    conf.level = 0.9, alternative = "less", eps = 1e-04)

         Dunnett contrasts for factor blanket

Contrast matrix:
                      blanketb0 blanketb1 blanketb2 blanketb3
blanketb1-blanketb0 0        -1         1         0         0
blanketb2-blanketb0 0        -1         0         1         0
blanketb3-blanketb0 0        -1         0         0         1

where the factor is `blanket' at levels b0,b1,b2,b3. Of course this is
restricted to simple contrasts (like the difference here) but breaks for
more complicated situations (tetrade constrasts for example).

best,

Torsten




> Here, for example, are rewrites of contr.treatment and contr.sum (renamed 
> contr.Treatment and contr.Sum because of name-space issues) that implement 
> my suggestions, together with illustrations of their use:
> 
> ------------------------------------------------------------------------------------------------------------------------------
> 
>      contr.Treatment <- function (n, base = 1, contrasts = TRUE) {
>          if (is.numeric(n) && length(n) == 1)
>              levs <- 1:n
>          else {
>              levs <- n
>              n <- length(n)
>          }
>          lev.opt <- getOption("decorate.factor.levels")
>          pre <- if (is.null(lev.opt)) "" else lev.opt[1]
>          suf <- if (is.null(lev.opt)) "" else lev.opt[2]
>          dec <- getOption("decorate.contr.Treatment")
>          dec <- if (is.null(dec)) "" else dec
>          contr.names <- paste(pre, dec, levs, suf, sep="")
>          contr <- array(0, c(n, n), list(levs, contr.names))
>          diag(contr) <- 1
>          if (contrasts) {
>              if (n < 2)
>                  stop(paste("Contrasts not defined for", n - 1, "degrees of 
> freedom"))
>              if (base < 1 | base > n)
>                  stop("Baseline group number out of range")
>              contr <- contr[, -base, drop = FALSE]
>          }
>          contr
>      }
> 
>      contr.Sum <- function (n, contrasts = TRUE)
>      {
>          if (length(n) <= 1) {
>              if (is.numeric(n) && length(n) == 1 && n > 1)
>                  levels <- 1:n
>              else stop("Not enough degrees of freedom to define contrasts")
>          }
>          else levels <- n
>          lenglev <- length(levels)
>          lev.opt <- getOption("decorate.factor.levels")
>          pre <- if (is.null(lev.opt)) "" else lev.opt[1]
>          suf <- if (is.null(lev.opt)) "" else lev.opt[2]
>          dec <- getOption("decorate.contr.Sum")
>          dec <- if (is.null(dec)) "" else dec
>          show.lev <- getOption("contr.Sum.show.levels")
>          contr.names <- if ((!is.null(show.lev)) && show.lev) paste(pre, 
> dec, levels, suf, sep="")
>          if (contrasts) {
>              cont <- array(0, c(lenglev, lenglev - 1), list(levels,
>                  contr.names[-lenglev]))
>              cont[col(cont) == row(cont)] <- 1
>              cont[lenglev, ] <- -1
>          }
>          else {
>              cont <- array(0, c(lenglev, lenglev), list(levels, levels))
>              cont[col(cont) == row(cont)] <- 1
>          }
>          cont
>      }
> 
>      > library(car)
>         . . .
> 
>      > data(Prestige)
>      > attach(Prestige)
>      > contrasts(type) <- "contr.Treatment"
>      >
>      > lm(prestige ~ (income + education)*type) # default behaviour
> 
>      Call:
>      lm(formula = prestige ~ (income + education) * type)
> 
>      Coefficients:
>          (Intercept)              income           education 
> typeprof              typewc
>              2.275753            0.003522            1.713275 
> 15.351896          -33.536652
>      income:typeprof       income:typewc  education:typeprof 
> education:typewc
>              -0.002903           -0.002072            1.387809 
> 4.290875
> 
>      >
>      > options(decorate.factor.levels=c("[", "]")) # using brackets
>      > lm(prestige ~ (income + education)*type)
> 
>      Call:
>      lm(formula = prestige ~ (income + education) * type)
> 
>      Coefficients:
>              (Intercept)                income             education 
>      type[prof]              type[wc]
>                  2.275753              0.003522              1.713275 
>        15.351896            -33.536652
>      income:type[prof]       income:type[wc]  education:type[prof] 
> education:type[wc]
>              -0.002903             -0.002072              1.387809 
>      4.290875
> 
>      >
>      > options(decorate.contr.Treatment="T.") # naming contrast type
>      > lm(prestige ~ (income + education)*type)
> 
>      Call:
>      lm(formula = prestige ~ (income + education) * type)
> 
>      Coefficients:
>              (Intercept)                  income               education 
>          type[T.prof]
>                  2.275753                0.003522                1.713275 
>              15.351896
>                  type[T.wc]     income:type[T.prof]       income:type[T.wc] 
>   education:type[T.prof]
>                  -33.536652               -0.002903               -0.002072 
>                 1.387809
>      education:type[T.wc]
>                  4.290875
> 
>      >
>      > options(decorate.contr.Treatment=NULL)
>      > options(decorate.factor.levels=c("#", "")) # alternate style, using hash
>      > lm(prestige ~ (income + education)*type)
> 
>      Call:
>      lm(formula = prestige ~ (income + education) * type)
> 
>      Coefficients:
>              (Intercept)               income            education 
>    type#prof              type#wc
>              2.275753             0.003522             1.713275 
> 15.351896           -33.536652
>      income:type#prof       income:type#wc  education:type#prof 
> education:type#wc
>              -0.002903            -0.002072             1.387809 
>   4.290875
> 
>      >
>      > lm(prestige ~ (income + education)*type, 
> contrasts=list(type="contr.Sum")) # default behaviour
> 
>      Call:
>      lm(formula = prestige ~ (income + education) * type, contrasts = 
> list(type = "contr.Sum"))
> 
>      Coefficients:
>          (Intercept)           income        education            type1 
>         type2     income:type1     income:type2
>          -3.785832         0.001864         3.606169         6.061585 
>   21.413481         0.001658        -0.001244
>      education:type1  education:type2
>          -1.892895        -0.505086
> 
>      >
>      > options(contr.Sum.show.levels=TRUE)
>      > options(decorate.factor.levels=c("[", "]"))
>      > options(decorate.contr.Sum="S.")  # showing levels, brackets, 
> contrast type
>      > lm(prestige ~ (income + education)*type, 
> contrasts=list(type="contr.Sum"))
> 
>      Call:
>      lm(formula = prestige ~ (income + education) * type, contrasts = 
> list(type = "contr.Sum"))
> 
>      Coefficients:
>              (Intercept)                  income               education 
>            type[S.bc]
>                  -3.785832                0.001864                3.606169 
>                6.061585
>              type[S.prof]       income:type[S.bc]     income:type[S.prof] 
>   education:type[S.bc]
>                  21.413481                0.001658               -0.001244 
>               -1.892895
>      education:type[S.prof]
>                  -0.505086
> 
> ------------------------------------------------------------------------------------------------------------------------------
> 
> I look forward to people's comments.
>   John
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox@mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>


From murdoch@stats.uwo.ca  Mon Dec  2 15:17:02 2002
From: murdoch@stats.uwo.ca (Duncan Murdoch)
Date: Mon Dec  2 15:17:02 2002
Subject: [Rd] Samples of external code with various compilers?
In-Reply-To: <Pine.LNX.4.31.0212020753570.1625-100000@gannet.stats>
References: <qbfkuuc5r24t71k2kle2ecpufk597aa9e9@4ax.com> <Pine.LNX.4.31.0212020753570.1625-100000@gannet.stats>
Message-ID: <26qmuuob02b0sj5sb6iul9igaqavnpitlh@4ax.com>

On Mon, 2 Dec 2002 08:07:19 +0000 (GMT), you wrote in message
<Pine.LNX.4.31.0212020753570.1625-100000@gannet.stats>:

>I think there is information and lots of examples already for Fortran. 

I was thinking of two additions:

 1.  Rewriting the samples in sections 4.2 and/or 4.5 in Fortran,
Delphi, etc.  I might make them a little more elaborate, e.g. showing
how to return a character string.

 2.  Write up the details of how to do it in various specific
compilers.  For example, if you're using Microsoft Visual Fortran, how
do you create a DLL, how do you set the exported entry points, what
bugs do you need to work around.

>Base R has only interfaces for C and Fortran (and that via C-style
>linkage): SJava adds .Java.  So is the issue how to write in other
>languages to use a C interface?  `how to dyn.load functions' is easy: you
>just create an appropriate compiled object, a shared library, a DLL or (on
>MacOS X as I understand it) a module.  The issues seem to be to export the
>symbols correctly, and even more to import ones from R correctly.

Yes, that's the main issue.  There are also issues even with C:  if
you're using some compiler other than gcc, you probably won't compile
using R SHLIB, so what do you need to do?

Duncan


From ripley@stats.ox.ac.uk  Mon Dec  2 17:09:13 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec  2 17:09:13 2002
Subject: [Rd] Samples of external code with various compilers?
In-Reply-To: <26qmuuob02b0sj5sb6iul9igaqavnpitlh@4ax.com>
Message-ID: <Pine.LNX.4.31.0212021606210.10423-100000@gannet.stats>

On Mon, 2 Dec 2002, Duncan Murdoch wrote:

> On Mon, 2 Dec 2002 08:07:19 +0000 (GMT), you wrote in message
> <Pine.LNX.4.31.0212020753570.1625-100000@gannet.stats>:
>
> >I think there is information and lots of examples already for Fortran.
>
> I was thinking of two additions:
>
>  1.  Rewriting the samples in sections 4.2 and/or 4.5 in Fortran,
> Delphi, etc.  I might make them a little more elaborate, e.g. showing
> how to return a character string.

(Except the last is non-portable for Fortran).  Contributions welcome, of
course.

>
>  2.  Write up the details of how to do it in various specific
> compilers.  For example, if you're using Microsoft Visual Fortran, how
> do you create a DLL, how do you set the exported entry points, what
> bugs do you need to work around.

I think it is only an issue on Windows.  That needs to go in
readme.packages: some is already there.

> >Base R has only interfaces for C and Fortran (and that via C-style
> >linkage): SJava adds .Java.  So is the issue how to write in other
> >languages to use a C interface?  `how to dyn.load functions' is easy: you
> >just create an appropriate compiled object, a shared library, a DLL or (on
> >MacOS X as I understand it) a module.  The issues seem to be to export the
> >symbols correctly, and even more to import ones from R correctly.
>
> Yes, that's the main issue.  There are also issues even with C:  if
> you're using some compiler other than gcc, you probably won't compile
> using R SHLIB, so what do you need to do?

You can: I do it all the time.  If you use use the same compilers to build
R and its extensions, it just works.

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Mark.Bravington@csiro.au  Tue Dec  3 00:02:03 2002
From: Mark.Bravington@csiro.au (Mark.Bravington@csiro.au)
Date: Tue Dec  3 00:02:03 2002
Subject: [Rd] Samples of external code with various compilers?
Message-ID: <A8877251964B294BAB5BA1FC58B43FED025B43FA@molly.tas.csiro.au>

I can remember hitting several issues with Delphi, that might be applicable
to other languages too. From simple to complicated (in Delphi), these are:

how to write a DLL and export procedures (easy).

how to declare parameters (VAR or pointers to arrays; pretty simple).

how arrays of >1 dimension map to R arrays (easy).

what call mode to use for procedures (i.e. stack order and removal of
parameters; I had always used STDCALL with S and R, and then found I was
getting bugs with R 1.6.1. So in desperation I eventually changed this at
random to C-CALL, and things started working again in R-- and continued to
work in S. To my continued puzzlement, actually.)

how to handle & return character strings (The only way I've found to return
a string of unknown length, was to call a Delphi function twice; the first
time it merely returns the number of characters in the string. Then create a
string of spaces of the correct length in R, and explicitly put that string
in a .C call to the Delphi function, which this time can fill in the actual
characters.)

how to get the Delphi debugger to work on a DLL being called by R. This is
incredibly easy in S but rather difficult in R, because of a quirk to do
with starting directories.

Then there are one or two tricks I've sometimes used: e.g. how to return a
Delphi pointer to R so that a "persistent" Delphi object can be created with
one call to a Delphi function from R, then accessed again on a subsequent
call. Useful even with simple things like returning a string, and essential
with really complex structures. All languages will have their own tricks,
which are well worth some informal documentation somewhere.

And then there is the business of turning the R headers into Delphi
equivalents-- a work in progress.

cheers
Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington@csiro.au 

#-----Original Message-----
#From: Duncan Murdoch [mailto:murdoch@stats.uwo.ca]
#Sent: Tuesday, 3 December 2002 1:15 AM
#To: ripley@stats.ox.ac.uk
#Cc: r-devel@stat.math.ethz.ch
#Subject: Re: [Rd] Samples of external code with various compilers?
#
#
#On Mon, 2 Dec 2002 08:07:19 +0000 (GMT), you wrote in message
#<Pine.LNX.4.31.0212020753570.1625-100000@gannet.stats>:
#
#>I think there is information and lots of examples already for 
#Fortran. 
#
#I was thinking of two additions:
#
# 1.  Rewriting the samples in sections 4.2 and/or 4.5 in Fortran,
#Delphi, etc.  I might make them a little more elaborate, e.g. showing
#how to return a character string.
#
# 2.  Write up the details of how to do it in various specific
#compilers.  For example, if you're using Microsoft Visual Fortran, how
#do you create a DLL, how do you set the exported entry points, what
#bugs do you need to work around.
#
#>Base R has only interfaces for C and Fortran (and that via C-style
#>linkage): SJava adds .Java.  So is the issue how to write in other
#>languages to use a C interface?  `how to dyn.load functions' 
#is easy: you
#>just create an appropriate compiled object, a shared library, 
#a DLL or (on
#>MacOS X as I understand it) a module.  The issues seem to be 
#to export the
#>symbols correctly, and even more to import ones from R correctly.
#
#Yes, that's the main issue.  There are also issues even with C:  if
#you're using some compiler other than gcc, you probably won't compile
#using R SHLIB, so what do you need to do?
#
#Duncan
#
#______________________________________________
#R-devel@stat.math.ethz.ch mailing list
#http://www.stat.math.ethz.ch/mailman/listinfo/r-devel
#


From senso.music@laposte.net  Tue Dec  3 02:24:02 2002
From: senso.music@laposte.net (senso.music@laposte.net)
Date: Tue Dec  3 02:24:02 2002
Subject: [Rd] (PR#2340)
Message-ID: <200212030124.CAA00247@pubhealth.ku.dk>

And if the music was a " relaxant " … 
 
It is of the boat, on which he lives in the Southwest of France, which Michel Craven creates all his compositions. Open to the nature and the human beings, his music, let us travel according to our ideas … 
These the last two CD are not to be missed (limited edition), at home or on the professional level: for the well-being of the customers (Waiting room , restaurant,.). 
Please , come on the site to listen and to appreciate some extracts 
come to http://cravenmusic.ifrance.com/    
Not to be disturbed any more, please , send back we a mail with the mention: " REMOVE "
 
C’est de son bateau, sur lequel il vit dans le Sud-Ouest de la France, que Michel Craven crée toutes ses compositions. 
Proche de la nature et des humains, sa musique, nous laisse voyager au gré de nos idées…
Ces deux derniers CD sont à ne pas manquer (édition limitée), chez soi ou sur le plan professionnel : pour le bien-être de la clientèle (salle d’attente, restaurant, …).
Venez écouter et apprécier sa musique
Venez sur http://relaxotherapie.free.fr/   
Pour ne plus être dérangé, renvoyez nous un mail avec la mention : « REMOVE »
 
 
 
 

	[[alternate HTML version deleted]]


From ripley@stats.ox.ac.uk  Tue Dec  3 07:56:03 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Dec  3 07:56:03 2002
Subject: [Rd] Samples of external code with various compilers?
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED025B43FA@molly.tas.csiro.au>
Message-ID: <Pine.LNX.4.31.0212030650110.28922-100000@gannet.stats>

On Tue, 3 Dec 2002 Mark.Bravington@csiro.au wrote:

> I can remember hitting several issues with Delphi, that might be applicable
> to other languages too. From simple to complicated (in Delphi), these are:

(Most of these are Windows-specific.)

> how to write a DLL and export procedures (easy).
>
> how to declare parameters (VAR or pointers to arrays; pretty simple).
>
> how arrays of >1 dimension map to R arrays (easy).
>
> what call mode to use for procedures (i.e. stack order and removal of
> parameters; I had always used STDCALL with S and R, and then found I was
> getting bugs with R 1.6.1. So in desperation I eventually changed this at
> random to C-CALL, and things started working again in R-- and continued to
> work in S. To my continued puzzlement, actually.)

Well, that *is* documented.  For R in readme.packages under `Using other
compilers and languages' which is quite a short section.  So if people
don't read what is already there, is there any point in expanding it?

It's also documented for S-PLUS (if that is what you mean by `S': it
reflects a lot of work by Insightful on top of Lucent S4).

[...]

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From smay213@netscape.net  Tue Dec  3 10:32:03 2002
From: smay213@netscape.net (smay213@netscape.net)
Date: Tue Dec  3 10:32:03 2002
Subject: [Rd] INFO. (PR#2342)
Message-ID: <200212030920.KAA02698@pubhealth.ku.dk>

ATTN:SIR/MADAN

                      STRICTLY CONFIDENTIAL.

I am pleased to introduce myself  to you.My name is Mr. Alex. Momoh
a native of South Africa and a senior employee of mines and natural
resources department currently on a trainning course in Holland for few months.

I  am writing this letter to request your assistance in order to redeem an investment with the South African mining Corporation.The said investment, now valued at  ($15.750 million dollars ) Fifteen  million,seven hundred and fifty thousand dollars only was purchased by Lucio Harper and contracted out to the South  African Mining Corporation in 1977 now recognised as mines and natural resources department.This redeemable investment interest,has now matured since March last year.

Since MARCH last year, several attempts have been made to contact Lucio Harper without success and there is no way to contact any of his close relatives in whose favour the investment cash value can be paid.

Since we have access to all Lucio Harper's information,we can claim this money with the help of my partners with the South African Mines and natural resources department.All we have to do is to file claim using you as Lucio Harper's relative.

I will like to assure you that there is absolutely nothing to worry about,because it is perfectly safe with no risk involved.Please ensure to keep this matter strictly confidential.My partner will file a claim for this money on your behalf from the SouthAfrican mining Corporation.When the claim is approved,you as the beneficiary
will be paid (25%) of the total amouth.

Since this money can be paid directly into any bank account of your
choice,you have responsibility to ensure that my partner and Ireceive(70%)of
the total amouth.While the balance (5%) will be set aside for any unforseen expenses in the cause of transfering this money.

I will appreciate if you can give your assurance and guarantee that
our share will be well secured.Please for the sake of confidentiality,reach
me on my e-mail address:smay213@netscape.net , Please let me know if this proposal is acceptable to you. Kindly reach me immediately
with any of the stated contact addresses so that better clearifications
relating to the transaction will be explained to you.


Truly yours,
Alex.Momoh.


From smay213@netscape.net  Tue Dec  3 10:33:48 2002
From: smay213@netscape.net (asmomoh@spinfinder.com)
Date: Tue Dec  3 10:33:48 2002
Subject: [Rd] INFO.
Message-ID: <200212030919.gB39J4Yr015259@hypatia.math.ethz.ch>

ATTN:SIR/MADAN

                      STRICTLY CONFIDENTIAL.

I am pleased to introduce myself  to you.My name is Mr. Alex. Momoh
a native of South Africa and a senior employee of mines and natural
resources department currently on a trainning course in Holland for few months.

I  am writing this letter to request your assistance in order to redeem an investment with the South African mining Corporation.The said investment, now valued at  ($15.750 million dollars ) Fifteen  million,seven hundred and fifty thousand dollars only was purchased by Lucio Harper and contracted out to the South  African Mining Corporation in 1977 now recognised as mines and natural resources department.This redeemable investment interest,has now matured since March last year.

Since MARCH last year, several attempts have been made to contact Lucio Harper without success and there is no way to contact any of his close relatives in whose favour the investment cash value can be paid.

Since we have access to all Lucio Harper's information,we can claim this money with the help of my partners with the South African Mines and natural resources department.All we have to do is to file claim using you as Lucio Harper's relative.

I will like to assure you that there is absolutely nothing to worry about,because it is perfectly safe with no risk involved.Please ensure to keep this matter strictly confidential.My partner will file a claim for this money on your behalf from the SouthAfrican mining Corporation.When the claim is approved,you as the beneficiary
will be paid (25%) of the total amouth.

Since this money can be paid directly into any bank account of your
choice,you have responsibility to ensure that my partner and Ireceive(70%)of
the total amouth.While the balance (5%) will be set aside for any unforseen expenses in the cause of transfering this money.

I will appreciate if you can give your assurance and guarantee that
our share will be well secured.Please for the sake of confidentiality,reach
me on my e-mail address:smay213@netscape.net , Please let me know if this proposal is acceptable to you. Kindly reach me immediately
with any of the stated contact addresses so that better clearifications
relating to the transaction will be explained to you.


Truly yours,
Alex.Momoh.


From dmurdoch@pair.com  Tue Dec  3 12:42:03 2002
From: dmurdoch@pair.com (Duncan Murdoch)
Date: Tue Dec  3 12:42:03 2002
Subject: [Rd] Samples of external code with various compilers?
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED025B43FA@molly.tas.csiro.au>
References: <A8877251964B294BAB5BA1FC58B43FED025B43FA@molly.tas.csiro.au>
Message-ID: <9b5puuk5fqa9fvl3siit07v23qrtc1jo2l@4ax.com>

On Tue, 3 Dec 2002 10:01:08 +1100 , Mark.Bravington@csiro.au wrote:

>what call mode to use for procedures (i.e. stack order and removal of
>parameters; I had always used STDCALL with S and R, and then found I was
>getting bugs with R 1.6.1. So in desperation I eventually changed this at
>random to C-CALL, and things started working again in R-- and continued to
>work in S. To my continued puzzlement, actually.)

The difference between stdcall and cdecl is that in the former, the
routine removes parameters from the stack, whereas in the latter, the
caller does.

R uses cdecl.  When the routine used stdcall, the parameters would be
removed twice.  My guess about why this worked was that the
"do_dotCode" routine had enough redundant locals that having some of
them removed from the stack didn't cause obvious problems.  In 1.6,
do_dotCode was modified, and now it messes up if you steal its locals.

Most other Windows programs use stdcall.  Using the stdcall convention
to call a cdecl routine means that the parameters won't be removed
from the stack by either the caller or the routine.  However, S-PLUS
is probably like R, and only makes one call to your routine from the
function that calls it.  When it returns, the extra junk on the stack
is removed.

Since stdcall is the Windows standard, and R uses cdecl, I've been
thinking lately about whether it would be worth putting in stdcall as
an option to .C and .Fortran.  Possibly we could just switch to
stdcall, and rely on the behaviour in the paragraph above to handle
cdecl routines, but that sounds pretty ugly to me.

Duncan Murdoch


From ripley@stats.ox.ac.uk  Tue Dec  3 13:38:03 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Dec  3 13:38:03 2002
Subject: [Rd] Samples of external code with various compilers?
In-Reply-To: <9b5puuk5fqa9fvl3siit07v23qrtc1jo2l@4ax.com>
Message-ID: <Pine.LNX.4.31.0212031150280.31679-100000@gannet.stats>

On Tue, 3 Dec 2002, Duncan Murdoch wrote:

> On Tue, 3 Dec 2002 10:01:08 +1100 , Mark.Bravington@csiro.au wrote:
>
> >what call mode to use for procedures (i.e. stack order and removal of
> >parameters; I had always used STDCALL with S and R, and then found I was
> >getting bugs with R 1.6.1. So in desperation I eventually changed this at
> >random to C-CALL, and things started working again in R-- and continued to
> >work in S. To my continued puzzlement, actually.)
>
> The difference between stdcall and cdecl is that in the former, the
> routine removes parameters from the stack, whereas in the latter, the
> caller does.
>
> R uses cdecl.  When the routine used stdcall, the parameters would be
> removed twice.  My guess about why this worked was that the
> "do_dotCode" routine had enough redundant locals that having some of
> them removed from the stack didn't cause obvious problems.  In 1.6,
> do_dotCode was modified, and now it messes up if you steal its locals.
>
> Most other Windows programs use stdcall.  Using the stdcall convention
> to call a cdecl routine means that the parameters won't be removed
> from the stack by either the caller or the routine.  However, S-PLUS
> is probably like R, and only makes one call to your routine from the
> function that calls it.  When it returns, the extra junk on the stack
> is removed.

S-PLUS 2000 was like R.  S-PLUS 6 is cleverer and tries to figure out
(from the decoration on the symbol, I believe) if stdcall or cdecl is
required, but it defaults to stdcall.

> Since stdcall is the Windows standard, and R uses cdecl, I've been
> thinking lately about whether it would be worth putting in stdcall as
> an option to .C and .Fortran.  Possibly we could just switch to
> stdcall, and rely on the behaviour in the paragraph above to handle
> cdecl routines, but that sounds pretty ugly to me.

You can't because of callbacks into R from the compiled code.  That's
where the problems arise with S-PLUS 6: such callbacks have to be stdcall
there.

stdcall requires that all the calls have the right number and type of
parameters.  That's really difficult to check with Fortran code (or with C
code with incomplete headers).  Working with S-PLUS 6 has been much more
error-prone precisely because of the use of stdcall, and I don't see it as
a way forward.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Torsten.Hothorn@rzmail.uni-erlangen.de  Tue Dec  3 14:27:02 2002
From: Torsten.Hothorn@rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue Dec  3 14:27:02 2002
Subject: [Rd] small inconsistency in sort
Message-ID: <Pine.LNX.4.21.0212031421030.5202-100000@artemis>

Hi, 

if an atomic with colnames / rownames attribute is sorted, its names are
not sorted in the appropriate way: 

R> a <- matrix(1:5, ncol=5) 
R> colnames(a) <- paste("V", 1:5, sep="")
R> a  
     V1 V2 V3 V4 V5
[1,]  1  2  3  4  5
R> sort(a, dec=TRUE)
     V1 V2 V3 V4 V5
[1,]  5  4  3  2  1
R> 

?sort states that x is `a numeric or complex vector' but sort only checks
if `is.atomic(x)' causing the small problem. 

best,

Torsten


From ripley@stats.ox.ac.uk  Tue Dec  3 14:51:02 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Dec  3 14:51:02 2002
Subject: [Rd] small inconsistency in sort
In-Reply-To: <Pine.LNX.4.21.0212031421030.5202-100000@artemis>
Message-ID: <Pine.LNX.4.31.0212031344010.31998-100000@gannet.stats>

On Tue, 3 Dec 2002, Torsten Hothorn wrote:

> if an atomic with colnames / rownames attribute is sorted, its names are
> not sorted in the appropriate way:
>
> R> a <- matrix(1:5, ncol=5)
> R> colnames(a) <- paste("V", 1:5, sep="")
> R> a
>      V1 V2 V3 V4 V5
> [1,]  1  2  3  4  5
> R> sort(a, dec=TRUE)
>      V1 V2 V3 V4 V5
> [1,]  5  4  3  2  1
> R>
>
> ?sort states that x is `a numeric or complex vector' but sort only checks
> if `is.atomic(x)' causing the small problem.

Where is the inconsistency?  Nothing I can see says that arbitrary
attributes of a vector will be sorted, and a (numeric or complex) array
*is* a (numeric or complex) vector with some extra attributes.

How can one possibly sort a matrix *and* its dimnames except for
one-dimensional arrays?  Sorting a matrix makes no sense except when it is
regarded as a vector, and if that makes sense it probably also makes sense
to leave the dimnames unchanged.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch@stats.uwo.ca  Tue Dec  3 16:55:03 2002
From: murdoch@stats.uwo.ca (Duncan Murdoch)
Date: Tue Dec  3 16:55:03 2002
Subject: [Rd] Samples of external code with various compilers?
In-Reply-To: <Pine.LNX.4.31.0212021606210.10423-100000@gannet.stats>
References: <26qmuuob02b0sj5sb6iul9igaqavnpitlh@4ax.com> <Pine.LNX.4.31.0212021606210.10423-100000@gannet.stats>
Message-ID: <sgkpuukm3qbbuqkeakr2ds5j5f2uqvhqud@4ax.com>

On Mon, 2 Dec 2002 16:08:12 +0000 (GMT), Brian Ripley wrote in message
<Pine.LNX.4.31.0212021606210.10423-100000@gannet.stats>:

>On Mon, 2 Dec 2002, Duncan Murdoch wrote:

>>  1.  Rewriting the samples in sections 4.2 and/or 4.5 in Fortran,
>> Delphi, etc.  I might make them a little more elaborate, e.g. showing
>> how to return a character string.
>
>(Except the last is non-portable for Fortran).  Contributions welcome, of
>course.

But that's the point:  the portable things belong in the R Extensions
manual, but the non-portable things are still useful to people.
>
>>
>>  2.  Write up the details of how to do it in various specific
>> compilers.  For example, if you're using Microsoft Visual Fortran, how
>> do you create a DLL, how do you set the exported entry points, what
>> bugs do you need to work around.
>
>I think it is only an issue on Windows.  That needs to go in
>readme.packages: some is already there.

Yes, that file as lots of the type of information I was thinking of.
I had forgotten about it; it should probably be mentioned in (the
Windows version of) the dyn.load help file.

Duncan Murdoch


From Mark.Bravington@csiro.au  Wed Dec  4 07:53:02 2002
From: Mark.Bravington@csiro.au (Mark.Bravington@csiro.au)
Date: Wed Dec  4 07:53:02 2002
Subject: [Rd] Samples of external code with various compilers?
Message-ID: <A8877251964B294BAB5BA1FC58B43FED025B440B@molly.tas.csiro.au>

>
#> what call mode to use for procedures (i.e. stack order and removal of
#> parameters; I had always used STDCALL with S and R, and then 
#found I was
#> getting bugs with R 1.6.1. So in desperation I eventually 
#changed this at
#> random to C-CALL, and things started working again in R-- 
#and continued to
#> work in S. To my continued puzzlement, actually.)
#
#Well, that *is* documented.  For R in readme.packages under 
#`Using other
#compilers and languages' which is quite a short section.  So if people
#don't read what is already there, is there any point in expanding it?

Well, here are some reasons:

documentation is distributed in quite a few different places and it is not
always easy to find the right bit. Duncan Murdoch's email said that he'd
also forgotten about readme.packages;

the location of documentation can change between R versions;

In this specific case, not all DLLs are loaded as part of packages, so
readme.packages might not occur to everyone. As Duncan said, it might be
good to refer to that file via dyn.load documentation.

BTW I still use Splus 2000 not S6, and I don't recall finding this in the
documentation for earlier version of S. 

Anyway, the STDCALL stuff was just an example of something that confused me
for a while. Different things will confuse different people. At any rate,
it's not a crime to duplicate the same pieces of information in different
places in the documentation, if it helps the user.

cheers
Mark

#
#It's also documented for S-PLUS (if that is what you mean by `S': it
#reflects a lot of work by Insightful on top of Lucent S4).

Duplicating documentatino

#-- 
#Brian D. Ripley,                  ripley@stats.ox.ac.uk
#Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
#University of Oxford,             Tel:  +44 1865 272861 (self)
#1 South Parks Road,                     +44 1865 272860 (secr)
#Oxford OX1 3TG, UK                Fax:  +44 1865 272595
#


From ripley@stats.ox.ac.uk  Wed Dec  4 08:59:03 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec  4 08:59:03 2002
Subject: [Rd] Samples of external code with various compilers?
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED025B440B@molly.tas.csiro.au>
Message-ID: <Pine.LNX.4.31.0212040755070.5666-100000@gannet.stats>

On Wed, 4 Dec 2002 Mark.Bravington@csiro.au wrote:

[Quoting me without attribution or copying to me (bad form).]

I am not at all sure where you are suggesting the information is
duplicated.  That information seems to appear in zero places.


> >
> #> what call mode to use for procedures (i.e. stack order and removal of
> #> parameters; I had always used STDCALL with S and R, and then
> #found I was
> #> getting bugs with R 1.6.1. So in desperation I eventually
> #changed this at
> #> random to C-CALL, and things started working again in R--
> #and continued to
> #> work in S. To my continued puzzlement, actually.)
> #
> #Well, that *is* documented.  For R in readme.packages under
> #`Using other
> #compilers and languages' which is quite a short section.  So if people
> #don't read what is already there, is there any point in expanding it?
>
> Well, here are some reasons:
>
> documentation is distributed in quite a few different places and it is not
> always easy to find the right bit. Duncan Murdoch's email said that he'd
> also forgotten about readme.packages;
>
> the location of documentation can change between R versions;
>
> In this specific case, not all DLLs are loaded as part of packages, so
> readme.packages might not occur to everyone. As Duncan said, it might be
> good to refer to that file via dyn.load documentation.
>
> BTW I still use Splus 2000 not S6, and I don't recall finding this in the
> documentation for earlier version of S.
>
> Anyway, the STDCALL stuff was just an example of something that confused me
> for a while. Different things will confuse different people. At any rate,
> it's not a crime to duplicate the same pieces of information in different
> places in the documentation, if it helps the user.
>
> cheers
> Mark
>
> #
> #It's also documented for S-PLUS (if that is what you mean by `S': it
> #reflects a lot of work by Insightful on top of Lucent S4).
>
> Duplicating documentatino
>
> #--
> #Brian D. Ripley,                  ripley@stats.ox.ac.uk
> #Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> #University of Oxford,             Tel:  +44 1865 272861 (self)
> #1 South Parks Road,                     +44 1865 272860 (secr)
> #Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> #
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch@stats.uwo.ca  Wed Dec  4 15:47:06 2002
From: murdoch@stats.uwo.ca (Duncan Murdoch)
Date: Wed Dec  4 15:47:06 2002
Subject: [Rd] Samples of external code with various compilers?
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED025B440B@molly.tas.csiro.au>
References: <A8877251964B294BAB5BA1FC58B43FED025B440B@molly.tas.csiro.au>
Message-ID: <m15suu8p5olkpop9d3nrvo3k8t1l8aqaqb@4ax.com>

On Wed, 4 Dec 2002 17:52:29 +1100 , you wrote in message
<A8877251964B294BAB5BA1FC58B43FED025B440B@molly.tas.csiro.au>:

>In this specific case, not all DLLs are loaded as part of packages, so
>readme.packages might not occur to everyone. As Duncan said, it might be
>good to refer to that file via dyn.load documentation.

I've put the reference there for the next release.  Any other places
it should be mentioned?

Duncan


From mowetejohnson@mail.com  Wed Dec  4 17:08:05 2002
From: mowetejohnson@mail.com (mowetejohnson@mail.com)
Date: Wed Dec  4 17:08:05 2002
Subject: [Rd] Urgent  Assistance (PR#2343)
Message-ID: <200212041608.RAA20442@pubhealth.ku.dk>

This is a multi-part message in MIME format
--b9d87174-3909-44ad-a15a-7241a8cc8369
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: quoted-printable

Tel.+31-641299662
Email: (mowetejohnson@mail.com)
                                         
                                  CONFIDENTIAL BUSINESS PROPOSAL

You may be surprised to receive this letter from me since you do not know me =
personally. The purpose of my introduction is that I am Johnson Mowete the =
first son of Frank Mowete , a farmer in Zimbabwe who was recently murdered in =
the land dispute in my country. I got your contact through network online =
hence decided to write you.Before the death of my father, he had taken me to =
Johannesburg to deposit the sum of US8.5 million (Eight million, Five Hundred =
thousand United States dollars), in one of the private security company, as =
he foresaw the looming danger in Zimbabwe this money was deposited in a box =
as gem stones to avoid much demurrage from security company. This amount was =
meant for the purchase of new machines and chemicals for the Farms and =
establishment of new farms in Swaziland.

This land problem came when Zimbabwean President Mr.Robert Mugabe introduced =
a new Land Act Reform wholly affecting the rich white farmers and some few =
black farmers, and this resulted to the killing and mob action by Zimbabwean =
war veterans and some lunatics in the 
society. In fact a lot of people were killed because of this Land reform Act =
for which my father was one of the victims.It is against this background =
that, I and my family fled Zimbabwe for fear of our lives and are currently =
staying in the Netherlands where we are seeking political asylum and moreso =
have decided  to transfer my father=92s money to a more reliable foreign =
account. since the law of Netherlands prohibits a refugee (asylum seeker) to =
open any bank account or to be involved in any financial transaction =
throughout the territorial zone of Netherlands, As the eldest son of my =
father, I am saddled with the responsibility of seeking a genuine foreign =
account where this money could be transferred without the knowledge of my =
government who are bent on taking everything we have got. The South African =
government seems to be playing along with them. 

I am faced with the dilemma of moving this amount of money out of South =
Africa for fear of going through the same experience in future, both =
countries have similar political history. As a businessman,I am seeking for a =
partner who I have to entrust my future and that of my family in his hands, I =
must let you know that this transaction is risk free. If you accept to assist =
me and my family, all I want you to do for me, is to make an arrangements =
with the security company to clear the consignment(funds) from their afiliate =
office here in the Netherlands as i have already given directives for the =
consignment to be brought to the Netherlands from South Africa.But
before then all modalities will have to be put in place like change of =
ownership to the consignment and more importantly this money I intend to use =
for investment. 

I have two options for you. Firstly you can choose to have certain percentage =
of the money for nominating your account for this transaction. Or you can go =
into partnership with me for the proper profitable investment of the money in =
your country. Whichever the option you want, feel free to notify me. I have =
also mapped out 5% of this money for all kinds of expenses incurred in the =
process of this transaction.If you do not prefer a partnership I am willing =
to give 
you 10% of the money while the remaining 85% will be for my investment in =
your country. Contact me with the above email address and telephone number , =
while I implore you to maintain the absolute secrecy required in this =
transaction. 

Thanks, GOD BLESS YOU

Yours Faithfully

Johnson Mowete  
--b9d87174-3909-44ad-a15a-7241a8cc8369--


From fharrell@virginia.edu  Wed Dec  4 17:46:03 2002
From: fharrell@virginia.edu (fharrell@virginia.edu)
Date: Wed Dec  4 17:46:03 2002
Subject: [Rd] problem with load('http://....') (PR#2344)
Message-ID: <200212041646.RAA20699@pubhealth.ku.dk>

Full_Name: Frank Harrell
Version: 1.6.1
OS: RedHat 8.0 Linux
Submission from: (NULL) (128.143.108.90)


I get an error when trying to load a URL that contains a file that was saved
using save(object, compress=TRUE):

> load('http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav')
Error in gzfile(file, "rb") : unable to open connection
In addition: Warning message:
cannot open compressed file
`http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav'

The above file will remain at that URL for your testing.

Thank you very much,

Frank Harrell


From B.Rowlingson@lancaster.ac.uk  Wed Dec  4 17:59:06 2002
From: B.Rowlingson@lancaster.ac.uk (B.Rowlingson@lancaster.ac.uk)
Date: Wed Dec  4 17:59:06 2002
Subject: [Rd] difftime arithmetic (PR#2345)
Message-ID: <200212041658.RAA20777@pubhealth.ku.dk>

Full_Name: Barry Rowlingson
Version: 1.6.0
OS: RH8 i386
Submission from: (NULL) (148.88.136.205)


Strange things happen if I premultiply a difftime() object with a number.

Example:

> d1 <- difftime(Sys.time(),Sys.time())
> d2 <- 1 * difftime(Sys.time(),Sys.time())
> d3 <- difftime(Sys.time(),Sys.time()) * 1

> d1
Time difference of 0 secs
 
  - thats fine

> d2
[1] 0
attr(,"units")
[1] "secs"
attr(,"class")
[1] "difftime"

 - d2 prints out with print.default, although it is of class(difftime)!
print.difftime isnt being called, even though:

> class(d2)
[1] "difftime"

> d3
Time difference of 0 secs

 - d3 prints out fine.

But if I dput those three objects, the files look identical, and when dgetted
(dgot?) they all act the same.

But if instead I save() them and then load() them then d2 acts weird again.

 More weirdness:

> unclass(d1)
[1] 0
attr(,"units")
[1] "secs"
 
 - as expected, but:

> unclass(d2)
[1] 0
attr(,"units")
[1] "secs"
attr(,"class")
[1] "difftime"

 similarly for unclass(unclass(unclass(d2))) !

 Any ideas?

Barry Rowlingson
Lancaster University
Lancaster, UK


From tlumley@u.washington.edu  Wed Dec  4 18:00:03 2002
From: tlumley@u.washington.edu (Thomas Lumley)
Date: Wed Dec  4 18:00:03 2002
Subject: [Rd] can this happen?
Message-ID: <Pine.A41.4.44.0212040841570.81760-100000@homer37.u.washington.edu>

This is basically a question about where to start looking for a problem.

I have a program that gives slightly different results on two Windows
computers.   It is a reasonably complicated numerical optimisation, with
iterative calls to optim().

The two computers both run Windows 2000. On each computer I get the same
results in two different versions of R (1.5.1 and 1.6.0 on one, 1.5.1 and
1.6.1 on the other, the standard binaries), and the results are stable
from run to run on each machine. There's nothing lurking in the workspace.

One computer has a 2GHz Pentium 4 cpu, the other has a 0.75GHz Pentium 3.
I think the problem is with the Pentium 4 machine, since it's giving
occasional errors due to NaNs in internal parts of optim that I don't
understand, but the fault could quite possibly be in my understanding. A
good-quality dual Pentium 4 Linux system doesn't give these internal
errors in optim and seems to give the same results as the Pentium 3
machine (I haven't checked that they are all identical).


	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley@u.washington.edu	University of Washington, Seattle


From maechler@stat.math.ethz.ch  Wed Dec  4 18:09:06 2002
From: maechler@stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Wed Dec  4 18:09:06 2002
Subject: [Rd] difftime arithmetic (PR#2345)
Message-ID: <200212041709.SAA20847@pubhealth.ku.dk>

>>>>> "BaRow" == B Rowlingson <B.Rowlingson@lancaster.ac.uk>
>>>>>     on Wed, 4 Dec 2002 17:58:51 +0100 (MET) writes:

    BaRow> Full_Name: Barry Rowlingson Version: 1.6.0 OS: RH8
    BaRow> i386 Submission from: (NULL) (148.88.136.205)

    BaRow> Strange things happen if I premultiply a difftime()
    BaRow> object with a number.

Thank you for the bug report!
Well, it's ``just'' the internal  object bit that got lost -> is.object()

The bug is still there in R-devel,
and a shorter example is

> now <- Sys.time(); d1 <- difftime(now,now); d2 <- 1 * d1
> d1
Time difference of 0 secs
> d2
[1] 0
attr(,"units")
[1] "secs"
attr(,"class")
[1] "difftime"

> is.object(d1)
[1] TRUE
> is.object(d2)
[1] FALSE

----

We will have to fix that in the C code, too.
Martin


From p.dalgaard@biostat.ku.dk  Wed Dec  4 18:16:03 2002
From: p.dalgaard@biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Dec  4 18:16:03 2002
Subject: [Rd] problem with load('http://....') (PR#2344)
In-Reply-To: <200212041646.RAA20699@pubhealth.ku.dk>
References: <200212041646.RAA20699@pubhealth.ku.dk>
Message-ID: <x21y4xaeof.fsf@biostat.ku.dk>

fharrell@virginia.edu writes:

> Full_Name: Frank Harrell
> Version: 1.6.1
> OS: RedHat 8.0 Linux
> Submission from: (NULL) (128.143.108.90)
> 
> 
> I get an error when trying to load a URL that contains a file that was saved
> using save(object, compress=TRUE):
> 
> > load('http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav')
> Error in gzfile(file, "rb") : unable to open connection
> In addition: Warning message:
> cannot open compressed file
> `http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav'
> 
> The above file will remain at that URL for your testing.

The root of the issue is that gzfile() doesn't know about URLs. Not
documented to either, but (on the face of things) it would seem easy
to add the feature.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907


From maechler@stat.math.ethz.ch  Wed Dec  4 18:22:03 2002
From: maechler@stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Wed Dec  4 18:22:03 2002
Subject: [Rd] difftime arithmetic (PR#2345)
Message-ID: <200212041722.SAA20917@pubhealth.ku.dk>

>>>>> "MM" == Martin Maechler <maechler@stat.math.ethz.ch>
>>>>>     on Wed, 4 Dec 2002 18:09:08 +0100 (MET) writes:

    MM> We will have to fix that in the C code, too.  Martin

well, probably, not.

I found that we are simply missing an  Ops.difftime()
{method implementation for `arithmetic' generics}.

Martin


From p.dalgaard@biostat.ku.dk  Wed Dec  4 18:24:05 2002
From: p.dalgaard@biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Dec  4 18:24:05 2002
Subject: [Rd] can this happen?
In-Reply-To: <Pine.A41.4.44.0212040841570.81760-100000@homer37.u.washington.edu>
References: <Pine.A41.4.44.0212040841570.81760-100000@homer37.u.washington.edu>
Message-ID: <x2wump8zqd.fsf@biostat.ku.dk>

Thomas Lumley <tlumley@u.washington.edu> writes:

> This is basically a question about where to start looking for a problem.
> 
> I have a program that gives slightly different results on two Windows
> computers.   It is a reasonably complicated numerical optimisation, with
> iterative calls to optim().
> 
> The two computers both run Windows 2000. On each computer I get the same
> results in two different versions of R (1.5.1 and 1.6.0 on one, 1.5.1 and
> 1.6.1 on the other, the standard binaries), and the results are stable
> from run to run on each machine. There's nothing lurking in the workspace.
> 
> One computer has a 2GHz Pentium 4 cpu, the other has a 0.75GHz Pentium 3.
> I think the problem is with the Pentium 4 machine, since it's giving
> occasional errors due to NaNs in internal parts of optim that I don't
> understand, but the fault could quite possibly be in my understanding. A
> good-quality dual Pentium 4 Linux system doesn't give these internal
> errors in optim and seems to give the same results as the Pentium 3
> machine (I haven't checked that they are all identical).

I believe that there's a lot of FP activity inside msvcrt.dll (if I
remember the name correctly) so if that isn't the same between the
machines, it might explain things.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907


From ripley@stats.ox.ac.uk  Wed Dec  4 19:03:03 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec  4 19:03:03 2002
Subject: [Rd] problem with load('http://....') (PR#2344)
In-Reply-To: <x21y4xaeof.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.31.0212041757210.26261-100000@gannet.stats>

On 4 Dec 2002, Peter Dalgaard BSA wrote:

> fharrell@virginia.edu writes:
>
> > Full_Name: Frank Harrell
> > Version: 1.6.1
> > OS: RedHat 8.0 Linux
> > Submission from: (NULL) (128.143.108.90)
> >
> >
> > I get an error when trying to load a URL that contains a file that was saved
> > using save(object, compress=TRUE):
> >
> > > load('http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav')
> > Error in gzfile(file, "rb") : unable to open connection
> > In addition: Warning message:
> > cannot open compressed file
> > `http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav'
> >
> > The above file will remain at that URL for your testing.
>
> The root of the issue is that gzfile() doesn't know about URLs. Not
> documented to either, but (on the face of things) it would seem easy
> to add the feature.

Right, this is not what the `file' argument of load() is documented as.
That is neither a file name nor a connection.

I am worried about attempting to get a binary file over a url connection,
but in principle what you should do is

load(url('http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav'))

That fails I think because the connection cannot handle binary files,
but I will look further when I have time.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kjetilh@umsanet.edu.bo  Wed Dec  4 19:25:03 2002
From: kjetilh@umsanet.edu.bo (kjetilh@umsanet.edu.bo)
Date: Wed Dec  4 19:25:03 2002
Subject: [Rd] documentation bug in (ctest) chisq.test (PR#2346)
Message-ID: <200212041824.TAA21143@pubhealth.ku.dk>

chisq.test with simulate.p.value=TRUE uses the Patefield algorithm, this
is not documented, and the original reference is not given, as it ought
to be. The reference is:

Patefield,W. M. (1981) An efficient method of generating r * c tables
with given row and column totals (algorithm AS 159). Applied Statistics
30, 91-97.


Kjetil Halvorsen


From pgilbert@bank-banque-canada.ca  Wed Dec  4 19:32:03 2002
From: pgilbert@bank-banque-canada.ca (Paul Gilbert)
Date: Wed Dec  4 19:32:03 2002
Subject: [Rd] can this happen?
References: <Pine.A41.4.44.0212040841570.81760-100000@homer37.u.washington.edu>
Message-ID: <3DEE49DB.2C095AD1@bank-banque-canada.ca>

Thomas Lumley wrote:
> 
> This is basically a question about where to start looking for a problem.
> 
> I have a program that gives slightly different results on two Windows
> computers.   It is a reasonably complicated numerical optimisation, with
> iterative calls to optim().
...

I don't test much in Windows, but I've had a far amount of trouble like this
with Linux. Not so much with optim(), but with some numerically ill conditioned
problems I get results that are different in the fourth or fifth significant
digit, whereas I typically expect my tests to be better than nine significant
digits, and are often good to fourteen. In Solaris my test values have much
tighter tolerances and were very stable for years, but changed a bit recently
when I switched from svd and eigen to La.svd and La.eigen. The obvious potential
culprit is nonBLAS/BLAS/ATLAS, but the Linux problem does not seem to be related
to that. It is a bit like problems that used to occur when the lower order bits
of doubles did not get zeroed, but the values from run to run on the same
machine are too consistent for a random problem like that.

If you figure out how to track this down, I would like to know. I was going to
try and keep track of the values I get more automatically, but I'm not sure what
information needs to be recorded. OS and R version are obvious, but I suspect
the issue has more to do with math library versions.

Paul Gilbert


From luke@stat.uiowa.edu  Wed Dec  4 20:07:03 2002
From: luke@stat.uiowa.edu (Luke Tierney)
Date: Wed Dec  4 20:07:03 2002
Subject: [Rd] problem with load('http://....') (PR#2344)
In-Reply-To: <Pine.LNX.4.31.0212041757210.26261-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0212041302140.31841-100000@itasca.stat.uiowa.edu>

On Wed, 4 Dec 2002 ripley@stats.ox.ac.uk wrote:

> On 4 Dec 2002, Peter Dalgaard BSA wrote:
> 
> > fharrell@virginia.edu writes:
> >
> > > Full_Name: Frank Harrell
> > > Version: 1.6.1
> > > OS: RedHat 8.0 Linux
> > > Submission from: (NULL) (128.143.108.90)
> > >
> > >
> > > I get an error when trying to load a URL that contains a file that was saved
> > > using save(object, compress=TRUE):
> > >
> > > > load('http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav')
> > > Error in gzfile(file, "rb") : unable to open connection
> > > In addition: Warning message:
> > > cannot open compressed file
> > > `http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav'
> > >
> > > The above file will remain at that URL for your testing.
> >
> > The root of the issue is that gzfile() doesn't know about URLs. Not
> > documented to either, but (on the face of things) it would seem easy
> > to add the feature.
> 
> Right, this is not what the `file' argument of load() is documented as.
> That is neither a file name nor a connection.
> 
> I am worried about attempting to get a binary file over a url connection,
> but in principle what you should do is
> 
> load(url('http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav'))
> 
> That fails I think because the connection cannot handle binary files,
> but I will look further when I have time.
> 

Not sure if being binary creates problems as such, but what the
connection would provide if it is working properly is the compressed
data, and we wo not currently have the tools to decompress off a
connection, as far as I know.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From luke@stat.uiowa.edu  Wed Dec  4 20:08:03 2002
From: luke@stat.uiowa.edu (luke@stat.uiowa.edu)
Date: Wed Dec  4 20:08:03 2002
Subject: [Rd] problem with load('http://....') (PR#2344)
Message-ID: <200212041907.UAA21283@pubhealth.ku.dk>

On Wed, 4 Dec 2002 ripley@stats.ox.ac.uk wrote:

> On 4 Dec 2002, Peter Dalgaard BSA wrote:
> 
> > fharrell@virginia.edu writes:
> >
> > > Full_Name: Frank Harrell
> > > Version: 1.6.1
> > > OS: RedHat 8.0 Linux
> > > Submission from: (NULL) (128.143.108.90)
> > >
> > >
> > > I get an error when trying to load a URL that contains a file that was saved
> > > using save(object, compress=TRUE):
> > >
> > > > load('http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav')
> > > Error in gzfile(file, "rb") : unable to open connection
> > > In addition: Warning message:
> > > cannot open compressed file
> > > `http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav'
> > >
> > > The above file will remain at that URL for your testing.
> >
> > The root of the issue is that gzfile() doesn't know about URLs. Not
> > documented to either, but (on the face of things) it would seem easy
> > to add the feature.
> 
> Right, this is not what the `file' argument of load() is documented as.
> That is neither a file name nor a connection.
> 
> I am worried about attempting to get a binary file over a url connection,
> but in principle what you should do is
> 
> load(url('http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav'))
> 
> That fails I think because the connection cannot handle binary files,
> but I will look further when I have time.
> 

Not sure if being binary creates problems as such, but what the
connection would provide if it is working properly is the compressed
data, and we wo not currently have the tools to decompress off a
connection, as far as I know.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ripley@stats.ox.ac.uk  Wed Dec  4 20:22:12 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec  4 20:22:12 2002
Subject: [Rd] problem with load('http://....') (PR#2344)
In-Reply-To: <Pine.LNX.4.44.0212041302140.31841-100000@itasca.stat.uiowa.edu>
Message-ID: <Pine.LNX.4.31.0212041918030.6357-100000@gannet.stats>

On Wed, 4 Dec 2002, Luke Tierney wrote:

> On Wed, 4 Dec 2002 ripley@stats.ox.ac.uk wrote:
>
> > On 4 Dec 2002, Peter Dalgaard BSA wrote:
> >
> > > fharrell@virginia.edu writes:
> > >
> > > > Full_Name: Frank Harrell
> > > > Version: 1.6.1
> > > > OS: RedHat 8.0 Linux
> > > > Submission from: (NULL) (128.143.108.90)
> > > >
> > > >
> > > > I get an error when trying to load a URL that contains a file that was saved
> > > > using save(object, compress=TRUE):
> > > >
> > > > > load('http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav')
> > > > Error in gzfile(file, "rb") : unable to open connection
> > > > In addition: Warning message:
> > > > cannot open compressed file
> > > > `http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav'
> > > >
> > > > The above file will remain at that URL for your testing.
> > >
> > > The root of the issue is that gzfile() doesn't know about URLs. Not
> > > documented to either, but (on the face of things) it would seem easy
> > > to add the feature.
> >
> > Right, this is not what the `file' argument of load() is documented as.
> > That is neither a file name nor a connection.
> >
> > I am worried about attempting to get a binary file over a url connection,
> > but in principle what you should do is
> >
> > load(url('http://hesweb1.med.virginia.edu/biostat/s/data/sav/kprats.sav'))
> >
> > That fails I think because the connection cannot handle binary files,
> > but I will look further when I have time.
> >
>
> Not sure if being binary creates problems as such, but what the
> connection would provide if it is working properly is the compressed
> data, and we wo not currently have the tools to decompress off a
> connection, as far as I know.

What I meant was that an ASCII save file (rather than a binary save file)
should work via url().

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley@stats.ox.ac.uk  Wed Dec  4 20:32:02 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec  4 20:32:02 2002
Subject: [Rd] documentation bug in (ctest) chisq.test (PR#2346)
In-Reply-To: <200212041824.TAA21143@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.31.0212041928030.6357-100000@gannet.stats>

This has already been fixed after your earlier comments.

On Wed, 4 Dec 2002 kjetilh@umsanet.edu.bo wrote:

> chisq.test with simulate.p.value=TRUE uses the Patefield algorithm, this
> is not documented, and the original reference is not given, as it ought
> to be. The reference is:
>
> Patefield,W. M. (1981) An efficient method of generating r * c tables
> with given row and column totals (algorithm AS 159). Applied Statistics
> 30, 91-97.

For your information, the original reference reads `R x C tables',
although the whole title is capitalized,  it is definitely x not *.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch@stats.uwo.ca  Wed Dec  4 20:56:03 2002
From: murdoch@stats.uwo.ca (Duncan Murdoch)
Date: Wed Dec  4 20:56:03 2002
Subject: [Rd] can this happen?
In-Reply-To: <Pine.A41.4.44.0212040841570.81760-100000@homer37.u.washington.edu>
References: <Pine.A41.4.44.0212040841570.81760-100000@homer37.u.washington.edu>
Message-ID: <dnmsuuomd8cucj79u1vi4h8bb5i4nj03ap@4ax.com>

On Wed, 4 Dec 2002 08:59:17 -0800 (PST), you wrote in message
<Pine.A41.4.44.0212040841570.81760-100000@homer37.u.washington.edu>:

>
>This is basically a question about where to start looking for a problem.
>
>I have a program that gives slightly different results on two Windows
>computers.   It is a reasonably complicated numerical optimisation, with
>iterative calls to optim().
>
>The two computers both run Windows 2000. On each computer I get the same
>results in two different versions of R (1.5.1 and 1.6.0 on one, 1.5.1 and
>1.6.1 on the other, the standard binaries), and the results are stable
>from run to run on each machine. There's nothing lurking in the workspace.

I've recently been trying to track down problems with a couple of
DLLs, and have turned up Windows bugs where common dialogs (file open,
etc) reduce the floating point precision.  The current development
version has code to fix these (everywhere I could think to put it),
but that's not in 1.6.1. 

I'll be putting these changes into 1.6.2 as well, but it's not in
r-patched yet (since I didn't know there was going to be a 1.6.2).

So if you're set up to do a Windows build, you could try compiling
r-devel, and should get consistent results (hopefully matching at
least one of the results you've seen!)

Duncan


From vograno@arbitrade.com  Thu Dec  5 01:30:02 2002
From: vograno@arbitrade.com (vograno@arbitrade.com)
Date: Thu Dec  5 01:30:02 2002
Subject: [Rd] writing to gzfile: segmentation fault (PR#2347)
Message-ID: <200212050030.BAA22418@pubhealth.ku.dk>

Full_Name: Vadim Ogranovich
Version: Version 1.6.0  (2002-10-01)
OS: Red Hat 7.1
Submission from: (NULL) (209.99.241.1)


The following sequence of commands crashes my R session. The first weirdness
happens after the second command that appears not to change the "foo.gz" file,
no error generated.

> con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
> cat("boo\n", file=gzfile("foo.gz"))
# this doesn't change "foo.gz"
cat("boo\n", file=gzfile("foo.gz"))
> con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
> cat("boo\n", file=gzfile("foo.gz"))
cat("boo\n", file=gzfile("foo.gz"))

Process R segmentation fault at Wed Dec  4 16:13:32 2002


From edd@debian.org  Thu Dec  5 03:41:05 2002
From: edd@debian.org (Dirk Eddelbuettel)
Date: Thu Dec  5 03:41:05 2002
Subject: [Rd] writing to gzfile: segmentation fault (PR#2347)
In-Reply-To: <200212050030.BAA22418@pubhealth.ku.dk>
References: <200212050030.BAA22418@pubhealth.ku.dk>
Message-ID: <20021205023954.GA31199@sonny.eddelbuettel.com>

On Thu, Dec 05, 2002 at 01:30:19AM +0100, vograno@arbitrade.com wrote:
> Full_Name: Vadim Ogranovich
> Version: Version 1.6.0  (2002-10-01)
> OS: Red Hat 7.1
> Submission from: (NULL) (209.99.241.1)
> 
> 
> The following sequence of commands crashes my R session. The first weirdness
> happens after the second command that appears not to change the "foo.gz" file,
> no error generated.
> 
> > con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
> con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
> > cat("boo\n", file=gzfile("foo.gz"))
> # this doesn't change "foo.gz"
> cat("boo\n", file=gzfile("foo.gz"))
> > con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
> con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
> > cat("boo\n", file=gzfile("foo.gz"))
> cat("boo\n", file=gzfile("foo.gz"))
> 
> Process R segmentation fault at Wed Dec  4 16:13:32 2002

Try upgrading -- 1.6.1 on Debian is happy:

edd@chibud:~> R

R : Copyright 2002, The R Development Core Team
Version 1.6.1  (2002-11-01)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type license()' or licence()' for distribution details.

R is a collaborative project with many contributors.
Type contributors()' for more information.

Type demo()' for some demos, help()' for on-line help, or
help.start()' for a HTML browser interface to help.
Type q()' to quit R.

> con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
> cat("boo\n", file=gzfile("foo.gz"))
> con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
> cat("boo\n", file=gzfile("foo.gz"))
> ls()
[1] "con"

Dirk

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr


From ripley@stats.ox.ac.uk  Thu Dec  5 07:45:03 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec  5 07:45:03 2002
Subject: [Rd] writing to gzfile: segmentation fault (PR#2347)
In-Reply-To: <20021205023954.GA31199@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.31.0212050639320.27301-100000@gannet.stats>

On Wed, 4 Dec 2002, Dirk Eddelbuettel wrote:

> On Thu, Dec 05, 2002 at 01:30:19AM +0100, vograno@arbitrade.com wrote:
> > Full_Name: Vadim Ogranovich
> > Version: Version 1.6.0  (2002-10-01)
> > OS: Red Hat 7.1
> > Submission from: (NULL) (209.99.241.1)
> >
> >
> > The following sequence of commands crashes my R session. The first weirdness
> > happens after the second command that appears not to change the "foo.gz" file,
> > no error generated.
> >
> > > con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
> > con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
> > > cat("boo\n", file=gzfile("foo.gz"))
> > # this doesn't change "foo.gz"
> > cat("boo\n", file=gzfile("foo.gz"))
> > > con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
> > con <- gzfile("foo.gz", open="w"); cat("goo\n", file=con); close(con)
> > > cat("boo\n", file=gzfile("foo.gz"))
> > cat("boo\n", file=gzfile("foo.gz"))
> >
> > Process R segmentation fault at Wed Dec  4 16:13:32 2002
>
> Try upgrading -- 1.6.1 on Debian is happy:

And 1.6.0 is happy here on RH7.2. Upgrading would be a good idea,
but I suspect the problem is in the zlib installation and/or the
flaky un-released compilers shipped by RedHat.  In particular, zlib
ought to have been upgraded to 1.1.4.  Has it?

In short, this is not an R problem, and RH7.1 is old and not known as the
model of stability.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wolfram@fischer-zim.ch  Thu Dec  5 15:30:03 2002
From: wolfram@fischer-zim.ch (wolfram@fischer-zim.ch)
Date: Thu Dec  5 15:30:03 2002
Subject: [Rd] [R] NA in first panel of xyplot causes error (PR#2349)
Message-ID: <200212051430.PAA29994@pubhealth.ku.dk>

Problem:
If the selection of values for the first panel of an xyplot
leads to a vector of NAs, an error is produced:
	Error in pretty(x[is.finite(x)], ...) : x must be numeric

Example:
	xa <- 1:8
	xb <- rep( c( NA, 10 ), 4 )
	xc <- rep( c( 'C1', 'C2' ), 4 )
	xyplot( xa ~ xb | xc )

Remark:
Changing the data for the first and the second panel eliminates
the error message:
	xb <- rep( c( 10, NA ), 4 )
	xyplot( xa ~ xb | xc )

Version of R:
	R 1.6.1 on Linux

Wolfram


From JLi2@prdus.jnj.com  Thu Dec  5 16:15:04 2002
From: JLi2@prdus.jnj.com (JLi2@prdus.jnj.com)
Date: Thu Dec  5 16:15:04 2002
Subject: [Rd] Bugs in Version 1.6.1  (2002-11-01), Windows Edition (PR#2350)
Message-ID: <200212051515.QAA00460@pubhealth.ku.dk>

Hot keys for list boxes do not work

Start RGui.exe, click the menu Edit->Gui preference, in the four list boxes
at the bottom of the dialog, the hot key does not work.

For example, when I want the black background, I click the "Background" list
box.  Then I press the key 'B', expecting the focus to jump to the first
item starting with 'B' (in this case it is "beige").  But it doesn't work.

James


	[[alternate HTML version deleted]]


From ripley@stats.ox.ac.uk  Thu Dec  5 17:22:03 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec  5 17:22:03 2002
Subject: [Rd] Bugs in Version 1.6.1  (2002-11-01), Windows Edition
 (PR#2350)
In-Reply-To: <200212051515.QAA00460@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.31.0212051614570.1367-100000@gannet.stats>

On Thu, 5 Dec 2002 JLi2@prdus.jnj.com wrote:

> Hot keys for list boxes do not work

Where does it say they do work, please?  The interface is built with
GraphApp, and probably that never implemented this.  I am pretty sure it
is not documented to work.

Not doing what you don't say you do is not to my mind a bug, but if you
would like to submit a patch for this enhancement it will be considered.

> Start RGui.exe, click the menu Edit->Gui preference, in the four list boxes
> at the bottom of the dialog, the hot key does not work.
>
> For example, when I want the black background, I click the "Background" list
> box.  Then I press the key 'B', expecting the focus to jump to the first
> item starting with 'B' (in this case it is "beige").  But it doesn't work.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley@stats.ox.ac.uk  Thu Dec  5 17:22:19 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec  5 17:22:19 2002
Subject: [Rd] Bugs in Version 1.6.1  (2002-11-01), Windows Edition (PR#2351)
Message-ID: <200212051621.RAA01008@pubhealth.ku.dk>

On Thu, 5 Dec 2002 JLi2@prdus.jnj.com wrote:

> Hot keys for list boxes do not work

Where does it say they do work, please?  The interface is built with
GraphApp, and probably that never implemented this.  I am pretty sure it
is not documented to work.

Not doing what you don't say you do is not to my mind a bug, but if you
would like to submit a patch for this enhancement it will be considered.

> Start RGui.exe, click the menu Edit->Gui preference, in the four list boxes
> at the bottom of the dialog, the hot key does not work.
>
> For example, when I want the black background, I click the "Background" list
> box.  Then I press the key 'B', expecting the focus to jump to the first
> item starting with 'B' (in this case it is "beige").  But it doesn't work.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch@stats.uwo.ca  Thu Dec  5 22:13:02 2002
From: murdoch@stats.uwo.ca (Duncan Murdoch)
Date: Thu Dec  5 22:13:02 2002
Subject: [Rd] Windows build of current patch release
Message-ID: <97fvuu8mitr50n3u46co8svdcl4k3t98ke@4ax.com>

To all Windows R users:

There are plans for a 1.6.2 release of R in the not too distant
future.  I've put a current binary build online at
<http://www.stats.uwo.ca/faculty/murdoch/software/r-devel>, and as
time permits, I'll put new builds online.  Please send comments on
bugs in the build to me.

I'll be away from Dec 13-21, so there'll be no updates then.

Duncan murdoch


From Mark.Bravington@csiro.au  Fri Dec  6 01:20:03 2002
From: Mark.Bravington@csiro.au (Mark.Bravington@csiro.au)
Date: Fri Dec  6 01:20:03 2002
Subject: [Rd] Samples of external code with various compilers?
Message-ID: <A8877251964B294BAB5BA1FC58B43FED025B4412@molly.tas.csiro.au>

#-----Original Message-----
#From: Duncan Murdoch [mailto:murdoch@stats.uwo.ca]
#Subject: Re: [Rd] Samples of external code with various compilers?
#
#
#On Wed, 4 Dec 2002 17:52:29 +1100 , you wrote in message
#<A8877251964B294BAB5BA1FC58B43FED025B440B@molly.tas.csiro.au>:
#
#>In this specific case, not all DLLs are loaded as part of packages, so
#>readme.packages might not occur to everyone. As Duncan said, 
#it might be
#>good to refer to that file via dyn.load documentation.
#
#I've put the reference there for the next release.  Any other places
#it should be mentioned?
#
#Duncan
#

I was completely unaware of readme.packages, I must say. It's not in my
distributions of 1.3.1 or 1.5.1, but it is in 1.6.1. I seem to recall that I
installed the "source" option for 1.6.1 but not for the others, which might
explain why. Note that non-C users are quite likely not to bother with the
"source" option when downloading/installing, but they might still write
DLLs.

There are three places besides dyn.load where mention or expansion might be
useful:

(1) In the main README. At present, "readme.packages" is mentioned, but only
under "Adding packages" under "installing packages from source code". Since
I was never likely to do that with other peoples' source, I didn't look at
this. Perhaps a short section in README explictly called "Writing DLLs"
(underlined with = signs) could alert people to the existence of
"readme.packages".

(2) In the help for .C etc., where the "Writing R Extensions" manual is
already referred to.

(3) And presumably in "Writing R Extensions" itself, if "readme.packages" is
likely to be a semi-permanent feature of R for Windows.

cheers
Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington@csiro.au


From Mark.Bravington@csiro.au  Fri Dec  6 02:57:02 2002
From: Mark.Bravington@csiro.au (Mark.Bravington@csiro.au)
Date: Fri Dec  6 02:57:02 2002
Subject: [Rd] Samples of external code with various compilers?
Message-ID: <A8877251964B294BAB5BA1FC58B43FED025B4414@molly.tas.csiro.au>

PS correction to previous my email, where I wrote the 2nd part before the
1st part:

Places to mention "readme.packages":

#(3) And presumably in "Writing R Extensions" itself, if 
#"readme.packages" is
#likely to be a semi-permanent feature of R for Windows.

I'm now thinking that readme.packages is already semi-permanent; it's just
that you don't get it unless you install the "with-source" version. (or am I
confused? I can't remember exactly what I've installed with each version.)


cheers
Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington@csiro.au

______________________________________________
R-devel@stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-devel


From dmurdoch@pair.com  Fri Dec  6 03:01:02 2002
From: dmurdoch@pair.com (Duncan Murdoch)
Date: Fri Dec  6 03:01:02 2002
Subject: [Rd] Samples of external code with various compilers?
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED025B4412@molly.tas.csiro.au>
References: <A8877251964B294BAB5BA1FC58B43FED025B4412@molly.tas.csiro.au>
Message-ID: <t600vukj2om2a9nrvim1u5gtl5p9mei9f3@4ax.com>

On Fri, 6 Dec 2002 11:19:28 +1100 , you wrote:
>
>There are three places besides dyn.load where mention or expansion might be
>useful:
>
>(1) In the main README. At present, "readme.packages" is mentioned, but only
>under "Adding packages" under "installing packages from source code". Since
>I was never likely to do that with other peoples' source, I didn't look at
>this. Perhaps a short section in README explictly called "Writing DLLs"
>(underlined with = signs) could alert people to the existence of
>"readme.packages".

I don't see it in README.  Are you thinking of rw-FAQ maybe?  

The reason it wouldn't be in README is that README is supposed to give
information common to all platforms.  But perhaps it would be useful
to add a pointer to platform-specific files to the RESOURCES file?

>
>(2) In the help for .C etc., where the "Writing R Extensions" manual is
>already referred to.

I've added it there.
>
>(3) And presumably in "Writing R Extensions" itself, if "readme.packages" is
>likely to be a semi-permanent feature of R for Windows.

I've added a cross reference at the end of section 4.4, Creating
Shared Libraries.

Duncan Murdoch


From Mark.Bravington@csiro.au  Fri Dec  6 03:17:02 2002
From: Mark.Bravington@csiro.au (Mark.Bravington@csiro.au)
Date: Fri Dec  6 03:17:02 2002
Subject: [Rd] Samples of external code with various compilers?
Message-ID: <A8877251964B294BAB5BA1FC58B43FED025B4415@molly.tas.csiro.au>

#>
#>There are three places besides dyn.load where mention or 
#expansion of "readme.packages" might be
#>useful:
#>
#>(1) In the main README. At present, "readme.packages" is 
#mentioned, but only
#>under "Adding packages" under "installing packages from 
#source code". Since
#>I was never likely to do that with other peoples' source, I 
#didn't look at
#>this. Perhaps a short section in README explictly called 
#"Writing DLLs"
#>(underlined with = signs) could alert people to the existence of
#>"readme.packages".
#
#I don't see it in README.  Are you thinking of rw-FAQ maybe?  
#
#The reason it wouldn't be in README is that README is supposed to give
#information common to all platforms.  But perhaps it would be useful
#to add a pointer to platform-specific files to the RESOURCES file?

Hmmm-- it is in my README for RW1061. The README file for the Windows binary
distribution specifically mentions Windows in its title line. Also, there
doesn't seem to be a file called RESOURCES in my distributions (1.3.1,
1.5.0, 1.5.1, 1.6.1, all for Windows). I installed pre-compiled binary
versions-- don't know if the "completely from source" method gives different
files?


cheers
Mark


From dmurdoch@pair.com  Fri Dec  6 03:52:02 2002
From: dmurdoch@pair.com (Duncan Murdoch)
Date: Fri Dec  6 03:52:02 2002
Subject: [Rd] Samples of external code with various compilers?
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED025B4415@molly.tas.csiro.au>
References: <A8877251964B294BAB5BA1FC58B43FED025B4415@molly.tas.csiro.au>
Message-ID: <fb30vuo0e62qfaptmbmpk2abet6q0h9uio@4ax.com>

On Fri, 6 Dec 2002 13:16:16 +1100 , you wrote:

>#The reason it wouldn't be in README is that README is supposed to give
>#information common to all platforms.  But perhaps it would be useful
>#to add a pointer to platform-specific files to the RESOURCES file?
>
>Hmmm-- it is in my README for RW1061. The README file for the Windows binary
>distribution specifically mentions Windows in its title line. Also, there
>doesn't seem to be a file called RESOURCES in my distributions (1.3.1,
>1.5.0, 1.5.1, 1.6.1, all for Windows). I installed pre-compiled binary
>versions-- don't know if the "completely from source" method gives different
>files?

Oops, yes, I was looking at the source tree, not an installed copy.
The README and RESOURCES files should probably be included in the
Windows binary distributions; they've got different sorts of
information than the Windows README.

Duncan Murdoch


From vograno@arbitrade.com  Fri Dec  6 19:42:06 2002
From: vograno@arbitrade.com (vograno@arbitrade.com)
Date: Fri Dec  6 19:42:06 2002
Subject: [Rd] avas: segmentation fault on empty args (PR#2352)
Message-ID: <200212061841.TAA11401@pubhealth.ku.dk>

Full_Name: Vadim Ogranovich
Version: 1.6.0
OS: Red Hat 7.1
Submission from: (NULL) (209.99.241.1)


Segmentation fault occurs when empty vectors passed to avas as arguments. 

> library("acepack")
library("acepack")
> avas(numeric(0),numeric(0))
avas(numeric(0),numeric(0))

Process R segmentation fault at Fri Dec  6 10:31:06 2002


From pd@pubhealth.ku.dk  Sat Dec  7 07:15:05 2002
From: pd@pubhealth.ku.dk (Peter Dalgaard BSA)
Date: Sat Dec  7 07:15:05 2002
Subject: [Rd] Bug list summary (automatic post)
Message-ID: <200212070615.gB76F5xH000447@blueberry.kubism.ku.dk>

=================================================
This is an automated summary of the status of the R-bugs
repository.

Note that this may be neither complete nor perfectly
correct at any given instance: Not all bugs are reported,
and some reported bugs may have been fixed, but the
repository not yet updated.

Some bug fixes are difficult to verify because they pertain
to specific hardware or operating system versions. If you
have information to contribute, please do so.

If you happen to know how to fix a problem please send
patches to the bug repository, too.

New bugs are reported either through the web
interface at r-bugs.r-project.org or via email to
r-bugs@r-project.org. The bug.report() function can be
used to automate parts of the procedure on many systems.
Followups on older bugs can be done by including the string
"(PR#999)" in the Subject of an email (change 999 to the
actual reference number, of course!).
=================================================

Directory:  Accuracy

* PR# 1228 *
Subject: bug with var(rep(1e30, 3))
From: Emmanuel Paradis <paradis@isem.univ-montp2.fr>
Date: Wed, 26 Dec 2001 13:03:31 +0100
* PR# 1664 *
Subject: Bug in rnorm.
From: Rolf Turner <rolf@math.unb.ca>
Date: Thu, 13 Jun 2002 16:35:59 -0300 (ADT)
..Strange interaction between "Marsaglia-Multicarry" generator and
.."Kinderman-Ramage" 
..method for normal variates. Apparently, switching either of them will help.
* PR# 2214 *
Subject: qgamma precision
From: terra@diku.dk
Date: Fri, 25 Oct 2002 16:50:17 +0200 (MET DST)

Directory:  Add-ons

* PR# 974 *
Subject: Lattice: panel.superpose with ordered factor groups
From: John Maindonald <john.maindonald@anu.edu.au>
Date: Sat, 9 Jun 2001 11:08:51 +1000 (EST)
..The warning is standard S and R behaviour.
..Probably xyplot needs to avoid it (by unclassing?)
..Still there in lattice 0.3-0.
* PR# 1044 *
Subject: Polymarsall.c
From: pleu@hotmail.com
Date: Tue, 7 Aug 2001 22:42:07 +0200 (MET DST)
* PR# 1178 *
Subject: segfault using svm from e1071
From: Jan Rychter <jan@rychter.com>
Date: Tue, 20 Nov 2001 23:38:17 +0100
* PR# 1199 *
Subject: pixmap: infinite recursion with nonascii pnm-files
From: thomas.baumann@ch.tum.de
Date: Fri, 7 Dec 2001 11:07:52 +0100 (CET)
* PR# 1361 *
Subject: Matrix identification bug
From: hyu@stats.uwo.ca
Date: Tue, 5 Mar 2002 21:19:46 +0100 (MET)
..seems to be about Matrix package, not solve
* PR# 1662 *
Subject: fisher.test FEXACT memory bug "should not occur"
From: Martin Maechler <maechler@stat.math.ethz.ch>
Date: Thu, 13 Jun 2002 08:21:50 +0200
..The supplementary (table of sum one) is fixed for 1.5.1.
..Detection code for the first problem has been added to 1.5.1 which will stop
..the crash, but the underlying cause is still open.
* PR# 1716 *
Subject: rdiscrete in e1071 fails when n==1
From: "John Aitchison" <jaitchis@hwy.com.au>
Date: Fri, 28 Jun 2002 10:28:17 +1000
* PR# 1729 *
Subject: problem with qq( )
From: Jarno.Tuimala@Helsinki.Fi
Date: Tue, 2 Jul 2002 10:37:10 +0200 (MET DST)
..A report on lattice
* PR# 1741 *
Subject: groupedData constructor from a function
From: dieter.menne@menne-biomed.de
Date: Thu, 4 Jul 2002 15:59:59 +0200 (MET DST)
* PR# 1745 *
Subject: nlme: failed augPred with NA in an unused column
From: dieter.menne@menne-biomed.de
Date: Fri, 5 Jul 2002 08:32:32 +0200 (MET DST)
..nlme needs an update as suggested in the followup
* PR# 1901 *
Subject: svm seg faults
From: stefan.boehringer+science@uni-bochum.de
Date: Tue, 13 Aug 2002 14:12:17 +0200 (MET DST)
..Seem to be due to gcc `2.96' from RH7.3
* PR# 1974 *
Subject: Rwave installation problem
From: ld-temp-qt3i@pobox.com
Date: Mon, 2 Sep 2002 09:27:36 +0200 (MET DST)
..Instead, this should use ISO C headers, namely <stdlib.h>
* PR# 2173 *
Subject: xlim in plot.survfit() [with a discussion on "..."]
From: jerome@hivnet.ubc.ca
Date: Wed, 16 Oct 2002 18:46:11 +0200 (MET DST)
* PR# 2252 *
Subject: Ansari-Bradley test
From: wex00002@uconn.edu
Date: Sun, 3 Nov 2002 23:38:20 +0100 (MET)
* PR# 2302 *
Subject: Package tseries: crash for Windows version
From: Fan <xiao.gang.fan1@libertysurf.fr>
Date: Sun, 17 Nov 2002 15:28:14 +0100
..Actually, there is a mismatch between the R call and the 
..C code in pred_garch, so this is not Windows-specific.
* PR# 2320 *
Subject: Segmentation fault using "survival" package
From: jerome@hivnet.ubc.ca
Date: Sat, 23 Nov 2002 00:51:50 +0100 (MET)
* PR# 2322 *
Subject: simplex
From: george@lecompte.org
Date: Sat, 23 Nov 2002 17:30:37 +0100 (MET)
..report on boot, I think (not mentioned, though)
* PR# 2349 *
Subject: [R] NA in first panel of xyplot causes error
From: Wolfram Fischer <wolfram@fischer-zim.ch>
Date: Thu, 5 Dec 2002 15:32:32 +0100
..Lattice

Directory:  Analyses

none

Directory:  Documentation

* PR# 988 *
Subject: input for R-intro
From: "Paul E. Johnson" <pauljohn@ku.edu>
Date: Mon, 18 Jun 2001 13:57:10 -0500
* PR# 1011 *
Subject: R-intro suggestions part II
From: "Paul E. Johnson" <pauljohn@ukans.edu>
Date: Tue, 03 Jul 2001 15:50:06 -0500
* PR# 1136 *
Subject: cex/col/etc. in title(): documentation?
From: Ben Bolker <ben@zoo.ufl.edu>
Date: Mon, 22 Oct 2001 11:55:14 -0400 (EDT)
..MM:actually the documentation still could elaborate a bit..
* PR# 1772 *
Subject: bug(?) in R FAQ - Should I run R from within Emacs?
From: Tim.Harrold@csiro.au
Date: Thu, 11 Jul 2002 18:21:42 +1000

Directory:  Graphics

* PR# 202 *
Subject: persp box occlusion bug
From: wsi@gcal.ac.uk
Date: Wed, 2 Jun 1999 15:02:03 +0200 (MET DST)
..The persp algorithm does not apply the occlusion rules to the frame, 
..which is always plotted first. 
..A bug, but not very simple to fix.
* PR# 660 *
Subject: identify.default ignores any setting of cex.
From: Prof Brian Ripley <ripley@stats.ox.ac.uk>
Date: Fri, 15 Sep 2000 10:23:39 +0100 (BST)
* PR# 776 *
Subject: strwidth does not take font into account
From: Martyn Plummer <plummer@iarc.fr>
Date: Tue, 19 Dec 2000 14:56:01 +0100 (CET)
..This needs a substantial redesign.
* PR# 791 *
Subject:  par(lab= *) / axis(*) bug 
From: maechler@stat.math.ethz.ch
Date: Fri, 22 Dec 2000 10:59:26 +0100
* PR# 816 *
Subject: dotplot: character size of labels
From: RINNER Heinrich <H.RINNER@TIROL.GV.AT>
Date: Thu, 18 Jan 2001 14:54:32 +0100
..Suggested fix is incorporated in 1.2.2.
..
..There is a deeper problem:  mtext() ignores par(cex=.5) in general.  
..To see the problem try:  par(cex=.5); mtext("hi")
..Paul thinks the right fix is to change the argument list for mtext so that
..cex=par(cex) by default rather than cex=NA by default (plus corresponding
..internal changes to  do_mtext in plot.c).
..This needs to be done very carefully because (i) the change suggested above 
..mayhave side-effects in many other pieces of interpreted code 
..(ii) do_mtext ignores dd->gp.cexbase unlike, for example, do_plot_xy 
..and anything to do with cexbase needs extreme care.
* PR# 820 *
Subject: interaction.plot
From: "Mark M. Span" <span@psy.uva.nl>
Date: Mon, 22 Jan 2001 10:47:39 +0100
..mtext is unscaled by default.  It is not clear if this should
..use the par("cex") setting or an inline cex setting such as cex.axis.
..It might make more sense to use axis rather than mtext, as boxplot does.
* PR# 831 *
Subject: screen can't go back to (split) screen with log="y" plot
From: Thomas Vogels <tov@ece.cmu.edu>
Date: 30 Jan 2001 00:39:41 -0500
..Still there. Suggested fix included in followups, but we didn't get around to
..try it in time for 1.2.3.
..
..Fix doesn't work. One problem is that the opar<-par();par(opar) idiom updates
..xaxp before xlog, and the new value of xaxp may only be valid under the new
..value of xlog.
* PR# 837 *
Subject: screen doesn't handle redrawing properly
From: Thomas Vogels <tov@ece.cmu.edu>
Date: 01 Feb 2001 14:20:52 -0500
* PR# 887 *
Subject: axis(adj=anything) has no effect
From: jhallman@frb.gov
Date: Wed, 28 Mar 2001 20:51:05 +0200 (MET DST)
* PR# 943 *
Subject: legend() with xpd=T; omission of initial plot character
From: John Maindonald <john.maindonald@anu.edu.au>
Date: Sun, 20 May 2001 10:35:16 +1000
* PR# 997 *
Subject:  las=1 with log axis 
From: Peter Dalgaard BSA <pd@pubhealth.ku.dk>
Date: Wed, 27 Jun 2001 11:54:06 +0200
* PR# 1045 *
Subject: Palette changes on redraw
From: Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk>
Date: 08 Aug 2001 19:08:01 +0200
* PR# 1147 *
Subject: postscript problem
From: kjetil halvorsen <kjetilh@umsanet.edu.bo>
Date: Fri, 26 Oct 2001 15:23:45 -0400
..This seems to be a problem with screen/layout rather than postscript.
* PR# 1161 *
Subject: x-axis label in persp()
From: Rolf Turner <rolf@maths.uwa.edu.au>
Date: Wed, 7 Nov 2001 18:07:22 +0800 (WST)
* PR# 1207 *
Subject: boxplot labels incorrect when horizontal = TRUE
From: Rashid Nassar <rnassar@duke.edu>
Date: Sun, 9 Dec 2001 21:46:32 -0500 (EST)
* PR# 1235 *
Subject: Axes labelling with logarithmic scales
From: tobias.hoevekamp@ilw.agrl.ethz.ch
Date: Thu, 3 Jan 2002 15:29:02 +0100 (MET)
* PR# 1300 *
Subject: FW: layout and piechart diameter problem
From: "Warnes, Gregory R" <gregory_r_warnes@groton.pfizer.com>
Date: Thu, 7 Feb 2002 11:05:15 -0500 
* PR# 1305 *
Subject: interaction.plot (with misplaced legend)
From: Uwe Ligges <ligges@statistik.uni-dortmund.de>
Date: Fri, 08 Feb 2002 14:27:01 +0100
* PR# 1395 *
Subject: mgp parameter in par()
From: mh.smith@niwa.cri.nz
Date: Tue, 19 Mar 2002 06:11:49 +0100 (MET)
* PR# 1470 *
Subject: color of axis lines
From: gray@jimmy.harvard.edu
Date: Sat, 20 Apr 2002 22:21:44 +0200 (MET DST)
* PR# 1476 *
Subject: Bug: persp and colors
From: oliver.niggemann@acterna.com
Date: Tue, 23 Apr 2002 09:41:37 +0200 (MET DST)
* PR# 1505 *
Subject: pictex 
From: luchini@ehess.cnrs-mrs.fr
Date: Thu, 2 May 2002 12:23:21 +0200 (MET DST)
* PR# 1653 *
Subject: coplot behaviour
From: "RenE J.V. Bertin" <rjvbertin@hotmail.com>
Date: Mon, 10 Jun 2002 20:11:02 +0200
* PR# 1654 *
Subject: R 1.5.0: axis() does not honor the xaxp argument
From: "Robert D. Merithew" <merithew@ccmr.cornell.edu>
Date: Tue, 11 Jun 2002 09:29:39 -0400 (EDT)
* PR# 1659 *
Subject:  mtext() alignment of perpendicular text 
From: p.murrell@auckland.ac.nz
Date: Wed, 12 Jun 2002 13:29:45 +1200 (NZST)
* PR# 1878 *
Subject: close.screen
From: Martin.Schlather@uni-bayreuth.de
Date: Mon, 5 Aug 2002 22:35:02 +0200 (MET DST)
* PR# 1899 *
Subject: interaction.plot() legend too narrow when mfcol > 2
From: Martin Maechler <maechler@stat.math.ethz.ch>
Date: Tue, 13 Aug 2002 09:36:15 +0200
* PR# 1933 *
Subject: dev2eps() prints ticks with wrong length!
From: Timur Elzhov <Timur.Elzhov@jinr.ru>
Date: Fri, 23 Aug 2002 17:22:15 +0400
..dev.copy problem
* PR# 1972 *
Subject: lattice install
From: robert.king@newcastle.edu.au
Date: Mon, 2 Sep 2002 04:55:41 +0200 (MET DST)
..Perhaps lattice should require(grid) and print a clearer message?
* PR# 2069 *
Subject: split.screen problem
From: cbodily@att.net
Date: Thu, 26 Sep 2002 19:37:40 +0200 (MET DST)
* PR# 2283 *
Subject: Wandering usr values in par(no.readonly=TRUW)
From: Jari Oksanen <jarioksa@sun3.oulu.fi>
Date: Tue, 12 Nov 2002 13:50:44 +0200

Directory:  In-Out

* PR# 1688 *
Subject: Maybe a problem in binary read/write
From: accot@free.fr
Date: Tue, 18 Jun 2002 22:51:17 +0200 (MET DST)
..I don't think file() is said to work with devices!

Directory:  Installation

* PR# 1222 *
Subject: configure: sed: Function s%@PDFLATEX@%/usr/local/bin/pdflatex%g
From: Peter Kleiweg <kleiweg@let.rug.nl>
Date: Thu, 20 Dec 2001 14:09:42 +0100 (CET)
..problem is on hppa2.0-hp-hpux10.20: may be HP-UX specific
* PR# 1268 *
Subject: Solaris 2.6 Compile
From: gm81640@development.nssmb.com
Date: Thu, 17 Jan 2002 06:28:26 +0100 (MET)
..Most likely a compiler installation problem
* PR# 1291 *
Subject: Installation problem : SunOS
From: brendan_mcmahon@prusec.com
Date: Thu, 31 Jan 2002 18:00:55 +0100 (MET)
..looks like gcc compiled under different OS version.
* PR# 1415 *
Subject: int 32 bit error on SPARC 64bit
From: kss28@mail.cba.nau.edu
Date: Mon, 25 Mar 2002 21:18:58 +0100 (MET)
..Was gcc 2.95.2 in private followup.
..Probably unappropriate flags
* PR# 1428 *
Subject: R compile on Solaris 8 fails
From: brower@bst.rochester.edu
Date: Mon, 1 Apr 2002 22:19:07 +0200 (MET DST)
..problems with g++ not finding -lstdc++
..Not a problem with R per se
* PR# 1500 *
Subject: configure script fails on comment in tkConfig.sh
From: Peter Kleiweg <kleiweg@let.rug.nl>
Date: Tue, 30 Apr 2002 16:41:51 +0200 (CEST)
..Looks like a conspiracy between a shell problem and an oddity in Tk 8.0 rather
..than an R problem. Good to know for the workaround though. The comment in
..TK_XINCLUDES has since disappeared, at least in Tk 8.3.3.
* PR# 1501 *
Subject: configure error: Maybe change CFLAGS or FFLAGS?
From: ale@ini.phys.ethz.ch
Date: Wed, 1 May 2002 15:23:14 +0200 (MET DST)
..Tried to use fort77 on RedHat, should likely try g77 instead.
* PR# 1658 *
Subject: make install fails - index.html not found
From: dhouston@bio.ri.ccf.org
Date: Tue, 11 Jun 2002 22:14:07 +0200 (MET DST)
..Missing perl??
* PR# 1676 *
Subject: R configure.in makes bad alpha assumptions
From: mcmahill@mtl.mit.edu
Date: Sat, 15 Jun 2002 19:21:09 -0400 (EDT)
..Probably fixed in 1.5.1
* PR# 1825 *
Subject: bug in R-1.5.1 for Mac OS X installer
From: Kow Kuroda <kkuroda@crl.ucsd.edu>
Date: Mon, 22 Jul 2002 16:40:26 -0700
..Darwin port
* PR# 1829 *
Subject: R config failure on solaris
From: "Siva Ginjupalli" <gsivrao@hotmail.com>
Date: Wed, 24 Jul 2002 20:08:49 +0000
..Missing info on R version and compilers.
* PR# 1937 *
Subject:  Inconsistent use of Perl? 
From: Berwin Turlach <berwin@maths.uwa.edu.au>
Date: Sat, 24 Aug 2002 18:41:09 +0800
..Some packages require Perl v 5.005
* PR# 1995 *
Subject:  2002-09-08 1.6.0 build fails in Recommended 
From: <stvjc@channing.harvard.edu>
Date: Sun, 8 Sep 2002 23:57:39 -0400 (EDT)
..I think this got cleared up...
* PR# 1996 *
Subject:  config checks for --with-gnome need update 
From: <stvjc@channing.harvard.edu>
Date: Mon, 9 Sep 2002 00:08:59 -0400 (EDT)

Directory:  Language

* PR# 408 *
Subject: convolution bug
From: wsimpson@gcal.ac.uk
Date: Fri, 28 Jan 2000 11:17:36 +0100 (MET)
* PR# 412 *
Subject: anomalies with call objects
From: Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk>
Date: 06 Feb 2000 01:18:50 +0100
* PR# 669 *
Subject: Bug(s) w/ rbind.data.frame(); fix also read.table(*, as.is = TRUE) ?
From: Martin Maechler <maechler@stat.math.ethz.ch>
Date: Mon, 25 Sep 2000 10:17:15 +0200
..status of AsIs columns
* PR# 1073 *
Subject: Wierd problem comparing numeric values and list using ==
From: "Warnes, Gregory R" <gregory_r_warnes@groton.pfizer.com>
Date: Fri, 24 Aug 2001 22:07:41 -0400
..see also PR#1075
* PR# 1076 *
Subject: Re: [Rd] Wierd problem comparing numeric values and list using == 
From: John Chambers <jmc@research.bell-labs.com>
Date: Mon, 27 Aug 2001 08:44:22 -0400
..part of PR#1073
* PR# 1186 *
Subject: a patch to tapply
From: Vadim Ogranovich <vograno@arbitrade.com>
Date: Thu, 29 Nov 2001 14:48:35 -0600
* PR# 1214 *
Subject: syntax questtion, maybe a bug
From: Rich Heiberger <rmh@surfer.sbm.temple.edu>
Date: Thu, 13 Dec 2001 13:46:54 -0500 (EST)
..Is .2logl meant to be a valid name in R? It is S
* PR# 1241 *
Subject:  Problem with "missing" in "local" 
From: J.C.Rougier@durham.ac.uk
Date: Fri, 4 Jan 2002 13:34:34 GMT
* PR# 1891 *
Subject: summary.data.frame with compound elements problem
From: b.rowlingson@lancaster.ac.uk
Date: Fri, 9 Aug 2002 10:35:43 +0200 (MET DST)

Directory:  Low-level

* PR# 989 *
Subject: "[.data.frame" allows un-named 3rd subscript
From: "Charles C. Berry" <cberry@tajo.ucsd.edu>
Date: Mon, 18 Jun 2001 13:13:46 -0700 (PDT)
* PR# 1068 *
Subject: Interrupts (was Re: [Rd] X11 protocol errors ...)
From: Luke Tierney <luke@nokomis.stat.umn.edu>
Date: Wed, 22 Aug 2001 19:32:51 -0500
..see also followup in PR#1069
* PR# 1069 *
Subject: Interrupts (was Re: [Rd] X11 protocol errors ...)
From: "John W. Eaton" <jwe@bevo.che.wisc.edu>
Date: Wed, 22 Aug 2001 21:56:33 -0500
..part of PR#1068
* PR# 1880 *
Subject:  You requested this report 
From: Berwin Turlach <berwin@maths.uwa.edu.au>
Date: Tue, 6 Aug 2002 16:57:54 +0800
..The bug is that we get as far as mkCLOSXP before an error is reported
* PR# 2253 *
Subject: [R] CTRL-C suspends echo of shell (R versions 1.6.0 and 1.6.1)
From: Wolfram Fischer - Z/I/M <wolfram@fischer-zim.ch>
Date: Mon, 4 Nov 2002 10:18:48 +0100

Directory:  Macintosh

* PR# 1819 *
Subject: Date arithmetic fails
From: RML27@cornell.edu
Date: Sun, 21 Jul 2002 20:26:12 +0200 (MET DST)
..In fact, as.POSIXct is off by 66 years. See
..   http://developer.apple.com/qa/ops/ops23.html
..This is semifixed, but timezones still don't work
* PR# 1991 *
Subject: Mac Save As... bug
From: Tim Cole <tjc1@cam.ac.uk>
Date: Sun, 8 Sep 2002 13:47:00 +0100
* PR# 2276 *
Subject: Mac specific - quartz leads to crash
From: h95mr@mun.ca
Date: Fri, 8 Nov 2002 16:28:50 +0100 (MET)

Directory:  Misc

* PR# 1126 *
Subject: R-bug report www page whishlist
From: jens.lund@nordea.com
Date: Wed, 10 Oct 2001 18:24:29 +0200 (MET DST)
* PR# 1158 *
Subject: bug.report()sends empty message
From: Paul Gilbert <pgilbert@bank-banque-canada.ca>
Date: Mon, 05 Nov 2001 10:05:27 -0500
* PR# 1503 *
Subject: R-GNOME
From: Patrick Gonin <gonin@genethon.fr>
Date: Thu, 2 May 2002 09:29:07 +0200
..1) is not a bug, as jpeg etc work.  capabilities() has been changed for 1.5.1
..2) system() needs a new version for GNOME.

Directory:  Models

* PR# 1861 *
Subject: update() can not find objects
From: yzhou@arcturusag.com
Date: Thu, 1 Aug 2002 19:01:59 +0200 (MET DST)
..The problem is actually deeper than this.
..
..Sometime update() wants to evaluate arguments in the environment where the model
..was defined, as here. 
..
..Sometimes it wants to use the current environment, eg this snippet from MASS 
..ph.fun <- function(data, i) {
..  d <- data
..  d$calls <- d$fitted + d$res[i]
..  coef(update(fit, data=d))
..}
* PR# 2206 *
Subject: model.matrix (via predict)
From: Glenn.Stone@csiro.au
Date: Thu, 24 Oct 2002 06:33:02 +0200 (MET DST)
..strange model used!

Directory:  Startup

none

Directory:  System-specific

* PR# 848 *
Subject: X11 device doesn't handle destroy events correcly
From: Thomas Vogels <tov@ece.cmu.edu>
Date: 13 Feb 2001 17:40:46 -0500
* PR# 1020 *
Subject: .Call and Mandrake 8.0
From: lcottret@yahoo.fr
Date: Wed, 11 Jul 2001 15:34:23 +0200 (MET DST)
..problem with symbol names only on Mandrake 8.0, not 7.2
..needs reply to follow-up
* PR# 1097 *
Subject: R 1.3.1 fails 'make check' on arm in the Bessel example
From: Dirk Eddelbuettel <edd@debian.org>
Date: Thu, 20 Sep 2001 23:54:19 -0500
..This platform turned out to have badly broken FPU behaviour. Given up, at 
..least for now .
* PR# 1140 *
Subject: Possible bug, Rprof() and scan(pipe())
From: Don MacQueen <macq@llnl.gov>
Date: Tue, 23 Oct 2001 13:50:26 -0700
..MacOS X: Doesn't happen on Solaris or Linux
* PR# 1145 *
Subject: Problem testing R version 1.3.1 on SGI Irix
From: Gordon Lack <gml4410@ggr.co.uk>
Date: Fri, 26 Oct 2001 19:04:04 +0100
..error from using SGI libblas (not reported on other systems?)
..use --without-blas
* PR# 1261 *
Subject: R_140 AND RHL_72 AND Packages
From: Patrick Gonin <gonin@genethon.fr>
Date: Wed, 15 Jan 2003 13:25:17 +0100
..Seems to relate to RH7.2 rpms
* PR# 1272 *
Subject: eigen segfault with GCC 3 on Solaris
From: Paul Gilbert <pgilbert@bank-banque-canada.ca>
Date: Thu, 17 Jan 2002 15:14:33 -0500
..Seems to be a problem with g77 in gcc 3.0.2 on Solaris only.
..Probably a compiler bug
* PR# 1275 *
Subject: compile problem with bessel_i.c on IRIX64 flexor 6.5 10100655 IP35 (uname -a)
From: Walter Tautz <wtautz@math.uwaterloo.ca>
Date: Tue, 22 Jan 2002 10:05:20 -0500 (EST)
* PR# 1289 *
Subject: R 1.4.0 build fails on AIX
From: lio@hpss1.ccs.ornl.gov
Date: Wed, 30 Jan 2002 14:10:30 +0100 (MET)
* PR# 1316 *
Subject: shared libraries on AIX
From: lio@hpss1.ccs.ornl.gov
Date: Mon, 18 Feb 2002 18:53:41 +0100 (MET)
* PR# 1461 *
Subject: make check fails d-p-q-r-tests.R - OpenBSD 3.0
From: Jason Turner <jasont@indigoindustrial.co.nz>
Date: Mon, 15 Apr 2002 10:13:36 +0000
* PR# 1606 *
Subject: hitting ^C breaks readline history
From: Cyril Humbert <humbertc@univ-mlv.fr>
Date: Tue, 28 May 2002 12:07:07 +0200 (MET DST)
* PR# 2091 *
Subject: Scripts not executable
From: Peter Kleiweg <kleiweg@let.rug.nl>
Date: Wed, 2 Oct 2002 00:54:15 +0200 (CEST)
* PR# 2144 *
Subject: Save() with ascii=TRUE may corrupt numeric values
From: "Efthymiou, Nick" <Nick.Efthymiou@schwab.com>
Date: Thu, 10 Oct 2002 14:09:21 -0700
..Only on systems without vsnprintf

Directory:  TooMuchAtOnce

none

Directory:  Windows

* PR# 1711 *
Subject: GUI bug
From: socrates@mail.ru
Date: Thu, 27 Jun 2002 10:30:51 +0200 (MET DST)
..A crash that is *very* hard to trigger (after several
..minutes of continuous resizing)

Directory:  incoming

* PR# 1556 *
Subject: lib.fixup, .GlobalEnv, and R1.5.0
From: mark.bravington@csiro.au
Date: Wed, 15 May 2002 08:30:50 +0200 (MET DST)
* PR# 2094 *
Subject: Mean and var inconsistency
From: Kevin.Wright@pioneer.com
Date: Wed, 2 Oct 2002 16:19:27 +0200 (MET DST)
* PR# 2345 *
Subject: difftime arithmetic
From: B.Rowlingson@lancaster.ac.uk
Date: Wed, 4 Dec 2002 17:58:49 +0100 (MET)
* PR# 2352 *
Subject: avas: segmentation fault on empty args
From: vograno@arbitrade.com
Date: Fri, 6 Dec 2002 19:41:48 +0100 (MET)


From ekiomo150@netscape.net  Sat Dec  7 11:18:04 2002
From: ekiomo150@netscape.net (ekiomo150@netscape.net)
Date: Sat Dec  7 11:18:04 2002
Subject: [Rd] GOOD-DAY (PR#2353)
Message-ID: <200212071018.LAA13450@pubhealth.ku.dk>

------=_NextPart_000_0067_7D95D683.25EB50AE
Content-Type: text/plain
Content-Transfer-Encoding: base64
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------=_NextPart_000_0067_7D95D683.25EB50AE--


From arnima@u.washington.edu  Sun Dec  8 00:29:03 2002
From: arnima@u.washington.edu (arnima@u.washington.edu)
Date: Sun Dec  8 00:29:03 2002
Subject: [Rd] Bug in logLik.nls (PR#2354)
Message-ID: <200212072329.AAA15158@pubhealth.ku.dk>

Platform: i386-pc-mingw32 (Windows XP)
Program:  R (1.6.1, 1 Nov 2002)
Package:  nls (1.6.1, 8 Nov 2002)



Dear R Core Team,


I believe there is a bug in logLik.nls because it counts model degrees of
freedom incorrectly, misleading AIC. Consider the following example:

my.lm <- lm(y~x)                        # simple linear regression
my.nls <- nls(y~b0+b1*x, start=c(0,0))  # ditto
logLik(my.lm)  # returns `log Lik.' -290.5322 (df=3), correct
logLik(my.nls) # returns `log Lik.' -290.5322 (df=1), incorrect
AIC(my.lm)     # returns 587.0645, correct
AIC(my.nls)    # returns 583.0645, incorrect


It looks like the culprit is line 10 in logLik.nls:

attr(val, "df") <- length(object[["parameters"]]) + 1

where object[["parameters"]] works in S-Plus but fails in R. This line
could be replaced with something like:

attr(val, "df") <- length(coef(object)) + 1


All the best,
Arni


From Torsten.Hothorn@rzmail.uni-erlangen.de  Mon Dec  9 10:26:02 2002
From: Torsten.Hothorn@rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon Dec  9 10:26:02 2002
Subject: [Rd] APL?
Message-ID: <Pine.LNX.4.21.0212091021480.7780-100000@artemis>

Hi, 

is anybody out there who knows APL and would help me to translate 52
lines of APL code into propper R? 

best, 

Torsten


From maechler@stat.math.ethz.ch  Mon Dec  9 12:22:25 2002
From: maechler@stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Mon Dec  9 12:22:25 2002
Subject: [Rd] Bug in logLik.nls (PR#2354)
Message-ID: <200212091120.MAA22906@pubhealth.ku.dk>

Thank you, Arni,
for your bug report!

However, this has been reported before, as PR#2295,
and fixed for "R-patched" quite a while.

Martin


From Martin Maechler <maechler@stat.math.ethz.ch>  Mon Dec  9 12:29:02 2002
From: Martin Maechler <maechler@stat.math.ethz.ch> (Martin Maechler)
Date: Mon Dec  9 12:29:02 2002
Subject: [Rd] APL?
In-Reply-To: <Pine.LNX.4.21.0212091021480.7780-100000@artemis>
References: <Pine.LNX.4.21.0212091021480.7780-100000@artemis>
Message-ID: <15860.32355.897330.942649@gargle.gargle.HOWL>

>>>>> "Torsten" == Torsten Hothorn <Torsten.Hothorn@rzmail.uni-erlangen.de>
>>>>>     on Mon, 9 Dec 2002 10:25:34 +0100 (MET) writes:

    Torsten> Hi,

    Torsten> is anybody out there who knows APL and would help
    Torsten> me to translate 52 lines of APL code into propper
    Torsten> R?

I do (did) know it. It's been my first "real" programming
language (1976 or so), but translating 52 lines of APL may
result in 500 lines of R code which needs too long...

Martin


From hosking@watson.ibm.com  Mon Dec  9 16:57:11 2002
From: hosking@watson.ibm.com (hosking@watson.ibm.com)
Date: Mon Dec  9 16:57:11 2002
Subject: [Rd] pmax loses row names (PR#2357)
Message-ID: <200212091554.QAA27421@pubhealth.ku.dk>

Full_Name: J. R. M. Hosking
Version: 1.5
OS: Win2000
Submission from: (NULL) (198.81.209.17)


Documentation for pmax says "`attributes' (such as `names' or `dim') are
transferred from the first argument (if applicable)".  But:

> a<-matrix(c(1,2,3,-1,-2,3),2,3,dimnames=list(c("A","B"),NULL))
> a
  [,1] [,2] [,3]
A    1    3   -2
B    2   -1    3
> pmax(a,0)
     [,1] [,2] [,3]
[1,]    1    3    0
[2,]    2    0    3
 
The row names have been lost.  This doesn't happen with column names, and it
doesn't happen in S-plus, so it looks like a bug.


From tlumley@u.washington.edu  Mon Dec  9 22:40:04 2002
From: tlumley@u.washington.edu (Thomas Lumley)
Date: Mon Dec  9 22:40:04 2002
Subject: [Rd] win/pentium 4 (was: can this happen?)
Message-ID: <Pine.A41.4.44.0212091321510.179436-100000@homer41.u.washington.edu>

I reported an inconsistency in results in the same R program run on
different Windows computers and received some suggestions

It isn't due to the version of msvcrt.dll (Peter Dalgaard & Brian Ripley)
and isn't fixed by Duncan Murdoch's patches to windows R.

More experimentation has shown that the set of results I like less
(involving internal error reports from optim()) happens on 3 out of 3
Pentium 4 machines, and not on 2 Pentium 3s (or on a dual Athlon under
Linux).


	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley@u.washington.edu	University of Washington, Seattle


From tlumley@u.washington.edu  Mon Dec  9 23:28:02 2002
From: tlumley@u.washington.edu (Thomas Lumley)
Date: Mon Dec  9 23:28:02 2002
Subject: [Rd] win/pentium 4 (was: can this happen?)
In-Reply-To: <Pine.A41.4.44.0212091321510.179436-100000@homer41.u.washington.edu>
Message-ID: <Pine.A41.4.44.0212091425520.12842-100000@homer17.u.washington.edu>

On Mon, 9 Dec 2002, Thomas Lumley wrote:

>
> I reported an inconsistency in results in the same R program run on
> different Windows computers and received some suggestions
>
> It isn't due to the version of msvcrt.dll (Peter Dalgaard & Brian Ripley)
> and isn't fixed by Duncan Murdoch's patches to windows R.
>
> More experimentation has shown that the set of results I like less
> (involving internal error reports from optim()) happens on 3 out of 3
> Pentium 4 machines, and not on 2 Pentium 3s (or on a dual Athlon under
> Linux).
>

Using Rterm instead of Rgui seems to fix the optim() errors (in one
example on one machine, so far).


	-thomas


From gatekeeper@EUnet.yu  Tue Dec 10 05:25:03 2002
From: gatekeeper@EUnet.yu (gatekeeper@EUnet.yu)
Date: Tue Dec 10 05:25:03 2002
Subject: [Rd] PORUKA KOJU STE POSLALI SADRZI VIRUS / VIRUS IN YOUR MAIL
Message-ID: <200212100424.gBA4OTm27340@smtp2.eunet.yu>

             U P O Z O R E N J E - D E T E K T O V A N  V I R U S
                             V I R U S  A L E R T
			       
			       
  Nas antivirus softver pronasao je  |   Our viruschecker found the

     	infected: I-Worm.Klez.h 


  virus(e) u poruci koju ste poslali |   virus(es) in your email
  na sledece adrese:                 |   to the following recipient(s):

     tomicb@eunet.yu

  Molimo vas da skenirate vas sistem |   Please check your system for
  antivirus softverom ili napomenete |   viruses or ask your system
  vasem administratoru da to ucini.  |   administrator to do so.

  Zarazena poruka je isporucena      |   The infected message has been
  primaoc(u/ima) u vidu attachmenta, |   delivered to the recipient(s)
  sa porukom upozorenja.             |   as an attachment to the warning
                                     |   message.

  PAZNJA: Samodistribuirajuci virusi |   ATTENTION: Self-distributing
  cesto koriste lazne adrese u From: |   viruses often use fake addresses
  polju poruka, pa nije iskljucena   |   in From: field of the message,
  mogucnost da je zarazena poruka    |   so it is possible that the
  poslata sa racunara koji u svom    |   infected message was sent from
  adresaru poseduje vasu adresu, bez |   a host that contains your address
  znanja njegovog vlasnika. Ukoliko  |   in the address book, without it's
  je to ovde slucaj, najverovatnije  |   owner's knowledge. If this is the  
  vas racunar nije zarazen.          |   case, it is most likely that your
  Medjutim, preporucujemo vam da     |   computer is not infected.
  ipak proverite vas sistem.         |   However, we recommend that you
                                     |   check your system anyway.

 =========================================================================
 ===== ___                        = YUnet Antivirus E-Mail Gateway
 ==== /     /  /   __   ___  _/_ == EUnet Yugoslavia, YUnet International
 === /---  /  /  /  /  /__   /  === 4 Obilicev Venac, 11000 Belgrade, YU
 == /___  /__/  /  /  /__   /  ==== phone: +381 11 3119233
 ==                             === http://www.EUnet.yu/
 == Connecting Europe since 1982 == e-mail: gatekeeper@EUnet.yu
 =========================================================================


From Mark.Bravington@csiro.au  Tue Dec 10 06:29:03 2002
From: Mark.Bravington@csiro.au (Mark.Bravington@csiro.au)
Date: Tue Dec 10 06:29:03 2002
Subject: [Rd] names<- bug, and incompatibility with c() (PR#2358)
Message-ID: <200212100529.GAA00131@pubhealth.ku.dk>

When assigning names to particular elements of hitherto-unnamed vectors,
there is inconsistent behaviour depending on whether the element being named
is the last one:

test> mm <- 1:3
test> names( mm)[1] <- 'y'
Error in "names<-.default"(*tmp*, value = "y") : 
        names attribute must be the same length as the vector
test> names( mm)[2] <- 'y'
Error in "names<-.default"(*tmp*, value = "y") : 
        names attribute must be the same length as the vector
test> names( mm)[3] <- 'y'
test> mm
<NA> <NA>    y 
   1    2    3 
   
As long as the last element of mm gets mentioned, R will allow the
operation, filling in any blanks with NA-strings. But if the last element of
mm isn't specified somewhere in the vector of things-to-be-named, R won't
allow the operation.

If mm already has names, there's no problem.

The usage above is sometimes valuable, and it should be easy to fix it, by
supplying default names in all other positions. But there is also some
inconsistency with the use of "c": should default names be NA-strings, or
empty strings? 

test> mm <- 1:2
test> names( mm)[2] <- 'y'
test> mm
<NA>    y 
   1    2 
test> mm <- c( mm, 3)
test> mm
NA  y    
 1  2  3 
test> names( mm)[1]
[1] "NA"
test> 

 Note that "c" has supplied an empty string for the unspecified name, and
has also taken the liberty of changing the special NA-string into a "NA"
(i.e. a 2-character string, first letter N, second letter A)!
 
An easy way to achieve consistency, would be to make unsupplied names should
always default to an empty string, rather than a special NA-string.
 
 cheers
 Mark


--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 1
 minor = 6.1
 year = 2002
 month = 11
 day = 01
 language = R

Windows 2000 Professional (build 2195) Service Pack 2.0

Search Path:
 .GlobalEnv, ROOT, package:handy, package:debug, mvb.session.info,
package:mvbutils, package:tcltk, Autoloads, package:base


From ripley@stats.ox.ac.uk  Tue Dec 10 12:41:02 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Dec 10 12:41:02 2002
Subject: [Rd] names<- bug, and incompatibility with c() (PR#2358)
Message-ID: <200212101140.MAA03623@pubhealth.ku.dk>

This is S-compatible, though, and it I think it is quite legitimately
an error.  I will fix it in R-devel, but I am little concerned that
advanced users may be surprised (but they probably would never do this).

> there is inconsistent behaviour depending on whether the element being named
> is the last one:
>
> test> mm <- 1:3
> test> names( mm)[1] <- 'y'
> Error in "names<-.default"(*tmp*, value = "y") :
>         names attribute must be the same length as the vector
> test> names( mm)[2] <- 'y'
> Error in "names<-.default"(*tmp*, value = "y") :
>         names attribute must be the same length as the vector
> test> names( mm)[3] <- 'y'
> test> mm
> <NA> <NA>    y
>    1    2    3
>
> As long as the last element of mm gets mentioned, R will allow the
> operation, filling in any blanks with NA-strings. But if the last element of
> mm isn't specified somewhere in the vector of things-to-be-named, R won't
> allow the operation.
>
> If mm already has names, there's no problem.
>
> The usage above is sometimes valuable, and it should be easy to fix it, by
> supplying default names in all other positions. But there is also some
> inconsistency with the use of "c": should default names be NA-strings, or
> empty strings?

They should now be NA-strings.

> test> mm <- 1:2
> test> names( mm)[2] <- 'y'
> test> mm
> <NA>    y
>    1    2
> test> mm <- c( mm, 3)
> test> mm
> NA  y
>  1  2  3
> test> names( mm)[1]
> [1] "NA"
> test>
>
>  Note that "c" has supplied an empty string for the unspecified name, and
> has also taken the liberty of changing the special NA-string into a "NA"
> (i.e. a 2-character string, first letter N, second letter A)!

That's a bug.

> An easy way to achieve consistency, would be to make unsupplied names should
> always default to an empty string, rather than a special NA-string.

But what's the point of having a special string then?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Mark.Bravington@csiro.au  Tue Dec 10 23:32:02 2002
From: Mark.Bravington@csiro.au (Mark.Bravington@csiro.au)
Date: Tue Dec 10 23:32:02 2002
Subject: [Rd] names<- bug, and incompatibility with c() (PR#2358)
Message-ID: <A8877251964B294BAB5BA1FC58B43FED025B442F@molly.tas.csiro.au>

#> From: Mark.Bravington@csiro.au 

#> When assigning names to parts of an hitherto-unnamed vector,
#> there is inconsistent behaviour depending on whether the 
#element being named
#> is the last one:
#>
#> test> mm <- 1:3
#> test> names( mm)[1] <- 'y'
#> Error in "names<-.default"(*tmp*, value = "y") :
#>         names attribute must be the same length as the vector
#> test> names( mm)[2] <- 'y'
#> Error in "names<-.default"(*tmp*, value = "y") :
#>         names attribute must be the same length as the vector
#> test> names( mm)[3] <- 'y'
#> test> mm
#> <NA> <NA>    y
#>    1    2    3

#From: ripley@stats.ox.ac.uk [mailto:ripley@stats.ox.ac.uk]

#Subject: Re: [Rd] names<- bug, and incompatibility with c() (PR#2358)
#
#
#This is S-compatible, though, and it I think it is quite legitimately
#an error.  I will fix it in R-devel, but I am little concerned that
#advanced users may be surprised (but they probably would never 
#do this).

don't be so sure! The "names" attribute can be useful for many things
besides the obvious-- "There are more things in heaven and earth,
Horatio,..."   ;)

#>  Note that "c" has supplied an empty string for the 
#unspecified name, and
#> has also taken the liberty of changing the special NA-string 
#into a "NA"
#> (i.e. a 2-character string, first letter N, second letter A)!
#
#That's a bug.

If you use NA-strings for unsupplied names, then will you for consistency be
making another change to c() so that

> mm <- c( a=1, b=2)
> mm <- c( mm, 5)

now gives an NA-string for mm's 3rd name? 

#
#> An easy way to achieve consistency, would be to make 
#unsupplied names should
#> always default to an empty string, rather than a special NA-string.
#
#But what's the point of having a special string then?

That's just what I was wondering (in the specific case of names attributes).
I can see the logic of NA-string names, but I do wonder whether this will
cause more practical problems than just using an empty string. It's not just
back-compatibility, but also unexpected behaviour. For example, after
setting up mm as above:

test> mm
<NA> <NA>    y 
   1    2    3 
test> names( mm)=='y'
[1]   NA   NA TRUE
test> mm[ names(mm)=='y']
<NA> <NA>    y 
  NA   NA    3 

the last line being a bit surprising to me, anyway. It's not a bug, but will
it be helpful? Empty names instead of NA-names give a behaviour that seems
to me more "natural". 

cheers
Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012


From dmurdoch@pair.com  Wed Dec 11 01:28:02 2002
From: dmurdoch@pair.com (Duncan Murdoch)
Date: Wed Dec 11 01:28:02 2002
Subject: [Rd] Flat documentation?
Message-ID: <b5vcvu0tp8ab3r1o9r9m9c1rqv4rke2llp@4ax.com>

Putting together documentation in Rd format is a bit of a pain.  In
fact, one of my colleagues has chosen to use S-PLUS instead of R
partly because it's easier to document the stuff he's written.  (In
S-PLUS plain text files can be used to document your code.  At least
they could in fairly recent versions; I don't have the current one
installed.)

I think it's reasonable to require Rd format documents for stuff on
CRAN, but it should be easier to document things that are for personal
use or limited distribution.

Are there existing schemes that help in this?  If not, would it be
worth putting one together?

Duncan Murdoch


From Mark.Bravington@csiro.au  Wed Dec 11 02:17:06 2002
From: Mark.Bravington@csiro.au (Mark.Bravington@csiro.au)
Date: Wed Dec 11 02:17:06 2002
Subject: [Rd] Flat documentation?
Message-ID: <A8877251964B294BAB5BA1FC58B43FED025B4436@molly.tas.csiro.au>

#-----Original Message-----
#From: Duncan Murdoch [mailto:dmurdoch@pair.com]
#Subject: [Rd] Flat documentation?
#
#
#Putting together documentation in Rd format is a bit of a pain.  In
#fact, one of my colleagues has chosen to use S-PLUS instead of R
#partly because it's easier to document the stuff he's written.  (In
#S-PLUS plain text files can be used to document your code.  At least
#they could in fairly recent versions; I don't have the current one
#installed.)
#

(1) Yes, I'd agree with that, speaking as an occasional package developer.
After all, the Windows binary (a fair proportion of the market) doesn't even
include Rd files. I've distributed a quite a bit of material to colleagues,
but the documentation issue has put me off releasing stuff more widely,
because of lack of time; it's very slow, and not much fun, to have to write
in Rd. 

#I think it's reasonable to require Rd format documents for stuff on
#CRAN, but it should be easier to document things that are for personal
#use or limited distribution.
#

(2) NB what are the alternatives for distribution, apart from CRAN? CRAN
currently has an "outside of CRAN" section, which mentions just 2 other
websites; could this be systematically expanded, to include references to
"informal packages" on other websites? [I've wondered about this, because
when I eventually do post to CRAN or somewhere, I will need to distribute
DLLs as my source code isn't in C. CRAN itself won't host DLLs, for security
reasons.]

#Are there existing schemes that help in this?  If not, would it be
#worth putting one together?

(3) It might well encourage the free exchange of useful programs, I think.

Eventually, writers will need to put things into Rd format, though. One
thing that might make this easier, is tools that can produce Rd from other
structured document formats for which there are already easy editing tools;
LaTex springs to mind, or HTML. Tools for converting *from* Rd already
exist, according to R-exts.pdf. (There was a recent exchange indicating that
something like this used to exist for SGML, but is now broken.)

For example, I use Scientific Word as a front-end to LaTeX (and very good it
is too, BTW; no \ and $ and { to worry about, it's all taken care of
automatically). I think it might be possible to produce a LaTeX package /
SciWord "shell" which makes it easy to bang out something very close to Rd
format; maybe just a short Perl function away. I posted yesterday to
Scientific Word, asking if anyone had done this; no reply yet, and I'm not
hopeful. But I'd love to hear otherwise!

cheers
Mark


*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington@csiro.au 

#
#______________________________________________
#R-devel@stat.math.ethz.ch mailing list
#http://www.stat.math.ethz.ch/mailman/listinfo/r-devel
#


From rossini@u.washington.edu  Wed Dec 11 02:29:02 2002
From: rossini@u.washington.edu (A.J. Rossini)
Date: Wed Dec 11 02:29:02 2002
Subject: [Rd] Flat documentation?
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED025B4436@molly.tas.csiro.au>
References: <A8877251964B294BAB5BA1FC58B43FED025B4436@molly.tas.csiro.au>
Message-ID: <871y4puyz9.fsf@jeeves.blindglobe.net>

>>>>> "mark" == Mark Bravington <Mark.Bravington@csiro.au> writes:

    mark> Eventually, writers will need to put things into Rd format, though. One
    mark> thing that might make this easier, is tools that can produce Rd from other
    mark> structured document formats for which there are already easy editing tools;
    mark> LaTex springs to mind, or HTML. Tools for converting *from* Rd already
    mark> exist, according to R-exts.pdf. (There was a recent exchange indicating that
    mark> something like this used to exist for SGML, but is now broken.)

what about "prompt"?  A bit more work, maybe a few widgets (ala
Bioconductor's widgets for adding MIAME information to chips; that is,
free-text fields/paragraphs) could result in "easy" generation of
documentation.  

Or is that not simple enough?

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini@u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini@scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)


From dmurdoch@pair.com  Wed Dec 11 03:10:03 2002
From: dmurdoch@pair.com (Duncan Murdoch)
Date: Wed Dec 11 03:10:03 2002
Subject: [Rd] Flat documentation?
In-Reply-To: <871y4puyz9.fsf@jeeves.blindglobe.net>
References: <A8877251964B294BAB5BA1FC58B43FED025B4436@molly.tas.csiro.au> <871y4puyz9.fsf@jeeves.blindglobe.net>
Message-ID: <146dvukntaqmcpr1at7hl0i5vks3fvigh8@4ax.com>

On 10 Dec 2002 17:27:06 -0800, you wrote:

>>>>>> "mark" == Mark Bravington <Mark.Bravington@csiro.au> writes:
>
>    mark> Eventually, writers will need to put things into Rd format, though. One
>    mark> thing that might make this easier, is tools that can produce Rd from other
>    mark> structured document formats for which there are already easy editing tools;
>    mark> LaTex springs to mind, or HTML. Tools for converting *from* Rd already
>    mark> exist, according to R-exts.pdf. (There was a recent exchange indicating that
>    mark> something like this used to exist for SGML, but is now broken.)
>
>what about "prompt"?  A bit more work, maybe a few widgets (ala
>Bioconductor's widgets for adding MIAME information to chips; that is,
>free-text fields/paragraphs) could result in "easy" generation of
>documentation.  
>
>Or is that not simple enough?

I think with the few extra widgets that would be fine for putting
together Rd files.  But there is still an overhead to Rd files in two
respects:

  - There is a lot of structure to an Rd file.  There are conventions
for how they're organized that need to be learned.  Sometimes it's
nice just to be able to associate some hastily written text with a
function.  

  - There is some amount (I'm honestly not sure exactly how much)
"infrastructure" needed before they work at all.  Most Windows users
won't have that.  I think you need  the "Source Package Installation
Files" plus a number of tools (including Perl) installed before you
can do anything with them.  I could make the installation files a
default install item, but they won't work without the tools.

I don't know how much these flat files should participate in the
overall R help system.  The more they show up like regular help topics
the better, but that's going to impose constraints on what goes in
them.  For example, cross-references or entries in the contents or
index listings would be nice, but would need markup of some sort.  

Duncan Murdoch


From rossini@u.washington.edu  Wed Dec 11 03:53:02 2002
From: rossini@u.washington.edu (A.J. Rossini)
Date: Wed Dec 11 03:53:02 2002
Subject: [Rd] Flat documentation?
In-Reply-To: <146dvukntaqmcpr1at7hl0i5vks3fvigh8@4ax.com>
References: <A8877251964B294BAB5BA1FC58B43FED025B4436@molly.tas.csiro.au>
 <871y4puyz9.fsf@jeeves.blindglobe.net>
 <146dvukntaqmcpr1at7hl0i5vks3fvigh8@4ax.com>
Message-ID: <87u1hlxo5h.fsf@jeeves.blindglobe.net>

>>>>> "duncan" == Duncan Murdoch <dmurdoch@pair.com> writes:

    duncan> I don't know how much these flat files should participate
    duncan> in the overall R help system.  The more they show up like
    duncan> regular help topics the better, but that's going to impose
    duncan> constraints on what goes in them.  For example,
    duncan> cross-references or entries in the contents or index
    duncan> listings would be nice, but would need markup of some
    duncan> sort.

I'm not sure how indexing might go.

One thought would be to do similar to the bioconductor Sweave files,
but completely in the opposite direction.

I.e. 

DHT (dumb help text) files could be put into an appropriate directory,
and then we could have a DHT.browser() function that would cat out,
using a pager, a copy of the file, or without prompting, give a list
of packages and topics for each package covered by DHT files.

Then, you'd stick 2 lines of formatting at the topic, ala the SWeave
vignettes, for indexing and referencing stuff.

I'd call it illiterate statistical programming, just to complete the
notion that they are complete opposites from the vignettes.

On re-reading the above, I think I need more sleep and less stress;
this isn't one of my better ideas...

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini@u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini@scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)


From ripley@stats.ox.ac.uk  Wed Dec 11 08:55:03 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec 11 08:55:03 2002
Subject: [Rd] Flat documentation?
In-Reply-To: <b5vcvu0tp8ab3r1o9r9m9c1rqv4rke2llp@4ax.com>
Message-ID: <Pine.LNX.4.31.0212110750500.23961-100000@gannet.stats>

On Tue, 10 Dec 2002, Duncan Murdoch wrote:

> Putting together documentation in Rd format is a bit of a pain.  In
> fact, one of my colleagues has chosen to use S-PLUS instead of R
> partly because it's easier to document the stuff he's written.  (In
> S-PLUS plain text files can be used to document your code.  At least
> they could in fairly recent versions; I don't have the current one
> installed.)

That was only so on Windows, and I *think* not true on S-PLUS 6 on Windows
either.

[...]

> Are there existing schemes that help in this?  If not, would it be
> worth putting one together?

Only for something very simple: put a text file up in a pager as we
do for info files.  That should be doable cross-platform easily.

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pgilbert@bank-banque-canada.ca  Wed Dec 11 16:19:06 2002
From: pgilbert@bank-banque-canada.ca (Paul Gilbert)
Date: Wed Dec 11 16:19:06 2002
Subject: [Rd] Flat documentation?
References: <b5vcvu0tp8ab3r1o9r9m9c1rqv4rke2llp@4ax.com>
Message-ID: <3DF7571E.20E2B822@bank-banque-canada.ca>

I am a bit concerned about the direction of some of this discussion. !!Please!!
do not consider gutting the R package Quality Assurance system and start a slide
back to the chaos of Statlib. There has to be a mechanism that weeds out code
that no longer works or is inadequately documented. Do you realize how much time
people have wasted trying to make poorly documented "casual" Statlib code work?
There is nothing that prevents non CRAN distribution of code and casual
documentation. Posting of an r-help message with a web site link does make this
fairly easily accessible to anyone who searches the help archives, and there is
no need for the code or documentation to be in any special format. CRAN also has
a devel area for packages that are not yet in good enough shape for the regular
area.

>In fact, one of my colleagues has chosen to use S-PLUS instead of R
>partly because it's easier to document the stuff he's written. 

I have mostly gone the other way, largely because of the QA tools (which in
large part are possible because of the Rd format). It is worth pointing out to
your colleagues that there is short term pain for long term gain. The fact that
code and documentation arguments are matched, and examples are checked, means
that documentation does not need to be manually checked all the time as your
code evolves. Changes that require changes in the documentation tend to be
pointed out automatically.

Paul Gilbert


From murdoch@stats.uwo.ca  Wed Dec 11 21:24:02 2002
From: murdoch@stats.uwo.ca (Duncan Murdoch)
Date: Wed Dec 11 21:24:02 2002
Subject: [Rd] Windows r-patched build uploaded
Message-ID: <7f7fvu4tof1ao819d94r260a6ha454pr75@4ax.com>

I've just uploaded today's build of R-patched for Windows (which is to
become 1.6.2).  As I'm going on vacation tomorrow, this will be the
last upload until Dec 23 or so.

You can download the installer from my web page,
<http://www.stats.uwo.ca/faculty/murdoch/software/r-devel>.  Please
let me know of any errors or omissions, but don't expect a reply
before the 23rd.

Duncan Murdoch


From jfox@mcmaster.ca  Wed Dec 11 21:25:03 2002
From: jfox@mcmaster.ca (John Fox)
Date: Wed Dec 11 21:25:03 2002
Subject: [Rd] Flat documentation?
In-Reply-To: <3DF7571E.20E2B822@bank-banque-canada.ca>
References: <b5vcvu0tp8ab3r1o9r9m9c1rqv4rke2llp@4ax.com>
Message-ID: <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca>

Dear Paul, Duncan, et al.,

I too like the package-construction tools in R, and find it easier to 
assemble R packages than S-PLUS libraries.

I wonder, however, whether the following simple suggestion might prove 
useful: Suppose that help(foo) and ?foo first look for standard 
documentation. If such documentation exists, it would be processed as at 
present. If there is no standard documentation on foo, then help and ? 
would look for a "doc" attribute of foo (or for initial comment lines in 
the function definition, if foo is a function), and, if this exists, 
display the contents in a pager.

John

At 10:17 AM 12/11/2002 -0500, Paul Gilbert wrote:
>I am a bit concerned about the direction of some of this discussion. 
>!!Please!!
>do not consider gutting the R package Quality Assurance system and start a 
>slide
>back to the chaos of Statlib. There has to be a mechanism that weeds out code
>that no longer works or is inadequately documented. Do you realize how 
>much time
>people have wasted trying to make poorly documented "casual" Statlib code 
>work?
>There is nothing that prevents non CRAN distribution of code and casual
>documentation. Posting of an r-help message with a web site link does make 
>this
>fairly easily accessible to anyone who searches the help archives, and 
>there is
>no need for the code or documentation to be in any special format. CRAN 
>also has
>a devel area for packages that are not yet in good enough shape for the 
>regular
>area.
>
> >In fact, one of my colleagues has chosen to use S-PLUS instead of R
> >partly because it's easier to document the stuff he's written.
>
>I have mostly gone the other way, largely because of the QA tools (which in
>large part are possible because of the Rd format). It is worth pointing out to
>your colleagues that there is short term pain for long term gain. The fact 
>that
>code and documentation arguments are matched, and examples are checked, means
>that documentation does not need to be manually checked all the time as your
>code evolves. Changes that require changes in the documentation tend to be
>pointed out automatically.

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox@mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox


From jerome@hivnet.ubc.ca  Wed Dec 11 22:30:03 2002
From: jerome@hivnet.ubc.ca (jerome@hivnet.ubc.ca)
Date: Wed Dec 11 22:30:03 2002
Subject: [Rd] nlme() and parameters "model", "fixed" and "random" (PR#2363)
Message-ID: <200212112129.WAA17784@pubhealth.ku.dk>

Full_Name: Jerome Asselin
Version: 1.6.1
OS: linux redhat 7.2
Submission from: (NULL) (142.103.173.179)



print.lme() fails when the parameters "model", "fixed" and "random"
are input as objects in nlme(). To show how this occurs, below is a
slightly modified example from the nlme help page.


     library(nlme)
     data(Loblolly)
     fm1 <- nlme(height ~ SSasymp(age, Asym, R0, lrc),
                 data = Loblolly,
                 fixed = Asym + R0 + lrc ~ 1,
                 random = Asym ~ 1,
                 start = c(Asym = 103, R0 = -8.5, lrc = -3.3))
     fm1 # THIS WORKS...

     model <- height ~ SSasymp(age, Asym, R0, lrc)
     fixed <- Asym + R0 + lrc ~ 1
     random <- Asym ~ 1
     start <- c(Asym = 103, R0 = -8.5, lrc = -3.3)
     fm2 <- nlme(model,
                 data = Loblolly,
                 fixed = fixed,
                 random = random,
                 start = start)
     fm2 # ERROR
     #Nonlinear mixed-effects model fit by maximum likelihood
     #Error in as.vector(x, mode) : cannot coerce to vector

     all(unlist(fm1$coefficients)==unlist(fm2$coefficients)) # TRUE


From ldimitro@wfubmc.edu  Wed Dec 11 22:45:11 2002
From: ldimitro@wfubmc.edu (Latchezar Dimitrov)
Date: Wed Dec 11 22:45:11 2002
Subject: [Rd] nlme() and parameters "model", "fixed" and "random" (PR#2363)
Message-ID: <F160BE32A2E5E04497668BBDFE83FEDF0350F764@EXCHVS1.medctr.ad.wfubmc.edu>

The same in Windows XP Pro

Latchezar Dimitrov

> -----Original Message-----
> From: jerome@hivnet.ubc.ca [mailto:jerome@hivnet.ubc.ca] 
> Sent: Wednesday, December 11, 2002 4:30 PM
> To: r-devel@stat.math.ethz.ch
> Cc: R-bugs@biostat.ku.dk
> Subject: [Rd] nlme() and parameters "model", "fixed" and 
> "random" (PR#2363)
> 
> 
> Full_Name: Jerome Asselin
> Version: 1.6.1
> OS: linux redhat 7.2
> Submission from: (NULL) (142.103.173.179)
> 
> 
> 
> print.lme() fails when the parameters "model", "fixed" and 
> "random" are input as objects in nlme(). To show how this 
> occurs, below is a slightly modified example from the nlme help page.
> 
> 
>      library(nlme)
>      data(Loblolly)
>      fm1 <- nlme(height ~ SSasymp(age, Asym, R0, lrc),
>                  data = Loblolly,
>                  fixed = Asym + R0 + lrc ~ 1,
>                  random = Asym ~ 1,
>                  start = c(Asym = 103, R0 = -8.5, lrc = -3.3))
>      fm1 # THIS WORKS...
> 
>      model <- height ~ SSasymp(age, Asym, R0, lrc)
>      fixed <- Asym + R0 + lrc ~ 1
>      random <- Asym ~ 1
>      start <- c(Asym = 103, R0 = -8.5, lrc = -3.3)
>      fm2 <- nlme(model,
>                  data = Loblolly,
>                  fixed = fixed,
>                  random = random,
>                  start = start)
>      fm2 # ERROR
>      #Nonlinear mixed-effects model fit by maximum likelihood
>      #Error in as.vector(x, mode) : cannot coerce to vector
> 
>      all(unlist(fm1$coefficients)==unlist(fm2$coefficients)) # TRUE
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listin> fo/r-devel
>


From bates@stat.wisc.edu  Wed Dec 11 22:54:03 2002
From: bates@stat.wisc.edu (Douglas Bates)
Date: Wed Dec 11 22:54:03 2002
Subject: [Rd] nlme() and parameters "model", "fixed" and "random" (PR#2363)
In-Reply-To: <200212112129.WAA17784@pubhealth.ku.dk>
References: <200212112129.WAA17784@pubhealth.ku.dk>
Message-ID: <6rbs3skysa.fsf@bates5.stat.wisc.edu>

jerome@hivnet.ubc.ca writes:

> Full_Name: Jerome Asselin
> Version: 1.6.1
> OS: linux redhat 7.2
> Submission from: (NULL) (142.103.173.179)
> 
> 
> 
> print.lme() fails when the parameters "model", "fixed" and "random"
> are input as objects in nlme(). To show how this occurs, below is a
> slightly modified example from the nlme help page.
> 
> 
>      library(nlme)
>      data(Loblolly)
>      fm1 <- nlme(height ~ SSasymp(age, Asym, R0, lrc),
>                  data = Loblolly,
>                  fixed = Asym + R0 + lrc ~ 1,
>                  random = Asym ~ 1,
>                  start = c(Asym = 103, R0 = -8.5, lrc = -3.3))
>      fm1 # THIS WORKS...
> 
>      model <- height ~ SSasymp(age, Asym, R0, lrc)
>      fixed <- Asym + R0 + lrc ~ 1
>      random <- Asym ~ 1
>      start <- c(Asym = 103, R0 = -8.5, lrc = -3.3)
>      fm2 <- nlme(model,
>                  data = Loblolly,
>                  fixed = fixed,
>                  random = random,
>                  start = start)
>      fm2 # ERROR
>      #Nonlinear mixed-effects model fit by maximum likelihood
>      #Error in as.vector(x, mode) : cannot coerce to vector
> 
>      all(unlist(fm1$coefficients)==unlist(fm2$coefficients)) # TRUE

Thanks for the report.  The construction deparse(as.vector(x)) where x
is a formula is needed in S-PLUS but can cause an error in R.  We
should, and will, revise the R package for nlme to replace any
instances of deparse(as.vector(x)) by deparse(x).


From nvj@fys.ku.dk  Thu Dec 12 00:17:02 2002
From: nvj@fys.ku.dk (nvj@fys.ku.dk)
Date: Thu Dec 12 00:17:02 2002
Subject: [Rd] R-intro: Simple manipulations/Vectors and assignment (PR#2365)
Message-ID: <200212112317.AAA18186@pubhealth.ku.dk>

Full_Name: Niels Vestergaard Jensen
Version: 1.6.1
OS: Linux (Mandrake 9.0)
Submission from: (NULL) (62.79.36.179)


The R-intro (1.6.1 (2002-11-01)) says in Simple manipulations/Vectors and
assignment:

"So with the above assignments the command 

> v <- 2*x + y + 1

generates a new vector v of length 11 constructed by adding together, element by
element, 2*x repeated 2.2 times, y repeated just once, and 1 repeated 11
times."

That's apparently not true:

> x <- c(10.4, 5.6, 3.1, 6.4, 21.7)
> y <- c(x, 0, x)
> x
[1] 10.4  5.6  3.1  6.4 21.7
> y
 [1] 10.4  5.6  3.1  6.4 21.7  0.0 10.4  5.6  3.1  6.4 21.7
> v <- 2*x + y + 1
Warning message:
longer object length
        is not a multiple of shorter object length in: 2 * x + y

Which was run first thing after starting R in a dir without .Rdata. I suspect R
has been updated, but the R-intro has not kept up.

See also: http://www.zoo.ufl.edu/bolker/emd/R/R-traps.html


From Bill.Venables@CMIS.CSIRO.AU  Thu Dec 12 01:03:05 2002
From: Bill.Venables@CMIS.CSIRO.AU (Bill.Venables@CMIS.CSIRO.AU)
Date: Thu Dec 12 01:03:05 2002
Subject: [Rd] R-intro: Simple manipulations/Vectors and assignment (PR
 #2365)
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A916571B@roper-cv.qld.cmis.CSIRO.AU>

The message is a warning message, (which is new), but it still works.

I guess the notes could warn you a warning was coming!  We might re-think
this, I suggest.  It began as an example that forced you to come to grips
with the recycling rule, but it is a bit obsolete now.  In S-PLUS 6.x it
actually fails.  Perhaps we don't need to be quite so thorough about this
after all and use a more normal example - for example just skip the 0 in the
y assignment and change the text accordingly.  

Bill Venables.

-----Original Message-----
From: nvj@fys.ku.dk [mailto:nvj@fys.ku.dk]
Sent: Thursday, December 12, 2002 9:17 AM
To: r-devel@stat.math.ethz.ch
Cc: R-bugs@biostat.ku.dk
Subject: [Rd] R-intro: Simple manipulations/Vectors and assignment
(PR#2365)


Full_Name: Niels Vestergaard Jensen
Version: 1.6.1
OS: Linux (Mandrake 9.0)
Submission from: (NULL) (62.79.36.179)


The R-intro (1.6.1 (2002-11-01)) says in Simple manipulations/Vectors and
assignment:

"So with the above assignments the command 

> v <- 2*x + y + 1

generates a new vector v of length 11 constructed by adding together,
element by
element, 2*x repeated 2.2 times, y repeated just once, and 1 repeated 11
times."

That's apparently not true:

> x <- c(10.4, 5.6, 3.1, 6.4, 21.7)
> y <- c(x, 0, x)
> x
[1] 10.4  5.6  3.1  6.4 21.7
> y
 [1] 10.4  5.6  3.1  6.4 21.7  0.0 10.4  5.6  3.1  6.4 21.7
> v <- 2*x + y + 1
Warning message:
longer object length
        is not a multiple of shorter object length in: 2 * x + y

Which was run first thing after starting R in a dir without .Rdata. I
suspect R
has been updated, but the R-intro has not kept up.

See also: http://www.zoo.ufl.edu/bolker/emd/R/R-traps.html

______________________________________________
R-devel@stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-devel


From hennig@stat.math.ethz.ch  Thu Dec 12 10:28:10 2002
From: hennig@stat.math.ethz.ch (Christian Hennig)
Date: Thu Dec 12 10:28:10 2002
Subject: [Rd] Kendall's tau
Message-ID: <Pine.LNX.4.44.0212121026001.27592-100000@florence>

Hi,

MM recommended to send this to R-devel:

As far as I know, the only method to compute Kendall's tau is to perform 
cor.test with method="kendall". I suggest that
1) this should be easier to find, namely with help.search("kendall")     
and/or link from cor,
2) cor should be given a method parameter like cor.test so that 
Kendall and Spearman correlations can be computed without doing the test.

Best,
Christian

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig@stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig@math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


From chris-public@math.uu.se  Thu Dec 12 14:20:03 2002
From: chris-public@math.uu.se (chris-public@math.uu.se)
Date: Thu Dec 12 14:20:03 2002
Subject: [Rd] R -g gnome has graphics bugs (PR#2366)
Message-ID: <200212121319.OAA24193@pubhealth.ku.dk>

Full_Name: Christian Nygaard
Version: 1.6.1
OS: Red Hat 7.3
Submission from: (NULL) (130.238.149.29)


R 1.6.1 run with argument -g gnome has bugs when plotting certain graphics. The
right and bottom plot borders are not shown sometimes.

$ R -g gnome
> demo ("graphics")
> Hit enter 5 times

The same works fine with R -g X11


From dmurdoch@pair.com  Thu Dec 12 15:19:03 2002
From: dmurdoch@pair.com (dmurdoch@pair.com)
Date: Thu Dec 12 15:19:03 2002
Subject: [Rd] Comments not documented in language reference (PR#2367)
Message-ID: <200212121419.PAA25199@pubhealth.ku.dk>

The R Language Definition manual should document comments.  I think
this should go after section 10.1 "The Parsing Process" and before
10.2 "Tokens".  Here's some draft text.

@node Comments, Tokens, The parsing process, Parser
@comment  node-name,  next,  previous,  up
@section Comments

Comments in R are ignored by the parser.  Any text from a \# character
to the end of the line is taken to be a comment.  For example, 

@smallexample
> x <- 1  # This is a comment
@smallexample


From dmurdoch@pair.com  Thu Dec 12 15:19:56 2002
From: dmurdoch@pair.com (Duncan Murdoch)
Date: Thu Dec 12 15:19:56 2002
Subject: [Rd] Flat documentation?
In-Reply-To: <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca>
References: <b5vcvu0tp8ab3r1o9r9m9c1rqv4rke2llp@4ax.com> <3DF7571E.20E2B822@bank-banque-canada.ca> <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca>
Message-ID: <8e3hvu4rvnimgh0bu798itlcbhhdeuv1c2@4ax.com>

On Wed, 11 Dec 2002 14:42:41 -0500, you wrote:

>I wonder, however, whether the following simple suggestion might prove 
>useful: Suppose that help(foo) and ?foo first look for standard 
>documentation. If such documentation exists, it would be processed as at 
>present. If there is no standard documentation on foo, then help and ? 
>would look for a "doc" attribute of foo (or for initial comment lines in 
>the function definition, if foo is a function), and, if this exists, 
>display the contents in a pager.

I think that would be an ideal solution, as long as there was a
relatively easy way to import text.  For example, if it's done with
comments (which would be my preference), there should be a way to
enter multi-line comments (like /* ...  */ in C).  If it's done with
attributes there needs to be an easy way to put free-form text into
the attribute.

As an aside, I wasn't certain that multi-line comments didn't exist,
so I checked the language reference.  Comments aren't documented at
all! (At least in the r-devel version...) This should probably be
fixed. I've submitted draft text as a bug report. 



Duncan Murdoch


From jfox@mcmaster.ca  Thu Dec 12 15:36:05 2002
From: jfox@mcmaster.ca (John Fox)
Date: Thu Dec 12 15:36:05 2002
Subject: [Rd] Flat documentation?
In-Reply-To: <8e3hvu4rvnimgh0bu798itlcbhhdeuv1c2@4ax.com>
References: <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca>
 <b5vcvu0tp8ab3r1o9r9m9c1rqv4rke2llp@4ax.com>
 <3DF7571E.20E2B822@bank-banque-canada.ca>
 <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca>
Message-ID: <5.1.0.14.2.20021212092533.01ddb880@mcmail.cis.mcmaster.ca>

Dear Duncan,

At 09:18 AM 12/12/2002 -0500, Duncan Murdoch wrote:
>On Wed, 11 Dec 2002 14:42:41 -0500, you wrote:
>
> >I wonder, however, whether the following simple suggestion might prove
> >useful: Suppose that help(foo) and ?foo first look for standard
> >documentation. If such documentation exists, it would be processed as at
> >present. If there is no standard documentation on foo, then help and ?
> >would look for a "doc" attribute of foo (or for initial comment lines in
> >the function definition, if foo is a function), and, if this exists,
> >display the contents in a pager.
>
>I think that would be an ideal solution, as long as there was a
>relatively easy way to import text.

One could simply supply a function to perform this task -- e.g., doc(foo, 
'file'), which returns the function or data frame foo with the contents of 
file in the doc attribute (or as initial comment lines).

>For example, if it's done with
>comments (which would be my preference), there should be a way to
>enter multi-line comments (like /* ...  */ in C).  If it's done with
>attributes there needs to be an easy way to put free-form text into
>the attribute.

I can think of several ways to store a multi-line text attribute: a vector 
of strings, a string with new-line characters, etc. It would be easiest to 
import the text from a file, and it would be up to help() to display the 
information correctly.

>As an aside, I wasn't certain that multi-line comments didn't exist,
>so I checked the language reference.  Comments aren't documented at
>all! (At least in the r-devel version...) This should probably be
>fixed. I've submitted draft text as a bug report.


Regards,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox@mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From dj@research.bell-labs.com  Thu Dec 12 16:49:06 2002
From: dj@research.bell-labs.com (David James)
Date: Thu Dec 12 16:49:06 2002
Subject: [Rd] lattice/points and pch="c" inconsistencies
Message-ID: <20021212104806.A16745@jessie.research.bell-labs.com>

Hi,

The current lattice/grid packages seem to position character 
plotting symbols (e.g., ".") differently than the base function 
points.  The following shows what I mean:

## plain old points() positions the pch="." right at y = c(0,1),
## and thus abline(h = c(0,1)) completely hides the points "."
## (provided the output device has enough resolution, like postscript)

y <- rep(0:1, 50)
x <- 1:100

plot(x, y, pch = ".", cex = 2)
abline(h = c(0, 1))

## on the other hand, lattice/grid position the "." off the
## the y=0,1 lines, apparently centering the character's bounding box
## rather than the actual glyph;

xyplot(y~x, 
   panel = function(x, y, ...){
      panel.xyplot(x, y, ...)
      panel.abline(h = c(0, 1))
   },
   pch = ".", cex = 2
   )


I've noticed the argument "just=" in grid.text(), but its default
value of "centre" would seem to be what's needed in this example(?)

This behavior is consistent on Linux and Windows versions of R 1.6.1,
lattice 0.6-6, and grid 0.7-2.

Is this a lattice/grid feature or a bug?

-- 
David A. James
Statistics Research, Room 2C-253            Phone:  (908) 582-3082       
Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
Murray Hill, NJ 09794-0636


From murdoch@stats.uwo.ca  Thu Dec 12 16:53:02 2002
From: murdoch@stats.uwo.ca (Duncan Murdoch)
Date: Thu Dec 12 16:53:02 2002
Subject: [Rd] Flat documentation?
In-Reply-To: <5.1.0.14.2.20021212092533.01ddb880@mcmail.cis.mcmaster.ca>
References: <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca> <b5vcvu0tp8ab3r1o9r9m9c1rqv4rke2llp@4ax.com> <3DF7571E.20E2B822@bank-banque-canada.ca> <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca> <8e3hvu4rvnimgh0bu798itlcbhhdeuv1c2@4ax.com> <5.1.0.14.2.20021212092533.01ddb880@mcmail.cis.mcmaster.ca>
Message-ID: <qbbhvu825pgqghjjn76cj8q8kckknda02l@4ax.com>

On Thu, 12 Dec 2002 09:35:40 -0500, you wrote in message
<5.1.0.14.2.20021212092533.01ddb880@mcmail.cis.mcmaster.ca>:

>Dear Duncan,
>
>At 09:18 AM 12/12/2002 -0500, Duncan Murdoch wrote:

>>For example, if it's done with
>>comments (which would be my preference), there should be a way to
>>enter multi-line comments (like /* ...  */ in C).  If it's done with
>>attributes there needs to be an easy way to put free-form text into
>>the attribute.
>
>I can think of several ways to store a multi-line text attribute: a vector 
>of strings, a string with new-line characters, etc. It would be easiest to 
>import the text from a file, and it would be up to help() to display the 
>information correctly.

Storage isn't a problem, I'm thinking of the user interface.  I
normally write my functions in a text editor, then source them into R.
Other people use a workspace as the primary place to store functions.
Both methods should allow for easy addition of lightweight
documentation.

One problem with using embedded comments is that people don't agree on
the One True Comment Style.  For example, I wrote a Turbo Pascal
language parser once that built help files from comments in Pascal
source, and I found it very useful.  However, when I gave it away to
other people, I found that everyone has their own comment style, and
they didn't like the assumptions my parser was making about how to put
the comments into the help file.  For example this sort of problem
(translated into R) came up.  Which style of source should I assume?

Version 1:

 # Add two vectors
 sum <- function(x, y) x+y

 # Subtract two vectors
 diff <- function(x, y) x-y

Version 2:  (This one makes more sense in TP, where you give the
function header in one section, and the implementation in another)

 sum <- function(x, y) x+y
 # Add two vectors
  
 diff <- function(x, y) x-y
 # Subtract two vectors

Version 3:

 sum <- function(x, y) {
	 # Add two vectors
	x+y
  }
  
 diff <- function(x, y) {
	 # Subtract two vectors
	 x-y
  }

Duncan Murdoch


From jfox@mcmaster.ca  Thu Dec 12 17:51:03 2002
From: jfox@mcmaster.ca (John Fox)
Date: Thu Dec 12 17:51:03 2002
Subject: [Rd] Flat documentation?
In-Reply-To: <qbbhvu825pgqghjjn76cj8q8kckknda02l@4ax.com>
References: <5.1.0.14.2.20021212092533.01ddb880@mcmail.cis.mcmaster.ca>
 <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca>
 <b5vcvu0tp8ab3r1o9r9m9c1rqv4rke2llp@4ax.com>
 <3DF7571E.20E2B822@bank-banque-canada.ca>
 <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca>
 <8e3hvu4rvnimgh0bu798itlcbhhdeuv1c2@4ax.com>
 <5.1.0.14.2.20021212092533.01ddb880@mcmail.cis.mcmaster.ca>
Message-ID: <5.1.0.14.2.20021212114114.01e2d398@mcmail.cis.mcmaster.ca>

Dear Duncan,

At 10:51 AM 12/12/2002 -0500, Duncan Murdoch wrote:
>On Thu, 12 Dec 2002 09:35:40 -0500, you wrote in message
><5.1.0.14.2.20021212092533.01ddb880@mcmail.cis.mcmaster.ca>:
>
> >Dear Duncan,
> >
> >At 09:18 AM 12/12/2002 -0500, Duncan Murdoch wrote:
>
> >>For example, if it's done with
> >>comments (which would be my preference), there should be a way to
> >>enter multi-line comments (like /* ...  */ in C).  If it's done with
> >>attributes there needs to be an easy way to put free-form text into
> >>the attribute.
> >
> >I can think of several ways to store a multi-line text attribute: a vector
> >of strings, a string with new-line characters, etc. It would be easiest to
> >import the text from a file, and it would be up to help() to display the
> >information correctly.
>
>Storage isn't a problem, I'm thinking of the user interface.  I
>normally write my functions in a text editor, then source them into R.
>Other people use a workspace as the primary place to store functions.
>Both methods should allow for easy addition of lightweight
>documentation.

I was assuming the use of your third style. At present -- in the absence of 
multiline comments -- that would require #ing each comment line at the 
start of the function.

Alternatively, you could create a separate text file, say sum.txt, and 
define the function as:

         sum <- function(x, y) x + y
         doc(sum, "sum.txt")

[or sum <- doc(sum, "sum.txt") for an implementation of doc() without side 
effects.]

Either method should work whether functions are kept in text files or in 
saved workspaces.

>One problem with using embedded comments is that people don't agree on
>the One True Comment Style.  For example, I wrote a Turbo Pascal
>language parser once that built help files from comments in Pascal
>source, and I found it very useful.  However, when I gave it away to
>other people, I found that everyone has their own comment style, and
>they didn't like the assumptions my parser was making about how to put
>the comments into the help file.  For example this sort of problem
>(translated into R) came up.  Which style of source should I assume?
>
>Version 1:
>
>  # Add two vectors
>  sum <- function(x, y) x+y
>
>  # Subtract two vectors
>  diff <- function(x, y) x-y
>
>Version 2:  (This one makes more sense in TP, where you give the
>function header in one section, and the implementation in another)
>
>  sum <- function(x, y) x+y
>  # Add two vectors
>
>  diff <- function(x, y) x-y
>  # Subtract two vectors
>
>Version 3:
>
>  sum <- function(x, y) {
>         # Add two vectors
>         x+y
>   }
>
>  diff <- function(x, y) {
>         # Subtract two vectors
>         x-y
>   }

Regards,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox@mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From edd@debian.org  Thu Dec 12 18:07:06 2002
From: edd@debian.org (Dirk Eddelbuettel)
Date: Thu Dec 12 18:07:06 2002
Subject: [Rd] Flat documentation?
Message-ID: <E18MWmA-0008TC-00@sonny.eddelbuettel.com>

This requirement of a particular comment strikes me as more 
restrictive than the requirement of having to learn the .Rd format. 

My preferred "dumb" format is Perl's POD.  It has a very simple 
markup structures, paragraphs come trough as is (in an ascii sense
of WYSIWYG) and it does require the user to comment code in any
particular way.  Would that (or something like it) be an alternative?

Dirk

> Dear Duncan,
> 
> At 10:51 AM 12/12/2002 -0500, Duncan Murdoch wrote:
> >On Thu, 12 Dec 2002 09:35:40 -0500, you wrote in message
> ><5.1.0.14.2.20021212092533.01ddb880@mcmail.cis.mcmaster.ca>:
> >
> > >Dear Duncan,
> > >
> > >At 09:18 AM 12/12/2002 -0500, Duncan Murdoch wrote:
> >
> > >>For example, if it's done with
> > >>comments (which would be my preference), there should be a way to
> > >>enter multi-line comments (like /* ...  */ in C).  If it's done with
> > >>attributes there needs to be an easy way to put free-form text into
> > >>the attribute.
> > >
> > >I can think of several ways to store a multi-line text attribute: a vector
> > >of strings, a string with new-line characters, etc. It would be easiest to
> > >import the text from a file, and it would be up to help() to display the
> > >information correctly.
> >
> >Storage isn't a problem, I'm thinking of the user interface.  I
> >normally write my functions in a text editor, then source them into R.
> >Other people use a workspace as the primary place to store functions.
> >Both methods should allow for easy addition of lightweight
> >documentation.
> 
> I was assuming the use of your third style. At present -- in the absence of 
> multiline comments -- that would require #ing each comment line at the 
> start of the function.
> 
> Alternatively, you could create a separate text file, say sum.txt, and 
> define the function as:
> 
>          sum <- function(x, y) x + y
>          doc(sum, "sum.txt")
> 
> [or sum <- doc(sum, "sum.txt") for an implementation of doc() without side 
> effects.]
> 
> Either method should work whether functions are kept in text files or in 
> saved workspaces.
> 
> >One problem with using embedded comments is that people don't agree on
> >the One True Comment Style.  For example, I wrote a Turbo Pascal
> >language parser once that built help files from comments in Pascal
> >source, and I found it very useful.  However, when I gave it away to
> >other people, I found that everyone has their own comment style, and
> >they didn't like the assumptions my parser was making about how to put
> >the comments into the help file.  For example this sort of problem
> >(translated into R) came up.  Which style of source should I assume?
> >
> >Version 1:
> >
> >  # Add two vectors
> >  sum <- function(x, y) x+y
> >
> >  # Subtract two vectors
> >  diff <- function(x, y) x-y
> >
> >Version 2:  (This one makes more sense in TP, where you give the
> >function header in one section, and the implementation in another)
> >
> >  sum <- function(x, y) x+y
> >  # Add two vectors
> >
> >  diff <- function(x, y) x-y
> >  # Subtract two vectors
> >
> >Version 3:
> >
> >  sum <- function(x, y) {
> >         # Add two vectors
> >         x+y
> >   }
> >
> >  diff <- function(x, y) {
> >         # Subtract two vectors
> >         x-y
> >   }
> 
> Regards,
>   John
> 
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox@mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 

-- 
According to the latest figures, 43% of all signatures are totally worthless.


From deepayan@stat.wisc.edu  Thu Dec 12 18:16:03 2002
From: deepayan@stat.wisc.edu (Deepayan Sarkar)
Date: Thu Dec 12 18:16:03 2002
Subject: [Rd] lattice/points and pch="c" inconsistencies
In-Reply-To: <20021212104806.A16745@jessie.research.bell-labs.com>
References: <20021212104806.A16745@jessie.research.bell-labs.com>
Message-ID: <200212121117.06069.deepayan@stat.wisc.edu>

This is not due to grid, it's caused by code in lattice (in lplot.xy) that was 
a workaround for an old bug in grid. That bug has been fixed, but I forgot to 
change the lattice code. I'll fix this by the next release (there should be a 
patch release next week).

The actual grid behaviour can be seen by 

xyplot(y~x, 
   panel = function(x, y, ...){
      grid.points(x, y, pch = '.', default.units = "native")
      panel.abline(h = c(0, 1))
   })

Deepayan

On Thursday 12 December 2002 09:48 am, David James wrote:
> Hi,
>
> The current lattice/grid packages seem to position character
> plotting symbols (e.g., ".") differently than the base function
> points.  The following shows what I mean:
>
> ## plain old points() positions the pch="." right at y = c(0,1),
> ## and thus abline(h = c(0,1)) completely hides the points "."
> ## (provided the output device has enough resolution, like postscript)
>
> y <- rep(0:1, 50)
> x <- 1:100
>
> plot(x, y, pch = ".", cex = 2)
> abline(h = c(0, 1))
>
> ## on the other hand, lattice/grid position the "." off the
> ## the y=0,1 lines, apparently centering the character's bounding box
> ## rather than the actual glyph;
>
> xyplot(y~x,
>    panel = function(x, y, ...){
>       panel.xyplot(x, y, ...)
>       panel.abline(h = c(0, 1))
>    },
>    pch = ".", cex = 2
>    )
>
>
> I've noticed the argument "just=" in grid.text(), but its default
> value of "centre" would seem to be what's needed in this example(?)
>
> This behavior is consistent on Linux and Windows versions of R 1.6.1,
> lattice 0.6-6, and grid 0.7-2.
>
> Is this a lattice/grid feature or a bug?


From maechler@stat.math.ethz.ch  Thu Dec 12 18:20:03 2002
From: maechler@stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Thu Dec 12 18:20:03 2002
Subject: [Rd] Comments not documented in language reference (PR#2367)
Message-ID: <200212121719.SAA26847@pubhealth.ku.dk>

>>>>> "Duncan" == Duncan Murdoch <dmurdoch@pair.com>
>>>>>     on Thu, 12 Dec 2002 15:19:07 +0100 (MET) writes:

    Duncan> The R Language Definition manual should document comments.  I think
    Duncan> this should go after section 10.1 "The Parsing Process" and before
    Duncan> 10.2 "Tokens".  

yes, very reasonable -- well spotted!

    Duncan> Here's some draft text.
    Duncan> @node Comments, Tokens, The parsing process, Parser
    Duncan> @comment  node-name,  next,  previous,  up
    Duncan> @section Comments


    Duncan> Comments in R are ignored by the parser.  Any text
    Duncan> from a \# character to the end of the line is taken
    Duncan> to be a comment.  For example,

    Duncan> @smallexample
    >> x <- 1  # This is a comment
    Duncan> @smallexample

this is not quite exact.  "#" only starts a comment when not
inside a string (or a comment already).

You can add it yourself to doc/manual/R-lang.texi, right?
Martin


From kjetilh@umsanet.edu.bo  Thu Dec 12 18:45:07 2002
From: kjetilh@umsanet.edu.bo (kjetil halvorsen)
Date: Thu Dec 12 18:45:07 2002
Subject: [Rd] Flat documentation?
References: <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca> <b5vcvu0tp8ab3r1o9r9m9c1rqv4rke2llp@4ax.com> <3DF7571E.20E2B822@bank-banque-canada.ca> <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca> <8e3hvu4rvnimgh0bu798itlcbhhdeuv1c2@4ax.com> <5.1.0.14.2.20021212092533.01ddb880@mcmail.cis.mcmaster.ca> <qbbhvu825pgqghjjn76cj8q8kckknda02l@4ax.com>
Message-ID: <3DF8C951.FB17F34A@umsanet.edu.bo>

Hola!


Duncan Murdoch wrote:
.
.
.

> 
> Storage isn't a problem, I'm thinking of the user interface.  I
> normally write my functions in a text editor, then source them into R.
> Other people use a workspace as the primary place to store functions.
> Both methods should allow for easy addition of lightweight
> documentation. 

When functions are stored in workspaces, and options keep.source=FALSE
are used, it will not work to write the documentation as comments in the
function. So attributes seems preferable, if one goes for 
light-weight documentation.

Kjetil Halvorsen


> 
> One problem with using embedded comments is that people don't agree on
> the One True Comment Style.  For example, I wrote a Turbo Pascal
> language parser once that built help files from comments in Pascal
> source, and I found it very useful.  However, when I gave it away to
> other people, I found that everyone has their own comment style, and
> they didn't like the assumptions my parser was making about how to put
> the comments into the help file.  For example this sort of problem
> (translated into R) came up.  Which style of source should I assume?
> 
> Version 1:
> 
>  # Add two vectors
>  sum <- function(x, y) x+y
> 
>  # Subtract two vectors
>  diff <- function(x, y) x-y
> 
> Version 2:  (This one makes more sense in TP, where you give the
> function header in one section, and the implementation in another)
> 
>  sum <- function(x, y) x+y
>  # Add two vectors
> 
>  diff <- function(x, y) x-y
>  # Subtract two vectors
> 
> Version 3:
> 
>  sum <- function(x, y) {
>          # Add two vectors
>         x+y
>   }
> 
>  diff <- function(x, y) {
>          # Subtract two vectors
>          x-y
>   }
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-devel


From jerome@hivnet.ubc.ca  Thu Dec 12 23:43:02 2002
From: jerome@hivnet.ubc.ca (jerome@hivnet.ubc.ca)
Date: Thu Dec 12 23:43:02 2002
Subject: [Rd] convergence problem with nlme() (PR#2369)
Message-ID: <200212122243.XAA27894@pubhealth.ku.dk>

Full_Name: Jerome Asselin
Version: 1.6.1
OS: linux redhat 7.2
Submission from: (NULL) (142.103.173.179)



I am using the nlme package version 3.1-33.

I tried an example from the file "library/nlme/scripts/ch08.R" that comes
with the nlme package but I did not obtain convergence. I assume that
this example worked at some point in the past, but I cannot determine
why it is not working anymore. So I am unable to determine whether this
is a numerical bug or a documentation bug (in the file "ch08.R").

More specifically, I tried the example below (in which I added the
option msVerbose=T.)

library(nlme)
data(Quinidine)
control <- nlmeControl(msVerbose = T)
fm1Quin.nlme <-
  nlme(conc ~ quinModel(Subject, time, conc, dose, interval,
                        lV, lKa, lCl),
       data = Quinidine, fixed = lV + lKa + lCl ~ 1,
       random = pdDiag(lV + lCl ~ 1), groups =  ~ Subject,
       start = list(fixed = c(5, -0.3, 2)),
       na.action = NULL, naPattern =  ~ !is.na(conc), control = control)
#Error in nlme.formula(conc ~ quinModel(Subject, time, conc, dose, interval,  :
#        Maximum number of iterations reached without convergence

Below is the trace of the calculations by nlme().


iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.9645714 1.2393630
Function Value
[1] 1053.026
Gradient:
[1] -5.1732725 -0.3194242

iteration = 10
Parameter:
[1] 5.492493 1.275746
Function Value
[1] 1050.678
Gradient:
[1] -0.0004125939  0.0012034419

Iteration limit exceeded.  Algorithm failed.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 5.492303 0.860876
Function Value
[1] 1047.32
Gradient:
[1]  8.080429e-04 -8.308982e-06

iteration = 6
Parameter:
[1] -1772.4732661     0.3624312
Function Value
[1] 815.6329
Gradient:
[1]  9.726484e-25 -2.590048e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.7142093 0.8328863
Function Value
[1] 1045.966
Gradient:
[1] -2.701254  1.837528

iteration = 6
Parameter:
[1] 1.1387817 0.8237138
Function Value
[1] 1045.492
Gradient:
[1] -3.297258e-08  4.558449e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2190786 0.8233033
Function Value
[1] 1044.609
Gradient:
[1]  2.589381 -2.443006

iteration = 7
Parameter:
[1] 0.6880674 0.8342263
Function Value
[1] 1043.658
Gradient:
[1] -5.457107e-08 -1.710382e-06

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6867763 0.8348800
Function Value
[1] 1045.262
Gradient:
[1] -3.318076  2.320207

iteration = 7
Parameter:
[1] 1.2547275 0.8239144
Function Value
[1] 1044.541
Gradient:
[1]  1.496284e-08 -6.761539e-21

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2661227 0.8244986
Function Value
[1] 1044.441
Gradient:
[1]  2.642391 -2.502298

iteration = 1
Parameter:
[1] -1509.6490716     0.8231054
Function Value
[1] 826.5788
Gradient:
[1] 5.044484e-19 3.488575e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6851074 0.8350764
Function Value
[1] 1045.189
Gradient:
[1] -3.359032  2.357977

iteration = 7
Parameter:
[1] 1.2648770 0.8239819
Function Value
[1] 1044.448
Gradient:
[1] -1.484278e-08 -4.556966e-08

Last global step failed to locate a point lower than x.
Either x is an approximate local minimum of the function,
the function is too non-linear for this algorithm,
or steptol is too large.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2679928 0.8245302
Function Value
[1] 1044.427
Gradient:
[1]  2.646834 -2.508039

iteration = 1
Parameter:
[1] -1511.23183     0.82312
Function Value
[1] 826.1627
Gradient:
[1] 1.373859e-18 3.405617e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6849866 0.8350863
Function Value
[1] 1045.184
Gradient:
[1] -3.361700  2.360219

iteration = 7
Parameter:
[1] 1.2654792 0.8239847
Function Value
[1] 1044.442
Gradient:
[1] -1.483571e-08 -2.278475e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.268088 0.824533
Function Value
[1] 1044.426
Gradient:
[1]  2.647101 -2.508261

iteration = 1
Parameter:
[1] -1511.3133956     0.8231232
Function Value
[1] 827.7616
Gradient:
[1] 1.046018e-18 3.410108e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6850998 0.8350804
Function Value
[1] 1045.188
Gradient:
[1] -3.359382  2.358456

iteration = 7
Parameter:
[1] 1.2650078 0.8239839
Function Value
[1] 1044.447
Gradient:
[1] -1.484124e-08  2.278477e-08

Last global step failed to locate a point lower than x.
Either x is an approximate local minimum of the function,
the function is too non-linear for this algorithm,
or steptol is too large.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2680136 0.8245307
Function Value
[1] 1044.426
Gradient:
[1]  2.646877 -2.508084

iteration = 1
Parameter:
[1] -1511.2495885     0.8231376
Function Value
[1] 827.6179
Gradient:
[1] 1.473509e-19 3.477226e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6851144 0.8350799
Function Value
[1] 1045.188
Gradient:
[1] -3.359088  2.358286

iteration = 6
Parameter:
[1] 1.2649473 0.8239835
Function Value
[1] 1044.448
Gradient:
[1]  2.968390e-08 -6.835435e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.267994 0.824532
Function Value
[1] 1044.427
Gradient:
[1]  2.646853 -2.507863

iteration = 1
Parameter:
[1] -1511.2336349     0.8231352
Function Value
[1] 828.0258
Gradient:
[1] -6.701743e-20  3.365341e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6851079 0.8350803
Function Value
[1] 1045.188
Gradient:
[1] -3.359215  2.358392

iteration = 7
Parameter:
[1] 1.2649721 0.8239836
Function Value
[1] 1044.447
Gradient:
[1] 1.484166e-08 4.556957e-08

Last global step failed to locate a point lower than x.
Either x is an approximate local minimum of the function,
the function is too non-linear for this algorithm,
or steptol is too large.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.268001 0.824530
Function Value
[1] 1044.427
Gradient:
[1]  2.646867 -2.508106

iteration = 1
Parameter:
[1] -1511.2385145     0.8231441
Function Value
[1] 825.0983
Gradient:
[1] -9.146131e-19  3.823514e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6849865 0.8350865
Function Value
[1] 1045.184
Gradient:
[1] -3.361722  2.360234

iteration = 6
Parameter:
[1] 1.265490 0.823985
Function Value
[1] 1044.442
Gradient:
[1] -1.254955e-20 -6.835423e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2681041 0.8245325
Function Value
[1] 1044.426
Gradient:
[1]  2.647101 -2.508336

iteration = 1
Parameter:
[1] -1511.3262872     0.8231335
Function Value
[1] 828.0964
Gradient:
[1] 2.680533e-19 3.401084e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6850990 0.8350805
Function Value
[1] 1045.188
Gradient:
[1] -3.359395  2.358484

iteration = 7
Parameter:
[1] 1.2650090 0.8239838
Function Value
[1] 1044.447
Gradient:
[1] -4.452368e-08 -2.278478e-08

Last global step failed to locate a point lower than x.
Either x is an approximate local minimum of the function,
the function is too non-linear for this algorithm,
or steptol is too large.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2680059 0.8245313
Function Value
[1] 1044.426
Gradient:
[1]  2.646886 -2.508011

iteration = 1
Parameter:
[1] -1511.24342     0.82312
Function Value
[1] 827.5457
Gradient:
[1] -1.234659e-18  3.430500e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6851253 0.8350791
Function Value
[1] 1045.189
Gradient:
[1] -3.358850  2.358082

iteration = 7
Parameter:
[1] 1.2648953 0.8239834
Function Value
[1] 1044.448
Gradient:
[1] -1.800871e-20 -4.556957e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2679782 0.8245315
Function Value
[1] 1044.427
Gradient:
[1]  2.646833 -2.507868

iteration = 1
Parameter:
[1] -1511.2203466     0.8231246
Function Value
[1] 827.655
Gradient:
[1] -6.572921e-20  3.458212e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6851108 0.8350802
Function Value
[1] 1045.188
Gradient:
[1] -3.359155  2.358352

iteration = 6
Parameter:
[1] 1.2649595 0.8239835
Function Value
[1] 1044.448
Gradient:
[1] 3.562034e-07 3.850629e-06

Last global step failed to locate a point lower than x.
Either x is an approximate local minimum of the function,
the function is too non-linear for this algorithm,
or steptol is too large.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2679959 0.8245315
Function Value
[1] 1044.427
Gradient:
[1]  2.646857 -2.507940

iteration = 1
Parameter:
[1] -1511.2351449     0.8231327
Function Value
[1] 826.1662
Gradient:
[1] -1.488559e-18  3.469375e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6849859 0.8350863
Function Value
[1] 1045.184
Gradient:
[1] -3.361721  2.360224

iteration = 7
Parameter:
[1] 1.2654851 0.8239848
Function Value
[1] 1044.442
Gradient:
[1] 1.483564e-08 2.278475e-08

Last global step failed to locate a point lower than x.
Either x is an approximate local minimum of the function,
the function is too non-linear for this algorithm,
or steptol is too large.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2680893 0.8245333
Function Value
[1] 1044.426
Gradient:
[1]  2.647108 -2.508211

iteration = 1
Parameter:
[1] -1511.3143179     0.8231573
Function Value
[1] 826.9291
Gradient:
[1] 2.104922e-20 3.529035e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6849815 0.8350874
Function Value
[1] 1045.184
Gradient:
[1] -3.361846  2.360388

iteration = 6
Parameter:
[1] 1.265520 0.823985
Function Value
[1] 1044.442
Gradient:
[1] -2.967047e-08 -2.278474e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.268114 0.824533
Function Value
[1] 1044.426
Gradient:
[1]  2.647111 -2.508323

iteration = 1
Parameter:
[1] -1511.3346598     0.8231364
Function Value
[1] 827.9441
Gradient:
[1] 5.172025e-19 3.451115e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6851007 0.8350806
Function Value
[1] 1045.188
Gradient:
[1] -3.359375  2.358493

iteration = 7
Parameter:
[1] 1.2650083 0.8239838
Function Value
[1] 1044.447
Gradient:
[1] -1.484124e-08 -2.278478e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2680159 0.8245307
Function Value
[1] 1044.426
Gradient:
[1]  2.646879 -2.508084

iteration = 1
Parameter:
[1] -1511.2514358     0.8231329
Function Value
[1] 827.6347
Gradient:
[1] 1.392743e-18 3.408522e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6851072 0.8350800
Function Value
[1] 1045.188
Gradient:
[1] -3.359213  2.358363

iteration = 6
Parameter:
[1] 1.2649669 0.8239834
Function Value
[1] 1044.447
Gradient:
[1] -1.484172e-08 -6.835436e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2679877 0.8245304
Function Value
[1] 1044.427
Gradient:
[1]  2.646868 -2.508028

iteration = 1
Parameter:
[1] -1511.2276862     0.8231314
Function Value
[1] 827.9284
Gradient:
[1] -8.458835e-19  3.418282e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6851074 0.8350800
Function Value
[1] 1045.188
Gradient:
[1] -3.359220  2.358355

iteration = 7
Parameter:
[1] 1.2649721 0.8239837
Function Value
[1] 1044.447
Gradient:
[1]  2.968332e-08 -2.162905e-20

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2680039 0.8245315
Function Value
[1] 1044.427
Gradient:
[1]  2.646863 -2.507970

iteration = 1
Parameter:
[1] -1511.2418099     0.8231307
Function Value
[1] 821.013
Gradient:
[1] -1.151748e-18  3.745284e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6849946 0.8350861
Function Value
[1] 1045.184
Gradient:
[1] -3.361550  2.360118

iteration = 7
Parameter:
[1] 1.2654518 0.8239848
Function Value
[1] 1044.443
Gradient:
[1] -1.483603e-08  2.278475e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2680745 0.8245337
Function Value
[1] 1044.426
Gradient:
[1]  2.647091 -2.508132

iteration = 1
Parameter:
[1] -1511.3021850     0.8231395
Function Value
[1] 826.9798
Gradient:
[1] -6.873270e-21  3.541503e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6849805 0.8350871
Function Value
[1] 1045.184
Gradient:
[1] -3.361853  2.360357

iteration = 6
Parameter:
[1] 1.265518 0.823985
Function Value
[1] 1044.442
Gradient:
[1] -6.414965e-21 -2.748390e-21

Relative gradient close to zero.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2680999 0.8245325
Function Value
[1] 1044.426
Gradient:
[1]  2.647123 -2.508339

iteration = 1
Parameter:
[1] -1511.3228120     0.8231412
Function Value
[1] 827.4251
Gradient:
[1] 2.387140e-18 3.362223e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6850398 0.8350784
Function Value
[1] 1045.187
Gradient:
[1] -3.360343  2.358820

iteration = 6
Parameter:
[1] 1.2651213 0.8239824
Function Value
[1] 1044.446
Gradient:
[1] -1.094700e-20  4.556963e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2680295 0.8245309
Function Value
[1] 1044.426
Gradient:
[1]  2.646955 -2.508173

iteration = 1
Parameter:
[1] -1511.262920     0.823141
Function Value
[1] 825.304
Gradient:
[1] 1.503567e-20 3.453135e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6849834 0.8350867
Function Value
[1] 1045.184
Gradient:
[1] -3.361774  2.360293

iteration = 6
Parameter:
[1] 1.2654961 0.8239848
Function Value
[1] 1044.442
Gradient:
[1]  1.483552e-08 -2.278475e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2680917 0.8245322
Function Value
[1] 1044.426
Gradient:
[1]  2.647117 -2.508340

iteration = 1
Parameter:
[1] -1511.3158054     0.8231388
Function Value
[1] 824.6348
Gradient:
[1] 5.051808e-19 3.498065e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6849795 0.8350869
Function Value
[1] 1045.184
Gradient:
[1] -3.361863  2.360350

iteration = 6
Parameter:
[1] 1.265517 0.823985
Function Value
[1] 1044.442
Gradient:
[1]  1.483527e-08 -2.819618e-20

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2680970 0.8245325
Function Value
[1] 1044.426
Gradient:
[1]  2.647123 -2.508321

iteration = 1
Parameter:
[1] -1511.3203920     0.8231351
Function Value
[1] 827.997
Gradient:
[1] 2.985541e-19 3.389715e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6850997 0.8350809
Function Value
[1] 1045.188
Gradient:
[1] -3.359386  2.358541

iteration = 7
Parameter:
[1] 1.2650077 0.8239836
Function Value
[1] 1044.447
Gradient:
[1] -1.724167e-20 -4.556957e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2679931 0.8245322
Function Value
[1] 1044.426
Gradient:
[1]  2.646886 -2.507881

iteration = 1
Parameter:
[1] -1511.2332090     0.8231399
Function Value
[1] 827.8576
Gradient:
[1] -4.046823e-19  3.374292e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6851068 0.8350803
Function Value
[1] 1045.188
Gradient:
[1] -3.359240  2.358399

iteration = 7
Parameter:
[1] 1.2649779 0.8239836
Function Value
[1] 1044.447
Gradient:
[1]  1.484159e-08 -2.278478e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2680074 0.8245313
Function Value
[1] 1044.427
Gradient:
[1]  2.646866 -2.507996

iteration = 1
Parameter:
[1] -1511.2447019     0.8231283
Function Value
[1] 828.111
Gradient:
[1] 1.838670e-19 3.383300e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0.6849700 0.8350883
Function Value
[1] 1045.183
Gradient:
[1] -3.362103  2.360611

iteration = 6
Parameter:
[1] 1.2655782 0.8239852
Function Value
[1] 1044.441
Gradient:
[1]  2.966911e-08 -4.556948e-08

Successive iterates within tolerance.
Current iterate is probably solution.

iteration = 0
Step:
[1] 0 0
Parameter:
[1] 1.2681166 0.8245338
Function Value
[1] 1044.426
Gradient:
[1]  2.647143 -2.508281

iteration = 1
Parameter:
[1] -1511.3374568     0.8231297
Function Value
[1] 827.5546
Gradient:
[1] -1.121176e-18  3.487243e+01

Maximum step size exceeded 5 consecutive times.
Either the function is unbounded below,
becomes asymptotic to a finite value
from above in some direction,
or stepmx is too small.

Error in nlme.formula(conc ~ quinModel(Subject, time, conc, dose, interval,  : 
	Maximum number of iterations reached without convergence
Execution halted


From bates@stat.wisc.edu  Fri Dec 13 00:15:05 2002
From: bates@stat.wisc.edu (Douglas Bates)
Date: Fri Dec 13 00:15:05 2002
Subject: [Rd] convergence problem with nlme() (PR#2369)
In-Reply-To: <200212122243.XAA27894@pubhealth.ku.dk>
References: <200212122243.XAA27894@pubhealth.ku.dk>
Message-ID: <6radjade7l.fsf@bates5.stat.wisc.edu>

It turns out that you learn more if you set verbose = TRUE in the call
to nlme rather than setting control = nlmeControl(msVerbose = TRUE).

The verbose = TRUE option shows you that the parameter values are
bouncing back and forth between two regions of the parameter space,
neither of which are close to the optimum.  It happens that nlm will
occasionally take very large steps at the beginning of the
optimization resulting in unusual parameter values.

This example is a difficult optimization problem.  It may be possible
to stabilize it somewhat by replacing the internal calls to nlm by
calls to optim but that brings its own set of difficulties.


From Toby.Patterson@csiro.au  Fri Dec 13 00:15:36 2002
From: Toby.Patterson@csiro.au (Toby.Patterson@csiro.au)
Date: Fri Dec 13 00:15:36 2002
Subject: [Rd] xyplot {lattice} bug causes crash (PR#2370)
Message-ID: <200212122314.AAA28082@pubhealth.ku.dk>

Full_Name: Toby Patterson
Version: 1.6.0
OS: winXP
Submission from: (NULL) (140.79.2.3)



I seem to be able to cause a predictable crash (i.e. the application terminates
abnormally) in R using the library lattice. If I have 

x<-cbind(1:10,c(rep(1,7),rep(2,3)),rnorm(10))
library(lattice)
xyplot(x[,1]~x[,3]|x[,2]) 
 
# works oK but reversing the ylim entries i.e. 

xyplot(x[,1]~x[,3]|x[,2],ylim=c(10,0)) 

# seems to crash R at this point with a "divide by zero" win32 popup error 
# message. 


platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.0            
year     2002           
month    10             
day      01             
language R


From deepayan@stat.wisc.edu  Fri Dec 13 00:45:03 2002
From: deepayan@stat.wisc.edu (deepayan@stat.wisc.edu)
Date: Fri Dec 13 00:45:03 2002
Subject: [Rd] xyplot {lattice} bug causes crash (PR#2370)
Message-ID: <200212122345.AAA28192@pubhealth.ku.dk>

This doesn't happen in the lattice (0.6-something) that ships with R 1.6.1 
(the fix wasn't intentional, but a by product of some other changes :). 
Please upgrade (R 1.6.0 has more severe problems anyway).

On Thursday 12 December 2002 05:14 pm, Toby.Patterson@csiro.au wrote:
> Full_Name: Toby Patterson
> Version: 1.6.0
> OS: winXP
> Submission from: (NULL) (140.79.2.3)
>
>
>
> I seem to be able to cause a predictable crash (i.e. the application
> terminates abnormally) in R using the library lattice. If I have
>
> x<-cbind(1:10,c(rep(1,7),rep(2,3)),rnorm(10))
> library(lattice)
> xyplot(x[,1]~x[,3]|x[,2])
>
> # works oK but reversing the ylim entries i.e.
>
> xyplot(x[,1]~x[,3]|x[,2],ylim=c(10,0))
>
> # seems to crash R at this point with a "divide by zero" win32 popup error
> # message.
>
>
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.0
> year     2002
> month    10
> day      01
> language R
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-devel


From jfox@McMaster.ca  Fri Dec 13 00:54:03 2002
From: jfox@McMaster.ca (John Fox)
Date: Fri Dec 13 00:54:03 2002
Subject: [Rd] Flat documentation?
In-Reply-To: <3DF8C951.FB17F34A@umsanet.edu.bo>
References: <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca>
 <b5vcvu0tp8ab3r1o9r9m9c1rqv4rke2llp@4ax.com>
 <3DF7571E.20E2B822@bank-banque-canada.ca>
 <5.0.2.1.0.20021211143041.02872480@mcmail.cis.mcmaster.ca>
 <8e3hvu4rvnimgh0bu798itlcbhhdeuv1c2@4ax.com>
 <5.1.0.14.2.20021212092533.01ddb880@mcmail.cis.mcmaster.ca>
 <qbbhvu825pgqghjjn76cj8q8kckknda02l@4ax.com>
Message-ID: <5.0.2.1.0.20021212184054.00aed228@mcmail.cis.mcmaster.ca>

Dear Kjetil,

At 01:37 PM 12/12/2002 -0400, kjetil halvorsen wrote:

>Duncan Murdoch wrote:
>
> >
> > Storage isn't a problem, I'm thinking of the user interface.  I
> > normally write my functions in a text editor, then source them into R.
> > Other people use a workspace as the primary place to store functions.
> > Both methods should allow for easy addition of lightweight
> > documentation.
>
>When functions are stored in workspaces, and options keep.source=FALSE
>are used, it will not work to write the documentation as comments in the
>function. So attributes seems preferable, if one goes for
>light-weight documentation.
>

It occurs to me that this behaviour could be modified so that comments at 
the beginning of a function are kept in any event (perhaps in an attribute).

It seems to me that there are lots of simple ways of implementing the ideas 
that we've been discussing and that any one of them would probably be 
reasonable and better than the current situation.

Regards,
  John
____________________________
John Fox
Department of Sociology
McMaster University
email: jfox@mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox


From ripley@stats.ox.ac.uk  Fri Dec 13 08:07:04 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 13 08:07:04 2002
Subject: [Rd] xyplot {lattice} bug causes crash (PR#2370)
In-Reply-To: <200212122314.AAA28082@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.31.0212130659560.2314-100000@gannet.stats>

That's not the current version of R (and presumably not of grid nor
lattice).

This does work with the current versions for me on XP: please update your
system.

On Fri, 13 Dec 2002 Toby.Patterson@csiro.au wrote:

> Full_Name: Toby Patterson
> Version: 1.6.0
> OS: winXP
> Submission from: (NULL) (140.79.2.3)
>
>
>
> I seem to be able to cause a predictable crash (i.e. the application terminates
> abnormally) in R using the library lattice. If I have
>
> x<-cbind(1:10,c(rep(1,7),rep(2,3)),rnorm(10))
> library(lattice)
> xyplot(x[,1]~x[,3]|x[,2])
>
> # works oK but reversing the ylim entries i.e.
>
> xyplot(x[,1]~x[,3]|x[,2],ylim=c(10,0))
>
> # seems to crash R at this point with a "divide by zero" win32 popup error
> # message.
>
>
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.0
> year     2002
> month    10
> day      01
> language R
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From prye@shiraz.apana.org.au  Fri Dec 13 11:02:02 2002
From: prye@shiraz.apana.org.au (prye@shiraz.apana.org.au)
Date: Fri Dec 13 11:02:02 2002
Subject: [Rd] Minor glitch in building documentation (PR#2371)
Message-ID: <200212131001.LAA01060@pubhealth.ku.dk>

This is a very minor glitch, which I think is a problem in
texi2dvi. Building *.dvi and *.pdf files fails due to a problem with the
"--texinfo=@set UseExternalXrefs" argument to texi2dvi. This inserts the
additional @set line where it is supposed to, but fails to follow it with a
space or newline, therefore creates a syntax error.


The following patch works here:

--- doc/manual/Makefile.in.orig Fri Sep  6 07:44:00 2002
+++ doc/manual/Makefile.in      Thu Dec 12 17:14:51 2002
@@ -34,7 +34,8 @@
 MAKEINFO_TEXT_OPTS = --number-sections --fill-column=76 --no-split --no-headers
 TEXI2HTML = $(MAKEINFO) $(MAKEINFO_HTML_OPTS)
 TEXI2TEXT = $(MAKEINFO) $(MAKEINFO_TEXT_OPTS)
-TEXI2DVI = $(top_builddir)/bin/texi2dvi --texinfo="@set UseExternalXrefs"
+# Looks like a bug in texi2dvi to me - needs a space after the --texinfo= argument
+TEXI2DVI = $(top_builddir)/bin/texi2dvi --texinfo="@set UseExternalXrefs "
 TEXI2PDF = $(TEXI2DVI) --pdf
 PDFLATEX = @PDFLATEX@
 PDFTEX = @PDFTEX@


From plummer@iarc.fr  Fri Dec 13 18:01:11 2002
From: plummer@iarc.fr (Martyn Plummer)
Date: Fri Dec 13 18:01:11 2002
Subject: [Rd] R -g gnome has graphics bugs (PR#2366)
In-Reply-To: <200212121319.OAA24193@pubhealth.ku.dk>
References: <200212121319.OAA24193@pubhealth.ku.dk>
Message-ID: <1039799053.1802.119.camel@xena>

On Thu, 2002-12-12 at 14:19, chris-public@math.uu.se wrote:
> Full_Name: Christian Nygaard
> Version: 1.6.1
> OS: Red Hat 7.3
> Submission from: (NULL) (130.238.149.29)
> 
> 
> R 1.6.1 run with argument -g gnome has bugs when plotting certain graphics. The
> right and bottom plot borders are not shown sometimes.
> 
> $ R -g gnome
> > demo ("graphics")
> > Hit enter 5 times
> 
> The same works fine with R -g X11


The default device under the gnome interface is the GTK+ device. This
has been put into a separate package called gtkDevice, which contains
the latest version of the code.  This bug is, I believe, fixed in the
package.

Martyn


From deepayan@stat.wisc.edu  Fri Dec 13 19:57:06 2002
From: deepayan@stat.wisc.edu (deepayan@stat.wisc.edu)
Date: Fri Dec 13 19:57:06 2002
Subject: [Rd] Re: [R] Problem with lattice bwplot (same as PR#2349)
Message-ID: <200212131848.TAA06973@pubhealth.ku.dk>

This is the same bug as that reported by Wolfram Fischer a few days back. I'm 
working on it, and hopefully it would be fixed by the next release of lattice 
(sometime next week).

Deepayan

On Friday 13 December 2002 08:57 am, Luis Torgo wrote:
> I've come across the following error when using free scales with bwplot (I
> use
>
> a small example data set just to illustrate the problem):
> > d <- data.frame(
>
> x=c(34.4, 12.4, NA, 65.3, NA, 12.0, 45.0, 645.0, 644.0,323.0),
> fac1=c('a','a','b','a','b','a','a','c','c','c'),
> fac2=c('v2','v2','v1','v2','v2','v2','v1','v2','v1','v2')
> )
>
> # ok, although "x" has only NA values for fac1=='b'
>
> > bwplot(fac2 ~ x | fac1,data=d)
>
> # not ok, if I try to use different scales in the X axis
>
> > bwplot(fac2 ~ x | fac1,data=d,scales=list(x="free"))
>
> Error in pretty(x[is.finite(x)], ...) : x must be numeric
>
> # I can go around the error with
>
> > bwplot(fac2 ~ x | fac1,data=d[!is.na(d$x),],scales=list(x="free"))
>
> The problem is that one of the panels has no data because 'x' has only NA
> values for that particular factor combination. This causes no problem with
> uniform scales, but generates that error when trying to guess the best
> scale for each panel. I think that it should be easy to add some test to
> the code obtaining the scales for each panel, to avoid the always
> unpleasant criptographic error messages ;-)
>
> Thanks,
> Luis Torgo


From u9801539@leonard.anu.edu.au  Sat Dec 14 10:47:02 2002
From: u9801539@leonard.anu.edu.au (u9801539@leonard.anu.edu.au)
Date: Sat Dec 14 10:47:02 2002
Subject: [Rd] quantreg package - predict method for rq objects (PR#2374)
Message-ID: <200212140947.KAA08582@pubhealth.ku.dk>

In help(rq.object), under Methods, it says:
"
The `"rq"' class of objects has methods for the following generic 
     functions:  `coef', `effects' , `formula' , `labels' , 
     `model.frame' , `model.matrix' , `plot' , `predict' , `print' ,
     `print.summary' , `residuals' , `summary'
"
There seems to be no predict method:

> y <- rnorm(500)
> u <- rq(y ~ 1, tau=.75)
Warning message: 
Solution may be nonunique in: rq.fit.br(x, y, tau = tau, ...) 
> predict(u)
Error in predict(u) : no applicable method for "predict"

[I have looked both at the Windows and at the Darwin/X11 versions.]

John Maindonald                     email : john.maindonald@anu.edu.au
Centre for Bioinformation Science,  phone : (6125)3473        
c/o MSI,                            fax   : (6125)5549 
John Dedman Mathematical Sciences Building (Building 27)
Australian National University
Canberra ACT 0200
Australia


From volker.franz@tuebingen.mpg.de  Mon Dec 16 14:32:03 2002
From: volker.franz@tuebingen.mpg.de (volker.franz@tuebingen.mpg.de)
Date: Mon Dec 16 14:32:03 2002
Subject: [Rd] Lattice: panel.superpose function does not pass subscripts and groups arguments (PR#2377)
Message-ID: <200212161332.OAA20633@pubhealth.ku.dk>

Full_Name: Volker Franz
Version: 1.5.1
OS: Debian-Linux
Submission from: (NULL) (134.176.77.64)


Hi,

working with the panel.superpose function, I found out that this
function does not pass the subscripts and groups arguments to
panel.groups functions.

In my view, this seems an unnecessary restriction, because the
subscripts-mechanism which allows to access the original data should
also work if we use the panel.superpose function. (see, "A Tour of
Trellis Graphics": "the subscripts argument is a numeric vector that
tells which observation in the original data is associated with the x-
and y- values"; section 3.2).

The following patch is for the panel.superpose function of the lattice
library.  It ensures that the subscripts and the groups arguments are
passed correctly to panel.groups functions.

For illustration, I append an example which only works with the
patch...

Best
Volker

######################################################################
##Patch
##(this is patched against /usr/lib/R/library/lattice/R/lattice in
##Debian; in the .tar.gz version, the target file is: panels.R)
##
##Description: 
##   Package: lattice
##   Version: 0.5-3
##   Date: 2002/05/30
##   Priority: recommended
##   Title: Lattice Graphics
##   Author: Deepayan Sarkar <deepayan@stat.wisc.edu>
##   Maintainer: Deepayan Sarkar <deepayan@stat.wisc.edu>
##   Description: Implementation of Trellis Graphics
##   Depends: R (>= 1.5.0), grid (>= 0.6), modreg
##   License: GPL version 2 or later
##   Built: R 1.5.1; i386-pc-linux-gnu; Mon Jul 15 21:40:24 CDT 2002
##
##Note: I just checked: the problem also exists in version, 0.6-6)
######################################################################
--- lattice.orig	Tue Jul 16 04:40:24 2002
+++ lattice	Sun Dec 15 22:46:18 2002
@@ -3995,6 +3995,8 @@
             id <- (groups[subscripts] == vals[i])
             if (any(id)) {
                 args <- list(x=x[id], 
+                             subscripts = subscripts[id],
+                             groups = groups,
                              pch = pch[i], cex = cex[i],
                              col.line = col.line[i],
                              col.symbol = col.symbol[i],
######################################################################
##Example: This is the patched panel.superpose function:
######################################################################
panel.superpose <-
    function(x, y = NULL, subscripts, groups,
             panel.groups = "panel.xyplot",
             col,
             col.line = superpose.line$col,
             col.symbol = superpose.symbol$col,
             pch = superpose.symbol$pch,
             cex = superpose.symbol$cex, 
             lty = superpose.line$lty,
             lwd = superpose.line$lwd,
             ...)
{
    if (length(x)>0) {

        if (!missing(col)) {
            if (missing(col.line)) col.line <- col
            if (missing(col.symbol)) col.symbol <- col
        }

        superpose.symbol <- trellis.par.get("superpose.symbol")
        superpose.line <- trellis.par.get("superpose.line")

        x <- as.numeric(x)
        if (!is.null(y)) y <- as.numeric(y)

        vals <- sort(unique(groups))
        nvals <- length(vals)
        col.line <- rep(col.line, length=nvals)
        col.symbol <- rep(col.symbol, length=nvals)
        pch <- rep(pch, length=nvals)
        lty <- rep(lty, length=nvals)
        lwd <- rep(lwd, length=nvals)
        cex <- rep(cex, length=nvals)

        panel.groups <- 
            if (is.function(panel.groups)) panel.groups
            else if (is.character(panel.groups)) get(panel.groups)
            else eval(panel.groups)

        for (i in seq(along=vals)) {
            id <- (groups[subscripts] == vals[i])
            if (any(id)) {
                args <- list(x=x[id], 
                             subscripts = subscripts[id],
                             groups = groups,
                             pch = pch[i], cex = cex[i],
                             col.line = col.line[i],
                             col.symbol = col.symbol[i],
                             lty = lty[i],
                             lwd = lwd[i], ...)
                if (!is.null(y)) args$y=y[id]

                do.call("panel.groups", args)
            }
        }
    }
}
######################################################################
##Example: Draw a nice figure with errorbars/conf.intervalls...:
######################################################################
library(lattice)
data(barley)
barley$variety  <- as.numeric(barley$variety)
barley$yield.se <- abs(rnorm(length(barley$yield),sd=3))#Simulate standard
errors
print(xyplot(yield ~ variety | site,
             data = barley,
             groups = year,
             ses = barley$yield.se,
             type="p",
             panel  = function(x,y, ...) {
               panel.superpose(x,y, ...)
               panel.superpose(x,y,
                                
panel.groups=function(x,y,subscripts,groups,ses,col.symbol,...){
                                   cat("Call to selfdefined panel.groups
function by panel.superpose:\n")
                                   cat("  length(x)=          ",length(x),"
x=",x,"\n")
                                   cat("  length(y)=          ",length(y),"
y=",y,"\n")
                                   cat("  length(groups)=     ",length(groups),"
groups=",groups,"\n")
                                   cat("  length(ses)=        ",length(ses),"
ses=",ses,"\n")
                                   cat("  length(subscripts)=
",length(subscripts)," subscripts=",subscripts,"\n")
                                   cat("  groups[subscripts]=
",groups[subscripts],"\n")
                                   cat("  ses[subscripts]=   
",ses[subscripts],"\n")
                                  
larrows(x,y,x,y+ses[subscripts],col=col.symbol,angle=90,proportion=0.05)
                                  
larrows(x,y,x,y-ses[subscripts],col=col.symbol,angle=90,proportion=0.05)
                                 },...)
             }))
######################################################################

--please do not edit the information below--

Version:
 platform = i386-pc-linux-gnu
 arch = i386
 os = linux-gnu
 system = i386, linux-gnu
 status = 
 major = 1
 minor = 5.1
 year = 2002
 month = 06
 day = 17
 language = R

Search Path:
 .GlobalEnv, package:ctest, package:lattice, package:grid, package:nlme,
package:nls, Autoloads, package:base


From wolfram@fischer-zim.ch  Mon Dec 16 15:25:08 2002
From: wolfram@fischer-zim.ch (Wolfram Fischer - Z/I/M)
Date: Mon Dec 16 15:25:08 2002
Subject: [Rd] [R] Proposal: barchart() with bars beginning at zero.
Message-ID: <20021216152532.A5741@s1x.zimnet.ch>

Hello

I would like to propose to extend the functionality
of barchart() with a argument "orig.zero" which results
in bars beginning at zero.

I have added a possible code for this extension.

Wolfram Fischer


#^wf	16.12.02 based on R 1.6.1

panel.barchart <-
function (x, y, box.ratio = 1, horizontal = TRUE, col = bar.fill$col, 
#--- NEW
	orig.zero = F,
#---
    ...) 
{
    x <- as.numeric(x)
    y <- as.numeric(y)
#--- NEW
	xlim <- current.viewport()$xscale
	ylim <- current.viewport()$yscale
#---
    bar.fill <- trellis.par.get("bar.fill")
    if (horizontal) {
#--- ORIG
#       xmin <- current.viewport()$xscale[1]
#--- NEW
		grid.lines( c(0,0), ylim, default.units = "native", gp = gpar(lty = 2) )
        xmin <- ifelse( orig.zero, 0, xlim[1] )
#---
        height <- box.ratio/(1 + box.ratio)
        for (i in seq(along = x)) {
            grid.rect(gp = gpar(fill = col), y = y[i], 
#--- ORIG
#				x = unit(0, "npc"),
#--- NEW
				x = ifelse( orig.zero, 0, unit(0, "npc") ),
#---
				height = height, width = x[i] - xmin, 
                just = c("left", "centre"), default.units = "native")
        }
    }
    else {
#--- ORIG
#       ymin <- current.viewport()$yscale[1]
#--- NEW
		grid.lines( xlim, c(0,0), default.units = "native", gp = gpar(lty = 2) )
        ymin <- ifelse( orig.zero, 0, ylim[1] )
#---
        width <- box.ratio/(1 + box.ratio)
        for (i in seq(along = y)) {
            grid.rect(gp = gpar(fill = col), x = x[i], 
#--- ORIG
#				y = unit(0, "npc"),
#--- NEW
				y = ifelse( orig.zero, 0, unit(0, "npc") ),
#---
				height = y[i] - ymin, width = width, 
                just = c("centre", "bottom"), default.units = "native")
        }
    }
}
barchart <-
function (formula, data = parent.frame(), panel = "panel.barchart", 
    prepanel = NULL, strip = TRUE, box.ratio = 2, groups = NULL, 
#--- NEW
	orig.zero = F,
#---
    horizontal = NULL, ..., subset = TRUE) 
{
    dots <- list(...)
    groups <- eval(substitute(groups), data, parent.frame())
    subset <- eval(substitute(subset), data, parent.frame())
    if (!is.function(panel)) 
        panel <- eval(panel)
    if (!is.function(strip)) 
        strip <- eval(strip)
    prepanel <- if (is.function(prepanel)) 
        prepanel
    else if (is.character(prepanel)) 
        get(prepanel)
    else eval(prepanel)
    do.call("bwplot", c(list(formula = formula, data = data, 
        horizontal = horizontal, groups = groups, subset = subset, 
        panel = panel, prepanel = prepanel, strip = strip, box.ratio = box.ratio), 
#--- NEW
	orig.zero = orig.zero,
#---
        dots))
}


--

_______________   
_______/___/___   Zentrum fuer Informatik und wirtschaftliche Medizin
____Z_/___/____   
_____/_I_/_____   Steigstrasse 12, CH-9116 Wolfertswil, Schweiz
____/___/_M____   Tel: +41 71 3900 444, Fax: +41 71 3900 447
___/___/_______   mailto:wolfram@fischer-zim.ch  http://www.fischer-zim.ch/


From volker.franz@tuebingen.mpg.de  Mon Dec 16 17:31:06 2002
From: volker.franz@tuebingen.mpg.de (volker.franz@tuebingen.mpg.de)
Date: Mon Dec 16 17:31:06 2002
Subject: [Rd] (PR#2377)
Message-ID: <200212161630.RAA23341@pubhealth.ku.dk>

P.s: Sorry, the example got screwed because the lines were longer than
72characters. Here, it is again...
 
######################################################################
library(lattice)
data(barley)

##Simulate standard errors:
barley$variety  <- as.numeric(barley$variety)
barley$yield.se <- abs(rnorm(length(barley$yield),sd=3))

##Print xyplot with errorbars:
print(xyplot(yield ~ variety | site,
data = barley,
groups = year,
ses = barley$yield.se,
type="p",
panel  = function(x,y, ...) {
panel.superpose(x,y, ...)
panel.superpose(x,y,
panel.groups=function(x,y,subscripts,groups,ses,col.symbol,...){
cat("Call to selfdefined panel.groups function by panel.superpose:\n")
cat("  length(x)=          ",length(x),"x=",x,"\n")
cat("  length(y)=          ",length(y),"y=",y,"\n")
cat("  length(groups)=     ",length(groups),"groups=",groups,"\n")
cat("  length(ses)=        ",length(ses),"ses=",ses,"\n")
cat("  subscripts: length=",length(subscripts)," val=",subscripts,"\n")
cat("  groups[subscripts]=",groups[subscripts],"\n")
cat("  ses[subscripts]=   ",ses[subscripts],"\n")
larrows(x,y,x,y+ses[subscripts],col=col.symbol,angle=90,proportion=0.05)
larrows(x,y,x,y-ses[subscripts],col=col.symbol,angle=90,proportion=0.05)
},...)
}))
######################################################################
Volker
--


From charpent@bacbuc.dyndns.org  Tue Dec 17 10:40:04 2002
From: charpent@bacbuc.dyndns.org (charpent@bacbuc.dyndns.org)
Date: Tue Dec 17 10:40:04 2002
Subject: [Rd] rsprng doesn't install on Debian (woody) (PR#2378)
Message-ID: <200212170940.KAA27539@pubhealth.ku.dk>

Full_Name: Emmanuel Charpentier
Version: 1.6.1
OS: Linux 2.4.20 / Debian Woody
Submission from: (NULL) (80.15.78.96)


rsprng depends on libraries available in the "genesis" package. However, even
when Genesis is installed, the installation of the source package fails for not
finding rsprng.h. It turns out that Debian installs it in a subdirectoru of
/usr/include, and that the rsprng packages assumes that it is located in
/usr/include.

I have but a suggestion : allow the rsprng installation to look in /usr/include
subdirectories.

Sincerely,

                           Emmanuel Charpentier


From rossini@u.washington.edu  Tue Dec 17 13:54:03 2002
From: rossini@u.washington.edu (A.J. Rossini)
Date: Tue Dec 17 13:54:03 2002
Subject: [Rd] rsprng doesn't install on Debian (woody) (PR#2378)
In-Reply-To: <200212170940.KAA27539@pubhealth.ku.dk> (charpent@bacbuc.dyndns.org's
 message of "Tue, 17 Dec 2002 10:40:33 +0100 (MET)")
References: <200212170940.KAA27539@pubhealth.ku.dk>
Message-ID: <87d6o0kds9.fsf@jeeves.blindglobe.net>

>>>>> "charpent" == charpent  <charpent@bacbuc.dyndns.org> writes:

    charpent> Full_Name: Emmanuel Charpentier
    charpent> Version: 1.6.1
    charpent> OS: Linux 2.4.20 / Debian Woody
    charpent> Submission from: (NULL) (80.15.78.96)


    charpent> rsprng depends on libraries available in the "genesis" package. However, even
    charpent> when Genesis is installed, the installation of the source package fails for not
    charpent> finding rsprng.h. It turns out that Debian installs it in a subdirectoru of
    charpent> /usr/include, and that the rsprng packages assumes that it is located in
    charpent> /usr/include.

    charpent> I have but a suggestion : allow the rsprng installation to look in /usr/include
    charpent> subdirectories.

Executive Summary:  

The Debian genesis package contains SPRNG v1.0.  The R RSPRNG package
is really set up to use SPRNG v2.0.  There are extremely crude RPM/DEB
packages of v2.0 for Intel Linux at 

     http://software.biostat.washington.edu/~rossini/cluster_computing/

(I should stress again, they are fairly crude; but they work on our
machines, and apparently, on some other people's machines as well).

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini@u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini@scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)


From Martin Maechler <maechler@stat.math.ethz.ch>  Tue Dec 17 19:08:06 2002
From: Martin Maechler <maechler@stat.math.ethz.ch> (Martin Maechler)
Date: Tue Dec 17 19:08:06 2002
Subject: [Rd] Changing "..." inside a function: impossible? desirable?
Message-ID: <15871.26572.352351.211263@gargle.gargle.HOWL>

This is was something like a request for your comments, thoughts
on the topic...

Many of you will know that the "..." (aka \dots) argument is
very useful for passing ``further graphical parameters'', 
but can be a pain when itself is passed to too many plotting
functions inside your own function.
An artificial example being

  myplot <- function(x,y, ...) {

   plot(0:1, 0:1, type = "n", axes = FALSE)

   result <-  <<do stuff with x,y>>

   points(result, ...)
   axis(1, ...)
   axis(2, ...)
   title(...)
  }

It's clear that some things in "..." can be passed to title() and
some to axis(), etc.
Of course the above is really silly, but I have a situation
where I'd like to see if something, say, `myarg' is part of "..."  
{piece of cake easy, see below} but then I want to  *eliminate*
it from "..." such that I can pass "..." down to other functions
which would want to see a `myarg' argument.

Something like

if("myarg" %in% (naml <- names(list(...)))) {
   ## ok, it's there, take it out
   marg <- list(...)$ marg

   ## what I now would like is  

   ...  <-  unlist( list(...)["myarg" != naml] )
}


BTW: one relatively ugly workaround is to use the above *list*
     say  nlist <- list(...)["myarg" != naml]
     and do all subsequent call where I'd had "..." as
     do.call( <funname> ,  c(list( <<other args to funnname>> ), nlist))
but this really obfuscates the code horrendously.

PS: 
    I know that using a  pars = list(.) argument instead of "..."
    is another alternative (that we have been using) as well,
    but lets assume this can't be done, because of compatibility reasons.

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From luke@stat.uiowa.edu  Tue Dec 17 22:16:03 2002
From: luke@stat.uiowa.edu (Luke Tierney)
Date: Tue Dec 17 22:16:03 2002
Subject: [Rd] Changing "..." inside a function: impossible? desirable?
In-Reply-To: <15871.26572.352351.211263@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.44.0212171507550.13373-100000@itasca.stat.uiowa.edu>

On Tue, 17 Dec 2002, Martin Maechler wrote:

> 
> It's clear that some things in "..." can be passed to title() and
> some to axis(), etc.
> Of course the above is really silly, but I have a situation
> where I'd like to see if something, say, `myarg' is part of "..."  
> {piece of cake easy, see below} but then I want to  *eliminate*
> it from "..." such that I can pass "..." down to other functions
> which would want to see a `myarg' argument.
> 
> Something like
> 
> if("myarg" %in% (naml <- names(list(...)))) {
>    ## ok, it's there, take it out
>    marg <- list(...)$ marg
> 
>    ## what I now would like is  
> 
>    ...  <-  unlist( list(...)["myarg" != naml] )
> }
> 

Does'nt

function(x, y, myarg, ...) {
    if(! missing(myarg)) {
       ## ok, it's there, do whatever
    }
    ....


i.e. just remove the things you explicitly want not in ... by naming
them as arguments work for your setting?

luke


-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From gregory_r_warnes@groton.pfizer.com  Tue Dec 17 22:33:02 2002
From: gregory_r_warnes@groton.pfizer.com (Warnes, Gregory R)
Date: Tue Dec 17 22:33:02 2002
Subject: [Rd] Changing "..." inside a function: impossible? desirable?
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C3AC@groexmb02.pfizer.com>


I agree that it would be useful to be able to manipulate the contents of
<...>.   
Perhaps syntax like:

	dots <- dotargs()  # equivalent to dots <- list(...)

	val1 <- dotargs('arg1')

to extract the contents of <...> and

	dotargs('arg1') <- val1

to modifiy the argument 'arg1' would do the trick.  Then one could do things
like


   myplot <- function(x,y, ...) {
 
    plot(0:1, 0:1, type = "n", axes = FALSE)
 
    result <-  <<do stuff with x,y>>
 
    points(result, ...)
	
    dotargs('pch') <- NA

    axis(1, ...)
    axis(2, ...)

    dotargs('lwd') <- dotargs('xaxp') <- dotartgs('yaxp') <- NULL
    title(...)
   }


-Greg


> -----Original Message-----
> From: Martin Maechler [mailto:maechler@stat.math.ethz.ch]
> Sent: Tuesday, December 17, 2002 1:07 PM
> To: R-devel@stat.math.ethz.ch
> Subject: [Rd] Changing "..." inside a function: impossible? desirable?
> 
> 
> This is was something like a request for your comments, thoughts
> on the topic...
> 
> Many of you will know that the "..." (aka \dots) argument is
> very useful for passing ``further graphical parameters'', 
> but can be a pain when itself is passed to too many plotting
> functions inside your own function.
> An artificial example being
> 
>   myplot <- function(x,y, ...) {
> 
>    plot(0:1, 0:1, type = "n", axes = FALSE)
> 
>    result <-  <<do stuff with x,y>>
> 
>    points(result, ...)
>    axis(1, ...)
>    axis(2, ...)
>    title(...)
>   }
> 
> It's clear that some things in "..." can be passed to title() and
> some to axis(), etc.
> Of course the above is really silly, but I have a situation
> where I'd like to see if something, say, `myarg' is part of "..."  
> {piece of cake easy, see below} but then I want to  *eliminate*
> it from "..." such that I can pass "..." down to other functions
> which would want to see a `myarg' argument.
> 
> Something like
> 
> if("myarg" %in% (naml <- names(list(...)))) {
>    ## ok, it's there, take it out
>    marg <- list(...)$ marg
> 
>    ## what I now would like is  
> 
>    ...  <-  unlist( list(...)["myarg" != naml] )
> }
> 
> 
> BTW: one relatively ugly workaround is to use the above *list*
>      say  nlist <- list(...)["myarg" != naml]
>      and do all subsequent call where I'd had "..." as
>      do.call( <funname> ,  c(list( <<other args to funnname>> 
> ), nlist))
> but this really obfuscates the code horrendously.
> 
> PS: 
>     I know that using a  pars = list(.) argument instead of "..."
>     is another alternative (that we have been using) as well,
>     but lets assume this can't be done, because of 
> compatibility reasons.
> 
> Martin Maechler <maechler@stat.math.ethz.ch>	
http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

______________________________________________
R-devel@stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-devel


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]


From tplate@blackmesacapital.com  Tue Dec 17 23:00:04 2002
From: tplate@blackmesacapital.com (Tony Plate)
Date: Tue Dec 17 23:00:04 2002
Subject: [Rd] Changing "..." inside a function: impossible?
 desirable?
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C202F2C3AC@groexmb02.pfizer.
 com>
Message-ID: <5.1.0.14.2.20021217144734.0480ad00@mailhost.blackmesacapital.com>

Another way of enabling more vesatile dot-args would be to allow an 
ordinary list to be used as "dotargs", e.g., the following three would be 
equivalent (except for issues around lazy evaluation):

# V1: current simple passing of dotargs
function(x, ...) {
    f(x, ...)
}

# V2: allow manipulation of dotargs using current language features, but 
syntax is ugly
function(x, ...) {
     dotargs <- list(...)
     do.call("f", c(list(x), dotargs))
}

# V3: proposed syntax for passing dotargs
function(x, ...) {
      dotargs <- list(...)
      f(x, ...=dotargs)  # a new syntax
}

This syntax in #3 would allow manipulation of dot-arguments, with a sweeter 
syntax for passing them than do.call() provides.

Where this might not fit neatly with the current semantics of the S 
language is that the "dotargs <- list(...)" would trigger evaluation of 
actual arguments.

-- Tony Plate

At Tuesday 03:28 PM 12/17/2002 -0500, Warnes, Gregory R wrote:


>I agree that it would be useful to be able to manipulate the contents of
><...>.
>Perhaps syntax like:
>
>         dots <- dotargs()  # equivalent to dots <- list(...)
>
>         val1 <- dotargs('arg1')
>
>to extract the contents of <...> and
>
>         dotargs('arg1') <- val1
>
>to modifiy the argument 'arg1' would do the trick.  Then one could do things
>like
>
>
>    myplot <- function(x,y, ...) {
>
>     plot(0:1, 0:1, type = "n", axes = FALSE)
>
>     result <-  <<do stuff with x,y>>
>
>     points(result, ...)
>
>     dotargs('pch') <- NA
>
>     axis(1, ...)
>     axis(2, ...)
>
>     dotargs('lwd') <- dotargs('xaxp') <- dotartgs('yaxp') <- NULL
>     title(...)
>    }
>
>
>-Greg
>
>
> > -----Original Message-----
> > From: Martin Maechler [mailto:maechler@stat.math.ethz.ch]
> > Sent: Tuesday, December 17, 2002 1:07 PM
> > To: R-devel@stat.math.ethz.ch
> > Subject: [Rd] Changing "..." inside a function: impossible? desirable?
> >
> >
> > This is was something like a request for your comments, thoughts
> > on the topic...
> >
> > Many of you will know that the "..." (aka \dots) argument is
> > very useful for passing ``further graphical parameters'',
> > but can be a pain when itself is passed to too many plotting
> > functions inside your own function.
> > An artificial example being
> >
> >   myplot <- function(x,y, ...) {
> >
> >    plot(0:1, 0:1, type = "n", axes = FALSE)
> >
> >    result <-  <<do stuff with x,y>>
> >
> >    points(result, ...)
> >    axis(1, ...)
> >    axis(2, ...)
> >    title(...)
> >   }
> >
> > It's clear that some things in "..." can be passed to title() and
> > some to axis(), etc.
> > Of course the above is really silly, but I have a situation
> > where I'd like to see if something, say, `myarg' is part of "..."
> > {piece of cake easy, see below} but then I want to  *eliminate*
> > it from "..." such that I can pass "..." down to other functions
> > which would want to see a `myarg' argument.
> >
> > Something like
> >
> > if("myarg" %in% (naml <- names(list(...)))) {
> >    ## ok, it's there, take it out
> >    marg <- list(...)$ marg
> >
> >    ## what I now would like is
> >
> >    ...  <-  unlist( list(...)["myarg" != naml] )
> > }
> >
> >
> > BTW: one relatively ugly workaround is to use the above *list*
> >      say  nlist <- list(...)["myarg" != naml]
> >      and do all subsequent call where I'd had "..." as
> >      do.call( <funname> ,  c(list( <<other args to funnname>>
> > ), nlist))
> > but this really obfuscates the code horrendously.
> >
> > PS:
> >     I know that using a  pars = list(.) argument instead of "..."
> >     is another alternative (that we have been using) as well,
> >     but lets assume this can't be done, because of
> > compatibility reasons.
> >
> > Martin Maechler <maechler@stat.math.ethz.ch>
>http://stat.ethz.ch/~maechler/
>Seminar fuer Statistik, ETH-Zentrum  LEO C16    Leonhardstr. 27
>ETH (Federal Inst. Technology)  8092 Zurich     SWITZERLAND
>phone: x-41-1-632-3408          fax: ...-1228                   <><
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>
>LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... 
>[[dropped]]
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-devel


From Martin Maechler <maechler@stat.math.ethz.ch>  Wed Dec 18 08:37:03 2002
From: Martin Maechler <maechler@stat.math.ethz.ch> (Martin Maechler)
Date: Wed Dec 18 08:37:03 2002
Subject: [Rd] Changing "..." inside a function: impossible? desirable?
In-Reply-To: <Pine.LNX.4.44.0212171507550.13373-100000@itasca.stat.uiowa.edu>
References: <15871.26572.352351.211263@gargle.gargle.HOWL>
 <Pine.LNX.4.44.0212171507550.13373-100000@itasca.stat.uiowa.edu>
Message-ID: <15872.9556.913993.601421@gargle.gargle.HOWL>

>>>>> "Luke" == Luke Tierney <luke@stat.uiowa.edu>
>>>>>     on Tue, 17 Dec 2002 15:12:40 -0600 (CST) writes:

    Luke> On Tue, 17 Dec 2002, Martin Maechler wrote:
    >>  It's clear that some things in "..." can be passed to
    >> title() and some to axis(), etc.  Of course the above is
    >> really silly, but I have a situation where I'd like to
    >> see if something, say, `myarg' is part of "..."  {piece
    >> of cake easy, see below} but then I want to *eliminate*
    >> it from "..." such that I can pass "..." down to other
    >> functions which would want to see a `myarg' argument.
    >> 
    >> Something like
    >> 
    >> if("myarg" %in% (naml <- names(list(...)))) { ## ok, it's
    >> there, take it out marg <- list(...)$ marg
    >> 
    >> ## what I now would like is
    >> 
    >> ...  <- unlist( list(...)["myarg" != naml] ) }
    >> 

    Luke> Doesn't

    Luke> function(x, y, myarg, ...) {
    Luke>    if(! missing(myarg)) {
    Luke> 	## ok, it's there, do whatever
    Luke>    }
    Luke>  ....


    Luke> i.e. just remove the things you explicitly want not in ... by naming
    Luke> them as arguments work for your setting?

Sure.  That's the standard approach I have been using many times
in the past (and still!).

For the (many!) graphics parameters, 
this leads to very many new arguments also differing between
context, i.e.  cex.axis, cex.main, ....

Fiddling with "..." could have been a  alternative..
and also a general `language utility', 
Martin


From wolfram@fischer-zim.ch  Wed Dec 18 15:09:14 2002
From: wolfram@fischer-zim.ch (wolfram@fischer-zim.ch)
Date: Wed Dec 18 15:09:14 2002
Subject: [Rd] [R] Lattice: ltext() takes only the x-part of the adj argument (PR#2380)
Message-ID: <200212181357.OAA12283@pubhealth.ku.dk>

In the following example, changing `adjx' from 0 to 0.5 to 1
changes the position of the letters. Changing `adjy' has no
influence on the position of the letters.

adjx = 0
adjy = 0
xyplot( 1:3 ~ 1:3, panel=function( x, y, ... ){
        ltext( x, y, LETTERS[1:3], adj=c( adjx, adjy ), cex=5 )
        panel.grid()
    } )

Wolfram Fischer


From phgrosjean@sciviews.org  Wed Dec 18 15:32:56 2002
From: phgrosjean@sciviews.org (Philippe Grosjean)
Date: Wed Dec 18 15:32:56 2002
Subject: [Rd] Changing "..." inside a function: impossible? desirable?
In-Reply-To: <15871.26572.352351.211263@gargle.gargle.HOWL>
Message-ID: <MABBLJDICACNFOLGIHJOMEPDDBAA.phgrosjean@sciviews.org>

Martin,

I am also fighting with this kind of problem. I consider it is logical to
"specialize" arguments as soon as they have to be used for different
features in the plot (col => col.axis, col.title, etc). For instance,
imagine one wants to create a simple function to plot two series on the same
graph:

dualplot <- function(x, y1, y2, ...){
	plot(x, y1, ...)
	lines(x, y2, ...)
}

# with for instance:
X <- 1:20
Y1 <- rnorm(20)
Y2 <- runif(20)
dualplot(X, Y1, Y2)

# so far, so good, but now, if one wants to change color of the second plot
separately. Using:
dualplot(X, Y1, Y2, col=2)
# ... changes color of BOTH plots!

# Here, it makes sens to use different arguments for the color of both
plots:
dualplot2 <- function(x, y1, y2, col1=1, col2=3, ...){
	plot(x, y1, col=col1, ...)
	lines(x, y2, col=col2, ...)
}
dualplot2(X, Y1, Y2, col1=2, col2=4)

# Or better yet, but requires additional code:
dualplot3 <- function(x, y1, y2, cols=c(1, 3), ...){
	cols <- rep(cols, length.out=3)	# For correct recycling rule
	plot(x, y1, col=cols[1], ...)
	lines(x, y2, col=cols[2], ...)
}
dualplot3(X, Y1, Y2, cols=c(2, 4))

# This could also apply for title(), axis(),... of course
# The only problem is when one wants to specialize the argument for one
subfunction only, but not for the other ones:
dualplot4 <- function(x, y1, y2, col2=3, ...){	# We want to use the standard
'col=' argument in the ... for plot(), and a specialized 'col2=' arg for
lines()
	plot(x, y1, ...)
	lines(x, y2, col=col2, ...)
}
dualplot4(X, Y1, Y2, col=2, col2=4)
# This gives an error of multiple arguments matching in lines()!

So, with this approach, we see that the only required change is to give
priority to argument 'col=col2' against what could be provided in '...'.
Eliminating 'col=' argument in ... is one solution, but the next one is
perhaps better. The alternative solution would be to add an option like
'allow.multiple.args.match', set to FALSE by default, but when set to TRUE,
only the first match of an argument is used without error message. So, our
dualplot4() function would work with:

dualplot4 <- function(x, y1, y2, col2=3,
){	
	plot(x, y1, ...)
	options(allow.multiple.args.match = TRUE)
	lines(x, y2, col=col2, ...)
	# ... other treatment susceptible to have multiple matches
	options(allow.multiple.args.match = FALSE)
}

Best,

Philippe

...........]<(({?<...............<?}))><...............................
( ( ( ( (
 ) ) ) ) )      Philippe Grosjean
( ( ( ( (
 ) ) ) ) )      IFREMER Nantes - DEL/AO
( ( ( ( (       rue de l'Ile d'Yeu, BP 21105, 44311 Nantes Cedex 3
 ) ) ) ) )      tel: (33) 02.40.37.42.29, fax: (33) 02.40.37.42.41
( ( ( ( ( 
 ) ) ) ) )      SciViews project coordinator (http://www.sciviews.org)
( ( ( ( (       e-mail: phgrosjean@sciviews.org
 ) ) ) ) ) 
( ( ( ( (       "I'm 100% confident that p is between 0 and 1"
 ) ) ) ) )                                L. Gonick & W. Smith (1993)
.......................................................................
 

-----Message d'origine-----
De : r-devel-admin@stat.math.ethz.ch
[mailto:r-devel-admin@stat.math.ethz.ch]De la part de Martin Maechler
Envoye : mardi 17 decembre 2002 19:07
A : R-devel@stat.math.ethz.ch
Objet : [Rd] Changing "..." inside a function: impossible? desirable?


This is was something like a request for your comments, thoughts
on the topic...

Many of you will know that the "..." (aka \dots) argument is
very useful for passing ``further graphical parameters'', 
but can be a pain when itself is passed to too many plotting
functions inside your own function.
An artificial example being

  myplot <- function(x,y, ...) {

   plot(0:1, 0:1, type = "n", axes = FALSE)

   result <-  <<do stuff with x,y>>

   points(result, ...)
   axis(1, ...)
   axis(2, ...)
   title(...)
  }

It's clear that some things in "..." can be passed to title() and
some to axis(), etc.
Of course the above is really silly, but I have a situation
where I'd like to see if something, say, `myarg' is par
t of "..."
{piece of cake easy, see below} but then I want to  *eliminate*
it from "..." such that I can pass "..." down to other functions
which would want to see a `myarg' argument.

Something like

if("myarg" %in% (naml <- names(list(...)))) {
   ## ok, it's there, take it out
   marg <- list(...)$ marg

   ## what I now would like is

   ...  <-  unlist( list(...)["myarg" != naml] )
}


BTW: one relatively ugly workaround is to use the above *list*
     say  nlist <- list(...)["myarg" != naml]
     and do all subsequent call where I'd had "..." as
     do.call( <funname> ,  c(list( <<other args to funnname>> ), nlist))
but this really obfuscates the code horrendously.

PS:
    I know that using a  pars = list(.) argument instead of "..."
    is another alternative (that we have been using) as well,
    but lets assume this can't be done, because of compatibility reasons.

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

______________________________________________
R-devel@stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-devel


From pedaa@rockefeller.edu  Wed Dec 18 16:59:07 2002
From: pedaa@rockefeller.edu (Allan Peda)
Date: Wed Dec 18 16:59:07 2002
Subject: [Rd] Announce: r-help and r-devel both available on www.mail-archive.com
Message-ID: <1040226992.10862.53.camel@array14>

Hi:

I recently subcribed r-help and r-develop to the mailing list archives
at http://www.mail-archive.com/index.php , more specifically you 
may browse to:

http://www.mail-archive.com/r-help%40stat.math.ethz.ch/
http://www.mail-archive.com/r-devel%40stat.math.ethz.ch/

It is a searchable mail archiving system.

/a
-- 
Allan Peda

Programmer, Gene Array Resource Center
Rockefeller University
Box 203
1230 York Ave
New York, NY 10021-6399

(tel) 212-327-7064
(fax) 212-327-7065


From deepayan@stat.wisc.edu  Wed Dec 18 22:27:03 2002
From: deepayan@stat.wisc.edu (deepayan@stat.wisc.edu)
Date: Wed Dec 18 22:27:03 2002
Subject: [Rd] [R] Lattice: ltext() takes only the x-part of the adj argument (PR#2380)
Message-ID: <200212182126.WAA15518@pubhealth.ku.dk>

Thanks. Fixed in the development version.

On Wednesday 18 December 2002 07:57 am, wolfram@fischer-zim.ch wrote:
> In the following example, changing `adjx' from 0 to 0.5 to 1
> changes the position of the letters. Changing `adjy' has no
> influence on the position of the letters.
>
> adjx = 0
> adjy = 0
> xyplot( 1:3 ~ 1:3, panel=function( x, y, ... ){
>         ltext( x, y, LETTERS[1:3], adj=c( adjx, adjy ), cex=5 )
>         panel.grid()
>     } )
>
> Wolfram Fischer
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-devel


From morlan@mayo.edu  Wed Dec 18 23:04:03 2002
From: morlan@mayo.edu (morlan@mayo.edu)
Date: Wed Dec 18 23:04:03 2002
Subject: [Rd] Unix Symbolic links failing ("ls -s realfile linkedas") (PR#2381)
Message-ID: <200212182203.XAA15618@pubhealth.ku.dk>

Full_Name: Bruce W. Morlan
Version: 1.5.1
OS: SunOS 5.8
Submission from: (NULL) (129.176.151.124)


I am using an R-package that reads from files if the files are physically in the
startup directory, but fails to read if I use symbolically linked files as in 

  "ln -s real_file linked_as_file"

I did not see this listed in the existing bugs.


From ripley@stats.ox.ac.uk  Wed Dec 18 23:33:02 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec 18 23:33:02 2002
Subject: [Rd] Unix Symbolic links failing ("ls -s realfile linkedas")
 (PR#2381)
In-Reply-To: <200212182203.XAA15618@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.31.0212182230010.24629-100000@gannet.stats>

How are you `reading from' the files?

We do need a reproducible example to have a hope of fixing this.

On Wed, 18 Dec 2002 morlan@mayo.edu wrote:

> Full_Name: Bruce W. Morlan
> Version: 1.5.1

That's two versions old already.

> OS: SunOS 5.8
> Submission from: (NULL) (129.176.151.124)
>
>
> I am using an R-package that reads from files if the files are physically in the
> startup directory, but fails to read if I use symbolically linked files as in
>
>   "ln -s real_file linked_as_file"
>
> I did not see this listed in the existing bugs.

If it were, it might well have been fixed since 1.5.1!

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley@stats.ox.ac.uk  Wed Dec 18 23:33:46 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec 18 23:33:46 2002
Subject: [Rd] Unix Symbolic links failing ("ls -s realfile linkedas") (PR#2382)
Message-ID: <200212182232.XAA15705@pubhealth.ku.dk>

How are you `reading from' the files?

We do need a reproducible example to have a hope of fixing this.

On Wed, 18 Dec 2002 morlan@mayo.edu wrote:

> Full_Name: Bruce W. Morlan
> Version: 1.5.1

That's two versions old already.

> OS: SunOS 5.8
> Submission from: (NULL) (129.176.151.124)
>
>
> I am using an R-package that reads from files if the files are physically in the
> startup directory, but fails to read if I use symbolically linked files as in
>
>   "ln -s real_file linked_as_file"
>
> I did not see this listed in the existing bugs.

If it were, it might well have been fixed since 1.5.1!

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From deepayan@stat.wisc.edu  Wed Dec 18 23:35:02 2002
From: deepayan@stat.wisc.edu (deepayan@stat.wisc.edu)
Date: Wed Dec 18 23:35:02 2002
Subject: [Rd] Lattice: panel.superpose function does not pass subscripts and groups arguments (PR#2377)
Message-ID: <200212182234.XAA15714@pubhealth.ku.dk>

I've added this in the development version.
-Deepayan

On Monday 16 December 2002 07:32 am, volker.franz@tuebingen.mpg.de wrote:
> Full_Name: Volker Franz
> Version: 1.5.1
> OS: Debian-Linux
> Submission from: (NULL) (134.176.77.64)
>
>
> Hi,
>
> working with the panel.superpose function, I found out that this
> function does not pass the subscripts and groups arguments to
> panel.groups functions.
>
> In my view, this seems an unnecessary restriction, because the
> subscripts-mechanism which allows to access the original data should
> also work if we use the panel.superpose function. (see, "A Tour of
> Trellis Graphics": "the subscripts argument is a numeric vector that
> tells which observation in the original data is associated with the x-
> and y- values"; section 3.2).
>
> The following patch is for the panel.superpose function of the lattice
> library.  It ensures that the subscripts and the groups arguments are
> passed correctly to panel.groups functions.
>
> For illustration, I append an example which only works with the
> patch...
>
> Best
> Volker
[...]


From annis@biostat.wisc.edu  Thu Dec 19 21:03:03 2002
From: annis@biostat.wisc.edu (annis@biostat.wisc.edu)
Date: Thu Dec 19 21:03:03 2002
Subject: [Rd] Perl library problem in docs install (PR#2383)
Message-ID: <200212191957.UAA26738@pubhealth.ku.dk>

Full_Name: William Annis
Version: 1.6.1
OS: Solaris
Submission from: (NULL) (144.92.164.199)


In order to get the documentation to build correctly I had to make a
change to the library $INST/share/perl/R/Utils.pm to path out fill
to Text::Wrap::fill.  This is for perl5.005 on solaris.

--
wm


From ripley@stats.ox.ac.uk  Thu Dec 19 21:20:03 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec 19 21:20:03 2002
Subject: [Rd] Perl library problem in docs install (PR#2383
In-Reply-To: <200212191957.UAA26738@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.31.0212192015190.5155-100000@gannet.stats>

That's an ancient version of perl, of which there are several variants,
and the one I had worked on Solaris 2.7.  My memory is that 5.00503 works,
and earlier versions of 5.005 are betas.  So which version precisely do
you have?

I believe this is a bug in your perl install, not in R.  Why don't you try
the current perl 5.8.0?  That does work on reasonably recent Solaris.

On Thu, 19 Dec 2002 annis@biostat.wisc.edu wrote:

> Full_Name: William Annis
> Version: 1.6.1
> OS: Solaris
> Submission from: (NULL) (144.92.164.199)
>
>
> In order to get the documentation to build correctly I had to make a
> change to the library $INST/share/perl/R/Utils.pm to path out fill
> to Text::Wrap::fill.  This is for perl5.005 on solaris.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From annis@biostat.wisc.edu  Thu Dec 19 21:45:03 2002
From: annis@biostat.wisc.edu (William Annis)
Date: Thu Dec 19 21:45:03 2002
Subject: [Rd] Perl library problem in docs install (PR#2383
In-Reply-To: <Pine.LNX.4.31.0212192015190.5155-100000@gannet.stats>
 (ripley@stats.ox.ac.uk)
References: <Pine.LNX.4.31.0212192015190.5155-100000@gannet.stats>
Message-ID: <200212192044.gBJKi8r08810@wazor.biostat.wisc.edu>

 >That's an ancient version of perl, of which there are several variants,
 >and the one I had worked on Solaris 2.7.  My memory is that 5.00503 works,
 >and earlier versions of 5.005 are betas.  So which version precisely do
 >you have?

        Ah.  5.00502, which seems odd.  I thought 03.

 >I believe this is a bug in your perl install, not in R.  Why don't you try
 >the current perl 5.8.0?

        Mostly because I got sick of rewriting several of my programs
after every new perl version change.  Certain functions kept library
hopping, and that quickly got annoying.  Then I converted to Python,
and stopped caring. :)

        But I guess we should get to 5.8.0 soon.

        Thanks.

-- 
William Annis  -  System Administrator -  Biomedical Computing Group
"When men are inhuman, take care not to feel towards them as they do
towards other humans."                       Marcus Aurelius  VII.65


From jerome@hivnet.ubc.ca  Fri Dec 20 01:40:03 2002
From: jerome@hivnet.ubc.ca (jerome@hivnet.ubc.ca)
Date: Fri Dec 20 01:40:03 2002
Subject: [Rd] degrees of freedom in nlme() (PR#2384)
Message-ID: <200212200040.BAA27739@pubhealth.ku.dk>

Full_Name: Jerome Asselin
Version: 1.6.1
OS: RedHat Linux 7.2
Submission from: (NULL) (142.103.173.179)



There is something very queer happening with the degrees
of freedom in nlme(). In the example below, I am fitting
the same model with lme() and nlme(). I am using the
nlme package version 3.1-34.


library(nlme)
set.seed(14)

a <- 2
x <- rep(rnorm(3),rep(5,3))
id <- rep(c("a","b","c"),rep(5,3))
y <- a+x+rnorm(15)
data <- data.frame(y=y,id=id)
initx <- matrix(x[c(1,6,11)],dimnames=list(c("a","b","c"),"x"))

summary(fit.lme <-
              lme(y ~ 1,data=data,random=~1|id,method="ML"))
summary(fit.nlme <-
              nlme(y ~ a + x, fixed= a~1, random=x~1|id,
              data=data, start=list(fixed=c(a=2),
              random=list(id=initx)),method="ML"))


The number of degrees of freedom for the intercept parameter
is 12 degrees using lme(), but only 2 degrees using nlme().
The same problem is noticed with seeds 15, 16 and 17.

But if I change the seed to 18 and try again, then I get 12
degrees of freedom for both lme() and nlme().


set.seed(18)

a <- 2
x <- rep(rnorm(3),rep(5,3))
id <- rep(c("a","b","c"),rep(5,3))
y <- a+x+rnorm(15)
data <- data.frame(y=y,id=id)
initx <- matrix(x[c(1,6,11)],dimnames=list(c("a","b","c"),"x"))

summary(fit.lme <-
              lme(y ~ 1,data=data,random=~1|id,method="ML"))
summary(fit.nlme <-
              nlme(y ~ a + x, fixed= a~1, random=x~1|id,
              data=data, start=list(fixed=c(a=2),
              random=list(id=initx)),method="ML"))


If I set the seed to 5 or 8, then nlme() fails despite the
simplicity of the model. The error messages are:
- for set.seed(5): 
    Step halving factor reduced below minimum in PNLS step
- for set.seed(8):
    Singularity in backsolve at level 0, block 1
This issue of degrees of freedom may be related to the
convergence problems stated in another bug report (PR#2369).

Sincerely,
Jerome Asselin

set.seed(5)

a <- 2
x <- rep(rnorm(3),rep(5,3))
id <- rep(c("a","b","c"),rep(5,3))
y <- a+x+rnorm(15)
data <- data.frame(y=y,id=id)
initx <- matrix(x[c(1,6,11)],dimnames=list(c("a","b","c"),"x"))

summary(fit.lme <-
              lme(y ~ 1,data=data,random=~1|id,method="ML"))
summary(fit.nlme <-
              nlme(y ~ a + x, fixed= a~1, random=x~1|id,
              data=data, start=list(fixed=c(a=2),
              random=list(id=initx)),method="ML"))


set.seed(8)

a <- 2
x <- rep(rnorm(3),rep(5,3))
id <- rep(c("a","b","c"),rep(5,3))
y <- a+x+rnorm(15)
data <- data.frame(y=y,id=id)
initx <- matrix(x[c(1,6,11)],dimnames=list(c("a","b","c"),"x"))

summary(fit.lme <-
              lme(y ~ 1,data=data,random=~1|id,method="ML"))
summary(fit.nlme <-
              nlme(y ~ a + x, fixed= a~1, random=x~1|id,
              data=data, start=list(fixed=c(a=2),
              random=list(id=initx)),method="ML"))


From fharrell@virginia.edu  Fri Dec 20 18:48:02 2002
From: fharrell@virginia.edu (fharrell@virginia.edu)
Date: Fri Dec 20 18:48:02 2002
Subject: [Rd] read.xport and lookup.xport in foreign (PR#2385)
Message-ID: <200212201748.SAA06803@pubhealth.ku.dk>

Under
            
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.1              
year     2002             
month    11               
day      01               
language R                

and using foreign 0.5-8 I am encountering errors when using read.xport.  Here's code for producing SAS transport files for testing:

libname x SASV5XPT "test.xpt";
libname y SASV5XPT "test2.xpt";
PROC FORMAT; VALUE race 1=green 2=blue 3=purple; RUN;
PROC FORMAT CNTLOUT=format;RUN;
data test;
LENGTH race 3 age 4;
age=30; label age="Age at Beginning of Study";
race=2;
d1='3mar2002'd ;
dt1='3mar2002 9:31:02'dt;
t1='11:13:45't;
output;

age=31;
race=4;
d1='3jun2002'd ;
dt1='3jun2002 9:42:07'dt;
t1='11:14:13't;
output;
format d1 mmddyy10. dt1 datetime. t1 time. race race.;
run;
PROC COPY IN=work OUT=x;SELECT test;RUN;
PROC COPY IN=work OUT=y;SELECT test format;RUN;

SAS output:

NOTE: Copying WORK.TEST to X.TEST (memtype=DATA).
NOTE: There were 2 observations read from the data set WORK.TEST.
NOTE: The data set X.TEST has 2 observations and 5 variables.
NOTE: PROCEDURE COPY used:
      real time           1.52 seconds
      cpu time            0.04 seconds
      
NOTE: Copying WORK.TEST to Y.TEST (memtype=DATA).
NOTE: There were 2 observations read from the data set WORK.TEST.
NOTE: The data set Y.TEST has 2 observations and 5 variables.
NOTE: Copying WORK.FORMAT to Y.FORMAT (memtype=DATA).
NOTE: There were 3 observations read from the data set WORK.FORMAT.
NOTE: The data set Y.FORMAT has 3 observations and 21 variables.
NOTE: PROCEDURE COPY used:

R results:

> library(foreign)
> read.xport('test.xpt')
      RACE      AGE    D1        DT1    T1
1 2.000063 30.00000 15402 1330767062 40425
2 4.000063 31.00000 15494 1338716527 40453

Note the corruption of RACE (a variable having a SAS length of 3 bytes).

> read.xport('test2.xpt')
            RACE           AGE            D1           DT1            T1
1   2.000063e+00  3.000000e+01  1.540200e+04  1.330767e+09  4.042500e+04
2   4.000063e+00  3.100000e+01  1.549400e+04  1.338717e+09  4.045300e+04
3   3.687825e-40  3.687825e-40  3.687825e-40  3.687896e-40  5.962240e+20
...
124 3.835229e-93  6.434447e-86            NA  3.687825e-40  3.687825e-40

Note corrupted data when trying to read a SAS transport file containing more than one SAS dataset.  According to the documentation, read.xport is supposed to work in this case and is supposed to return a list of data frames.

> names(lookup.xport('test2.xpt'))
[1] "TEST"

Note the inclusion of only one of the 2 datasets.


Also I would greatly benefit from having lookup.xport return all of the SAS variable attributes, especially variable label and format name.  I could then write a little function for the community that makes read.xport as comprehensive as read.spss in terms of creating factor variables and variable labels, if the user exports the PROC CONTENTS CNTLOUT= dataset.

Thanks.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From fharrell@virginia.edu  Fri Dec 20 18:59:02 2002
From: fharrell@virginia.edu (fharrell@virginia.edu)
Date: Fri Dec 20 18:59:02 2002
Subject: [Rd] ace and avas in acepack (PR#2386)
Message-ID: <200212201759.SAA06861@pubhealth.ku.dk>

Under
            
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.1              
year     2002             
month    11               
day      01               
language R                

and using acepack 1.3-2, ace() and avas() have checks such as 
            if(circ[i] < 0 || circ[i] > nrow(x)) {
            if(mon[i] < 0 || mon[i] > nrow(x)) {
            if(lin[i] < 0 || lin[i] > nrow(x)) {

etc.  I believe that nrow should be ncol.

Also, in ace() there is the follwing check:

            if (cat[i] == 0) {
                cat("response spec can only be lin or ordered (default)")
                return()
            }
whereas I believe that the ace algorithm does allow for categorical response variables.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From pd@pubhealth.ku.dk  Sat Dec 21 07:15:05 2002
From: pd@pubhealth.ku.dk (Peter Dalgaard BSA)
Date: Sat Dec 21 07:15:05 2002
Subject: [Rd] Bug list summary (automatic post)
Message-ID: <200212210615.gBL6F5e7021923@blueberry.kubism.ku.dk>

=================================================
This is an automated summary of the status of the R-bugs
repository.

Note that this may be neither complete nor perfectly
correct at any given instance: Not all bugs are reported,
and some reported bugs may have been fixed, but the
repository not yet updated.

Some bug fixes are difficult to verify because they pertain
to specific hardware or operating system versions. If you
have information to contribute, please do so.

If you happen to know how to fix a problem please send
patches to the bug repository, too.

New bugs are reported either through the web
interface at r-bugs.r-project.org or via email to
r-bugs@r-project.org. The bug.report() function can be
used to automate parts of the procedure on many systems.
Followups on older bugs can be done by including the string
"(PR#999)" in the Subject of an email (change 999 to the
actual reference number, of course!).
=================================================

Directory:  Accuracy

* PR# 1228 *
Subject: bug with var(rep(1e30, 3))
From: Emmanuel Paradis <paradis@isem.univ-montp2.fr>
Date: Wed, 26 Dec 2001 13:03:31 +0100
* PR# 1664 *
Subject: Bug in rnorm.
From: Rolf Turner <rolf@math.unb.ca>
Date: Thu, 13 Jun 2002 16:35:59 -0300 (ADT)
..Strange interaction between "Marsaglia-Multicarry" generator and
.."Kinderman-Ramage" 
..method for normal variates. Apparently, switching either of them will help.
* PR# 2214 *
Subject: qgamma precision
From: terra@diku.dk
Date: Fri, 25 Oct 2002 16:50:17 +0200 (MET DST)

Directory:  Add-ons

* PR# 974 *
Subject: Lattice: panel.superpose with ordered factor groups
From: John Maindonald <john.maindonald@anu.edu.au>
Date: Sat, 9 Jun 2001 11:08:51 +1000 (EST)
..The warning is standard S and R behaviour.
..Probably xyplot needs to avoid it (by unclassing?)
..Still there in lattice 0.3-0.
* PR# 1044 *
Subject: Polymarsall.c
From: pleu@hotmail.com
Date: Tue, 7 Aug 2001 22:42:07 +0200 (MET DST)
* PR# 1178 *
Subject: segfault using svm from e1071
From: Jan Rychter <jan@rychter.com>
Date: Tue, 20 Nov 2001 23:38:17 +0100
* PR# 1199 *
Subject: pixmap: infinite recursion with nonascii pnm-files
From: thomas.baumann@ch.tum.de
Date: Fri, 7 Dec 2001 11:07:52 +0100 (CET)
* PR# 1361 *
Subject: Matrix identification bug
From: hyu@stats.uwo.ca
Date: Tue, 5 Mar 2002 21:19:46 +0100 (MET)
..seems to be about Matrix package, not solve
* PR# 1662 *
Subject: fisher.test FEXACT memory bug "should not occur"
From: Martin Maechler <maechler@stat.math.ethz.ch>
Date: Thu, 13 Jun 2002 08:21:50 +0200
..The supplementary (table of sum one) is fixed for 1.5.1.
..Detection code for the first problem has been added to 1.5.1 which will stop
..the crash, but the underlying cause is still open.
* PR# 1716 *
Subject: rdiscrete in e1071 fails when n==1
From: "John Aitchison" <jaitchis@hwy.com.au>
Date: Fri, 28 Jun 2002 10:28:17 +1000
* PR# 1729 *
Subject: problem with qq( )
From: Jarno.Tuimala@Helsinki.Fi
Date: Tue, 2 Jul 2002 10:37:10 +0200 (MET DST)
..A report on lattice
* PR# 1741 *
Subject: groupedData constructor from a function
From: dieter.menne@menne-biomed.de
Date: Thu, 4 Jul 2002 15:59:59 +0200 (MET DST)
* PR# 1745 *
Subject: nlme: failed augPred with NA in an unused column
From: dieter.menne@menne-biomed.de
Date: Fri, 5 Jul 2002 08:32:32 +0200 (MET DST)
..nlme needs an update as suggested in the followup
* PR# 1901 *
Subject: svm seg faults
From: stefan.boehringer+science@uni-bochum.de
Date: Tue, 13 Aug 2002 14:12:17 +0200 (MET DST)
..Seem to be due to gcc `2.96' from RH7.3
* PR# 1974 *
Subject: Rwave installation problem
From: ld-temp-qt3i@pobox.com
Date: Mon, 2 Sep 2002 09:27:36 +0200 (MET DST)
..Instead, this should use ISO C headers, namely <stdlib.h>
* PR# 2173 *
Subject: xlim in plot.survfit() [with a discussion on "..."]
From: jerome@hivnet.ubc.ca
Date: Wed, 16 Oct 2002 18:46:11 +0200 (MET DST)
* PR# 2252 *
Subject: Ansari-Bradley test
From: wex00002@uconn.edu
Date: Sun, 3 Nov 2002 23:38:20 +0100 (MET)
* PR# 2302 *
Subject: Package tseries: crash for Windows version
From: Fan <xiao.gang.fan1@libertysurf.fr>
Date: Sun, 17 Nov 2002 15:28:14 +0100
..Actually, there is a mismatch between the R call and the 
..C code in pred_garch, so this is not Windows-specific.
* PR# 2320 *
Subject: Segmentation fault using "survival" package
From: jerome@hivnet.ubc.ca
Date: Sat, 23 Nov 2002 00:51:50 +0100 (MET)
* PR# 2322 *
Subject: simplex
From: george@lecompte.org
Date: Sat, 23 Nov 2002 17:30:37 +0100 (MET)
..report on boot, I think (not mentioned, though)
* PR# 2349 *
Subject: [R] NA in first panel of xyplot causes error
From: Wolfram Fischer <wolfram@fischer-zim.ch>
Date: Thu, 5 Dec 2002 15:32:32 +0100
..Lattice
* PR# 2352 *
Subject: avas: segmentation fault on empty args
From: vograno@arbitrade.com
Date: Fri, 6 Dec 2002 19:41:48 +0100 (MET)
* PR# 2363 *
Subject: nlme() and parameters "model", "fixed" and "random"
From: jerome@hivnet.ubc.ca
Date: Wed, 11 Dec 2002 22:29:47 +0100 (MET)
* PR# 2369 *
Subject: convergence problem with nlme()
From: jerome@hivnet.ubc.ca
Date: Thu, 12 Dec 2002 23:43:14 +0100 (MET)
* PR# 2374 *
Subject: quantreg package - predict method for rq objects
From: John Maindonald <u9801539@leonard.anu.edu.au>
Date: Sat, 14 Dec 2002 20:46:34 +1100 (EST)

Directory:  Analyses

none

Directory:  Documentation

* PR# 988 *
Subject: input for R-intro
From: "Paul E. Johnson" <pauljohn@ku.edu>
Date: Mon, 18 Jun 2001 13:57:10 -0500
* PR# 1011 *
Subject: R-intro suggestions part II
From: "Paul E. Johnson" <pauljohn@ukans.edu>
Date: Tue, 03 Jul 2001 15:50:06 -0500
* PR# 1136 *
Subject: cex/col/etc. in title(): documentation?
From: Ben Bolker <ben@zoo.ufl.edu>
Date: Mon, 22 Oct 2001 11:55:14 -0400 (EDT)
..MM:actually the documentation still could elaborate a bit..
* PR# 1772 *
Subject: bug(?) in R FAQ - Should I run R from within Emacs?
From: Tim.Harrold@csiro.au
Date: Thu, 11 Jul 2002 18:21:42 +1000

Directory:  Graphics

* PR# 202 *
Subject: persp box occlusion bug
From: wsi@gcal.ac.uk
Date: Wed, 2 Jun 1999 15:02:03 +0200 (MET DST)
..The persp algorithm does not apply the occlusion rules to the frame, 
..which is always plotted first. 
..A bug, but not very simple to fix.
* PR# 660 *
Subject: identify.default ignores any setting of cex.
From: Prof Brian Ripley <ripley@stats.ox.ac.uk>
Date: Fri, 15 Sep 2000 10:23:39 +0100 (BST)
* PR# 776 *
Subject: strwidth does not take font into account
From: Martyn Plummer <plummer@iarc.fr>
Date: Tue, 19 Dec 2000 14:56:01 +0100 (CET)
..This needs a substantial redesign.
* PR# 791 *
Subject:  par(lab= *) / axis(*) bug 
From: maechler@stat.math.ethz.ch
Date: Fri, 22 Dec 2000 10:59:26 +0100
* PR# 816 *
Subject: dotplot: character size of labels
From: RINNER Heinrich <H.RINNER@TIROL.GV.AT>
Date: Thu, 18 Jan 2001 14:54:32 +0100
..Suggested fix is incorporated in 1.2.2.
..
..There is a deeper problem:  mtext() ignores par(cex=.5) in general.  
..To see the problem try:  par(cex=.5); mtext("hi")
..Paul thinks the right fix is to change the argument list for mtext so that
..cex=par(cex) by default rather than cex=NA by default (plus corresponding
..internal changes to  do_mtext in plot.c).
..This needs to be done very carefully because (i) the change suggested above 
..mayhave side-effects in many other pieces of interpreted code 
..(ii) do_mtext ignores dd->gp.cexbase unlike, for example, do_plot_xy 
..and anything to do with cexbase needs extreme care.
* PR# 820 *
Subject: interaction.plot
From: "Mark M. Span" <span@psy.uva.nl>
Date: Mon, 22 Jan 2001 10:47:39 +0100
..mtext is unscaled by default.  It is not clear if this should
..use the par("cex") setting or an inline cex setting such as cex.axis.
..It might make more sense to use axis rather than mtext, as boxplot does.
* PR# 831 *
Subject: screen can't go back to (split) screen with log="y" plot
From: Thomas Vogels <tov@ece.cmu.edu>
Date: 30 Jan 2001 00:39:41 -0500
..Still there. Suggested fix included in followups, but we didn't get around to
..try it in time for 1.2.3.
..
..Fix doesn't work. One problem is that the opar<-par();par(opar) idiom updates
..xaxp before xlog, and the new value of xaxp may only be valid under the new
..value of xlog.
* PR# 837 *
Subject: screen doesn't handle redrawing properly
From: Thomas Vogels <tov@ece.cmu.edu>
Date: 01 Feb 2001 14:20:52 -0500
* PR# 887 *
Subject: axis(adj=anything) has no effect
From: jhallman@frb.gov
Date: Wed, 28 Mar 2001 20:51:05 +0200 (MET DST)
* PR# 943 *
Subject: legend() with xpd=T; omission of initial plot character
From: John Maindonald <john.maindonald@anu.edu.au>
Date: Sun, 20 May 2001 10:35:16 +1000
* PR# 997 *
Subject:  las=1 with log axis 
From: Peter Dalgaard BSA <pd@pubhealth.ku.dk>
Date: Wed, 27 Jun 2001 11:54:06 +0200
* PR# 1045 *
Subject: Palette changes on redraw
From: Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk>
Date: 08 Aug 2001 19:08:01 +0200
* PR# 1147 *
Subject: postscript problem
From: kjetil halvorsen <kjetilh@umsanet.edu.bo>
Date: Fri, 26 Oct 2001 15:23:45 -0400
..This seems to be a problem with screen/layout rather than postscript.
* PR# 1161 *
Subject: x-axis label in persp()
From: Rolf Turner <rolf@maths.uwa.edu.au>
Date: Wed, 7 Nov 2001 18:07:22 +0800 (WST)
* PR# 1207 *
Subject: boxplot labels incorrect when horizontal = TRUE
From: Rashid Nassar <rnassar@duke.edu>
Date: Sun, 9 Dec 2001 21:46:32 -0500 (EST)
* PR# 1235 *
Subject: Axes labelling with logarithmic scales
From: tobias.hoevekamp@ilw.agrl.ethz.ch
Date: Thu, 3 Jan 2002 15:29:02 +0100 (MET)
* PR# 1300 *
Subject: FW: layout and piechart diameter problem
From: "Warnes, Gregory R" <gregory_r_warnes@groton.pfizer.com>
Date: Thu, 7 Feb 2002 11:05:15 -0500 
* PR# 1305 *
Subject: interaction.plot (with misplaced legend)
From: Uwe Ligges <ligges@statistik.uni-dortmund.de>
Date: Fri, 08 Feb 2002 14:27:01 +0100
* PR# 1395 *
Subject: mgp parameter in par()
From: mh.smith@niwa.cri.nz
Date: Tue, 19 Mar 2002 06:11:49 +0100 (MET)
* PR# 1470 *
Subject: color of axis lines
From: gray@jimmy.harvard.edu
Date: Sat, 20 Apr 2002 22:21:44 +0200 (MET DST)
* PR# 1476 *
Subject: Bug: persp and colors
From: oliver.niggemann@acterna.com
Date: Tue, 23 Apr 2002 09:41:37 +0200 (MET DST)
* PR# 1505 *
Subject: pictex 
From: luchini@ehess.cnrs-mrs.fr
Date: Thu, 2 May 2002 12:23:21 +0200 (MET DST)
* PR# 1653 *
Subject: coplot behaviour
From: "RenE J.V. Bertin" <rjvbertin@hotmail.com>
Date: Mon, 10 Jun 2002 20:11:02 +0200
* PR# 1654 *
Subject: R 1.5.0: axis() does not honor the xaxp argument
From: "Robert D. Merithew" <merithew@ccmr.cornell.edu>
Date: Tue, 11 Jun 2002 09:29:39 -0400 (EDT)
* PR# 1659 *
Subject:  mtext() alignment of perpendicular text 
From: p.murrell@auckland.ac.nz
Date: Wed, 12 Jun 2002 13:29:45 +1200 (NZST)
* PR# 1878 *
Subject: close.screen
From: Martin.Schlather@uni-bayreuth.de
Date: Mon, 5 Aug 2002 22:35:02 +0200 (MET DST)
* PR# 1899 *
Subject: interaction.plot() legend too narrow when mfcol > 2
From: Martin Maechler <maechler@stat.math.ethz.ch>
Date: Tue, 13 Aug 2002 09:36:15 +0200
* PR# 1933 *
Subject: dev2eps() prints ticks with wrong length!
From: Timur Elzhov <Timur.Elzhov@jinr.ru>
Date: Fri, 23 Aug 2002 17:22:15 +0400
..dev.copy problem
* PR# 1972 *
Subject: lattice install
From: robert.king@newcastle.edu.au
Date: Mon, 2 Sep 2002 04:55:41 +0200 (MET DST)
..Perhaps lattice should require(grid) and print a clearer message?
* PR# 2069 *
Subject: split.screen problem
From: cbodily@att.net
Date: Thu, 26 Sep 2002 19:37:40 +0200 (MET DST)
* PR# 2283 *
Subject: Wandering usr values in par(no.readonly=TRUW)
From: Jari Oksanen <jarioksa@sun3.oulu.fi>
Date: Tue, 12 Nov 2002 13:50:44 +0200

Directory:  In-Out

* PR# 1688 *
Subject: Maybe a problem in binary read/write
From: accot@free.fr
Date: Tue, 18 Jun 2002 22:51:17 +0200 (MET DST)
..I don't think file() is said to work with devices!

Directory:  Installation

* PR# 1222 *
Subject: configure: sed: Function s%@PDFLATEX@%/usr/local/bin/pdflatex%g
From: Peter Kleiweg <kleiweg@let.rug.nl>
Date: Thu, 20 Dec 2001 14:09:42 +0100 (CET)
..problem is on hppa2.0-hp-hpux10.20: may be HP-UX specific
* PR# 1268 *
Subject: Solaris 2.6 Compile
From: gm81640@development.nssmb.com
Date: Thu, 17 Jan 2002 06:28:26 +0100 (MET)
..Most likely a compiler installation problem
* PR# 1291 *
Subject: Installation problem : SunOS
From: brendan_mcmahon@prusec.com
Date: Thu, 31 Jan 2002 18:00:55 +0100 (MET)
..looks like gcc compiled under different OS version.
* PR# 1415 *
Subject: int 32 bit error on SPARC 64bit
From: kss28@mail.cba.nau.edu
Date: Mon, 25 Mar 2002 21:18:58 +0100 (MET)
..Was gcc 2.95.2 in private followup.
..Probably unappropriate flags
* PR# 1428 *
Subject: R compile on Solaris 8 fails
From: brower@bst.rochester.edu
Date: Mon, 1 Apr 2002 22:19:07 +0200 (MET DST)
..problems with g++ not finding -lstdc++
..Not a problem with R per se
* PR# 1500 *
Subject: configure script fails on comment in tkConfig.sh
From: Peter Kleiweg <kleiweg@let.rug.nl>
Date: Tue, 30 Apr 2002 16:41:51 +0200 (CEST)
..Looks like a conspiracy between a shell problem and an oddity in Tk 8.0 rather
..than an R problem. Good to know for the workaround though. The comment in
..TK_XINCLUDES has since disappeared, at least in Tk 8.3.3.
* PR# 1501 *
Subject: configure error: Maybe change CFLAGS or FFLAGS?
From: ale@ini.phys.ethz.ch
Date: Wed, 1 May 2002 15:23:14 +0200 (MET DST)
..Tried to use fort77 on RedHat, should likely try g77 instead.
* PR# 1658 *
Subject: make install fails - index.html not found
From: dhouston@bio.ri.ccf.org
Date: Tue, 11 Jun 2002 22:14:07 +0200 (MET DST)
..Missing perl??
* PR# 1676 *
Subject: R configure.in makes bad alpha assumptions
From: mcmahill@mtl.mit.edu
Date: Sat, 15 Jun 2002 19:21:09 -0400 (EDT)
..Probably fixed in 1.5.1
* PR# 1825 *
Subject: bug in R-1.5.1 for Mac OS X installer
From: Kow Kuroda <kkuroda@crl.ucsd.edu>
Date: Mon, 22 Jul 2002 16:40:26 -0700
..Darwin port
* PR# 1829 *
Subject: R config failure on solaris
From: "Siva Ginjupalli" <gsivrao@hotmail.com>
Date: Wed, 24 Jul 2002 20:08:49 +0000
..Missing info on R version and compilers.
* PR# 1937 *
Subject:  Inconsistent use of Perl? 
From: Berwin Turlach <berwin@maths.uwa.edu.au>
Date: Sat, 24 Aug 2002 18:41:09 +0800
..Some packages require Perl v 5.005
* PR# 1995 *
Subject:  2002-09-08 1.6.0 build fails in Recommended 
From: <stvjc@channing.harvard.edu>
Date: Sun, 8 Sep 2002 23:57:39 -0400 (EDT)
..I think this got cleared up...
* PR# 1996 *
Subject:  config checks for --with-gnome need update 
From: <stvjc@channing.harvard.edu>
Date: Mon, 9 Sep 2002 00:08:59 -0400 (EDT)

Directory:  Language

* PR# 408 *
Subject: convolution bug
From: wsimpson@gcal.ac.uk
Date: Fri, 28 Jan 2000 11:17:36 +0100 (MET)
* PR# 412 *
Subject: anomalies with call objects
From: Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk>
Date: 06 Feb 2000 01:18:50 +0100
* PR# 669 *
Subject: Bug(s) w/ rbind.data.frame(); fix also read.table(*, as.is = TRUE) ?
From: Martin Maechler <maechler@stat.math.ethz.ch>
Date: Mon, 25 Sep 2000 10:17:15 +0200
..status of AsIs columns
* PR# 1073 *
Subject: Wierd problem comparing numeric values and list using ==
From: "Warnes, Gregory R" <gregory_r_warnes@groton.pfizer.com>
Date: Fri, 24 Aug 2001 22:07:41 -0400
..see also PR#1075
* PR# 1076 *
Subject: Re: [Rd] Wierd problem comparing numeric values and list using == 
From: John Chambers <jmc@research.bell-labs.com>
Date: Mon, 27 Aug 2001 08:44:22 -0400
..part of PR#1073
* PR# 1186 *
Subject: a patch to tapply
From: Vadim Ogranovich <vograno@arbitrade.com>
Date: Thu, 29 Nov 2001 14:48:35 -0600
* PR# 1214 *
Subject: syntax questtion, maybe a bug
From: Rich Heiberger <rmh@surfer.sbm.temple.edu>
Date: Thu, 13 Dec 2001 13:46:54 -0500 (EST)
..Is .2logl meant to be a valid name in R? It is S
* PR# 1241 *
Subject:  Problem with "missing" in "local" 
From: J.C.Rougier@durham.ac.uk
Date: Fri, 4 Jan 2002 13:34:34 GMT
* PR# 1891 *
Subject: summary.data.frame with compound elements problem
From: b.rowlingson@lancaster.ac.uk
Date: Fri, 9 Aug 2002 10:35:43 +0200 (MET DST)

Directory:  Low-level

* PR# 989 *
Subject: "[.data.frame" allows un-named 3rd subscript
From: "Charles C. Berry" <cberry@tajo.ucsd.edu>
Date: Mon, 18 Jun 2001 13:13:46 -0700 (PDT)
* PR# 1068 *
Subject: Interrupts (was Re: [Rd] X11 protocol errors ...)
From: Luke Tierney <luke@nokomis.stat.umn.edu>
Date: Wed, 22 Aug 2001 19:32:51 -0500
..see also followup in PR#1069
* PR# 1069 *
Subject: Interrupts (was Re: [Rd] X11 protocol errors ...)
From: "John W. Eaton" <jwe@bevo.che.wisc.edu>
Date: Wed, 22 Aug 2001 21:56:33 -0500
..part of PR#1068
* PR# 1880 *
Subject:  You requested this report 
From: Berwin Turlach <berwin@maths.uwa.edu.au>
Date: Tue, 6 Aug 2002 16:57:54 +0800
..The bug is that we get as far as mkCLOSXP before an error is reported
* PR# 2253 *
Subject: [R] CTRL-C suspends echo of shell (R versions 1.6.0 and 1.6.1)
From: Wolfram Fischer - Z/I/M <wolfram@fischer-zim.ch>
Date: Mon, 4 Nov 2002 10:18:48 +0100

Directory:  Macintosh

* PR# 1819 *
Subject: Date arithmetic fails
From: RML27@cornell.edu
Date: Sun, 21 Jul 2002 20:26:12 +0200 (MET DST)
..In fact, as.POSIXct is off by 66 years. See
..   http://developer.apple.com/qa/ops/ops23.html
..This is semifixed, but timezones still don't work
* PR# 1991 *
Subject: Mac Save As... bug
From: Tim Cole <tjc1@cam.ac.uk>
Date: Sun, 8 Sep 2002 13:47:00 +0100
* PR# 2276 *
Subject: Mac specific - quartz leads to crash
From: h95mr@mun.ca
Date: Fri, 8 Nov 2002 16:28:50 +0100 (MET)

Directory:  Misc

* PR# 1126 *
Subject: R-bug report www page whishlist
From: jens.lund@nordea.com
Date: Wed, 10 Oct 2001 18:24:29 +0200 (MET DST)
* PR# 1158 *
Subject: bug.report()sends empty message
From: Paul Gilbert <pgilbert@bank-banque-canada.ca>
Date: Mon, 05 Nov 2001 10:05:27 -0500
* PR# 1503 *
Subject: R-GNOME
From: Patrick Gonin <gonin@genethon.fr>
Date: Thu, 2 May 2002 09:29:07 +0200
..1) is not a bug, as jpeg etc work.  capabilities() has been changed for 1.5.1
..2) system() needs a new version for GNOME.

Directory:  Models

* PR# 1861 *
Subject: update() can not find objects
From: yzhou@arcturusag.com
Date: Thu, 1 Aug 2002 19:01:59 +0200 (MET DST)
..The problem is actually deeper than this.
..
..Sometime update() wants to evaluate arguments in the environment where the model
..was defined, as here. 
..
..Sometimes it wants to use the current environment, eg this snippet from MASS 
..ph.fun <- function(data, i) {
..  d <- data
..  d$calls <- d$fitted + d$res[i]
..  coef(update(fit, data=d))
..}
* PR# 2206 *
Subject: model.matrix (via predict)
From: Glenn.Stone@csiro.au
Date: Thu, 24 Oct 2002 06:33:02 +0200 (MET DST)
..strange model used!

Directory:  Startup

none

Directory:  System-specific

* PR# 848 *
Subject: X11 device doesn't handle destroy events correcly
From: Thomas Vogels <tov@ece.cmu.edu>
Date: 13 Feb 2001 17:40:46 -0500
* PR# 1020 *
Subject: .Call and Mandrake 8.0
From: lcottret@yahoo.fr
Date: Wed, 11 Jul 2001 15:34:23 +0200 (MET DST)
..problem with symbol names only on Mandrake 8.0, not 7.2
..needs reply to follow-up
* PR# 1097 *
Subject: R 1.3.1 fails 'make check' on arm in the Bessel example
From: Dirk Eddelbuettel <edd@debian.org>
Date: Thu, 20 Sep 2001 23:54:19 -0500
..This platform turned out to have badly broken FPU behaviour. Given up, at 
..least for now .
* PR# 1140 *
Subject: Possible bug, Rprof() and scan(pipe())
From: Don MacQueen <macq@llnl.gov>
Date: Tue, 23 Oct 2001 13:50:26 -0700
..MacOS X: Doesn't happen on Solaris or Linux
* PR# 1145 *
Subject: Problem testing R version 1.3.1 on SGI Irix
From: Gordon Lack <gml4410@ggr.co.uk>
Date: Fri, 26 Oct 2001 19:04:04 +0100
..error from using SGI libblas (not reported on other systems?)
..use --without-blas
* PR# 1261 *
Subject: R_140 AND RHL_72 AND Packages
From: Patrick Gonin <gonin@genethon.fr>
Date: Wed, 15 Jan 2003 13:25:17 +0100
..Seems to relate to RH7.2 rpms
* PR# 1272 *
Subject: eigen segfault with GCC 3 on Solaris
From: Paul Gilbert <pgilbert@bank-banque-canada.ca>
Date: Thu, 17 Jan 2002 15:14:33 -0500
..Seems to be a problem with g77 in gcc 3.0.2 on Solaris only.
..Probably a compiler bug
* PR# 1275 *
Subject: compile problem with bessel_i.c on IRIX64 flexor 6.5 10100655 IP35 (uname -a)
From: Walter Tautz <wtautz@math.uwaterloo.ca>
Date: Tue, 22 Jan 2002 10:05:20 -0500 (EST)
* PR# 1289 *
Subject: R 1.4.0 build fails on AIX
From: lio@hpss1.ccs.ornl.gov
Date: Wed, 30 Jan 2002 14:10:30 +0100 (MET)
* PR# 1316 *
Subject: shared libraries on AIX
From: lio@hpss1.ccs.ornl.gov
Date: Mon, 18 Feb 2002 18:53:41 +0100 (MET)
* PR# 1461 *
Subject: make check fails d-p-q-r-tests.R - OpenBSD 3.0
From: Jason Turner <jasont@indigoindustrial.co.nz>
Date: Mon, 15 Apr 2002 10:13:36 +0000
* PR# 1606 *
Subject: hitting ^C breaks readline history
From: Cyril Humbert <humbertc@univ-mlv.fr>
Date: Tue, 28 May 2002 12:07:07 +0200 (MET DST)
* PR# 2144 *
Subject: Save() with ascii=TRUE may corrupt numeric values
From: "Efthymiou, Nick" <Nick.Efthymiou@schwab.com>
Date: Thu, 10 Oct 2002 14:09:21 -0700
..Only on systems without vsnprintf

Directory:  TooMuchAtOnce

none

Directory:  Windows

* PR# 1711 *
Subject: GUI bug
From: socrates@mail.ru
Date: Thu, 27 Jun 2002 10:30:51 +0200 (MET DST)
..A crash that is *very* hard to trigger (after several
..minutes of continuous resizing)

Directory:  incoming

* PR# 1556 *
Subject: lib.fixup, .GlobalEnv, and R1.5.0
From: mark.bravington@csiro.au
Date: Wed, 15 May 2002 08:30:50 +0200 (MET DST)
* PR# 2094 *
Subject: Mean and var inconsistency
From: Kevin.Wright@pioneer.com
Date: Wed, 2 Oct 2002 16:19:27 +0200 (MET DST)
* PR# 2365 *
Subject: R-intro: Simple manipulations/Vectors and assignment
From: nvj@fys.ku.dk
Date: Thu, 12 Dec 2002 00:17:26 +0100 (MET)
* PR# 2366 *
Subject: R -g gnome has graphics bugs
From: chris-public@math.uu.se
Date: Thu, 12 Dec 2002 14:19:43 +0100 (MET)
* PR# 2384 *
Subject: degrees of freedom in nlme()
From: jerome@hivnet.ubc.ca
Date: Fri, 20 Dec 2002 01:40:06 +0100 (MET)
* PR# 2385 *
Subject: read.xport and lookup.xport in foreign
From: Frank E Harrell Jr <fharrell@virginia.edu>
Date: Fri, 20 Dec 2002 12:47:58 -0500
* PR# 2386 *
Subject: ace and avas in acepack
From: Frank E Harrell Jr <fharrell@virginia.edu>
Date: Fri, 20 Dec 2002 12:59:07 -0500
* PR# 2387 *
Subject: ¯Â°Ó·~¿ì¤½«Ç¥X¯²
From: bhc5_2gk1525@adidas.de
Date: Sat, 21 Dec 2002 01:51:21 +0100 (MET)


From p.dalgaard@biostat.ku.dk  Sun Dec 22 01:09:02 2002
From: p.dalgaard@biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun Dec 22 01:09:02 2002
Subject: [Rd] read.xport and lookup.xport in foreign (PR#2385)
In-Reply-To: <200212201748.SAA06803@pubhealth.ku.dk>
References: <200212201748.SAA06803@pubhealth.ku.dk>
Message-ID: <x2isxmc3tf.fsf@biostat.ku.dk>

fharrell@virginia.edu writes:

[How to create an xpt file that R cannot read...]
> Also I would greatly benefit from having lookup.xport return all of
> the SAS variable attributes, especially variable label and format
> name. I could then write a little function for the community that
> makes read.xport as comprehensive as read.spss in terms of creating
> factor variables and variable labels, if the user exports the PROC
> CONTENTS CNTLOUT= dataset.

If anyone is interested in trying to figure this stuff out, it would
be most welcome (information on the file format can be obtained via
the link http://www.wotsit.org/download.asp?f=sas). To save you the
trouble, here's the inverse of Frank's code, i.e., how to read the
stuff back into SAS:

libname x SASV5XPT "test.xpt";
libname y SASV5XPT "test2.xpt";
proc format cntlin=y.format;
proc contents data=x.test;
proc contents data=y.test;
proc contents data=y.format;
proc print data=x.test;
proc print data=y.test;
proc print data=y.format;

Notice in particular that nothing works without the proc format line,
SAS can't read test.xpt without somehow being told what the RACE
format is. One possibly relevant oddity is that SAS seems to claim
that RACE has length 4, not 3, in the contents listing.

(Of course, if you haven't already realized: Once we know how to
extract SAS format names and interpret user-supplied formats, people
are going to want us to be able to interpret standard formats like
DATETIME. as well....)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907


From janice_kendall@emaildelvery.org  Sun Dec 22 23:25:03 2002
From: janice_kendall@emaildelvery.org (janice_kendall@emaildelvery.org)
Date: Sun Dec 22 23:25:03 2002
Subject: [Rd] Tired throwing money on DVDs?  Then you might want to take a look (PR#2390)
Message-ID: <200212222225.XAA12838@pubhealth.ku.dk>

------=_NextPart_19596_3265_3742.26A1780215A5
Content-Type: text/html; 
	charset="us-ascii"
Content-Transfer-Encoding: 8bit


<body bgcolor="#FFFFFF">
<p><b>USE YOUR HOME COMPUTER TO COPY ANY DVD MOVIE! </b></p>
<p><b>With our revolutionary software you can copy virtually any DVD Movie using 
  your existing equipment! Conventional DVD copying equipment can cost thousands 
  of $$ </b></p>
<p><b>Our CopyDVD Software cost only $19.95! <a href="http://www.copydvd.net%20">http://www.copydvd.net 
  </a></b></p>
<p><b>Also it will CONVERT VHS INTO DVD! </b></p>
<p><b>Why pay for a copy of a movie on DVD that you already own of VHS??? Also 
  not all movies on VHS are available on DVD. </b></p>
<p><b>So MAKE Them into a DVD yourself!!   </b></p>
<p><b>Copy DVD Movies And Create Your Own Personal Collection! </b></p>
<p><b>Convert VHS and Camcorder Movies into DVD Movies! </b></p>
<p><b>Order NOW and Take Advantage Of This Limited Time Offer! Get your PlayStation& 
  Dreamcast Software Copier For FREE! </b></p>
<p><b>Please Visit us at <a href="http://www.copydvd.net%20">http://www.copydvd.net 
  </a></b></p>
<p>&nbsp;</p>
<p><b>To be optout from our future mailing please email optout@emaildelvery.org 
  </b></p>
<p><b>You can also opt out by mail; Please send your request to: </b></p>
<p><b>11314 Ventura Blvd Suite #141 Studio City, CA 91604 </b></p>
<p><b>Or by Phone (213) 216 8305 </b></p>


------=_NextPart_19596_3265_3742.26A1780215A5--


From olefc@birc.dk  Wed Dec 25 13:05:02 2002
From: olefc@birc.dk (olefc@birc.dk)
Date: Wed Dec 25 13:05:02 2002
Subject: [Rd] inv.logit (package boot) (PR#2394)
Message-ID: <200212251205.NAA19295@pubhealth.ku.dk>

Full_Name: Ole Christensen
Version: 1.6.1
OS: linux-gnu

Submission from: (NULL) (130.225.18.176)


In package boot :

> inv.logit(800)
[1] NaN

where it should have been 1.


The problem is caused by exp(x) returning Inf when x is large.

One way of fixing the problem [there may be better ways] would be to include the
line 

out[x > 709] <- 1

in inv.logit()



Cheers Ole




> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.1
year     2002
month    11
day      01
language R


From p.dalgaard@biostat.ku.dk  Wed Dec 25 18:10:03 2002
From: p.dalgaard@biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Dec 25 18:10:03 2002
Subject: [Rd] inv.logit (package boot) (PR#2394)
In-Reply-To: <200212251205.NAA19295@pubhealth.ku.dk>
References: <200212251205.NAA19295@pubhealth.ku.dk>
Message-ID: <x2k7hy9g92.fsf@biostat.ku.dk>

olefc@birc.dk writes:

> The problem is caused by exp(x) returning Inf when x is large.
> 
> One way of fixing the problem [there may be better ways] would be to include the
> line 
> 
> out[x > 709] <- 1
> 
> in inv.logit()

Yes, or replace the entire code with something like

  inv.logit2 <- function(x) ifelse(x > 0, 1 - 1/(1+exp(x)), 1/(1+exp(-x)))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907


From gb@stat.umu.se  Thu Dec 26 01:18:02 2002
From: gb@stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu Dec 26 01:18:02 2002
Subject: [Rd] inv.logit (package boot) (PR#2394)
In-Reply-To: <x2k7hy9g92.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0212260113170.15690-100000@tal.stat.umu.se>

On 25 Dec 2002, Peter Dalgaard BSA wrote:

> olefc@birc.dk writes:
>
> > The problem is caused by exp(x) returning Inf when x is large.
> >
> > One way of fixing the problem [there may be better ways] would be to include the
> > line
> >
> > out[x > 709] <- 1
> >
> > in inv.logit()
>
> Yes, or replace the entire code with something like
>
>   inv.logit2 <- function(x) ifelse(x > 0, 1 - 1/(1+exp(x)), 1/(1+exp(-x)))

Or use 'plogis(x)', eventually with 'lower.tail = ...' ...

>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

---
 Göran Broström                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Umeå University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Umeå, Sweden             e-mail: gb@stat.umu.se


From maechler@stat.math.ethz.ch  Thu Dec 26 11:39:02 2002
From: maechler@stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Thu Dec 26 11:39:02 2002
Subject: [Rd] inv.logit (package boot) (PR#2394)
Message-ID: <200212261038.LAA20802@pubhealth.ku.dk>

>>>>> "GB" == Göran Broström <gb@stat.umu.se>
>>>>>     on Thu, 26 Dec 2002 01:17:21 +0100 (CET) writes:

    GB> On 25 Dec 2002, Peter Dalgaard BSA wrote:
    >> olefc@birc.dk writes:
    >> 
    >> > The problem is caused by exp(x) returning Inf when x is
    >> large.
    >> >
    >> > One way of fixing the problem [there may be better
    >> ways] would be to include the > line
    >> >
    >> > out[x > 709] <- 1
    >> >
    >> > in inv.logit()
    >> 
    >> Yes, or replace the entire code with something like
    >> 
    >> inv.logit2 <- function(x) ifelse(x > 0, 1 - 1/(1+exp(x)),
    >> 1/(1+exp(-x)))

    GB> Or use 'plogis(x)', eventually with 'lower.tail = ...'
    GB> ...

yes, really!

inv.logit() should never have made its way into the boot
package at all I think.
I mean neither in tto the S-plus "library".  plogis() has bveen
part of S since ages AFAIK.


Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From beebe@math.utah.edu  Thu Dec 26 17:40:03 2002
From: beebe@math.utah.edu (beebe@math.utah.edu)
Date: Thu Dec 26 17:40:03 2002
Subject: [Rd] R-1.6.2beta_2002-12-20: build problems (PR#2395)
Message-ID: <200212261639.RAA21247@pubhealth.ku.dk>

While builds and validations of R-1.6.2beta_2002-12-20 were
successful on several systems, there were a few failures:

------------------------------------------------------------------------
Apple Darwin 6.2 (MacOS 10.2.2) with gcc-3.2.1:

gcc -dynamiclib -flat_namespace -undefined suppress -o
.libs/libgslcblas.0.0.0.dylib  sasum.lo saxpy.lo ... isamax.lo izamax.lo xerbla.lo  -lc -install_name  /usr/local/lib/libgslcblas.0.dylib -compatibility_version 1 -current_version 1.0
gcc: suppress: No such file or directory
gcc: /usr/local/lib/libgslcblas.0.dylib: No such file or directory
gcc: 1: No such file or directory
gcc: 1.0: No such file or directory
gcc: unrecognized option `-compatibility_version'
gcc: unrecognized option `-current_version'

------------------------------------------------------------------------
Sun Solaris 2.7 and 2.8 with gcc-2.95.3:

gcc -shared  sasum.lo ... xerbla.lo  -L/usr/local/lib -lm -lc -Wl,-rpath -Wl,-soname -Wl,libgslcblas.so.0 -o .libs/libgslcblas.so.0.0.0

/usr/local/sparc-sun-solaris2.7/bin/ld: cannot open libgslcblas.so.0: No such file or directory
collect2: ld returned 1 exit status
make[2]: *** [libgslcblas.la] Error 1

I tried a restart with a newer version of libtool, that failed as
well:

make LIBTOOL=/usr/local/bin/libtool
/usr/ccs/bin/ld -G -h libgslcblas.so.0 -o .libs/libgslcblas.so.0.0.0 sasum.lo ... xerbla.lo  -L/usr/local/lib -lm -lc  -rpath

ld: fatal: option -dn and -h are incompatible
ld: fatal: option -dn and -P are incompatible
ld: fatal: option -dn and -G are incompatible
ld: fatal: Flags processing errors
------------------------------------------------------------------------
Compaq Alpha OSF/1 5.1:

The herm tests all fail (gcc 2.9-gnupro-99r1), but that
is from a known gcc code-generation error.  However, I
also got this failure:

gcc -DHAVE_CONFIG_H -I. -I. -I.. -I..    -mieee -mfp-rounding-mode=d -g -O2 -c test_rotg.c
mips-tfile, /tmp/cc0u7O0L.s:8107 Invalid .stabs/.stabn directive, value not found
line:	 #.stabs "c_expected:V12",38,0,120,$LC46

If I use "make -i check", then the tests proceed, and
and I get 53716 passes.
------------------------------------------------------------------------

-------------------------------------------------------------------------------
- Nelson H. F. Beebe                    Tel: +1 801 581 5254                  -
- Center for Scientific Computing       FAX: +1 801 581 4148                  -
- University of Utah                    Internet e-mail: beebe@math.utah.edu  -
- Department of Mathematics, 110 LCB        beebe@acm.org  beebe@computer.org -
- 155 S 1400 E RM 233                       beebe@ieee.org                    -
- Salt Lake City, UT 84112-0090, USA    URL: http://www.math.utah.edu/~beebe  -
-------------------------------------------------------------------------------


From deleeuw@stat.ucla.edu  Thu Dec 26 18:31:02 2002
From: deleeuw@stat.ucla.edu (Jan de Leeuw)
Date: Thu Dec 26 18:31:02 2002
Subject: [Rd] R-1.6.2beta_2002-12-20: build problems (PR#2395)
In-Reply-To: <200212261639.RAA21247@pubhealth.ku.dk>
Message-ID: <B8102716-18F7-11D7-86C6-000393BB6D36@stat.ucla.edu>

I don't see this, but then again several strange things are going on  
here. The
R build is making a GSL version of BLAS in /usr/local/lib ? Also, for  
some
reason, gcc  does not properly recognize its flags.

Now this looks like a --without-blas build. I am using ATLAS from fink  
(somewhat
reluctantly, because I should be using BLAS from the vecLib framework),  
and this
may explain the difference.

I'll try --without-blas, but with ATLAS R-1.6.2beta_2002-12-25 builds  
fine. Also,
justbchechking for the gcc, I have

cabledoc107:Developer/R/R-1.6.2] deleeuw% gcc -v
Reading specs from /usr/libexec/gcc/darwin/ppc/3.1/specs
Thread model: posix
Apple Computer, Inc. GCC version 1173, based on gcc version 3.1  
20020420 (prerelease)


On Thursday, December 26, 2002, at 08:39 AM, beebe@math.utah.edu wrote:

> While builds and validations of R-1.6.2beta_2002-12-20 were
> successful on several systems, there were a few failures:
>
> ----------------------------------------------------------------------- 
> -
> Apple Darwin 6.2 (MacOS 10.2.2) with gcc-3.2.1:
>
> gcc -dynamiclib -flat_namespace -undefined suppress -o
> .libs/libgslcblas.0.0.0.dylib  sasum.lo saxpy.lo ... isamax.lo  
> izamax.lo xerbla.lo  -lc -install_name   
> /usr/local/lib/libgslcblas.0.dylib -compatibility_version 1  
> -current_version 1.0
> gcc: suppress: No such file or directory
> gcc: /usr/local/lib/libgslcblas.0.dylib: No such file or directory
> gcc: 1: No such file or directory
> gcc: 1.0: No such file or directory
> gcc: unrecognized option `-compatibility_version'
> gcc: unrecognized option `-current_version'
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------


From deleeuw@stat.ucla.edu  Thu Dec 26 18:37:03 2002
From: deleeuw@stat.ucla.edu (Jan de Leeuw)
Date: Thu Dec 26 18:37:03 2002
Subject: [Rd] R-1.6.2beta_2002-12-20: build problems (PR#2395)
In-Reply-To: <200212261639.RAA21247@pubhealth.ku.dk>
Message-ID: <8CD68339-18F8-11D7-86C6-000393BB6D36@stat.ucla.edu>

No, R builds also fine with the --without-blas flag. Did you use a
--with-blas=something flag ?

On Thursday, December 26, 2002, at 08:39 AM, beebe@math.utah.edu wrote:

> While builds and validations of R-1.6.2beta_2002-12-20 were
> successful on several systems, there were a few failures:
>
> ----------------------------------------------------------------------- 
> -
> Apple Darwin 6.2 (MacOS 10.2.2) with gcc-3.2.1:
>
> gcc -dynamiclib -flat_namespace -undefined suppress -o
> .libs/libgslcblas.0.0.0.dylib  sasum.lo saxpy.lo ... isamax.lo  
> izamax.lo xerbla.lo  -lc -install_name   
> /usr/local/lib/libgslcblas.0.dylib -compatibility_version 1  
> -current_version 1.0
> gcc: suppress: No such file or directory
> gcc: /usr/local/lib/libgslcblas.0.dylib: No such file or directory
> gcc: 1: No such file or directory
> gcc: 1.0: No such file or directory
> gcc: unrecognized option `-compatibility_version'
> gcc: unrecognized option `-current_version'
>
> ----------------------------------------------------------------------- 
> -
> Sun Solaris 2.7 and 2.8 with gcc-2.95.3:
>
> gcc -shared  sasum.lo ... xerbla.lo  -L/usr/local/lib -lm -lc  
> -Wl,-rpath -Wl,-soname -Wl,libgslcblas.so.0 -o  
> .libs/libgslcblas.so.0.0.0
>
> /usr/local/sparc-sun-solaris2.7/bin/ld: cannot open libgslcblas.so.0:  
> No such file or directory
> collect2: ld returned 1 exit status
> make[2]: *** [libgslcblas.la] Error 1
>
> I tried a restart with a newer version of libtool, that failed as
> well:
>
> make LIBTOOL=/usr/local/bin/libtool
> /usr/ccs/bin/ld -G -h libgslcblas.so.0 -o .libs/libgslcblas.so.0.0.0  
> sasum.lo ... xerbla.lo  -L/usr/local/lib -lm -lc  -rpath
>
> ld: fatal: option -dn and -h are incompatible
> ld: fatal: option -dn and -P are incompatible
> ld: fatal: option -dn and -G are incompatible
> ld: fatal: Flags processing errors
> ----------------------------------------------------------------------- 
> -
> Compaq Alpha OSF/1 5.1:
>
> The herm tests all fail (gcc 2.9-gnupro-99r1), but that
> is from a known gcc code-generation error.  However, I
> also got this failure:
>
> gcc -DHAVE_CONFIG_H -I. -I. -I.. -I..    -mieee -mfp-rounding-mode=d  
> -g -O2 -c test_rotg.c
> mips-tfile, /tmp/cc0u7O0L.s:8107 Invalid .stabs/.stabn directive,  
> value not found
> line:	 #.stabs "c_expected:V12",38,0,120,$LC46
>
> If I use "make -i check", then the tests proceed, and
> and I get 53716 passes.
> ----------------------------------------------------------------------- 
> -
>
> ----------------------------------------------------------------------- 
> --------
> - Nelson H. F. Beebe                    Tel: +1 801 581 5254            
>        -
> - Center for Scientific Computing       FAX: +1 801 581 4148            
>        -
> - University of Utah                    Internet e-mail:  
> beebe@math.utah.edu  -
> - Department of Mathematics, 110 LCB        beebe@acm.org   
> beebe@computer.org -
> - 155 S 1400 E RM 233                       beebe@ieee.org              
>        -
> - Salt Lake City, UT 84112-0090, USA    URL:  
> http://www.math.utah.edu/~beebe  -
> ----------------------------------------------------------------------- 
> --------
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------


From ripley@stats.ox.ac.uk  Thu Dec 26 19:01:02 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec 26 19:01:02 2002
Subject: [Rd] R-1.6.2beta_2002-12-20: build problems (PR#2395)
Message-ID: <200212261800.TAA21372@pubhealth.ku.dk>

On Thu, 26 Dec 2002, Jan de Leeuw wrote:

> No, R builds also fine with the --without-blas flag. Did you use a
> --with-blas=something flag ?

I don't think this is a report on R!  It seems to be about building
libgslcblas, and there are no routines sasum.? etc in the R sources.
Similarly, `make check' does not count passes, and on Solaris a command
like that is never generated by R's configure.


> On Thursday, December 26, 2002, at 08:39 AM, beebe@math.utah.edu wrote:
>
> > While builds and validations of R-1.6.2beta_2002-12-20 were
> > successful on several systems, there were a few failures:
> >
> > -----------------------------------------------------------------------
> > -
> > Apple Darwin 6.2 (MacOS 10.2.2) with gcc-3.2.1:
> >
> > gcc -dynamiclib -flat_namespace -undefined suppress -o
> > .libs/libgslcblas.0.0.0.dylib  sasum.lo saxpy.lo ... isamax.lo
> > izamax.lo xerbla.lo  -lc -install_name
> > /usr/local/lib/libgslcblas.0.dylib -compatibility_version 1
> > -current_version 1.0
> > gcc: suppress: No such file or directory
> > gcc: /usr/local/lib/libgslcblas.0.dylib: No such file or directory
> > gcc: 1: No such file or directory
> > gcc: 1.0: No such file or directory
> > gcc: unrecognized option `-compatibility_version'
> > gcc: unrecognized option `-current_version'
> >
> > -----------------------------------------------------------------------
> > -
> > Sun Solaris 2.7 and 2.8 with gcc-2.95.3:
> >
> > gcc -shared  sasum.lo ... xerbla.lo  -L/usr/local/lib -lm -lc
> > -Wl,-rpath -Wl,-soname -Wl,libgslcblas.so.0 -o
> > .libs/libgslcblas.so.0.0.0
> >
> > /usr/local/sparc-sun-solaris2.7/bin/ld: cannot open libgslcblas.so.0:
> > No such file or directory
> > collect2: ld returned 1 exit status
> > make[2]: *** [libgslcblas.la] Error 1
> >
> > I tried a restart with a newer version of libtool, that failed as
> > well:
> >
> > make LIBTOOL=/usr/local/bin/libtool
> > /usr/ccs/bin/ld -G -h libgslcblas.so.0 -o .libs/libgslcblas.so.0.0.0
> > sasum.lo ... xerbla.lo  -L/usr/local/lib -lm -lc  -rpath
> >
> > ld: fatal: option -dn and -h are incompatible
> > ld: fatal: option -dn and -P are incompatible
> > ld: fatal: option -dn and -G are incompatible
> > ld: fatal: Flags processing errors
> > -----------------------------------------------------------------------
> > -
> > Compaq Alpha OSF/1 5.1:
> >
> > The herm tests all fail (gcc 2.9-gnupro-99r1), but that
> > is from a known gcc code-generation error.  However, I
> > also got this failure:
> >
> > gcc -DHAVE_CONFIG_H -I. -I. -I.. -I..    -mieee -mfp-rounding-mode=d
> > -g -O2 -c test_rotg.c
> > mips-tfile, /tmp/cc0u7O0L.s:8107 Invalid .stabs/.stabn directive,
> > value not found
> > line:	 #.stabs "c_expected:V12",38,0,120,$LC46
> >
> > If I use "make -i check", then the tests proceed, and
> > and I get 53716 passes.
> > -----------------------------------------------------------------------
> > -
> >
> > -----------------------------------------------------------------------
> > --------
> > - Nelson H. F. Beebe                    Tel: +1 801 581 5254
> >        -
> > - Center for Scientific Computing       FAX: +1 801 581 4148
> >        -
> > - University of Utah                    Internet e-mail:
> > beebe@math.utah.edu  -
> > - Department of Mathematics, 110 LCB        beebe@acm.org
> > beebe@computer.org -
> > - 155 S 1400 E RM 233                       beebe@ieee.org
> >        -
> > - Salt Lake City, UT 84112-0090, USA    URL:
> > http://www.math.utah.edu/~beebe  -
> > -----------------------------------------------------------------------
> > --------
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> >
> >
> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> Editor: Journal of Multivariate Analysis, Journal of Statistical
> Software
> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
> homepage: http://gifi.stat.ucla.edu
>
> ------------------------------------------------------------------------
> -------------------------
>            No matter where you go, there you are. --- Buckaroo Banzai
>                     http://gifi.stat.ucla.edu/sounds/nomatter.au
>
> ------------------------------------------------------------------------
> -------------------------
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From deleeuw@stat.ucla.edu  Thu Dec 26 20:01:34 2002
From: deleeuw@stat.ucla.edu (Jan de Leeuw)
Date: Thu Dec 26 20:01:34 2002
Subject: [Rd] BLAS/Lapack on OS X
Message-ID: <4EC12574-1904-11D7-86C6-000393BB6D36@stat.ucla.edu>

R-devel has the --with-lapack flag for configure. If you build R with

--with-blas="-framework vecLib" --with-lapack="--framework vecLib"

then the build goes through, using the native optimized BLAS and
Lapack in /System/Library/Frameworks/vecLib.framework. Also, it
works, in the sense that it does eigenvalue problems correctly.

I don't have any timings yet, because I just upgraded to a new Mac,
but I'll post some soon.
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------


From deleeuw@stat.ucla.edu  Thu Dec 26 20:36:22 2002
From: deleeuw@stat.ucla.edu (Jan de Leeuw)
Date: Thu Dec 26 20:36:22 2002
Subject: [Rd] timings of BLAS/Lapack combos
Message-ID: <25C91A8E-1909-11D7-8DB8-000393BB6D36@stat.ucla.edu>

OS X 10.2.3, dual 1.25Ghz Tower, gcc/g77 3.1. Three versions
of BLAS/LAPACK on the included benchmark. First using
the BLAS and LAPACK that come with R (--without-blas flag
in configure), then using the ATLAS from fink and the Lapack
from R (no flag), then using the BLAS and ATLAS from the
vecLib framework. The first two use R-1.6.2beta, the third uses
R-devel.

Conclusions are clear. Obviously there is no difference for
the sort task. Using ATLAS does not do anything for eigen()
but vecLib SEEMS to make eigen() about 5 times faster. This
is just because eigen() in R-devel actually defaults to La.eigen().

Using ATLAS or vecLib makes La.eigen about 2.5 times faster,
compared to included BLAS. vecLib and ATLAS are comparable,
with possibly vecLib a few percentage points faster. In double
precision there does not seem to be much impact of the
optimized LAPACK in vecLib (but more comparisons are
needed).

Code

sink("timings.lis")
hilbert<-function(n) 1/(outer(seq(n),seq(n),"+")-1)
print("hilbert n=500")
print(system.time(eigen(hilbert(500))))
print(system.time(eigen(hilbert(500))))
print(system.time(eigen(hilbert(500))))
print("hilbert n=1000")
print(system.time(eigen(hilbert(1000))))
print(system.time(eigen(hilbert(1000))))
print(system.time(eigen(hilbert(1000))))
print("La.hilbert n=500")
print(system.time(La.eigen(hilbert(500))))
print(system.time(La.eigen(hilbert(500))))
print(system.time(La.eigen(hilbert(500))))
print("La.hilbert n=1000")
print(system.time(La.eigen(hilbert(1000))))
print(system.time(La.eigen(hilbert(1000))))
print(system.time(La.eigen(hilbert(1000))))
print("sort n=6")
print(system.time(sort(rnorm(10^6))))
print(system.time(sort(rnorm(10^6))))
print(system.time(sort(rnorm(10^6))))
print("sort n=7")
print(system.time(sort(rnorm(10^7))))
print(system.time(sort(rnorm(10^7))))
print(system.time(sort(rnorm(10^7))))

--without-blas

[1] "hilbert n=500"
[1] 4.75 0.00 4.84 0.00 0.00
[1] 4.01 0.00 3.99 0.00 0.00
[1] 4.09 0.00 4.06 0.00 0.00
[1] "hilbert n=1000"
[1] 44.19  0.00 44.24  0.00  0.00
[1] 42.03  0.00 42.15  0.00  0.00
[1] 41.80  0.00 43.41  0.00  0.00
[1] "La.hilbert n=500"
[1] 1.98 0.00 2.08 0.00 0.00
[1] 2.00 0.00 2.05 0.00 0.00
[1] 1.96 0.00 2.00 0.00 0.00
[1] "La.hilbert n=1000"
[1] 19.02  0.00 19.58  0.00  0.00
[1] 19.08  0.00 19.89  0.00  0.00
[1] 19.24  0.00 19.30  0.00  0.00
[1] "sort n=6"
[1] 2.04 0.00 2.04 0.00 0.00
[1] 1.92 0.00 1.95 0.00 0.00
[1] 1.88 0.00 2.04 0.00 0.00
[1] "sort n=7"
[1] 24.23  0.00 24.62  0.00  0.00
[1] 24.23  0.00 24.21  0.00  0.00
[1] 24.60  0.00 24.59  0.00  0.00

Using ATLAS

[1] "hilbert n=500"
[1] 4.52 0.00 4.54 0.00 0.00
[1] 4.24 0.00 4.25 0.00 0.00
[1] 4.28 0.00 4.37 0.00 0.00
[1] "hilbert n=1000"
[1] 44.24  0.00 45.32  0.00  0.00
[1] 44.28  0.00 46.84  0.00  0.00
[1] 45.58  0.00 46.69  0.00  0.00
[1] "La.hilbert n=500"
[1] 0.90 0.00 1.44 0.00 0.00
[1] 1.17 0.00 1.31 0.00 0.00
[1] 1.16 0.00 1.15 0.00 0.00
[1] "La.hilbert n=1000"
[1] 8.36 0.00 8.37 0.00 0.00
[1] 8.09 0.00 8.13 0.00 0.00
[1] 8.37 0.00 8.45 0.00 0.00
[1] "sort n=6"
[1] 1.91 0.00 2.46 0.00 0.00
[1] 2.04 0.00 2.12 0.00 0.00
[1] 2.16 0.00 2.08 0.00 0.00
[1] "sort n=7"
[1] 25.30  0.00 27.18  0.00  0.00
[1] 24.81  0.00 24.71  0.00  0.00
[1] 24.36  0.00 24.51  0.00  0.00

using vecLib

[1] "hilbert n=500"
[1] 1.71 0.00 1.68 0.00 0.00
[1] 1.41 0.00 1.31 0.00 0.00
[1] 1.25 0.00 1.16 0.00 0.00
[1] "hilbert n=1000"
[1] 8.59 0.00 7.86 0.00 0.00
[1] 7.68 0.00 7.21 0.00 0.00
[1] 7.85 0.00 7.18 0.00 0.00
[1] "La.hilbert n=500"
[1] 1.15 0.00 1.02 0.00 0.00
[1] 1.16 0.00 1.02 0.00 0.00
[1] 1.21 0.00 1.09 0.00 0.00
[1] "La.hilbert n=1000"
[1] 7.75 0.00 6.77 0.00 0.00
[1] 7.98 0.00 6.86 0.00 0.00
[1] 7.85 0.00 6.77 0.00 0.00
[1] "sort n=6"
[1] 2.06 0.00 2.10 0.00 0.00
[1] 2.08 0.00 2.06 0.00 0.00
[1] 2.04 0.00 2.05 0.00 0.00
[1] "sort n=7"
[1] 24.8  0.0 25.2  0.0  0.0
[1] 24.74  0.00 24.95  0.00  0.00
[1] 24.72  0.00 24.88  0.00  0.00

===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------


From ripley@stats.ox.ac.uk  Thu Dec 26 20:41:02 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec 26 20:41:02 2002
Subject: [Rd] BLAS/Lapack on OS X
In-Reply-To: <4EC12574-1904-11D7-86C6-000393BB6D36@stat.ucla.edu>
Message-ID: <Pine.LNX.4.31.0212261938480.30122-100000@gannet.stats>

On Thu, 26 Dec 2002, Jan de Leeuw wrote:

> R-devel has the --with-lapack flag for configure. If you build R with
>
> --with-blas="-framework vecLib" --with-lapack="--framework vecLib"
>
> then the build goes through, using the native optimized BLAS and
> Lapack in /System/Library/Frameworks/vecLib.framework. Also, it
> works, in the sense that it does eigenvalue problems correctly.

I hope

--with-blas="-framework vecLib" --with-lapack

is all that is needed.  --with-lapack searches the BLAS library for lapack
routines.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From nikko@hailmail.net  Fri Dec 27 03:33:02 2002
From: nikko@hailmail.net (Nicholas Lewin-Koh)
Date: Fri Dec 27 03:33:02 2002
Subject: [Rd] Ratfor->Fortran conversion
In-Reply-To: <Pine.LNX.4.31.0212261938480.30122-100000@gannet.stats>
References: <Pine.LNX.4.31.0212261938480.30122-100000@gannet.stats>
Message-ID: <1040957430.8104.5.camel@sta49.stat.nus.edu.sg>

Hi,
Does anyone have any experience porting Ratfor to fortran. I have gotten
the ratfor preprocessor working and if I compile the ratfor code
directly and dynamically load into R it seems to work (using g77 on RH
linux). However if I just use the ratfor command and try to compile the
output fortran file it does not compile. Is there some flags I should
use to get ratfor to format the fortran output better, or is there a
flag I need to set for g77 to get the output code to compile. Thanks

Nicholas


From Mark.Bravington@csiro.au  Fri Dec 27 04:18:03 2002
From: Mark.Bravington@csiro.au (Mark.Bravington@csiro.au)
Date: Fri Dec 27 04:18:03 2002
Subject: [Rd] parse and pushBack (PR#2396)
Message-ID: <200212270317.EAA22333@pubhealth.ku.dk>

Is this the last bug of the year? Well, it's the last one from me, anyway...

The "parse" function seems to give erratic behaviour when used in
conjunction with "pushBack" on an open connection (R1.6.1, Windows 2000).
Try this: 

> { cat( c( '1', 'a+b', '2'), file='r123.r', sep='\n');
tcon_ file( 'r123.r'); open( tcon); 
print( readLines( tcon, n=1)); 
pushBack( c( 'a+b'), tcon); 
print( parse( file=tcon, n=1));
print( readLines( tcon)); close( tcon); unlink( 'r123.r' }

[1] "1"
Error in parse(file, n, text, prompt) : syntax error on line 1

But if I drop the "pushBack" call, "parse" copes fine with the line a+b in
the file 'r123.r'.

However, "parse" works OK if the line a+b in the file (generated in the call
to "cat") is changed just to contain a, or 1, or "a", or +1. Removing the
"n=1" argument doesn't materially change the behaviour. "readLines" itself
seems to work fine when "pushBack" is used just as above, so "parse" seems
to be the offender here. More possibly helpful diagnostics are given below.

R is the best! Keep up the fantastic work in 2003

cheers
Mark

Interesting behaviour #1: change the line a+b in the file to a; . Parsing is
OK, but the final "readLines" call shows the next line starting ";2". See
also...

...Interesting behaviour #2:

> { tcon_ file( 'r123.r'); open( tcon); print( readLines( tcon, n=1)); 
pushBack( c( '1+', 'c(a)'), tcon); 
print( parse( file=tcon, n=1)); 
print( readLines( tcon)); close( tcon); unlink( 'r123.r') }

[1] "1"
expression(1)
[1] "c(a)" "+2"   "3"   
Warning message: 
incomplete final line found by readLines on `r123.r' 

Look where the plus sign (and semicolon in #1) have been moved to.

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington@csiro.au 

*******************************

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 1
 minor = 6.1
 year = 2002
 month = 11
 day = 01
 language = R

Windows 2000 Professional (build 2195) Service Pack 2.0

Search Path:
 .GlobalEnv, ROOT, package:handy, package:debug, mvb.session.info,
package:mvbutils, package:tcltk, Autoloads, package:base


From deleeuw@stat.ucla.edu  Fri Dec 27 04:48:39 2002
From: deleeuw@stat.ucla.edu (Jan de Leeuw)
Date: Fri Dec 27 04:48:39 2002
Subject: [Rd] BLAS/Lapack on OS X
In-Reply-To: <Pine.LNX.4.31.0212261938480.30122-100000@gannet.stats>
Message-ID: <03B89F98-194D-11D7-BFB2-000393BB6D36@stat.ucla.edu>

Yes, that also works fine.

-- Jan

On Thursday, December 26, 2002, at 11:40 AM, ripley@stats.ox.ac.uk  
wrote:

> On Thu, 26 Dec 2002, Jan de Leeuw wrote:
>
>> R-devel has the --with-lapack flag for configure. If you build R with
>>
>> --with-blas="-framework vecLib" --with-lapack="--framework vecLib"
>>
>> then the build goes through, using the native optimized BLAS and
>> Lapack in /System/Library/Frameworks/vecLib.framework. Also, it
>> works, in the sense that it does eigenvalue problems correctly.
>
> I hope
>
> --with-blas="-framework vecLib" --with-lapack
>
> is all that is needed.  --with-lapack searches the BLAS library for  
> lapack
> routines.
>
> --  
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------


From deleeuw@stat.ucla.edu  Fri Dec 27 07:05:29 2002
From: deleeuw@stat.ucla.edu (Jan de Leeuw)
Date: Fri Dec 27 07:05:29 2002
Subject: [Rd] R-devel
Message-ID: <05F09653-1961-11D7-BFB2-000393BB6D36@stat.ucla.edu>

On http://gifi.stat.ucla.edu/pub there is a build of R-devel (12/26/02)
compiled with gcc-3.3-pch  and g77-3.3-pch (apple build 1310 of
12/05/02) and linked with the vecLib framework for both BLAS
and LAPACK. This is maybe a tiny bit faster than a build with OS X
optimized ATLAS from fink, and it has the usual advantages of using
dynamic libraries instead of static ones. Because R now includes
libpcre and libbz2, and OS X includes libncurses, this makes
building R.bin almost independent of fink (except for dlcompat
and readline).
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------


From ripley@stats.ox.ac.uk  Fri Dec 27 14:32:06 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 27 14:32:06 2002
Subject: [Rd] Ratfor->Fortran conversion
In-Reply-To: <1040957430.8104.5.camel@sta49.stat.nus.edu.sg>
Message-ID: <Pine.LNX.4.31.0212270756310.3774-100000@gannet.stats>

Yes, quite a bit of R is converted ratfor.

There is `ratfor' (from AT&T) and then there is at least one `public
domain' clone. My RH7.2 came with neither.  I tend to use the AT&T version
on Solaris, as it seems better-behaved than the clone that is available
for e.g. Debian.

On 27 Dec 2002, Nicholas Lewin-Koh wrote:

> Does anyone have any experience porting Ratfor to fortran. I have gotten
> the ratfor preprocessor working and if I compile the ratfor code
> directly and dynamically load into R it seems to work (using g77 on RH
> linux). However if I just use the ratfor command and try to compile the
> output fortran file it does not compile. Is there some flags I should
> use to get ratfor to format the fortran output better, or is there a
> flag I need to set for g77 to get the output code to compile. Thanks

It really depends on the version details of both tools.  Your report is
about as non-specific as it is possible to get!  The only problems I have
had have been bugs in the ratfor -> f77 translation by the PD ratfor.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hannes@ruhrau.de  Sat Dec 28 14:57:02 2002
From: hannes@ruhrau.de (hannes@ruhrau.de)
Date: Sat Dec 28 14:57:02 2002
Subject: [Rd] dump() behaves unexpectedly with local variables (PR#2400)
Message-ID: <200212281357.OAA26367@pubhealth.ku.dk>

Full_Name: Johannes Hüsing
Version: 1.6.0.1
OS: Windows 2000
Submission from: (NULL) (132.252.149.100)


The following code produces an error:

> f <- function() { x <- 4; dump("x") }
> f()
Error in dump("x") : Object "x" not found

In the documentation the limited functionality 
of the current version of dump() is mentioned. 
It may be a good idea to give this as an example where dump()
does not (yet) work.

Greetings


Johannes


From ripley@stats.ox.ac.uk  Mon Dec 30 10:45:02 2002
From: ripley@stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec 30 10:45:02 2002
Subject: [Rd] dump() behaves *correctly* with local variables (PR#2400)
In-Reply-To: <200212281357.OAA26367@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.31.0212300908030.14218-100000@gannet.stats>

This is as expected; it is your expectations which are incorrect.  Please
read the definition of a bug in the R FAQ.

`x' is defined in the environment of the call to dump, and that is not in
the search path from inside dump().  Please re-check the R scope rules.

It is planned to add an envir argument to dump() from 1.7.x,
which will allow you to do this.  Note the difference from save(),
which does have an envir argument starting at parent.frame().

On Sat, 28 Dec 2002 hannes@ruhrau.de wrote:

> Full_Name: Johannes Hüsing
> Version: 1.6.0.1

No such version!

> OS: Windows 2000
> Submission from: (NULL) (132.252.149.100)
>
>
> The following code produces an error:
>
> > f <- function() { x <- 4; dump("x") }
> > f()
> Error in dump("x") : Object "x" not found
>
> In the documentation the limited functionality
> of the current version of dump() is mentioned.
> It may be a good idea to give this as an example where dump()
> does not (yet) work.

It should never work.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kjetil@entelnet.bo  Tue Dec 31 00:47:02 2002
From: kjetil@entelnet.bo (Kjetil Brinchmann Halvorsen)
Date: Tue Dec 31 00:47:02 2002
Subject: [Rd] Problem with predict.nlme
Message-ID: <3E10DA90.000014.00112@personal-apzxmv>

--------------Boundary-00=_KZHY36E1VA4000000000
Content-Type: Multipart/Alternative;
  boundary="------------Boundary-00=_KZHYYHI1VA4000000000"


--------------Boundary-00=_KZHYYHI1VA4000000000
Content-Type: Text/Plain;
  charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

Hola!=0D
=0D
plot( augPred(papas2.nlme.5), layout=3Dc(5,5,6) )=0D
Error in predict.nlme(object, value[1:(nrow(value)/nL), , drop =3D FALSE]=
,  : =0D
        Levels 1,2,3,4,5 not allowed for medio=0D
=0D
 plot( augPred(papas2.nlme.2), layout=3Dc(5,5,6) )=0D
   ... succeeds=0D
plot( augPred(papas2.nlme.2,level=3D0:1), layout=3Dc(5,5,6) )=0D
   ... succeeds=0D
> plot( augPred(papas2.nlme.3), layout=3Dc(5,5,6) )=0D
Error in predict.nlme(object, value[1:(nrow(value)/nL), , drop =3D FALSE]=
,  : =0D
        Levels 1,2,3,4,5 not allowed for medio=0D
> plot( augPred(papas2.nlme.4), layout=3Dc(5,5,6) )=0D
Error in predict.nlme(object, value[1:(nrow(value)/nL), , drop =3D FALSE]=
,  : =0D
        Levels 1,2,3,4,5 not allowed for medio=0D
=0D
The difference between the object papas2.nlme.2 where it succeeds and =0D
papas2.nlme.3, papas2.nlme.4, papas2.nlme.5 where it not, is that in the
last =0D
objects the argument fixed to nlme models the parameters as regressions o=
n =0D
covariables (factors), while in the first object the parametrs have only =
an
intercept. =0D
The covariables are constant in each group (plant), so the augPred plot =0D
seems to make sense, no averaging should be necessary. =0D
An excerpt from debug(predict.nlme) follows:=0D
> plot( augPred(papas2.nlme.5), layout=3Dc(5,5,6) )=0D
debugging in: predict.nlme(object, value[1:(nrow(value)/nL), , drop =3D F=
ALSE]
 =0D
   .=0D
   .=0D
   .=0D
debug: revOrder <- match(origOrder, row.names(dataMix))=0D
Browse[1]> n=0D
debug: contr <- object$contrasts=0D
Browse[1]> n=0D
debug: for (i in names(dataMix)) {=0D
    if (inherits(dataMix[, i], "factor") && !is.null(contr[[i]])) {=0D
        levs <- levels(dataMix[, i])=0D
        levsC <- dimnames(contr[[i]])[[1]]=0D
        if (any(wch <- is.na(match(levs, levsC)))) {=0D
            stop(paste("Levels", paste(levs[wch], collapse =3D ","), =0D
                "not allowed for", i))=0D
        }=0D
        attr(dataMix[, i], "contrasts") <- contr[[i]][levs, , =0D
            drop =3D FALSE]=0D
    }=0D
}=0D
Browse[1]> contr=0D
$medio=0D
[1] "contr.treatment"=0D
$variedad=0D
[1] "contr.treatment"=0D
# contr have names of functions supposed to construct contrast matrices.=0D
Browse[1]> dimnames(contr[["medio"]])=0D
NULL=0D
Browse[1]> n=0D
debug: i=0D
Browse[1]> n=0D
debug: if (inherits(dataMix[, i], "factor") && !is.null(contr[[i]])) {=0D
    levs <- levels(dataMix[, i])=0D
    levsC <- dimnames(contr[[i]])[[1]]=0D
    if (any(wch <- is.na(match(levs, levsC)))) {=0D
 # the code seems to assume that contr has the actual contrast matrix!=0D
        stop(paste("Levels", paste(levs[wch], collapse =3D ","), =0D
            "not allowed for", i))=0D
    }=0D
    attr(dataMix[, i], "contrasts") <- contr[[i]][levs, , drop =3D FALSE]=
=0D
}=0D
=2E=0D
=2E=0D
=2E=0D
=2E=0D
debug: levs <- levels(dataMix[, i])=0D
Browse[1]> n=0D
debug: levsC <- dimnames(contr[[i]])[[1]]=0D
Browse[1]> levs=0D
[1] "1" "2" "3" "4" "5"=0D
Browse[1]> n=0D
debug: if (any(wch <- is.na(match(levs, levsC)))) {=0D
    stop(paste("Levels", paste(levs[wch], collapse =3D ","), "not allowed=
 for"
 =0D
        i))=0D
}=0D
Browse[1]> n=0D
debug: stop(paste("Levels", paste(levs[wch], collapse =3D ","), "not allo=
wed
for", =0D
    i))=0D
Browse[1]> n=0D
Error in predict.nlme(object, value[1:(nrow(value)/nL), , drop =3D FALSE]=
,  : =0D
        Levels 1,2,3,4,5 not allowed for medio=0D
# because dimnames of "contr.treatment" is NULL!=0D
=0D
Kjetil Halvorsen
--------------Boundary-00=_KZHYYHI1VA4000000000
Content-Type: Text/HTML;
  charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

<meta http-equiv=3D"Content-Type" content=3D"text/html; charset=3Diso-885=
9-1"><html>
<head>
<meta name=3D"GENERATOR" content=3D"IncrediMail 1.0">=0D
<!--IncrdiXMLRemarkStart>
<IncrdiX-Info>
<X-FID>BA285063-5BCE-11D4-AF8D-0050DAC67E11</X-FID>
<X-FVER>2.0</X-FVER>
<X-FIT>Letter</X-FIT>
<X-FCOL>Elegant Paper</X-FCOL>
<X-FCAT>Stationery</X-FCAT>
<X-FDIS>Rice Fields</X-FDIS>
<X-Extensions>SU1CTDEsNDEsgUmBSTAkkcGNgZmVTY0wNCxNhYUoiU0kOMEoTYGBjYEoJDS=
ZnSyFhUksSU1CTDIsMCwsSU1CTDMsMCws</X-Extensions>
<X-BG>8F283858-1599-4CA4-A962-FEA2F09D0D6A</X-BG>
<X-BGT>repeat</X-BGT>
<X-BGC>#dce0e3</X-BGC>
<X-BGPX>0px</X-BGPX>
<X-BGPY>0px</X-BGPY>
<X-ASN>ANIM3D00-NONE-0000-0000-000000000000</X-ASN>
<X-ASNF>0</X-ASNF>
<X-ASH>ANIM3D00-NONE-0000-0000-000000000000</X-ASH>
<X-ASHF>1</X-ASHF>
<X-AN>6486DDE0-3EFD-11D4-BA3D-0050DAC68030</X-AN>
<X-ANF>0</X-ANF>
<X-AP>6486DDE0-3EFD-11D4-BA3D-0050DAC68030</X-AP>
<X-APF>1</X-APF>
<X-AD>C3C52140-4147-11D4-BA3D-0050DAC68030</X-AD>
<X-ADF>0</X-ADF>
<X-AUTO>X-ASN,X-ASH,X-AN,X-AP,X-AD</X-AUTO>
<X-CNT>;</X-CNT>
</IncrdiX-Info>
<IncrdiXMLRemarkEnd-->
=0A</head>
<BODY style=3D"BACKGROUND-POSITION: 0px 0px; FONT-SIZE: 12pt; MARGIN: 0px=
 10px 10px; BACKGROUND-REPEAT: repeat; FONT-FAMILY: Comic Sans MS" text=3D=
#000040 bgColor=3D#dce0e3 background=3Dcid:8F283858-1599-4CA4-A962-FEA2F0=
9D0D6A scroll=3D"yes" X-FIT=3D"Letter" X-FCAT=3D"Elegant Paper" X-FCOL=3D=
"Elegant Paper" X-FDIS=3D"Rice Fields" X-FID=3D"BA285063-5BCE-11D4-AF8D-0=
050DAC67E11" X-FVER=3D"2.0" X-ASN=3D"ANIM3D00-NONE-0000-0000-000000000000=
" X-ASNF=3D"0" X-ASH =3D"ANIM3D00-NONE-0000-0000-000000000000" X-ASHF =3D=
"1" X-AN =3D"6486DDE0-3EFD-11D4-BA3D-0050DAC68030" X-ANF=3D"0" X-AP=3D"64=
86DDE0-3EFD-11D4-BA3D-0050DAC68030" X-APF=3D"1" X-AD=3D"C3C52140-4147-11D=
4-BA3D-0050DAC68030" X-ADF=3D"0" SIGCOLOR=3D"0" ORGYPOS=3D"0"><TABLE id=3D=
INCREDIMAINTABLE cellSpacing=3D0 cellPadding=3D2 width=3D"95%" border=3D0=
>
<TBODY>

<TR>

<TD id=3DINCREDITEXTREGION style=3D"PADDING-RIGHT: 7px; PADDING-LEFT: 7px=
; FONT-SIZE: 10pt; FONT-FAMILY: Comic Sans MS"=20
    width=3D"100%">
      <DIV>Hola!</DIV>
      <DIV><BR>plot( augPred(papas2.nlme.5), layout=3Dc(5,5,6) )<BR>Error=
 in=20
      predict.nlme(object, value[1:(nrow(value)/nL), , drop =3D FALSE],&n=
bsp; :=20
      <BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Levels 1,2,3,4,5 not=
=20
      allowed for medio</DIV>
      <DIV><BR>&nbsp;plot( augPred(papas2.nlme.2), layout=3Dc(5,5,6)=20
      )<BR>&nbsp;&nbsp; ... succeeds</DIV>
      <DIV>plot( augPred(papas2.nlme.2,level=3D0:1), layout=3Dc(5,5,6)=20
      )<BR>&nbsp;&nbsp; ... succeeds</DIV>
      <DIV>&gt; plot( augPred(papas2.nlme.3), layout=3Dc(5,5,6) )<BR>Erro=
r in=20
      predict.nlme(object, value[1:(nrow(value)/nL), , drop =3D FALSE],&n=
bsp; :=20
      <BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Levels 1,2,3,4,5 not=
=20
      allowed for medio<BR>&gt; plot( augPred(papas2.nlme.4), layout=3Dc(=
5,5,6)=20
      )<BR>Error in predict.nlme(object, value[1:(nrow(value)/nL), , drop=
 =3D=20
      FALSE],&nbsp; : <BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Leve=
ls=20
      1,2,3,4,5 not allowed for medio</DIV>
      <DIV><BR>The difference between the object papas2.nlme.2 where it s=
ucceeds=20
      and <BR>papas2.nlme.3, papas2.nlme.4, papas2.nlme.5 where it not, i=
s that=20
      in the last <BR>objects the argument fixed to nlme models the param=
eters=20
      as regressions on <BR>covariables (factors), while in the first obj=
ect the=20
      parametrs have only an intercept. <BR>The covariables are constant =
in each=20
      group (plant), so the augPred plot <BR>seems to make sense, no aver=
aging=20
      should be necessary. </DIV>
      <DIV>An excerpt from debug(predict.nlme) follows:</DIV>
      <DIV>&gt; plot( augPred(papas2.nlme.5), layout=3Dc(5,5,6) )<BR>debu=
gging in:=20
      predict.nlme(object, value[1:(nrow(value)/nL), , drop =3D FALSE],=20
      <BR>&nbsp;&nbsp; .<BR>&nbsp;&nbsp; .<BR>&nbsp;&nbsp; .</DIV>
      <DIV>debug: revOrder &lt;- match(origOrder,=20
      row.names(dataMix))<BR>Browse[1]&gt; n<BR>debug: contr &lt;-=20
      object$contrasts<BR>Browse[1]&gt; n<BR>debug: for (i in names(dataM=
ix))=20
      {<BR>&nbsp;&nbsp;&nbsp; if (inherits(dataMix[, i], "factor") &amp;&=
amp;=20
      !is.null(contr[[i]])) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p; levs=20
      &lt;- levels(dataMix[, i])<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;=20
      levsC &lt;-=20
      dimnames(contr[[i]])[[1]]<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp; if=20
      (any(wch &lt;- is.na(match(levs, levsC))))=20
      {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;=20
      stop(paste("Levels", paste(levs[wch], collapse =3D ","),=20
      <BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;=20
      "not allowed for", i))<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;=20
      }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; attr(dataMix[, i],=20
      "contrasts") &lt;- contr[[i]][levs, ,=20
      <BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;=20
      drop =3D FALSE]<BR>&nbsp;&nbsp;&nbsp; }<BR>}<BR>Browse[1]&gt;=20
      contr<BR>$medio<BR>[1] "contr.treatment"</DIV>
      <DIV>$variedad<BR>[1] "contr.treatment"</DIV>
      <DIV># contr have names of functions supposed to construct contrast=
=20
      matrices.</DIV>
      <DIV>Browse[1]&gt; dimnames(contr[["medio"]])<BR>NULL<BR>Browse[1]&=
gt;=20
      n<BR>debug: i<BR>Browse[1]&gt; n<BR>debug: if (inherits(dataMix[, i=
],=20
      "factor") &amp;&amp; !is.null(contr[[i]])) {<BR>&nbsp;&nbsp;&nbsp; =
levs=20
      &lt;- levels(dataMix[, i])<BR>&nbsp;&nbsp;&nbsp; levsC &lt;-=20
      dimnames(contr[[i]])[[1]]<BR>&nbsp;&nbsp;&nbsp; if (any(wch &lt;-=20
      is.na(match(levs, levsC)))) {</DIV>
      <DIV>&nbsp;# the code seems to assume that contr has the actual con=
trast=20
      matrix!</DIV>
      <DIV>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; stop(paste("Levels"=
,=20
      paste(levs[wch], collapse =3D ","),=20
      <BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;=20
      "not allowed for", i))<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp=
;=20
      attr(dataMix[, i], "contrasts") &lt;- contr[[i]][levs, , drop =3D=20
      FALSE]<BR>}<BR>.<BR>.<BR>.<BR>.</DIV>
      <DIV>debug: levs &lt;- levels(dataMix[, i])<BR>Browse[1]&gt; n<BR>d=
ebug:=20
      levsC &lt;- dimnames(contr[[i]])[[1]]<BR>Browse[1]&gt; levs<BR>[1] =
"1" "2"=20
      "3" "4" "5"<BR>Browse[1]&gt; n<BR>debug: if (any(wch &lt;-=20
      is.na(match(levs, levsC)))) {<BR>&nbsp;&nbsp;&nbsp; stop(paste("Lev=
els",=20
      paste(levs[wch], collapse =3D ","), "not allowed for",=20
      <BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i))<BR>}<BR>Browse[1=
]&gt;=20
      n<BR>debug: stop(paste("Levels", paste(levs[wch], collapse =3D ",")=
, "not=20
      allowed for", <BR>&nbsp;&nbsp;&nbsp; i))<BR>Browse[1]&gt; n<BR>Erro=
r in=20
      predict.nlme(object, value[1:(nrow(value)/nL), , drop =3D FALSE],&n=
bsp; :=20
      <BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Levels 1,2,3,4,5 not=
=20
      allowed for medio</DIV>
      <DIV># because dimnames of "contr.treatment" is NULL!</DIV>
      <DIV>&nbsp;</DIV>
      <DIV>Kjetil Halvorsen</DIV>
      <DIV>&nbsp;</DIV></TD></TR>
<TR>
<TD id=3DINCREDIFOOTER width=3D"100%">
<TABLE cellSpacing=3D0 cellPadding=3D0 width=3D"100%">
<TBODY>
<TR>
<TD width=3D"100%"></TD>
<TD id=3DINCREDISOUND vAlign=3Dbottom align=3Dmiddle></TD>
<TD id=3DINCREDIANIM vAlign=3Dbottom align=3Dmiddle></TD></TR></TBODY></T=
ABLE></TD></TR></TBODY></TABLE><SPAN=20
id=3DIncrediStamp><SPAN dir=3Dltr><FONT face=3D"Arial, Helvetica, sans-se=
rif"=20
size=3D2>____________________________________________________<BR><FONT=20
face=3D"Comic Sans MS" size=3D2><A=20
href=3D"http://www.incredimail.com/redir.asp?ad_id=3D309&amp;lang=3D9"><I=
MG alt=3D""=20
hspace=3D0 src=3D"cid:1EB49B54-4A05-473A-A477-BD6136BC92F4" align=3Dbasel=
ine=20
border=3D0></A>&nbsp; <I>IncrediMail</I> - <B>Email has finally evolved</=
B> -=20
</FONT><A href=3D"http://www.incredimail.com/redir.asp?ad_id=3D309&amp;la=
ng=3D9"><FONT=20
face=3D"Times New Roman" size=3D3><B><U>Click=20
Here</U></B></FONT></A></SPAN></SPAN></FONT></BODY></html>
--------------Boundary-00=_KZHYYHI1VA4000000000--

--------------Boundary-00=_KZHY36E1VA4000000000
Content-Type: image/gif
Content-Transfer-Encoding: base64
Content-ID: <1EB49B54-4A05-473A-A477-BD6136BC92F4>

R0lGODlhFAAPALMIAP9gAM9gAM8vAM9gL/+QL5AvAGAvAP9gL////wAAAAAAAAAAAAAAAAAAAAAA
AAAAACH/C05FVFNDQVBFMi4wAwEAAAAh+QQJFAAIACwAAAAAFAAPAAAEVRDJSaudJuudrxlEKI6B
URlCUYyjKpgYAKSgOBSCDEuGDKgrAtC3Q/R+hkPJEDgYCjpKr5A8WK9OaPFZwHoPqm3366VKyeRt
E30tVVRscMHDqV/u+AgAIfkEBWQACAAsAAAAABQADwAABBIQyUmrvTjrzbv/YCiOZGmeaAQAIfkE
CRQACAAsAgABABAADQAABEoQIUOrpXIOwrsPxiQUheeRAgUA49YNhbCqK1kS9grQhXGAhsDBUJgZ
AL2Dcqkk7ogFpvRAokSn0p4PO6UIuUsQggSmFjKXdAgRAQAh+QQFCgAIACwAAAAAFAAPAAAEEhDJ
Sau9OOvNu/9gKI5kaZ5oBAAh+QQJFAAIACwCAAEAEAANAAAEShAhQ6ulcg7Cuw/GJBSF55ECBQDj
1g2FsKorWRL2CtCFcYCGwMFQmBkAvYNyqSTuiAWm9ECiRKfSng87pQi5SxCCBKYWMpd0CBEBACH5
BAVkAAgALAAAAAAUAA8AAAQSEMlJq7046827/2AojmRpnmgEADs=

--------------Boundary-00=_KZHY36E1VA4000000000
Content-Type: Image/jpeg
Content-ID: <8F283858-1599-4CA4-A962-FEA2F09D0D6A>
Content-Transfer-Encoding: base64

/9j/4AAQSkZJRgABAgAAZABkAAD/7AARRHVja3kAAQAEAAAAHgAA/+4AIUFkb2JlAGTAAAAAAQMA
EAMCAwYAAAHbAAAC1gAABZX/2wCEABALCwsMCxAMDBAXDw0PFxsUEBAUGx8XFxcXFx8eFxoaGhoX
Hh4jJSclIx4vLzMzLy9AQEBAQEBAQEBAQEBAQEABEQ8PERMRFRISFRQRFBEUGhQWFhQaJhoaHBoa
JjAjHh4eHiMwKy4nJycuKzU1MDA1NUBAP0BAQEBAQEBAQEBAQP/CABEIAGUAcwMBIgACEQEDEQH/
xACAAAEBAQEAAAAAAAAAAAAAAAAAAQIGAQEBAAAAAAAAAAAAAAAAAAAAARABAAICAwEAAgMAAAAA
AAAAAQARIQIxQRIiQDIQMFARAAICAgIBBAIDAQEAAAAAAAERACExQVFhcYGRobECEsHhMtHxEgEA
AAAAAAAAAAAAAAAAAABQ/9oADAMBAAIRAxEAAADtRZYE1ASghQFgUZoCkKSwLmhcllAEqkSkqFAl
hUomoAS3IoJqFlDNpFEAQFE1AIVYAWIVKAJRNZpYCwVmmshKACA0CBAUCBYGwf/aAAgBAgABBQD8
B/yP/9oACAEDAAEFAPz6/or8H//aAAgBAQABBQC2+ZeHjbD+saX6hwXeDW1Rg4xLLTa+m7ZiIEsI
1MTiHP1dYpvFADiFM1/X6nq9byuwdPPz5oFofWlEMQ9ULKrWq2ppG9Y2J6INQma9lVTRdlUKgHzX
XSEECw1SYu5WsGoJPkisZYpx31GvXZQ/JM3VwShzVTsp1EZbBI8LcaUSih86+s2Zl4Wp6+lAZnVs
Dkjdku5m+lJTdXDG2SHM9M2wKX1YxsaZTTwmoVrYnqsMrM652yjs01K0mtbGAz6Y5dpfqNz06qpq
5QNjiIjiZtbhtceNuf0jyeqGgu6rXMvI4omPWbPMYzEfMI+axHnFvOP4/9oACAECAgY/AGP/2gAI
AQMCBj8AY//aAAgBAQEGPwB72Yucb1BfIhFEaeZ+xRXFQELN+HEUQdjU0Xn4g9gRCQcpw1yajGYs
P/kFvUzvjUBWrIMFHI2OJQNEAjiEEFdTmfG/MTHq5RFOnpTV3kzCBx7x4YOD1AV5uYJvnqMA0hep
jfwpYCwC4Bx3q55zeZRBCw9TkoIuHw78RdczSNH2mgqcLpRC+RASAkA3B13mcYd5mR84c/yOx4lW
tRAZ6mGDhiP9WgXVyhWA+xDgMOWGMsTg/wBTz8SjjXrP8hHIlX1MZ6mDzgc/cIV/iyN1GBR0MQMK
jnEzvvMz8mUkErKlfqU63iV+IKNH7mNZBLFQEpEDeDOV32IVn8WR4caoywqI2p695mbZzNUQIcKf
k0bo+0NpCqn7CiQiNGXkdQen1DpjGeZ7WNw3pK+I93maCPc16+Zkf6XxMCsFwAkaiIB57vc/IAhZ
/HqZBBbB0ZokAEOGxsYqBgPp8agQBu4VSMJdqx6SwDsGBrTmAR93uZGX6KePowEADAIjoX8gw459
CICaW/MLGvodQfkDW71zBxRHtB3j3jC4PMIYoAgKNfPMCQNN7jCzvlzXPopzhQvNZY3CRya9ZrEF
fRE0iCB5mscZuVYfKmAi94uE3Q8qfytQ7xD0svmFcmaxNPI8iMjh3pmF2HbzqeUi+YkiD/MrOl5L
mbwPuWVfmXpv3hDH8qAjPpiZHXkRnSd6ZhB53mejzKV6US0K9TCCLyCeIhtETX5MsHBGJkD/ANiF
kMCE2qGoCdZ8Q8AMGpYFqEhdhRIYH3CF3d1M/Mexma+4CwdQ2Ddcx0exAlmj04QUQd8QWLB/iB5G
xmEg5TENVZqPYzFV8eHAy9T/AEc8a4n3Ov6g/VwvE6lpQ4VNysXzhS8esOO8w/rlF/rypjV3B5H1
Knr8T//Z

--------------Boundary-00=_KZHY36E1VA4000000000--


From buildwithflash2003@aol.com  Tue Dec 31 20:37:02 2002
From: buildwithflash2003@aol.com (buildwithflash2003@aol.com)
Date: Tue Dec 31 20:37:02 2002
Subject: [Rd] This Movie will create Millions (PR#2411)
Message-ID: <200212311936.UAA06996@pubhealth.ku.dk>

------=_NextPart_000_00B7_41B78A4C.D0644D84
Content-Type: text/html;
	charset="iso-8859-1"
Content-Transfer-Encoding: base64

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From kevin.wright@pioneer.com  Tue Dec 31 21:19:21 2002
From: kevin.wright@pioneer.com (Wright, Kevin)
Date: Tue Dec 31 21:19:21 2002
Subject: [Rd] Suggested change in cor.test help page
Message-ID: <BCB409391040E040A3B7F77238076C6F0C8DB0@leo.phibred.com>

Using the search engine on "correlation" fails to find the cor.test
function.  I would imagine it to be very useful for the search to find the
cor.test function--I know it would have saved me a fair amount of time.

One way for the search engine to find cor.test would be to add the word
"correlation" to the title page for cor.test, for example:

Test for Association/Correlation Between Paired Samples


Kevin Wright
(Apologies for the corporate sig.)



This communication is for use by the intended recipient and contains 
information that may be privileged, confidential or copyrighted under
applicable law.  If you are not the intended recipient, you are hereby
formally notified that any use, copying or distribution of this e-mail,
in whole or in part, is strictly prohibited.  Please notify the sender
by return e-mail and delete this e-mail from your system.  Unless
explicitly and conspicuously designated as "E-Contract Intended",
this e-mail does not constitute a contract offer, a contract amendment,
or an acceptance of a contract offer.  This e-mail does not constitute
a consent to the use of sender's contact information for direct marketing
purposes or for transfers of data to third parties.

 Francais Deutsch Italiano  Espanol  Portugues  Japanese  Chinese  Korean

            http://www.DuPont.com/corp/email_disclaimer.html


