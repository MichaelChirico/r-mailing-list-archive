From maechler at stat.math.ethz.ch  Tue Jun  1 08:32:38 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue Jun  1 08:32:42 2004
Subject: [Rd] Problem with .First.lib while running R CMD check 
In-Reply-To: <40BB6107.5040001@vanderbilt.edu>
References: <40BB6107.5040001@vanderbilt.edu>
Message-ID: <16572.8966.59739.966023@gargle.gargle.HOWL>

>>>>> "Frank" == Frank E Harrell <f.harrell@vanderbilt.edu>
>>>>>     on Mon, 31 May 2004 18:44:55 +0200 writes:

    Frank> I am having difficulty running R CMD check using the
    Frank> 30May04 version of R-devel and a new version of the
    Frank> Hmisc package:

    Frank> * checking S3 generic/method consistency ... WARNING
    Frank> Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
    Frank> character.only = TRUE, verbose = FALSE) :
    Frank> .First.lib failed
    Frank> Execution halted

    Frank> See section 'Generic functions and methods' of the
    Frank> 'Writing R Extensions' manual.

I'm not sure, but I'd guess it's simply the last line of your
.First.lib. that fails, i.e.,
    library.dynam("Hmisc", pkg, lib)
which fails loading the C/Fortran code.
I've had similar experiences.  The 'R CMD check' error message
is definitely ``sub optimal''.

Simply try (in R-devel)

   library(Hmisc, lib.loc="~/R/Hmisc.Rcheck")

This should give a much better error message.
Let us know if this helped.

Regards, Martin

From f.harrell at vanderbilt.edu  Tue Jun  1 07:48:17 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue Jun  1 13:50:51 2004
Subject: [Rd] Problem with .First.lib while running R CMD check
In-Reply-To: <16572.8966.59739.966023@gargle.gargle.HOWL>
References: <40BB6107.5040001@vanderbilt.edu>
	<16572.8966.59739.966023@gargle.gargle.HOWL>
Message-ID: <40BC18A1.5070005@vanderbilt.edu>

Martin Maechler wrote:
>>>>>>"Frank" == Frank E Harrell <f.harrell@vanderbilt.edu>
>>>>>>    on Mon, 31 May 2004 18:44:55 +0200 writes:
> 
> 
>     Frank> I am having difficulty running R CMD check using the
>     Frank> 30May04 version of R-devel and a new version of the
>     Frank> Hmisc package:
> 
>     Frank> * checking S3 generic/method consistency ... WARNING
>     Frank> Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
>     Frank> character.only = TRUE, verbose = FALSE) :
>     Frank> .First.lib failed
>     Frank> Execution halted
> 
>     Frank> See section 'Generic functions and methods' of the
>     Frank> 'Writing R Extensions' manual.
> 
> I'm not sure, but I'd guess it's simply the last line of your
> .First.lib. that fails, i.e.,
>     library.dynam("Hmisc", pkg, lib)
> which fails loading the C/Fortran code.
> I've had similar experiences.  The 'R CMD check' error message
> is definitely ``sub optimal''.
> 
> Simply try (in R-devel)
> 
>    library(Hmisc, lib.loc="~/R/Hmisc.Rcheck")
> 
> This should give a much better error message.
> Let us know if this helped.
> 
> Regards, Martin

Thanks Martin.  Here's what I get:

 > library(Hmisc,lib.loc="~/R/Hmisc.Rcheck")
Hmisc library by Frank E Harrell Jr

Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
to see overall documentation.

Hmisc redefines [.factor to drop unused levels of factor variables
when subscripting. To prevent this behaviour, issue the command
options(drop.unused.levels=F).

Error in dyn.load(x, as.logical(local), as.logical(now)) :
         unable to load shared library 
"/home/harrelfe/R/Hmisc.Rcheck/Hmisc/libs/Hmisc.so":
   libR.so: cannot open shared object file: No such file or directory
Error in library(Hmisc, lib.loc = "~/R/Hmisc.Rcheck") :
         .First.lib failed

Since Hmisc.so is in the right place:

~/R/Hmisc.Rcheck/Hmisc/libs harrelfe:ls -la
total 48
drwxr-xr-x    2 harrelfe harrelfe     4096 May 31 18:31 .
drwxr-xr-x   10 harrelfe harrelfe     4096 May 31 18:34 ..
-rwxr-xr-x    1 harrelfe harrelfe    37524 May 31 18:31 Hmisc.so

I don't understand the problem.  The same Hmisc.so (under 
/usr/local/lib/R/site-library) loads fine under R 1.9.

Frank

From maechler at stat.math.ethz.ch  Tue Jun  1 14:18:00 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue Jun  1 14:18:02 2004
Subject: [Rd] Problem with .First.lib while running R CMD check
In-Reply-To: <40BC18A1.5070005@vanderbilt.edu>
References: <40BB6107.5040001@vanderbilt.edu>
	<16572.8966.59739.966023@gargle.gargle.HOWL>
	<40BC18A1.5070005@vanderbilt.edu>
Message-ID: <16572.29688.125672.489994@gargle.gargle.HOWL>

>>>>> "Frank" == Frank E Harrell <f.harrell@vanderbilt.edu>
>>>>>     on Tue, 01 Jun 2004 07:48:17 +0200 writes:

    Frank> Martin Maechler wrote:
    >>>>>>> "Frank" == Frank E Harrell <f.harrell@vanderbilt.edu>
    >>>>>>> on Mon, 31 May 2004 18:44:55 +0200 writes:
    >> 
    >> 
    Frank> I am having difficulty running R CMD check using the
    Frank> 30May04 version of R-devel and a new version of the
    Frank> Hmisc package:
    >> 
    Frank> * checking S3 generic/method consistency ... WARNING
    Frank> Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
    Frank> character.only = TRUE, verbose = FALSE) :
    Frank> .First.lib failed
    Frank> Execution halted
    >> 
    Frank> See section 'Generic functions and methods' of the
    Frank> 'Writing R Extensions' manual.
    >> 
    >> I'm not sure, but I'd guess it's simply the last line of your
    >> .First.lib. that fails, i.e.,
    >> library.dynam("Hmisc", pkg, lib)
    >> which fails loading the C/Fortran code.
    >> I've had similar experiences.  The 'R CMD check' error message
    >> is definitely ``sub optimal''.
    >> 
    >> Simply try (in R-devel)
    >> 
    >> library(Hmisc, lib.loc="~/R/Hmisc.Rcheck")
    >> 
    >> This should give a much better error message.
    >> Let us know if this helped.
    >> 
    >> Regards, Martin

    Frank> Thanks Martin.  Here's what I get:

    >> library(Hmisc,lib.loc="~/R/Hmisc.Rcheck")
    Frank> Hmisc library by Frank E Harrell Jr

    Frank> Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
    Frank> to see overall documentation.

    Frank> Hmisc redefines [.factor to drop unused levels of factor variables
    Frank> when subscripting. To prevent this behaviour, issue the command
    Frank> options(drop.unused.levels=F).

    Frank> Error in dyn.load(x, as.logical(local), as.logical(now)) :
    Frank> unable to load shared library 
    Frank> "/home/harrelfe/R/Hmisc.Rcheck/Hmisc/libs/Hmisc.so":
    Frank> libR.so: cannot open shared object file: No such file or directory
	   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

this probably is the clue :  Hmisc.so expects an libR.so
which is what you get when you do ......./configure --enable-shared
and make for building R itself.

It looks like your version of R-devel
hasn't successfully been built with the ..shared option.
But when using it to build packages, it *does* assume the
'shared R' (libR.so in unix) to be available.

[or Hmisc.so itself or its underlying *.o files were built with 
 a non-shared (i.e. default) version of R ?]

If it the former (and incomplete shared installation) I'd
consider wiping that out and rebuild R afresh -- shared or not --
test R ("make check" or even "make check-all") and when
successful, rebuild Hmisc {removing at least  Hmisc/src/*o
beforehand!} with that version of R.

Martin

    Frank> Error in library(Hmisc, lib.loc = "~/R/Hmisc.Rcheck") :
    Frank> .First.lib failed

    Frank> Since Hmisc.so is in the right place:

    Frank> ~/R/Hmisc.Rcheck/Hmisc/libs harrelfe:ls -la
    Frank> total 48
    Frank> drwxr-xr-x    2 harrelfe harrelfe     4096 May 31 18:31 .
    Frank> drwxr-xr-x   10 harrelfe harrelfe     4096 May 31 18:34 ..
    Frank> -rwxr-xr-x    1 harrelfe harrelfe    37524 May 31 18:31 Hmisc.so

    Frank> I don't understand the problem.  The same Hmisc.so (under 
    Frank> /usr/local/lib/R/site-library) loads fine under R 1.9.

    Frank> Frank

From f.harrell at vanderbilt.edu  Tue Jun  1 21:03:30 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue Jun  1 21:02:30 2004
Subject: [Rd] Problem with .First.lib while running R CMD check
In-Reply-To: <16572.29688.125672.489994@gargle.gargle.HOWL>
References: <40BB6107.5040001@vanderbilt.edu>	<16572.8966.59739.966023@gargle.gargle.HOWL>	<40BC18A1.5070005@vanderbilt.edu>
	<16572.29688.125672.489994@gargle.gargle.HOWL>
Message-ID: <40BCD302.4060208@vanderbilt.edu>

Martin Maechler wrote:
>>>>>>"Frank" == Frank E Harrell <f.harrell@vanderbilt.edu>
>>>>>>    on Tue, 01 Jun 2004 07:48:17 +0200 writes:
> 
> 
>     Frank> Martin Maechler wrote:
>     >>>>>>> "Frank" == Frank E Harrell <f.harrell@vanderbilt.edu>
>     >>>>>>> on Mon, 31 May 2004 18:44:55 +0200 writes:
>     >> 
>     >> 
>     Frank> I am having difficulty running R CMD check using the
>     Frank> 30May04 version of R-devel and a new version of the
>     Frank> Hmisc package:
>     >> 
>     Frank> * checking S3 generic/method consistency ... WARNING
>     Frank> Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
>     Frank> character.only = TRUE, verbose = FALSE) :
>     Frank> .First.lib failed
>     Frank> Execution halted
>     >> 
>     Frank> See section 'Generic functions and methods' of the
>     Frank> 'Writing R Extensions' manual.
>     >> 
>     >> I'm not sure, but I'd guess it's simply the last line of your
>     >> .First.lib. that fails, i.e.,
>     >> library.dynam("Hmisc", pkg, lib)
>     >> which fails loading the C/Fortran code.
>     >> I've had similar experiences.  The 'R CMD check' error message
>     >> is definitely ``sub optimal''.
>     >> 
>     >> Simply try (in R-devel)
>     >> 
>     >> library(Hmisc, lib.loc="~/R/Hmisc.Rcheck")
>     >> 
>     >> This should give a much better error message.
>     >> Let us know if this helped.
>     >> 
>     >> Regards, Martin
> 
>     Frank> Thanks Martin.  Here's what I get:
> 
>     >> library(Hmisc,lib.loc="~/R/Hmisc.Rcheck")
>     Frank> Hmisc library by Frank E Harrell Jr
> 
>     Frank> Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
>     Frank> to see overall documentation.
> 
>     Frank> Hmisc redefines [.factor to drop unused levels of factor variables
>     Frank> when subscripting. To prevent this behaviour, issue the command
>     Frank> options(drop.unused.levels=F).
> 
>     Frank> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>     Frank> unable to load shared library 
>     Frank> "/home/harrelfe/R/Hmisc.Rcheck/Hmisc/libs/Hmisc.so":
>     Frank> libR.so: cannot open shared object file: No such file or directory
> 	   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
> this probably is the clue :  Hmisc.so expects an libR.so
> which is what you get when you do ......./configure --enable-shared
> and make for building R itself.
> 
> It looks like your version of R-devel
> hasn't successfully been built with the ..shared option.
> But when using it to build packages, it *does* assume the
> 'shared R' (libR.so in unix) to be available.
> 
> [or Hmisc.so itself or its underlying *.o files were built with 
>  a non-shared (i.e. default) version of R ?]
> 
> If it the former (and incomplete shared installation) I'd
> consider wiping that out and rebuild R afresh -- shared or not --
> test R ("make check" or even "make check-all") and when
> successful, rebuild Hmisc {removing at least  Hmisc/src/*o
> beforehand!} with that version of R.
> 
> Martin

Thanks very much Martin.  I think you've hit on it.  The problem seems 
to have to do with the order in which I install Hmisc using regular 
(non-shared) R (installed the usual Debian way) with regard to when I 
run CMD check under R-devel.  I configured R-devel using --enable-shared 
(if this matters) and ran R-devel CMD check "fresh" and all seems to be 
well.  Thanks for your insight.  In the future I think I'll just remove 
the *.o files from regular R before running CMD check.  I am surprised 
that R-devel and R 1.9 are inconsistent on this point.  -Frank

> 
>     Frank> Error in library(Hmisc, lib.loc = "~/R/Hmisc.Rcheck") :
>     Frank> .First.lib failed
> 
>     Frank> Since Hmisc.so is in the right place:
> 
>     Frank> ~/R/Hmisc.Rcheck/Hmisc/libs harrelfe:ls -la
>     Frank> total 48
>     Frank> drwxr-xr-x    2 harrelfe harrelfe     4096 May 31 18:31 .
>     Frank> drwxr-xr-x   10 harrelfe harrelfe     4096 May 31 18:34 ..
>     Frank> -rwxr-xr-x    1 harrelfe harrelfe    37524 May 31 18:31 Hmisc.so
> 
>     Frank> I don't understand the problem.  The same Hmisc.so (under 
>     Frank> /usr/local/lib/R/site-library) loads fine under R 1.9.
> 
>     Frank> Frank
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University

From ejr at EECS.Berkeley.EDU  Tue Jun  1 23:22:20 2004
From: ejr at EECS.Berkeley.EDU (Jason Riedy)
Date: Tue Jun  1 23:30:22 2004
Subject: [Rd] ANN: LAPACK and ScaLAPACK new functionality survey
Message-ID: <200406012122.i51LMKEV019399@lotus.CS.Berkeley.EDU>

[mailed jointly to maintainers@octave.org, r-devel@stat.math.ethz.ch
to reach users with relevant experience.  watch where your replies
go.  what would make using LAPACK and ScaLAPACK easier for Octave 
and R developers?  -- ejr, not subscribed]

We plan to update the LAPACK and ScaLAPACK libraries and would like to have
feedback from users on what functionalities they think are missing and would
be needed in order to make these libraries more useful for the community. We
invite you to enter your suggestions in the form below. It would be most
useful to have input by June 16th, although we would welcome your input at
any time. 

Both LAPACK and ScaLAPACK provide well-tested, open source, reviewed code
implementing trusted algorithms that guarantee reliability, efficiency and
accuracy. Any new functionality must adhere to these standards and should
have a significant impact in order to justify the development costs. We are
also interested in suggestions regarding user interfaces, documentation,
language interfaces, target (parallel) architectures and other issues, again
provided the impact is large enough. 

We already plan to include a variety of improved algorithms discovered over
the years by a number of researchers (e.g. faster or more accurate
eigenvalue and SVD algorithms, extra precise iterative refinement, recursive
blocking for some linear solvers, etc.). We also know of a variety of other
possible functions we could add (e.g. updating and downdating
factorizations), but are uncertain of their impact. 

Please see http://icl.cs.utk.edu/lapack-survey.html for the survey.
We would like to have your input by June 16th, 2004.

Regards,
Jack Dongarra, Jim Demmel, and Sven Hammarling

From martin.lenze at web.de  Wed Jun  2 02:29:24 2004
From: martin.lenze at web.de (martin.lenze@web.de)
Date: Wed Jun  2 02:29:26 2004
Subject: [Rd] Bug with date 1970-01-01 on Windows (PR#6929)
Message-ID: <20040602002924.3F60310687@slim.kubism.ku.dk>

Full_Name: Martin Lenze
Version: 1.8.0 alpha (2003-09-18)
OS: Microsoft Windows 2000 [Version 5.00.2195], SP4
Submission from: (NULL) (82.82.76.131)


Seems to be related to PR#1332...

Hello,

I get:
> Sys.getlocale()
[1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=C;LC_NUMERIC=C;LC_TIME=English_United States.1252"
> strptime("20040602","%Y%m%d")-strptime("19700101","%Y%m%d")
Time difference of NA secs
> strptime("20040602","%Y%m%d")-strptime("19700102","%Y%m%d")
Time difference of 12569.96 days

I get as well the bug reported in 1332:
> as.POSIXct("1970-01-01", tz = "GMT")
Error in fromchar(x) : character string is not in a standard unambiguous format

Regarding hint on msvcrt.dll in Windows-FAQ on R:
The downloaded archive contains:
msvcrt.dll 4.20.0.6164
msvcrt20.dll 2.11.0.0
msvcrt40.dll 4.10.0.5349

My Windows 2000 System has the following versions in ...\system32:
msvcrt.dll 6.1.9844.0
msvcrt20.dll 2.12.0.0
msvcrt40.dll 4.2000.0.6201
which are all newer than the ones from the archive mentioned within the FAQ.
Thus I feel a bit unhappy, to replace those, especially as the readme.txt in the
archive recommends not to do so if files are present.

I have made this a new bug report, because the other one is over two years old
now...

Hope You don't mind.

Many thanx in advance
M. Lenze

From pkienzle at users.sourceforge.net  Wed Jun  2 03:55:56 2004
From: pkienzle at users.sourceforge.net (Paul Kienzle)
Date: Wed Jun  2 03:55:49 2004
Subject: [Rd] Re: ANN: LAPACK and ScaLAPACK new functionality survey
In-Reply-To: <200406012122.i51LMKEV019399@lotus.CS.Berkeley.EDU>
References: <200406012122.i51LMKEV019399@lotus.CS.Berkeley.EDU>
Message-ID: <FCCEB35E-B437-11D8-9FA2-000A95EC9F50@users.sf.net>

The only candidates that leap to mind are matrix sqrt, exp and log for 
which
there are accurate algorithms which are not built upon diagonalization.
There are also candidates in control systems, such as the discrete 
Lyapunov
solver  (a x a' - x + b = 0), which has a loop, but I don't know how 
broadly
useful it is.  Anyone care to put forward an argument for any of these?

I'm assuming that sparse methods are beyond the scope of LAPACK.
And fft, filtering, convolution, optimization, special functions, 
sorting,
random number generation, quadrature, interpolation, ...

Paul Kienzle
pkienzle@users.sf.net

On Jun 1, 2004, at 5:30 PM, Jason Riedy wrote:

> [mailed jointly to maintainers@octave.org, r-devel@stat.math.ethz.ch
> to reach users with relevant experience.  watch where your replies
> go.  what would make using LAPACK and ScaLAPACK easier for Octave
> and R developers?  -- ejr, not subscribed]
>
> We plan to update the LAPACK and ScaLAPACK libraries and would like to 
> have
> feedback from users on what functionalities they think are missing and 
> would
> be needed in order to make these libraries more useful for the 
> community. We
> invite you to enter your suggestions in the form below. It would be 
> most
> useful to have input by June 16th, although we would welcome your 
> input at
> any time.
>
> Both LAPACK and ScaLAPACK provide well-tested, open source, reviewed 
> code
> implementing trusted algorithms that guarantee reliability, efficiency 
> and
> accuracy. Any new functionality must adhere to these standards and 
> should
> have a significant impact in order to justify the development costs. 
> We are
> also interested in suggestions regarding user interfaces, 
> documentation,
> language interfaces, target (parallel) architectures and other issues, 
> again
> provided the impact is large enough.
>
> We already plan to include a variety of improved algorithms discovered 
> over
> the years by a number of researchers (e.g. faster or more accurate
> eigenvalue and SVD algorithms, extra precise iterative refinement, 
> recursive
> blocking for some linear solvers, etc.). We also know of a variety of 
> other
> possible functions we could add (e.g. updating and downdating
> factorizations), but are uncertain of their impact.
>
> Please see http://icl.cs.utk.edu/lapack-survey.html for the survey.
> We would like to have your input by June 16th, 2004.
>
> Regards,
> Jack Dongarra, Jim Demmel, and Sven Hammarling
>

From ligges at statistik.uni-dortmund.de  Wed Jun  2 10:27:49 2004
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Wed Jun  2 10:27:54 2004
Subject: [Rd] Bug with date 1970-01-01 on Windows (PR#6929)
Message-ID: <20040602082749.E521E10683@slim.kubism.ku.dk>

martin.lenze@web.de wrote:

> Full_Name: Martin Lenze
> Version: 1.8.0 alpha (2003-09-18)

1.8.0 alpha????

Please try the current version of R (R-1.9.0 has been realeased some 
time ago!) - it has been fixed in the meantime!

Please don't report bugs in outdated version of R.

Uwe Ligges


> OS: Microsoft Windows 2000 [Version 5.00.2195], SP4
> Submission from: (NULL) (82.82.76.131)
> 
> 
> Seems to be related to PR#1332...
> 
> Hello,
> 
> I get:
> 
>>Sys.getlocale()
> 
> [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=C;LC_NUMERIC=C;LC_TIME=English_United States.1252"
> 
>>strptime("20040602","%Y%m%d")-strptime("19700101","%Y%m%d")
> 
> Time difference of NA secs
> 
>>strptime("20040602","%Y%m%d")-strptime("19700102","%Y%m%d")
> 
> Time difference of 12569.96 days
> 
> I get as well the bug reported in 1332:
> 
>>as.POSIXct("1970-01-01", tz = "GMT")
> 
> Error in fromchar(x) : character string is not in a standard unambiguous format
> 
> Regarding hint on msvcrt.dll in Windows-FAQ on R:
> The downloaded archive contains:
> msvcrt.dll 4.20.0.6164
> msvcrt20.dll 2.11.0.0
> msvcrt40.dll 4.10.0.5349
> 
> My Windows 2000 System has the following versions in ...\system32:
> msvcrt.dll 6.1.9844.0
> msvcrt20.dll 2.12.0.0
> msvcrt40.dll 4.2000.0.6201
> which are all newer than the ones from the archive mentioned within the FAQ.
> Thus I feel a bit unhappy, to replace those, especially as the readme.txt in the
> archive recommends not to do so if files are present.
> 
> I have made this a new bug report, because the other one is over two years old
> now...
> 
> Hope You don't mind.
> 
> Many thanx in advance
> M. Lenze
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From stephanschlueter at gmx.de  Wed Jun  2 11:34:28 2004
From: stephanschlueter at gmx.de (stephanschlueter@gmx.de)
Date: Wed Jun  2 11:34:30 2004
Subject: [Rd] a fault in the "hist" - function (PR#6931)
Message-ID: <20040602093428.8BF501088C@slim.kubism.ku.dk>

Full_Name: Stephan Schlueter
Version: 1.9.0
OS: 
Submission from: (NULL) (217.184.109.24)


During my studies, I found a fault in the hist()-function:
If you have a vector x with values around zero and also bigger than 10,000,000 ,
there will be a shift of   -max(x)/10,000,000    in the hist-datas.
See my example:

x<-runif(10000)
hist(x,breaks=c(seq(-3,3,0.1)),prob=TRUE)
#everything ok, but now produce the problem 
x[254]=20000000
hist(x,breaks=c(seq(-3,3,0.1),max(x)),prob=TRUE,xlim=c(-3,3))
#here you can see the shift

hist(x + max(x)/10000000,breaks=c(seq(-3,3,0.1),max(x)),prob=TRUE,xlim=c(-3,3))
#first solution (but I don't know ,why it works)

for(i in 1:10000)
 {
 if(x[i]>10)x[i]=10
 }
hist(x,breaks=c(seq(-3,3,0.1),max(x)),prob=TRUE,xlim=c(-3,3))
#second solution (the better one I think)


Good Luck for the solution of this problem, and it would be nice to send me an
answer. 
               Thanks and till then,  Stephan Schlueter

From martin.lenze at web.de  Wed Jun  2 12:29:35 2004
From: martin.lenze at web.de (martin.lenze@web.de)
Date: Wed Jun  2 12:29:39 2004
Subject: [Rd] Bug with date 1970-01-01 on Windows (PR#6929)
Message-ID: <20040602102935.AC1951076F@slim.kubism.ku.dk>

Hello,

sorry, You are right. As I did'nt find any comments in the Changes or in t=
he bug tracking system I believed, this bug might still be there.
Besides You are releasing new versions even faster, then I can update my s=
tatistics.

Well done job and many thanxs for the great stuff!
Kindest regards
Martin Lenze

Uwe Ligges <ligges@statistik.uni-dortmund.de> schrieb am 02.06.04 10:27:27=
:
>=20
> martin.lenze@web.de wrote:
>=20
> > Full=5FName: Martin Lenze
> > Version: 1.8.0 alpha (2003-09-18)
>=20
> 1.8.0 alpha=3F=3F=3F=3F
>=20
> Please try the current version of R (R-1.9.0 has been realeased some=20
> time ago!) - it has been fixed in the meantime!
>=20
> Please don't report bugs in outdated version of R.
>=20
> Uwe Ligges
>=20
>=20
> > OS: Microsoft Windows 2000 [Version 5.00.2195], SP4
> > Submission from: (NULL) (82.82.76.131)
> >=20
> >=20
> > Seems to be related to PR#1332...
> >=20
> > Hello,
> >=20
> > I get:
> >=20
> >>Sys.getlocale()
> >=20
> > [1] "LC=5FCOLLATE=3DEnglish=5FUnited States.1252;LC=5FCTYPE=3DEnglish=5FUnited
> > States.1252;LC=5FMONETARY=3DC;LC=5FNUMERIC=3DC;LC=5FTIME=3DEnglish=5FUnited States.1=
252"
> >=20
> >>strptime("20040602","%Y%m%d")-strptime("19700101","%Y%m%d")
> >=20
> > Time difference of NA secs
> >=20
> >>strptime("20040602","%Y%m%d")-strptime("19700102","%Y%m%d")
> >=20
> > Time difference of 12569.96 days
> >=20
> > I get as well the bug reported in 1332:
> >=20
> >>as.POSIXct("1970-01-01", tz =3D "GMT")
> >=20
> > Error in fromchar(x) : character string is not in a standard unambiguo=
us format
> >=20
> > Regarding hint on msvcrt.dll in Windows-FAQ on R:
> > The downloaded archive contains:
> > msvcrt.dll 4.20.0.6164
> > msvcrt20.dll 2.11.0.0
> > msvcrt40.dll 4.10.0.5349
> >=20
> > My Windows 2000 System has the following versions in ...\system32:
> > msvcrt.dll 6.1.9844.0
> > msvcrt20.dll 2.12.0.0
> > msvcrt40.dll 4.2000.0.6201
> > which are all newer than the ones from the archive mentioned within th=
e FAQ.
> > Thus I feel a bit unhappy, to replace those, especially as the readme.=
txt in the
> > archive recommends not to do so if files are present.
> >=20
> > I have made this a new bug report, because the other one is over two y=
ears old
> > now...
> >=20
> > Hope You don't mind.
> >=20
> > Many thanx in advance
> > M. Lenze
> >=20
> > =5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F
> > R-devel@stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>=20

--=A0
Martin=A0Lenze,=A0Brunnengasse=A01,=A069117=A0Heidelberg,=A0Germany
+49=A0178=A03582640,=A0fax=A0+49=A012126=A027041965=A0

From ligges at statistik.uni-dortmund.de  Wed Jun  2 15:34:46 2004
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Wed Jun  2 15:34:50 2004
Subject: [Rd] a fault in the "hist" - function (PR#6931)
Message-ID: <20040602133446.186CF10882@slim.kubism.ku.dk>

stephanschlueter@gmx.de wrote:

> Full_Name: Stephan Schlueter
> Version: 1.9.0
> OS: 
> Submission from: (NULL) (217.184.109.24)
> 
> 
> During my studies, I found a fault in the hist()-function:
> If you have a vector x with values around zero and also bigger than 10,000,000 ,
> there will be a shift of   -max(x)/10,000,000    in the hist-datas.
> See my example:
> 
> x<-runif(10000)
> hist(x,breaks=c(seq(-3,3,0.1)),prob=TRUE)
> #everything ok, but now produce the problem 
> x[254]=20000000
> hist(x,breaks=c(seq(-3,3,0.1),max(x)),prob=TRUE,xlim=c(-3,3))
> #here you can see the shift
> 
> hist(x + max(x)/10000000,breaks=c(seq(-3,3,0.1),max(x)),prob=TRUE,xlim=c(-3,3))
> #first solution (but I don't know ,why it works)
> 
> for(i in 1:10000)
>  {
>  if(x[i]>10)x[i]=10
>  }
> hist(x,breaks=c(seq(-3,3,0.1),max(x)),prob=TRUE,xlim=c(-3,3))
> #second solution (the better one I think)
> 
> 
> Good Luck for the solution of this problem, and it would be nice to send me an
> answer. 
>                Thanks and till then,  Stephan Schlueter
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel


The problem is in hist.default():

     diddle <- 1e-7 * max(abs(range(breaks)))

and whereever we are diddling - there are some disadvantages.

Do we want a flag that turns off diddling and the following "fuzz" 
stuff? Or do we want something to adjust the hardcoded heuristical value 
"1e-7" (to zero, for example)?

Uwe Ligges

From p.dalgaard at biostat.ku.dk  Wed Jun  2 16:09:50 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed Jun  2 16:16:24 2004
Subject: [Rd] a fault in the "hist" - function (PR#6931)
In-Reply-To: <20040602133446.186CF10882@slim.kubism.ku.dk>
References: <20040602133446.186CF10882@slim.kubism.ku.dk>
Message-ID: <x2isea126p.fsf@biostat.ku.dk>

ligges@statistik.uni-dortmund.de writes:

> The problem is in hist.default():
> 
>      diddle <- 1e-7 * max(abs(range(breaks)))
> 
> and whereever we are diddling - there are some disadvantages.
> 
> Do we want a flag that turns off diddling and the following "fuzz" 
> stuff? Or do we want something to adjust the hardcoded heuristical value 
> "1e-7" (to zero, for example)?

Neither, I think, since the diddle is there for a reason, and the only
real problem is the use of breaks that are wildly off-scale. We might
key diddle to xlim instead, or possibly let "diddle" be an argument
with a suitable default. 

You probably can't get all cases completely right though. A tiny range
of numbers (compared to the mean) is likely to cause problems whatever
you do.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From PS at blr.hexaware.com  Wed Jun  2 22:03:25 2004
From: PS at blr.hexaware.com (PS@blr.hexaware.com)
Date: Wed Jun  2 21:56:29 2004
Subject: [Rd] (no subject)
Message-ID: <OF65256EA7.006E2D17-ON65256EA7.006E2D17-65256EA7.006E2D18@blr.hexaware.com>

Hi,

Thank you for your interest in Hexaware.

Your application is being processed.  We shall revert to you , if you are
shortlisted.

This is a system generated message, Please do not reply.

Sincerely,
HR Team

From rpeng at jhsph.edu  Thu Jun  3 15:06:07 2004
From: rpeng at jhsph.edu (rpeng@jhsph.edu)
Date: Thu Jun  3 15:06:10 2004
Subject: [Rd] Saving Trellis Graphics in R 1.9.0. (PR#6915)
Message-ID: <20040603130607.D565410A54@slim.kubism.ku.dk>

An even simpler example that doesn't work for me (on Linux) is:

library(lattice)
xyplot(0 ~ 0)
dev.copy2eps(file = "asdf.ps")

The file `asdf.ps' is reproduced at the bottom.  It appears blank when 
viewed in gv.  What does work for me is to do

trellis.device(dev = postscript, file = "asdf.ps", ...etc...)
xyplot(0 ~ 0)
dev.off()

This problem persists in recent R-devel with lattice 0.9-12.

 > version
          _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status   Under development (unstable)
major    2
minor    0.0
year     2004
month    06
day      03
language R


-roger

%!PS-Adobe-3.0 EPSF-3.0
%%DocumentNeededResources: font Helvetica
%%+ font Helvetica-Bold
%%+ font Helvetica-Oblique
%%+ font Helvetica-BoldOblique
%%+ font Symbol
%%Title: R Graphics Output
%%Creator: R Software
%%Pages: (atend)
%%BoundingBox: 0 0 503 503
%%EndComments
%%BeginProlog
/bp  { gs gs } def
% begin .ps.prolog
/gs  { gsave } def
/gr  { grestore } def
/ep  { showpage gr gr } def
/m   { moveto } def
/l  { rlineto } def
/np  { newpath } def
/cp  { closepath } def
/f   { fill } def
/o   { stroke } def
/c   { newpath 0 360 arc } def
/r   { 4 2 roll moveto 1 copy 3 -1 roll exch 0 exch rlineto 0 rlineto 
-1 mul 0 e
xch rlineto closepath } def
/p1  { stroke } def
/p2  { gsave bg setrgbcolor fill grestore newpath } def
/p3  { gsave bg setrgbcolor fill grestore stroke } def
/t   { 6 -2 roll moveto gsave rotate
        ps mul neg 0 2 1 roll rmoveto
        1 index stringwidth pop
        mul neg 0 rmoveto show grestore } def
/cl  { grestore gsave newpath 3 index 3 index moveto 1 index
        4 -1 roll lineto  exch 1 index lineto lineto
        closepath clip newpath } def
/rgb { setrgbcolor } def
/s   { scalefont setfont } def
/R   { /Font1 findfont } def
/B   { /Font2 findfont } def
/I   { /Font3 findfont } def
/BI  { /Font4 findfont } def
/S   { /Font5 findfont } def
1 setlinecap 1 setlinejoin
% end   .ps.prolog
%%IncludeResource: font Helvetica
...skipping...
   currentdict
   end
/Font3 exch definefont pop
%%IncludeResource: font Helvetica-BoldOblique
/Helvetica-BoldOblique findfont
dup length dict begin
   {1 index /FID ne {def} {pop pop} ifelse} forall
   /Encoding ISOLatin1Encoding def
   currentdict
   end
/Font4 exch definefont pop
%%IncludeResource: font Symbol
/Symbol findfont
dup length dict begin
   {1 index /FID ne {def} {pop pop} ifelse} forall
   currentdict
   end
/Font5 exch definefont pop
%%EndProlog
ep
%%Trailer
%%Pages: 0
%%EOF


rpeng@jhsph.edu wrote:
> Okay, here's one example that might reproduce this behavior.  At least 
> it doesn't work for me at the moment:
> 
> library(lattice)
> trellis.device(dev = x11)
> set.seed(1); x <- rnorm(100); y <- rnorm(100)
> xyplot(y ~ x, panel = function(...) {
> 	panel.xyplot(...)
> 	ltext(0,0,labels = expression(paste("P(", beta[2] > 0, ")") == .65), 
> cex = .6) })
> dev.copy2eps(file = "asdf.eps")
> 
> Note that, when I run it on my computer, I do get the following 
> warning after the call to xyplot():
> 
> Warning message:
> X11 used font size 8 when 7 was requested
> 
> So I have been warned, but I didn't think this would produce an empty 
> plot.  One problem, if I remember correctly, is that sometimes it 
> works and sometimes it doesn't which I think is why I didn't bother 
> with it before.
> 
> -roger
> 
>  > version
>           _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status   alpha
> major    1
> minor    9.1
> year     2004
> month    05
> day      24
> language R
>  >
> 
> valenta@euromise.cz wrote:
> 
>>Full_Name: Zdenek Valenta
>>Version: 1.9.0.
>>OS: Windows XP
>>Submission from: (NULL) (147.231.7.250)
>>
>>
>>I could not copy/save (Trelis) graphics using R version 1.9.0. The graphics
>>displayed normally, but copying/saving it only produced an empty file.
>>Everything works o.k. with R rel. 1.8.1.
>>
>>Best regards,
>>
>>Zdenek Valenta
>>
>>______________________________________________
>>R-devel@stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From ripley at stats.ox.ac.uk  Thu Jun  3 18:36:58 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jun  3 18:37:01 2004
Subject: [Rd] Problem with .First.lib while running R CMD check
In-Reply-To: <40BCD302.4060208@vanderbilt.edu>
Message-ID: <Pine.LNX.4.44.0406031734480.3219-100000@gannet.stats>

On Tue, 1 Jun 2004, Frank E Harrell Jr wrote:

> Thanks very much Martin.  I think you've hit on it.  The problem seems 
> to have to do with the order in which I install Hmisc using regular 
> (non-shared) R (installed the usual Debian way) with regard to when I 
> run CMD check under R-devel.  I configured R-devel using --enable-shared 
> (if this matters) and ran R-devel CMD check "fresh" and all seems to be 
> well.  Thanks for your insight.  In the future I think I'll just remove 
> the *.o files from regular R before running CMD check.  I am surprised 
> that R-devel and R 1.9 are inconsistent on this point.  -Frank

Take a look at the NEWS file.  In R-devel, if --enable-R-shared (sic) is 
specified libR.so is always used, even by R.bin.  There are several 
reasons for the change, one of which is that libR.so actually gets tested.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From f.harrell at vanderbilt.edu  Thu Jun  3 21:47:33 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu Jun  3 21:48:37 2004
Subject: [Rd] Problem with .First.lib while running R CMD check
In-Reply-To: <Pine.LNX.4.44.0406031734480.3219-100000@gannet.stats>
References: <Pine.LNX.4.44.0406031734480.3219-100000@gannet.stats>
Message-ID: <40BF8055.4030307@vanderbilt.edu>

Prof Brian Ripley wrote:
> On Tue, 1 Jun 2004, Frank E Harrell Jr wrote:
> 
> 
>>Thanks very much Martin.  I think you've hit on it.  The problem seems 
>>to have to do with the order in which I install Hmisc using regular 
>>(non-shared) R (installed the usual Debian way) with regard to when I 
>>run CMD check under R-devel.  I configured R-devel using --enable-shared 
>>(if this matters) and ran R-devel CMD check "fresh" and all seems to be 
>>well.  Thanks for your insight.  In the future I think I'll just remove 
>>the *.o files from regular R before running CMD check.  I am surprised 
>>that R-devel and R 1.9 are inconsistent on this point.  -Frank
> 
> 
> Take a look at the NEWS file.  In R-devel, if --enable-R-shared (sic) is 
> specified libR.so is always used, even by R.bin.  There are several 
> reasons for the change, one of which is that libR.so actually gets tested.

Thanks Brian.  The simple solution was to remove *.o before and after 
running R-devel CMD check.

Frank
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University

From martin.lenze at web.de  Fri Jun  4 12:04:12 2004
From: martin.lenze at web.de (martin.lenze@web.de)
Date: Fri Jun  4 12:04:14 2004
Subject: [Rd] subset: evaluating expressions missing? (PR#6937)
Message-ID: <20040604100412.BF0DC1097F@slim.kubism.ku.dk>

Full_Name: Martin Lenze
Version: Version 1.9.0  (2004-04-12), ISBN 3-900051-00-3
OS: Microsoft Windows 2000 [Version 5.00.2195] SP4
Submission from: (NULL) (82.83.167.79)


Hello,

now I switched to R 1.9.0 and did get a problem with subset, see sample:

x <- data.frame(a=as.integer(round(runif(5),0)), 
  b=as.integer(round(runif(5),0)),c=as.integer(round(runif(5),0)))
# correct results:
for (c in c(expression(x$a==1),expression(x$b==1),
  expression(x$c==1))) print(x[eval(c),])
# results I don't understand:
for (c in c(expression(x$a==1),expression(x$b==1),
  expression(x$c==1))) print(subset(x,eval(c)))
for (c in c(expression(x$a==1),expression(x$b==1),
  expression(x$c==1))) print(subset(x,c))

Am I doing something wrong? Using subset this way with R 1.8.0 worked fine.

Many thanks in advance
Martin Lenze

From ripley at stats.ox.ac.uk  Fri Jun  4 15:40:46 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jun  4 15:40:51 2004
Subject: [Rd] subset: evaluating expressions missing? (PR#6937)
In-Reply-To: <20040604100412.BF0DC1097F@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406041431460.25099-100000@gannet.stats>

You should not use the system object `c' as an index! BTW, expression()
takes multiple arguments, so you can do

# OK
for (c2 in expression(x$a==1, x$b==1, x$c==1)) print(x[eval(c2),])
for (c2 in expression(x$a==1, x$b==1, x$c==1)) print(subset(x, eval(c2)))

# error, correctly
for (c2 in expression(x$a==1, x$b==1, x$c==1)) print(subset(x,c2))
Error in r & !is.na(r) : operations are possible only for numeric or logical types
In addition: Warning message:
is.na() applied to non-(list or vector) in: is.na(r)

On Fri, 4 Jun 2004 martin.lenze@web.de wrote:

> Full_Name: Martin Lenze
> Version: Version 1.9.0  (2004-04-12), ISBN 3-900051-00-3
> OS: Microsoft Windows 2000 [Version 5.00.2195] SP4
> Submission from: (NULL) (82.83.167.79)

> now I switched to R 1.9.0 and did get a problem with subset, see sample:
> 
> x <- data.frame(a=as.integer(round(runif(5),0)), 
>   b=as.integer(round(runif(5),0)),c=as.integer(round(runif(5),0)))
> # correct results:
> for (c in c(expression(x$a==1),expression(x$b==1),
>   expression(x$c==1))) print(x[eval(c),])
> # results I don't understand:
> for (c in c(expression(x$a==1),expression(x$b==1),
>   expression(x$c==1))) print(subset(x,eval(c)))
> for (c in c(expression(x$a==1),expression(x$b==1),
>   expression(x$c==1))) print(subset(x,c))
> 
> Am I doing something wrong? Using subset this way with R 1.8.0 worked fine.

Not for me!  I get the same wrong results as in 1.9.0 with your code.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ramasamy at cancer.org.uk  Fri Jun  4 16:21:07 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri Jun  4 16:21:11 2004
Subject: [Rd] Suggestions for help pages
In-Reply-To: <Pine.LNX.4.44.0406041431460.25099-100000@gannet.stats>
References: <Pine.LNX.4.44.0406041431460.25099-100000@gannet.stats>
Message-ID: <1086358867.4406.60.camel@vpn202001.lif.icnet.uk>

Dear all,

Can I make two suggestions regarding help pages.

1) Reflect the current package version on the help pages. Example
	truehist {MASS v7.1-14} or truehist {MASS}{7.1-14}

2) Put all of the help.start() pages online like www.perldoc.com. I
realise that there exists
   http://www.maths.lth.se/help/R/.R/doc/html/index.html
   http://stat.ethz.ch/R-manual/R-patched/doc/html/index.html
and few others but it would be nice to have it on an official page or
linked from it. It would also be nice to have these pages updated
automatically everytime there is new package or new version release.

Of course 2) may create some confusion if the package version that the
help page was based on is different from the installed version, which is
why 1) should be considered as well.

Thanks. Hope this helps,

-- 
Adaikalavan Ramasamy <ramasamy@cancer.org.uk>
Cancer Research UK

From lecoutre at stat.ucl.ac.be  Fri Jun  4 16:38:57 2004
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Fri Jun  4 16:39:38 2004
Subject: [Rd] [Wish]: Add "..." argument to library function
Message-ID: <6.0.1.1.2.20040604163037.0224fec0@stat4ux.stat.ucl.ac.be>


Hello,

I would find it very usefull to have the ability to load packages with options.
Consider for example the SciViews package Philippe and me are working on. 
When loading on Windows, it automatically loads the associated GUI 
executable. It should be convenient to have an option not to load the exe 
but still have an access to the R functions of the package.

For that, I think a simple change to 'library' would do the trick, which is 
to add '...' to it, as it is not used for the moment.

The definition of library would then be:

----
function (package, help, pos = 2, lib.loc = NULL, character.only = FALSE,
     logical.return = FALSE, warn.conflicts = TRUE, keep.source = 
getOption("keep.source.pkgs"),
     verbose = getOption("verbose"), version,...)
#
# Stuff removed to show which lines are changed later
#
   .Internal(lib.fixup(loadenv, env))
                 if (exists(".First.lib", mode = "function", envir = env,
                   inherits = FALSE)) {
                   firstlib <- get(".First.lib", mode = "function",
                     envir = env, inherits = FALSE)
                   tt <- try(firstlib(which.lib.loc, package,...))
                   if (inherits(tt, "try-error"))
                     if (logical.return)
                       return(FALSE)
                     else stop(".First.lib failed")
                 }
                 if (!is.null(firstlib <- 
getOption(".First.lib")[[package]])) {
                   tt <- try(firstlib(which.lib.loc, package,...))
                   if (inherits(tt, "try-error"))
                     if (logical.return)
                       return(FALSE)
                     else stop(".First.lib failed")
                 }
---------

Then, in a package, the maintener can decide to include as many options as 
desired within his ".First.lib"

".First.lib" <- function(lib,pkg,showGUI=TRUE,useWidgets="TclTk")
{
	if (showGUI) #
}

I am quite sure many packages could benefit from such an additionnal 
loading options

Eric
Eric Lecoutre
UCL /  Institut de Statistique
Voie du Roman Pays, 20
1348 Louvain-la-Neuve
Belgium

tel: (+32)(0)10473050
lecoutre@stat.ucl.ac.be
http://www.stat.ucl.ac.be/ISpersonnel/lecoutre

If the statistics are boring, then you've got the wrong numbers. -Edward 
Tufte

From andy_liaw at merck.com  Fri Jun  4 17:28:46 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Jun  4 17:29:21 2004
Subject: [Rd] [Wish]: Add "..." argument to library function
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7E1E@usrymx25.merck.com>

IMHO this should be done by the package author(s), without resorting to
changing behavior of library().  I.e., I write a function, say, startGUI(),
that does just that, and print a message in .First.lib() that tells the user
that that's what he/she should execute to startup the GUI.  I believe this
is sort of how it's done in MASS on Windows (or was that MASS in S-PLUS?),
if I remember correctly...

Andy

> From: Eric Lecoutre
> 
> Hello,
> 
> I would find it very usefull to have the ability to load 
> packages with options.
> Consider for example the SciViews package Philippe and me are 
> working on. 
> When loading on Windows, it automatically loads the associated GUI 
> executable. It should be convenient to have an option not to 
> load the exe 
> but still have an access to the R functions of the package.
> 
> For that, I think a simple change to 'library' would do the 
> trick, which is 
> to add '...' to it, as it is not used for the moment.
> 
> The definition of library would then be:
> 
> ----
> function (package, help, pos = 2, lib.loc = NULL, 
> character.only = FALSE,
>      logical.return = FALSE, warn.conflicts = TRUE, keep.source = 
> getOption("keep.source.pkgs"),
>      verbose = getOption("verbose"), version,...)
> #
> # Stuff removed to show which lines are changed later
> #
>    .Internal(lib.fixup(loadenv, env))
>                  if (exists(".First.lib", mode = "function", 
> envir = env,
>                    inherits = FALSE)) {
>                    firstlib <- get(".First.lib", mode = "function",
>                      envir = env, inherits = FALSE)
>                    tt <- try(firstlib(which.lib.loc, package,...))
>                    if (inherits(tt, "try-error"))
>                      if (logical.return)
>                        return(FALSE)
>                      else stop(".First.lib failed")
>                  }
>                  if (!is.null(firstlib <- 
> getOption(".First.lib")[[package]])) {
>                    tt <- try(firstlib(which.lib.loc, package,...))
>                    if (inherits(tt, "try-error"))
>                      if (logical.return)
>                        return(FALSE)
>                      else stop(".First.lib failed")
>                  }
> ---------
> 
> Then, in a package, the maintener can decide to include as 
> many options as 
> desired within his ".First.lib"
> 
> ".First.lib" <- function(lib,pkg,showGUI=TRUE,useWidgets="TclTk")
> {
> 	if (showGUI) #
> }
> 
> I am quite sure many packages could benefit from such an additionnal 
> loading options
> 
> Eric
> Eric Lecoutre
> UCL /  Institut de Statistique
> Voie du Roman Pays, 20
> 1348 Louvain-la-Neuve
> Belgium
> 
> tel: (+32)(0)10473050
> lecoutre@stat.ucl.ac.be
> http://www.stat.ucl.ac.be/ISpersonnel/lecoutre
> 
> If the statistics are boring, then you've got the wrong 
> numbers. -Edward 
> Tufte
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
>

From murray.pung at studentmail.newcastle.edu.au  Sat Jun  5 04:36:55 2004
From: murray.pung at studentmail.newcastle.edu.au (murray.pung@studentmail.newcastle.edu.au)
Date: Sat Jun  5 04:37:00 2004
Subject: [Rd] Crash in OSX (PR#6940)
Message-ID: <20040605023655.74B6910880@slim.kubism.ku.dk>

Full_Name: Murray Pung
Version: 1.9.0
OS: OSX Mac
Submission from: (NULL) (134.148.20.33)


Date/Time:      2004-06-05 12:32:30 +1000
OS Version:     10.3.4 (Build 7H63)
Report Version: 2

Command: R.bin
Path:    /Library/Frameworks/R.framework/Resources/bin/R.bin
Version: 1.9.0 (R 1.9.0)
PID:     358
Thread:  0

Exception:  EXC_BAD_ACCESS (0x0001)
Codes:      KERN_PROTECTION_FAILURE (0x0002) at 0x00000005

Thread 0 Crashed:
0   libSystem.B.dylib   	0x90006e70 strlen + 0x50
1   R_aqua.so           	0x0048699c HistFwd + 0x134 (aquaconsole.c:3451)
2   R_aqua.so           	0x004825c8 KeybHandler + 0xd4 (aquaconsole.c:1370)
3   com.apple.HIToolbox 	0x927d2330 DispatchEventToHandlers + 0x150
4   com.apple.HIToolbox 	0x927d25a4 SendEventToEventTargetInternal + 0x174
5   com.apple.HIToolbox 	0x927d6a0c SendEventToEventTargetWithOptions + 0x28
6   com.apple.HIToolbox 	0x9280b4c0 _Z19HandleKeyboardEventP14OpaqueEventRefm +
0x160
7   com.apple.HIToolbox 	0x927e2fe4
_Z29ToolboxEventDispatcherHandlerP25OpaqueEventHandlerCallRefP14OpaqueEventRefPv
+ 0x1f8
8   com.apple.HIToolbox 	0x927d23ec DispatchEventToHandlers + 0x20c
9   com.apple.HIToolbox 	0x927d25a4 SendEventToEventTargetInternal + 0x174
10  com.apple.HIToolbox 	0x927e4a34 SendEventToEventTarget + 0x28
11  R_aqua.so           	0x004876d0 Raqua_ProcessEvents + 0xa4
(aquaconsole.c:3889)
12  R_aqua.so           	0x0048204c Raqua_ReadConsole + 0x9c
(aquaconsole.c:1228)
13  R.bin               	0x00080c78 Rf_ReplIteration + 0x60 (main.c:200)
14  R.bin               	0x00080f30 R_ReplConsole + 0x88 (main.c:299)
15  R.bin               	0x000818d8 run_Rmainloop + 0x78 (main.c:654)
16  R.bin               	0x000ed7bc main + 0x14 (system.c:102)
17  R.bin               	0x0000204c _start + 0x17c (crt.c:267)
18  R.bin               	0x00001ecc start + 0x30

PPC Thread State:
  srr0: 0x90006e70 srr1: 0x0200f030                vrsave: 0x00000000
    cr: 0x44022244  xer: 0x20000000   lr: 0x0048699c  ctr: 0x90006e20
    r0: 0x0048699c   r1: 0xbffff060   r2: 0x000001f4   r3: 0x00000005
    r4: 0x00000001   r5: 0x00000004   r6: 0x0000007d   r7: 0x004b6870
    r8: 0x004b6870   r9: 0x00000005  r10: 0x004b6870  r11: 0x00494a34
   r12: 0x90006e20  r13: 0x00000000  r14: 0x00000000  r15: 0x00000000
   r16: 0x00000000  r17: 0x00000000  r18: 0x00000000  r19: 0x00000000
   r20: 0x00000002  r21: 0x00000000  r22: 0x05607710  r23: 0x0110d8f0
   r24: 0xbffff270  r25: 0xffffd96e  r26: 0x00000000  r27: 0xbffff180
   r28: 0x00000001  r29: 0x004af55c  r30: 0x004afd2c  r31: 0x00486870

Binary Images Description:
    0x1000 -   0x16dfff R.bin 
/Library/Frameworks/R.framework/Resources/bin/R.bin
  0x47f000 -   0x493fff R_aqua.so 
/Library/Frameworks/R.framework/Resources/modules/R_aqua.so
  0x605000 -   0x62ffff libreadline.4.3.dylib 
/Library/Frameworks/R.framework/Resources/bin/Frameworks/libreadline.4.3.dylib
 0x17b9000 -  0x17bcfff methods.so 
/Library/Frameworks/R.framework/Versions/1.9.0/Resources/library/methods/libs/methods.so
 0x2008000 -  0x217bfff libR.dylib 
/Library/Frameworks/R.framework/Resources/bin/libR.dylib
 0x5489000 -  0x548afff tools.so 
/Library/Frameworks/R.framework/Versions/1.9.0/Resources/library/tools/libs/tools.so
 0x5492000 -  0x54bcfff stats.so 
/Library/Frameworks/R.framework/Versions/1.9.0/Resources/library/stats/libs/stats.so
 0x576a000 -  0x57a4fff vfonts.so 
/Library/Frameworks/R.framework/Resources/modules/vfonts.so
0x8fe00000 - 0x8fe4ffff dyld 	/usr/lib/dyld
0x90000000 - 0x90122fff libSystem.B.dylib 	/usr/lib/libSystem.B.dylib
0x90190000 - 0x9023dfff com.apple.CoreFoundation 6.3.4 (299.31)
/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation
0x90280000 - 0x904f9fff com.apple.CoreServices.CarbonCore 10.3.4
/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/CarbonCore.framework/Versions/A/CarbonCore
0x90570000 - 0x905defff com.apple.framework.IOKit 1.3.2 (???)
/System/Library/Frameworks/IOKit.framework/Versions/A/IOKit
0x90610000 - 0x9069afff com.apple.CoreServices.OSServices 3.0.1
/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/OSServices.framework/Versions/A/OSServices
0x90700000 - 0x90700fff com.apple.CoreServices 10.3 (???)
/System/Library/Frameworks/CoreServices.framework/Versions/A/CoreServices
0x90720000 - 0x90787fff com.apple.audio.CoreAudio 2.1.2
/System/Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio
0x907f0000 - 0x907f9fff com.apple.DiskArbitration 2.0.3
/System/Library/PrivateFrameworks/DiskArbitration.framework/Versions/A/DiskArbitration
0x90810000 - 0x90810fff com.apple.ApplicationServices 1.0 (???)
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/ApplicationServices
0x90910000 - 0x90983fff com.apple.DesktopServices 1.2.2
/System/Library/PrivateFrameworks/DesktopServicesPriv.framework/Versions/A/DesktopServicesPriv
0x90d00000 - 0x90d1bfff com.apple.SystemConfiguration 1.7.1 (???)
/System/Library/Frameworks/SystemConfiguration.framework/Versions/A/SystemConfiguration
0x90d40000 - 0x90d40fff com.apple.Carbon 10.3 (???)
/System/Library/Frameworks/Carbon.framework/Versions/A/Carbon
0x910b0000 - 0x910fffff com.apple.bom 1.2.4 (63)
/System/Library/PrivateFrameworks/Bom.framework/Versions/A/Bom
0x912a0000 - 0x912bdfff com.apple.audio.SoundManager 3.8
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/CarbonSound.framework/Versions/A/CarbonSound
0x912e0000 - 0x912f7fff com.apple.LangAnalysis 1.5.4
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/LangAnalysis.framework/Versions/A/LangAnalysis
0x91320000 - 0x913defff ColorSync 
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ColorSync.framework/Versions/A/ColorSync
0x91460000 - 0x91473fff com.apple.speech.synthesis.framework 3.2
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis
0x914a0000 - 0x91509fff com.apple.htmlrendering 1.1.2
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/HTMLRendering.framework/Versions/A/HTMLRendering
0x91560000 - 0x91619fff com.apple.QD 3.4.64 (???)
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/QD.framework/Versions/A/QD
0x91670000 - 0x916a8fff com.apple.AE 1.3.2
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/AE.framework/Versions/A/AE
0x916e0000 - 0x91773fff com.apple.print.framework.PrintCore 3.3
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore
0x917e0000 - 0x917f0fff com.apple.speech.recognition.framework 3.3
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SpeechRecognition.framework/Versions/A/SpeechRecognition
0x91810000 - 0x9182afff com.apple.openscripting 1.2.1 (???)
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/OpenScripting.framework/Versions/A/OpenScripting
0x91850000 - 0x91860fff com.apple.ImageCapture 2.1.0
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ImageCapture.framework/Versions/A/ImageCapture
0x91890000 - 0x9189cfff com.apple.help 1.0.1
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Help.framework/Versions/A/Help
0x918c0000 - 0x918cdfff com.apple.CommonPanels 1.2.1 (1.0)
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/CommonPanels.framework/Versions/A/CommonPanels
0x918f0000 - 0x9193efff com.apple.print.framework.Print 3.3
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Print.framework/Versions/A/Print
0x91990000 - 0x9199bfff com.apple.securityhi 1.2 (90)
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SecurityHI.framework/Versions/A/SecurityHI
0x919c0000 - 0x91a33fff com.apple.NavigationServices 3.3.1
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/NavigationServices.framework/Versions/A/NavigationServices
0x91ab0000 - 0x91ac4fff libCGATS.A.dylib 
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/CoreGraphics.framework/Versions/A/Resources/libCGATS.A.dylib
0x91ae0000 - 0x91aebfff libCSync.A.dylib 
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/CoreGraphics.framework/Versions/A/Resources/libCSync.A.dylib
0x91b10000 - 0x91b2afff libPDFRIP.A.dylib 
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/CoreGraphics.framework/Versions/A/Resources/libPDFRIP.A.dylib
0x91b50000 - 0x91b5ffff libPSRIP.A.dylib 
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/CoreGraphics.framework/Versions/A/Resources/libPSRIP.A.dylib
0x91b80000 - 0x91b93fff libRIP.A.dylib 
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/CoreGraphics.framework/Versions/A/Resources/libRIP.A.dylib
0x91bb0000 - 0x91d3cfff com.apple.QuickTime 6.4.0
/System/Library/Frameworks/QuickTime.framework/Versions/A/QuickTime
0x92070000 - 0x92096fff com.apple.FindByContent 1.4 (1.2)
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/FindByContent.framework/Versions/A/FindByContent
0x920c0000 - 0x922a7fff com.apple.security 2.3 (176)
/System/Library/Frameworks/Security.framework/Versions/A/Security
0x92430000 - 0x92468fff com.apple.LaunchServices 10.3 (84)
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/LaunchServices
0x92740000 - 0x92777fff com.apple.CFNetwork 1.2.1 (7)
/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/CFNetwork.framework/Versions/A/CFNetwork
0x927d0000 - 0x92b54fff com.apple.HIToolbox 1.3.3 (???)
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/HIToolbox.framework/Versions/A/HIToolbox
0x92d30000 - 0x92d80fff com.apple.HIServices 1.4.1 (0.0.1d1)
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/HIServices.framework/Versions/A/HIServices
0x935d0000 - 0x938a8fff com.apple.CoreGraphics 1.203.20 (???)
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics
0x939a0000 - 0x939b4fff libcups.2.dylib 	/usr/lib/libcups.2.dylib
0x939d0000 - 0x939d4fff libmathCommon.A.dylib 
/usr/lib/system/libmathCommon.A.dylib
0x94060000 - 0x94078fff com.apple.WebServices 1.1.1 (1.1.0)
/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/WebServicesCore.framework/Versions/A/WebServicesCore
0x94120000 - 0x9414bfff libncurses.5.dylib 	/usr/lib/libncurses.5.dylib
0x945b0000 - 0x945b9fff libz.1.dylib 	/usr/lib/libz.1.dylib
0x94610000 - 0x9462afff libresolv.9.dylib 	/usr/lib/libresolv.9.dylib
0x94650000 - 0x946affff com.apple.SearchKit 1.0.2
/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SearchKit.framework/Versions/A/SearchKit
0x94b20000 - 0x94badfff com.apple.ink.framework 55.8
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Ink.framework/Versions/A/Ink
0x954c0000 - 0x95ac6fff libBLAS.dylib 
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
0x95b20000 - 0x95df0fff libLAPACK.dylib 
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib
0x95e40000 - 0x95eadfff libvDSP.dylib 
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvDSP.dylib
0x95f00000 - 0x95f20fff libvMisc.dylib 
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvMisc.dylib
0x968d0000 - 0x969b2fff libicucore.A.dylib 	/usr/lib/libicucore.A.dylib
0x96a20000 - 0x96ae2fff libcrypto.0.9.7.dylib 	/usr/lib/libcrypto.0.9.7.dylib
0x96b40000 - 0x96b6efff libssl.0.9.7.dylib 	/usr/lib/libssl.0.9.7.dylib
0x96bf0000 - 0x96c7ffff ATS 
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/ATS
0x96e80000 - 0x96e90fff com.apple.vecLib 3.0.1 (vecLib 3.0.1)
/System/Library/Frameworks/vecLib.framework/Versions/A/vecLib
0x97510000 - 0x97518fff libbsm.dylib 	/usr/lib/libbsm.dylib

From gregory_r_warnes at groton.pfizer.com  Sat Jun  5 07:58:07 2004
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Sat Jun  5 07:58:14 2004
Subject: [Rd] 'cygpath -d' to fix windows paths with spaces
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20C5214D1@groexmb02.pfizer.com>


The cygwin 'cygpath' command can now convert arbitrary windows and unix
paths into the short ms-dos 8.3 equivalents.  This tools might allow the
windows build system to better deal with those messy long Windows file and
directory names that contain spaces.

EG:

warneg@GRDGROL99X1028: src [1]$ pwd
/cygdrive/c/Documents and Settings/WarnesGR/My
Documents/cygwin_home/src/gregmisc/src

warneg@GRDGROL99X1028: src [1]$ cygpath -d "`pwd`"
c:\DOCUME~1\WarnesGR\MYDOCU~1\CYGWIN~1\src\gregmisc\src

-Greg

Gregory R. Warnes
Manager, Non-Clinical Statistics
Pfizer Global Research and Development



LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

From ripley at stats.ox.ac.uk  Sat Jun  5 08:51:25 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Jun  5 08:51:29 2004
Subject: [Rd] 'cygpath -d' to fix windows paths with spaces
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C20C5214D1@groexmb02.pfizer.com>
Message-ID: <Pine.LNX.4.44.0406050749160.26709-100000@gannet.stats>

This should be done internally already, e.g. in the Perl code and by the 
Rpwd.exe we use.  The problem is to anticipate everything people might 
actually try.

On Sat, 5 Jun 2004, Warnes, Gregory R wrote:

> 
> The cygwin 'cygpath' command can now convert arbitrary windows and unix
> paths into the short ms-dos 8.3 equivalents.  This tools might allow the
> windows build system to better deal with those messy long Windows file and
> directory names that contain spaces.
> 
> EG:
> 
> warneg@GRDGROL99X1028: src [1]$ pwd
> /cygdrive/c/Documents and Settings/WarnesGR/My
> Documents/cygwin_home/src/gregmisc/src
> 
> warneg@GRDGROL99X1028: src [1]$ cygpath -d "`pwd`"
> c:\DOCUME~1\WarnesGR\MYDOCU~1\CYGWIN~1\src\gregmisc\src

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From xiao.gang.fan1 at libertysurf.fr  Sat Jun  5 14:30:55 2004
From: xiao.gang.fan1 at libertysurf.fr (Fan)
Date: Sat Jun  5 14:31:03 2004
Subject: [Rd] Crash of "approx" on extreme case
References: <Pine.LNX.4.44.0406050749160.26709-100000@gannet.stats>
Message-ID: <40C1BCFF.1060707@libertysurf.fr>

 > approx(1:2, c(NA,NA),1.5)

Version: 1.9.0
OS: Windows XP

From ligges at statistik.uni-dortmund.de  Sat Jun  5 14:38:40 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Jun  5 14:37:39 2004
Subject: [Rd] Crash of "approx" on extreme case
In-Reply-To: <40C1BCFF.1060707@libertysurf.fr>
References: <Pine.LNX.4.44.0406050749160.26709-100000@gannet.stats>
	<40C1BCFF.1060707@libertysurf.fr>
Message-ID: <40C1BED0.1000901@statistik.uni-dortmund.de>

Fan wrote:
>  > approx(1:2, c(NA,NA),1.5)
> 
> Version: 1.9.0
> OS: Windows XP
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel


Already fixed in R-patched to be R-1.9.1 in a few weeks:

     o   approx(list(x=rep(NaN,9),y=1:9), xout=NaN) does not seg.fault
     anymore (PR#6809).

Uwe Ligges

From p.dalgaard at biostat.ku.dk  Sat Jun  5 18:01:28 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat Jun  5 18:08:12 2004
Subject: [Rd] R-1.9.1 scheduled for June 21
Message-ID: <x2wu2m6lk7.fsf@biostat.ku.dk>

The release of R-1.9.1 is scheduled for Monday, June 21.

Automatic generation of daily alpha releases should start Monday, June
7 and switch to beta status on Monday, June 14.

It would be good if package maintainers could get any planned changes
done as soon as possible, and test their packages carefully against
the alpha/beta releases.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Simon.Abbuehl at swisscom.com  Sun Jun  6 20:43:11 2004
From: Simon.Abbuehl at swisscom.com (Simon.Abbuehl@swisscom.com)
Date: Sun Jun  6 20:43:15 2004
Subject: [Rd] Abwesenheitsnotiz: error in dbase [id:7831] (PR#6946)
Message-ID: <20040606184311.AD7A11066A@slim.kubism.ku.dk>

Hallo / Hello 

Ich bin abwesend bis am 8. Juni 2004.
Ihre Mails werden nicht weitergeleitet.

I'm out of office until June 8th 2004.
There is no forwarding for your mails.

Freundliche Gr?sse
Kind regards

Simon Abb?hl

From spencer.graves at pdf.com  Sun Jun  6 22:31:55 2004
From: spencer.graves at pdf.com (spencer.graves@pdf.com)
Date: Sun Jun  6 22:31:57 2004
Subject: [Rd] Re: [R] Printing Lattice Graphs from Windows (PR#6947)
Message-ID: <20040606203155.1D9AEAEAB@slim.kubism.ku.dk>

      I agree:  It sounds like a  bug, as you said, Irk, in that 
Rgui.exe cannot copy a metafile to the clipboard, at least under MS 
Windows 2000, 5.00.2195, Service Pack 3, even though Rterm.exe can.  
Therefore, I'm including "r-bugs@biostat.ku.dk" in the list of addresses 
to this email. 

      Spencer Graves

Irk Eddelbuettel wrote:

>On Sun, Jun 06, 2004 at 12:26:45PM -0700, Spencer Graves wrote:
>  
>
>>     Using R 1.9.1 alpha via XEmacs with ESS under Windows 2000, I did 
>>the following: 
>>
>>     library(lattice)
>>     xyplot(1~1)
>>
>>     I got the plot in a separate window, from which I did File -> Copy 
>>to the clipboard -> as a metafile.  I then changed to MS Word, and it 
>>pasted fine. 
>>    
>>
>
>Ok.
> 
>  
>
>>     When I started R 1.9.1 alpha directly (without XEmacs) and tried 
>>the same thing, I got a standard lattice plot.  However, when I tried 
>>File -> Copy to the clipboard -> as a metafile, I got a blank plot when 
>>copying into MS Word.  When I copied as a bitmap, it came through fine.  
>>However, I suspect that is unacceptable. 
>>    
>>
>
>Not ok. 
>
>But isn't it a bug in the windows version of R if the Rgui.exe cannot copy
>to the clipboard where Rterm.exe can?
>
>I may be missing some subtle detail, though... 
>
>Irk
>
>  
>

From ripley at stats.ox.ac.uk  Sun Jun  6 22:42:50 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Jun  6 22:42:58 2004
Subject: [Rd] Re: [R] Printing Lattice Graphs from Windows (PR#6947)
In-Reply-To: <20040606203155.1D9AEAEAB@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406062136451.31642-100000@gannet.stats>

On Sun, 6 Jun 2004 spencer.graves@pdf.com wrote:

>       I agree:  It sounds like a  bug, as you said, Irk, in that 
> Rgui.exe cannot copy a metafile to the clipboard, at least under MS 
> Windows 2000, 5.00.2195, Service Pack 3, even though Rterm.exe can.  

Please send reproducible code to back that up.  I don't believe it is 
anything to do with Rterm.exe vs Rgui.exe, as the phenomenon seems to 
occur randomly under either.  I tested 1.9.0 and 1.9.1 alpha 
(2004-06-06).

Note also that this seems only to occur for grid and lattice plots, and
happens (when it happens) when copying to at least metafile and pdf
devices.


> Therefore, I'm including "r-bugs@biostat.ku.dk" in the list of addresses 
> to this email. 
> 
>       Spencer Graves
> 
> Irk Eddelbuettel wrote:
> 
> >On Sun, Jun 06, 2004 at 12:26:45PM -0700, Spencer Graves wrote:
> >  
> >
> >>     Using R 1.9.1 alpha via XEmacs with ESS under Windows 2000, I did 

Which day's `R 1.9.1 alpha'?

> >>the following: 
> >>
> >>     library(lattice)
> >>     xyplot(1~1)
> >>
> >>     I got the plot in a separate window, from which I did File -> Copy 
> >>to the clipboard -> as a metafile.  I then changed to MS Word, and it 
> >>pasted fine. 
> >>    
> >>
> >
> >Ok.
> > 
> >  
> >
> >>     When I started R 1.9.1 alpha directly (without XEmacs) and tried 
> >>the same thing, I got a standard lattice plot.  However, when I tried 
> >>File -> Copy to the clipboard -> as a metafile, I got a blank plot when 
> >>copying into MS Word.  When I copied as a bitmap, it came through fine.  
> >>However, I suspect that is unacceptable. 
> >>    
> >>
> >
> >Not ok. 
> >
> >But isn't it a bug in the windows version of R if the Rgui.exe cannot copy
> >to the clipboard where Rterm.exe can?
> >
> >I may be missing some subtle detail, though... 
> >
> >Irk
> >
> >  
> >
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From spencer.graves at pdf.com  Sun Jun  6 23:02:01 2004
From: spencer.graves at pdf.com (spencer.graves@pdf.com)
Date: Sun Jun  6 23:02:05 2004
Subject: [Rd] Re: [R] Printing Lattice Graphs from Windows (PR#6948)
Message-ID: <20040606210201.4759E1066B@slim.kubism.ku.dk>

Hi, Duncan: 

      I just did "plot(1:2)" in Rgui.exe, and that copied fine as a 
metafile into MS Word via the clipboard. 

      Then I exited and restarted Rterm.exe under ESS and tried it 
again.  This time, I got a blank image copied into MS Word.  However, 
after I modified the Lattice defaults via, 
"trellis.par.set('background', list('white')); 
trellis.par.set('plot.symbol',  list(cex=0.8, col=1, font=1, pch=1))", I 
was able to copy the results of "xyplot(1~1)" as a metafile into Word.  
Unfortunately, when I tried modifying the Lattice defaults the same way 
under Rgui.exe. I again got a blank image copied into Word. 

      hope this helps.  spencer graves

#######################
Duncan Murdoch wrote:

On Sun, 6 Jun 2004 15:00:52 -0500, Dirk Eddelbuettel <edd@debian.org>
wrote:


>But isn't it a bug in the windows version of R if the Rgui.exe cannot copy
>to the clipboard where Rterm.exe can?
>  
>

Yes, definitely.  Can someone distill this down to code that uses only
the base packages (e.g. just grid)?  Lattice is a recommended package,
so I'd refer you to its maintainer, but it's probably something in a
base package that's going wrong.

Once you've done that, please submit it as a bug report with
reproducible code.  I've never looked at the Windows metafile device
driver, so it's unlikely I'll fix this by 1.9.1, but it is something
that should be fixed.

Duncan Murdoch

Spencer Graves wrote:

>      I agree:  It sounds like a  bug, as you said, Irk, in that 
> Rgui.exe cannot copy a metafile to the clipboard, at least under MS 
> Windows 2000, 5.00.2195, Service Pack 3, even though Rterm.exe can.  
> Therefore, I'm including "r-bugs@biostat.ku.dk" in the list of 
> addresses to this email.
>      Spencer Graves
>
> Irk Eddelbuettel wrote:
>
>> On Sun, Jun 06, 2004 at 12:26:45PM -0700, Spencer Graves wrote:
>>  
>>
>>>     Using R 1.9.1 alpha via XEmacs with ESS under Windows 2000, I 
>>> did the following:
>>>     library(lattice)
>>>     xyplot(1~1)
>>>
>>>     I got the plot in a separate window, from which I did File -> 
>>> Copy to the clipboard -> as a metafile.  I then changed to MS Word, 
>>> and it pasted fine.   
>>
>>
>> Ok.
>>
>>  
>>
>>>     When I started R 1.9.1 alpha directly (without XEmacs) and tried 
>>> the same thing, I got a standard lattice plot.  However, when I 
>>> tried File -> Copy to the clipboard -> as a metafile, I got a blank 
>>> plot when copying into MS Word.  When I copied as a bitmap, it came 
>>> through fine.  However, I suspect that is unacceptable.   
>>
>>
>> Not ok.
>> But isn't it a bug in the windows version of R if the Rgui.exe cannot 
>> copy
>> to the clipboard where Rterm.exe can?
>>
>> I may be missing some subtle detail, though...
>> Irk
>>
>>  
>>
>
> ______________________________________________
> R-help@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

From ripley at stats.ox.ac.uk  Sun Jun  6 23:11:12 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Jun  6 23:11:19 2004
Subject: [Rd] Re: [R] Printing Lattice Graphs from Windows (PR#6948)
In-Reply-To: <20040606210201.4759E1066B@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406062207570.31642-100000@gannet.stats>

It does *not* help to generate a new bug report when replying to a message 
to R-devel: please be more careful.  The PR number is PR#6947.

On Sun, 6 Jun 2004 spencer.graves@pdf.com wrote:

> Hi, Duncan: 
> 
>       I just did "plot(1:2)" in Rgui.exe, and that copied fine as a 
> metafile into MS Word via the clipboard. 
> 
>       Then I exited and restarted Rterm.exe under ESS and tried it 
> again.  This time, I got a blank image copied into MS Word.  However, 

A blank image from "plot(1:2)"?  That's news.  As I have now posted twice, 
there is something random here (probably depending on some uninitialized 
variable), so only the results of repeated testing are of any value.

> after I modified the Lattice defaults via, 
> "trellis.par.set('background', list('white')); 
> trellis.par.set('plot.symbol',  list(cex=0.8, col=1, font=1, pch=1))", I 
> was able to copy the results of "xyplot(1~1)" as a metafile into Word.  
> Unfortunately, when I tried modifying the Lattice defaults the same way 
> under Rgui.exe. I again got a blank image copied into Word. 
> 
>       hope this helps.  spencer graves
> 
> #######################
> Duncan Murdoch wrote:
> 
> On Sun, 6 Jun 2004 15:00:52 -0500, Dirk Eddelbuettel <edd@debian.org>
> wrote:
> 
> 
> >But isn't it a bug in the windows version of R if the Rgui.exe cannot copy
> >to the clipboard where Rterm.exe can?
> >  
> >
> 
> Yes, definitely.  Can someone distill this down to code that uses only
> the base packages (e.g. just grid)?  Lattice is a recommended package,
> so I'd refer you to its maintainer, but it's probably something in a
> base package that's going wrong.
> 
> Once you've done that, please submit it as a bug report with
> reproducible code.  I've never looked at the Windows metafile device
> driver, so it's unlikely I'll fix this by 1.9.1, but it is something
> that should be fixed.
> 
> Duncan Murdoch
> 
> Spencer Graves wrote:
> 
> >      I agree:  It sounds like a  bug, as you said, Irk, in that 
> > Rgui.exe cannot copy a metafile to the clipboard, at least under MS 
> > Windows 2000, 5.00.2195, Service Pack 3, even though Rterm.exe can.  
> > Therefore, I'm including "r-bugs@biostat.ku.dk" in the list of 
> > addresses to this email.
> >      Spencer Graves
> >
> > Irk Eddelbuettel wrote:
> >
> >> On Sun, Jun 06, 2004 at 12:26:45PM -0700, Spencer Graves wrote:
> >>  
> >>
> >>>     Using R 1.9.1 alpha via XEmacs with ESS under Windows 2000, I 
> >>> did the following:
> >>>     library(lattice)
> >>>     xyplot(1~1)
> >>>
> >>>     I got the plot in a separate window, from which I did File -> 
> >>> Copy to the clipboard -> as a metafile.  I then changed to MS Word, 
> >>> and it pasted fine.   
> >>
> >>
> >> Ok.
> >>
> >>  
> >>
> >>>     When I started R 1.9.1 alpha directly (without XEmacs) and tried 
> >>> the same thing, I got a standard lattice plot.  However, when I 
> >>> tried File -> Copy to the clipboard -> as a metafile, I got a blank 
> >>> plot when copying into MS Word.  When I copied as a bitmap, it came 
> >>> through fine.  However, I suspect that is unacceptable.   
> >>
> >>
> >> Not ok.
> >> But isn't it a bug in the windows version of R if the Rgui.exe cannot 
> >> copy
> >> to the clipboard where Rterm.exe can?
> >>
> >> I may be missing some subtle detail, though...
> >> Irk
> >>
> >>  
> >>
> >
> > ______________________________________________
> > R-help@stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From edd at debian.org  Mon Jun  7 00:06:54 2004
From: edd at debian.org (edd@debian.org)
Date: Mon Jun  7 00:06:55 2004
Subject: [Rd] Re: [R] Printing Lattice Graphs from Windows (PR#6949)
Message-ID: <20040606220654.083FF10669@slim.kubism.ku.dk>

On Sun, Jun 06, 2004 at 01:32:00PM -0700, Spencer Graves wrote:
>      I agree:  It sounds like a  bug, as you said, Irk, in that 

That brilliant :)  Many people, in Germany as well as abroad, managed to
chop Eddelbuettel quite well. Turning Dirk into Irk is rather unsurpassed.

Dirk, with a big grin

-- 
FEATURE:  VW Beetle license plate in California

From p.dalgaard at biostat.ku.dk  Mon Jun  7 00:30:16 2004
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Mon Jun  7 00:30:21 2004
Subject: [Rd] Re: [R] Printing Lattice Graphs from Windows (PR#6950)
Message-ID: <20040606223016.B4EC510668@slim.kubism.ku.dk>

Dirk Eddelbuettel <edd@debian.org> writes:

> On Sun, Jun 06, 2004 at 01:32:00PM -0700, Spencer Graves wrote:
> >      I agree:  It sounds like a  bug, as you said, Irk, in that 
> 
> That brilliant :)  Many people, in Germany as well as abroad, managed to
> chop Eddelbuettel quite well. Turning Dirk into Irk is rather unsurpassed.
> 
> Dirk, with a big grin

Not to say "smirk", Dirk. (Did Spencer's quirk irk Dirk?) ;-)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Mon Jun  7 00:33:36 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Jun  7 00:40:23 2004
Subject: [Rd] Re: [R] Printing Lattice Graphs from Windows (PR#6950)
In-Reply-To: <20040606223016.B4EC510668@slim.kubism.ku.dk>
References: <20040606223016.B4EC510668@slim.kubism.ku.dk>
Message-ID: <x2ekosmi4f.fsf@biostat.ku.dk>

p.dalgaard@biostat.ku.dk writes:

> > Dirk, with a big grin
> 
> Not to say "smirk", Dirk. (Did Spencer's quirk irk Dirk?) ;-)

Argh. Now I fell for it. 

Watch out for Cc's so as not to generate add'l bug reports. And please
don't Cc bug reports, or this sort of thing will happen.

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From spencer.graves at pdf.com  Mon Jun  7 01:06:21 2004
From: spencer.graves at pdf.com (spencer.graves@pdf.com)
Date: Mon Jun  7 01:06:23 2004
Subject: [Rd] Re: [R] Printing Lattice Graphs from Windows (PR#6951)
Message-ID: <20040606230621.D56ED10668@slim.kubism.ku.dk>

Entschuldigung!  My English spellchecker failed me again.  spencer graves

Peter Dalgaard wrote:

>Dirk Eddelbuettel <edd@debian.org> writes:
>
>  
>
>>On Sun, Jun 06, 2004 at 01:32:00PM -0700, Spencer Graves wrote:
>>    
>>
>>>     I agree:  It sounds like a  bug, as you said, Irk, in that 
>>>      
>>>
>>That brilliant :)  Many people, in Germany as well as abroad, managed to
>>chop Eddelbuettel quite well. Turning Dirk into Irk is rather unsurpassed.
>>
>>Dirk, with a big grin
>>    
>>
>
>Not to say "smirk", Dirk. (Did Spencer's quirk irk Dirk?) ;-)
>
>  
>

From ckjmaner at carolina.rr.com  Mon Jun  7 01:11:12 2004
From: ckjmaner at carolina.rr.com (ckjmaner@carolina.rr.com)
Date: Mon Jun  7 01:11:14 2004
Subject: [Rd] RE: [R] Printing Lattice Graphs from Windows (PR#6952)
Message-ID: <20040606231112.4F1B810668@slim.kubism.ku.dk>


Hi folks.  It looks like it's stirred some discussion ultimately
resulting/concluding that this phenomena is a possible bug either in the
lattice package or in R 1.9.0/1.9.1 itself.  So, I'll stay tuned, so to
speak, for either an update in the lattice package or R as it seems that
that's where the bug may lie.  FYI, the resulting plot, (e.g., plot(1~1)),
worked as it should either printing or as a copy and paste as a metafile
which causes me to believe it's in the lattice package.

I appreciate you guys looking into this.  (As you may/may not, for some us
corporate folk, data mining is (1) pulling data, (2) producing a graphical
representation of a story/hypothesis from the data and (3) pasting it into
MS Word and/or MS PowerPoint for presentation quickly.  So, to much of you
all's potential satisfaction, a number of us use R instead of S-Plus.)


Thanks,
Charles

-----Original Message-----
From: Spencer Graves [mailto:spencer.graves@pdf.com] 
Sent: Sunday, June 06, 2004 5:02 PM
To: Spencer Graves
Cc: Dirk Eddelbuettel; r-bugs@biostat.ku.dk; Ulises Mora Alvarez;
r-help@stat.math.ethz.ch; Charles and Kimberly Maner
Subject: Re: [R] Printing Lattice Graphs from Windows

Hi, Duncan: 

      I just did "plot(1:2)" in Rgui.exe, and that copied fine as a metafile
into MS Word via the clipboard. 

      Then I exited and restarted Rterm.exe under ESS and tried it again.
This time, I got a blank image copied into MS Word.  However, after I
modified the Lattice defaults via, "trellis.par.set('background',
list('white')); trellis.par.set('plot.symbol',  list(cex=0.8, col=1, font=1,
pch=1))", I was able to copy the results of "xyplot(1~1)" as a metafile into
Word.  
Unfortunately, when I tried modifying the Lattice defaults the same way
under Rgui.exe. I again got a blank image copied into Word. 

      hope this helps.  spencer graves

#######################
Duncan Murdoch wrote:

On Sun, 6 Jun 2004 15:00:52 -0500, Dirk Eddelbuettel <edd@debian.org>
wrote:


>But isn't it a bug in the windows version of R if the Rgui.exe cannot 
>copy to the clipboard where Rterm.exe can?
>  
>

Yes, definitely.  Can someone distill this down to code that uses only the
base packages (e.g. just grid)?  Lattice is a recommended package, so I'd
refer you to its maintainer, but it's probably something in a base package
that's going wrong.

Once you've done that, please submit it as a bug report with reproducible
code.  I've never looked at the Windows metafile device driver, so it's
unlikely I'll fix this by 1.9.1, but it is something that should be fixed.

Duncan Murdoch

Spencer Graves wrote:

>      I agree:  It sounds like a  bug, as you said, Irk, in that 
> Rgui.exe cannot copy a metafile to the clipboard, at least under MS 
> Windows 2000, 5.00.2195, Service Pack 3, even though Rterm.exe can.
> Therefore, I'm including "r-bugs@biostat.ku.dk" in the list of 
> addresses to this email.
>      Spencer Graves
>
> Irk Eddelbuettel wrote:
>
>> On Sun, Jun 06, 2004 at 12:26:45PM -0700, Spencer Graves wrote:
>>  
>>
>>>     Using R 1.9.1 alpha via XEmacs with ESS under Windows 2000, I 
>>> did the following:
>>>     library(lattice)
>>>     xyplot(1~1)
>>>
>>>     I got the plot in a separate window, from which I did File -> 
>>> Copy to the clipboard -> as a metafile.  I then changed to MS Word,
>>> and it pasted fine.   
>>
>>
>> Ok.
>>
>>  
>>
>>>     When I started R 1.9.1 alpha directly (without XEmacs) and tried 
>>> the same thing, I got a standard lattice plot.  However, when I 
>>> tried File -> Copy to the clipboard -> as a metafile, I got a blank 
>>> plot when copying into MS Word.  When I copied as a bitmap, it came
>>> through fine.  However, I suspect that is unacceptable.   
>>
>>
>> Not ok.
>> But isn't it a bug in the windows version of R if the Rgui.exe cannot 
>> copy to the clipboard where Rterm.exe can?
>>
>> I may be missing some subtle detail, though...
>> Irk
>>
>>  
>>
>
> ______________________________________________
> R-help@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

From csmail at support.prognet.com  Mon Jun  7 10:24:41 2004
From: csmail at support.prognet.com (csmail@support.prognet.com)
Date: Mon Jun  7 10:24:47 2004
Subject: [Rd] We will not receive your email
Message-ID: <200406070824.i578Of8C004400@support.real.com>

Greetings,

You have received this message as a result of replying via email
to a RealNetworks Order Receipt or Customer Service message.  

We will -not- receive this email, and have no means of responding.

If you received this mail as a result of replying to your Order
Receipt from our e-commerce system at www.real.com or 
www.realstore.com, you will need to submit your service request
at the following URL:

     http://service.real.com/faq/contcs.html

If you received this message as a result of replying to a customer
service response, there are instructions on how to reply to
the customer service agent that responded to your inquiry. This reply 
method is handled with a web form, and you may find the URL in the
Customer Service response message.  

Thanks again for seeking assistance, and we hope that your problem is
resolved shortly.

Best regards,

Customer Service 
RealNetworks, Inc.

From ligges at statistik.uni-dortmund.de  Mon Jun  7 14:14:07 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Jun  7 14:13:04 2004
Subject: [Rd] R-1.9.1 scheduled for June 21
In-Reply-To: <x2wu2m6lk7.fsf@biostat.ku.dk>
References: <x2wu2m6lk7.fsf@biostat.ku.dk>
Message-ID: <40C45C0F.7000206@statistik.uni-dortmund.de>

Peter Dalgaard wrote:

> The release of R-1.9.1 is scheduled for Monday, June 21.
> 
> Automatic generation of daily alpha releases should start Monday, June
> 7 and switch to beta status on Monday, June 14.
> 
> It would be good if package maintainers could get any planned changes
> done as soon as possible, and test their packages carefully against
> the alpha/beta releases.
> 

Besser, aber geht noch nicht ganz ...


Kannst Du den ganzen Kram unter
  ..../GfKl2004/admin/
bitte auch noch anpassen?

Danke!

Uwe

From ligges at statistik.uni-dortmund.de  Mon Jun  7 14:16:29 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Jun  7 14:15:26 2004
Subject: [Rd] R-1.9.1 scheduled for June 21
In-Reply-To: <40C45C0F.7000206@statistik.uni-dortmund.de>
References: <x2wu2m6lk7.fsf@biostat.ku.dk>
	<40C45C0F.7000206@statistik.uni-dortmund.de>
Message-ID: <40C45C9D.6010608@statistik.uni-dortmund.de>

Uwe Ligges wrote:

> Peter Dalgaard wrote:
> 
>> The release of R-1.9.1 is scheduled for Monday, June 21.
>>
>> Automatic generation of daily alpha releases should start Monday, June
>> 7 and switch to beta status on Monday, June 14.
>>
>> It would be good if package maintainers could get any planned changes
>> done as soon as possible, and test their packages carefully against
>> the alpha/beta releases.
>>
> 
> Besser, aber geht noch nicht ganz ...
> 
> 
> Kannst Du den ganzen Kram unter
>  ..../GfKl2004/admin/
> bitte auch noch anpassen?
> 
> Danke!
> 
> Uwe


Whhoooooops. My apologies!
I thought I'm answering to a completely different mail.

Too much stuff at once and not enough coffee in my veins,
Uwe

From tplate at blackmesacapital.com  Mon Jun  7 18:59:27 2004
From: tplate at blackmesacapital.com (tplate@blackmesacapital.com)
Date: Mon Jun  7 18:59:30 2004
Subject: [Rd] strange apparently data-dependent crash with large data
	(PR#6955)
Message-ID: <20040607165927.D6BD8108F1@slim.kubism.ku.dk>

I'm consistently seeing R crash with a particular large data set.  What's 
strange is that although the crash seems related to running out of memory, 
I'm unable to construct a pseudo-random data set of the same size that also 
causes the crash.  Further adding to the strangeness is that the crash only 
happens if the dataset goes through a save()/load() cycle -- without that, 
the command in question just gives an out-of-memory error, but does not crash.

To make this clear, three different versions of the same data consistently 
produce very different behavior:

(1) original data read with read.table: memory error; fail to allocate 
164062 Kb
(2) original data through save()/load() cycle: memory error; fail to 
allocate 82031 Kb, followed by crash
(3) psuedo-random data of same size and similar characteristics: works 
without problem

This is with R-1.9.0 under Windows 2000.  I'm not loading any optional 
packages.  I get the same crash behavior with R-1.9.0 patched, and R-2.0.0 
alpha, but I didn't test success with the psuedo-random data under those 
programs.  (In case it matters, I got R-1.9.0 patched and R-2.0.0 alpha as 
pre-compiled Windows binaries from http://cran.us.r-project.org/ at 9:30am 
MDT on Jun 7, 2004.)  Unfortunately, I don't have sufficient knowledge of 
how to debug memory problems in R to make further progress than I've made 
here, but maybe the following will provide some clues for someone else.

All the following transcripts are from Rgui.exe, with new runs at each 
comment beginning with "###"

### Read in the data and get a out-of-memory error (but no crash)
 > # ClassifyTrain.txt is from http://mill.ucsd.edu/data/ClassifyTrain.zip
 > X <- read.table("ClassifyTrain.txt", skip=2)
 > X1 <- as.matrix(X)
 > hist(log(X1[,-(1:2)]+1))
Error: cannot allocate vector of size 164062 Kb
In addition: Warning message:
Reached total allocation of 1024Mb: see help(memory.size)
 >

### Read in the data and save it as a .RData file for faster runs (I 
initially did this for speed,
### but this seems to be essential to causing the crash)
 > # ClassifyTrain.txt is from http://mill.ucsd.edu/data/ClassifyTrain.zip
 > X <- read.table("ClassifyTrain.txt", skip=2)
 > X1 <- as.matrix(X)
 > c(class(X1), storage.mode(X1), dim(X1))
[1] "matrix" "double" "30000"  "702"
 > save(list="X1", file="X1.RData")

### Produce the crash
 > version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.0
year     2004
month    04
day      12
language R
 >
 > load("X1.RData")
 > c(class(X1), storage.mode(X1), dim(X1))
[1] "matrix" "double" "30000"  "702"
 > # all of the following 3 command consistently cause a crash
 > hist(log(X1[,-(1:2)]+1))
 > hist(log(X1[,-(1:2)]+1), breaks=seq(0,13,0.5))
 > hist(log(X1[,-(1:2)]+1), breaks=seq(0,13,0.5), plot=F)
Error: cannot allocate vector of size 82031 Kb
In addition: Warning message:
Reached total allocation of 1024Mb: see help(memory.size)

[message that comes in a Windows dialog box after a wait of many seconds:]

R Console: Rgui.exe - Application Error
The exception unknown software exception (0xc00000fd) occured in the 
application at location 0x6b5b0a53

#### The following is a failed attempt to reproduce the crash with 
psuedo-random
#### data, i.e., R functions correctly (even when X1 is in memory)
 >
 > # Look at some characteristics of the original data in
 > # order to produce a matrix of similar psuedo-random numbers.
 > load("X1.RData")
 > dim(X1)
[1] 30000   702
 > class(X1)
[1] "matrix"
 > storage.mode(X1)
[1] "double"
 > table(is.na(X1))

    FALSE
21060000
 > table(X1==0)

    FALSE     TRUE
  2284455 18775545
 > exp(diff(log(table(X1==0))))
     TRUE
8.218829
 > table(X1>=0)

     TRUE
21060000
 > range(X1)
[1]      0 326022
 > memory.limit()
[1] 1073741824
 > memory.limit()/2^20
[1] 1024
 > object.size(X1)/2^20
[1] 161.0267
 >
 > set.seed(1)
 > X <- matrix(rexp(30000 * 702, 5e-5) * rbinom(30000 * 702, 1, 1/8), ncol=702)
 > range(X)
[1] 3.615044e-04 3.249415e+05
 >
 > # Both of thse commands seem to work without problems
 > hist(log(X[,-(1:2)]+1))
 > hist(log(X[,-(1:2)]+1), breaks=seq(0,13,0.5))

From ripley at stats.ox.ac.uk  Mon Jun  7 19:40:17 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jun  7 19:40:24 2004
Subject: (PR#6955) Re: [Rd] strange apparently data-dependent crash with
	large data
In-Reply-To: <20040607165927.D6BD8108F1@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406071836090.13771-100000@gannet.stats>

It is not very surprising that the R process might crash once the maximum 
memory limit is reached.  View anything done in a session after that as 
suspect.  (The Unix equivalent is often to crash without even telling you 
that you are out of memory.)

On Mon, 7 Jun 2004 tplate@blackmesacapital.com wrote:

> I'm consistently seeing R crash with a particular large data set.  What's 
> strange is that although the crash seems related to running out of memory, 
> I'm unable to construct a pseudo-random data set of the same size that also 
> causes the crash.  Further adding to the strangeness is that the crash only 
> happens if the dataset goes through a save()/load() cycle -- without that, 
> the command in question just gives an out-of-memory error, but does not crash.
> 
> To make this clear, three different versions of the same data consistently 
> produce very different behavior:
> 
> (1) original data read with read.table: memory error; fail to allocate 
> 164062 Kb
> (2) original data through save()/load() cycle: memory error; fail to 
> allocate 82031 Kb, followed by crash
> (3) psuedo-random data of same size and similar characteristics: works 
> without problem
> 
> This is with R-1.9.0 under Windows 2000.  I'm not loading any optional 
> packages.  I get the same crash behavior with R-1.9.0 patched, and R-2.0.0 
> alpha, but I didn't test success with the psuedo-random data under those 
> programs.  (In case it matters, I got R-1.9.0 patched and R-2.0.0 alpha as 
> pre-compiled Windows binaries from http://cran.us.r-project.org/ at 9:30am 
> MDT on Jun 7, 2004.)  Unfortunately, I don't have sufficient knowledge of 
> how to debug memory problems in R to make further progress than I've made 
> here, but maybe the following will provide some clues for someone else.
> 
> All the following transcripts are from Rgui.exe, with new runs at each 
> comment beginning with "###"
> 
> ### Read in the data and get a out-of-memory error (but no crash)
>  > # ClassifyTrain.txt is from http://mill.ucsd.edu/data/ClassifyTrain.zip
>  > X <- read.table("ClassifyTrain.txt", skip=2)
>  > X1 <- as.matrix(X)
>  > hist(log(X1[,-(1:2)]+1))
> Error: cannot allocate vector of size 164062 Kb
> In addition: Warning message:
> Reached total allocation of 1024Mb: see help(memory.size)
>  >
> 
> ### Read in the data and save it as a .RData file for faster runs (I 
> initially did this for speed,
> ### but this seems to be essential to causing the crash)
>  > # ClassifyTrain.txt is from http://mill.ucsd.edu/data/ClassifyTrain.zip
>  > X <- read.table("ClassifyTrain.txt", skip=2)
>  > X1 <- as.matrix(X)
>  > c(class(X1), storage.mode(X1), dim(X1))
> [1] "matrix" "double" "30000"  "702"
>  > save(list="X1", file="X1.RData")
> 
> ### Produce the crash
>  > version
>           _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    9.0
> year     2004
> month    04
> day      12
> language R
>  >
>  > load("X1.RData")
>  > c(class(X1), storage.mode(X1), dim(X1))
> [1] "matrix" "double" "30000"  "702"
>  > # all of the following 3 command consistently cause a crash
>  > hist(log(X1[,-(1:2)]+1))
>  > hist(log(X1[,-(1:2)]+1), breaks=seq(0,13,0.5))
>  > hist(log(X1[,-(1:2)]+1), breaks=seq(0,13,0.5), plot=F)
> Error: cannot allocate vector of size 82031 Kb
> In addition: Warning message:
> Reached total allocation of 1024Mb: see help(memory.size)
> 
> [message that comes in a Windows dialog box after a wait of many seconds:]
> 
> R Console: Rgui.exe - Application Error
> The exception unknown software exception (0xc00000fd) occured in the 
> application at location 0x6b5b0a53
> 
> #### The following is a failed attempt to reproduce the crash with 
> psuedo-random
> #### data, i.e., R functions correctly (even when X1 is in memory)
>  >
>  > # Look at some characteristics of the original data in
>  > # order to produce a matrix of similar psuedo-random numbers.
>  > load("X1.RData")
>  > dim(X1)
> [1] 30000   702
>  > class(X1)
> [1] "matrix"
>  > storage.mode(X1)
> [1] "double"
>  > table(is.na(X1))
> 
>     FALSE
> 21060000
>  > table(X1==0)
> 
>     FALSE     TRUE
>   2284455 18775545
>  > exp(diff(log(table(X1==0))))
>      TRUE
> 8.218829
>  > table(X1>=0)
> 
>      TRUE
> 21060000
>  > range(X1)
> [1]      0 326022
>  > memory.limit()
> [1] 1073741824
>  > memory.limit()/2^20
> [1] 1024
>  > object.size(X1)/2^20
> [1] 161.0267
>  >
>  > set.seed(1)
>  > X <- matrix(rexp(30000 * 702, 5e-5) * rbinom(30000 * 702, 1, 1/8), ncol=702)
>  > range(X)
> [1] 3.615044e-04 3.249415e+05
>  >
>  > # Both of thse commands seem to work without problems
>  > hist(log(X[,-(1:2)]+1))
>  > hist(log(X[,-(1:2)]+1), breaks=seq(0,13,0.5))
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dmurdoch at pair.com  Mon Jun  7 20:14:57 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon Jun  7 20:14:54 2004
Subject: [Rd] strange apparently data-dependent crash with large data
	(PR#6955)
In-Reply-To: <20040607165927.D6BD8108F1@slim.kubism.ku.dk>
References: <20040607165927.D6BD8108F1@slim.kubism.ku.dk>
Message-ID: <62c9c01e9n6c97icd6jf36v10euvdr0htk@4ax.com>

On Mon,  7 Jun 2004 18:59:27 +0200 (CEST), tplate@blackmesacapital.com
wrote :

>I'm consistently seeing R crash with a particular large data set.  What's 
>strange is that although the crash seems related to running out of memory, 
>I'm unable to construct a pseudo-random data set of the same size that also 
>causes the crash.  Further adding to the strangeness is that the crash only 
>happens if the dataset goes through a save()/load() cycle -- without that, 
>the command in question just gives an out-of-memory error, but does not crash.

This kind of error is very difficult to debug.  What's likely
happening is that in one case you run out of memory at a place with a
correct check, and in the other you are hitting some flaky code that
assumes every memory allocation is guaranteed to succeed.

You could install DrMinGW (which produces a stack dump when you
crash), but it's not necessarily informative:  often the crash occurs
relatively distantly from the buggy code that caused it.

The other problem with this kind of error is that it may well
disappear if you run under a debugger, since that will make you run
out of memory at a different spot, and it may not appear on a
different machine.  For example, I ran your examples and they all
failed because R ran out of memory, but none crashed.

Duncan Murdoch

From gb at stat.umu.se  Mon Jun  7 23:26:44 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon Jun  7 23:26:29 2004
Subject: [Rd] R-1.9.1 scheduled for June 21
In-Reply-To: <x2wu2m6lk7.fsf@biostat.ku.dk>
References: <x2wu2m6lk7.fsf@biostat.ku.dk>
Message-ID: <20040607212644.GB16749@stat.umu.se>

On Sat, Jun 05, 2004 at 06:01:28PM +0200, Peter Dalgaard wrote:
> The release of R-1.9.1 is scheduled for Monday, June 21.
> 
> Automatic generation of daily alpha releases should start Monday, June
> 7 and switch to beta status on Monday, June 14.

And where can I find these releases?

-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb@stat.umu.se

From p.dalgaard at biostat.ku.dk  Mon Jun  7 23:39:47 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Jun  7 23:46:41 2004
Subject: [Rd] R-1.9.1 scheduled for June 21
In-Reply-To: <20040607212644.GB16749@stat.umu.se>
References: <x2wu2m6lk7.fsf@biostat.ku.dk> <20040607212644.GB16749@stat.umu.se>
Message-ID: <x27juj2gkc.fsf@biostat.ku.dk>

G?ran Brostr?m <gb@stat.umu.se> writes:

> On Sat, Jun 05, 2004 at 06:01:28PM +0200, Peter Dalgaard wrote:
> > The release of R-1.9.1 is scheduled for Monday, June 21.
> > 
> > Automatic generation of daily alpha releases should start Monday, June
> > 7 and switch to beta status on Monday, June 14.
> 
> And where can I find these releases?

Hmmm... They should turn up at CRAN, but they are not there yet. The
version from today has been created on cvs.r-project.org in
/var/rsync/cran/src/base/ which should be mirrored into
http://cran.r-project.org/src/base, but we might have a timing issue.
(All of this stuff got changed a bit haphazardly due to the break-in
just before 1.9.0)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From gb at stat.umu.se  Tue Jun  8 08:24:20 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue Jun  8 08:24:05 2004
Subject: [Rd] R-1.9.1 scheduled for June 21
In-Reply-To: <x27juj2gkc.fsf@biostat.ku.dk>
References: <x2wu2m6lk7.fsf@biostat.ku.dk> <20040607212644.GB16749@stat.umu.se>
	<x27juj2gkc.fsf@biostat.ku.dk>
Message-ID: <20040608062420.GA21463@stat.umu.se>

On Mon, Jun 07, 2004 at 11:39:47PM +0200, Peter Dalgaard wrote:
> G?ran Brostr?m <gb@stat.umu.se> writes:
> 
> > On Sat, Jun 05, 2004 at 06:01:28PM +0200, Peter Dalgaard wrote:
> > > The release of R-1.9.1 is scheduled for Monday, June 21.
> > > 
> > > Automatic generation of daily alpha releases should start Monday, June
> > > 7 and switch to beta status on Monday, June 14.
> > 
> > And where can I find these releases?
> 
> Hmmm... They should turn up at CRAN, but they are not there yet. 

Yes, it is there now. I asked because it appeared from the r-help list
yesterday as if someone had got his hands on it.

Thanks,

G?ran

From otoomet at econ.dk  Tue Jun  8 11:37:09 2004
From: otoomet at econ.dk (otoomet@econ.dk)
Date: Tue Jun  8 11:37:14 2004
Subject: [Rd] make fails with utf-8 locale, RH9 (PR#6958)
Message-ID: <20040608093709.75495108FB@slim.kubism.ku.dk>

Hi,

I have an RH9 box (gcc (GCC) 3.2.2, perl 5.8.0, make 3.79.1).  My
locale is

LANG="et_EE.UTF-8"

I do:

$ ./configure --prefix=/usr/local
...
$ make
...
make[4]: Entering directory `/home/otoomet/a/R-1.9.0/src/library/stats4'
dumping R code in package 'stats4'
Error in structure(c(unlist(lapply(list(...), unclass))), class = c("POSIXt",  : 
        couldn't find function "unlist"
Execution halted
...

make stops with similar error messages later.

when I say now

$ LANG="" make

everything works OK.

I can supply further information if you consider the problem worth of
investigating/mentioning in docs.

Thanks for R!

Ott

-- 
Ott Toomet
PhD Student

Dept. of Economics
?rhus University
Building 322
Universitetsparken
8000 ?rhus C
Denmark

otoomet (a) econ au dk
ph: (+45) 89 42 20 40
-------------------------------------------

 (o_         (*_         (O_         (o< -!  
//\         //\         //\         //\      
V_/_        V_/_        V_/_        V_/_     
					     
standard    drunken     shocked     noisy    
penguin     penguin     penguin     penguin

From dmurdoch at pair.com  Tue Jun  8 14:14:40 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Jun  8 14:14:37 2004
Subject: [Rd] R-1.9.1 scheduled for June 21
In-Reply-To: <20040608062420.GA21463@stat.umu.se>
References: <x2wu2m6lk7.fsf@biostat.ku.dk> <20040607212644.GB16749@stat.umu.se>
	<x27juj2gkc.fsf@biostat.ku.dk> <20040608062420.GA21463@stat.umu.se>
Message-ID: <8cbbc01bsg9gmlk67k9leuneit4ff300gt@4ax.com>

On Tue, 8 Jun 2004 08:24:20 +0200, G?ran Brostr?m <gb@stat.umu.se>
wrote :

>On Mon, Jun 07, 2004 at 11:39:47PM +0200, Peter Dalgaard wrote:
>> G?ran Brostr?m <gb@stat.umu.se> writes:
>> 
>> > On Sat, Jun 05, 2004 at 06:01:28PM +0200, Peter Dalgaard wrote:
>> > > The release of R-1.9.1 is scheduled for Monday, June 21.
>> > > 
>> > > Automatic generation of daily alpha releases should start Monday, June
>> > > 7 and switch to beta status on Monday, June 14.
>> > 
>> > And where can I find these releases?
>> 
>> Hmmm... They should turn up at CRAN, but they are not there yet. 
>
>Yes, it is there now. I asked because it appeared from the r-help list
>yesterday as if someone had got his hands on it.

The Windows binary builds were showing up early, labelled as "alpha"
before it was official.

Duncan Murdoch

From dmurdoch at pair.com  Tue Jun  8 14:52:05 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Jun  8 14:52:02 2004
Subject: [Rd] Saving Trellis Graphics in R 1.9.0. (PR#6915)
In-Reply-To: <20040526083458.0F1FB10980@slim.kubism.ku.dk>
References: <20040526083458.0F1FB10980@slim.kubism.ku.dk>
Message-ID: <jidbc01elhir1s3lod7lomvsocm6gqjsnd@4ax.com>

On Wed, 26 May 2004 10:34:58 +0200 (CEST), valenta@euromise.cz wrote :

>Full_Name: Zdenek Valenta
>Version: 1.9.0.
>OS: Windows XP
>Submission from: (NULL) (147.231.7.250)
>
>
>I could not copy/save (Trelis) graphics using R version 1.9.0. The graphics
>displayed normally, but copying/saving it only produced an empty file.
>Everything works o.k. with R rel. 1.8.1.

This should be fixed in today's build of 1.9.1 alpha.

Duncan Murdoch

From wettenhall at wehi.edu.au  Tue Jun  8 15:41:05 2004
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Tue Jun  8 15:41:09 2004
Subject: [Rd] Nested shared library calls in Linux
Message-ID: <Pine.LNX.4.44.0406082302570.933-100000@unix24.alpha.wehi.edu.au>

Hi,

I have an interface from R to the wxPython GUI toolkit which 
works under Windows:
http://bioinf.wehi.edu.au/folders/james/wxPython/

(as long as you build RSPython with a shared (not static) 
Python library).

But on Linux I get an error:
> library(RSPython)
> importPythonModule("wx")
Error in .PythonEval(cmd) : Error in Python call: 
/export/share/disk501/lab0605/wettenhall/usr/local/lib/
python2.2/site-packages/wx/_core.so: 
undefined symbol: PyExc_IOError

I am working within my home area at the moment:
~ 
= /home/users/lab0605/wettenhall/
= /export/share/disk501/lab0605/wettenhall/

By running strace, I found that the Python command "import wx" 
correctly loads 
~/usr/local/lib/python2.2/site-packages/wx/_core.so

but then when _core.so tries to load libwx_gtk_html-2.5.so.1 
(its first shared-library-dependency), it only looks 
in one place:
~/usr/local/lib/R/bin/
i.e. THE DIRECTORY CONTAINING THE R SHARED LIBRARY.
when in fact it should be looking in:
~/usr/local/lib/

Has LD_LIBRARY_PATH somehow been collapsed into just one 
directory???  I have tried checking it with Sys.getenv() 
just before running importPythonModule("wx"), and 
it seems to be OK:  ~/usr/local/lib/ is certainly included 
in $LD_LIBRARY_PATH. 

I have included ~/usr/local/lib in my PYTHONPATH and 
I can also modify the Python path within R, using:
importPythonModule("sys")
.PythonEval("path=['path1','path2',...]",.module="sys")
or .PythonEval("path.append ...",.module="sys")

I have registered the shared libraries with ldconfig.

One more complication is that libwx_gtk_html-2.5.so.1 is 
actually a symbolic link to libwx_gtk_html-2.5.so.1.0.0 
(in the same directory, ~/usr/local/lib).

I'm running Fedora Linux with R 1.9.0. I've installed Python 
2.2.3 from source in ~/usr/local/ and I've built RSPython 
0.5-3 with a shared Python library libpython2.2.so (which I 
built from the Python source).  R and wxPython are also 
installed from source, both in ~/usr/local/ and R is 
configured with --enable-shlib.

If it would be helpful, I could try to come up with a much 
simpler example of nested shared-library calls from R, but 
people may wish to suggest that this is not the real problem.

Regards,
James

> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    9.0
year     2004
month    04
day      12
language R

From jago at mclink.it  Tue Jun  8 16:06:01 2004
From: jago at mclink.it (stefano iacus)
Date: Tue Jun  8 16:06:20 2004
Subject: [Rd] Crash in OSX (PR#6940)
In-Reply-To: <20040605023655.74B6910880@slim.kubism.ku.dk>
References: <20040605023655.74B6910880@slim.kubism.ku.dk>
Message-ID: <F8E3CCBE-B954-11D8-B1DD-000A95C87F66@mclink.it>

Please report a reproducible example.
It's surely something related to the history (prev/next key) management  
but I cannot track it down this way.
stefano

On Jun 5, 2004, at 4:36 AM, murray.pung@studentmail.newcastle.edu.au  
wrote:

> Full_Name: Murray Pung
> Version: 1.9.0
> OS: OSX Mac
> Submission from: (NULL) (134.148.20.33)
>
>
> Date/Time:      2004-06-05 12:32:30 +1000
> OS Version:     10.3.4 (Build 7H63)
> Report Version: 2
>
> Command: R.bin
> Path:    /Library/Frameworks/R.framework/Resources/bin/R.bin
> Version: 1.9.0 (R 1.9.0)
> PID:     358
> Thread:  0
>
> Exception:  EXC_BAD_ACCESS (0x0001)
> Codes:      KERN_PROTECTION_FAILURE (0x0002) at 0x00000005
>
> Thread 0 Crashed:
> 0   libSystem.B.dylib   	0x90006e70 strlen + 0x50
> 1   R_aqua.so           	0x0048699c HistFwd + 0x134  
> (aquaconsole.c:3451)
> 2   R_aqua.so           	0x004825c8 KeybHandler + 0xd4  
> (aquaconsole.c:1370)
> 3   com.apple.HIToolbox 	0x927d2330 DispatchEventToHandlers + 0x150
> 4   com.apple.HIToolbox 	0x927d25a4 SendEventToEventTargetInternal +  
> 0x174
> 5   com.apple.HIToolbox 	0x927d6a0c SendEventToEventTargetWithOptions  
> + 0x28
> 6   com.apple.HIToolbox 	0x9280b4c0  
> _Z19HandleKeyboardEventP14OpaqueEventRefm +
> 0x160
> 7   com.apple.HIToolbox 	0x927e2fe4
> _Z29ToolboxEventDispatcherHandlerP25OpaqueEventHandlerCallRefP14OpaqueE 
> ventRefPv
> + 0x1f8
> 8   com.apple.HIToolbox 	0x927d23ec DispatchEventToHandlers + 0x20c
> 9   com.apple.HIToolbox 	0x927d25a4 SendEventToEventTargetInternal +  
> 0x174
> 10  com.apple.HIToolbox 	0x927e4a34 SendEventToEventTarget + 0x28
> 11  R_aqua.so           	0x004876d0 Raqua_ProcessEvents + 0xa4
> (aquaconsole.c:3889)
> 12  R_aqua.so           	0x0048204c Raqua_ReadConsole + 0x9c
> (aquaconsole.c:1228)
> 13  R.bin               	0x00080c78 Rf_ReplIteration + 0x60  
> (main.c:200)
> 14  R.bin               	0x00080f30 R_ReplConsole + 0x88 (main.c:299)
> 15  R.bin               	0x000818d8 run_Rmainloop + 0x78 (main.c:654)
> 16  R.bin               	0x000ed7bc main + 0x14 (system.c:102)
> 17  R.bin               	0x0000204c _start + 0x17c (crt.c:267)
> 18  R.bin               	0x00001ecc start + 0x30
>
> PPC Thread State:
>   srr0: 0x90006e70 srr1: 0x0200f030                vrsave: 0x00000000
>     cr: 0x44022244  xer: 0x20000000   lr: 0x0048699c  ctr: 0x90006e20
>     r0: 0x0048699c   r1: 0xbffff060   r2: 0x000001f4   r3: 0x00000005
>     r4: 0x00000001   r5: 0x00000004   r6: 0x0000007d   r7: 0x004b6870
>     r8: 0x004b6870   r9: 0x00000005  r10: 0x004b6870  r11: 0x00494a34
>    r12: 0x90006e20  r13: 0x00000000  r14: 0x00000000  r15: 0x00000000
>    r16: 0x00000000  r17: 0x00000000  r18: 0x00000000  r19: 0x00000000
>    r20: 0x00000002  r21: 0x00000000  r22: 0x05607710  r23: 0x0110d8f0
>    r24: 0xbffff270  r25: 0xffffd96e  r26: 0x00000000  r27: 0xbffff180
>    r28: 0x00000001  r29: 0x004af55c  r30: 0x004afd2c  r31: 0x00486870
>
> Binary Images Description:
>     0x1000 -   0x16dfff R.bin
> /Library/Frameworks/R.framework/Resources/bin/R.bin
>   0x47f000 -   0x493fff R_aqua.so
> /Library/Frameworks/R.framework/Resources/modules/R_aqua.so
>   0x605000 -   0x62ffff libreadline.4.3.dylib
> /Library/Frameworks/R.framework/Resources/bin/Frameworks/ 
> libreadline.4.3.dylib
>  0x17b9000 -  0x17bcfff methods.so
> /Library/Frameworks/R.framework/Versions/1.9.0/Resources/library/ 
> methods/libs/methods.so
>  0x2008000 -  0x217bfff libR.dylib
> /Library/Frameworks/R.framework/Resources/bin/libR.dylib
>  0x5489000 -  0x548afff tools.so
> /Library/Frameworks/R.framework/Versions/1.9.0/Resources/library/ 
> tools/libs/tools.so
>  0x5492000 -  0x54bcfff stats.so
> /Library/Frameworks/R.framework/Versions/1.9.0/Resources/library/ 
> stats/libs/stats.so
>  0x576a000 -  0x57a4fff vfonts.so
> /Library/Frameworks/R.framework/Resources/modules/vfonts.so
> 0x8fe00000 - 0x8fe4ffff dyld 	/usr/lib/dyld
> 0x90000000 - 0x90122fff libSystem.B.dylib 	/usr/lib/libSystem.B.dylib
> 0x90190000 - 0x9023dfff com.apple.CoreFoundation 6.3.4 (299.31)
> /System/Library/Frameworks/CoreFoundation.framework/Versions/A/ 
> CoreFoundation
> 0x90280000 - 0x904f9fff com.apple.CoreServices.CarbonCore 10.3.4
> /System/Library/Frameworks/CoreServices.framework/Versions/A/ 
> Frameworks/CarbonCore.framework/Versions/A/CarbonCore
> 0x90570000 - 0x905defff com.apple.framework.IOKit 1.3.2 (???)
> /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit
> 0x90610000 - 0x9069afff com.apple.CoreServices.OSServices 3.0.1
> /System/Library/Frameworks/CoreServices.framework/Versions/A/ 
> Frameworks/OSServices.framework/Versions/A/OSServices
> 0x90700000 - 0x90700fff com.apple.CoreServices 10.3 (???)
> /System/Library/Frameworks/CoreServices.framework/Versions/A/ 
> CoreServices
> 0x90720000 - 0x90787fff com.apple.audio.CoreAudio 2.1.2
> /System/Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio
> 0x907f0000 - 0x907f9fff com.apple.DiskArbitration 2.0.3
> /System/Library/PrivateFrameworks/DiskArbitration.framework/Versions/ 
> A/DiskArbitration
> 0x90810000 - 0x90810fff com.apple.ApplicationServices 1.0 (???)
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> ApplicationServices
> 0x90910000 - 0x90983fff com.apple.DesktopServices 1.2.2
> /System/Library/PrivateFrameworks/DesktopServicesPriv.framework/ 
> Versions/A/DesktopServicesPriv
> 0x90d00000 - 0x90d1bfff com.apple.SystemConfiguration 1.7.1 (???)
> /System/Library/Frameworks/SystemConfiguration.framework/Versions/A/ 
> SystemConfiguration
> 0x90d40000 - 0x90d40fff com.apple.Carbon 10.3 (???)
> /System/Library/Frameworks/Carbon.framework/Versions/A/Carbon
> 0x910b0000 - 0x910fffff com.apple.bom 1.2.4 (63)
> /System/Library/PrivateFrameworks/Bom.framework/Versions/A/Bom
> 0x912a0000 - 0x912bdfff com.apple.audio.SoundManager 3.8
> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
> CarbonSound.framework/Versions/A/CarbonSound
> 0x912e0000 - 0x912f7fff com.apple.LangAnalysis 1.5.4
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/LangAnalysis.framework/Versions/A/LangAnalysis
> 0x91320000 - 0x913defff ColorSync
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/ColorSync.framework/Versions/A/ColorSync
> 0x91460000 - 0x91473fff com.apple.speech.synthesis.framework 3.2
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis
> 0x914a0000 - 0x91509fff com.apple.htmlrendering 1.1.2
> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
> HTMLRendering.framework/Versions/A/HTMLRendering
> 0x91560000 - 0x91619fff com.apple.QD 3.4.64 (???)
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/QD.framework/Versions/A/QD
> 0x91670000 - 0x916a8fff com.apple.AE 1.3.2
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/AE.framework/Versions/A/AE
> 0x916e0000 - 0x91773fff com.apple.print.framework.PrintCore 3.3
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/PrintCore.framework/Versions/A/PrintCore
> 0x917e0000 - 0x917f0fff com.apple.speech.recognition.framework 3.3
> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
> SpeechRecognition.framework/Versions/A/SpeechRecognition
> 0x91810000 - 0x9182afff com.apple.openscripting 1.2.1 (???)
> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
> OpenScripting.framework/Versions/A/OpenScripting
> 0x91850000 - 0x91860fff com.apple.ImageCapture 2.1.0
> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
> ImageCapture.framework/Versions/A/ImageCapture
> 0x91890000 - 0x9189cfff com.apple.help 1.0.1
> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
> Help.framework/Versions/A/Help
> 0x918c0000 - 0x918cdfff com.apple.CommonPanels 1.2.1 (1.0)
> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
> CommonPanels.framework/Versions/A/CommonPanels
> 0x918f0000 - 0x9193efff com.apple.print.framework.Print 3.3
> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
> Print.framework/Versions/A/Print
> 0x91990000 - 0x9199bfff com.apple.securityhi 1.2 (90)
> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
> SecurityHI.framework/Versions/A/SecurityHI
> 0x919c0000 - 0x91a33fff com.apple.NavigationServices 3.3.1
> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
> NavigationServices.framework/Versions/A/NavigationServices
> 0x91ab0000 - 0x91ac4fff libCGATS.A.dylib
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/CoreGraphics.framework/Versions/A/Resources/ 
> libCGATS.A.dylib
> 0x91ae0000 - 0x91aebfff libCSync.A.dylib
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/CoreGraphics.framework/Versions/A/Resources/ 
> libCSync.A.dylib
> 0x91b10000 - 0x91b2afff libPDFRIP.A.dylib
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/CoreGraphics.framework/Versions/A/Resources/ 
> libPDFRIP.A.dylib
> 0x91b50000 - 0x91b5ffff libPSRIP.A.dylib
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/CoreGraphics.framework/Versions/A/Resources/ 
> libPSRIP.A.dylib
> 0x91b80000 - 0x91b93fff libRIP.A.dylib
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/CoreGraphics.framework/Versions/A/Resources/libRIP.A.dylib
> 0x91bb0000 - 0x91d3cfff com.apple.QuickTime 6.4.0
> /System/Library/Frameworks/QuickTime.framework/Versions/A/QuickTime
> 0x92070000 - 0x92096fff com.apple.FindByContent 1.4 (1.2)
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/FindByContent.framework/Versions/A/FindByContent
> 0x920c0000 - 0x922a7fff com.apple.security 2.3 (176)
> /System/Library/Frameworks/Security.framework/Versions/A/Security
> 0x92430000 - 0x92468fff com.apple.LaunchServices 10.3 (84)
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/LaunchServices.framework/Versions/A/LaunchServices
> 0x92740000 - 0x92777fff com.apple.CFNetwork 1.2.1 (7)
> /System/Library/Frameworks/CoreServices.framework/Versions/A/ 
> Frameworks/CFNetwork.framework/Versions/A/CFNetwork
> 0x927d0000 - 0x92b54fff com.apple.HIToolbox 1.3.3 (???)
> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
> HIToolbox.framework/Versions/A/HIToolbox
> 0x92d30000 - 0x92d80fff com.apple.HIServices 1.4.1 (0.0.1d1)
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/HIServices.framework/Versions/A/HIServices
> 0x935d0000 - 0x938a8fff com.apple.CoreGraphics 1.203.20 (???)
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics
> 0x939a0000 - 0x939b4fff libcups.2.dylib 	/usr/lib/libcups.2.dylib
> 0x939d0000 - 0x939d4fff libmathCommon.A.dylib
> /usr/lib/system/libmathCommon.A.dylib
> 0x94060000 - 0x94078fff com.apple.WebServices 1.1.1 (1.1.0)
> /System/Library/Frameworks/CoreServices.framework/Versions/A/ 
> Frameworks/WebServicesCore.framework/Versions/A/WebServicesCore
> 0x94120000 - 0x9414bfff libncurses.5.dylib 	/usr/lib/libncurses.5.dylib
> 0x945b0000 - 0x945b9fff libz.1.dylib 	/usr/lib/libz.1.dylib
> 0x94610000 - 0x9462afff libresolv.9.dylib 	/usr/lib/libresolv.9.dylib
> 0x94650000 - 0x946affff com.apple.SearchKit 1.0.2
> /System/Library/Frameworks/CoreServices.framework/Versions/A/ 
> Frameworks/SearchKit.framework/Versions/A/SearchKit
> 0x94b20000 - 0x94badfff com.apple.ink.framework 55.8
> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
> Ink.framework/Versions/A/Ink
> 0x954c0000 - 0x95ac6fff libBLAS.dylib
> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/ 
> vecLib.framework/Versions/A/libBLAS.dylib
> 0x95b20000 - 0x95df0fff libLAPACK.dylib
> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/ 
> vecLib.framework/Versions/A/libLAPACK.dylib
> 0x95e40000 - 0x95eadfff libvDSP.dylib
> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/ 
> vecLib.framework/Versions/A/libvDSP.dylib
> 0x95f00000 - 0x95f20fff libvMisc.dylib
> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/ 
> vecLib.framework/Versions/A/libvMisc.dylib
> 0x968d0000 - 0x969b2fff libicucore.A.dylib 	/usr/lib/libicucore.A.dylib
> 0x96a20000 - 0x96ae2fff libcrypto.0.9.7.dylib  
> 	/usr/lib/libcrypto.0.9.7.dylib
> 0x96b40000 - 0x96b6efff libssl.0.9.7.dylib 	/usr/lib/libssl.0.9.7.dylib
> 0x96bf0000 - 0x96c7ffff ATS
> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
> Frameworks/ATS.framework/Versions/A/ATS
> 0x96e80000 - 0x96e90fff com.apple.vecLib 3.0.1 (vecLib 3.0.1)
> /System/Library/Frameworks/vecLib.framework/Versions/A/vecLib
> 0x97510000 - 0x97518fff libbsm.dylib 	/usr/lib/libbsm.dylib
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From tplate at blackmesacapital.com  Tue Jun  8 17:11:15 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue Jun  8 17:11:35 2004
Subject: [Rd] strange apparently data-dependent crash with large
	data (PR#6955)
In-Reply-To: <62c9c01e9n6c97icd6jf36v10euvdr0htk@4ax.com>
References: <20040607165927.D6BD8108F1@slim.kubism.ku.dk>
	<62c9c01e9n6c97icd6jf36v10euvdr0htk@4ax.com>
Message-ID: <6.1.0.6.2.20040607153720.03f76740@mailhost.blackmesacapital.com>

At Monday 12:14 PM 6/7/2004, Duncan Murdoch wrote:
>On Mon,  7 Jun 2004 18:59:27 +0200 (CEST), tplate@blackmesacapital.com
>wrote :
>
> >I'm consistently seeing R crash with a particular large data set.  What's
> >strange is that although the crash seems related to running out of memory,
> >I'm unable to construct a pseudo-random data set of the same size that also
> >causes the crash.  Further adding to the strangeness is that the crash only
> >happens if the dataset goes through a save()/load() cycle -- without that,
> >the command in question just gives an out-of-memory error, but does not 
> crash.
>
>This kind of error is very difficult to debug.  What's likely
>happening is that in one case you run out of memory at a place with a
>correct check, and in the other you are hitting some flaky code that
>assumes every memory allocation is guaranteed to succeed.

This seems likely, given that there is quite a wait (with CPU pegged) 
between when the message about being out-of-memory is printed, and when the 
Windows error dialog appears.  I guess the different setups with save/load 
vs read.table are leaving the memory in different states, which then 
affects whether or not the bug is triggered.

Is code that assumes every memory allocation is guaranteed to succeed 
considered OK, or is it something to fix when found?

Thanks to you and Brian Ripley for the informative responses.

-- Tony Plate


>You could install DrMinGW (which produces a stack dump when you
>crash), but it's not necessarily informative:  often the crash occurs
>relatively distantly from the buggy code that caused it.
>
>The other problem with this kind of error is that it may well
>disappear if you run under a debugger, since that will make you run
>out of memory at a different spot, and it may not appear on a
>different machine.  For example, I ran your examples and they all
>failed because R ran out of memory, but none crashed.
>
>Duncan Murdoch

From wettenhall at wehi.edu.au  Tue Jun  8 17:13:10 2004
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Tue Jun  8 17:13:16 2004
Subject: [Rd] Nested shared library calls in Linux
In-Reply-To: <20040608142454.GA19388@wald.ucdavis.edu>
References: <Pine.LNX.4.44.0406082302570.933-100000@unix24.alpha.wehi.edu.au>
	<20040608142454.GA19388@wald.ucdavis.edu>
Message-ID: <Pine.LNX.4.58.0406090104440.32669@unix28.alpha.wehi.edu.au>

Duncan,

Thanks for your answer.

I just realised that I was probably a bit too quick to claim 
that ~/usr/local/lib/R/bin/ is the only place that the dynamic 
linker is looking for libwx_gtk_html-2.5.so.1  I don't have much 
experience at reading strace output.  I think it looks in the 
wrong place initially, but then in the correct place.

On Jun 2004, Duncan Temple Lang wrote:
> What should happen is that _core.so and all Python packages
> should be linked against libpython2.2.so or libpython2.2.a.
> We can tell whether this has happened via
> 
>   ldd  /export/share/disk501/lab0605/wettenhall/usr/local/lib/
python2.2/site-packages/wx/_core.so 

I haven't included all the ldd output from wxPython's _core.so 
but I can tell you that libpython2.2.so is not there.  Here's 
some of the output:
unix28 507 % ldd _core.so
        libwx_gtk_html-2.5.so.1 => 
/home/users/lab0605/wettenhall/usr/local/lib/libwx_gtk_html-2.5.so.1 
(0x00842000)
        libwx_gtk_adv-2.5.so.1 => 
/home/users/lab0605/wettenhall/usr/local/lib/libwx_gtk_adv-2.5.so.1 
(0x00d98000)
        libwx_gtk_core-2.5.so.1 => 
/home/users/lab0605/wettenhall/usr/local/lib/libwx_gtk_core-2.5.so.1 
(0x00111000)
        libwx_base_xml-2.5.so.1 => 
/home/users/lab0605/wettenhall/usr/local/lib/libwx_base_xml-2.5.so.1 
(0x003e5000)
        libwx_base_net-2.5.so.1 => 
/home/users/lab0605/wettenhall/usr/local/lib/libwx_base_net-2.5.so.1 
(0x0054b000)
        libwx_base-2.5.so.1 => 
/home/users/lab0605/wettenhall/usr/local/lib/libwx_base-2.5.so.1 
(0x005e5000)
        libpthread.so.0 => /lib/tls/libpthread.so.0 (0x004e6000)
        libc.so.6 => /lib/tls/libc.so.6 (0x00a39000)
<snip>

> 
>   nm  /export/share/disk501/lab0605/wettenhall/usr/local/lib/python2.2/site-packages/wx/_core.so  | grep PyExc_IOError

This returns:
unix28 510 % nm _core.so | grep PyExc_IOError
         U PyExc_IOError

i.e. the symbol is undefined in wxPython's _core.so

whereas it is defined in libpython2.2.so :
unix28 513 % nm libpython2.2.so | grep PyExc_IOError
000f65d8 B PyExc_IOError

(To be precise, it is declared but not initialized).

OK, so I guess I will experiment with trying to build wxPython 
and get it to link against libpython2.2.so.  

Or maybe for each wxPython .so file, I can just add a 
libpython2.2.so dependency with something like:
ld -o _core2.so _core.so libpython2.2.so
mv _core2.so _core.so

I'll play around with this sort of thing for a while...

Regards,
James

From dmurdoch at pair.com  Tue Jun  8 17:18:25 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Jun  8 17:18:23 2004
Subject: [Rd] strange apparently data-dependent crash with large data
	(PR#6955)
In-Reply-To: <6.1.0.6.2.20040607153720.03f76740@mailhost.blackmesacapital.com>
References: <20040607165927.D6BD8108F1@slim.kubism.ku.dk>
	<62c9c01e9n6c97icd6jf36v10euvdr0htk@4ax.com>
	<6.1.0.6.2.20040607153720.03f76740@mailhost.blackmesacapital.com>
Message-ID: <i4mbc0hudcqvc7omc4r0sple07bjenvqjn@4ax.com>

On Tue, 08 Jun 2004 09:11:15 -0600, Tony Plate
<tplate@blackmesacapital.com> wrote :

>Is code that assumes every memory allocation is guaranteed to succeed 
>considered OK, or is it something to fix when found?

It's usually something that needs to be fixed.  There are probably
cases where the assumption is valid, but usually it's not.

Duncan Murdoch

From ripley at stats.ox.ac.uk  Tue Jun  8 19:46:58 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Jun  8 19:47:12 2004
Subject: [Rd] make fails with utf-8 locale, RH9 (PR#6958)
In-Reply-To: <20040608093709.75495108FB@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406081839090.16457-100000@gannet.stats>

After some tracking down, this is not due to utf-8 at all.  It happens in
et_EE as well, and it does not happen in en_GB.UTF-8.  It is due to the
position of z in the sort in that locale (before u).

In detail, it is down to how make interprets

RSRC = $(srcdir)/R/*.R $(srcdir)/R/$(R_OSTYPE)/*.R

in ${R_HOME}/src/library/base/Makefile, and we need to force LC_COLLATE=C
there.

On Tue, 8 Jun 2004 otoomet@econ.dk wrote:

> Hi,
> 
> I have an RH9 box (gcc (GCC) 3.2.2, perl 5.8.0, make 3.79.1).  My
> locale is
> 
> LANG="et_EE.UTF-8"
> 
> I do:
> 
> $ ./configure --prefix=/usr/local
> ...
> $ make
> ...
> make[4]: Entering directory `/home/otoomet/a/R-1.9.0/src/library/stats4'
> dumping R code in package 'stats4'
> Error in structure(c(unlist(lapply(list(...), unclass))), class = c("POSIXt",  : 
>         couldn't find function "unlist"
> Execution halted
> ...
> 
> make stops with similar error messages later.
> 
> when I say now
> 
> $ LANG="" make
> 
> everything works OK.
> 
> I can supply further information if you consider the problem worth of
> investigating/mentioning in docs.
> 
> Thanks for R!
> 
> Ott
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jfox at mcmaster.ca  Wed Jun  9 01:10:54 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed Jun  9 01:10:59 2004
Subject: [Rd] Using macros
Message-ID: <20040608231053.RQGW14757.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear list members,

I've been puzzling over how best to clean up the code for my Rcmdr package.
In particular, there's a lot of repetitive tcltk code in the package, and as
Martin M?chler has pointed out to me, this makes the package difficult to
maintain.

If R were Lisp, I'd use macros for much of the clean up. My efforts to do
similar things with R functions has run into problems with scoping issues.
My attempts to solve these problems have worked, but lead to awkward code
(perhaps because I've not been clever enough to do it in a natural way).

Thomas Lumley describes a function for constructing R "macros" in the Sept.
2001 issue of R-news. Here's an application to producing standard OK,
Cancel, and Help buttons using tcltk:

    ### Thomas's defmacro:
    defmacro <- function(..., expr){
        expr <- substitute(expr)
        a <- substitute(list(...))[-1]
        ## process the argument list
        nn <- names(a)
        if (is.null(nn)) nn <- rep("", length(a))
        for (i in seq(length=length(a))){
            if (nn[i] == "") {
                nn[i] <- paste(a[[i]])
                msg <- paste(a[[i]], "not supplied")
                a[[i]] <- substitute(stop(foo), list(foo = msg))
                }
            }
        names(a) <- nn
        a <- as.list(a)
        ff <- eval(substitute(
            function(){
                tmp <- substitute(body)
                eval(tmp, parent.frame())
                },
            list(body = expr)))
        ## add the argument list
        formals(ff) <- a
        ## create a fake source attribute
        mm <- match.call()
        mm$expr <- NULL
        mm[[1]] <- as.name("macro")
        attr(ff, "source") <- c(deparse(mm), deparse(expr))
        ## return the macro
        ff
        }

    OKCancelHelp <- defmacro(window=top, OKbutton=OKbutton, onOK=onOK, 
        cancelButton=cancelButton, onCancel=onCancel,
        helpButton=helpButton, onHelp=onHelp, helpSubject,
        expr={
            OKbutton <- tkbutton(window, text="OK", fg="darkgreen",
width="12", command=onOK, default="active")
            onCancel <- function() {
                tkdestroy(top)  
                } 
            cancelButton <- tkbutton(window, text="Cancel", fg="red",
width="12", command=onCancel)
            onHelp <- function() {
                help(helpSubject)
                }
            helpButton <- tkbutton(window, text="Help", width="12",
command=onHelp)
            }
        )
    
    test <- function(){
        top <- tktoplevel()
        onOK <- function(){
            tkmessageBox(message="Foo.", icon="info", type="ok")
            tkdestroy(top)
            }
        OKCancelHelp(helpSubject="lm")
        tkgrid(OKbutton, cancelButton, helpButton)
        }
    
    test()

That is, the OKCancelHelp macro makes the buttons and the call-back
functions onCancel and onHelp in the environment of the calling function
(here test). This seems to work fine, but I wonder whether there are any
hidden pitfalls to adopting this as a general strategy. For example, is
there some problematic interaction with namespaces if I export the macro
OKCancelHelp?

Any advice would be appreciated.
 John 

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox

From Mark.Bravington at csiro.au  Wed Jun  9 02:20:28 2004
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Wed Jun  9 02:20:38 2004
Subject: [Rd] Using macros
Message-ID: <C4178DC99E08604EA5E2BDB989F093800240A2A6@extas2-hba.tas.csiro.au>

Hi John

I haven't looked at your application in detail, but you might also want to have a look at 'mlocal' in my 'mvbutils' package, which provides an alternative way of setting up "macros". (See also "do.in.envir" and "extract.named") There are some nice facilities, e.g. in letting you "declare" temporary variables that don't overwrite existing variables in the frame of the macro's caller. This gets round two potential usage pitfalls: creation of junk variables in the caller, and accidental overwriting of non-junk variables in the caller that happen to have the same name as a variable in the macro.

OTOMH the other technical pitfalls are 

(i) macro arguments are evaluated at time of calling the macro, not via "lazy evaluation" [though this might be fixable with 'delay']

(ii) 'return'-- just including a 'return' statement doesn't work. 'mvbutils' has a 'local.return' function that deals with this.

(iii) 'on.exit'-- macro or caller? 'mlocal' has a fix for this, allowing the 'on.exit' to apply only to the macro.

(iv) 'sys.call' etc.-- the frame sequence is not what you might guess.

The 'mlocal' documentation has notes on all of these.

I also haven't looked at Thomas' approach in detail, so I can't be sure all these things apply to his macro system too-- but I suspect they are generic.

Hope this helps

Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington@csiro.au 

#-----Original Message-----
#From: r-devel-bounces@stat.math.ethz.ch
#[mailto:r-devel-bounces@stat.math.ethz.ch]On Behalf Of John Fox
#Sent: Wednesday, 9 June 2004 9:11 AM
#To: r-devel@stat.math.ethz.ch
#Subject: [Rd] Using macros
#
#
#Dear list members,
#
#I've been puzzling over how best to clean up the code for my 
#Rcmdr package.
#In particular, there's a lot of repetitive tcltk code in the 
#package, and as
#Martin M?chler has pointed out to me, this makes the package 
#difficult to
#maintain.
#
#If R were Lisp, I'd use macros for much of the clean up. My 
#efforts to do
#similar things with R functions has run into problems with 
#scoping issues.
#My attempts to solve these problems have worked, but lead to 
#awkward code
#(perhaps because I've not been clever enough to do it in a 
#natural way).
#
#Thomas Lumley describes a function for constructing R "macros" 
#in the Sept.
#2001 issue of R-news. Here's an application to producing standard OK,
#Cancel, and Help buttons using tcltk:
#
#    ### Thomas's defmacro:
#    defmacro <- function(..., expr){
#        expr <- substitute(expr)
#        a <- substitute(list(...))[-1]
#        ## process the argument list
#        nn <- names(a)
#        if (is.null(nn)) nn <- rep("", length(a))
#        for (i in seq(length=length(a))){
#            if (nn[i] == "") {
#                nn[i] <- paste(a[[i]])
#                msg <- paste(a[[i]], "not supplied")
#                a[[i]] <- substitute(stop(foo), list(foo = msg))
#                }
#            }
#        names(a) <- nn
#        a <- as.list(a)
#        ff <- eval(substitute(
#            function(){
#                tmp <- substitute(body)
#                eval(tmp, parent.frame())
#                },
#            list(body = expr)))
#        ## add the argument list
#        formals(ff) <- a
#        ## create a fake source attribute
#        mm <- match.call()
#        mm$expr <- NULL
#        mm[[1]] <- as.name("macro")
#        attr(ff, "source") <- c(deparse(mm), deparse(expr))
#        ## return the macro
#        ff
#        }
#
#    OKCancelHelp <- defmacro(window=top, OKbutton=OKbutton, onOK=onOK, 
#        cancelButton=cancelButton, onCancel=onCancel,
#        helpButton=helpButton, onHelp=onHelp, helpSubject,
#        expr={
#            OKbutton <- tkbutton(window, text="OK", fg="darkgreen",
#width="12", command=onOK, default="active")
#            onCancel <- function() {
#                tkdestroy(top)  
#                } 
#            cancelButton <- tkbutton(window, text="Cancel", fg="red",
#width="12", command=onCancel)
#            onHelp <- function() {
#                help(helpSubject)
#                }
#            helpButton <- tkbutton(window, text="Help", width="12",
#command=onHelp)
#            }
#        )
#    
#    test <- function(){
#        top <- tktoplevel()
#        onOK <- function(){
#            tkmessageBox(message="Foo.", icon="info", type="ok")
#            tkdestroy(top)
#            }
#        OKCancelHelp(helpSubject="lm")
#        tkgrid(OKbutton, cancelButton, helpButton)
#        }
#    
#    test()
#
#That is, the OKCancelHelp macro makes the buttons and the call-back
#functions onCancel and onHelp in the environment of the 
#calling function
#(here test). This seems to work fine, but I wonder whether 
#there are any
#hidden pitfalls to adopting this as a general strategy. For example, is
#there some problematic interaction with namespaces if I export 
#the macro
#OKCancelHelp?
#
#Any advice would be appreciated.
# John 
#
#--------------------------------
#John Fox
#Department of Sociology
#McMaster University
#Hamilton, Ontario
#Canada L8S 4M4
#905-525-9140x23604
#http://socserv.mcmaster.ca/jfox
#
#______________________________________________
#R-devel@stat.math.ethz.ch mailing list
#https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
#

From otoomet at econ.dk  Wed Jun  9 08:59:26 2004
From: otoomet at econ.dk (Ott Toomet)
Date: Wed Jun  9 08:57:58 2004
Subject: [Rd] make fails with utf-8 locale, RH9 (PR#6958)
In-Reply-To: <Pine.LNX.4.44.0406081839090.16457-100000@gannet.stats> (message
	from Prof Brian Ripley on Tue, 8 Jun 2004 18:46:58 +0100 (BST))
References: <Pine.LNX.4.44.0406081839090.16457-100000@gannet.stats>
Message-ID: <200406090659.i596xQ3U001596@localhost.localdomain>

Hi,

 | Date: Tue, 8 Jun 2004 18:46:58 +0100 (BST)
 | From: Prof Brian Ripley <ripley@stats.ox.ac.uk>

 | After some tracking down, this is not due to utf-8 at all.  It happens in
 | et_EE as well, and it does not happen in en_GB.UTF-8.  It is due to the
 | position of z in the sort in that locale (before u).

you are right, Estonian alphabet looks like 

... o p q r s z t u v... AFAIR.

Thanks for a quick answer :-)

Ott

 | In detail, it is down to how make interprets
 | 
 | RSRC = $(srcdir)/R/*.R $(srcdir)/R/$(R_OSTYPE)/*.R
 | 
 | in ${R_HOME}/src/library/base/Makefile, and we need to force LC_COLLATE=C
 | there.

From ripley at stats.ox.ac.uk  Wed Jun  9 09:55:21 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jun  9 09:55:26 2004
Subject: [Rd] a fault in the "hist" - function (PR#6931)
In-Reply-To: <x2isea126p.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0406090831480.17932-100000@gannet.stats>

On 2 Jun 2004, Peter Dalgaard wrote:

> ligges@statistik.uni-dortmund.de writes:
> 
> > The problem is in hist.default():
> > 
> >      diddle <- 1e-7 * max(abs(range(breaks)))
> > 
> > and whereever we are diddling - there are some disadvantages.
> > 
> > Do we want a flag that turns off diddling and the following "fuzz" 
> > stuff? Or do we want something to adjust the hardcoded heuristical value 
> > "1e-7" (to zero, for example)?
> 
> Neither, I think, since the diddle is there for a reason, and the only
> real problem is the use of breaks that are wildly off-scale. We might
> key diddle to xlim instead, or possibly let "diddle" be an argument

We can't do that, as hist might not be used to plot.

> with a suitable default. 
> 
> You probably can't get all cases completely right though. A tiny range
> of numbers (compared to the mean) is likely to cause problems whatever
> you do.

I think the fuzz really needs to be relative to the adjacent bin size (and 
the one to the left or right as appropriate).  So I am going to replace

    diddle <- 1e-7 * max(abs(range(breaks)))

by

    diddle <- 1e-7 * median(diff(breaks))

that is to use a typical bin size to set the fuzz factor.  (Note: I know
this is typically a bit smaller, but 1e-7 was a rather large tolerance.)

[I hadn't realized we used the largest limit and not the range (normal 
sense) of the data.  There is also something of a design error in that we 
shift the breaks and not the data.]

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Jun  9 09:56:03 2004
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jun  9 09:56:10 2004
Subject: [Rd] a fault in the "hist" - function (PR#6931)
Message-ID: <20040609075603.BA532108EB@slim.kubism.ku.dk>

On 2 Jun 2004, Peter Dalgaard wrote:

> ligges@statistik.uni-dortmund.de writes:
> 
> > The problem is in hist.default():
> > 
> >      diddle <- 1e-7 * max(abs(range(breaks)))
> > 
> > and whereever we are diddling - there are some disadvantages.
> > 
> > Do we want a flag that turns off diddling and the following "fuzz" 
> > stuff? Or do we want something to adjust the hardcoded heuristical value 
> > "1e-7" (to zero, for example)?
> 
> Neither, I think, since the diddle is there for a reason, and the only
> real problem is the use of breaks that are wildly off-scale. We might
> key diddle to xlim instead, or possibly let "diddle" be an argument

We can't do that, as hist might not be used to plot.

> with a suitable default. 
> 
> You probably can't get all cases completely right though. A tiny range
> of numbers (compared to the mean) is likely to cause problems whatever
> you do.

I think the fuzz really needs to be relative to the adjacent bin size (and 
the one to the left or right as appropriate).  So I am going to replace

    diddle <- 1e-7 * max(abs(range(breaks)))

by

    diddle <- 1e-7 * median(diff(breaks))

that is to use a typical bin size to set the fuzz factor.  (Note: I know
this is typically a bit smaller, but 1e-7 was a rather large tolerance.)

[I hadn't realized we used the largest limit and not the range (normal 
sense) of the data.  There is also something of a design error in that we 
shift the breaks and not the data.]

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From gb at stat.umu.se  Wed Jun  9 13:23:49 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed Jun  9 13:23:35 2004
Subject: [Rd] 1.9.1-alpha & tty
Message-ID: <20040609112349.GA21941@stat.umu.se>

I have two versions of R on my Debian testing: R-1.9.0 (precompiled) and
R-1.9.1-alpha of 2004-06-07 (built on my system). In the latter, I get

> system("emacs sim.R &")
> emacs: standard input is not a tty

while with R-1.9.0 it works as expected. I have absolutely no idea about
what's going on, so I could use some help. Anyone?

Thanks,

G?ran
-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb@stat.umu.se

From gb at stat.umu.se  Wed Jun  9 13:30:34 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed Jun  9 13:30:21 2004
Subject: [Rd] Re: 1.9.1-alpha & tty
In-Reply-To: <20040609112349.GA21941@stat.umu.se>
References: <20040609112349.GA21941@stat.umu.se>
Message-ID: <20040609113034.GB23805@stat.umu.se>

On Wed, Jun 09, 2004 at 01:23:49PM +0200, G?ran Brostr?m wrote:
> I have two versions of R on my Debian testing: R-1.9.0 (precompiled) and
> R-1.9.1-alpha of 2004-06-07 (built on my system). In the latter, I get
> 
> > system("emacs sim.R &")
> > emacs: standard input is not a tty
> 
> while with R-1.9.0 it works as expected. I have absolutely no idea about
> what's going on, so I could use some help. Anyone?

I just recalled that I was running R-1.9.1 as root ("su -; R") in order to
be able to 'install.packages'. That must be the reason, but I still don't
understand what it means.

G?ran

From ripley at stats.ox.ac.uk  Wed Jun  9 13:40:25 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jun  9 13:40:28 2004
Subject: [Rd] Re: 1.9.1-alpha & tty
In-Reply-To: <20040609113034.GB23805@stat.umu.se>
Message-ID: <Pine.LNX.4.44.0406091233300.22827-100000@gannet.stats>

On Wed, 9 Jun 2004, G?ran Brostr?m wrote:

> On Wed, Jun 09, 2004 at 01:23:49PM +0200, G?ran Brostr?m wrote:
> > I have two versions of R on my Debian testing: R-1.9.0 (precompiled) and
> > R-1.9.1-alpha of 2004-06-07 (built on my system). In the latter, I get
> > 
> > > system("emacs sim.R &")
> > > emacs: standard input is not a tty
> > 
> > while with R-1.9.0 it works as expected. I have absolutely no idea about
> > what's going on, so I could use some help. Anyone?
> 
> I just recalled that I was running R-1.9.1 as root ("su -; R") in order to
> be able to 'install.packages'. That must be the reason, but I still don't
> understand what it means.

It means the shell you are running it from is not an interactive shell
connected to a terminal, which is true as it is launched from R.  You are
trying to run a detached session with '&': that does not work for me in
1.9.0 without su -.

> system("emacs &")
> emacs: standard input is not a tty

as I would expect.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Wed Jun  9 14:01:29 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed Jun  9 14:08:27 2004
Subject: [Rd] Re: 1.9.1-alpha & tty
In-Reply-To: <Pine.LNX.4.44.0406091233300.22827-100000@gannet.stats>
References: <Pine.LNX.4.44.0406091233300.22827-100000@gannet.stats>
Message-ID: <x2ekopj5ye.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> On Wed, 9 Jun 2004, G?ran Brostr?m wrote:
> 
> > On Wed, Jun 09, 2004 at 01:23:49PM +0200, G?ran Brostr?m wrote:
> > > I have two versions of R on my Debian testing: R-1.9.0 (precompiled) and
> > > R-1.9.1-alpha of 2004-06-07 (built on my system). In the latter, I get
> > > 
> > > > system("emacs sim.R &")
> > > > emacs: standard input is not a tty
> > > 
> > > while with R-1.9.0 it works as expected. I have absolutely no idea about
> > > what's going on, so I could use some help. Anyone?
> > 
> > I just recalled that I was running R-1.9.1 as root ("su -; R") in order to
> > be able to 'install.packages'. That must be the reason, but I still don't
> > understand what it means.
> 
> It means the shell you are running it from is not an interactive shell
> connected to a terminal, which is true as it is launched from R.  You are
> trying to run a detached session with '&': that does not work for me in
> 1.9.0 without su -.
> 
> > system("emacs &")
> > emacs: standard input is not a tty
> 
> as I would expect.

It's probably a matter of whether DISPLAY is set:

>  system("emacs sim.R &") # works
>  system("DISPLAY= emacs sim.R &")
> emacs: standard input is not a tty

(Redhat 8)

"su -" will usually not set DISPLAY since root might not have
credentials to write to the display (which might be on a completely
unrelated system). 
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From rossini at blindglobe.net  Wed Jun  9 16:00:20 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed Jun  9 16:00:25 2004
Subject: [Rd] Re: 1.9.1-alpha & tty
In-Reply-To: =?iso-8859-1?q?<20040609113034.GB23805@stat.umu.se>_(G=F6r?=
	=?iso-8859-1?q?an_Brostr=F6m's_message_of_"Wed,
	_9_Jun_2004_13:30:34_+02?= =?iso-8859-1?q?00")?=
References: <20040609112349.GA21941@stat.umu.se>
	<20040609113034.GB23805@stat.umu.se>
Message-ID: <85hdtk3k7f.fsf@servant.blindglobe.net>


To answer a completely different question than the one you pose, an
alternative strategy for Debian's default system install is to give
ownership of /usr/local/lib/R/site-packages to a group and make it
group writable, granting membership to those who are allowed to
install packages. 


G?ran Brostr?m <gb@stat.umu.se> writes:

> On Wed, Jun 09, 2004 at 01:23:49PM +0200, G?ran Brostr?m wrote:
>> I have two versions of R on my Debian testing: R-1.9.0 (precompiled) and
>> R-1.9.1-alpha of 2004-06-07 (built on my system). In the latter, I get
>> 
>> > system("emacs sim.R &")
>> > emacs: standard input is not a tty
>> 
>> while with R-1.9.0 it works as expected. I have absolutely no idea about
>> what's going on, so I could use some help. Anyone?
>
> I just recalled that I was running R-1.9.1 as root ("su -; R") in order to
> be able to 'install.packages'. That must be the reason, but I still don't
> understand what it means.
>
> G?ran
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

-- 
rossini@u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}

From gregory_r_warnes at groton.pfizer.com  Wed Jun  9 20:06:59 2004
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Wed Jun  9 20:07:11 2004
Subject: [Rd] Add links to NEWS/ChangeLog to package pages
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20C521509@groexmb02.pfizer.com>


Just a thought:

It would be nice to be able to review the NEWS and/or ChangeLog files for
packages via the package web page on CRAN...

-Greg

Gregory R. Warnes
Manager, Non-Clinical Statistics
Pfizer Global Research and Development



LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

From rossini at blindglobe.net  Wed Jun  9 20:16:34 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed Jun  9 20:16:42 2004
Subject: [Rd] Add links to NEWS/ChangeLog to package pages
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C20C521509@groexmb02.pfizer.com>
	(Gregory R. Warnes's message of "Wed, 9 Jun 2004 14:06:59 -0400")
References: <D7A3CFD7825BD6119B880002A58F06C20C521509@groexmb02.pfizer.com>
Message-ID: <85vfi0wq9p.fsf@servant.blindglobe.net>


That's a great idea, Greg!  (actually, have you seen the
apt-listchanges and apt-listbugs features on debian, which does the
same prior to install?  Then you can abort the install if the changes
aren't what you want (or if outstanding bugs have/havn't been
fixed/introduced, which is even better, but linking in a bugtracking
system would be a PITA).

best,
-tony


"Warnes, Gregory R" <gregory_r_warnes@groton.pfizer.com> writes:

> Just a thought:
>
> It would be nice to be able to review the NEWS and/or ChangeLog files for
> packages via the package web page on CRAN...
>
> -Greg
>
> Gregory R. Warnes
> Manager, Non-Clinical Statistics
> Pfizer Global Research and Development
>
>
>
> LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

-- 
rossini@u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}

From rkoenker at uiuc.edu  Wed Jun  9 22:03:03 2004
From: rkoenker at uiuc.edu (roger koenker)
Date: Wed Jun  9 22:03:09 2004
Subject: [Rd] Notes on model fitting functions
Message-ID: <03F6DD66-BA50-11D8-AEC3-000A95A7E3AA@uiuc.edu>

I would just like to express my thanks to the anon. author
of the "notes on model fitting functions" on the developer
page.  They proved to be very helpful today for some updating
of my quantreg package.

url:	www.econ.uiuc.edu/~roger        	Roger Koenker
email	rkoenker@uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

From edd at debian.org  Wed Jun  9 22:07:51 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed Jun  9 22:07:56 2004
Subject: [Rd] Add links to NEWS/ChangeLog to package pages
In-Reply-To: <85vfi0wq9p.fsf@servant.blindglobe.net>
References: <D7A3CFD7825BD6119B880002A58F06C20C521509@groexmb02.pfizer.com>
	<85vfi0wq9p.fsf@servant.blindglobe.net>
Message-ID: <20040609200751.GA10579@sonny.eddelbuettel.com>

On Wed, Jun 09, 2004 at 11:16:34AM -0700, A.J. Rossini wrote:
> 
> That's a great idea, Greg!  (actually, have you seen the
> apt-listchanges and apt-listbugs features on debian, which does the
> same prior to install?  Then you can abort the install if the changes
> aren't what you want (or if outstanding bugs have/havn't been
> fixed/introduced, which is even better, but linking in a bugtracking
> system would be a PITA).

It is a good idea -- but we currently do not have a standard of 
-- whether it is CHANGES, ChangeLog or changelog
-- whether it is in the top-level or the inst directory

edd@chibud:~/src/debian/CRAN> ls */CHANGES
multcomp-0.4.6/CHANGES  mvtnorm-0.6.8/CHANGES
edd@chibud:~/src/debian/CRAN> ls */ChangeLog
Rmpi-0.4.8/ChangeLog     date-1.2.17/ChangeLog    gregmisc-1.11.1/ChangeLog
nlme-3.1.48/ChangeLog     rsprng-0.3.1/ChangeLog
abind-1.1.0/ChangeLog    date-1.2.18/ChangeLog    gregmisc-1.11.2/ChangeLog
quadprog-1.4.7/ChangeLog  tseries-0.9.21/ChangeLog
cluster-1.9.1/ChangeLog  foreign-0.6.9/ChangeLog  lattice-0.9.12/ChangeLog
rpvm-0.6.2/ChangeLog
edd@chibud:~/src/debian/CRAN> ls */inst/CHANGES
Rcmdr-0.9.8/inst/CHANGES  car-1.0.12/inst/CHANGES  effects-1.0.5/inst/CHANGES
edd@chibud:~/src/debian/CRAN> ls */inst/ChangeLog
ls: */inst/ChangeLog: No such file or directory

Dirk

> 
> best,
> -tony
> 
> 
> "Warnes, Gregory R" <gregory_r_warnes@groton.pfizer.com> writes:
> 
> > Just a thought:
> >
> > It would be nice to be able to review the NEWS and/or ChangeLog files for
> > packages via the package web page on CRAN...
> >
> > -Greg
> >
> > Gregory R. Warnes
> > Manager, Non-Clinical Statistics
> > Pfizer Global Research and Development
> >
> >
> >
> > LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> >
> 
> -- 
> rossini@u.washington.edu            http://www.analytics.washington.edu/ 
> Biomedical and Health Informatics   University of Washington
> Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
> UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
> FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email
> 
> CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
FEATURE:  VW Beetle license plate in California

From rossini at blindglobe.net  Wed Jun  9 22:17:13 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed Jun  9 22:17:29 2004
Subject: [Rd] Add links to NEWS/ChangeLog to package pages
In-Reply-To: <20040609200751.GA10579@sonny.eddelbuettel.com> (Dirk
	Eddelbuettel's message of "Wed, 9 Jun 2004 15:07:51 -0500")
References: <D7A3CFD7825BD6119B880002A58F06C20C521509@groexmb02.pfizer.com>
	<85vfi0wq9p.fsf@servant.blindglobe.net>
	<20040609200751.GA10579@sonny.eddelbuettel.com>
Message-ID: <85u0xktrjq.fsf@servant.blindglobe.net>


Dirk, I'm thinking of the application to CRAN, where it might be
standardizable; not to Debian, where it could only produce holy wars,
flamage, and bikeshedding.

i.e. I'd love to be able to do:

     update.packages(ListChanges=TRUE, ListBugs=TRUE) 

best,
-tony


Dirk Eddelbuettel <edd@debian.org> writes:

> On Wed, Jun 09, 2004 at 11:16:34AM -0700, A.J. Rossini wrote:
>> 
>> That's a great idea, Greg!  (actually, have you seen the
>> apt-listchanges and apt-listbugs features on debian, which does the
>> same prior to install?  Then you can abort the install if the changes
>> aren't what you want (or if outstanding bugs have/havn't been
>> fixed/introduced, which is even better, but linking in a bugtracking
>> system would be a PITA).
>
> It is a good idea -- but we currently do not have a standard of 
> -- whether it is CHANGES, ChangeLog or changelog
> -- whether it is in the top-level or the inst directory
>
> edd@chibud:~/src/debian/CRAN> ls */CHANGES
> multcomp-0.4.6/CHANGES  mvtnorm-0.6.8/CHANGES
> edd@chibud:~/src/debian/CRAN> ls */ChangeLog
> Rmpi-0.4.8/ChangeLog     date-1.2.17/ChangeLog    gregmisc-1.11.1/ChangeLog
> nlme-3.1.48/ChangeLog     rsprng-0.3.1/ChangeLog
> abind-1.1.0/ChangeLog    date-1.2.18/ChangeLog    gregmisc-1.11.2/ChangeLog
> quadprog-1.4.7/ChangeLog  tseries-0.9.21/ChangeLog
> cluster-1.9.1/ChangeLog  foreign-0.6.9/ChangeLog  lattice-0.9.12/ChangeLog
> rpvm-0.6.2/ChangeLog
> edd@chibud:~/src/debian/CRAN> ls */inst/CHANGES
> Rcmdr-0.9.8/inst/CHANGES  car-1.0.12/inst/CHANGES  effects-1.0.5/inst/CHANGES
> edd@chibud:~/src/debian/CRAN> ls */inst/ChangeLog
> ls: */inst/ChangeLog: No such file or directory
>
> Dirk
>
>> 
>> best,
>> -tony
>> 
>> 
>> "Warnes, Gregory R" <gregory_r_warnes@groton.pfizer.com> writes:
>> 
>> > Just a thought:
>> >
>> > It would be nice to be able to review the NEWS and/or ChangeLog files for
>> > packages via the package web page on CRAN...
>> >
>> > -Greg
>> >
>> > Gregory R. Warnes
>> > Manager, Non-Clinical Statistics
>> > Pfizer Global Research and Development
>> >
>> >
>> >
>> > LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
>> >
>> > ______________________________________________
>> > R-devel@stat.math.ethz.ch mailing list
>> > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>> >
>> 
>> -- 
>> rossini@u.washington.edu            http://www.analytics.washington.edu/ 
>> Biomedical and Health Informatics   University of Washington
>> Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
>> UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
>> FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email
>> 
>> CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}
>> 
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>> 
>
> -- 
> FEATURE:  VW Beetle license plate in California
>

-- 
rossini@u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}

From pgilbert at bank-banque-canada.ca  Thu Jun 10 01:53:47 2004
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu Jun 10 01:53:30 2004
Subject: [Rd] .Random.seed saved in .RData
Message-ID: <40C7A30B.1090103@bankofcanada.ca>

Is it intentional that the .Random.seed is saved in .RData?  If people 
run multiple sessions from the same directory they will get the same 
intial seed setting, which seems a bit dangerous. I don't often save my 
session nor run two sessions in the same directory, so I have never run 
it this, but there was a question on r-help where it may have been an issue.

Paul Gilbert

From Kurt.Hornik at wu-wien.ac.at  Thu Jun 10 08:40:53 2004
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu Jun 10 08:40:31 2004
Subject: [Rd] Add links to NEWS/ChangeLog to package pages
In-Reply-To: <85u0xktrjq.fsf@servant.blindglobe.net>
References: <D7A3CFD7825BD6119B880002A58F06C20C521509@groexmb02.pfizer.com>
	<85vfi0wq9p.fsf@servant.blindglobe.net>
	<20040609200751.GA10579@sonny.eddelbuettel.com>
	<85u0xktrjq.fsf@servant.blindglobe.net>
Message-ID: <16584.629.227681.6830@mithrandir.hornik.net>

>>>>> A J Rossini writes:

> Dirk, I'm thinking of the application to CRAN, where it might be
> standardizable; not to Debian, where it could only produce holy wars,
> flamage, and bikeshedding.

> i.e. I'd love to be able to do:

>      update.packages(ListChanges=TRUE, ListBugs=TRUE)

If we believe in the GNU development model, it is either NEWS or
ChangeLog (top-level).  Currently, these are not copied over at install
time, but we could easily change that for 2.0.

Myself being a Debian and apt-listchanges user, I would very much like
to have something similar for R.  Not sure if it is feasible, though:
just because there is a file called NEWS, we know nothing about its
structure and whether we'll be able to do anything useful with it.
(Note also that I think the Debian changelog file used by
apt-listchanges is not the "usual" traditional ChangeLog file.)

In general, all these needs for having and computing on additional
information means, I think, that we want to move towards XML ...

-k

> best,
> -tony


> Dirk Eddelbuettel <edd@debian.org> writes:

>> On Wed, Jun 09, 2004 at 11:16:34AM -0700, A.J. Rossini wrote:
>>> 
>>> That's a great idea, Greg!  (actually, have you seen the
>>> apt-listchanges and apt-listbugs features on debian, which does the
>>> same prior to install?  Then you can abort the install if the changes
>>> aren't what you want (or if outstanding bugs have/havn't been
>>> fixed/introduced, which is even better, but linking in a bugtracking
>>> system would be a PITA).
>> 
>> It is a good idea -- but we currently do not have a standard of 
>> -- whether it is CHANGES, ChangeLog or changelog
>> -- whether it is in the top-level or the inst directory
>> 
>> edd@chibud:~/src/debian/CRAN> ls */CHANGES
>> multcomp-0.4.6/CHANGES  mvtnorm-0.6.8/CHANGES
>> edd@chibud:~/src/debian/CRAN> ls */ChangeLog
>> Rmpi-0.4.8/ChangeLog     date-1.2.17/ChangeLog    gregmisc-1.11.1/ChangeLog
>> nlme-3.1.48/ChangeLog     rsprng-0.3.1/ChangeLog
>> abind-1.1.0/ChangeLog    date-1.2.18/ChangeLog    gregmisc-1.11.2/ChangeLog
>> quadprog-1.4.7/ChangeLog  tseries-0.9.21/ChangeLog
>> cluster-1.9.1/ChangeLog  foreign-0.6.9/ChangeLog  lattice-0.9.12/ChangeLog
>> rpvm-0.6.2/ChangeLog
>> edd@chibud:~/src/debian/CRAN> ls */inst/CHANGES
>> Rcmdr-0.9.8/inst/CHANGES  car-1.0.12/inst/CHANGES  effects-1.0.5/inst/CHANGES
>> edd@chibud:~/src/debian/CRAN> ls */inst/ChangeLog
>> ls: */inst/ChangeLog: No such file or directory
>> 
>> Dirk
>> 
>>> 
>>> best,
>>> -tony
>>> 
>>> 
>>> "Warnes, Gregory R" <gregory_r_warnes@groton.pfizer.com> writes:
>>> 
>>> > Just a thought:
>>> >
>>> > It would be nice to be able to review the NEWS and/or ChangeLog files for
>>> > packages via the package web page on CRAN...
>>> >
>>> > -Greg
>>> >
>>> > Gregory R. Warnes
>>> > Manager, Non-Clinical Statistics
>>> > Pfizer Global Research and Development
>>> >
>>> >
>>> >
>>> > LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
>>> >
>>> > ______________________________________________
>>> > R-devel@stat.math.ethz.ch mailing list
>>> > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>> >
>>> 
>>> -- 
>>> rossini@u.washington.edu            http://www.analytics.washington.edu/ 
>>> Biomedical and Health Informatics   University of Washington
>>> Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
>>> UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
>>> FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email
>>> 
>>> CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}
>>> 
>>> ______________________________________________
>>> R-devel@stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> -- 
>> FEATURE:  VW Beetle license plate in California
>> 

> -- 
> rossini@u.washington.edu            http://www.analytics.washington.edu/ 
> Biomedical and Health Informatics   University of Washington
> Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
> UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
> FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

> CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}

> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Thu Jun 10 08:51:17 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jun 10 08:51:22 2004
Subject: [Rd] .Random.seed saved in .RData
In-Reply-To: <40C7A30B.1090103@bankofcanada.ca>
Message-ID: <Pine.LNX.4.44.0406100746550.3886-100000@gannet.stats>

On Wed, 9 Jun 2004, Paul Gilbert wrote:

> Is it intentional that the .Random.seed is saved in .RData?  If people 

Yes.  (And it happens in S-PLUS equivalently.)  The idea of saving .RData
is to save the session where it left off, and perhaps go forward in
different ways from the same session, e.g. to stop after 37 more
simulations and examine what happened there.

> run multiple sessions from the same directory they will get the same 
> intial seed setting, which seems a bit dangerous. I don't often save my 
> session nor run two sessions in the same directory, so I have never run 
> it this, but there was a question on r-help where it may have been an issue.

I don't think it was the issue there.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From xinan at molgen.mpg.de  Thu Jun 10 09:04:05 2004
From: xinan at molgen.mpg.de (Xinan Yang)
Date: Thu Jun 10 09:04:11 2004
Subject: [Rd] question about similarities cluster using hierclust
Message-ID: <40C807E5.7000008@molgen.mpg.de>

my major is bioinformatics, and i'm trying to cluster ( agglomerate
the closest pari of observations ) in R.


i have already got my own similarities metric, but do not know how to
clust it based on similarities instead of dissimilarities.


since the help document of hierclust mentions the parameter "sim",
which seems good to me, but it doesn't appear in the code of
hierclust() function again? and no sample about it.  so could anybody
please help me as author?

thanks in advance

xinan yang
xinan@molgen.mpg.de

From ripley at stats.ox.ac.uk  Thu Jun 10 09:04:17 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jun 10 09:04:20 2004
Subject: [Rd] Re: [R] Help with a Lattice plot that fails with an empty
 unique combination
In-Reply-To: <200406091804.38752.deepayan@stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0406100754520.3886-100000@gannet.stats>

This is surely a bug in jitter, which should pass through a 0-length input 
unchanged as S does (and I will fix that).

I do wonder what jitter should do with a length-1 input.  It does change 
it, using a rather arbitrary notion of the scale of the change (as does 
S).  Given the description

     'jitter(x,...)' returns a numeric of the same length as 'x', but
     with an 'amount' of noise added in order to break ties.

it appears it should not change a length-1 input.

Opinions?


On Wed, 9 Jun 2004, Deepayan Sarkar wrote:

> On Wednesday 09 June 2004 01:58, Tom Mulholland wrote:
> > While using Lattice I received the following error.
> >
> > Error in if (xx != 0) xx/10 else z/10 : argument is of length zero
> > In addition: Warning messages:
> > 1: is.na() applied to non-(list or vector) in: is.na(x)
> > 2: is.na() applied to non-(list or vector) in: is.na(x)
> > 3: no finite arguments to min; returning Inf
> > 4: no finite arguments to max; returning -Inf
> > 5: NaNs produced in: log(x, base)
> > Can anyone point me in the right direction.
> 
> A traceback() shows that this is happening due to jitter() being called 
> with a length-0 numeric. I have added a check in panel.stripplot. Until 
> the next release, you can work around it by:
> 
> 
> assignInNamespace("panel.stripplot",     
>     function(x, y, jitter.data = FALSE, factor = 0.5,
>              horizontal = TRUE, groups = NULL, ...)
> {
>     if (length(x) < 1) return()
>     x <- as.numeric(x)
>     y <- as.numeric(y)
>     y.jitter  <-
>         if (horizontal && jitter.data) 
>             jitter(y, factor = factor) else y
>     x.jitter  <-
>         if (!horizontal && jitter.data) 
>             jitter(x, factor = factor) else x
>     if (is.null(groups)) panel.xyplot(x = x.jitter, 
>         y = y.jitter, ...) else 
>     panel.superpose(x = x.jitter, y = y.jitter, 
>         groups = groups, ...)
> }, "lattice")
> 
> 
> Deepayan
> 
> ______________________________________________
> R-help@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Thu Jun 10 09:30:37 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Jun 10 09:30:39 2004
Subject: [Rd] question about similarities cluster using hierclust
In-Reply-To: <40C807E5.7000008@molgen.mpg.de>
References: <40C807E5.7000008@molgen.mpg.de>
Message-ID: <16584.3613.234051.419924@gargle.gargle.HOWL>

Hmm,

why on earth are you using hierclust() from the ORPHANED package
'multiv',  when there's  hclust() in the core 'stats' package
and 'agnes' in the recommended 'cluster' package ?

To your question  "similarities -> dissimilarities"
the textbooks all deal with this.

Assuming similarities s_ij in [0,1]  {which you can get by scaling},
things mentioned are
e.g.,
       d_ij := 1 - s_ij
       d_ij := sqrt(1 - (s_ij)^2)
also   d_ij := sqrt(1 -   s_ij)

but really, in your situation where you're defining your
similarities yourself, you probably should rather think about
defining your dissimilarities yourself *directly* {i.e. not via
the above formulae}.

Martin Maechler

>>>>> "Xinan" == Xinan Yang <xinan@molgen.mpg.de>
>>>>>     on Thu, 10 Jun 2004 09:04:05 +0200 writes:

    Xinan> my major is bioinformatics, and i'm trying to cluster ( agglomerate
    Xinan> the closest pari of observations ) in R.


    Xinan> i have already got my own similarities metric, but do not know how to
    Xinan> clust it based on similarities instead of dissimilarities.


    Xinan> since the help document of hierclust mentions the parameter "sim",
    Xinan> which seems good to me, but it doesn't appear in the code of
    Xinan> hierclust() function again? and no sample about it.  so could anybody
    Xinan> please help me as author?

    Xinan> thanks in advance

    Xinan> xinan yang
    Xinan> xinan@molgen.mpg.de

From maechler at stat.math.ethz.ch  Thu Jun 10 09:36:42 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Jun 10 09:36:44 2004
Subject: [Rd] Re: [R] Help with a Lattice plot that fails with an empty
	unique combination
In-Reply-To: <Pine.LNX.4.44.0406100754520.3886-100000@gannet.stats>
References: <200406091804.38752.deepayan@stat.wisc.edu>
	<Pine.LNX.4.44.0406100754520.3886-100000@gannet.stats>
Message-ID: <16584.3978.930989.660589@gargle.gargle.HOWL>

>>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
>>>>>     on Thu, 10 Jun 2004 08:04:17 +0100 (BST) writes:

    BDR> This is surely a bug in jitter, which should pass through a 0-length input 
    BDR> unchanged as S does (and I will fix that).

    BDR> I do wonder what jitter should do with a length-1 input.  It does change 
    BDR> it, using a rather arbitrary notion of the scale of the change (as does 
    BDR> S).  Given the description

    BDR> 'jitter(x,...)' returns a numeric of the same length as 'x', but
    BDR> with an 'amount' of noise added in order to break ties.

    BDR> it appears it should not change a length-1 input.

    BDR> Opinions?

I agree with you:  It shouldn't change a length-1 input by
default (when no 'amount' is specified)
One could argue that it should add jitter when a positive
'amount' is specified explicitly.  But I'd still vote for having
return length-1 arguments unaltered.

Martin

From kestler at onlinehome.de  Thu Jun 10 13:11:48 2004
From: kestler at onlinehome.de (kestler@onlinehome.de)
Date: Thu Jun 10 13:11:50 2004
Subject: [Rd] =?iso-8859-1?q?Can=B4t_start_help_and_update_on_Mac_=28PR?=
	=?iso-8859-1?q?=236920?=
Message-ID: <20040610111148.217B7108F0@slim.kubism.ku.dk>


--Apple-Mail-1--963012407
Content-Transfer-Encoding: 7bit
Content-Type: text/plain;
	charset=US-ASCII;
	format=flowed

Hi,

I get exactly the same error message as in report no 6920. Furthermore, 
starting "update Bioconducter" the following message appears (running 
Mac OS X 10.3.4 (7H63)) :

 > {library(reposTools);update.packages2(getAllDeps=TRUE)}

Synching your local package management information ...
Packages which have been added/updated:
	sm
	sma
	wavethresh
	


	Note: reposTools can not access 
/Library/Frameworks/R.framework/Resources/library.
	This will not affect your R session unless you wish
	to install/update/remove packages from this directory

Note: argument `lib' is missing: using /Users/admin/Library/R/library
  Note: argument `lib' is missing: using 
/Library/Frameworks/R.framework/Resources/library
  Note: argument `lib' is missing: using 
/tmp/RtmpKEgaWQ/tempLibs/file3ab50c2a

Synching your local package management information ...

	Note: reposTools can not access 
/Library/Frameworks/R.framework/Resources/library.
	This will not affect your R session unless you wish
	to install/update/remove packages from this directory

Error in lapply(locLibList, Package) : Object "locLibList" not found

 >


Sincerely

           Hans Kestler
--Apple-Mail-1--963012407
Content-Transfer-Encoding: 7bit
Content-Type: text/enriched;
	charset=US-ASCII

Hi,


I get exactly the same error message as in report no 6920.
Furthermore, starting "update Bioconducter" the following message
appears
(<fontfamily><param>Lucida Grande</param><x-tad-smaller>running Mac OS
X 10.3.4 (7H63)</x-tad-smaller></fontfamily>) :


<fixed><color><param>0000,0000,FFFF</param><x-tad-bigger>>
{library(reposTools);update.packages2(getAllDeps=TRUE)}


Synching your local package management information ...

Packages which have been added/updated:

	sm

	sma

	wavethresh

	



	Note: reposTools can not access
/Library/Frameworks/R.framework/Resources/library.

	This will not affect your R session unless you wish 

	to install/update/remove packages from this directory

 

Note: argument `lib' is missing: using /Users/admin/Library/R/library 

 Note: argument `lib' is missing: using
/Library/Frameworks/R.framework/Resources/library 

 Note: argument `lib' is missing: using
/tmp/RtmpKEgaWQ/tempLibs/file3ab50c2a 


Synching your local package management information ...


	Note: reposTools can not access
/Library/Frameworks/R.framework/Resources/library.

	This will not affect your R session unless you wish 

	to install/update/remove packages from this directory

 

Error in lapply(locLibList, Package) : Object "locLibList" not found


> 



</x-tad-bigger></color><color><param>0000,0000,0000</param><x-tad-bigger>Sincerely 


          Hans Kestler</x-tad-bigger></color></fixed>
--Apple-Mail-1--963012407--

From ripley at stats.ox.ac.uk  Thu Jun 10 13:37:27 2004
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jun 10 13:37:31 2004
Subject: [Rd] =?iso-8859-1?q?Can=B4t_start_help_and_update_on_Mac_=28PR?=
	(PR#6964)
Message-ID: <20040610113727.134F510565@slim.kubism.ku.dk>

reposTools is part of Bioconductor not R.  Please use the correct bug 
repository.

Note that PR#6920 does not mention any `error message' whatsoever (nor
does it claim to): the message quoted

help.start()
Making links in per-session dir ...
If /usr/bin/open is already running, it is *not* restarted, and you 
must switch to its
     window.
Otherwise, be patient ...

is the standard informational message.  We need to know what the error 
actually is.  If no browser window opens, then does it help to have one 
open already?  (Was true of Netscape 7.0.)  Does setting a more standard 
browser (e.g. Mozilla) solve this ....

On Thu, 10 Jun 2004 kestler@onlinehome.de wrote:

> 
> --Apple-Mail-1--963012407
> Content-Transfer-Encoding: 7bit
> Content-Type: text/plain;
> 	charset=US-ASCII;
> 	format=flowed
> 
> Hi,
> 
> I get exactly the same error message as in report no 6920. Furthermore, 
> starting "update Bioconducter" the following message appears (running 
> Mac OS X 10.3.4 (7H63)) :
> 
>  > {library(reposTools);update.packages2(getAllDeps=TRUE)}
> 
> Synching your local package management information ...
> Packages which have been added/updated:
> 	sm
> 	sma
> 	wavethresh
> 	
> 
> 
> 	Note: reposTools can not access 
> /Library/Frameworks/R.framework/Resources/library.
> 	This will not affect your R session unless you wish
> 	to install/update/remove packages from this directory
> 
> Note: argument `lib' is missing: using /Users/admin/Library/R/library
>   Note: argument `lib' is missing: using 
> /Library/Frameworks/R.framework/Resources/library
>   Note: argument `lib' is missing: using 
> /tmp/RtmpKEgaWQ/tempLibs/file3ab50c2a
> 
> Synching your local package management information ...
> 
> 	Note: reposTools can not access 
> /Library/Frameworks/R.framework/Resources/library.
> 	This will not affect your R session unless you wish
> 	to install/update/remove packages from this directory
> 
> Error in lapply(locLibList, Package) : Object "locLibList" not found
> 
>  >
> 
> 
> Sincerely
> 
>            Hans Kestler


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Thu Jun 10 13:37:06 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jun 10 13:37:33 2004
Subject: [Rd] =?iso-8859-1?q?Can=B4t_start_help_and_update_on_Mac_=28PR?=
	=?iso-8859-1?q?=236920?=
In-Reply-To: <20040610111148.217B7108F0@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406101230240.6134-100000@gannet.stats>

reposTools is part of Bioconductor not R.  Please use the correct bug 
repository.

Note that PR#6920 does not mention any `error message' whatsoever (nor
does it claim to): the message quoted

help.start()
Making links in per-session dir ...
If /usr/bin/open is already running, it is *not* restarted, and you 
must switch to its
     window.
Otherwise, be patient ...

is the standard informational message.  We need to know what the error 
actually is.  If no browser window opens, then does it help to have one 
open already?  (Was true of Netscape 7.0.)  Does setting a more standard 
browser (e.g. Mozilla) solve this ....

On Thu, 10 Jun 2004 kestler@onlinehome.de wrote:

> 
> --Apple-Mail-1--963012407
> Content-Transfer-Encoding: 7bit
> Content-Type: text/plain;
> 	charset=US-ASCII;
> 	format=flowed
> 
> Hi,
> 
> I get exactly the same error message as in report no 6920. Furthermore, 
> starting "update Bioconducter" the following message appears (running 
> Mac OS X 10.3.4 (7H63)) :
> 
>  > {library(reposTools);update.packages2(getAllDeps=TRUE)}
> 
> Synching your local package management information ...
> Packages which have been added/updated:
> 	sm
> 	sma
> 	wavethresh
> 	
> 
> 
> 	Note: reposTools can not access 
> /Library/Frameworks/R.framework/Resources/library.
> 	This will not affect your R session unless you wish
> 	to install/update/remove packages from this directory
> 
> Note: argument `lib' is missing: using /Users/admin/Library/R/library
>   Note: argument `lib' is missing: using 
> /Library/Frameworks/R.framework/Resources/library
>   Note: argument `lib' is missing: using 
> /tmp/RtmpKEgaWQ/tempLibs/file3ab50c2a
> 
> Synching your local package management information ...
> 
> 	Note: reposTools can not access 
> /Library/Frameworks/R.framework/Resources/library.
> 	This will not affect your R session unless you wish
> 	to install/update/remove packages from this directory
> 
> Error in lapply(locLibList, Package) : Object "locLibList" not found
> 
>  >
> 
> 
> Sincerely
> 
>            Hans Kestler


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Pascal.Niklaus at unibas.ch  Thu Jun 10 14:08:42 2004
From: Pascal.Niklaus at unibas.ch (Pascal.Niklaus@unibas.ch)
Date: Thu Jun 10 14:08:48 2004
Subject: [Rd] Compiling under SuSE 9.1 (PR#6965)
Message-ID: <20040610120842.7F94D108B3@slim.kubism.ku.dk>

Full_Name: Pascal
Version: 1.9.0
OS: GNU/Linux 
Submission from: (NULL) (212.152.21.2)


In order to compile under SuSE 9.1, I needed to change 

#define NeedFunctionPrototypes 0

to 

#define NeedFunctionPrototypes 1

in line 29 of src/modules/X11/dataentry.c;

/* don't use X11 function prototypes (which tend to ...): */
#define NeedFunctionPrototypes 1
#include <X11/X.h>


HTH

Pascal

From ripley at stats.ox.ac.uk  Thu Jun 10 14:22:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jun 10 14:22:59 2004
Subject: [Rd] Compiling under SuSE 9.1 (PR#6965)
In-Reply-To: <20040610120842.7F94D108B3@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406101313210.6302-100000@gannet.stats>

This is not a bug in R, and already covered in

- already fixed in the alpha release of R 1.9.1 under test. From the NEWS 
file

    o	src/modules/X11/dataentry.c would not build on some XFree
	4.4.0 systems.	(This is a bug in their header files but we have
	added a workaround.)


- the same as PR#6805, PR#6844 and PR#6855

so you are the fourth person not to do an adequate search before reporting 
a bug in XFree86 to R.

Please do now report the problem to the actual originator.

On Thu, 10 Jun 2004 Pascal.Niklaus@unibas.ch wrote:

> Full_Name: Pascal
> Version: 1.9.0
> OS: GNU/Linux 
> Submission from: (NULL) (212.152.21.2)
> 
> 
> In order to compile under SuSE 9.1, I needed to change 
> 
> #define NeedFunctionPrototypes 0
> 
> to 
> 
> #define NeedFunctionPrototypes 1
> 
> in line 29 of src/modules/X11/dataentry.c;
> 
> /* don't use X11 function prototypes (which tend to ...): */
> #define NeedFunctionPrototypes 1
> #include <X11/X.h>

And what makes you think that is a bug in R?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Kurt.Hornik at wu-wien.ac.at  Thu Jun 10 14:26:41 2004
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu Jun 10 14:26:17 2004
Subject: [Rd] barplot() behavior changes under 1.9.1 Alpha
In-Reply-To: <1086026044.27028.87.camel@localhost>
References: <1086026044.27028.87.camel@localhost>
Message-ID: <16584.21377.977508.546555@mithrandir.hornik.net>

>>>>> Marc Schwartz writes:

> Greetings all,
> It would appear that some default behavior changes for barplot() have
> been introduced into Version 1.9.1 alpha (2004-05-30).

> One change is in the specification of the default 'col' argument, which
> is now:

> col: a vector of colors for the bars or bar components. By default, grey
> is used if height is a vector, and heat.colors(nrow(height)) if height
> is a matrix.


> 'col' now defaults to NULL, whereas up through 1.9.0-patched it
> defaulted to 'col = heat.colors(NR)'.

> I just completed the installation/upgrade of FC2 this weekend and
> thought initially there was a problem with FC2, until I
> compiled/re-installed a copy of '1.9.0-patched' and noted the old
> behavior.

> Can this change be noted in the NEWS file?  I did not see it noted
> there, which contributed to my confusion until I reviewed the code and
> help file.

> Also, it would appear that the initial change in 1.9.0's barplot(),
> which caused some problems for folks relative to using the output of
> table() as the input for the 'height' argument, has been restored to the
> 1.8.1 behavior. The 1.9.0 change from 1.8.1 was reported in r-bugs
> #6776.

> It would appear from a code review that the initial checks of the
> 'height' argument in barplot() have been restructured in 1.9.1-alpha,
> restoring the 1.8.1 style behavior.

> Can this change also be documented in the NEWS file?

Mark,

Thanks for bringing this up.  I have now changed NEWS to say

    o   The default barplot method now handles vectors and 1-d arrays
        (e.g., obtained by table()) the same, and uses grey instead of
        heat color palettes in these cases.  (Also fixes PR#6776.)

It is not true that the 1.8.1 behavior has been restored.  1.8.1 treated
vectors and 1-d arrays differently, which after long discussions has
been decided to be a bug :-)

Best
-k

From jago at mclink.it  Thu Jun 10 14:49:42 2004
From: jago at mclink.it (stefano iacus)
Date: Thu Jun 10 14:49:45 2004
Subject: =?ISO-8859-1?Q?Re:_[Rd]_Can=B4t_start_help_and_update_on_Mac_=28?=
	=?ISO-8859-1?Q?PR#6920?=
In-Reply-To: <Pine.LNX.4.44.0406101230240.6134-100000@gannet.stats>
References: <Pine.LNX.4.44.0406101230240.6134-100000@gannet.stats>
Message-ID: <A4DEC3AA-BADC-11D8-B1DD-000A95C87F66@mclink.it>

"open" works on my system, so it seems something related to user 
specific settings.
Can you please try to issue the command open from a Terminal on a html 
file to see if safari or your favorite browser pops up?

i.e.

open my_file.html

stefano

On Jun 10, 2004, at 1:37 PM, Prof Brian Ripley wrote:

> reposTools is part of Bioconductor not R.  Please use the correct bug
> repository.
>
> Note that PR#6920 does not mention any `error message' whatsoever (nor
> does it claim to): the message quoted
>
> help.start()
> Making links in per-session dir ...
> If /usr/bin/open is already running, it is *not* restarted, and you
> must switch to its
>      window.
> Otherwise, be patient ...
>
> is the standard informational message.  We need to know what the error
> actually is.  If no browser window opens, then does it help to have one
> open already?  (Was true of Netscape 7.0.)  Does setting a more 
> standard
> browser (e.g. Mozilla) solve this ....
>
> On Thu, 10 Jun 2004 kestler@onlinehome.de wrote:
>
>>
>> --Apple-Mail-1--963012407
>> Content-Transfer-Encoding: 7bit
>> Content-Type: text/plain;
>> 	charset=US-ASCII;
>> 	format=flowed
>>
>> Hi,
>>
>> I get exactly the same error message as in report no 6920. 
>> Furthermore,
>> starting "update Bioconducter" the following message appears (running
>> Mac OS X 10.3.4 (7H63)) :
>>
>>> {library(reposTools);update.packages2(getAllDeps=TRUE)}
>>
>> Synching your local package management information ...
>> Packages which have been added/updated:
>> 	sm
>> 	sma
>> 	wavethresh
>> 	
>>
>>
>> 	Note: reposTools can not access
>> /Library/Frameworks/R.framework/Resources/library.
>> 	This will not affect your R session unless you wish
>> 	to install/update/remove packages from this directory
>>
>> Note: argument `lib' is missing: using /Users/admin/Library/R/library
>>   Note: argument `lib' is missing: using
>> /Library/Frameworks/R.framework/Resources/library
>>   Note: argument `lib' is missing: using
>> /tmp/RtmpKEgaWQ/tempLibs/file3ab50c2a
>>
>> Synching your local package management information ...
>>
>> 	Note: reposTools can not access
>> /Library/Frameworks/R.framework/Resources/library.
>> 	This will not affect your R session unless you wish
>> 	to install/update/remove packages from this directory
>>
>> Error in lapply(locLibList, Package) : Object "locLibList" not found
>>
>>>
>>
>>
>> Sincerely
>>
>>            Hans Kestler
>
>
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From MSchwartz at MedAnalytics.com  Thu Jun 10 15:40:52 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu Jun 10 15:40:57 2004
Subject: [Rd] barplot() behavior changes under 1.9.1 Alpha
In-Reply-To: <16584.21377.977508.546555@mithrandir.hornik.net>
References: <1086026044.27028.87.camel@localhost>
	<16584.21377.977508.546555@mithrandir.hornik.net>
Message-ID: <1086874852.29898.314.camel@localhost.localdomain>

On Thu, 2004-06-10 at 07:26, Kurt Hornik wrote:
> >>>>> Marc Schwartz writes:
> 
> > Greetings all,
> > It would appear that some default behavior changes for barplot() have
> > been introduced into Version 1.9.1 alpha (2004-05-30).

snip

> > Can this change also be documented in the NEWS file?
> 
> Mark,
> 
> Thanks for bringing this up.  I have now changed NEWS to say
> 
>     o   The default barplot method now handles vectors and 1-d arrays
>         (e.g., obtained by table()) the same, and uses grey instead of
>         heat color palettes in these cases.  (Also fixes PR#6776.)
> 
> It is not true that the 1.8.1 behavior has been restored.  1.8.1 treated
> vectors and 1-d arrays differently, which after long discussions has
> been decided to be a bug :-)
> 
> Best
> -k

Hi Kurt!

Thanks for following up and the clarification.

As soon as I can take a breather from the current list of things I have
going, I will also make the requisite changes to barplot2() so that they
stay in synch.

Best regards,

Marc

From tkirsten at izbi.uni-leipzig.de  Thu Jun 10 18:22:43 2004
From: tkirsten at izbi.uni-leipzig.de (Toralf Kirsten)
Date: Thu Jun 10 18:22:57 2004
Subject: [Rd] Package installation
Message-ID: <40C88AD3.2000602@izbi.uni-leipzig.de>

Hi all,
I'm very new to R.
I have installed R 1.9.0 on Linux (Fedora).

Now I got an self-made package comprising R functions as well as C-Code 
which are used in several R functions.

I installed the package without any error (see install log below).
Then, I checked in /usr/lib/R/library if the package izbi exists and it 
exists.

But whenever I try to load the library on the command line I got the 
following error.
 > library(izbi)
Error in .find.package(package, lib.loc, verbose = verbose) :
         Object "izbi" not found
Error in library(izbi) : .First.lib failed


Unfortunately, the whole package is written and tested under R 1.8.0 on 
Linux (RedHat 9.0) and there are no problems loading and working with 
the library. To have a more cross check I installed the same package on 
my laptop using SUSE Linux with R 1.8.0. Ther are also no problems with 
loading and working with the package.


Does anybody knows what I can do?
Many thanks, Toralf

PS: If you need more info please let me know.



---- install log ---------
/u/geware/programs/analysis/R-packages (root) ->R CMD INSTALL izbi
* Installing *source* package 'izbi' ...
** libs
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c aggreg.c -o 
aggreg.o
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c grptest.c -o 
grptest.o
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c mathutils.c -o 
mathutils.o
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c uvartest.c -o 
uvartest.o
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c wyclust.c -o 
wyclust.o
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c wygrps.c -o 
wygrps.o
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c wyr.c -o wyr.o
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c wyutils.c -o 
wyutils.o
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c wyuvar.c -o 
wyuvar.o
gcc -shared -L/usr/local/lib -o izbi.so aggreg.o grptest.o mathutils.o 
uvartest.o wyclust.o wygrps.o wyr.o wyutils.o wyuvar.o
** R
** data
** help
  >>> Building/Updating help pages for package 'izbi'
      Formats: text html latex example
   COLS                              text    html    latex
   ROWS                              text    html    latex
   bin                               text    html    latex   example
   cor.total                         text    html    latex   example
   data.mat                          text    html    latex   example
   fac                               text    html    latex   example
   ubeta                             text    html    latex   example
   umbeta                            text    html    latex   example
   wy.clust                          text    html    latex   example
   wy.grps                           text    html    latex   example
   wy.uvar                           text    html    latex   example
* DONE (izbi)

From ligges at statistik.uni-dortmund.de  Thu Jun 10 18:32:39 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Jun 10 18:31:35 2004
Subject: [Rd] Package installation
In-Reply-To: <40C88AD3.2000602@izbi.uni-leipzig.de>
References: <40C88AD3.2000602@izbi.uni-leipzig.de>
Message-ID: <40C88D27.7000505@statistik.uni-dortmund.de>

Toralf Kirsten wrote:

> Hi all,
> I'm very new to R.
> I have installed R 1.9.0 on Linux (Fedora).
> 
> Now I got an self-made package comprising R functions as well as C-Code 
> which are used in several R functions.
> 
> I installed the package without any error (see install log below).
> Then, I checked in /usr/lib/R/library if the package izbi exists and it 
> exists.
> 
> But whenever I try to load the library on the command line I got the 
> following error.
>  > library(izbi)
> Error in .find.package(package, lib.loc, verbose = verbose) :
>         Object "izbi" not found
> Error in library(izbi) : .First.lib failed

Hmm. What is your actual library.dynam() call in .First.lib()?

Do you have read access to all the files in /usr/lib/R/library/izbi (in 
particular to ..../izbi/lib/izbi.so - and does it exist)?

Running R CMD check might give additional hints ...

Uwe Ligges



> 
> Unfortunately, the whole package is written and tested under R 1.8.0 on 
> Linux (RedHat 9.0) and there are no problems loading and working with 
> the library. To have a more cross check I installed the same package on 
> my laptop using SUSE Linux with R 1.8.0. Ther are also no problems with 
> loading and working with the package.
> 
> 
> Does anybody knows what I can do?
> Many thanks, Toralf
> 
> PS: If you need more info please let me know.
> 
> 
> 
> ---- install log ---------
> /u/geware/programs/analysis/R-packages (root) ->R CMD INSTALL izbi
> * Installing *source* package 'izbi' ...
> ** libs
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
> -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c aggreg.c -o 
> aggreg.o
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
> -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c grptest.c -o 
> grptest.o
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
> -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c mathutils.c -o 
> mathutils.o
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
> -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c uvartest.c -o 
> uvartest.o
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
> -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c wyclust.c -o 
> wyclust.o
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
> -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c wygrps.c -o 
> wygrps.o
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
> -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c wyr.c -o wyr.o
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
> -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c wyutils.c -o 
> wyutils.o
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
> -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c wyuvar.c -o 
> wyuvar.o
> gcc -shared -L/usr/local/lib -o izbi.so aggreg.o grptest.o mathutils.o 
> uvartest.o wyclust.o wygrps.o wyr.o wyutils.o wyuvar.o
> ** R
> ** data
> ** help
>  >>> Building/Updating help pages for package 'izbi'
>      Formats: text html latex example
>   COLS                              text    html    latex
>   ROWS                              text    html    latex
>   bin                               text    html    latex   example
>   cor.total                         text    html    latex   example
>   data.mat                          text    html    latex   example
>   fac                               text    html    latex   example
>   ubeta                             text    html    latex   example
>   umbeta                            text    html    latex   example
>   wy.clust                          text    html    latex   example
>   wy.grps                           text    html    latex   example
>   wy.uvar                           text    html    latex   example
> * DONE (izbi)
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From tkirsten at izbi.uni-leipzig.de  Thu Jun 10 18:42:58 2004
From: tkirsten at izbi.uni-leipzig.de (Toralf Kirsten)
Date: Thu Jun 10 18:42:15 2004
Subject: [Rd] Package installation
In-Reply-To: <40C88D27.7000505@statistik.uni-dortmund.de>
References: <40C88AD3.2000602@izbi.uni-leipzig.de>
	<40C88D27.7000505@statistik.uni-dortmund.de>
Message-ID: <40C88F92.4090006@izbi.uni-leipzig.de>

Hi Uwe,
thanks for your fast response.

The content of the file izbi/R/First.lib.R of the source package is as 
follows:
*************
.First.lib <- function(libname, pkgname) {
   library.dynam("izbi", package = pkgname, lib.loc = libname)
   data(COLS, package=izbi)
   data(ROWS, package=izbi)
}
*************

The check command also fails (see below).
Any hints?
Toralf

/u/geware/programs/analysis/R-packages (root) ->R CMD check izbi
* checking for working latex ... OK
* using log directory '/u/geware/programs/analysis/R-packages/izbi.Rcheck'
* checking for file 'izbi/DESCRIPTION' ... OK
* checking if this is a source package ... OK

* Installing *source* package 'izbi' ...
** libs
make: `izbi.so' is up to date.
** R
** data
** help
  >>> Building/Updating help pages for package 'izbi'
      Formats: text html latex example
   COLS                              text    html    latex
   ROWS                              text    html    latex
   bin                               text    html    latex   example
   cor.total                         text    html    latex   example
   data.mat                          text    html    latex   example
   fac                               text    html    latex   example
   ubeta                             text    html    latex   example
   umbeta                            text    html    latex   example
   wy.clust                          text    html    latex   example
   wy.grps                           text    html    latex   example
   wy.uvar                           text    html    latex   example
* DONE (izbi)

* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking package dependencies ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for syntax errors ... OK
* checking R files for library.dynam ... OK
* checking S3 generic/method consistency ... WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
character.only = TRUE, verbose = FALSE) :
         .First.lib failed
Execution halted
* checking for replacement functions with final arg not named 'value' 
... WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
character.only = TRUE, verbose = FALSE) :
         .First.lib failed
Execution halted
* checking foreign function calls ... WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
character.only = TRUE, verbose = FALSE) :
         .First.lib failed
Execution halted
* checking Rd files ... WARNING
Rd files with non-standard keywords:
   'man/fac.Rd': ~kwd2 ~kwd1
   'man/data.mat.Rd': ~kwd2 ~kwd1
   'man/wy.clust.Rd': ~kwd2 ~kwd1
   'man/bin.Rd': ~kwd2 ~kwd1
   'man/wy.uvar.Rd': ~kwd2 ~kwd1
   'man/cor.total.Rd': ~kwd2 correlation ~kwd1
   'man/wy.grps.Rd': ~kwd2 ~kwd1
   'man/ubeta.Rd': ~kwd2 ~kwd1
   'man/umbeta.Rd': ~kwd2 ~kwd1
Each '\keyword' entry should specify one of the standard keywords (as
listed in file 'KEYWORDS.db' in the 'doc' subdirectory of the R home
directory).
See chapter 'Writing R documentation files' in manual 'Writing R
Extensions'.
* checking for missing documentation entries ... ERROR
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
character.only = TRUE, verbose = FALSE) :





Uwe Ligges wrote:

> Toralf Kirsten wrote:
> 
>> Hi all,
>> I'm very new to R.
>> I have installed R 1.9.0 on Linux (Fedora).
>>
>> Now I got an self-made package comprising R functions as well as 
>> C-Code which are used in several R functions.
>>
>> I installed the package without any error (see install log below).
>> Then, I checked in /usr/lib/R/library if the package izbi exists and 
>> it exists.
>>
>> But whenever I try to load the library on the command line I got the 
>> following error.
>>  > library(izbi)
>> Error in .find.package(package, lib.loc, verbose = verbose) :
>>         Object "izbi" not found
>> Error in library(izbi) : .First.lib failed
> 
> 
> Hmm. What is your actual library.dynam() call in .First.lib()?
> 
> Do you have read access to all the files in /usr/lib/R/library/izbi (in 
> particular to ..../izbi/lib/izbi.so - and does it exist)?
> 
> Running R CMD check might give additional hints ...
> 
> Uwe Ligges
> 
> 
> 
>>
>> Unfortunately, the whole package is written and tested under R 1.8.0 
>> on Linux (RedHat 9.0) and there are no problems loading and working 
>> with the library. To have a more cross check I installed the same 
>> package on my laptop using SUSE Linux with R 1.8.0. Ther are also no 
>> problems with loading and working with the package.
>>
>>
>> Does anybody knows what I can do?
>> Many thanks, Toralf
>>
>> PS: If you need more info please let me know.


<snip>

From andy_liaw at merck.com  Thu Jun 10 18:45:38 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Jun 10 18:46:11 2004
Subject: [Rd] Package installation
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7E88@usrymx25.merck.com>

> From: Toralf Kirsten
> 
> Hi Uwe,
> thanks for your fast response.
> 
> The content of the file izbi/R/First.lib.R of the source 
> package is as 
> follows:
> *************
> .First.lib <- function(libname, pkgname) {
>    library.dynam("izbi", package = pkgname, lib.loc = libname)
>    data(COLS, package=izbi)
>    data(ROWS, package=izbi)
> }
> *************
> 
> The check command also fails (see below).
> Any hints?

Starting in R-1.9.0, I believe, you need to quote the package name in
data().

Andy


> Toralf

From tkirsten at izbi.uni-leipzig.de  Thu Jun 10 18:53:44 2004
From: tkirsten at izbi.uni-leipzig.de (Toralf Kirsten)
Date: Thu Jun 10 18:52:48 2004
Subject: [Rd] Package installation
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7E88@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7E88@usrymx25.merck.com>
Message-ID: <40C89218.1020806@izbi.uni-leipzig.de>

Hi Andy,
that solves the problem.
Many thanks again.
I'm really happy. ;-)
Toralf


Liaw, Andy wrote:

>>From: Toralf Kirsten
>>
>>Hi Uwe,
>>thanks for your fast response.
>>
>>The content of the file izbi/R/First.lib.R of the source 
>>package is as 
>>follows:
>>*************
>>.First.lib <- function(libname, pkgname) {
>>   library.dynam("izbi", package = pkgname, lib.loc = libname)
>>   data(COLS, package=izbi)
>>   data(ROWS, package=izbi)
>>}
>>*************
>>
>>The check command also fails (see below).
>>Any hints?
> 
> 
> Starting in R-1.9.0, I believe, you need to quote the package name in
> data().
> 
> Andy
> 
> 
> 
>>Toralf
> 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New Jersey, USA 08889), and/or its affiliates (which may be known outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be confidential, proprietary copyrighted and/or legally privileged. It is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please notify us immediately by reply e-mail and then delete it from your system.
> ------------------------------------------------------------------------------

From ripley at stats.ox.ac.uk  Thu Jun 10 18:53:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jun 10 18:53:05 2004
Subject: [Rd] Package installation
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7E88@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0406101751070.15525-100000@gannet.stats>

On Thu, 10 Jun 2004, Liaw, Andy wrote:

> > From: Toralf Kirsten
> > 
> > Hi Uwe,
> > thanks for your fast response.
> > 
> > The content of the file izbi/R/First.lib.R of the source 
> > package is as 
> > follows:
> > *************
> > .First.lib <- function(libname, pkgname) {
> >    library.dynam("izbi", package = pkgname, lib.loc = libname)
> >    data(COLS, package=izbi)
> >    data(ROWS, package=izbi)
> > }
> > *************
> > 
> > The check command also fails (see below).
> > Any hints?
> 
> Starting in R-1.9.0, I believe, you need to quote the package name in
> data().

Yes if it a string and not a variable, and since the package might get
renamed, I think you really want

.First.lib <- function(libname, pkgname) {
   library.dynam("izbi", package = pkgname, lib.loc = libname)
   data(COLS, package=pkgname)
   data(ROWS, package=pkgname)
}

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From mark0060 at tc.umn.edu  Thu Jun 10 19:00:27 2004
From: mark0060 at tc.umn.edu (mark0060@tc.umn.edu)
Date: Thu Jun 10 19:00:29 2004
Subject: [Rd] na.omit and class conversion (PR#6967)
Message-ID: <20040610170027.ABD04108F0@slim.kubism.ku.dk>

Full_Name: Kristian E. Markon
Version: 1.90
OS: WinXP
Submission from: (NULL) (24.26.179.28)


I have been having problems with na.omit, and am not sure if it is a bug, or new
behavior.

Basically, I observe exactly the same behavior as described in the bug
Language-fixed/522, but it occurs with classes other than matrices, including
data.frames. I am not sure how to reproduce it, as it sometimes occurs with
matrices, and sometimes not, and sometimes with data.frames and sometimes not.
It does occur repeatedly, however. 

I have observed another issue that may be related: It sometimes seems that
classes are not being converted. 

For example, if I do a factor analysis and save the loading matrix in an
object--e.g.,

temp.fa = factanal(covmat=x.cor, factors=2)

temp.load = temp.fa$load

I will sometimes get error messages that such and such is not possible with
loading matrices. 

For example, if I try to put the loadings in a list, and then convert the list
to a data.frame, as in

as.data.frame(list(items=names, load=temp.load)), I get an error stating that
loadings cannot be converted to data.frames. 

This error persists if I convert the loading matrix to a matrix class--e.g.,

as.data.frame(list(items=names, load=as.matrix(temp.load)))

However, if I create a matrix, and assign the loadings to this matrix--e.g.,

load.mat = matrix(nrow=35,ncol=2)

load.mat[1:35,1:2] = as.matrix(temp.load)

then the following command 

as.data.frame(list(items=names, load=temp.load))

works as expected. 

The reason why I suspect the na.omit problem may be related is that I seem to
observe na.omit problems more often when dealing with objects that have been
converted from one class to another.

From bolker at zoo.ufl.edu  Thu Jun 10 20:10:06 2004
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Thu Jun 10 19:12:04 2004
Subject: [Rd] overhaul of mle
Message-ID: <40C8A3FE.6030102@zoo.ufl.edu>

   So, I've embarked on my threatened modifications to the mle subset
of the stats4 package.    Most of what I've done so far has *not* been
adding the slick formula interface, but rather making it work properly
and reasonably robustly with real mle problems -- especially ones
involving reasonably complex fixed and default parameter sets.
Some of what I've done breaks backward compatibility (see below), but
there are what I think are some reasonably important design issues -- it
would be nice to get them fixed now, while the mle library is still
in its infancy ...

   I've appended quite a long list of changes and "to do" stuff, which
is also available at http://www.zoo.ufl.edu/bolker/mle/mle-changes.txt
also there are
http://www.zoo.ufl.edu/bolker/mle/mle-diffs.txt  (diffs against 1.9.1) and
http://www.zoo.ufl.edu/bolker/mle/mle.R (R code).

   I'm sure some of the code could be improved, especially in issues 
relating to eval() -- I'm not very good at that stuff.

   I apologize for changing so much at once, I got kind of carried away.
I look forward to comments on the various bits & pieces ...

   Ben Bolker

------------

*** = changes default behavior in a user-visible way that I consider
better, but arguably not just a bug fix: I've tried to justify these

*** added checking code at the beginning of mle() that converts named
numeric vectors into lists [this seems harmless to me -- is there a
reason not to allow the user to specify a named vector rather than a
list?  especially since start gets sapply'd back to a vector before it
gets passed to optim() anyway?]

Added some (probably not quite right) code to mle to make sure that
fullcoef gets evaluated properly when (1) the list contains
expressions and (2) the list contains expressions that depend on other
arguments e.g. fixed = list(a=y,b=x[y])
I used

     fullcoef <- lapply(fullcoef,eval,envir=fullcoef,
                        enclos=parent.frame(100))

but there may well be a better way to do it.

*** Changed type of fullcoef from "numeric" to "list", and return
fullcoef rather than unlist(fullcoef) from mle [couldn't see a rationale 
for this -- it destroys a lot of the information in fullcoef *and* is a
pain, say, when the fixed arguments include a data frame with lots of
information in it]

*** Changed "coef" method to return object@coef, not object@fullcoef
[this really seems to be the better choice to me -- I normally want to
see the *fitted values* of the MLE, not all the other auxiliary
stuff.  Besides, object@fullcoef can be very long, and therefore a
nuisance to see in the default show(object) method]

made a fullcoef accessor *function* to return object@fullcoef --
should this really be a method?

added a cor method for mle objects -- which just normalizes the
variance-covariance matrix to a correlation matrix.  Is this a bad
idea/perversion of the cor method?

changed variable "pi" to "p.i" throughout mle -- less confusing!

changed
call$fixed <- fix
to
call$fixed <- c(fix,eval(call$fixed))
for cases where there are non-trivial fixed arguments

added "follow" argument to profile: this makes profiling use a
continuation method where the starting point for each profile
optimization is the previous best-fit solution, rather than the
overall MLEs of the parameters.  Actually fairly easy to implement (I
think: I haven't really tested that it works on anything hard, just
that it doesn't seem to break profiling) -- requires pfit to be
assigned globally within onestep() and a few lines of code further
down.

added an AIC method for mle objects

collapsed the absVal/!absVal code cases slightly

added a "sqrVal" argument for those who want to see the value of the
log-likelihood, not the square root or signed square root (could be
collapsed into a "scale" argument for the profile plot = "sqrt",
"abssqrt", "lik")

added code and options to plot labels of confidence levels (logical
plot.confstr, character confstr)

added add= argument (to draw profiles on an existing plot)

added arguments for color of minimum values, confidence limits,
profile (col.minval, col.conf, col.prof)

added options for confidence interval: when applied to an mle object,
method "spline" does the previous behavior (profile and apply confint
to the result).  Method "quad" simply presents the quadratic
approximation to the confidence intervals.  Method "exact" uses
uniroot() to find the precise point where the profile crosses the
critical level in each direction.

Added mle.options() command, and .mle.options state variable, to keep
global options (method for optim() and method for confint()): I'm not
at all sure that this is the best way to implement options, this was
just my first crack at it

added a warning to show(mle) if optim() did not converge

Added code that allows (1) default arguments (evaluated
in the frame of the full coefficient list, with fixed values
and starting values substituted and (2) arguments specified in the
start list in arbitrary order (which seems like a reasonable expectation 
since
it *is* specified as a list).  The fundamental problem is that optim() 
loses names
of the parameter vector somewhere.
Example:

x = runif(200)
y = 1+x+x^2+rnorm(200,sd=0.05)
fn <- function(a,b,z=2,c,d) {
    -sum(dnorm(y,mean=a+c*x+d*x^2,sd=exp(b),log=TRUE))
}

m1 = mle(minuslogl=fn,start=list(a=1,b=1,c=1,d=1))
## fails with "missing argument" warning, about wrong argument
m1 = mle(minuslogl=fn,start=list(a=1,b=1,c=1,d=1),fixed=list(z=2))
## works
m2 = mle(minuslogl=fn,start=list(a=1,d=1,c=1,b=1),fixed=list(z=2))
## fails -- coeffs returned in wrong order


TO DO:

torture-test on some real problems!

better documentation?  e.g. ?profile.mle-class doesn't give details on
arguments -- have to look at profile.nls

(allow "which" to be a character vector -- match names)?

HARDER:
fancy formula interface [cf. svymle in survey package] e.g.
mll <-
mLL(type="independent",distrib="normal",resp=y,mean=~a+b*x,sd=~s,
       param=~a+b+s)

allow for fitting of transformed parameters (exp/log, tanh/atanh =
logistic/logit)

2D profiles (quadratic or thin-plate spline???)

EASIER but breaking backward compatibility:
merge absVal/sqrVal into a "scale" argument?

EASIER but ??worthwhile??:
allow spline to be turned off when plotting profiles?
   (method "spline"/"raw")?

code for producing/plotting "slices" (non-optimized transects through
parameter space); other diagnostic tools?

NOT SURE:
change show, show(summary) methods to bring them more in line with
other classes?

add test to confint(profile) that warns if method is supplied?

From ripley at stats.ox.ac.uk  Thu Jun 10 19:57:55 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jun 10 19:58:04 2004
Subject: [Rd] na.omit and class conversion (PR#6967)
In-Reply-To: <20040610170027.ABD04108F0@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406101855490.15593-100000@gannet.stats>

We need a reproducible example.  Please read the FAQ on BUGS and give an 
example and a clear example of why you are sure it is an error and not a 
misunderstanding.

On Thu, 10 Jun 2004 mark0060@tc.umn.edu wrote:

> Full_Name: Kristian E. Markon
> Version: 1.90
> OS: WinXP
> Submission from: (NULL) (24.26.179.28)
> 
> 
> I have been having problems with na.omit, and am not sure if it is a bug, or new
> behavior.
> 
> Basically, I observe exactly the same behavior as described in the bug
> Language-fixed/522, but it occurs with classes other than matrices, including
> data.frames. I am not sure how to reproduce it, as it sometimes occurs with
> matrices, and sometimes not, and sometimes with data.frames and sometimes not.
> It does occur repeatedly, however. 
> 
> I have observed another issue that may be related: It sometimes seems that
> classes are not being converted. 
> 
> For example, if I do a factor analysis and save the loading matrix in an
> object--e.g.,
> 
> temp.fa = factanal(covmat=x.cor, factors=2)
> 
> temp.load = temp.fa$load
> 
> I will sometimes get error messages that such and such is not possible with
> loading matrices. 
> 
> For example, if I try to put the loadings in a list, and then convert the list
> to a data.frame, as in
> 
> as.data.frame(list(items=names, load=temp.load)), I get an error stating that
> loadings cannot be converted to data.frames. 

True, and why do you think that is an error?

> This error persists if I convert the loading matrix to a matrix class--e.g.,
> 
> as.data.frame(list(items=names, load=as.matrix(temp.load)))
> 
> However, if I create a matrix, and assign the loadings to this matrix--e.g.,
> 
> load.mat = matrix(nrow=35,ncol=2)
> 
> load.mat[1:35,1:2] = as.matrix(temp.load)
> 
> then the following command 
> 
> as.data.frame(list(items=names, load=temp.load))
> 
> works as expected. 
> 
> The reason why I suspect the na.omit problem may be related is that I seem to
> observe na.omit problems more often when dealing with objects that have been
> converted from one class to another.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From notulei at yahoo.com  Fri Jun 11 02:29:08 2004
From: notulei at yahoo.com (Alex Nu)
Date: Fri Jun 11 02:29:14 2004
Subject: [Rd] bug or correct behaviour ?
Message-ID: <20040611002908.42114.qmail@web60109.mail.yahoo.com>


 This is the general outline of my code::
 
main(argc,argv){
   ...
   Rf_initEmbeddedR(argc,argv);
   ...
   Test_tryEval("source(test.r)");
   ...
}
############# 
# test.r
#############
...
dyn.load("toload.so")

tmp <-matrix(data=1,nrow=narray*2,ncol=nclust)

.Call("Init",tmp,...)
while(...) {
   criteria <-feval(tmp)
   if (criteria < criteria.min) 
        tmp.last <- tmp
   else  
       tmp <- tmp.last
   ...
   .Call("replace",tmp,...)
}
####################################


 When I try to recover tmp 

      tmp <- tmp.last
 
 I got the modified value of tmp.
 It means that tmp.last is modified
 when I modified tmp in the C funciont replace.
 
 The program seems to work fine if I change 
 to this::
            
  tmp.last <- tmp*1.0
  
  tmp <- tmp.last*1.0


 Any comments ?

 Alex

From ripley at stats.ox.ac.uk  Fri Jun 11 08:58:59 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jun 11 08:59:01 2004
Subject: [Rd] bug or correct behaviour ?
In-Reply-To: <20040611002908.42114.qmail@web60109.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0406110742540.16535-100000@gannet.stats>

Without seeing your code for the .Call parts it is impossible for us to
know, but as .Call does not duplicate its arguments (unlike .C), it is
possible for it to change both tmp and a copy of tmp, tmp.last.

So it seems likely there is a bug in your C code if that is not your 
intention.  The normal way to use .Call is to return something, and to 
duplicate any arguments which will be changed (possibly only provided 
NAMED(tmp) is true as otherwise there are no named copies around).

In other words, it would be normal to have

tmp <- .Call("Replace", tmp, ...)

and call duplicate() inside the C code for Replace.

On Thu, 10 Jun 2004, Alex Nu wrote:

> 
>  This is the general outline of my code::
>  
> main(argc,argv){
>    ...
>    Rf_initEmbeddedR(argc,argv);
>    ...
>    Test_tryEval("source(test.r)");
>    ...
> }

Not sure of the relevance of this.

> ############# 
> # test.r
> #############
> ...
> dyn.load("toload.so")
> 
> tmp <-matrix(data=1,nrow=narray*2,ncol=nclust)
> 
> .Call("Init",tmp,...)
> while(...) {
>    criteria <-feval(tmp)
>    if (criteria < criteria.min) 
>         tmp.last <- tmp

That makes a potential copy. The actual copying occurs if tmp is changed
and R is aware of it.  This is the purpose of the 'named' element of a
SEXP, but I don't think that is documented anywhere.

>    else  
>        tmp <- tmp.last
>    ...
>    .Call("replace",tmp,...)
> }
> ####################################
> 
> 
>  When I try to recover tmp 
> 
>       tmp <- tmp.last
>  
>  I got the modified value of tmp.
>  It means that tmp.last is modified
>  when I modified tmp in the C funciont replace.
>  
>  The program seems to work fine if I change 
>  to this::
>             
>   tmp.last <- tmp*1.0
>   
>   tmp <- tmp.last*1.0

Those do definitely make new objects.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Fri Jun 11 15:21:54 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Jun 11 15:29:03 2004
Subject: [Rd] overhaul of mle
In-Reply-To: <40C8A3FE.6030102@zoo.ufl.edu>
References: <40C8A3FE.6030102@zoo.ufl.edu>
Message-ID: <x2n03ab571.fsf@biostat.ku.dk>

Ben Bolker <bolker@zoo.ufl.edu> writes:

> *** Changed type of fullcoef from "numeric" to "list", and return
> fullcoef rather than unlist(fullcoef) from mle [couldn't see a
> rationale for this -- it destroys a lot of the information in fullcoef
> *and* is a
> pain, say, when the fixed arguments include a data frame with lots of
> information in it]

Wait a minute. How can a likelihood function have an argument that is
a data frame? I think you're abusing the fixed arguments if you use it
to pass in data. The natural paradigm for that would be to pass data
via a closure, i.e. 

mll <- with(data,
    function(lambda=1,theta=0)sum(dpois(y, lambda+theta*x, log=TRUE))
)

 
> *** Changed "coef" method to return object@coef, not object@fullcoef
> [this really seems to be the better choice to me -- I normally want to
> see the *fitted values* of the MLE, not all the other auxiliary
> stuff.  Besides, object@fullcoef can be very long, and therefore a
> nuisance to see in the default show(object) method]

See above. This was never intended to contain auxiliary stuff (and
AFAIR has already been changed once in the opposite direction, by Brian)
 
> made a fullcoef accessor *function* to return object@fullcoef --
> should this really be a method?
> 
> added a cor method for mle objects -- which just normalizes the
> variance-covariance matrix to a correlation matrix.  Is this a bad
> idea/perversion of the cor method?

Yes, I think so. cov2cor(vcov(ml.obj)) is easy enough.

> changed variable "pi" to "p.i" throughout mle -- less confusing!

OK. 
 
> changed
> call$fixed <- fix
> to
> call$fixed <- c(fix,eval(call$fixed))
> for cases where there are non-trivial fixed arguments

Which there shouldn't be...
 
> added "follow" argument to profile: this makes profiling use a
> continuation method where the starting point for each profile
> optimization is the previous best-fit solution, rather than the
> overall MLEs of the parameters.  Actually fairly easy to implement (I
> think: I haven't really tested that it works on anything hard, just
> that it doesn't seem to break profiling) -- requires pfit to be
> assigned globally within onestep() and a few lines of code further
> down.

Sounds nice, but surely you don't need a global assignment there? A
superassign ("<<-") perhaps, but that doesn't need to go to
.GlobalEnv. 


> added an AIC method for mle objects
> 
> collapsed the absVal/!absVal code cases slightly
> 
> added a "sqrVal" argument for those who want to see the value of the
> log-likelihood, not the square root or signed square root (could be
> collapsed into a "scale" argument for the profile plot = "sqrt",
> "abssqrt", "lik")
> 
> added code and options to plot labels of confidence levels (logical
> plot.confstr, character confstr)
> 
> added add= argument (to draw profiles on an existing plot)
> 
> added arguments for color of minimum values, confidence limits,
> profile (col.minval, col.conf, col.prof)
> 
> added options for confidence interval: when applied to an mle object,
> method "spline" does the previous behavior (profile and apply confint
> to the result).  Method "quad" simply presents the quadratic
> approximation to the confidence intervals.  Method "exact" uses
> uniroot() to find the precise point where the profile crosses the
> critical level in each direction.

All fine. The last one could be important as I had a case where the
spline method went rather badly wrong (the data it happened with are
still rather heavily embargoed I'm afraid). 

> Added mle.options() command, and .mle.options state variable, to keep
> global options (method for optim() and method for confint()): I'm not
> at all sure that this is the best way to implement options, this was
> just my first crack at it
> 
> added a warning to show(mle) if optim() did not converge
> 
> Added code that allows (1) default arguments (evaluated
> in the frame of the full coefficient list, with fixed values
> and starting values substituted and (2) arguments specified in the
> start list in arbitrary order (which seems like a reasonable
> expectation since
> it *is* specified as a list).  The fundamental problem is that optim()
> loses names
> of the parameter vector somewhere.
> Example:
> 
> x = runif(200)
> y = 1+x+x^2+rnorm(200,sd=0.05)
> fn <- function(a,b,z=2,c,d) {
>     -sum(dnorm(y,mean=a+c*x+d*x^2,sd=exp(b),log=TRUE))
> }
> 
> m1 = mle(minuslogl=fn,start=list(a=1,b=1,c=1,d=1))
> ## fails with "missing argument" warning, about wrong argument
> m1 = mle(minuslogl=fn,start=list(a=1,b=1,c=1,d=1),fixed=list(z=2))
> ## works
> m2 = mle(minuslogl=fn,start=list(a=1,d=1,c=1,b=1),fixed=list(z=2))
> ## fails -- coeffs returned in wrong order

Hmm.. I see the effect with the current version too. Depending on
temperament, it is the labels rather than the order that is wrong...  

> TO DO:
> 
> torture-test on some real problems!
> 
> better documentation?  e.g. ?profile.mle-class doesn't give details on
> arguments -- have to look at profile.nls
> 
> (allow "which" to be a character vector -- match names)?
> 
> HARDER:
> fancy formula interface [cf. svymle in survey package] e.g.
> mll <-
> mLL(type="independent",distrib="normal",resp=y,mean=~a+b*x,sd=~s,
>        param=~a+b+s)
> 
> allow for fitting of transformed parameters (exp/log, tanh/atanh =
> logistic/logit)

The last one should be trivial, no?

mll2 <- function(a,b,c,d) mll1(log(a),atan(b),c,d)
 
Also: code for combination of likelihoods (i.e. summing likelihoods
for independent subexperiments involving the same parameters;
integrating out nuisance variables.)

MUCH, MUCH HARDER: Figure out what it would take to include higher
order asymptotic inference (as per Brazzale/Bellio's hoa bundle) in a
generic likelihood setting...



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From rpeng at jhsph.edu  Fri Jun 11 16:43:57 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri Jun 11 16:44:02 2004
Subject: [Rd] Change in grep behavior from 1.9.0 to R-patched
Message-ID: <40C9C52D.4020900@jhsph.edu>

I've noticed a change in the way grep() behaves between the 1.9.0 
release and a recent R-patched.  On 1.9.0 I get the following output:

 > x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
 > length(grep("^l\\w+tmean", x, perl = TRUE, value = TRUE))
[1] 84

And on R-patched (2004-06-11) I get

 > x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
 > length(grep("^l\\w+tmean", x, perl = TRUE, value = TRUE))
[1] 13

I can't come up with a simpler example which is why I've posted my 
actual character vector on the web (please let me know if there are 
problems downloading it).

I didn't find anything in the NEWs file that would indicate a change 
and another problem is that I'm not sure which behavior is correct. 
My knowledge of regular expressions is limited.

-roger

From maechler at stat.math.ethz.ch  Fri Jun 11 17:21:43 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Jun 11 17:21:46 2004
Subject: [Rd] Change in grep behavior from 1.9.0 to R-patched
In-Reply-To: <40C9C52D.4020900@jhsph.edu>
References: <40C9C52D.4020900@jhsph.edu>
Message-ID: <16585.52743.784743.730560@gargle.gargle.HOWL>

>>>>> "Roger" == Roger D Peng <rpeng@jhsph.edu>
>>>>>     on Fri, 11 Jun 2004 10:43:57 -0400 writes:

    Roger> I've noticed a change in the way grep() behaves between the 1.9.0 
    Roger> release and a recent R-patched.  On 1.9.0 I get the following output:

    >> x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
    >> length(grep("^l\\w+tmean", x, perl = TRUE, value = TRUE))
    Roger> [1] 84

    Roger> And on R-patched (2004-06-11) I get

    >> x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
    >> length(grep("^l\\w+tmean", x, perl = TRUE, value = TRUE))
    Roger> [1] 13

I can reproduce this exactly.

    <....>

    Roger> I didn't find anything in the NEWs file that would indicate a change 

yes: The src/extras/pcre/ (Perl Compatible Regular Expressions)
     library was upgraded, and since we assumed that wouldn't
     have any effect --- as we now see, a too optimistically ---
     it wasn't documented in NEWS

    Roger> and another problem is that I'm not sure which behavior is correct. 
    Roger> My knowledge of regular expressions is limited.

The first one is correct I think: '\w' means word constituents
(see below) and for 1.9.0, 
you get

 > grep("^l\\w+tmean", x, perl = TRUE, value = TRUE)
  [1] "l1pm10tmean"  "l1pm25tmean"  "l1cotmean"    "l1no2tmean"   "l1so2tmean"  
  [6] "l1o3tmean"    "l2pm10tmean"  "l2pm25tmean"  "l2cotmean"    "l2no2tmean"  
 [11] "l2so2tmean"   "l2o3tmean"    "l3pm10tmean"  "l3pm25tmean"  "l3cotmean"   
 [16] "l3no2tmean"   "l3so2tmean"   "l3o3tmean"    "l4pm10tmean"  "l4pm25tmean" 
 [21] "l4cotmean"    "l4no2tmean"   "l4so2tmean"   "l4o3tmean"    "l5pm10tmean" 
 [26] "l5pm25tmean"  "l5cotmean"    "l5no2tmean"   "l5so2tmean"   "l5o3tmean"   
 [31] "l6pm10tmean"  "l6pm25tmean"  "l6cotmean"    "l6no2tmean"   "l6so2tmean"  
 [36] "l6o3tmean"    "l7pm10tmean"  "l7pm25tmean"  "l7cotmean"    "l7no2tmean"  
 [41] "l7so2tmean"   "l7o3tmean"    "lm1pm10tmean" "lm1pm25tmean" "lm1cotmean"  
 [46] "lm1no2tmean"  "lm1so2tmean"  "lm1o3tmean"   "lm2pm10tmean" "lm2pm25tmean"
 [51] "lm2cotmean"   "lm2no2tmean"  "lm2so2tmean"  "lm2o3tmean"   "lm3pm10tmean"
 [56] "lm3pm25tmean" "lm3cotmean"   "lm3no2tmean"  "lm3so2tmean"  "lm3o3tmean"  
 [61] "lm4pm10tmean" "lm4pm25tmean" "lm4cotmean"   "lm4no2tmean"  "lm4so2tmean" 
 [66] "lm4o3tmean"   "lm5pm10tmean" "lm5pm25tmean" "lm5cotmean"   "lm5no2tmean" 
 [71] "lm5so2tmean"  "lm5o3tmean"   "lm6pm10tmean" "lm6pm25tmean" "lm6cotmean"  
 [76] "lm6no2tmean"  "lm6so2tmean"  "lm6o3tmean"   "lm7pm10tmean" "lm7pm25tmean"
 [81] "lm7cotmean"   "lm7no2tmean"  "lm7so2tmean"  "lm7o3tmean"  
 > 

which is correct AFAICS and shouldn't be shorted to the only 13 elements

> grep("^l\\w+tmean", x, perl = TRUE, value = TRUE)
 [1] "l1pm10tmean" "l1pm25tmean" "l1cotmean"   "l1no2tmean"  "l1so2tmean" 
 [6] "l1o3tmean"   "l2pm10tmean" "l2pm25tmean" "l2cotmean"   "l2no2tmean" 
[11] "l2so2tmean"  "l2o3tmean"   "l3pm10tmean"

in R-patched.

------------

For me,  'man perlre' contains

>>         \w  Match a "word" character (alphanumeric plus "_")

         <......>

>>     A "\w" matches a single alphanumeric character or "_", not a whole
>>     word.  Use "\w+" to match a string of Perl-identifier characters (which
>>     isn't the same as matching an English word).  If "use locale" is in
>>     effect, the list of alphabetic characters generated by "\w" is taken
>>     from the current locale.  See the perllocale manpage. .......

so it may well be connected to locale problems.  But I don't
think any locale should  have   
 "l2pm25tmean" matched by  '^l\w+tmean'   but not match
 "lm5pm25tmean"

[If making a difference between these two, it should rather be
 the other way round].

Martin Maechler

From ripley at stats.ox.ac.uk  Fri Jun 11 17:28:37 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jun 11 17:28:48 2004
Subject: [Rd] Change in grep behavior from 1.9.0 to R-patched
In-Reply-To: <40C9C52D.4020900@jhsph.edu>
Message-ID: <Pine.LNX.4.44.0406111554290.8420-100000@gannet.stats>

This is actually PCRE.  Something is wrong with your build of R-patched
(1.9.1 alpha, I assume): I get 84 everywhere.  You are asking for a first
character l, then one or more characters of `word' then tmean.  In your
example this is the same as (in a suitable locale, including C)

length(grep("^l[A-Za-z0-9]+tmean", x, perl = TRUE, value = TRUE))
length(grep("^l[[:alnum:]_]+tmean", x, perl = TRUE, value = TRUE))

which each give 84.

One issue: PCRE is locale-dependent.  Did you use the same locale for 
each?  What happens if you force LANG=C?

(I've just checked an R-devel Solaris system.  This gave 13 on a build 
from Weds, and 84 when remade today.  The result with 13 seems truncated, 
as they are the first 13.  Might be coincidental, of course.)

On Fri, 11 Jun 2004, Roger D. Peng wrote:

> I've noticed a change in the way grep() behaves between the 1.9.0 
> release and a recent R-patched.  On 1.9.0 I get the following output:
> 
>  > x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
>  > length(grep("^l\\w+tmean", x, perl = TRUE, value = TRUE))
> [1] 84
> 
> And on R-patched (2004-06-11) I get
> 
>  > x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
>  > length(grep("^l\\w+tmean", x, perl = TRUE, value = TRUE))
> [1] 13
> 
> I can't come up with a simpler example which is why I've posted my 
> actual character vector on the web (please let me know if there are 
> problems downloading it).
> 
> I didn't find anything in the NEWs file that would indicate a change 

No change is intended and the underlying C code is unchanged.

> and another problem is that I'm not sure which behavior is correct. 
> My knowledge of regular expressions is limited.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Fri Jun 11 17:28:49 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Jun 11 17:28:52 2004
Subject: [Rd] Change in grep behavior from 1.9.0 to R-patched
In-Reply-To: <16585.52743.784743.730560@gargle.gargle.HOWL>
References: <40C9C52D.4020900@jhsph.edu>
	<16585.52743.784743.730560@gargle.gargle.HOWL>
Message-ID: <16585.53169.516143.5595@gargle.gargle.HOWL>

I forgot to add

  Thank you very much for
  - starting to use R-patched and hence testing it
  - providing a nicely reproducible example

Everyone else: do follow Roger!

Thanks again!
Martin

From ripley at stats.ox.ac.uk  Fri Jun 11 17:33:32 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jun 11 17:33:38 2004
Subject: [Rd] Change in grep behavior from 1.9.0 to R-patched
In-Reply-To: <16585.52743.784743.730560@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.44.0406111630470.8420-100000@gannet.stats>

On Fri, 11 Jun 2004, Martin Maechler wrote:

> >>>>> "Roger" == Roger D Peng <rpeng@jhsph.edu>
> >>>>>     on Fri, 11 Jun 2004 10:43:57 -0400 writes:
> 
>     Roger> I've noticed a change in the way grep() behaves between the 1.9.0 
>     Roger> release and a recent R-patched.  On 1.9.0 I get the following output:
> 
>     >> x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
>     >> length(grep("^l\\w+tmean", x, perl = TRUE, value = TRUE))
>     Roger> [1] 84
> 
>     Roger> And on R-patched (2004-06-11) I get
> 
>     >> x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
>     >> length(grep("^l\\w+tmean", x, perl = TRUE, value = TRUE))
>     Roger> [1] 13
> 
> I can reproduce this exactly.

Are you using a clean build of the current sources?

>     <....>
> 
>     Roger> I didn't find anything in the NEWs file that would indicate a change 
> 
> yes: The src/extras/pcre/ (Perl Compatible Regular Expressions)
>      library was upgraded, and since we assumed that wouldn't
>      have any effect --- as we now see, a too optimistically ---
>      it wasn't documented in NEWS

Eh?  It was upgraded before 1.9.0, and it is documented there as

INSTALLATION CHANGES

    o	The defaults for configure are now --without-zlib
	--without-bzlib --without-pcre.

	The included PCRE sources have been updated to version 4.5 and
	PCRE >= 4.0 is now required if --with-pcre is used.

The files date from 2004 Jan 11.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rpeng at jhsph.edu  Fri Jun 11 17:36:32 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri Jun 11 17:36:37 2004
Subject: [Rd] Change in grep behavior from 1.9.0 to R-patched
In-Reply-To: <16585.52743.784743.730560@gargle.gargle.HOWL>
References: <40C9C52D.4020900@jhsph.edu>
	<16585.52743.784743.730560@gargle.gargle.HOWL>
Message-ID: <40C9D180.1010905@jhsph.edu>

To make matters a little more interesting, I get some weird behavior 
on R 1.9.0 also.  For example, when I run

x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))

and then run

d <- replicate(1000, length(grep("^l\\w+tmean", x, perl = TRUE, value 
= TRUE)))

 > summary(d)
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
   13.00   13.00   13.00   30.47   13.00   84.00

Similar behavior on both R 1.9.0 and today's R-patched (I'm running on 
Linux).  To me this smells like a memory issue in PCRE.

-roger


Martin Maechler wrote:
>>>>>>"Roger" == Roger D Peng <rpeng@jhsph.edu>
>>>>>>    on Fri, 11 Jun 2004 10:43:57 -0400 writes:
> 
> 
>     Roger> I've noticed a change in the way grep() behaves between the 1.9.0 
>     Roger> release and a recent R-patched.  On 1.9.0 I get the following output:
> 
>     >> x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
>     >> length(grep("^l\\w+tmean", x, perl = TRUE, value = TRUE))
>     Roger> [1] 84
> 
>     Roger> And on R-patched (2004-06-11) I get
> 
>     >> x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
>     >> length(grep("^l\\w+tmean", x, perl = TRUE, value = TRUE))
>     Roger> [1] 13
> 
> I can reproduce this exactly.
> 
>     <....>
> 
>     Roger> I didn't find anything in the NEWs file that would indicate a change 
> 
> yes: The src/extras/pcre/ (Perl Compatible Regular Expressions)
>      library was upgraded, and since we assumed that wouldn't
>      have any effect --- as we now see, a too optimistically ---
>      it wasn't documented in NEWS
> 
>     Roger> and another problem is that I'm not sure which behavior is correct. 
>     Roger> My knowledge of regular expressions is limited.
> 
> The first one is correct I think: '\w' means word constituents
> (see below) and for 1.9.0, 
> you get
> 
>  > grep("^l\\w+tmean", x, perl = TRUE, value = TRUE)
>   [1] "l1pm10tmean"  "l1pm25tmean"  "l1cotmean"    "l1no2tmean"   "l1so2tmean"  
>   [6] "l1o3tmean"    "l2pm10tmean"  "l2pm25tmean"  "l2cotmean"    "l2no2tmean"  
>  [11] "l2so2tmean"   "l2o3tmean"    "l3pm10tmean"  "l3pm25tmean"  "l3cotmean"   
>  [16] "l3no2tmean"   "l3so2tmean"   "l3o3tmean"    "l4pm10tmean"  "l4pm25tmean" 
>  [21] "l4cotmean"    "l4no2tmean"   "l4so2tmean"   "l4o3tmean"    "l5pm10tmean" 
>  [26] "l5pm25tmean"  "l5cotmean"    "l5no2tmean"   "l5so2tmean"   "l5o3tmean"   
>  [31] "l6pm10tmean"  "l6pm25tmean"  "l6cotmean"    "l6no2tmean"   "l6so2tmean"  
>  [36] "l6o3tmean"    "l7pm10tmean"  "l7pm25tmean"  "l7cotmean"    "l7no2tmean"  
>  [41] "l7so2tmean"   "l7o3tmean"    "lm1pm10tmean" "lm1pm25tmean" "lm1cotmean"  
>  [46] "lm1no2tmean"  "lm1so2tmean"  "lm1o3tmean"   "lm2pm10tmean" "lm2pm25tmean"
>  [51] "lm2cotmean"   "lm2no2tmean"  "lm2so2tmean"  "lm2o3tmean"   "lm3pm10tmean"
>  [56] "lm3pm25tmean" "lm3cotmean"   "lm3no2tmean"  "lm3so2tmean"  "lm3o3tmean"  
>  [61] "lm4pm10tmean" "lm4pm25tmean" "lm4cotmean"   "lm4no2tmean"  "lm4so2tmean" 
>  [66] "lm4o3tmean"   "lm5pm10tmean" "lm5pm25tmean" "lm5cotmean"   "lm5no2tmean" 
>  [71] "lm5so2tmean"  "lm5o3tmean"   "lm6pm10tmean" "lm6pm25tmean" "lm6cotmean"  
>  [76] "lm6no2tmean"  "lm6so2tmean"  "lm6o3tmean"   "lm7pm10tmean" "lm7pm25tmean"
>  [81] "lm7cotmean"   "lm7no2tmean"  "lm7so2tmean"  "lm7o3tmean"  
>  > 
> 
> which is correct AFAICS and shouldn't be shorted to the only 13 elements
> 
> 
>>grep("^l\\w+tmean", x, perl = TRUE, value = TRUE)
> 
>  [1] "l1pm10tmean" "l1pm25tmean" "l1cotmean"   "l1no2tmean"  "l1so2tmean" 
>  [6] "l1o3tmean"   "l2pm10tmean" "l2pm25tmean" "l2cotmean"   "l2no2tmean" 
> [11] "l2so2tmean"  "l2o3tmean"   "l3pm10tmean"
> 
> in R-patched.
> 
> ------------
> 
> For me,  'man perlre' contains
> 
> 
>>>        \w  Match a "word" character (alphanumeric plus "_")
> 
> 
>          <......>
> 
>>>    A "\w" matches a single alphanumeric character or "_", not a whole
>>>    word.  Use "\w+" to match a string of Perl-identifier characters (which
>>>    isn't the same as matching an English word).  If "use locale" is in
>>>    effect, the list of alphabetic characters generated by "\w" is taken
>>>    from the current locale.  See the perllocale manpage. .......
> 
> 
> so it may well be connected to locale problems.  But I don't
> think any locale should  have   
>  "l2pm25tmean" matched by  '^l\w+tmean'   but not match
>  "lm5pm25tmean"
> 
> [If making a difference between these two, it should rather be
>  the other way round].
> 
> Martin Maechler
> 
> 
>

From maechler at stat.math.ethz.ch  Fri Jun 11 17:40:34 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Jun 11 17:40:35 2004
Subject: [Rd] Change in grep behavior from 1.9.0 to R-patched
In-Reply-To: <Pine.LNX.4.44.0406111554290.8420-100000@gannet.stats>
References: <40C9C52D.4020900@jhsph.edu>
	<Pine.LNX.4.44.0406111554290.8420-100000@gannet.stats>
Message-ID: <16585.53874.189070.102053@gargle.gargle.HOWL>

>>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
>>>>>     on Fri, 11 Jun 2004 16:28:37 +0100 (BST) writes:

    BDR> This is actually PCRE.  Something is wrong with your build of R-patched
    BDR> (1.9.1 alpha, I assume): I get 84 everywhere.  You are asking for a first
    BDR> character l, then one or more characters of `word' then tmean.  In your
    BDR> example this is the same as (in a suitable locale, including C)

    BDR> length(grep("^l[A-Za-z0-9]+tmean", x, perl = TRUE, value = TRUE))
    BDR> length(grep("^l[[:alnum:]_]+tmean", x, perl = TRUE, value = TRUE))

    BDR> which each give 84.

    BDR> One issue: PCRE is locale-dependent.  Did you use the same locale for 
    BDR> each?  What happens if you force LANG=C?

For me:

- I did use the same locale for both R versions
   (LC_CTYPE=de_CH; no explicit LANG which -- as I just realize
   nowadays (for Redhat Enterprise) means "en_US.UTF-8" -- aaaargh)
- Forcing LANG=C  helps (giving 84).

and I was wrong in saying that we've upgraded PCRE between 1.9.0
and R-patched.

Still quite peculiar (same locale settings leading to different
 PCRE behavior)..
Could it be that the locale at  *BUILD* time plays a role as well?
That might explain it for me.

Martin

From MSchwartz at MedAnalytics.com  Fri Jun 11 17:46:37 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri Jun 11 17:46:43 2004
Subject: [Rd] Change in grep behavior from 1.9.0 to R-patched
In-Reply-To: <Pine.LNX.4.44.0406111554290.8420-100000@gannet.stats>
References: <Pine.LNX.4.44.0406111554290.8420-100000@gannet.stats>
Message-ID: <1086968797.29898.409.camel@localhost.localdomain>

On Fri, 2004-06-11 at 10:28, Prof Brian Ripley wrote:
> This is actually PCRE.  Something is wrong with your build of R-patched
> (1.9.1 alpha, I assume): I get 84 everywhere.  You are asking for a first
> character l, then one or more characters of `word' then tmean.  In your
> example this is the same as (in a suitable locale, including C)
> 
> length(grep("^l[A-Za-z0-9]+tmean", x, perl = TRUE, value = TRUE))
> length(grep("^l[[:alnum:]_]+tmean", x, perl = TRUE, value = TRUE))
> 
> which each give 84.
> 
> One issue: PCRE is locale-dependent.  Did you use the same locale for 
> each?  What happens if you force LANG=C?
> 
> (I've just checked an R-devel Solaris system.  This gave 13 on a build 
> from Weds, and 84 when remade today.  The result with 13 seems truncated, 
> as they are the first 13.  Might be coincidental, of course.)


The above is confirmed using Version 1.9.1 alpha (2004-06-10) on FC2:

> x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
> length(grep("^l[A-Za-z0-9]+tmean", x, perl = TRUE, value = TRUE))
[1] 84
> length(grep("^l[[:alnum:]_]+tmean", x, perl = TRUE, value = TRUE))
[1] 84


Also, to demonstrate Roger's follow up example:

> d <- replicate(1000, length(grep("^l\\w+tmean", x, perl = TRUE, value
= TRUE)))
> summary(d)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  13.00   13.00   13.00   14.14   13.00   84.00 


BTW: pcre-4.5-2

HTH,

Marc Schwartz

From rpeng at jhsph.edu  Fri Jun 11 17:54:21 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri Jun 11 17:54:25 2004
Subject: [Rd] Change in grep behavior from 1.9.0 to R-patched
In-Reply-To: <Pine.LNX.4.44.0406111554290.8420-100000@gannet.stats>
References: <Pine.LNX.4.44.0406111554290.8420-100000@gannet.stats>
Message-ID: <40C9D5AD.30101@jhsph.edu>

I have the following to environmental variables set:

LANGVAR=en_US.UTF-8
LANG=C

I don't know exactly what both of these mean, but I always 
deliberately set LANG=C in my .tcshrc files since that is necessary to 
get Acrobat Reader working on my Red Hat system.  My guess is they 
were both set this way at build time.

When I run Brian's two alternatives, I *always* get 84, no matter how 
many times I repeat it.  However, when I use \w+, I sometimes get 13 
and sometimes get 84 (say, when repeated 1000 times).

-roger

Prof Brian Ripley wrote:
> This is actually PCRE.  Something is wrong with your build of R-patched
> (1.9.1 alpha, I assume): I get 84 everywhere.  You are asking for a first
> character l, then one or more characters of `word' then tmean.  In your
> example this is the same as (in a suitable locale, including C)
> 
> length(grep("^l[A-Za-z0-9]+tmean", x, perl = TRUE, value = TRUE))
> length(grep("^l[[:alnum:]_]+tmean", x, perl = TRUE, value = TRUE))
> 
> which each give 84.
> 
> One issue: PCRE is locale-dependent.  Did you use the same locale for 
> each?  What happens if you force LANG=C?
> 
> (I've just checked an R-devel Solaris system.  This gave 13 on a build 
> from Weds, and 84 when remade today.  The result with 13 seems truncated, 
> as they are the first 13.  Might be coincidental, of course.)
> 
> On Fri, 11 Jun 2004, Roger D. Peng wrote:
> 
> 
>>I've noticed a change in the way grep() behaves between the 1.9.0 
>>release and a recent R-patched.  On 1.9.0 I get the following output:
>>
>> > x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
>> > length(grep("^l\\w+tmean", x, perl = TRUE, value = TRUE))
>>[1] 84
>>
>>And on R-patched (2004-06-11) I get
>>
>> > x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
>> > length(grep("^l\\w+tmean", x, perl = TRUE, value = TRUE))
>>[1] 13
>>
>>I can't come up with a simpler example which is why I've posted my 
>>actual character vector on the web (please let me know if there are 
>>problems downloading it).
>>
>>I didn't find anything in the NEWs file that would indicate a change 
> 
> 
> No change is intended and the underlying C code is unchanged.
> 
> 
>>and another problem is that I'm not sure which behavior is correct. 
>>My knowledge of regular expressions is limited.
> 
>

From ripley at stats.ox.ac.uk  Fri Jun 11 17:55:59 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jun 11 17:56:07 2004
Subject: [Rd] Change in grep behavior from 1.9.0 to R-patched
In-Reply-To: <1086968797.29898.409.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.44.0406111653230.26123-100000@gannet.stats>

So the consensus is

- it happens equally in 1.9.0 and 1.9.1 alpha current
- it happens in the C locale
- it is random and bursty, as in

> d
   [1] 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 
84 84
  [25] 84 84 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 
13 13
  [49] 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 
13 13
  [73] 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 
13 13
  [97] 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 
13 13
 [121] 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 
13 13
 [145] 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 84 84 84 84 
84 84
 [169] 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 
84 84
 [193] 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 13 13 84 84 84 13 
13 13
 [217] 84 84 84 13 13 13 84 84 84 13 13 13 84 84 84 13 13 13 13 13 13 13 
13 13
...

So looks like a problem in the PCRE compiled code.

On Fri, 11 Jun 2004, Marc Schwartz wrote:

> On Fri, 2004-06-11 at 10:28, Prof Brian Ripley wrote:
> > This is actually PCRE.  Something is wrong with your build of R-patched
> > (1.9.1 alpha, I assume): I get 84 everywhere.  You are asking for a first
> > character l, then one or more characters of `word' then tmean.  In your
> > example this is the same as (in a suitable locale, including C)
> > 
> > length(grep("^l[A-Za-z0-9]+tmean", x, perl = TRUE, value = TRUE))

I omitted _ there, not that it mattered.

> > length(grep("^l[[:alnum:]_]+tmean", x, perl = TRUE, value = TRUE))
> > 
> > which each give 84.
> > 
> > One issue: PCRE is locale-dependent.  Did you use the same locale for 
> > each?  What happens if you force LANG=C?
> > 
> > (I've just checked an R-devel Solaris system.  This gave 13 on a build 
> > from Weds, and 84 when remade today.  The result with 13 seems truncated, 
> > as they are the first 13.  Might be coincidental, of course.)
> 
> 
> The above is confirmed using Version 1.9.1 alpha (2004-06-10) on FC2:
> 
> > x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
> > length(grep("^l[A-Za-z0-9]+tmean", x, perl = TRUE, value = TRUE))
> [1] 84
> > length(grep("^l[[:alnum:]_]+tmean", x, perl = TRUE, value = TRUE))
> [1] 84
> 
> 
> Also, to demonstrate Roger's follow up example:
> 
> > d <- replicate(1000, length(grep("^l\\w+tmean", x, perl = TRUE, value
> = TRUE)))
> > summary(d)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
>   13.00   13.00   13.00   14.14   13.00   84.00 

table(d) is more informative.

> BTW: pcre-4.5-2

Did you use --with-pcre, though?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Fri Jun 11 18:21:06 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jun 11 18:21:15 2004
Subject: [Rd] Change in grep behavior from 1.9.0 to R-patched
In-Reply-To: <Pine.LNX.4.44.0406111653230.26123-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0406111716440.29865-100000@gannet.stats>

I think I have a solution I am just about to commit.  It looks as if the 
PCRE documentation I read is wrong as to when it is safe to free the 
locale-specific tables, and I've deferred doing so until much later.

Incidentally, I cannot make this misbehave on Windows.


On Fri, 11 Jun 2004, Prof Brian Ripley wrote:

> So the consensus is
> 
> - it happens equally in 1.9.0 and 1.9.1 alpha current
> - it happens in the C locale
> - it is random and bursty, as in
> 
> > d
>    [1] 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 
> 84 84
>   [25] 84 84 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 
> 13 13
>   [49] 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 
> 13 13
>   [73] 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 
> 13 13
>   [97] 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 
> 13 13
>  [121] 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 
> 13 13
>  [145] 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 84 84 84 84 
> 84 84
>  [169] 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 
> 84 84
>  [193] 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 13 13 84 84 84 13 
> 13 13
>  [217] 84 84 84 13 13 13 84 84 84 13 13 13 84 84 84 13 13 13 13 13 13 13 
> 13 13
> ...
> 
> So looks like a problem in the PCRE compiled code.
> 
> On Fri, 11 Jun 2004, Marc Schwartz wrote:
> 
> > On Fri, 2004-06-11 at 10:28, Prof Brian Ripley wrote:
> > > This is actually PCRE.  Something is wrong with your build of R-patched
> > > (1.9.1 alpha, I assume): I get 84 everywhere.  You are asking for a first
> > > character l, then one or more characters of `word' then tmean.  In your
> > > example this is the same as (in a suitable locale, including C)
> > > 
> > > length(grep("^l[A-Za-z0-9]+tmean", x, perl = TRUE, value = TRUE))
> 
> I omitted _ there, not that it mattered.
> 
> > > length(grep("^l[[:alnum:]_]+tmean", x, perl = TRUE, value = TRUE))
> > > 
> > > which each give 84.
> > > 
> > > One issue: PCRE is locale-dependent.  Did you use the same locale for 
> > > each?  What happens if you force LANG=C?
> > > 
> > > (I've just checked an R-devel Solaris system.  This gave 13 on a build 
> > > from Weds, and 84 when remade today.  The result with 13 seems truncated, 
> > > as they are the first 13.  Might be coincidental, of course.)
> > 
> > 
> > The above is confirmed using Version 1.9.1 alpha (2004-06-10) on FC2:
> > 
> > > x <- dget(file = url("http://www.biostat.jhsph.edu/~rpeng/names.R"))
> > > length(grep("^l[A-Za-z0-9]+tmean", x, perl = TRUE, value = TRUE))
> > [1] 84
> > > length(grep("^l[[:alnum:]_]+tmean", x, perl = TRUE, value = TRUE))
> > [1] 84
> > 
> > 
> > Also, to demonstrate Roger's follow up example:
> > 
> > > d <- replicate(1000, length(grep("^l\\w+tmean", x, perl = TRUE, value
> > = TRUE)))
> > > summary(d)
> >    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
> >   13.00   13.00   13.00   14.14   13.00   84.00 
> 
> table(d) is more informative.
> 
> > BTW: pcre-4.5-2
> 
> Did you use --with-pcre, though?
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From notulei at yahoo.com  Fri Jun 11 19:51:29 2004
From: notulei at yahoo.com (Alex Nu)
Date: Fri Jun 11 19:51:34 2004
Subject: [Rd] bug or correct behaviour ?
In-Reply-To: <Pine.LNX.4.44.0406110742540.16535-100000@gannet.stats>
Message-ID: <20040611175129.68296.qmail@web60108.mail.yahoo.com>


 Dr. Ripley,

 Thanks for your answer, I guest the key is that
 in my code R can't know tmp is being modified.
 
 I couldn't find a duplicate function for the
 R environment. Is there any ?
 So I could avoid doing tmp.last <-tmp*1.0
  
 Thanks

 Alex
 


--- Prof Brian Ripley <ripley@stats.ox.ac.uk> wrote:
> Without seeing your code for the .Call parts it is
> impossible for us to
> know, but as .Call does not duplicate its arguments
> (unlike .C), it is
> possible for it to change both tmp and a copy of
> tmp, tmp.last.
> 
> So it seems likely there is a bug in your C code if
> that is not your 
> intention.  The normal way to use .Call is to return
> something, and to 
> duplicate any arguments which will be changed
> (possibly only provided 
> NAMED(tmp) is true as otherwise there are no named
> copies around).
> 
> In other words, it would be normal to have
> 
> tmp <- .Call("Replace", tmp, ...)
> 
> and call duplicate() inside the C code for Replace.
> 
> On Thu, 10 Jun 2004, Alex Nu wrote:
> 
> > 
> >  This is the general outline of my code::
> >  
> > main(argc,argv){
> >    ...
> >    Rf_initEmbeddedR(argc,argv);
> >    ...
> >    Test_tryEval("source(test.r)");
> >    ...
> > }
> 
> Not sure of the relevance of this.
> 
> > ############# 
> > # test.r
> > #############
> > ...
> > dyn.load("toload.so")
> > 
> > tmp <-matrix(data=1,nrow=narray*2,ncol=nclust)
> > 
> > .Call("Init",tmp,...)
> > while(...) {
> >    criteria <-feval(tmp)
> >    if (criteria < criteria.min) 
> >         tmp.last <- tmp
> 
> That makes a potential copy. The actual copying
> occurs if tmp is changed
> and R is aware of it.  This is the purpose of the
> 'named' element of a
> SEXP, but I don't think that is documented anywhere.
> 
> >    else  
> >        tmp <- tmp.last
> >    ...
> >    .Call("replace",tmp,...)
> > }
> > ####################################
> > 
> > 
> >  When I try to recover tmp 
> > 
> >       tmp <- tmp.last
> >  
> >  I got the modified value of tmp.
> >  It means that tmp.last is modified
> >  when I modified tmp in the C funciont replace.
> >  
> >  The program seems to work fine if I change 
> >  to this::
> >             
> >   tmp.last <- tmp*1.0
> >   
> >   tmp <- tmp.last*1.0
> 
> Those do definitely make new objects.
> 
> -- 
> Brian D. Ripley,                 
> ripley@stats.ox.ac.uk
> Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865
> 272861 (self)
> 1 South Parks Road,                     +44 1865
> 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865
> 272595
>

From ripley at stats.ox.ac.uk  Fri Jun 11 20:01:26 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jun 11 20:01:28 2004
Subject: [Rd] bug or correct behaviour ?
In-Reply-To: <20040611175129.68296.qmail@web60108.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0406111901010.30189-100000@gannet.stats>

On Fri, 11 Jun 2004, Alex Nu wrote:

> 
>  Dr. Ripley,
> 
>  Thanks for your answer, I guest the key is that
>  in my code R can't know tmp is being modified.
>  
>  I couldn't find a duplicate function for the
>  R environment. Is there any ?

No.  You should be doing this in your C/C++ code.

>  So I could avoid doing tmp.last <-tmp*1.0
>   
>  Thanks
> 
>  Alex
>  
> 
> 
> --- Prof Brian Ripley <ripley@stats.ox.ac.uk> wrote:
> > Without seeing your code for the .Call parts it is
> > impossible for us to
> > know, but as .Call does not duplicate its arguments
> > (unlike .C), it is
> > possible for it to change both tmp and a copy of
> > tmp, tmp.last.
> > 
> > So it seems likely there is a bug in your C code if
> > that is not your 
> > intention.  The normal way to use .Call is to return
> > something, and to 
> > duplicate any arguments which will be changed
> > (possibly only provided 
> > NAMED(tmp) is true as otherwise there are no named
> > copies around).
> > 
> > In other words, it would be normal to have
> > 
> > tmp <- .Call("Replace", tmp, ...)
> > 
> > and call duplicate() inside the C code for Replace.
> > 
> > On Thu, 10 Jun 2004, Alex Nu wrote:
> > 
> > > 
> > >  This is the general outline of my code::
> > >  
> > > main(argc,argv){
> > >    ...
> > >    Rf_initEmbeddedR(argc,argv);
> > >    ...
> > >    Test_tryEval("source(test.r)");
> > >    ...
> > > }
> > 
> > Not sure of the relevance of this.
> > 
> > > ############# 
> > > # test.r
> > > #############
> > > ...
> > > dyn.load("toload.so")
> > > 
> > > tmp <-matrix(data=1,nrow=narray*2,ncol=nclust)
> > > 
> > > .Call("Init",tmp,...)
> > > while(...) {
> > >    criteria <-feval(tmp)
> > >    if (criteria < criteria.min) 
> > >         tmp.last <- tmp
> > 
> > That makes a potential copy. The actual copying
> > occurs if tmp is changed
> > and R is aware of it.  This is the purpose of the
> > 'named' element of a
> > SEXP, but I don't think that is documented anywhere.
> > 
> > >    else  
> > >        tmp <- tmp.last
> > >    ...
> > >    .Call("replace",tmp,...)
> > > }
> > > ####################################
> > > 
> > > 
> > >  When I try to recover tmp 
> > > 
> > >       tmp <- tmp.last
> > >  
> > >  I got the modified value of tmp.
> > >  It means that tmp.last is modified
> > >  when I modified tmp in the C funciont replace.
> > >  
> > >  The program seems to work fine if I change 
> > >  to this::
> > >             
> > >   tmp.last <- tmp*1.0
> > >   
> > >   tmp <- tmp.last*1.0
> > 
> > Those do definitely make new objects.
> > 
> > -- 
> > Brian D. Ripley,                 
> > ripley@stats.ox.ac.uk
> > Professor of Applied Statistics, 
> > http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865
> > 272861 (self)
> > 1 South Parks Road,                     +44 1865
> > 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865
> > 272595
> >
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From bolker at zoo.ufl.edu  Fri Jun 11 22:35:55 2004
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Fri Jun 11 21:38:52 2004
Subject: [Rd] overhaul of mle
In-Reply-To: <x2n03ab571.fsf@biostat.ku.dk>
References: <40C8A3FE.6030102@zoo.ufl.edu> <x2n03ab571.fsf@biostat.ku.dk>
Message-ID: <40CA17AB.4090805@zoo.ufl.edu>



Peter Dalgaard wrote:
> Ben Bolker <bolker@zoo.ufl.edu> writes:
> 
> 
>>*** Changed type of fullcoef from "numeric" to "list", and return
>>fullcoef rather than unlist(fullcoef) from mle [couldn't see a
>>rationale for this -- it destroys a lot of the information in fullcoef
>>*and* is a
>>pain, say, when the fixed arguments include a data frame with lots of
>>information in it]
> 
> 
> Wait a minute. How can a likelihood function have an argument that is
> a data frame? I think you're abusing the fixed arguments if you use it
> to pass in data. The natural paradigm for that would be to pass data
> via a closure, i.e. 
> 
> mll <- with(data,
>     function(lambda=1,theta=0)sum(dpois(y, lambda+theta*x, log=TRUE))
> )

>>*** Changed "coef" method to return object@coef, not object@fullcoef
>>[this really seems to be the better choice to me -- I normally want to
>>see the *fitted values* of the MLE, not all the other auxiliary
>>stuff.  Besides, object@fullcoef can be very long, and therefore a
>>nuisance to see in the default show(object) method]
> 
> 
> See above. This was never intended to contain auxiliary stuff (and
> AFAIR has already been changed once in the opposite direction, by Brian)

    OK, I want to hear about this.  My normal approach to writing 
likelihood functions that can be evaluated with more than one data
set is essentially

mll <- function(par1,par2,par3,X=Xdefault,Y=Ydefault,Z=Zdefault) { ... }

where X, Y, Z are the data values that may change from one fitting 
exercise to the next.  This seems straightforward to me, and I always 
thought it was the reason why optim() had a ... in its argument list,
so that one could easily pass these arguments down.  I have to confess 
that I don't quite understand how your paradigm with with() works: if
mll() is defined as you have it above, "data" is a data frame containing
$x and $y, right?  How do I run mle(minuslogl=mll,start=...) for 
different values of "data" (data1, data2, data3) in this case?  Does
it go in the call as mle(minuslogl=mll,start=...,data=...)?  Once I've
found my mle, how do I view/access these values when I want to see
what data I used to fit mle1, mle2, etc.?

   I'm willing to change the way I do things (and teach my students
differently), but I need to see how ... I don't see how what I've
written is an "abuse" of the fixed arguments [I'm willing to believe
that it is, but just don't know why]

>>added a cor method for mle objects -- which just normalizes the
>>variance-covariance matrix to a correlation matrix.  Is this a bad
>>idea/perversion of the cor method?
> 
> 
> Yes, I think so. cov2cor(vcov(ml.obj)) is easy enough.

   OK.  I wasn't aware of cov2cor().

> 
>>changed
>>call$fixed <- fix
>>to
>>call$fixed <- c(fix,eval(call$fixed))
>>for cases where there are non-trivial fixed arguments
> 
> 
> Which there shouldn't be...
>  
> 
>>added "follow" argument to profile: this makes profiling use a
>>continuation method where the starting point for each profile
>>optimization is the previous best-fit solution, rather than the
>>overall MLEs of the parameters.  Actually fairly easy to implement (I
>>think: I haven't really tested that it works on anything hard, just
>>that it doesn't seem to break profiling) -- requires pfit to be
>>assigned globally within onestep() and a few lines of code further
>>down.
> 
> 
> Sounds nice, but surely you don't need a global assignment there? A
> superassign ("<<-") perhaps, but that doesn't need to go to
> .GlobalEnv. 

   OK -- I think that's just my ignorance showing.

>>
>>Added code that allows (1) default arguments (evaluated
>>in the frame of the full coefficient list, with fixed values
>>and starting values substituted and (2) arguments specified in the
>>start list in arbitrary order (which seems like a reasonable
>>expectation since
>>it *is* specified as a list).  The fundamental problem is that optim()
>>loses names
>>of the parameter vector somewhere.
>>Example:
>>
>>x = runif(200)
>>y = 1+x+x^2+rnorm(200,sd=0.05)
>>fn <- function(a,b,z=2,c,d) {
>>    -sum(dnorm(y,mean=a+c*x+d*x^2,sd=exp(b),log=TRUE))
>>}
>>
>>m1 = mle(minuslogl=fn,start=list(a=1,b=1,c=1,d=1))
>>## fails with "missing argument" warning, about wrong argument
>>m1 = mle(minuslogl=fn,start=list(a=1,b=1,c=1,d=1),fixed=list(z=2))
>>## works
>>m2 = mle(minuslogl=fn,start=list(a=1,d=1,c=1,b=1),fixed=list(z=2))
>>## fails -- coeffs returned in wrong order
> 
> 
> Hmm.. I see the effect with the current version too. Depending on
> temperament, it is the labels rather than the order that is wrong...  

   Hmmm.  By "current version" do you mean you can still
find ways to get wrong answers with my modified version?
Can you send me an example?  Can you think of a better way to fix this?

>>
>>allow for fitting of transformed parameters (exp/log, tanh/atanh =
>>logistic/logit)
> 
> 
> The last one should be trivial, no?
> 
> mll2 <- function(a,b,c,d) mll1(log(a),atan(b),c,d)

   Yes, but I was thinking of something convenient for my students --
syntactic sugar, if you like -- so that fitted values, confidence
intervals, etc., would automatically be displayed on the
original (non-transformed) scale


   cheers,
     Ben Bolker

From jon at mcauliffe.com  Fri Jun 11 22:49:18 2004
From: jon at mcauliffe.com (jon@mcauliffe.com)
Date: Fri Jun 11 22:49:34 2004
Subject: [Rd] qbinom(p, size, prob = 0, lower.tail = FALSE) hangs (PR#6972)
Message-ID: <20040611204918.68D00108E0@slim.kubism.ku.dk>

Full_Name: Jon McAuliffe
Version: 1.9.0
OS: Mac OS X 10.3.4
Submission from: (NULL) (64.166.16.252)



a call like qbinom(0.3, 10, prob = 0, lower.tail = FALSE) hangs R. prob = 0 does
not
look interesting, but it can be useful for completeness when qbinom is part of
other general routines.

please see PR#5900 (Accuracy-fixed).

jon.


--please do not edit the information below--

Version:
 platform = powerpc-apple-darwin6.8
 arch = powerpc
 os = darwin6.8
 system = powerpc, darwin6.8
 status = 
 major = 1
 minor = 9.0
 year = 2004
 month = 04
 day = 12
 language = R

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:utils,
Autoloads, package:base

From p.dalgaard at biostat.ku.dk  Sat Jun 12 02:20:22 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat Jun 12 02:27:32 2004
Subject: [Rd] overhaul of mle
In-Reply-To: <40CA17AB.4090805@zoo.ufl.edu>
References: <40C8A3FE.6030102@zoo.ufl.edu> <x2n03ab571.fsf@biostat.ku.dk>
	<40CA17AB.4090805@zoo.ufl.edu>
Message-ID: <x2acz9bpa1.fsf@biostat.ku.dk>

Ben Bolker <bolker@zoo.ufl.edu> writes:

 
>     OK, I want to hear about this.  My normal approach to writing
> likelihood functions that can be evaluated with more than one data
> set is essentially
> 
> mll <- function(par1,par2,par3,X=Xdefault,Y=Ydefault,Z=Zdefault) { ... }
> 
> where X, Y, Z are the data values that may change from one fitting
> exercise to the next.  This seems straightforward to me, and I always
> thought it was the reason why optim() had a ... in its argument list,
> so that one could easily pass these arguments down.  I have to confess
> that I don't quite understand how your paradigm with with() works: if
> mll() is defined as you have it above, "data" is a data frame containing
> $x and $y, right?  How do I run mle(minuslogl=mll,start=...) for
> different values of "data" (data1, data2, data3) in this case?  Does
> it go in the call as mle(minuslogl=mll,start=...,data=...)?  Once I've
> found my mle, how do I view/access these values when I want to see
> what data I used to fit mle1, mle2, etc.?

You generate different likelihood functions. If you do it using
lexical scoping, the data is available in the environment(mll). If you
insist on having one function that can be modified by changing data, you
can simply assign into that environment.
 
>    I'm willing to change the way I do things (and teach my students
> differently), but I need to see how ... I don't see how what I've
> written is an "abuse" of the fixed arguments [I'm willing to believe
> that it is, but just don't know why]

"Abuse" is of course a strong word, but...

The point is that likelihood inference views the likelihood as a
function of the model parameters *only* and it is useful to stick to
that concept in the implementation. The fixed arguments were only ever
introduced to allow profiling by keeping some parameters fixed during
optimization. 

Another aspect is that one of my ultimate goals with this stuff was to
allow generic operations to be defined on likelihoods (combining,
integrating, mixing, conditioning...) and that becomes even more
elusive if you have to deal with data arguments for the component
likelihoods. Not that I've got very far thinking about the design, but
I'm rather sure that the "likelihood object" needs to be well-defined
if it is to have a chance at all.

> > Hmm.. I see the effect with the current version too. Depending on
> > temperament, it is the labels rather than the order that is wrong...
> 
>    Hmmm.  By "current version" do you mean you can still
> find ways to get wrong answers with my modified version?
> Can you send me an example?  Can you think of a better way to fix this?

Strike "too", haven't gotten around to checking your code yet.
Possibly, this requires a bug fix for 1.9.1.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From rpeng at jhsph.edu  Sat Jun 12 03:40:24 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sat Jun 12 03:42:31 2004
Subject: [Rd] overhaul of mle
In-Reply-To: <x2acz9bpa1.fsf@biostat.ku.dk>
References: <40C8A3FE.6030102@zoo.ufl.edu>
	<x2n03ab571.fsf@biostat.ku.dk>	<40CA17AB.4090805@zoo.ufl.edu>
	<x2acz9bpa1.fsf@biostat.ku.dk>
Message-ID: <40CA5F08.5010604@jhsph.edu>

Taking advantage of lexical scoping is definitely the way to go 
here.  I usually write a function called `makeLogLik' or 
something like that which basically returns a function that can 
be passed into an optimizer.  Something like:

makeLogLik <- function(X=Xdefault, Y=Ydefault, Z=Zdefault) {
	function(par1, par2, par3) {
		...
	}
}

-roger

Peter Dalgaard wrote:

> Ben Bolker <bolker@zoo.ufl.edu> writes:
> 
>  
> 
>>    OK, I want to hear about this.  My normal approach to writing
>>likelihood functions that can be evaluated with more than one data
>>set is essentially
>>
>>mll <- function(par1,par2,par3,X=Xdefault,Y=Ydefault,Z=Zdefault) { ... }
>>
>>where X, Y, Z are the data values that may change from one fitting
>>exercise to the next.  This seems straightforward to me, and I always
>>thought it was the reason why optim() had a ... in its argument list,
>>so that one could easily pass these arguments down.  I have to confess
>>that I don't quite understand how your paradigm with with() works: if
>>mll() is defined as you have it above, "data" is a data frame containing
>>$x and $y, right?  How do I run mle(minuslogl=mll,start=...) for
>>different values of "data" (data1, data2, data3) in this case?  Does
>>it go in the call as mle(minuslogl=mll,start=...,data=...)?  Once I've
>>found my mle, how do I view/access these values when I want to see
>>what data I used to fit mle1, mle2, etc.?
> 
> 
> You generate different likelihood functions. If you do it using
> lexical scoping, the data is available in the environment(mll). If you
> insist on having one function that can be modified by changing data, you
> can simply assign into that environment.
>  
> 
>>   I'm willing to change the way I do things (and teach my students
>>differently), but I need to see how ... I don't see how what I've
>>written is an "abuse" of the fixed arguments [I'm willing to believe
>>that it is, but just don't know why]
> 
> 
> "Abuse" is of course a strong word, but...
> 
> The point is that likelihood inference views the likelihood as a
> function of the model parameters *only* and it is useful to stick to
> that concept in the implementation. The fixed arguments were only ever
> introduced to allow profiling by keeping some parameters fixed during
> optimization. 
> 
> Another aspect is that one of my ultimate goals with this stuff was to
> allow generic operations to be defined on likelihoods (combining,
> integrating, mixing, conditioning...) and that becomes even more
> elusive if you have to deal with data arguments for the component
> likelihoods. Not that I've got very far thinking about the design, but
> I'm rather sure that the "likelihood object" needs to be well-defined
> if it is to have a chance at all.
> 
> 
>>>Hmm.. I see the effect with the current version too. Depending on
>>>temperament, it is the labels rather than the order that is wrong...
>>
>>   Hmmm.  By "current version" do you mean you can still
>>find ways to get wrong answers with my modified version?
>>Can you send me an example?  Can you think of a better way to fix this?
> 
> 
> Strike "too", haven't gotten around to checking your code yet.
> Possibly, this requires a bug fix for 1.9.1.
>

From maechler at stat.math.ethz.ch  Sat Jun 12 20:29:08 2004
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Sat Jun 12 20:29:14 2004
Subject: [Rd] qbinom(p, size, prob = 0, lower.tail = FALSE) hangs (PR#6972)
Message-ID: <20040612182908.62E861058E@slim.kubism.ku.dk>

>>>>> "Jon" == Jon McAuliffe <jon@mcauliffe.com>
>>>>>     on Fri, 11 Jun 2004 22:49:18 +0200 (CEST) writes:


    Jon> a call like qbinom(0.3, 10, prob = 0, lower.tail =  FALSE)
    Jon> hangs R. prob = 0 does not look interesting, but
    Jon> it can be useful for completeness when qbinom is part
    Jon> of other general routines.

yes.  I've already fixed this bug.

    Jon> please see PR#5900 (Accuracy-fixed).

which looks very similar but was different.

Thank you for the report.
Martin Maechler

From phil at google.com  Sun Jun 13 06:54:09 2004
From: phil at google.com (phil@google.com)
Date: Sun Jun 13 06:54:11 2004
Subject: [Rd] can't create a POSIXct from an actual Unix timestamp (PR#6975)
Message-ID: <20040613045409.738A01058D@slim.kubism.ku.dk>

Full_Name: Philip Gross
Version: 1.9.0
OS: Linux Redhat 9.0
Submission from: (NULL) (65.57.245.11)


Among the many conversions for POSIXct values, there does not seem to be one
which will accept an actual POSIX timestamp, e.g. as produced by MySQL's
UNIX_TIMESTAMP() function.  I have fixed this by adding the following lines to
R-1.9.0/src/library/base/R/datetime.R , at line 89:

    if(is.numeric(x))
        return(structure(x, class = c("POSIXt", "POSIXct")))

I am far from an R guru, and this was done based on pattern matching the code. 
It seems to work, though.

From ripley at stats.ox.ac.uk  Sun Jun 13 08:45:33 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Jun 13 08:45:39 2004
Subject: (PR#6975) [Rd] can't create a POSIXct from an actual Unix
	timestamp
In-Reply-To: <20040613045409.738A01058D@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406130736290.13293-100000@gannet.stats>

On Sun, 13 Jun 2004 phil@google.com wrote:

> Full_Name: Philip Gross
> Version: 1.9.0
> OS: Linux Redhat 9.0
> Submission from: (NULL) (65.57.245.11)
> 
> 
> Among the many conversions for POSIXct values, there does not seem to be one
> which will accept an actual POSIX timestamp, e.g. as produced by MySQL's
> UNIX_TIMESTAMP() function.  I have fixed this by adding the following lines to
> R-1.9.0/src/library/base/R/datetime.R , at line 89:
> 
>     if(is.numeric(x))
>         return(structure(x, class = c("POSIXt", "POSIXct")))
> 
> I am far from an R guru, and this was done based on pattern matching the code. 
> It seems to work, though.

This cannot be correct, as the numeric value could be the integer number
of days after 1980-01-01, for example.  This is a deliberate omission, but
you will note (I hope) that R does handle actual Unix timestamps in e.g.  
Sys.time() and file.info().  (They use code equivalent to yours, *when*
the interpretation of the number is known, *and* x is known to be double 
and not integer.)

Note this is not a bug, and would not have been even if your suggestion 
had been correct.  Please read the section on BUGS in the FAQ.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.murrell at auckland.ac.nz  Mon Jun 14 00:43:02 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon Jun 14 00:43:43 2004
Subject: [Rd] trellis.device in .First (PR#6812)
References: <Pine.LNX.4.44.0404260712280.22842-100000@gannet.stats>
	<408DA442.5070408@stat.auckland.ac.nz>
Message-ID: <40CCD876.6040002@stat.auckland.ac.nz>

Hi


Paul Murrell wrote:
> Prof Brian Ripley wrote:
>> On Mon, 26 Apr 2004, Paul Murrell wrote:
>>> Martin Maechler wrote:
>>>
>>>>>>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
>>>>>>>>>   on Fri, 23 Apr 2004 08:21:34 +0100 (BST) writes:
>>>>>>>>
>>>>>>>>
>>>>       <........>
>>>>
>>>>    BDR> It is a matter for discussion (with the lattice
>>>>    BDR> maintainer) whether trellis.device should help you out
>>>>    BDR> here by importing the devices from package graphics.  I
>>>>    BDR> think adding (conditionalized on the platform)
>>>>
>>>>    BDR> importFrom(graphics, windows, postscript, pdf, pictex,
>>>>    BDR>            win.metafile, win.print, png, jpeg, bmp, xfig, 
>>>> bitmap)
>>>>
>>>>    BDR> to its NAMESPACE might be worth considering.
>>>>
>>>>    BDR> Alternatively, device.call <- get(device) could be put
>>>>    BDR> in a try call, followed by a try on
>>>>    BDR> getFromNamespace("graphics", device).
>>>>
>>>> That's a very good idea, I'd support quite a bit.
>>>>
>>>> I think I would go with the alternative approach
>>>> (where you probably meant to say  device <- getOption("device") 
>>>> first?),
>>>> since the importFrom(..) approach leeds to a somewhat tedious 
>>>> maintenance
>>>> effort to keep up the list of available devices for the different 
>>>> platforms
>>>> (For MacOS X one has to include quartz() only in the situations
>>>> where it's available) where as Deepayan (the lattice
>>>> maintainer) could rely on getOption("device") to be ok
>>>> {and as you proposed would be on guard using try() or its newer 
>>>> siblings}.
>>>
>>>
>>>
>>> I probably should have thought of this sooner, but anyway ...
>>> Perhaps a better solution would be to split out another package 
>>> called "devices".  Then both "graphics" and "grid" could require 
>>> "devices" (so whenever you go to do any graphics you are guaranteed 
>>> access to the default devices).
>>
>>
>>
>> I am not sure it is better, but it is not something we can do for a 
>> few months (that is, not in a patchlevel release).  
> 
> 
> 
> Yep, it would have to be only at the next minor release.
> 
> 
>> It's not quite that simple -- where would you put ps.options?  
>> Presumably in devices, and then people would need to change their 
>> hooks again ....
> 
> 
> 
> Yep (I probably should have thought of it sooner ...).
> 
> 
>> Incidentally, I think the name `devices' is rather narrow-minded (as is
>> .Devices borrowed from S-PLUS).  They are _graphics_ devices and we might
>> one day want audio devices or even devices for other types of
>> visualization such as dynamic graphics.
> 
> 
> 
> Yep.  Good point.
> 
> I think it would be a cleaner design (it would be nicer if "grid" did 
> not have to require (bits of) "graphics"), but it would be a bit 
> disruptive for users.


Could we avoid the user-disruption problem by making a new 
graphicsDevices package (to contain postscript(), x11(), ps.options(), 
...) and have the graphics package import these symbols from 
graphicsDevices AND export them (this is technically feasible with the 
current NAMESPACE implementation right?).  Then existing users wouldn't 
have to change their hooks, but grid could import directly from 
graphicsDevices, not via graphics.

Paul


>>>>    BDR> On Fri, 23 Apr 2004, Prof Brian Ripley wrote:
>>>>
>>>>    >> 1) On the first point, please do read the NEWS file for R
>>>>    >> 1.9.0.
>>>>    >>    >> .Rprofile and .First have always been run before the
>>>>    >> default packages are loaded in .First.sys, to allow them
>>>>    >> to be changed.
>>>>    >>    >> So this *is* a documented change in behaviour, not a bug.
>>>>    >> If I do
>>>>    >>    >> .First <- function() {library(lattice); trellis.device()}
>>>>    >>    >> This happens on all platforms.  You need
>>>>    >>    >> .First <- function() {library(graphics);
>>>>    >> library(lattice); trellis.device()}
>>>>    >>    >> That is true of starting any graphics device in .Rprofile
>>>>    >> or .First.
>>>>
>>>>
>>>>    BDR> -- Brian D. Ripley, ripley@stats.ox.ac.uk Professor of
>>>>    BDR> Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
>>>>    BDR> University of Oxford, Tel: +44 1865 272861 (self) 1
>>>>    BDR> South Parks Road, +44 1865 272866 (PA) Oxford OX1 3TG,
>>>>    BDR> UK Fax: +44 1865 272595
>>>>
>>>>    BDR> ______________________________________________
>>>>    BDR> R-devel@stat.math.ethz.ch mailing list
>>>>    BDR> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>> ______________________________________________
>>>> R-devel@stat.math.ethz.ch mailing list
>>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>>
>>>
>>
> 
> 


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul@stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/

From rmh at temple.edu  Mon Jun 14 03:35:57 2004
From: rmh at temple.edu (rmh@temple.edu)
Date: Mon Jun 14 03:35:59 2004
Subject: [Rd] inheritance problem in multcomp package (PR#6978)
Message-ID: <20040614013557.1C7E910582@slim.kubism.ku.dk>

# Your mailer is set to "none" (default on Windows),
# hence we cannot send the bug report directly from R.
# Please copy the bug report (after finishing it) to
# your favorite email program and send it to
#
#       r-bugs@r-project.org
#
######################################################


The multcomp functions work on "lm" objects as anticipated.
They do not work on "aov" objects.  Somehow the inheritance isn't
being acknowledged.  I can't spot where in the code the problem lies.
Somewhere the df argument for "aov" objects is not defined.
My workaround is to change the class of the "aov" object to "lm".

Rich




> search()
 [1] ".GlobalEnv"       "package:multcomp" "package:mvtnorm"  "package:methods" 
 [5] "package:stats"    "package:utils"    "package:graphics" "package:lattice" 
 [9] "package:grid"     "Autoloads"        "package:base"    
> ## from R/rw1091alpha/library/multcomp/R-ex/simint.R
> data(recovery)
> lmmod <- lm(minutes ~ blanket, data=recovery, contrasts=list(blanket =
+             "contr.Dunnett"))
> summary(simint(lmmod, psubset=2:4, conf.level=0.9,
+                alternative="less",eps=0.0001))

	Simultaneous 90% confidence intervals: model contrasts

	 model contrasts for factor

Contrast matrix:
     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    0    1    0
[3,]    0    0    1

Absolute Error Tolerance:  1e-04 

 90 % quantile:  1.8431 

Coefficients:
             Estimate   --    90 % t value Std.Err.  p raw p Bonf  p adj
blanketb1-b0  -2.1333 -Inf  0.8226 -1.3302   1.6038 0.0958 0.2874 0.2412
blanketb2-b0  -7.4667 -Inf -4.5108 -4.6556   1.6038 0.0000 0.0001 0.0001
blanketb3-b0  -1.6667 -Inf -0.0360 -1.8837   0.8848 0.0337 0.1012 0.0924
> ## change lm to aov
> aovmod <- aov(minutes ~ blanket, data=recovery, contrasts=list(blanket =
+             "contr.Dunnett"))
> aovmod
Call:
   aov(formula = minutes ~ blanket, data = recovery, contrasts = list(blanket = "contr.Dunnett"))

Terms:
                 blanket Residuals
Sum of Squares  151.9772  248.2667
Deg. of Freedom        3        37

Residual standard error: 2.590349 
Estimated effects may be unbalanced
> simint(aovmod)
Error in floor(df) : Non-numeric argument to mathematical function
> names(aovmod)
 [1] "coefficients"  "residuals"     "effects"       "rank"         
 [5] "fitted.values" "assign"        "qr"            "df.residual"  
 [9] "contrasts"     "xlevels"       "call"          "terms"        
[13] "model"        
> names(lmmod)
 [1] "coefficients"  "residuals"     "effects"       "rank"         
 [5] "fitted.values" "assign"        "qr"            "df.residual"  
 [9] "contrasts"     "xlevels"       "call"          "terms"        
[13] "model"        
> all.equal(lmmod, aovmod)
[1] "Attributes: < Component 1: Lengths (1, 2) differ (string compare on first 1) >"
[2] "Attributes: < Component 1: 1 string mismatches >"                              
[3] "Component 11: target, current don't match when deparsed"                       
> attributes(lmmod)
$names
 [1] "coefficients"  "residuals"     "effects"       "rank"         
 [5] "fitted.values" "assign"        "qr"            "df.residual"  
 [9] "contrasts"     "xlevels"       "call"          "terms"        
[13] "model"        

$class
[1] "lm"

> attributes(aovmod)
$names
 [1] "coefficients"  "residuals"     "effects"       "rank"         
 [5] "fitted.values" "assign"        "qr"            "df.residual"  
 [9] "contrasts"     "xlevels"       "call"          "terms"        
[13] "model"        

$class
[1] "aov" "lm" 

> lmmod$call
lm(formula = minutes ~ blanket, data = recovery, contrasts = list(blanket = "contr.Dunnett"))
> aovmod$call
aov(formula = minutes ~ blanket, data = recovery, contrasts = list(blanket = "contr.Dunnett"))
> ### play games
> class(aovmod) <- "lm"
> summary(simint(aovmod, psubset=2:4, conf.level=0.9,
+                alternative="less",eps=0.0001))

	Simultaneous 90% confidence intervals: model contrasts

	 model contrasts for factor

Contrast matrix:
     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    0    1    0
[3,]    0    0    1

Absolute Error Tolerance:  1e-04 

 90 % quantile:  1.8431 

Coefficients:
             Estimate   --    90 % t value Std.Err.  p raw p Bonf  p adj
blanketb1-b0  -2.1333 -Inf  0.8226 -1.3302   1.6038 0.0958 0.2874 0.2412
blanketb2-b0  -7.4667 -Inf -4.5107 -4.6556   1.6038 0.0000 0.0001 0.0001
blanketb3-b0  -1.6667 -Inf -0.0359 -1.8837   0.8848 0.0337 0.1012 0.0924
> bug.report("inheritance problem in multcomp package")



--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = alpha
 major = 1
 minor = 9.1
 year = 2004
 month = 05
 day = 25
 language = R

Windows XP Home Edition (build 2600) Service Pack 1.0

Search Path:
 .GlobalEnv, file:c:/HOME/rmh/hh/splus.library/.RData, 
file:c:/HOME/rmh/hh/splus.library/HH/.RData, package:multcomp, package:mvtnorm, package:methods, 
package:stats, package:utils, package:graphics, package:lattice, package:grid, Autoloads, 
package:base

From ripley at stats.ox.ac.uk  Mon Jun 14 08:27:42 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jun 14 08:27:49 2004
Subject: [Rd] trellis.device in .First (PR#6812)
In-Reply-To: <40CCD876.6040002@stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0406140727040.21931-100000@gannet.stats>

On Mon, 14 Jun 2004, Paul Murrell wrote:

> Could we avoid the user-disruption problem by making a new 
> graphicsDevices package (to contain postscript(), x11(), ps.options(), 
> ...) and have the graphics package import these symbols from 
> graphicsDevices AND export them (this is technically feasible with the 
> current NAMESPACE implementation right?).  Then existing users wouldn't 
> have to change their hooks, but grid could import directly from 
> graphicsDevices, not via graphics.

I believe that is possible.  Are you going to try it?

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From click21_bounce at qmail-in.click21.com.br  Mon Jun 14 15:13:50 2004
From: click21_bounce at qmail-in.click21.com.br (click21_bounce@qmail-in.click21.com.br)
Date: Mon Jun 14 15:13:56 2004
Subject: [Rd] failure notice
Message-ID: <200406141313.i5EDDqsK032691@hypatia.math.ethz.ch>

Hi. This is the qmail-send program at qmail-in.click21.com.br.
I'm afraid I wasn't able to deliver your message to the following addresses.
This is a permanent error; I've given up. Sorry it didn't work out.

<leandroallan@ibest.com.br>:
Sorry, I wasn't able to establish an SMTP connection. (#4.4.1)
I'm not going to try again; this message has been in the queue too long.

--- Below this line is a copy of the message.

Return-Path: <r-devel@lists.r-project.org>
Received: (qmail 32294 invoked by uid 10000); 14 Jun 2004 12:13:50 -0000
Message-ID: <20040614121350.32289.qmail@qmail-in.click21.com.br>
X-Velop-Forward: 150914 (ttoquinho@click21.com.br)
Received: (qmail 32272 invoked by uid 0); 14 Jun 2004 12:13:48 -0000
X-qfilter-stat: ok
Received: from unknown (HELO click21.com.br) (200.19.175.9)  by pizza with SMTP; 14 Jun 2004 12:13:47 -0000
From: r-devel@lists.r-project.org
To: ttoquinho@click21.com.br
Subject: My details
Date: Mon, 14 Jun 2004 09:13:43 -0300
X-Priority: 3
X-MSMail-Priority: Normal
MIME-Version: 1.0
Content-Type: multipart/mixed; boundary="----=_NextPart_000_0016----=_NextPart_000_0016"

This is a multi-part message in MIME format.

------=_NextPart_000_0016----=_NextPart_000_0016
Content-Type: text/plain; charset=Windows-1252
Content-Transfer-Encoding: 7bit


Hello!
Please read the e-mail.


+++ X-Attachment-Type: document
+++ X-Attachment-Status: no virus found
+++ Powered by the new F-Secure OnlineAntiVirus
+++ Visit us: www.f-secure.com



------=_NextPart_000_0016----=_NextPart_000_0016
Content-Type: text/plain

Worm.SomeFool.Gen-2 virus detected, removed attachment e-mail3.pif.

------=_NextPart_000_0016----=_NextPart_000_0016--

From lecoutre at stat.ucl.ac.be  Mon Jun 14 17:27:39 2004
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Mon Jun 14 17:29:10 2004
Subject: [Rd] Copyright issues question
Message-ID: <6.0.1.1.2.20040614172025.02178dd0@stat4ux.stat.ucl.ac.be>


Hi to the Devel list,

I am at present developping a little Excel add-in that would consist into a 
translation of John Fox RCommander package.

The idea is to have R code that recreates within Excel the menus and some 
VBA part that handles data input and outputs (those beeing redirected to 
HTML and imported within Excel in a user-transparent way).

Actualy, a first beyta version of this add-in exists and has been tested 
successfully on both Office 2000 and Office 2002, although John Fox didn't 
success to make it work on his Office 2003.

We intended to deliver this add-in as a component of the Rcmdr package. But 
Philippe Grosjean told me I may have problems with that as Excel is 
definitively not GPL... In a way, this add-in provides the R/Rmcdr-power to 
Excel.

What sort of exact problems can we expect to have? Should we consider to 
propose this as Open Source and not GPL? Do we have to obtain the agreement 
of the R Core Team?

Thanks,

Eric

Eric Lecoutre
UCL /  Institut de Statistique
Voie du Roman Pays, 20
1348 Louvain-la-Neuve
Belgium

tel: (+32)(0)10473050
lecoutre@stat.ucl.ac.be
http://www.stat.ucl.ac.be/ISpersonnel/lecoutre

If the statistics are boring, then you've got the wrong numbers. -Edward 
Tufte

From p.dalgaard at biostat.ku.dk  Mon Jun 14 18:10:14 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Jun 14 18:17:35 2004
Subject: [Rd] Copyright issues question
In-Reply-To: <6.0.1.1.2.20040614172025.02178dd0@stat4ux.stat.ucl.ac.be>
References: <6.0.1.1.2.20040614172025.02178dd0@stat4ux.stat.ucl.ac.be>
Message-ID: <x2isduqfx5.fsf@biostat.ku.dk>

Eric Lecoutre <lecoutre@stat.ucl.ac.be> writes:

> Hi to the Devel list,
> 
> I am at present developping a little Excel add-in that would consist
> into a translation of John Fox RCommander package.
> 
> The idea is to have R code that recreates within Excel the menus and
> some VBA part that handles data input and outputs (those beeing
> redirected to HTML and imported within Excel in a user-transparent
> way).
> 
> Actualy, a first beyta version of this add-in exists and has been
> tested successfully on both Office 2000 and Office 2002, although John
> Fox didn't success to make it work on his Office 2003.
> 
> We intended to deliver this add-in as a component of the Rcmdr
> package. But Philippe Grosjean told me I may have problems with that
> as Excel is definitively not GPL... In a way, this add-in provides the
> R/Rmcdr-power to Excel.
> 
> What sort of exact problems can we expect to have? Should we consider
> to propose this as Open Source and not GPL? Do we have to obtain the
> agreement of the R Core Team?

These issues are among the the murkier aspects of GPL. First, most of
R is GPL, so it is difficult to slap any other license onto it or any
glue code. Then there's the issue of whether plugins are a form of
linking or just a way of getting two separate programs to talk
together. Third, the GPL is a distribution license, so the question is
whether the worst thing that could happen would be that Microsoft
cannot distribute your plugin together with Excel...

There used to be an FSF memo on the matter, but I can't find it just
now. Closest relevant link is this one:

http://www.soberit.hut.fi/~msvalima/gpl_derivative.pdf

(+ the Rosen link inside of it)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From tlumley at u.washington.edu  Mon Jun 14 18:32:07 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Jun 14 18:32:13 2004
Subject: [Rd] Copyright issues question
In-Reply-To: <x2isduqfx5.fsf@biostat.ku.dk>
References: <6.0.1.1.2.20040614172025.02178dd0@stat4ux.stat.ucl.ac.be>
	<x2isduqfx5.fsf@biostat.ku.dk>
Message-ID: <Pine.A41.4.58.0406140927020.153096@homer12.u.washington.edu>

On Mon, 14 Jun 2004, Peter Dalgaard wrote:

> Eric Lecoutre <lecoutre@stat.ucl.ac.be> writes:
>
> >
> > What sort of exact problems can we expect to have? Should we consider
> > to propose this as Open Source and not GPL? Do we have to obtain the
> > agreement of the R Core Team?
>

It might also be worth pointing out that the R Core Team's agreement is
neither necessary nor sufficient.  The GPL permits whatever it permits,
and R as it stands is covered by the GPL, rather than by what the
developers would like on a case-by-case basis.

	-thomas

From bolker at zoo.ufl.edu  Sun Jun 13 20:49:39 2004
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Mon Jun 14 20:19:33 2004
Subject: [Rd] overhaul of mle
In-Reply-To: <40CA5F08.5010604@jhsph.edu>
References: <40C8A3FE.6030102@zoo.ufl.edu>
	<x2n03ab571.fsf@biostat.ku.dk>	<40CA17AB.4090805@zoo.ufl.edu>
	<x2acz9bpa1.fsf@biostat.ku.dk> <40CA5F08.5010604@jhsph.edu>
Message-ID: <40CCA1C3.1060407@zoo.ufl.edu>

Hmmm.  I'm still struggling with this a little bit.  I do now see, I
guess, how to use lexical scoping to get the same thing accomplished
as
mll <- function(p1,p2,p3,data1,data2,data3)
[although it still seems like the long way around].

   Peter, I appreciate why you're trying to define things this narrowly,
and I agree that I've extended the use of the "fixed" arguments.  Would
it make you any happier if there were a third argument in addition to
start and fixed (say "otherargs") that allowed for other arguments?
The other possibility would be to try to allow other arguments in a ...
argument that got passed through to optim(), but that would conflict
with the way the function is defined now since right now ... is supposed
to contain additional arguments to optim() [if you wanted to
allow the use of ... you  could either (1) add
an "optimargs" argument list with arguments for optim or (2) try
to sort the ... list according to those that matched formals(optim)
and those that didn't -- either way is bit of a nuisance, I guess).

   The advantage of an "otherargs" argument is that it would provide
a way for you (Peter) to define a strict subset of the functionality
that only worked when people refrained from messing with the data --
if someone wanted to combine two likelihoods you could either check
that the "otherargs" components were identical, or disallow that
operation if "otherargs" was non-NULL.

   Again, I don't want to be a pain -- we all have our own goals and
ways of working, and I certainly don't have any intention
of hijacking the mle code (although
in the end I guess I could always fork my own version -- this is GPL,
right?).  It's just that it seems much more natural to me to do

mll <- function(p1,p2,p3,data1,data2,data3)
m1 = mle(mll,start=...,otherargs=list(data1=X1,data2=X2,data3=X3))
m2 = mle(mll,start=...,otherargs=list(data1=Y1,data2=Y2,data3=Y3))

rather than

mll <- function(p1,p2,p3) { f(p1,p2,p3,data1) }
assign("data1",X1,envir=environment(mll))
assign("data2",X2,envir=environment(mll))
assign("data3",X3,envir=environment(mll))
...
m1 = mle(mll,start=...)
assign("data1",Y1,envir=environment(mll))
assign("data2",Y2,envir=environment(mll))
assign("data3",Y3,envir=environment(mll))
m2 = mle(mll,start=...)

or

makeLogLik <- function(data1,data2,data3) {
    function(p1,p2,p3) { }
}
m1 <- mle(makeLogLik(X1,X2,X3),start=...)
m2 <- mle(makeLogLik(Y1,Y2,Y3),start=...)

[and yes, I do sometimes have three different
"data" objects, of different lengths, to use
in MLE analyses: right now I'm doing something
where I have population samples in one set
of years and fishery closures in another, different-length,
set of years -- it would be possible to combine
them all into a single data frame, but the point
is that it's not an unusual requirement to
have multiple auxiliary data sets]

   Am I making any sense here?  Do any other readers of R-devel (or at
least those that have hung on to this point) routinely run the same
MLE analyses for a variety of different data sets and find my
approach sensible, or am I alone?

   Ben

PS lm(), glm(), nls(), nlme(), ... all have a "data" argument that
seems to play the role of "otherargs" presented above.  Would this
be a sensible and precedented way to go?

[SNIPPED context: discussion of lexical scoping and closures
and why to use them instead of passing data as extra parameters
to a likelihood function]

From frog at frogrecruitment.co.nz  Tue Jun 15 03:06:34 2004
From: frog at frogrecruitment.co.nz (FrogRec)
Date: Tue Jun 15 03:06:40 2004
Subject: [Rd] Frog Recruitment
Message-ID: <B19B65A9427A794392154042B9F3B0691293AE@dcfrog01.frogrecruitment.net.nz>

 

Thank you for sending your details to Frog Recruitment.

Please be assured that all applications are carefully considered.

Should we require a meeting with you, we will make contact to discuss
further.

We wish you all the very best with your career search.

Regards

The Job Seeker Team at frog recruitment.

From p.murrell at auckland.ac.nz  Tue Jun 15 05:54:19 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue Jun 15 05:57:56 2004
Subject: [Rd] trellis.device in .First (PR#6812)
References: <Pine.LNX.4.44.0406140727040.21931-100000@gannet.stats>
Message-ID: <40CE72EB.6010503@stat.auckland.ac.nz>

Hi


Prof Brian Ripley wrote:
> On Mon, 14 Jun 2004, Paul Murrell wrote:
> 
> 
>>Could we avoid the user-disruption problem by making a new 
>>graphicsDevices package (to contain postscript(), x11(), ps.options(), 
>>...) and have the graphics package import these symbols from 
>>graphicsDevices AND export them (this is technically feasible with the 
>>current NAMESPACE implementation right?).  Then existing users wouldn't 
>>have to change their hooks, but grid could import directly from 
>>graphicsDevices, not via graphics.
> 
> 
> I believe that is possible.  Are you going to try it?


Yep.  I'll give it a go.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul@stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/

From d.firth at warwick.ac.uk  Tue Jun 15 12:50:42 2004
From: d.firth at warwick.ac.uk (d.firth@warwick.ac.uk)
Date: Tue Jun 15 12:50:44 2004
Subject: [Rd] out-of-date information in R for Mac OS X FAQ (PR#6982)
Message-ID: <20040615105042.29FD41059D@slim.kubism.ku.dk>

Full_Name: David Firth
Version: 1.9.0
OS: Mac OS 10.3
Submission from: (NULL) (137.205.240.25)


For libreadline, the R for Mac OS X FAQ points to http://www.economia.unimi.it/R
-- but libreadline does not seem to be there at http://www.economia.unimi.it/R
(any more?)

It seems useful still to provide this "patched" version of libreadline, for
those of us who want to run R from the Terminal.

From Vidar.Hjellvik at imr.no  Tue Jun 15 14:20:05 2004
From: Vidar.Hjellvik at imr.no (Vidar.Hjellvik@imr.no)
Date: Tue Jun 15 14:20:10 2004
Subject: [Rd] tapply/barplot (PR#6983)
Message-ID: <20040615122005.D794C105A2@slim.kubism.ku.dk>

Hello,

there seems to be a bug in tapply or barplot in R 1.9.0 that was not in =
earlier versions. The following code creates two nice barplots in 1.7.0, =
but the first one is bad in 1.9.0:

par(mfrow=3Dc(1,2))
x <- rep(1:10,10)
y <- runif(100,1,100)
z <- tapply(y,x,mean)
barplot(z)
barplot(as.numeric(z))

although is.numeric(z) returns TRUE!

Best regards,

Vidar Hjellvik
Institute of Marine Research
P.O.Box 1870 Nordnes
N-5817 Bergen
phone: +47 55 23 86 62
email: vidarh@imr.no

From ripley at stats.ox.ac.uk  Tue Jun 15 14:31:59 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Jun 15 14:32:07 2004
Subject: [Rd] tapply/barplot (PR#6983)
In-Reply-To: <20040615122005.D794C105A2@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406151324050.5383-100000@gannet.stats>

But not in R 1.9.1 beta, due for release next Monday.  This has been
reported quite a few times already -- see the R-help archives and
PR#6676/7/8 and PR#6894, for example.

Note that the plots in 1.9.1 beta are deliberately different from 1.7.0.

On Tue, 15 Jun 2004 Vidar.Hjellvik@imr.no wrote:

> Hello,
> 
> there seems to be a bug in tapply or barplot in R 1.9.0 that was not in =
> earlier versions. 

It's not a bug, rather a design change.  That change has been revisited in 
1.9.1.

> The following code creates two nice barplots in 1.7.0, =
> but the first one is bad in 1.9.0:
> 
> par(mfrow=c(1,2))
> x <- rep(1:10,10)
> y <- runif(100,1,100)
> z <- tapply(y,x,mean)
> barplot(z)
> barplot(as.numeric(z))
> 
> although is.numeric(z) returns TRUE!

Yes, but z is a 1D array, and as.numeric makes it into a numeric *vector*.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Tue Jun 15 14:26:18 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Jun 15 14:33:44 2004
Subject: [Rd] tapply/barplot (PR#6983)
In-Reply-To: <20040615122005.D794C105A2@slim.kubism.ku.dk>
References: <20040615122005.D794C105A2@slim.kubism.ku.dk>
Message-ID: <x2n035hus5.fsf@biostat.ku.dk>

Vidar.Hjellvik@imr.no writes:

> Hello,
> 
> there seems to be a bug in tapply or barplot in R 1.9.0 that was not in =
> earlier versions. The following code creates two nice barplots in 1.7.0, =
> but the first one is bad in 1.9.0:
> 
> par(mfrow=3Dc(1,2))
> x <- rep(1:10,10)
> y <- runif(100,1,100)
> z <- tapply(y,x,mean)
> barplot(z)
> barplot(as.numeric(z))

We know. Please check the relevant sources for previous reports, and,
in particular at this stage, the current 1.9.1beta!

> 
> although is.numeric(z) returns TRUE!

That's irrelevant: as.numeric does more than convert to numeric. Try
this for instance:

 m <- matrix(1:6,2)
 barplot(m)
 barplot(as.numeric(m))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From dmurdoch at pair.com  Tue Jun 15 17:27:04 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Jun 15 17:27:01 2004
Subject: [Rd] Names of versions (was: [R] error with barplot command?)
In-Reply-To: <0HZC00ED7R2534@mail.fudan.edu.cn>
References: <0HZC00ED7R2534@mail.fudan.edu.cn>
Message-ID: <ps3uc01dkriumfim2g7n7n46veqe1vlgsd@4ax.com>

On Tue, 15 Jun 2004 21:41:00 +0800, ?????? <0034058@fudan.edu.cn>
wrote :

>Duncan Murdoch??
>
> thanks for your information:)
>
> i have another small question,i hope you can give me an perfect answer.
>
>i know the difference between alpha and beta version,but how about pathed verion?
>
>does pathed version means final version,formal version?

Here's a summary of how we refer to various R versions:

R has official releases:  1.9.0 is the current official release, 1.9.1
will be out in a week.

Development occurs in two main branches:  in the "r-patched" branch,
we fix bugs in the current official release, but add (almost) no new
features.  In the "r-devel" branch, we add new features.  (There may
also be other small branches, not really intended for public
consumption, where people are trying things out.)

Several weeks after each release, we look at how many bugs have been
identified, and decide whether to have a bug fix release.  For
example, 1.9.0 came out in early April, and the decision to have a
1.9.1 release was made around the end of the month.  The date for it
is set depending on the schedules of the core developers:  it was set
for June 21.  There may be a 1.9.2 release, but I doubt it: 1.9.0 had
very few bugs, and I don't expect to see many at all in 1.9.1
(especially if people have been testing the current alpha/beta
releases!).

The r-devel branch has already had a lot of changes since April, and
will get more over the summer.  It will be released as R 2.0.0 in
early October, according to current plans.

About a month before a major release, we have a "grand feature
freeze".  Only minor changes to features will be allowed.  (The big
changes are never allowed in the r-patched branch, and even small
feature changes are discouraged unless they are badly needed.)

About 2-3 weeks before any release, we have a "feature freeze", and
start making "alpha" releases.  At this point, no new features will be
added.

About a week before release, we go to "beta" releases.  At this point
only "trivial or critical" bugs will be fixed, because sometimes bug
fixes cause other bugs.  This is the state we're in right now, with
the r-patched branch frozen.  In September or October, it will be the
r-devel branch that gets frozen.

I hope that makes it clear.  For even more detail, see the
developer.r-project.org page, under "Development Guidelines".

Duncan Murdoch

From p.dalgaard at biostat.ku.dk  Tue Jun 15 17:50:30 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Jun 15 17:57:58 2004
Subject: [Rd] Names of versions (was: [R] error with barplot command?)
In-Reply-To: <ps3uc01dkriumfim2g7n7n46veqe1vlgsd@4ax.com>
References: <0HZC00ED7R2534@mail.fudan.edu.cn>
	<ps3uc01dkriumfim2g7n7n46veqe1vlgsd@4ax.com>
Message-ID: <x2ekogizw9.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch@pair.com> writes:

> On Tue, 15 Jun 2004 21:41:00 +0800, ?????? <0034058@fudan.edu.cn>
> wrote :
> 
> >Duncan Murdoch??
> >
> > thanks for your information:)
> >
> > i have another small question,i hope you can give me an perfect answer.
> >
> >i know the difference between alpha and beta version,but how about pathed verion?
> >
> >does pathed version means final version,formal version?
> 
> Here's a summary of how we refer to various R versions:
> 
> R has official releases:  1.9.0 is the current official release, 1.9.1
> will be out in a week.
> 
> Development occurs in two main branches:  in the "r-patched" branch,
> we fix bugs in the current official release, but add (almost) no new
> features.  In the "r-devel" branch, we add new features.  (There may
> also be other small branches, not really intended for public
> consumption, where people are trying things out.)
> 
> Several weeks after each release, we look at how many bugs have been
> identified, and decide whether to have a bug fix release.  For
> example, 1.9.0 came out in early April, and the decision to have a
> 1.9.1 release was made around the end of the month.  The date for it
> is set depending on the schedules of the core developers:  it was set
> for June 21.  There may be a 1.9.2 release, but I doubt it: 1.9.0 had
> very few bugs, and I don't expect to see many at all in 1.9.1
> (especially if people have been testing the current alpha/beta
> releases!).
> 
> The r-devel branch has already had a lot of changes since April, and
> will get more over the summer.  It will be released as R 2.0.0 in
> early October, according to current plans.
> 
> About a month before a major release, we have a "grand feature
> freeze".  Only minor changes to features will be allowed.  (The big
> changes are never allowed in the r-patched branch, and even small
> feature changes are discouraged unless they are badly needed.)
> 
> About 2-3 weeks before any release, we have a "feature freeze", and
> start making "alpha" releases.  At this point, no new features will be
> added.
> 
> About a week before release, we go to "beta" releases.  At this point
> only "trivial or critical" bugs will be fixed, because sometimes bug
> fixes cause other bugs.  This is the state we're in right now, with
> the r-patched branch frozen.  In September or October, it will be the
> r-devel branch that gets frozen.
> 
> I hope that makes it clear.  For even more detail, see the
> developer.r-project.org page, under "Development Guidelines".

Nice summary, Duncan. 

Just let me add that the patch versions are the formal versions (e.g.
1.9.0) plus patches to fix bugs that have been discovered in the
meantime. As you might have gathered, patched versions are usually
more bug free than the official ones, but they carry a larger risk of
new failures, because they are basically only as good as the latest
commit, which is typically a single developer's work. (We haven't seen
many such failures over the years though, and I think almost all have
been portability issues or people forgetting to commit *all* their
changes.)



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From r-devel at stat.math.ethz.ch  Wed Jun 16 09:58:12 2004
From: r-devel at stat.math.ethz.ch (r-devel@stat.math.ethz.ch)
Date: Wed Jun 16 10:16:29 2004
Subject: [Rd] Virus intercepted
Message-ID: <200406160758.i5G7wCFB092464@assassin.nexon.com.au>

A message you sent to
	<noc@corp.nexon.com.au>
contained Worm.SomeFool.Z and has not been delivered.

The infected machine is likely to be here:
from nexon.com.au (222-152-4-106.jetstream.xtra.co.nz [222.152.4.106])
	by scooter.nexon.com.au (8.11.6/8.11.6) with ESMTP id i5G7v2D03238
	for <noc@nexon.com.au>; Wed, 16 Jun 2004 17:57:03 +1000 (EST)
	(envelope-from r-devel@hypatia.math.ethz.ch)

From phgrosjean at sciviews.org  Wed Jun 16 12:08:39 2004
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed Jun 16 12:09:10 2004
Subject: [Rd] Copyright issues question
In-Reply-To: <Pine.A41.4.58.0406140927020.153096@homer12.u.washington.edu>
Message-ID: <MABBLJDICACNFOLGIHJOGEKIEIAA.phgrosjean@sciviews.org>

>> Eric Lecoutre <lecoutre@stat.ucl.ac.be> writes:
>>
>> >
>> > What sort of exact problems can we expect to have? Should we consider
>> > to propose this as Open Source and not GPL? Do we have to obtain the
>> > agreement of the R Core Team?
>>

Thomas Lumley answered:

>It might also be worth pointing out that the R Core Team's agreement is
>neither necessary nor sufficient.  The GPL permits whatever it permits,
>and R as it stands is covered by the GPL, rather than by what the
>developers would like on a case-by-case basis.

>	-thomas

OK, that is probably true. However, in GPL 2, you have:

10. If you wish to incorporate parts of the Program into other free
programs whose distribution conditions are different, write to the author
to ask for permission.

I think I must clarify the context here. I already think about copyright
aspects since a while, as the maintainer of the R GUI Projects web site.
Indeed, I think several programs violate GPL, because they place a different
(G)UI on top of R, and claim for a different, incompatible license.
Recently, I have reworked a little bit the R GUI Projects web site in such a
way that I eliminated links, and send mails to authors of obviously
offending programs, namely, Brodgar and Statistical Lab. You find no link to
these programs any more in R GUI Projects. I hope thay will resolve the
conflicts as soon as possible.

However, there are other programs whose status is not clear for me. I think
that GUIs and Plugins are derivatives and the contaminent character of GPL
applies to them. The following quote from the document pointed by Peter
Dalgaard, reinforces my conviction
(http://www.soberit.hut.fi/~msvalima/gpl_derivative.pdf, p. 12):


4.4 Plug-Ins and Device Drivers
Consider next a situation where one develops a plug-in or device driver to a
program
under GPL. Is such a plug-in a derivative work of the main program and,
hence, under GPL? FSF FAQ answers with an interpretation criteria based on
substance and form. It states:
"If the program dynamically links plug-ins, and they make function calls
to each other and share data structures, we believe they form a single pro-
gram, so plug-ins must be treated as extensions to the main program. This
means they must be released under the GPL ."

Of course, it is lawyers that decide, not me, or us!!! However, I am
wondering if the status of any plugin extension to commercial software like
Excel with GPL programs is valid. I think about RxlCommander, but also,
RExcel. In a sense, these programs are totally against the GPL philosophy.
Basically, we provide to a commercial software (Microsoft Excel), new
functionnalities that derive from a GPL work (R). It is clear that, if
people at Microsoft developped these plugins, they would be havily blamed.
Now, if someone else write and distribute them... what does it changes? The
result is still the same: to use GPL software (R) to provide additionnal
features to a commercial software (Microsoft Excel), and the later could
possibly benefit from these additionnal features to reinforce its dominancy
(let's consider the speculative situation where R versus Excel plugins are
so much appreciated and used that they have a siginificant impact in the
future). This is potentially a serious breach in the GPL philosophy that
allows, indirectly, to reuse features from a GPL program to supplement a
commercial one. Philosophically speaking, I am against such a practice.
However, this is, and should remain my own opinion... Now, what about legal
aspects here?

Best,

Philippe Grosjean

P.S.: I am also concerned about JGR, because it is also not GPL. Any
comment?

.......................................................<?}))><....
 ) ) ) ) )
( ( ( ( (   Prof. Philippe Grosjean
\  ___   )
 \/ECO\ (   Numerical Ecology of Aquatic Systems
 /\___/  )  Mons-Hainaut University, Pentagone
/ ___  /(   8, Av. du Champ de Mars, 7000 Mons, Belgium
 /NUM\/  )
 \___/\ (   phone: + 32.65.37.34.97, fax: + 32.65.37.33.12
       \ )  email: Philippe.Grosjean@umh.ac.be
 ) ) ) ) )  SciViews project coordinator (http://www.sciviews.org)
( ( ( ( (
...................................................................

From dmurdoch at pair.com  Wed Jun 16 14:15:02 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed Jun 16 14:14:55 2004
Subject: [Rd] Copyright issues question
In-Reply-To: <MABBLJDICACNFOLGIHJOGEKIEIAA.phgrosjean@sciviews.org>
References: <Pine.A41.4.58.0406140927020.153096@homer12.u.washington.edu>
	<MABBLJDICACNFOLGIHJOGEKIEIAA.phgrosjean@sciviews.org>
Message-ID: <2ae0d0974ju0tbt90apjtpg5ja1avcuoja@4ax.com>

On Wed, 16 Jun 2004 12:08:39 +0200, "Philippe Grosjean"
<phgrosjean@sciviews.org> wrote:

>Thomas Lumley answered:
>
>>It might also be worth pointing out that the R Core Team's agreement is
>>neither necessary nor sufficient.  The GPL permits whatever it permits,
>>and R as it stands is covered by the GPL, rather than by what the
>>developers would like on a case-by-case basis.
>
>>	-thomas
>
>OK, that is probably true. However, in GPL 2, you have:
>
>10. If you wish to incorporate parts of the Program into other free
>programs whose distribution conditions are different, write to the author
>to ask for permission.

Unfortunately, the R Core Team is the author only of some of R, not
all of it.  It incorporates other GPL code, so you'd need to track
down all of those authors and get their permission too.

Duncan Murdoch

From mmr at tci.ufal.br  Wed Jun 16 16:45:49 2004
From: mmr at tci.ufal.br (mmr@tci.ufal.br)
Date: Wed Jun 16 16:45:51 2004
Subject: [Rd] is.integer() (PR#6984)
Message-ID: <20040616144549.6AE271057A@slim.kubism.ku.dk>

Hello!

I'm not sure if is it a BUG or not...
I'm using R 1.9.0, and I used the command below:

> is.integer(9)
[1] FALSE

R manual contains this words about the is.integer() function:

"is.integer returns TRUE or FALSE depending on whether its argument is of 
integer type or not."

What's the problem? Am I wrong about the BUG report?

Thank you very much.

M?rcio de Medeiros Ribeiro
Graduando em Ci?ncia da Computa??o
Departamento de Tecnologia da Informa??o - TCI
Universidade Federal de Alagoas - UFAL
Macei? - Alagoas - Brasil
Projeto CoCADa

From ripley at stats.ox.ac.uk  Wed Jun 16 16:50:21 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jun 16 16:50:26 2004
Subject: [Rd] is.integer() (PR#6984)
In-Reply-To: <20040616144549.6AE271057A@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406161547580.14428-100000@gannet.stats>

On Wed, 16 Jun 2004 mmr@tci.ufal.br wrote:

> I'm not sure if is it a BUG or not...

You were wrong to send a bug report if you are not sure: see the R FAQ.

> I'm using R 1.9.0, and I used the command below:
> 
> > is.integer(9)
> [1] FALSE
> 
> R manual contains this words about the is.integer() function:
> 
> "is.integer returns TRUE or FALSE depending on whether its argument is of 
> integer type or not."
> 
> What's the problem? Am I wrong about the BUG report?

9 is a double constant, not an integer constant.  The type of `9' is not
integer: try it

> typeof(9)
[1] "double"

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From tlumley at u.washington.edu  Wed Jun 16 17:19:20 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Jun 16 17:19:34 2004
Subject: [Rd] Copyright issues question
In-Reply-To: <MABBLJDICACNFOLGIHJOGEKIEIAA.phgrosjean@sciviews.org>
References: <MABBLJDICACNFOLGIHJOGEKIEIAA.phgrosjean@sciviews.org>
Message-ID: <Pine.A41.4.58.0406160803540.99070@homer09.u.washington.edu>

On Wed, 16 Jun 2004, Philippe Grosjean wrote:

> >> Eric Lecoutre <lecoutre@stat.ucl.ac.be> writes:
> >>
> >> >
> >> > What sort of exact problems can we expect to have? Should we consider
> >> > to propose this as Open Source and not GPL? Do we have to obtain the
> >> > agreement of the R Core Team?
> >>
>
> Thomas Lumley answered:
>
> >It might also be worth pointing out that the R Core Team's agreement is
> >neither necessary nor sufficient.  The GPL permits whatever it permits,
> >and R as it stands is covered by the GPL, rather than by what the
> >developers would like on a case-by-case basis.
>
> >	-thomas
>
> OK, that is probably true. However, in GPL 2, you have:
>
> 10. If you wish to incorporate parts of the Program into other free
> programs whose distribution conditions are different, write to the author
> to ask for permission.
>

There are two points here.  The first is that, as Duncan has pointed out,
the R distribution contains GPL code written by people other than us.  It
might well be possible to extract a working subset that we could release
under another license, but it would take quite a bit of effort.

The second point is that one of your concerns is about areas where the GPL
is not clear.  If it isn't clear to you then asking us won't help. We are
not experts in what the GPL means, nor do we have the authority to change
what it means.  It would still be polite to ask about uses of R that the
developers might personally object to, but there is no legal benefit in
doing so.

On the other hand, as the early history of KDE shows, it is possible for
free software to be produced and become popular even when there are honest
differences of opinion about the legalities.

	-thomas

From phgrosjean at sciviews.org  Wed Jun 16 17:41:00 2004
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed Jun 16 17:41:21 2004
Subject: [Rd] Copyright issues question
In-Reply-To: <Pine.A41.4.58.0406160803540.99070@homer09.u.washington.edu>
Message-ID: <MABBLJDICACNFOLGIHJOIELAEIAA.phgrosjean@sciviews.org>

> Thomas Lumley answered:
>
> >It might also be worth pointing out that the R Core Team's agreement is
> >neither necessary nor sufficient.  The GPL permits whatever it permits,
> >and R as it stands is covered by the GPL, rather than by what the
> >developers would like on a case-by-case basis.
>
> >	-thomas
>
> OK, that is probably true. However, in GPL 2, you have:
>
> 10. If you wish to incorporate parts of the Program into other free
> programs whose distribution conditions are different, write to the author
> to ask for permission.
>

>There are two points here.  The first is that, as Duncan has pointed out,
>the R distribution contains GPL code written by people other than us.  It
>might well be possible to extract a working subset that we could release
>under another license, but it would take quite a bit of effort.

>The second point is that one of your concerns is about areas where the GPL
>is not clear.  If it isn't clear to you then asking us won't help. We are
>not experts in what the GPL means, nor do we have the authority to change
>what it means.  It would still be polite to ask about uses of R that the
>developers might personally object to, but there is no legal benefit in
>doing so.

>On the other hand, as the early history of KDE shows, it is possible for
>free software to be produced and become popular even when there are honest
>differences of opinion about the legalities.

>	-thomas

Thomas,

Sorry if I did not expressed correctly what I meant, but my query was to
make sure all programs presented in the R GUI Projects web site have valid
licensing terms. As it seems to be some difficults points with plugins and
GUI, I ask the question to the R core Team and other developers on this
list, just in case someone got a clearer answer than the one I can get
myself.

Let's me reformulate the questions in a simpler way:

1) Is it OK to develop GPL plugins for commercial software, and to bring
functionnalities of these GPL software into those commercial programs,
namely, plugins based on R for Excel, like RExcel and RxlCommander?

2) Is it OK to make a GUI on top of R, and to distribute it under a
different license than GPL, like Statistical Lab, Brodgar, or JGR?

3) In case there is no clear answer to these questions (which seems to be
the case), is it OK to support such plugins or GUIs that possibly violate
the GPL license, for instance, by distributing them, or by placing links to
them in the R GUI Projects web site?

Best,

Philippe Grosjean

From rpeng at jhsph.edu  Wed Jun 16 17:48:18 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed Jun 16 17:48:23 2004
Subject: [Rd] Copyright issues question
In-Reply-To: <MABBLJDICACNFOLGIHJOIELAEIAA.phgrosjean@sciviews.org>
References: <MABBLJDICACNFOLGIHJOIELAEIAA.phgrosjean@sciviews.org>
Message-ID: <40D06BC2.8080508@jhsph.edu>

Regarding question 3, it seems the answer is probably "yes" since, for 
example, there are packages on CRAN which restrict commercial use, and 
this is incompatible with the GPL.

-roger

Philippe Grosjean wrote:
>>Thomas Lumley answered:
>>
>>
>>>It might also be worth pointing out that the R Core Team's agreement is
>>>neither necessary nor sufficient.  The GPL permits whatever it permits,
>>>and R as it stands is covered by the GPL, rather than by what the
>>>developers would like on a case-by-case basis.
>>
>>>	-thomas
>>
>>OK, that is probably true. However, in GPL 2, you have:
>>
>>10. If you wish to incorporate parts of the Program into other free
>>programs whose distribution conditions are different, write to the author
>>to ask for permission.
>>
> 
> 
>>There are two points here.  The first is that, as Duncan has pointed out,
>>the R distribution contains GPL code written by people other than us.  It
>>might well be possible to extract a working subset that we could release
>>under another license, but it would take quite a bit of effort.
> 
> 
>>The second point is that one of your concerns is about areas where the GPL
>>is not clear.  If it isn't clear to you then asking us won't help. We are
>>not experts in what the GPL means, nor do we have the authority to change
>>what it means.  It would still be polite to ask about uses of R that the
>>developers might personally object to, but there is no legal benefit in
>>doing so.
> 
> 
>>On the other hand, as the early history of KDE shows, it is possible for
>>free software to be produced and become popular even when there are honest
>>differences of opinion about the legalities.
> 
> 
>>	-thomas
> 
> 
> Thomas,
> 
> Sorry if I did not expressed correctly what I meant, but my query was to
> make sure all programs presented in the R GUI Projects web site have valid
> licensing terms. As it seems to be some difficults points with plugins and
> GUI, I ask the question to the R core Team and other developers on this
> list, just in case someone got a clearer answer than the one I can get
> myself.
> 
> Let's me reformulate the questions in a simpler way:
> 
> 1) Is it OK to develop GPL plugins for commercial software, and to bring
> functionnalities of these GPL software into those commercial programs,
> namely, plugins based on R for Excel, like RExcel and RxlCommander?
> 
> 2) Is it OK to make a GUI on top of R, and to distribute it under a
> different license than GPL, like Statistical Lab, Brodgar, or JGR?
> 
> 3) In case there is no clear answer to these questions (which seems to be
> the case), is it OK to support such plugins or GUIs that possibly violate
> the GPL license, for instance, by distributing them, or by placing links to
> them in the R GUI Projects web site?
> 
> Best,
> 
> Philippe Grosjean
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng

From ripley at stats.ox.ac.uk  Wed Jun 16 18:20:50 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jun 16 18:21:09 2004
Subject: [Rd] Copyright issues question
In-Reply-To: <MABBLJDICACNFOLGIHJOIELAEIAA.phgrosjean@sciviews.org>
Message-ID: <Pine.LNX.4.44.0406161706430.14482-100000@gannet.stats>

On Wed, 16 Jun 2004, Philippe Grosjean wrote:

> > Thomas Lumley answered:
> >
> > >It might also be worth pointing out that the R Core Team's agreement is
> > >neither necessary nor sufficient.  The GPL permits whatever it permits,
> > >and R as it stands is covered by the GPL, rather than by what the
> > >developers would like on a case-by-case basis.
> >
> > >	-thomas
> >
> > OK, that is probably true. However, in GPL 2, you have:
> >
> > 10. If you wish to incorporate parts of the Program into other free
> > programs whose distribution conditions are different, write to the author
> > to ask for permission.
> >
> 
> >There are two points here.  The first is that, as Duncan has pointed out,
> >the R distribution contains GPL code written by people other than us.  It
> >might well be possible to extract a working subset that we could release
> >under another license, but it would take quite a bit of effort.
> 
> >The second point is that one of your concerns is about areas where the GPL
> >is not clear.  If it isn't clear to you then asking us won't help. We are
> >not experts in what the GPL means, nor do we have the authority to change
> >what it means.  It would still be polite to ask about uses of R that the
> >developers might personally object to, but there is no legal benefit in
> >doing so.
> 
> >On the other hand, as the early history of KDE shows, it is possible for
> >free software to be produced and become popular even when there are honest
> >differences of opinion about the legalities.
> 
> >	-thomas
> 
> Thomas,
> 
> Sorry if I did not expressed correctly what I meant, but my query was to
> make sure all programs presented in the R GUI Projects web site have valid
> licensing terms. As it seems to be some difficults points with plugins and
> GUI, I ask the question to the R core Team and other developers on this
> list, just in case someone got a clearer answer than the one I can get
> myself.
> 
> Let's me reformulate the questions in a simpler way:
> 
> 1) Is it OK to develop GPL plugins for commercial software, and to bring
> functionnalities of these GPL software into those commercial programs,
> namely, plugins based on R for Excel, like RExcel and RxlCommander?

Definitely OK to develop them.  GPL is about distribution.  I don't see 
any issue here as you are not distributing Excel.  It's OK that gcc uses 
proprietary runtime libraries on Solaris (and elsewhere) for example.

For many years Doug Bates and others have distributed GPLed S addons.  
That seems to cause no difficulty until commercial distributors want to 
include them, when they need a different licence (which they do have in 
the prominent cases).

> 2) Is it OK to make a GUI on top of R, and to distribute it under a
> different license than GPL, like Statistical Lab, Brodgar, or JGR?

That's the murky one, and depends on the precise meaning of `on top of'.
If like Rcmdr this were a pure R package then to deny this would be to say 
that any distributed R code must be GPL-ed and that is not the common 
understanding (nor than of the CRAN hosts).

> 3) In case there is no clear answer to these questions (which seems to be
> the case), is it OK to support such plugins or GUIs that possibly violate
> the GPL license, for instance, by distributing them, or by placing links to
> them in the R GUI Projects web site?

I think it is agreed that making an HTML link is OK, although it might be 
to point out that you do not recommend using Whizzy-R-GUI as it cannot be 
distributed with R.

Your questions are not precise enough to be answered.  And if they were, 
as Thomas has said repeatedly the onus is on the distributors of such code 
to meet their obligations, not the R developers to enforce them (or even 
advise what they are).

As practical advice, in your position I would be seeking an undertaking 
from the developers of the various components that their usage is 
consistent with the R licence(s).  That might cause some of them to ponder 
the issue.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From phgrosjean at sciviews.org  Thu Jun 17 09:55:04 2004
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu Jun 17 09:55:39 2004
Subject: [Rd] Copyright issues question
In-Reply-To: <Pine.LNX.4.44.0406161706430.14482-100000@gannet.stats>
Message-ID: <MABBLJDICACNFOLGIHJOMELLEIAA.phgrosjean@sciviews.org>

Thanks all for your answer,

As the maintainer of the R GUI Projects web page I will continue to place a
link to all software that do not obviously enfringes GPL, that is, RExcel,
RxlCommander or JGR.

Best,

Philippe Grosjean

From fc at maths.uq.edu.au  Thu Jun 17 12:00:47 2004
From: fc at maths.uq.edu.au (fc@maths.uq.edu.au)
Date: Thu Jun 17 12:00:50 2004
Subject: [Rd] Bug in FEXACT: gave negative key (PR#6986)
Message-ID: <20040617100047.B13DB1057B@slim.kubism.ku.dk>



Hello,

I'm using R to apply Fishers exact test to a whole pile of
contingency tables, and I've run into the bug shown below.

regards,

Francis

--

> dat1 = matrix(c(0,1,0,1,0,0,1,0,0,0,1,0,1,0,0,1,0,0,0,1,0,1,0,0,1,0,0,0,0,
           1,1,0,0,1,0,0,1,0,0,1,0,0,3,0,0,2,0,0,1,0,0,0,1,0,0,2,0,0,
          2,0,0,1,0,1,0,0,3,0,0,2,0,0,0,1,0,5,0,0,0,1,0,1,0,0),    nrow=3)

> fisher.test( dat1 )

Error in fisher.test(dat1) : Bug in FEXACT: gave negative key

From p.dalgaard at biostat.ku.dk  Thu Jun 17 12:25:36 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu Jun 17 12:33:16 2004
Subject: [Rd] Bug in FEXACT: gave negative key (PR#6986)
In-Reply-To: <20040617100047.B13DB1057B@slim.kubism.ku.dk>
References: <20040617100047.B13DB1057B@slim.kubism.ku.dk>
Message-ID: <x2r7sexyzj.fsf@biostat.ku.dk>

fc@maths.uq.edu.au writes:

> Hello,
> 
> I'm using R to apply Fishers exact test to a whole pile of
> contingency tables, and I've run into the bug shown below.
> 
> regards,
> 
> Francis
> 
> --
> 
> > dat1 = matrix(c(0,1,0,1,0,0,1,0,0,0,1,0,1,0,0,1,0,0,0,1,0,1,0,0,1,0,0,0,0,
>            1,1,0,0,1,0,0,1,0,0,1,0,0,3,0,0,2,0,0,1,0,0,0,1,0,0,2,0,0,
>           2,0,0,1,0,1,0,0,3,0,0,2,0,0,0,1,0,5,0,0,0,1,0,1,0,0),    nrow=3)
> 
> > fisher.test( dat1 )
> 
> Error in fisher.test(dat1) : Bug in FEXACT: gave negative key

I suppose it counts as a bug when FEXACT says so. However it is most
likely caused by integer overrun, and so really a code for "problem too
large". I.e. we can probably fix the error message, put not get
fisher.test to do the problem. Consider instead

> chisq.test(dat1,sim=T,B=50000)

        Pearson's Chi-squared test with simulated p-value (based on 50000
        replicates)

data:  dat1
X-squared = 80, df = NA, p-value = 2e-05


BTW, a line with "-- " at the start means beginning of signature, and
mail readers may do funny things with the subsequent text. Mine just
puts it in italics, but others might elect to discard the signature
completely or chop it to four lines, etc.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From andrew_zachary at yahoo.com  Thu Jun 17 16:06:40 2004
From: andrew_zachary at yahoo.com (andrew_zachary@yahoo.com)
Date: Thu Jun 17 16:06:44 2004
Subject: [Rd] Bug in RODBC (PR#6987)
Message-ID: <20040617140640.1BBD7D622@slim.kubism.ku.dk>

Full_Name: Andrew Zachary
Version: 1.9.0
OS: XP Pro
Submission from: (NULL) (24.44.128.138)


Hello -

Have an odd problem with RODBC -- it fails in an sqlSave with the RGui reporting
a fatal exception in ModName msvcrt.dll. I'm using MySQL and trying to append a
medium size data frame to an already existing table.

I will work to isolate the problem and send a more detailed report.

In the meantime, does anyone have some pointers for what might generate such an
error, and for how to work around it?

Thanks,
Andrew Zachary

From clayton.springer at pharma.novartis.com  Thu Jun 17 17:43:33 2004
From: clayton.springer at pharma.novartis.com (clayton.springer@pharma.novartis.com)
Date: Thu Jun 17 17:45:51 2004
Subject: [Rd] using "= matrix (...)" in .C calls
Message-ID: <OFA53FF1DF.EBC14134-ON85256EB6.0052F4B7-85256EB6.00569613@EU.novartis.net>

Dear R-devel,

I am trying to alter rpart so that it makes additional calculations when 
growing the tree. 

In the "rpart.s" there is a call to the C routine:

     rp    <- .C("s_to_rp2",
                       as.integer(nobs),
                       as.integer(nsplit),
                       as.integer(nodes),
                       as.integer(ncat),
                       as.integer(cats *!isord),
                       as.integer(max(cats)),
                       as.integer(xval),
                       which = integer(nobs),
                       cptable = matrix(double(numcp*cpcol), nrow=cpcol),
                       dsplit =  matrix(double(1),  nsplit,3),
                       isplit =  matrix(integer(1), nsplit,3),
                       csplit =  catmat,
                       dnode  =  matrix(double(1),  nodes, 3+numresp),
                       inode  =  matrix(integer(1), nodes, 6),
                       PACKAGE = "rpart")

Which in communicates with the C code in  "s_to_rp.c"

void s_to_rp2(Sint *n,         Sint *nsplit,    Sint *nnode,     Sint 
*ncat, 
              Sint *numcat,    Sint *maxcat,    Sint *xvals,     Sint 
*which, 
              double *cptable, double *dsplit,  Sint *isplit,    Sint 
*csplit,
              double *dnode,   Sint *inode)


Apparently the lines like:

        dsplit =  matrix(double(1),  nsplit,3),

Cause C arrays to be pulled over into an R matrix. However I can't figure 
out the syntax from context nor can I find documentation.

I have an array which was created and exists in the "C" part of the code, 
but I can not figure out how to pull it over to the "R" side.

The array was ALLOCed as 1-D array (of size nodes * variables), and 
ultimately I would like to get into matrix of nodes * variables.

Any help or advice would be appreciated.

thanks in advance,

Clayton
 
	[[alternative HTML version deleted]]

From tplate at blackmesacapital.com  Thu Jun 17 18:38:33 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Thu Jun 17 18:38:49 2004
Subject: [Rd] using "= matrix (...)" in .C calls
In-Reply-To: <OFA53FF1DF.EBC14134-ON85256EB6.0052F4B7-85256EB6.00569613@
	EU.novartis.net>
References: <OFA53FF1DF.EBC14134-ON85256EB6.0052F4B7-85256EB6.00569613@EU.novartis.net>
Message-ID: <6.1.0.6.2.20040617103352.0cf67ec0@mailhost.blackmesacapital.com>

Try looking at subsection "4.2 Interface functions .C and .Fortran" in the 
manual "Writing R Extensions".  (hint: it's done in a simple way that 
should be obvious after you've read this.)  You're far more likely to get a 
helpful answer if you indicate in your posting that you've read this and 
indicate how it did not answer the questions you have.  Also, this type of 
basic question is more appropriate for R-help, not R-devel.

hope this helps,

Tony Plate


At Thursday 09:43 AM 6/17/2004, you wrote:
>Dear R-devel,
>
>I am trying to alter rpart so that it makes additional calculations when
>growing the tree.
>
>In the "rpart.s" there is a call to the C routine:
>
>      rp    <- .C("s_to_rp2",
>                        as.integer(nobs),
>                        as.integer(nsplit),
>                        as.integer(nodes),
>                        as.integer(ncat),
>                        as.integer(cats *!isord),
>                        as.integer(max(cats)),
>                        as.integer(xval),
>                        which = integer(nobs),
>                        cptable = matrix(double(numcp*cpcol), nrow=cpcol),
>                        dsplit =  matrix(double(1),  nsplit,3),
>                        isplit =  matrix(integer(1), nsplit,3),
>                        csplit =  catmat,
>                        dnode  =  matrix(double(1),  nodes, 3+numresp),
>                        inode  =  matrix(integer(1), nodes, 6),
>                        PACKAGE = "rpart")
>
>Which in communicates with the C code in  "s_to_rp.c"
>
>void s_to_rp2(Sint *n,         Sint *nsplit,    Sint *nnode,     Sint
>*ncat,
>               Sint *numcat,    Sint *maxcat,    Sint *xvals,     Sint
>*which,
>               double *cptable, double *dsplit,  Sint *isplit,    Sint
>*csplit,
>               double *dnode,   Sint *inode)
>
>
>Apparently the lines like:
>
>         dsplit =  matrix(double(1),  nsplit,3),
>
>Cause C arrays to be pulled over into an R matrix. However I can't figure
>out the syntax from context nor can I find documentation.
>
>I have an array which was created and exists in the "C" part of the code,
>but I can not figure out how to pull it over to the "R" side.
>
>The array was ALLOCed as 1-D array (of size nodes * variables), and
>ultimately I would like to get into matrix of nodes * variables.
>
>Any help or advice would be appreciated.
>
>thanks in advance,
>
>Clayton
>
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From p.dalgaard at biostat.ku.dk  Thu Jun 17 18:39:22 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu Jun 17 18:39:25 2004
Subject: [Rd] using "= matrix (...)" in .C calls
In-Reply-To: <OFA53FF1DF.EBC14134-ON85256EB6.0052F4B7-85256EB6.00569613@EU.novartis.net>
References: <OFA53FF1DF.EBC14134-ON85256EB6.0052F4B7-85256EB6.00569613@EU.novartis.net>
Message-ID: <x2r7sew345.fsf@biostat.ku.dk>

clayton.springer@pharma.novartis.com writes:

> Apparently the lines like:
> 
>         dsplit =  matrix(double(1),  nsplit,3),
> 
> Cause C arrays to be pulled over into an R matrix. However I can't figure 
> out the syntax from context nor can I find documentation.

Actually no. It *creates* an R matrix (nsplit x 3) and then passes the
block of numeric data as a 1d array of nsplit. Coming back from C this
will still be an R matrix but possibly with new values inside.
help(matrix) should tell you the details. The double(1) is really just
a silly way of writing 0.0 (it specifies a double precision vector of
length 1, and the value will default to 0); matrix() will
automagically replicate it to fill the matrix.
 
> I have an array which was created and exists in the "C" part of the code, 
> but I can not figure out how to pull it over to the "R" side.
> 
> The array was ALLOCed as 1-D array (of size nodes * variables), and 
> ultimately I would like to get into matrix of nodes * variables.
> 
> Any help or advice would be appreciated.

You cannot pull, only push, when dealing with .C (I suspect that's not
quite true but it's a close approximation). The canonical way is to
dimension the array on the R side and pass it as an argument to the C
side.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Thu Jun 17 18:50:25 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu Jun 17 18:50:32 2004
Subject: [Rd] using "= matrix (...)" in .C calls
In-Reply-To: <6.1.0.6.2.20040617103352.0cf67ec0@mailhost.blackmesacapital.com>
References: <OFA53FF1DF.EBC14134-ON85256EB6.0052F4B7-85256EB6.00569613@EU.novartis.net>
	<6.1.0.6.2.20040617103352.0cf67ec0@mailhost.blackmesacapital.com>
Message-ID: <x2n032w2lq.fsf@biostat.ku.dk>

Tony Plate <tplate@blackmesacapital.com> writes:

>        Also, this type of basic question is more appropriate for
> R-help, not R-devel.

Hmm. No. 

(1) This list is for developers, and they can be beginners too. On
    r-help we cannot even assume that people know that C is a
    programming language.

(2) The author of rpart() had been using a couple of nifty but
    unorthodox tricks that it is not unreasonable for beginners to be
    confused by.

(not disagreeing that reading the documentation is generally a good
idea, of course!)

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From w.huber at dkfz-heidelberg.de  Thu Jun 17 18:54:47 2004
From: w.huber at dkfz-heidelberg.de (Wolfgang Huber)
Date: Thu Jun 17 18:54:54 2004
Subject: [Rd] is.integer() (PR#6984)
In-Reply-To: <20040616144549.6AE271057A@slim.kubism.ku.dk>
References: <20040616144549.6AE271057A@slim.kubism.ku.dk>
Message-ID: <40D1CCD7.2080209@dkfz-heidelberg.de>

Hi Marcio,

it's not a bug, it's a well-documented feature. In the S language, 
numeric literals are floating point by default.

 > mode(9)
[1] "numeric"
 > is.integer(9)
[1] FALSE
 > is.integer(as.integer(9))
[1] TRUE

Best wishes
  Wolfgang


-- 
-------------------------------------
Wolfgang Huber
Division of Molecular Genome Analysis
German Cancer Research Center
Heidelberg, Germany
Phone: +49 6221 424709
Fax:   +49 6221 42524709
Http:  www.dkfz.de/abt0840/whuber
-------------------------------------


mmr@tci.ufal.br wrote:
> Hello!
> 
> I'm not sure if is it a BUG or not...
> I'm using R 1.9.0, and I used the command below:
> 
> 
>>is.integer(9)
> 
> [1] FALSE
> 
> R manual contains this words about the is.integer() function:
> 
> "is.integer returns TRUE or FALSE depending on whether its argument is of 
> integer type or not."
> 
> What's the problem? Am I wrong about the BUG report?
> 
> Thank you very much.
> 
> M?rcio de Medeiros Ribeiro
> Graduando em Ci?ncia da Computa??o
> Departamento de Tecnologia da Informa??o - TCI
> Universidade Federal de Alagoas - UFAL
> Macei? - Alagoas - Brasil
> Projeto CoCADa

From tplate at blackmesacapital.com  Thu Jun 17 19:05:19 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Thu Jun 17 19:05:30 2004
Subject: [Rd] using "= matrix (...)" in .C calls
In-Reply-To: <x2n032w2lq.fsf@biostat.ku.dk>
References: <OFA53FF1DF.EBC14134-ON85256EB6.0052F4B7-85256EB6.00569613@EU.novartis.net>
	<6.1.0.6.2.20040617103352.0cf67ec0@mailhost.blackmesacapital.com>
	<x2n032w2lq.fsf@biostat.ku.dk>
Message-ID: <6.1.0.6.2.20040617110323.0cf68ea8@mailhost.blackmesacapital.com>

OK, thanks for the correction!

cheers,

Tony Plate

At Thursday 10:50 AM 6/17/2004, Peter Dalgaard wrote:
>Tony Plate <tplate@blackmesacapital.com> writes:
>
> >        Also, this type of basic question is more appropriate for
> > R-help, not R-devel.
>
>Hmm. No.
>
>(1) This list is for developers, and they can be beginners too. On
>     r-help we cannot even assume that people know that C is a
>     programming language.
>
>(2) The author of rpart() had been using a couple of nifty but
>     unorthodox tricks that it is not unreasonable for beginners to be
>     confused by.
>
>(not disagreeing that reading the documentation is generally a good
>idea, of course!)
>
>         -p
>
>--
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
>~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Thu Jun 17 19:18:17 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jun 17 19:18:26 2004
Subject: [Rd] using "= matrix (...)" in .C calls
In-Reply-To: <x2r7sew345.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0406171814310.20880-100000@gannet.stats>

It is worth noting that anyone writing rpart today (or in the last 5 
years) would have used .Call and allocated in C code.  But rpart goes back 
much further than that.  Further, had it been written for S-PLUS's .Call, 
it might never have got ported to R (and certainly not when it was).

On 17 Jun 2004, Peter Dalgaard wrote:

> clayton.springer@pharma.novartis.com writes:
> 
> > Apparently the lines like:
> > 
> >         dsplit =  matrix(double(1),  nsplit,3),
> > 
> > Cause C arrays to be pulled over into an R matrix. However I can't figure 
> > out the syntax from context nor can I find documentation.
> 
> Actually no. It *creates* an R matrix (nsplit x 3) and then passes the
> block of numeric data as a 1d array of nsplit. Coming back from C this
> will still be an R matrix but possibly with new values inside.
> help(matrix) should tell you the details. The double(1) is really just
> a silly way of writing 0.0 (it specifies a double precision vector of
> length 1, and the value will default to 0); matrix() will
> automagically replicate it to fill the matrix.
>  
> > I have an array which was created and exists in the "C" part of the code, 
> > but I can not figure out how to pull it over to the "R" side.
> > 
> > The array was ALLOCed as 1-D array (of size nodes * variables), and 
> > ultimately I would like to get into matrix of nodes * variables.
> > 
> > Any help or advice would be appreciated.
> 
> You cannot pull, only push, when dealing with .C (I suspect that's not
> quite true but it's a close approximation).  The canonical way is to
> dimension the array on the R side and pass it as an argument to the C
> side.

And with DUP=TRUE I don't think there is much choice.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Fri Jun 18 10:17:18 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Jun 18 10:17:20 2004
Subject: [Rd] R-devel and not R-help (was 'using "= matrix (...)" in .C
	calls')
In-Reply-To: <x2n032w2lq.fsf@biostat.ku.dk>
References: <OFA53FF1DF.EBC14134-ON85256EB6.0052F4B7-85256EB6.00569613@EU.novartis.net>
	<6.1.0.6.2.20040617103352.0cf67ec0@mailhost.blackmesacapital.com>
	<x2n032w2lq.fsf@biostat.ku.dk>
Message-ID: <16594.42254.680716.993405@gargle.gargle.HOWL>

>>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
>>>>>     on 17 Jun 2004 18:50:25 +0200 writes:

    PD> Tony Plate <tplate@blackmesacapital.com> writes:
    >> Also, this type of basic question is more appropriate for
    >> R-help, not R-devel.

    PD> Hmm. No. 

    PD> (1) This list is for developers, and they can be beginners too. On
    PD> r-help we cannot even assume that people know that C is a
    PD> programming language.

yes, yes, yes!
In general, I believe people should shift more topics from
R-help to R-devel, rather than the other way around.  Indeed,
lately we have been seeing too many things on R-help that should
have gone to R-devel instead.

A very good example being the thread started by Vadim Ogranovich
with subject "mkChar can be interrupted" (on Mon, 14 Jun 2004).
That has been utterly non-intelligible for probably more than
90% of the readers of R-help, and it may even have been the reason of
several "unsubscribe"rs (from R-help) that I as list maintainer
had seen happening +- subsequently.

I'd say, informed questions should go to R-devel in many cases
where .C() is involved and certainly in all cases where .Call()
is used.  Even though we (R core) would like to promote the use
of .Call() as much as possible, for most R users, programming in
C (or C++, Java, Fortran) is a big step, and learning to use
SEXP's is a much bigger step most (unfortunately) never take.

BTW: I'm glad for well formulated suggestions along the lines
     above to be added to http://www.r-project.org/mail.html
     and/or the posting guide

Regards,
Martin Maechler

From Matthias.Kohl at uni-bayreuth.de  Fri Jun 18 11:48:02 2004
From: Matthias.Kohl at uni-bayreuth.de (Matthias Kohl)
Date: Fri Jun 18 10:45:40 2004
Subject: [Rd] Problem with setValidity() or resetClass() or ... ?
Message-ID: <40D2BA52.30802@uni-bayreuth.de>

Hi,

I'm working with Version 1.9.0  (2004-04-12) on Windows 98/NT/2000 where 
I found the following wrong (?) behavior of setValidity().
I already mentioned this on the R-help list (2004-06-11, was 
"setValidity changes Extends?") , but as I got no answer I tried to 
figure out what's happening.

Well, setValidity() behaves not as I would expect (something about the 
superclasses is lost,
but nothing about the subclasses, see code below)
So, I did some debugging and it seems to be caused by resetClass() which 
calls completeClassDefinition() which calls ... (see the example code 
and the explanations below)

Unfortunately, I couldn't really figure out which of the called methods 
is doing the "wrong thing".

Would someone explain me this?

Best regards,
Matthias


##########################################
## Example code
##########################################
setClass("Class1", representation("name" = "character"))

if(!isGeneric("name")) setGeneric("name", function(object)
standardGeneric("name"))
setMethod("name", "Class1", function(object) object@name)

setClass("Class2", representation("Class1"))
setClass("Class3", representation("Class2"))
setClass("Class4", representation("Class3"))
setClass("Class5", representation("Class4"))

getClass("Class3") # as I expected

Class3Def <- getClassDef("Class3", where = topenv(parent.frame()))

## the following is called in setValidity() via resetClass()
## (further explanations, see below)
completeClassDefinition("Class3", Class3Def,
        where = topenv(parent.frame()), doExtends = TRUE)
## 'Extends' includs only "Class2"
##
## would give the right result *in this case*
completeClassDefinition("Class3", Class3Def,
        where = topenv(parent.frame()), doExtends = FALSE)
## (no call to completeExtends(), as doExtends = FALSE)
## probably no good idea

validClass3 <- function(object){TRUE}
setValidity("Class3", validClass3)
## nothing seems to be lost
## concerning the subclasses!

C3 <- new("Class3")
is(C3, "Class1") # o.k.
extends("Class3", "Class1") # o.k.

## But something gets lost
## concerning the superclasses!
name(C3) # generates an error!

## The subclasses work as expected
getClass("Class4") # o.k.
getClass("Class5") # o.k.
C4 <- new("Class4")
name(C4) # o.k.
C5 <- new("Class5")
name(C5) # o.k.

## Some debugging ...
##
## after the call of resetClass() in the setValidity() method
## the complete definition of the Class3 is (see: ?resetClass)
##      "(...) re-computed, from the representation
##      and superclasses specified in the original
##      call to 'setClass' (...)
##      (but doing that in the  middle of a session is living
##      dangerously, since it may invalidate existing objects)"
##      (seems to happen here)
##
## The original call to 'setClass' "finds" all
## superclasses, but resetClass() doesn't. Why?

## resetClass() calls completeClassDefinition() which
##      "Completes the definition of 'Class', relative to the
##      class definitions visible from environment 'where'. 
##      If 'doExtends' is 'TRUE', complete the super- and
##      sub-class information." (see: ?completeClassDefinition())
##      (the default value of 'doExtends' is TRUE)
##
## Shouldn't this give the *complete* class definition?

## completeClassDefinition() calls completeExtends() as
## 'doExtends = TRUE' (by default)
## Using debug(completeExtends) shows
## .uncompleteClassDefinition(ClassDef, "contains")
## is called. After this call "Extends" of ClassDef contains
## only 'Class2'
##
## Why is this necessary?
## In this step (I think) the information about
## 'Class1' is lost.
##
## The variable 'exts' which is involved in the calculations
## has length = 2 and would still contain the information
## that 'Class2' extends 'Class1'.
## But, then 'getAllSuperClasses(ClassDef)' is called which
## returns "only" 'Class2' (as already 'ClassDef' contains
## only 'Class2') and 'exts' is reduced to exts["Class2"]
## which is then returned.
##
## 'getAllSuperClasses(ClassDef)' calls 'superClassDepth()'
## which don't get "all" but only 'Class2'
## But, for me this seems to be right, since 'ClassDef'
## (in the call) contains only the information about 'Class2'.

From maechler at stat.math.ethz.ch  Fri Jun 18 11:08:10 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Jun 18 11:08:12 2004
Subject: [Rd] is.integer() (PR#6984)
In-Reply-To: <40D1CCD7.2080209@dkfz-heidelberg.de>
References: <20040616144549.6AE271057A@slim.kubism.ku.dk>
	<40D1CCD7.2080209@dkfz-heidelberg.de>
Message-ID: <16594.45306.798287.841013@gargle.gargle.HOWL>

       {removed R-bugs from CC; as we've seen it's not a bug at all}

>>>>> "Wolfi" == Wolfgang Huber <w.huber@dkfz-heidelberg.de>
>>>>>     on Thu, 17 Jun 2004 18:54:47 +0200 writes:

    Wolfi> Hi Marcio,
    Wolfi> it's not a bug, it's a well-documented feature. In the S language, 
    Wolfi> numeric literals are floating point by default.

that hasn't been true for quite a while now:
In S-plus since version 5.0, these literals *are* integer.

    > mode(9)
    [1] "numeric"

and the above doesn't tell you anything, since the mode() of an
integer is "numeric" in any case.
You'd need  storage.mode(9) [S and R] or  typeof(9) [R only] to get the
``low-level mode''.

    > is.integer(9)
    [1] FALSE
    > is.integer(as.integer(9))
    [1] TRUE

BTW, I've been using the  9:9  `acronym' instead of as.integer(9)
in cases where it enhances readability {e.g. in formulas}.
But note that really you shouldn't care in almost all
situations.

Regards,
Martin Maechler

    Wolfi> Best wishes
    Wolfi> Wolfgang

    Wolfi> mmr@tci.ufal.br wrote:
    >> Hello!
    >> 
    >> I'm not sure if is it a BUG or not...
    >> I'm using R 1.9.0, and I used the command below:
    >> 
    >> 
    >>> is.integer(9)
    >> 
    >> [1] FALSE
    >> 
    >> R manual contains this words about the is.integer() function:
    >> 
    >> "is.integer returns TRUE or FALSE depending on whether its argument is of 
    >> integer type or not."
    >> 
    >> What's the problem? Am I wrong about the BUG report?
    >> 
    >> Thank you very much.
    >> 
    >> M?rcio de Medeiros Ribeiro
    >> Graduando em Ci?ncia da Computa??o
    >> Departamento de Tecnologia da Informa??o - TCI
    >> Universidade Federal de Alagoas - UFAL
    >> Macei? - Alagoas - Brasil
    >> Projeto CoCADa

From lupi.claudio at fastwebnet.it  Fri Jun 18 16:00:32 2004
From: lupi.claudio at fastwebnet.it (Claudio Lupi)
Date: Fri Jun 18 16:00:40 2004
Subject: [Rd] x-table package
Message-ID: <40D2F580.2060004@fastwebnet.it>

 Dear Sirs,

 I would like to propose a (I believe) simple but useful enhancement to the xtable package.

 The latest version of the xtable package doesn't accept "H" as a 
 possible table.placement argument. Indeed, the "H" placement would be 
 very useful if one wanted to use the float latex package. I guess that 
 many users would be very happy of having this further possibility when 
 using xtable!
 Would it be possible to implement this change in a future version of  
 xtable?
 Thank you for your kind attention (and for having developed a very 
 useful package indeed!).

 Sincerely
 Claudio Lupi

From ligges at statistik.uni-dortmund.de  Fri Jun 18 16:38:08 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Jun 18 16:36:54 2004
Subject: [Rd] x-table package
In-Reply-To: <40D2F580.2060004@fastwebnet.it>
References: <40D2F580.2060004@fastwebnet.it>
Message-ID: <40D2FE50.1040502@statistik.uni-dortmund.de>

Claudio Lupi wrote:

> Dear Sirs,
> 
> I would like to propose a (I believe) simple but useful enhancement to 
> the xtable package.
> 
> The latest version of the xtable package doesn't accept "H" as a 
> possible table.placement argument. Indeed, the "H" placement would be 
> very useful if one wanted to use the float latex package. I guess that 
> many users would be very happy of having this further possibility when 
> using xtable!
> Would it be possible to implement this change in a future version of  
> xtable?

Proposals for enhancements / bugfixes of contributed packages are ought 
to be send to the package maintainer. In this case the maintainer is: 
David Dahl <dbdahl@stat.wisc.edu>

Uwe Ligges


> Thank you for your kind attention (and for having developed a very 
> useful package indeed!).
>
> Sincerely
> Claudio Lupi
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From dmurdoch at pair.com  Fri Jun 18 16:37:14 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri Jun 18 16:37:18 2004
Subject: [Rd] x-table package
In-Reply-To: <40D2F580.2060004@fastwebnet.it>
References: <40D2F580.2060004@fastwebnet.it>
Message-ID: <mav5d01obmbop9r8onlsvrv0s04li6aedf@4ax.com>

On Fri, 18 Jun 2004 16:00:32 +0200, Claudio Lupi
<lupi.claudio@fastwebnet.it> wrote :

> Dear Sirs,
>
> I would like to propose a (I believe) simple but useful enhancement to the xtable package.

Claudio:

Most R packages (except the base ones) are maintained by individuals
who are listed in the DESCRIPTION file.  You can see this if you type

 library(help=xtable)

which shows

Maintainer: David Dahl <dbdahl@stat.wisc.edu>

I don't know if David would see your message in r-devel; I've cc'd
this reply to him.  In general you should send package suggestions
directly to the maintainer, and it's even better if you work out how
to implement the change, and send that.

Duncan Murdoch
>
> The latest version of the xtable package doesn't accept "H" as a 
> possible table.placement argument. Indeed, the "H" placement would be 
> very useful if one wanted to use the float latex package. I guess that 
> many users would be very happy of having this further possibility when 
> using xtable!
> Would it be possible to implement this change in a future version of  
> xtable?
> Thank you for your kind attention (and for having developed a very 
> useful package indeed!).
>
> Sincerely
> Claudio Lupi
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Fri Jun 18 16:45:03 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jun 18 16:45:08 2004
Subject: [Rd] x-table package
In-Reply-To: <40D2FE50.1040502@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0406181541210.3866-100000@gannet.stats>

On Fri, 18 Jun 2004, Uwe Ligges wrote:

> Claudio Lupi wrote:
> 
> > I would like to propose a (I believe) simple but useful enhancement to 
> > the xtable package.
> > 
> > The latest version of the xtable package doesn't accept "H" as a 
> > possible table.placement argument. Indeed, the "H" placement would be 
> > very useful if one wanted to use the float latex package. I guess that 
> > many users would be very happy of having this further possibility when 
> > using xtable!
> > Would it be possible to implement this change in a future version of  
> > xtable?
> 
> Proposals for enhancements / bugfixes of contributed packages are ought 
> to be send to the package maintainer. In this case the maintainer is: 
> David Dahl <dbdahl@stat.wisc.edu>

BTW, this has already been sent to R-bugs yesterday (PR#6988) by the same
person from a different address and I have now closed the bug report (as
it is inappropriate for R-bugs which package authors do not read and
cannot close bugs on).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From joehl at gmx.de  Fri Jun 18 17:08:54 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Fri Jun 18 17:08:56 2004
Subject: [Rd] interpreter change from RW1.7 to RW1.8 reviewed at RW1.9
Message-ID: <6093.1087571334@www21.gmx.net>

Dear r-developers,

on January 23rd I reported on this list a dramatic performance loss of R1.8
compared to previous versions. As I did not receive any answer for this
important observation, I try again with some more recent results.

The slowdown happens when manipulating parts of objects in other
environments. This severely impedes Henrik Bengtsons oo extensions and usage
of my package ref. It would be great if it would be possible to recover the
great performance R had until version 1.7. Identifying or solving this
problem is far beyond my understanding of the interpreters internals, so
please forgive me just sending this report without offering any patches.

You find my test code below, in case you like to have a look on it. I would
appreciate your comments very much.

Best regards



Jens Oehlschl?gel


# This example shows the slowdown (where as.ref and deref are defined as
below)
nmatrix <- 1000
nloop <- 100
m <- matrix(nrow=nmatrix, ncol=nmatrix)
rm <- as.ref(m)
# the following is by order of magnitudes (factor 20 to 80) slower
# under R 1.8, R 1.9           (11.45 seconds)
# compared to R 1.7, 1.6, 1.5  ( 0.12 seconds)
system.time(
      for(i in 1:nloop)
        deref(rm)[1,1] <- i
)
# May be this helps finding the reason:
# You got the same slow behaviour under 1.7 if you turned
# deref() into method deref.ref() for a generic deref(ref,
value)UseMethod("deref")
# Under 1.8 every object has a class. Does that mean every function has
method dispatch under 1.8?
# If yes, can we bypass that by making deref() an internal function?


# What always works is using substitute directly,
# but this requires explicit programming of what the interpreter could do
automatically.
# I don't think it is possible to write deref() such that it takes care
about embedding subsetting.
# under R 1.8, R 1.9           (0.02 seconds)
# compared to R 1.7, 1.6, 1.5  (0.15 seconds)
system.time(
      for(i in 1:nloop)
        eval(substitute(m[1,1] <- i, list(i=i)), rm$loc)
)


# I also tried whether having deref use the the new 1.9.0 operators for
environments helps,
# but it doesn't
# under R 1.9           (8.84 seconds)
system.time(
      for(i in 1:nloop)
        deref2(rm)[1,1] <- i
)

# Again, coding with this 1.9.0 feature explicitely gives the real speed
# under R 1.9           (0.03 seconds)
system.time(
      for(i in 1:nloop)
        rm$loc[["m"]][1,1] <- i
)






# Function definitions

"deref2<-" <-
function(ref, value)
{
  ref$loc[[ref$name]] <- value
  ref
}

deref2 <-
function (ref)
{
    ref$loc[[ref$name]]
}



"deref<-" <-
function(ref, value)
{
  assign(ref$name, value, envir=ref$loc)
  ref
}

deref <-
function (ref)
{
    get(ref$name, envir = ref$loc)
}

ref <-
function (name, loc = parent.frame())
{
    temp <- list(name = name, loc = loc)
    class(temp) <- "ref"
    temp
}

as.ref <-
function (obj)
{
    obj.name <- substitute(obj)
    obj.loc <- parent.frame()
    if (!is.name(obj.name))
        stop("obj must be a named object")
    obj.name <- deparse(obj.name)
    if (is.ref(obj)) {
        obj
    }
    else {
        ref(obj.name, obj.loc)
    }
}

is.ref <- function(x)
{
  inherits(x, "ref")
}


-- 
+++ Jetzt WLAN-Router f?r alle DSL-Einsteiger und Wechsler +++
GMX DSL-Powertarife zudem 3 Monate gratis* http://www.gmx.net/dsl

From tplate at blackmesacapital.com  Fri Jun 18 17:24:19 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Fri Jun 18 17:24:33 2004
Subject: [Rd] Re: R-devel and not R-help (was 'using "= matrix (...)" in .C
 calls')
In-Reply-To: <16594.42254.680716.993405@gargle.gargle.HOWL>
References: <OFA53FF1DF.EBC14134-ON85256EB6.0052F4B7-85256EB6.00569613@EU.novartis.net>
	<6.1.0.6.2.20040617103352.0cf67ec0@mailhost.blackmesacapital.com>
	<x2n032w2lq.fsf@biostat.ku.dk>
	<16594.42254.680716.993405@gargle.gargle.HOWL>
Message-ID: <6.1.0.6.2.20040618091321.0cfcdcb8@mailhost.blackmesacapital.com>

Here are three suggested additions to the posting guide:  (the last two 
have been on my queue based on public and private suggestions of frequent 
contributors to R-help and R-devel)

[after the heading "Basic statistics and classroom homework"]

<p><b>Which list: R-help or R-devel?</b>There are two widely
used mailing list for questions and discussion about R.
R-devel is intended for questions and discussion about code
development in R.  Informed questions involving R
code, and most questions involving C, C++, etc code should
go to R-devel.  R-help is for more general questions.

[under "Do your homework"]

<li>If something seems to have changed in R, look in the
latest <a
href="http://cran.r-project.org/src/base/NEWS">NEWS</a> file
on CRAN for information about it.

[under "Technical details of posting"]

   <li>If you can't send from an email address that simply
accepts replies, then say so in your posting so that people
are not inconvenienced when they try to respond to your message

comments?

-- Tony Plate


At Friday 02:17 AM 6/18/2004, Martin Maechler wrote:
> >>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
> >>>>>     on 17 Jun 2004 18:50:25 +0200 writes:
>
>     PD> Tony Plate <tplate@blackmesacapital.com> writes:
>     >> Also, this type of basic question is more appropriate for
>     >> R-help, not R-devel.
>
>     PD> Hmm. No.
>
>     PD> (1) This list is for developers, and they can be beginners too. On
>     PD> r-help we cannot even assume that people know that C is a
>     PD> programming language.
>
>yes, yes, yes!
>In general, I believe people should shift more topics from
>R-help to R-devel, rather than the other way around.  Indeed,
>lately we have been seeing too many things on R-help that should
>have gone to R-devel instead.
>
>A very good example being the thread started by Vadim Ogranovich
>with subject "mkChar can be interrupted" (on Mon, 14 Jun 2004).
>That has been utterly non-intelligible for probably more than
>90% of the readers of R-help, and it may even have been the reason of
>several "unsubscribe"rs (from R-help) that I as list maintainer
>had seen happening +- subsequently.
>
>I'd say, informed questions should go to R-devel in many cases
>where .C() is involved and certainly in all cases where .Call()
>is used.  Even though we (R core) would like to promote the use
>of .Call() as much as possible, for most R users, programming in
>C (or C++, Java, Fortran) is a big step, and learning to use
>SEXP's is a much bigger step most (unfortunately) never take.
>
>BTW: I'm glad for well formulated suggestions along the lines
>      above to be added to http://www.r-project.org/mail.html
>      and/or the posting guide
>
>Regards,
>Martin Maechler

From tplate at blackmesacapital.com  Fri Jun 18 17:47:23 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Fri Jun 18 17:47:35 2004
Subject: [Rd] .C() vs .Call() (was Re: R-devel and not R-help (was 'using "=
 matrix (...)" in .C calls')
In-Reply-To: <16594.42254.680716.993405@gargle.gargle.HOWL>
References: <OFA53FF1DF.EBC14134-ON85256EB6.0052F4B7-85256EB6.00569613@EU.novartis.net>
	<6.1.0.6.2.20040617103352.0cf67ec0@mailhost.blackmesacapital.com>
	<x2n032w2lq.fsf@biostat.ku.dk>
	<16594.42254.680716.993405@gargle.gargle.HOWL>
Message-ID: <6.1.0.6.2.20040618092430.0cfd0bc0@mailhost.blackmesacapital.com>

At Friday 02:17 AM 6/18/2004, Martin Maechler wrote:

>[snip]  Even though we (R core) would like to promote the use
>of .Call() as much as possible, for most R users, [snip]

Why does "R core" wish to promote the use of .Call() over .C()?

I see two advantages for .C():

(1) The interface is very straightforward and I don't need to go to the 
trouble of using R macros and extractor functions in my C or C++ code in 
order to get at the data -- the data is just passed in C vectors of 
standard types, and I can return data the same way.  This means my C code 
is simpler and consequently (on average) more maintainable and less prone 
to bugs.  For example, consider the C functions 'convolve' (to be called by 
.C()) and 'convolve2' (to be called by .Call()) that are in "Writing R 
Extensions".  I am more confident that I can write correctly the R code for 
type checking and coercion needed for the .C() call than I can write 
correctly the corresponding C code (for example, because then I need to 
think about things like stack imbalances in my calls to PROTECT/UNPROTECT).

(2) .C() functions are easier to port between different implementations of 
the S language.

Am I missing advantages to using .Call() when .C() would suffice?  (i.e., 
when the data that must be passed back and forth can be easily packed into 
vectors.)

-- Tony Plate

From ripley at stats.ox.ac.uk  Fri Jun 18 17:56:51 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jun 18 17:56:55 2004
Subject: [Rd] .C() vs .Call() (was Re: R-devel and not R-help (was 'using
	"= matrix (...)" in .C calls')
In-Reply-To: <6.1.0.6.2.20040618092430.0cfd0bc0@mailhost.blackmesacapital.com>
Message-ID: <Pine.LNX.4.44.0406181650210.12547-100000@gannet.stats>

On Fri, 18 Jun 2004, Tony Plate wrote:

> At Friday 02:17 AM 6/18/2004, Martin Maechler wrote:
> 
> >[snip]  Even though we (R core) would like to promote the use
> >of .Call() as much as possible, for most R users, [snip]
> 
> Why does "R core" wish to promote the use of .Call() over .C()?
> 
> I see two advantages for .C():
> 
> (1) The interface is very straightforward and I don't need to go to the 
> trouble of using R macros and extractor functions in my C or C++ code in 
> order to get at the data -- the data is just passed in C vectors of 
> standard types, and I can return data the same way.  This means my C code 
> is simpler and consequently (on average) more maintainable and less prone 
> to bugs.  For example, consider the C functions 'convolve' (to be called by 
> .C()) and 'convolve2' (to be called by .Call()) that are in "Writing R 
> Extensions".  I am more confident that I can write correctly the R code for 
> type checking and coercion needed for the .C() call than I can write 
> correctly the corresponding C code (for example, because then I need to 
> think about things like stack imbalances in my calls to PROTECT/UNPROTECT).

That is a _very_ simple example.  In the original context (the main
function of rpart), I suspect the .Call equivalent would be much simpler,
and it would certainly be easier to maintain as the preallocation in the R
code is not needed.

> (2) .C() functions are easier to port between different implementations of 
> the S language.

Not necessarily true if the Rdefines macros are used.  In part true 
because the S4 internals are so sparsely documented, but there are some 
serious examples of code written for both systems.

> Am I missing advantages to using .Call() when .C() would suffice?  (i.e., 
> when the data that must be passed back and forth can be easily packed into 
> vectors.)

Many -

1) A lot less copying.

2) The ability to dimension the answer in the C code.

3) Access to other types, e.g. expressions, raw type and the ability to 
easily execute R code (call_R is a pain).

4) Access to the attributes of the vectors, for example the names.

5) The ability to handle missing values easily.

...

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From confirm-s2-cKJnluPx2m_RDWYSZvrl22gO5og-r-devel=lists.r-project.org at yahoogroupes.fr  Sat Jun 19 13:35:15 2004
From: confirm-s2-cKJnluPx2m_RDWYSZvrl22gO5og-r-devel=lists.r-project.org at yahoogroupes.fr (Yahoo! Groupes)
Date: Sat Jun 19 13:35:23 2004
Subject: [Rd] Demande de confirmation d'inscription =?iso-8859-1?q?=E0?=
	ORCULTURE
Message-ID: <1087644915.32.92235.m20@yahoogroupes.fr>


Bonjour,

Nous avons re?u votre demande d'inscription au groupe 
ORCULTURE sur Yahoo! Groupes, le nouveau service de
communaut?s de Yahoo!. Pour vous inscrire, vous devez confirmer votre
demande en r?pondant ? ce message.

Si vous n'avez pas demand? ou ne souhaitez pas vous inscrire au groupe
ORCULTURE, veuillez ignorer ce message.


Cordialement,

L'?quipe support Yahoo! Groupes 


L'utilisation du service Yahoo! Groupes est soumise ? l'acceptation des 
Conditions d'utilisation et de la Charte sur la vie priv?e, disponibles 
respectivement sur http://fr.docs.yahoo.com/info/utos.html et
http://fr.docs.yahoo.com/info/privacy.html

From simon.urbanek at math.uni-augsburg.de  Sun Jun 20 04:02:52 2004
From: simon.urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Sun Jun 20 04:02:55 2004
Subject: [Rd] Copyright issues question
In-Reply-To: <MABBLJDICACNFOLGIHJOGEKIEIAA.phgrosjean@sciviews.org>
References: <MABBLJDICACNFOLGIHJOGEKIEIAA.phgrosjean@sciviews.org>
Message-ID: <EFEC0BBC-C25D-11D8-B986-000A959F327E@math.uni-augsburg.de>

On Jun 16, 2004, at 12:08 PM, Philippe Grosjean wrote:

> P.S.: I am also concerned about JGR, because it is also not GPL. Any
> comment?

All C code in JGR is GPL. Tha Java parts talking to R directly (JavaGD, 
Rengine) are, too. From what you posted here this seems to be 
sufficient. As of the other Java code, well, that is a good question - 
I guess we have two purely practical reasons for not-GPLing it ATM: one 
is that we have to check whether we're allowed to do so and the other 
is that we still want to incorporate some major changes until the 
official release (I'm not that much worried about the GUI itself but 
the other parts). I'm sure the licensing issue will be sorted out 
before the official release.

A side note: with xGD and a slightly modifiied JRI it is possible to 
use *any* (incl. commercial) application with R as backend (as it's 
even now legally possible with Rserve), so I don't think this is an 
issue anyway (at least for JGR).

Cheers,
Simon

From acrux at enduro.zzn.com  Sun Jun 20 11:47:00 2004
From: acrux at enduro.zzn.com (acrux@enduro.zzn.com)
Date: Sun Jun 20 11:47:03 2004
Subject: [Rd] linux: compilation problems with gcc 3.3.3 and xorg (PR#6992)
Message-ID: <20040620094700.88ED3EAEA@slim.kubism.ku.dk>

Full_Name: acrux
Version: 1.9.0
OS: linux (Crux2.0)
Submission from: (NULL) (151.37.85.179)


info linux distro:
acrux@vesuvio:~$ crux
CRUX version 2.0
acrux@vesuvio:~$ uname -a
Linux vesuvio 2.6.7-ck1-vesuvio #1 Sat Jun 19 12:52:24 CEST 2004 i686 unknown
unknown GNU/Linux
acrux@vesuvio:~$ gcc --ver
Reading specs from /usr/lib/gcc-lib/i686-pc-linux-gnu/3.3.3/specs
Configured with: ../gcc-3.3.3/configure --prefix=/usr
--enable-languages=c,c++,objc,f77 --enable-threads=posix --enable-__cxa_atexit
--enable-clocale=gnu --enable-shared --disable-nls
Thread model: posix
gcc version 3.3.3 (CRUX)


problems during the source compilation, maybe X.org incompatibility:
make[4]: Entering directory `/root/ports/r/work/src/R-1.9.0/src/modules/X11'
/usr/bin/ccache-gcc -I. -I../../../src/include -I../../../src/include -I/usr/X11
     R6/include -I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES
-mieee-fp -f      PIC  -O3 -march=athlon-xp -pipe -fomit-frame-pointer -c
dataentry.c -o dataentry      .lo
In file included from dataentry.c:31:
/usr/X11R6/include/X11/Xlib.h:1400: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1488: error: parse error before "char"
/usr/X11R6/include/X11/Xlib.h:1516: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1520: error: parse error before "char"
/usr/X11R6/include/X11/Xlib.h:1542: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1577: error: parse error before '*' token
/usr/X11R6/include/X11/Xlib.h:1586: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1611: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1661: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1667: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1714: error: parse error before "char"
/usr/X11R6/include/X11/Xlib.h:1753: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1994: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2078: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2331: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2341: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2413: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2423: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2581: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2596: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2789: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2856: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2861: error: parse error before "char"
/usr/X11R6/include/X11/Xlib.h:2975: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3001: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3012: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3037: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3046: error: parse error before "char"
/usr/X11R6/include/X11/Xlib.h:3059: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3202: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3251: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3283: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3374: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3381: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3401: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3407: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3419: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3429: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3439: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3445: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3546: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3563: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3614: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3657: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3663: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3669: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3675: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3683: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3691: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3699: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3711: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3723: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3770: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3781: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3792: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3803: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3814: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3825: error: parse error before "_Xconst"
In file included from dataentry.c:32:
/usr/X11R6/include/X11/Xutil.h:566: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xutil.h:606: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xutil.h:666: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xutil.h:678: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xutil.h:801: error: parse error before "_Xconst"
dataentry.c: In function `GetKey':
dataentry.c:1272: warning: passing arg 4 of `XLookupString' from incompatible po
     inter type
dataentry.c: In function `GetCharP':
dataentry.c:1281: warning: passing arg 4 of `XLookupString' from incompatible po
     inter type
dataentry.c: In function `doControl':
dataentry.c:1302: warning: passing arg 4 of `XLookupString' from incompatible po
     inter type
make[4]: *** [dataentry.lo] Error 1
make[4]: Leaving directory `/root/ports/r/work/src/R-1.9.0/src/modules/X11'
make[3]: *** [R] Error 2
make[3]: Leaving directory `/root/ports/r/work/src/R-1.9.0/src/modules/X11'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/root/ports/r/work/src/R-1.9.0/src/modules'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/root/ports/r/work/src/R-1.9.0/src'
make: *** [R] Error 1
=======> ERROR: Building '/root/ports/r/r#1.9.0-2.pkg.tar.gz' failed.

From ripley at stats.ox.ac.uk  Sun Jun 20 12:09:24 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Jun 20 12:09:32 2004
Subject: (PR#6992)[Rd] linux: compilation problems with gcc 3.3.3 and xorg
In-Reply-To: <20040620094700.88ED3EAEA@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406201104110.6208-100000@gannet.stats>

This is a known bug in some distributions of XFree 4.4.0 (and not in R).

It is the same as PR#6805 and PR#6844 and PR#6855 and PR#6965 and has been
worked around in R-patched for a couple of months and in R-1.9.1 beta (due 
for release tomorrow).

Please report the bug to the supplier of your Linux distro.

On Sun, 20 Jun 2004 acrux@enduro.zzn.com wrote:

> Full_Name: acrux
> Version: 1.9.0
> OS: linux (Crux2.0)
> Submission from: (NULL) (151.37.85.179)
> 
> 
> info linux distro:
> acrux@vesuvio:~$ crux
> CRUX version 2.0
> acrux@vesuvio:~$ uname -a
> Linux vesuvio 2.6.7-ck1-vesuvio #1 Sat Jun 19 12:52:24 CEST 2004 i686 unknown
> unknown GNU/Linux
> acrux@vesuvio:~$ gcc --ver
> Reading specs from /usr/lib/gcc-lib/i686-pc-linux-gnu/3.3.3/specs
> Configured with: ../gcc-3.3.3/configure --prefix=/usr
> --enable-languages=c,c++,objc,f77 --enable-threads=posix --enable-__cxa_atexit
> --enable-clocale=gnu --enable-shared --disable-nls
> Thread model: posix
> gcc version 3.3.3 (CRUX)
> 
> 
> problems during the source compilation, maybe X.org incompatibility:
> make[4]: Entering directory `/root/ports/r/work/src/R-1.9.0/src/modules/X11'
> /usr/bin/ccache-gcc -I. -I../../../src/include -I../../../src/include -I/usr/X11
>      R6/include -I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES
> -mieee-fp -f      PIC  -O3 -march=athlon-xp -pipe -fomit-frame-pointer -c
> dataentry.c -o dataentry      .lo
> In file included from dataentry.c:31:
> /usr/X11R6/include/X11/Xlib.h:1400: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1488: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:1516: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1520: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:1542: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1577: error: parse error before '*' token
> /usr/X11R6/include/X11/Xlib.h:1586: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1611: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1661: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1667: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1714: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:1753: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1994: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2078: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2331: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2341: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2413: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2423: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2581: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2596: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2789: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2856: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2861: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:2975: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3001: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3012: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3037: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3046: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:3059: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3202: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3251: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3283: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3374: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3381: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3401: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3407: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3419: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3429: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3439: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3445: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3546: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3563: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3614: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3657: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3663: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3669: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3675: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3683: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3691: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3699: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3711: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3723: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3770: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3781: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3792: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3803: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3814: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3825: error: parse error before "_Xconst"
> In file included from dataentry.c:32:
> /usr/X11R6/include/X11/Xutil.h:566: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xutil.h:606: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xutil.h:666: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xutil.h:678: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xutil.h:801: error: parse error before "_Xconst"
> dataentry.c: In function `GetKey':
> dataentry.c:1272: warning: passing arg 4 of `XLookupString' from incompatible po
>      inter type
> dataentry.c: In function `GetCharP':
> dataentry.c:1281: warning: passing arg 4 of `XLookupString' from incompatible po
>      inter type
> dataentry.c: In function `doControl':
> dataentry.c:1302: warning: passing arg 4 of `XLookupString' from incompatible po
>      inter type
> make[4]: *** [dataentry.lo] Error 1
> make[4]: Leaving directory `/root/ports/r/work/src/R-1.9.0/src/modules/X11'
> make[3]: *** [R] Error 2
> make[3]: Leaving directory `/root/ports/r/work/src/R-1.9.0/src/modules/X11'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/root/ports/r/work/src/R-1.9.0/src/modules'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/root/ports/r/work/src/R-1.9.0/src'
> make: *** [R] Error 1
> =======> ERROR: Building '/root/ports/r/r#1.9.0-2.pkg.tar.gz' failed.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From saurin_jani at yahoo.com  Sun Jun 20 22:18:47 2004
From: saurin_jani at yahoo.com (SAURIN)
Date: Sun Jun 20 22:19:05 2004
Subject: [Rd] regarding saving R graphis images directly to directory
Message-ID: <20040620201847.75508.qmail@web41107.mail.yahoo.com>

Dear R,

I am student at University of new haven, CT.I am trying to run my R scripts where I don't have
X11() authentication to my account. I run those R scripts and when I generate any graphics I get
error and it comes out from system. 

if possible , please let me know how can i run R scripts ...so, that I just SAVE BOX PLOT or
HISTOGRAM jpeg or png files to current directory without poping up on screen or without using any
devices or make them silent..or something.


Thakn you,
Saurin Jnai

From edd at debian.org  Sun Jun 20 22:59:38 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun Jun 20 22:59:40 2004
Subject: [Rd] regarding saving R graphis images directly to directory
In-Reply-To: <20040620201847.75508.qmail@web41107.mail.yahoo.com>
References: <20040620201847.75508.qmail@web41107.mail.yahoo.com>
Message-ID: <20040620205938.GA10384@sonny.eddelbuettel.com>

On Sun, Jun 20, 2004 at 01:18:47PM -0700, SAURIN wrote:
> Dear R,
> 
> I am student at University of new haven, CT.I am trying to run my R scripts where I don't have
> X11() authentication to my account. I run those R scripts and when I generate any graphics I get
> error and it comes out from system. 
> 
> if possible , please let me know how can i run R scripts ...so, that I just SAVE BOX PLOT or
> HISTOGRAM jpeg or png files to current directory without poping up on screen or without using any
> devices or make them silent..or something.

Use either a 'virtual' X11 display (such as the xvfb server) to provide a
X11 display even though you don't have a terminal, or the bitmap() device,
which needs ghostscript installed.

Hth, Dirk

-- 
FEATURE:  VW Beetle license plate in California

From vograno at evafunds.com  Mon Jun 21 00:22:41 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Mon Jun 21 00:23:02 2004
Subject: [Rd] regarding saving R graphis images directly to directory
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A5568990@phost015.EVAFUNDS.intermedia.net>

If you just need to ignore the errors use try or tryCatch around the
plotting functions.

Re: jpeg and friends. R has a notion of current device where it sends
all its graphics. If none is open R opens the default device for you,
which happens to be X11 on your system. To use a different device just
open it, say jpeg, and all graphics will go there until you close it or
open yet another device. For the list of available devices see ?Devices

It might be useful to have a null device which just silently ignores all
graphics (aka /dev/null on UNIX), but I don't know if R has anything
like this.


P.S. This sort of questions looks more appropriate for r-help. Just
personal sensing, I am no master of polices.

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of SAURIN
> Sent: Sunday, June 20, 2004 1:19 PM
> To: r-devel@stat.math.ethz.ch
> Subject: [Rd] regarding saving R graphis images directly to directory
> 
> Dear R,
> 
> I am student at University of new haven, CT.I am trying to 
> run my R scripts where I don't have
> X11() authentication to my account. I run those R scripts and 
> when I generate any graphics I get error and it comes out 
> from system. 
> 
> if possible , please let me know how can i run R scripts 
> ...so, that I just SAVE BOX PLOT or HISTOGRAM jpeg or png 
> files to current directory without poping up on screen or 
> without using any devices or make them silent..or something.
> 
> 
> Thakn you,
> Saurin Jnai
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
>

From tlumley at u.washington.edu  Mon Jun 21 01:03:26 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Jun 21 01:03:35 2004
Subject: [Rd] regarding saving R graphis images directly to directory
In-Reply-To: <20040620205938.GA10384@sonny.eddelbuettel.com>
References: <20040620201847.75508.qmail@web41107.mail.yahoo.com>
	<20040620205938.GA10384@sonny.eddelbuettel.com>
Message-ID: <Pine.A41.4.58.0406201602270.11050@homer04.u.washington.edu>

On Sun, 20 Jun 2004, Dirk Eddelbuettel wrote:

> On Sun, Jun 20, 2004 at 01:18:47PM -0700, SAURIN wrote:
> > Dear R,
> >
> > I am student at University of new haven, CT.I am trying to run my R scripts where I don't have
> > X11() authentication to my account. I run those R scripts and when I generate any graphics I get
> > error and it comes out from system.
> >
> > if possible , please let me know how can i run R scripts ...so, that I just SAVE BOX PLOT or
> > HISTOGRAM jpeg or png files to current directory without poping up on screen or without using any
> > devices or make them silent..or something.
>
> Use either a 'virtual' X11 display (such as the xvfb server) to provide a
> X11 display even though you don't have a terminal, or the bitmap() device,
> which needs ghostscript installed.
>

Or use pdf() to make PDF files.

	-thomas

From saurin_jani at yahoo.com  Mon Jun 21 01:26:32 2004
From: saurin_jani at yahoo.com (SAURIN)
Date: Mon Jun 21 01:26:37 2004
Subject: [Rd] BATCH: line 55:  5681 Broken pipe     cat ${in}
Message-ID: <20040620232632.10395.qmail@web41103.mail.yahoo.com>

Dear Bioconductor,

I am running R non interactively from command line on my lunux AMD 64 remotely. My R scripts
analyze data and generates lots of jpeg files and puts in to directory. so,I am running below
command:

R CMD BATCH Saurin_Script1.R

/usr/local/lib/R/bin/BATCH: line 55:  5681 Broken pipe        cat ${in}

I get above error??



plz..let me know, if any one had encounterd this one or knows how to solve this..!!


have a great day,
Saurin Jani

From nobody at pgp.com  Mon Jun 21 04:42:21 2004
From: nobody at pgp.com (nobody@pgp.com)
Date: Mon Jun 21 04:42:26 2004
Subject: [Rd] Your message was flagged as possible spam (PR#6996)
Message-ID: <20040621024221.6C4D4EAC0@slim.kubism.ku.dk>

This is a multi-part message in MIME format...

------------=_1087785732-11892-7
Content-Type: text/plain; charset="iso-8859-1"
Content-Disposition: inline
Content-Transfer-Encoding: 7bit


********************************
IMPORTANT: This informational message was sent from an unattended mailbox.  Do not respond directly to this message.  Please read it in its entirety for ways you can contact the mail administrators.
********************************
 
Your message: 
     Does it matter? 

has been flagged as possible spam by our filtering software and might not have been delivered to:
     pgpsupport@pgp.com

If you believe you have received this message in error, and would like to resend your message immediately, please either: 

1) use the following report to resend a message that will not be seen by our system as possible spam
	
or

2) add the following text, on a separate line, in the body of your message:

filter_passthrough 

You may also be added to our list of senders who may bypass our spam filters.  To request this, please forward a copy of this message to spam_admin@pgp.com and we will add you to our whitelist (process takes up to 24 hours).

We sincerely apologize for any inconvenience this may have caused,

Postmaster

********************************
IMPORTANT: This informational message was sent from an unattended mailbox.  Do not respond directly to this message.  Please read it in its entirety for ways you can contact the mail administrators.
********************************
 
Your message: 
SPAM Assessment:
Spam detection software, running on the system "garfish-1.pgp.com", has
identified this incoming email as possible spam.  The original message
has been attached to this so you can view it (if it isn't spam) or block
similar future email.  If you have any questions, see
postmaster@pgp.com for details.

Content preview:  You have written a very good text, excellent, good
  work! +++ Attachment: No Virus found +++ MC-Afee AntiVirus -
  www.mcafee.com [...] 

Content analysis details:   (15.6 points, 5.0 required)

 pts rule name              description
---- ---------------------- --------------------------------------------------
 0.2 NO_REAL_NAME           From: does not include a real name
 2.3 BAYES_70               BODY: Bayesian spam probability is 70 to 80%
                            [score: 0.7713]
 1.1 RAZOR2_CF_RANGE_51_100 BODY: Razor2 gives confidence between 51 and 100
                            [cf: 100]
 0.1 MICROSOFT_EXECUTABLE   RAW: Message includes Microsoft executable program
 2.6 RAZOR2_CHECK           Listed in Razor2 (http://razor.sf.net/)
 3.6 DCC_CHECK              Listed in DCC (http://rhyolite.com/anti-spam/dcc/)
 0.8 MSGID_FROM_MTA_BACKUP  Message-Id was added by a relay
 1.6 NO_DNS_FOR_FROM        Domain in From header has no MX or A DNS records
 1.6 MISSING_MIMEOLE        Message has X-MSMail-Priority, but no X-MimeOLE
 0.5 MIME_BOUND_NEXTPART    Spam tool pattern in MIME boundary
 1.2 PRIORITY_NO_NAME       Message has priority setting, but no X-Mailer



------------=_1087785732-11892-7
Content-Type: message/delivery-status
Content-Disposition: inline
Content-Transfer-Encoding: 7bit
Content-Description: Delivery error report

Reporting-MTA: dns; garfish-1.pgp.com
Received-From-MTA: smtp; mta3.pgp.com ([10.216.2.26])
Arrival-Date: Sun, 20 Jun 2004 19:42:05 -0700 (PDT)

Final-Recipient: rfc822; pgpsupport@pgp.com
Action: failed
Status: 5.7.1
Diagnostic-Code: smtp; 550 5.7.1 Message content rejected, UBE, id=11892-04
Last-Attempt-Date: Sun, 20 Jun 2004 19:42:12 -0700 (PDT)

------------=_1087785732-11892-7
Content-Type: text/rfc822-headers
Content-Disposition: inline
Content-Transfer-Encoding: 7bit
Content-Description: Undelivered-message headers

Received: from pgp.com (level-3-left-173.newcastle.edu.au [134.148.197.173])
	by mta3.pgp.com (Postfix) with SMTP id 0B474A8B0
	for <pgpsupport@pgp.com>; Sun, 20 Jun 2004 19:42:04 -0700 (PDT)
From: "r-bugs@r-project.org"@mta3.pgp.com
To: pgpsupport@pgp.com
Subject: Does it matter?
Date: Mon, 21 Jun 2004 12:41:03 +1000
MIME-Version: 1.0
Content-Type: multipart/mixed;
	boundary="----=_NextPart_000_0016----=_NextPart_000_0016"
X-Priority: 3
X-MSMail-Priority: Normal
Message-Id: <20040621024204.0B474A8B0@mta3.pgp.com>

------------=_1087785732-11892-7--

From phgrosjean at sciviews.org  Mon Jun 21 11:35:23 2004
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Mon Jun 21 11:36:03 2004
Subject: [Rd] Copyright issues question
In-Reply-To: <EFEC0BBC-C25D-11D8-B986-000A959F327E@math.uni-augsburg.de>
Message-ID: <MABBLJDICACNFOLGIHJOEEPHEIAA.phgrosjean@sciviews.org>

OK, thank you for those precisions on JGR license... For me, the more code
will be GPL, the better!
Have a nice day,

Philippe

-----Original Message-----
From: Simon Urbanek [mailto:simon.urbanek@math.uni-augsburg.de]
Sent: Sunday, 20 June, 2004 04:03
To: Philippe Grosjean
Cc: R-devel@stat.math.ethz.chr-devel@stat.math.ethz.ch
Subject: Re: [Rd] Copyright issues question


On Jun 16, 2004, at 12:08 PM, Philippe Grosjean wrote:

> P.S.: I am also concerned about JGR, because it is also not GPL. Any
> comment?

All C code in JGR is GPL. Tha Java parts talking to R directly (JavaGD,
Rengine) are, too. From what you posted here this seems to be
sufficient. As of the other Java code, well, that is a good question -
I guess we have two purely practical reasons for not-GPLing it ATM: one
is that we have to check whether we're allowed to do so and the other
is that we still want to incorporate some major changes until the
official release (I'm not that much worried about the GUI itself but
the other parts). I'm sure the licensing issue will be sorted out
before the official release.

A side note: with xGD and a slightly modifiied JRI it is possible to
use *any* (incl. commercial) application with R as backend (as it's
even now legally possible with Rserve), so I don't think this is an
issue anyway (at least for JGR).

Cheers,
Simon

From maechler at stat.math.ethz.ch  Mon Jun 21 12:16:38 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Jun 21 12:16:40 2004
Subject: [Rd] regarding saving R graphis images directly to directory
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A5568990@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A5568990@phost015.EVAFUNDS.intermedia.net>
Message-ID: <16598.46470.330452.580369@gargle.gargle.HOWL>

>>>>> "Vadim" == Vadim Ogranovich <vograno@evafunds.com>
>>>>>     on Sun, 20 Jun 2004 15:22:41 -0700 writes:

    Vadim> If you just need to ignore the errors use try or tryCatch around the
    Vadim> plotting functions.

    Vadim> Re: jpeg and friends. R has a notion of current
    Vadim> device where it sends all its graphics. If none is
    Vadim> open R opens the default device for you, which
    Vadim> happens to be X11 on your system. To use a different
    Vadim> device just open it, say jpeg, and all graphics will
    Vadim> go there until you close it or open yet another
    Vadim> device. For the list of available devices see
    Vadim> ?Devices

    Vadim> It might be useful to have a null device which just
    Vadim> silently ignores all graphics (aka /dev/null on
    Vadim> UNIX), but I don't know if R has anything like this.


    Vadim> P.S. This sort of questions looks more appropriate for r-help. Just
    Vadim> personal sensing, I am no master of polices.

but you are very right, Vadim.  
Saurin's question would have been appropriate only for R-help.

OTOH, your "P.S." above --- being a proposal for enhancing R ---
does well fit into R-devel.

I agree that it would be nice to have a
  nullDev() or dev.null()
graphics device which would efficiently discard all "plotting to
devices" graphics.  
Note however that it should *not* discard the building of GROBs
(graphical objects) [grid package], i.e. it would construct all
these also for all lattice (or nlme) graphics.  It would just
trash discard when grob's are being 'printed' (i.e. plotted).

A -- quite inefficient -- but easy way on Unix-alikes
{i.e. everwhere but Windows}, 
would be to call, e.g.,   postscript(file = "/dev/null")
I assume there's something equivalent on modern Windows (?)

Martin

From ligges at statistik.uni-dortmund.de  Mon Jun 21 13:00:45 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Jun 21 13:00:40 2004
Subject: [Rd] regarding saving R graphis images directly to directory
In-Reply-To: <16598.46470.330452.580369@gargle.gargle.HOWL>
References: <C698D707214E6F4AB39AB7096C3DE5A5568990@phost015.EVAFUNDS.intermedia.net>
	<16598.46470.330452.580369@gargle.gargle.HOWL>
Message-ID: <40D6BFDD.70509@statistik.uni-dortmund.de>

Martin Maechler wrote:

>>>>>>"Vadim" == Vadim Ogranovich <vograno@evafunds.com>
>>>>>>    on Sun, 20 Jun 2004 15:22:41 -0700 writes:
> 
> 
>     Vadim> If you just need to ignore the errors use try or tryCatch around the
>     Vadim> plotting functions.
> 
>     Vadim> Re: jpeg and friends. R has a notion of current
>     Vadim> device where it sends all its graphics. If none is
>     Vadim> open R opens the default device for you, which
>     Vadim> happens to be X11 on your system. To use a different
>     Vadim> device just open it, say jpeg, and all graphics will
>     Vadim> go there until you close it or open yet another
>     Vadim> device. For the list of available devices see
>     Vadim> ?Devices
> 
>     Vadim> It might be useful to have a null device which just
>     Vadim> silently ignores all graphics (aka /dev/null on
>     Vadim> UNIX), but I don't know if R has anything like this.
> 
> 
>     Vadim> P.S. This sort of questions looks more appropriate for r-help. Just
>     Vadim> personal sensing, I am no master of polices.
> 
> but you are very right, Vadim.  
> Saurin's question would have been appropriate only for R-help.
> 
> OTOH, your "P.S." above --- being a proposal for enhancing R ---
> does well fit into R-devel.
> 
> I agree that it would be nice to have a
>   nullDev() or dev.null()
> graphics device which would efficiently discard all "plotting to
> devices" graphics.  
> Note however that it should *not* discard the building of GROBs
> (graphical objects) [grid package], i.e. it would construct all
> these also for all lattice (or nlme) graphics.  It would just
> trash discard when grob's are being 'printed' (i.e. plotted).
> 
> A -- quite inefficient -- but easy way on Unix-alikes
> {i.e. everwhere but Windows}, 
> would be to call, e.g.,   postscript(file = "/dev/null")
> I assume there's something equivalent on modern Windows (?)

Martin, indeed, it's there since the days of DOS:

   postscript(file = "NUL")

hence even understood by my 8 year old OS Windows NT 4.0 ... ;-)

Uwe

From ligges at statistik.uni-dortmund.de  Mon Jun 21 15:34:46 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Jun 21 15:34:41 2004
Subject: [Rd] Windows binary packages for R-1.8.x and R-devel
Message-ID: <40D6E3F6.9040909@statistik.uni-dortmund.de>


Notes on Windows binary packages for R-1.8.x and R-devel
--------------------------------------------------------

- Compiling (and checking!) Windows binaries of contributed CRAN
packages for R-devel has been started.
Package maintainers might want to check from time to time whether the
results they get by the checks on Linux
(http://cran.r-project.org/src/contrib/checkSummary.html) are consistent
with those on Windows
(http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html).

- Compiling Windows binaries of contributed CRAN packages for R-1.8.x
has been suspended.

Uwe Ligges

From ssa.tvm at telesp.com.br  Mon Jun 21 17:35:59 2004
From: ssa.tvm at telesp.com.br (ssa.tvm@telesp.com.br)
Date: Mon Jun 21 17:36:02 2004
Subject: [Rd] Virus Alert (PR#6997)
Message-ID: <20040621153559.123B1F473@slim.kubism.ku.dk>

A mensagem (arquivo: screensaver.zip) que voce enviou para dandrea@telesp.com.br contem um virus ou tem um anexo nao permitido. (no the network)

From imosqueira at suk.azti.es  Mon Jun 21 19:55:35 2004
From: imosqueira at suk.azti.es (Iago Mosqueira)
Date: Mon Jun 21 18:55:02 2004
Subject: [Rd] Re: [R] Cross build Makefile
In-Reply-To: <Pine.LNX.4.44.0406210742320.31373-100000@gannet.stats>
References: <Pine.LNX.4.44.0406210742320.31373-100000@gannet.stats>
Message-ID: <1087840534.2858.25.camel@xurelo>

O Lun, 2004-06-21 ?s 08:00, Prof Brian Ripley escribiu:

> On Mon, 21 Jun 2004, Iago Mosqueira wrote:
> 
> > Hello,
> > 
> > I am trying to use Yan and Rossini's Makefile for cross building Windows
> > versions of R packages in Linux with R 1.9.0. When compiling R with the
> > mingw tools I get an error about expm1 being undeclared when first found
> > at src/main/arithmetic.c:1019
> > 
> > If I fiddle a bit with it later on I also get errors about log1p bein
> > undeclared.
> > 
> > Any idea what should I look for?
> > 
> > I am using R 1.9.0 in Debian, with R-mathlib avaliable, and gcc 3.3.
> 
> Did you build your own cross-compiler, or where did you get it from?

No, I got it following their indications, and I think it is from your
webpage, is that recent enough?

> log1p is definitely declared in math.h these days, but it used not to be, 
> so that one might be due to using too old a cross-compiler.
> 
> For expm1, the Windows config.h has /* #undef HAVE_EXPM1 */ which means it 
> is declared in Rmath.h and compiled up as part of libnmath.a.  Here all I 
> can suggest is that you check the headers files are correct and that you 
> are finding the ones for cross-compiling and not for Linux compiling 
> (which can be a problem if the cross-compiler was built incorrectly or you 
> configured R in that source tree without the right options).

I'll check it out. Thanks,


Iago Mosqueira

From sales at inkfactory.com  Mon Jun 21 18:59:00 2004
From: sales at inkfactory.com (Ink Factory Sales)
Date: Mon Jun 21 18:58:46 2004
Subject: [Rd] Re: Secure SMTP Message [20193722:95585]
Message-ID: <40D71409.000977.02684@TIF02.inkcartridges.ltd.uk>

This is an automated email to confirm that your message to sales@inkfactory.com has been received and will be dealt with by a member of our support team.

In the unlikely event that you have not had a reply in the next 2 working days, please reply to this email ensuring that the reference number remains in the subject line.

Kind Regards,

The Ink Factory Team.

From ripley at stats.ox.ac.uk  Mon Jun 21 20:39:31 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jun 21 20:39:34 2004
Subject: [Rd] Re: [R] Cross build Makefile
In-Reply-To: <1087840534.2858.25.camel@xurelo>
Message-ID: <Pine.LNX.4.44.0406211937180.27620-100000@gannet.stats>

On Mon, 21 Jun 2004, Iago Mosqueira wrote:

> O Lun, 2004-06-21 ?s 08:00, Prof Brian Ripley escribiu:
> 
> > On Mon, 21 Jun 2004, Iago Mosqueira wrote:
> > 
> > > Hello,
> > > 
> > > I am trying to use Yan and Rossini's Makefile for cross building Windows
> > > versions of R packages in Linux with R 1.9.0. When compiling R with the
> > > mingw tools I get an error about expm1 being undeclared when first found
> > > at src/main/arithmetic.c:1019
> > > 
> > > If I fiddle a bit with it later on I also get errors about log1p bein
> > > undeclared.
> > > 
> > > Any idea what should I look for?
> > > 
> > > I am using R 1.9.0 in Debian, with R-mathlib avaliable, and gcc 3.3.
> > 
> > Did you build your own cross-compiler, or where did you get it from?
> 
> No, I got it following their indications, and I think it is from your
> webpage, is that recent enough?

Mine is now, but a copy of what was there a few months ago might not be.
Specifically

-rw-r--r--    1 ripley   bdr       6549268 Apr  2 16:04 mingw-cross2.tar.bz2

is fine.

> > log1p is definitely declared in math.h these days, but it used not to be, 
> > so that one might be due to using too old a cross-compiler.
> > 
> > For expm1, the Windows config.h has /* #undef HAVE_EXPM1 */ which means it 
> > is declared in Rmath.h and compiled up as part of libnmath.a.  Here all I 
> > can suggest is that you check the headers files are correct and that you 
> > are finding the ones for cross-compiling and not for Linux compiling 
> > (which can be a problem if the cross-compiler was built incorrectly or you 
> > configured R in that source tree without the right options).
> 
> I'll check it out. Thanks,

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From umalvarez at fata.unam.mx  Tue Jun 22 02:35:19 2004
From: umalvarez at fata.unam.mx (umalvarez@fata.unam.mx)
Date: Tue Jun 22 02:35:21 2004
Subject: [Rd] Re: [R] Html help does not work in Mac OSX 10.3.4 (PR#7000)
Message-ID: <20040622003519.5A1FEEAE5@slim.kubism.ku.dk>

Hello!

If I launch R from a console I get:


R : Copyright 2004, The R Foundation for Statistical Computing
Version 1.9.0  (2004-04-12), ISBN 3-900051-00-3

> help.start()
Making links in per-session dir ...
If /usr/bin/open is already running, it is *not* restarted, and you
    must switch to its window.
Otherwise, be patient ...
> dyld: /usr/bin/open version mismatch for library: 
/usr/local/lib/libxml2.2.dylib (compatibility version of user: 9.0.0 
greater than library's version: 8.0.0)


This was with the default (browser="/usr/bin/open").

I also tried with:

> options(bowser="/usr/bin/open -a /Applications/firefox.app")
> help.start()
Making links in per-session dir ...
If /usr/bin/open is already running, it is *not* restarted, and you
    must switch to its window.
Otherwise, be patient ...
> dyld: /usr/bin/open version mismatch for library: 
/usr/local/lib/libxml2.2.dylib (compatibility version of user: 9.0.0 
greater than library's version: 8.0.0)
dyld: /usr/bin/open version mismatch for library: 
/usr/local/lib/libxml2.2.dylib (compatibility version of user: 9.0.0 
greater than library's version: 8.0.0)


After that, I check my fink installation:

.~/$ fink -V
Package manager version: 0.20.2
Distribution version: 0.7.0.cvs 

And...

.~/fink list libxml

 i   libxml2            2.6.7-1        XML parsing library, version 2
 i   libxml2-bin        2.6.7-1        XML parsing library, version 2
 i   libxml2-shlibs     2.6.7-1        XML parsing library, version 2
 

So far, no upgrades are available in fink's repositories. Perhaps Stefano
could help us. So, I'm submitting a copy of this mail. I don't know if 
this qualify as a bug, but I'm including R-bugs. I'll be not able to work 
on this full-time till Saturday. 

Regards.

On Fri, 18 Jun 2004, Emilio A. Laca wrote:

> I recently upgraded from R 1.8 to 1.9. I removed 1.8 following the
> instructions. Html help has not worked since. When htmlhelp="TRUE" the
> help.start() command results in the "patience" message and nothing else
> happens. I am using mac osx 10.3.4. Help worked fine when I was using R 
1.8.
> 
> I need help help ;-] Thanks!
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez@fata.unam.mx

From deleeuw at stat.ucla.edu  Tue Jun 22 02:40:48 2004
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Tue Jun 22 02:49:22 2004
Subject: [Rd] Re: [R] Html help does not work in Mac OSX 10.3.4 (PR#7000)
In-Reply-To: <20040622003519.5A1FEEAE5@slim.kubism.ku.dk>
References: <20040622003519.5A1FEEAE5@slim.kubism.ku.dk>
Message-ID: <CE3F1A09-C3E4-11D8-A088-000A95A67E82@stat.ucla.edu>

sudo rm /usr/local/lib/libxml2.2.dylib

and try again


On Jun 21, 2004, at 17:35, umalvarez@fata.unam.mx wrote:

> /usr/local/lib/libxml2.2.dylib
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From umalvarez at fata.unam.mx  Tue Jun 22 03:08:07 2004
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Tue Jun 22 03:08:16 2004
Subject: [Rd] Re: [R] Html help does not work in Mac OSX 10.3.4 (PR#7000)
In-Reply-To: <CE3F1A09-C3E4-11D8-A088-000A95A67E82@stat.ucla.edu>
Message-ID: <Pine.LNX.4.44.0406212000440.1191-100000@athena.fata.unam.mx>

Hello!

That's it!

Thank you.

On Mon, 21 Jun 2004, Jan de Leeuw wrote:

> sudo rm /usr/local/lib/libxml2.2.dylib
> 
> and try again
> 
> 
> On Jun 21, 2004, at 17:35, umalvarez@fata.unam.mx wrote:
> 
> > /usr/local/lib/libxml2.2.dylib
> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> Editor: Journal of Multivariate Analysis, Journal of Statistical  
> Software
> US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
> homepage: http://gifi.stat.ucla.edu
>    
> ------------------------------------------------------------------------ 
> -------------------------
>            No matter where you go, there you are. --- Buckaroo Banzai
>                     http://gifi.stat.ucla.edu/sounds/nomatter.au
>    
> ------------------------------------------------------------------------ 
> -------------------------
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez@fata.unam.mx

From olafuri at imr.no  Tue Jun 22 11:35:12 2004
From: olafuri at imr.no (olafuri@imr.no)
Date: Tue Jun 22 11:35:14 2004
Subject: [Rd] Copying and printing lattice graphics (PR#7004)
Message-ID: <20040622093512.9B3AA104D0@slim.kubism.ku.dk>

Full_Name: Olafur Arnar Ingolfsson
Version: 1.9.1
OS: Win XP
Submission from: (NULL) (213.236.225.194)


Copying lattice graphics only works with copy as bitmap.
Printing the graphic window doesn't work either.
I have the same problem with 1.9.0 and 1.9.1, just updatet packages
If I have done som (obvious) mistake, I do apologize.

x.val <- rnorm(100,50,3)
library(grid);library(lattice)
bwplot(x.val)  # can't copy or print that except w. copy as bitmap
boxplot(x.val) # this works without any problems

From ripley at stats.ox.ac.uk  Tue Jun 22 11:57:19 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Jun 22 11:57:26 2004
Subject: [Rd] Copying and printing lattice graphics (PR#7004)
In-Reply-To: <20040622093512.9B3AA104D0@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406221054380.23443-100000@gannet.stats>

This looks very like a bug introduced in 1.9.0 and supposedly fixed in
1.9.1. Do you really have a proper build of 1.9.1 (and not some
prerelease)?

Your example works for me in 1.9.1 but only randomly in 1.9.0.

On Tue, 22 Jun 2004 olafuri@imr.no wrote:

> Full_Name: Olafur Arnar Ingolfsson
> Version: 1.9.1
> OS: Win XP
> Submission from: (NULL) (213.236.225.194)
> 
> 
> Copying lattice graphics only works with copy as bitmap.
> Printing the graphic window doesn't work either.
> I have the same problem with 1.9.0 and 1.9.1, just updatet packages
> If I have done som (obvious) mistake, I do apologize.
> 
> x.val <- rnorm(100,50,3)
> library(grid);library(lattice)
> bwplot(x.val)  # can't copy or print that except w. copy as bitmap
> boxplot(x.val) # this works without any problems

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From humbertc at univ-mlv.fr  Tue Jun 22 13:16:58 2004
From: humbertc at univ-mlv.fr (humbertc@univ-mlv.fr)
Date: Tue Jun 22 13:17:00 2004
Subject: [Rd] X11 device, plot(...,
	xlab=expression(...)): missing parentheses (PR#7005)
Message-ID: <20040622111658.4C68CF6D8@slim.kubism.ku.dk>

Full_Name: Cyril Humbert
Version: 1.9.1
OS: Debian GNU/Linux (i386)
Submission from: (NULL) (193.50.159.2)


Hello,
For the X11 graphic device, parentheses are not displayed in 
labels for constructions like:

    X11()
    plot(0,0, ylab=expression(f(x)))

In this case, ylabel shows : 'yx' and not 'y(x)' as expected.
The same problem appears also with 'xlab' and 'sub' but not
with 'main':

    X11()
    plot(0,0, xlab=expression(x(t)), ylab=expression(y(t)), 
         main=expression(m(t)), sub=expression(s(t)))

-- 
R Version 1.9.1  (2004-06-21)

From maechler at stat.math.ethz.ch  Tue Jun 22 15:00:02 2004
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue Jun 22 15:00:04 2004
Subject: [Rd] Re: (PR#7005) X11 ,
	plot(...expression(...)): missing parentheses
Message-ID: <20040622130002.C3F36F6DA@slim.kubism.ku.dk>

>>>>> "humbertc" == humbertc  <humbertc@univ-mlv.fr>
>>>>>     on Tue, 22 Jun 2004 13:16:58 +0200 (CEST) writes:

    humbertc> Full_Name: Cyril Humbert
    humbertc> Version: 1.9.1
    humbertc> OS: Debian GNU/Linux (i386)
    humbertc> Submission from: (NULL) (193.50.159.2)


    humbertc> Hello,
    humbertc> For the X11 graphic device, parentheses are not displayed in 
    humbertc> labels for constructions like:

    humbertc> X11()
    humbertc> plot(0,0, ylab=expression(f(x)))

    humbertc> In this case, ylabel shows : 'yx' and not 'y(x)' as expected.
    humbertc> The same problem appears also with 'xlab' and 'sub' but not
    humbertc> with 'main':

    humbertc> X11()
    humbertc> plot(0,0, xlab=expression(x(t)), ylab=expression(y(t)), 
    humbertc>      main=expression(m(t)), sub=expression(s(t)))

I assume this could be some kind of font (server) problem with
your X11 / Xserver setup.

For me (also Linux, R 1.9.1) all the parentheses display fine.
and I'm pretty sure they do for most people or we would have
heard about it earlier.
--
Martin Maechler

From cyril.humbert at univ-mlv.fr  Tue Jun 22 16:32:18 2004
From: cyril.humbert at univ-mlv.fr (cyril.humbert@univ-mlv.fr)
Date: Tue Jun 22 16:32:21 2004
Subject: [Rd] Re: (PR#7005) X11 ,
	plot(...expression(...)): missing parentheses
Message-ID: <20040622143218.7F055F31F@slim.kubism.ku.dk>

Martin Maechler wrote:
> >>>>> "humbertc" == humbertc  <humbertc@univ-mlv.fr>
> >>>>>     on Tue, 22 Jun 2004 13:16:58 +0200 (CEST) writes:
> 
>     humbertc> Full_Name: Cyril Humbert
>     humbertc> Version: 1.9.1
>     humbertc> OS: Debian GNU/Linux (i386)
>     humbertc> Submission from: (NULL) (193.50.159.2)
> 
> 
>     humbertc> Hello,
>     humbertc> For the X11 graphic device, parentheses are not displayed in 
>     humbertc> labels for constructions like:
> 
>     humbertc> X11()
>     humbertc> plot(0,0, ylab=expression(f(x)))
> 
>     humbertc> In this case, ylabel shows : 'yx' and not 'y(x)' as expected.
>     humbertc> The same problem appears also with 'xlab' and 'sub' but not
>     humbertc> with 'main':
> 
>     humbertc> X11()
>     humbertc> plot(0,0, xlab=expression(x(t)), ylab=expression(y(t)), 
>     humbertc>      main=expression(m(t)), sub=expression(s(t)))
> 
> I assume this could be some kind of font (server) problem with
> your X11 / Xserver setup.
> 
> For me (also Linux, R 1.9.1) all the parentheses display fine.
> and I'm pretty sure they do for most people or we would have
> heard about it earlier.
> --
> Martin Maechler

Yes, you're right: I've tried the same example on another machine
and the parentheses are correctly displayed. Sorry...

-- 
Cyril Humbert

From tkirsten at izbi.uni-leipzig.de  Tue Jun 22 18:52:51 2004
From: tkirsten at izbi.uni-leipzig.de (Toralf Kirsten)
Date: Tue Jun 22 18:51:48 2004
Subject: [Rd] function not in load table
Message-ID: <40D863E3.1050209@izbi.uni-leipzig.de>

Hi,
I apologize for this often/old question. I found some hints but couldn't 
solve the problem so far.

I have C functions (incl. the header files) as well as the R wrapper 
functions which I want to use for faster calculations. These functions 
are included in a R package.
The installation process seems to be ok (no errors). I also can load the 
package without errors. But when I call the function I got the following 
error
 > wy.result <- wy.grps(data1=X1, grpdata=groups, nres=10000, 
alpha1=0.05, alpha2=0.05)
Error in .C("wy_grps_R", as.double(X), as.integer(n1), as.integer(n2),  :
         C function name not in load table
Execution halted

The parameter are
data1 - result of read.table()
grpdata - dito
nres - integer
alpha1 nad alpha1 - factors (float)

In the R function wy.grps(...) the C function is called by using the 
statement

result <- .C("wy_grps_R",
              as.double(X),
              as.integer(n1),
              as.integer(n2),
              as.integer(p),
              as.integer(unlist(grpidx)),
              as.integer(grplen),
              as.integer(grpnum),
              as.character(WYFUN),
              as.double(alpha2),
              as.character(MINMAXFUN),
              WYdist=double(nres),
              as.integer(nres),
              test.value=double(grpnum),
              p.value=double(grpnum))


My .First.lib.R is as follows:
.First.lib <- function(libname, pkgname) {
   library.dynam("izbi", package = pkgname, lib.loc = libname)
   data(COLS, package=pkgname)
   data(ROWS, package=pkgname)
   if (exists(".Dyn.libs")) remove(".Dyn.libs")
   if (interactive() && getenv("DISPLAY") != "") x11()
}

I read something about R_CMethodDef in "Writing R Extensions" but I'm 
not really sure where I should write it, may in the .First.lib.R or in a 
separate file?
Any other possible mistakes?

We are using R 1.9.0 on Fedora Linux.

Thanks a lot, Toralf

From vograno at evafunds.com  Tue Jun 22 19:22:29 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Tue Jun 22 19:22:56 2004
Subject: [Rd] function not in load table
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A5568A3A@phost015.EVAFUNDS.intermedia.net>

.C has a named argument 'PACKAGE', which you didn't set. I usually have
such an error when I forget about the argument. 

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Toralf Kirsten
> Sent: Tuesday, June 22, 2004 9:53 AM
> To: r-devel@stat.math.ethz.ch
> Subject: [Rd] function not in load table
> 
> Hi,
> I apologize for this often/old question. I found some hints 
> but couldn't solve the problem so far.
> 
> I have C functions (incl. the header files) as well as the R 
> wrapper functions which I want to use for faster 
> calculations. These functions are included in a R package.
> The installation process seems to be ok (no errors). I also 
> can load the package without errors. But when I call the 
> function I got the following error  > wy.result <- 
> wy.grps(data1=X1, grpdata=groups, nres=10000, alpha1=0.05, 
> alpha2=0.05) Error in .C("wy_grps_R", as.double(X), 
> as.integer(n1), as.integer(n2),  :
>          C function name not in load table Execution halted
> 
> The parameter are
> data1 - result of read.table()
> grpdata - dito
> nres - integer
> alpha1 nad alpha1 - factors (float)
> 
> In the R function wy.grps(...) the C function is called by 
> using the statement
> 
> result <- .C("wy_grps_R",
>               as.double(X),
>               as.integer(n1),
>               as.integer(n2),
>               as.integer(p),
>               as.integer(unlist(grpidx)),
>               as.integer(grplen),
>               as.integer(grpnum),
>               as.character(WYFUN),
>               as.double(alpha2),
>               as.character(MINMAXFUN),
>               WYdist=double(nres),
>               as.integer(nres),
>               test.value=double(grpnum),
>               p.value=double(grpnum))
> 
> 
> My .First.lib.R is as follows:
> .First.lib <- function(libname, pkgname) {
>    library.dynam("izbi", package = pkgname, lib.loc = libname)
>    data(COLS, package=pkgname)
>    data(ROWS, package=pkgname)
>    if (exists(".Dyn.libs")) remove(".Dyn.libs")
>    if (interactive() && getenv("DISPLAY") != "") x11() }
> 
> I read something about R_CMethodDef in "Writing R Extensions" 
> but I'm not really sure where I should write it, may in the 
> .First.lib.R or in a separate file?
> Any other possible mistakes?
> 
> We are using R 1.9.0 on Fedora Linux.
> 
> Thanks a lot, Toralf
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
>

From wb at arb-phys.uni-dortmund.de  Tue Jun 22 20:53:06 2004
From: wb at arb-phys.uni-dortmund.de (wb@arb-phys.uni-dortmund.de)
Date: Tue Jun 22 20:53:08 2004
Subject: [Rd] lme4 fails to install on R-1.9/FreeBSD-5.2 (PR#7007)
Message-ID: <20040622185306.A1225EC53@slim.kubism.ku.dk>

Full_Name: W.B.Kloke
Version: 1.9.1
OS: FreeBSD-5.2.1
Submission from: (NULL) (195.253.16.182)


Subject line says it. I had problems installing lme4.

1. The dependency on package Matrix was not resolved (I am not sure that this is
really a bug; but it is annoying, anyway).

2. Installing Matrix failed with a message saying something like "no rule for
%_D.o"
after compiling a lot of sources and combining them into an archive. I traced
this down to a Linuxism. I found the string _D.o in subdirectory taucs of
Matrix. Forcing GNU make by adding MAKE=gmake to the environment of R installed
the package successfully. I consider this a real non-portability bug.

From gilescrane at doh.state.nj.us  Tue Jun 22 22:18:46 2004
From: gilescrane at doh.state.nj.us (gilescrane@doh.state.nj.us)
Date: Tue Jun 22 22:18:51 2004
Subject: [Rd] dates (PR#7008)
Message-ID: <20040622201846.CE08DEABD@slim.kubism.ku.dk>

Full_Name: Giles L Crane
Version: 1.9.0
OS: Windows 98
Submission from: (NULL) (199.20.71.17)


In package foreign, the read.epiinfo() does not
read dates properly.  
(1) In reading a dataset,
read.epiinfo made many dates NA.
(2) Instead of reading dates to a POSIXct format,
why not read to a mm/dd/yyyy format such as 
"06/22/2004"?
As you may know, EPI6 calculates and displays
dates quite directly.
(3) The package date does not seem to have
a convenient way of extracting dates
from POSIXct format.
Appreciate any comments,
GLC

From ubisoft_ca at mailnj.custhelp.com  Wed Jun 23 09:55:43 2004
From: ubisoft_ca at mailnj.custhelp.com (Support Technique UBISOFT)
Date: Wed Jun 23 09:55:48 2004
Subject: [Rd] Re : *****SPAM***** Important
Message-ID: <40D9377F.0003FF.11451@utilnj01.int.rightnowtech.com>

Rponse
---------------------------------------------------------------
(English will Follow)
 
Merci d'avoir contact le Support Technique UBISOFT Canada.
 
Nous n'acceptons plus les requtes de support par courriel standard. Votre courriel original ne sera donc pas trait. Veuillez suivre les tapes ci-dessous pour trouver rponse  votre question.
 
Pour connatre la procdure  suivre pour nous contacter, cliquez sur le lien suivant :
 
http://ubisoft-fr.custhelp.com/cgi-bin/ubisoft_fr.cfg/php/enduser/std_adp.php?p_faqid=8985
 
Si vous nous avez dj contact et que vous voulez rpondre  un incident, veuillez cliquer sur ce lien http://ubisoft-fr.custhelp.com/cgi-bin/ubisoft_fr.cfg/php/enduser/acct_login.php pour vous connecter  votre compte en utilisant votre nom d'utilisateur Ubi.com et mot de passe. Une fois connect, vous pourrez mettre  jour votre incident correctement.
 
Nous vous rappelons que votre courriel original ne sera pas trait.  Vous devez suivre les tapes ci-dessus.
 
Merci,
 
Support Technique UBISOFT Canada
 
----------------------------
 
Thank You for contacting UBISOFT Technical Support.
 
We are no longer accepting standard e-mail support requests. Your original e-mail will not be processed. Please follow the steps below to find the answers you need.
 
In order to contact us, click on the following link and follow the steps listed here:
 
http://ubisoft.custhelp.com/cgi-bin/ubisoft.cfg/php/enduser/std_adp.php?p_faqid=8982
 
If you already contacted us and want to answer to an incident, please go to http://ubisoft.custhelp.com/cgi-bin/ubisoft.cfg/php/enduser/acct_login.php to login to your incident using your ubi.com login name and password. Once you are logged in, you will be able to update your support incident correctly.
 
Again your original e-mail will not be processed. You will need to follow the steps listed above. 
 
Thank You,
 
UBISOFT Technical Support


	[[alternative HTML version deleted]]

From maechler at stat.math.ethz.ch  Wed Jun 23 10:08:20 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Jun 23 10:08:22 2004
Subject: [Rd] function not in load table
In-Reply-To: <40D863E3.1050209@izbi.uni-leipzig.de>
References: <40D863E3.1050209@izbi.uni-leipzig.de>
Message-ID: <16601.14964.360131.27461@gargle.gargle.HOWL>

>>>>> "Toralf" == Toralf Kirsten <tkirsten@izbi.uni-leipzig.de>
>>>>>     on Tue, 22 Jun 2004 18:52:51 +0200 writes:


    Toralf> I apologize for this often/old question. I found
    Toralf> some hints but couldn't solve the problem so far.

    Toralf> I have C functions (incl. the header files) as well

really C, not C++ ?
[or did you compile by a C++ compiler instead of C ?]
I ask because for C++ that's really a FAQ

    Toralf> as the R wrapper functions which I want to use for
    Toralf> faster calculations. These functions are included in
    Toralf> a R package.  The installation process seems to be
    Toralf> ok (no errors). I also can load the package without
    Toralf> errors. But when I call the function I got the
    Toralf> following error

    Toralf> wy.result <- wy.grps(data1=X1, grpdata=groups, nres=10000, 
    Toralf> alpha1=0.05, alpha2=0.05)
    Toralf> Error in .C("wy_grps_R", as.double(X), as.integer(n1), as.integer(n2),  :
    Toralf> C function name not in load table
    Toralf> Execution halted

this really means that there's no exported C function named 'wy_grps_R'
from the dyn.loaded C code.
Do
	nm -g  izbi.so
inside izbi/src/ in the shell to check.


    Toralf> The parameter are
    Toralf> data1 - result of read.table()
    Toralf> grpdata - dito
    Toralf> nres - integer
    Toralf> alpha1 nad alpha1 - factors (float)

    Toralf> In the R function wy.grps(...) the C function is called by using the 
    Toralf> statement

    Toralf> result <- .C("wy_grps_R",
    Toralf> as.double(X),
    Toralf> as.integer(n1),
    Toralf> as.integer(n2),
    Toralf> as.integer(p),
    Toralf> as.integer(unlist(grpidx)),
    Toralf> as.integer(grplen),
    Toralf> as.integer(grpnum),
    Toralf> as.character(WYFUN),
    Toralf> as.double(alpha2),
    Toralf> as.character(MINMAXFUN),
    Toralf> WYdist=double(nres),
    Toralf> as.integer(nres),
    Toralf> test.value=double(grpnum),
    Toralf> p.value=double(grpnum))

Vadim mentions that you should add  PACKAGE= "<pkgname>"  here
which is true but not related to your problem.

    Toralf> My .First.lib.R is as follows:
    Toralf> .First.lib <- function(libname, pkgname) {
    Toralf> library.dynam("izbi", package = pkgname, lib.loc = libname)
    Toralf> data(COLS, package=pkgname)
    Toralf> data(ROWS, package=pkgname)

    Toralf> if (exists(".Dyn.libs")) remove(".Dyn.libs")

not sure if the above is a good idea.
What do you want it for?

    Toralf> if (interactive() && getenv("DISPLAY") != "") x11()
    Toralf> }


    Toralf> I read something about R_CMethodDef in "Writing R
    Toralf> Extensions" but I'm not really sure where I should
    Toralf> write it, may in the .First.lib.R or in a separate
    Toralf> file?

That's something else nice -- but all happens on the C level.
For an example of this see in the R sources
  R-1.9.1/src/library/stats/src/init.c

Martin Maechler

From stefan.albrecht at allianz.com  Wed Jun 23 10:28:38 2004
From: stefan.albrecht at allianz.com (stefan.albrecht@allianz.com)
Date: Wed Jun 23 10:28:45 2004
Subject: [Rd] Cannot Restore Workspace with R 1.9.1 (PR#7012)
Message-ID: <20040623082838.D8548EABD@slim.kubism.ku.dk>

Full_Name: Stefan Albrecht
Version: 1.9.1
OS: Windows NT 4.0
Submission from: (NULL) (194.127.2.73)


Hi  all,

upgrading to R 1.9.1 I am no longer able to restore saved data in .RData with
after some involved data manipulations and calculations (fatal error!).
In addition I get the message
Error: object 'family' not found whilst loading namespace 'MASS'.

This problem does not occur with R 1.9.0 or if I just make some easier
calculations with R 1.9.1.

Is there any way to analyse the problem more closely and come around it?

Many thanks and best regards,

Stefan

From ripley at stats.ox.ac.uk  Wed Jun 23 10:46:15 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jun 23 10:46:21 2004
Subject: [Rd] Cannot Restore Workspace with R 1.9.1 (PR#7012)
In-Reply-To: <20040623082838.D8548EABD@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406230934480.16631-100000@gannet.stats>

This has recently been discussed in R-help with several workarounds. See
https://www.stat.math.ethz.ch/pipermail/r-help/2004-June/051531.html
and the rest of the thread.

Yet another workaround is

R --vanilla
> load(".RData")

It is not a bug in R, and it is not new in 1.9.1 (the person who reported
problems was using prior to release of 1.9.1).  A more permanent
workaround will appear in the next update of the VR bundle.  AFAICS the
problem reported by Roland Reis is actually in nlme, which manages to
require MASS, grid, lattice and nlme namespaces to reload a glmmPQL object
(via the environment of some embedded formula).

Please don't use R-bugs to ask questions -- see the R FAQ and the posting
guide for the correct places.


On Wed, 23 Jun 2004 stefan.albrecht@allianz.com wrote:

> Full_Name: Stefan Albrecht
> Version: 1.9.1
> OS: Windows NT 4.0
> Submission from: (NULL) (194.127.2.73)
> 
> 
> Hi  all,
> 
> upgrading to R 1.9.1 I am no longer able to restore saved data in .RData with
> after some involved data manipulations and calculations (fatal error!).
> In addition I get the message
> Error: object 'family' not found whilst loading namespace 'MASS'.
> 
> This problem does not occur with R 1.9.0 or if I just make some easier
> calculations with R 1.9.1.
> 
> Is there any way to analyse the problem more closely and come around it?

Yes. See the R-help archives.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ligges at statistik.uni-dortmund.de  Wed Jun 23 10:54:13 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Jun 23 10:54:02 2004
Subject: [Rd] Cannot Restore Workspace with R 1.9.1 (PR#7012)
In-Reply-To: <20040623082838.D8548EABD@slim.kubism.ku.dk>
References: <20040623082838.D8548EABD@slim.kubism.ku.dk>
Message-ID: <40D94535.3050103@statistik.uni-dortmund.de>

stefan.albrecht@allianz.com wrote:
> Full_Name: Stefan Albrecht
> Version: 1.9.1
> OS: Windows NT 4.0
> Submission from: (NULL) (194.127.2.73)
> 
> 
> Hi  all,
> 
> upgrading to R 1.9.1 I am no longer able to restore saved data in .RData with
> after some involved data manipulations and calculations (fatal error!).
> In addition I get the message
> Error: object 'family' not found whilst loading namespace 'MASS'.

[not CCing to r-bugs, because quite probably not a bug ...]

He? Why does MASS load when you try to load a workspace?

Anyway, it sounds like you have mixed different R installations (in 
particular one that is older than R-1.9.0 and R-1.9.1) or at least you 
have outdated packages in your libraries.
Moreover, you may have some self edited startup stuff (like loading 
MASS in any RProfile file???).

It would help us to know what you did exactly ...

Uwe Ligges


> This problem does not occur with R 1.9.0 or if I just make some easier
> calculations with R 1.9.1.
> 
> Is there any way to analyse the problem more closely and come around it?
> 
> Many thanks and best regards,
> 
> Stefan
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From tkirsten at izbi.uni-leipzig.de  Wed Jun 23 11:36:23 2004
From: tkirsten at izbi.uni-leipzig.de (Toralf Kirsten)
Date: Wed Jun 23 11:39:36 2004
Subject: [Rd] function not in load table
In-Reply-To: <16601.14964.360131.27461@gargle.gargle.HOWL>
References: <40D863E3.1050209@izbi.uni-leipzig.de>
	<16601.14964.360131.27461@gargle.gargle.HOWL>
Message-ID: <40D94F17.70303@izbi.uni-leipzig.de>

Hi Martin, Vadim,

<snip>
> 
> really C, not C++ ?
> [or did you compile by a C++ compiler instead of C ?]
> I ask because for C++ that's really a FAQ

It's really a C function.

>     Toralf> wy.result <- wy.grps(data1=X1, grpdata=groups, nres=10000, 
>     Toralf> alpha1=0.05, alpha2=0.05)
>     Toralf> Error in .C("wy_grps_R", as.double(X), as.integer(n1), as.integer(n2),  :
>     Toralf> C function name not in load table
>     Toralf> Execution halted
> 
> this really means that there's no exported C function named 'wy_grps_R'
> from the dyn.loaded C code.
> Do
> 	nm -g  izbi.so
> inside izbi/src/ in the shell to check.


I checked the exported function as you mentioned above and I can see the 
function named 'wy_grps_R' in the list (as you can see below)
...
00004d80 T uvarWYdist
00004790 T wy_clust_R
000045a0 T wy_grps_R   <---
00004450 T wy_uvar_R
...
The T in the second column means it is available in the code segment, right.

> 
>     Toralf> My .First.lib.R is as follows:
>     Toralf> .First.lib <- function(libname, pkgname) {
>     Toralf> library.dynam("izbi", package = pkgname, lib.loc = libname)
>     Toralf> data(COLS, package=pkgname)
>     Toralf> data(ROWS, package=pkgname)
> 
>     Toralf> if (exists(".Dyn.libs")) remove(".Dyn.libs")
> 
> not sure if the above is a good idea.
> What do you want it for?

What do you think what is not a good practice?
The COLS and ROWS are R objects which we use in R programs to replace 
the 1 and 0 used as col and row parameter.
Do you think we should use the command
dyn.load("<compiled_code.so>")
for each C file instead of
library.dynam(...)?

I also tried to specify the package name in this manner
result <- .C("wy_grps_R",
              as.double(X),
              as.integer(n1),
              as.integer(n2),
              as.integer(p),
              as.integer(unlist(grpidx)),
              as.integer(grplen),
              as.integer(grpnum),
              as.character(WYFUN),
              as.double(alpha2),
              as.character(MINMAXFUN),
              WYdist=double(nres),
              as.integer(nres),
              test.value=double(grpnum),
              p.value=double(grpnum),
              PACKAGE="izbi")
Unfortunately it didn't solve the problem.

Many Thanks for your help,
Toralf

From stefan.albrecht at allianz.com  Wed Jun 23 11:45:16 2004
From: stefan.albrecht at allianz.com (stefan.albrecht@allianz.com)
Date: Wed Jun 23 11:45:26 2004
Subject: [Rd] Cannot Restore Workspace with R 1.9.1 (PR#7012)
Message-ID: <OFDA7087AB.927AE044-ONC1256EBC.0034F9E6@muc.allianz>


Many thanks.

 "Another way is to use

library(stats)

in your .Rprofile in that directory."

has worked very fine.

Stefan Albrecht





|---------+--------------------------->
|         |           Prof Brian      |
|         |           Ripley          |
|         |           <ripley@stats.ox|
|         |           .ac.uk>         |
|         |                           |
|         |           06/23/04 10:46  |
|         |                           |
|---------+--------------------------->
  >-------------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                               |
  |        An:      Stefan Albrecht/HV/Finanzen/Allianz-Sach@ALLIANZ-SACH                                                         |
  |        Kopie:   r-devel@stat.math.ethz.ch, <R-bugs@biostat.ku.dk>                                                             |
  |        Thema:   Re: [Rd] Cannot Restore Workspace with R 1.9.1 (PR#7012)                                                      |
  >-------------------------------------------------------------------------------------------------------------------------------|



This has recently been discussed in R-help with several workarounds. See
https://www.stat.math.ethz.ch/pipermail/r-help/2004-June/051531.html
and the rest of the thread.

Yet another workaround is

R --vanilla
> load(".RData")

It is not a bug in R, and it is not new in 1.9.1 (the person who reported
problems was using prior to release of 1.9.1).  A more permanent
workaround will appear in the next update of the VR bundle.  AFAICS the
problem reported by Roland Reis is actually in nlme, which manages to
require MASS, grid, lattice and nlme namespaces to reload a glmmPQL object
(via the environment of some embedded formula).

Please don't use R-bugs to ask questions -- see the R FAQ and the posting
guide for the correct places.


On Wed, 23 Jun 2004 stefan.albrecht@allianz.com wrote:

> Full_Name: Stefan Albrecht
> Version: 1.9.1
> OS: Windows NT 4.0
> Submission from: (NULL) (194.127.2.73)
>
>
> Hi  all,
>
> upgrading to R 1.9.1 I am no longer able to restore saved data in .RData
with
> after some involved data manipulations and calculations (fatal error!).
> In addition I get the message
> Error: object 'family' not found whilst loading namespace 'MASS'.
>
> This problem does not occur with R 1.9.0 or if I just make some easier
> calculations with R 1.9.1.
>
> Is there any way to analyse the problem more closely and come around it?

Yes. See the R-help archives.

--
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Jun 23 14:09:09 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jun 23 14:09:17 2004
Subject: [Rd] dates (PR#7008)
In-Reply-To: <20040622201846.CE08DEABD@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406231300590.23737-100000@gannet.stats>

R-bugs is for bugs, and one bug per report.  That means it cannot cope 
with three-part reports, two parts of which seem to be questions/wishes.

On Tue, 22 Jun 2004 gilescrane@doh.state.nj.us wrote:

> Full_Name: Giles L Crane
> Version: 1.9.0
> OS: Windows 98
> Submission from: (NULL) (199.20.71.17)
> 
> 
> In package foreign, the read.epiinfo() does not
> read dates properly.  
> (1) In reading a dataset,
> read.epiinfo made many dates NA.

Can you give a reproducible example, please.  Please start a new topic 
with a comprehensive subject line, as this one has been closed.

> (2) Instead of reading dates to a POSIXct format,
> why not read to a mm/dd/yyyy format such as 
> "06/22/2004"?
> As you may know, EPI6 calculates and displays
> dates quite directly.

R does not use that date format (which is not an international standard).
Indeed, how does anyone know that is a date (and if "01/01/1989", that it 
is in the illogical mm/dd/yyyy format only used in a few countries).

> (3) The package date does not seem to have
> a convenient way of extracting dates
> from POSIXct format.

Well, the date package was written about a decade before POSIXct.  Why 
would anyone still be using it for new data?  (Such a person could easily 
write one for his/her own use.)

> Appreciate any comments,

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Jun 23 14:30:04 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jun 23 14:30:09 2004
Subject: [Rd] lme4 fails to install on R-1.9/FreeBSD-5.2 (PR#7007)
In-Reply-To: <20040622185306.A1225EC53@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406231309370.23737-100000@gannet.stats>

Please send reports on contributed packages to the package maintainer 
(Cc:ed here, but he is on leave this summer so don't expect a fast 
response).

On Tue, 22 Jun 2004 wb@arb-phys.uni-dortmund.de wrote:

> Full_Name: W.B.Kloke
> Version: 1.9.1

What about the package versions?

> OS: FreeBSD-5.2.1
> Submission from: (NULL) (195.253.16.182)
> 
> 
> Subject line says it. I had problems installing lme4.

Actually not (especially as there is no R-1.9).  I gather you had problems
installing Matrix, and the bug you found is in Matrix.

> 1. The dependency on package Matrix was not resolved (I am not sure that this is
> really a bug; but it is annoying, anyway).

I am not sure what you mean here.  It seems you did not install Matrix 
first?  Did you expect install.packages() to do that for you?

> 2. Installing Matrix failed with a message saying something like "no rule for
> %_D.o"
> after compiling a lot of sources and combining them into an archive. I traced
> this down to a Linuxism. I found the string _D.o in subdirectory taucs of
> Matrix. Forcing GNU make by adding MAKE=gmake to the environment of R installed
> the package successfully. I consider this a real non-portability bug.

GNUism, I suspect.  There seem to be similar problems on Solaris.

make: Fatal error in reader: Makefile, line 32: Extra `:', `::', or `:=' 
on dependency line
Current working directory /tmp/R.INSTALL.28676/Matrix/src/taucs

I managed to get this to compile and check (apart from some 
documentation problems) with

%_D.o: %.c
        $(CC) $(ALL_CPPFLAGS) $(ALL_CFLAGS) $(TDFLAGS) -c $< -o $@

%.o: %.c
        $(CC) $(ALL_CPPFLAGS) $(ALL_CFLAGS) $(TGFLAGS) -c $< -o $@

(there is no TAUCS_G to worry about).

I am sure Dr Bates will appreciate your sending him a tested patch when 
you get it working.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Wed Jun 23 14:38:30 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Jun 23 14:38:32 2004
Subject: [Rd] function not in load table
In-Reply-To: <40D94F17.70303@izbi.uni-leipzig.de>
References: <40D863E3.1050209@izbi.uni-leipzig.de>
	<16601.14964.360131.27461@gargle.gargle.HOWL>
	<40D94F17.70303@izbi.uni-leipzig.de>
Message-ID: <16601.31174.615612.410723@gargle.gargle.HOWL>

>>>>> "Toralf" == Toralf Kirsten <tkirsten@izbi.uni-leipzig.de>
>>>>>     on Wed, 23 Jun 2004 11:36:23 +0200 writes:

    Toralf> Hi Martin, Vadim,
    Toralf> <snip>
    >> 
    >> really C, not C++ ?
    >> [or did you compile by a C++ compiler instead of C ?]
    >> I ask because for C++ that's really a FAQ

    Toralf> It's really a C function.

ok

    Toralf> wy.result <- wy.grps(data1=X1, grpdata=groups, nres=10000, 
    Toralf> alpha1=0.05, alpha2=0.05)
    Toralf> Error in .C("wy_grps_R", as.double(X), as.integer(n1), as.integer(n2),  :
    Toralf> C function name not in load table
    Toralf> Execution halted
    >> 
    >> this really means that there's no exported C function named 'wy_grps_R'
    >> from the dyn.loaded C code.
    >> Do
    >> nm -g  izbi.so
    >> inside izbi/src/ in the shell to check.


    Toralf> I checked the exported function as you mentioned above and I can see the 
    Toralf> function named 'wy_grps_R' in the list (as you can see below)
    Toralf> ...
    Toralf> 00004d80 T uvarWYdist
    Toralf> 00004790 T wy_clust_R
    Toralf> 000045a0 T wy_grps_R   <---
    Toralf> 00004450 T wy_uvar_R
    Toralf> ...
    Toralf> The T in the second column means it is available in the code segment, right.

yes.


    Toralf> My .First.lib.R is as follows:
    Toralf> .First.lib <- function(libname, pkgname) {
    Toralf> library.dynam("izbi", package = pkgname, lib.loc = libname)
    Toralf> data(COLS, package=pkgname)
    Toralf> data(ROWS, package=pkgname)
    >> 
    Toralf> if (exists(".Dyn.libs")) remove(".Dyn.libs")
    >> 
    >> not sure if the above is a good idea.
    >> What do you want it for?

    Toralf> What do you think what is not a good practice?

only the last line (before which I had added an empty line)
removing .Dyn.libs.


    Toralf> The COLS and ROWS are R objects which we use in R
    Toralf> programs to replace the 1 and 0 used as col and row
    Toralf> parameter.

(I don't understand but it's not relevant here anyway)

    Toralf> Do you think we should use the command
    Toralf> dyn.load("<compiled_code.so>")
    Toralf> for each C file instead of
    Toralf> library.dynam(...)?

No, no these were fine. Do not change them

    Toralf> I also tried to specify the package name in this manner
    Toralf> result <- .C("wy_grps_R",
    Toralf> as.double(X),
    Toralf> as.integer(n1),
    Toralf> as.integer(n2),
    Toralf> as.integer(p),
    Toralf> as.integer(unlist(grpidx)),
    Toralf> as.integer(grplen),
    Toralf> as.integer(grpnum),
    Toralf> as.character(WYFUN),
    Toralf> as.double(alpha2),
    Toralf> as.character(MINMAXFUN),
    Toralf> WYdist=double(nres),
    Toralf> as.integer(nres),
    Toralf> test.value=double(grpnum),
    Toralf> p.value=double(grpnum),
    Toralf> PACKAGE="izbi")

    Toralf> Unfortunately it didn't solve the problem.

yes, as I said in my e-mail.

I'm almost at the end of my hints here.
One thing -- you probably have already tried is to use
is.loaded()  
as in the following example

  > is.loaded(symbol.C("pam"))
  [1] FALSE
  > library(cluster)
  > is.loaded(symbol.C("pam"))
  [1] TRUE
  > 

but I presume you will just find that
    is.loaded(symbol.C("wy_grps_R"))
gives FALSE for you even after  
    library(izbi)

Is there nobody in Leipzig willing to delve into your package's
source?

Regards,
Martin

From rpeng at jhsph.edu  Wed Jun 23 15:59:10 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed Jun 23 15:59:13 2004
Subject: [Rd] problem with tilde expansion in install.packages
Message-ID: <40D98CAE.7000501@jhsph.edu>

In R 1.9.0 on Solaris/Sparc when I run, for example, 
install.packages("gregmisc", "~/R-local/lib"), instead of installing 
the `gregmisc' package in the directory 
/users/student/rpeng/R-local/lib the package gets installed in 
/users/student/rpeng/\~/R-local/lib, so the directory \~ is created in 
my home directory.  This doesn't happen to me on Linux or Windows so I 
thought it might not be an R problem.

I realize I'm referring to an older version of R but I was wondering 
if anyone had seen this happen (perhaps on 1.9.1) or how I might 
better pinpoint the problem.

 > version
          _
platform sparc-sun-solaris2.8
arch     sparc
os       solaris2.8
system   sparc, solaris2.8
status
major    1
minor    9.0
year     2004
month    04
day      12
language R

If it matters, I'm using tcsh (in /bin/tcsh).

-roger

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/

From ripley at stats.ox.ac.uk  Wed Jun 23 16:39:51 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jun 23 16:39:59 2004
Subject: [Rd] problem with tilde expansion in install.packages
In-Reply-To: <40D98CAE.7000501@jhsph.edu>
Message-ID: <Pine.LNX.4.44.0406231537050.10798-100000@gannet.stats>

Do you have readline working on that version of R?  If so, it is readline 
problem.  If not, do you have HOME set? - if not, try setting it.

On Wed, 23 Jun 2004, Roger D. Peng wrote:

> In R 1.9.0 on Solaris/Sparc when I run, for example, 
> install.packages("gregmisc", "~/R-local/lib"), instead of installing 
> the `gregmisc' package in the directory 
> /users/student/rpeng/R-local/lib the package gets installed in 
> /users/student/rpeng/\~/R-local/lib, so the directory \~ is created in 
> my home directory.  This doesn't happen to me on Linux or Windows so I 
> thought it might not be an R problem.
> 
> I realize I'm referring to an older version of R but I was wondering 
> if anyone had seen this happen (perhaps on 1.9.1) or how I might 
> better pinpoint the problem.
> 
>  > version
>           _
> platform sparc-sun-solaris2.8
> arch     sparc
> os       solaris2.8
> system   sparc, solaris2.8
> status
> major    1
> minor    9.0
> year     2004
> month    04
> day      12
> language R
> 
> If it matters, I'm using tcsh (in /bin/tcsh).
> 
> -roger
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rpeng at jhsph.edu  Wed Jun 23 16:45:38 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed Jun 23 16:45:40 2004
Subject: [Rd] problem with tilde expansion in install.packages
In-Reply-To: <Pine.LNX.4.44.0406231537050.10798-100000@gannet.stats>
References: <Pine.LNX.4.44.0406231537050.10798-100000@gannet.stats>
Message-ID: <40D99792.70705@jhsph.edu>

I didn't compile this version of R myself but I believe readline is 
compiled in -- the command history works and:

 > capabilities("cledit")
cledit
   TRUE

Also,

 > Sys.getenv("HOME")
                   HOME
"/users/student/rpeng"

which is in fact my home directory.

-roger

Prof Brian Ripley wrote:
> Do you have readline working on that version of R?  If so, it is readline 
> problem.  If not, do you have HOME set? - if not, try setting it.
> 
> On Wed, 23 Jun 2004, Roger D. Peng wrote:
> 
> 
>>In R 1.9.0 on Solaris/Sparc when I run, for example, 
>>install.packages("gregmisc", "~/R-local/lib"), instead of installing 
>>the `gregmisc' package in the directory 
>>/users/student/rpeng/R-local/lib the package gets installed in 
>>/users/student/rpeng/\~/R-local/lib, so the directory \~ is created in 
>>my home directory.  This doesn't happen to me on Linux or Windows so I 
>>thought it might not be an R problem.
>>
>>I realize I'm referring to an older version of R but I was wondering 
>>if anyone had seen this happen (perhaps on 1.9.1) or how I might 
>>better pinpoint the problem.
>>
>> > version
>>          _
>>platform sparc-sun-solaris2.8
>>arch     sparc
>>os       solaris2.8
>>system   sparc, solaris2.8
>>status
>>major    1
>>minor    9.0
>>year     2004
>>month    04
>>day      12
>>language R
>>
>>If it matters, I'm using tcsh (in /bin/tcsh).
>>
>>-roger
>>
>>
> 
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/

From p.dalgaard at biostat.ku.dk  Wed Jun 23 17:51:18 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed Jun 23 17:51:48 2004
Subject: [Rd] problem with tilde expansion in install.packages
In-Reply-To: <40D99792.70705@jhsph.edu>
References: <Pine.LNX.4.44.0406231537050.10798-100000@gannet.stats>
	<40D99792.70705@jhsph.edu>
Message-ID: <x21xk6clxl.fsf@biostat.ku.dk>

"Roger D. Peng" <rpeng@jhsph.edu> writes:

> I didn't compile this version of R myself but I believe readline is
> compiled in -- the command history works and:
> 
>  > capabilities("cledit")
> cledit
>    TRUE
> 
> Also,
> 
>  > Sys.getenv("HOME")
>                    HOME
> "/users/student/rpeng"
> 
> which is in fact my home directory.

I think sufficiently braindead versions of sh just will do this to you,
including the one that comes default on Solaris 9:

rasch:~/>/usr/bin/sh
$ ls ~
~: No such file or directory

This applies also to system() processing, e.g. 

system("mkdir -p ~/xxx") 

gets you a directory "~" with subdir "xxx". (NB: If you try this,
think VERY carefully about how to remove that dir!!!!)

> Prof Brian Ripley wrote:
> > Do you have readline working on that version of R?  If so, it is
> > readline problem.  If not, do you have HOME set? - if not, try
> > setting it.
> > On Wed, 23 Jun 2004, Roger D. Peng wrote:
> >
> >> In R 1.9.0 on Solaris/Sparc when I run, for example,
> >> install.packages("gregmisc", "~/R-local/lib"), instead of
> >> installing the `gregmisc' package in the directory
> >> /users/student/rpeng/R-local/lib the package gets installed in
> >> /users/student/rpeng/\~/R-local/lib, so the directory \~ is created
> >> in my home directory.  This doesn't happen to me on Linux or
> >> Windows so I thought it might not be an R problem.
> >>
> >> I realize I'm referring to an older version of R but I was
> >> wondering if anyone had seen this happen (perhaps on 1.9.1) or how
> >> I might better pinpoint the problem.
> >>
> >> > version
> >>          _
> >>platform sparc-sun-solaris2.8
> >>arch     sparc
> >>os       solaris2.8
> >>system   sparc, solaris2.8
> >>status
> >>major    1
> >>minor    9.0
> >>year     2004
> >>month    04
> >>day      12
> >>language R
> >>
> >>If it matters, I'm using tcsh (in /bin/tcsh).
> >>
> >>-roger
> >>
> >>
> >
> 
> -- 
> Roger D. Peng
> http://www.biostat.jhsph.edu/~rpeng/
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From rpeng at jhsph.edu  Wed Jun 23 18:00:19 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed Jun 23 18:00:22 2004
Subject: [Rd] problem with tilde expansion in install.packages
In-Reply-To: <x21xk6clxl.fsf@biostat.ku.dk>
References: <Pine.LNX.4.44.0406231537050.10798-100000@gannet.stats>	<40D99792.70705@jhsph.edu>
	<x21xk6clxl.fsf@biostat.ku.dk>
Message-ID: <40D9A913.2080606@jhsph.edu>

Peter Dalgaard wrote:
> "Roger D. Peng" <rpeng@jhsph.edu> writes:
> 
> 
>>I didn't compile this version of R myself but I believe readline is
>>compiled in -- the command history works and:
>>
>> > capabilities("cledit")
>>cledit
>>   TRUE
>>
>>Also,
>>
>> > Sys.getenv("HOME")
>>                   HOME
>>"/users/student/rpeng"
>>
>>which is in fact my home directory.
> 
> 
> I think sufficiently braindead versions of sh just will do this to you,
> including the one that comes default on Solaris 9:
> 
> rasch:~/>/usr/bin/sh
> $ ls ~
> ~: No such file or directory

I get the same result on our system.

> 
> This applies also to system() processing, e.g. 
> 
> system("mkdir -p ~/xxx") 
> 
> gets you a directory "~" with subdir "xxx". (NB: If you try this,
> think VERY carefully about how to remove that dir!!!!)

Yes, I've already made that mistake once.  Once.

-roger

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/

From b-h at mevik.net  Wed Jun 23 23:36:53 2004
From: b-h at mevik.net (b-h@mevik.net)
Date: Wed Jun 23 23:36:56 2004
Subject: [Rd] Similar error as (PR#6958)
Message-ID: <20040623213653.9AC95F473@slim.kubism.ku.dk>

When compiling R 1.9.1 on a Linux system with the environment variable
LANG=3Dno_NO, I get a similar error as reported in PR#6958:

## FACTS:

$ locale
LANG=3Dno_NO
LC_CTYPE=3D"no_NO"
LC_NUMERIC=3D"no_NO"
LC_TIME=3D"no_NO"
LC_COLLATE=3D"no_NO"
LC_MONETARY=3D"no_NO"
LC_MESSAGES=3D"no_NO"
LC_PAPER=3D"no_NO"
LC_NAME=3D"no_NO"
LC_ADDRESS=3D"no_NO"
LC_TELEPHONE=3D"no_NO"
LC_MEASUREMENT=3D"no_NO"
LC_IDENTIFICATION=3D"no_NO"
LC_ALL=3D
$ cd /usr/src/R/R-1.9.1
$ ./configure
[...]
$ make
[...]
make[3]: Entering directory `/usr/src/R/R-1.9.1/src/library/stats4'
building package 'stats4'
mkdir -p -- ../../../library/stats4/R
mkdir -p -- ../../../library/stats4/man
make[4]: Entering directory `/usr/src/R/R-1.9.1/src/library/stats4'
dumping R code in package 'stats4'
Error in eval(expr, envir, enclos) : couldn't find function "setGeneric"
Execution halted

If unset LANG before running make, the error doesn't appear, and the
build passes make check.

I've tried this on a Debian 3.0 stable system and a Red Hat 9 system,
with identical results.

## HYPOTHESIS:

>From Professor Ripley's answer to the original PR#6958, I would guess
the problem is that LC_COLLATE (in effect) is no_NO.  This matters for
the line

          cat `ls $(srcdir)/R/*.R` >> $${f}; \

in ${R_HOME}/src/library/stats4/Makefile.

With LC_COLLATE=3Dno_NO, ls will list the files in the order BIC.R
mle.R  AAA.R, making the require(methods) in AAA.R come last instead
of first in $${f}.  (In Norwegian, Aa is an old (but still often used in
names) way of writing the letter =C5, and lately, ls(1) has become
"intelligent" enough to sort them together, at the end of the
alphabet.)

## IDEA/SUGGESTION/RAMBLING:

Instead of relying on getting LC_COLLATE correct all places where that
is needed, perhaps one could use something like 111.R instead of AAA.R
(what to use instead of zzz.R I don't know).  Or perhaps use a
mechanism not based on sorting to ensure a file is read first or last?


--=20
Bj=F8rn-Helge Mevik

From p.dalgaard at biostat.ku.dk  Thu Jun 24 00:05:33 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu Jun 24 00:06:11 2004
Subject: [Rd] Similar error as (PR#6958)
In-Reply-To: <20040623213653.9AC95F473@slim.kubism.ku.dk>
References: <20040623213653.9AC95F473@slim.kubism.ku.dk>
Message-ID: <x2u0x253rm.fsf@biostat.ku.dk>

b-h@mevik.net writes:

> With LC_COLLATE=3Dno_NO, ls will list the files in the order BIC.R
> mle.R  AAA.R, making the require(methods) in AAA.R come last instead
> of first in $${f}.  (In Norwegian, Aa is an old (but still often used in
> names) way of writing the letter =C5, and lately, ls(1) has become
> "intelligent" enough to sort them together, at the end of the
> alphabet.)

Oh great... Same thing in da_DK actually, and for the same reason
(witness my surname).
 
> ## IDEA/SUGGESTION/RAMBLING:
> 
> Instead of relying on getting LC_COLLATE correct all places where that
> is needed, perhaps one could use something like 111.R instead of AAA.R
> (what to use instead of zzz.R I don't know).  Or perhaps use a
> mechanism not based on sorting to ensure a file is read first or last?

The cynic will say that some locale will probably have the idea of
sorting numerals after letters. Anyways, the right way of fixing it is
to prefix all those ls-constructs with LC_COLLATE=C, which really
isn't harder to enforce than any naming convention.

BTW, we just had two weeks of alpha and beta releases in which to
find this sort of stuff, you know....

BTW2, what happened to your mail? Been a while since I saw
quoted-unreadable damage like that.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From dmurdoch at pair.com  Thu Jun 24 03:31:56 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu Jun 24 03:31:55 2004
Subject: [Rd] Packages of snippets? (was: A way to list only variables or
	functions?)
In-Reply-To: <20040624092912.H11533@hortresearch.co.nz>
References: <Pine.LNX.4.44.0406201658590.3158-100000@gannet.stats>
	<OAEOKPIGCLDDHAEMCAKIKELECOAA.sdhyok@email.unc.edu>
	<vasdd01ctero57ub14dumk6g066lditfam@4ax.com>
	<40D6F5B0.4060501@lancaster.ac.uk>
	<20040624092912.H11533@hortresearch.co.nz>
Message-ID: <v8akd01911ne7v4kfmm81f61b7i61akdhr@4ax.com>

[Moved from r-help to r-devel]

On Thu, 24 Jun 2004 09:29:12 +1200, Patrick Connolly
<p.connolly@hortresearch.co.nz> wrote:

>I made myself a function in the S-PLUS days which I've modified to
>work in R.  It involved adding another few functions to add dates to
>objects.

This isn't something I'd use, since I prefer to keep objects in source
form, but I bet there are quite a few people who would use it if it
were generally available.

>I've toyed with the idea of adding an object size column but it's not
>important enough for my use.  Since I revisit projects over a period
>of years at times, the date is very useful information -- in fact,
>it's the main reason why I wrote it.
>
>My code is not elegant enough for an esteemed place on CRAN.  I could
>make it a lot better myself if I spent the time on it, but it works
>well enough for me as it is, so in that sense, it ain't broke.
>However, if anyone is interested in having such functionality my code
>could be a good starting point.

Inelegance is no excuse!  However, I do understand the feeling of
writing a nice little function, and not knowing exactly what to do
with it:  CRAN is crowded, and it does seem that an entire package
just to support one or two simple functions is a bit of overkill.

Can we work out a way to publish such things?  Here's a proposal, with
some serious flaws listed below.  Can someone fix them?

 - It should be easy to publish a short article describing your nice
little function, and making the code available to others.  (I think
this is already in place, either by publishing in RNews or Journal of
Statistical Software, as a code snippet.)

 - It should be easy for users to get it, together with man pages,
etc.  This is not in place, unless you package your function and send
it to CRAN.  What I'd propose is that a volunteer should act as an
editor of an "RNews" or "JSS" package, that contains *all* of the
snippets that have been published in RNews or JSS.

Some major flaws in this proposal are:

 - It needs a volunteer editor.

 - The editor would have to be organized, and willing to bug authors
for updates whenever R changes and breaks their snippet (or makes it
obsolete).  If there's no one willing to do this, the editor should
feel free to drop the snippet from the package.

 - There'd have to be a way for someone to see which snippets don't
have maintainers so have been dropped, but could be resurrected.

 - If it's successful, there'll be name clashes.  The editor should
try to head these off from the start, by setting some rules for what
kinds of names should be used for internal functions, and what public
names should look like.

 - There aren't actually that many snippets being published, because
it's hard work to convert something that works "well enough for me" to
something we'd like others to see.

Duncan Murdoch

From deleeuw at stat.ucla.edu  Thu Jun 24 04:29:20 2004
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Thu Jun 24 04:29:37 2004
Subject: [Rd] Packages of snippets? (was: A way to list only variables or
	functions?)
In-Reply-To: <v8akd01911ne7v4kfmm81f61b7i61akdhr@4ax.com>
References: <Pine.LNX.4.44.0406201658590.3158-100000@gannet.stats>
	<OAEOKPIGCLDDHAEMCAKIKELECOAA.sdhyok@email.unc.edu>
	<vasdd01ctero57ub14dumk6g066lditfam@4ax.com>
	<40D6F5B0.4060501@lancaster.ac.uk>
	<20040624092912.H11533@hortresearch.co.nz>
	<v8akd01911ne7v4kfmm81f61b7i61akdhr@4ax.com>
Message-ID: <4C658AC0-C586-11D8-8B53-000A95A67E82@stat.ucla.edu>

JSS does not have a "code snippet" section yet, but we
have been in the process of trying to start one for a long
time. We just haven't quite worked out how to define
snippets. They need some documentation. I was thinking
along the lines of the old JRSS-C or Applied Statistics
code section. Publishing in JSS would have the advantage
of a real journal publication, although a small one and
easy access to the code on the jstatsoft site.

Although we don't have the section yet, we do have
some editors willing to handle it. So one possible strategy
would be not to wait for precise instructions for authors,
keep the JRSS-C model in mind, and just submit. JSS
is working on TeX templates for articles, book reviews,
software reviews, and code snippets.

On Jun 23, 2004, at 18:31, Duncan Murdoch wrote:

> [Moved from r-help to r-devel]
>
> On Thu, 24 Jun 2004 09:29:12 +1200, Patrick Connolly
> <p.connolly@hortresearch.co.nz> wrote:
>
>> I made myself a function in the S-PLUS days which I've modified to
>> work in R.  It involved adding another few functions to add dates to
>> objects.
>
> This isn't something I'd use, since I prefer to keep objects in source
> form, but I bet there are quite a few people who would use it if it
> were generally available.
>
>> I've toyed with the idea of adding an object size column but it's not
>> important enough for my use.  Since I revisit projects over a period
>> of years at times, the date is very useful information -- in fact,
>> it's the main reason why I wrote it.
>>
>> My code is not elegant enough for an esteemed place on CRAN.  I could
>> make it a lot better myself if I spent the time on it, but it works
>> well enough for me as it is, so in that sense, it ain't broke.
>> However, if anyone is interested in having such functionality my code
>> could be a good starting point.
>
> Inelegance is no excuse!  However, I do understand the feeling of
> writing a nice little function, and not knowing exactly what to do
> with it:  CRAN is crowded, and it does seem that an entire package
> just to support one or two simple functions is a bit of overkill.
>
> Can we work out a way to publish such things?  Here's a proposal, with
> some serious flaws listed below.  Can someone fix them?
>
>  - It should be easy to publish a short article describing your nice
> little function, and making the code available to others.  (I think
> this is already in place, either by publishing in RNews or Journal of
> Statistical Software, as a code snippet.)
>
>  - It should be easy for users to get it, together with man pages,
> etc.  This is not in place, unless you package your function and send
> it to CRAN.  What I'd propose is that a volunteer should act as an
> editor of an "RNews" or "JSS" package, that contains *all* of the
> snippets that have been published in RNews or JSS.
>
> Some major flaws in this proposal are:
>
>  - It needs a volunteer editor.
>
>  - The editor would have to be organized, and willing to bug authors
> for updates whenever R changes and breaks their snippet (or makes it
> obsolete).  If there's no one willing to do this, the editor should
> feel free to drop the snippet from the package.
>
>  - There'd have to be a way for someone to see which snippets don't
> have maintainers so have been dropped, but could be resurrected.
>
>  - If it's successful, there'll be name clashes.  The editor should
> try to head these off from the start, by setting some rules for what
> kinds of names should be used for internal functions, and what public
> names should look like.
>
>  - There aren't actually that many snippets being published, because
> it's hard work to convert something that works "well enough for me" to
> something we'd like others to see.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From ggrothendieck at myway.com  Thu Jun 24 04:51:23 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu Jun 24 04:51:35 2004
Subject: [Rd] Packages of snippets? (was: A way to list only variables or
	functions?)
Message-ID: <20040624025123.003D639FD@mprdmxin.myway.com>



From:   Duncan Murdoch <dmurdoch@pair.com>

>I do understand the feeling of
>writing a nice little function, and not knowing exactly what to do
>with it: CRAN is crowded, and it does seem that an entire package
>just to support one or two simple functions is a bit of overkill.

>Can we work out a way to publish such things? Here's a 
>proposal, with some serious flaws listed below. 
>Can someone fix them?

This would be a good job for a wiki.  The key advantage is it
requires minimal maintenance.  

For an example of how this might work check out the code 
samples (snippets) for the Lua language on their wiki at:

   http://lua-users.org/wiki/SampleCode

Actually there is already an R wiki at:

   http://fawn.unibw-hamburg.de/cgi-bin/Rwiki.pl?RwikiHome

however, no one seems to use it.  If a critical mass were to
post some code snippets it might get off the ground.

From rpeng at jhsph.edu  Thu Jun 24 05:34:54 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu Jun 24 05:35:03 2004
Subject: [Rd] Packages of snippets?
In-Reply-To: <v8akd01911ne7v4kfmm81f61b7i61akdhr@4ax.com>
References: <Pine.LNX.4.44.0406201658590.3158-100000@gannet.stats>	<OAEOKPIGCLDDHAEMCAKIKELECOAA.sdhyok@email.unc.edu>	<vasdd01ctero57ub14dumk6g066lditfam@4ax.com>	<40D6F5B0.4060501@lancaster.ac.uk>	<20040624092912.H11533@hortresearch.co.nz>
	<v8akd01911ne7v4kfmm81f61b7i61akdhr@4ax.com>
Message-ID: <40DA4BDE.6040703@jhsph.edu>

Duncan, I very much like your idea of a RNews/JSS "package" which 
would contain code snippets from different contributors.  In 
fact, I would be willing to maintain such a package if it came 
into existence.  One note (I'm not sure if this is a flaw, 
strictly speaking), the package would only be able to cover 
functions.  So general "tips", for example those covered on the 
Rtips webpage (http://www.ku.edu/~pauljohn/R/Rtips.html), would 
not be able to make their way into the package.

Another issue is that as of now, there are many useful tools for 
checking for errors/problems in *packages*.  But there's no real 
way to check a single code file and a documentation file (say, an 
.Rd file).  One possibility might be to force contributors to 
submit something like a DESCRIPTION file for their function (with 
the necessary contact information), along with the code and a man 
page.  Then there would be anough material to make a fake package 
on which to run R CMD check.

-roger

Duncan Murdoch wrote:

> [Moved from r-help to r-devel]
> 
> On Thu, 24 Jun 2004 09:29:12 +1200, Patrick Connolly
> <p.connolly@hortresearch.co.nz> wrote:
> 
> 
>>I made myself a function in the S-PLUS days which I've modified to
>>work in R.  It involved adding another few functions to add dates to
>>objects.
> 
> 
> This isn't something I'd use, since I prefer to keep objects in source
> form, but I bet there are quite a few people who would use it if it
> were generally available.
> 
> 
>>I've toyed with the idea of adding an object size column but it's not
>>important enough for my use.  Since I revisit projects over a period
>>of years at times, the date is very useful information -- in fact,
>>it's the main reason why I wrote it.
>>
>>My code is not elegant enough for an esteemed place on CRAN.  I could
>>make it a lot better myself if I spent the time on it, but it works
>>well enough for me as it is, so in that sense, it ain't broke.
>>However, if anyone is interested in having such functionality my code
>>could be a good starting point.
> 
> 
> Inelegance is no excuse!  However, I do understand the feeling of
> writing a nice little function, and not knowing exactly what to do
> with it:  CRAN is crowded, and it does seem that an entire package
> just to support one or two simple functions is a bit of overkill.
> 
> Can we work out a way to publish such things?  Here's a proposal, with
> some serious flaws listed below.  Can someone fix them?
> 
>  - It should be easy to publish a short article describing your nice
> little function, and making the code available to others.  (I think
> this is already in place, either by publishing in RNews or Journal of
> Statistical Software, as a code snippet.)
> 
>  - It should be easy for users to get it, together with man pages,
> etc.  This is not in place, unless you package your function and send
> it to CRAN.  What I'd propose is that a volunteer should act as an
> editor of an "RNews" or "JSS" package, that contains *all* of the
> snippets that have been published in RNews or JSS.
> 
> Some major flaws in this proposal are:
> 
>  - It needs a volunteer editor.
> 
>  - The editor would have to be organized, and willing to bug authors
> for updates whenever R changes and breaks their snippet (or makes it
> obsolete).  If there's no one willing to do this, the editor should
> feel free to drop the snippet from the package.
> 
>  - There'd have to be a way for someone to see which snippets don't
> have maintainers so have been dropped, but could be resurrected.
> 
>  - If it's successful, there'll be name clashes.  The editor should
> try to head these off from the start, by setting some rules for what
> kinds of names should be used for internal functions, and what public
> names should look like.
> 
>  - There aren't actually that many snippets being published, because
> it's hard work to convert something that works "well enough for me" to
> something we'd like others to see.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/

From ripley at stats.ox.ac.uk  Thu Jun 24 08:26:33 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jun 24 08:26:39 2004
Subject: [Rd] Similar error as (PR#6958)
In-Reply-To: <x2u0x253rm.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0406240720300.1575-100000@gannet.stats>

On 24 Jun 2004, Peter Dalgaard wrote:

> b-h@mevik.net writes:
> 
> > With LC_COLLATE=3Dno_NO, ls will list the files in the order BIC.R
> > mle.R  AAA.R, making the require(methods) in AAA.R come last instead
> > of first in $${f}.  (In Norwegian, Aa is an old (but still often used in
> > names) way of writing the letter =C5, and lately, ls(1) has become
> > "intelligent" enough to sort them together, at the end of the
> > alphabet.)
> 
> Oh great... Same thing in da_DK actually, and for the same reason
> (witness my surname).
>  
> > ## IDEA/SUGGESTION/RAMBLING:
> > 
> > Instead of relying on getting LC_COLLATE correct all places where that
> > is needed, perhaps one could use something like 111.R instead of AAA.R
> > (what to use instead of zzz.R I don't know).  Or perhaps use a
> > mechanism not based on sorting to ensure a file is read first or last?
> 
> The cynic will say that some locale will probably have the idea of
> sorting numerals after letters. Anyways, the right way of fixing it is
> to prefix all those ls-constructs with LC_COLLATE=C, which really
> isn't harder to enforce than any naming convention.

Right, but hard to find.  This works on Windows: unfortunately Unix has a
separate Makefile for every standard package and they are not even in the
same style so my pattern-matching failed.  It seems I missed just one 
(some others are in stub packages which only have one file).

> BTW, we just had two weeks of alpha and beta releases in which to
> find this sort of stuff, you know....

Ye...s!

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Thu Jun 24 08:26:41 2004
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jun 24 08:26:43 2004
Subject: [Rd] Similar error as (PR#6958)
Message-ID: <20040624062641.618E2EAE3@slim.kubism.ku.dk>

On 24 Jun 2004, Peter Dalgaard wrote:

> b-h@mevik.net writes:
> 
> > With LC_COLLATE=3Dno_NO, ls will list the files in the order BIC.R
> > mle.R  AAA.R, making the require(methods) in AAA.R come last instead
> > of first in $${f}.  (In Norwegian, Aa is an old (but still often used in
> > names) way of writing the letter =C5, and lately, ls(1) has become
> > "intelligent" enough to sort them together, at the end of the
> > alphabet.)
> 
> Oh great... Same thing in da_DK actually, and for the same reason
> (witness my surname).
>  
> > ## IDEA/SUGGESTION/RAMBLING:
> > 
> > Instead of relying on getting LC_COLLATE correct all places where that
> > is needed, perhaps one could use something like 111.R instead of AAA.R
> > (what to use instead of zzz.R I don't know).  Or perhaps use a
> > mechanism not based on sorting to ensure a file is read first or last?
> 
> The cynic will say that some locale will probably have the idea of
> sorting numerals after letters. Anyways, the right way of fixing it is
> to prefix all those ls-constructs with LC_COLLATE=C, which really
> isn't harder to enforce than any naming convention.

Right, but hard to find.  This works on Windows: unfortunately Unix has a
separate Makefile for every standard package and they are not even in the
same style so my pattern-matching failed.  It seems I missed just one 
(some others are in stub packages which only have one file).

> BTW, we just had two weeks of alpha and beta releases in which to
> find this sort of stuff, you know....

Ye...s!

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Thu Jun 24 09:04:40 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu Jun 24 09:05:13 2004
Subject: [Rd] Similar error as (PR#6958)
In-Reply-To: <Pine.LNX.4.44.0406240720300.1575-100000@gannet.stats>
References: <Pine.LNX.4.44.0406240720300.1575-100000@gannet.stats>
Message-ID: <x2brj9xwqf.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> > BTW, we just had two weeks of alpha and beta releases in which to
> > find this sort of stuff, you know....
> 
> Ye...s!

[I even might have found it myself, but I set LANG=C, LC_CTYPE=da_DK
in my shells because I otherwise go nuts from the semi-translated
system messages ("hiding the randomness frog", etc..)]

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Thu Jun 24 09:05:14 2004
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Thu Jun 24 09:05:16 2004
Subject: [Rd] Similar error as (PR#6958)
Message-ID: <20040624070514.80D0FEAD7@slim.kubism.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> > BTW, we just had two weeks of alpha and beta releases in which to
> > find this sort of stuff, you know....
> 
> Ye...s!

[I even might have found it myself, but I set LANG=C, LC_CTYPE=da_DK
in my shells because I otherwise go nuts from the semi-translated
system messages ("hiding the randomness frog", etc..)]

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From cirovic at usc.edu  Thu Jun 24 09:36:45 2004
From: cirovic at usc.edu (Ita Cirovic)
Date: Thu Jun 24 09:36:40 2004
Subject: [Rd] R in Visual.Net studio
Message-ID: <006801c459be$00209490$8e69fea9@finmetrikaita>

Can R be used in Visual.Net studio and if so is there any documentation on
how R can be used in this manner? More precisely, is there any
documentation/manual regarding R.dll and it usage? Thanks.

Ita

	[[alternative HTML version deleted]]

From ripley at stats.ox.ac.uk  Thu Jun 24 10:17:03 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jun 24 10:17:06 2004
Subject: [Rd] R in Visual.Net studio
In-Reply-To: <006801c459be$00209490$8e69fea9@finmetrikaita>
Message-ID: <Pine.LNX.4.44.0406240913340.5935-100000@gannet.stats>

You have already asked this on S-news and received a reply.  Do look in 
src/gnuwin32/front-ends for a worked example (and a README).

On Thu, 24 Jun 2004, Ita Cirovic wrote:

> Can R be used in Visual.Net studio and if so is there any documentation on
> how R can be used in this manner? More precisely, is there any
> documentation/manual regarding R.dll and it usage? Thanks.

I didn't receive _any_ acknowledgement for already answering this.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From B.Rowlingson at lancaster.ac.uk  Thu Jun 24 10:43:32 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu Jun 24 10:43:35 2004
Subject: [Rd] Packages of snippets? (was: A way to list only variables
	or	functions?)
In-Reply-To: <20040624025123.003D639FD@mprdmxin.myway.com>
References: <20040624025123.003D639FD@mprdmxin.myway.com>
Message-ID: <40DA9434.7000804@lancaster.ac.uk>


> For an example of how this might work check out the code 
> samples (snippets) for the Lua language on their wiki at:
> 
>    http://lua-users.org/wiki/SampleCode
> 
> Actually there is already an R wiki at:
> 
>    http://fawn.unibw-hamburg.de/cgi-bin/Rwiki.pl?RwikiHome
> 
> however, no one seems to use it.  If a critical mass were to
> post some code snippets it might get off the ground.

  Just to add another system to the pile of snippet-libraries, there's 
http://www.zopelabs.com/ , which is a 'cookbook' site of 'recipes' for 
Zope. Its a categorised submission system with comments and ratings 
given by the other users. A bit less free-form and hence less chaotic 
than a (poorly-managed) wiki.

  The source code is available, but I've not played with it (yet). Its 
not that active.

Baz

From dmurdoch at pair.com  Thu Jun 24 13:12:31 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu Jun 24 13:12:40 2004
Subject: [Rd] Packages of snippets? (was: A way to list only variables or
	functions?)
In-Reply-To: <20040624025123.003D639FD@mprdmxin.myway.com>
References: <20040624025123.003D639FD@mprdmxin.myway.com>
Message-ID: <kfdld09l4q25fcp2u29kibtko4jttd6ha0@4ax.com>

On Wed, 23 Jun 2004 22:51:23 -0400 (EDT), "Gabor Grothendieck"
<ggrothendieck@myway.com> wrote:

>
>From:   Duncan Murdoch <dmurdoch@pair.com>
>
>>I do understand the feeling of
>>writing a nice little function, and not knowing exactly what to do
>>with it: CRAN is crowded, and it does seem that an entire package
>>just to support one or two simple functions is a bit of overkill.
>
>>Can we work out a way to publish such things? Here's a 
>>proposal, with some serious flaws listed below. 
>>Can someone fix them?
>
>This would be a good job for a wiki.  The key advantage is it
>requires minimal maintenance.  

I think a wiki would be fine for making the snippets available, but
code maintenance is essential.  That's why CRAN is more useful than
Statlib:  it has active maintainers who enforce documentation
standards and try to make sure that if you install a CRAN package in a
current version of R it will work properly.

Duncan Murdoch

From dmurdoch at pair.com  Thu Jun 24 13:16:43 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu Jun 24 13:17:32 2004
Subject: [Rd] Packages of snippets?
In-Reply-To: <40DA4BDE.6040703@jhsph.edu>
References: <Pine.LNX.4.44.0406201658590.3158-100000@gannet.stats>	<OAEOKPIGCLDDHAEMCAKIKELECOAA.sdhyok@email.unc.edu>	<vasdd01ctero57ub14dumk6g066lditfam@4ax.com>	<40D6F5B0.4060501@lancaster.ac.uk>	<20040624092912.H11533@hortresearch.co.nz>
	<v8akd01911ne7v4kfmm81f61b7i61akdhr@4ax.com>
	<40DA4BDE.6040703@jhsph.edu>
Message-ID: <ppdld0h8q3p3rbpmiauovo6tdfpjbqve1f@4ax.com>

On Wed, 23 Jun 2004 23:34:54 -0400, "Roger D. Peng" <rpeng@jhsph.edu>
wrote:

>Duncan, I very much like your idea of a RNews/JSS "package" which 
>would contain code snippets from different contributors.  In 
>fact, I would be willing to maintain such a package if it came 
>into existence.  One note (I'm not sure if this is a flaw, 
>strictly speaking), the package would only be able to cover 
>functions.  So general "tips", for example those covered on the 
>Rtips webpage (http://www.ku.edu/~pauljohn/R/Rtips.html), would 
>not be able to make their way into the package.

I'm not so sure about that.  Packages have a variety of mechanisms for
including demos, vignettes, and other documentation.  It would just
require working out a way to present the stuff so that people could
find what they need.

Duncan Murdoch

From andy_liaw at merck.com  Thu Jun 24 15:42:29 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Jun 24 15:43:10 2004
Subject: [Rd] news file included in source but not binary package
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7F68@usrymx25.merck.com>

Dear R-devel,

I've noticed that when I place a `NEWS' file in the top-level directory for
a package, then do R CMD build mypkg, the file gets included in the .tar.gz
file.  However, if I do R CMD build --binary mypkg, the `NEWS' file does not
get included in the .zip file.  Is this intentional?  Is there a way I can
get such a file included in the pre-compiled package automatically?

Best,
Andy

Andy Liaw, PhD
Biometrics Research      PO Box 2000, RY33-300     
Merck Research Labs           Rahway, NJ 07065
mailto:andy_liaw@merck.com        732-594-0820

From rpeng at jhsph.edu  Thu Jun 24 15:54:49 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu Jun 24 15:54:52 2004
Subject: [Rd] news file included in source but not binary package
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7F68@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7F68@usrymx25.merck.com>
Message-ID: <40DADD29.5020101@jhsph.edu>

I think you need to put it in the inst/ subdirectory.

-roger

Liaw, Andy wrote:
> Dear R-devel,
> 
> I've noticed that when I place a `NEWS' file in the top-level directory for
> a package, then do R CMD build mypkg, the file gets included in the .tar.gz
> file.  However, if I do R CMD build --binary mypkg, the `NEWS' file does not
> get included in the .zip file.  Is this intentional?  Is there a way I can
> get such a file included in the pre-compiled package automatically?
> 
> Best,
> Andy
> 
> Andy Liaw, PhD
> Biometrics Research      PO Box 2000, RY33-300     
> Merck Research Labs           Rahway, NJ 07065
> mailto:andy_liaw@merck.com        732-594-0820
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/

From ripley at stats.ox.ac.uk  Thu Jun 24 15:59:45 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jun 24 15:59:50 2004
Subject: [Rd] news file included in source but not binary package
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7F68@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0406241459060.10212-100000@gannet.stats>

Use the inst directory - it's documented in Writing R Extensions, and has 
lots of examples on CRAN.

On Thu, 24 Jun 2004, Liaw, Andy wrote:

> I've noticed that when I place a `NEWS' file in the top-level directory for
> a package, then do R CMD build mypkg, the file gets included in the .tar.gz
> file.  However, if I do R CMD build --binary mypkg, the `NEWS' file does not
> get included in the .zip file.  Is this intentional?  Is there a way I can
> get such a file included in the pre-compiled package automatically?


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From andy_liaw at merck.com  Thu Jun 24 16:37:49 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Jun 24 16:38:08 2004
Subject: [Rd] news file included in source but not binary package
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7F6B@usrymx25.merck.com>

Thanks to Brian, Roger and Dirk for the pointer to inst.  I do remember it,
but R-exts doesn't really suggest what that directory is for, merely what
would happen to files placed there.  For a source package, though, that
seems a rather obscure place to put a `NEWS' file...

On a slightly different topic:  May I suggest inclusion of something like
the following (suitably modified, if need be) in the next version of R (and
perhaps even advertise it in the startup message)?

news <- function(package=NULL, lib.loc=NULL) {
    if (is.null(package)) {
        file.show(file.path(R.home(), "NEWS"),
                  title=paste("NEWS for R-",
                  paste(R.version[c("major", "minor")], collapse=".")))
    } else {
        ## check if package is installed
        pkgs <- installed.packages(lib.loc=lib.loc)
        which <- match(package, pkgs[, "Package"])
        if (is.na(which)) stop(package, "not found")
        newsfile <- file.path(pkgs[which, "LibPath"], "NEWS")
        if (!file.exists(newsfile)) stop("Sorry, no news from Lake
Wobegon...")
        file.show(newsfile, title=paste("NEWS for ",
                            paste(pkgs[which, c("Package", "Version")],
                                  collapse="_")))
    }
}

Best,
Andy

> From: Prof Brian Ripley
> 
> Use the inst directory - it's documented in Writing R 
> Extensions, and has 
> lots of examples on CRAN.
> 
> On Thu, 24 Jun 2004, Liaw, Andy wrote:
> 
> > I've noticed that when I place a `NEWS' file in the 
> top-level directory for
> > a package, then do R CMD build mypkg, the file gets 
> included in the .tar.gz
> > file.  However, if I do R CMD build --binary mypkg, the 
> `NEWS' file does not
> > get included in the .zip file.  Is this intentional?  Is 
> there a way I can
> > get such a file included in the pre-compiled package automatically?
> 
> 
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
>

From andy_liaw at merck.com  Thu Jun 24 20:05:20 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Jun 24 20:05:45 2004
Subject: [Rd] typo in R-admin
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7F6E@usrymx25.merck.com>

Just want to point out what seems to be a typo in R-admin.texi (still there
in R-devel snapshot of 2004-06-24).  Line 1698 of R-admin.texi probably
should read:

@section Java Virtual Machines on Mac

Best,
Andy

Andy Liaw, PhD
Biometrics Research      PO Box 2000, RY33-300     
Merck Research Labs           Rahway, NJ 07065
mailto:andy_liaw@merck.com        732-594-0820

From dmurdoch at pair.com  Thu Jun 24 20:54:43 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu Jun 24 20:56:29 2004
Subject: [Rd] typo in R-admin
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7F6E@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7F6E@usrymx25.merck.com>
Message-ID: <8r8md0lavssdqb2vq29n0qrrajpjbi3vch@4ax.com>

On Thu, 24 Jun 2004 14:05:20 -0400, "Liaw, Andy" <andy_liaw@merck.com>
wrote :

>Just want to point out what seems to be a typo in R-admin.texi (still there
>in R-devel snapshot of 2004-06-24).  Line 1698 of R-admin.texi probably
>should read:
>
>@section Java Virtual Machines on Mac

Right, thanks.

Duncan Murdoch

From Friedrich.Leisch at ci.tuwien.ac.at  Thu Jun 24 22:14:53 2004
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Thu Jun 24 22:30:58 2004
Subject: [Rd] news file included in source but not binary package
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7F6B@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7F6B@usrymx25.merck.com>
Message-ID: <16603.13885.913179.863810@celebrian.ci.tuwien.ac.at>

>>>>> On Thu, 24 Jun 2004 10:37:49 -0400,
>>>>> Liaw, Andy (LA) wrote:

  > Thanks to Brian, Roger and Dirk for the pointer to inst.  I do remember it,
  > but R-exts doesn't really suggest what that directory is for, merely what
  > would happen to files placed there.  For a source package, though, that
  > seems a rather obscure place to put a `NEWS' file...

I agree ...

  > On a slightly different topic:  May I suggest inclusion of something like
  > the following (suitably modified, if need be) in the next version of R (and
  > perhaps even advertise it in the startup message)?

  > news <- function(package=NULL, lib.loc=NULL) {
  >     if (is.null(package)) {
  >         file.show(file.path(R.home(), "NEWS"),
  >                   title=paste("NEWS for R-",
  >                   paste(R.version[c("major", "minor")], collapse=".")))
  >     } else {
  >         ## check if package is installed
  >         pkgs <- installed.packages(lib.loc=lib.loc)
  >         which <- match(package, pkgs[, "Package"])
  >         if (is.na(which)) stop(package, "not found")
  >         newsfile <- file.path(pkgs[which, "LibPath"], "NEWS")
  >         if (!file.exists(newsfile)) stop("Sorry, no news from Lake
  > Wobegon...")
  >         file.show(newsfile, title=paste("NEWS for ",
  >                             paste(pkgs[which, c("Package", "Version")],
  >                                   collapse="_")))
  >     }
  > }


You might want to take a look at the system.file() function, that
reduces the above quite condiderably :-)

But to get to the heart of the email (something similar was proposed
by Greg Warnes a few weeks ago): We should definetely provide a simple
mechanism to see the latest changes in a package.

Question: I am aware of files calles NEWS and ChangeLog (or CHANGELOG,
etc.) holding the relevant information ... are there any others we
want/need to respect?

best,
fritz

From dmurdoch at pair.com  Thu Jun 24 23:29:04 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu Jun 24 23:29:11 2004
Subject: [Rd] news file included in source but not binary package
In-Reply-To: <16603.13885.913179.863810@celebrian.ci.tuwien.ac.at>
References: <3A822319EB35174CA3714066D590DCD504AF7F6B@usrymx25.merck.com>
	<16603.13885.913179.863810@celebrian.ci.tuwien.ac.at>
Message-ID: <3mhmd0p5m8lduueji1r7ftd49c6d3v3h8a@4ax.com>

On Thu, 24 Jun 2004 22:14:53 +0200, Friedrich.Leisch@ci.tuwien.ac.at
wrote:


>Question: I am aware of files calles NEWS and ChangeLog (or CHANGELOG,
>etc.) holding the relevant information ... are there any others we
>want/need to respect?

R itself also uses CHANGES (in src/gnuwin32).  There was some talk a
while back about changing this to NEWS.win, and having NEWS.mac, etc.

Duncan Murdoch

From andy_liaw at merck.com  Fri Jun 25 01:33:00 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Jun 25 01:33:21 2004
Subject: [Rd] news file included in source but not binary package
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7F71@usrymx25.merck.com>

> From: Friedrich Leisch
> 
[snip]
> You might want to take a look at the system.file() function, that
> reduces the above quite considerably :-)

Indeed:

news <- function(package=NULL, lib.loc=NULL) {
    if (is.null(package)) {
        newsfile <- file.path(R.home(), "NEWS")
        title <- paste("NEWS for R-",
                       paste(R.version[c("major", "minor")], collapse="."))
    } else {
        newsfile <- file.path(system.file(package=package, lib.loc=lib.loc),
                              "NEWS")
        title <- paste("NEWS for", package)
    }
    file.show(newsfile, title=title)
}

[One might want to add the pager argument as in file.show.]
 
> But to get to the heart of the email (something similar was proposed
> by Greg Warnes a few weeks ago): We should definetely provide a simple
> mechanism to see the latest changes in a package.
> 
> Question: I am aware of files calles NEWS and ChangeLog (or CHANGELOG,
> etc.) holding the relevant information ... are there any others we
> want/need to respect?

Yes, I do recall the thread that Greg started.  This is sort of trying to
get it going again...  Could we just settle on a standard name and be done
with it?  Since base R uses NEWS, why not just use that for all packages,
and use NEWS.platform as Duncan suggested (in the top-level directory,
rather than platform-specific directories)?

[A saying I've heard mentioned in an industry-standard committee meeting:
`Demoncracy is not about what you want, but what you can live with.']

Best,
Andy


> best,
> fritz
> 
>

From maechler at stat.math.ethz.ch  Fri Jun 25 09:19:40 2004
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Fri Jun 25 09:19:44 2004
Subject: [Rd] Bug in parse(text = <long polynom>) (PR#7022)
Message-ID: <20040625071940.9096610871@slim.kubism.ku.dk>

Merci beaucoup, Jean,
for the bug report -- which I'm no "completeing" to R-bugs

>>>>> "Jean" == Jean Coursol <coursol@cristal.math.u-psud.fr>
>>>>>     on Thu, 24 Jun 2004 15:22:37 +0200 (CEST) writes:

    Jean> I was exploring the polynom library with students:

 <and found a segmentation fault from parsing a long expression>

The following is reproducible also with the current version of R
1.9.1 [on RHEL Linux]

horner <- function(p) {
        a <- as.character(rev(unclass(p)))
        h <- a[1]
        while (length(a <- a[-1]) > 0) {
            h <- paste("x*(", h, ")", sep = "")
            if (a[1] != 0)
                h <- paste(a[1], " + ", h, sep = "")
        }
        h
}

library(polynom)

x <- polynomial()
z <- (1+x)^100
zh <- horner(z)

nchar(zh)
## [1] 2404

parse(text = zh) # => Segmentation fault

## where Jean wrote  '(it ran one time !!!)'
## and it happens the first time for me.

From p.dalgaard at biostat.ku.dk  Fri Jun 25 09:32:48 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Jun 25 09:33:24 2004
Subject: [Rd] Bug in parse(text = <long polynom>) (PR#7022)
In-Reply-To: <20040625071940.9096610871@slim.kubism.ku.dk>
References: <20040625071940.9096610871@slim.kubism.ku.dk>
Message-ID: <x2smckrt27.fsf@biostat.ku.dk>

maechler@stat.math.ethz.ch writes:

> Merci beaucoup, Jean,
> for the bug report -- which I'm no "completeing" to R-bugs

But you're still requiring library(polynom) for triggering the bug. If
we are to be sure that it is not a bug in that package but a bug in R,
you need to include the definition of at least polynomial() with the
instructions to reproduce the effect...

[snip]
> library(polynom)
> 
> x <- polynomial()
> z <- (1+x)^100
> zh <- horner(z)


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Fri Jun 25 10:09:11 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jun 25 10:09:18 2004
Subject: [Rd] Bug in parse(text = <long polynom>) (PR#7022)
In-Reply-To: <x2smckrt27.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0406250849040.32191-100000@gannet.stats>

On 25 Jun 2004, Peter Dalgaard wrote:

> maechler@stat.math.ethz.ch writes:
> 
> > Merci beaucoup, Jean,
> > for the bug report -- which I'm no "completeing" to R-bugs
> 
> But you're still requiring library(polynom) for triggering the bug. If
> we are to be sure that it is not a bug in that package 

There seems to be in that it is not using the R code from `S Programming' 
p.95, according to the original report.

> but a bug in R,
> you need to include the definition of at least polynomial() with the
> instructions to reproduce the effect...
> 
> [snip]
> > library(polynom)
> > 
> > x <- polynomial()
> > z <- (1+x)^100
> > zh <- horner(z)

Hmm, horner is not in the package!   It is a function internal to 
as.function.polynomial.

as.function(z) segfaults at

#0  R_TextBufferGetc (txtb=0xffda00)
    at /users/ripley/R/cvs/R-devel/src/main/iosupport.c:232
#1  0x080c7623 in text_getc () at ./gram.y:1011
#2  0x080c6eed in xxgetc () at ./gram.y:291
#3  0x080c7bc5 in token () at ./gram.y:1496
#4  0x080c85c5 in Rf_yylex () at ./gram.y:1894
#5  0x080c8bef in Rf_yyparse () at /usr/share/bison/bison.simple:573
#6  0x080c997e in R_Parse1 (status=0xbfffda58) at ./gram.y:941
#7  0x080c9aad in R_Parse (n=-1, status=0xbfffda58) at ./gram.y:1076
#8  0x080c9c1e in R_ParseVector (text=0xffffffff, n=-1, status=0xffffffff)
    at ./gram.y:1153
#9  0x0813c3d9 in do_parse (call=0x8500c00, op=0xffffffff, args=0x84fb898,
    env=0x8ed385c) at /users/ripley/R/cvs/R-devel/src/main/source.c:68

so that's definitely a bug in R. It is being asked to parse a very long
line and a highly-nested expression.  I suspect the latter is the problem.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Fri Jun 25 10:09:21 2004
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jun 25 10:09:23 2004
Subject: [Rd] Bug in parse(text = <long polynom>) (PR#7022)
Message-ID: <20040625080921.849D2108C4@slim.kubism.ku.dk>

On 25 Jun 2004, Peter Dalgaard wrote:

> maechler@stat.math.ethz.ch writes:
> 
> > Merci beaucoup, Jean,
> > for the bug report -- which I'm no "completeing" to R-bugs
> 
> But you're still requiring library(polynom) for triggering the bug. If
> we are to be sure that it is not a bug in that package 

There seems to be in that it is not using the R code from `S Programming' 
p.95, according to the original report.

> but a bug in R,
> you need to include the definition of at least polynomial() with the
> instructions to reproduce the effect...
> 
> [snip]
> > library(polynom)
> > 
> > x <- polynomial()
> > z <- (1+x)^100
> > zh <- horner(z)

Hmm, horner is not in the package!   It is a function internal to 
as.function.polynomial.

as.function(z) segfaults at

#0  R_TextBufferGetc (txtb=0xffda00)
    at /users/ripley/R/cvs/R-devel/src/main/iosupport.c:232
#1  0x080c7623 in text_getc () at ./gram.y:1011
#2  0x080c6eed in xxgetc () at ./gram.y:291
#3  0x080c7bc5 in token () at ./gram.y:1496
#4  0x080c85c5 in Rf_yylex () at ./gram.y:1894
#5  0x080c8bef in Rf_yyparse () at /usr/share/bison/bison.simple:573
#6  0x080c997e in R_Parse1 (status=0xbfffda58) at ./gram.y:941
#7  0x080c9aad in R_Parse (n=-1, status=0xbfffda58) at ./gram.y:1076
#8  0x080c9c1e in R_ParseVector (text=0xffffffff, n=-1, status=0xffffffff)
    at ./gram.y:1153
#9  0x0813c3d9 in do_parse (call=0x8500c00, op=0xffffffff, args=0x84fb898,
    env=0x8ed385c) at /users/ripley/R/cvs/R-devel/src/main/source.c:68

so that's definitely a bug in R. It is being asked to parse a very long
line and a highly-nested expression.  I suspect the latter is the problem.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Fri Jun 25 10:15:44 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Jun 25 10:15:46 2004
Subject: [Rd] news file included in source but not binary package
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7F71@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7F71@usrymx25.merck.com>
Message-ID: <16603.57136.919489.318322@gargle.gargle.HOWL>

>>>>> "AndyL" == Liaw, Andy <andy_liaw@merck.com>
>>>>>     on Thu, 24 Jun 2004 19:33:00 -0400 writes:

    >> From: Friedrich Leisch
    >> 
 
    >> But to get to the heart of the email (something similar
    >> was proposed by Greg Warnes a few weeks ago): We should
    >> definetely provide a simple mechanism to see the latest
    >> changes in a package.
    >> 
    >> Question: I am aware of files calles NEWS and ChangeLog
    >> (or CHANGELOG, etc.) holding the relevant information
    >> ... are there any others we want/need to respect?

    AndyL> Yes, I do recall the thread that Greg started.  This
    AndyL> is sort of trying to get it going again...  

yes, thanks, Andy!

    AndyL> Could we just settle on a standard name and be done
    AndyL> with it?  Since base R uses NEWS, why not just use
    AndyL> that for all packages,

We emacs fans would definitely additionally want 'ChangeLog' (as
per Fritz' proposal).
This has been a standard name for decades with a very convenient
emacs interface ['C-x 4 a'] to create and update the file.

    AndyL> and use NEWS.platform as Duncan suggested
    AndyL> (in the top-level directory, rather than
    AndyL> platform-specific directories)?

I agree.  

BTW, both NEWS and ChangeLog have specific (but different) syntax
the main difference that NEWS entries are anonymous and not
dated whereas ChangeLog is a "log", i.e. has dated entries.
Kurt (or Fritz?) already mentioned in the earlier
'Greg-initiated' thread that it might be interesting to consider
automatic conversion of these files to (e.g.) html.  
But such possibilities should not hinder us from agreeing *now*
that e.g. files with regexps
----------
m{NEWS.*}
m{Change(s|Log)}i
----------
should automatically be taken from the source toplevel directory
and put into <installed>/doc/<filename>.txt
				       ^^^^
(the '.txt' maybe a good idea idea because the ./doc/ directory
 can be easily opened in the browser in some interfaces)

Martin

From maechler at stat.math.ethz.ch  Fri Jun 25 10:19:31 2004
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Fri Jun 25 10:19:33 2004
Subject: [Rd] Bug in parse(text = <long polynom>) (PR#7022)
Message-ID: <20040625081931.47B55108C5@slim.kubism.ku.dk>
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=

From chris.jackson at imperial.ac.uk  Fri Jun 25 10:33:17 2004
From: chris.jackson at imperial.ac.uk (Chris Jackson)
Date: Fri Jun 25 10:33:22 2004
Subject: [Rd] news file included in source but not binary package
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7F71@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7F71@usrymx25.merck.com>
Message-ID: <40DBE34D.10607@imperial.ac.uk>

Liaw, Andy wrote:
>> From: Friedrich Leisch
>> Question: I am aware of files calles NEWS and ChangeLog (or CHANGELOG,
>> etc.) holding the relevant information ... are there any others we
>> want/need to respect?
> 
> Yes, I do recall the thread that Greg started.  This is sort of trying to
> get it going again...  Could we just settle on a standard name and be done
> with it?  Since base R uses NEWS, why not just use that for all packages,
> and use NEWS.platform as Duncan suggested (in the top-level directory,
> rather than platform-specific directories)?


For what it's worth, my package uses the file NEWS to summarise
the visible changes to the package user.  ChangeLog details
the exact changes in the internal code, in a standard(ish) format with 
each change labelled by date and contributor.   This seems to be a GNU 
convention.  Then NEWS gets put in inst/ so binary package users can see 
it, while ChangeLog stays in the top of the source package as it's only 
of interest to developers.

Chris

-- 
Christopher Jackson <chris.jackson@imperial.ac.uk>, Research Associate,
Department of Epidemiology and Public Health, Imperial College
School of Medicine, Norfolk Place, London W2 1PG, tel. 020 759 43371

From ripley at stats.ox.ac.uk  Fri Jun 25 10:36:48 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jun 25 10:36:53 2004
Subject: [Rd] news file included in source but not binary package
In-Reply-To: <16603.57136.919489.318322@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.44.0406250927090.32429-100000@gannet.stats>

On Fri, 25 Jun 2004, Martin Maechler wrote:

> We emacs fans would definitely additionally want 'ChangeLog' (as
> per Fritz' proposal).
> This has been a standard name for decades with a very convenient
> emacs interface ['C-x 4 a'] to create and update the file.

Only if it is in a certain very rigid format.  Unfortunately Emacs 
interferes with attempts to edit a file called ChangeLog in other people's 
formats.

>     AndyL> and use NEWS.platform as Duncan suggested
>     AndyL> (in the top-level directory, rather than
>     AndyL> platform-specific directories)?
> 
> I agree.  
> 
> BTW, both NEWS and ChangeLog have specific (but different) syntax
> the main difference that NEWS entries are anonymous and not
> dated whereas ChangeLog is a "log", i.e. has dated entries.

To my mind the main difference is that NEWS is for interesting information 
for users, and ChangeLog for notes for developers.

> Kurt (or Fritz?) already mentioned in the earlier
> 'Greg-initiated' thread that it might be interesting to consider
> automatic conversion of these files to (e.g.) html.  
> But such possibilities should not hinder us from agreeing *now*
> that e.g. files with regexps
> ----------
> m{NEWS.*}
> m{Change(s|Log)}i
> ----------

And what software you propose to evaluate those regexps (which look like 
Perl commands to me)?

> should automatically be taken from the source toplevel directory
> and put into <installed>/doc/<filename>.txt
> 			       ^^^^
> (the '.txt' maybe a good idea idea because the ./doc/ directory
>  can be easily opened in the browser in some interfaces)

I disagree.  Lots of packages already install their documentation files
where they want them, and we should not retrospectively change what the
maintainers did.  (In at least one case I deliberately do not install a
ChangeLog file, which refers to source files which are also not
installed.)  Those people who have inst/doc and a nice index probably
don't want other files added there.

Let's start from the position that we already have a mechanism for 
installing files and encourage its use.  We may want to add some 
guidelines on the use of information files, but we cannot impose them 
retrospectively.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Fri Jun 25 10:42:19 2004
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Fri Jun 25 10:42:21 2004
Subject: [Rd] Bug in parse(text = <long polynom>) (PR#7022)
Message-ID: <20040625084219.57E7D108CF@slim.kubism.ku.dk>

>>>>> "MM" == Martin Maechler <maechler@stat.math.ethz.ch>
>>>>>     on Fri, 25 Jun 2004 10:19:19 +0200 writes:

>>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
>>>>>     on 25 Jun 2004 09:32:48 +0200 writes:

    PD> But you're still requiring library(polynom) for
    PD> triggering the bug. If we are to be sure that it is not
    PD> a bug in that package but a bug in R, you need to
    PD> include the definition of at least polynomial() with the
    PD> instructions to reproduce the effect...

    MM> well, try this (without package polynom):

    >> parse(text="1 + x*(100 + x*(4950 + x*(161700 + x*(3921225 
....

and then I had the full length 2404 string which---I had
"known in advance" (Murphy's law)--- has been thrown up
before it got back to R-devel, actually by my mailer already.

Now this should be easier to pass through:

 tt <- tempfile() 
 download.file("ftp://ftp.stat.math.ethz.ch/U/maechler/R/longpoly.rda", tt)
 load(tt)
 zh # look at the long "polygon string"

 parse(text=zh) ## seg.fault

--
Martin

From ripley at stats.ox.ac.uk  Fri Jun 25 10:48:43 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jun 25 10:48:46 2004
Subject: [Rd] Bug in parse(text = <long polynom>) (PR#7022)
In-Reply-To: <20040625084219.57E7D108CF@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0406250946160.32429-100000@gannet.stats>

On Fri, 25 Jun 2004 maechler@stat.math.ethz.ch wrote:

> >>>>> "MM" == Martin Maechler <maechler@stat.math.ethz.ch>
> >>>>>     on Fri, 25 Jun 2004 10:19:19 +0200 writes:
> 
> >>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
> >>>>>     on 25 Jun 2004 09:32:48 +0200 writes:
> 
>     PD> But you're still requiring library(polynom) for
>     PD> triggering the bug. If we are to be sure that it is not
>     PD> a bug in that package but a bug in R, you need to
>     PD> include the definition of at least polynomial() with the
>     PD> instructions to reproduce the effect...
> 
>     MM> well, try this (without package polynom):
> 
>     >> parse(text="1 + x*(100 + x*(4950 + x*(161700 + x*(3921225 
> ....
> 
> and then I had the full length 2404 string which---I had
> "known in advance" (Murphy's law)--- has been thrown up
> before it got back to R-devel, actually by my mailer already.
> 
> Now this should be easier to pass through:
> 
>  tt <- tempfile() 
>  download.file("ftp://ftp.stat.math.ethz.ch/U/maechler/R/longpoly.rda", tt)
>  load(tt)
>  zh # look at the long "polygon string"

FYI

	load(url("ftp://ftp.stat.math.ethz.ch/U/maechler/R/longpoly.rda"))

is a neater way to do this.  (Or use loadURL.)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Lfo at psykiatri.aaa.dk  Fri Jun 25 11:03:42 2004
From: Lfo at psykiatri.aaa.dk (Lfo@psykiatri.aaa.dk)
Date: Fri Jun 25 11:03:46 2004
Subject: [Rd] legend lwd - feature request (PR#7023)
Message-ID: <20040625090342.F28B1108CF@slim.kubism.ku.dk>

(R1.9.1 Windows)

In legend( ) lwd have no effect on points - contrary to the behaviour
in e.g. plot( ) and points( ). It would be nice to have an option pt.lwd
affecting the line width of legend points (like pt.cex changes the
magnification).


An example (note the difference in line width between points in the
plot and the legend):
x <- 1:10 ; y <- rnorm(10,10,5) ; y2 <- rnorm(10,8,4)
plot(x,y,bty="l",lwd=3,type="o",col=2,ylim=c(min(y,y2),max(y,y2)),cex=1.5)
points(x,y2,lwd=3,lty=8,col=4,type="o",pch=2,cex=1.5)
legend(10,max(y,y2),legend=c("Method 1","Method
2"),col=c(2,4),lty=c(1,8),pch=c(1,2),
    xjust=1,yjust=1,pt.cex=1.5,lwd=3)

Workaround (thanks to Peter Dalgaard):
x <- 1:10 ; y <- rnorm(10,10,5) ; y2 <- rnorm(10,8,4)
plot(x,y,bty="l",lwd=3,type="o",col=2,ylim=c(min(y,y2),max(y,y2)),cex=1.5)
points(x,y2,lwd=3,lty=8,col=4,type="o",pch=2,cex=1.5)
legend(10,max(y,y2),legend=c("Method 1","Method
2"),col=c(0,0),lty=c(1,8),pch=c(1,2),
    xjust=1,yjust=1,pt.cex=1.5,lwd=0,text.col=0)
pp <- par(lwd=3)
legend(10,max(y,y2),legend=c("Method 1","Method 2"),
    col=c(2,4),lty=c(1,8),pch=c(1,2), 
    xjust=1,yjust=1,pt.cex=1.5,lwd=3,bty="n")
par(pp)


-- 
Leslie Foldager
Cand.scient., Statistiker
Afdeling for Psykiatrisk Demografi
Tlf.: (+45) 7789 2865
Email: lfo@psykiatri.aaa.dk
Web: www.psychdem.dk

From dmurdoch at pair.com  Fri Jun 25 12:10:52 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri Jun 25 12:10:58 2004
Subject: [Rd] Bug in parse(text = <long polynom>) (PR#7022)
In-Reply-To: <20040625084219.57E7D108CF@slim.kubism.ku.dk>
References: <20040625084219.57E7D108CF@slim.kubism.ku.dk>
Message-ID: <fqtnd0pl57p5tacbheciq9ugbgk0030195@4ax.com>

On Fri, 25 Jun 2004 10:42:19 +0200 (CEST), maechler@stat.math.ethz.ch
wrote:

>>>>>> "MM" == Martin Maechler <maechler@stat.math.ethz.ch>
>>>>>>     on Fri, 25 Jun 2004 10:19:19 +0200 writes:
>
>>>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
>>>>>>     on 25 Jun 2004 09:32:48 +0200 writes:
>
>    PD> But you're still requiring library(polynom) for
>    PD> triggering the bug. If we are to be sure that it is not
>    PD> a bug in that package but a bug in R, you need to
>    PD> include the definition of at least polynomial() with the
>    PD> instructions to reproduce the effect...
>
>    MM> well, try this (without package polynom):
>
>    >> parse(text="1 + x*(100 + x*(4950 + x*(161700 + x*(3921225 
>....
>
>and then I had the full length 2404 string which---I had
>"known in advance" (Murphy's law)--- has been thrown up
>before it got back to R-devel, actually by my mailer already.
>
>Now this should be easier to pass through:
>
> tt <- tempfile() 
> download.file("ftp://ftp.stat.math.ethz.ch/U/maechler/R/longpoly.rda", tt)
> load(tt)
> zh # look at the long "polygon string"
>
> parse(text=zh) ## seg.fault

I don't see any problems in 1.9.1 or R-patched on Windows:

> parse(text=zh)
expression(1 + x * (100 + x * (4950 + x * (161700 + x * (3921225 + 
    x * (75287520 + x * (1192052400 + x * (16007560800 + x * 
        (186087894300 + x * (1902231808400 + x * (17310309456440 + 
            x * (141629804643600 + x * (1050421051106700 + x * 
                (7110542499799200 + x * (44186942677323608 + 
... etc

Duncan Murdoch

From dmurdoch at pair.com  Fri Jun 25 17:50:55 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri Jun 25 17:51:02 2004
Subject: [Rd] Using MiKTeX with R
Message-ID: <u9iod0lfvbmu40lfbv99s8e0r5ggg0u5bf@4ax.com>

Recent releases of MiKTeX don't work with the R make process.  I've
put together a little web page describing what to do to fix it:

http://www.murdoch-sutherland.com/Rtools/miktex.html

Duncan Murdoch

From dmurdoch at pair.com  Fri Jun 25 22:38:33 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri Jun 25 22:38:37 2004
Subject: [Rd] Using MiKTeX with R
In-Reply-To: <u9iod0lfvbmu40lfbv99s8e0r5ggg0u5bf@4ax.com>
References: <u9iod0lfvbmu40lfbv99s8e0r5ggg0u5bf@4ax.com>
Message-ID: <a93pd0h08ah04g1gtda4jpv0a8480u770n@4ax.com>

On Fri, 25 Jun 2004 11:50:55 -0400, Duncan Murdoch <dmurdoch@pair.com>
wrote :

>Recent releases of MiKTeX don't work with the R make process.  I've
>put together a little web page describing what to do to fix it:
>
>http://www.murdoch-sutherland.com/Rtools/miktex.html


Just found a better way to get MiKTeX to use TEXINPUTS, so I've
updated the page.

Duncan Murdoch

From reitter at mle.media.mit.edu  Sat Jun 26 02:17:13 2004
From: reitter at mle.media.mit.edu (reitter@mle.media.mit.edu)
Date: Sat Jun 26 02:17:18 2004
Subject: [Rd] Installer package destroys permission settings on /Applcations
	(PR#7025)
Message-ID: <20040626001713.79E28FC0F@slim.kubism.ku.dk>

Full_Name: david Reitter
Version: 1.9.1
OS: Mac OS X 10.3
Submission from: (NULL) (18.85.44.174)


The installer package seems to change the permissions on the /Applications
folder (and probably on other folders as well), which means that a normal user
(that does not happen to have user id 501) cannot open the Applications folder
anymore. Both group and user are changed to id '501' (which doesn't exist on my
system). 501 is usually the first user on a system.
Also, it seems to change permissions of the root directory /.

Running Disk Utility ("repair permissions") helps in such a case -- provided you
are able to run Disk Utility without accessing your Applications folder (which
might be hard for the non-techie).
 
The libxml package that is included does the same kind of BS, but this time with
the less important /usr folder.

I could reproduce the problem by installing R again after I ran the system's
repair permissions script. 
I wonder if this is a general problem with Apple's installer.

From ggrothendieck at myway.com  Sat Jun 26 05:25:31 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat Jun 26 05:40:24 2004
Subject: [Rd] Suggestion: ties.method = "last" in rank
Message-ID: <loom.20040626T052358-266@post.gmane.org>


An earlier post shown at the bottom of:

https://www.stat.math.ethz.ch/pipermail/r-help/2004-June/051975.html

asked for a ranking in which the highest rank among ties
was to be used for all ties.  Note that if the lowest rank 
among ties had been required then this would have worked:

   rank(x, ties.method = "first")[match(rank(x),rank(x))]

and if tie="last" were available, the poster's question could have
had a similarly simple solution:

   rank(x, ties.method = "last")[match(rank(x),rank(x))] 

The existence of this question and symmetry suggests that ties.method="last"
should be made available too.  To do this, just add this to the switch
statement in rank:

   last = order(order(rev(x[!nas])), decreasing = TRUE)

From stefano.iacus at unimi.it  Sat Jun 26 09:41:23 2004
From: stefano.iacus at unimi.it (stefano iacus)
Date: Sat Jun 26 09:41:30 2004
Subject: [Rd] Installer package destroys permission settings on
	/Applcations (PR#7025)
In-Reply-To: <20040626001713.79E28FC0F@slim.kubism.ku.dk>
References: <20040626001713.79E28FC0F@slim.kubism.ku.dk>
Message-ID: <38C96526-C744-11D8-8D70-000A95C87F66@unimi.it>

Thanks for raising this problem. I agree, the installer should not 
change the permissions on /Applications (but user can decide to install 
the application somewhere else and move it to /Applications later as a 
temporary solution)

It only affects the directory where you choose to install R.app (the 
few KB application). So the rest of your system is safe (at least)

As for the R.framework: it should stay in /Library/Frameworks in this 
release as well as for 1.9.0. So nothing changes there

I've just upload a new version of the installer on CRAN. It will take 
till tomorrow to propagate on the web.

Apart from this (serious) issue: user should upgrade always to the 
latest version of R

As said in the ReadMe file, you should install the libxml2 package if 
you use Panther (which seems to be your case).

stefano


On Jun 26, 2004, at 2:17 AM, reitter@mle.media.mit.edu wrote:

> Full_Name: david Reitter
> Version: 1.9.1
> OS: Mac OS X 10.3
> Submission from: (NULL) (18.85.44.174)
>
>
> The installer package seems to change the permissions on the 
> /Applications
> folder (and probably on other folders as well), which means that a 
> normal user
> (that does not happen to have user id 501) cannot open the 
> Applications folder
> anymore. Both group and user are changed to id '501' (which doesn't 
> exist on my
> system). 501 is usually the first user on a system.
> Also, it seems to change permissions of the root directory /.
>
> Running Disk Utility ("repair permissions") helps in such a case -- 
> provided you
> are able to run Disk Utility without accessing your Applications 
> folder (which
> might be hard for the non-techie).
>
> The libxml package that is included does the same kind of BS, but this 
> time with
> the less important /usr folder.
>
> I could reproduce the problem by installing R again after I ran the 
> system's
> repair permissions script.
> I wonder if this is a general problem with Apple's installer.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From Matthias.Kohl at uni-bayreuth.de  Sat Jun 26 11:26:28 2004
From: Matthias.Kohl at uni-bayreuth.de (Matthias.Kohl@uni-bayreuth.de)
Date: Sat Jun 26 11:26:32 2004
Subject: [Rd] S4 group "Math", "getGroupMembers", "genericForPrimitive"
Message-ID: <1185.132.180.246.23.1088241988.squirrel@mail.uni-bayreuth.de>

Hi,

I found the following on Windows 2000/NT
R Version 1.9.1  (2004-06-21) (also Version 1.9.0):

The S4 group "Math" doesn't work as documented; i.e., "log", "log10",
"gamma" and "lgamma" are included
in the documentation but don't work. See example code below.

Moreover, what about 'genericForPrimitive' which is used
in 'getGeneric'. It seems that this method is not included in
the R Version 1.9.1 (also 1.9.0). See the example code of
John Chambers at the end of this email.

Why not add the method 'getGroupMembers' as proposed by John Chambers
to the methods package?
(see reply to mail: "Missing 'getGroupMembers()'"
 from Sat May 31 2003 - 15:18:18 EDT)

Thanks for your attention,
Matthias


###################################################
## Example Code
###################################################
## Example Code from the "green book"
setClass("track", representation(x = "numeric", y = "numeric"))

setMethod("Math", "track",
            function(x){ x@y = callGeneric(x@y); x })

tr1 <- new("track", x = 1:3, y = 1:3)
tr1

## are documented as belonging to group "Math"
## see ?"Math"
## but don't work
log(tr1)
log10(tr1)
gamma(tr1)
lgamma(tr1)

## are not generic and don't belong to any group!
is("log", "genericFunction")
is("log10", "genericFunction")
is("gamma", "genericFunction")
is("lgamma", "genericFunction")
getGroup("log")
getGroup("log10")
getGroup("gamma")
getGroup("lgamma")

## make this functions generic and add to group "Math"
## (only local!)
setGeneric("log", function(x, base) standardGeneric("log"), group = "Math")
setGeneric("log10", function(x) standardGeneric("log10"), group = "Math")
setGeneric("gamma", function(x) standardGeneric("gamma"), group = "Math")
setGeneric("lgamma", function(x) standardGeneric("lgamma"), group = "Math")

setMethod("Math", "track",
            function(x){ x@y = callGeneric(x@y); x })

## now works as documented
log(tr1)
log10(tr1)
gamma(tr1)
lgamma(tr1)

## By John Chambers:
## "... the following code implements what one is
## likely to want in most cases." (see reply
## to mail: "Missing 'getGroupMembers()'"
## from Sat May 31 2003 - 15:18:18 EDT)
## Modification of this code
## since 'genericForPrimitive' is not defined (?)
## although it is called in 'getGeneric'!!!
getGroups <- function(what = c(getGenerics(), names(.BasicFunsList))) {
    what <- what[what != "is.function"]
    what <- what[what != "is.null"]
    what <- what[what != "is.object"]
    g <-unlist(sapply(what,
          function(x){
                f <- getGeneric(x)
                if(is(f, "genericFunction"))f@group else NULL
          }))
    split(names(g), g)
}
getGroupMembers <- function(group, whatGenerics) {
    groups <- if(missing(whatGenerics)) getGroups()
              else getGroups(whatGenerics)
    elNamed(groups, group)
}

From stefano.iacus at unimi.it  Sat Jun 26 11:52:40 2004
From: stefano.iacus at unimi.it (stefano iacus)
Date: Sat Jun 26 11:52:51 2004
Subject: [Rd] Installer package destroys permission settings on
	/Applcations (PR#7025)
In-Reply-To: <38C96526-C744-11D8-8D70-000A95C87F66@unimi.it>
References: <20040626001713.79E28FC0F@slim.kubism.ku.dk>
	<38C96526-C744-11D8-8D70-000A95C87F66@unimi.it>
Message-ID: <90263A9E-C756-11D8-8D70-000A95C87F66@unimi.it>


On Jun 26, 2004, at 9:41 AM, stefano iacus wrote:

> Thanks for raising this problem. I agree, the installer should not 
> change the permissions on /Applications (but user can decide to 
> install the application somewhere else and move it to /Applications 
> later as a temporary solution)
>
> It only affects the directory where you choose to install R.app (the 
> few KB application). So the rest of your system is safe (at least)
>
> As for the R.framework: it should stay in /Library/Frameworks in this 
> release as well as for 1.9.0. So nothing changes there
>
> I've just upload a new version of the installer on CRAN. It will take 
> till tomorrow to propagate on the web.
>
> Apart from this (serious) issue: user should upgrade always to the 
> latest version of R
>
> As said in the ReadMe file, you should install the libxml2 package if 
> you use Panther (which seems to be your case).
sorry, you should "NOT" install it on Panther.
stefano

>
> stefano
>
>
> On Jun 26, 2004, at 2:17 AM, reitter@mle.media.mit.edu wrote:
>
>> Full_Name: david Reitter
>> Version: 1.9.1
>> OS: Mac OS X 10.3
>> Submission from: (NULL) (18.85.44.174)
>>
>>
>> The installer package seems to change the permissions on the 
>> /Applications
>> folder (and probably on other folders as well), which means that a 
>> normal user
>> (that does not happen to have user id 501) cannot open the 
>> Applications folder
>> anymore. Both group and user are changed to id '501' (which doesn't 
>> exist on my
>> system). 501 is usually the first user on a system.
>> Also, it seems to change permissions of the root directory /.
>>
>> Running Disk Utility ("repair permissions") helps in such a case -- 
>> provided you
>> are able to run Disk Utility without accessing your Applications 
>> folder (which
>> might be hard for the non-techie).
>>
>> The libxml package that is included does the same kind of BS, but 
>> this time with
>> the less important /usr folder.
>>
>> I could reproduce the problem by installing R again after I ran the 
>> system's
>> repair permissions script.
>> I wonder if this is a general problem with Apple's installer.
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From maechler at stat.math.ethz.ch  Sat Jun 26 22:00:08 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat Jun 26 22:00:15 2004
Subject: [Rd] Re: plot.new() warning from coplot()'s par(*, new=FALSE)
In-Reply-To: <x2lliay7eh.fsf@biostat.ku.dk>
References: <Pine.LNX.4.44.0406261811560.1421-100000@unix24.alpha.wehi.edu.au>
	<x2lliay7eh.fsf@biostat.ku.dk>
Message-ID: <16605.54728.73248.430943@gargle.gargle.HOWL>

{diverted from the R-SIG-gui list}

>>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
>>>>>     on 26 Jun 2004 11:51:02 +0200 writes:

    PD> James Wettenhall <wettenhall@wehi.edu.au> writes:
    >> Hi,
    >> 
    >> Does anyone know a good way to get rid of warnings like:
    >> Warning message: calling par(new=) with no plot
    >> 
    >> when using an R plot function which calls plot.new()
    >> (e.g. coplot) from within tkrplot?
    >> 
       .....

    PD> Hmm, the same wart appears if you just plot to a freshly
    PD> opened X11 device (X11(); coplot(....)), nothing
    PD> specific to tkrplot. I think I've seen this reported
    PD> before, but I have forgotten what the recommended action
    PD> was.

If I look at coplot, I see that it's very first graphics call is

  par(mfrow =..................., new = FALSE)

and this ('new = FALSE') of course gives the warning when no
graphic device is active.
coplot()'s code  is just not quite right here IMO.

I can rid of the warning and keep coplot() behaving as
now otherwise by replacing

      opar <- par(mfrow = c(total.rows, total.columns),
                  oma = oma, mar = mar, xaxs = "r", yaxs = "r", new = FALSE)

by
      if(dev.cur() > 1 && par("new")) # turn off a par(new=TRUE) setting
          par(new = FALSE)
      opar <- par(mfrow = c(total.rows, total.columns),
                  oma = oma, mar = mar, xaxs = "r", yaxs = "r")

- - -

and I'd commit this (to R-patched).

OTOH, I wonder if we couldn't just omit the   
      if(...) par(new = FALSE)
clause {for R-devel at least}.
If a user really calls  par(new = TRUE) before calling coplot()
(s)he should be allowed to produce such a monstrosity --- unless
its an ingenuosity such as drawing a background image on which
to draw coplot() ...

Martin Maechler

From edd at debian.org  Sat Jun 26 22:46:09 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat Jun 26 22:46:17 2004
Subject: [Rd] Problem setting environment variable in R/zzz.R
Message-ID: <20040626204609.GA6901@sonny.eddelbuettel.com>


I am trying to get the Rmetrics.org component package fBasics by Diethelm
Wuertz into a Debian package. Thanks to a lot of work by Diethelm, it is
_almost_ there. It fails 'R CMD check' for me if I do not have the TZ
environment variable set [1], yet works fine as long as I set TZ.

I figured I could patch this in R/zzz.R and do 

    ## set a timezone if none found in environment variables or options()
    if (Sys.getenv("TZ")=="") {
      if (is.null(getOption("TZ"))) {
        cat("No timezone information found, using default of GMT\n")
        Sys.putenv("TZ"=="GMT")
      } else {
        cat("No timezone information found, applying option() value of",
            getOption("TZ"), "\n")
        Sys.putenv("TZ"==getOption("TZ"))
      }
    }

right before   library.dynam("fBasics", pkg, lib)  concludes .First.lib().

Now, even with that little patch, the R CMD check still fails.  Which means
that the package could fail CRAN tests unless CRAN has TZ set. That is a bit
of a gamble I'd rather avoid.

What am I doing wrong here?

Thanks,  Dirk


[1] There is a bit of a Debian tradition to, if in doubt, cover things via
    a configuration file in /etc rather than an environment variable. I got
    rather used to that, and like living without env.vars.

-- 
"Cheney has the mouth of a sailor, which is odd for someone who did 
everything he could to stay out of the Navy," one observer said.
          -- Andy Borowitz, http://borowitzreport.com, 26 June 2004

From rpeng at jhsph.edu  Sat Jun 26 23:09:51 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sat Jun 26 23:09:59 2004
Subject: [Rd] Problem setting environment variable in R/zzz.R
In-Reply-To: <20040626204609.GA6901@sonny.eddelbuettel.com>
References: <20040626204609.GA6901@sonny.eddelbuettel.com>
Message-ID: <40DDE61F.6020406@jhsph.edu>

The help page for Sys.putenv seems to indicate using a single "=" 
rather than the double "==".  Could that be your problem?

-roger

Dirk Eddelbuettel wrote:

> I am trying to get the Rmetrics.org component package fBasics by Diethelm
> Wuertz into a Debian package. Thanks to a lot of work by Diethelm, it is
> _almost_ there. It fails 'R CMD check' for me if I do not have the TZ
> environment variable set [1], yet works fine as long as I set TZ.
> 
> I figured I could patch this in R/zzz.R and do 
> 
>     ## set a timezone if none found in environment variables or options()
>     if (Sys.getenv("TZ")=="") {
>       if (is.null(getOption("TZ"))) {
>         cat("No timezone information found, using default of GMT\n")
>         Sys.putenv("TZ"=="GMT")
>       } else {
>         cat("No timezone information found, applying option() value of",
>             getOption("TZ"), "\n")
>         Sys.putenv("TZ"==getOption("TZ"))
>       }
>     }
> 
> right before   library.dynam("fBasics", pkg, lib)  concludes .First.lib().
> 
> Now, even with that little patch, the R CMD check still fails.  Which means
> that the package could fail CRAN tests unless CRAN has TZ set. That is a bit
> of a gamble I'd rather avoid.
> 
> What am I doing wrong here?
> 
> Thanks,  Dirk
> 
> 
> [1] There is a bit of a Debian tradition to, if in doubt, cover things via
>     a configuration file in /etc rather than an environment variable. I got
>     rather used to that, and like living without env.vars.
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/

From p.dalgaard at biostat.ku.dk  Sun Jun 27 00:02:51 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun Jun 27 00:03:36 2004
Subject: [Rd] Problem setting environment variable in R/zzz.R
In-Reply-To: <40DDE61F.6020406@jhsph.edu>
References: <20040626204609.GA6901@sonny.eddelbuettel.com>
	<40DDE61F.6020406@jhsph.edu>
Message-ID: <x2vfhej7uc.fsf@biostat.ku.dk>

"Roger D. Peng" <rpeng@jhsph.edu> writes:

> The help page for Sys.putenv seems to indicate using a single "="
> rather than the double "==".  Could that be your problem?

> >         Sys.putenv("TZ"=="GMT")
> >         Sys.putenv("TZ"==getOption("TZ"))

Whoa! Nice catch, Roger.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From edd at debian.org  Sun Jun 27 00:45:59 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun Jun 27 00:46:02 2004
Subject: [Rd] Problem setting environment variable in R/zzz.R
In-Reply-To: <40DDE61F.6020406@jhsph.edu>
References: <20040626204609.GA6901@sonny.eddelbuettel.com>
	<40DDE61F.6020406@jhsph.edu>
Message-ID: <20040626224559.GA7682@sonny.eddelbuettel.com>

On Sat, Jun 26, 2004 at 05:09:51PM -0400, Roger D. Peng wrote:
> The help page for Sys.putenv seems to indicate using a single "=" 
> rather than the double "==".  Could that be your problem?

Plonk!  Sure was.

I won't publically how long I chased this one ==:-O

Thanks, Roger!

Dirk

-- 
"Cheney has the mouth of a sailor, which is odd for someone who did 
everything he could to stay out of the Navy," one observer said.
          -- Andy Borowitz, http://borowitzreport.com, 26 June 2004

From pburns at pburns.seanet.com  Sun Jun 27 11:55:30 2004
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sun Jun 27 11:55:46 2004
Subject: [Rd] suggestion for addition to substring
Message-ID: <40DE9992.7070701@pburns.seanet.com>

Below is suggested code for adding a "tail" argument to the
"substring" function.

Getting the end of a string is a fairly common operation in
finance where the exchange of an asset is often encoded.

This is a new implementation,  but I don't think there are any
tricky bits I haven't thought of.

function (text, first, last = 1e+06, tail=NULL)
{
    storage.mode(text) <- "character"
    if(length(tail)) {
        if(!missing(first))
                stop("only one of first and tail allowed")
        nc <- nchar(text)
        first <- nc - tail + 1
    }
    n <- max(lt <- length(text), length(first), length(last))
    if (lt && lt < n)
        text <- rep(text, length.out = n)
    substr(text, first, last)
}
<environment: namespace:base>

As implemented here "tail" gives the distance from the original end of the
strings, not the number of characters in the answer (when "last" is given).


Patrick Burns

Burns Statistics
patrick@burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

From simon.urbanek at math.uni-augsburg.de  Sun Jun 27 17:51:54 2004
From: simon.urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Sun Jun 27 17:52:12 2004
Subject: [Rd] Installer package destroys permission settings on
	/Applcations (PR#7025)
In-Reply-To: <38C96526-C744-11D8-8D70-000A95C87F66@unimi.it>
References: <20040626001713.79E28FC0F@slim.kubism.ku.dk>
	<38C96526-C744-11D8-8D70-000A95C87F66@unimi.it>
Message-ID: <E9C53B7F-C851-11D8-987A-000A959F327E@math.uni-augsburg.de>


On Jun 26, 2004, at 9:41 AM, stefano iacus wrote:

> Thanks for raising this problem. I agree, the installer should not 
> change the permissions on /Applications (but user can decide to 
> install the application somewhere else and move it to /Applications 
> later as a temporary solution)

I'd say that it shouldn't read "the installer should", but rather "the 
package creator should" - again the package is very badly created - 
same as the R 1.9.0 one and defies all mechanisms Apple provides in the 
Installer. It's not a fault of the Apple's Installer but rather how the 
package was created (Apple's Package Manager provides ways to set 
rights correctly). Unfortunately the only way to get proper 
installation of R (if you didn't build you own package) is to 
re-compile it and use corresponding make install commands. I have 
addressed this issue previously and even created a package template, 
but sometimes things just don't change :(

Cheers,
simon

From simon.urbanek at math.uni-augsburg.de  Sun Jun 27 17:52:15 2004
From: simon.urbanek at math.uni-augsburg.de (simon.urbanek@math.uni-augsburg.de)
Date: Sun Jun 27 17:52:21 2004
Subject: [Rd] Installer package destroys permission settings on
	/Applcations (PR#7025)
Message-ID: <20040627155215.7FDF8F32C@slim.kubism.ku.dk>


On Jun 26, 2004, at 9:41 AM, stefano iacus wrote:

> Thanks for raising this problem. I agree, the installer should not 
> change the permissions on /Applications (but user can decide to 
> install the application somewhere else and move it to /Applications 
> later as a temporary solution)

I'd say that it shouldn't read "the installer should", but rather "the 
package creator should" - again the package is very badly created - 
same as the R 1.9.0 one and defies all mechanisms Apple provides in the 
Installer. It's not a fault of the Apple's Installer but rather how the 
package was created (Apple's Package Manager provides ways to set 
rights correctly). Unfortunately the only way to get proper 
installation of R (if you didn't build you own package) is to 
re-compile it and use corresponding make install commands. I have 
addressed this issue previously and even created a package template, 
but sometimes things just don't change :(

Cheers,
simon

From jonathan.taylor at stanford.edu  Sun Jun 27 21:57:47 2004
From: jonathan.taylor at stanford.edu (Jonathan Taylor)
Date: Sun Jun 27 21:57:55 2004
Subject: [Rd] cross-compiling + expm1
Message-ID: <42EB7F10-C874-11D8-9ED5-000A95DA50E2@stanford.edu>

Hello all,
	Just joined this mailing list -- not sure if this is the right list to 
send this question, but I have a question about cross-compiling R. I am 
working with R-1.9.1.tgz.
	It may just be with my version of mingw32, but it seems that expm1 is 
not defined, so I tried to ensure that HAVE_EXPM1 was #undef'ed before 
cross-compiling. The problem is that, in <include/Rmath.h> if it is 
#undef'ed it is then #define'd as 1, meaning that the line where expm1 
is declared automatically not included. I had similar problems with 
logpq, but after changing Rmath.h cross-compiling was straightforward. 
My question is: is this a "bug" in Rmath.h with respect to expm1 and 
logp1? If so, how would you cross-compile, or even compile, if you 
don't have expm1 or logp1?

Thanks,

Jonathan Taylor

From ripley at stats.ox.ac.uk  Sun Jun 27 22:21:22 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Jun 27 22:26:42 2004
Subject: [Rd] cross-compiling + expm1
In-Reply-To: <42EB7F10-C874-11D8-9ED5-000A95DA50E2@stanford.edu>
Message-ID: <Pine.LNX.4.44.0406272106460.29419-100000@gannet.stats>

If set up correctly, this _does_ work.  There is no known bug in the R
files for cross-compiling, and it _has_ been tested.

Something is seriously wrong with your cross-compiling setup, which since
you do not credit I presume you made yourself.  See below for some
guesses as to what might be wrong.

On Sun, 27 Jun 2004, Jonathan Taylor wrote:

> Hello all,
> 	Just joined this mailing list -- not sure if this is the right list to 
> send this question, but I have a question about cross-compiling R. I am 
> working with R-1.9.1.tgz.
> 	It may just be with my version of mingw32, but it seems that expm1 is 
> not defined, so I tried to ensure that HAVE_EXPM1 was #undef'ed before 
> cross-compiling. The problem is that, in <include/Rmath.h> if it is 
> #undef'ed it is then #define'd as 1, meaning that the line where expm1 
> is declared automatically not included. 

That's not right.  First, the file is called Rmath.h but it is in
src/include not include.  Second, the Windows Rmath.h has

#ifndef HAVE_EXPM1
#endif

so I guess your cross-compiling is set up to use the Rmath.h from the host
and not the target.  Incorrectly built cross-compilers do get the include
paths wrong, and I have seen several such.  I suggest you use gcc -v and 
check your include paths.

> I had similar problems with 
> logpq, but after changing Rmath.h cross-compiling was straightforward. 
> My question is: is this a "bug" in Rmath.h with respect to expm1 and 
> logp1? If so, how would you cross-compile, or even compile, if you 
> don't have expm1 or logp1?

Not relevant, as the correct Rmath.h will define expm1/log1p (sic, not 
logpq or logp1) iff it is not present in the system's runtime files.

You should have log1p in your mingw32 files, and if you do not your
system is too old (and the file src/gnuwin32/INSTALL does have warnings 
about this).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sun Jun 27 22:40:26 2004
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sun Jun 27 22:45:37 2004
Subject: [Rd] cross-compiling + expm1
In-Reply-To: <Pine.LNX.4.44.0406272106460.29419-100000@gannet.stats>
References: <Pine.LNX.4.44.0406272106460.29419-100000@gannet.stats>
Message-ID: <Pine.WNT.4.58.0406272136190.3988@auk>

Another thought: you are not by any chance using sources that have been
configured for the host?  configure on the host would give you
inappropriate files in src/include and then the Windows make would not
create the correct ones.

src/include/Rmath.h should be dated almost immediately after you first ran
make in src/gnuwin32.  To be sure, I would run make distclean and start
again.

Another way to check include paths is to look at the *.d files.

On Sun, 27 Jun 2004, Prof Brian Ripley wrote:

> If set up correctly, this _does_ work.  There is no known bug in the R
> files for cross-compiling, and it _has_ been tested.
>
> Something is seriously wrong with your cross-compiling setup, which since
> you do not credit I presume you made yourself.  See below for some
> guesses as to what might be wrong.
>
> On Sun, 27 Jun 2004, Jonathan Taylor wrote:
>
> > Hello all,
> > 	Just joined this mailing list -- not sure if this is the right list to
> > send this question, but I have a question about cross-compiling R. I am
> > working with R-1.9.1.tgz.
> > 	It may just be with my version of mingw32, but it seems that expm1 is
> > not defined, so I tried to ensure that HAVE_EXPM1 was #undef'ed before
> > cross-compiling. The problem is that, in <include/Rmath.h> if it is
> > #undef'ed it is then #define'd as 1, meaning that the line where expm1
> > is declared automatically not included.
>
> That's not right.  First, the file is called Rmath.h but it is in
> src/include not include.  Second, the Windows Rmath.h has
>
> #ifndef HAVE_EXPM1
> #endif
>
> so I guess your cross-compiling is set up to use the Rmath.h from the host
> and not the target.  Incorrectly built cross-compilers do get the include
> paths wrong, and I have seen several such.  I suggest you use gcc -v and
> check your include paths.
>
> > I had similar problems with
> > logpq, but after changing Rmath.h cross-compiling was straightforward.
> > My question is: is this a "bug" in Rmath.h with respect to expm1 and
> > logp1? If so, how would you cross-compile, or even compile, if you
> > don't have expm1 or logp1?
>
> Not relevant, as the correct Rmath.h will define expm1/log1p (sic, not
> logpq or logp1) iff it is not present in the system's runtime files.
>
> You should have log1p in your mingw32 files, and if you do not your
> system is too old (and the file src/gnuwin32/INSTALL does have warnings
> about this).
>
> --
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From stefano.iacus at unimi.it  Mon Jun 28 00:45:47 2004
From: stefano.iacus at unimi.it (stefano iacus)
Date: Mon Jun 28 00:45:51 2004
Subject: [Rd] Installer package destroys permission settings on
	/Applcations (PR#7025)
In-Reply-To: <E9C53B7F-C851-11D8-987A-000A959F327E@math.uni-augsburg.de>
References: <20040626001713.79E28FC0F@slim.kubism.ku.dk>
	<38C96526-C744-11D8-8D70-000A95C87F66@unimi.it>
	<E9C53B7F-C851-11D8-987A-000A959F327E@math.uni-augsburg.de>
Message-ID: <BB210C1D-C88B-11D8-81FD-000A95C87F66@unimi.it>


On Jun 27, 2004, at 5:51 PM, Simon Urbanek wrote:

>
> On Jun 26, 2004, at 9:41 AM, stefano iacus wrote:
>
>> Thanks for raising this problem. I agree, the installer should not 
>> change the permissions on /Applications (but user can decide to 
>> install the application somewhere else and move it to /Applications 
>> later as a temporary solution)
>
> I'd say that it shouldn't read "the installer should", but rather "the 
> package creator should" -

I never said that this is Apple's installer fault. It was my fault of 
an unfortunate clicking on the option to overwrite permissions.
stefano

> again the package is very badly created - same as the R 1.9.0 one and 
> defies all mechanisms Apple provides in the Installer. It's not a 
> fault of the Apple's Installer but rather how the package was created 
> (Apple's Package Manager provides ways to set rights correctly). 
> Unfortunately the only way to get proper installation of R (if you 
> didn't build you own package) is to re-compile it and use 
> corresponding make install commands. I have addressed this issue 
> previously and even created a package template, but sometimes things 
> just don't change :(
>
> Cheers,
> simon
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From stefano.iacus at unimi.it  Mon Jun 28 00:50:58 2004
From: stefano.iacus at unimi.it (stefano iacus)
Date: Mon Jun 28 00:51:02 2004
Subject: [Rd] out-of-date information in R for Mac OS X FAQ (PR#6982)
In-Reply-To: <20040615105042.29FD41059D@slim.kubism.ku.dk>
References: <20040615105042.29FD41059D@slim.kubism.ku.dk>
Message-ID: <7480C951-C88C-11D8-81FD-000A95C87F66@unimi.it>

now added back on the page mentioned on the MAC OS X FAq.

stefano

On Jun 15, 2004, at 12:50 PM, d.firth@warwick.ac.uk wrote:

> Full_Name: David Firth
> Version: 1.9.0
> OS: Mac OS 10.3
> Submission from: (NULL) (137.205.240.25)
>
>
> For libreadline, the R for Mac OS X FAQ points to 
> http://www.economia.unimi.it/R
> -- but libreadline does not seem to be there at 
> http://www.economia.unimi.it/R
> (any more?)
>
> It seems useful still to provide this "patched" version of 
> libreadline, for
> those of us who want to run R from the Terminal.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From j.j.goeman at lumc.nl  Mon Jun 28 11:12:28 2004
From: j.j.goeman at lumc.nl (j.j.goeman@lumc.nl)
Date: Mon Jun 28 11:12:33 2004
Subject: [Rd] Problem with hasArg and the ... argument (PR#7027)
Message-ID: <20040628091228.B04B8EAD6@slim.kubism.ku.dk>

Full_Name: Jelle Goeman
Version: 1.9.0
OS: mingw32, windows 2000
Submission from: (NULL) (145.88.209.33)


Hi Everyone,

I get very strange results using the function hasArg with the ... function
argument. In my own function: 

> gt <- globaltest(X,Y)
> sampling(gt)

works fine, but

> sampling(globaltest(X,Y))

results in:

Error in eval(expr, envir, enclos) : "missing" illegal use of missing

I've tracked down the problem. Define the simple function:

xory <- function(x, ...) if (hasArg(y)) y else x

then 

x <- 1:10
xx <- xory(x)
plot(x, xx)

works fine, but

plot(x, xory(x))

gives the same error. The problem is that the plot function also has an argument
y, which somehow interferes with the hasArg function. Is there an alternative to
hasArg that really checks if an argument y was supplied for the xy function
itself?

Jelle

From dmurdoch at pair.com  Mon Jun 28 13:41:10 2004
From: dmurdoch at pair.com (dmurdoch@pair.com)
Date: Mon Jun 28 13:41:15 2004
Subject: [Rd] Problem with hasArg and the ... argument (PR#7027)
Message-ID: <20040628114110.A75A4F306@slim.kubism.ku.dk>

On Mon, 28 Jun 2004 11:12:28 +0200 (CEST), j.j.goeman@lumc.nl wrote:

>Full_Name: Jelle Goeman
>Version: 1.9.0
>OS: mingw32, windows 2000
>Submission from: (NULL) (145.88.209.33)

>I've tracked down the problem. Define the simple function:
>
>xory <- function(x, ...) if (hasArg(y)) y else x
>
>then 
>
>x <- 1:10
>xx <- xory(x)
>plot(x, xx)
>
>works fine, but
>
>plot(x, xory(x))
>
>gives the same error. The problem is that the plot function also has an argument
>y, which somehow interferes with the hasArg function. Is there an alternative to
>hasArg that really checks if an argument y was supplied for the xy function
>itself?

This is still present in 1.9.1 and r-patched (on Windows).  It appears
to be a bug in or misuse of sys.function: within hasArg,
sys.function(0) returns hasArg as expected, but sys.function(1)
returns plot.  xory() seems to get lost.

Duncan Murdoch

From p.dalgaard at biostat.ku.dk  Mon Jun 28 13:52:05 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Jun 28 13:53:00 2004
Subject: [Rd] Problem with hasArg and the ... argument (PR#7027)
In-Reply-To: <20040628091228.B04B8EAD6@slim.kubism.ku.dk>
References: <20040628091228.B04B8EAD6@slim.kubism.ku.dk>
Message-ID: <x2d63jdhne.fsf@biostat.ku.dk>

j.j.goeman@lumc.nl writes:

> xory <- function(x, ...) if (hasArg(y)) y else x
> 
> then 
> 
> x <- 1:10
> xx <- xory(x)
> plot(x, xx)
> 
> works fine, but
> 
> plot(x, xory(x))
> 
> gives the same error. The problem is that the plot function also has
> an argument y, which somehow interferes with the hasArg function. Is
> there an alternative to hasArg that really checks if an argument y
> was supplied for the xy function itself?

No, but hasArg has issues: 

    fnames <- names(formals(sys.function(1)))

is getting the names of plot() rather than xory(). I almost thought I
had caught the Mighty John blundering there, but this actually looks
more like sys.function is not behaving as documented and counts frames
in the wrong direction. 

Checking... Yep, the logic in R_sysfunction() is to give the function
of frame #n:

    if (n > 0)
        n = framedepth(cptr) - n;
    else
        n = - n;
    if (n < 0 )
        errorcall(R_GlobalContext->call, "illegal frame number");
    while (cptr->nextcontext != NULL) {
        if (cptr->callflag & CTXT_FUNCTION ) {
            if (n == 0)
                return duplicate(cptr->callfun);  /***** do we need to DUP? */
            else
                n--;
        }
        cptr = cptr->nextcontext;
    }


whereas the documentation has

     'sys.function' gives the definition of the function currently
     being evaluated in the frame 'n' generations back.

However, we're using the current convention in quite a few places
(sys.function(sys.parent())) and, worse, who know what packages might
do. It is tempting just to change the documentation, but it is part of
a grouped documentation of sys.whatever, which has

   which: the frame number if non-negative, the number of generations
          to go back if negative. (See the Details section.)

       n: the number of frame generations to go back.

and sys.function is documented with argument 'n', which we'd have to
change to 'which', but the default is n=0 for "current function" which
is unlike 'which' which has 0 meaning .GlobalEnv. Argh...

My take is that we need to fix sys.function to behave according to
docs, change what we can in the R internals, and face the consequences
for package maintainers.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From mckay at gmr.com  Mon Jun 28 20:34:29 2004
From: mckay at gmr.com (Neil McKay)
Date: Mon Jun 28 20:36:00 2004
Subject: [Rd] R scripting patches for R-1.9.1
Message-ID: <200406281834.i5SIYTb13112@repsac.gmr.com>

I've updated my R scripting patches for R-1.9.1. These patches allow
the R binary to be used in shell scripts via the standard Unix "#!"
mechanism. If you would like the patches, send your request to me at

	mckay@gmr.com

and I will send you the patch file.

-- 
Neil D. McKay, Mail Code 480-106-359    Phone: (586)986-1470 (GM:8-226-1470)
Manufacturing Systems Research Lab      FAX:   (586)986-0574 (GM:8-226-0574)
GM Research & Development Center        Internet e-mail: mckay@gmr.com
30500 Mound Road
Warren, Mich. 48090

From marc-roettig at web.de  Mon Jun 28 22:52:51 2004
From: marc-roettig at web.de (=?ISO-8859-1?Q?Marc_R=F6ttig?=)
Date: Mon Jun 28 22:52:54 2004
Subject: [Rd] Survey: "Motivation of Free/Open Source Software (F/OSS)
	Developers"
Message-ID: <40E08523.3070601@web.de>

Survey: "Motivation of Free/Open Source Software (F/OSS) Developers"

We (Marc R?ttig and Carl-Daniel Hailfinger) are currently working
on a survey on the motivation of open source developers as part of
a "Computer Science and Society" project at the CS department of the
University of T?bingen. We invite every developer in the Free / Open
Source Software community to help us with our survey by filling out
a little web form to give us some hints on possible motivation-motifs
of F/OSS-developers.

You can find the survey-form at

                     http://foss.ta-altensteig.de/


Privacy statement:
We do not want to collect personal information about you without
your agreement. That's why we do not ask for your name and give
you the ability to leave personal information unspecified (age
and profession). We (the authors) will not make the raw survey
data available to anyone except members of our faculty for
verification of proper scientific procedures in extracting the
results.


Thank you in advance for your support. You can reach our CS faculty at

                    http://informatik.uni-tuebingen.de/

From confirm-s2-QaKY6u1gRW=cdN3ZTYLl8G2cLAA-r-devel=r-project.org at yahoogroupes.fr  Tue Jun 29 00:02:16 2004
From: confirm-s2-QaKY6u1gRW=cdN3ZTYLl8G2cLAA-r-devel=r-project.org at yahoogroupes.fr (Yahoo! Groupes)
Date: Tue Jun 29 00:02:20 2004
Subject: [Rd] Demande de confirmation d'inscription =?iso-8859-1?q?=E0?=
	mysql-france
Message-ID: <1088460136.96.20389.m17@yahoogroupes.fr>


Bonjour,

Nous avons re?u votre demande d'inscription au groupe 
mysql-france sur Yahoo! Groupes, le nouveau service de
communaut?s de Yahoo!. Pour vous inscrire, vous devez confirmer votre
demande en r?pondant ? ce message.

Si vous n'avez pas demand? ou ne souhaitez pas vous inscrire au groupe
mysql-france, veuillez ignorer ce message.


Cordialement,

L'?quipe support Yahoo! Groupes 


L'utilisation du service Yahoo! Groupes est soumise ? l'acceptation des 
Conditions d'utilisation et de la Charte sur la vie priv?e, disponibles 
respectivement sur http://fr.docs.yahoo.com/info/utos.html et
http://fr.docs.yahoo.com/info/privacy.html

From dmurdoch at pair.com  Tue Jun 29 02:07:01 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Jun 29 02:07:06 2004
Subject: [Rd] Survey: "Motivation of Free/Open Source Software (F/OSS)
	Developers"
In-Reply-To: <40E08523.3070601@web.de>
References: <40E08523.3070601@web.de>
Message-ID: <ubc1e0lho7ih58uei48njk9msvtenvkp2p@4ax.com>

On Mon, 28 Jun 2004 22:52:51 +0200, Marc R?ttig <marc-roettig@web.de>
wrote:

>Survey: "Motivation of Free/Open Source Software (F/OSS) Developers"
>
>We (Marc R?ttig and Carl-Daniel Hailfinger) are currently working
>on a survey on the motivation of open source developers as part of
>a "Computer Science and Society" project at the CS department of the
>University of T?bingen. We invite every developer in the Free / Open
>Source Software community to help us with our survey by filling out
>a little web form to give us some hints on possible motivation-motifs
>of F/OSS-developers.
>
>You can find the survey-form at
>
>                     http://foss.ta-altensteig.de/


Your survey is flawed.  In particular, question 6 does not contain any
answer that is acceptable to me:

I think about commercial closed source software ...  

 - I don?t like closed source software at all. Free Software is the
only ethical possibility

 - It's their code, so they get to choose the licence. But I will
never use it

 - Commercial closed source software is is right for the average end
user. But skilled people like me will use Open Source alternatives

 - The majority of software in the future will be some kind of Open
Source

 - The majority of software in the future will be Free Software.

 - Don?t know.  

There's no answer even remotely close to:

 - Sometimes commercial closed source software is the best choice.

I think what you'll find is that 100% of respondents are hard-core
open source supporters, because you don't give them any other choice!

Duncan Murdoch

From jerome.mutterer at ibmp-ulp.u-strasbg.fr  Tue Jun 29 09:00:39 2004
From: jerome.mutterer at ibmp-ulp.u-strasbg.fr (jerome.mutterer@ibmp-ulp.u-strasbg.fr)
Date: Tue Jun 29 09:00:41 2004
Subject: [Rd] input file and console command size limit (PR#7030)
Message-ID: <20040629070039.2D2D5FCDC@slim.kubism.ku.dk>

Full_Name: j m
Version: 1.9.0
OS: Mac OsX 10.3.4
Submission from: (NULL) (130.79.19.4)


I noticed a 1024  characters size limit when entering R commands in the R
console 
or when calling R from the command line using something like 
>R $R_in_opts $r_inputfile $R_out_opts $r_outputfile

From gregory_r_warnes at groton.pfizer.com  Tue Jun 29 16:24:42 2004
From: gregory_r_warnes at groton.pfizer.com (gregory_r_warnes@groton.pfizer.com)
Date: Tue Jun 29 16:24:45 2004
Subject: [Rd] vfont and title() (PR#7031)
Message-ID: <20040629142442.CC638108BA@slim.kubism.ku.dk>


The "Hershey" help page  states:

     If the 'vfont' argument to one of the text-drawing functions
     ('text', 'mtext', 'title', 'axis', and 'contour') is a character
     vector of length 2, Hershey vector fonts are used to render the
     text.

However, title() issues warnings and does not use the vfont information if
provided:

> title(main="test",vfont=c("sans serif","bold"))
NULL
Warning message: 
parameter "vfont" couldn't be set in high-level plot() function 
>

-Greg

Gregory R. Warnes
Manager, Non-Clinical Statistics
Pfizer Global Research and Development



LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

From jmc at research.bell-labs.com  Tue Jun 29 17:06:38 2004
From: jmc at research.bell-labs.com (John Chambers)
Date: Tue Jun 29 17:07:06 2004
Subject: [Rd] Problem with hasArg and the ... argument (PR#7027)
References: <20040628091228.B04B8EAD6@slim.kubism.ku.dk>
	<x2d63jdhne.fsf@biostat.ku.dk>
Message-ID: <40E1857E.A7B7E908@research.bell-labs.com>

Peter Dalgaard wrote:
> 
>
<..snip>

> Checking... Yep, the logic in R_sysfunction() is to give the function
> of frame #n:
> 
>     if (n > 0)
>         n = framedepth(cptr) - n;
>     else
>         n = - n;
>     if (n < 0 )
>         errorcall(R_GlobalContext->call, "illegal frame number");
>     while (cptr->nextcontext != NULL) {
>         if (cptr->callflag & CTXT_FUNCTION ) {
>             if (n == 0)
>                 return duplicate(cptr->callfun);  /***** do we need to DUP? */
>             else
>                 n--;
>         }
>         cptr = cptr->nextcontext;
>     }
> 
> whereas the documentation has
> 
>      'sys.function' gives the definition of the function currently
>      being evaluated in the frame 'n' generations back.
> 
> However, we're using the current convention in quite a few places
> (sys.function(sys.parent())) and, worse, who know what packages might
> do. It is tempting just to change the documentation, but it is part of
> a grouped documentation of sys.whatever, which has
> 
>    which: the frame number if non-negative, the number of generations
>           to go back if negative. (See the Details section.)
> 
>        n: the number of frame generations to go back.
> 
> and sys.function is documented with argument 'n', which we'd have to
> change to 'which', but the default is n=0 for "current function" which
> is unlike 'which' which has 0 meaning .GlobalEnv. Argh...
> 
> My take is that we need to fix sys.function to behave according to
> docs, change what we can in the R internals, and face the consequences
> for package maintainers.

Things are actually messier, even.

1. A counter-argument for changing the documentation might be that the
green book (p 106) and S-Plus take the argument to be the frame number
(only sys.parent(n) uses the argument for the number of frames back).

Unfortunately for the counter-argument, the (current) R implementation
and the S-Plus implementation differ in where they start indexing.  In
S-Plus, 1 is the top-level frame (corresponding to the global
environment).  In R, it is the first function call frame (and 0
corresponds to the global environment).

So there seems no way to have R/S-Plus compatibility.

2. And R-only consistency does not look too good either: sys.call() and
sys.frame() claim to have the which= behavior.  It's not very natural
for sys.function() to behave differently.

And even if that didn't bother us, sys.call(0) returns the current call,
not the "global call" (whatever that would mean), regardless of
documentation.  (The test at the bottom of this mail illustrates.)

What to do?  Well, a tentative suggestion.  
- Leave the implementation almost alone--no simple fix will clean up all
the problems. Optionally make one change: If sys.frame(0) produced the
frame of the current call, then sys.function, sys.call, and sys.frame
would be consistent.

- Change the documentation to give sys.function argument `which',
explaining that which=0 is interpreted as the current
call/function/frame.

If we wanted to leave the implementation totally unchanged, then we have
to admit the inconsistency in sys.frame, and tell people to use
sys.frame(sys.nframe()) to produce the current frame.

John



> 
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

--------------------------------------------------------------------
Example.  Source in the following function definitions:

foo <- function(n)bar(n)
bar <- function(n)baz(n)
baz <- function(n)list(sys.function(n), sys.call(n), sys.frame(n))

Call foo() with various arguments.  In R, you get:

R> foo(1)
[[1]]
function(n)bar(n)

[[2]]
foo(1)

[[3]]
<environment: 0x8eb6378>

R> foo(2)
[[1]]
function(n)baz(n)

[[2]]
bar(n)

[[3]]
<environment: 0x8eb6d24>

R> foo(3)
[[1]]
function(n)list(sys.function(n), sys.call(n), sys.frame(n))

[[2]]
baz(n)

[[3]]
<environment: 0x8eb7e68>

R> foo(0)
[[1]]
function(n)list(sys.function(n), sys.call(n), sys.frame(n))

[[2]]
baz(n)

[[3]]
<environment: R_GlobalEnv>


-----------------------------------

In S-Plus you get:

S+> foo(1)
[[1]]:
NULL

[[2]]:
[[2]]$.Last.expr:
expression(foo(1))

[[2]]$.Auto.print:
[1] T


S+> foo(2)
[[1]]:
function(n)
bar(n)

[[2]]:
foo(2)

[[3]]:
[[3]]$n:
[1] 2


S+> foo(3)
[[1]]:
function(n)
baz(n)

[[2]]:
bar(n)

[[3]]:
[[3]]$n:
[1] 3


S+> foo(0)
Problem in sys.function(n): Illegal frame number (0), should be between
1 and 5
Debug ?  ( y|n ): n

From p.dalgaard at biostat.ku.dk  Tue Jun 29 17:21:02 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Jun 29 17:22:03 2004
Subject: [Rd] Problem with hasArg and the ... argument (PR#7027)
In-Reply-To: <40E1857E.A7B7E908@research.bell-labs.com>
References: <20040628091228.B04B8EAD6@slim.kubism.ku.dk>
	<x2d63jdhne.fsf@biostat.ku.dk>
	<40E1857E.A7B7E908@research.bell-labs.com>
Message-ID: <x2r7ryfl0h.fsf@biostat.ku.dk>

John Chambers <jmc@research.bell-labs.com> writes:

> > and sys.function is documented with argument 'n', which we'd have to
> > change to 'which', but the default is n=0 for "current function" which
> > is unlike 'which' which has 0 meaning .GlobalEnv. Argh...
> > 
> > My take is that we need to fix sys.function to behave according to
> > docs, change what we can in the R internals, and face the consequences
> > for package maintainers.
> 
> Things are actually messier, even.
> 
> 1. A counter-argument for changing the documentation might be that the
> green book (p 106) and S-Plus take the argument to be the frame number
> (only sys.parent(n) uses the argument for the number of frames back).
> 
> Unfortunately for the counter-argument, the (current) R implementation
> and the S-Plus implementation differ in where they start indexing.  In
> S-Plus, 1 is the top-level frame (corresponding to the global
> environment).  In R, it is the first function call frame (and 0
> corresponds to the global environment).
> 
> So there seems no way to have R/S-Plus compatibility.
> 
> 2. And R-only consistency does not look too good either: sys.call() and
> sys.frame() claim to have the which= behavior.  It's not very natural
> for sys.function() to behave differently.
> 
> And even if that didn't bother us, sys.call(0) returns the current call,
> not the "global call" (whatever that would mean), regardless of
> documentation.  (The test at the bottom of this mail illustrates.)
> 
> What to do?  Well, a tentative suggestion.  
> - Leave the implementation almost alone--no simple fix will clean up all
> the problems. Optionally make one change: If sys.frame(0) produced the
> frame of the current call, then sys.function, sys.call, and sys.frame
> would be consistent.
> 
> - Change the documentation to give sys.function argument `which',
> explaining that which=0 is interpreted as the current
> call/function/frame.
> 
> If we wanted to leave the implementation totally unchanged, then we have
> to admit the inconsistency in sys.frame, and tell people to use
> sys.frame(sys.nframe()) to produce the current frame.

(or environment()!) 

Changing the behaviour of sys.frame() would probably mess rather badly
with the sys.frame(sys.parent()) idiom whenever sys.parent() returns
zero (yes I know about parent.frame(), but does everybody else?).

Probably, we should just document what we got, possibly changing the
argument name in sys.function() from n to which. I think we might be
able to explain succinctly that sys.call(0) and sys.function(0) gives
current call and function, since there is no "top level" definitions
of the two.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From andy_liaw at merck.com  Tue Jun 29 21:20:48 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Jun 29 21:21:22 2004
Subject: [Rd] suggestion for ?read.table
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FAF@usrymx25.merck.com>

Dear R-devel,

May I suggest the following, or something to its effect (taken from the R
Data Import Export manual, item #8 in section 2.1) be added to the
colClasses argument in ?read.table:

Note that colClasses and as.is are specified per column, not per variable,
and so
include the column of row names (if any).

Thanks!
Andy

From ripley at stats.ox.ac.uk  Tue Jun 29 22:34:39 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Jun 29 22:34:42 2004
Subject: [Rd] suggestion for ?read.table
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7FAF@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0406292131500.6777-100000@gannet.stats>

Thanks, I have added this.

Not that, as a recent posting on R-help shows, some people will read it 
...


On Tue, 29 Jun 2004, Liaw, Andy wrote:

> Dear R-devel,
> 
> May I suggest the following, or something to its effect (taken from the R
> Data Import Export manual, item #8 in section 2.1) be added to the
> colClasses argument in ?read.table:
> 
> Note that colClasses and as.is are specified per column, not per variable,
> and so
> include the column of row names (if any).


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From vograno at evafunds.com  Wed Jun 30 03:46:08 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Wed Jun 30 03:46:28 2004
Subject: [Rd] Slow IO: was [R] naive question
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A5568C47@phost015.EVAFUNDS.intermedia.net>

I believe IO in R is slow because of the way it is implemented, not
because it has to do some extra work for the user. 

I compared scan() with 'what' argument set (which is, AFAIK, is the
fastest way to read a CSV file) to an equivalent C code. It turned out
to be 20 - 50 times slower.
I can see at least two main reasons why R's IO is so slow (I didn't
profile this though):
A) it reads from a connection char-by-char as opposed to the buffered
read. Reading each char requires a call to scanchar() which then calls
Rconn_fgetc() (with some non-trivial overhead). Rconn_fgetc() on its
part is defined somewhere else (not in scan.c) and therefore the call
can not be inlined, etc.
B) mkChar, which is used very extensively, is too slow. There are ways
to minimize the number of calls to mkChar, but I won't expand on it in
this message.

I brought this up because it seems that many people believe that the
slowness is inherent and is a tradeoff for something else. I don't think
this is the case.

Thanks,
Vadim

-----Original Message-----
From: r-help-bounces@stat.math.ethz.ch
[mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of Douglas Bates
Sent: Tuesday, June 29, 2004 5:56 PM
To: Igor Rivin
Cc: r-help@stat.math.ethz.ch
Subject: Re: [R] naive question

Igor Rivin wrote:

> I was not particularly annoyed, just disappointed, since R seems like 
> a much better thing than SAS in general, and doing everything with a 
> combination of hand-rolled tools is too much work. However, I do need 
> to work with very large data sets, and if it takes 20 minutes to read 
> them in, I have to explore other options (one of which might be
S-PLUS, which claims scalability as a major , er, PLUS over R).


If you are routinely working with very large data sets it would be
worthwhile learning to use a relational database (PostgreSQL, MySQL,
even Access) to store the data and then access it from R with RODBC or
one of the specialized database packages.

R is slow reading ASCII files because it is assembling the meta-data on
the fly and it is continually checking the types of the variables being
read.  If you know all this information and build it into your table
definitions, reading the data will be much faster.

A disadvantage of this approach is the need to learn yet another
language and system.  I was going to do an example but found I could not
because I left all my SQL books at home (I'm travelling at the moment)
and I couldn't remember the particular commands for loading a table from
an ASCII file.

______________________________________________
R-help@stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

From p.dalgaard at biostat.ku.dk  Wed Jun 30 12:09:42 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed Jun 30 12:10:41 2004
Subject: [Rd] Slow IO: was [R] naive question
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A5568C47@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A5568C47@phost015.EVAFUNDS.intermedia.net>
Message-ID: <x2zn6lqrvd.fsf@biostat.ku.dk>

"Vadim Ogranovich" <vograno@evafunds.com> writes:

> I believe IO in R is slow because of the way it is implemented, not
> because it has to do some extra work for the user. 
> 
> I compared scan() with 'what' argument set (which is, AFAIK, is the
> fastest way to read a CSV file) to an equivalent C code. It turned out
> to be 20 - 50 times slower.
> I can see at least two main reasons why R's IO is so slow (I didn't
> profile this though):
> A) it reads from a connection char-by-char as opposed to the buffered
> read. Reading each char requires a call to scanchar() which then calls
> Rconn_fgetc() (with some non-trivial overhead). Rconn_fgetc() on its
> part is defined somewhere else (not in scan.c) and therefore the call
> can not be inlined, etc.
> B) mkChar, which is used very extensively, is too slow. There are ways
> to minimize the number of calls to mkChar, but I won't expand on it in
> this message.
> 
> I brought this up because it seems that many people believe that the
> slowness is inherent and is a tradeoff for something else. I don't think
> this is the case.

Do you have some hard data on the relative importance of the above
issues?

I wouldn't think that R is really unbuffered, since there is buffering
underlying the various fgetc() variants. Most C programs will do
char-by-char processing by the same definition. The lack of inlining
is sort of a consequence of a design where Rconn_fgetc() is
switchable. However, conventional wisdom is that all of this tends to
drown out compared to disk i/o. This might be a changing balance, but
I think you're more on the mark with the mkChar issue. (Then again, it
is quite a bit easier to come up with buffering designs for
Rconn_fgetc than it is to redefine STRSXP...)
 
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From daniel.hoppe at univie.ac.at  Wed Jun 30 17:40:21 2004
From: daniel.hoppe at univie.ac.at (Daniel Hoppe)
Date: Wed Jun 30 17:40:37 2004
Subject: [Rd] AS_NUMERIC and as.numeric - Could someone explain?
Message-ID: <000701c45eb8$8e001520$82b98283@DH>

Dear List,

I stepped into a strange effect which I can't explain to myself
(probably due to lack of knowledge on R internals). 

I have four vectors a,b,c and z of size 10000 each. With these vectors I
call

    .Call("hyp2f1forrey", a, b, b, z, PACKAGE = "hyp2f1")

to access 

SEXP hyp2f1forrey(SEXP a, SEXP b, SEXP c, SEXP x)
{
    int i,n;
    double *xa, *xb, *xc, *xx, *xresr, *xresi;
    SEXP resr, resi;

    n = LENGTH(a);

    PROTECT(a = AS_NUMERIC(a));
    PROTECT(b = AS_NUMERIC(b));
    PROTECT(c = AS_NUMERIC(c));
    PROTECT(x = AS_NUMERIC(x));
    PROTECT(resr = NEW_NUMERIC(n));
    PROTECT(resi = NEW_NUMERIC(n));

    xa = NUMERIC_POINTER(a);
    xb = NUMERIC_POINTER(b);
    xc = NUMERIC_POINTER(c);
    xx = NUMERIC_POINTER(x);
    xresr = NUMERIC_POINTER(resr);
    xresi = NUMERIC_POINTER(resi);

    for (i = 0; i < n; i++)
        F77_CALL(hyp)(&xx[i], &xa[i], &xb[i], &xc[i],  &xresr[i],
&xresi[i]);
    UNPROTECT(6);
    return(resr);
}

I read the documentation in the way that I could either do the call from
above or  

    .Call("hyp2f1forrey", as.numeric(a), as.numeric(b), as.numeric(b),
as.numeric(z), PACKAGE = "hyp2f1")

and remove the 

    PROTECT(a = AS_NUMERIC(a));
    PROTECT(b = AS_NUMERIC(b));
    PROTECT(c = AS_NUMERIC(c));
    PROTECT(x = AS_NUMERIC(x));

in the C-Code. What happens now is that in my resulting vector of length
10000 some values are incorrect depending on the exact way of calling
the C-Function. 

    .Call("hyp2f1forrey", a, b, b, z, PACKAGE = "hyp2f1")[11]  -->
incorrect result
    .Call("hyp2f1forrey", a[11], b[11], b[11]), z[11]), PACKAGE =
"hyp2f1") --> works
    .Call("hyp2f1forrey", as.numeric(a), as.numeric(b), as.numeric(c),
as.numeric(z), PACKAGE = "hyp2f1")[11] -- works
    .Call("hyp2f1forrey", a[1:10000], b[1:10000], b[1:10000]),
z[1:10000]), PACKAGE = "hyp2f1") --> works too!


Could someone explain to me where the difference in these calls comes
from?

Thanks in advance,

Daniel

From NAVMSE-EXCHANGE_MUC at muc.guj.de  Wed Jun 30 18:14:11 2004
From: NAVMSE-EXCHANGE_MUC at muc.guj.de (=?iso-8859-1?Q?NAV_f=FCr_MS_Exchange-EXCHANGE=5FMUC?=)
Date: Wed Jun 30 18:15:35 2004
Subject: [Rd] =?iso-8859-1?q?Norton_AntiVirus_hat_einen_Virus_in_einer_vo?=
	=?iso-8859-1?q?n_Ihnen_gesendeten_Nachricht_ermittelt=2E_Die_infiz?=
	=?iso-8859-1?q?ierte_Anlage_wurde_gel=F6scht=2E?=
Message-ID: <91E1EE818590D211933E0008C74CFB79020A13E9@exchange.muc.guj.de>

Empf?nger der infizierten Anlage: Putz, Christine\Posteingang
Betreff der Nachricht: {Spam?:12.78} Re: Extended Mail
Mindestens eine Anlage wurde gel?scht
  Anlage message.zip wurde aus folgendem Grund Gel?scht:
    Virus W32.Netsky.P@mm gefunden.
    Der Virus W32.Netsky.P@mm wurde in details.txt
.pif gefunden.
From NAVMSE-EXCHANGE_MUC at muc.guj.de  Wed Jun 30 18:14:11 2004
From: NAVMSE-EXCHANGE_MUC at muc.guj.de (=?iso-8859-1?Q?NAV_f=FCr_MS_Exchange-EXCHANGE=5FMUC?=)
Date: Wed Jun 30 18:15:40 2004
Subject: [Rd] =?iso-8859-1?q?Norton_AntiVirus_hat_einen_Virus_in_einer_vo?=
	=?iso-8859-1?q?n_Ihnen_gesendeten_Nachricht_ermittelt=2E_Die_infiz?=
	=?iso-8859-1?q?ierte_Anlage_wurde_gel=F6scht=2E?=
Message-ID: <91E1EE818590D211933E0008C74CFB79020A13E8@exchange.muc.guj.de>

Empf?nger der infizierten Anlage: Korn, Renate\Posteingang
Betreff der Nachricht: {Spam?:12.78} Re: Extended Mail
Mindestens eine Anlage wurde gel?scht
  Anlage message.zip wurde aus folgendem Grund Gel?scht:
    Virus W32.Netsky.P@mm gefunden.
    Der Virus W32.Netsky.P@mm wurde in details.txt
.pif gefunden.
From cornulier at cebc.cnrs.fr  Wed Jun 30 22:06:29 2004
From: cornulier at cebc.cnrs.fr (cornulier@cebc.cnrs.fr)
Date: Wed Jun 30 22:06:32 2004
Subject: [Rd] R crashes (PR#7037)
Message-ID: <20040630200629.55CE510943@slim.kubism.ku.dk>

Full_Name: thomas cornulier
Version: 1.9.0 and 1.9.1
OS: Win XP
Submission from: (NULL) (194.254.155.62)


the following function produces R crashes under windows XP
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    9.1            
year     2004           
month    06             
day      21             
language R

start code-----
ts.cor<- function(Variable, Xcoord, Ycoord, Year){
  ts<- tapply(Variable, list(Year, paste(Xcoord, Ycoord)), mean)
  for(j in 1:500) {
    samp<- sample(seq(ncol(ts)), replace= T)
    cor.ts.boot<- cor(ts[, samp], use= "p", method= "spearman")
    cor.ts.boot<- cor.ts.boot[lower.tri(cor.ts.boot)]
  }
}

V<- rpois(180, 0.05)
X<- rep.int(runif(20), 9)
Y<- rep.int(runif(20), 9)
Yr<- rep(1:9, each= 20)
b<- ts.cor(V, X, Y, Yr)

end code------

use= "c" or use= "a" in cor() cause systematic crash, whereas use= "p" produces
crashes or inconsistent error messages:
Error in cor.ts.boot[lower.tri(cor.ts.boot)] : 
        object is not subsettable
In addition: There were 50 or more warnings (use warnings() to see the first
50)

Error in as.vector(x, mode) : cannot coerce to vector
In addition: There were 22 warnings (use warnings() to see them)

Error: invalid type/length (4/399) in vector allocation
In addition: There were 50 or more warnings (use warnings() to see the first
50)

Error in cor.ts.boot[lower.tri(cor.ts.boot)] : 
        Unimplemented feature in type2str
In addition: There were 50 or more warnings (use warnings() to see the first
50)

Error in cor.ts.boot[lower.tri(cor.ts.boot)] : 
        Unimplemented feature in type2str
In addition: There were 22 warnings (use warnings() to see them)


Behaviour similar whatever the method specification in cor(),
but V has to contain many ties for the errors/crashes being produced.
(problems fixed by jittering V)
V<- jitter(rpois(180, 0.05), a=0.001)

Crash occured at line 6 of the function when using debug()

Hope I didn't miss something obvious,
Thomas

From vograno at evafunds.com  Wed Jun 30 22:13:18 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Wed Jun 30 22:13:40 2004
Subject: [Rd] Slow IO: was [R] naive question
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A5568C7C@phost015.EVAFUNDS.intermedia.net>

> -----Original Message-----
> From: Peter Dalgaard [mailto:p.dalgaard@biostat.ku.dk] 
> Sent: Wednesday, June 30, 2004 3:10 AM
> To: Vadim Ogranovich
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] Slow IO: was [R] naive question
> 
> "Vadim Ogranovich" <vograno@evafunds.com> writes:
> 
> > ...
> > I can see at least two main reasons why R's IO is so slow (I didn't 
> > profile this though):
> > A) it reads from a connection char-by-char as opposed to 
> the buffered 
> > read. Reading each char requires a call to scanchar() which 
> then calls
> > Rconn_fgetc() (with some non-trivial overhead). 
> Rconn_fgetc() on its 
> > part is defined somewhere else (not in scan.c) and 
> therefore the call 
> > can not be inlined, etc.
> > B) mkChar, which is used very extensively, is too slow. 
> > ...
> 
> Do you have some hard data on the relative importance of the 
> above issues?

Well, here is a little analysis which sheds some light. I have a file,
foo, 154M uncompressed. It contains about 3.8M lines

01/02% ls -l foo*
-rw-rw-r--    1 vograno  man      153797513 Jun 30 11:56 foo
-rw-rw-r--    1 vograno  man      21518547 Jun 30 11:56 foo.gz

# reading the files using standard UNIX utils takes no time
01/02% time cat foo > /dev/null
0.030u 0.110s 0:00.80 17.5%	0+0k 0+0io 124pf+0w
01/02% time zcat foo.gz  > /dev/null
1.210u 0.030s 0:01.24 100.0%	0+0k 0+0io 90pf+0w

# compute exact line count
01/02% zcat foo.gz | wc
3794929 3794929 153797513


# now we fire R-1.8.1
# we will experiment with the gzip-ed copy since we've seen that the
overhead of decompression is trivial
> nlines <- 3794929

# this exercises scanchar(), but not mkChar(), see scan() in scan.c
> system.time(scan(gzfile("foo.gz", open="r"), what="character", skip =
nlines - 1))
system.time(scan(gzfile("foo.gz", open="r"), what="character", skip =
nlines - 1))
Read 1 items
[1] 67.83  0.01 68.04  0.00  0.00

# this exercises both scanchar() and mkChar()
system.time(readLines(gzfile("foo.gz", open="r"), n = nlines))
[1] 110.61   0.83 112.44   0.00   0.00

It seems that scanchar() and mkChar() have comparable overheads in this
case.


> ... This might be a changing balance, but I 
> think you're more on the mark with the mkChar issue. (Then 
> again, it is quite a bit easier to come up with buffering 
> designs for Rconn_fgetc than it is to redefine STRSXP...)

First off all I agree that redefining STRSXP is not easy, but this has a
potential to considerably speed up R as whole since name propagation
would work faster.
As to the mkChar() in scan() there are few tricks that can help. Say we
have a CSV file that contains categorical and numerical data. Here is
what we can do to minimize the number of calls to mkChar:

* when reading the file in as a bunch of lines (before type conversion)
do not call mkChar, rather pre-allocate large temporary char * arrays
(via R_alloc) and store the lines sequentially in the arrays. This
allows us to read the file into the memory with just few, however
expensive, calls to R_alloc. Here the arrays effectively serve as a heap
which will released by R at the end of the call.

* Field conversion
	- when converting numeric fields there is no need to call mkChar
at all (obvious)
	- when creating char fields that correspond to categorical data
(going from the first element to the end) we can maintain a hash table
that maps, char* -> SEXP, the field values encountered so far. When we
get a new field value we first look it up in the hash table and if it is
already there we use the corresponding SEXP to assign to the string
element. This leads to a considerable speed-up in the common case where
most field values are drawn from a small (<1000) set of "factor levels".


And a final observation once we are on the scan() subject. I've found it
more convenient to convert data column-by-column rather than row-by-row.
When you do it column-by-column you
* figure out the type of the column only once. Ditto about the
destination vector.
* maintain only one hash table for the current column, not for all
columns at once.


Thanks,
Vadim

From jmc at research.bell-labs.com  Wed Jun 30 23:16:58 2004
From: jmc at research.bell-labs.com (John Chambers)
Date: Wed Jun 30 23:17:08 2004
Subject: [Rd] S4 group "Math", "getGroupMembers", "genericForPrimitive"
References: <1185.132.180.246.23.1088241988.squirrel@mail.uni-bayreuth.de>
Message-ID: <40E32DCA.622FABF4@research.bell-labs.com>

R is not S4, the system that the green book describes, although we try
to be compatible where there is not a serious reason to be different. 
The behavior of group generics and of the basic functions, such as those
in the Math group, differs.

First, functions such as "log", "sin", and their peers are not generic
functions by default in R.

Second, defining methods for the group generic does not automatically
turn the members of the group into generic functions.

Some comments about the reason for this approach are given below.  But
the implication is that code wishing to define methods for the group
generic needs to ensure that all the relevant group members are set to
be generic functions from the group.

We can provide a function that does this in one step (if no problems
arise, it will be in the next release).  A simple version of it would
look like this:

setGroupMembersOn <- function(group) {
    groupFun <- getGeneric(group)
    for(fun in groupFun@groupMembers)
        if(!isGeneric(fun) && !is.primitive(getFunction(fun)))
            setGeneric(fun, group = group)
}

            
The actual version will be somewhat more careful, but this should work
in the obvious cases.

Calling
   setGroupMembersOn("Math")
either before or after the setMethod() calls, seems to give the desired
effect.

End of the practical part.  Some comments on this and on the other
questions in your mail:

- The reason for the two differences noted from S4 is efficiency.  When
S4-style methods were being introduced in R, there was concern not to
slow down basic computations on basic data (e.g, math functions on
ordinary numeric vectors).  Therefore, the math functions are left
non-generic by default and setting group methods does not change that. 
The exception is that functions which are primitives in R have special
code for dispatching methods.  This code exits quickly for ordinary
vectors.  So primitive functions ARE dispatched.

Some of the Math group are primitive functions and some are not.  That's
why there is inconsistent behavior.  It will stay that way unless the R
developers decide that consistency is worth the inefficiency of turning
the non-primitves into generic functions. (Probably will have to wait
until method dispatch can be made more efficient.)

What we can & should do for the next release is to include the
explanation in the documentation of group generic functions.

- as for the getGroupMembers function, yes it seems good to add that for
compatibility.  But notice that the current implementation stores the
members as a slot in the group generic function object.  So
  Math@groupMembers
gives a list of the members, as would getGroupMembers("Math").

- genericForPrimitive does not appear because it is not exported from
the namespace in the methods package (and probably shouldn't be, since
it's not really meaningful apart from the current implementation).

Matthias.Kohl@uni-bayreuth.de wrote:
> 
> Hi,
> 
> I found the following on Windows 2000/NT
> R Version 1.9.1  (2004-06-21) (also Version 1.9.0):
> 
> The S4 group "Math" doesn't work as documented; i.e., "log", "log10",
> "gamma" and "lgamma" are included
> in the documentation but don't work. See example code below.
> 
> Moreover, what about 'genericForPrimitive' which is used
> in 'getGeneric'. It seems that this method is not included in
> the R Version 1.9.1 (also 1.9.0). See the example code of
> John Chambers at the end of this email.
> 
> Why not add the method 'getGroupMembers' as proposed by John Chambers
> to the methods package?
> (see reply to mail: "Missing 'getGroupMembers()'"
>  from Sat May 31 2003 - 15:18:18 EDT)
> 
> Thanks for your attention,
> Matthias
> 
> ###################################################
> ## Example Code
> ###################################################
> ## Example Code from the "green book"
> setClass("track", representation(x = "numeric", y = "numeric"))
> 
> setMethod("Math", "track",
>             function(x){ x@y = callGeneric(x@y); x })
> 
> tr1 <- new("track", x = 1:3, y = 1:3)
> tr1
> 
> ## are documented as belonging to group "Math"
> ## see ?"Math"
> ## but don't work
> log(tr1)
> log10(tr1)
> gamma(tr1)
> lgamma(tr1)
> 
> ## are not generic and don't belong to any group!
> is("log", "genericFunction")
> is("log10", "genericFunction")
> is("gamma", "genericFunction")
> is("lgamma", "genericFunction")
> getGroup("log")
> getGroup("log10")
> getGroup("gamma")
> getGroup("lgamma")
> 
> ## make this functions generic and add to group "Math"
> ## (only local!)
> setGeneric("log", function(x, base) standardGeneric("log"), group = "Math")
> setGeneric("log10", function(x) standardGeneric("log10"), group = "Math")
> setGeneric("gamma", function(x) standardGeneric("gamma"), group = "Math")
> setGeneric("lgamma", function(x) standardGeneric("lgamma"), group = "Math")
> 
> setMethod("Math", "track",
>             function(x){ x@y = callGeneric(x@y); x })
> 
> ## now works as documented
> log(tr1)
> log10(tr1)
> gamma(tr1)
> lgamma(tr1)
> 
> ## By John Chambers:
> ## "... the following code implements what one is
> ## likely to want in most cases." (see reply
> ## to mail: "Missing 'getGroupMembers()'"
> ## from Sat May 31 2003 - 15:18:18 EDT)
> ## Modification of this code
> ## since 'genericForPrimitive' is not defined (?)
> ## although it is called in 'getGeneric'!!!
> getGroups <- function(what = c(getGenerics(), names(.BasicFunsList))) {
>     what <- what[what != "is.function"]
>     what <- what[what != "is.null"]
>     what <- what[what != "is.object"]
>     g <-unlist(sapply(what,
>           function(x){
>                 f <- getGeneric(x)
>                 if(is(f, "genericFunction"))f@group else NULL
>           }))
>     split(names(g), g)
> }
> getGroupMembers <- function(group, whatGenerics) {
>     groups <- if(missing(whatGenerics)) getGroups()
>               else getGroups(whatGenerics)
>     elNamed(groups, group)
> }
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

