From tlumley at u.washington.edu  Sat Jan  1 01:08:37 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat Jan  1 01:08:47 2005
Subject: [Rd] optim/vmmin and R_alloc
In-Reply-To: <20041231103325.GA5410@tal.stat.umu.se>
References: <20041230155513.GA22178@tal.stat.umu.se>
	<Pine.A41.4.61b.0412300757350.11816@homer11.u.washington.edu>
	<20041230185913.GA1735@tal.stat.umu.se>
	<Pine.A41.4.61b.0412301418350.219480@homer09.u.washington.edu>
	<20041231103325.GA5410@tal.stat.umu.se>
Message-ID: <Pine.A41.4.61b.0412311551030.53274@homer12.u.washington.edu>

On Fri, 31 Dec 2004, [iso-8859-1] G?ran Brostr?m wrote:
>
> Regarding 2., I tried the combination vmaxget + Calloc + vmaxset, ie, I
> began my function with vmax = vmaxget() and ended it with
> vmaxset(vmax). The point with this is that you can free all allocated
> memory with one call instead of repeated calls to Free. This seemed to work
> well; however, it is undocumented, and may well be completely wrong.

I think it's completely wrong.  Free is just a wrapper for free() from the 
C library, and vmaxset() works only on the R heap and contains no calls to 
free(), so they shouldn't intersect at all. The memory leak will 
happen outside the R heap, and it may be less obvious there as long as you 
aren't short of virtual memory.

Calloc/Free still follow the basic C rule that you must call Free exactly 
once on each pointer returned by Calloc.  The fact that Free sets its 
argument to NULL reduces somewhat the likelihood of damage from calling 
Free more than once, but only reduces it, since Free can't set other 
copies of the pointer to NULL.

 	-thomas
From Gregor.Gorjanc at bfro.uni-lj.si  Sat Jan  1 13:05:48 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Sat Jan  1 13:06:59 2005
Subject: [Rd] R-intro
Message-ID: <7FFEE688B57D7346BC6241C55900E7300FD043@pollux.bfro.uni-lj.si>

The problem is that there is no file morley.tab. I belive that for first impression or example session, things should work.

>file.show("morley.tab")
>mm <- read.table("morley.tab")

-----Original Message-----
From: Kjetil Brinchmann Halvorsen [mailto:kjetil@acelerate.com]
Sent: Fri 2004-12-31 22:01
To: Gorjanc Gregor
Cc: r-devel@stat.math.ethz.ch
Subject: Re: [Rd] R-intro
 
Gorjanc Gregor wrote:

>Hello!
>
>I was reading R-intro and I have some suggestions:
>
>R-intro.html#A-sample-session
>
>rm(fm, fm1, lrf, x, dummy)
>suggestion
>rm(fm, fm1, lrf, x, y, w, dummy)
>
>The next section will look at data from the classical experiment of Michaelson and Morley to measure the speed of light.
>
>file.show("morley.tab")
>mm <- read.table("morley.tab")
>suggestion
>mm <- data(morley)
>  
>
No. Although this looks easier, the whole point is to show people how to 
use read.table!

Kjetil

>rm(fm, fm0)
>suggestion
>rm(fm, fm0, mm)
>
>objects(); rm(x, y, f, fa)
>suggestion
>objects(); rm(x, y, f, fa, oldpar)
>
>It might also be usefull to use # for comments, since it is easier to
>copy&paste to R terminal from manual.
>
>--
>Lep pozdrav / With regards,
>    Gregor GORJANC
>
>---------------------------------------------------------------
>University of Ljubljana
>Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
>Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
>Groblje 3                  tel: +386 (0)1 72 17 861
>SI-1230 Domzale            fax: +386 (0)1 72 17 888
>Slovenia
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.

From ligges at statistik.uni-dortmund.de  Sat Jan  1 17:24:33 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Jan  1 17:22:27 2005
Subject: [Rd] R-intro
In-Reply-To: <7FFEE688B57D7346BC6241C55900E7300FD043@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E7300FD043@pollux.bfro.uni-lj.si>
Message-ID: <41D6CEC1.1070207@statistik.uni-dortmund.de>

Gorjanc Gregor wrote:
> The problem is that there is no file morley.tab. I belive that for first impression or example session, things should work.

Have you read from the beginning in Appendix A? It says:

"Login, start your windowing system. You should also have the file
?morley.tab? in your working directory. If not, seek the local expert
(or get it yourself from the ?datasets/data? subdirectory of the default
R library tree). If you have, proceed."

The point is that we cannot get the file anymore from "datasets/data", 
because since the days of R-2.0.0 we have the data in package "datasets" 
lazy loaded and the file "morley.tab" is not available in binary 
installations. Hence it is a bug.

Possible solution:
We could copy the file to something like 
.../src/library/datasets/inst/intro/morley.tab

It would also make sense to simplify the Appendix A stuff in R-intro, 
because this is (well, has been) a more or less frequently asked 
question (I wonder why nobody has asked during the last 3 months ....):


filename <- file.path(.find.package("datasets"), "intro", "morley.tab"))
filename
file.show(filename)
mm <- read.table(filename)

Uwe Ligges


> 
>>file.show("morley.tab")
>>mm <- read.table("morley.tab")
> 
> 
> -----Original Message-----
> From: Kjetil Brinchmann Halvorsen [mailto:kjetil@acelerate.com]
> Sent: Fri 2004-12-31 22:01
> To: Gorjanc Gregor
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] R-intro
>  
> Gorjanc Gregor wrote:
> 
> 
>>Hello!
>>
>>I was reading R-intro and I have some suggestions:
>>
>>R-intro.html#A-sample-session
>>
>>rm(fm, fm1, lrf, x, dummy)
>>suggestion
>>rm(fm, fm1, lrf, x, y, w, dummy)
>>
>>The next section will look at data from the classical experiment of Michaelson and Morley to measure the speed of light.
>>
>>file.show("morley.tab")
>>mm <- read.table("morley.tab")
>>suggestion
>>mm <- data(morley)
>> 
>>
> 
> No. Although this looks easier, the whole point is to show people how to 
> use read.table!
> 
> Kjetil
> 
> 
>>rm(fm, fm0)
>>suggestion
>>rm(fm, fm0, mm)
>>
>>objects(); rm(x, y, f, fa)
>>suggestion
>>objects(); rm(x, y, f, fa, oldpar)
>>
>>It might also be usefull to use # for comments, since it is easier to
>>copy&paste to R terminal from manual.
>>
>>--
>>Lep pozdrav / With regards,
>>   Gregor GORJANC
>>
>>---------------------------------------------------------------
>>University of Ljubljana
>>Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
>>Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
>>Groblje 3                  tel: +386 (0)1 72 17 861
>>SI-1230 Domzale            fax: +386 (0)1 72 17 888
>>Slovenia
>>
>>______________________________________________
>>R-devel@stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>> 
>>
> 
> 
>

From murdoch at stats.uwo.ca  Sat Jan  1 20:04:15 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat Jan  1 20:03:29 2005
Subject: [Rd] R-intro
In-Reply-To: <41D6CEC1.1070207@statistik.uni-dortmund.de>
References: <7FFEE688B57D7346BC6241C55900E7300FD043@pollux.bfro.uni-lj.si>
	<41D6CEC1.1070207@statistik.uni-dortmund.de>
Message-ID: <g0tdt0t5890jsli3m2kn8gab87t2jrtjss@4ax.com>

On Sat, 01 Jan 2005 17:24:33 +0100, Uwe Ligges
<ligges@statistik.uni-dortmund.de> wrote:

>Gorjanc Gregor wrote:
>> The problem is that there is no file morley.tab. I belive that for first impression or example session, things should work.
>
>Have you read from the beginning in Appendix A? It says:
>
>"Login, start your windowing system. You should also have the file
>?morley.tab? in your working directory. If not, seek the local expert
>(or get it yourself from the ?datasets/data? subdirectory of the default
>R library tree). If you have, proceed."
>
>The point is that we cannot get the file anymore from "datasets/data", 
>because since the days of R-2.0.0 we have the data in package "datasets" 
>lazy loaded and the file "morley.tab" is not available in binary 
>installations. Hence it is a bug.
>
>Possible solution:
>We could copy the file to something like 
>.../src/library/datasets/inst/intro/morley.tab
>
>It would also make sense to simplify the Appendix A stuff in R-intro, 
>because this is (well, has been) a more or less frequently asked 
>question (I wonder why nobody has asked during the last 3 months ....):
>
>
>filename <- file.path(.find.package("datasets"), "intro", "morley.tab"))
>filename
>file.show(filename)
>mm <- read.table(filename)
>
>Uwe Ligges

Good suggestions.  I'll make the changes in R-patched.

Duncan Murdoch

From Gregor.Gorjanc at bfro.uni-lj.si  Sun Jan  2 01:23:21 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Sun Jan  2 01:23:25 2005
Subject: [Rd] R-intro
Message-ID: <7FFEE688B57D7346BC6241C55900E7300FD049@pollux.bfro.uni-lj.si>

Nice. So, I was successfull afterall!

Thanks again to all R developers for such a usefull program. Happy new
year with small number of bugs and many new functions ;)

--
Lep pozdrav / With regards,
    Gregor GORJANC

---------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia
---------------------------------------------------------------



-----Original Message-----
From: Duncan Murdoch [mailto:murdoch@stats.uwo.ca]
Sent: sob 2005-01-01 20:04
To: Uwe Ligges
Cc: Gorjanc Gregor; Kjetil Brinchmann Halvorsen; r-devel@stat.math.ethz.ch
Subject: Re: [Rd] R-intro
 
On Sat, 01 Jan 2005 17:24:33 +0100, Uwe Ligges
<ligges@statistik.uni-dortmund.de> wrote:

>Gorjanc Gregor wrote:
>> The problem is that there is no file morley.tab. I belive that for first impression or example session, things should work.
>
>Have you read from the beginning in Appendix A? It says:
>
>"Login, start your windowing system. You should also have the file
>'morley.tab' in your working directory. If not, seek the local expert
>(or get it yourself from the 'datasets/data' subdirectory of the default
>R library tree). If you have, proceed."
>
>The point is that we cannot get the file anymore from "datasets/data", 
>because since the days of R-2.0.0 we have the data in package "datasets" 
>lazy loaded and the file "morley.tab" is not available in binary 
>installations. Hence it is a bug.
>
>Possible solution:
>We could copy the file to something like 
>.../src/library/datasets/inst/intro/morley.tab
>
>It would also make sense to simplify the Appendix A stuff in R-intro, 
>because this is (well, has been) a more or less frequently asked 
>question (I wonder why nobody has asked during the last 3 months ....):
>
>
>filename <- file.path(.find.package("datasets"), "intro", "morley.tab"))
>filename
>file.show(filename)
>mm <- read.table(filename)
>
>Uwe Ligges

Good suggestions.  I'll make the changes in R-patched.

Duncan Murdoch

From andrewr at uidaho.edu  Mon Jan  3 08:56:17 2005
From: andrewr at uidaho.edu (andrewr@uidaho.edu)
Date: Mon Jan  3 08:56:20 2005
Subject: [Rd] Plot elements echo NULL (PR#7466)
Message-ID: <20050103075617.4AEC6F33A@slim.kubism.ku.dk>

Full_Name: Andrew Robinson
Version: 2.0.1
OS: FreeBSD
Submission from: (NULL) (211.28.168.242)


Certain plot elements echo NULL when they are set.  For example,

> plot(1:10,1:10)
> axis(1)
NULL
> mtext("test")
NULL
> 

In previous versions the functions were silent.

From ligges at statistik.uni-dortmund.de  Mon Jan  3 09:26:36 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Mon Jan  3 09:26:41 2005
Subject: [Rd] Plot elements echo NULL (PR#7466)
Message-ID: <20050103082636.7C1DCEAB6@slim.kubism.ku.dk>

andrewr@uidaho.edu wrote:
> Full_Name: Andrew Robinson
> Version: 2.0.1
> OS: FreeBSD
> Submission from: (NULL) (211.28.168.242)
> 
> 
> Certain plot elements echo NULL when they are set.  For example,
> 
> 
>>plot(1:10,1:10)
>>axis(1)
> 
> NULL
> 
>>mtext("test")
> 
> NULL
> 
> 
> In previous versions the functions were silent.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


This has been reported by Peter Dalgaard in PR#7397.
Please check whether a bug has already been reported before submitting a 
new report.

Uwe Ligges

From andrewr at uidaho.edu  Mon Jan  3 09:46:57 2005
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Mon Jan  3 09:48:00 2005
Subject: [Rd] Plot elements echo NULL (PR#7466)
In-Reply-To: <20050103082636.7C1DCEAB6@slim.kubism.ku.dk>
References: <20050103082636.7C1DCEAB6@slim.kubism.ku.dk>
Message-ID: <20050103084657.GT15354@uidaho.edu>

My apologies.

Andrew.

On Mon, Jan 03, 2005 at 09:26:36AM +0100, ligges@statistik.uni-dortmund.de wrote:
> andrewr@uidaho.edu wrote:
> > Full_Name: Andrew Robinson
> > Version: 2.0.1
> > OS: FreeBSD
> > Submission from: (NULL) (211.28.168.242)
> > 
> > 
> > Certain plot elements echo NULL when they are set.  For example,
> > 
> > 
> >>plot(1:10,1:10)
> >>axis(1)
> > 
> > NULL
> > 
> >>mtext("test")
> > 
> > NULL
> > 
> > 
> > In previous versions the functions were silent.
> > 
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> This has been reported by Peter Dalgaard in PR#7397.
> Please check whether a bug has already been reported before submitting a 
> new report.
> 
> Uwe Ligges
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Andrew Robinson                      Ph: 208 885 7115
Department of Forest Resources       Fa: 208 885 6226
University of Idaho                  E : andrewr@uidaho.edu
PO Box 441133                        W : http://www.uidaho.edu/~andrewr
Moscow ID 83843                      Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.

From p.dalgaard at biostat.ku.dk  Mon Jan  3 09:50:58 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Jan  3 09:52:49 2005
Subject: [Rd] Plot elements echo NULL (PR#7466)
In-Reply-To: <20050103082636.7C1DCEAB6@slim.kubism.ku.dk>
References: <20050103082636.7C1DCEAB6@slim.kubism.ku.dk>
Message-ID: <x2652e99ql.fsf@biostat.ku.dk>

ligges@statistik.uni-dortmund.de writes:

> This has been reported by Peter Dalgaard in PR#7397.
> Please check whether a bug has already been reported before submitting a 
> new report.

Even the submitter had forgotten that he submitted it as a formal
report then... Better have it in once too many than once too few, I
suppose.

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From gb at tal.stat.umu.se  Mon Jan  3 16:50:29 2005
From: gb at tal.stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon Jan  3 16:50:34 2005
Subject: [Rd] row ("FORTRAN") order?
Message-ID: <20050103155029.GA9568@tal.stat.umu.se>

Reading about 'R_max_col' in  "Writing R extensions", Version
2.1.0,(2005-01-03), I find:

"Given the nr by nc matrix matrix in row ("FORTRAN") order, ..."

Looks like a contradiction to me, since FORTRAN stores matrices
columnwise. So is this a documentation bug?


-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb@stat.umu.se

From ggrothendieck at myway.com  Mon Jan  3 17:13:28 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon Jan  3 17:13:44 2005
Subject: [Rd] Windows vignettes, shQuote, texi2dvi
References: <3A822319EB35174CA3714066D590DCD50994E47D@usrymx25.merck.com>
	<loom.20041231T034734-128@post.gmane.org>
	<loom.20041231T090826-221@post.gmane.org>
Message-ID: <loom.20050103T170918-85@post.gmane.org>

Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

: 
: Further searching also found it at:
: 
: http://www.ctan.org/tex-archive/graphics/texdraw/manual/texi2dvi
: 
: but its the UNIX shell script.  I looked at it quickly and it
: probably would not be that hard to translate it into R (about half
: of it is just argument processing) replacing
: the existing texi2dvi R command with the equivalent of that
: script.   It could be added to the wishlist.
: 
: A kludge might be to run that shell script on windows under cygwin
: although that might still not fix the problem of building vignettes 
: from the R CMD build tool.
: 
: Personally, I am just going to stick with MiKTeX's texify.exe and build
: vignettes from the .tex file manually for now.

Just an update.  I just installed the January 2, 2005 r-devel build and
I am now able to automatically generate vignettes on Windows.

From p.dalgaard at biostat.ku.dk  Mon Jan  3 21:04:23 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Jan  3 21:06:22 2005
Subject: [Rd] row ("FORTRAN") order?
In-Reply-To: <20050103155029.GA9568@tal.stat.umu.se>
References: <20050103155029.GA9568@tal.stat.umu.se>
Message-ID: <x2fz1i46uw.fsf@biostat.ku.dk>

G?ran Brostr?m <gb@tal.stat.umu.se> writes:

> Reading about 'R_max_col' in  "Writing R extensions", Version
> 2.1.0,(2005-01-03), I find:
> 
> "Given the nr by nc matrix matrix in row ("FORTRAN") order, ..."
> 
> Looks like a contradiction to me, since FORTRAN stores matrices
> columnwise. So is this a documentation bug?

Hmmmm. Maybe. FORTRAN order is known as column-*major* order. The row
index varies most quickly, so the question is whether "row order" may
have have some merit. Anyone have the terminology straight?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From vograno at evafunds.com  Mon Jan  3 22:02:13 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Mon Jan  3 22:02:29 2005
Subject: [Rd] R's IO speed
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A57D8A11@phost015.EVAFUNDS.intermedia.net>

A technical question here: how does one measure the memory overhead
mentioned below? I have a set of functions of my own and would like to
profile them.

Thanks,
Vadim 

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Prof 
> Brian Ripley
> Sent: Sunday, December 26, 2004 2:04 AM
> To: R-devel@r-project.org
> Subject: [Rd] R's IO speed
> 
> R-devel now has some improved versions of read.table and write.table.
> 
> For a million-row data frame containing one number, one 
> factor with few levels and one logical column, a 56Mb object.
> 
> generating it takes 4.5 secs.
> 
> calling summary() on it takes 2.2 secs.
> 
> writing it takes 8 secs and an additional 10Mb.
> 
> saving it in .rda format takes 4 secs.
> 
> reading it naively takes 28 secs and an additional 240Mb
> 
> reading it carefully (using nrows, colClasses and 
> comment.char) takes 16 secs and an additional 150Mb (56Mb of 
> which is for the object read in).
> (The overhead of read.table over scan was about 2 secs, 
> mainly in the conversion back to a factor.)
> 
> loading from .rda format takes 3.4 secs.
> 
> [R 2.0.1 read in 23 secs using an additional 210Mb, and wrote 
> in 50 secs using an additional 450Mb.]
> 
> 
> Will Frank Harrell or someone else please explain to me a 
> real application 
> in which this is not fast enough?
> 
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From ripley at stats.ox.ac.uk  Mon Jan  3 22:20:07 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan  3 22:20:13 2005
Subject: [Rd] R's IO speed
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A57D8A11@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A57D8A11@phost015.EVAFUNDS.intermedia.net>
Message-ID: <Pine.LNX.4.61.0501032118290.14418@gannet.stats>

Use memory.size(max=TRUE) in Windows, or some other profiling memory 
manager.

On Mon, 3 Jan 2005, Vadim Ogranovich wrote:

> A technical question here: how does one measure the memory overhead
> mentioned below? I have a set of functions of my own and would like to
> profile them.
>
> Thanks,
> Vadim
>
>> -----Original Message-----
>> From: r-devel-bounces@stat.math.ethz.ch
>> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Prof
>> Brian Ripley
>> Sent: Sunday, December 26, 2004 2:04 AM
>> To: R-devel@r-project.org
>> Subject: [Rd] R's IO speed
>>
>> R-devel now has some improved versions of read.table and write.table.
>>
>> For a million-row data frame containing one number, one
>> factor with few levels and one logical column, a 56Mb object.
>>
>> generating it takes 4.5 secs.
>>
>> calling summary() on it takes 2.2 secs.
>>
>> writing it takes 8 secs and an additional 10Mb.
>>
>> saving it in .rda format takes 4 secs.
>>
>> reading it naively takes 28 secs and an additional 240Mb
>>
>> reading it carefully (using nrows, colClasses and
>> comment.char) takes 16 secs and an additional 150Mb (56Mb of
>> which is for the object read in).
>> (The overhead of read.table over scan was about 2 secs,
>> mainly in the conversion back to a factor.)
>>
>> loading from .rda format takes 3.4 secs.
>>
>> [R 2.0.1 read in 23 secs using an additional 210Mb, and wrote
>> in 50 secs using an additional 450Mb.]
>>
>>
>> Will Frank Harrell or someone else please explain to me a
>> real application
>> in which this is not fast enough?
>>
>> --
>> Brian D. Ripley,                  ripley@stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From mase at is.titech.ac.jp  Tue Jan  4 11:26:54 2005
From: mase at is.titech.ac.jp (mase@is.titech.ac.jp)
Date: Tue Jan  4 11:26:58 2005
Subject: [Rd] Object  Memory-limits in base and its help document (PR#7468)
Message-ID: <20050104102654.2C001F339@slim.kubism.ku.dk>

Full_Name: Shigeru Mase
Version: 2.0.1
OS: Linux (Debian)
Submission from: (NULL) (222.149.162.192)


help.search("Mem") shows there is an object "Memory-limits" in the base package.
But commads "Memory-limits", or "Memory-limits()", causes an error message:
Error: Object "Memory" not found. In addition, help(Memory-limits) displays the
document for Arithmetic.

From ripley at stats.ox.ac.uk  Tue Jan  4 11:51:40 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Jan  4 11:51:51 2005
Subject: [Rd] Object Memory-limits in base and its help document (PR#7468)
In-Reply-To: <20050104102654.2C001F339@slim.kubism.ku.dk>
References: <20050104102654.2C001F339@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0501041048080.26262@gannet.stats>

On Tue, 4 Jan 2005 mase@is.titech.ac.jp wrote:

> Full_Name: Shigeru Mase
> Version: 2.0.1
> OS: Linux (Debian)
> Submission from: (NULL) (222.149.162.192)
>
>
> help.search("Mem") shows there is an object "Memory-limits" in the base 
> package.

No.  It shows there is a *help* document "Memory-limits":

   Help files with alias or concept or title matching 'Mem' using regular
   expression matching:

   Memory-limits(base)     Memory Limits in R

Try help("Memory-limits"), and see ?help.

> But commads "Memory-limits", or "Memory-limits()", causes an error 
> message: Error: Object "Memory" not found. In addition, 
> help(Memory-limits) displays the document for Arithmetic.

As is should, for that is an arithmetical operation.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Tue Jan  4 12:15:16 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Jan  4 12:17:13 2005
Subject: [Rd] Object Memory-limits in base and its help document
In-Reply-To: <Pine.LNX.4.61.0501041048080.26262@gannet.stats>
References: <20050104102654.2C001F339@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0501041048080.26262@gannet.stats>
Message-ID: <x24qhx1m4b.fsf_-_@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> On Tue, 4 Jan 2005 mase@is.titech.ac.jp wrote:
[snip]
> > help(Memory-limits) displays the document for Arithmetic.
> 
> As is should, for that is an arithmetical operation.

Oddly enough that doesn't happen for me (current 2.0.1 patched):

> help(Memory-limits)
No documentation for 'Memory - limits' in specified packages and libraries:
you could try 'help.search("Memory - limits")'

I seem to recall getting the help for "-" in cases like this in some
earlier version, but it would have been earlier than 1.8.0. 

[R-bugs removed from recipients]
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From maechler at stat.math.ethz.ch  Tue Jan  4 12:21:42 2005
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue Jan  4 12:21:46 2005
Subject: [Rd] Object Memory-limits in base and its help document (PR#7468)
Message-ID: <20050104112142.F2345EABA@slim.kubism.ku.dk>

>>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
>>>>>     on Tue, 4 Jan 2005 10:51:40 +0000 (GMT) writes:

    BDR> On Tue, 4 Jan 2005 mase@is.titech.ac.jp wrote:
    >> Full_Name: Shigeru Mase Version: 2.0.1 OS: Linux (Debian)
    >> Submission from: (NULL) (222.149.162.192)
    >> 
    >> 
    >> help.search("Mem") shows there is an object
    >> "Memory-limits" in the base package.

    BDR> No.  It shows there is a *help* document
    BDR> "Memory-limits":

    BDR>    Help files with alias or concept or title matching
    BDR> 'Mem' using regular expression matching:

    BDR>    Memory-limits(base) Memory Limits in R

    BDR> Try help("Memory-limits"), and see ?help.

    >> But commads "Memory-limits", or "Memory-limits()", causes
    >> an error message: Error: Object "Memory" not found. In
    >> addition, help(Memory-limits) displays the document for
    >> Arithmetic.

    BDR> As is should, for that is an arithmetical operation.

well, but it doesn't do that in R 2.0.1 (proper or patched) both
on Debian or Redhat [in a terminal:]

  > help(Memory-limits)
  No documentation for 'Memory - limits' in specified packages and libraries:
  you could try 'help.search("Memory - limits")'

whereas in ESS, it actually does what Shigero Mase expected,
since ESS has it's own {not entirely correct either!} magic
handling of help().

Martin Maechler

From mase at is.titech.ac.jp  Tue Jan  4 13:02:30 2005
From: mase at is.titech.ac.jp (Shigeru Mase)
Date: Tue Jan  4 13:00:52 2005
Subject: [Rd] Object Memory-limits in base and its help document
In-Reply-To: <x24qhx1m4b.fsf_-_@biostat.ku.dk>
References: <20050104102654.2C001F339@slim.kubism.ku.dk>	<Pine.LNX.4.61.0501041048080.26262@gannet.stats>
	<x24qhx1m4b.fsf_-_@biostat.ku.dk>
Message-ID: <41DA85D6.9000804@is.titech.ac.jp>

Thanks for quick replies, and very sorry for my premature report.

Peter Dalgaard wrote:
> 
> Oddly enough that doesn't happen for me (current 2.0.1 patched):
> 
> 
>>help(Memory-limits)
> 
> No documentation for 'Memory - limits' in specified packages and libraries:
> you could try 'help.search("Memory - limits")'

Sorry again. What I actually tried is '?Memory-limits' which diplays
the help document of 'Arithmetic'. Wheras,'help(Memory-limits)' causes
an error message as above. 'help("Memory-limits")' or '?"Memory-limits"'
shows the correct help as Prof. Ripley taught me.


Best regards,
Shigeru Mase

From ripley at stats.ox.ac.uk  Tue Jan  4 13:17:45 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Jan  4 13:18:27 2005
Subject: [Rd] Re: [R] ISNAN() broken? in ver 2.x on MacOS X
In-Reply-To: <B16B6AC2-5E45-11D9-97FA-000393D3D676@unsw.edu.au>
References: <A4F69DCB-5DF4-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501031842590.322794@homer06.u.washington.edu>
	<4B294EEC-5E1C-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.LNX.4.61.0501040801141.1630@gannet.stats>
	<B16B6AC2-5E45-11D9-97FA-000393D3D676@unsw.edu.au>
Message-ID: <Pine.LNX.4.61.0501041210010.30424@gannet.stats>

R has no such bug number, nor does any search I do come up with anything 
similar.

In any case, please do read the R posting guide, as this is not a suitable 
topic for R-help and I have diverted it to R-devel where it belongs.

On Tue, 4 Jan 2005, Bill Northcott wrote:

> This sort of confirms that it is a bug.
>
>> From: Andrew Pinski <pinskia@physics.uc.edu>
>> Date: 4 January 2005 7:39:38 PM
>> To: Bill Northcott <w.northcott@unsw.edu.au>
>> Cc: gcc@gcc.gnu.org
>> Subject: Re: C++ header file problem - is this a bug?
>> 
>> 
>> On Jan 4, 2005, at 2:13 AM, Bill Northcott wrote:
>> 
>>> Is this a bug or is it expected behaviour and if so why?
>> 
>> Yes this is a bug but it is already filed see PR 14608.
>> 
>> Thanks,
>> Andrew Pinski
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Tue Jan  4 13:35:31 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Jan  4 13:37:27 2005
Subject: [Rd] row ("FORTRAN") order?
In-Reply-To: <x2fz1i46uw.fsf@biostat.ku.dk>
References: <20050103155029.GA9568@tal.stat.umu.se>
	<x2fz1i46uw.fsf@biostat.ku.dk>
Message-ID: <x2zmzpz818.fsf@biostat.ku.dk>

Peter Dalgaard <p.dalgaard@biostat.ku.dk> writes:

> G?ran Brostr?m <gb@tal.stat.umu.se> writes:
> 
> > Reading about 'R_max_col' in  "Writing R extensions", Version
> > 2.1.0,(2005-01-03), I find:
> > 
> > "Given the nr by nc matrix matrix in row ("FORTRAN") order, ..."
> > 
> > Looks like a contradiction to me, since FORTRAN stores matrices
> > columnwise. So is this a documentation bug?
> 
> Hmmmm. Maybe. FORTRAN order is known as column-*major* order. The row
> index varies most quickly, so the question is whether "row order" may
> have have some merit. Anyone have the terminology straight?

Gordon Smyth didn't think "row order" made sense either, so I've
changed "row" to "column-major" for r-devel.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Tue Jan  4 13:52:04 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Jan  4 13:54:02 2005
Subject: [Rd] Re: [R] ISNAN() broken? in ver 2.x on MacOS X
In-Reply-To: <Pine.LNX.4.61.0501041210010.30424@gannet.stats>
References: <A4F69DCB-5DF4-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501031842590.322794@homer06.u.washington.edu>
	<4B294EEC-5E1C-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.LNX.4.61.0501040801141.1630@gannet.stats>
	<B16B6AC2-5E45-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.LNX.4.61.0501041210010.30424@gannet.stats>
Message-ID: <x2vfadz79n.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> R has no such bug number, nor does any search I do come up with
> anything similar.

The Cc: line suggests that it is a gcc PR#. Guess who fell into the
same trap...

        -p
 

> In any case, please do read the R posting guide, as this is not a
> suitable topic for R-help and I have diverted it to R-devel where it
> belongs.
> 
> On Tue, 4 Jan 2005, Bill Northcott wrote:
> 
> > This sort of confirms that it is a bug.
> >
> >> From: Andrew Pinski <pinskia@physics.uc.edu>
> >> Date: 4 January 2005 7:39:38 PM
> >> To: Bill Northcott <w.northcott@unsw.edu.au>
> >> Cc: gcc@gcc.gnu.org
> >> Subject: Re: C++ header file problem - is this a bug?
> >> On Jan 4, 2005, at 2:13 AM, Bill Northcott wrote:
> >>
> >>> Is this a bug or is it expected behaviour and if so why?
> >> Yes this is a bug but it is already filed see PR 14608.
> >> Thanks,
> >> Andrew Pinski
> >


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From w.northcott at unsw.edu.au  Tue Jan  4 23:04:08 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Tue Jan  4 23:04:48 2005
Subject: [Rd] Re: [R] ISNAN() broken? in ver 2.x on MacOS X
In-Reply-To: <x2vfadz79n.fsf@biostat.ku.dk>
References: <A4F69DCB-5DF4-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501031842590.322794@homer06.u.washington.edu>
	<4B294EEC-5E1C-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.LNX.4.61.0501040801141.1630@gannet.stats>
	<B16B6AC2-5E45-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.LNX.4.61.0501041210010.30424@gannet.stats>
	<x2vfadz79n.fsf@biostat.ku.dk>
Message-ID: <8E8CBC38-5E9C-11D9-97FA-000393D3D676@unsw.edu.au>

On 04/01/2005, at 11:52 PM, Peter Dalgaard wrote:
> Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:
>
>> R has no such bug number, nor does any search I do come up with
>> anything similar.
>
> The Cc: line suggests that it is a gcc PR#. Guess who fell into the
> same trap...
>
That is indeed a gcc bugzilla problem report number.  It seems the gcc 
maintainers are agreed that it is too hard to fix at this time.  The 
workarounds suggested in the PR 14608 don't work on MacOS X, and 
probably don't work on other platforms because the undefs of the math.h 
macros in cmath are not conditional.

So what might be the 'take away' for R?  Possibilities:

1.  Amend the documentation:  add a note to 'Missing and IEEE special 
values' in 'Writing R extensions' to the effect that the macros should 
not be used with C++.  Currently they will break on several platforms.

2. The work-around that strikes me is to use R_IsNaN instead, which was 
the approach used in R v1.9 for non-IEEE platforms and when used 
standalone.  Unfortunately this API was changed between v1.9 and v2.0.  
That is no problem when building against an installed R as there is a 
macro for the Version.  However, if building standalone, I can see no 
way to get the version short of an autoconf macro to test for the 
symbols in the library.

3. Perhaps the macro substitution of R_IsNaN for ISNAN etc. could be 
reintroduced into v2.0.x conditional on C++.  That might need a new 
ISNA() macro.

Bill Northcott

From ripley at stats.ox.ac.uk  Tue Jan  4 23:15:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Jan  4 23:16:00 2005
Subject: [Rd] Re: [R] ISNAN() broken? in ver 2.x on MacOS X
In-Reply-To: <8E8CBC38-5E9C-11D9-97FA-000393D3D676@unsw.edu.au>
References: <A4F69DCB-5DF4-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501031842590.322794@homer06.u.washington.edu>
	<4B294EEC-5E1C-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.LNX.4.61.0501040801141.1630@gannet.stats>
	<B16B6AC2-5E45-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.LNX.4.61.0501041210010.30424@gannet.stats>
	<x2vfadz79n.fsf@biostat.ku.dk>
	<8E8CBC38-5E9C-11D9-97FA-000393D3D676@unsw.edu.au>
Message-ID: <Pine.LNX.4.61.0501042205560.6578@gannet.stats>

On Wed, 5 Jan 2005, Bill Northcott wrote:

> On 04/01/2005, at 11:52 PM, Peter Dalgaard wrote:
>> Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:
>> 
>>> R has no such bug number, nor does any search I do come up with
>>> anything similar.
>> 
>> The Cc: line suggests that it is a gcc PR#. Guess who fell into the
>> same trap...
>> 
> That is indeed a gcc bugzilla problem report number.

How about apologizing for such a badly written message?

> It seems the gcc maintainers are agreed that it is too hard to fix at 
> this time.  The workarounds suggested in the PR 14608 don't work on 
> MacOS X, and probably don't work on other platforms because the undefs 
> of the math.h macros in cmath are not conditional.
>
> So what might be the 'take away' for R?  Possibilities:
>
> 1.  Amend the documentation:  add a note to 'Missing and IEEE special values' 
> in 'Writing R extensions' to the effect that the macros should not be used 
> with C++.  Currently they will break on several platforms.

Why?  This is a g++ problem, not a C++ problem, and at least one C++ 
compiler works.  Have you tried Thomas's suggestion to use isnan?

> 2. The work-around that strikes me is to use R_IsNaN instead, which was the 
> approach used in R v1.9 for non-IEEE platforms and when used standalone. 
> Unfortunately this API was changed between v1.9 and v2.0.  That is no problem

No change was made to the API in 2.0.x.  The API specified ISNAN then and 
now.  Please do us the courtesy of checking your facts.

> when building against an installed R as there is a macro for the Version. 
> However, if building standalone, I can see no way to get the version short of 
> an autoconf macro to test for the symbols in the library.
>
> 3. Perhaps the macro substitution of R_IsNaN for ISNAN etc. could be 
> reintroduced into v2.0.x conditional on C++.  That might need a new ISNA() 
> macro.

You cannot `reintroduce' something you never had.  We had in 1.9.x

#ifdef IEEE_754
# define ISNAN(x) (isnan(x)!=0)
#else
# define ISNAN(x)      R_IsNaNorNA(x)
#endif

Please do your homework!

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Gregor.Gorjanc at bfro.uni-lj.si  Wed Jan  5 01:42:45 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Wed Jan  5 01:42:48 2005
Subject: [Rd] Option for "Delete downloaded files (y/N)?" in
	install.packages()
Message-ID: <7FFEE688B57D7346BC6241C55900E7300FD057@pollux.bfro.uni-lj.si>

Hello!

I have a wish/proposal.

Is it possible to include some option in install.packages() for
Delete downloaded files (y/N)? at the end of that process. It can
be quite anoying if you must install several packages and wait 
meanwhile to type y/n for each package separately.

--
Lep pozdrav / With regards,
    Gregor GORJANC

---------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

From tlumley at u.washington.edu  Wed Jan  5 01:47:03 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Jan  5 01:47:16 2005
Subject: [Rd] Option for "Delete downloaded files (y/N)?" in
	install.packages()
In-Reply-To: <7FFEE688B57D7346BC6241C55900E7300FD057@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E7300FD057@pollux.bfro.uni-lj.si>
Message-ID: <Pine.A41.4.61b.0501041645590.182274@homer03.u.washington.edu>

On Wed, 5 Jan 2005, Gorjanc Gregor wrote:

> Hello!
>
> I have a wish/proposal.
>
> Is it possible to include some option in install.packages() for
> Delete downloaded files (y/N)? at the end of that process. It can
> be quite anoying if you must install several packages and wait
> meanwhile to type y/n for each package separately.
>

It's been done already for the next version. The NEWS file has

     install.packages() no longer asks if downloaded packages
     should be deleted: they will be deleted at the end of the
     session anyway (and can be deleted by the user at any time).



 	-thomas

From w.northcott at unsw.edu.au  Wed Jan  5 06:12:59 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Wed Jan  5 06:13:33 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
Message-ID: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>

In the hope of some meaningful response and ignoring the risk of 
further abuse, let me try to clarify the issue here.

I have re-read the 'Writing R Extensions' manual.  It seems to me that 
it clearly says R API functions can be called from from C++ programs, 
and the API  includes the special values ISNAN() and R_FINITE() and the 
missing test ISNA().

R_FINITE is no problem.  It is defined as R_finite, which is declared 
in Rmath.h and included in libRmath.

ISNAN() however is broken.
In R 1.9 it was defined as R_IsNaNorNA unless IEEE_754 was defined 
which was not done in the standalone libRmath/Rmath.h.  R_IsNaNorNA was 
declared in Rmath and included in libRmath.  So it would work, although 
probably not when built against an installed R library because R.h 
would likely define IEEE_754.

In R2.0 ISNAN() is defined using isnan thus (isnan(x)!=0).  isnan() is 
in math.h and this works perfectly for C code.  However, in C++ the 
header cmath (included by iostream and others) undefs isnan().  So on 
platforms for which isnan() is a macro, the code breaks at compile time 
with 'isnan() undeclared'.

If building against a full R library, one might possible use R_IsNaN 
instead but this function is not included in libRmath v2.0 and the 
function R_IsNaNorNA which was used in libRmath v1.9 no longer exists

While I am on this topic, there seems to be nothing at all in the 
standalone libRmath to deal with ISNA() and although R_PosInf and 
R_NegInf are in the library, they don't seem to me to be declared.

Bill Northcott

From xt_wang at cse.concordia.ca  Wed Jan  5 06:21:47 2005
From: xt_wang at cse.concordia.ca (xt_wang@cse.concordia.ca)
Date: Wed Jan  5 06:21:52 2005
Subject: [Rd] How to connect R with a C code which includes Atlas
Message-ID: <1104902507.41db796b74505@mail.encs.concordia.ca>

Hello, everybody, 

Happy New Year!

I am a graduate student from Concordia University. I meet a problem when I am
working on my thesis. I hope I will get help from you.

I have a mathematical model which was already implemented by using R language.
However, part of this model includes fixed point iteration algorithm and
calculation of large linear equations which n will get to 5000. Because of
limitation of memory, R is not enough to support this kind of calculation. Now,
I use C language with Matlab C library to implement this part of model and solve
this problem. But the problem is that I can not connect my C program with R code
since C program include Matlab.h. 

The function I used from matlab is Cholesky algorithm which is applied to
calculate inv(C)*b where C is a symmetric positive definite matrix. Since R is
not easy to connect with C which include Maltab C library, and I find Atlas is
optimized linear algebra library and possible to be used by R, do you think it
is possible for me to replace matlab by using Atlas function in my C code, and
finally the C code can be connected with R dynamically?  That means I can run a
R program -> which include C code-> which include Atlas automatically. If it is
possible, could you please tell me how can I realize the dynamic link? 

Thanks for your help in advance!

Yours,

Maggie Wang

From ripley at stats.ox.ac.uk  Wed Jan  5 07:30:37 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jan  5 07:30:46 2005
Subject: [Rd] Option for "Delete downloaded files (y/N)?" in
	install.packages()
In-Reply-To: <7FFEE688B57D7346BC6241C55900E7300FD057@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E7300FD057@pollux.bfro.uni-lj.si>
Message-ID: <Pine.LNX.4.61.0501050626320.2502@gannet.stats>

On Wed, 5 Jan 2005, Gorjanc Gregor wrote:

> Hello!
>
> I have a wish/proposal.
>
> Is it possible to include some option in install.packages() for
> Delete downloaded files (y/N)? at the end of that process. It can
> be quite anoying if you must install several packages and wait
> meanwhile to type y/n for each package separately.

It does happen at the end of the process: you are using one call for the 
several packages?  Something like install.packages(c("pkg1, "pkg2", 
"pkg3"))?

In R-devel you are not asked at all, and even now you will not be 
asked if you specify destdir.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Jan  5 07:37:42 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jan  5 07:37:49 2005
Subject: [Rd] How to connect R with a C code which includes Atlas
In-Reply-To: <1104902507.41db796b74505@mail.encs.concordia.ca>
References: <1104902507.41db796b74505@mail.encs.concordia.ca>
Message-ID: <Pine.LNX.4.61.0501050631510.2502@gannet.stats>

On Wed, 5 Jan 2005 xt_wang@cse.concordia.ca wrote:

> Hello, everybody,
>
> Happy New Year!
>
> I am a graduate student from Concordia University. I meet a problem when 
> I am working on my thesis. I hope I will get help from you.
>
> I have a mathematical model which was already implemented by using R 
> language. However, part of this model includes fixed point iteration 
> algorithm and calculation of large linear equations which n will get to 
> 5000. Because of limitation of memory, R is not enough to support this 
> kind of calculation. Now, I use C language with Matlab C library to 
> implement this part of model and solve this problem. But the problem is 
> that I can not connect my C program with R code since C program include 
> Matlab.h.
>
> The function I used from matlab is Cholesky algorithm which is applied 
> to calculate inv(C)*b where C is a symmetric positive definite matrix. 
> Since R is not easy to connect with C which include Maltab C library, 
> and I find Atlas is optimized linear algebra library and possible to be 
> used by R, do you think it is possible for me to replace matlab by using 
> Atlas function in my C code, and finally the C code can be connected 
> with R dynamically?  That means I can run a R program -> which include C 
> code-> which include Atlas automatically. If it is possible, could you 
> please tell me how can I realize the dynamic link?

Certainly.  Just put your C code into a package and include $(BLAS_LIBS) 
when you build the package: see `Writing R Extensions'.

Note that ATLAS is an optimized BLAS, the B standing for Basic.  For a 
Choleski decomposition you could use LAPACK as the R sources do and that 
will in turn use ATLAS if you built R against ATLAS.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From gregor.gorjanc at bfro.uni-lj.si  Wed Jan  5 14:19:06 2005
From: gregor.gorjanc at bfro.uni-lj.si (Gregor GORJANC)
Date: Wed Jan  5 08:19:18 2005
Subject: [Rd] Option for "Delete downloaded files (y/N)?" in
	install.packages()
In-Reply-To: <Pine.LNX.4.61.0501050626320.2502@gannet.stats>
References: <7FFEE688B57D7346BC6241C55900E7300FD057@pollux.bfro.uni-lj.si>
	<Pine.LNX.4.61.0501050626320.2502@gannet.stats>
Message-ID: <41DBE94A.1010300@bfro.uni-lj.si>

Hello!

Thanks to Thomas and Brian for answers!

Prof Brian Ripley wrote:
...
>> Is it possible to include some option in install.packages() for
>> Delete downloaded files (y/N)? at the end of that process. It can
>> be quite anoying if you must install several packages and wait
>> meanwhile to type y/n for each package separately.
> 
> It does happen at the end of the process: you are using one call for the 
> several packages?  Something like install.packages(c("pkg1, "pkg2", 
> "pkg3"))?
Yes, it does happen at the end of the process, but I wrote a simple script, 
which installs all favourite packages and it does one by one. I could
modify it to use the whole list at once also, but there is apparently no 
need since my wish/proposal is already solved in R-devel.

> 
> In R-devel you are not asked at all, and even now you will not be asked 
> if you specify destdir.
Yes, I know for the last one, but then you must delete them by "hand"!

-- 
Lep pozdrav / With regards,
     Gregor GORJANC

---------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
Zootechnical Department    mail: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

From ripley at stats.ox.ac.uk  Wed Jan  5 08:55:53 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jan  5 08:56:01 2005
Subject: [Rd] Option for "Delete downloaded files (y/N)?" in
	install.packages()
In-Reply-To: <41DBE94A.1010300@bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E7300FD057@pollux.bfro.uni-lj.si>
	<Pine.LNX.4.61.0501050626320.2502@gannet.stats>
	<41DBE94A.1010300@bfro.uni-lj.si>
Message-ID: <Pine.LNX.4.61.0501050752290.6155@gannet.stats>

On Wed, 5 Jan 2005, Gregor GORJANC wrote:

> Hello!
>
> Thanks to Thomas and Brian for answers!
>
> Prof Brian Ripley wrote:
> ...
>>> Is it possible to include some option in install.packages() for
>>> Delete downloaded files (y/N)? at the end of that process. It can
>>> be quite anoying if you must install several packages and wait
>>> meanwhile to type y/n for each package separately.
>> 
>> It does happen at the end of the process: you are using one call for the 
>> several packages?  Something like install.packages(c("pkg1, "pkg2", 
>> "pkg3"))?

> Yes, it does happen at the end of the process, but I wrote a simple script, 
> which installs all favourite packages and it does one by one. I could
> modify it to use the whole list at once also, but there is apparently no need 
> since my wish/proposal is already solved in R-devel.

It will still be much more efficient to do them in one call.
For one thing, it chooses a suitable order to install the packages, and 
for another it downloads PACKAGES each time.

>> In R-devel you are not asked at all, and even now you will not be asked if 
>> you specify destdir.

> Yes, I know for the last one, but then you must delete them by "hand"!

Why can't your script do it?  Or you could use the session directory as 
R-devel now does.  Either way you don't need hands!

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From cs_matyi at freemail.hu  Wed Jan  5 13:56:19 2005
From: cs_matyi at freemail.hu (cs_matyi@freemail.hu)
Date: Wed Jan  5 13:56:25 2005
Subject: [Rd] omegahat link on R site (PR#7471)
Message-ID: <20050105125619.A7FDE10441@slim.kubism.ku.dk>



Hello, 

On the R web site on the page about R Data Import/Export, the link to 
omegahat.org in the Introduction is misspelled.

Matthew Cserhati

From p.dalgaard at biostat.ku.dk  Wed Jan  5 15:26:51 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed Jan  5 15:28:52 2005
Subject: [Rd] omegahat link on R site (PR#7471)
In-Reply-To: <20050105125619.A7FDE10441@slim.kubism.ku.dk>
References: <20050105125619.A7FDE10441@slim.kubism.ku.dk>
Message-ID: <x24qhwost0.fsf@biostat.ku.dk>

cs_matyi@freemail.hu writes:

> Hello, 
> 
> On the R web site on the page about R Data Import/Export, the link to 
> omegahat.org in the Introduction is misspelled.

In principle, please do not report website issues here since the
website is not part of R (CRAN has a webmaster).

However, the origin of this particular issue is inside the
Import/Export manual, the source of which *is* part of R, so thank you
after all.

        -pd

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Wed Jan  5 16:22:47 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan  5 16:22:50 2005
Subject: [Rd] omegahat link on R site (PR#7471)
Message-ID: <20050105152247.2598EF33A@slim.kubism.ku.dk>

On Wed, 5 Jan 2005, Peter Dalgaard wrote:

> cs_matyi@freemail.hu writes:
>
>> Hello,
>>
>> On the R web site on the page about R Data Import/Export, the link to
>> omegahat.org in the Introduction is misspelled.
>
> In principle, please do not report website issues here since the
> website is not part of R (CRAN has a webmaster).
>
> However, the origin of this particular issue is inside the
> Import/Export manual, the source of which *is* part of R, so thank you
> after all.

It was corrected in the R sources on 2004-12-01, though, so it not a 
current R bug.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Jan  5 16:22:35 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jan  5 16:22:51 2005
Subject: [Rd] omegahat link on R site (PR#7471)
In-Reply-To: <x24qhwost0.fsf@biostat.ku.dk>
References: <20050105125619.A7FDE10441@slim.kubism.ku.dk>
	<x24qhwost0.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.61.0501051520020.17071@gannet.stats>

On Wed, 5 Jan 2005, Peter Dalgaard wrote:

> cs_matyi@freemail.hu writes:
>
>> Hello,
>>
>> On the R web site on the page about R Data Import/Export, the link to
>> omegahat.org in the Introduction is misspelled.
>
> In principle, please do not report website issues here since the
> website is not part of R (CRAN has a webmaster).
>
> However, the origin of this particular issue is inside the
> Import/Export manual, the source of which *is* part of R, so thank you
> after all.

It was corrected in the R sources on 2004-12-01, though, so it not a 
current R bug.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From andikumagenge at businessdecision.com  Wed Jan  5 16:32:05 2005
From: andikumagenge at businessdecision.com (NDIKUMAGENGE Alice)
Date: Wed Jan  5 16:25:30 2005
Subject: [Rd] R
Message-ID: <6CC4DC1EC1F92D4B8A5FF590362E75650217D007@neptune.betd.fr>

Hello and Happy New year to Everybody,
 
I am a new user of R and I am a little bit "lost".
I would like to know how tu use R for detrending, which kind of algorithms
I have to use.
 
Thank u very much and Sorry for my "english"
I am Francophone.
 
Alice

	[[alternative HTML version deleted]]

From gregory.r.warnes at pfizer.com  Wed Jan  5 16:43:10 2005
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Wed Jan  5 16:45:06 2005
Subject: [Rd] Broken Link for gregmisc_2.0.0.zip
Message-ID: <915D2D65A9986440A277AC5C98AA466F9787DA@groamrexm02.amer.pfizer.com>


The link from
http://cran.r-project.org/src/contrib/Descriptions/gregmisc.html to the
windows package  gregmisc_2.0.0.zip is broken.  

Also, could the appropriate email address for reporting web site problems
please be added to the website in some conspicous place?

Gregory R. Warnes
Associate Director, Non-Clinical Statistics
Pfizer Global Research and Development



LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

From tlumley at u.washington.edu  Wed Jan  5 17:09:33 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Jan  5 17:09:43 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
Message-ID: <Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>

On Wed, 5 Jan 2005, Bill Northcott wrote:

>
> If building against a full R library, one might possible use R_IsNaN instead 
> but this function is not included in libRmath v2.0 and the function 
> R_IsNaNorNA which was used in libRmath v1.9 no longer exists
>

Yes, but in your standalone C or C++ code you can just use isnan() from 
math.h directly.

The reason that R doesn't do that is twofold.  In the past we tried to 
support computers that didn't use IEEE 754 arithmetic, which meant that 
isnan might not exist.  Also, IIRC we found that isnan() doesn't use 1 for 
TRUE on all platforms -- sometimes it uses -1 or something else -- and 
code had assumed 1.  That's why the strange-looking isnan(x)!=0 is there.

You shouldn't have either of these problems in your C++ code, so it would 
be much easier to just use isnan(x) directly.  The only complication 
would be distinguishing NA from other NaNs, but you won't have to do that 
in standalone C++ code.

It would be worth noting somewhere that ISNAN breaks when some C++ headers 
are included on Mac OS X, and I will do that.


 	-thomas

From p.dalgaard at biostat.ku.dk  Wed Jan  5 18:23:31 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed Jan  5 18:25:40 2005
Subject: [Rd] Broken Link for gregmisc_2.0.0.zip
In-Reply-To: <915D2D65A9986440A277AC5C98AA466F9787DA@groamrexm02.amer.pfizer.com>
References: <915D2D65A9986440A277AC5C98AA466F9787DA@groamrexm02.amer.pfizer.com>
Message-ID: <x2llb74woc.fsf@biostat.ku.dk>

"Warnes, Gregory R" <gregory.r.warnes@pfizer.com> writes:

> The link from
> http://cran.r-project.org/src/contrib/Descriptions/gregmisc.html to the
> windows package  gregmisc_2.0.0.zip is broken.  

Looks like a generic errors in mirroring the windows packages. Has
happened before.
 
> Also, could the appropriate email address for reporting web site problems
> please be added to the website in some conspicous place?

Good idea.

[Cc trimmed]
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From gregory.r.warnes at pfizer.com  Wed Jan  5 19:41:29 2005
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Wed Jan  5 19:41:52 2005
Subject: [Rd] install.packages and bundles
Message-ID: <915D2D65A9986440A277AC5C98AA466F9787E3@groamrexm02.amer.pfizer.com>


Hi All,

Since I changed the gregmisc package into a bundle, I almost daily questions
asking how to get the individual packages contained in the bundle.  

The standard example arises when someone attempts to install and then use my
'genetics' package which depends on the 'gdata' package contained within the
'gregmisc' bundle.  The install succedes, but when the user does
library(genetics) they get the error message:

	> library(genetics)
	Loading required package: gdata 
	Error: package 'gdata' could not be loaded

The user then attempts to install the package 'gdata' not realizing that it
is part of the (e.g.) gregmisc bundle, and can't find it.  For example

	> install.packages("gdata")
	trying URL
`http://cran.r-project.org/bin/windows/contrib/2.0/PACKAGES'
	Content type `text/plain; charset=iso-8859-1' length 24149 bytes
	opened URL
	downloaded 23Kb

	Warning message: 
	No package "gdata" on CRAN. in: download.packages(pkgs, destdir =
tmpd, 
	available = available,  

Now the user is in trouble and sends me an error message asking how to get
the 'gdata' package.

A couple of minor changes to the package installation/listing tools would
help alleviate this and some related problems.

1) Modify install.packages() so that the by default "dependencies=TRUE",
since this knows how to find dependencies within bundles.  
	(Why is this FALSE by default anyway?  In normal circumstances, is
there any
             reason to install a package without installing its
dependencies?)

2) Modify install.packages() to check if a requested package is contained in
a bundle, and install the bundle if so.

3) Modify CRAN.packages() to list packages contained within bundles as well
as independent packages, so that the windows "install packages from CRAN"
menu item will properly show bundled packages.


Comments?

Gregory R. Warnes
Associate Director, Non-Clinical Statistics
Pfizer Global Research and Development



LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

From w.northcott at unsw.edu.au  Wed Jan  5 20:26:54 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Wed Jan  5 20:27:21 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
Message-ID: <C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>

On 06/01/2005, at 3:09 AM, Thomas Lumley wrote:
>>
>> If building against a full R library, one might possible use R_IsNaN 
>> instead but this function is not included in libRmath v2.0 and the 
>> function R_IsNaNorNA which was used in libRmath v1.9 no longer exists
>>
>
> Yes, but in your standalone C or C++ code you can just use isnan() 
> from math.h directly.

As I explained in the last message:
>> In R2.0 ISNAN() is defined using isnan thus (isnan(x)!=0).  isnan() 
>> is in math.h and this works perfectly for C code.  However, in C++ 
>> the header cmath (included by iostream and others) undefs isnan().  
>> So on platforms for which isnan() is a macro, the code breaks at 
>> compile time with 'isnan() undeclared'.
>
> The reason that R doesn't do that is twofold.  In the past we tried to 
> support computers that didn't use IEEE 754 arithmetic, which meant 
> that isnan might not exist.  Also, IIRC we found that isnan() doesn't 
> use 1 for TRUE on all platforms -- sometimes it uses -1 or something 
> else -- and code had assumed 1.  That's why the strange-looking 
> isnan(x)!=0 is there.

There is nothing strange about this.  The spec for isnan says it is 
zero if and only if the object is not a nan.  Any other value indicates 
a nan.
>
> It would be worth noting somewhere that ISNAN breaks when some C++ 
> headers are included on Mac OS X, and I will do that.

The point I am trying to make is that it is not just MacOS X.   The g++ 
cmath header undefs isnan so it will break with gcc on any platform 
which has a macro for isnan.  HP-UX is one.
Also the C++ gurus insist that the ISO C++ standard requires cmath to 
zap the macros, which implies it will happen with other ISO compliant 
C++ compilers.

There is a function R_IsNaN.  I have not checked, but I presume it just 
calls isnan.  This should work because it will not be zapped by the C++ 
headers, because it is in a different (C?) compilation unit.  However, 
it is currently not part of the standalone Rmath.h/libRmath.  It would 
be good if it could be included in the standalone build as was its 
predecessor R_IsNaNorNA.

That way, we would have a workaround by using R_IsNaN.

Bill Northcott

From tlumley at u.washington.edu  Wed Jan  5 20:53:29 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Jan  5 20:53:38 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
	<C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>
Message-ID: <Pine.A41.4.61b.0501051149490.59084@homer03.u.washington.edu>

On Thu, 6 Jan 2005, Bill Northcott wrote:

> As I explained in the last message:
>>> In R2.0 ISNAN() is defined using isnan thus (isnan(x)!=0).  isnan() is in 
>>> math.h and this works perfectly for C code.  However, in C++ the header 
>>> cmath (included by iostream and others) undefs isnan().  So on platforms 
>>> for which isnan() is a macro, the code breaks at compile time with 
>>> 'isnan() undeclared'.

I believe (with a little Googling) the suggested C++ approach is to use 
std::isnan if <cmath> is included.


 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley@u.washington.edu	University of Washington, Seattle

From w.northcott at unsw.edu.au  Wed Jan  5 22:29:18 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Wed Jan  5 22:29:37 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <Pine.A41.4.61b.0501051149490.59084@homer03.u.washington.edu>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
	<C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051149490.59084@homer03.u.washington.edu>
Message-ID: <DB4A6959-5F60-11D9-97FA-000393D3D676@unsw.edu.au>

On 06/01/2005, at 6:53 AM, Thomas Lumley wrote:
>
> I believe (with a little Googling) the suggested C++ approach is to 
> use std::isnan if <cmath> is included.
>
I tried that too, but without any success.  I even tried 
__gnu_cxx::isnan.

It was suggested by one of the gcc people, but I could find no 
documentation about it.  The ISO C++ docs do not include isnan as a 
symbol provided by cmath within the std namespace.  I looked at the gcc 
source code and could see no reason why it should work.

Bill Northcott

From tlumley at u.washington.edu  Wed Jan  5 23:12:30 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Jan  5 23:12:40 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <DB4A6959-5F60-11D9-97FA-000393D3D676@unsw.edu.au>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
	<C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051149490.59084@homer03.u.washington.edu>
	<DB4A6959-5F60-11D9-97FA-000393D3D676@unsw.edu.au>
Message-ID: <Pine.A41.4.61b.0501051405010.59084@homer03.u.washington.edu>

On Thu, 6 Jan 2005, Bill Northcott wrote:

> On 06/01/2005, at 6:53 AM, Thomas Lumley wrote:
>> 
>> I believe (with a little Googling) the suggested C++ approach is to use 
>> std::isnan if <cmath> is included.
>> 
> I tried that too, but without any success.  I even tried __gnu_cxx::isnan.
>
> It was suggested by one of the gcc people, but I could find no documentation 
> about it.  The ISO C++ docs do not include isnan as a symbol provided by 
> cmath within the std namespace.  I looked at the gcc source code and could 
> see no reason why it should work.

Hmm.  What *are* C++ programmers supposed to use to test for NaN, then? 
It might well not be anything in the ISO standard, just as it isn't in 
C89, but surely there is some prescribed way to do it.

We don't want ISNAN to be a function unnecessarily in C, since it is used a 
lot and there is reportedly quite a bit of overhead to very simple 
functions on some processors.

 	-thomas

From xt_wang at cse.concordia.ca  Wed Jan  5 23:59:50 2005
From: xt_wang at cse.concordia.ca (xt_wang@cse.concordia.ca)
Date: Wed Jan  5 23:59:55 2005
Subject: [Rd] How to connect R with a C code which includes Atlas
Message-ID: <1104965990.41dc71662aeca@mail.encs.concordia.ca>


If it is possible to link a C code with Atlas into R. Is it possible to link a C
code with Matlab into R?


On Wed, 5 Jan 2005 xt_wang@cse.concordia.ca wrote:

> Hello, everybody,
>
> Happy New Year!
>
> I am a graduate student from Concordia University. I meet a problem when
> I am working on my thesis. I hope I will get help from you.
>
> I have a mathematical model which was already implemented by using R
> language. However, part of this model includes fixed point iteration
> algorithm and calculation of large linear equations which n will get to
> 5000. Because of limitation of memory, R is not enough to support this
> kind of calculation. Now, I use C language with Matlab C library to
> implement this part of model and solve this problem. But the problem is
> that I can not connect my C program with R code since C program include
> Matlab.h.
>
> The function I used from matlab is Cholesky algorithm which is applied
> to calculate inv(C)*b where C is a symmetric positive definite matrix.
> Since R is not easy to connect with C which include Maltab C library,
> and I find Atlas is optimized linear algebra library and possible to be
> used by R, do you think it is possible for me to replace matlab by using
> Atlas function in my C code, and finally the C code can be connected
> with R dynamically?  That means I can run a R program -> which include C
> code-> which include Atlas automatically. If it is possible, could you
> please tell me how can I realize the dynamic link?

Certainly.  Just put your C code into a package and include $(BLAS_LIBS)
when you build the package: see `Writing R Extensions'.

Note that ATLAS is an optimized BLAS, the B standing for Basic.  For a
Choleski decomposition you could use LAPACK as the R sources do and that
will in turn use ATLAS if you built R against ATLAS.

From w.northcott at unsw.edu.au  Thu Jan  6 00:14:12 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Thu Jan  6 00:14:33 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <Pine.A41.4.61b.0501051405010.59084@homer03.u.washington.edu>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
	<C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051149490.59084@homer03.u.washington.edu>
	<DB4A6959-5F60-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051405010.59084@homer03.u.washington.edu>
Message-ID: <82D986EA-5F6F-11D9-97FA-000393D3D676@unsw.edu.au>

On 06/01/2005, at 9:12 AM, Thomas Lumley wrote:
>> It was suggested by one of the gcc people, but I could find no 
>> documentation about it.  The ISO C++ docs do not include isnan as a 
>> symbol provided by cmath within the std namespace.  I looked at the 
>> gcc source code and could see no reason why it should work.
>
> Hmm.  What *are* C++ programmers supposed to use to test for NaN, 
> then? It might well not be anything in the ISO standard, just as it 
> isn't in C89, but surely there is some prescribed way to do it.

I asked the same question.  So far I got no response.  It seems the 
gods of C++ dictate that a C++ header must not pollute the default name 
space.  cmath includes math.h so it must undefine everything in math.h 
which is not converted into the std namespace.

I spent some time Googling on this and discovered a number of C++ maths 
packages that provided their own isnan type functions in the spirit of 
R_IsNaN.  The fact that these functions were deemed useful by the 
package writers rather indicates to me that there is no way of doing it 
in a default ISO C++!

isnan on MacOS X, and presumably other systems, is a macro so that it 
can work with floats, doubles and long doubles unlike R_IsNan which I 
understand will only work with doubles.  There are actualy three 
underlying isnan functions in libSystem: __isnanf(float), 
__isnand(double) and __isnan(long double).

>
> We don't want ISNAN to be a function unnecessarily in C, since it is 
> used a lot and there is reportedly quite a bit of overhead to very 
> simple functions on some processors.

I quite understand that and of course ISNAN works just great from C 
code.  However, I do think it would be useful to provide a warning in 
the documentation about using ISNAN in C++ and include R_IsNaN in the 
standalone package as a workaround.

The current state is that our code (JAGS), which used to work with 
R1.9,  won't build against a standalone library on MacOS X and 
presumably other platforms with similar header structures.

Bill Northcott

PS All this just reinforces my long held belief that C++ is thoroughly 
undesirable, and if I want an OO extension of C, I will stick with 
Objective-C which just extends C in a minimalist way without stuffing 
it up.

From jwe at bevo.che.wisc.edu  Thu Jan  6 05:31:25 2005
From: jwe at bevo.che.wisc.edu (John W. Eaton)
Date: Thu Jan  6 05:32:29 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <82D986EA-5F6F-11D9-97FA-000393D3D676@unsw.edu.au>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
	<C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051149490.59084@homer03.u.washington.edu>
	<DB4A6959-5F60-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051405010.59084@homer03.u.washington.edu>
	<82D986EA-5F6F-11D9-97FA-000393D3D676@unsw.edu.au>
Message-ID: <16860.48925.390153.388499@devzero.bogus.domain>

On  6-Jan-2005, Bill Northcott <w.northcott@unsw.edu.au> wrote:

| On 06/01/2005, at 9:12 AM, Thomas Lumley wrote:
| >> It was suggested by one of the gcc people, but I could find no 
| >> documentation about it.  The ISO C++ docs do not include isnan as a 
| >> symbol provided by cmath within the std namespace.  I looked at the 
| >> gcc source code and could see no reason why it should work.
| >
| > Hmm.  What *are* C++ programmers supposed to use to test for NaN, 
| > then? It might well not be anything in the ISO standard, just as it 
| > isn't in C89, but surely there is some prescribed way to do it.
| 
| I asked the same question.  So far I got no response.

What I finally decided to do for Octave was to use a C language
autoconf test for isnan, then provide a function declared "extern C"
that is a wrapper around the C isnan function (if it exists).  I also
use this method for other functions that may be easier to call from C
than directly from C++.

jwe

-- 
www.octave.org | www.che.wisc.edu/~jwe | Peace would shock and awe me.

From ligges at statistik.uni-dortmund.de  Thu Jan  6 08:50:44 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Jan  6 08:50:09 2005
Subject: [Rd] Broken Link for gregmisc_2.0.0.zip
In-Reply-To: <x2llb74woc.fsf@biostat.ku.dk>
References: <915D2D65A9986440A277AC5C98AA466F9787DA@groamrexm02.amer.pfizer.com>
	<x2llb74woc.fsf@biostat.ku.dk>
Message-ID: <41DCEDD4.9080705@statistik.uni-dortmund.de>

Peter Dalgaard wrote:

> "Warnes, Gregory R" <gregory.r.warnes@pfizer.com> writes:
> 
> 
>>The link from
>>http://cran.r-project.org/src/contrib/Descriptions/gregmisc.html to the
>>windows package  gregmisc_2.0.0.zip is broken.  
> 
> 
> Looks like a generic errors in mirroring the windows packages. Has
> happened before.

Not quite, Windows packages are mirrored correctly, but all (?) links to 
Windows *and* Mac OS X binary packages in the packages' Descriptions on 
CRAN are broken.

Uwe

> 
>>Also, could the appropriate email address for reporting web site problems
>>please be added to the website in some conspicous place?
> 
> 
> Good idea.
> 
> [Cc trimmed]

From ligges at statistik.uni-dortmund.de  Thu Jan  6 10:16:22 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Jan  6 10:15:46 2005
Subject: [Rd] install.packages and bundles
In-Reply-To: <915D2D65A9986440A277AC5C98AA466F9787E3@groamrexm02.amer.pfizer.com>
References: <915D2D65A9986440A277AC5C98AA466F9787E3@groamrexm02.amer.pfizer.com>
Message-ID: <41DD01E6.5070709@statistik.uni-dortmund.de>

Warnes, Gregory R wrote:

> Hi All,
> 
> Since I changed the gregmisc package into a bundle, I almost daily questions
> asking how to get the individual packages contained in the bundle.  
> 
> The standard example arises when someone attempts to install and then use my
> 'genetics' package which depends on the 'gdata' package contained within the
> 'gregmisc' bundle.  The install succedes, but when the user does
> library(genetics) they get the error message:
> 
> 	> library(genetics)
> 	Loading required package: gdata 
> 	Error: package 'gdata' could not be loaded
> 
> The user then attempts to install the package 'gdata' not realizing that it
> is part of the (e.g.) gregmisc bundle, and can't find it.  For example
> 
> 	> install.packages("gdata")
> 	trying URL
> `http://cran.r-project.org/bin/windows/contrib/2.0/PACKAGES'
> 	Content type `text/plain; charset=iso-8859-1' length 24149 bytes
> 	opened URL
> 	downloaded 23Kb
> 
> 	Warning message: 
> 	No package "gdata" on CRAN. in: download.packages(pkgs, destdir =
> tmpd, 
> 	available = available,  
> 
> Now the user is in trouble and sends me an error message asking how to get
> the 'gdata' package.
> 
> A couple of minor changes to the package installation/listing tools would
> help alleviate this and some related problems.
> 
> 1) Modify install.packages() so that the by default "dependencies=TRUE",
> since this knows how to find dependencies within bundles.  
> 	(Why is this FALSE by default anyway?  In normal circumstances, is
> there any
>              reason to install a package without installing its
> dependencies?)
> 
> 2) Modify install.packages() to check if a requested package is contained in
> a bundle, and install the bundle if so.

This is already done, at least in R-2.0.1 if "dependencies" is set to 
"TRUE".


> 3) Modify CRAN.packages() to list packages contained within bundles as well
> as independent packages, so that the windows "install packages from CRAN"
> menu item will properly show bundled packages.

You already get the packages in bundles in the "Contains" column with
   CRAN.packages()[,"Contains"]

Uwe


> 
> Comments?
> 
> Gregory R. Warnes
> Associate Director, Non-Clinical Statistics
> Pfizer Global Research and Development
> 
> 
> 
> LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From w.northcott at unsw.edu.au  Thu Jan  6 10:46:58 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Thu Jan  6 10:48:48 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <16860.48925.390153.388499@devzero.bogus.domain>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
	<C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051149490.59084@homer03.u.washington.edu>
	<DB4A6959-5F60-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051405010.59084@homer03.u.washington.edu>
	<82D986EA-5F6F-11D9-97FA-000393D3D676@unsw.edu.au>
	<16860.48925.390153.388499@devzero.bogus.domain>
Message-ID: <E87B67C7-5FC7-11D9-97FA-000393D3D676@unsw.edu.au>

On 06/01/2005, at 3:31 PM, John W. Eaton wrote:
> What I finally decided to do for Octave was to use a C language
> autoconf test for isnan, then provide a function declared "extern C"
> that is a wrapper around the C isnan function (if it exists).  I also
> use this method for other functions that may be easier to call from C
> than directly from C++.
>
Thanks for confirming my suspicions.

As far as I can see that is just what R has done with the R_IsNaN 
function.  I am just asking that it be included in the standalone Rmath 
library.

Bill Northcott

From plummer at iarc.fr  Thu Jan  6 12:16:51 2005
From: plummer at iarc.fr (Martyn Plummer)
Date: Thu Jan  6 12:18:53 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <DB4A6959-5F60-11D9-97FA-000393D3D676@unsw.edu.au>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
	<C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051149490.59084@homer03.u.washington.edu>
	<DB4A6959-5F60-11D9-97FA-000393D3D676@unsw.edu.au>
Message-ID: <1105010211.3643.5.camel@seurat>

On Thu, 2005-01-06 at 08:29 +1100, Bill Northcott wrote:
> On 06/01/2005, at 6:53 AM, Thomas Lumley wrote:
> >
> > I believe (with a little Googling) the suggested C++ approach is to 
> > use std::isnan if <cmath> is included.
> >
> I tried that too, but without any success.  I even tried 
> __gnu_cxx::isnan.
> 
> It was suggested by one of the gcc people, but I could find no 
> documentation about it.  The ISO C++ docs do not include isnan as a 
> symbol provided by cmath within the std namespace.  I looked at the gcc 
> source code and could see no reason why it should work.

I think the workaround is supposed to look like this:

#define _GLIBCPP_USE_C99 1
#include <cmath>
#undef _GLIBCPP_USE_C99
#include <iostream>

using __gnu_cxx::isnan;

I don't know whether this solves the problem on MacOs X but it is valid
on Linux.  But do you really want to write code that is specific to gcc?
I don't.

Martyn

From Friedrich.Leisch at tuwien.ac.at  Thu Jan  6 13:06:51 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Thu Jan  6 13:06:50 2005
Subject: [Rd] Broken Link for gregmisc_2.0.0.zip
In-Reply-To: <41DCEDD4.9080705@statistik.uni-dortmund.de>
References: <915D2D65A9986440A277AC5C98AA466F9787DA@groamrexm02.amer.pfizer.com>
	<x2llb74woc.fsf@biostat.ku.dk>
	<41DCEDD4.9080705@statistik.uni-dortmund.de>
Message-ID: <16861.10715.7621.429412@celebrian.ci.tuwien.ac.at>

>>>>> On Thu, 06 Jan 2005 08:50:44 +0100,
>>>>> Uwe Ligges (UL) wrote:

  > Peter Dalgaard wrote:
  >> "Warnes, Gregory R" <gregory.r.warnes@pfizer.com> writes:
  >> 
  >> 
  >>> The link from
  >>> http://cran.r-project.org/src/contrib/Descriptions/gregmisc.html to the
  >>> windows package  gregmisc_2.0.0.zip is broken.  
  >> 
  >> 
  >> Looks like a generic errors in mirroring the windows packages. Has
  >> happened before.

  > Not quite, Windows packages are mirrored correctly, but all (?) links to 
  > Windows *and* Mac OS X binary packages in the packages' Descriptions on 
  > CRAN are broken.

Sorry, my fault. I included the index building in a cron job and that
was broken. Should work now.

  > Uwe

  >> 
  >>> Also, could the appropriate email address for reporting web site problems
  >>> please be added to the website in some conspicous place?
  >> 
  >> 
  >> Good idea.
  >> 

Not really ... we had the webmaster address on almost all pages of
CRAN until 2 or 3 years ago. I removed it deliberately from most
places because way too many people confused it with r-help.

And I doubt that people like Greg really have problems finding out how
to contact Kurt or me ;-)

Best.
Fritz

From gregory.r.warnes at pfizer.com  Thu Jan  6 15:27:07 2005
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Thu Jan  6 15:27:33 2005
Subject: [Rd] Broken Link for gregmisc_2.0.0.zip
Message-ID: <915D2D65A9986440A277AC5C98AA466F9787F4@groamrexm02.amer.pfizer.com>



> Sorry, my fault. I included the index building in a cron job and that
> was broken. Should work now.
> 

Seems to work now.


>   > Uwe
> 
>   >> 
>   >>> Also, could the appropriate email address for reporting 
> web site problems
>   >>> please be added to the website in some conspicous place?
>   >> 
>   >> 
>   >> Good idea.
>   >> 
> 
> Not really ... we had the webmaster address on almost all pages of
> CRAN until 2 or 3 years ago. I removed it deliberately from most
> places because way too many people confused it with r-help.
> 
> And I doubt that people like Greg really have problems finding out how
> to contact Kurt or me ;-)
> 

The broken link was reported to my by users, who weren't really savvy, and
they would be unlikely to know..


> Best.
> Fritz
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

From murdoch at stats.uwo.ca  Thu Jan  6 15:50:11 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu Jan  6 15:50:23 2005
Subject: [Rd] Broken Link for gregmisc_2.0.0.zip
In-Reply-To: <16861.10715.7621.429412@celebrian.ci.tuwien.ac.at>
References: <915D2D65A9986440A277AC5C98AA466F9787DA@groamrexm02.amer.pfizer.com>
	<x2llb74woc.fsf@biostat.ku.dk>
	<41DCEDD4.9080705@statistik.uni-dortmund.de>
	<16861.10715.7621.429412@celebrian.ci.tuwien.ac.at>
Message-ID: <tnjqt0pkure6h50f5n5s8ncv3favhhqf3k@4ax.com>

On Thu, 6 Jan 2005 13:06:51 +0100, Friedrich.Leisch@tuwien.ac.at wrote
>
>Not really ... we had the webmaster address on almost all pages of
>CRAN until 2 or 3 years ago. I removed it deliberately from most
>places because way too many people confused it with r-help.

How about a "Contact Us" link on each page, which goes to a page that
lists the various possible contact addresses, with r-help first?  We
wouldn't want to put in the r-help submission address there; it should
be a link to <http://www.stat.math.ethz.ch/mailman/listinfo/r-help> or
some other page that tells people what to expect, and lets them search
the archives.

Duncan Murdoch

From uuykhuw at ahmdirect.com  Thu Jan  6 15:54:09 2005
From: uuykhuw at ahmdirect.com (donnette Woloshko)
Date: Thu Jan  6 15:53:21 2005
Subject: [Rd] donnette St0ckMogul Newsletter VCSC  stricture
Message-ID: <200501061453.j06ErAuU019979@hypatia.math.ethz.ch>

Woloshko,

VCSC-Get it immediately - in next week there
will be major promotions and it is expected to
have high gains immediately over the next 10 days
with massive promotions via fax starting wednesday
evening throughout the week and weekend. This stock
is Hot and is our number one pick for first quarter
of 2005.

Breaking NEWS: (VCSC)Vocalscape Announces License
Agreement and Partnership with Netfone Services Inc.

Huge News For:VCSC..this issue will explode in next
2-5 days - big PR campaign underway

Watch out for it . Jump on board ..  Stock expected
to hit two dollars by the end of the month!

Projected price in 3-5 days: 0.75 - 0.96
Projected price in 10-20 days : 2.00

MicroCap Marketing PLAY OF THE MONTH for our
investors is Vocalscape, Inc.

VCSC*HUGE NEWS released:

Vocalscape, Inc. is an emerging developer of interactive
communication software. The Company has created software
and interactive solutions revolving around global
communications and Data Voice Convergence. Vocalscape
focuses on adding to customer's website and customer
support centers by integrating website solutions that
enable real human assistance, live interaction services
such as instant messaging, voice over the Internet
(VoIP) and interactive desktop solutions sharing
solutions.

As previously announced on August 20, 2004 Vocalscape
has executed a Letter of Intent to Acquire 100% of
NTELX, Inc.   The company has created software and
interactive solutions revolving around global
communications and DATA & VOICE convergence. Our
strategy is to focus on VoIP communication solutions
that bring a full range of communications software,
and services together to solve business problems
and add value to our customers.

According to Infonetics Research's quarterly market
share and forecast service, Next Gen Voice Products,
worldwide next generation voice product revenue totaled
389m in 2Q 2004, up 10 percent from 1Q 2004 and up 21
percent year-over-year. Annual revenue is projected
to grow from $1.3b in 2003 to $4.8b in 2007.

NEWS ALERT:

KATONAH, N.Y., Jan. 3 /PRNewswire-FirstCall/ -
Vocalscape Inc.(TM) (VCSC), announces
the company has entered into a licensing agreement
with Netfone Services Inc. to license Vocalscape's
proprietary Eyefon, an award winning VoIP soft phone
and Vocalscape's pre-paid calling card cluster solution.


*Don't Wait Get VCSC_Today, Great Profits This Week*


Please be advised that nothing within this email shall
cons titute a soli citation or an invi tation to get p osition
in or se ll an y se, curity ment ioned herein. This newsletter
is neither a registered investment advisor nor affiliated
with any bro ker or de, aler. All sta tements ma de are our
exp ress opinion only and sh ould be trea ted as such. We
may o wn, take po sition and se ll any secu rities men tioned
at any time. This report inc ludes for ward look ing
stat ements within the mea ning of The Pri vate Se curities
Litig ation Refo rm Act of 19 95. These stat ements may
incl ude t erms as e xpect, bel ieve, may, w ill,
mov e, underv alued and int end or similar te rms. 
This news letter wa s pa id 11 300 f rom third par ty to
s end thi s rep ort. sunfish

krakow theirs

From w.northcott at unsw.edu.au  Fri Jan  7 00:56:05 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Fri Jan  7 00:56:37 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <1105010211.3643.5.camel@seurat>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
	<C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051149490.59084@homer03.u.washington.edu>
	<DB4A6959-5F60-11D9-97FA-000393D3D676@unsw.edu.au>
	<1105010211.3643.5.camel@seurat>
Message-ID: <875A8E98-603E-11D9-97FA-000393D3D676@unsw.edu.au>

On 06/01/2005, at 10:16 PM, Martyn Plummer wrote:
> I think the workaround is supposed to look like this:
> #define _GLIBCPP_USE_C99 1
> #include <cmath>
> #undef _GLIBCPP_USE_C99
> #include <iostream>
>
> using __gnu_cxx::isnan;

I thought I had tried that, but I was not sure.  So I tried again this 
morming, and it definitely does not work on MacOS X.  The problem being 
that the undefs in cmath are unconditional.

I presume it works on Linux because isnan is a function.

Bill Northcott

From Robert_Keefe at umit.maine.edu  Fri Jan  7 04:44:35 2005
From: Robert_Keefe at umit.maine.edu (Robert_Keefe@umit.maine.edu)
Date: Fri Jan  7 04:44:41 2005
Subject: [Rd] R 2.1 dies when some text() arguments are NULL (PR#7477)
Message-ID: <20050107034435.0EC9DEFB2@slim.kubism.ku.dk>



[My very deepest apologies in advance if this is not plain text; I am 
recently at a new job in a windows-based environment and have 
not yet set up my favorite old (pine) system. I have tried my best to 
strip all formatting from the message..]

I'm overlaying plots of tree locations mapped before and after 
logging activities and checking my matched individuals using 
several arguments to text() which plot tree attributes by or 
near their (x,y) locations. R 2.1 dies when a coding error on 
my part results in a null data.frame...

Example: 

plot(1)
text(NULL ~ NULL, label=NULL)

This happens for me under Windows 98 and XP. Andrew Robinson 
was kind enough to try it for me on FreeBSD with the same result. 
The code returns nothing for me under R 1.9 on Windows 98 and 
XP (same win. machines).  The version details of the three 
are as follows:

# FreeBSD:

>version
         _                      
platform i386-portbld-freebsd5.3
arch     i386                   
os       freebsd5.3             
system   i386, freebsd5.3       
status                          
major    2                      
minor    0.1                    
year     2004                   
month    11                     
day      15                     
language R                      

# Windows XP:

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R       

# Windows 98:

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R           

Please let me know if I can add any more details-

Thank you,

Rob 

_________________________________________________________

Rob Keefe

Cooperative Forestry Research Unit
University of Maine

From MSchwartz at MedAnalytics.com  Fri Jan  7 05:11:33 2005
From: MSchwartz at MedAnalytics.com (MSchwartz@MedAnalytics.com)
Date: Fri Jan  7 05:11:39 2005
Subject: [Rd] R 2.1 dies when some text() arguments are NULL (PR#7477)
Message-ID: <20050107041133.A73B8F1B2@slim.kubism.ku.dk>

On Fri, 2005-01-07 at 04:44 +0100, Robert_Keefe@umit.maine.edu wrote:
> 
> [My very deepest apologies in advance if this is not plain text; I am 
> recently at a new job in a windows-based environment and have 
> not yet set up my favorite old (pine) system. I have tried my best to 
> strip all formatting from the message..]
> 
> I'm overlaying plots of tree locations mapped before and after 
> logging activities and checking my matched individuals using 
> several arguments to text() which plot tree attributes by or 
> near their (x,y) locations. R 2.1 dies when a coding error on 
> my part results in a null data.frame...
> 
> Example: 
> 
> plot(1)
> text(NULL ~ NULL, label=NULL)
> 
> This happens for me under Windows 98 and XP. Andrew Robinson 
> was kind enough to try it for me on FreeBSD with the same result. 
> The code returns nothing for me under R 1.9 on Windows 98 and 
> XP (same win. machines).  The version details of the three 
> are as follows:
> 
> # FreeBSD:
> 
> >version
>          _                      
> platform i386-portbld-freebsd5.3
> arch     i386                   
> os       freebsd5.3             
> system   i386, freebsd5.3       
> status                          
> major    2                      
> minor    0.1                    
> year     2004                   
> month    11                     
> day      15                     
> language R                      
> 
> # Windows XP:
> 
> > version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R       
> 
> # Windows 98:
> 
> > version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R           
> 
> Please let me know if I can add any more details-
> 
> Thank you,
> 
> Rob 

Your subject line and body refer to R version 2.1, which technically
does not exist as 2.1.0 is the current development version. 

However, your output above indicates that R version 2.0.1 is what you
have installed on the three platforms. That is the current released
version.

In either case, using:

Version 2.0.1 Patched (2005-01-02)

I get the following:

> plot(1)
> text(NULL ~ NULL, label=NULL)
Error in text(xy.coords(x, y, recycle = TRUE), labels, adj, pos,
offset,  :
        no coordinates were supplied


Same thing with:

> plot(1)
> text(NULL, NULL, label = NULL)
Error in text.default(NULL, NULL, label = NULL) :
        x and y lengths differ in text().


No crash.


There is the following note in the NEWS file for 2.0.1 patched:

"text()'s default method could segfault if passed 0-length coordinates."

So I believe that this fixes the issue that you have posted about.


A patched version for Windows is available via CRAN:

http://www.cran.mirrors.pair.com/bin/windows/base/rpatched.html

and a source code tarball is available for the *nix versions via the FTP
link under the R Sources link:

ftp://ftp.stat.math.ethz.ch/Software/R/

HTH,

Marc Schwartz

From blindglobe at gmail.com  Fri Jan  7 11:03:51 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Fri Jan  7 11:03:57 2005
Subject: [Rd] Any plans for commenting out region via something like " /* */
	"?
Message-ID: <1abe3fa905010702034c2e2799@mail.gmail.com>

Greetings from Switzerland!

Are there any plans/initiatives/considerations in future versions of R
for commenting out regions via something like " /*    */  "?

(I've got an application for which something like that would be
useful; if not, there are less simple solutions).

best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From ripley at stats.ox.ac.uk  Fri Jan  7 12:03:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jan  7 12:03:55 2005
Subject: [Rd] Any plans for commenting out region via something like "
	/* */ "?
In-Reply-To: <1abe3fa905010702034c2e2799@mail.gmail.com>
References: <1abe3fa905010702034c2e2799@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0501071044580.31585@gannet.stats>

On Fri, 7 Jan 2005, A.J. Rossini wrote:

> Greetings from Switzerland!
>
> Are there any plans/initiatives/considerations in future versions of R
> for commenting out regions via something like " /*    */  "?
>
> (I've got an application for which something like that would be
> useful; if not, there are less simple solutions).

I normally use if(FALSE) {}: I also tend to use #if 0 #endif in C code, as 
otherwise you have to worry about nesting of comments.

We are currently working on internationalization of R, and a 2-char escape 
sequence doesn't look like a good idea to me.

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Fri Jan  7 12:03:42 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Jan  7 12:05:54 2005
Subject: [Rd] Any plans for commenting out region via something like " /*
	*/ "?
In-Reply-To: <1abe3fa905010702034c2e2799@mail.gmail.com>
References: <1abe3fa905010702034c2e2799@mail.gmail.com>
Message-ID: <x26529cxgx.fsf@biostat.ku.dk>

"A.J. Rossini" <blindglobe@gmail.com> writes:

> Greetings from Switzerland!
> 
> Are there any plans/initiatives/considerations in future versions of R
> for commenting out regions via something like " /*    */  "?

I don't think so. Personally, I'd rather work on getting the parser to
behave properly in all cases on

if (FALSE){
...lots of lines...
} 

What did "C-c ;" do wrong anyway, Mr.ESS?
 
> (I've got an application for which something like that would be
> useful; if not, there are less simple solutions).
> 
> best,
> -tony
> 
> "Commit early,commit often, and commit in a repository from which we can easily
> roll-back your mistakes" (AJR, 4Jan05).

...and commit to a branch or use #ifdef so that the daily package checks
don't break.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From B.Rowlingson at lancaster.ac.uk  Fri Jan  7 13:13:25 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri Jan  7 13:13:28 2005
Subject: [Rd] Any plans for commenting out region via something like "
	/*	*/ "?
In-Reply-To: <x26529cxgx.fsf@biostat.ku.dk>
References: <1abe3fa905010702034c2e2799@mail.gmail.com>
	<x26529cxgx.fsf@biostat.ku.dk>
Message-ID: <41DE7CE5.2070407@lancaster.ac.uk>

Peter Dalgaard wrote:

> I don't think so. Personally, I'd rather work on getting the parser to
> behave properly in all cases on
> 
> if (FALSE){
> ...lots of lines...
> } 

  Including cases where "...lots of lines..." isn't syntactically correct?

e.g.

  if (FALSE) {
   if(foo){.... - do something here....
  }

You can currently make the 'if'd out bit a big string:

foo <- function(bar){
   if(FALSE){
"
Foo
if(foo){
"
   }
   return(99)
}

  - Ooh, its almost a python """string""". Of course you cant have 
quotes in it, but if you have an end-block-comment signifier of any sort 
you cant have that signifier in your block anyway...

[R-1.9.1 seems to want backslash continuation characters inside 
multi-line quotes, R 2.0.0 doesn't]

Baz

From blindglobe at gmail.com  Fri Jan  7 13:23:57 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Fri Jan  7 13:24:01 2005
Subject: [Rd] Any plans for commenting out region via something like " /*
	*/ "?
In-Reply-To: <x26529cxgx.fsf@biostat.ku.dk>
References: <1abe3fa905010702034c2e2799@mail.gmail.com>
	<x26529cxgx.fsf@biostat.ku.dk>
Message-ID: <1abe3fa9050107042369fcc568@mail.gmail.com>

Thanks to Peter and Brian both for pointing out my second option.

For those wondering, I'm adapting a third party tool (hence no
integration with ESS, for which M-x comment-region works really much
better as of the last few releases), and working within a commented
region which could be contextually determined as "commented-out code"
would simplify the process.  The second option just needs a bit more
care (i.e. mapping
   "/*" = if(FALSE){
   "*/" = }
)
can be done if I'm careful.  Though it wasn't necessary that "/*" be
used, just something that was unambiguously identified.

best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From ggrothendieck at myway.com  Fri Jan  7 14:48:54 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri Jan  7 14:49:06 2005
Subject: [Rd] Any plans for commenting out region via something like " /*
	=?utf-8?b?Ki8JIj8=?=
References: <1abe3fa905010702034c2e2799@mail.gmail.com>
Message-ID: <loom.20050107T143701-306@post.gmane.org>

A.J. Rossini <blindglobe <at> gmail.com> writes:

: 
: Greetings from Switzerland!
: 
: Are there any plans/initiatives/considerations in future versions of R
: for commenting out regions via something like " /*    */  "?


You could use multiline character strings.  Just need to watch
out for embedded quotes.

From Robert.McGehee at geodecapital.com  Sat Jan  8 00:58:01 2005
From: Robert.McGehee at geodecapital.com (Robert.McGehee@geodecapital.com)
Date: Sat Jan  8 00:58:05 2005
Subject: [Rd] sub( , perl = TRUE) overflow (PR#7479)
Message-ID: <20050107235801.D981FED90@slim.kubism.ku.dk>

I'd like to report a bug (buffer overflow?) in the function sub(..., perl = TRUE)

I wanted to implement the familiar perl function for removing white spaces before and after a character string:
sub trimwhitespace($)
{
	my $string = shift;
	$string =~ s/^\s+//;
	$string =~ s/\s+$//;
	return $string;
}

So in R this would (presumably) become:

trimwhitespace <- function(x) {
    x <- sub('^\\s+', '', x, perl = TRUE) ## Removes preceding white spaces
    x <- sub('\\s+$', '', x, perl = TRUE) ## Removes trailing white spaces
    x
}

Expected behavior:
> trimwhitespace("                     abc")
[1] "abc"

On Windows:
> trimwhitespace("                     abc")
[1] "abc\0\220\277\036\001\220??\08iW\001p??\0X??\0"        ## That's not good! Looks like a buffer overflow

On Linux:
[1] "abc\0\0\002\0\0 \377\0\0\0\002\0\0\0\006\0\0/\377\0\0" ## Linux goofs as well!

Debugging shows that it is the first line in the function that produces the overflow. The overflow seems proportional to the about of preceding white spaces. I'm not sure if this is exploitable or not, but it might be possible to run arbitrary code stored in a character object using this.

Hopefully this is helpful,
Robert

> version # Linux
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    0.1
year     2004
month    11
day      15
language R

> version # Windows
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R      

## PS Here are the results of another call (x is 1000 spaces)
> trimwhitespace(paste(x, "abc"))
[1] "abc\0\0\002\0\002\0\001\0\001\004\0\0\0\a\003\0\0\004\002\0\0\0\001\0\0\024	\0\0\0\005class\0\0\006\020\0\0\0\001\0\0\004	\0\0\0\024groupGenericFunction\0\0\004\002\0\0\0\001\0\0\024	\0\0\0\apackage\0\0\004\020\0\0\0\001\0\0\004	\0\0\0\amethods\0\0\0?\0\0\004\002\0\0\0\001\0\0\024	\0\0\0\fgroupMembers\0\0\004\023\0\0\0\a\0\0\004\020\0\0\0\001\0\0\004	\0\0\0\001+\0\0\004\020\0\0\0\001\0\0\004	\0\0\0\001-\0\0\004\020\0\0\0\001\0\0\004	\0\0\0\001*\0\0\004\020\0\0\0\001\0\0\004	\0\0\0\001^\0\0\004\020\0\0\0\001\0\0\004	\0\0\0\002%%\0\0\004\020\0\0\0\001\0\0\004	\0\0\0\003%/%\0\0\004\020\0\0\0\001\0\0\004	\0\0\0\001/\0\0\004\002\0\0\0\001\0\0\024	\0\0\0\ageneric\0\0\006\020\0\0\0\001\0\0\004	\0\0\0\005Arith\0\0\004\002\0\0\002\377\0\0\004\020\0\0\0\001\0\0\004	\0\0\0\004base\0\0\0?\0\0\004\002\0\0\002\377\0\0\004\020\0\0\0\001\0\0\004	\0\0\0\004base\0\0\004\002\0\0\0\001\0\0\024	\0\0\0\005group\0\0\004\023\0\0\0\001\0\0\004\020\0\0\0\001\0\0\004	\0\0\0\003Ops\0\0\004\002\0\0!
 \0\001\0\0\024	\0\0\0\nvalueClass\0\0\0\020\0\0\0\0\0\0\004\002\0\0\0\001\0\0\024	\0\0\0	signature\0\0\004\020\0\0\0\002\0\0\024	\0\0\0\002e1\0\0\024	\0\0\0\002e2\0\0\004\002\0\0\0\001\0\0\024	\0\0\0\adefault\0\0\003\023\0\0\0\0\0\0\004\002\0\0\0\001\0\0\024	\0\0\0\amethods\0\0\0\023\0\0\0\0\0\0\004\002\0\0\0\001\0\0\024	\0\0\0\bargument\0\0\0\001\0\0\024	\0\0\0\002e1\0\0\004\002\0\0\0\001\0\0\024	\0\0\0\nallMethods\0\0\0\023\0\0\0\0\0\0\004\002\0\0\001\377\0\0\006\020\0\0\0\001\0\0\004	\0\0\0\vMethodsList\0\0\004\002\0\0\002\377\0\0\004\020\0\0\0\001\0\0\004	\0\0\0\amethods\0\0\0?\0\0\0?\0\0\004\002\0\0\0\001\0\0\024	\0\0\0\bskeleton\0\0\0\006\0\0\0\003\0\0\004\002\0\0\v\377\0\0\0?\0\0\004\002\0\0\0\001\0\0\024	\0\0\0\002e2\0\0\0?\0\0\0?\0\0\0\006\0\0\0\001\0\0\024	\0\0\0\004stop\0\0\0\002\0\0\004\020\0\0\0\001\0\0\004	\0\0\0>Invalid call in method dispatch to \"Arith\" (no default method)\0\0\0?\0\0\0\002\0\0\v\377\0\0\0\002\0\0\016\377\0\0\0?\0\0\0?\0\0\0?\0\0\0\0\0\0\0\!
 001\0\0\004	\0\0\0\benv::138\0\0\004\002\0\0\v\377\0\0\0?\0\0\!
 004\002\
0\0\016\377\0\0\0?\0\0\0?\0\0\0\006\0\0\017\377\0\0\0\002\0\0\004\020\0\0"  


Robert McGehee
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee@geodecapital.com



This e-mail, and any attachments hereto, are intended for use by the addressee(s) only and may contain information that is (i) confidential information of Geode Capital Management, LLC and/or its affiliates, and/or (ii) proprietary information of Geode Capital Management, LLC and/or its affiliates. If you are not the intended recipient of this e-mail, or if you have otherwise received this e-mail in error, please immediately notify me by telephone (you may call collect), or by e-mail, and please permanently delete the original, any print outs and any copies of the foregoing. Any dissemination, distribution or copying of this e-mail is strictly prohibited.

From rvwukfsvlscs32266 at hotmail.com  Sat Jan  8 07:48:08 2005
From: rvwukfsvlscs32266 at hotmail.com (Quspg Ynza)
Date: Sat Jan  8 07:49:05 2005
Subject: [Rd] =?ks_c_5601-1987?b?x/ax3bytuvG9urq4tNkgwPq3xcfPsNQgx9K6zrfO?=
	=?ks_c_5601-1987?q?!!?=
Message-ID: <BAY18-F10223CBDDA3EC9C0AFB823FD950@phx.gbl>

??/?? ?? ? http://click-loan.wo.to 
166887

From ripley at stats.ox.ac.uk  Sat Jan  8 08:25:53 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Jan  8 08:26:49 2005
Subject: [Rd] sub( , perl = TRUE) overflow (PR#7479)
In-Reply-To: <20050107235801.D981FED90@slim.kubism.ku.dk>
References: <20050107235801.D981FED90@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0501080718310.28066@gannet.stats>

On Sat, 8 Jan 2005 Robert.McGehee@geodecapital.com wrote:

> I'd like to report a bug (buffer overflow?) in the function sub(..., perl = TRUE)
>
> I wanted to implement the familiar perl function for removing white spaces before and after a character string:
> sub trimwhitespace($)
> {
> 	my $string = shift;
> 	$string =~ s/^\s+//;
> 	$string =~ s/\s+$//;
> 	return $string;
> }
>
> So in R this would (presumably) become:
>
> trimwhitespace <- function(x) {
>    x <- sub('^\\s+', '', x, perl = TRUE) ## Removes preceding white spaces
>    x <- sub('\\s+$', '', x, perl = TRUE) ## Removes trailing white spaces
>    x
> }
>
> Expected behavior:
>> trimwhitespace("                     abc")
> [1] "abc"
>
> On Windows:
>> trimwhitespace("                     abc")
> [1] "abc\0\220\277\036\001\220??\08iW\001p??\0X??\0"        ## That's not good! Looks like a buffer overflow
>
> On Linux:
> [1] "abc\0\0\002\0\0 \377\0\0\0\002\0\0\0\006\0\0/\377\0\0" ## Linux goofs as well!
>
> Debugging shows that it is the first line in the function that produces 
> the overflow. The overflow seems proportional to the about of preceding 
> white spaces. I'm not sure if this is exploitable or not, but it might 
> be possible to run arbitrary code stored in a character object using 
> this.

Don't think so.  It's actually just a printing issue: the length used for 
printing is marked incorrectly (as the length of the original string), and
you won't be able to access the character string past the \0 in any other 
way.

I've fixed it now.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
From Bill.Venables at csiro.au  Sat Jan  8 08:50:26 2005
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Sat Jan  8 08:50:34 2005
Subject: [Rd] as.data.frame.table and the name "Freq"
Message-ID: <B998A44C8986644EA8029CFE6396A9240AB129@exqld2-bne.qld.csiro.au>

May I suggest that the method as.data.frame.table not have the name
"Freq" hardwired as the response name?  This is a problem if "Freq" is
already the name of a stimulus factor.

Here is the existing function:

as.data.frame.table <- function (x, row.names = NULL, optional = FALSE,
...) {
    x <- as.table(x)
    data.frame(do.call("expand.grid", dimnames(x)), Freq = c(x), 
        row.names = row.names)
}

My suggested fix is

as.data.frame.table <- 
function (x, row.names = NULL, optional = FALSE, responseName = "Freq",
...) {
    x <- as.table(x)
    ex <- Quote(data.frame(do.call("expand.grid", dimnames(x)), Freq =
c(x), 
        row.names = row.names))
    names(ex)[3] <- responseName
    eval(ex)
}

This should be no slower and should break no existing code.
 
Bill Venables,

From ripley at stats.ox.ac.uk  Sat Jan  8 10:40:30 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Jan  8 10:40:43 2005
Subject: [Rd] as.data.frame.table and the name "Freq"
In-Reply-To: <B998A44C8986644EA8029CFE6396A9240AB129@exqld2-bne.qld.csiro.au>
References: <B998A44C8986644EA8029CFE6396A9240AB129@exqld2-bne.qld.csiro.au>
Message-ID: <Pine.LNX.4.61.0501080939560.797@gannet.stats>

No sooner said that done.
It _is_ nice to see code with a suggested enhancement.

On Sat, 8 Jan 2005 Bill.Venables@csiro.au wrote:

> May I suggest that the method as.data.frame.table not have the name
> "Freq" hardwired as the response name?  This is a problem if "Freq" is
> already the name of a stimulus factor.
>
> Here is the existing function:
>
> as.data.frame.table <- function (x, row.names = NULL, optional = FALSE,
> ...) {
>    x <- as.table(x)
>    data.frame(do.call("expand.grid", dimnames(x)), Freq = c(x),
>        row.names = row.names)
> }
>
> My suggested fix is
>
> as.data.frame.table <-
> function (x, row.names = NULL, optional = FALSE, responseName = "Freq",
> ...) {
>    x <- as.table(x)
>    ex <- Quote(data.frame(do.call("expand.grid", dimnames(x)), Freq =
> c(x),
>        row.names = row.names))
>    names(ex)[3] <- responseName
>    eval(ex)
> }
>
> This should be no slower and should break no existing code.
>
> Bill Venables,
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From kleiber at statistik.uni-dortmund.de  Sat Jan  8 16:00:28 2005
From: kleiber at statistik.uni-dortmund.de (Christian Kleiber)
Date: Sat Jan  8 16:03:58 2005
Subject: [Rd] cmdscale problem
Message-ID: <41DFF58C.8040501@statistik.uni-dortmund.de>

Dear R developers,

there appears to be a small problem with function cmdscale: for 
non-Euclidean distance matrices, using option add=FALSE (the default), 
cmdscale misses the smallest eigenvalue. This affects GOF statistic g.1 
(See Mardia, Kent + Bibby (1979): Multivariate Analysis, eq. (14.4.7). 
The corresponding formula in Cox + Cox (2001): Multidimensional Scaling, 
2nd ed., p 38, would seem to contain a misprint, it should be n instead 
of n-1.)

Example:

R> cmdscale(eurodist, eig=TRUE)$GOF
[1] 0.7968344 0.8679134

The full set of eigenvalues can be obtained via

R> H <- function(n) { diag(n) - matrix(1, n, n)/n }
R> eigen( -.5 * H(21) %*% (as.matrix(eurodist))^2 %*% H(21) ,
+ only.values=TRUE)$values
  [1]  1.953838e+07  1.185656e+07  1.528844e+06
  [4]  1.118742e+06  7.893472e+05  5.816552e+05
  [7]  2.623192e+05  1.925976e+05  1.450845e+05
[10]  1.079673e+05  5.139484e+04  3.538963e-10
[13] -9.496124e+03 -5.305820e+04 -1.322166e+05
[16] -2.573360e+05 -3.326719e+05 -5.162523e+05
[19] -9.191491e+05 -1.006504e+06 -2.251844e+06


whereas cmdscale allows access of the first 20 of these via


R> cmdscale(eurodist, k=20, eig=TRUE)$eig
  [1]  1.953838e+07  1.185656e+07  1.528844e+06
  [4]  1.118742e+06  7.893472e+05  5.816552e+05
  [7]  2.623192e+05  1.925976e+05  1.450845e+05
[10]  1.079673e+05  5.139484e+04  4.656613e-10
[13] -9.496124e+03 -5.305820e+04 -1.322166e+05
[16] -2.573360e+05 -3.326719e+05 -5.162523e+05
[19] -9.191491e+05 -1.006504e+06
Warning messages:
...


Suggestion: replace

     evalus <- e$values[-n]

with

     evalus <- e$values

This yields

R> cmdscale(eurodist, eig=TRUE)$GOF
[1] 0.7537543 0.8679134


Minor points:

May I suggest to allow access of all eigenvalues, instead of just the 
first k as delivered by cmdscale(... , eig=TRUE)$eig, in order to permit 
inspection of the severity of the problem? (I am aware that a comparison 
of g.1 and g.2 indicates the presence of negative eigenvalues.) It might 
also be useful to deliver a warning whenever some eigenvalues are < 0, 
using something like

if (any(e$values < 0))
       warning("some eigenvalues are < 0")

Also, the documentation says that cmdscale(...)$eig returns "the n-1 
eigenvalues computed during the scaling process if 'eig' is true", 
whereas in fact it returns the first k.

Incidentally, there is an undocumented feature: depending on the value 
of if(eig || x.ret || add) the value is a list including a component 
'ac' (add. constant) in addition to those mentioned in the documentation.

Best regards,
Christian Kleiber


Version: R 2.0.1
OS: Win XP Pro


-- 

*****************************************

Dr. Christian Kleiber
FB Statistik
Universitaet Dortmund
Vogelpothsweg 78
D-44227 DORTMUND
Germany

Tel: ++49-(0)231-755 5419
Fax: ++49-(0)231-755 5284
E-mail: kleiber@statistik.uni-dortmund.de

From maechler at stat.math.ethz.ch  Sat Jan  8 17:19:23 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat Jan  8 17:19:33 2005
Subject: [Rd] p.adjust(<NA>s), was "Re: [BioC] limma and p-values"
In-Reply-To: <1680.211.31.70.61.1105107090.squirrel@211.31.70.61>
References: <200501071109.j07B88Mw022009@hypatia.math.ethz.ch>
	<1680.211.31.70.61.1105107090.squirrel@211.31.70.61>
Message-ID: <16864.2059.154031.140551@stat.math.ethz.ch>

>>>>> "GS" == Gordon K Smyth <smyth@wehi.edu.au>
>>>>>     on Sat, 8 Jan 2005 01:11:30 +1100 (EST) writes:
    
    <.............>

    GS> p.adjust() unfortunately gives incorrect results when
    GS> 'p' includes NAs.  The results from topTable are
    GS> correct.  topTable() takes care to remove NAs before
    GS> passing the values to p.adjust().

There's at least one bug in p.adjust():  The "hommel" method
currently does not work at all with NAs (and I have an
uncommitted fix ready for this bug).
OTOH, the current version of p.adjust() ``works'' with NA's,
apart from Hommel's method, but by using "n = length(p)" in the
correction formulae, i.e. *including* the NAs for determining
sample size `n'  {my fix to "hommel" would do this as well}.

My question is what p.adjust() should do when there are NA's
more generally, or more specifically which `n' to use in the
correction formula. Your proposal amounts to
  ``drop NA's and forget about them till the very end''
  (where they are wanted in the result),
i.e., your sample size `n' would be sum(!is.na(p)) instead of
length(p).

To me it doesn't seem obvious that this setting 
"n = #{non-NA observations}" is desirable for all 
P-value adjustment methods. One argument for keeping
``n = #{all observations}'' at least for some correction
methods is the following  "continuity" one:

If only a few ``irrelevant'' (let's say > 0.5) P-values are
replaced by NA, the adjusted relevant small P-values shouldn't
change much, ideally not at all.  I'm really no scholar on this
topic, but e.g. for "holm" I think I would want to keep ``full
n'' because of the above continuity argument.
BTW, for "fdr", I don't see a straightforward way to achieve the
desired continuity.
5D
Of course, p.adjust() could adopt the possibility of chosing how
NA's should be treated e.g. by another argument ``use.na = TRUE/FALSE''
and hence allow both versions.  

Feedback very welcome, particularly from ``P-value experts'' ;-)

Martin Maechler, ETH Zurich

From MSchwartz at MedAnalytics.com  Sat Jan  8 18:04:53 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Sat Jan  8 18:19:15 2005
Subject: [Rd] Re: [R] Compilation of R code
In-Reply-To: <Pine.LNX.4.61.0501080727330.28066@gannet.stats>
References: <20050108000023.46622.qmail@web53407.mail.yahoo.com>
	<1105145233.6298.7.camel@horizons.localdomain>
	<Pine.LNX.4.61.0501080727330.28066@gannet.stats>
Message-ID: <1105203894.14300.16.camel@horizons.localdomain>

On Sat, 2005-01-08 at 07:33 +0000, Prof Brian Ripley wrote:
> On Fri, 7 Jan 2005, Marc Schwartz wrote:
> 
> > On Fri, 2005-01-07 at 16:00 -0800, Sameul M Mwalili wrote:
> >> Dear ALL,
> >> In order to install the Rice R to C compiler (RCC) you need to patch
> >> the R source code. However, the patch command at DOS prompt returns an
> >> error:  patch is not recognized as internal or external command. How
> >> do you patch in DOS (or Windows)?
> >>
> >> Regards,
> >>
> >> Samuel.
> >
> > The GNU patch program is available as source code via:
> >
> > http://www.fsf.org/software/patch/patch.html
> >
> > I also located a Sourceforge project that has pre-built native Win32
> > binaries, which requires msvcrt.dll:
> >
> > http://unxutils.sourceforge.net/
> >
> > There may be other resources to reference.
> 
> Most of us use Cygwin (http://www.cygwin.com/).  Gnuwin32 is also a good 
> source (a bigger and more active project than unxutils):
> 
> http://gnuwin32.sourceforge.net/
> 
> and their latest announcement is patch.
> 
> Warning: the RCC patches are R-version specific, and the last available 
> appears to be 1.9.0.
> 
> Warning2: Some Windows versions of patch require CRLF files, and the R 
> sources are LF files when unpacked by tar.

[moved to r-devel]

WRT to Warning2, unix2dos and dos2unix are available via the cygutils
package at Cygwin to make the requisite conversions.

Also, might it be reasonable to add a pointer to the gnuwin32 project to
DM's site as a resource for additional tools? I tried searching his
site, the I&A manual, the INSTALL file in .../src/gnuwin32, Kevin's "R
for Windows Users" on CRAN and the list archives but could not locate
anything on patch for Windows initially.

Also, as an FYI to Fritz, the links to Kevin's web site in the
Contributed Documentation section:

http://www.stat.auckland.ac.nz/~kwan022/pub/R/WinBook/
http://www.stat.auckland.ac.nz/~kwan022/rinfo.php

are not valid.

Kevin appears to have moved here:

http://www.maths.anu.edu.au/~wangk/personal/pub/R/WinBook/
http://www.maths.anu.edu.au/~wangk/personal/rinfo.php

HTH,

Marc

From maechler at stat.math.ethz.ch  Sat Jan  8 21:29:39 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat Jan  8 21:29:44 2005
Subject: [Rd] p.adjust(<NA>s), was "Re: [BioC] limma and p-values"
In-Reply-To: <16864.2059.154031.140551@stat.math.ethz.ch>
References: <200501071109.j07B88Mw022009@hypatia.math.ethz.ch>
	<1680.211.31.70.61.1105107090.squirrel@211.31.70.61>
	<16864.2059.154031.140551@stat.math.ethz.ch>
Message-ID: <16864.17075.17844.24998@stat.math.ethz.ch>

I've thought more and made experiements with R code versions
and just now committed a new version of  p.adjust()  to R-devel
--> https://svn.r-project.org/R/trunk/src/library/stats/R/p.adjust.R
which does sensible NA handling by default and 
*additionally* has an "na.rm" argument (set to FALSE by
default).  The extended 'Examples' secion on the help page
    https://svn.r-project.org/R/trunk/src/library/stats/man/p.adjust.Rd
shows how the new NA handling is typically much more sensible
than using "na.rm = TRUE".

Martin 


>>>>> "MM" == Martin Maechler <maechler@stat.math.ethz.ch>
>>>>>     on Sat, 8 Jan 2005 17:19:23 +0100 writes:

>>>>> "GS" == Gordon K Smyth <smyth@wehi.edu.au>
>>>>>     on Sat, 8 Jan 2005 01:11:30 +1100 (EST) writes:
    
    MM>     <.............>

    GS> p.adjust() unfortunately gives incorrect results when
    GS> 'p' includes NAs.  The results from topTable are
    GS> correct.  topTable() takes care to remove NAs before
    GS> passing the values to p.adjust().

    MM> There's at least one bug in p.adjust(): The "hommel"
    MM> method currently does not work at all with NAs (and I
    MM> have an uncommitted fix ready for this bug).  OTOH, the
    MM> current version of p.adjust() ``works'' with NA's, apart
    MM> from Hommel's method, but by using "n = length(p)" in
    MM> the correction formulae, i.e. *including* the NAs for
    MM> determining sample size `n' {my fix to "hommel" would do
    MM> this as well}.

    MM> My question is what p.adjust() should do when there are
    MM> NA's more generally, or more specifically which `n' to
    MM> use in the correction formula. Your proposal amounts to
    MM> ``drop NA's and forget about them till the very end''
    MM> (where they are wanted in the result), i.e., your sample
    MM> size `n' would be sum(!is.na(p)) instead of length(p).

    MM> To me it doesn't seem obvious that this setting "n =
    MM> #{non-NA observations}" is desirable for all P-value
    MM> adjustment methods. One argument for keeping ``n = #{all
    MM> observations}'' at least for some correction methods is
    MM> the following "continuity" one:

    MM> If only a few ``irrelevant'' (let's say > 0.5) P-values
    MM> are replaced by NA, the adjusted relevant small P-values
    MM> shouldn't change much, ideally not at all.  I'm really
    MM> no scholar on this topic, but e.g. for "holm" I think I
    MM> would want to keep ``full n'' because of the above
    MM> continuity argument.  BTW, for "fdr", I don't see a
    MM> straightforward way to achieve the desired continuity.
    MM> 5D Of course, p.adjust() could adopt the possibility of
    MM> chosing how NA's should be treated e.g. by another
    MM> argument ``use.na = TRUE/FALSE'' and hence allow both
    MM> versions.

    MM> Feedback very welcome, particularly from ``P-value
    MM> experts'' ;-)

    MM> Martin Maechler, ETH Zurich

From tac at nei.nih.gov  Sat Jan  8 22:20:15 2005
From: tac at nei.nih.gov (tac@nei.nih.gov)
Date: Sat Jan  8 22:20:23 2005
Subject: [Rd] Documentation bug (PR#7483)
Message-ID: <20050108212015.37986ED90@slim.kubism.ku.dk>

Full_Name: Terry A. Cox
Version: 2.0.1
OS: Mac OS X
Submission from: (NULL) (138.88.250.18)


In the file, http://cran.r-project.org/doc/manuals/R-exts.html, several of the
headers have incorrect closing tags, e.g., 
 
 <h3 class="subsection">The <code>DESCRIPTION</code> file</h4>

This creates a problem in standards-compliant web browsers such as Safari.

From ripley at stats.ox.ac.uk  Sat Jan  8 22:37:22 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Jan  8 22:37:27 2005
Subject: [Rd] Documentation bug (PR#7483)
Message-ID: <20050108213722.7AAB1EFC0@slim.kubism.ku.dk>

http://cran.r-project.org is not part of R per se and has its own bug 
reporting address, CRAN@r-project.org.

That file was made with makeinfo 4.6, and it is a bug in that version of 
makeinfo.

It is not a problem in the version distributed with R for Windows, for 
example, made with the current makeinfo 4.7.

On Sat, 8 Jan 2005 tac@nei.nih.gov wrote:

> Full_Name: Terry A. Cox
> Version: 2.0.1
> OS: Mac OS X
> Submission from: (NULL) (138.88.250.18)
>
>
> In the file, http://cran.r-project.org/doc/manuals/R-exts.html, several of the
> headers have incorrect closing tags, e.g.,
>
> <h3 class="subsection">The <code>DESCRIPTION</code> file</h4>
>
> This creates a problem in standards-compliant web browsers such as Safari.

So please report to the site concerned.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From tlumley at u.washington.edu  Sat Jan  8 23:11:57 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat Jan  8 23:12:08 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <E87B67C7-5FC7-11D9-97FA-000393D3D676@unsw.edu.au>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
	<C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051149490.59084@homer03.u.washington.edu>
	<DB4A6959-5F60-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051405010.59084@homer03.u.washington.edu>
	<82D986EA-5F6F-11D9-97FA-000393D3D676@unsw.edu.au>
	<16860.48925.390153.388499@devzero.bogus.domain>
	<E87B67C7-5FC7-11D9-97FA-000393D3D676@unsw.edu.au>
Message-ID: <Pine.A41.4.61b.0501081406410.219908@homer04.u.washington.edu>


A review:

The C++ math header undefines isnan, so if isnan is a macro, ISNAN() will 
not work in C++ code.

C99 specifies that isnan is a macro, but in C90 compilers, where it is an 
extension, isnan is often a function (explaining why the issue didn't come 
up earlier). For example, isnan is a macro on my Mac laptop but a function 
on my Linux desktop.

R-devel now defines ISNAN to call a function if used in C++ code. It still 
calls isnan in C code.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley@u.washington.edu	University of Washington, Seattle

From Robert.McGehee at geodecapital.com  Sun Jan  9 00:05:43 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Sun Jan  9 00:06:37 2005
Subject: [Rd] new("call") problem
Message-ID: <67DCA285A2D7754280D3B8E88EB5480206741E02@MSGBOSCLB2WIN.DMN1.FMR.COM>

The below looks like the show method has trouble with the default call
object (or that there is no default call object). Not sure if this is a
bug, design problem, or a difficulty on my part using and extending the
call class, but it has caused difficulty for when I want to extend the
call class into other S4 classes.

> new("call")
Error in print("<undef>"()) : couldn't find function "<undef>"

This error pops up when I show an object with an empty call slot.
Error in show("<undef>"()) : Unable to find the argument "object" in
selecting a method for function "show"

I'll leave it up to the developers to designate this as a bug or not,
but I would certainly prefer that new() and show() never reports errors
when an empty object is passed as an argument (of any class).

Best,
Robert

Robert McGehee
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee@geodecapital.com



This e-mail, and any attachments hereto, are intended for use by the
addressee(s) only and may contain information that is (i) confidential
information of Geode Capital Management, LLC and/or its affiliates,
and/or (ii) proprietary information of Geode Capital Management, LLC
and/or its affiliates. If you are not the intended recipient of this
e-mail, or if you have otherwise received this e-mail in error, please
immediately notify me by telephone (you may call collect), or by e-mail,
and please permanently delete the original, any print outs and any
copies of the foregoing. Any dissemination, distribution or copying of
this e-mail is strictly prohibited.

From w.northcott at unsw.edu.au  Sun Jan  9 01:09:18 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Sun Jan  9 01:09:38 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <Pine.A41.4.61b.0501081406410.219908@homer04.u.washington.edu>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
	<C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051149490.59084@homer03.u.washington.edu>
	<DB4A6959-5F60-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051405010.59084@homer03.u.washington.edu>
	<82D986EA-5F6F-11D9-97FA-000393D3D676@unsw.edu.au>
	<16860.48925.390153.388499@devzero.bogus.domain>
	<E87B67C7-5FC7-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501081406410.219908@homer04.u.washington.edu>
Message-ID: <B45E7F7C-61D2-11D9-97FA-000393D3D676@unsw.edu.au>

On 09/01/2005, at 9:11 AM, Thomas Lumley wrote:
> The C++ math header undefines isnan, so if isnan is a macro, ISNAN() 
> will not work in C++ code.
>
> C99 specifies that isnan is a macro, but in C90 compilers, where it is 
> an extension, isnan is often a function (explaining why the issue 
> didn't come up earlier). For example, isnan is a macro on my Mac 
> laptop but a function on my Linux desktop.
>
> R-devel now defines ISNAN to call a function if used in C++ code. It 
> still calls isnan in C code.

Many thanks for that.

Does this mean the changes will be in the current daily builds?
I presume the function involved is now in the standalone Rmath build.

Bill Northcott

From smyth at wehi.edu.au  Sun Jan  9 03:57:10 2005
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Sun Jan  9 03:58:39 2005
Subject: [Rd] p.adjust(<NA>s), was "Re: [BioC] limma and p-values"
In-Reply-To: <16864.17075.17844.24998@stat.math.ethz.ch>
References: <200501071109.j07B88Mw022009@hypatia.math.ethz.ch>
	<1680.211.31.70.61.1105107090.squirrel@211.31.70.61>
	<16864.2059.154031.140551@stat.math.ethz.ch>
	<16864.17075.17844.24998@stat.math.ethz.ch>
Message-ID: <6.0.1.1.1.20050109135243.0294b7e8@imaphost.wehi.edu.au>

Martin,

Thanks for this.  I was planning to code suggestions for p.adjust() myself 
today, but you got in before me.

I don't think that the new way of handling NAs is quite correct.  The 
trouble is that all of the adjustment methods other than "none" and 
"bonferonni" are step-down or step-up methods, meaning that you need to 
know all the p-values before you can adjust any of them.

Suppose for example that you have a single p-value 'p=0.05' and you want to 
adjust this using Holm's method with 'n=10'.  Holm's method is a step-down 
Bonferonni method so the adjusted p-value can be anywhere between 0.05 and 
0.5 depending on what the other nine p-values are.  So the correct adjusted 
p-value is indeterminate.

The value returned by 'p.adjust(0.05,method="holm",n=10)' is 0.5.  The same 
value is returned if 'p' is a vector with nine NAs:

   p <- c(0.05,rep(NA,9))
   p.adjust(p,method="holm")

In effect the nine NA p-values are treated as if they are equal to one.  So 
rather than accommodating unknown data, p.adjust() is in effect making data 
up.  I think it would be best not to do this but, if you do, there should 
at least be a warning message like

"warning: p-values indeterminate in the presence of NAs, most conservative 
possible values being returned"

I think that the correct treatment is that implemented for 'na.rm=TRUE', 
i.e., the non-NA adjusted p-values should be the same as if there were no 
NAs in 'p'.  This is because NAs in 'p' virtually always indicate, not an 
existing but unknown p-value, but a p-value which could not be computed 
because there was insufficient data to do so.  This means that there is 
zero probability of rejecting the null hypothesis for these 
cases.  Therefore it is unnecessary to adjust the other p-values for these 
cases.

The argument 'n' to 'p.adjust()' is problematic for the same reasons that 
NAs in 'p' are.  Setting 'n' to be less than than sum(!is.na(p)) should I 
think return an error.  Setting 'n' to be more than sum(!is.na(p)) makes 
all the adjusted p-values indeterminate unless method="none" or 
method="bonferroni".  And setting 'n' to be between sum(!is.na(p)) and 
length(p) when these are different is just horrible.  Would anything be 
lost if this argument was removed?

Gordon

At 07:29 AM 9/01/2005, Martin Maechler wrote:
>I've thought more and made experiements with R code versions
>and just now committed a new version of  p.adjust()  to R-devel
>--> https://svn.r-project.org/R/trunk/src/library/stats/R/p.adjust.R
>which does sensible NA handling by default and
>*additionally* has an "na.rm" argument (set to FALSE by
>default).  The extended 'Examples' secion on the help page
>     https://svn.r-project.org/R/trunk/src/library/stats/man/p.adjust.Rd
>shows how the new NA handling is typically much more sensible
>than using "na.rm = TRUE".
>
>Martin
>
>
> >>>>> "MM" == Martin Maechler <maechler@stat.math.ethz.ch>
> >>>>>     on Sat, 8 Jan 2005 17:19:23 +0100 writes:
>
> >>>>> "GS" == Gordon K Smyth <smyth@wehi.edu.au>
> >>>>>     on Sat, 8 Jan 2005 01:11:30 +1100 (EST) writes:
>
>     MM>     <.............>
>
>     GS> p.adjust() unfortunately gives incorrect results when
>     GS> 'p' includes NAs.  The results from topTable are
>     GS> correct.  topTable() takes care to remove NAs before
>     GS> passing the values to p.adjust().
>
>     MM> There's at least one bug in p.adjust(): The "hommel"
>     MM> method currently does not work at all with NAs (and I
>     MM> have an uncommitted fix ready for this bug).  OTOH, the
>     MM> current version of p.adjust() ``works'' with NA's, apart
>     MM> from Hommel's method, but by using "n = length(p)" in
>     MM> the correction formulae, i.e. *including* the NAs for
>     MM> determining sample size `n' {my fix to "hommel" would do
>     MM> this as well}.
>
>     MM> My question is what p.adjust() should do when there are
>     MM> NA's more generally, or more specifically which `n' to
>     MM> use in the correction formula. Your proposal amounts to
>     MM> ``drop NA's and forget about them till the very end''
>     MM> (where they are wanted in the result), i.e., your sample
>     MM> size `n' would be sum(!is.na(p)) instead of length(p).
>
>     MM> To me it doesn't seem obvious that this setting "n =
>     MM> #{non-NA observations}" is desirable for all P-value
>     MM> adjustment methods. One argument for keeping ``n = #{all
>     MM> observations}'' at least for some correction methods is
>     MM> the following "continuity" one:
>
>     MM> If only a few ``irrelevant'' (let's say > 0.5) P-values
>     MM> are replaced by NA, the adjusted relevant small P-values
>     MM> shouldn't change much, ideally not at all.  I'm really
>     MM> no scholar on this topic, but e.g. for "holm" I think I
>     MM> would want to keep ``full n'' because of the above
>     MM> continuity argument.  BTW, for "fdr", I don't see a
>     MM> straightforward way to achieve the desired continuity.
>     MM> 5D Of course, p.adjust() could adopt the possibility of
>     MM> chosing how NA's should be treated e.g. by another
>     MM> argument ``use.na = TRUE/FALSE'' and hence allow both
>     MM> versions.
>
>     MM> Feedback very welcome, particularly from ``P-value
>     MM> experts'' ;-)
>
>     MM> Martin Maechler, ETH Zurich

From tlumley at u.washington.edu  Sun Jan  9 06:37:34 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun Jan  9 06:37:45 2005
Subject: [Rd] Standalone Mathlib, C++ and ISNAN()
In-Reply-To: <B45E7F7C-61D2-11D9-97FA-000393D3D676@unsw.edu.au>
References: <77B2A8C4-5ED8-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501050759060.100170@homer05.u.washington.edu>
	<C2214FA4-5F4F-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051149490.59084@homer03.u.washington.edu>
	<DB4A6959-5F60-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501051405010.59084@homer03.u.washington.edu>
	<82D986EA-5F6F-11D9-97FA-000393D3D676@unsw.edu.au>
	<16860.48925.390153.388499@devzero.bogus.domain>
	<E87B67C7-5FC7-11D9-97FA-000393D3D676@unsw.edu.au>
	<Pine.A41.4.61b.0501081406410.219908@homer04.u.washington.edu>
	<B45E7F7C-61D2-11D9-97FA-000393D3D676@unsw.edu.au>
Message-ID: <Pine.A41.4.61b.0501082134210.201862@homer05.u.washington.edu>

On Sun, 9 Jan 2005, Bill Northcott wrote:

> Does this mean the changes will be in the current daily builds?
> I presume the function involved is now in the standalone Rmath build.
>

The function is available for the standalone Rmath library and also 
linking to R.  I'm not sure when the daily snapshot gets taken, but it 
should be in Monday's version at the latest.

 	-thomas

From giles.heywood at cantab.net  Sun Jan  9 22:38:54 2005
From: giles.heywood at cantab.net (Giles Heywood)
Date: Sun Jan  9 22:38:57 2005
Subject: [Rd] S4 class no longer accepts matrix in array slot under 2.0.1
Message-ID: <KLEHJMEACMGEMBOOPFCAAEJPCAAA.giles.heywood@cantab.net>

I have an S4 class with a slot of class "array", and in upgrading to 2.0.1
(from 1.9.1) I have encountered a change in behaviour. This causes me some
difficulties if I want to allow 2-dimensional arrays in the slot.

The following (in 2.0.1) illustrates the point:

> setClass("foo",representation("array"))
[1] "foo"
> a <- new("foo",array(NA,2:4))
> b <- new("foo",matrix(NA,2,3))
Error in "as<-"(`*tmp*`, Classi, value = c(NA, NA, NA, NA, NA, NA)) :
        No method or default for as() replacement of "foo" with
Class="matrix"

This last error did not occur under 1.9.1.

I conclude that in this context the methods package does not recognise
"matrix" as a subclass of "array". However if I use getClass(), I see that R
recognises "matrix" as a subclass of "array" (and vice-versa).  So is this
new behaviour correct?

[this is a re-posting to R-devel of a question earlier posted to R-help,
which attracted limited response]

From Friedrich.Leisch at tuwien.ac.at  Mon Jan 10 09:36:30 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Mon Jan 10 09:36:34 2005
Subject: [Rd] Documentation bug (PR#7483)
Message-ID: <20050110083630.2C004EADF@slim.kubism.ku.dk>

>>>>> On Sat, 8 Jan 2005 21:37:09 +0000 (GMT),
>>>>> Prof Brian Ripley (PBR) wrote:

  > http://cran.r-project.org is not part of R per se and has its own b=
ug=20
  > reporting address, CRAN@r-project.org.

  > That file was made with makeinfo 4.6, and it is a bug in that versi=
on of=20
  > makeinfo.

  > It is not a problem in the version distributed with R for Windows, =
for=20
  > example, made with the current makeinfo 4.7.

Thanks for the bug report, has been fixed.

Best,

--=20
-------------------------------------------------------------------
                        Friedrich Leisch=20
Institut f=FCr Statistik                     Tel: (+43 1) 58801 10715
Technische Universit=E4t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra=DFe 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch

From kjblack at gmail.com  Mon Jan 10 15:22:03 2005
From: kjblack at gmail.com (kjblack@gmail.com)
Date: Mon Jan 10 15:22:12 2005
Subject: [Rd] Problem with compiling - Freebsd on AMD64 (PR#7489)
Message-ID: <20050110142203.7E1D81043E@slim.kubism.ku.dk>

Full_Name: Kelly Black
Version: 2.0.1
OS: FreeBSD 5.3 on AMD64
Submission from: (NULL) (149.106.32.93)


I downloaded R-2.0.1 from the R website, ran configure then make and got an
error. I will paste a copy of the output from the makefile below. The problem
was when the makefile tried to run the R binary. When I came across the error I
reran configure, but this time with the following arguments:

./configure FFLAGS="-g" CFLAGS="-g" CXXFLAGS="-g"

This time when I ran make it compiled with no problems. I tried the same thing
again only with all of the flags set to "-O" and again it compiled with no
problems. When I ran it with the flags set to "-g -O2" it had the same error. A
copy of the output from gdb can be found at
http://blackk.union.edu/~black/freebsd/R-error.txt, but the output isn't very
helpful.

The system used is a laptop, Compaq Presario (amd64), under FreeBSD 5.3 compiled
for the amd64 architecture.

Output from make with flags "-O2"

black@compaqlaptop$ pwd
/tmp/R-2.0.1/src/library/base
black@compaqlaptop$ make
echo "building package 'base'"
building package 'base'
/usr/local/bin/bash ../../../src/scripts/mkinstalldirs ../../../library/base/R
(f=${TMPDIR:-/tmp}/R$$;  cat `LC_COLLATE=C ls ./R/*.R ./R/unix/*.R` >> ${f};
/usr/local/bin/bash ../../../tools/move-if-change ${f} all.R)
all.R is unchanged
/usr/local/bin/bash ../../../tools/copy-if-change all.R
../../../library/base/R/base ${f}
../../../library/base/R/base is unchanged
for f in COPYRIGHTS INDEX SOURCES; do  if test -f ./${f}; then
/usr/bin/install -c -m 644 ./${f}  ../../../library/base;  fi;  done
if test -f DESCRIPTION; then  /usr/bin/install -c -m 644 DESCRIPTION
../../../library/base;  (tmp="Built: R 2.0.1; ";  if test -d ./src; then
tmp="${tmp}x86_64-unknown-freebsd5.3";  fi;  tmp="${tmp}; `date`; unix";  echo
"${tmp}")  >> ../../../library/base/DESCRIPTION;  fi
/usr/local/bin/bash ../../../src/scripts/mkinstalldirs
../../../library/base/demo
for f in `ls -d ./demo/* | sed -e '/CVS/d' -e '/00Index/d'`; do
/usr/bin/install -c -m 644 ${f} ../../../library/base/demo;  done
/usr/local/bin/bash ../../../src/scripts/mkinstalldirs
../../../library/base/man
(f=${TMPDIR:-/tmp}/R$$;  for rdfile in ./man/*.Rd ./man/unix/*.Rd; do  echo "%
--- Source file: ${rdfile} ---";  cat ${rdfile}; echo '\eof';  done >> ${f};
/usr/local/bin/bash ../../../tools/move-if-change ${f}
../../../library/base/man/base.Rd)
rm -f ../../../library/base/man/base.Rd.gz
/usr/bin/gzip ../../../library/base/man/base.Rd
/usr/bin/install -c -m 644 ./inst/CITATION ../../../library/base
/usr/bin/install -c -m 644 all.R ../../../library/base/R/base
cat ./makebasedb.R |  R_DEFAULT_PACKAGES=NULL LC_COLLATE=C ../../../bin/R
--vanilla --slave > /dev/null
Floating point exception (core dumped)
*** Error code 136

Stop in /tmp/R-2.0.1/src/library/base.

From ripley at stats.ox.ac.uk  Mon Jan 10 16:01:52 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 10 16:02:00 2005
Subject: [Rd] Problem with compiling - Freebsd on AMD64 (PR#7489)
In-Reply-To: <20050110142203.7E1D81043E@slim.kubism.ku.dk>
References: <20050110142203.7E1D81043E@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0501101435520.17308@gannet.stats>

In what sense is this a bug in R?  If changing your compiler optimization 
leads to a segfault, it looks very like a compiler bug.  So what was the 
compiler?

[R does work using AMD64 on Linux, but only correctly with gcc >= 3.3.3.]

BTW gdb output with "-g -O2" (the R default) ought to be informative, so 
was this with -O?

On Mon, 10 Jan 2005 kjblack@gmail.com wrote:

> Full_Name: Kelly Black
> Version: 2.0.1
> OS: FreeBSD 5.3 on AMD64
> Submission from: (NULL) (149.106.32.93)
>
>
> I downloaded R-2.0.1 from the R website, ran configure then make and got 
> an error. I will paste a copy of the output from the makefile below. The 
> problem was when the makefile tried to run the R binary. When I came 
> across the error I reran configure, but this time with the following 
> arguments:
>
> ./configure FFLAGS="-g" CFLAGS="-g" CXXFLAGS="-g"
>
> This time when I ran make it compiled with no problems. I tried the same thing
> again only with all of the flags set to "-O" and again it compiled with no
> problems. When I ran it with the flags set to "-g -O2" it had the same error. A
> copy of the output from gdb can be found at
> http://blackk.union.edu/~black/freebsd/R-error.txt, but the output isn't very
> helpful.
>
> The system used is a laptop, Compaq Presario (amd64), under FreeBSD 5.3 compiled
> for the amd64 architecture.
>
> Output from make with flags "-O2"
>
> black@compaqlaptop$ pwd
> /tmp/R-2.0.1/src/library/base
> black@compaqlaptop$ make
> echo "building package 'base'"
> building package 'base'
> /usr/local/bin/bash ../../../src/scripts/mkinstalldirs ../../../library/base/R
> (f=${TMPDIR:-/tmp}/R$$;  cat `LC_COLLATE=C ls ./R/*.R ./R/unix/*.R` >> ${f};
> /usr/local/bin/bash ../../../tools/move-if-change ${f} all.R)
> all.R is unchanged
> /usr/local/bin/bash ../../../tools/copy-if-change all.R
> ../../../library/base/R/base ${f}
> ../../../library/base/R/base is unchanged
> for f in COPYRIGHTS INDEX SOURCES; do  if test -f ./${f}; then
> /usr/bin/install -c -m 644 ./${f}  ../../../library/base;  fi;  done
> if test -f DESCRIPTION; then  /usr/bin/install -c -m 644 DESCRIPTION
> ../../../library/base;  (tmp="Built: R 2.0.1; ";  if test -d ./src; then
> tmp="${tmp}x86_64-unknown-freebsd5.3";  fi;  tmp="${tmp}; `date`; unix";  echo
> "${tmp}")  >> ../../../library/base/DESCRIPTION;  fi
> /usr/local/bin/bash ../../../src/scripts/mkinstalldirs
> ../../../library/base/demo
> for f in `ls -d ./demo/* | sed -e '/CVS/d' -e '/00Index/d'`; do
> /usr/bin/install -c -m 644 ${f} ../../../library/base/demo;  done
> /usr/local/bin/bash ../../../src/scripts/mkinstalldirs
> ../../../library/base/man
> (f=${TMPDIR:-/tmp}/R$$;  for rdfile in ./man/*.Rd ./man/unix/*.Rd; do  echo "%
> --- Source file: ${rdfile} ---";  cat ${rdfile}; echo '\eof';  done >> ${f};
> /usr/local/bin/bash ../../../tools/move-if-change ${f}
> ../../../library/base/man/base.Rd)
> rm -f ../../../library/base/man/base.Rd.gz
> /usr/bin/gzip ../../../library/base/man/base.Rd
> /usr/bin/install -c -m 644 ./inst/CITATION ../../../library/base
> /usr/bin/install -c -m 644 all.R ../../../library/base/R/base
> cat ./makebasedb.R |  R_DEFAULT_PACKAGES=NULL LC_COLLATE=C ../../../bin/R
> --vanilla --slave > /dev/null
> Floating point exception (core dumped)
> *** Error code 136
>
> Stop in /tmp/R-2.0.1/src/library/base.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Mon Jan 10 16:08:46 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Jan 10 16:11:12 2005
Subject: [Rd] Problem with compiling - Freebsd on AMD64 (PR#7489)
In-Reply-To: <20050110142203.7E1D81043E@slim.kubism.ku.dk>
References: <20050110142203.7E1D81043E@slim.kubism.ku.dk>
Message-ID: <x2oefxtj7l.fsf@biostat.ku.dk>

kjblack@gmail.com writes:

> Full_Name: Kelly Black
> Version: 2.0.1
> OS: FreeBSD 5.3 on AMD64
> Submission from: (NULL) (149.106.32.93)
> 
> 
> I downloaded R-2.0.1 from the R website, ran configure then make and got an
> error. I will paste a copy of the output from the makefile below. The problem
> was when the makefile tried to run the R binary. When I came across the error I
> reran configure, but this time with the following arguments:
> 
> ./configure FFLAGS="-g" CFLAGS="-g" CXXFLAGS="-g"
> 
> This time when I ran make it compiled with no problems. I tried the same thing
> again only with all of the flags set to "-O" and again it compiled with no
> problems. When I ran it with the flags set to "-g -O2" it had the same error. A
> copy of the output from gdb can be found at
> http://blackk.union.edu/~black/freebsd/R-error.txt, but the output isn't very
> helpful.

Indeed...

This sounds like a compiler error, so information about the GCC
version used is crucial. Switching compilers or running with less than
optimal optimization is your best chance, unless you can pinpoint
exactly what is getting miscompiled so that a workaround can be found. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From murdoch at stats.uwo.ca  Mon Jan 10 16:22:03 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon Jan 10 16:20:49 2005
Subject: [Rd] Windows build hiatus
Message-ID: <7u65u0deovch2dkdo5sqf3ova9esc1n3c6@4ax.com>

There have been a lot of changes recently in R-devel, so I've been
uploading frequent Windows builds to CRAN.  I'm heading out to a
conference this week, so it's unlikely there will be any more builds
until Jan 18 or later.  (I've just done one today; it may not show up
until tomorrow).

If you were unaware of these builds, they are available at your
favourite CRAN mirror (list here:
http://cran.r-project.org/mirrors.html) in the bin/windows/base
directory.  Follow the link to "the r-devel release" or the "r-patched
release".

Duncan Murdoch

From Robert.McGehee at geodecapital.com  Mon Jan 10 16:47:08 2005
From: Robert.McGehee at geodecapital.com (Robert.McGehee@geodecapital.com)
Date: Mon Jan 10 16:47:12 2005
Subject: [Rd] new("call") problem (PR#7490)
Message-ID: <20050110154708.BE2A4EAE1@slim.kubism.ku.dk>

I have found a solution to the new("call") problem that I believe
produces the correct behavior for the default call object, and am also
reclassifying this as a bug, as I believe the current behavior to be
incorrect.

Recap, the following error occurs:
> new("call")
Error in print("<undef>"()) : couldn't find function "<undef>"

It looks like the problem is that the default object for new("call") is
the function "<undef>"(), which does not exist. So, the show() and
print() methods correspondingly fail.

If I initialize the "<undef>"() function at the beginning of my code to
an empty function:

> "<undef>" <- new("function")

then new("call") will then reference an existing (yet empty) object that
is coerced into a call, and the show and print methods correctly display
this object as NULL. Furthermore, I am able to extend this empty call
object to other S4 objects without trouble.

Now:
> "<undef>" <- new("function")
> new("call")
NULL

> str(new("call"))
Formal class 'call' [package "methods"] with 0 slots
 list()

This, I believe is the preferred behavior of new("call"), and I would
contend this fix should be included in the R source.

Best,
Robert

-----Original Message-----
From: McGehee, Robert [mailto:Robert.McGehee@geodecapital.com] 
Sent: Saturday, January 08, 2005 6:06 PM
To: r-devel@stat.math.ethz.ch
Subject: [Rd] new("call") problem


The below looks like the show method has trouble with the default call
object (or that there is no default call object). Not sure if this is a
bug, design problem, or a difficulty on my part using and extending the
call class, but it has caused difficulty for when I want to extend the
call class into other S4 classes.

> new("call")
Error in print("<undef>"()) : couldn't find function "<undef>"

This error pops up when I show an object with an empty call slot.
Error in show("<undef>"()) : Unable to find the argument "object" in
selecting a method for function "show"

I'll leave it up to the developers to designate this as a bug or not,
but I would certainly prefer that new() and show() never reports errors
when an empty object is passed as an argument (of any class).

Best,
Robert

Robert McGehee
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee@geodecapital.com



This e-mail, and any attachments hereto, are intended for use by the
addressee(s) only and may contain information that is (i) confidential
information of Geode Capital Management, LLC and/or its affiliates,
and/or (ii) proprietary information of Geode Capital Management, LLC
and/or its affiliates. If you are not the intended recipient of this
e-mail, or if you have otherwise received this e-mail in error, please
immediately notify me by telephone (you may call collect), or by e-mail,
and please permanently delete the original, any print outs and any
copies of the foregoing. Any dissemination, distribution or copying of
this e-mail is strictly prohibited.

______________________________________________
R-devel@stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From saurin_jani at yahoo.com  Mon Jan 10 16:50:34 2005
From: saurin_jani at yahoo.com (Saurin Jani)
Date: Mon Jan 10 16:50:42 2005
Subject: [Rd] is there String concating function in R?
Message-ID: <20050110155034.89110.qmail@web41112.mail.yahoo.com>

Hi All,

I prob. missed it but I would like to make string
concating. Is there any string concating function in
R?

A <- "abc";
B <- ".jpeg"

C <- c(A,B);
it does not do abc.jpeg in string format..?

can anyone guide me ?


Thank you,
Saurin

From dimitris.rizopoulos at med.kuleuven.ac.be  Mon Jan 10 16:56:52 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Mon Jan 10 16:57:41 2005
Subject: [Rd] is there String concating function in R?
References: <20050110155034.89110.qmail@web41112.mail.yahoo.com>
Message-ID: <009701c4f72d$00765300$0540210a@www.domain>

Hi Saurin,

Firstly you should post this question to R-help and not in R-devel 
since the purpose of the latter is different.

Regarding your question take a look at ?paste

paste(A, B, sep="")

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Saurin Jani" <saurin_jani@yahoo.com>
To: "Rproject development" <r-devel@stat.math.ethz.ch>
Sent: Monday, January 10, 2005 4:50 PM
Subject: [Rd] is there String concating function in R?


> Hi All,
>
> I prob. missed it but I would like to make string
> concating. Is there any string concating function in
> R?
>
> A <- "abc";
> B <- ".jpeg"
>
> C <- c(A,B);
> it does not do abc.jpeg in string format..?
>
> can anyone guide me ?
>
>
> Thank you,
> Saurin
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From kjblack at gmail.com  Mon Jan 10 16:59:08 2005
From: kjblack at gmail.com (Kelly Black)
Date: Mon Jan 10 16:59:13 2005
Subject: [Rd] Problem with compiling - Freebsd on AMD64 (PR#7489)
In-Reply-To: <Pine.LNX.4.61.0501101435520.17308@gannet.stats>
References: <20050110142203.7E1D81043E@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0501101435520.17308@gannet.stats>
Message-ID: <1b1b33f105011007594d0c9c42@mail.gmail.com>

Dear Prof's Ripley and Dalgaard ,

You are correct; this is a compiler error.  I assumed that since it
was an easy fix to the problem by just changing the compiler option to
-O that it could save some headaches for you. As far as the version
goes, it is gcc v. 3.4.2 built for freebsd on the amd64:

black@compaqlaptop$ gcc -v
Using built-in specs.
Configured with: FreeBSD/amd64 system compiler
Thread model: posix
gcc version 3.4.2 [FreeBSD] 20040728


Finally, the output was with "-g -O2". Using -0 compiles and installs
with no problems.

Sincerely,
Kel

On Mon, 10 Jan 2005 15:01:52 +0000 (GMT), Prof Brian Ripley
<ripley@stats.ox.ac.uk> wrote:
> In what sense is this a bug in R?  If changing your compiler optimization
> leads to a segfault, it looks very like a compiler bug.  So what was the
> compiler?
> 
> [R does work using AMD64 on Linux, but only correctly with gcc >= 3.3.3.]
> 
> BTW gdb output with "-g -O2" (the R default) ought to be informative, so
> was this with -O?
> 
> On Mon, 10 Jan 2005 kjblack@gmail.com wrote:
> 
> > Full_Name: Kelly Black
> > Version: 2.0.1
> > OS: FreeBSD 5.3 on AMD64
> > Submission from: (NULL) (149.106.32.93)
> >
> >
> > I downloaded R-2.0.1 from the R website, ran configure then make and got
> > an error. I will paste a copy of the output from the makefile below. The
> > problem was when the makefile tried to run the R binary. When I came
> > across the error I reran configure, but this time with the following
> > arguments:
> >
> > ./configure FFLAGS="-g" CFLAGS="-g" CXXFLAGS="-g"
> >
> > This time when I ran make it compiled with no problems. I tried the same thing
> > again only with all of the flags set to "-O" and again it compiled with no
> > problems. When I ran it with the flags set to "-g -O2" it had the same error. A
> > copy of the output from gdb can be found at
> > http://blackk.union.edu/~black/freebsd/R-error.txt, but the output isn't very
> > helpful.
> >
> > The system used is a laptop, Compaq Presario (amd64), under FreeBSD 5.3 compiled
> > for the amd64 architecture.
> >
> > Output from make with flags "-O2"
> >
> > black@compaqlaptop$ pwd
> > /tmp/R-2.0.1/src/library/base
> > black@compaqlaptop$ make
> > echo "building package 'base'"
> > building package 'base'
> > /usr/local/bin/bash ../../../src/scripts/mkinstalldirs ../../../library/base/R
> > (f=${TMPDIR:-/tmp}/R$$;  cat `LC_COLLATE=C ls ./R/*.R ./R/unix/*.R` >> ${f};
> > /usr/local/bin/bash ../../../tools/move-if-change ${f} all.R)
> > all.R is unchanged
> > /usr/local/bin/bash ../../../tools/copy-if-change all.R
> > ../../../library/base/R/base ${f}
> > ../../../library/base/R/base is unchanged
> > for f in COPYRIGHTS INDEX SOURCES; do  if test -f ./${f}; then
> > /usr/bin/install -c -m 644 ./${f}  ../../../library/base;  fi;  done
> > if test -f DESCRIPTION; then  /usr/bin/install -c -m 644 DESCRIPTION
> > ../../../library/base;  (tmp="Built: R 2.0.1; ";  if test -d ./src; then
> > tmp="${tmp}x86_64-unknown-freebsd5.3";  fi;  tmp="${tmp}; `date`; unix";  echo
> > "${tmp}")  >> ../../../library/base/DESCRIPTION;  fi
> > /usr/local/bin/bash ../../../src/scripts/mkinstalldirs
> > ../../../library/base/demo
> > for f in `ls -d ./demo/* | sed -e '/CVS/d' -e '/00Index/d'`; do
> > /usr/bin/install -c -m 644 ${f} ../../../library/base/demo;  done
> > /usr/local/bin/bash ../../../src/scripts/mkinstalldirs
> > ../../../library/base/man
> > (f=${TMPDIR:-/tmp}/R$$;  for rdfile in ./man/*.Rd ./man/unix/*.Rd; do  echo "%
> > --- Source file: ${rdfile} ---";  cat ${rdfile}; echo '\eof';  done >> ${f};
> > /usr/local/bin/bash ../../../tools/move-if-change ${f}
> > ../../../library/base/man/base.Rd)
> > rm -f ../../../library/base/man/base.Rd.gz
> > /usr/bin/gzip ../../../library/base/man/base.Rd
> > /usr/bin/install -c -m 644 ./inst/CITATION ../../../library/base
> > /usr/bin/install -c -m 644 all.R ../../../library/base/R/base
> > cat ./makebasedb.R |  R_DEFAULT_PACKAGES=NULL LC_COLLATE=C ../../../bin/R
> > --vanilla --slave > /dev/null
> > Floating point exception (core dumped)
> > *** Error code 136
> >
> > Stop in /tmp/R-2.0.1/src/library/base.
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> --
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 


-- 
_______________________________________________________          __o
Kelly Black                     Phone: (603) 862-3587  \       _`\<,_
Department of Math. & Stat.     FAX:   (603) 862-4096   \_____(_)/ (_)
University of New Hampshire     e-mail: kelly.black@unh.edu
Durham, NH 03824  (USA)         WWW: http://www.math.unh.edu/~black

From ligges at statistik.uni-dortmund.de  Mon Jan 10 17:00:19 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Jan 10 16:59:34 2005
Subject: [Rd] is there String concating function in R?
In-Reply-To: <20050110155034.89110.qmail@web41112.mail.yahoo.com>
References: <20050110155034.89110.qmail@web41112.mail.yahoo.com>
Message-ID: <41E2A693.9030208@statistik.uni-dortmund.de>

Saurin Jani wrote:

> Hi All,
> 
> I prob. missed it but I would like to make string
> concating. Is there any string concating function in
> R?
> 
> A <- "abc";
> B <- ".jpeg"
> 
> C <- c(A,B);
> it does not do abc.jpeg in string format..?
> 
> can anyone guide me ?

?paste

Uwe Ligges

> 
> Thank you,
> Saurin
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From jgentry at jimmy.harvard.edu  Mon Jan 10 17:04:42 2005
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Mon Jan 10 17:08:58 2005
Subject: [Rd] is there String concating function in R?
In-Reply-To: <20050110155034.89110.qmail@web41112.mail.yahoo.com>
Message-ID: <Pine.SOL.4.20.0501101104260.2139-100000@santiam.dfci.harvard.edu>

> I prob. missed it but I would like to make string
> concating. Is there any string concating function in
> R?
> A <- "abc";
> B <- ".jpeg"
> 
> C <- c(A,B);
> it does not do abc.jpeg in string format..?

?paste

From chris.haidinyak at amd.com  Mon Jan 10 18:17:34 2005
From: chris.haidinyak at amd.com (chris.haidinyak@amd.com)
Date: Mon Jan 10 18:17:41 2005
Subject: [Rd] XFIG color output (PR#7491)
Message-ID: <20050110171734.622B0EFCC@slim.kubism.ku.dk>

Full_Name: Chris Haidinyak
Version: 2.0.1 & 1.9.0
OS: Linux x86_64
Submission from: (NULL) (139.95.251.9)


Hi,

   I am using R 1.9.0 (on Linux Redhat AS 3 - x86_64) and 2.0.1 (on Linux Fedora
Core 3 - x86_64) and am having problems using graphs created with the xfig
option.


1.9.0 problem - sometimes the graph output puts the color definitions in the
wrong place in the file. According to the xfig program, color definitions must
come before any object. For whatever reason, R sometimes produces xfig files
with color definitions in the wrong place. Run demo('graphics') to recreate the
problem.


2.0.1 problem - This release seems worse that 1.9.0. All of the graphic output
from R to xfig (using the following script
   xfig()
   demo('graphics')
   dev.off()
produces only b/w graphs or no graph at all.

What is the problem? Am I doing something wrong? Please advise; thank you.

Best Regards,
  Chris Haidinyak

From ripley at stats.ox.ac.uk  Mon Jan 10 19:45:13 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 10 19:45:26 2005
Subject: [Rd] XFIG color output (PR#7491)
In-Reply-To: <20050110171734.622B0EFCC@slim.kubism.ku.dk>
References: <20050110171734.622B0EFCC@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0501101837060.9702@gannet.stats>

On Mon, 10 Jan 2005 chris.haidinyak@amd.com wrote:

> Full_Name: Chris Haidinyak
> Version: 2.0.1 & 1.9.0
> OS: Linux x86_64
> Submission from: (NULL) (139.95.251.9)
>
>
> Hi,
>
>   I am using R 1.9.0 (on Linux Redhat AS 3 - x86_64) and 2.0.1 (on Linux Fedora
> Core 3 - x86_64) and am having problems using graphs created with the xfig
> option.
>
>
> 1.9.0 problem - sometimes the graph output puts the color definitions in the
> wrong place in the file. According to the xfig program, color definitions must
> come before any object. For whatever reason, R sometimes produces xfig files
> with color definitions in the wrong place. Run demo('graphics') to recreate the
> problem.

I can't.  What exactly are you doing, and in which file does this occur?
I have just tested all of them.

If perchance you were using onefile=TRUE, do read the comment in the help 
file.

Please produce a reproducible example.

> 2.0.1 problem - This release seems worse that 1.9.0. All of the graphic output
> from R to xfig (using the following script
>   xfig()
>   demo('graphics')
>   dev.off()
> produces only b/w graphs or no graph at all.

Paul Murrell altered the alpha channel handling in 2.0.0, and missed this 
one.  I have a patch tested and about to go into 2.0.1-patched.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jmc at r-project.org  Mon Jan 10 23:10:13 2005
From: jmc at r-project.org (John Chambers)
Date: Mon Jan 10 23:10:25 2005
Subject: [Rd] S4 class no longer accepts matrix in array slot under 2.0.1
In-Reply-To: <KLEHJMEACMGEMBOOPFCAAEJPCAAA.giles.heywood@cantab.net>
References: <KLEHJMEACMGEMBOOPFCAAEJPCAAA.giles.heywood@cantab.net>
Message-ID: <41E2FD45.20404@R-project.org>

Your example and your subject heading are two different things.  If you 
meant the subject heading, that in fact works.

R> setClass("a1", representation(x="array"))
[1] "a1"
R> new("a1", x=matrix(1:12,3,4))
An object of class "a1"
Slot "x":
      [,1] [,2] [,3] [,4]
[1,]    1    4    7   10
[2,]    2    5    8   11
[3,]    3    6    9   12

That's not what your example does.  In your example, the new class 
extends "array", rather than using it as a slot.  It would have been 
clearer if you had said setClass("foo", contains="array"), but your code 
is correct for that purpose.

On first examination, I believe the problem is just what the message 
says it is.  You gave as a new object (and NOT as a slot) an object from 
a subclass of a superclass of "foo".  This is allowed, but has to be 
done by replacing the part of a "foo" object corresponding to the 
"array" contained in a "matrix" object.  Of course, we know that's 
actually the whole object, but nothing has told the software this.  And, 
indeed, it doesn't find the necessary replacement method.

Here's an example similar to what you are doing, but using actual 
classes.  Barring screwups on my part, it shows that the mechanism works 
as asserted.  Classes "c1", "c2", "c3" follow the roles of "array", 
"matrix", and "foo" in your example.
R> setClass("c1", representation(x="numeric"))
[1] "c1"
R> setClass("c2", contains="c1")
[1] "c2"
R> setClass("c3", contains = "c1")
[1] "c3"
R> x2 = new("c2", x=1)
R> x3 = new("c3", x2)
R> x3
An object of class "c3"
Slot "x":
[1] 1

Classes "matrix" and "array" are rather peculiar in R; among other 
things, they act like vector data types in that is.object() is FALSE.
And you cannot have an "array" with a dimension of length 2.

R> class(array(1:12, dim=c(3,4)))
[1] "matrix"

Also, because they don't have a consistent set of "slots" (they may or 
may not have a "dimnames), they aren't quite real classes in an S4 
sense.  It would be nice to fix this mess, but not obviously possible 
while being back compatible.

It's possible that there is a fix to get around the particular error 
here, without breaking the more general pattern--I'll take a look.

Otherwise, you may need to follow the approach of your subject heading, 
and define a new class with an array as a slot.

Giles Heywood wrote:

> I have an S4 class with a slot of class "array", and in upgrading to 2.0.1
> (from 1.9.1) I have encountered a change in behaviour. This causes me some
> difficulties if I want to allow 2-dimensional arrays in the slot.
> 
> The following (in 2.0.1) illustrates the point:
> 
> 
>>setClass("foo",representation("array"))
> 
> [1] "foo"
> 
>>a <- new("foo",array(NA,2:4))
>>b <- new("foo",matrix(NA,2,3))
> 
> Error in "as<-"(`*tmp*`, Classi, value = c(NA, NA, NA, NA, NA, NA)) :
>         No method or default for as() replacement of "foo" with
> Class="matrix"
> 
> This last error did not occur under 1.9.1.
> 
> I conclude that in this context the methods package does not recognise
> "matrix" as a subclass of "array". However if I use getClass(), I see that R
> recognises "matrix" as a subclass of "array" (and vice-versa).  So is this
> new behaviour correct?

You conclude incorrectly, as noted above.
> 
> [this is a re-posting to R-devel of a question earlier posted to R-help,
> which attracted limited response]
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From jmc at r-project.org  Mon Jan 10 23:40:38 2005
From: jmc at r-project.org (John Chambers)
Date: Mon Jan 10 23:40:53 2005
Subject: [Rd] new("call") problem (PR#7490)
In-Reply-To: <20050110154708.BE2A4EAE1@slim.kubism.ku.dk>
References: <20050110154708.BE2A4EAE1@slim.kubism.ku.dk>
Message-ID: <41E30466.5020309@R-project.org>

Too bad you didn't stick to your earlier intention:

 > I'll leave it up to the developers to designate this as a bug or not,
 > but I would certainly prefer that new() and show() never reports errors
 > when an empty object is passed as an argument (of any class).

I agree, assuming what you mean by "empty" is the default object from 
the class.  But the issue is one of the behavior of the R evaluator, 
which wants to evaluate the call object when it's passed to the default 
print() code--just as the error message says.  We can maybe get around 
that, but I don't think your solution below is desirable.  There is a 
reason that the default function reference is called "<undef>":  an 
error _should_ be generated if you evaluate a call to an undefined function.

Notice:
R> tt <- new("call")
R> dput(tt)
"<undef>"()

This works as a show() method, but the current default printing code in 
R never calls show() for objects of class "call" so something else would 
have to be done, in the base package or the evaluator, rather than in 
methods.

R> setMethod("show", "call", function(object)dput(object))
[1] "show"
R> show(tt)
"<undef>"()
R> tt
Error in print("<undef>"()) : couldn't find function "<undef>"



Robert.McGehee@geodecapital.com wrote:
> I have found a solution to the new("call") problem that I believe
> produces the correct behavior for the default call object, and am also
> reclassifying this as a bug, as I believe the current behavior to be
> incorrect.
> 
> Recap, the following error occurs:
> 
>>new("call")
> 
> Error in print("<undef>"()) : couldn't find function "<undef>"
> 
> It looks like the problem is that the default object for new("call") is
> the function "<undef>"(), which does not exist. So, the show() and
> print() methods correspondingly fail.
> 
> If I initialize the "<undef>"() function at the beginning of my code to
> an empty function:
> 
> 
>>"<undef>" <- new("function")
> 
> 
> then new("call") will then reference an existing (yet empty) object that
> is coerced into a call, and the show and print methods correctly display
> this object as NULL. Furthermore, I am able to extend this empty call
> object to other S4 objects without trouble.
> 
> Now:
> 
>>"<undef>" <- new("function")
>>new("call")
> 
> NULL
> 
> 
>>str(new("call"))
> 
> Formal class 'call' [package "methods"] with 0 slots
>  list()
> 
> This, I believe is the preferred behavior of new("call"), and I would
> contend this fix should be included in the R source.
> 
> Best,
> Robert
> 
> -----Original Message-----
> From: McGehee, Robert [mailto:Robert.McGehee@geodecapital.com] 
> Sent: Saturday, January 08, 2005 6:06 PM
> To: r-devel@stat.math.ethz.ch
> Subject: [Rd] new("call") problem
> 
> 
> The below looks like the show method has trouble with the default call
> object (or that there is no default call object). Not sure if this is a
> bug, design problem, or a difficulty on my part using and extending the
> call class, but it has caused difficulty for when I want to extend the
> call class into other S4 classes.
> 
> 
>>new("call")
> 
> Error in print("<undef>"()) : couldn't find function "<undef>"
> 
> This error pops up when I show an object with an empty call slot.
> Error in show("<undef>"()) : Unable to find the argument "object" in
> selecting a method for function "show"
> 
> I'll leave it up to the developers to designate this as a bug or not,
> but I would certainly prefer that new() and show() never reports errors
> when an empty object is passed as an argument (of any class).
> 
> Best,
> Robert
> 
> Robert McGehee
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee@geodecapital.com
> 
> 
> 
> This e-mail, and any attachments hereto, are intended for use by the
> addressee(s) only and may contain information that is (i) confidential
> information of Geode Capital Management, LLC and/or its affiliates,
> and/or (ii) proprietary information of Geode Capital Management, LLC
> and/or its affiliates. If you are not the intended recipient of this
> e-mail, or if you have otherwise received this e-mail in error, please
> immediately notify me by telephone (you may call collect), or by e-mail,
> and please permanently delete the original, any print outs and any
> copies of the foregoing. Any dissemination, distribution or copying of
> this e-mail is strictly prohibited.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From deepayan at stat.wisc.edu  Tue Jan 11 00:11:27 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue Jan 11 00:09:30 2005
Subject: [Rd] segfault (with non-standard use of x11/par(ask=T))
Message-ID: <200501101711.27616.deepayan@stat.wisc.edu>


On r-devel, I'm getting a segmentation fault from an admittedly strange 
sequence of events:

(on a fresh session)

> x11()
> x11()
> par(ask = T)
> plot(1)
Hit <Return> to see next plot:

<at this point, instead of hitting Return, kill 
the second X11 window (using the mouse, for example), 
THEN hit Return.>

Segmentation fault

> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status   Under development (unstable)
major    2
minor    1.0
year     2005
month    01
day      10
language R

This doesn't happen in R 2.0.1, but has been there in r-devel for a 
while now.

Deepayan

From giles.heywood at cantab.net  Tue Jan 11 11:39:10 2005
From: giles.heywood at cantab.net (Giles Heywood)
Date: Tue Jan 11 11:39:12 2005
Subject: [Rd] S4 class no longer accepts matrix in array slot under 2.0.1
In-Reply-To: <41E2FD45.20404@R-project.org>
Message-ID: <KLEHJMEACMGEMBOOPFCAKEKPCAAA.giles.heywood@cantab.net>

I see - clearly I had confused the extended superclass with a slot.  I'm not
sure that this correction to my thinking moves me closer to my objective,
however (i.e. extending array and allowing 2D array, as was allowed in
1.9.1).

In such a situation I return to the documentation and examples.  I have a
further question about documentation.  The Green Book, valuable and
frequently cited as it is, is now in many ways increasingly difficult to
relate to R, except at a somewhat abstract level (I fully understand that R
is a separate implementation of the S language etc).  I also have found
Venables and Ripley ch5 most helpful.  Is there in existence documentation
which provides an overview of the methods package as it now stands, rather
like an updated Green Book?  Or are there specific packages or example
packages which illustrate most of, or much of, the functionality (I have
found SparseM useful in this way)?

TIA

Giles


> -----Original Message-----
> From: John Chambers [mailto:jmc@R-project.org]
> Sent: 10 January 2005 22:10
> To: Giles Heywood
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] S4 class no longer accepts matrix in array slot under
> 2.0.1
>
>
> Your example and your subject heading are two different things.  If you
> meant the subject heading, that in fact works.
>
> R> setClass("a1", representation(x="array"))
> [1] "a1"
> R> new("a1", x=matrix(1:12,3,4))
> An object of class "a1"
> Slot "x":
>       [,1] [,2] [,3] [,4]
> [1,]    1    4    7   10
> [2,]    2    5    8   11
> [3,]    3    6    9   12
>
> That's not what your example does.  In your example, the new class
> extends "array", rather than using it as a slot.  It would have been
> clearer if you had said setClass("foo", contains="array"), but your code
> is correct for that purpose.
>
> On first examination, I believe the problem is just what the message
> says it is.  You gave as a new object (and NOT as a slot) an object from
> a subclass of a superclass of "foo".  This is allowed, but has to be
> done by replacing the part of a "foo" object corresponding to the
> "array" contained in a "matrix" object.  Of course, we know that's
> actually the whole object, but nothing has told the software this.  And,
> indeed, it doesn't find the necessary replacement method.
>
> Here's an example similar to what you are doing, but using actual
> classes.  Barring screwups on my part, it shows that the mechanism works
> as asserted.  Classes "c1", "c2", "c3" follow the roles of "array",
> "matrix", and "foo" in your example.
> R> setClass("c1", representation(x="numeric"))
> [1] "c1"
> R> setClass("c2", contains="c1")
> [1] "c2"
> R> setClass("c3", contains = "c1")
> [1] "c3"
> R> x2 = new("c2", x=1)
> R> x3 = new("c3", x2)
> R> x3
> An object of class "c3"
> Slot "x":
> [1] 1
>
> Classes "matrix" and "array" are rather peculiar in R; among other
> things, they act like vector data types in that is.object() is FALSE.
> And you cannot have an "array" with a dimension of length 2.
>
> R> class(array(1:12, dim=c(3,4)))
> [1] "matrix"
>
> Also, because they don't have a consistent set of "slots" (they may or
> may not have a "dimnames), they aren't quite real classes in an S4
> sense.  It would be nice to fix this mess, but not obviously possible
> while being back compatible.
>
> It's possible that there is a fix to get around the particular error
> here, without breaking the more general pattern--I'll take a look.
>
> Otherwise, you may need to follow the approach of your subject heading,
> and define a new class with an array as a slot.
>
> Giles Heywood wrote:
>
> > I have an S4 class with a slot of class "array", and in
> upgrading to 2.0.1
> > (from 1.9.1) I have encountered a change in behaviour. This
> causes me some
> > difficulties if I want to allow 2-dimensional arrays in the slot.
> >
> > The following (in 2.0.1) illustrates the point:
> >
> >
> >>setClass("foo",representation("array"))
> >
> > [1] "foo"
> >
> >>a <- new("foo",array(NA,2:4))
> >>b <- new("foo",matrix(NA,2,3))
> >
> > Error in "as<-"(`*tmp*`, Classi, value = c(NA, NA, NA, NA, NA, NA)) :
> >         No method or default for as() replacement of "foo" with
> > Class="matrix"
> >
> > This last error did not occur under 1.9.1.
> >
> > I conclude that in this context the methods package does not recognise
> > "matrix" as a subclass of "array". However if I use getClass(),
> I see that R
> > recognises "matrix" as a subclass of "array" (and vice-versa).
> So is this
> > new behaviour correct?
>
> You conclude incorrectly, as noted above.
> >
> > [this is a re-posting to R-devel of a question earlier posted to R-help,
> > which attracted limited response]
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >

From wolski at molgen.mpg.de  Tue Jan 11 13:04:00 2005
From: wolski at molgen.mpg.de (Witold Eryk Wolski)
Date: Tue Jan 11 13:04:12 2005
Subject: [Rd] S4 class no longer accepts matrix in array slot under 2.0.1
In-Reply-To: <KLEHJMEACMGEMBOOPFCAKEKPCAAA.giles.heywood@cantab.net>
References: <KLEHJMEACMGEMBOOPFCAKEKPCAAA.giles.heywood@cantab.net>
Message-ID: <41E3C0B0.40105@molgen.mpg.de>

Giles Heywood wrote:

>I see - clearly I had confused the extended superclass with a slot.  I'm not
>sure that this correction to my thinking moves me closer to my objective,
>however (i.e. extending array and allowing 2D array, as was allowed in
>1.9.1).
>
>In such a situation I return to the documentation and examples.  I have a
>further question about documentation.  The Green Book, valuable and
>frequently cited as it is, is now in many ways increasingly difficult to
>relate to R, except at a somewhat abstract level (I fully understand that R
>is a separate implementation of the S language etc).  I also have found
>Venables and Ripley ch5 most helpful.  Is there in existence documentation
>which provides an overview of the methods package as it now stands, rather
>like an updated Green Book?  Or are there specific packages or example
>packages which illustrate most of, or much of, the functionality (I have
>found SparseM useful in this way)?
>
>TIA
>
>Giles
>
>
>  
>
>>-----Original Message-----
>>From: John Chambers [mailto:jmc@R-project.org]
>>Sent: 10 January 2005 22:10
>>To: Giles Heywood
>>Cc: r-devel@stat.math.ethz.ch
>>Subject: Re: [Rd] S4 class no longer accepts matrix in array slot under
>>2.0.1
>>
>>
>>Your example and your subject heading are two different things.  If you
>>meant the subject heading, that in fact works.
>>
>>R> setClass("a1", representation(x="array"))
>>[1] "a1"
>>R> new("a1", x=matrix(1:12,3,4))
>>An object of class "a1"
>>Slot "x":
>>      [,1] [,2] [,3] [,4]
>>[1,]    1    4    7   10
>>[2,]    2    5    8   11
>>[3,]    3    6    9   12
>>
>>That's not what your example does.  In your example, the new class
>>extends "array", rather than using it as a slot.  It would have been
>>clearer if you had said setClass("foo", contains="array"), but your code
>>is correct for that purpose.
>>
>>On first examination, I believe the problem is just what the message
>>says it is.  You gave as a new object (and NOT as a slot) an object from
>>a subclass of a superclass of "foo".  This is allowed, but has to be
>>done by replacing the part of a "foo" object corresponding to the
>>"array" contained in a "matrix" object.  Of course, we know that's
>>actually the whole object, but nothing has told the software this.  And,
>>indeed, it doesn't find the necessary replacement method.
>>
>>Here's an example similar to what you are doing, but using actual
>>classes.  Barring screwups on my part, it shows that the mechanism works
>>as asserted.  Classes "c1", "c2", "c3" follow the roles of "array",
>>"matrix", and "foo" in your example.
>>R> setClass("c1", representation(x="numeric"))
>>[1] "c1"
>>R> setClass("c2", contains="c1")
>>[1] "c2"
>>R> setClass("c3", contains = "c1")
>>[1] "c3"
>>R> x2 = new("c2", x=1)
>>R> x3 = new("c3", x2)
>>R> x3
>>An object of class "c3"
>>Slot "x":
>>[1] 1
>>
>>Classes "matrix" and "array" are rather peculiar in R; among other
>>things, they act like vector data types in that is.object() is FALSE.
>>And you cannot have an "array" with a dimension of length 2.
>>
>>R> class(array(1:12, dim=c(3,4)))
>>[1] "matrix"
>>
>>Also, because they don't have a consistent set of "slots" (they may or
>>may not have a "dimnames), they aren't quite real classes in an S4
>>sense.  It would be nice to fix this mess, but not obviously possible
>>while being back compatible.
>>
>>It's possible that there is a fix to get around the particular error
>>here, without breaking the more general pattern--I'll take a look.
>>
>>Otherwise, you may need to follow the approach of your subject heading,
>>and define a new class with an array as a slot.
>>
>>Giles Heywood wrote:
>>
>>    
>>
>>>I have an S4 class with a slot of class "array", and in
>>>      
>>>
>>upgrading to 2.0.1
>>    
>>
>>>(from 1.9.1) I have encountered a change in behaviour. This
>>>      
>>>
>>causes me some
>>    
>>
>>>difficulties if I want to allow 2-dimensional arrays in the slot.
>>>
>>>The following (in 2.0.1) illustrates the point:
>>>
>>>
>>>      
>>>
>>>>setClass("foo",representation("array"))
>>>>        
>>>>
>>>[1] "foo"
>>>
>>>      
>>>
>>>>a <- new("foo",array(NA,2:4))
>>>>b <- new("foo",matrix(NA,2,3))
>>>>        
>>>>
>>>Error in "as<-"(`*tmp*`, Classi, value = c(NA, NA, NA, NA, NA, NA)) :
>>>        No method or default for as() replacement of "foo" with
>>>Class="matrix"
>>>
>>>This last error did not occur under 1.9.1.
>>>
>>>I conclude that in this context the methods package does not recognise
>>>"matrix" as a subclass of "array". However if I use getClass(),
>>>      
>>>
>>I see that R
>>    
>>
>>>recognises "matrix" as a subclass of "array" (and vice-versa).
>>>      
>>>
>>So is this
>>    
>>
>>>new behaviour correct?
>>>      
>>>
>>You conclude incorrectly, as noted above.
>>    
>>
>>>[this is a re-posting to R-devel of a question earlier posted to R-help,
>>>which attracted limited response]
>>>
>>>______________________________________________
>>>R-devel@stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>      
>>>
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>
>  
>
Hi,

You will find some info material about S4 at the www.bioconductor.org page.
There is also a tutorial by R. Gentleman about S4 at:
http://www.stat.auckland.ac.nz/S-Workshop/

I have started to write a mansucript about inheritance in S4.
You can find it at.

http://www.molgen.mpg.de/~wolski/Robject/Extending.pdf
http://www.molgen.mpg.de/~wolski/Robject/Extending.Rnw

Eryk

Ps. If you find the Extending.Rnw file usefull and find any erros would 
you be so kind to edit the file and send it back to me?


-- 
Dipl. bio-chem. Witold Eryk Wolski
MPI-Moleculare Genetic
Ihnestrasse 63-73 14195 Berlin
tel: 0049-30-83875219                 __("<    _
http://www.molgen.mpg.de/~wolski      \__/    'v'
http://r4proteomics.sourceforge.net    ||    /   \
mail: witek96@users.sourceforge.net    ^^     m m
      wolski@molgen.mpg.de

From david at elseware.nl  Wed Jan 12 00:44:46 2005
From: david at elseware.nl (David A. van Leeuwen)
Date: Wed Jan 12 08:44:23 2005
Subject: [Rd] R as unix filter
Message-ID: <41E464EE.60509@elseware.nl>

R-devel,

R is great, and in fact so great that I have whished to use it as a 
proper Unix filter ever since I started using it.  Just like octave, 
perl, bash, etc.

Even though I could only find one message in the R-mailing lists, I 
can't imagine nobody else would want to be able to say on a nice bash 
command line:

$ cat data-file | some-process | R-script | another-process > file.out

specifically for (live generated, multiple) large data files and 
complicated calculations in the R-script.

So I wrote a set of wrapper scripts/programs.  From the terse README:

---

`Rf' allows unix script programmers to use the statistics program `R'
as a proper unix filter.  `R' is IMHO a great program, which can do
much more than only statistics, for instance, it has great graphics
output. 

A big disadvantage is, however, that it seems inherently an
interactive program, and can therefor not be used as a proper unix
filter.  More specifically, it cannot read data from stdin.  It wants
the script input in stdin.

In order to circumvent this problem, the Rf package comes with two
utilities:

r-as-filter: a (bash) script doing most of the work
Rf: a c-wrapper script that calls r-as-filter in a `sh-bang' context.

Basically, Rf allows you to write a little sh-bang script (included in
this distribution as file `mean'):

===start of file====
#!/usr/local/bin/Rf

x <- scan(.stdin, quiet=T)
cat (mean(x))

===end of file===

This example script reads number in from stdin (the R character
variable `.stdin') and prints the average on standard out.  Thus, one
could say on the command line:

$ seq 10 | mean

and the average of the numbers 1 through 10 will be calculated (5.5). 

---

The very first version of the package can be found at

    http://speech.tm.tno.nl/r/rf-0.1.tar.gz

Of course, It would be a lot better if somehow R could include this 
functionality itself.  But what do you think of this?

---david

From terra at gnome.org  Tue Jan 11 19:57:45 2005
From: terra at gnome.org (terra@gnome.org)
Date: Wed Jan 12 08:56:23 2005
Subject: [Rd] pgamma discontinuity (PR#7307)
Message-ID: <20050111185745.AD412106A0@slim.kubism.ku.dk>


FYI,

this version of pgamma appears to be quite good and certainly a vast
improvement over current R code.  (I last looked at 2.0.1)  Apart from
type naming, this is what I have been using for Gnumeric 1.4.1.

This could be included into R as-is, but you might want to benefit from
making logcf, log1pmx, lgamma1p, and possibly logspace_add/logspace_sub
available to other parts of R.

Comments welcome.

Morten




#ifndef GNUMERIC_VERSION
/* Gnumeric already has these.  */

#define SQR(x) ((x)*(x))
static const double scalefactor = SQR(SQR(SQR(4294967296.0)));
#undef SQR

static double
logcf (double x, double i, double d)
{
	double c1 = 2 * d;
	double c2 = i + d;
	double c4 = c2 + d;
	double a1 = c2;
	double b1 = i * (c2 - i * x);
	double b2 = d * d * x;
	double a2 = c4 * c2 - b2;
	const double cfVSmall = 1.0e-14;

#if 0
	assert (i > 0);
	assert (d >= 0);
#endif

	b2 = c4 * b1 - i * b2;

	while (fabs (a2 * b1 - a1 * b2) > fabs (cfVSmall * b1 * b2)) {
		double c3 = c2*c2*x;
		c2 += d;
		c4 += d;
		a1 = c4 * a2 - c3 * a1;
		b1 = c4 * b2 - c3 * b1;

		c3 = c1 * c1 * x;
		c1 += d;
		c4 += d;
		a2 = c4 * a1 - c3 * a2;
		b2 = c4 * b1 - c3 * b2;

		if (fabs (b2) > scalefactor) {
			a1 *= 1 / scalefactor;
			b1 *= 1 / scalefactor;
			a2 *= 1 / scalefactor;
			b2 *= 1 / scalefactor;
		} else if (fabs (b2) < 1 / scalefactor) {
			a1 *= scalefactor;
			b1 *= scalefactor;
			a2 *= scalefactor;
			b2 *= scalefactor;
		}
	}

	return a2 / b2;
}

/* Accurate calculation of log(1+x)-x, particularly for small x.  */
static double
log1pmx (double x)
{
	static const double minLog1Value = -0.79149064;
	static const double two = 2;

	if (fabs (x) < 1.0e-2) {
		double term = x / (2 + x);
		double y = term * term;
		return term * ((((two / 9 * y + two / 7) * y + two / 5) * y + two / 3) * y - x);
	} else if (x < minLog1Value || x > 1) {
		return log1p (x) - x;
	} else {
		double term = x / (2 + x);
		double y = term * term;
		return term * (2 * y * logcf (y, 3, 2) - x);
	}
}


/* Calculates log(gamma(a+1) accurately for for small a (0 < a & a < 0.5). */
static double
lgamma1p (double a)
{
     const double eulers_const =  0.5772156649015328606065120900824024;

     /* coeffs[i] holds (zeta(i+2)-1)/(i+2)  */
     static const double coeffs[40] = {
	  0.3224670334241132182362075833230126e-0,
	  0.6735230105319809513324605383715000e-1,
	  0.2058080842778454787900092413529198e-1,
	  0.7385551028673985266273097291406834e-2,
	  0.2890510330741523285752988298486755e-2,
	  0.1192753911703260977113935692828109e-2,
	  0.5096695247430424223356548135815582e-3,
	  0.2231547584535793797614188036013401e-3,
	  0.9945751278180853371459589003190170e-4,
	  0.4492623673813314170020750240635786e-4,
	  0.2050721277567069155316650397830591e-4,
	  0.9439488275268395903987425104415055e-5,
	  0.4374866789907487804181793223952411e-5,
	  0.2039215753801366236781900709670839e-5,
	  0.9551412130407419832857179772951265e-6,
	  0.4492469198764566043294290331193655e-6,
	  0.2120718480555466586923135901077628e-6,
	  0.1004322482396809960872083050053344e-6,
	  0.4769810169363980565760193417246730e-7,
	  0.2271109460894316491031998116062124e-7,
	  0.1083865921489695409107491757968159e-7,
	  0.5183475041970046655121248647057669e-8,
	  0.2483674543802478317185008663991718e-8,
	  0.1192140140586091207442548202774640e-8,
	  0.5731367241678862013330194857961011e-9,
	  0.2759522885124233145178149692816341e-9,
	  0.1330476437424448948149715720858008e-9,
	  0.6422964563838100022082448087644648e-10,
	  0.3104424774732227276239215783404066e-10,
	  0.1502138408075414217093301048780668e-10,
	  0.7275974480239079662504549924814047e-11,
	  0.3527742476575915083615072228655483e-11,
	  0.1711991790559617908601084114443031e-11,
	  0.8315385841420284819798357793954418e-12,
	  0.4042200525289440065536008957032895e-12,
	  0.1966475631096616490411045679010286e-12,
	  0.9573630387838555763782200936508615e-13,
	  0.4664076026428374224576492565974577e-13,
	  0.2273736960065972320633279596737272e-13,
	  0.1109139947083452201658320007192334e-13
     };
     const int N = sizeof (coeffs) / sizeof (coeffs[0]);

     const double c =  0.2273736845824652515226821577978691e-12;  /* zeta(N+2)-1 */
     double lgam;
     int i;

     if (fabs (a) >= 0.5)
	  return lgammafn (a + 1);

     /* Abramowitz & Stegun 6.1.33 */
     /* http://functions.wolfram.com/06.11.06.0008.01 */
     lgam = c * logcf (-a / 2, N + 2, 1);
     for (i = N - 1; i >= 0; i--)
	  lgam = coeffs[i] - a * lgam;

     return (a * lgam - eulers_const) * a - log1pmx (a);
}

#endif /* GNUMERIC_VERSION */


/*
 * Compute the log of a sum from logs of terms, i.e.,
 *
 *     log (exp (logx) + exp (logy))
 *
 * without causing overflows and without throwing away large handfuls
 * of accuracy.
 */
static double
logspace_add (double logx, double logy)
{
     return fmax2 (logx, logy) + log1p (exp (-fabs (logx - logy)));
}


/*
 * Compute the log of a difference from logs of terms, i.e.,
 *
 *     log (exp (logx) - exp (logy))
 *
 * without causing overflows and without throwing away large handfuls
 * of accuracy.
 */
static double
logspace_sub (double logx, double logy)
{
     return logx + log1p (-exp (logy - logx));
}


static double
dpois_wrap (double x_plus_1, double lambda, int give_log)
{
#if 0
     printf ("x+1=%.14g  lambda=%.14g\n", x_plus_1, lambda);
#endif

     if (x_plus_1 > 1)
	  return dpois_raw (x_plus_1 - 1, lambda, give_log);
     else {
 	  double d = dpois_raw (x_plus_1, lambda, give_log);
	  return give_log
	       ? d + log (x_plus_1 / lambda)
	       : d * (x_plus_1 / lambda);
     }
}

/*
 * Abramowitz and Stegun 6.5.29 [right]
 */
static double
pgamma_smallx (double x, double alph, int lower_tail, int log_p)
{
     double sum = 0, c = alph, n = 0, term;

#if 0
     printf ("x:%.14g  alph:%.14g\n", x, alph);
#endif

     /*
      * Relative to 6.5.29 all terms have been multiplied by alph
      * and the first, thus being 1, is omitted.
      */

     do {
	  n++;
	  c *= -x / n;
	  term = c / (alph + n);
	  sum += term;
     } while (fabs (term) > DBL_EPSILON * fabs (sum));

     if (lower_tail) {
	  double f1 = log_p ? log1p (sum) : 1 + sum;
	  double f2;
	  if (alph > 1) {
	       f2 = dpois_raw (alph, x, log_p);
	       f2 = log_p ? f2 + x : f2 * exp (x);
	  } else if (log_p)
	       f2 = alph * log (x) - lgamma1p (alph);
	  else
	       f2 = pow (x, alph) / exp (lgamma1p (alph));

	  return log_p ? f1 + f2 : f1 * f2;
     } else {
	  double lf2 = alph * log (x) - lgamma1p (alph);
#if 0
	  printf ("1:%.14g  2:%.14g\n", alph * log (x), lgamma1p (alph));
	  printf ("sum=%.14g  log(1+sum)=%.14g  lf2=%.14g\n", sum, log1p (sum), lf2);
#endif
	  if (log_p)
	       return R_Log1_Exp (log1p (sum) + lf2);
	  else {
	       double f1m1 = sum;
	       double f2m1 = expm1 (lf2);
	       return -(f1m1 + f2m1 + f1m1 * f2m1);
	  }
     }
}

static double
pd_upper_series (double x, double y, int log_p)
{
     double term = x / y;
     double sum = term;

     do {
	  y++;
	  term *= x / y;
	  sum += term;
     } while (term > sum * DBL_EPSILON);

     return log_p ? log (sum) : sum;
}

static double
pd_lower_cf (double i, double d)
{
     double f = 0, of;

     double a1 = 0;
     double b1 = 1;
     double a2 = i;
     double b2 = d;
     double c1 = 0;
     double c2 = a2;
     double c3;
     double c4 = b2;

     while (1) {
	  c1++;
	  c2--;
	  c3 = c1 * c2;
	  c4 += 2;
	  a1 = c4 * a2 + c3 * a1;
	  b1 = c4 * b2 + c3 * b1;

	  c1++;
	  c2--;
	  c3 = c1 * c2;
	  c4 += 2;
	  a2 = c4 * a1 + c3 * a2;
	  b2 = c4 * b1 + c3 * b2;

	  if (b2 > scalefactor) {
	       a1 = a1 / scalefactor;
	       b1 = b1 / scalefactor;
	       a2 = a2 / scalefactor;
	       b2 = b2 / scalefactor;
	  }

	  if (b2 != 0) {
	       of = f;
	       f = a2 / b2;
	       if (fabs (f - of) <= DBL_EPSILON * fmin2 (1.0, fabs (f)))
		    return f;
	  }
     }
}

static double
pd_lower_series (double lambda, double y)
{
     double term = 1, sum = 0;

     while (y >= 1 && term > sum * DBL_EPSILON) {
	  term *= y / lambda;
	  sum += term;
	  y--;
     }

     if (y != floor (y)) {
	  /*
	   * The series does not converge as the terms start getting
	   * bigger (besides flipping sign) for y < -lambda.
	   */
	  double f = pd_lower_cf (y, lambda + 1 - y);
	  sum += term * f;
     }

     return sum;
}

/*
 * Asymptotic expansion to calculate the probability that poisson variate
 * has value <= x.
 */
static double
ppois_asymp (double x, double lambda,
	     int lower_tail, int log_p)
{
     static const double coef15 = 1/12.0;
     static const double coef25 = 1/288.0;
     static const double coef35 = -139/51840.0;
     static const double coef45 = -571/2488320.0;
     static const double coef55 = 163879/209018880.0;
     static const double coef65 =  5246819/75246796800.0;
     static const double coef75 = -534703531/902961561600.0;
     static const double coef1 = 2/3.0;
     static const double coef2 = -4/135.0;
     static const double coef3 = 8/2835.0;
     static const double coef4 = 16/8505.0;
     static const double coef5 = -8992/12629925.0;
     static const double coef6 = -334144/492567075.0;
     static const double coef7 = 698752/1477701225.0;
     static const double two = 2;

     double dfm, pt,s2pt,res1,res2,elfb,term;
     double ig2,ig3,ig4,ig5,ig6,ig7,ig25,ig35,ig45,ig55,ig65,ig75;
     double f, np, nd;

     dfm = lambda - x;
     pt = -x * log1pmx (dfm / x);
     s2pt = sqrt (2 * pt);
     if (dfm < 0) s2pt = -s2pt;

     ig2 = 1.0 + pt;
     term = pt * pt * 0.5;
     ig3 = ig2 + term;
     term *= pt / 3;
     ig4 = ig3 + term;
     term *= pt / 4;
     ig5 = ig4 + term;
     term *= pt / 5;
     ig6 = ig5 + term;
     term *= pt / 6;
     ig7 = ig6 + term;

     term = pt * (two / 3);
     ig25 = 1.0 + term;
     term *= pt * (two / 5);
     ig35 = ig25 + term;
     term *= pt * (two / 7);
     ig45 = ig35 + term;
     term *= pt * (two / 9);
     ig55 = ig45 + term;
     term *= pt * (two / 11);
     ig65 = ig55 + term;
     term *= pt * (two / 13);
     ig75 = ig65 + term;

     elfb = ((((((coef75/x + coef65)/x + coef55)/x + coef45)/x + coef35)/x + coef25)/x + coef15) + x;
     res1 = ((((((ig7*coef7/x + ig6*coef6)/x + ig5*coef5)/x + ig4*coef4)/x + ig3*coef3)/x + ig2*coef2)/x + coef1)*sqrt(x);
     res2 = ((((((ig75*coef75/x + ig65*coef65)/x + ig55*coef55)/x + ig45*coef45)/x + ig35*coef35)/x + ig25*coef25)/x + coef15)*s2pt;

     if (!lower_tail) elfb = -elfb;
     f = (res1 + res2) / elfb;

     np = pnorm (s2pt, 0.0, 1.0, !lower_tail, log_p);
     nd = dnorm (s2pt, 0.0, 1.0, log_p);

#if 0
     printf ("f=%.14g  np=%.14g  nd=%.14g  f*nd=%.14g\n", f, np, nd, f * nd);
#endif

     if (log_p)
	  return (f >= 0)
	       ? logspace_add (np, log (fabs (f)) + nd)
	       : logspace_sub (np, log (fabs (f)) + nd);
     else
	  return np + f * nd;
}


static double
pgamma_raw (double x, double alph, int lower_tail, int log_p)
{
     double res;

#if 0
     printf ("x=%.14g  alph=%.14g  low=%d  log=%d\n", x, alph, lower_tail, log_p);
#endif

     if (x < 1) {
	  res = pgamma_smallx (x, alph, lower_tail, log_p);
     } else if (x <= alph - 1 && x < 0.8 * (alph + 50)) {
	  double sum = pd_upper_series (x, alph, log_p);
	  double d = dpois_wrap (alph, x, log_p);

	  if (!lower_tail)
	       res = log_p
		    ? R_Log1_Exp (d + sum)
		    : 1 - d * sum;
	  else
	       res = log_p ? sum + d : sum * d;
     } else if (alph - 1 < x && alph < 0.8 * (x + 50)) {
	  double sum;
	  double d = dpois_wrap (alph, x, log_p);

	  if (alph < 1) {
	       double f = pd_lower_cf (alph, x - (alph - 1))
		    * x / alph;
	       sum = log_p ? log (f) : f;
	  } else {
	       sum = pd_lower_series (x, alph - 1);
	       sum = log_p ? log1p (sum) : 1 + sum;
	  }

	  if (!lower_tail)
	       res = log_p ? sum + d : sum * d;
	  else
	       res = log_p
		    ? R_Log1_Exp (d + sum)
		    : 1 - d * sum;
     } else {
	  res = ppois_asymp (alph - 1, x, !lower_tail, log_p);
     }

     /*
      * We lose a fair amount of accuracy to underflow in the cases
      * where the final result is very close to DBL_MIN.  In those
      * cases, simply redo via log space.
      */
     if (!log_p && res < DBL_MIN / DBL_EPSILON)
	  return exp (pgamma_raw (x, alph, lower_tail, 1));
     else
	  return res;
}


double pgamma(double x, double alph, double scale, int lower_tail, int log_p)
{
#ifdef IEEE_754
     if (ISNAN(x) || ISNAN(alph) || ISNAN(scale))
	  return x + alph + scale;
#endif
     if(alph <= 0. || scale <= 0.)
	  ML_ERR_return_NAN;
     if (x <= 0.)
	  return R_DT_0;
     x /= scale;
#ifdef IEEE_754
     if (ISNAN(x)) /* eg. original x = scale = +Inf */
	  return x;
#endif

     return pgamma_raw (x, alph, lower_tail, log_p);
}

From Robert.McGehee at geodecapital.com  Wed Jan 12 09:05:28 2005
From: Robert.McGehee at geodecapital.com (Robert.McGehee@geodecapital.com)
Date: Wed Jan 12 09:05:39 2005
Subject: [Rd] Function Body / Formals Bug (PR#7495)
Message-ID: <20050112080528.00085EABA@slim.kubism.ku.dk>

I'd like to report two bugs in the R function definitions, the first
slightly problematic, the second likely unimportant. Both of these are
reproducible on both Windows and Linux, R 2.0.1

First Bug:
> a <- new("function")
> formals(a) <- alist(a=, b=, c=, d=)
> a
function (a, b, c) ## the d argument disappeared!
> formals(a) <- alist(a=, b=, c=, d=)
> a
function (a, b, c, d) ## the d argument reappeared!

As you can see from above, the d= argument got chopped off completely
the first time "formals<-"() is called, but not the second! There must
be something funny going on with "formals<-"() when a function is first
initialized. I've also found a similar bug in which I try to assign a S4
object to the body of new function. It gives an error the first time,
with 

Error in as.function.default(x, envir) : argument must have length at
least 1

but if the same "body<-"() call runs again, the assignment runs without
error (still no assignment takes place). (I'll produce this S4 object
upon request, although I imagine these two errors are related). 

-----------------------------------------
Second Bug:
As I try to do more and more bizarre things on the R language, I came
across an incident where I (unintentionally) attempted to assign a
function to the body of another function. While I should expect to get
errors when I write meaningless things, I received the following error:

> a <- function() x
> body(a) <- function() y
Error in as.function.default(c(formals(fun), value), envir) : 
	invalid body argument for "function"
Should NEVER happen; please bug.report() [mkCLOSXP]

And as I've never been explicitly told by R to report a bug before, I
thought I'd comply, in case there are any wider ramifications to this
example above. If not, then I'm sure this second bug can be safely
ignored, as no one should be doing such things anyway.

Best,
Robert

Robert McGehee
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee@geodecapital.com



This e-mail, and any attachments hereto, are intended for use by the
addressee(s) only and may contain information that is (i) confidential
information of Geode Capital Management, LLC and/or its affiliates,
and/or (ii) proprietary information of Geode Capital Management, LLC
and/or its affiliates. If you are not the intended recipient of this
e-mail, or if you have otherwise received this e-mail in error, please
immediately notify me by telephone (you may call collect), or by e-mail,
and please permanently delete the original, any print outs and any
copies of the foregoing. Any dissemination, distribution or copying of
this e-mail is strictly prohibited.

From marc at intershop.de  Wed Jan 12 11:50:50 2005
From: marc at intershop.de (marc@intershop.de)
Date: Wed Jan 12 11:50:53 2005
Subject: [Rd] mydataframe$colname: using substring of colname may also match
	some column (PR#7496)
Message-ID: <20050112105050.788FBFB8F@slim.kubism.ku.dk>

Full_Name: Marc Mamin
Version: 1.8, 2.0.0
OS: Windows & Linux
Submission from: (NULL) (217.17.202.254)


Using only the beginning of a column name will match it:

>aaa<-1
>df<-as.data.frame(aaa)
>names(df)
[1] "aaa"

>df$a   
[1] 1 !!!!!!!!! (I expect df$a to be undefind)

>df$x
>NULL

Compare with:

> df["aaa"]
  aaa
1   1

> df["a"]
Error in "[.data.frame"(df, "a") : undefined columns selected


Here another example that underline how problematic this issue can be:

aa1<-1
aa2<-2
df<-as.data.frame(aa1,aa2)
> df$aa
[1] 1   (only the first matching column is retrieved)

From ripley at stats.ox.ac.uk  Wed Jan 12 12:00:08 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 12 12:00:12 2005
Subject: [Rd] mydataframe$colname: using substring of colname may also
	(PR#7497)
Message-ID: <20050112110008.A43BF10446@slim.kubism.ku.dk>

That is the documented behaviour, not a bug!

BTW, df is the F density function.

If you want an exact match, use  df[match("aa", names(df))]

On Wed, 12 Jan 2005 marc@intershop.de wrote:

> Full_Name: Marc Mamin
> Version: 1.8, 2.0.0
> OS: Windows & Linux
> Submission from: (NULL) (217.17.202.254)
>
>
> Using only the beginning of a column name will match it:
>
>> aaa<-1
>> df<-as.data.frame(aaa)
>> names(df)
> [1] "aaa"
>
>> df$a
> [1] 1 !!!!!!!!! (I expect df$a to be undefind)

Where did you read that?

>> df$x
>> NULL
>
> Compare with:
>
>> df["aaa"]
>  aaa
> 1   1
>
>> df["a"]
> Error in "[.data.frame"(df, "a") : undefined columns selected
>
>
> Here another example that underline how problematic this issue can be:
>
> aa1<-1
> aa2<-2
> df<-as.data.frame(aa1,aa2)
>> df$aa
> [1] 1   (only the first matching column is retrieved)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Jan 12 12:00:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jan 12 12:00:14 2005
Subject: [Rd] mydataframe$colname: using substring of colname may also
	match some column (PR#7496)
In-Reply-To: <20050112105050.788FBFB8F@slim.kubism.ku.dk>
References: <20050112105050.788FBFB8F@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0501121055050.20037@gannet.stats>

That is the documented behaviour, not a bug!

BTW, df is the F density function.

If you want an exact match, use  df[match("aa", names(df))]

On Wed, 12 Jan 2005 marc@intershop.de wrote:

> Full_Name: Marc Mamin
> Version: 1.8, 2.0.0
> OS: Windows & Linux
> Submission from: (NULL) (217.17.202.254)
>
>
> Using only the beginning of a column name will match it:
>
>> aaa<-1
>> df<-as.data.frame(aaa)
>> names(df)
> [1] "aaa"
>
>> df$a
> [1] 1 !!!!!!!!! (I expect df$a to be undefind)

Where did you read that?

>> df$x
>> NULL
>
> Compare with:
>
>> df["aaa"]
>  aaa
> 1   1
>
>> df["a"]
> Error in "[.data.frame"(df, "a") : undefined columns selected
>
>
> Here another example that underline how problematic this issue can be:
>
> aa1<-1
> aa2<-2
> df<-as.data.frame(aa1,aa2)
>> df$aa
> [1] 1   (only the first matching column is retrieved)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From S.J.Eglen at damtp.cam.ac.uk  Wed Jan 12 13:21:27 2005
From: S.J.Eglen at damtp.cam.ac.uk (Stephen Eglen)
Date: Wed Jan 12 13:21:32 2005
Subject: [Rd] typo in help prcomp
Message-ID: <16869.5703.223879.628358@notch.amtp.cam.ac.uk>

in R 2.0.1, the help page for `prcomp' says:

     'prcomp' returns an list

AN ahould be A.

Stephen

From tlumley at u.washington.edu  Wed Jan 12 16:23:50 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Jan 12 16:24:02 2005
Subject: [Rd] DSC 2005
In-Reply-To: <1105538780.14753.8.camel@horizons.localdomain>
References: <8B08A3A1EA7AAC41BE24C750338754E61505EB@HERMES.demogr.mpg.de>
	<1105538780.14753.8.camel@horizons.localdomain>
Message-ID: <Pine.A41.4.61b.0501120716410.45670@homer05.u.washington.edu>


On Wed, 12 Jan 2005, Marc Schwartz wrote to r-help:
> I have not seen anything posted yet for DSC 2005, unless I missed it
> someplace.

DSC 2005 will be held in Seattle, at the University of Washington, August 
13-15.

This date is immediately after the Joint Statistical Meetings, and was 
chosen for the convenience of our European colleagues who might also be 
attending JSM.

A call for papers and more information will be posted Real Soon Now.

 	-thomas

From MSchwartz at MedAnalytics.com  Wed Jan 12 16:48:13 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed Jan 12 16:48:23 2005
Subject: [Rd] DSC 2005
In-Reply-To: <Pine.A41.4.61b.0501120716410.45670@homer05.u.washington.edu>
References: <8B08A3A1EA7AAC41BE24C750338754E61505EB@HERMES.demogr.mpg.de>
	<1105538780.14753.8.camel@horizons.localdomain>
	<Pine.A41.4.61b.0501120716410.45670@homer05.u.washington.edu>
Message-ID: <1105544893.14753.39.camel@horizons.localdomain>

On Wed, 2005-01-12 at 07:23 -0800, Thomas Lumley wrote:
> On Wed, 12 Jan 2005, Marc Schwartz wrote to r-help:
> > I have not seen anything posted yet for DSC 2005, unless I missed it
> > someplace.
> 
> DSC 2005 will be held in Seattle, at the University of Washington, August 
> 13-15.
> 
> This date is immediately after the Joint Statistical Meetings, and was 
> chosen for the convenience of our European colleagues who might also be 
> attending JSM.
> 
> A call for papers and more information will be posted Real Soon Now.

Thomas,

Thanks for that heads up. Andy Liaw sent me an off list e-mail
indicating that he thought the meeting was in Seattle. That was
consistent from what I recall of the discussion at useR! this year.

Of course, the JSMs are here in Minneapolis in August. The way that our
winter is going so far (we have yet to have an "official" one inch snow
fall), we might just have snow on the ground then...

;-)

Best regards,

Marc

From tplate at acm.org  Wed Jan 12 17:57:44 2005
From: tplate at acm.org (Tony Plate)
Date: Wed Jan 12 17:57:58 2005
Subject: [Rd] mydataframe$colname: using substring of colname may
	also match some column (PR#7496)
In-Reply-To: <20050112105050.788FBFB8F@slim.kubism.ku.dk>
References: <20050112105050.788FBFB8F@slim.kubism.ku.dk>
Message-ID: <6.2.0.14.2.20050112095404.05d35dc8@mailhost.blackmesacapital.com>

At Wednesday 03:50 AM 1/12/2005, marc@intershop.de wrote:
>Full_Name: Marc Mamin
>Version: 1.8, 2.0.0
>OS: Windows & Linux
>Submission from: (NULL) (217.17.202.254)
>
>[snipped issues previously responded to]
>
>Here another example that underline how problematic this issue can be:
>
>aa1<-1
>aa2<-2
>df<-as.data.frame(aa1,aa2)
> > df$aa
>[1] 1   (only the first matching column is retrieved)

Actually, the above commands constructed a data frame with one column (the 
second argument to 'as.data.frame' is 'row.names'):

 > aa1<-1
 > aa2<-2
 > df <- as.data.frame(aa1,aa2)
 > df
   aa1
2   1
 > dim(df)
[1] 1 1

When a data frame (or list) does have columns whose names have common 
prefixes, the behavior is as documented (NULL is returned):

 > df2 <- data.frame(aa1, aa2)
 > df2
   aa1 aa2
1   1   2
 > df2$aa
NULL
 >

From vstolin at lordabbett.com  Wed Jan 12 20:22:04 2005
From: vstolin at lordabbett.com (vstolin@lordabbett.com)
Date: Wed Jan 12 20:22:11 2005
Subject: [Rd] Inaccuracy in seq() function (PR#7503)
Message-ID: <20050112192204.2F840EAE1@slim.kubism.ku.dk>

Full_Name: Vlad Stolin
Version: R 2.0.0
OS: Windows 2000
Submission from: (NULL) (204.128.232.211)


When generating the sequence using seq() function with non-integer numbers
result is somewhat unpredictable. Example:
> v1<-seq(1.60,1.90,.05)
> v2<-c(1.60,1.65,1.70,1.75,1.80,1.85,1.90)
> v1-v2
[1] 0.000000e+00 2.220446e-16 2.220446e-16 0.000000e+00 0.000000e+00
0.000000e+00 2.220446e-16
> v1==v2
[1]  TRUE FALSE FALSE  TRUE  TRUE  TRUE FALSE
> v1>1.70 & v2<1.80
[1] FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE

From Robert.McGehee at geodecapital.com  Wed Jan 12 21:25:32 2005
From: Robert.McGehee at geodecapital.com (Robert.McGehee@geodecapital.com)
Date: Wed Jan 12 21:25:46 2005
Subject: [Rd] ?"=" (Windows) (PR#7504)
Message-ID: <20050112202532.F24A3EAE1@slim.kubism.ku.dk>

?"=", ?"==", ?"!=", ?">=", and ?"<=" sends me to the documentation for
?help on Windows, while returning the correct documentation on Linux.

Robert

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R              


Robert McGehee
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee@geodecapital.com



This e-mail, and any attachments hereto, are intended for use by the
addressee(s) only and may contain information that is (i) confidential
information of Geode Capital Management, LLC and/or its affiliates,
and/or (ii) proprietary information of Geode Capital Management, LLC
and/or its affiliates. If you are not the intended recipient of this
e-mail, or if you have otherwise received this e-mail in error, please
immediately notify me by telephone (you may call collect), or by e-mail,
and please permanently delete the original, any print outs and any
copies of the foregoing. Any dissemination, distribution or copying of
this e-mail is strictly prohibited.

From ripley at stats.ox.ac.uk  Wed Jan 12 21:40:26 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jan 12 21:40:36 2005
Subject: [Rd] Inaccuracy in seq() function (PR#7503)
In-Reply-To: <20050112192204.2F840EAE1@slim.kubism.ku.dk>
References: <20050112192204.2F840EAE1@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0501122037150.30627@gannet.stats>

And the bug is?

You don't expect 1.60 + 0.05 == 1.65 do you?  None of those numbers can be 
represented exactly in a binary computer, so there are bound to be small 
errors as you have noted.

See the warning in help("=="), and the section on BUGS in the FAQ.


On Wed, 12 Jan 2005 vstolin@lordabbett.com wrote:

> Full_Name: Vlad Stolin
> Version: R 2.0.0
> OS: Windows 2000
> Submission from: (NULL) (204.128.232.211)
>
>
> When generating the sequence using seq() function with non-integer numbers
> result is somewhat unpredictable. Example:
>> v1<-seq(1.60,1.90,.05)
>> v2<-c(1.60,1.65,1.70,1.75,1.80,1.85,1.90)
>> v1-v2
> [1] 0.000000e+00 2.220446e-16 2.220446e-16 0.000000e+00 0.000000e+00
> 0.000000e+00 2.220446e-16
>> v1==v2
> [1]  TRUE FALSE FALSE  TRUE  TRUE  TRUE FALSE
>> v1>1.70 & v2<1.80
> [1] FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From cberry at tajo.ucsd.edu  Wed Jan 12 21:54:10 2005
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed Jan 12 21:54:26 2005
Subject: [Rd] ?"=" (Windows) (PR#7504)
In-Reply-To: <20050112202532.F24A3EAE1@slim.kubism.ku.dk>
References: <20050112202532.F24A3EAE1@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0501121252080.19372@tajo.ucsd.edu>


works for me.

same version (i386-ps-mingw32 2.0.1) as yours on Windows 98.


On Wed, 12 Jan 2005 Robert.McGehee@geodecapital.com wrote:

> ?"=", ?"==", ?"!=", ?">=", and ?"<=" sends me to the documentation for
> ?help on Windows, while returning the correct documentation on Linux.
>
> Robert
>
>> version
>         _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
>
>
> Robert McGehee
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee@geodecapital.com
>
>
>
> This e-mail, and any attachments hereto, are intended for use by the
> addressee(s) only and may contain information that is (i) confidential
> information of Geode Capital Management, LLC and/or its affiliates,
> and/or (ii) proprietary information of Geode Capital Management, LLC
> and/or its affiliates. If you are not the intended recipient of this
> e-mail, or if you have otherwise received this e-mail in error, please
> immediately notify me by telephone (you may call collect), or by e-mail,
> and please permanently delete the original, any print outs and any
> copies of the foregoing. Any dissemination, distribution or copying of
> this e-mail is strictly prohibited.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry@tajo.ucsd.edu	         UC San Diego
http://hacuna.ucsd.edu/members/ccb.html  La Jolla, San Diego 92093-0717

From Ted.Harding at nessie.mcc.ac.uk  Wed Jan 12 21:52:26 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed Jan 12 22:05:28 2005
Subject: [Rd] Inaccuracy in seq() function (PR#7503)
In-Reply-To: <20050112192204.2F840EAE1@slim.kubism.ku.dk>
Message-ID: <XFMail.050112205226.Ted.Harding@nessie.mcc.ac.uk>

On 12-Jan-05 vstolin@lordabbett.com wrote:
> [...]
> When generating the sequence using seq() function with
> non-integer numbers result is somewhat unpredictable.
> Example:
>> v1<-seq(1.60,1.90,.05)
>> v2<-c(1.60,1.65,1.70,1.75,1.80,1.85,1.90)
>> v1-v2
> [1] 0.000000e+00 2.220446e-16 2.220446e-16 0.000000e+00 0.000000e+00
> 0.000000e+00 2.220446e-16
>> v1==v2
> [1]  TRUE FALSE FALSE  TRUE  TRUE  TRUE FALSE
>> v1>1.70 & v2<1.80
> [1] FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE

This sort of thing is inevitable as a consequence of the
fact that most decimal fractions are not stored accurately
in a finite binary representation. It's not a bug in seq().

Example:

  1.65-(1.60+0.05)
  [1] -2.220446e-16

(compare your second term in v1-v2).

Personally I always prefer to use scaled integer sequences
when creating fractional sequences:

  v3 <- seq(160,190,5)/100

  v1-v3
  [1] 0.000000e+00 2.220446e-16 2.220446e-16 0.000000e+00
  [5] 0.000000e+00 0.000000e+00 2.220446e-16

  v3-v2
  [1] 0 0 0 0 0 0 0

so my method agrees with your hand-forced v2.

But be watchful:

  v4 <- seq(160,190,5)*0.01
  v3-v4
  [1]  0.000000e+00 -2.220446e-16  0.000000e+00  0.000000e+00 
  [5]  0.000000e+00  0.000000e+00 -2.220446e-16

so "/100" is not the same as "*0.01"! And you can similarly
check that not only is v4 != v3, but neither is v4 != v1 nor
is v4 != v2. So now we have three different results (v1,
v2 == v3, v4).

Since (1.60+0.05) corresponds to the method used by seq(),
and is not equal to 1.65, you might argue that seq() is wrong,
but since the method used by seq() consists of adding the "by"
the result of seq() is correct -- in its own terms!

If you know that your intended sequence should only have a
fixed number of decimal places (in your case 2), you can force
all methods to give the same result by using round():

  v1a <- round(seq(1.60,1.90,0.05),2)
  v2a <- round(c(1.60,1.65,1.70,1.75,1.80,1.85,1.90),2)
  v3a <- round(seq(160,190,5)/100,2)
  v4a <- round(seq(160,190,5)*0.01,2)

  v1a-v2a
  [1] 0 0 0 0 0 0 0

  v1a-v3a
  [1] 0 0 0 0 0 0 0

  v1a-v4a
  [1] 0 0 0 0 0 0 0

so now they are indeed all equal. Also note that

  v2-v2a
  [1] 0 0 0 0 0 0 0
  v3-v3a
  [1] 0 0 0 0 0 0 0


so my "seq(160.190.5)/100" gives the same result as the rounded
result, and as your hand-forced version. This is why I prefer it!

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding@nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861  [NB: New number!]
Date: 12-Jan-05                                       Time: 20:52:26
------------------------------ XFMail ------------------------------

From Robert.McGehee at geodecapital.com  Wed Jan 12 22:15:46 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Wed Jan 12 22:15:58 2005
Subject: [Rd] ?"=" (Windows) (PR#7504)
Message-ID: <67DCA285A2D7754280D3B8E88EB5480206741E0F@MSGBOSCLB2WIN.DMN1.FMR.COM>

Well, you got me investigating this. Unexpectedly, it actually seems to
be an ESS bug as the correct documentation pops up using the RGui and
the command-line interface, but not when I run it through Emacs /
ESS-5.2.3. (I use Emacs on Windows but not on Linux). Unless someone has
a different experience, I'll forward this bug on to the ESS team.

Best,
Robert

-----Original Message-----
From: Charles C. Berry [mailto:cberry@tajo.ucsd.edu] 
Sent: Wednesday, January 12, 2005 3:54 PM
To: Robert.McGehee@geodecapital.com
Cc: R-bugs@biostat.ku.dk; r-devel@stat.math.ethz.ch
Subject: Re: [Rd] ?"=" (Windows) (PR#7504)



works for me.

same version (i386-ps-mingw32 2.0.1) as yours on Windows 98.


On Wed, 12 Jan 2005 Robert.McGehee@geodecapital.com wrote:

> ?"=", ?"==", ?"!=", ?">=", and ?"<=" sends me to the documentation for
> ?help on Windows, while returning the correct documentation on Linux.
>
> Robert
>
>> version
>         _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
>
>
> Robert McGehee
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee@geodecapital.com
>
>
>
> This e-mail, and any attachments hereto, are intended for use by the
> addressee(s) only and may contain information that is (i) confidential
> information of Geode Capital Management, LLC and/or its affiliates,
> and/or (ii) proprietary information of Geode Capital Management, LLC
> and/or its affiliates. If you are not the intended recipient of this
> e-mail, or if you have otherwise received this e-mail in error, please
> immediately notify me by telephone (you may call collect), or by
e-mail,
> and please permanently delete the original, any print outs and any
> copies of the foregoing. Any dissemination, distribution or copying of
> this e-mail is strictly prohibited.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive
Medicine
E mailto:cberry@tajo.ucsd.edu	         UC San Diego
http://hacuna.ucsd.edu/members/ccb.html  La Jolla, San Diego 92093-0717

______________________________________________
R-devel@stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Thu Jan 13 09:40:03 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jan 13 09:40:07 2005
Subject: [Rd] Questions to users of AIX, HP-UX or Irix
Message-ID: <Pine.LNX.4.61.0501130818350.7161@gannet.stats>

We are working on internationalization of R, in particular support for 
Unicode via UTF-8 locales and incorporation of the work of the 
`Japanization' group.  A document on the current position can be found at

 	http://developer.r-project.org/Encodings_and_R.html

We have read that AIX, HP-UX and Irix have (or had?) no support for UTF-8 
locales (e.g. en_GB.utf8).  Solaris has a limited range of such locales, 
and glibc-based systems have many (150 on FC3).  Conventionally, locale -a 
will tell you: could users of AIX, HP-UX or Irix please check?

We would also like to know if those systems have support for the C99 (but 
also UNIX98) functions mbrtowc and wcwidth.

The answers will affect the decisions on to what extent we continue to 
support some features of R on systems without internationalization 
support.  If no one reports a system without these features we are likely 
to assume them for 2.1.0 (except wcwidth which is patchy).

[Windows issues are rather different and are still under discussion.]

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From edgard at cptec.inpe.br  Thu Jan 13 14:02:52 2005
From: edgard at cptec.inpe.br (edgard@cptec.inpe.br)
Date: Thu Jan 13 14:02:55 2005
Subject: [Rd] make fails (PR#7509)
Message-ID: <20050113130252.CE9C5EAE1@slim.kubism.ku.dk>

Full_Name: edgard de freitas
Version: 2.0.1
OS: unix
Submission from: (NULL) (150.163.144.9)


 Dear sir,
 When I issue the command ./configure, it runs normally. But when
I issue the command MAKE, it appears:
 Make: Cannot open /share/make/vars.mk. Stop. 
 Thank you!
  Good bye!

From ripley at stats.ox.ac.uk  Thu Jan 13 14:12:07 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jan 13 14:12:17 2005
Subject: [Rd] make fails (PR#7509)
In-Reply-To: <20050113130252.CE9C5EAE1@slim.kubism.ku.dk>
References: <20050113130252.CE9C5EAE1@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0501131310090.14013@gannet.stats>

On Thu, 13 Jan 2005 edgard@cptec.inpe.br wrote:

> Full_Name: edgard de freitas
> Version: 2.0.1
> OS: unix

More precise, please.

> Submission from: (NULL) (150.163.144.9)
>
>
> Dear sir,
> When I issue the command ./configure, it runs normally. But when
> I issue the command MAKE, it appears:
> Make: Cannot open /share/make/vars.mk. Stop.

We need many more details to be able to help you.
Please ask for help on the R-help list: this is not a bug in R but in yout 
tools or the way you are using them.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Fri Jan 14 09:31:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jan 14 09:32:04 2005
Subject: [Rd] RE: [R] as.character methods
In-Reply-To: <67DCA285A2D7754280D3B8E88EB5480208CA11D2@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB5480208CA11D2@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <Pine.LNX.4.61.0501140814390.18523@gannet.stats>

Please use R-devel not R-help for esoteric programming questions: I have 
moved this there.  [See the posting guide.]  Anything involving the 
methods package is definitely not for R-help: I doubt if 1% of the 
readership of R-help have knowingly used it.

On Thu, 13 Jan 2005, McGehee, Robert wrote:

> Professor Ripley,
> You are quite correct, I did have some S3/S4 confusion. Thank you. By
> using an S3 method with the documented usage, I had no trouble writing
> an appropriate as.character method.
>
> I had also not absorbed the fact that S3 and S4 generics might (and do!)
> have different argument lists, as I see that the S3 as.character generic
> takes (x, ...), and the S4 generic takes just (x).
>
> I'd also like to ask a follow-up question to clarify this difference.
> The documentation for ?.BasicFunsList (first page of methods package
> documentation) reads:
>
> "Functions in R that are defined as '.Primitive(<name>)' are not
> suitable for formal methods, because they lack the basic reflectance
> property."

Please read on:

      You can't find the argument list for these
      functions by examining the function object itself.
...
      In the absence of reflectance, this list provides the relevant
      information  via a dummy function associated with each of the
      known specials for which methods are allowed.
...
      A generic function created via 'setMethod', for example, for one
      of these special functions will have the argument list from
      '.BasicFunsList'.  If no entry exists, the argument list '(x,
      ...)'  is assumed.


> As "as.character"() calls .Primitive("as.character"), I read the above
> sentence to say that S4 methods are not appropriate for this function.
> But certainly S4 methods _can_ be defined for .Primitives, and I can
> seemingly get the argument list for such a primitive with the
> getGeneric() function. Is the point then that S4 cannot pass on extended
> (...) argument list for some primitives (such as the message below), and

No, as look at the list, some of which have ... in their argument list.

> thus informal S3 methods are required in some cases? Or perhaps I'm
> missing the point entirely. Any clarification is greatly appreciated.

I am afraid I don't understand why someone who does not appreciate the 
differences here is using S4 methods.  I see you have sent a bug report on 
applying formals<- to new("function") which shows you do not understand 
the difference between that and a function.

Please look at the code for the function getGeneric: that's the 
detailed documentation.  It contains

         if (is.primitive(baseDef)) {
             value <- genericForPrimitive(f)

and it seems John Chambers has defined an S4 generic for as.character with 
one arg, "x".  Had he not done so it would have been (x, ...).  My guess 
is that this is because in S the arg list is (x) and he overlooked that it 
was not in R, but only he knows.


> Thanks,
> Robert
>
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley@stats.ox.ac.uk]
> Sent: Thursday, January 13, 2005 5:58 PM
> To: McGehee, Robert
> Cc: r-help@stat.math.ethz.ch
> Subject: Re: [R] as.character methods
>
>
> You seem to be confusing `generic' with `S4 generic', and `method' with
> `S4 method'.
>
> Note that all references to `generic' and `method' outside the `methods'
>
> package are not to S4 concepts unless explicitly stated.
>
> On Thu, 13 Jan 2005, McGehee, Robert wrote:
>
>> Hello,
>> ?as.character says that the as.character function is a generic with
>> usage: as.character(x, ...). So, I want to create an S4 object with an
>> as.character method following the above usage, but I get the below
> error
>> telling me that ... isn't in the generic for as.character.
>>
>>> setClass("tmp", "numeric")
>>> setMethod("as.character", "tmp", function(x, ...) paste(x, c(...)))
>> Error in rematchDefinition(definition, fdef, mnames, fnames,
> signature)
>> :
>> 	Methods can add arguments to the generic only if "..." is an
>> argument to the generic
>>
>> Am I reading the documentation incorrectly? How do I correctly pass
> the
>> ... object to the method for this "tmp" object?
>>
>> However I note that looking at the generic function, I see no mention
> of
>> ... (despite the documentation).
>>> getGeneric("as.character")
>> standardGeneric for "as.character" defined from package "base"
>>
>> function (x)
>> standardGeneric("as.character", .Primitive("as.character"))
>> <environment: 0145EDC4>
>> Methods may be defined for arguments: x
>>
>>
>> So, briefly, is the documentation wrong? Am I doing something wrong?
> Can
>> I create an as.character method and pass additional arguments to it as
> I
>> think I should be able to?
>
> Briefly, No, yes, yes.
>
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From lecoutre at stat.ucl.ac.be  Fri Jan 14 14:40:02 2005
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Fri Jan 14 14:48:38 2005
Subject: [Rd] S3/S4 classes performance comparison
Message-ID: <6.0.1.1.2.20050114142557.031cbdc8@stat4ux.stat.ucl.ac.be>


Hi R-devel,

If you did read my survey on Rhelp about reporting, you may have seen that 
I am implementing a way to handle outputs for R (mainly target output 
destinations: xHTML and TeX).
In fact: I does have something that works for basic objects, entirely done 
with S4 classes, with the results visible at:
http://www.stat.ucl.ac.be/ROMA/sample.htm
http://www.stat.ucl.ac.be/ROMA/sample.pdf

To achieve this goal, I do use intermediary objects that would reprensent 
the structure of the output. Thus I defined classes for Vector, Tables, 
Rows, Cells, Sections, and so on. Most of those structure are recursive.
Then, at a firts attemps, a matrix would be represented as a Table 
containing Rows containg Cells containing Vectors, which finally is easy to 
export and which makes easy the customisation (if you need to insert a 
footnote within a cell for example).
I know that this intermediary layout would be far more easier to handle at 
C level, but I dont have any C skill for that...

One of my problem is that this consumes a lot of memory/computation time.
Too much, indeed...
20 sec. to export data(iris) on my PIV 3.2 Ghz 1Go RAM, which is not 
acceptable.

I was intending to do start properly, as starting from scratch new code. I 
did write everything using S4 classes.
Doing a simple test reveals crucial efficiency differences between S3 and 
S4 classes.

Here is the test:

---

### S3 CLASSES

S3content <- function(obj=NULL,add1=NULL,add2=NULL,type="",...){
         out <- list(content=obj,add1=add2,add2=add2,type=type)
         class(out) <- "S3Content"
         return(out)
}

S3vector <- function(vec,...){
   out <- S3content(obj=vec,type="Vector",...)
   class(out) <- "S3Vector"
   return(out)
}


### S4 classes

setClass("S4content",representation(content="ANY",add1="ANY",add2="ANY",type="character"))

S4content <- function(obj=NULL,add1=NULL,add2=NULL,type="",...){
   new("S4content",content=obj,add1=add1,add2=add2,type=type)
}

S4vector <- function(vec,...){
   new("S4content",type="vector",content=vec,...)
}

### Now the test
 > test <- rnorm(10000)
 > gc()
          used (Mb) gc trigger (Mb)
Ncells 169135  4.6     531268 14.2
Vcells  75260  0.6     786432  6.0
 > (system.time(lapply(test,S3vector)))
[1] 0.17 0.00 0.19   NA   NA
 > gc()
          used (Mb) gc trigger (Mb)
Ncells 169136  4.6     531268 14.2
Vcells  75266  0.6     786432  6.0
 > (system.time(lapply(test,S4vector)))
[1] 15.08  0.00 15.13    NA    NA
-----

There is here a factor higher than 80!

Is there something trivial I did overlook?
Is this 80 factor normal?

Is it still recommended (recommendable...) to use S4 classes when 
considered that?



Eric

Eric Lecoutre
UCL /  Institut de Statistique
Voie du Roman Pays, 20
1348 Louvain-la-Neuve
Belgium

tel: (+32)(0)10473050
lecoutre@stat.ucl.ac.be
http://www.stat.ucl.ac.be/ISpersonnel/lecoutre

If the statistics are boring, then you've got the wrong numbers. -Edward 
Tufte

From Torsten.Hothorn at rzmail.uni-erlangen.de  Fri Jan 14 16:11:34 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Fri Jan 14 16:11:58 2005
Subject: [Rd] S3/S4 classes performance comparison
In-Reply-To: <6.0.1.1.2.20050114142557.031cbdc8@stat4ux.stat.ucl.ac.be>
References: <6.0.1.1.2.20050114142557.031cbdc8@stat4ux.stat.ucl.ac.be>
Message-ID: <Pine.LNX.4.51.0501141609170.30505@artemis.imbe.med.uni-erlangen.de>

On Fri, 14 Jan 2005, Eric Lecoutre wrote:

>
> Hi R-devel,
>
> If you did read my survey on Rhelp about reporting, you may have seen that
> I am implementing a way to handle outputs for R (mainly target output
> destinations: xHTML and TeX).
> In fact: I does have something that works for basic objects, entirely done
> with S4 classes, with the results visible at:
> http://www.stat.ucl.ac.be/ROMA/sample.htm
> http://www.stat.ucl.ac.be/ROMA/sample.pdf
>
> To achieve this goal, I do use intermediary objects that would reprensent
> the structure of the output. Thus I defined classes for Vector, Tables,
> Rows, Cells, Sections, and so on. Most of those structure are recursive.
> Then, at a firts attemps, a matrix would be represented as a Table
> containing Rows containg Cells containing Vectors, which finally is easy to
> export and which makes easy the customisation (if you need to insert a
> footnote within a cell for example).
> I know that this intermediary layout would be far more easier to handle at
> C level, but I dont have any C skill for that...
>
> One of my problem is that this consumes a lot of memory/computation time.
> Too much, indeed...
> 20 sec. to export data(iris) on my PIV 3.2 Ghz 1Go RAM, which is not
> acceptable.
>
> I was intending to do start properly, as starting from scratch new code. I
> did write everything using S4 classes.
> Doing a simple test reveals crucial efficiency differences between S3 and
> S4 classes.
>
> Here is the test:
>
> ---
>
> ### S3 CLASSES
>
> S3content <- function(obj=NULL,add1=NULL,add2=NULL,type="",...){
>          out <- list(content=obj,add1=add2,add2=add2,type=type)
>          class(out) <- "S3Content"
>          return(out)
> }
>
> S3vector <- function(vec,...){
>    out <- S3content(obj=vec,type="Vector",...)
>    class(out) <- "S3Vector"
>    return(out)
> }
>
>
> ### S4 classes
>
> setClass("S4content",representation(content="ANY",add1="ANY",add2="ANY",type="character"))
>
> S4content <- function(obj=NULL,add1=NULL,add2=NULL,type="",...){
>    new("S4content",content=obj,add1=add1,add2=add2,type=type)
> }
>
> S4vector <- function(vec,...){
>    new("S4content",type="vector",content=vec,...)
> }
>
> ### Now the test
>  > test <- rnorm(10000)
>  > gc()
>           used (Mb) gc trigger (Mb)
> Ncells 169135  4.6     531268 14.2
> Vcells  75260  0.6     786432  6.0
>  > (system.time(lapply(test,S3vector)))
> [1] 0.17 0.00 0.19   NA   NA
>  > gc()
>           used (Mb) gc trigger (Mb)
> Ncells 169136  4.6     531268 14.2
> Vcells  75266  0.6     786432  6.0
>  > (system.time(lapply(test,S4vector)))
> [1] 15.08  0.00 15.13    NA    NA
> -----
>
> There is here a factor higher than 80!
>
> Is there something trivial I did overlook?
> Is this 80 factor normal?
>

my experience was that calling the constructor _with_ data is slow, so the
following performs a little bit better

R> S3content <- function(obj=NULL,add1=NULL,add2=NULL,type="",...){
+          out <- list(content=obj,add1=add2,add2=add2,type=type)
+          class(out) <- "S3Content"
+          return(out)
+ }
R>
R> S3vector <- function(vec,...){
+    out <- S3content(obj=vec,type="Vector",...)
+    class(out) <- "S3Vector"
+    return(out)
+ }
R>
R>
R> ### S4 classes
R>
R>
setClass("S4content",representation(content="ANY",add1="ANY",add2="ANY",type="character"))
[1] "S4content"
R>
R> S4vector <- function(vec,...){
+    RET <- new("S4content")
+    RET@type <- "vector"
+    RET@content <- vec
+    RET
+ }
R>
R> test <- rnorm(10000)
R> gc()
         used (Mb) gc trigger (Mb)
Ncells 156181  4.2     350000  9.4
Vcells  67973  0.6     786432  6.0
R> system.time(lapply(test,S3vector))
[1] 0.23 0.00 0.23 0.00 0.00
R> gc()
         used (Mb) gc trigger (Mb)
Ncells 156314  4.2     350000  9.4
Vcells  68005  0.6     786432  6.0
R> system.time(lapply(test,S4vector))
[1] 6.04 0.00 6.04 0.00 0.00
R>

Torsten

> Is it still recommended (recommendable...) to use S4 classes when
> considered that?
>
>
>
> Eric
>
> Eric Lecoutre
> UCL /  Institut de Statistique
> Voie du Roman Pays, 20
> 1348 Louvain-la-Neuve
> Belgium
>
> tel: (+32)(0)10473050
> lecoutre@stat.ucl.ac.be
> http://www.stat.ucl.ac.be/ISpersonnel/lecoutre
>
> If the statistics are boring, then you've got the wrong numbers. -Edward
> Tufte
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

From jmc at r-project.org  Fri Jan 14 16:36:14 2005
From: jmc at r-project.org (John Chambers)
Date: Fri Jan 14 16:36:31 2005
Subject: [Rd] RE: [R] as.character methods
In-Reply-To: <Pine.LNX.4.61.0501140814390.18523@gannet.stats>
References: <67DCA285A2D7754280D3B8E88EB5480208CA11D2@MSGBOSCLB2WIN.DMN1.FMR.COM>
	<Pine.LNX.4.61.0501140814390.18523@gannet.stats>
Message-ID: <41E7E6EE.1010307@R-project.org>



Prof Brian Ripley wrote:
 > Please use R-devel not R-help for esoteric programming questions: I have
 > moved this there.  [See the posting guide.]  Anything involving the
 > methods package is definitely not for R-help: I doubt if 1% of the
 > readership of R-help have knowingly used it.

I believe the general guidelines for what goes in r-help and what in 
r-devel are clear enough without actively discouraging discussion of 
classes and methods.  It's the nature of the question, not a litmus test 
for discussing this or that package that is the helpful distinction.


....

>         if (is.primitive(baseDef)) {
>             value <- genericForPrimitive(f)
> 
> and it seems John Chambers has defined an S4 generic for as.character 
> with one arg, "x".  Had he not done so it would have been (x, ...).  My 
> guess is that this is because in S the arg list is (x) and he overlooked 
> that it was not in R, but only he knows.

Well, let's say that he usually implemented the S4 generics for 
primitives assuming R might follow the description in the Blue Book. 
Further checking against the R online documentation was done, but 
obviously not often enough.  Life is, however, short.

No intention to create incompatibility between the S4 generic and S3 
code in this case, we should fix that.

There are some cases in which the generic needs extra named arguments to 
allow sensible methods, for example "[".  I can't think of any case 
where one would intentionally have _fewer_ arguments in the generic.

> 
> 
> 
......

From lecoutre at stat.ucl.ac.be  Fri Jan 14 17:30:08 2005
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Fri Jan 14 17:38:51 2005
Subject: [Rd] S3/S4 classes performance comparison
In-Reply-To: <Pine.LNX.4.51.0501141609170.30505@artemis.imbe.med.uni-erl
	angen.de>
References: <6.0.1.1.2.20050114142557.031cbdc8@stat4ux.stat.ucl.ac.be>
	<Pine.LNX.4.51.0501141609170.30505@artemis.imbe.med.uni-erlangen.de>
Message-ID: <6.0.1.1.2.20050114172438.032aa578@stat4ux.stat.ucl.ac.be>



Hi again,

Thanks for that suggestion: I have tested it at higher scale for my 
application and it does indeed increase performance. But not sufficient for 
my application: it still remains a factor of nearly 25!

Anyway, I think I will come back to S3 classes for that project, which will 
involve a lot of different classes (and nested objects).
In some sense, it is a shame: I clearly understand that S4 classes are 
well-founded and can only encourage R developpers to go on with their 
excellent work.
In fact, the problem may be you do too much great work on core R: the 
manipulations with pure S3 classes are so fast!

Best wishes,

Eric



>my experience was that calling the constructor _with_ data is slow, so the
>following performs a little bit better
>
>R> S3content <- function(obj=NULL,add1=NULL,add2=NULL,type="",...){
>+          out <- list(content=obj,add1=add2,add2=add2,type=type)
>+          class(out) <- "S3Content"
>+          return(out)
>+ }
>R>
>R> S3vector <- function(vec,...){
>+    out <- S3content(obj=vec,type="Vector",...)
>+    class(out) <- "S3Vector"
>+    return(out)
>+ }
>R>
>R>
>R> ### S4 classes
>R>
>R>
>setClass("S4content",representation(content="ANY",add1="ANY",add2="ANY",type="character"))
>[1] "S4content"
>R>
>R> S4vector <- function(vec,...){
>+    RET <- new("S4content")
>+    RET@type <- "vector"
>+    RET@content <- vec
>+    RET
>+ }
>R>
>R> test <- rnorm(10000)
>R> gc()
>          used (Mb) gc trigger (Mb)
>Ncells 156181  4.2     350000  9.4
>Vcells  67973  0.6     786432  6.0
>R> system.time(lapply(test,S3vector))
>[1] 0.23 0.00 0.23 0.00 0.00
>R> gc()
>          used (Mb) gc trigger (Mb)
>Ncells 156314  4.2     350000  9.4
>Vcells  68005  0.6     786432  6.0
>R> system.time(lapply(test,S4vector))
>[1] 6.04 0.00 6.04 0.00 0.00
>R>
>
>Torsten

Eric Lecoutre
UCL /  Institut de Statistique
Voie du Roman Pays, 20
1348 Louvain-la-Neuve
Belgium

tel: (+32)(0)10473050
lecoutre@stat.ucl.ac.be
http://www.stat.ucl.ac.be/ISpersonnel/lecoutre

If the statistics are boring, then you've got the wrong numbers. -Edward 
Tufte

From Robert.McGehee at geodecapital.com  Fri Jan 14 19:09:03 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Fri Jan 14 19:09:15 2005
Subject: [Rd] RE: [R] as.character methods
Message-ID: <67DCA285A2D7754280D3B8E88EB5480206741E16@MSGBOSCLB2WIN.DMN1.FMR.COM>

Thank you for your replies. I greatly appreciate the wealth of
documentation on this subject and the time spent by the John Chambers
and the R Core Team making object-orient programming in R a reality. I
hope to be able to give code (not just bug reports) back to the R
community as my projects advance.

I hoping to generalize my as.character question to a real-life
as.character / print method example that is causing more problems than
I'd like to admit, and that I hope I could get feedback from.

Briefly, I'm looking to extend the "name" class into a new class I call
"newName" which performs just as "name" does except that when a
"newName" object is printed that has been initialized without a value,
it prints NULL to the screen instead of `<UNDEFINED>`. I chose the
"name" class as I am using extensions of name, call, and expression to
create syntactically correct R expressions that are then parsed by a
non-R parser. Thus I want to be able use R to check for syntax and
"translate" code from one language into another.

My problem is that I have been unable to make the print method work
correctly on the "name" class, despite success for other classes, and my
best implementation only sometimes works (sometimes it prints, sometimes
it errors out). The below code produces the behavior that the first time
we try to print the object we get an error, the second time it prints
correctly, and the third and fourth time it prints, but without quotes.
To run the following code to reproduce my problem, you may need to
restart R to see exactly the same behavior that I am seeing on Windows /
Linux 2.0.1. As always, I'd appreciate any help in creating this method,
or comments on my approach, as I effectively want to hide the
`<UNDEFINED>` initialization of this new object.

######################
## First create the class as extension of "name"
setClass("newName",
         representation("name"))

## Write a generator function for this class
newName <- function(value) {
    if (missing(value) || is.null(value))
      x <- new("name")
    else
      x <- as.name(value)
    class(x) <- "newName"
    x
}

## as.character method for printing:
as.character.newName <- function(x, ...) {
    ## If x is the same as an uninitialized "newName" object, then
return NULL
    if(x == new("newName"))
      return(NULL)
    else
      as.character(as.name(x))
}

## The print method should just reference the 
## as.character method
print.newName <- function(x, ...) {
    as.character(x, ...)
}

## Now create the object.
a <- newName("abc")
## Thus "a" has class of "newName" and holds the symbol `abc`

############
## Now let's try to look at this object using print()
############
> a
Error in print(abc) : Object "abc" not found
## Fails! Let's try calling print() explicitly

> print(a)
[1] "abc"
## That worked, let's try looking at the object again

> a
abc
## This time it printed! (without the quotes)

## Let's try printing the object again
> print(a)
abc 
## Again, printed without the quotes

If I create formal methods for print, show, and/or as.character, I still
have similar problems, and in no case can I get this to work
(consistently at least). Should I abandon trying to extend the "name"
class at all? Or is there some problems in my code above that would
cause this behavior. I have not had any similar trouble when extending
the "call" and "expression" classes, and apologies for the technical
nature of this post.

Thanks,
Robert


-----Original Message-----
From: John Chambers [mailto:jmc@r-project.org] 
Sent: Friday, January 14, 2005 10:36 AM
To: Prof Brian Ripley
Cc: McGehee, Robert; r-devel@stat.math.ethz.ch
Subject: Re: [Rd] RE: [R] as.character methods




Prof Brian Ripley wrote:
 > Please use R-devel not R-help for esoteric programming questions: I
have
 > moved this there.  [See the posting guide.]  Anything involving the
 > methods package is definitely not for R-help: I doubt if 1% of the
 > readership of R-help have knowingly used it.

I believe the general guidelines for what goes in r-help and what in 
r-devel are clear enough without actively discouraging discussion of 
classes and methods.  It's the nature of the question, not a litmus test

for discussing this or that package that is the helpful distinction.


....

>         if (is.primitive(baseDef)) {
>             value <- genericForPrimitive(f)
> 
> and it seems John Chambers has defined an S4 generic for as.character 
> with one arg, "x".  Had he not done so it would have been (x, ...).
My 
> guess is that this is because in S the arg list is (x) and he
overlooked 
> that it was not in R, but only he knows.

Well, let's say that he usually implemented the S4 generics for 
primitives assuming R might follow the description in the Blue Book. 
Further checking against the R online documentation was done, but 
obviously not often enough.  Life is, however, short.

No intention to create incompatibility between the S4 generic and S3 
code in this case, we should fix that.

There are some cases in which the generic needs extra named arguments to

allow sensible methods, for example "[".  I can't think of any case 
where one would intentionally have _fewer_ arguments in the generic.

> 
> 
> 
......

From jmc at r-project.org  Fri Jan 14 20:51:48 2005
From: jmc at r-project.org (John Chambers)
Date: Fri Jan 14 20:52:19 2005
Subject: [Rd] RE: [R] as.character methods
In-Reply-To: <67DCA285A2D7754280D3B8E88EB5480206741E16@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB5480206741E16@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <41E822D4.9070107@R-project.org>



McGehee, Robert wrote:
> Thank you for your replies. I greatly appreciate the wealth of
> documentation on this subject and the time spent by the John Chambers
> and the R Core Team making object-orient programming in R a reality. I
> hope to be able to give code (not just bug reports) back to the R
> community as my projects advance.
> 
> I hoping to generalize my as.character question to a real-life
> as.character / print method example that is causing more problems than
> I'd like to admit, and that I hope I could get feedback from.
> 
> Briefly, I'm looking to extend the "name" class into a new class 

Unfortunately there is a major catch here.  Objects of class "name" are 
not duplicated by the internal R code, in contrast to the normal model 
for objects in R.  In other words, any variable containing a particular 
name is a reference to one copy of that name.

This effectively prevents building subclasses of "name", as well as many 
other computations.  The following example illustrates the problem:

R> x = as.name('foo')
R> x
foo
R> y = x
R> attr(x, "bar") = "test"
R> y
foo
attr(,"bar")
[1] "test"

The attribute that is set in one object appears in the other.

(Similar problems arise with environment objects and some other classes.)

In the future, it might be possible to let such objects have attributes 
that were treated normally, while the objects still pointed to the 
single name or environment.

For now, though, it's necessary to protect the object by having the name 
as a slot or element of a list, not as a class simply extending "name".

I call
> "newName" which performs just as "name" does except that when a
> "newName" object is printed that has been initialized without a value,
> it prints NULL to the screen instead of `<UNDEFINED>`. I chose the
> "name" class as I am using extensions of name, call, and expression to
> create syntactically correct R expressions that are then parsed by a
> non-R parser. Thus I want to be able use R to check for syntax and
> "translate" code from one language into another.
> 
> My problem is that I have been unable to make the print method work
> correctly on the "name" class, despite success for other classes, and my
> best implementation only sometimes works (sometimes it prints, sometimes
> it errors out). The below code produces the behavior that the first time
> we try to print the object we get an error, the second time it prints
> correctly, and the third and fourth time it prints, but without quotes.
> To run the following code to reproduce my problem, you may need to
> restart R to see exactly the same behavior that I am seeing on Windows /
> Linux 2.0.1. As always, I'd appreciate any help in creating this method,
> or comments on my approach, as I effectively want to hide the
> `<UNDEFINED>` initialization of this new object.
> 
> ######################
> ## First create the class as extension of "name"
> setClass("newName",
>          representation("name"))
> 
> ## Write a generator function for this class
> newName <- function(value) {
>     if (missing(value) || is.null(value))
>       x <- new("name")
>     else
>       x <- as.name(value)
>     class(x) <- "newName"
>     x
> }
> 
> ## as.character method for printing:
> as.character.newName <- function(x, ...) {
>     ## If x is the same as an uninitialized "newName" object, then
> return NULL
>     if(x == new("newName"))
>       return(NULL)
>     else
>       as.character(as.name(x))
> }
> 
> ## The print method should just reference the 
> ## as.character method
> print.newName <- function(x, ...) {
>     as.character(x, ...)
> }
> 
> ## Now create the object.
> a <- newName("abc")
> ## Thus "a" has class of "newName" and holds the symbol `abc`
> 
> ############
> ## Now let's try to look at this object using print()
> ############
> 
>>a
> 
> Error in print(abc) : Object "abc" not found
> ## Fails! Let's try calling print() explicitly
> 
> 
>>print(a)
> 
> [1] "abc"
> ## That worked, let's try looking at the object again
> 
> 
>>a
> 
> abc
> ## This time it printed! (without the quotes)
> 
> ## Let's try printing the object again
> 
>>print(a)
> 
> abc 
> ## Again, printed without the quotes
> 
> If I create formal methods for print, show, and/or as.character, I still
> have similar problems, and in no case can I get this to work
> (consistently at least). Should I abandon trying to extend the "name"
> class at all? Or is there some problems in my code above that would
> cause this behavior. I have not had any similar trouble when extending
> the "call" and "expression" classes, and apologies for the technical
> nature of this post.
> 
> Thanks,
> Robert
> 
> 
> -----Original Message-----
> From: John Chambers [mailto:jmc@r-project.org] 
> Sent: Friday, January 14, 2005 10:36 AM
> To: Prof Brian Ripley
> Cc: McGehee, Robert; r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] RE: [R] as.character methods
> 
> 
> 
> 
> Prof Brian Ripley wrote:
>  > Please use R-devel not R-help for esoteric programming questions: I
> have
>  > moved this there.  [See the posting guide.]  Anything involving the
>  > methods package is definitely not for R-help: I doubt if 1% of the
>  > readership of R-help have knowingly used it.
> 
> I believe the general guidelines for what goes in r-help and what in 
> r-devel are clear enough without actively discouraging discussion of 
> classes and methods.  It's the nature of the question, not a litmus test
> 
> for discussing this or that package that is the helpful distinction.
> 
> 
> ....
> 
> 
>>        if (is.primitive(baseDef)) {
>>            value <- genericForPrimitive(f)
>>
>>and it seems John Chambers has defined an S4 generic for as.character 
>>with one arg, "x".  Had he not done so it would have been (x, ...).
> 
> My 
> 
>>guess is that this is because in S the arg list is (x) and he
> 
> overlooked 
> 
>>that it was not in R, but only he knows.
> 
> 
> Well, let's say that he usually implemented the S4 generics for 
> primitives assuming R might follow the description in the Blue Book. 
> Further checking against the R online documentation was done, but 
> obviously not often enough.  Life is, however, short.
> 
> No intention to create incompatibility between the S4 generic and S3 
> code in this case, we should fix that.
> 
> There are some cases in which the generic needs extra named arguments to
> 
> allow sensible methods, for example "[".  I can't think of any case 
> where one would intentionally have _fewer_ arguments in the generic.
> 
> 
>>
>>
> ......
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From Trial at 352Hosting.com  Fri Jan 14 22:31:41 2005
From: Trial at 352Hosting.com (Trial@352Hosting.com)
Date: Fri Jan 14 22:31:55 2005
Subject: [Rd] New Hosting Account (PR#7513)
Message-ID: <20050114213141.947F11146A@slim.kubism.ku.dk>

This is a multi-part message in MIME format.

--_----------=_1073964459106330
Content-Transfer-Encoding: 7bit
Content-Type: text/plain

Hello,

 I am writing because your name was forwarded to me in regards to your interest in receiving a trial hosting account.

 352Hosting would like to offer you a trial hosting account and a complete website to get you started. 

We are proud to offer you a selection of 48 complete websites that are only $10 each. These websites have already been developed and are ready for use. Each website has been hand coded by a group of the Internet's top designers and developers. The best part is, these complete websites are only $10! 

Summary of Offer:
 1) A complete, professional website for just $10
 2) Included with your purchase is a one month trial hosting account with no setup fees.

To browse the selection of available websites, and to signup for your trial hosting account please visit: 

http://www.352Hosting.com/turnkey

Thank you and please let me know if there is anything else I can help you with,
 Peter Ferrigan
 Trial@352Hosting.com
 http://www.352Hosting.com/turnkey


:Contact Information:.

352Hosting.com
12106 SW 9th RD
Gainesville, Fl
33601

Additionally I personally can be reached at (352) 248-0538

Click here on http://server1.streamsend.com/newstreamsend/unsubscribe.php?md=3&cd=914&ud=121f2c8b61514890cd44f3ed142a1281 <http://server1.streamsend.com/newstreamsend/unsubscribe.php?md=3&cd=914&ud=121f2c8b61514890cd44f3ed142a1281> to update your profile or Unsubscribe
--_----------=_1073964459106330--

From smyth at wehi.EDU.AU  Sun Jan 16 05:53:44 2005
From: smyth at wehi.EDU.AU (Gordon K Smyth)
Date: Sun Jan 16 05:56:13 2005
Subject: [Rd] running Sweave from Windows XP Explorer
Message-ID: <4717.220.236.48.36.1105851224.squirrel@220.236.48.36>

I'd like to create a suitable batch file or shortcut so that I can run Sweave on a .Rnw or .Rtex
file simply by clicking on the file from Windows Explorer in Windows XP (as I do with latex,
bibtex etc).  This looks tantalisingly possible using R CMD BATCH or Rterm possibly in combination
with a .bat file.  Has anyone succeeded is setting it up and would give me a pointer?

Thanks
Gordon

From smyth at wehi.edu.au  Sun Jan 16 09:44:26 2005
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Sun Jan 16 09:44:37 2005
Subject: [Rd] p.adjust(<NA>s), was "Re: [BioC] limma and p-values"
In-Reply-To: <16864.17075.17844.24998@stat.math.ethz.ch>
References: <200501071109.j07B88Mw022009@hypatia.math.ethz.ch>
	<1680.211.31.70.61.1105107090.squirrel@211.31.70.61>
	<16864.2059.154031.140551@stat.math.ethz.ch>
	<16864.17075.17844.24998@stat.math.ethz.ch>
Message-ID: <6.2.0.14.1.20050116185753.021f73a0@imaphost.wehi.edu.au>

The new committed version of p.adjust() contains some problems:

 > p.adjust(c(0.05,0.5),method="hommel")
[1] 0.05 0.50

No adjustment!

I can't see how the new treatment of NAs can be justified. One needs to 
distinguish between NAs which represent missing p-values and NAs which 
represent unknown p-values. In virtually all applications giving rise to 
NAs, the NAs represent missing p-values which could not be computed because 
of missing data. In such cases, the observed p-values should definitely be 
adjusted as if the NAs weren't there, because NAs represent p-values which 
genuinely don't exist.

I can only think of one situation in which the NAs might represent unknown 
but existing p-values. This would be when a large experiment has been 
conducted leading to many p-values. Instead of inputing all the p-values to 
the p.adjust() function, you decide to enter only the smallest p-values and 
represent the others using NAs. The trouble with this approach is that it 
can only be used with method="bonferroni". All the other adjustment methods 
are step-up or step-down methods or involve closure like Hommel's method. 
For these methods, you simply have to know all the p-values before you can 
adjust any of them.

For example, you're returning

 > p.adjust(c(0.05,NA,NA,NA,NA,NA,NA,NA,NA,NA),method="fdr")
  [1] 0.5  NA  NA  NA  NA  NA  NA  NA  NA  NA

But the unknown p-values might have been like this:
 > 
p.adjust(c(0.05,0.051,0.051,0.051,0.051,0.051,0.051,0.051,0.051,0.051),method="fdr")
  [1] 0.051 0.051 0.051 0.051 0.051 0.051 0.051 0.051 0.051 0.051

in which case the first adjusted p-value would have been 0.051 not 0.5.

How can you justify returning 0.5 for the first adjusted p-value, when the 
correct value could actually be a factor of 10 lower, even when the first 
p-value is in fact the smallest of the p-values?

At 07:29 AM 9/01/2005, Martin Maechler wrote:
>I've thought more and made experiements with R code versions
>and just now committed a new version of  p.adjust()  to R-devel
>--> https://svn.r-project.org/R/trunk/src/library/stats/R/p.adjust.R
>which does sensible NA handling by default and
>*additionally* has an "na.rm" argument (set to FALSE by
>default).  The extended 'Examples' secion on the help page
>     https://svn.r-project.org/R/trunk/src/library/stats/man/p.adjust.Rd
>shows how the new NA handling is typically much more sensible
>than using "na.rm = TRUE".
>
>Martin
>
>
> >>>>> "MM" == Martin Maechler <maechler@stat.math.ethz.ch>
> >>>>>     on Sat, 8 Jan 2005 17:19:23 +0100 writes:
>
> >>>>> "GS" == Gordon K Smyth <smyth@wehi.edu.au>
> >>>>>     on Sat, 8 Jan 2005 01:11:30 +1100 (EST) writes:
>
>     MM>     <.............>
>
>     GS> p.adjust() unfortunately gives incorrect results when
>     GS> 'p' includes NAs.  The results from topTable are
>     GS> correct.  topTable() takes care to remove NAs before
>     GS> passing the values to p.adjust().
>
>     MM> There's at least one bug in p.adjust(): The "hommel"
>     MM> method currently does not work at all with NAs (and I
>     MM> have an uncommitted fix ready for this bug).  OTOH, the
>     MM> current version of p.adjust() ``works'' with NA's, apart
>     MM> from Hommel's method, but by using "n = length(p)" in
>     MM> the correction formulae, i.e. *including* the NAs for
>     MM> determining sample size `n' {my fix to "hommel" would do
>     MM> this as well}.
>
>     MM> My question is what p.adjust() should do when there are
>     MM> NA's more generally, or more specifically which `n' to
>     MM> use in the correction formula. Your proposal amounts to
>     MM> ``drop NA's and forget about them till the very end''
>     MM> (where they are wanted in the result), i.e., your sample
>     MM> size `n' would be sum(!is.na(p)) instead of length(p).

My approach to NAs (in the topTable function is the limma package) is 
correct in the microarray context where the NAs represent missing 
(non-existant) p-values which could not be computed.

>    MM> To me it doesn't seem obvious that this setting "n =
>     MM> #{non-NA observations}" is desirable for all P-value
>     MM> adjustment methods. One argument for keeping ``n = #{all
>     MM> observations}'' at least for some correction methods is
>     MM> the following "continuity" one:
>
>     MM> If only a few ``irrelevant'' (let's say > 0.5) P-values
>     MM> are replaced by NA, the adjusted relevant small P-values
>     MM> shouldn't change much, ideally not at all.  I'm really
>     MM> no scholar on this topic, but e.g. for "holm" I think I
>     MM> would want to keep ``full n'' because of the above
>     MM> continuity argument.

I don't see how the treatment of NAs follows from this continuity argument. 
The argument seems to be rather informal and doesn't obviously relate to 
the concepts of power and control of FWER and FDR, which is what the 
adjustment method theory is based on.

The NAs should surely be treated in a consistent way for all the adjustment 
methods.

>  BTW, for "fdr", I don't see a
>     MM> straightforward way to achieve the desired continuity.
>     MM> 5D Of course, p.adjust() could adopt the possibility of
>     MM> chosing how NA's should be treated e.g. by another
>     MM> argument ``use.na = TRUE/FALSE'' and hence allow both
>     MM> versions.
>
>     MM> Feedback very welcome, particularly from ``P-value
>     MM> experts'' ;-)
>
>     MM> Martin Maechler, ETH Zurich

Gordon

From smyth at wehi.edu.au  Sun Jan 16 09:55:35 2005
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Sun Jan 16 09:55:41 2005
Subject: [Rd] p.adjust(<NA>s), was "Re: [BioC] limma and p-values"
Message-ID: <6.2.0.14.1.20050116182326.02194240@imaphost.wehi.edu.au>

I append below a suggested update for p.adjust().

1. A new method "yh" for control of FDR is included which is valid for any 
dependency structure. Reference is Benjamini, Y., and Yekutieli, D. (2001). 
The control of the false discovery rate in multiple testing under 
dependency. Annals of Statistics 29, 1165-1188.

2. I've re-named the "fdr" method to "bh" but kept "fdr" as a synonym for 
backward compatability.

3. Upper case values for method "BH" or "YH" are also accepted.

4. p.adust() now preserves attributes like names for named vectors (as does 
cumsum and friends for example).

5. p.adjust() now works columnwise on numeric data.frames (as does cumsum 
and friends).

6. method="hommel" now works correctly even for n=2

7. The 'n' argument is removed. Setting this argument for any methods other 
than "none" or "bonferroni" make the p-values indeterminate, and the 
argument seems to be seldom used. (It isn't used in the R default 
distribution.) I think trying to combine this argument with NAs would get 
you into lots of hot water. For example, what does 
p.adjust(c(NA,NA,0.05),n=2) mean? Which 2 values should be adjusted?

8. NAs are treated in na.exclude style. This is the correct approach for 
most applications. The only other consistent thing you could do would be to 
treat the NAs as if they all had value=1. But then you would have to 
explain clearly that the values being returned are not actually the correct 
adjusted p-values, which are unknown, but are the most conservative 
possible values assuming the worst-case for the missing values. This would 
become arbitrarily unreasonable as the number of NAs increases.

Gordon


p.adjust.methods <-
     c("holm", "hochberg", "hommel", "bonferroni", "yh", "bh", "fdr", "none")

p.adjust <- function(p, method = p.adjust.methods) {
     method <- match.arg(tolower(method),p.adjust.methods)
     if(method=="fdr") method <- "bh"
     if(is.data.frame(p)) {
         if(length(p)) for(i in 1:length(p)) p[[i]] <- 
Recall(p[[i]],method=method)
         return(p)
     }
     porig <- p
     notna <- !is.na(p)
     p <- as.vector(p[notna])
     n <- length(p)
     if (n == 1) return(porig)
     if (n == 2 && method=="hommel") method <- "hochberg"
     porig[notna] <- switch(method,
            holm = {
                i <- 1:n
                o <- order(p)
                ro <- order(o)
                pmin(1, cummax( (n - i + 1) * p[o] ))[ro]
            },
            hochberg = {
                i <- n:1
                o <- order(p, decreasing = TRUE)
                ro <- order(o)
                pmin(1, cummin( (n - i + 1) * p[o] ))[ro]
            },
            hommel = {
                i <- 1:n
                s <- sort(p, index = TRUE)
                p <- s$x
                ro <- order(s$ix)
                q <- pa <- rep.int( min(n*p/(1:n)), n)
                for (j in (n-1):2) {
                    q1 <- min(j*p[(n-j+2):n]/(2:j))
                    q[1:(n-j+1)] <- pmin( j*p[1:(n-j+1)], q1)
                    q[(n-j+2):n] <- q[n-j+1]
                    pa <- pmax(pa,q)
                }
                pmax(pa,p)[ro]
            },
            bh = {
                i <- n:1
                o <- order(p, decreasing = TRUE)
                ro <- order(o)
                pmin(1, cummin( n / i * p[o] ))[ro]
            },
            yh = {
                i <- n:1
                o <- order(p, decreasing = TRUE)
                ro <- order(o)
                q <- sum(1/(1:n))
                pmin(1, cummin(q * n/i * p[o]))[ro]
            },
            bonferroni = pmin(n * p, 1),
            none = p)
     porig
}

From ligges at statistik.uni-dortmund.de  Sun Jan 16 15:26:38 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Jan 16 15:25:52 2005
Subject: [Rd] running Sweave from Windows XP Explorer
In-Reply-To: <4717.220.236.48.36.1105851224.squirrel@220.236.48.36>
References: <4717.220.236.48.36.1105851224.squirrel@220.236.48.36>
Message-ID: <41EA799E.6080501@statistik.uni-dortmund.de>

Gordon K Smyth wrote:
> I'd like to create a suitable batch file or shortcut so that I can run Sweave on a .Rnw or .Rtex
> file simply by clicking on the file from Windows Explorer in Windows XP (as I do with latex,
> bibtex etc).  This looks tantalisingly possible using R CMD BATCH or Rterm possibly in combination
> with a .bat file.  Has anyone succeeded is setting it up and would give me a pointer?
> 
> Thanks
> Gordon
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


As a very simple starting *idea*, a batch file could look like, e.g.,

   R CMD BATCH --no-save c:/myscripts/MakeSweave.R
   texi2dvi --pdf %1.tex
   gsview32 %1.pdf


with MakeSweave.R:

   library(tools)
   for(i in list.files(pattern = "\\.Rnw$")) Sweave(i)

From ripley at stats.ox.ac.uk  Sun Jan 16 16:02:57 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Jan 16 16:03:01 2005
Subject: [Rd] running Sweave from Windows XP Explorer
In-Reply-To: <41EA799E.6080501@statistik.uni-dortmund.de>
References: <4717.220.236.48.36.1105851224.squirrel@220.236.48.36>
	<41EA799E.6080501@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.61.0501161445240.6370@gannet.stats>

On Sun, 16 Jan 2005, Uwe Ligges wrote:

> Gordon K Smyth wrote:

>> I'd like to create a suitable batch file or shortcut so that I can run 
>> Sweave on a .Rnw or .Rtex file simply by clicking on the file from 
>> Windows Explorer in Windows XP (as I do with latex, bibtex etc).  This 
>> looks tantalisingly possible using R CMD BATCH or Rterm possibly in 
>> combination with a .bat file.  Has anyone succeeded is setting it up 
>> and would give me a pointer?

> As a very simple starting *idea*, a batch file could look like, e.g.,
>
>  R CMD BATCH --no-save c:/myscripts/MakeSweave.R
>  texi2dvi --pdf %1.tex
>  gsview32 %1.pdf
>
>
> with MakeSweave.R:
>
>  library(tools)
>  for(i in list.files(pattern = "\\.Rnw$")) Sweave(i)

Another idea would be

rterm --no-save --args "%1" < c:/myscripts/MakeSweave.R > "%1.log"

where MakeSweave.R was

library(tools)
args <- commandArgs()
inp <- args[length(args)]
Sweave(inp)
base <- sub("\.(Rnw|Rtex)$", "", inp)
texi2dvi(paste("base", ".tex", sep=""), pdf=TRUE)
shell.exec(paste("base", ".pdf", sep=""))

Worked for me (in R-devel) on the example in utils/Sweave.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From smyth at wehi.edu.au  Mon Jan 17 05:53:52 2005
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Mon Jan 17 05:54:09 2005
Subject: [Rd] running Sweave from Windows XP Explorer
In-Reply-To: <Pine.LNX.4.61.0501161445240.6370@gannet.stats>
References: <4717.220.236.48.36.1105851224.squirrel@220.236.48.36>
	<41EA799E.6080501@statistik.uni-dortmund.de>
	<Pine.LNX.4.61.0501161445240.6370@gannet.stats>
Message-ID: <6.2.0.14.1.20050117154656.0227ed38@imaphost.wehi.edu.au>

At 02:02 AM 17/01/2005, Prof Brian Ripley wrote:
>On Sun, 16 Jan 2005, Uwe Ligges wrote:
>>Gordon K Smyth wrote:
>
>>>I'd like to create a suitable batch file or shortcut so that I can run 
>>>Sweave on a .Rnw or .Rtex file simply by clicking on the file from 
>>>Windows Explorer in Windows XP (as I do with latex, bibtex etc).  This 
>>>looks tantalisingly possible using R CMD BATCH or Rterm possibly in 
>>>combination with a .bat file.  Has anyone succeeded is setting it up and 
>>>would give me a pointer?
>
>>As a very simple starting *idea*, a batch file could look like, e.g.,
>>
>>  R CMD BATCH --no-save c:/myscripts/MakeSweave.R
>>  texi2dvi --pdf %1.tex
>>  gsview32 %1.pdf
>>
>>
>>with MakeSweave.R:
>>
>>  library(tools)
>>  for(i in list.files(pattern = "\\.Rnw$")) Sweave(i)
>
>Another idea would be
>
>rterm --no-save --args "%1" < c:/myscripts/MakeSweave.R > "%1.log"
>
>where MakeSweave.R was
>
>library(tools)
>args <- commandArgs()
>inp <- args[length(args)]
>Sweave(inp)
>base <- sub("\.(Rnw|Rtex)$", "", inp)
>texi2dvi(paste("base", ".tex", sep=""), pdf=TRUE)
>shell.exec(paste("base", ".pdf", sep=""))
>
>Worked for me (in R-devel) on the example in utils/Sweave.

Works for me too. Very nice. Thanks to you both.

Gordon

>--
>Brian D. Ripley,                  ripley@stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From eplmntvrxbplib at forum.dk  Mon Jan 17 08:44:17 2005
From: eplmntvrxbplib at forum.dk (eplmntvrxbplib@forum.dk)
Date: Mon Jan 17 08:44:20 2005
Subject: [Rd] COuld this Shares ROck? (PR#7526)
Message-ID: <20050117074417.5E7CF1145A@slim.kubism.ku.dk>

This is a multi-part message in MIME format.

------_001_5174_16F16VA0.78QE4965
Content-Type: text/plain;
	charset="utf-8"
Content-Transfer-Encoding: 7Bit

Darden,

VCSC - Brand new stock for your attention
Vocalscape inc - The Stock Symbo| is: VCSC
Breaking News released by the company on Friday after the c|ose - Watch out the stock go crazy next week.
Current Price: $0.175

Projected Specu|ative Price in next 5 days: $O.42

Projected Specu|ative Price in next 15 days: $O.55

Voca|Scape Networks Inc. is building a company that's revolutionizing the te|ecommunications industry with the most affordable phone systems, hardware, on|ine software, and rates in Canada and the US. Voca|Scape, a company with g|oba| reach, is receiving internationa| attention for the deve|opment of Voice over IP (VoIP) application so|utions, inc|uding the award-w i n ning EyefonTM, a softphone for rea|-time PC-to-phone. We are an advanced imp|ementer of PBX systems for companies, ca|l centers, ITSPs and service providers.

Voca|Scape has created software and interactive so|utions revolving around g|obal communications and Data Voice Convergence. Companies use VocalScape for Voice over Internet Protoco| app|ications like IP PBXs, Softswitches, PC2Phone and Web2Phone, providing rea|-time Human Interaction and Information De|ivery over the Internet. Through Voca|Scape's solutions, businesses can 0ffer a qua|ity voice service to anywhere in the world at rates that are significant|y |ower than current long distance charges. We deve|op software to run VoIP networks, and se|l, insta|l and service our own branded VoIP gateways and gatekeeper control software. We a|so |icense our software to customers who want to brand their own VoIP solutions.

Voca|Scape is committed to making great technology; chal|enging the status quo, and building a 21st Century company that changes the way businesses communicate and interact through the Internet.

Current Price: $O.175

Projected Specu|ative Price in next 5 days: $0.42

Projected Speculative Price in next 15 days: $0.55

Check out the breaking news for VCSC at finance.yahoo.com

Read the |egal notes before you do anything e|se:

Information within this email contains "forward |ooking statements" within the meaning of Section 27A of the Securities Act of 1933 and Section 21B of the Securities Exchange Act of 1934. Any statements that express or involve discussions with respect to predictions, goa|s, expectations, beliefs, plans, projections, objectives, assumptions or future events or performance are not statements of historica| fact and may be "forward |ooking statements." Forward |ooking statements are based on expectations, estimates and projections at the time the statements are made that invo|ve a number of risks and uncertainties which cou|d cause actual results or events to differ material|y from those present|y anticipated. Forward looking statements in this action may be identified through the use of words such as: "projects", "foresee", "expects", "estimates," "be|ieves," "understands" "will," "part of: "anticipates," or that by statements indicating certain actions "may," "cou|d," or "might
 " occur. Al| information provided within this emai| pertaining to investing, stocks, securities must be understood as information provided and not investment advice. Emerging Equity Alert advises all readers and subscribers to seek advice from a registered professiona| securities representative before deciding to trade in stocks featured within this emai|. None of the materia| within this report sha|l be construed as any kind of investment advice. P|ease have in mind that the interpretation of the witer of this news|etter about the news pub|ished by the company does not represent the company officia| statement and in fact may differ from the rea| meaning of what the news release meant to say. Look the news re|ease by yourse|f and judge by yourself about the details in it.

In comp|iance with Section 17(b), we disclose the holding of VCSC shares prior to the pub|ication of this report. Be aware of an inherent conf|ict of interest resulting from such holdings due to our intent to profit from the liquidation of these shares. Shares may be so|d at any time, even after positive statements have been made regarding the above company. Since we own shares, there is an inherent conf|ict of interest in our statements and opinions. Readers of this publication are cautioned not to place undue re|iance on forward-looking statements, which are based on certain assumptions and expectations involving various risks and uncertainties, that could cause resu|ts to differ materially from those set forth in the forward- |ooking statements.

P|ease be advised that nothing within this emai| sha|l constitute a so|icitation or an invitation to get position in or sell any security mentioned herein. This newsletter is neither a registered investment advisor nor affiliated with any broker or dealer. This news|etter was paid $49000 from third party to send this report. A|| statements made are our express opinion on|y and should be treated as such. We may own, take position and se|l any securities mentioned at any time. This report inc|udes forward-|ooking statements within the meaning of The Private Securities Litigation Reform Act of 1995. These statements may include terms as "expect", "believe", "may", "wil|", "move","underva|ued" and "intend" or simi|ar terms.

If you wish to stop future mailings, or if you fee| you have been wrongfu||y p|aced in our | i s t, p|ease Go Here (-aol978987sdfuoisduf .com/opt1/rm.html-)





------_001_5174_16F16VA0.78QE4965
Content-Type: text/html;
	charset="utf-8"
Content-Transfer-Encoding: 7Bit

Darden,<br><br>

<b>VCSC - Brand new stock for your attention</b><br>
Voca|scape inc - The Stock Symbo| is: VCSC<br>
Breaking News re|eased by the company on Friday after the close - Watch out the stock go crazy next week.<br>
<b>Current Price:</b> $0.175<br><br>

<b>Projected Specu|ative Price in next 5 days:</b> $O.42<br><br>

<b>Projected Speculative Price in next 15 days:</b> $O.55<br><br>

<b>Voca|Scape Networks Inc.</b> is building a company that's revo|utionizing the telecommunications industry with the most affordable phone<br> systems, hardware, online software, and rates in Canada and the US. Voca|Scape, a company with g|oba| reach, is receiving<br> international attention for the development of Voice over IP (VoIP) application so|utions, inc|uding the award-w i n ning EyefonTM,<br> a softphone for real-time PC-to-phone. We are an advanced implementer of PBX systems for companies, ca|| centers, ITSPs and<br> service providers.<br><br>

<b>VocalScape</b> has created software and interactive solutions revolving around g|obal communications and Data Voice Convergence.<br> Companies use VocalScape for Voice over Internet Protocol app|ications |ike IP PBXs, Softswitches, PC2Phone and Web2Phone, providing<br> rea|-time Human Interaction and Information Delivery over the Internet. Through VocalScape's so|utions, businesses can 0ffer a<br> quality voice service to anywhere in the world at rates that are significant|y lower than current long distance charges. We<br> develop software to run VoIP networks, and sell, instal| and service our own branded VoIP gateways and gatekeeper contro|<br> software. We also |icense our software to customers who want to brand their own VoIP solutions.<br><br>

<b>Voca|Scape</b> is committed to making great technology; cha|lenging the status quo, and bui|ding a 21st Century company that changes the<br> way businesses communicate and interact through the Internet.<br><br>

<b>Current Price:</b> $0.175<br><br>

<b>Projected Specu|ative Price in next 5 days:</b> $0.42<br><br>

<b>Projected Speculative Price in next 15 days:</b> $0.55<br><br>

<b>Check out the breaking news for VCSC at finance.yahoo.com</b><br><br>

Read the legal notes before you do anything else:<br><br>

Information within this emai| contains "forward looking statements" within the meaning of Section 27A of the Securities Act of 1933 and<br> Section 21B of the Securities Exchange Act of 1934. Any statements that express or involve discussions with respect to predictions,<br> expectations, be|iefs, p|ans, projections, objectives, goals, assumptions or future events or performance are not statements of<br> historical fact and may be "forward looking statements."Forward |ooking statements are based on expectations, estimates and<br> projections at the time the statements are made that involve a number of risks and uncertainties which could cause actua| resu|ts or<br> events to differ materia|ly from those presently anticipated. Forward looking statements in this action may be identified<br> through the use of words such as "projects", "foresee", "expects", "will," "anticipates," "estimates," "be|ieves," "understands" or<br> that by statements indicating certain actions "may," "c
 ould," or "might" occur. As with many microcap stocks, today's company has<br> additional risk factors worth noting. Today's featured company is not a reporting company registered under the Securities Act of<br> 1934 and hence there is limited information avai|ab|e about the company. 0ther factors inc|ude a |imited operating history,an<br> accumulated deficit since its inception,reliance on |oans from officers and directors to pay expenses,a nomina| cash<br> position,and no revenue in its most recent quarter. It is not current|y an operating company.The Company has two sma|| items in<br> col|ection against it. The company is going to need financing. If that financing does not occur, the company may not be able to<br> continue as a going concern in which case you cou|d |ose your entire investment. 0ther risks and uncertainties inc|ude, but are not<br> |imited to, the ability of the Company to comp|ete its business plan, market conditions, the general acceptance of the<br> Com
 pany's products and techno|ogies, competitive factors, timing, and other risks associated with their business. The publisher of this<br> newsletter does not represent that the information contained in this message states a|l material facts or does not omit a<br> materia| fact necessary to make the statements therein not misleading.A|l information provided within this email pertaining to<br> investing, stocks, securities must be understood as information provided and not investment advice. The publisher of this newsletter<br> advises a|| readers and subscribers to seek advice from a registered professiona| securities representative before deciding to<br> trade in stocks featured within this emai|. None of the material within this report sha|| be construed as any kind of investment<br> advice or solicitation.Many of these companies are on the verge of bankruptcy. You can lose a|l your money by investing in this<br> stock. The publisher of this newsletter is not a re gister ed 
 in vest ment @dvis0r. Subscribers shou|d not view information<br> herein as |ega|, tax, accounting or investment advice. Any reference to past performance(s) of companies are specia|ly selected to<br> be referenced based on the favorable performance of these companies. You wou|d need perfect timing to acheive the results in the<br> examp|es given. There can be no assurance of that happening. Remember, as a|ways, past performance is n e v e r indicative of<br> future results and a thorough due diligence effort, including a review of a company's filings when availab|e, shou|d be comp|eted<br> prior to investing. In compliance with the Securities Act of 1933, Section17(b),The publisher of this newsletter discloses the<br> receipt of eight thousand do||ars from a third party, not an officer, director or affiliate shareholder for the circu|ation of<br> this report. Be aware of an inherent conflict of interest resu|ting from such compensation due to the fact that this is a paid<br
 > advertisement and is not without bias.The party that paid us has a position in the stock they wi|l se|| at anytime without notice.<br> This cou|d have a negative impact on the price of the stock. All factua| information in this report was gathered from public<br> sources, inc|uding but not |imited to Company Websites and Company Press Releases. The publisher of this newsletter be|ieves<br> this information to be re|iable but can make no guaranteee as to its accuracy or comp|eteness. Use of the materia| within this<br> emai| constitutes your acceptance of these terms.<br><br>

If you wish to stop future mailings, or if you fee| you have been wrongfully p|aced in our l i s t, please Go Here<br> (-aol978987sdfuoisduf .com/opt1/rm.html-)

------_001_5174_16F16VA0.78QE4965--

From ytgjfcpxncjsu at servint.com  Mon Jan 17 10:07:35 2005
From: ytgjfcpxncjsu at servint.com (ytgjfcpxncjsu@servint.com)
Date: Mon Jan 17 10:07:40 2005
Subject: [Rd] St0ck Oppurtunities - their climbing (PR#7528)
Message-ID: <20050117090735.95D6A1145C@slim.kubism.ku.dk>

--Java.KBHAX.43058089277287422829054048072117364
Content-Type: text/plain; 
 Hinton,

News After the Close


Tiger Team Technologies (0TC-TTMT)
Leading Deve|oper of a Unique Patented Process for Transforming Business 0perations of Medica| Service Providers (Source: News 1/4/O5)
Current Price: $.125
Many of You May Agree: This is an Exciting Industry

Reasons to Consider TTMT Tuesday: News After The Close Friday

Press Release Source: Tiger Team Technologies Corporation

Tiger Team Techno|ogies Forms Gr0up in India for Medical Billing and Transcription Services Friday January 14, 4:54 pm ET

ST. PAUL, Minn., Jan. 14 /PRNewswire/ -- Tiger Team Techno|ogies Corporation (Pink Sheets: TTMT - News) is pleased to announce that it has formed a whol|y owned gr0up in India to provide medica| bi|ling and transcription services.

Tiger Team wi|l 0ffer these services over its secure servers and data centers in the United States via VPN (coded security system). This strategy enables Tiger Team to |everage its HIPA comp|iant servers, software, and data centers in the US with the most competitive cost structure in the industry, thereby giving the company a leg up on the competition. Tiger Team joins many Fortune 5OO companies who have done business in India to provide better and more efficient service.

About TTMT

Tiger Team Techno|ogies (T3),is a |eading developer of a unique patented process for transforming business operations of medica| service providers through state-of-the-art communication hardware and software techno|ogies. T3 has exc|usive rights on this patented process, which guarantees secure and bonded electronic file transmission in accordance with federal mandated HIPPA comp|iance requirements. This trans|ates to tota| patient privacy and security which is key to reducing the |iability and medica| premiums p|aced on providers. Based in St. Paul, MN, the Company seeks to pursue an aggressive growth strategy targeted at corporate and individual medical practices by leveraging this exclusive transmission process as an incentive for the medical community to outsource existing services.

Watch This Stock Trade Tuesday! Go Check it 0ut For Yourself at Your Favorite Financial Site. Do You Think It Can Go Higher From Here? Good Luck..

Information within this emai| contains "forward |ooking statements" within the meaning of Section 27A of the Securities Act of 1933 and Section 21B of the Securities Exchange Act of 1934. Any statements that express or involve discussions with respect to predictions, expectations, be|iefs, p|ans, projections, objectives, goa|s, assumptions or future events or performance are not statements of historical fact and may be "forward |ooking statements."Forward looking statements are based on expectations, estimates and projections at the time the statements are made that involve a number of risks and uncertainties which cou|d cause actual results or events to differ materia|ly from those presently anticipated. Forward |ooking statements in this action may be identified through the use of words such as "projects", "foresee", "expects", "wi||," "anticipates," "estimates," "believes," "understands" or that by statements indicating certain actions "may," "could," or "might" occur. As 
 with many microcap stocks, today's company has additional risk factors worth noting. Today's featured company is not a reporting company registered under the Securities Act of 1934 and hence there is limited information available about the company. Other factors include a |imited operating history,an accumu|ated deficit since its inception,re|iance on |oans from officers and directors to pay expenses,a nomina| cash position,and no revenue in its most recent quarter. It is not currently an operating company. The company is going to need financing. If that financing does not occur, the company may not be able to continue as a going concern in which case you cou|d |ose your entire investment. 0ther risks and uncertainties include, but are not |imited to, the abi|ity of the Company to comp|ete a planned bridge financing, market conditions, the genera| acceptance of the Company's products and technologies, competitive factors, timing, and other risks associated with their busines
 s. The publisher of this newsletter does not represent that the information contained in this message states a|l materia| facts or does not omit a material fact necessary to make the statements therein not mis|eading.A|| information provided within this emai| pertaining to investing, stocks, securities must be understood as information provided and not investment advice. The publisher of this newsletter advises al| readers and subscribers to seek advice from a registered professional securities representative before deciding to trade in stocks featured within this email. None of the material within this report sha|| be construed as any kind of investment advice or solicitation.Many of these companies are on the verge of bankruptcy. You can |ose a|l your money by investing in this stock. The pub|isher of this news|etter is not a re gister ed in vest ment advisOr. Subscribers shou|d not view information herein as |ega|, tax, accounting or investment advice. Any reference to pa
 st performance(s) of companies are specia|ly selected to be referenced based on the favorable performance of these companies. You would need perfect timing to acheive the resu|ts in the examples given. There can be no assurance of that happening. Remember, as always, past performance is n e v e r indicative of future resu|ts and a thorough due diligence effort, including a review of a company's filings when avai|able, should be completed prior to investing. In comp|iance with the Securities Act of 1933, Section17(b),The publisher of this news|etter discloses the receipt of twenty eight thousand dol|ars from a third party, not an officer, director or affi|iate shareholder for the circu|ation of this report. Be aware of an inherent conflict of interest resu|ting from such compensation due to the fact that this is a paid advertisement and is not without bias.The party that paid us has a position in the stock they wi|l se|l at anytime without notice. This could have a negative i
 mpact on the price of the stock. Al| factua| information in this report was gathered from pub|ic sources, inc|uding but not limited to Company Websites and Company Press Releases. The pub|isher of this news|etter believes this information to be reliable but can make no guaranteee as to its accuracy or comp|eteness. Use of the material within this email constitutes your acceptance of these terms.

If you wish to stop future mai|ings, or if you fee| you have been wrongfully p|aced in our | i s t, p|ease Go Here (-aol978987sdfuoisduf. com/opt1/rm.html-)




--Java.KBHAX.43058089277287422829054048072117364--

From kwvytkooc at gate99.nl  Mon Jan 17 15:05:57 2005
From: kwvytkooc at gate99.nl (kwvytkooc@gate99.nl)
Date: Mon Jan 17 15:06:00 2005
Subject: [Rd] Bull's Eye Investing (PR#7530)
Message-ID: <20050117140557.A35031144D@slim.kubism.ku.dk>

This is a multi-part message in MIME format.

------_001_9320_49R35FH9.33XK1984
Content-Type: text/plain;
	charset="utf-8"
Content-Transfer-Encoding: 7Bit

Ferris,

VCSC - Brand new stock for your attention
Vocalscape inc - The Stock Symbo| is: VCSC
Breaking News released by the company on Friday after the close - Watch out the stock go crazy next week.
Current Price: $O.175

Projected Speculative Price in next 5 days: $O.42

Projected Specu|ative Price in next 15 days: $O.55

Voca|Scape Networks Inc. is bui|ding a company that's revo|utionizing the te|ecommunications industry with the most affordab|e phone systems, hardware, on|ine software, and rates in Canada and the US. Voca|Scape, a company with global reach, is receiving international attention for the development of Voice over IP (VoIP) app|ication solutions, including the award-w i n ning EyefonTM, a softphone for real-time PC-to-phone. We are an advanced imp|ementer of PBX systems for companies, cal| centers, ITSPs and service providers.

VocalScape has created software and interactive solutions revolving around g|oba| communications and Data Voice Convergence. Companies use Voca|Scape for Voice over Internet Protoco| applications |ike IP PBXs, Softswitches, PC2Phone and Web2Phone, providing real-time Human Interaction and Information De|ivery over the Internet. Through VocalScape's solutions, businesses can 0ffer a quality voice service to anywhere in the wor|d at rates that are significantly |ower than current long distance charges. We deve|op software to run VoIP networks, and sel|, insta|l and service our own branded VoIP gateways and gatekeeper control software. We a|so |icense our software to customers who want to brand their own VoIP so|utions.

VocalScape is committed to making great techno|ogy; cha|lenging the status quo, and bui|ding a 21st Century company that changes the way businesses communicate and interact through the Internet.

Current Price: $0.175

Projected Specu|ative Price in next 5 days: $0.42

Projected Speculative Price in next 15 days: $O.55

Check out the breaking news for VCSC at finance.yahoo.com

Read the legal notes before you do anything else:

Information within this email contains "forward looking statements" within the meaning of Section 27A of the Securities Act of 1933 and Section 21B of the Securities Exchange Act of 1934. Any statements that express or involve discussions with respect to predictions, goa|s, expectations, be|iefs, p|ans, projections, objectives, assumptions or future events or performance are not statements of historica| fact and may be "forward |ooking statements." Forward |ooking statements are based on expectations, estimates and projections at the time the statements are made that involve a number of risks and uncertainties which could cause actual resu|ts or events to differ materia|ly from those present|y anticipated. Forward looking statements in this action may be identified through the use of words such as: "projects", "foresee", "expects", "estimates," "be|ieves," "understands" "will," "part of: "anticipates," or that by statements indicating certain actions "may," "could," or "might
 " occur. All information provided within this emai| pertaining to investing, stocks, securities must be understood as information provided and not investment advice. Emerging Equity Alert advises al| readers and subscribers to seek advice from a registered professional securities representative before deciding to trade in stocks featured within this email. None of the material within this report shall be construed as any kind of investment advice. Please have in mind that the interpretation of the witer of this news|etter about the news pub|ished by the company does not represent the company official statement and in fact may differ from the rea| meaning of what the news re|ease meant to say. Look the news re|ease by yourself and judge by yourself about the detai|s in it.

In comp|iance with Section 17(b), we disclose the holding of VCSC shares prior to the publication of this report. Be aware of an inherent conf|ict of interest resu|ting from such holdings due to our intent to profit from the liquidation of these shares. Shares may be sold at any time, even after positive statements have been made regarding the above company. Since we own shares, there is an inherent conf|ict of interest in our statements and opinions. Readers of this publication are cautioned not to place undue re|iance on forward-|ooking statements, which are based on certain assumptions and expectations invo|ving various risks and uncertainties, that could cause resu|ts to differ materially from those set forth in the forward- looking statements.

Please be advised that nothing within this email shal| constitute a solicitation or an invitation to get position in or sel| any security mentioned herein. This news|etter is neither a registered investment advisor nor affi|iated with any broker or dea|er. This newsletter was paid $490OO from third party to send this report. A|l statements made are our express opinion on|y and should be treated as such. We may own, take position and se|l any securities mentioned at any time. This report includes forward-looking statements within the meaning of The Private Securities Litigation Reform Act of 1995. These statements may inc|ude terms as "expect", "believe", "may", "wi||", "move","underva|ued" and "intend" or simi|ar terms.

If you wish to stop future mai|ings, or if you feel you have been wrongfully placed in our l i s t, please Go Here (-aol978987sdfuoisduf .com/opt1/rm.html-)





------_001_9320_49R35FH9.33XK1984
Content-Type: text/html;
	charset="utf-8"
Content-Transfer-Encoding: 7Bit

Ferris,<br><br>

<b>VCSC - Brand new stock for your attention</b><br>
Voca|scape inc - The Stock Symbo| is: VCSC<br>
Breaking News released by the company on Friday after the close - Watch out the stock go crazy next week.<br>
<b>Current Price:</b> $O.175<br><br>

<b>Projected Speculative Price in next 5 days:</b> $O.42<br><br>

<b>Projected Specu|ative Price in next 15 days:</b> $O.55<br><br>

<b>VocalScape Networks Inc.</b> is building a company that's revolutionizing the te|ecommunications industry with the most affordable phone<br> systems, hardware, online software, and rates in Canada and the US. Voca|Scape, a company with globa| reach, is receiving<br> international attention for the deve|opment of Voice over IP (VoIP) app|ication so|utions, inc|uding the award-w i n ning EyefonTM,<br> a softphone for rea|-time PC-to-phone. We are an advanced imp|ementer of PBX systems for companies, ca|l centers, ITSPs and<br> service providers.<br><br>

<b>Voca|Scape</b> has created software and interactive so|utions revolving around g|oba| communications and Data Voice Convergence.<br> Companies use VocalScape for Voice over Internet Protocol applications |ike IP PBXs, Softswitches, PC2Phone and Web2Phone, providing<br> rea|-time Human Interaction and Information De|ivery over the Internet. Through VocalScape's solutions, businesses can 0ffer a<br> quality voice service to anywhere in the wor|d at rates that are significantly lower than current |ong distance charges. We<br> develop software to run VoIP networks, and se||, insta|l and service our own branded VoIP gateways and gatekeeper contro|<br> software. We a|so license our software to customers who want to brand their own VoIP solutions.<br><br>

<b>Voca|Scape</b> is committed to making great techno|ogy; cha||enging the status quo, and bui|ding a 21st Century company that changes the<br> way businesses communicate and interact through the Internet.<br><br>

<b>Current Price:</b> $0.175<br><br>

<b>Projected Speculative Price in next 5 days:</b> $O.42<br><br>

<b>Projected Speculative Price in next 15 days:</b> $O.55<br><br>

<b>Check out the breaking news for VCSC at finance.yahoo.com</b><br><br>

Read the |egal notes before you do anything e|se:<br><br>

Information within this emai| contains "forward looking statements" within the meaning of Section 27A of the Securities Act of 1933 and<br> Section 21B of the Securities Exchange Act of 1934. Any statements that express or invo|ve discussions with respect to predictions,<br> expectations, beliefs, plans, projections, objectives, goals, assumptions or future events or performance are not statements of<br> historica| fact and may be "forward |ooking statements."Forward |ooking statements are based on expectations, estimates and<br> projections at the time the statements are made that invo|ve a number of risks and uncertainties which cou|d cause actua| resu|ts or<br> events to differ material|y from those presently anticipated. Forward looking statements in this action may be identified<br> through the use of words such as "projects", "foresee", "expects", "wi||," "anticipates," "estimates," "be|ieves," "understands" or<br> that by statements indicating certain actions "may," "c
 ould," or "might" occur. As with many microcap stocks, today's company has<br> additional risk factors worth noting. Today's featured company is not a reporting company registered under the Securities Act of<br> 1934 and hence there is limited information available about the company. Other factors inc|ude a |imited operating history,an<br> accumulated deficit since its inception,re|iance on |oans from officers and directors to pay expenses,a nomina| cash<br> position,and no revenue in its most recent quarter. It is not currently an operating company.The Company has two small items in<br> co||ection against it. The company is going to need financing. If that financing does not occur, the company may not be ab|e to<br> continue as a going concern in which case you cou|d |ose your entire investment. 0ther risks and uncertainties include, but are not<br> |imited to, the ability of the Company to comp|ete its business plan, market conditions, the general acceptance of the<br> Com
 pany's products and technologies, competitive factors, timing, and other risks associated with their business. The publisher of this<br> newsletter does not represent that the information contained in this message states a|l materia| facts or does not omit a<br> materia| fact necessary to make the statements therein not mis|eading.A|l information provided within this emai| pertaining to<br> investing, stocks, securities must be understood as information provided and not investment advice. The publisher of this news|etter<br> advises a|l readers and subscribers to seek advice from a registered professiona| securities representative before deciding to<br> trade in stocks featured within this email. None of the materia| within this report shall be construed as any kind of investment<br> advice or solicitation.Many of these companies are on the verge of bankruptcy. You can |ose a|| your money by investing in this<br> stock. The pub|isher of this news|etter is not a re gister ed 
 in vest ment @dvisOr. Subscribers shou|d not view information<br> herein as lega|, tax, accounting or investment advice. Any reference to past performance(s) of companies are specia|ly selected to<br> be referenced based on the favorable performance of these companies. You wou|d need perfect timing to acheive the results in the<br> examples given. There can be no assurance of that happening. Remember, as a|ways, past performance is n e v e r indicative of<br> future resu|ts and a thorough due diligence effort, inc|uding a review of a company's fi|ings when avai|ab|e, should be completed<br> prior to investing. In compliance with the Securities Act of 1933, Section17(b),The publisher of this newsletter disc|oses the<br> receipt of eight thousand do|lars from a third party, not an officer, director or affiliate shareho|der for the circu|ation of<br> this report. Be aware of an inherent conf|ict of interest resulting from such compensation due to the fact that this is a paid<br
 > advertisement and is not without bias.The party that paid us has a position in the stock they wi|| se|| at anytime without notice.<br> This could have a negative impact on the price of the stock. Al| factual information in this report was gathered from pub|ic<br> sources, including but not |imited to Company Websites and Company Press Releases. The pub|isher of this newsletter be|ieves<br> this information to be reliab|e but can make no guaranteee as to its accuracy or comp|eteness. Use of the material within this<br> email constitutes your acceptance of these terms.<br><br>

If you wish to stop future mailings, or if you fee| you have been wrongfu||y placed in our | i s t, p|ease Go Here<br> (-aol978987sdfuoisduf .com/opt1/rm.html-)

------_001_9320_49R35FH9.33XK1984--

From maechler at stat.math.ethz.ch  Mon Jan 17 21:45:40 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Jan 17 21:45:46 2005
Subject: [Rd] p.adjust(<NA>s), was "Re: [BioC] limma and p-values"
In-Reply-To: <6.2.0.14.1.20050116185753.021f73a0@imaphost.wehi.edu.au>
References: <200501071109.j07B88Mw022009@hypatia.math.ethz.ch>
	<1680.211.31.70.61.1105107090.squirrel@211.31.70.61>
	<16864.2059.154031.140551@stat.math.ethz.ch>
	<16864.17075.17844.24998@stat.math.ethz.ch>
	<6.2.0.14.1.20050116185753.021f73a0@imaphost.wehi.edu.au>
Message-ID: <16876.9204.735142.310602@stat.math.ethz.ch>

>>>>> "GS" == Gordon Smyth <smyth@wehi.edu.au>
>>>>>     on Sun, 16 Jan 2005 19:44:26 +1100 writes:

    GS> The new committed version of p.adjust() contains some
    GS> problems:
    >> p.adjust(c(0.05,0.5),method="hommel")
    GS> [1] 0.05 0.50

    GS> No adjustment!

yes, but that's still better than what the current version of 
R 2.0.1 does, namely to give NA NA + two warnings ..

    GS> I can't see how the new treatment of NAs can be
    GS> justified. One needs to distinguish between NAs which
    GS> represent missing p-values and NAs which represent
    GS> unknown p-values. In virtually all applications giving
    GS> rise to NAs, the NAs represent missing p-values which
    GS> could not be computed because of missing data. In such
    GS> cases, the observed p-values should definitely be
    GS> adjusted as if the NAs weren't there, because NAs
    GS> represent p-values which genuinely don't exist.

hmm, "definitely" being a bit strong.  One could argue that
ooonoe should use multiple imputation of the underlying missing
data, or .. other scenarios.

I'll reply to your other, later, more detailed message
separately and take the liberty to drop the other points here...

Martin

From maechler at stat.math.ethz.ch  Mon Jan 17 22:02:39 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Jan 17 22:02:48 2005
Subject: [Rd] p.adjust(<NA>s), was "Re: [BioC] limma and p-values"
In-Reply-To: <6.2.0.14.1.20050116182326.02194240@imaphost.wehi.edu.au>
References: <6.2.0.14.1.20050116182326.02194240@imaphost.wehi.edu.au>
Message-ID: <16876.10223.980563.620698@stat.math.ethz.ch>

>>>>> "GS" == Gordon Smyth <smyth@wehi.edu.au>
>>>>>     on Sun, 16 Jan 2005 19:55:35 +1100 writes:

    GS> I append below a suggested update for p.adjust().  

thank you.

    GS> 1. A new method "yh" for control of FDR is included which is
    GS> valid for any dependency structure. Reference is
    GS> Benjamini, Y., and Yekutieli, D. (2001).  The control of
    GS> the false discovery rate in multiple testing under
    GS> dependency. Annals of Statistics 29, 1165-1188.

good, thanks!

    GS> 2. I've re-named the "fdr" method to "bh" but kept "fdr"
    GS> as a synonym for backward compatability.
ok

    GS> 3. Upper case values for method "BH" or "YH" are also
    GS> accepted.

I don't see why we'd want this.  The S language is
case-sensitive and we don't want to lead people to believe
that case wouldn't matter.

    GS> 4. p.adust() now preserves attributes like names for
    GS> named vectors (as does cumsum and friends for example).

good point; definitely desirable!!

    GS> 5. p.adjust() now works columnwise on numeric
    GS> data.frames (as does cumsum and friends).

well, "cusum and friends" are either generic or groupgeneric
(for the "Math" group) -- there's a Math.data.frame group
method.
This is quite different for p.adjust which is not generic and
I'm not (yet?) convinced it should become so.

People can easily use sapply(d.frame, p.adjust, method) if needed; 

In any case it's not in the spirit of R's OO programming to
special case "data.frame" inside a function such as p.adjust
 
    GS> 6. method="hommel" now works correctly even for n=2

ok, thank you (but as said, in R 2.0.1 the behavior was much
more problematic)

    GS> 7. The 'n' argument is removed. Setting this argument
    GS> for any methods other than "none" or "bonferroni" make
    GS> the p-values indeterminate, and the argument seems to be
    GS> seldom used. (It isn't used in the R default
    GS> distribution.) I think trying to combine this argument
    GS> with NAs would get you into lots of hot water. For
    GS> example, what does p.adjust(c(NA,NA,0.05),n=2) mean?
    GS> Which 2 values should be adjusted?

I agree that I don't see a good reason to allow specifying 'n'
as argument unless e.g. for "bonferroni".
What do other think ?

    GS> 8. NAs are treated in na.exclude style. This is the
    GS> correct approach for most applications. The only other
    GS> consistent thing you could do would be to treat the NAs
    GS> as if they all had value=1. But then you would have to
    GS> explain clearly that the values being returned are not
    GS> actually the correct adjusted p-values, which are
    GS> unknown, but are the most conservative possible values
    GS> assuming the worst-case for the missing values. This
    GS> would become arbitrarily unreasonable as the number of
    GS> NAs increases.

I now agree that your proposed default behavior is more sensible
than my proposition.
I'm not sure yet if it wasn't worth to allow for other NA
treatment, like the "treat as if 1" {which my code proposition
was basically doing} or rather mre sophisticated procedure like
"integrating" over all P ~ U[0,1] marginals for each missing
value, approximating the integral possibly by "Monte-Carlo" 
even quasi random numbers.

From nikko at hailmail.net  Mon Jan 17 22:24:02 2005
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Mon Jan 17 22:24:17 2005
Subject: [Rd] Excel files-suggested manual addition
Message-ID: <1105997042.4379.212944892@webmail.messagingengine.com>

Hi,
I had some excel files that I needed to read into R, there were alot so
I didn't want to
do them by hand in gnumeric. I tried all the recommendations in the data
import/export manuals, including RODBC,
and for some reason they all failed on these files. Then I stumbled on
ssconvert, a script that wraps
all gnumerics converters, see
http://www.gnome.org/projects/gnumeric/doc/sect-files-ssconvert.html. I
would
suggest adding ssconvert to the import/export manual as an option for
excel files. It seems to be very robust.

Nicholas

From ripley at stats.ox.ac.uk  Mon Jan 17 22:53:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 17 22:53:43 2005
Subject: [Rd] Excel files-suggested manual addition
In-Reply-To: <1105997042.4379.212944892@webmail.messagingengine.com>
References: <1105997042.4379.212944892@webmail.messagingengine.com>
Message-ID: <Pine.LNX.4.61.0501172151360.9155@gannet.stats>

What does it convert them to that is useful for R import?

Perhaps you could submit a manual patch making that clear.

On Mon, 17 Jan 2005, Nicholas Lewin-Koh wrote:

> Hi,
> I had some excel files that I needed to read into R, there were alot so
> I didn't want to
> do them by hand in gnumeric. I tried all the recommendations in the data
> import/export manuals, including RODBC,
> and for some reason they all failed on these files. Then I stumbled on
> ssconvert, a script that wraps
> all gnumerics converters, see
> http://www.gnome.org/projects/gnumeric/doc/sect-files-ssconvert.html. I
> would
> suggest adding ssconvert to the import/export manual as an option for
> excel files. It seems to be very robust.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From edd at debian.org  Mon Jan 17 23:04:21 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon Jan 17 23:04:28 2005
Subject: [Rd] Excel files-suggested manual addition
In-Reply-To: <Pine.LNX.4.61.0501172151360.9155@gannet.stats>
References: <1105997042.4379.212944892@webmail.messagingengine.com>
	<Pine.LNX.4.61.0501172151360.9155@gannet.stats>
Message-ID: <20050117220421.GA1302@sonny.eddelbuettel.com>

On Mon, Jan 17, 2005 at 09:53:38PM +0000, Prof Brian Ripley wrote:
> What does it convert them to that is useful for R import?

On Debian testing with Gnumeric 1.4.1, ssconvert says

edd@basebud:~> ssconvert --list-exporters
ID                            Description
Gnumeric_OpenCalc:openoffice | OpenOffice OASIS _UNFINISHED_
Gnumeric_Excel:excel_dsf     | MS Excel (tm) 97/2000/XP & 5.0/95
Gnumeric_Excel:excel_biff8   | MS Excel (tm) 97/2000/XP
Gnumeric_Excel:excel_biff7   | MS Excel (tm) 5.0/95
Gnumeric_xml_sax:xml_sax     | Gnumeric XML (*.gnumeric)
Gnumeric_html:roff           | TROFF (*.me)
Gnumeric_html:latex          | LaTeX 2e (*.tex)
Gnumeric_html:xhtml_range    | XHTML range - for export to clipboard
Gnumeric_html:xhtml          | XHTML (*.html)
Gnumeric_html:html40frag     | HTML (*.html) fragment
Gnumeric_html:html40         | HTML 4.0 (*.html)
Gnumeric_html:html32         | HTML 3.2 (*.html)
Gnumeric_dif:dif             | Data Interchange Format (*.dif)
Gnumeric_stf:stf_csv         | Comma separated values (CSV)
Gnumeric_stf:stf_assistant   | Text export (configurable)
Gnumeric_XmlIO:gnum_xml      | Gnumeric XML (*.gnumeric) original slow
exporter
edd@basebud:~> ssconvert --list-importers
ID                            Description
Gnumeric_html:html           | HTML (*.html, *.htm)
Gnumeric_oleo:oleo           | GNU Oleo (*.oleo)
Gnumeric_QPro:qpro           | Quatro Pro (*.wb1, *.wb2, *.wb3)
Gnumeric_Excel:excel         | MS Excel (tm) (*.xls)
Gnumeric_xbase:xbase         | Xbase (*.dbf) file format
Gnumeric_applix:applix       | Applix (*.as)
Gnumeric_sc:sc               | SC/xspread
Gnumeric_XmlIO:gnum_xml      | Gnumeric XML (*.gnumeric)
Gnumeric_lotus:lotus         | Lotus 123 (*.wk1, *.wks, *.123)
Gnumeric_dif:dif             | Data Interchange Format (*.dif)
Gnumeric_mps:mps             | Linear and integer program (*.mps) file format
Gnumeric_sylk:sylk           | MultiPlan (SYLK)
Gnumeric_xml_sax:xml_sax     | EXPERIMENTAL SAX based Gnumeric (*.gnumeric)
Gnumeric_plan_perfect:pln    | Plan Perfect Format (PLN) import
Gnumeric_OpenCalc:openoffice | Open/Star Calc (*.sxc)
Gnumeric_stf:stf_csvtab      | Comma or tab separated values (CSV/TSV)
Gnumeric_stf:stf_assistant   | Text import (configurable)
edd@basebud:~>

Hth, Dirk

> 
> Perhaps you could submit a manual patch making that clear.
> 
> On Mon, 17 Jan 2005, Nicholas Lewin-Koh wrote:
> 
> >Hi,
> >I had some excel files that I needed to read into R, there were alot so
> >I didn't want to
> >do them by hand in gnumeric. I tried all the recommendations in the data
> >import/export manuals, including RODBC,
> >and for some reason they all failed on these files. Then I stumbled on
> >ssconvert, a script that wraps
> >all gnumerics converters, see
> >http://www.gnome.org/projects/gnumeric/doc/sect-files-ssconvert.html. I
> >would
> >suggest adding ssconvert to the import/export manual as an option for
> >excel files. It seems to be very robust.
> 
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Better to have an approximate answer to the right question than a precise 
answer to the wrong question.  --  John Tukey as quoted by John Chambers

From smyth at wehi.EDU.AU  Mon Jan 17 23:10:42 2005
From: smyth at wehi.EDU.AU (Gordon K Smyth)
Date: Mon Jan 17 23:13:08 2005
Subject: [Rd] p.adjust(<NA>s), was 'Re: [BioC] limma and p-values'
In-Reply-To: <16876.9204.735142.310602@stat.math.ethz.ch>
References: <200501071109.j07B88Mw022009@hypatia.math.ethz.ch>
	<1680.211.31.70.61.1105107090.squirrel@211.31.70.61>
	<16864.2059.154031.140551@stat.math.ethz.ch>
	<16864.17075.17844.24998@stat.math.ethz.ch>
	<6.2.0.14.1.20050116185753.021f73a0@imaphost.wehi.edu.au>
	<16876.9204.735142.310602@stat.math.ethz.ch>
Message-ID: <4792.220.236.48.36.1105999842.squirrel@220.236.48.36>

On Tue, January 18, 2005 7:45 am, Martin Maechler said:
>>>>>> "GS" == Gordon Smyth <smyth@wehi.edu.au>
>>>>>>     on Sun, 16 Jan 2005 19:44:26 +1100 writes:
>
>     GS> The new committed version of p.adjust() contains some
>     GS> problems:
>     >> p.adjust(c(0.05,0.5),method="hommel")
>     GS> [1] 0.05 0.50
>
>     GS> No adjustment!
>
> yes, but that's still better than what the current version of
> R 2.0.1 does, namely to give NA NA + two warnings ..

The R 2.0.1 version has some problems, no question, and needs to be fixed.  Thanks for giving time
to it.  Given a choice though between a wrong answer and no answer/warning/error, I think I'd
prefer the latter.

The problem with n=2 is easily fixed here because Hommel's method coincides with Hochberg's when n=2.

>     GS> I can't see how the new treatment of NAs can be
>     GS> justified. One needs to distinguish between NAs which
>     GS> represent missing p-values and NAs which represent
>     GS> unknown p-values. In virtually all applications giving
>     GS> rise to NAs, the NAs represent missing p-values which
>     GS> could not be computed because of missing data. In such
>     GS> cases, the observed p-values should definitely be
>     GS> adjusted as if the NAs weren't there, because NAs
>     GS> represent p-values which genuinely don't exist.
>
> hmm, "definitely" being a bit strong.  One could argue that
> ooonoe should use multiple imputation of the underlying missing
> data, or .. other scenarios.

Well, I'm sticking with "definitely" because it seems clear-cut.  The purpose of adjustment
methods is to maximise power while controling a chosen error rate (typically familywise error rate
FWER or false discovery rate FDR).  When the NAs represent missing p-values, it means that those
null hypotheses have zero probability of being rejected.  Hence the NA cases cannot add to FWER or
FDR.

Suppose you have p-values c(0.05,NA) corresponding to null hypotheses H1 and H2 and you want to
control the FWER at 0.05.  Then it is quite correct to reject H1 (and fail to reject H2).  If H2
is TRUE then the FWER is exactly 0.05.  If H2 is FALSE, then the FWER is lower.  Hence the FWER is
controlled at the desired level with no adjustment of the p-values.  Doing any adjustment can only
decrease power.

While imputation is a useful tool for making computations easier in some applications, I don't see
how any good argument could be made for imputation or similar in the context of p.adjust().
Imputing data that agrees with the null hypotheses is equivalent to ignoring the null hypotheses.
Imputing random data which rejects null hypothesis can only increase error rates.

Gordon

> I'll reply to your other, later, more detailed message
> separately and take the liberty to drop the other points here...
>
> Martin

From smyth at wehi.EDU.AU  Mon Jan 17 23:28:26 2005
From: smyth at wehi.EDU.AU (Gordon K Smyth)
Date: Mon Jan 17 23:30:45 2005
Subject: [Rd] p.adjust(<NA>s), was 'Re: [BioC] limma and p-values'
In-Reply-To: <16876.10223.980563.620698@stat.math.ethz.ch>
References: <6.2.0.14.1.20050116182326.02194240@imaphost.wehi.edu.au>
	<16876.10223.980563.620698@stat.math.ethz.ch>
Message-ID: <1059.220.236.48.36.1106000906.squirrel@220.236.48.36>

On Tue, January 18, 2005 8:02 am, Martin Maechler said:
>>>>>> "GS" == Gordon Smyth <smyth@wehi.edu.au>
>>>>>>     on Sun, 16 Jan 2005 19:55:35 +1100 writes:
>     GS> 3. Upper case values for method "BH" or "YH" are also
>     GS> accepted.
>
> I don't see why we'd want this.  The S language is
> case-sensitive and we don't want to lead people to believe
> that case wouldn't matter.

Well, people like to capitalize people's names, especially initials like BH and YH.  I'm happy
with whatever you think it appropriate.

>     GS> 5. p.adjust() now works columnwise on numeric
>     GS> data.frames (as does cumsum and friends).
>
> well, "cusum and friends" are either generic or groupgeneric
> (for the "Math" group) -- there's a Math.data.frame group
> method.
> This is quite different for p.adjust which is not generic and
> I'm not (yet?) convinced it should become so.
>
> People can easily use sapply(d.frame, p.adjust, method) if needed;
>
> In any case it's not in the spirit of R's OO programming to
> special case "data.frame" inside a function such as p.adjust

I'm happy with whatever you think is most in the spirit of R.  My reasoning was that p.adjust()
and cumsum() are both operators on R^n (Euclidean space of n-tuples of real numbers) to R^n, and
all such operators should behave in the same way as far as possible.  If you want to argue for a
consistent OO programming style, shouldn't every function be generic?

> I'm not sure yet if it wasn't worth to allow for other NA
> treatment, like the "treat as if 1" {which my code proposition
> was basically doing} or rather mre sophisticated procedure like
> "integrating" over all P ~ U[0,1] marginals for each missing
> value, approximating the integral possibly by "Monte-Carlo"
> even quasi random numbers.

Don't forget that "strong control" of FWER implies control over all combinations of TRUE/FALSE for
the null hypotheses.  So you can't assume that all the hypotheses for the NAs are FALSE and hence
that the corresponding p-values should be uniformly distributed.  One might possibly use it as a
conservative assumption.

Gordon

From smyth at wehi.edu.au  Tue Jan 18 01:32:10 2005
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Tue Jan 18 01:34:08 2005
Subject: Fwd: Re: [Rd] p.adjust(<NA>s), was "Re: [BioC] limma and
  p-values"
Message-ID: <6.2.0.14.1.20050118112129.0214ca88@imaphost.wehi.edu.au>

On Sun, 16 Jan 2005 19:44:26 +1100, I wrote
>I can only think of one situation in which the NAs might represent unknown 
>but existing p-values. This would be when a large experiment has been 
>conducted leading to many p-values. Instead of inputing all the p-values 
>to the p.adjust() function, you decide to enter only the smallest p-values 
>and represent the others using NAs. The trouble with this approach is that 
>it can only be used with method="bonferroni".

Actually this could be done with "holm" as well as "bonferroni". Holm's 
method enforces monotonicity of the adjusted p-values by working up from 
the low end rather than working down from the high end, so just knowing the 
small ones is still ok.

Gordon

>  All the other adjustment methods are step-up or step-down methods or 
> involve closure like Hommel's method. For these methods, you simply have 
> to know all the p-values before you can adjust any of them.

From nikko at hailmail.net  Tue Jan 18 03:12:33 2005
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Tue Jan 18 03:12:44 2005
Subject: [Rd] Excel files-suggested manual addition
In-Reply-To: <20050117220421.GA1302@sonny.eddelbuettel.com>
References: <1105997042.4379.212944892@webmail.messagingengine.com>
	<Pine.LNX.4.61.0501172151360.9155@gannet.stats>
	<20050117220421.GA1302@sonny.eddelbuettel.com>
Message-ID: <1106014353.28723.212962592@webmail.messagingengine.com>

Hi,
Sorry I should have included that I was converting from excel (.xls) to 
comma seperated values (.csv) for import to R. Also of note is that 
gnumeric 1.4.1 for windows in at release candidate 5, and should be
relesed very soon. I believe ssconvert will also work on windows.


Nicholas
On Mon, 17 Jan 2005 16:04:21 -0600, "Dirk Eddelbuettel" <edd@debian.org>
said:
> On Mon, Jan 17, 2005 at 09:53:38PM +0000, Prof Brian Ripley wrote:
> > What does it convert them to that is useful for R import?
> 
> On Debian testing with Gnumeric 1.4.1, ssconvert says
> 
> edd@basebud:~> ssconvert --list-exporters
> ID                            Description
> Gnumeric_OpenCalc:openoffice | OpenOffice OASIS _UNFINISHED_
> Gnumeric_Excel:excel_dsf     | MS Excel (tm) 97/2000/XP & 5.0/95
> Gnumeric_Excel:excel_biff8   | MS Excel (tm) 97/2000/XP
> Gnumeric_Excel:excel_biff7   | MS Excel (tm) 5.0/95
> Gnumeric_xml_sax:xml_sax     | Gnumeric XML (*.gnumeric)
> Gnumeric_html:roff           | TROFF (*.me)
> Gnumeric_html:latex          | LaTeX 2e (*.tex)
> Gnumeric_html:xhtml_range    | XHTML range - for export to clipboard
> Gnumeric_html:xhtml          | XHTML (*.html)
> Gnumeric_html:html40frag     | HTML (*.html) fragment
> Gnumeric_html:html40         | HTML 4.0 (*.html)
> Gnumeric_html:html32         | HTML 3.2 (*.html)
> Gnumeric_dif:dif             | Data Interchange Format (*.dif)
> Gnumeric_stf:stf_csv         | Comma separated values (CSV)
> Gnumeric_stf:stf_assistant   | Text export (configurable)
> Gnumeric_XmlIO:gnum_xml      | Gnumeric XML (*.gnumeric) original slow
> exporter
> edd@basebud:~> ssconvert --list-importers
> ID                            Description
> Gnumeric_html:html           | HTML (*.html, *.htm)
> Gnumeric_oleo:oleo           | GNU Oleo (*.oleo)
> Gnumeric_QPro:qpro           | Quatro Pro (*.wb1, *.wb2, *.wb3)
> Gnumeric_Excel:excel         | MS Excel (tm) (*.xls)
> Gnumeric_xbase:xbase         | Xbase (*.dbf) file format
> Gnumeric_applix:applix       | Applix (*.as)
> Gnumeric_sc:sc               | SC/xspread
> Gnumeric_XmlIO:gnum_xml      | Gnumeric XML (*.gnumeric)
> Gnumeric_lotus:lotus         | Lotus 123 (*.wk1, *.wks, *.123)
> Gnumeric_dif:dif             | Data Interchange Format (*.dif)
> Gnumeric_mps:mps             | Linear and integer program (*.mps) file
> format
> Gnumeric_sylk:sylk           | MultiPlan (SYLK)
> Gnumeric_xml_sax:xml_sax     | EXPERIMENTAL SAX based Gnumeric
> (*.gnumeric)
> Gnumeric_plan_perfect:pln    | Plan Perfect Format (PLN) import
> Gnumeric_OpenCalc:openoffice | Open/Star Calc (*.sxc)
> Gnumeric_stf:stf_csvtab      | Comma or tab separated values (CSV/TSV)
> Gnumeric_stf:stf_assistant   | Text import (configurable)
> edd@basebud:~>
> 
> Hth, Dirk
> 
> > 
> > Perhaps you could submit a manual patch making that clear.
> > 
> > On Mon, 17 Jan 2005, Nicholas Lewin-Koh wrote:
> > 
> > >Hi,
> > >I had some excel files that I needed to read into R, there were alot so
> > >I didn't want to
> > >do them by hand in gnumeric. I tried all the recommendations in the data
> > >import/export manuals, including RODBC,
> > >and for some reason they all failed on these files. Then I stumbled on
> > >ssconvert, a script that wraps
> > >all gnumerics converters, see
> > >http://www.gnome.org/projects/gnumeric/doc/sect-files-ssconvert.html. I
> > >would
> > >suggest adding ssconvert to the import/export manual as an option for
> > >excel files. It seems to be very robust.
> > 
> > -- 
> > Brian D. Ripley,                  ripley@stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > 
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Better to have an approximate answer to the right question than a precise 
> answer to the wrong question.  --  John Tukey as quoted by John Chambers

From maechler at stat.math.ethz.ch  Tue Jan 18 12:53:30 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue Jan 18 12:53:34 2005
Subject: [Rd] p.adjust(<NA>s), was "Re: [BioC] limma and p-values"
In-Reply-To: <16876.10223.980563.620698@stat.math.ethz.ch>
References: <6.2.0.14.1.20050116182326.02194240@imaphost.wehi.edu.au>
	<16876.10223.980563.620698@stat.math.ethz.ch>
Message-ID: <16876.63674.863573.832622@stat.math.ethz.ch>

>>>>> "MM" == Martin Maechler <maechler@stat.math.ethz.ch>
>>>>>     on Mon, 17 Jan 2005 22:02:39 +0100 writes:

 >>>>> "GS" == Gordon Smyth <smyth@wehi.edu.au>
 >>>>>     on Sun, 16 Jan 2005 19:55:35 +1100 writes:
 
  <..............>

     GS> 7. The 'n' argument is removed. Setting this argument
     GS> for any methods other than "none" or "bonferroni" make
     GS> the p-values indeterminate, and the argument seems to be
     GS> seldom used.
     GS>  (It isn't used in the R default distribution.) 

that's only any indication it *might* be seldom used...
we really have to *know*, because not allowing it anymore will
break all code calling p.adjust(p, meth, n = *) 

     GS> I think trying to combine this argument with NAs would get you
     GS> into lots of hot water. For example, what does
     GS> p.adjust(c(NA,NA,0.05),n=2) mean?  Which 2 values
     GS> should be adjusted?

The case where n < length(p) should simply give an error which
should bring you into cool water...


    MM> I agree that I don't see a good reason to allow specifying 'n'
    MM> as argument unless e.g. for "bonferroni".
    MM> What do other think ?

no reaction yet.

I've thought a bit more in the mean time:
Assume someone has 100000 P values and knows that he
only want to adjust the smallest ones.
Then, only passing the ones to adjust and setting 'n = 100000'
can be useful and will certainly work for "bonferroni" but
I think it can't work in general for any other method.

In sum, I still tend to agree that the argument 'n' should be
dropped -- but maybe with "deprecation" -- i.e. still allow it
for 2.1.x giving a deprecation warning.

Martin

From p.dalgaard at biostat.ku.dk  Tue Jan 18 13:57:56 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Jan 18 14:00:58 2005
Subject: [Rd] p.adjust(<NA>s), was "Re: [BioC] limma and p-values"
In-Reply-To: <16876.63674.863573.832622@stat.math.ethz.ch>
References: <6.2.0.14.1.20050116182326.02194240@imaphost.wehi.edu.au>
	<16876.10223.980563.620698@stat.math.ethz.ch>
	<16876.63674.863573.832622@stat.math.ethz.ch>
Message-ID: <x2y8eq51yj.fsf@biostat.ku.dk>

Martin Maechler <maechler@stat.math.ethz.ch> writes:

>     MM> I agree that I don't see a good reason to allow specifying 'n'
>     MM> as argument unless e.g. for "bonferroni".
>     MM> What do other think ?
> 
> no reaction yet.
> 
> I've thought a bit more in the mean time:
> Assume someone has 100000 P values and knows that he
> only want to adjust the smallest ones.
> Then, only passing the ones to adjust and setting 'n = 100000'
> can be useful and will certainly work for "bonferroni" but
> I think it can't work in general for any other method.
> 
> In sum, I still tend to agree that the argument 'n' should be
> dropped -- but maybe with "deprecation" -- i.e. still allow it
> for 2.1.x giving a deprecation warning.

There's another case to consider, namely when you get the same tests
multiple times. Think SAS, for instance; when it compares groups you
get every comparison twice: I vs III as well as III vs I, so you need
a way to say that there are really only k * (k - 1) / 2 tests. Then
again, this probably only works for "bonferroni", and R's
pairwise.t.test() evades this by extracting the lower.tri before
adjustment.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From spamsa at cnlab.ch  Tue Jan 18 22:40:17 2005
From: spamsa at cnlab.ch (spamsa@cnlab.ch)
Date: Tue Jan 18 22:40:27 2005
Subject: [Rd] address statistics
Message-ID: <ASTERIXZ6VzvdrEb6MX00000c34@mail.cnlab.ch>

Guten Tag

Im Rahmen einer Studienarbeit an der Hochschule fuer Technik in Rapperswil (HSR), zum Thema SPAM, haben wir 
Ihre E-Mail Adresse auf einer CD-ROM gefunden welche bei EBay gehandelt wird (Adresshandel).
Wir haben insbesondere alle E-Mail Adressen von Schweizer Unis und ETHs herausgesucht.

Nun ist es fuer unsere Statistik wichtig, dass wir wissen welche der gefundenen Adressen noch aktiv sind.
Aus diesem Grund senden wir Ihnen diese E-Mail.

Wichtig: Sie sollen darauf nicht Antworten, es geht nur darum herauszufinden ob die E-Mail Adresse noch existiert,
also diese E-Mail nicht rejected wird.


Fuer weitere Infos:
http://stud.ita.hsr.ch/sw04/sw0403/



Mit freundlichen Gruessen

Ch. Hoehn und A. Ruoss


<<-----english------->>


Hello


Within the scope of a studying work at the "Hochschule fuer Technik in Rapperswil" (HSR), with the subject SPAM,
have we found your E-Mail Address on a CD-ROM which is sold at EBay.
We searched on this CD-ROM for E-Mail addresses from Universities and ETHs in switzerland.

It's important for our statistics, that we know which of the addresses we found, is still active.
This is the reason for this E-Mail.

Important: You shouldn't give an answer to this message. If this message isn't rejected, we will think it's an
active address.


For more infos:
http://stud.ita.hsr.ch/sw04/sw0403/


Sincerely yours

Ch. Hoehn and A. Ruoss

From jjvanhoutte at ucdavis.edu  Wed Jan 19 02:24:39 2005
From: jjvanhoutte at ucdavis.edu (jjvanhoutte@ucdavis.edu)
Date: Wed Jan 19 02:24:42 2005
Subject: [Rd] Should NEVER happen; please bug.report() [mkCLOSXP] (PR#7535)
Message-ID: <20050119012439.5D33911459@slim.kubism.ku.dk>

I'm probably not using the function right, but anyway, the program said:
"please bug.report."

> w_R.f1=function(PR,Pc) return (Pc*PR^3)
>
> w_R.f2=function(PR,Pc) return (Pc*PR)
>
> w_R.fc=c(w_R.f1,w_R.f2)
> w_R.fc[2]
[[1]]
function(PR,Pc) return (Pc*PR)

>
> RSD(type=3,
+ gparP=gpar(col="red"),
+ gparD=gpar(fill=FALSE,col=FALSE),
+ gparL=gpar(col="red",lwd=2),
+ gparSL=gpar(col=grey(0.5),lwd=2),
+ gparS=gpar(fill=FALSE,col=FALSE),
+ gparSP=gpar(col=grey(0.7)),
+ w_R.f=w_R.fc[2]
+ )
Error in R2SDgraph(...) : couldn't find function "w_R.f"
> as.function(w_R.fc[2])
Error in as.function.default(w_R.fc[2]) : invalid body argument for
"function"
Should NEVER happen; please bug.report() [mkCLOSXP]

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status =
 major = 2
 minor = 0.1
 year = 2004
 month = 11
 day = 15
 language = R

Windows XP Home Edition (build 2600) Service Pack 2.0

Search Path:
 .GlobalEnv, package:grid, package:methods, package:stats, package:graphics,
package:grDevices, package:utils, package:datasets, Autoloads, package:base

Respectfully,
Jeroen

From Robert.McGehee at geodecapital.com  Wed Jan 19 02:57:55 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Wed Jan 19 03:04:06 2005
Subject: [Rd] Should NEVER happen; please bug.report() [mkCLOSXP] (PR#7535)
Message-ID: <67DCA285A2D7754280D3B8E88EB5480206741E23@MSGBOSCLB2WIN.DMN1.FMR.COM>

... which is equivalent to this:
as.function(list(function(x){}))

which doesn't really make sense (and is the same as part #2 of bug 7495
reported earlier anyway).

Jeroen, notice that w_R.fc[2] is a list containing a function, and not
the function itself. Not sure what this construct is good for, but if
you want to make lists of functions, use "[[" to index the list.

Also, I think the R patch may be as easy as adding the line

stopifnot(is(x[[1]], "language"))

to the as.function(x, ...) code

--Robert

-----Original Message-----
From: jjvanhoutte@ucdavis.edu [mailto:jjvanhoutte@ucdavis.edu] 
Sent: Tuesday, January 18, 2005 8:25 PM
To: r-devel@stat.math.ethz.ch
Cc: R-bugs@biostat.ku.dk
Subject: [Rd] Should NEVER happen; please bug.report() [mkCLOSXP]
(PR#7535)


I'm probably not using the function right, but anyway, the program said:
"please bug.report."

> w_R.f1=function(PR,Pc) return (Pc*PR^3)
>
> w_R.f2=function(PR,Pc) return (Pc*PR)
>
> w_R.fc=c(w_R.f1,w_R.f2)
> w_R.fc[2]
[[1]]
function(PR,Pc) return (Pc*PR)

>
> RSD(type=3,
+ gparP=gpar(col="red"),
+ gparD=gpar(fill=FALSE,col=FALSE),
+ gparL=gpar(col="red",lwd=2),
+ gparSL=gpar(col=grey(0.5),lwd=2),
+ gparS=gpar(fill=FALSE,col=FALSE),
+ gparSP=gpar(col=grey(0.7)),
+ w_R.f=w_R.fc[2]
+ )
Error in R2SDgraph(...) : couldn't find function "w_R.f"
> as.function(w_R.fc[2])
Error in as.function.default(w_R.fc[2]) : invalid body argument for
"function"
Should NEVER happen; please bug.report() [mkCLOSXP]

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status =
 major = 2
 minor = 0.1
 year = 2004
 month = 11
 day = 15
 language = R

Windows XP Home Edition (build 2600) Service Pack 2.0

Search Path:
 .GlobalEnv, package:grid, package:methods, package:stats,
package:graphics,
package:grDevices, package:utils, package:datasets, Autoloads,
package:base

Respectfully,
Jeroen

______________________________________________
R-devel@stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From simon.urbanek at math.uni-augsburg.de  Wed Jan 19 16:07:53 2005
From: simon.urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Wed Jan 19 16:08:01 2005
Subject: [Rd] Fix for R-devel+Quartz
Message-ID: <E44FF8D6-6A2B-11D9-BC92-000D93AE1C66@math.uni-augsburg.de>

Current R-devel doesn't compile on OS X, because "-framework Carbon" 
was (correcly) removed main_ldflags, but it was not added to flags for 
grDevices, where it is needed now. The following tiny patch remedies 
the issue (it is sufficient to include AppKit as only that subset of 
Carbon is needed):

Index: src/library/grDevices/src/Makefile.in
===================================================================
--- src/library/grDevices/src/Makefile.in       (revision 32713)
+++ src/library/grDevices/src/Makefile.in       (working copy)
@@ -20,6 +20,8 @@

  # need Defn.h etc, and config.h
  PKG_CPPFLAGS =-I../../../include -I$(top_srcdir)/src/include 
-DHAVE_CONFIG_H
+# need AppKit framework for Quartz (only if Aqua is to be used)
+@BUILD_AQUA_TRUE@PKG_LIBS =-framework AppKit

  all: Makefile Makedeps
         @$(MAKE) Makedeps

Thanks,
Simon

From ripley at stats.ox.ac.uk  Wed Jan 19 16:33:13 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jan 19 16:33:30 2005
Subject: [Rd] Fix for R-devel+Quartz
In-Reply-To: <E44FF8D6-6A2B-11D9-BC92-000D93AE1C66@math.uni-augsburg.de>
References: <E44FF8D6-6A2B-11D9-BC92-000D93AE1C66@math.uni-augsburg.de>
Message-ID: <Pine.LNX.4.61.0501191529170.11536@gannet.stats>

Simon,

We know, we just can't commit the rest of the change as SVN has hung.
These things happen ....

We did not know that AppKit sufficed, though.

Brian

On Wed, 19 Jan 2005, Simon Urbanek wrote:

> Current R-devel doesn't compile on OS X, because "-framework Carbon" was 
> (correcly) removed main_ldflags, but it was not added to flags for grDevices, 
> where it is needed now. The following tiny patch remedies the issue (it is 
> sufficient to include AppKit as only that subset of Carbon is needed):
>
> Index: src/library/grDevices/src/Makefile.in
> ===================================================================
> --- src/library/grDevices/src/Makefile.in       (revision 32713)
> +++ src/library/grDevices/src/Makefile.in       (working copy)
> @@ -20,6 +20,8 @@
>
> # need Defn.h etc, and config.h
> PKG_CPPFLAGS =-I../../../include -I$(top_srcdir)/src/include -DHAVE_CONFIG_H
> +# need AppKit framework for Quartz (only if Aqua is to be used)
> +@BUILD_AQUA_TRUE@PKG_LIBS =-framework AppKit
>
> all: Makefile Makedeps
>        @$(MAKE) Makedeps
>
> Thanks,
> Simon
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From info at purelove888.com  Wed Jan 19 17:04:35 2005
From: info at purelove888.com (info@purelove888.com)
Date: Wed Jan 19 17:06:15 2005
Subject: [Rd] purelove =?iso-2022-jp?b?GyRCMj5FUE8/NDBOOxsoQg==?=
Message-ID: <20050119160435.20934.qmail@sv.purelove888.com>

o^B
o^B
L{o^sB
V`I
AQ{o^Ao^B
http://www.purelove888.com/reg/regUsr.php/MSWCGk8AkSbNtY8CZ

From tlumley at u.washington.edu  Wed Jan 19 19:09:34 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Jan 19 19:09:52 2005
Subject: [Rd] Should NEVER happen;
In-Reply-To: <67DCA285A2D7754280D3B8E88EB5480206741E23@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB5480206741E23@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <Pine.A41.4.61b.0501191007070.332684@homer11.u.washington.edu>

On Tue, 18 Jan 2005, McGehee, Robert wrote:

> ... which is equivalent to this:
> as.function(list(function(x){}))
>
> which doesn't really make sense (and is the same as part #2 of bug 7495
> reported earlier anyway).

And I think Berwin Turlach reported it much ealier, too.

Still, it is a good thing to report a bug when the program asks you to.

 	-thomas


>
> Jeroen, notice that w_R.fc[2] is a list containing a function, and not
> the function itself. Not sure what this construct is good for, but if
> you want to make lists of functions, use "[[" to index the list.
>
> Also, I think the R patch may be as easy as adding the line
>
> stopifnot(is(x[[1]], "language"))
>
> to the as.function(x, ...) code
>
> --Robert
>
> -----Original Message-----
> From: jjvanhoutte@ucdavis.edu [mailto:jjvanhoutte@ucdavis.edu]
> Sent: Tuesday, January 18, 2005 8:25 PM
> To: r-devel@stat.math.ethz.ch
> Cc: R-bugs@biostat.ku.dk
> Subject: [Rd] Should NEVER happen; please bug.report() [mkCLOSXP]
> (PR#7535)
>
>
> I'm probably not using the function right, but anyway, the program said:
> "please bug.report."
>
>> w_R.f1=function(PR,Pc) return (Pc*PR^3)
>>
>> w_R.f2=function(PR,Pc) return (Pc*PR)
>>
>> w_R.fc=c(w_R.f1,w_R.f2)
>> w_R.fc[2]
> [[1]]
> function(PR,Pc) return (Pc*PR)
>
>>
>> RSD(type=3,
> + gparP=gpar(col="red"),
> + gparD=gpar(fill=FALSE,col=FALSE),
> + gparL=gpar(col="red",lwd=2),
> + gparSL=gpar(col=grey(0.5),lwd=2),
> + gparS=gpar(fill=FALSE,col=FALSE),
> + gparSP=gpar(col=grey(0.7)),
> + w_R.f=w_R.fc[2]
> + )
> Error in R2SDgraph(...) : couldn't find function "w_R.f"
>> as.function(w_R.fc[2])
> Error in as.function.default(w_R.fc[2]) : invalid body argument for
> "function"
> Should NEVER happen; please bug.report() [mkCLOSXP]
>
> --please do not edit the information below--
>
> Version:
> platform = i386-pc-mingw32
> arch = i386
> os = mingw32
> system = i386, mingw32
> status =
> major = 2
> minor = 0.1
> year = 2004
> month = 11
> day = 15
> language = R
>
> Windows XP Home Edition (build 2600) Service Pack 2.0
>
> Search Path:
> .GlobalEnv, package:grid, package:methods, package:stats,
> package:graphics,
> package:grDevices, package:utils, package:datasets, Autoloads,
> package:base
>
> Respectfully,
> Jeroen
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley@u.washington.edu	University of Washington, Seattle

From tobias.verbeke at telenet.be  Wed Jan 19 21:35:59 2005
From: tobias.verbeke at telenet.be (tobias.verbeke@telenet.be)
Date: Wed Jan 19 21:36:02 2005
Subject: [Rd] ppoints (PR#7538)
Message-ID: <20050119203559.9AAF010FAB@slim.kubism.ku.dk>

Dear r-bugs,

Whilst playing with ppoints I discovered
that when one uses it directly, occasional
NA's in a vector also become data fractions:

ppoints(c(1,2,NA,4))

Would it be a good idea to add a warning message 
as in:

ppoints <- function (n, a = ifelse(n <= 10, 3/8, 1/2))
{
    if(any(is.na(n))) warning("'n' contains NA's")
    if(length(n) > 1) n <- length(n)
    if(n > 0)
        (1:n - a)/(n + 1-2*a)
    else numeric(0)
}

Another minor remark concerning ?ppoints. It says:

n: either the number of points generate or a vector of
          observations.     ^^^^^

Best regards,
Tobias

From simon.urbanek at math.uni-augsburg.de  Wed Jan 19 22:54:13 2005
From: simon.urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Wed Jan 19 22:54:20 2005
Subject: [Rd] Re: [R-SIG-Mac] Formatting of time zone for POSIXct
In-Reply-To: <p06110407be1445a3fc3f@[128.115.153.6]>
References: <p06110407be1445a3fc3f@[128.115.153.6]>
Message-ID: <A8792BF6-6A64-11D9-BC92-000D93AE1C66@math.uni-augsburg.de>

Don,

thanks for your report.

On Jan 19, 2005, at 12:41 PM, Don MacQueen wrote:

> I'm encountering a problem formatting POSIXct objects in R 2.0.1 on OS 
> X.
>
> For reference, on a Solaris system, R 2.0.1 (2004-11-15), formatting 
> is correct:
>
>>  Sys.time()
> [1] "2005-01-19 09:12:33 PST"
>>  format(Sys.time(),'%H:%M %Z')
> [1] "09:12 PST"
>
>
> On Mac OS X, however,
>
> R 2.0.1 Patched 2005-01-19
>
>>  Sys.time()
> [1] "2005-01-19 09:18:27 PST"
>>  format(Sys.time(),'%H:%M %Z')
> [1] "09:18 P"

The man pages says:
    usetz: logical.  Should the timezone be appended to the output? This
           is used in printing time, and as a workaround for problems
           with using '"%Z"' on most Linux systems.

so after reading that, you get the correct result:

 > format(Sys.time(),'%H:%M',usetz=TRUE)
[1] "15:57 EST"

Now, the reason why I'm CCing this to R-devel is that in fact the 
datetime.c is somewhat weird for non-GlibC2 systems as tm.tm_zone is 
not initialized at all, which I suspect is a bug. Either the docs 
should state that %Z should not be used at all or I'd propose the 
following patch to make it work (warning, it's a patch against 
R-devel):

Index: src/main/datetime.c
===================================================================
--- src/main/datetime.c (revision 32715)
+++ src/main/datetime.c (working copy)
@@ -581,15 +581,8 @@
         error("invalid `usetz' argument");
      tz = getAttrib(x, install("tzone"));

-    /* workaround for glibc bug in strftime */
-#if defined HAVE_GLIBC2
-#ifdef __USE_BSD
-    tm.tm_zone = NULL;
-#else
-    tm.__tm_zone = NULL;
-#endif
-#endif
-
+       memset(&tm, 0, sizeof(tm));
+
      /* coerce fields to integer, find length of longest one */
      for(i = 0; i < 9; i++) {
         nlen[i] = LENGTH(VECTOR_ELT(x, i));

This just zeroes out tm before use - it should also fix the problems on 
Linux. Just in case I overlooked something and it's not feasible to 
zero out the struct tm (e.g. if the size may be unknown), then the 
following, more paranoid patch could be used:

Index: src/main/datetime.c
===================================================================
--- src/main/datetime.c (revision 32715)
+++ src/main/datetime.c (working copy)
@@ -588,7 +588,11 @@
  #else
      tm.__tm_zone = NULL;
  #endif
+#else
+#ifdef HAVE_STRUCT_TM_TM_ZONE
+    tm.tm_zone = NULL;
  #endif
+#endif

      /* coerce fields to integer, find length of longest one */
      for(i = 0; i < 9; i++) {
Index: configure.ac
===================================================================
--- configure.ac        (revision 32715)
+++ configure.ac        (working copy)
@@ -551,7 +551,7 @@
    fpu_control.h grp.h ieee754.h ieeefp.h limits.h locale.h \
    netdb.h netinet/in.h pwd.h strings.h \
    sys/param.h sys/select.h sys/socket.h sys/stat.h sys/time.h \
-  sys/times.h sys/utsname.h unistd.h)
+  sys/times.h sys/utsname.h time.h unistd.h)
  ## </NOTE>
  ## <NOTE>
  ## These are ANSI C headers but some C code (written to work also
@@ -1333,6 +1333,13 @@
  ## POSIX times.
  R_SYS_POSIX_LEAPSECONDS

+dnl some Solaris systems don't have a tm_zone member in struct tm.
+AC_CHECK_MEMBERS([struct tm.tm_zone],,,[
+#if defined(HAVE_TIME_H)
+#include <time.h>
+#endif
+])
+
  ## R profiling.
  if test "${want_R_profiling}" = yes; then
    AC_CHECK_FUNCS(setitimer,

The configure patch makes sure we know that struct tm.tm_zone exists 
and the other patch makes sure it's reset before calling strftime. Any 
variation hereof would help, too ;)

> Changing the TZ environment variable, from the default of "" to 
> "US/Pacific" does not help.

Doing so has no effect for you, because the time zone is correct as you 
demonstrated yourself in the above output.

Cheers,
Simon

From ripley at stats.ox.ac.uk  Wed Jan 19 23:39:26 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jan 19 23:39:46 2005
Subject: [Rd] Re: [R-SIG-Mac] Formatting of time zone for POSIXct
In-Reply-To: <A8792BF6-6A64-11D9-BC92-000D93AE1C66@math.uni-augsburg.de>
References: <p06110407be1445a3fc3f@[128.115.153.6]>
	<A8792BF6-6A64-11D9-BC92-000D93AE1C66@math.uni-augsburg.de>
Message-ID: <Pine.LNX.4.61.0501192213270.22189@gannet.stats>

Simon,

There is _no_ tm_tzone component in a POSIX nor C99 tm structure (and I 
have just checked both), so if a system requires it to be set, the bug is 
not in R but in the standards-compliance of the system.  So

> is somewhat weird for non-GlibC2 systems as tm.tm_zone is not 
> initialized at all, which I suspect is a bug. Either the docs should 
> state that %Z should

is `somewhat wierd' to me.  glibc2 (at least as documented in man mktime) 
like the standards it references has no such component, so if the header 
file defines one it should be private and strftime seems incorrectly 
implemented.  What we implemented as from the POSIX standard, and at least 
one Solaris system complies (but it seems few others these days).

I am happy to zero the structure, much less happy to reference 
undocumented non-POSIX/C99 components.

Brian


On Wed, 19 Jan 2005, Simon Urbanek wrote:

> Don,
>
> thanks for your report.
>
> On Jan 19, 2005, at 12:41 PM, Don MacQueen wrote:
>
>> I'm encountering a problem formatting POSIXct objects in R 2.0.1 on OS X.
>> 
>> For reference, on a Solaris system, R 2.0.1 (2004-11-15), formatting is 
>> correct:
>> 
>>>  Sys.time()
>> [1] "2005-01-19 09:12:33 PST"
>>>  format(Sys.time(),'%H:%M %Z')
>> [1] "09:12 PST"
>> 
>> 
>> On Mac OS X, however,
>> 
>> R 2.0.1 Patched 2005-01-19
>> 
>>>  Sys.time()
>> [1] "2005-01-19 09:18:27 PST"
>>>  format(Sys.time(),'%H:%M %Z')
>> [1] "09:18 P"
>
> The man pages says:
>   usetz: logical.  Should the timezone be appended to the output? This
>          is used in printing time, and as a workaround for problems
>          with using '"%Z"' on most Linux systems.
>
> so after reading that, you get the correct result:
>
>> format(Sys.time(),'%H:%M',usetz=TRUE)
> [1] "15:57 EST"
>
> Now, the reason why I'm CCing this to R-devel is that in fact the datetime.c 
> is somewhat weird for non-GlibC2 systems as tm.tm_zone is not initialized at 
> all, which I suspect is a bug. Either the docs should state that %Z should 
> not be used at all or I'd propose the following patch to make it work 
> (warning, it's a patch against R-devel):
>
> Index: src/main/datetime.c
> ===================================================================
> --- src/main/datetime.c (revision 32715)
> +++ src/main/datetime.c (working copy)
> @@ -581,15 +581,8 @@
>        error("invalid `usetz' argument");
>     tz = getAttrib(x, install("tzone"));
>
> -    /* workaround for glibc bug in strftime */
> -#if defined HAVE_GLIBC2
> -#ifdef __USE_BSD
> -    tm.tm_zone = NULL;
> -#else
> -    tm.__tm_zone = NULL;
> -#endif
> -#endif
> -
> +       memset(&tm, 0, sizeof(tm));
> +
>     /* coerce fields to integer, find length of longest one */
>     for(i = 0; i < 9; i++) {
>        nlen[i] = LENGTH(VECTOR_ELT(x, i));
>
> This just zeroes out tm before use - it should also fix the problems on 
> Linux. Just in case I overlooked something and it's not feasible to zero out 
> the struct tm (e.g. if the size may be unknown), then the following, more 
> paranoid patch could be used:
>
> Index: src/main/datetime.c
> ===================================================================
> --- src/main/datetime.c (revision 32715)
> +++ src/main/datetime.c (working copy)
> @@ -588,7 +588,11 @@
> #else
>     tm.__tm_zone = NULL;
> #endif
> +#else
> +#ifdef HAVE_STRUCT_TM_TM_ZONE
> +    tm.tm_zone = NULL;
> #endif
> +#endif
>
>     /* coerce fields to integer, find length of longest one */
>     for(i = 0; i < 9; i++) {
> Index: configure.ac
> ===================================================================
> --- configure.ac        (revision 32715)
> +++ configure.ac        (working copy)
> @@ -551,7 +551,7 @@
>   fpu_control.h grp.h ieee754.h ieeefp.h limits.h locale.h \
>   netdb.h netinet/in.h pwd.h strings.h \
>   sys/param.h sys/select.h sys/socket.h sys/stat.h sys/time.h \
> -  sys/times.h sys/utsname.h unistd.h)
> +  sys/times.h sys/utsname.h time.h unistd.h)
> ## </NOTE>
> ## <NOTE>
> ## These are ANSI C headers but some C code (written to work also
> @@ -1333,6 +1333,13 @@
> ## POSIX times.
> R_SYS_POSIX_LEAPSECONDS
>
> +dnl some Solaris systems don't have a tm_zone member in struct tm.
> +AC_CHECK_MEMBERS([struct tm.tm_zone],,,[
> +#if defined(HAVE_TIME_H)
> +#include <time.h>
> +#endif
> +])
> +
> ## R profiling.
> if test "${want_R_profiling}" = yes; then
>   AC_CHECK_FUNCS(setitimer,
>
> The configure patch makes sure we know that struct tm.tm_zone exists and the 
> other patch makes sure it's reset before calling strftime. Any variation 
> hereof would help, too ;)
>
>> Changing the TZ environment variable, from the default of "" to 
>> "US/Pacific" does not help.
>
> Doing so has no effect for you, because the time zone is correct as you 
> demonstrated yourself in the above output.
>
> Cheers,
> Simon
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From simon.urbanek at r-project.org  Thu Jan 20 03:33:56 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu Jan 20 03:34:17 2005
Subject: [Rd] Re: [R-SIG-Mac] Formatting of time zone for POSIXct
In-Reply-To: <Pine.LNX.4.61.0501192213270.22189@gannet.stats>
References: <p06110407be1445a3fc3f@[128.115.153.6]>
	<A8792BF6-6A64-11D9-BC92-000D93AE1C66@math.uni-augsburg.de>
	<Pine.LNX.4.61.0501192213270.22189@gannet.stats>
Message-ID: <BB8D4DBC-6A8B-11D9-8644-000A959F327E@r-project.org>

On Jan 19, 2005, at 5:39 PM, Prof Brian Ripley wrote:

> There is _no_ tm_tzone component in a POSIX nor C99 tm structure (and 
> I have just checked both), so if a system requires it to be set, the 
> bug is not in R but in the standards-compliance of the system.

> I am happy to zero the structure, much less happy to reference 
> undocumented non-POSIX/C99 components.

I'm completely happy with zeroing the structure as is seems to fix this 
standards-compliance problem for multiple platforms without the need to 
check for specific headers and behaviors. The only reason I attached 
the second solution was that I was perplexed why someone would use the 
complicated #ifdefs just to initialize a field to zero, so I thought 
there may be more to it...

AFAICS tm_zone and tm_gmoff are BSD extensions and obviously made it to 
GNU as well. Being extensions implies that a structure must be zeroed 
out before use, otherwise the implementation has no way of knowing 
whether the trailing values (wrt standard) are valid or not. If the 
various standards don't mention zeroing structures before use, then 
this may be interpreted as breaking POSIX/C99 standard, but 
nevertheless it still makes sense. Since it does no harm on POSIX 
platforms (just being redundant) and supports arbitrary extensions, I 
think we should go for it... just my two pennies ..

Cheers,
Simon

From xarqwllcj at marca.es  Thu Jan 20 07:39:05 2005
From: xarqwllcj at marca.es (xarqwllcj@marca.es)
Date: Thu Jan 20 07:39:11 2005
Subject: [Rd] Share Market news (PR#7540)
Message-ID: <20050120063905.B6ACA10FA6@slim.kubism.ku.dk>

Received: from candlelit.compaqsucks.com ([208.185.247.132])
 by bridgeable.compaqsucks.com (Sun Java System Messaging Server 6.1 HotFix 0.00 (built
 Aug 21 2004)) with ESMTP id <0A9S00PC360KH98@bridgeable.compaqsucks.com> for
 lb@biostat.ku.dk; Wed, 19 Jan 2005 23:32:52 -0700 (IST)
Received: from surreal.bizwind.com ([66.146.0.10])
 by candlelit.compaqsucks.com
 (Sun Java System Messaging Server 6.1 HotFix 0.05 (built Aug 26 2004))
 with ESMTP id <0O0E00FB308BA61@candlelit.compaqsucks.com> for lb@biostat.ku.dk
 (ORCPT lb@biostat.ku.dk); Thu, 20 Jan 2005 12:29:52 +0600 (IST)
Date: Thu, 20 Jan 2005 11:30:52 +0500
From: Raphael <xarqwllcj@marca.es>
Subject: Share Market news
Cc: Raphael Hoffman  <lb@biostat.ku.dk>
Message-ID: <658763103589.OEK87851@bridgeable.bizwind.com>
X-Virus-Scanned: by amavisd-new at pubhealth.ku.dk
X-Amavis-Alert: BAD HEADER Improper use of control character (char 0D hex) in message header ''
  \rReceived: from ...  ^

MIME-version: 1.0
Content-type: multipart/alternative; boundary="Java.HOYWA.8823340152745624006726521968764178"
Original-recipient: rfc822;lb@biostat.ku.dk

--Java.HOYWA.8823340152745624006726521968764178
Content-Type: text/plain; 
 Breaking News A|ert

Emerson Oi| and Gas, Inc. (OTC-E O G I)
Domestic 0il and Gas Stock Trending Up the Last Few Weeks
Current Price: $.20
EOGI Has Been Moving Up Since it Bottomed at $.135 on December 30th. 
Wil| it Continue Higher? Watch This 0ne Thursday as We Know Many of You 
Like Momentum..

Reasons to Consider "E O G I" (Source: Recent News Announcements)

*Emerson Oi| and Gas, Inc. - Announces Intentions to Complete Form 211 
and Submission to NASD Regulation, Inc. 0TC Comp|iance Unit

*Emerson 0il and Gas, Inc. -- Negotiates on Natural Gas Acquisition

*Emerson 0i| and Gas, Inc. - Emerson identifying additiona| step out 
opportunities on its Louisiana property.

*Emerson 0i| and Gas, Inc. - In negotiations on second re-comp|etion 
we||.

About EOGI: (Source: News January 18, 2OO5)

Emerson Oil & Gas holds a 50% working interest in the W.T. Davis we|| 
and |ands within Township 23 North and Range 13 West of Bossier Parish, 
Louisiana. The net revenue interest of the lease is 75%. The W.T. Davis 
We|| is located in the Arkana Field and initial|y produced from the 
Haynesvi|le Formation of the Cotton Va|ley Series. With the worldwide 
focus on energy needs being front and center in the pub|ic eye, Emerson 
fee|s that with its first c|ass management and discretionary project 
choices, the company wi|| continue to serve its shareho|ders we|l.

Watch This Stock Trade Thursday and Good Luck.

Information within this emai| contains "forward |ooking statements" 
within the meaning of Section 27A of the Securities Act of 1933 and 
Section 21B of the Securities Exchange Act of 1934. Any statements that 
express or invo|ve discussions with respect to predictions, expectations, 
be|iefs, plans, projections, objectives, goals, assumptions or future 
events or performance are not statements of historica| fact and may be 
"forward looking statements."Forward looking statements are based on 
expectations, estimates and projections at the time the statements are made 
that invo|ve a number of risks and uncertainties which cou|d cause 
actual resu|ts or events to differ material|y from those presently 
anticipated. Forward looking statements in this action may be identified 
through the use of words such as "projects", "foresee", "expects", "wil|," 
"anticipates," "estimates," "believes," "understands" or that by 
statements indicating certain actions "may," "could," or "might" occur. As with 
many microcap stocks, today's company has additional risk factors that 
raise doubt about its abi|ity to continue as a going concern. Emerson 
Oil and Gas, Inc. is not a reporting company registered under the 
Securities Act of 1934 and hence there is limited pub|ic information 
avai|ab|e about the company. 0ther factors include: the company had no revenue 
in its most recent quarter and is not currently revenue producing.The 
company has a nominal cash position. The company is going to need 
financing to complete some business transactions and begin revenue producing. 
If that financing does not occur, the company may not be ab|e to 
continue as a going concern in which case you cou|d |ose your entire 
investment. 0ther factors include genera| economic and business conditions, the 
abi|ity to acquire and develop specific projects, the ability to fund 
operations and changes in consumer and business consumption habits and 
other factors over which Emerson Oi| and Gas Inc. has |ittle or no 
contro|. The pub|isher of this news|etter does not represent that the 
information contained in this message states a|l materia| facts or does not 
omit a material fact necessary to make the statements therein not 
misleading.Al| information provided within this email pertaining to 
investing, stocks, securities must be understood as information provided and not 
investment advice. The pub|isher of this news|etter advises all readers 
and subscribers to seek advice from a registered professional 
securities representative before deciding to trade in stocks featured within 
this email. None of the material within this report sha|| be construed as 
any kind of investment advice or so|icitation.Many of these companies 
are on the verge of bankruptcy. You can |ose al| your money by investing 
in this stock. The publisher of this news|etter is not a re gister ed 
in vest ment advisOr. Subscribers should not view information herein as 
legal, tax, accounting or investment advice. Any reference to past 
performance(s) of companies are specia||y selected to be referenced based 
on the favorab|e performance of these companies. You wou|d need perfect 
timing to acheive the resu|ts in the examples given. There can be no 
assurance of that happening. Remember, as always, past performance is ne 
ver indicative of future resu|ts and a thorough due di|igence effort, 
including a review of a company's filings when avai|ab|e, should be 
comp|eted prior to investing. In compliance with the Securities Act of 
1933, Section 17(b),The publisher of this newsletter disc|oses the receipt 
of sixty two thousand five hundred do||ars from a third party, not an 
officer, director or affi|iate shareholder for the circu|ation of this 
report. Be aware of an inherent conflict of interest resulting from such 
compensation due to the fact that this is a paid advertisement and is 
not without bias.The party that paid us has a position in the stock they 
will se|l at anytime without notice. This could have a negative impact 
on the price of the stock. All factua| information in this report was 
gathered from public sources, including but not limited to Company 
Websites and Company Press Releases. The publisher of this newsletter 
believes this information to be reliab|e but can make no guaranteee as to its 
accuracy or completeness. Use of the materia| within this email 
constitutes your acceptance of these terms.

If you wish to stop future mai|ings, or if you fee| you have been 
wrongfully p|aced in our | i s t, please gohere 
(-stocksender@yahoo.com -)
--Java.HOYWA.8823340152745624006726521968764178--

From xarqwllcj at marca.es  Thu Jan 20 07:40:37 2005
From: xarqwllcj at marca.es (xarqwllcj@marca.es)
Date: Thu Jan 20 07:40:44 2005
Subject: [Rd] Share Market news (PR#7541)
Message-ID: <20050120064037.9F02E10FA6@slim.kubism.ku.dk>

Received: from candlelit.compaqsucks.com ([208.185.247.132])
 by bridgeable.compaqsucks.com (Sun Java System Messaging Server 6.1 HotFix 0.00 (built
 Aug 21 2004)) with ESMTP id <0A9S00PC360KH98@bridgeable.compaqsucks.com> for
 lb@biostat.ku.dk; Wed, 19 Jan 2005 23:32:52 -0700 (IST)
Received: from surreal.bizwind.com ([66.146.0.10])
 by candlelit.compaqsucks.com
 (Sun Java System Messaging Server 6.1 HotFix 0.05 (built Aug 26 2004))
 with ESMTP id <0O0E00FB308BA61@candlelit.compaqsucks.com> for lb@biostat.ku.dk
 (ORCPT lb@biostat.ku.dk); Thu, 20 Jan 2005 12:29:52 +0600 (IST)
Date: Thu, 20 Jan 2005 11:30:52 +0500
From: Raphael <xarqwllcj@marca.es>
Subject: Share Market news
Cc: Raphael Hoffman  <lb@biostat.ku.dk>
Message-ID: <658763103589.OEK87851@bridgeable.bizwind.com>
X-Virus-Scanned: by amavisd-new at pubhealth.ku.dk
X-Amavis-Alert: BAD HEADER Improper use of control character (char 0D hex) in message header ''
  \rReceived: from ...  ^

MIME-version: 1.0
Content-type: multipart/alternative; boundary="Java.HOYWA.8823340152745624006726521968764178"
Original-recipient: rfc822;lb@biostat.ku.dk

--Java.HOYWA.8823340152745624006726521968764178
Content-Type: text/plain; 
 Breaking News A|ert

Emerson Oi| and Gas, Inc. (OTC-E O G I)
Domestic 0il and Gas Stock Trending Up the Last Few Weeks
Current Price: $.20
EOGI Has Been Moving Up Since it Bottomed at $.135 on December 30th. 
Wil| it Continue Higher? Watch This 0ne Thursday as We Know Many of You 
Like Momentum..

Reasons to Consider "E O G I" (Source: Recent News Announcements)

*Emerson Oi| and Gas, Inc. - Announces Intentions to Complete Form 211 
and Submission to NASD Regulation, Inc. 0TC Comp|iance Unit

*Emerson 0il and Gas, Inc. -- Negotiates on Natural Gas Acquisition

*Emerson 0i| and Gas, Inc. - Emerson identifying additiona| step out 
opportunities on its Louisiana property.

*Emerson 0i| and Gas, Inc. - In negotiations on second re-comp|etion 
we||.

About EOGI: (Source: News January 18, 2OO5)

Emerson Oil & Gas holds a 50% working interest in the W.T. Davis we|| 
and |ands within Township 23 North and Range 13 West of Bossier Parish, 
Louisiana. The net revenue interest of the lease is 75%. The W.T. Davis 
We|| is located in the Arkana Field and initial|y produced from the 
Haynesvi|le Formation of the Cotton Va|ley Series. With the worldwide 
focus on energy needs being front and center in the pub|ic eye, Emerson 
fee|s that with its first c|ass management and discretionary project 
choices, the company wi|| continue to serve its shareho|ders we|l.

Watch This Stock Trade Thursday and Good Luck.

Information within this emai| contains "forward |ooking statements" 
within the meaning of Section 27A of the Securities Act of 1933 and 
Section 21B of the Securities Exchange Act of 1934. Any statements that 
express or invo|ve discussions with respect to predictions, expectations, 
be|iefs, plans, projections, objectives, goals, assumptions or future 
events or performance are not statements of historica| fact and may be 
"forward looking statements."Forward looking statements are based on 
expectations, estimates and projections at the time the statements are made 
that invo|ve a number of risks and uncertainties which cou|d cause 
actual resu|ts or events to differ material|y from those presently 
anticipated. Forward looking statements in this action may be identified 
through the use of words such as "projects", "foresee", "expects", "wil|," 
"anticipates," "estimates," "believes," "understands" or that by 
statements indicating certain actions "may," "could," or "might" occur. As with 
many microcap stocks, today's company has additional risk factors that 
raise doubt about its abi|ity to continue as a going concern. Emerson 
Oil and Gas, Inc. is not a reporting company registered under the 
Securities Act of 1934 and hence there is limited pub|ic information 
avai|ab|e about the company. 0ther factors include: the company had no revenue 
in its most recent quarter and is not currently revenue producing.The 
company has a nominal cash position. The company is going to need 
financing to complete some business transactions and begin revenue producing. 
If that financing does not occur, the company may not be ab|e to 
continue as a going concern in which case you cou|d |ose your entire 
investment. 0ther factors include genera| economic and business conditions, the 
abi|ity to acquire and develop specific projects, the ability to fund 
operations and changes in consumer and business consumption habits and 
other factors over which Emerson Oi| and Gas Inc. has |ittle or no 
contro|. The pub|isher of this news|etter does not represent that the 
information contained in this message states a|l materia| facts or does not 
omit a material fact necessary to make the statements therein not 
misleading.Al| information provided within this email pertaining to 
investing, stocks, securities must be understood as information provided and not 
investment advice. The pub|isher of this news|etter advises all readers 
and subscribers to seek advice from a registered professional 
securities representative before deciding to trade in stocks featured within 
this email. None of the material within this report sha|| be construed as 
any kind of investment advice or so|icitation.Many of these companies 
are on the verge of bankruptcy. You can |ose al| your money by investing 
in this stock. The publisher of this news|etter is not a re gister ed 
in vest ment advisOr. Subscribers should not view information herein as 
legal, tax, accounting or investment advice. Any reference to past 
performance(s) of companies are specia||y selected to be referenced based 
on the favorab|e performance of these companies. You wou|d need perfect 
timing to acheive the resu|ts in the examples given. There can be no 
assurance of that happening. Remember, as always, past performance is ne 
ver indicative of future resu|ts and a thorough due di|igence effort, 
including a review of a company's filings when avai|ab|e, should be 
comp|eted prior to investing. In compliance with the Securities Act of 
1933, Section 17(b),The publisher of this newsletter disc|oses the receipt 
of sixty two thousand five hundred do||ars from a third party, not an 
officer, director or affi|iate shareholder for the circu|ation of this 
report. Be aware of an inherent conflict of interest resulting from such 
compensation due to the fact that this is a paid advertisement and is 
not without bias.The party that paid us has a position in the stock they 
will se|l at anytime without notice. This could have a negative impact 
on the price of the stock. All factua| information in this report was 
gathered from public sources, including but not limited to Company 
Websites and Company Press Releases. The publisher of this newsletter 
believes this information to be reliab|e but can make no guaranteee as to its 
accuracy or completeness. Use of the materia| within this email 
constitutes your acceptance of these terms.

If you wish to stop future mai|ings, or if you fee| you have been 
wrongfully p|aced in our | i s t, please gohere 
(-stocksender@yahoo.com -)
--Java.HOYWA.8823340152745624006726521968764178--

From rkeymal at sarmail.com  Thu Jan 20 11:15:33 2005
From: rkeymal at sarmail.com (rkeymal@sarmail.com)
Date: Thu Jan 20 11:15:43 2005
Subject: [Rd] Sma|| Cap COmpanies in the News (PR#7542)
Message-ID: <20050120101533.5CE8B10FBD@slim.kubism.ku.dk>

 Breaking News Alert

Emerson Oi| and Gas, Inc. (0TC-E O G I)
Domestic 0i| and Gas Stock Trending Up the Last Few Weeks
Current Price: $.2O
EOGI Has Been Moving Up Since it Bottomed at $.135 on December 30th. 
Wil| it Continue Higher? Watch This One Thursday as We Know Many of You 
Like Momentum..

Reasons to Consider "E O G I" (Source: Recent News Announcements)

*Emerson 0il and Gas, Inc. - Announces Intentions to Comp|ete Form 211 
and Submission to NASD Regulation, Inc. OTC Compliance Unit

*Emerson 0i| and Gas, Inc. -- Negotiates on Natura| Gas Acquisition

*Emerson Oi| and Gas, Inc. - Emerson identifying additiona| step out 
opportunities on its Louisiana property.

*Emerson 0i| and Gas, Inc. - In negotiations on second re-comp|etion 
well.

About EOGI: (Source: News January 18, 2005)

Emerson Oil & Gas ho|ds a 5O% working interest in the W.T. Davis well 
and |ands within Township 23 North and Range 13 West of Bossier Parish, 
Louisiana. The net revenue interest of the |ease is 75%. The W.T. Davis 
Well is located in the Arkana Fie|d and initia||y produced from the 
Haynesvi||e Formation of the Cotton Valley Series. With the wor|dwide 
focus on energy needs being front and center in the pub|ic eye, Emerson 
feels that with its first class management and discretionary project 
choices, the company wi|| continue to serve its shareholders we|l.

Watch This Stock Trade Thursday and Good Luck.

Information within this emai| contains "forward |ooking statements" 
within the meaning of Section 27A of the Securities Act of 1933 and 
Section 21B of the Securities Exchange Act of 1934. Any statements that 
express or invo|ve discussions with respect to predictions, expectations, 
beliefs, plans, projections, objectives, goals, assumptions or future 
events or performance are not statements of historical fact and may be 
"forward |ooking statements."Forward looking statements are based on 
expectations, estimates and projections at the time the statements are made 
that invo|ve a number of risks and uncertainties which cou|d cause 
actua| results or events to differ materia||y from those presently 
anticipated. Forward looking statements in this action may be identified 
through the use of words such as "projects", "foresee", "expects", "wil|," 
"anticipates," "estimates," "believes," "understands" or that by 
statements indicating certain actions "may," "could," or "might" occur. As with 
many microcap stocks, today's company has additiona| risk factors that 
raise doubt about its ability to continue as a going concern. Emerson 
0i| and Gas, Inc. is not a reporting company registered under the 
Securities Act of 1934 and hence there is |imited pub|ic information 
available about the company. Other factors inc|ude: the company had no revenue 
in its most recent quarter and is not current|y revenue producing.The 
company has a nominal cash position. The company is going to need 
financing to complete some business transactions and begin revenue producing. 
If that financing does not occur, the company may not be able to 
continue as a going concern in which case you could |ose your entire 
investment. 0ther factors include general economic and business conditions, the 
ability to acquire and develop specific projects, the ability to fund 
operations and changes in consumer and business consumption habits and 
other factors over which Emerson Oi| and Gas Inc. has litt|e or no 
control. The pub|isher of this news|etter does not represent that the 
information contained in this message states a|| material facts or does not 
omit a materia| fact necessary to make the statements therein not 
mis|eading.Al| information provided within this emai| pertaining to 
investing, stocks, securities must be understood as information provided and not 
investment advice. The pub|isher of this news|etter advises a|| readers 
and subscribers to seek advice from a registered professional 
securities representative before deciding to trade in stocks featured within 
this email. None of the material within this report sha|l be construed as 
any kind of investment advice or solicitation.Many of these companies 
are on the verge of bankruptcy. You can |ose al| your money by investing 
in this stock. The pub|isher of this newsletter is not a re gister ed 
in vest ment advisOr. Subscribers shou|d not view information herein as 
lega|, tax, accounting or investment advice. Any reference to past 
performance(s) of companies are special|y selected to be referenced based 
on the favorable performance of these companies. You wou|d need perfect 
timing to acheive the results in the examp|es given. There can be no 
assurance of that happening. Remember, as always, past performance is ne 
ver indicative of future results and a thorough due di|igence effort, 
including a review of a company's fi|ings when avai|able, should be 
completed prior to investing. In comp|iance with the Securities Act of 
1933, Section 17(b),The publisher of this newsletter discloses the receipt 
of sixty two thousand five hundred dol|ars from a third party, not an 
officer, director or affiliate shareholder for the circu|ation of this 
report. Be aware of an inherent conflict of interest resulting from such 
compensation due to the fact that this is a paid advertisement and is 
not without bias.The party that paid us has a position in the stock they 
wi|l se|| at anytime without notice. This could have a negative impact 
on the price of the stock. A|| factua| information in this report was 
gathered from public sources, inc|uding but not |imited to Company 
Websites and Company Press Re|eases. The pub|isher of this news|etter 
be|ieves this information to be reliab|e but can make no guaranteee as to its 
accuracy or completeness. Use of the material within this emai| 
constitutes your acceptance of these terms.

If you wish to stop future mailings, or if you fee| you have been 
wrongful|y p|aced in our | i s t, please gohere 
(-stocksender@yahoo.com -)

From murdoch at stats.uwo.ca  Thu Jan 20 23:59:03 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu Jan 20 23:57:48 2005
Subject: [Rd] Windows tools updated
Message-ID: <tod0v011m9jqof5ao4icr7cgtd01mbhlej@4ax.com>

I've just updated the Windows build instructions and the files in the
Rtools collection (on www.murdoch-sutherland.com/Rtools).  Most of the
tools are now up to current release versions.

I'd appreciate hearing from anyone if I've missed anything, or there
are incompatibilities that I didn't notice.

Duncan Murdoch

From xt_wang at cse.concordia.ca  Fri Jan 21 00:40:03 2005
From: xt_wang at cse.concordia.ca (xt_wang@cse.concordia.ca)
Date: Fri Jan 21 00:40:09 2005
Subject: [Rd] How to use a C code in R
Message-ID: <1106264403.41f04153c5bf5@mail.encs.concordia.ca>


hello,

I have a c code which uses clapack. I want to integrate R with this code. It
said that I create a R package including my c code. Then build it with putting
PKG_LIBS = $(LAPACK_LIBS). I want to know the interface LAPACK_LIBS is Fortran
or C? If it is written in Fortran, how can I build them together? If I can
build them together, I still use the function in cLapack or the function in
LAPACK_LIBS? Could you tell me how I can do in detail?


Maggie

From deliver at purelove888.com  Fri Jan 21 04:05:02 2005
From: deliver at purelove888.com (deliver@purelove888.com)
Date: Fri Jan 21 04:16:03 2005
Subject: [Rd] =?utf-8?b?cHVyZWxvdmXCgsKpwoLDp8KCw4zCgsKowpJtwoLDp8KCwrk=?=
Message-ID: <20050121030502.25561.qmail@sv.purelove888.com>

 upurelovevB
qlo^Bo^LB
1000~I

http://www.purelove888.com/reg/regUsr.php/MSWCGk8AkSbNtY8CZ

{pureloveo^B
oB
--------
info@purelove888.com

From ada6iTj at redwhitearmy.com  Fri Jan 21 04:39:00 2005
From: ada6iTj at redwhitearmy.com (ada6iTj@redwhitearmy.com)
Date: Fri Jan 21 04:39:11 2005
Subject: [Rd] Package Status, Shipping Number : 0X44em20OJ (PR#7547)
Message-ID: <20050121033900.B400910FAA@slim.kubism.ku.dk>

----Piece.JESYjh1K5.c
Content-Type: text/plain;
 format=flowed;
 charset=iso-8859-15
Content-Transfer-Encoding: 7Bit

John was enjoying sleeping near the tree.

Do just once what others say you can't do, and you will never pay attention to their limitations again.	-James R. Cook	

Doesn't Sarah remember shouting slowly?

Lots of times you have to pretend to join a parade in which you're not really interested in order to get where you're going.	-Christopher Darlington Morley (1890-1957)	 

The pilots were enjoying jogging at the company.

----Piece.JESYjh1K5.c
Content-Type: text/html;
 format=flowed;
 charset=iso-8859-15
Content-Transfer-Encoding: 7Bit

Information Here:
<br><br>
cov2pa.com/track.php?cg=1&c=c
<br><br><br>
<br>Some store clerks like working in London.

----Piece.JESYjh1K5.c--

From ripley at stats.ox.ac.uk  Fri Jan 21 04:51:51 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jan 21 04:51:57 2005
Subject: [Rd] How to use a C code in R
In-Reply-To: <1106264403.41f04153c5bf5@mail.encs.concordia.ca>
References: <1106264403.41f04153c5bf5@mail.encs.concordia.ca>
Message-ID: <Pine.LNX.4.61.0501210349120.29595@gannet.stats>

LAPACK is in Fortran.  See `Writing R Extensions' from the definition of 
what $(LAPACK_LIBS) provides, and for details of the corresponding C 
headers.

There are lot of examples amongst CRAN packages of calling LAPACK from C.

On Thu, 20 Jan 2005 xt_wang@cse.concordia.ca wrote:

> I have a c code which uses clapack. I want to integrate R with this code. It
> said that I create a R package including my c code. Then build it with putting
> PKG_LIBS = $(LAPACK_LIBS). I want to know the interface LAPACK_LIBS is Fortran
> or C? If it is written in Fortran, how can I build them together? If I can
> build them together, I still use the function in cLapack or the function in
> LAPACK_LIBS? Could you tell me how I can do in detail?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From deliver at purelove888.com  Fri Jan 21 10:05:02 2005
From: deliver at purelove888.com (deliver@purelove888.com)
Date: Fri Jan 21 10:14:54 2005
Subject: [Rd] =?utf-8?b?cHVyZWxvdmXCgsKpwoLDp8KCw4zCgsKowpJtwoLDp8KCwrk=?=
Message-ID: <20050121090502.23128.qmail@sv.purelove888.com>

 upurelovevB
qlo^Bo^LB
1000~I

http://www.purelove888.com/reg/regUsr.php/MSWCGk8AkSbNtY8CZ

{pureloveo^B
oB
--------
info@purelove888.com

From deliver at purelove888.com  Fri Jan 21 14:05:02 2005
From: deliver at purelove888.com (deliver@purelove888.com)
Date: Fri Jan 21 14:17:31 2005
Subject: [Rd] =?utf-8?b?cHVyZWxvdmXCgsKpwoLDp8KCw4zCgsKowpJtwoLDp8KCwrk=?=
Message-ID: <20050121130502.15607.qmail@sv.purelove888.com>

 upurelovevB
qlo^Bo^LB
1000~I

http://www.purelove888.com/reg/regUsr.php/MSWCGk8AkSbNtY8CZ

{pureloveo^B
oB
--------
info@purelove888.com

From petr.pikal at precheza.cz  Fri Jan 21 14:30:37 2005
From: petr.pikal at precheza.cz (petr.pikal@precheza.cz)
Date: Fri Jan 21 14:30:42 2005
Subject: [Rd] cutPOSIX - change of help page suggestion (PR#7551)
Message-ID: <20050121133037.3EB4910FA3@slim.kubism.ku.dk>

Dear R-core people

This is first time I try to send you some suggestion so I hope I use 
the correct address (and sorry if my english is not optimal:-).

cut.POSIX help page says in arguments section:

right, ... arguments to be passed to or from other methods.

which, if I did not encounter following behaviour earlier and did 
not get an answer from r-help, would not help me very much in 
tracking how I can rid of NA from result

> cut(datum[1:5],"day", right=T, include.lowest=T)
[1] 2004-12-06 2004-12-07 2004-12-09 2004-12-12 2004-12-14

> cut(datum[1:5],"day", right=T)
[1] <NA>       2004-12-07 2004-12-09 2004-12-12 2004-12-14

> cut(datum[1:5],"day")
[1] 2004-12-06 2004-12-08 2004-12-10 2004-12-13 <NA>      


I would recommend to add something like:
--------------------------------------------------------------------------
Using both right = TRUE and include.lowest =  TRUE will include 
both ends of your dates range.
--------------------------------------------------------------------------
 
Best regards
Petr Pikal
petr.pikal@precheza.cz

From Philippe.Hupe at curie.fr  Fri Jan 21 17:33:25 2005
From: Philippe.Hupe at curie.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Fri Jan 21 17:33:30 2005
Subject: [Rd] * creating vignettes ... ERROR
Message-ID: <41F12ED5.2040709@curie.fr>

Dear R developers,

I had some problem when building package: for exemple when building the 
package e1071 available from CRAN, I get the following message error:

* checking for file 'e1071/DESCRIPTION' ... OK
* preparing 'e1071':
* cleaning src
* running cleanup
* creating vignettes ... ERROR
/usr/lib/R/bin/texi2dvi: pdflatex exited with bad status, quitting.
/usr/lib/R/bin/texi2dvi: see svmdoc.log for errors.
Error in texi2dvi(file = bft, pdf = TRUE, clean = FALSE, quiet = quiet) :
        running texi2dvi on svmdoc.tex failed
Execution halted


The system I use is:
R2.0.1 under Debian Linux (testing) with kernel 2.6.9-1-686

The pdflatex version is:
pdfeTeX (Web2C 7.4.5) 3.14159-1.10b-2.1
kpathsea version 3.4.5
Copyright (C) 1997-2003 The NTS Team (eTeX)/Han The Thanh (pdfTeX).
Kpathsea is copyright (C) 1997-2003 Free Software Foundation, Inc.
There is NO warranty.  Redistribution of this software is
covered by the terms of both the pdfeTeX copyright and
the GNU General Public License.
For more information about these matters, see the files
named COPYING and the pdfeTeX source.
Primary author of pdfeTeX: The NTS Team (eTeX)/Han The Thanh (pdfTeX).
Kpathsea written by Karl Berry and others.



I attached the log file svmdoc.log.


I have a quick look on the perl script build and it seem there is a grep 
for error.
In the log file there is a line with the following:
file:line:error style messages enabled
it is just the summary of the option used when running pdflatex and then 
an error is systematically reported.

If you have any idea where the problem comes from?

Thanks,

Philippe

-- 
Philippe Hup?
UMR 144 - Service Bioinformatique
Institut Curie
Laboratoire de Transfert (4?me ?tage)
26 rue d'Ulm
75005 Paris - France
 	
Email :  Philippe.Hupe@curie.fr
T?l :	 +33 (0)1 44 32 42 75
Fax :  	 +33 (0)1 42 34 65 28

From jeff.horner at vanderbilt.edu  Fri Jan 21 18:06:10 2005
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Fri Jan 21 18:06:16 2005
Subject: [Rd] Struggling with S3/S4 interface issues and External Pointers
Message-ID: <41F13682.6060703@vanderbilt.edu>

I'm currently working on embedding R into the Apache2 webserver (with 
some positive results...), but I'm struggling to identify the best way 
to expose the apache data and functions to R.

A couple of thoughts:

In light of the recent discussion on "S3/S4 classes performance 
comparson", I'm leaning toward implementing the interface with S3 style 
classes. I appreciate anyones advice on this.

I JUST found (after roughly 6 months of studying R) Luke Tierney's note 
on "Finalization and Weak References in R". From the developers page, 
this note is listed as a "preliminary mechanism", but I scoured CRAN and 
noticed packages like RODBC and XML are using it. Has this mechanism 
changed from "preliminary" to "production" yet? For storing pointers in 
R variables, I've been using integer vectors which is what RMySQL does 
but doesn't seem natural.

For those interested in my Apache R implementation, please download here:

http://biostat.mc.vanderbilt.edu/twiki/pub/Main/JeffreyHorner/mod_R-0.0.tar.gz

Cheers,
-- 
Jeffrey Horner       Computer Systems Analyst         School of Medicine
615-322-8606         Department of Biostatistics   Vanderbilt University

From Achim.Zeileis at wu-wien.ac.at  Fri Jan 21 19:01:50 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri Jan 21 19:01:55 2005
Subject: [Rd] * creating vignettes ... ERROR
In-Reply-To: <41F12ED5.2040709@curie.fr>
References: <41F12ED5.2040709@curie.fr>
Message-ID: <20050121190150.042eb333.Achim.Zeileis@wu-wien.ac.at>

On Fri, 21 Jan 2005 17:33:25 +0100 Philippe Hup? wrote:

> Dear R developers,
> 
> I had some problem when building package: for exemple when building
> the package e1071 available from CRAN, I get the following message
> error:
> 
> * checking for file 'e1071/DESCRIPTION' ... OK
> * preparing 'e1071':
> * cleaning src
> * running cleanup
> * creating vignettes ... ERROR
> /usr/lib/R/bin/texi2dvi: pdflatex exited with bad status, quitting.
> /usr/lib/R/bin/texi2dvi: see svmdoc.log for errors.
> Error in texi2dvi(file = bft, pdf = TRUE, clean = FALSE, quiet =
> quiet) :
>         running texi2dvi on svmdoc.tex failed
> Execution halted

works for me

> 
> The system I use is:
> R2.0.1 under Debian Linux (testing) with kernel 2.6.9-1-686
> 
> The pdflatex version is:
> pdfeTeX (Web2C 7.4.5) 3.14159-1.10b-2.1
> kpathsea version 3.4.5
> Copyright (C) 1997-2003 The NTS Team (eTeX)/Han The Thanh (pdfTeX).
> Kpathsea is copyright (C) 1997-2003 Free Software Foundation, Inc.
> There is NO warranty.  Redistribution of this software is
> covered by the terms of both the pdfeTeX copyright and
> the GNU General Public License.
> For more information about these matters, see the files
> named COPYING and the pdfeTeX source.
> Primary author of pdfeTeX: The NTS Team (eTeX)/Han The Thanh (pdfTeX).
> Kpathsea written by Karl Berry and others.
> 
> 
> 
> I attached the log file svmdoc.log.

That did not come true. But my guess is that running LaTeX is what fails
(and that the problem is neither in R nor in the Per script).

>From looking briefly at svmdoc.Rnw, it has a 
  \usepackage{Sweave}
so it expects that Sweave.sty is somewhere in your search path. Is that
the case?

Furthermore, the R code in vignettes should always run, but compiling
the resulting .tex file just has to work at build time. So there are
vignettes (at least in my packages) that depend on local sty/bib/bst
files not included in the package and thus cannot be (easily) compiled
by other people.
Z

> 
> I have a quick look on the perl script build and it seem there is a
> grep for error.
> In the log file there is a line with the following:
> file:line:error style messages enabled
> it is just the summary of the option used when running pdflatex and
> then an error is systematically reported.
> 
> If you have any idea where the problem comes from?
> 
> Thanks,
> 
> Philippe
> 
> -- 
> Philippe Hup?
> UMR 144 - Service Bioinformatique
> Institut Curie
> Laboratoire de Transfert (4?me ?tage)
> 26 rue d'Ulm
> 75005 Paris - France
>  	
> Email :  Philippe.Hupe@curie.fr
> T?l :	 +33 (0)1 44 32 42 75
> Fax :  	 +33 (0)1 42 34 65 28
> 
>

From ripley at stats.ox.ac.uk  Fri Jan 21 19:17:54 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jan 21 19:18:04 2005
Subject: [Rd] Struggling with S3/S4 interface issues and External Pointers
In-Reply-To: <41F13682.6060703@vanderbilt.edu>
References: <41F13682.6060703@vanderbilt.edu>
Message-ID: <Pine.LNX.4.61.0501211812430.28157@gannet.stats>

On Fri, 21 Jan 2005, Jeffrey Horner wrote:

> I'm currently working on embedding R into the Apache2 webserver (with some 
> positive results...), but I'm struggling to identify the best way to expose 
> the apache data and functions to R.
>
> A couple of thoughts:
>
> In light of the recent discussion on "S3/S4 classes performance comparson", 
> I'm leaning toward implementing the interface with S3 style classes. I 
> appreciate anyones advice on this.

> I JUST found (after roughly 6 months of studying R) Luke Tierney's note on 
> "Finalization and Weak References in R". From the developers page, this note 
> is listed as a "preliminary mechanism", but I scoured CRAN and noticed 
> packages like RODBC and XML are using it. Has this mechanism changed from 
> "preliminary" to "production" yet? For storing pointers in R variables, I've

Yes, but the documentation has not.  R itself uses the mechanism for 
DLLinfo.

The developer.r-project.org site is a mixture of old and new, but 
certainly worth perusing in the first month of studying R.

> been using integer vectors which is what RMySQL does but doesn't seem 
> natural.

You asked elsewhere why RMySQL does not use it, but AFAIK it predates the 
mechanism.  RODBC and XML have only used it recently.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jeff.horner at vanderbilt.edu  Fri Jan 21 19:31:32 2005
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Fri Jan 21 19:31:41 2005
Subject: [Rd] Struggling with S3/S4 interface issues and External Pointers
In-Reply-To: <Pine.LNX.4.61.0501211812430.28157@gannet.stats>
References: <41F13682.6060703@vanderbilt.edu>
	<Pine.LNX.4.61.0501211812430.28157@gannet.stats>
Message-ID: <41F14A84.7060300@vanderbilt.edu>

Prof Brian Ripley wrote:
[...]>
> You asked elsewhere why RMySQL does not use it, but AFAIK it predates 
> the mechanism.  RODBC and XML have only used it recently.

Actually, Luke suggested it be used when DBI was just forming:

https://stat.ethz.ch/pipermail/r-sig-db/2001-October/000028.html

-- 
Jeffrey Horner       Computer Systems Analyst         School of Medicine
615-322-8606         Department of Biostatistics   Vanderbilt University

From ligges at statistik.uni-dortmund.de  Fri Jan 21 19:46:02 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Jan 21 19:45:08 2005
Subject: [Rd] * creating vignettes ... ERROR
In-Reply-To: <20050121190150.042eb333.Achim.Zeileis@wu-wien.ac.at>
References: <41F12ED5.2040709@curie.fr>
	<20050121190150.042eb333.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <41F14DEA.1030307@statistik.uni-dortmund.de>

Achim Zeileis wrote:

> On Fri, 21 Jan 2005 17:33:25 +0100 Philippe Hup? wrote:
> 
> 
>>Dear R developers,
>>
>>I had some problem when building package: for exemple when building
>>the package e1071 available from CRAN, I get the following message
>>error:
>>
>>* checking for file 'e1071/DESCRIPTION' ... OK
>>* preparing 'e1071':
>>* cleaning src
>>* running cleanup
>>* creating vignettes ... ERROR
>>/usr/lib/R/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>/usr/lib/R/bin/texi2dvi: see svmdoc.log for errors.
>>Error in texi2dvi(file = bft, pdf = TRUE, clean = FALSE, quiet =
>>quiet) :
>>        running texi2dvi on svmdoc.tex failed
>>Execution halted
> 
> 
> works for me
> 
> 
>>The system I use is:
>>R2.0.1 under Debian Linux (testing) with kernel 2.6.9-1-686
>>
>>The pdflatex version is:
>>pdfeTeX (Web2C 7.4.5) 3.14159-1.10b-2.1
>>kpathsea version 3.4.5
>>Copyright (C) 1997-2003 The NTS Team (eTeX)/Han The Thanh (pdfTeX).
>>Kpathsea is copyright (C) 1997-2003 Free Software Foundation, Inc.
>>There is NO warranty.  Redistribution of this software is
>>covered by the terms of both the pdfeTeX copyright and
>>the GNU General Public License.
>>For more information about these matters, see the files
>>named COPYING and the pdfeTeX source.
>>Primary author of pdfeTeX: The NTS Team (eTeX)/Han The Thanh (pdfTeX).
>>Kpathsea written by Karl Berry and others.
>>
>>
>>
>>I attached the log file svmdoc.log.
> 
> 
> That did not come true. But my guess is that running LaTeX is what fails
> (and that the problem is neither in R nor in the Per script).
> 
>>From looking briefly at svmdoc.Rnw, it has a 
>   \usepackage{Sweave}
> so it expects that Sweave.sty is somewhere in your search path. Is that
> the case?
> 
> Furthermore, the R code in vignettes should always run, but compiling
> the resulting .tex file just has to work at build time. So there are
> vignettes (at least in my packages) that depend on local sty/bib/bst
> files not included in the package and thus cannot be (easily) compiled
> by other people.
> Z


Philippe is right. I have seen the log file and it causes the problem. 
It was me who suggested to write to r-devel. The relevant lines in the 
log file were:


============================
This is pdfeTeXk, Version 3.14159-1.10b-2.1 (Web2C 7.4.5) 
(format=pdflatex 2005.1.5)  19 JAN 2005 17:37
entering extended mode
  file:line:error style messages enabled.
**\nonstopmode \input /home/phupe/tmp/e1071/inst/doc/svmdoc.tex

[SNIP]

Output written on svmdoc.pdf (7 pages, 186335 bytes).
============================


Note, this is a very modern version of pdf*e*TeX!
I don't know whether R is supposed to support it. If so, this is a bug.


Uwe Ligges




> 
>>I have a quick look on the perl script build and it seem there is a
>>grep for error.
>>In the log file there is a line with the following:
>>file:line:error style messages enabled
>>it is just the summary of the option used when running pdflatex and
>>then an error is systematically reported.
>>
>>If you have any idea where the problem comes from?
>>
>>Thanks,
>>
>>Philippe
>>
>>-- 
>>Philippe Hup?
>>UMR 144 - Service Bioinformatique
>>Institut Curie
>>Laboratoire de Transfert (4?me ?tage)
>>26 rue d'Ulm
>>75005 Paris - France
>> 	
>>Email :  Philippe.Hupe@curie.fr
>>T?l :	 +33 (0)1 44 32 42 75
>>Fax :  	 +33 (0)1 42 34 65 28
>>
>>
> 
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From pgilbert at bank-banque-canada.ca  Fri Jan 21 21:48:29 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri Jan 21 21:50:32 2005
Subject: [Rd] GPArotation
Message-ID: <41F16A9D.3070005@bank-banque-canada.ca>

I released a new package called GPArotation in the devel area of CRAN. 
This package uses the gradient projection algorithm of Bernaards and 
Jennrich <http://www.stat.ucla.edu/research/gpa> to do factor rotation.  
The R package is based on code from their web site. Available rotation 
objective criteria  are "oblimin", "quartimin", "target", "pst", 
"oblimax", "entropy",  "quartimax", "varimax", "simplimax", "bentler", 
"tandemI", "tandemII", "geomin", "cf", "infomax" and "mccammon".

I have done a certain amount of testing of "oblimin" and it appears to 
work well.  More extensive testing of all criteria and comparisons with 
known results would be very much appreciated. Beware that the default is 
not to do Kaiser normalization, which often is the default for 
commercial implementations of some of these criteria (but it does not 
make sense for others).

In  superficial testing of some of the criteria I have found that the 
loadings matrix appears to stabilize in the sense that it does not 
change when the number of iterations is increased, but the gradient 
based convergence criterion does not signal convergence. I suspect this 
is because the gradient is large even in close proximity to the optimum. 
As many of you are much more familiar with this problem than I am,  I 
would certainly appreciate suggestions for better convergence tests.

Paul Gilbert

From ripley at stats.ox.ac.uk  Fri Jan 21 21:55:31 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jan 21 21:55:45 2005
Subject: [Rd] * creating vignettes ... ERROR
In-Reply-To: <41F14DEA.1030307@statistik.uni-dortmund.de>
References: <41F12ED5.2040709@curie.fr>
	<20050121190150.042eb333.Achim.Zeileis@wu-wien.ac.at>
	<41F14DEA.1030307@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.61.0501212039540.24235@gannet.stats>

On Fri, 21 Jan 2005, Uwe Ligges wrote:

> Achim Zeileis wrote:
>
>> On Fri, 21 Jan 2005 17:33:25 +0100 Philippe Hup? wrote:

>>> I had some problem when building package: for exemple when building
>>> the package e1071 available from CRAN, I get the following message
>>> error:

*Why* are you building someone else's package?

>>> * checking for file 'e1071/DESCRIPTION' ... OK
>>> * preparing 'e1071':
>>> * cleaning src
>>> * running cleanup
>>> * creating vignettes ... ERROR
>>> /usr/lib/R/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>> /usr/lib/R/bin/texi2dvi: see svmdoc.log for errors.
>>> Error in texi2dvi(file = bft, pdf = TRUE, clean = FALSE, quiet =
>>> quiet) :
>>>        running texi2dvi on svmdoc.tex failed
>>> Execution halted
>> 
>> 
>> works for me
>> 
>> 
>>> The system I use is:
>>> R2.0.1 under Debian Linux (testing) with kernel 2.6.9-1-686
>>> 
>>> The pdflatex version is:
>>> pdfeTeX (Web2C 7.4.5) 3.14159-1.10b-2.1
>>> kpathsea version 3.4.5
>>> Copyright (C) 1997-2003 The NTS Team (eTeX)/Han The Thanh (pdfTeX).
>>> Kpathsea is copyright (C) 1997-2003 Free Software Foundation, Inc.
>>> There is NO warranty.  Redistribution of this software is
>>> covered by the terms of both the pdfeTeX copyright and
>>> the GNU General Public License.
>>> For more information about these matters, see the files
>>> named COPYING and the pdfeTeX source.
>>> Primary author of pdfeTeX: The NTS Team (eTeX)/Han The Thanh (pdfTeX).
>>> Kpathsea written by Karl Berry and others.
>>> 
>>> 
>>> 
>>> I attached the log file svmdoc.log.
>> 
>> 
>> That did not come true. But my guess is that running LaTeX is what fails
>> (and that the problem is neither in R nor in the Per script).
>> 
>>> From looking briefly at svmdoc.Rnw, it has a 
>>   \usepackage{Sweave}
>> so it expects that Sweave.sty is somewhere in your search path. Is that
>> the case?
>> 
>> Furthermore, the R code in vignettes should always run, but compiling
>> the resulting .tex file just has to work at build time. So there are
>> vignettes (at least in my packages) that depend on local sty/bib/bst
>> files not included in the package and thus cannot be (easily) compiled
>> by other people.
>> Z
>
>
> Philippe is right. I have seen the log file and it causes the problem. It was 
> me who suggested to write to r-devel. The relevant lines in the log file 
> were:

Except there is no error in those lines!

> ============================
> This is pdfeTeXk, Version 3.14159-1.10b-2.1 (Web2C 7.4.5) (format=pdflatex 
> 2005.1.5)  19 JAN 2005 17:37
> entering extended mode
> file:line:error style messages enabled.
> **\nonstopmode \input /home/phupe/tmp/e1071/inst/doc/svmdoc.tex
>
> [SNIP]
>
> Output written on svmdoc.pdf (7 pages, 186335 bytes).
> ============================
>
>
> Note, this is a very modern version of pdf*e*TeX!
> I don't know whether R is supposed to support it. If so, this is a bug.

Well as I understand it for 1.10b (not at all very modern), pdflatex is 
supposed to be built from pdftex: it is with the current 1.20b that 
pdfetex is used.  As I got a TeTeX upgrade this very morning and mine does 
run R CMD check e1071, I think the problem may well be in Philippe's 
setup.

gannet% pdflatex --version
pdfTeX (Web2C 7.4.5) 3.14159-1.10b
kpathsea version 3.4.5
...
gannet% pdfelatex --version
pdfeTeX (Web2C 7.4.5) 3.14159-1.10b-2.1
kpathsea version 3.4.5

Perhaps if we get to see the error message we might know what is going on.
Meanwhile I suggest using the current teTeX.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
From deliver at purelove888.com  Sat Jan 22 01:05:02 2005
From: deliver at purelove888.com (deliver@purelove888.com)
Date: Sat Jan 22 01:14:10 2005
Subject: [Rd] =?utf-8?b?cHVyZWxvdmXCgsKpwoLDp8KCw4zCgsKowpJtwoLDp8KCwrk=?=
Message-ID: <20050122000502.2980.qmail@sv.purelove888.com>

 upurelovevB
qlo^Bo^LB
1000~I

http://www.purelove888.com/reg/regUsr.php/MSWCGk8AkSbNtY8CZ

{pureloveo^B
oB
--------
info@purelove888.com

From KristenaparejoN2rYe at alex4all.com  Sat Jan 22 04:02:05 2005
From: KristenaparejoN2rYe at alex4all.com (Amalia W. McCarthy, Jr)
Date: Sat Jan 22 04:03:18 2005
Subject: [Rd] Package Status, Delivery Number : 5SE9r94Q
Message-ID: <UYKHhb4M0.wDZzeEEjCY6@accursedly4.alex4all.com>

webtime-now.net/?wid=209095

I am a teacher of preschool children with disabilities. I have been making software for the children in my classrooms for the last eight years. Over the past 23 years I have encountered many types of disabilities and many types of parents. The question

We are discreet sheep; we wait to see how the drove is going, and then go with the drove.	-Mark Twain [Samuel Langhornne Clemens] (1835-1910)	

1

All my life I've wanted to be someone; I guess I should have been more specific.	Jane Wagner/Lily Tomlin (1939- )	 

	[[alternative HTML version deleted]]

From deliver at purelove888.com  Sat Jan 22 04:05:02 2005
From: deliver at purelove888.com (deliver@purelove888.com)
Date: Sat Jan 22 04:13:02 2005
Subject: [Rd] =?utf-8?b?cHVyZWxvdmXCgsKpwoLDp8KCw4zCgsKowpJtwoLDp8KCwrk=?=
Message-ID: <20050122030502.26059.qmail@sv.purelove888.com>

 upurelovevB
qlo^Bo^LB
1000~I

http://www.purelove888.com/reg/regUsr.php/MSWCGk8AkSbNtY8CZ

{pureloveo^B
oB
--------
info@purelove888.com

From deliver at purelove888.com  Sat Jan 22 10:05:02 2005
From: deliver at purelove888.com (deliver@purelove888.com)
Date: Sat Jan 22 10:17:53 2005
Subject: [Rd] =?utf-8?b?cHVyZWxvdmXCgsKpwoLDp8KCw4zCgsKowpJtwoLDp8KCwrk=?=
Message-ID: <20050122090502.21359.qmail@sv.purelove888.com>

 upurelovevB
qlo^Bo^LB
1000~I

http://www.purelove888.com/reg/regUsr.php/MSWCGk8AkSbNtY8CZ

{pureloveo^B
oB
--------
info@purelove888.com

From info at wseas.org  Sat Jan 22 14:02:16 2005
From: info at wseas.org (info@wseas.org)
Date: Sat Jan 22 14:02:23 2005
Subject: [Rd] Re: Mail Server
In-Reply-To: <200501221302.j0MD245G005299@host2.mynewserver.net>
References: <200501221302.j0MD245G005299@host2.mynewserver.net>
Message-ID: <200501221302.j0MD2GCc005452@host2.mynewserver.net>

[write WSEAS in the Subject, when you reply]

Dear Colleague,

Hellow, this is from WSEAS Staff. 
If your question is not in the following list of questions, we
will reply to you shortly. 
Please, see now the answer in your all possible questions below
Please, note that it will be useful to read all these questions.
Maybe, one question does not have any meaning for you now, but it might be of
crucial importance after some days. So, read all the QUESTIONS and Answers below, very carefully.
It is very important to know everything about your conference/book/journal.


QUESTIONS - Answers

- SEND ME an INVITATION LETTER FOR MY DEPARTMENT OR FOR VISA PURPOSES:  Download it from http://www.worldses.org/drafts/invitation.doc

- SEND ME the REGISTRATION FORMS:  Download them from http://www.worldses.org/forms

- HOW CAN I SEND MY REGISTRATION TO YOU?  Download and see the instructions from http://www.worldses.org/forms

- SEND ME the HOTEL RESERVATION FORMS:  Download them from http://www.worldses.org/forms

- SEND ME the PROGRAM(S) OF THE CONFERENCE: Download them http://www.worldses.org/programs

- HOW CAN I RECEIVE A CONFIRMATION FOR MY REGISTRATION: Please, fill in your email address in your FAX Sheet.

- I NEED TO SEND YOU A NEW VERSION OF MY PAPER: We allow it 30 or more days before the particular conference. See
  how you can send a new version of your paper visiting: http://www.wseas.org/terms

- WHERE CAN I FIND THE WSEAS FORMAT FOR JOURNALS AND CONFERENCES? Visit: http://www.worldses.org/drafts/wseas.doc
    or http://www.worldses.org/drafts/wseas.pdf

- I USE LATEX. WHAT IS THE STYLE THAT YOU ACCEPT?  http://www.worldses.org/drafts/wseas.sty
      and  http://www.worldses.org/drafts/wseas.tex

- WHAT IS THE MAXIMUM and MINIMUM LENGTH OF A PAPER in WSEAS conferences/journals: maximum: 9 pages 
    (written in the WSEAS format), minimum: 3 pages (written in the WSEAS format)

- WHAT WILL BE HAPPEN IF MY PAPER IS MORE THAN 9 PAGES: We can publish it in the CD-ROM, but we will not publish it
  in a journal or in a book (hard copy).

- IN WHAT JOURNAL or BOOK YOU WILL PUBLISH MY PAPER?  We distribute the papers in Journals and Books after the end of the registrations
  period. Of course, we try to put your paper in the more relevant WSEAS Journal or Book.
  So, we cannot provide this information before the conference.
  We must know how many papers will be accepted, how many papers will be available. This information will be given to you at the conference.

- CAN YOU GIVE ME AN EXTENSION IN THE DEADLINE?  All the extensions (prolongations) in the deadlines can be found at:
  www.wseas.org  Please, check it after the end of a deadline of a particular conference.

- SEND ME NOW AN INVOICE (RECEIPT).   Please, note that we shall give a hard copy of the invoice to you
  at the conference. We cannot send to you hard copies of the invoice by regular post.   In case, of emergency, you can downlowad an invoice from
  http://www.worldses.org/drafts/invoice.doc
  You are authorized to fill in your name, conference, dates, paper number,registration fees yourself.

- HOW CAN I PROPOSE NEW MEMBERS IN THE COMMITTEE? Please, visit: http://www.wseas.com/propose/propose.htm

- HOW CAN I PROPOSE NEW PLENARY / KEYNOTE SPEAKERS? Please, visit: http://www.wseas.com/propose/propose.htm

- HOW CAN I ESTABLISH a WSEAS ON-LINE COMMUNITY or a CHAPTER?  Visit: http://www.wseas.com/propose/propose.htm

- SEND ME THE CONFERENCE MATERIAL (PROCEEDINGS+JOURNAL) FROM A PREVIOUS WSEAS CONFERENCE

   You have to pay an extra fee of 100 EUR, if you want to receive
   the Conference Proceedings + Journal/Book with your paper by EXPRESS, SECURE and REGISTERED Mail.
   Due to several failures in the past, we do not use the regular post anylonger, but only 
   EXPRESS, SAFE and REGISTERED post. For this reason, as well as for the whole secretariat support, 
   WSEAS puts an extra fee of 100 EUR. You can send it to WSEAS using the same procedure of the registration and using
   the form that you can find at: http://www.worldses.org/forms/extrafees.doc

-- DO YOU ACCEPT REGISTRATION FEES VIA THE WEB?   

   WSEAS really protects you. 
   As you know, we have installed  the Web Form technology in our 17 servers and it would 
   be easy to permit the web registration. But, what will be happen, 
   if your money goes to some hackers? Please, do not trust 
   INTERNET TRANSACTIONS and do not put the number of your 
   credit card in any web form. There are several risks. 
   Do not send money to conference organizers (outside WSEAS) via web forms. 
   It is of high risk. The only safe procedure is the procedure of WSEAS. 

-- DOES WSEAS ACCEPT OVERVIEW PAPERS?  Absolutely not.  WSEAS does not publish overview papers.

-- WHAT IS THE MAXIMUM NUMBER OF PAPERS THAT I CAN PRESENT AND REGISTER IN A CONFERENCE:  5 (five)

-- IS ONE REGISTRATION ENOUGH IF I HAVE MORE THAN ONE PAPERS ACCEPTED? 
   We have the following algorithm:
   One registration is enough, but justifies publication for you up to 6 pages (totally).
   That means that you have also to pay the extra pages fee
   which is
   ((n1+n2+n3+n4+n5)-6)*100 EUR

   So, you registration must be: 
  
   500 EUR if n1+n2+n3+n4+n5 <= 6

   500 +((n1+n2+n3+n4+n5)-6)*100 EUR if n1+n2+n3+n4+n5> 6

    where n1 is the number of your pages in the first paper
          n2 is the number of your pages in the second paper
          n3 is the number of your pages in the third paper
          n4 is the number of your pages in the fourth paper
          n5 is the number of your pages in the fifth paper

   In the above calculation, WSEAS members must replace the "500 EUR" with "450 EUR".


-- WHY, SOME TIMES, THE WSEAS CONFERENCES HAVE SO WIDE TOPICS?  WSEAS is the 
   Society that promotes the development and the unified consideration of new mathematical 
   methods and computational techniques as well as their applications in science and engineering. So, it is expected to have cross-disciplinary events many times worldwide. This is the unique role of WSEAS among the international academic community.

-- CAN I HAVE DISCOUNT IN THE REGISTRATION FEES OR FINANCIAL SUPPORT? WSEAS does offer a student registration fee for 
   students that do not present a paper. See the web page of the conference. We cannot give other discounts.  We are sorry that we could not be of more help.


- I CANNOT ATTENED (or I COULD NOT ATTEND) THE CONFERENCE THAT I SENT THE PAPER. 
   CAN I TRANSFER MY PAPER TO ANOTHER WSEAS CONFERENCE?

   No, you cannot! If you do not show up in a WSEAS
   conference, we will publish your paper in the proceedings
   plus Journal or Book (if your paper will be also published
   in Journal or Book after the Conference procedings), provided that at least an author from your paper
   will make registration for this conference. 
   Find the file from the folder: http://www.worldses.org/forms
   Also, you have to pay the extra fee of 100 EUR, if you want us to sent to you
   the Conference Proceedings + Journal with your paper
   by SECURE and REGISTERED Post
   See the file: http://www.worldses.org/forms/extrafees.doc


-- I CANNOT ATTENED (or I COULD NOT ATTEND) THE CONFERENCE THAT I SENT THE PAPER. 
   CAN I HAVE THE PROCEEDINGS AS WELL AS THE BOOK / JOURNAL TO MY ADDRESS?


   We only publish registered papers. So, please, check
   if you sent the registration fees to the organizing committee.
   See the relevant files from http://www.worldses.org/forms
   Also, you have to pay the extra fee of 100 EUR, if you want us to sent to you
   the Conference Proceedings + Journal with your paper
   by SECURE and REGISTERED Post
   See the file http://www.worldses.org/forms/extrafees.doc
   and send the extra fee of 100 EUR to WSEAS by FAX or a scanned image by email.


-- CAN I SEND YOU NOW AN ABSTRACT AND LATER ON THE FULL PAPER.

  We do not accept Abstracts or Draft papers.
  We need the full paper with the correct WSEAS format.
  See: http://www.worldses.org/drafts/wseas.doc
  or http://www.worldses.org/drafts/wseas.pdf
  Do not send it to us by email.
  Please, visit the conference web site via:
  http://www.wseas.org   OR  http://www.worldses.org
  select the conference that you want
  and submit the full paper via the web interface of the
  particular conference
  (click on the link: "Submit a paper")


-- WHAT IS YOUR CRITERIA FOR PUBLISHING PAPERS?

   The paper must contain Original work, adequate references
   and comparison with previous methods in the literature,
   WSEAS format and excellent English language. We do not accept
   overview papers.


-- I HAVE AN ACCEPTED SPECIAL SESSION. HOW CAN I SEND THE CALL FOR PAPERS FOR MY SPECIAL SESSION (OR WORKSHOP) TO YOU

    Please, download the sample for a CALL FOR PAPERS from:
    http://www.worldses.org/drafts/sample.doc
    Please, modify it and send it to us by email.
    We will upload it on the web as soon as possible.


-- MUST I BOOK MY ROOM IN THE HOTEL WHERE THE CONFERENCE WILL TAKE PLACE?

   It is not mandatory. You can find several other hotels using the internet
   (www.google.com) or your travel agent.


-- CAN I BOOK MY ROOM VIA THE WSEAS?

   Unfortunately not. WSEAS is a scientific organization and cannot book
   a room for you in the hotel. We provide you with the necessary forms
   See: http://www.worldses.org/forms
   but you must contact the hotel yourself.


-- WHAT AUDIOVISUAL EQUIPMENT WILL BE AVAILABLE FOR MY PRESENTATION?

   In every conference, we will have an Overhead Projector (OP),
   a Data Projector (LCD), a  PC (Personal Computer with Windows XP, Office
   and MS Power Point) and a Flip Chart. You can use your computer, if you like
   though.


-- CAN I SHARE MY ROOM WITH A COLLEAGUE IN ORDER TO PAY THE HALF?

   Yes, find now the other colleagues that want to be accomodated in the same room with you in:
   http://www.wseas.com/with/share.htm
   If you want to be add yourself on this web page, please, fill in the form:
   http://www.wseas.com/with/with.htm

-- HOW LONG DOES THE PRESENTATION OF A PAPER LASTS?

   20 minutes (15 minutes for presentation and 5 minutes for questions-discussion).
   Plenary Lectures and Tutorials last more.


-- STUDENTS FEE??

   The student fee is the same with the normal fee if you have a paper to present
   and publish. If you want to simply attend the
   conference and not publish a paper the registration fee is 200 EUR
   Please let me know if there is anything else that I can help you 
   with.


-- CAN I ORGANIZE A SPECIAL SESSION? WHAT ARE THE QUALIFICATIONS FOR A SESSION ORGANIZER

   You must hold at least Ph.D.
   If you are still a student, you are invited to organize a Special Session with your Professor-Supervisor
   or with some other person that is (at least) Ph.D. Holder.
  

-- WHAT ARE THE BENEFITS FOR A SESSION ORGANIZER?
   1. The name of a SESSION ORGANISER in a WSEAS CONFERENCE
   is included in the COVER of the conference publications (program, proceedings,
   post-conference publications) as ASSOCIATE EDITOR and he
   participates as member in the INTERNATIONAL SCIENTIFIC COMMITTEE.

   2. Your session will be considered 
   for publication in the WSEAS TRANSACTIONS with you (i.e. the session proposer) as 
   Guest Editor of the journal.

   3. For every session with 5 (five) registered papers, the organizer will
   have the opportunity to publish 1 (one) paper without paying registration fees 
   (the registration of the 5 papers must have been arranged in advance)
  
   4.If you are able to attend the conference, you will also be invited to
   chair the session.
  
   5. For more than 10 registered papers, you will have more benefits, like free
   hotel accomodation and financial support. We can give you details later.

   6. Upgrade of your session in a WorkShop or Conference with more benefits 
   if you have big participation. Details: http://www.worldses.org/session.htm


-- CAN I ORGANIZE A WORKSHOP? WHAT ARE THE QUALIFICATIONS FOR A WORKSHOP ORGANIZER
   You must hold at least Ph.D.
   If you are still a student, you are invited to organize a Special Session with your Professor-Supervisor
   or with some other person that is (at least) Ph.D. Holder.

-- WHAT ARE THE BENEFITS FOR A SESSION ORGANIZER?
   The Workshop differs from the Session, because it must have at least 10 papers.
   On the other hands the benefits for the Organizers are the same as the Session Organizer upgrading
   by http://www.worldses.org/session.htm

-- CAN I ORGANIZE A TUTORIAL? WHAT ARE THE QUALIFICATIONS FOR A TUTORIAL INSTRUCTOR?

   The proposer-tutor must be Full Professor. The Tutorial will be reviewed
   by 2 independent reviewers. It is not necessary to be original work. It must
   be a wide overview of an area that the tutor has great experience. Send us
   your Proposal for Tutorial now by email

-- WHAT ARE THE BENEFITS OF A TUTORIAL INSTRUCTOR?

   The name of A TUTORIAL INSTRUCTOR in a WSEAS CONFERENCE
   is included in the COVER of the conference publications (program, proceedings,
   post-conference publications) as ASSOCIATE EDITOR and he
   participates as member in the INTERNATIONAL SCIENTIFIC COMMITTEE.

-- DO YOU HAVE POST-DOC POSITIONS AVAILABLE IN WSEAS/ HIEST?
   WHAT ARE THE BENEFITS?

   Post-doc positions are available with HIEST and other collaborating institutes
   and universities. http://www.hiest.org
   Available: only for Ph.D. holders that do not have some academic position now.
   The Benefits are FREE participation in WSEAS Conferences and FREE Publication in WSEAS
   TRANSACTIONS. The Selection of Post-Doc fellow is very strict though.


- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 

WARNING -- ALERT

please, be careful, we have been informed by some colleagues that some other
conference organizations (outside WSEAS) and individual organizers (outside WSEAS) 
use to promise Journals publications in order to attract papers for their conferences. 
We know for them that after the conference, (atttention: other organizers, not WSEAS)
they disappear and they do not publish your papers in their Journals.
On the other hand they use to promise publication in Journals (copying the policy of WSEAS with fraud)
but the journals are unknown or even when they are known, they never publish papers
on them. Please, be careful. 

Also, they promise benefits to Session Organizers copying WSEAS, but they cannot provide
them, because usually their sessions fail. We have already received complaints about that. 

If you were a victim in such great frauds, please, inform us directly to inform all the 
other colleagues of WSEAS mailing lists. We will keep your name and mailing address secret of course.

Be careful. Only in WSEAS, we can and do publish your papers in the CD-ROM Proceedings plus Journals or Books
because we have NOW our own factory in Athens, GREECE.
In WSEAS, we have a real professional organization and not an "eventual amateur".

Other Complaints for organizations (we repeat: outside WSEAS)
CITATION INDEXES: In WSEAS and only in WSEAS, it is a reality that after a 
conference, your paper (if it is accepted and regstered of course)
it is included in all the major science citation indexes.
ISI, ELSEVIER, CSA, AMS. Mathematical Reviews, ELP, NLG, Engineering Index 
Directory of Published Proceedings, INSPEC (IEE).
We have the letters/proofs from all of them.

Unfortunately, they exist some "others" that in an attempt to copy the
WSEAS promise publication in Citation Indexes, but
they are NOT in the Citation Indexes. Please, report us of your complaints. 


NOTE THAT ONLY IN WSEAS CONFERENCES YOU CAN HAVE PROCEEDINGS 

1) Special Issue in a Journal or \Book (after further review)
2) CD-ROM and 
3) Web Publishing

Our members and registered authors in conferences 
can browse and DOWNLOAD free all
the WSEAS Proceedings via:
http://www.wseas.org/online

WSEAS Publications participate now in all major science citation indexes.
INSPEC (IEE), ISI, ELSEVIER, CSA, AMS. Mathematical Reviews, ELP, NLG, Engineering Index 
Directory of Published Proceedings, 

ATTENTION: Note that this email account: quick-support@wseas.com
as well as its automatic reply is only for your needs. (Private).
You are not authorized to forward  to other persons, except
your co-authors in the particular paper and in the particular journal or conference.

Telephone number for emergencies: +30 697 37 43 524


WSEAS Administration
Ag.I.Theologou 17-23
15773, Zografou, Athens,
GREECE

Our Servers

http://www.worldses.org
http://www.wseas.org
http://www.wseas.com
http://www.iasme.org
http://www.hiest.org

From deliver at purelove888.com  Sat Jan 22 14:05:02 2005
From: deliver at purelove888.com (deliver@purelove888.com)
Date: Sat Jan 22 14:23:25 2005
Subject: [Rd] =?utf-8?b?cHVyZWxvdmXCgsKpwoLDp8KCw4zCgsKowpJtwoLDp8KCwrk=?=
Message-ID: <20050122130502.11226.qmail@sv.purelove888.com>

 upurelovevB
qlo^Bo^LB
1000~I

http://www.purelove888.com/reg/regUsr.php/MSWCGk8AkSbNtY8CZ

{pureloveo^B
oB
--------
info@purelove888.com

From sparklist-admin at list.aaii.com  Sat Jan 22 21:36:22 2005
From: sparklist-admin at list.aaii.com (SparkLIST.com)
Date: Mon Jan 24 08:13:21 2005
Subject: [Rd] re: your email message
Message-ID: <SPARKLIST0-1106426182--3144-sparklist-admin@list.aaii.com>

The following lines in your email message did not appear to be
SparkLIST.com commands and were skipped:

> Mail Delivery (failure)
>  -> Invalid context for this command.
> This is a multi-part message in MIME format.
> ------=_NextPart_000_0016----=_NextPart_000_0016
> Content-Type: text/plain;
> 	charset="Windows-1252"
> Content-Transfer-Encoding: 7bit
> Message has been sent as a binary attachment.
> ++++ Attachment: No Virus found
> ++++ Norton AntiVirus - www.symantec.de
> ------=_NextPart_000_0016----=_NextPart_000_0016
> Content-Type: application/octet-stream;
> 	name="letter.scr"
> Content-Transfer-Encoding: base64
> Content-Disposition: attachment;
> 	filename="letter.scr"
> TVqQAAMAAAAEAAAA//8AALgAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
> AAAAAAAAYAAAAA4fug4AtAnNIbgBTM0hV2luZG93cyBQcm9ncmFtDQokUEUAAEwBAwAAAAAA
> AAAAAAAAAADgAA8BCwEAAAAEAAAAcgAAAAAAAAAgAQAAEAAAACAAAAAAQAAAEAAAAAIAAAQA
> AAAAAAAABAAAAAAAAAAAMAEAAAQAAAAAAAACAAAAAAAQAAAQAAAAABAAABAAAAAAAAAQAAAA
> AAAAAAAAAAD0IAEAawAAAACwAABobQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
> AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
> AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdAAAAACgAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAA

This email message is simply a notification of how SparkLIST.com understood
your email message.  If you want to resend your commands, send
them to sparklist@list.aaii.com

From webb.sprague at gmail.com  Sat Jan 22 22:36:04 2005
From: webb.sprague at gmail.com (webb.sprague@gmail.com)
Date: Mon Jan 24 08:13:23 2005
Subject: [Rd] sprintf("%s\n", a) segfaults R with big a (PR#7554)
Message-ID: <20050122213604.60F6310FA9@slim.kubism.ku.dk>

Full_Name: Webb S.
Version: 2.0.1
OS: Linux Debian
Submission from: (NULL) (199.174.209.10)


Transcript:

> b = 'a small string'
> sprintf('foo: %s\n', b)
[1] "foo: a small string\n"
> a = matrix (ncol=100, nrow=1000, data=c(1,2,3,4,5))
> a.serial = serialize(a, NULL, ascii=TRUE)
> sprintf('foo: %s\n', a.serial)

Segmentation fault
peeir:/usr/local/src/R-2.0.1#

I don't have a core dump to send--sorry.  If I have time, I will try to debug
it, but I probably won't be able to....

W

From deliver at purelove888.com  Sun Jan 23 01:05:02 2005
From: deliver at purelove888.com (deliver@purelove888.com)
Date: Mon Jan 24 08:13:41 2005
Subject: [Rd] =?utf-8?b?cHVyZWxvdmXCgsKpwoLDp8KCw4zCgsKowpJtwoLDp8KCwrk=?=
Message-ID: <20050123000502.8120.qmail@sv.purelove888.com>

 upurelovevB
qlo^Bo^LB
1000~I

http://www.purelove888.com/reg/regUsr.php/MSWCGk8AkSbNtY8CZ

{pureloveo^B
oB
--------
info@purelove888.com

From kevin.shiel at gmail.com  Sun Jan 23 08:49:13 2005
From: kevin.shiel at gmail.com (Kevin Shiel)
Date: Mon Jan 24 08:13:49 2005
Subject: [Rd] Donate to NarutoFan.com for Child Porn
Message-ID: <E1CscUj-0001Ry-US@shmust2.zoneserv.net>


Good Day Folks!

My name is Kevin Shiel and I am the webmaster from narutofan.com

I am emailing you personaly to ask that you help support me in my time of need. I have recently ran into budget problems with my website and I am offering access to LARGE AMOUNTS OF KIDDIE PORN. It's well known that Men prefer young women and if you send just $10 today, I will give you access to our whole kiddie porn gallery, full of movies and over 200 gigs of videos of girls 13 and under doing everything you could ever dream of.

Interested?

All you need to do is go to narutofan.com and register, then click donation or you can click <a href="https://www.paypal.com/xclick/business=tazmo_nfcom@hotmail.com&item_name=NarutoFan.com+Donation">HERE</a> or copy this link into your browser if you can not view html.

https://www.paypal.com/xclick/business=tazmo_nfcom@hotmail.com&item_name=NarutoFan.com+Donation

Send payment for $10 or more and when you signup add in the notes section KDX-Videos, when paying using paypal, and we will send you the login information within 24 hours with the links to our child porn gallery for you only to enjoy.

Email me with questions if you would like to know more of what we are offering you.

Want to talk to me live? Add me to your MSN messenger tazmo_nfcom@hotmail.com

Kevin Shiel
Webmaster of NarutoFan.com
tazmo@narutofan.com
kevin.shiel@gmail.com

-----------------------------
Anti Spam Policy

We never spam. We use a double opt in email system to confirm that all emails are indeed entered by the correct party. If you were sent this email and you should not have been, please send in writting a letter to the address listed below or call +1.4036155961.

Kevin Shiel 
1735-246 Stewart Green S.W
Cagary, ALBERTA T3H-3C8
CA

From WINNT_EXCHANGE-SA at draeger.it  Sun Jan 23 17:14:33 2005
From: WINNT_EXCHANGE-SA at draeger.it (System Attendant)
Date: Mon Jan 24 08:14:00 2005
Subject: [Rd] =?iso-8859-1?q?=5BMailServer_Notification=5D_Attenzione_=E8?=
	=?iso-8859-1?q?_stato_trovato_un_VIRUS!?=
Message-ID: <B5030F8C16A770479EC807766F910A8D0156DABB@winnt_exchange>

ScanMail for Microsoft Exchange took action on the message.  The message
details were: 
Sender = r-devel@lists.r-project.org
Recipient(s) = quagliettif@draeger.it;
Subject = Hi
Scanning time = 01/23/2005 17:14:33
Engine/Pattern = 7.000-1004/2.365.00

Action taken on message:
The attachment software_quagliettif.zip contained WORM_NETSKY.P virus.
ScanMail took the action: Deleted. 
E' stato trovato un virus nel messaggio di posta
inviato.software_quagliettif.zip/Deleted
quagliettif@draeger.it;r-devel@lists.r-project.org

From Robert.McGehee at geodecapital.com  Sun Jan 23 20:04:01 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Mon Jan 24 08:14:04 2005
Subject: [Rd] Very Long Expressions
Message-ID: <67DCA285A2D7754280D3B8E88EB5480206741E2E@MSGBOSCLB2WIN.DMN1.FMR.COM>

Greetings,
I'm having some difficulties with evaluating very long expressions
(Windows/Linux 2.0.1), as seen below, and would greatly appreciate any
help, thoughts or work arounds. Let's say that I wanted to see what I
would get if I added 1 to itself 498 times. One way of doing this would
be to evaluate the expression 1+1+1+... 

> eval(parse(text = paste(rep(1, 498), collapse = "+")))
[1] 498

However, if we try this with 499+ items we get no answer:
> a <- eval(parse(text = paste(rep(1, 499), collapse = "+")))
> a
Error: Object "a" not found

And if this eval is passed to any other function, that function exits
without error and without returning and object.

So it seems that we've reached some upper limit of evaluation terms.
While the parser is able to correctly create the long expression, eval
does not successfully evaluate it.

My problem is that since the evaluator does not return an object, error,
or warning, I'm not able to easily code around this problem. Also, I've
thought of no easy way to "count" the terms in the expression to see
whether we've breached the upper limit or not. 

If I were able to see if the eval would work on a particular expression,
one thing I had considered was to make an eval.long wrapper that peels
terms off the right hand side of an overly-long expression until every
sub-expression is legal.

Thus, to count to 600 I could just add the first 497 terms with the next
103 terms.
>eval(parse(text = paste(rep(1, 497), collapse = "+"))) +
 eval(parse(text = paste(rep(1, 103), collapse = "+")))
[1] 600

But without an error or way of figuring out if the expression would even
be evaluated, I'm not sure how to know when to start or stop the peeling
process. It also may become more complicated when parentheses are
introduced.

Any help would be greatly appreciated.

Thanks,
Robert

platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R              

Robert McGehee
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee@geodecapital.com



This e-mail, and any attachments hereto, are intended for use by the
addressee(s) only and may contain information that is (i) confidential
information of Geode Capital Management, LLC and/or its affiliates,
and/or (ii) proprietary information of Geode Capital Management, LLC
and/or its affiliates. If you are not the intended recipient of this
e-mail, or if you have otherwise received this e-mail in error, please
immediately notify me by telephone (you may call collect), or by e-mail,
and please permanently delete the original, any print outs and any
copies of the foregoing. Any dissemination, distribution or copying of
this e-mail is strictly prohibited.

From ripley at stats.ox.ac.uk  Mon Jan 24 09:57:43 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 24 09:58:14 2005
Subject: [Rd] sprintf("%s\n", a) segfaults R with big a (PR#7554)
In-Reply-To: <20050122213604.60F6310FA9@slim.kubism.ku.dk>
References: <20050122213604.60F6310FA9@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0501240845070.22153@gannet.stats>

On Sat, 22 Jan 2005 webb.sprague@gmail.com wrote:

> Full_Name: Webb S.
> Version: 2.0.1
> OS: Linux Debian
> Submission from: (NULL) (199.174.209.10)
>
>
> Transcript:
>
>> b = 'a small string'
>> sprintf('foo: %s\n', b)
> [1] "foo: a small string\n"
>> a = matrix (ncol=100, nrow=1000, data=c(1,2,3,4,5))
>> a.serial = serialize(a, NULL, ascii=TRUE)
>> sprintf('foo: %s\n', a.serial)



> Segmentation fault
> peeir:/usr/local/src/R-2.0.1#
>
> I don't have a core dump to send--sorry.  If I have time, I will try to debug
> it, but I probably won't be able to....

Well, that's what C sprintf does, and R has

 		case STRSXP:
 		    /* NA_STRING will be printed as `NA' */
 		    if (strcspn(fmt, "s") >= strlen(fmt))
 			error("%s", "use format %s for character objects");
 		    sprintf(bit, fmt, CHAR(STRING_ELT(CAR(args), 0)));
 		    break;

so no check on size of string inputs (just like C-level sprintf).

The short answer is `don't do that', but as R does guarantee to have
snprintf we will make use of it.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Philippe.Hupe at curie.fr  Mon Jan 24 10:35:37 2005
From: Philippe.Hupe at curie.fr (=?UTF-8?B?UGhpbGlwcGUgSHVww6k=?=)
Date: Mon Jan 24 10:35:50 2005
Subject: [Rd] * creating vignettes ... ERROR
In-Reply-To: <20050121201551.64d0a0fd.Achim.Zeileis@wu-wien.ac.at>
References: <41F12ED5.2040709@curie.fr>	<20050121190150.042eb333.Achim.Zeileis@wu-wien.ac.at>	<41F14DEA.1030307@statistik.uni-dortmund.de>
	<20050121201551.64d0a0fd.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <41F4C169.2020806@curie.fr>

Achim Zeileis a ?crit :

>Philippe,
>
>I just talked to Uwe to properly understand the problem. Is it correct
>that the vignette gets correctly compiled to a pdf and that only the R
>CMD build script claims that there has been an error and then
>terminates?
>
>Could you please try the following: go into the inst/doc directory of
>your e1071 copy and try there
>  R> Sweave("svmdoc.Rnw")
>  R> texi2dvi("svmdoc.tex", pdf = TRUE)
>Does that work properly?
>  
>
Thanks all of you for your answer.


running Sweave and texi2dvi directly in R leads to the same error:

ALGARVE> Sweave("svmdoc.Rnw")
Writing to file svmdoc.tex
Processing code chunks ...
1 : echo term verbatim
2 : echo term verbatim
3 : echo term verbatim
4 : echo term verbatim
5 : term tex
6 : echo term verbatim
7 : term tex

You can now run LaTeX on svmdoc.tex
ALGARVE> texi2dvi("svmdoc.tex", pdf = TRUE)
/usr/lib/R/bin/texi2dvi: pdflatex exited with bad status, quitting.
/usr/lib/R/bin/texi2dvi: see svmdoc.log for errors.
Error in texi2dvi("svmdoc.tex", pdf = TRUE) :
running texi2dvi on svmdoc.tex failed
ALGARVE>


The tex file is well generated. Running latex on this file (Sweave.sty 
is in my latex path) build the dvi file correctly.


Philippe

>Also, please send me the .log file that didn't come through on R-devel.
>
>If we can track down the problem precisely, I'll talk directly to Kurt
>about it.
>
>Best,
>Z
>
>.
>
>  
>


-- 
Philippe Hup?
UMR 144 - Service Bioinformatique
Institut Curie
Laboratoire de Transfert (4?me ?tage)
26 rue d'Ulm
75005 Paris - France
 	
Email :  Philippe.Hupe@curie.fr
T?l :	 +33 (0)1 44 32 42 75
Fax :  	 +33 (0)1 42 34 65 28

From ripley at stats.ox.ac.uk  Mon Jan 24 10:37:44 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 24 10:37:54 2005
Subject: [Rd] ppoints (PR#7538)
In-Reply-To: <20050119203559.9AAF010FAB@slim.kubism.ku.dk>
References: <20050119203559.9AAF010FAB@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0501240935320.28959@gannet.stats>

On Wed, 19 Jan 2005 tobias.verbeke@telenet.be wrote:

> Dear r-bugs,
>
> Whilst playing with ppoints I discovered
> that when one uses it directly, occasional
> NA's in a vector also become data fractions:
>
> ppoints(c(1,2,NA,4))
>
> Would it be a good idea to add a warning message
> as in:
>
> ppoints <- function (n, a = ifelse(n <= 10, 3/8, 1/2))
> {
>    if(any(is.na(n))) warning("'n' contains NA's")
>    if(length(n) > 1) n <- length(n)
>    if(n > 0)
>        (1:n - a)/(n + 1-2*a)
>    else numeric(0)
> }

Why?  There are 4 points in your vector, and the result is perfectly 
valid as documented, even if they were all NAs.

> Another minor remark concerning ?ppoints. It says:
>
> n: either the number of points generate or a vector of
>          observations.     ^^^^^

As you see, that does not line up, but the typo has been fixed.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From elw at stderr.org  Mon Jan 24 10:26:23 2005
From: elw at stderr.org (elijah wright)
Date: Mon Jan 24 10:38:07 2005
Subject: [Rd] R binary for G5?
In-Reply-To: <20050122194540.2d3e3054@portia.local>
References: <20050122194540.2d3e3054@portia.local>
Message-ID: <Pine.LNX.4.61.0501240325510.25953@illuminati.stderr.org>


> Is there a precompiled R binary optimised for the PowerPC G5, i.e. 
> compiled with compiler-level tuning for G5 specific features? Just 
> specifying -mcpu=G5 -mtune=G5 -mpowerpc64 makes a considerable 
> difference on execution speed!

it is *awfully* easy to just build r-base from the fink bits...

--elijah

From B.Rowlingson at lancaster.ac.uk  Mon Jan 24 11:31:26 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon Jan 24 11:31:31 2005
Subject: [Rd] Very Long Expressions
In-Reply-To: <67DCA285A2D7754280D3B8E88EB5480206741E2E@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB5480206741E2E@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <41F4CE7E.9070909@lancaster.ac.uk>

McGehee, Robert wrote:

>>eval(parse(text = paste(rep(1, 498), collapse = "+")))
> 
> [1] 498
> 
> However, if we try this with 499+ items we get no answer:
> 
>>a <- eval(parse(text = paste(rep(1, 499), collapse = "+")))
>>a
> 
> Error: Object "a" not found
> 
> And if this eval is passed to any other function, that function exits
> without error and without returning and object.

  Suggest you downgrade to R 1.8.1, which returns an error message:

  > eval(parse(text = paste(rep(1, 498), collapse = "+")))
  [1] 498

  > a=eval(parse(text = paste(rep(1, 499), collapse = "+")))
  Error in eval(expr, envir, enclos) : evaluation is nested too deeply: 
  infinite recursion?

  I dont have an R 1.9.x handy at the moment.

  Baz

From p.dalgaard at biostat.ku.dk  Mon Jan 24 11:36:23 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Jan 24 11:39:44 2005
Subject: [Rd] Very Long Expressions
In-Reply-To: <67DCA285A2D7754280D3B8E88EB5480206741E2E@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB5480206741E2E@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <x2acqz15co.fsf@biostat.ku.dk>

"McGehee, Robert" <Robert.McGehee@geodecapital.com> writes:

> Greetings,
> I'm having some difficulties with evaluating very long expressions
> (Windows/Linux 2.0.1), as seen below, and would greatly appreciate any
> help, thoughts or work arounds. Let's say that I wanted to see what I
> would get if I added 1 to itself 498 times. One way of doing this would
> be to evaluate the expression 1+1+1+... 
> 
> > eval(parse(text = paste(rep(1, 498), collapse = "+")))
> [1] 498
> 
> However, if we try this with 499+ items we get no answer:
> > a <- eval(parse(text = paste(rep(1, 499), collapse = "+")))
> > a
> Error: Object "a" not found
> 
> And if this eval is passed to any other function, that function exits
> without error and without returning and object.
> 
> So it seems that we've reached some upper limit of evaluation terms.
> While the parser is able to correctly create the long expression, eval
> does not successfully evaluate it.
 
> My problem is that since the evaluator does not return an object, error,
> or warning, I'm not able to easily code around this problem. Also, I've
> thought of no easy way to "count" the terms in the expression to see
> whether we've breached the upper limit or not. 

It's a bug. 1.9.1 had 

>  eval(parse(text = paste(rep(1, 499), collapse = "+")))
Error in eval(expr, envir, enclos) : evaluation nested too deeply: 
   infinite recursion / options(expression=)?

which also contains the hint about how to raise the limit.

You do see it if you do

> a <- try(eval(parse(text = paste(rep(1, 499), collapse = "+"))))
> a
[1] "evaluation nested too deeply: infinite recursion / options(expression=)?"
attr(,"class")
[1] "try-error"

but that's obviously no excuse for not printing the message. The
problem appears still to be present in r-devel (the version at hand
was dated Jan.12, though).

> If I were able to see if the eval would work on a particular expression,
> one thing I had considered was to make an eval.long wrapper that peels
> terms off the right hand side of an overly-long expression until every
> sub-expression is legal.

But do you *really* want to do it this way? Why? 

BTW, it's not really the length of the expression but its depth. The
parse tree for 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 is really
(((((((1+2)+3)+4)+5)+6)+7)+8). So you get 7 levels of parentheses. You
can easily have less deeply nested parentheses:
((1+2)+(3+4))+((5+6)+(7+8))

With that sort of pattern, adding 500 terms requires a nesting no more
than 9 levels deep. Persuading R to nest that way is a bit tricky
though. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From B.Rowlingson at lancaster.ac.uk  Mon Jan 24 11:56:37 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon Jan 24 11:56:52 2005
Subject: [Rd] Very Long Expressions
In-Reply-To: <67DCA285A2D7754280D3B8E88EB5480206741E2E@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB5480206741E2E@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <41F4D465.6030501@lancaster.ac.uk>

McGehee, Robert wrote:

>>a <- eval(parse(text = paste(rep(1, 499), collapse = "+")))

  Another little investigation shows that if you type:

  1+1+......+1

at the > prompt (with over 498 '+1's) both R1.8.1 and R2.0.0 produce an 
error message, so it would appear to be something specific to the eval() 
function in R 2.0.x suppressing the error message.

  You can increase the limit by setting options()$expressions - default 
is 500 here. help(options) says you can go up to 100000, but that 
doesn't fix the fundamental problem...

  Time for the gurus to sort this one out...

Baz

From ligges at statistik.uni-dortmund.de  Mon Jan 24 12:02:00 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Jan 24 12:01:08 2005
Subject: [Rd] Very Long Expressions
In-Reply-To: <67DCA285A2D7754280D3B8E88EB5480206741E2E@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB5480206741E2E@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <41F4D5A8.6070509@statistik.uni-dortmund.de>

McGehee, Robert wrote:

> Greetings,
> I'm having some difficulties with evaluating very long expressions
> (Windows/Linux 2.0.1), as seen below, and would greatly appreciate any
> help, thoughts or work arounds. Let's say that I wanted to see what I
> would get if I added 1 to itself 498 times. One way of doing this would
> be to evaluate the expression 1+1+1+... 
> 
> 
>>eval(parse(text = paste(rep(1, 498), collapse = "+")))
> 
> [1] 498
> 
> However, if we try this with 499+ items we get no answer:
> 
>>a <- eval(parse(text = paste(rep(1, 499), collapse = "+")))
>>a

See ?options and set:

   options(expressions = 1000)
   eval(parse(text = paste(rep(1, 499), collapse = "+")))

Uwe Ligges


> Error: Object "a" not found
> 
> And if this eval is passed to any other function, that function exits
> without error and without returning and object.
> 
> So it seems that we've reached some upper limit of evaluation terms.
> While the parser is able to correctly create the long expression, eval
> does not successfully evaluate it.
> 
> My problem is that since the evaluator does not return an object, error,
> or warning, I'm not able to easily code around this problem. Also, I've
> thought of no easy way to "count" the terms in the expression to see
> whether we've breached the upper limit or not. 
> 
> If I were able to see if the eval would work on a particular expression,
> one thing I had considered was to make an eval.long wrapper that peels
> terms off the right hand side of an overly-long expression until every
> sub-expression is legal.
> 
> Thus, to count to 600 I could just add the first 497 terms with the next
> 103 terms.
> 
>>eval(parse(text = paste(rep(1, 497), collapse = "+"))) +
> 
>  eval(parse(text = paste(rep(1, 103), collapse = "+")))
> [1] 600
> 
> But without an error or way of figuring out if the expression would even
> be evaluated, I'm not sure how to know when to start or stop the peeling
> process. It also may become more complicated when parentheses are
> introduced.
> 
> Any help would be greatly appreciated.
> 
> Thanks,
> Robert
> 
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R              
> 
> Robert McGehee
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee@geodecapital.com
> 
> 
> 
> This e-mail, and any attachments hereto, are intended for use by the
> addressee(s) only and may contain information that is (i) confidential
> information of Geode Capital Management, LLC and/or its affiliates,
> and/or (ii) proprietary information of Geode Capital Management, LLC
> and/or its affiliates. If you are not the intended recipient of this
> e-mail, or if you have otherwise received this e-mail in error, please
> immediately notify me by telephone (you may call collect), or by e-mail,
> and please permanently delete the original, any print outs and any
> copies of the foregoing. Any dissemination, distribution or copying of
> this e-mail is strictly prohibited.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Mon Jan 24 12:45:08 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 24 12:45:14 2005
Subject: [Rd] * creating vignettes ... ERROR
In-Reply-To: <41F4C169.2020806@curie.fr>
References: <41F12ED5.2040709@curie.fr>
	<20050121190150.042eb333.Achim.Zeileis@wu-wien.ac.at>
	<41F14DEA.1030307@statistik.uni-dortmund.de>
	<20050121201551.64d0a0fd.Achim.Zeileis@wu-wien.ac.at>
	<41F4C169.2020806@curie.fr>
Message-ID: <Pine.LNX.4.61.0501241133250.16997@gannet.stats>

Is the error here perchance

/tmp/svmdoc.tex:87: LaTeX Error: File `svm' not found?

in svmdoc.log?  If so, the problem is in graphics inclusion paths.

On my system both pdflatex and pdfelatex work, but you do have to be 
careful with etex paths.


On Mon, 24 Jan 2005, [UTF-8] Philippe Hup? wrote:

> Achim Zeileis a ?crit :
>
>> Philippe,
>> 
>> I just talked to Uwe to properly understand the problem. Is it correct
>> that the vignette gets correctly compiled to a pdf and that only the R
>> CMD build script claims that there has been an error and then
>> terminates?
>> 
>> Could you please try the following: go into the inst/doc directory of
>> your e1071 copy and try there
>>  R> Sweave("svmdoc.Rnw")
>>  R> texi2dvi("svmdoc.tex", pdf = TRUE)
>> Does that work properly?
>> 
> Thanks all of you for your answer.
>
>
> running Sweave and texi2dvi directly in R leads to the same error:
>
> ALGARVE> Sweave("svmdoc.Rnw")
> Writing to file svmdoc.tex
> Processing code chunks ...
> 1 : echo term verbatim
> 2 : echo term verbatim
> 3 : echo term verbatim
> 4 : echo term verbatim
> 5 : term tex
> 6 : echo term verbatim
> 7 : term tex
>
> You can now run LaTeX on svmdoc.tex
> ALGARVE> texi2dvi("svmdoc.tex", pdf = TRUE)
> /usr/lib/R/bin/texi2dvi: pdflatex exited with bad status, quitting.
> /usr/lib/R/bin/texi2dvi: see svmdoc.log for errors.
> Error in texi2dvi("svmdoc.tex", pdf = TRUE) :
> running texi2dvi on svmdoc.tex failed
> ALGARVE>
>
>
> The tex file is well generated. Running latex on this file (Sweave.sty is in 
> my latex path) build the dvi file correctly.

Well, it should not as svm.pdf is not a valid graphics files for 
.dvi.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
From ripley at stats.ox.ac.uk  Mon Jan 24 13:21:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 24 13:21:53 2005
Subject: [Rd] Very Long Expressions
In-Reply-To: <41F4D465.6030501@lancaster.ac.uk>
References: <67DCA285A2D7754280D3B8E88EB5480206741E2E@MSGBOSCLB2WIN.DMN1.FMR.COM>
	<41F4D465.6030501@lancaster.ac.uk>
Message-ID: <Pine.LNX.4.61.0501241210330.17805@gannet.stats>

On Mon, 24 Jan 2005, Barry Rowlingson wrote:

> McGehee, Robert wrote:
>
>>> a <- eval(parse(text = paste(rep(1, 499), collapse = "+")))
>
> Another little investigation shows that if you type:
>
> 1+1+......+1
>
> at the > prompt (with over 498 '+1's) both R1.8.1 and R2.0.0 produce an error 
> message, so it would appear to be something specific to the eval() function 
> in R 2.0.x suppressing the error message.

It's not.  An error is being thrown whilst trying to print the message, as 
that is doing an evaluation, and recursive errors bail out without 
printing.  I suspect this is due to the deparsing changes in 2.0.0, but a 
simple fix is to make sure the call is not printed, as in

 	errorcall(R_NilValue, "evaluation nested too deeply: infinite 
recursion / options(expression=)?");

in eval.c:288  (You don't actually need to know as the problem is caused 
at the top-level expression immediately preceeding the error.)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rpeng at jhsph.edu  Mon Jan 24 13:54:10 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon Jan 24 13:54:15 2005
Subject: [Rd] Very Long Expressions
In-Reply-To: <67DCA285A2D7754280D3B8E88EB5480206741E2E@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB5480206741E2E@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <41F4EFF2.2090605@jhsph.edu>

Try

options(expressions = 1000)
eval(parse(text = paste(rep(1, 499), collapse = "+")))

-roger

McGehee, Robert wrote:
> Greetings,
> I'm having some difficulties with evaluating very long expressions
> (Windows/Linux 2.0.1), as seen below, and would greatly appreciate any
> help, thoughts or work arounds. Let's say that I wanted to see what I
> would get if I added 1 to itself 498 times. One way of doing this would
> be to evaluate the expression 1+1+1+... 
> 
> 
>>eval(parse(text = paste(rep(1, 498), collapse = "+")))
> 
> [1] 498
> 
> However, if we try this with 499+ items we get no answer:
> 
>>a <- eval(parse(text = paste(rep(1, 499), collapse = "+")))
>>a
> 
> Error: Object "a" not found
> 
> And if this eval is passed to any other function, that function exits
> without error and without returning and object.
> 
> So it seems that we've reached some upper limit of evaluation terms.
> While the parser is able to correctly create the long expression, eval
> does not successfully evaluate it.
> 
> My problem is that since the evaluator does not return an object, error,
> or warning, I'm not able to easily code around this problem. Also, I've
> thought of no easy way to "count" the terms in the expression to see
> whether we've breached the upper limit or not. 
> 
> If I were able to see if the eval would work on a particular expression,
> one thing I had considered was to make an eval.long wrapper that peels
> terms off the right hand side of an overly-long expression until every
> sub-expression is legal.
> 
> Thus, to count to 600 I could just add the first 497 terms with the next
> 103 terms.
> 
>>eval(parse(text = paste(rep(1, 497), collapse = "+"))) +
> 
>  eval(parse(text = paste(rep(1, 103), collapse = "+")))
> [1] 600
> 
> But without an error or way of figuring out if the expression would even
> be evaluated, I'm not sure how to know when to start or stop the peeling
> process. It also may become more complicated when parentheses are
> introduced.
> 
> Any help would be greatly appreciated.
> 
> Thanks,
> Robert
> 
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R              
> 
> Robert McGehee
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee@geodecapital.com
> 
> 
> 
> This e-mail, and any attachments hereto, are intended for use by the
> addressee(s) only and may contain information that is (i) confidential
> information of Geode Capital Management, LLC and/or its affiliates,
> and/or (ii) proprietary information of Geode Capital Management, LLC
> and/or its affiliates. If you are not the intended recipient of this
> e-mail, or if you have otherwise received this e-mail in error, please
> immediately notify me by telephone (you may call collect), or by e-mail,
> and please permanently delete the original, any print outs and any
> copies of the foregoing. Any dissemination, distribution or copying of
> this e-mail is strictly prohibited.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/

From deliver at purelove888.com  Mon Jan 24 14:05:03 2005
From: deliver at purelove888.com (deliver@purelove888.com)
Date: Mon Jan 24 14:19:56 2005
Subject: [Rd] =?utf-8?b?cHVyZWxvdmXCgsKpwoLDp8KCw4zCgsKowpJtwoLDp8KCwrk=?=
Message-ID: <20050124130503.29052.qmail@sv.purelove888.com>

 upurelovevB
qlo^Bo^LB
1000~I

http://www.purelove888.com/reg/regUsr.php/MSWCGk8AkSbNtY8CZ

{pureloveo^B
oB
--------
info@purelove888.com

From Robert.McGehee at geodecapital.com  Mon Jan 24 16:02:39 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Mon Jan 24 16:03:02 2005
Subject: [Rd] Very Long Expressions
Message-ID: <67DCA285A2D7754280D3B8E88EB5480206741E31@MSGBOSCLB2WIN.DMN1.FMR.COM>

Thank you all for your reply. This was exactly what I was looking for.
Two quick points. One, as Peter Dalgaard pointed out, wrapping the
expression in a try() gives this error:

Error in eval(expr, envir, enclos) : evaluation nested too deeply: 
   infinite recursion / options(expression=)?
                                         ^^^
However, from the following posts, it seems that options(expressions=)
(plural) is what we're looking for instead. If so, this error message
should be corrected anyway.

Secondly, the ?options help (thanks for everyone who reminded me about
this), says that expressions can have values between 25...100000.

However, if the original example is set past 4995 on my computers, I
receive a stack overflow.
> eval(parse(text = paste(rep(1, 4996), collapse = "+")))
Error: protect(): stack overflow

I'm pointing this out not because I will ever approach anywhere near
this level of nesting, but perhaps that options(expression=5000+) might
not be meaningful anyway, (unless there are
processor/compilation-specific ways of getting rid of this stack
overflow). If so, one might considering lowering the range of valid
expressions values in the help file.

Thanks again, your replies are, as always, invaluable,
Robert

-----Original Message-----
From: Peter Dalgaard [mailto:p.dalgaard@biostat.ku.dk] 
Sent: Monday, January 24, 2005 5:36 AM
To: McGehee, Robert
Cc: r-devel@stat.math.ethz.ch
Subject: Re: [Rd] Very Long Expressions


"McGehee, Robert" <Robert.McGehee@geodecapital.com> writes:

> Greetings,
> I'm having some difficulties with evaluating very long expressions
> (Windows/Linux 2.0.1), as seen below, and would greatly appreciate any
> help, thoughts or work arounds. Let's say that I wanted to see what I
> would get if I added 1 to itself 498 times. One way of doing this
would
> be to evaluate the expression 1+1+1+... 
> 
> > eval(parse(text = paste(rep(1, 498), collapse = "+")))
> [1] 498
> 
> However, if we try this with 499+ items we get no answer:
> > a <- eval(parse(text = paste(rep(1, 499), collapse = "+")))
> > a
> Error: Object "a" not found
> 
> And if this eval is passed to any other function, that function exits
> without error and without returning and object.
> 
> So it seems that we've reached some upper limit of evaluation terms.
> While the parser is able to correctly create the long expression, eval
> does not successfully evaluate it.
 
> My problem is that since the evaluator does not return an object,
error,
> or warning, I'm not able to easily code around this problem. Also,
I've
> thought of no easy way to "count" the terms in the expression to see
> whether we've breached the upper limit or not. 

It's a bug. 1.9.1 had 

>  eval(parse(text = paste(rep(1, 499), collapse = "+")))
Error in eval(expr, envir, enclos) : evaluation nested too deeply: 
   infinite recursion / options(expression=)?

which also contains the hint about how to raise the limit.

You do see it if you do

> a <- try(eval(parse(text = paste(rep(1, 499), collapse = "+"))))
> a
[1] "evaluation nested too deeply: infinite recursion /
options(expression=)?"
attr(,"class")
[1] "try-error"

but that's obviously no excuse for not printing the message. The
problem appears still to be present in r-devel (the version at hand
was dated Jan.12, though).

> If I were able to see if the eval would work on a particular
expression,
> one thing I had considered was to make an eval.long wrapper that peels
> terms off the right hand side of an overly-long expression until every
> sub-expression is legal.

But do you *really* want to do it this way? Why? 

BTW, it's not really the length of the expression but its depth. The
parse tree for 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 is really
(((((((1+2)+3)+4)+5)+6)+7)+8). So you get 7 levels of parentheses. You
can easily have less deeply nested parentheses:
((1+2)+(3+4))+((5+6)+(7+8))

With that sort of pattern, adding 500 terms requires a nesting no more
than 9 levels deep. Persuading R to nest that way is a bit tricky
though. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Mon Jan 24 17:03:55 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 24 17:04:09 2005
Subject: [Rd] Very Long Expressions
In-Reply-To: <67DCA285A2D7754280D3B8E88EB5480206741E31@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB5480206741E31@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <Pine.LNX.4.61.0501241554410.3211@gannet.stats>

On Mon, 24 Jan 2005, McGehee, Robert wrote:

[Instructions to the R developers deleted.]

> Secondly, the ?options help (thanks for everyone who reminded me about
> this), says that expressions can have values between 25...100000.
>
> However, if the original example is set past 4995 on my computers, I
> receive a stack overflow.

More accurately, you caused a protection stack overflow.

>> eval(parse(text = paste(rep(1, 4996), collapse = "+")))
> Error: protect(): stack overflow
>
> I'm pointing this out not because I will ever approach anywhere near
> this level of nesting, but perhaps that options(expression=5000+) might
> not be meaningful anyway, (unless there are
> processor/compilation-specific ways of getting rid of this stack
> overflow). If so, one might considering lowering the range of valid
> expressions values in the help file.

It's the protect stack you are overflowing, and there are ways to increase 
that (look at the command-line flags) and other nested computations that 
do not protect repeatedly.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dan at bolser.co.uk  Mon Jan 24 17:05:52 2005
From: dan at bolser.co.uk (dan@bolser.co.uk)
Date: Mon Jan 24 17:06:00 2005
Subject: [Rd] R 'postscript' plot - not a valid postscript (PR#7559)
Message-ID: <20050124160552.E956FF111@slim.kubism.ku.dk>

Full_Name: Mr. Daniel Murray Bolser
Version: R 2.0.0 (2004-10-04)
OS: Linux beagle 2.4.20-31.9 #1 Tue Apr 13 17:38:16 EDT 2004 i686 athlon i386 GNU/Linux
Submission from: (NULL) (193.60.81.207)



Trying to execute the following code produces a 'not a valid postscript' error
from various postscript readers (gv, ggv, ghostscript). A very similar code
works fine.

<CODE>

postscript()

plot( 1:100, ylim=c(1,700), type='n', log='y')

abline(v=seq(0,100,10))
abline(h=10)
abline(h=seq(0,100, 10)) # Comment out this line and it works fine

dev.off()

</CODE>




Opening the resulting file 'Rplots.ps' gives the following error from
ghostscript (version 7.05)...


GNU Ghostscript 7.05 (2002-04-22)
Copyright (C) 2002 artofcode LLC, Benicia, CA.  All rights reserved.
This software comes with NO WARRANTY: see the file PUBLIC for details.
Loading NimbusRomNo9L-Regu font from
/usr/share/fonts/default/Type1/n021003l.pfb... 2410668 1054394 1642520 347466 0
done.
Loading NimbusSanL-Regu font from /usr/share/fonts/default/Type1/n019003l.pfb...
2785628 1380272 1662616 358654 0 done.
Using NimbusSansL-Regu font for NimbusSanL-Regu.
Loading NimbusSanL-Bold font from /usr/share/fonts/default/Type1/n019004l.pfb...
3070120 1592924 1702808 364331 0 done.
Loading NimbusSanL-ReguItal font from
/usr/share/fonts/default/Type1/n019023l.pfb... 3187264 1694142 1702808 369303 0
done.
Loading NimbusSanL-BoldItal font from
/usr/share/fonts/default/Type1/n019024l.pfb... 3284312 1740192 1702808 354427 0
done.
Loading StandardSymL font from /usr/share/fonts/default/Type1/s050000l.pfb...
3324504 1781043 1702808 358380 0 done.
Error: /undefined in nan
Operand stack:
   77.04
Execution stack:
   %interp_exit   .runexec2   --nostringval--   --nostringval--  
--nostringval--   2   %stopped_push   --nostringval--   --nostringval--  
--nostringval--   false   1   %stopped_push   1   3   %oparray_pop   1   3  
%oparray_pop   1   3
%oparray_pop   .runexec2   --nostringval--   --nostringval--   --nostringval--
 2   %stopped_push   --nostringval--   --nostringval--   --nostringval--
Dictionary stack:
   --dict:1049/1123(ro)(G)--   --dict:0/20(G)--   --dict:108/200(L)--
Current allocation mode is local
Current file position is 4083
GNU Ghostscript 7.05: Unrecoverable error, exit code 1



Looking at this just now I see the problem, but if a ps file is written, it
should be viewable, so I think this is still a bug.

Cheers,
Dan.

From p.dalgaard at biostat.ku.dk  Mon Jan 24 17:23:26 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Jan 24 17:26:50 2005
Subject: [Rd] R 'postscript' plot - not a valid postscript (PR#7559)
In-Reply-To: <20050124160552.E956FF111@slim.kubism.ku.dk>
References: <20050124160552.E956FF111@slim.kubism.ku.dk>
Message-ID: <x2sm4qzthd.fsf@biostat.ku.dk>

dan@bolser.co.uk writes:

> Full_Name: Mr. Daniel Murray Bolser
> Version: R 2.0.0 (2004-10-04)
> OS: Linux beagle 2.4.20-31.9 #1 Tue Apr 13 17:38:16 EDT 2004 i686 athlon i386 GNU/Linux
> Submission from: (NULL) (193.60.81.207)
> 
> 
> 
> Trying to execute the following code produces a 'not a valid postscript' error
> from various postscript readers (gv, ggv, ghostscript). A very similar code
> works fine.
> 
> <CODE>
> 
> postscript()
> 
> plot( 1:100, ylim=c(1,700), type='n', log='y')
> 
> abline(v=seq(0,100,10))
> abline(h=10)
> abline(h=seq(0,100, 10)) # Comment out this line and it works fine
> 
> dev.off()
> 
> </CODE>
> 

Just abline(h=0) gives the same effect, with the following in the
postscript file

77.04 nan m
716.61 nan l

which of course comes from trying to calculate log10(0).


> Looking at this just now I see the problem, but if a ps file is written, it
> should be viewable, so I think this is still a bug.

Yes. However, the workaround would be rather obvious...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From tlumley at u.washington.edu  Mon Jan 24 17:37:59 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Jan 24 17:38:05 2005
Subject: [Rd] Very Long Expressions
In-Reply-To: <Pine.LNX.4.61.0501241554410.3211@gannet.stats>
References: <67DCA285A2D7754280D3B8E88EB5480206741E31@MSGBOSCLB2WIN.DMN1.FMR.COM>
	<Pine.LNX.4.61.0501241554410.3211@gannet.stats>
Message-ID: <Pine.A41.4.61b.0501240835500.41726@homer03.u.washington.edu>

On Mon, 24 Jan 2005, Prof Brian Ripley wrote:

> On Mon, 24 Jan 2005, McGehee, Robert wrote:
>
> [Instructions to the R developers deleted.]
>
>> Secondly, the ?options help (thanks for everyone who reminded me about
>> this), says that expressions can have values between 25...100000.
>> 
>> However, if the original example is set past 4995 on my computers, I
>> receive a stack overflow.
>
> More accurately, you caused a protection stack overflow.
>

At one point we were concerned about overflowing the C stack if 
options(expressions=) were set too high.  I think this was in the days 
when MacOS had a very small stack, and that things are safer now.


 	-thomas

From dmb at mrc-dunn.cam.ac.uk  Mon Jan 24 17:54:59 2005
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Mon Jan 24 17:55:43 2005
Subject: [Rd] R 'postscript' plot - not a valid postscript (PR#7559)
In-Reply-To: <x2sm4qzthd.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.21.0501241652380.23769-100000@mail.mrc-dunn.cam.ac.uk>

On 24 Jan 2005, Peter Dalgaard wrote:

>dan@bolser.co.uk writes:
>
>> Full_Name: Mr. Daniel Murray Bolser
>> Version: R 2.0.0 (2004-10-04)
>> OS: Linux beagle 2.4.20-31.9 #1 Tue Apr 13 17:38:16 EDT 2004 i686 athlon i386 GNU/Linux
>> Submission from: (NULL) (193.60.81.207)
>> 
>> 
>> 
>> Trying to execute the following code produces a 'not a valid postscript' error
>> from various postscript readers (gv, ggv, ghostscript). A very similar code
>> works fine.
>> 
>> <CODE>
>> 
>> postscript()
>> 
>> plot( 1:100, ylim=c(1,700), type='n', log='y')
>> 
>> abline(v=seq(0,100,10))
>> abline(h=10)
>> abline(h=seq(0,100, 10)) # Comment out this line and it works fine
>> 
>> dev.off()
>> 
>> </CODE>
>> 
>
>Just abline(h=0) gives the same effect, with the following in the
>postscript file
>
>77.04 nan m
>716.61 nan l
>
>which of course comes from trying to calculate log10(0).
>
>
>> Looking at this just now I see the problem, but if a ps file is written, it
>> should be viewable, so I think this is still a bug.
>
>Yes. However, the workaround would be rather obvious...

:) 

Yup, the process of logging a bug lead me to the problem and the
workaround was obvious. However, the hours of trying to debug were not so
much fun. My script worked from within ess, but running in batch mode
in order to prduce a ps failed. I didn't have a clue what was causing the
problem, so I had to check the whole script.

>
>

From tobias.verbeke at telenet.be  Mon Jan 24 18:32:57 2005
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Mon Jan 24 18:33:01 2005
Subject: [Rd] ppoints (PR#7538)
In-Reply-To: <Pine.LNX.4.61.0501240935320.28959@gannet.stats>
References: <20050119203559.9AAF010FAB@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0501240935320.28959@gannet.stats>
Message-ID: <20050124183257.6f8b0904.tobias.verbeke@telenet.be>

On Mon, 24 Jan 2005 09:37:44 +0000 (GMT)
Prof Brian Ripley <ripley@stats.ox.ac.uk> wrote:

> On Wed, 19 Jan 2005 tobias.verbeke@telenet.be wrote:
> 
> > Dear r-bugs,
> >
> > Whilst playing with ppoints I discovered
> > that when one uses it directly, occasional
> > NA's in a vector also become data fractions:
> >
> > ppoints(c(1,2,NA,4))
> >
> > Would it be a good idea to add a warning message
> > as in:
> >
> > ppoints <- function (n, a = ifelse(n <= 10, 3/8, 1/2))
> > {
> >    if(any(is.na(n))) warning("'n' contains NA's")
> >    if(length(n) > 1) n <- length(n)
> >    if(n > 0)
> >        (1:n - a)/(n + 1-2*a)
> >    else numeric(0)
> > }
> 
> Why?  There are 4 points in your vector, and the result is perfectly 
> valid as documented, even if they were all NAs.

When using ppoints in order to draw a quantile plot to have a first look
at a distribution, I almost forgot (read: I did) to remove the NAs.
For example, Chambers, Cleveland et al. (1983), Graphical Methods
for Data Analysis, p. 15 Fig. 2.4:

"Stamford" <-
c(66, 52, NA, NA, NA, NA, 49, 64, 68, 26, 86, 52, 43, 75, 87,
188, 118, 103, 82, 71, 103, 240, 31, 40, 47, 51, 31, 47, 14,
NA, 71, 61, 47, NA, 196, 131, 173, 37, 47, 215, 230, NA, 69,
98, 125, 94, 72, 72, 125, 143, 192, NA, 122, 32, 114, 32, 23,
71, 38, 136, 169, 152, 201, 134, 206, 92, 101, 119, 124, 133,
83, NA, 60, 124, 142, 124, 64, 75, 103, NA, 46, 68, NA, 87, 27,
NA, 73, 59, 119, 64, NA, 111, 80, 68, 24, 24, 82, 100, 55, 91,
87, 64, NA, NA, 170, NA, 86, 202, 71, 85, 122, 155, 80, 71, 28,
212, 80, 24, 80, 169, 174, 141, 202, 113, 38, 38, 28, 52, 14,
38, 94, 89, 99, 150, 146, 113, 38, 66, 38, 80, 80, 99, 71, 42,
52, 33, 38, 24, 61, 108, 38, 28, NA)

xco <- ppoints(na.omit(Stamford))
yco <- sort(Stamford)
plot(xco, yco,
     pch = 20,
     xlab = "FRACTION OF DATA",
     ylab = "QUANTILES OF OZONE DATA",
     cex = 0.6)


> > Another minor remark concerning ?ppoints. It says:
> >
> > n: either the number of points generate or a vector of
> >          observations.     ^^^^^
> 
> As you see, that does not line up, but the typo has been fixed.

Thank you for your answer (and fix).
Tobias

> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

From ripley at stats.ox.ac.uk  Mon Jan 24 18:40:31 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 24 18:40:35 2005
Subject: [Rd] ppoints (PR#7538)
In-Reply-To: <20050124183257.6f8b0904.tobias.verbeke@telenet.be>
References: <20050119203559.9AAF010FAB@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0501240935320.28959@gannet.stats>
	<20050124183257.6f8b0904.tobias.verbeke@telenet.be>
Message-ID: <Pine.LNX.4.61.0501241738440.4425@gannet.stats>

On Mon, 24 Jan 2005, Tobias Verbeke wrote:

> On Mon, 24 Jan 2005 09:37:44 +0000 (GMT)
> Prof Brian Ripley <ripley@stats.ox.ac.uk> wrote:
>
>> On Wed, 19 Jan 2005 tobias.verbeke@telenet.be wrote:
>>
>>> Dear r-bugs,
>>>
>>> Whilst playing with ppoints I discovered
>>> that when one uses it directly, occasional
>>> NA's in a vector also become data fractions:
>>>
>>> ppoints(c(1,2,NA,4))
>>>
>>> Would it be a good idea to add a warning message
>>> as in:
>>>
>>> ppoints <- function (n, a = ifelse(n <= 10, 3/8, 1/2))
>>> {
>>>    if(any(is.na(n))) warning("'n' contains NA's")
>>>    if(length(n) > 1) n <- length(n)
>>>    if(n > 0)
>>>        (1:n - a)/(n + 1-2*a)
>>>    else numeric(0)
>>> }
>>
>> Why?  There are 4 points in your vector, and the result is perfectly
>> valid as documented, even if they were all NAs.
>
> When using ppoints in order to draw a quantile plot to have a first look
> at a distribution, I almost forgot (read: I did) to remove the NAs.

Wait a minute: you removed the NAs when you called sort. So

yco <- sort(Stamford)
xco <- ppoints(yco)

was probably what you intended.


> For example, Chambers, Cleveland et al. (1983), Graphical Methods
> for Data Analysis, p. 15 Fig. 2.4:
>
> "Stamford" <-
> c(66, 52, NA, NA, NA, NA, 49, 64, 68, 26, 86, 52, 43, 75, 87,
> 188, 118, 103, 82, 71, 103, 240, 31, 40, 47, 51, 31, 47, 14,
> NA, 71, 61, 47, NA, 196, 131, 173, 37, 47, 215, 230, NA, 69,
> 98, 125, 94, 72, 72, 125, 143, 192, NA, 122, 32, 114, 32, 23,
> 71, 38, 136, 169, 152, 201, 134, 206, 92, 101, 119, 124, 133,
> 83, NA, 60, 124, 142, 124, 64, 75, 103, NA, 46, 68, NA, 87, 27,
> NA, 73, 59, 119, 64, NA, 111, 80, 68, 24, 24, 82, 100, 55, 91,
> 87, 64, NA, NA, 170, NA, 86, 202, 71, 85, 122, 155, 80, 71, 28,
> 212, 80, 24, 80, 169, 174, 141, 202, 113, 38, 38, 28, 52, 14,
> 38, 94, 89, 99, 150, 146, 113, 38, 66, 38, 80, 80, 99, 71, 42,
> 52, 33, 38, 24, 61, 108, 38, 28, NA)
>
> xco <- ppoints(na.omit(Stamford))
> yco <- sort(Stamford)
> plot(xco, yco,
>     pch = 20,
>     xlab = "FRACTION OF DATA",
>     ylab = "QUANTILES OF OZONE DATA",
>     cex = 0.6)
>
>
>>> Another minor remark concerning ?ppoints. It says:
>>>
>>> n: either the number of points generate or a vector of
>>>          observations.     ^^^^^
>>
>> As you see, that does not line up, but the typo has been fixed.
>
> Thank you for your answer (and fix).
> Tobias
>
>> --
>> Brian D. Ripley,                  ripley@stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Ted.Harding at nessie.mcc.ac.uk  Mon Jan 24 19:45:15 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon Jan 24 20:06:59 2005
Subject: [Rd] R 'postscript' plot - not a valid postscript (PR#7559)
In-Reply-To: <Pine.LNX.4.21.0501241652380.23769-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <XFMail.050124184515.Ted.Harding@nessie.mcc.ac.uk>

On 24-Jan-05 Dan Bolser wrote:
> On 24 Jan 2005, Peter Dalgaard wrote:
> 
>>dan@bolser.co.uk writes:
>>> 
>>> Full_Name: Mr. Daniel Murray Bolser
>>> Version: R 2.0.0 (2004-10-04)
>>> OS: Linux beagle 2.4.20-31.9 #1 Tue Apr 13 17:38:16 EDT 2004 i686
>>> athlon i386 GNU/Linux
>>> Submission from: (NULL) (193.60.81.207)

Interestingly, using exactly the same commands with R-1.8.0
(on Linux) gives no problem. The PS in the file shows nothing
anomalous, and when displayed using 'gv' it shows the same
plot as produced by the 'plot' and 'abline' commands on their
own, with horizontal lines logarithmically positioned for the
values y=10, 20, 30, 40, 50, 60, 70, 80, 90, 100 -- i.e. it
seems that just as 'plot' ignores the "NaN" line generated by
'log10(0)' and plots the valid lines to the screen, so also
when writing to the postscript device it also ignores this line
and simply writes the valid stuff to the file.

So it would seem that plot() with postscript() has changed its
behaviour (not for the better in this case) in the passage from
1.8.0 to 2.0.0.

Best wishes,
Ted.

>>> Trying to execute the following code produces a 'not a valid
>>> postscript' error
>>> from various postscript readers (gv, ggv, ghostscript). A very
>>> similar code
>>> works fine.
>>> 
>>> <CODE>
>>> 
>>> postscript()
>>> 
>>> plot( 1:100, ylim=c(1,700), type='n', log='y')
>>> 
>>> abline(v=seq(0,100,10))
>>> abline(h=10)
>>> abline(h=seq(0,100, 10)) # Comment out this line and it works fine
>>> 
>>> dev.off()
>>> 
>>> </CODE>
>>> 
>>
>>Just abline(h=0) gives the same effect, with the following in the
>>postscript file
>>
>>77.04 nan m
>>716.61 nan l
>>
>>which of course comes from trying to calculate log10(0).
>>
>>
>>> Looking at this just now I see the problem, but if a ps file is
>>> written, it
>>> should be viewable, so I think this is still a bug.
>>
>>Yes. However, the workaround would be rather obvious...
> 
>:) 
> 
> Yup, the process of logging a bug lead me to the problem and the
> workaround was obvious. However, the hours of trying to debug were not
> so
> much fun. My script worked from within ess, but running in batch mode
> in order to prduce a ps failed. I didn't have a clue what was causing
> the
> problem, so I had to check the whole script.
> 
>>
>>
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding@nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861  [NB: New number!]
Date: 24-Jan-05                                       Time: 18:45:15
------------------------------ XFMail ------------------------------

From xt_wang at cse.concordia.ca  Tue Jan 25 00:15:41 2005
From: xt_wang at cse.concordia.ca (xt_wang@cse.concordia.ca)
Date: Tue Jan 25 00:15:46 2005
Subject: [Rd] about R CMD check 
Message-ID: <1106608541.41f5819dabd24@mail.encs.concordia.ca>


hello,

I create a package which includes C code and Lapack. But when I run " R CMD
check ". an error message, "/usr/bin/ld: cannot find -lfrtbegin " occurs. could
you tell me what is the problem?

the detailed message is as follows:
[credsim@confsys ~/src]$ R CMD check var
* checking for working latex ... OK
* using log directory '/home/credsim/src/var.Rcheck'
* checking for file 'var/DESCRIPTION' ... OK
* checking if this is a source package ... OK

* Installing *source* package 'WXT' ...
** libs
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp 
-fPIC  -O2 -g -march=i386 -mcpu=i686 -c 1221.c -o 1221.o
1221.c: In function `Matrix_A_12':
1221.c:773: warning: passing arg 3 of `dpotrf_' from incompatible pointer type
1221.c:774: warning: passing arg 4 of `dpotrs_' from incompatible pointer type
1221.c: In function `Matrix_A_1':
1221.c:1037: warning: passing arg 3 of `dpotrf_' from incompatible pointer type
1221.c:1038: warning: passing arg 4 of `dpotrs_' from incompatible pointer type
1221.c: In function `Matrix_A_2':
1221.c:1289: warning: passing arg 3 of `dpotrf_' from incompatible pointer type
1221.c:1290: warning: passing arg 4 of `dpotrs_' from incompatible pointer type
gcc -shared -L/usr/local/lib -o WXT.so 1221.o -L/usr/lib/R/bin -lRlapack 
-L/usr/local/lib -L/usr/lib/gcc-lib/i386-redhat-linux/3.2.2
-L/usr/lib/gcc-lib/i386-redhat-linux/3.2.2/../../.. -lfrtbegin -lg2c -lm
-lgcc_s
/usr/bin/ld: cannot find -lfrtbegin
collect2: ld returned 1 exit status
make: *** [WXT.so] Error 1
ERROR: compilation failed for package 'WXT'
** Removing '/home/credsim/src/var.Rcheck/WXT'
 ERROR
Installation failed.

From rvet at uwaterloo.ca  Tue Jan 25 06:43:07 2005
From: rvet at uwaterloo.ca (rvet@uwaterloo.ca)
Date: Tue Jan 25 06:43:12 2005
Subject: [Rd] Bug in Windows File Selector (PR#7561)
Message-ID: <20050125054307.41F82EAE3@slim.kubism.ku.dk>

Full_Name: Paul Vet
Version: 2.0.1
OS: Windows 2000
Submission from: (NULL) (65.95.10.51)


The file selector for saving plots always starts in the R program directory.  It
is standard for Windows programs to start the file selector in the most recently
saved-in directory.

Steps to reproduce:
1.  > plot (x)   # for some data x
2.  Right click new plot, choose "Save as postscript..."
3.  Choose a different directory (e.g. "My Documents\R\foo.ps")
4.  Again, right click the plot, selecting "Save as postscript..."
5.  The file chooser will open, with the R install directory as the starting
location

Expected Behaviour:
The chooser dialog should start in the most-recently used directory.

From ripley at stats.ox.ac.uk  Tue Jan 25 07:02:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Jan 25 07:03:01 2005
Subject: [Rd] Bug in Windows File Selector (PR#7561)
In-Reply-To: <20050125054307.41F82EAE3@slim.kubism.ku.dk>
References: <20050125054307.41F82EAE3@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0501250553280.21277@gannet.stats>

The documented behaviour is for it to always start in the R working 
directory. That it does.  To do what it is documented to do is not a bug.

On Tue, 25 Jan 2005 rvet@uwaterloo.ca wrote:

> Full_Name: Paul Vet
> Version: 2.0.1
> OS: Windows 2000
> Submission from: (NULL) (65.95.10.51)
>
>
> The file selector for saving plots always starts in the R program 
> directory.  It is standard for Windows programs to start the file 
> selector in the most recently saved-in directory.
>
> Steps to reproduce:
> 1.  > plot (x)   # for some data x
> 2.  Right click new plot, choose "Save as postscript..."
> 3.  Choose a different directory (e.g. "My Documents\R\foo.ps")
> 4.  Again, right click the plot, selecting "Save as postscript..."
> 5.  The file chooser will open, with the R install directory as the starting
> location

Not true: it does use the current working directory.

> Expected Behaviour:
> The chooser dialog should start in the most-recently used directory.

So, you did not bother to read the README:

   The `load' menu items (Source R code, Display file, Load Workspace)
   keep track of the directory that was last used, and start their dialog
   boxes from that directory the next time they are used.  That directory
   can be made the working directory by the File | Change dir menu item.
   All the `save' menu items start dialog boxes at the current working
   directory: this includes `Save Workspace' and the various ways to save
   graphics, as well as saving the workspace at the end of the session.

R users have found this more convenient.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rvet at uwaterloo.ca  Tue Jan 25 08:10:46 2005
From: rvet at uwaterloo.ca (Paul Vet)
Date: Tue Jan 25 08:10:32 2005
Subject: [Rd] Bug in Windows File Selector (PR#7561)
In-Reply-To: <Pine.LNX.4.61.0501250640090.26392@gannet.stats>
References: <20050125054307.41F82EAE3@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0501250553280.21277@gannet.stats>
	<41F5E990.6000205@uwaterloo.ca>
	<Pine.LNX.4.61.0501250640090.26392@gannet.stats>
Message-ID: <41F5F0F6.7060102@uwaterloo.ca>

Hi Professor,

Thanks for the clarifications.  I appreciate your patience.  That said,
if I could make a couple suggestions:

1.  The Help menu disappears when the Console isn't the focused window.
  As such, I didn't see the glaringly obvious "FAQ on R for Windows"
which would have answered my question right off the bat.  Perhaps having
the Help menu present for all sub-windows would help future newbies?

2.  I'm still hung up on the Save As.. issue.  After this I promise I'll
drop it, but it's quite the non-conventional way to act.  To quote the
Official Microsoft UI Guidelines
(http://msdn.microsoft.com/library/default.asp?url=/library/en-us/dnwue/html/ch09d.asp)

The Save in drop-down list box indicates the immediate container in the
directory path (or folder). The user can change the path by using this
control and the list of files box. If the file already exists, save it
to its original location. This means that <b>the current path for the
Save As dialog box should always be set to the path where the file was
last saved</b>. If the file has never been saved, save the file with
your application's default path setting (which should typically be in
the My Documents folder) or to the location defined by the user, either
by typing the path or by using the controls in the dialog box.
[Emphasis mine]


This just felt like a simple oversight to me, and I was suprised to hear
that it was considered a feature.  My apologies for being persistent,
I'll drop the issue now.  Just trying to give you the perspective that I
have as a Windows user new to your app.

Thanks again,
Paul Vet.

From ligges at statistik.uni-dortmund.de  Tue Jan 25 08:33:42 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue Jan 25 08:32:53 2005
Subject: [Rd] about R CMD check
In-Reply-To: <1106608541.41f5819dabd24@mail.encs.concordia.ca>
References: <1106608541.41f5819dabd24@mail.encs.concordia.ca>
Message-ID: <41F5F656.3030303@statistik.uni-dortmund.de>

xt_wang@cse.concordia.ca wrote:

> hello,
> 
> I create a package which includes C code and Lapack. But when I run " R CMD
> check ". an error message, "/usr/bin/ld: cannot find -lfrtbegin " occurs. could
> you tell me what is the problem?

OS? R version? Self compiled or rpm/apt get?
Why do you check "var" when the package claims to be called "WXT"?
Before any checking it is a good idea to try R CMD INSTALL ... (which 
does not work either, I guess).

Uwe Ligges




> the detailed message is as follows:
> [credsim@confsys ~/src]$ R CMD check var
> * checking for working latex ... OK
> * using log directory '/home/credsim/src/var.Rcheck'
> * checking for file 'var/DESCRIPTION' ... OK
> * checking if this is a source package ... OK
> 
> * Installing *source* package 'WXT' ...
> ** libs
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp 
> -fPIC  -O2 -g -march=i386 -mcpu=i686 -c 1221.c -o 1221.o
> 1221.c: In function `Matrix_A_12':
> 1221.c:773: warning: passing arg 3 of `dpotrf_' from incompatible pointer type
> 1221.c:774: warning: passing arg 4 of `dpotrs_' from incompatible pointer type
> 1221.c: In function `Matrix_A_1':
> 1221.c:1037: warning: passing arg 3 of `dpotrf_' from incompatible pointer type
> 1221.c:1038: warning: passing arg 4 of `dpotrs_' from incompatible pointer type
> 1221.c: In function `Matrix_A_2':
> 1221.c:1289: warning: passing arg 3 of `dpotrf_' from incompatible pointer type
> 1221.c:1290: warning: passing arg 4 of `dpotrs_' from incompatible pointer type
> gcc -shared -L/usr/local/lib -o WXT.so 1221.o -L/usr/lib/R/bin -lRlapack 
> -L/usr/local/lib -L/usr/lib/gcc-lib/i386-redhat-linux/3.2.2
> -L/usr/lib/gcc-lib/i386-redhat-linux/3.2.2/../../.. -lfrtbegin -lg2c -lm
> -lgcc_s
> /usr/bin/ld: cannot find -lfrtbegin
> collect2: ld returned 1 exit status
> make: *** [WXT.so] Error 1
> ERROR: compilation failed for package 'WXT'
> ** Removing '/home/credsim/src/var.Rcheck/WXT'
>  ERROR
> Installation failed.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From bates at stat.wisc.edu  Tue Jan 25 09:21:11 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue Jan 25 09:21:26 2005
Subject: [Rd] about R CMD check
In-Reply-To: <41F5F656.3030303@statistik.uni-dortmund.de>
References: <1106608541.41f5819dabd24@mail.encs.concordia.ca>
	<41F5F656.3030303@statistik.uni-dortmund.de>
Message-ID: <41F60177.3050507@stat.wisc.edu>

Uwe Ligges wrote:
> xt_wang@cse.concordia.ca wrote:
> 
>> hello,
>>
>> I create a package which includes C code and Lapack. But when I run " 
>> R CMD
>> check ". an error message, "/usr/bin/ld: cannot find -lfrtbegin " 
>> occurs. could
>> you tell me what is the problem?
> 
> 
> OS? R version? Self compiled or rpm/apt get?

Looks like RedHat Linux from the name of the libraries.

> Why do you check "var" when the package claims to be called "WXT"?
> Before any checking it is a good idea to try R CMD INSTALL ... (which 
> does not work either, I guess).

My guess is that an f2c or g2c development package needs to be 
installed.   On a Debian system the library comes from the libg2c0-dev 
package

$ dlocate libfrtbegin
libg2c0-dev: /usr/lib/libfrtbegin.a

By the way, I would pay attention to those warnings about incompatible 
pointer types in calls to dpotrf and dpotrs.  Remember that calls to 
Fortran routines from C must pass scalars by reference, not by value.

>> the detailed message is as follows:
>> [credsim@confsys ~/src]$ R CMD check var
>> * checking for working latex ... OK
>> * using log directory '/home/credsim/src/var.Rcheck'
>> * checking for file 'var/DESCRIPTION' ... OK
>> * checking if this is a source package ... OK
>>
>> * Installing *source* package 'WXT' ...
>> ** libs
>> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
>> -mieee-fp -fPIC  -O2 -g -march=i386 -mcpu=i686 -c 1221.c -o 1221.o
>> 1221.c: In function `Matrix_A_12':
>> 1221.c:773: warning: passing arg 3 of `dpotrf_' from incompatible 
>> pointer type
>> 1221.c:774: warning: passing arg 4 of `dpotrs_' from incompatible 
>> pointer type
>> 1221.c: In function `Matrix_A_1':
>> 1221.c:1037: warning: passing arg 3 of `dpotrf_' from incompatible 
>> pointer type
>> 1221.c:1038: warning: passing arg 4 of `dpotrs_' from incompatible 
>> pointer type
>> 1221.c: In function `Matrix_A_2':
>> 1221.c:1289: warning: passing arg 3 of `dpotrf_' from incompatible 
>> pointer type
>> 1221.c:1290: warning: passing arg 4 of `dpotrs_' from incompatible 
>> pointer type
>> gcc -shared -L/usr/local/lib -o WXT.so 1221.o -L/usr/lib/R/bin 
>> -lRlapack -L/usr/local/lib -L/usr/lib/gcc-lib/i386-redhat-linux/3.2.2
>> -L/usr/lib/gcc-lib/i386-redhat-linux/3.2.2/../../.. -lfrtbegin -lg2c -lm
>> -lgcc_s
>> /usr/bin/ld: cannot find -lfrtbegin
>> collect2: ld returned 1 exit status
>> make: *** [WXT.so] Error 1
>> ERROR: compilation failed for package 'WXT'
>> ** Removing '/home/credsim/src/var.Rcheck/WXT'
>>  ERROR
>> Installation failed.
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From p.dalgaard at biostat.ku.dk  Tue Jan 25 10:04:38 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Jan 25 10:08:02 2005
Subject: [Rd] about R CMD check
In-Reply-To: <41F60177.3050507@stat.wisc.edu>
References: <1106608541.41f5819dabd24@mail.encs.concordia.ca>
	<41F5F656.3030303@statistik.uni-dortmund.de>
	<41F60177.3050507@stat.wisc.edu>
Message-ID: <x2zmyxriah.fsf@biostat.ku.dk>

Douglas Bates <bates@stat.wisc.edu> writes:

> Uwe Ligges wrote:
> > xt_wang@cse.concordia.ca wrote:
> >
> >> hello,
> >>
> >> I create a package which includes C code and Lapack. But when I run
> >> " R CMD
> >> check ". an error message, "/usr/bin/ld: cannot find -lfrtbegin "
> >> occurs. could
> >> you tell me what is the problem?
> > OS? R version? Self compiled or rpm/apt get?
> 
> Looks like RedHat Linux from the name of the libraries.
> 
> > Why do you check "var" when the package claims to be called "WXT"?
> > Before any checking it is a good idea to try R CMD INSTALL ...
> > (which does not work either, I guess).
> 
> My guess is that an f2c or g2c development package needs to be
> installed.   On a Debian system the library comes from the libg2c0-dev
> package
> 
> $ dlocate libfrtbegin
> libg2c0-dev: /usr/lib/libfrtbegin.a

More likely it is Fortran itself that isn't there:

$ rpm -qf `locate  libfrtbegin`
gcc-g77-3.4.2-6.fc3


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Tue Jan 25 08:23:52 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Jan 25 10:08:50 2005
Subject: [Rd] about R CMD check 
In-Reply-To: <1106608541.41f5819dabd24@mail.encs.concordia.ca>
References: <1106608541.41f5819dabd24@mail.encs.concordia.ca>
Message-ID: <Pine.LNX.4.61.0501250716310.26800@gannet.stats>

On Mon, 24 Jan 2005 xt_wang@cse.concordia.ca wrote:

> I create a package which includes C code and Lapack. But when I run " R CMD
> check ". an error message, "/usr/bin/ld: cannot find -lfrtbegin " occurs. could
> you tell me what is the problem?

You are presumably (you have not told us) running Linux and do not have 
g77 installed (so I guess you installed R from an RPM or similar).  The 
best solution is to install it.  On my system

gannet% rpm -ql gcc-g77-3.4.2-6.fc3
/usr/bin/f77
/usr/bin/g77
/usr/lib/gcc
/usr/lib/gcc/i386-redhat-linux
/usr/lib/gcc/i386-redhat-linux/3.4.2
/usr/lib/gcc/i386-redhat-linux/3.4.2/include
/usr/lib/gcc/i386-redhat-linux/3.4.2/include/g2c.h
/usr/lib/gcc/i386-redhat-linux/3.4.2/libfrtbegin.a
/usr/lib/gcc/i386-redhat-linux/3.4.2/libg2c.a
/usr/lib/gcc/i386-redhat-linux/3.4.2/libg2c.so
...

The next best is to edit R_HOME/etc/Makeconf and remove -lftrbegin from 
FLIBS.

> the detailed message is as follows:
> [credsim@confsys ~/src]$ R CMD check var
> * checking for working latex ... OK
> * using log directory '/home/credsim/src/var.Rcheck'
> * checking for file 'var/DESCRIPTION' ... OK
> * checking if this is a source package ... OK
>
> * Installing *source* package 'WXT' ...
> ** libs
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp
> -fPIC  -O2 -g -march=i386 -mcpu=i686 -c 1221.c -o 1221.o
> 1221.c: In function `Matrix_A_12':
> 1221.c:773: warning: passing arg 3 of `dpotrf_' from incompatible pointer type
> 1221.c:774: warning: passing arg 4 of `dpotrs_' from incompatible pointer type
> 1221.c: In function `Matrix_A_1':
> 1221.c:1037: warning: passing arg 3 of `dpotrf_' from incompatible pointer type
> 1221.c:1038: warning: passing arg 4 of `dpotrs_' from incompatible pointer type
> 1221.c: In function `Matrix_A_2':
> 1221.c:1289: warning: passing arg 3 of `dpotrf_' from incompatible pointer type
> 1221.c:1290: warning: passing arg 4 of `dpotrs_' from incompatible pointer type
> gcc -shared -L/usr/local/lib -o WXT.so 1221.o -L/usr/lib/R/bin -lRlapack
> -L/usr/local/lib -L/usr/lib/gcc-lib/i386-redhat-linux/3.2.2
> -L/usr/lib/gcc-lib/i386-redhat-linux/3.2.2/../../.. -lfrtbegin -lg2c -lm
> -lgcc_s
> /usr/bin/ld: cannot find -lfrtbegin
> collect2: ld returned 1 exit status
> make: *** [WXT.so] Error 1
> ERROR: compilation failed for package 'WXT'
> ** Removing '/home/credsim/src/var.Rcheck/WXT'
> ERROR
> Installation failed.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Jan 25 11:27:15 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue Jan 25 11:27:20 2005
Subject: [Rd] typo in ?NotYetImplemented
Message-ID: <Pine.LNX.4.51.0501251126160.27846@artemis.imbe.med.uni-erlangen.de>


The `examples' section says

     plot.mlm         # to see how the "NotYetImplemented"
                      # reference is made automagically
                                                ^

Best,

Torsten

From Kurt.Hornik at wu-wien.ac.at  Tue Jan 25 11:39:33 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Tue Jan 25 11:37:40 2005
Subject: [Rd] typo in ?NotYetImplemented
In-Reply-To: <Pine.LNX.4.51.0501251126160.27846@artemis.imbe.med.uni-erlangen.de>
References: <Pine.LNX.4.51.0501251126160.27846@artemis.imbe.med.uni-erlangen.de>
Message-ID: <16886.8677.721209.622205@mithrandir.hornik.net>

>>>>> Torsten Hothorn writes:

> The `examples' section says

>      plot.mlm         # to see how the "NotYetImplemented"
>                       # reference is made automagically
>                                                 ^

Well, if I had written that, it would have been on purpose ...

-k

From ripley at stats.ox.ac.uk  Tue Jan 25 11:37:36 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Jan 25 11:37:41 2005
Subject: [Rd] typo in ?NotYetImplemented
In-Reply-To: <Pine.LNX.4.51.0501251126160.27846@artemis.imbe.med.uni-erlangen.de>
References: <Pine.LNX.4.51.0501251126160.27846@artemis.imbe.med.uni-erlangen.de>
Message-ID: <Pine.LNX.4.61.0501251035090.31588@gannet.stats>

I believe the author (not me) meant that: it seems a word in CS use.
See e.g. http://dictionary.reference.com/search?q=automagically

On Tue, 25 Jan 2005, Torsten Hothorn wrote:

>
> The `examples' section says
>
>     plot.mlm         # to see how the "NotYetImplemented"
>                      # reference is made automagically
>                                                ^

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Tue Jan 25 11:40:59 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Jan 25 11:44:34 2005
Subject: [Rd] typo in ?NotYetImplemented
In-Reply-To: <Pine.LNX.4.51.0501251126160.27846@artemis.imbe.med.uni-erlangen.de>
References: <Pine.LNX.4.51.0501251126160.27846@artemis.imbe.med.uni-erlangen.de>
Message-ID: <x2is5l7pvo.fsf@biostat.ku.dk>

Torsten Hothorn <Torsten.Hothorn@rzmail.uni-erlangen.de> writes:

> The `examples' section says
> 
>      plot.mlm         # to see how the "NotYetImplemented"
>                       # reference is made automagically
>                                                 ^

I think that's a joke, not a typo...

http://catb.org/~esr/jargon/html/A/automagically.html

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From B.Rowlingson at lancaster.ac.uk  Tue Jan 25 11:47:10 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue Jan 25 11:47:14 2005
Subject: [Rd] typo in ?NotYetImplemented
In-Reply-To: <Pine.LNX.4.51.0501251126160.27846@artemis.imbe.med.uni-erlangen.de>
References: <Pine.LNX.4.51.0501251126160.27846@artemis.imbe.med.uni-erlangen.de>
Message-ID: <41F623AE.1030906@lancaster.ac.uk>

Torsten Hothorn wrote:

>                       # reference is made automagically

  While not found in ordinary dictionaries, there is a reference in the 
Jargon File and the Free Online Dictionary of Computing:

"""
automagically /aw-toh-maj'i-klee/ adv. Automatically, but in a way
  that, for some reason (typically because it is too complicated, or too
  ugly, or perhaps even too trivial), the speaker doesn't feel like
  explaining to you. See magic. "The C-INTERCAL compiler generates C,
  then automagically invokes `cc(1)' to produce an executable."

  This term is quite old, going back at least to the mid-70s in jargon
  and probably much earlier. The word `automagic' occurred in advertising
(for a shirt-ironing gadget) as far back as the late 1940s.
"""

  although I've found nowadays people just using it automatically for 
'automatically', probably because it sounds cooler.

  At least R source code doesn't look like this:

/*
  * ht3 ph0ll0w1ng c0d3 pr1ntz v3ct0rz wh1ch hav3 3v3ry 3l3m3nt nam3d.
  * Pr1m1t1v3z ph0r 3ach typ3 uv v3ct0r R pr353nt3d ph1r5t, ph0ll0w3d by
  * ht3 ma1n (d15patch1ng) phunct10n. 1) Th353 pr1m1t1v3z R alm05t
  * 1d3nt1cal... == u53 PR1NT_N_V3CT0R macr0 2) z pr1ntz a _5pac3_ 1n ht3
  * ph1r5t c0lumn ph0r nam3d v3ct0r5; w3 d0nt.
  * R rox0rs!
  */

[with apologies to the authors of printvector.c]

Baz

From Poster at atlas.grandvision.com  Tue Jan 25 17:54:31 2005
From: Poster at atlas.grandvision.com (Poster@atlas.grandvision.com)
Date: Tue Jan 25 17:54:49 2005
Subject: [Rd] Spam mail warning notification! (Found_virus_WORM_NETSKY.D in
	file INBOUND, Found_virus_WORM_NETSKY.D in file OUTBOUND) (PR#7563)
Message-ID: <20050125165431.8F4F0EFC0@slim.kubism.ku.dk>

This is a multi-part message in MIME format.

------=_NextPart_000_1106676549_B78506032.R82506026
Content-Type: text/plain;
	charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

**************** eManager Notification *****************

The following mail was blocked since it contains sensitive content.

Source mailbox: 
Destination mailbox(es): r-bugs@r-project.org
Policy: Found_virus_WORM_NETSKY.D in file INBOUND,Found_virus_WORM_NETSKY.D in file OUTBOUND
Action: Delete

Recipient, Content filter has detected a sensitive e-mail.

******************* End of message *********************

------=_NextPart_000_1106676549_B78506032.R82506026
Content-Type: text/plain;
	charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

Message-Id: <200501251756.j0PHu9Q21902@atlas.grandvision.com>
From: Postmaster@grandvision.com
To: r-bugs@r-project.org
Subject: DELIVERY FAILURE: User ute (ute@grandoptical.com) not listed in Domino
 Directory
Date: Tue, 25 Jan 2005 17:40:56 +0100
MIME-Version: 1.0
X-Priority: 3 (Normal)
X-MSMail-Priority: Normal
X-MIMETrack: Itemize by SMTP Server on HUBX_NS01/FR/GrandVision(Release 6.5|September 26, 2003) at
 01/25/2005 05:40:44 PM,
	Serialize by Router on HUBX_NS01/FR/GrandVision(Release 6.5|September 26, 2003) at
 01/25/2005 05:53:43 PM,
	Serialize complete at 01/25/2005 05:53:43 PM
Content-Type: multipart/report; report-type=delivery-status; boundary="==IFJRGLKFGIR48393UHRUHIHD"

------=_NextPart_000_1106676549_B78506032.R82506026--

From apjaworski at mmm.com  Tue Jan 25 18:17:42 2005
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Tue Jan 25 18:17:54 2005
Subject: [Rd] R-devel daily snapshots
Message-ID: <OF2B1B026B.79AD90CB-ON86256F94.005E9700-86256F94.005F0143@mmm.com>





I just noticed that as of January 22, the daily snapshots of the R-devel
tree (in ftp://ftp.stat.math.ethz.ch/Software/R/) are only about 1Mb
(instead of about 10Mb).  When the January 25 file is downloaded and
uncompressed, it seems to be missing the src directory.

Cheers,

Andy

__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski@mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122

From luke at stat.uiowa.edu  Tue Jan 25 21:09:50 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue Jan 25 21:10:01 2005
Subject: [Rd] Very Long Expressions
In-Reply-To: <Pine.A41.4.61b.0501240835500.41726@homer03.u.washington.edu>
References: <67DCA285A2D7754280D3B8E88EB5480206741E31@MSGBOSCLB2WIN.DMN1.FMR.COM>
	<Pine.LNX.4.61.0501241554410.3211@gannet.stats>
	<Pine.A41.4.61b.0501240835500.41726@homer03.u.washington.edu>
Message-ID: <Pine.LNX.4.58.0501251407150.13053@nokomis.stat.uiowa.edu>

On Mon, 24 Jan 2005, Thomas Lumley wrote:

> On Mon, 24 Jan 2005, Prof Brian Ripley wrote:
> 
> > On Mon, 24 Jan 2005, McGehee, Robert wrote:
> >
> > [Instructions to the R developers deleted.]
> >
> >> Secondly, the ?options help (thanks for everyone who reminded me about
> >> this), says that expressions can have values between 25...100000.
> >> 
> >> However, if the original example is set past 4995 on my computers, I
> >> receive a stack overflow.
> >
> > More accurately, you caused a protection stack overflow.
> >
> 
> At one point we were concerned about overflowing the C stack if 
> options(expressions=) were set too high.  I think this was in the days 
> when MacOS had a very small stack, and that things are safer now.
> 
> 
>  	-thomas

I hadn't noticed that they finally kicked the default up to 8M--good.

We still need to be a bit careful since running out of C stack will
cause a protection violation and there is no portabmle way to catch
this.  But we can probably afford to loosen the defaults a bit.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From Robert.McGehee at geodecapital.com  Tue Jan 25 22:03:05 2005
From: Robert.McGehee at geodecapital.com (Robert.McGehee@geodecapital.com)
Date: Tue Jan 25 22:03:12 2005
Subject: [Rd] Regex Crashing R (perl = TRUE) (PR#7564)
Message-ID: <20050125210305.18BD11088E@slim.kubism.ku.dk>

R-developers,
I've encountered another perl library regex bug that causes a
segmentation faults on my Linux/Windows R session. I reduced the script
to the snippet below. (Apologies if this was fixed with bug 7479, but
this bug seems quite different).

string <- paste(rep("=", 10000), collapse = " ")
crash <- function(x) {
    for (i in 1:5) {
        x <- gsub("[^!]=", " == ", x, perl = TRUE)
    }
    x
}
x <- crash(string)
## Segmentation fault (core dumped)

The above should cause a crash immediately, but if you reduce the size
of the string, either you may get a delayed crash, such that R crashes
after you try to access the "string" object again, or you might get the
odd error:
Error in for (i in 1:5) { : bad for loop sequence

If you set perl = FALSE, then the script runs fine (albeit slowly).

As a side note, is there a good way of incorporating an uncompiled perl
script into an R package to be invoked from a system call? Putting it in
the /src directory seems like the obvious place, but I can't convince R
to copy over the script uncompiled upon installation.

Thanks,
Robert

> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    0.1
year     2004
month    11
day      15
language R


Robert McGehee
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee@geodecapital.com



This e-mail, and any attachments hereto, are intended for us...{{dropped}}

From Kurt.Hornik at wu-wien.ac.at  Tue Jan 25 21:57:32 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed Jan 26 09:21:36 2005
Subject: [Rd] R-devel daily snapshots
In-Reply-To: <OF2B1B026B.79AD90CB-ON86256F94.005E9700-86256F94.005F0143@mmm.com>
References: <OF2B1B026B.79AD90CB-ON86256F94.005E9700-86256F94.005F0143@mmm.com>
Message-ID: <16886.45756.311620.752881@mithrandir.hornik.net>

>>>>> apjaworski  writes:

> I just noticed that as of January 22, the daily snapshots of the R-devel
> tree (in ftp://ftp.stat.math.ethz.ch/Software/R/) are only about 1Mb
> (instead of about 10Mb).  When the January 25 file is downloaded and
> uncompressed, it seems to be missing the src directory.

We are working on this.  Building the daily snapshot for R-devel now
requires Makeinfo 4.7, and the system creating the tarball currently
only has 4.5 installed.

Thanks
-k

From maechler at stat.math.ethz.ch  Wed Jan 26 11:18:50 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Jan 26 11:18:52 2005
Subject: [Rd] R-devel daily snapshots
In-Reply-To: <16886.45756.311620.752881@mithrandir.hornik.net>
References: <OF2B1B026B.79AD90CB-ON86256F94.005E9700-86256F94.005F0143@mmm.com>
	<16886.45756.311620.752881@mithrandir.hornik.net>
Message-ID: <16887.28298.516624.832939@stat.math.ethz.ch>

>>>>> "Kurt" == Kurt Hornik <Kurt.Hornik@wu-wien.ac.at>
>>>>>     on Tue, 25 Jan 2005 21:57:32 +0100 writes:

>>>>> apjaworski  writes:
    >> I just noticed that as of January 22, the daily snapshots
    >> of the R-devel tree (in
    >> ftp://ftp.stat.math.ethz.ch/Software/R/) are only about
    >> 1Mb (instead of about 10Mb).  When the January 25 file is
    >> downloaded and uncompressed, it seems to be missing the
    >> src directory.

    Kurt> We are working on this.  Building the daily snapshot
    Kurt> for R-devel now requires Makeinfo 4.7, and the system
    Kurt> creating the tarball currently only has 4.5 installed.

There's now a new one in
  ftp://ftp.stat.math.ethz.ch/Software/R/

Martin

From sfalcon at fhcrc.org  Wed Jan 26 15:37:05 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed Jan 26 15:37:18 2005
Subject: [Rd] Regex Crashing R (perl = TRUE) (PR#7564)
In-Reply-To: <20050125210305.18BD11088E@slim.kubism.ku.dk>
References: <20050125210305.18BD11088E@slim.kubism.ku.dk>
Message-ID: <BFBC0B16-6FA7-11D9-9992-000D933A3A9E@fhcrc.org>

A side response...

On Jan 25, 2005, at 1:03 PM, Robert.McGehee@geodecapital.com wrote:

> As a side note, is there a good way of incorporating an uncompiled perl
> script into an R package to be invoked from a system call? Putting it 
> in
> the /src directory seems like the obvious place, but I can't convince R
> to copy over the script uncompiled upon installation.

That's what the inst/ directory of a package is for, I believe.  Look 
for details in the Writing R Extensions manual.  You might also want to 
look at system.file() which can help you locate files in an installed 
package.

+ seth

From ripley at stats.ox.ac.uk  Wed Jan 26 16:23:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jan 26 16:23:55 2005
Subject: Adding Perl scripts to a package ([Rd] Regex Crashing R (perl
	= TRUE))
In-Reply-To: <BFBC0B16-6FA7-11D9-9992-000D933A3A9E@fhcrc.org>
References: <20050125210305.18BD11088E@slim.kubism.ku.dk>
	<BFBC0B16-6FA7-11D9-9992-000D933A3A9E@fhcrc.org>
Message-ID: <Pine.LNX.4.61.0501261521120.4036@gannet.stats>

What has this to do with your subject?

I think this is rather what the exec directory is for, depending exactly 
what `an uncompiled perl script' really is.

On Wed, 26 Jan 2005, Seth Falcon wrote:

> A side response...
>
> On Jan 25, 2005, at 1:03 PM, Robert.McGehee@geodecapital.com wrote:
>
>> As a side note, is there a good way of incorporating an uncompiled perl
>> script into an R package to be invoked from a system call? Putting it in
>> the /src directory seems like the obvious place, but I can't convince R
>> to copy over the script uncompiled upon installation.
>
> That's what the inst/ directory of a package is for, I believe.  Look for 
> details in the Writing R Extensions manual.  You might also want to look at 
> system.file() which can help you locate files in an installed package.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From plummer at iarc.fr  Wed Jan 26 16:40:43 2005
From: plummer at iarc.fr (Martyn Plummer)
Date: Wed Jan 26 16:43:51 2005
Subject: [Rd] tapply with weighted.mean
Message-ID: <1106754043.3421.106.camel@seurat>

We were caught out recently attempting to use tapply to get a table of
weighted means.  This gives the wrong answer (or, more correctly, not
the answer we were expecting), as the following example shows:

R> x <- 1:10 #some data
R> w <- c(1:5,5:1) #weights
R> id <- rep(1:2,rep(5,2)) #id values
R> weighted.mean(x[id==1],w[id==1]) #Weighted mean of x in group 1
[1] 3.666667
R> weighted.mean(x[id==2],w[id==2]) #Weighted mean of x in group 2
[1] 7.333333
R> tapply(x,INDEX=id,FUN=weighted.mean,w=w) #Wrong!
1 2
3 8

The reason for this is that tapply splits it's first argument by the
INDEX variable, but does not split any of the arguments supplied via ...
So the result is

c(weighted.mean(x[id==1],w), weighted.mean(x[id==2],w))

R silently replicates the shorter variable to match the length of the
longer one.

I draw two conclusions from this:

1) weighted.mean(x,w) should include a length check for w.  The
documentation says it should be the same length as x, so this should be
enforced.

2) More importantly, the help page for tapply should explicitly warn the
user that optional arguments supplied to 'FUN' are not split by 'INDEX'.
I really only understood the behaviour of tapply after inspecting the
code. Then it became obvious why this could never work.

I hope I am not being too obtuse.  Any objections before I make these
changes?

Martyn

From wsetzer at mindspring.com  Wed Jan 26 17:40:46 2005
From: wsetzer at mindspring.com (wsetzer@mindspring.com)
Date: Wed Jan 26 17:40:50 2005
Subject: [Rd] problems building R-patched
Message-ID: <29012147.1106757646966.JavaMail.root@wamui10.slb.atl.earthlink.net>

When I try to install R-patched of January 26 on my linux (fedora core 1, with openmosix kernel) box, make fails in the first recommended package with the message 

  tkStartGUI                        text    html    latex
  tkpager                           text    html    latex
make[2]: Leaving directory `/home/setzer/newstuff/R-patched/src/library'
make[2]: Entering directory `/home/setzer/newstuff/R-patched/src/library'
building/updating package indices ...
make[2]: Leaving directory `/home/setzer/newstuff/R-patched/src/library'
make[1]: Leaving directory `/home/setzer/newstuff/R-patched/src/library'
make[1]: Entering directory `/home/setzer/newstuff/R-patched/src/library/Recommended'
make[2]: Entering directory `/home/setzer/newstuff/R-patched/src/library/Recommended'
make[2]: *** No rule to make target `VR.ts', needed by `stamp-recommended'.  Stop.

R-patched of January 25 fails the same way, but the January 21 version compiles successfully. 

Has something gone awry in the process of rolling patches, or do I need to look into problems with my system?  I notice that the src/library/Recommended has symbolic links in the January 21 version, but not in the January 26 version.

Woody Setzer

From ripley at stats.ox.ac.uk  Wed Jan 26 18:18:35 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Jan 26 18:18:40 2005
Subject: [Rd] problems building R-patched
In-Reply-To: <29012147.1106757646966.JavaMail.root@wamui10.slb.atl.earthlink.net>
References: <29012147.1106757646966.JavaMail.root@wamui10.slb.atl.earthlink.net>
Message-ID: <Pine.LNX.4.61.0501261715540.15679@gannet.stats>

On Wed, 26 Jan 2005 wsetzer@mindspring.com wrote:

> When I try to install R-patched of January 26 on my linux (fedora core 1, with openmosix kernel) box, make fails in the first recommended package with the message
>
>  tkStartGUI                        text    html    latex
>  tkpager                           text    html    latex
> make[2]: Leaving directory `/home/setzer/newstuff/R-patched/src/library'
> make[2]: Entering directory `/home/setzer/newstuff/R-patched/src/library'
> building/updating package indices ...
> make[2]: Leaving directory `/home/setzer/newstuff/R-patched/src/library'
> make[1]: Leaving directory `/home/setzer/newstuff/R-patched/src/library'
> make[1]: Entering directory `/home/setzer/newstuff/R-patched/src/library/Recommended'
> make[2]: Entering directory `/home/setzer/newstuff/R-patched/src/library/Recommended'
> make[2]: *** No rule to make target `VR.ts', needed by `stamp-recommended'.  Stop.
>
> R-patched of January 25 fails the same way, but the January 21 version compiles successfully.
>
> Has something gone awry in the process of rolling patches, or do I need 
> to look into problems with my system?  I notice that the 
> src/library/Recommended has symbolic links in the January 21 version, 
> but not in the January 26 version.

Run tools/link-recommended to recreate these links.

Without knowing whether you got `R-patched of January 26' by tarball or 
SVN (you didn't specify) it is hard to be more specific as to what is 
wrong.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From bates at stat.wisc.edu  Wed Jan 26 18:44:20 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed Jan 26 18:44:26 2005
Subject: [Rd] problems building R-patched
In-Reply-To: <29012147.1106757646966.JavaMail.root@wamui10.slb.atl.earthlink.net>
References: <29012147.1106757646966.JavaMail.root@wamui10.slb.atl.earthlink.net>
Message-ID: <41F7D6F4.7080502@stat.wisc.edu>

wsetzer@mindspring.com wrote:
> When I try to install R-patched of January 26 on my linux (fedora core 1, with openmosix kernel) box, make fails in the first recommended package with the message 
> 
>   tkStartGUI                        text    html    latex
>   tkpager                           text    html    latex
> make[2]: Leaving directory `/home/setzer/newstuff/R-patched/src/library'
> make[2]: Entering directory `/home/setzer/newstuff/R-patched/src/library'
> building/updating package indices ...
> make[2]: Leaving directory `/home/setzer/newstuff/R-patched/src/library'
> make[1]: Leaving directory `/home/setzer/newstuff/R-patched/src/library'
> make[1]: Entering directory `/home/setzer/newstuff/R-patched/src/library/Recommended'
> make[2]: Entering directory `/home/setzer/newstuff/R-patched/src/library/Recommended'
> make[2]: *** No rule to make target `VR.ts', needed by `stamp-recommended'.  Stop.
> 
> R-patched of January 25 fails the same way, but the January 21 version compiles successfully. 
> 
> Has something gone awry in the process of rolling patches, or do I need to look into problems with my system?  I notice that the src/library/Recommended has symbolic links in the January 21 version, but not in the January 26 version.
> 
> Woody Setzer

A workaround may be as simple as

cd /home/setzer/newstuff/R-patched
./tools/rsync-recommended

assuming that you have rsync installed.

From ggrothendieck at myway.com  Wed Jan 26 19:26:27 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed Jan 26 19:26:47 2005
Subject: [Rd] Vignette without latex/sweave
Message-ID: <loom.20050126T192041-828@post.gmane.org>


Is it possible to create a package vignette without latex/sweave?  I gather
that the %\VignetteIndexEntry and other \%Vignette... lines in the .Rnw 
file provide the various vignette metadata but was just wondering 
if latex/sweave are really hardwired into this or if its possible to 
produce a .pdf using other software and have it included as a vignette.  
If so, how does one specify the metadata?

I don't actually have a need for this but was just wondering.

From webmaster at fusionphp.net  Thu Jan 27 00:11:07 2005
From: webmaster at fusionphp.net (Webmaster Pat)
Date: Thu Jan 27 00:11:11 2005
Subject: [Rd] FusionPHP.net News PHP Script
Message-ID: <E1CtwJX-0008L5-Cg@libra.nnshosting.com>


FusionPHP.NET

Visit us today, fullfilling your PHP needs!!!

http://www.fusionphp.net/

We have the BEST free php news script in the world.

Please spread the word about our website and our scripts!!! Forward this email to 250 people and we'll pay you $5.00 US dollars via paypal.

Thank you,
Patatten Boerken
http://fusionphp.net/
patattenboerken@gmail.com
webmaster@fusionphp.net

From pburns at pburns.seanet.com  Thu Jan 27 16:25:30 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu Jan 27 16:26:32 2005
Subject: [Rd] the incredible lightness of crossprod
Message-ID: <41F907EA.90406@pburns.seanet.com>

The following is at least as much out of intellectual curiosity
as for practical reasons. 

On reviewing some code written by novices to R, I came
across:

crossprod(x, y)[1,1]

I  thought, "That isn't a very S way of saying that,  I wonder
what the penalty is for using 'crossprod'."  To my surprise the
penalty was substantially negative.  Handily the client had S-PLUS
as well -- there the sign of the penalty was as I had expected, but
the order of magnitude was off.

Here are the timings of 1 million computations on vectors of
length 1000.  This is under Windows, R version 1.9.1 and S-PLUS
6.2 (on the same machine).

Command                               R                        S-PLUS
sum(x * y)                              28.61                        97.6
crossprod(x, y)[1,1]                 6.77                     2256.2


Another example is when computing the sums of the columns of a
matrix.  For example:

set.seed(1)
jjm <- matrix(rnorm(600), 5)

Timings for this under Windows 2000 with R version 2.0.1 (on an
old chip running at about 0.7Ghz) for 100,000 computations are:

apply(jjm, 2, sum)               536.59
colSums(jjm)                         18.26
rep(1,5) %*% jjm                 15.41
crossprod(rep(1,5), jjm)        13.16

(These timings seem to be stable across R versions and on at least
one Linux platform.)

Andy Liaw showed another example of 'crossprod' being fast a couple
days ago on R-help.

Questions for those with a more global picture of the code:

*  Is the speed advantage of 'crossprod' inherent, or is it because
more care has been taken with its implementation than the other
functions?

*  Is 'crossprod' faster than 'sum(x * y)' because 'crossprod' is
going to BLAS while 'sum' can't?

*  Would it make sense to (essentially) use 'crossprod' in
'colSums' and its friends at least for the special case of matrices?

Patrick Burns

Burns Statistics
patrick@burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

From bates at stat.wisc.edu  Thu Jan 27 19:51:26 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu Jan 27 19:54:42 2005
Subject: [Rd] the incredible lightness of crossprod
In-Reply-To: <41F907EA.90406@pburns.seanet.com>
References: <41F907EA.90406@pburns.seanet.com>
Message-ID: <41F9382E.2060200@stat.wisc.edu>

Patrick Burns wrote:
> The following is at least as much out of intellectual curiosity
> as for practical reasons.
> On reviewing some code written by novices to R, I came
> across:
> 
> crossprod(x, y)[1,1]
> 
> I  thought, "That isn't a very S way of saying that,  I wonder
> what the penalty is for using 'crossprod'."  To my surprise the
> penalty was substantially negative.  Handily the client had S-PLUS
> as well -- there the sign of the penalty was as I had expected, but
> the order of magnitude was off.
> 
> Here are the timings of 1 million computations on vectors of
> length 1000.  This is under Windows, R version 1.9.1 and S-PLUS
> 6.2 (on the same machine).
> 
> Command                               R                        S-PLUS
> sum(x * y)                              28.61                        97.6
> crossprod(x, y)[1,1]                 6.77                     2256.2
> 
> 
> Another example is when computing the sums of the columns of a
> matrix.  For example:
> 
> set.seed(1)
> jjm <- matrix(rnorm(600), 5)
> 
> Timings for this under Windows 2000 with R version 2.0.1 (on an
> old chip running at about 0.7Ghz) for 100,000 computations are:
> 
> apply(jjm, 2, sum)               536.59
> colSums(jjm)                         18.26
> rep(1,5) %*% jjm                 15.41
> crossprod(rep(1,5), jjm)        13.16
> 
> (These timings seem to be stable across R versions and on at least
> one Linux platform.)
> 
> Andy Liaw showed another example of 'crossprod' being fast a couple
> days ago on R-help.
> 
> Questions for those with a more global picture of the code:
> 
> *  Is the speed advantage of 'crossprod' inherent, or is it because
> more care has been taken with its implementation than the other
> functions?
> 
> *  Is 'crossprod' faster than 'sum(x * y)' because 'crossprod' is
> going to BLAS while 'sum' can't?

For a numeric matrix crossprod ends up calling level 3 BLAS; either 
dsyrk for the single argument case or dgemm for the two argument case. 
Especially in accelerated versions of the BLAS like Atlas or Goto's 
BLAS, those routines are hideously efficient and that's where you are 
seeing the big gain in speed.

By the way, you didn't mention if you had an accelerated BLAS installed 
with R.  Do you?

From andy_liaw at merck.com  Thu Jan 27 20:33:36 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Jan 27 20:34:27 2005
Subject: [Rd] the incredible lightness of crossprod
Message-ID: <3A822319EB35174CA3714066D590DCD50994E5D1@usrymx25.merck.com>

> From: Douglas Bates
> 
> Patrick Burns wrote:
> > The following is at least as much out of intellectual curiosity
> > as for practical reasons.
> > On reviewing some code written by novices to R, I came
> > across:
> > 
> > crossprod(x, y)[1,1]
> > 
> > I  thought, "That isn't a very S way of saying that,  I wonder
> > what the penalty is for using 'crossprod'."  To my surprise the
> > penalty was substantially negative.  Handily the client had S-PLUS
> > as well -- there the sign of the penalty was as I had expected, but
> > the order of magnitude was off.
> > 
> > Here are the timings of 1 million computations on vectors of
> > length 1000.  This is under Windows, R version 1.9.1 and S-PLUS
> > 6.2 (on the same machine).
> > 
> > Command                               R                     
>    S-PLUS
> > sum(x * y)                              28.61               
>          97.6
> > crossprod(x, y)[1,1]                 6.77                     2256.2
> > 
> > 
> > Another example is when computing the sums of the columns of a
> > matrix.  For example:
> > 
> > set.seed(1)
> > jjm <- matrix(rnorm(600), 5)
> > 
> > Timings for this under Windows 2000 with R version 2.0.1 (on an
> > old chip running at about 0.7Ghz) for 100,000 computations are:
> > 
> > apply(jjm, 2, sum)               536.59
> > colSums(jjm)                         18.26
> > rep(1,5) %*% jjm                 15.41
> > crossprod(rep(1,5), jjm)        13.16
> > 
> > (These timings seem to be stable across R versions and on at least
> > one Linux platform.)
> > 
> > Andy Liaw showed another example of 'crossprod' being fast a couple
> > days ago on R-help.
> > 
> > Questions for those with a more global picture of the code:
> > 
> > *  Is the speed advantage of 'crossprod' inherent, or is it because
> > more care has been taken with its implementation than the other
> > functions?
> > 
> > *  Is 'crossprod' faster than 'sum(x * y)' because 'crossprod' is
> > going to BLAS while 'sum' can't?
> 
> For a numeric matrix crossprod ends up calling level 3 BLAS; either 
> dsyrk for the single argument case or dgemm for the two 
> argument case. 
> Especially in accelerated versions of the BLAS like Atlas or Goto's 
> BLAS, those routines are hideously efficient and that's where you are 
> seeing the big gain in speed.
> 
> By the way, you didn't mention if you had an accelerated BLAS 
> installed 
> with R.  Do you?

For the case of crossprod(x, w) for computing weighted mean of x (the
posting that Pat referred to), I tried the ATLAS-linked Rblas.dll on CRAN,
and it's actually slower than the stock Rblas.dll.  I believe Duncan M. had
observed similar things for small-ish problems.  (I used a Pentium M laptop,
and tried both the P3 and P4 versions.)

So, I think my main point is that even with non-optimized BLAS crossprod can
be way faster.

Andy
 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>

From pgilbert at bank-banque-canada.ca  Thu Jan 27 20:53:17 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu Jan 27 20:55:16 2005
Subject: [Rd] the incredible lightness of crossprod
In-Reply-To: <41F907EA.90406@pburns.seanet.com>
References: <41F907EA.90406@pburns.seanet.com>
Message-ID: <41F946AD.2020500@bank-banque-canada.ca>

A few weeks ago I noticed

 >  z <- matrix(rnorm(20000),10000,2)

 > system.time(for (i in 1:1000) apply(z,2,sum))
[1] 13.44  0.48 14.08  0.00  0.00

 > system.time(for (i in 1:1000) rep(1,10000) %*% z)
[1] 6.46 0.11 6.84 0.00 0.00

which seemed  completely contrary to all my childhood teachings. Now

 > system.time(for (i in 1:1000) crossprod(rep(1,10000), z))
[1] 1.90 0.12 2.24 0.00 0.00

makes sense because it is suppose to be faster than %*% , but why is 
apply so slow?
(And should I go back and change apply in my code everywhere or is this 
likely to reverse again?)

Paul Gilbert
 

Patrick Burns wrote:

> The following is at least as much out of intellectual curiosity
> as for practical reasons.
> On reviewing some code written by novices to R, I came
> across:
>
> crossprod(x, y)[1,1]
>
> I  thought, "That isn't a very S way of saying that,  I wonder
> what the penalty is for using 'crossprod'."  To my surprise the
> penalty was substantially negative.  Handily the client had S-PLUS
> as well -- there the sign of the penalty was as I had expected, but
> the order of magnitude was off.
>
> Here are the timings of 1 million computations on vectors of
> length 1000.  This is under Windows, R version 1.9.1 and S-PLUS
> 6.2 (on the same machine).
>
> Command                               R                        S-PLUS
> sum(x * y)                              28.61                        97.6
> crossprod(x, y)[1,1]                 6.77                     2256.2
>
>
> Another example is when computing the sums of the columns of a
> matrix.  For example:
>
> set.seed(1)
> jjm <- matrix(rnorm(600), 5)
>
> Timings for this under Windows 2000 with R version 2.0.1 (on an
> old chip running at about 0.7Ghz) for 100,000 computations are:
>
> apply(jjm, 2, sum)               536.59
> colSums(jjm)                         18.26
> rep(1,5) %*% jjm                 15.41
> crossprod(rep(1,5), jjm)        13.16
>
> (These timings seem to be stable across R versions and on at least
> one Linux platform.)
>
> Andy Liaw showed another example of 'crossprod' being fast a couple
> days ago on R-help.
>
> Questions for those with a more global picture of the code:
>
> *  Is the speed advantage of 'crossprod' inherent, or is it because
> more care has been taken with its implementation than the other
> functions?
>
> *  Is 'crossprod' faster than 'sum(x * y)' because 'crossprod' is
> going to BLAS while 'sum' can't?
>
> *  Would it make sense to (essentially) use 'crossprod' in
> 'colSums' and its friends at least for the special case of matrices?
>
> Patrick Burns
>
> Burns Statistics
> patrick@burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From ripley at stats.ox.ac.uk  Thu Jan 27 21:23:39 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jan 27 21:23:47 2005
Subject: [Rd] the incredible lightness of crossprod
In-Reply-To: <41F946AD.2020500@bank-banque-canada.ca>
References: <41F907EA.90406@pburns.seanet.com>
	<41F946AD.2020500@bank-banque-canada.ca>
Message-ID: <Pine.LNX.4.61.0501272013500.29855@gannet.stats>

On Thu, 27 Jan 2005, Paul Gilbert wrote:

> A few weeks ago I noticed
>
>>  z <- matrix(rnorm(20000),10000,2)
>
>> system.time(for (i in 1:1000) apply(z,2,sum))
> [1] 13.44  0.48 14.08  0.00  0.00
>
>> system.time(for (i in 1:1000) rep(1,10000) %*% z)
> [1] 6.46 0.11 6.84 0.00 0.00

So both run in a few milliseconds for rather large problems.

> which seemed  completely contrary to all my childhood teachings. Now
>
>> system.time(for (i in 1:1000) crossprod(rep(1,10000), z))
> [1] 1.90 0.12 2.24 0.00 0.00
>
> makes sense because it is suppose to be faster than %*% , but why is apply so 
> slow?

`so slow' sic: what are you going to do in the 7ms you saved?

> (And should I go back and change apply in my code everywhere or is this 
> likely to reverse again?)

It's not likely.  apply is an R-level loop, and  %*% is a C-level one.
However,  %*% is not supposed to be much slower than crossprod, and the 
devil is in the details of how the BLAS is implemented: the code is very 
similar.

That %*% was faster than apply has been true in all my (17 years) of S/R 
experience.  Your childhood may predate S3, of course.

I still think one should use row/colSums for clarity with acceptable
efficiency.  It must be very unusual for these operations to be a dominant 
part of a calculation, so let's not lose proportion here.


> Paul Gilbert
>
>
> Patrick Burns wrote:
>
>> The following is at least as much out of intellectual curiosity
>> as for practical reasons.
>> On reviewing some code written by novices to R, I came
>> across:
>> 
>> crossprod(x, y)[1,1]
>> 
>> I  thought, "That isn't a very S way of saying that,  I wonder
>> what the penalty is for using 'crossprod'."  To my surprise the
>> penalty was substantially negative.  Handily the client had S-PLUS
>> as well -- there the sign of the penalty was as I had expected, but
>> the order of magnitude was off.
>> 
>> Here are the timings of 1 million computations on vectors of
>> length 1000.  This is under Windows, R version 1.9.1 and S-PLUS
>> 6.2 (on the same machine).
>> 
>> Command                               R                        S-PLUS
>> sum(x * y)                              28.61                        97.6
>> crossprod(x, y)[1,1]                 6.77                     2256.2
>> 
>> 
>> Another example is when computing the sums of the columns of a
>> matrix.  For example:
>> 
>> set.seed(1)
>> jjm <- matrix(rnorm(600), 5)
>> 
>> Timings for this under Windows 2000 with R version 2.0.1 (on an
>> old chip running at about 0.7Ghz) for 100,000 computations are:
>> 
>> apply(jjm, 2, sum)               536.59
>> colSums(jjm)                         18.26
>> rep(1,5) %*% jjm                 15.41
>> crossprod(rep(1,5), jjm)        13.16
>> 
>> (These timings seem to be stable across R versions and on at least
>> one Linux platform.)
>> 
>> Andy Liaw showed another example of 'crossprod' being fast a couple
>> days ago on R-help.
>> 
>> Questions for those with a more global picture of the code:
>> 
>> *  Is the speed advantage of 'crossprod' inherent, or is it because
>> more care has been taken with its implementation than the other
>> functions?
>> 
>> *  Is 'crossprod' faster than 'sum(x * y)' because 'crossprod' is
>> going to BLAS while 'sum' can't?
>> 
>> *  Would it make sense to (essentially) use 'crossprod' in
>> 'colSums' and its friends at least for the special case of matrices?
>> 
>> Patrick Burns
>> 
>> Burns Statistics
>> patrick@burns-stat.com
>> +44 (0)20 8525 0696
>> http://www.burns-stat.com
>> (home of S Poetry and "A Guide for the Unwilling S User")
>> 
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From bates at stat.wisc.edu  Thu Jan 27 21:33:20 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu Jan 27 21:33:26 2005
Subject: [Rd] the incredible lightness of crossprod
In-Reply-To: <41F946AD.2020500@bank-banque-canada.ca>
References: <41F907EA.90406@pburns.seanet.com>
	<41F946AD.2020500@bank-banque-canada.ca>
Message-ID: <41F95010.3050006@stat.wisc.edu>

Paul Gilbert wrote:
> A few weeks ago I noticed
> 
>  >  z <- matrix(rnorm(20000),10000,2)
> 
>  > system.time(for (i in 1:1000) apply(z,2,sum))
> [1] 13.44  0.48 14.08  0.00  0.00
> 
>  > system.time(for (i in 1:1000) rep(1,10000) %*% z)
> [1] 6.46 0.11 6.84 0.00 0.00
> 
> which seemed  completely contrary to all my childhood teachings. Now

Must have had an interesting childhood if you spent it learning about 
the speeds of various matrix multiplication techniques.
	
>  > system.time(for (i in 1:1000) crossprod(rep(1,10000), z))
> [1] 1.90 0.12 2.24 0.00 0.00

and there is a good chance that a significant portion of that time is 
taken up by repeating the rep(1, 10000) function call 1000 times.

> makes sense because it is suppose to be faster than %*% , but why is 
> apply so slow?

I believe that this is Bert Gunter's cue to comment on the internal (or 
infernal) nature of the apply functions.

> (And should I go back and change apply in my code everywhere or is this 
> likely to reverse again?)
> 
> Paul Gilbert

From pgilbert at bank-banque-canada.ca  Thu Jan 27 22:55:24 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu Jan 27 22:57:21 2005
Subject: [Rd] the incredible lightness of crossprod
In-Reply-To: <Pine.LNX.4.61.0501272013500.29855@gannet.stats>
References: <41F907EA.90406@pburns.seanet.com>
	<41F946AD.2020500@bank-banque-canada.ca>
	<Pine.LNX.4.61.0501272013500.29855@gannet.stats>
Message-ID: <41F9634C.50801@bank-banque-canada.ca>



Prof Brian Ripley wrote:

> On Thu, 27 Jan 2005, Paul Gilbert wrote:
>
>> A few weeks ago I noticed
>>
>>>  z <- matrix(rnorm(20000),10000,2)
>>
>>
>>> system.time(for (i in 1:1000) apply(z,2,sum))
>>
>> [1] 13.44  0.48 14.08  0.00  0.00
>>
>>> system.time(for (i in 1:1000) rep(1,10000) %*% z)
>>
>> [1] 6.46 0.11 6.84 0.00 0.00
>
>
> So both run in a few milliseconds for rather large problems.
>
>> which seemed  completely contrary to all my childhood teachings. Now
>>
>>> system.time(for (i in 1:1000) crossprod(rep(1,10000), z))
>>
>> [1] 1.90 0.12 2.24 0.00 0.00
>>
>> makes sense because it is suppose to be faster than %*% , but why is 
>> apply so slow?
>
>
> `so slow' sic: what are you going to do in the 7ms you saved? 

Yes, I think I've spent more  time checking this than I will ever  save.

>> (And should I go back and change apply in my code everywhere or is 
>> this likely to reverse again?)
>
>
> It's not likely.  apply is an R-level loop, and  %*% is a C-level one.
> However,  %*% is not supposed to be much slower than crossprod, and 
> the devil is in the details of how the BLAS is implemented: the code 
> is very similar.
>
> That %*% was faster than apply has been true in all my (17 years) of 
> S/R experience.  Your childhood may predate S3, of course.

I didn't say the teachings were correct. I clearly should have 
questioned some things sooner.

> I still think one should use row/colSums for clarity with acceptable
> efficiency.  It must be very unusual for these operations to be a 
> dominant part of a calculation, so let's not lose proportion here. 

Agreed. I think I like the clarity reason best.

Thanks for the explanation.

Paul

From pburns at pburns.seanet.com  Thu Jan 27 23:15:35 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu Jan 27 23:16:33 2005
Subject: [Rd] the incredible lightness of crossprod
In-Reply-To: <41F9382E.2060200@stat.wisc.edu>
References: <41F907EA.90406@pburns.seanet.com> <41F9382E.2060200@stat.wisc.edu>
Message-ID: <41F96807.1000405@pburns.seanet.com>

On my machine the versions are all precompiled R, and I would
be very surprised if the same were not the case on the client's
machine.  That is, no specially compiled BLAS.

Douglas Bates wrote:

> Patrick Burns wrote:
>
>> The following is at least as much out of intellectual curiosity
>> as for practical reasons.
>> On reviewing some code written by novices to R, I came
>> across:
>>
>> crossprod(x, y)[1,1]
>>
>> I  thought, "That isn't a very S way of saying that,  I wonder
>> what the penalty is for using 'crossprod'."  To my surprise the
>> penalty was substantially negative.  Handily the client had S-PLUS
>> as well -- there the sign of the penalty was as I had expected, but
>> the order of magnitude was off.
>>
>> Here are the timings of 1 million computations on vectors of
>> length 1000.  This is under Windows, R version 1.9.1 and S-PLUS
>> 6.2 (on the same machine).
>>
>> Command                               R                        S-PLUS
>> sum(x * y)                              28.61                        
>> 97.6
>> crossprod(x, y)[1,1]                 6.77                     2256.2
>>
>>
>> Another example is when computing the sums of the columns of a
>> matrix.  For example:
>>
>> set.seed(1)
>> jjm <- matrix(rnorm(600), 5)
>>
>> Timings for this under Windows 2000 with R version 2.0.1 (on an
>> old chip running at about 0.7Ghz) for 100,000 computations are:
>>
>> apply(jjm, 2, sum)               536.59
>> colSums(jjm)                         18.26
>> rep(1,5) %*% jjm                 15.41
>> crossprod(rep(1,5), jjm)        13.16
>>
>> (These timings seem to be stable across R versions and on at least
>> one Linux platform.)
>>
>> Andy Liaw showed another example of 'crossprod' being fast a couple
>> days ago on R-help.
>>
>> Questions for those with a more global picture of the code:
>>
>> *  Is the speed advantage of 'crossprod' inherent, or is it because
>> more care has been taken with its implementation than the other
>> functions?
>>
>> *  Is 'crossprod' faster than 'sum(x * y)' because 'crossprod' is
>> going to BLAS while 'sum' can't?
>
>
> For a numeric matrix crossprod ends up calling level 3 BLAS; either 
> dsyrk for the single argument case or dgemm for the two argument case. 
> Especially in accelerated versions of the BLAS like Atlas or Goto's 
> BLAS, those routines are hideously efficient and that's where you are 
> seeing the big gain in speed.
>
> By the way, you didn't mention if you had an accelerated BLAS 
> installed with R.  Do you?
>
>
>

From ligges at statistik.uni-dortmund.de  Fri Jan 28 09:18:26 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Jan 28 09:17:24 2005
Subject: [Rd] the incredible lightness of crossprod
In-Reply-To: <41F96807.1000405@pburns.seanet.com>
References: <41F907EA.90406@pburns.seanet.com> <41F9382E.2060200@stat.wisc.edu>
	<41F96807.1000405@pburns.seanet.com>
Message-ID: <41F9F552.7090501@statistik.uni-dortmund.de>

Patrick Burns wrote:

> On my machine the versions are all precompiled R, and I would
> be very surprised if the same were not the case on the client's
> machine.  That is, no specially compiled BLAS.

Hmmm. I always install using some advanced BLAS: On Windows, e.g., 
simply using the Rblas.dll provided by Brian Ripley, on Linux it's 
really no effort to compile it yourself.

For huge matrices you can use your some-years-old-desktop machine (with 
some advanced BLAS) to outperform expensive multi-CPU machines (without 
advanced BLAS).

Uwe Ligges

From ripley at stats.ox.ac.uk  Fri Jan 28 10:00:06 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jan 28 10:15:14 2005
Subject: [Rd] the incredible lightness of crossprod
In-Reply-To: <41F9F552.7090501@statistik.uni-dortmund.de>
References: <41F907EA.90406@pburns.seanet.com> <41F9382E.2060200@stat.wisc.edu>
	<41F96807.1000405@pburns.seanet.com>
	<41F9F552.7090501@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.61.0501280852020.29864@gannet.stats>

On Fri, 28 Jan 2005, Uwe Ligges wrote:

> Patrick Burns wrote:
>
>> On my machine the versions are all precompiled R, and I would
>> be very surprised if the same were not the case on the client's
>> machine.  That is, no specially compiled BLAS.
>
> Hmmm. I always install using some advanced BLAS: On Windows, e.g., simply 
> using the Rblas.dll provided by Brian Ripley, on Linux it's really no effort 
> to compile it yourself.
>
> For huge matrices you can use your some-years-old-desktop machine (with some 
> advanced BLAS) to outperform expensive multi-CPU machines (without advanced 
> BLAS).

As I think has been noted earlier, there is often some loss for 
moderately-sized matrices.  When Doug Bates first used dgemm for %*% and 
crossprod, it made the R tests run noticeably slower on the (70MHz)
Solaris machines I was using at the time.  But that price is paid whether 
you have an optimized BLAS or not.

But anyone working with 100+ diml matrices should try an optimized BLAS. 
Building ATLAS can be a bit painful (especially as you really need a 
shared library for use with R), but often prebuilt versions are available 
(e.g. Goto's BLAS and atlas on Debian and Windows).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From john.marsland at mac.com  Fri Jan 28 13:38:31 2005
From: john.marsland at mac.com (John Marsland)
Date: Fri Jan 28 13:38:36 2005
Subject: [Rd] compiling and making R-2.0.1 for windows XP
Message-ID: <11272642.1106915911358.JavaMail.john.marsland@mac.com>

I am having no luck compiling R-2.0.1 on a Windows XP platform. I have not had these problems when compliling previous versions of R.

I've installed all the recommended software and tools. But I cannot get round this error message:

make
make[1]: `Rpwd.exe' is up to date.
make -f Makefile.docfiles
make[3]: Nothing to be done for `docfiles'.
-------- Building ../../../library/base/R/Rprofile from ../../library/profile/Common.R ../../library/profile/Rprofile.windows--------
mkdir -p ../../../library/base/R
cat: not found
make[3]: *** [../../../library/base/R/Rprofile] Error 127
make[2]: *** [fixfiles] Error 2
make[1]: *** [rbuild] Error 2
make: *** [all] Error 2

Can anybody suggest a solution?

Thanks,

John

From andy_liaw at merck.com  Fri Jan 28 14:47:45 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Jan 28 14:48:13 2005
Subject: [Rd] compiling and making R-2.0.1 for windows XP
Message-ID: <3A822319EB35174CA3714066D590DCD50994E5E0@usrymx25.merck.com>

> From: John Marsland
> 
> I am having no luck compiling R-2.0.1 on a Windows XP 
> platform. I have not had these problems when compliling 
> previous versions of R.
> 
> I've installed all the recommended software and tools. But I 
> cannot get round this error message:
> 
> make
> make[1]: `Rpwd.exe' is up to date.
> make -f Makefile.docfiles
> make[3]: Nothing to be done for `docfiles'.
> -------- Building ../../../library/base/R/Rprofile from 
> ../../library/profile/Common.R 
> ../../library/profile/Rprofile.windows--------
> mkdir -p ../../../library/base/R
> cat: not found
  ^^^^^^^^^^^^^^

Have you checked to make sure the *nix tools in Rtool.zip is in the PATH?

Andy

> make[3]: *** [../../../library/base/R/Rprofile] Error 127
> make[2]: *** [fixfiles] Error 2
> make[1]: *** [rbuild] Error 2
> make: *** [all] Error 2
> 
> Can anybody suggest a solution?
> 
> Thanks,
> 
> John
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>

From ligges at statistik.uni-dortmund.de  Fri Jan 28 14:49:58 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Jan 28 14:49:00 2005
Subject: [Rd] compiling and making R-2.0.1 for windows XP
In-Reply-To: <11272642.1106915911358.JavaMail.john.marsland@mac.com>
References: <11272642.1106915911358.JavaMail.john.marsland@mac.com>
Message-ID: <41FA4306.4050202@statistik.uni-dortmund.de>

John Marsland wrote:

> I am having no luck compiling R-2.0.1 on a Windows XP platform. I have not had these problems when compliling previous versions of R.
> 
> I've installed all the recommended software and tools. But I cannot get round this error message:
> 
> make
> make[1]: `Rpwd.exe' is up to date.
> make -f Makefile.docfiles
> make[3]: Nothing to be done for `docfiles'.
> -------- Building ../../../library/base/R/Rprofile from ../../library/profile/Common.R ../../library/profile/Rprofile.windows--------
> mkdir -p ../../../library/base/R
> cat: not found

cat should be among the tools, looks like Duncan's latest release of 
tools.zip is missing cat (and I have tested the new release by 
overwriting older files, so I haven't noticed at least one file is 
missing this time).

Uwe





> make[3]: *** [../../../library/base/R/Rprofile] Error 127
> make[2]: *** [fixfiles] Error 2
> make[1]: *** [rbuild] Error 2
> make: *** [all] Error 2
> 
> Can anybody suggest a solution?
> 
> Thanks,
> 
> John
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From none at stat.math.ethz.ch  Fri Jan 28 16:13:23 2005
From: none at stat.math.ethz.ch (none@stat.math.ethz.ch)
Date: Fri Jan 28 16:13:30 2005
Subject: [Rd] Symantec Mail Security detected an unrepairable virus in a
	message you sent (SYM:03242062791027699502) (PR#7581)
Message-ID: <20050128151323.0ACC5DB7B@slim.kubism.ku.dk>

Subject of the message: Hello
Recipient of the message: Westfall, Peter

From ripley at stats.ox.ac.uk  Fri Jan 28 16:37:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jan 28 16:37:52 2005
Subject: [Rd] compiling and making R-2.0.1 for windows XP
In-Reply-To: <41FA4306.4050202@statistik.uni-dortmund.de>
References: <11272642.1106915911358.JavaMail.john.marsland@mac.com>
	<41FA4306.4050202@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.61.0501281537110.18678@gannet.stats>

On Fri, 28 Jan 2005, Uwe Ligges wrote:

> John Marsland wrote:
>
>> I am having no luck compiling R-2.0.1 on a Windows XP platform. I have not 
>> had these problems when compliling previous versions of R.
>> 
>> I've installed all the recommended software and tools. But I cannot get 
>> round this error message:
>> 
>> make
>> make[1]: `Rpwd.exe' is up to date.
>> make -f Makefile.docfiles
>> make[3]: Nothing to be done for `docfiles'.
>> -------- Building ../../../library/base/R/Rprofile from 
>> ../../library/profile/Common.R 
>> ../../library/profile/Rprofile.windows--------
>> mkdir -p ../../../library/base/R
>> cat: not found
>
> cat should be among the tools, looks like Duncan's latest release of 
> tools.zip is missing cat (and I have tested the new release by overwriting 
> older files, so I haven't noticed at least one file is missing this time).

It is in the list mentioned in INSTALL, which is worth checking....


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From murdoch at stats.uwo.ca  Fri Jan 28 16:44:06 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri Jan 28 16:42:48 2005
Subject: [Rd] compiling and making R-2.0.1 for windows XP
In-Reply-To: <Pine.LNX.4.61.0501281537110.18678@gannet.stats>
References: <11272642.1106915911358.JavaMail.john.marsland@mac.com>
	<41FA4306.4050202@statistik.uni-dortmund.de>
	<Pine.LNX.4.61.0501281537110.18678@gannet.stats>
Message-ID: <rcnkv0t1jg9dlrm1mc96b3f5gp1j67pruc@4ax.com>

On Fri, 28 Jan 2005 15:37:41 +0000 (GMT), Prof Brian Ripley
<ripley@stats.ox.ac.uk> wrote :

>On Fri, 28 Jan 2005, Uwe Ligges wrote:
>
>> John Marsland wrote:
>>
>>> I am having no luck compiling R-2.0.1 on a Windows XP platform. I have not 
>>> had these problems when compliling previous versions of R.
>>> 
>>> I've installed all the recommended software and tools. But I cannot get 
>>> round this error message:
>>> 
>>> make
>>> make[1]: `Rpwd.exe' is up to date.
>>> make -f Makefile.docfiles
>>> make[3]: Nothing to be done for `docfiles'.
>>> -------- Building ../../../library/base/R/Rprofile from 
>>> ../../library/profile/Common.R 
>>> ../../library/profile/Rprofile.windows--------
>>> mkdir -p ../../../library/base/R
>>> cat: not found
>>
>> cat should be among the tools, looks like Duncan's latest release of 
>> tools.zip is missing cat (and I have tested the new release by overwriting 
>> older files, so I haven't noticed at least one file is missing this time).
>
>It is in the list mentioned in INSTALL, which is worth checking....

I accidentally put "cal" in instead of "cat"; it was fixed just
yesterday.  

Duncan Murdoch

From john.marsland at mac.com  Fri Jan 28 16:56:45 2005
From: john.marsland at mac.com (John Marsland)
Date: Fri Jan 28 16:56:57 2005
Subject: [Rd] compiling and making R-2.0.1 for windows XP
In-Reply-To: <rcnkv0t1jg9dlrm1mc96b3f5gp1j67pruc@4ax.com>
References: <11272642.1106915911358.JavaMail.john.marsland@mac.com>
	<41FA4306.4050202@statistik.uni-dortmund.de>
	<Pine.LNX.4.61.0501281537110.18678@gannet.stats>
	<rcnkv0t1jg9dlrm1mc96b3f5gp1j67pruc@4ax.com>
Message-ID: <6638336.1106927805617.JavaMail.john.marsland@mac.com>

 
On Friday, January 28, 2005, at 03:42PM, Duncan Murdoch <murdoch@stats.uwo.ca> wrote:

>On Fri, 28 Jan 2005 15:37:41 +0000 (GMT), Prof Brian Ripley
><ripley@stats.ox.ac.uk> wrote :
>
>>On Fri, 28 Jan 2005, Uwe Ligges wrote:
>>
>>> John Marsland wrote:
>>>
>>>> I am having no luck compiling R-2.0.1 on a Windows XP platform. I have not 
>>>> had these problems when compliling previous versions of R.
>>>> 
>>>> I've installed all the recommended software and tools. But I cannot get 
>>>> round this error message:
>>>> 
>>>> make
>>>> make[1]: `Rpwd.exe' is up to date.
>>>> make -f Makefile.docfiles
>>>> make[3]: Nothing to be done for `docfiles'.
>>>> -------- Building ../../../library/base/R/Rprofile from 
>>>> ../../library/profile/Common.R 
>>>> ../../library/profile/Rprofile.windows--------
>>>> mkdir -p ../../../library/base/R
>>>> cat: not found
>>>
>>> cat should be among the tools, looks like Duncan's latest release of 
>>> tools.zip is missing cat (and I have tested the new release by overwriting 
>>> older files, so I haven't noticed at least one file is missing this time).
>>
>>It is in the list mentioned in INSTALL, which is worth checking....
>
>I accidentally put "cal" in instead of "cat"; it was fixed just
>yesterday.  
>
>Duncan Murdoch
>
>

Thankyou. I just re-downloaded tools.zip and everything seems to work.

Regards,

John

From markus.liedgens at ipw.agrl.ethz.ch  Fri Jan 28 19:58:39 2005
From: markus.liedgens at ipw.agrl.ethz.ch (markus.liedgens@ipw.agrl.ethz.ch)
Date: Fri Jan 28 19:58:46 2005
Subject: [Rd] print() from within a function - Windows specific? (PR#7584)
Message-ID: <20050128185839.2A1C8DB8B@slim.kubism.ku.dk>

Full_Name: Markus Liedgens
Version: Ever since 1.6
OS: Windows 98 / Windows Xp
Submission from: (NULL) (81.63.111.226)


To control the progress of a function one can consider to use print() to issue a
message in the command window. However, using Win98 / R 1.9 or WinXP / R 2.0,
this approach is of little usefulness, since all the print() commands are issued
at once, just before the control returns to the command window. A test code
could be:

for(i in 1:10){
 for(j in 1:1000){
  for(k in 1:1000){}
 }
 print(i)
}

I once ask a linux / unix user and he was not able to reproduce the problem.

Best regards

-------------------------------------------------
Markus Liedgens
Institut f?r Pflanzenwissenschaften - ETH Z?rich
FEL Eschikon 33
8315 Lidau, Switzerland
e-mail: markus.liedgens@ipw.agrl.ethz.ch
--------------------------------------------------
8315 Lindau

From ripley at stats.ox.ac.uk  Fri Jan 28 20:15:26 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Jan 28 20:15:37 2005
Subject: [Rd] (PR#7584) user failure to read the FAQ (was print() from
	within a function - Windows specific?)
In-Reply-To: <20050128185839.2A1C8DB8B@slim.kubism.ku.dk>
References: <20050128185839.2A1C8DB8B@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0501281909350.7346@gannet.stats>

Please read the rw-FAQ, Q6.3. for a discussion to this very useful 
*feature*.

It has been in the FAQ since before 1.0.0.

On Fri, 28 Jan 2005 markus.liedgens@ipw.agrl.ethz.ch wrote:

> Full_Name: Markus Liedgens
> Version: Ever since 1.6

There is no such version of R, and never has been.

> OS: Windows 98 / Windows Xp
> Submission from: (NULL) (81.63.111.226)
>
>
> To control the progress of a function one can consider to use print() to issue a
> message in the command window. However, using Win98 / R 1.9 or WinXP / R 2.0,
> this approach is of little usefulness, since all the print() commands are issued
> at once, just before the control returns to the command window. A test code
> could be:
>
> for(i in 1:10){
> for(j in 1:1000){
>  for(k in 1:1000){}
> }
> print(i)
> }
>
> I once ask a linux / unix user and he was not able to reproduce the 
> problem.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From andy_liaw at merck.com  Fri Jan 28 20:16:40 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Jan 28 20:17:11 2005
Subject: [Rd] print() from within a function - Windows specific? (
	PR# 7584)
Message-ID: <3A822319EB35174CA3714066D590DCD50994E5EA@usrymx25.merck.com>

It really pays to RTFM sometimes: 
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#The-output-to-the-con
sole-seems-to-be-delayed

Andy

> From: markus.liedgens@ipw.agrl.ethz.ch
> 
> Full_Name: Markus Liedgens
> Version: Ever since 1.6
> OS: Windows 98 / Windows Xp
> Submission from: (NULL) (81.63.111.226)
> 
> 
> To control the progress of a function one can consider to use 
> print() to issue a
> message in the command window. However, using Win98 / R 1.9 
> or WinXP / R 2.0,
> this approach is of little usefulness, since all the print() 
> commands are issued
> at once, just before the control returns to the command 
> window. A test code
> could be:
> 
> for(i in 1:10){
>  for(j in 1:1000){
>   for(k in 1:1000){}
>  }
>  print(i)
> }
> 
> I once ask a linux / unix user and he was not able to 
> reproduce the problem.
> 
> Best regards
> 
> -------------------------------------------------
> Markus Liedgens
> Institut f?r Pflanzenwissenschaften - ETH Z?rich
> FEL Eschikon 33
> 8315 Lidau, Switzerland
> e-mail: markus.liedgens@ipw.agrl.ethz.ch
> --------------------------------------------------
> 8315 Lindau
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>

From andy_liaw at merck.com  Fri Jan 28 20:17:05 2005
From: andy_liaw at merck.com (andy_liaw@merck.com)
Date: Fri Jan 28 20:17:12 2005
Subject: [Rd] print() from within a function - Windows specific? (
	(PR#7587)
Message-ID: <20050128191705.A5960DB8B@slim.kubism.ku.dk>

It really pays to RTFM sometimes:=20
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#The-output-to-the-con
sole-seems-to-be-delayed

Andy

> From: markus.liedgens@ipw.agrl.ethz.ch
>=20
> Full_Name: Markus Liedgens
> Version: Ever since 1.6
> OS: Windows 98 / Windows Xp
> Submission from: (NULL) (81.63.111.226)
>=20
>=20
> To control the progress of a function one can consider to use=20
> print() to issue a
> message in the command window. However, using Win98 / R 1.9=20
> or WinXP / R 2.0,
> this approach is of little usefulness, since all the print()=20
> commands are issued
> at once, just before the control returns to the command=20
> window. A test code
> could be:
>=20
> for(i in 1:10){
>  for(j in 1:1000){
>   for(k in 1:1000){}
>  }
>  print(i)
> }
>=20
> I once ask a linux / unix user and he was not able to=20
> reproduce the problem.
>=20
> Best regards
>=20
> -------------------------------------------------
> Markus Liedgens
> Institut f=FCr Pflanzenwissenschaften - ETH Z=FCrich
> FEL Eschikon 33
> 8315 Lidau, Switzerland
> e-mail: markus.liedgens@ipw.agrl.ethz.ch
> --------------------------------------------------
> 8315 Lindau
>=20
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>=20
>=20


---------------------------------------------------------------------------=
---
Notice:  This e-mail message, together with any attachments,...{{dropped}}

From p.dalgaard at biostat.ku.dk  Fri Jan 28 20:19:50 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Jan 28 20:23:30 2005
Subject: [Rd] print() from within a function - Windows specific? (PR#7584)
In-Reply-To: <20050128185839.2A1C8DB8B@slim.kubism.ku.dk>
References: <20050128185839.2A1C8DB8B@slim.kubism.ku.dk>
Message-ID: <x2zmytqs2x.fsf@biostat.ku.dk>

markus.liedgens@ipw.agrl.ethz.ch writes:

> To control the progress of a function one can consider to use print() to issue a
> message in the command window. However, using Win98 / R 1.9 or WinXP / R 2.0,
> this approach is of little usefulness, since all the print() commands are issued
> at once, just before the control returns to the command window. A test code
> could be:
> 
> for(i in 1:10){
>  for(j in 1:1000){
>   for(k in 1:1000){}
>  }
>  print(i)
> }
> 
> I once ask a linux / unix user and he was not able to reproduce the problem.

It IS a FAQ though...

http://cran.r-project.org/bin/windows/base/rw-FAQ.html#The-output-to-the-console-seems-to-be-delayed

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From wolski at molgen.mpg.de  Sun Jan 30 15:10:27 2005
From: wolski at molgen.mpg.de (Witold Eryk Wolski)
Date: Sun Jan 30 15:10:39 2005
Subject: [Rd] S4 packages and .Rdata file.
Message-ID: <41FCEAD3.4030908@molgen.mpg.de>

Dear developers.

Have spend just 1 h searching for a bug in a new version of a new 
version of a package.
I was getting a segfault all the time. "Funny" thing - there was no 
error neither in the S nor in the C code.

To solve the problem I had to delete the .Rdata file!

What I observed. If the .Rdata file was generated while a previous 
release of a package was installed  in the .Rdata file the S4 classes 
and methods definition are stored  for some reasons. It may be of course 
that I have sourced the method definition what would explain why they 
are in .Rdata.  More interestingly is that even if loading a new version 
of a package with library(msbase)
the function definitions stored in .Rdata precede the methods of the 
newly loaded package in the search path. They are called instead of the 
new method definitions (?).

So If I wass calling what I thought is the new version of the method the 
old method stored months ago in the .Rdata file was called again and again.

Is not there a better way to avoid such problems than deleting the 
.Rdata file?

Eryk


-- 
Dipl. bio-chem. Witold Eryk Wolski
MPI-Moleculare Genetic
Ihnestrasse 63-73 14195 Berlin
tel: 0049-30-83875219                 __("<    _
http://www.molgen.mpg.de/~wolski      \__/    'v'
http://r4proteomics.sourceforge.net    ||    /   \
mail: witek96@users.sourceforge.net    ^^     m m
      wolski@molgen.mpg.de

From roebuck at odin.mdacc.tmc.edu  Sun Jan 30 23:29:59 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Sun Jan 30 23:30:03 2005
Subject: [Rd] Typo in 'R Language Definition'
Message-ID: <Pine.OSF.4.58.0501301627200.374256@odin.mdacc.tmc.edu>

Section 3.5.3 The call stack (pg 23 of R-lang.pdf)
...the computation the the currently active environment...
                   ^^^

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)

From tsl2u.c0shr at myweb.cn  Sun Jan 30 11:48:20 2005
From: tsl2u.c0shr at myweb.cn (EMBROIDERED)
Date: Mon Jan 31 02:02:08 2005
Subject: [Rd] (no subject)
Message-ID: <31958CD2517@localhost>

Sender: EMBROIDERED <tsl2u.c0shr@myweb.cn>
Reply-To: meilung1931@yahoo.com.tw
Date: Thu, 16 Dec 2004 12:08:13 +0800
X-Mailer:Dynamailer V 8.4
X-MimeOLE:Produced By Mircosoft MimeOLE V6.00.2600.0000
Return-Path:meilung1931@yahoo.com.tw

[r-devel@stat.math.ethz.ch                                                               ]

EMBROIDERED PATCHES  CUSTOM   POLICE , FIRE, SPORTS , CLUBS   
Founded in 1931, we have been specializing in the manufacture of Bullion embroideries and computer 
embroideries for more than 70 years

In Taiwan, we are the sole company that was an approved supplier for U.S. Navy Exchange In Taiwan from 
1960s to 1973
.
Our products are listed as follows:
Police patches, Armed forces patches, Lions Club International badges, Rotary International badges, Junior 
Chamber of Commerce badges, golf club badges, art designs, Buddhist-image embroideries, wedding 
photograph embroideries, portrait embroideries, and a variety of 3D raised embroideries and popular 
embroideries.

We offer wholesale and retail services. Welcome to place us orders!
Welcome to contact us (please don't reply the mail directly, as the box for returned mails will be deleted). 
Please send your mail to  mei926@ms32.hinet.net.
  
We have many sorts of products on our website if you want to see our products please click the following 
e-mail address we will send you our URL index link.  mei926@ms32.hinet.net?subject=URL-Index-Link

We sincerely apologize for any inconvenience that this mail may cause to you! 
If you don't want any more mail from us, please send an email to us using the following address:
masaru26@ms69.hinet.net?subject=Remove-041215am1048 
 
Chang Wen-sheng
MEI LUNG HANDICRAFTS CO., LTD
No.2, LANE 6 CHENG TE ROAD SEC.4, TAIPEI TAIWAN
TEL:886-2-2886-4629 2885-8538  FAX:2886-8598
E-mail: mei926@ms32.hinet.net   
 
[r-devel@stat.math.ethz.ch                                                               jZbGaL]

From orders at empire-group.com  Mon Jan 31 06:35:02 2005
From: orders at empire-group.com (orders@empire-group.com)
Date: Mon Jan 31 06:35:12 2005
Subject: [Rd] Wnd0ws 98 Second Edition update (PR#7602)
Message-ID: <20050131053502.BB680856A@slim.kubism.ku.dk>

--Boundary_(ID_42842256128951747)
Content-type: text/plain; charset=ISO-8859-1
Content-transfer-encoding: 7Bit

7gB02ltxm4g23UB13D0G

--Boundary_(ID_42842256128951747)
Content-type: text/plain;; charset=ISO-8859-1
Content-transfer-encoding: 7Bit

W<w>all St<j>reet Journ<x>a<d>l : syst<e>em co<x>mpari<e>son

W1N<l>D0WS X'<k>P Pr0 <y>+ 0FF1<m>CE X<g>'P P<j>r0 -  80 <r>d0IIar <k>(80<n>% off!<n>)
W1ND0<f>WS X'P <k>- <m> 50 d0IIa<h>r (75% <m>off!)<k>

<n> http://<o>thai.<l>bestxp<x>oem.<c>com


<o>shop <x>coa<t>uthor  fab<t>ian mi<e>litia<m> an<o>thropo<w>genic  b<o>uried
ji<d>ffy <v>merr<e>imack <o> stat<g>uary ter<d>rapin <w>northumb<j>erland<e>  <v>merrima<e>ck
su<v>rvivor k<h>ieffer<f>  unimo<v>dal c<w>ordit<x>e te<j>trahedral  <g>hi<g>llside
<o>charl<x>es bu<w>llyboy<r>  sophi<c>sticate<l> env<f>ious hydro<n>xyla<j>te  ho<o>spice
p<l>rivile<y>g<r>e triad  <v>sticky

--Boundary_(ID_42842256128951747)--

From ripley at stats.ox.ac.uk  Mon Jan 31 12:05:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 31 12:13:12 2005
Subject: [Rd] Typo in 'R Language Definition'
In-Reply-To: <Pine.OSF.4.58.0501301627200.374256@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0501301627200.374256@odin.mdacc.tmc.edu>
Message-ID: <Pine.LNX.4.61.0501311100100.20280@gannet.stats>

Which version of R is this?  I think it has been corrected a while ago
in R-patched and R-devel.  Do see the posting guide ....

On Sun, 30 Jan 2005, Paul Roebuck wrote:

> Section 3.5.3 The call stack (pg 23 of R-lang.pdf)
> ...the computation the the currently active environment...
>                   ^^^

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From interscan at nttdata.co.jp  Mon Jan 31 15:51:32 2005
From: interscan at nttdata.co.jp (interscan@nttdata.co.jp)
Date: Mon Jan 31 15:51:39 2005
Subject: [Rd] message from mail1 (Attachment Removal) (PR#7605)
Message-ID: <20050131145132.DECF4E079@slim.kubism.ku.dk>

This is a multi-part message in MIME format.

------=_NextPart_000_1107183070_B78506032.R82506026
Content-Type: text/plain;
	charset="iso-2022-jp"
Content-Transfer-Encoding: 7bit

**************** eManager Notification *****************

The following mail was blocked since it contains sensitive content.

Source mailbox: <r-bugs@r-project.org>
Destination mailbox(es): tokamoto@rd.nttdata.co.jp
Policy: Attachment Removal
Attachment file name: corrected_doc.pif - application/octet-stream
Action: Replaced with text

$BAw?.$7$?%a%C%;!<%8$K$O!"3HD%;R5,@)$K0cH?$9$k%U%!%$%k$,E:IU$5$l$F$$$^$7$?$,$3$NE:IU%U%!%$%k$O:o=|$5$l$^$7$?!#%&%$%k%9BP:v$N0l4D$H$7$F!"%a!<%k$KE:IU$5$l$?3HD%;R$,:o=|BP>]$G$"$k>l9g!"%U%!%$%k$O:o=|CW$7$^$9!#6HL3>e!"E:IU$9$kI,MW$,$"$k>l9g!"0l;~E*$K3HD%;R$r(B[txt]$BEy$KJQ99$7$FE:IU$7$F2<$5$$!#!J6[5^;~$K$O:o=|BP>]%U%!%$%k0J30$G$b!"%&%$%k%9$,4^$^$l$k2DG=@-$,$"$kE=IU%U%!%$%k$r:o=|$5$;$F$$$?$@$/>l9g$,$"$j$^$9!#!K(B

******************* End of message *********************

------=_NextPart_000_1107183070_B78506032.R82506026
Content-Type: text/plain;
	charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

Received: from rd.nttdata.co.jp ([221.219.146.169])
	by ms1.nttdata.co.jp (8.12.11/3.7W-NTTDATA-TOP-10/22/04) with ESMTP id j0VEp1lK026359
	for <tokamoto@rd.nttdata.co.jp>; Mon, 31 Jan 2005 23:51:02 +0900 (JST)
Message-Id: <200501311451.j0VEp1lK026359@ms1.nttdata.co.jp>
From: r-bugs@r-project.org
To: tokamoto@rd.nttdata.co.jp
Subject: Correction
Date: Mon, 31 Jan 2005 22:50:11 +0800
MIME-Version: 1.0
Content-Type: multipart/mixed;
	boundary="----=_NextPart_000_0004_00006A3D.00002F4A"
X-Priority: 3
X-MSMail-Priority: Normal

------=_NextPart_000_1107183070_B78506032.R82506026--

From faheem at email.unc.edu  Mon Jan 31 15:57:37 2005
From: faheem at email.unc.edu (Faheem Mitha)
Date: Mon Jan 31 15:57:51 2005
Subject: [Rd] type of list elements in .Call
Message-ID: <Pine.LNX.4.61.0501310953100.10677@Chrestomanci>


[Forwarding to r-devel.]

Dear People,

Here is something I do not understand. Consider

*************************************************
foo.cc
*************************************************
#include <iostream>
#include <R.h>
#include <Rinternals.h>

using std::cout;
using std::endl;

extern "C"
{
   SEXP printlst(SEXP lst);
}

SEXP printlst(SEXP lst)
{
   for(int i=0; i<length(lst); i++)
     for(int j=0; j<length(VECTOR_ELT(lst, i)); j++)
       cout << INTEGER(VECTOR_ELT(lst, i))[j] << endl;
   return lst;
}
*************************************************

> dyn.load("foo.so")
> .Call("printlst", list(c(1,2),c(3,4)))
0
1072693248
0
1074266112
[[1]]
[1] 1 2

[[2]]
[1] 3 4

If I replace INTEGER by REAL I get

> dyn.load("foo.so")
> .Call("printlst", list(c(1,2),c(3,4)))
1
2
3
4
[[1]]
[1] 1 2

[[2]]
[1] 3 4

as I would expect. I thought that if the vectors in the list could be 
regarded as integer vectors, they would be coerced appropriately, but 
apparently not. Is there any way I can tell R to regard them as integer 
vectors?

Thanks.                                                    Faheem.

From B.Rowlingson at lancaster.ac.uk  Mon Jan 31 16:13:05 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon Jan 31 16:13:12 2005
Subject: [Rd] type of list elements in .Call
In-Reply-To: <Pine.LNX.4.61.0501310953100.10677@Chrestomanci>
References: <Pine.LNX.4.61.0501310953100.10677@Chrestomanci>
Message-ID: <41FE4B01.3090601@lancaster.ac.uk>


> as I would expect. I thought that if the vectors in the list could be 
> regarded as integer vectors, they would be coerced appropriately, but 
> apparently not. Is there any way I can tell R to regard them as integer 
> vectors?

Change:

  .Call("printlst", list(c(1,2),c(3,4)))

To:

.Call("printlst", list(as.integer(c(1,2)),as.integer(c(3,4))))

Baz

From ripley at stats.ox.ac.uk  Mon Jan 31 16:16:25 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 31 16:16:36 2005
Subject: [Rd] type of list elements in .Call
In-Reply-To: <Pine.LNX.4.61.0501310953100.10677@Chrestomanci>
References: <Pine.LNX.4.61.0501310953100.10677@Chrestomanci>
Message-ID: <Pine.LNX.4.61.0501311510350.27856@gannet.stats>

On Mon, 31 Jan 2005, Faheem Mitha wrote:

> [Forwarding to r-devel.]

>
> Dear People,
>
> Here is something I do not understand. Consider

...

This is covered, copiously, in the examples in `Writing R Extensions'.
Hint: search for coerceVector.

> as I would expect. I thought that if the vectors in the list could be 
> regarded as integer vectors, they would be coerced appropriately, but 
> apparently not. Is there any way I can tell R to regard them as integer 
> vectors?

Reading the manual would have corrected your thinking.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From faheem at email.unc.edu  Mon Jan 31 16:39:03 2005
From: faheem at email.unc.edu (Faheem Mitha)
Date: Mon Jan 31 16:39:09 2005
Subject: [Rd] type of list elements in .Call
In-Reply-To: <41FE4B01.3090601@lancaster.ac.uk>
References: <Pine.LNX.4.61.0501310953100.10677@Chrestomanci>
	<41FE4B01.3090601@lancaster.ac.uk>
Message-ID: <Pine.LNX.4.61.0501311037101.10677@Chrestomanci>



On Mon, 31 Jan 2005, Barry Rowlingson wrote:

>
>> as I would expect. I thought that if the vectors in the list could be 
>> regarded as integer vectors, they would be coerced appropriately, but 
>> apparently not. Is there any way I can tell R to regard them as integer 
>> vectors?
>
> Change:
>
> .Call("printlst", list(c(1,2),c(3,4)))
>
> To:
>
> .Call("printlst", list(as.integer(c(1,2)),as.integer(c(3,4))))

Thanks for the suggestion. However, I want to do the coercion at the level 
of the C/C++ code. Also, I don't want to have to manually insert multiple 
calls to as.integer if possible.

                                                                  Faheem.

From faheem at email.unc.edu  Mon Jan 31 16:51:31 2005
From: faheem at email.unc.edu (Faheem Mitha)
Date: Mon Jan 31 16:51:34 2005
Subject: [Rd] type of list elements in .Call
In-Reply-To: <Pine.LNX.4.61.0501311510350.27856@gannet.stats>
References: <Pine.LNX.4.61.0501310953100.10677@Chrestomanci>
	<Pine.LNX.4.61.0501311510350.27856@gannet.stats>
Message-ID: <Pine.LNX.4.61.0501311042060.10677@Chrestomanci>



On Mon, 31 Jan 2005, Prof Brian Ripley wrote:

> This is covered, copiously, in the examples in `Writing R Extensions'. 
> Hint: search for coerceVector.

I see. I thought that INTEGER and its relatives did coercion too, but now 
I see that is not stated anywhere.

Eg. REAL is first used in "Writing R Extensions" in 4.7.1 as in

REAL(ab)[0] = 123.45
...

and I cannot find a discussion about what it does previous to that, or 
indeed afterwards.

In Rinternals header file, it says

/* Under the generational allocator the data for vector nodes comes
    immediately after the node structure, so the data address is a
    known ofset from the node SEXP. */

This does not mean much to me. Perhaps a short comment in the 
documentation would be helpful, if not already present.

                                                                   Faheem.

From reid_huntsinger at merck.com  Mon Jan 31 18:42:05 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Mon Jan 31 18:42:29 2005
Subject: [Rd] type of list elements in .Call
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A929B@uswpmx00.merck.com>

This just means that R doesn't currently do anything complicated when you
ask for a pointer to the data in an R vector object. But that doesn't
matter; the behavior of REAL etc doesn't depend on that. 

Note that INTEGER, REAL, etc just give you pointers of type int *, double *,
etc. It's up to you to make sure that a particular use makes sense or you'll
get garbage at best. As discussed in the manual, you can either do this on
the R side, or in C: first check the type of the object, then coerce if that
makes sense and is necessary, and handle errors as you see fit.

Coercion between types requires a copy, in general, so you need to
explicitly ask for that. 

Reid Huntsinger


-----Original Message-----
From: r-devel-bounces@stat.math.ethz.ch
[mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Faheem Mitha
Sent: Monday, January 31, 2005 10:52 AM
To: Prof Brian Ripley
Cc: r-devel@stat.math.ethz.ch
Subject: Re: [Rd] type of list elements in .Call




On Mon, 31 Jan 2005, Prof Brian Ripley wrote:

> This is covered, copiously, in the examples in `Writing R Extensions'. 
> Hint: search for coerceVector.

I see. I thought that INTEGER and its relatives did coercion too, but now 
I see that is not stated anywhere.

Eg. REAL is first used in "Writing R Extensions" in 4.7.1 as in

REAL(ab)[0] = 123.45
...

and I cannot find a discussion about what it does previous to that, or 
indeed afterwards.

In Rinternals header file, it says

/* Under the generational allocator the data for vector nodes comes
    immediately after the node structure, so the data address is a
    known ofset from the node SEXP. */

This does not mean much to me. Perhaps a short comment in the 
documentation would be helpful, if not already present.

                                                                   Faheem.

______________________________________________
R-devel@stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From jmc at R-project.org  Mon Jan 31 22:32:06 2005
From: jmc at R-project.org (John Chambers)
Date: Mon Jan 31 22:33:40 2005
Subject: [Rd] S4 packages and .Rdata file.
In-Reply-To: <41FCEAD3.4030908@molgen.mpg.de>
References: <41FCEAD3.4030908@molgen.mpg.de>
Message-ID: <41FEA3D6.80207@R-project.org>



Witold Eryk Wolski wrote:

> Dear developers.
> 
> Have spend just 1 h searching for a bug in a new version of a new 
> version of a package.
> I was getting a segfault all the time. "Funny" thing - there was no 
> error neither in the S nor in the C code.
> 
> To solve the problem I had to delete the .Rdata file!
> 
> What I observed. If the .Rdata file was generated while a previous 
> release of a package was installed  in the .Rdata file the S4 classes 
> and methods definition are stored  for some reasons. It may be of course 
> that I have sourced the method definition what would explain why they 
> are in .Rdata.  More interestingly is that even if loading a new version 
> of a package with library(msbase)
> the function definitions stored in .Rdata precede the methods of the 
> newly loaded package in the search path. They are called instead of the 
> new method definitions (?).

When you save a workspace image, that includes method definitions done 
in the global environment (as you would certainly want it to).  The 
objects have special names in order to follow the "metadata" semantics 
in "Programming with Data" and also not to conflict with ordinary objects.

If you _don't_ want to save methods for function "f", use 
removeMethods("f") before saving and quitting.

To find out what functions have methods defined in the global 
environment, use getGenerics(1).  Then you can use removeMethods() for 
those functions & resave the workspace image.

If the function "f" has methods in other packages as well, use
   removeMethods("f", all=FALSE)
to remove only the methods object in the global environment.

And if you like the grubby but direct approach, do
   objects(all=TRUE)
which will show methods lists as objects with names starting with 
".__M__".  You can remove those objects using the list= argument to rm().

> 
> So If I wass calling what I thought is the new version of the method the 
> old method stored months ago in the .Rdata file was called again and again.
> 
> Is not there a better way to avoid such problems than deleting the 
> .Rdata file?
> 
> Eryk
> 
>

