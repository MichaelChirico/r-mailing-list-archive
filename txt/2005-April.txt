From volker.franz at tuebingen.mpg.de  Fri Apr  1 06:25:58 2005
From: volker.franz at tuebingen.mpg.de (volker.franz@tuebingen.mpg.de)
Date: Fri Apr  1 06:26:15 2005
Subject: [Rd] plotCI error when trying to omit upper or lower bars (PR#7764)
Message-ID: <20050401042558.4F188C031@slim.kubism.ku.dk>

Full_Name: Volker Franz
Version: 2.0.1  (2004-11-15)
OS: Mac OSX / Debian
Submission from: (NULL) (84.58.8.232)


Hi there,

the new version of plotCI (Version: 2.0.3 of gplots) produces errors
if the upper or lower error bars should be omitted by passing NULL as
an argument. Older versions of plotCI had no problem with this. Here 
is an example:

library(gplots)
means  <- c(1,2,3,4,5)
upperw <- c(1,1,1,1,1)
lowerw <- c(1,1,1,1,1)
upper  <- means+upperw
lower  <- means-lowerw

plotCI(x=means,uiw=upperw,liw=lowerw) #Works fine
plotCI(x=means,ui=upper,li=lower)     #Works fine

##Error with uiw and liw:
plotCI(x=means,uiw=NULL,liw=lowerw) #Error: subscript out of bounds
plotCI(x=means,uiw=upperw,liw=NULL) #Error: subscript out of bounds

##Error with ui and li:
plotCI(x=means,ui=NULL ,li=lower) #Error: Argument "uiw" is missing, with no
default
plotCI(x=means,ui=upper,li=NULL)  #Error: Argument "uiw" is missing, with no
default

##These are errors, because the plotCI-help says: 
##      uiw: width of the upper or right error bar. Set to 'NULL' omit
##           upper bars.
##      liw: width of the lower or left error bar.  Defaults to same value
##           as 'uiw'.  Set to 'NULL' to omit lower bars. 
##      ui: upper end of error bars.  Defaults to 'y + uiw' or 'x + uiw'
##          depeding on 'err'.  Set to 'NULL' omit upper bars. 
##      li: lower end of error bars.  Defaults to 'y - liw' or 'x - liw'
##          depedning on 'err'.  Set to 'NULL' to omit lower bars.

Best
Volker

From charlie at stat.umn.edu  Fri Apr  1 09:31:51 2005
From: charlie at stat.umn.edu (Charles Geyer)
Date: Fri Apr  1 09:32:15 2005
Subject: [Rd] formulas and frames
In-Reply-To: <200503051102.j25B2jec015493@hypatia.math.ethz.ch>
References: <200503051102.j25B2jec015493@hypatia.math.ethz.ch>
Message-ID: <20050401073151.GA13433@stat.umn.edu>

I have a design problem.  I'm trying to design a package that does
something like glm, but

  1. the response is multivariate, so I can't be just like glm
     and get the response variables out of the formula.  I decided
     (perhaps incorrectly) to just supply the response variable
     names as an argument "response".

  2. I have the usual predictor variables.

  3. I discovered the reshape function, which will allow me to
     string out the data frame in long form with the response
     strung out in a single vector.  So I can get a model matrix
     for the right hand side of the formula, which can also include
     what reshape calls the time variable (although it isn't time).

so far so good, but

  4. Each response variable is conditioned on a "predecessor" variable.

so we come to my question.  How do I force a bunch of variables into
a data frame?  I need all of the "response" and "predecessor" variables,
which are at this point specified only by a character vector containing
their names (or something else???) and I also need all of the predictor
variables.  If the user has supplied a data frame containing all that
stuff fine!  But if it's just all over the place, some in the "data"
argument and some in the R global environment (or elsewhere???).
Maybe I'm just ignorant, but I haven't stumbled across a function that
just stuffs all that stuff into a data frame (model.frame would do it
if I didn't have this extra stuff).

Any help?  Or do I just have to kludge this?

-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie@stat.umn.edu

From buser at stat.math.ethz.ch  Fri Apr  1 11:14:36 2005
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Fri Apr  1 11:14:50 2005
Subject: [Rd] simtest with lm object: depends on order in formula
Message-ID: <16973.4348.501231.667259@stat.math.ethz.ch>

Hi

I used the simtest function from the package multcomp. When
using simtest with an lm object, it seems to depend on the order
of the variables in the formula. See the code for an example:

library(multcomp)
set.seed(1)
# response
y <- rnorm(21)  
# one factor
f1 <- factor(c(rep(c("A", "B", "C"), 7)))
# and one continuous covariable
x <- rnorm(21)
testdata <- cbind(as.data.frame(y), f1, x)

# the same model, just change the order in the formula
reg1 <- lm(y ~ x + f1, data=testdata)
reg2 <- lm(y ~ f1 + x, data=testdata)
summary(simtest(reg1))
> Coefficients:
>             Estimate t value Std.Err. p raw p Bonf p adj
> (Intercept)    0.427  -1.670    0.347 0.113  0.453 0.307
> x              0.295  -0.599    0.256 0.557  1.000 0.848
> f1B            0.204  -0.406    0.503 0.690  1.000 0.866
> f1C            0.089  -0.255    0.493 0.802  1.000 0.866
summary(simtest(reg2))
> Coefficients:
>             Estimate t value Std.Err. p raw p Bonf p adj
> (Intercept)    0.427  -1.670    0.347 0.113  0.453 0.307
> f1B            0.295  -0.599    0.503 0.557  1.000 0.848
> f1C            0.204  -0.406    0.493 0.690  1.000 0.866
> x              0.089  -0.255    0.256 0.802  1.000 0.866
 
The tabular is fix, but the names of the variables are
permutated, maybe a bug in extracting the formula from the lm
object. 
You can avoid the problem by using a formula instead of an lm
object, but in the help is mentioned that simtest works with an 
lm object, too.


Regards,

Christoph Buser

--------------------------------------------------------------
Christoph Buser <buser@stat.math.ethz.ch>
Seminar fuer Statistik, LEO C11
ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
phone: x-41-1-632-5414		fax: 632-1228
http://stat.ethz.ch/~buser/

From Torsten.Hothorn at rzmail.uni-erlangen.de  Fri Apr  1 11:28:45 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Fri Apr  1 11:30:44 2005
Subject: [Rd] Re: simtest with lm object: depends on order in formula
In-Reply-To: <16973.4348.501231.667259@stat.math.ethz.ch>
References: <16973.4348.501231.667259@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.51.0504011128200.26417@artemis.imbe.med.uni-erlangen.de>

On Fri, 1 Apr 2005, Christoph Buser wrote:

> Hi
>
> I used the simtest function from the package multcomp. When
> using simtest with an lm object, it seems to depend on the order
> of the variables in the formula. See the code for an example:
>
> library(multcomp)
> set.seed(1)
> # response
> y <- rnorm(21)
> # one factor
> f1 <- factor(c(rep(c("A", "B", "C"), 7)))
> # and one continuous covariable
> x <- rnorm(21)
> testdata <- cbind(as.data.frame(y), f1, x)
>
> # the same model, just change the order in the formula
> reg1 <- lm(y ~ x + f1, data=testdata)
> reg2 <- lm(y ~ f1 + x, data=testdata)
> summary(simtest(reg1))
> > Coefficients:
> >             Estimate t value Std.Err. p raw p Bonf p adj
> > (Intercept)    0.427  -1.670    0.347 0.113  0.453 0.307
> > x              0.295  -0.599    0.256 0.557  1.000 0.848
> > f1B            0.204  -0.406    0.503 0.690  1.000 0.866
> > f1C            0.089  -0.255    0.493 0.802  1.000 0.866
> summary(simtest(reg2))
> > Coefficients:
> >             Estimate t value Std.Err. p raw p Bonf p adj
> > (Intercept)    0.427  -1.670    0.347 0.113  0.453 0.307
> > f1B            0.295  -0.599    0.503 0.557  1.000 0.848
> > f1C            0.204  -0.406    0.493 0.690  1.000 0.866
> > x              0.089  -0.255    0.256 0.802  1.000 0.866
>
> The tabular is fix, but the names of the variables are
> permutated, maybe a bug in extracting the formula from the lm
> object.
> You can avoid the problem by using a formula instead of an lm
> object, but in the help is mentioned that simtest works with an
> lm object, too.

you are right, thanks for the hint!

Torsten

>
>
> Regards,
>
> Christoph Buser
>
> --------------------------------------------------------------
> Christoph Buser <buser@stat.math.ethz.ch>
> Seminar fuer Statistik, LEO C11
> ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
> phone: x-41-1-632-5414		fax: 632-1228
> http://stat.ethz.ch/~buser/
> --------------------------------------------------------------
>
>

From ligges at statistik.uni-dortmund.de  Fri Apr  1 16:32:04 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Fri Apr  1 16:32:12 2005
Subject: [Rd] plotCI error when trying to omit upper or lower bars
	(PR#7764)
Message-ID: <20050401143204.6D209C9DF@slim.kubism.ku.dk>

volker.franz@tuebingen.mpg.de wrote:

> Full_Name: Volker Franz
> Version: 2.0.1  (2004-11-15)
> OS: Mac OSX / Debian
> Submission from: (NULL) (84.58.8.232)
> 
> 
> Hi there,
> 
> the new version of plotCI (Version: 2.0.3 of gplots) produces errors

So this is not a bug in R!
Please report bugs (if this is really a bug) to the package maintainer.

Uwe Ligges



> if the upper or lower error bars should be omitted by passing NULL as
> an argument. Older versions of plotCI had no problem with this. Here 
> is an example:
> 
> library(gplots)
> means  <- c(1,2,3,4,5)
> upperw <- c(1,1,1,1,1)
> lowerw <- c(1,1,1,1,1)
> upper  <- means+upperw
> lower  <- means-lowerw
> 
> plotCI(x=means,uiw=upperw,liw=lowerw) #Works fine
> plotCI(x=means,ui=upper,li=lower)     #Works fine
> 
> ##Error with uiw and liw:
> plotCI(x=means,uiw=NULL,liw=lowerw) #Error: subscript out of bounds
> plotCI(x=means,uiw=upperw,liw=NULL) #Error: subscript out of bounds
> 
> ##Error with ui and li:
> plotCI(x=means,ui=NULL ,li=lower) #Error: Argument "uiw" is missing, with no
> default
> plotCI(x=means,ui=upper,li=NULL)  #Error: Argument "uiw" is missing, with no
> default
> 
> ##These are errors, because the plotCI-help says: 
> ##      uiw: width of the upper or right error bar. Set to 'NULL' omit
> ##           upper bars.
> ##      liw: width of the lower or left error bar.  Defaults to same value
> ##           as 'uiw'.  Set to 'NULL' to omit lower bars. 
> ##      ui: upper end of error bars.  Defaults to 'y + uiw' or 'x + uiw'
> ##          depeding on 'err'.  Set to 'NULL' omit upper bars. 
> ##      li: lower end of error bars.  Defaults to 'y - liw' or 'x - liw'
> ##          depedning on 'err'.  Set to 'NULL' to omit lower bars.
> 
> Best
> Volker
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From ggrothendieck at gmail.com  Fri Apr  1 16:56:01 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri Apr  1 16:56:09 2005
Subject: [Rd] formulas and frames
In-Reply-To: <20050401073151.GA13433@stat.umn.edu>
References: <200503051102.j25B2jec015493@hypatia.math.ethz.ch>
	<20050401073151.GA13433@stat.umn.edu>
Message-ID: <971536df05040106564f692bab@mail.gmail.com>

Try this:

my.df <- data.frame(a=1:10, b=11:20, c=21:30, d=31:40)
> model.response(model.frame(cbind(a,b) ~ c+d, my.df))
    a  b
1   1 11
2   2 12
3   3 13
4   4 14
5   5 15
6   6 16
7   7 17
8   8 18
9   9 19
10 10 20


On Apr 1, 2005 2:31 AM, Charles Geyer <charlie@stat.umn.edu> wrote:
> I have a design problem.  I'm trying to design a package that does
> something like glm, but
> 
>  1. the response is multivariate, so I can't be just like glm
>     and get the response variables out of the formula.  I decided
>     (perhaps incorrectly) to just supply the response variable
>     names as an argument "response".
> 
>  2. I have the usual predictor variables.
> 
>  3. I discovered the reshape function, which will allow me to
>     string out the data frame in long form with the response
>     strung out in a single vector.  So I can get a model matrix
>     for the right hand side of the formula, which can also include
>     what reshape calls the time variable (although it isn't time).
> 
> so far so good, but
> 
>  4. Each response variable is conditioned on a "predecessor" variable.
> 
> so we come to my question.  How do I force a bunch of variables into
> a data frame?  I need all of the "response" and "predecessor" variables,
> which are at this point specified only by a character vector containing
> their names (or something else???) and I also need all of the predictor
> variables.  If the user has supplied a data frame containing all that
> stuff fine!  But if it's just all over the place, some in the "data"
> argument and some in the R global environment (or elsewhere???).
> Maybe I'm just ignorant, but I haven't stumbled across a function that
> just stuffs all that stuff into a data frame (model.frame would do it
> if I didn't have this extra stuff).
> 
> Any help?  Or do I just have to kludge this?
> 
> --
> Charles Geyer
> Professor, School of Statistics
> University of Minnesota
> charlie@stat.umn.edu
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From jfox at mcmaster.ca  Fri Apr  1 23:49:48 2005
From: jfox at mcmaster.ca (John Fox)
Date: Fri Apr  1 23:50:03 2005
Subject: [Rd] Selections from tcltk list boxes
Message-ID: <20050401214948.MUNM25800.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear r-devel list members,

I've experienced the following problem in getting a selection from a Tk list
box using tcltk. This is a long-standing problem, but I've finally decided
to tackle it.

Consider the following:

Library(tcltk)
top <- tktoplevel()
listbox <- tklistbox(top, height="10", width="2", exportselection="FALSE",
     selectmode="single")
for (x in letters[1:10]) tkinsert(listbox, "end", x)
value <- tclVar("")
entry <- tkentry(top, width="2", textvariable=value)
onOK <- function(){
    tkdestroy(top)
    print(tclvalue(value))
    return()
    }
onSelect <- function(){
    selection <- letters[1:10][as.numeric(tkcurselection(listbox)) + 1]
    tclvalue(value) <- selection
    }
OK <- tkbutton(top, text="OK", command=onOK)
tkgrid(listbox, entry, sticky="nw")
tkgrid(OK)
tkbind(listbox, "<ButtonPress-1>", onSelect)

As I understand it, single-clicking on an entry in the list box should
execute onSelect(), placing the selection in the entry box. What happens
instead is that one has to click twice on the entry, once (apparently) to
move the highlight to it and again to select it, executing onSelect().

If, however, I substitute tkbind(listbox, "<Double-ButtonPress-1>",
onSelect) for the last line, everything works as expected: double-clicking
on an entry executes onSelect(). One doesn't have to triple-click or
double-click twice.

Does anyone have an idea of what's going on, or how to get the behaviour
that I want -- i.e., to have a single click execute onSelect()?

I just checked all this on a Windows XP system under R 2.0.1 but have
observed the problem under Linux as well.

Thank you,
 John 

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox

From bates at stat.wisc.edu  Sat Apr  2 02:12:51 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat Apr  2 02:13:49 2005
Subject: [Rd] An exercise in the use of 'substitute'
Message-ID: <424DE383.8020101@stat.wisc.edu>

I would like to create a method for the generic function "with" applied 
to a class of fitted models.  The method should do two things:

1. Substitute the name of the first argument for '.' throughout the 
expression

2. Evaluate the modified expression using the data argument to the 
fitted model as the first element of the search list.

The second part is relatively easy.  The default method for "with" has body
   eval(substitute(expr), data, enclos = parent.frame())
and you just change this to
   eval(substitute(expr), eval(data$call$data), enclos = parent.frame())

So, for example

 > fm <- lm(optden ~ carb, Formaldehyde)
 > with.lm <- function(data, expr, ...) eval(substitute(expr), 
eval(data$call$data), enclos = parent.frame())
 > with(fm, carb)
[1] 0.1 0.3 0.5 0.6 0.7 0.9

However, I haven't been able to work out a clever way of using 
substitute to get the first part.  I would like to be able to call, e.g.

with(fm, xyplot(resid(.) ~ carb))

and get a plot of resid(fm) ~ Formaldehyde$carb

It is possible to do the first part by deparsing, substituting, and 
parsing but that's inelegant.  Can anyone suggest a more elegant method?

BTW, the example of an lm model is just for illustration.  The actual 
use I have in mind is for lme (now lmer) models.  The plot method for 
the lme class in the nlme package does something very similar to this.

From p.dalgaard at biostat.ku.dk  Sat Apr  2 02:39:09 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat Apr  2 02:39:18 2005
Subject: [Rd] An exercise in the use of 'substitute'
In-Reply-To: <424DE383.8020101@stat.wisc.edu>
References: <424DE383.8020101@stat.wisc.edu>
Message-ID: <x23bua6mhe.fsf@turmalin.kubism.ku.dk>

Douglas Bates <bates@stat.wisc.edu> writes:
[..snip..]
> However, I haven't been able to work out a clever way of using
> substitute to get the first part.  I would like to be able to call,
> e.g.
> 
> with(fm, xyplot(resid(.) ~ carb))
> 
> and get a plot of resid(fm) ~ Formaldehyde$carb
> 
> It is possible to do the first part by deparsing, substituting, and
> parsing but that's inelegant.  Can anyone suggest a more elegant
> method?

Here's part of one, I think:

> w <- function(x,y)eval(substitute(substitute(y,list(.=quote(x)))))
> w(fm, xyplot(resid(.) ~ carb))
xyplot(resid(fm) ~ carb)

(The double substitute is often needed in this type of problem. Things
would be easier if we had a version of substitute that didn't
automatically quote it's argument.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ggrothendieck at gmail.com  Sat Apr  2 03:21:48 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat Apr  2 03:22:01 2005
Subject: [Rd] An exercise in the use of 'substitute'
In-Reply-To: <424DE383.8020101@stat.wisc.edu>
References: <424DE383.8020101@stat.wisc.edu>
Message-ID: <971536df0504011721481fb5cc@mail.gmail.com>

On Apr 1, 2005 7:12 PM, Douglas Bates <bates@stat.wisc.edu> wrote:
> I would like to create a method for the generic function "with" applied
> to a class of fitted models.  The method should do two things:
> 
> 1. Substitute the name of the first argument for '.' throughout the
> expression
> 
> 2. Evaluate the modified expression using the data argument to the
> fitted model as the first element of the search list.
> 
> The second part is relatively easy.  The default method for "with" has body
>   eval(substitute(expr), data, enclos = parent.frame())
> and you just change this to
>   eval(substitute(expr), eval(data$call$data), enclos = parent.frame())
> 
> So, for example
> 
> > fm <- lm(optden ~ carb, Formaldehyde)
> > with.lm <- function(data, expr, ...) eval(substitute(expr),
> eval(data$call$data), enclos = parent.frame())
> > with(fm, carb)
> [1] 0.1 0.3 0.5 0.6 0.7 0.9
> 
> However, I haven't been able to work out a clever way of using
> substitute to get the first part.  I would like to be able to call, e.g.
> 
> with(fm, xyplot(resid(.) ~ carb))
> 
> and get a plot of resid(fm) ~ Formaldehyde$carb
> 
> It is possible to do the first part by deparsing, substituting, and
> parsing but that's inelegant.  Can anyone suggest a more elegant method?
> 
> BTW, the example of an lm model is just for illustration.  The actual
> use I have in mind is for lme (now lmer) models.  The plot method for
> the lme class in the nlme package does something very similar to this.

This seems to work, at least on your examples:

> with.lm <- function(data, expr, ...) eval(substitute(expr), 
+      append(model.frame(data), list(. = data)), parent.frame())
> 
> library(lattice)
> data(Formaldehyde)
> fm <- lm(optden ~ carb, Formaldehyde)
> with(fm, carb)
[1] 0.1 0.3 0.5 0.6 0.7 0.9
> with(fm, xyplot(resid(.) ~ carb))

From prathouz at health.bsd.uchicago.edu  Sat Apr  2 06:27:42 2005
From: prathouz at health.bsd.uchicago.edu (prathouz@health.bsd.uchicago.edu)
Date: Sat Apr  2 06:27:49 2005
Subject: [Rd] print.glm() signif digits (PR#7765)
Message-ID: <20050402042742.3D4F2C711@slim.kubism.ku.dk>

Hi -- I have found that by default the function print.glm() uses 3
significant figures when printing out null and model deviances and the
aic.  Of course, this is not wrong.  But if a person fitted two nested
models and compared the resulting deviances obtained from print.glm(), the
resulting hypothesis test could indeed be wrong because of this rounding.
The function summary() applied to a glm object gives a more precise
printout and I think that print.glm() ought to as well by default.  Thanks
much.  -- pr

==========================================================================
Paul Rathouz, Assoc. Professor       ph   773-834-1970
Dept. of Health Studies, Rm. W-264   fax  773-702-1979
University of Chicago                prathouz@health.bsd.uchicago.edu
5841 S. Maryland Ave. MC 2007
Chicago, IL  60637

From ripley at stats.ox.ac.uk  Sat Apr  2 09:40:09 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Apr  2 09:40:24 2005
Subject: [Rd] print.glm() signif digits (PR#7765)
In-Reply-To: <20050402042742.3D4F2C711@slim.kubism.ku.dk>
References: <20050402042742.3D4F2C711@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0504020828090.19252@gannet.stats>

Why did you file a bug report on something with is `not wrong' and indeed 
you can change?  How does this correspond to the definition of a `bug' in 
the FAQ?

Your analysis is in fact based on an incorrect assertion:  the default is

> args(print.glm)
function (x, digits = max(3, getOption("digits") - 3), ...)

and that defaults to 4 since getOption("digits") defaults to 7.

The correct way to compare two deviances is by the anova() function, and 
the correct way to extract them is the deviance() function.  (You seems to 
have a 1960s mindset of poring over lineprinter output from a statistical 
analysis: by the 1970s and GLIM we did not do that.)

On Sat, 2 Apr 2005 prathouz@health.bsd.uchicago.edu wrote:

> Hi -- I have found that by default the function print.glm() uses 3
> significant figures when printing out null and model deviances and the
> aic.  Of course, this is not wrong.  But if a person fitted two nested
> models and compared the resulting deviances obtained from print.glm(), the
> resulting hypothesis test could indeed be wrong because of this rounding.
> The function summary() applied to a glm object gives a more precise
> printout and I think that print.glm() ought to as well by default.  Thanks
> much.  -- pr

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From mmmm at pp.inet.fi  Sat Apr  2 12:31:55 2005
From: mmmm at pp.inet.fi (Markku Mielityinen)
Date: Sat Apr  2 12:28:05 2005
Subject: [Rd] Building new graphic device drivers with g++
Message-ID: <000001c5376f$31987620$0d01a8c0@MARKKUOLD>

Dear Group,

I'm trying to build a set of new graphic device drivers. I use the
devNull example a a beginning point:

$ R CMD SHLIB devNull.c
gcc -shared -L/usr/local/lib -o devNull.so devNull.o
(everything works OK)

$ R CMD SHLIB devNull.cpp
g++ -shared -L/usr/local/lib -o devNull.so devNull.o
(everything works OK)

The difficulties start when trying to compile manually. I compile the
library with no errors:

g++ devNull.cpp -o devNull.so -I/usr/lib/R/include -I/usr/local/include
-L/usr/local/lib -lm -lpthread -lsupc++ -lg2c -shared -fPIC -O2 -Wall
-Wunused -Wconversion -fno-exceptions -g -pipe -m32 -march=i386
-mtune=pentium4

But when I try to load the library I get:

R : Copyright 2004, The R Foundation for Statistical Computing
Version 2.0.1  (2004-11-15), ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

> dyn.load("devNull.so")
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
"/home/mmmm/R/devNull/src/devNull.so":
  /home/mmmm/R/devNull/src/devNull.so: undefined symbol:
_Z17GEinitDisplayListP10_GEDevDesc
>

I probably need to link to some "libR.a" module. But where is it? In
windows R uses -lR switch but I cannot find that library file in my
Fedora Core 3 distribution.

Is there a file that defines the compiler switches for R CMD SHLIB
compiling?

Here is an example code:

=devNull.cpp============================================================
======================

#include <R.h>
#include <Rinternals.h>
#include <Rgraphics.h>  
#include <Rdevices.h>
#include <R_ext/GraphicsDevice.h>
#include <R_ext/GraphicsEngine.h>

extern "C" {

static Rboolean nullDeviceDriver(NewDevDesc *dev);

SEXP do_devNULL() {
    NewDevDesc *dev = NULL;
    GEDevDesc *dd;

    R_CheckDeviceAvailable();
    if (!(dev = (NewDevDesc *) calloc(1, sizeof(NewDevDesc))))
        return R_NilValue;
    dev->displayList = R_NilValue;
    if (!nullDeviceDriver(dev)) {
       free(dev);
       error("unable to start NULL device");
    }
    gsetVar(install(".Device"), mkString("NULL"), R_NilValue);
    dd = GEcreateDevDesc(dev);
    Rf_addDevice((DevDesc*) dd);
    GEinitDisplayList(dd);
    return R_NilValue;
}
static void NULL_Circle(double x, double y, double r,
                        R_GE_gcontext *gc,
                        NewDevDesc *dev) {                        
    Rprintf("circle(%lf,%lf,%lf)\n", x, y, r);
}
static void NULL_Line(double x1, double y1, double x2, double y2,
                      R_GE_gcontext *gc,
                      NewDevDesc *dev) {
    Rprintf("line(%lf,%lf,%lf,%lf)\n", x1, y1, x2, y2);
}
static void NULL_Polygon(int n, double *x, double *y, 
                         R_GE_gcontext *gc,
                         NewDevDesc *dev) {
    Rprintf("polygon(%d)\n", n);
}
static void NULL_Polyline(int n, double *x, double *y, 
                          R_GE_gcontext *gc,
                          NewDevDesc *dev) {
    Rprintf("polyline(%d)\n", n);
}
static void NULL_Rect(double x0, double y0, double x1, double y1,
                      R_GE_gcontext *gc,
                      NewDevDesc *dev) {
    Rprintf("rectangle(%lf,%lf,%lf,%lf)\n", x0, y0, x1, y1);
}
static void NULL_Text(double x, double y, char *str, 
                      double rot, double hadj,
                      R_GE_gcontext *gc,
                      NewDevDesc *dev) {
    Rprintf("text(%lf,%lf,\"%s\",%lf,%lf)\n", x, y, str, rot, hadj);
}
static void NULL_NewPage(R_GE_gcontext *gc,
                         NewDevDesc *dev) {
    Rprintf("newpage\n");
}
static void NULL_Close(NewDevDesc *dev) {
    Rprintf("close\n");
}
Rboolean NULL_Open(NewDevDesc *dev) {
    Rprintf("open\n");
    return TRUE;
}
static void NULL_Activate(NewDevDesc *dev) {
    Rprintf("activate\n");
}
static void NULL_Clip(double x0, double x1, double y0, double y1, 
                      NewDevDesc *dev) {
    Rprintf("clip(%lf,%lf,%lf,%lf)\n", x0, y0, x1, y1);
}
static void NULL_Deactivate(NewDevDesc *dev) {
    Rprintf("deactivate\n");
}
static void NULL_Mode(int mode, NewDevDesc *dev) {
}
static Rboolean NULL_Locator(double *x, double *y, NewDevDesc *dev) {
    return FALSE;
}
static void NULL_MetricInfo(int c,
                            R_GE_gcontext *gc,
                            double* ascent, double* descent,
                            double* width, NewDevDesc *dev) {
    *ascent = 0.0;
    *descent = 0.0;
    *width = 0.0;
}
static void NULL_Size(double *left, double *right,
                      double *bottom, double *top,
                      NewDevDesc *dev) {
    *left = dev->left;
    *right = dev->right;
    *bottom = dev->bottom;
    *top = dev->top;
}
static double NULL_StrWidth(char *str, 
                            R_GE_gcontext *gc,
                            NewDevDesc *dev) {
    return 0.0;
}
static void NULL_dot(NewDevDesc *dev) {
}
static void NULL_Hold(NewDevDesc *dev) {
}
static Rboolean nullDeviceDriver(NewDevDesc *dev) {	 
    dev->deviceSpecific = NULL;
    /* 
     * Device functions
     */
    dev->open = (Rboolean (*)())NULL_Open;
    dev->close = (void (*)())NULL_Close;
    dev->activate = (void (*)())NULL_Activate;
    dev->deactivate = (void (*)())NULL_Deactivate;
    dev->size = (void (*)())NULL_Size;
    dev->newPage = (void (*)())NULL_NewPage;
    dev->clip = (void (*)())NULL_Clip;
    dev->strWidth = (double (*)())NULL_StrWidth;
    dev->text = (void (*)())NULL_Text;
    dev->rect = (void (*)())NULL_Rect;
    dev->circle = (void (*)())NULL_Circle;
    dev->line = (void (*)())NULL_Line;
    dev->polyline = (void (*)())NULL_Polyline;
    dev->polygon = (void (*)())NULL_Polygon;
    dev->locator = (Rboolean (*)())NULL_Locator;
    dev->mode = (void (*)())NULL_Mode;
    dev->hold = (void (*)())NULL_Hold;
    dev->metricInfo = (void (*)())NULL_MetricInfo;    
    /*
     * Initial graphical settings
     */
    dev->startfont = 1; 
    dev->startps = 10;
    dev->startcol = R_RGB(0, 0, 0);
    dev->startfill = R_TRANWHITE;
    dev->startlty = LTY_SOLID; 
    dev->startgamma = 1;
    /* 
     * Start device
     */
    if(!NULL_Open(dev)) {
        return FALSE;
    }
    /* 
     * Device physical characteristics
     */
    dev->left = 0;
    dev->right = 1000;
    dev->bottom = 0;
    dev->top = 1000;
    dev->cra[0] = 10;
    dev->cra[1] = 10;
    dev->xCharOffset = 0.4900;
    dev->yCharOffset = 0.3333;
    dev->yLineBias = 0.1;
    dev->ipr[0] = 1.0/72;
    dev->ipr[1] = 1.0/72;
    /* 
     * Device capabilities 
     */
    dev->canResizePlot= FALSE;
    dev->canChangeFont= FALSE;
    dev->canRotateText= TRUE;
    dev->canResizeText= TRUE;
    dev->canClip = TRUE; 
    dev->canHAdj = 2;
    dev->canChangeGamma = FALSE;
    dev->displayListOn = TRUE;

    dev->newDevStruct = 1;
    return TRUE;
}

}

========================================================================
======================

Best regards,
	Markku Mielityinen

From ripley at stats.ox.ac.uk  Sat Apr  2 15:16:37 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Apr  2 15:16:46 2005
Subject: [Rd] Building new graphic device drivers with g++
In-Reply-To: <000001c5376f$31987620$0d01a8c0@MARKKUOLD>
References: <000001c5376f$31987620$0d01a8c0@MARKKUOLD>
Message-ID: <Pine.LNX.4.61.0504021402140.22374@gannet.stats>

On Sat, 2 Apr 2005, Markku Mielityinen wrote:

> Dear Group,
>
> I'm trying to build a set of new graphic device drivers. I use the
> devNull example a a beginning point:
>
> $ R CMD SHLIB devNull.c
> gcc -shared -L/usr/local/lib -o devNull.so devNull.o
> (everything works OK)
>
> $ R CMD SHLIB devNull.cpp
> g++ -shared -L/usr/local/lib -o devNull.so devNull.o
> (everything works OK)

Is this the same devNull.cpp as below?  If so, I don't believe that it did 
work.

> The difficulties start when trying to compile manually. I compile the
> library with no errors:
>
> g++ devNull.cpp -o devNull.so -I/usr/lib/R/include -I/usr/local/include
> -L/usr/local/lib -lm -lpthread -lsupc++ -lg2c -shared -fPIC -O2 -Wall
> -Wunused -Wconversion -fno-exceptions -g -pipe -m32 -march=i386
> -mtune=pentium4

Where did that come from?  Why do you need the Fortran runtime linked into 
C++ code?  What has pthreads to do with this?

> But when I try to load the library I get:
>
> R : Copyright 2004, The R Foundation for Statistical Computing
> Version 2.0.1  (2004-11-15), ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
>
>> dyn.load("devNull.so")
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>        unable to load shared library
> "/home/mmmm/R/devNull/src/devNull.so":
>  /home/mmmm/R/devNull/src/devNull.so: undefined symbol:
> _Z17GEinitDisplayListP10_GEDevDesc
>>
>
> I probably need to link to some "libR.a" module.

Please don't hypothesize out of thin air.  Nothing there says anything 
about libR.a.  However, it does refer to a symbol you did not call, so you 
should have noticed that something in the name was amiss.

> But where is it? In windows R uses -lR switch but I cannot find that 
> library file in my Fedora Core 3 distribution.

You only need -lR if you built a shared-R-lib version of R, a configure 
option.  If it were needed, R SHLIB would have made use of it.

Notice the name mangling: It seems you are trying to build a C++ graphics 
device driver.  Where did you get the idea that was supported?
You seem unaware how to include C headers in C++ code, but it would be 
easier to write C as C and not as pseudo-C++.

> Is there a file that defines the compiler switches for R CMD SHLIB
> compiling?

Is there some local tuition about the differences between C and C++ you 
could obtain?


> Here is an example code:
>
> =devNull.cpp============================================================
> ======================
>
> #include <R.h>
> #include <Rinternals.h>
> #include <Rgraphics.h>
> #include <Rdevices.h>
> #include <R_ext/GraphicsDevice.h>
> #include <R_ext/GraphicsEngine.h>
>
> extern "C" {
>
> static Rboolean nullDeviceDriver(NewDevDesc *dev);
>
> SEXP do_devNULL() {
>    NewDevDesc *dev = NULL;
>    GEDevDesc *dd;
>
>    R_CheckDeviceAvailable();
>    if (!(dev = (NewDevDesc *) calloc(1, sizeof(NewDevDesc))))
>        return R_NilValue;
>    dev->displayList = R_NilValue;
>    if (!nullDeviceDriver(dev)) {
>       free(dev);
>       error("unable to start NULL device");
>    }
>    gsetVar(install(".Device"), mkString("NULL"), R_NilValue);
>    dd = GEcreateDevDesc(dev);
>    Rf_addDevice((DevDesc*) dd);
>    GEinitDisplayList(dd);
>    return R_NilValue;
> }
> static void NULL_Circle(double x, double y, double r,
>                        R_GE_gcontext *gc,
>                        NewDevDesc *dev) {
>    Rprintf("circle(%lf,%lf,%lf)\n", x, y, r);
> }
> static void NULL_Line(double x1, double y1, double x2, double y2,
>                      R_GE_gcontext *gc,
>                      NewDevDesc *dev) {
>    Rprintf("line(%lf,%lf,%lf,%lf)\n", x1, y1, x2, y2);
> }
> static void NULL_Polygon(int n, double *x, double *y,
>                         R_GE_gcontext *gc,
>                         NewDevDesc *dev) {
>    Rprintf("polygon(%d)\n", n);
> }
> static void NULL_Polyline(int n, double *x, double *y,
>                          R_GE_gcontext *gc,
>                          NewDevDesc *dev) {
>    Rprintf("polyline(%d)\n", n);
> }
> static void NULL_Rect(double x0, double y0, double x1, double y1,
>                      R_GE_gcontext *gc,
>                      NewDevDesc *dev) {
>    Rprintf("rectangle(%lf,%lf,%lf,%lf)\n", x0, y0, x1, y1);
> }
> static void NULL_Text(double x, double y, char *str,
>                      double rot, double hadj,
>                      R_GE_gcontext *gc,
>                      NewDevDesc *dev) {
>    Rprintf("text(%lf,%lf,\"%s\",%lf,%lf)\n", x, y, str, rot, hadj);
> }
> static void NULL_NewPage(R_GE_gcontext *gc,
>                         NewDevDesc *dev) {
>    Rprintf("newpage\n");
> }
> static void NULL_Close(NewDevDesc *dev) {
>    Rprintf("close\n");
> }
> Rboolean NULL_Open(NewDevDesc *dev) {
>    Rprintf("open\n");
>    return TRUE;
> }
> static void NULL_Activate(NewDevDesc *dev) {
>    Rprintf("activate\n");
> }
> static void NULL_Clip(double x0, double x1, double y0, double y1,
>                      NewDevDesc *dev) {
>    Rprintf("clip(%lf,%lf,%lf,%lf)\n", x0, y0, x1, y1);
> }
> static void NULL_Deactivate(NewDevDesc *dev) {
>    Rprintf("deactivate\n");
> }
> static void NULL_Mode(int mode, NewDevDesc *dev) {
> }
> static Rboolean NULL_Locator(double *x, double *y, NewDevDesc *dev) {
>    return FALSE;
> }
> static void NULL_MetricInfo(int c,
>                            R_GE_gcontext *gc,
>                            double* ascent, double* descent,
>                            double* width, NewDevDesc *dev) {
>    *ascent = 0.0;
>    *descent = 0.0;
>    *width = 0.0;
> }
> static void NULL_Size(double *left, double *right,
>                      double *bottom, double *top,
>                      NewDevDesc *dev) {
>    *left = dev->left;
>    *right = dev->right;
>    *bottom = dev->bottom;
>    *top = dev->top;
> }
> static double NULL_StrWidth(char *str,
>                            R_GE_gcontext *gc,
>                            NewDevDesc *dev) {
>    return 0.0;
> }
> static void NULL_dot(NewDevDesc *dev) {
> }
> static void NULL_Hold(NewDevDesc *dev) {
> }
> static Rboolean nullDeviceDriver(NewDevDesc *dev) {
>    dev->deviceSpecific = NULL;
>    /*
>     * Device functions
>     */
>    dev->open = (Rboolean (*)())NULL_Open;
>    dev->close = (void (*)())NULL_Close;
>    dev->activate = (void (*)())NULL_Activate;
>    dev->deactivate = (void (*)())NULL_Deactivate;
>    dev->size = (void (*)())NULL_Size;
>    dev->newPage = (void (*)())NULL_NewPage;
>    dev->clip = (void (*)())NULL_Clip;
>    dev->strWidth = (double (*)())NULL_StrWidth;
>    dev->text = (void (*)())NULL_Text;
>    dev->rect = (void (*)())NULL_Rect;
>    dev->circle = (void (*)())NULL_Circle;
>    dev->line = (void (*)())NULL_Line;
>    dev->polyline = (void (*)())NULL_Polyline;
>    dev->polygon = (void (*)())NULL_Polygon;
>    dev->locator = (Rboolean (*)())NULL_Locator;
>    dev->mode = (void (*)())NULL_Mode;
>    dev->hold = (void (*)())NULL_Hold;
>    dev->metricInfo = (void (*)())NULL_MetricInfo;
>    /*
>     * Initial graphical settings
>     */
>    dev->startfont = 1;
>    dev->startps = 10;
>    dev->startcol = R_RGB(0, 0, 0);
>    dev->startfill = R_TRANWHITE;
>    dev->startlty = LTY_SOLID;
>    dev->startgamma = 1;
>    /*
>     * Start device
>     */
>    if(!NULL_Open(dev)) {
>        return FALSE;
>    }
>    /*
>     * Device physical characteristics
>     */
>    dev->left = 0;
>    dev->right = 1000;
>    dev->bottom = 0;
>    dev->top = 1000;
>    dev->cra[0] = 10;
>    dev->cra[1] = 10;
>    dev->xCharOffset = 0.4900;
>    dev->yCharOffset = 0.3333;
>    dev->yLineBias = 0.1;
>    dev->ipr[0] = 1.0/72;
>    dev->ipr[1] = 1.0/72;
>    /*
>     * Device capabilities
>     */
>    dev->canResizePlot= FALSE;
>    dev->canChangeFont= FALSE;
>    dev->canRotateText= TRUE;
>    dev->canResizeText= TRUE;
>    dev->canClip = TRUE;
>    dev->canHAdj = 2;
>    dev->canChangeGamma = FALSE;
>    dev->displayListOn = TRUE;
>
>    dev->newDevStruct = 1;
>    return TRUE;
> }
>
> }
>
> ========================================================================
> ======================
>
> Best regards,
> 	Markku Mielityinen
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From teru at sodan.ecc.u-tokyo.ac.jp  Sat Apr  2 18:24:04 2005
From: teru at sodan.ecc.u-tokyo.ac.jp (teru@sodan.ecc.u-tokyo.ac.jp)
Date: Sat Apr  2 18:24:11 2005
Subject: [Rd] Solaris10/amd64 + SunSutio Compile (PR#7767)
Message-ID: <20050402162404.15C6AC74E@slim.kubism.ku.dk>

Full_Name: Teru KAMOGASHRIA
Version: 2.0.1
OS: SunOS sun 5.10 Generic i86pc i386 i86pc
Submission from: (NULL) (219.5.176.24)


rbinom.c cannot be compiled because of the casting problem.

/opt/SUNWspro/bin/cc -I. -I../../src/include -I../../src/include
-I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES  -g -c rbinom.c -o
rbinom.o
"rbinom.c", line 60: operand must have real floating type: op "isfinite"
cc: acomp failed for rbinom.c

Following patch may solve this problem.

*** R-2.0.1.orig/src/nmath/rbinom.c     Mon Nov 15 21:33:01 2004
--- R-2.0.1/src/nmath/rbinom.c  Sun Apr  3 00:19:52 2005
***************
*** 57,63 ****
      n = floor(nin + 0.5);
      if (n != nin) ML_ERR_return_NAN;

!     if (!R_FINITE(n) || !R_FINITE(pp) ||
        /* n=0, p=0, p=1 are not errors <TSL>*/
        n < 0 || pp < 0. || pp > 1.)    ML_ERR_return_NAN;

--- 57,63 ----
      n = floor(nin + 0.5);
      if (n != nin) ML_ERR_return_NAN;

!     if (!R_FINITE((double)n) || !R_FINITE(pp) ||
        /* n=0, p=0, p=1 are not errors <TSL>*/
        n < 0 || pp < 0. || pp > 1.)    ML_ERR_return_NAN;

From mmmm at pp.inet.fi  Sat Apr  2 18:40:37 2005
From: mmmm at pp.inet.fi (Markku Mielityinen)
Date: Sat Apr  2 18:36:46 2005
Subject: [Rd] Building new graphic device drivers with g++
In-Reply-To: <Pine.LNX.4.61.0504021402140.22374@gannet.stats>
Message-ID: <000001c537a2$b30fe480$0d01a8c0@MARKKUOLD>

> Is this the same devNull.cpp as below?  If so, I don't believe that it
did 
> work.

The given example devNull.cpp demonstrates the problem and thus does not
work. I have other examples that have calls to device API removed. It
seems the call to R_CheckDeviceAvailable is linked properly but calls to
GEcreateDevDesc and GEinitDisplayList are not. This must have been
confusing. Sorry...

> Where did that come from?  Why do you need the Fortran 
> runtime linked into 
> C++ code?  What has pthreads to do with this?

I like to develop code with a few additional options (such as -Wall)
that are not used with R CMD SHLIB (atleast by my system). The presented
command line is used to build the code I'm currently working on (it uses
those additional libraries). In this case those additional library
references are not needed. On the other hand they should not cause any
problems either.

> > I probably need to link to some "libR.a" module.
> 
> Please don't hypothesize out of thin air.

Good tip. If we could all just live by it... The yielded error message
is a result of a function call that cannot be dynamically linked to its
respective implementation. Usually this means you have forgotten to link
some required library. Reference to "libR.a" was not meant to specify
any particular file literally.

> You only need -lR if you built a shared-R-lib version of R, a 
> configure 
> option.  If it were needed, R SHLIB would have made use of it.

OK.

> 
> Notice the name mangling: It seems you are trying to build a 
> C++ graphics 
> device driver.

Yep.

>  Where did you get the idea that was 
> supported? 

With respect to graphic device drivers I have not seen a clear statement
one way or the other. "Writing R extensions" states that C++ can be used
for libraries. I have written a lot of C++ code that use R functions
without any problems. As far as I know it should always be possible to
call C compiled code from C++. If one can use Java to build device
drivers why not C++? Your question leads me to believe that there is
some mysterious incompatibility...

> it would be easier to write C as C and not as pseudo-C++.

True. In this case I NEED to re-use already existing C++ code. How
should I include the headers?

> Is there some local tuition about the differences between C 
> and C++ you 
> could obtain?

:(. Actually I have read quite a lot about these languages ranging from
advanced manuals to ISO/IEC 9899 and beyond. Sorry if you feel I hit a
nerve. The example I presented was a bit stupid (like examples tend to
be). Nobody uses C++ and place all code in extern "C" block.

Regards,
	Markku Mielityinen

From p.dalgaard at biostat.ku.dk  Sat Apr  2 18:40:04 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat Apr  2 18:40:14 2005
Subject: [Rd] Solaris10/amd64 + SunSutio Compile (PR#7767)
In-Reply-To: <20050402162404.15C6AC74E@slim.kubism.ku.dk>
References: <20050402162404.15C6AC74E@slim.kubism.ku.dk>
Message-ID: <x2mzshxhcr.fsf@turmalin.kubism.ku.dk>

teru@sodan.ecc.u-tokyo.ac.jp writes:

> Full_Name: Teru KAMOGASHRIA
> Version: 2.0.1
> OS: SunOS sun 5.10 Generic i86pc i386 i86pc
> Submission from: (NULL) (219.5.176.24)
> 
> 
> rbinom.c cannot be compiled because of the casting problem.
> 
> /opt/SUNWspro/bin/cc -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES  -g -c rbinom.c -o
> rbinom.o
> "rbinom.c", line 60: operand must have real floating type: op "isfinite"
> cc: acomp failed for rbinom.c
> 
> Following patch may solve this problem.
> 
> *** R-2.0.1.orig/src/nmath/rbinom.c     Mon Nov 15 21:33:01 2004
> --- R-2.0.1/src/nmath/rbinom.c  Sun Apr  3 00:19:52 2005
> ***************
> *** 57,63 ****
>       n = floor(nin + 0.5);
>       if (n != nin) ML_ERR_return_NAN;
> 
> !     if (!R_FINITE(n) || !R_FINITE(pp) ||
>         /* n=0, p=0, p=1 are not errors <TSL>*/
>         n < 0 || pp < 0. || pp > 1.)    ML_ERR_return_NAN;
> 
> --- 57,63 ----
>       n = floor(nin + 0.5);
>       if (n != nin) ML_ERR_return_NAN;
> 
> !     if (!R_FINITE((double)n) || !R_FINITE(pp) ||
>         /* n=0, p=0, p=1 are not errors <TSL>*/
>         n < 0 || pp < 0. || pp > 1.)    ML_ERR_return_NAN;

Hmm... But does it at all make sense to pass an integer to R_FINITE?
and why isn't there a prototype causing automatic casting anyway?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Sat Apr  2 19:37:54 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Apr  2 19:38:10 2005
Subject: [Rd] Solaris10/amd64 + SunSutio Compile (PR#7767)
In-Reply-To: <x2mzshxhcr.fsf@turmalin.kubism.ku.dk>
References: <20050402162404.15C6AC74E@slim.kubism.ku.dk>
	<x2mzshxhcr.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0504021821200.24678@gannet.stats>

On Sat, 2 Apr 2005, Peter Dalgaard wrote:

> teru@sodan.ecc.u-tokyo.ac.jp writes:
>
>> Full_Name: Teru KAMOGASHRIA
>> Version: 2.0.1
>> OS: SunOS sun 5.10 Generic i86pc i386 i86pc
>> Submission from: (NULL) (219.5.176.24)
>>
>>
>> rbinom.c cannot be compiled because of the casting problem.
>>
>> /opt/SUNWspro/bin/cc -I. -I../../src/include -I../../src/include
>> -I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES  -g -c rbinom.c -o
>> rbinom.o
>> "rbinom.c", line 60: operand must have real floating type: op "isfinite"
>> cc: acomp failed for rbinom.c
>>
>> Following patch may solve this problem.
>>
>> *** R-2.0.1.orig/src/nmath/rbinom.c     Mon Nov 15 21:33:01 2004
>> --- R-2.0.1/src/nmath/rbinom.c  Sun Apr  3 00:19:52 2005
>> ***************
>> *** 57,63 ****
>>       n = floor(nin + 0.5);
>>       if (n != nin) ML_ERR_return_NAN;
>>
>> !     if (!R_FINITE(n) || !R_FINITE(pp) ||
>>         /* n=0, p=0, p=1 are not errors <TSL>*/
>>         n < 0 || pp < 0. || pp > 1.)    ML_ERR_return_NAN;
>>
>> --- 57,63 ----
>>       n = floor(nin + 0.5);
>>       if (n != nin) ML_ERR_return_NAN;
>>
>> !     if (!R_FINITE((double)n) || !R_FINITE(pp) ||
>>         /* n=0, p=0, p=1 are not errors <TSL>*/
>>         n < 0 || pp < 0. || pp > 1.)    ML_ERR_return_NAN;
>
> Hmm... But does it at all make sense to pass an integer to R_FINITE?

Dunno.  It was in the original (r574 code), with finite rather than 
R_FINITE.  It would make sense to test nin (rather than n).

> and why isn't there a prototype causing automatic casting anyway?

Because isfinite is a macro.  (Solaris 10 is rather new, which is probably 
why we have not seen this before.  We received our CDs last week.)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sat Apr  2 19:38:05 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Apr  2 19:38:13 2005
Subject: [Rd] Solaris10/amd64 + SunSutio Compile (PR#7767)
Message-ID: <20050402173805.055C0C74E@slim.kubism.ku.dk>

On Sat, 2 Apr 2005, Peter Dalgaard wrote:

> teru@sodan.ecc.u-tokyo.ac.jp writes:
>
>> Full_Name: Teru KAMOGASHRIA
>> Version: 2.0.1
>> OS: SunOS sun 5.10 Generic i86pc i386 i86pc
>> Submission from: (NULL) (219.5.176.24)
>>
>>
>> rbinom.c cannot be compiled because of the casting problem.
>>
>> /opt/SUNWspro/bin/cc -I. -I../../src/include -I../../src/include
>> -I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES  -g -c rbinom.c -o
>> rbinom.o
>> "rbinom.c", line 60: operand must have real floating type: op "isfinite"
>> cc: acomp failed for rbinom.c
>>
>> Following patch may solve this problem.
>>
>> *** R-2.0.1.orig/src/nmath/rbinom.c     Mon Nov 15 21:33:01 2004
>> --- R-2.0.1/src/nmath/rbinom.c  Sun Apr  3 00:19:52 2005
>> ***************
>> *** 57,63 ****
>>       n = floor(nin + 0.5);
>>       if (n != nin) ML_ERR_return_NAN;
>>
>> !     if (!R_FINITE(n) || !R_FINITE(pp) ||
>>         /* n=0, p=0, p=1 are not errors <TSL>*/
>>         n < 0 || pp < 0. || pp > 1.)    ML_ERR_return_NAN;
>>
>> --- 57,63 ----
>>       n = floor(nin + 0.5);
>>       if (n != nin) ML_ERR_return_NAN;
>>
>> !     if (!R_FINITE((double)n) || !R_FINITE(pp) ||
>>         /* n=0, p=0, p=1 are not errors <TSL>*/
>>         n < 0 || pp < 0. || pp > 1.)    ML_ERR_return_NAN;
>
> Hmm... But does it at all make sense to pass an integer to R_FINITE?

Dunno.  It was in the original (r574 code), with finite rather than 
R_FINITE.  It would make sense to test nin (rather than n).

> and why isn't there a prototype causing automatic casting anyway?

Because isfinite is a macro.  (Solaris 10 is rather new, which is probably 
why we have not seen this before.  We received our CDs last week.)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From mmmm at pp.inet.fi  Sat Apr  2 21:19:23 2005
From: mmmm at pp.inet.fi (Markku Mielityinen)
Date: Sat Apr  2 21:15:33 2005
Subject: [Rd] Building new graphic device drivers with g++
Message-ID: <000201c537b8$e125fb00$0d01a8c0@MARKKUOLD>

OK. Found the problem.

Cheers,
	Markku Mielityinen

From charlie at stat.umn.edu  Sat Apr  2 22:29:06 2005
From: charlie at stat.umn.edu (Charles Geyer)
Date: Sat Apr  2 22:29:13 2005
Subject: [Rd] formulas and frames
In-Reply-To: <971536df05040106564f692bab@mail.gmail.com>
References: <200503051102.j25B2jec015493@hypatia.math.ethz.ch>
	<20050401073151.GA13433@stat.umn.edu>
	<971536df05040106564f692bab@mail.gmail.com>
Message-ID: <20050402202906.GC8581@stat.umn.edu>

On Fri, Apr 01, 2005 at 09:56:01AM -0500, Gabor Grothendieck wrote:
> Try this:
> 
> my.df <- data.frame(a=1:10, b=11:20, c=21:30, d=31:40)
> > model.response(model.frame(cbind(a,b) ~ c+d, my.df))
>     a  b
> 1   1 11
> 2   2 12
> 3   3 13
> 4   4 14
> 5   5 15
> 6   6 16
> 7   7 17
> 8   8 18
> 9   9 19
> 10 10 20

Well I learned something.  I didn't know that you could have a multivariate
response, but that doesn't actually address my problem.  I also have
some other variables, which I call "predecessor" variables, that also
need to go in the data frame.  The problem is basically that the R
formula language is just too limiting (unless you are of the "all statistics
is regression" school, which I am not).  In this application, I am just over
the border.  I have "response" variables, "predecessor" variables, and
"predictor" variables (all need to be vectors of the same length or matrices
with the appropriate row dimension, just the usual requirement for data
frames).

I want the user to be able to use the formula language to connect the
"predictor" variables to the linear predictor parameter in the usual
way.  But in order to get any calculations done, I need to get these
other variables -- including the "predecessor" variables, which have
no place in the R formula language (!!) -- into a data frame (if I am
going to use the reshape function on the data).

Moreover, it is not the "S way" to force the user to construct this
data frame herself.  The variables in the formula (and out of the formula)
can just be anywhere, and R is supposed to "do the right thing".

So I'm still looking for

> > ... a function that
> > just stuffs all that stuff into a data frame (model.frame would do it
> > if I didn't have this extra stuff).

-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie@stat.umn.edu

From charlie at stat.umn.edu  Sat Apr  2 22:35:20 2005
From: charlie at stat.umn.edu (Charles Geyer)
Date: Sat Apr  2 22:35:27 2005
Subject: [Rd] formulas and frames
In-Reply-To: <006c01c536cc$16bf9610$0540210a@www.domain>
References: <200503051102.j25B2jec015493@hypatia.math.ethz.ch>
	<20050401073151.GA13433@stat.umn.edu>
	<006c01c536cc$16bf9610$0540210a@www.domain>
Message-ID: <20050402203520.GD8581@stat.umn.edu>

On Fri, Apr 01, 2005 at 05:04:23PM +0200, Dimitris Rizopoulos wrote:
> if I understand well you want something like this:
> 
> y <- rnorm(100)
> p <- rnorm(100)
> x1 <- rnorm(100)
> x2 <- rnorm(100)
> x3 <- rnorm(100)
> nams <- c("y", "p", paste("x", 1:3, sep=""))
> ##############
> dat <- as.data.frame(lapply(nams, get))
> names(dat) <- nams
> dat
> 
> I hope it helps.

Yes, that's it.  Thanks.
(So ignore previous message).
-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie@stat.umn.edu

From ggrothendieck at gmail.com  Sun Apr  3 03:10:59 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun Apr  3 03:11:14 2005
Subject: [Rd] formulas and frames
In-Reply-To: <20050402203520.GD8581@stat.umn.edu>
References: <200503051102.j25B2jec015493@hypatia.math.ethz.ch>
	<20050401073151.GA13433@stat.umn.edu>
	<006c01c536cc$16bf9610$0540210a@www.domain>
	<20050402203520.GD8581@stat.umn.edu>
Message-ID: <971536df050402171059c30418@mail.gmail.com>

On Apr 2, 2005 3:35 PM, Charles Geyer <charlie@stat.umn.edu> wrote:
> On Fri, Apr 01, 2005 at 05:04:23PM +0200, Dimitris Rizopoulos wrote:
> > if I understand well you want something like this:
> >
> > y <- rnorm(100)
> > p <- rnorm(100)
> > x1 <- rnorm(100)
> > x2 <- rnorm(100)
> > x3 <- rnorm(100)
> > nams <- c("y", "p", paste("x", 1:3, sep=""))
> > ##############
> > dat <- as.data.frame(lapply(nams, get))
> > names(dat) <- nams
> > dat
> >
> > I hope it helps.
> 
> Yes, that's it.  Thanks.

With that, maybe you could use a notation like this
where the predecessor variables are after the bar:

	fo <- cbind(a, b) ~ c + I(c^2)*f | d + e

	all.vars(fo) # all variables 
	all.vars(fo[[2]]) # response variables
	all.vars(fo[[3]][[2]]) # explanatory variables
	all.vars(fo[[3]][[3]]) # predecessor variables

From charlie at stat.umn.edu  Sun Apr  3 07:50:24 2005
From: charlie at stat.umn.edu (Charles Geyer)
Date: Sun Apr  3 07:50:33 2005
Subject: [Rd] Error: cannot set length of non-vector
In-Reply-To: <200504021001.j32A1O1O003559@hypatia.math.ethz.ch>
References: <200504021001.j32A1O1O003559@hypatia.math.ethz.ch>
Message-ID: <20050403055024.GB16595@stat.umn.edu>

The subject line says it all.  How can I find what

    Error: cannot set length of non-vector

means?  RTFS is no help.  I can find out of course that
it comes from "lengthgets", but who called that?  Not me!

The situation is as follows.  I am trying to get a package
ready for CRAN.  Every time I run "R CMD check" I get this
error when building the package vignette.  But (!)
"R CMD build" has no complaints and neither does "Sweave"
when run directly on the vignette.

The whole story is in the file

    http://www.stat.umn.edu/geyer/mcmc/package/typescript

If it makes any difference

    R 2.1.0 alpha (2005-03-31)
    gcc (GCC) 3.3.3 (SuSE Linux)
    SuSE Linux 9.1 (i586)
    Linux 2.6.5-7.104-smp i686 athlon i386 GNU/Linux

The whole package is

   http://www.stat.umn.edu/geyer/mcmc/package/mcmc_0.5.tar.gz

As far as I can see there is no "debug" mode for "R CMD check"
that will tell me what it is complaining about.

Google gives me only a couple of other packages exhibiting this
error and no helpful info.

From Gregor.Gorjanc at bfro.uni-lj.si  Sun Apr  3 12:20:35 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Sun Apr  3 12:23:54 2005
Subject: [Rd] Re: F90
Message-ID: <7FFEE688B57D7346BC6241C55900E730B70049@pollux.bfro.uni-lj.si>

Hello!

I posted this question already a week ago, but didn't get any response. I 
will try again if anybody, who can answer this, wasn't reading mails
during easter holidays.

Has anyone successfully compiled F90 sources in R-package? I found the
same question on r-devel list from 2002 and I wonder if there is any
progress. I heard that g95 and gfortran can be usable. 

Thanks in advance!

--
Lep pozdrav / With regards,
    Gregor Gorjanc

------------------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

From andy_liaw at merck.com  Sun Apr  3 15:02:58 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun Apr  3 15:03:46 2005
Subject: [Rd] Re: F90
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D31@usctmx1106.merck.com>

I saw the following in a Springer catalog recently:

Developing Statistical Software in Fortran 95
Lemmon, David R., Schafer, Joseph L. 
2005, XVI, 328 p., Softcover
ISBN: 0-387-23817-4

which has the following in the description:

Through detailed examples, readers are shown how to call Fortran procedures
from packages including Excel, SAS, SPSS, S-PLUS, R, and MATLAB. They are
even given a tutorial on creating GUIs for Fortran computational code using
Visual Basic.NET. 

I believe the publication date is April 2005, so you might want to wait, or
pre-order it on the Springer web site.

Andy


> From: Gorjanc Gregor
> 
> Hello!
> 
> I posted this question already a week ago, but didn't get any 
> response. I 
> will try again if anybody, who can answer this, wasn't reading mails
> during easter holidays.
> 
> Has anyone successfully compiled F90 sources in R-package? I found the
> same question on r-devel list from 2002 and I wonder if there is any
> progress. I heard that g95 and gfortran can be usable. 
> 
> Thanks in advance!
> 
> --
> Lep pozdrav / With regards,
>     Gregor Gorjanc
> 
> --------------------------------------------------------------
> ----------
> University of Ljubljana
> Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
> Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
> Groblje 3                  tel: +386 (0)1 72 17 861
> SI-1230 Domzale            fax: +386 (0)1 72 17 888
> Slovenia
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
>

From murdoch at stats.uwo.ca  Sun Apr  3 15:13:56 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun Apr  3 15:14:03 2005
Subject: [Rd] Error: cannot set length of non-vector
In-Reply-To: <20050403055024.GB16595@stat.umn.edu>
References: <200504021001.j32A1O1O003559@hypatia.math.ethz.ch>
	<20050403055024.GB16595@stat.umn.edu>
Message-ID: <0oqv41d62slqdg1k4hpgmp1uplk2i9m6pm@4ax.com>

On Sat, 2 Apr 2005 23:50:24 -0600, Charles Geyer
<charlie@stat.umn.edu> wrote :

>The subject line says it all.  How can I find what
>
>    Error: cannot set length of non-vector
>
>means?  RTFS is no help.  I can find out of course that
>it comes from "lengthgets", but who called that?  Not me!

I think the error comes from your second chunk where you have
read.table("logit.txt", header=T).  I don't think CHECK is running in
the right directory to find the file.

Whether this is your bug or CHECK's bug, I don't know.

It certainly would be nice if CHECK errors were easier to diagnose.
I'm not sure my diagnosis is right, because I was just trying to
manually duplicate bits of the CHECK script, and I might have missed a
setwd somewhere.

Duncan Murdoch

From charlie at stat.umn.edu  Sun Apr  3 19:24:21 2005
From: charlie at stat.umn.edu (Charles Geyer)
Date: Sun Apr  3 19:24:33 2005
Subject: [Rd] Error: cannot set length of non-vector
In-Reply-To: <0oqv41d62slqdg1k4hpgmp1uplk2i9m6pm@4ax.com>
References: <200504021001.j32A1O1O003559@hypatia.math.ethz.ch>
	<20050403055024.GB16595@stat.umn.edu>
	<0oqv41d62slqdg1k4hpgmp1uplk2i9m6pm@4ax.com>
Message-ID: <20050403172421.GA22788@stat.umn.edu>

On Sun, Apr 03, 2005 at 09:13:56AM -0400, Duncan Murdoch wrote:
> On Sat, 2 Apr 2005 23:50:24 -0600, Charles Geyer
> <charlie@stat.umn.edu> wrote :
> 
> >The subject line says it all.  How can I find what
> >
> >    Error: cannot set length of non-vector
> >
> >means?  RTFS is no help.  I can find out of course that
> >it comes from "lengthgets", but who called that?  Not me!
> 
> I think the error comes from your second chunk where you have
> read.table("logit.txt", header=T).  I don't think CHECK is running in
> the right directory to find the file.
> 
> Whether this is your bug or CHECK's bug, I don't know.
> 
> It certainly would be nice if CHECK errors were easier to diagnose.
> I'm not sure my diagnosis is right, because I was just trying to
> manually duplicate bits of the CHECK script, and I might have missed a
> setwd somewhere.

No.  That's not it.  (I'm almost sure.)

I've rewritten the read.table to read from the web.  Now there are no local
reads.  Of course there are local writes to the eps and pdf files for
figures that it builds.

But even more important, despite the "error" the vignette is created just
fine (see the bottom of the new, just redone)

    http://www.stat.umn.edu/geyer/mcmc/package/typescript

No difference in the two tex files (produced by R CMD build and R CMD check)
except for timing stuff.  Furthermore

    http://www.stat.umn.edu/geyer/mcmc/package/mcmc.Rcheck/mcmc/doc/demo.pdf

looks o. k. to me.  (All the figures are there, for example).
I can't do a diff on pdf's but it seems like the error is not in
the vignette or in Sweave but in the plumbing (or in some weird interaction
of all of the above -- or in something I can't imagine).

For anyone else interested, the package (just rebuilt) is

    http://www.stat.umn.edu/geyer/mcmc/package/mcmc_0.5.tar.gz

-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie@stat.umn.edu

From edd at debian.org  Sun Apr  3 22:18:49 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun Apr  3 22:19:07 2005
Subject: [Rd] Alpha releases from Copenhagen not mirrored?
Message-ID: <16976.20393.275067.111824@basebud.nulle.part>


Looking at http://cran.r-project.org/src/base-prerelease shows that the
latest alpha tarball is dated April 1. That page reveals its source via the
various ?D=A etc sorting links, and looking at Peter's page at
www.biostat.ku.dk, I do indeed see April 2 and 3 releases in Denmark.  Has
anything dropped in Vienna?

Dirk

-- 
Better to have an approximate answer to the right question than a precise 
answer to the wrong question.  --  John Tukey as quoted by John Chambers

From edd at debian.org  Sun Apr  3 22:23:59 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun Apr  3 22:24:13 2005
Subject: [Rd] Alpha releases from Copenhagen not mirrored?
In-Reply-To: <16976.20393.275067.111824@basebud.nulle.part>
References: <16976.20393.275067.111824@basebud.nulle.part>
Message-ID: <16976.20703.541973.190883@basebud.nulle.part>


On 3 April 2005 at 15:18, Dirk Eddelbuettel wrote:
| 
| Looking at http://cran.r-project.org/src/base-prerelease shows that the
| latest alpha tarball is dated April 1. That page reveals its source via the
| various ?D=A etc sorting links, and looking at Peter's page at
| www.biostat.ku.dk, I do indeed see April 2 and 3 releases in Denmark.  Has
| anything dropped in Vienna?

I guess I could have checked before posting, but it looks like the error is
in .dk rather than in .at:

edd@chibud:~/src/debian/R> wget http://www.biostat.ku.dk/~pd/R-pre/R-alpha_2005-04-03.tar.gz
--15:22:19--  http://www.biostat.ku.dk/%7Epd/R-pre/R-alpha_2005-04-03.tar.gz
           => `R-alpha_2005-04-03.tar.gz'
Resolving www.biostat.ku.dk... 192.38.18.114
Connecting to www.biostat.ku.dk[192.38.18.114]:80... connected.
HTTP request sent, awaiting response... 403 Forbidden
15:22:20 ERROR 403: Forbidden.


Dirk

-- 
Better to have an approximate answer to the right question than a precise 
answer to the wrong question.  --  John Tukey as quoted by John Chambers

From p.dalgaard at biostat.ku.dk  Sun Apr  3 22:42:03 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun Apr  3 22:42:12 2005
Subject: [Rd] Alpha releases from Copenhagen not mirrored?
In-Reply-To: <16976.20703.541973.190883@basebud.nulle.part>
References: <16976.20393.275067.111824@basebud.nulle.part>
	<16976.20703.541973.190883@basebud.nulle.part>
Message-ID: <x2fyy7vbhg.fsf@turmalin.kubism.ku.dk>

Dirk Eddelbuettel <edd@debian.org> writes:

> On 3 April 2005 at 15:18, Dirk Eddelbuettel wrote:
> | 
> | Looking at http://cran.r-project.org/src/base-prerelease shows that the
> | latest alpha tarball is dated April 1. That page reveals its source via the
> | various ?D=A etc sorting links, and looking at Peter's page at
> | www.biostat.ku.dk, I do indeed see April 2 and 3 releases in Denmark.  Has
> | anything dropped in Vienna?
> 
> I guess I could have checked before posting, but it looks like the error is
> in .dk rather than in .at:
> 
> edd@chibud:~/src/debian/R> wget http://www.biostat.ku.dk/~pd/R-pre/R-alpha_2005-04-03.tar.gz
> --15:22:19--  http://www.biostat.ku.dk/%7Epd/R-pre/R-alpha_2005-04-03.tar.gz
>            => `R-alpha_2005-04-03.tar.gz'
> Resolving www.biostat.ku.dk... 192.38.18.114
> Connecting to www.biostat.ku.dk[192.38.18.114]:80... connected.
> HTTP request sent, awaiting response... 403 Forbidden
> 15:22:20 ERROR 403: Forbidden.

Odd... There have been various issues causing the tarball build to
fail occasionally. The Subversion database go itself wedged Saturday,
which is the usual mod of failure, but this morning it was a collision
with a temp dir in /tmp. When it happens, I run the build script by
hand, but obviously not at 5am, so the CRAN mirroring might not pick it
up.

However, permissions are also different between cron-built tarballs
and the manual ones. Looks like someone changed my umask to 0027 in a
shell startup file...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From vograno at evafunds.com  Sun Apr  3 23:39:53 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Sun Apr  3 23:40:03 2005
Subject: [Rd] Error: NAs are not allowed in subscripted assignments: change
	from R.1.9
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A58FFAC1@phost015.EVAFUNDS.intermedia.net>

Hi,

There seems to be a change in 2.0.1 in the workings of subscript
assignments with missing values.


# This is R.2.0.1

# assignment w/ missing index doesn't work when right-hand-side is a
matrix. It did work in 1.9.1
> x = matrix(1, 2, 2); x[c(1,NA),] = x
Error: NAs are not allowed in subscripted assignments
# it does work for a vector
> x = matrix(1, 2, 2); x[c(1,NA),] = 1

Is this change intentional? There seems to be nothing about it in the
release notes.

Thanks,
Vadim


> version
         _                       
platform x86_64-unknown-linux-gnu
arch     x86_64                  
os       linux-gnu               
system   x86_64, linux-gnu       
status                           
major    2                       
minor    0.1                     
year     2004                    
month    11                      
day      15                      
language R

From p.dalgaard at biostat.ku.dk  Sun Apr  3 23:49:15 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun Apr  3 23:49:23 2005
Subject: [Rd] Error: NAs are not allowed in subscripted assignments:
	change from R.1.9
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A58FFAC1@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A58FFAC1@phost015.EVAFUNDS.intermedia.net>
Message-ID: <x2br8vv8dg.fsf@turmalin.kubism.ku.dk>

"Vadim Ogranovich" <vograno@evafunds.com> writes:

> Hi,
> 
> There seems to be a change in 2.0.1 in the workings of subscript
> assignments with missing values.
> 
> 
> # This is R.2.0.1
> 
> # assignment w/ missing index doesn't work when right-hand-side is a
> matrix. It did work in 1.9.1
> > x = matrix(1, 2, 2); x[c(1,NA),] = x
> Error: NAs are not allowed in subscripted assignments
> # it does work for a vector
> > x = matrix(1, 2, 2); x[c(1,NA),] = 1
> 
> Is this change intentional? There seems to be nothing about it in the
> release notes.

Yes, and oh yes there is, for the version where it changed, in ONEWS:

    o   Subassignments involving NAs and with a replacement value of
        length > 1 are now disallowed.  (They were handled
        inconsistently in R < 2.0.0, see PR#7210.)  For data frames
        they are disallowed altogether, even for logical matrix indices
        (the only case which used to work).


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Kurt.Hornik at wu-wien.ac.at  Mon Apr  4 11:16:58 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Mon Apr  4 11:17:03 2005
Subject: [Rd] Error: cannot set length of non-vector
In-Reply-To: <20050403172421.GA22788@stat.umn.edu>
References: <200504021001.j32A1O1O003559@hypatia.math.ethz.ch>
	<20050403055024.GB16595@stat.umn.edu>
	<0oqv41d62slqdg1k4hpgmp1uplk2i9m6pm@4ax.com>
	<20050403172421.GA22788@stat.umn.edu>
Message-ID: <16977.1546.138642.712005@mithrandir.hornik.net>

>>>>> Charles Geyer writes:

> On Sun, Apr 03, 2005 at 09:13:56AM -0400, Duncan Murdoch wrote:
>> On Sat, 2 Apr 2005 23:50:24 -0600, Charles Geyer
>> <charlie@stat.umn.edu> wrote :
>> 
>> >The subject line says it all.  How can I find what
>> >
>> >    Error: cannot set length of non-vector
>> >
>> >means?  RTFS is no help.  I can find out of course that
>> >it comes from "lengthgets", but who called that?  Not me!
>> 
>> I think the error comes from your second chunk where you have
>> read.table("logit.txt", header=T).  I don't think CHECK is running in
>> the right directory to find the file.
>> 
>> Whether this is your bug or CHECK's bug, I don't know.
>> 
>> It certainly would be nice if CHECK errors were easier to diagnose.
>> I'm not sure my diagnosis is right, because I was just trying to
>> manually duplicate bits of the CHECK script, and I might have missed a
>> setwd somewhere.

> No.  That's not it.  (I'm almost sure.)

> I've rewritten the read.table to read from the web.  Now there are no local
> reads.  Of course there are local writes to the eps and pdf files for
> figures that it builds.

> But even more important, despite the "error" the vignette is created just
> fine (see the bottom of the new, just redone)

>     http://www.stat.umn.edu/geyer/mcmc/package/typescript

> No difference in the two tex files (produced by R CMD build and R CMD check)
> except for timing stuff.  Furthermore

>     http://www.stat.umn.edu/geyer/mcmc/package/mcmc.Rcheck/mcmc/doc/demo.pdf

> looks o. k. to me.  (All the figures are there, for example).
> I can't do a diff on pdf's but it seems like the error is not in
> the vignette or in Sweave but in the plumbing (or in some weird interaction
> of all of the above -- or in something I can't imagine).

> For anyone else interested, the package (just rebuilt) is

>     http://www.stat.umn.edu/geyer/mcmc/package/mcmc_0.5.tar.gz

After playing with this some time ...

I get the same error when I run R CMD check from the command line.
I do not get the error when I use Stangle() to create demo.R and run
this either interactively, or via R CMD BATCH using --vanilla, or not.

The error comes from

SEXP lengthgets(SEXP x, R_len_t len)
{
    R_len_t lenx, i;
    SEXP rval, names, xnames, t;
    if (!isVector(x) && !isVectorizable(x))
	error(_("cannot set length of non-vector"));

in src/main/builtin.c.  I see no way to globally turn on dumping call
stack info at the C level to actually see where in the code the error
triggers.  If I add debugging info prior to the error call, the error is
gone.

Btw, if I comment *output* redirection in tools::checkVignettes(), the
error is gone as well.

Note that this is *NOT* an error thrown by R CMD check.  The failure
occurs when checkVignettes() is running the code (via source()) of the
.R files created via Stangle(), and all the info we have about the error
is being passed on.

-k

From p.dalgaard at biostat.ku.dk  Mon Apr  4 13:23:28 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Apr  4 13:23:37 2005
Subject: [Rd] Error: cannot set length of non-vector
In-Reply-To: <16977.1546.138642.712005@mithrandir.hornik.net>
References: <200504021001.j32A1O1O003559@hypatia.math.ethz.ch>
	<20050403055024.GB16595@stat.umn.edu>
	<0oqv41d62slqdg1k4hpgmp1uplk2i9m6pm@4ax.com>
	<20050403172421.GA22788@stat.umn.edu>
	<16977.1546.138642.712005@mithrandir.hornik.net>
Message-ID: <x2wtri7plb.fsf@turmalin.kubism.ku.dk>

Kurt Hornik <Kurt.Hornik@wu-wien.ac.at> writes:

> stack info at the C level to actually see where in the code the error
> triggers.  If I add debugging info prior to the error call, the error is
> gone.
> 
> Btw, if I comment *output* redirection in tools::checkVignettes(), the
> error is gone as well.
> 
> Note that this is *NOT* an error thrown by R CMD check.  The failure
> occurs when checkVignettes() is running the code (via source()) of the
> .R files created via Stangle(), and all the info we have about the error
> is being passed on.

Aha, so *that's* how to reproduce it. 

One thing that catches my eye is that 
tools::checkVignettes has

    outConn <- textConnection("out", "w")
    sink(outConn, type = "output")
    sink(outConn, type = "message")
....
           for (f in rfiles) {
            yy <- try(source(f))

and demo.R does extensive manipulation of an object called "out".

Perhaps it helps to do something like local(source(f, local=TRUE))? Or
maybe put local=TRUE in the textConnection() call.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Kurt.Hornik at wu-wien.ac.at  Mon Apr  4 13:36:14 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Mon Apr  4 13:36:23 2005
Subject: [Rd] Error: cannot set length of non-vector
In-Reply-To: <x2wtri7plb.fsf@turmalin.kubism.ku.dk>
References: <200504021001.j32A1O1O003559@hypatia.math.ethz.ch>
	<20050403055024.GB16595@stat.umn.edu>
	<0oqv41d62slqdg1k4hpgmp1uplk2i9m6pm@4ax.com>
	<20050403172421.GA22788@stat.umn.edu>
	<16977.1546.138642.712005@mithrandir.hornik.net>
	<x2wtri7plb.fsf@turmalin.kubism.ku.dk>
Message-ID: <16977.9902.875712.722704@mithrandir.hornik.net>

>>>>> Peter Dalgaard writes:

> Kurt Hornik <Kurt.Hornik@wu-wien.ac.at> writes:
>> stack info at the C level to actually see where in the code the error
>> triggers.  If I add debugging info prior to the error call, the error is
>> gone.
>> 
>> Btw, if I comment *output* redirection in tools::checkVignettes(), the
>> error is gone as well.
>> 
>> Note that this is *NOT* an error thrown by R CMD check.  The failure
>> occurs when checkVignettes() is running the code (via source()) of the
>> .R files created via Stangle(), and all the info we have about the error
>> is being passed on.

> Aha, so *that's* how to reproduce it. 

> One thing that catches my eye is that 
> tools::checkVignettes has

>     outConn <- textConnection("out", "w")
>     sink(outConn, type = "output")
>     sink(outConn, type = "message")
> ....
>            for (f in rfiles) {
>             yy <- try(source(f))

> and demo.R does extensive manipulation of an object called "out".

> Perhaps it helps to do something like local(source(f, local=TRUE))? Or
> maybe put local=TRUE in the textConnection() call.

Or maybe
	
	textConnection("out", "w", local = TRUE)

as done in similar places ...

Will try.

-k

From davidhughjones at gmail.com  Mon Apr  4 17:15:29 2005
From: davidhughjones at gmail.com (davidhughjones@gmail.com)
Date: Mon Apr  4 17:15:37 2005
Subject: [Rd] acf segfault (PR#7771)
Message-ID: <20050404151529.10EE6C752@slim.kubism.ku.dk>

Test case:
z <- ts(matrix(rnorm(200),10,20), start=c(1961,1))
acf(z,lag.max=1)

This segfaults for me. Maybe it shouldn't?
cheers
dave

--please do not edit the information below--

Version:
 platform = i386-pc-linux-gnu
 arch = i386
 os = linux-gnu
 system = i386, linux-gnu
 status =
 major = 2
 minor = 0.1
 year = 2004
 month = 11
 day = 15
 language = R

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics,
+package:grDevices, package:utils, package:datasets, Autoloads, package:base

From msa at biostat.mgh.harvard.edu  Mon Apr  4 18:01:05 2005
From: msa at biostat.mgh.harvard.edu (msa@biostat.mgh.harvard.edu)
Date: Mon Apr  4 18:01:13 2005
Subject: [Rd] Problems with predict.lm: incorrect SE estimate (PR#7772)
Message-ID: <20050404160105.969CCC9E9@slim.kubism.ku.dk>

Full_Name: Marek Ancukiewicz
Version: 2.01
OS: Linux
Submission from: (NULL) (132.183.12.87)


It seems that the the standard error of prediction of the linear regression,
caclulated with predict.lm is incorrect. Consider the following example where
the standard error is first calculated with predict.lm, then using delta
method. and finally, using the formula rms*sqrt(1+1/n+(xp-x0)^2/Sxx). 

Marek Ancukiewicz

> n <- 10
> x <- 1:n
> y <- x
> y[c(2,4,6)] <- y[c(2,4,6)] + 0.1
> y[c(3,5,7)] <- y[c(3,5,7)] - 0.1
> a <- lm(y~x)
> rms <- sqrt(sum(a$residuals^2)/(n-2))
> s <- covmat(a)*rms^2
> xp <- 3
> xm <- mean(x)
> summary(a)

Call:
lm(formula = y ~ x)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.10909 -0.07500  0.01091  0.06955  0.10182 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 0.020000   0.058621   0.341    0.742    
x           0.996364   0.009448 105.463  7.3e-14 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Residual standard error: 0.08581 on 8 degrees of freedom
Multiple R-Squared: 0.9993,     Adjusted R-squared: 0.9992 
F-statistic: 1.112e+04 on 1 and 8 DF,  p-value: 7.3e-14 

> print(predict(a,new=data.frame(x=xp),se.fit=T))
$fit
[1] 3.009091

$se.fit
[1] 0.0359752

$df
[1] 8

$residual.scale
[1] 0.08581163

> print(se.delta.method <- sqrt(s[1,1]+xp^2*s[2,2]+2*xp*s[1,2] + rms^2))
[1] 0.09304758
> print(se.ss.formula <- rms*sqrt(1+1/n+(xp-xm)^2/sum((x-xm)^2)))
[1] 0.09304758

From murdoch at stats.uwo.ca  Mon Apr  4 18:19:41 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Mon Apr  4 18:19:49 2005
Subject: [Rd] Problems with predict.lm: incorrect SE estimate (PR#7772)
Message-ID: <20050404161941.75307C9E4@slim.kubism.ku.dk>

On Mon,  4 Apr 2005 18:01:05 +0200 (CEST), msa@biostat.mgh.harvard.edu
wrote :

>Full_Name: Marek Ancukiewicz
>Version: 2.01
>OS: Linux
>Submission from: (NULL) (132.183.12.87)
>
>
>It seems that the the standard error of prediction of the linear regression,
>caclulated with predict.lm is incorrect. Consider the following example where
>the standard error is first calculated with predict.lm, then using delta
>method. and finally, using the formula rms*sqrt(1+1/n+(xp-x0)^2/Sxx). 

Your formula is incorrect.  You've got the formula for the so called
"prediction error" (i.e. the stddev of the difference between the
prediction and a new observation) rather than the "standard error"
(i.e. the stddev of the prediction).

Duncan Murdoch
>
>Marek Ancukiewicz
>
>> n <- 10
>> x <- 1:n
>> y <- x
>> y[c(2,4,6)] <- y[c(2,4,6)] + 0.1
>> y[c(3,5,7)] <- y[c(3,5,7)] - 0.1
>> a <- lm(y~x)
>> rms <- sqrt(sum(a$residuals^2)/(n-2))
>> s <- covmat(a)*rms^2
>> xp <- 3
>> xm <- mean(x)
>> summary(a)
>
>Call:
>lm(formula = y ~ x)
>
>Residuals:
>     Min       1Q   Median       3Q      Max 
>-0.10909 -0.07500  0.01091  0.06955  0.10182 
>
>Coefficients:
>            Estimate Std. Error t value Pr(>|t|)    
>(Intercept) 0.020000   0.058621   0.341    0.742    
>x           0.996364   0.009448 105.463  7.3e-14 ***
>---
>Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
>
>Residual standard error: 0.08581 on 8 degrees of freedom
>Multiple R-Squared: 0.9993,     Adjusted R-squared: 0.9992 
>F-statistic: 1.112e+04 on 1 and 8 DF,  p-value: 7.3e-14 
>
>> print(predict(a,new=data.frame(x=xp),se.fit=T))
>$fit
>[1] 3.009091
>
>$se.fit
>[1] 0.0359752
>
>$df
>[1] 8
>
>$residual.scale
>[1] 0.08581163
>
>> print(se.delta.method <- sqrt(s[1,1]+xp^2*s[2,2]+2*xp*s[1,2] + rms^2))
>[1] 0.09304758
>> print(se.ss.formula <- rms*sqrt(1+1/n+(xp-xm)^2/sum((x-xm)^2)))
>[1] 0.09304758
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel

From murdoch at stats.uwo.ca  Mon Apr  4 18:21:32 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Mon Apr  4 18:21:40 2005
Subject: [Rd] acf segfault (PR#7771)
Message-ID: <20050404162132.0796AC9E9@slim.kubism.ku.dk>

On Mon,  4 Apr 2005 17:15:29 +0200 (CEST), davidhughjones@gmail.com
wrote :

>Test case:
>z <- ts(matrix(rnorm(200),10,20), start=c(1961,1))
>acf(z,lag.max=1)
>
>This segfaults for me. Maybe it shouldn't?

Not for me in a recent alpha build on Windows.  Could you try it in
the latest R-alpha from CRAN?

Duncan Murdoch

>cheers
>dave
>
>--please do not edit the information below--
>
>Version:
> platform = i386-pc-linux-gnu
> arch = i386
> os = linux-gnu
> system = i386, linux-gnu
> status =
> major = 2
> minor = 0.1
> year = 2004
> month = 11
> day = 15
> language = R
>
>Search Path:
> .GlobalEnv, package:methods, package:stats, package:graphics,
>+package:grDevices, package:utils, package:datasets, Autoloads, package:base
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Mon Apr  4 18:47:26 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Apr  4 18:47:35 2005
Subject: [Rd] acf segfault (PR#7771)
Message-ID: <20050404164726.BB23AC9E4@slim.kubism.ku.dk>

On Mon, 4 Apr 2005 murdoch@stats.uwo.ca wrote:

> On Mon,  4 Apr 2005 17:15:29 +0200 (CEST), davidhughjones@gmail.com
> wrote :
>
>> Test case:
>> z <- ts(matrix(rnorm(200),10,20), start=c(1961,1))
>> acf(z,lag.max=1)
>>
>> This segfaults for me. Maybe it shouldn't?
>
> Not for me in a recent alpha build on Windows.  Could you try it in
> the latest R-alpha from CRAN?

Not for me in R-alpha nor R-2.0.1 on i686 or x86_64 Fedora Core 3.

What device was this (presumably X11)?  Looks like a problem with the 
exact OS or hardware in use: if it is reproducible, please provide a gdb 
backtrace.

>> --please do not edit the information below--
>>
>> Version:
>> platform = i386-pc-linux-gnu
>> arch = i386
>> os = linux-gnu
>> system = i386, linux-gnu
>> status =
>> major = 2
>> minor = 0.1
>> year = 2004
>> month = 11
>> day = 15
>> language = R

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Mon Apr  4 18:51:52 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Apr  4 18:52:01 2005
Subject: [Rd] Problems with predict.lm: incorrect SE estimate (PR#7772)
In-Reply-To: <20050404161941.75307C9E4@slim.kubism.ku.dk>
References: <20050404161941.75307C9E4@slim.kubism.ku.dk>
Message-ID: <x24qema3iv.fsf@turmalin.kubism.ku.dk>

murdoch@stats.uwo.ca writes:

> On Mon,  4 Apr 2005 18:01:05 +0200 (CEST), msa@biostat.mgh.harvard.edu
> wrote :
> 
> >Full_Name: Marek Ancukiewicz
> >Version: 2.01
> >OS: Linux
> >Submission from: (NULL) (132.183.12.87)
> >
> >
> >It seems that the the standard error of prediction of the linear regression,
> >caclulated with predict.lm is incorrect. Consider the following example where
> >the standard error is first calculated with predict.lm, then using delta
> >method. and finally, using the formula rms*sqrt(1+1/n+(xp-x0)^2/Sxx). 
> 
> Your formula is incorrect.  You've got the formula for the so called
> "prediction error" (i.e. the stddev of the difference between the
> prediction and a new observation) rather than the "standard error"
> (i.e. the stddev of the prediction).

And:

>  print(predict(a,new=data.frame(x=xp),interval="pred"))
          fit      lwr      upr
[1,] 3.009091 2.794523 3.223659
>  3.009091  + qt(.975,8)*0.09304758
[1] 3.223659
>  3.009091  - qt(.975,8)*0.09304758
[1] 2.794523

so reading the help page might have given a clue that the authors knew
what they were doing....

The help page text could be improved, though. Will do.

> >$fit
> >[1] 3.009091
> >
> >$se.fit
> >[1] 0.0359752
> >
> >$df
> >[1] 8
> >
> >$residual.scale
> >[1] 0.08581163
> >
> >> print(se.delta.method <- sqrt(s[1,1]+xp^2*s[2,2]+2*xp*s[1,2] + rms^2))
> >[1] 0.09304758
> >> print(se.ss.formula <- rms*sqrt(1+1/n+(xp-xm)^2/sum((x-xm)^2)))
> >[1] 0.09304758

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From msa at biostat.mgh.harvard.edu  Mon Apr  4 19:07:17 2005
From: msa at biostat.mgh.harvard.edu (msa@biostat.mgh.harvard.edu)
Date: Mon Apr  4 19:07:26 2005
Subject: [Rd] Problems with predict.lm: incorrect SE estimate (PR#7772)
Message-ID: <20050404170717.9A24BC9E4@slim.kubism.ku.dk>


Thanks!

I did not realize that predict.lm calculates the standard
error of the prediction (which goes asumptotically to zero)
rather then prediction error.

The formula for standard erro should omits leding 1 under
square root and with delta method, one should omit rms^2
component. Then everything agrees nicely with predict.lm
output.

Sorry about bothering, I did not get a good hit this time.

Marek Ancukiewicz

> From: Duncan Murdoch <murdoch@stats.uwo.ca>
> Cc: R-bugs@biostat.ku.dk
> Date: Mon, 04 Apr 2005 12:19:32 -0400
> 
> On Mon,  4 Apr 2005 18:01:05 +0200 (CEST), msa@biostat.mgh.harvard.edu
> wrote :
> 
> >Full_Name: Marek Ancukiewicz
> >Version: 2.01
> >OS: Linux
> >Submission from: (NULL) (132.183.12.87)
> >
> >
> >It seems that the the standard error of prediction of the linear regression,
> >caclulated with predict.lm is incorrect. Consider the following example where
> >the standard error is first calculated with predict.lm, then using delta
> >method. and finally, using the formula rms*sqrt(1+1/n+(xp-x0)^2/Sxx). 
> 
> Your formula is incorrect.  You've got the formula for the so called
> "prediction error" (i.e. the stddev of the difference between the
> prediction and a new observation) rather than the "standard error"
> (i.e. the stddev of the prediction).
> 
> Duncan Murdoch
> >
> >Marek Ancukiewicz
> >
> >> n <- 10
> >> x <- 1:n
> >> y <- x
> >> y[c(2,4,6)] <- y[c(2,4,6)] + 0.1
> >> y[c(3,5,7)] <- y[c(3,5,7)] - 0.1
> >> a <- lm(y~x)
> >> rms <- sqrt(sum(a$residuals^2)/(n-2))
> >> s <- covmat(a)*rms^2
> >> xp <- 3
> >> xm <- mean(x)
> >> summary(a)
> >
> >Call:
> >lm(formula = y ~ x)
> >
> >Residuals:
> >     Min       1Q   Median       3Q      Max 
> >-0.10909 -0.07500  0.01091  0.06955  0.10182 
> >
> >Coefficients:
> >            Estimate Std. Error t value Pr(>|t|)    
> >(Intercept) 0.020000   0.058621   0.341    0.742    
> >x           0.996364   0.009448 105.463  7.3e-14 ***
> >---
> >Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> >
> >Residual standard error: 0.08581 on 8 degrees of freedom
> >Multiple R-Squared: 0.9993,     Adjusted R-squared: 0.9992 
> >F-statistic: 1.112e+04 on 1 and 8 DF,  p-value: 7.3e-14 
> >
> >> print(predict(a,new=data.frame(x=xp),se.fit=T))
> >$fit
> >[1] 3.009091
> >
> >$se.fit
> >[1] 0.0359752
> >
> >$df
> >[1] 8
> >
> >$residual.scale
> >[1] 0.08581163
> >
> >> print(se.delta.method <- sqrt(s[1,1]+xp^2*s[2,2]+2*xp*s[1,2] + rms^2))
> >[1] 0.09304758
> >> print(se.ss.formula <- rms*sqrt(1+1/n+(xp-xm)^2/sum((x-xm)^2)))
> >[1] 0.09304758
> >
> >______________________________________________
> >R-devel@stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-devel
>

From kjetil at acelerate.com  Mon Apr  4 18:27:33 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Mon Apr  4 20:43:43 2005
Subject: [Rd] intentional changes in rw2010alpha?
Message-ID: <42516AF5.90000@acelerate.com>

Is this changes intentional?

Now

Rcmd INSTALL --build --clean myPkg

builds the tar.gz, and only then cleans. Also, files left by xemacs like
myfile~ are now included in the tar.gz. I think this were excluded before?

Intentional?

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
Internal Virus Database is out-of-date.
Checked by AVG Anti-Virus.

From Kurt.Hornik at wu-wien.ac.at  Mon Apr  4 22:07:09 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Mon Apr  4 22:07:26 2005
Subject: [Rd] Error: cannot set length of non-vector
In-Reply-To: <16977.9902.875712.722704@mithrandir.hornik.net>
References: <200504021001.j32A1O1O003559@hypatia.math.ethz.ch>
	<20050403055024.GB16595@stat.umn.edu>
	<0oqv41d62slqdg1k4hpgmp1uplk2i9m6pm@4ax.com>
	<20050403172421.GA22788@stat.umn.edu>
	<16977.1546.138642.712005@mithrandir.hornik.net>
	<x2wtri7plb.fsf@turmalin.kubism.ku.dk>
	<16977.9902.875712.722704@mithrandir.hornik.net>
Message-ID: <16977.40557.280814.142897@mithrandir.hornik.net>

>>>>> Kurt Hornik writes:

>>>>> Peter Dalgaard writes:
>> Kurt Hornik <Kurt.Hornik@wu-wien.ac.at> writes:
>>> stack info at the C level to actually see where in the code the error
>>> triggers.  If I add debugging info prior to the error call, the error is
>>> gone.
>>> 
>>> Btw, if I comment *output* redirection in tools::checkVignettes(), the
>>> error is gone as well.
>>> 
>>> Note that this is *NOT* an error thrown by R CMD check.  The failure
>>> occurs when checkVignettes() is running the code (via source()) of the
>>> .R files created via Stangle(), and all the info we have about the error
>>> is being passed on.

>> Aha, so *that's* how to reproduce it. 

>> One thing that catches my eye is that 
>> tools::checkVignettes has

>> outConn <- textConnection("out", "w")
>> sink(outConn, type = "output")
>> sink(outConn, type = "message")
>> ....
>> for (f in rfiles) {
>> yy <- try(source(f))

>> and demo.R does extensive manipulation of an object called "out".

>> Perhaps it helps to do something like local(source(f, local=TRUE))? Or
>> maybe put local=TRUE in the textConnection() call.

> Or maybe
	
> 	textConnection("out", "w", local = TRUE)

> as done in similar places ...

[As you had already written.]

Or maybe use an anonymous tempfile.

Works for me, committed now.

-k

From murdoch at stats.uwo.ca  Mon Apr  4 22:19:28 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Mon Apr  4 22:19:35 2005
Subject: [Rd] acf segfault (PR#7771)
Message-ID: <20050404201928.6B689CA69@slim.kubism.ku.dk>

David emailed me his dataset, and I get a segfault crash with it.
This happens in an R memory allocation routine after the C function
acf() in src/library/stats/src/filter.c has returned, so it looks to
me as though acf() is writing somewhere it shouldn't.

I'll try to track it down...

Duncan Murdoch

From charlie at stat.umn.edu  Mon Apr  4 22:56:03 2005
From: charlie at stat.umn.edu (Charles Geyer)
Date: Mon Apr  4 22:56:11 2005
Subject: [Rd] Error: cannot set length of non-vector
In-Reply-To: <608caeb917b5cfdd7e8b6c775d8dba1d@fhcrc.org>
References: <200504021001.j32A1O1O003559@hypatia.math.ethz.ch>
	<20050403055024.GB16595@stat.umn.edu>
	<0oqv41d62slqdg1k4hpgmp1uplk2i9m6pm@4ax.com>
	<20050403172421.GA22788@stat.umn.edu>
	<e9fc1917548120d30bbd939f732a8a62@fhcrc.org>
	<20050404024809.GA24866@stat.umn.edu>
	<608caeb917b5cfdd7e8b6c775d8dba1d@fhcrc.org>
Message-ID: <20050404205603.GB27105@stat.umn.edu>

On Mon, Apr 04, 2005 at 07:58:59AM -0700, Robert Gentleman wrote:
> Well, then what most of us, that really want to figure it out do is:
> 1) look at the check script and find the actual invocation of Sweave
>   (try running checkVignettes from the prompt, try running R with  
> --quiet, etc.
> 
>   It looks very much like a memory protection bug, either in R or in  
> your code (do you have C/Fortran) and if so, you might try running with  
> -d valgrind (now you do not want to do that on a tiny little computer  
> as valgrind sucks up a lot of time).

No, I've already done that too.

   R CMD check --use-valgrind mcmc

gives no errors from valgrind.  BTW, this is really ultra hyper cool!!!!!!!
Thanks to whoever is responsible.
-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie@stat.umn.edu

From murdoch at stats.uwo.ca  Mon Apr  4 22:58:34 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon Apr  4 23:02:10 2005
Subject: [Rd] acf segfault (PR#7771)
In-Reply-To: <20050404151529.10EE6C752@slim.kubism.ku.dk>
References: <20050404151529.10EE6C752@slim.kubism.ku.dk>
Message-ID: <vt9351pq1jndn3psnejeme9s4uipdqjgcv@4ax.com>

On Mon,  4 Apr 2005 17:15:29 +0200 (CEST), davidhughjones@gmail.com
wrote :

>Test case:
>z <- ts(matrix(rnorm(200),10,20), start=c(1961,1))
>acf(z,lag.max=1)
>
>This segfaults for me. Maybe it shouldn't?

This was a bug in the memory allocation in the C code, now fixed.
I've committed the fix to the beta and to the 2.0.1 patch version.

Duncan Murdoch

From romain at berkeley.edu  Tue Apr  5 01:34:14 2005
From: romain at berkeley.edu (Romain Neugebauer)
Date: Tue Apr  5 01:34:26 2005
Subject: [Rd] Calling an MPI-based C program in R 
Message-ID: <001a01c5396e$d008f180$1701a8c0@RNlaptop>

Hello,
 
I currently work on the development of an R package where most of the
algorithm is implemented in C.
I would like to use MPI to improve the speed of the C routines when used
in a distributed computing environment. I am very new to MPI.
 
>From what I found in the R archive and online, I came to the conclusion
that packages like Rmpi provide an interface to MPI so that R users can
use capabilities of distributed computing at the R level. 
However, I would like to use the capabilities of MPI at the C level and
use R as the interface to the C routine.
 
Could anyone tell me if it is possible in the latest version of R to
call a C program which itself relies on calls to the MPI library? If it
is, could you please refer me to some documentation?
 
Thank you.
 
Romain
 

	[[alternative HTML version deleted]]

From ripley at stats.ox.ac.uk  Tue Apr  5 10:23:13 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Apr  5 10:23:24 2005
Subject: [Rd] intentional changes in rw2010alpha?
In-Reply-To: <42516AF5.90000@acelerate.com>
References: <42516AF5.90000@acelerate.com>
Message-ID: <Pine.LNX.4.61.0504050911250.16251@gannet.stats>

On Mon, 4 Apr 2005, Kjetil Brinchmann Halvorsen wrote:

> Is this changes intentional?

The description of what happened (and still happens) is wrong ....

> Now
>
> Rcmd INSTALL --build --clean myPkg
>
> builds the tar.gz, and only then cleans. Also, files left by xemacs like
> myfile~ are now included in the tar.gz. I think this were excluded before?
>
> Intentional?

Rcmd INSTALL --build  does not build a .tar.gz, but a .zip!

I think you are confusing it with Rcmd build.  The documented process is

1) Use R CMD build to build myPkg_ver.tar.gz, the source package.
2) Use R CMD INSTALL --build myPkg_ver.tar.gz to build myPkg_ver.zip, the 
binary package for distribution.

The --clean you are using refers to cleaning e.g. src/*.a after the 
install, not to cleaning the sources.  That has not changed:
Rcmd INSTALL --help says

   -c, --clean           remove all files created during installation
                                                  ^^^^^^^^^^^^^^^^^^^


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Kurt.Hornik at wu-wien.ac.at  Tue Apr  5 12:51:13 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Tue Apr  5 12:51:13 2005
Subject: [Rd] R-alpha_2005-03-31: make check fails on Debian 3.0
In-Reply-To: <m03bubhp7n.fsf@bar.nemo-project.org>
References: <m03bubhp7n.fsf@bar.nemo-project.org>
Message-ID: <16978.28065.3489.148481@mithrandir.hornik.net>

>>>>> Bj?rn-Helge Mevik writes:

> I've just tested R-alpha_2005-03-31.tar.gz.  ./configure and make
> ran without any apparent errors, but make check failed:

> 58 (0) $ make check 2>&1 | tee make_check-logg
> make[1]: Entering directory `/usr/local/src/R/R-alpha/tests'
> make[2]: Entering directory `/usr/local/src/R/R-alpha/tests'
> make[3]: Entering directory `/usr/local/src/R/R-alpha/tests/Examples'
> make[4]: Entering directory `/usr/local/src/R/R-alpha/tests/Examples'
> make[4]: Leaving directory `/usr/local/src/R/R-alpha/tests/Examples'
> make[4]: Entering directory `/usr/local/src/R/R-alpha/tests/Examples'
> collecting examples for package 'base' ...
> make[5]: Entering directory `/usr/local/src/R/R-alpha/src/library'
>>>> Building/Updating help pages for package 'base'
>      Formats: text html latex example 
> make[5]: Leaving directory `/usr/local/src/R/R-alpha/src/library'
> running code in 'base-Ex.R' ... OK
> collecting examples for package 'tools' ...
> make[5]: Entering directory `/usr/local/src/R/R-alpha/src/library'
>>>> Building/Updating help pages for package 'tools'
>      Formats: text html latex example 
> make[5]: Leaving directory `/usr/local/src/R/R-alpha/src/library'
> running code in 'tools-Ex.R' ... OK
> collecting examples for package 'utils' ...
> make[5]: Entering directory `/usr/local/src/R/R-alpha/src/library'
>>>> Building/Updating help pages for package 'utils'
>      Formats: text html latex example 
> make[5]: Leaving directory `/usr/local/src/R/R-alpha/src/library'
> running code in 'utils-Ex.R' ...make[4]: *** [utils-Ex.Rout] Error 1
> make[4]: Leaving directory `/usr/local/src/R/R-alpha/tests/Examples'
> make[3]: *** [test-Examples-Base] Error 2
> make[3]: Leaving directory `/usr/local/src/R/R-alpha/tests/Examples'
> make[2]: *** [test-Examples] Error 2
> make[2]: Leaving directory `/usr/local/src/R/R-alpha/tests'
> make[1]: *** [test-all-basics] Error 1
> make[1]: Leaving directory `/usr/local/src/R/R-alpha/tests'
> make: *** [check] Error 2
> 59 (0) $ 


> The final part of tests/Examples/utils-Ex.Rout.fail reads

>> cleanEx(); ..nameEx <- "help.search"
>> 
>> ### * help.search
>> 
>> flush(stderr()); flush(stdout())
>> 
>> ### Name: help.search
>> ### Title: Search the Help System
>> ### Aliases: help.search print.hsearch
>> ### Keywords: documentation
>> 
>> ### ** Examples
>> 
>> help.search("linear models")    # In case you forgot how to fit linear
> Error in iconv(db[[i]][ind, ], enc, "") : 'iconv' is not available on this system
> Execution halted

Can you try again with a current (SVN) version of r-devel?

Best
-k

> The parts of the output fron ./configure that meantion "iconv" is

> checking iconv.h usability... yes
> checking iconv.h presence... yes
> checking for iconv.h... yes
> checking for iconv... yes
> checking whether iconv() accepts "UTF-8" and "latin1"... no
> checking for iconvlist... no
> [...]
> checking for iconv... yes
> checking for iconv declaration... 
>          extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);

> The only warnings I got was

> checking whether makeinfo version is at least 4.7... no
> configure: WARNING: you cannot build info or html versions of the R manuals

> from ./configure, and

> gcc -I../../src/extra/zlib -I../../src/extra/bzip2 -I../../src/extra/pcre  -I. -I../../src/include -I../../src/include -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c regex.c -o regex.o
> regex.c:2525: warning: `noinline' attribute directive ignored
> regex.c:2699: warning: `always_inline' attribute directive ignored
> regex.c:6236: warning: `always_inline' attribute directive ignored
> [...]
> gcc -I/usr/local/src/R/R-alpha/include  -I/usr/local/include  -Wno-long-long -fPIC  -g -O2 -c pfm-read.c -o pfm-read.o
> pfm-read.c:225: warning: `match' redefined
> /usr/local/src/R/R-alpha/include/Rinternals.h:1002: warning: this is the location of the previous definition

> from make.

> -- 
> Bj?rn-Helge Mevik

> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Tue Apr  5 13:19:27 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Apr  5 13:19:36 2005
Subject: [Rd] R-alpha_2005-03-31: make check fails on Debian 3.0
In-Reply-To: <16978.28065.3489.148481@mithrandir.hornik.net>
References: <m03bubhp7n.fsf@bar.nemo-project.org>
	<16978.28065.3489.148481@mithrandir.hornik.net>
Message-ID: <Pine.LNX.4.61.0504051212340.8440@gannet.stats>

On Tue, 5 Apr 2005, Kurt Hornik wrote:

>>>>>> Bj?rn-Helge Mevik writes:
>
>> I've just tested R-alpha_2005-03-31.tar.gz.  ./configure and make
>> ran without any apparent errors, but make check failed:

>>> ### ** Examples
>>>
>>> help.search("linear models")    # In case you forgot how to fit linear
>> Error in iconv(db[[i]][ind, ], enc, "") : 'iconv' is not available on this system
>> Execution halted
>
> Can you try again with a current (SVN) version of r-devel?

You will need to test this in a non-C locale.  I wondered why this was 
working on my Solaris systems without iconv, but they are all in C.
Testing in LANG=en_GB shows that the recent patches have indeed resolved 
this.


>> The parts of the output fron ./configure that meantion "iconv" is
>
>> checking iconv.h usability... yes
>> checking iconv.h presence... yes
>> checking for iconv.h... yes
>> checking for iconv... yes
>> checking whether iconv() accepts "UTF-8" and "latin1"... no

That's the first time I have seen a Linux system fail that test ....

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
From btyner at gmail.com  Tue Apr  5 15:21:15 2005
From: btyner at gmail.com (Benjamin Tyner)
Date: Tue Apr  5 15:21:25 2005
Subject: [Rd] future update to loess
Message-ID: <425290CB.9050306@stat.purdue.edu>

Background: I'm a student of Prof. Cleveland at Purdue University.
Eventually, we'd like to release a new version of the loess routine in R.
For starters, this implementation would have support for local polynomial
degree 3, better control over the number of cells in the KD tree, and
perhaps a better solution in higher predictor dimension.

I see that Prof. Ripley was responsible for originally porting loess to R
as part of the modreg library, which has been absorbed into the stardard
stats library. My first question is, what would be the preferred way to
package this update? As an updated version of modreg, or as a new standalone
implementation of loess? Or something else entirely?

Second, I'd like to hear what additional features or modifications other
loess users would like to see incorporated into this release.

Thanks,
Ben

From bhs2 at mevik.net  Tue Apr  5 15:23:07 2005
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Tue Apr  5 15:23:07 2005
Subject: [Rd] R-alpha_2005-03-31: make check fails on Debian 3.0
In-Reply-To: <Pine.LNX.4.61.0504051212340.8440@gannet.stats> (Brian Ripley's
	message of "Tue, 5 Apr 2005 12:19:27 +0100 (BST)")
References: <m03bubhp7n.fsf@bar.nemo-project.org>
	<16978.28065.3489.148481@mithrandir.hornik.net>
	<Pine.LNX.4.61.0504051212340.8440@gannet.stats>
Message-ID: <m0d5t9bbno.fsf@bar.nemo-project.org>

Prof Brian Ripley writes:

> On Tue, 5 Apr 2005, Kurt Hornik wrote:
>
>> Can you try again with a current (SVN) version of r-devel?

It passed make check without error.

> You will need to test this in a non-C locale.

Yes.  I have LANG=no_NO

-- 
Bj?rn-Helge Mevik

From ggrothendieck at gmail.com  Tue Apr  5 15:44:30 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue Apr  5 15:44:38 2005
Subject: [Rd] future update to loess
In-Reply-To: <425290CB.9050306@stat.purdue.edu>
References: <425290CB.9050306@stat.purdue.edu>
Message-ID: <971536df05040506442cd6eca7@mail.gmail.com>

On Apr 5, 2005 9:21 AM, Benjamin Tyner <btyner@gmail.com> wrote:
> Second, I'd like to hear what additional features or modifications other
> loess users would like to see incorporated into this release.

More documentation: a vignette, additional discussion in the help page 
or other reference to _online_ material.

From gregory.r.warnes at pfizer.com  Tue Apr  5 18:53:49 2005
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Tue Apr  5 18:54:17 2005
Subject: [Rd] future update to loess
Message-ID: <915D2D65A9986440A277AC5C98AA466F978DA0@groamrexm02.amer.pfizer.com>

How about a clean way to plot 2-d lowess curves, so that we can replace most
usage of lowess() ?

-G

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch
> [mailto:r-devel-bounces@stat.math.ethz.ch]On Behalf Of Gabor
> Grothendieck
> Sent: Tuesday, April 05, 2005 9:45 AM
> To: btyner@stat.purdue.edu
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] future update to loess
> 
> 
> On Apr 5, 2005 9:21 AM, Benjamin Tyner <btyner@gmail.com> wrote:
> > Second, I'd like to hear what additional features or 
> modifications other
> > loess users would like to see incorporated into this release.
> 
> More documentation: a vignette, additional discussion in the 
> help page 
> or other reference to _online_ material.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

From penglish at 3tiergroup.com  Tue Apr  5 22:51:55 2005
From: penglish at 3tiergroup.com (Paul English)
Date: Tue Apr  5 22:52:05 2005
Subject: [Rd] Install R 2.0 package on R 1.9.1
Message-ID: <Pine.LNX.4.62.0504051346070.2205@localhost.localdomain>


Hi,
 	I'm wondering if it is possible to install a package for R 2.0 on 
R 1.9.1 on Mac OS X? I'm getting this error which seems to be known issue:

library("quantreg")
Error in firstlib(which.lib.loc, package) :
         couldn't find function "lazyLoad"
In addition: Warning message:
package quantreg was built under R version 2.0.1
Error in library("quantreg") : .First.lib failed

However, on CRAN, the Mac OS X "1.9" directory is just a symlink to the 
Mac OS X "2.0" directory - there is no separate directory for 1.9 packages as best I can 
tell.

I did also try building the source package, but that failed. I emailed the 
packager asking for help, but it can't hurt to ask here as well. The 
problem is that the package build can't find -lfrtbegin. On Mac OS X this 
comes from fink so it is installed in /sw. So I untarred the package and 
edited Makevars to tell the build to look at -L/sw/lib, but interestingly 
enough that only worked for one gcc line, and not the final linking stage. 
As you can see below, the final linking stage is also looking for 
/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4 which doesn't exist. I'm 
not sure where it is getting that from. I can only guess that autoconf or 
something is messed up on this machine:

R CMD INSTALL quantreg_3.76.tar.gz
* Installing *source* package 'quantreg' ...
** libs
g77   -fno-common  -g -O2 -c akj.f -o akj.o
g77   -fno-common  -g -O2 -c boot.f -o boot.o
g77   -fno-common  -g -O2 -c bound.f -o bound.o
g77   -fno-common  -g -O2 -c boundc.f -o boundc.o
g77   -fno-common  -g -O2 -c chlfct.f -o chlfct.o
g77   -fno-common  -g -O2 -c cholesky.f -o cholesky.o
g77   -fno-common  -g -O2 -c extract.f -o extract.o
gcc -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include 
-I/usr/local/include  -L/opt/sw -fno-common  -g -O2 -c mcmb.c -o mcmb.o
g77   -fno-common  -g -O2 -c penalty.f -o penalty.o
g77   -fno-common  -g -O2 -c rls.f -o rls.o
g77   -fno-common  -g -O2 -c rq1.f -o rq1.o
g77   -fno-common  -g -O2 -c rqbr.f -o rqbr.o
g77   -fno-common  -g -O2 -c rqfn.f -o rqfn.o
g77   -fno-common  -g -O2 -c rqfnb.f -o rqfnb.o
g77   -fno-common  -g -O2 -c rqfnc.f -o rqfnc.o
g77   -fno-common  -g -O2 -c sparskit2.f -o sparskit2.o
g77   -fno-common  -g -O2 -c srqfn.f -o srqfn.o
g77   -fno-common  -g -O2 -c srqfnc.f -o srqfnc.o
g77   -fno-common  -g -O2 -c srtpai.f -o srtpai.o
g77   -fno-common  -g -O2 -c xlapack.f -o xlapack.o
gcc -bundle -flat_namespace -undefined suppress -L/usr/local/lib -o 
quantreg.so akj.o boot.o bound.o boundc.o chlfct.o cholesky.o extract.o 
mcmb.o penalty.o rls.o rq1.o rqbr.o rqfn.o rqfnb.o rqfnc.o sparskit2.o 
srqfn.o srqfnc.o srtpai.o xlapack.o -framework vecLib -L/usr/local/lib 
-L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4 
-L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/../../.. -lfrtbegin -lg2c 
-lSystem -lcc_dynamic -framework R
ld: warning -L: directory name 
(/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4) does not exist
ld: warning -L: directory name 
(/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/../../..) does not exist
ld: can't locate file for: -lfrtbegin
make: *** [quantreg.so] Error 1
ERROR: compilation failed for package 'quantreg'
** Removing 
'/Library/Frameworks/R.framework/Versions/1.9.1/Resources/library/quantreg'

From stefano.iacus at unimi.it  Tue Apr  5 23:31:10 2005
From: stefano.iacus at unimi.it (stefano iacus)
Date: Tue Apr  5 23:31:18 2005
Subject: [Rd] Install R 2.0 package on R 1.9.1
In-Reply-To: <Pine.LNX.4.62.0504051346070.2205@localhost.localdomain>
References: <Pine.LNX.4.62.0504051346070.2205@localhost.localdomain>
Message-ID: <f0d57a8efdb3490c1b3b8012c3e9cdb1@unimi.it>


On 05/apr/05, at 22:51, Paul English wrote:

>
> Hi,
> 	I'm wondering if it is possible to install a package for R 2.0 on R  
> 1.9.1 on Mac OS X?

no, not even on other platforms, R-2.0.x requires packages built for  
these releases

>  I'm getting this error which seems to be known issue:
>
> library("quantreg")
> Error in firstlib(which.lib.loc, package) :
>         couldn't find function "lazyLoad"
> In addition: Warning message:
> package quantreg was built under R version 2.0.1
> Error in library("quantreg") : .First.lib failed
>
> However, on CRAN, the Mac OS X "1.9" directory is just a symlink to  
> the Mac OS X "2.0" directory - there is no separate directory for 1.9  
> packages as best I can tell.
this is not true,
have a look at
http://cran.r-project.org/bin/macosx/2.0
http://cran.r-project.org/bin/macosx/1.9
they are just different (and 1.9 has not been updated since oct 2004)


>
> I did also try building the source package, but that failed. I emailed  
> the packager asking for help, but it can't hurt to ask here as well.  
> The problem is that the package build can't find -lfrtbegin. On Mac OS  
> X this comes from fink so it is installed in /sw. So I untarred the  
> package and edited Makevars to tell the build to look at -L/sw/lib,  
> but interestingly enough that only worked for one gcc line, and not  
> the final linking stage. As you can see below, the final linking stage  
> is also looking for /usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4  
> which doesn't exist. I'm not sure where it is getting that from. I can  
> only guess that autoconf or something is messed up on this machine:
>
> R CMD INSTALL quantreg_3.76.tar.gz
> * Installing *source* package 'quantreg' ...
> ** libs
> g77   -fno-common  -g -O2 -c akj.f -o akj.o
> g77   -fno-common  -g -O2 -c boot.f -o boot.o
> g77   -fno-common  -g -O2 -c bound.f -o bound.o
> g77   -fno-common  -g -O2 -c boundc.f -o boundc.o
> g77   -fno-common  -g -O2 -c chlfct.f -o chlfct.o
> g77   -fno-common  -g -O2 -c cholesky.f -o cholesky.o
> g77   -fno-common  -g -O2 -c extract.f -o extract.o
> gcc -no-cpp-precomp  
> -I/Library/Frameworks/R.framework/Resources/include  
> -I/usr/local/include  -L/opt/sw -fno-common  -g -O2 -c mcmb.c -o  
> mcmb.o
> g77   -fno-common  -g -O2 -c penalty.f -o penalty.o
> g77   -fno-common  -g -O2 -c rls.f -o rls.o
> g77   -fno-common  -g -O2 -c rq1.f -o rq1.o
> g77   -fno-common  -g -O2 -c rqbr.f -o rqbr.o
> g77   -fno-common  -g -O2 -c rqfn.f -o rqfn.o
> g77   -fno-common  -g -O2 -c rqfnb.f -o rqfnb.o
> g77   -fno-common  -g -O2 -c rqfnc.f -o rqfnc.o
> g77   -fno-common  -g -O2 -c sparskit2.f -o sparskit2.o
> g77   -fno-common  -g -O2 -c srqfn.f -o srqfn.o
> g77   -fno-common  -g -O2 -c srqfnc.f -o srqfnc.o
> g77   -fno-common  -g -O2 -c srtpai.f -o srtpai.o
> g77   -fno-common  -g -O2 -c xlapack.f -o xlapack.o
> gcc -bundle -flat_namespace -undefined suppress -L/usr/local/lib -o  
> quantreg.so akj.o boot.o bound.o boundc.o chlfct.o cholesky.o  
> extract.o mcmb.o penalty.o rls.o rq1.o rqbr.o rqfn.o rqfnb.o rqfnc.o  
> sparskit2.o srqfn.o srqfnc.o srtpai.o xlapack.o -framework vecLib  
> -L/usr/local/lib -L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4  
> -L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/../../.. -lfrtbegin  
> -lg2c -lSystem -lcc_dynamic -framework R
> ld: warning -L: directory name  
> (/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4) does not exist
> ld: warning -L: directory name  
> (/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/../../..) does not  
> exist
> ld: can't locate file for: -lfrtbegin
> make: *** [quantreg.so] Error 1
> ERROR: compilation failed for package 'quantreg'
> ** Removing  
> '/Library/Frameworks/R.framework/Versions/1.9.1/Resources/library/ 
> quantreg'
>

this problem comes from the fact that you have system configured  
differently from how the R binaries has been built, so config files  
distributed with it reflect these differences (in particular this  
folder is relative to the gcc shipped with OS X 10.2, you should  
replace it with the one pointing to the right gcc for your system)
My suggestions is to build R from sources as well following the notes  
on the Faq for Mac OS X or asking to R-sig-Mac.

In any case, you should give us more details on the version of R you  
are using, the OS X version, etc to leave us be helpful.

stefano


> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From penglish at 3tiergroup.com  Tue Apr  5 23:58:33 2005
From: penglish at 3tiergroup.com (Paul English)
Date: Tue Apr  5 23:58:45 2005
Subject: [Rd] Install R 2.0 package on R 1.9.1
In-Reply-To: <f0d57a8efdb3490c1b3b8012c3e9cdb1@unimi.it>
References: <Pine.LNX.4.62.0504051346070.2205@localhost.localdomain>
	<f0d57a8efdb3490c1b3b8012c3e9cdb1@unimi.it>
Message-ID: <Pine.LNX.4.62.0504051443320.2205@localhost.localdomain>


On Tue, 5 Apr 2005, stefano iacus wrote:

>>  I'm getting this error which seems to be known issue:
>> 
>> library("quantreg")
>> Error in firstlib(which.lib.loc, package) :
>>         couldn't find function "lazyLoad"
>> In addition: Warning message:
>> package quantreg was built under R version 2.0.1
>> Error in library("quantreg") : .First.lib failed
>> 
>> However, on CRAN, the Mac OS X "1.9" directory is just a symlink to the Mac 
>> OS X "2.0" directory - there is no separate directory for 1.9 packages as 
>> best I can tell.
> this is not true,
> have a look at
> http://cran.r-project.org/bin/macosx/2.0
> http://cran.r-project.org/bin/macosx/1.9
> they are just different (and 1.9 has not been updated since oct 2004)

Aah, the mirrors are very slow, so I only tried one. cran.r-project 
doesn't show the problem, so now I've got a R 1.9 package - thanks!
http://cran.cnr.Berkeley.edu
http://www.bioconductor.org/CRAN
do not have the problem either.

but:

http://lib.stat.cmu.edu/R/CRAN/

has this problem. Even if you go directly to:

http://lib.stat.cmu.edu/R/CRAN/bin/macosx/1.9/

The index lists "2.0." The way I got to it was by going from the R 
homepage CRAN->http://lib.stat.cmu.edu->Mac OS X->1.9


>> I did also try building the source package, but that failed. I emailed the 
>> packager asking for help, but it can't hurt to ask here as well. The 
>> problem is that the package build can't find -lfrtbegin. On Mac OS X this 
>> comes from fink so it is installed in /sw. So I untarred the package and 
>> edited Makevars to tell the build to look at -L/sw/lib, but interestingly 
>> enough that only worked for one gcc line, and not the final linking stage. 
>> As you can see below, the final linking stage is also looking for 
>> /usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4 which doesn't exist. I'm not 
>> sure where it is getting that from. I can only guess that autoconf or 
>> something is messed up on this machine:
<snip build errors>
>
> this problem comes from the fact that you have system configured differently 
> from how the R binaries has been built, so config files distributed with it 
> reflect these differences (in particular this folder is relative to the gcc 
> shipped with OS X 10.2, you should replace it with the one pointing to the 
> right gcc for your system)

That makes good sense. I see there is an Aqua version out now that my 
users might like.

> My suggestions is to build R from sources as well following the notes on the 
> Faq for Mac OS X or asking to R-sig-Mac.

I'm setting up 2.0 in parallel on a separate machine, so I will do that, 
and whenever my user is ready I'll upgrade her R install.

> In any case, you should give us more details on the version of R you are 
> using, the OS X version, etc to leave us be helpful.

OS X ver 10.3.8
R 1.9.1

Although you've already answered all my questions. :-)

From vograno at evafunds.com  Wed Apr  6 00:13:33 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Wed Apr  6 00:13:46 2005
Subject: [Rd] Calling do_inherit from C
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A58FFBC1@phost015.EVAFUNDS.intermedia.net>

Hi,
 
Is there a way (or better say idiom) for calling functions like
do_inherit() (which are meant to be called via .Internal) from regular C
code. Say I have a SEXP object x and I want to check if it inherits from
"POSIXt". How do I do this?
 
Thanks,
Vadim

	[[alternative HTML version deleted]]

From htang at hpl.hp.com  Wed Apr  6 02:45:05 2005
From: htang at hpl.hp.com (htang@hpl.hp.com)
Date: Wed Apr  6 02:45:12 2005
Subject: [Rd] Unexpected behavior of colSums (rowSums) when the input matrix
	has zero rows (columns) (PR#7775)
Message-ID: <20050406004505.7954FCA5A@slim.kubism.ku.dk>

Hi all,

colSums() does not work as I expect when there are no rows.  For example:

> x = matrix(0, nrow=0, ncol=5)
> colSums(x)
Error in colSums(x, n, prod(dn), na.rm) : invalid value of n

I expected to get 0's, as is given by apply():

> apply(x, 2, sum, na.rm=TRUE)
[1] 0 0 0 0 0

This behavior is also inconsistent with the case when NA's are removed:

> colSums(matrix(NA, nrow=1, ncol=5), na.rm=TRUE)
[1] 0 0 0 0 0

(This latter case is described in the documentation.)

The same problem occurs with rowSums(), of course.

Thanks,
Hsiu-Khuern.

--please do not edit the information below--

Version:
 platform = i386-pc-linux-gnu
 arch = i386
 os = linux-gnu
 system = i386, linux-gnu
 status =
 major = 2
 minor = 0.1
 year = 2004
 month = 11
 day = 15
 language = R

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:grDevices, package:utils, Autoloads, package:base

From Mark.Bravington at csiro.au  Wed Apr  6 06:53:37 2005
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Wed Apr  6 06:53:49 2005
Subject: [Rd] makeActiveBinding warning
Message-ID: <4D99275E380CA94F998977EDACE548DC1AE692@extas2-hba.tas.csiro.au>

A while ago Luke Tierney remarked that the warning associated with
'makeActiveBinding'-- "saved workspaces with active bindings may not
work properly when loaded into older versions of R"-- should probably be
removed in R-devel. It's still cropping up *sporadically* with R-alpha
of 3/4/2004, but not every time I call 'makeActiveBinding'.

So, two questions:

(i) is it going to go altogether with the release of R2.1? If not, I'll
need to tweak my code to suppress the warning

(ii) is the warning actually correct? When I experimented with this (a
bit), it seemed to me that the binary image file contained the full
unbound version of the object, and actually did load normally into R1.7
(the oldest version I still have).

Thanks
Mark

Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623


	[[alternative HTML version deleted]]

From ripley at stats.ox.ac.uk  Wed Apr  6 08:49:55 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Apr  6 08:50:05 2005
Subject: [Rd] Calling do_inherit from C
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A58FFBC1@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A58FFBC1@phost015.EVAFUNDS.intermedia.net>
Message-ID: <Pine.LNX.4.61.0504060742310.18825@gannet.stats>

On Tue, 5 Apr 2005, Vadim Ogranovich wrote:

> Hi,
>
> Is there a way (or better say idiom) for calling functions like
> do_inherit() (which are meant to be called via .Internal) from regular C
> code. Say I have a SEXP object x and I want to check if it inherits from
> "POSIXt". How do I do this?

Call eval() on the R expression you want.  There are lots of examples in 
the tests/Embedding directory, and the following (in objects.c)

#ifdef UNUSED
static void load_methods_package()
{
     SEXP e;
     R_set_standardGeneric_ptr(dispatchNonGeneric, NULL);
     PROTECT(e = allocVector(LANGSXP, 2));
     SETCAR(e, install("library"));
     SETCAR(CDR(e), install("methods"));
     eval(e, R_GlobalEnv);
     UNPROTECT(1);
}
#endif

is a simple prototype for such calls.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Apr  6 10:07:18 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Apr  6 10:07:26 2005
Subject: [Rd] HP-UX and IRIX recent builds?  Any other rare platforms?
Message-ID: <Pine.LNX.4.61.0504060854100.19609@gannet.stats>

I am revising the section in R-admin on platforms.  When I asked about 
locales earlier this year I got no reply about HP-UX and IRIX, so I will 
presume that no one has built R on those OSes recently.  If you have, 
please send me the OS number and the flags you used.

Platforms where I have seen recent reports:

Linux
MacOS X
Solaris 8, 9, 10   (any Solaris 7 users please let me know)
AIX 5.1 and 5.2
FreeBSD

and less recently, OSF/1.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From plummer at iarc.fr  Wed Apr  6 12:40:16 2005
From: plummer at iarc.fr (Martyn Plummer)
Date: Wed Apr  6 12:42:22 2005
Subject: [Rd] HP-UX and IRIX recent builds?  Any other rare platforms?
In-Reply-To: <Pine.LNX.4.61.0504060854100.19609@gannet.stats>
References: <Pine.LNX.4.61.0504060854100.19609@gannet.stats>
Message-ID: <1112784016.26851.5.camel@seurat>

I have just (this week) got access to an SGI Origin running IRIX 6.5.27.
In answer to your previous questions about locales, "locale -a" shows no
utf8 locales; mbrtowc and wcwidth are defined in wchar.h.

Compiling R with the native compilers looks problematic. If I find the
right compiler flags I will let you know.

Martyn

On Wed, 2005-04-06 at 09:07 +0100, Prof Brian Ripley wrote:
> I am revising the section in R-admin on platforms.  When I asked about 
> locales earlier this year I got no reply about HP-UX and IRIX, so I will 
> presume that no one has built R on those OSes recently.  If you have, 
> please send me the OS number and the flags you used.
> 
> Platforms where I have seen recent reports:
> 
> Linux
> MacOS X
> Solaris 8, 9, 10   (any Solaris 7 users please let me know)
> AIX 5.1 and 5.2
> FreeBSD
> 
> and less recently, OSF/1.
>

From gavin.simpson at ucl.ac.uk  Wed Apr  6 16:42:44 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed Apr  6 16:42:54 2005
Subject: [Rd] make error in R devel
Message-ID: <4253F564.4090706@ucl.ac.uk>

Dear list,

I just hit an error that stopped my make && make check-devel operation 
on my linux box (FC3, i686 P4 2GB RAM). Just to note that I've been 
building the development branch(?) for some time and this is the first 
hint of a problem.

1) updated the src tree using svn update
2) ran ../configure --with-recommended-package=no from my build directory
3) got:
R is now configured for i686-pc-linux-gnu

   Source directory:          ../src
   Installation directory:    /usr/local

   C compiler:                gcc  -O3 -g -march=i386 -mcpu=i686
   C++ compiler:              g++  -O3 -g -march=i386 -mcpu=i686
   Fortran compiler:          g77  -O3 -g -march=i386 -mcpu=i686

   Interfaces supported:      X11, tcltk
   External libraries:        readline, BLAS(generic)
   Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
   Options enabled:           R profiling

   Recommended packages:      no

Note I've editted config.site to compile with optimisations -O3
4) did make && make check-devel and get this:
...
make[5]: Entering directory `/home/gavin/R/devel/build/src/library'
  >>> Building/Updating help pages for package 'graphics'
      Formats: text html latex example
make[5]: Leaving directory `/home/gavin/R/devel/build/src/library'
running code in 'graphics-Ex.R' ... OK
collecting examples for package 'stats' ...
make[5]: Entering directory `/home/gavin/R/devel/build/src/library'
  >>> Building/Updating help pages for package 'stats'
      Formats: text html latex example
make[5]: Leaving directory `/home/gavin/R/devel/build/src/library'
running code in 'stats-Ex.R' ...make[4]: *** [stats-Ex.Rout] Error 1
make[4]: Leaving directory `/home/gavin/R/devel/build/tests/Examples'
make[3]: *** [test-Examples-Base] Error 2
make[3]: Leaving directory `/home/gavin/R/devel/build/tests/Examples'
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory `/home/gavin/R/devel/build/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/home/gavin/R/devel/build/tests'
make: *** [check-devel] Error 2

5) Looking at stats-Ex.Rout.fail I see this at the end:
 >
 > ### Name: confint
 > ### Title: Confidence Intervals for Model Parameters
 > ### Aliases: confint confint.default
 > ### Keywords: models
 >
 > ### ** Examples
 >
 > fit <- lm(100/mpg ~ disp + hp + wt + am, data=mtcars)
 > confint(fit)
                    2.5 %      97.5 %
(Intercept) -0.774822875 2.256118188
disp        -0.002867999 0.008273849
hp          -0.001400580 0.011949674
wt           0.380088737 1.622517536
am          -0.614677730 0.926307310
 > confint(fit, "wt")
        2.5 %   97.5 %
wt 0.3800887 1.622518
 >
 > ## from example(glm)
 > counts <- c(18,17,15,20,10,20,25,13,12)
 > outcome <- gl(3,1,9); treatment <- gl(3,3)
 > glm.D93 <- glm(counts ~ outcome + treatment, family=poisson())
 > confint(glm.D93)
Error in loadNamespace(name) : there is no package called 'MASS'
Execution halted

But as there are no recommended packages this fails as indicated. So is 
there something wrong with what I'm doing (i.e. something recent in the 
last week has changed that I missed in NEWS) or is this a bug in the 
tests or examples?

Cheers

Gav
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

From ripley at stats.ox.ac.uk  Wed Apr  6 17:01:09 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Apr  6 17:01:18 2005
Subject: [Rd] make error in R devel
In-Reply-To: <4253F564.4090706@ucl.ac.uk>
References: <4253F564.4090706@ucl.ac.uk>
Message-ID: <Pine.LNX.4.61.0504061558560.469@gannet.stats>

What you are doing is not building the recommended packages.  We not 
guarantee that the examples will work if you do not.  (I was aware this 
would happen but have not yet put in a workaround.)

*WHY* are you not building the recommended packages?

On Wed, 6 Apr 2005, Gavin Simpson wrote:

> Dear list,
>
> I just hit an error that stopped my make && make check-devel operation on my 
> linux box (FC3, i686 P4 2GB RAM). Just to note that I've been building the 
> development branch(?) for some time and this is the first hint of a problem.
>
> 1) updated the src tree using svn update
> 2) ran ../configure --with-recommended-package=no from my build directory
> 3) got:
> R is now configured for i686-pc-linux-gnu
>
>  Source directory:          ../src
>  Installation directory:    /usr/local
>
>  C compiler:                gcc  -O3 -g -march=i386 -mcpu=i686
>  C++ compiler:              g++  -O3 -g -march=i386 -mcpu=i686
>  Fortran compiler:          g77  -O3 -g -march=i386 -mcpu=i686
>
>  Interfaces supported:      X11, tcltk
>  External libraries:        readline, BLAS(generic)
>  Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
>  Options enabled:           R profiling
>
>  Recommended packages:      no
>
> Note I've editted config.site to compile with optimisations -O3
> 4) did make && make check-devel and get this:
> ...
> make[5]: Entering directory `/home/gavin/R/devel/build/src/library'
> >>> Building/Updating help pages for package 'graphics'
>     Formats: text html latex example
> make[5]: Leaving directory `/home/gavin/R/devel/build/src/library'
> running code in 'graphics-Ex.R' ... OK
> collecting examples for package 'stats' ...
> make[5]: Entering directory `/home/gavin/R/devel/build/src/library'
> >>> Building/Updating help pages for package 'stats'
>     Formats: text html latex example
> make[5]: Leaving directory `/home/gavin/R/devel/build/src/library'
> running code in 'stats-Ex.R' ...make[4]: *** [stats-Ex.Rout] Error 1
> make[4]: Leaving directory `/home/gavin/R/devel/build/tests/Examples'
> make[3]: *** [test-Examples-Base] Error 2
> make[3]: Leaving directory `/home/gavin/R/devel/build/tests/Examples'
> make[2]: *** [test-Examples] Error 2
> make[2]: Leaving directory `/home/gavin/R/devel/build/tests'
> make[1]: *** [test-all-basics] Error 1
> make[1]: Leaving directory `/home/gavin/R/devel/build/tests'
> make: *** [check-devel] Error 2
>
> 5) Looking at stats-Ex.Rout.fail I see this at the end:
>>
>> ### Name: confint
>> ### Title: Confidence Intervals for Model Parameters
>> ### Aliases: confint confint.default
>> ### Keywords: models
>>
>> ### ** Examples
>>
>> fit <- lm(100/mpg ~ disp + hp + wt + am, data=mtcars)
>> confint(fit)
>                   2.5 %      97.5 %
> (Intercept) -0.774822875 2.256118188
> disp        -0.002867999 0.008273849
> hp          -0.001400580 0.011949674
> wt           0.380088737 1.622517536
> am          -0.614677730 0.926307310
>> confint(fit, "wt")
>       2.5 %   97.5 %
> wt 0.3800887 1.622518
>>
>> ## from example(glm)
>> counts <- c(18,17,15,20,10,20,25,13,12)
>> outcome <- gl(3,1,9); treatment <- gl(3,3)
>> glm.D93 <- glm(counts ~ outcome + treatment, family=poisson())
>> confint(glm.D93)
> Error in loadNamespace(name) : there is no package called 'MASS'
> Execution halted
>
> But as there are no recommended packages this fails as indicated. So is there 
> something wrong with what I'm doing (i.e. something recent in the last week 
> has changed that I missed in NEWS) or is this a bug in the tests or examples?
>
> Cheers
>
> Gav
> -- 
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> Gavin Simpson                     [T] +44 (0)20 7679 5522
> ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
> UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> London.  WC1H 0AP.
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From plummer at iarc.fr  Wed Apr  6 17:09:45 2005
From: plummer at iarc.fr (Martyn Plummer)
Date: Wed Apr  6 17:11:51 2005
Subject: [Rd] make error in R devel
In-Reply-To: <4253F564.4090706@ucl.ac.uk>
References: <4253F564.4090706@ucl.ac.uk>
Message-ID: <1112800185.26851.7.camel@seurat>

If you get the R source via svn, then you need to run tools/rsync-
recommended to get the recommended packages.  If you download the
tarball from CRAN then these are already included.

Martyn


On Wed, 2005-04-06 at 15:42 +0100, Gavin Simpson wrote:
> Dear list,
> 
> I just hit an error that stopped my make && make check-devel operation 
> on my linux box (FC3, i686 P4 2GB RAM). Just to note that I've been 
> building the development branch(?) for some time and this is the first 
> hint of a problem.
> 
> 1) updated the src tree using svn update
> 2) ran ../configure --with-recommended-package=no from my build directory
> 3) got:
> R is now configured for i686-pc-linux-gnu
> 
>    Source directory:          ../src
>    Installation directory:    /usr/local
> 
>    C compiler:                gcc  -O3 -g -march=i386 -mcpu=i686
>    C++ compiler:              g++  -O3 -g -march=i386 -mcpu=i686
>    Fortran compiler:          g77  -O3 -g -march=i386 -mcpu=i686
> 
>    Interfaces supported:      X11, tcltk
>    External libraries:        readline, BLAS(generic)
>    Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
>    Options enabled:           R profiling
> 
>    Recommended packages:      no
> 
> Note I've editted config.site to compile with optimisations -O3
> 4) did make && make check-devel and get this:
> ...
> make[5]: Entering directory `/home/gavin/R/devel/build/src/library'
>   >>> Building/Updating help pages for package 'graphics'
>       Formats: text html latex example
> make[5]: Leaving directory `/home/gavin/R/devel/build/src/library'
> running code in 'graphics-Ex.R' ... OK
> collecting examples for package 'stats' ...
> make[5]: Entering directory `/home/gavin/R/devel/build/src/library'
>   >>> Building/Updating help pages for package 'stats'
>       Formats: text html latex example
> make[5]: Leaving directory `/home/gavin/R/devel/build/src/library'
> running code in 'stats-Ex.R' ...make[4]: *** [stats-Ex.Rout] Error 1
> make[4]: Leaving directory `/home/gavin/R/devel/build/tests/Examples'
> make[3]: *** [test-Examples-Base] Error 2
> make[3]: Leaving directory `/home/gavin/R/devel/build/tests/Examples'
> make[2]: *** [test-Examples] Error 2
> make[2]: Leaving directory `/home/gavin/R/devel/build/tests'
> make[1]: *** [test-all-basics] Error 1
> make[1]: Leaving directory `/home/gavin/R/devel/build/tests'
> make: *** [check-devel] Error 2
> 
> 5) Looking at stats-Ex.Rout.fail I see this at the end:
>  >
>  > ### Name: confint
>  > ### Title: Confidence Intervals for Model Parameters
>  > ### Aliases: confint confint.default
>  > ### Keywords: models
>  >
>  > ### ** Examples
>  >
>  > fit <- lm(100/mpg ~ disp + hp + wt + am, data=mtcars)
>  > confint(fit)
>                     2.5 %      97.5 %
> (Intercept) -0.774822875 2.256118188
> disp        -0.002867999 0.008273849
> hp          -0.001400580 0.011949674
> wt           0.380088737 1.622517536
> am          -0.614677730 0.926307310
>  > confint(fit, "wt")
>         2.5 %   97.5 %
> wt 0.3800887 1.622518
>  >
>  > ## from example(glm)
>  > counts <- c(18,17,15,20,10,20,25,13,12)
>  > outcome <- gl(3,1,9); treatment <- gl(3,3)
>  > glm.D93 <- glm(counts ~ outcome + treatment, family=poisson())
>  > confint(glm.D93)
> Error in loadNamespace(name) : there is no package called 'MASS'
> Execution halted
> 
> But as there are no recommended packages this fails as indicated. So is 
> there something wrong with what I'm doing (i.e. something recent in the 
> last week has changed that I missed in NEWS) or is this a bug in the 
> tests or examples?
> 
> Cheers
> 
> Gav

From gavin.simpson at ucl.ac.uk  Wed Apr  6 17:18:03 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed Apr  6 17:18:17 2005
Subject: [Rd] make error in R devel
In-Reply-To: <Pine.LNX.4.61.0504061558560.469@gannet.stats>
References: <4253F564.4090706@ucl.ac.uk>
	<Pine.LNX.4.61.0504061558560.469@gannet.stats>
Message-ID: <4253FDAB.3010002@ucl.ac.uk>

Prof Brian Ripley wrote:
> What you are doing is not building the recommended packages.  We not 
> guarantee that the examples will work if you do not.  (I was aware this 
> would happen but have not yet put in a workaround.)
> 
> *WHY* are you not building the recommended packages?
> 

Because I have a single library of packages and this is a throw back to 
when I used the Fedora R rpm and had to be root to update the packages 
(I was new to Linux - what can I say) - so it was easier to not have the 
packages in the default library and install them into my own library in ~/

There's no reason not to do this now of course I'm just stuck in my ways :-)

I only wanted to use devel now because I wanted to check whether a 
problem I was having with axis.Date was still present in the devel tree 
before emailing the list about it. I'll build the recommended packages 
and try again.

Thanks for the prompt reply.

G

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

From gavin.simpson at ucl.ac.uk  Wed Apr  6 19:35:44 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed Apr  6 19:35:53 2005
Subject: [Rd] axis.Date problem, bug(?)
Message-ID: <42541DF0.1030709@ucl.ac.uk>

Dear List,

I have the following problem with axis.Date, here is an artificial example:

dates <- scan(what = "character")
"25/03/2000" "26/03/2000" "27/03/2000" "28/03/2000" "29/03/2000" 
"30/03/2000" "31/03/2000" "01/04/2000" "02/04/2000" "03/04/2000" 
"04/04/2000" "05/04/2000"

dates <- as.Date(as.character(dates), format = "%d/%m/%Y")
vals <- rnorm(12)
plot(x = dates, y = vals, axes = FALSE)
axis(side = 2)
box()
axis.Date(side = 1, x = dates, labels = "")
Error in axis(side, at = z, labels = labels, ...) :
         formal argument "labels" matched by multiple actual arguments

Which arises because axis.Date has this in the function:
axis.Date
function (side, x, at, format, ...)
{
	...
	labels <- format.Date(z, format = format)
	axis(side, at = z, labels = labels, ...)
	invisible()
}

Commenting out the labels <- format... allows labels to be passed. I 
guess there should be something checking if labels is in ... and if it 
is don't generate new labels, and then don't pass this along in the ... 
to axis, but I haven't got as far as working out how to use dots() 
properly so I can't contribute a patch - yet, bit more reading and 
experimenting to do... - or decide if this is the way things should be done.

What I want to do is is have, following my example, the days plotted 
with ticks and labeled as they are, but I also want ticks for say the 
hours, plotted with smaller tick marks and un-labeled.

I've worked out how to do this for my actual application (where the 
years are labeled but I want months within years as unlabeled, little 
ticks) but I can't suppress the labellings when using a second call to 
axis.Date. Maybe this is the wrong way of doing things? If anyone has a 
better idea then I'd been keen to learn.

For now I've hacked my own my.axis.Date for my purposes that works.

Thanks for your time,

Gav
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

From gavin.simpson at ucl.ac.uk  Wed Apr  6 19:39:01 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed Apr  6 19:39:10 2005
Subject: [Rd] axis.Date problem, bug(?)
In-Reply-To: <42541DF0.1030709@ucl.ac.uk>
References: <42541DF0.1030709@ucl.ac.uk>
Message-ID: <42541EB5.7010903@ucl.ac.uk>

Gavin Simpson wrote:
> Dear List,
> 
> I have the following problem with axis.Date, here is an artificial example:
> 
> dates <- scan(what = "character")
> "25/03/2000" "26/03/2000" "27/03/2000" "28/03/2000" "29/03/2000" 
> "30/03/2000" "31/03/2000" "01/04/2000" "02/04/2000" "03/04/2000" 
> "04/04/2000" "05/04/2000"
> 
> dates <- as.Date(as.character(dates), format = "%d/%m/%Y")
> vals <- rnorm(12)
> plot(x = dates, y = vals, axes = FALSE)
> axis(side = 2)
> box()
> axis.Date(side = 1, x = dates, labels = "")
> Error in axis(side, at = z, labels = labels, ...) :
>         formal argument "labels" matched by multiple actual arguments
> 
> Which arises because axis.Date has this in the function:
> axis.Date
> function (side, x, at, format, ...)
> {
>     ...
>     labels <- format.Date(z, format = format)
>     axis(side, at = z, labels = labels, ...)
>     invisible()
> }
> 

Sorry, forgot the all important:

version
          _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status   beta
major    2
minor    1.0
year     2005
month    04
day      06
language R

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

From rmh at temple.edu  Wed Apr  6 21:07:32 2005
From: rmh at temple.edu (rmh@temple.edu)
Date: Wed Apr  6 21:07:40 2005
Subject: [Rd] bug in color handling in lattice (PR#7777)
Message-ID: <20050406190732.4104ECA6A@slim.kubism.ku.dk>

# Your mailer is set to "none" (default on Windows),
# hence we cannot send the bug report directly from R.
# Please copy the bug report (after finishing it) to
# your favorite email program and send it to
#
#       r-bugs@r-project.org
#
######################################################

## open a new trellis.device
trellis.device()

## works normally
xyplot(rnorm(10) ~ I(1:10), panel=function(...) {
  panel.axis(side="b")
})

## invalid color name
xyplot(rnorm(10) ~ I(1:10), panel=function(...) {
  panel.axis(side="b", line.col="invisible")
})

## repeat of previously working example.
## still an invalid color name.
## It is necesary to dev.off() in order to continue.
xyplot(rnorm(10) ~ I(1:10), panel=function(...) {
  panel.axis(side="b")
})






> search()
[1] ".GlobalEnv"        "package:methods"   "package:stats"    
[4] "package:graphics"  "package:grDevices" "package:utils"    
[7] "package:datasets"  "Autoloads"         "package:base"     
> ls()
[1] "last.warning"
> ## open a new trellis.device
> trellis.device()
Error: couldn't find function "trellis.device"
> 
> library(lattice)
> ## open a new trellis.device
> trellis.device()
> 
> ## works normally
> xyplot(rnorm(10) ~ I(1:10), panel=function(...) {
+   panel.axis(side="b")
+ })
> 
> ## invalid color name
> xyplot(rnorm(10) ~ I(1:10), panel=function(...) {
+   panel.axis(side="b", line.col="invisible")
+ })
Error in grid.Call.graphics("L_segments", x$x0, x$y0, x$x1, x$y1) : 
        invalid color name
> 
> ## repeat of previously working example.
> ## still an invalid color name.
> ## It is necesary to dev.off() in order to continue.
> xyplot(rnorm(10) ~ I(1:10), panel=function(...) {
+   panel.axis(side="b")
+ })
Error in grid.newpage() : invalid color name
>


--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 0.1
 year = 2004
 month = 11
 day = 15
 language = R

Windows XP Home Edition (build 2600) Service Pack 2.0

Search Path:
 .GlobalEnv, package:lattice, package:methods, package:stats, package:graphics, package:grDevices, 
package:utils, package:datasets, Autoloads, package:base

From rich.fitzjohn at gmail.com  Thu Apr  7 09:07:42 2005
From: rich.fitzjohn at gmail.com (Rich FitzJohn)
Date: Thu Apr  7 09:07:51 2005
Subject: [Rd] HP-UX and IRIX recent builds? Any other rare platforms?
In-Reply-To: <Pine.LNX.4.61.0504060854100.19609@gannet.stats>
References: <Pine.LNX.4.61.0504060854100.19609@gannet.stats>
Message-ID: <5934ae5705040700072a421013@mail.gmail.com>

Hi,

Not that rare presumably, but I've just got R up and running on NetBSD
2.0/i386, using gcc 3.3.3, straight from the packages collection (this
does apply a few patches to the configure script, and I have not
examined what they are).

make check does fail, however, as it cannot load package tcktk.  There
is a core dump, but I have no idea how to extract anything useful from
that (and presumably need to recompile R with debugging information
turned on).  As I don't use this package, it doesn't bother me, but
I'm happy to do any investigating.  (Since it seems relevant, I have
tcl 8.4.9).

I'll probably have a shot at NetBSD/alpha once R-2.1.0 is released.

Cheers,
Rich

On Apr 6, 2005 8:07 PM, Prof Brian Ripley <ripley@stats.ox.ac.uk> wrote:
> I am revising the section in R-admin on platforms.  When I asked about
> locales earlier this year I got no reply about HP-UX and IRIX, so I will
> presume that no one has built R on those OSes recently.  If you have,
> please send me the OS number and the flags you used.
> 
> Platforms where I have seen recent reports:
> 
> Linux
> MacOS X
> Solaris 8, 9, 10   (any Solaris 7 users please let me know)
> AIX 5.1 and 5.2
> FreeBSD
> 
> and less recently, OSF/1.
> 
> --
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


-- 
Rich FitzJohn
rich.fitzjohn <at> gmail.com   |    http://homepages.paradise.net.nz/richa183
                      You are in a maze of twisty little functions, all alike

From chienyu at stat.sinica.edu.tw  Thu Apr  7 10:51:41 2005
From: chienyu at stat.sinica.edu.tw (chienyu@stat.sinica.edu.tw)
Date: Thu Apr  7 10:51:49 2005
Subject: [Rd] about mantelhaen.test (PR#7779)
Message-ID: <20050407085141.920DCCA5A@slim.kubism.ku.dk>

Full_Name: Chien-yu Peng
Version: 2.0.1
OS: Windows XP Professional
Submission from: (NULL) (140.109.72.181)


Dear all:
     Although I don't know you, I am thankful for your help.
     When I use the function mantelhaen.test for R x C x K (R, C > 2) table,
the output is not the same as SAS's. I don't know that the result consist with
one of SAS's. But it works correctly for 2 x 2 x K table.
In addition, the function mantelhaen.test does not contain such as test for
general association, test for row means scores differ, and test for nonzero
correlation in SAS.

Could you tell me "Is it something wrong in the function (mantelhaen.test) for R
x C x K (R, C > 2) table"?

Therefore, I modify part of the function such that output looks as the same as
SASs.

mh.test <- function(x) {         
    if (any(apply(x, 3, sum) < 2)) 
        stop("sample size in each stratum must be > 1")
    I <- dim(x)[1];    J <- dim(x)[2];    K <- dim(x)[3]
    df_GMH <- (I - 1) * (J - 1);    df_SMH <- I - 1;    df_CSMH <- 1
    A_GMH <- cbind(diag(I-1), 0) %x% cbind(diag(J-1), 0)
    A_SMH <- cbind(diag(I-1), 0) %x% t(1:J)
    A_CSMH <- t(1:I) %x% t(1:J)
    Y_GMH <- matrix(0, nc = 1, nr = df_GMH)
    Y_SMH <- matrix(0, nc = 1, nr = df_SMH)
    Y_CSMH <- matrix(0, nc = 1, nr = df_CSMH)
    S_GMH <- matrix(0, nc = df_GMH, nr = df_GMH)
    S_SMH <- matrix(0, nc = df_SMH, nr = df_SMH)
    S_CSMH <- matrix(0, nc = df_CSMH, nr = df_CSMH)
    for(k in 1:K) {
        V <- NULL
        f <- x[, , k]
        ntot <- sum(f)
        p_ip <- apply(f, 1, sum) / ntot
        p_pj <- apply(f, 2, sum) / ntot
        m <- p_ip %x% p_pj * ntot
        V <- ntot^2 * ((diag(p_ip) - p_ip %*% t(p_ip)) %x% (diag(p_pj) - p_pj
%*% t(p_pj))) / (ntot-1)
        Y_GMH <- Y_GMH + A_GMH %*% (c(t(f)) - m)
        Y_SMH <- Y_SMH + A_SMH %*% (c(t(f)) - m)
        Y_CSMH <- Y_CSMH + A_CSMH %*% (c(t(f)) - m)
        S_GMH <- S_GMH + A_GMH %*% V %*% t(A_GMH)
        S_SMH <- S_SMH + A_SMH %*% V %*% t(A_SMH)
        S_CSMH <- S_CSMH + A_CSMH %*% V %*% t(A_CSMH)
    }
    Q_GMH <- t(Y_GMH) %*% solve(S_GMH) %*% Y_GMH
    Q_SMH <- t(Y_SMH) %*% solve(S_SMH) %*% Y_SMH
    Q_CSMH <- t(Y_CSMH) %*% solve(S_CSMH) %*% Y_CSMH
    STATISTIC <- c(Q_CSMH, Q_SMH, Q_GMH)
    PARAMETER <- c(df_CSMH, df_SMH, df_GMH)
    PVAL <- pchisq(STATISTIC, PARAMETER, lower = FALSE)
    result <- cbind(STATISTIC, PARAMETER, PVAL)
    rownames(result) <- list("Nonzero Correlation", "Row Mean Scores Differ",
"General Association")
    colnames(result) <- list("Statistic", "df", "p-value")
    return (result)
}

x <- array(c(23,23,20,24,7,10,13,10,2,5,5,6,18,18,13,9,6,6,13,15,1,2,2,2,8,12,11,7,6,4,6,7,3,4,2,4,12,15,14,13,9,3,8,6,1,2,3,4),
dim = c(4,3,4))

mh.test(x)
                       Statistic df    p-value
Nonzero Correlation      6.34043  1 0.01180163
Row Mean Scores Differ   6.59013  3 0.08617498
General Association     10.59828  6 0.10161441

From plummer at iarc.fr  Thu Apr  7 15:26:21 2005
From: plummer at iarc.fr (Martyn Plummer)
Date: Thu Apr  7 15:28:31 2005
Subject: [Rd] R 2.1.0 (beta) on IRIX
Message-ID: <1112880381.24287.56.camel@seurat>

I'm trying to compile R-beta on IRIX using the native MipsPro 7.4
compilers, without great satisfaction.  A list of problems is given
below, and any advice on solving them is appreciated.

Martyn

Configuration:
-------------

Here are the configuration options I am using

./configure CC=cc CXX=CC F77=f77 CPPFLAGS="-I/usr/freeware/include"
LDFLAGS="-L/usr/freeware/lib32" CFLAGS="-g -O2" CXXFLAGS="-g -O2"
FFLAGS="-g -O2"

The CPPFLAGS and LDFLAGS are required for readline and NLS capabilities.
The compilers are not optimized by default so you need to supply the
relevant flags.

Major problems:
--------------

1) inline function in src/extra/bzip2

The function BZ2_indexIntoF is declared inline in bzlib.c and extern in
bzlib_private.h.  The linker claims that the symbol is undefined.

This can be solved by removing the R_INLINE keyword.  I can't see
another solution, and reading these guidelines on inlining
( http://www.greenend.org.uk/rjk/2003/03/inline.html ) leaves me no
wiser.

2) IEEE arithmetic

The standalone math library fails to compile, as the compiler chokes on
the definition of ML_POSINF, ML_NEGINF and ML_NAN, e.g.

> cc-1195 cc: ERROR File = mlutils.c, Line = 130
>   The indicated floating-point operation result is out of range.
> 
>   double NA_REAL = ML_NAN;

where ML_NAN is defined as (0.0 / 0.0)  in nmath.h.  The compiler flag
 -OPT:IEEE_NaN_inf=ON is supposed to enforce IEEE arithmetic but
apparently isn't enough.

Minor problems
--------------

3) Make
IRIX make does not like continuation lines followed only by a comment.
So, for example, these lines from src/appl/Makefile.in

OBJECTS = $(SOURCES_C:.c=.o) $(SOURCES_F:.f=.o)\
@USE_EXTERNAL_BLAS_FALSE@ blas.o @COMPILE_DOUBLE_COMPLEX_FALSE@ zgemm.o

which become

OBJECTS = $(SOURCES_C:.c=.o) $(SOURCES_F:.f=.o) \
# blas.o  zgemm.o

in the Makefile, cause an error.  I have worked around this by joining
the two lines, but the problem recurs several times in the tests
directory.  I shall probably fall back on gmake.

4) Building in a setgid directory

This isn't an IRIX-specific problem.  The administrators provide some
"scratch" space for temporary files in a setgid directory and I started
building R here.   All files have the group "sys" of which ordinary
users are not members.  This causes some difficulty with the
installation of files in src/library/<libname>/inst/po.  I can't give
the exact error message as I have accidentally deleted the file in which
I was making notes, but it's an ownership problem.

5) strptime

The problem with strptime documented in the R-admin manual is still
present on this system (release 6.5.27), although it is supposed to have
been solved in release 6.5.22m.  Briefly, is.na fails to recognize a
valid POSIX time:

> strptime("1910/1/1", "%Y/%m/%d")
[1] "1910-01-01"
> is.na(strptime("1910/1/1", "%Y/%m/%d"))
[1] TRUE

I have not tried the suggested work-around yet.

From Kurt.Hornik at wu-wien.ac.at  Thu Apr  7 16:46:22 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu Apr  7 17:28:59 2005
Subject: [Rd] about mantelhaen.test (PR#7779)
In-Reply-To: <20050407085141.920DCCA5A@slim.kubism.ku.dk>
References: <20050407085141.920DCCA5A@slim.kubism.ku.dk>
Message-ID: <16981.18366.734945.872383@mithrandir.hornik.net>

>>>>> chienyu  writes:

> Full_Name: Chien-yu Peng
> Version: 2.0.1
> OS: Windows XP Professional
> Submission from: (NULL) (140.109.72.181)


> Dear all:
>      Although I don't know you, I am thankful for your help.
>      When I use the function mantelhaen.test for R x C x K (R, C > 2) table,
> the output is not the same as SAS's. I don't know that the result consist with
> one of SAS's. But it works correctly for 2 x 2 x K table.
> In addition, the function mantelhaen.test does not contain such as test for
> general association, test for row means scores differ, and test for nonzero
> correlation in SAS.

> Could you tell me "Is it something wrong in the function (mantelhaen.test) for R
> x C x K (R, C > 2) table"?

> Therefore, I modify part of the function such that output looks as the same as
> SASs.

> mh.test <- function(x) {         
>     if (any(apply(x, 3, sum) < 2)) 
>         stop("sample size in each stratum must be > 1")
>     I <- dim(x)[1];    J <- dim(x)[2];    K <- dim(x)[3]
>     df_GMH <- (I - 1) * (J - 1);    df_SMH <- I - 1;    df_CSMH <- 1
>     A_GMH <- cbind(diag(I-1), 0) %x% cbind(diag(J-1), 0)
>     A_SMH <- cbind(diag(I-1), 0) %x% t(1:J)
>     A_CSMH <- t(1:I) %x% t(1:J)
>     Y_GMH <- matrix(0, nc = 1, nr = df_GMH)
>     Y_SMH <- matrix(0, nc = 1, nr = df_SMH)
>     Y_CSMH <- matrix(0, nc = 1, nr = df_CSMH)
>     S_GMH <- matrix(0, nc = df_GMH, nr = df_GMH)
>     S_SMH <- matrix(0, nc = df_SMH, nr = df_SMH)
>     S_CSMH <- matrix(0, nc = df_CSMH, nr = df_CSMH)
>     for(k in 1:K) {
>         V <- NULL
>         f <- x[, , k]
>         ntot <- sum(f)
>         p_ip <- apply(f, 1, sum) / ntot
>         p_pj <- apply(f, 2, sum) / ntot
>         m <- p_ip %x% p_pj * ntot
>         V <- ntot^2 * ((diag(p_ip) - p_ip %*% t(p_ip)) %x% (diag(p_pj) - p_pj
> %*% t(p_pj))) / (ntot-1)
>         Y_GMH <- Y_GMH + A_GMH %*% (c(t(f)) - m)
>         Y_SMH <- Y_SMH + A_SMH %*% (c(t(f)) - m)
>         Y_CSMH <- Y_CSMH + A_CSMH %*% (c(t(f)) - m)
>         S_GMH <- S_GMH + A_GMH %*% V %*% t(A_GMH)
>         S_SMH <- S_SMH + A_SMH %*% V %*% t(A_SMH)
>         S_CSMH <- S_CSMH + A_CSMH %*% V %*% t(A_CSMH)
>     }
>     Q_GMH <- t(Y_GMH) %*% solve(S_GMH) %*% Y_GMH
>     Q_SMH <- t(Y_SMH) %*% solve(S_SMH) %*% Y_SMH
>     Q_CSMH <- t(Y_CSMH) %*% solve(S_CSMH) %*% Y_CSMH
>     STATISTIC <- c(Q_CSMH, Q_SMH, Q_GMH)
>     PARAMETER <- c(df_CSMH, df_SMH, df_GMH)
>     PVAL <- pchisq(STATISTIC, PARAMETER, lower = FALSE)
>     result <- cbind(STATISTIC, PARAMETER, PVAL)
>     rownames(result) <- list("Nonzero Correlation", "Row Mean Scores Differ",
> "General Association")
>     colnames(result) <- list("Statistic", "df", "p-value")
>     return (result)
> }

> x <- array(c(23,23,20,24,7,10,13,10,2,5,5,6,18,18,13,9,6,6,13,15,1,2,2,2,8,12,11,7,6,4,6,7,3,4,2,4,12,15,14,13,9,3,8,6,1,2,3,4),
> dim = c(4,3,4))

> mh.test(x)
>                        Statistic df    p-value
> Nonzero Correlation      6.34043  1 0.01180163
> Row Mean Scores Differ   6.59013  3 0.08617498
> General Association     10.59828  6 0.10161441

This is already fixed in R-devel, to be released as R 2.1.0 on Apr 18:

R> mantelhaen.test(x)

        Cochran-Mantel-Haenszel test

data:  x 
Cochran-Mantel-Haenszel M^2 = 10.5983, df = 6, p-value = 0.1016

as you get, whereas in 2.0.1, quite incorrectly

Cochran-Mantel-Haenszel M^2 = 35.9735, df = 6, p-value = 2.790e-06

Best
-k

From tlumley at u.washington.edu  Thu Apr  7 17:35:10 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Apr  7 17:35:27 2005
Subject: [Rd] about mantelhaen.test (PR#7779)
In-Reply-To: <20050407085141.920DCCA5A@slim.kubism.ku.dk>
References: <20050407085141.920DCCA5A@slim.kubism.ku.dk>
Message-ID: <Pine.A41.4.61b.0504070824220.161458@homer09.u.washington.edu>


Thanks for the report and code.

There's two parts to this: a suggested enhancement to show components of 
the (R-1)(C-1) df "general association" test that are useful for ordinal 
variables, and a bug report on the test itself: R gives 35.9 and the 
suggested code (and apparently SAS) give 10.6.  I'll look into the bug.

To be a proper replacement for mantelhaen.test your code would need to 
return an object of class "htest", the way the other test functions do. 
If the function is going to compute the test statistics for ordinal data 
It would also be better to have the option to test for differences in 
column means rather than row means, and to specify scores.

 	-thomas


On Thu, 7 Apr 2005 chienyu@stat.sinica.edu.tw wrote:

> Full_Name: Chien-yu Peng
> Version: 2.0.1
> OS: Windows XP Professional
> Submission from: (NULL) (140.109.72.181)
>
>
> Dear all:
>     Although I don't know you, I am thankful for your help.
>     When I use the function mantelhaen.test for R x C x K (R, C > 2) table,
> the output is not the same as SAS's. I don't know that the result consist with
> one of SAS's. But it works correctly for 2 x 2 x K table.
> In addition, the function mantelhaen.test does not contain such as test for
> general association, test for row means scores differ, and test for nonzero
> correlation in SAS.
>
> Could you tell me "Is it something wrong in the function (mantelhaen.test) for R
> x C x K (R, C > 2) table"?
>
> Therefore, I modify part of the function such that output looks as the same as
> SASs.
>
> mh.test <- function(x) {
>    if (any(apply(x, 3, sum) < 2))
>        stop("sample size in each stratum must be > 1")
>    I <- dim(x)[1];    J <- dim(x)[2];    K <- dim(x)[3]
>    df_GMH <- (I - 1) * (J - 1);    df_SMH <- I - 1;    df_CSMH <- 1
>    A_GMH <- cbind(diag(I-1), 0) %x% cbind(diag(J-1), 0)
>    A_SMH <- cbind(diag(I-1), 0) %x% t(1:J)
>    A_CSMH <- t(1:I) %x% t(1:J)
>    Y_GMH <- matrix(0, nc = 1, nr = df_GMH)
>    Y_SMH <- matrix(0, nc = 1, nr = df_SMH)
>    Y_CSMH <- matrix(0, nc = 1, nr = df_CSMH)
>    S_GMH <- matrix(0, nc = df_GMH, nr = df_GMH)
>    S_SMH <- matrix(0, nc = df_SMH, nr = df_SMH)
>    S_CSMH <- matrix(0, nc = df_CSMH, nr = df_CSMH)
>    for(k in 1:K) {
>        V <- NULL
>        f <- x[, , k]
>        ntot <- sum(f)
>        p_ip <- apply(f, 1, sum) / ntot
>        p_pj <- apply(f, 2, sum) / ntot
>        m <- p_ip %x% p_pj * ntot
>        V <- ntot^2 * ((diag(p_ip) - p_ip %*% t(p_ip)) %x% (diag(p_pj) - p_pj
> %*% t(p_pj))) / (ntot-1)
>        Y_GMH <- Y_GMH + A_GMH %*% (c(t(f)) - m)
>        Y_SMH <- Y_SMH + A_SMH %*% (c(t(f)) - m)
>        Y_CSMH <- Y_CSMH + A_CSMH %*% (c(t(f)) - m)
>        S_GMH <- S_GMH + A_GMH %*% V %*% t(A_GMH)
>        S_SMH <- S_SMH + A_SMH %*% V %*% t(A_SMH)
>        S_CSMH <- S_CSMH + A_CSMH %*% V %*% t(A_CSMH)
>    }
>    Q_GMH <- t(Y_GMH) %*% solve(S_GMH) %*% Y_GMH
>    Q_SMH <- t(Y_SMH) %*% solve(S_SMH) %*% Y_SMH
>    Q_CSMH <- t(Y_CSMH) %*% solve(S_CSMH) %*% Y_CSMH
>    STATISTIC <- c(Q_CSMH, Q_SMH, Q_GMH)
>    PARAMETER <- c(df_CSMH, df_SMH, df_GMH)
>    PVAL <- pchisq(STATISTIC, PARAMETER, lower = FALSE)
>    result <- cbind(STATISTIC, PARAMETER, PVAL)
>    rownames(result) <- list("Nonzero Correlation", "Row Mean Scores Differ",
> "General Association")
>    colnames(result) <- list("Statistic", "df", "p-value")
>    return (result)
> }
>
> x <- array(c(23,23,20,24,7,10,13,10,2,5,5,6,18,18,13,9,6,6,13,15,1,2,2,2,8,12,11,7,6,4,6,7,3,4,2,4,12,15,14,13,9,3,8,6,1,2,3,4),
> dim = c(4,3,4))
>
> mh.test(x)
>                       Statistic df    p-value
> Nonzero Correlation      6.34043  1 0.01180163
> Row Mean Scores Differ   6.59013  3 0.08617498
> General Association     10.59828  6 0.10161441
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley@u.washington.edu	University of Washington, Seattle

From charlie at stat.umn.edu  Thu Apr  7 18:19:17 2005
From: charlie at stat.umn.edu (Charles Geyer)
Date: Thu Apr  7 18:20:02 2005
Subject: [Rd] subversion
In-Reply-To: <200504061006.j36A6VDW017656@hypatia.math.ethz.ch>
References: <200504061006.j36A6VDW017656@hypatia.math.ethz.ch>
Message-ID: <20050407161917.GA4735@stat.umn.edu>

So R is on subversion right?  So why doesn't somebody authoritative
get r-project.org on the subversion testimonials page?

    http://subversion.tigris.org/testimonials.html

Just a suggestion.
-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie@stat.umn.edu

From andy_liaw at merck.com  Thu Apr  7 19:31:20 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Apr  7 19:32:06 2005
Subject: [Rd] R-beta 2004-04-07 build failed on AIX
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D6C@usctmx1106.merck.com>

I thought I'd give this another shot before the official release.  I tried
building R-beta_2004-04-07 on the AIX system that I have access to, and it
seemed to failed at lazy-loading survival.  I'd very much appreciate any
pointer on what to try or look for next.

1.  I set OBJECT_MODE to 64 for building 64-bit binary.

2.  I edited config.site with the following:
CC="xlc_r"
CFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto"
F77="xlf_r"
FFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -qextname"
SHLIB_LDFLAGS="-Wl,-G -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry
-Wl,-bexpall"
CXX="xlC_r"
CXXFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto"
SHLIB_CXXLDFLAGS="-qmkshrobj"

3. Ran configure with the following options:
   --with-tcltk=no --prefix=$HOME --with-readline=no
   and get the following:

R is now configured for powerpc-ibm-aix5.1.0.0

  Source directory:          ../R-beta
  Installation directory:    /SFS/user/ry/liawand

  C compiler:                xlc_r  -O -qmaxmem=-1 -qarch=auto -qtune=auto
  C++ compiler:              xlC_r  -O -qmaxmem=-1 -qarch=auto -qtune=auto
  Fortran compiler:          xlf_r  -O -qmaxmem=-1 -qarch=auto -qtune=auto
-qext
name

  Interfaces supported:      X11
  External libraries:        
  Additional capabilities:   MBCS, NLS
  Options enabled:           R profiling

  Recommended packages:      yes

4.  Ran `gmake', which produced the following:

[...]
xlc_r -Wl,-G -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry -Wl,-bexpall
-Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry -Wl,-bexpall
-Wl,-bI:/SFS/user/ry/liawand/R/Rbuild/etc/R.exp -L/usr/local/lib -o
survival.so agexact.o agfit2.o agfit3.o agfit5.o agfit_null.o agmart.o
agmart2.o agscore.o agsurv1.o agsurv2.o agsurv3.o char_date.o chinv2.o
chinv3.o cholesky2.o cholesky3.o chsolve2.o chsolve3.o cox_Rcallback.o
coxdetail.o coxfit2.o coxfit5.o coxmart.o coxph_wtest.o coxscho.o coxscore.o
dmatrix.o doloop.o pyears1.o pyears2.o pyears3.o pystep.o surv_callback.o
survdiff2.o survfit2.o survfit3.o survindex2.o survindex3.o survreg2.o
survreg3.o survreg4.o survreg5.o  -lm 
gmake[3]: Leaving directory `/ltmp/R.INSTALL.5603432/survival/src'
** R
** data
**  moving datasets to lazyload DB
** inst
** preparing package for lazy loading
/SFS/user/ry/liawand/R/Rbuild/bin/INSTALL[325]: 5677292 Illegal
instruction(coredump)
ERROR: lazy loading failed for package 'survival'
gmake[2]: *** [survival.ts] Error 1
gmake[2]: Leaving directory
`/SFS/user/ry/liawand/R/Rbuild/src/library/Recommended'
gmake[1]: *** [recommended-packages] Error 2
gmake[1]: Leaving directory
`/SFS/user/ry/liawand/R/Rbuild/src/library/Recommended'
gmake: *** [stamp-recommended] Error 2

Best,
Andy

From andy_liaw at merck.com  Thu Apr  7 21:39:44 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Apr  7 21:40:28 2005
Subject: [Rd] a couple of things about ":"
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D72@usctmx1106.merck.com>

Dear R-devel,

A colleague was recently surprised by the behavior of the ":" operator (as
sequence generator), so I decided to dig a little bit.  Here are a couple of
things I found.

-  ?":" seems a bit imprecise.  The Details section says:

`The operator : and the seq(from, to) form generate the sequence from,
from+1, ..., to.'

but `to' is not necessarily included in the output; e.g.,

> 0.5:3
[1] 0.5 1.5 2.5

Then it says: `The second form generates from, from+by, ..., up to the
sequence value less than or equal to to.'  That's not necessarily true,
either, if `by' is negative:

> 0.5:-3
[1]  0.5 -0.5 -1.5 -2.5

- It seems counter-intuitive to allow non-integer values as operand for ":".
It also seems a bit odd that 1:2 returns something with storage.mode
integer, whereas 0.5:2 gives doubles.  Would it make sense to disallow
non-integer operands to ":"?  I can't think of a situation when non-integer
operands for ":" would be good...

Best,
Andy

From tlumley at u.washington.edu  Thu Apr  7 23:13:47 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Apr  7 23:13:58 2005
Subject: [Rd] a couple of things about ":"
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D72@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D72@usctmx1106.merck.com>
Message-ID: <Pine.A41.4.61b.0504071410040.346778@homer12.u.washington.edu>

On Thu, 7 Apr 2005, Liaw, Andy wrote:

> - It seems counter-intuitive to allow non-integer values as operand for ":".
> It also seems a bit odd that 1:2 returns something with storage.mode
> integer, whereas 0.5:2 gives doubles.  Would it make sense to disallow
> non-integer operands to ":"?  I can't think of a situation when non-integer
> operands for ":" would be good...
>

It depends on what you mean by non-integer.  You certainly want to allow 
operand with storage.mode "double".  You might want to exclude 
non-integers, but then you have problems with rounding:

   a<-sqrt(2)
   b<-sqrt(3)
   (a^2):(b^2)

would fail.  Allowing non-integers up to some tolerance would be needed, 
but then there isn't much reason to forbid 0.5:2, and someone might have a 
use for it.


 	-thomas

From paul at stat.auckland.ac.nz  Thu Apr  7 23:33:14 2005
From: paul at stat.auckland.ac.nz (paul@stat.auckland.ac.nz)
Date: Thu Apr  7 23:33:24 2005
Subject: [Rd] palette bug (PR#7780)
Message-ID: <20050407213314.C0D76CA4C@slim.kubism.ku.dk>

Full_Name: Paul Murrell
Version: 1.9.* and up at least
OS: doesn't matter
Submission from: (NULL) (130.216.50.118)
Submitted by: paul


As reported by Earl Glynn, if you do the following ...

n <- 5
par(mfrow = c(2,2))
palette("default")
barplot(1:25,col = 1:25)
palette(rainbow(n))
barplot(1:25,col = 1:25)
palette(rgb((0:15)/15, g=0,b=0, names=paste("red",0:15,sep=".")))
barplot(1:25,col = 1:25)

... then refresh the graphics window (e.g. resize it) all three plots end up
using the *last* palette (not three different palettes as originally drawn).

This is happening because the setting of the R graphics palette is not being
recorded on the R graphics display list.

Even worse, the R graphics palette is global to the R session, not per-device,
so simply recording the setting of the palette on the (per-device) display list
would only create a more subtle undesirable effect.

A possible solution is to make a per-device palette (and record the setting of
the palette on the display list).

Paul

From pfortini at wyeth.com  Thu Apr  7 23:41:08 2005
From: pfortini at wyeth.com (pfortini@wyeth.com)
Date: Thu Apr  7 23:41:15 2005
Subject: [Rd] complex tangent (PR#7781)
Message-ID: <20050407214108.A4A5FCA4D@slim.kubism.ku.dk>

Full_Name: Peter Fortini
Version: 2.0.1
OS: Windows 2000
Submission from: (NULL) (65.246.187.164)


When the imaginary part of the argument is very large, the complex tangent
function returns 0+NaNi.  For example, tan(1+1000i)=0+NaNi; it should be 0+1i

Easy to fix in complex.c, as the original NaN came from division of sinh and
cosh that had reached machine infinity. 

static void z_tan(Rcomplex *r, Rcomplex *z)
{
    double x2, y2, den;
    x2 = 2.0 * z->r;
    y2 = 2.0 * z->i;
    den = cos(x2) + cosh(y2);
    r->r = sin(x2)/den;
    /* any limit above about log(DBL_EPSILON) will do */
    if (fabs(r->i) < 40.0) 
      r->i = sinh(y2)/den;
    else
      r->i = 1.0;
}

From tlumley at u.washington.edu  Fri Apr  8 00:16:32 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri Apr  8 00:17:48 2005
Subject: [Rd] complex tangent (PR#7781)
In-Reply-To: <20050407214108.A4A5FCA4D@slim.kubism.ku.dk>
References: <20050407214108.A4A5FCA4D@slim.kubism.ku.dk>
Message-ID: <Pine.A41.4.61b.0504071510080.346778@homer12.u.washington.edu>


On Thu, 7 Apr 2005 pfortini@wyeth.com wrote:
>
> static void z_tan(Rcomplex *r, Rcomplex *z)
> {
>    double x2, y2, den;
>    x2 = 2.0 * z->r;
>    y2 = 2.0 * z->i;
>    den = cos(x2) + cosh(y2);
>    r->r = sin(x2)/den;
>    /* any limit above about log(DBL_EPSILON) will do */
>    if (fabs(r->i) < 40.0)

You need z->i (or y2) here, r->i hasn't been initialized yet. Otherwise, 
yes.


 	-thomas

From bates at stat.wisc.edu  Fri Apr  8 00:20:09 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Apr  8 00:21:09 2005
Subject: [Rd] subversion
In-Reply-To: <20050407161917.GA4735@stat.umn.edu>
References: <200504061006.j36A6VDW017656@hypatia.math.ethz.ch>
	<20050407161917.GA4735@stat.umn.edu>
Message-ID: <4255B219.7030308@stat.wisc.edu>

Charles Geyer wrote:
> So R is on subversion right?  So why doesn't somebody authoritative
> get r-project.org on the subversion testimonials page?
> 
>     http://subversion.tigris.org/testimonials.html
> 
> Just a suggestion.

Considering the number of times that the subversion server has locked up 
on us I'm not sure we want to give a testimonial yet.  I'd wait until 
Martin feels that it is possible for him to go away for a weekend 
without worrying about the server.

From btyner at stat.purdue.edu  Fri Apr  8 03:42:58 2005
From: btyner at stat.purdue.edu (btyner@stat.purdue.edu)
Date: Fri Apr  8 03:43:05 2005
Subject: [Rd] fisher.g.test.single cannot handle time series longer than 341
	(PR#7782)
Message-ID: <20050408014258.67F9BCA4C@slim.kubism.ku.dk>

Full_Name: Benjamin Tyner
Version: R version 2.0.1, 2004-11-15
OS: Linux (kernel version 2.6.10-1.770_FC3)
Submission from: (NULL) (4.64.8.220)


On my build, for example:

library(GeneTS)
fisher.g.test.single(rnorm(341)) #this works fine
fisher.g.test.single(rnorm(342)) #this fails with the following error:

"Error in if (pval > 1) pval <- 1 : missing value where TRUE/FALSE needed"

The error always occurs for n>=342. This also affects the behavior of
fisher.g.test. I suspect the problem may lie in periodogram.spec

From andy_liaw at merck.com  Fri Apr  8 03:45:29 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Apr  8 03:46:02 2005
Subject: [Rd] a couple of things about ":"
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D76@usctmx1106.merck.com>

> From: Thomas Lumley 
> 
> On Thu, 7 Apr 2005, Liaw, Andy wrote:
> 
> > - It seems counter-intuitive to allow non-integer values as 
> operand for ":".
> > It also seems a bit odd that 1:2 returns something with storage.mode
> > integer, whereas 0.5:2 gives doubles.  Would it make sense 
> to disallow
> > non-integer operands to ":"?  I can't think of a situation 
> when non-integer
> > operands for ":" would be good...
> >
> 
> It depends on what you mean by non-integer.  You certainly 
> want to allow 
> operand with storage.mode "double".  You might want to exclude 
> non-integers, but then you have problems with rounding:
> 
>    a<-sqrt(2)
>    b<-sqrt(3)
>    (a^2):(b^2)
> 
> would fail.  Allowing non-integers up to some tolerance would 
> be needed, 

I think the fact that we don't need to do as.integer(1):as.integer(3) in
order for ":" to return an integer vector must means that there's some
tolerance built-in.  (I know, I should just check the source...)  Here are
some experiments (R-devel 2005-03-11 on WinXPPro):

> storage.mode((1 + .Machine$double.eps):3)
[1] "double"
> storage.mode((1 - .Machine$double.eps/4):3)
[1] "integer"
> storage.mode((1 + .Machine$double.eps/4):3)
[1] "integer"
> storage.mode((1 + .Machine$double.eps/3):3)
[1] "integer"
> storage.mode((1 - .Machine$double.eps/3):3)
[1] "double"

> but then there isn't much reason to forbid 0.5:2, and someone 
> might have a use for it.

IMHO that's more of a trap than a `feature'.  At least to me it's not
immediately obvious what one should expect when the first operand is an
`obvious' non-integer such as 0.5.  For such sequences, I'd say one should
really use seq() instead of ":".  (I'd go as far as saying that something
like 0.5:2 is an abuse.)

BTW, here's something that surprised me:

> x <- 1:10
> i <- (1 + 1e-15):5
> i
[1] 1 2 3 4 5
> x[i]
[1] 1 2 3 4 5
> i <- (1 - 1e-15):5
> i
[1] 1 2 3 4 5
> x[i]
[1] 1 2 3 4

The reason for this, of course, is that (as ?"[" explains):

> as.integer(i)
[1] 0 1 2 3 4

My wish would be for ":" to coerce its operands to integers, perhaps with a
bit more tolerance, and always return object of integer storage mode.

Cheers,
Andy
 
> 
>  	-thomas
> 
> 
>

From ripley at stats.ox.ac.uk  Fri Apr  8 08:21:55 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Apr  8 08:22:04 2005
Subject: Inappropriate bug report on package GeneTS (was [Rd]
	fisher.g.test.single
	cannot handle time series longer than 341 (PR#7782))
In-Reply-To: <20050408014258.67F9BCA4C@slim.kubism.ku.dk>
References: <20050408014258.67F9BCA4C@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0504080714560.20391@gannet.stats>

The FAQ says:

    Bug reports on contributed packages should be sent first to the package
    maintainer, and only submitted to the R-bugs repository by package
    maintainers, mentioning the package in the subject line.

You have not mentioned the package in the subject line, and you are not 
the stated maintainer. The report on R-bugs has been closed.

On Fri, 8 Apr 2005 btyner@stat.purdue.edu wrote:

> Full_Name: Benjamin Tyner
> Version: R version 2.0.1, 2004-11-15
> OS: Linux (kernel version 2.6.10-1.770_FC3)
> Submission from: (NULL) (4.64.8.220)
>
>
> On my build, for example:
>
> library(GeneTS)
> fisher.g.test.single(rnorm(341)) #this works fine
> fisher.g.test.single(rnorm(342)) #this fails with the following error:
>
> "Error in if (pval > 1) pval <- 1 : missing value where TRUE/FALSE needed"
>
> The error always occurs for n>=342. This also affects the behavior of
> fisher.g.test. I suspect the problem may lie in periodogram.spec
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Fri Apr  8 12:02:31 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Apr  8 12:03:54 2005
Subject: [Rd] R-beta 2004-04-07 build failed on AIX
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D6C@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D6C@usctmx1106.merck.com>
Message-ID: <x2u0mhwpqg.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw@merck.com> writes:

> ** data
> **  moving datasets to lazyload DB
> ** inst
> ** preparing package for lazy loading
> /SFS/user/ry/liawand/R/Rbuild/bin/INSTALL[325]: 5677292 Illegal
> instruction(coredump)

Illegal instruction? Sound like it is either a compiler error or a
stray pointer overwriting code or stack. Can you get a handle on this
with a debugger?


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From sturtz at statistik.uni-dortmund.de  Fri Apr  8 13:18:36 2005
From: sturtz at statistik.uni-dortmund.de (Sibylle Sturtz)
Date: Fri Apr  8 13:18:17 2005
Subject: [Rd] new R package BRugs
Message-ID: <4256688C.1000202@statistik.uni-dortmund.de>

Hi,

this is the first announcement of a *developer version* of the R package 
BRugs, which is based on OpenBUGS 2.1.0.

OpenBUGS 2.1.0 has been released earlier this week 
(http://mathstat.helsinki.fi/openbugs/).

BRugs contains a complete OpenBUGS installation as well as R code to 
access OpenBUGS functionality from R. Simply install the package, load 
it and say ?BRugs and ?BRugsFit respectively.

Sources (BRugs_0.2-0.tar.gz) and Windows binaries (BRugs_0.2-0.zip) are 
available from
http://www.statistik.uni-dortmund.de/~ligges/BRugs/
(*this is a temporary directory that will be removed after we think 
BRugs is really stable*).

Feedback, bug reports and feature requests to 
sturtz@statistik.uni-dortmund.de are welcome!

All the best,
Sibylle Sturtz and Uwe Ligges

From Friedrich.Leisch at tuwien.ac.at  Fri Apr  8 13:19:51 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Fri Apr  8 13:19:59 2005
Subject: [Rd] orphaning CRAN packages
Message-ID: <16982.26839.379527.281168@galadriel.ci.tuwien.ac.at>


Dear R Developers,

the following CRAN packages do not cleanly pass R CMD check for quite
some time now and did not have any updates since the time
given. Several attempts by the CRAN admins to contact the package
maintainers had no success.

norm, 1.0-9, 2002-05-07, WARN
sound, 0.6, 2002-08-31, WARN
Bhat, 0.9-07, 2003-11-04, WARN
HI, 0.1, 2003-11-04, WARN
mmlcr, 1.3.2, 2003-11-15, WARN
mvnmle, 0.1-4, 2003-08-21, WARN

If you are the author or maintainer of one of these packages, or a
user and are interested that the package stays in the main CRAN
package area (including binaries for various platforms), please
consider taking over as maintainer of the respective
package. Otheriwse we will orphanize the packages after the release of
R 2.1.0 in 10 days.


In addition, the Orphaned directory of CRAN currently contains

anm,2004-09-30,1.9.1
fdim,2004-09-30,1.9.1
kza,2005-01-15,2.0.1
meanscore,2004-09-30,1.9.1
npmc,2004-09-30,1.9.1
phyloarray,2004-09-30,1.9.1
seao.gui,2004-09-30,1.9.1
seao,2004-09-30,1.9.1
twostage,2004-09-30,1.9.1


We try hard to keep all packages on CRAN working "out of the box",
hence we need to remove packages that are no longer actively
maintained.

Best,
Fritz

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch

From blindglobe at gmail.com  Fri Apr  8 13:51:18 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Fri Apr  8 13:51:26 2005
Subject: [Rd] new R package BRugs
In-Reply-To: <4256688C.1000202@statistik.uni-dortmund.de>
References: <4256688C.1000202@statistik.uni-dortmund.de>
Message-ID: <1abe3fa9050408045156d8ff80@mail.gmail.com>

Is this an MS Windows only package?  The source package contains DLL's.


On Apr 8, 2005 1:18 PM, Sibylle Sturtz <sturtz@statistik.uni-dortmund.de> wrote:
> Hi,
> 
> this is the first announcement of a *developer version* of the R package
> BRugs, which is based on OpenBUGS 2.1.0.
> 
> OpenBUGS 2.1.0 has been released earlier this week
> (http://mathstat.helsinki.fi/openbugs/).
> 
> BRugs contains a complete OpenBUGS installation as well as R code to
> access OpenBUGS functionality from R. Simply install the package, load
> it and say ?BRugs and ?BRugsFit respectively.
> 
> Sources (BRugs_0.2-0.tar.gz) and Windows binaries (BRugs_0.2-0.zip) are
> available from
> http://www.statistik.uni-dortmund.de/~ligges/BRugs/
> (*this is a temporary directory that will be removed after we think
> BRugs is really stable*).
> 
> Feedback, bug reports and feature requests to
> sturtz@statistik.uni-dortmund.de are welcome!
> 
> All the best,
> Sibylle Sturtz and Uwe Ligges
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From sturtz at statistik.uni-dortmund.de  Fri Apr  8 14:01:48 2005
From: sturtz at statistik.uni-dortmund.de (Sibylle Sturtz)
Date: Fri Apr  8 14:01:28 2005
Subject: [Rd] new R package BRugs
In-Reply-To: <1abe3fa9050408045156d8ff80@mail.gmail.com>
References: <4256688C.1000202@statistik.uni-dortmund.de>
	<1abe3fa9050408045156d8ff80@mail.gmail.com>
Message-ID: <425672AC.7010102@statistik.uni-dortmund.de>

This package is supposed to work on Windows and it may alos work under 
some flavours of Linux. (It runs on Andrew Thomas? box but not on ours 
:-) ) For the interface the OpenBUGS sources need to be compiled with 
Component Pascal. For R, we are using the .dll and .so provided by 
OpenBUGS.

Sibylle

A.J. Rossini wrote:
> Is this an MS Windows only package?  The source package contains DLL's.
> 
> 
> On Apr 8, 2005 1:18 PM, Sibylle Sturtz <sturtz@statistik.uni-dortmund.de> wrote:
> 
>>Hi,
>>
>>this is the first announcement of a *developer version* of the R package
>>BRugs, which is based on OpenBUGS 2.1.0.
>>
>>OpenBUGS 2.1.0 has been released earlier this week
>>(http://mathstat.helsinki.fi/openbugs/).
>>
>>BRugs contains a complete OpenBUGS installation as well as R code to
>>access OpenBUGS functionality from R. Simply install the package, load
>>it and say ?BRugs and ?BRugsFit respectively.
>>
>>Sources (BRugs_0.2-0.tar.gz) and Windows binaries (BRugs_0.2-0.zip) are
>>available from
>>http://www.statistik.uni-dortmund.de/~ligges/BRugs/
>>(*this is a temporary directory that will be removed after we think
>>BRugs is really stable*).
>>
>>Feedback, bug reports and feature requests to
>>sturtz@statistik.uni-dortmund.de are welcome!
>>
>>All the best,
>>Sibylle Sturtz and Uwe Ligges
>>
>>______________________________________________
>>R-devel@stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 
>

From blindglobe at gmail.com  Fri Apr  8 14:19:00 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Fri Apr  8 14:19:10 2005
Subject: [Rd] new R package BRugs
In-Reply-To: <425672AC.7010102@statistik.uni-dortmund.de>
References: <4256688C.1000202@statistik.uni-dortmund.de>
	<1abe3fa9050408045156d8ff80@mail.gmail.com>
	<425672AC.7010102@statistik.uni-dortmund.de>
Message-ID: <1abe3fa905040805195d353454@mail.gmail.com>

where does one find a Component Pascal compiler?  Does anyone know
which one the OpenBUGS project is using?

On Apr 8, 2005 2:01 PM, Sibylle Sturtz <sturtz@statistik.uni-dortmund.de> wrote:
> This package is supposed to work on Windows and it may alos work under
> some flavours of Linux. (It runs on Andrew Thomas? box but not on ours
> :-) ) For the interface the OpenBUGS sources need to be compiled with
> Component Pascal. For R, we are using the .dll and .so provided by
> OpenBUGS.
> 
> Sibylle
> 
> A.J. Rossini wrote:
> > Is this an MS Windows only package?  The source package contains DLL's.
> >
> >
> > On Apr 8, 2005 1:18 PM, Sibylle Sturtz <sturtz@statistik.uni-dortmund.de> wrote:
> >
> >>Hi,
> >>
> >>this is the first announcement of a *developer version* of the R package
> >>BRugs, which is based on OpenBUGS 2.1.0.
> >>
> >>OpenBUGS 2.1.0 has been released earlier this week
> >>(http://mathstat.helsinki.fi/openbugs/).
> >>
> >>BRugs contains a complete OpenBUGS installation as well as R code to
> >>access OpenBUGS functionality from R. Simply install the package, load
> >>it and say ?BRugs and ?BRugsFit respectively.
> >>
> >>Sources (BRugs_0.2-0.tar.gz) and Windows binaries (BRugs_0.2-0.zip) are
> >>available from
> >>http://www.statistik.uni-dortmund.de/~ligges/BRugs/
> >>(*this is a temporary directory that will be removed after we think
> >>BRugs is really stable*).
> >>
> >>Feedback, bug reports and feature requests to
> >>sturtz@statistik.uni-dortmund.de are welcome!
> >>
> >>All the best,
> >>Sibylle Sturtz and Uwe Ligges
> >>
> >>______________________________________________
> >>R-devel@stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >
> >
> 


-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From Ted.Harding at nessie.mcc.ac.uk  Fri Apr  8 15:16:00 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri Apr  8 15:23:36 2005
Subject: [Rd] new R package BRugs
In-Reply-To: <1abe3fa905040805195d353454@mail.gmail.com>
Message-ID: <XFMail.050408141600.Ted.Harding@nessie.mcc.ac.uk>

On 08-Apr-05 A.J. Rossini wrote:
> where does one find a Component Pascal compiler?  Does anyone
> know which one the OpenBUGS project is using?

I hesitate to suggest that Tony Rossini might be confused,
but I think I am (though I feel a bit confused about that
too)!

One piece of information which may be helpful (though it
hasn't cleared things up for me) is from

  http://www.math.helsinki.fi/openbugs/

    Software

    A combined version of the OpenBUGS programme for
    Windows and Linux personel computers can be downloaded
    as a .zip file from here. There are some instructions
    for installation on this page.

    The Windows version of OpenBUGS contains three seperate
    exectutable files: winbugs.exe for running the GUI
    Windows version, the shortcut BackBUGS for running a
    non interative script in WinBUGS and ClassicBUGS,
    a non Windows command line version of BUGS. BRugs,
    a set of R functions which reproduce the functionality
    of the GUI interface, is also avaliable to Windows users.
    The Linux version of OpenBUGS consists of a single shell
    script, LinBUGS, which provides the "ClassicBUGS" interface.
    At present the BRugs R functions do not work under Linux.

    The binary distribution of the programme comes with
    documentation in two formats: *.odc the native WinBUGS
    format, and *.html which can also be read on Linux personal
    computers using a web browser. The documentation can also
    be read online here.

    The full source code for OpenBUGS is available. The source
    code for the most recent verion (OpenBUGS 2.1.0) can be
    downloaded as a .zip file from here

    The Component Pascal source code consists of a large number
    of modules of which only a subset are required for the Linux
    personel computer platform.

As to "Component Pascal", this seems from my searches to be
a outgrowth of Oberon, and apparently at one time was called
"Garden Point Component Pascal". Garden Point originally
produced a version of Modula 2, which was required to compile
the old orignal version of BUGS (pre-WinBUGS) on Linux (which
I once did, about 10 years ago).

So it all seems to be tangled up together, with no clear
indication of what you need, nor how to do it, if you want
to get BRugs up on Linux.

As to getting hold of Component Pascal, while there is
documentation on the Oberon Website

  http://www.oberon.ch

there is no indication of how to get the software. It looks
as though (though this is not clear either) it may be a
commercial product.

Hoping this helps, if not to clarify, at least to assist
others in their searches!

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding@nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 08-Apr-05                                       Time: 14:16:00
------------------------------ XFMail ------------------------------

From ligges at statistik.uni-dortmund.de  Fri Apr  8 18:36:28 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Apr  8 18:36:22 2005
Subject: [Rd] new R package BRugs
In-Reply-To: <XFMail.050408141600.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.050408141600.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <4256B30C.50607@statistik.uni-dortmund.de>

OK, here we go (since we forgot to address the the Linux folks' problems 
explicitly - apologies!).

*In principle*, you need the 1.5 version of the BlackBox Compiler from
http://www.oberon.ch/blackbox.html

Details and documentation how to compile are available from the 
developer manual:
http://mathstat.helsinki.fi/openbugs/data/Docu/Developer%20Manual.html

*BUT*:
- We (Sibylle and Uwe) have not managed to compile OpenBUGS ourselves.
- In particular, we have not managed to get the .dll/.so compiled, and 
Andrew Thomas writes in the developer manual: "Please note I am the only 
person who has the ELF linker at present".

That's why we do ship the .so/.dll for now (and later?).

Andrew Thomas told us that the .so is supposed to work under some Linux 
versions (I have never managed to get it to work up to now, but this is 
high level on the ToDo list).
The .dll has been tested on WinNT, WinXP and WinServer2003.

Best,
Uwe



(Ted Harding) wrote:

> On 08-Apr-05 A.J. Rossini wrote:
> 
>>where does one find a Component Pascal compiler?  Does anyone
>>know which one the OpenBUGS project is using?
> 
> 
> I hesitate to suggest that Tony Rossini might be confused,
> but I think I am (though I feel a bit confused about that
> too)!
> 
> One piece of information which may be helpful (though it
> hasn't cleared things up for me) is from
> 
>   http://www.math.helsinki.fi/openbugs/
> 
>     Software
> 
>     A combined version of the OpenBUGS programme for
>     Windows and Linux personel computers can be downloaded
>     as a .zip file from here. There are some instructions
>     for installation on this page.
> 
>     The Windows version of OpenBUGS contains three seperate
>     exectutable files: winbugs.exe for running the GUI
>     Windows version, the shortcut BackBUGS for running a
>     non interative script in WinBUGS and ClassicBUGS,
>     a non Windows command line version of BUGS. BRugs,
>     a set of R functions which reproduce the functionality
>     of the GUI interface, is also avaliable to Windows users.
>     The Linux version of OpenBUGS consists of a single shell
>     script, LinBUGS, which provides the "ClassicBUGS" interface.
>     At present the BRugs R functions do not work under Linux.
> 
>     The binary distribution of the programme comes with
>     documentation in two formats: *.odc the native WinBUGS
>     format, and *.html which can also be read on Linux personal
>     computers using a web browser. The documentation can also
>     be read online here.
> 
>     The full source code for OpenBUGS is available. The source
>     code for the most recent verion (OpenBUGS 2.1.0) can be
>     downloaded as a .zip file from here
> 
>     The Component Pascal source code consists of a large number
>     of modules of which only a subset are required for the Linux
>     personel computer platform.
> 
> As to "Component Pascal", this seems from my searches to be
> a outgrowth of Oberon, and apparently at one time was called
> "Garden Point Component Pascal". Garden Point originally
> produced a version of Modula 2, which was required to compile
> the old orignal version of BUGS (pre-WinBUGS) on Linux (which
> I once did, about 10 years ago).
> 
> So it all seems to be tangled up together, with no clear
> indication of what you need, nor how to do it, if you want
> to get BRugs up on Linux.
> 
> As to getting hold of Component Pascal, while there is
> documentation on the Oberon Website
> 
>   http://www.oberon.ch
> 
> there is no indication of how to get the software. It looks
> as though (though this is not clear either) it may be a
> commercial product.
> 
> Hoping this helps, if not to clarify, at least to assist
> others in their searches!
> 
> Best wishes to all,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding@nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 08-Apr-05                                       Time: 14:16:00
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From luke at stat.uiowa.edu  Fri Apr  8 18:59:23 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri Apr  8 18:59:43 2005
Subject: [Rd] makeActiveBinding warning
In-Reply-To: <4D99275E380CA94F998977EDACE548DC1AE692@extas2-hba.tas.csiro.au>
References: <4D99275E380CA94F998977EDACE548DC1AE692@extas2-hba.tas.csiro.au>
Message-ID: <Pine.LNX.4.62.0504081158230.13710@nokomis.stat.uiowa.edu>

On Wed, 6 Apr 2005 Mark.Bravington@csiro.au wrote:

> A while ago Luke Tierney remarked that the warning associated with
> 'makeActiveBinding'-- "saved workspaces with active bindings may not
> work properly when loaded into older versions of R"-- should probably be
> removed in R-devel. It's still cropping up *sporadically* with R-alpha
> of 3/4/2004, but not every time I call 'makeActiveBinding'.
>
> So, two questions:
>
> (i) is it going to go altogether with the release of R2.1? If not, I'll
> need to tweak my code to suppress the warning

It is now gone from R-devel.

> (ii) is the warning actually correct? When I experimented with this (a
> bit), it seemed to me that the binary image file contained the full
> unbound version of the object, and actually did load normally into R1.7
> (the oldest version I still have).

Yes; you have to go farther back in history than that.

luke

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From andy_liaw at merck.com  Fri Apr  8 20:04:14 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Apr  8 20:04:51 2005
Subject: [Rd] R-beta 2004-04-07 build failed on AIX
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D81@usctmx1106.merck.com>

> From: Peter Dalgaard
> 
> "Liaw, Andy" <andy_liaw@merck.com> writes:
> 
> > > From: Peter Dalgaard 
> > > 
> > > "Liaw, Andy" <andy_liaw@merck.com> writes:
> > > 
> > > > ** data
> > > > **  moving datasets to lazyload DB
> > > > ** inst
> > > > ** preparing package for lazy loading
> > > > /SFS/user/ry/liawand/R/Rbuild/bin/INSTALL[325]: 5677292 Illegal
> > > > instruction(coredump)
> > > 
> > > Illegal instruction? Sound like it is either a compiler error or a
> > > stray pointer overwriting code or stack. Can you get a 
> handle on this
> > > with a debugger?
> > 
> > Thanks, Peter, but how do I do that?  I know how to do that 
> to run R, but
> > not how to run R CMD INSTALL under a debugger...
> 
> Inside the INSTALL script, there's
> 
>       message " moving datasets to lazyload DB"
>       ## it is possible that data in a package will make use of the
>       ## code in the package, so ensure the package we have just
>       ## installed is on the library path.
>       echo "invisible(.libPaths(c(\"${lib}\", .libPaths()))); 
> tools:::data2LazyLoadDB(\"${R_PACKAGE_NAME}\", \"${lib}\")" | \
>         R_DEFAULT_PACKAGES=NULL LANG=C "${R_EXE}" --vanilla > 
> /dev/null
> 
> You could try replacing the --vanilla with -d gdb (or whichever
> debugger is relevant). I suppose you'd have to send the commands to a
> temp file rather than piping them and then within the debugger use
> 
> run --vanilla < yourtempfile

OK, after re-building R with the debug flags, I don't think I'm getting
anything useful.  GDB gives me:

gdb) run --vanilla < /ltmp/try.R
Starting program: /SFS/user/ry/liawand/R/Rbuild/bin/exec/R --vanilla <
/ltmp/try.R

Error: [tcsetpgrp failed in terminal_inferior: Not owner]
aix-thread resume: unknown pthread 19
aix-thread: fetch_registers: pthdb_pthread_context returned CALLBACK

(gdb) bt
Error: aix-thread: fetch_registers: pthdb_pthread_context returned CALLBACK

and:

Unable to Read Instructions at 0x90000000018c6d4

Anyone know what these means?

Best,
Andy
 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: 
> (+45) 35327907
> 
> 
>

From p.dalgaard at biostat.ku.dk  Fri Apr  8 20:26:49 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Apr  8 20:27:01 2005
Subject: [Rd] R-beta 2004-04-07 build failed on AIX
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D81@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D81@usctmx1106.merck.com>
Message-ID: <x28y3truom.fsf@turmalin.kubism.ku.dk>

"Liaw, Andy" <andy_liaw@merck.com> writes:

> OK, after re-building R with the debug flags, I don't think I'm getting
> anything useful.  GDB gives me:
> 
> gdb) run --vanilla < /ltmp/try.R
> Starting program: /SFS/user/ry/liawand/R/Rbuild/bin/exec/R --vanilla <
> /ltmp/try.R

Nothing in here??
 
> Error: [tcsetpgrp failed in terminal_inferior: Not owner]
> aix-thread resume: unknown pthread 19
> aix-thread: fetch_registers: pthdb_pthread_context returned CALLBACK
> 
> (gdb) bt
> Error: aix-thread: fetch_registers: pthdb_pthread_context returned CALLBACK
> 
> and:
> 
> Unable to Read Instructions at 0x90000000018c6d4
> 
> Anyone know what these means?

Not really, but a couple of thoughts:

1) Why are threads involved? Multi-threaded blas? Can you build
   without one?

2) If you blew away the stack, the object is to get to the point just
   before it happened, which means checkpoints, single-stepping and
   general attempts to bisect the path leading to the point of
   failure. Can you read the gc_count variable after the crash? It is
   sometimes useful to conditionalize breakpoints (cond 1
   gc_count==1234 etc.) 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Ted.Harding at nessie.mcc.ac.uk  Fri Apr  8 21:02:28 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri Apr  8 21:44:26 2005
Subject: [Rd] new R package BRugs
In-Reply-To: <4256B30C.50607@statistik.uni-dortmund.de>
Message-ID: <XFMail.050408181154.Ted.Harding@nessie.mcc.ac.uk>

On 08-Apr-05 Uwe Ligges wrote:
> OK, here we go (since we forgot to address the the Linux
> folks' problems explicitly - apologies!).
> [informative details snipped]

Thanks Uwe! Very useful clarifiation!

Best wishes,
Ted.

From andy_liaw at merck.com  Fri Apr  8 21:51:06 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Apr  8 21:51:59 2005
Subject: [Rd] R-beta 2004-04-07 build failed on AIX
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D84@usctmx1106.merck.com>

> From: pd@pubhealth.ku.dk
> 
> "Liaw, Andy" <andy_liaw@merck.com> writes:
> 
> > OK, after re-building R with the debug flags, I don't think 
> I'm getting
> > anything useful.  GDB gives me:
> > 
> > gdb) run --vanilla < /ltmp/try.R
> > Starting program: /SFS/user/ry/liawand/R/Rbuild/bin/exec/R 
> --vanilla <
> > /ltmp/try.R
> 
> Nothing in here??

Nada.
  
> > Error: [tcsetpgrp failed in terminal_inferior: Not owner]
> > aix-thread resume: unknown pthread 19
> > aix-thread: fetch_registers: pthdb_pthread_context returned CALLBACK
> > 
> > (gdb) bt
> > Error: aix-thread: fetch_registers: pthdb_pthread_context 
> returned CALLBACK
> > 
> > and:
> > 
> > Unable to Read Instructions at 0x90000000018c6d4
> > 
> > Anyone know what these means?
> 
> Not really, but a couple of thoughts:
> 
> 1) Why are threads involved? Multi-threaded blas? Can you build
>    without one?

No, it's using R's internal BLAS.  I see that -lpthread is in FLIBS defined
in Makeconf, so it was the Fortran compiler that wanted it.

 
> 2) If you blew away the stack, the object is to get to the point just
>    before it happened, which means checkpoints, single-stepping and
>    general attempts to bisect the path leading to the point of
>    failure. Can you read the gc_count variable after the crash? It is
>    sometimes useful to conditionalize breakpoints (cond 1
>    gc_count==1234 etc.) 

I'll keep tryin'...

Thanks!
Andy

 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: 
> (+45) 35327907
> 
> 
>

From blindglobe at gmail.com  Sat Apr  9 09:43:09 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Sat Apr  9 09:43:18 2005
Subject: [Rd] new R package BRugs
In-Reply-To: <4256B30C.50607@statistik.uni-dortmund.de>
References: <XFMail.050408141600.Ted.Harding@nessie.mcc.ac.uk>
	<4256B30C.50607@statistik.uni-dortmund.de>
Message-ID: <1abe3fa9050409004346930d27@mail.gmail.com>

On Apr 8, 2005 6:36 PM, Uwe Ligges <ligges@statistik.uni-dortmund.de> wrote:
> OK, here we go (since we forgot to address the the Linux folks' problems
> explicitly - apologies!).

Well, actually, you forgot to address everyone EXCEPT MS Windows --
not clear if you really have such a thing as a source package -- you
might want to write a version of Jun and I'd "Cross Compiling to MS
Windows" as

   "compiling binary packages for linux, distribution Y, version X1
and X2, hardware only x86, ...."

Anyway, I played a bit with 4 different compilers last night.  Not
finished yet, but to say the least, it's a mess.

If only Bayesian methods weren't so deeply entrenched at Novartis...

best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From ligges at statistik.uni-dortmund.de  Sat Apr  9 12:38:28 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Apr  9 12:34:16 2005
Subject: [Rd] orphaning CRAN packages
In-Reply-To: <16982.26839.379527.281168@galadriel.ci.tuwien.ac.at>
References: <16982.26839.379527.281168@galadriel.ci.tuwien.ac.at>
Message-ID: <4257B0A4.1020308@statistik.uni-dortmund.de>

Friedrich.Leisch@tuwien.ac.at wrote:

> Dear R Developers,
> 
> the following CRAN packages do not cleanly pass R CMD check for quite
> some time now and did not have any updates since the time
> given. Several attempts by the CRAN admins to contact the package
> maintainers had no success.
> 
> norm, 1.0-9, 2002-05-07, WARN
> sound, 0.6, 2002-08-31, WARN

Hmm, does anybody use sound extensively or does anybody use its data 
structures?

If not: tuneR contains quite a lot of the functionality of sound and I 
would agree to port missing functionality (seem to be just a few 
functions) to tuneR (which is based on S4 rather than the S3 methods 
"sound" is base on). So it won't hurt if sound is moved way from CRAN 
one day.

Uwe


> Bhat, 0.9-07, 2003-11-04, WARN
> HI, 0.1, 2003-11-04, WARN
> mmlcr, 1.3.2, 2003-11-15, WARN
> mvnmle, 0.1-4, 2003-08-21, WARN
> 
> If you are the author or maintainer of one of these packages, or a
> user and are interested that the package stays in the main CRAN
> package area (including binaries for various platforms), please
> consider taking over as maintainer of the respective
> package. Otheriwse we will orphanize the packages after the release of
> R 2.1.0 in 10 days.
> 
> 
> In addition, the Orphaned directory of CRAN currently contains
> 
> anm,2004-09-30,1.9.1
> fdim,2004-09-30,1.9.1
> kza,2005-01-15,2.0.1
> meanscore,2004-09-30,1.9.1
> npmc,2004-09-30,1.9.1
> phyloarray,2004-09-30,1.9.1
> seao.gui,2004-09-30,1.9.1
> seao,2004-09-30,1.9.1
> twostage,2004-09-30,1.9.1
> 
> 
> We try hard to keep all packages on CRAN working "out of the box",
> hence we need to remove packages that are no longer actively
> maintained.
> 
> Best,
> Fritz
>

From Ted.Harding at nessie.mcc.ac.uk  Sat Apr  9 14:02:22 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat Apr  9 14:12:00 2005
Subject: [Rd] orphaning CRAN packages
In-Reply-To: <4257B0A4.1020308@statistik.uni-dortmund.de>
Message-ID: <XFMail.050409130222.Ted.Harding@nessie.mcc.ac.uk>

On 09-Apr-05 Uwe Ligges wrote:
> Friedrich.Leisch@tuwien.ac.at wrote:
> 
>> Dear R Developers,
>> 
>> the following CRAN packages do not cleanly pass R CMD check
>> for quite some time now and did not have any updates since
>> the time given. Several attempts by the CRAN admins to contact
>> the package maintainers had no success.
>> 
>> norm, 1.0-9, 2002-05-07, WARN

It would be serious if 'norm' were to lapse, since it is
part of the 'norm+cat+mix+pan' family, and people using any
of these are likely to have occasion to use the others.

I'd offer to try to clean up 'norm' myself if only I were
up-to-date on R itself (I'm waiting for 2.1.0 to come out,
which I understand is scheduled to happen soon, yes?).

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding@nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 09-Apr-05                                       Time: 13:02:22
------------------------------ XFMail ------------------------------

From ligges at statistik.uni-dortmund.de  Sat Apr  9 14:57:15 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Apr  9 14:57:06 2005
Subject: [Rd] orphaning CRAN packages
In-Reply-To: <XFMail.050409130222.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.050409130222.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <4257D12B.6000302@statistik.uni-dortmund.de>

(Ted Harding) wrote:
> On 09-Apr-05 Uwe Ligges wrote:
> 
>>Friedrich.Leisch@tuwien.ac.at wrote:
>>
>>
>>>Dear R Developers,
>>>
>>>the following CRAN packages do not cleanly pass R CMD check
>>>for quite some time now and did not have any updates since
>>>the time given. Several attempts by the CRAN admins to contact
>>>the package maintainers had no success.
>>>
>>>norm, 1.0-9, 2002-05-07, WARN
> 
> 
> It would be serious if 'norm' were to lapse, since it is
> part of the 'norm+cat+mix+pan' family, and people using any
> of these are likely to have occasion to use the others.
> 
> I'd offer to try to clean up 'norm' myself if only I were
> up-to-date on R itself (I'm waiting for 2.1.0 to come out,
> which I understand is scheduled to happen soon, yes?).

Ted, that's great!

R-2.1.0 is scheduled to be released on April 18 (see 
http://developer.r-project.org/).

It would be even better if you could try out the recent beta release of 
R-2.1.0 right now in order to spot some possible bugs before release.

So it is the perfect occasion to clean up "norm" on R-2.1.0 beta this 
weekend. ;-)

Best,
Uwe


> Best wishes,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding@nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 09-Apr-05                                       Time: 13:02:22
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From maechler at stat.math.ethz.ch  Sat Apr  9 16:23:52 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat Apr  9 16:24:00 2005
Subject: [Rd] orphaning CRAN packages
In-Reply-To: <XFMail.050409130222.Ted.Harding@nessie.mcc.ac.uk>
References: <4257B0A4.1020308@statistik.uni-dortmund.de>
	<XFMail.050409130222.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <16983.58744.275573.577522@stat.math.ethz.ch>

>>>>> "Ted" == Ted Harding <Ted.Harding@nessie.mcc.ac.uk>
>>>>>     on Sat, 09 Apr 2005 13:02:22 +0100 (BST) writes:

    Ted> On 09-Apr-05 Uwe Ligges wrote:
    >> Friedrich.Leisch@tuwien.ac.at wrote:
    >> 
    >>> Dear R Developers,
    >>> 
    >>> the following CRAN packages do not cleanly pass R CMD
    >>> check for quite some time now and did not have any
    >>> updates since the time given. Several attempts by the
    >>> CRAN admins to contact the package maintainers had no
    >>> success.
    >>> 
    >>> norm, 1.0-9, 2002-05-07, WARN

    Ted> It would be serious if 'norm' were to lapse, since it
    Ted> is part of the 'norm+cat+mix+pan' family, and people
    Ted> using any of these are likely to have occasion to use
    Ted> the others.

Indeed!  I had a very similar thought but couldn't afford your
offer (below), so thanks a lot !

    Ted> I'd offer to try to clean up 'norm' myself if only I
    Ted> were up-to-date on R itself (I'm waiting for 2.1.0 to
    Ted> come out, which I understand is scheduled to happen
    Ted> soon, yes?).

yes, as Uwe has already confirmed.

Since R 2.1.0 is now in beta testing, we consider it very
stable, and having less bugs than any other version of R, so
please ("everyone!") follow Uwe's advice and install R 2.1.0"beta"

Martin

From edd at debian.org  Sat Apr  9 16:43:37 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat Apr  9 16:43:57 2005
Subject: [Rd] orphaning CRAN packages
In-Reply-To: <16983.58744.275573.577522@stat.math.ethz.ch>
References: <4257B0A4.1020308@statistik.uni-dortmund.de>
	<XFMail.050409130222.Ted.Harding@nessie.mcc.ac.uk>
	<16983.58744.275573.577522@stat.math.ethz.ch>
Message-ID: <16983.59929.436682.235618@basebud.nulle.part>


On 9 April 2005 at 16:23, Martin Maechler wrote:
| Since R 2.1.0 is now in beta testing, we consider it very
| stable, and having less bugs than any other version of R, so
| please ("everyone!") follow Uwe's advice and install R 2.1.0"beta"

FYI, for those using Debian, packages can be had from the so-called
'experimental' archive (i.e. needs a sources.list entry for experiremental),
or directly from the pool directory
	http://ftp.debian.org/debian/pool/main/r/r-base/

This provides the April 3 snapshot still tagged 'alpha'; I'll probably add a
beta release tonight or tomorrow and insert that into Debian's unstable
archive. 

Dirk

-- 
Better to have an approximate answer to the right question than a precise 
answer to the wrong question.  --  John Tukey as quoted by John Chambers

From Ted.Harding at nessie.mcc.ac.uk  Sat Apr  9 17:16:35 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat Apr  9 17:22:55 2005
Subject: [Rd] orphaning CRAN packages
In-Reply-To: <4257D12B.6000302@statistik.uni-dortmund.de>
Message-ID: <XFMail.050409161635.Ted.Harding@nessie.mcc.ac.uk>

On 09-Apr-05 Uwe Ligges wrote:
> (Ted Harding) wrote:
>> It would be serious if 'norm' were to lapse, since it is
>> part of the 'norm+cat+mix+pan' family, and people using any
>> of these are likely to have occasion to use the others.
>> 
>> I'd offer to try to clean up 'norm' myself if only I were
>> up-to-date on R itself (I'm waiting for 2.1.0 to come out,
>> which I understand is scheduled to happen soon, yes?).
> 
> Ted, that's great!
> 
> R-2.1.0 is scheduled to be released on April 18 (see 
> http://developer.r-project.org/).
> 
> It would be even better if you could try out the recent beta
> release of R-2.1.0 right now in order to spot some possible
> bugs before release.
> 
> So it is the perfect occasion to clean up "norm" on R-2.1.0 beta
> this weekend. ;-)

Well, I'll see what I can do ... though this weekend may not offer
a lot of free time!

Bearing in mind Martin's and Dirk's comments, going for 2.1.0-beta
right now seems unlikely to lead to any grief compared with waiting
for the final release. So at any rate I could start looking at it
over the next week sometime.

However, there's a question or two.

1. Simply for the sake of having a look at 'norm', I think
   this may depend only on things which are part of R-base,
   so I should not need to download any "recommended"
   packages. Or are there things in "recommended" which are
   likely to be presumed? (I've always taken such things for
   granted since they have been installed by default when I've
   installed from RPMs; I've not done a full R compilation
   before, at least not for several years).

2. Is there a way to get, off CRAN say, a listing of which
   packages are "recommended"?

   I suffer from slow connection (5min/MB if I'm lucky,
   and lucky to stay fully connected for more than an hour
   or two -- even R-base is going to take at least an hour),
   so I don't want to just connect and do
     tools/rsync-recommended
   as suggested on CRAN since this may silently drop into
   a black hole at some point.

   I'd sooner do it all piecemeal, knowing what's supposed
   to be on the way and able to start again at that point
   if there are problems. But this means knowing which are
   the recommended ones.

(This, by the way, is why I'd been waiting for 2.1.0, since
it then becomes worth while making an expedition to a fast
connection or negotiating with someone to do me a CD; but
with the above assurances I suppose I can go ahead now anyway!)

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding@nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 09-Apr-05                                       Time: 16:16:35
------------------------------ XFMail ------------------------------

From ligges at statistik.uni-dortmund.de  Sat Apr  9 17:36:47 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Apr  9 17:36:37 2005
Subject: [Rd] orphaning CRAN packages
In-Reply-To: <XFMail.050409161635.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.050409161635.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <4257F68F.5000709@statistik.uni-dortmund.de>

(Ted Harding) wrote:

> On 09-Apr-05 Uwe Ligges wrote:
> 
>>(Ted Harding) wrote:
>>
>>>It would be serious if 'norm' were to lapse, since it is
>>>part of the 'norm+cat+mix+pan' family, and people using any
>>>of these are likely to have occasion to use the others.
>>>
>>>I'd offer to try to clean up 'norm' myself if only I were
>>>up-to-date on R itself (I'm waiting for 2.1.0 to come out,
>>>which I understand is scheduled to happen soon, yes?).
>>
>>Ted, that's great!
>>
>>R-2.1.0 is scheduled to be released on April 18 (see 
>>http://developer.r-project.org/).
>>
>>It would be even better if you could try out the recent beta
>>release of R-2.1.0 right now in order to spot some possible
>>bugs before release.
>>
>>So it is the perfect occasion to clean up "norm" on R-2.1.0 beta
>>this weekend. ;-)
> 
> 
> Well, I'll see what I can do ... though this weekend may not offer
> a lot of free time!

No need to apologise, I just tried to take advantage of the current 
enthusiasm on your side. ;-)


> Bearing in mind Martin's and Dirk's comments, going for 2.1.0-beta
> right now seems unlikely to lead to any grief compared with waiting
> for the final release. So at any rate I could start looking at it
> over the next week sometime.
> 
> However, there's a question or two.
> 
> 1. Simply for the sake of having a look at 'norm', I think
>    this may depend only on things which are part of R-base,
>    so I should not need to download any "recommended"
>    packages. Or are there things in "recommended" which are
>    likely to be presumed? (I've always taken such things for
>    granted since they have been installed by default when I've
>    installed from RPMs; I've not done a full R compilation
>    before, at least not for several years).
>
> 2. Is there a way to get, off CRAN say, a listing of which
>    packages are "recommended"?
> 
>    I suffer from slow connection (5min/MB if I'm lucky,
>    and lucky to stay fully connected for more than an hour
>    or two -- even R-base is going to take at least an hour),
>    so I don't want to just connect and do
>      tools/rsync-recommended
>    as suggested on CRAN since this may silently drop into
>    a black hole at some point.
> 
>    I'd sooner do it all piecemeal, knowing what's supposed
>    to be on the way and able to start again at that point
>    if there are problems. But this means knowing which are
>    the recommended ones.
> 
> (This, by the way, is why I'd been waiting for 2.1.0, since
> it then becomes worth while making an expedition to a fast
> connection or negotiating with someone to do me a CD; but
> with the above assurances I suppose I can go ahead now anyway!)

Two questions, one answer: The beta versions available from
CRAN/src/base-prerelease
already contain recommended packages.

   ./configure
   make
   make install

should be sufficient, in principle.

   make check

would be nice in order to spot errors on your platform.


Uwe


> Best wishes,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding@nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 09-Apr-05                                       Time: 16:16:35
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Sat Apr  9 18:17:35 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Apr  9 18:17:47 2005
Subject: Pacakge norm (was Re: [Rd] orphaning CRAN packages)
In-Reply-To: <4257D12B.6000302@statistik.uni-dortmund.de>
References: <XFMail.050409130222.Ted.Harding@nessie.mcc.ac.uk>
	<4257D12B.6000302@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.61.0504091708000.16633@gannet.stats>

The known problems are in the file

http://www.r-project.org/nocvs/R.check/r-devel/norm-00check.txt

No showstoppers, so given the saga of Ted's connectivity, I would suggest 
waiting for the release on April 18.

There are no declared dependencies, nor did I find any searching the 
code.

On Sat, 9 Apr 2005, Uwe Ligges wrote:

> (Ted Harding) wrote:
>> On 09-Apr-05 Uwe Ligges wrote:
>> 
>>> Friedrich.Leisch@tuwien.ac.at wrote:
>>> 
>>> 
>>>> Dear R Developers,
>>>> 
>>>> the following CRAN packages do not cleanly pass R CMD check
>>>> for quite some time now and did not have any updates since
>>>> the time given. Several attempts by the CRAN admins to contact
>>>> the package maintainers had no success.
>>>> 
>>>> norm, 1.0-9, 2002-05-07, WARN
>> 
>> 
>> It would be serious if 'norm' were to lapse, since it is
>> part of the 'norm+cat+mix+pan' family, and people using any
>> of these are likely to have occasion to use the others.
>> 
>> I'd offer to try to clean up 'norm' myself if only I were
>> up-to-date on R itself (I'm waiting for 2.1.0 to come out,
>> which I understand is scheduled to happen soon, yes?).
>
> Ted, that's great!
>
> R-2.1.0 is scheduled to be released on April 18 (see 
> http://developer.r-project.org/).
>
> It would be even better if you could try out the recent beta release of 
> R-2.1.0 right now in order to spot some possible bugs before release.
>
> So it is the perfect occasion to clean up "norm" on R-2.1.0 beta this 
> weekend. ;-)
>
> Best,
> Uwe
>
>
>> Best wishes,
>> Ted.
>> 
>> 
>> --------------------------------------------------------------------
>> E-Mail: (Ted Harding) <Ted.Harding@nessie.mcc.ac.uk>
>> Fax-to-email: +44 (0)870 094 0861
>> Date: 09-Apr-05                                       Time: 13:02:22
>> ------------------------------ XFMail ------------------------------
>> 
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From znmeb at cesmail.net  Sat Apr  9 19:21:36 2005
From: znmeb at cesmail.net (znmeb@cesmail.net)
Date: Sat Apr  9 19:21:43 2005
Subject: [Rd] make check-all fails (PR#7784)
Message-ID: <20050409172136.1C551CA2F@slim.kubism.ku.dk>

Full_Name: Ed Borasky
Version: R-beta 2.1.0 2005-04-08
OS: Linux 2.6.11 GCC 3.3.5
Submission from: (NULL) (24.21.57.139)


I downloaded the latest R-beta tarball and did a build with the default options.
OS is Linux 2.6.11 and compiler is GCC 3.3.5. "make check-all" failed with the
following message:

make[3]: Entering directory `/home/znmeb/R-beta/tests'
running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout] Error 1
make[3]: Leaving directory `/home/znmeb/R-beta/tests'
make[2]: *** [test-Reg] Error 2
make[2]: Leaving directory `/home/znmeb/R-beta/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/home/znmeb/R-beta/tests'
make: *** [check-all] Error 2

I looked at "tests/reg-tests-1.Rout.fail"; it's 1427 lines long. The error given
is

> ## Comments:
>
>
> ## PR 796 (aic in binomial models is often wrong)
> ##
> a1 <- glm(cbind(ncases, ncontrols) ~ agegp + tobgp * alcgp,
+     data = esoph, family = binomial())$aic
> a1
[1] 236.9645
> a2 <- glm(ncases/(ncases+ncontrols) ~ agegp + tobgp * alcgp,
+     data = esoph, family = binomial(), weights=ncases+ncontrols)$aic
> a2
[1] 236.9645
> stopifnot(a1 == a2)
Error: a1 == a2 is not TRUE
Execution halted

I am running on an Athlon Thunderbird with Atlas 3.6.0 installed. If necessary,
I can back Atlas out and run this again.

From Ted.Harding at nessie.mcc.ac.uk  Sat Apr  9 19:23:13 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat Apr  9 19:30:37 2005
Subject: Pacakge norm (was Re: [Rd] orphaning CRAN packages)
In-Reply-To: <Pine.LNX.4.61.0504091708000.16633@gannet.stats>
Message-ID: <XFMail.050409182142.Ted.Harding@nessie.mcc.ac.uk>

On 09-Apr-05 Prof Brian Ripley wrote:
> The known problems are in the file
> 
> http://www.r-project.org/nocvs/R.check/r-devel/norm-00check.txt
> 
> No showstoppers, so given the saga of Ted's connectivity, I would
> suggest waiting for the release on April 18.
> 
> There are no declared dependencies, nor did I find any searching the 
> code.

Thanks for the pointer. Yes, they look innocuous enough.
On the precautionary principle, however, it would be worth
dealing with the ".Fortran" warnings, since this would
safeguard against the possibility of name clash if some
other package used the same names.

Question 1:
I take it that all that's needed here is to search for
all such calls, e.g.

  .Fortran("tobsn", ...)

and make sure that it one becomes

  .Fortran("tobsn", ... ,PACKAGE=norm)

and so on?

This could be done without installing any new R (though
being able to check against the latest would be added
assurance), as also could be possible amendements related
to the "Rd" warnings (which, however, only affect "help"
and other documentation issues).

None the less,

Question 2.
It would still be interesting to test out the compilability
of the latest R on the machine I would be installing the
new one on anyway (SuSE Linux 7.2 from 2001), since this
would have oldish math libs ...

I think I have sussed out how to keep different versions
of R on the same machine, namely:

a) Edit /usr/bin/R and change

     R_HOME_DIR=/usr/lib/R

   to

     R_HOME_DIR=/usr/lib/R-x.y.z

   as appropriate.

b) Rename the directory /usr/lib/R to /usr/lib/R-x.y.z

c) Rename /usr/bin/R to /usr/bin/R-x.y.z

d) (pro tem) Make a symbolic link

   ln -s /usr/bin/R-x.y.z /usr/bin/R

Then one can install a new R without thinking about it,
provided one remembers to delete the symbolic link before
starting (or will the new installation do this all by
itself?).

Have I missed anything?

Thanks, and best wishes,
Ted.

From ligges at statistik.uni-dortmund.de  Sat Apr  9 19:37:50 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Apr  9 19:37:40 2005
Subject: Pacakge norm (was Re: [Rd] orphaning CRAN packages)
In-Reply-To: <XFMail.050409182142.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.050409182142.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <425812EE.8090500@statistik.uni-dortmund.de>

(Ted Harding) wrote:
> On 09-Apr-05 Prof Brian Ripley wrote:
> 
>>The known problems are in the file
>>
>>http://www.r-project.org/nocvs/R.check/r-devel/norm-00check.txt
>>
>>No showstoppers, so given the saga of Ted's connectivity, I would
>>suggest waiting for the release on April 18.
>>
>>There are no declared dependencies, nor did I find any searching the 
>>code.
> 
> 
> Thanks for the pointer. Yes, they look innocuous enough.
> On the precautionary principle, however, it would be worth
> dealing with the ".Fortran" warnings, since this would
> safeguard against the possibility of name clash if some
> other package used the same names.
> 
> Question 1:
> I take it that all that's needed here is to search for
> all such calls, e.g.
> 
>   .Fortran("tobsn", ...)
> 
> and make sure that it one becomes
> 
>   .Fortran("tobsn", ... ,PACKAGE=norm)
> 
> and so on?

Yes, but PACKAGE="norm" (quotes!)


> This could be done without installing any new R (though
> being able to check against the latest would be added
> assurance), as also could be possible amendements related
> to the "Rd" warnings (which, however, only affect "help"
> and other documentation issues).
> 
> None the less,
> 
> Question 2.
> It would still be interesting to test out the compilability
> of the latest R on the machine I would be installing the
> new one on anyway (SuSE Linux 7.2 from 2001), since this
> would have oldish math libs ...
> 
> I think I have sussed out how to keep different versions
> of R on the same machine, namely:
> 
> a) Edit /usr/bin/R and change
> 
>      R_HOME_DIR=/usr/lib/R
> 
>    to
> 
>      R_HOME_DIR=/usr/lib/R-x.y.z
> 
>    as appropriate.
> 
> b) Rename the directory /usr/lib/R to /usr/lib/R-x.y.z
> 
> c) Rename /usr/bin/R to /usr/bin/R-x.y.z
> 
> d) (pro tem) Make a symbolic link
> 
>    ln -s /usr/bin/R-x.y.z /usr/bin/R


No, it is much simpler (and cleaner) to specify the installation 
directory using

   ./configure --prefix=/the/path/to/R-2.0.1

After make, make install, you can start R-2.0.1 by

   /the/path/to/R-2.0.1/bin/R


Uwe




> Then one can install a new R without thinking about it,
> provided one remembers to delete the symbolic link before
> starting (or will the new installation do this all by
> itself?).
> 
> Have I missed anything?
> 
> Thanks, and best wishes,
> Ted.

From p.dalgaard at biostat.ku.dk  Sat Apr  9 19:45:03 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat Apr  9 19:45:12 2005
Subject: [Rd] make check-all fails (PR#7784)
In-Reply-To: <20050409172136.1C551CA2F@slim.kubism.ku.dk>
References: <20050409172136.1C551CA2F@slim.kubism.ku.dk>
Message-ID: <x2y8br26ao.fsf@turmalin.kubism.ku.dk>

znmeb@cesmail.net writes:

> Full_Name: Ed Borasky
> Version: R-beta 2.1.0 2005-04-08
> OS: Linux 2.6.11 GCC 3.3.5
> Submission from: (NULL) (24.21.57.139)
> 
> 
> I downloaded the latest R-beta tarball and did a build with the default options.
> OS is Linux 2.6.11 and compiler is GCC 3.3.5. "make check-all" failed with the
> following message:
> 
> make[3]: Entering directory `/home/znmeb/R-beta/tests'
> running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout] Error 1
> make[3]: Leaving directory `/home/znmeb/R-beta/tests'
> make[2]: *** [test-Reg] Error 2
> make[2]: Leaving directory `/home/znmeb/R-beta/tests'
> make[1]: *** [test-all-basics] Error 1
> make[1]: Leaving directory `/home/znmeb/R-beta/tests'
> make: *** [check-all] Error 2
> 
> I looked at "tests/reg-tests-1.Rout.fail"; it's 1427 lines long. The error given
> is
> 
> > ## Comments:
> >
> >
> > ## PR 796 (aic in binomial models is often wrong)
> > ##
> > a1 <- glm(cbind(ncases, ncontrols) ~ agegp + tobgp * alcgp,
> +     data = esoph, family = binomial())$aic
> > a1
> [1] 236.9645
> > a2 <- glm(ncases/(ncases+ncontrols) ~ agegp + tobgp * alcgp,
> +     data = esoph, family = binomial(), weights=ncases+ncontrols)$aic
> > a2
> [1] 236.9645
> > stopifnot(a1 == a2)
> Error: a1 == a2 is not TRUE
> Execution halted
> 
> I am running on an Athlon Thunderbird with Atlas 3.6.0 installed. If necessary,
> I can back Atlas out and run this again.

Hmm, could you replace the a1 == a2 with all.equal(a1, a2) instead?
(inside reg-tests-1.R of course)

Asking for identity up to machine precision does look a bit optimistic...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From znmeb at cesmail.net  Sat Apr  9 20:06:58 2005
From: znmeb at cesmail.net (M. Edward (Ed) Borasky)
Date: Sat Apr  9 20:07:14 2005
Subject: [Rd] make check-all fails (PR#7784)
In-Reply-To: <x2y8br26ao.fsf@turmalin.kubism.ku.dk>
References: <20050409172136.1C551CA2F@slim.kubism.ku.dk>
	<x2y8br26ao.fsf@turmalin.kubism.ku.dk>
Message-ID: <425819C2.5070108@cesmail.net>

Peter Dalgaard wrote:

>znmeb@cesmail.net writes:
>
>  
>
>>Full_Name: Ed Borasky
>>Version: R-beta 2.1.0 2005-04-08
>>OS: Linux 2.6.11 GCC 3.3.5
>>Submission from: (NULL) (24.21.57.139)
>>
>>
>>I downloaded the latest R-beta tarball and did a build with the default options.
>>OS is Linux 2.6.11 and compiler is GCC 3.3.5. "make check-all" failed with the
>>following message:
>>
>>make[3]: Entering directory `/home/znmeb/R-beta/tests'
>>running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout] Error 1
>>make[3]: Leaving directory `/home/znmeb/R-beta/tests'
>>make[2]: *** [test-Reg] Error 2
>>make[2]: Leaving directory `/home/znmeb/R-beta/tests'
>>make[1]: *** [test-all-basics] Error 1
>>make[1]: Leaving directory `/home/znmeb/R-beta/tests'
>>make: *** [check-all] Error 2
>>
>>I looked at "tests/reg-tests-1.Rout.fail"; it's 1427 lines long. The error given
>>is
>>
>>    
>>
>>>## Comments:
>>>
>>>
>>>## PR 796 (aic in binomial models is often wrong)
>>>##
>>>a1 <- glm(cbind(ncases, ncontrols) ~ agegp + tobgp * alcgp,
>>>      
>>>
>>+     data = esoph, family = binomial())$aic
>>    
>>
>>>a1
>>>      
>>>
>>[1] 236.9645
>>    
>>
>>>a2 <- glm(ncases/(ncases+ncontrols) ~ agegp + tobgp * alcgp,
>>>      
>>>
>>+     data = esoph, family = binomial(), weights=ncases+ncontrols)$aic
>>    
>>
>>>a2
>>>      
>>>
>>[1] 236.9645
>>    
>>
>>>stopifnot(a1 == a2)
>>>      
>>>
>>Error: a1 == a2 is not TRUE
>>Execution halted
>>
>>I am running on an Athlon Thunderbird with Atlas 3.6.0 installed. If necessary,
>>I can back Atlas out and run this again.
>>    
>>
>
>Hmm, could you replace the a1 == a2 with all.equal(a1, a2) instead?
>(inside reg-tests-1.R of course)
>
>Asking for identity up to machine precision does look a bit optimistic...
>
>  
>
That worked ... it got through reg-tests-1.R fine. However, it failed a 
little further down in the NA handling tests:

running tests of NA handling functions
make[3]: Entering directory `/home/znmeb/R-beta/tests'
running code in 'nafns.R' ...make[3]: *** [nafns.Rout] Error 1
make[3]: Leaving directory `/home/znmeb/R-beta/tests'
make[2]: *** [test-Nafns] Error 2
make[2]: Leaving directory `/home/znmeb/R-beta/tests'
make[1]: *** [test-all-devel] Error 1
make[1]: Leaving directory `/home/znmeb/R-beta/tests'
make: *** [check-all] Error 2

 > sm(fitted(gfit2))
length 153 with 42 NAs
 > sm(resid(gfit2))
length 153 with 42 NAs
 > sm(predict(gfit2))
length 153 with 42 NAs
 > (pp2 <- predict(gfit2, nd))
6 25 26 27
NA -16.177404 1.688479 NA
 > stopifnot(all.equal(pp, pp2))
 >
 > ## more precise tests.
 > f1 <- fitted(gfit)
 > f2 <- fitted(gfit2)
 > common <- match(names(f1), names(f2))
 > stopifnot(max(abs(f1 - f2[common])) < 100*.Machine$double.eps)
Error: max(abs(f1 - f2[common])) < 100 * .Machine$double.eps is not TRUE
Execution halted
"tests/nafns.Rout.fail"

From p.dalgaard at biostat.ku.dk  Sat Apr  9 20:24:00 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat Apr  9 20:27:09 2005
Subject: [Rd] make check-all fails (PR#7784)
In-Reply-To: <425819C2.5070108@cesmail.net>
References: <20050409172136.1C551CA2F@slim.kubism.ku.dk>
	<x2y8br26ao.fsf@turmalin.kubism.ku.dk> <425819C2.5070108@cesmail.net>
Message-ID: <x2u0mf24hr.fsf@turmalin.kubism.ku.dk>

"M. Edward (Ed) Borasky" <znmeb@cesmail.net> writes:

[snip]
> >Hmm, could you replace the a1 == a2 with all.equal(a1, a2) instead?
> >(inside reg-tests-1.R of course)
> >
> >Asking for identity up to machine precision does look a bit optimistic...
> >
> >
> That worked ... it got through reg-tests-1.R fine. However, it failed
> a little further down in the NA handling tests:
> 
> running tests of NA handling functions
> make[3]: Entering directory `/home/znmeb/R-beta/tests'
> running code in 'nafns.R' ...make[3]: *** [nafns.Rout] Error 1
> make[3]: Leaving directory `/home/znmeb/R-beta/tests'
> make[2]: *** [test-Nafns] Error 2
> make[2]: Leaving directory `/home/znmeb/R-beta/tests'
> make[1]: *** [test-all-devel] Error 1
> make[1]: Leaving directory `/home/znmeb/R-beta/tests'
> make: *** [check-all] Error 2
> 
>  > sm(fitted(gfit2))
> length 153 with 42 NAs
>  > sm(resid(gfit2))
> length 153 with 42 NAs
>  > sm(predict(gfit2))
> length 153 with 42 NAs
>  > (pp2 <- predict(gfit2, nd))
> 6 25 26 27
> NA -16.177404 1.688479 NA
>  > stopifnot(all.equal(pp, pp2))
>  >
>  > ## more precise tests.
>  > f1 <- fitted(gfit)
>  > f2 <- fitted(gfit2)
>  > common <- match(names(f1), names(f2))
>  > stopifnot(max(abs(f1 - f2[common])) < 100*.Machine$double.eps)
> Error: max(abs(f1 - f2[common])) < 100 * .Machine$double.eps is not TRUE
> Execution halted
> "tests/nafns.Rout.fail"

This looks more serious. 100 times machine precision is quite a large
margin in these matters. Could you perhaps stick in a printout of the
two terms and their difference?

I have an ATLAS build on AMD64 and it passes all the checks, but it is
using ATLAS 3.7.8, so you might want to try an upgrade.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Sat Apr  9 20:24:11 2005
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Sat Apr  9 20:27:13 2005
Subject: [Rd] make check-all fails (PR#7784)
Message-ID: <20050409182411.C7B2CCA33@slim.kubism.ku.dk>

"M. Edward (Ed) Borasky" <znmeb@cesmail.net> writes:

[snip]
> >Hmm, could you replace the a1 == a2 with all.equal(a1, a2) instead?
> >(inside reg-tests-1.R of course)
> >
> >Asking for identity up to machine precision does look a bit optimistic...
> >
> >
> That worked ... it got through reg-tests-1.R fine. However, it failed
> a little further down in the NA handling tests:
> 
> running tests of NA handling functions
> make[3]: Entering directory `/home/znmeb/R-beta/tests'
> running code in 'nafns.R' ...make[3]: *** [nafns.Rout] Error 1
> make[3]: Leaving directory `/home/znmeb/R-beta/tests'
> make[2]: *** [test-Nafns] Error 2
> make[2]: Leaving directory `/home/znmeb/R-beta/tests'
> make[1]: *** [test-all-devel] Error 1
> make[1]: Leaving directory `/home/znmeb/R-beta/tests'
> make: *** [check-all] Error 2
> 
>  > sm(fitted(gfit2))
> length 153 with 42 NAs
>  > sm(resid(gfit2))
> length 153 with 42 NAs
>  > sm(predict(gfit2))
> length 153 with 42 NAs
>  > (pp2 <- predict(gfit2, nd))
> 6 25 26 27
> NA -16.177404 1.688479 NA
>  > stopifnot(all.equal(pp, pp2))
>  >
>  > ## more precise tests.
>  > f1 <- fitted(gfit)
>  > f2 <- fitted(gfit2)
>  > common <- match(names(f1), names(f2))
>  > stopifnot(max(abs(f1 - f2[common])) < 100*.Machine$double.eps)
> Error: max(abs(f1 - f2[common])) < 100 * .Machine$double.eps is not TRUE
> Execution halted
> "tests/nafns.Rout.fail"

This looks more serious. 100 times machine precision is quite a large
margin in these matters. Could you perhaps stick in a printout of the
two terms and their difference?

I have an ATLAS build on AMD64 and it passes all the checks, but it is
using ATLAS 3.7.8, so you might want to try an upgrade.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Sat Apr  9 20:24:11 2005
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Sat Apr  9 20:27:47 2005
Subject: [Rd] make check-all fails (PR#7784)
Message-ID: <20050409182411.C7B2CCA33@slim.kubism.ku.dk>

"M. Edward (Ed) Borasky" <znmeb@cesmail.net> writes:

[snip]
> >Hmm, could you replace the a1 == a2 with all.equal(a1, a2) instead?
> >(inside reg-tests-1.R of course)
> >
> >Asking for identity up to machine precision does look a bit optimistic...
> >
> >
> That worked ... it got through reg-tests-1.R fine. However, it failed
> a little further down in the NA handling tests:
> 
> running tests of NA handling functions
> make[3]: Entering directory `/home/znmeb/R-beta/tests'
> running code in 'nafns.R' ...make[3]: *** [nafns.Rout] Error 1
> make[3]: Leaving directory `/home/znmeb/R-beta/tests'
> make[2]: *** [test-Nafns] Error 2
> make[2]: Leaving directory `/home/znmeb/R-beta/tests'
> make[1]: *** [test-all-devel] Error 1
> make[1]: Leaving directory `/home/znmeb/R-beta/tests'
> make: *** [check-all] Error 2
> 
>  > sm(fitted(gfit2))
> length 153 with 42 NAs
>  > sm(resid(gfit2))
> length 153 with 42 NAs
>  > sm(predict(gfit2))
> length 153 with 42 NAs
>  > (pp2 <- predict(gfit2, nd))
> 6 25 26 27
> NA -16.177404 1.688479 NA
>  > stopifnot(all.equal(pp, pp2))
>  >
>  > ## more precise tests.
>  > f1 <- fitted(gfit)
>  > f2 <- fitted(gfit2)
>  > common <- match(names(f1), names(f2))
>  > stopifnot(max(abs(f1 - f2[common])) < 100*.Machine$double.eps)
> Error: max(abs(f1 - f2[common])) < 100 * .Machine$double.eps is not TRUE
> Execution halted
> "tests/nafns.Rout.fail"

This looks more serious. 100 times machine precision is quite a large
margin in these matters. Could you perhaps stick in a printout of the
two terms and their difference?

I have an ATLAS build on AMD64 and it passes all the checks, but it is
using ATLAS 3.7.8, so you might want to try an upgrade.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From znmeb at cesmail.net  Sun Apr 10 00:52:15 2005
From: znmeb at cesmail.net (M. Edward (Ed) Borasky)
Date: Sun Apr 10 00:52:39 2005
Subject: [Rd] make check-all fails (PR#7784)
In-Reply-To: <20050409182411.C7B2CCA33@slim.kubism.ku.dk>
References: <20050409182411.C7B2CCA33@slim.kubism.ku.dk>
Message-ID: <42585C9F.7010903@cesmail.net>

p.dalgaard@biostat.ku.dk wrote:

>This looks more serious. 100 times machine precision is quite a large
>margin in these matters. Could you perhaps stick in a printout of the
>two terms and their difference?
>
>I have an ATLAS build on AMD64 and it passes all the checks, but it is
>using ATLAS 3.7.8, so you might want to try an upgrade.
>
>  
>
Attached ... you actually weren't very far off:

 > print (max(abs(f1 - f2[common])))
[1] 2.842171e-14
 > print (100*.Machine$double.eps)
[1] 2.220446e-14
 > stopifnot(max(abs(f1 - f2[common])) < 100*.Machine$double.eps)
Error: max(abs(f1 - f2[common])) < 100 * .Machine$double.eps is not TRUE
Execution halted

I'll go ahead and try ATLAS 3.7.8, but that takes a couple of hours to 
build. I've also got a Pentium III I can test this on.
-------------- next part --------------

R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.1.0 beta (2005-04-08), ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

> ## Tests of functions handling NAs in fits
> ## These functions were introduced in 1.3.0.
> ## They are used by lm and glm in base R, and by
> ## packages MASS, rpart and survival.
> 
> dim(airquality)
[1] 153   6
> nd <- airquality[c(6,25:27), ]
> 
> sm <- function(x) cat("length", length(x), "with", sum(is.na(x)), "NAs\n")
> 
> # default is to omit some rows
> fit <- lm(Ozone ~ ., data=airquality, na.action=na.omit)
> summary(fit)

Call:
lm(formula = Ozone ~ ., data = airquality, na.action = na.omit)

Residuals:
    Min      1Q  Median      3Q     Max 
-37.014 -12.284  -3.302   8.454  95.348 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) -64.11632   23.48249  -2.730  0.00742 ** 
Solar.R       0.05027    0.02342   2.147  0.03411 *  
Wind         -3.31844    0.64451  -5.149 1.23e-06 ***
Temp          1.89579    0.27389   6.922 3.66e-10 ***
Month        -3.03996    1.51346  -2.009  0.04714 *  
Day           0.27388    0.22967   1.192  0.23576    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 20.86 on 105 degrees of freedom
Multiple R-Squared: 0.6249,	Adjusted R-squared: 0.6071 
F-statistic: 34.99 on 5 and 105 DF,  p-value: < 2.2e-16 

> sm(fitted(fit))
length 111 with 0 NAs
> sm(resid(fit))
length 111 with 0 NAs
> sm(predict(fit))
length 111 with 0 NAs
> (pp <- predict(fit, nd))
         6         25         26         27 
        NA -16.177404   1.688479         NA 
> 
> fit2 <- lm(Ozone ~ ., data=airquality, na.action=na.exclude)
> summary(fit2) # same as before

Call:
lm(formula = Ozone ~ ., data = airquality, na.action = na.exclude)

Residuals:
    Min      1Q  Median      3Q     Max 
-37.014 -12.284  -3.302   8.454  95.348 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) -64.11632   23.48249  -2.730  0.00742 ** 
Solar.R       0.05027    0.02342   2.147  0.03411 *  
Wind         -3.31844    0.64451  -5.149 1.23e-06 ***
Temp          1.89579    0.27389   6.922 3.66e-10 ***
Month        -3.03996    1.51346  -2.009  0.04714 *  
Day           0.27388    0.22967   1.192  0.23576    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 20.86 on 105 degrees of freedom
Multiple R-Squared: 0.6249,	Adjusted R-squared: 0.6071 
F-statistic: 34.99 on 5 and 105 DF,  p-value: < 2.2e-16 

> sm(fitted(fit2))
length 153 with 42 NAs
> sm(resid(fit2))
length 153 with 42 NAs
> sm(predict(fit2))
length 153 with 42 NAs
> (pp2 <- predict(fit2, nd))
         6         25         26         27 
        NA -16.177404   1.688479         NA 
> 
> ## same as before: napredict is only applied to predictions on the
> ## original data, following Therneau's original code (and S-PLUS).
> ## However, as from R 1.8.0 there is a separate na.action arg to predict.lm()
> stopifnot(all.equal(pp, pp2))
> 
> ## should fail
> try(fit3 <- lm(Ozone ~ ., data=airquality, na.action=na.fail))
Error in na.fail.default(list(Ozone = c(41, 36, 12, 18, NA, 28, 23, 19,  : 
	missing values in object
> 
> ## more precise tests.
> f1 <- fitted(fit)
> f2 <- fitted(fit2)
> common <- match(names(f1), names(f2))
> stopifnot(max(abs(f1 - f2[common])) < 100*.Machine$double.eps)
> stopifnot(all(is.na(f2[-common])))
> 
> r1 <- resid(fit)
> r2 <- resid(fit2)
> common <- match(names(r1), names(r2))
> stopifnot(max(abs(r1 - r2[common])) < 100*.Machine$double.eps)
> stopifnot(all(is.na(r2[-common])))
> 
> p1 <- predict(fit)
> p2 <- predict(fit2)
> common <- match(names(p1), names(p2))
> stopifnot(max(abs(p1 - p2[common])) < 100*.Machine$double.eps)
> stopifnot(all(is.na(p2[-common])))
> 
> 
> ### now try out glm
> gfit <- glm(Ozone ~ ., data=airquality, na.action=na.omit)
> summary(gfit)

Call:
glm(formula = Ozone ~ ., data = airquality, na.action = na.omit)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-37.014  -12.284   -3.302    8.454   95.348  

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) -64.11632   23.48249  -2.730  0.00742 ** 
Solar.R       0.05027    0.02342   2.147  0.03411 *  
Wind         -3.31844    0.64451  -5.149 1.23e-06 ***
Temp          1.89579    0.27389   6.922 3.66e-10 ***
Month        -3.03996    1.51346  -2.009  0.04714 *  
Day           0.27388    0.22967   1.192  0.23576    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

(Dispersion parameter for gaussian family taken to be 435.0755)

    Null deviance: 121802  on 110  degrees of freedom
Residual deviance:  45683  on 105  degrees of freedom
AIC: 997.22

Number of Fisher Scoring iterations: 2

> sm(fitted(gfit))
length 111 with 0 NAs
> sm(resid(gfit))
length 111 with 0 NAs
> sm(predict(gfit))
length 111 with 0 NAs
> predict(gfit, nd)
         6         25         26         27 
        NA -16.177404   1.688479         NA 
> (pp <- predict(gfit, nd))
         6         25         26         27 
        NA -16.177404   1.688479         NA 
> 
> gfit2 <- glm(Ozone ~ ., data=airquality, na.action=na.exclude)
> summary(gfit2) # same as before

Call:
glm(formula = Ozone ~ ., data = airquality, na.action = na.exclude)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-37.014  -12.284   -3.302    8.454   95.348  

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) -64.11632   23.48249  -2.730  0.00742 ** 
Solar.R       0.05027    0.02342   2.147  0.03411 *  
Wind         -3.31844    0.64451  -5.149 1.23e-06 ***
Temp          1.89579    0.27389   6.922 3.66e-10 ***
Month        -3.03996    1.51346  -2.009  0.04714 *  
Day           0.27388    0.22967   1.192  0.23576    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

(Dispersion parameter for gaussian family taken to be 435.0755)

    Null deviance: 121802  on 110  degrees of freedom
Residual deviance:  45683  on 105  degrees of freedom
AIC: 997.22

Number of Fisher Scoring iterations: 2

> sm(fitted(gfit2))
length 153 with 42 NAs
> sm(resid(gfit2))
length 153 with 42 NAs
> sm(predict(gfit2))
length 153 with 42 NAs
> (pp2 <- predict(gfit2, nd))
         6         25         26         27 
        NA -16.177404   1.688479         NA 
> stopifnot(all.equal(pp, pp2))
> 
> ## more precise tests.
> f1 <- fitted(gfit)
> f2 <- fitted(gfit2)
> common <- match(names(f1), names(f2))
> print (common)
  [1]   1   2   3   4   7   8   9  12  13  14  15  16  17  18  19  20  21  22
 [19]  23  24  28  29  30  31  38  40  41  44  47  48  49  50  51  62  63  64
 [37]  66  67  68  69  70  71  73  74  76  77  78  79  80  81  82  85  86  87
 [55]  88  89  90  91  92  93  94  95  99 100 101 104 105 106 108 109 110 111
 [73] 112 113 114 116 117 118 120 121 122 123 124 125 126 127 128 129 130 131
 [91] 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
[109] 151 152 153
> print (f1)
         1          2          3          4          7          8          9 
 32.971099  37.113091  27.472204  16.891921  32.320560  -6.091053 -26.953745 
        12         13         14         15         16         17         18 
 35.461009  33.416076  31.035783  -5.787958  25.025785  26.074607 -23.464453 
        19         20         21         22         23         24         28 
 32.827271  13.723369   6.500011  26.103224  11.694003   7.703839  16.202396 
        29         30         31         38         40         41         44 
 45.409358  70.963391  62.723917  49.211501  59.564916  63.392633  57.551881 
        47         48         49         50         51         62         63 
 28.159115   4.382598  17.130318  29.110834  39.908867  74.042091  58.231930 
        64         66         67         68         69         70         71 
 50.319370  66.856807  53.212618  80.301978  83.724400  86.240715  70.309270 
        73         74         76         77         78         79         80 
 22.101594  31.076282  25.334479  62.718783  54.309578  72.201821  77.218308 
        81         82         85         86         87         88         89 
 54.121624  38.098263  70.456707  67.256388  52.712887  49.337475  75.253703 
        90         91         92         93         94         95         99 
 74.853015  68.333499  58.892879  46.672109  21.082539  47.154782  81.752335 
       100        101        104        105        106        108        109 
 61.708671  68.508934  49.378753  46.141704  42.765387  31.311125  47.644865 
       110        111        112        113        114        116        117 
 41.798651  40.734935  40.285066  24.876177   8.442082  46.373463  72.652242 
       118        120        121        122        123        124        125 
 65.983901  81.140660 101.389698  92.784665  86.803528  66.813059  76.464152 
       126        127        128        129        130        131        132 
 85.562396  80.164720  55.046451  22.602751  38.602215  35.466808  28.565003 
       133        134        135        136        137        138        139 
 30.487396  27.515347  17.475536  49.119123  11.994736  14.701687  49.795201 
       140        141        142        143        144        145        146 
  5.664599  24.711067  20.426534  53.013693   5.758723  19.324367  41.190110 
       147        148        149        151        152        153 
 14.189862 -19.275130  35.155615  20.525269  40.584670  18.702940 
> print (f2[common])
         1          2          3          4          7          8          9 
 32.971099  37.113091  27.472204  16.891921  32.320560  -6.091053 -26.953745 
        12         13         14         15         16         17         18 
 35.461009  33.416076  31.035783  -5.787958  25.025785  26.074607 -23.464453 
        19         20         21         22         23         24         28 
 32.827271  13.723369   6.500011  26.103224  11.694003   7.703839  16.202396 
        29         30         31         38         40         41         44 
 45.409358  70.963391  62.723917  49.211501  59.564916  63.392633  57.551881 
        47         48         49         50         51         62         63 
 28.159115   4.382598  17.130318  29.110834  39.908867  74.042091  58.231930 
        64         66         67         68         69         70         71 
 50.319370  66.856807  53.212618  80.301978  83.724400  86.240715  70.309270 
        73         74         76         77         78         79         80 
 22.101594  31.076282  25.334479  62.718783  54.309578  72.201821  77.218308 
        81         82         85         86         87         88         89 
 54.121624  38.098263  70.456707  67.256388  52.712887  49.337475  75.253703 
        90         91         92         93         94         95         99 
 74.853015  68.333499  58.892879  46.672109  21.082539  47.154782  81.752335 
       100        101        104        105        106        108        109 
 61.708671  68.508934  49.378753  46.141704  42.765387  31.311125  47.644865 
       110        111        112        113        114        116        117 
 41.798651  40.734935  40.285066  24.876177   8.442082  46.373463  72.652242 
       118        120        121        122        123        124        125 
 65.983901  81.140660 101.389698  92.784665  86.803528  66.813059  76.464152 
       126        127        128        129        130        131        132 
 85.562396  80.164720  55.046451  22.602751  38.602215  35.466808  28.565003 
       133        134        135        136        137        138        139 
 30.487396  27.515347  17.475536  49.119123  11.994736  14.701687  49.795201 
       140        141        142        143        144        145        146 
  5.664599  24.711067  20.426534  53.013693   5.758723  19.324367  41.190110 
       147        148        149        151        152        153 
 14.189862 -19.275130  35.155615  20.525269  40.584670  18.702940 
> print (f1 - f2[common])
            1             2             3             4             7 
-2.131628e-14 -1.421085e-14 -1.065814e-14 -2.486900e-14 -2.842171e-14 
            8             9            12            13            14 
-1.776357e-14 -7.105427e-15 -2.131628e-14 -2.131628e-14 -1.776357e-14 
           15            16            17            18            19 
-1.865175e-14 -2.486900e-14 -2.131628e-14 -1.065814e-14 -2.131628e-14 
           20            21            22            23            24 
-1.953993e-14 -2.131628e-14 -1.065814e-14 -2.131628e-14 -1.865175e-14 
           28            29            30            31            38 
-1.065814e-14 -7.105427e-15 -1.421085e-14 -1.421085e-14 -7.105427e-15 
           40            41            44            47            48 
 0.000000e+00 -7.105427e-15 -7.105427e-15 -7.105427e-15 -3.552714e-15 
           49            50            51            62            63 
-1.776357e-14 -1.421085e-14 -1.421085e-14 -1.421085e-14 -7.105427e-15 
           64            66            67            68            69 
-1.421085e-14 -1.421085e-14 -7.105427e-15 -1.421085e-14 -1.421085e-14 
           70            71            73            74            76 
-1.421085e-14  0.000000e+00 -1.065814e-14 -3.552714e-15 -3.552714e-15 
           77            78            79            80            81 
-1.421085e-14 -1.421085e-14 -2.842171e-14 -1.421085e-14 -7.105427e-15 
           82            85            86            87            88 
-1.421085e-14 -1.421085e-14 -1.421085e-14 -7.105427e-15  0.000000e+00 
           89            90            91            92            93 
-1.421085e-14 -1.421085e-14 -1.421085e-14 -1.421085e-14 -1.421085e-14 
           94            95            99           100           101 
-3.552714e-15 -7.105427e-15 -1.421085e-14 -7.105427e-15  0.000000e+00 
          104           105           106           108           109 
-7.105427e-15 -7.105427e-15 -1.421085e-14 -1.065814e-14 -1.421085e-14 
          110           111           112           113           114 
-1.421085e-14 -1.421085e-14 -1.421085e-14 -1.065814e-14 -8.881784e-15 
          116           117           118           120           121 
-1.421085e-14 -2.842171e-14 -1.421085e-14  0.000000e+00 -1.421085e-14 
          122           123           124           125           126 
-1.421085e-14 -1.421085e-14 -1.421085e-14 -1.421085e-14 -1.421085e-14 
          127           128           129           130           131 
 0.000000e+00 -7.105427e-15  0.000000e+00 -7.105427e-15 -1.421085e-14 
          132           133           134           135           136 
-1.776357e-14 -1.776357e-14 -3.552714e-15 -1.065814e-14 -2.131628e-14 
          137           138           139           140           141 
-1.421085e-14 -1.421085e-14 -1.421085e-14 -1.687539e-14 -1.065814e-14 
          142           143           144           145           146 
-1.776357e-14 -1.421085e-14 -2.042810e-14 -1.421085e-14 -7.105427e-15 
          147           148           149           151           152 
-1.598721e-14 -1.065814e-14 -2.842171e-14 -1.065814e-14 -2.131628e-14 
          153 
-1.776357e-14 
> print (abs(f1 - f2[common]))
           1            2            3            4            7            8 
2.131628e-14 1.421085e-14 1.065814e-14 2.486900e-14 2.842171e-14 1.776357e-14 
           9           12           13           14           15           16 
7.105427e-15 2.131628e-14 2.131628e-14 1.776357e-14 1.865175e-14 2.486900e-14 
          17           18           19           20           21           22 
2.131628e-14 1.065814e-14 2.131628e-14 1.953993e-14 2.131628e-14 1.065814e-14 
          23           24           28           29           30           31 
2.131628e-14 1.865175e-14 1.065814e-14 7.105427e-15 1.421085e-14 1.421085e-14 
          38           40           41           44           47           48 
7.105427e-15 0.000000e+00 7.105427e-15 7.105427e-15 7.105427e-15 3.552714e-15 
          49           50           51           62           63           64 
1.776357e-14 1.421085e-14 1.421085e-14 1.421085e-14 7.105427e-15 1.421085e-14 
          66           67           68           69           70           71 
1.421085e-14 7.105427e-15 1.421085e-14 1.421085e-14 1.421085e-14 0.000000e+00 
          73           74           76           77           78           79 
1.065814e-14 3.552714e-15 3.552714e-15 1.421085e-14 1.421085e-14 2.842171e-14 
          80           81           82           85           86           87 
1.421085e-14 7.105427e-15 1.421085e-14 1.421085e-14 1.421085e-14 7.105427e-15 
          88           89           90           91           92           93 
0.000000e+00 1.421085e-14 1.421085e-14 1.421085e-14 1.421085e-14 1.421085e-14 
          94           95           99          100          101          104 
3.552714e-15 7.105427e-15 1.421085e-14 7.105427e-15 0.000000e+00 7.105427e-15 
         105          106          108          109          110          111 
7.105427e-15 1.421085e-14 1.065814e-14 1.421085e-14 1.421085e-14 1.421085e-14 
         112          113          114          116          117          118 
1.421085e-14 1.065814e-14 8.881784e-15 1.421085e-14 2.842171e-14 1.421085e-14 
         120          121          122          123          124          125 
0.000000e+00 1.421085e-14 1.421085e-14 1.421085e-14 1.421085e-14 1.421085e-14 
         126          127          128          129          130          131 
1.421085e-14 0.000000e+00 7.105427e-15 0.000000e+00 7.105427e-15 1.421085e-14 
         132          133          134          135          136          137 
1.776357e-14 1.776357e-14 3.552714e-15 1.065814e-14 2.131628e-14 1.421085e-14 
         138          139          140          141          142          143 
1.421085e-14 1.421085e-14 1.687539e-14 1.065814e-14 1.776357e-14 1.421085e-14 
         144          145          146          147          148          149 
2.042810e-14 1.421085e-14 7.105427e-15 1.598721e-14 1.065814e-14 2.842171e-14 
         151          152          153 
1.065814e-14 2.131628e-14 1.776357e-14 
> print (max(abs(f1 - f2[common])))
[1] 2.842171e-14
> print (100*.Machine$double.eps)
[1] 2.220446e-14
> stopifnot(max(abs(f1 - f2[common])) < 100*.Machine$double.eps)
Error: max(abs(f1 - f2[common])) < 100 * .Machine$double.eps is not TRUE
Execution halted
From p.dalgaard at biostat.ku.dk  Sun Apr 10 11:01:04 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun Apr 10 11:01:20 2005
Subject: [Rd] make check-all fails (PR#7784)
In-Reply-To: <42585C9F.7010903@cesmail.net>
References: <20050409182411.C7B2CCA33@slim.kubism.ku.dk>
	<42585C9F.7010903@cesmail.net>
Message-ID: <x2zmw7knu7.fsf@turmalin.kubism.ku.dk>

"M. Edward (Ed) Borasky" <znmeb@cesmail.net> writes:

> p.dalgaard@biostat.ku.dk wrote:
> 
> >This looks more serious. 100 times machine precision is quite a large
> >margin in these matters. Could you perhaps stick in a printout of the
> >two terms and their difference?
> >
> >I have an ATLAS build on AMD64 and it passes all the checks, but it is
> >using ATLAS 3.7.8, so you might want to try an upgrade.
> >
> >
> Attached ... you actually weren't very far off:
...
> > print (f2[common])
>          1          2          3          4          7          8          9 
>  32.971099  37.113091  27.472204  16.891921  32.320560  -6.091053 -26.953745 
>         12         13         14         15         16         17         18 
...
>  41.798651  40.734935  40.285066  24.876177   8.442082  46.373463  72.652242 
>        118        120        121        122        123        124        125 
>  65.983901  81.140660 101.389698  92.784665  86.803528  66.813059  76.464152 
>        126        127        128        129        130        131        132 
>  85.562396  80.164720  55.046451  22.602751  38.602215  35.466808  28.565003 
>        133        134        135        136        137        138        139 
>  30.487396  27.515347  17.475536  49.119123  11.994736  14.701687  49.795201 
>        140        141        142        143        144        145        146 
>   5.664599  24.711067  20.426534  53.013693   5.758723  19.324367  41.190110 
>        147        148        149        151        152        153 
>  14.189862 -19.275130  35.155615  20.525269  40.584670  18.702940 
...

Aha! 100 times machine precision in not all that much when the numbers
themselves are in double digits. In fact, one is over 100. The case
that triggers the failure is #149

>           147           148           149           151           152 
> -1.598721e-14 -1.065814e-14 -2.842171e-14 -1.065814e-14 -2.131628e-14 

which is 2 ULP off by my reckoning (scaling 35.15 to be between 0.5
and 1 makes the error 2.842e-14/64 =  4.44e-16 and .Machine@double.eps
is 2.22e-16).

So again, we might be too strict. I just wonder why we haven't heard
of this on any other platforms.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Sun Apr 10 14:21:41 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun Apr 10 14:21:57 2005
Subject: [Rd] make check-all fails (PR#7784)
In-Reply-To: <x2zmw7knu7.fsf@turmalin.kubism.ku.dk>
References: <20050409182411.C7B2CCA33@slim.kubism.ku.dk>
	<42585C9F.7010903@cesmail.net> <x2zmw7knu7.fsf@turmalin.kubism.ku.dk>
Message-ID: <x2aco6styi.fsf@turmalin.kubism.ku.dk>

Peter Dalgaard <p.dalgaard@biostat.ku.dk> writes:

> Aha! 100 times machine precision in not all that much when the numbers
> themselves are in double digits. In fact, one is over 100. The case
> that triggers the failure is #149
> 
> >           147           148           149           151           152 
> > -1.598721e-14 -1.065814e-14 -2.842171e-14 -1.065814e-14 -2.131628e-14 
> 
> which is 2 ULP off by my reckoning (scaling 35.15 to be between 0.5
> and 1 makes the error 2.842e-14/64 =  4.44e-16 and .Machine@double.eps
> is 2.22e-16).
> 
> So again, we might be too strict. I just wonder why we haven't heard
> of this on any other platforms.

I've fixed the precision requirement (for this and the reg-tests-1
issue) in the repository and what should become tomorrow's beta
version.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Sun Apr 10 14:21:52 2005
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Sun Apr 10 14:22:06 2005
Subject: [Rd] make check-all fails (PR#7784)
Message-ID: <20050410122152.B6293AD33@slim.kubism.ku.dk>

Peter Dalgaard <p.dalgaard@biostat.ku.dk> writes:

> Aha! 100 times machine precision in not all that much when the numbers
> themselves are in double digits. In fact, one is over 100. The case
> that triggers the failure is #149
> 
> >           147           148           149           151           152 
> > -1.598721e-14 -1.065814e-14 -2.842171e-14 -1.065814e-14 -2.131628e-14 
> 
> which is 2 ULP off by my reckoning (scaling 35.15 to be between 0.5
> and 1 makes the error 2.842e-14/64 =  4.44e-16 and .Machine@double.eps
> is 2.22e-16).
> 
> So again, we might be too strict. I just wonder why we haven't heard
> of this on any other platforms.

I've fixed the precision requirement (for this and the reg-tests-1
issue) in the repository and what should become tomorrow's beta
version.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From plummer at iarc.fr  Sun Apr 10 16:03:42 2005
From: plummer at iarc.fr (plummer@iarc.fr)
Date: Sun Apr 10 16:05:29 2005
Subject: [Rd] new R package BRugs
In-Reply-To: <4256B30C.50607@statistik.uni-dortmund.de>
References: <XFMail.050408141600.Ted.Harding@nessie.mcc.ac.uk>
	<4256B30C.50607@statistik.uni-dortmund.de>
Message-ID: <1113141822.4259323e8fdd1@webmail.iarc.fr>

Quoting Uwe Ligges <ligges@statistik.uni-dortmund.de>:

> OK, here we go (since we forgot to address the the Linux folks' problems
> explicitly - apologies!).
>
> *In principle*, you need the 1.5 version of the BlackBox Compiler from
> http://www.oberon.ch/blackbox.html
>
> Details and documentation how to compile are available from the
> developer manual:
> http://mathstat.helsinki.fi/openbugs/data/Docu/Developer%20Manual.html
>
> *BUT*:
> - We (Sibylle and Uwe) have not managed to compile OpenBUGS ourselves.
> - In particular, we have not managed to get the .dll/.so compiled, and
> Andrew Thomas writes in the developer manual: "Please note I am the only
> person who has the ELF linker at present".
>
> That's why we do ship the .so/.dll for now (and later?).
>
> Andrew Thomas told us that the .so is supposed to work under some Linux
> versions (I have never managed to get it to work up to now, but this is
> high level on the ToDo list).

The linux .so assumes an old kernel ABI. With a recent Linux kernel you will
need to do (in a bash shell)

export LD_ASSUME_KERNEL=2.4.1

before using it. If not you will get a BlackBox message about failure to install
signal.

Unfortunately the BRugs package still crashes R with a memory error, but
presumably it is one step closer to working.

> The .dll has been tested on WinNT, WinXP and WinServer2003.
>
> Best,
> Uwe
>
>

From znmeb at cesmail.net  Sun Apr 10 20:50:14 2005
From: znmeb at cesmail.net (M. Edward (Ed) Borasky)
Date: Sun Apr 10 20:50:39 2005
Subject: [Rd] make check-all fails (PR#7784)
In-Reply-To: <x2zmw7knu7.fsf@turmalin.kubism.ku.dk>
References: <20050409182411.C7B2CCA33@slim.kubism.ku.dk>	<42585C9F.7010903@cesmail.net>
	<x2zmw7knu7.fsf@turmalin.kubism.ku.dk>
Message-ID: <42597566.6060606@cesmail.net>

Peter Dalgaard wrote:

>"M. Edward (Ed) Borasky" <znmeb@cesmail.net> writes:
>
>  
>
>>p.dalgaard@biostat.ku.dk wrote:
>>
>>    
>>
>>>This looks more serious. 100 times machine precision is quite a large
>>>margin in these matters. Could you perhaps stick in a printout of the
>>>two terms and their difference?
>>>
>>>I have an ATLAS build on AMD64 and it passes all the checks, but it is
>>>using ATLAS 3.7.8, so you might want to try an upgrade.
>>>
>>>
>>>      
>>>
>>Attached ... you actually weren't very far off:
>>    
>>
>...
>  
>
>>>print (f2[common])
>>>      
>>>
>>         1          2          3          4          7          8          9 
>> 32.971099  37.113091  27.472204  16.891921  32.320560  -6.091053 -26.953745 
>>        12         13         14         15         16         17         18 
>>    
>>
>...
>  
>
>> 41.798651  40.734935  40.285066  24.876177   8.442082  46.373463  72.652242 
>>       118        120        121        122        123        124        125 
>> 65.983901  81.140660 101.389698  92.784665  86.803528  66.813059  76.464152 
>>       126        127        128        129        130        131        132 
>> 85.562396  80.164720  55.046451  22.602751  38.602215  35.466808  28.565003 
>>       133        134        135        136        137        138        139 
>> 30.487396  27.515347  17.475536  49.119123  11.994736  14.701687  49.795201 
>>       140        141        142        143        144        145        146 
>>  5.664599  24.711067  20.426534  53.013693   5.758723  19.324367  41.190110 
>>       147        148        149        151        152        153 
>> 14.189862 -19.275130  35.155615  20.525269  40.584670  18.702940 
>>    
>>
>...
>
>Aha! 100 times machine precision in not all that much when the numbers
>themselves are in double digits. In fact, one is over 100. The case
>that triggers the failure is #149
>
>  
>
>>          147           148           149           151           152 
>>-1.598721e-14 -1.065814e-14 -2.842171e-14 -1.065814e-14 -2.131628e-14 
>>    
>>
>
>which is 2 ULP off by my reckoning (scaling 35.15 to be between 0.5
>and 1 makes the error 2.842e-14/64 =  4.44e-16 and .Machine@double.eps
>is 2.22e-16).
>
>So again, we might be too strict. I just wonder why we haven't heard
>of this on any other platforms.
>
>  
>
I think it's an Atlas issue, and possibly an Atlas/Athlon32 issue. The 
built-in BLAS in R-beta don't show this. Is there enough detail on 
what's happening available for me to take this to the Atlas folks? 
They've done a lot of work, including assembler code, on Athlons and 
their 64-bit descendents. My "main system", where I've been doing this 
testing, is a rather old Athlon T-Bird.

Incidentally, even though Atlas does have most parameters set to 
pre-defined values for the Athlon/Linux, it does in fact make *some* 
decisions when it compiles, which may be why I'm showing this and nobody 
else is. I'm using Gentoo Linux, which recompiles nearly everything from 
source, including Atlas and R, when it does an install. Most of the 
other Linux distros have pre-compiled binaries for the various packages. 
Debian, for example, has pre-compiled Atlas libraries for P3, P4 and Athlon.

From ripley at stats.ox.ac.uk  Sun Apr 10 21:15:31 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Apr 10 21:15:56 2005
Subject: [Rd] make check-all fails (PR#7784)
In-Reply-To: <42597566.6060606@cesmail.net>
References: <20050409182411.C7B2CCA33@slim.kubism.ku.dk>
	<42585C9F.7010903@cesmail.net>
	<x2zmw7knu7.fsf@turmalin.kubism.ku.dk> <42597566.6060606@cesmail.net>
Message-ID: <Pine.LNX.4.61.0504102006180.18859@gannet.stats>

On Sun, 10 Apr 2005, M. Edward (Ed) Borasky wrote:

> Peter Dalgaard wrote:
>
>> "M. Edward (Ed) Borasky" <znmeb@cesmail.net> writes:
>> 
>> 
>>> p.dalgaard@biostat.ku.dk wrote:
>>> 
>>> 
>>>> This looks more serious. 100 times machine precision is quite a large
>>>> margin in these matters. Could you perhaps stick in a printout of the
>>>> two terms and their difference?
>>>> 
>>>> I have an ATLAS build on AMD64 and it passes all the checks, but it is
>>>> using ATLAS 3.7.8, so you might want to try an upgrade.
>>>> 
>>>> 
>>>> 
>>> Attached ... you actually weren't very far off:
>>> 
>> ...
>> 
>>>> print (f2[common])
>>>> 
>>>         1          2          3          4          7          8 
>>> 9 32.971099  37.113091  27.472204  16.891921  32.320560  -6.091053 
>>> -26.953745        12         13         14         15         16 
>>> 17         18 
>> ...
>> 
>>> 41.798651  40.734935  40.285066  24.876177   8.442082  46.373463 
>>> 72.652242       118        120        121        122        123        124 
>>> 125 65.983901  81.140660 101.389698  92.784665  86.803528  66.813059 
>>> 76.464152       126        127        128        129        130        131 
>>> 132 85.562396  80.164720  55.046451  22.602751  38.602215  35.466808 
>>> 28.565003       133        134        135        136        137        138 
>>> 139 30.487396  27.515347  17.475536  49.119123  11.994736  14.701687 
>>> 49.795201       140        141        142        143        144        145 
>>> 146  5.664599  24.711067  20.426534  53.013693   5.758723  19.324367 
>>> 41.190110       147        148        149        151        152        153 
>>> 14.189862 -19.275130  35.155615  20.525269  40.584670  18.702940 
>> ...
>> 
>> Aha! 100 times machine precision in not all that much when the numbers
>> themselves are in double digits. In fact, one is over 100. The case
>> that triggers the failure is #149
>> 
>> 
>>>          147           148           149           151           152 
>>> -1.598721e-14 -1.065814e-14 -2.842171e-14 -1.065814e-14 -2.131628e-14 
>> 
>> which is 2 ULP off by my reckoning (scaling 35.15 to be between 0.5
>> and 1 makes the error 2.842e-14/64 =  4.44e-16 and .Machine@double.eps
>> is 2.22e-16).
>> 
>> So again, we might be too strict. I just wonder why we haven't heard
>> of this on any other platforms.
>> 
>> 
> I think it's an Atlas issue, and possibly an Atlas/Athlon32 issue. The 
> built-in BLAS in R-beta don't show this. Is there enough detail on what's 
> happening available for me to take this to the Atlas folks? They've done a 
> lot of work, including assembler code, on Athlons and their 64-bit 
> descendents. My "main system", where I've been doing this testing, is a 
> rather old Athlon T-Bird.
>
> Incidentally, even though Atlas does have most parameters set to pre-defined 
> values for the Athlon/Linux, it does in fact make *some* decisions when it 
> compiles, which may be why I'm showing this and nobody else is. I'm using 
> Gentoo Linux, which recompiles nearly everything from source, including Atlas 
> and R, when it does an install. Most of the other Linux distros have 
> pre-compiled binaries for the various packages. Debian, for example, has 
> pre-compiled Atlas libraries for P3, P4 and Athlon.

I think the issue is ATLAS on your old Athlon.  ATLAS 3.6.0 compiled from 
the sources works correctly with gcc-3.4.3 on my Athlon MP (and also on an 
Athlon XP), but AFAIR those have instructions the Athlon Thunderbird does 
not have.  (Both my machines with such Athlons fried their motherboards, 
so I no longer have access to one.)

Incidentally to Peter: ATLAS 3.7.8 is an unreleased unstable version, so I 
would hesitate to recommend it over 3.6.0.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Sun Apr 10 22:25:37 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun Apr 10 22:25:52 2005
Subject: [Rd] make check-all fails (PR#7784)
In-Reply-To: <Pine.LNX.4.61.0504102006180.18859@gannet.stats>
References: <20050409182411.C7B2CCA33@slim.kubism.ku.dk>
	<42585C9F.7010903@cesmail.net> <x2zmw7knu7.fsf@turmalin.kubism.ku.dk>
	<42597566.6060606@cesmail.net>
	<Pine.LNX.4.61.0504102006180.18859@gannet.stats>
Message-ID: <x23bty2xby.fsf@turmalin.kubism.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> I think the issue is ATLAS on your old Athlon.  ATLAS 3.6.0 compiled
> from the sources works correctly with gcc-3.4.3 on my Athlon MP (and
> also on an Athlon XP), but AFAIR those have instructions the Athlon
> Thunderbird does not have.  (Both my machines with such Athlons fried
> their motherboards, so I no longer have access to one.)
> 
> Incidentally to Peter: ATLAS 3.7.8 is an unreleased unstable version,
> so I would hesitate to recommend it over 3.6.0.

To be precise, it's a release on an unstable branch. Hasn't changed
since 2004-07-23 though.. But you're right in principle; I had
forgotten about that.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From kjetil at acelerate.com  Sun Apr 10 20:00:52 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Sun Apr 10 23:22:28 2005
Subject: [Rd] strange error with rw2010dev
In-Reply-To: <4248AC1A.3020104@acelerate.com>
References: <4248AC1A.3020104@acelerate.com>
Message-ID: <425969D4.9020105@acelerate.com>

The error reported below still occurs in todays (2005-04-08)  rw2010beta,
should I file a formal bug report?

Kjetil.


Kjetil Brinchmann Halvorsen wrote:

> With rw2010dev I get a strange  protect(): protection stack overflow
> error with a small data frame which otherwise is usable:
>
> If anybody wants to have a look I can provide an RData file
> with the problematic data frame.
>
> Doesn't seem to be necessary, the following simulated example
> generates the error:
>
> > testmat <- matrix(1:80, 20,4)
> > dim(testmat)
> [1] 20  4
> > str(testmat)
> int [1:20, 1:4] 1 2 3 4 5 6 7 8 9 10 ...
> > testframe <- data.frame(testmat=I(testmat),
>    x=rnorm(20), y=rnorm(20), z=sample(1:20))
> > str(testframe)
> `data.frame':   20 obs. of  4 variables:
> $ testmat: int [1:20, 1:4] 1 2 3 4 5 6 7 8 9 10 ...
>  ..- attr(*, "class")= chr "AsIs"
> $ x      : num   0.768 -0.462  0.450  0.476 -1.077 ...
> $ y      : num   0.453  1.227 -1.514 -0.904 -0.129 ...
> $ z      : int  10 4 15 19 14 3 9 17 18 5 ...
> > summary(testframe)
> Error: protect(): protection stack overflow
>
>
> Kjetil
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.

From rich.fitzjohn at gmail.com  Mon Apr 11 05:43:42 2005
From: rich.fitzjohn at gmail.com (Rich FitzJohn)
Date: Mon Apr 11 05:43:58 2005
Subject: [Rd] S4 group methods don't dispatch for "Summary"?
Message-ID: <5934ae5705041020436d90301c@mail.gmail.com>

Hi all,

I am having a little problem with S4 group generics (apologies if I
get some terminology wrong below).  I'm finding I can set methods for some
group generic functions, but not others:

> setClass("foo", representation(data="numeric"))
> x <- new("foo", data=1:10)

## Setting "Ops" works just as expected:
> setMethod("Ops", signature("foo", "foo"), function(e1, e2)
          match.fun(.Generic)(e1@data, e2@data))
> x+x
 [1]  2  4  6  8 10 12 14 16 18 20

## But "Summary" does not:
> setMethod("Summary", signature("foo"), function(x, ..., na.rm=FALSE)
          browser())
> min(x)
[1] Inf
Warning message: 
no finite arguments to min; returning Inf 

## However, getMethod() shows that the method is registered:
> getMethod("Summary", "foo")
Method Definition:

function (x, ..., na.rm = FALSE) 
.Generic(x@data, ..., na.rm = na.rm)

Signatures:
        x    
target  "foo"
defined "foo"

If I set a method directly for the members of "Summary" (e.g. min),
the new function is still not dispatched.

Of the group generics listed in ?Summary, Arith, Compare, Ops, and
Complex work for me, and I cannot get Math, Math2 or Summary to work.

I presume I'm probably missing something, but am at a loss.  I would
appreciate any pointers as to what I am doing wrong.  I have run into
this problem on both Linux/R 2.0.1, and Windows/R 2.0.0 (will upgrade
soon!).

Thanks,
Rich

-- 
Rich FitzJohn
rich.fitzjohn <at> gmail.com   |    http://homepages.paradise.net.nz/richa183
                      You are in a maze of twisty little functions, all alike

-- 
Rich FitzJohn
rich.fitzjohn <at> gmail.com   |    http://homepages.paradise.net.nz/richa183
                      You are in a maze of twisty little functions, all alike

From maechler at stat.math.ethz.ch  Mon Apr 11 08:57:31 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Apr 11 08:57:39 2005
Subject: [Rd] strange error with rw2010dev
In-Reply-To: <425969D4.9020105@acelerate.com>
References: <4248AC1A.3020104@acelerate.com> <425969D4.9020105@acelerate.com>
Message-ID: <16986.8155.624235.787171@stat.math.ethz.ch>

>>>>> "Kjetil" == Kjetil Brinchmann Halvorsen <kjetil@acelerate.com>
>>>>>     on Sun, 10 Apr 2005 14:00:52 -0400 writes:

    Kjetil> The error reported below still occurs in todays
    Kjetil> (2005-04-08) rw2010beta, should I file a formal bug
    Kjetil> report?

Thank you, Kjetil.

It seems nobody has found time to look at this in the mean time.
However,
I can confirm the bug on quite a different platform
(Linux Redhat 64-bit on AMD 64).
The problem is infinite recursion which you see more easily,
when you set something like options(expressions=500).

Further note that the bug is not new, it also happens in
previous versions of R ( -> i.e. no reason to stop using "R 2.1.0 beta"!)

Here's a ``pure script''

testmat <- matrix(1:80, 20,4)
dim(testmat)
#
testframe <- data.frame(testmat=I(testmat),
                        x=rnorm(20), y=rnorm(20), z=sample(1:20))
str(testframe)

options(expressions=100)
summary(testframe)
##> Error: evaluation nested too deeply: infinite recursion / options(expression=)?
## -- or --
##> Error: protect(): protection stack overflow


### In the second case, I at least get a useful trace back:

traceback() ## longish output, shows the infinite recursion:

..........................
...........................

17: summary.data.frame(data.frame(object), ...)
16: summary.matrix(object, digits = digits, ...)
15: summary.default(X[[1]], ...)
14: FUN(X[[1]], ...)
13: lapply(as.list(object), summary, maxsum = maxsum, digits = 12, 
        ...)
12: summary.data.frame(data.frame(object), ...)
11: summary.matrix(object, digits = digits, ...)
10: summary.default(X[[1]], ...)
9: FUN(X[[1]], ...)
8: lapply(as.list(object), summary, maxsum = maxsum, digits = 12, 
       ...)
7: summary.data.frame(data.frame(object), ...)
6: summary.matrix(object, digits = digits, ...)
5: summary.default(X[[1]], ...)
4: FUN(X[[1]], ...)
3: lapply(as.list(object), summary, maxsum = maxsum, digits = 12, 
       ...)
2: summary.data.frame(testframe)
1: summary(testframe)

--------

Thanks again for the report;
this should be fixable before release.

Martin

From p.dalgaard at biostat.ku.dk  Mon Apr 11 09:46:11 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Apr 11 09:46:20 2005
Subject: [Rd] strange error with rw2010dev
In-Reply-To: <16986.8155.624235.787171@stat.math.ethz.ch>
References: <4248AC1A.3020104@acelerate.com> <425969D4.9020105@acelerate.com>
	<16986.8155.624235.787171@stat.math.ethz.ch>
Message-ID: <x2fyxxdad8.fsf@turmalin.kubism.ku.dk>

Martin Maechler <maechler@stat.math.ethz.ch> writes:

> >>>>> "Kjetil" == Kjetil Brinchmann Halvorsen <kjetil@acelerate.com>
> >>>>>     on Sun, 10 Apr 2005 14:00:52 -0400 writes:
> 
>     Kjetil> The error reported below still occurs in todays
>     Kjetil> (2005-04-08) rw2010beta, should I file a formal bug
>     Kjetil> report?
> 
> Thank you, Kjetil.
> 
> It seems nobody has found time to look at this in the mean time.
> However,
> I can confirm the bug on quite a different platform
> (Linux Redhat 64-bit on AMD 64).
> The problem is infinite recursion which you see more easily,
> when you set something like options(expressions=500).
> 
> Further note that the bug is not new, it also happens in
> previous versions of R ( -> i.e. no reason to stop using "R 2.1.0 beta"!)
> 
> Here's a ``pure script''
> 
> testmat <- matrix(1:80, 20,4)
> dim(testmat)
> #
> testframe <- data.frame(testmat=I(testmat),
>                         x=rnorm(20), y=rnorm(20), z=sample(1:20))
> str(testframe)
> 
> options(expressions=100)
> summary(testframe)
> ##> Error: evaluation nested too deeply: infinite recursion / options(expression=)?
> ## -- or --
> ##> Error: protect(): protection stack overflow
> 
> 
> ### In the second case, I at least get a useful trace back:
> 
> traceback() ## longish output, shows the infinite recursion:
> 
> ..........................
> ...........................
> 
> 17: summary.data.frame(data.frame(object), ...)
> 16: summary.matrix(object, digits = digits, ...)
> 15: summary.default(X[[1]], ...)
> 14: FUN(X[[1]], ...)
> 13: lapply(as.list(object), summary, maxsum = maxsum, digits = 12, 
>         ...)
> 12: summary.data.frame(data.frame(object), ...)
> 11: summary.matrix(object, digits = digits, ...)
> 10: summary.default(X[[1]], ...)
> 9: FUN(X[[1]], ...)
> 8: lapply(as.list(object), summary, maxsum = maxsum, digits = 12, 
>        ...)
> 7: summary.data.frame(data.frame(object), ...)
> 6: summary.matrix(object, digits = digits, ...)
> 5: summary.default(X[[1]], ...)
> 4: FUN(X[[1]], ...)
> 3: lapply(as.list(object), summary, maxsum = maxsum, digits = 12, 
>        ...)
> 2: summary.data.frame(testframe)
> 1: summary(testframe)
> 
> --------
> 
> Thanks again for the report;
> this should be fixable before release.

Preferably before code freeze! (today)

I think we (Thomas L.?) got it analysed once before: The issue is that
summary.matrix is passing data.frame(object) back to
summary.data.frame without removing the AsIs class.

I don't a simple unclass() will do here. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From maechler at stat.math.ethz.ch  Mon Apr 11 10:07:57 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Apr 11 10:08:04 2005
Subject: [Rd] strange error with rw2010dev
In-Reply-To: <x2fyxxdad8.fsf@turmalin.kubism.ku.dk>
References: <4248AC1A.3020104@acelerate.com> <425969D4.9020105@acelerate.com>
	<16986.8155.624235.787171@stat.math.ethz.ch>
	<x2fyxxdad8.fsf@turmalin.kubism.ku.dk>
Message-ID: <16986.12381.797445.890227@stat.math.ethz.ch>

>>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
>>>>>     on 11 Apr 2005 09:46:11 +0200 writes:

 .....

     MM> Thanks again for the report; this should be fixable
     MM> before release.

    PD> Preferably before code freeze! (today)

    PD> I think we (Thomas L.?) got it analysed once before: The
    PD> issue is that summary.matrix is passing
    PD> data.frame(object) back to summary.data.frame without
    PD> removing the AsIs class.

    PD> I don't a simple unclass() will do here.
	       
or, a bit more cautiously,

summary.matrix <- function(object, ...)
    summary.data.frame(data.frame(if(inherits(object,"AsIs")) unclass(object)
    else object), ...)

That does cure the problem in the Kjetil's example and the equivalent

 ## short 1-liner:
 summary(df <- data.frame(mat = I(matrix(1:8, 2))))


I'm currently make-checking the above.
Martin

From p.dalgaard at biostat.ku.dk  Mon Apr 11 10:16:21 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Apr 11 10:16:29 2005
Subject: [Rd] strange error with rw2010dev
In-Reply-To: <16986.12381.797445.890227@stat.math.ethz.ch>
References: <4248AC1A.3020104@acelerate.com> <425969D4.9020105@acelerate.com>
	<16986.8155.624235.787171@stat.math.ethz.ch>
	<x2fyxxdad8.fsf@turmalin.kubism.ku.dk>
	<16986.12381.797445.890227@stat.math.ethz.ch>
Message-ID: <x23btxd8yy.fsf@turmalin.kubism.ku.dk>

Martin Maechler <maechler@stat.math.ethz.ch> writes:

> >>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
> >>>>>     on 11 Apr 2005 09:46:11 +0200 writes:
> 
>  .....
> 
>      MM> Thanks again for the report; this should be fixable
>      MM> before release.
> 
>     PD> Preferably before code freeze! (today)
> 
>     PD> I think we (Thomas L.?) got it analysed once before: The
>     PD> issue is that summary.matrix is passing
>     PD> data.frame(object) back to summary.data.frame without
>     PD> removing the AsIs class.
> 
>     PD> I don't a simple unclass() will do here.
> 	       
> or, a bit more cautiously,

A "think" fell out in the above... Beware! I think you might want

cl <- class(object)
class(object) <- cl[cl != "AsIs"]

in case the object inherits from other classes. (Then again, it might
not be necessary, but better safe than sorry.)

> summary.matrix <- function(object, ...)
>     summary.data.frame(data.frame(if(inherits(object,"AsIs")) unclass(object)
>     else object), ...)
> 
> That does cure the problem in the Kjetil's example and the equivalent
> 
>  ## short 1-liner:
>  summary(df <- data.frame(mat = I(matrix(1:8, 2))))
> 
> 
> I'm currently make-checking the above.
> Martin
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Mon Apr 11 10:22:32 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Apr 11 10:22:40 2005
Subject: [Rd] strange error with rw2010dev
In-Reply-To: <16986.12381.797445.890227@stat.math.ethz.ch>
References: <4248AC1A.3020104@acelerate.com> <425969D4.9020105@acelerate.com>
	<16986.8155.624235.787171@stat.math.ethz.ch>
	<x2fyxxdad8.fsf@turmalin.kubism.ku.dk>
	<16986.12381.797445.890227@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0504110915220.30969@gannet.stats>

On Mon, 11 Apr 2005, Martin Maechler wrote:

>>>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
>>>>>>     on 11 Apr 2005 09:46:11 +0200 writes:
>
> .....
>
>     MM> Thanks again for the report; this should be fixable
>     MM> before release.
>
>    PD> Preferably before code freeze! (today)
>
>    PD> I think we (Thomas L.?) got it analysed once before: The
>    PD> issue is that summary.matrix is passing
>    PD> data.frame(object) back to summary.data.frame without
>    PD> removing the AsIs class.
>
>    PD> I don't a simple unclass() will do here.
>
> or, a bit more cautiously,
>
> summary.matrix <- function(object, ...)
>    summary.data.frame(data.frame(if(inherits(object,"AsIs")) unclass(object)
>    else object), ...)

I do not think that is correct.  You need either to remove the "AsIs" 
class and leave any other classes, or unclass all objects.
Otherwise adding an "AsIs" class will change the behaviour.

I would suggest that if you get to the summary.matrix method you want the 
summary as a matrix and so should always unclass, but that is debatable 
(think for example of an object of class c("mts", "ts"), which is a 
classed matrix, and there is an as.data.frame.ts method but no 
summary.ts).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From kjetil at acelerate.com  Mon Apr 11 03:16:47 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Mon Apr 11 11:39:35 2005
Subject: [Rd] cancor bug
Message-ID: <4259CFFF.4080405@acelerate.com>

I think the following is a bug in cancor. When one of the inputs
are rank deficient, the output loses dimensions.

Look at the following taken from example(cancor):

 > pop <- LifeCycleSavings[, 2:3]
 > oec <- LifeCycleSavings[, -(2:3)]
 > cancor(pop, oec)
$cor
[1] 0.8247966 0.3652762

$xcoef
              [,1]        [,2]
pop15 -0.009110856 -0.03622206
pop75  0.048647514 -0.26031158

$ycoef
             [,1]           [,2]            [,3]
sr   0.0084710221  0.03337935588 -0.005157129776
dpi  0.0001307398 -0.00007588232  0.000004543705
ddpi 0.0041706000 -0.01226789642  0.051883236069

$xcenter
  pop15   pop75
35.0896  2.2930

$ycenter
       sr       dpi      ddpi
   9.6710 1106.7584    3.7576

 > pop <- sweep(pop, 1, apply(pop, 1, sum), "/") # artificially 
constructing rank-deficient data.
 > cancor(pop, oec)
$cor
[1] 0.8184737

$xcoef
           [,1]
pop15 -2.818801

$ycoef
             [,1]           [,2]           [,3]
sr   0.0065719475  0.03128130402 -0.01381394682
dpi  0.0001349168 -0.00006333436  0.00002564945
ddpi 0.0036178800  0.00226518493  0.05330614649

$xcenter
     pop15      pop75
0.92893618 0.07106382

$ycenter
       sr       dpi      ddpi
   9.6710 1106.7584    3.7576

 >

Look at xcoef: The coefficient for pop75 is mising. (I encountered this
programming reduced rank regression).

Kjetil

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.

From kjetil at acelerate.com  Mon Apr 11 16:03:36 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Mon Apr 11 16:05:18 2005
Subject: [Rd] docu buglet
Message-ID: <425A83B8.2060203@acelerate.com>

?oneway.test

contains:

|var.equal| a logical variable indicating whether to treat the variances 
in the samples as equal. If |TRUE|, then a simple F test for the 
equality of means in a one-way analysis of variance is preformed. If 
|FALSE|, an approximate method of Welch (1951) is used, which 
generalizes the commonly known 2-sample Welch test to the case of 
arbitrarily many samples.

I guess preformed should read performed

Kjetil

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.

From murdoch at math.aau.dk  Mon Apr 11 17:02:14 2005
From: murdoch at math.aau.dk (Duncan Murdoch)
Date: Mon Apr 11 17:02:21 2005
Subject: [Rd] docu buglet
In-Reply-To: <425A83B8.2060203@acelerate.com>
References: <425A83B8.2060203@acelerate.com>
Message-ID: <425A9176.4040402@math.aau.dk>

Kjetil Brinchmann Halvorsen wrote:
> ?oneway.test
> 
> contains:
> 
> |var.equal| a logical variable indicating whether to treat the variances 
> in the samples as equal. If |TRUE|, then a simple F test for the 
> equality of means in a one-way analysis of variance is preformed. If 
> |FALSE|, an approximate method of Welch (1951) is used, which 
> generalizes the commonly known 2-sample Welch test to the case of 
> arbitrarily many samples.
> 
> I guess preformed should read performed
> 

Thanks, I'll fix it.

Duncan Murdoch

From maechler at stat.math.ethz.ch  Mon Apr 11 17:18:56 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Apr 11 17:19:04 2005
Subject: [Rd] exists("loadings.default") ...
In-Reply-To: <A6DA59168387AF408128AC9C7EBE521D17E7F6@BOC-EXMAIL1.bocad.bank-banque-canada.ca>
References: <A6DA59168387AF408128AC9C7EBE521D17E7F6@BOC-EXMAIL1.bocad.bank-banque-canada.ca>
Message-ID: <16986.38240.449928.740979@stat.math.ethz.ch>

Paul Gilbert asked me the following, about a topic that was
dealt here (on R-devel) a few weeks ago (~ March 21):

>>>>> "PaulG" == Paul Gilbert <pgilbert@bank-banque-canada.ca>
>>>>>     on Mon, 11 Apr 2005 10:35:03 -0400 writes:

    PaulG> Martin, a while ago you suggested:

    >> For S3, it's a bit uglier, but I think you could still do -- in your
    >> package --

    >> if(!exists("loadings.default", mode="function")) {
    >>   loadings.default <- loadings
    >>   loadings <- function(x, ...) UseMethod("loadings")
    >> }

    PaulG> I don't think exists works properly here if namespaces are used and
    PaulG> loadings.default is not exported. (i.e. it always gives false.) I can
    PaulG> redefine loadings and loadings.default, but I can't guard against the
    PaulG> possibility that those might actually be defined in stats someday.

Yes, you are correct, one cannot easily use exists() for this
when namespaces are involved.

For S3 methods, instead of exists(), I think one should use
something like

  > !is.null(getS3method("loadings", "default", optional = TRUE))
  [1] FALSE
  > !is.null(getS3method("predict", "ppr", optional = TRUE))
  [1] TRUE

Apart from the need to mention something along this line on
'exists' help page,  I wonder if we shouldn't even consider providing an  
existsS3method() wrapper, or alternatively and analogously to getAnywhere() an
existsAnywhere() function.

Martin

From alexander_schinner at genua.de  Tue Apr 12 12:36:19 2005
From: alexander_schinner at genua.de (Alexander Schinner)
Date: Tue Apr 12 12:36:29 2005
Subject: [Rd] C Interface to R?
Message-ID: <200504121236.19913.alexander_schinner@genua.de>

Hi,

can somebody tell me, if there is a C or C++ Interface to the R? Reading the 
documentation, FAQ, CRAN etc. I found nothing. But as i am very new to R, I 
might have not searched in the right place.

Thanks,
Alexander

From sdavis2 at mail.nih.gov  Tue Apr 12 12:41:04 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue Apr 12 12:41:12 2005
Subject: [Rd] C Interface to R?
In-Reply-To: <200504121236.19913.alexander_schinner@genua.de>
References: <200504121236.19913.alexander_schinner@genua.de>
Message-ID: <8a0b157bceb645468e72eb1303a27c18@mail.nih.gov>

Have you looked at the "Writing R Extensions" manual:

http://cran.r-project.org/manuals.html

Sean

On Apr 12, 2005, at 6:36 AM, Alexander Schinner wrote:

> Hi,
>
> can somebody tell me, if there is a C or C++ Interface to the R? 
> Reading the
> documentation, FAQ, CRAN etc. I found nothing. But as i am very new to 
> R, I
> might have not searched in the right place.
>
> Thanks,
> Alexander
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From murdoch at math.aau.dk  Tue Apr 12 12:44:48 2005
From: murdoch at math.aau.dk (Duncan Murdoch)
Date: Tue Apr 12 12:44:55 2005
Subject: [Rd] C Interface to R?
In-Reply-To: <200504121236.19913.alexander_schinner@genua.de>
References: <200504121236.19913.alexander_schinner@genua.de>
Message-ID: <425BA6A0.5000600@math.aau.dk>

Alexander Schinner wrote:
> Hi,
> 
> can somebody tell me, if there is a C or C++ Interface to the R? Reading the 
> documentation, FAQ, CRAN etc. I found nothing. But as i am very new to R, I 
> might have not searched in the right place.

Yes, there is.  You want to look in the "Writing R Extensions" manual.

The easiest thing is to write C routines to be called from R, but you 
can also call some R functions or R itself from a C program.

Duncan Murdoch

From ripley at stats.ox.ac.uk  Tue Apr 12 13:25:59 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Apr 12 13:26:15 2005
Subject: [Rd] C Interface to R?
In-Reply-To: <425BA6A0.5000600@math.aau.dk>
References: <200504121236.19913.alexander_schinner@genua.de>
	<425BA6A0.5000600@math.aau.dk>
Message-ID: <Pine.LNX.4.61.0504121223160.3559@gannet.stats>

On Tue, 12 Apr 2005, Duncan Murdoch wrote:

> Alexander Schinner wrote:

>> can somebody tell me, if there is a C or C++ Interface to the R? Reading 
>> the documentation, FAQ, CRAN etc. I found nothing. But as i am very new to 
>> R, I might have not searched in the right place.
>
> Yes, there is.  You want to look in the "Writing R Extensions" manual.
>
> The easiest thing is to write C routines to be called from R, but you can 
> also call some R functions or R itself from a C program.

If you want to do the latter, please use the R 2.1.0 beta which has more 
convenience functions and much more extensive documentation. If you are 
using a Unix-alike OS, see also the examples in tests/Embedding (which 
work in 2.1.0 beta but not in 2.0.1).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From pgilbert at bank-banque-canada.ca  Tue Apr 12 14:29:52 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue Apr 12 14:30:53 2005
Subject: [Rd] par()$ask in plot.acf
Message-ID: <A6DA59168387AF408128AC9C7EBE521D17E7FC@BOC-EXMAIL1.bocad.bank-banque-canada.ca>

There seems to be a problem with acf (in both R-2.0.1 and R-2.1.0beta)
not passing par()$ask to the plot routine. I think the fix is that the
argument to plot.acf should be changed from
    ask = Npgs > 1 && dev.interactive()
to 
    ask = par()$ask | Npgs > 1 && dev.interactive()
 
Paul Gilbert

	[[alternative HTML version deleted]]

From jari.oksanen at oulu.fi  Tue Apr 12 15:57:25 2005
From: jari.oksanen at oulu.fi (jari.oksanen@oulu.fi)
Date: Tue Apr 12 15:57:39 2005
Subject: [Rd] MASS: isoMDS drops names of points in R-2.1.0 (PR#7786)
Message-ID: <20050412135725.85A2CCC58@slim.kubism.ku.dk>

Full_Name: Jari Oksanen
Version: 2.1.0
OS: Linux & MacOS X
Submission from: (NULL) (130.231.102.145)


isoMDS (MASS) drops names of points. The reason seems to be that R-2.1.0
abandoned names.dist that isoMDS uses to get the Labels attribute of dist
object:

    points <- matrix(tmp$y, , k)
    rn <- if (is.matrix(d))
        rownames(d)
    else names(d)   # This does not work any longer
    dimnames(points) <- list(rn, NULL)
    list(points = points, stress = tmp$val)

The solution is obvious but not very elegant.

From andy_liaw at merck.com  Tue Apr 12 15:59:24 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Apr 12 16:00:15 2005
Subject: [Rd] one suggestion for R-admin
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D9E@usctmx1106.merck.com>

Just one minor point about building bitmap.dll on Windows in
doc/manual/R-admin.texi:

In lines 601-605:

@item
You need @code{libpng} and @code{jpeg} sources (available, e.g., from
@url{http://www.libpng.org}, @url{ftp://ftp.uu.net/graphics/}[png,jpeg].
You will need files @file{libpng-1.2.8.tar.gz} and
@file{jpegsrc.v6b.tar.gz} or later.

and lines 699-707:

The file @file{@var{R_HOME}/bin/Rbitmap.dll} is not built automatically:
instructions on how to build it are in the file @file{bitmap/INSTALL}.

If everything is set up in directory @file{bitmap},
@example
make bitmapdll
@end example
@noindent
will work from this directory.

Why not just add the instruction in src/gnuwin32/bitmap/INSTALL into these
places?  It seems like unnecessary work to go find the few lines of
instruction in a different file...  (Especially in the first part quoted
above:  It tells what to get the files, but not where to put them.)

Best,
Andy

From jari.oksanen at oulu.fi  Tue Apr 12 16:07:39 2005
From: jari.oksanen at oulu.fi (jari.oksanen@oulu.fi)
Date: Tue Apr 12 16:07:53 2005
Subject: [Rd] stripchart: doc of add (PR#7787)
Message-ID: <20050412140739.D82E4CC5C@slim.kubism.ku.dk>

Full_Name: Jari Oksanen
Version: 2.1.0  and 2.0.1
OS: linux
Submission from: (NULL) (130.231.102.145)


?stripchart says:

add: logical, if true _add_ boxplot to current plot.

However, 'add' does not add a boxplot, but it adds a stripchart to an existing
plot (overlays). See:

example(stripchart)

From ripley at stats.ox.ac.uk  Tue Apr 12 16:44:51 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Apr 12 16:45:12 2005
Subject: [Rd] MASS: isoMDS drops names of points in R-2.1.0 (PR#7786)
In-Reply-To: <20050412135725.85A2CCC58@slim.kubism.ku.dk>
References: <20050412135725.85A2CCC58@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0504121544110.9543@gannet.stats>

Please DO read the FAQ and do not send reports on contributed packages to 
R-bugs.

On Tue, 12 Apr 2005 jari.oksanen@oulu.fi wrote:

> Full_Name: Jari Oksanen
> Version: 2.1.0
> OS: Linux & MacOS X
> Submission from: (NULL) (130.231.102.145)
>
>
> isoMDS (MASS) drops names of points. The reason seems to be that R-2.1.0
> abandoned names.dist that isoMDS uses to get the Labels attribute of dist
> object:
>
>    points <- matrix(tmp$y, , k)
>    rn <- if (is.matrix(d))
>        rownames(d)
>    else names(d)   # This does not work any longer
>    dimnames(points) <- list(rn, NULL)
>    list(points = points, stress = tmp$val)
>
> The solution is obvious but not very elegant.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From andy_liaw at merck.com  Tue Apr 12 18:57:31 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Apr 12 18:58:19 2005
Subject: [Rd] patch to add a menu item in Rgui for RSiteSearch
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DA2@usctmx1106.merck.com>

Please consider adding the following to the next R release (I understand
that it's too late for R-2.1.0).  It adds the menu item `Search R Site' in
the `Help' menu in Rgui (which calls RSiteSearch() on the input string).

Best,
Andy

--- R-beta/src/gnuwin32/rui.c	2005-03-06 09:41:40.000000000 -0500
+++ R-beta-new/src/gnuwin32/rui.c	2005-04-12 08:21:55.001824500 -0400
@@ -65,7 +65,8 @@
 static menuitem msource, mdisplay, mload, msave, mloadhistory,
     msavehistory, mpaste, mpastecmds, mcopy, mcopypaste, mlazy, mconfig,
     mls, mrm, msearch, mhelp, mmanintro, mmanref, mmandata,
-    mmanext, mmanlang, mmanadmin, mman0, mapropos, mhelpstart, mhelpsearch,

+    mmanext, mmanlang, mmanadmin, mman0, mapropos, mhelpstart, mhelpsearch,
+    msearchRsite,
     mFAQ, mrwFAQ, mpkgl, mpkgm, mpkgi, mpkgil, mpkgu, /*mpkgb, mpkgbu,*/
     mde, mCRAN, mrepos;
 static int lmanintro, lmanref, lmandata, lmanlang, lmanext, lmanadmin;
@@ -485,6 +486,21 @@
     }
 }
 
+static void menusearchRsite(control m)
+{
+    char *s;
+    static char olds[256] = "";
+
+    if (!ConsoleAcceptCmd) return;
+    s = askstring(G_("Search R Site"), olds);
+    if (s && strlen(s)) {
+	snprintf(cmd, 1024, "RSiteSearch(\"%s\")", s);
+	if (strlen(s) > 255) s[255] = '\0';
+	strcpy(olds, s);
+	consolecmd(RConsole, cmd);
+    }
+}
+
 static void menuapropos(control m)
 {
     char *s;
@@ -560,6 +576,7 @@
 	enable(msearch);
 	enable(mhelp);
 	enable(mhelpsearch);
+	enable(msearchRsite);
 	enable(mapropos);
 	enable(mpkgl);
 	enable(mpkgm);
@@ -579,6 +596,7 @@
 	disable(msearch);
 	disable(mhelp);
 	disable(mhelpsearch);
+	disable(msearchRsite);
 	disable(mapropos);
 	disable(mpkgl);
 	disable(mpkgm);
@@ -985,6 +1003,7 @@
     MCHECK(mhelpstart = newmenuitem(G_("Html help"), 0, menuhelpstart));
     if (!check_doc_file("doc\\html\\rwin.html")) disable(mhelpstart);
     MCHECK(mhelpsearch = newmenuitem(G_("Search help..."), 0,
menuhelpsearch));
+    MCHECK(msearchRsite = newmenuitem(G_("Search R Site..."), 0,
menusearchRsite));
     MCHECK(newmenuitem("-", 0, NULL));
     MCHECK(mapropos = newmenuitem(G_("Apropos..."), 0, menuapropos));
     MCHECK(newmenuitem("-", 0, NULL));

From ripley at stats.ox.ac.uk  Tue Apr 12 19:09:01 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Apr 12 19:09:20 2005
Subject: [Rd] patch to add a menu item in Rgui for RSiteSearch
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DA2@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DA2@usctmx1106.merck.com>
Message-ID: <Pine.LNX.4.61.0504121802250.11312@gannet.stats>

On Tue, 12 Apr 2005, Liaw, Andy wrote:

> Please consider adding the following to the next R release (I understand
> that it's too late for R-2.1.0).  It adds the menu item `Search R Site' in
> the `Help' menu in Rgui (which calls RSiteSearch() on the input string).

Can you or someone else think of a better name?  That sounds like it 
searches www.r-project.org.  I think even 'R Sites Search' would be 
better.

Yes, it is too late: we need lead time for the translators these days.
(RGui has Chinese, German, Italian and Japanese menus available.)

>
> Best,
> Andy
>
> --- R-beta/src/gnuwin32/rui.c	2005-03-06 09:41:40.000000000 -0500
> +++ R-beta-new/src/gnuwin32/rui.c	2005-04-12 08:21:55.001824500 -0400
> @@ -65,7 +65,8 @@
> static menuitem msource, mdisplay, mload, msave, mloadhistory,
>     msavehistory, mpaste, mpastecmds, mcopy, mcopypaste, mlazy, mconfig,
>     mls, mrm, msearch, mhelp, mmanintro, mmanref, mmandata,
> -    mmanext, mmanlang, mmanadmin, mman0, mapropos, mhelpstart, mhelpsearch,
>
> +    mmanext, mmanlang, mmanadmin, mman0, mapropos, mhelpstart, mhelpsearch,
> +    msearchRsite,
>     mFAQ, mrwFAQ, mpkgl, mpkgm, mpkgi, mpkgil, mpkgu, /*mpkgb, mpkgbu,*/
>     mde, mCRAN, mrepos;
> static int lmanintro, lmanref, lmandata, lmanlang, lmanext, lmanadmin;
> @@ -485,6 +486,21 @@
>     }
> }
>
> +static void menusearchRsite(control m)
> +{
> +    char *s;
> +    static char olds[256] = "";
> +
> +    if (!ConsoleAcceptCmd) return;
> +    s = askstring(G_("Search R Site"), olds);
> +    if (s && strlen(s)) {
> +	snprintf(cmd, 1024, "RSiteSearch(\"%s\")", s);
> +	if (strlen(s) > 255) s[255] = '\0';
> +	strcpy(olds, s);
> +	consolecmd(RConsole, cmd);
> +    }
> +}
> +
> static void menuapropos(control m)
> {
>     char *s;
> @@ -560,6 +576,7 @@
> 	enable(msearch);
> 	enable(mhelp);
> 	enable(mhelpsearch);
> +	enable(msearchRsite);
> 	enable(mapropos);
> 	enable(mpkgl);
> 	enable(mpkgm);
> @@ -579,6 +596,7 @@
> 	disable(msearch);
> 	disable(mhelp);
> 	disable(mhelpsearch);
> +	disable(msearchRsite);
> 	disable(mapropos);
> 	disable(mpkgl);
> 	disable(mpkgm);
> @@ -985,6 +1003,7 @@
>     MCHECK(mhelpstart = newmenuitem(G_("Html help"), 0, menuhelpstart));
>     if (!check_doc_file("doc\\html\\rwin.html")) disable(mhelpstart);
>     MCHECK(mhelpsearch = newmenuitem(G_("Search help..."), 0,
> menuhelpsearch));
> +    MCHECK(msearchRsite = newmenuitem(G_("Search R Site..."), 0,
> menusearchRsite));
>     MCHECK(newmenuitem("-", 0, NULL));
>     MCHECK(mapropos = newmenuitem(G_("Apropos..."), 0, menuapropos));
>     MCHECK(newmenuitem("-", 0, NULL));
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From andy_liaw at merck.com  Tue Apr 12 19:16:57 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Apr 12 19:17:44 2005
Subject: [Rd] patch to add a menu item in Rgui for RSiteSearch
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DA4@usctmx1106.merck.com>

> From: Prof Brian Ripley
> 
> On Tue, 12 Apr 2005, Liaw, Andy wrote:
> 
> > Please consider adding the following to the next R release 
> (I understand
> > that it's too late for R-2.1.0).  It adds the menu item 
> `Search R Site' in
> > the `Help' menu in Rgui (which calls RSiteSearch() on the 
> input string).
> 
> Can you or someone else think of a better name?  That sounds like it 
> searches www.r-project.org.  I think even 'R Sites Search' would be 
> better.

I can't (sorry, not very imaginative...).  Your suggestion is as good as I
can see.

I guess I can also add more descriptive phrase, e.g., 

   s = askstring(G_("Search in R documentations and R-help archive"), olds);

Any other suggestions?

Best,
Andy
 
> Yes, it is too late: we need lead time for the translators these days.
> (RGui has Chinese, German, Italian and Japanese menus available.)
> 
> >
> > Best,
> > Andy
> >
> > --- R-beta/src/gnuwin32/rui.c	2005-03-06 
> 09:41:40.000000000 -0500
> > +++ R-beta-new/src/gnuwin32/rui.c	2005-04-12 
> 08:21:55.001824500 -0400
> > @@ -65,7 +65,8 @@
> > static menuitem msource, mdisplay, mload, msave, mloadhistory,
> >     msavehistory, mpaste, mpastecmds, mcopy, mcopypaste, 
> mlazy, mconfig,
> >     mls, mrm, msearch, mhelp, mmanintro, mmanref, mmandata,
> > -    mmanext, mmanlang, mmanadmin, mman0, mapropos, 
> mhelpstart, mhelpsearch,
> >
> > +    mmanext, mmanlang, mmanadmin, mman0, mapropos, 
> mhelpstart, mhelpsearch,
> > +    msearchRsite,
> >     mFAQ, mrwFAQ, mpkgl, mpkgm, mpkgi, mpkgil, mpkgu, 
> /*mpkgb, mpkgbu,*/
> >     mde, mCRAN, mrepos;
> > static int lmanintro, lmanref, lmandata, lmanlang, lmanext, 
> lmanadmin;
> > @@ -485,6 +486,21 @@
> >     }
> > }
> >
> > +static void menusearchRsite(control m)
> > +{
> > +    char *s;
> > +    static char olds[256] = "";
> > +
> > +    if (!ConsoleAcceptCmd) return;
> > +    s = askstring(G_("Search R Site"), olds);
> > +    if (s && strlen(s)) {
> > +	snprintf(cmd, 1024, "RSiteSearch(\"%s\")", s);
> > +	if (strlen(s) > 255) s[255] = '\0';
> > +	strcpy(olds, s);
> > +	consolecmd(RConsole, cmd);
> > +    }
> > +}
> > +
> > static void menuapropos(control m)
> > {
> >     char *s;
> > @@ -560,6 +576,7 @@
> > 	enable(msearch);
> > 	enable(mhelp);
> > 	enable(mhelpsearch);
> > +	enable(msearchRsite);
> > 	enable(mapropos);
> > 	enable(mpkgl);
> > 	enable(mpkgm);
> > @@ -579,6 +596,7 @@
> > 	disable(msearch);
> > 	disable(mhelp);
> > 	disable(mhelpsearch);
> > +	disable(msearchRsite);
> > 	disable(mapropos);
> > 	disable(mpkgl);
> > 	disable(mpkgm);
> > @@ -985,6 +1003,7 @@
> >     MCHECK(mhelpstart = newmenuitem(G_("Html help"), 0, 
> menuhelpstart));
> >     if (!check_doc_file("doc\\html\\rwin.html")) 
> disable(mhelpstart);
> >     MCHECK(mhelpsearch = newmenuitem(G_("Search help..."), 0,
> > menuhelpsearch));
> > +    MCHECK(msearchRsite = newmenuitem(G_("Search R Site..."), 0,
> > menusearchRsite));
> >     MCHECK(newmenuitem("-", 0, NULL));
> >     MCHECK(mapropos = newmenuitem(G_("Apropos..."), 0, 
> menuapropos));
> >     MCHECK(newmenuitem("-", 0, NULL));
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 
>

From vograno at evafunds.com  Tue Apr 12 21:31:03 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Tue Apr 12 21:31:57 2005
Subject: [Rd] How allocate STRSXP outside of gc
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A59E8922@phost015.EVAFUNDS.intermedia.net>

Hi,
 
I am trying to figure a way to allocate a string SEXP so that gc() won't
ever collect it.
 
Here is a little bit of a background. Suppose I want to write a
.Call-callable function that upon each call returns the same value, say
mkChar("foo"):
 
SEXP getFoo() {
   return mkChar("foo");
}
 
The above implementation doesn't take advantage of the fact that
mkChar("foo") could be pre-computed only once, and then the function
would return the pre-computed value. So the question is how to create
this precomputed value.
 
 
The closest thing I could find in the sources is R_NaString, but I was
not able to trace down how it comes about.
 
 
Thanks,
Vadim
 
 
P.S. I was able to solve a similar problem with symbols. If I need a
symbol "foo", I do
 
static SEXP  FooSymbol = install("foo");
 
and then use FooSymbol instead of install("foo")
 
 
 

	[[alternative HTML version deleted]]

From vograno at evafunds.com  Tue Apr 12 22:38:17 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Tue Apr 12 22:38:56 2005
Subject: [Rd] How allocate STRSXP outside of gc
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A59E8931@phost015.EVAFUNDS.intermedia.net>

Thanks Duncan!

R_PreserveObject will do. One thought, wouldn't it make sense to modify
R_PreserveObject to return its argument?
This would allow things like

static SEXP fooSexp = R_PreserveObject(mkChar("foo"));

and would also make R_PreserveObject more similar to Rf_protect().

There should be no problem w/ backward compatability, at least not that
I could see.

Thanks,
Vadim

> -----Original Message-----
> From: Duncan Temple Lang [mailto:duncan@wald.ucdavis.edu] 
> Sent: Tuesday, April 12, 2005 12:52 PM
> To: Vadim Ogranovich
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] How allocate STRSXP outside of gc
> 
> Look at R_PreserveObject to see if it will do what you want.
> It certainly used to.
> 
> SEXP getFoo()
> {
>   static SEXP val = NULL;
> 
>   if(!val) {
>     val = mkChar("foo");
>     R_PreserveObject(val);
>   }
> 
>   return(val);
> }
> 
> 
> You may want to have a routine that is called when the 
> package is unloaded that calls R_ReleaseObject().
> 
> Alternatively, store the object in a package's namespace 
> environment and it won't be gc'ed.
> 
>  D.
> 
> 
> Vadim Ogranovich wrote:
> > Hi,
> >  
> > I am trying to figure a way to allocate a string SEXP so that gc() 
> > won't ever collect it.
> >  
> > Here is a little bit of a background. Suppose I want to write a 
> > .Call-callable function that upon each call returns the same value, 
> > say
> > mkChar("foo"):
> >  
> > SEXP getFoo() {
> >    return mkChar("foo");
> > }
> >  
> > The above implementation doesn't take advantage of the fact that
> > mkChar("foo") could be pre-computed only once, and then the 
> function 
> > would return the pre-computed value. So the question is how 
> to create 
> > this precomputed value.
> >  
> >  
> > The closest thing I could find in the sources is 
> R_NaString, but I was 
> > not able to trace down how it comes about.
> >  
> >  
> > Thanks,
> > Vadim
> >  
> >  
> > P.S. I was able to solve a similar problem with symbols. If 
> I need a 
> > symbol "foo", I do
> >  
> > static SEXP  FooSymbol = install("foo");
> >  
> > and then use FooSymbol instead of install("foo")
> >  
> >  
> >  
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Duncan Temple Lang                duncan@wald.ucdavis.edu
> Department of Statistics          work:  (530) 752-4782
> 371 Kerr Hall                     fax:   (530) 752-7099
> One Shields Ave.
> University of California at Davis
> Davis, CA 95616, USA
> 
> 
> 
>

From doris.soehnlein at iab.de  Wed Apr 13 10:05:44 2005
From: doris.soehnlein at iab.de (doris.soehnlein@iab.de)
Date: Wed Apr 13 10:05:52 2005
Subject: [Rd] IAB (PR#7788)
Message-ID: <20050413080544.BB8C3CA0A@slim.kubism.ku.dk>

Full_Name: Doris S?hnlein
Version: 1.8.1
OS: XP
Submission from: (NULL) (212.204.77.23)


It is not possible to save workspace image and the following error messages
appear:
> help.start()
updating HTML package listing
updating HTML search index
Error in file(f.tg, open = "w") : unable to open connection
In addition: Warning messages: 
1: cannot update HTML package index in: make.packages.html(.libPaths()) 
2: cannot open file `C:\Programme\R_rw1081/doc/html/search/index.txt' 
If nothing happens, you should open ` C:\Programme\R_rw1081\doc\html\rwin.html '
yourself
> q()
Error in file(file, "wb") : unable to open connection
In addition: Warning message: 
cannot open file `.RDataTmp' 

Was the installation not correct?

From murdoch at math.aau.dk  Wed Apr 13 10:12:37 2005
From: murdoch at math.aau.dk (Duncan Murdoch)
Date: Wed Apr 13 10:12:45 2005
Subject: [Rd] one suggestion for R-admin
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D9E@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076D9E@usctmx1106.merck.com>
Message-ID: <425CD475.3050605@math.aau.dk>

Liaw, Andy wrote:
> Just one minor point about building bitmap.dll on Windows in
> doc/manual/R-admin.texi:
> 
> In lines 601-605:
> 
> @item
> You need @code{libpng} and @code{jpeg} sources (available, e.g., from
> @url{http://www.libpng.org}, @url{ftp://ftp.uu.net/graphics/}[png,jpeg].
> You will need files @file{libpng-1.2.8.tar.gz} and
> @file{jpegsrc.v6b.tar.gz} or later.
> 
> and lines 699-707:
> 
> The file @file{@var{R_HOME}/bin/Rbitmap.dll} is not built automatically:
> instructions on how to build it are in the file @file{bitmap/INSTALL}.
> 
> If everything is set up in directory @file{bitmap},
> @example
> make bitmapdll
> @end example
> @noindent
> will work from this directory.
> 
> Why not just add the instruction in src/gnuwin32/bitmap/INSTALL into these
> places?  It seems like unnecessary work to go find the few lines of
> instruction in a different file...  (Especially in the first part quoted
> above:  It tells what to get the files, but not where to put them.)

Good suggestion; I've just done it.  I think the only reason I didn't do 
it before was laziness.

Duncan Murdoch

From murdoch at math.aau.dk  Wed Apr 13 10:18:49 2005
From: murdoch at math.aau.dk (Duncan Murdoch)
Date: Wed Apr 13 10:18:58 2005
Subject: [Rd] IAB (PR#7788)
In-Reply-To: <20050413080544.BB8C3CA0A@slim.kubism.ku.dk>
References: <20050413080544.BB8C3CA0A@slim.kubism.ku.dk>
Message-ID: <425CD5E9.6030800@math.aau.dk>

doris.soehnlein@iab.de wrote:
> Full_Name: Doris S?hnlein
> Version: 1.8.1
> OS: XP
> Submission from: (NULL) (212.204.77.23)
> 
> 
> It is not possible to save workspace image and the following error messages
> appear:
> 
>>help.start()
> 
> updating HTML package listing
> updating HTML search index
> Error in file(f.tg, open = "w") : unable to open connection
> In addition: Warning messages: 
> 1: cannot update HTML package index in: make.packages.html(.libPaths()) 
> 2: cannot open file `C:\Programme\R_rw1081/doc/html/search/index.txt' 
> If nothing happens, you should open ` C:\Programme\R_rw1081\doc\html\rwin.html '
> yourself
> 
>>q()
> 
> Error in file(file, "wb") : unable to open connection
> In addition: Warning message: 
> cannot open file `.RDataTmp' 
> 
> Was the installation not correct?'

Version 1.8.1 is a couple of years old; please upgrade.  In general we 
don't fix bugs in older versions, and you shouldn't submit bug reports 
about them.

Duncan Murdoch

From ligges at statistik.uni-dortmund.de  Wed Apr 13 10:45:02 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Wed Apr 13 10:45:10 2005
Subject: [Rd] IAB (PR#7788)
Message-ID: <20050413084502.8E4A5C9F0@slim.kubism.ku.dk>

doris.soehnlein@iab.de wrote:

> Full_Name: Doris S?hnlein
> Version: 1.8.1
> OS: XP
> Submission from: (NULL) (212.204.77.23)
> 
> 
> It is not possible to save workspace image and the following error messages
> appear:
> 
>>help.start()
> 
> updating HTML package listing
> updating HTML search index
> Error in file(f.tg, open = "w") : unable to open connection
> In addition: Warning messages: 
> 1: cannot update HTML package index in: make.packages.html(.libPaths()) 
> 2: cannot open file `C:\Programme\R_rw1081/doc/html/search/index.txt' 
> If nothing happens, you should open ` C:\Programme\R_rw1081\doc\html\rwin.html '
> yourself
> 
>>q()
> 
> Error in file(file, "wb") : unable to open connection
> In addition: Warning message: 
> cannot open file `.RDataTmp' 
> 
> Was the installation not correct?

a) This is a question. Please ask questions on R-help instead of 
reporting a bug. And please ask the questions after having read the 
posting guide.

b) R-1.8.1 is OUTDATED (4 versions have been released in the meantime)!
R-2.0.1 is recent and R-2.1.0 will be released next week (beta releases 
are available).
Please read what a bug is and how to report bugs but do NOT report bugs 
of outdated versions of R.

To answer your question:
We do not know what happened, maybe permission issue, maybe disc-space 
is running low, or maybe a bug in R. Please check again with a recent 
version.
The directory name "R_rw1081" (underscore) seems to be strange, BTW.

Uwe Ligges






> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From murdoch at math.aau.dk  Wed Apr 13 10:49:34 2005
From: murdoch at math.aau.dk (Duncan Murdoch)
Date: Wed Apr 13 10:49:42 2005
Subject: [Rd] patch to add a menu item in Rgui for RSiteSearch
In-Reply-To: <Pine.LNX.4.61.0504121802250.11312@gannet.stats>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DA2@usctmx1106.merck.com>
	<Pine.LNX.4.61.0504121802250.11312@gannet.stats>
Message-ID: <425CDD1E.8050508@math.aau.dk>

Prof Brian Ripley wrote:
> On Tue, 12 Apr 2005, Liaw, Andy wrote:
> 
>> Please consider adding the following to the next R release (I understand
>> that it's too late for R-2.1.0).  It adds the menu item `Search R 
>> Site' in
>> the `Help' menu in Rgui (which calls RSiteSearch() on the input string).
> 
> 
> Can you or someone else think of a better name?  That sounds like it 
> searches www.r-project.org.  I think even 'R Sites Search' would be better.
> 
> Yes, it is too late: we need lead time for the translators these days.
> (RGui has Chinese, German, Italian and Japanese menus available.)

I'd suggest "R help online...".

After the release, I think this should go into R-patched.  Do we have 
tools to tell the translators all the new strings that need translating, 
or should they be explicitly informed about such a thing?

Duncan Murdoch

From ripley at stats.ox.ac.uk  Wed Apr 13 10:59:01 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Apr 13 10:59:11 2005
Subject: [Rd] patch to add a menu item in Rgui for RSiteSearch
In-Reply-To: <425CDD1E.8050508@math.aau.dk>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DA2@usctmx1106.merck.com>
	<Pine.LNX.4.61.0504121802250.11312@gannet.stats>
	<425CDD1E.8050508@math.aau.dk>
Message-ID: <Pine.LNX.4.61.0504130955280.7213@gannet.stats>

On Wed, 13 Apr 2005, Duncan Murdoch wrote:

> Prof Brian Ripley wrote:
>> On Tue, 12 Apr 2005, Liaw, Andy wrote:
>> 
>>> Please consider adding the following to the next R release (I understand
>>> that it's too late for R-2.1.0).  It adds the menu item `Search R Site' in
>>> the `Help' menu in Rgui (which calls RSiteSearch() on the input string).
>> 
>> 
>> Can you or someone else think of a better name?  That sounds like it 
>> searches www.r-project.org.  I think even 'R Sites Search' would be better.
>> 
>> Yes, it is too late: we need lead time for the translators these days.
>> (RGui has Chinese, German, Italian and Japanese menus available.)
>
> I'd suggest "R help online...".

But, it is not 'help online': it is searching docs and past help.

> After the release, I think this should go into R-patched.  Do we have tools 
> to tell the translators all the new strings that need translating, or should 
> they be explicitly informed about such a thing?

Yes, msgmerge/msgfmt tells them.  The message catalogues change almost 
daily as people add features.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From murdoch at math.aau.dk  Wed Apr 13 11:45:14 2005
From: murdoch at math.aau.dk (Duncan Murdoch)
Date: Wed Apr 13 11:45:22 2005
Subject: [Rd] patch to add a menu item in Rgui for RSiteSearch
In-Reply-To: <Pine.LNX.4.61.0504130955280.7213@gannet.stats>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DA2@usctmx1106.merck.com>	<Pine.LNX.4.61.0504121802250.11312@gannet.stats>	<425CDD1E.8050508@math.aau.dk>
	<Pine.LNX.4.61.0504130955280.7213@gannet.stats>
Message-ID: <425CEA2A.3090101@math.aau.dk>

Prof Brian Ripley wrote:
> On Wed, 13 Apr 2005, Duncan Murdoch wrote:
> 
>> Prof Brian Ripley wrote:
>>
>>> On Tue, 12 Apr 2005, Liaw, Andy wrote:
>>>
>>>> Please consider adding the following to the next R release (I 
>>>> understand
>>>> that it's too late for R-2.1.0).  It adds the menu item `Search R 
>>>> Site' in
>>>> the `Help' menu in Rgui (which calls RSiteSearch() on the input 
>>>> string).
>>>
>>>
>>>
>>> Can you or someone else think of a better name?  That sounds like it 
>>> searches www.r-project.org.  I think even 'R Sites Search' would be 
>>> better.
>>>
>>> Yes, it is too late: we need lead time for the translators these days.
>>> (RGui has Chinese, German, Italian and Japanese menus available.)
>>
>>
>> I'd suggest "R help online...".
> 
> 
> But, it is not 'help online': it is searching docs and past help.

That's "help" in the Windows Help-menu sense, but the important word is 
"online".  Some alternatives:

"R online..."  (sounds like it runs R online, but maybe the context is 
enough)
"Search online..."  (easily confused with a general Google search)
"R sites online..."

In any case, the 2 or 3 words in the menu aren't going to be the only 
clue to the user:  the dialog box should give a line or two describing 
what will happen when you do the search.

Duncan Murdoch
> 
>> After the release, I think this should go into R-patched.  Do we have 
>> tools to tell the translators all the new strings that need 
>> translating, or should they be explicitly informed about such a thing?
> 
> 
> Yes, msgmerge/msgfmt tells them.  The message catalogues change almost 
> daily as people add features.
>

From jtk at cmp.uea.ac.uk  Wed Apr 13 12:44:02 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Wed Apr 13 11:48:40 2005
Subject: [Rd] How allocate STRSXP outside of gc
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A59E8922@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A59E8922@phost015.EVAFUNDS.intermedia.net>
Message-ID: <20050413104402.GG31498@jtkpc.cmp.uea.ac.uk>

On Tue, Apr 12, 2005 at 12:31:03PM -0700, Vadim Ogranovich wrote:
> Hi,
>  
> I am trying to figure a way to allocate a string SEXP so that gc() won't
> ever collect it.
>  
> Here is a little bit of a background. Suppose I want to write a
> .Call-callable function that upon each call returns the same value, say
> mkChar("foo"):
>  
> SEXP getFoo() {
>    return mkChar("foo");
> }
>  
> The above implementation doesn't take advantage of the fact that
> mkChar("foo") could be pre-computed only once, and then the function
> would return the pre-computed value. So the question is how to create
> this precomputed value.
>  
>  
> The closest thing I could find in the sources is R_NaString, but I was
> not able to trace down how it comes about.

For being unaffected by R's memory management, it may be the best to
not use a SEXP for storing the pre-computed result at all. Rather, use
a static variable "private" to your code, as in

    SEXP getFoo()
    {
      static char *foo = NULL;

      if (foo == NULL)
      {
        foo = the_difficult_to_compute_value_of_foo();
      }
      return mkChar(foo);
    }

This way, getFoo indeed invokes mkChar each time, but in your scenario,
that might be an overhead which is negligible compared to the actual
computation of the foo value.

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk@cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*

From ramasamy at cancer.org.uk  Wed Apr 13 13:18:15 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed Apr 13 13:18:16 2005
Subject: [Rd] patch to add a menu item in Rgui for RSiteSearch
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DA2@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DA2@usctmx1106.merck.com>
Message-ID: <1113391095.5975.50.camel@ndmpc126.orc.ox.ac.uk>

While on the subject, may I also suggest that a menu item to search the
BioConductor archives be added.

 Archives             : https://stat.ethz.ch/pipermail/bioconductor/
 Search-able archives : http://files.protsuggest.org/cgi-bin/biocond.cgi

I hope this is not an unreasonable request considering that there is
menu item to select repositories to include BioConductor in R-2.1.0beta.

Thank you.

Regards, Adai



On Tue, 2005-04-12 at 12:57 -0400, Liaw, Andy wrote:
> Please consider adding the following to the next R release (I understand
> that it's too late for R-2.1.0).  It adds the menu item `Search R Site' in
> the `Help' menu in Rgui (which calls RSiteSearch() on the input string).
> 
> Best,
> Andy
> 
> --- R-beta/src/gnuwin32/rui.c	2005-03-06 09:41:40.000000000 -0500
> +++ R-beta-new/src/gnuwin32/rui.c	2005-04-12 08:21:55.001824500 -0400
> @@ -65,7 +65,8 @@
>  static menuitem msource, mdisplay, mload, msave, mloadhistory,
>      msavehistory, mpaste, mpastecmds, mcopy, mcopypaste, mlazy, mconfig,
>      mls, mrm, msearch, mhelp, mmanintro, mmanref, mmandata,
> -    mmanext, mmanlang, mmanadmin, mman0, mapropos, mhelpstart, mhelpsearch,
> 
> +    mmanext, mmanlang, mmanadmin, mman0, mapropos, mhelpstart, mhelpsearch,
> +    msearchRsite,
>      mFAQ, mrwFAQ, mpkgl, mpkgm, mpkgi, mpkgil, mpkgu, /*mpkgb, mpkgbu,*/
>      mde, mCRAN, mrepos;
>  static int lmanintro, lmanref, lmandata, lmanlang, lmanext, lmanadmin;
> @@ -485,6 +486,21 @@
>      }
>  }
>  
> +static void menusearchRsite(control m)
> +{
> +    char *s;
> +    static char olds[256] = "";
> +
> +    if (!ConsoleAcceptCmd) return;
> +    s = askstring(G_("Search R Site"), olds);
> +    if (s && strlen(s)) {
> +	snprintf(cmd, 1024, "RSiteSearch(\"%s\")", s);
> +	if (strlen(s) > 255) s[255] = '\0';
> +	strcpy(olds, s);
> +	consolecmd(RConsole, cmd);
> +    }
> +}
> +
>  static void menuapropos(control m)
>  {
>      char *s;
> @@ -560,6 +576,7 @@
>  	enable(msearch);
>  	enable(mhelp);
>  	enable(mhelpsearch);
> +	enable(msearchRsite);
>  	enable(mapropos);
>  	enable(mpkgl);
>  	enable(mpkgm);
> @@ -579,6 +596,7 @@
>  	disable(msearch);
>  	disable(mhelp);
>  	disable(mhelpsearch);
> +	disable(msearchRsite);
>  	disable(mapropos);
>  	disable(mpkgl);
>  	disable(mpkgm);
> @@ -985,6 +1003,7 @@
>      MCHECK(mhelpstart = newmenuitem(G_("Html help"), 0, menuhelpstart));
>      if (!check_doc_file("doc\\html\\rwin.html")) disable(mhelpstart);
>      MCHECK(mhelpsearch = newmenuitem(G_("Search help..."), 0,
> menuhelpsearch));
> +    MCHECK(msearchRsite = newmenuitem(G_("Search R Site..."), 0,
> menusearchRsite));
>      MCHECK(newmenuitem("-", 0, NULL));
>      MCHECK(mapropos = newmenuitem(G_("Apropos..."), 0, menuapropos));
>      MCHECK(newmenuitem("-", 0, NULL));
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From murdoch at math.aau.dk  Wed Apr 13 13:29:37 2005
From: murdoch at math.aau.dk (Duncan Murdoch)
Date: Wed Apr 13 13:29:45 2005
Subject: [Rd] patch to add a menu item in Rgui for RSiteSearch
In-Reply-To: <1113391095.5975.50.camel@ndmpc126.orc.ox.ac.uk>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DA2@usctmx1106.merck.com>
	<1113391095.5975.50.camel@ndmpc126.orc.ox.ac.uk>
Message-ID: <425D02A1.4070801@math.aau.dk>

Adaikalavan Ramasamy wrote:
> While on the subject, may I also suggest that a menu item to search the
> BioConductor archives be added.
> 
>  Archives             : https://stat.ethz.ch/pipermail/bioconductor/
>  Search-able archives : http://files.protsuggest.org/cgi-bin/biocond.cgi
> 
> I hope this is not an unreasonable request considering that there is
> menu item to select repositories to include BioConductor in R-2.1.0beta.

I think this would make more sense as an enhancement to 
search.r-project.org (the site where RSiteSearch sends the search 
request) than to Rgui.

Duncan Murdoch

From andy_liaw at merck.com  Wed Apr 13 14:04:10 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed Apr 13 14:04:54 2005
Subject: [Rd] patch to add a menu item in Rgui for RSiteSearch
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DAC@usctmx1106.merck.com>

> From: Duncan Murdoch
> 
> Adaikalavan Ramasamy wrote:
> > While on the subject, may I also suggest that a menu item 
> to search the
> > BioConductor archives be added.
> > 
> >  Archives             : https://stat.ethz.ch/pipermail/bioconductor/
> >  Search-able archives : 
> http://files.protsuggest.org/cgi-> bin/biocond.cgi
> > 
> > I hope 
> this is not an unreasonable 
> request considering that there is
> > menu item to select repositories to include BioConductor in 
> R-2.1.0beta.
> 
> I think this would make more sense as an enhancement to 
> search.r-project.org (the site where RSiteSearch sends the search 
> request) than to Rgui.
> 
> Duncan Murdoch

Jonathan had committed to keep his site up (and gave a very detail set of
instructions on how to reconstruct the search page, in case his can not be
maintained), before RSiteSearch() was admitted to base R.  Is the search
site Adai mentioned the `official' BioC archive search page?

BTW, Jonathan's search page already includes (all?) BioC packages.  The only
missing part is the mailing list archives.

Andy

From ramasamy at cancer.org.uk  Wed Apr 13 14:50:55 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed Apr 13 14:51:02 2005
Subject: [Rd] patch to add a menu item in Rgui for RSiteSearch
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DAC@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DAC@usctmx1106.merck.com>
Message-ID: <1113396656.5975.97.camel@ndmpc126.orc.ox.ac.uk>

I believe that is the official search page as it is linked from the main
BioConductor webpage www.bioconductor.org as 'Searchable Mail Archives'
under 'Project' on the left pane. It is maintained by Istvan Albert
(iua1@psu.edu) who might be able to provide more information.

It would be nice to have the BioConductor mailing archives under
Jonathon Baron's page for comprehensiveness but I am not sure how much
extra work this would be and if he is willing to do so.


Otherwise, here are two functions that may get around this

 BiocSiteSearch <- function( string ){ 
   # Searches query 'string' on the BioConductor searchable mail archive
   prefix <- "http://files.protsuggest.org/cgi-bin/biocond.cgi?search="
   string <- paste( prefix, gsub(" ", "+", string), sep = "")
   browseURL( string )
 }


And then perhaps generalise to 

 online.search <- function( string, archive, ... ){

   archive <- pmatch( toupper( arhive ), 
                      c("R", "BIOCONDUCTOR", "OMEGAHAT" )

   if(is.na(archive)) stop("Invalid value for 'archive'")

   qstring <- switch ( archive,
                              1 = RSiteSearch(string),
                              2 = BiocSiteSearch(string),
                              3 = OmegaSiteSearch(string)
                      )

    browseURL( qstring )
 }

Regards, Adai


On Wed, 2005-04-13 at 08:04 -0400, Liaw, Andy wrote:
> > From: Duncan Murdoch
> > 
> > Adaikalavan Ramasamy wrote:
> > > While on the subject, may I also suggest that a menu item 
> > to search the
> > > BioConductor archives be added.
> > > 
> > >  Archives             : https://stat.ethz.ch/pipermail/bioconductor/
> > >  Search-able archives : 
> > http://files.protsuggest.org/cgi-> bin/biocond.cgi
> > > 
> > > I hope 
> > this is not an unreasonable 
> > request considering that there is
> > > menu item to select repositories to include BioConductor in 
> > R-2.1.0beta.
> > 
> > I think this would make more sense as an enhancement to 
> > search.r-project.org (the site where RSiteSearch sends the search 
> > request) than to Rgui.
> > 
> > Duncan Murdoch
> 
> Jonathan had committed to keep his site up (and gave a very detail set of
> instructions on how to reconstruct the search page, in case his can not be
> maintained), before RSiteSearch() was admitted to base R.  Is the search
> site Adai mentioned the `official' BioC archive search page?
> 
> BTW, Jonathan's search page already includes (all?) BioC packages.  The only
> missing part is the mailing list archives.
> 
> Andy
> 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachment...{{dropped}}

From vograno at evafunds.com  Wed Apr 13 17:01:04 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Wed Apr 13 17:01:45 2005
Subject: [Rd] How allocate STRSXP outside of gc
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A59E8984@phost015.EVAFUNDS.intermedia.net>

mkChar is a rather expensive call since it allocates a new R object. For
example in reading char data from a file it is often advantageous to
first try to look up an already made R string and only then use mkChar.
That is, the overhead of the lookup is usually smaller than that of
mkChar.

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Jan T. Kim
> Sent: Wednesday, April 13, 2005 3:44 AM
> To: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] How allocate STRSXP outside of gc
> 
> On Tue, Apr 12, 2005 at 12:31:03PM -0700, Vadim Ogranovich wrote:
> > Hi,
> >  
> > I am trying to figure a way to allocate a string SEXP so that gc() 
> > won't ever collect it.
> >  
> > Here is a little bit of a background. Suppose I want to write a 
> > .Call-callable function that upon each call returns the same value, 
> > say
> > mkChar("foo"):
> >  
> > SEXP getFoo() {
> >    return mkChar("foo");
> > }
> >  
> > The above implementation doesn't take advantage of the fact that
> > mkChar("foo") could be pre-computed only once, and then the 
> function 
> > would return the pre-computed value. So the question is how 
> to create 
> > this precomputed value.
> >  
> >  
> > The closest thing I could find in the sources is 
> R_NaString, but I was 
> > not able to trace down how it comes about.
> 
> For being unaffected by R's memory management, it may be the 
> best to not use a SEXP for storing the pre-computed result at 
> all. Rather, use a static variable "private" to your code, as in
> 
>     SEXP getFoo()
>     {
>       static char *foo = NULL;
> 
>       if (foo == NULL)
>       {
>         foo = the_difficult_to_compute_value_of_foo();
>       }
>       return mkChar(foo);
>     }
> 
> This way, getFoo indeed invokes mkChar each time, but in your 
> scenario, that might be an overhead which is negligible 
> compared to the actual computation of the foo value.
> 
> Best regards, Jan
> --
>  +- Jan T. Kim 
> -------------------------------------------------------+
>  |    *NEW*    email: jtk@cmp.uea.ac.uk                       
>         |
>  |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk     
>         |
>  *-----=<  hierarchical systems are for files, not for humans 
>  >=-----*
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From giles.heywood at uk.abnamro.com  Wed Apr 13 18:51:59 2005
From: giles.heywood at uk.abnamro.com (giles.heywood@uk.abnamro.com)
Date: Wed Apr 13 18:52:57 2005
Subject: [Rd] S4 extends a class, but .Data slot has different class
Message-ID: <OF21FD6ED6.14294508-ONC1256FE2.005A016A@abnamro.com>

When I define an S4 class ("B" in the example below) that directly extends
another ("A" in the example below) , which in turn directly extends another
("character" in the example below), I find that the slot does not have the
class I specified in setClass(), it has the underlying class.

Is this an intended feature?

Briefly, the reason for using this type of structure is to avoid the issue
which I posted to this list before, where in 2.0.1 matrix no long 'is'
array for the purposes of S4, and therefore an extract drop=TRUE can, in a
special case, lead to an error.

Giles Heywood

- - - - -

Example:

> setClass("A",representation("character"))
[1] "A"
> setClass("B",representation("A"))
[1] "B"
> getClass("B")

Slots:

Name:      .Data
Class: character

Extends:
Class "A", directly
Class "character", by class "A"
Class "vector", by class "A"

> is(new("B",new("A","abc"))@.Data,"A")
[1] FALSE

---------------------------------------------------------------------------
This message (including any attachments) is confidential and...{{dropped}}

From paul at stat.auckland.ac.nz  Thu Apr 14 02:46:45 2005
From: paul at stat.auckland.ac.nz (paul@stat.auckland.ac.nz)
Date: Thu Apr 14 02:46:53 2005
Subject: [Rd] read.table bug (PR#7789)
Message-ID: <20050414004645.4C0D4CA0A@slim.kubism.ku.dk>

Full_Name: Paul Murrell
Version: 2.1.0 (unsure how long it has been there)
OS: Linux
Submission from: (NULL) (130.216.50.118)
Submitted by: paul



There seems to be a problem with escaped quotes in read.table.
Suppose this is the contents of a text file called "temp.txt" ...

6 'TV2  Shortland Street'
2 'I don\'t watch TV at 7'
1 'I\'m not bothered, whatever that looks good'
2 'I channel surf'

> x <- read.table("temp.txt")
> x
  V1                                         V2
1  2                             I channel surf
2  6                      TV2  Shortland Street
3  2                      I don't watch TV at 7
4  1 I'm not bothered, whatever that looks good
5  2                             I channel surf

(what is "I channel surf" doing as the first row?!)

Problem goes away if I use \" instead of \' or if I leave it as \' and change
the outer quotes from single to double.  e.g. ...

2 "I don\'t watch TV at 7" 

Analysis from Brian Ripley:

The problem is that readTableHead does not handle embedded quotes and so thinks
there are three lines on that file.  See the comment in scan.c

/* <FIXME>  This does not handle escaped quotes, nor does it appear to
   use the blank.lines.skip arg */

From andy_liaw at merck.com  Thu Apr 14 03:46:28 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Apr 14 03:47:17 2005
Subject: [Rd] predict.glm(..., type="response") loses names (was RE: [R] A
 sugg estion for predict function(s))
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DC4@usctmx1106.merck.com>

> From: Ross Darnell 
> 
> Liaw, Andy wrote:
> >>From: Liaw, Andy
> >>
> >>
> >>>From: Ross Darnell 
> >>>
> >>>A good point but what is the value of storing a large set of 
> >>>predicted 
> >>>values when the values of the explanatory variables are lost 
> >>>(predicted 
> >>>values of what?). I thought the purpose of objects was that 
> >>
> >>they were 
> >>
> >>>self explanatory (pardon the pun).
> >>>
> >>>Maybe we could make it optional.
> >>
> >>If what you are looking for is a way to track the 
> >>observations, I'd suggest
> >>simply adding rownames of newdata as names of the predicted 
> >>values.  Storing
> >>names is much cheaper than the entire data frame of 
> >>predictors.  (And in R,
> >>data frames _must_ have unique row names.)
> > 
> > 
> > And as a matter of fact, predict.lm() and predict.glm() 
> > (and probably most other predict() methods) already do 
> > that.
> > 
> > Andy
> > 
> > 
> >>Cheers,
> >>Andy
> >> 
> >>
> >>>Ross Darnell
> >>>-- 
> >>>Email: <r.darnell@uq.edu.au>
> >>>
> Hi Andy
> 
> Where?
> 
> Try predict.glm example
>       ## example from Venables and Ripley (2002, pp. 190-2.)
>       ldose <- rep(0:5, 2)
>       numdead <- c(1, 4, 9, 13, 18, 20, 0, 2, 6, 10, 12, 16)
>       sex <- factor(rep(c("M", "F"), c(6, 6)))
>       SF <- cbind(numdead, numalive=20-numdead)
>       budworm.lg <- glm(SF ~ sex*ldose, family=binomial)
>       ld <- seq(0, 5, 0.1)
>       row.names(predict(budworm.lg, data.frame(ldose=ld,
>          sex=factor(rep("M", length(ld)), levels=levels(sex))),
>          type = "response"))

[You'd want names() rather than row.names(), since predict() 
in this case returns a vector.]
 
I don't know if this is intended (and if it is, I don't 
understand why):  the names are missing only for 
type="response".  For the other types, the names are 
there.  The problem seems to be the order of arguments
in pmin() inside make.link():

            eta <- pmin(thresh, pmax(eta, -thresh))

which should probably be:

            eta <- pmin(pmax(eta, -thresh), thresh)

This is because pmin/pmax preserve the names of it's first 
argument, not the second.

There are quite a few other places in make.link() like
this.  Question to R Core:  Would such fixes be considered
`trivial' enough to make it into R-2.1.0?

Andy 


 
> I'm using
> 
>  > version
>           _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
>  >
> 
> What have I done wrong? I didn't send this to the R list to avoid 
> embarrassing myself.
> 
> Cheers
> 
> Ross Darnell
> -- 
> Email: <r.darnell@uq.edu.au>
> 
> 
>

From ripley at stats.ox.ac.uk  Thu Apr 14 07:59:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Apr 14 07:59:48 2005
Subject: [Rd] predict.glm(..., type="response") loses names (was RE: [R]
	A sugg estion for predict function(s))
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DC4@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DC4@usctmx1106.merck.com>
Message-ID: <Pine.LNX.4.61.0504140649150.27505@gannet.stats>

On Wed, 13 Apr 2005, Liaw, Andy wrote:

[...]

> There are quite a few other places in make.link() like
> this.  Question to R Core:  Would such fixes be considered
> `trivial' enough to make it into R-2.1.0?

No.

This sort of thing could affect packages, and at this point in code freeze 
we are only going to change things which are tightly confined (changing 
endianness in complex vectors in writeBin is one example) or show-stoppers 
(so if for example a new compiler were released and no longer compiled R, 
which has happened in code freeze before).

There will be 2.1.0-patched and no doubt 2.1.1 will be along in 1-2 
months.  Right now (during code freeze) is the least helpful time to make 
suggestions because we do not have any open branch to work on.  (Other 
projects do this differently: I have in the past suggested branching at 
code freeze and releasing from the branch.  But the reason for the exact 
release date is that our release manager is busy until then.)

Please file a report and proposed changes with R-bugs so it does not get 
overlooked.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Thu Apr 14 09:02:25 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Apr 14 09:02:43 2005
Subject: [Rd] How allocate STRSXP outside of gc
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A59E8984@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A59E8984@phost015.EVAFUNDS.intermedia.net>
Message-ID: <Pine.LNX.4.61.0504131632090.10084@gannet.stats>

On Wed, 13 Apr 2005, Vadim Ogranovich wrote:

> mkChar is a rather expensive call since it allocates a new R object. For
> example in reading char data from a file it is often advantageous to
> first try to look up an already made R string and only then use mkChar.
> That is, the overhead of the lookup is usually smaller than that of
> mkChar.

Yes (and that is one reason why scan in 2.1.0 uses lookups, space sharing 
being the other), but both are really fast and this only comes into play 
with hundreds of millions of items.  (On my machine mkChar takes about 200 
ns, hardly `rather expensive'.)  And if you have that much data, why not 
store it in a more efficient format?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From mjw at celos.net  Thu Apr 14 11:54:21 2005
From: mjw at celos.net (mjw@celos.net)
Date: Thu Apr 14 11:54:29 2005
Subject: [Rd] Behaviour of array() (PR#7790)
Message-ID: <20050414095421.01A6BCA07@slim.kubism.ku.dk>

Slightly surprising behaviour from array() when passed dim
arguments slightly below integer values.  Example:

    dd <- c(10.0, 9.9)
    a  <- array(numeric(1), dd)

produces an error (R 2.0.1, NetBSD 2.0):

    Error in array(numeric(1), dd) : dim<- : dims [product 90] 
    do not match the length of object [99]

Problem is that dim is coerced to integer before product in
dimgets() (src/main/attrib.c, line 711), but the product is
found from floating point values then converted to integer
when replicating the data argument (library/base/R/array.R).

This bit me with a dimension 'invisibly' less than an
integer (along the lines of 10 - 5e-7, so printed as 10).
If this needs fixing (current behaviour is sort of
"correct", but probably not usually what you want), the
simplest thing is to say

    dim <- as.integer(dim)

at the start of array() in array.R.

Mark <><

From rbaboin at mac.com  Thu Apr 14 13:10:50 2005
From: rbaboin at mac.com (Renaud Baboin)
Date: Thu Apr 14 13:11:04 2005
Subject: [Rd] Freelance developper job
Message-ID: <527d6cc77b14bea979cc7eaa05313d42@mac.com>

Hi,

I am looking for a R-project specialist to develop a simple application 
to compute linear regressions on financial datas stored in a mysql 
database :

This implies
- arranging importaion of datas in R, and exporting of results
- advising on the way to build the linear regression it self

A mix of math and programming.

Is anyone interested ?

Thanks

Renaud

From lunde.eric at mayo.edu  Thu Apr 14 15:01:13 2005
From: lunde.eric at mayo.edu (lunde.eric@mayo.edu)
Date: Thu Apr 14 15:01:24 2005
Subject: [Rd] Sd2Rd command (PR#7791)
Message-ID: <20050414130113.4C2D3CC6A@slim.kubism.ku.dk>

Full_Name: Eric Lunde
Version: 2.0.1
OS: Solaris 9
Submission from: (NULL) (129.176.151.21)


Hi R Devel,

I am assisting one of my fellow R users who is developing a package for both
Splus and R.  He has been using the Sd2Rd command to convert his sgml help files
into Rd help files.  We believe we have found a bug.  We noticed that if an sgml
help file has multiple <s-topic> tags, each of those tags gets translated into
both a \name{} and an \alias{} tag in the Rd file.  The desired functionality is
a \name{} tag is written once (given the value of the first <s-topic>) and an
\alias tag is written for each <s-topic> tag.  Having multiple \name{} tags
caused R CMD check to holler the following:

* checking Rd files ... WARNING
Rd files with duplicate 'name':
 /people/biostat3/sinnwell/Rdir/Make/haplo.stats/man/haplo.score.Rd
These entries must be unique in an Rd file.

I believe that the developers of Sd2Rd attempted to prevent this from happening.
 They use a variable named nalias (used as a Boolean and initialized to 0).  If
nalias is equal to 0 then the \name{} tag is written to the output Rd file and
nalias is given the value 1.  This nalias is not used anywhere else in the
subroutine which makes me think that the developers were trying to use nalias as
a static variable and hoped it would retain the value of 1 for the next time the
subroutine process_sub_group is called.  Here is the code:

sub process_sub_group{
  my $topic = $_[0];
  my $text = $_[1];
  my $nalias = 0;
  my $example = 0;

  . . .
    if(!$nalias) {
      print "\\name{$text}\n";
      $nalias = 1;
      $fun = $text;
    }
    print "\\alias{$text}\n";
  . . .
}

I propose that the code be altered slightly to gain the proper functionality. 
If process_sub_group was wrapped in braces and nalias was removed from inside
process_sub_group and was declared outside the subroutine but inside the braces,
nalias would retain its value from call to call and the "static" mentality of
nalias would be gained.  My proposed code:

{
my $nalias = 0;

sub process_sub_group{
  my $topic = $_[0];
  my $text = $_[1];
  #my $nalias = 0;
  my $example = 0;

  . . . 
    if(!$nalias) {
      print "\\name{$text}\n";
      $nalias = 1;
      $fun = $text;
    }
    print "\\alias{$text}\n"
  . . .
}
}

Other functions will be able to call process_sub_group just as before, but
nalias will retain its value of 1 during the second, third, etc calls to
process_sub_group.  Thanks for your consideration,

Eric Lunde
Analyst/Programmer
Mayo Clinic
Phone: 507-284-5630
Email: lunde.eric@mayo.edu

From andy_liaw at merck.com  Thu Apr 14 16:17:36 2005
From: andy_liaw at merck.com (andy_liaw@merck.com)
Date: Thu Apr 14 16:17:44 2005
Subject: [Rd] predict.glm(...,
	type="response") dropping names (and a propsed (PR#7792)
Message-ID: <20050414141736.0199ECC61@slim.kubism.ku.dk>

Here's a patch that should make predict.glm(..., type="response") retain the
names.  The change passes make check on our Opteron running SLES9.  One
simple test is:

names(predict(glm(y ~ x, family=binomial,
                  data=data.frame(y=c(1, 0, 1, 0), x=c(1, 1, 0, 0))),
              newdata=data.frame(x=c(0, 0.5, 1)), type="response"))

which gives

[1] "1" "2" "3"

with this patch, and "NULL" with the current R-beta.

I only use glm() once in a blue moon, so others may want to test other
cases.

Best,
Andy


--- R-beta/src/library/stats/R/family.R	2005-03-04 04:40:03.000000000 -0500
+++ R-beta-fix/src/library/stats/R/family.R	2005-04-14
08:30:03.000000000 -0400
@@ -25,9 +25,9 @@
     else if(!is.character(link) && !is.na(lambda <- as.numeric(link))) {
         linkfun <- function(mu) mu^lambda
         linkinv <- function(eta)
-            pmax(.Machine$double.eps, eta^(1/lambda))
+            pmax(eta^(1/lambda), .Machine$double.eps)
         mu.eta <- function(eta)
-            pmax(.Machine$double.eps, (1/lambda) * eta^(1/lambda - 1))
+            pmax((1/lambda) * eta^(1/lambda - 1), .Machine$double.eps)
         valideta <- function(eta) all(eta>0)
     }
     else
@@ -36,7 +36,7 @@
                    linkfun <- function(mu) log(mu/(1 - mu))
                    linkinv <- function(eta) {
                        thresh <- -log(.Machine$double.eps)
-                       eta <- pmin(thresh, pmax(eta, -thresh))
+                       eta <- pmin(pmax(eta, -thresh), thresh)
                        exp(eta)/(1 + exp(eta))
                    }
                    mu.eta <- function(eta) {
@@ -52,7 +52,7 @@
                    linkfun <- function(mu) qnorm(mu)
                    linkinv <- function(eta) {
                        thresh <- - qnorm(.Machine$double.eps)
-                       eta <- pmin(thresh, pmax(eta, -thresh))
+                       eta <- pmin(pmax(eta, -thresh), thresh)
                        pnorm(eta)
                    }
                    mu.eta <- function(eta)
@@ -63,7 +63,7 @@
          	   linkfun <- function(mu) qcauchy(mu)
          	   linkinv <- function(eta) {
                        thresh <- -qcauchy(.Machine$double.eps)
-                       eta <- pmin(thresh, pmax(eta, -thresh))
+                       eta <- pmin(pmax(eta, -thresh), thresh)
                        pcauchy(eta)
          	   }
          	   mu.eta <- function(eta)
@@ -73,11 +73,11 @@
                "cloglog" = {
                    linkfun <- function(mu) log(-log(1 - mu))
                    linkinv <- function(eta)
-                       pmax(.Machine$double.eps,
-                            pmin(1 - .Machine$double.eps, -
expm1(-exp(eta))))
+                       pmax(pmin(-expm1(-exp(eta)), 1 -
.Machine$double.eps),
+                            .Machine$double.eps)
                    mu.eta <- function(eta) {
                        eta <- pmin(eta, 700)
-                       pmax(.Machine$double.eps, exp(eta) * exp(-exp(eta)))
+                       pmax(exp(eta) * exp(-exp(eta)), .Machine$double.eps)
                    }
                    valideta <- function(eta) TRUE
                },
@@ -90,9 +90,9 @@
                "log" = {
                    linkfun <- function(mu) log(mu)
                    linkinv <- function(eta)
-                       pmax(.Machine$double.eps, exp(eta))
+                       pmax(exp(eta), .Machine$double.eps)
                    mu.eta <- function(eta)
-                       pmax(.Machine$double.eps, exp(eta))
+                       pmax(exp(eta), .Machine$double.eps)
                    valideta <- function(eta) TRUE
                },
                "sqrt" = {

From bonolottoprimitiva at mail2world.com  Thu Apr 14 00:33:07 2005
From: bonolottoprimitiva at mail2world.com (BONO LOTTO/ PRIMITIVA)
Date: Thu Apr 14 17:49:15 2005
Subject: [Rd] CONGRATULATION,WINNING NOTIFICATION LETTER
Message-ID: <200504141546.j3EFkAqE024180@hypatia.math.ethz.ch>

BONO LOTTO/ PRIMITIVA 
C/GUZMAN EL BUENO,137
MADRID - SPAIN

FROM: THE DESK OF THE PROMOTIONS MANAGER, 
INTERNATIONAL PROMOTIONS/PRIZE AWARD DEPARTMENT, 
E-mail:  <http://mail.yahoo.com/config/login?/ym/Compose?To=bonolottoprimitiva@mail2world.com>bonolottoprimitiva@mail2world.com <http://mail.yahoo.com/config/login?/ym/Compose?To=bonolottoprimitiva@mail2world.com   maiser> 

AWARD WINNING NOTIFICATION LETTER

YOUR REF: LP/26510460037/05
YOUR BATCH: 24/00319/IPD

We are pleased to inform you of the release today, 14th of APRIL, 2005, of 
the BONO LOTTO SWEEPSTAKE LOTTERY/INTER-NATIONAL PROGRAMS held on the 12th of APRIL, 2005. 
Your Email Address Name was attached to the Ticket number- 025 11464992-750 with 
Serial number 2113-05 drew the Lucky number- 3-18-19-30-32-39, which 
consequently won the lottery in the 3rd category. 

You are therefore have been approved for the lump sum pay out of Euros 
394,861.07(Three Hundred And Ninety Four Thousand,Eight Hundred And SixtyOne,Seven cents Only.) in cash credited to the file REF: LP/26510460037/05,BATCH: 24/00319/IPD.This is from the total prize of Euros 10,000,000.00(Ten Million Euros) shared among the 
Twenty Five (25)International winners in this category. 

CONGRATULATION! 

Your fund is now deposited with a Security Company EURO SECURITY AND 
INSURANCE .S.A.. Due to the mixed up of some numbers and names, we ask 
that you keep this award a top secret from the public notice until your 
claim as been processed and your prize money remitted to your account 
as this is a part of our Security protocol to avoid double claiming 
award or unwarranted taking advantage of this program by nonparticipants. 

All participants were selected through a computer ballot system drawn 
from 100,000 email addresses, names from Australia, Africa, USA, Europe, Asia 
,New Zealand, Middle-East and South-North America .As part of our 
international promotions program, which we conduct every April of every year. 
We hope with a part of your prize, you will take part in our end of the 
year high stake euros 150 Million International Lottery. 

To begin your claim, please contact the issuing authority, your prize 
claim agent, MR.FERNANDO GARCIA,at EURO SECURITY AND INSURANCE .S.A. 
(Foreign Operational Manager) for processing and remittance of your prize 
money to your designated account of your choice. Tel: 0034 606 916 014, Fax: 0034 657 606 061. Email: fernando_garcia@excite.com <http://mail.yahoo.com/config/login?/ym/Compose?To=fernando_garcia@excite.com> 
Remember, all prize money must be claimed not later than the 15th of MAY, 2005. 
After this date, all funds will be returned as unclaimed. 

Note: In order to avoid unnecessary delays and complications, please 
remember to quote your reference and batch numbers in every of your 
correspondence with your agent. 
Furthermore, should there be any change of address do inform your 
claiming agent as soon as possible. 

Please remember to ask for your prize claim certificate. 
Congratulations once again from all the member of our staff and thank you for 
been part of our International Promotion Program. 

Best regards, 
MARIA JOSE SANCHEZ.
VICE PRESIDENT BONOLOTTO.

From vograno at evafunds.com  Thu Apr 14 19:57:13 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Thu Apr 14 19:57:31 2005
Subject: [Rd] How allocate STRSXP outside of gc
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A59E8A42@phost015.EVAFUNDS.intermedia.net>

Yes, and space sharing also improves speed since gc() does not need to
collect so many objects.

I thought about more efficient formats for my data, but:
* ASCII is ubiquitous. Your have grep, head, perl, etc. to work w/ them
* AFAIK, there is no industry standard binary format and a mature
supporting C-library (especially when the data needs to be compressed).
I considered HDF and netcdf.
* the programs that collect my data store it in ASCII. It is
advantageous to be able to read it directly from the original files. (I
have about 200G of these compressed)
* C code was able to read the data at a decent speed, it was the R's
overhead that was causing problems. One of them was mkChar, the other
was how chars are read from a connection. I detailed my findings in a
message to r-devel.

I tried to see is I could improve the original R codes for IO, but for
various reasons decided that I wouldn't be able to accomplish this. In
the end I decided to write a custom R IO package which came close to the
speed of raw C code (the difference is largely due to the lookup
overhead).

Thanks,
Vadim

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley@stats.ox.ac.uk] 
> Sent: Thursday, April 14, 2005 12:02 AM
> To: Vadim Ogranovich
> Cc: Jan T. Kim; r-devel@stat.math.ethz.ch
> Subject: RE: [Rd] How allocate STRSXP outside of gc
> 
> On Wed, 13 Apr 2005, Vadim Ogranovich wrote:
> 
> > mkChar is a rather expensive call since it allocates a new 
> R object. 
> > For example in reading char data from a file it is often 
> advantageous 
> > to first try to look up an already made R string and only 
> then use mkChar.
> > That is, the overhead of the lookup is usually smaller than that of 
> > mkChar.
> 
> Yes (and that is one reason why scan in 2.1.0 uses lookups, 
> space sharing being the other), but both are really fast and 
> this only comes into play with hundreds of millions of items. 
>  (On my machine mkChar takes about 200 ns, hardly `rather 
> expensive'.)  And if you have that much data, why not store 
> it in a more efficient format?
> 
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

From nali at umn.edu  Thu Apr 14 19:54:34 2005
From: nali at umn.edu (Na Li)
Date: Thu Apr 14 19:58:12 2005
Subject: [Rd] documentation for 'open': some clarification?
Message-ID: <xky8blp7l1.fsf@bass.local>


I'm been doing more and more of file text parsing inside R instead of
coping with Perl.  For that, I need open a file and read it line-by-line.
I found the documentation for 'open' isn't very clear.

Right now it has

,----[ *help(R)[open]* ]
|  'open' opens a connection.  In general functions using connections
|  will open them if they are not open, but then close them again, so
|  to leave a connection open call 'open' explicitly.
`----

It seems that one has to call 'open' to open a live connection that can be
parsed line by line (using readLines() or scan() to read).  But open()
cannot be directly applied to a file name.

In fact, one only needs supply the 'open' argument in file() with
something other than the empty string,

,----
| > con <- file ("S200.dat")
| > isOpen (con)
| [1] FALSE
| > con <- file ("S200.dat", open = "r")
| > isOpen (con)
| [1] TRUE
`----

It is not clear to me how 'open()' is supposed to be used.  It took me a
while to figure this out and I thought it might be worthwhile to add one
sentence or two to make it more clear in the doc.

Cheers,

Michael

-- 
Na (Michael) Li, Ph.D.               
Division of Biostatistics          A443 Mayo Building, MMC 303   
School of Public Health            420 Delaware St SE            
University of Minnesota            Minneapolis, MN 55455         
Phone: (612) 626-4765              Email: nali@umn.edu                  
Fax:   (612) 626-0660              http://www.biostat.umn.edu/~nali

GPG Public Key: 
http://www.umn.edu/lookup?SET_INSTITUTION=UMNTC&UID=nali&show_pgp=1

From jeff.horner at vanderbilt.edu  Thu Apr 14 20:18:53 2005
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Thu Apr 14 20:19:14 2005
Subject: [Rd] How allocate STRSXP outside of gc
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A59E8A42@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A59E8A42@phost015.EVAFUNDS.intermedia.net>
Message-ID: <425EB40D.9040600@vanderbilt.edu>

Vadim Ogranovich wrote:
[...]
> * AFAIK, there is no industry standard binary format and a mature
> supporting C-library (especially when the data needs to be compressed).
> I considered HDF and netcdf.
[...]

Interesting. I just finished reading a little about HDF's new format HD5 
and their web documentation claims it's flexible enough to store 
compressed or chunked data:

http://hdf.ncsa.uiuc.edu/whatishdf5.html

Also, you mentioned that you like line oriented ASCII files since many 
UNIX utilities work with them, but have you considered NCO, a collection 
of UNIX utilites for processing netcdf files:

http://nco.sourceforge.net/

-- 
Jeffrey Horner       Computer Systems Analyst         School of Medicine
615-322-8606         Department of Biostatistics   Vanderbilt University

From vograno at evafunds.com  Thu Apr 14 20:38:55 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Thu Apr 14 20:39:13 2005
Subject: [Rd] How allocate STRSXP outside of gc
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A59E8A51@phost015.EVAFUNDS.intermedia.net>

Yes, HDF5 had this promise at the time I looked at it, but it was not
there yet. Don't know the current status. Judging from your e-mail,
they've delivered. 

Thank you for pointing to NCO. I didn't know about it.

> -----Original Message-----
> From: Jeffrey Horner [mailto:jeff.horner@vanderbilt.edu] 
> Sent: Thursday, April 14, 2005 11:19 AM
> To: Vadim Ogranovich
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] How allocate STRSXP outside of gc
> 
> Vadim Ogranovich wrote:
> [...]
> > * AFAIK, there is no industry standard binary format and a mature 
> > supporting C-library (especially when the data needs to be 
> compressed).
> > I considered HDF and netcdf.
> [...]
> 
> Interesting. I just finished reading a little about HDF's new 
> format HD5 and their web documentation claims it's flexible 
> enough to store compressed or chunked data:
> 
> http://hdf.ncsa.uiuc.edu/whatishdf5.html
> 
> Also, you mentioned that you like line oriented ASCII files 
> since many UNIX utilities work with them, but have you 
> considered NCO, a collection of UNIX utilites for processing 
> netcdf files:
> 
> http://nco.sourceforge.net/
> 
> -- 
> Jeffrey Horner       Computer Systems Analyst         School 
> of Medicine
> 615-322-8606         Department of Biostatistics   Vanderbilt 
> University
>

From ripley at stats.ox.ac.uk  Thu Apr 14 20:47:55 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Apr 14 20:48:12 2005
Subject: [Rd] documentation for 'open': some clarification?
In-Reply-To: <xky8blp7l1.fsf@bass.local>
References: <xky8blp7l1.fsf@bass.local>
Message-ID: <Pine.LNX.4.61.0504141905260.12266@gannet.stats>

On Thu, 14 Apr 2005, Na Li wrote:

>
> I'm been doing more and more of file text parsing inside R instead of
> coping with Perl.  For that, I need open a file and read it line-by-line.
> I found the documentation for 'open' isn't very clear.

You appears to have missed almost all the documentation.

> Right now it has
>
> ,----[ *help(R)[open]* ]
> |  'open' opens a connection.  In general functions using connections
> |  will open them if they are not open, but then close them again, so
> |  to leave a connection open call 'open' explicitly.
> `----
>
> It seems that one has to call 'open' to open a live connection that can be
> parsed line by line (using readLines() or scan() to read).  But open()
> cannot be directly applied to a file name.

Not surprising, as it is documented as

      open(con, ...)
      ## S3 method for class 'connection':
      open(con, open = "r", blocking = TRUE, ...)

      con: a connection.
            ^^^^^^^^^^^

> In fact, one only needs supply the 'open' argument in file() with
> something other than the empty string,

Or use 'open(con)', but you are asking about the usage of something that 
you never need to use, as should have been clear from all the examples, 
e.g. those in ?readBin (which is in the SeeAlso) that get on fine without 
it.

> ,----
> | > con <- file ("S200.dat")
> | > isOpen (con)
> | [1] FALSE
> | > con <- file ("S200.dat", open = "r")
> | > isOpen (con)
> | [1] TRUE
> `----
>
> It is not clear to me how 'open()' is supposed to be used.  It took me a
> while to figure this out

Have you figured it out?

> and I thought it might be worthwhile to add one
> sentence or two to make it more clear in the doc.

Help pages are not tutorials: there is a reference on the help page, and 
an article in R-news.  (I have raised several times the idea of a 
technical papers section with such articles, but other do not share my 
enthusiasm.)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ggrothendieck at gmail.com  Thu Apr 14 21:24:31 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu Apr 14 21:24:48 2005
Subject: [Rd] documentation for 'open': some clarification?
In-Reply-To: <xky8blp7l1.fsf@bass.local>
References: <xky8blp7l1.fsf@bass.local>
Message-ID: <971536df05041412242a65b32c@mail.gmail.com>

Here is an example:

# read and print first 10 lines one by one
# the next two lines could be collapsed into con <- file("myfile", r)
con <- file("myfile") 
open(con) 
for(i in 1:10) print(readLines(con, n=1))
close(con) 

Also its possible that you may not need open.  For example,
one can just read it all in at once like this:

mylines <- readLines("myfile")
# and now mylines[1] is the first line, etc.  

# or
my.numbers <- scan("myfile")

# or
my.table <- read.table("myfile")



On 4/14/05, Na Li <nali@umn.edu> wrote:
> 
> I'm been doing more and more of file text parsing inside R instead of
> coping with Perl.  For that, I need open a file and read it line-by-line.
> I found the documentation for 'open' isn't very clear.
> 
> Right now it has
> 
> ,----[ *help(R)[open]* ]
> |  'open' opens a connection.  In general functions using connections
> |  will open them if they are not open, but then close them again, so
> |  to leave a connection open call 'open' explicitly.
> `----
> 
> It seems that one has to call 'open' to open a live connection that can be
> parsed line by line (using readLines() or scan() to read).  But open()
> cannot be directly applied to a file name.
> 
> In fact, one only needs supply the 'open' argument in file() with
> something other than the empty string,
> 
> ,----
> | > con <- file ("S200.dat")
> | > isOpen (con)
> | [1] FALSE
> | > con <- file ("S200.dat", open = "r")
> | > isOpen (con)
> | [1] TRUE
> `----
> 
> It is not clear to me how 'open()' is supposed to be used.  It took me a
> while to figure this out and I thought it might be worthwhile to add one
> sentence or two to make it more clear in the doc.
> 
> Cheers,
> 
> Michael
> 
> --
> Na (Michael) Li, Ph.D.
> Division of Biostatistics          A443 Mayo Building, MMC 303
> School of Public Health            420 Delaware St SE
> University of Minnesota            Minneapolis, MN 55455
> Phone: (612) 626-4765              Email: nali@umn.edu
> Fax:   (612) 626-0660              http://www.biostat.umn.edu/~nali
> 
> GPG Public Key:
> http://www.umn.edu/lookup?SET_INSTITUTION=UMNTC&UID=nali&show_pgp=1
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From Detlef.Steuer at unibw-hamburg.de  Thu Apr 14 22:42:49 2005
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Thu Apr 14 22:41:08 2005
Subject: Technical papers  was: Re: [Rd] documentation for 'open': some
	clarification?
In-Reply-To: <Pine.LNX.4.61.0504141905260.12266@gannet.stats>
References: <xky8blp7l1.fsf@bass.local>
	<Pine.LNX.4.61.0504141905260.12266@gannet.stats>
Message-ID: <20050414224249.512d7c19@linux.site>

On Thu, 14 Apr 2005 19:47:55 +0100 (BST)
Prof Brian Ripley <ripley@stats.ox.ac.uk> wrote:

> > and I thought it might be worthwhile to add one
> > sentence or two to make it more clear in the doc.
> 
> Help pages are not tutorials: there is a reference on the help page,
> and an article in R-news.  (I have raised several times the idea of a 
> technical papers section with such articles, but other do not share my
> enthusiasm.)

I for one want to support the idea of adding such technical papers to
R-news.

detlef

From deleeuw at stat.ucla.edu  Thu Apr 14 22:48:20 2005
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Thu Apr 14 22:49:37 2005
Subject: Technical papers was: Re: [Rd] documentation for 'open': some
	clarification?
In-Reply-To: <20050414224249.512d7c19@linux.site>
References: <xky8blp7l1.fsf@bass.local>
	<Pine.LNX.4.61.0504141905260.12266@gannet.stats>
	<20050414224249.512d7c19@linux.site>
Message-ID: <B5FC61F7-47B1-4710-BA32-90E6A002822F@stat.ucla.edu>

I humbly suggest the Journal of Statistical Software (www.jstatsoft.org)
which gives you peer-review, ISSN, directory of open access journals,
Nelson Beebe's BibTeX repository, CODEN, and pretty soon CIS and
official ASA status.

-- Jan

On Apr 14, 2005, at 13:42 , Detlef Steuer wrote:

> I for one want to support the idea of adding such technical papers to
> R-news.
>

===
Jan de Leeuw; Distinguished Professor and Chair, UCLA Department of  
Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
.mac: jdeleeuw ++++++  aim: deleeuwjan ++++++ skype: j_deleeuw
homepages: http://gifi.stat.ucla.edu ++++++ http://www.cuddyvalley.org
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From tibshirani at gmail.com  Thu Apr 14 23:06:08 2005
From: tibshirani at gmail.com (Tib)
Date: Thu Apr 14 23:06:23 2005
Subject: [Rd] dynamic array output by .C
Message-ID: <58618a6205041414062f07d2a8@mail.gmail.com>

Greetings,

I am building a stochastic simulation model in a C++ shared library
for R. My model will generate a random number of new observations and
also delete some old observations, however, the numbers cannot be
predicted before the computation engine runs. For simplicity, I am
trying to control my programming at the second stage (pure C++ for R).
It seems .C accepts fixed size of arrays as input (also ouput), can I
modify size of array for deleting old and adding new observations in
.C?
Thanks in advance.
-- 
I am Tib, not Rob.

From ripley at stats.ox.ac.uk  Thu Apr 14 23:12:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Apr 14 23:13:08 2005
Subject: [Rd] dynamic array output by .C
In-Reply-To: <58618a6205041414062f07d2a8@mail.gmail.com>
References: <58618a6205041414062f07d2a8@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0504142212070.14473@gannet.stats>

On Thu, 14 Apr 2005, Tib wrote:

> Greetings,
>
> I am building a stochastic simulation model in a C++ shared library
> for R. My model will generate a random number of new observations and
> also delete some old observations, however, the numbers cannot be
> predicted before the computation engine runs. For simplicity, I am
> trying to control my programming at the second stage (pure C++ for R).
> It seems .C accepts fixed size of arrays as input (also ouput), can I
> modify size of array for deleting old and adding new observations in
> .C?

No, but .Call can.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From tibshirani at gmail.com  Fri Apr 15 00:01:19 2005
From: tibshirani at gmail.com (Tib)
Date: Fri Apr 15 00:01:37 2005
Subject: [Rd] dynamic array output by .C
In-Reply-To: <Pine.LNX.4.61.0504142212070.14473@gannet.stats>
References: <58618a6205041414062f07d2a8@mail.gmail.com>
	<Pine.LNX.4.61.0504142212070.14473@gannet.stats>
Message-ID: <58618a62050414150165aae64@mail.gmail.com>

HI,
from the examples of Writing R Extensions,  I see one still has to
declare the size of arrays by NEW_NUMERIC(n) or
allocVector(REALSXP,n), how can I extend arrays?

I know this question is a little specific, but it would be a lot
helpful if anyone can give me a  quick question. Thanks


On 4/14/05, Prof Brian Ripley <ripley@stats.ox.ac.uk> wrote:
> On Thu, 14 Apr 2005, Tib wrote:
> 
> > Greetings,
> >
> > I am building a stochastic simulation model in a C++ shared library
> > for R. My model will generate a random number of new observations and
> > also delete some old observations, however, the numbers cannot be
> > predicted before the computation engine runs. For simplicity, I am
> > trying to control my programming at the second stage (pure C++ for R).
> > It seems .C accepts fixed size of arrays as input (also ouput), can I
> > modify size of array for deleting old and adding new observations in
> > .C?
> 
> No, but .Call can.
> 
> --
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 


-- 
I am Tib, not Rob.

From simon.urbanek at r-project.org  Fri Apr 15 01:29:25 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri Apr 15 01:30:09 2005
Subject: [Rd] dynamic array output by .C
In-Reply-To: <58618a62050414150165aae64@mail.gmail.com>
References: <58618a6205041414062f07d2a8@mail.gmail.com>
	<Pine.LNX.4.61.0504142212070.14473@gannet.stats>
	<58618a62050414150165aae64@mail.gmail.com>
Message-ID: <92FD2DE5-0622-464B-BFF5-AA66881CD0E5@r-project.org>

On Apr 14, 2005, at 6:01 PM, Tib wrote:

> from the examples of Writing R Extensions,  I see one still has to
> declare the size of arrays by NEW_NUMERIC(n) or
> allocVector(REALSXP,n), how can I extend arrays?

AFAIR you cannot extend vectors - it's like in C, you cannot extend  
allocated memory without changing the pointer (i.g.). In order to get  
a vector of a different size, you have to allocate a new one and copy  
the common contents. If you are concerned about efficiency, why don't  
you just use arbitrary large vectors and pass along the number of  
used elements? Then you can easily add elements without re-allocating  
and just return the number of elements used after the operation. That  
way you can control the probability of having to allocate a new  
vector, possibly making it zero.

Cheers,
Simon

From xiangli at gila-fw.bioengr.uic.edu  Fri Apr 15 02:26:44 2005
From: xiangli at gila-fw.bioengr.uic.edu (xiangli@gila-fw.bioengr.uic.edu)
Date: Fri Apr 15 02:26:58 2005
Subject: [Rd] inconsistent fonts generated in postscript file (PR#7795)
Message-ID: <20050415002644.267BABAF8@slim.kubism.ku.dk>

Full_Name: Xiang Li
Version: 2.01
OS: WinXP
Submission from: (NULL) (128.248.174.125)


I am trying to use the font of "TT Courier New: bold" to get the equal size of
letters. The "TT Courier New: bold" is the 11th font listed in the Rdevga file.

You can just try a simple case:

plot(1:10, 1:10, xlab = "XILMV", font.lab = 11)

I save the plot in postscript format, and found the font in .ps file becomes
Arial font. While I save the plot in JPEG or PNG format, everything is correct.

Best

Xiang

From schouwla at yahoo.com  Fri Apr 15 03:45:18 2005
From: schouwla at yahoo.com (Lars Schouw)
Date: Fri Apr 15 03:45:33 2005
Subject: [Rd] (no subject)
Message-ID: <20050415014518.95680.qmail@web50303.mail.yahoo.com>

Can anyone explain what this means the NEWS for for
2.1 beta?

R is now linked against ncurses/termlib/termcap only
if
readline is specified (now the default) and that
requires it.

I get an error while running configure:
checking for history_truncate_file... no
configure: error: --with-readline=yes (default) and
headers/libs are not available

Regards
Lars Schouw

From andy_liaw at merck.com  Fri Apr 15 04:54:29 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Apr 15 04:55:05 2005
Subject: [Rd] (no subject)
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DDB@usctmx1106.merck.com>

> From: Lars Schouw
> 
> Can anyone explain what this means the NEWS for for
> 2.1 beta?
> 
> R is now linked against ncurses/termlib/termcap only
> if
> readline is specified (now the default) and that
> requires it.
> 
> I get an error while running configure:
> checking for history_truncate_file... no
> configure: error: --with-readline=yes (default) and
> headers/libs are not available

It means what it says: configure will try to find 
ncurses/termcap/readline (and their headers) unless
you explicitly say --with-readline=no.

Andy
 
> Regards
> Lars Schouw
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
>

From charlie at stat.umn.edu  Fri Apr 15 06:51:00 2005
From: charlie at stat.umn.edu (Charles Geyer)
Date: Fri Apr 15 06:51:14 2005
Subject: [Rd] MacOS X check summary missing packages
In-Reply-To: <200504141003.j3EA38IM005483@hypatia.math.ethz.ch>
References: <200504141003.j3EA38IM005483@hypatia.math.ethz.ch>
Message-ID: <20050415045100.GA13510@stat.umn.edu>

The "MacOS X check summary" at CRAN "Contributed Packages"
has been missing packages 227-438 for a while.  Some problem
with table formatting?  Or what?
-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie@stat.umn.edu

From ripley at stats.ox.ac.uk  Fri Apr 15 08:20:59 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Apr 15 08:21:10 2005
Subject: [Rd] dynamic array output by .C
In-Reply-To: <58618a62050414150165aae64@mail.gmail.com>
References: <58618a6205041414062f07d2a8@mail.gmail.com> 
	<Pine.LNX.4.61.0504142212070.14473@gannet.stats>
	<58618a62050414150165aae64@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0504150719460.19992@gannet.stats>

On Thu, 14 Apr 2005, Tib wrote:

> from the examples of Writing R Extensions,  I see one still has to
> declare the size of arrays by NEW_NUMERIC(n) or
> allocVector(REALSXP,n), how can I extend arrays?
>
> I know this question is a little specific, but it would be a lot
> helpful if anyone can give me a  quick question. Thanks

Use lengthgets().

> On 4/14/05, Prof Brian Ripley <ripley@stats.ox.ac.uk> wrote:
>> On Thu, 14 Apr 2005, Tib wrote:
>>
>>> Greetings,
>>>
>>> I am building a stochastic simulation model in a C++ shared library
>>> for R. My model will generate a random number of new observations and
>>> also delete some old observations, however, the numbers cannot be
>>> predicted before the computation engine runs. For simplicity, I am
>>> trying to control my programming at the second stage (pure C++ for R).
>>> It seems .C accepts fixed size of arrays as input (also ouput), can I
>>> modify size of array for deleting old and adding new observations in
>>> .C?
>>
>> No, but .Call can.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Fri Apr 15 08:26:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Apr 15 08:26:55 2005
Subject: [Rd] dynamic array output by .C
In-Reply-To: <92FD2DE5-0622-464B-BFF5-AA66881CD0E5@r-project.org>
References: <58618a6205041414062f07d2a8@mail.gmail.com>
	<Pine.LNX.4.61.0504142212070.14473@gannet.stats>
	<58618a62050414150165aae64@mail.gmail.com>
	<92FD2DE5-0622-464B-BFF5-AA66881CD0E5@r-project.org>
Message-ID: <Pine.LNX.4.61.0504150721340.19992@gannet.stats>

On Thu, 14 Apr 2005, Simon Urbanek wrote:

> On Apr 14, 2005, at 6:01 PM, Tib wrote:
>
>> from the examples of Writing R Extensions,  I see one still has to
>> declare the size of arrays by NEW_NUMERIC(n) or
>> allocVector(REALSXP,n), how can I extend arrays?
>
> AFAIR you cannot extend vectors - it's like in C, you cannot extend allocated 
> memory without changing the pointer (i.g.). In order to get a vector of a 
> different size, you have to allocate a new one and copy the common contents. 
> If you are concerned about efficiency, why don't you just use arbitrary large 
> vectors and pass along the number of used elements? Then you can easily add 
> elements without re-allocating and just return the number of elements used 
> after the operation. That way you can control the probability of having to 
> allocate a new vector, possibly making it zero.

That's not a particularly good idea, as R keeps the length in the vector.
There is a way to do this, lengthgets().  That shortens vectors in one 
case, and reallocates and copies contents if extending.  Quite a lot of 
internal code does use long vectors and call lengthgets() at the end to 
shorten them to the right size.  (Other code duplicates that in 
lengthgets.)

As the name implies, this is the internal form of length(x) <- value.

Yes, it does change the pointer because it creates (potentially a new 
object).  But since an R object is just a few parameters (e.g. type and 
length) and a pointer, you could in fact extend an R vector `in place'.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Fri Apr 15 08:43:25 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Apr 15 08:43:50 2005
Subject: [Rd] inconsistent fonts generated in postscript file (PR#7795)
In-Reply-To: <20050415002644.267BABAF8@slim.kubism.ku.dk>
References: <20050415002644.267BABAF8@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0504150736120.20210@gannet.stats>

Please DO READ the documentation.

Rdevga applies to *windows* devices: see its help page.
On Windows, saving to JPEG or PNG is using a windows device.

The way fonts are chosen in postscript() is described on its help page. It 
is *definitely* using not Arial but Helvetica, even though your viewer 
might do a substitution.

There is a section in the FAQ on BUGS.  Had you read it, you could have 
avoided wasting our time.  Or even if you had read ?postscript.


On Fri, 15 Apr 2005 xiangli@gila-fw.bioengr.uic.edu wrote:

> Full_Name: Xiang Li
> Version: 2.01
> OS: WinXP
> Submission from: (NULL) (128.248.174.125)
>
>
> I am trying to use the font of "TT Courier New: bold" to get the equal 
> size of letters. The "TT Courier New: bold" is the 11th font listed in 
> the Rdevga file.
>
> You can just try a simple case:
>
> plot(1:10, 1:10, xlab = "XILMV", font.lab = 11)
>
> I save the plot in postscript format, and found the font in .ps file 
> becomes Arial font. While I save the plot in JPEG or PNG format, 
> everything is correct.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Fri Apr 15 09:14:13 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Apr 15 09:14:22 2005
Subject: [Rd] inconsistent fonts generated in postscript file (PR#7795)
In-Reply-To: <20050415002644.267BABAF8@slim.kubism.ku.dk>
References: <20050415002644.267BABAF8@slim.kubism.ku.dk>
Message-ID: <x2sm1so6ka.fsf@turmalin.kubism.ku.dk>

xiangli@gila-fw.bioengr.uic.edu writes:

> Full_Name: Xiang Li
> Version: 2.01
> OS: WinXP
> Submission from: (NULL) (128.248.174.125)
> 
> 
> I am trying to use the font of "TT Courier New: bold" to get the equal size of
> letters. The "TT Courier New: bold" is the 11th font listed in the Rdevga file.
> 
> You can just try a simple case:
> 
> plot(1:10, 1:10, xlab = "XILMV", font.lab = 11)
> 
> I save the plot in postscript format, and found the font in .ps file becomes
> Arial font. While I save the plot in JPEG or PNG format, everything is correct.

It's not a device independent font so you cannot expect it to be
copied between devices. Look at the help page for postscript().

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Fri Apr 15 09:25:58 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Apr 15 09:26:07 2005
Subject: [Rd] (no subject)
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DDB@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076DDB@usctmx1106.merck.com>
Message-ID: <x2oecgo60p.fsf@turmalin.kubism.ku.dk>

"Liaw, Andy" <andy_liaw@merck.com> writes:

> > From: Lars Schouw
> > 
> > Can anyone explain what this means the NEWS for for
> > 2.1 beta?
> > 
> > R is now linked against ncurses/termlib/termcap only
> > if
> > readline is specified (now the default) and that
> > requires it.
> > 
> > I get an error while running configure:
> > checking for history_truncate_file... no
> > configure: error: --with-readline=yes (default) and
> > headers/libs are not available
> 
> It means what it says: configure will try to find 
> ncurses/termcap/readline (and their headers) unless
> you explicitly say --with-readline=no.

..the point being that you now get an error during configure, instead
of a just build with non-functioning arrow keys. (If you're a
sysadmin, you will catch the issue immediately, rather than your users
at some later point...)

(On Linux systems, it usually just means that you need to install
readline-devel and ncurses-devel packages.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From stefano.iacus at unimi.it  Fri Apr 15 10:16:13 2005
From: stefano.iacus at unimi.it (stefano iacus)
Date: Fri Apr 15 10:16:24 2005
Subject: [Rd] MacOS X check summary missing packages
In-Reply-To: <20050415045100.GA13510@stat.umn.edu>
References: <200504141003.j3EA38IM005483@hypatia.math.ethz.ch>
	<20050415045100.GA13510@stat.umn.edu>
Message-ID: <ba2c56bcc0d3d9828e799edaa16de5cc@unimi.it>


On 15/apr/05, at 06:51, Charles Geyer wrote:

> The "MacOS X check summary" at CRAN "Contributed Packages"
> has been missing packages 227-438 for a while.  Some problem
> with table formatting?  Or what?
gosh, it should be some script problem as all the packages are checked. 
I'll fix this. thanks for spotting
stefano

> -- 
> Charles Geyer
> Professor, School of Statistics
> University of Minnesota
> charlie@stat.umn.edu
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From mliyvzkfmksw at elong.com  Fri Apr 15 12:26:59 2005
From: mliyvzkfmksw at elong.com (mliyvz)
Date: Fri Apr 15 12:31:28 2005
Subject: [Rd] From China: Want Capital Suppliers & Agent (6%)
Message-ID: <200504151031.j3FAUuCg010207@hypatia.math.ethz.ch>

Please just reply to: buyfromchina@tom.com

Dir sir:

    We are trying to find relationship with capital suppliers around 

world,which must have strong interest on China financing market and

capability to raise over 1 billon each year.

    Agent is welcome! which can go between for us to look for funding 

and help to pass muster.

    The projects are bridge,road,power station,civil engineering,

fertilizer,etc.,which are fully supported by the government and bank 

guarantee from four major banks of China.

    The rate offered could be between 6-8% in 10-15 years term. 

    We work for the government in capital supplier acquisition and we 

are paid by the government for our performance.so this mail is not for the

detailed project.We just want to meet right providers at initial stage.

   Any qualified supplier, pls write to us for further development.

   Also, leave your contact phone number or FAX number or MSN, we have lost

some important reltionships because of unstable email communication. 

   Yours Faithfully,

         
   Allen Ling
   Yada Information Co.,Limited
   phone: 86-755-26087941
   FAX  : 86-755-26160114

   email: buyfromchina@tom.com

From ripley at stats.ox.ac.uk  Fri Apr 15 15:32:02 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Apr 15 15:41:34 2005
Subject: [Rd] New developer.r-project.org page
Message-ID: <Pine.LNX.4.61.0504151359270.27390@gannet.stats>

I've added a page on the developer site on

 	`Resources for Portable Programming'

It should show up via the index page in due course and is at

 	https://svn.r-project.org/R-dev-web/trunk/Portability.html

now.  (R core members are welcome to add to it.)

Some of the articles linked there are very useful background on e.g.
32- vs 64-bit differences and how to write efficient shared libraries.

Some of these things are targets for R 2.2.0 (e.g. using lib64, controllng 
visibility), especially after gcc 4.0.0 is released (it was due this 
week).

Note to users of ix86 Linux: valgrind 2.4.0 is out and has solved almost 
all the instability problems of 2.2.0 on recent Linux kernels.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From tplate at blackmesacapital.com  Fri Apr 15 17:32:12 2005
From: tplate at blackmesacapital.com (Tony Plate)
Date: Fri Apr 15 17:32:26 2005
Subject: [Rd] dealing with empty actual arguments matched by '...' formals
Message-ID: <425FDE7C.1080709@blackmesacapital.com>

I'm trying to write some functions to deal with empty actual arguments 
that are picked up by '...' formals.  Such actual arguments are common 
(and very useful) in calls to subsetting functions, e.g., x[1:2,].  It 
seems that R and S-PLUS treat these arguments differently: in S-PLUS 
list(...) will return a list containing just the non-empty arguments, 
whereas in R list(...) stops with an error:

 > # In R:
 > f <- function(x, ...) list(...)
 > f(1,2)
[[1]]
[1] 2
 > f(1,2,)
Error in f(1, 2, ) : argument is missing, with no default
 >

So it seems that quite different methods must be used in S-PLUS and R to 
detect and process the arguments of a function that can have empty 
arguments matched to '...'.

In R, the only way I could find to get the non-empty arguments in the 
presence of empty arguments was to call eval() on particular components 
of match.call() (as in the function f.R() below).  Is there a better way?

I've appended some example functions and test calls in case anyone wants 
to play with this and suggest possible alternative methods.

-- Tony Plate

# R function to process empty arguments
f.R <- function(x, ...) {
     dotargs <- match.call(expand.dots=F)$...
     arg.missing <- sapply(dotargs,
         function(a) is.name(a) && as.character(a)=="")
     args <- vector("list", length(arg.missing))
     i <- 3 # check that args are being eval'd in the right env
     args[!arg.missing] <- lapply(dotargs[!arg.missing],
                                  eval, sys.parent())
     data.frame(missing=arg.missing,
                length=if (length(args)) sapply(args, length)
                       else numeric(0))
}
i <- 1:7
f.R(1,1:2,i)
# Try to confirm that f.R evaluates its argument in the correct environment
(function() {i<-1:2; f.R(1,1:2,i)})()
f.R(1)
f.R(1,,,)
f.R(1,,2:4,)
f.R(1,numeric(0),2:4,)
f.R(1,NULL,2:4,)
f.R(1,NULL,2:4,,,,)

# Example of an S-PLUS function that can process empty anonymous arguments
f.S <- function(x, ...) {
     dotargs <- match.call(expand.dots=F)$...[-1]
     arg.missing <- if (length(dotargs)) sapply(dotargs, mode)=="missing"
                    else logical(0)
     args <- list(...)
     args <- args[replace(cumsum(!arg.missing), arg.missing,
                          length(args)+1)]
     data.frame(missing=arg.missing,
                length=if (length(args)) sapply(args, length)
                       else numeric(0))
}
f.S(1)
f.S(1,,,)
f.S(1,,2:4,)
f.S(1,numeric(0),2:4,)
f.S(1,NULL,2:4,)
f.S(1,NULL,2:4,,,,)

From tplate at blackmesacapital.com  Fri Apr 15 17:54:37 2005
From: tplate at blackmesacapital.com (Tony Plate)
Date: Fri Apr 15 17:54:57 2005
Subject: [Rd] treatment of zero and negative elements in matrix indices
Message-ID: <425FE3BD.4010704@blackmesacapital.com>

Matrix indexing seems to give rather "variable" results when zeros or 
negative values are included among the indices (in terms of both error 
messages and in terms of the number of returned values when there is no 
error message).

Is this the intended behavior?

I couldn't see any comments about zeros or negative values in matrix 
indices in either ?"[" or Section 3.4.2 "Indexing matrices and arrays" 
of the "R Language Definition" (Version 2.0.1), or in Section 5.3 "Index 
arrays" of "An Introduction to R" (Version 2.1.0).

(It looks like the special treatment of zeros and negative indices is 
being applied to the vector indices after they are derived by standard 
indexing arithmetic from the matrix indices -- so zeros and negative 
values in the matrix indices have no special meaning.  There does seem 
to be some range checking, but it's not consistent -- sometimes index 
values that are out of range get through.)

 > x <- matrix(1:6,ncol=2)
 > dim(x)
[1] 3 2
 > x
      [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6
 > x[rbind(c(1,1), c(2,2))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(0,1))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(0,0))]
Error: only 0's may mix with negative subscripts
 > x[rbind(c(1,1), c(2,2), c(0,2))]
[1] 1 5 3
 > x[rbind(c(1,1), c(2,2), c(0,3))]
Error: subscript out of bounds
 > x[rbind(c(1,1), c(2,2), c(1,0))]
Error: only 0's may mix with negative subscripts
 > x[rbind(c(1,1), c(2,2), c(2,0))]
Error: only 0's may mix with negative subscripts
 > x[rbind(c(1,1), c(2,2), c(3,0))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(1,2))]
[1] 1 5 4
 > x[rbind(c(1,1), c(2,2), c(-1,2))]
[1] 1 5 2
 > x[rbind(c(1,1), c(2,2), c(-2,2))]
[1] 1 5 1
 > x[rbind(c(1,1), c(2,2), c(-3,2))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(-4,2))]
Error: only 0's may mix with negative subscripts
 > x[rbind(c(1,1), c(2,2), c(-1,-1))]
Error: subscript out of bounds
 >
 > # range checks are at least sometimes not applied
 > x <- matrix(1:6, ncol=3)
 > dim(x)
[1] 2 3
 > x[rbind(c(1,1), c(2,2), c(-3,3))]
[1] 1 4 1
 > x[rbind(c(1,1), c(2,2), c(-4,3))]
[1] 1 4
 >


 > version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    0.1
year     2004
month    11
day      15
language R
 >

(I see the same behavior in R 2.1.0 beta of 2005/04/04)

-- Tony Plate

PS: FWIW, S-PLUS 6.2 does something more like one would get when using 
each row of the index matrix as arguments to a call to "[", except that 
negative values are not allowed at all (any zero value in a row causes 
that row to be omitted from the result).

From tplate at blackmesacapital.com  Fri Apr 15 18:03:50 2005
From: tplate at blackmesacapital.com (Tony Plate)
Date: Fri Apr 15 18:04:02 2005
Subject: [Rd] treatment of zero and negative elements in matrix indices
In-Reply-To: <425FE3BD.4010704@blackmesacapital.com>
References: <425FE3BD.4010704@blackmesacapital.com>
Message-ID: <425FE5E6.8090009@blackmesacapital.com>

PS: I'm talking about subsetting matrices using a matrix as an index.

Tony Plate wrote:
> Matrix indexing seems to give rather "variable" results when zeros or 
> negative values are included among the indices (in terms of both error 
> messages and in terms of the number of returned values when there is no 
> error message).
> 
> Is this the intended behavior?
> 
> I couldn't see any comments about zeros or negative values in matrix 
> indices in either ?"[" or Section 3.4.2 "Indexing matrices and arrays" 
> of the "R Language Definition" (Version 2.0.1), or in Section 5.3 "Index 
> arrays" of "An Introduction to R" (Version 2.1.0).
> 
> (It looks like the special treatment of zeros and negative indices is 
> being applied to the vector indices after they are derived by standard 
> indexing arithmetic from the matrix indices -- so zeros and negative 
> values in the matrix indices have no special meaning.  There does seem 
> to be some range checking, but it's not consistent -- sometimes index 
> values that are out of range get through.)
> 
>  > x <- matrix(1:6,ncol=2)
>  > dim(x)
> [1] 3 2
>  > x
>      [,1] [,2]
> [1,]    1    4
> [2,]    2    5
> [3,]    3    6
>  > x[rbind(c(1,1), c(2,2))]
> [1] 1 5
>  > x[rbind(c(1,1), c(2,2), c(0,1))]
> [1] 1 5
>  > x[rbind(c(1,1), c(2,2), c(0,0))]
> Error: only 0's may mix with negative subscripts
>  > x[rbind(c(1,1), c(2,2), c(0,2))]
> [1] 1 5 3
>  > x[rbind(c(1,1), c(2,2), c(0,3))]
> Error: subscript out of bounds
>  > x[rbind(c(1,1), c(2,2), c(1,0))]
> Error: only 0's may mix with negative subscripts
>  > x[rbind(c(1,1), c(2,2), c(2,0))]
> Error: only 0's may mix with negative subscripts
>  > x[rbind(c(1,1), c(2,2), c(3,0))]
> [1] 1 5
>  > x[rbind(c(1,1), c(2,2), c(1,2))]
> [1] 1 5 4
>  > x[rbind(c(1,1), c(2,2), c(-1,2))]
> [1] 1 5 2
>  > x[rbind(c(1,1), c(2,2), c(-2,2))]
> [1] 1 5 1
>  > x[rbind(c(1,1), c(2,2), c(-3,2))]
> [1] 1 5
>  > x[rbind(c(1,1), c(2,2), c(-4,2))]
> Error: only 0's may mix with negative subscripts
>  > x[rbind(c(1,1), c(2,2), c(-1,-1))]
> Error: subscript out of bounds
>  >
>  > # range checks are at least sometimes not applied
>  > x <- matrix(1:6, ncol=3)
>  > dim(x)
> [1] 2 3
>  > x[rbind(c(1,1), c(2,2), c(-3,3))]
> [1] 1 4 1
>  > x[rbind(c(1,1), c(2,2), c(-4,3))]
> [1] 1 4
>  >
> 
> 
>  > version
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
>  >
> 
> (I see the same behavior in R 2.1.0 beta of 2005/04/04)
> 
> -- Tony Plate
> 
> PS: FWIW, S-PLUS 6.2 does something more like one would get when using 
> each row of the index matrix as arguments to a call to "[", except that 
> negative values are not allowed at all (any zero value in a row causes 
> that row to be omitted from the result).
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From murdoch at math.aau.dk  Sat Apr 16 10:59:38 2005
From: murdoch at math.aau.dk (Duncan Murdoch)
Date: Sat Apr 16 10:59:46 2005
Subject: [Rd] dealing with empty actual arguments matched by '...' formals
In-Reply-To: <425FDE7C.1080709@blackmesacapital.com>
References: <425FDE7C.1080709@blackmesacapital.com>
Message-ID: <4260D3FA.4030905@math.aau.dk>

Tony Plate wrote:
> I'm trying to write some functions to deal with empty actual arguments 
> that are picked up by '...' formals.  Such actual arguments are common 
> (and very useful) in calls to subsetting functions, e.g., x[1:2,].  It 
> seems that R and S-PLUS treat these arguments differently: in S-PLUS 
> list(...) will return a list containing just the non-empty arguments, 
> whereas in R list(...) stops with an error:
> 
>  > # In R:
>  > f <- function(x, ...) list(...)
>  > f(1,2)
> [[1]]
> [1] 2
>  > f(1,2,)
> Error in f(1, 2, ) : argument is missing, with no default
>  >
> 
> So it seems that quite different methods must be used in S-PLUS and R to 
> detect and process the arguments of a function that can have empty 
> arguments matched to '...'.

Can you give an example where it's useful to do this, i.e. to have a 
call like f(1,2,)?  I've never used that construction as far as I can 
recall.

Duncan Murdoch

From supraben2 at hotmail.com  Sat Apr 16 06:26:10 2005
From: supraben2 at hotmail.com (ben)
Date: Sat Apr 16 15:53:35 2005
Subject: [Rd] about constructing a logit model
Message-ID: <BAY103-DAV3D586CD407C1ED855E782F1370@phx.gbl>

I am a new B for R, so as this mailing list too.   Thank you very much to those who will reply me and the contrubutors, THANK YOU.
let me tell my problem that I am encountering now
I have grabbed some data from census department to do an analysis.  however, it is too bad that the data have been handle so I cannot treat them as the homework i did in school. 
I am going to test the determinants of the people want to move to developing city from developed city

EXAMPLE suppose there is 3 individuals a,b,c 
a = age <30, salary 10k, and edu.level=highschool    move
b = age 30~40, salary 30k, and edu.level=college      not move
c = age 40~50, salary 20k, and edu.level=highschool   move
(IT IS JUST AN EXAMPLE TO TELL MY SITUATION, I HAVE THOUSAND OF DATA SETS INTEAD OF 3)
I used
<summary(glm(mydata))
and all the variable are significant, but once i do it as 3 models
<summary(glm(move~edu.level))
<summary(glm(move~salary))
<summary(glm(move~age))
only salaries is significant, all the rest pvalue>0.2..too bad
furthermore, i tried
<summary(glm(mydata, family=binomial))
only salary significant too... why does it happen?
the result affects by the "family=binomial"... i m not sure how it works....

further more
actually, my data is not that good as shows as individual..instead...
aged <30  move , 30~40 not move , 40~50  move
 salary.20k move, 30k not move, 40k  move,
edu.level highschool move, highschool move, college  not move

all the categories have been rearranged and i dont know which of each characteristic is with respect to which person.
do u think I will miss some correlation for those factors?
or i can test them group by group only..(move vs age, SAY AGE <30 ARE MORE MOBILITY)
Thank you very much again.
sbest regards
Ben
	[[alternative HTML version deleted]]

From p.dalgaard at biostat.ku.dk  Sat Apr 16 16:42:25 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat Apr 16 16:42:34 2005
Subject: [Rd] dealing with empty actual arguments matched by '...' formals
In-Reply-To: <4260D3FA.4030905@math.aau.dk>
References: <425FDE7C.1080709@blackmesacapital.com>
	<4260D3FA.4030905@math.aau.dk>
Message-ID: <x264ym941a.fsf@turmalin.kubism.ku.dk>

Duncan Murdoch <murdoch@math.aau.dk> writes:

> Tony Plate wrote:
> > I'm trying to write some functions to deal with empty actual
> > arguments that are picked up by '...' formals.  Such actual
> > arguments are common (and very useful) in calls to subsetting
> > functions, e.g., x[1:2,].  It seems that R and S-PLUS treat these
> > arguments differently: in S-PLUS list(...) will return a list
> > containing just the non-empty arguments, whereas in R list(...)
> > stops with an error:
> >  > # In R:
> >  > f <- function(x, ...) list(...)
> >  > f(1,2)
> > [[1]]
> > [1] 2
> >  > f(1,2,)
> > Error in f(1, 2, ) : argument is missing, with no default
> >  >
> > So it seems that quite different methods must be used in S-PLUS and
> > R to detect and process the arguments of a function that can have
> > empty arguments matched to '...'.
> 
> Can you give an example where it's useful to do this, i.e. to have a
> call like f(1,2,)?  I've never used that construction as far as I can
> recall.

The standard case is indexing, as Tony mentions. 

The whole thing is somewhat tricky because at least some of R's
semantics are deliberately different from S. E.g.

> f <- function(i) g(i)
> g <- function(i) missing(i)
> f()
[1] TRUE

Same thing in S gives FALSE. S looks at the call to g whereas R looks
at the value. This works by passing a "magic bullet" which is
implemented as the "empty name", as you can get to see by doing
something like

> f <- function(...) match.call(expand.dots=FALSE)$...
> l <- f(1,,2)
> eval(l[[2]])
Error in eval(expr, envir, enclos) : Argument is missing, with no default
> mode(l[[2]])
[1] "name"
> as.character(l[[2]])
[1] ""

One side effect of R's way of doing things is that a call to
list(i,j,k) with k missing is hard to tell from list(i,j,). However,
list() must be doing that somehow... I'm not sure it is a good thing, but
it may have been necessary for S compatibility.

I think that what Tony was up to might be doable through variations on
the match.call() scheme above.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ltordsen at mymachinery.net  Sat Apr 16 23:37:32 2005
From: ltordsen at mymachinery.net (Larry Tordsen)
Date: Sat Apr 16 23:37:42 2005
Subject: [Rd] SET_LENGTH
Message-ID: <20050416213732.87710.qmail@web303.biz.mail.mud.yahoo.com>

Hello.

I'm trying to read a delimited file.  I'm a little new
to the R api.  In the program, I do something like
this...

/*****************************/
SEXP retval;
PROTECT(retval = allocMatrix(STRSXP,1,names.dim));
int r_eltctr = 0;
while(!myfile.eof())
{
  SET_LENGTH(retval,r_eltctr+num_of_fields);
  for(int i = 0;numofcolumns; ++i)
    {
      INTEGER(retval)[r_eltctr++] = 1;/*some
value...*/
    }
  ++r_eltctr;
}
UNPROTECT(1);
/***************************************/

There is a segmentation fault when SET_LENGTH() is
called several iterations into the program.  It seems
like it should not be a memory issue, unless a
constraint is set by R.  The vector only has about
3500 elements at the time it crashes.

Does anyone have any ideas what the problem could be?

From ripley at stats.ox.ac.uk  Sun Apr 17 09:10:36 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Apr 17 09:10:46 2005
Subject: [Rd] Using lengthgets() correctly (was SET_LENGTH)
In-Reply-To: <20050416213732.87710.qmail@web303.biz.mail.mud.yahoo.com>
References: <20050416213732.87710.qmail@web303.biz.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.61.0504170758460.10873@gannet.stats>

If you use R not the S-compatibility macros you will be less likely to 
confuse yourself.  The definition is (analogous to realloc)

Rdefines.h:#define SET_LENGTH(x, n)  (x = lengthgets(x, n))

so x is changed and needs to be reprotected.  [I don't know that
SET_LENGTH *is* part of the API: it is not defined in `Writing R 
Extensions'.]

Your error will potentially occur at the first garbage collection.  Try 
using REPROTECT.

Note though that what you are doing is very inefficient, and re-setting 
the length without changing the dim is also an error.  What R's internal 
examples do is to allocate a modest vector, double in size when needed, 
call lengthgets to shorten at the end, then set the dim attribute.

On Sat, 16 Apr 2005, Larry Tordsen wrote:

> Hello.
>
> I'm trying to read a delimited file.  I'm a little new
> to the R api.  In the program, I do something like
> this...
>
> /*****************************/
> SEXP retval;
> PROTECT(retval = allocMatrix(STRSXP,1,names.dim));
> int r_eltctr = 0;
> while(!myfile.eof())
> {
>  SET_LENGTH(retval,r_eltctr+num_of_fields);
>  for(int i = 0;numofcolumns; ++i)
>    {
>      INTEGER(retval)[r_eltctr++] = 1;/*some
> value...*/
>    }
>  ++r_eltctr;
> }
> UNPROTECT(1);
> /***************************************/
>
> There is a segmentation fault when SET_LENGTH() is
> called several iterations into the program.  It seems
> like it should not be a memory issue, unless a
> constraint is set by R.  The vector only has about
> 3500 elements at the time it crashes.
>
> Does anyone have any ideas what the problem could be?

The problem seems to be the assumption that R (and not the user) was at 
fault.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sun Apr 17 10:54:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Apr 17 10:54:19 2005
Subject: [Rd] Using lengthgets() correctly (was SET_LENGTH)
In-Reply-To: <Pine.LNX.4.61.0504170758460.10873@gannet.stats>
References: <20050416213732.87710.qmail@web303.biz.mail.mud.yahoo.com>
	<Pine.LNX.4.61.0504170758460.10873@gannet.stats>
Message-ID: <Pine.LNX.4.61.0504170950340.12022@gannet.stats>

I assume this is not true of your actual example, but the sample code
allocates a character matrix and calls INTEGER() on it.  Ouch!

On Sun, 17 Apr 2005, Prof Brian Ripley wrote:

> If you use R not the S-compatibility macros you will be less likely to 
> confuse yourself.  The definition is (analogous to realloc)
>
> Rdefines.h:#define SET_LENGTH(x, n)  (x = lengthgets(x, n))
>
> so x is changed and needs to be reprotected.  [I don't know that
> SET_LENGTH *is* part of the API: it is not defined in `Writing R 
> Extensions'.]
>
> Your error will potentially occur at the first garbage collection.  Try using 
> REPROTECT.
>
> Note though that what you are doing is very inefficient, and re-setting the 
> length without changing the dim is also an error.  What R's internal examples 
> do is to allocate a modest vector, double in size when needed, call 
> lengthgets to shorten at the end, then set the dim attribute.
>
> On Sat, 16 Apr 2005, Larry Tordsen wrote:
>
>> Hello.
>> 
>> I'm trying to read a delimited file.  I'm a little new
>> to the R api.  In the program, I do something like
>> this...
>> 
>> /*****************************/
>> SEXP retval;
>> PROTECT(retval = allocMatrix(STRSXP,1,names.dim));
>> int r_eltctr = 0;
>> while(!myfile.eof())
>> {
>>  SET_LENGTH(retval,r_eltctr+num_of_fields);
>>  for(int i = 0;numofcolumns; ++i)
>>    {
>>      INTEGER(retval)[r_eltctr++] = 1;/*some
>> value...*/
>>    }
>>  ++r_eltctr;
>> }
>> UNPROTECT(1);
>> /***************************************/
>> 
>> There is a segmentation fault when SET_LENGTH() is
>> called several iterations into the program.  It seems
>> like it should not be a memory issue, unless a
>> constraint is set by R.  The vector only has about
>> 3500 elements at the time it crashes.
>> 
>> Does anyone have any ideas what the problem could be?
>
> The problem seems to be the assumption that R (and not the user) was at 
> fault.
>
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sun Apr 17 13:38:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Apr 17 13:38:19 2005
Subject: [Rd] RFC: hexadecimal constants and decimal points
Message-ID: <Pine.LNX.4.61.0504171136210.13254@gannet.stats>

These are some points stimulated by reading about C history (and 
related in their implementation).


1) On some platforms

> as.integer("0xA")
[1] 10

but not all (not on Solaris nor Windows).  We do not define what is 
allowed, and rely on the OS's implementation of strtod (yes, not strtol). 
It seems that glibc does allow hex: C99 mandates it but C89 seems not to 
allow it.

I think that was a mistake, and strtol should have been used.  Then C89
does mandate the handling of hex constants and also octal ones.  So 
changing to strtol would change the meaning of as.integer("011").

Proposal: we handle this ourselves and define what values are acceptable,
namely for as.integer:

[+|-][0-9]+
NA
0[x|X][0-9A-fa-f]+

in all cases such that the converted value is in-range.  (This does mean 
as.integer("1e+05") would be invalid, but is it clear that is allowed 
now?)

For as.numeric(), probably the C99 rules (which include NaN, Inf, 
Infinity, and we need to add NA).

Alternatively, make and document the semantics to be
as.integer(as.numeric(char_string)) (which is effectively what we have 
now, although it causes surprises).

[As a side point, some locales may accept non-Roman digits.  I think we 
need to exclude those everywhere, not just some places like parsing.]


2) R does not have integer constants.  It would be convenient if it did, 
and I can see no difficulty in allowing the same conversions when parsing 
as when coercing.  This would have the side effect that 100 would be 
integer (but the coercion rules would come into play) but 
200000000000000000 would be double.  And x <-0xce80 would be valid.


3) We do allow setting LC_NUMERIC, but it partially breaks R if the 
decimal point is not ".".  (I know of no locale in which it is not "." or 
",", and we cannot allow "," as part of numeric constants when parsing.) 
E.g.:

> Sys.setlocale("LC_NUMERIC", "fr_FR")
[1] "fr_FR"
Warning message:
setting 'LC_NUMERIC' may cause R to function strangely in: 
setlocale(category, locale)
> x <- 3.12
> x
[1] 3
> as.numeric("3,12")
[1] 3,12
> as.numeric("3.12")
[1] NA
Warning message:
NAs introduced by coercion

We could do better by insisting that "." was the decimal point in all 
interval conversions _to_ numeric.  Then the effect of setting LC_NUMERIC 
would primarily be on conversions _from_ numeric, especially printing and 
graphical output.  (One issue would be what to do with scan(), which has a 
`dec' argument but is implemented assuming LC_NUMERIC=C.  I would hope to 
continue to have `dec' but perhaps with a locale-dependent default.)  The 
resulting asymmetry (R would not be able to parse its own output) would be 
unhappy, but seems inevitable. (This could be implemented easily by having 
a `dec' arg to EncodeReal and EncodeComplex, and using LC_NUMERIC to 
control that rather than actually setting the local category.  For 
example, deparsing needs to be done in LC_NUMERIC=C.)


All of these could be implemented by customized versions of 
strtod/strtol.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ggrothendieck at gmail.com  Sun Apr 17 14:31:12 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun Apr 17 14:31:23 2005
Subject: [Rd] RFC: hexadecimal constants and decimal points
In-Reply-To: <Pine.LNX.4.61.0504171136210.13254@gannet.stats>
References: <Pine.LNX.4.61.0504171136210.13254@gannet.stats>
Message-ID: <971536df05041705313c317755@mail.gmail.com>

On 4/17/05, Prof Brian Ripley <ripley@stats.ox.ac.uk> wrote:
> These are some points stimulated by reading about C history (and
> related in their implementation).
> 
> 1) On some platforms
> 
> > as.integer("0xA")
> [1] 10
> 
> but not all (not on Solaris nor Windows).  We do not define what is
> allowed, and rely on the OS's implementation of strtod (yes, not strtol).
> It seems that glibc does allow hex: C99 mandates it but C89 seems not to
> allow it.
> 
> I think that was a mistake, and strtol should have been used.  Then C89
> does mandate the handling of hex constants and also octal ones.  So
> changing to strtol would change the meaning of as.integer("011").

In the windows batch language the following (translated to R):
       month <- substr("20050817",5,2)
must be further processed to removed any leading zero.  Mostly
people don't even realize this and just wind up writing erroneous
programs.  Its actually a big nuisance IMHO.

From jtk at cmp.uea.ac.uk  Sun Apr 17 15:50:01 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Sun Apr 17 14:54:47 2005
Subject: [Rd] RFC: hexadecimal constants and decimal points
In-Reply-To: <Pine.LNX.4.61.0504171136210.13254@gannet.stats>
References: <Pine.LNX.4.61.0504171136210.13254@gannet.stats>
Message-ID: <20050417135001.GA14537@jtkpc.cmp.uea.ac.uk>

On Sun, Apr 17, 2005 at 12:38:10PM +0100, Prof Brian Ripley wrote:
> These are some points stimulated by reading about C history (and 
> related in their implementation).
> 
> 
> 1) On some platforms
> 
> >as.integer("0xA")
> [1] 10
> 
> but not all (not on Solaris nor Windows).  We do not define what is 
> allowed, and rely on the OS's implementation of strtod (yes, not strtol). 
> It seems that glibc does allow hex: C99 mandates it but C89 seems not to 
> allow it.
> 
> I think that was a mistake, and strtol should have been used.  Then C89
> does mandate the handling of hex constants and also octal ones.  So 
> changing to strtol would change the meaning of as.integer("011").

I think interpretation of a leading "0" as a prefix indicating an octal
representation should indeed be avoided. People not familiar to C will
have a hard time understanding and getting used to this concept, and
in addition, it happens way too often that numeric data are provided left-
padded with zeros.

> Proposal: we handle this ourselves and define what values are acceptable,
> namely for as.integer:
> 
> [+|-][0-9]+
> NA
> 0[x|X][0-9A-fa-f]+

It can be a somewhat mixed blessing if the string representation of numeric
values contain information about their base, in the form of the 0x prefix
in this case.

The base argument (#3) of C's strtol function can be set to to a base
explicitly or to 0, which gives the prefix-based "auto-selection"
behaviour. On the R level, such a base argument (to as.integer) could be
included and a default could be set.

Personally, I would be equally happy with the default being 0 (auto-select)
or 10. Considering the perhaps limited spread of familiarity with C's
"0x" idiom, I somewhat favour a consistent and "stubborn" decimal behaviour
(base defaults to 10), though.

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk@cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*

From ripley at stats.ox.ac.uk  Sun Apr 17 15:46:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Apr 17 15:46:58 2005
Subject: [Rd] RFC: hexadecimal constants and decimal points
In-Reply-To: <20050417135001.GA14537@jtkpc.cmp.uea.ac.uk>
References: <Pine.LNX.4.61.0504171136210.13254@gannet.stats>
	<20050417135001.GA14537@jtkpc.cmp.uea.ac.uk>
Message-ID: <Pine.LNX.4.61.0504171445040.15170@gannet.stats>

On Sun, 17 Apr 2005, Jan T. Kim wrote:

> On Sun, Apr 17, 2005 at 12:38:10PM +0100, Prof Brian Ripley wrote:
>> These are some points stimulated by reading about C history (and
>> related in their implementation).
>>
>>
>> 1) On some platforms
>>
>>> as.integer("0xA")
>> [1] 10
>>
>> but not all (not on Solaris nor Windows).  We do not define what is
>> allowed, and rely on the OS's implementation of strtod (yes, not strtol).
>> It seems that glibc does allow hex: C99 mandates it but C89 seems not to
>> allow it.
>>
>> I think that was a mistake, and strtol should have been used.  Then C89
>> does mandate the handling of hex constants and also octal ones.  So
>> changing to strtol would change the meaning of as.integer("011").
>
> I think interpretation of a leading "0" as a prefix indicating an octal
> representation should indeed be avoided. People not familiar to C will
> have a hard time understanding and getting used to this concept, and
> in addition, it happens way too often that numeric data are provided left-
> padded with zeros.
>
>> Proposal: we handle this ourselves and define what values are acceptable,
>> namely for as.integer:
>>
>> [+|-][0-9]+
>> NA
>> 0[x|X][0-9A-fa-f]+
>
> It can be a somewhat mixed blessing if the string representation of numeric
> values contain information about their base, in the form of the 0x prefix
> in this case.
>
> The base argument (#3) of C's strtol function can be set to to a base
> explicitly or to 0, which gives the prefix-based "auto-selection"
> behaviour. On the R level, such a base argument (to as.integer) could be
> included and a default could be set.

A lot of this is internal, not at R level.

> Personally, I would be equally happy with the default being 0 (auto-select)
> or 10. Considering the perhaps limited spread of familiarity with C's
> "0x" idiom, I somewhat favour a consistent and "stubborn" decimal behaviour
> (base defaults to 10), though.

Some people already rely on it, and those who don't know about it are 
unliekly to ever enter what they think is an illegal value, surely?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From pawwpqxnhnsr at browreckers.com  Mon Apr 18 04:52:03 2005
From: pawwpqxnhnsr at browreckers.com (Roderick Thomas)
Date: Mon Apr 18 05:31:14 2005
Subject: [Rd] Growing company ignored by Wall Street
Message-ID: <871484159925.JJN64573@decompression.bertarelli.edu>

"StOck Watch A|ert" this morning are Wysak Petroleum (WYSK), Key
Energy Services, Inc. (Pink Sheets: KEGS), Medify So|utions (MFYS),
Sequoia Interests Corporation (SQNC).

Wysak Petroleum (WYSK)
Current Price:   0.21

Wysak Petro|eum announces the signing of a Letter of Intent with the European
Commission Ba|tic Renewable Energy Centre (EC BREC) to assist Wysak Petroleum in
the development of the Wysak Wind Power Project.

EC BREC and Wysak have signed a LOI in respect to the deve|opment of a
fu||-sized Commercia| Wind Power Project in Europe. This letter states that EC
BREC can support Wysak in matters such as financia| structuring and investment,
regu|atory issues, government policies, negotiations, wind technologies, and
other aspects relating to Wind Power.

About the Wysak Wind Project

This deve|opment will be up to a maximum 90Mw in size and cost upwards of $12O
milli0n in deve|opment expenditures. Once comp|eted, this Wind Park wi|l supp|y
upwards of 170,O00 Mw of electricity annually for Po|and and the European
Community. This is enough green energy to supp|y upwards of 25,O00 homes with
electricity and offset near|y 170,0O0 tonnes of Greenhouse gases. Tota| gross
e|ectric sales over a 2O-year period are estimated at over $450 mil|i0n for a
project this size.

About the EC Baltic Renewable Energy Centre

The mission of European Commission-founded EC BREC is to stimu|ate the
development of renewable energy sources (RES) in Po|and through the construction
of RES projects, the development of innovative techno|ogies, and the creation of
re|evant policies, strategies and plans. To fulfill the mission, EC BREC uses
its own research capabilities and cooperates with partner institutions from the
EU, other countries, and international organizations.

About Wysak Petroleum

Wysak is a diversified energy company whose goal is to identify and develop
traditional fossil fuel sites, as wel| as clean air alternative energy producing
techno|ogies. Wysak contro|s one Wyoming Federa| oil & gas lease in the Bighorn
Basin region and another in the Green River Basin. Its two Wyoming State leases
are located 45 miles apart within the massive CoalBed Methane p|ay area of the
Powder River Basin. Numerous large petroleum and exp|oration firms operate near
to a|l of these properties; they inc|ude ExxonMobi|e (XOM), Wi|liams Gas (WMB),
and Western Gas (WGR) among others. Col|ectively, over 26,0OO we||s produced
54.7 mi|lion barre|s of oi| and 1.75 tril|ion cubic feet of natura| gas in
Wyoming

Conclusion:

The Examp|es Above Show The Awesome, Earning Potentia| of Litt|e Known Companies
That Explode Onto Investor's Radar Screens; Many of You Are Already Fami|iar with This.
Is WYSK Poised and Positioned to Do that For You?
Then You May Feel the Time Has Come to Act... And Please Watch this One Trade Monday!
Go WYSK.

Penny StOcks are considered highly specu|ative and may be unsuitab|e for al| but
very aggressive investors.  This Profile is not in any way affi|iated with the
featured company.We were compensated 3000 dollars to distribute this report.
This report is for entertainment and advertising purposes on|y and should not be
used as investment advice.
 
If you wish to stop future mai|ings, or if you feel you have been
wrongful|y p|aced in our membership, please go here or send a b|ank
e mai| with No Thanks in the subject to   st0ck1004 @  yahoo.com

From adrian at maths.uwa.edu.au  Mon Apr 18 07:17:18 2005
From: adrian at maths.uwa.edu.au (Adrian Baddeley)
Date: Mon Apr 18 07:17:48 2005
Subject: [Rd] density() with weights
Message-ID: <16995.17118.603485.179514@maths.uwa.edu.au>

Hello - 

Recently I needed to compute kernel density estimates 
for a vector of observations x with given weights w
instead of the conventional equal weights w[i] = 1/length(x).

AFAIK, the existing code in 'base' does not accept weights. 

It wasn't hard to modify the C and R code for `density' in the base library
to accept weights. Source code is available at this URL

   <http://www.maths.uwa.edu.au/~adrian/density.html>

Just a suggestion.

regards
Adrian Baddeley.

From WeiQiang.Li at seagate.com  Mon Apr 18 08:05:43 2005
From: WeiQiang.Li at seagate.com (WeiQiang.Li@seagate.com)
Date: Mon Apr 18 08:06:03 2005
Subject: [Rd] UnauthorizedAccessException in R(D)COM
Message-ID: <OFD0F24CAE.6754860D-ON48256FE7.001F349A-48256FE7.002198AA@seagate.com>

Dear friends,

        I am trying to create a web application to produce some 
statistical result using R. In order to avoid high CPU usage of  web 
server caused by R, I have to create an ASP.NET web service in another 
server to involve R.

        But I am facing the unauthorizedAccessException when I call the 
web service, even I have assigned access and launch permission to everyone 
using DCOMCNFG.exe


        The sample code is shown as below, and the 
unauthorizedAccessException  exception is occurred when myR.Init("R") is 
called.
        myR = New STATCONNECTORSRVLib.StatConnector
        myR.Init("R")


        Does anyone know this solution and please advide me?  Your help is 
appreciated.


With Best Regards,
WeiQiang Li


	[[alternative HTML version deleted]]

From maechler at stat.math.ethz.ch  Mon Apr 18 08:28:26 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Apr 18 08:28:39 2005
Subject: [Rd] recent spam on mailing lists
Message-ID: <16995.21386.856640.879274@stat.math.ethz.ch>

Probably not many of you have noticed, since I assume you
have your own active spam filters:
But we have recently (first time on Friday April 15) had problems
with spam filtering on our mail server.  The spamassassin daemon
(spamd) has "died" for no apparent reason, and hence the mail
has been passed through without spam filtering.

We have had a look at the log files and haven't got a real clue
about the reasons.  As stop-gap measure we now have a "nanny
script" that tries to see if 'spamd' lives, and restarts it in
case it isn't there anymore.

Martin Maechler
ETH Zurich

From WeiQiang.Li at seagate.com  Mon Apr 18 08:29:34 2005
From: WeiQiang.Li at seagate.com (WeiQiang.Li@seagate.com)
Date: Mon Apr 18 08:29:56 2005
Subject: [Rd] UnauthorizedAccessException in R(D)COM
Message-ID: <OFD0F24CAE.6754860D-ON48256FE7.001F349A-48256FE7.0023C7A1@seagate.com>

Dear friends, 

        I am trying to create a web application to produce some 
statistical result using R. In order to avoid high CPU usage of  web 
server caused by R, I have to create an ASP.NET web service in another 
server to involve R. 

        But I am facing the unauthorizedAccessException when I call the 
web service, even I have assigned access and launch permission to everyone 
using DCOMCNFG.exe 


        The sample code is shown as below, and the 
unauthorizedAccessException  exception is occurred when myR.Init("R") is 
called. 
        myR = New STATCONNECTORSRVLib.StatConnector 
        myR.Init("R") 


        Does anyone know this solution and please advide me?  Your help is 
appreciated. 


With Best Regards, 
WeiQiang Li 

	[[alternative HTML version deleted]]

From ripley at stats.ox.ac.uk  Mon Apr 18 08:34:33 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Apr 18 08:34:49 2005
Subject: [Rd] UnauthorizedAccessException in R(D)COM
In-Reply-To: <OFD0F24CAE.6754860D-ON48256FE7.001F349A-48256FE7.002198AA@seagate.com>
References: <OFD0F24CAE.6754860D-ON48256FE7.001F349A-48256FE7.002198AA@seagate.com>
Message-ID: <Pine.LNX.4.61.0504180726400.3138@gannet.stats>

This is the wrong list for R(D)COM, which is not part of R.  It has its
own support list.  Almost all readers of this list have no idea what the
MicroSoft jargon you are using means.

See the `home page'

http://cran.r-project.org/contrib/extra/dcom/RSrv135.html

for more details.

On Mon, 18 Apr 2005 WeiQiang.Li@seagate.com wrote:

> Dear friends,
>
>        I am trying to create a web application to produce some
> statistical result using R. In order to avoid high CPU usage of  web
> server caused by R, I have to create an ASP.NET web service in another
> server to involve R.
>
>        But I am facing the unauthorizedAccessException when I call the
> web service, even I have assigned access and launch permission to everyone
> using DCOMCNFG.exe
>
>
>        The sample code is shown as below, and the
> unauthorizedAccessException  exception is occurred when myR.Init("R") is
> called.
>        myR = New STATCONNECTORSRVLib.StatConnector
>        myR.Init("R")
>
>
>        Does anyone know this solution and please advide me?  Your help is
> appreciated.
>
>
> With Best Regards,
> WeiQiang Li

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From saveez at hotmail.com  Mon Apr 18 10:25:52 2005
From: saveez at hotmail.com (Ali -)
Date: Mon Apr 18 10:26:01 2005
Subject: [Rd] A 'true' R-wrapper for C++ classes
Message-ID: <BAY17-F25AAF617A04C82EF46FB7CD1290@phx.gbl>

Hello

I am trying to wrap some C++ classes into R.

(1) Comparing the OOP and methods packages, I have came to this conclusion 
that OOP works much better for this wrapper -- please correct me if I am 
wrong. One question is why this useful package (OOP) is not included in the 
official release of R?

(2) Choosing the OOP package way, I have carried out the following steps to 
wrap the C++ classes:

  (2.1) A C-wrapper is created to convert the C++ class to some C-style 
code.
  (2.2) An R-wrapper wraps the C-wrapper.

Here is a rough example to demonstrate the above:

---------------------
C++ class:

class foo
{
public:
  foo();
  ~foo();

  fun();
}

---------------------
C-wrapper:

extern "C" SEXP R_foo_init()
{
  foo* obj = new foo();

  SEXP res;
  PROTECT(res = R_MakeExternalPtr(obj, R_NilValue, R_NilValue));
  UNPROTECT(1);

  return res;
}

extern "C" SEXP R_foo_fun(SEXP ptr)
{
  foo *ptr = Hello

I am trying to wrap some C++ classes into R.

(1) Comparing the OOP and methods packages, I have came to this conclusion 
that OOP works much better for this wrapper -- please correct me if I am 
wrong. One question is why this useful package (OOP) is not included in the 
official release of R?

(2) Choosing the OOP package way, I have carried out the following steps to 
wrap the C++ classes:

  (2.1) A C-wrapper is created to convert the C++ class to some C-style 
code.
  (2.2) An R-wrapper wraps the C-wrapper.

Here is a rough example to demonstrate the above:

---------------------
C++ class:

class foo
{
public:
  foo();
  ~foo();

  fun();
}

---------------------
C-wrapper:

extern "C" SEXP R_foo_init()
{
  foo* obj = new foo();

  SEXP res;
  PROTECT(res = R_MakeExternalPtr(obj, R_NilValue, R_NilValue));
  UNPROTECT(1);

  return res;
}

extern "C" SEXP R_foo_fun(SEXP ptr)
{
  foo *= Hello

I am trying to wrap some C++ classes into R.

(1) Comparing the OOP and methods packages, I have came to this conclusion 
that OOP works much better for this wrapper -- please correct me if I am 
wrong. One question is why this useful package (OOP) is not included in the 
official release of R?

(2) Choosing the OOP package way, I have carried out the following steps to 
wrap the C++ classes:

  (2.1) A C-wrapper is created to convert the C++ class to some C-style 
code.
  (2.2) An R-wrapper wraps the C-wrapper.

Here is a rough example to demonstrate the above:

---------------------
C++ class:

class foo
{
public:
  foo();
  ~foo();

  fun();
}

---------------------
C-wrapper:

extern "C" SEXP R_foo_init()
{
  foo* ptr= new foo();

  SEXP res;
  PROTECT(res = R_MakeExternalPtr(ptr, R_NilValue, R_NilValue));
  UNPROTECT(1);

  return res;
}

extern "C" SEXP R_foo_fun(SEXP obj)
{
  foo *ptr= (foo *) R_ExternalPtrAddr(obj);
  ptr->fun();

  return  R_NilValue;
}

---------------------
R-wrapper:

defineClass(className = "foo");

vtkObject$defineFields(ptr = "externalptr");

vtkObject$defineMethod(
	"initialize",
	function(){
		ptr <- .Call("R_foo_init")
	}
);

vtkObject$defineMethod(
    "fun",
    function()
    {
        .Call("R_foo_fun", ptr);
    }
);
--------------------

(3) The above model lacks something like an 'environment' for the pointer to 
the C++ object to live in it. Assume we create the foo class in R like:

  obj <- foo$new()

Now, the following would return an error:

  obj$fun()

and the reason is that the pointer created in the initialize method is lost.

(4) The question is how to assign an environment to the pointers. A well 
described answer, rather than some abstract hints, is well-appreciated. Also 
I am curious to know why there is no standard method for R to wrap C++ 
classes, something like JNI.

Thanks,

Ali

From murdoch at stats.uwo.ca  Mon Apr 18 09:33:42 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon Apr 18 10:33:50 2005
Subject: [Rd] RFC: hexadecimal constants and decimal points
In-Reply-To: <Pine.LNX.4.61.0504171445040.15170@gannet.stats>
References: <Pine.LNX.4.61.0504171136210.13254@gannet.stats>
	<20050417135001.GA14537@jtkpc.cmp.uea.ac.uk>
	<Pine.LNX.4.61.0504171445040.15170@gannet.stats>
Message-ID: <40932.130.225.48.22.1113809622.squirrel@www.stats.uwo.ca>

> On Sun, 17 Apr 2005, Jan T. Kim wrote:
>
>> On Sun, Apr 17, 2005 at 12:38:10PM +0100, Prof Brian Ripley wrote:
>>> These are some points stimulated by reading about C history (and
>>> related in their implementation).
>>>
>>>
>>> 1) On some platforms
>>>
>>>> as.integer("0xA")
>>> [1] 10
>>>
>>> but not all (not on Solaris nor Windows).  We do not define what is
>>> allowed, and rely on the OS's implementation of strtod (yes, not
>>> strtol).
>>> It seems that glibc does allow hex: C99 mandates it but C89 seems not
>>> to
>>> allow it.
>>>
>>> I think that was a mistake, and strtol should have been used.  Then C89
>>> does mandate the handling of hex constants and also octal ones.  So
>>> changing to strtol would change the meaning of as.integer("011").
>>
>> I think interpretation of a leading "0" as a prefix indicating an octal
>> representation should indeed be avoided. People not familiar to C will
>> have a hard time understanding and getting used to this concept, and
>> in addition, it happens way too often that numeric data are provided
>> left-
>> padded with zeros.

I agree with this:  011 should be 11, it should not be 9.

>>> Proposal: we handle this ourselves and define what values are
>>> acceptable,
>>> namely for as.integer:
>>>
>>> [+|-][0-9]+
>>> NA
>>> 0[x|X][0-9A-fa-f]+
>>
>> It can be a somewhat mixed blessing if the string representation of
>> numeric
>> values contain information about their base, in the form of the 0x
>> prefix
>> in this case.
>>
>> The base argument (#3) of C's strtol function can be set to to a base
>> explicitly or to 0, which gives the prefix-based "auto-selection"
>> behaviour. On the R level, such a base argument (to as.integer) could be
>> included and a default could be set.
>
> A lot of this is internal, not at R level.
>
>> Personally, I would be equally happy with the default being 0
>> (auto-select)
>> or 10. Considering the perhaps limited spread of familiarity with C's
>> "0x" idiom, I somewhat favour a consistent and "stubborn" decimal
>> behaviour
>> (base defaults to 10), though.
>
> Some people already rely on it, and those who don't know about it are
> unliekly to ever enter what they think is an illegal value, surely?

As long as we document it, I think the 0x prefix is fine.

We should provide a way to use other bases on input and output.  This
could be through format specifiers, but it would be enough to have a pair
of dedicated functions to do the conversions.

Duncan Murdoch

From jari.oksanen at oulu.fi  Mon Apr 18 10:35:10 2005
From: jari.oksanen at oulu.fi (jari.oksanen@oulu.fi)
Date: Mon Apr 18 10:35:18 2005
Subject: [Rd] citation() chops "Roeland " (PR#7797)
Message-ID: <20050418083510.25A7AA1D8@slim.kubism.ku.dk>

Full_Name: Jari Oksanen
Version: 2.0.1, 2.1.0 beta (2005-04-17)
OS: Linux
Submission from: (NULL) (130.231.102.145)


If name ends with "and", such as "Roeland Lastname", citation() will chop "and"
as a separate word giving "Roel and Lastname". This is the case in the upcoming
release of vegan (1.6-8) just submitted to CRAN. Basically, this seems to happen
in utils:::as.personList.default

> unlist(as.personList("Roeland Lastname"))
 name.first name.middle   name.last  name.first name.middle   name.last
         ""          ""      "Roel"          ""          ""  "Lastname"

and the culprit line seems to be:

x <- unlist(strsplit(x, "[[:space:]]?(,|and)[[:space:]]+"))

Fortunately, persons like Anders Andtfolk and Mandalay Grandjean are not
chopped, because they don't have space after "and".

From maechler at stat.math.ethz.ch  Mon Apr 18 10:47:39 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Apr 18 10:47:57 2005
Subject: [Rd] ESS 5.2.7 released
Message-ID: <16995.29739.56260.570019@stat.math.ethz.ch>

Dear ESS users,	    {BCC'ed to RPM and Debian maintainers of ESS}

We have now released ESS 5.2.7.  This is a bug fix release against 5.2.6
where - the new UTF-8 "support" gave problems for Xemacs, and
      - accidentally, 'auto-fill-mode' was activated for *.R buffers
with a few new features, see "New Features" below , notably some
extended Sweave supported, originally contributed by David Whiting.

I'm crossposting to R-devel just to make you aware that R 2.1.0,
bound to be released today, comes with UTF-8 (unicode) support and
that doesn't work correctly in ESS versions prior to 5.2.6.

Downloads from the ESS site http://ESS.R-project.org/ or
directly http://ess.r-project.org/downloads/ess/ as *.zip and
*.tar.gz files. Hopefully, *.deb and *.rpm will also be made
available in due time.

For the ESS core team,
Martin Maechler, ETH Zurich.

--------------- ANNOUNCE ------------------------------


ANNOUNCING ESS
**************

   The ESS Developers proudly announce the release of ESS

   5.2.7

   Emacs Speaks Statistics (ESS) provides an intelligent, consistent
interface between the user and the software.  ESS interfaces with
S-PLUS, R, SAS, BUGS and other statistical analysis packages under the
Unix, Microsoft Windows, and Apple Mac OS operating systems.  ESS is a
package for the GNU Emacs and XEmacs text editors whose features ESS
uses to streamline the creation and use of statistical software.  ESS
knows the syntax and grammar of statistical analysis packages and
provides consistent display and editing features based on that
knowledge.  ESS assists in interactive and batch execution of
statements written in these statistical analysis languages.

   ESS is freely available under the GNU General Public License (GPL).
Please read the file COPYING which comes with the distribution, for
more information about the license. For more detailed information,
please read the README files that come with ESS.

Getting the Latest Version
==========================

   The latest released version of ESS is always available on the web at:
ESS web page (http://ess.r-project.org) or StatLib
(http://lib.stat.cmu.edu/general/ESS/)

   The latest development version of ESS is available via
`https://svn.R-project.org/ESS/', the ESS Subversion repository.  If
you have a Subversion client (see `http://subversion.tigris.org/'), you
can download the sources using:
     % svn checkout https://svn.r-project.org/ESS/trunk PATH

which will put the ESS files into directory PATH.  Later, within that
directory, `svn update' will bring that directory up to date.
Windows-based tools such as TortoiseSVN are also available for
downloading the files.  Alternatively, you can browse the sources with a
web browser at: ESS SVN site (https://svn.r-project.org/ESS/trunk).
However, please use a subversion client instead to minimize the load
when retrieving.

   If you remove other versions of ESS from your emacs load-path, you
can then use the development version by adding the following to .emacs:

     (load "/path/to/ess-svn/lisp/ess-site.el")

   Note that https is required, and that the SSL certificate for the
Subversion server of the R project is

     Certificate information:
      - Hostname: svn.r-project.org
      - Valid: from Jul 16 08:10:01 2004 GMT until Jul 14 08:10:01 2014 GMT
      - Issuer: Department of Mathematics, ETH Zurich, Zurich, Switzerland, CH
      - Fingerprint: c9:5d:eb:f9:f2:56:d1:04:ba:44:61:f8:64:6b:d9:33:3f:93:6e:ad

(currently, there is no "trusted certificate").  You can accept this
certificate permanently and will not be asked about it anymore.

Current Features
================

   * Languages Supported:
        * S family (S 3/4, S-PLUS 3.x/4.x/5.x/6.x/7.x, and R)

        * SAS

        * BUGS

        * Stata

        * XLispStat including Arc and ViSta

   * Editing source code (S family, SAS, BUGS, XLispStat)
        * Syntactic indentation and highlighting of source code

        * Partial evaluation of code

        * Loading and error-checking of code

        * Source code revision maintenance

        * Batch execution (SAS, BUGS)

        * Use of imenu to provide links to appropriate functions

   * Interacting with the process (S family, SAS, XLispStat)
        * Command-line editing

        * Searchable Command history

        * Command-line completion of S family object names and file
          names

        * Quick access to object lists and search lists

        * Transcript recording

        * Interface to the help system

   * Transcript manipulation (S family, XLispStat)
        * Recording and saving transcript files

        * Manipulating and editing saved transcripts

        * Re-evaluating commands from transcript files

   * Help File Editing (R)
        * Syntactic indentation and highlighting of source code.

        * Sending Examples to running ESS process.

        * Previewing

Requirements
============

   ESS has been tested with

   * S-PLUS 3.3-4, 4.5, 2000, 5.0-1, 6.0-2, 7.0

   * R >=0.49

   * S4

   * SAS >=6.12

   * BUGS 0.5, 0.603

   * Stata >=6.0

   * XLispStat >=3.50

   on the following platforms

   * Linux (all)

   * Solaris/SunOS (all)

   * Microsoft Windows 95/98/NT/2000/XP (SPLUS 4.5/2000/6.*, R, SAS and
     BUGS)

   * Apple Mac OS (SAS for OS 9 and R for OS X)

   with the following versions of emacs

   * GNU Emacs 20.3-7, 21.1, 21.3, 21.4

   * XEmacs 21.0, 21.1.13-14, 21.4.0-8, 21.4.9-13(1), 21.4.14-15,
     21.4.17, 21.5.18

   ---------- Footnotes ----------

   (1) require the files.el patch to revert-buffer for the Local
Variables updating problem

Stability
=========

   Versions 5.2.x are meant to be release-quality versions.  While some
new features are being introduced, we are cleaning up and improving the
interface.  We know about some remaining documentation inconsistencies.
Patches or suggested fixes with bug reports are much appreciated!

Mailing List
============

   There is a mailing list for discussions and announcements relating to
ESS.  Join the list by sending an e-mail with "subscribe ess-help" (or
"help") in the body to <ess-help-request@stat.math.ethz.ch>;
contributions to the list may be mailed to
<ess-help@stat.math.ethz.ch>.  Rest assured, this is a fairly
low-volume mailing list.

   The purposes of the mailing list include

   *  helping users of ESS to get along with it.

   *  discussing aspects of using ESS on Emacs and XEmacs.

   *  suggestions for improvements.

   *  announcements of new releases of ESS.

   *  posting small patches to ESS.

Reporting Bugs
==============

   Please send bug reports, suggestions etc. to

   <ESS-bugs@stat.math.ethz.ch>

   The easiest way to do this is within Emacs by typing

   `M-x ess-submit-bug-report'

   This also gives the maintainers valuable information about your
installation which may help us to identify or even fix the bug.

   If Emacs reports an error, backtraces can help us debug the problem.
Type "M-x set-variable RET debug-on-error RET t RET".  Then run the
command that causes the error and you should see a *Backtrace* buffer
containing debug information; send us that buffer.

   Note that comments, suggestions, words of praise and large cash
donations are also more than welcome.

Authors
=======

   * A.J. Rossini (mailto:blindglobe@gmail.com)

   * Richard M. Heiberger (mailto:rmh@temple.edu)

   * Kurt Hornik (mailto:Kurt.Hornik@R-project.org)

   * Martin Maechler (mailto:maechler@stat.math.ethz.ch)

   * Rodney A. Sparapani (mailto:rsparapa@mcw.edu)

   * Stephen Eglen (mailto:stephen@gnu.org)

License
=======

   ESS is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free
Software Foundation; either version 2, or (at your option) any later
version.

   ESS is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
in the file COPYING in the same directory as this file for more details.

New Features
============

   Changes/New Features in 5.2.7:
   * If you use Custom to change the variable ess-toolbar-items, the
     new toolbar is used in all subsequent ESS buffers.

   * ESS[SAS]: new feature:  if ess-sas-log-max >0 and your .log grows
     to more than ess-sas-log-max bytes, just the first ess-sas-log-max
     bytes are refreshed; this is helpful when your .sas program
     generates lots of error messages and gets too big for emacs to
     display

   * ESS[R/S]: `M-;' in R/S editing modes will now indent with either
     one or two hashes depending on context.

   * ESS[R]: David Whiting's Sweave extensions (to 'noweb') are now
     available (from ess-swv.el loaded by default).

   Changes/New Features in 5.2.6:
   * Removed non-ASCII characters in a few files.

   * ESS[R]: now works better when UTF-8 locale is active; in
     particular, you get correct directional quotes in R's startup
     message  for R-devel (unstable development version of R 2.1.0)
     when using  environment variables LANGUAGE=en@quot
     LC_ALL=en_US.UTF-8

   * ESS[SAS]: toggling of .log mode improved (`F10'); toggling of .lst
     mode now also available (`C-F10'); killing all buffers associated
     with .sas program no longer bound to `C-F10' since its a bit
     overzealous; EXPERIMENTAL new feature:  if your .log grows to more
     than 2.5MB, just the first 2.5MB are refreshed; this is helpful
     when your .sas program generates lots of error messages and gets
     too big for emacs to display; the truncation size is controlled by
     the variable ess-sas-log-max and defaults to 2500000.

   * S-Plus 7 for Windows is now recognized.

   * ESS[S] (incl. R): in auto-fill mode, strings are not wrapped
     anymore.

   * ESS[S] (incl. R): font-lock now correctly differs between R and S,
     e.g., for "_"; both now fontify warning(.) and S does terminate()
     additionally.

   * Support for `bell' aka `beep' aka `ding' aka `alarm' in all
     inferior modes: When \a is output "to the the console" at the
     beginning of a line, the bell is rung.

   Changes/New Features in 5.2.5:
   * ESS[R]: `C-c C-q' or `Quit S' from the menu now should work (again
     and less klunkily) and do not append `-exited' to the buffer name.
     Further, the behavior of `(ess-cleanup)', called from ess-quit,
     now depends on the new customizable variable
     `ess-S-quit-kill-buffers-p' which defaults to `nil'.
     Consequently, the question _"Delete all buffers associated with
     ..?"_ will not be asked anymore by default.

   * ESS[SAS] - ess-ebcdic-to-ascii-search-and-replace will now work
     with the `recode' application as well which is available on many
     platforms

   * ESS[S] (incl. R): Name completion for slots of S4 objects now
     works!

   Changes/New Features in 5.2.4:
   * The documentation now includes an overview of how to use the emacs
     TAGS facility for S functions.  (The distribution also used to
     contain a directory `etc/other/Tags' where a ~1990 version of
     `etags.c' was distributed; this is no longer relevant and so has
     been deleted.)

   * ESS[SAS] - When you are working with EBCDIC files on an ASCII
     platform, .log NOTEs may display as gibberish since the EBCDIC
     characters are not converted to ASCII prior to their display.  So,
     the function ess-ebcdic-to-ascii-search-and-replace is provided for
     convenience and is bound to `C-F11'.  This function requires the
     `dd' command (only available on unix or unix-like platforms).

   * ESS: Completion of object names is now always done dynamically
     rather than allowing the option of using a pre-computed database
     (by `ess-create-object-name-db') since modern computers seem fast
     enough for dynamic completion.  (We expect few users, if any, have
     been using the pre-computed database method.)

   * ESS: object completion in iESS buffers running on Windows was very
     slow (for GNU Emacs, but not XEmacs) and has now been fixed.
     Further, it was more or less broken for all versions of S-plus 6.x,
     and has been fixed to work everywhere but with the Windows' GUI of
     S-plus.  The list of objects now shows unique names also when an
     object appears more than once in the search path.

   * ESS[R]: Completion of object names now also includes those
     starting with ".".

   Changes/New Features in 5.2.3:
   * ESS: When new inferior ESS processes are created, by default they
     will replace the current buffer (this restores behavior from pre
     5.2.0). If you wish new ESS processes to start in another window
     of the current frame, set inferior-ess-same-window to nil.

   * New variables inferior-Splus-args and inferior-R-args provide a
     way to pass command line arguments to starting S and R processes.

   Changes/New Features in 5.2.2:
   * bug-fixes for 5.2.1 (require 'executable), html docs, etc.

   * ess-lisp-directory/../doc/info added to Info-directory-list if
     ess-info not found by info

   * ESS[R]: If you have other versions of R on your exec-path, such as
     "R-1.8.1" with Unix or "rw1081" with Windows, ESS will find them
     and create appropriate functions, such as `M-x R-1.8.1' or `M-x
     rw1081', for calling them.  By default only Unix programs
     beginning "R-1" and "R-2" and Windows programs parallel to the
     version of R in your exec-path will be found, but see
     ess-r-versions and ess-rterm-versions for ways to find other
     versions of R.

   * ESS[R]: Other versions of R, such as "R-1.8.1" on Unix and
     "rw1081" on Windows, are added to the "ESS / Start Process /
     Other" menu.

   * ESS[S]: If you have other versions of S-Plus on your Windows
     computer, such as S-Plus 6.1 or S-Plus 4.5, ESS will find them and
     create appropriate functions, such as `M-x splus61', for calling
     the console version (Sqpe) inside an emacs buffer.  By default only
     programs installed in the default location will be found, but see
     ess-SHOME-versions for ways to find other versions of S-Plus.

   * ESS[S]: Other versions of Sqpe on Windows, such as "splus61", are
     added to the "ESS / Start Process / Other" menu.

   * ESS[R]: (bug fix) ess-quit (bound to `C-c C-q') should now quit the
     inferior R process, when issued from either the inferior buffer,
     or from a .R buffer.

   Changes/New Features in 5.2.1:
   * ESS[S] (R and S-plus): now have toolbar support with icons to
     evaluate code in the inferior process or to switch there.  This
     code is experimental and likely to change as XEmacs/Emacs issues
     get resolved. The toolbar should be enabled if your Emacs displays
     images, but can be disabled with the variable ess-use-toolbar.
     Thanks to David Smith from Insightful for the S-plus logo.

   * ESS[SAS]: ess-sas-graph-view (`F12') enhanced; you can specify
     external file viewers for each graphics file type via the alist
     ess-sas-graph-view-viewer-alist; also .jpg/.gif are now handled by
     image-mode on XEmacs, if available, otherwise by graphics
     primitives as before

   ...........................

   [[ new features in older versions 
       ---> see the file ANNOUNCE in the ESS distribution ]]

   ...........................

From murdoch at stats.uwo.ca  Mon Apr 18 10:08:24 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon Apr 18 11:08:20 2005
Subject: [Rd] A 'true' R-wrapper for C++ classes
In-Reply-To: <BAY17-F25AAF617A04C82EF46FB7CD1290@phx.gbl>
References: <BAY17-F25AAF617A04C82EF46FB7CD1290@phx.gbl>
Message-ID: <40957.130.225.48.22.1113811704.squirrel@www.stats.uwo.ca>

> Hello
>
> I am trying to wrap some C++ classes into R.
>
> (1) Comparing the OOP and methods packages, I have came to this conclusion
> that OOP works much better for this wrapper -- please correct me if I am
> wrong.

The methods package using a different conceptual model of object-oriented
programming than C++ uses, one based on generic functions
rather than methods being defined within classes.  You should also look at
the R.oo package for another way to do what you want.

> One question is why this useful package (OOP) is not included in
> the
> official release of R?

There are a lot of useful packages that aren't in R.  They can't all be.

Another question is why OOP is not on CRAN.  This would be because its
author (John Chambers) thought Omegahat.org was a better place to put it
(assuming you're talking about that OOP).

The rest of your message contained a lot of repeated copies of the same
text.  I didn't read it all, so might have missed something new hidden in
there.

Duncan Murdoch

From p.dalgaard at biostat.ku.dk  Mon Apr 18 11:18:03 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Apr 18 11:20:16 2005
Subject: [Rd] citation() chops "Roeland " (PR#7797)
In-Reply-To: <20050418083510.25A7AA1D8@slim.kubism.ku.dk>
References: <20050418083510.25A7AA1D8@slim.kubism.ku.dk>
Message-ID: <x2fyxov3xw.fsf@biostat.ku.dk>

jari.oksanen@oulu.fi writes:

> Full_Name: Jari Oksanen
> Version: 2.0.1, 2.1.0 beta (2005-04-17)
> OS: Linux
> Submission from: (NULL) (130.231.102.145)
> 
> 
> If name ends with "and", such as "Roeland Lastname", citation() will chop "and"
> as a separate word giving "Roel and Lastname". This is the case in the upcoming
> release of vegan (1.6-8) just submitted to CRAN. Basically, this seems to happen
> in utils:::as.personList.default
> 
> > unlist(as.personList("Roeland Lastname"))
>  name.first name.middle   name.last  name.first name.middle   name.last
>          ""          ""      "Roel"          ""          ""  "Lastname"
> 
> and the culprit line seems to be:
> 
> x <- unlist(strsplit(x, "[[:space:]]?(,|and)[[:space:]]+"))
> 
> Fortunately, persons like Anders Andtfolk and Mandalay Grandjean are not
> chopped, because they don't have space after "and".

I'm sure it'll annoy Anders|George Sand, Bertrand Russell, Inge
Helland, et al., but it hardly counts as release-critical, nor trivial
enough to slip in during code freeze, especially as regular
expressions are involved (does one *ever* get them right on the first
try?)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From saveez at hotmail.com  Mon Apr 18 11:20:16 2005
From: saveez at hotmail.com (Ali -)
Date: Mon Apr 18 11:20:25 2005
Subject: [Rd] RE: A 'true' R-wrapper for C++ classes
Message-ID: <BAY17-F344E23FE86622C7C9FD4DBD1290@phx.gbl>

Sorry about the mistake in the previous post, here is the corrected version:

Hello

I am trying to wrap some C++ classes into R.

(1) Comparing the OOP and methods packages, I have came to this conclusion
that OOP works much better for this wrapper -- please correct me if I am
wrong. One question is why this useful package (OOP) is not included in the
official release of R?

(2) Choosing the OOP package way, I have carried out the following steps to
wrap the C++ classes:

  (2.1) A C-wrapper is created to convert the C++ class to some C-style
code.
  (2.2) An R-wrapper wraps the C-wrapper.

Here is a rough example to demonstrate the above:

---------------------
C++ class:

class foo
{
public:
  foo();
  ~foo();

  fun();
}

---------------------
C-wrapper:

extern "C" SEXP R_foo_init()
{
  foo* ptr= new foo();

  SEXP res;
  PROTECT(res = R_MakeExternalPtr(ptr, R_NilValue, R_NilValue));
  UNPROTECT(1);

  return res;
}

extern "C" SEXP R_foo_fun(SEXP obj)
{
  foo *ptr= (foo *) R_ExternalPtrAddr(obj);
  ptr->fun();

  return  R_NilValue;
}

---------------------
R-wrapper:

defineClass(className = "foo");

vtkObject$defineFields(ptr = "externalptr");

vtkObject$defineMethod(
	"initialize",
	function(){
		ptr <- .Call("R_foo_init")
	}
);

vtkObject$defineMethod(
    "fun",
    function()
    {
        .Call("R_foo_fun", ptr);
    }
);
--------------------

(3) The above model lacks something like an 'environment' for the pointer to
the C++ object to live in it. Assume we create the foo class in R like:

  obj <- foo$new()

Now, the following would return an error:

  obj$fun()

and the reason is that the pointer created in the initialize method is lost.

(4) The question is how to assign an environment to the pointers. A well
described answer, rather than some abstract hints, is well-appreciated. Also
I am curious to know why there is no standard method for R to wrap C++
classes, something like JNI.

Thanks,

Ali

From ripley at stats.ox.ac.uk  Mon Apr 18 11:20:57 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Apr 18 11:21:08 2005
Subject: [Rd] A 'true' R-wrapper for C++ classes
In-Reply-To: <BAY17-F25AAF617A04C82EF46FB7CD1290@phx.gbl>
References: <BAY17-F25AAF617A04C82EF46FB7CD1290@phx.gbl>
Message-ID: <Pine.LNX.4.61.0504181009160.17593@gannet.stats>

On Mon, 18 Apr 2005, Ali - wrote:

> I am trying to wrap some C++ classes into R.
>
> (1) Comparing the OOP and methods packages, I have came to this conclusion 
> that OOP works much better for this wrapper -- please correct me if I am 
> wrong. One question is why this useful package (OOP) is not included in the 
> official release of R?

Quick answer: almost nothing else makes use of it.  The `methods' package 
is depended on by 27 CRAN packages and most BioC packages.  The OOP 
package is not even on CRAN (although it once was as part of Omegahat).

The official release of R contains packages that are thought to be of high 
quality, actively maintained and useful to a wide range of R users.  And 
those are necessary conditions, not sufficient ones -- an at least 
historic criterion was to fill out coverage of the S Blue and White books
and the sort of statistics covered by MASS (the book).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Friedrich.Leisch at tuwien.ac.at  Mon Apr 18 11:30:00 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Mon Apr 18 11:30:12 2005
Subject: [Rd] citation() chops "Roeland " (PR#7797)
In-Reply-To: <x2fyxov3xw.fsf@biostat.ku.dk>
References: <20050418083510.25A7AA1D8@slim.kubism.ku.dk>
	<x2fyxov3xw.fsf@biostat.ku.dk>
Message-ID: <16995.32280.929214.598834@galadriel.ci.tuwien.ac.at>

>>>>> On 18 Apr 2005 11:18:03 +0200,
>>>>> Peter Dalgaard (PD) wrote:

  > jari.oksanen@oulu.fi writes:
  >> Full_Name: Jari Oksanen
  >> Version: 2.0.1, 2.1.0 beta (2005-04-17)
  >> OS: Linux
  >> Submission from: (NULL) (130.231.102.145)
  >> 
  >> 
  >> If name ends with "and", such as "Roeland Lastname", citation() will chop "and"
  >> as a separate word giving "Roel and Lastname". This is the case in the upcoming
  >> release of vegan (1.6-8) just submitted to CRAN. Basically, this seems to happen
  >> in utils:::as.personList.default
  >> 
  >> > unlist(as.personList("Roeland Lastname"))
  >> name.first name.middle   name.last  name.first name.middle   name.last
  >> ""          ""      "Roel"          ""          ""  "Lastname"
  >> 
  >> and the culprit line seems to be:
  >> 
  >> x <- unlist(strsplit(x, "[[:space:]]?(,|and)[[:space:]]+"))
  >> 
  >> Fortunately, persons like Anders Andtfolk and Mandalay Grandjean are not
  >> chopped, because they don't have space after "and".

  > I'm sure it'll annoy Anders|George Sand, Bertrand Russell, Inge
  > Helland, et al., but it hardly counts as release-critical, nor trivial
  > enough to slip in during code freeze, especially as regular
  > expressions are involved (does one *ever* get them right on the first
  > try?)

Certainly not release critical ... especially as the conversion
doesn't claim to work in all cases and is there only for convenience:

	person("Roeland", "Lastname")

does the right thing, so one can write a correct CITATION file.

unlist(strsplit(x, "[[:space:]]?(,|[[:space:]]and)[[:space:]]+"))


should do the trick, I'll put it into the patched branch after
release.

.f

From Friedrich.Leisch at tuwien.ac.at  Mon Apr 18 11:30:12 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Mon Apr 18 11:30:19 2005
Subject: [Rd] citation() chops "Roeland " (PR#7797)
Message-ID: <20050418093012.641F2A1EC@slim.kubism.ku.dk>

>>>>> On 18 Apr 2005 11:18:03 +0200,
>>>>> Peter Dalgaard (PD) wrote:

  > jari.oksanen@oulu.fi writes:
  >> Full_Name: Jari Oksanen
  >> Version: 2.0.1, 2.1.0 beta (2005-04-17)
  >> OS: Linux
  >> Submission from: (NULL) (130.231.102.145)
  >> 
  >> 
  >> If name ends with "and", such as "Roeland Lastname", citation() will chop "and"
  >> as a separate word giving "Roel and Lastname". This is the case in the upcoming
  >> release of vegan (1.6-8) just submitted to CRAN. Basically, this seems to happen
  >> in utils:::as.personList.default
  >> 
  >> > unlist(as.personList("Roeland Lastname"))
  >> name.first name.middle   name.last  name.first name.middle   name.last
  >> ""          ""      "Roel"          ""          ""  "Lastname"
  >> 
  >> and the culprit line seems to be:
  >> 
  >> x <- unlist(strsplit(x, "[[:space:]]?(,|and)[[:space:]]+"))
  >> 
  >> Fortunately, persons like Anders Andtfolk and Mandalay Grandjean are not
  >> chopped, because they don't have space after "and".

  > I'm sure it'll annoy Anders|George Sand, Bertrand Russell, Inge
  > Helland, et al., but it hardly counts as release-critical, nor trivial
  > enough to slip in during code freeze, especially as regular
  > expressions are involved (does one *ever* get them right on the first
  > try?)

Certainly not release critical ... especially as the conversion
doesn't claim to work in all cases and is there only for convenience:

	person("Roeland", "Lastname")

does the right thing, so one can write a correct CITATION file.

unlist(strsplit(x, "[[:space:]]?(,|[[:space:]]and)[[:space:]]+"))


should do the trick, I'll put it into the patched branch after
release.

.f

From murdoch at stats.uwo.ca  Mon Apr 18 11:02:41 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon Apr 18 12:02:35 2005
Subject: [Rd] RE: A 'true' R-wrapper for C++ classes
In-Reply-To: <BAY17-F344E23FE86622C7C9FD4DBD1290@phx.gbl>
References: <BAY17-F344E23FE86622C7C9FD4DBD1290@phx.gbl>
Message-ID: <41166.130.225.48.22.1113814961.squirrel@www.stats.uwo.ca>

> Sorry about the mistake in the previous post, here is the corrected
> version:

And I've just added responses to part of it:


> (3) The above model lacks something like an 'environment' for the pointer
> to
> the C++ object to live in it. Assume we create the foo class in R like:
>
>   obj <- foo$new()
>
> Now, the following would return an error:
>
>   obj$fun()
>
> and the reason is that the pointer created in the initialize method is
> lost.
>
> (4) The question is how to assign an environment to the pointers. A well
> described answer, rather than some abstract hints, is well-appreciated.

I think you'll have to ask the OOP author this one.  Generally R doesn't
have pointers, so when a package provides them, it needs to do a lot of
low level support for them.

> Also
> I am curious to know why there is no standard method for R to wrap C++
> classes, something like JNI.

I think it would be harder to write such a thing, in that R and C++ are
more different than Java and C++ are.

Duncan Murdoch

From maechler at stat.math.ethz.ch  Mon Apr 18 12:06:48 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Apr 18 12:06:57 2005
Subject: [Rd] RFC: hexadecimal constants and decimal points
In-Reply-To: <40932.130.225.48.22.1113809622.squirrel@www.stats.uwo.ca>
References: <Pine.LNX.4.61.0504171136210.13254@gannet.stats>
	<20050417135001.GA14537@jtkpc.cmp.uea.ac.uk>
	<Pine.LNX.4.61.0504171445040.15170@gannet.stats>
	<40932.130.225.48.22.1113809622.squirrel@www.stats.uwo.ca>
Message-ID: <16995.34488.148220.500383@stat.math.ethz.ch>

>>>>> "Duncan" == Duncan Murdoch <murdoch@stats.uwo.ca>
>>>>>     on Mon, 18 Apr 2005 03:33:42 -0400 (EDT) writes:

    >> On Sun, 17 Apr 2005, Jan T. Kim wrote:
    >> 
    >>> On Sun, Apr 17, 2005 at 12:38:10PM +0100, Prof Brian Ripley wrote:
    >>>> These are some points stimulated by reading about C history (and
    >>>> related in their implementation).
    >>>> 
    >>>> 
    >>>> 1) On some platforms
    >>>> 
    >>>>> as.integer("0xA")
    >>>> [1] 10
    >>>> 
    >>>> but not all (not on Solaris nor Windows).  We do not define what is
    >>>> allowed, and rely on the OS's implementation of strtod (yes, not
    >>>> strtol).
    >>>> It seems that glibc does allow hex: C99 mandates it but C89 seems not
    >>>> to
    >>>> allow it.
    >>>> 
    >>>> I think that was a mistake, and strtol should have been used.  Then C89
    >>>> does mandate the handling of hex constants and also octal ones.  So
    >>>> changing to strtol would change the meaning of as.integer("011").
    >>> 
    >>> I think interpretation of a leading "0" as a prefix indicating an octal
    >>> representation should indeed be avoided. People not familiar to C will
    >>> have a hard time understanding and getting used to this concept, and
    >>> in addition, it happens way too often that numeric data are provided
    >>> left-
    >>> padded with zeros.

    Duncan> I agree with this:  011 should be 11, it should not be 9.

I agree (with Duncan and Jan).

I'm sure the current (decimal) behavior is implicitly used in
many places of people's code that reads text files and
manipulates it.

Martin

From maechler at stat.math.ethz.ch  Mon Apr 18 12:24:44 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Apr 18 12:24:54 2005
Subject: [Rd] RFC: hexadecimal constants and decimal points
In-Reply-To: <Pine.LNX.4.61.0504171136210.13254@gannet.stats>
References: <Pine.LNX.4.61.0504171136210.13254@gannet.stats>
Message-ID: <16995.35564.89801.678206@stat.math.ethz.ch>

>>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
>>>>>     on Sun, 17 Apr 2005 12:38:10 +0100 (BST) writes:

    BDR> These are some points stimulated by reading about C history (and 
    BDR> related in their implementation).

    <.....>


    BDR> 2) R does not have integer constants.  It would be
    BDR> convenient if it did, and I can see no difficulty in
    BDR> allowing the same conversions when parsing as when
    BDR> coercing.  This would have the side effect that 100
    BDR> would be integer (but the coercion rules would come
    BDR> into play) but 200000000000000000 would be double.  And
    BDR> x <- 0xce80 would be valid.

Hmm, I'm not sure if this (parser change, mainly) is worth the
potential problems.  Of course you (Brian) know better than
anyone here that, when that change was implemented for S-plus, I think
Mathsoft (the predecessor of 'Insightful') did also change all
their legacy S code and translate all '<n>' to '<n>.'  just in
order to make sure that things stayed back compatible.  
And, IIRC, they recommended users to do so similarly with their
own S source files. I had found this extremely ugly at the time,
but it was mandated by the fact they didn't want to break
existing code which in some places did assume that e.g. '0' was
a double but became an integer in the new version of S-plus
{and e.g., as.double(.) became absolutely mandated before passing
 things to C  --- of course, using as.double(.) ``everywhere''
 before passing to C has been recommended for a long time which
 didn't prevent people to rely on the current behavior (in R) that
 almost all numbers are double}. 

We (or rather the less sophisticated members of the R community)
may get into similar problems when, e.g.,
matrix(0, 3,4)  suddenly produces an integer matrix instead of a
double precision one.


    BDR> 3) We do allow setting LC_NUMERIC, but it partially breaks R if the 
    BDR> decimal point is not ".".  (I know of no locale in which it is not "." or 
    BDR> ",", and we cannot allow "," as part of numeric constants when parsing.) 
    BDR> E.g.:

    >> Sys.setlocale("LC_NUMERIC", "fr_FR")
    BDR> [1] "fr_FR"
    BDR> Warning message:
    BDR> setting 'LC_NUMERIC' may cause R to function strangely in: 
    BDR> setlocale(category, locale)
    >> x <- 3.12
    >> x
    BDR> [1] 3
    >> as.numeric("3,12")
    BDR> [1] 3,12
    >> as.numeric("3.12")
    BDR> [1] NA
    BDR> Warning message:
    BDR> NAs introduced by coercion

    BDR> We could do better by insisting that "." was the decimal point in all 
    BDR> interval conversions _to_ numeric.  Then the effect of setting LC_NUMERIC 
    BDR> would primarily be on conversions _from_ numeric, especially printing and 
    BDR> graphical output.  (One issue would be what to do with scan(), which has a 
    BDR> `dec' argument but is implemented assuming LC_NUMERIC=C.  I would hope to 
    BDR> continue to have `dec' but perhaps with a locale-dependent default.)  The 
    BDR> resulting asymmetry (R would not be able to parse its own output) would be 
    BDR> unhappy, but seems inevitable. (This could be implemented easily by having 
    BDR> a `dec' arg to EncodeReal and EncodeComplex, and using LC_NUMERIC to 
    BDR> control that rather than actually setting the local category.  For 
    BDR> example, deparsing needs to be done in LC_NUMERIC=C.)

Yes, I like this quite a bit:

 -  Only allow "." as decimal point in conversions to numeric.

 -  Allowing "," (or other locale settings if there are) for
    conversions _from_ numeric will be very attractive to some
    (not to me) and will make the use of R's ``reporting
    facility' much more natural to them. 

  That the asymmetry is bit unhappy -- and that will be a good reason
  to advocate (to the user community) that using "," for decimal
  point may be a bad idea in general.

Martin Maechler
ETH Zurich

    BDR> All of these could be implemented by customized versions of 
    BDR> strtod/strtol.

    BDR> -- 
    BDR> Brian D. Ripley,                  ripley@stats.ox.ac.uk
    BDR> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
    BDR> University of Oxford,             Tel:  +44 1865 272861 (self)
    BDR> 1 South Parks Road,                     +44 1865 272866 (PA)
    BDR> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Mon Apr 18 15:14:43 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Apr 18 15:16:50 2005
Subject: [Rd] RFC: hexadecimal constants and decimal points
In-Reply-To: <16995.35564.89801.678206@stat.math.ethz.ch>
References: <Pine.LNX.4.61.0504171136210.13254@gannet.stats>
	<16995.35564.89801.678206@stat.math.ethz.ch>
Message-ID: <x2ll7gtef0.fsf@biostat.ku.dk>

Martin Maechler <maechler@stat.math.ethz.ch> writes:

>     BDR> We could do better by insisting that "." was the decimal
>     BDR> point in all interval conversions _to_ numeric. Then the
>     BDR> effect of setting LC_NUMERIC would primarily be on
>     BDR> conversions _from_ numeric, especially printing and
>     BDR> graphical output. (One issue would be what to do with
>     BDR> scan(), which has a `dec' argument but is implemented
>     BDR> assuming LC_NUMERIC=C. I would hope to continue to have
>     BDR> `dec' but perhaps with a locale-dependent default.) The
>     BDR> resulting asymmetry (R would not be able to parse its own
>     BDR> output) would be unhappy, but seems inevitable. (This could
>     BDR> be implemented easily by having a `dec' arg to EncodeReal
>     BDR> and EncodeComplex, and using LC_NUMERIC to control that
>     BDR> rather than actually setting the local category. For
>     BDR> example, deparsing needs to be done in LC_NUMERIC=C.)
> 
> Yes, I like this quite a bit:
> 
>  -  Only allow "." as decimal point in conversions to numeric.
> 
>  -  Allowing "," (or other locale settings if there are) for
>     conversions _from_ numeric will be very attractive to some
>     (not to me) and will make the use of R's ``reporting
>     facility' much more natural to them. 
> 
>   That the asymmetry is bit unhappy -- and that will be a good reason
>   to advocate (to the user community) that using "," for decimal
>   point may be a bad idea in general.

Could I suggest that we tread very carefully here? This issue has
caused several trip-ups historically:

- The locale-dependent "comma-separated variables" format, in some
  cases not separated by commas. And it seems that you can still get
  Excel files that use comma both for separation and as decimal point
  (I thought that problem disappeared with early versions of Paradox,
  but apparently not, according to a resent query on r-help).

- Exports from SAS as a text file cannot be read by SPSS and vice
  versa.

etc. Quite possibly, the "computer world" missed the opportunity to
agree on an international standard (what's the big deal with using
commas anyway?). As it is we probably have to adjust to it, but we
have to distinguish very carefully between reports, code, and data,
and choose appropriate conventions for each case.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From justin.bem at gmail.com  Mon Apr 18 16:33:17 2005
From: justin.bem at gmail.com (justin.bem@gmail.com)
Date: Mon Apr 18 16:33:25 2005
Subject: [Rd] Poblem while build a package (PR#7798)
Message-ID: <20050418143317.89B4FA1D8@slim.kubism.ku.dk>

Full_Name: Justin Bem
Version: 1.9.1
OS: Windows XP Home
Submission from: (NULL) (196.202.235.48)


I am a R new user !

I have writed procedure that i wantto transform as a package but with
RCMD build packageName [...]

I have 'sh' is not a recognized command in the dos promp I have Active Perl 5.8
!
Does I need to have another software or it is a Perl problem ?

I hope you will find a solution for me 

Salutations !

From murdoch at math.aau.dk  Mon Apr 18 17:07:58 2005
From: murdoch at math.aau.dk (Duncan Murdoch)
Date: Mon Apr 18 17:08:05 2005
Subject: [Rd] Poblem while build a package (PR#7798)
In-Reply-To: <20050418143317.89B4FA1D8@slim.kubism.ku.dk>
References: <20050418143317.89B4FA1D8@slim.kubism.ku.dk>
Message-ID: <4263CD4E.2060509@math.aau.dk>

justin.bem@gmail.com wrote:
> Full_Name: Justin Bem
> Version: 1.9.1
> OS: Windows XP Home
> Submission from: (NULL) (196.202.235.48)
> 
> 
> I am a R new user !
> 
> I have writed procedure that i wantto transform as a package but with
> RCMD build packageName [...]
> 
> I have 'sh' is not a recognized command in the dos promp I have Active Perl 5.8
> !
> Does I need to have another software or it is a Perl problem ?
> 
> I hope you will find a solution for me 

You are missing several tools.  Upgrade to R 2.1.0, it has a (hopefully) 
better description of the process in the R Installation and 
Administration manual.

Duncan Murdoch

From ripley at stats.ox.ac.uk  Mon Apr 18 19:07:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Apr 18 19:08:06 2005
Subject: [Rd] RFC: hexadecimal constants and decimal points
In-Reply-To: <x2ll7gtef0.fsf@biostat.ku.dk>
References: <Pine.LNX.4.61.0504171136210.13254@gannet.stats>
	<16995.35564.89801.678206@stat.math.ethz.ch>
	<x2ll7gtef0.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.61.0504181601560.26699@gannet.stats>

On Mon, 18 Apr 2005, Peter Dalgaard wrote:

> Martin Maechler <maechler@stat.math.ethz.ch> writes:
>
>>     BDR> We could do better by insisting that "." was the decimal
>>     BDR> point in all interval conversions _to_ numeric. Then the
>>     BDR> effect of setting LC_NUMERIC would primarily be on
>>     BDR> conversions _from_ numeric, especially printing and
>>     BDR> graphical output. (One issue would be what to do with
>>     BDR> scan(), which has a `dec' argument but is implemented
>>     BDR> assuming LC_NUMERIC=C. I would hope to continue to have
>>     BDR> `dec' but perhaps with a locale-dependent default.) The
>>     BDR> resulting asymmetry (R would not be able to parse its own
>>     BDR> output) would be unhappy, but seems inevitable. (This could
>>     BDR> be implemented easily by having a `dec' arg to EncodeReal
>>     BDR> and EncodeComplex, and using LC_NUMERIC to control that
>>     BDR> rather than actually setting the local category. For
>>     BDR> example, deparsing needs to be done in LC_NUMERIC=C.)
>>
>> Yes, I like this quite a bit:
>>
>>  -  Only allow "." as decimal point in conversions to numeric.
>>
>>  -  Allowing "," (or other locale settings if there are) for
>>     conversions _from_ numeric will be very attractive to some
>>     (not to me) and will make the use of R's ``reporting
>>     facility' much more natural to them.
>>
>>   That the asymmetry is bit unhappy -- and that will be a good reason
>>   to advocate (to the user community) that using "," for decimal
>>   point may be a bad idea in general.
>
> Could I suggest that we tread very carefully here? This issue has
> caused several trip-ups historically:
>
> - The locale-dependent "comma-separated variables" format, in some
>  cases not separated by commas. And it seems that you can still get
>  Excel files that use comma both for separation and as decimal point
>  (I thought that problem disappeared with early versions of Paradox,
>  but apparently not, according to a resent query on r-help).
>
> - Exports from SAS as a text file cannot be read by SPSS and vice
>  versa.
>
> etc. Quite possibly, the "computer world" missed the opportunity to
> agree on an international standard (what's the big deal with using
> commas anyway?). As it is we probably have to adjust to it, but we
> have to distinguish very carefully between reports, code, and data,
> and choose appropriate conventions for each case.

I was treading _very_ carefully.  Nowhere did I suggest altering any of
write.table and friends.  I did not even suggest altering read.table.
I tentatively suggested the default in scan() might be locale-specific,
but was otherwise leaving import/export completely alone.

The aim is to allow people to have commas in printed output and graph 
labels if they want.  Note, nothing would be done unless people explicitly 
did something like Sys.setlocale("LC_MISSING", "fr_FR") so this would not 
affect naive users in any way.

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From kwright at eskimo.com  Mon Apr 18 20:12:06 2005
From: kwright at eskimo.com (kwright@eskimo.com)
Date: Mon Apr 18 20:12:16 2005
Subject: [Rd] Why no BIC.default function?
Message-ID: <17905.170.54.59.167.1113847926.squirrel@170.54.59.167>


I'm using R 2.0.1.

I looked in the email archives but didn't see anything on this topic.

I've noticed a surprising (to me) difference between AIC and BIC:

> methods("AIC")
[1] AIC.default* AIC.logLik*

> methods("BIC")
[1] BIC.gls*    BIC.lm*     BIC.lme*    BIC.lmList* BIC.logLik* BIC.nls*

The BIC.gls BIC.lm BIC.lme BIC.lmList and BIC.nls functions appear to have
exactly the same definition.  (I didn't check with 'diff' though.)

Would it make sense to treat BIC similarly to AIC and have just
BIC.default and BIC.logLik?

Kevin Wright

From ripley at stats.ox.ac.uk  Mon Apr 18 20:30:36 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Apr 18 20:30:48 2005
Subject: [Rd] Why no BIC.default function?
In-Reply-To: <17905.170.54.59.167.1113847926.squirrel@170.54.59.167>
References: <17905.170.54.59.167.1113847926.squirrel@170.54.59.167>
Message-ID: <Pine.LNX.4.61.0504181925230.17897@gannet.stats>

R does not have a BIC S3 generic function: it is in package nlme!
(There is one for S4 classes in package stats4.)

So this is a question for the nlme maintainer.

On Mon, 18 Apr 2005 kwright@eskimo.com wrote:

>
> I'm using R 2.0.1.
>
> I looked in the email archives but didn't see anything on this topic.
>
> I've noticed a surprising (to me) difference between AIC and BIC:
>
>> methods("AIC")
> [1] AIC.default* AIC.logLik*
>
>> methods("BIC")
> [1] BIC.gls*    BIC.lm*     BIC.lme*    BIC.lmList* BIC.logLik* BIC.nls*
>
> The BIC.gls BIC.lm BIC.lme BIC.lmList and BIC.nls functions appear to have
> exactly the same definition.  (I didn't check with 'diff' though.)
>
> Would it make sense to treat BIC similarly to AIC and have just
> BIC.default and BIC.logLik?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From bates at stat.wisc.edu  Mon Apr 18 20:42:06 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon Apr 18 20:43:18 2005
Subject: [Rd] Why no BIC.default function?
In-Reply-To: <17905.170.54.59.167.1113847926.squirrel@170.54.59.167>
References: <17905.170.54.59.167.1113847926.squirrel@170.54.59.167>
Message-ID: <4263FF7E.9020909@stat.wisc.edu>

kwright@eskimo.com wrote:
> I'm using R 2.0.1.
> 
> I looked in the email archives but didn't see anything on this topic.
> 
> I've noticed a surprising (to me) difference between AIC and BIC:
> 
> 
>>methods("AIC")
> 
> [1] AIC.default* AIC.logLik*
> 
> 
>>methods("BIC")
> 
> [1] BIC.gls*    BIC.lm*     BIC.lme*    BIC.lmList* BIC.logLik* BIC.nls*
> 
> The BIC.gls BIC.lm BIC.lme BIC.lmList and BIC.nls functions appear to have
> exactly the same definition.  (I didn't check with 'diff' though.)
> 
> Would it make sense to treat BIC similarly to AIC and have just
> BIC.default and BIC.logLik?

Yes.  We will do so.

From kwright at eskimo.com  Mon Apr 18 20:55:24 2005
From: kwright at eskimo.com (kwright@eskimo.com)
Date: Mon Apr 18 20:55:35 2005
Subject: [Rd] Why no BIC.default function?
In-Reply-To: <Pine.LNX.4.61.0504181925230.17897@gannet.stats>
References: <17905.170.54.59.167.1113847926.squirrel@170.54.59.167>
	<Pine.LNX.4.61.0504181925230.17897@gannet.stats>
Message-ID: <31605.170.54.59.167.1113850524.squirrel@170.54.59.167>

> R does not have a BIC S3 generic function: it is in package nlme!
> (There is one for S4 classes in package stats4.)

Sorry, I should have noticed that.  Maybe my question should have been:

Since the stats package has generics for logLik and AIC, could it include
a generic for BIC?

Kevin Wright

>> I'm using R 2.0.1.
>>
>> I looked in the email archives but didn't see anything on this topic.
>>
>> I've noticed a surprising (to me) difference between AIC and BIC:
>>
>>> methods("AIC")
>> [1] AIC.default* AIC.logLik*
>>
>>> methods("BIC")
>> [1] BIC.gls*    BIC.lm*     BIC.lme*    BIC.lmList* BIC.logLik* BIC.nls*
>>
>> The BIC.gls BIC.lm BIC.lme BIC.lmList and BIC.nls functions appear to
>> have
>> exactly the same definition.  (I didn't check with 'diff' though.)
>>
>> Would it make sense to treat BIC similarly to AIC and have just
>> BIC.default and BIC.logLik?
>
> --
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

From jmc at R-project.org  Mon Apr 18 22:11:47 2005
From: jmc at R-project.org (John Chambers)
Date: Mon Apr 18 22:11:57 2005
Subject: [Rd] S4 extends a class, but .Data slot has different class
In-Reply-To: <OF21FD6ED6.14294508-ONC1256FE2.005A016A@abnamro.com>
References: <OF21FD6ED6.14294508-ONC1256FE2.005A016A@abnamro.com>
Message-ID: <42641483.3060901@R-project.org>

giles.heywood@uk.abnamro.com wrote:

> When I define an S4 class ("B" in the example below) that directly extends
> another ("A" in the example below) , which in turn directly extends another
> ("character" in the example below), I find that the slot does not have the
> class I specified in setClass(), it has the underlying class.
> 
> Is this an intended feature?

Well, it seems to be an implication of how classes work.

An object from an S4 class is implemented in R by slots (which are in 
fact attributes).  The .Data "slot", if there is one, is special that it 
is in fact the actual vector of data to which the real slots are 
attached.  This implementation makes many things back-compatible that 
would not be otherwise.

The .Data slot of class B is inherited in your example from the .Data 
slot of class A & therefore it has class "character" as illustrated.

writing

setClass("B",representation("A"))

does NOT say to make "A" the .Data slot of "B".  It says that "B" should 
inherit all the slots of "A".  The fact that extending a basic vector 
class DOES implicitly define the .Data slot is a somewhat special case.

In R, we would prefer for stylistic reasons to write the above as:

setClass("B", contains = "A")

This has the exact same effect, I think, but is perhaps clearer in 
saying that "B" should contain all the same slots as "A" (and therefore, 
should have a .Data slot of class "character").

> 
> Briefly, the reason for using this type of structure is to avoid the issue
> which I posted to this list before, where in 2.0.1 matrix no long 'is'
> array for the purposes of S4, and therefore an extract drop=TRUE can, in a
> special case, lead to an error.
> 
> Giles Heywood
> 
> - - - - -
> 
> Example:
> 
> 
>>setClass("A",representation("character"))
> 
> [1] "A"
> 
>>setClass("B",representation("A"))
> 
> [1] "B"
> 
>>getClass("B")
> 
> 
> Slots:
> 
> Name:      .Data
> Class: character
> 
> Extends:
> Class "A", directly
> Class "character", by class "A"
> Class "vector", by class "A"
> 
> 
>>is(new("B",new("A","abc"))@.Data,"A")
> 
> [1] FALSE
> 
> ---------------------------------------------------------------------------
> This message (including any attachments) is confidential and...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From Benjamin.Chan at inet.polyu.edu.hk  Tue Apr 19 10:47:29 2005
From: Benjamin.Chan at inet.polyu.edu.hk (Benjamin Chan [BRE])
Date: Tue Apr 19 10:47:54 2005
Subject: [Rd] chi-square test
Message-ID: <s265362c.026@inet.polyu.edu.hk>

 
a warning message appears when i use the chisq.test ,but it doesnt
appear everytime, why?
"Warning message: 
Chi-squared approximation may be incorrect in:
chisq.test(matrix(c(20.1, 18.5, 2.6, 32.9, 23.5, 5.4), nc = 2)) "
 
why does the warning message appear, please?
Thank you very much
here is the data which I have tried appear and not appear warning
message
 
have warning message
(1.3,4.9,12.6,10.5,5.5,6.5,4.7,9.8,10.3,23.2,7.3,6.6)
(13.8,8.4,8.7,10.4,25.5,28.7,2.5,5.1)
(20.1,18.5,2.6,32.9,23.5,5.4)
 
doesnt have warning message
(32.7,8.6,2561.5,2726.5)
(44.4,17.4,2561.5,2726.5)
(44.4,17.4,32.7,8.6)
(13.9,22.3,5.1,17.4,32.3,12)
(8.1,5.2,13.8,11.5,2.6,15.8,15.5,9.6,6.7,14.2)
(13.9,17.4,22.3,1740,2230,1390)

	[[alternative HTML version deleted]]

From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Apr 19 11:05:38 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue Apr 19 11:03:18 2005
Subject: [Rd] chi-square test
References: <s265362c.026@inet.polyu.edu.hk>
Message-ID: <015a01c544be$f43a65b0$0540210a@www.domain>

if you print "chisq.test()" you'll see when this warning message 
appears (i.e., if any expected count is less than 5, in which case it 
is known that the approximation to the Chi-squared distribution may 
not be adequate).

Alternatively, you could simulate to approximate the reference 
distribution of the statistic and obtain an estimation of the p-value 
using:

chisq.test(matrix(c(20.1, 18.5, 2.6, 32.9, 23.5, 5.4), nc = 2), 
simulate.p.value = TRUE)

I hope it helps.

Best,
Dimitris

p.s., you should send this message to r-help and not r-devel.

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm



----- Original Message ----- 
From: "Benjamin Chan [BRE]" <Benjamin.Chan@inet.polyu.edu.hk>
To: <r-devel@stat.math.ethz.ch>
Sent: Tuesday, April 19, 2005 10:47 AM
Subject: [Rd] chi-square test


>
> a warning message appears when i use the chisq.test ,but it doesnt
> appear everytime, why?
> "Warning message:
> Chi-squared approximation may be incorrect in:
> chisq.test(matrix(c(20.1, 18.5, 2.6, 32.9, 23.5, 5.4), nc = 2)) "
>
> why does the warning message appear, please?
> Thank you very much
> here is the data which I have tried appear and not appear warning
> message
>
> have warning message
> (1.3,4.9,12.6,10.5,5.5,6.5,4.7,9.8,10.3,23.2,7.3,6.6)
> (13.8,8.4,8.7,10.4,25.5,28.7,2.5,5.1)
> (20.1,18.5,2.6,32.9,23.5,5.4)
>
> doesnt have warning message
> (32.7,8.6,2561.5,2726.5)
> (44.4,17.4,2561.5,2726.5)
> (44.4,17.4,32.7,8.6)
> (13.9,22.3,5.1,17.4,32.3,12)
> (8.1,5.2,13.8,11.5,2.6,15.8,15.5,9.6,6.7,14.2)
> (13.9,17.4,22.3,1740,2230,1390)
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From hkawakat at qub.ac.uk  Tue Apr 19 13:50:16 2005
From: hkawakat at qub.ac.uk (Hiroyuki Kawakatsu)
Date: Tue Apr 19 13:50:28 2005
Subject: [Rd] building recommended packages on Windows
Message-ID: <Pine.CYG.4.58.0504191238250.2352@erdos>

Hi,

I am building 2.1.0 (re-release version, if that matters) on a Windows XP
machine. Following the instructions 3.1 "Building from source" in
R-admin.html, I managed to get up to 3.1.6. But when I try to build the
recommended packages, I get

C:\hiro\codes\proj\R-2.1.0\src\gnuwin32>make recommended
--- Unpacking recommended packages
---- VR
make[1]: *** No rule to make target `../library/boot/DESCRIPTION'.  Stop.
make: *** [unpack-recommended] Error 1

What did I do wrong? In /library/Recommended I do see boot_1.2-22.tar.gz
but I don't see the /boot subdirectory in /library. Thanks for any help,

h.
----------------------------------
Hiroyuki Kawakatsu
School of Management and Economics
25 University Square
Queen's University, Belfast
Belfast BT7 1NN
Northern Ireland
United Kingdom
Tel +44 (0)28 9097 3290
Fax +44 (0)28 9033 5156

From murdoch at math.aau.dk  Tue Apr 19 13:58:00 2005
From: murdoch at math.aau.dk (Duncan Murdoch)
Date: Tue Apr 19 13:58:09 2005
Subject: [Rd] building recommended packages on Windows
In-Reply-To: <Pine.CYG.4.58.0504191238250.2352@erdos>
References: <Pine.CYG.4.58.0504191238250.2352@erdos>
Message-ID: <4264F248.4070603@math.aau.dk>

Hiroyuki Kawakatsu wrote:
> Hi,
> 
> I am building 2.1.0 (re-release version, if that matters) on a Windows XP
> machine. Following the instructions 3.1 "Building from source" in
> R-admin.html, I managed to get up to 3.1.6. But when I try to build the
> recommended packages, I get
> 
> C:\hiro\codes\proj\R-2.1.0\src\gnuwin32>make recommended
> --- Unpacking recommended packages
> ---- VR
> make[1]: *** No rule to make target `../library/boot/DESCRIPTION'.  Stop.
> make: *** [unpack-recommended] Error 1
> 
> What did I do wrong? In /library/Recommended I do see boot_1.2-22.tar.gz
> but I don't see the /boot subdirectory in /library. Thanks for any help,

Did you put the tar.gz file in the right place?  It should be in 
src/library/Recommended, which is where "make rsync-recommended" should 
put it, not library/Recommended, which won't exist in a correct build.

Duncan Murdoch

From ligges at statistik.uni-dortmund.de  Tue Apr 19 13:59:09 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue Apr 19 13:58:50 2005
Subject: [Rd] building recommended packages on Windows
In-Reply-To: <Pine.CYG.4.58.0504191238250.2352@erdos>
References: <Pine.CYG.4.58.0504191238250.2352@erdos>
Message-ID: <4264F28D.3030905@statistik.uni-dortmund.de>

Hiroyuki Kawakatsu wrote:

> Hi,
> 
> I am building 2.1.0 (re-release version, if that matters) on a Windows XP
> machine. Following the instructions 3.1 "Building from source" in
> R-admin.html, I managed to get up to 3.1.6. But when I try to build the
> recommended packages, I get
> 
> C:\hiro\codes\proj\R-2.1.0\src\gnuwin32>make recommended
> --- Unpacking recommended packages
> ---- VR
> make[1]: *** No rule to make target `../library/boot/DESCRIPTION'.  Stop.
> make: *** [unpack-recommended] Error 1
> 
> What did I do wrong? In /library/Recommended I do see boot_1.2-22.tar.gz
> but I don't see the /boot subdirectory in /library. Thanks for any help,

Maybe you forgot to unpack with the correct tools?
   tar xfz R-2.1.0.tar.gz
should do the trick using tar from the tools provided un Duncan 
Murdoch's page, but many other (un)compress tools under Windows cannot 
deal with the links (e.g. boot.tgz) provided in the Recommended 
packages' subdirectory.

Uwe Ligges



> h.
> ----------------------------------
> Hiroyuki Kawakatsu
> School of Management and Economics
> 25 University Square
> Queen's University, Belfast
> Belfast BT7 1NN
> Northern Ireland
> United Kingdom
> Tel +44 (0)28 9097 3290
> Fax +44 (0)28 9033 5156
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Tue Apr 19 14:56:21 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Apr 19 14:56:37 2005
Subject: [Rd] Re: [R] pl/R and MacOS X using R binary
In-Reply-To: <5d1b06f985e233a1d5782f0d5a6de8ac@mail.nih.gov>
References: <5d1b06f985e233a1d5782f0d5a6de8ac@mail.nih.gov>
Message-ID: <Pine.LNX.4.61.0504191337320.23033@gannet.stats>

[Moved from R-help.]

On Tue, 19 Apr 2005, Sean Davis wrote:

> I'm sorry if this is too off-topic--feel free to ignore.  I am interested in 
> using pl/R, an amazing "plugin" for the postgresql database.  As is typical 
> of these types of applications, pl/R needs to link against a shared library. 
> However, it appears that the MacOS R binary does not build a static (.so) 
> shared library.

Excuse me, but a .so is a DSO, a Dynamic _Shared_ Object.  What does 
`static' have to do with this?  libR is a dynamic library, actually 
libR$(DYLIB_EXT) with values of .so. .sl and .dylib being known.

> Is there an accepted, general way (read, a way that works) 
> for linking against R (presumably the dylib) on the Mac?

Yes, since that is how the GUI on MacOS X works.

My guess is that you think that pl/R requires libR.so: if correct that is 
a false assumption made somewhere along the line, and the best thing to do 
is to consult the author.  In any case

http://www.joeconway.com/plr/doc/plr-install.html

just says

   Tip:  R headers are required. Download and install R prior to building
    PL/R. R must have been built with the --enable-R-shlib option when it
    was configured, in order for the libR shared object library to be available.


Please do consult the posting guide as to the right place.  (I've moved 
this to R-devel and included Joe Conway. Joe: perhaps you could make you 
email address more readily available in the PL/R pages.)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From sdavis2 at mail.nih.gov  Tue Apr 19 15:08:38 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue Apr 19 15:08:47 2005
Subject: [Rd] Re: [R] pl/R and MacOS X using R binary
In-Reply-To: <Pine.LNX.4.61.0504191337320.23033@gannet.stats>
References: <5d1b06f985e233a1d5782f0d5a6de8ac@mail.nih.gov>
	<Pine.LNX.4.61.0504191337320.23033@gannet.stats>
Message-ID: <9bd24be6404929de0ae99ce7a342717d@mail.nih.gov>


On Apr 19, 2005, at 8:56 AM, Prof Brian Ripley wrote:

> [Moved from R-help.]
>
> On Tue, 19 Apr 2005, Sean Davis wrote:
>
>> I'm sorry if this is too off-topic--feel free to ignore.  I am 
>> interested in using pl/R, an amazing "plugin" for the postgresql 
>> database.  As is typical of these types of applications, pl/R needs 
>> to link against a shared library. However, it appears that the MacOS 
>> R binary does not build a static (.so) shared library.
>
> Excuse me, but a .so is a DSO, a Dynamic _Shared_ Object.  What does 
> `static' have to do with this?  libR is a dynamic library, actually 
> libR$(DYLIB_EXT) with values of .so. .sl and .dylib being known.
>

My misunderstanding, you are correct in that assumption.  Your 
explanation helps a lot.

>> Is there an accepted, general way (read, a way that works) for 
>> linking against R (presumably the dylib) on the Mac?
>
> Yes, since that is how the GUI on MacOS X works.
>
> My guess is that you think that pl/R requires libR.so: if correct that 
> is a false assumption made somewhere along the line, and the best 
> thing to do is to consult the author.  In any case
>

This is again my misunderstanding.

> Please do consult the posting guide as to the right place.  (I've 
> moved this to R-devel and included Joe Conway. Joe: perhaps you could 
> make you email address more readily available in the PL/R pages.)
>

Actually, Joe has been quite helpful in this regard and the question 
has come up on his pl/R email list before, but without resolution, as 
far as I could tell (but again, I could be sadly mistaken).  I thought 
that posting to r-help (with the caveat that I was perhaps off-topic) 
would clarify things for me a bit.  It has done just that and I really 
appreciate your willingness to answer the off-topic post and move it to 
the appropriate forum.

Sean

From mail at joeconway.com  Tue Apr 19 16:40:21 2005
From: mail at joeconway.com (Joe Conway)
Date: Tue Apr 19 16:40:34 2005
Subject: [Rd] Re: [R] pl/R and MacOS X using R binary
In-Reply-To: <9bd24be6404929de0ae99ce7a342717d@mail.nih.gov>
References: <5d1b06f985e233a1d5782f0d5a6de8ac@mail.nih.gov>
	<Pine.LNX.4.61.0504191337320.23033@gannet.stats>
	<9bd24be6404929de0ae99ce7a342717d@mail.nih.gov>
Message-ID: <42651855.90409@joeconway.com>

Sean Davis wrote:
> 
> On Apr 19, 2005, at 8:56 AM, Prof Brian Ripley wrote:
>> Please do consult the posting guide as to the right place.  (I've 
>> moved this to R-devel and included Joe Conway. Joe: perhaps you could 
>> make you email address more readily available in the PL/R pages.)

Yes, I'll do that. Sorry for the confusion.

> Actually, Joe has been quite helpful in this regard and the question has 
> come up on his pl/R email list before, but without resolution, as far as 
> I could tell (but again, I could be sadly mistaken).  I thought that 
> posting to r-help (with the caveat that I was perhaps off-topic) would 
> clarify things for me a bit.  It has done just that and I really 
> appreciate your willingness to answer the off-topic post and move it to 
> the appropriate forum.

The Makefile for PL/R actually does attempt to use the dylib, and at one 
point (at least) worked according to a report that I received. There 
have been a couple of reported issues with MacOS X since then though. 
Part of my problem in resolving this has been lack of an OS X machine 
that I can debug on.

Joe

p.s. I apologize in advance for slow responses -- I just arrived 9 
timezones away from home at the start of a 2 week business trip.

From hkawakat at qub.ac.uk  Tue Apr 19 16:59:34 2005
From: hkawakat at qub.ac.uk (Hiroyuki Kawakatsu)
Date: Tue Apr 19 16:59:47 2005
Subject: [Rd] building recommended packages on Windows
In-Reply-To: <4264F28D.3030905@statistik.uni-dortmund.de>
References: <Pine.CYG.4.58.0504191238250.2352@erdos>
	<4264F28D.3030905@statistik.uni-dortmund.de>
Message-ID: <Pine.CYG.4.58.0504191552540.3792@erdos>

On Tue, 19 Apr 2005, Uwe Ligges wrote:

> Maybe you forgot to unpack with the correct tools?
>    tar xfz R-2.1.0.tar.gz
> should do the trick using tar from the tools provided un Duncan
> Murdoch's page, but many other (un)compress tools under Windows cannot
> deal with the links (e.g. boot.tgz) provided in the Recommended
> packages' subdirectory.

Arggggg. Uwe is of course right. Looking at the Recommended packages
directory, I did notice that some of the links had different icons from
the other link files. I must have unpacked it with cygwin, not with
Duncan's tools as instructed in R-admin. After redoing the unpacking,
everything went fine. Many thanks for spotting my stupidity,

h.
----------------------------------
Hiroyuki Kawakatsu
School of Management and Economics
25 University Square
Queen's University, Belfast
Belfast BT7 1NN
Northern Ireland
United Kingdom
Tel +44 (0)28 9097 3290
Fax +44 (0)28 9033 5156

From stefano.iacus at unimi.it  Tue Apr 19 17:16:38 2005
From: stefano.iacus at unimi.it (stefano iacus)
Date: Tue Apr 19 17:16:50 2005
Subject: [Rd] Re: [R] pl/R and MacOS X using R binary
In-Reply-To: <42651855.90409@joeconway.com>
References: <5d1b06f985e233a1d5782f0d5a6de8ac@mail.nih.gov>
	<Pine.LNX.4.61.0504191337320.23033@gannet.stats>
	<9bd24be6404929de0ae99ce7a342717d@mail.nih.gov>
	<42651855.90409@joeconway.com>
Message-ID: <0a655b9efafe7457e268fb41a23bf405@unimi.it>


On 19/apr/05, at 16:40, Joe Conway wrote:

> Sean Davis wrote:
>> On Apr 19, 2005, at 8:56 AM, Prof Brian Ripley wrote:
>>> Please do consult the posting guide as to the right place.  (I've 
>>> moved this to R-devel and included Joe Conway. Joe: perhaps you 
>>> could make you email address more readily available in the PL/R 
>>> pages.)
>
> Yes, I'll do that. Sorry for the confusion.
>
>> Actually, Joe has been quite helpful in this regard and the question 
>> has come up on his pl/R email list before, but without resolution, as 
>> far as I could tell (but again, I could be sadly mistaken).  I 
>> thought that posting to r-help (with the caveat that I was perhaps 
>> off-topic) would clarify things for me a bit.  It has done just that 
>> and I really appreciate your willingness to answer the off-topic post 
>> and move it to the appropriate forum.
>
> The Makefile for PL/R actually does attempt to use the dylib, and at 
> one point (at least) worked according to a report that I received. 
> There have been a couple of reported issues with MacOS X since then 
> though. Part of my problem in resolving this has been lack of an OS X 
> machine that I can debug on.

Joe, I can provide one login on one of my testing machines here and/or 
help for debugging.
stefano

>
> Joe
>
> p.s. I apologize in advance for slow responses -- I just arrived 9 
> timezones away from home at the start of a 2 week business trip.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From christophe.pouzat at univ-paris5.fr  Tue Apr 19 19:58:26 2005
From: christophe.pouzat at univ-paris5.fr (Christophe Pouzat)
Date: Tue Apr 19 19:56:32 2005
Subject: [Rd] R-2.1.0 compilation with Intel icc and ifort
Message-ID: <426546C2.1010609@univ-paris5.fr>

Guys,

I'm using a Linux PC (Pentium IV, Mandrake 10.1) and I've just tried to 
compile the new R-2.1.0 release with both gcc/g77 (3.4.1) and icc/ifort 
(8.1).
Of course everything went fine with the GNU compilers.
After checking the archives of the mailing list I tried compiling with 
the Intel compilers using the following options:

CFLAGS = '-O2 -mp -prec_div'
CXXFLAGS = '-O2 -mp -prec_div'
FFLAGS = '-C90 -w90 -w95 -mp -prec_div'
CPIPCFLAGS = -shared
CXXPIPCFLAGS = -shared
FPIPCFLAGS = -shared
SHLIB_LDFLAGS = -shared
SHLIB_CXXLDFLAGS = -shared
--with-blas = '-lmkl -lguide -lpthread'

The compilation went fine (just a few warnings). There was apparently a 
single problem when I ran "make check". It was in:

d-p-q-r-tests.R

at line 469:

All.eq(dpois(  10, 2e-308, log=TRUE), -7100.13502718914)

which returned -Inf with the Intel compiled version.

I don't think it's a big deal but I'd like to know if you have ideas 
and/or suggestions.

Thanks,

Christophe.

-- 
A Master Carpenter has many tools and is expert with most of them.If you
only know how to use a hammer, every problem starts to look like a nail.
Stay away from that trap.
Richard B Johnson.
--

Christophe Pouzat
Laboratoire de Physiologie Cerebrale
CNRS UMR 8118
UFR biomedicale de l'Universite Paris V
45, rue des Saints Peres
75006 PARIS
France

tel: +33 (0)1 42 86 38 28
fax: +33 (0)1 42 86 38 30
web: www.biomedicale.univ-paris5.fr/physcerv/C_Pouzat.html

From hutcha.s at psu.ac.th  Wed Apr 20 07:11:12 2005
From: hutcha.s at psu.ac.th (hutcha.s@psu.ac.th)
Date: Wed Apr 20 07:11:24 2005
Subject: [Rd] localeToCharset error for Thai locale (PR#7799)
Message-ID: <20050420051112.890C1A1DE@slim.kubism.ku.dk>

Full_Name: Hutcha Sriplung
Version: 2.1.0
OS: windows
Submission from: (NULL) (202.12.74.9)


In R-2.1.0, I found that 'example' function does not work properly and report an
error message as shown below on a Windows machine (running r-devel release) but
not on Linux.

> example(attach)
Error in switch(x[2], "1250" = return("ISO 8859-2"), "1251" = return("KOI8-U"), 
: argument is missing, with no default

I tracked the source codes and finally found minor mistakes with Thai language
management on Windows platform in 'localeToCharset' function.

file: /R-2.1.0/src/library/utils/iconv.R 
line: 50
if (en %in% "th") 	<<-- Should be "tg"-tajik???     
    return("KOI8-T")

"th" is for Thai (TIS-620; already defined on line 48-49).

line: 53-56
"874" = return("TIS 620")   <<-- Should be added???   
A default return should also be stated???

Note: 
> Sys.getlocale("LC_CTYPE")
[1] "Thai_Thailand.874"

'example' works fine on a Linux machine.

From ripley at stats.ox.ac.uk  Wed Apr 20 08:14:56 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Apr 20 08:15:07 2005
Subject: [Rd] localeToCharset error for Thai locale (PR#7799)
Message-ID: <20050420061456.A375AA1DE@slim.kubism.ku.dk>

Please try R-patched, where this is already fixed.

On Wed, 20 Apr 2005 hutcha.s@psu.ac.th wrote:

> Full_Name: Hutcha Sriplung
> Version: 2.1.0
> OS: windows
> Submission from: (NULL) (202.12.74.9)
>
>
> In R-2.1.0, I found that 'example' function does not work properly and report an
> error message as shown below on a Windows machine (running r-devel release) but
> not on Linux.
>
>> example(attach)
> Error in switch(x[2], "1250" = return("ISO 8859-2"), "1251" = return("KOI8-U"),
> : argument is missing, with no default
>
> I tracked the source codes and finally found minor mistakes with Thai language
> management on Windows platform in 'localeToCharset' function.
>
> file: /R-2.1.0/src/library/utils/iconv.R
> line: 50
> if (en %in% "th") 	<<-- Should be "tg"-tajik???
>    return("KOI8-T")
>
> "th" is for Thai (TIS-620; already defined on line 48-49).
>
> line: 53-56
> "874" = return("TIS 620")   <<-- Should be added???
> A default return should also be stated???
>
> Note:
>> Sys.getlocale("LC_CTYPE")
> [1] "Thai_Thailand.874"
>
> 'example' works fine on a Linux machine.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From j.m.harold at uea.ac.uk  Wed Apr 20 10:03:28 2005
From: j.m.harold at uea.ac.uk (Julie Harold)
Date: Wed Apr 20 10:03:38 2005
Subject: [Rd] Compiler flags for portland group compilers on opteron (64 bit)
Message-ID: <42660CD0.8060707@uea.ac.uk>

I need to compile R-2.0.1 on an opteron running suse9.1 and using 
portland group compilers.  Can you advise me of the environemt variables
I need to set, particulalry the FPICFLAGS.

Thanks,
Julie

---------------------------------------------------------------
Dr Julie Harold: University of East Anglia, Norwich, NR4 7TJ
       Environmental Sciences: Unix Support Officer
IT and Computing Service: High Performance Computing Consultant
                  phone 01603 59 2385/3121
                 email  j.m.harold@uea.ac.uk
       for env unix/linux support please mail envcs.unix@uea

From saveez at hotmail.com  Wed Apr 20 14:16:42 2005
From: saveez at hotmail.com (Ali -)
Date: Wed Apr 20 14:16:51 2005
Subject: [Rd] Overloading methods in R
Message-ID: <BAY17-F138DB205C684A882E69EF3D12B0@phx.gbl>

(1) It seems to me that, generally, in R it is not possible to overload 
functions. Is that right?

(2) Assuming that the above is true, or partially true, is there any extra 
packages to handle overloading in R?

(3) Assuming (1) is TRUE and (2) is FALSE, can anyone provide some advice on 
developing some function that understand what the arguments are and then 
calls the right overloaded function?

It would be something like this:

overloadedFunction1 <- function(x) {};

overloadedFunction2 <- function(x, y) {};

theFunction <- function(...)
{
   # How to identify ... and call the right overloaded function?
}

From sdavis2 at mail.nih.gov  Wed Apr 20 14:23:15 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed Apr 20 14:23:24 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F138DB205C684A882E69EF3D12B0@phx.gbl>
References: <BAY17-F138DB205C684A882E69EF3D12B0@phx.gbl>
Message-ID: <51e673cd8d2702cf963930629b2fa87d@mail.nih.gov>


On Apr 20, 2005, at 8:16 AM, Ali - wrote:

> (1) It seems to me that, generally, in R it is not possible to  
> overload functions. Is that right?
>
> (2) Assuming that the above is true, or partially true, is there any  
> extra packages to handle overloading in R?
>
> (3) Assuming (1) is TRUE and (2) is FALSE, can anyone provide some  
> advice on developing some function that understand what the arguments  
> are and then calls the right overloaded function?
>
> It would be something like this:
>
> overloadedFunction1 <- function(x) {};
>
> overloadedFunction2 <- function(x, y) {};
>
> theFunction <- function(...)
> {
>   # How to identify ... and call the right overloaded function?
> }
>

Ali,

You are probably interested in "methods".  Functions can have different  
"methods" depending on what the arguments and their types are.  A first  
place to look is:

http://cran.r-project.org/doc/manuals/R-exts.html#Generic-functions- 
and-methods

Sean

From conrad.halling at bifx.org  Wed Apr 20 16:42:05 2005
From: conrad.halling at bifx.org (Conrad Halling)
Date: Wed Apr 20 16:42:11 2005
Subject: [Rd] make check failure -- R 2.1.0 Windows XP SP2
Message-ID: <42666A3D.505@bifx.org>

I compiled R 2.1.0 under Windows XP SP2 as a preliminary to rebuilding a 
custom package for use with R 2.1.0. The compile completed successfully, 
and I was able to run demo(graphics) successfully. But make check and 
make check-recommended fail.

 > version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    1.0
year     2005
month    04
day      18
language R


I downloaded the R source code and the tools on Tuesday morning, 
19-Apr-2005. I carefully followed the directions in the 
R-2.1.0/doc/html/R-admin.html document and the directions at 
http://www.murdoch-sutherland.com/Rtools/. I used the Unix tools from 
http://www.murdoch-sutherland.com/Rtools/tools.zip and the MinGW 
compilers, MinGW-3.2.0-rc-3 (gcc 3.4.2) with the fixed f771.exe compiler 
from http://www.stats.ox.ac.uk/pub/RWin/gcc-3.4.2-fix/f771.exe.

Make check fails with the following error:


running code in 'd-p-q-r-tests.R' ...OK
  comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save' 
...386,387c386,387
<  [7,]  7 -1.279898e-12   -1.279813e-12     -27.384307       -27.384307
<  [8,]  8 -6.991040e-16   -6.220961e-16     -35.013437       -35.013437
---
 >  [7,]  7 -1.279865e-12   -1.279813e-12     -27.384307       -27.384307
 >  [8,]  8 -6.661338e-16   -6.220961e-16     -35.013437       -35.013437
932,940c932
< [1] "TRUE"
< [2] "TRUE"
< [3] "TRUE"
< [4] "TRUE"
< [5] "TRUE"
< [6] "TRUE"
< [7] "`is.NA' value mismatches: 1 in current, 0  in target"
< Warning message:
< NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
---
 > [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE
951c943
< [1] "Mean scaled  difference: 7.710642e-05"
---
 > [1] TRUE
make[3]: *** [d-p-q-r-tests.Rout] Error 1
make[2]: *** [test-Specific] Error 2
make[1]: *** [test-all-basics] Error 1
make: [test-Basic] Error 2 (ignored)



After building the recommended packages and then running make 
check-recommended, I got the following error:


C:\RTools\src\R-2.1.0\src\gnuwin32>make check-recommended
-------- Testing package boot --------
Massaging examples into 'boot-Ex.R' ...
Running examples in 'boot-Ex.R' ...
-------- Testing package cluster --------
Massaging examples into 'cluster-Ex.R' ...
Running examples in 'cluster-Ex.R' ...
Running specific tests
  Running `agnes-ex.R'
  Comparing `agnes-ex.Rout' to `agnes-ex.Rout.save' ...552c552
<  [9]   2.0000   9.0000   6.0000  32.1172  10.0000   8.0000  16.0000  
27.9063
---
 >  [9]   2.0000   9.0000   6.0000  32.1172  10.0000   8.0000  16.0000  
27.9062
554c554
< [25]   4.0000   5.5000   5.0000  22.3438   5.0000  12.5000  23.7813   
8.0000
---
 > [25]   4.0000   5.5000   5.0000  22.3438   5.0000  12.5000  23.7812   
8.0000
559c559
< [65]   5.0000  19.1250   2.0000   6.0000  10.5000   4.0000  15.0000  
41.5313
---
 > [65]   5.0000  19.1250   2.0000   6.0000  10.5000   4.0000  15.0000  
41.5312
OK
  Running `clara-NAs.R'
  Comparing `clara-NAs.Rout' to `clara-NAs.Rout.save' ...36,47c36,47
< 6  NaN NaN NaN NaN NaN
< 7   40  45  12  56  65 NaN
< 8    8  21  46  52  33 NaN  34
< 9   23  18  64  41  22 NaN  63  29
< 10  19  30  42  61  44 NaN  33  13  42
< 11 165 178 270 209 190 NaN 181 157 168 148
< 12 169 182 244 213 194 NaN 185 161 172 152  30
< 13 155 168 248 199 180 NaN 171 147 158 138  12  18
< 14 208 216 252 236 208 NaN 264 206 188 210  18   8   4
< 15 214 222 258 242 214 NaN 270 212 194 216  12  14  10   6
< 16 157 170 260 201 182 NaN 173 149 160 140   8  28  10   8   2
< 17 171 184 246 215 196 NaN 187 163 174 154  30   2  18   6  12  28
---
 > 6   NA  NA  NA  NA  NA
 > 7   40  45  12  56  65  NA
 > 8    8  21  46  52  33  NA  34
 > 9   23  18  64  41  22  NA  63  29
 > 10  19  30  42  61  44  NA  33  13  42
 > 11 165 178 270 209 190  NA 181 157 168 148
 > 12 169 182 244 213 194  NA 185 161 172 152  30
 > 13 155 168 248 199 180  NA 171 147 158 138  12  18
 > 14 208 216 252 236 208  NA 264 206 188 210  18   8   4
 > 15 214 222 258 242 214  NA 270 212 194 216  12  14  10   6
 > 16 157 170 260 201 182  NA 173 149 160 140   8  28  10   8   2
 > 17 171 184 246 215 196  NA 187 163 174 154  30   2  18   6  12  28
50c50
<    2.00   27.25  147.50  114.60  188.50  270.00   16.00
---
 >    2.00   27.25  147.50  114.50  188.50  270.00   16.00
OK
  Running `clara-ex.R'
  Running `clara.R'
  Comparing `clara.Rout' to `clara.Rout.save' ...OK
  Running `clusplot-out.R'
  Comparing `clusplot-out.Rout' to `clusplot-out.Rout.save' ...26,28c26,28
< [1,]   0.0000  NaN 166.9258
< [2,]      NaN    0      NaN
< [3,] 166.9258  NaN   0.0000
---
 > [1,]   0.0000   NA 166.9258
 > [2,]       NA    0       NA
 > [3,] 166.9258   NA   0.0000
35,38c35,38
< [1,]   0.0000  NaN 146.3222 291.3211
< [2,]      NaN    0      NaN      NaN
< [3,] 146.3222  NaN   0.0000      NaN
< [4,] 291.3211  NaN      NaN   0.0000
---
 > [1,]   0.0000   NA 146.3222 291.3211
 > [2,]       NA    0       NA       NA
 > [3,] 146.3222   NA   0.0000       NA
 > [4,] 291.3211   NA       NA   0.0000
62,63c62,63
< [2,] 1.433071 0.000000      NaN
< [3,] 2.851715      NaN 0.000000
---
 > [2,] 1.433071 0.000000       NA
 > [3,] 2.851715       NA 0.000000
71,73c71,73
< [2,] 2.241570 0.00000       NaN       NaN
< [3,] 1.634033     NaN 0.0000000 0.9461858
< [4,] 3.094589     NaN 0.9461858 0.0000000
---
 > [2,] 2.241570 0.00000        NA        NA
 > [3,] 1.634033      NA 0.0000000 0.9461858
 > [4,] 3.094589      NA 0.9461858 0.0000000
81,83c81,83
< [2,] 1.989916 0.0000000      NaN        NaN 0.94713417
< [3,] 1.552387       NaN 0.000000 1.17348334 2.22769309
< [4,] 3.115161       NaN 1.173483 0.00000000 0.04539385
---
 > [2,] 1.989916 0.0000000       NA         NA 0.94713417
 > [3,] 1.552387        NA 0.000000 1.17348334 2.22769309
 > [4,] 3.115161        NA 1.173483 0.00000000 0.04539385
OK
  Running `daisy-ex.R'
make[2]: *** [daisy-ex.Rout] Error 1
make[1]: *** [tests] Error 2
make: *** [pkgcheck-cluster] Error 2

-- 
Conrad Halling
conrad.halling@bifx.org

From saveez at hotmail.com  Wed Apr 20 16:50:50 2005
From: saveez at hotmail.com (Ali -)
Date: Wed Apr 20 16:50:58 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <51e673cd8d2702cf963930629b2fa87d@mail.nih.gov>
Message-ID: <BAY17-F35C3663390F61BA4A6BBBFD12B0@phx.gbl>

Sean,

Thanks, but, I am actually talking about overloading 'methods' and not 
'functions', or you may want to answer this question: How to overload 
methods in classes created by R.oo package?

>
>On Apr 20, 2005, at 8:16 AM, Ali - wrote:
>
>>(1) It seems to me that, generally, in R it is not possible to  overload 
>>functions. Is that right?
>>
>>(2) Assuming that the above is true, or partially true, is there any  
>>extra packages to handle overloading in R?
>>
>>(3) Assuming (1) is TRUE and (2) is FALSE, can anyone provide some  advice 
>>on developing some function that understand what the arguments  are and 
>>then calls the right overloaded function?
>>
>>It would be something like this:
>>
>>overloadedFunction1 <- function(x) {};
>>
>>overloadedFunction2 <- function(x, y) {};
>>
>>theFunction <- function(...)
>>{
>>   # How to identify ... and call the right overloaded function?
>>}
>>
>
>Ali,
>
>You are probably interested in "methods".  Functions can have different  
>"methods" depending on what the arguments and their types are.  A first  
>place to look is:
>
>http://cran.r-project.org/doc/manuals/R-exts.html#Generic-functions- 
>and-methods
>
>Sean
>

From ripley at stats.ox.ac.uk  Wed Apr 20 16:55:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Apr 20 16:55:47 2005
Subject: [Rd] make check failure -- R 2.1.0 Windows XP SP2
In-Reply-To: <42666A3D.505@bifx.org>
References: <42666A3D.505@bifx.org>
Message-ID: <Pine.LNX.4.61.0504201554270.32678@gannet.stats>

Please read the comments: that is a random test and fails about 1 in 50.

On Wed, 20 Apr 2005, Conrad Halling wrote:

> I compiled R 2.1.0 under Windows XP SP2 as a preliminary to rebuilding a 
> custom package for use with R 2.1.0. The compile completed successfully, and 
> I was able to run demo(graphics) successfully. But make check and make 
> check-recommended fail.
>
>> version
>        _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    1.0
> year     2005
> month    04
> day      18
> language R
>
>
> I downloaded the R source code and the tools on Tuesday morning, 19-Apr-2005. 
> I carefully followed the directions in the R-2.1.0/doc/html/R-admin.html 
> document and the directions at http://www.murdoch-sutherland.com/Rtools/. I 
> used the Unix tools from http://www.murdoch-sutherland.com/Rtools/tools.zip 
> and the MinGW compilers, MinGW-3.2.0-rc-3 (gcc 3.4.2) with the fixed f771.exe 
> compiler from http://www.stats.ox.ac.uk/pub/RWin/gcc-3.4.2-fix/f771.exe.
>
> Make check fails with the following error:
>
>
> running code in 'd-p-q-r-tests.R' ...OK
> comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save' 
> ...386,387c386,387
> <  [7,]  7 -1.279898e-12   -1.279813e-12     -27.384307       -27.384307
> <  [8,]  8 -6.991040e-16   -6.220961e-16     -35.013437       -35.013437
> ---
>>  [7,]  7 -1.279865e-12   -1.279813e-12     -27.384307       -27.384307
>>  [8,]  8 -6.661338e-16   -6.220961e-16     -35.013437       -35.013437
> 932,940c932
> < [1] "TRUE"
> < [2] "TRUE"
> < [3] "TRUE"
> < [4] "TRUE"
> < [5] "TRUE"
> < [6] "TRUE"
> < [7] "`is.NA' value mismatches: 1 in current, 0  in target"
> < Warning message:
> < NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> ---
>> [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE
> 951c943
> < [1] "Mean scaled  difference: 7.710642e-05"
> ---
>> [1] TRUE
> make[3]: *** [d-p-q-r-tests.Rout] Error 1
> make[2]: *** [test-Specific] Error 2
> make[1]: *** [test-all-basics] Error 1
> make: [test-Basic] Error 2 (ignored)
>
>
>
> After building the recommended packages and then running make 
> check-recommended, I got the following error:
>
>
> C:\RTools\src\R-2.1.0\src\gnuwin32>make check-recommended
> -------- Testing package boot --------
> Massaging examples into 'boot-Ex.R' ...
> Running examples in 'boot-Ex.R' ...
> -------- Testing package cluster --------
> Massaging examples into 'cluster-Ex.R' ...
> Running examples in 'cluster-Ex.R' ...
> Running specific tests
> Running `agnes-ex.R'
> Comparing `agnes-ex.Rout' to `agnes-ex.Rout.save' ...552c552
> <  [9]   2.0000   9.0000   6.0000  32.1172  10.0000   8.0000  16.0000 
> 27.9063
> ---
>>  [9]   2.0000   9.0000   6.0000  32.1172  10.0000   8.0000  16.0000 
> 27.9062
> 554c554
> < [25]   4.0000   5.5000   5.0000  22.3438   5.0000  12.5000  23.7813 
> 8.0000
> ---
>> [25]   4.0000   5.5000   5.0000  22.3438   5.0000  12.5000  23.7812 
> 8.0000
> 559c559
> < [65]   5.0000  19.1250   2.0000   6.0000  10.5000   4.0000  15.0000 
> 41.5313
> ---
>> [65]   5.0000  19.1250   2.0000   6.0000  10.5000   4.0000  15.0000 
> 41.5312
> OK
> Running `clara-NAs.R'
> Comparing `clara-NAs.Rout' to `clara-NAs.Rout.save' ...36,47c36,47
> < 6  NaN NaN NaN NaN NaN
> < 7   40  45  12  56  65 NaN
> < 8    8  21  46  52  33 NaN  34
> < 9   23  18  64  41  22 NaN  63  29
> < 10  19  30  42  61  44 NaN  33  13  42
> < 11 165 178 270 209 190 NaN 181 157 168 148
> < 12 169 182 244 213 194 NaN 185 161 172 152  30
> < 13 155 168 248 199 180 NaN 171 147 158 138  12  18
> < 14 208 216 252 236 208 NaN 264 206 188 210  18   8   4
> < 15 214 222 258 242 214 NaN 270 212 194 216  12  14  10   6
> < 16 157 170 260 201 182 NaN 173 149 160 140   8  28  10   8   2
> < 17 171 184 246 215 196 NaN 187 163 174 154  30   2  18   6  12  28
> ---
>> 6   NA  NA  NA  NA  NA
>> 7   40  45  12  56  65  NA
>> 8    8  21  46  52  33  NA  34
>> 9   23  18  64  41  22  NA  63  29
>> 10  19  30  42  61  44  NA  33  13  42
>> 11 165 178 270 209 190  NA 181 157 168 148
>> 12 169 182 244 213 194  NA 185 161 172 152  30
>> 13 155 168 248 199 180  NA 171 147 158 138  12  18
>> 14 208 216 252 236 208  NA 264 206 188 210  18   8   4
>> 15 214 222 258 242 214  NA 270 212 194 216  12  14  10   6
>> 16 157 170 260 201 182  NA 173 149 160 140   8  28  10   8   2
>> 17 171 184 246 215 196  NA 187 163 174 154  30   2  18   6  12  28
> 50c50
> <    2.00   27.25  147.50  114.60  188.50  270.00   16.00
> ---
>>    2.00   27.25  147.50  114.50  188.50  270.00   16.00
> OK
> Running `clara-ex.R'
> Running `clara.R'
> Comparing `clara.Rout' to `clara.Rout.save' ...OK
> Running `clusplot-out.R'
> Comparing `clusplot-out.Rout' to `clusplot-out.Rout.save' ...26,28c26,28
> < [1,]   0.0000  NaN 166.9258
> < [2,]      NaN    0      NaN
> < [3,] 166.9258  NaN   0.0000
> ---
>> [1,]   0.0000   NA 166.9258
>> [2,]       NA    0       NA
>> [3,] 166.9258   NA   0.0000
> 35,38c35,38
> < [1,]   0.0000  NaN 146.3222 291.3211
> < [2,]      NaN    0      NaN      NaN
> < [3,] 146.3222  NaN   0.0000      NaN
> < [4,] 291.3211  NaN      NaN   0.0000
> ---
>> [1,]   0.0000   NA 146.3222 291.3211
>> [2,]       NA    0       NA       NA
>> [3,] 146.3222   NA   0.0000       NA
>> [4,] 291.3211   NA       NA   0.0000
> 62,63c62,63
> < [2,] 1.433071 0.000000      NaN
> < [3,] 2.851715      NaN 0.000000
> ---
>> [2,] 1.433071 0.000000       NA
>> [3,] 2.851715       NA 0.000000
> 71,73c71,73
> < [2,] 2.241570 0.00000       NaN       NaN
> < [3,] 1.634033     NaN 0.0000000 0.9461858
> < [4,] 3.094589     NaN 0.9461858 0.0000000
> ---
>> [2,] 2.241570 0.00000        NA        NA
>> [3,] 1.634033      NA 0.0000000 0.9461858
>> [4,] 3.094589      NA 0.9461858 0.0000000
> 81,83c81,83
> < [2,] 1.989916 0.0000000      NaN        NaN 0.94713417
> < [3,] 1.552387       NaN 0.000000 1.17348334 2.22769309
> < [4,] 3.115161       NaN 1.173483 0.00000000 0.04539385
> ---
>> [2,] 1.989916 0.0000000       NA         NA 0.94713417
>> [3,] 1.552387        NA 0.000000 1.17348334 2.22769309
>> [4,] 3.115161        NA 1.173483 0.00000000 0.04539385
> OK
> Running `daisy-ex.R'
> make[2]: *** [daisy-ex.Rout] Error 1
> make[1]: *** [tests] Error 2
> make: *** [pkgcheck-cluster] Error 2
>
> -- 
> Conrad Halling
> conrad.halling@bifx.org
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From tplate at acm.org  Wed Apr 20 17:27:33 2005
From: tplate at acm.org (Tony Plate)
Date: Wed Apr 20 17:27:50 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F138DB205C684A882E69EF3D12B0@phx.gbl>
References: <BAY17-F138DB205C684A882E69EF3D12B0@phx.gbl>
Message-ID: <426674E5.8030705@acm.org>

If I understand what you are looking for, I believe your assumption (1) 
is FALSE, not TRUE as you suspected.

One thing to realize is that "methods" in R are very different to those 
in other common "object-oriented" languages such as C++, Java, or 
Python.  One difference is that methods are not intimately associated 
with a class definition -- the method dispatch system pulls disparate 
pieces of information together.  Another difference is that the choice 
of which method to invoke can depend on all arguments, not just the first.

Yet another thing to realize is that R has two class systems (commonly 
known as something like "S3" and "S4" methods and classes).  Each has 
its own way of defining classes, generic functions and methods.  The S4 
class system offers more control over which method is called.  Consult 
the "Green Book" for details of the S4 system.  (See the FAQ for full 
details of the "Green Book").

Here's an example of something like what you are asking for, using the 
S4 class system.  Note that this example doesn't involve the definition 
of any classes, just a generic and methods for some standard classes. 
Also note that a generic and its methods should have the same argument 
names.

 > setGeneric("foo", function(x,y) standardGeneric("foo"))
[1] "foo"
 > setMethod("foo", c("ANY", "missing"),
+     function(x,y) "x:any y:missing")
[1] "foo"
 > setMethod("foo", c("numeric", "numeric"),
+     function(x,y) "x:numeric y:numeric")
[1] "foo"
 > setMethod("foo", c("missing", "numeric"),
+     function(x,y) "x:missing y:numeric")
[1] "foo"
 > foo(1,2)
[1] "x:numeric y:numeric"
 > foo(1)
[1] "x:any y:missing"
 > foo(y=2)
[1] "x:missing y:numeric"
 > foo(y="bar")
Error in foo(y = "bar") : no direct or inherited method for function 
'foo' for this call
 >

(You can execute the above commands under Windows by copying the entire 
transcript to the clipboard, and then using the "Paste commands only" 
menu item under the "Edit" menu in the "R console" window.)

hope this helps to at least get you started,

Tony Plate

Ali - wrote:
> (1) It seems to me that, generally, in R it is not possible to overload 
> functions. Is that right?
> 
> (2) Assuming that the above is true, or partially true, is there any 
> extra packages to handle overloading in R?
> 
> (3) Assuming (1) is TRUE and (2) is FALSE, can anyone provide some 
> advice on developing some function that understand what the arguments 
> are and then calls the right overloaded function?
> 
> It would be something like this:
> 
> overloadedFunction1 <- function(x) {};
> 
> overloadedFunction2 <- function(x, y) {};
> 
> theFunction <- function(...)
> {
>   # How to identify ... and call the right overloaded function?
> }
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From saveez at hotmail.com  Wed Apr 20 17:45:09 2005
From: saveez at hotmail.com (Ali -)
Date: Wed Apr 20 17:45:19 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <426674E5.8030705@acm.org>
Message-ID: <BAY17-F3487AE8B0461A5BEC97D08D12B0@phx.gbl>

Thanks a lot Tony. I am trying to apply the overloading to the methods 
created by R.oo package and, unfortunately, R.oo uses S3-style classes; so I 
cannot use the features of S4 methods as you described. On the other hand, I 
caouldn't find a decent OO package which is based on S4 AND comes with the 
official release of R.

Assume we have this class created using R.oo:

-------------------------
require(R.oo)

setConstructorS3("SomeClass",
    function(...)
    {
        extend(Object(), "SomeClass");
    }
);

setMethodS3(
    "fun",
    "SomeClass",
    function(this, x, ...)
    {
        paste(x);
    }
);
-------------------------

Now if we overload the method by:

-------------------------
setMethodS3(
    "fun",
    "SomeClass",
    function(this, x, y, ...)
    {
        paste(x, y);
    }
);
-------------------------

then R.oo overwrites the method 'fun' with the new definition. As the 
overloaded methods share the same class, it is not possible to use the 
function overloading method as you described.

I hope there is some other way to handle this problem.



>One thing to realize is that "methods" in R are very different to those in 
>other common "object-oriented" languages such as C++, Java, or Python.  One 
>difference is that methods are not intimately associated with a class 
>definition -- the method dispatch system pulls disparate pieces of 
>information together.  Another difference is that the choice of which 
>method to invoke can depend on all arguments, not just the first.
>
>Yet another thing to realize is that R has two class systems (commonly 
>known as something like "S3" and "S4" methods and classes).  Each has its 
>own way of defining classes, generic functions and methods.  The S4 class 
>system offers more control over which method is called.  Consult the "Green 
>Book" for details of the S4 system.  (See the FAQ for full details of the 
>"Green Book").
>
>Here's an example of something like what you are asking for, using the S4 
>class system.  Note that this example doesn't involve the definition of any 
>classes, just a generic and methods for some standard classes. Also note 
>that a generic and its methods should have the same argument names.
>
> > setGeneric("foo", function(x,y) standardGeneric("foo"))
>[1] "foo"
> > setMethod("foo", c("ANY", "missing"),
>+     function(x,y) "x:any y:missing")
>[1] "foo"
> > setMethod("foo", c("numeric", "numeric"),
>+     function(x,y) "x:numeric y:numeric")
>[1] "foo"
> > setMethod("foo", c("missing", "numeric"),
>+     function(x,y) "x:missing y:numeric")
>[1] "foo"
> > foo(1,2)
>[1] "x:numeric y:numeric"
> > foo(1)
>[1] "x:any y:missing"
> > foo(y=2)
>[1] "x:missing y:numeric"
> > foo(y="bar")
>Error in foo(y = "bar") : no direct or inherited method for function 'foo' 
>for this call
> >
>
>(You can execute the above commands under Windows by copying the entire 
>transcript to the clipboard, and then using the "Paste commands only" menu 
>item under the "Edit" menu in the "R console" window.)
>
>hope this helps to at least get you started,
>
>Tony Plate
>

From blindglobe at gmail.com  Wed Apr 20 18:20:51 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Wed Apr 20 18:21:01 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F35C3663390F61BA4A6BBBFD12B0@phx.gbl>
References: <51e673cd8d2702cf963930629b2fa87d@mail.nih.gov>
	<BAY17-F35C3663390F61BA4A6BBBFD12B0@phx.gbl>
Message-ID: <1abe3fa9050420092020ee934e@mail.gmail.com>

R.oo tries to implement an old-fashioned OO system as found in Java,
Python, C++, etc.  R's S4 methods implement a nice modern system based
on the generic function approach , dispatch on argument signatures,
which is different.

While the R documentation for S4 classes is quite useful (spanning the
green book, the BioC developer help pages,  V&R's book on programming,
and some other papers), I've found that for a nice background, Paul
Graham's ANSI Lisp book, and in particular the nicely written chapter
on CLOS, provides a nice introduction to the thought process.

With respect to the R.oo package, the author might be the best source for that.

Another package which you might take a look at is the proto package,
which provides prototype object-orientation similar to that found in
XLispStat, and also might help with what you are trying to do. 
However, I suspect that learning about the S4 system will provide more
benefit in the future.

best,
-tony

On 4/20/05, Ali - <saveez@hotmail.com> wrote:
> Sean,
> 
> Thanks, but, I am actually talking about overloading 'methods' and not
> 'functions', or you may want to answer this question: How to overload
> methods in classes created by R.oo package?
> 
> >
> >On Apr 20, 2005, at 8:16 AM, Ali - wrote:
> >
> >>(1) It seems to me that, generally, in R it is not possible to  overload
> >>functions. Is that right?
> >>
> >>(2) Assuming that the above is true, or partially true, is there any
> >>extra packages to handle overloading in R?
> >>
> >>(3) Assuming (1) is TRUE and (2) is FALSE, can anyone provide some  advice
> >>on developing some function that understand what the arguments  are and
> >>then calls the right overloaded function?
> >>
> >>It would be something like this:
> >>
> >>overloadedFunction1 <- function(x) {};
> >>
> >>overloadedFunction2 <- function(x, y) {};
> >>
> >>theFunction <- function(...)
> >>{
> >>   # How to identify ... and call the right overloaded function?
> >>}
> >>
> >
> >Ali,
> >
> >You are probably interested in "methods".  Functions can have different
> >"methods" depending on what the arguments and their types are.  A first
> >place to look is:
> >
> >http://cran.r-project.org/doc/manuals/R-exts.html#Generic-functions-
> >and-methods
> >
> >Sean
> >
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From thomas.friedrichsmeier at ruhr-uni-bochum.de  Wed Apr 20 18:34:33 2005
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Wed Apr 20 18:33:25 2005
Subject: [Rd] Embedded R and x11
Message-ID: <200504201834.33320.thomas.friedrichsmeier@ruhr-uni-bochum.de>

Hi,

I'm working on a frontend for R. I have R running in a separate thread in my 
application using Rf_initEmbeddedR, and I'm using R_tryEval to run commands 
in R (i.e. I don't run the mainloop).
Everything works fine, except the x11-device: I can open x11-windows and paint 
to them alright from R. However, the x11-window does not respond to any 
events. E.g. clicking the close-button simply does not close the window and 
the contents in the window do not get refreshed when it was hidden by other 
windows.
I figured that the reason for this might be, that R_ProcessEvents () and 
handleEvent () in devX11.c do not get called (of course I might be completely 
wrong?). So I tried calling R_ProcessEvents () manually, but I can't get that 
to link (unresolved symbol R_ProcessEvents).
Any hints on how I can get this to work?

Thanks
Thomas

From sfalcon at fhcrc.org  Wed Apr 20 19:10:20 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed Apr 20 19:10:25 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F3487AE8B0461A5BEC97D08D12B0@phx.gbl> (Ali's message of
	"Wed, 20 Apr 2005 15:45:09 +0000")
References: <BAY17-F3487AE8B0461A5BEC97D08D12B0@phx.gbl>
Message-ID: <m2sm1lcr2b.fsf@macaroni.local>

"Ali -" <saveez@hotmail.com> writes:
> On the other hand, I caouldn't find a decent OO package which is
> based on S4 AND comes with the official release of R.

The OO system that comes with R and is based on S4 *is* S4.  The
challenge is that it is a different way of doing OO as compared to
Java.  But for most uses, it works just fine once you get used to
"spelling" things differently.

+ seth

From thomas.friedrichsmeier at ruhr-uni-bochum.de  Wed Apr 20 19:12:58 2005
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Wed Apr 20 19:11:50 2005
Subject: [Rd] Re: Embedded R and x11
In-Reply-To: <200504201834.33320.thomas.friedrichsmeier@ruhr-uni-bochum.de>
References: <200504201834.33320.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <200504201912.58537.thomas.friedrichsmeier@ruhr-uni-bochum.de>

Hi again,

> I figured that the reason for this might be, that R_ProcessEvents () and
> handleEvent () in devX11.c do not get called (of course I might be
> completely wrong?). So I tried calling R_ProcessEvents () manually, but I
> can't get that to link (unresolved symbol R_ProcessEvents).
> Any hints on how I can get this to work?

ok, I figured it out. For the record, the following code (called periodically 
when there is nothing else to do) does the trick:

#include "R_ext/eventloop.h"

void processX11 () {
	extern InputHandler *R_InputHandlers;
	InputHandler *handler = R_InputHandlers;
	while (handler) {
		if (handler->activity == XActivity) {
			handler->handler ((void*) 0);
		}
		handler = handler->next;
	}
}

Thomas

From john.marsland at wmgfunds.com  Wed Apr 20 19:33:03 2005
From: john.marsland at wmgfunds.com (John Marsland)
Date: Wed Apr 20 19:33:14 2005
Subject: [Rd] callNextMethod()
Message-ID: <b12b2f098c76bde2b021461f40ed2e54@wmgfunds.com>

I have built a sequence of eight S4 classes, each of which inherits 
from the previous one but adds extra slots.

I have a corresponding generic function for which I have described 
methods for each of these classes in a signature with one other 
variable. There are also some ad hoc variable outside the signature 
which have different default values for each class.

Each method calls callNextMethod() to populate the slots which it has 
in common with the previous class and then some additional code to 
populate the new slots in the class.

Before writing each new method the selectMethod() function correctly 
identifies the method which I would like to call from the 
callNextMethod() function. But after 3-4 levels of nesting the method 
seem unable to identify the correct next method and returns nothing but 
continues without error.

I'm sorry, but I couldn't reproduce the problem with a simple example. 
But after countless hours of debug, a thorough reading of the Green 
Book and various attempts with the trace() function - this just drops 
the trace within callNextMethod(), again without error - , I have 
exhausted all my ideas for what is wrong.

All I can think is there might be a problem in callNextMethod(), making 
it inconsistent with selectMethod(). It also not clear to me how 
default values are passed through to the next method.

Is there a recommended debug process for this sort of problem? Is there 
a way call a specific method with a defined signature from within the 
new method definition?

Regards,

John Marsland

From maechler at stat.math.ethz.ch  Wed Apr 20 19:42:41 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Apr 20 19:42:51 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F3487AE8B0461A5BEC97D08D12B0@phx.gbl>
References: <426674E5.8030705@acm.org>
	<BAY17-F3487AE8B0461A5BEC97D08D12B0@phx.gbl>
Message-ID: <16998.38033.698493.702420@stat.math.ethz.ch>

>>>>> "Ali" == Ali - <saveez@hotmail.com>
>>>>>     on Wed, 20 Apr 2005 15:45:09 +0000 writes:

    Ali> Thanks a lot Tony. I am trying to apply the overloading
    Ali> to the methods created by R.oo package and,
    Ali> unfortunately, R.oo uses S3-style classes; so I cannot
    Ali> use the features of S4 methods as you described. On the
    Ali> other hand, I caouldn't find a decent OO package which
    Ali> is based on S4 AND comes with the official release of
    Ali> R.

Ali, maybe we R-core members are not decent enough.
But we strongly believe that we don't want to advocate yet
another object system additionally to the S3 and S4 one,
and several of us have given talks and classes, even written
books on how to do "decent" object oriented programming 
`just' with the S3 and/or S4 object system.

No need of additional "oo" in our eyes.
Your main problem is that you assume what "oo" means {which may
well be true} but *additionally* you also assume that OO has to
be done in the same way you know it from Python, C++, or Java..

Since you are new, please try to learn the S4 way,
where methods belong to (generic) functions more than
to classes in some way, particularly if you compare with other
OO systems where methods belong entirely to classes.
This is NOT true for R (and S-plus) and we don't want this to
change {and yes, we do know about C++, Python, Java,... and
their way to do OO}.

Please also read in more details the good advice given by Tony
Plate and Sean Davis.

Martin Maechler,
ETH Zurich

From ggrothendieck at gmail.com  Wed Apr 20 19:49:52 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed Apr 20 19:50:01 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F138DB205C684A882E69EF3D12B0@phx.gbl>
References: <BAY17-F138DB205C684A882E69EF3D12B0@phx.gbl>
Message-ID: <971536df050420104965297d30@mail.gmail.com>

On 4/20/05, Ali - <saveez@hotmail.com> wrote:
> (1) It seems to me that, generally, in R it is not possible to overload
> functions. Is that right?
> 
> (2) Assuming that the above is true, or partially true, is there any extra
> packages to handle overloading in R?
> 
> (3) Assuming (1) is TRUE and (2) is FALSE, can anyone provide some advice on
> developing some function that understand what the arguments are and then
> calls the right overloaded function?
> 
> It would be something like this:
> 
> overloadedFunction1 <- function(x) {};
> 
> overloadedFunction2 <- function(x, y) {};
> 
> theFunction <- function(...)
> {
>   # How to identify ... and call the right overloaded function?
> }

Here is an example using S3:

> 
> f <- function(x, y) UseMethod("f")
> 
> f.default <- function(x,y,z) {
+         if (missing(z)) {
+         class.x <- if (missing(x)) "missing" else class(x)
+         class.y <- if (missing(y)) "missing" else class(y)
+         .Class <- paste(class.x, class.y, sep = ".")
+         NextMethod("f", z = 1)
+ } else # real default method
+ if (!missing(x) && !missing(y)) paste(x,y) else "one missing"
+ }
> 
> f.missing.missing <- function(x, y, z) "both Missing"
> f.numeric.numeric <- function(x,y, z) paste(x, y)
> 
> f()
[1] "both Missing"
> f(1)
[1] "one missing"
> f(y=1)
[1] "one missing"
> f(1,1)
[1] "1 1"

From john.marsland at wmgfunds.com  Wed Apr 20 19:55:57 2005
From: john.marsland at wmgfunds.com (John Marsland)
Date: Wed Apr 20 19:56:05 2005
Subject: [Rd] callNextMethod()
Message-ID: <77b8b041607b6036a041bc345998cd08@wmgfunds.com>

I have built a sequence of eight S4 classes, each of which inherits 
from the previous one but adds extra slots.

I have a corresponding generic function for which I have described 
methods for each of these classes in a signature with one other 
variable. There are also some ad hoc variable outside the signature 
which have different default values for each class.

Each method calls callNextMethod() to populate the slots which it has 
in common with the previous class and then some additional code to 
populate the new slots in the class.

Before writing each new method the selectMethod() function correctly 
identifies the method which I would like to call from the 
callNextMethod() function. But after 3-4 levels of nesting the method 
seem unable to identify the correct next method and returns nothing but 
continues without error.

I'm sorry, but I couldn't reproduce the problem with a simple example. 
But after countless hours of debug, a thorough reading of the Green 
Book and various attempts with the trace() function - this just drops 
the trace within callNextMethod(), again without error - , I have 
exhausted all my ideas for what is wrong.

All I can think is there might be a problem in callNextMethod(), making 
it inconsistent with selectMethod(). It also not clear to me how 
default values are passed through to the next method.

Is there a recommended debug process for this sort of problem? Is there 
a way call a specific method with a defined signature from within the 
new method definition?

Regards,

John Marsland

From vincent.goulet at act.ulaval.ca  Wed Apr 20 20:26:24 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Wed Apr 20 20:26:40 2005
Subject: [Rd] Negative argument for head() and tail()
Message-ID: <200504201426.24523.vincent.goulet@act.ulaval.ca>

Dear R developers,

I'm a former APL programmer. In that language, the "take" (up arrow) and 
"drop" (down arrow) operators were extensively used to, well, take and drop 
elements of vectors. Functions head() and tail() are equivalents in R for the 
"take" operator, but nothing seems to mimic the "drop" operator. I think it 
would be useful.

For example, is there any simpler way to extract all elements of a vector but 
the last one than doing

> x[1:(length(x) - 1)]  ?

An equivalent of "drop" would make this easy.

Now, I think this could be easily implemented with the existing functions by 
allowing negative arguments to head() and tail(). For example, 

> head(x, -1)

would drop the first element of a vector and

> tail(x, -length(x))

the last one.

Is there any interest for such an extension?

I would be very willing to contribute a patch, although I don't have much 
experience in doing so.

Best regards,

-- 
  Vincent Goulet, Associate Professor
  ?cole d'actuariat
  Universit? Laval, Qu?bec 
  Vincent.Goulet@act.ulaval.ca   http://vgoulet.act.ulaval.ca

From ripley at stats.ox.ac.uk  Wed Apr 20 20:31:28 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Apr 20 20:31:38 2005
Subject: [Rd] Embedded R and x11
In-Reply-To: <200504201834.33320.thomas.friedrichsmeier@ruhr-uni-bochum.de>
References: <200504201834.33320.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <Pine.LNX.4.61.0504201928350.32166@gannet.stats>

I think you are barking up the wrong tree.  If you want to use an 
event-driven sub-system you need to run an event loop.

There is a lot of new information in 2.1.0 on building a front-end.
Please read it.

On Wed, 20 Apr 2005, Thomas Friedrichsmeier wrote:

> I'm working on a frontend for R. I have R running in a separate thread in my
> application using Rf_initEmbeddedR, and I'm using R_tryEval to run commands
> in R (i.e. I don't run the mainloop).
> Everything works fine, except the x11-device: I can open x11-windows and paint
> to them alright from R. However, the x11-window does not respond to any
> events. E.g. clicking the close-button simply does not close the window and
> the contents in the window do not get refreshed when it was hidden by other
> windows.
> I figured that the reason for this might be, that R_ProcessEvents () and
> handleEvent () in devX11.c do not get called (of course I might be completely
> wrong?). So I tried calling R_ProcessEvents () manually, but I can't get that
> to link (unresolved symbol R_ProcessEvents).
> Any hints on how I can get this to work?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From thomas.friedrichsmeier at ruhr-uni-bochum.de  Wed Apr 20 21:05:33 2005
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Wed Apr 20 21:04:50 2005
Subject: [Rd] Embedded R and x11
Message-ID: <200504202105.33116.thomas.friedrichsmeier@ruhr-uni-bochum.de>

> I think you are barking up the wrong tree.  If you want to use an
> event-driven sub-system you need to run an event loop.

Well, but I only want part of R's event loop, namely handling of some specific
X11-events. Of course, I do have a sort of event-loop, except that the main
category of "events" is requests coming from the main application/thread. For
this it's simply more practical to run my "own" event loop. The only problem
was how to trigger processing of X11-events from there.

Anyway, you will see in my follow-up, that I found a solution that does just
what I want.

> There is a lot of new information in 2.1.0 on building a front-end.
> Please read it.

Yes, I've seen that, and it's very helpful compared to the documentation
available when I had last checked (pre 2.0.0).

Regards
Thomas Friedrichsmeier

P.S.: In case you're interested, the project I'm working on is this:
http://rkward.sourceforge.net

From ldimitro at wfubmc.edu  Wed Apr 20 21:30:54 2005
From: ldimitro at wfubmc.edu (Latchezar Dimitrov)
Date: Wed Apr 20 21:31:34 2005
Subject: [Rd] Overloading methods in R
Message-ID: <F160BE32A2E5E04497668BBDFE83FEDF08DA8250@EXCHVS1.medctr.ad.wfubmc.edu>

Hello, 

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of A.J. Rossini
> Sent: Wednesday, April 20, 2005 12:21 PM
> To: Ali -
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] Overloading methods in R
> 
> R.oo tries to implement an old-fashioned OO system as found 
> in Java, Python, C++, etc.  R's S4 methods implement a nice 
> modern system based on the generic function approach , 
> dispatch on argument signatures,

With all respect to R (and its developers) and for the records I
couldn't
help but refer to Ada'83 (not even '95 :-)) 

Best regards,

Latchezar Dimitrov

> which is different.
> 
> While the R documentation for S4 classes is quite useful 
> (spanning the green book, the BioC developer help pages,  
> V&R's book on programming, and some other papers), I've found 
> that for a nice background, Paul Graham's ANSI Lisp book, and 
> in particular the nicely written chapter on CLOS, provides a 
> nice introduction to the thought process.
> 
> With respect to the R.oo package, the author might be the 
> best source for that.
> 
> Another package which you might take a look at is the proto 
> package, which provides prototype object-orientation similar 
> to that found in XLispStat, and also might help with what you 
> are trying to do. 
> However, I suspect that learning about the S4 system will 
> provide more benefit in the future.
> 
> best,
> -tony
> 
> On 4/20/05, Ali - <saveez@hotmail.com> wrote:
> > Sean,
> > 
> > Thanks, but, I am actually talking about overloading 
> 'methods' and not 
> > 'functions', or you may want to answer this question: How 
> to overload 
> > methods in classes created by R.oo package?
> > 
> > >
> > >On Apr 20, 2005, at 8:16 AM, Ali - wrote:
> > >
> > >>(1) It seems to me that, generally, in R it is not possible to  
> > >>overload functions. Is that right?
> > >>
> > >>(2) Assuming that the above is true, or partially true, 
> is there any 
> > >>extra packages to handle overloading in R?
> > >>
> > >>(3) Assuming (1) is TRUE and (2) is FALSE, can anyone 
> provide some  
> > >>advice on developing some function that understand what the 
> > >>arguments  are and then calls the right overloaded function?
> > >>
> > >>It would be something like this:
> > >>
> > >>overloadedFunction1 <- function(x) {};
> > >>
> > >>overloadedFunction2 <- function(x, y) {};
> > >>
> > >>theFunction <- function(...)
> > >>{
> > >>   # How to identify ... and call the right overloaded function?
> > >>}
> > >>
> > >
> > >Ali,
> > >
> > >You are probably interested in "methods".  Functions can have 
> > >different "methods" depending on what the arguments and 
> their types 
> > >are.  A first place to look is:
> > >
> > 
> >http://cran.r-project.org/doc/manuals/R-exts.html#Generic-functions-
> > >and-methods
> > >
> > >Sean
> > >
> > 
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> 
> 
> --
> best,
> -tony
> 
> "Commit early,commit often, and commit in a repository from 
> which we can easily roll-back your mistakes" (AJR, 4Jan05).
> 
> A.J. Rossini
> blindglobe@gmail.com
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From rlee at fpcc.net  Wed Apr 20 22:05:36 2005
From: rlee at fpcc.net (rlee@fpcc.net)
Date: Wed Apr 20 22:04:17 2005
Subject: [Rd] Suggestions for manipulating formula objects
Message-ID: <33078.136.177.22.105.1114027536.squirrel@webmail.fpcc.net>

I'm trying to manipulate/change a formula prior to passing it to another
function.  A simplified example:

User passes formula to my function: y~x
My function does: lm(transform(y)~x)

Here, transform() is added to the model's response.

What is the best way to accomplish this?

From vincent.goulet at act.ulaval.ca  Wed Apr 20 22:32:56 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Wed Apr 20 22:33:38 2005
Subject: [Rd] Negative argument for head() and tail()
In-Reply-To: <1abe3fa90504201305190301cd@mail.gmail.com>
References: <200504201426.24523.vincent.goulet@act.ulaval.ca>
	<1abe3fa90504201305190301cd@mail.gmail.com>
Message-ID: <200504201632.56138.vincent.goulet@act.ulaval.ca>

Le 20 Avril 2005 16:05, A.J. Rossini a ?crit?:
> x[-length(x)] ?

I feel idiot from that one, but hold on to my point. ;-)

Better example, then: how about a compact way to drop, say, the last 3 
elements of a vector? I think

> tail(x, -3)

would be nicer --- and more readable --- than

> x[-((length(x)-2):length(x))]

or

> x[0:3 -length(x)]

or some other convoluted way to achieve the same result.

(BTW, dropping the last element of a vector would be 'tail(x, -1)., not 
'tail(x, -length(x))' as stated in my original post. The latter would drop 
all the elements.)

> On 4/20/05, Vincent Goulet <vincent.goulet@act.ulaval.ca> wrote:
> > Dear R developers,
> >
> > I'm a former APL programmer. In that language, the "take" (up arrow) and
> > "drop" (down arrow) operators were extensively used to, well, take and
> > drop elements of vectors. Functions head() and tail() are equivalents in
> > R for the "take" operator, but nothing seems to mimic the "drop"
> > operator. I think it would be useful.
> >
> > For example, is there any simpler way to extract all elements of a vector
> > but the last one than doing
> >
> > > x[1:(length(x) - 1)]  ?
> >
> > An equivalent of "drop" would make this easy.
> >
> > Now, I think this could be easily implemented with the existing functions
> > by allowing negative arguments to head() and tail(). For example,
> >
> > > head(x, -1)
> >
> > would drop the first element of a vector and
> >
> > > tail(x, -length(x))
> >
> > the last one.
> >
> > Is there any interest for such an extension?
> >
> > I would be very willing to contribute a patch, although I don't have much
> > experience in doing so.
> >
> > Best regards,
> >
> > --
> >   Vincent Goulet, Associate Professor
> >   ?cole d'actuariat
> >   Universit? Laval, Qu?bec
> >   Vincent.Goulet@act.ulaval.ca   http://vgoulet.act.ulaval.ca
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
  Vincent Goulet, Professeur agr?g?
  ?cole d'actuariat
  Universit? Laval, Qu?bec 
  Vincent.Goulet@act.ulaval.ca   http://vgoulet.act.ulaval.ca

From mnason at Niaid.nih.gov  Wed Apr 20 23:31:35 2005
From: mnason at Niaid.nih.gov (mnason@Niaid.nih.gov)
Date: Wed Apr 20 23:31:43 2005
Subject: [Rd] negative p-values from fisher's test (PR#7801)
Message-ID: <20050420213135.87D15A1EE@slim.kubism.ku.dk>

Full_Name: Martha Nason
Version: 2.0.1
OS: Windows XP
Submission from: (NULL) (137.187.154.154)


I am running simulations using fisher's test on 2 x c tables and a very small
p.value from fisher's test (<2.2e-16) is returned as a negative number. Code
follows. 

> set.seed(0)
> nreps.outer <-7
> pvalue.fisher <- rep(NA,nreps.outer)
> 
> population1 <- c( rep("A",300),seq(1:100)) 
> 
> population2 <- c( rep("A",100),seq(101:200))
> 
> 
> for (j in 1:nreps.outer){
+ n1 <- sample(30:100,1)
+ n2 <- sample(30:100,1)
+ 
+ group1 <- sample(population1, n1, replace=T)
+ group2 <- sample(population2, n2, replace=T)
+ 
+ pvalue.fisher[j] <-
fisher.test(table(c(group1,group2),c(rep("group1",n1),rep("group2",n2))))$p.value
+ 
+ print(c(j,pvalue.fisher[j]))
+ 
+ }
[1] 1.000000e+00 3.581362e-05
[1] 2.0000000 0.1424779
[1] 3.0000000 0.1196600
[1] 4.000000000 0.004222897
[1] 5.000000e+00 3.234016e-07
[1] 6.000000000 0.003240286
[1]  7.000000e+00 -3.847298e-05

> 
> fisher.test(table(c(group1,group2),c(rep("group1",n1),rep("group2",n2))))

        Fisher's Exact Test for Count Data

data:  table(c(group1, group2), c(rep("group1", n1), rep("group2", n2))) 
p-value < 2.2e-16
alternative hypothesis: two.sided 

> fisher.test(table(c(group1,group2),c(rep("group1",n1),rep("group2",n2))))$p.value
[1] -3.847298e-05

From cberry at tajo.ucsd.edu  Thu Apr 21 00:49:26 2005
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu Apr 21 00:49:44 2005
Subject: [Rd] Negative argument for head() and tail()
In-Reply-To: <200504201632.56138.vincent.goulet@act.ulaval.ca>
References: <200504201426.24523.vincent.goulet@act.ulaval.ca>
	<1abe3fa90504201305190301cd@mail.gmail.com>
	<200504201632.56138.vincent.goulet@act.ulaval.ca>
Message-ID: <Pine.LNX.4.62.0504201514260.5180@tajo.ucsd.edu>


I'd like to second Vincent's appeal.

Before 'head' and 'tail' were added to package:utils, I had 
versions that allowed negative subscripts.

And I found the code rendered by them readable and less subject to 
mental or typographical errors.

I think all that is needed for the versions in package::utils is:

 	if (n < 0 ) n <- length(x) + n

or

 	if (n < 0 ) n <- nrow(x) + n

as the first line of the body of each method except head.function.

Chuck


On Wed, 20 Apr 2005, Vincent Goulet wrote:

> Le 20 Avril 2005 16:05, A.J. Rossini a crit:
>> x[-length(x)] ?
>
> I feel idiot from that one, but hold on to my point. ;-)
>
> Better example, then: how about a compact way to drop, say, the last 3
> elements of a vector? I think
>
>> tail(x, -3)
>
> would be nicer --- and more readable --- than
>
>> x[-((length(x)-2):length(x))]
>
> or
>
>> x[0:3 -length(x)]
>
> or some other convoluted way to achieve the same result.
>
> (BTW, dropping the last element of a vector would be 'tail(x, -1)., not
> 'tail(x, -length(x))' as stated in my original post. The latter would drop
> all the elements.)
>
>> On 4/20/05, Vincent Goulet <vincent.goulet@act.ulaval.ca> wrote:
>>> Dear R developers,
>>>
>>> I'm a former APL programmer. In that language, the "take" (up arrow) and
>>> "drop" (down arrow) operators were extensively used to, well, take and
>>> drop elements of vectors. Functions head() and tail() are equivalents in
>>> R for the "take" operator, but nothing seems to mimic the "drop"
>>> operator. I think it would be useful.
>>>
>>> For example, is there any simpler way to extract all elements of a vector
>>> but the last one than doing
>>>
>>>> x[1:(length(x) - 1)]  ?
>>>
>>> An equivalent of "drop" would make this easy.
>>>
>>> Now, I think this could be easily implemented with the existing functions
>>> by allowing negative arguments to head() and tail(). For example,
>>>
>>>> head(x, -1)
>>>
>>> would drop the first element of a vector and
>>>
>>>> tail(x, -length(x))
>>>
>>> the last one.
>>>
>>> Is there any interest for such an extension?
>>>
>>> I would be very willing to contribute a patch, although I don't have much
>>> experience in doing so.
>>>
>>> Best regards,
>>>
>>> --
>>>   Vincent Goulet, Associate Professor
>>>   cole d'actuariat
>>>   Universit Laval, Qubec
>>>   Vincent.Goulet@act.ulaval.ca   http://vgoulet.act.ulaval.ca
>>>
>>> ______________________________________________
>>> R-devel@stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> -- 
>  Vincent Goulet, Professeur agrg
>  cole d'actuariat
>  Universit Laval, Qubec
>  Vincent.Goulet@act.ulaval.ca   http://vgoulet.act.ulaval.ca
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry@tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717

From tlumley at u.washington.edu  Thu Apr 21 01:47:12 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Apr 21 01:47:28 2005
Subject: [Rd] Suggestions for manipulating formula objects
In-Reply-To: <33078.136.177.22.105.1114027536.squirrel@webmail.fpcc.net>
References: <33078.136.177.22.105.1114027536.squirrel@webmail.fpcc.net>
Message-ID: <Pine.A41.4.61b.0504201644290.71116@homer07.u.washington.edu>

On Wed, 20 Apr 2005 rlee@fpcc.net wrote:

> I'm trying to manipulate/change a formula prior to passing it to another
> function.  A simplified example:
>
> User passes formula to my function: y~x
> My function does: lm(transform(y)~x)
>
> Here, transform() is added to the model's response.
>
> What is the best way to accomplish this?

One way is

formula[[2]]<-substitute(transform(y),list(y=formula[[2]]))


 	-thomas

From rich.fitzjohn at gmail.com  Thu Apr 21 01:52:12 2005
From: rich.fitzjohn at gmail.com (Rich FitzJohn)
Date: Thu Apr 21 01:52:21 2005
Subject: [Rd] Suggestions for manipulating formula objects
In-Reply-To: <33078.136.177.22.105.1114027536.squirrel@webmail.fpcc.net>
References: <33078.136.177.22.105.1114027536.squirrel@webmail.fpcc.net>
Message-ID: <5934ae570504201652af78001@mail.gmail.com>

Hi,

Formulas (and other language objects) can be manipulated to some
extent like lists (see the R Language Definition).  A formula
corresponds to a 3-element list, where the first argument is the
function `~`, and the next two are the LHS and RHS of the formula,
respectively (for unary use of ~, the list is 2 elements; `~` and the
single argument).

as.list(y ~ x)

The following function would apply the function "trans" to the
response of a formula "form".
addTransform <- function(form, trans) {
  stopifnot(inherits(form, "formula"),
            deparse(form[[1]]) == "~",
            is.function(match.fun(trans)))
  form[[2]] <- as.call(list(substitute(trans), form[[2]]))
  form
}

addTransform(y ~ x, sqrt)

## Testing this:
x <- 3*runif(20)
y <- sqrt(x*(2 + rnorm(20, sd=.1)))

f <- addTransform(y ~ x, sqrt)
lm(f) # Not a very informative call statement from lm()
lm(addTransform(y ~ x, sqrt)) # Slightly better call statement
do.call("lm", list(f)) # Matches appearence of the call below:
lm(sqrt(y) ~ x)

Cheers,
Rich


On 4/21/05, rlee@fpcc.net <rlee@fpcc.net> wrote:
> I'm trying to manipulate/change a formula prior to passing it to another
> function.  A simplified example:
> 
> User passes formula to my function: y~x
> My function does: lm(transform(y)~x)
> 
> Here, transform() is added to the model's response.
> 
> What is the best way to accomplish this?
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


-- 
Rich FitzJohn
rich.fitzjohn <at> gmail.com   |    http://homepages.paradise.net.nz/richa183
                      You are in a maze of twisty little functions, all alike

From saveez at hotmail.com  Thu Apr 21 11:44:34 2005
From: saveez at hotmail.com (Ali -)
Date: Thu Apr 21 11:44:43 2005
Subject: [Rd] Limitations of generic functions
Message-ID: <BAY17-F197A50240015116B894904D12C0@phx.gbl>

(1) Assume we have some automatic C++ wrapper which , briefly, reads the C++ 
files and generates some R files in which the equivalent of the C++ classes 
are reconstructed.

(2) As the OO design of R is different to that of C++, some isses exist when 
creating an interface between these two systems. (I said these two are 
'different', I didn't say which one is better or which one is uglier. So 
please save the posts on criticising the designs for somewhere else. I am 
trying to make these two designs talk to each other without judging them.)

(3) One of these issues is about handling overloaded member functions in C++ 
in the form of R classes. Following the discussion followed by my previous 
post, I have decided to wrap the C++ in the form of S4 classes.

(4) Some more assumptions:

    (a) A C++ class may have any arbitrary number of overloaded functions 
each of them have some arbitrary number of arguments.

    (b) To create the equivalent 'overloaded functions' in R, we need to 
have a generic function with several methods. The arguments (signature) of 
each of these methods are determined by the generic function.
    (c) In order to make the automatic wrapper as general as possible, it 
should not know about the arguments of the overloaded functions.

(5) And finally the question: How to define the generic function so that it 
covers any unknown arguments of its methods? Apparently simply using '...' 
does not work.

From hb at maths.lth.se  Thu Apr 21 12:57:37 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu Apr 21 13:01:54 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <1abe3fa9050420092020ee934e@mail.gmail.com>
Message-ID: <005701c54660$efb1aa50$d50040d5@hblaptop>

Hi. Some clarification on R.oo:

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of A.J. Rossini
> Sent: Wednesday, April 20, 2005 6:21 PM
> To: Ali -
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] Overloading methods in R
> 
> 
> R.oo tries to implement an old-fashioned OO system as found 
> in Java, Python, C++, etc.  R's S4 methods implement a nice 
> modern system based on the generic function approach , 
> dispatch on argument signatures, which is different.

I would call them different, rather than old and modern - each kind has its
own use. 

To the details: 
It is the Object class that is related to Java & co; the setMethodS3() and
setConstructorS3() methods are orthogonal and just userfriendly wrappers to
creating functions manually.

The main purpose of Object is provide *reference variables*, with the main
purpose to save memory! This is done by utilizing environment, which is
standard R code, no ugly hacks are used. The Object class defines operators
"$" and "$<-" (and a few others) to access variables within the environment,
which is unique to each instance of class Object. Indeed, there was a
similar feature added in R v1.9.0 (or was it v2.0.0) to the environment
variable; "$" and "$<-" wraps up get() and assign() methods for easy use.
For an object Object, the environment is in a list structure, contrary to
being an environment directly. The reason for this is that attr(), save()
and load() on environments does (did?) not work as you would expect, cf.
https://stat.ethz.ch/pipermail/r-devel/2002-October/025197.html. 

The the Object class defines some other methods to simplify life, and yes,
to imitate Java in the sense that it is convenient to inherit from one
single root Class. It does not allow multiple inheritance (although you can
update the class attributes yourself if you wish too). 

To differ between OOP in Java and S4/Dylan, I prefer to refer to the former
as
class-object-oriented programming (COOP) and the latter as
function-object-oriented programming (FOOP). Then, comparing COOP style with
FOOP style is a bit like comparing peas to apples. I would say that choosing
COOP or FOOP is a design issue that has to do what you are trying to
implement and not a
once-in-a-lifetime/I-want-to-belong-to-this-group-of-people decision. For
what I am working on, I found that higher level implementation, where it is
clear that a method "belongs" to a class, is easier using COOP. Classes for
statistical and mathematical modelling, where functions does not belong to a
specific object, is probably better i FOOP. So, please do not rule out one
for the other!

The setMethodS3() is a wrapper to automatically test for generic and default
functions and create generic functions when needed etc. So

setMethodS3("foo", "MyClass", function(object, ...) { 
  #something
})

replaces things like

if (exists("foo.MyClass", mode="function"))
  warning/stop("Replacing foo.MyClass")

if (exists("foo", mode="function") && !"not a generic function")
  try to rename foo() to foo.default(), but only if foo.default() 
  does not already exists.

... and so on until you can safely write

foo.MyClass <- function(object, ...) {
  # something
}

setConstructorS3() is basically like the above, but it does not create a
generic function nor a class specific method, but a "plain" function

setConstructorS3("MyClass", function(args, ...) {
  # Something
}

to get 

MyClass <- function(args, ...) {
  # Something
}

with check for naming conflicts etc.

Cheers

Henrik Bengtsson
(author of R.oo)

> While the R documentation for S4 classes is quite useful 
> (spanning the green book, the BioC developer help pages,  
> V&R's book on programming, and some other papers), I've found 
> that for a nice background, Paul Graham's ANSI Lisp book, and 
> in particular the nicely written chapter on CLOS, provides a 
> nice introduction to the thought process.
> 
> With respect to the R.oo package, the author might be the 
> best source for that.
> 
> Another package which you might take a look at is the proto 
> package, which provides prototype object-orientation similar 
> to that found in XLispStat, and also might help with what you 
> are trying to do. 
> However, I suspect that learning about the S4 system will 
> provide more benefit in the future.
> 
> best,
> -tony
> 
> On 4/20/05, Ali - <saveez@hotmail.com> wrote:
> > Sean,
> > 
> > Thanks, but, I am actually talking about overloading 
> 'methods' and not 
> > 'functions', or you may want to answer this question: How 
> to overload 
> > methods in classes created by R.oo package?
> > 
> > >
> > >On Apr 20, 2005, at 8:16 AM, Ali - wrote:
> > >
> > >>(1) It seems to me that, generally, in R it is not possible to  
> > >>overload functions. Is that right?
> > >>
> > >>(2) Assuming that the above is true, or partially true, 
> is there any 
> > >>extra packages to handle overloading in R?
> > >>
> > >>(3) Assuming (1) is TRUE and (2) is FALSE, can anyone 
> provide some  
> > >>advice on developing some function that understand what the 
> > >>arguments  are and then calls the right overloaded function?
> > >>
> > >>It would be something like this:
> > >>
> > >>overloadedFunction1 <- function(x) {};
> > >>
> > >>overloadedFunction2 <- function(x, y) {};
> > >>
> > >>theFunction <- function(...)
> > >>{
> > >>   # How to identify ... and call the right overloaded function? }
> > >>
> > >
> > >Ali,
> > >
> > >You are probably interested in "methods".  Functions can 
> have different
> > >"methods" depending on what the arguments and their types 
> are.  A first
> > >place to look is:
> > >
> > 
> >http://cran.r-project.org/doc/manuals/R-exts.html#Generic-functions-
> > >and-methods
> > >
> > >Sean
> > >
> > 
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> 
> 
> -- 
> best,
> -tony
> 
> "Commit early,commit often, and commit in a repository from 
> which we can easily
> roll-back your mistakes" (AJR, 4Jan05).
> 
> A.J. Rossini
> blindglobe@gmail.com
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>

From saveez at hotmail.com  Thu Apr 21 13:28:13 2005
From: saveez at hotmail.com (Ali -)
Date: Thu Apr 21 13:28:23 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <005701c54660$efb1aa50$d50040d5@hblaptop>
Message-ID: <BAY17-F1436EACACCB0438E594C05D12C0@phx.gbl>

Henrik,

Thanks for a reply as the author of the package. I understand that you 
people are interested in discussing this COOP-FOOP fight, however, the 
original question of this thread is all forgotton. So, I declare the 
question again:

-> How to overload methods in classes created by R.oo package? <-

I even sent you this question by the email provided in the package, but 
still no answer!

I am trying to wrap some C++ class into R, so, in the way that you 
described, I am trying to wrap some COOP 'things' by some FOOP 'things'. 
Although there are some packages in R that already wrapped some C++ classes 
into R, none of them kept the originality of the wrapped classes. That is, 
the original C++ classes are customised and dissolved to R functions. There 
is nothing wrong with doing this, but, I am wrapping a few hundered C++ 
classes automatically and apparently it is not possible to customise each of 
them.

The good thing about R.oo is that it is a trouble-less interface between 
COOP and FOOP. In fact, I have already used the package successfully to 
generate S3 classes from C++ *automatically*. The only big issue that I have 
with it is that R.oo overwrites overloaded methods and, to keep the 
originality of the C++ class and bein nice to the end user, I don't want to 
change the name of the overloaded functions. Also there is this point that 
sometime in feature S3 classes will become completely obsolete and new 
packages shouldn't be based on it. So it would be nice to have a 'S4-R.oo'.

Finally, I remind the package author about the original question:

- How to overload methods in classes created by R.oo package?

with one more question that I add it right now:

- Why R.00 is not upgraded to S4?

and I hope we have some 'answer'.


-Ali


>Hi. Some clarification on R.oo:
>
> > -----Original Message-----
> > From: r-devel-bounces@stat.math.ethz.ch
> > [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of A.J. Rossini
> > Sent: Wednesday, April 20, 2005 6:21 PM
> > To: Ali -
> > Cc: r-devel@stat.math.ethz.ch
> > Subject: Re: [Rd] Overloading methods in R
> >
> >
> > R.oo tries to implement an old-fashioned OO system as found
> > in Java, Python, C++, etc.  R's S4 methods implement a nice
> > modern system based on the generic function approach ,
> > dispatch on argument signatures, which is different.
>
>I would call them different, rather than old and modern - each kind has its
>own use.
>
>To the details:
>It is the Object class that is related to Java & co; the setMethodS3() and
>setConstructorS3() methods are orthogonal and just userfriendly wrappers to
>creating functions manually.
>
>The main purpose of Object is provide *reference variables*, with the main
>purpose to save memory! This is done by utilizing environment, which is
>standard R code, no ugly hacks are used. The Object class defines operators
>"$" and "$<-" (and a few others) to access variables within the 
>environment,
>which is unique to each instance of class Object. Indeed, there was a
>similar feature added in R v1.9.0 (or was it v2.0.0) to the environment
>variable; "$" and "$<-" wraps up get() and assign() methods for easy use.
>For an object Object, the environment is in a list structure, contrary to
>being an environment directly. The reason for this is that attr(), save()
>and load() on environments does (did?) not work as you would expect, cf.
>https://stat.ethz.ch/pipermail/r-devel/2002-October/025197.html.
>
>The the Object class defines some other methods to simplify life, and yes,
>to imitate Java in the sense that it is convenient to inherit from one
>single root Class. It does not allow multiple inheritance (although you can
>update the class attributes yourself if you wish too).
>
>To differ between OOP in Java and S4/Dylan, I prefer to refer to the former
>as
>class-object-oriented programming (COOP) and the latter as
>function-object-oriented programming (FOOP). Then, comparing COOP style 
>with
>FOOP style is a bit like comparing peas to apples. I would say that 
>choosing
>COOP or FOOP is a design issue that has to do what you are trying to
>implement and not a
>once-in-a-lifetime/I-want-to-belong-to-this-group-of-people decision. For
>what I am working on, I found that higher level implementation, where it is
>clear that a method "belongs" to a class, is easier using COOP. Classes for
>statistical and mathematical modelling, where functions does not belong to 
>a
>specific object, is probably better i FOOP. So, please do not rule out one
>for the other!
>
>The setMethodS3() is a wrapper to automatically test for generic and 
>default
>functions and create generic functions when needed etc. So
>
>setMethodS3("foo", "MyClass", function(object, ...) {
>   #something
>})
>
>replaces things like
>
>if (exists("foo.MyClass", mode="function"))
>   warning/stop("Replacing foo.MyClass")
>
>if (exists("foo", mode="function") && !"not a generic function")
>   try to rename foo() to foo.default(), but only if foo.default()
>   does not already exists.
>
>... and so on until you can safely write
>
>foo.MyClass <- function(object, ...) {
>   # something
>}
>
>setConstructorS3() is basically like the above, but it does not create a
>generic function nor a class specific method, but a "plain" function
>
>setConstructorS3("MyClass", function(args, ...) {
>   # Something
>}
>
>to get
>
>MyClass <- function(args, ...) {
>   # Something
>}
>
>with check for naming conflicts etc.
>
>Cheers
>
>Henrik Bengtsson
>(author of R.oo)
>
> > While the R documentation for S4 classes is quite useful
> > (spanning the green book, the BioC developer help pages,
> > V&R's book on programming, and some other papers), I've found
> > that for a nice background, Paul Graham's ANSI Lisp book, and
> > in particular the nicely written chapter on CLOS, provides a
> > nice introduction to the thought process.
> >
> > With respect to the R.oo package, the author might be the
> > best source for that.
> >
> > Another package which you might take a look at is the proto
> > package, which provides prototype object-orientation similar
> > to that found in XLispStat, and also might help with what you
> > are trying to do.
> > However, I suspect that learning about the S4 system will
> > provide more benefit in the future.
> >
> > best,
> > -tony
> >
> > On 4/20/05, Ali - <saveez@hotmail.com> wrote:
> > > Sean,
> > >
> > > Thanks, but, I am actually talking about overloading
> > 'methods' and not
> > > 'functions', or you may want to answer this question: How
> > to overload
> > > methods in classes created by R.oo package?
> > >
> > > >
> > > >On Apr 20, 2005, at 8:16 AM, Ali - wrote:
> > > >
> > > >>(1) It seems to me that, generally, in R it is not possible to
> > > >>overload functions. Is that right?
> > > >>
> > > >>(2) Assuming that the above is true, or partially true,
> > is there any
> > > >>extra packages to handle overloading in R?
> > > >>
> > > >>(3) Assuming (1) is TRUE and (2) is FALSE, can anyone
> > provide some
> > > >>advice on developing some function that understand what the
> > > >>arguments  are and then calls the right overloaded function?
> > > >>
> > > >>It would be something like this:
> > > >>
> > > >>overloadedFunction1 <- function(x) {};
> > > >>
> > > >>overloadedFunction2 <- function(x, y) {};
> > > >>
> > > >>theFunction <- function(...)
> > > >>{
> > > >>   # How to identify ... and call the right overloaded function? }
> > > >>
> > > >
> > > >Ali,
> > > >
> > > >You are probably interested in "methods".  Functions can
> > have different
> > > >"methods" depending on what the arguments and their types
> > are.  A first
> > > >place to look is:
> > > >
> > >
> > >http://cran.r-project.org/doc/manuals/R-exts.html#Generic-functions-
> > > >and-methods
> > > >
> > > >Sean
> > > >
> > >
> > > ______________________________________________
> > > R-devel@stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
> >
> > --
> > best,
> > -tony
> >
> > "Commit early,commit often, and commit in a repository from
> > which we can easily
> > roll-back your mistakes" (AJR, 4Jan05).
> >
> > A.J. Rossini
> > blindglobe@gmail.com
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>

From ggrothendieck at gmail.com  Thu Apr 21 13:30:11 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu Apr 21 13:30:26 2005
Subject: [Rd] Suggestions for manipulating formula objects
In-Reply-To: <Pine.A41.4.61b.0504201644290.71116@homer07.u.washington.edu>
References: <33078.136.177.22.105.1114027536.squirrel@webmail.fpcc.net>
	<Pine.A41.4.61b.0504201644290.71116@homer07.u.washington.edu>
Message-ID: <971536df05042104304c8622c4@mail.gmail.com>

On 4/20/05, Thomas Lumley <tlumley@u.washington.edu> wrote:
> On Wed, 20 Apr 2005 rlee@fpcc.net wrote:
> 
> > I'm trying to manipulate/change a formula prior to passing it to another
> > function.  A simplified example:
> >
> > User passes formula to my function: y~x
> > My function does: lm(transform(y)~x)
> >
> > Here, transform() is added to the model's response.
> >
> > What is the best way to accomplish this?
> 
> One way is
> 
> formula[[2]]<-substitute(transform(y),list(y=formula[[2]]))
> 

Another way is to use update, e.g.

> fo <- y ~ x
> update(fo, transform(.) ~ .)
transform(y) ~ x

From wolfgang.lederer at stat.uni-muenchen.de  Thu Apr 21 13:36:22 2005
From: wolfgang.lederer at stat.uni-muenchen.de (wolfgang.lederer@stat.uni-muenchen.de)
Date: Thu Apr 21 13:36:29 2005
Subject: [Rd] printCoefmat(signif.legend =FALSE) (PR#7802)
Message-ID: <20050421113622.AFBCEA1ED@slim.kubism.ku.dk>

printCoefmat(signif.legend =FALSE) does not work properly. The option 
"signif.legend = FALSE" is ignored as shown in the example below.

cmat <- cbind(rnorm(3, 10), sqrt(rchisq(3, 12)))
cmat <- cbind(cmat, cmat[,1]/cmat[,2])
cmat <- cbind(cmat, 2*pnorm(-cmat[,3]))
colnames(cmat) <- c("Estimate", "Std.Err", "Z value", "Pr(>z)")

# Prints the legend, although it should not

printCoefmat(cmat, signif.stars =TRUE, signif.legend = FALSE)
#     Estimate Std.Err Z value   Pr(>z)
#[1,]  10.3567  3.3680  3.0750 0.002105 **
#[2,]   9.1652  4.3609  2.1017 0.035581 *
#[3,]  10.4420  3.6527  2.8587 0.004253 **
#---
#Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

# Does not print the legend, although it should

printCoefmat(cmat, signif.stars = FALSE, signif.legend = TRUE)
#     Estimate Std.Err Z value   Pr(>z)
#[1,]  10.3567  3.3680  3.0750 0.002105
#[2,]   9.1652  4.3609  2.1017 0.035581
#[3,]  10.4420  3.6527  2.8587 0.004253


I think the problem can be easily solved by changing the code lines (3. 
and 4. from the bottom)

if (signif.stars)
        cat("---\nSignif. codes: ", attr(Signif, "legend"), "\n")
to

if (signif.legend)
        cat("---\nSignif. codes: ", attr(Signif, "legend"), "\n")

At least it works for the more sensibel case, that no legend should be 
produced.

Regards

Wolfgang



--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status =
 major = 2
 minor = 1.0
 year = 2005
 month = 04
 day = 18
 language = R

Windows XP Professional (build 2600) Service Pack 2.0

Search Path:
 .GlobalEnv, package:simex, package:methods, package:stats, 
package:graphics, package:grDevices, package:utils, package:datasets, 
Autoloads, package:base

**************************************************

Wolfgang Lederer
Institut f?r Statistik
Ludwig-Maximilians-Universit?t M?nchen
Ludwigstra?e 33
D-80539 M?nchen
Tel: +49 89 2180 3165
Fax: +49 89 2180 5308

From ripley at stats.ox.ac.uk  Thu Apr 21 13:43:08 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Apr 21 13:43:16 2005
Subject: [Rd] printCoefmat(signif.legend =FALSE) (PR#7802)
Message-ID: <20050421114308.A4A69A1FF@slim.kubism.ku.dk>

On Thu, 21 Apr 2005 wolfgang.lederer@stat.uni-muenchen.de wrote:

> printCoefmat(signif.legend =FALSE) does not work properly. The option
> "signif.legend = FALSE" is ignored as shown in the example below.
>
> cmat <- cbind(rnorm(3, 10), sqrt(rchisq(3, 12)))
> cmat <- cbind(cmat, cmat[,1]/cmat[,2])
> cmat <- cbind(cmat, 2*pnorm(-cmat[,3]))
> colnames(cmat) <- c("Estimate", "Std.Err", "Z value", "Pr(>z)")
>
> # Prints the legend, although it should not
>
> printCoefmat(cmat, signif.stars =TRUE, signif.legend = FALSE)
> #     Estimate Std.Err Z value   Pr(>z)
> #[1,]  10.3567  3.3680  3.0750 0.002105 **
> #[2,]   9.1652  4.3609  2.1017 0.035581 *
> #[3,]  10.4420  3.6527  2.8587 0.004253 **
> #---
> #Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> # Does not print the legend, although it should
>
> printCoefmat(cmat, signif.stars = FALSE, signif.legend = TRUE)
> #     Estimate Std.Err Z value   Pr(>z)
> #[1,]  10.3567  3.3680  3.0750 0.002105
> #[2,]   9.1652  4.3609  2.1017 0.035581
> #[3,]  10.4420  3.6527  2.8587 0.004253
>
>
> I think the problem can be easily solved by changing the code lines (3.
> and 4. from the bottom)
>
> if (signif.stars)
>        cat("---\nSignif. codes: ", attr(Signif, "legend"), "\n")
> to
>
> if (signif.legend)
>        cat("---\nSignif. codes: ", attr(Signif, "legend"), "\n")
>
> At least it works for the more sensibel case, that no legend should be
> produced.

Probably if(signif.stars && signif.legend)  would be most appropriate.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From cyril.humbert at univ-mlv.fr  Thu Apr 21 14:08:19 2005
From: cyril.humbert at univ-mlv.fr (cyril.humbert@univ-mlv.fr)
Date: Thu Apr 21 14:08:26 2005
Subject: [Rd] print.data.frame(), wrong column names alignement,
	UTF-8 names (PR#7803)
Message-ID: <20050421120819.90CF4A1CA@slim.kubism.ku.dk>

Hello,

When a data.frame contains column names with accentued characters 
(UTF8 encoded), the alignement of the column names is wrong (extra
spaces inserted).

For example : ------------------------------------------------

> Sys.getlocale()
[1] "LC_CTYPE=fr_FR.UTF-8@euro;LC_NUMERIC=C;LC_TIME=fr_FR.UTF-8@euro;LC_COLLATE=fr_FR.UTF-8@euro;LC_MONETARY=fr_FR.UTF-8@euro;LC_MESSAGES=fr_FR.UTF-8@euro;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C"

> print (data.frame(aaaa=1, b=2, c=3)) # (ok)
  aaaa b c
1    1 2 3


> print (data.frame(????????=1, b=2, c=3)) # (extra blanks)
  ???????? b c
1        1 2 3

--------------------------------------------------------------

This is probably due to fact that the number of white spaces
to insert between the columns is computed using the length 
of the column names (in bytes) instead of their width (in 
characters), which are different in the example above.

The problem is the same (extra spaces inserted) with
print.data.frame(..., right = FALSE).

Thanks,
Cyril


--please do not edit the information below--

Version:
 platform = i386-pc-linux-gnu
 arch = i386
 os = linux-gnu
 system = i386, linux-gnu
 status = 
 major = 2
 minor = 1.0
 year = 2005
 month = 04
 day = 18
 language = R

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base

From hb at maths.lth.se  Thu Apr 21 14:46:06 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu Apr 21 14:46:22 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F1436EACACCB0438E594C05D12C0@phx.gbl>
Message-ID: <000701c54670$16ac9de0$820040d5@hblaptop>

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Ali -
> Sent: Thursday, April 21, 2005 1:28 PM
> To: hb@maths.lth.se
> Cc: r-devel@stat.math.ethz.ch
> Subject: RE: [Rd] Overloading methods in R
> 
> 
> Henrik,
> 
> Thanks for a reply as the author of the package. I understand 
> that you 
> people are interested in discussing this COOP-FOOP fight, 
> however, the 
> original question of this thread is all forgotton. So, I declare the 
> question again:
> 
> -> How to overload methods in classes created by R.oo package? <-
> 
> I even sent you this question by the email provided in the 
> package, but still no answer!

[That one got stuck in my spam filter; I've sent you a reply just before
seing this one. I'll paste th?t answer here too, if someone else is interest
or can add to the topic.]

Unfortunately, there is no immediate solution to this in the R language;
neither in S3 nor S4. The problem as is basically that you can only have one
generic function and that all methods dispatch by this generic function are
required to have the same arguments. I've been trying to get a discussion on
this problem, because I see the problem of two people creating two
independent package containing generic functions of the same name but
different arguments - that won't work today (at least not well). [namespaces
help a bit, though]

However, in S3 you can create a "generic" generic function by not specifying
arguments but only '...' - this way any methods can take any arguments (and
you don't force your argument names onto other developer's). Example:

foo <- function(...) UseMethodS3("foo")

foo.ClassA <- function(object, ...) { <code> }
foo.ClassB <- function(x, y, ...) { <code> }

and so on. This will *not* solve your problem of have overloaded methods in
the same class [using COOP thinking]. That is not possible to do, what I
understand. The only way I can think of is to have an ad hoc method which in
turn checks the arguments and dispatch on them. 

foo.ClassA <- function(...) {
  args <- list(...);
  # Investigate names(args) and lapply(args, FUN=class) for further
dispatching
  # to "private" methods .foo_x.ClassA(...), .foo_x_y.ClassA(...). 
}

(This is inline with what Gabor Grothendieck outlined.) However, I am not
sure if the further methods dispatching with NextMethod() will work. You
probably want to define generic functions for .foo_x() and .foo_x_y() so
they in turn can be overloaded by subclasses.

If you figure a good schema for the above, maybe it can be made automatic so
that one can have a

setOverloadMethodS3("foo", "ClassA", function(object, ...) { <code> })
setOverloadMethodS3("foo", "ClassA", function(x, y, ...) { <code> })

to do the above. That would require some inspection of the arguments, but
that is not hard using formals().

So, the above is just a sketch that might or might not work. I think you
best shot is indeed to use S3, because it is a bit more flexible; S4 is
probably too rigid for this purpose.

BTW, I think it would be nice if you can develope an easy way to define
wrappers for C++ and other similar language! [Just don't reinvent the
wheel.]
 
> I am trying to wrap some C++ class into R, so, in the way that you 
> described, I am trying to wrap some COOP 'things' by some 
> FOOP 'things'. 
> Although there are some packages in R that already wrapped 
> some C++ classes 
> into R, none of them kept the originality of the wrapped 
> classes. That is, 
> the original C++ classes are customised and dissolved to R 
> functions. There 
> is nothing wrong with doing this, but, I am wrapping a few 
> hundered C++ 
> classes automatically and apparently it is not possible to 
> customise each of 
> them.
> 
> The good thing about R.oo is that it is a trouble-less 
> interface between 
> COOP and FOOP. In fact, I have already used the package 
> successfully to 
> generate S3 classes from C++ *automatically*. The only big 
> issue that I have 
> with it is that R.oo overwrites overloaded methods and, to keep the 
> originality of the C++ class and bein nice to the end user, I 
> don't want to 
> change the name of the overloaded functions. Also there is 
> this point that 
> sometime in feature S3 classes will become completely 
> obsolete and new 
> packages shouldn't be based on it. So it would be nice to 
> have a 'S4-R.oo'.

I certainly hope S3 will not be obsolete on day and if it is every planned I
certainly would to see a real and sensible open discussion on this long
before being done! [You already know my standpoint here; S3 and S4
complement, not fight, each other]

> Finally, I remind the package author about the original question:
> 
> - How to overload methods in classes created by R.oo package?

So answered aboved.

> with one more question that I add it right now:
> 
> - Why R.00 is not upgraded to S4?

Indeed, I know that Nathan Whitehouse worked on this, see
http://maths.newcastle.edu.au/~rking/R/devel/03b/0584.html. I do not know
the current status of it, but I think he wrote some "white papers" on the
topic. I don't know where and how many they are. There might be something in
the http://www.rho-project.org project.
 
Best wishes

Henrik

> and I hope we have some 'answer'.
> 
> 
> -Ali
> 
> 
> >Hi. Some clarification on R.oo:
> >
> > > -----Original Message-----
> > > From: r-devel-bounces@stat.math.ethz.ch 
> > > [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of 
> A.J. Rossini
> > > Sent: Wednesday, April 20, 2005 6:21 PM
> > > To: Ali -
> > > Cc: r-devel@stat.math.ethz.ch
> > > Subject: Re: [Rd] Overloading methods in R
> > >
> > >
> > > R.oo tries to implement an old-fashioned OO system as 
> found in Java, 
> > > Python, C++, etc.  R's S4 methods implement a nice modern system 
> > > based on the generic function approach , dispatch on argument 
> > > signatures, which is different.
> >
> >I would call them different, rather than old and modern - 
> each kind has 
> >its own use.
> >
> >To the details:
> >It is the Object class that is related to Java & co; the 
> setMethodS3() 
> >and
> >setConstructorS3() methods are orthogonal and just 
> userfriendly wrappers to
> >creating functions manually.
> >
> >The main purpose of Object is provide *reference variables*, 
> with the 
> >main purpose to save memory! This is done by utilizing environment, 
> >which is standard R code, no ugly hacks are used. The Object class 
> >defines operators "$" and "$<-" (and a few others) to access 
> variables 
> >within the environment, which is unique to each instance of class 
> >Object. Indeed, there was a similar feature added in R 
> v1.9.0 (or was 
> >it v2.0.0) to the environment variable; "$" and "$<-" wraps up get() 
> >and assign() methods for easy use. For an object Object, the 
> >environment is in a list structure, contrary to being an environment 
> >directly. The reason for this is that attr(), save() and load() on 
> >environments does (did?) not work as you would expect, cf. 
> >https://stat.ethz.ch/pipermail/r-devel/2002-October/025197.html.
> >
> >The the Object class defines some other methods to simplify 
> life, and 
> >yes, to imitate Java in the sense that it is convenient to 
> inherit from 
> >one single root Class. It does not allow multiple 
> inheritance (although 
> >you can update the class attributes yourself if you wish too).
> >
> >To differ between OOP in Java and S4/Dylan, I prefer to refer to the 
> >former as class-object-oriented programming (COOP) and the latter as
> >function-object-oriented programming (FOOP). Then, comparing 
> COOP style 
> >with
> >FOOP style is a bit like comparing peas to apples. I would say that 
> >choosing
> >COOP or FOOP is a design issue that has to do what you are trying to
> >implement and not a
> >once-in-a-lifetime/I-want-to-belong-to-this-group-of-people 
> decision. For
> >what I am working on, I found that higher level 
> implementation, where it is
> >clear that a method "belongs" to a class, is easier using 
> COOP. Classes for
> >statistical and mathematical modelling, where functions does 
> not belong to 
> >a
> >specific object, is probably better i FOOP. So, please do 
> not rule out one
> >for the other!
> >
> >The setMethodS3() is a wrapper to automatically test for generic and
> >default
> >functions and create generic functions when needed etc. So
> >
> >setMethodS3("foo", "MyClass", function(object, ...) {
> >   #something
> >})
> >
> >replaces things like
> >
> >if (exists("foo.MyClass", mode="function"))
> >   warning/stop("Replacing foo.MyClass")
> >
> >if (exists("foo", mode="function") && !"not a generic function")
> >   try to rename foo() to foo.default(), but only if foo.default()
> >   does not already exists.
> >
> >... and so on until you can safely write
> >
> >foo.MyClass <- function(object, ...) {
> >   # something
> >}
> >
> >setConstructorS3() is basically like the above, but it does 
> not create 
> >a generic function nor a class specific method, but a 
> "plain" function
> >
> >setConstructorS3("MyClass", function(args, ...) {
> >   # Something
> >}
> >
> >to get
> >
> >MyClass <- function(args, ...) {
> >   # Something
> >}
> >
> >with check for naming conflicts etc.
> >
> >Cheers
> >
> >Henrik Bengtsson
> >(author of R.oo)
> >
> > > While the R documentation for S4 classes is quite useful 
> (spanning 
> > > the green book, the BioC developer help pages, V&R's book on 
> > > programming, and some other papers), I've found that for a nice 
> > > background, Paul Graham's ANSI Lisp book, and in particular the 
> > > nicely written chapter on CLOS, provides a nice 
> introduction to the 
> > > thought process.
> > >
> > > With respect to the R.oo package, the author might be the best 
> > > source for that.
> > >
> > > Another package which you might take a look at is the 
> proto package, 
> > > which provides prototype object-orientation similar to 
> that found in 
> > > XLispStat, and also might help with what you are trying to do.
> > > However, I suspect that learning about the S4 system will
> > > provide more benefit in the future.
> > >
> > > best,
> > > -tony
> > >
> > > On 4/20/05, Ali - <saveez@hotmail.com> wrote:
> > > > Sean,
> > > >
> > > > Thanks, but, I am actually talking about overloading
> > > 'methods' and not
> > > > 'functions', or you may want to answer this question: How
> > > to overload
> > > > methods in classes created by R.oo package?
> > > >
> > > > >
> > > > >On Apr 20, 2005, at 8:16 AM, Ali - wrote:
> > > > >
> > > > >>(1) It seems to me that, generally, in R it is not 
> possible to 
> > > > >>overload functions. Is that right?
> > > > >>
> > > > >>(2) Assuming that the above is true, or partially true,
> > > is there any
> > > > >>extra packages to handle overloading in R?
> > > > >>
> > > > >>(3) Assuming (1) is TRUE and (2) is FALSE, can anyone
> > > provide some
> > > > >>advice on developing some function that understand what the 
> > > > >>arguments  are and then calls the right overloaded function?
> > > > >>
> > > > >>It would be something like this:
> > > > >>
> > > > >>overloadedFunction1 <- function(x) {};
> > > > >>
> > > > >>overloadedFunction2 <- function(x, y) {};
> > > > >>
> > > > >>theFunction <- function(...)
> > > > >>{
> > > > >>   # How to identify ... and call the right 
> overloaded function? 
> > > > >>}
> > > > >>
> > > > >
> > > > >Ali,
> > > > >
> > > > >You are probably interested in "methods".  Functions can
> > > have different
> > > > >"methods" depending on what the arguments and their types
> > > are.  A first
> > > > >place to look is:
> > > > >
> > > >
> > > 
> >http://cran.r-project.org/doc/manuals/R-exts.html#Generic-functions
> > > >-
> > > > >and-methods
> > > > >
> > > > >Sean
> > > > >
> > > >
> > > > ______________________________________________
> > > > R-devel@stat.math.ethz.ch mailing list 
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >
> > >
> > >
> > > --
> > > best,
> > > -tony
> > >
> > > "Commit early,commit often, and commit in a repository 
> from which we 
> > > can easily roll-back your mistakes" (AJR, 4Jan05).
> > >
> > > A.J. Rossini
> > > blindglobe@gmail.com
> > >
> > > ______________________________________________
> > > R-devel@stat.math.ethz.ch mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> > >
> >
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>

From ripley at stats.ox.ac.uk  Thu Apr 21 15:38:08 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Apr 21 15:38:17 2005
Subject: [Rd] print.data.frame(), wrong column names alignement,
	UTF-8 (PR#7804)
Message-ID: <20050421133808.C8401A1FD@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-1314679168-1114090679=:19546
Content-Type: TEXT/PLAIN; charset=iso-8859-1; format=flowed
Content-Transfer-Encoding: QUOTED-PRINTABLE

Thank you for the report (which has to be viewed in UTF-8 ...).
That was overlooked (and did not crop up in beta testing): We will fix=20
for R-patched shortly.

On Thu, 21 Apr 2005 cyril.humbert@univ-mlv.fr wrote:

> Hello,
>
> When a data.frame contains column names with accentued characters
> (UTF8 encoded), the alignement of the column names is wrong (extra
> spaces inserted).
>
> For example : ------------------------------------------------
>
>> Sys.getlocale()
> [1] "LC_CTYPE=3Dfr_FR.UTF-8@euro;LC_NUMERIC=3DC;LC_TIME=3Dfr_FR.UTF-8@eur=
o;LC_COLLATE=3Dfr_FR.UTF-8@euro;LC_MONETARY=3Dfr_FR.UTF-8@euro;LC_MESSAGES=
=3Dfr_FR.UTF-8@euro;LC_PAPER=3DC;LC_NAME=3DC;LC_ADDRESS=3DC;LC_TELEPHONE=3D=
C;LC_MEASUREMENT=3DC;LC_IDENTIFICATION=3DC"
>
>> print (data.frame(aaaa=3D1, b=3D2, c=3D3)) # (ok)
>  aaaa b c
> 1    1 2 3
>
>
>> print (data.frame(=C3=A9=C3=A9=C3=A9=C3=A9=3D1, b=3D2, c=3D3)) # (extra =
blanks)
>  =C3=A9=C3=A9=C3=A9=C3=A9 b c
> 1        1 2 3
>
> --------------------------------------------------------------
>
> This is probably due to fact that the number of white spaces
> to insert between the columns is computed using the length
> of the column names (in bytes) instead of their width (in
> characters), which are different in the example above.
>
> The problem is the same (extra spaces inserted) with
> print.data.frame(..., right =3D FALSE).
>
> Thanks,
> Cyril
>
>
> --please do not edit the information below--
>
> Version:
> platform =3D i386-pc-linux-gnu
> arch =3D i386
> os =3D linux-gnu
> system =3D i386, linux-gnu
> status =3D
> major =3D 2
> minor =3D 1.0
> year =3D 2005
> month =3D 04
> day =3D 18
> language =3D R
>
> Search Path:
> .GlobalEnv, package:methods, package:stats, package:graphics, package:grD=
evices, package:utils, package:datasets, Autoloads, package:base
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

--=20
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-1314679168-1114090679=:19546--

From saveez at hotmail.com  Thu Apr 21 16:03:57 2005
From: saveez at hotmail.com (Ali -)
Date: Thu Apr 21 16:04:05 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <000701c54670$16ac9de0$820040d5@hblaptop>
Message-ID: <BAY17-F340FDF8018D96F0C3A37FDD12C0@phx.gbl>

Thanks a lot for the reply Henrik.

I do not know what was the motivation of R developers to go for yet another 
OO design, but I wish the designers would have thought of ways to interface 
this design to the other designs.

As a wrapper developer, I like packages like R.oo not because it uses S3, 
but for this reason that it 'hides' the OO design of R -- I don't mind if 
the hidden design is S3, S4 or maybe S5!


>However, in S3 you can create a "generic" generic function by not 
>specifying
>arguments but only '...' - this way any methods can take any arguments (and
>you don't force your argument names onto other developer's).

So why did they go a step backward in S4 and remov this feature?

>
>So, the above is just a sketch that might or might not work. I think you
>best shot is indeed to use S3, because it is a bit more flexible; S4 is
>probably too rigid for this purpose.

It seems to me by making the parser a bit less dynamic and putting some 
limitations this could be done.

>BTW, I think it would be nice if you can develope an easy way to define
>wrappers for C++ and other similar language! [Just don't reinvent the
>wheel.]

I assume you mean C++ wrappers for R. I believe before touching a project 
like that, first some issues must be resolved in R. The problem is not how 
to automate the parser, the problem is that OO design of R lacks some 
important equivalents of OO designs like C++. Another problem could be that 
some R developers believe that the previous is not a problem :) Once a 
flexible and stable interface between the two designs is estabilished, 
parsing may be perfomed in the classical way.

From tkeitt at mail.utexas.edu  Thu Apr 21 17:54:02 2005
From: tkeitt at mail.utexas.edu (Tim Keitt)
Date: Thu Apr 21 17:58:46 2005
Subject: [Rd] Limitations of generic functions
Message-ID: <1114098842.15798.14.camel@fosteri.keittlab.net>

I think the issue is not whether C++/R OO models are better. R serves a
different role in computing than does C++. In my experience, simply
projecting (cloning) a C++ interface directly into R rarely provides
satisfactory results. Figure out what you want to do in R. Encapsulate
the appropriate abstractions using S4 methods and then figure out which
services you want to hand off to the C++ libraries. The low-level
manipulation of R's internal data structures can then be done in C++ in
your extension. Emulating C++ code in R is not much fun.

Ciao,
THK

PS. Sorry for the foo bar quoting. I'm subscribed to the digest. -- T.

> Message: 26
> Date: Thu, 21 Apr 2005 09:44:34 +0000
> From: "Ali -" <saveez@hotmail.com>
> Subject: [Rd] Limitations of generic functions
> To: r-devel@stat.math.ethz.ch
> Message-ID: <BAY17-F197A50240015116B894904D12C0@phx.gbl>
> Content-Type: text/plain; format=flowed
> 
> (1) Assume we have some automatic C++ wrapper which , briefly, reads
> the C++ 
> files and generates some R files in which the equivalent of the C++
> classes 
> are reconstructed.
> 
> (2) As the OO design of R is different to that of C++, some isses
> exist when 
> creating an interface between these two systems. (I said these two
> are 
> 'different', I didn't say which one is better or which one is uglier.
> So 
> please save the posts on criticising the designs for somewhere else. I
> am 
> trying to make these two designs talk to each other without judging
> them.)
> 
> (3) One of these issues is about handling overloaded member functions
> in C++ 
> in the form of R classes. Following the discussion followed by my
> previous 
> post, I have decided to wrap the C++ in the form of S4 classes.
> 
> (4) Some more assumptions:
> 
>     (a) A C++ class may have any arbitrary number of overloaded
> functions 
> each of them have some arbitrary number of arguments.
> 
>     (b) To create the equivalent 'overloaded functions' in R, we need
> to 
> have a generic function with several methods. The arguments
> (signature) of 
> each of these methods are determined by the generic function.
>     (c) In order to make the automatic wrapper as general as possible,
> it 
> should not know about the arguments of the overloaded functions.
> 
> (5) And finally the question: How to define the generic function so
> that it 
> covers any unknown arguments of its methods? Apparently simply using
> '...' 
> does not work.

-- 
Tim Keitt
Section of Integrative Biology
http://www.keittlab.org/

From blindglobe at gmail.com  Thu Apr 21 18:27:21 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Thu Apr 21 18:27:30 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F340FDF8018D96F0C3A37FDD12C0@phx.gbl>
References: <000701c54670$16ac9de0$820040d5@hblaptop>
	<BAY17-F340FDF8018D96F0C3A37FDD12C0@phx.gbl>
Message-ID: <1abe3fa90504210927249f5829@mail.gmail.com>

On 4/21/05, Ali - <saveez@hotmail.com> wrote:
> Thanks a lot for the reply Henrik.
> 
> I do not know what was the motivation of R developers to go for yet another
> OO design, but I wish the designers would have thought of ways to interface
> this design to the other designs.

Depends on which OO design you are coming from, as I mentioned before.

You are of course free to develop whatever you like, but trying to
drive a screw with a hammer is generally frowned on, when you've
already been given a powerful electric screwdriver.  It's just a
matter of learning about slightly different tools.

Of course, the amazing thing about open source is that you can do
almost anything you want with it, and prove the experts wrong!

best,
-tony

From nlwhitehouse at yahoo.com  Thu Apr 21 18:37:30 2005
From: nlwhitehouse at yahoo.com (Nathan Whitehouse)
Date: Thu Apr 21 18:37:38 2005
Subject: [Rd] Objects in R
Message-ID: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>


Hi,
  A few comments from a fairly experienced R user who
worked for several years on a R-based bioinformatics
analysis framework.

  I don't want to misrepresent anyone's views, but...

  There are real disadvantages to the
"objects-as-C-structs" and functions/methods which
"mutate" based on argument type. i.e. S4.

  (1)Novices simply don't understand it.  Students are
trained in "standard" object-oriented technique and
this wonkish offshoot(puritanical functional
programming) just increases the information costs to
using R and thus decreases the demand.

  (2)Large frameworks benefit from
serializable/storable objects which contain both
functionality and modifiable values.  S4 stores
"class" information and R.oo does not upon
"save()"ing, but there are still real hindrances to
"trading" objects, which is -extraordinarily-
important in creating industrial-variety R-based
analysis.
  The classical example in my mind is the difficulties
in implementing a "visitor" pattern in S4.  

  (3)The absence of references means for large
datasets and long "analysis flows," there is (1)a
hideous amount of memory used storing each predecessor
analysis or (2)there are awkward "references" that
I've seen used like storing the name of the reference
object in a data slot.
  I find the use of environments in R.oo as opposed to
the glorified LISTSXP of S4 to be a satisfying way
around this.

  S4 is a nice step forward.  But R should be open to
further evolution.  The design choices for S4 and the
reasons behind abandoning OOP have never been
adequately justified in my knowledge.  Instead most
inquiries have been met by a Sphinx-like silence by
the core community.

  But the hindrances faced by our friend Ali are
common, and even in packages maintained by experienced
R developers, S4 is implemented shall we say curiously
as per the specs.
  Clearly OOP and R.oo are not the final answer.  But
some serious discussion about why packages like R.oo
which "layer" onto the standard functional R are
inappropriate is in order.

  It would be great to see R emerge from its niche
audience.  I believe that would aid statisticians and
programmers.  However, a little bit more transparency
and something beyond a categorical "we just don't like
that way of doing things" would go a long way towards
growing the base community of R.
 
  Cheers,
  Nathan Whitehouse
  Formerly of Baylor College of Medicine.

Ali, maybe we R-core members are not decent enough.
But we strongly believe that we don't want to advocate
yet
another object system additionally to the S3 and S4
one,
and several of us have given talks and classes, even
written
books on how to do "decent" object oriented
programming 
`just' with the S3 and/or S4 object system.

No need of additional "oo" in our eyes.
Your main problem is that you assume what "oo" means
{which may
well be true} but *additionally* you also assume that
OO has to
be done in the same way you know it from Python, C++,
or Java..

Since you are new, please try to learn the S4 way,
where methods belong to (generic) functions more than
to classes in some way, particularly if you compare
with other
OO systems where methods belong entirely to classes.
This is NOT true for R (and S-plus) and we don't want
this to
change {and yes, we do know about C++, Python,
Java,... and
their way to do OO}.

Please also read in more details the good advice given
by Tony
Plate and Sean Davis.

Martin Maechler,
ETH Zurich



Nathan Whitehouse
nlwhitehouse@yahoo.com

From rpeng at jhsph.edu  Thu Apr 21 19:01:54 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu Apr 21 19:02:04 2005
Subject: [Rd] Objects in R
In-Reply-To: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>
References: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>
Message-ID: <4267DC82.3000005@jhsph.edu>

One important thing to remember, which I think some more 
experienced programmers may forget, is that R is two things---a 
programming language and an *interactive* system for statistics 
and graphics.  Maintaining the "interactive-ableness" of R may 
have imposed certain design choices.  I personally think the 
current S4 system of generics/methods is quite suitable for both 
the "programming" and "interactive" sides of R.

Just $0.02.

-roger

Nathan Whitehouse wrote:
> Hi,
>   A few comments from a fairly experienced R user who
> worked for several years on a R-based bioinformatics
> analysis framework.
> 
>   I don't want to misrepresent anyone's views, but...
> 
>   There are real disadvantages to the
> "objects-as-C-structs" and functions/methods which
> "mutate" based on argument type. i.e. S4.
> 
>   (1)Novices simply don't understand it.  Students are
> trained in "standard" object-oriented technique and
> this wonkish offshoot(puritanical functional
> programming) just increases the information costs to
> using R and thus decreases the demand.
> 
>   (2)Large frameworks benefit from
> serializable/storable objects which contain both
> functionality and modifiable values.  S4 stores
> "class" information and R.oo does not upon
> "save()"ing, but there are still real hindrances to
> "trading" objects, which is -extraordinarily-
> important in creating industrial-variety R-based
> analysis.
>   The classical example in my mind is the difficulties
> in implementing a "visitor" pattern in S4.  
> 
>   (3)The absence of references means for large
> datasets and long "analysis flows," there is (1)a
> hideous amount of memory used storing each predecessor
> analysis or (2)there are awkward "references" that
> I've seen used like storing the name of the reference
> object in a data slot.
>   I find the use of environments in R.oo as opposed to
> the glorified LISTSXP of S4 to be a satisfying way
> around this.
> 
>   S4 is a nice step forward.  But R should be open to
> further evolution.  The design choices for S4 and the
> reasons behind abandoning OOP have never been
> adequately justified in my knowledge.  Instead most
> inquiries have been met by a Sphinx-like silence by
> the core community.
> 
>   But the hindrances faced by our friend Ali are
> common, and even in packages maintained by experienced
> R developers, S4 is implemented shall we say curiously
> as per the specs.
>   Clearly OOP and R.oo are not the final answer.  But
> some serious discussion about why packages like R.oo
> which "layer" onto the standard functional R are
> inappropriate is in order.
> 
>   It would be great to see R emerge from its niche
> audience.  I believe that would aid statisticians and
> programmers.  However, a little bit more transparency
> and something beyond a categorical "we just don't like
> that way of doing things" would go a long way towards
> growing the base community of R.
>  
>   Cheers,
>   Nathan Whitehouse
>   Formerly of Baylor College of Medicine.
> 
> Ali, maybe we R-core members are not decent enough.
> But we strongly believe that we don't want to advocate
> yet
> another object system additionally to the S3 and S4
> one,
> and several of us have given talks and classes, even
> written
> books on how to do "decent" object oriented
> programming 
> `just' with the S3 and/or S4 object system.
> 
> No need of additional "oo" in our eyes.
> Your main problem is that you assume what "oo" means
> {which may
> well be true} but *additionally* you also assume that
> OO has to
> be done in the same way you know it from Python, C++,
> or Java..
> 
> Since you are new, please try to learn the S4 way,
> where methods belong to (generic) functions more than
> to classes in some way, particularly if you compare
> with other
> OO systems where methods belong entirely to classes.
> This is NOT true for R (and S-plus) and we don't want
> this to
> change {and yes, we do know about C++, Python,
> Java,... and
> their way to do OO}.
> 
> Please also read in more details the good advice given
> by Tony
> Plate and Sean Davis.
> 
> Martin Maechler,
> ETH Zurich
> 
> 
> 
> Nathan Whitehouse
> nlwhitehouse@yahoo.com
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/

From jtk at cmp.uea.ac.uk  Thu Apr 21 20:24:33 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Thu Apr 21 19:28:49 2005
Subject: [Rd] Objects in R
In-Reply-To: <4267DC82.3000005@jhsph.edu>
References: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>
	<4267DC82.3000005@jhsph.edu>
Message-ID: <20050421182433.GC10744@jtkpc.cmp.uea.ac.uk>

On Thu, Apr 21, 2005 at 01:01:54PM -0400, Roger D. Peng wrote:
> One important thing to remember, which I think some more 
> experienced programmers may forget, is that R is two things---a 
> programming language and an *interactive* system for statistics 
> and graphics.  Maintaining the "interactive-ableness" of R may 
> have imposed certain design choices.  I personally think the 
> current S4 system of generics/methods is quite suitable for both 
> the "programming" and "interactive" sides of R.

That's certainly a valid point. A more "standard" kind of
object orientation does not necessarily impair interactive
use, however. Python is no less usable interactively than R,
for example.

Best regards, Jan

> Just $0.02.
> 
> -roger
> 
> Nathan Whitehouse wrote:
> >Hi,
> >  A few comments from a fairly experienced R user who
> >worked for several years on a R-based bioinformatics
> >analysis framework.
> >
> >  I don't want to misrepresent anyone's views, but...
> >
> >  There are real disadvantages to the
> >"objects-as-C-structs" and functions/methods which
> >"mutate" based on argument type. i.e. S4.
> >
> >  (1)Novices simply don't understand it.  Students are
> >trained in "standard" object-oriented technique and
> >this wonkish offshoot(puritanical functional
> >programming) just increases the information costs to
> >using R and thus decreases the demand.

-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk@cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*

From jgentry at jimmy.harvard.edu  Thu Apr 21 20:34:00 2005
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu Apr 21 20:31:32 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F340FDF8018D96F0C3A37FDD12C0@phx.gbl>
Message-ID: <Pine.SOL.4.20.0504211430410.24738-100000@santiam.dfci.harvard.edu>


On Thu, 21 Apr 2005, Ali - wrote:
> >However, in S3 you can create a "generic" generic function by not 
> >specifying
> >arguments but only '...' - this way any methods can take any arguments (and
> >you don't force your argument names onto other developer's).
> So why did they go a step backward in S4 and remov this feature?

I might be misunderstanding what you're getting at here, but if indeed I
do understand this correctly then not only is it still possible in S4 but
I was tought that it was generally considered Good Behavior.

Consider the following code snippet:

> setClass("foo", representation(aStr="character"))
[1] "foo"
> setClass("bar", representation(aStr="character"))
[1] "bar"
> setGeneric("testFun", function(object, ...)
+ standardGeneric("testFun"))
[1] "testFun"
> setMethod("testFun", "foo", function(object, x)
+ print(x))
[1] "testFun"
> setMethod("testFun", "bar", function(object, a, b, c)
+ print(a+b+c))
[1] "testFun"
> z <- new("foo", aStr="")
> x <- new("bar", aStr="")
> testFun(z, "blah")
[1] "blah"
> testFun(x, 1, 2, 3)
[1] 6

Here I've defined a generic 'testFun' and assigned it the '...' argument
(note that you could still specify required arguments,
e.g. 'function(object, anArg, anotherArg, ...)' in the segGeneric
command).  Then when I use setMethod(s) for the two classes I am able to
specify differing sets of arguments for each class.

From saveez at hotmail.com  Thu Apr 21 21:06:25 2005
From: saveez at hotmail.com (Ali -)
Date: Thu Apr 21 21:06:35 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <Pine.SOL.4.20.0504211430410.24738-100000@santiam.dfci.harvard.edu>
Message-ID: <BAY17-F25B1871E5EAA74B9424957D12C0@phx.gbl>


>
>On Thu, 21 Apr 2005, Ali - wrote:
> > >However, in S3 you can create a "generic" generic function by not
> > >specifying
> > >arguments but only '...' - this way any methods can take any arguments 
>(and
> > >you don't force your argument names onto other developer's).
> > So why did they go a step backward in S4 and remov this feature?
>
>I might be misunderstanding what you're getting at here, but if indeed I
>do understand this correctly then not only is it still possible in S4 but
>I was tought that it was generally considered Good Behavior.
>

I guess the context says you cannot have something like this in S4:

>setGeneric("testFun", function(...)
+ standardGeneric("testFun"))

From tplate at blackmesacapital.com  Thu Apr 21 21:11:08 2005
From: tplate at blackmesacapital.com (Tony Plate)
Date: Thu Apr 21 21:12:12 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F1436EACACCB0438E594C05D12C0@phx.gbl>
References: <BAY17-F1436EACACCB0438E594C05D12C0@phx.gbl>
Message-ID: <4267FACC.9050001@blackmesacapital.com>

Ali - wrote:
> Henrik,
> 
> [snip] 
 >
> Finally, I remind the package author about the original question:
> 
> - How to overload methods in classes created by R.oo package?
> [snip]

Maybe you missed it in the flurry of messages, but did the idea 
suggested by Gabor Grothendick not suit your needs?  I don't know the 
R.oo package, but Gabor's idea worked with the S3 class system, and just 
required some easily programmable syntactic processing to generate the 
method names.  (Basically the idea was that the generic function would 
dynamically create a class for its first argument, which consisted of 
the classes of all the arguments appended together.  If there is little 
inheritance structure, this should work fine.)

cheers,

Tony Plate

From veraf at stat.sc.edu  Thu Apr 21 21:16:23 2005
From: veraf at stat.sc.edu (veraf@stat.sc.edu)
Date: Thu Apr 21 21:16:32 2005
Subject: [Rd] Plots with lots of points (PR#7805)
Message-ID: <20050421191623.8B398A20C@slim.kubism.ku.dk>

Full_Name: Francisco Vera
Version: 2.1.0
OS: Windows XP
Submission from: (NULL) (129.252.16.42)


I have this time series with 96000 data points which I am using R to analyze.
The plots produced by some functions (like stl) were working fine in version
2.0.1, but the same plots are causing my machine to stop working all together in
version 2.1.0.

After trying several times, I uninstalled version 2.1.0 and install again 2.0.1,
and the plots worked fine. So I think there is a bug introduced in version
2.1.0.

Thanks

From jgentry at jimmy.harvard.edu  Thu Apr 21 21:22:25 2005
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu Apr 21 21:19:54 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F25B1871E5EAA74B9424957D12C0@phx.gbl>
Message-ID: <Pine.SOL.4.20.0504211520200.24738-100000@santiam.dfci.harvard.edu>


On Thu, 21 Apr 2005, Ali - wrote:
> I guess the context says you cannot have something like this in S4:
> >setGeneric("testFun", function(...)
> + standardGeneric("testFun"))

But what is wrong with:

setGeneric("testFun", function(object, ...))

Keeping in mind that 'object' is the actual instantiated object of the
class which you wish to operate on.  I guess I don't see how that aspect
is a problem?

From hb at maths.lth.se  Thu Apr 21 21:25:36 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu Apr 21 21:25:53 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <4267FACC.9050001@blackmesacapital.com>
Message-ID: <000601c546a7$e624c7a0$ab0040d5@hblaptop>

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Tony Plate
> Sent: Thursday, April 21, 2005 9:11 PM
> To: Ali -
> Cc: hb@maths.lth.se; r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] Overloading methods in R
> 
> 
> Ali - wrote:
> > Henrik,
> > 
> > [snip]
>  >
> > Finally, I remind the package author about the original question:
> > 
> > - How to overload methods in classes created by R.oo package? [snip]
> 
> Maybe you missed it in the flurry of messages, but did the idea 
> suggested by Gabor Grothendick not suit your needs?  I don't know the 
> R.oo package, but Gabor's idea worked with the S3 class 
> system, and just 

FYI: R.oo is just defining methods and lets S3/UseMethod do the dispatching.

Cheers

Henrik

> required some easily programmable syntactic processing to 
> generate the 
> method names.  (Basically the idea was that the generic 
> function would 
> dynamically create a class for its first argument, which consisted of 
> the classes of all the arguments appended together.  If there 
> is little 
> inheritance structure, this should work fine.)
> 
> cheers,
> 
> Tony Plate
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>

From hb at maths.lth.se  Thu Apr 21 21:32:49 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu Apr 21 21:33:03 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <Pine.SOL.4.20.0504211520200.24738-100000@santiam.dfci.harvard.edu>
Message-ID: <000701c546a8$e7d3e1c0$ab0040d5@hblaptop>

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Jeff Gentry
> Sent: Thursday, April 21, 2005 9:22 PM
> To: Ali -
> Cc: r-devel@stat.math.ethz.ch
> Subject: RE: [Rd] Overloading methods in R
> 
> 
> 
> On Thu, 21 Apr 2005, Ali - wrote:
> > I guess the context says you cannot have something like this in S4:
> > >setGeneric("testFun", function(...)
> > + standardGeneric("testFun"))
> 
> But what is wrong with:
> 
> setGeneric("testFun", function(object, ...))

Naming conflicts, may be the problem. You have that generic in your package,
but I might, without know about yours, and I write 

 setGeneric("testFun", function(x, ...))

in my package, and then a third person that we don't know of, is loading
both of our packages. Ouch! Indeed, this do happens. 

I would be ok with the above, if everyone agreed to use 'object' as the
first argument - but then you have plot(x, ...) and so on. Also, how should
you treat default functions not taking any arguments, e.g. traceback()?
Until then I stick with testFun <- function(...) UseMethod("foo") whenever
possible.

Cheers

Henrik
 
> Keeping in mind that 'object' is the actual instantiated 
> object of the class which you wish to operate on.  I guess I 
> don't see how that aspect is a problem?
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>

From jgentry at jimmy.harvard.edu  Thu Apr 21 21:37:12 2005
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu Apr 21 21:34:41 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <000701c546a8$e7d3e1c0$ab0040d5@hblaptop>
Message-ID: <Pine.SOL.4.20.0504211536290.24738-100000@santiam.dfci.harvard.edu>


On Thu, 21 Apr 2005, Henrik Bengtsson wrote:
> > But what is wrong with:
> > setGeneric("testFun", function(object, ...))
> Naming conflicts, may be the problem. You have that generic in your package,
> but I might, without know about yours, and I write 
>  setGeneric("testFun", function(x, ...))
> in my package, and then a third person that we don't know of, is loading
> both of our packages. Ouch! Indeed, this do happens. 

True, but isn't that what namespaces are for?

From petzoldt at rcs.urz.tu-dresden.de  Thu Apr 21 22:22:15 2005
From: petzoldt at rcs.urz.tu-dresden.de (Thomas Petzoldt)
Date: Thu Apr 21 22:22:21 2005
Subject: [Rd] Objects in R
In-Reply-To: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>
References: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>
Message-ID: <42680B77.9000302@rcs.urz.tu-dresden.de>

Hi Nathan,

regarding the use of environments as the
basis of objects, note that in R 2.1.0 the
CRAN 'proto' package provides a facility for object
oriented programming that uses environments
as the underlying implementation.

Unlike the OO models discussed here, it
is based on the prototype model of
object oriented programming which is one
in which classes are not an atomic
concept (though it is powerful enough to
readily express them if one wants).

Thomas Petzoldt

From p.dalgaard at biostat.ku.dk  Thu Apr 21 22:43:21 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu Apr 21 22:43:30 2005
Subject: [Rd] Plots with lots of points (PR#7805)
In-Reply-To: <20050421191623.8B398A20C@slim.kubism.ku.dk>
References: <20050421191623.8B398A20C@slim.kubism.ku.dk>
Message-ID: <x2mzrr509i.fsf@turmalin.kubism.ku.dk>

veraf@stat.sc.edu writes:

> Full_Name: Francisco Vera
> Version: 2.1.0
> OS: Windows XP
> Submission from: (NULL) (129.252.16.42)
> 
> 
> I have this time series with 96000 data points which I am using R to analyze.
> The plots produced by some functions (like stl) were working fine in version
> 2.0.1, but the same plots are causing my machine to stop working all together in
> version 2.1.0.
> 
> After trying several times, I uninstalled version 2.1.0 and install again 2.0.1,
> and the plots worked fine. So I think there is a bug introduced in version
> 2.1.0.

Could well be, but you're much more likely to find a volunteer to fix
it for you if you provide a reproducible example.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From saveez at hotmail.com  Thu Apr 21 23:04:54 2005
From: saveez at hotmail.com (Ali -)
Date: Thu Apr 21 23:05:02 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <4267FACC.9050001@blackmesacapital.com>
Message-ID: <BAY17-F69C404BCA375CB5704ABCD12C0@phx.gbl>


>>
>>- How to overload methods in classes created by R.oo package?
>[snip]
>
>Maybe you missed it in the flurry of messages, but did the idea suggested 
>by Gabor Grothendick not suit your needs?

I had to abstract the question in a setntence this time to prevent it to be 
missed again 'in the flurry of messages'.

Gabor Grothendick's example does work for S3 and your own example does work 
for S4 but none of them answer the problem I declared a few times. Both 
examples work fine for an 'specific' case. I am looking for a general 
solution to use it with a parser as part of an automatic  wrapper.

When wrapping some arbitrary C++ classes, we don't know

- how many functions are overloaded in a class
- how many arguments each function has
- what class is each argument of each function

Implementing the wrapper in the way that you and Gabor Grothendick suggest 
requires a lot of 'if' and 'missing' making it too elaborated.

Now if anyone has any elegant solutions for some 'automatic' implementation 
of overloaded methods in R, I am open to suggestions.

From ggrothendieck at gmail.com  Fri Apr 22 00:49:03 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri Apr 22 00:55:52 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F69C404BCA375CB5704ABCD12C0@phx.gbl>
References: <4267FACC.9050001@blackmesacapital.com>
	<BAY17-F69C404BCA375CB5704ABCD12C0@phx.gbl>
Message-ID: <971536df050421154970feeadf@mail.gmail.com>

On 4/21/05, Ali - <saveez@hotmail.com> wrote:
> 
> >>
> >>- How to overload methods in classes created by R.oo package?
> >[snip]
> >
> >Maybe you missed it in the flurry of messages, but did the idea suggested
> >by Gabor Grothendick not suit your needs?
> 
> I had to abstract the question in a setntence this time to prevent it to be
> missed again 'in the flurry of messages'.
> 
> Gabor Grothendick's example does work for S3 and your own example does work
> for S4 but none of them answer the problem I declared a few times. Both
> examples work fine for an 'specific' case. I am looking for a general
> solution to use it with a parser as part of an automatic  wrapper.
> 
> When wrapping some arbitrary C++ classes, we don't know
> 
> - how many functions are overloaded in a class
> - how many arguments each function has
> - what class is each argument of each function
> 
> Implementing the wrapper in the way that you and Gabor Grothendick suggest
> requires a lot of 'if' and 'missing' making it too elaborated.



Here is another example which hopefully shows that
there is no limitation on number of arguments,
number of methods and classes.    Here we have
methods with one, two and three arguments and a
variety of classes.

Note that this and the previous examples are not
intended to be complete finished solutions to your
problem but are only illustrative to give you the
idea how to proceed.  Generalizing them should not
be too complex nor inelegant.  Dealing with
vectors of arguments is not that much harder than
dealing with individual arguments in a vector
oriented language like R.


f <- function(...) UseMethod("f", NULL)

f.NULL <- function(...) {
	args <- list(...)
	classes <- sapply(args, class)
	.Class <- paste(classes, collapse = ".")
	NextMethod("f", ...)
}

f.numeric <- function(...) 2 * ..1 
f.numeric.numeric <- function(...) ..1 + ..2
f.character.numeric.Date <- function(...) {
   args <- list(...)
   paste(args[[1]], args[[2]], format(args[[3]], "%Y-%m-%d"))
}
f.default <- function(...) print(list(...))


f(1)   # 2
f(1,2) # 3
f("a", 23, Sys.Date()) # "a 23 2005-04-21"
f()    # list()

From nlwhitehouse at yahoo.com  Fri Apr 22 01:38:08 2005
From: nlwhitehouse at yahoo.com (Nathan Whitehouse)
Date: Fri Apr 22 01:38:17 2005
Subject: [Rd] Objects in R
In-Reply-To: <4267DC82.3000005@jhsph.edu>
Message-ID: <20050421233808.61644.qmail@web30203.mail.mud.yahoo.com>

  I think S4 is certainly ok for the "interactivity"
aspect of R.

  And probably avoiding untraceable references and
preserving clarity was important to preserve R's role
as a "playing-with-data" language.  

  But R can be potentially used for much more than it
is, and therein lies the difficulty.  I think a full
and frank discussion about data structures would be
healthy.   Enunciating the design choices for the
current R object model would be a step in the right
direction.

  Cheers,
  Nathan

> One important thing to remember, which I think some
> more 
> experienced programmers may forget, is that R is two
> things---a 
> programming language and an *interactive* system for
> statistics 
> and graphics.  Maintaining the
> "interactive-ableness" of R may 
> have imposed certain design choices.  I personally
> think the 
> current S4 system of generics/methods is quite
> suitable for both 
> the "programming" and "interactive" sides of R.
> 
> Just $0.02.
> 
> -roger
> 
> Nathan Whitehouse wrote:
> > Hi,
> >   A few comments from a fairly experienced R user
> who
> > worked for several years on a R-based
> bioinformatics
> > analysis framework.
> > 
> >   I don't want to misrepresent anyone's views,
> but...
> > 
> >   There are real disadvantages to the
> > "objects-as-C-structs" and functions/methods which
> > "mutate" based on argument type. i.e. S4.
> > 
> >   (1)Novices simply don't understand it.  Students
> are
> > trained in "standard" object-oriented technique
> and
> > this wonkish offshoot(puritanical functional
> > programming) just increases the information costs
> to
> > using R and thus decreases the demand.
> > 
> >   (2)Large frameworks benefit from
> > serializable/storable objects which contain both
> > functionality and modifiable values.  S4 stores
> > "class" information and R.oo does not upon
> > "save()"ing, but there are still real hindrances
> to
> > "trading" objects, which is -extraordinarily-
> > important in creating industrial-variety R-based
> > analysis.
> >   The classical example in my mind is the
> difficulties
> > in implementing a "visitor" pattern in S4.  
> > 
> >   (3)The absence of references means for large
> > datasets and long "analysis flows," there is (1)a
> > hideous amount of memory used storing each
> predecessor
> > analysis or (2)there are awkward "references" that
> > I've seen used like storing the name of the
> reference
> > object in a data slot.
> >   I find the use of environments in R.oo as
> opposed to
> > the glorified LISTSXP of S4 to be a satisfying way
> > around this.
> > 
> >   S4 is a nice step forward.  But R should be open
> to
> > further evolution.  The design choices for S4 and
> the
> > reasons behind abandoning OOP have never been
> > adequately justified in my knowledge.  Instead
> most
> > inquiries have been met by a Sphinx-like silence
> by
> > the core community.
> > 
> >   But the hindrances faced by our friend Ali are
> > common, and even in packages maintained by
> experienced
> > R developers, S4 is implemented shall we say
> curiously
> > as per the specs.
> >   Clearly OOP and R.oo are not the final answer. 
> But
> > some serious discussion about why packages like
> R.oo
> > which "layer" onto the standard functional R are
> > inappropriate is in order.
> > 
> >   It would be great to see R emerge from its niche
> > audience.  I believe that would aid statisticians
> and
> > programmers.  However, a little bit more
> transparency
> > and something beyond a categorical "we just don't
> like
> > that way of doing things" would go a long way
> towards
> > growing the base community of R.
> >  
> >   Cheers,
> >   Nathan Whitehouse
> >   Formerly of Baylor College of Medicine.
> > 
> > Ali, maybe we R-core members are not decent
> enough.
> > But we strongly believe that we don't want to
> advocate
> > yet
> > another object system additionally to the S3 and
> S4
> > one,
> > and several of us have given talks and classes,
> even
> > written
> > books on how to do "decent" object oriented
> > programming 
> > `just' with the S3 and/or S4 object system.
> > 
> > No need of additional "oo" in our eyes.
> > Your main problem is that you assume what "oo"
> means
> > {which may
> > well be true} but *additionally* you also assume
> that
> > OO has to
> > be done in the same way you know it from Python,
> C++,
> > or Java..
> > 
> > Since you are new, please try to learn the S4 way,
> > where methods belong to (generic) functions more
> than
> > to classes in some way, particularly if you
> compare
> > with other
> > OO systems where methods belong entirely to
> classes.
> > This is NOT true for R (and S-plus) and we don't
> want
> > this to
> > change {and yes, we do know about C++, Python,
> > Java,... and
> > their way to do OO}.
> > 
> > Please also read in more details the good advice
> given
> > by Tony
> > Plate and Sean Davis.
> > 
> > Martin Maechler,
> > ETH Zurich
> > 
> > 
> > 
> > Nathan Whitehouse
> > nlwhitehouse@yahoo.com
> > 
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> 
> -- 
> Roger D. Peng
> http://www.biostat.jhsph.edu/~rpeng/
> 

Nathan Whitehouse
nlwhitehouse@yahoo.com

From saveez at hotmail.com  Fri Apr 22 03:04:40 2005
From: saveez at hotmail.com (Ali -)
Date: Fri Apr 22 03:04:50 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <971536df050421154970feeadf@mail.gmail.com>
Message-ID: <BAY17-F332D1436DE28A72C33D140D12D0@phx.gbl>


>
>
>f <- function(...) UseMethod("f", NULL)
>
>f.NULL <- function(...) {
>	args <- list(...)
>	classes <- sapply(args, class)
>	.Class <- paste(classes, collapse = ".")
>	NextMethod("f", ...)
>}
>
>f.numeric <- function(...) 2 * ..1
>f.numeric.numeric <- function(...) ..1 + ..2
>f.character.numeric.Date <- function(...) {
>    args <- list(...)
>    paste(args[[1]], args[[2]], format(args[[3]], "%Y-%m-%d"))
>}
>f.default <- function(...) print(list(...))
>
>
>f(1)   # 2
>f(1,2) # 3
>f("a", 23, Sys.Date()) # "a 23 2005-04-21"
>f()    # list()


Thanks Gabor! This answers a big part of my question. I am just curious why 
something like this doesn't work in S4:

-------------------------
setGeneric("foo", function(object, ...) standardGeneric("foo"))

foo.NULL <- function(object, ...) {
	args <- list(...)
	classes <- sapply(args, class)
	.Class <- paste(classes, collapse = ".")
}

foo.default <- function(object, ...) paste("wrong args!")

foo.numeric <- function(object, ...) 2 * ..1
foo.numeric.numeric <- function(object, ...) ..1 + ..2

From ggrothendieck at gmail.com  Fri Apr 22 05:11:39 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri Apr 22 05:11:48 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <BAY17-F332D1436DE28A72C33D140D12D0@phx.gbl>
References: <971536df050421154970feeadf@mail.gmail.com>
	<BAY17-F332D1436DE28A72C33D140D12D0@phx.gbl>
Message-ID: <971536df05042120117c4988c9@mail.gmail.com>

On 4/21/05, Ali - <saveez@hotmail.com> wrote: 
> 
> 
> >
> >
> >f <- function(...) UseMethod("f", NULL)
> >
> >f.NULL <- function(...) {
> > args <- list(...)
> > classes <- sapply(args, class)
> > .Class <- paste(classes, collapse = ".")
> > NextMethod("f", ...)
> >}
> >
> >f.numeric <- function(...) 2 * ..1
> >f.numeric.numeric <- function(...) ..1 + ..2
> >f.character.numeric.Date <- function(...) {
> > args <- list(...)
> > paste(args[[1]], args[[2]], format(args[[3]], "%Y-%m-%d"))
> >}
> >f.default <- function(...) print(list(...))
> >
> >
> >f(1) # 2
> >f(1,2) # 3
> >f("a", 23, Sys.Date()) # "a 23 2005-04-21"
> >f() # list()
> 
> Thanks Gabor! This answers a big part of my question. I am just curious 
> why
> something like this doesn't work in S4:
> 
> -------------------------
> setGeneric("foo", function(object, ...) standardGeneric("foo"))
> 
> foo.NULL <- function(object, ...) {
> args <- list(...)
> classes <- sapply(args, class)
> .Class <- paste(classes, collapse = ".")
> }
> 
> foo.default <- function(object, ...) paste("wrong args!")
> 
> foo.numeric <- function(object, ...) 2 * ..1
> foo.numeric.numeric <- function(object, ...) ..1 + ..2
> --------------------------
> 
> 
> On 4/21/05, Ali - <saveez@hotmail.com> wrote: 
> > 
> > 
> > >
> > >
> > >f <- function(...) UseMethod("f", NULL)
> > >
> > >f.NULL <- function(...) {
> > > args <- list(...)
> > > classes <- sapply(args, class)
> > > .Class <- paste(classes, collapse = ".")
> > > NextMethod("f", ...)
> > >}
> > >
> > >f.numeric <- function(...) 2 * ..1
> > >f.numeric.numeric <- function(...) ..1 + ..2
> > >f.character.numeric.Date <- function(...) {
> > > args <- list(...)
> > > paste(args[[1]], args[[2]], format(args[[3]], "%Y-%m-%d"))
> > >}
> > >f.default <- function(...) print(list(...))
> > >
> > >
> > >f(1) # 2
> > >f(1,2) # 3
> > >f("a", 23, Sys.Date()) # "a 23 2005-04-21"
> > >f() # list()
> > 
> > Thanks Gabor! This answers a big part of my question. I am just curious 
> > why
> > something like this doesn't work in S4:
> > 
> > -------------------------
> > setGeneric("foo", function(object, ...) standardGeneric("foo"))
> > 
> > foo.NULL <- function(object, ...) {
> > args <- list(...)
> > classes <- sapply(args, class)
> > .Class <- paste(classes, collapse = ".")
> > }
> > 
> > foo.default <- function(object, ...) paste("wrong args!")
> > 
> > foo.numeric <- function(object, ...) 2 * ..1
> > foo.numeric.numeric <- function(object, ...) ..1 + ..2
> > --------------------------
> 
>  I am not 100% sure I understand what the question is but I think what
> you are looking for is the fact that ... cannot be part of the signature 
> in
> S4. That is ... can be among the method arguments but you can't 
> dispatch on those arguments in S4.
>

	[[alternative HTML version deleted]]

From mbreuer at ecology.uni-kiel.de  Fri Apr 22 10:09:42 2005
From: mbreuer at ecology.uni-kiel.de (mbreuer@ecology.uni-kiel.de)
Date: Fri Apr 22 10:09:49 2005
Subject: [Rd] Bug in Version 2010 (PR#7807)
Message-ID: <20050422080942.6395BA209@slim.kubism.ku.dk>

Dr. Michael 
Breuer                                                                                     
22.04.05
?kologiezentrum der Universit?t Kiel
Olshausenstra?e 75
24118 Kiel

Dear Ladies and Sirs,
After updating the R-Windows-program (binary) by the latest version 
(2010), the R-Scripts that I want to execute are not shown in the 
File-Window anymore. In the former version it worked correct.  However, 
if I call a script by command line, it will be found and intepreted. I 
tried it on two PCs wirh Windows XP Home and Windows XP Professional SP2.

With best regards

M. Breuer

From murdoch at stats.uwo.ca  Fri Apr 22 10:50:36 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri Apr 22 10:50:42 2005
Subject: [Rd] Bug in Version 2010 (PR#7807)
In-Reply-To: <20050422080942.6395BA209@slim.kubism.ku.dk>
References: <20050422080942.6395BA209@slim.kubism.ku.dk>
Message-ID: <4268BADC.4070908@stats.uwo.ca>

mbreuer@ecology.uni-kiel.de wrote:
> Dr. Michael 
> Breuer                                                                                     
> 22.04.05
> ?kologiezentrum der Universit?t Kiel
> Olshausenstra?e 75
> 24118 Kiel
> 
> Dear Ladies and Sirs,
> After updating the R-Windows-program (binary) by the latest version 
> (2010), the R-Scripts that I want to execute are not shown in the 
> File-Window anymore. In the former version it worked correct.  However, 
> if I call a script by command line, it will be found and intepreted. I 
> tried it on two PCs wirh Windows XP Home and Windows XP Professional SP2.


This is not enough information to allow us to try to duplicate your 
error.  Tell us where you keep your scripts, how you start R (the 
starting directory is likely important), and the exact steps you take to 
try to show your scripts.  Without that information your report is too 
vague to act on.

Duncan Murdoch

From smyth at wehi.edu.au  Fri Apr 22 11:17:17 2005
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Fri Apr 22 11:17:34 2005
Subject: [Rd] Infinite degrees of freedom for F-distribution
Message-ID: <6.2.1.2.1.20050422190734.02174a88@imaphost.wehi.edu.au>

This is just a suggestion/wish that it would be nice for the F-distribution 
functions to recognize limiting cases for infinite degrees of freedom, as 
the t-distribution functions already do.

The t-distribution functions recognize that df=Inf is equivalent to the 
standard normal distribution:

 > pt(1,df=Inf)
[1] 0.8413447
 > pnorm(1)
[1] 0.8413447

On the other hand, pf() will accept Inf for df1, but returns the wrong result:

 > pf(1,df1=Inf,df2=1)
[1] 1

whereas the correct limiting value is

 > pchisq(1,df=1,lower.tail=FALSE)
[1] 0.3173105

pf() returns NaN when df2=Inf:

 > pf(1,df1=1,df2=Inf)
[1] NaN
Warning message:
NaNs produced in: pf(q, df1, df2, lower.tail, log.p)

although the correct value is available as

 > pchisq(1,df=1)
[1] 0.6826895


Gordon

 > version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    1.0
year     2005
month    04
day      18
language R
---------------------------------------------------------------------------------------
Dr Gordon K Smyth, Senior Research Scientist, Bioinformatics,
Walter and Eliza Hall Institute of Medical Research,
1G Royal Parade, Parkville, Vic 3050, Australia
Tel: (03) 9345 2326, Fax (03) 9347 0852,
Email: smyth@wehi.edu.au, www: http://www.statsci.org

From ligges at statistik.uni-dortmund.de  Fri Apr 22 11:27:16 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Fri Apr 22 11:27:24 2005
Subject: [Rd] Bug in Version 2010 (PR#7807)
Message-ID: <20050422092716.5ECB2A207@slim.kubism.ku.dk>

Duncan Murdoch wrote:

> mbreuer@ecology.uni-kiel.de wrote:
> 
>> Dr. Michael 
>> Breuer                                                                                     
>> 22.04.05
>> ?kologiezentrum der Universit?t Kiel
>> Olshausenstra?e 75
>> 24118 Kiel
>>
>> Dear Ladies and Sirs,
>> After updating the R-Windows-program (binary) by the latest version 
>> (2010), the R-Scripts that I want to execute are not shown in the 
>> File-Window anymore. In the former version it worked correct.  
>> However, if I call a script by command line, it will be found and 
>> intepreted. I tried it on two PCs wirh Windows XP Home and Windows XP 
>> Professional SP2.
> 
> 
> 
> This is not enough information to allow us to try to duplicate your 
> error.  Tell us where you keep your scripts, how you start R (the 
> starting directory is likely important), and the exact steps you take to 
> try to show your scripts.  Without that information your report is too 
> vague to act on.
> 
> Duncan Murdoch


Looks like it happens with the german (and maybe also other?) 
translation. I'll take a closer look later.

Uwe Ligges



> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From p.dalgaard at biostat.ku.dk  Fri Apr 22 11:36:18 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Apr 22 11:36:26 2005
Subject: [Rd] Infinite degrees of freedom for F-distribution
In-Reply-To: <6.2.1.2.1.20050422190734.02174a88@imaphost.wehi.edu.au>
References: <6.2.1.2.1.20050422190734.02174a88@imaphost.wehi.edu.au>
Message-ID: <x2sm1jkval.fsf@turmalin.kubism.ku.dk>

Gordon Smyth <smyth@wehi.edu.au> writes:

> This is just a suggestion/wish that it would be nice for the
> F-distribution functions to recognize limiting cases for infinite
> degrees of freedom, as the t-distribution functions already do.
> 
> The t-distribution functions recognize that df=Inf is equivalent to
> the standard normal distribution:
> 
>  > pt(1,df=Inf)
> [1] 0.8413447
>  > pnorm(1)
> [1] 0.8413447
> 
> On the other hand, pf() will accept Inf for df1, but returns the wrong result:
> 
>  > pf(1,df1=Inf,df2=1)
> [1] 1
> 
> whereas the correct limiting value is
> 
>  > pchisq(1,df=1,lower.tail=FALSE)
> [1] 0.3173105
> 
> pf() returns NaN when df2=Inf:
> 
>  > pf(1,df1=1,df2=Inf)
> [1] NaN
> Warning message:
> NaNs produced in: pf(q, df1, df2, lower.tail, log.p)
> 
> although the correct value is available as
> 
>  > pchisq(1,df=1)
> [1] 0.6826895
> 
> 
> Gordon
> 
>  > version
>           _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    1.0
> year     2005
> month    04
> day      18
> language R

This is actually a regression. It worked as you suggest in 2.0.1, at
least on Linux. Also, somewhat disturbing,

> pf(1,df1=1,df2=Inf)
[1] NaN
Warning message:
NaNs produced in: pf(q, df1, df2, lower.tail, log.p)
> pf(1,df1=1,df2=99999999)
[1] 0.6826895
> pf(1,df1=1,df2=999999999999)
[1] 0.6826841
> pf(1,df1=1,df2=99999999999999999999)
[1] 0

(notice that the middle case has actually begun to diverge from the
limiting value)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From saveez at hotmail.com  Fri Apr 22 15:10:35 2005
From: saveez at hotmail.com (Ali -)
Date: Fri Apr 22 15:10:45 2005
Subject: [Rd] Overloading methods in R
In-Reply-To: <1abe3fa9050421211121c84665@mail.gmail.com>
Message-ID: <BAY17-F107545CCB23AB102F3DC9BD12D0@phx.gbl>

>From: "A.J. Rossini" <blindglobe@gmail.com>
>
>You are mixing S3 and S4 paradigms.   You want setMethod to define the
>method, not the  FunctionName.ClassOfObject S3 specification.

That just proves my newbie-ness in R programming. I would appreciate it if 
you could provide me the S4 equivalent. According to the documentation in 
the methods package:

"Computations using the notion of 'NULL' class attributes or
of class attributes with multiple class names are not really
compatible with the ideas in the 'methods' package."

So I guess a different approach should be taken in S4?


>On 4/22/05, Ali - <saveez@hotmail.com> wrote:
> >
> > >
> > >
> > >f <- function(...) UseMethod("f", NULL)
> > >
> > >f.NULL <- function(...) {
> > >       args <- list(...)
> > >       classes <- sapply(args, class)
> > >       .Class <- paste(classes, collapse = ".")
> > >       NextMethod("f", ...)
> > >}
> > >
> > >f.numeric <- function(...) 2 * ..1
> > >f.numeric.numeric <- function(...) ..1 + ..2
> > >f.character.numeric.Date <- function(...) {
> > >    args <- list(...)
> > >    paste(args[[1]], args[[2]], format(args[[3]], "%Y-%m-%d"))
> > >}
> > >f.default <- function(...) print(list(...))
> > >
> > >
> > >f(1)   # 2
> > >f(1,2) # 3
> > >f("a", 23, Sys.Date()) # "a 23 2005-04-21"
> > >f()    # list()
> >
> > Thanks Gabor! This answers a big part of my question. I am just curious 
>why
> > something like this doesn't work in S4:
> >
> > -------------------------
> > setGeneric("foo", function(object, ...) standardGeneric("foo"))
> >
> > foo.NULL <- function(object, ...) {
> >         args <- list(...)
> >         classes <- sapply(args, class)
> >         .Class <- paste(classes, collapse = ".")
> > }
> >
> > foo.default <- function(object, ...) paste("wrong args!")
> >
> > foo.numeric <- function(object, ...) 2 * ..1
> > foo.numeric.numeric <- function(object, ...) ..1 + ..2
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
>--
>best,
>-tony
>
>"Commit early,commit often, and commit in a repository from which we can 
>easily
>roll-back your mistakes" (AJR, 4Jan05).
>
>A.J. Rossini
>blindglobe@gmail.com

From macq at llnl.gov  Fri Apr 22 16:34:39 2005
From: macq at llnl.gov (Don MacQueen)
Date: Fri Apr 22 16:34:49 2005
Subject: [Rd] R --gui=none and R --help
Message-ID: <p06210201be8eba691496@[128.115.153.6]>

I noticed something in R --help that needs updating for R 2.1.0

In the changes documentation for R 2.1.0:

  o	BATCH on Unix no longer sets --gui="none" as the X11 module
	is only loaded if needed.

But --gui=none is still documented as acceptable in R --help

[39]% R --version
R 2.1.0 (2005-04-18).
Copyright (C) 2005 R Development Core Team


[40]% R --help

[ output omitted, until]

  -g, --gui=TYPE        Use TYPE as GUI; possible values are 'X11'
                         (default), 'none', 'Tk' and 'gnome'


but,


[41]% R --gui=none
ERROR: unknown GUI none


-Don
-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA

From ligges at statistik.uni-dortmund.de  Fri Apr 22 17:28:30 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Fri Apr 22 17:28:38 2005
Subject: [Rd] Bug in Version 2010 (PR#7807)
Message-ID: <20050422152830.5A0ABA20B@slim.kubism.ku.dk>

ligges@statistik.uni-dortmund.de wrote:

> Duncan Murdoch wrote:
> 
> 
>>mbreuer@ecology.uni-kiel.de wrote:
>>
>>
>>>Dr. Michael 
>>>Breuer                                                                                     
>>>22.04.05
>>>?kologiezentrum der Universit?t Kiel
>>>Olshausenstra?e 75
>>>24118 Kiel
>>>
>>>Dear Ladies and Sirs,
>>>After updating the R-Windows-program (binary) by the latest version 
>>>(2010), the R-Scripts that I want to execute are not shown in the 
>>>File-Window anymore. In the former version it worked correct.  
>>>However, if I call a script by command line, it will be found and 
>>>intepreted. I tried it on two PCs wirh Windows XP Home and Windows XP 
>>>Professional SP2.
>>
>>
>>
>>This is not enough information to allow us to try to duplicate your 
>>error.  Tell us where you keep your scripts, how you start R (the 
>>starting directory is likely important), and the exact steps you take to 
>>try to show your scripts.  Without that information your report is too 
>>vague to act on.
>>
>>Duncan Murdoch
> 
> 
> 
> Looks like it happens with the german (and maybe also other?) 
> translation. I'll take a closer look later.
> 
> Uwe Ligges

Indeed, if you set LANGUAGE=de using the RGui-de.po as shipped with 
R-2.1.0, you won't see any files in that dialog. If you copy the english 
version to the translation, you see ALL files (not only R files as 
expected), and if you leave the translation blank (i.e. the english 
version will be displayed), you get the expected behaviour.

I guess lines such as

     setuserfilter(G_("R files (*.R)\0*.R\0S files (*.q)\0*.q\0All files 
(*.*)\0*.*\0\0"));

in rui.c are casuing the trouble. "S files (*.q)" never appears in the 
*.po(t) file, so it's probably a gettext related problem, but I really 
don't know how to fix this ...


Uwe Ligges

From Robert.McGehee at geodecapital.com  Fri Apr 22 19:03:04 2005
From: Robert.McGehee at geodecapital.com (Robert.McGehee@geodecapital.com)
Date: Fri Apr 22 19:03:11 2005
Subject: [Rd] as.data.frame: Error in "names<-.default" (PR#7808)
Message-ID: <20050422170304.373C8A207@slim.kubism.ku.dk>

Hello,
I found a potential problem in R 2.1.0 (and R 2.0.1)

I expect that

> tmp <- FUN(x1, x2, x3, x4)
> as.data.frame(tmp)

is the same as
> as.data.frame(FUN(x1, x2, x3, x4))

since the tmp variable in this case is unnecessary.

However, below I will demonstrate that under an odd set of conditions, I
can correctly perform as.data.frame(tmp), but not as.data.frame(FUN(x1,
x2, x3, x4)). 

## This code works correctly
FUN <- function(x1, x2, x3, x4) 
     cbind(x1[, 1, 1:2], x1[, 2, 1:2])[, 1]

x1 <- array(1:9, c(3, 3, 3))
tmp <- FUN(x1[1:3, , ], x2 = c("a", "b"), x3 = c("a", "b"), x4 = c("a",
"b"))

## Works correctly
as.data.frame(tmp)  

  tmp
1   1
2   2
3   3


## This (supposedly equivalent) code gives an error

as.data.frame(FUN(x1[1:3,,], x2 = c("a", "b"), x3 = c("a", "b"), x4 =
c("a", "b")))

Error in "names<-.default"(`*tmp*`, value = c("FUN(x1[1:3, , ], x2 =
c(\"a\", \"b\"), x3 = c(\"a\", \"b\"), x4 = c(\"a\", ",  : 
	'names' attribute [2] must be the same length as the vector [1]

Note, that while the extra (unused) arguments in FUN seem unnecessary,
as well as the odd indexing, the problem disappears when I remove the
extraneous values. Unfortunately, I have not found a more elegant way to
present this problem, but hopefully this code will be helpful.

Robert

Robert McGehee
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee@geodecapital.com



This e-mail, and any attachments hereto, are intended for us...{{dropped}}

From Kurt.Hornik at wu-wien.ac.at  Fri Apr 22 20:17:50 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Fri Apr 22 20:17:23 2005
Subject: [Rd] negative p-values from fisher's test (PR#7801)
In-Reply-To: <20050420213135.87D15A1EE@slim.kubism.ku.dk>
References: <20050420213135.87D15A1EE@slim.kubism.ku.dk>
Message-ID: <17001.16334.176316.369109@mithrandir.hornik.net>

>>>>> mnason  writes:

> Full_Name: Martha Nason
> Version: 2.0.1
> OS: Windows XP
> Submission from: (NULL) (137.187.154.154)

> I am running simulations using fisher's test on 2 x c tables and a
> very small p.value from fisher's test (<2.2e-16) is returned as a
> negative number. Code follows.

>> set.seed(0)
>> nreps.outer <-7
>> pvalue.fisher <- rep(NA,nreps.outer)
>> 
>> population1 <- c( rep("A",300),seq(1:100)) 
>> 
>> population2 <- c( rep("A",100),seq(101:200))
>> 
>> 
>> for (j in 1:nreps.outer){
> + n1 <- sample(30:100,1)
> + n2 <- sample(30:100,1)
> + 
> + group1 <- sample(population1, n1, replace=T)
> + group2 <- sample(population2, n2, replace=T)
> + 
> + pvalue.fisher[j] <-
> fisher.test(table(c(group1,group2),c(rep("group1",n1),rep("group2",n2))))$p.value
> + 
> + print(c(j,pvalue.fisher[j]))
> + 
> + }
> [1] 1.000000e+00 3.581362e-05
> [1] 2.0000000 0.1424779
> [1] 3.0000000 0.1196600
> [1] 4.000000000 0.004222897
> [1] 5.000000e+00 3.234016e-07
> [1] 6.000000000 0.003240286
> [1]  7.000000e+00 -3.847298e-05

>> 
>> fisher.test(table(c(group1,group2),c(rep("group1",n1),rep("group2",n2))))

>         Fisher's Exact Test for Count Data

> data:  table(c(group1, group2), c(rep("group1", n1), rep("group2", n2))) 
> p-value < 2.2e-16
> alternative hypothesis: two.sided 

>> fisher.test(table(c(group1,group2),c(rep("group1",n1),rep("group2",n2))))$p.value
> [1] -3.847298e-05

Thanks.

This comes from

L300:
    /* Process node with new PASTP */
    if (pastp <= obs3) {
	/* Update pre */
	*pre += (double) ifreq * exp(pastp + drn);

in f2xact which (e.g. by adding

	REprintf("pre: %f %d %f \n", *pre, ifreq, (double) ifreq * exp(pastp + drn));

shows that ifreq may have negative values.

Now ifreq comes from ifrq which has

     IFRQ   - Vector of length LDSTP containing the past path
	      frequencies.  					(in/out)

so I am not sure whether we should have negative values here (we migth
be indexing something one off) ...

Does anyone know how the algorithm works in detail?

-k

From saveez at hotmail.com  Fri Apr 22 20:31:23 2005
From: saveez at hotmail.com (Ali -)
Date: Fri Apr 22 20:31:32 2005
Subject: [Rd] Passing arguments to standardGeneric
Message-ID: <BAY17-F363816633F320D152724A2D12D0@phx.gbl>

This could be quite trivial (or could be not): when passing a character 
string argument to standardGeneric, the argument is not passed properly:

>dummy <- function(str){
+ setGeneric(str, function(object, ...) standardGeneric(str))
+ }
>dummy("foo")
[1] "foo"
Warning message:
The body of the generic function for "foo" calls standardGeneric to dispatch 
on a different name ("str")! in: .recursiveCallTest(body, fname)
>

I don't know how this call test works but the test shouldn't fail in this 
case!

From vograno at evafunds.com  Fri Apr 22 21:02:06 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Fri Apr 22 21:02:17 2005
Subject: [Rd] RE: [R] when can we expect Prof Tierney's compiled R?
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A59E8DBF@phost015.EVAFUNDS.intermedia.net>

If we are on the subject of byte compilation, let me bring a couple of
examples which have been puzzling me for some time. I'd like to know a)
if the compilation will likely to improve the performance for this type
of computations, and b) at least roughly understand the reasons for the
observed numbers, specifically why x[i]<- assignment is so much slower
than x[i] extraction.

The loops below are typical in any recursive calculation where the new
value of a vector is based on its immediate neighbor say to the left.
Specifically we assign the previous value to the current element.

# this shows that the assignment x[i]<- is the bottleneck in the loop
> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) x[i]
= x[i-1])
[1] 4.29 0.00 4.30 0.00 0.00
> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA)
x[i-1])
[1] 1.46 0.01 1.46 0.00 0.00

# the overhead of the loop itself is reasonably low, just 0.17 sec
> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) 1)
[1] 0.17 0.01 0.17 0.00 0.00

# pure assignment (w/o the extraction x[i]) takes 3.09 sec. Thus x[i] as
extraction is (3.09 - 0.17)/(0.79 - 0.17) = 4.7 times faster than x[i]<-
as assignment. This looks a bit odd.
> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) x[i]
= 1.0)
[1] 3.08 0.00 3.09 0.00 0.00


# this shows that just evaluation of (i-1) takes about (0.79 - 0.24) =
0.55 sec on my machine (AMD 64 bit). Looks too slow.
> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) i-1)
[1] 0.79 0.00 0.79 0.00 0.00
> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) i)
[1] 0.24 0.01 0.24 0.00 0.00

Thanks,
Vadim

> -----Original Message-----
> From: r-help-bounces@stat.math.ethz.ch 
> [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of Luke Tierney
> Sent: Friday, April 22, 2005 7:33 AM
> To: Peter Dalgaard
> Cc: Jason Liao; r-help@stat.math.ethz.ch
> Subject: Re: [R] when can we expect Prof Tierney's compiled R?
> 
> On Wed, 20 Apr 2005, Peter Dalgaard wrote:
> 
> > Luke Tierney <luke@stat.uiowa.edu> writes:
> >
> >> Vectorized operations in R are also as fast as compiled C (because 
> >> that is what they are :-)).  A compiler such as the one 
> I'm working 
> >> on will be able to make most difference for 
> non-vectorizable or not 
> >> very vectorizable code.  It may also be able to reduce the 
> need for 
> >> intermediate allocations in vectorizable code, which may 
> have other 
> >> benefits beyond just speed improvements.
> >
> > Actually, it has struck me a couple of times that these 
> operations are 
> > not as fast as they could be, since they are outside the 
> scope of fast 
> > BLAS routines, but "embarrassingly parallel" code could easily be 
> > written for the relevant hardware. Even on uniprocessor 
> systems there 
> > might be speedups that the C compiler cannot find (e.g. because it 
> > cannot assume that source and destination of the operation are 
> > distinct).
> 
> My guess is that for anything beyond basic operations we are 
> doing OK on uniprocessors. but it would be useful to do some 
> testing to be sure.  For the basic operations I suspect we 
> are paying a heavy price for the way we handle recycling, 
> both in terms of overhead as such and in terms of inhibiting 
> compiler optimizations. For performance it would probably be 
> better to code the scalar-vector, equal-length-vector, and 
> general cases separately, though keeping the code 
> maintainable may be a bit of a challenge.  Again testing on a 
> range of platforms and compilers would be useful.
> 
> With multiprocessors likely to become more widely available 
> it would be good to look into ways of factoring the 
> vectorized math code so we can slide in one that uses threads 
> when approprate.  This should dovetail nicely with 
> compilation to identify larger vectorized expressions that 
> can be parallelized as a unit; I hope to look into this a bit 
> this summer.
> 
> luke
> 
> 
> 
> --
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> 
> ______________________________________________
> R-help@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>

From smyth at wehi.EDU.AU  Sat Apr 23 02:31:45 2005
From: smyth at wehi.EDU.AU (Gordon K Smyth)
Date: Sat Apr 23 02:37:11 2005
Subject: [Rd] Infinite degrees of freedom for F-distribution
In-Reply-To: <x2sm1jkval.fsf@turmalin.kubism.ku.dk>
References: <6.2.1.2.1.20050422190734.02174a88@imaphost.wehi.edu.au>
	<x2sm1jkval.fsf@turmalin.kubism.ku.dk>
Message-ID: <3887.220.236.84.74.1114216305.squirrel@homebase.wehi.edu.au>

On Fri, April 22, 2005 7:36 pm, Peter Dalgaard said:
> Gordon Smyth <smyth@wehi.edu.au> writes:
>
>> This is just a suggestion/wish that it would be nice for the
>> F-distribution functions to recognize limiting cases for infinite
>> degrees of freedom, as the t-distribution functions already do.
>>
>> The t-distribution functions recognize that df=Inf is equivalent to
>> the standard normal distribution:
>>
>>  > pt(1,df=Inf)
>> [1] 0.8413447
>>  > pnorm(1)
>> [1] 0.8413447
>>
>> On the other hand, pf() will accept Inf for df1, but returns the wrong result:
>>
>>  > pf(1,df1=Inf,df2=1)
>> [1] 1
>>
>> whereas the correct limiting value is
>>
>>  > pchisq(1,df=1,lower.tail=FALSE)
>> [1] 0.3173105
>>
>> pf() returns NaN when df2=Inf:
>>
>>  > pf(1,df1=1,df2=Inf)
>> [1] NaN
>> Warning message:
>> NaNs produced in: pf(q, df1, df2, lower.tail, log.p)
>>
>> although the correct value is available as
>>
>>  > pchisq(1,df=1)
>> [1] 0.6826895
>>
>>
>> Gordon
>>
>>  > version
>>           _
>> platform i386-pc-mingw32
>> arch     i386
>> os       mingw32
>> system   i386, mingw32
>> status
>> major    2
>> minor    1.0
>> year     2005
>> month    04
>> day      18
>> language R
>
> This is actually a regression. It worked as you suggest in 2.0.1, at
> least on Linux. Also, somewhat disturbing,
>
>> pf(1,df1=1,df2=Inf)
> [1] NaN
> Warning message:
> NaNs produced in: pf(q, df1, df2, lower.tail, log.p)
>> pf(1,df1=1,df2=99999999)
> [1] 0.6826895
>> pf(1,df1=1,df2=999999999999)
> [1] 0.6826841
>> pf(1,df1=1,df2=99999999999999999999)
> [1] 0
>
> (notice that the middle case has actually begun to diverge from the
> limiting value)
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907
>

You're right, it worked ok in R 2.0.1 in Windows as well.  I guess the new behaviour is associated
with the new algorithm for pbeta() in R 2.1.0, which will affect a number of functions besides
pf().  The new algorithm is faster for large shape parameters but seems to have accuracy problems:

> a <- 100000000; pbeta(0.5,a,a)
[1] 0.5
> a <- 1000000000; pbeta(0.5,a,a)
[1] 0.4999999
> a <- 10000000000; pbeta(0.5,a,a)
[1] 0
> pbeta(0.5,Inf,Inf)
[1] 0

Gordon

From andy_liaw at merck.com  Sat Apr 23 05:21:40 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat Apr 23 05:22:22 2005
Subject: [Rd] as.data.frame: Error in "names<-.default" (PR#7808)
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076E57@usctmx1106.merck.com>

> From: Robert.McGehee@geodecapital.com
> 
> Hello,
> I found a potential problem in R 2.1.0 (and R 2.0.1)
> 
> I expect that
> 
> > tmp <- FUN(x1, x2, x3, x4)
> > as.data.frame(tmp)
> 
> is the same as
> > as.data.frame(FUN(x1, x2, x3, x4))
> 
> since the tmp variable in this case is unnecessary.
> 
> However, below I will demonstrate that under an odd set of 
> conditions, I
> can correctly perform as.data.frame(tmp), but not 
> as.data.frame(FUN(x1,
> x2, x3, x4)). 
> 
> ## This code works correctly
> FUN <- function(x1, x2, x3, x4) 
>      cbind(x1[, 1, 1:2], x1[, 2, 1:2])[, 1]
> 
> x1 <- array(1:9, c(3, 3, 3))
> tmp <- FUN(x1[1:3, , ], x2 = c("a", "b"), x3 = c("a", "b"), 
> x4 = c("a",
> "b"))
> 
> ## Works correctly
> as.data.frame(tmp)  
> 
>   tmp
> 1   1
> 2   2
> 3   3
> 
> 
> ## This (supposedly equivalent) code gives an error
> 
> as.data.frame(FUN(x1[1:3,,], x2 = c("a", "b"), x3 = c("a", "b"), x4 =
> c("a", "b")))
> 
> Error in "names<-.default"(`*tmp*`, value = c("FUN(x1[1:3, , ], x2 =
> c(\"a\", \"b\"), x3 = c(\"a\", \"b\"), x4 = c(\"a\", ",  : 
> 	'names' attribute [2] must be the same length as the vector [1]
> 
> Note, that while the extra (unused) arguments in FUN seem unnecessary,
> as well as the odd indexing, the problem disappears when I remove the
> extraneous values. Unfortunately, I have not found a more 
> elegant way to
> present this problem, but hopefully this code will be helpful.

The basic problem, I think, boils down to something like this:

> f <- function(x) deparse(substitute(x))
> f(FUN(x1[1:3,,], x2=c("a","b"), x3=c("a", "b"), x4=c("a", "b")))
[1] "FUN(x1[1:3, , ], x2 = c(\"a\", \"b\"), x3 = c(\"a\", \"b\"), x4 =
c(\"a\", "
[2] "    \"b\"))"


which is caused by deparse() chopping up the expression.  The fix would be
to set the width.cutoff argument to something large.  Here's a proposed
patch:

--- R-2.1.0/src/library/base/R/dataframe.R      2005-04-18
06:19:15.000000000 -0
400
+++ R-2.1.0-fix/src/library/base/R/dataframe.R  2005-04-22
23:17:18.972665600 -0
400
@@ -114,7 +114,7 @@
 as.data.frame.vector <- function(x, row.names = NULL, optional = FALSE)
 {
     nrows <- length(x)
-    nm <- deparse(substitute(x))
+    nm <- deparse(substitute(x), width.cutoff=500)
     if(is.null(row.names)) {
        if (nrows == 0)
            row.names <- character(0)
@@ -235,7 +235,7 @@
        as.data.frame.model.matrix(x, row.names, optional)
     else { # as.data.frame.vector without removing names
         nrows <- length(x)
-        nm <- deparse(substitute(x))
+        nm <- deparse(substitute(x), width.cutoff=500)
         if(is.null(row.names)) {
             if (nrows == 0)
                 row.names <- character(0)

(I used width.cutoff=500, as ?deparse says that the max.  I'd imagine the
number of characters allowed for valid symbol names in R is probably lower
than that?)

Andy
 
> Robert
> 
> Robert McGehee
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee@geodecapital.com
> 
> 
> 
> This e-mail, and any attachments hereto, are intended for 
> us...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
>

From john.maindonald at anu.edu.au  Sat Apr 23 13:30:17 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat Apr 23 13:30:34 2005
Subject: [Rd] Enhanced version of plot.lm()
Message-ID: <320af97cfe90da4c59b7e9c8cd9956d4@anu.edu.au>

I propose the following enhancements and changes to plot.lm(),
the most important of which is the addition of a Residuals vs
Leverage plot.

(1) A residual versus leverage plot has been added, available
by specifying which = 5, and not included as one of the default
plots.  Contours of Cook's distance are included, by default at
values of 0.5 and 1.0.  The labeled points, if any, are those with
the largest Cook's distances.  The parameter cook.levels can be
changed as required, to control what contours appear.

(2) Remove the word "plot" from the captions for which=2, 3, 4.
It is redundant.

(3) Now that the pos argument to text() is vectorized, use that
in preference to an offset.

(4) For which!=4 or 5, by default use pos=4 on the left half
of the panel, and pos=2 on the right half of the panel.
This prevents labels from appearing outside the plot area,
where they can overlap other graphical features.
The parameter label.pos allows users to change this default.

The modified code that I propose is below.   This, a modified .Rd
file, and files from diff used with the April 20 development version,
are in my directory

http://wwwmaths.anu.edu.au/~johnm/r/plot-lm/

I believe the Residual-Leverage plot is given in Krause & Olsen,
whether with Cook's distance contours I do not recall.  I do not
have access to a copy of this book.  Martin Maechler drew my
attention to it in 2003, as superior to the Cook's distance plot.
I have finally got around to coding it up!

John Maindonald.

"plot.lm" <-
function (x, which = 1:4, caption = c("Residuals vs Fitted",
                               "Normal Q-Q", "Scale-Location",
                               "Cook's distance", "Residuals vs 
Leverage"),
             panel = points, sub.caption = deparse(x$call), main = "",
             ask = prod(par("mfcol")) < length(which) && 
dev.interactive(),
             ..., id.n = 3, labels.id = names(residuals(x)), cex.id = 
0.75,
             cook.levels=c(0.5, 1.0), label.pos=c(4,2))
{
   if (!inherits(x, "lm"))
     stop("Use only with 'lm' objects")
   if (!is.numeric(which) || any(which < 1) || any(which > 5))
     stop("`which' must be in 1:5")
   isGlm <- inherits(x, "glm")
   show <- rep(FALSE, 5)
   show[which] <- TRUE
   r <- residuals(x)
   yh <- predict(x)
   w <- weights(x)
   if (!is.null(w)) {
     wind <- w != 0
     r <- r[wind]
     yh <- yh[wind]
     w <- w[wind]
     labels.id <- labels.id[wind]
   }
   n <- length(r)
   if (any(show[2:5])) {
     s <- if (inherits(x, "rlm"))
       x$s
     else sqrt(deviance(x)/df.residual(x))
     hii <- lm.influence(x, do.coef = FALSE)$hat
     if (any(show[4:5])) {
       cook <- if (isGlm)cooks.distance(x)
       else cooks.distance(x, sd = s, res = r)
     }
   }
   if (any(show[c(2:3,5)])) {
     ylab23 <- if (isGlm)
       "Std. deviance resid."
     else "Standardized residuals"
     r.w <- if (is.null(w))
       r
     else sqrt(w) * r
     rs <- r.w/(s * sqrt(1 - hii))
   }
   if (any(show[c(1, 3)]))
     l.fit <- if (isGlm)
       "Predicted values"
     else "Fitted values"
   if (is.null(id.n))
     id.n <- 0
   else {
     id.n <- as.integer(id.n)
     if (id.n < 0 || id.n > n)
       stop("`id.n' must be in {1,..,", n, "}")
   }
   if (id.n > 0) {
     if (is.null(labels.id))
       labels.id <- paste(1:n)
     iid <- 1:id.n
     show.r <- sort.list(abs(r), decreasing = TRUE)[iid]
     if (any(show[2:3]))
       show.rs <- sort.list(abs(rs), decreasing = TRUE)[iid]
     text.id <- function(x, y, ind, adj.x = FALSE){
       midx <- mean(range(x))
       labpos <- if (!adj.x) 3
       else
         label.pos[1+as.numeric(x>midx)]
       text(x, y, labels.id[ind], cex = cex.id, xpd = TRUE, pos=labpos,
            offset=0.25)
     }
   }
   one.fig <- prod(par("mfcol")) == 1
   if (ask) {
     op <- par(ask = TRUE)
     on.exit(par(op))
   }
   if (show[1]) {
     ylim <- range(r, na.rm = TRUE)
     if (id.n > 0)
       ylim <- ylim + c(-1, 1) * 0.08 * diff(ylim)
     plot(yh, r, xlab = l.fit, ylab = "Residuals", main = main,
          ylim = ylim, type = "n", ...)
     panel(yh, r, ...)
     if (one.fig)
       title(sub = sub.caption, ...)
     mtext(caption[1], 3, 0.25)
     if (id.n > 0) {
       y.id <- r[show.r]
       y.id[y.id < 0] <- y.id[y.id < 0] - strheight(" ")/3
       text.id(yh[show.r], y.id, show.r, adj.x = TRUE)
     }
     abline(h = 0, lty = 3, col = "gray")
   }
   if (show[2]) {
     ylim <- range(rs, na.rm = TRUE)
     ylim[2] <- ylim[2] + diff(ylim) * 0.075
     qq <- qqnorm(rs, main = main, ylab = ylab23, ylim = ylim,
                  ...)
     if (one.fig)
       title(sub = sub.caption, ...)
     mtext(caption[2], 3, 0.25)
     if (id.n > 0)
       text.id(qq$x[show.rs], qq$y[show.rs], show.rs, adj.x = TRUE)
   }
   if (show[3]) {
     sqrtabsr <- sqrt(abs(rs))
     ylim <- c(0, max(sqrtabsr, na.rm = TRUE))
     yl <- as.expression(substitute(sqrt(abs(YL)), list(YL = 
as.name(ylab23))))
     yhn0 <- if (is.null(w))
       yh
     else yh[w != 0]
     plot(yhn0, sqrtabsr, xlab = l.fit, ylab = yl, main = main,
          ylim = ylim, type = "n", ...)
     panel(yhn0, sqrtabsr, ...)
     if (one.fig)
       title(sub = sub.caption, ...)
     mtext(caption[3], 3, 0.25)
     if (id.n > 0)
       text.id(yhn0[show.rs], sqrtabsr[show.rs], show.rs,
               adj.x = TRUE)
   }
   if (show[4]) {
     if (id.n > 0) {
       show.r <- order(-cook)[iid]
       ymx <- cook[show.r[1]] * 1.075
     }
     else ymx <- max(cook)
     plot(cook, type = "h", ylim = c(0, ymx), main = main,
          xlab = "Obs. number", ylab = "Cook's distance", ...)
     if (one.fig)
       title(sub = sub.caption, ...)
     mtext(caption[4], 3, 0.25)
     if (id.n > 0)
       text.id(show.r, cook[show.r], show.r, adj.x=FALSE)
   }
   if (show[5]) {
     ylim <- range(rs, na.rm = TRUE)
     hatval <- hatvalues(x)
     if (id.n > 0) {
       ylim <- ylim + c(-1, 1) * 0.08 * diff(ylim)
       show.r <- order(-cook)[iid]
     }
     plot(hatval, rs, ylim = ylim, main = main,
          xlab = "Leverages", ylab = ylab23,
          type="n", ...)
     panel(hatval, rs, ...)
     if (one.fig)
       title(sub = sub.caption, ...)
     p <- length(coef(x))
     for(crit in cook.levels){
       curve(sqrt(crit*p*(1-x)/x), lty=2, add=T)
       curve(-sqrt(crit*p*(1-x)/x), lty=2, add=T)
     }
     xmax <- par()$usr[2]
     ymult <- sqrt(p*(1-xmax)/xmax)
     aty <- c(-sqrt(rev(cook.levels))*ymult, sqrt(cook.levels)*ymult)
     axis(4, at=aty, labels=paste(c(rev(cook.levels), cook.levels)),
          mgp=c(.25,.25,0), las=2, tck=0, cex.axis=cex.id)
     mtext(caption[5], 3, 0.25)
     if (id.n > 0) {
       y.id <- rs[show.r]
       y.id[y.id < 0] <- y.id[y.id < 0] - strheight(" ")/3
       text(hatval[show.r], y.id, paste(show.r), pos=2, cex=cex.id, 
offset=0.25)
   }
   }
   if (!one.fig && par("oma")[3] >= 1)
     mtext(sub.caption, outer = TRUE, cex = 1.25)
   invisible()
}

John Maindonald             email: john.maindonald@anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

From d.firth at warwick.ac.uk  Sat Apr 23 17:09:02 2005
From: d.firth at warwick.ac.uk (David Firth)
Date: Sat Apr 23 17:09:15 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <320af97cfe90da4c59b7e9c8cd9956d4@anu.edu.au>
References: <320af97cfe90da4c59b7e9c8cd9956d4@anu.edu.au>
Message-ID: <9717926f912f9fb045c57dd9be4e743c@warwick.ac.uk>

On 23 Apr 2005, at 12:30, John Maindonald wrote:

> I propose the following enhancements and changes to plot.lm(),
> the most important of which is the addition of a Residuals vs
> Leverage plot.
>
> (1) A residual versus leverage plot has been added, available
> by specifying which = 5, and not included as one of the default
> plots.  Contours of Cook's distance are included, by default at
> values of 0.5 and 1.0.  The labeled points, if any, are those with
> the largest Cook's distances.  The parameter cook.levels can be
> changed as required, to control what contours appear.
>
> (2) Remove the word "plot" from the captions for which=2, 3, 4.
> It is redundant.
>
> (3) Now that the pos argument to text() is vectorized, use that
> in preference to an offset.
>
> (4) For which!=4 or 5, by default use pos=4 on the left half
> of the panel, and pos=2 on the right half of the panel.
> This prevents labels from appearing outside the plot area,
> where they can overlap other graphical features.
> The parameter label.pos allows users to change this default.
>
> The modified code that I propose is below.   This, a modified .Rd
> file, and files from diff used with the April 20 development version,
> are in my directory
>
> http://wwwmaths.anu.edu.au/~johnm/r/plot-lm/
>
> I believe the Residual-Leverage plot is given in Krause & Olsen,
> whether with Cook's distance contours I do not recall.  I do not
> have access to a copy of this book.  Martin Maechler drew my
> attention to it in 2003, as superior to the Cook's distance plot.

Agreed.  Alternatively Cook's distance versus leverage/(1-leverage), as 
on p74 of this book:
Statistical Theory and Modelling, In honour of Sir David Cox, FRS.  Eds 
D V Hinkley, N Reid and E J Snell.  Chapman and Hall, 1991.
In that graph the contours of residual^2 are straight lines through the 
origin.  A small disadvantage is that the sign of the residual is lost.

David

> I have finally got around to coding it up!
>
> John Maindonald.
...

From murdoch at stats.uwo.ca  Sat Apr 23 17:21:29 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat Apr 23 17:21:19 2005
Subject: [Rd] tclServiceMode:  stop Tcl/Tk from updating
Message-ID: <426A67F9.7000104@stats.uwo.ca>

In Windows, Tcl/Tk programs running under the tcltk package can update
too frequently:  for exmaple, we might go through a long sequence of
operations to construct a complex display, and in Windows each addition
will be shown separately.

To work around this, I've added a function "tclServiceMode" which serves
as an R interface to the "Tcl_SetServiceMode" function in the TCL API.
Calling "tclServiceMode(on = FALSE)" will stop Tcl/Tk from responding to
any events (redraws in particular) until "tclServiceMode(on = TRUE)" is
called. As far as I know, events are queued, not lost, when handling is
turned off.

So far this function is only in R-devel, but I'll commit it to R-patched
the next chance I get.

Duncan Murdoch

From ellis at stat.harvard.edu  Sat Apr 23 21:59:54 2005
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Sat Apr 23 22:00:10 2005
Subject: [Rd] Objects in R
In-Reply-To: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>
References: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>
Message-ID: <14d2d99f8f37278ebc8961c773758c27@stat.harvard.edu>


On Apr 21, 2005, at 9:37 AM, Nathan Whitehouse wrote:

>
>
>   (1)Novices simply don't understand it.  Students are
> trained in "standard" object-oriented technique and
> this wonkish offshoot(puritanical functional
> programming) just increases the information costs to
> using R and thus decreases the demand.

The obvious solution here is to avoid the phrase "object oriented," 
since that apparently means "acts like Java" these days.

>
>   (2)Large frameworks benefit from
> serializable/storable objects which contain both
> functionality and modifiable values.  S4 stores
> "class" information and R.oo does not upon
> "save()"ing, but there are still real hindrances to
> "trading" objects, which is -extraordinarily-
> important in creating industrial-variety R-based
> analysis.
>   The classical example in my mind is the difficulties
> in implementing a "visitor" pattern in S4.

I'm not sure what your complaint about serialization is exactly, 
serialization is just a way of storing data---its not like Java 
serialization is actually putting *code* into data objects or anything, 
so S4's method of saving objects is more or less equivalent. Yes, you 
have to have the class definition around to get the object back in a 
reasonable way, but this is true of any language.

As for the visitor pattern, the need to implement the visitor pattern 
is actually a hack needed for single dispatch object systems to 
overcome that limitation (typically implementing some sort of double 
dispatch system). This is a classical example of why you really want 
S4's style of OO and NOT GangOfFour style OO not the other way 'round. 
You simply implement the methods directly with a signature of length 2 
instead of a signature of length 1.


>
>   (3)The absence of references means for large
> datasets and long "analysis flows," there is (1)a
> hideous amount of memory used storing each predecessor
> analysis or (2)there are awkward "references" that
> I've seen used like storing the name of the reference
> object in a data slot.
>   I find the use of environments in R.oo as opposed to
> the glorified LISTSXP of S4 to be a satisfying way
> around this.

True, though this has little to do with objects per-se, it has to do 
with memory management semantics that exist independently of the object 
system. Frankly, for large datasets you really want to be doing your 
analytics in some sort of database but weaning people from Excel has 
proven to be even more daunting than convincing them that "object 
oriented" is like "vehicular transportation"---it comes in many forms.

>
>   S4 is a nice step forward.  But R should be open to
> further evolution.  The design choices for S4 and the
> reasons behind abandoning OOP have never been
> adequately justified in my knowledge.  Instead most
> inquiries have been met by a Sphinx-like silence by
> the core community.

Abandoning OOP how? S4 is just as object oriented (more so) than S3 and 
is certainly as object based as Java or C++. Sure it doesn't really act 
like the Java/C++ style of OO, but to paraphrase the famous  Alan Kay 
quote, "I coined the term object oriented and I sure wasn't thinking of 
C++ when I did."

>
>   But the hindrances faced by our friend Ali are
> common, and even in packages maintained by experienced
> R developers, S4 is implemented shall we say curiously
> as per the specs.
>   Clearly OOP and R.oo are not the final answer.  But
> some serious discussion about why packages like R.oo
> which "layer" onto the standard functional R are
> inappropriate is in order.
>
>   It would be great to see R emerge from its niche
> audience.  I believe that would aid statisticians and
> programmers.  However, a little bit more transparency
> and something beyond a categorical "we just don't like
> that way of doing things" would go a long way towards
> growing the base community of R.
>
>   Cheers,
>   Nathan Whitehouse
>   Formerly of Baylor College of Medicine.
>
> Ali, maybe we R-core members are not decent enough.
> But we strongly believe that we don't want to advocate
> yet
> another object system additionally to the S3 and S4
> one,
> and several of us have given talks and classes, even
> written
> books on how to do "decent" object oriented
> programming
> `just' with the S3 and/or S4 object system.
>
> No need of additional "oo" in our eyes.
> Your main problem is that you assume what "oo" means
> {which may
> well be true} but *additionally* you also assume that
> OO has to
> be done in the same way you know it from Python, C++,
> or Java..
>
> Since you are new, please try to learn the S4 way,
> where methods belong to (generic) functions more than
> to classes in some way, particularly if you compare
> with other
> OO systems where methods belong entirely to classes.
> This is NOT true for R (and S-plus) and we don't want
> this to
> change {and yes, we do know about C++, Python,
> Java,... and
> their way to do OO}.
>
> Please also read in more details the good advice given
> by Tony
> Plate and Sean Davis.
>
> Martin Maechler,
> ETH Zurich
>
>
>
> Nathan Whitehouse
> nlwhitehouse@yahoo.com
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
---
Byron Ellis (ellis@stat.harvard.edu)
"Oook" -- The Librarian

From andy_liaw at merck.com  Sun Apr 24 01:00:12 2005
From: andy_liaw at merck.com (andy_liaw@merck.com)
Date: Sun Apr 24 01:00:21 2005
Subject: [Rd] as.data.frame: Error in "names<-.default" (PR#7808)
Message-ID: <20050423230012.7238DA1EE@slim.kubism.ku.dk>

> From: Robert.McGehee@geodecapital.com
> 
> Hello,
> I found a potential problem in R 2.1.0 (and R 2.0.1)
> 
> I expect that
> 
> > tmp <- FUN(x1, x2, x3, x4)
> > as.data.frame(tmp)
> 
> is the same as
> > as.data.frame(FUN(x1, x2, x3, x4))
> 
> since the tmp variable in this case is unnecessary.
> 
> However, below I will demonstrate that under an odd set of 
> conditions, I
> can correctly perform as.data.frame(tmp), but not 
> as.data.frame(FUN(x1,
> x2, x3, x4)). 
> 
> ## This code works correctly
> FUN <- function(x1, x2, x3, x4) 
>      cbind(x1[, 1, 1:2], x1[, 2, 1:2])[, 1]
> 
> x1 <- array(1:9, c(3, 3, 3))
> tmp <- FUN(x1[1:3, , ], x2 = c("a", "b"), x3 = c("a", "b"), 
> x4 = c("a",
> "b"))
> 
> ## Works correctly
> as.data.frame(tmp)  
> 
>   tmp
> 1   1
> 2   2
> 3   3
> 
> 
> ## This (supposedly equivalent) code gives an error
> 
> as.data.frame(FUN(x1[1:3,,], x2 = c("a", "b"), x3 = c("a", "b"), x4 =
> c("a", "b")))
> 
> Error in "names<-.default"(`*tmp*`, value = c("FUN(x1[1:3, , ], x2 =
> c(\"a\", \"b\"), x3 = c(\"a\", \"b\"), x4 = c(\"a\", ",  : 
> 	'names' attribute [2] must be the same length as the vector [1]
> 
> Note, that while the extra (unused) arguments in FUN seem unnecessary,
> as well as the odd indexing, the problem disappears when I remove the
> extraneous values. Unfortunately, I have not found a more 
> elegant way to
> present this problem, but hopefully this code will be helpful.

The basic problem, I think, boils down to something like this:

> f <- function(x) deparse(substitute(x))
> f(FUN(x1[1:3,,], x2=c("a","b"), x3=c("a", "b"), x4=c("a", "b")))
[1] "FUN(x1[1:3, , ], x2 = c(\"a\", \"b\"), x3 = c(\"a\", \"b\"), x4 =
c(\"a\", "
[2] "    \"b\"))"


which is caused by deparse() chopping up the expression.  The fix would be
to set the width.cutoff argument to something large.  Here's a proposed
patch:

--- R-2.1.0/src/library/base/R/dataframe.R      2005-04-18
06:19:15.000000000 -0
400
+++ R-2.1.0-fix/src/library/base/R/dataframe.R  2005-04-22
23:17:18.972665600 -0
400
@@ -114,7 +114,7 @@
 as.data.frame.vector <- function(x, row.names = NULL, optional = FALSE)
 {
     nrows <- length(x)
-    nm <- deparse(substitute(x))
+    nm <- deparse(substitute(x), width.cutoff=500)
     if(is.null(row.names)) {
        if (nrows == 0)
            row.names <- character(0)
@@ -235,7 +235,7 @@
        as.data.frame.model.matrix(x, row.names, optional)
     else { # as.data.frame.vector without removing names
         nrows <- length(x)
-        nm <- deparse(substitute(x))
+        nm <- deparse(substitute(x), width.cutoff=500)
         if(is.null(row.names)) {
             if (nrows == 0)
                 row.names <- character(0)

(I used width.cutoff=500, as ?deparse says that the max.  I'd imagine the
number of characters allowed for valid symbol names in R is probably lower
than that?)

Andy
 
> Robert
> 
> Robert McGehee
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee@geodecapital.com
> 
> 
> 
> This e-mail, and any attachments hereto, are intended for 
> us...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
>

From john.maindonald at anu.edu.au  Sun Apr 24 06:37:10 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun Apr 24 06:37:25 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <9717926f912f9fb045c57dd9be4e743c@warwick.ac.uk>
References: <320af97cfe90da4c59b7e9c8cd9956d4@anu.edu.au>
	<9717926f912f9fb045c57dd9be4e743c@warwick.ac.uk>
Message-ID: <40567787fcb17bee0bf9ecf403fb8e21@anu.edu.au>

I'd not like to lose the signs of the residuals. Also, as
plots 1-3 focus on residuals, there is less of a mental
leap in moving to residuals vs leverage; residuals vs
leverage/(1-leverage) would also be in the same spirit.

Maybe, one way or another, both plots (residuals vs
a function of leverage, and the plot from Hinkley et al)
should go in.  The easiest way to do this is to add a
further which=6.  I will do this if the consensus is that
this is the right way to go.  In any case, I'll add the
Hinkley et al reference (author of the contribution that
includes p.74?) to the draft help page.

John Maindonald.

On 24 Apr 2005, at 1:09 AM, David Firth wrote:

> On 23 Apr 2005, at 12:30, John Maindonald wrote:
>
>> I propose the following enhancements and changes to plot.lm(),
>> the most important of which is the addition of a Residuals vs
>> Leverage plot.
>>
>> (1) A residual versus leverage plot has been added, available
>> by specifying which = 5, and not included as one of the default
>> plots.  Contours of Cook's distance are included, by default at
>> values of 0.5 and 1.0.  The labeled points, if any, are those with
>> the largest Cook's distances.  The parameter cook.levels can be
>> changed as required, to control what contours appear.
>>
>> (2) Remove the word "plot" from the captions for which=2, 3, 4.
>> It is redundant.
>>
>> (3) Now that the pos argument to text() is vectorized, use that
>> in preference to an offset.
>>
>> (4) For which!=4 or 5, by default use pos=4 on the left half
>> of the panel, and pos=2 on the right half of the panel.
>> This prevents labels from appearing outside the plot area,
>> where they can overlap other graphical features.
>> The parameter label.pos allows users to change this default.
>>
>> The modified code that I propose is below.   This, a modified .Rd
>> file, and files from diff used with the April 20 development version,
>> are in my directory
>>
>> http://wwwmaths.anu.edu.au/~johnm/r/plot-lm/
>>
>> I believe the Residual-Leverage plot is given in Krause & Olsen,
>> whether with Cook's distance contours I do not recall.  I do not
>> have access to a copy of this book.  Martin Maechler drew my
>> attention to it in 2003, as superior to the Cook's distance plot.
>
> Agreed.  Alternatively Cook's distance versus leverage/(1-leverage), 
> as on p74 of this book:
> Statistical Theory and Modelling, In honour of Sir David Cox, FRS.  
> Eds D V Hinkley, N Reid and E J Snell.  Chapman and Hall, 1991.
> In that graph the contours of residual^2 are straight lines through 
> the origin.  A small disadvantage is that the sign of the residual is 
> lost.
>
> David
>
>> I have finally got around to coding it up!
>>
>> John Maindonald.
> ...
>
>
John Maindonald             email: john.maindonald@anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

From murdoch at stats.uwo.ca  Sun Apr 24 08:54:44 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun Apr 24 08:54:20 2005
Subject: [Rd] Objects in R
In-Reply-To: <14d2d99f8f37278ebc8961c773758c27@stat.harvard.edu>
References: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>
	<14d2d99f8f37278ebc8961c773758c27@stat.harvard.edu>
Message-ID: <426B42B4.3090306@stats.uwo.ca>

Byron Ellis wrote:
> 
> On Apr 21, 2005, at 9:37 AM, Nathan Whitehouse wrote:
> 
>>
>>
>>   (1)Novices simply don't understand it.  Students are
>> trained in "standard" object-oriented technique and
>> this wonkish offshoot(puritanical functional
>> programming) just increases the information costs to
>> using R and thus decreases the demand.
> 
> 
> The obvious solution here is to avoid the phrase "object oriented," 
> since that apparently means "acts like Java" these days.

That's actually a good suggestion.  In S4, objects don't own methods, 
generics do, so it might be more informative to call it "generic 
oriented".

>>   (2)Large frameworks benefit from
>> serializable/storable objects which contain both
>> functionality and modifiable values.  S4 stores
>> "class" information and R.oo does not upon
>> "save()"ing, but there are still real hindrances to
>> "trading" objects, which is -extraordinarily-
>> important in creating industrial-variety R-based
>> analysis.
>>   The classical example in my mind is the difficulties
>> in implementing a "visitor" pattern in S4.
> 
> 
> I'm not sure what your complaint about serialization is exactly, 
> serialization is just a way of storing data---its not like Java 
> serialization is actually putting *code* into data objects or anything, 
> so S4's method of saving objects is more or less equivalent. Yes, you 
> have to have the class definition around to get the object back in a 
> reasonable way, but this is true of any language.
> 
> As for the visitor pattern, the need to implement the visitor pattern is 
> actually a hack needed for single dispatch object systems to overcome 
> that limitation (typically implementing some sort of double dispatch 
> system). This is a classical example of why you really want S4's style 
> of OO and NOT GangOfFour style OO not the other way 'round. You simply 
> implement the methods directly with a signature of length 2 instead of a 
> signature of length 1.

I disagree with this.  Dispatch on multiple arguments is not 
inconsistent with Java-style OOP.  It would be called "function 
overloading".

I don't know if there are languages that do this (i.e. do function 
overloading based on run-time type, rather than declared type), but 
that's likely because I don't know a lot of languages, not because they 
don't exist.

The big advantage of Java-style OOP is that it allows a clear definition 
of what is needed in order to be a valid descendant class.  For example, 
if I want to be a descendant of a "vector", I would need to implement 
index lookup and assignment, a way to print when in a data.frame, etc.

With S4, it's not so clear what my class needs to do to be a vector. 
Suppose I call my class myVector, and get it working, submitted to CRAN, 
etc.

Independently, you create a new generic that is supposed to work on 
vectors.  You are unaware of my work, so you don't create a method for 
MyVector, and I'm unaware of your work so I don't create one either. 
When someone else tries to use both of our packages, they don't work 
together.

In Java-style OOP, on the other hand, you couldn't change the 
requirements for MyVector.  If it did the things that were required by 
the original class definition properly, then it would work with your 
code (since you couldn't require anything beyond the original 
definition).  If you needed methods not in the original, you would have 
to declare a new class, and there wouldn't be a risk of a third party 
getting burned by mixing my code with yours.


>>   (3)The absence of references means for large
>> datasets and long "analysis flows," there is (1)a
>> hideous amount of memory used storing each predecessor
>> analysis or (2)there are awkward "references" that
>> I've seen used like storing the name of the reference
>> object in a data slot.
>>   I find the use of environments in R.oo as opposed to
>> the glorified LISTSXP of S4 to be a satisfying way
>> around this.
> 
> 
> True, though this has little to do with objects per-se, it has to do 
> with memory management semantics that exist independently of the object 
> system. Frankly, for large datasets you really want to be doing your 
> analytics in some sort of database but weaning people from Excel has 
> proven to be even more daunting than convincing them that "object 
> oriented" is like "vehicular transportation"---it comes in many forms.
 >
>>   S4 is a nice step forward.  But R should be open to
>> further evolution.  The design choices for S4 and the
>> reasons behind abandoning OOP have never been
>> adequately justified in my knowledge.  Instead most
>> inquiries have been met by a Sphinx-like silence by
>> the core community.
> 
> 
> Abandoning OOP how? S4 is just as object oriented (more so) than S3 and 
> is certainly as object based as Java or C++. Sure it doesn't really act 
> like the Java/C++ style of OO, but to paraphrase the famous  Alan Kay 
> quote, "I coined the term object oriented and I sure wasn't thinking of 
> C++ when I did."

What S4 is missing is "encapsulation". Wikipedia's article on 
object-oriented programming gives a good definition:

"Encapsulation - Ensures that users of an object cannot change the 
internal state of the object in unexpected ways; only the object's own 
internal methods are allowed to access its state. Each object exposes an 
interface that specifies how other objects may interact with it."

Neither of these properties holds in S4.

Duncan Murdoch

>>   But the hindrances faced by our friend Ali are
>> common, and even in packages maintained by experienced
>> R developers, S4 is implemented shall we say curiously
>> as per the specs.
>>   Clearly OOP and R.oo are not the final answer.  But
>> some serious discussion about why packages like R.oo
>> which "layer" onto the standard functional R are
>> inappropriate is in order.
>>
>>   It would be great to see R emerge from its niche
>> audience.  I believe that would aid statisticians and
>> programmers.  However, a little bit more transparency
>> and something beyond a categorical "we just don't like
>> that way of doing things" would go a long way towards
>> growing the base community of R.
>>
>>   Cheers,
>>   Nathan Whitehouse
>>   Formerly of Baylor College of Medicine.
>>
>> Ali, maybe we R-core members are not decent enough.
>> But we strongly believe that we don't want to advocate
>> yet
>> another object system additionally to the S3 and S4
>> one,
>> and several of us have given talks and classes, even
>> written
>> books on how to do "decent" object oriented
>> programming
>> `just' with the S3 and/or S4 object system.
>>
>> No need of additional "oo" in our eyes.
>> Your main problem is that you assume what "oo" means
>> {which may
>> well be true} but *additionally* you also assume that
>> OO has to
>> be done in the same way you know it from Python, C++,
>> or Java..
>>
>> Since you are new, please try to learn the S4 way,
>> where methods belong to (generic) functions more than
>> to classes in some way, particularly if you compare
>> with other
>> OO systems where methods belong entirely to classes.
>> This is NOT true for R (and S-plus) and we don't want
>> this to
>> change {and yes, we do know about C++, Python,
>> Java,... and
>> their way to do OO}.
>>
>> Please also read in more details the good advice given
>> by Tony
>> Plate and Sean Davis.
>>
>> Martin Maechler,
>> ETH Zurich
>>
>>
>>
>> Nathan Whitehouse
>> nlwhitehouse@yahoo.com
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> ---
> Byron Ellis (ellis@stat.harvard.edu)
> "Oook" -- The Librarian
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From d.firth at warwick.ac.uk  Sun Apr 24 14:23:51 2005
From: d.firth at warwick.ac.uk (David Firth)
Date: Sun Apr 24 14:24:06 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <40567787fcb17bee0bf9ecf403fb8e21@anu.edu.au>
References: <320af97cfe90da4c59b7e9c8cd9956d4@anu.edu.au>
	<9717926f912f9fb045c57dd9be4e743c@warwick.ac.uk>
	<40567787fcb17bee0bf9ecf403fb8e21@anu.edu.au>
Message-ID: <ef50d09805dfd7583635d02b5f4aaeec@warwick.ac.uk>

On 24 Apr 2005, at 05:37, John Maindonald wrote:

> I'd not like to lose the signs of the residuals. Also, as
> plots 1-3 focus on residuals, there is less of a mental
> leap in moving to residuals vs leverage; residuals vs
> leverage/(1-leverage) would also be in the same spirit.

Yes, I know what you mean.  Mental leaps are a matter of 
taste...pitfalls, etc, come to mind.

>
> Maybe, one way or another, both plots (residuals vs
> a function of leverage, and the plot from Hinkley et al)
> should go in.  The easiest way to do this is to add a
> further which=6.  I will do this if the consensus is that
> this is the right way to go.  In any case, I'll add the
> Hinkley et al reference (author of the contribution that
> includes p.74?) to the draft help page.

Sorry, I should have given the full reference, which (in BibTeX format 
from CIS) is

@inproceedings{Firt:gene:1991,
     author = {Firth, D.},
     title = {Generalized Linear Models},
     year = {1991},
     booktitle = {Statistical Theory and Modelling. In Honour of Sir 
David Cox, FRS},
     editor = {Hinkley, D. V. and Reid, N. and Snell, E. J.},
     publisher = {Chapman \& Hall Ltd},
     pages = {55--82},
     keywords = {Analysis of deviance; Likelihood}
}

David

>
> John Maindonald.
>
> On 24 Apr 2005, at 1:09 AM, David Firth wrote:
>
>> On 23 Apr 2005, at 12:30, John Maindonald wrote:
>>
>>> I propose the following enhancements and changes to plot.lm(),
>>> the most important of which is the addition of a Residuals vs
>>> Leverage plot.
>>>
>>> (1) A residual versus leverage plot has been added, available
>>> by specifying which = 5, and not included as one of the default
>>> plots.  Contours of Cook's distance are included, by default at
>>> values of 0.5 and 1.0.  The labeled points, if any, are those with
>>> the largest Cook's distances.  The parameter cook.levels can be
>>> changed as required, to control what contours appear.
>>>
>>> (2) Remove the word "plot" from the captions for which=2, 3, 4.
>>> It is redundant.
>>>
>>> (3) Now that the pos argument to text() is vectorized, use that
>>> in preference to an offset.
>>>
>>> (4) For which!=4 or 5, by default use pos=4 on the left half
>>> of the panel, and pos=2 on the right half of the panel.
>>> This prevents labels from appearing outside the plot area,
>>> where they can overlap other graphical features.
>>> The parameter label.pos allows users to change this default.
>>>
>>> The modified code that I propose is below.   This, a modified .Rd
>>> file, and files from diff used with the April 20 development version,
>>> are in my directory
>>>
>>> http://wwwmaths.anu.edu.au/~johnm/r/plot-lm/
>>>
>>> I believe the Residual-Leverage plot is given in Krause & Olsen,
>>> whether with Cook's distance contours I do not recall.  I do not
>>> have access to a copy of this book.  Martin Maechler drew my
>>> attention to it in 2003, as superior to the Cook's distance plot.
>>
>> Agreed.  Alternatively Cook's distance versus leverage/(1-leverage), 
>> as on p74 of this book:
>> Statistical Theory and Modelling, In honour of Sir David Cox, FRS.  
>> Eds D V Hinkley, N Reid and E J Snell.  Chapman and Hall, 1991.
>> In that graph the contours of residual^2 are straight lines through 
>> the origin.  A small disadvantage is that the sign of the residual is 
>> lost.
>>
>> David
>>
>>> I have finally got around to coding it up!
>>>
>>> John Maindonald.
>> ...
>>
>>
> John Maindonald             email: john.maindonald@anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Bioinformation Science, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>

From john.gavin at ubs.com  Sun Apr 24 17:41:45 2005
From: john.gavin at ubs.com (john.gavin@ubs.com)
Date: Sun Apr 24 17:41:54 2005
Subject: [Rd] utils::setRepositories bug when adding a local repository?
	(PR#7810)
Message-ID: <20050424154145.DD709A1C3@slim.kubism.ku.dk>

Full_Name: John Gavin
Version: 2.1.0 patched 18-04-05
OS: windows XP SP2
Submission from: (NULL) (139.149.1.203)


Hi,

I suspect that there may be a bug in utils::setRepositories().

Starting with

> getOption("repos")
                                CRAN                            CRANextra 
                            "@CRAN@" "http://www.stats.ox.ac.uk/pub/RWin" 

I set

> options(repos = c(
+  UBS = "http://wfdevapps:8150/qrms/r",
+   CRAN = "http://cran.uk.r-project.org",
+   CRANextra = "http://www.stats.ox.ac.uk/pub/RWin",
+   Omegahat = "http://www.omegahat.org/R"
+ ))
> getOption("repos")
                                 UBS                                 CRAN 
      "http://wfdevapps:8150/qrms/r"       "http://cran.uk.r-project.org" 
                           CRANextra                             Omegahat 
"http://www.stats.ox.ac.uk/pub/RWin"          "http://www.omegahat.org/R" 
> 

now when I run 'utils::setRepositories' I see

> utils::setRepositories()
Error in xi[[j]] : subscript out of bounds
In addition: Warning message:
longer object length
        is not a multiple of shorter object length in: clabs == nmi 

Examining that function via 'debug'

Browse[1]> a
              menu_name                                URL default source
CRAN               CRAN       http://cran.uk.r-project.org    TRUE   TRUE
CRANextra CRAN (extras) http://www.stats.ox.ac.uk/pub/RWin    TRUE  FALSE
BioC       Bioconductor        http://www.bioconductor.org   FALSE   TRUE
Omegahat       Omegahat          http://www.omegahat.org/R    TRUE   TRUE

Browse[1]> newa
    menu_name                          URL default
UBS       UBS http://wfdevapps:8150/qrms/r    TRUE

The 'source' column is present in 'a' but not in 'newa'.
This causes the error when they are merged via 'rbind'

Browse[1]>  rbind(a, newa)
Error in xi[[j]] : subscript out of bounds
In addition: Warning message:
longer object length
        is not a multiple of shorter object length in: clabs == nmi 

Artifically adding a 'source = FALSE' column to 'a' 
seems to fix the problem.

Browse[1]> newa <- data.frame(menu_name = aa, URL = repos[new], default = TRUE,
source = FALSE)
Browse[1]> row.names(newa) <- aa
Browse[1]>  rbind(a, newa)
              menu_name                                URL default source
CRAN               CRAN       http://cran.uk.r-project.org    TRUE   TRUE
CRANextra CRAN (extras) http://www.stats.ox.ac.uk/pub/RWin    TRUE  FALSE
BioC       Bioconductor        http://www.bioconductor.org   FALSE   TRUE
Omegahat       Omegahat          http://www.omegahat.org/R    TRUE   TRUE
UBS                 UBS       http://wfdevapps:8150/qrms/r    TRUE  FALSE
Browse[1]> a <- rbind(a, newa)
...

producing the output

exiting from: utils::setRepositories()
$repos
                                 UBS                                 CRAN 
      "http://wfdevapps:8150/qrms/r"       "http://cran.uk.r-project.org" 
                           CRANextra                             Omegahat 
"http://www.stats.ox.ac.uk/pub/RWin"          "http://www.omegahat.org/R" 


> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status   Patched        
major    2              
minor    1.0            
year     2005           
month    04             
day      18             
language R          


Regards,

John.

John Gavin <john.gavin 'at' ubs 'dot' com>,
Quantitative Risk Models and Statistics,
UBS Investment Bank, 6th floor, 
100 Liverpool St., London EC2M 2RH, UK.
Phone +44 (0) 207 567 4289
Fax   +44 (0) 207 568 5352

From sfalcon at fhcrc.org  Sun Apr 24 19:50:29 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sun Apr 24 19:51:18 2005
Subject: [Rd] Objects in R
In-Reply-To: <426B42B4.3090306@stats.uwo.ca> (Duncan Murdoch's message of
	"Sun, 24 Apr 2005 07:54:44 +0100")
References: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>
	<14d2d99f8f37278ebc8961c773758c27@stat.harvard.edu>
	<426B42B4.3090306@stats.uwo.ca>
Message-ID: <m27jisvzbu.fsf@macaroni.local>

Duncan Murdoch <murdoch@stats.uwo.ca> writes:
> What S4 is missing is "encapsulation". Wikipedia's article on 
> object-oriented programming gives a good definition:
>
> "Encapsulation - Ensures that users of an object cannot change the 
> internal state of the object in unexpected ways; only the object's own 
> internal methods are allowed to access its state. Each object exposes an 
> interface that specifies how other objects may interact with it."
>
> Neither of these properties holds in S4.

I don't like the definition of encapsulation in the Wikipedia.  If
nothing else, I think the second part about objects exposing an
interface specifying how to interact with them should come first ---
and S4 provides that.

In my experience, the ability to create "obvious" interfaces to
classes is the important part of encapsulation.  Python's object
system, for example, does not (easily) provide protections against
abuse, but other than some initial misgivings, I've not missed it.

+ seth

From davison at uchicago.edu  Sun Apr 24 22:06:09 2005
From: davison at uchicago.edu (davison@uchicago.edu)
Date: Sun Apr 24 22:06:16 2005
Subject: [Rd] typo in ?"[" (PR#7811)
Message-ID: <20050424200609.21CB3A1D3@slim.kubism.ku.dk>

from ?"[" :

---------------------------
Argument matching:

      Note that these operations do match their index arguments in the
      standard way: argument names are ignored and positional matching
      only is used. So 'm[j=2,i=1]' is equivalent to 'm[2,1]' and *not*
      'm[1,2]'.
---------------------------

I think that the first line of this paragraph should read "... do not 
match ...".


> version
          _
platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    2
minor    1.0
year     2005
month    04
day      18
language R


Thanks,

Dan

From saveez at hotmail.com  Sun Apr 24 22:12:17 2005
From: saveez at hotmail.com (Ali -)
Date: Sun Apr 24 22:12:25 2005
Subject: [Rd] Collade doesn't work for more than 256 files!
Message-ID: <BAY17-F26F98431F665C5A929328CD12F0@phx.gbl>

Last week I managed to automatically wrap over 600 C++ classes into R in 
less than 24 hours. It was not because I am an expert in R programming, it 
was simply because I wrapped the classes as S3. Not only the wrapping 
process was easy, but also installation process and loading the final 
library was fast too.

Now I am also trying to do the wrapping into the 'modern' S4 classes. This 
is the 5th day I am working on this and I have to say S4 was not design for 
big packages!

(1) Because of its meta-data design, the setClass commands must be sorted in 
the order of inheritance and this is a real pain when it comes to a few 
hundered classes. I wrote some R code to read the annotated source files and 
return the ordered file names.

(2) After all, when I put the ordered file list in front of Collade in the 
DESCRIPTION file, I got this error induring installation:

---------- Making package vtkr ------------
  adding build stamp to DESCRIPTION
Error in .read_description(dfile) : file 'DESCRIPTION' is
not in valid DCF format
Execution halted
make[2]: *** [frontmatter] Error 1
make[1]: *** [all] Error 2
make: *** [pkg-vtkr] Error 2
*** Installation of vtkr failed ***

After a bit playing with th enumber of th efiles, it seems to me Collade 
cannot handle (probably) more than 256 files.

For many good reasosns,  I am not going to break the package up into 
different pieces. If I am not missing anything here, I hope some R developer 
can let me know about some work around on this bug. (hey even java and 
python don't have this limitation, not sure about Ada83.)

From blindglobe at gmail.com  Sun Apr 24 23:06:36 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Sun Apr 24 23:06:46 2005
Subject: [Rd] Collade doesn't work for more than 256 files!
In-Reply-To: <BAY17-F26F98431F665C5A929328CD12F0@phx.gbl>
References: <BAY17-F26F98431F665C5A929328CD12F0@phx.gbl>
Message-ID: <1abe3fa9050424140640806de2@mail.gmail.com>

Since most of what Collate does is to cat files together in a
particular order, and you are doing automatic conversion, why not just
sacrifice the individual files and cat them together during the
conversion that you are doing, instead of package building?

You aren't planning on editing them by hand, are you, or
replacing/updating piecemeal?

Alternatively, do this as part of a configure script or makefile? 
(i.e. on build, concatenate the files into one and remove the little
pieces)?

best,
-tony


On 4/24/05, Ali - <saveez@hotmail.com> wrote:
> Last week I managed to automatically wrap over 600 C++ classes into R in
> less than 24 hours. It was not because I am an expert in R programming, it
> was simply because I wrapped the classes as S3. Not only the wrapping
> process was easy, but also installation process and loading the final
> library was fast too.
> 
> Now I am also trying to do the wrapping into the 'modern' S4 classes. This
> is the 5th day I am working on this and I have to say S4 was not design for
> big packages!
> 
> (1) Because of its meta-data design, the setClass commands must be sorted in
> the order of inheritance and this is a real pain when it comes to a few
> hundered classes. I wrote some R code to read the annotated source files and
> return the ordered file names.
> 
> (2) After all, when I put the ordered file list in front of Collade in the
> DESCRIPTION file, I got this error induring installation:
> 
> ---------- Making package vtkr ------------
>   adding build stamp to DESCRIPTION
> Error in .read_description(dfile) : file 'DESCRIPTION' is
> not in valid DCF format
> Execution halted
> make[2]: *** [frontmatter] Error 1
> make[1]: *** [all] Error 2
> make: *** [pkg-vtkr] Error 2
> *** Installation of vtkr failed ***
> 
> After a bit playing with th enumber of th efiles, it seems to me Collade
> cannot handle (probably) more than 256 files.
> 
> For many good reasosns,  I am not going to break the package up into
> different pieces. If I am not missing anything here, I hope some R developer
> can let me know about some work around on this bug. (hey even java and
> python don't have this limitation, not sure about Ada83.)
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From murdoch at stats.uwo.ca  Sun Apr 24 23:15:15 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun Apr 24 23:14:53 2005
Subject: [Rd] Objects in R
In-Reply-To: <m27jisvzbu.fsf@macaroni.local>
References: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>	<14d2d99f8f37278ebc8961c773758c27@stat.harvard.edu>	<426B42B4.3090306@stats.uwo.ca>
	<m27jisvzbu.fsf@macaroni.local>
Message-ID: <426C0C63.7000207@stats.uwo.ca>

Seth Falcon wrote:
> Duncan Murdoch <murdoch@stats.uwo.ca> writes:
> 
>>What S4 is missing is "encapsulation". Wikipedia's article on 
>>object-oriented programming gives a good definition:
>>
>>"Encapsulation - Ensures that users of an object cannot change the 
>>internal state of the object in unexpected ways; only the object's own 
>>internal methods are allowed to access its state. Each object exposes an 
>>interface that specifies how other objects may interact with it."
>>
>>Neither of these properties holds in S4.
> 
> 
> I don't like the definition of encapsulation in the Wikipedia.  If
> nothing else, I think the second part about objects exposing an
> interface specifying how to interact with them should come first ---
> and S4 provides that.

I agree the second part is more important.  If you have the second part, 
you can handle the first part by convention, e.g. by exposing ways to do 
things with the internals through a public interface, and adopting the 
convention that you should never go in and meddle directly.

But I don't think S4 does the second part.  S4 fixes the representation 
of an object, but it doesn't specify how other objects should interact 
with it.  That's done in other languages through the methods of the 
class, but S4 classes don't have any methods, S4 generics have methods. 
  Generics can be created independently of the class, and the author of 
the class will not know to create methods for them.

> In my experience, the ability to create "obvious" interfaces to
> classes is the important part of encapsulation.  Python's object
> system, for example, does not (easily) provide protections against
> abuse, but other than some initial misgivings, I've not missed it.

I don't know Python, but a quick look at the reference manual online 
makes it look class-oriented like Java rather than generic-oriented like S4.

I think this would be relatively easy to add to R.  I'd do it as follows:

Put the class methods in an environment, and put the class slots in a 
different one.  There would only be one method environment for the 
class, but a separate one for each instance.  Set the methods 
environment to be the parent of each instance's slot environment.

Single inheritance could work by setting the ancestor's method 
environment as the parent of the method environment, but it's harder to 
handle multiple inheritance.  However, since there's only one copy of 
the method environment needed, making copies of the methods for each 
declared class wouldn't be a big deal.

Duncan Murdoch

From saveez at hotmail.com  Sun Apr 24 23:45:54 2005
From: saveez at hotmail.com (Ali -)
Date: Sun Apr 24 23:46:02 2005
Subject: [Rd] Collade doesn't work for more than 256 files!
In-Reply-To: <1abe3fa9050424140640806de2@mail.gmail.com>
Message-ID: <BAY17-F41F75D29CDE3331B1BE900D12F0@phx.gbl>


>
>Alternatively, do this as part of a configure script or makefile?
>(i.e. on build, concatenate the files into one and remove the little
>pieces)?

Or better than that: file.append from R itself, thanks for the idea!

(1) Could you explain to me why the performance in S4 is not as good as S3 
when it comes to a huge number of classes? I thought the meta-data generated 
by S4 is for boosting the performance.

(2) Any tips for improving the performance?

(3) Why turning SaveImage on doesn't help it?

From ellis at stat.harvard.edu  Mon Apr 25 02:18:57 2005
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Mon Apr 25 02:19:16 2005
Subject: [Rd] Objects in R
In-Reply-To: <426B42B4.3090306@stats.uwo.ca>
References: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>
	<14d2d99f8f37278ebc8961c773758c27@stat.harvard.edu>
	<426B42B4.3090306@stats.uwo.ca>
Message-ID: <76e95de2f50fb467210854f1ded80c4d@stat.harvard.edu>


On Apr 23, 2005, at 11:54 PM, Duncan Murdoch wrote:

> Byron Ellis wrote:
>> On Apr 21, 2005, at 9:37 AM, Nathan Whitehouse wrote:
>>>
>>>
>>>   (1)Novices simply don't understand it.  Students are
>>> trained in "standard" object-oriented technique and
>>> this wonkish offshoot(puritanical functional
>>> programming) just increases the information costs to
>>> using R and thus decreases the demand.
>> The obvious solution here is to avoid the phrase "object oriented," 
>> since that apparently means "acts like Java" these days.
>
> That's actually a good suggestion.  In S4, objects don't own methods, 
> generics do, so it might be more informative to call it "generic 
> oriented".

People may confuse that with C++'s "generic programming," maybe "data 
oriented" programming or something ;-)

>> I'm not sure what your complaint about serialization is exactly, 
>> serialization is just a way of storing data---its not like Java 
>> serialization is actually putting *code* into data objects or 
>> anything, so S4's method of saving objects is more or less 
>> equivalent. Yes, you have to have the class definition around to get 
>> the object back in a reasonable way, but this is true of any 
>> language.
>> As for the visitor pattern, the need to implement the visitor pattern 
>> is actually a hack needed for single dispatch object systems to 
>> overcome that limitation (typically implementing some sort of double 
>> dispatch system). This is a classical example of why you really want 
>> S4's style of OO and NOT GangOfFour style OO not the other way 
>> 'round. You simply implement the methods directly with a signature of 
>> length 2 instead of a signature of length 1.
>
> I disagree with this.  Dispatch on multiple arguments is not 
> inconsistent with Java-style OOP.  It would be called "function 
> overloading".
>
> I don't know if there are languages that do this (i.e. do function 
> overloading based on run-time type, rather than declared type), but 
> that's likely because I don't know a lot of languages, not because 
> they don't exist.

Naw, it still doesn't work since you wouldn't able to extend an object 
you don't own to dispatch to new sorts of visitors. You can do a bit 
better by ignoring typing altogether a la Smalltalk leading to a much 
cleaner implementation of the visitor pattern, but its still not 
totally gone. Multimethods OTOH give you both the typing information 
and the class extension (since classes don't hold methods at all).

>
> The big advantage of Java-style OOP is that it allows a clear 
> definition of what is needed in order to be a valid descendant class.  
> For example, if I want to be a descendant of a "vector", I would need 
> to implement index lookup and assignment, a way to print when in a 
> data.frame, etc.
>
> With S4, it's not so clear what my class needs to do to be a vector. 
> Suppose I call my class myVector, and get it working, submitted to 
> CRAN, etc.
>
> Independently, you create a new generic that is supposed to work on 
> vectors.  You are unaware of my work, so you don't create a method for 
> MyVector, and I'm unaware of your work so I don't create one either. 
> When someone else tries to use both of our packages, they don't work 
> together.
>
> In Java-style OOP, on the other hand, you couldn't change the 
> requirements for MyVector.  If it did the things that were required by 
> the original class definition properly, then it would work with your 
> code (since you couldn't require anything beyond the original 
> definition).  If you needed methods not in the original, you would 
> have to declare a new class, and there wouldn't be a risk of a third 
> party getting burned by mixing my code with yours.

More precisely Java's Interface system allows for the clear definition 
of requirements for a particular type. Ironically this system exists 
outside of the Java's OO structure and plays be completely different 
rules (no inheritance, no polymorphism. encapsulation doesn't apply 
since interfaces can't hold mutable data. All they really give you is 
abstraction). I'd be more than happy to see S4 pick up some sort of 
protocol mechanism, but that can (and does in other languages) 
obviously exist independently of a Java-style OO system.

>> Abandoning OOP how? S4 is just as object oriented (more so) than S3 
>> and is certainly as object based as Java or C++. Sure it doesn't 
>> really act like the Java/C++ style of OO, but to paraphrase the 
>> famous  Alan Kay quote, "I coined the term object oriented and I sure 
>> wasn't thinking of C++ when I did."
>
> What S4 is missing is "encapsulation". Wikipedia's article on 
> object-oriented programming gives a good definition:
>
> "Encapsulation - Ensures that users of an object cannot change the 
> internal state of the object in unexpected ways; only the object's own 
> internal methods are allowed to access its state. Each object exposes 
> an interface that specifies how other objects may interact with it."
>
> Neither of these properties holds in S4.

They don't hold in C++ or Java either if the object has a public data 
member. Also, S4 classes already have this by convention--- foo() and 
foo()<- much in the same way Java has adopted the convention of 
getFoo() and setFoo() (or Smalltalk's foo foo: and so on). The only 
difference is that an R function doesn't know when its a method call so 
there's no good way of restricting the '@' operator to situations where 
you should have access to the data members.

I would also observe that the Wikipedia article also contains an entire 
section ("Multimethod Model") on S4's OO model.

>
> Duncan Murdoch
>
---
Byron Ellis (ellis@stat.harvard.edu)
"Oook" -- The Librarian

From blindglobe at gmail.com  Mon Apr 25 06:42:31 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Mon Apr 25 06:42:40 2005
Subject: [Rd] Objects in R
In-Reply-To: <20050421182433.GC10744@jtkpc.cmp.uea.ac.uk>
References: <20050421163730.20887.qmail@web30213.mail.mud.yahoo.com>
	<4267DC82.3000005@jhsph.edu>
	<20050421182433.GC10744@jtkpc.cmp.uea.ac.uk>
Message-ID: <1abe3fa905042421422b5e586a@mail.gmail.com>

On 4/21/05, Jan T. Kim <jtk@cmp.uea.ac.uk> wrote:
> On Thu, Apr 21, 2005 at 01:01:54PM -0400, Roger D. Peng wrote:
> > One important thing to remember, which I think some more
> > experienced programmers may forget, is that R is two things---a
> > programming language and an *interactive* system for statistics
> > and graphics.  Maintaining the "interactive-ableness" of R may
> > have imposed certain design choices.  I personally think the
> > current S4 system of generics/methods is quite suitable for both
> > the "programming" and "interactive" sides of R.
> 
> That's certainly a valid point. A more "standard" kind of
> object orientation does not necessarily impair interactive
> use, however. Python is no less usable interactively than R,
> for example.

Again, it depends on what you are doing.  As much as I like Python
(and I really do), interactive construction of (moderately complex)
classes is a PITA (compared to class structures in S4, or prototypes
with XLispStat which can be done on a single line instead of many). 
Now, interactive Java via Omegahat or Bean-shell is worse (more
annoying) for class construction, for certain definitions of worse.

Which brings up the problem with imprecision, that all examples are
equally "usable", for various definitions of usability and contexts
that programmers would work in.

best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From ellis at stat.harvard.edu  Mon Apr 25 09:55:23 2005
From: ellis at stat.harvard.edu (ellis@stat.harvard.edu)
Date: Mon Apr 25 09:55:30 2005
Subject: [Rd] RAW types not restored from Rda files (PR#7812)
Message-ID: <20050425075523.42D7EA1DB@slim.kubism.ku.dk>

Full_Name: Byron Ellis
Version: 2.1.0
OS: OS X
Submission from: (NULL) (67.124.246.46)


> x = charToRaw("12345")
> x
[1] 31 32 33 34 35
> save(x,file="x.Rda")
> rm(x)
> load("x.Rda")
> x
[1] 00 00 00 00 00

Thats no fun.

From p.dalgaard at biostat.ku.dk  Mon Apr 25 10:12:22 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Apr 25 10:12:31 2005
Subject: [Rd] RAW types not restored from Rda files (PR#7812)
In-Reply-To: <20050425075523.42D7EA1DB@slim.kubism.ku.dk>
References: <20050425075523.42D7EA1DB@slim.kubism.ku.dk>
Message-ID: <x2pswjl1g9.fsf@turmalin.kubism.ku.dk>

ellis@stat.harvard.edu writes:

> Full_Name: Byron Ellis
> Version: 2.1.0
> OS: OS X
> Submission from: (NULL) (67.124.246.46)
> 
> 
> > x = charToRaw("12345")
> > x
> [1] 31 32 33 34 35
> > save(x,file="x.Rda")
> > rm(x)
> > load("x.Rda")
> > x
> [1] 00 00 00 00 00
> 
> Thats no fun.

It's not happening to me though (with R-devel). Can you do a hex dump
of the x.Rda file so that we can see whether the load or the save is
failing? As in

$ od -x x.Rda
0000000 4452 3258 580a 000a 0000 0002 0202 0000
0000020 0401 0000 0400 0002 0000 0001 1000 0009
0000040 0000 7801 0000 1800 0000 0500 3231 3433
0000060 0035 0000 00fe
0000065



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From eTrust_InoculateIT_Lotus_Notes_Domino_Option at BLNET.COM  Mon Apr 25 11:37:24 2005
From: eTrust_InoculateIT_Lotus_Notes_Domino_Option at BLNET.COM (eTrust_InoculateIT_Lotus_Notes_Domino_Option@BLNET.COM)
Date: Mon Apr 25 11:37:35 2005
Subject: [Rd] eTrust InoculateIT Lotus Notes Domino Option detected virus!
	(PR#7813)
Message-ID: <20050425093724.AD58AA21B@slim.kubism.ku.dk>


eTrust InoculateIT Lotus Notes Domino Option detected a virus infection in
an e-mail from [r-bugs@r-project.org] to [jack@blnet.com] with subject
[Nuyrhdokdsnxua].  Infected attachment(s):  [dzn.pif]  Action taken:  File
Deleted

From p.dalgaard at biostat.ku.dk  Mon Apr 25 12:08:17 2005
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Mon Apr 25 12:08:24 2005
Subject: [Rd] RAW types not restored from Rda files (PR#7812)
Message-ID: <20050425100817.19089A21F@slim.kubism.ku.dk>

Byron Ellis <ellis@stat.harvard.edu> writes:

> There's an endian difference, but other than that our results are
> identical:
> 
> 0000000     5244    5832    0a58    0a00    0000    0200    0202    0000
> 0000020     0104    0000    0004    0200    0000    0100    0010    0900
> 0000040     0000    0178    0000    0018    0000    0005    0000    0000
> 0000060     0000    0000    fe00
> 0000065
> 
> I updated from SVN and checked that as well, no luck. I'm a wee bit
> suspicious of saveload.c, which doesn't seem to know anything about
> RAWSXP at all.

....

> > $ od -x x.Rda
> > 0000000 4452 3258 580a 000a 0000 0002 0202 0000
> > 0000020 0401 0000 0400 0002 0000 0001 1000 0009
> > 0000040 0000 7801 0000 1800 0000 0500 3231 3433
> > 0000060 0035 0000 00fe
> > 0000065

Look closer! The "payload" is the five bytes around 0000060 and they
don't seem at all similar to me. So save() is to blame.

BTW, I'm redirecting this back to R-bugs. It is not a good idea to
take this kind of stuff to private email, for various good reasons in
general, but particularly so in this case since I don't run OSX!

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From manager at molbiol.ox.ac.uk  Mon Apr 25 14:12:11 2005
From: manager at molbiol.ox.ac.uk (manager@molbiol.ox.ac.uk)
Date: Mon Apr 25 14:12:19 2005
Subject: [Rd] Failed to install gbm_1.4-2 (PR#7814)
Message-ID: <20050425121211.EF9C7A21A@slim.kubism.ku.dk>

Full_Name: The Manager
Version: 2.0.1
OS: Solaris 9
Submission from: (NULL) (129.67.80.243)


> install.packages("gbm")
trying URL `http://cran.uk.r-project.org/src/contrib/PACKAGES'
Content type `text/plain; charset=ISO-8859-1' length 52975 bytes
opened URL
==================================================
downloaded 51Kb

trying URL `http://cran.uk.r-project.org/src/contrib/gbm_1.4-2.tar.gz'
Content type `application/x-gzip' length 252551 bytes
opened URL
==================================================
downloaded 246Kb
* Installing *source* package 'gbm' ...
** libs
g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
adaboost.cpp -oadaboost.o
g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
bernoulli.cpp -o bernoulli.o
g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
coxph.cpp -o coxph.o
g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
dataset.cpp -o dataset.o
g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
distribution.cpp -o distribution.o
g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
gaussian.cpp -ogaussian.o
g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
gbm.cpp -o gbm.o
g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
gbm_engine.cpp -o gbm_engine.o
g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
gbmentry.cpp -ogbmentry.o
gbmentry.cpp: In function `SEXPREC* gbm_shrink_pred(SEXPREC*, SEXPREC*,
SEXPREC*, SEXPREC*, SEXPREC*, SEXPREC*, SEXPREC*, SEXPREC*, SEXPREC*,
SEXPREC*)':
gbmentry.cpp:677: error: `NAN' undeclared (first use this function)
gbmentry.cpp:677: error: (Each undeclared identifier is reported only once for
each function it appears in.)
make: *** [gbmentry.o] Error 1
ERROR: compilation failed for package 'gbm'
** Removing '/package/R/2.0.1-32bit/lib/R/library/gbm'
** Restoring previous '/package/R/2.0.1-32bit/lib/R/library/gbm'

Delete downloaded files (y/N)? y

Warning message:
Installation of package gbm had non-zero exit status in:
install.packages("gbm")
> q()

From roebuck at odin.mdacc.tmc.edu  Mon Apr 25 16:23:30 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Mon Apr 25 16:23:40 2005
Subject: [Rd] RAqua Crashes Flushing Console
Message-ID: <Pine.OSF.4.58.0504250917510.494366@odin.mdacc.tmc.edu>

Anyone else experiencing crashes when attempting to flush
the console with the R GUI on OS X? I get a consistent
crash launching the app-bundle and entering the following
command:

> flush.console()

--------

platform powerpc-apple-darwin6.8
arch     powerpc
os       darwin6.8
system   powerpc, darwin6.8
status
major    2
minor    0.1
year     2004
month    11
day      15
language R


----------------------------------------------------------
SIGSIG -- signature too long (core dumped)

From replies-discarded at sas.com  Mon Apr 25 16:39:28 2005
From: replies-discarded at sas.com (replies-discarded@sas.com)
Date: Mon Apr 25 16:39:35 2005
Subject: [Rd] Notification of removed compressed attachment - ple (PR#7815)
Message-ID: <20050425143928.576A8A21F@slim.kubism.ku.dk>

Please read this notification carefully.  Almost certainly, you need not contact your Help Desk at this time.

A compressed file attachment was removed from the email described below because it did not comply with our email policies. This does not mean that a virus-infected attachment was removed. However, it is our policy to restrict the free flow of this type of attachment in order to protect ourselves and our customers from the damage that can be caused by viruses that are sometimes transported in these files.

If a business need exists to transfer this type of file by email, the sender/recipient within our company should refer to http://sww.sas.com/helpdesk/documents/outlook/CompressedAttachments.htm. The sender/recipient external to our company may refer to http://support.sas.com/misc/mail for additional information.

++++++++++++++
Sender: r-bugs@r-project.org
Recipient(s):  adam@unx.sas.com
Received:  Mon Apr 25 10:39:10 2005
Subject of Message:  Good day

Filter Type: Advanced Content Filter
Event:
file.zip:HEADER Action on Attachment: STRIP

++++++++++++++

From replies-discarded at sas.com  Mon Apr 25 16:39:36 2005
From: replies-discarded at sas.com (replies-discarded@sas.com)
Date: Mon Apr 25 16:39:43 2005
Subject: [Rd] Mail could not be delivered (PR#7816)
Message-ID: <20050425143936.8F51DA1C3@slim.kubism.ku.dk>


--------------InterScan_NT_MIME_Boundary
Content-type: text/plain

****** Message from InterScan Messaging Security Suite ******


Sent <<< RCPT TO:<adam@unx.sas.com>
Received >>> 550 5.1.1 <adam@unx.sas.com>... user unknown

Unable to deliver message to <adam@unx.sas.com>.

************************     End of message     **********************

--------------InterScan_NT_MIME_Boundary
Content-type: message/rfc822

Received: from merc97.na.sas.com ([10.16.11.211]) by merc91.na.sas.com with InterScan Messaging Security Suite; Mon, 25 Apr 2005 10:39:10 -0400
Received: from r-project.org ([210.115.59.17]) by merc97.na.sas.com with Microsoft SMTPSVC(6.0.3790.211);
	 Mon, 25 Apr 2005 10:39:08 -0400
From: r-bugs@r-project.org
To: adam@unx.sas.com
Subject: Good day
Date: Mon, 25 Apr 2005 23:39:06 +0900
MIME-Version: 1.0
Content-Type: multipart/mixed;
	boundary="----=_NextPart_000_0003_2AEF9342.1E8075A5"
X-Priority: 3
X-MSMail-Priority: Normal
Return-Path: r-bugs@r-project.org
Message-ID: <MERC976tcZl951qxnEa000f9fcc@merc97.na.sas.com>
X-OriginalArrivalTime: 25 Apr 2005 14:39:08.0410 (UTC) FILETIME=[89BA9DA0:01C549A4]

This is a multi-part message in MIME format.

------=_NextPart_000_0003_2AEF9342.1E8075A5
Content-Type: text/plain;
	charset="Windows-1252"
Content-Transfer-Encoding: 7bit

The message contains Unicode characters and has been sent as a binary attachment.


------=_NextPart_000_0003_2AEF9342.1E8075A5--



--------------InterScan_NT_MIME_Boundary--

From replies-discarded at sas.com  Mon Apr 25 17:40:42 2005
From: replies-discarded at sas.com (SAS Postmaster 91)
Date: Mon Apr 25 17:40:51 2005
Subject: [Rd] Mail could not be delivered
Message-ID: <200504251540.j3PFehvc025898@hypatia.math.ethz.ch>

****** Message from InterScan Messaging Security Suite ******


Sent <<< RCPT TO:<jerry@unx.sas.com>
Received >>> 550 5.1.1 <jerry@unx.sas.com>... user unknown

Unable to deliver message to <jerry@unx.sas.com>.

************************     End of message     **********************
-------------- next part --------------
An embedded message was scrubbed...
From: r-devel@r-project.org
Subject: Status
Date: Tue, 26 Apr 2005 00:40:38 +0900
Size: 1027
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20050425/c4b139a6/attachment.mht
From replies-discarded at sas.com  Mon Apr 25 17:40:42 2005
From: replies-discarded at sas.com (SAS Postmaster 91)
Date: Mon Apr 25 17:40:53 2005
Subject: [Rd] Notification of removed compressed attachment - please read
	for details 
Message-ID: <200504251540.j3PFeiBA025901@hypatia.math.ethz.ch>

Please read this notification carefully.  Almost certainly, you need not contact your Help Desk at this time.

A compressed file attachment was removed from the email described below because it did not comply with our email policies. This does not mean that a virus-infected attachment was removed. However, it is our policy to restrict the free flow of this type of attachment in order to protect ourselves and our customers from the damage that can be caused by viruses that are sometimes transported in these files.

If a business need exists to transfer this type of file by email, the sender/recipient within our company should refer to http://sww.sas.com/helpdesk/documents/outlook/CompressedAttachments.htm. The sender/recipient external to our company may refer to http://support.sas.com/misc/mail for additional information.

++++++++++++++
Sender: r-devel@r-project.org
Recipient(s):  jerry@unx.sas.com
Received:  Mon Apr 25 11:40:42 2005
Subject of Message:  Status

Filter Type: Advanced Content Filter
Event:
hcbts.zip:HEADER Action on Attachment: STRIP

++++++++++++++

From saveez at hotmail.com  Mon Apr 25 18:35:08 2005
From: saveez at hotmail.com (Ali -)
Date: Mon Apr 25 18:35:18 2005
Subject: [Rd] Speeding up library loading
Message-ID: <BAY17-F35B2B8F6B3220D1E1379CD1200@phx.gbl>

(1) When R tries to load a library, does it load 'everything' in the library 
at once?

(2) Is there any options to 'load as you go'?

From ligges at statistik.uni-dortmund.de  Mon Apr 25 18:51:50 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Apr 25 18:51:20 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <BAY17-F35B2B8F6B3220D1E1379CD1200@phx.gbl>
References: <BAY17-F35B2B8F6B3220D1E1379CD1200@phx.gbl>
Message-ID: <426D2026.9070201@statistik.uni-dortmund.de>

Ali - wrote:

> (1) When R tries to load a library, does it load 'everything' in the 
> library at once?

No, see ?lazyLoad

> (2) Is there any options to 'load as you go'?

Well, this is the way R does it....

Uwe Ligges



> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From maechler at stat.math.ethz.ch  Mon Apr 25 19:14:20 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Apr 25 19:14:28 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <426D2026.9070201@statistik.uni-dortmund.de>
References: <BAY17-F35B2B8F6B3220D1E1379CD1200@phx.gbl>
	<426D2026.9070201@statistik.uni-dortmund.de>
Message-ID: <17005.9580.496192.296113@stat.math.ethz.ch>

>>>>> "UweL" == Uwe Ligges <ligges@statistik.uni-dortmund.de>
>>>>>     on Mon, 25 Apr 2005 18:51:50 +0200 writes:

    UweL> Ali - wrote:
    >> (1) When R tries to load a library, does it load 'everything' in the 
    >> library at once?

    UweL> No, see ?lazyLoad

are you sure Ali is talking about *package*s.
He did use the word "library" though, and most of us (including
Uwe!) know the difference...

    >> (2) Is there any options to 'load as you go'?

    UweL> Well, this is the way R does it....

for packages yes, because of lazyloading, as Uwe mentioned above.

For libraries, (you know: the things you get from compiling and
linking C code ..), it may be a bit different.

What do you really mean, packages or libraries,
Ali?

From saveez at hotmail.com  Mon Apr 25 20:16:06 2005
From: saveez at hotmail.com (Ali -)
Date: Mon Apr 25 20:16:22 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <17005.9580.496192.296113@stat.math.ethz.ch>
Message-ID: <BAY17-F3987DC3947745C8B240B5D1200@phx.gbl>


>
>     UweL> Ali - wrote:
>     >> (1) When R tries to load a library, does it load 'everything' in 
>the
>     >> library at once?
>
>     UweL> No, see ?lazyLoad
>
>are you sure Ali is talking about *package*s.
>He did use the word "library" though, and most of us (including
>Uwe!) know the difference...
>
>     >> (2) Is there any options to 'load as you go'?
>
>     UweL> Well, this is the way R does it....
>
>for packages yes, because of lazyloading, as Uwe mentioned above.
>
>For libraries, (you know: the things you get from compiling and
>linking C code ..), it may be a bit different.
>
>What do you really mean, packages or libraries,
>Ali?

Well, the terminology used here is a bit confusing. ?library shows something 
like 'library(package)' and that's why I used the term 'library' for loading 
packages. The package does load some dll's but what I meant by library was 
actually package.

The package I am working on currently has one big R file (~ 4 Mb) and this 
causes at least 2 troubles:

(1) Things are slow:

    (a) Installation with (LazyLoad = Yes) is slow. Then when the library is 
loaded into R, the loading is slow too. So LazyLoad is of not big help.

    (b) Installation with (SaveImage = Yes) is -extremely- slow. To give you 
some idea, compiling the associated C++ code takes around 10 mins while 
saving the R images takes more than 40 mins (the package is a wrapper for 
some C++ libraries. All the R functions do is to call .Call). this doesn't 
improve the loading speed as well.
    (c) Installation with (LazyLoad = Yes) AND (SaveImage = Yes) causes this 
error:

    preparing package <package_name> for lazy loading
    make: *** [lazyload] Error 1
    *** Installation of <package_name> failed ***

    It is likely that this happens because of some memory problems.

(2) After all, when the package is loaded, not surprisingly, loads of memory 
is taken. It seems that the whole (huge) file is loaded into R at once and 
turning LazyLoad on or off doesn't make a difference when the package is 
big.

From ch_schneider_hi at freenet.de  Mon Apr 25 20:31:25 2005
From: ch_schneider_hi at freenet.de (ch_schneider_hi@freenet.de)
Date: Mon Apr 25 20:31:33 2005
Subject: [Rd] Problem with documentation: undefined page/section references
	in some PDFs (PR#7817)
Message-ID: <20050425183125.DEA11A21E@slim.kubism.ku.dk>

Hi,

I have just compiled R-base 2.1.0 using the spec-file for SuSE (slightly 
modified for the new R version).

In R-intro.pdf and R-FAQ.pdf I discovered references like this one:
<undefined> [The command-line editor], page <undefined>
The other PDFs seem to be ok.

Compiling the sources without the spec led to the same result 
(configure ...; make; make dvi; make pdf).

(Running "make clean; make pdf" again in the manuals' source directory 
fixes the problem.)

Regards,
Christian

From ligges at statistik.uni-dortmund.de  Mon Apr 25 20:34:34 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Apr 25 20:34:12 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <BAY17-F3987DC3947745C8B240B5D1200@phx.gbl>
References: <BAY17-F3987DC3947745C8B240B5D1200@phx.gbl>
Message-ID: <426D383A.1070208@statistik.uni-dortmund.de>

Ali - wrote:
> 
>>
>>     UweL> Ali - wrote:
>>     >> (1) When R tries to load a library, does it load 'everything' 
>> in the
>>     >> library at once?
>>
>>     UweL> No, see ?lazyLoad
>>
>> are you sure Ali is talking about *package*s.
>> He did use the word "library" though, and most of us (including
>> Uwe!) know the difference...
>>
>>     >> (2) Is there any options to 'load as you go'?
>>
>>     UweL> Well, this is the way R does it....
>>
>> for packages yes, because of lazyloading, as Uwe mentioned above.
>>
>> For libraries, (you know: the things you get from compiling and
>> linking C code ..), it may be a bit different.
>>
>> What do you really mean, packages or libraries,
>> Ali?
> 
> 
> Well, the terminology used here is a bit confusing. ?library shows 
> something like 'library(package)' and that's why I used the term 
> 'library' for loading packages. The package does load some dll's but 
> what I meant by library was actually package.
> 
> The package I am working on currently has one big R file (~ 4 Mb) and 
> this causes at least 2 troubles:
> 
> (1) Things are slow:
> 
>    (a) Installation with (LazyLoad = Yes) is slow. Then when the library 
> is loaded into R, the loading is slow too. So LazyLoad is of not big help.
> 
>    (b) Installation with (SaveImage = Yes) is -extremely- slow. To give 
> you some idea, compiling the associated C++ code takes around 10 mins 
> while saving the R images takes more than 40 mins (the package is a 
> wrapper for some C++ libraries. All the R functions do is to call 
> .Call). this doesn't improve the loading speed as well.
>    (c) Installation with (LazyLoad = Yes) AND (SaveImage = Yes) causes 
> this error:
> 
>    preparing package <package_name> for lazy loading
>    make: *** [lazyload] Error 1
>    *** Installation of <package_name> failed ***
> 
>    It is likely that this happens because of some memory problems.
> 
> (2) After all, when the package is loaded, not surprisingly, loads of 
> memory is taken. It seems that the whole (huge) file is loaded into R at 
> once and turning LazyLoad on or off doesn't make a difference when the 
> package is big.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


4Mb R file just containing .Call()s? Never seen something like that.
If these are all very small functions, lazy load won't be of that 
advantage, because you have to load the index file anyway.

You know, R including all base and recommended packages has just ~ 6Mb 
of R code. Are you really sure about your code?

Uwe Ligges

From stefano.iacus at unimi.it  Mon Apr 25 20:39:01 2005
From: stefano.iacus at unimi.it (stefano iacus)
Date: Mon Apr 25 20:39:07 2005
Subject: [Rd] RAqua Crashes Flushing Console
In-Reply-To: <Pine.OSF.4.58.0504250917510.494366@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0504250917510.494366@odin.mdacc.tmc.edu>
Message-ID: <792827d22c49804d9477a69651091529@unimi.it>

This has been fixed and a bug in 2.0.1.
2.1.0 binary will be fine.
stefano
p.s. You are actually referring to R.app no RAqua (the old carbon code)
On 25/apr/05, at 16:23, Paul Roebuck wrote:

> Anyone else experiencing crashes when attempting to flush
> the console with the R GUI on OS X? I get a consistent
> crash launching the app-bundle and entering the following
> command:
>
>> flush.console()
>
> --------
>
> platform powerpc-apple-darwin6.8
> arch     powerpc
> os       darwin6.8
> system   powerpc, darwin6.8
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
>
>
> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From saveez at hotmail.com  Mon Apr 25 20:52:02 2005
From: saveez at hotmail.com (Ali -)
Date: Mon Apr 25 20:52:17 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <426D383A.1070208@statistik.uni-dortmund.de>
Message-ID: <BAY17-F33CE9F0BF730E75419D3B9D1200@phx.gbl>


>4Mb R file just containing .Call()s? Never seen something like that.
>If these are all very small functions, lazy load won't be of that 
>advantage, because you have to load the index file anyway.
>
>You know, R including all base and recommended packages has just ~ 6Mb of R 
>code. Are you really sure about your code?

Positively. The wrapped library is actually much bigger than R, it brings a 
few hundered new classes to R. The library has been already wrapped to other 
languages like java, and the loading speed for these other languages is 
quite reasonable. I cannot see any reasons why not this can be done with R 
too -- as a computational application R is supposed to be efficient in all 
ways.

It seems that, so far, no packages as big as this one have been created for 
R. I would appreciate any clues from the development team for improving the 
performance of big packages in R.

From rpeng at jhsph.edu  Mon Apr 25 21:30:10 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon Apr 25 21:30:20 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <BAY17-F33CE9F0BF730E75419D3B9D1200@phx.gbl>
References: <BAY17-F33CE9F0BF730E75419D3B9D1200@phx.gbl>
Message-ID: <426D4542.1080008@jhsph.edu>

Is it possible to break the package into multiple parts, perhaps 
like a bundle?  Then you could only load the parts that you need 
at any particular time.

-roger

Ali - wrote:
> 
>> 4Mb R file just containing .Call()s? Never seen something like that.
>> If these are all very small functions, lazy load won't be of that 
>> advantage, because you have to load the index file anyway.
>>
>> You know, R including all base and recommended packages has just ~ 6Mb 
>> of R code. Are you really sure about your code?
> 
> 
> Positively. The wrapped library is actually much bigger than R, it 
> brings a few hundered new classes to R. The library has been already 
> wrapped to other languages like java, and the loading speed for these 
> other languages is quite reasonable. I cannot see any reasons why not 
> this can be done with R too -- as a computational application R is 
> supposed to be efficient in all ways.
> 
> It seems that, so far, no packages as big as this one have been created 
> for R. I would appreciate any clues from the development team for 
> improving the performance of big packages in R.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/

From saveez at hotmail.com  Mon Apr 25 21:54:10 2005
From: saveez at hotmail.com (Ali -)
Date: Mon Apr 25 21:54:18 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <426D4542.1080008@jhsph.edu>
Message-ID: <BAY17-F29363AC45E862245EEDB50D1200@phx.gbl>


>Is it possible to break the package into multiple parts, perhaps like a 
>bundle?  Then you could only load the parts that you need at any particular 
>time.
>

It could be done, but the question is, what if one of the packages in the 
bundle depends on all of the rest? And the bigger question is, why lazy 
loading is not efficient when it comes to many small functions?

From rpeng at jhsph.edu  Mon Apr 25 21:57:01 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon Apr 25 21:57:12 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <BAY17-F29363AC45E862245EEDB50D1200@phx.gbl>
References: <BAY17-F29363AC45E862245EEDB50D1200@phx.gbl>
Message-ID: <426D4B8D.5090401@jhsph.edu>

I think the reason, as Uwe already said, is that you have to load 
the lazyload index file, and in your case that file is likely to 
be as large as the R file itself.

-roger

Ali - wrote:
> 
>> Is it possible to break the package into multiple parts, perhaps like 
>> a bundle?  Then you could only load the parts that you need at any 
>> particular time.
>>
> 
> It could be done, but the question is, what if one of the packages in 
> the bundle depends on all of the rest? And the bigger question is, why 
> lazy loading is not efficient when it comes to many small functions?
> 
> _________________________________________________________________
> Express yourself instantly with MSN Messenger! Download today it's FREE! 
> http://messenger.msn.click-url.com/go/onm00200471ave/direct/01/
> 
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/

From murdoch at stats.uwo.ca  Mon Apr 25 22:02:51 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon Apr 25 22:02:26 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <BAY17-F29363AC45E862245EEDB50D1200@phx.gbl>
References: <BAY17-F29363AC45E862245EEDB50D1200@phx.gbl>
Message-ID: <426D4CEB.7010802@stats.uwo.ca>

Ali - wrote:
> 
>> Is it possible to break the package into multiple parts, perhaps like 
>> a bundle?  Then you could only load the parts that you need at any 
>> particular time.
>>
> 
> It could be done, but the question is, what if one of the packages in 
> the bundle depends on all of the rest? And the bigger question is, why 
> lazy loading is not efficient when it comes to many small functions?

Lazy loading just converts an object into a small instruction to load 
the object. If the object was already small, there's no advantage to 
that.  It's mainly designed to avoid memory use (some rarely used 
objects can be gigantic).

Duncan Murdoch

From tlumley at u.washington.edu  Mon Apr 25 22:25:20 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Apr 25 22:25:32 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <426D4CEB.7010802@stats.uwo.ca>
References: <BAY17-F29363AC45E862245EEDB50D1200@phx.gbl>
	<426D4CEB.7010802@stats.uwo.ca>
Message-ID: <Pine.A41.4.61b.0504251314110.36074@homer03.u.washington.edu>

On Mon, 25 Apr 2005, Duncan Murdoch wrote:

> Ali - wrote:
>> 
>>> Is it possible to break the package into multiple parts, perhaps like a 
>>> bundle?  Then you could only load the parts that you need at any 
>>> particular time.
>>> 
>> 
>> It could be done, but the question is, what if one of the packages in the 
>> bundle depends on all of the rest? And the bigger question is, why lazy 
>> loading is not efficient when it comes to many small functions?
>
> Lazy loading just converts an object into a small instruction to load the 
> object. If the object was already small, there's no advantage to that.  It's 
> mainly designed to avoid memory use (some rarely used objects can be 
> gigantic).

>From a design point of view the reason is that this isn't the problem lazy 
loading is trying to solve. We didn't have a problem with packages that 
have huge number of small objects, but we did have a problem with packages 
that had a moderate number of moderately large objects.

In addition, trying to optimize performance is not usually a good idea 
unless you can measure the performance of different implementations on 
real applications, and we didn't have applications like that.


 	-thomas

From saveez at hotmail.com  Mon Apr 25 23:05:15 2005
From: saveez at hotmail.com (Ali -)
Date: Mon Apr 25 23:05:24 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <Pine.A41.4.61b.0504251314110.36074@homer03.u.washington.edu>
Message-ID: <BAY17-F11AA791A3E71A75A6F785BD1200@phx.gbl>



>>Lazy loading just converts an object into a small instruction to load the 
>>object. If the object was already small, there's no advantage to that.  
>>It's mainly designed to avoid memory use (some rarely used objects can be 
>>gigantic).
>
>From a design point of view the reason is that this isn't the problem lazy 
>loading is trying to solve. We didn't have a problem with packages that 
>have huge number of small objects, but we did have a problem with packages 
>that had a moderate number of moderately large objects.
>
>In addition, trying to optimize performance is not usually a good idea 
>unless you can measure the performance of different implementations on real 
>applications, and we didn't have applications like that.

Assume 100 C++ classes each class having 100 member functions. After 
wrapping these classes into R, if the wrapping design is class-oriented we 
should have like 100 objects. At the same time, if the wrapping design is 
function-oriented we have like 10`000 objects which are too lazy for lazy 
loading.

I have tried wrapping exactly the same classes by R.oo based on S3 and the 
outcome package was much faster in both installation and loading. The 
package went slow once I tried it with S4. I guess R.oo makes the package 
more class-oriented while S4 object-orientation is really function-oriented 
causing all this friction in installation and loading.

Is there any way to ask R to lazy-load each object as a 'bundle of S4 
methods with the same class'?

From mulakken1 at llnl.gov  Tue Apr 26 01:57:46 2005
From: mulakken1 at llnl.gov (mulakken1@llnl.gov)
Date: Tue Apr 26 01:57:54 2005
Subject: [Rd] associating R with .R and .RData files (PR#7818)
Message-ID: <20050425235746.DB1F3A21D@slim.kubism.ku.dk>

Full_Name: Nisha Mulakken
Version: 2.1.0
OS: Windows XP
Submission from: (NULL) (134.9.187.231)


Hi,

I uninstalled all previous versions of R, and installed R 2.1.0. I noticed that
even though I specified that I wanted all .R and .RData files to be associated
with R during the installation, those files are not associated with R.

Thanks,
Nisha

From sfalcon at fhcrc.org  Tue Apr 26 05:30:37 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue Apr 26 05:30:49 2005
Subject: [Rd] Feature request: report the url if 404 error occurs
Message-ID: <m2ll76rz8i.fsf@fhcrc.org>

Currently, the connection code does not include the URL in the warning
message when a 404 response is received:

myUrl = "http://www.r-project.org/ABadPage.html"
con = url(myUrl)
readLines(con)

  Error in readLines(con) : cannot open the connection
  In addition: Warning message:
  cannot open: HTTP status was '404 Not Found' 

Would it be possible (and desirable) to include the URL in the warning
message?  Here's an example:

Error in readLines(con) : cannot open the connection
In addition: Warning message:
cannot open 'http://www.r-project.org/ABadPage.html': HTTP status was '404 Not Found' 


+ seth

From srjafarzadeh at gmail.com  Tue Apr 26 07:37:30 2005
From: srjafarzadeh at gmail.com (Seyed Reza Jafarzadeh)
Date: Tue Apr 26 07:37:38 2005
Subject: [Rd] associating R with .R and .RData files (PR#7818)
In-Reply-To: <20050425235746.DB1F3A21D@slim.kubism.ku.dk>
References: <20050425235746.DB1F3A21D@slim.kubism.ku.dk>
Message-ID: <83217d0050425223716119568@mail.gmail.com>

Nisha,

If you run R under Windows (XP), right-click on a .R or .Rdata file
and select "Open With" > "Choose Program..." > "R for Windows GUI
front-end" from the programs list. Do not forget to select the option
"Always use the selected program to open this kind of file" before
clicking on OK. If the "R for Windows GUI front-end" is not on the
programs list, browse your computer (the directory in which you
installed R) by clicking on "Browse..." (it must be in "Program Files"
> "R" > "rw2???" > "bin" > "Rgui").

I hope this helps.
Reza



On 4/25/05, mulakken1@llnl.gov <mulakken1@llnl.gov> wrote:
> Full_Name: Nisha Mulakken
> Version: 2.1.0
> OS: Windows XP
> Submission from: (NULL) (134.9.187.231)
> 
> Hi,
> 
> I uninstalled all previous versions of R, and installed R 2.1.0. I noticed that
> even though I specified that I wanted all .R and .RData files to be associated
> with R during the installation, those files are not associated with R.
> 
> Thanks,
> Nisha
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From john.maindonald at anu.edu.au  Tue Apr 26 07:41:56 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue Apr 26 07:42:13 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <200504251000.j3PA01lD009332@hypatia.math.ethz.ch>
References: <200504251000.j3PA01lD009332@hypatia.math.ethz.ch>
Message-ID: <09c07cec416193d86febad7476a5ff0f@anu.edu.au>

The web page http://wwwmaths.anu.edu.au/~johnm/r/plot-lm/
now includes files:
plot.lm.RData: Image for file for plot6.lm, a version of plot.lm in 
which
   David Firth's Cook's distance vs leverage/(1-leverage) plot is plot 6.
   The tick labels are in units of leverage, and the contour labels are
   in units of absolute values of the standardized residual.

plot6.lm.Rd file: A matching help file

Comments will be welcome.

Another issue, discussed recently on r-help, is that when the model
formula is long, the default sub.caption=deparse(x$call) is broken
into multiple text elements and overwrites.  The only clean and
simple way that I can see to handle is to set a default that tests
whether the formula is broken into multiple text elements, and if it is
then omit it.  Users can then use their own imaginative skills, and
such suggestions as have been made on r-help, to construct
whatever form of labeling best suits their case, their imaginative
skills and their coding skills.

John Maindonald.


On 25 Apr 2005, at 8:00 PM, David Firth wrote:

> From: David Firth <d.firth@warwick.ac.uk>
> Date: 24 April 2005 10:23:51 PM
> To: John Maindonald <john.maindonald@anu.edu.au>
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] Enhanced version of plot.lm()
>
>
> On 24 Apr 2005, at 05:37, John Maindonald wrote:
>
>> I'd not like to lose the signs of the residuals. Also, as
>> plots 1-3 focus on residuals, there is less of a mental
>> leap in moving to residuals vs leverage; residuals vs
>> leverage/(1-leverage) would also be in the same spirit.
>
> Yes, I know what you mean.  Mental leaps are a matter of 
> taste...pitfalls, etc, come to mind.
>
>>
>> Maybe, one way or another, both plots (residuals vs
>> a function of leverage, and the plot from Hinkley et al)
>> should go in.  The easiest way to do this is to add a
>> further which=6.  I will do this if the consensus is that
>> this is the right way to go.  In any case, I'll add the
>> Hinkley et al reference (author of the contribution that
>> includes p.74?) to the draft help page.
>
> Sorry, I should have given the full reference, which (in BibTeX format 
> from CIS) is
>
> @inproceedings{Firt:gene:1991,
>     author = {Firth, D.},
>     title = {Generalized Linear Models},
>     year = {1991},
>     booktitle = {Statistical Theory and Modelling. In Honour of Sir 
> David Cox, FRS},
>     editor = {Hinkley, D. V. and Reid, N. and Snell, E. J.},
>     publisher = {Chapman \& Hall Ltd},
>     pages = {55--82},
>     keywords = {Analysis of deviance; Likelihood}
> }
>
> David
>
John Maindonald             email: john.maindonald@anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

	[[alternative text/enriched version deleted]]

From john.maindonald at anu.edu.au  Tue Apr 26 07:44:26 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue Apr 26 07:44:38 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <200504251000.j3PA01lD009332@hypatia.math.ethz.ch>
References: <200504251000.j3PA01lD009332@hypatia.math.ethz.ch>
Message-ID: <b21d1d1a13e8f82d4e1d44c233e9f76e@anu.edu.au>

The web page http://wwwmaths.anu.edu.au/~johnm/r/plot-lm/
now includes files:
plot.lm.RData: Image for file for plot6.lm, a version of plot.lm in 
which
   David Firth's Cook's distance vs leverage/(1-leverage) plot is plot 6.
   The tick labels are in units of leverage, and the contour labels are
   in units of absolute values of the standardized residual.

plot6.lm.Rd file: A matching help file

Comments will be welcome.

Another issue, discussed recently on r-help, is that when the model
formula is long, the default sub.caption=deparse(x$call) is broken
into multiple text elements and overwrites.  The only clean and
simple way that I can see to handle is to set a default that tests
whether the formula is broken into multiple text elements, and if it is
then omit it.  Users can then use their own imaginative skills, and
such suggestions as have been made on r-help, to construct
whatever form of labeling best suits their case, their imaginative
skills and their coding skills.

John Maindonald.


On 25 Apr 2005, at 8:00 PM, David Firth wrote:

> From: David Firth <d.firth@warwick.ac.uk>
> Date: 24 April 2005 10:23:51 PM
> To: John Maindonald <john.maindonald@anu.edu.au>
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] Enhanced version of plot.lm()
>
>
> On 24 Apr 2005, at 05:37, John Maindonald wrote:
>
>> I'd not like to lose the signs of the residuals. Also, as
>> plots 1-3 focus on residuals, there is less of a mental
>> leap in moving to residuals vs leverage; residuals vs
>> leverage/(1-leverage) would also be in the same spirit.
>
> Yes, I know what you mean.  Mental leaps are a matter of 
> taste...pitfalls, etc, come to mind.
>
>>
>> Maybe, one way or another, both plots (residuals vs
>> a function of leverage, and the plot from Hinkley et al)
>> should go in.  The easiest way to do this is to add a
>> further which=6.  I will do this if the consensus is that
>> this is the right way to go.  In any case, I'll add the
>> Hinkley et al reference (author of the contribution that
>> includes p.74?) to the draft help page.
>
> Sorry, I should have given the full reference, which (in BibTeX format 
> from CIS) is
>
> @inproceedings{Firt:gene:1991,
>     author = {Firth, D.},
>     title = {Generalized Linear Models},
>     year = {1991},
>     booktitle = {Statistical Theory and Modelling. In Honour of Sir 
> David Cox, FRS},
>     editor = {Hinkley, D. V. and Reid, N. and Snell, E. J.},
>     publisher = {Chapman \& Hall Ltd},
>     pages = {55--82},
>     keywords = {Analysis of deviance; Likelihood}
> }
>
> David
>
John Maindonald             email: john.maindonald@anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

From ripley at stats.ox.ac.uk  Tue Apr 26 08:25:27 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Apr 26 08:25:46 2005
Subject: [Rd] Feature request: report the url if 404 error occurs
In-Reply-To: <m2ll76rz8i.fsf@fhcrc.org>
References: <m2ll76rz8i.fsf@fhcrc.org>
Message-ID: <Pine.LNX.4.61.0504260721440.2948@gannet.stats>

On Mon, 25 Apr 2005, Seth Falcon wrote:

> Currently, the connection code does not include the URL in the warning
> message when a 404 response is received:
>
> myUrl = "http://www.r-project.org/ABadPage.html"
> con = url(myUrl)
> readLines(con)
>
>  Error in readLines(con) : cannot open the connection
>  In addition: Warning message:
>  cannot open: HTTP status was '404 Not Found'
>
> Would it be possible (and desirable) to include the URL in the warning
> message?  Here's an example:
>
> Error in readLines(con) : cannot open the connection
> In addition: Warning message:
> cannot open 'http://www.r-project.org/ABadPage.html': HTTP status was '404 Not Found'

It is part of `con':

> con
                              description
"http://www.r-project.org/ABadPage.html"
                                    class
                                    "url"
                                     mode
                                      "r"
                                     text
                                   "text"
                                   opened
                                 "closed"
                                 can read
                                    "yes"
                                can write
                                     "no"

Remember R is an interactive system: you just need to ask it for the 
information you want.

This would be tedious to add, but you could submit a patch (remember there 
are at least three places to look at in the internet code).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From murdoch at stats.uwo.ca  Tue Apr 26 08:29:53 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue Apr 26 08:29:27 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <BAY17-F11AA791A3E71A75A6F785BD1200@phx.gbl>
References: <BAY17-F11AA791A3E71A75A6F785BD1200@phx.gbl>
Message-ID: <426DDFE1.9040705@stats.uwo.ca>

Ali - wrote:
> 
> 
>>> Lazy loading just converts an object into a small instruction to load 
>>> the object. If the object was already small, there's no advantage to 
>>> that.  It's mainly designed to avoid memory use (some rarely used 
>>> objects can be gigantic).
>>
>>
>> From a design point of view the reason is that this isn't the problem 
>> lazy loading is trying to solve. We didn't have a problem with 
>> packages that have huge number of small objects, but we did have a 
>> problem with packages that had a moderate number of moderately large 
>> objects.
>>
>> In addition, trying to optimize performance is not usually a good idea 
>> unless you can measure the performance of different implementations on 
>> real applications, and we didn't have applications like that.
> 
> 
> Assume 100 C++ classes each class having 100 member functions. After 
> wrapping these classes into R, if the wrapping design is class-oriented 
> we should have like 100 objects. At the same time, if the wrapping 
> design is function-oriented we have like 10`000 objects which are too 
> lazy for lazy loading.
> 
> I have tried wrapping exactly the same classes by R.oo based on S3 and 
> the outcome package was much faster in both installation and loading. 
> The package went slow once I tried it with S4. I guess R.oo makes the 
> package more class-oriented while S4 object-orientation is really 
> function-oriented causing all this friction in installation and loading.
> 
> Is there any way to ask R to lazy-load each object as a 'bundle of S4 
> methods with the same class'?

I don't think so.  There are ways to load a bundle of objects all at 
once (put them in an environment, attach the environment), but S4 
methods aren't self-contained, they need to be registered with the 
system.   You could probably write a function to load them and register 
them all at once, but I don't think it exists now.

Duncan Murdoch

From saveez at hotmail.com  Tue Apr 26 08:46:03 2005
From: saveez at hotmail.com (Ali -)
Date: Tue Apr 26 08:46:19 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <426DDFE1.9040705@stats.uwo.ca>
Message-ID: <BAY17-F3A3B8341367CB01364502D1210@phx.gbl>



>>
>>Assume 100 C++ classes each class having 100 member functions. After 
>>wrapping these classes into R, if the wrapping design is class-oriented we 
>>should have like 100 objects. At the same time, if the wrapping design is 
>>function-oriented we have like 10`000 objects which are too lazy for lazy 
>>loading.
>>
>>I have tried wrapping exactly the same classes by R.oo based on S3 and the 
>>outcome package was much faster in both installation and loading. The 
>>package went slow once I tried it with S4. I guess R.oo makes the package 
>>more class-oriented while S4 object-orientation is really 
>>function-oriented causing all this friction in installation and loading.
>>
>>Is there any way to ask R to lazy-load each object as a 'bundle of S4 
>>methods with the same class'?
>
>I don't think so.  There are ways to load a bundle of objects all at once 
>(put them in an environment, attach the environment), but S4 methods aren't 
>self-contained, they need to be registered with the system.   You could 
>probably write a function to load them and register them all at once, but I 
>don't think it exists now.
>
>Duncan Murdoch

(1) What is the difference between loading and registering objects in R?

(2) You are talking about 'loading and registering at once'. Isn't this 'at 
once' the cause of slow loading?

(3) Doesn't having many environments mean lose of efficiency again?

From rn001 at cebas.csic.es  Tue Apr 26 11:03:41 2005
From: rn001 at cebas.csic.es (javier garcia - CEBAS)
Date: Tue Apr 26 11:02:30 2005
Subject: [Rd] Fwd: R - C programm. calling load() from within C code
Message-ID: <20050426100328.3E35CA7AC6@cebas.csic.es>

Hi!

I've already asked in in R-help, but it seems that is more a topic for this
list.

This is the first time I'm trying to write a C program to be linked with R by
my own and I've got one (main) problem

1) I've got a stack of big matrixes, so to manage them I' using save() in the
 preparation process to save workspace (they are about 1000 matrixes and each

one occupies 4.2 MB in my hard disk):
> for ( i in 1:1000) {

	...
	save(temp, file=paste("temp_matrix",i,"R.sav",sep=""))
}


Later on, I would need to be able to use something like
load(paste("temp_matrix",i,"R.sav",sep=""))

to reload the corresponding matrix in each of the loops running within the C
code, and to be able to load this matrix, (called temp) into the C code.

I've tried to load the vector into the R workspace using load(a[i]) where a
is a vector with names of the maps, and also passing a list a in the call to
the C code, where each element of the list a[[i]] is the name of each map,
and tried to extract this names in the list to be used along with the
expresion, but nothing works.

With the html R-extensions help I've been able to load existing R objects in
run time into C, but I'm not able to use load() to put saved R object into
the R workspace and load them in C afterwards. Please, have anyone tried to
use this succesfully? Or you have any clue?


Thanks a lot for your help

Best regards,

Javier

From maechler at stat.math.ethz.ch  Tue Apr 26 12:13:38 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue Apr 26 12:16:48 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <b21d1d1a13e8f82d4e1d44c233e9f76e@anu.edu.au>
References: <200504251000.j3PA01lD009332@hypatia.math.ethz.ch>
	<40567787fcb17bee0bf9ecf403fb8e21@anu.edu.au>
	<320af97cfe90da4c59b7e9c8cd9956d4@anu.edu.au>
	<9717926f912f9fb045c57dd9be4e743c@warwick.ac.uk>
	<b21d1d1a13e8f82d4e1d44c233e9f76e@anu.edu.au>
Message-ID: <17006.5202.986122.321760@stat.math.ethz.ch>

>>>>> "JMd" == John Maindonald <john.maindonald@anu.edu.au>
>>>>>     on Tue, 26 Apr 2005 15:44:26 +1000 writes:

    JMd> The web page http://wwwmaths.anu.edu.au/~johnm/r/plot-lm/
    JMd> now includes files:
    JMd> plot.lm.RData: Image for file for plot6.lm, a version of plot.lm in 
    JMd> which
    JMd> David Firth's Cook's distance vs leverage/(1-leverage) plot is plot 6.
    JMd> The tick labels are in units of leverage, and the contour labels are
    JMd> in units of absolute values of the standardized residual.

    JMd> plot6.lm.Rd file: A matching help file

    JMd> Comments will be welcome.

Thank you John!

The *.Rd has the new references and a new example but
is not quite complete: the \usage{} has only 4 captions,
\arguments{ .. \item{which} ..}  only mentions '1:5' --- but
never mind.

One of the new examples is

    ## Replace Cook's distance plot by Residual-Leverage plot
    plot(lm.SR, which=c(1:3, 5))

and -- conceptually I'd really like to change the default from
'which = 1:4' to the above
'which=c(1:3, 5))' 

This would be non-compatible though for all those that have
always used the current default 1:4. 
OTOH, "MASS" or Peter Dalgaard's book don't mention  plot(<lm fit> )
or at least don't show it's result.

What do others think?
How problematic would a change be in the default plots that
plot.lm() produces?


    JMd> Another issue, discussed recently on r-help, is that when the model
    JMd> formula is long, the default sub.caption=deparse(x$call) is broken
    JMd> into multiple text elements and overwrites.  
good point!

    JMd>  The only clean and simple way that I can see to handle
    JMd> is to set a default that tests whether the formula is
    JMd> broken into multiple text elements, and if it is then
    JMd> omit it.  Users can then use their own imaginative
    JMd> skills, and such suggestions as have been made on
    JMd> r-help, to construct whatever form of labeling best
    JMd> suits their case, their imaginative skills and their
    JMd> coding skills.

Hmm, yes, but I think we (R programmers) could try a bit harder
to provide a reasonable default, e.g., something along
 
 cap <- deparse(x$call, width.cutoff = 500)[1]
 if((nc <- nchar(cap)) > 53)	    
     cap <- paste(substr(cap, 1, 50), "....", substr(cap, nc-2, nc))

{untested;  some of the details will differ;
 and the '53', '50' could depend on par("..") measures}


    JMd> John Maindonald.


    JMd> On 25 Apr 2005, at 8:00 PM, David Firth wrote:

    >> From: David Firth <d.firth@warwick.ac.uk>
    >> Date: 24 April 2005 10:23:51 PM
    >> To: John Maindonald <john.maindonald@anu.edu.au>
    >> Cc: r-devel@stat.math.ethz.ch
    >> Subject: Re: [Rd] Enhanced version of plot.lm()
    >> 
    >> 
    >> On 24 Apr 2005, at 05:37, John Maindonald wrote:
    >> 
    >>> I'd not like to lose the signs of the residuals. Also, as
    >>> plots 1-3 focus on residuals, there is less of a mental
    >>> leap in moving to residuals vs leverage; residuals vs
    >>> leverage/(1-leverage) would also be in the same spirit.
    >> 
    >> Yes, I know what you mean.  Mental leaps are a matter of 
    >> taste...pitfalls, etc, come to mind.
    >> 
    >>> 
    >>> Maybe, one way or another, both plots (residuals vs
    >>> a function of leverage, and the plot from Hinkley et al)
    >>> should go in.  The easiest way to do this is to add a
    >>> further which=6.  I will do this if the consensus is that
    >>> this is the right way to go.  In any case, I'll add the
    >>> Hinkley et al reference (author of the contribution that
    >>> includes p.74?) to the draft help page.
    >> 
    >> Sorry, I should have given the full reference, which (in BibTeX format 
    >> from CIS) is
    >> 
    >> @inproceedings{Firt:gene:1991,
    >> author = {Firth, D.},
    >> title = {Generalized Linear Models},
    >> year = {1991},
    >> booktitle = {Statistical Theory and Modelling. In Honour of Sir 
    >> David Cox, FRS},
    >> editor = {Hinkley, D. V. and Reid, N. and Snell, E. J.},
    >> publisher = {Chapman \& Hall Ltd},
    >> pages = {55--82},
    >> keywords = {Analysis of deviance; Likelihood}
    >> }
    >> 
    >> David
    >> 
    JMd> John Maindonald             email: john.maindonald@anu.edu.au
    JMd> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
    JMd> Centre for Bioinformation Science, Room 1194,
    JMd> John Dedman Mathematical Sciences Building (Building 27)
    JMd> Australian National University, Canberra ACT 0200.

    JMd> ______________________________________________
    JMd> R-devel@stat.math.ethz.ch mailing list
    JMd> https://stat.ethz.ch/mailman/listinfo/r-devel

>>>>> "JMd" == John Maindonald <john.maindonald@anu.edu.au>
>>>>>     on Tue, 26 Apr 2005 15:44:26 +1000 writes:

    JMd> The web page
    JMd> http://wwwmaths.anu.edu.au/~johnm/r/plot-lm/ now
    JMd> includes files: plot.lm.RData: Image for file for
    JMd> plot6.lm, a version of plot.lm in which David Firth's
    JMd> Cook's distance vs leverage/(1-leverage) plot is plot
    JMd> 6.  The tick labels are in units of leverage, and the
    JMd> contour labels are in units of absolute values of the
    JMd> standardized residual.

    JMd> plot6.lm.Rd file: A matching help file

    JMd> Comments will be welcome.

    JMd> Another issue, discussed recently on r-help, is that
    JMd> when the model formula is long, the default
    JMd> sub.caption=deparse(x$call) is broken into multiple
    JMd> text elements and overwrites.  The only clean and
    JMd> simple way that I can see to handle is to set a default
    JMd> that tests whether the formula is broken into multiple
    JMd> text elements, and if it is then omit it.  Users can
    JMd> then use their own imaginative skills, and such
    JMd> suggestions as have been made on r-help, to construct
    JMd> whatever form of labeling best suits their case, their
    JMd> imaginative skills and their coding skills.

    JMd> John Maindonald.


    JMd> On 25 Apr 2005, at 8:00 PM, David Firth wrote:

    >> From: David Firth <d.firth@warwick.ac.uk> Date: 24 April
    >> 2005 10:23:51 PM To: John Maindonald
    >> <john.maindonald@anu.edu.au> Cc:
    >> r-devel@stat.math.ethz.ch Subject: Re: [Rd] Enhanced
    >> version of plot.lm()
    >> 
    >> 
    >> On 24 Apr 2005, at 05:37, John Maindonald wrote:
    >> 
    >>> I'd not like to lose the signs of the residuals. Also,
    >>> as plots 1-3 focus on residuals, there is less of a
    >>> mental leap in moving to residuals vs leverage;
    >>> residuals vs leverage/(1-leverage) would also be in the
    >>> same spirit.
    >>  Yes, I know what you mean.  Mental leaps are a matter of
    >> taste...pitfalls, etc, come to mind.
    >> 
    >>>  Maybe, one way or another, both plots (residuals vs a
    >>> function of leverage, and the plot from Hinkley et al)
    >>> should go in.  The easiest way to do this is to add a
    >>> further which=6.  I will do this if the consensus is
    >>> that this is the right way to go.  In any case, I'll add
    >>> the Hinkley et al reference (author of the contribution
    >>> that includes p.74?) to the draft help page.
    >>  Sorry, I should have given the full reference, which (in
    >> BibTeX format from CIS) is
    >> 
    >> @inproceedings{Firt:gene:1991, author = {Firth, D.},
    >> title = {Generalized Linear Models}, year = {1991},
    >> booktitle = {Statistical Theory and Modelling. In Honour
    >> of Sir David Cox, FRS}, editor = {Hinkley, D. V. and
    >> Reid, N. and Snell, E. J.}, publisher = {Chapman \& Hall
    >> Ltd}, pages = {55--82}, keywords = {Analysis of deviance;
    >> Likelihood} }
    >> 
    >> David
    >> 
    JMd> John Maindonald email: john.maindonald@anu.edu.au phone
    JMd> : +61 2 (6125)3473 fax : +61 2(6125)5549 Centre for
    JMd> Bioinformation Science, Room 1194, John Dedman
    JMd> Mathematical Sciences Building (Building 27) Australian
    JMd> National University, Canberra ACT 0200.

    JMd> ______________________________________________
    JMd> R-devel@stat.math.ethz.ch mailing list
    JMd> https://stat.ethz.ch/mailman/listinfo/r-devel

From murdoch at stats.uwo.ca  Tue Apr 26 12:23:04 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue Apr 26 12:22:37 2005
Subject: [Rd] Speeding up library loading
In-Reply-To: <BAY17-F3A3B8341367CB01364502D1210@phx.gbl>
References: <BAY17-F3A3B8341367CB01364502D1210@phx.gbl>
Message-ID: <426E1688.4080003@stats.uwo.ca>

Ali - wrote:
> 
> 
>>>
>>> Assume 100 C++ classes each class having 100 member functions. After 
>>> wrapping these classes into R, if the wrapping design is 
>>> class-oriented we should have like 100 objects. At the same time, if 
>>> the wrapping design is function-oriented we have like 10`000 objects 
>>> which are too lazy for lazy loading.
>>>
>>> I have tried wrapping exactly the same classes by R.oo based on S3 
>>> and the outcome package was much faster in both installation and 
>>> loading. The package went slow once I tried it with S4. I guess R.oo 
>>> makes the package more class-oriented while S4 object-orientation is 
>>> really function-oriented causing all this friction in installation 
>>> and loading.
>>>
>>> Is there any way to ask R to lazy-load each object as a 'bundle of S4 
>>> methods with the same class'?
>>
>>
>> I don't think so.  There are ways to load a bundle of objects all at 
>> once (put them in an environment, attach the environment), but S4 
>> methods aren't self-contained, they need to be registered with the 
>> system.   You could probably write a function to load them and 
>> register them all at once, but I don't think it exists now.
>>
>> Duncan Murdoch
> 
> 
> (1) What is the difference between loading and registering objects in R?

Loading just creates the object.  Registering it is what setMethod() and 
such calls do.  They allow the system to know that it should call that 
function in response to a call to the generic with a certain signature, 
and so on.
> 
> (2) You are talking about 'loading and registering at once'. Isn't this 
> 'at once' the cause of slow loading?

I haven't done any profiling, but I would guess the registering is the 
slow part.

> (3) Doesn't having many environments mean lose of efficiency again?

Yes, I'd guess that looking things up in a chain of 100 environments is 
slower than looking them up in one gigantic environment.  Again, I 
haven't done any profiling, but I'd guess it would come close to being 
100 times worse, i.e. in practice order N time instead of order 1 time 
(but I'm sure these aren't the theoretical limits).

But you were asking about delayed loading, so I was assuming that in 
most cases you would only load a small subset of those 100 environments. 
  I haven't tried any big problems like yours, but I would be willing to 
guess that registering is slower than O(N), so cutting down on the 
number of things you register will give a big improvement on loading speed.

But you do have to remember the two pieces of advice you've been given 
in this thread:

   - nobody else has written a package with ten thousand methods, so 
you're likely to find things out that nobody else knows about.

   - The S4 object model is quite different from that of C++, so it 
probably doesn't make sense to have a direct correspondence between C++ 
classes and methods and R classes and methods.  There are probably much 
more efficient ways to get access to the functionality of your C++ library.

Duncan Murdoch

From ripley at stats.ox.ac.uk  Tue Apr 26 13:24:32 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Apr 26 13:24:41 2005
Subject: [Rd] Failed to install gbm_1.4-2 (PR#7814)
Message-ID: <20050426112432.32246A1DB@slim.kubism.ku.dk>

The FAQ asks you to send bug reports on contributed packages to their 
manitainer.  This is NOT a bug in R.

gbm is a contributed package, and 2.0.1 is not the current release of R.
I can confirm it with 2.1.0 on Solaris.

On Mon, 25 Apr 2005 manager@molbiol.ox.ac.uk wrote:

> Full_Name: The Manager
> Version: 2.0.1
> OS: Solaris 9
> Submission from: (NULL) (129.67.80.243)
>
>
>> install.packages("gbm")
> trying URL `http://cran.uk.r-project.org/src/contrib/PACKAGES'
> Content type `text/plain; charset=ISO-8859-1' length 52975 bytes
> opened URL
> ==================================================
> downloaded 51Kb
>
> trying URL `http://cran.uk.r-project.org/src/contrib/gbm_1.4-2.tar.gz'
> Content type `application/x-gzip' length 252551 bytes
> opened URL
> ==================================================
> downloaded 246Kb
> * Installing *source* package 'gbm' ...
> ** libs
> g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
> adaboost.cpp -oadaboost.o
> g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
> bernoulli.cpp -o bernoulli.o
> g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
> coxph.cpp -o coxph.o
> g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
> dataset.cpp -o dataset.o
> g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
> distribution.cpp -o distribution.o
> g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
> gaussian.cpp -ogaussian.o
> g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
> gbm.cpp -o gbm.o
> g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
> gbm_engine.cpp -o gbm_engine.o
> g++ -I/package/R/2.0.1-32bit/lib/R/include  -I/usr/local/include   -fPIC  -O2 -c
> gbmentry.cpp -ogbmentry.o
> gbmentry.cpp: In function `SEXPREC* gbm_shrink_pred(SEXPREC*, SEXPREC*,
> SEXPREC*, SEXPREC*, SEXPREC*, SEXPREC*, SEXPREC*, SEXPREC*, SEXPREC*,
> SEXPREC*)':
> gbmentry.cpp:677: error: `NAN' undeclared (first use this function)
> gbmentry.cpp:677: error: (Each undeclared identifier is reported only once for
> each function it appears in.)
> make: *** [gbmentry.o] Error 1
> ERROR: compilation failed for package 'gbm'
> ** Removing '/package/R/2.0.1-32bit/lib/R/library/gbm'
> ** Restoring previous '/package/R/2.0.1-32bit/lib/R/library/gbm'
>
> Delete downloaded files (y/N)? y
>
> Warning message:
> Installation of package gbm had non-zero exit status in:
> install.packages("gbm")
>> q()


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Tue Apr 26 14:10:46 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Apr 26 14:11:00 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <17006.5202.986122.321760@stat.math.ethz.ch>
References: <200504251000.j3PA01lD009332@hypatia.math.ethz.ch>
	<40567787fcb17bee0bf9ecf403fb8e21@anu.edu.au>
	<320af97cfe90da4c59b7e9c8cd9956d4@anu.edu.au>
	<9717926f912f9fb045c57dd9be4e743c@warwick.ac.uk>
	<b21d1d1a13e8f82d4e1d44c233e9f76e@anu.edu.au>
	<17006.5202.986122.321760@stat.math.ethz.ch>
Message-ID: <x21x8xu4ah.fsf@turmalin.kubism.ku.dk>

Martin Maechler <maechler@stat.math.ethz.ch> writes:

> This would be non-compatible though for all those that have
> always used the current default 1:4. 
> OTOH, "MASS" or Peter Dalgaard's book don't mention  plot(<lm fit> )
> or at least don't show it's result.

Ummm, check page 183... 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Tue Apr 26 14:15:15 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Apr 26 14:15:35 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <x21x8xu4ah.fsf@turmalin.kubism.ku.dk>
References: <200504251000.j3PA01lD009332@hypatia.math.ethz.ch>
	<40567787fcb17bee0bf9ecf403fb8e21@anu.edu.au>
	<320af97cfe90da4c59b7e9c8cd9956d4@anu.edu.au>
	<9717926f912f9fb045c57dd9be4e743c@warwick.ac.uk>
	<b21d1d1a13e8f82d4e1d44c233e9f76e@anu.edu.au>
	<17006.5202.986122.321760@stat.math.ethz.ch>
	<x21x8xu4ah.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0504261314490.4572@gannet.stats>

On Tue, 26 Apr 2005, Peter Dalgaard wrote:

> Martin Maechler <maechler@stat.math.ethz.ch> writes:
>
>> This would be non-compatible though for all those that have
>> always used the current default 1:4.
>> OTOH, "MASS" or Peter Dalgaard's book don't mention  plot(<lm fit> )
>> or at least don't show it's result.
>
> Ummm, check page 183...

OTOH MASS does not because of S-PLUS/R differences.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Tue Apr 26 14:46:26 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Apr 26 14:46:41 2005
Subject: [Rd] Re: [R] R-2.1.0 doesn't compile on FreeBSD6-CURRENT
In-Reply-To: <426A03D1.9080201@gwdg.de>
References: <426A03D1.9080201@gwdg.de>
Message-ID: <Pine.LNX.4.61.0504261333420.5874@gannet.stats>

[This is an inappropriate question for R-help.  Perhaps R-devel (see the 
posting guide) but more likely a FreeBSD mailing list.  Moved to R-devel.]

R itself does not refer to __builtin_alloca.  That is something being 
mapped by the FreeBSD headers, and it should be `builtin' using gcc.  (No 
version of alloca is appearing as an import in error.o on Linux or Solaris 
using gcc.)  So it looks like an inconsistency between your compiler and 
OS.

On Sat, 23 Apr 2005, Rainer Hurling wrote:

> Dear R-users,
>
> is there anyone else with problems to get R-2.1.0 compiled on
> FreeBSD6-CURRENT?
>
> After typing '.configure' and then 'make' I get the following output:
>
> -------------------------------------
> [...snip...]
> gcc -export-dynamic -L/usr/local/lib -o R.bin  Rmain.o  CConverters.o
> CommandLineArgs.o Rdynload.o Renviron.o RNG.o apply.o arithmetic.o
> apse.o array.o attrib.o base.o bind.o builtin.o character.o coerce.o
> colors.o complex.o connections.o context.o cov.o cum.o dcf.o datetime.o
> debug.o deparse.o deriv.o dotcode.o dounzip.o dstruct.o duplicate.o
> engine.o envir.o errors.o eval.o format.o fourier.o gevents.o gram.o
> gram-ex.o graphics.o identical.o internet.o iosupport.o lapack.o list.o
> logic.o main.o mapply.o match.o memory.o model.o names.o objects.o
> optim.o optimize.o options.o par.o paste.o pcre.o platform.o plot.o
> plot3d.o plotmath.o print.o printarray.o printvector.o printutils.o
> qsort.o random.o regex.o registration.o relop.o saveload.o scan.o seq.o
> serialize.o size.o sort.o source.o split.o sprintf.o startup.o
> subassign.o subscript.o subset.o summary.o sysutils.o unique.o util.o
> version.o vfonts.o xxxpr.o ../unix/libunix.a ../appl/libappl.a
> ../nmath/libnmath.a   -lg2c -lm  ../extra/zlib/libz.a
> ../extra/bzip2/libbz2.a ../extra/pcre/libpcre.a
> /usr/local/lib/libintl.so -Wl,-rpath -Wl,/usr/local/lib -lreadline -lm
> -liconv
>
> errors.o(.text+0x154b): In function `do_gettext':
> /usr/local/R-2.1.0/src/main/errors.c:779: undefined reference to
> `__builtin_alloca'
> errors.o(.text+0x15fa):/usr/local/R-2.1.0/src/main/errors.c:752:
> undefined reference to `__builtin_alloca'
> errors.o(.text+0x1652):/usr/local/R-2.1.0/src/main/errors.c:760:
> undefined reference to `__builtin_alloca'
> errors.o(.text+0x16aa):/usr/local/R-2.1.0/src/main/errors.c:770:
> undefined reference to `__builtin_alloca'
> errors.o(.text+0x1728):/usr/local/R-2.1.0/src/main/errors.c:738:
> undefined reference to `__builtin_alloca'
> errors.o(.text+0x274d):/usr/local/R-2.1.0/src/main/errors.c:829: more
> undefined references to `__builtin_alloca' follow
> *** Error code 1
>
> Stop in /usr/local/R-2.1.0/src/main.
> *** Error code 1
>
> Stop in /usr/local/R-2.1.0/src/main.
> *** Error code 1
>
> Stop in /usr/local/R-2.1.0/src.
> *** Error code 1
>
> Stop in /usr/local/R-2.1.0.
> -------------------------------------
>
> Are there any experiences with this break?
>
> R-2.0.1 _does_ compile on the same system.
>
> Many thanks in advance,
> Rainer Hurling
>
> ______________________________________________
> R-help@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Manuel.A.Morales at williams.edu  Tue Apr 26 16:47:42 2005
From: Manuel.A.Morales at williams.edu (Manuel.A.Morales@williams.edu)
Date: Tue Apr 26 16:47:49 2005
Subject: [Rd] Ctrl-c crashes R when run as sudo (PR#7819)
Message-ID: <20050426144742.87100A1D3@slim.kubism.ku.dk>

I tried to submit this in R, but not sure if it worked.

When running R as sudo, using ctrl-c dumps me to the command line.
Hitting exit to exit the terminal window results in R taking 100% of
resources.

I am using R-2.1.0 on Fedora Core 3.

Thanks.

Manuel

From jfox at mcmaster.ca  Tue Apr 26 17:00:20 2005
From: jfox at mcmaster.ca (John Fox)
Date: Tue Apr 26 17:00:32 2005
Subject: [Rd] tclServiceMode:  stop Tcl/Tk from updating
In-Reply-To: <426A67F9.7000104@stats.uwo.ca>
Message-ID: <20050426150019.FIMB27245.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Duncan,

I hope that some follow-up questions are in order:

In the Rcdmr package, there is a pair of functions for initializing and
completing dialogs:

initializeDialog <- defmacro(window=top, title="", offset=10,
    expr={
        window <- tktoplevel(borderwidth=10)
        tkwm.title(window, title)
        position <- if (is.SciViews()) -1 else commanderPosition() # +PhG
        position <- if (any(position < 0)) "-50+50"
            else paste("+", paste(offset + position, collapse="+"), sep="")
        tkwm.geometry(window, position)
        }
    )

dialogSuffix <- defmacro(window=top, onOK=onOK, rows=1, columns=1,
focus=top,
    bindReturn=TRUE, preventGrabFocus=FALSE, preventDoubleClick=FALSE,
    expr={
        for (row in 0:(rows-1)) tkgrid.rowconfigure(window, row, weight=0)
        for (col in 0:(columns-1)) tkgrid.columnconfigure(window, col,
weight=0)
        .Tcl("update idletasks")
        tkwm.resizable(window, 0, 0)
        if (bindReturn) tkbind(window, "<Return>", onOK)
        if (getRcmdr("double.click") && (!preventDoubleClick))
tkbind(window, "<Double-ButtonPress-1>", onOK)
        tkwm.deiconify(window)
        # focus grabs appear to cause problems for some dialogs
        if (GrabFocus() && (!preventGrabFocus)) tkgrab.set(window)
        tkfocus(focus)
        tkwait.window(window)
        }
    )

(Both of these are "macro-like" in the sense of Thomas Lumley's R-news
article.)

If I understand you correctly, I could improve the R Commander's stability
under windows by putting tclServiceMode(on = FALSE) at the beginning of
initializeDialog(), and tclServiceMode(on = TRUE) at the end of
dialogSuffix(). Is that correct? If so, is there any harm in doing this on
other platforms, or should I test for Windows? Finally, do you mind if I put
tclServiceMode() in the Rcmdr package for the time-being, or would it just
be better to wait for R 2.1.1?

Thanks,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Duncan Murdoch
> Sent: Saturday, April 23, 2005 10:21 AM
> To: r-devel@stat.math.ethz.ch
> Subject: [Rd] tclServiceMode: stop Tcl/Tk from updating
> 
> In Windows, Tcl/Tk programs running under the tcltk package 
> can update too frequently:  for exmaple, we might go through 
> a long sequence of operations to construct a complex display, 
> and in Windows each addition will be shown separately.
> 
> To work around this, I've added a function "tclServiceMode" 
> which serves as an R interface to the "Tcl_SetServiceMode" 
> function in the TCL API.
> Calling "tclServiceMode(on = FALSE)" will stop Tcl/Tk from 
> responding to any events (redraws in particular) until 
> "tclServiceMode(on = TRUE)" is called. As far as I know, 
> events are queued, not lost, when handling is turned off.
> 
> So far this function is only in R-devel, but I'll commit it 
> to R-patched the next chance I get.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From MSchwartz at MedAnalytics.com  Tue Apr 26 17:34:24 2005
From: MSchwartz at MedAnalytics.com (MSchwartz@MedAnalytics.com)
Date: Tue Apr 26 17:34:32 2005
Subject: [Rd] Ctrl-c crashes R when run as sudo (PR#7819)
Message-ID: <20050426153424.76CAFA1D9@slim.kubism.ku.dk>

On Tue, 2005-04-26 at 16:47 +0200, Manuel.A.Morales@williams.edu wrote:
> I tried to submit this in R, but not sure if it worked.
> 
> When running R as sudo, using ctrl-c dumps me to the command line.
> Hitting exit to exit the terminal window results in R taking 100% of
> resources.
> 
> I am using R-2.1.0 on Fedora Core 3.
> 
> Thanks.
> 
> Manuel

I suspect that we are going to need more information.

Running on a fully updated FC3 box using Xfce's Terminal, gnome-terminal
and kconsole, I cannot duplicate this issue either as a user or as root
using sudo.

Attach the output of:

> R.version 

Was there a program running in R at the time, or were you at the R
prompt when you hit ctrl-c?

Which desktop environment and terminal emulator are you using? 

Have you perhaps re-mapped ctrl-c using modified keybindings?

Marc

From p.dalgaard at biostat.ku.dk  Tue Apr 26 17:39:45 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Apr 26 17:41:22 2005
Subject: [Rd] tclServiceMode:  stop Tcl/Tk from updating
In-Reply-To: <20050426150019.FIMB27245.tomts25-srv.bellnexxia.net@JohnDesktop8300>
References: <20050426150019.FIMB27245.tomts25-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <x2r7gxsg1q.fsf@turmalin.kubism.ku.dk>

"John Fox" <jfox@mcmaster.ca> writes:

> Dear Duncan,
> 
> I hope that some follow-up questions are in order:
> 
> In the Rcdmr package, there is a pair of functions for initializing and
> completing dialogs:
> 
> initializeDialog <- defmacro(window=top, title="", offset=10,
>     expr={
>         window <- tktoplevel(borderwidth=10)
>         tkwm.title(window, title)
>         position <- if (is.SciViews()) -1 else commanderPosition() # +PhG
>         position <- if (any(position < 0)) "-50+50"
>             else paste("+", paste(offset + position, collapse="+"), sep="")
>         tkwm.geometry(window, position)
>         }
>     )
> 
> dialogSuffix <- defmacro(window=top, onOK=onOK, rows=1, columns=1,
> focus=top,
>     bindReturn=TRUE, preventGrabFocus=FALSE, preventDoubleClick=FALSE,
>     expr={
>         for (row in 0:(rows-1)) tkgrid.rowconfigure(window, row, weight=0)
>         for (col in 0:(columns-1)) tkgrid.columnconfigure(window, col,
> weight=0)
>         .Tcl("update idletasks")
>         tkwm.resizable(window, 0, 0)
>         if (bindReturn) tkbind(window, "<Return>", onOK)
>         if (getRcmdr("double.click") && (!preventDoubleClick))
> tkbind(window, "<Double-ButtonPress-1>", onOK)
>         tkwm.deiconify(window)
>         # focus grabs appear to cause problems for some dialogs
>         if (GrabFocus() && (!preventGrabFocus)) tkgrab.set(window)
>         tkfocus(focus)
>         tkwait.window(window)
>         }
>     )
> 
> (Both of these are "macro-like" in the sense of Thomas Lumley's R-news
> article.)
> 
> If I understand you correctly, I could improve the R Commander's stability
> under windows by putting tclServiceMode(on = FALSE) at the beginning of
> initializeDialog(), and tclServiceMode(on = TRUE) at the end of
> dialogSuffix(). Is that correct? If so, is there any harm in doing this on
> other platforms, or should I test for Windows? Finally, do you mind if I put
> tclServiceMode() in the Rcmdr package for the time-being, or would it just
> be better to wait for R 2.1.1?

It's a horrible kludge (I can say so because I suggested it) and a
sign that we don't really understand the way the Tk event loop runs on
Windows. 

However, as far as I can tell, it should be harmless to use
tclServiceMode() on other platforms, as long as you ensure that
on=TRUE is used whenever you do want to process events. Mostly, you'll
just be disabling event processing at points where you weren't
handling events anyway.

If you use things like tkwait.variable() when on=FALSE, then you're in
trouble, but that goes for all platforms.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From aliasdevel at yahoo.com  Tue Apr 26 17:47:49 2005
From: aliasdevel at yahoo.com (Werner Bier)
Date: Tue Apr 26 17:47:57 2005
Subject: [Rd] "wild" function example in optim
Message-ID: <20050426154749.33905.qmail@web61201.mail.yahoo.com>

Dear all,
 
Firstly, I do apologize if my question is simple and posted in the wrong place but I had no reply from the R-help mailing list (maybe it is too simple!).
 
 I was wondering why parscale is set to 20 in the "wild" function example used in ?optim. This function has only one parameter and if we set parscale equal to 1 then the solution near the global minimum is not found.

I would use parscale only in cases the object function has more than one parameter to be optimised, shouldn't I? 
 
Many thanks in advance to all of you and kind regards,
Tom

__________________________________________________



	[[alternative HTML version deleted]]

From tlumley at u.washington.edu  Tue Apr 26 17:57:29 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue Apr 26 17:57:39 2005
Subject: [Rd] "wild" function example in optim
In-Reply-To: <20050426154749.33905.qmail@web61201.mail.yahoo.com>
References: <20050426154749.33905.qmail@web61201.mail.yahoo.com>
Message-ID: <Pine.A41.4.61b.0504260851450.131934@homer03.u.washington.edu>

On Tue, 26 Apr 2005, Werner Bier wrote:

> Dear all,
>
> Firstly, I do apologize if my question is simple and posted in the wrong 
> place but I had no reply from the R-help mailing list (maybe it is too 
> simple!).
>
> I was wondering why parscale is set to 20 in the "wild" function example 
> used in ?optim. This function has only one parameter and if we set 
> parscale equal to 1 then the solution near the global minimum is not 
> found.
>
> I would use parscale only in cases the object function has more than one 
> parameter to be optimised, shouldn't I?
>

parscale is more important in cases with more than one parameter 
(and with one parameter you could set fnscale instead of parscale to get 
the same effect)

However, a sufficiently badly scaled one-d problem can still benefit from 
fnscale or parscale.
> f
function(x) 1e-10*x^2
> g
function(x) 2e-10*x
> optim(7,f,g,method="CG")$par
[1] 7
> optim(7,f,g,method="CG",control=list(parscale=1e5))$par
[1] 1.209735e-14
> optim(7,f,g,method="CG",control=list(fnscale=1e-10))$par
[1] 1.673141e-15

 	-thomas


 	-thomas

From ripley at stats.ox.ac.uk  Tue Apr 26 18:26:00 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Apr 26 18:26:11 2005
Subject: [Rd] "wild" function example in optim
In-Reply-To: <Pine.A41.4.61b.0504260851450.131934@homer03.u.washington.edu>
References: <20050426154749.33905.qmail@web61201.mail.yahoo.com>
	<Pine.A41.4.61b.0504260851450.131934@homer03.u.washington.edu>
Message-ID: <Pine.LNX.4.61.0504261709040.9726@gannet.stats>

On Tue, 26 Apr 2005, Thomas Lumley wrote:

> On Tue, 26 Apr 2005, Werner Bier wrote:
>
>> Dear all,
>> 
>> Firstly, I do apologize if my question is simple and posted in the wrong 
>> place but I had no reply from the R-help mailing list (maybe it is too 
>> simple!).
>> 
>> I was wondering why parscale is set to 20 in the "wild" function example 
>> used in ?optim. This function has only one parameter and if we set parscale 
>> equal to 1 then the solution near the global minimum is not found.

Note that there the method is "SANN".  That makes assumptions about step 
sizes, in fact using a spherical Gaussian distribution of fixed size.  So 
parscale=20 is telling it to make initial steps large enough to explore 
the `blobs'. In particular, parscale is not set for the BFGS call in that 
example.

>> I would use parscale only in cases the object function has more than one 
>> parameter to be optimised, shouldn't I?
>> 
>
> parscale is more important in cases with more than one parameter (and with 
> one parameter you could set fnscale instead of parscale to get the same 
> effect)

Not necessarily.  The finite-differencing is done in units rescaled by 
parscale.  So a unit change in a single parameter needs to be a 
reasonably-sized step.  One can always set fnscale and neps, but it is 
easier to set parscale.

> However, a sufficiently badly scaled one-d problem can still benefit from 
> fnscale or parscale.
>> f
> function(x) 1e-10*x^2
>> g
> function(x) 2e-10*x
>> optim(7,f,g,method="CG")$par
> [1] 7
>> optim(7,f,g,method="CG",control=list(parscale=1e5))$par
> [1] 1.209735e-14
>> optim(7,f,g,method="CG",control=list(fnscale=1e-10))$par
> [1] 1.673141e-15

but without g

> optim(7,f,method="CG",control=list(parscale=1e5))$par
[1] 1.209735e-14
> optim(7,f,method="CG",control=list(fnscale=1e-10))$par
[1] 1.997947e-11


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From MSchwartz at MedAnalytics.com  Tue Apr 26 18:30:18 2005
From: MSchwartz at MedAnalytics.com (MSchwartz@MedAnalytics.com)
Date: Tue Apr 26 18:30:28 2005
Subject: [Rd] Ctrl-c crashes R when run as sudo (PR#7819)
Message-ID: <20050426163018.722C5A1D3@slim.kubism.ku.dk>

On Tue, 2005-04-26 at 11:41 -0400, Manuel Morales wrote:
> On Tue, 2005-04-26 at 10:34 -0500, Marc Schwartz wrote:
> > On Tue, 2005-04-26 at 16:47 +0200, Manuel.A.Morales@williams.edu wrote:
> > > I tried to submit this in R, but not sure if it worked.
> > > 
> > > When running R as sudo, using ctrl-c dumps me to the command line.
> > > Hitting exit to exit the terminal window results in R taking 100% of
> > > resources.
> > > 
> > > I am using R-2.1.0 on Fedora Core 3.
> > > 
> > > Thanks.
> > > 
> > > Manuel
> > 
> > I suspect that we are going to need more information.
> > 
> > Running on a fully updated FC3 box using Xfce's Terminal, gnome-terminal
> > and kconsole, I cannot duplicate this issue either as a user or as root
> > using sudo.
> > 
> Note that this doesn't happen if I run R as a normal user or as root.
> I.e.,
> 
> R
> <ctrl-c>
> or
> 
> su
> R
> <ctrl-c>
> works fine.
> 
> sudo R
> <ctrl-c>
> does not.
> 
> > Attach the output of:
> > 
> > > R.version 
> > 
> 
> > R.version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    2
> minor    1.0
> year     2005
> month    04
> day      18
> language R
> 
> 
> > Was there a program running in R at the time, or were you at the R
> > prompt when you hit ctrl-c?
> > 
> 
> R prompt
> 
> > Which desktop environment and terminal emulator are you using? 
> > 
>  
> Gnome and gnome-terminal, although the problem also happens when using
> xterm.
> 
> > Have you perhaps re-mapped ctrl-c using modified keybindings?
> 
> No. And ctrl-c works fine as a normal user or as root.

Manuel,

Please be sure to copy R-bugs@biostat.ku.dk when you reply so that the
thread is properly archived in the bug tracking system.

I tried this under GNOME using gnome-terminal and the unpatched version
of R 2.1.0 and still could not duplicate the problem.

Can you post back with the contents of /etc/sudoers?

The other possibility would be to run:

sudo R -d gdb

in gnome-terminal. When you get to the (gdb) prompt, type 'r' (without
the quotes) for run, which will start up R.

If you can replicate the problem under gdb and R exits after a ctrl-c,
you should be left at a (gdb) prompt. If that occurs, type 'bt' (without
the quotes), which will display a backtrace. If that all works, post the
output of gdb from the crtl-c through and including the backtrace here.

Marc

From MSchwartz at MedAnalytics.com  Tue Apr 26 18:30:37 2005
From: MSchwartz at MedAnalytics.com (MSchwartz@MedAnalytics.com)
Date: Tue Apr 26 18:30:45 2005
Subject: [Rd] Ctrl-c crashes R when run as sudo (PR#7819)
Message-ID: <20050426163037.F1ECAA1D3@slim.kubism.ku.dk>

On Tue, 2005-04-26 at 11:41 -0400, Manuel Morales wrote:
> On Tue, 2005-04-26 at 10:34 -0500, Marc Schwartz wrote:
> > On Tue, 2005-04-26 at 16:47 +0200, Manuel.A.Morales@williams.edu wrote:
> > > I tried to submit this in R, but not sure if it worked.
> > > 
> > > When running R as sudo, using ctrl-c dumps me to the command line.
> > > Hitting exit to exit the terminal window results in R taking 100% of
> > > resources.
> > > 
> > > I am using R-2.1.0 on Fedora Core 3.
> > > 
> > > Thanks.
> > > 
> > > Manuel
> > 
> > I suspect that we are going to need more information.
> > 
> > Running on a fully updated FC3 box using Xfce's Terminal, gnome-terminal
> > and kconsole, I cannot duplicate this issue either as a user or as root
> > using sudo.
> > 
> Note that this doesn't happen if I run R as a normal user or as root.
> I.e.,
> 
> R
> <ctrl-c>
> or
> 
> su
> R
> <ctrl-c>
> works fine.
> 
> sudo R
> <ctrl-c>
> does not.
> 
> > Attach the output of:
> > 
> > > R.version 
> > 
> 
> > R.version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    2
> minor    1.0
> year     2005
> month    04
> day      18
> language R
> 
> 
> > Was there a program running in R at the time, or were you at the R
> > prompt when you hit ctrl-c?
> > 
> 
> R prompt
> 
> > Which desktop environment and terminal emulator are you using? 
> > 
>  
> Gnome and gnome-terminal, although the problem also happens when using
> xterm.
> 
> > Have you perhaps re-mapped ctrl-c using modified keybindings?
> 
> No. And ctrl-c works fine as a normal user or as root.

Manuel,

Please be sure to copy R-bugs@biostat.ku.dk when you reply so that the
thread is properly archived in the bug tracking system.

I tried this under GNOME using gnome-terminal and the unpatched version
of R 2.1.0 and still could not duplicate the problem.

Can you post back with the contents of /etc/sudoers?

The other possibility would be to run:

sudo R -d gdb

in gnome-terminal. When you get to the (gdb) prompt, type 'r' (without
the quotes) for run, which will start up R.

If you can replicate the problem under gdb and R exits after a ctrl-c,
you should be left at a (gdb) prompt. If that occurs, type 'bt' (without
the quotes), which will display a backtrace. If that all works, post the
output of gdb from the crtl-c through and including the backtrace here.

Marc

From Manuel.A.Morales at williams.edu  Tue Apr 26 18:52:55 2005
From: Manuel.A.Morales at williams.edu (Manuel.A.Morales@williams.edu)
Date: Tue Apr 26 18:53:04 2005
Subject: [Rd] Ctrl-c crashes R when run as sudo (PR#7819)
Message-ID: <20050426165255.EAC33A1D9@slim.kubism.ku.dk>

On Tue, 2005-04-26 at 11:30 -0500, Marc Schwartz wrote:
> On Tue, 2005-04-26 at 11:41 -0400, Manuel Morales wrote:
> > On Tue, 2005-04-26 at 10:34 -0500, Marc Schwartz wrote:
> > > On Tue, 2005-04-26 at 16:47 +0200, Manuel.A.Morales@williams.edu wrote:
> > > > I tried to submit this in R, but not sure if it worked.
> > > > 
> > > > When running R as sudo, using ctrl-c dumps me to the command line.
> > > > Hitting exit to exit the terminal window results in R taking 100% of
> > > > resources.
> > > > 
> > > > I am using R-2.1.0 on Fedora Core 3.
> > > > 
> > > > Thanks.
> > > > 
> > > > Manuel
> > > 
> > > I suspect that we are going to need more information.
> > > 
> > > Running on a fully updated FC3 box using Xfce's Terminal, gnome-terminal
> > > and kconsole, I cannot duplicate this issue either as a user or as root
> > > using sudo.
> > > 
> > Note that this doesn't happen if I run R as a normal user or as root.
> > I.e.,
> > 
> > R
> > <ctrl-c>
> > or
> > 
> > su
> > R
> > <ctrl-c>
> > works fine.
> > 
> > sudo R
> > <ctrl-c>
> > does not.
> > 
> > > Attach the output of:
> > > 
> > > > R.version 
> > > 
> > 
> > > R.version
> >          _
> > platform i686-pc-linux-gnu
> > arch     i686
> > os       linux-gnu
> > system   i686, linux-gnu
> > status
> > major    2
> > minor    1.0
> > year     2005
> > month    04
> > day      18
> > language R
> > 
> > 
> > > Was there a program running in R at the time, or were you at the R
> > > prompt when you hit ctrl-c?
> > > 
> > 
> > R prompt
> > 
> > > Which desktop environment and terminal emulator are you using? 
> > > 
> >  
> > Gnome and gnome-terminal, although the problem also happens when using
> > xterm.
> > 
> > > Have you perhaps re-mapped ctrl-c using modified keybindings?
> > 
> > No. And ctrl-c works fine as a normal user or as root.
> 
> Manuel,
> 
> Please be sure to copy R-bugs@biostat.ku.dk when you reply so that the
> thread is properly archived in the bug tracking system.
> 
> I tried this under GNOME using gnome-terminal and the unpatched version
> of R 2.1.0 and still could not duplicate the problem.
> 
> Can you post back with the contents of /etc/sudoers?
> 
> The other possibility would be to run:
> 
> sudo R -d gdb
> 
> in gnome-terminal. When you get to the (gdb) prompt, type 'r' (without
> the quotes) for run, which will start up R.
> 
> If you can replicate the problem under gdb and R exits after a ctrl-c,
> you should be left at a (gdb) prompt. If that occurs, type 'bt' (without
> the quotes), which will display a backtrace. If that all works, post the
> output of gdb from the crtl-c through and including the backtrace here.
> 
> Marc
> 
>
Program received signal SIGINT, Interrupt.
0x006547a2 in _dl_sysinfo_int80 () from /lib/ld-linux.so.2
(gdb) bt
#0  0x006547a2 in _dl_sysinfo_int80 () from /lib/ld-linux.so.2
#1  0x0072da1d in ___newselect_nocancel () from /lib/tls/libc.so.6
#2  0x0813e060 in R_SelectEx (n=1, readfds=0x825dde0, writefds=0x0,
    exceptfds=0x0, timeout=0x0, intr=0x813e5a8 <handleInterrupt>)
    at sys-std.c:138
#3  0x0813e281 in R_checkActivityEx (usec=-1, ignore_stdin=0,
    intr=0x813e5a8 <handleInterrupt>) at sys-std.c:302
#4  0x0813e6f0 in Rstd_ReadConsole (prompt=0x0, buf=0xbfffb33c "",
len=1024,
    addtohistory=-514) at sys-std.c:642
#5  0x080cac4a in Rf_ReplIteration (rho=0x9522cb8, savestack=-514,
    browselevel=0, state=0xbfffb330) at main.c:208
#6  0x080cadef in R_ReplConsole (rho=0x9522cb8, savestack=0,
browselevel=0)
    at main.c:306
#7  0x080cb03d in run_Rmainloop () at main.c:685
#8  0x0805d948 in main (ac=1, av=0xbfffb844) at Rmain.c:31

The relevant line in my /etc/sudoers:
mmorales        ALL=(ALL) ALL

From p.dalgaard at biostat.ku.dk  Tue Apr 26 19:04:55 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Apr 26 19:05:03 2005
Subject: [Rd] "wild" function example in optim
In-Reply-To: <Pine.A41.4.61b.0504260851450.131934@homer03.u.washington.edu>
References: <20050426154749.33905.qmail@web61201.mail.yahoo.com>
	<Pine.A41.4.61b.0504260851450.131934@homer03.u.washington.edu>
Message-ID: <x2ekcxsc3s.fsf@turmalin.kubism.ku.dk>

Thomas Lumley <tlumley@u.washington.edu> writes:

> On Tue, 26 Apr 2005, Werner Bier wrote:
> 
> > Dear all,
> >
> > Firstly, I do apologize if my question is simple and posted in the
> > wrong place but I had no reply from the R-help mailing list (maybe
> > it is too simple!).
> >
> > I was wondering why parscale is set to 20 in the "wild" function
> > example used in ?optim. This function has only one parameter and if
> > we set parscale equal to 1 then the solution near the global minimum
> > is not found.
> >
> > I would use parscale only in cases the object function has more than
> > one parameter to be optimised, shouldn't I?
> >
> 
> parscale is more important in cases with more than one parameter (and
> with one parameter you could set fnscale instead of parscale to get
> the same effect)
> 
> However, a sufficiently badly scaled one-d problem can still benefit
> from fnscale or parscale.
> > f
> function(x) 1e-10*x^2
> > g
> function(x) 2e-10*x
> > optim(7,f,g,method="CG")$par
> [1] 7
> > optim(7,f,g,method="CG",control=list(parscale=1e5))$par
> [1] 1.209735e-14
> > optim(7,f,g,method="CG",control=list(fnscale=1e-10))$par
> [1] 1.673141e-15

It also depends on the optimizer. The SANN optimizer basically jumps
haphazardly (well, a bit more intelligently than that) back and forth
along the x axis and then "cools down" in order to settle in the
"best" local minimum. The parscale plays a role in setting the scale
of those jumps and if it is too low it might not wander far enough to
get near the true minimum.

For further information, you really need to do your own reading.
References are given on the help page.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From simon.urbanek at r-project.org  Tue Apr 26 19:14:08 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue Apr 26 19:13:22 2005
Subject: [Rd] Ctrl-c crashes R when run as sudo (PR#7819)
In-Reply-To: <20050426165255.EAC33A1D9@slim.kubism.ku.dk>
References: <20050426165255.EAC33A1D9@slim.kubism.ku.dk>
Message-ID: <72BCC1A4-FF6A-477C-8268-3929B8D15CE1@r-project.org>

On 26.04.2005, at 12:52, Manuel.A.Morales@williams.edu wrote:

> Program received signal SIGINT, Interrupt.
> 0x006547a2 in _dl_sysinfo_int80 () from /lib/ld-linux.so.2

Thanks you, however Marc omitted to mention that you need to type
signal SIGINT
before running the backtrace (bt), because gdb will catch the INT  
signal thus not leading to the desired crash and the backtrace just  
shows when you hit Ctrl-C, not what happens after. Only after the  
signal SIGINT you should get the crash (if at all).

Cheers,
Simon

From murdoch at stats.uwo.ca  Tue Apr 26 19:18:32 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue Apr 26 19:18:08 2005
Subject: [Rd] tclServiceMode:  stop Tcl/Tk from updating
In-Reply-To: <20050426150019.FIMB27245.tomts25-srv.bellnexxia.net@JohnDesktop8300>
References: <20050426150019.FIMB27245.tomts25-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <426E77E8.1090004@stats.uwo.ca>

John Fox wrote:
> Dear Duncan,
> 
> I hope that some follow-up questions are in order:
> 
> In the Rcdmr package, there is a pair of functions for initializing and
> completing dialogs:
> 
> initializeDialog <- defmacro(window=top, title="", offset=10,
>     expr={
>         window <- tktoplevel(borderwidth=10)
>         tkwm.title(window, title)
>         position <- if (is.SciViews()) -1 else commanderPosition() # +PhG
>         position <- if (any(position < 0)) "-50+50"
>             else paste("+", paste(offset + position, collapse="+"), sep="")
>         tkwm.geometry(window, position)
>         }
>     )
> 
> dialogSuffix <- defmacro(window=top, onOK=onOK, rows=1, columns=1,
> focus=top,
>     bindReturn=TRUE, preventGrabFocus=FALSE, preventDoubleClick=FALSE,
>     expr={
>         for (row in 0:(rows-1)) tkgrid.rowconfigure(window, row, weight=0)
>         for (col in 0:(columns-1)) tkgrid.columnconfigure(window, col,
> weight=0)
>         .Tcl("update idletasks")
>         tkwm.resizable(window, 0, 0)
>         if (bindReturn) tkbind(window, "<Return>", onOK)
>         if (getRcmdr("double.click") && (!preventDoubleClick))
> tkbind(window, "<Double-ButtonPress-1>", onOK)
>         tkwm.deiconify(window)
>         # focus grabs appear to cause problems for some dialogs
>         if (GrabFocus() && (!preventGrabFocus)) tkgrab.set(window)
>         tkfocus(focus)
>         tkwait.window(window)
>         }
>     )
> 
> (Both of these are "macro-like" in the sense of Thomas Lumley's R-news
> article.)
> 
> If I understand you correctly, I could improve the R Commander's stability
> under windows by putting tclServiceMode(on = FALSE) at the beginning of
> initializeDialog(), and tclServiceMode(on = TRUE) at the end of
> dialogSuffix(). Is that correct? 

I don't know that it will affect stability.  What it is intended to do 
is to make your dialogs appear on screen fully drawn, rather than 
letting the user see you add each widget.  (In fact I hope it has no 
effect on stability, because I'm worried it would only make things worse...)

The only change I would make to your suggestion (assuming I understand 
what your code does) is to save the return value from the first call, 
and use it as the value in the second, i.e.

   .savemode <- tclServiceMode(on = FALSE)

  ...

   tclServiceMode(on = .savemode)

This would allow you to nest these calls, if you did it in a way that 
didn't stomp on .savemode.

>If so, is there any harm in doing this on
> other platforms, or should I test for Windows? Finally, do you mind if I put
> tclServiceMode() in the Rcmdr package for the time-being, or would it just
> be better to wait for R 2.1.1?

As Peter said, this should be harmless on other platforms.  Copying the 
code into Rcmdr would be fine in the short term, but I expect there'll 
be a 2.1.1 release soon, which will have it.

Duncan Murdoch

From MSchwartz at MedAnalytics.com  Tue Apr 26 19:25:52 2005
From: MSchwartz at MedAnalytics.com (MSchwartz@MedAnalytics.com)
Date: Tue Apr 26 19:25:59 2005
Subject: [Rd] Ctrl-c crashes R when run as sudo (PR#7819)
Message-ID: <20050426172552.72B76A1D9@slim.kubism.ku.dk>

On Tue, 2005-04-26 at 13:14 -0400, Simon Urbanek wrote:
> On 26.04.2005, at 12:52, Manuel.A.Morales@williams.edu wrote:
> 
> > Program received signal SIGINT, Interrupt.
> > 0x006547a2 in _dl_sysinfo_int80 () from /lib/ld-linux.so.2
> 
> Thanks you, however Marc omitted to mention that you need to type
> signal SIGINT
> before running the backtrace (bt), because gdb will catch the INT  
> signal thus not leading to the desired crash and the backtrace just  
> shows when you hit Ctrl-C, not what happens after. Only after the  
> signal SIGINT you should get the crash (if at all).
> 
> Cheers,
> Simon


Thanks Simon for picking that up.  My error.

Also, apologies for the double post, not sure how that happened.



Manuel, I should have asked earlier, but I presume that you installed
from source as I don't see RPMs for 2.1.0 yet?

Marc

From saveez at hotmail.com  Tue Apr 26 19:48:21 2005
From: saveez at hotmail.com (Ali -)
Date: Tue Apr 26 19:48:30 2005
Subject: [Rd] C++ <-> R mapping
Message-ID: <BAY17-F26300EE0A16352E6973475D1210@phx.gbl>

Following my previous post and the intuitive adivces of Duncan Murdoch, I 
would like to ask some questions regarding C++ to R mapping.

Initially, it appeared to me that in order to perform this mapping, the 
existing object-oriented design of R would be a good choice. This could 
include both the S3 and S4 classes approaches. However, there were replies 
about some 'other' approaches. I would appreciate it if someone could 
explaines these other tenchiques. Please note that this C++ ro R mapping 
should be:

(1) automated -- so there is no manual contribution

(2) able to handle of the order of (at least) 10^3 methods efficiently


Thanks.

From p.dalgaard at biostat.ku.dk  Tue Apr 26 19:59:45 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Apr 26 19:59:53 2005
Subject: [Rd] Ctrl-c crashes R when run as sudo (PR#7819)
In-Reply-To: <20050426172552.72B76A1D9@slim.kubism.ku.dk>
References: <20050426172552.72B76A1D9@slim.kubism.ku.dk>
Message-ID: <x2acnls9ke.fsf@turmalin.kubism.ku.dk>

MSchwartz@medanalytics.com writes:

> > Thanks you, however Marc omitted to mention that you need to type
> > signal SIGINT
> > before running the backtrace (bt), because gdb will catch the INT  
> > signal thus not leading to the desired crash and the backtrace just  
> > shows when you hit Ctrl-C, not what happens after. Only after the  
> > signal SIGINT you should get the crash (if at all).
...
> Manuel, I should have asked earlier, but I presume that you installed
> from source as I don't see RPMs for 2.1.0 yet?
> 
> Marc

The effect seem to have been neatly backported to 2.0.1 though...

Gdb doesn't seem to help. If you run a ps while "sudo R" is running,
you'll see something like this:

root     30416  0.0  0.1  2356  252 pts/5    S+   19:48   0:00 sesh /usr/bin/R
root     30417 10.0  7.2 18016 13860 pts/5   S+   19:48   0:01 /usr/lib/R/bin/exec/R

What I suspect is happening is that the ^C kills the sesh process, but
that in turn does not manage to kill R.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Tue Apr 26 20:09:41 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Apr 26 20:09:49 2005
Subject: [Rd] Ctrl-c crashes R when run as sudo (PR#7819)
Message-ID: <20050426180941.6D593A1DA@slim.kubism.ku.dk>

On Tue, 26 Apr 2005, Peter Dalgaard wrote:

> MSchwartz@medanalytics.com writes:
>
>>> Thanks you, however Marc omitted to mention that you need to type
>>> signal SIGINT
>>> before running the backtrace (bt), because gdb will catch the INT
>>> signal thus not leading to the desired crash and the backtrace just
>>> shows when you hit Ctrl-C, not what happens after. Only after the
>>> signal SIGINT you should get the crash (if at all).
> ...
>> Manuel, I should have asked earlier, but I presume that you installed
>> from source as I don't see RPMs for 2.1.0 yet?
>>
>> Marc
>
> The effect seem to have been neatly backported to 2.0.1 though...
>
> Gdb doesn't seem to help. If you run a ps while "sudo R" is running,
> you'll see something like this:
>
> root     30416  0.0  0.1  2356  252 pts/5    S+   19:48   0:00 sesh /usr/bin/R
> root     30417 10.0  7.2 18016 13860 pts/5   S+   19:48   0:01 /usr/lib/R/bin/exec/R
>
> What I suspect is happening is that the ^C kills the sesh process, but
> that in turn does not manage to kill R.

Should it?  R traps that signal.

I'll now make the comment I thought when I first saw this:

 	Why is this a bug report against R not sudo?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From MSchwartz at MedAnalytics.com  Tue Apr 26 20:18:35 2005
From: MSchwartz at MedAnalytics.com (MSchwartz@MedAnalytics.com)
Date: Tue Apr 26 20:18:43 2005
Subject: [Rd] Ctrl-c crashes R when run as sudo (PR#7819)
Message-ID: <20050426181835.74988A1D9@slim.kubism.ku.dk>

On Tue, 2005-04-26 at 19:59 +0200, Peter Dalgaard wrote:
> MSchwartz@medanalytics.com writes:
> 
> > > Thanks you, however Marc omitted to mention that you need to type
> > > signal SIGINT
> > > before running the backtrace (bt), because gdb will catch the INT  
> > > signal thus not leading to the desired crash and the backtrace just  
> > > shows when you hit Ctrl-C, not what happens after. Only after the  
> > > signal SIGINT you should get the crash (if at all).
> ...
> > Manuel, I should have asked earlier, but I presume that you installed
> > from source as I don't see RPMs for 2.1.0 yet?
> > 
> > Marc
> 
> The effect seem to have been neatly backported to 2.0.1 though...
> 
> Gdb doesn't seem to help. If you run a ps while "sudo R" is running,
> you'll see something like this:
> 
> root     30416  0.0  0.1  2356  252 pts/5    S+   19:48   0:00 sesh /usr/bin/R
> root     30417 10.0  7.2 18016 13860 pts/5   S+   19:48   0:01 /usr/lib/R/bin/exec/R
> 
> What I suspect is happening is that the ^C kills the sesh process, but
> that in turn does not manage to kill R.

So is this perhaps an SELinux issue? I don't get sesh running when I use
sudo R.

That would perhaps explain why I am not seeing it. Given the almost
daily changes in SELinux policies, I have foregone using it for the time
being. I was having all kinds of 'avc' related errors, so I gave up
until things stabilize more.

Marc

From tplate at acm.org  Tue Apr 26 20:20:17 2005
From: tplate at acm.org (Tony Plate)
Date: Tue Apr 26 20:20:35 2005
Subject: [Rd] C++ <-> R mapping
In-Reply-To: <BAY17-F26300EE0A16352E6973475D1210@phx.gbl>
References: <BAY17-F26300EE0A16352E6973475D1210@phx.gbl>
Message-ID: <426E8661.7000400@acm.org>

An alternative that *might* be more efficient: Write a single R-function
corresponding to each C++ function (which could have multiple methods).
  This R function would analyze its arguments and call the appropriate
C++ method.  Whether or not this will be more efficient probably depends
on the ratio of the number of methods to the number of functions -- if
there are relatively few functions, each with many methods, then it will 
probably be more efficient.

Whether or not you make your C++ classes, and additionally the
inheritance structure, correspond to S3 or S4 classes is another choice.
  If you define your inheritance structure in your own data structures
outside of S3 or S4 mechanisms, then you have the freedom to model the
C++ class structure more accurately, e.g., by modeling multiple inheritance.

-- Tony Plate

Ali - wrote:
> Following my previous post and the intuitive adivces of Duncan Murdoch, 
> I would like to ask some questions regarding C++ to R mapping.
> 
> Initially, it appeared to me that in order to perform this mapping, the 
> existing object-oriented design of R would be a good choice. This could 
> include both the S3 and S4 classes approaches. However, there were 
> replies about some 'other' approaches. I would appreciate it if someone 
> could explaines these other tenchiques. Please note that this C++ ro R 
> mapping should be:
> 
> (1) automated -- so there is no manual contribution
> 
> (2) able to handle of the order of (at least) 10^3 methods efficiently
> 
> 
> Thanks.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From Manuel.A.Morales at williams.edu  Tue Apr 26 20:20:22 2005
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Tue Apr 26 20:20:38 2005
Subject: [Rd] Ctrl-c crashes R when run as sudo (PR#7819)
In-Reply-To: <72BCC1A4-FF6A-477C-8268-3929B8D15CE1@r-project.org>
References: <20050426165255.EAC33A1D9@slim.kubism.ku.dk>
	<72BCC1A4-FF6A-477C-8268-3929B8D15CE1@r-project.org>
Message-ID: <1114539622.5030.1.camel@localhost.localdomain>

I get no crash after typing signal SIGINT - it just returns me to the R
prompt.

On Tue, 2005-04-26 at 13:14 -0400, Simon Urbanek wrote:
> On 26.04.2005, at 12:52, Manuel.A.Morales@williams.edu wrote:
> 
> > Program received signal SIGINT, Interrupt.
> > 0x006547a2 in _dl_sysinfo_int80 () from /lib/ld-linux.so.2
> 
> Thanks you, however Marc omitted to mention that you need to type
> signal SIGINT
> before running the backtrace (bt), because gdb will catch the INT  
> signal thus not leading to the desired crash and the backtrace just  
> shows when you hit Ctrl-C, not what happens after. Only after the  
> signal SIGINT you should get the crash (if at all).
> 
> Cheers,
> Simon

From aliasdevel at yahoo.com  Tue Apr 26 20:27:01 2005
From: aliasdevel at yahoo.com (Werner Bier)
Date: Tue Apr 26 20:27:10 2005
Subject: [Rd] "wild" function example in optim
In-Reply-To: 6667
Message-ID: <20050426182701.35227.qmail@web61204.mail.yahoo.com>

I have no words. Thank you so much for all your answers. This was just great. 
Thanks again and regards,
Tom


Peter Dalgaard <p.dalgaard@biostat.ku.dk> wrote:
Thomas Lumley writes:

> On Tue, 26 Apr 2005, Werner Bier wrote:
> 
> > Dear all,
> >
> > Firstly, I do apologize if my question is simple and posted in the
> > wrong place but I had no reply from the R-help mailing list (maybe
> > it is too simple!).
> >
> > I was wondering why parscale is set to 20 in the "wild" function
> > example used in ?optim. This function has only one parameter and if
> > we set parscale equal to 1 then the solution near the global minimum
> > is not found.
> >
> > I would use parscale only in cases the object function has more than
> > one parameter to be optimised, shouldn't I?
> >
> 
> parscale is more important in cases with more than one parameter (and
> with one parameter you could set fnscale instead of parscale to get
> the same effect)
> 
> However, a sufficiently badly scaled one-d problem can still benefit
> from fnscale or parscale.
> > f
> function(x) 1e-10*x^2
> > g
> function(x) 2e-10*x
> > optim(7,f,g,method="CG")$par
> [1] 7
> > optim(7,f,g,method="CG",control=list(parscale=1e5))$par
> [1] 1.209735e-14
> > optim(7,f,g,method="CG",control=list(fnscale=1e-10))$par
> [1] 1.673141e-15

It also depends on the optimizer. The SANN optimizer basically jumps
haphazardly (well, a bit more intelligently than that) back and forth
along the x axis and then "cools down" in order to settle in the
"best" local minimum. The parscale plays a role in setting the scale
of those jumps and if it is too low it might not wander far enough to
get near the true minimum.

For further information, you really need to do your own reading.
References are given on the help page.

-- 
O__ ---- Peter Dalgaard Blegdamsvej 3 
c/ /'_ --- Dept. of Biostatistics 2200 Cph. N 
(*) \(*) -- University of Copenhagen Denmark Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk) FAX: (+45) 35327907

__________________________________________________



	[[alternative HTML version deleted]]

From deepayan at stat.wisc.edu  Tue Apr 26 20:32:05 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue Apr 26 20:31:49 2005
Subject: [Rd] minor doc bug: options.Rd should be updated
Message-ID: <200504261332.05722.deepayan@stat.wisc.edu>


src/library/base/man/options.Rd Currently has:

    \item{\code{expressions}:}{sets a limit on the number of nested
      expressions that will be evaluated.
      Valid values are 25\dots100000 with default 500.}

The last line should be 

      Valid values are 25\dots500000 with default 5000.}

-Deepayan

From rpeng at jhsph.edu  Tue Apr 26 23:22:42 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue Apr 26 23:22:51 2005
Subject: [Rd] Any plans for commenting out region via something like "
	/* */	"?
In-Reply-To: <1abe3fa905010702034c2e2799@mail.gmail.com>
References: <1abe3fa905010702034c2e2799@mail.gmail.com>
Message-ID: <426EB122.2010801@jhsph.edu>

I realize this thread is a bit old, but it only just came to my 
mind.  What about using a function like

commentOut <- function(expr) { invisible() }

and then

commentOut({
	a <- 10
	bladfkljasdlkfj()
	blah blah blah
})

Lazy evaluation prevents the expression from being evaluated so 
you don't have to worry about syntatic correctness.  And it nests 
too (I believe).

Belated US$0.02.

-roger

A.J. Rossini wrote:
> Greetings from Switzerland!
> 
> Are there any plans/initiatives/considerations in future versions of R
> for commenting out regions via something like " /*    */  "?
> 
> (I've got an application for which something like that would be
> useful; if not, there are less simple solutions).
> 
> best,
> -tony
> 
> "Commit early,commit often, and commit in a repository from which we can easily
> roll-back your mistakes" (AJR, 4Jan05).
> 
> A.J. Rossini
> blindglobe@gmail.com
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/

From jtk at cmp.uea.ac.uk  Wed Apr 27 00:46:11 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Tue Apr 26 23:50:38 2005
Subject: [Rd] Any plans for commenting out region via something like " /*
	*/	"?
In-Reply-To: <426EB122.2010801@jhsph.edu>
References: <1abe3fa905010702034c2e2799@mail.gmail.com>
	<426EB122.2010801@jhsph.edu>
Message-ID: <20050426224611.GD3718@jtkpc.cmp.uea.ac.uk>

On Tue, Apr 26, 2005 at 05:22:42PM -0400, Roger D. Peng wrote:
> I realize this thread is a bit old, but it only just came to my 
> mind.  What about using a function like
> 
> commentOut <- function(expr) { invisible() }
> 
> and then
> 
> commentOut({
> 	a <- 10
> 	bladfkljasdlkfj()
> 	blah blah blah
> })
> 
> Lazy evaluation prevents the expression from being evaluated so 
> you don't have to worry about syntatic correctness.  And it nests 
> too (I believe).

This doesn't work too well, unfortunately. Firstly the argument(s) of
commentOut are still parsed, so if there is a syntax error (which creates
a problem during parsing), execution is halted. Furthermore, while
a series of statements (separated by newlines or semicolons) is not
acceptable as a function argument, so this approach is limited to
commenting out pieces that represent single expressions.

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk@cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*

From saveez at hotmail.com  Tue Apr 26 23:55:17 2005
From: saveez at hotmail.com (Ali -)
Date: Tue Apr 26 23:55:27 2005
Subject: [Rd] C++ <-> R mapping
In-Reply-To: <20050426180439.GC11793@wald.ucdavis.edu>
Message-ID: <BAY17-F2994B601FB22E2262E6309D1210@phx.gbl>

>Hi Ali.
>
>  Can you post an example of some of the C++ classes and the
>style of interface you want to the methods and fields?
>It would help to make the responses concrete.
>
>  D.

Hi Duncan,

First of all, if you have not received my reply to your question, it's 
likely that the message was eaten by your spam filter.

Here is a *rough* example of the wrapper design I am currently using.

Assume we have some c++ class like:

---------------------
c++
---------------------
class foo
{
	public:
		Foo();
		void function1() { /* implementation */};
};

Now the first thing to consider before jumping to R is that R really can 
call compiled codes only from C (and Fortran). So we need some C layer like:

---------------------
c wrapper layer
---------------------
extern "C" SEXP R_Foo_New()
{
	/* return an instance of Foo as SEXP */
}

extern "C" SEXP R_Foo_function1(SEXP obj)
{
	obj->function1();

	return R_NilValue;
}

And finally we can enter to the R environment by something like:

---------------------
R wrapper layer: S4 style
---------------------
setClass("Foo",
    representation(.ptr = "externalptr"),
    );

setMethod("initialize", "Foo",
	function(.Object) {.Object@.ptr = .Call("R_Foo_New"); .Object;})

if( !isGeneric("function1") ){
    setGeneric("function1", function(.Object, ...) 
standardGeneric("function1"))
}

setMethod(
    "function1",
    signature(.Object = "Foo"),
    function(.Object, ...)
    {
        ret <- .Call("R_Foo_function1", .Object@.ptr);
        ret;
    });


The R layer approach in this example is in S4 style. Obviously, it can be 
done in S3 as well. Even it is possible to have more than one R layer 
co-existing at the same time so that the usercan help himself/herself with 
whatever choice he/she is happy with.

I have to say I am a bit surprised that in R there is no unique and standard 
class-oriented structure. In addition, as Tony Plate and Duncan Murdoch 
explained, currently, the existing designs cannot handle loads of methods.

It seems that the above gap can only be filled with some new developments. I 
am very keen to know about your approach in interfacing R to class-oriented 
languages.

From MSchwartz at MedAnalytics.com  Wed Apr 27 01:07:39 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed Apr 27 01:08:01 2005
Subject: [Rd] Re: [R] postscript (eps) / latex / par(mfg=...) / problem!
In-Reply-To: <Pine.LNX.4.21.0504261805150.25057-100000@mail.mrc-dunn.cam.ac.uk>
References: <Pine.LNX.4.21.0504261805150.25057-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <1114556859.8390.108.camel@horizons.localdomain>

[MOVED TO R-DEVEL]

On Tue, 2005-04-26 at 18:05 +0100, Dan Bolser wrote:
> Should I post this to 'bugs'?

Dan,

I suspect part of the problem here is that your code and example were
difficult to replicate and there may have been a focus on the page
rotation issue, which I think is a red herring here.

All below is done with Version 2.1.0 Patched (2005-04-20), which is more
recent of course and may reflect an existing problem when using par
("mfg").


mat <- matrix(c(1:14, 16, 20, 23, 24, 26, 28,
         886, 792, 136, 201, 16, 58, 6,
         21, 3, 9, 3, 9, 1, 4, 3, 1, 1,
         1, 1, 1), ncol = 2)

colnames(mat) <- c("CHAINS", "FREQUENCY")

# Use either the EPS or PDF creation here
# Naming the output file based upon the use or non-use
# of par("mfg")

# Comment the two par("mfg") lines below as appropriate


postscript("x.mfg.eps", width = 6, height = 6,
           horizontal = FALSE, onefile = FALSE,
           paper = "special")

# pdf("nomfg.pdf", width = 5, height = 6)
    
par(mfrow= c(2, 1))

par(mfg = c(1, 1))
par(mar = c(3, 4, 1, 2))
plot(mat, type = "b")

par(mfg = c(2, 1))
par(mar = c(4, 4, 0, 2))
plot(mat, type = "b", log = "y")

dev.off()


What I found, if correct, does not reflect rotation issues with the
graphic, but a problem when using par("mfg"), resulting in both EPS and
PDF files having a 0 page indication in the resultant file. I have
attached EPS and PDF files here named based upon using or not using par
("mfg").

I also used the following LaTeX code to create PS/PDF files as
appropriate with curious results. Modify the included graphic file name
as appropriate when using it:

\documentclass{report}
\usepackage{graphicx}
\begin{document}
\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{x.mfg.eps}
  \caption[X]{Hello!}
  \label{xFig}
\end{figure}
\end{document}


When using latex and dvips with the x.mfg.eps file, the plot is in the
upper left hand corner of the page, very small. Substituting the
x.nomfg.eps file, the page looks fine.


When using pdflatex with the mfg.pdf file, get the following error:

Error: pdflatex (file mfg.pdf): pdf inclusion: required page does not
exist <0>

 ==> Fatal error occurred, the output PDF file is not finished!


Trying to open the mfg.pdf file, I get errors from multiple PDF viewers
indicating the lack of pages in the file.

Interestingly, when opening the EPS files in gv, it seems to happily
ignore the 0 page issue and displays the x.mfg.eps file without problem.


There are a few other posts in the archive that report problems that
were presumed to be the usual rotation issues that Ted refers to in his
reply post on r-help.

However, when reading them:

http://tolstoy.newcastle.edu.au/R/devel/04a/0344.html

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/25436.html

in both cases, par("mfg") is being used, which is common to Dan's
problem here.

So, unless I am missing something and without yet delving further into
graphic device specific source code, I suspect that there is a problem
when creating PS/EPS/PDF files in conjunction with par("mfg").

HTH,

Marc Schwartz

-------------- next part --------------
A non-text attachment was scrubbed...
Name: mfg.pdf
Type: application/pdf
Size: 7620 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20050426/718503ea/mfg.pdf
-------------- next part --------------
A non-text attachment was scrubbed...
Name: nomfg.pdf
Type: application/pdf
Size: 7852 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20050426/718503ea/nomfg.pdf
-------------- next part --------------
A non-text attachment was scrubbed...
Name: x.mfg.eps
Type: application/postscript
Size: 6463 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20050426/718503ea/x.mfg.eps
-------------- next part --------------
A non-text attachment was scrubbed...
Name: x.nomfg.eps
Type: application/postscript
Size: 6478 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20050426/718503ea/x.nomfg.eps
From dan at bolser.co.uk  Wed Apr 27 01:18:32 2005
From: dan at bolser.co.uk (dan@bolser.co.uk)
Date: Wed Apr 27 01:18:43 2005
Subject: [Rd] postscript (eps) / latex / par(mfg=...) / problem! (PR#7820)
Message-ID: <20050426231832.E9DD2A1E4@slim.kubism.ku.dk>

Full_Name: Dan Freak Bolser
Version: Version 2.0.0  (2004-10-04)
OS: Linux 2.4.20-31.9 (RedHat 9)
Submission from: (NULL) (62.253.128.15)


                                                                                
                                                                        
The same problem I am having has been reported here
                                                                                
                                                                        
http://tolstoy.newcastle.edu.au/R/devel/04a/0344.html
                                                                                
                                                                        
                                                                                
                                                                        
Namely that using par(mfg=...) with a postscript (eps) for inclusion with
latex makes the figure appear upside down and back to front (flipped)!
                                                                                
                                                                        
Converting the dvi to ps makes matters worse (the eps seems to be broken),
however, it appears fine with gv.
                                                                                
                                                                        
Here is (basically) the code I am using...
                                                                                
                                                                        
>dat <- read.table("x.dmp", header=1)
>t(dat)
t(dat)
            1   2   3   4  5  6 7  8 9 10 11 12 13 14 15 16 17 18 19 20
CHAINS      1   2   3   4  5  6 7  8 9 10 11 12 13 14 16 20 23 24 26 28
FREQUENCY 886 792 136 201 16 58 6 21 3  9  3  9  1  4  3  1  1  1  1  1
>
>postscript(
+           "x.eps",
+           width = 6.0,
+           height = 6.0,
+           horizontal = FALSE,
+           onefile = FALSE,
+           paper = "special",
+           )
>
>par(mfg=c(1,1))
>par(mar=c(3,4,1,2))
>plot(dat,type='b')
>
>par(mfg=c(2,1))
>par(mar=c(4,4,0,2))
>plot(dat,type='b', log='y')
>
>dev.off()
                                                                                
                                                                        
                                                                                
                                                                        
Including the resulting file in a latex document like this...
                                                                                
                                                                        
begin{figure}
\centering
\includegraphics[width=\textwidth]{x.eps}
\caption[X]
{
Hello!
}
\label{xFig}
\end{figure}
                                                                                
                                                                        
The result is an upside down (flipped) version of my plot. I tried
rotating 180 degrees (based on similar problems people were having on the
list), but then it just gets worse (most of the plot is off the page). If
I convert the dvi to ps (dvips -Ppdf my.tex.dvi -o my.tex.ps) it gets
worse (a tiny speck where the image should be).
                                                                                
                                                                        
After removing the two mfg commands (which I use to add grid lines (not
shown for clarity)) everything is fine! Some how mfg is snarling things
up.
                                                                                
                                                                        
OK, I just had a brain wave (dont laugh). Here is a diff of the working
eps vs the broken eps...
                                                                                
                                                                        
diff broken working
                                                                                
                                                                        
78a79,80
> %%Page: 1 1
> bp
229c231
< 57.60 43.20 403.20 201.60 cl
---
> 57.60 57.60 403.20 216.00 cl
417c419
< %%Pages: 0
---
> %%Pages: 1
                                                                                
                                                                        
                                                                                
                                                                        
Does that help anyone debug my problem? Like I said, both look identical
via gv, and are 'conceptually' identical in R.
                                                                                
                                                                        
Here are my vitals
                                                                                
                                                                        
Linux 2.4.20-31.9 i686 athlon i386 GNU/Linux
R 2.0.0 (2004-10-04).
GNU Ghostscript 7.05 (2002-04-22)
                                                                                
                                                                        
Anything else you need?
                                                                                
                                                                        
Please help!

From luke at stat.uiowa.edu  Wed Apr 27 02:50:12 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Wed Apr 27 02:50:42 2005
Subject: [Rd] RE: [R] when can we expect Prof Tierney's compiled R?
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A59E8DBF@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A59E8DBF@phost015.EVAFUNDS.intermedia.net>
Message-ID: <Pine.LNX.4.62.0504261932360.9843@itasca2.wildberry.org>

For what it's worth (probably not much as these simple benchmarks are
rarely representative of real code and so need to be taken with a huge
chunk of salt) here is what happens with your examples in R 2.1.0 with
the current byte compiler.

Define your examples as functions:

     n = 1e6; iA = seq(2,n); x = double(n);
     f1 <- function(x, iA) for (i in iA) x[i] = x[i-1]
     f2 <- function(x, iA) for (i in iA) x[i-1]
     f3 <- function(x, iA) for (i in iA) 1
     f4 <- function(x, iA) for (i in iA) x[i] = 1.0
     f5 <- function(x, iA) for (i in iA) i-1
     f6 <- function(x, iA) for (i in iA) i

Make byte compiled versions:

     f1c <- cmpfun(f1)
     f2c <- cmpfun(f2)
     f3c <- cmpfun(f3)
     f4c <- cmpfun(f4)
     f5c <- cmpfun(f5)
     f6c <- cmpfun(f6)

and run them:

     > system.time(f1(x, iA))
     [1] 5.43 0.04 5.56 0.00 0.00
     > system.time(f1c(x, iA))
     [1] 1.77 0.03 1.81 0.00 0.00

     > system.time(f2(x, iA))
     [1] 1.72 0.01 1.74 0.00 0.00
     > system.time(f2c(x, iA))
     [1] 0.63 0.00 0.63 0.00 0.00

     > system.time(f3(x, iA))
     [1] 0.19 0.00 0.20 0.00 0.00
     > system.time(f3c(x, iA))
     [1] 0.14 0.00 0.15 0.00 0.00

     > system.time(f4(x, iA))
     [1] 3.78 0.03 3.82 0.00 0.00
     > system.time(f4c(x, iA))
     [1] 1.26 0.02 1.30 0.00 0.00

     > system.time(f5(x, iA))
     [1] 0.99 0.00 1.00 0.00 0.00
     > system.time(f5c(x, iA))
     [1] 0.30 0.00 0.31 0.00 0.00

     > system.time(f6(x, iA))
     [1] 0.21 0.00 0.23 0.00 0.00
     > system.time(f6c(x, iA))
     [1] 0.17 0.00 0.20 0.00 0.00

I'll let you do the arithmetic.  The byte compiler does get rid of a
fair bit of interpreter overhead (which is large in these kinds of
examples compared to most real code) but there is still considerable
room for improvement.  The byte code engine currently uses the same
internal C code for doing the actual work as the interpreter, so
improvements there would help both interpreted and byte compiled code.

Best,

luke

On Fri, 22 Apr 2005, Vadim Ogranovich wrote:

> If we are on the subject of byte compilation, let me bring a couple of
> examples which have been puzzling me for some time. I'd like to know a)
> if the compilation will likely to improve the performance for this type
> of computations, and b) at least roughly understand the reasons for the
> observed numbers, specifically why x[i]<- assignment is so much slower
> than x[i] extraction.
>
> The loops below are typical in any recursive calculation where the new
> value of a vector is based on its immediate neighbor say to the left.
> Specifically we assign the previous value to the current element.
>
> # this shows that the assignment x[i]<- is the bottleneck in the loop
>> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) x[i]
> = x[i-1])
> [1] 4.29 0.00 4.30 0.00 0.00
>> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA)
> x[i-1])
> [1] 1.46 0.01 1.46 0.00 0.00
>
> # the overhead of the loop itself is reasonably low, just 0.17 sec
>> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) 1)
> [1] 0.17 0.01 0.17 0.00 0.00
>
> # pure assignment (w/o the extraction x[i]) takes 3.09 sec. Thus x[i] as
> extraction is (3.09 - 0.17)/(0.79 - 0.17) = 4.7 times faster than x[i]<-
> as assignment. This looks a bit odd.
>> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) x[i]
> = 1.0)
> [1] 3.08 0.00 3.09 0.00 0.00
>
>
> # this shows that just evaluation of (i-1) takes about (0.79 - 0.24) =
> 0.55 sec on my machine (AMD 64 bit). Looks too slow.
>> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) i-1)
> [1] 0.79 0.00 0.79 0.00 0.00
>> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) i)
> [1] 0.24 0.01 0.24 0.00 0.00
>
> Thanks,
> Vadim
>
>> -----Original Message-----
>> From: r-help-bounces@stat.math.ethz.ch
>> [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of Luke Tierney
>> Sent: Friday, April 22, 2005 7:33 AM
>> To: Peter Dalgaard
>> Cc: Jason Liao; r-help@stat.math.ethz.ch
>> Subject: Re: [R] when can we expect Prof Tierney's compiled R?
>>
>> On Wed, 20 Apr 2005, Peter Dalgaard wrote:
>>
>>> Luke Tierney <luke@stat.uiowa.edu> writes:
>>>
>>>> Vectorized operations in R are also as fast as compiled C (because
>>>> that is what they are :-)).  A compiler such as the one
>> I'm working
>>>> on will be able to make most difference for
>> non-vectorizable or not
>>>> very vectorizable code.  It may also be able to reduce the
>> need for
>>>> intermediate allocations in vectorizable code, which may
>> have other
>>>> benefits beyond just speed improvements.
>>>
>>> Actually, it has struck me a couple of times that these
>> operations are
>>> not as fast as they could be, since they are outside the
>> scope of fast
>>> BLAS routines, but "embarrassingly parallel" code could easily be
>>> written for the relevant hardware. Even on uniprocessor
>> systems there
>>> might be speedups that the C compiler cannot find (e.g. because it
>>> cannot assume that source and destination of the operation are
>>> distinct).
>>
>> My guess is that for anything beyond basic operations we are
>> doing OK on uniprocessors. but it would be useful to do some
>> testing to be sure.  For the basic operations I suspect we
>> are paying a heavy price for the way we handle recycling,
>> both in terms of overhead as such and in terms of inhibiting
>> compiler optimizations. For performance it would probably be
>> better to code the scalar-vector, equal-length-vector, and
>> general cases separately, though keeping the code
>> maintainable may be a bit of a challenge.  Again testing on a
>> range of platforms and compilers would be useful.
>>
>> With multiprocessors likely to become more widely available
>> it would be good to look into ways of factoring the
>> vectorized math code so we can slide in one that uses threads
>> when approprate.  This should dovetail nicely with
>> compilation to identify larger vectorized expressions that
>> can be parallelized as a unit; I hope to look into this a bit
>> this summer.
>>
>> luke
>>
>>
>>
>> --
>> Luke Tierney
>> Chair, Statistics and Actuarial Science
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>     Actuarial Science
>> 241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>
>> ______________________________________________
>> R-help@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From vograno at evafunds.com  Wed Apr 27 03:27:09 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Wed Apr 27 03:27:18 2005
Subject: [Rd] RE: [R] when can we expect Prof Tierney's compiled R?
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A59E8F2A@phost015.EVAFUNDS.intermedia.net>

Luke,

Thank you for sharing the benchmark results. The improvement is very
substantial, I am looking forward to the release of the byte compiler!

The arithmetic shows that x[i]<- is still the bottleneck. I suspect that
this is due to a very involved dispatching/search for the appropriate
function on the C level. There might be significant gain if loops
somehow cached the result of the initial dispatching. This is what you
probably referred to as additional improvements in the engine itself.

Though the examples are very simple, I think they are typical of any
simulation of dynamic systems where the new state is computed as a
transformation of the previous state. In my example, the f1(), the state
was a scalar and the transformation was the identity.

In any case the timing of the byte-compilation is remarkable!

Thanks,
Vadim



> -----Original Message-----
> From: Luke Tierney [mailto:luke@stat.uiowa.edu] 
> Sent: Tuesday, April 26, 2005 5:50 PM
> To: Vadim Ogranovich
> Cc: Peter Dalgaard; Jason Liao; r-devel@stat.math.ethz.ch
> Subject: RE: [R] when can we expect Prof Tierney's compiled R?
> 
> For what it's worth (probably not much as these simple 
> benchmarks are rarely representative of real code and so need 
> to be taken with a huge chunk of salt) here is what happens 
> with your examples in R 2.1.0 with the current byte compiler.
> 
> Define your examples as functions:
> 
>      n = 1e6; iA = seq(2,n); x = double(n);
>      f1 <- function(x, iA) for (i in iA) x[i] = x[i-1]
>      f2 <- function(x, iA) for (i in iA) x[i-1]
>      f3 <- function(x, iA) for (i in iA) 1
>      f4 <- function(x, iA) for (i in iA) x[i] = 1.0
>      f5 <- function(x, iA) for (i in iA) i-1
>      f6 <- function(x, iA) for (i in iA) i
> 
> Make byte compiled versions:
> 
>      f1c <- cmpfun(f1)
>      f2c <- cmpfun(f2)
>      f3c <- cmpfun(f3)
>      f4c <- cmpfun(f4)
>      f5c <- cmpfun(f5)
>      f6c <- cmpfun(f6)
> 
> and run them:
> 
>      > system.time(f1(x, iA))
>      [1] 5.43 0.04 5.56 0.00 0.00
>      > system.time(f1c(x, iA))
>      [1] 1.77 0.03 1.81 0.00 0.00
> 
>      > system.time(f2(x, iA))
>      [1] 1.72 0.01 1.74 0.00 0.00
>      > system.time(f2c(x, iA))
>      [1] 0.63 0.00 0.63 0.00 0.00
> 
>      > system.time(f3(x, iA))
>      [1] 0.19 0.00 0.20 0.00 0.00
>      > system.time(f3c(x, iA))
>      [1] 0.14 0.00 0.15 0.00 0.00
> 
>      > system.time(f4(x, iA))
>      [1] 3.78 0.03 3.82 0.00 0.00
>      > system.time(f4c(x, iA))
>      [1] 1.26 0.02 1.30 0.00 0.00
> 
>      > system.time(f5(x, iA))
>      [1] 0.99 0.00 1.00 0.00 0.00
>      > system.time(f5c(x, iA))
>      [1] 0.30 0.00 0.31 0.00 0.00
> 
>      > system.time(f6(x, iA))
>      [1] 0.21 0.00 0.23 0.00 0.00
>      > system.time(f6c(x, iA))
>      [1] 0.17 0.00 0.20 0.00 0.00
> 
> I'll let you do the arithmetic.  The byte compiler does get 
> rid of a fair bit of interpreter overhead (which is large in 
> these kinds of examples compared to most real code) but there 
> is still considerable room for improvement.  The byte code 
> engine currently uses the same internal C code for doing the 
> actual work as the interpreter, so improvements there would 
> help both interpreted and byte compiled code.
> 
> Best,
> 
> luke
> 
> On Fri, 22 Apr 2005, Vadim Ogranovich wrote:
> 
> > If we are on the subject of byte compilation, let me bring 
> a couple of 
> > examples which have been puzzling me for some time. I'd 
> like to know 
> > a) if the compilation will likely to improve the 
> performance for this 
> > type of computations, and b) at least roughly understand 
> the reasons 
> > for the observed numbers, specifically why x[i]<- assignment is so 
> > much slower than x[i] extraction.
> >
> > The loops below are typical in any recursive calculation 
> where the new 
> > value of a vector is based on its immediate neighbor say to 
> the left.
> > Specifically we assign the previous value to the current element.
> >
> > # this shows that the assignment x[i]<- is the bottleneck 
> in the loop
> >> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i 
> in iA) x[i]
> > = x[i-1])
> > [1] 4.29 0.00 4.30 0.00 0.00
> >> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA)
> > x[i-1])
> > [1] 1.46 0.01 1.46 0.00 0.00
> >
> > # the overhead of the loop itself is reasonably low, just 0.17 sec
> >> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) 1)
> > [1] 0.17 0.01 0.17 0.00 0.00
> >
> > # pure assignment (w/o the extraction x[i]) takes 3.09 sec. 
> Thus x[i] 
> > as extraction is (3.09 - 0.17)/(0.79 - 0.17) = 4.7 times 
> faster than 
> > x[i]<- as assignment. This looks a bit odd.
> >> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i 
> in iA) x[i]
> > = 1.0)
> > [1] 3.08 0.00 3.09 0.00 0.00
> >
> >
> > # this shows that just evaluation of (i-1) takes about 
> (0.79 - 0.24) =
> > 0.55 sec on my machine (AMD 64 bit). Looks too slow.
> >> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i 
> in iA) i-1)
> > [1] 0.79 0.00 0.79 0.00 0.00
> >> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) i)
> > [1] 0.24 0.01 0.24 0.00 0.00
> >
> > Thanks,
> > Vadim
> >
> >> -----Original Message-----
> >> From: r-help-bounces@stat.math.ethz.ch 
> >> [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of Luke Tierney
> >> Sent: Friday, April 22, 2005 7:33 AM
> >> To: Peter Dalgaard
> >> Cc: Jason Liao; r-help@stat.math.ethz.ch
> >> Subject: Re: [R] when can we expect Prof Tierney's compiled R?
> >>
> >> On Wed, 20 Apr 2005, Peter Dalgaard wrote:
> >>
> >>> Luke Tierney <luke@stat.uiowa.edu> writes:
> >>>
> >>>> Vectorized operations in R are also as fast as compiled 
> C (because 
> >>>> that is what they are :-)).  A compiler such as the one
> >> I'm working
> >>>> on will be able to make most difference for
> >> non-vectorizable or not
> >>>> very vectorizable code.  It may also be able to reduce the
> >> need for
> >>>> intermediate allocations in vectorizable code, which may
> >> have other
> >>>> benefits beyond just speed improvements.
> >>>
> >>> Actually, it has struck me a couple of times that these
> >> operations are
> >>> not as fast as they could be, since they are outside the
> >> scope of fast
> >>> BLAS routines, but "embarrassingly parallel" code could easily be 
> >>> written for the relevant hardware. Even on uniprocessor
> >> systems there
> >>> might be speedups that the C compiler cannot find (e.g. 
> because it 
> >>> cannot assume that source and destination of the operation are 
> >>> distinct).
> >>
> >> My guess is that for anything beyond basic operations we 
> are doing OK 
> >> on uniprocessors. but it would be useful to do some testing to be 
> >> sure.  For the basic operations I suspect we are paying a 
> heavy price 
> >> for the way we handle recycling, both in terms of overhead as such 
> >> and in terms of inhibiting compiler optimizations. For 
> performance it 
> >> would probably be better to code the scalar-vector, 
> >> equal-length-vector, and general cases separately, though 
> keeping the 
> >> code maintainable may be a bit of a challenge.  Again testing on a 
> >> range of platforms and compilers would be useful.
> >>
> >> With multiprocessors likely to become more widely 
> available it would 
> >> be good to look into ways of factoring the vectorized math 
> code so we 
> >> can slide in one that uses threads when approprate.  This should 
> >> dovetail nicely with compilation to identify larger vectorized 
> >> expressions that can be parallelized as a unit; I hope to 
> look into 
> >> this a bit this summer.
> >>
> >> luke
> >>
> >>
> >>
> >> --
> >> Luke Tierney
> >> Chair, Statistics and Actuarial Science Ralph E. Wareham 
> Professor of 
> >> Mathematical Sciences
> >> University of Iowa                  Phone:             319-335-3386
> >> Department of Statistics and        Fax:               319-335-3017
> >>     Actuarial Science
> >> 241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
> >> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> >>
> >> ______________________________________________
> >> R-help@stat.math.ethz.ch mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide!
> >> http://www.R-project.org/posting-guide.html
> >>
> >
> >
> 
> --
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>

From Russell.Moffitt at noaa.gov  Wed Apr 27 05:03:59 2005
From: Russell.Moffitt at noaa.gov (Russell Moffitt)
Date: Wed Apr 27 05:03:21 2005
Subject: [Rd] ncdf with opendap/dods support
Message-ID: <426F011F.9@noaa.gov>

Aloha,

I just made some quick hacks on the configure script with the 'ncdf' 
package to make it link with the opendap/dods libraries (opendap.org) 
rather than the netcdf api library.  Basically, this allows a user to 
interact in R with a remotely served dataset as if it were a netcdf file 
on the local filesystem (read-only).  Functionality with local files 
should continue to work as well.  This opendap feature should be greatly 
useful for a number of fields of scientific computing, including 
oceanography and climate modelling, where a huge number of data sets are 
already served via opendap around the world.

In order to do this, the user must install the opendap/dods netcdf 
libraries on the system and then run
R CMD INSTALL --configure-args="-with-dods=$DODS_INSTALL_DIR" 
ncdf_1.3-dods.tar.gz
where $DODS_INSTALL_DIR is wherever the opendap lib and include 
directories are found.

My modifications are small and unelegant, but it works, providing that 
the user can successfully install the opendap libraries.  I am neither a 
compile guru nor do I have very much experience using and developing for 
R.  Therefore, I would like to see if anyone would be willing to help me 
make this modification into a more official package/patch that can be 
shared with other R users.  The biggest obstacle for me is making 
binaries for Windows.  Precompiled opendap libraries are available for 
windows, so this should be possible.  B Ripley has compiled the 'ncdf' 
package for windows, and this version should be exactly the same except 
for different external libraries.

This same modification should also be possible for the RNetCDF/nvar 
packages since they use the same support libraries.  I just happened to 
try it with ncdf first.  Which package do more people tend to use/like 
for accessing netcdf files?

Please let me know if you can provide some assistance in making this 
modified package as easy to install as possible on 
unix/linux/windows/etc...  I can provide more info about the opendap 
library and what is required to link to it if you ask.

Mahalo,
Russell

P.S.  I imagine that this opendap support in R will allow us to list R 
on opendap.org's list of client applications, giving R some more exposure.

From ripley at stats.ox.ac.uk  Wed Apr 27 08:41:42 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Apr 27 08:41:58 2005
Subject: [Rd] ncdf with opendap/dods support
In-Reply-To: <426F011F.9@noaa.gov>
References: <426F011F.9@noaa.gov>
Message-ID: <Pine.LNX.4.61.0504270735560.18495@gannet.stats>

You need to approach the package maintainers directly: they may well not 
read r-devel.  What you seem to be suggesting is an extra feature for the 
ncdf package.

Note from `B Ripley':  you need libraries for a specific compiler on 
Windows.

Professor Ripley.

On Tue, 26 Apr 2005, Russell Moffitt wrote:

> Aloha,
>
> I just made some quick hacks on the configure script with the 'ncdf' package 
> to make it link with the opendap/dods libraries (opendap.org) rather than the 
> netcdf api library.  Basically, this allows a user to interact in R with a 
> remotely served dataset as if it were a netcdf file on the local filesystem 
> (read-only).  Functionality with local files should continue to work as well. 
> This opendap feature should be greatly useful for a number of fields of 
> scientific computing, including oceanography and climate modelling, where a 
> huge number of data sets are already served via opendap around the world.
>
> In order to do this, the user must install the opendap/dods netcdf libraries 
> on the system and then run
> R CMD INSTALL --configure-args="-with-dods=$DODS_INSTALL_DIR" 
> ncdf_1.3-dods.tar.gz
> where $DODS_INSTALL_DIR is wherever the opendap lib and include directories 
> are found.
>
> My modifications are small and unelegant, but it works, providing that the 
> user can successfully install the opendap libraries.  I am neither a compile 
> guru nor do I have very much experience using and developing for R. 
> Therefore, I would like to see if anyone would be willing to help me make 
> this modification into a more official package/patch that can be shared with 
> other R users.  The biggest obstacle for me is making binaries for Windows. 
> Precompiled opendap libraries are available for windows, so this should be 
> possible.  B Ripley has compiled the 'ncdf' package for windows, and this 
> version should be exactly the same except for different external libraries.
>
> This same modification should also be possible for the RNetCDF/nvar packages 
> since they use the same support libraries.  I just happened to try it with 
> ncdf first.  Which package do more people tend to use/like for accessing 
> netcdf files?
>
> Please let me know if you can provide some assistance in making this modified 
> package as easy to install as possible on unix/linux/windows/etc...  I can 
> provide more info about the opendap library and what is required to link to 
> it if you ask.
>
> Mahalo,
> Russell
>
> P.S.  I imagine that this opendap support in R will allow us to list R on 
> opendap.org's list of client applications, giving R some more exposure.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Apr 27 10:12:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Apr 27 10:13:01 2005
Subject: [Rd] RE: [R] when can we expect Prof Tierney's compiled R?
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A59E8F2A@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A59E8F2A@phost015.EVAFUNDS.intermedia.net>
Message-ID: <Pine.LNX.4.61.0504270642550.18495@gannet.stats>

On Tue, 26 Apr 2005, Vadim Ogranovich wrote:

> Thank you for sharing the benchmark results. The improvement is very
> substantial, I am looking forward to the release of the byte compiler!
>
> The arithmetic shows that x[i]<- is still the bottleneck. I suspect that
> this is due to a very involved dispatching/search for the appropriate
> function on the C level. There might be significant gain if loops
> somehow cached the result of the initial dispatching. This is what you
> probably referred to as additional improvements in the engine itself.

I'd be surprised if dispatching were the issue: have you (C-level) 
profiled to find out?  Please do so: these statements do tend to get 
perpetuated as fact.

You cannot cache the result, as [<- can change the class of x, as could 
other operations done by the rhs (e.g. if it were x[i] <- g(x, i) the 
function g could change its argument).

There are a large number of allocations going on (e.g. you need to create 
a length-one vector x[i-1]), and

> gc.time(TRUE)
[1] 0 0 0 0 0
> system.time(f1(x, iA), gcFirst=TRUE)
[1] 6.46 0.02 6.49 0.00 0.00
> gc.time()
[1] 1.83 1.30 1.85 0.00 0.00

(although note the comment in ?gc.time).  It is typical that gc()-ing is a 
major component of the time for such simple tasks, and allocations can be 
even more.

Note the use of gcFirst=TRUE (one could gc() before gc.time to be even 
fairer).  Comparable figures for f2

> system.time(f2(x, iA), gcFirst=TRUE)
[1] 2.13 0.00 2.13 0.00 0.00
> gc.time()
[1] 0.69 0.54 0.71 0.00 0.00

It's quite typical for gc()-ing to take 1/3 of the time (as reported by 
gc.time) in trivial problems like this.

> Though the examples are very simple, I think they are typical of any
> simulation of dynamic systems where the new state is computed as a
> transformation of the previous state. In my example, the f1(), the state
> was a scalar and the transformation was the identity.

I don't believe they are typical, as the transformation is so trivial.
Of course, `simulation of dynamic systems' is not a typical task for R.

> In any case the timing of the byte-compilation is remarkable!

> Thanks,
> Vadim
>
>
>
>> -----Original Message-----
>> From: Luke Tierney [mailto:luke@stat.uiowa.edu]
>> Sent: Tuesday, April 26, 2005 5:50 PM
>> To: Vadim Ogranovich
>> Cc: Peter Dalgaard; Jason Liao; r-devel@stat.math.ethz.ch
>> Subject: RE: [R] when can we expect Prof Tierney's compiled R?
>>
>> For what it's worth (probably not much as these simple
>> benchmarks are rarely representative of real code and so need
>> to be taken with a huge chunk of salt) here is what happens
>> with your examples in R 2.1.0 with the current byte compiler.
>>
>> Define your examples as functions:
>>
>>      n = 1e6; iA = seq(2,n); x = double(n);
>>      f1 <- function(x, iA) for (i in iA) x[i] = x[i-1]
>>      f2 <- function(x, iA) for (i in iA) x[i-1]
>>      f3 <- function(x, iA) for (i in iA) 1
>>      f4 <- function(x, iA) for (i in iA) x[i] = 1.0
>>      f5 <- function(x, iA) for (i in iA) i-1
>>      f6 <- function(x, iA) for (i in iA) i
>>
>> Make byte compiled versions:
>>
>>      f1c <- cmpfun(f1)
>>      f2c <- cmpfun(f2)
>>      f3c <- cmpfun(f3)
>>      f4c <- cmpfun(f4)
>>      f5c <- cmpfun(f5)
>>      f6c <- cmpfun(f6)
>>
>> and run them:
>>
>>     > system.time(f1(x, iA))
>>      [1] 5.43 0.04 5.56 0.00 0.00
>>     > system.time(f1c(x, iA))
>>      [1] 1.77 0.03 1.81 0.00 0.00
>>
>>     > system.time(f2(x, iA))
>>      [1] 1.72 0.01 1.74 0.00 0.00
>>     > system.time(f2c(x, iA))
>>      [1] 0.63 0.00 0.63 0.00 0.00
>>
>>     > system.time(f3(x, iA))
>>      [1] 0.19 0.00 0.20 0.00 0.00
>>     > system.time(f3c(x, iA))
>>      [1] 0.14 0.00 0.15 0.00 0.00
>>
>>     > system.time(f4(x, iA))
>>      [1] 3.78 0.03 3.82 0.00 0.00
>>     > system.time(f4c(x, iA))
>>      [1] 1.26 0.02 1.30 0.00 0.00
>>
>>     > system.time(f5(x, iA))
>>      [1] 0.99 0.00 1.00 0.00 0.00
>>     > system.time(f5c(x, iA))
>>      [1] 0.30 0.00 0.31 0.00 0.00
>>
>>     > system.time(f6(x, iA))
>>      [1] 0.21 0.00 0.23 0.00 0.00
>>     > system.time(f6c(x, iA))
>>      [1] 0.17 0.00 0.20 0.00 0.00
>>
>> I'll let you do the arithmetic.  The byte compiler does get
>> rid of a fair bit of interpreter overhead (which is large in
>> these kinds of examples compared to most real code) but there
>> is still considerable room for improvement.  The byte code
>> engine currently uses the same internal C code for doing the
>> actual work as the interpreter, so improvements there would
>> help both interpreted and byte compiled code.
>>
>> Best,
>>
>> luke
>>
>> On Fri, 22 Apr 2005, Vadim Ogranovich wrote:
>>
>>> If we are on the subject of byte compilation, let me bring
>> a couple of
>>> examples which have been puzzling me for some time. I'd
>> like to know
>>> a) if the compilation will likely to improve the
>> performance for this
>>> type of computations, and b) at least roughly understand
>> the reasons
>>> for the observed numbers, specifically why x[i]<- assignment is so
>>> much slower than x[i] extraction.
>>>
>>> The loops below are typical in any recursive calculation
>> where the new
>>> value of a vector is based on its immediate neighbor say to
>> the left.
>>> Specifically we assign the previous value to the current element.
>>>
>>> # this shows that the assignment x[i]<- is the bottleneck
>> in the loop
>>>> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i
>> in iA) x[i]
>>> = x[i-1])
>>> [1] 4.29 0.00 4.30 0.00 0.00
>>>> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA)
>>> x[i-1])
>>> [1] 1.46 0.01 1.46 0.00 0.00
>>>
>>> # the overhead of the loop itself is reasonably low, just 0.17 sec
>>>> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) 1)
>>> [1] 0.17 0.01 0.17 0.00 0.00
>>>
>>> # pure assignment (w/o the extraction x[i]) takes 3.09 sec.
>> Thus x[i]
>>> as extraction is (3.09 - 0.17)/(0.79 - 0.17) = 4.7 times
>> faster than
>>> x[i]<- as assignment. This looks a bit odd.
>>>> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i
>> in iA) x[i]
>>> = 1.0)
>>> [1] 3.08 0.00 3.09 0.00 0.00
>>>
>>>
>>> # this shows that just evaluation of (i-1) takes about
>> (0.79 - 0.24) =
>>> 0.55 sec on my machine (AMD 64 bit). Looks too slow.
>>>> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i
>> in iA) i-1)
>>> [1] 0.79 0.00 0.79 0.00 0.00
>>>> n = 1e6; iA = seq(2,n); x = double(n); system.time(for (i in iA) i)
>>> [1] 0.24 0.01 0.24 0.00 0.00
>>>
>>> Thanks,
>>> Vadim
>>>
>>>> -----Original Message-----
>>>> From: r-help-bounces@stat.math.ethz.ch
>>>> [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of Luke Tierney
>>>> Sent: Friday, April 22, 2005 7:33 AM
>>>> To: Peter Dalgaard
>>>> Cc: Jason Liao; r-help@stat.math.ethz.ch
>>>> Subject: Re: [R] when can we expect Prof Tierney's compiled R?
>>>>
>>>> On Wed, 20 Apr 2005, Peter Dalgaard wrote:
>>>>
>>>>> Luke Tierney <luke@stat.uiowa.edu> writes:
>>>>>
>>>>>> Vectorized operations in R are also as fast as compiled
>> C (because
>>>>>> that is what they are :-)).  A compiler such as the one
>>>> I'm working
>>>>>> on will be able to make most difference for
>>>> non-vectorizable or not
>>>>>> very vectorizable code.  It may also be able to reduce the
>>>> need for
>>>>>> intermediate allocations in vectorizable code, which may
>>>> have other
>>>>>> benefits beyond just speed improvements.
>>>>>
>>>>> Actually, it has struck me a couple of times that these
>>>> operations are
>>>>> not as fast as they could be, since they are outside the
>>>> scope of fast
>>>>> BLAS routines, but "embarrassingly parallel" code could easily be
>>>>> written for the relevant hardware. Even on uniprocessor
>>>> systems there
>>>>> might be speedups that the C compiler cannot find (e.g.
>> because it
>>>>> cannot assume that source and destination of the operation are
>>>>> distinct).
>>>>
>>>> My guess is that for anything beyond basic operations we
>> are doing OK
>>>> on uniprocessors. but it would be useful to do some testing to be
>>>> sure.  For the basic operations I suspect we are paying a
>> heavy price
>>>> for the way we handle recycling, both in terms of overhead as such
>>>> and in terms of inhibiting compiler optimizations. For
>> performance it
>>>> would probably be better to code the scalar-vector,
>>>> equal-length-vector, and general cases separately, though
>> keeping the
>>>> code maintainable may be a bit of a challenge.  Again testing on a
>>>> range of platforms and compilers would be useful.
>>>>
>>>> With multiprocessors likely to become more widely
>> available it would
>>>> be good to look into ways of factoring the vectorized math
>> code so we
>>>> can slide in one that uses threads when approprate.  This should
>>>> dovetail nicely with compilation to identify larger vectorized
>>>> expressions that can be parallelized as a unit; I hope to
>> look into
>>>> this a bit this summer.
>>>>
>>>> luke
>>>>
>>>>
>>>>
>>>> --
>>>> Luke Tierney
>>>> Chair, Statistics and Actuarial Science Ralph E. Wareham
>> Professor of
>>>> Mathematical Sciences
>>>> University of Iowa                  Phone:             319-335-3386
>>>> Department of Statistics and        Fax:               319-335-3017
>>>>     Actuarial Science
>>>> 241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
>>>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>>>
>>>> ______________________________________________
>>>> R-help@stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide!
>>>> http://www.R-project.org/posting-guide.html
>>>>
>>>
>>>
>>
>> --
>> Luke Tierney
>> Chair, Statistics and Actuarial Science
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>     Actuarial Science
>> 241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Wed Apr 27 12:07:43 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Apr 27 12:07:50 2005
Subject: [Rd] smooth.spline(): residuals(), fitted(),...
Message-ID: <17007.25711.369456.615907@stat.math.ethz.ch>

It has bothered me for quite some time that a smoothing spline
fit doesn't allow access to residuals or fitted values in
general, since after
  fit <- smooth.spline(x,y, *)

the resulting fit$x is really equal to the unique (up to 1e-6
precision) sorted original x values and fit$yin (and $y) is accordingly.

There are several possible ways to implement the missing
feature.  My current implementation would add a new argument
'keep.data' which when set to TRUE would make sure that the
original (x, y, w) are kept such that fitted values and (weighted
or unweighted) residuals are sensibly available from the result.

My main RFC (:= request for comments) is about the
acceptance of the new behavior to become the *default*
(i.e. 'keep.data = TRUE' would be default) such that by default
residuals(smooth.spline(...)) will work.

The drawback of the new default behavior would be that
potentially a 'fit' can become quite a bit larger than previously, e.g.
in the following extremely artificial example

  x0 <- seq(0,1, by = 0.1)
  x <- sort(sample(x0, 1000, replace = TRUE))
  ff <- function(x) 10*(x-1/4)^2 + sin(7*pi*x)
  y <- ff(x) + rnorm(x) / 2
  fit <- smooth.spline(x,y)

but typically the size increase will only be less than about 40%.

Comments are welcome.

Martin Maechler, ETH Zurich

From MSchwartz at MedAnalytics.com  Wed Apr 27 15:31:23 2005
From: MSchwartz at MedAnalytics.com (MSchwartz@MedAnalytics.com)
Date: Wed Apr 27 15:34:33 2005
Subject: [Rd] Re: Ctrl-c crashes R when run as sudo (PR#7819)
Message-ID: <20050427133123.EC464A20B@slim.kubism.ku.dk>

> On Tue, 2005-04-26 at 19:59 +0200, Peter Dalgaard wrote:
> > MSchwartz at medanalytics.com writes:
> > The effect seem to have been neatly backported to 2.0.1 though...
> > 
> > Gdb doesn't seem to help. If you run a ps while "sudo R" is running,
> > you'll see something like this:
> > 
> > root     30416  0.0  0.1  2356  252 pts/5    S+   19:48   0:00 sesh /usr/bin/R
> > root     30417 10.0  7.2 18016 13860 pts/5   S+   19:48   0:01 /usr/lib/R/bin/exec/R
> > 
> > What I suspect is happening is that the ^C kills the sesh process, but
> > that in turn does not manage to kill R.
> 
> So is this perhaps an SELinux issue? I don't get sesh running when I use
> sudo R.
> 
> That would perhaps explain why I am not seeing it. Given the almost
> daily changes in SELinux policies, I have foregone using it for the time
> being. I was having all kinds of 'avc' related errors, so I gave up
> until things stabilize more.

Hi all,

Just a quick note that I seem to have confirmed this as a SELinux/sudo
interaction issue.

I re-booted my system this morning, with SELinux enabled using the
targeted policy, which is the default for FC3.

I was then able to confirm the behavior that Manuel initially reported
here.

As a result, I have filed a bug report with Fedora's Bugzilla against
sudo:

https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=156086

and we'll let the FC folks take it from there.

Needless to say, I am now back with SELinux disabled...

Presumably we can now close out the R bug report.

HTH,

Marc Schwartz

From virctoalgn at gmail.com  Wed Apr 27 15:27:46 2005
From: virctoalgn at gmail.com (Victor Trevino)
Date: Wed Apr 27 15:34:36 2005
Subject: [Rd] Problems compiling C code on windows
Message-ID: <426f9353.2f0e484d.7904.4935@mx.gmail.com>

Hi all,

 

I can't get my C routines running on a windows box. I have no problems at
all in Linux.

 

On windows, I have installed cygwin and the compilation works well but once
I execute "dyn.load(.)" it hangs whatever I use C/C++ interfaces.

 

In Linux it works wonderful but I need to get this code running on windows
boxes.

I know that the problem should be something with the dll generation/linkage
in windows but I can't figure out.

 

As a matter of test I did the following C code:

 

#include <R.h>

#include <Rinternals.h>

SEXP thisisatest(SEXP);

SEXP thisisatest(SEXP a)

{

            long int i;

            if (!isReal(a)) printf("Vector should be double.\n");

            for (i=LENGTH(a)-1; i >=0; i--) {

                        REAL(a)[i] = REAL(a)[i] + 1;

            }

            return (a);

}

 

 

 

Linux output:

R CMD SHLIB thisisthetest.c

gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp
-fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c thisisthetest.c -o
thisisthetest.o

g++ -shared -L/usr/local/lib -o thisisthetest.so thisisthetest.o   

 

In R:

> dyn.load("thisisthetest.so")

> .Call("thisisatest",5)

[1] 6

> 

[[ WONDERFUL ]]

 

 

 

 

Windows output:

L:\R>Rcmd SHLIB thisisthetest.c

making thisisthetest.d from thisisthetest.c

gcc   -IC:/PROGRA~1/R/rw2001/include -Wall -O2   -c thisisthetest.c -o
thisisthetest.o 

ar cr thisisthetest.a thisisthetest.o

ranlib thisisthetest.a

gcc  --shared -s  -o thisisthetest.dll thisisthetest.def thisisthetest.a
-LC:/PROGRA~1/R/rw2001/src/gnuwin32  -lg2c -lR

 

In R:

> dyn.load("thisisthetest.dll")

 [[ IT HANGS ]]

 

 

 

I have tried different combinations in paths (for library search) and
compiling inside cygwin. no success. 

 

Any comments are very very very welcome.

 

 

Thanks !

 

 


	[[alternative HTML version deleted]]

From ripley at stats.ox.ac.uk  Wed Apr 27 15:52:43 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Apr 27 15:52:53 2005
Subject: [Rd] Problems compiling C code on windows
In-Reply-To: <426f9353.2f0e484d.7904.4935@mx.gmail.com>
References: <426f9353.2f0e484d.7904.4935@mx.gmail.com>
Message-ID: <Pine.LNX.4.61.0504271451030.15454@gannet.stats>

On Wed, 27 Apr 2005, Victor Trevino wrote:

> I can't get my C routines running on a windows box. I have no problems at
> all in Linux.
>
> On windows, I have installed cygwin and the compilation works well but once
> I execute "dyn.load(.)" it hangs whatever I use C/C++ interfaces.

Please try reading the R-admin manual (in 2.1.0) and installing a Windows 
compiler instead.  R does not have a Cygwin port: it does have a native 
Windows port.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Wed Apr 27 15:56:32 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Apr 27 15:56:41 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <17006.5202.986122.321760@stat.math.ethz.ch>
References: <200504251000.j3PA01lD009332@hypatia.math.ethz.ch>
	<40567787fcb17bee0bf9ecf403fb8e21@anu.edu.au>
	<320af97cfe90da4c59b7e9c8cd9956d4@anu.edu.au>
	<9717926f912f9fb045c57dd9be4e743c@warwick.ac.uk>
	<b21d1d1a13e8f82d4e1d44c233e9f76e@anu.edu.au>
	<17006.5202.986122.321760@stat.math.ethz.ch>
Message-ID: <17007.39440.105964.263932@stat.math.ethz.ch>

>>>>> "MM" == Martin Maechler <maechler@stat.math.ethz.ch>
>>>>>     on Tue, 26 Apr 2005 12:13:38 +0200 writes:

>>>>> "JMd" == John Maindonald <john.maindonald@anu.edu.au>
>>>>>     on Tue, 26 Apr 2005 15:44:26 +1000 writes:

    JMd> The web page http://wwwmaths.anu.edu.au/~johnm/r/plot-lm/
    JMd> now includes files:
    JMd> plot.lm.RData: Image for file for plot6.lm, a version of plot.lm in 
    JMd> which
    JMd> David Firth's Cook's distance vs leverage/(1-leverage) plot is plot 6.
    JMd> The tick labels are in units of leverage, and the contour labels are
    JMd> in units of absolute values of the standardized residual.

    JMd> plot6.lm.Rd file: A matching help file

    JMd> Comments will be welcome.

    MM> Thank you John!

    MM> The *.Rd has the new references and a new example but
    MM> is not quite complete: the \usage{} has only 4 captions,
    MM> \arguments{ .. \item{which} ..}  only mentions '1:5' --- but
    MM> never mind.

    MM> One of the new examples is

    MM> ## Replace Cook's distance plot by Residual-Leverage plot
    MM> plot(lm.SR, which=c(1:3, 5))

    MM> and -- conceptually I'd really like to change the default from
    MM> 'which = 1:4' to the above
    MM> 'which=c(1:3, 5))' 

    MM> This would be non-compatible though for all those that have
    MM> always used the current default 1:4. 
    MM> OTOH, "MASS" or Peter Dalgaard's book don't mention  plot(<lm fit> )
    MM> or at least don't show it's result.

    MM> What do others think?
    MM> How problematic would a change be in the default plots that
    MM> plot.lm() produces?


    JMd> Another issue, discussed recently on r-help, is that when the model
    JMd> formula is long, the default sub.caption=deparse(x$call) is broken
    JMd> into multiple text elements and overwrites.  
    MM> good point!

    JMd> The only clean and simple way that I can see to handle
    JMd> is to set a default that tests whether the formula is
    JMd> broken into multiple text elements, and if it is then
    JMd> omit it.  Users can then use their own imaginative
    JMd> skills, and such suggestions as have been made on
    JMd> r-help, to construct whatever form of labeling best
    JMd> suits their case, their imaginative skills and their
    JMd> coding skills.

    MM> Hmm, yes, but I think we (R programmers) could try a bit harder
    MM> to provide a reasonable default, e.g., something along
 
    MM> cap <- deparse(x$call, width.cutoff = 500)[1]
    MM> if((nc <- nchar(cap)) > 53)	    
    MM>   cap <- paste(substr(cap, 1, 50), "....", substr(cap, nc-2, nc))

    MM> {untested;  some of the details will differ;
    MM> and the '53', '50' could depend on par("..") measures}

In the mean time, I came to quite a nice way of doing this:

    if(is.null(sub.caption)) { ## construct a default:
        cal <- x$call
        if (!is.na(m.f <- match("formula", names(cal)))) {
            cal <- cal[c(1, m.f)]
            names(cal)[2] <- "" # drop  " formula = "
        }
        cc <- deparse(cal, 80)
        nc <- nchar(cc[1])
        abbr <- length(cc) > 1 || nc > 75
        sub.caption <-
            if(abbr) paste(substr(cc[1], 1, min(75,nc)), "...") else cc[1]
    }


I'm about to commit the current proposal(s) to R-devel,
**INCLUDING** changing the default from 
	      'which = 1:4' to 'which = c(1:3,5)

and ellicit feedback starting from there.

One thing I think I would like is to use color for the Cook's
contours in the new 4th plot.

Martin


	<.............. lots deleted ..........>

From ligges at statistik.uni-dortmund.de  Wed Apr 27 15:59:00 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Apr 27 15:58:32 2005
Subject: [Rd] Problems compiling C code on windows
In-Reply-To: <426f9353.2f0e484d.7904.4935@mx.gmail.com>
References: <426f9353.2f0e484d.7904.4935@mx.gmail.com>
Message-ID: <426F9AA4.3030008@statistik.uni-dortmund.de>

Victor Trevino wrote:

> Hi all,
> 
>  
> 
> I can't get my C routines running on a windows box. I have no problems at
> all in Linux.
> 
>  
> 
> On windows, I have installed cygwin and the compilation works well but once
> I execute "dyn.load(.)" it hangs whatever I use C/C++ interfaces.


cygwin is not supported. Please read the manuals on how to set upo a 
working environment under Windows.

Uwe Ligges



>  
> 
> In Linux it works wonderful but I need to get this code running on windows
> boxes.
> 
> I know that the problem should be something with the dll generation/linkage
> in windows but I can't figure out.
> 
>  
> 
> As a matter of test I did the following C code:
> 
>  
> 
> #include <R.h>
> 
> #include <Rinternals.h>
> 
> SEXP thisisatest(SEXP);
> 
> SEXP thisisatest(SEXP a)
> 
> {
> 
>             long int i;
> 
>             if (!isReal(a)) printf("Vector should be double.\n");
> 
>             for (i=LENGTH(a)-1; i >=0; i--) {
> 
>                         REAL(a)[i] = REAL(a)[i] + 1;
> 
>             }
> 
>             return (a);
> 
> }
> 
>  
> 
>  
> 
>  
> 
> Linux output:
> 
> R CMD SHLIB thisisthetest.c
> 
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp
> -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c thisisthetest.c -o
> thisisthetest.o
> 
> g++ -shared -L/usr/local/lib -o thisisthetest.so thisisthetest.o   
> 
>  
> 
> In R:
> 
> 
>>dyn.load("thisisthetest.so")
> 
> 
>>.Call("thisisatest",5)
> 
> 
> [1] 6
> 
> 
> 
> [[ WONDERFUL ]]
> 
>  
> 
>  
> 
>  
> 
>  
> 
> Windows output:
> 
> L:\R>Rcmd SHLIB thisisthetest.c
> 
> making thisisthetest.d from thisisthetest.c
> 
> gcc   -IC:/PROGRA~1/R/rw2001/include -Wall -O2   -c thisisthetest.c -o
> thisisthetest.o 
> 
> ar cr thisisthetest.a thisisthetest.o
> 
> ranlib thisisthetest.a
> 
> gcc  --shared -s  -o thisisthetest.dll thisisthetest.def thisisthetest.a
> -LC:/PROGRA~1/R/rw2001/src/gnuwin32  -lg2c -lR
> 
>  
> 
> In R:
> 
> 
>>dyn.load("thisisthetest.dll")
> 
> 
>  [[ IT HANGS ]]
> 
>  
> 
>  
> 
>  
> 
> I have tried different combinations in paths (for library search) and
> compiling inside cygwin. no success. 
> 
>  
> 
> Any comments are very very very welcome.
> 
>  
> 
>  
> 
> Thanks !
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From virctoalgn at gmail.com  Wed Apr 27 16:53:41 2005
From: virctoalgn at gmail.com (Victor Trevino)
Date: Wed Apr 27 16:53:50 2005
Subject: SOLVED RE: [Rd] Problems compiling C code on windows
In-Reply-To: <426F9AA4.3030008@statistik.uni-dortmund.de>
Message-ID: <426fa775.0d33a559.0cac.58bf@mx.gmail.com>

Thanks all replies,

I followed your advice. From readme.package I installed Rtools and Mingw,
set them in front of my path and now everything is running.

Thanks very much!


> -----Original Message-----
> From: Uwe Ligges [mailto:ligges@statistik.uni-dortmund.de]
> Sent: 27 April 2005 14:59
> To: Victor Trevino
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] Problems compiling C code on windows
> 
> Victor Trevino wrote:
> 
> > Hi all,
> >
> >
> >
> > I can't get my C routines running on a windows box. I have no problems
> at
> > all in Linux.
> >
> >
> >
> > On windows, I have installed cygwin and the compilation works well but
> once
> > I execute "dyn.load(.)" it hangs whatever I use C/C++ interfaces.
> 
> 
> cygwin is not supported. Please read the manuals on how to set upo a
> working environment under Windows.
> 
> Uwe Ligges
> 
> 
> 
> >
> >
> > In Linux it works wonderful but I need to get this code running on
> windows
> > boxes.
> >
> > I know that the problem should be something with the dll
> generation/linkage
> > in windows but I can't figure out.
> >
> >
> >
> > As a matter of test I did the following C code:
> >
> >
> >
> > #include <R.h>
> >
> > #include <Rinternals.h>
> >
> > SEXP thisisatest(SEXP);
> >
> > SEXP thisisatest(SEXP a)
> >
> > {
> >
> >             long int i;
> >
> >             if (!isReal(a)) printf("Vector should be double.\n");
> >
> >             for (i=LENGTH(a)-1; i >=0; i--) {
> >
> >                         REAL(a)[i] = REAL(a)[i] + 1;
> >
> >             }
> >
> >             return (a);
> >
> > }
> >
> >
> >
> >
> >
> >
> >
> > Linux output:
> >
> > R CMD SHLIB thisisthetest.c
> >
> > gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES -
> mieee-fp
> > -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c thisisthetest.c -o
> > thisisthetest.o
> >
> > g++ -shared -L/usr/local/lib -o thisisthetest.so thisisthetest.o
> >
> >
> >
> > In R:
> >
> >
> >>dyn.load("thisisthetest.so")
> >
> >
> >>.Call("thisisatest",5)
> >
> >
> > [1] 6
> >
> >
> >
> > [[ WONDERFUL ]]
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > Windows output:
> >
> > L:\R>Rcmd SHLIB thisisthetest.c
> >
> > making thisisthetest.d from thisisthetest.c
> >
> > gcc   -IC:/PROGRA~1/R/rw2001/include -Wall -O2   -c thisisthetest.c -o
> > thisisthetest.o
> >
> > ar cr thisisthetest.a thisisthetest.o
> >
> > ranlib thisisthetest.a
> >
> > gcc  --shared -s  -o thisisthetest.dll thisisthetest.def thisisthetest.a
> > -LC:/PROGRA~1/R/rw2001/src/gnuwin32  -lg2c -lR
> >
> >
> >
> > In R:
> >
> >
> >>dyn.load("thisisthetest.dll")
> >
> >
> >  [[ IT HANGS ]]
> >
> >
> >
> >
> >
> >
> >
> > I have tried different combinations in paths (for library search) and
> > compiling inside cygwin. no success.
> >
> >
> >
> > Any comments are very very very welcome.
> >
> >
> >
> >
> >
> > Thanks !
> >
> >
> >
> >
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel

From p.dalgaard at biostat.ku.dk  Wed Apr 27 16:54:02 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed Apr 27 16:56:54 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <17007.39440.105964.263932@stat.math.ethz.ch>
References: <200504251000.j3PA01lD009332@hypatia.math.ethz.ch>
	<40567787fcb17bee0bf9ecf403fb8e21@anu.edu.au>
	<320af97cfe90da4c59b7e9c8cd9956d4@anu.edu.au>
	<9717926f912f9fb045c57dd9be4e743c@warwick.ac.uk>
	<b21d1d1a13e8f82d4e1d44c233e9f76e@anu.edu.au>
	<17006.5202.986122.321760@stat.math.ethz.ch>
	<17007.39440.105964.263932@stat.math.ethz.ch>
Message-ID: <x2zmvkz2wl.fsf@biostat.ku.dk>

Martin Maechler <maechler@stat.math.ethz.ch> writes:

> I'm about to commit the current proposal(s) to R-devel,
> **INCLUDING** changing the default from 
> 	      'which = 1:4' to 'which = c(1:3,5)
> 
> and ellicit feedback starting from there.
> 
> One thing I think I would like is to use color for the Cook's
> contours in the new 4th plot.

Hmm. First try running example(plot.lm) with the modified function and
tell me which observation has the largest Cook's D. With the suggested
new 4th plot it is very hard to tell whether obs #49 is potentially or
actually influential. Plots #1 and #3 are very close to conveying the
same information though...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From maechler at stat.math.ethz.ch  Wed Apr 27 17:30:06 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Apr 27 17:30:27 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <x2zmvkz2wl.fsf@biostat.ku.dk>
References: <200504251000.j3PA01lD009332@hypatia.math.ethz.ch>
	<40567787fcb17bee0bf9ecf403fb8e21@anu.edu.au>
	<320af97cfe90da4c59b7e9c8cd9956d4@anu.edu.au>
	<9717926f912f9fb045c57dd9be4e743c@warwick.ac.uk>
	<b21d1d1a13e8f82d4e1d44c233e9f76e@anu.edu.au>
	<17006.5202.986122.321760@stat.math.ethz.ch>
	<17007.39440.105964.263932@stat.math.ethz.ch>
	<x2zmvkz2wl.fsf@biostat.ku.dk>
Message-ID: <17007.45054.561976.705623@stat.math.ethz.ch>

>>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
>>>>>     on 27 Apr 2005 16:54:02 +0200 writes:

    PD> Martin Maechler <maechler@stat.math.ethz.ch> writes:
    >> I'm about to commit the current proposal(s) to R-devel,
    >> **INCLUDING** changing the default from 
    >> 'which = 1:4' to 'which = c(1:3,5)
    >> 
    >> and ellicit feedback starting from there.
    >> 
    >> One thing I think I would like is to use color for the Cook's
    >> contours in the new 4th plot.

    PD> Hmm. First try running example(plot.lm) with the modified function and
    PD> tell me which observation has the largest Cook's D. With the suggested
    PD> new 4th plot it is very hard to tell whether obs #49 is potentially or
    PD> actually influential. Plots #1 and #3 are very close to conveying the
    PD> same information though...

I shouldn't be teaching here, and I know that I'm getting into fighted
territory (regression diagnostics; robustness; "The" Truth, etc,etc)
but I believe there is no unique way to define "actually influential"
(hence I don't believe that it's extremely useful to know
exactly which Cook's D is largest).

Partly because there are many statistics that can be derived from a
multiple regression fit all of which are influenced in some way. 
AFAIK, all observation-influence measures g(i) are functions of
(r_i, h_{ii}) and the latter are the quantities that "regression
users" should really know {without consulting a text book} and
that are generalizable {e.g. to "linear smoothers" such as
gam()s (for "non-estimated" smoothing parameter)}.

Martin

From ripley at stats.ox.ac.uk  Wed Apr 27 19:21:43 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Apr 27 19:21:52 2005
Subject: [Rd] as.data.frame: Error in "names<-.default" (PR#7808)
Message-ID: <20050427172143.D9140A1D3@slim.kubism.ku.dk>

On Sun, 24 Apr 2005 andy_liaw@merck.com wrote:

[...]

>> f <- function(x) deparse(substitute(x))
>> f(FUN(x1[1:3,,], x2=c("a","b"), x3=c("a", "b"), x4=c("a", "b")))
> [1] "FUN(x1[1:3, , ], x2 = c(\"a\", \"b\"), x3 = c(\"a\", \"b\"), x4 =
> c(\"a\", "
> [2] "    \"b\"))"
>
>
> which is caused by deparse() chopping up the expression.  The fix would be
> to set the width.cutoff argument to something large.  Here's a proposed
> patch:

[...]

> (I used width.cutoff=500, as ?deparse says that the max.  I'd imagine the
> number of characters allowed for valid symbol names in R is probably lower
> than that?)

This is an expression, and can be arbitrarily long.  So one needs to do 
things like terms.formula:

         else paste(deparse(form[[2]]), collapse = "")

or just use the initial part (as done elsewhere).

It's fixed in R-patched now.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Apr 27 22:18:24 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Apr 27 22:18:33 2005
Subject: (PR#7803) [Rd] print.data.frame(), wrong column names alignement, 
Message-ID: <20050427201824.85F6EA1E3@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-733928972-1114633091=:27258
Content-Type: TEXT/PLAIN; charset=iso-8859-1; format=flowed
Content-Transfer-Encoding: QUOTED-PRINTABLE

I've managed to solve this, but the major problem I had was not R but that=
=20
printf was not respecting multi-byte characters in its field widths in
Fedora Core 3.  It is clear from the C99 standard that field widths are in=
=20
characters not bytes.  This may occur elsewhere.

Similarly, double-width characters in e.g. Chinese will not be accounted=20
for.


On Thu, 21 Apr 2005 cyril.humbert@univ-mlv.fr wrote:

> Hello,
>
> When a data.frame contains column names with accentued characters
> (UTF8 encoded), the alignement of the column names is wrong (extra
> spaces inserted).
>
> For example : ------------------------------------------------
>
>> Sys.getlocale()
> [1] "LC_CTYPE=3Dfr_FR.UTF-8@euro;LC_NUMERIC=3DC;LC_TIME=3Dfr_FR.UTF-8@eur=
o;LC_COLLATE=3Dfr_FR.UTF-8@euro;LC_MONETARY=3Dfr_FR.UTF-8@euro;LC_MESSAGES=
=3Dfr_FR.UTF-8@euro;LC_PAPER=3DC;LC_NAME=3DC;LC_ADDRESS=3DC;LC_TELEPHONE=3D=
C;LC_MEASUREMENT=3DC;LC_IDENTIFICATION=3DC"
>
>> print (data.frame(aaaa=3D1, b=3D2, c=3D3)) # (ok)
>  aaaa b c
> 1    1 2 3
>
>
>> print (data.frame(=C3=A9=C3=A9=C3=A9=C3=A9=3D1, b=3D2, c=3D3)) # (extra =
blanks)
>  =C3=A9=C3=A9=C3=A9=C3=A9 b c
> 1        1 2 3
>
> --------------------------------------------------------------
>
> This is probably due to fact that the number of white spaces
> to insert between the columns is computed using the length
> of the column names (in bytes) instead of their width (in
> characters), which are different in the example above.
>
> The problem is the same (extra spaces inserted) with
> print.data.frame(..., right =3D FALSE).
>
> Thanks,
> Cyril
>
>
> --please do not edit the information below--
>
> Version:
> platform =3D i386-pc-linux-gnu
> arch =3D i386
> os =3D linux-gnu
> system =3D i386, linux-gnu
> status =3D
> major =3D 2
> minor =3D 1.0
> year =3D 2005
> month =3D 04
> day =3D 18
> language =3D R
>
> Search Path:
> .GlobalEnv, package:methods, package:stats, package:graphics, package:grD=
evices, package:utils, package:datasets, Autoloads, package:base

--=20
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-733928972-1114633091=:27258--

From reid_huntsinger at merck.com  Thu Apr 28 00:29:26 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Thu Apr 28 00:30:12 2005
Subject: [Rd] RE: [R] Advice for calling a C function
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A93EC@uswpmx00.merck.com>

You have the dimensions switched, in

 double x [*MATDESC][*OBJ];

so when the dimensions aren't equal you do get odd things.

You might be better off defining functions to index into mat with a pair of
subscripts directly (.C() copies the argument anyway). Come to think of it,
there might be macros/functions for this in Rinternals.h.  Then you don't
need to worry about row-major vs column-major order and related issues.

Finally, as this is a C programming question, it should go to R-devel.

Reid Huntsinger

-----Original Message-----
From: r-help-bounces@stat.math.ethz.ch
[mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of Tyler Smith
Sent: Tuesday, April 26, 2005 11:02 AM
To: R-Help
Subject: [R] Advice for calling a C function


Hi,

I'm having some trouble with a bit of combined C & R code. I'm trying to 
write a C function to handle the for loops in a function I'm working on 
to calculate a similarity matrix. Jari Oksanen has kindly added the 
necessary changes to the vegan package so that I can use the vegdist 
function, so this isn't absolutely necessary. However, I'm stubborn and 
want to know why Jari's code works and mine doesn't! Other than, of 
course, the obvious - one of us knows what their doing and the other 
doesn't. I would appreciate any help. What I've done is:

pass a matrix x to my C function, as a double:

.C("gowsim", as.double(mat), as.integer(nrow(mat)), as.integer(ncol(mat)))

 Then I try and reconstruct the matrix, in the form of a C array:

#include <R.h>
#include <Rmath.h>
#include <math.h>

void gowsim ( double *mat, int *OBJ, int *MATDESC)
 {
    double x [*MATDESC][*OBJ];
    int i, j, nrow, ncol;
    nrow = *OBJ;
    ncol = *MATDESC;
   
    /* Rebuild Matrix */
    for (j=0; j < ncol; j++) {
        for (i=0; i < nrow; i++) {
            x[i][j] = *mat;
            Rprintf("row %d col %d value %f\n", i, j, x[i][j]);
            mat++;
        }
    }
    for (i=0; i< nrow; i++) {
    Rprintf("%f %f %f %f\n", x[i][0], x[i][1], x[i][2], x[i][3]);
    }
}

The Rprintf statements display what's going on at each step. It looks 
for all the world as if the assignments are working properly, but when I 
try and print the matrix I get very strange results. If mat is 3x3 or 
4x4 everything seems ok. But if mat is not symetrical the resulting x 
matrix is very strange. In the case of a 5x4 mat only the first column 
works out, and for 3x4 mat the second and third positions in the first 
column are replaced by the first and second positions of the last 
column. I'm guessing that I've messed up something in my use of 
pointers, or perhaps the for loop, but I can't for the life of me figure 
out what!! Once I sort this out I'll be calculating the differences 
between rows in the x array en route to producing a similarity matrix. I 
looked at the vegdist code, which is fancier than this, and  manages to 
avoid rebuilding the matrix entirely, but it's a bit beyond me.

I'm using WindowsXP, R 2.1.0  (2005-04-18), and the MinGW compiler.

Thanks for your continued patience,

Tyler

-- 
Tyler Smith

PhD Candidate
Department of Plant Science
McGill University
21,111 Lakeshore Road
Ste. Anne de Bellevue, Quebec
H9X 3V9
CANADA

Tel: 514 398-7851 ext. 8726
Fax: 514 398-7897

tyler.smith@mail.mcgill.ca

______________________________________________
R-help@stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

From dmb at mrc-dunn.cam.ac.uk  Thu Apr 28 00:48:05 2005
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Thu Apr 28 00:48:08 2005
Subject: [Rd] Re: [Filtered!] Re: [R] postscript (eps) / latex /
 par(mfg=...) / problem!
In-Reply-To: <1114556859.8390.108.camel@horizons.localdomain>
Message-ID: <Pine.LNX.4.21.0504272347300.9191-100000@mail.mrc-dunn.cam.ac.uk>

On Tue, 26 Apr 2005, Marc Schwartz wrote:

>Warning: This message has had one or more attachments removed
>Warning: (x.mfg.eps).
>Warning: Please read the "FilterNotice.txt" attachment(s) for more information.
>
>[MOVED TO R-DEVEL]
>
>On Tue, 2005-04-26 at 18:05 +0100, Dan Bolser wrote:
>> Should I post this to 'bugs'?
>
>Dan,
>
>I suspect part of the problem here is that your code and example were
>difficult to replicate and there may have been a focus on the page
>rotation issue, which I think is a red herring here.
>
>All below is done with Version 2.1.0 Patched (2005-04-20), which is more
>recent of course and may reflect an existing problem when using par
>("mfg").
>
>
>mat <- matrix(c(1:14, 16, 20, 23, 24, 26, 28,
>         886, 792, 136, 201, 16, 58, 6,
>         21, 3, 9, 3, 9, 1, 4, 3, 1, 1,
>         1, 1, 1), ncol = 2)
>
>colnames(mat) <- c("CHAINS", "FREQUENCY")
>
># Use either the EPS or PDF creation here
># Naming the output file based upon the use or non-use
># of par("mfg")
>
># Comment the two par("mfg") lines below as appropriate
>
>
>postscript("x.mfg.eps", width = 6, height = 6,
>           horizontal = FALSE, onefile = FALSE,
>           paper = "special")
>
># pdf("nomfg.pdf", width = 5, height = 6)
>    
>par(mfrow= c(2, 1))
>
>par(mfg = c(1, 1))
>par(mar = c(3, 4, 1, 2))
>plot(mat, type = "b")
>
>par(mfg = c(2, 1))
>par(mar = c(4, 4, 0, 2))
>plot(mat, type = "b", log = "y")
>
>dev.off()
>
>
>What I found, if correct, does not reflect rotation issues with the
>graphic, but a problem when using par("mfg"), resulting in both EPS and
>PDF files having a 0 page indication in the resultant file. I have
>attached EPS and PDF files here named based upon using or not using par
>("mfg").
>
>I also used the following LaTeX code to create PS/PDF files as
>appropriate with curious results. Modify the included graphic file name
>as appropriate when using it:
>
>\documentclass{report}
>\usepackage{graphicx}
>\begin{document}
>\begin{figure}
>  \centering
>  \includegraphics[width=\textwidth]{x.mfg.eps}
>  \caption[X]{Hello!}
>  \label{xFig}
>\end{figure}
>\end{document}
>
>
>When using latex and dvips with the x.mfg.eps file, the plot is in the
>upper left hand corner of the page, very small. Substituting the
>x.nomfg.eps file, the page looks fine.
>
>
>When using pdflatex with the mfg.pdf file, get the following error:
>
>Error: pdflatex (file mfg.pdf): pdf inclusion: required page does not
>exist <0>
>
> ==> Fatal error occurred, the output PDF file is not finished!
>
>
>Trying to open the mfg.pdf file, I get errors from multiple PDF viewers
>indicating the lack of pages in the file.
>
>Interestingly, when opening the EPS files in gv, it seems to happily
>ignore the 0 page issue and displays the x.mfg.eps file without problem.
>
>
>There are a few other posts in the archive that report problems that
>were presumed to be the usual rotation issues that Ted refers to in his
>reply post on r-help.
>
>However, when reading them:
>
>http://tolstoy.newcastle.edu.au/R/devel/04a/0344.html
>
>http://finzi.psych.upenn.edu/R/Rhelp02a/archive/25436.html
>
>in both cases, par("mfg") is being used, which is common to Dan's
>problem here.
>
>So, unless I am missing something and without yet delving further into
>graphic device specific source code, I suspect that there is a problem
>when creating PS/EPS/PDF files in conjunction with par("mfg").

Yup! I created a bug so hopefully its safely logged (described) now?

Cheers,
Dan.

>
>HTH,
>
>Marc Schwartz
>
>

From MSchwartz at MedAnalytics.com  Thu Apr 28 01:57:33 2005
From: MSchwartz at MedAnalytics.com (MSchwartz@MedAnalytics.com)
Date: Thu Apr 28 01:58:29 2005
Subject: [Rd] Re: postscript (eps) / latex / par(mfg=...) / problem!
	(PR#7820)
Message-ID: <20050427235733.11B2984C9@slim.kubism.ku.dk>

Just for the sake of linkage and further information, a related post to
this bug is on r-devel at:

https://stat.ethz.ch/pipermail/r-devel/2005-April/033016.html

Marc Schwartz

From MSchwartz at MedAnalytics.com  Thu Apr 28 02:04:44 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu Apr 28 02:05:00 2005
Subject: [Rd] Re: [Filtered!] Re: [R] postscript (eps) / latex /
	par(mfg=...) / problem!
In-Reply-To: <Pine.LNX.4.21.0504272347300.9191-100000@mail.mrc-dunn.cam.ac.uk>
References: <Pine.LNX.4.21.0504272347300.9191-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <1114646684.650.81.camel@horizons.localdomain>

On Wed, 2005-04-27 at 23:48 +0100, Dan Bolser wrote:
> On Tue, 26 Apr 2005, Marc Schwartz wrote:

> >So, unless I am missing something and without yet delving further into
> >graphic device specific source code, I suspect that there is a problem
> >when creating PS/EPS/PDF files in conjunction with par("mfg").
> 
> Yup! I created a bug so hopefully its safely logged (described) now?

OK. I just posted a follow up to your bug report with a link to my post
on r-devel to provide further info and sample graphic files.

I suspect we'll need help from R Core on this one. If this is confirmed
as a bug, this is getting to the periphery of my low level graphic
device knowledge.

Marc

From john.maindonald at anu.edu.au  Thu Apr 28 02:54:18 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu Apr 28 02:56:06 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <17007.45054.561976.705623@stat.math.ethz.ch>
References: <200504251000.j3PA01lD009332@hypatia.math.ethz.ch>
	<40567787fcb17bee0bf9ecf403fb8e21@anu.edu.au>
	<320af97cfe90da4c59b7e9c8cd9956d4@anu.edu.au>
	<9717926f912f9fb045c57dd9be4e743c@warwick.ac.uk>
	<b21d1d1a13e8f82d4e1d44c233e9f76e@anu.edu.au>
	<17006.5202.986122.321760@stat.math.ethz.ch>
	<17007.39440.105964.263932@stat.math.ethz.ch>
	<x2zmvkz2wl.fsf@biostat.ku.dk>
	<17007.45054.561976.705623@stat.math.ethz.ch>
Message-ID: <3251b0dcc594874d43240a966355b002@anu.edu.au>


On 28 Apr 2005, at 1:30 AM, Martin Maechler wrote:

>>>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
>>>>>>     on 27 Apr 2005 16:54:02 +0200 writes:
>
>     PD> Martin Maechler <maechler@stat.math.ethz.ch> writes:
>>> I'm about to commit the current proposal(s) to R-devel,
>>> **INCLUDING** changing the default from
>>> 'which = 1:4' to 'which = c(1:3,5)
>>>
>>> and ellicit feedback starting from there.
>>>
>>> One thing I think I would like is to use color for the Cook's
>>> contours in the new 4th plot.
>
>     PD> Hmm. First try running example(plot.lm) with the modified 
> function and
>     PD> tell me which observation has the largest Cook's D. With the 
> suggested
>     PD> new 4th plot it is very hard to tell whether obs #49 is 
> potentially or
>     PD> actually influential. Plots #1 and #3 are very close to 
> conveying the
>     PD> same information though...
>
> I shouldn't be teaching here, and I know that I'm getting into fighted
> territory (regression diagnostics; robustness; "The" Truth, etc,etc)
> but I believe there is no unique way to define "actually influential"
> (hence I don't believe that it's extremely useful to know
> exactly which Cook's D is largest).
>
> Partly because there are many statistics that can be derived from a
> multiple regression fit all of which are influenced in some way.
> AFAIK, all observation-influence measures g(i) are functions of
> (r_i, h_{ii}) and the latter are the quantities that "regression
> users" should really know {without consulting a text book} and
> that are generalizable {e.g. to "linear smoothers" such as
> gam()s (for "non-estimated" smoothing parameter)}.
>
> Martin

I agree with Martin.  I like the idea of using color (red?) for
the new Cook's contours.  People who want (fairly) precise
comparisons of the Cook's statistics can still use the present
plot #4, perhaps as a follow-up to the new plot #5.
It would be possible to label the Cookwise most extreme
points with the actual values (to perhaps 2sig figures, i.e.,
labeling on both sides of such points), but this would add
what I consider is unnecessary clutter to the graph.

John.

John Maindonald             email: john.maindonald@anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

From ripley at stats.ox.ac.uk  Thu Apr 28 08:30:56 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Apr 28 08:31:14 2005
Subject: [Rd] Bug in Version 2010 (PR#7807)
Message-ID: <20050428063056.449A3A21D@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-697381171-1114669841=:21056
Content-Type: TEXT/PLAIN; charset=iso-8859-1; format=flowed
Content-Transfer-Encoding: QUOTED-PRINTABLE

Looks like gettext cannot handle strings with embedded nulls.

I'll remove all such from translation.

On Fri, 22 Apr 2005 ligges@statistik.uni-dortmund.de wrote:

> ligges@statistik.uni-dortmund.de wrote:
>
>> Duncan Murdoch wrote:
>>
>>
>>> mbreuer@ecology.uni-kiel.de wrote:
>>>
>>>
>>>> Dr. Michael
>>>> Breuer
>>>> 22.04.05
>>>> =D6kologiezentrum der Universit=E4t Kiel
>>>> Olshausenstra=DFe 75
>>>> 24118 Kiel
>>>>
>>>> Dear Ladies and Sirs,
>>>> After updating the R-Windows-program (binary) by the latest version
>>>> (2010), the R-Scripts that I want to execute are not shown in the
>>>> File-Window anymore. In the former version it worked correct.
>>>> However, if I call a script by command line, it will be found and
>>>> intepreted. I tried it on two PCs wirh Windows XP Home and Windows XP
>>>> Professional SP2.
>>>
>>>
>>>
>>> This is not enough information to allow us to try to duplicate your
>>> error.  Tell us where you keep your scripts, how you start R (the
>>> starting directory is likely important), and the exact steps you take t=
o
>>> try to show your scripts.  Without that information your report is too
>>> vague to act on.
>>>
>>> Duncan Murdoch
>>
>>
>>
>> Looks like it happens with the german (and maybe also other?)
>> translation. I'll take a closer look later.
>>
>> Uwe Ligges
>
> Indeed, if you set LANGUAGE=3Dde using the RGui-de.po as shipped with
> R-2.1.0, you won't see any files in that dialog. If you copy the english
> version to the translation, you see ALL files (not only R files as
> expected), and if you leave the translation blank (i.e. the english
> version will be displayed), you get the expected behaviour.
>
> I guess lines such as
>
>     setuserfilter(G_("R files (*.R)\0*.R\0S files (*.q)\0*.q\0All files
> (*.*)\0*.*\0\0"));
>
> in rui.c are casuing the trouble. "S files (*.q)" never appears in the
> *.po(t) file, so it's probably a gettext related problem, but I really
> don't know how to fix this ...
>
>
> Uwe Ligges
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

--=20
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-697381171-1114669841=:21056--

From jfox at mcmaster.ca  Thu Apr 28 14:39:04 2005
From: jfox at mcmaster.ca (John Fox)
Date: Thu Apr 28 14:39:19 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <3251b0dcc594874d43240a966355b002@anu.edu.au>
Message-ID: <20050428123902.YKFW26102.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear John et al.,

Curiously, Georges Monette (at York University in Toronto) and I were just
talking last week about influence-statistic contours, and I wrote a couple
of functions to show these for Cook's D and for covratio as functions of
hat-values and studentized residuals. These differ a bit from the ones
previously discussed here in that they show rule-of-thumb cut-offs for D and
covratio, along with Bonferroni critical values for studentized residuals. 

I've attached a file with these functions, even though they're not that
polished.

More generally, I wonder whether it's not best to supply plots like these as
separate functions rather than as a do-it-all plot method for lm objects.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of John 
> Maindonald
> Sent: Wednesday, April 27, 2005 7:54 PM
> To: Martin Maechler
> Cc: David Firth; Werner Stahel; r-devel@stat.math.ethz.ch; 
> Peter Dalgaard
> Subject: Re: [Rd] Enhanced version of plot.lm()
> 
> 
> On 28 Apr 2005, at 1:30 AM, Martin Maechler wrote:
> 
> >>>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
> >>>>>>     on 27 Apr 2005 16:54:02 +0200 writes:
> >
> >     PD> Martin Maechler <maechler@stat.math.ethz.ch> writes:
> >>> I'm about to commit the current proposal(s) to R-devel,
> >>> **INCLUDING** changing the default from 'which = 1:4' to 'which = 
> >>> c(1:3,5)
> >>>
> >>> and ellicit feedback starting from there.
> >>>
> >>> One thing I think I would like is to use color for the Cook's 
> >>> contours in the new 4th plot.
> >
> >     PD> Hmm. First try running example(plot.lm) with the modified 
> > function and
> >     PD> tell me which observation has the largest Cook's D. 
> With the 
> > suggested
> >     PD> new 4th plot it is very hard to tell whether obs #49 is 
> > potentially or
> >     PD> actually influential. Plots #1 and #3 are very close to 
> > conveying the
> >     PD> same information though...
> >
> > I shouldn't be teaching here, and I know that I'm getting 
> into fighted 
> > territory (regression diagnostics; robustness; "The" Truth, 
> etc,etc) 
> > but I believe there is no unique way to define "actually 
> influential"
> > (hence I don't believe that it's extremely useful to know exactly 
> > which Cook's D is largest).
> >
> > Partly because there are many statistics that can be derived from a 
> > multiple regression fit all of which are influenced in some way.
> > AFAIK, all observation-influence measures g(i) are 
> functions of (r_i, 
> > h_{ii}) and the latter are the quantities that "regression users" 
> > should really know {without consulting a text book} and that are 
> > generalizable {e.g. to "linear smoothers" such as gam()s (for 
> > "non-estimated" smoothing parameter)}.
> >
> > Martin
> 
> I agree with Martin.  I like the idea of using color (red?) 
> for the new Cook's contours.  People who want (fairly) 
> precise comparisons of the Cook's statistics can still use 
> the present plot #4, perhaps as a follow-up to the new plot #5.
> It would be possible to label the Cookwise most extreme 
> points with the actual values (to perhaps 2sig figures, i.e., 
> labeling on both sides of such points), but this would add 
> what I consider is unnecessary clutter to the graph.
> 
> John.
> 
> John Maindonald             email: john.maindonald@anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Bioinformation Science, Room 1194, John Dedman 
> Mathematical Sciences Building (Building 27) Australian 
> National University, Canberra ACT 0200.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
From alexander_schinner at genua.de  Thu Apr 28 16:01:31 2005
From: alexander_schinner at genua.de (Alexander Schinner)
Date: Thu Apr 28 16:01:43 2005
Subject: [Rd] C Interface to R? New question
Message-ID: <200504281601.31088.alexander_schinner@genua.de>

Hi,

thanks for your help by pointing to the correct documentation and 
tests/Embedding from 2.1.0. Using this information, I could realize most of 
the work, I wanted to accomplish. Still, one problem is remaining.

In principle, I whould like to do

> dim(matrix) 
[1] 100   3
> matrix[,3] 
 [1] 201 202 203 ......

But how do I use the [ function from C? From the manual, I learned, that the 
missing value before the "," is an empty list, but how to make one? 

I tried something like

  R_result = getListElement(R_stl_y, "time.series");

  PROTECT(Rc_bracket = allocVector(LANGSXP, 4));
  SETCAR(Rc_bracket, Rf_findFun(Rf_install("["), R_GlobalEnv));
  SETCAR(CDR(Rc_bracket), R_result);

#if 1
  PROTECT(R_tmp = NEW_INTEGER(0));
  SETCAR(CDDR(Rc_bracket),  R_tmp);
#endif

#if 0  
  PROTECT(R_tmp = allocVector(INTSXP, 0)); 
  SETCAR(CDDR(Rc_bracket),  R_tmp);
#endif

#if 0  
 SETCAR(CDDR(Rc_bracket),  R_NilValue);
#endif

#if 0  
 SETCAR(CDDR(Rc_bracket),  R_NilValue);
#endif

  PROTECT(R_tmp = NEW_INTEGER(1));
  INTEGER_DATA(R_tmp)[0] = 1; 
  SETCAR(CDR(CDR(CDR(Rc_bracket))), R_tmp);

  PROTECT(R_remainder = Test_tryEval(Rc_bracket, &hadError));
 
but I always failed. So, How do I correctly call the [ function? How learn 
from the source, which parameter has which function? And How do I generate an 
empty vector/list?

Thanks,
Alexander Schinner

From iGMailer at mailserver-55.ig.com.br  Thu Apr 28 18:55:50 2005
From: iGMailer at mailserver-55.ig.com.br (iGMailer@mailserver-55.ig.com.br)
Date: Thu Apr 28 19:16:27 2005
Subject: [Rd] =?iso-8859-1?q?Sua_mensagem_n=E3o_pode_ser_entregue?=
Message-ID: <200504281716.j3SHGDOf015401@hypatia.math.ethz.ch>

ESTE EMAIL ? AUTOM?TICO.
POR FAVOR, N?O ENVIE UMA REPOSTA, POIS ELA N?O SER? RECEBIDA.

N?o foi poss?vel entregar a sua mensagem.
O destinat?rio n?o recebeu a sua mensagem. Veja a seguir a descri??o do
motivo.


<steve@ig.com.br>:
A caixa postal do destinat?rio excedeu o limite de capacidade de armazenamento.
maildrop: maildir over quota.

--- Below this line is a copy of the message.

Return-Path: <r-devel@r-project.org>
Received: (qmail 29672 invoked from network); 28 Apr 2005 16:43:04 -0000
Received: from unknown ([10.20.1.83])
          (envelope-sender <>)
          by mailserver-55.ig.com.br (qmail-ldap-1.03) with QMQP
          for <>; 28 Apr 2005 16:43:05 -0000
Delivered-To: CLUSTERHOST email-83.ig.com.br steve@ig.com.br
Received: (qmail 12734 invoked from network); 28 Apr 2005 16:36:04 -0000
Received: from micro-170-236.ensp.fiocruz.br (HELO r-project.org) ([157.86.170.236])
          (envelope-sender <r-devel@r-project.org>)
          by email-83.ig.com.br (qmail-ldap-1.03) with SMTP
          for <steve@ig.com.br>; 28 Apr 2005 16:36:04 -0000
Received-SPF: none (email-83.ig.com.br: domain at r-project.org does not designate permitted sender hosts)
From: r-devel@r-project.org
To: steve@ig.com.br
Subject: DUVIDO VOCE ME RECONHER =)
Date: Thu, 28 Apr 2005 13:35:45 -0300
MIME-Version: 1.0
Content-Type: multipart/mixed;
	boundary="----=_NextPart_000_0006_D3A6F4A3.8A93A785"
X-Priority: 3
X-MSMail-Priority: Normal
X-iGspam-global: Yes, spamicity=0.856071 - pe=8.56e-01 - pf=0.856071 - pg=0.856071

This is a multi-part message in MIME format.

------=_NextPart_000_0006_D3A6F4A3.8A93A785
Content-Type: text/plain;
	charset="Windows-1252"
Content-Transfer-Encoding: 7bit

-:????p^???<?{5?;??H?????{]?!?]???B????n??OOY??^a4?Po?_
Z???????&???93w8??lRD9?z?x?k
?r%
Qo,????9??fE? ??d?N4????iCr???(?C??????e
????M?]??<H?r3~o????j^??W???LO??????/KbqwNql{>??????u?s uIf???6a?
??y???HN2??i?r?J?{???????\>?HtY|x?R???"96dV:??v??/V?[%
???????????????#?!2?!??????2L???f?1???w?A??0??fuM???{L?%J???
Q????p6<?
?Y??a?IXu]hHe?x?????
\d1u??x???????
?8?I????K?atX?q???????
?h?/?~3HI????,\
^?h|\l<g????w/???
??R???&???????v>?1J?H$?,K?>
?M????ld"/:$j?W????:6v??
0xX
j????$?
-???>l7i?J?g????,??q}
x?l?H?-??U
??I?G<5????P????x?,pW?a
?????<?4d???8~r??7?????(?&??.
???m?:?????]Pq?x??
???Q?????
 
???-~&??_:?}??YG?e???9?8?'??Z~????b.????Q?????CaL.???????n??ZnB?g?fu'??
?)???Gr8iW??
?E?`hQ|?%LZ?????k#???)o??:???&??O?
]?*??
P?n?????m?P???(s?-~WA?????a??C?*?8Q7eS???s0q?????X??X
??2? z,?-??1r????7????`??QJ???^zxS??_?}*?W7???]?
:
/cP??^d???????gE??????G??7?
V."Q?U?$?}???:??'?3
9?|U)??WE?
???7


------=_NextPart_000_0006_D3A6F4A3.8A93A785
Content-Type: application/octet-stream;
	name="fotos.zip"
Content-Transfer-Encoding: base64
Content-Disposition: attachment;
	filename="fotos.zip"
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--- End of message stripped.

From murdoch at stats.uwo.ca  Thu Apr 28 20:04:22 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu Apr 28 20:03:56 2005
Subject: [Rd] Re: [R] strange behaviour of importFrom directive in name space
In-Reply-To: <1114696405.11517.68.camel@perro.inet.dkfz-heidelberg.de>
References: <1114696405.11517.68.camel@perro.inet.dkfz-heidelberg.de>
Message-ID: <427125A6.2040406@stats.uwo.ca>

This is really an R-devel question, and I've moved it there.

Florian Hahne wrote:
> Dear listers,
> After activating the name space for my bioconductor package (prada) I
> successfully ran R CMD check. However when loading the package in R and
> running the examples the imported function brewer.pal from package
> RColorBrewer is not found. I can directly call brewer.pal from the
> RColorBrewer name space typing RColorBrewer::brewer.pal, but it is not
> imported into my prada name space. When I attach RColorBrewer, the
> example runs fine. For several other function from different packages
> the import works without problems.
> I'm quite puzzled how this import can work with R CMD check but not when
> attaching the package in a "regular" R session. And if the importFrom
> directive was corrupted, shouldn't there be an error message?
> This is not realy a problem, since I can load RColorBrewer by putting it
> into the dependent field in my DESCRIPTION file as I did before, but
> none the less I wanted to mention this strange behaviour. Could it be a
> bug?

Could you be more specific about the bug?  Which example fails?  Is it 
run by the R CMD check tests?

Generally, I wouldn't expect "importFrom" to be sufficient to make an 
example using the import work, either during Rcmd CHECK or in the 
console.  It makes the import available from within your package, but 
examples are run in the global environment.

Duncan Murdoch

> Regards,   
> Florian
> 
> Here is my NAMESPACE file:
> export("analysePlate", "as.all",
>        "barploterrbar", "combineFrames",
>        "csApply", "ddCt",
>        "densCols", "eListWrite",
>        "fitNorm2", "getPradaPar",
>        "histStack", "plotNorm2",
>        "plotPlate", "readCytoSet",
>        "readFCS", "readSDM",
>        "removeCensored", "setPradaPars",
>        "smoothScatter", "thresholds")
> 
> 
> importFrom("KernSmooth", "bkde2D")
> importFrom("RColorBrewer", "brewer.pal")
> importFrom("utils", "getFromNamespace", "assignInNamespace")
> importFrom("MASS", "cov.rob") 
> S3method("$", "cytoFrame")
> exportClasses("cytoFrame", "cytoSet")
> exportMethods("colnames", "colnames<-",
>               "description", "description<-",
>               "exprs", "exprs<-",
>               "length", "[", "[[", "[[<-",
>               "pData", "phenoData", "phenoData<-",
>               "show")
> 
> System:
> R 2.1.0 on Suse9.2 Linux box
> 
>

From rich.fitzjohn at gmail.com  Thu Apr 28 23:08:38 2005
From: rich.fitzjohn at gmail.com (rich.fitzjohn@gmail.com)
Date: Thu Apr 28 23:08:46 2005
Subject: [Rd] Rgui crash when >1 figure plotted to single wmf file (PR#7821)
Message-ID: <20050428210838.6A2BAA1E2@slim.kubism.ku.dk>

Hi,

R for Windows crashes where more than one plot is plotted to a windows
metafile where an integer format is not included in the character
string (i.e. when attempting to write more than one plot to the same
file).

win.metafile("tmp.wmf")
plot(1:10)
plot(1:10)

The following dialogues then come up:

Unable to create metafile

Program Error: Rgui.exe has generated errors and will be closed by
Windows.  You will need to restart the program.  An error log is being
created.

And R closes.  (This happens with both Rgui and Rterm).

As well as this current box, this crash also occurs on my Windows 98
box (R 2.1.0), and R 2.0.0 on Windows 2000.

This problem does not seem to happen for other graphics file devices
(png, bmp, jpeg).

R also does not crash when writing a metafile to the clipboard (where
filename is ""):
> win.metafile()
> plot(1:10)
> plot(1:10)
Error in plot.new() : A clipboard metafile can store only one figure.

The DrWatson error log contains a stack trace from the crash; not sure
if this is any use:
FramePtr ReturnAd Param#1  Param#2  Param#3  Param#4  Function Name
0022E638 1015FD10 0000037F 400F037F 037F0F7F 00000001 ntdll!DbgBreakPoint 
0022E658 0229247D 00000000 00000049 00000049 00000233 !gsetcliprect 
0022E6C8 1006E9E2 F9F2700C 4057A5EC 2C53EC28 40819342 !PDF 
0022E768 10070315 F9F2700C 4057A5EC 2C53EC28 40819342 !GECircle 
0022E958 100920A6 F9F2700C 4057A5EC 2C53EC28 40819342 !GESymbol 
0022EA38 100BF1B8 F9F2700C 4057A5EC 2C53EC28 40819342 !Rf_GSymbol 
0022EBA8 100A4AA1 0253FBAC 017E542C 02419DAC 02419D3C !do_plot_xy 
0022EBE8 10080C5A 0253FB74 017D7324 0253FB90 02419D3C !do_internal 
0022ECE8 100826D5 0253FB74 02419D3C 0022ED18 10073411 !Rf_eval 
0022ED18 10080C5A 0253FB3C 017D6074 0253FB58 02419D3C !do_begin 
0022EE18 100838AB 0253FB3C 02419D3C 024F7F68 02419D3C !Rf_eval 
0022EF08 100809F0 024F7F68 02540520 0241CF9C 0242FA0C !Rf_applyClosure 
0022F008 100826D5 024F7F68 0242FA0C 0022F038 10073411 !Rf_eval 
0022F038 10080C5A 024F6E40 017D6074 024F6E24 0242FA0C !do_begin 
0022F138 100838AB 024F6E40 0242FA0C 0242F478 0242FA0C !Rf_eval 
0022F228 100A4FC1 0242F478 024F44C0 0243069C 02430798 !Rf_applyClosure 
0022F278 100A5605 0243069C 02430798 0242F424 023D25B8 !do_internal 
0022F4C8 100A5A7A 0260D6F8 017FA400 02665880 017CB3A0 !Rf_usemethod 
0022F508 10080C5A 02665880 017E6880 02665848 02430798 !do_usemethod 
0022F608 10080C5A 02665880 02430798 026644F0 02430798 !Rf_eval 
0022F708 100826D5 0266450C 02430798 0022F738 10073411 !Rf_eval 
0022F738 10080C5A 02664544 017D6074 02664528 02430798 !do_begin 
0022F838 100838AB 02664544 02430798 02430648 02430798 !Rf_eval 
0022F928 100809F0 02430648 026639D8 0243069C 017E89FC !Rf_applyClosure 
0022FA28 10099246 02430648 017E89FC 0022FA70 00000001 !Rf_eval 
0022FA58 10099377 017E89FC 00000000 00000000 0022FA70 !Rf_ReplIteration 
0022FEA8 100995F7 00000000 00404010 0022FED8 0040135A !Rf_ReplIteration 
0022FEB8 0040135A 00000000 004723F0 00000000 00472400 !run_Rmainloop 
0022FED8 004012C5 00000001 004723F0 00000001 7C5C1F44 !<nosymbols> 
0022FEF8 0040151A 00400000 00000000 00232439 00000001 !<nosymbols> 
0022FF78 004011E7 00000001 004723F0 00472C78 00404000 !<nosymbols> 
0022FFB0 00401258 00000002 00000009 0022FFF0 7C59893D !<nosymbols> 
0022FFC0 7C59893D 00000000 00000000 7FFDF000 80000003 !<nosymbols> 
0022FFF0 00000000 00401240 00000000 000000C8 00000100
kernel32!ProcessIdToSessionId

Thanks,
Rich

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 1.0
 year = 2005
 month = 04
 day = 18
 language = R

Windows 2000 Professional (build 2195) Service Pack 4.0

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics,
package:grDevices, package:utils, package:datasets, Autoloads,
package:base

-- 
Rich FitzJohn
rich.fitzjohn <at> gmail.com   |    http://homepages.paradise.net.nz/richa183
                      You are in a maze of twisty little functions, all alike

From john.maindonald at anu.edu.au  Fri Apr 29 01:46:59 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri Apr 29 01:48:48 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <20050428123902.YKFW26102.tomts10-srv.bellnexxia.net@JohnDesktop8300>
References: <20050428123902.YKFW26102.tomts10-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <c10c38030e1ff62a6c031f0ad6b38c29@anu.edu.au>

NB also the mention of a possible addition to stats: vif()

Dear John -
I think users can cope with six plots offered by one function,
with four of them given by default, and the two remaining
plots alternative ways of presenting the information in the
final default plot.  The idea of plot.lm() was to provide a
set of plots that would serve most basic purposes.

It may be reasonable to have a suite of plots for
examining residuals and influence.  I'd suggest
trying to follow the syntax and labeling conventions
as for plot.lm(), unless these seem inappropriate.

While on such matters, there is a function vif() in DAAG,
and a more comprehensive function vif() in car.  One of
these, probably yours if you are willing, should go into
stats.  There's one addition that I'd make; allow a model
matrix as parameter, as an optional alternative to giving
the model object.
Regards
John M.

On 28 Apr 2005, at 10:39 PM, John Fox wrote:

> Dear John et al.,
>
> Curiously, Georges Monette (at York University in Toronto) and I were 
> just
> talking last week about influence-statistic contours, and I wrote a 
> couple
> of functions to show these for Cook's D and for covratio as functions 
> of
> hat-values and studentized residuals. These differ a bit from the ones
> previously discussed here in that they show rule-of-thumb cut-offs for 
> D and
> covratio, along with Bonferroni critical values for studentized 
> residuals.
>
> I've attached a file with these functions, even though they're not that
> polished.
>
> More generally, I wonder whether it's not best to supply plots like 
> these as
> separate functions rather than as a do-it-all plot method for lm 
> objects.
>
> Regards,
>  John
>
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox
> --------------------------------
>
>> -----Original Message-----
>> From: r-devel-bounces@stat.math.ethz.ch
>> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of John
>> Maindonald
>> Sent: Wednesday, April 27, 2005 7:54 PM
>> To: Martin Maechler
>> Cc: David Firth; Werner Stahel; r-devel@stat.math.ethz.ch;
>> Peter Dalgaard
>> Subject: Re: [Rd] Enhanced version of plot.lm()
>>
>>
>> On 28 Apr 2005, at 1:30 AM, Martin Maechler wrote:
>>
>>>>>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
>>>>>>>>     on 27 Apr 2005 16:54:02 +0200 writes:
>>>
>>>     PD> Martin Maechler <maechler@stat.math.ethz.ch> writes:
>>>>> I'm about to commit the current proposal(s) to R-devel,
>>>>> **INCLUDING** changing the default from 'which = 1:4' to 'which =
>>>>> c(1:3,5)
>>>>>
>>>>> and ellicit feedback starting from there.
>>>>>
>>>>> One thing I think I would like is to use color for the Cook's
>>>>> contours in the new 4th plot.
>>>
>>>     PD> Hmm. First try running example(plot.lm) with the modified
>>> function and
>>>     PD> tell me which observation has the largest Cook's D.
>> With the
>>> suggested
>>>     PD> new 4th plot it is very hard to tell whether obs #49 is
>>> potentially or
>>>     PD> actually influential. Plots #1 and #3 are very close to
>>> conveying the
>>>     PD> same information though...
>>>
>>> I shouldn't be teaching here, and I know that I'm getting
>> into fighted
>>> territory (regression diagnostics; robustness; "The" Truth,
>> etc,etc)
>>> but I believe there is no unique way to define "actually
>> influential"
>>> (hence I don't believe that it's extremely useful to know exactly
>>> which Cook's D is largest).
>>>
>>> Partly because there are many statistics that can be derived from a
>>> multiple regression fit all of which are influenced in some way.
>>> AFAIK, all observation-influence measures g(i) are
>> functions of (r_i,
>>> h_{ii}) and the latter are the quantities that "regression users"
>>> should really know {without consulting a text book} and that are
>>> generalizable {e.g. to "linear smoothers" such as gam()s (for
>>> "non-estimated" smoothing parameter)}.
>>>
>>> Martin
>>
>> I agree with Martin.  I like the idea of using color (red?)
>> for the new Cook's contours.  People who want (fairly)
>> precise comparisons of the Cook's statistics can still use
>> the present plot #4, perhaps as a follow-up to the new plot #5.
>> It would be possible to label the Cookwise most extreme
>> points with the actual values (to perhaps 2sig figures, i.e.,
>> labeling on both sides of such points), but this would add
>> what I consider is unnecessary clutter to the graph.
>>
>> John.
>>
>> John Maindonald             email: john.maindonald@anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Bioinformation Science, Room 1194, John Dedman
>> Mathematical Sciences Building (Building 27) Australian
>> National University, Canberra ACT 0200.
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> <influence-plots.R>
John Maindonald             email: john.maindonald@anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

From jfox at mcmaster.ca  Fri Apr 29 02:08:43 2005
From: jfox at mcmaster.ca (John Fox)
Date: Fri Apr 29 02:08:57 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <c10c38030e1ff62a6c031f0ad6b38c29@anu.edu.au>
Message-ID: <20050429000841.KZUW21470.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear John


> -----Original Message-----
> From: John Maindonald [mailto:john.maindonald@anu.edu.au] 
> Sent: Thursday, April 28, 2005 6:47 PM
> To: John Fox
> Cc: 'Werner Stahel'; 'Peter Dalgaard'; 
> <r-devel@stat.math.ethz.ch>; 'David Firth'; 'Martin Maechler'
> Subject: Re: [Rd] Enhanced version of plot.lm()
> 
> NB also the mention of a possible addition to stats: vif()
> 
> Dear John -
> I think users can cope with six plots offered by one 
> function, with four of them given by default, and the two 
> remaining plots alternative ways of presenting the 
> information in the final default plot.  The idea of plot.lm() 
> was to provide a set of plots that would serve most basic purposes.
> 

I rather like added-variable plots for examining influence and leverage on
coefficients.

> It may be reasonable to have a suite of plots for examining 
> residuals and influence.  I'd suggest trying to follow the 
> syntax and labeling conventions as for plot.lm(), unless 
> these seem inappropriate.
> 

I don't have strong feelings about this -- I certainly don't think that the
suggestion is inappropriate.

> While on such matters, there is a function vif() in DAAG, and 
> a more comprehensive function vif() in car.  One of these, 
> probably yours if you are willing, should go into stats.  

I'd have no objection to that.

> There's one addition that I'd make; allow a model matrix as 
> parameter, as an optional alternative to giving the model object.

That seems reasonable -- for linear models, anyway. The current approach
works (at least arguably) for generalized linear models as well. My only
hesitation is that having just the model matrix doesn't insure that the
model is a linear model. With this caveat, I should be able to handle model
matrices by adding a matrix method to vif (and perhaps printing a warning).
I'll probably do that when I next revise the car package.

Thanks for the suggestion.
 John

> Regards
> John M.
> 
> On 28 Apr 2005, at 10:39 PM, John Fox wrote:
> 
> > Dear John et al.,
> >
> > Curiously, Georges Monette (at York University in Toronto) 
> and I were 
> > just talking last week about influence-statistic contours, 
> and I wrote 
> > a couple of functions to show these for Cook's D and for 
> covratio as 
> > functions of hat-values and studentized residuals. These 
> differ a bit 
> > from the ones previously discussed here in that they show 
> > rule-of-thumb cut-offs for D and covratio, along with Bonferroni 
> > critical values for studentized residuals.
> >
> > I've attached a file with these functions, even though they're not 
> > that polished.
> >
> > More generally, I wonder whether it's not best to supply plots like 
> > these as separate functions rather than as a do-it-all plot 
> method for 
> > lm objects.
> >
> > Regards,
> >  John
> >
> > --------------------------------
> > John Fox
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > 905-525-9140x23604
> > http://socserv.mcmaster.ca/jfox
> > --------------------------------
> >
> >> -----Original Message-----
> >> From: r-devel-bounces@stat.math.ethz.ch 
> >> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of John 
> >> Maindonald
> >> Sent: Wednesday, April 27, 2005 7:54 PM
> >> To: Martin Maechler
> >> Cc: David Firth; Werner Stahel; r-devel@stat.math.ethz.ch; Peter 
> >> Dalgaard
> >> Subject: Re: [Rd] Enhanced version of plot.lm()
> >>
> >>
> >> On 28 Apr 2005, at 1:30 AM, Martin Maechler wrote:
> >>
> >>>>>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
> >>>>>>>>     on 27 Apr 2005 16:54:02 +0200 writes:
> >>>
> >>>     PD> Martin Maechler <maechler@stat.math.ethz.ch> writes:
> >>>>> I'm about to commit the current proposal(s) to R-devel,
> >>>>> **INCLUDING** changing the default from 'which = 1:4' 
> to 'which =
> >>>>> c(1:3,5)
> >>>>>
> >>>>> and ellicit feedback starting from there.
> >>>>>
> >>>>> One thing I think I would like is to use color for the Cook's 
> >>>>> contours in the new 4th plot.
> >>>
> >>>     PD> Hmm. First try running example(plot.lm) with the modified 
> >>> function and
> >>>     PD> tell me which observation has the largest Cook's D.
> >> With the
> >>> suggested
> >>>     PD> new 4th plot it is very hard to tell whether obs #49 is 
> >>> potentially or
> >>>     PD> actually influential. Plots #1 and #3 are very close to 
> >>> conveying the
> >>>     PD> same information though...
> >>>
> >>> I shouldn't be teaching here, and I know that I'm getting
> >> into fighted
> >>> territory (regression diagnostics; robustness; "The" Truth,
> >> etc,etc)
> >>> but I believe there is no unique way to define "actually
> >> influential"
> >>> (hence I don't believe that it's extremely useful to know exactly 
> >>> which Cook's D is largest).
> >>>
> >>> Partly because there are many statistics that can be 
> derived from a 
> >>> multiple regression fit all of which are influenced in some way.
> >>> AFAIK, all observation-influence measures g(i) are
> >> functions of (r_i,
> >>> h_{ii}) and the latter are the quantities that "regression users"
> >>> should really know {without consulting a text book} and that are 
> >>> generalizable {e.g. to "linear smoothers" such as gam()s (for 
> >>> "non-estimated" smoothing parameter)}.
> >>>
> >>> Martin
> >>
> >> I agree with Martin.  I like the idea of using color 
> (red?) for the 
> >> new Cook's contours.  People who want (fairly) precise 
> comparisons of 
> >> the Cook's statistics can still use the present plot #4, 
> perhaps as a 
> >> follow-up to the new plot #5.
> >> It would be possible to label the Cookwise most extreme 
> points with 
> >> the actual values (to perhaps 2sig figures, i.e., labeling on both 
> >> sides of such points), but this would add what I consider is 
> >> unnecessary clutter to the graph.
> >>
> >> John.
> >>
> >> John Maindonald             email: john.maindonald@anu.edu.au
> >> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> >> Centre for Bioinformation Science, Room 1194, John Dedman 
> >> Mathematical Sciences Building (Building 27) Australian National 
> >> University, Canberra ACT 0200.
> >>
> >> ______________________________________________
> >> R-devel@stat.math.ethz.ch mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > <influence-plots.R>
> John Maindonald             email: john.maindonald@anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Bioinformation Science, Room 1194, John Dedman 
> Mathematical Sciences Building (Building 27) Australian 
> National University, Canberra ACT 0200.
>

From ripley at stats.ox.ac.uk  Fri Apr 29 08:40:52 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Apr 29 08:41:00 2005
Subject: (PR#7821) [Rd] Rgui crash when >1 figure plotted to single wmf
Message-ID: <20050429064052.690A3A1ED@slim.kubism.ku.dk>

On Thu, 28 Apr 2005 rich.fitzjohn@gmail.com wrote:

> R for Windows crashes where more than one plot is plotted to a windows
> metafile where an integer format is not included in the character
> string (i.e. when attempting to write more than one plot to the same
> file).

That is a user error, but the C code is missing a test for a non-NULL 
pointer.

What is unclear is why the metafile cannot be created.  Although we have 
called CloseEnhMetafile and DeleteEnhMetafile, it seems Windows is still
locking the file it opened.  I don't know how to work around that.

> win.metafile("tmp.wmf")
> plot(1:10)
> plot(1:10)
>
> The following dialogues then come up:
>
> Unable to create metafile

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From john.maindonald at anu.edu.au  Fri Apr 29 09:50:55 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri Apr 29 09:51:16 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <20050429000841.KZUW21470.tomts22-srv.bellnexxia.net@JohnDesktop8300>
References: <20050429000841.KZUW21470.tomts22-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <42b18f45d9ff18a35a065f6a062e9d9b@anu.edu.au>

On 29 Apr 2005, at 10:08 AM, John Fox wrote:

> Dear John
>
>> -----Original Message-----
>> From: John Maindonald [mailto:john.maindonald@anu.edu.au]
>> Sent: Thursday, April 28, 2005 6:47 PM
>> To: John Fox
>> Cc: 'Werner Stahel'; 'Peter Dalgaard';
>> <r-devel@stat.math.ethz.ch>; 'David Firth'; 'Martin Maechler'
>> Subject: Re: [Rd] Enhanced version of plot.lm()
>>
>> NB also the mention of a possible addition to stats: vif()
>>
>> Dear John -
>> I think users can cope with six plots offered by one
>> function, with four of them given by default, and the two
>> remaining plots alternative ways of presenting the
>> information in the final default plot.  The idea of plot.lm()
>> was to provide a set of plots that would serve most basic purposes.
>
> I rather like added-variable plots for examining influence and 
> leverage on
> coefficients.

I think that plots of this type are compulsory.  termplot() is
a pretty good start.

John M.
John Maindonald             email: john.maindonald@anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

From npnssmtp3/npnet at np.edu.sg  Fri Apr 29 10:01:55 2005
From: npnssmtp3/npnet at np.edu.sg (npnssmtp3/npnet@np.edu.sg)
Date: Fri Apr 29 10:02:03 2005
Subject: [Rd] {Details on virus detected and blocked.} (PR#7822)
Message-ID: <20050429080155.77228A1CA@slim.kubism.ku.dk>





This is a system-generated notification from Computer Centre, Ngee Ann
Polytechnic.

Our system has detected a virus in an email sent with your email address.
As Internet
email addresses can be easily impersonated, please ignore this notification
if the email
was not sent by you.  If you are indeed the sender, kindly scan your system
for virus and
resend a clean attachment.

Best regards


Date: 04/29/2005 04:01:18 PM
Subject:  Re: Error
Virus:      WORM_NETSKY.P
File: details.zip
From: r-bugs@lists.r-project.org
To:   90@np.edu.sg
Action:     Blocked;

Scanned by ScanMail for Lotus Notes 2.6 SP1
with scanengine 7.510-1002
and pattern version 2.604.00

From jfox at mcmaster.ca  Fri Apr 29 13:28:06 2005
From: jfox at mcmaster.ca (John Fox)
Date: Fri Apr 29 13:28:13 2005
Subject: [Rd] Enhanced version of plot.lm()
In-Reply-To: <42b18f45d9ff18a35a065f6a062e9d9b@anu.edu.au>
Message-ID: <20050429112803.EIEO27245.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear John,

I agree that component+residual (partial residual) plots, as produced by
termplot(), should be examined, but these are distinct from added-variable
(partial regression) plots.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: John Maindonald [mailto:john.maindonald@anu.edu.au] 
> Sent: Friday, April 29, 2005 2:51 AM
> To: John Fox
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] Enhanced version of plot.lm()
> 
> On 29 Apr 2005, at 10:08 AM, John Fox wrote:
> 
> > Dear John
> >
> >> -----Original Message-----
> >> From: John Maindonald [mailto:john.maindonald@anu.edu.au]
> >> Sent: Thursday, April 28, 2005 6:47 PM
> >> To: John Fox
> >> Cc: 'Werner Stahel'; 'Peter Dalgaard'; 
> <r-devel@stat.math.ethz.ch>; 
> >> 'David Firth'; 'Martin Maechler'
> >> Subject: Re: [Rd] Enhanced version of plot.lm()
> >>
> >> NB also the mention of a possible addition to stats: vif()
> >>
> >> Dear John -
> >> I think users can cope with six plots offered by one 
> function, with 
> >> four of them given by default, and the two remaining plots 
> >> alternative ways of presenting the information in the 
> final default 
> >> plot.  The idea of plot.lm() was to provide a set of plots 
> that would 
> >> serve most basic purposes.
> >
> > I rather like added-variable plots for examining influence and 
> > leverage on coefficients.
> 
> I think that plots of this type are compulsory.  termplot() 
> is a pretty good start.
> 
> John M.
> John Maindonald             email: john.maindonald@anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Bioinformation Science, Room 1194, John Dedman 
> Mathematical Sciences Building (Building 27) Australian 
> National University, Canberra ACT 0200.
>

From kanglin at gmail.com  Fri Apr 29 15:21:31 2005
From: kanglin at gmail.com (D0c)
Date: Fri Apr 29 15:21:41 2005
Subject: [Rd] Calling R functions from Java
Message-ID: <2667b213050429062157c4c124@mail.gmail.com>

Hey guys,
I got a java gui app which loads up data into a table. How can i use R
to perform statistical functions on the data in the table?


P.S My question is not particularly geared towards Java coding, but
more towards allowing R functionality within Java.

From f.hahne at dkfz-heidelberg.de  Fri Apr 29 15:25:12 2005
From: f.hahne at dkfz-heidelberg.de (Florian Hahne)
Date: Fri Apr 29 15:26:31 2005
Subject: [Rd] [R] strange behaviour of importFrom directive in name space
Message-ID: <1114781113.11517.101.camel@perro.inet.dkfz-heidelberg.de>

Thanks for moving this post. 
I think i could resolve the issue. It was my stupid mistake (or better a
weird combination of mistakes...)
I dug a little bit deeper into the problem and made a small test package
to reproduce the error. If you like, you can download it at
http://www.dkfz.de/mga2/testImport_1.0.tar.gz .
The package passed R CMD check (R-2.1.0) without errors or warnings. 
When running example("densCols"), it froze with: Error in
col2rgb(colors) : couldn't find function "brewer.pal". 
At first I thought this to be a problem of a corrupted import of
brewer.pal into my name space, but I simply did not realize that I also
explicitly call the function in the example code. So brewer.pal is
correctly imported and it can be (and is) called in the function body as
it is supposed to be.
The example code passes R CMD check, because I put it into an
if(interactive) clause.
But thanks a lot for the quick answer,
Florian   
-- 
Florian Hahne <f.hahne@dkfz-heidelberg.de>

From ripley at stats.ox.ac.uk  Fri Apr 29 16:46:30 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Apr 29 16:46:38 2005
Subject: [Rd] R-devel instability
Message-ID: <Pine.LNX.4.61.0504291543550.30481@gannet.stats>

Recent commits to R-devel mean that you will definitely need to 
re-configure and may even need to re-build from scratch.

This is to support configure options --datadir and --includedir

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From leifere at nhlbi.nih.gov  Fri Apr 29 17:06:50 2005
From: leifere at nhlbi.nih.gov (leifere@nhlbi.nih.gov)
Date: Fri Apr 29 17:06:58 2005
Subject: [Rd] I'm unable to download R from any of the CRAN mirrors. Any
	sugge (PR#7823)
Message-ID: <20050429150650.305E2A1E6@slim.kubism.ku.dk>

	
Thanks.

Eric Leifer, Ph.D.
Office of Biostatistics Research
National Heart, Lung, and Blood Institute
6701 Rockledge Drive, MSC 8217
Bethesda, MD  20892-8217
Email:  LeiferE@NHLBI.NIH.GOV
Phone:  301-435-0436
FAX:    301-480-1862

From p.dalgaard at biostat.ku.dk  Fri Apr 29 17:29:43 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Apr 29 17:29:51 2005
Subject: [Rd] I'm unable to download R from any of the CRAN mirrors. Any
	sugge (PR#7823)
In-Reply-To: <20050429150650.305E2A1E6@slim.kubism.ku.dk>
References: <20050429150650.305E2A1E6@slim.kubism.ku.dk>
Message-ID: <x2k6mlk3dk.fsf@turmalin.kubism.ku.dk>


This is not a bug in R. Please do not misuse the bug repository.

The central CRAN site in Vienna was offline for some hours tonight.
This may have disrupted mirroring, but things look like they are back
to normal. If you have problems downloading in general, then you
probably need to talk to your local support staff.

leifere@nhlbi.nih.gov writes:

> 	
> Thanks.
> 
> Eric Leifer, Ph.D.
> Office of Biostatistics Research
> National Heart, Lung, and Blood Institute
> 6701 Rockledge Drive, MSC 8217
> Bethesda, MD  20892-8217
> Email:  LeiferE@NHLBI.NIH.GOV
> Phone:  301-435-0436
> FAX:    301-480-1862
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Friedrich.Leisch at tuwien.ac.at  Fri Apr 29 17:44:10 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Fri Apr 29 17:44:22 2005
Subject: [Rd] I'm unable to download R from any of the CRAN mirrors. Any
	sugge (PR#7823)
In-Reply-To: <x2k6mlk3dk.fsf@turmalin.kubism.ku.dk>
References: <20050429150650.305E2A1E6@slim.kubism.ku.dk>
	<x2k6mlk3dk.fsf@turmalin.kubism.ku.dk>
Message-ID: <17010.22090.404277.457955@galadriel.ci.tuwien.ac.at>

>>>>> On 29 Apr 2005 17:29:43 +0200,
>>>>> Peter Dalgaard (PD) wrote:

  > This is not a bug in R. Please do not misuse the bug repository.

  > The central CRAN site in Vienna was offline for some hours tonight.
  > This may have disrupted mirroring, but things look like they are back
  > to normal.

Actually if our server is down that shouldn't affect mirroring too
much (most mirroring software is smart enough not to delete everything
is the master site is unreacheable), but URLs of form

	cran.XX.r-project.org

may not work because most of them do not have a DNS entry but are
apache redirections by our server. In that case simply use a CRAN
mirror with a non r-project.org address, a current list can be
obtained by running

 read.csv(file.path(R.home(), "doc", "CRAN_mirrors.csv", as.is=TRUE))[,"URL"]

in a recent version of R ... I'll encapsulate that into a
one-liner CRAN_mirrors().

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch

From leifere at nhlbi.nih.gov  Fri Apr 29 18:04:33 2005
From: leifere at nhlbi.nih.gov (Leifer, Eric (NIH/NHLBI))
Date: Fri Apr 29 18:05:08 2005
Subject: [Rd] I'm unable to download R from any of the CRAN mirrors. A
	ny sugge (PR#7823)
Message-ID: <71216A8F6A7AE24D9F48116DE89A44580D687D93@nihexchange19.nih.gov>


Friedrich,

Thank you for your prompt response.  Unfortunately, none of the CRAN mirrors
seem to be working for me.  I'm not really sure what's going on since I was
able to download R about a year ago, but I recently got a new computer and
needed to download it again.  I'll see if my support staff here at the
National Institutes of Health have any suggestions.

Thanks again,
Eric

-----Original Message-----
From: Friedrich.Leisch@tuwien.ac.at [mailto:Friedrich.Leisch@tuwien.ac.at] 
Sent: Friday, April 29, 2005 11:44 AM
To: Peter Dalgaard
Cc: Leifer, Eric (NIH/NHLBI); r-devel@stat.math.ethz.ch
Subject: Re: [Rd] I'm unable to download R from any of the CRAN mirrors. Any
sugge (PR#7823)


>>>>> On 29 Apr 2005 17:29:43 +0200,
>>>>> Peter Dalgaard (PD) wrote:

  > This is not a bug in R. Please do not misuse the bug repository.

  > The central CRAN site in Vienna was offline for some hours tonight.
  > This may have disrupted mirroring, but things look like they are back
  > to normal.

Actually if our server is down that shouldn't affect mirroring too much
(most mirroring software is smart enough not to delete everything is the
master site is unreacheable), but URLs of form

	cran.XX.r-project.org

may not work because most of them do not have a DNS entry but are apache
redirections by our server. In that case simply use a CRAN mirror with a non
r-project.org address, a current list can be obtained by running

 read.csv(file.path(R.home(), "doc", "CRAN_mirrors.csv",
as.is=TRUE))[,"URL"]

in a recent version of R ... I'll encapsulate that into a one-liner
CRAN_mirrors().

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch

From stefano.iacus at unimi.it  Fri Apr 29 18:47:01 2005
From: stefano.iacus at unimi.it (stefano iacus)
Date: Fri Apr 29 18:47:05 2005
Subject: [Rd] Calling R functions from Java
In-Reply-To: <2667b213050429062157c4c124@mail.gmail.com>
References: <2667b213050429062157c4c124@mail.gmail.com>
Message-ID: <28de3783731028a5504cdb9bda6df564@unimi.it>

Have a look at JGR.
stefano

On 29/apr/05, at 15:21, D0c wrote:

> Hey guys,
> I got a java gui app which loads up data into a table. How can i use R
> to perform statistical functions on the data in the table?
>
>
> P.S My question is not particularly geared towards Java coding, but
> more towards allowing R functionality within Java.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From info at markushelbig.de  Fri Apr 29 18:57:18 2005
From: info at markushelbig.de (Markus Helbig)
Date: Fri Apr 29 18:56:44 2005
Subject: [Rd] Calling R functions from Java
In-Reply-To: <2667b213050429062157c4c124@mail.gmail.com>
References: <2667b213050429062157c4c124@mail.gmail.com>
Message-ID: <200504291857.18181.info@markushelbig.de>

Especially look at JRI, which is responsible for the communication Java -> R.

JGR source: http://www.rosuda.org/JGR/1.1a/src/JGRsrc.tar.gz
JRI source: http://www.rosuda.org/JGR/1.1a/linux/JGR-1.1a.tar.gz

Best

Markus

On Friday 29 April 2005 15:21, D0c wrote:
> Hey guys,
> I got a java gui app which loads up data into a table. How can i use R
> to perform statistical functions on the data in the table?
>
>
> P.S My question is not particularly geared towards Java coding, but
> more towards allowing R functionality within Java.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Markus Helbig
-------------------------

Bahnhofstrasse 21
86492 Egling
Germany

info@markushelbig.de
-------------------------
http://www.markushelbig.de

From tplate at acm.org  Fri Apr 29 18:59:46 2005
From: tplate at acm.org (tplate@acm.org)
Date: Fri Apr 29 19:00:22 2005
Subject: [Rd] handling of zero and negative indices in
	src/main/subscript.c:mat2indsub() (PR#7824)
Message-ID: <20050429165946.0ABD8A1CF@slim.kubism.ku.dk>

This message contains a description of what looks like a bug, examples 
of the suspect behavior, a proposed change to the C code to change this 
behavior, example of behavior with the fix, and suggestions for 3 places 
to update the documentation to reflect the proposed behavior.  It is 
submitted for consideration for inclusion in R.  Comments are requested.

Currently, the code for subscripting by matrices checks that values in 
the matrix are not greater than the dimensions of the array being 
indexed.  However, it does not check for zero or negative indices, and 
blindly does index computation with them as though they were positive 
indices (including for negative indices whose absolute value exceeds the 
dimensions of the array being indexed).  Here are examples of indexing 
by matrices that do not return unequivocally sensible results (in most 
cases):

 > x <- matrix(1:6,ncol=2)
 > dim(x)
[1] 3 2
 > x
      [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6
 > x[rbind(c(1,1), c(2,2))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(0,1))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(0,0))]
Error: only 0's may be mixed with negative subscripts
 > x[rbind(c(1,1), c(2,2), c(0,2))]
[1] 1 5 3
 > x[rbind(c(1,1), c(2,2), c(0,3))]
Error: subscript out of bounds
 > x[rbind(c(1,1), c(2,2), c(1,0))]
Error: only 0's may be mixed with negative subscripts
 > x[rbind(c(1,1), c(2,2), c(2,0))]
Error: only 0's may be mixed with negative subscripts
 > x[rbind(c(1,1), c(2,2), c(3,0))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(1,2))]
[1] 1 5 4
 > x[rbind(c(1,1), c(2,2), c(-1,2))]
[1] 1 5 2
 > x[rbind(c(1,1), c(2,2), c(-2,2))]
[1] 1 5 1
 > x[rbind(c(1,1), c(2,2), c(-3,2))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(-4,2))]
Error: only 0's may be mixed with negative subscripts
 > x[rbind(c(1,1), c(2,2), c(-1,-1))]
Error: subscript out of bounds
 >
 > # range checks are not applied to negative indices
 > x <- matrix(1:6, ncol=3)
 > dim(x)
[1] 2 3
 > x[rbind(c(1,1), c(2,2), c(-3,3))]
[1] 1 4 1
 > x[rbind(c(1,1), c(2,2), c(-4,3))]
[1] 1 4
 >
 > version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    1.0
year     2005
month    04
day      18
language R
 >

The followed version of mat2indsub() (to replace the one in 
src/main/subscript.c) allows zero indices and explicitly disallows all 
negative indices:

/* Special Matrix Subscripting: Handles the case x[i] where */
/* x is an n-way array and i is a matrix with n columns. */
/* This code returns a vector containing the integer subscripts */
/* to be extracted when x is regarded as unravelled. */
/* Negative indices are not allowed. */
/* A zero anywhere in a row will cause a zero in the same */
/* position in the result. */

SEXP mat2indsub(SEXP dims, SEXP s)
{
     int tdim, j, i, k, nrs = nrows(s);
     SEXP rvec;

     PROTECT(rvec = allocVector(INTSXP, nrs));
     s = coerceVector(s, INTSXP);
     setIVector(INTEGER(rvec), nrs, 0);

     for (i = 0; i < nrs; i++) {
	tdim = 1;
	/* compute 0-based subscripts for a row (0 in the input */
         /* gets -1 in the output here) */
	for (j = 0; j < LENGTH(dims); j++) {
	    k = INTEGER(s)[i + j * nrs];
	    if(k == NA_INTEGER) {
		INTEGER(rvec)[i] = NA_INTEGER;
		break;
	    }
             if(k < 0)
		error(_("cannot have negative values in matrices used as subscripts"));
	    if(k == 0) {
		INTEGER(rvec)[i] = -1;
		break;
	    }
	    if (k > INTEGER(dims)[j])
		error(_("subscript out of bounds"));
	    INTEGER(rvec)[i] += (k - 1) * tdim;
	    tdim *= INTEGER(dims)[j];
	}
	/* transform to 1 based subscripting (0 in the input */
         /* gets 0 in the output here) */
	if(INTEGER(rvec)[i] != NA_INTEGER)
	    INTEGER(rvec)[i]++;
     }
     UNPROTECT(1);
     return (rvec);
}

With this version, the above commands (+ a couple more) produce the 
following output (with commands that fail suitably wrapped in try() so 
that they can be included in a test files.)

 > x <- matrix(1:6,ncol=2)
 > dim(x)
[1] 3 2
 > x
      [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6
 > x[rbind(c(1,1), c(2,2))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(0,1))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(0,0))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(0,2))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(0,3))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(1,0))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(2,0))]
[1] 1 5
 > x[rbind(c(1,1), c(2,2), c(3,0))]
[1] 1 5
 > x[rbind(c(1,0), c(0,2), c(3,0))]
numeric(0)
 > x[rbind(c(1,0), c(0,0), c(3,0))]
numeric(0)
 > x[rbind(c(1,1), c(2,2), c(1,2))]
[1] 1 5 4
 > x[rbind(c(1,1), c(2,NA), c(1,2))]
[1]  1 NA  4
 > x[rbind(c(1,0), c(2,NA), c(1,2))]
[1] NA  4
 > try(x[rbind(c(1,1), c(2,2), c(-1,2))])
Error in try(x[rbind(c(1, 1), c(2, 2), c(-1, 2))]) :
         cannot have negative values in matrices used as subscripts
 > try(x[rbind(c(1,1), c(2,2), c(-2,2))])
Error in try(x[rbind(c(1, 1), c(2, 2), c(-2, 2))]) :
         cannot have negative values in matrices used as subscripts
 > try(x[rbind(c(1,1), c(2,2), c(-3,2))])
Error in try(x[rbind(c(1, 1), c(2, 2), c(-3, 2))]) :
         cannot have negative values in matrices used as subscripts
 > try(x[rbind(c(1,1), c(2,2), c(-4,2))])
Error in try(x[rbind(c(1, 1), c(2, 2), c(-4, 2))]) :
         cannot have negative values in matrices used as subscripts
 > try(x[rbind(c(1,1), c(2,2), c(-1,-1))])
Error in try(x[rbind(c(1, 1), c(2, 2), c(-1, -1))]) :
         cannot have negative values in matrices used as subscripts
 >
 > # verify that range checks are applied to negative indices
 > x <- matrix(1:6, ncol=3)
 > dim(x)
[1] 2 3
 > try(x[rbind(c(1,1), c(2,2), c(-3,3))])
Error in try(x[rbind(c(1, 1), c(2, 2), c(-3, 3))]) :
         cannot have negative values in matrices used as subscripts
 > try(x[rbind(c(1,1), c(2,2), c(-4,3))])
Error in try(x[rbind(c(1, 1), c(2, 2), c(-4, 3))]) :
         cannot have negative values in matrices used as subscripts
 >


The documentation page for ?Extract could have the following sentences 
added to the end of the 2nd para in the description of arguments "i, j, 
...":

   Negative indices are not allowed in matrices used as indices.
   NA and zero values are allowed: rows containing a zero are
   omitted from the result, and rows containing an NA produce an
   NA in the result.

In "Introduction to R", the same material could be added to the end of 
the section "Index Arrays" (in the chapter "Arrays and matrices").

In "R Language Definition", the third paragraph of the section "Indexing 
matrices and arrays" (Section 3.4.2 in my copy) currently reads:

> It is possible to use a matrix of integers as an index. In
> this case, the number of columns of the matrix should match
> the number of dimensions of the structure, and the result
> will be a vector with length as the number of rows of the
> matrix. The following example shows how to extract the
> elements m[1, 1] and m[2, 2] in one operation.

It could be changed to the following:

It is possible to use a matrix of integers as an index.
Negative indices are not allowed in matrices used as
indices.  NA and zero values are allowed: rows containing a
zero are omitted from the result, and rows containing an NA
produce an NA in the result.  To use a matrix as an index,
the number of columns of the matrix should match the number
of dimensions of the structure, and the result will be a
vector with length as the number of rows of the matrix
(except when the matrix contains zeros). The following
example shows how to extract the elements m[1, 1] and m[2,
2] in one operation.


Additionally, indexing by matrix just goes ahead and uses matrix 
elements as vector indices in cases where the number of columns in the 
matrix does not match the number of dimensions in the array.  E.g.:

 > x <- matrix(1:6,ncol=2)
 > x[rbind(c(1,1,1), c(2,2,2))]
[1] 1 2 1 2 1 2
 >

Would it not be preferable behavior to stop with an error in such cases?

From phgrosjean at sciviews.org  Fri Apr 29 20:25:21 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri Apr 29 20:25:44 2005
Subject: [Rd] Installing different files in R packages,
	depending on the platform
Message-ID: <42727C11.8090205@sciviews.org>

Hello,

I have a package that needs to install different files, depending if it 
is compiled under Windows, or under other platforms. Those files are 
currently in the ./inst subdirectory. What is the preferred way to do this?

I imagine that I have to place platform specific files in another place 
than ./inst, and then use configure and configure.win to do the job 
selectively. Is it a better way to do so? Can someone point me to an 
example package that does something similar?

Thanks,

Philippe

..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean@umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................

From ayjvr at fbi.gov  Fri Apr 29 21:18:01 2005
From: ayjvr at fbi.gov (ayjvr@fbi.gov)
Date: Fri Apr 29 21:18:22 2005
Subject: [Rd] hello
Message-ID: <200504291918.j3TJI5gJ014484@ms-smtp-04.texas.rr.com>

ALERT!

This e-mail, in its original form, contained one or more attached files that were infected with a virus, worm, or other type of security threat. This e-mail was sent from a Road Runner IP address. As part of our continuing initiative to stop the spread of malicious viruses, Road Runner scans all outbound e-mail attachments. If a virus, worm, or other security threat is found, Road Runner cleans or deletes the infected attachments as necessary, but continues to send the original message content to the recipient. Further information on this initiative can be found at http://help.rr.com/faqs/e_mgsp.html.
Please be advised that Road Runner does not contact the original sender of the e-mail as part of the scanning process. Road Runner recommends that if the sender is known to you, you contact them directly and advise them of their issue. If you do not know the sender, we advise you to forward this message in its entirety (including full headers) to the Road Runner Abuse Department, at abuse@rr.com.

The original message was included as an attachment.

From matt at olga.net  Fri Apr 29 21:18:12 2005
From: matt at olga.net (matt@olga.net)
Date: Fri Apr 29 21:18:31 2005
Subject: [Rd] Error
Message-ID: <200504291918.j3TJIFRZ022753@ms-smtp-03-eri0.texas.rr.com>

ALERT!

This e-mail, in its original form, contained one or more attached files that were infected with a virus, worm, or other type of security threat. This e-mail was sent from a Road Runner IP address. As part of our continuing initiative to stop the spread of malicious viruses, Road Runner scans all outbound e-mail attachments. If a virus, worm, or other security threat is found, Road Runner cleans or deletes the infected attachments as necessary, but continues to send the original message content to the recipient. Further information on this initiative can be found at http://help.rr.com/faqs/e_mgsp.html.
Please be advised that Road Runner does not contact the original sender of the e-mail as part of the scanning process. Road Runner recommends that if the sender is known to you, you contact them directly and advise them of their issue. If you do not know the sender, we advise you to forward this message in its entirety (including full headers) to the Road Runner Abuse Department, at abuse@rr.com.

The message cannot be represented in 7-bit ASCII encoding and has been sent as a binary attachment.

From Jskud at jskud.com  Sat Apr 30 10:59:27 2005
From: Jskud at jskud.com (Jskud@jskud.com)
Date: Sat Apr 30 10:59:36 2005
Subject: [Rd] segfault during build of 2.1.0 on RH9;
	print.POSIXct implicated (PR#7827)
Message-ID: <20050430085927.3336DA1CA@slim.kubism.ku.dk>

In attempting to build R using 

	rpmbuild --rebuild R-2.1.0-0.fdr.2.fc3.src.rpm 

on a fairly up-to-date RedHat 9 system (that is, with patches installed
through May 1 2004), it failed at the make check-all step.

The problem was reproducible by going into the tests directory and

	make test-Segfault

The last lines of the saved file no-segfault.Rout.fail are

> > ##  c.POSIXct  :
> > f <- get("c.POSIXct", pos = 'package:base')
> > f()
> character(0)
> > f(NULL)
> character(0)
> > f(,NULL)
> Error in lapply(list(...), unclass) : argument is missing, with no default
> > f(NULL,NULL)
> character(0)
> > f(list())
> character(0)
> > f(l0)
> character(0)

I was able to reproduce the problem (a segfault) as the following simple
transcript demonstrates: 

    LC_ALL=C SRCDIR=. R_DEFAULT_PACKAGES= ../bin/R --vanilla

    R : Copyright 2005, The R Foundation for Statistical Computing
    Version 2.1.0  (2005-04-18), ISBN 3-900051-07-0

    R is free software and comes with ABSOLUTELY NO WARRANTY.
    You are welcome to redistribute it under certain conditions.
    Type 'license()' or 'licence()' for distribution details.

    R is a collaborative project with many contributors.
    Type 'contributors()' for more information and
    'citation()' on how to cite R or R packages in publications.

    Type 'demo()' for some demos, 'help()' for on-line help, or
    'help.start()' for a HTML browser interface to help.
    Type 'q()' to quit R.

    > unusual_but_ok <- c.POSIXlt(character(0))
    > unusual_but_ok
    character(0)
    > unusual_and_faults <- c.POSIXct(character(0))
    > unusual_and_faults
    Segmentation fault

Running this test program under gdb, we find that we're running off the
end of the stack, with 4222 stack frames showing -- apparently in an
infinite recursion -- "as.character" shows up every 69 function calls:

#64 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4, 
    args=0x8af8b00, rho=0x8af8b70, callrho=0x8af8b70, defrho=0x829d4c0, ans=0xbff042b8)
    at objects.c:328

#133 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4, 
    args=0x8af35f0, rho=0x8af3660, callrho=0x8af3660, defrho=0x829d4c0, ans=0xbff08538)
    at objects.c:328

#202 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4, 
    args=0x8aeca08, rho=0x8aeca78, callrho=0x8aeca78, defrho=0x829d4c0, ans=0xbff0c7b8)
    at objects.c:328

#271 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4, 
    args=0x8ae7514, rho=0x8ae7584, callrho=0x8ae7584, defrho=0x829d4c0, ans=0xbff10a38)
    at objects.c:328

#340 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4, 
    args=0x8ade4c0, rho=0x8ade530, callrho=0x8ade530, defrho=0x829d4c0, ans=0xbff14cb8)
    at objects.c:328

So it would seem that *printing* the unusual POSIXct value is suspect.
Looking at a R-1.8.1 install, we find these definitions in base/R/base:

    print.POSIXct <- function(x, ...)
    {
	print(format(x, usetz=TRUE), ...)
	invisible(x)
    }

    print.POSIXlt <- function(x, ...)
    {
	print(format(x, usetz=TRUE), ...)
	invisible(x)
    }

However, looking at the 2.1.0 src file
R-2.1.0/src/library/base/R/datetime.R, we find

    print.POSIXct <- function(x, ...)
    {
	print(format(x, usetz=TRUE, ...), ...)
	invisible(x)
    }

    print.POSIXlt <- function(x, ...)
    {
	print(format(x, usetz=TRUE), ...)
	invisible(x)
    }

Note the suspicious definition of print.POSIXct using *two* sets of
ellipses, and that the print.POSIXct and print.POSIXlt definitions no
longer match.

/Jskud

--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status = 
 major = 2
 minor = 1.0
 year = 2005
 month = 04
 day = 18
 language = R

[]

From Jskud at Jskud.com  Sat Apr 30 09:04:03 2005
From: Jskud at Jskud.com (Jskud@Jskud.com)
Date: Sat Apr 30 11:16:17 2005
Subject: [Rd] segfault during build of 2.1.0 on RH9;
	print.POSIXct implicated (PR#7826)
Message-ID: <20050430070403.7B61FA1CA@slim.kubism.ku.dk>

In attempting to build R using 

	rpmbuild --rebuild R-2.1.0-0.fdr.2.fc3.src.rpm 

on a fairly up-to-date RedHat 9 system (that is, with patches installed
through May 1 2004), it failed at the make check-all step.

The problem was reproducible by going into the tests directory and

	make test-Segfault

The last lines of the saved file no-segfault.Rout.fail are

> > ##  c.POSIXct  :
> > f <- get("c.POSIXct", pos = 'package:base')
> > f()
> character(0)
> > f(NULL)
> character(0)
> > f(,NULL)
> Error in lapply(list(...), unclass) : argument is missing, with no default
> > f(NULL,NULL)
> character(0)
> > f(list())
> character(0)
> > f(l0)
> character(0)

I was able to reproduce the problem (a segfault) as the following simple
transcript demonstrates: 

    LC_ALL=C SRCDIR=. R_DEFAULT_PACKAGES= ../bin/R --vanilla

    R : Copyright 2005, The R Foundation for Statistical Computing
    Version 2.1.0  (2005-04-18), ISBN 3-900051-07-0

    R is free software and comes with ABSOLUTELY NO WARRANTY.
    You are welcome to redistribute it under certain conditions.
    Type 'license()' or 'licence()' for distribution details.

    R is a collaborative project with many contributors.
    Type 'contributors()' for more information and
    'citation()' on how to cite R or R packages in publications.

    Type 'demo()' for some demos, 'help()' for on-line help, or
    'help.start()' for a HTML browser interface to help.
    Type 'q()' to quit R.

    > unusual_but_ok <- c.POSIXlt(character(0))
    > unusual_but_ok
    character(0)
    > unusual_and_faults <- c.POSIXct(character(0))
    > unusual_and_faults
    Segmentation fault

Running this test program under gdb, we find that we're running off the
end of the stack, with 4222 stack frames showing -- apparently in an
infinite recursion -- "as.character" shows up every 69 function calls:

#64 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4, 
    args=0x8af8b00, rho=0x8af8b70, callrho=0x8af8b70, defrho=0x829d4c0, ans=0xbff042b8)
    at objects.c:328

#133 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4, 
    args=0x8af35f0, rho=0x8af3660, callrho=0x8af3660, defrho=0x829d4c0, ans=0xbff08538)
    at objects.c:328

#202 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4, 
    args=0x8aeca08, rho=0x8aeca78, callrho=0x8aeca78, defrho=0x829d4c0, ans=0xbff0c7b8)
    at objects.c:328

#271 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4, 
    args=0x8ae7514, rho=0x8ae7584, callrho=0x8ae7584, defrho=0x829d4c0, ans=0xbff10a38)
    at objects.c:328

#340 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4, 
    args=0x8ade4c0, rho=0x8ade530, callrho=0x8ade530, defrho=0x829d4c0, ans=0xbff14cb8)
    at objects.c:328

So it would seem that *printing* the unusual POSIXct value is suspect.
Looking at a R-1.8.1 install, we find these definitions in base/R/base:

    print.POSIXct <- function(x, ...)
    {
	print(format(x, usetz=TRUE), ...)
	invisible(x)
    }

    print.POSIXlt <- function(x, ...)
    {
	print(format(x, usetz=TRUE), ...)
	invisible(x)
    }

However, looking at the 2.1.0 src file
R-2.1.0/src/library/base/R/datetime.R, we find

    print.POSIXct <- function(x, ...)
    {
	print(format(x, usetz=TRUE, ...), ...)
	invisible(x)
    }

    print.POSIXlt <- function(x, ...)
    {
	print(format(x, usetz=TRUE), ...)
	invisible(x)
    }

Note the suspicious definition of print.POSIXct using *two* sets of
ellipses, and that the print.POSIXct and print.POSIXlt definitions no
longer match.

/Jskud

--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status = 
 major = 2
 minor = 1.0
 year = 2005
 month = 04
 day = 18
 language = R

[]

From Bill.Venables at csiro.au  Sat Apr 30 08:03:27 2005
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Sat Apr 30 11:16:45 2005
Subject: [Rd] as.numeric method for objects of class "difftime"
Message-ID: <B998A44C8986644EA8029CFE6396A9241B32C5@exqld2-bne.qld.csiro.au>

I have just become painfully aware that objects of class "difftime",
generated by the difference of two POSIXct objects, carry a "units"
attribute, which flashes by when the object is printed, for example.

The pain was occasioned when I tried to turn these objects into numberic
objects for use elsewhere as a covariate.  

as.numeric(difftime object)

simply turns off the units attribute and provides a numeric object which
may represent a number of seconds or a number of days, with no warning
as to which.

I think this is an unfortunate situation, but I can't see how to rectify
it without breaking code that may rely on this quirky feature.  My
inclination is to suggest a method for as.numeric (ie for as.double)
that settles on a single unit, which for consistency with
as.numeric(POSIXct object) should probably be seconds:

as.double.difftime <- function(x, ...)
  if(attr(x, "units") == "days") as.vector(x) * 86400 else as.vector(x)

but there must now be lots of code out there that has blythely assumed
that the difference will always be a number of days and others assume it
is always seconds.

At the very least I think the help information should carry a big red
warning about this rather unusual feature.  (It may, I suppose, but I
couldn't find it.)

Comments?

Bill Venables, 
CMIS, CSIRO Laboratories, 
PO Box 120, Cleveland, Qld. 4163
AUSTRALIA
Phone:  +61 7 3826 7251  
Fax:    +61 7 3826 7304
Mobile: +61 4 1963 4642
Home:   +61 7 3286 7700
mailto:Bill.Venables@csiro.au
http://www.cmis.csiro.au/bill.venables/

From ripley at stats.ox.ac.uk  Sat Apr 30 11:47:19 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Apr 30 11:47:28 2005
Subject: (PR#7826) [Rd] segfault during build of 2.1.0 on RH9;
	print.POSIXct
Message-ID: <20050430094719.918BBA1CA@slim.kubism.ku.dk>

1) Why did you submit this *twice*, as PR#7826 and PR#7827?  Please don't 
be so careless of the volunteers' time.

2) > print.POSIXct
function (x, ...)
{
     print(format(x, usetz = TRUE, ...), ...)
     invisible(x)
}

is definitely *not* implicated.  (Use of ... in two places is correct.)

3) On FC3:

> unusual_and_faults
Error: protect(): protection stack overflow
> format(unusual_and_faults)
Error: protect(): protection stack overflow
> as.POSIXlt(unusual_and_faults)
Error: protect(): protection stack overflow

which is what should happen.  It looks like RH9 has an inadequate stack 
size for the new recursion limits of R 2.1.0.  This is nothing whatsoever 
to do with print.POSIXct.

The problem is in fact in c.POSIXct which is not checking its arguments.


On Sat, 30 Apr 2005 Jskud@jskud.com wrote:

> In attempting to build R using
>
> 	rpmbuild --rebuild R-2.1.0-0.fdr.2.fc3.src.rpm
>
> on a fairly up-to-date RedHat 9 system (that is, with patches installed
> through May 1 2004), it failed at the make check-all step.
>
> The problem was reproducible by going into the tests directory and
>
> 	make test-Segfault
>
> The last lines of the saved file no-segfault.Rout.fail are
>
>>> ##  c.POSIXct  :
>>> f <- get("c.POSIXct", pos = 'package:base')
>>> f()
>> character(0)
>>> f(NULL)
>> character(0)
>>> f(,NULL)
>> Error in lapply(list(...), unclass) : argument is missing, with no default
>>> f(NULL,NULL)
>> character(0)
>>> f(list())
>> character(0)
>>> f(l0)
>> character(0)
>
> I was able to reproduce the problem (a segfault) as the following simple
> transcript demonstrates:
>
>    LC_ALL=C SRCDIR=. R_DEFAULT_PACKAGES= ../bin/R --vanilla
>
>    R : Copyright 2005, The R Foundation for Statistical Computing
>    Version 2.1.0  (2005-04-18), ISBN 3-900051-07-0
>
>    R is free software and comes with ABSOLUTELY NO WARRANTY.
>    You are welcome to redistribute it under certain conditions.
>    Type 'license()' or 'licence()' for distribution details.
>
>    R is a collaborative project with many contributors.
>    Type 'contributors()' for more information and
>    'citation()' on how to cite R or R packages in publications.
>
>    Type 'demo()' for some demos, 'help()' for on-line help, or
>    'help.start()' for a HTML browser interface to help.
>    Type 'q()' to quit R.
>
>    > unusual_but_ok <- c.POSIXlt(character(0))
>    > unusual_but_ok
>    character(0)
>    > unusual_and_faults <- c.POSIXct(character(0))
>    > unusual_and_faults
>    Segmentation fault
>
> Running this test program under gdb, we find that we're running off the
> end of the stack, with 4222 stack frames showing -- apparently in an
> infinite recursion -- "as.character" shows up every 69 function calls:
>
> #64 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4,
>    args=0x8af8b00, rho=0x8af8b70, callrho=0x8af8b70, defrho=0x829d4c0, ans=0xbff042b8)
>    at objects.c:328
>
> #133 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4,
>    args=0x8af35f0, rho=0x8af3660, callrho=0x8af3660, defrho=0x829d4c0, ans=0xbff08538)
>    at objects.c:328
>
> #202 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4,
>    args=0x8aeca08, rho=0x8aeca78, callrho=0x8aeca78, defrho=0x829d4c0, ans=0xbff0c7b8)
>    at objects.c:328
>
> #271 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4,
>    args=0x8ae7514, rho=0x8ae7584, callrho=0x8ae7584, defrho=0x829d4c0, ans=0xbff10a38)
>    at objects.c:328
>
> #340 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4,
>    args=0x8ade4c0, rho=0x8ade530, callrho=0x8ade530, defrho=0x829d4c0, ans=0xbff14cb8)
>    at objects.c:328
>
> So it would seem that *printing* the unusual POSIXct value is suspect.
> Looking at a R-1.8.1 install, we find these definitions in base/R/base:
>
>    print.POSIXct <- function(x, ...)
>    {
> 	print(format(x, usetz=TRUE), ...)
> 	invisible(x)
>    }
>
>    print.POSIXlt <- function(x, ...)
>    {
> 	print(format(x, usetz=TRUE), ...)
> 	invisible(x)
>    }
>
> However, looking at the 2.1.0 src file
> R-2.1.0/src/library/base/R/datetime.R, we find
>
>    print.POSIXct <- function(x, ...)
>    {
> 	print(format(x, usetz=TRUE, ...), ...)
> 	invisible(x)
>    }
>
>    print.POSIXlt <- function(x, ...)
>    {
> 	print(format(x, usetz=TRUE), ...)
> 	invisible(x)
>    }
>
> Note the suspicious definition of print.POSIXct using *two* sets of
> ellipses, and that the print.POSIXct and print.POSIXlt definitions no
> longer match.
>
> /Jskud
>
> --please do not edit the information below--
>
> Version:
> platform = i686-pc-linux-gnu
> arch = i686
> os = linux-gnu
> system = i686, linux-gnu
> status =
> major = 2
> minor = 1.0
> year = 2005
> month = 04
> day = 18
> language = R
>
> []
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sat Apr 30 12:16:58 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Apr 30 12:19:19 2005
Subject: (PR#7826) [Rd] segfault during build of 2.1.0 on RH9;
	print.POSIXct
In-Reply-To: <20050430094719.918BBA1CA@slim.kubism.ku.dk>
References: <20050430094719.918BBA1CA@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0504301111440.21745@gannet.stats>

I've now tested our one remaining RH9 system (built from the sources), and 
that behaves exactly as FC3.

Something is wrong with Jskud@jskud.com's system or its build, not RH9 nor 
R generically.

I've put a workaround in R-patched, but ultimately cycles in inheritance 
are always possible and the expressions/ppsize limits are there to catch 
those.

On Sat, 30 Apr 2005 ripley@stats.ox.ac.uk wrote:

> 1) Why did you submit this *twice*, as PR#7826 and PR#7827?  Please don't
> be so careless of the volunteers' time.
>
> 2) > print.POSIXct
> function (x, ...)
> {
>     print(format(x, usetz = TRUE, ...), ...)
>     invisible(x)
> }
>
> is definitely *not* implicated.  (Use of ... in two places is correct.)
>
> 3) On FC3:
>
>> unusual_and_faults
> Error: protect(): protection stack overflow
>> format(unusual_and_faults)
> Error: protect(): protection stack overflow
>> as.POSIXlt(unusual_and_faults)
> Error: protect(): protection stack overflow
>
> which is what should happen.  It looks like RH9 has an inadequate stack
> size for the new recursion limits of R 2.1.0.  This is nothing whatsoever
> to do with print.POSIXct.
>
> The problem is in fact in c.POSIXct which is not checking its arguments.
>
>
> On Sat, 30 Apr 2005 Jskud@jskud.com wrote:
>
>> In attempting to build R using
>>
>> 	rpmbuild --rebuild R-2.1.0-0.fdr.2.fc3.src.rpm
>>
>> on a fairly up-to-date RedHat 9 system (that is, with patches installed
>> through May 1 2004), it failed at the make check-all step.
>>
>> The problem was reproducible by going into the tests directory and
>>
>> 	make test-Segfault
>>
>> The last lines of the saved file no-segfault.Rout.fail are
>>
>>>> ##  c.POSIXct  :
>>>> f <- get("c.POSIXct", pos = 'package:base')
>>>> f()
>>> character(0)
>>>> f(NULL)
>>> character(0)
>>>> f(,NULL)
>>> Error in lapply(list(...), unclass) : argument is missing, with no default
>>>> f(NULL,NULL)
>>> character(0)
>>>> f(list())
>>> character(0)
>>>> f(l0)
>>> character(0)
>>
>> I was able to reproduce the problem (a segfault) as the following simple
>> transcript demonstrates:
>>
>>    LC_ALL=C SRCDIR=. R_DEFAULT_PACKAGES= ../bin/R --vanilla
>>
>>    R : Copyright 2005, The R Foundation for Statistical Computing
>>    Version 2.1.0  (2005-04-18), ISBN 3-900051-07-0
>>
>>    R is free software and comes with ABSOLUTELY NO WARRANTY.
>>    You are welcome to redistribute it under certain conditions.
>>    Type 'license()' or 'licence()' for distribution details.
>>
>>    R is a collaborative project with many contributors.
>>    Type 'contributors()' for more information and
>>    'citation()' on how to cite R or R packages in publications.
>>
>>    Type 'demo()' for some demos, 'help()' for on-line help, or
>>    'help.start()' for a HTML browser interface to help.
>>    Type 'q()' to quit R.
>>
>>   > unusual_but_ok <- c.POSIXlt(character(0))
>>   > unusual_but_ok
>>    character(0)
>>   > unusual_and_faults <- c.POSIXct(character(0))
>>   > unusual_and_faults
>>    Segmentation fault
>>
>> Running this test program under gdb, we find that we're running off the
>> end of the stack, with 4222 stack frames showing -- apparently in an
>> infinite recursion -- "as.character" shows up every 69 function calls:
>>
>> #64 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4,
>>    args=0x8af8b00, rho=0x8af8b70, callrho=0x8af8b70, defrho=0x829d4c0, ans=0xbff042b8)
>>    at objects.c:328
>>
>> #133 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4,
>>    args=0x8af35f0, rho=0x8af3660, callrho=0x8af3660, defrho=0x829d4c0, ans=0xbff08538)
>>    at objects.c:328
>>
>> #202 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4,
>>    args=0x8aeca08, rho=0x8aeca78, callrho=0x8aeca78, defrho=0x829d4c0, ans=0xbff0c7b8)
>>    at objects.c:328
>>
>> #271 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4,
>>    args=0x8ae7514, rho=0x8ae7584, callrho=0x8ae7584, defrho=0x829d4c0, ans=0xbff10a38)
>>    at objects.c:328
>>
>> #340 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4,
>>    args=0x8ade4c0, rho=0x8ade530, callrho=0x8ade530, defrho=0x829d4c0, ans=0xbff14cb8)
>>    at objects.c:328
>>
>> So it would seem that *printing* the unusual POSIXct value is suspect.
>> Looking at a R-1.8.1 install, we find these definitions in base/R/base:
>>
>>    print.POSIXct <- function(x, ...)
>>    {
>> 	print(format(x, usetz=TRUE), ...)
>> 	invisible(x)
>>    }
>>
>>    print.POSIXlt <- function(x, ...)
>>    {
>> 	print(format(x, usetz=TRUE), ...)
>> 	invisible(x)
>>    }
>>
>> However, looking at the 2.1.0 src file
>> R-2.1.0/src/library/base/R/datetime.R, we find
>>
>>    print.POSIXct <- function(x, ...)
>>    {
>> 	print(format(x, usetz=TRUE, ...), ...)
>> 	invisible(x)
>>    }
>>
>>    print.POSIXlt <- function(x, ...)
>>    {
>> 	print(format(x, usetz=TRUE), ...)
>> 	invisible(x)
>>    }
>>
>> Note the suspicious definition of print.POSIXct using *two* sets of
>> ellipses, and that the print.POSIXct and print.POSIXlt definitions no
>> longer match.
>>
>> /Jskud
>>
>> --please do not edit the information below--
>>
>> Version:
>> platform = i686-pc-linux-gnu
>> arch = i686
>> os = linux-gnu
>> system = i686, linux-gnu
>> status =
>> major = 2
>> minor = 1.0
>> year = 2005
>> month = 04
>> day = 18
>> language = R
>>
>> []
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Sat Apr 30 12:18:56 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat Apr 30 12:19:22 2005
Subject: [Rd] segfault during build of 2.1.0 on RH9;
	print.POSIXct implicated (PR#7827)
In-Reply-To: <20050430085927.3336DA1CA@slim.kubism.ku.dk>
References: <20050430085927.3336DA1CA@slim.kubism.ku.dk>
Message-ID: <x2is24tvn3.fsf@turmalin.kubism.ku.dk>

Jskud@jskud.com writes:
>     > unusual_but_ok <- c.POSIXlt(character(0))
>     > unusual_but_ok
>     character(0)
>     > unusual_and_faults <- c.POSIXct(character(0))
>     > unusual_and_faults
>     Segmentation fault
> 
> Running this test program under gdb, we find that we're running off the
> end of the stack, with 4222 stack frames showing -- apparently in an
> infinite recursion -- "as.character" shows up every 69 function calls:

This gives a protection stack overflow on FC3 and RH8. Is the stack
particularly small on RH9? I have 8MB on RH8 and 10MB on FC3. (The R
limits for expression depth and pointer protection were increased in
2.1.0). I can force a segfault, but only after "ulimit -s 1024" or so.
 
> #64 0x080ea1ef in Rf_usemethod (generic=0x81c8b12 "as.character", obj=0x0, call=0x85a04f4, 
...
> So it would seem that *printing* the unusual POSIXct value is suspect.

Pretty obviously, yes.

> Looking at a R-1.8.1 install, we find these definitions in base/R/base:
> 
>     print.POSIXct <- function(x, ...)
>     {
> 	print(format(x, usetz=TRUE), ...)
> 	invisible(x)
>     }
> 
>     print.POSIXlt <- function(x, ...)
>     {
> 	print(format(x, usetz=TRUE), ...)
> 	invisible(x)
>     }
> 
> However, looking at the 2.1.0 src file
> R-2.1.0/src/library/base/R/datetime.R, we find
> 
>     print.POSIXct <- function(x, ...)
>     {
> 	print(format(x, usetz=TRUE, ...), ...)
> 	invisible(x)
>     }
> 
>     print.POSIXlt <- function(x, ...)
>     {
> 	print(format(x, usetz=TRUE), ...)
> 	invisible(x)
>     }
> 
> Note the suspicious definition of print.POSIXct using *two* sets of
> ellipses, and that the print.POSIXct and print.POSIXlt definitions no
> longer match.

Probably both should use the double ellipses, but "..." will be empty
on automatic printing, so that's not it. 

The issue is an infinite recursion inside as.POSIXlt(). Specifically,
strptime() internally calls as.character(x) inside the fromchar()
function in as.POSIXlt(), and as.character.POSIXt() invokes format()
which calls as.POSIXlt() again.

I think the fix is to unclass(x) inside fromchar(), but perhaps others
know better?
 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From pburns at pburns.seanet.com  Sat Apr 30 13:26:03 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat Apr 30 13:26:58 2005
Subject: [Rd] formals assignment now strips attributres
Message-ID: <42736B4B.3080507@pburns.seanet.com>

The assignment form of 'formals' strips attributes (or something close
to that) from the values in the list.  This wasn't intentional, was it?

The current behavior (2.0.0 through 2.1.0 on Windows at least):

 > fjj <- function() x
 > formals(fjj) <- list(x=c(a=2, b=4))
 > fjj
function (x = c(2, 4))
x


Previous behavior:

 > fjj <- function() x
 > formals(fjj) <- list(x=c(a=2, b=4))
 > fjj
function (x = structure(c(2, 4), .Names = c("a", "b")))
x

Patrick Burns

Burns Statistics
patrick@burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

From kjetil at acelerate.com  Sat Apr 30 13:56:35 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Sat Apr 30 13:56:44 2005
Subject: [Rd] Re: [R] Warning from Rcmd check - data could not find data set
In-Reply-To: <Pine.LNX.4.61.0504300702540.19431@gannet.stats>
References: <4272E9D6.7030706@acelerate.com>
	<Pine.LNX.4.61.0504300702540.19431@gannet.stats>
Message-ID: <42737273.6070404@acelerate.com>

Prof Brian Ripley wrote:

> On Fri, 29 Apr 2005, Kjetil Brinchmann Halvorsen wrote:
>
>> This is rw2010 from CRAN.
>>
>> When running Rcmd check
>> on a package I get:
>>
>> Warning in utils::data(list = al, envir = data_env) :
>>    data set 'vowel.test' not found
>> Warning in utils::data(list = al, envir = data_env) :
>>    data set 'vowel.train' not found
>> Warning in utils::data(list = al, envir = data_env) :
>>    data set 'waveform.test' not found
>> Warning in utils::data(list = al, envir = data_env) :
>>    data set 'waveform.train' not found
>>
>>
>> However, I have no problem with this when using the package.
>>
>> This datasets are loaded, multiple datasets at a time, under another 
>> name.
>> data(vowel)  loads the two first in the list above. Could it be this
>> (which should be allowed, is mentioned in "writing R extensions")
>> or is it something else, or a bug?
>
>
> Such issues are probably best for R-devel.


(changed it)

>
> There is nothing to reproduce here, which could well be considered a 
> bug in your posting.

Yes, indeed. But I did'nt know how to make something reproducible without
attaching the package, which does'nt make sense.

>
> It seems likely that your package's documentation has an alias for 
> 'vowel.test' in a man page marked as \docType{data}, yet 
> data('vowel.test') does not work.

Yes, indeed.  But "Writing R extensions" has:

"If your data files are enormous you can speed up installation by 
providing a file datalist in the data subdirectory. This should have one 
line per topic that |data()| will find, in the format foo if |data(foo)| 
provides foo, or foo: bar bah if |data(foo)| provides bar and bah."

which seems to permite that 
data(vowel)
makes 'vowel.test' available (and 'vowel.train') without making 'vowel' 
available.

And the help for help pages says that only one data object should be 
documented for each help page,
so it seems to be necesary with one help page for 'vowel.test' and one 
for 'vowel.train'.

So what to do?

Kjetil


> That seems like a bug in your package.
> Using LazyData makes such things much more consistent.
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra




-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.

From p.dalgaard at biostat.ku.dk  Sat Apr 30 14:18:08 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat Apr 30 14:18:17 2005
Subject: [Rd] formals assignment now strips attributres
In-Reply-To: <42736B4B.3080507@pburns.seanet.com>
References: <42736B4B.3080507@pburns.seanet.com>
Message-ID: <x2ekcstq4f.fsf@turmalin.kubism.ku.dk>

Patrick Burns <pburns@pburns.seanet.com> writes:

> The assignment form of 'formals' strips attributes (or something close
> to that) from the values in the list.  This wasn't intentional, was it?
> 
> The current behavior (2.0.0 through 2.1.0 on Windows at least):
> 
>  > fjj <- function() x
>  > formals(fjj) <- list(x=c(a=2, b=4))
>  > fjj
> function (x = c(2, 4))
> x
> 
> 
> Previous behavior:
> 
>  > fjj <- function() x
>  > formals(fjj) <- list(x=c(a=2, b=4))
>  > fjj
> function (x = structure(c(2, 4), .Names = c("a", "b")))
> x

It is only a buglet in deparsing:

>  formals(fjj)
$x
a b
2 4
> fjj()
a b
2 4
> as.list(fjj)
$x
a b
2 4

[[2]]
x

BTW, why is it that we cannot deparse named vectors nicely?
> deparse(c(a=1,b=2))
[1] "structure(c(1, 2), .Names = c(\"a\", \"b\"))"
> deparse(as.list(c(a=1,b=2)))
[1] "structure(list(a = 1, b = 2), .Names = c(\"a\", \"b\"))"

Notice also that fjj constructed as above is not identical to 

function (x = c(a = 1, b = 2))
x

since the default expression is a vector in one case and  a call to "c"
in the other. This is part of the problem; you're trying to deparse
something that cannot be the result of parsing. (The existence of such
objects is a generic problem in the R (and S) language).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Sat Apr 30 14:44:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Apr 30 14:44:51 2005
Subject: [Rd] Re: [R] Warning from Rcmd check - data could not find data set
In-Reply-To: <42737273.6070404@acelerate.com>
References: <4272E9D6.7030706@acelerate.com>
	<Pine.LNX.4.61.0504300702540.19431@gannet.stats>
	<42737273.6070404@acelerate.com>
Message-ID: <Pine.LNX.4.61.0504301342380.25534@gannet.stats>

On Sat, 30 Apr 2005, Kjetil Brinchmann Halvorsen wrote:

> Prof Brian Ripley wrote:
>
>> On Fri, 29 Apr 2005, Kjetil Brinchmann Halvorsen wrote:
>> 
>>> This is rw2010 from CRAN.
>>> 
>>> When running Rcmd check
>>> on a package I get:
>>> 
>>> Warning in utils::data(list = al, envir = data_env) :
>>>    data set 'vowel.test' not found
>>> Warning in utils::data(list = al, envir = data_env) :
>>>    data set 'vowel.train' not found
>>> Warning in utils::data(list = al, envir = data_env) :
>>>    data set 'waveform.test' not found
>>> Warning in utils::data(list = al, envir = data_env) :
>>>    data set 'waveform.train' not found
>>> 
>>> 
>>> However, I have no problem with this when using the package.
>>> 
>>> This datasets are loaded, multiple datasets at a time, under another name.
>>> data(vowel)  loads the two first in the list above. Could it be this
>>> (which should be allowed, is mentioned in "writing R extensions")
>>> or is it something else, or a bug?
>> 
>> 
>> Such issues are probably best for R-devel.
>
>
> (changed it)
>
>> 
>> There is nothing to reproduce here, which could well be considered a bug in 
>> your posting.
>
> Yes, indeed. But I did'nt know how to make something reproducible without
> attaching the package, which does'nt make sense.
>
>> 
>> It seems likely that your package's documentation has an alias for 
>> 'vowel.test' in a man page marked as \docType{data}, yet data('vowel.test') 
>> does not work.
>
> Yes, indeed.  But "Writing R extensions" has:
>
> "If your data files are enormous you can speed up installation by providing a 
> file datalist in the data subdirectory. This should have one line per topic 
> that |data()| will find, in the format foo if |data(foo)| provides foo, or 
> foo: bar bah if |data(foo)| provides bar and bah."
>
> which seems to permite that data(vowel)
> makes 'vowel.test' available (and 'vowel.train') without making 'vowel' 
> available.
>
> And the help for help pages says that only one data object should be 
> documented for each help page,
> so it seems to be necesary with one help page for 'vowel.test' and one for 
> 'vowel.train'.
>
> So what to do?

Either

1) Omit the aliases from the help page.

or

2) Use LazyData and document 'vowel.test' and 'vowel.train' on one help 
page.  ?Pima.te in MASS is an example.

>> Using LazyData makes such things much more consistent.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Sat Apr 30 15:37:32 2005
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Sat Apr 30 15:37:40 2005
Subject: [Rd] (PR#7826) Re: ... print.POSIXct .. infinite recursion
Message-ID: <20050430133732.47A319F68@slim.kubism.ku.dk>

Thank you, Jskud.

I can reproduce your problem, though not the
seg.fault, see below

>>>>> "Jskud" == Jskud  <Jskud@Jskud.com>
>>>>>     on Sat, 30 Apr 2005 09:04:03 +0200 (CEST) writes:

    Jskud> In attempting to build R using rpmbuild --rebuild
    Jskud> R-2.1.0-0.fdr.2.fc3.src.rpm

    Jskud> on a fairly up-to-date RedHat 9 system (that is, with
    Jskud> patches installed through May 1 2004), it failed at
    Jskud> the make check-all step.

    Jskud> The problem was reproducible by going into the tests
    Jskud> directory and

    Jskud> 	make test-Segfault

<....>

    Jskud> I was able to reproduce the problem (a segfault) as the following simple
    Jskud> transcript demonstrates: 

    Jskud> LC_ALL=C SRCDIR=. R_DEFAULT_PACKAGES= ../bin/R --vanilla

    Jskud> R : Copyright 2005, The R Foundation for Statistical Computing
    Jskud> Version 2.1.0  (2005-04-18), ISBN 3-900051-07-0

<....>

    >> unusual_but_ok <- c.POSIXlt(character(0))
    >> unusual_but_ok
    Jskud> character(0)
    >> unusual_and_faults <- c.POSIXct(character(0))
    >> unusual_and_faults
    Jskud> Segmentation fault

    Jskud> Running this test program under gdb, we find that we're running off the
    Jskud> end of the stack, with 4222 stack frames showing -- apparently in an
    Jskud> infinite recursion -- "as.character" shows up every 69 function calls:
<........>

    Jskud> So it would seem that *printing* the unusual POSIXct
    Jskud> value is suspect.  

that's correct.

    Jskud> value is suspect.  Looking at a R-1.8.1 install, we
    Jskud> find these definitions in base/R/base:

    Jskud>     print.POSIXct <- function(x, ...)  {
    Jskud> print(format(x, usetz=TRUE), ...)  invisible(x) }

    Jskud>     print.POSIXlt <- function(x, ...)  {
    Jskud> print(format(x, usetz=TRUE), ...)  invisible(x) }

    Jskud> However, looking at the 2.1.0 src file
    Jskud> R-2.1.0/src/library/base/R/datetime.R, we find

    Jskud>     print.POSIXct <- function(x, ...)  {
    Jskud> print(format(x, usetz=TRUE, ...), ...)  invisible(x)
    Jskud> }

    Jskud>     print.POSIXlt <- function(x, ...)  {
    Jskud> print(format(x, usetz=TRUE), ...)  invisible(x) }

    Jskud> Note the suspicious definition of print.POSIXct using
    Jskud> *two* sets of ellipses, and that the print.POSIXct
    Jskud> and print.POSIXlt definitions no longer match.

well, passing the "..." to both format() and print()
is probably on purpose -- and I assume even fixes another bug.  
You are right however in wondering, why this is done only in
print.*ct() and not in print.*lt().

The infinite recursion, BTW, happens with format(), not print()...:
Here is the end of the stack you get from 
traceback(), after e.g. options(expressions = 50)

13: structure(format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...), 
        names = names(x))
12: format.POSIXct(x, ...)
11: format(x, ...)
10: as.character.POSIXt(x)
9: as.character(x)
8: strptime(x, f)
7: fromchar(x)
6: as.POSIXlt(x, tz)
5: inherits(x, "POSIXlt")
4: format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...)
3: structure(format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...), 
       names = names(x))
2: format.POSIXct(unusual_and_faults, usetz = TRUE)
1: format(unusual_and_faults, usetz = TRUE)

- - - 
Unfortunately, I must do less fun things at the moment than
fixing such a bug...  but of course it *will* be fixed rather
sooner than later.

Martin Maechler, ETH Zurich

From znmeb at cesmail.net  Sat Apr 30 19:04:49 2005
From: znmeb at cesmail.net (M. Edward (Ed) Borasky)
Date: Sat Apr 30 19:05:12 2005
Subject: [Rd] as.numeric method for objects of class "difftime"
In-Reply-To: <B998A44C8986644EA8029CFE6396A9241B32C5@exqld2-bne.qld.csiro.au>
References: <B998A44C8986644EA8029CFE6396A9241B32C5@exqld2-bne.qld.csiro.au>
Message-ID: <4273BAB1.3020407@cesmail.net>

Yes, this bit me just about a week ago. I subtracted the start time from
the end time of a benchmark, and it came back with a duration in
minutes, so I assumed it always yielded minutes and coded accordingly.
If left to its own choices, a benchmark over an hour came back in hours,
and one of the benchmarks ran three hours. So I had benchmark durations
of 30, 30, 30, 30, 30, ... 3.

The difftime function does have an optional argument to force the units
to your choice, which in my case was seconds. I should have read the
manual, discovered you could pick your units, and done so, which I did
eventually. So I would definitely put a warning in the difftime
documentation. The whole process only cost me an hour, though -- not a
great loss of time. Well, maybe 3607 seconds ...

<ducking>

Bill.Venables@csiro.au wrote:

>I have just become painfully aware that objects of class "difftime",
>generated by the difference of two POSIXct objects, carry a "units"
>attribute, which flashes by when the object is printed, for example.
>
>The pain was occasioned when I tried to turn these objects into numberic
>objects for use elsewhere as a covariate.  
>
>as.numeric(difftime object)
>
>simply turns off the units attribute and provides a numeric object which
>may represent a number of seconds or a number of days, with no warning
>as to which.
>
>I think this is an unfortunate situation, but I can't see how to rectify
>it without breaking code that may rely on this quirky feature.  My
>inclination is to suggest a method for as.numeric (ie for as.double)
>that settles on a single unit, which for consistency with
>as.numeric(POSIXct object) should probably be seconds:
>
>as.double.difftime <- function(x, ...)
>  if(attr(x, "units") == "days") as.vector(x) * 86400 else as.vector(x)
>
>but there must now be lots of code out there that has blythely assumed
>that the difference will always be a number of days and others assume it
>is always seconds.
>
>At the very least I think the help information should carry a big red
>warning about this rather unusual feature.  (It may, I suppose, but I
>couldn't find it.)
>
>Comments?
>
>Bill Venables, 
>CMIS, CSIRO Laboratories, 
>PO Box 120, Cleveland, Qld. 4163
>AUSTRALIA
>Phone:  +61 7 3826 7251  
>Fax:    +61 7 3826 7304
>Mobile: +61 4 1963 4642
>Home:   +61 7 3286 7700
>mailto:Bill.Venables@csiro.au
>http://www.cmis.csiro.au/bill.venables/
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>
>  
>

From Jskud at Jskud.com  Sat Apr 30 19:55:45 2005
From: Jskud at Jskud.com (Jskud@Jskud.com)
Date: Sat Apr 30 19:55:52 2005
Subject: (PR#7826) [Rd] segfault during build of 2.1.0 on RH9;
	print.POSIXct
Message-ID: <20050430175545.1EA2BA1CA@slim.kubism.ku.dk>

   Date: Sat, 30 Apr 2005 10:47:06 +0100 (BST)
   From: Prof Brian Ripley <ripley@stats.ox.ac.uk>

Thank you for the rapid and helpful reply.	

   1) Why did you submit this *twice*, as PR#7826 and PR#7827?  Please don't 
   be so careless of the volunteers' time.

I noticed that the email I originally sent to R-bugs@R-project.org was
timing out while connecting to hypatia.ethz.ch. [129.132.145.15].
Checking the R-project web page, I found that the recommended address is
r-bugs@biostat.ku.dk; hence, I resent the email to the recommended
address.  I did not intend to waste the volunteers' time, nor to annoy
any of them, and I'm sorry if that happened.

   2) > print.POSIXct
   function (x, ...)
   {
	print(format(x, usetz = TRUE, ...), ...)
	invisible(x)
   }

   is definitely *not* implicated.  (Use of ... in two places is correct.)

I thought use of ... in two places might be incorrect for two reasons.
(1) It would seem to supply the same arguments to both print and format
-- it is not clear that all trailing arguments to print.POSIXct should
go to both routines. (2)  If it is correct to use ... in two places for
print.POSIXct, then why not for print.POSIXlt?

   3) On FC3:

   > unusual_and_faults
   Error: protect(): protection stack overflow
   > format(unusual_and_faults)
   Error: protect(): protection stack overflow
   > as.POSIXlt(unusual_and_faults)
   Error: protect(): protection stack overflow

   which is what should happen.  It looks like RH9 has an inadequate stack 
   size for the new recursion limits of R 2.1.0.  This is nothing whatsoever 
   to do with print.POSIXct.

You are correct -- to deal with problems in other software that I use, I
had reduced my allowed stack size to 1 MB in my .bashrc, and forgotten
about it.  Building R (actually, running the tests) requires a larger
stack.  So it was a user problem, not a RH9 problem.  

   The problem is in fact in c.POSIXct which is not checking its arguments.

Sincerely,

/Jskud

From pburns at pburns.seanet.com  Sat Apr 30 22:28:10 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat Apr 30 22:29:05 2005
Subject: [Rd] formals assignment now strips attributres
In-Reply-To: <x2ekcstq4f.fsf@turmalin.kubism.ku.dk>
References: <42736B4B.3080507@pburns.seanet.com>
	<x2ekcstq4f.fsf@turmalin.kubism.ku.dk>
Message-ID: <4273EA5A.2060503@pburns.seanet.com>

Peter Dalgaard wrote:

>Patrick Burns <pburns@pburns.seanet.com> writes:
>
>  
>
>>The assignment form of 'formals' strips attributes (or something close
>>to that) from the values in the list.  This wasn't intentional, was it?
>>
>>The current behavior (2.0.0 through 2.1.0 on Windows at least):
>>
>> > fjj <- function() x
>> > formals(fjj) <- list(x=c(a=2, b=4))
>> > fjj
>>function (x = c(2, 4))
>>x
>>
>>
>>Previous behavior:
>>
>> > fjj <- function() x
>> > formals(fjj) <- list(x=c(a=2, b=4))
>> > fjj
>>function (x = structure(c(2, 4), .Names = c("a", "b")))
>>x
>>    
>>
>
>It is only a buglet in deparsing:
>
>  
>
>> formals(fjj)
>>    
>>
>$x
>a b
>2 4
>  
>
>>fjj()
>>    
>>
>a b
>2 4
>

But the buglet gets more aggressive if you edit the function:

 > fjj <- function() x
 > formals(fjj) <- list(x=c(a=2, b=4))
 > fjj
function (x = c(2, 4))
x
 > fjj()
a b
2 4
 > fix(fjj) # do nothing but save
 > fjj()
[1] 2 4

I'm quite sure that I wouldn't have noticed if my real function were
not broken.

Now I know that my functions will work if I assign the formals after I 
edit the
function -- even though they look like they shouldn't work.

>  
>
>>as.list(fjj)
>>    
>>
>$x
>a b
>2 4
>
>[[2]]
>x
>
>BTW, why is it that we cannot deparse named vectors nicely?
>  
>
>>deparse(c(a=1,b=2))
>>    
>>
>[1] "structure(c(1, 2), .Names = c(\"a\", \"b\"))"
>  
>
>>deparse(as.list(c(a=1,b=2)))
>>    
>>
>[1] "structure(list(a = 1, b = 2), .Names = c(\"a\", \"b\"))"
>
>Notice also that fjj constructed as above is not identical to 
>
>function (x = c(a = 1, b = 2))
>x
>
>since the default expression is a vector in one case and  a call to "c"
>in the other. This is part of the problem; you're trying to deparse
>something that cannot be the result of parsing. (The existence of such
>objects is a generic problem in the R (and S) language).
>
>  
>

From p.dalgaard at biostat.ku.dk  Sat Apr 30 22:39:57 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat Apr 30 22:40:06 2005
Subject: [Rd] formals assignment now strips attributres
In-Reply-To: <4273EA5A.2060503@pburns.seanet.com>
References: <42736B4B.3080507@pburns.seanet.com>
	<x2ekcstq4f.fsf@turmalin.kubism.ku.dk>
	<4273EA5A.2060503@pburns.seanet.com>
Message-ID: <x23bt8t2w2.fsf@turmalin.kubism.ku.dk>

Patrick Burns <pburns@pburns.seanet.com> writes:

> But the buglet gets more aggressive if you edit the function:
> 
>  > fjj <- function() x
>  > formals(fjj) <- list(x=c(a=2, b=4))
>  > fjj
> function (x = c(2, 4))
> x
>  > fjj()
> a b
> 2 4
>  > fix(fjj) # do nothing but save
>  > fjj()
> [1] 2 4
> 
> I'm quite sure that I wouldn't have noticed if my real function were
> not broken.
> 
> Now I know that my functions will work if I assign the formals after I
> edit the
> function -- even though they look like they shouldn't work.

You did invite trouble by creating and subsequently a function that
_has_ no source representation though:

> fjj <- function() x
> formals(fjj) <- list(x=quote(c(a=2, b=4)))
> fjj()
a b
2 4
> fix(fjj)
> fjj()
a b
2 4
> fjj
function (x = c(a = 2, b = 4))
x


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

