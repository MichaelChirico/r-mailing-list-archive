From evelynpax at yahoo.com  Fri Jan  1 09:41:03 2016
From: evelynpax at yahoo.com (Evelyn Nyamadi)
Date: Fri, 1 Jan 2016 08:41:03 +0000 (UTC)
Subject: [R-SIG-Finance] Forecasting with nnetar
In-Reply-To: <1388556763.4297241.1451555808819.JavaMail.yahoo@mail.yahoo.com>
References: <1388556763.4297241.1451555808819.JavaMail.yahoo.ref@mail.yahoo.com>
	<1388556763.4297241.1451555808819.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1587831987.4566343.1451637663454.JavaMail.yahoo@mail.yahoo.com>


Dear? All,
Please, I would like to use the nnetar in the forecast package to do both in sample and out of sample forecasting. 

But what is package does is not very clear to me. It gives you rather an extrapolated forecast.
Just using this example:
fit <- nnetar(lynx)
fcast <- forecast(fit)
plot(fcast)

How can you go about the in-sample and out-of-sample forecast.

Thanks in advance for your kind response.

Wishing you a happy new year.

Best regards,
Evelyn

 

      From: Evelyn Nyamadi <evelynpax at yahoo.com>
 To: "Rob.Hyndman at monash.edu" <Rob.Hyndman at monash.edu> 
 Sent: Thursday, December 31, 2015 10:56 AM
 Subject: Forecasting with nnetar
   
Dear? Sir,
Please, I would like to use the nnetar in the forecast package to do both in sample and out of sample forecasting. 

But what is package does is not very clear to me. It gives you rather an extrapolated forecast.
Just using this example:
fit <- nnetar(lynx)
fcast <- forecast(fit)
plot(fcast)

How can you go about the in-sample and out-of-sample forecast.

Thanks in advance for your kind response.

Wishing you a happy new year.

Best regards,
Evelyn





  
	[[alternative HTML version deleted]]


From michael.weylandt at gmail.com  Fri Jan  1 21:30:11 2016
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Fri, 1 Jan 2016 14:30:11 -0600
Subject: [R-SIG-Finance] Forecasting with nnetar
In-Reply-To: <1587831987.4566343.1451637663454.JavaMail.yahoo@mail.yahoo.com>
References: <1388556763.4297241.1451555808819.JavaMail.yahoo.ref@mail.yahoo.com>
	<1388556763.4297241.1451555808819.JavaMail.yahoo@mail.yahoo.com>
	<1587831987.4566343.1451637663454.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAmySGO45rr6P91_e8Kbpwk_So4G7FrnZW7SyOi7kdGHTz8wYQ@mail.gmail.com>

On Fri, Jan 1, 2016 at 2:41 AM, Evelyn Nyamadi via R-SIG-Finance
<r-sig-finance at r-project.org> wrote:
>
> Dear  All,
> Please, I would like to use the nnetar in the forecast package to do both in sample and out of sample forecasting.
>
> But what is package does is not very clear to me. It gives you rather an extrapolated forecast.
> Just using this example:
> fit <- nnetar(lynx)
> fcast <- forecast(fit)
> plot(fcast)
>
> How can you go about the in-sample and out-of-sample forecast.
>

This post from Rob's blog may help:
http://robjhyndman.com/hyndsight/rolling-forecasts/

Michael


From samitpaulin at gmail.com  Mon Jan  4 11:31:54 2016
From: samitpaulin at gmail.com (Samit Paul)
Date: Mon, 4 Jan 2016 16:01:54 +0530
Subject: [R-SIG-Finance] Formula used for EGARCH in "rugarch" package
Message-ID: <CALROeVFU1DQ1CmThHeoQO_6pAgmiDEoq6DK3EEJNqojehBR3hw@mail.gmail.com>

Dear R users,

I am using "rugarch" package while fitting ARMA(1,1) - EGARCH (1,1) to a
dataset. The coefficient of leverage ("gamma") is coming as positive ,
while other softwares (say, Eviews, SPSS) is giving the same as negative.
The absolute value of the coefficient is almost same. It seems, that the
formula built in R for EGARCH in "rugarch" package, perhaps depicting the
leverage effect in different sign.

Could you please help me to get the formula used for EGARCH in "ruagrch"
package?

Thanks in advance,

Samit Paul

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Mon Jan  4 15:54:31 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 4 Jan 2016 08:54:31 -0600
Subject: [R-SIG-Finance] R/Finance 2016 Call for Papers
In-Reply-To: <CAPPM_gSgYv3=9Eu=0jvi2SYNes3nDdJh8iZm9isB6nynQ7qG8w@mail.gmail.com>
References: <CAPPM_gSgYv3=9Eu=0jvi2SYNes3nDdJh8iZm9isB6nynQ7qG8w@mail.gmail.com>
Message-ID: <CAPPM_gSvo=1tohLEbAXBFnGZs2LoJTRV-JEXuX-jbHV7-Ljttg@mail.gmail.com>

A friendly reminder that the submission deadline (January 29, 2016) is
less than a month away!

On Thu, Oct 15, 2015 at 11:02 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> Call for Papers:
>
> R/Finance 2016: Applied Finance with R
> May 20 and 21, 2016
> University of Illinois at Chicago
>
> The eighth annual R/Finance conference for applied finance using R
> will be held on May 20 and 21, 2016 in Chicago, IL, USA at the
> University of Illinois at Chicago.  The conference will cover topics
> including portfolio management, time series analysis, advanced risk
> tools, high-performance computing, market microstructure, and
> econometrics.  All will be discussed within the context of using R as
> a primary tool for financial risk management, portfolio construction,
> and trading.
>
> Over the past seven years, R/Finance has included attendees from
> around the world.  It has featured presentations from prominent
> academics and practitioners, and we anticipate another exciting
> line-up for 2016.
>
> We invite you to submit complete papers in pdf format for
> consideration.  We will also consider one-page abstracts (in txt or
> pdf format) although more complete papers are preferred.  We welcome
> submissions for both full talks and abbreviated "lightning talks."
> Both academic and practitioner proposals related to R are encouraged.
>
> All slides will be made publicly available at conference time.
> Presenters are strongly encouraged to provide working R code to
> accompany the slides.  Data sets should also be made public for the
> purposes of reproducibility (though we realize this may be limited due
> to contracts with data vendors).  Preference may be given to
> presenters who have released R packages.
>
> The conference will award two (or more) $1000 prizes for best papers.
> A submission must be a full paper to be eligible for a best paper
> award.  Extended abstracts, even if a full paper is provided by
> conference time, are not eligible for a best paper award.  Financial
> assistance for travel and accommodation may be available to
> presenters, however requests must be made at the time of submission.
> Assistance will be granted at the discretion of the conference
> committee.
>
> Please make your submission online at: http://www.cvent.com/d/3fqnb8.
>
> The submission deadline is January 29, 2016.  Submitters will be
> notified via email by February 29, 2016 of acceptance, presentation
> length, and financial assistance (if requested).
>
> Additional details will be announced via the conference website
>
> http://www.RinFinance.com/
>
> as they become available.  Information on previous years' presenters
> and their presentations are also at the conference website.  We will
> make a separate announcement when registration opens.
>
> For the program committee:
> Gib Bassett, Peter Carl, Dirk Eddelbuettel, Brian Peterson, Dale
> Rosenthal, Jeffrey Ryan, Joshua Ulrich
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From michael.weylandt at gmail.com  Mon Jan  4 15:56:35 2016
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Mon, 4 Jan 2016 08:56:35 -0600
Subject: [R-SIG-Finance] Formula used for EGARCH in "rugarch" package
In-Reply-To: <CALROeVFU1DQ1CmThHeoQO_6pAgmiDEoq6DK3EEJNqojehBR3hw@mail.gmail.com>
References: <CALROeVFU1DQ1CmThHeoQO_6pAgmiDEoq6DK3EEJNqojehBR3hw@mail.gmail.com>
Message-ID: <CAAmySGOaPjeuiYA-AFMzNNxxU2ici+jfjYQJURvTytoVUfDHmA@mail.gmail.com>

Take a look at Section 2.2.3 of the package vignette [1, 2].

Michael

[1] https://cran.r-project.org/web/packages/rugarch/vignettes/Introduction_to_the_rugarch_package.pdf
[2] https://bitbucket.org/alexiosg/rugarch/src/1bf0f673286b22124fe3a55dfd79d94b3169fb6b/vignettes/rugarch.tex?at=master&fileviewer=file-view-default#rugarch.tex-226

On Mon, Jan 4, 2016 at 4:31 AM, Samit Paul <samitpaulin at gmail.com> wrote:
> Dear R users,
>
> I am using "rugarch" package while fitting ARMA(1,1) - EGARCH (1,1) to a
> dataset. The coefficient of leverage ("gamma") is coming as positive ,
> while other softwares (say, Eviews, SPSS) is giving the same as negative.
> The absolute value of the coefficient is almost same. It seems, that the
> formula built in R for EGARCH in "rugarch" package, perhaps depicting the
> leverage effect in different sign.
>
> Could you please help me to get the formula used for EGARCH in "ruagrch"
> package?
>
> Thanks in advance,
>
> Samit Paul
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From samitpaulin at gmail.com  Mon Jan  4 16:38:21 2016
From: samitpaulin at gmail.com (Samit Paul)
Date: Mon, 4 Jan 2016 21:08:21 +0530
Subject: [R-SIG-Finance] Formula used for EGARCH in "rugarch" package
In-Reply-To: <CAAmySGOaPjeuiYA-AFMzNNxxU2ici+jfjYQJURvTytoVUfDHmA@mail.gmail.com>
References: <CALROeVFU1DQ1CmThHeoQO_6pAgmiDEoq6DK3EEJNqojehBR3hw@mail.gmail.com>
	<CAAmySGOaPjeuiYA-AFMzNNxxU2ici+jfjYQJURvTytoVUfDHmA@mail.gmail.com>
Message-ID: <CALROeVHYdJLXoF2K_CZ+KRGY22AtvcRa0MpgMMEi=E3x_DpGzQ@mail.gmail.com>

Thanks a lot, Michael, Cheers!!

Samit

On Mon, Jan 4, 2016 at 8:26 PM, Michael Weylandt <michael.weylandt at gmail.com
> wrote:

> Take a look at Section 2.2.3 of the package vignette [1, 2].
>
> Michael
>
> [1]
> https://cran.r-project.org/web/packages/rugarch/vignettes/Introduction_to_the_rugarch_package.pdf
> [2]
> https://bitbucket.org/alexiosg/rugarch/src/1bf0f673286b22124fe3a55dfd79d94b3169fb6b/vignettes/rugarch.tex?at=master&fileviewer=file-view-default#rugarch.tex-226
>
> On Mon, Jan 4, 2016 at 4:31 AM, Samit Paul <samitpaulin at gmail.com> wrote:
> > Dear R users,
> >
> > I am using "rugarch" package while fitting ARMA(1,1) - EGARCH (1,1) to a
> > dataset. The coefficient of leverage ("gamma") is coming as positive ,
> > while other softwares (say, Eviews, SPSS) is giving the same as negative.
> > The absolute value of the coefficient is almost same. It seems, that the
> > formula built in R for EGARCH in "rugarch" package, perhaps depicting the
> > leverage effect in different sign.
> >
> > Could you please help me to get the formula used for EGARCH in "ruagrch"
> > package?
> >
> > Thanks in advance,
> >
> > Samit Paul
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From verial.damon at gmail.com  Thu Jan  7 14:45:54 2016
From: verial.damon at gmail.com (Damon Verial)
Date: Thu, 7 Jan 2016 22:45:54 +0900
Subject: [R-SIG-Finance] Exit Timing in Quantstrat
Message-ID: <CA+3g=Df47kek0BtPQRzkMjVu6tAsvVaUDNQ289eN75qvOueNPw@mail.gmail.com>

Let's say I want to exit a certain number of days after I see a certain
candlestick pattern. How would I do this in quantstrat? I have the
candlestick pattern programming down, but I don't know how to make the exit
rule align with the candlestick pattern.

Assume I have an indicator called "candlestick." How would I assign the
signal and rule to exit X days after seeing the indicator?

Damon Verial
Office: (206) 395-3688
Skype: DamonVerial
YouTube Channel <https://www.youtube.com/channel/UChoZqpn_fLmoExx2g4KL58A>
Is Altria Group a Quality Investment?
<http://seekingalpha.com/article/3788476-is-altria-group-a-quality-investment>
I purposely keep my emails to 5 sentences or fewer - which is a miracle for
a writer.
I do this to show that I respect both your time and mine.

	[[alternative HTML version deleted]]


From brian at braverock.com  Thu Jan  7 14:52:35 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 07 Jan 2016 07:52:35 -0600
Subject: [R-SIG-Finance] Exit Timing in Quantstrat
In-Reply-To: <CA+3g=Df47kek0BtPQRzkMjVu6tAsvVaUDNQ289eN75qvOueNPw@mail.gmail.com>
References: <CA+3g=Df47kek0BtPQRzkMjVu6tAsvVaUDNQ289eN75qvOueNPw@mail.gmail.com>
Message-ID: <1452174755.14030.46.camel@brian-rcg>

use lag() as your signal function.

e.g.

x<-xts(sample(c(rep(0,5),1),100,replace=TRUE),as.Date(1:100))
cbind(x,lag(x,-5))

the second column demonstrates your signal column.

Regards,

Brian

On Thu, 2016-01-07 at 22:45 +0900, Damon Verial wrote:
> Let's say I want to exit a certain number of days after I see a certain
> candlestick pattern. How would I do this in quantstrat? I have the
> candlestick pattern programming down, but I don't know how to make the exit
> rule align with the candlestick pattern.
> 
> Assume I have an indicator called "candlestick." How would I assign the
> signal and rule to exit X days after seeing the indicator?
> 
> Damon Verial
> Office: (206) 395-3688
> Skype: DamonVerial
> YouTube Channel <https://www.youtube.com/channel/UChoZqpn_fLmoExx2g4KL58A>
> Is Altria Group a Quality Investment?
> <http://seekingalpha.com/article/3788476-is-altria-group-a-quality-investment>
> I purposely keep my emails to 5 sentences or fewer - which is a miracle for
> a writer.
> I do this to show that I respect both your time and mine.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From scottnichols at hotmail.com  Mon Jan 11 22:49:27 2016
From: scottnichols at hotmail.com (Scott Nichols)
Date: Mon, 11 Jan 2016 15:49:27 -0600
Subject: [R-SIG-Finance] Rbbg includeConditionCodes not returning codes
Message-ID: <BLU176-W19E1B30BAFA1560D25A3ECCC90@phx.gbl>

Hi,
Here is a snippet of code, I'm trying tick() and i would expect valid condition codes to be returned, but there is nothing after 'Size'.  Is there another way I should be calling the option name to return the condition codes?
symbol <-  "WNH6 Comdty"local.times <- as.POSIXct(c("2016-01-11 15:28:00", "2016-01-11 15:30:00"), format="%Y-%m-%d %H:%M:%S") bbg.times <- strftime(local.times, "%Y-%m-%d %H:%M:%S.000", tz="UTC") tick(conn, symbol, "TRADE", bbg.times[1], bbg.times[2], option_names = "includeConditionCodes", option_values = "TRUE")
                                         time  type      value          size1  2016-01-11T21:28:47.000 TRADE 159.9688    52  2016-01-11T21:28:47.000 TRADE 159.9688    23  2016-01-11T21:28:47.000 TRADE 159.9688    24  2016-01-11T21:28:47.000 TRADE 159.9688    15  2016-01-11T21:28:47.000 TRADE 159.9688    46  2016-01-11T21:28:47.000 TRADE 159.9688    37  2016-01-11T21:28:47.000 TRADE 159.9688    18  2016-01-11T21:28:47.000 TRADE 159.9375    59  2016-01-11T21:28:47.000 TRADE 159.9375    410 2016-01-11T21:28:47.000 TRADE 159.9375    211 2016-01-11T21:28:47.000 TRADE 159.9375    112 2016-01-11T21:28:52.000 TRADE 159.9375   2813 2016-01-11T21:29:31.000 TRADE 159.9375   2914 2016-01-11T21:29:31.000 TRADE 159.9375    115 2016-01-11T21:29:31.000 TRADE 159.9375    116 2016-01-11T21:29:31.000 TRADE 159.9375    117 2016-01-11T21:29:31.000 TRADE 159.9375    118 2016-01-11T21:30:00.000 TRADE 159.9375    1
Thanks!Scott 		 	   		  
	[[alternative HTML version deleted]]


From scottnichols at hotmail.com  Tue Jan 12 00:36:18 2016
From: scottnichols at hotmail.com (Scott Nichols)
Date: Mon, 11 Jan 2016 17:36:18 -0600
Subject: [R-SIG-Finance] Rbbg includeConditionCodes not returning codes
In-Reply-To: <BLU176-W19E1B30BAFA1560D25A3ECCC90@phx.gbl>
References: <BLU176-W19E1B30BAFA1560D25A3ECCC90@phx.gbl>
Message-ID: <BLU176-W23FAF8AF38A3EFA88929FCCCC90@phx.gbl>



Hi,

Here is a snippet of code, I'm trying tick() and i would expect valid condition codes to be returned, but there is nothing after 'Size'.  Is there another way I should be calling the option name to return the condition codes?

symbol <-  "WNH6 Comdty"
local.times <- as.POSIXct(c("2016-01-11 15:28:00", "2016-01-11 15:30:00"), format="%Y-%m-%d %H:%M:%S") 
bbg.times <- strftime(local.times, "%Y-%m-%d %H:%M:%S.000", tz="UTC") 
tick(conn, symbol, "TRADE", bbg.times[1], bbg.times[2], option_names = "includeConditionCodes", option_values = "TRUE")

                                         time  type      value          size
1  2016-01-11T21:28:47.000 TRADE 159.9688    5
2  2016-01-11T21:28:47.000 TRADE 159.9688    2
3  2016-01-11T21:28:47.000 TRADE 159.9688    2
4  2016-01-11T21:28:47.000 TRADE 159.9688    1
5  2016-01-11T21:28:47.000 TRADE 159.9688    4
6  2016-01-11T21:28:47.000 TRADE 159.9688    3
7  2016-01-11T21:28:47.000 TRADE 159.9688    1
8  2016-01-11T21:28:47.000 TRADE 159.9375    5
9  2016-01-11T21:28:47.000 TRADE 159.9375    4
10 2016-01-11T21:28:47.000 TRADE 159.9375    2
11 2016-01-11T21:28:47.000 TRADE 159.9375    1
12 2016-01-11T21:28:52.000 TRADE 159.9375   28
13 2016-01-11T21:29:31.000 TRADE 159.9375   29
14 2016-01-11T21:29:31.000 TRADE 159.9375    1
15 2016-01-11T21:29:31.000 TRADE 159.9375    1
16 2016-01-11T21:29:31.000 TRADE 159.9375    1
17 2016-01-11T21:29:31.000 TRADE 159.9375    1
18 2016-01-11T21:30:00.000 TRADE 159.9375    1

Thanks!
Scott 		 	   		  
	[[alternative HTML version deleted]]


From samitpaulin at gmail.com  Fri Jan 15 08:27:53 2016
From: samitpaulin at gmail.com (Samit Paul)
Date: Fri, 15 Jan 2016 12:57:53 +0530
Subject: [R-SIG-Finance] Markov Switching GARCH
Message-ID: <CALROeVEgrbyrUnRA8B+b6HoYNQpjORR-VDe6iyWNKhM05epJWg@mail.gmail.com>

Dear users,

I want to forecast 1 step ahead mean and variance forecast of a return
series using Markov's Regime Switching GARCH specification.

Can anybody provide me the codes or suitable R package for that?

Thank you and have a nice year ahead,

Regards,

Samit

	[[alternative HTML version deleted]]


From samuelandjw at gmail.com  Sun Jan 17 16:48:13 2016
From: samuelandjw at gmail.com (Degang WU)
Date: Sun, 17 Jan 2016 23:48:13 +0800
Subject: [R-SIG-Finance] how to enter coefficient matrices of a VAR into
	dse::ARMA?
Message-ID: <6841899C-AA8E-4260-BD98-64F6B2AE34AB@gmail.com>

Hi,

Suppose I have a VAR(p) process with known coefficient matrices

y_t = A_1 y_{t-1} + A_2 y_{t-2} + .. A_p y_{t-p} + e_t

where {y_i} are vectors, {A_i} are coefficient matrices and e_t is white noise.

Now I want to enter the coefficient matrices into dse::ARMA.

However, dse::ARMA requires writing the process in the form of 

A(L)y(t) = B(L)w(t) + C(L)u(t) + TREND(t),

where A(L)=I - \sum_i A_i L^i, where L is the lag operator.

I have no idea how to write the lag operator as a numerical matrix.

The documentation of dse::ARMA future states that A is a

(axpxp) is the auto-regressive polynomial array.

which is even more confusing.

The example in the documentation is

AR   <- array(c(1, .5, .3, 0, .2, .1, 0, .2, .05, 1, .5, .3) ,c(3,2,2))
VAR  <- ARMA(A=AR, B=diag(1,2))

However, the example does not mention what the coefficient matrices {A_i} look like in the first place, so it does not help at all.

So my question is, how to write the matrix A dse::ARMA requires in terms of known coefficient matrices {A_i}?

Regards,
Degang Wu
	[[alternative HTML version deleted]]


From sheila_aziz at yahoo.com  Mon Jan 18 15:26:16 2016
From: sheila_aziz at yahoo.com (sheila aziz)
Date: Mon, 18 Jan 2016 14:26:16 +0000 (UTC)
Subject: [R-SIG-Finance] Copula GARCH forecasting
References: <1927660169.5410676.1453127176389.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1927660169.5410676.1453127176389.JavaMail.yahoo@mail.yahoo.com>

Hi,?I?m trying to forecast the Copula Garch Model for portfolio optimization. I have tried to use the dccforecast function with the cgarchfit function but it turns out to be error saying that there is no applicable method for dccforecast applied to an object of class cGARCHfit. So, how do we actually forecast the dcc copula garch model? Is there any other package that I should look at other than ?rmgarch???For instance, I have the following code:-?library(zoo)library(rugarch)library(rmgarch)data("EuStockMarkets")EuStockLevel <- as.zoo(EuStockMarkets)[,c("DAX","CAC","FTSE")]EuStockRet <- diff(log(EuStockLevel))?# DCC timecopula MVN?uspec = ugarchspec(mean.model = list(armaOrder = c(0,0)), variance.model = list(garchOrder = c(1,1), model = "sGARCH", variance.targeting=FALSE), distribution.model = "norm")spec1 = cgarchspec(uspec = multispec( replicate(3, uspec) ), asymmetric = TRUE,? distribution.model = list(copula = "mvnorm", method = "Kendall", time.varying = TRUE, transformation = "parametric"))fit1 = cgarchfit(spec1, data = EuStockRet, cluster = NULL, solver.control=list(trace=1))print(fit1)??#Forecastingfit.copula = cgarchfit(spec1, data = EuStockRet, out.sample = 12, solver = "solnp", solver.control =list(),fit.control = list(eval.se = TRUE, stationarity = TRUE, scale = FALSE),cluster = NULL, fit =NULL, VAR.fit = NULL)dcc.copula.focast=dccforecast(fit.copula, n.ahead = 1, n.roll = 0)?## Error in UseMethod("dccforecast") : no applicable method for 'dccforecast' applied to an object of class "c('cGARCHfit', 'mGARCHfit', 'GARCHfit', 'rGARCH')"?I need to forecast the copula garch model so that I can get the forecasted variance covariance matrix and also the forecasted mean value from the fitted model.?covmat.copula.focast= rcov(dcc.copula.focast)? ##Forecasted Covariance matrixmean.copula.focast = fitted(dcc.copula.focast)? ##Mean forecast matrix array?Appreciate if anyone can assist me on this matter.?Thank you..


	[[alternative HTML version deleted]]


From pgilbert902 at gmail.com  Mon Jan 18 16:18:06 2016
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Mon, 18 Jan 2016 10:18:06 -0500
Subject: [R-SIG-Finance] how to enter coefficient matrices of a VAR into
 dse::ARMA?
In-Reply-To: <6841899C-AA8E-4260-BD98-64F6B2AE34AB@gmail.com>
References: <6841899C-AA8E-4260-BD98-64F6B2AE34AB@gmail.com>
Message-ID: <569D022E.2000905@gmail.com>



On 01/17/2016 10:48 AM, Degang WU wrote:
> Hi,
>
> Suppose I have a VAR(p) process with known coefficient matrices
>
> y_t = A_1 y_{t-1} + A_2 y_{t-2} + .. A_p y_{t-p} + e_t

  y_t = A_1 y_{t-1} + A_2 y_{t-2} + .. A_p y_{t-p} + e_t  (1)

>
> where {y_i} are vectors, {A_i} are coefficient matrices and e_t is
> white noise.
>
> Now I want to enter the coefficient matrices into dse::ARMA.
>
> However, dse::ARMA requires writing the process in the form of
>
> A(L)y(t) = B(L)w(t) + C(L)u(t) + TREND(t),
>
> where A(L)=I - \sum_i A_i L^i, where L is the lag operator.
>
> I have no idea how to write the lag operator as a numerical matrix.

The lag operator is strictly notational. Writing (1) in the dse 
convention would be

  y_t + A_1 y_{t-1} + A_2 y_{t-2} + .. A_p y_{t-p} = e_t  (2)

so you need to change the sign on all but the zero lag y coefficient 
when you convert from (1) to (2). Beware that one consequence of this is 
that roots are inverted relative to the unit circle, so stable models 
will be inside rather than outside.

[BTW, while (1) may be more widely used and intuitive to practitioners, 
(2) has a big advantage for theoretical work: A(L) is a standard matrix 
of polynomials, thus a ring, and some heavy mathematical machinery can 
be applied.]

>
> The documentation of dse::ARMA future states that A is a
>
> (axpxp) is the auto-regressive polynomial array.
>
> which is even more confusing.

You point out a technical mistake in the wording, but I doubt that is 
the source of your confusion. Technically, A is a pxp matrix, with 
elements that are polynomials. A polynomial of degree a-1 is represented 
by its a coefficients so A becomes an axpxp array in R.

>
> The example in the documentation is
>
> AR   <- array(c(1, .5, .3, 0, .2, .1, 0, .2, .05, 1, .5, .3)
> ,c(3,2,2)) VAR  <- ARMA(A=AR, B=diag(1,2))
>
> However, the example does not mention what the coefficient matrices
> {A_i} look like in the first place, so it does not help at all.

You can print these out:

 >  AR <- array(c(1, .5, .3, 0, .2, .1, 0, .2, .05, 1, .5, .3)
           ,c(3,2,2))

 >  VAR  <- ARMA(A=AR, B=diag(1,2))

 > VAR

A(L) =
1+0.5L1+0.3L2    0+0.2L1+0.05L2
0+0.2L1+0.1L2    1+0.5L1+0.3L2

B(L) =
1    0
0    1


 > AR

, , 1

      [,1] [,2]
[1,]  1.0  0.0
[2,]  0.5  0.2
[3,]  0.3  0.1

, , 2

      [,1] [,2]
[1,] 0.00  1.0
[2,] 0.20  0.5
[3,] 0.05  0.3

 > AR[1,,]

      [,1] [,2]
[1,]    1    0
[2,]    0    1

>
> So my question is, how to write the matrix A dse::ARMA requires in
> terms of known coefficient matrices {A_i}?

If the above is not enough then I would suggest reading up a bit more on 
R. Once-upon-a-time I included an R/S tutorial in the dse documentation, 
but I removed that a long time ago because there are much better ones 
available.

HTH,
Paul

>
> Regards, Degang Wu [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance --
> Subscriber-posting only. If you want to post, subscribe first. --
> Also note that this is not the r-help list where general R questions
> should go.
>


From stephen at organicfoodmarkets.com.au  Tue Jan 19 22:10:07 2016
From: stephen at organicfoodmarkets.com.au (Stephen Choularton)
Date: Wed, 20 Jan 2016 08:10:07 +1100
Subject: [R-SIG-Finance] getting suffix for symbols
Message-ID: <569EA62F.3050905@organicfoodmarkets.com.au>

Hi

I am using getSymbols and want to try and find somewhere I can look up 
the exchange suffix for a symbol.

eg I know Westpac is WBC.AX with the AX being the Australian Stock 
Exchange but I have an EFT called GLD which is on the NYSE Arca (I 
think).  I have bo idea what the suffix is.

Is there some central reference for these suffixes.  If not does anyone 
know what the right one is for this symbol to get the data down using 
getSymbols.

Thanks.

Stephen


From lhvan at u.nus.edu  Thu Jan 21 10:49:15 2016
From: lhvan at u.nus.edu (Le Hoang Van)
Date: Thu, 21 Jan 2016 09:49:15 +0000
Subject: [R-SIG-Finance] Multivariate student t distribution in rmgarch
Message-ID: <E9955391-CA6C-4655-850F-6B6364413DE3@u.nus.edu>

Hi Alexios,

Is there a multivariate version of pdist (rugarch) that allows us to compute the joint probability of two returns, say, P(Rs < 0.01, Rt < 0.02) at a certain point of time? So I was trying to fit a DCC-GARCH model with multivariate student t innovations:

xspec = ugarchspec(mean.model = list(armaOrder = c(1,1)), variance.model = list(garchOrder = c(1,1), model = 'sGARCH'), distribution.model = 'norm')
uspec = multispec(replicate(2, xspec))
spec = dccspec(uspec = uspec, dccOrder = c(1, 1), distribution = 'mvt?)
fit = dccfit(spec, data = ret, fit.control = list(eval.se<http://eval.se> = TRUE))

I was able to retrieve the mean vector (fitted(fit)), the covariance matrix (rcov(fit)), and the shape parameter (rshape(fit)) but have no idea how to put them together to compute said probability. Thank you and look forward to your response.

Regards,
Van

	[[alternative HTML version deleted]]


From donglei.du at gmail.com  Thu Jan 21 15:34:33 2016
From: donglei.du at gmail.com (Donglei Du)
Date: Thu, 21 Jan 2016 10:34:33 -0400
Subject: [R-SIG-Finance] error in loading rugarch package
Message-ID: <C864D5CA-4F81-4110-A266-5B31304510F2@gmail.com>

Any help with the following issues is greatly appreciated. I am running R on a Mac computer rather than a Windows one.


Donglei Du

Was able to install the 'rugarch? from CRAN without error/warning, but has the following loading error when calling 

library("rugarch")


Error : .onLoad failed in loadNamespace() for 'rgl', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.2/Resources/library/rgl/libs/rgl.so':
  dlopen(/Library/Frameworks/R.framework/Versions/3.2/Resources/library/rgl/libs/rgl.so, 6): Library not loaded: /opt/X11/lib/libGLU.1.dylib
  Referenced from: /Library/Frameworks/R.framework/Versions/3.2/Resources/library/rgl/libs/rgl.so
  Reason: image not found
Error: package or namespace load failed for ?rugarch?  

From zadig_1 at excite.com  Fri Jan 22 01:46:34 2016
From: zadig_1 at excite.com (ce)
Date: Thu, 21 Jan 2016 19:46:34 -0500
Subject: [R-SIG-Finance] error in loading rugarch package
Message-ID: <20160121194634.17702@web008.roc2.bluetie.com>


Did you install rgl package from cran ?


-----Original Message-----
From: "Donglei Du" [donglei.du at gmail.com]
Date: 01/21/2016 10:47 AM
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] error in loading rugarch package

Any help with the following issues is greatly appreciated. I am running R on a Mac computer rather than a Windows one.


Donglei Du

Was able to install the 'rugarch? from CRAN without error/warning, but has the following loading error when calling 

library("rugarch")


Error : .onLoad failed in loadNamespace() for 'rgl', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.2/Resources/library/rgl/libs/rgl.so':
  dlopen(/Library/Frameworks/R.framework/Versions/3.2/Resources/library/rgl/libs/rgl.so, 6): Library not loaded: /opt/X11/lib/libGLU.1.dylib
  Referenced from: /Library/Frameworks/R.framework/Versions/3.2/Resources/library/rgl/libs/rgl.so
  Reason: image not found
Error: package or namespace load failed for ?rugarch?  
_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go


From will.oswald at gmail.com  Fri Jan 22 07:12:11 2016
From: will.oswald at gmail.com (Will Oswald)
Date: Fri, 22 Jan 2016 14:12:11 +0800
Subject: [R-SIG-Finance] Rblpapi connection issue
Message-ID: <CD51144E-59DA-4D44-80B7-80410EF4F790@gmail.com>

I am unable to authenticate my Bloomberg data connection using the Rblpapi function, blpAuthenticate. I have used the following: uuid = Taken from the "IAM " screen, both as a character type as well as numeric host = Using "CONN ", I have chosen the host name listed "Adapter Info" tab ip.address = Again, from "CONN ", I have used the IP Address shown there (as a character).

If I use the blpConnect function, as specified in help, I can connect but if I call the defaultConnection() function, I get an error stating this function cannot be found. If I alternatively call the blpConnect function in this call, the process just hangs and never completes.

Any suggestions please on whether I have either set the parameters, or if there are other checks I need to make in order to connect? As a final note, I?m connecting to Bloomberg using Internet rather than a Private IP network (I?m running Bloomberg on a home computer).
	[[alternative HTML version deleted]]


From n-e-w at qtradr.net  Fri Jan 22 11:11:15 2016
From: n-e-w at qtradr.net (Nick White)
Date: Fri, 22 Jan 2016 21:11:15 +1100
Subject: [R-SIG-Finance] Rblpapi connection issue
In-Reply-To: <CD51144E-59DA-4D44-80B7-80410EF4F790@gmail.com>
References: <CD51144E-59DA-4D44-80B7-80410EF4F790@gmail.com>
Message-ID: <CAH+4RFt4y2YtMBHAe+V_W1mdCAOeH4QgDySfDnQFwm+-_q2e2w@mail.gmail.com>

Does it not work if you just enter:

conn <-blpConnect()

without more?

That should usually be enough to get you up and running with the rest of
the package unless you have some significantly different defaults

The above assumes you're on a Win box, Bloomberg terminal is open on the
same machine as your R instance (ie desktop API), you are logged in and you
have no other issues connecting to the API (check if you can use the Excel
API)

On Fri, Jan 22, 2016 at 5:12 PM, Will Oswald <will.oswald at gmail.com> wrote:

> I am unable to authenticate my Bloomberg data connection using the Rblpapi
> function, blpAuthenticate. I have used the following: uuid = Taken from the
> "IAM " screen, both as a character type as well as numeric host = Using
> "CONN ", I have chosen the host name listed "Adapter Info" tab ip.address =
> Again, from "CONN ", I have used the IP Address shown there (as a
> character).
>
> If I use the blpConnect function, as specified in help, I can connect but
> if I call the defaultConnection() function, I get an error stating this
> function cannot be found. If I alternatively call the blpConnect function
> in this call, the process just hangs and never completes.
>
> Any suggestions please on whether I have either set the parameters, or if
> there are other checks I need to make in order to connect? As a final note,
> I?m connecting to Bloomberg using Internet rather than a Private IP network
> (I?m running Bloomberg on a home computer).
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.

	[[alternative HTML version deleted]]


From will.oswald at gmail.com  Fri Jan 22 11:17:17 2016
From: will.oswald at gmail.com (Will Oswald)
Date: Fri, 22 Jan 2016 18:17:17 +0800
Subject: [R-SIG-Finance] Rblpapi connection issue
In-Reply-To: <CAH+4RFt4y2YtMBHAe+V_W1mdCAOeH4QgDySfDnQFwm+-_q2e2w@mail.gmail.com>
References: <CD51144E-59DA-4D44-80B7-80410EF4F790@gmail.com>
	<CAH+4RFt4y2YtMBHAe+V_W1mdCAOeH4QgDySfDnQFwm+-_q2e2w@mail.gmail.com>
Message-ID: <C68E94D3-30E6-4C58-BAC7-9C0E97828ACC@gmail.com>

Thanks Nick. I tried that option, but my processes just hang.

On 22 Jan 2016, at 6:11 PM, Nick White <n-e-w at qtradr.net> wrote:

Does it not work if you just enter:

conn <-blpConnect()

without more?

That should usually be enough to get you up and running with the rest of the package unless you have some significantly different defaults

The above assumes you're on a Win box, Bloomberg terminal is open on the same machine as your R instance (ie desktop API), you are logged in and you have no other issues connecting to the API (check if you can use the Excel API)

On Fri, Jan 22, 2016 at 5:12 PM, Will Oswald <will.oswald at gmail.com <mailto:will.oswald at gmail.com>> wrote:
I am unable to authenticate my Bloomberg data connection using the Rblpapi function, blpAuthenticate. I have used the following: uuid = Taken from the "IAM " screen, both as a character type as well as numeric host = Using "CONN ", I have chosen the host name listed "Adapter Info" tab ip.address = Again, from "CONN ", I have used the IP Address shown there (as a character).

If I use the blpConnect function, as specified in help, I can connect but if I call the defaultConnection() function, I get an error stating this function cannot be found. If I alternatively call the blpConnect function in this call, the process just hangs and never completes.

Any suggestions please on whether I have either set the parameters, or if there are other checks I need to make in order to connect? As a final note, I?m connecting to Bloomberg using Internet rather than a Private IP network (I?m running Bloomberg on a home computer).
        [[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance <https://stat.ethz.ch/mailman/listinfo/r-sig-finance>
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.



	[[alternative HTML version deleted]]


From john.laing at gmail.com  Fri Jan 22 13:11:36 2016
From: john.laing at gmail.com (John Laing)
Date: Fri, 22 Jan 2016 07:11:36 -0500
Subject: [R-SIG-Finance] Rblpapi connection issue
In-Reply-To: <C68E94D3-30E6-4C58-BAC7-9C0E97828ACC@gmail.com>
References: <CD51144E-59DA-4D44-80B7-80410EF4F790@gmail.com>
	<CAH+4RFt4y2YtMBHAe+V_W1mdCAOeH4QgDySfDnQFwm+-_q2e2w@mail.gmail.com>
	<C68E94D3-30E6-4C58-BAC7-9C0E97828ACC@gmail.com>
Message-ID: <CAA3Wa=v68Q+-hMY-Rx06zW-92AsTeL+DByYK4OVHDEhjfDXK+g@mail.gmail.com>

Will,

There are a few things causing you problems here. First, the real answer
for you:

If you're running the usual setup, where both R and Bloomberg are local to
your desktop, you don't need to use blpAuthenticate at all. Because you're
connecting through your own terminal your API connection will inherit all
of your settings. This function exists for use with Server API, in which
many users connect through a single headless process.

And additional detail on the side-issues:
* Don't worry about the defaultConnection() function. It is just a shortcut
for managing a single connection (the most common use case) rather than
having to pass the connection object into every. single. function. call. It
is not exported from the package, which is why you can't find it.
* Because of the above, you don't need to fiddle with the con argument in
general. Your trouble with blpAuthenticate is coming from the
host/ip.address arguments. To the extent you need to use this (and you
probably don't), you should use the IP address associated with your
computer.

Hope that helps,
-John

On Fri, Jan 22, 2016 at 5:17 AM, Will Oswald <will.oswald at gmail.com> wrote:

> Thanks Nick. I tried that option, but my processes just hang.
>
> On 22 Jan 2016, at 6:11 PM, Nick White <n-e-w at qtradr.net> wrote:
>
> Does it not work if you just enter:
>
> conn <-blpConnect()
>
> without more?
>
> That should usually be enough to get you up and running with the rest of
> the package unless you have some significantly different defaults
>
> The above assumes you're on a Win box, Bloomberg terminal is open on the
> same machine as your R instance (ie desktop API), you are logged in and you
> have no other issues connecting to the API (check if you can use the Excel
> API)
>
> On Fri, Jan 22, 2016 at 5:12 PM, Will Oswald <will.oswald at gmail.com
> <mailto:will.oswald at gmail.com>> wrote:
> I am unable to authenticate my Bloomberg data connection using the Rblpapi
> function, blpAuthenticate. I have used the following: uuid = Taken from the
> "IAM " screen, both as a character type as well as numeric host = Using
> "CONN ", I have chosen the host name listed "Adapter Info" tab ip.address =
> Again, from "CONN ", I have used the IP Address shown there (as a
> character).
>
> If I use the blpConnect function, as specified in help, I can connect but
> if I call the defaultConnection() function, I get an error stating this
> function cannot be found. If I alternatively call the blpConnect function
> in this call, the process just hangs and never completes.
>
> Any suggestions please on whether I have either set the parameters, or if
> there are other checks I need to make in order to connect? As a final note,
> I?m connecting to Bloomberg using Internet rather than a Private IP network
> (I?m running Bloomberg on a home computer).
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org> mailing
> list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance <
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance>
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From donglei.du at gmail.com  Fri Jan 22 14:16:47 2016
From: donglei.du at gmail.com (Donglei Du)
Date: Fri, 22 Jan 2016 09:16:47 -0400
Subject: [R-SIG-Finance] error in loading rugarch package
Message-ID: <B9E2A818-7847-49BA-BB80-139762E0C699@gmail.com>

Dear all, 

I resolved the problem by installing XQuartz  http://xquartz.macosforge.org <http://xquartz.macosforge.org/>, since X11 is no longer included with OS X.

Since the problem is resolved before I received the suggestion of installing rgl package from CRAN, I do not know if these two solutions serve the same purpose. 

Thanks


Donglei Du
	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Fri Jan 22 14:44:40 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 22 Jan 2016 07:44:40 -0600
Subject: [R-SIG-Finance] getting suffix for symbols
In-Reply-To: <569EA62F.3050905@organicfoodmarkets.com.au>
References: <569EA62F.3050905@organicfoodmarkets.com.au>
Message-ID: <CAPPM_gQ6-X-hoDMEJrGT3JYzjkEwN=-x3_2V7WkLrOWcHk4iZA@mail.gmail.com>

On Tue, Jan 19, 2016 at 3:10 PM, Stephen Choularton
<stephen at organicfoodmarkets.com.au> wrote:
> Hi
>
> I am using getSymbols and want to try and find somewhere I can look up the
> exchange suffix for a symbol.
>
> eg I know Westpac is WBC.AX with the AX being the Australian Stock Exchange
> but I have an EFT called GLD which is on the NYSE Arca (I think).  I have bo
> idea what the suffix is.
>
> Is there some central reference for these suffixes.  If not does anyone know
> what the right one is for this symbol to get the data down using getSymbols.
>
getSymbols is an interface to multiple data sources.  Where to find
the exchange suffix depends on the data source you're using.

If you're using Yahoo, you need to reference
http://finance.yahoo.com/exchanges. If you're using Google, you need
to reference https://www.google.com/googlefinance/disclaimer/.  I'm
not sure about exchange codes for other data sources.

> Thanks.
>
> Stephen
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From will.oswald at gmail.com  Fri Jan 22 15:45:09 2016
From: will.oswald at gmail.com (Will Oswald)
Date: Fri, 22 Jan 2016 22:45:09 +0800
Subject: [R-SIG-Finance] Rblpapi connection issue
In-Reply-To: <CAA3Wa=v68Q+-hMY-Rx06zW-92AsTeL+DByYK4OVHDEhjfDXK+g@mail.gmail.com>
References: <CD51144E-59DA-4D44-80B7-80410EF4F790@gmail.com>
	<CAH+4RFt4y2YtMBHAe+V_W1mdCAOeH4QgDySfDnQFwm+-_q2e2w@mail.gmail.com>
	<C68E94D3-30E6-4C58-BAC7-9C0E97828ACC@gmail.com>
	<CAA3Wa=v68Q+-hMY-Rx06zW-92AsTeL+DByYK4OVHDEhjfDXK+g@mail.gmail.com>
Message-ID: <10D2F1C8-45BF-4AD5-B883-7C1E62D693B5@gmail.com>

Thanks all. I hadn?t thought of ignoring the blpConnect & blpAuthenticate calls altogether and, using the bdp function to test things out (passing blpConnect() as the final parameter), I had no issues whatsoever with retrieving data.

On 22 Jan 2016, at 8:11 PM, John Laing <john.laing at gmail.com> wrote:

Will,

There are a few things causing you problems here. First, the real answer for you:

If you're running the usual setup, where both R and Bloomberg are local to your desktop, you don't need to use blpAuthenticate at all. Because you're connecting through your own terminal your API connection will inherit all of your settings. This function exists for use with Server API, in which many users connect through a single headless process.

And additional detail on the side-issues:
* Don't worry about the defaultConnection() function. It is just a shortcut for managing a single connection (the most common use case) rather than having to pass the connection object into every. single. function. call. It is not exported from the package, which is why you can't find it.
* Because of the above, you don't need to fiddle with the con argument in general. Your trouble with blpAuthenticate is coming from the host/ip.address arguments. To the extent you need to use this (and you probably don't), you should use the IP address associated with your computer.

Hope that helps,
-John 

On Fri, Jan 22, 2016 at 5:17 AM, Will Oswald <will.oswald at gmail.com <mailto:will.oswald at gmail.com>> wrote:
Thanks Nick. I tried that option, but my processes just hang.

On 22 Jan 2016, at 6:11 PM, Nick White <n-e-w at qtradr.net <mailto:n-e-w at qtradr.net>> wrote:

Does it not work if you just enter:

conn <-blpConnect()

without more?

That should usually be enough to get you up and running with the rest of the package unless you have some significantly different defaults

The above assumes you're on a Win box, Bloomberg terminal is open on the same machine as your R instance (ie desktop API), you are logged in and you have no other issues connecting to the API (check if you can use the Excel API)

On Fri, Jan 22, 2016 at 5:12 PM, Will Oswald <will.oswald at gmail.com <mailto:will.oswald at gmail.com> <mailto:will.oswald at gmail.com <mailto:will.oswald at gmail.com>>> wrote:
I am unable to authenticate my Bloomberg data connection using the Rblpapi function, blpAuthenticate. I have used the following: uuid = Taken from the "IAM " screen, both as a character type as well as numeric host = Using "CONN ", I have chosen the host name listed "Adapter Info" tab ip.address = Again, from "CONN ", I have used the IP Address shown there (as a character).

If I use the blpConnect function, as specified in help, I can connect but if I call the defaultConnection() function, I get an error stating this function cannot be found. If I alternatively call the blpConnect function in this call, the process just hangs and never completes.

Any suggestions please on whether I have either set the parameters, or if there are other checks I need to make in order to connect? As a final note, I?m connecting to Bloomberg using Internet rather than a Private IP network (I?m running Bloomberg on a home computer).
        [[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org> <mailto:R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org>> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance <https://stat.ethz.ch/mailman/listinfo/r-sig-finance> <https://stat.ethz.ch/mailman/listinfo/r-sig-finance <https://stat.ethz.ch/mailman/listinfo/r-sig-finance>>
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.



        [[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance <https://stat.ethz.ch/mailman/listinfo/r-sig-finance>
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


	[[alternative HTML version deleted]]


From john.laing at gmail.com  Fri Jan 22 16:44:10 2016
From: john.laing at gmail.com (John Laing)
Date: Fri, 22 Jan 2016 10:44:10 -0500
Subject: [R-SIG-Finance] Rblpapi connection issue
In-Reply-To: <10D2F1C8-45BF-4AD5-B883-7C1E62D693B5@gmail.com>
References: <CD51144E-59DA-4D44-80B7-80410EF4F790@gmail.com>
	<CAH+4RFt4y2YtMBHAe+V_W1mdCAOeH4QgDySfDnQFwm+-_q2e2w@mail.gmail.com>
	<C68E94D3-30E6-4C58-BAC7-9C0E97828ACC@gmail.com>
	<CAA3Wa=v68Q+-hMY-Rx06zW-92AsTeL+DByYK4OVHDEhjfDXK+g@mail.gmail.com>
	<10D2F1C8-45BF-4AD5-B883-7C1E62D693B5@gmail.com>
Message-ID: <CAA3Wa=u57=aN+Cb2k6W7s2VpP4fsh935ehyfrT+ZcBWs2Fh2aQ@mail.gmail.com>

I think you may have misinterpreted. You _should_ call blpConnect, and you
only need to do it once. You don't need to call blpAuthenticate. A very
short script might look like this:

require(Rblpapi)
blpConnect()
bdp("USDCAD Curncy","PX_LAST")

-John

On Fri, Jan 22, 2016 at 9:45 AM, Will Oswald <will.oswald at gmail.com> wrote:

> Thanks all. I hadn?t thought of ignoring the blpConnect & blpAuthenticate
> calls altogether and, using the bdp function to test things out (passing
> blpConnect() as the final parameter), I had no issues whatsoever with
> retrieving data.
>
> On 22 Jan 2016, at 8:11 PM, John Laing <john.laing at gmail.com> wrote:
>
> Will,
>
> There are a few things causing you problems here. First, the real answer
> for you:
>
> If you're running the usual setup, where both R and Bloomberg are local to
> your desktop, you don't need to use blpAuthenticate at all. Because you're
> connecting through your own terminal your API connection will inherit all
> of your settings. This function exists for use with Server API, in which
> many users connect through a single headless process.
>
> And additional detail on the side-issues:
> * Don't worry about the defaultConnection() function. It is just a
> shortcut for managing a single connection (the most common use case) rather
> than having to pass the connection object into every. single. function.
> call. It is not exported from the package, which is why you can't find it.
> * Because of the above, you don't need to fiddle with the con argument in
> general. Your trouble with blpAuthenticate is coming from the
> host/ip.address arguments. To the extent you need to use this (and you
> probably don't), you should use the IP address associated with your
> computer.
>
> Hope that helps,
> -John
>
> On Fri, Jan 22, 2016 at 5:17 AM, Will Oswald <will.oswald at gmail.com>
> wrote:
>
>> Thanks Nick. I tried that option, but my processes just hang.
>>
>> On 22 Jan 2016, at 6:11 PM, Nick White <n-e-w at qtradr.net> wrote:
>>
>> Does it not work if you just enter:
>>
>> conn <-blpConnect()
>>
>> without more?
>>
>> That should usually be enough to get you up and running with the rest of
>> the package unless you have some significantly different defaults
>>
>> The above assumes you're on a Win box, Bloomberg terminal is open on the
>> same machine as your R instance (ie desktop API), you are logged in and you
>> have no other issues connecting to the API (check if you can use the Excel
>> API)
>>
>> On Fri, Jan 22, 2016 at 5:12 PM, Will Oswald <will.oswald at gmail.com
>> <mailto:will.oswald at gmail.com>> wrote:
>> I am unable to authenticate my Bloomberg data connection using the
>> Rblpapi function, blpAuthenticate. I have used the following: uuid = Taken
>> from the "IAM " screen, both as a character type as well as numeric host =
>> Using "CONN ", I have chosen the host name listed "Adapter Info" tab
>> ip.address = Again, from "CONN ", I have used the IP Address shown there
>> (as a character).
>>
>> If I use the blpConnect function, as specified in help, I can connect but
>> if I call the defaultConnection() function, I get an error stating this
>> function cannot be found. If I alternatively call the blpConnect function
>> in this call, the process just hangs and never completes.
>>
>> Any suggestions please on whether I have either set the parameters, or if
>> there are other checks I need to make in order to connect? As a final note,
>> I?m connecting to Bloomberg using Internet rather than a Private IP network
>> (I?m running Bloomberg on a home computer).
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org> mailing
>> list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance <
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance>
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>

	[[alternative HTML version deleted]]


From edd at debian.org  Fri Jan 22 16:56:00 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 22 Jan 2016 09:56:00 -0600
Subject: [R-SIG-Finance] Rblpapi connection issue
In-Reply-To: <CAA3Wa=u57=aN+Cb2k6W7s2VpP4fsh935ehyfrT+ZcBWs2Fh2aQ@mail.gmail.com>
References: <CD51144E-59DA-4D44-80B7-80410EF4F790@gmail.com>
	<CAH+4RFt4y2YtMBHAe+V_W1mdCAOeH4QgDySfDnQFwm+-_q2e2w@mail.gmail.com>
	<C68E94D3-30E6-4C58-BAC7-9C0E97828ACC@gmail.com>
	<CAA3Wa=v68Q+-hMY-Rx06zW-92AsTeL+DByYK4OVHDEhjfDXK+g@mail.gmail.com>
	<10D2F1C8-45BF-4AD5-B883-7C1E62D693B5@gmail.com>
	<CAA3Wa=u57=aN+Cb2k6W7s2VpP4fsh935ehyfrT+ZcBWs2Fh2aQ@mail.gmail.com>
Message-ID: <22178.20752.684045.867503@max.nulle.part>


On 22 January 2016 at 10:44, John Laing wrote:
| I think you may have misinterpreted. You _should_ call blpConnect, and you
| only need to do it once. You don't need to call blpAuthenticate. A very
| short script might look like this:
| 
| require(Rblpapi)
| blpConnect()
| bdp("USDCAD Curncy","PX_LAST")

Exactly.  (Though I prefer library() over requires() here.)

We worked diligently to make this as trivial and reliable as possible.

A connection object is established _once_ when the package is loaded if and
only options("blpAutoConnect") is set to true. Then blpConnect() is called,
and it too relies on options() to get the hostname (if "localhost") and/or
the default port will not do.  Once you have that connection, it will be
supplied to all accessor functions -- no need to carry it around explicitly
from call to call.

All that should "just work" as it does for us.  If it doesn't for you, please
file an issue at the GitHub repo.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From will.oswald at gmail.com  Fri Jan 22 17:08:15 2016
From: will.oswald at gmail.com (Will Oswald)
Date: Sat, 23 Jan 2016 00:08:15 +0800
Subject: [R-SIG-Finance] Rblpapi connection issue
In-Reply-To: <22178.20752.684045.867503@max.nulle.part>
References: <CD51144E-59DA-4D44-80B7-80410EF4F790@gmail.com>
	<CAH+4RFt4y2YtMBHAe+V_W1mdCAOeH4QgDySfDnQFwm+-_q2e2w@mail.gmail.com>
	<C68E94D3-30E6-4C58-BAC7-9C0E97828ACC@gmail.com>
	<CAA3Wa=v68Q+-hMY-Rx06zW-92AsTeL+DByYK4OVHDEhjfDXK+g@mail.gmail.com>
	<10D2F1C8-45BF-4AD5-B883-7C1E62D693B5@gmail.com>
	<CAA3Wa=u57=aN+Cb2k6W7s2VpP4fsh935ehyfrT+ZcBWs2Fh2aQ@mail.gmail.com>
	<22178.20752.684045.867503@max.nulle.part>
Message-ID: <0E063957-02E6-4CD7-B151-AB9150AE1336@gmail.com>

Thanks, and yes, all working straight out of the box.

On 22 Jan 2016, at 11:56 PM, Dirk Eddelbuettel <edd at debian.org> wrote:


On 22 January 2016 at 10:44, John Laing wrote:
| I think you may have misinterpreted. You _should_ call blpConnect, and you
| only need to do it once. You don't need to call blpAuthenticate. A very
| short script might look like this:
| 
| require(Rblpapi)
| blpConnect()
| bdp("USDCAD Curncy","PX_LAST")

Exactly.  (Though I prefer library() over requires() here.)

We worked diligently to make this as trivial and reliable as possible.

A connection object is established _once_ when the package is loaded if and
only options("blpAutoConnect") is set to true. Then blpConnect() is called,
and it too relies on options() to get the hostname (if "localhost") and/or
the default port will not do.  Once you have that connection, it will be
supplied to all accessor functions -- no need to carry it around explicitly
from call to call.

All that should "just work" as it does for us.  If it doesn't for you, please
file an issue at the GitHub repo.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From samuelandjw at gmail.com  Fri Jan 22 17:17:44 2016
From: samuelandjw at gmail.com (Degang WU)
Date: Sat, 23 Jan 2016 00:17:44 +0800
Subject: [R-SIG-Finance] Problem understanding the code of dse::simulate
Message-ID: <5D695962-87B6-4F4C-B19F-14A7A70BF6E7@gmail.com>

Hi,
I want to simulate a VAR process using the following code
library(dse)
AR   <- array(c(1, .5, .3, 0, .2, .1, 0, .2, .05, 1, .5, .3) ,c(3,2,2))
VAR  <- ARMA(A=AR, B=diag(1,2))
print(VAR)
simData <- simulate(VAR)
Inside dse::simulate:

    if (p == 1) 
        invA0 <- matrix(1/A[1, , ], 1, 1)
    else invA0 <- solve(A[1, , ])
    for (l in 1:a) A[l, , ] <- invA0 %*% A[l, , ]
    for (l in 1:b) B[l, , ] <- invA0 %*% B[l, , ]

Where A[,,,] are the coefficient matrix for the process. I have no idea why the inverse of A[1, ,] is involved in the simulation.

Thanks!

Regards,
Degang
	[[alternative HTML version deleted]]


From stephen at organicfoodmarkets.com.au  Sat Jan 23 23:14:58 2016
From: stephen at organicfoodmarkets.com.au (Stephen Choularton)
Date: Sun, 24 Jan 2016 09:14:58 +1100
Subject: [R-SIG-Finance] reqHistory
Message-ID: <56A3FB62.8000105@organicfoodmarkets.com.au>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20160124/4020c483/attachment.html>

From pgilbert902 at gmail.com  Sun Jan 24 14:33:47 2016
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sun, 24 Jan 2016 08:33:47 -0500
Subject: [R-SIG-Finance] Problem understanding the code of dse::simulate
In-Reply-To: <5D695962-87B6-4F4C-B19F-14A7A70BF6E7@gmail.com>
References: <5D695962-87B6-4F4C-B19F-14A7A70BF6E7@gmail.com>
Message-ID: <56A4D2BB.1060709@gmail.com>

On 01/22/2016 11:17 AM, Degang WU wrote:
> Hi, I want to simulate a VAR process using the following code
> library(dse) AR   <- array(c(1, .5, .3, 0, .2, .1, 0, .2, .05, 1, .5,
> .3) ,c(3,2,2)) VAR  <- ARMA(A=AR, B=diag(1,2)) print(VAR) simData <-
> simulate(VAR) Inside dse::simulate:
>
> if (p == 1) invA0 <- matrix(1/A[1, , ], 1, 1) else invA0 <-
> solve(A[1, , ]) for (l in 1:a) A[l, , ] <- invA0 %*% A[l, , ] for (l
> in 1:b) B[l, , ] <- invA0 %*% B[l, , ]
>
> Where A[,,,] are the coefficient matrix for the process. I have no
> idea why the inverse of A[1, ,] is involved in the simulation.

Degang

In response to your previous question I said the dse specification is

y_t + A_1 y_{t-1} + A_2 y_{t-2} + .. A_p y_{t-p} = e_t (2)

but that is the form corresponding to your specification. In general, 
VAR models can be written

A_0 y_t + A_1 y_{t-1} + A_2 y_{t-2} + .. A_p y_{t-p} = e_t (3)

In your specification A_0 is the identity matrix. For simulation it is 
convenient to re-write (3) as

y_t = (A_0)^-1 (-A_1 y_{t-1} - A_2 y_{t-2} - ... - A_p y_{t-p} + e_t)

R indexes arrays starting with 1, so A_0 is stored in A[1,,]. If A_0 is 
the identity, as in your specification, the inverse will also be 
identity and the multiplication is not necessary.

Paul
>
> Thanks!
>
> Regards, Degang [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance --
> Subscriber-posting only. If you want to post, subscribe first. --
> Also note that this is not the r-help list where general R questions
> should go.
>


From spiovesan at alice.it  Sun Jan 24 22:41:21 2016
From: spiovesan at alice.it (Stefano)
Date: Sun, 24 Jan 2016 22:41:21 +0100
Subject: [R-SIG-Finance] get financial data from morningstar.com with rvest
Message-ID: <002d01d156ef$f783af70$e68b0e50$@alice.it>

Dear all,

I am trying to get financial data from morningstar.com; I want to get i.e.
MSFT yearly revenue data.

They are in a row `<div>`of a main `<div>` table.

I followed some samples to get the main table:



    url <-
"http://financials.morningstar.com/income-statement/is.html?t=MSFT&region=us
a&culture=en-US"

    table <- url %>%

     read_html() %>%

     html_nodes(xpath='//*[@id="sfcontent"]/div[3]/div[3]') %>%

     html_table()



but I get an empty `list()`. `html_nodes` itself returns a `{xml_nodeset
(0)}` that I don't know how to handle.



Best regards,

Stefano





---
Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From samuelandjw at gmail.com  Mon Jan 25 04:45:53 2016
From: samuelandjw at gmail.com (Degang WU)
Date: Mon, 25 Jan 2016 11:45:53 +0800
Subject: [R-SIG-Finance] Problem understanding the code of dse::simulate
In-Reply-To: <56A4D2BB.1060709@gmail.com>
References: <5D695962-87B6-4F4C-B19F-14A7A70BF6E7@gmail.com>
	<56A4D2BB.1060709@gmail.com>
Message-ID: <8195B3FD-8EF0-4D85-A6C8-7C890A54DBAC@gmail.com>

Paul,

Thanks for your clear and insightful answers!

Degang

> On 24 Jan, 2016, at 9:33 pm, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> 
> On 01/22/2016 11:17 AM, Degang WU wrote:
>> Hi, I want to simulate a VAR process using the following code
>> library(dse) AR   <- array(c(1, .5, .3, 0, .2, .1, 0, .2, .05, 1, .5,
>> .3) ,c(3,2,2)) VAR  <- ARMA(A=AR, B=diag(1,2)) print(VAR) simData <-
>> simulate(VAR) Inside dse::simulate:
>> 
>> if (p == 1) invA0 <- matrix(1/A[1, , ], 1, 1) else invA0 <-
>> solve(A[1, , ]) for (l in 1:a) A[l, , ] <- invA0 %*% A[l, , ] for (l
>> in 1:b) B[l, , ] <- invA0 %*% B[l, , ]
>> 
>> Where A[,,,] are the coefficient matrix for the process. I have no
>> idea why the inverse of A[1, ,] is involved in the simulation.
> 
> Degang
> 
> In response to your previous question I said the dse specification is
> 
> y_t + A_1 y_{t-1} + A_2 y_{t-2} + .. A_p y_{t-p} = e_t (2)
> 
> but that is the form corresponding to your specification. In general, VAR models can be written
> 
> A_0 y_t + A_1 y_{t-1} + A_2 y_{t-2} + .. A_p y_{t-p} = e_t (3)
> 
> In your specification A_0 is the identity matrix. For simulation it is convenient to re-write (3) as
> 
> y_t = (A_0)^-1 (-A_1 y_{t-1} - A_2 y_{t-2} - ... - A_p y_{t-p} + e_t)
> 
> R indexes arrays starting with 1, so A_0 is stored in A[1,,]. If A_0 is the identity, as in your specification, the inverse will also be identity and the multiplication is not necessary.
> 
> Paul
>> 
>> Thanks!
>> 
>> Regards, Degang [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance --
>> Subscriber-posting only. If you want to post, subscribe first. --
>> Also note that this is not the r-help list where general R questions
>> should go.
>> 


From josh.m.ulrich at gmail.com  Mon Jan 25 22:50:46 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 25 Jan 2016 15:50:46 -0600
Subject: [R-SIG-Finance] R/Finance 2016 Call for Papers
In-Reply-To: <CAPPM_gSvo=1tohLEbAXBFnGZs2LoJTRV-JEXuX-jbHV7-Ljttg@mail.gmail.com>
References: <CAPPM_gSgYv3=9Eu=0jvi2SYNes3nDdJh8iZm9isB6nynQ7qG8w@mail.gmail.com>
	<CAPPM_gSvo=1tohLEbAXBFnGZs2LoJTRV-JEXuX-jbHV7-Ljttg@mail.gmail.com>
Message-ID: <CAPPM_gT+FAOFkOuSTpx6WfDRyyScBe9WRXCghOaVFJqfZS5JtQ@mail.gmail.com>

Final reminder: the submission deadline is this Friday!

On Mon, Jan 4, 2016 at 8:54 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> A friendly reminder that the submission deadline (January 29, 2016) is
> less than a month away!
>
> On Thu, Oct 15, 2015 at 11:02 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>> Call for Papers:
>>
>> R/Finance 2016: Applied Finance with R
>> May 20 and 21, 2016
>> University of Illinois at Chicago
>>
>> The eighth annual R/Finance conference for applied finance using R
>> will be held on May 20 and 21, 2016 in Chicago, IL, USA at the
>> University of Illinois at Chicago.  The conference will cover topics
>> including portfolio management, time series analysis, advanced risk
>> tools, high-performance computing, market microstructure, and
>> econometrics.  All will be discussed within the context of using R as
>> a primary tool for financial risk management, portfolio construction,
>> and trading.
>>
>> Over the past seven years, R/Finance has included attendees from
>> around the world.  It has featured presentations from prominent
>> academics and practitioners, and we anticipate another exciting
>> line-up for 2016.
>>
>> We invite you to submit complete papers in pdf format for
>> consideration.  We will also consider one-page abstracts (in txt or
>> pdf format) although more complete papers are preferred.  We welcome
>> submissions for both full talks and abbreviated "lightning talks."
>> Both academic and practitioner proposals related to R are encouraged.
>>
>> All slides will be made publicly available at conference time.
>> Presenters are strongly encouraged to provide working R code to
>> accompany the slides.  Data sets should also be made public for the
>> purposes of reproducibility (though we realize this may be limited due
>> to contracts with data vendors).  Preference may be given to
>> presenters who have released R packages.
>>
>> The conference will award two (or more) $1000 prizes for best papers.
>> A submission must be a full paper to be eligible for a best paper
>> award.  Extended abstracts, even if a full paper is provided by
>> conference time, are not eligible for a best paper award.  Financial
>> assistance for travel and accommodation may be available to
>> presenters, however requests must be made at the time of submission.
>> Assistance will be granted at the discretion of the conference
>> committee.
>>
>> Please make your submission online at: http://www.cvent.com/d/3fqnb8.
>>
>> The submission deadline is January 29, 2016.  Submitters will be
>> notified via email by February 29, 2016 of acceptance, presentation
>> length, and financial assistance (if requested).
>>
>> Additional details will be announced via the conference website
>>
>> http://www.RinFinance.com/
>>
>> as they become available.  Information on previous years' presenters
>> and their presentations are also at the conference website.  We will
>> make a separate announcement when registration opens.
>>
>> For the program committee:
>> Gib Bassett, Peter Carl, Dirk Eddelbuettel, Brian Peterson, Dale
>> Rosenthal, Jeffrey Ryan, Joshua Ulrich
>>
>>
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From n.manganaro at alum.mit.edu  Tue Jan 26 23:55:11 2016
From: n.manganaro at alum.mit.edu (Nicholas Manganaro)
Date: Tue, 26 Jan 2016 17:55:11 -0500 (EST)
Subject: [R-SIG-Finance] Error in autoarfima output
Message-ID: <1202093032.44622.1453848911377.JavaMail.help@alum.mit.edu>

I am using autoarfima from rugarch separately on a series of differences, with ar.max=ma.max=3.
The search process converges.
I am getting the normal outputs from object$fit at fit until it gets to the ARCH LM Tests and beyond. There I get the following message and no further outputs:

ARCH LM Tests
------------------------------------
Error in model.frame.default(formula = mat[, 1] ~ mat[, -1], drop.unused.levels = TRUE) : 
  variable lengths differ (found for 'mat[, -1]')

-------------------------------------
I am running rugarch 1.3-1, with R version 3.2.3 through RStudio, on Platform: x86_64-w64-mingw32/x64, using Win7-SP1.
Given a clue, I can look for a solution, but this seems to be happening internally in the function.
Thanks for any help you can provide.
-Nick

From aschmid1 at stevens.edu  Wed Jan 27 21:47:26 2016
From: aschmid1 at stevens.edu (aschmid1)
Date: Wed, 27 Jan 2016 15:47:26 -0500
Subject: [R-SIG-Finance] high/low prices
Message-ID: <9b09d3a38fafdb3e71bc6cea747014c4@stevens.edu>

I have a quick question: are High/Low intraday prices available on the 
yahoo/morningstar websites transaction prices or bid/ask prices?
Thanks! Alec


From metz.magnus at gmail.com  Thu Jan 28 21:18:09 2016
From: metz.magnus at gmail.com (Magnus Metz)
Date: Thu, 28 Jan 2016 21:18:09 +0100
Subject: [R-SIG-Finance] Could you please take me off your mailing list?
Message-ID: <CABOBsHPE3EQTO7hEVP8OfUOOoi_ZQh84x4C3RtMTntsmjxdJ4A@mail.gmail.com>

Thanks

-- 
Magnus Metz, M.Sc.
Tel.: +49 176 47751680
Email: metz.magnus at gmail.com

	[[alternative HTML version deleted]]


From pzulfugarli at gmail.com  Fri Jan 29 06:58:23 2016
From: pzulfugarli at gmail.com (Pasha Zulfugarli)
Date: Fri, 29 Jan 2016 09:58:23 +0400
Subject: [R-SIG-Finance] Could you please take me off your mailing list?
In-Reply-To: <CABOBsHPE3EQTO7hEVP8OfUOOoi_ZQh84x4C3RtMTntsmjxdJ4A@mail.gmail.com>
References: <CABOBsHPE3EQTO7hEVP8OfUOOoi_ZQh84x4C3RtMTntsmjxdJ4A@mail.gmail.com>
Message-ID: <CADnj+qYWhEJmRM5UOqS-itERMOM9qH=4ONgL8Xc+FtdKC5+Zug@mail.gmail.com>

Please, take me off too. thanks!!

On Fri, Jan 29, 2016 at 12:18 AM, Magnus Metz <metz.magnus at gmail.com> wrote:

> Thanks
>
> --
> Magnus Metz, M.Sc.
> Tel.: +49 176 47751680
> Email: metz.magnus at gmail.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>



-- 
Regards,
Pasha Zulfugarli

	[[alternative HTML version deleted]]


From ntobiaskramer at gmail.com  Fri Jan 29 09:33:02 2016
From: ntobiaskramer at gmail.com (Nils Tobias Kramer)
Date: Fri, 29 Jan 2016 09:33:02 +0100
Subject: [R-SIG-Finance] Could you please take me off your mailing list?
In-Reply-To: <CADnj+qYWhEJmRM5UOqS-itERMOM9qH=4ONgL8Xc+FtdKC5+Zug@mail.gmail.com>
References: <CABOBsHPE3EQTO7hEVP8OfUOOoi_ZQh84x4C3RtMTntsmjxdJ4A@mail.gmail.com>
	<CADnj+qYWhEJmRM5UOqS-itERMOM9qH=4ONgL8Xc+FtdKC5+Zug@mail.gmail.com>
Message-ID: <9FF5799F-1C9A-4E7C-9DE0-1A3EDB8F575C@gmail.com>

See https://stat.ethz.ch/mailman/listinfo/r-sig-finance at the bottom.

> On 29.01.2016, at 06:58, Pasha Zulfugarli <pzulfugarli at gmail.com> wrote:
> 
> Please, take me off too. thanks!!
> 
>> On Fri, Jan 29, 2016 at 12:18 AM, Magnus Metz <metz.magnus at gmail.com> wrote:
>> 
>> Thanks
>> 
>> --
>> Magnus Metz, M.Sc.
>> Tel.: +49 176 47751680
>> Email: metz.magnus at gmail.com
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>> 
> 
> 
> 
> -- 
> Regards,
> Pasha Zulfugarli
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From jerseyfanatic1 at gmail.com  Mon Feb  1 08:12:18 2016
From: jerseyfanatic1 at gmail.com (Jersey Fanatic)
Date: Mon, 1 Feb 2016 09:12:18 +0200
Subject: [R-SIG-Finance] apply.paramset trade-by-trade PnL data
Message-ID: <CAC_=oyPe7JAGkeX1a_7A-itpPJ2=O35+a_fey3oWgRp6_M_uPQ@mail.gmail.com>

Transaction table from applyStrategy() lists transaction dates and PnL in
trade-by-trade basis. However, after executing apply.paramset() on a
distribution of parameters, same trade-by-trade PnL statistics is not
retrievable via getTxns(). Is there a way to access trade-by-trade PnL data
results from applyStrategy for each combination tried in the optimization
range? My end goal is to construct a time-aligned data table with
hourly/daily/weekly PnL for each combination of parameters.

Thanks for the help in advance.

	[[alternative HTML version deleted]]


From jerseyfanatic1 at gmail.com  Mon Feb  1 11:43:06 2016
From: jerseyfanatic1 at gmail.com (Jersey Fanatic)
Date: Mon, 1 Feb 2016 12:43:06 +0200
Subject: [R-SIG-Finance] apply.paramset trade-by-trade PnL data
In-Reply-To: <CAC_=oyPe7JAGkeX1a_7A-itpPJ2=O35+a_fey3oWgRp6_M_uPQ@mail.gmail.com>
References: <CAC_=oyPe7JAGkeX1a_7A-itpPJ2=O35+a_fey3oWgRp6_M_uPQ@mail.gmail.com>
Message-ID: <CAC_=oyNU_UCGkfD85x49a0PkJZmYAMgDUXjU1BxGKcsyxG2VQg@mail.gmail.com>

Transaction table from applyStrategy() lists transaction dates and PnL in
trade-by-trade basis. However, after executing apply.paramset() on a
distribution of parameters, same trade-by-trade PnL statistics is not
retrievable via getTxns(). Is there a way to access trade-by-trade PnL data
results from *apply.paramset()* for each combination tried in the
optimization range? My end goal is to construct a time-aligned data table
with hourly/daily/weekly PnL for each combination of parameters.


2016-02-01 9:12 GMT+02:00 Jersey Fanatic <jerseyfanatic1 at gmail.com>:

> Transaction table from applyStrategy() lists transaction dates and PnL in
> trade-by-trade basis. However, after executing apply.paramset() on a
> distribution of parameters, same trade-by-trade PnL statistics is not
> retrievable via getTxns(). Is there a way to access trade-by-trade PnL data
> results from applyStrategy for each combination tried in the optimization
> range? My end goal is to construct a time-aligned data table with
> hourly/daily/weekly PnL for each combination of parameters.
>
> Thanks for the help in advance.
>

	[[alternative HTML version deleted]]


From jerseyfanatic1 at gmail.com  Tue Feb  2 15:29:53 2016
From: jerseyfanatic1 at gmail.com (Jersey Fanatic)
Date: Tue, 2 Feb 2016 16:29:53 +0200
Subject: [R-SIG-Finance] apply.paramset trade-by-trade PnL data
In-Reply-To: <CAC_=oyNU_UCGkfD85x49a0PkJZmYAMgDUXjU1BxGKcsyxG2VQg@mail.gmail.com>
References: <CAC_=oyPe7JAGkeX1a_7A-itpPJ2=O35+a_fey3oWgRp6_M_uPQ@mail.gmail.com>
	<CAC_=oyNU_UCGkfD85x49a0PkJZmYAMgDUXjU1BxGKcsyxG2VQg@mail.gmail.com>
Message-ID: <CAC_=oyNUjOZKhXBbEc9Gh+St+noZdAvTO-ym9ipShiFYPbcVUw@mail.gmail.com>

Reproducible code:

library(lattice);library(foreach);library(doSNOW);library(ggplot2)
library(gridExtra);library(reshape);library(beepr);library(quantstrat)

Sys.setenv(TZ="UTC")

.strategy<- new.env();.blotter<- new.env()



currency('USD')
symbol.name = "AAPL"


stock(symbol.name, currency="USD", multiplier=1,tick_size= 0.01)

initialEquity = 100000

strategy.keyword = "MACD_D1"

constantTxnFee = 0

getSymbols('AAPL',src = 'yahoo', from="2014-01-01", to="2015-05-31")
AAPL <- adjustOHLC(AAPL)

strategy.st <- paste(symbol.name,strategy.keyword,sep = "_")
rm.strat(strategy.st)

initDate = "2013-12-30"
initPortf(strategy.st, symbol.name, initDate=initDate, currency = "USD")
initAcct(strategy.st, portfolios=strategy.st, initDate=initDate,
initEq=initialEquity, currency = "USD")
initOrders(portfolio=strategy.st,initDate=initDate)
strategy(strategy.st,store=TRUE)

txn.model <- constantTxnFee

macdFastMARange <- seq(5,35,by=10)
macdSlowMARange <- seq(2,62,by=20)
macdSignalRange <- seq(2,26,by=6)
strategy.indicator.name <- "MACD"

strategy.name <- strategy.st
add.indicator(strategy.name,
              name = strategy.indicator.name,
              arguments = list(x=Cl(eval(parse(text = symbol.name)))),
              label='macd')

add.signal(strategy.name,name="sigCrossover",
           arguments =
list(columns=c("macd.macd","signal.macd"),relationship="gt"),
           label="macd.gt.signal")
add.signal(strategy.name,name="sigCrossover",
           arguments =
list(columns=c("macd.macd","signal.macd"),relationship="lt"),
           label="macd.lt.signal")

add.rule(strategy.name,
         name='ruleSignal', arguments = list(sigcol="macd.gt.signal",
sigval=TRUE,  prefer="Open",
                          orderqty= 1000,  ordertype='market',
orderside='long',
                          orderset='ocolong',  TxnFees = txn.model),
         type='enter', label='longenter', enabled=FALSE)
add.rule(strategy.name,
         name='ruleSignal', arguments = list(sigcol="macd.lt.signal",
sigval=TRUE, prefer="Open",  orderqty='all',
                          ordertype='market', orderside='long',
orderset='ocolong', TxnFees = txn.model),
         type='exit', label='longexit', enabled=FALSE)
add.rule(strategy.name, name='ruleSignal', arguments =
list(sigcol="macd.lt.signal", sigval=TRUE,
                          prefer="Open",  orderqty=1000,
 ordertype='market',
                          orderside='short', orderset='ocoshort', TxnFees =
txn.model),
         type='enter', label='shortenter', enabled=FALSE)
add.rule(strategy.name, name='ruleSignal', arguments =
list(sigcol="macd.gt.signal",  sigval=TRUE,
                          prefer="Open",  orderqty='all',
ordertype='market',  orderside='short',
                          orderset='ocoshort',  TxnFees = txn.model),
type='exit', label='shortexit', enabled=FALSE)

add.distribution(strategy.name, paramset.label = "MACD_OPT", component.type
= 'indicator',
                 component.label = "macd", variable = list( nFast =
macdFastMARange ), label = "macdFastMARANGE")
add.distribution(strategy.name, paramset.label = "MACD_OPT", component.type
= 'indicator',
                 component.label = "macd", variable = list( nSlow =
macdSlowMARange ), label = "macdSlowMARANGE")
add.distribution(strategy.name, paramset.label = "MACD_OPT", component.type
= 'indicator',
                 component.label = "macd", variable = list( nSig =
macdSignalRange ), label = "macdSignalRANGE")
add.distribution.constraint(strategy.name, paramset.label = 'MACD_OPT',
                            distribution.label.1 = 'macdFastMARANGE',
distribution.label.2 = 'macdSlowMARANGE',
                            operator = '<', label = 'FastMA<SlowMA')

enable.rule(strategy.st,type="enter",label="longenter", enable = TRUE)
enable.rule(strategy.st,type="exit",label="longexit", enable = TRUE)
enable.rule(strategy.st,type="enter",label="shortenter", enable = TRUE)
enable.rule(strategy.st,type="exit",label="shortexit", enable = TRUE)

results <- apply.paramset(strategy.st,paramset.label = "MACD_OPT",
                          portfolio=strategy.st, account=strategy.st,
nsamples=0,verbose = FALSE)


2016-02-01 12:43 GMT+02:00 Jersey Fanatic <jerseyfanatic1 at gmail.com>:

> Transaction table from applyStrategy() lists transaction dates and PnL in
> trade-by-trade basis. However, after executing apply.paramset() on a
> distribution of parameters, same trade-by-trade PnL statistics is not
> retrievable via getTxns(). Is there a way to access trade-by-trade PnL data
> results from *apply.paramset()* for each combination tried in the
> optimization range? My end goal is to construct a time-aligned data table
> with hourly/daily/weekly PnL for each combination of parameters.
>
>
> 2016-02-01 9:12 GMT+02:00 Jersey Fanatic <jerseyfanatic1 at gmail.com>:
>
>> Transaction table from applyStrategy() lists transaction dates and PnL in
>> trade-by-trade basis. However, after executing apply.paramset() on a
>> distribution of parameters, same trade-by-trade PnL statistics is not
>> retrievable via getTxns(). Is there a way to access trade-by-trade PnL data
>> results from applyStrategy for each combination tried in the optimization
>> range? My end goal is to construct a time-aligned data table with
>> hourly/daily/weekly PnL for each combination of parameters.
>>
>> Thanks for the help in advance.
>>
>
>

	[[alternative HTML version deleted]]


From brian at braverock.com  Tue Feb  2 17:55:02 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 02 Feb 2016 10:55:02 -0600
Subject: [R-SIG-Finance] apply.paramset trade-by-trade PnL data
In-Reply-To: <CAC_=oyNUjOZKhXBbEc9Gh+St+noZdAvTO-ym9ipShiFYPbcVUw@mail.gmail.com>
References: <CAC_=oyPe7JAGkeX1a_7A-itpPJ2=O35+a_fey3oWgRp6_M_uPQ@mail.gmail.com>
	<CAC_=oyNU_UCGkfD85x49a0PkJZmYAMgDUXjU1BxGKcsyxG2VQg@mail.gmail.com>
	<CAC_=oyNUjOZKhXBbEc9Gh+St+noZdAvTO-ym9ipShiFYPbcVUw@mail.gmail.com>
Message-ID: <1454432102.2794.61.camel@brian-rcg>

On Tue, 2016-02-02 at 16:29 +0200, Jersey Fanatic wrote:
> results <- apply.paramset(strategy.st,paramset.label = "MACD_OPT",
>                           portfolio=strategy.st, account=strategy.st,
>                           nsamples=0,verbose = FALSE)
> 
Your problem is here.  You're not setting an 'audit' environment.


paramsetenv<-new.env()

results <- apply.paramset(strategy.st,paramset.label="MACD_OPT",
portfolio=strategy.st, account=strategy.st,nsamples=0,verbose = FALSE,
audit=paramsetenv)

ls(pos=paramsetenv)

#note that paramsetenv will have the portfolio for each parameter set.
#results$tradeStats will give you summary statistics for each paramset. 

# see: http://www.rinfinance.com/agenda/2013/workshop/Humme+Peterson.pdf
# p.42-43 on paramsets, 
# and p.62-67 on walk forward testing, which uses the audit environment


> 
> 2016-02-01 12:43 GMT+02:00 Jersey Fanatic <jerseyfanatic1 at gmail.com>:
> 
> > Transaction table from applyStrategy() lists transaction dates and
> PnL in > trade-by-trade basis. However, after executing
> apply.paramset() on a > distribution of parameters, same
> trade-by-trade
> PnL statistics is not > retrievable via getTxns(). Is there a way to
> access trade-by-trade PnL data > results from *apply.paramset()* for
> each combination tried in the > optimization range? My end goal is to
> construct a time-aligned data table > with hourly/daily/weekly PnL for
> each combination of parameters. > > > 2016-02-01 9:12 GMT+02:00 Jersey
> Fanatic <jerseyfanatic1 at gmail.com>: > >> Transaction table from
> applyStrategy() lists transaction dates and PnL in >> trade-by-trade
> basis. However, after executing apply.paramset() on a >> distribution
> of parameters, same trade-by-trade PnL statistics is not >>
> retrievable
> via getTxns(). Is there a way to access trade-by-trade PnL data >>
> results from applyStrategy for each combination tried in the
> optimization >> range? My end goal is to construct a time-aligned data
> table with >> hourly/daily/weekly PnL for each combination of
> parameters. >> >> Thanks for the help in advance. >> > >


From daniel.cegielka at gmail.com  Tue Feb  2 19:00:23 2016
From: daniel.cegielka at gmail.com (=?UTF-8?Q?Daniel_Cegie=C5=82ka?=)
Date: Tue, 2 Feb 2016 19:00:23 +0100
Subject: [R-SIG-Finance] tick data database
In-Reply-To: <197a5bbc0905011445r3e7ca72co41abe6a6bc315a28@mail.gmail.com>
References: <197a5bbc0905011445r3e7ca72co41abe6a6bc315a28@mail.gmail.com>
Message-ID: <CAPLrYERx9ORwb927XkhMQyBHjmA8OqLHYeE8j3gMop9Z1cKXYQ@mail.gmail.com>

2009-05-01 23:45 GMT+02:00 Hae Kyung Im <haky.im at gmail.com>:

> Hi,
>
> it may be slightly off topic but I was wondering if any of you heard
> about using netCDF format (or similar) to handle tick data?
>
> I thought kdb would be a nice option but the price seems a bit too
> high for my purpose. Do you know of any good open source alternative?
>
> Also is there any package to connect R with kdb?
>
>
Hi Haky,

If you want to have a database primarily for analysis, testing etc.:

http://www.cerebralmastication.com/wp-content/uploads/2010/06/RUG-Chicago-RYAN.pdf

http://files.meetup.com/1772780/Analyzing%20Big%20Data%20in%20R.pdf

Best regards,
Daniel

	[[alternative HTML version deleted]]


From daniel.krizian at gmail.com  Tue Feb  2 20:22:41 2016
From: daniel.krizian at gmail.com (Daniel Krizian)
Date: Tue, 2 Feb 2016 19:22:41 +0000
Subject: [R-SIG-Finance] tick data database
In-Reply-To: <CAPLrYERx9ORwb927XkhMQyBHjmA8OqLHYeE8j3gMop9Z1cKXYQ@mail.gmail.com>
References: <197a5bbc0905011445r3e7ca72co41abe6a6bc315a28@mail.gmail.com>
	<CAPLrYERx9ORwb927XkhMQyBHjmA8OqLHYeE8j3gMop9Z1cKXYQ@mail.gmail.com>
Message-ID: <CALqbvp5e1Or1Woyigx_GV232aTK4NoDPGEXKPdyRRLUsXDQHMg@mail.gmail.com>

Note that the pricey kdb is the one in 64-bit.

32-bit kdb+/q prior version v.3.3 (and after 2.8 I think) is free for
production use (if you managed to download the copy from kx site in the
past).
Note that those versions are no longer available for download. Latest
32-bit versions are still free for proof-of-concept and development use.

Regards,
Daniel Krizian


On Tue, Feb 2, 2016 at 6:00 PM, Daniel Cegie?ka <daniel.cegielka at gmail.com>
wrote:

> 2009-05-01 23:45 GMT+02:00 Hae Kyung Im <haky.im at gmail.com>:
>
> > Hi,
> >
> > it may be slightly off topic but I was wondering if any of you heard
> > about using netCDF format (or similar) to handle tick data?
> >
> > I thought kdb would be a nice option but the price seems a bit too
> > high for my purpose. Do you know of any good open source alternative?
> >
> > Also is there any package to connect R with kdb?
> >
> >
> Hi Haky,
>
> If you want to have a database primarily for analysis, testing etc.:
>
>
> http://www.cerebralmastication.com/wp-content/uploads/2010/06/RUG-Chicago-RYAN.pdf
>
> http://files.meetup.com/1772780/Analyzing%20Big%20Data%20in%20R.pdf
>
> Best regards,
> Daniel
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From twah at gmx.ch  Thu Feb  4 17:33:49 2016
From: twah at gmx.ch (T.)
Date: Thu, 04 Feb 2016 17:33:49 +0100
Subject: [R-SIG-Finance] gmm error
Message-ID: <56B37D6D.4030204@gmx.ch>

Hello all,

I am trying to estimate a gmm in order to estimate a capital market 
model. I use the gmm-package. I set up the moment functions, and an 
analytic gradient matrix function and I chose some initial values. I 
thoroughly tested the moment functions and the gradient matrix as inputs 
of the gmm function. There are no missing values or NaN in the input data.

Now I am getting the following error message, after runing the gmm-function:

"Error in colMeans(gt) : 'x' must be an array of at least two dimensions"

I have been looking for hours to fix the error, with no success. Do some 
of you know how this error arises?

Thanks,

Tom


From rsherry8 at comcast.net  Fri Feb  5 23:02:02 2016
From: rsherry8 at comcast.net (Robert Sherry)
Date: Fri, 5 Feb 2016 17:02:02 -0500
Subject: [R-SIG-Finance] Option Quotes
Message-ID: <56B51BDA.4080408@comcast.net>


I have been getting my option quotes (calls and puts), in R, using the 
library quantmod. That library gets the quotes via Yahoo. At times,
I find the quotes I get from Yahoo to be incomplete. That is, it is not 
carrying all the options.

Is there a better way to get option quotes in R?

Bob


From reachbiswarup at gmail.com  Sun Feb  7 01:23:33 2016
From: reachbiswarup at gmail.com (Biswarup Ghosh)
Date: Sat, 6 Feb 2016 16:23:33 -0800
Subject: [R-SIG-Finance] Approach to predict balance of account in retail
	bank
Message-ID: <CAH8hi=Kq4M1f6bYAD=Sj7OLweZ2tbovGsz6OM+h4pV03gZznYA@mail.gmail.com>

Hi
I have a database table consisting of balance of accounts over a year
during different Business dates . I want to predict the balance of the
account in next one month period .

Few of the concerns that I am facing is

1. The balances of this accounts are not on same dates like for example
some accounts is very active and the balance is changed over every one or
two days in this One year period and Some accounts are not that active and
rarely changes

Now What I have done so far is
1. Flagging no of changes of a account per year
2. Percent of balance change on each period

Now I am at loss on how to go with the forecasting algorithm.

Now based on this parameters how I can give a forecasting , please point me
to a similar literature on which I can work on



-- 
with warm regards
Biswarup Ghosh

	[[alternative HTML version deleted]]


From danielmelendez at alum.northwestern.edu  Sun Feb  7 02:28:58 2016
From: danielmelendez at alum.northwestern.edu (Daniel Melendez)
Date: Sat, 6 Feb 2016 19:28:58 -0600
Subject: [R-SIG-Finance] Approach to predict balance of account in
	retail bank
In-Reply-To: <CAH8hi=Kq4M1f6bYAD=Sj7OLweZ2tbovGsz6OM+h4pV03gZznYA@mail.gmail.com>
References: <CAH8hi=Kq4M1f6bYAD=Sj7OLweZ2tbovGsz6OM+h4pV03gZznYA@mail.gmail.com>
Message-ID: <0795860C-7EAB-4F48-B095-5E54EEFC4169@alum.northwestern.edu>

Hello Biswarup -  

Have you looked into state space models?  If not, I'd first start with an ARIMA model.  I suggest working with the forecast package.  

Regards - Daniel

> On Feb 6, 2016, at 6:23 PM, Biswarup Ghosh <reachbiswarup at gmail.com> wrote:
> 
> Hi
> I have a database table consisting of balance of accounts over a year
> during different Business dates . I want to predict the balance of the
> account in next one month period .
> 
> Few of the concerns that I am facing is
> 
> 1. The balances of this accounts are not on same dates like for example
> some accounts is very active and the balance is changed over every one or
> two days in this One year period and Some accounts are not that active and
> rarely changes
> 
> Now What I have done so far is
> 1. Flagging no of changes of a account per year
> 2. Percent of balance change on each period
> 
> Now I am at loss on how to go with the forecasting algorithm.
> 
> Now based on this parameters how I can give a forecasting , please point me
> to a similar literature on which I can work on
> 
> 
> 
> -- 
> with warm regards
> Biswarup Ghosh
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From reachbiswarup at gmail.com  Sun Feb  7 06:00:02 2016
From: reachbiswarup at gmail.com (Biswarup Ghosh)
Date: Sat, 6 Feb 2016 21:00:02 -0800
Subject: [R-SIG-Finance] Approach to predict balance of account in
	retail bank
In-Reply-To: <0795860C-7EAB-4F48-B095-5E54EEFC4169@alum.northwestern.edu>
References: <CAH8hi=Kq4M1f6bYAD=Sj7OLweZ2tbovGsz6OM+h4pV03gZznYA@mail.gmail.com>
	<0795860C-7EAB-4F48-B095-5E54EEFC4169@alum.northwestern.edu>
Message-ID: <CAH8hi=J-deQbQvhCj6HsvodYzWe1kVG2OcmsQDwv6roHpqj0Ow@mail.gmail.com>

Hi Daniel ,

My confusion for using an Arima / or any other Time series  model, is,
since for every account I have a series  ,How do I ensure a model which is
applicable to all .
pardon my lack of knowledge in this.

On Sat, Feb 6, 2016 at 5:28 PM, Daniel Melendez <
danielmelendez at alum.northwestern.edu> wrote:

> Hello Biswarup -
>
> Have you looked into state space models?  If not, I'd first start with an
> ARIMA model.  I suggest working with the forecast package.
>
> Regards - Daniel
>
> > On Feb 6, 2016, at 6:23 PM, Biswarup Ghosh <reachbiswarup at gmail.com>
> wrote:
> >
> > Hi
> > I have a database table consisting of balance of accounts over a year
> > during different Business dates . I want to predict the balance of the
> > account in next one month period .
> >
> > Few of the concerns that I am facing is
> >
> > 1. The balances of this accounts are not on same dates like for example
> > some accounts is very active and the balance is changed over every one or
> > two days in this One year period and Some accounts are not that active
> and
> > rarely changes
> >
> > Now What I have done so far is
> > 1. Flagging no of changes of a account per year
> > 2. Percent of balance change on each period
> >
> > Now I am at loss on how to go with the forecasting algorithm.
> >
> > Now based on this parameters how I can give a forecasting , please point
> me
> > to a similar literature on which I can work on
> >
> >
> >
> > --
> > with warm regards
> > Biswarup Ghosh
> >
> >    [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>



-- 
with warm regards
Biswarup Ghosh

	[[alternative HTML version deleted]]


From reachbiswarup at gmail.com  Mon Feb  8 03:15:07 2016
From: reachbiswarup at gmail.com (Biswarup Ghosh)
Date: Sun, 7 Feb 2016 18:15:07 -0800
Subject: [R-SIG-Finance] Approach to predict balance of account in
	retail bank
In-Reply-To: <CAJWf-119YjXQbZHwj3oxbK+oSecrRYBWzXdySJ7ey_o1Ozt72A@mail.gmail.com>
References: <CAH8hi=Kq4M1f6bYAD=Sj7OLweZ2tbovGsz6OM+h4pV03gZznYA@mail.gmail.com>
	<0795860C-7EAB-4F48-B095-5E54EEFC4169@alum.northwestern.edu>
	<CAH8hi=J-deQbQvhCj6HsvodYzWe1kVG2OcmsQDwv6roHpqj0Ow@mail.gmail.com>
	<CAJWf-119YjXQbZHwj3oxbK+oSecrRYBWzXdySJ7ey_o1Ozt72A@mail.gmail.com>
Message-ID: <CAH8hi=KZVG9JfxmH0J_DAsjsnyY92OmogAELxCYbkoDnExs1QQ@mail.gmail.com>

Hi John ,

The data set I have is for one year . For some accounts which are very
active the balance is changed pretty often ,and for some it does not . Now
there is no apparent seasonality as this are bank accounts of retail
banking customers ( normal folks ) .
Now what would be your suggestion in this case .

On Sun, Feb 7, 2016 at 12:49 PM, John Frain <frainj at tcd.ie> wrote:

>
> On 7 Feb 2016 05:03, "Biswarup Ghosh" <reachbiswarup at gmail.com> wrote:
> >
> > Hi Daniel ,
> >
> > My confusion for using an Arima / or any other Time series  model, is,
> > since for every account I have a series  ,How do I ensure a model which
> is
> > applicable to all .
> > pardon my lack of knowledge in this.
> >
> > On Sat, Feb 6, 2016 at 5:28 PM, Daniel Melendez <
> > danielmelendez at alum.northwestern.edu> wrote:
>
> I would think that each individual account holder is different.  If you do
> find an appropriate model you will need to estimate separate parameters for
> each account holder. For each account holder I presume that the balance
> remains constant between the dates on which the balances are recorded. You
> should extend your data set by filling in the missing values by repeating
> the previous balance.
>
> Would it be sufficient to aggregate accounts for each date. You might find
> it easier to obtain aggregates (e. g. end of month aggregate data) for a
> period of several years and apply Bureau X12 methodology. I presume that
> data are seasonal.lpl
>
> '
>
> >
> > > Hello Biswarup -
> > >
> > > Have you looked into state space models?  If not, I'd first start with
> an
> > > ARIMA model.  I suggest working with the forecast package.
> > >
> > > Regards - Daniel
> > >
> > > > On Feb 6, 2016, at 6:23 PM, Biswarup Ghosh <reachbiswarup at gmail.com>
> > > wrote:
> > > >
> > > > Hi
> > > > I have a database table consisting of balance of accounts over a year
> > > > during different Business dates . I want to predict the balance of
> the
> > > > account in next one month period .
> > > >
> > > > Few of the concerns that I am facing is
> > > >
> > > > 1. The balances of this accounts are not on same dates like for
> example
> > > > some accounts is very active and the balance is changed over every
> one or
> > > > two days in this One year period and Some accounts are not that
> active
> > > and
> > > > rarely changes
> > > >
> > > > Now What I have done so far is
> > > > 1. Flagging no of changes of a account per year
> > > > 2. Percent of balance change on each period
> > > >
> > > > Now I am at loss on how to go with the forecasting algorithm.
> > > >
> > > > Now based on this parameters how I can give a forecasting , please
> point
> > > me
> > > > to a similar literature on which I can work on
> > > >
> > > >
> > > >
> > > > --
> > > > with warm regards
> > > > Biswarup Ghosh
> > > >
> > > >    [[alternative HTML version deleted]]
> > > >
> > > > _______________________________________________
> > > > R-SIG-Finance at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > > > -- Subscriber-posting only. If you want to post, subscribe first.
> > > > -- Also note that this is not the r-help list where general R
> questions
> > > should go.
> > >
> >
> >
> >
> > --
> > with warm regards
> > Biswarup Ghosh
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>



-- 
with warm regards
Biswarup Ghosh

	[[alternative HTML version deleted]]


From smithyj2727 at gmail.com  Tue Feb  9 10:56:01 2016
From: smithyj2727 at gmail.com (Smith Jimmy)
Date: Tue, 9 Feb 2016 17:56:01 +0800
Subject: [R-SIG-Finance] Using the market (SPY) as an indicator in Quanstrat
Message-ID: <CAGb2M9du0kBWW4DPRTT85Z3xSR9HS7cAVxx-bOe7W793o=b1Pg@mail.gmail.com>

I have a portfolio of 50 stocks that I am back testing a strategy on using
Quantstrat.

I would like to also use the RSI of the SPY (as an example) as another
signal in the strategy.

Eg. Buy Signal - SPY RSI < 20

However I'm not sure where in the Quanstrat workflow I should be
implementing it.

I can't add it to the add.indicator as that references mktdata and the
add.signal references the columns.

How should I go about adding this in?

Many thanks.

	[[alternative HTML version deleted]]


From brian at braverock.com  Tue Feb  9 11:18:36 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 9 Feb 2016 04:18:36 -0600
Subject: [R-SIG-Finance] Using the market (SPY) as an indicator in
 Quanstrat
In-Reply-To: <CAGb2M9du0kBWW4DPRTT85Z3xSR9HS7cAVxx-bOe7W793o=b1Pg@mail.gmail.com>
References: <CAGb2M9du0kBWW4DPRTT85Z3xSR9HS7cAVxx-bOe7W793o=b1Pg@mail.gmail.com>
Message-ID: <56B9BCFC.4010801@braverock.com>

On 02/09/2016 03:56 AM, Smith Jimmy wrote:
> I have a portfolio of 50 stocks that I am back testing a strategy on using
> Quantstrat.
>
> I would like to also use the RSI of the SPY (as an example) as another
> signal in the strategy.
>
> Eg. Buy Signal - SPY RSI < 20
>
> However I'm not sure where in the Quanstrat workflow I should be
> implementing it.
>
> I can't add it to the add.indicator as that references mktdata and the
> add.signal references the columns.
>
> How should I go about adding this in?

In the future, please provide a minimal reproducible example, per the 
posting guide.  It makes it easier for others to help you.

There is nothing that requires your indicators to reference mktdata. 
That's the most common case, as you typically want to be adding columns 
to the mktdata object, and want mktdata to change as quantstrat loops 
over symbols.

So, for example, if the 'standard' or 'demonstration' construction looks 
something like this:

add.indicator(strategy = 'stratRSI', name = "RSI",
arguments = list(price = quote(getPrice(mktdata))), label="RSI")

where you reference mktdata (and as such, are expecting mktdata to 
change for each instrument, see the 'faber' demo for an example).

You can construct an indicator like so:

add.indicator(strategy = stratRSI, name = "RSI",
arguments = list(price = getPrice(SPY)), label="SPYRSI")

This will cause a 'SPYRSI' column to be added to the mktdata object for 
each symbol in your symbols list, and you may now reference column 
'SPYRSI' in later indicators or signals, as usual.

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From Markus.Gesmann at lloyds.com  Tue Feb  9 12:03:19 2016
From: Markus.Gesmann at lloyds.com (Gesmann, Markus)
Date: Tue, 9 Feb 2016 11:03:19 +0000
Subject: [R-SIG-Finance] CONFERENCE: R in Insurance, London, 11 July 2015
Message-ID: <2D1AC19CDA3D5643B9D7AE596C377B280C57C2C8@GBS0039303.lloyds.net>

Dear all,

Following the successful 3rd R in Insurance conference in Amsterdam last year, we return to London this year.

The registration for the 4th conference on R in Insurance on Monday 11 July 2016 at Cass Business School has opened.

This one-day conference will focus again on applications in insurance and actuarial science that use R, the lingua franca for statistical computation.

The intended audience of the conference includes both academics and practitioners who are active or interested in the applications of R in insurance.

Invited talks will be given by:

        - Mario V. W?thrich, RiskLab, Department of Mathematics, ETH Zurich.
        - Dan Murphy, President, Trinostics LLC.

Details about the registration and abstract submission are given on the dedicated R in Insurance page at Cass Business School:
http://www.cass.city.ac.uk/news-and-events/conferences/r-in-insurance2016

The submission deadline for abstracts is 28 March 2016. Please email your abstract of no more than 300 words to: rinsuranceconference at gmail.com<mailto:rinsuranceconference at gmail.com>.

Attendance of the whole conference is the equivalent of 6.5 hours of CPD for members of the Actuarial Profession.

For more information about the past events visit http://www.rininsurance.com .

The organisers gratefully acknowledge the sponsorship of Verisk/ISO, Mirai Solutions, RStudio, Applied AI, and CYBAEA.

Best regards

Markus


----------------------------------------------------------------------
The information in this E-Mail and in any attachments is...{{dropped:22}}


From andrey.kostin at snowfallsystems.com  Wed Feb 10 18:00:08 2016
From: andrey.kostin at snowfallsystems.com (Andrey Kostin)
Date: Wed, 10 Feb 2016 12:00:08 -0500
Subject: [R-SIG-Finance] New Package PortfolioEffectEstim
Message-ID: <CADSYbtV_ZiL6DX4BkEZavZHwqg4Wx7mwASDg9njiupTvr6Mdqw@mail.gmail.com>

Dear R enthusiasts,



I would like to announce PortfolioEffectEstim package availability on CRAN:
https://cran.r-project.org/web/packages/PortfolioEffectEstim/



Package features estimators for working with high frequency market data.


Microstructure Noise:
- Autocovariance Noise Variance
- Realized Noise Variance
- Unbiased Realized Noise Variance
- Noise-to-Signal Ratio



Price Variance:
- Two Series Realized Variance
- Multiple Series Realized Variance
- Modulated Realized Variance
- Jump Robust Modulated Realized Variance
- Uncertainty Zones Realized Variance
- Kernel Realized Variance (Bartlett, Cubic, 5th/6th/7th/8th-order,
Epanichnikov, Parzen, Tukey-Hanning kernels)

Price Quarticity:
- Realized Quarticity
- Realized Quad-power Quarticity
- Realized Tri-power Quarticity
- Modulated Realized Quarticity



Use could provide your own high frequency market data or use our
server-side equity prices since 2013.


More details in the package manual:
https://cran.r-project.org/web/packages/PortfolioEffectEstim/vignettes/PortfolioEffectEstim.pdf


API Reference:
https://cran.r-project.org/web/packages/PortfolioEffectEstim/PortfolioEffectEstim.pdf


Sincerely,

Andrey Kostin, PhD

	[[alternative HTML version deleted]]


From smithyj2727 at gmail.com  Thu Feb 11 07:50:24 2016
From: smithyj2727 at gmail.com (Smith Jimmy)
Date: Thu, 11 Feb 2016 14:50:24 +0800
Subject: [R-SIG-Finance] Quantstrat - Entering a limit order below the open
	price
Message-ID: <CAGb2M9eKBHDbiygqBvdA9TkyUiNCZW=9ZMVAz==egB-8vDmpXQ@mail.gmail.com>

I'm wanting to enter a limit order at a set percentage below the open price
if that's possible with Quantstrat.

I'm not sure if I have set this out correctly but here is an example. I was
trying to set the limit 1% below the open price.

I'm not quite sure how to use order.price to achieve this.

add.rule(strategy.st, name="ruleSignal",
         arguments=list(sigcol="longentry", sigval=TRUE, ordertype="limit",
                        orderside="long", replace=FALSE, prefer="Open",
order.price=mktdata*(0.99),tmult=TRUE, orderqty=tradeSize,
osFUN=osMaxDollar, tradeSize=tradeSize,
                        maxSize=tradeSize),
         type="enter", path.dep=TRUE, label="enterlong")

I'd ideally like to have a trailing stop that would be based on the
executed price.

add.rule(strategy.st, name="ruleSignal", arguments=list(sigcol="longentry",
                                                        sigval=TRUE,

ordertype="stoptrailing",
                                                        orderside="long",
                                                        replace=FALSE,
                                                        orderqty="all",
                                                        threshold=0.05,
                                                        tmult=TRUE,
                                                        TxnFees=-2,

orderset="ocolong"),
         type="chain",
         parent="enterlong",
         label="stopLossLong",
         path.dep=TRUE,
         enable=TRUE)

Any advice would be much appreciated. At this point this strategy doesn't
produce any errors but it also doesn't trade.

Thank you in advance.

	[[alternative HTML version deleted]]


From brian at braverock.com  Thu Feb 11 12:39:56 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 11 Feb 2016 05:39:56 -0600
Subject: [R-SIG-Finance] Quantstrat - Entering a limit order below the
 open price
In-Reply-To: <CAGb2M9eKBHDbiygqBvdA9TkyUiNCZW=9ZMVAz==egB-8vDmpXQ@mail.gmail.com>
References: <CAGb2M9eKBHDbiygqBvdA9TkyUiNCZW=9ZMVAz==egB-8vDmpXQ@mail.gmail.com>
Message-ID: <56BC730C.10508@braverock.com>

Dear 'Jimmy',

(if that is your real name, the complete lack of online footprint seems 
to suggest that it is not)

On 02/11/2016 12:50 AM, Smith Jimmy wrote:
> I'm wanting to enter a limit order at a set percentage below the open price
> if that's possible with Quantstrat.

Yes, it is.

Please do your homework, and read the documentation. Many people have 
contributed that documentation in the hopes that users will actually 
read it.

> I'm not sure if I have set this out correctly but here is an example. I was
> trying to set the limit 1% below the open price.

This is *still* not a minimal reproducible example.

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

> I'm not quite sure how to use order.price to achieve this.

You won't use order.price, you'll use threshold.

> add.rule(strategy.st, name="ruleSignal",
>           arguments=list(sigcol="longentry", sigval=TRUE, ordertype="limit",
>                          orderside="long", replace=FALSE, prefer="Open",
> order.price=mktdata*(0.99),tmult=TRUE, orderqty=tradeSize,
> osFUN=osMaxDollar, tradeSize=tradeSize,
>                          maxSize=tradeSize),
>           type="enter", path.dep=TRUE, label="enterlong")

You most likely want

threshold=0.99, tmult=TRUE

and no order.price argument.

in your code, 'mktdata' probably doesn't exist yet, which is why you get 
no errors.  Have you noticed the use of quote() in many of the demos?  I 
suggest you look at

?quote

and the descriptions of the 'mktdata' object inside quantstrat to 
understand why mktdata is so often quoted when used inside parts of the 
strategy specification.

In your example mktdata probably doesn't exist at the time of strategy 
specification, so you are setting order.price = NULL*0.99, getting NULL. 
  quantstrat will quite reasonably set no price and enter no order.

If you had a mktdata object from a previous run or inadvisably quoted 
mktdata as it is in the other demos, you would have been multiplying 
0.99 by the entire time series of the mktdata object, and quantstrat 
would fail pointing out that order.price needs to be a scalar.

> I'd ideally like to have a trailing stop that would be based on the
> executed price.

Then please spend some time examining and working with the many demos 
which do this already.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From samitpaulin at gmail.com  Tue Feb 16 05:32:56 2016
From: samitpaulin at gmail.com (Samit Paul)
Date: Tue, 16 Feb 2016 10:02:56 +0530
Subject: [R-SIG-Finance] Tangency portfolio in "fPortfolio" package
Message-ID: <CALROeVEjpcxtDxkCJHvy=JLJyMNX0hcho+yUhbUzp+gDhxHjDA@mail.gmail.com>

Dear R users,

I am using "fPortfolio" package for portfolio construction by minimizing
CVaR. I want to remove the constraint "LongOnly" and allow the portfolio to
be constructed when short sale is allowed. Therefore, I have set solver as
"solveRshortExact" instead of "solveRquadprog" in portfolioSpec() and use
constraint "Short" instead of "LongOnly".

It's working fine for the function "efficientPortfolio". However, when I
try to use "tangencyPortfolio" function, it's assigning maximum weight of 1
to the constituent and does not allow for short position.

Can you provide a solution please? Thank you.

Regards,

Samit Paul

	[[alternative HTML version deleted]]


From treydog999 at gmail.com  Wed Feb 17 09:22:46 2016
From: treydog999 at gmail.com (Derek Wong)
Date: Wed, 17 Feb 2016 16:22:46 +0800
Subject: [R-SIG-Finance] stoptrailing mechanics question in MACD example -
	Quantstrat
Message-ID: <CALQudT-OuA_xp5ntfjTnrHzzmf3UHMsy4F-kD6B4eaWBTCF0yg@mail.gmail.com>

Hello All,

I am using Quantstrat 0.9.1709 with Microsoft R Open 3.2.3 on Rstudio.

I am having a problem understanding the trailing methodology of the
stoptrailing order type in Quantstrat. It seems to me that the
trailing stop is not replaced as frequently as it should. Only for
larger price changes (threshold value?) it moves but for smaller
increments it remains the same. Is this the intended result?

I am using the MACD example and commenting out the original exit rule
and un-commenting the trailing exit.

<snip>
#alternatives for risk stops:
# simple stoplimit order, with threshold multiplier
#add.rule(strat.st,name='ruleSignal', arguments =
list(sigcol="signal.gt.zero",sigval=TRUE, orderqty='all',
ordertype='stoplimit', orderside='long', threshold=-.05,tmult=TRUE,
orderset='exit2'),type='chain', parent='enter',
label='risk',storefun=FALSE)
# alternately, use a trailing order, also with a threshold multiplier
add.rule(strat.st,name='ruleSignal',
         arguments = list(sigcol="signal.gt.zero",
                          sigval=TRUE,
                          orderqty='all',
                          ordertype='stoptrailing',
                          orderside='long',
                          threshold=-1,
                          tmult=FALSE,
                          orderset='exit2'),
         type='chain',
         parent='enter',
         label='trailingexit')

# # exit
# add.rule(strat.st,name='ruleSignal',
#          arguments = list(sigcol="signal.lt.zero",
#                           sigval=TRUE,
#                           orderqty='all',
#                           ordertype='market',
#                           orderside='long',
#                           threshold=NULL,
#                           orderset='exit2'),
#          type='exit',
#          label='exit'
# )

<snip>


I am looking at the orderbook and comparing it to the portfolio and
price of AAPL. I can see that the trailing stop moves but not on every
new high created during the trade. The first trade is an example.

<output>
> AAPL["2007-03-15/2007-03-26"]
           AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted
2007-03-15     89.96     90.36    89.31      89.57   139874700      11.84997
2007-03-16     89.54     89.99    89.32      89.59   142926000      11.85262
2007-03-19     90.24     91.55    89.59      91.13   178240300      12.05636
2007-03-20     91.35     91.84    91.06      91.48   122229100      12.10266
2007-03-21     91.99     94.00    91.65      93.87   171724000      12.41886
2007-03-22     93.73     94.36    93.00      93.96   140373100      12.43076
2007-03-23     93.35     94.07    93.30      93.52   112721000      12.37255
2007-03-26     93.99     95.90    93.30      95.85   216246800      12.68081
> obook$macd$AAPL["2007-03-15/2007-03-26"]
           Order.Qty Order.Price Order.Type     Order.Side
Order.Threshold Order.Status Order.StatusTime      Prefer
2007-03-15 "100"     "89.570001" "market"       "long"     NA
    "closed"     "2007-03-16 00:00:00" ""
2007-03-16 "all"     "88.590001" "stoptrailing" "long"     "-1"
    "replaced"   "2007-03-19 00:00:00" ""
2007-03-19 "all"     "90.549999" "stoptrailing" "long"     "-1"
    "replaced"   "2007-03-21 00:00:00" ""
2007-03-21 "all"     "93.000002" "stoptrailing" "long"     "-1"
    "replaced"   "2007-03-26 00:00:00" ""
2007-03-26 "all"     "94.899999" "stoptrailing" "long"     "-1"
    "closed"     "2007-03-28 00:00:00" ""
           Order.Set Txn.Fees Rule           Time.In.Force
2007-03-15 NA        "0"      "enter"        ""
2007-03-16 "exit2"   "0"      "trailingexit" ""
2007-03-19 "exit2"   "0"      "trailingexit" ""
2007-03-21 "exit2"   "0"      "trailingexit" ""
2007-03-26 "exit2"   "0"      "trailingexit" ""

<output>

You can see that for the date 2007-03-15 to 2007-03-21 we would have
what I would believe to be the expected behavior. However at
2007-03-22 we have a new high of 94.36 so i thought the new
Order.Price would be at 93.36 given a threshold =-1 but the order is
not adjusted. The order is however adjusted to the correct value on
2007-03-26 after a new AAPL.High at 95.90 and Order Price is 94.899999

I am very curious if the threshold works not only as the distance
between price but also the threshold of a new high price change in
order for the new Order.Price to be changed. I was expecting every new
AAPL.high to generate a new Order.Price for a stoptrailing order type.

If someone could explain this to me or tell me the expected behavior
and mechanics of the trailing methodology I would very much appreciate
it.

Thank you

Derek


From hlinder33 at gmail.com  Sun Feb 21 05:04:54 2016
From: hlinder33 at gmail.com (Hannah Linder)
Date: Sat, 20 Feb 2016 20:04:54 -0800
Subject: [R-SIG-Finance] Rugarch fitted values lag by 1
Message-ID: <CAKqaSd_ASgUiiWirwKsmpu0dirCk5EufmjDwN1gfRmgT6d8qHw@mail.gmail.com>

Hello,

I am sorry to post a naive question, but I am struggling to sort this out
on my own. I am fitting the following garch model using the rugarch package:

fit.spec1a[[1]]=ugarchspec(variance.model = list(model = "sGARCH",
                                               garchOrder = c(2,0)),
                         mean.model= list(armaOrder = c(1,0),
                                          include.mean = T),
                         distribution.model = "sstd")

garch[[1]]<- ugarchfit(data=train.set[[2]][,c(1)],spec =
fit.spec1a[[1]],solver="hybrid")


When I examine the fitted values using fitted(garch[[1]]) the values appear
to lag behind the observed values by 1 even though the length of the fitted
series is equal to that of the observed data (See plot below), so I am not
sure if I am using the fitted function incorrectly, or if the fitted values
are truly lagged. Should be using the fitted values from t=2 until t=T
rather than t=1 until t=T for calculations such as RMSE in-sample.

[image: Inline image 2]

Thank-you very much for any help,
Hannah
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20160220/71276124/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 46543 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20160220/71276124/attachment.png>

From niheaven at gmail.com  Mon Feb 22 07:10:36 2016
From: niheaven at gmail.com (Hsiao-nan Cheung)
Date: Mon, 22 Feb 2016 14:10:36 +0800
Subject: [R-SIG-Finance] How to Draw a Candle Chart using ggplot2?
Message-ID: <CAK80y3DNMZRY7wu=H9AaGk+tNJgMW4Qx-48xhT6SqwFUE-Y-Pg@mail.gmail.com>

Dear All,

Recently I tried to plot a candle chart using package ggplot2, and have
tried geom_boxplot function, but here I have some problems. Since a candle
chart haven't a middle bar, when I use stat = "identity" to set the single
candle's border of a candle chart, I want to ignore the middle param of a
boxplot. But in recent ggplot2 version (2.0), in geom_boxplot's aesthetics,
the middle param is required, and I cannot give it a NA value to ommit it
as early version. My solution now is set middle = lower, but this would
lead to a VERY strong lower bar. So is there any suggestion that can meet
my requirement?

My sessionInfo()

R version 3.2.3 (2015-12-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=Chinese (Simplified)_People's Republic of China.936
[2] LC_CTYPE=Chinese (Simplified)_People's Republic of China.936
[3] LC_MONETARY=Chinese (Simplified)_People's Republic of China.936
[4] LC_NUMERIC=C
[5] LC_TIME=Chinese (Simplified)_People's Republic of China.936

attached base packages:
[1] stats graphics grDevices utils datasets methods base

other attached packages:
[1] ggplot2_2.0.0 RevoUtilsMath_3.2.3

loaded via a namespace (and not attached):
[1] colorspace_1.2-6 scales_0.3.0 plyr_1.8.3 rsconnect_0.3.79 tools_3.2.3
[6] gtable_0.1.2 Rcpp_0.12.2 grid_3.2.3 munsell_0.4.2

btw, my data's data.frame has two column to indecate the single boxplot's
color and fill, but ggplot2 will treat it as some factors. For example, if
I set somedata[1, "Color"] = "red" and somedata[1, "Fill"] = "red",
and set colour
= Color, fill = Fill in geom_boxplot's aes arg, the plot may show me a
green box... How to define the colour and fill in the data.frame directly?
Yours,

Hsiao-nan Cheung
2016/2/22

	[[alternative HTML version deleted]]


From niheaven at gmail.com  Mon Feb 22 07:12:07 2016
From: niheaven at gmail.com (Hsiao-nan Cheung)
Date: Mon, 22 Feb 2016 14:12:07 +0800
Subject: [R-SIG-Finance] RStudio Crashes when using quantmod's chartSeries()
Message-ID: <CAK80y3BRB+i_MrFQnToNGuLbmv+a9DUJ1oDz0W-y7nVM59Z86A@mail.gmail.com>

Dear All,

Sorry for my second question.

When I use quantmod's chartSeries() function, the RStudio crashes. The code
is as below.

library(quantmod)
getSymbols("IBM")
chartSeries(IBM)

Very simple code... And the same function is working well in Rgui.exe, i.e.
there is a plot in the default graphics device. So maybe it's a graphics
engine error?

I've tried the plot() function, e.g., plot(chartSeries(IBM)), and it
crashes, too. Nothing improve.

Yours,
Hsiao-nan Cheung
2016/2/22

	[[alternative HTML version deleted]]


From mxfomin at gmail.com  Mon Feb 22 09:15:22 2016
From: mxfomin at gmail.com (Maxim Fomin)
Date: Mon, 22 Feb 2016 11:15:22 +0300
Subject: [R-SIG-Finance] RStudio Crashes when using quantmod's
	chartSeries()
In-Reply-To: <CAK80y3BRB+i_MrFQnToNGuLbmv+a9DUJ1oDz0W-y7nVM59Z86A@mail.gmail.com>
References: <CAK80y3BRB+i_MrFQnToNGuLbmv+a9DUJ1oDz0W-y7nVM59Z86A@mail.gmail.com>
Message-ID: <CALB30JC_742XcVXWWgqpzAhcpY5JWfsosVzjDqc7a9z62WbeCg@mail.gmail.com>

 Hi!

1) Your problem has nothing to do with R Finance in particular. You
have R or Rstudio problem.
2) You need to figure out whether it works in simple R session. If it
works, then it is Rstudio problem.
3) Also please consider providing session information (if you have
truly R problem) using sessionInfo() .

P.S. The code works for me.

Best regards,
Maxim

2016-02-22 9:12 GMT+03:00 Hsiao-nan Cheung <niheaven at gmail.com>:
> Dear All,
>
> Sorry for my second question.
>
> When I use quantmod's chartSeries() function, the RStudio crashes. The code
> is as below.
>
> library(quantmod)
> getSymbols("IBM")
> chartSeries(IBM)
>
> Very simple code... And the same function is working well in Rgui.exe, i.e.
> there is a plot in the default graphics device. So maybe it's a graphics
> engine error?
>
> I've tried the plot() function, e.g., plot(chartSeries(IBM)), and it
> crashes, too. Nothing improve.
>
> Yours,
> Hsiao-nan Cheung
> 2016/2/22
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From stephen at organicfoodmarkets.com.au  Wed Feb 24 05:06:34 2016
From: stephen at organicfoodmarkets.com.au (Stephen Choularton)
Date: Wed, 24 Feb 2016 15:06:34 +1100
Subject: [R-SIG-Finance] IBrokers reqOpenOrders - getting data into a program
Message-ID: <56CD2C4A.9090309@organicfoodmarkets.com.au>

Hi

I am working with the IBrokers package.  I notice that almost all the 
code samples I can find simply assume that if you are doing a spread and 
you issue the orders you can then assume that trading has taken place on 
both sides but my experience is that sometimes the short cannot be put 
in place or can only be partially fulfilled.  So I am trying to make 
sure the long only takes place to the extent the short has been 
fulfilled.  So I need to be able to check the state of the short.

I have spent a lot of time trying to grapple with reqOpenOrders but I 
find (just like I did with reqMarketData which I can now manage) that 
unless you know the places in the data structure that hold the 
information you are after its very difficult to guess.  I notice that 
the manual does not seem to have an entry for ?reqOpenOrders so I have 
been googling generally but without success.

I wondered if anyone could point me to a/some example(s) on the internet 
where the code checks the state of the transaction so that I can try and 
work them out.

Thanks for any help.

Stephen


From niheaven at gmail.com  Wed Feb 24 07:26:58 2016
From: niheaven at gmail.com (Hsiao-nan Cheung)
Date: Wed, 24 Feb 2016 14:26:58 +0800
Subject: [R-SIG-Finance] RStudio Crashes when using quantmod's
	chartSeries()
In-Reply-To: <CALB30JC_742XcVXWWgqpzAhcpY5JWfsosVzjDqc7a9z62WbeCg@mail.gmail.com>
References: <CAK80y3BRB+i_MrFQnToNGuLbmv+a9DUJ1oDz0W-y7nVM59Z86A@mail.gmail.com>
	<CALB30JC_742XcVXWWgqpzAhcpY5JWfsosVzjDqc7a9z62WbeCg@mail.gmail.com>
Message-ID: <CAK80y3CbBt8hzO=70NECf2i4-ud4CwXYR3bX+k6vB7r6DY6-iQ@mail.gmail.com>

Hi,

That's a truly RStudio problem, since I've tested it in R console. So I'll
resend it to RStudio Support and R mailing list to get a solution. Thank
you any more.

Yours,
Hsiao-nan

2016-02-22 16:15 GMT+08:00 Maxim Fomin <mxfomin at gmail.com>:

>  Hi!
>
> 1) Your problem has nothing to do with R Finance in particular. You
> have R or Rstudio problem.
> 2) You need to figure out whether it works in simple R session. If it
> works, then it is Rstudio problem.
> 3) Also please consider providing session information (if you have
> truly R problem) using sessionInfo() .
>
> P.S. The code works for me.
>
> Best regards,
> Maxim
>
> 2016-02-22 9:12 GMT+03:00 Hsiao-nan Cheung <niheaven at gmail.com>:
> > Dear All,
> >
> > Sorry for my second question.
> >
> > When I use quantmod's chartSeries() function, the RStudio crashes. The
> code
> > is as below.
> >
> > library(quantmod)
> > getSymbols("IBM")
> > chartSeries(IBM)
> >
> > Very simple code... And the same function is working well in Rgui.exe,
> i.e.
> > there is a plot in the default graphics device. So maybe it's a graphics
> > engine error?
> >
> > I've tried the plot() function, e.g., plot(chartSeries(IBM)), and it
> > crashes, too. Nothing improve.
> >
> > Yours,
> > Hsiao-nan Cheung
> > 2016/2/22
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From john.b.williams at gmail.com  Wed Feb 24 07:37:37 2016
From: john.b.williams at gmail.com (John Williams)
Date: Wed, 24 Feb 2016 01:37:37 -0500
Subject: [R-SIG-Finance] RStudio Crashes when using quantmod's
	chartSeries()
In-Reply-To: <CAK80y3CbBt8hzO=70NECf2i4-ud4CwXYR3bX+k6vB7r6DY6-iQ@mail.gmail.com>
References: <CAK80y3BRB+i_MrFQnToNGuLbmv+a9DUJ1oDz0W-y7nVM59Z86A@mail.gmail.com>
	<CALB30JC_742XcVXWWgqpzAhcpY5JWfsosVzjDqc7a9z62WbeCg@mail.gmail.com>
	<CAK80y3CbBt8hzO=70NECf2i4-ud4CwXYR3bX+k6vB7r6DY6-iQ@mail.gmail.com>
Message-ID: <CAEeDWya5VsBfg_-z_5LP==HOmC-ts2xkh-vsYiCPfeFwsHVfmw@mail.gmail.com>

library(quantmod)
getSymbols("IBM")
chartSeries(IBM)

works fine in Rstudio

On Wed, Feb 24, 2016 at 1:26 AM, Hsiao-nan Cheung <niheaven at gmail.com>
wrote:

> Hi,
>
> That's a truly RStudio problem, since I've tested it in R console. So I'll
> resend it to RStudio Support and R mailing list to get a solution. Thank
> you any more.
>
> Yours,
> Hsiao-nan
>
> 2016-02-22 16:15 GMT+08:00 Maxim Fomin <mxfomin at gmail.com>:
>
> >  Hi!
> >
> > 1) Your problem has nothing to do with R Finance in particular. You
> > have R or Rstudio problem.
> > 2) You need to figure out whether it works in simple R session. If it
> > works, then it is Rstudio problem.
> > 3) Also please consider providing session information (if you have
> > truly R problem) using sessionInfo() .
> >
> > P.S. The code works for me.
> >
> > Best regards,
> > Maxim
> >
> > 2016-02-22 9:12 GMT+03:00 Hsiao-nan Cheung <niheaven at gmail.com>:
> > > Dear All,
> > >
> > > Sorry for my second question.
> > >
> > > When I use quantmod's chartSeries() function, the RStudio crashes. The
> > code
> > > is as below.
> > >
> > > library(quantmod)
> > > getSymbols("IBM")
> > > chartSeries(IBM)
> > >
> > > Very simple code... And the same function is working well in Rgui.exe,
> > i.e.
> > > there is a plot in the default graphics device. So maybe it's a
> graphics
> > > engine error?
> > >
> > > I've tried the plot() function, e.g., plot(chartSeries(IBM)), and it
> > > crashes, too. Nothing improve.
> > >
> > > Yours,
> > > Hsiao-nan Cheung
> > > 2016/2/22
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-SIG-Finance at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > > -- Subscriber-posting only. If you want to post, subscribe first.
> > > -- Also note that this is not the r-help list where general R questions
> > should go.
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From niheaven at gmail.com  Wed Feb 24 07:41:54 2016
From: niheaven at gmail.com (Hsiao-nan Cheung)
Date: Wed, 24 Feb 2016 14:41:54 +0800
Subject: [R-SIG-Finance] RStudio Crashes when using quantmod's
	chartSeries()
In-Reply-To: <CAEeDWya5VsBfg_-z_5LP==HOmC-ts2xkh-vsYiCPfeFwsHVfmw@mail.gmail.com>
References: <CAK80y3BRB+i_MrFQnToNGuLbmv+a9DUJ1oDz0W-y7nVM59Z86A@mail.gmail.com>
	<CALB30JC_742XcVXWWgqpzAhcpY5JWfsosVzjDqc7a9z62WbeCg@mail.gmail.com>
	<CAK80y3CbBt8hzO=70NECf2i4-ud4CwXYR3bX+k6vB7r6DY6-iQ@mail.gmail.com>
	<CAEeDWya5VsBfg_-z_5LP==HOmC-ts2xkh-vsYiCPfeFwsHVfmw@mail.gmail.com>
Message-ID: <CAK80y3A_GTPVw-wBDFr0Wmkv8wzUEyPH1dVgLVww5dJ0+O4QHA@mail.gmail.com>

Sorry for no screen capture, but it really crashes here, and it's ok in R
console...

I don't know why...??

2016-02-24 14:37 GMT+08:00 John Williams <john.b.williams at gmail.com>:

> library(quantmod)
> getSymbols("IBM")
> chartSeries(IBM)

	[[alternative HTML version deleted]]


From roger.bos at rothschild.com  Fri Feb 26 18:28:00 2016
From: roger.bos at rothschild.com (Bos, Roger)
Date: Fri, 26 Feb 2016 17:28:00 +0000
Subject: [R-SIG-Finance] quartstrat applyStrategy error when starting one
 month earlier (endDate not found)
Message-ID: <0765308CD028654885F30322557308D81F072366@NYCSM0208.rth.ad.rothschild.com>

Dear all quantstrat users,

I am trying to learn how to use quantstrat with pricing data read in from a csv file using getSymbols(symbols, src='csv'). I think I have that part working, but I am having a problem that I cannot debug myself.  The following code is from the faber_rebal demo. To make it reproducible I have used dput() to generate a truncated version of the csv pricing data for my example symbol G12 (actually XLF).  I have truncated the data to make it easier to post this message.  The first version of G12 does not work and the second version does.  The only difference is the starting point.  If the G12 data starts in 1/31/1999 the code works fine, but if the G12 data starts in 12/31/1998 the code gives an error in applyStrategy.rebalancing:

> out<-applyStrategy.rebalancing(strategy='faber' , portfolios='faber')
Error in if (is.na(endDate)) endDate <- NULL : argument is of length zero

Thanks in advance for any advice on this, Roger


# Not Working (starting at 12/31/1998)
G12 <- structure(c(23.4375, 23.84375, 24.21875, 24.9375, 26.6875, 25.078125, 
26.09375, 24.5, 23.421875, 22.125, 25.5625, 24.4375, 23.765625, 
23.0625, 20.59375, 24.265625, 24.5, 25.046875, 23.75, 25.984375, 
28.46875, 29, 28.75, 27.28125, 29.5, 23.8125, 25.0625, 24.875, 
26.3125, 29.28125, 27.28125, 26.3125, 26.84375, 25.796875, 24.25, 
26.15625, 26.78125, 25.40625, 24.078125, 23.234375, 25.1875, 
25.796875, 25.1875, 27.15625, 26.34375, 28.625, 29.625, 29.625, 
29.21875, 30.0625, 23.21875, 22.71875, 22.0625, 24.015625, 24.75, 
24.375, 24.15625, 24.46875, 22.65625, 21.5, 20.875, 24.03125, 
22.71875, 21.46875, 19.65625, 19.46875, 22.125, 22.65625, 23.40625, 
23.5625, 25.875, 27.125, 24.875, 25.75, 26.71875, 23.4375, 23.84375, 
24.21875, 24.9375, 26.6875, 25.078125, 26.09375, 24.5, 23.421875, 
22.125, 25.5625, 24.4375, 23.765625, 23.0625, 20.59375, 24.265625, 
24.5, 25.046875, 23.75, 25.984375, 28.46875, 29, 28.75, 27.28125, 
29.5, 447800, 2057500, 2334300, 3122300, 2662900, 3307500, 2091900, 
2333800, 3945700, 5653600, 9955200, 5993600, 14715300, 8663400, 
8425500, 15117400, 8647800, 5391700, 9438800, 4609900, 4224100, 
9112300, 18210900, 17317600, 21173200, 23.4375, 23.84375, 24.21875, 
24.9375, 26.6875, 25.078125, 26.09375, 24.5, 23.421875, 22.125, 
25.5625, 24.4375, 23.765625, 23.0625, 20.59375, 24.265625, 24.5, 
25.046875, 23.75, 25.984375, 28.46875, 29, 28.75, 27.28125, 29.5), 
.Dim = c(25L, 6L), .Dimnames = list(NULL, c("G12.Open", "G12.High", 
"G12.Low", "G12.Close", "G12.Volume", "G12.Adjusted")), index = structure(c(915062400, 
                                   917740800, 920160000, 922838400, 925430400, 928108800, 930700800, 
                                   933379200, 936057600, 938649600, 941328000, 943920000, 946598400, 
                                   949276800, 951782400, 954460800, 957052800, 959731200, 962323200, 
                                   965001600, 967680000, 970272000, 972950400, 975542400, 978220800
), tclass = "Date"), tclass = "Date", tzone = "UTC", src = "csv", updated = structure(1456505311.48799, class = c("POSIXct", 
                                                                         "POSIXt")), .indexCLASS = "Date", .indexTZ = "UTC", .indexFORMAT = "%Y-%m-%d", class = c("xts","zoo"))


# Working (starting at 1/31/1999)
G12 <- structure(c(23.84375, 24.21875, 24.9375, 26.6875, 25.078125, 
26.09375, 24.5, 23.421875, 22.125, 25.5625, 24.4375, 23.765625, 
23.0625, 20.59375, 24.265625, 24.5, 25.046875, 23.75, 25.984375, 
28.46875, 29, 28.75, 27.28125, 29.5, 25.0625, 24.875, 26.3125, 
29.28125, 27.28125, 26.3125, 26.84375, 25.796875, 24.25, 26.15625, 
26.78125, 25.40625, 24.078125, 23.234375, 25.1875, 25.796875, 
25.1875, 27.15625, 26.34375, 28.625, 29.625, 29.625, 29.21875, 
30.0625, 22.71875, 22.0625, 24.015625, 24.75, 24.375, 24.15625, 
24.46875, 22.65625, 21.5, 20.875, 24.03125, 22.71875, 21.46875, 
19.65625, 19.46875, 22.125, 22.65625, 23.40625, 23.5625, 25.875, 
27.125, 24.875, 25.75, 26.71875, 23.84375, 24.21875, 24.9375, 
26.6875, 25.078125, 26.09375, 24.5, 23.421875, 22.125, 25.5625, 
24.4375, 23.765625, 23.0625, 20.59375, 24.265625, 24.5, 25.046875, 
23.75, 25.984375, 28.46875, 29, 28.75, 27.28125, 29.5, 2057500, 
2334300, 3122300, 2662900, 3307500, 2091900, 2333800, 3945700, 
5653600, 9955200, 5993600, 14715300, 8663400, 8425500, 15117400, 
8647800, 5391700, 9438800, 4609900, 4224100, 9112300, 18210900, 
17317600, 21173200, 23.84375, 24.21875, 24.9375, 26.6875, 25.078125, 
26.09375, 24.5, 23.421875, 22.125, 25.5625, 24.4375, 23.765625, 
23.0625, 20.59375, 24.265625, 24.5, 25.046875, 23.75, 25.984375, 
28.46875, 29, 28.75, 27.28125, 29.5), .Dim = c(24L, 6L), .Dimnames = list(
NULL, c("G12.Open", "G12.High", "G12.Low", "G12.Close", "G12.Volume", 
"G12.Adjusted")), index = structure(c(917740800, 920160000, 
922838400, 925430400, 928108800, 930700800, 933379200, 936057600, 
938649600, 941328000, 943920000, 946598400, 949276800, 951782400, 
954460800, 957052800, 959731200, 962323200, 965001600, 967680000, 
970272000, 972950400, 975542400, 978220800), tclass = "Date"), tclass = "Date", tzone = "UTC", src = "csv", 
updated = structure(1456505447.82159, class = c("POSIXct", 
"POSIXt")), .indexCLASS = "Date", .indexTZ = "UTC", .indexFORMAT = "%Y-%m-%d", class = c("xts","zoo"))



# Load required libraries
require(quantstrat)

#correct for TZ issues if they crop up
oldtz <- Sys.getenv('TZ')
if(oldtz=='') {
  Sys.setenv(TZ="UTC")
}

# Try to clean up in case the demo was run previously
suppressWarnings(rm("account.faber","portfolio.faber",pos=.blotter))
suppressWarnings(rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate", "equity", 
            "GSPC", "stratFaber", "startDate", "initEq", "Posn", "UnitSize", "verbose"))
suppressWarnings(rm("order_book.faber",pos=.strategy))

# Set initial values
startDate='1997-12-31'
initEq=100000

# Set up instruments with FinancialInstruments package
currency("USD")
#symbols = c("XLF", "XLP", "XLE", "XLY", "XLV", "XLI", "XLB", "XLK", "XLU")
symbols = c("G12")
for(symbol in symbols){ # establish tradable instruments
    stock(symbol, currency="USD",multiplier=1)
}

# Load data with quantmod
#getSymbols(symbols, src='yahoo', index.class=c("POSIXt","POSIXct"), from='1998-01-01')
### Download monthly data instead?
### GSPC=to.monthly(GSPC, indexAt='endof')
#getSymbols(symbols, src='yahoo', index.class=c("POSIXt","POSIXct"), from='1999-01-01')
#getSymbols(symbols, src='csv')
for(symbol in symbols) {
    x<-get(symbol)
    x<-to.monthly(x,indexAt='lastof',drop.time=TRUE)
    indexFormat(x)<-'%Y-%m-%d'
    colnames(x)<-gsub("x",symbol,colnames(x))
    assign(symbol,x)
}

# Initialize portfolio and account
initPortf('faber', symbols=symbols)
initAcct('faber', portfolios='faber', initEq=100000)
initOrders(portfolio='faber')

# set intial position limits
posval <- initEq/length(symbols)
for(symbol in symbols){
  #pos <- round((posval/first(getPrice(get(symbol)))[,1]),-2)
  pos <- round((posval/first(getPrice(get(symbol)))),-2)
  addPosLimit('faber', symbol, startDate, maxpos=pos, minpos=-pos)
}
print("setup completed")

# Initialize a strategy object
strategy("faber", store=TRUE)

# Add an indicator
add.indicator('faber', name = "SMA", arguments = list(x = quote(Cl(mktdata)), n=10), label="SMA10")

# There are two signals:
# The first is when monthly price crosses over the 10-month SMA
add.signal('faber',name="sigCrossover",arguments = list(columns=c("Close","SMA10"),relationship="gte"),label="Cl.gt.SMA")
# The second is when the monthly price crosses under the 10-month SMA
add.signal('faber',name="sigCrossover",arguments = list(columns=c("Close","SMA10"),relationship="lt"),label="Cl.lt.SMA")

# There are two rules:
# The first is to buy when the price crosses above the SMA
add.rule('faber', name='ruleSignal', arguments = list(sigcol="Cl.gt.SMA", sigval=TRUE, orderqty=100000, osFUN='osMaxPos', ordertype='market', orderside='long', pricemethod='market',TxnFees=-5), type='enter', path.dep=TRUE)
# The second is to sell when the price crosses below the SMA
add.rule('faber', name='ruleSignal', arguments = list(sigcol="Cl.lt.SMA", sigval=TRUE, orderqty='all', ordertype='market', orderside='long', pricemethod='market',TxnFees=-5), type='exit', path.dep=TRUE)

# add quaterly rebalancing
add.rule('faber', 'rulePctEquity',
        arguments=list(rebalance_on='quarters',
                trade.percent=1/length(symbols),
                refprice=quote(last(getPrice(mktdata)[paste('::',as.character(curIndex),sep='')][,1])),
                digits=0
        ),
        type='rebalance',
        label='rebalance'
)

# Process the strategy and generate trades
start_t<-Sys.time()
out<-applyStrategy.rebalancing(strategy='faber' , portfolios='faber')
end_t<-Sys.time()
print("Strategy Loop:")
print(end_t-start_t)


From suchislife27 at gmail.com  Mon Feb 29 04:10:11 2016
From: suchislife27 at gmail.com (Ryan)
Date: Mon, 29 Feb 2016 14:10:11 +1100
Subject: [R-SIG-Finance] Time in Force conditions with Quantstrat
Message-ID: <CANf4qfjuqJ2Ps1+nwd+=hZXUbMpY2oNL_SnkiHxucderLXy_mw@mail.gmail.com>

I'm having some difficulty getting time in force to work with quanstrat.

I've studied the documentation and it states that:

timestamp time-in-force; either a time stamp, or a number of seconds, or
'GTC' / ?, 'GTC' and ? both meaning 'Good Till Canceled'; order expires if
still 'open' at this timestamp, default is ?

I have been trying to enter a limit order, 5% below the Close price, as
when I study the orderbook and mktdata object, it appears that a limit
order is based on the bar in which the signal occurs. Hence the limit price
would be 5% below the Close.

I've tried to enter a time in seconds, which is the equivalent to two days,
for the sake of the example. If I remove timestamp it runs however
time.in.force remains blank in the orderbook as I would expect timestamp +
time.in.force is the time when the order is cancelled.

As laid out below I get the following error:

Error in if (prefer == "Close") { : argument is of length zero


Below is a reproducible example that produces the error. Any assistance
would be greatly appreciated.


require(quantstrat)
require(quantmod)
require(PerformanceAnalytics)
require(TTR)
require(blotter)
require(IKTrading)

# Suppresses warnings
options("getSymbols.warning4.0" = FALSE)

# Set the currency and the timezone
currency('USD')
Sys.setenv(TZ = "UTC")

# Define symbols of interest
symbols <- c("AMP.AX",
             "BHP.AX",
             "ANZ.AX",
             "CBA.AX",
             "BXB.AX",
             "CSL.AX",
             "IAG.AX",
             "MQG.AX",
             "NAB.AX",
             "ORG.AX",
             "QBE.AX",
             "RIO.AX",
             "SCG.AX",
             "SUN.AX",
             "TLS.AX",
             "WBC.AX",
             "WES.AX",
             "WOW.AX",
             "WPL.AX",
             "TCL.AX",
             "WFD.AX",
             "AMC.AX"
)


#Get Symbols
getSymbols(Symbols=symbols, from="2010-01-01", to="2015-12-31")

# Define the instrument type
stock(symbols, currency = "USD", multiplier = 1)

#Boilerplate
initDate = "2005-01-01"
from = "2010-01-01"
to = "2015-12-31"

#trade sizing and initial equity settings
tradeSize <- 2500
initEq <- 100000

strategy.st <- portfolio.st <- account.st <- "Timeinforce"
rm.strat(portfolio.st)
rm.strat(strategy.st)
initPortf(portfolio.st, symbols=symbols, initDate=initDate, currency='USD')
initAcct(account.st, portfolios=portfolio.st, initDate=initDate,
currency='USD',initEq=initEq)
initOrders(portfolio.st, initDate=initDate)
strategy(strategy.st, store=TRUE)

#parameters

nSMA=20

#Add Indicators

add.indicator(strategy.st, name="SMA",
              arguments=list(x=quote(Cl(mktdata)), n=nSMA),
              label="sma")

#Add Entry and Exit Signals

add.signal(strategy.st, name="sigComparison",
           arguments=list(columns=c("Close", "SMA.20.sma"),
relationship="gt"),
           label="longentry")

#add.signal(strategy.st, name="sigComparison",
#          arguments=list(columns=c("Close", "SMA.20.sma"),
relationship="lt"),
#         label="longexit")

#enter signal rule
add.rule(strategy.st, name="ruleSignal",
         arguments=list(sigcol="longentry", sigval=TRUE, ordertype="limit",
                        orderside="long", replace=TRUE, prefer="Close",
tmult = TRUE, threshold = 0.05, timestamp, time.in.force='172800',
orderqty=tradeSize, osFUN=osMaxDollar, tradeSize=tradeSize,
                        maxSize=tradeSize),
         type="enter", path.dep=TRUE, label="enterlong")

#add.rule(strategy.st, name="ruleSignal",
#       arguments=list(sigcol="longexit", sigval=TRUE, ordertype="market",
#                    orderside="long", replace=FALSE, prefer="Open",
orderqty="all", TxnFees=-12),
#   type="exit", path.dep=TRUE, label="exitlong")

#stop loss.
add.rule(strategy.st, name="ruleSignal", arguments=list(sigcol="longentry",
                                                        sigval=TRUE,

ordertype="stoptrailing",
                                                        orderside="long",
                                                        replace=FALSE,
                                                        orderqty="all",
                                                        threshold=0.05,
                                                        tmult=TRUE,
                                                        orderset="ocolong"),
         type="chain",
         parent="enterlong",
         label="stopLossLong",
         path.dep=TRUE,
         enable=TRUE)

#apply strategy
t1 <- Sys.time()
out2 <- applyStrategy(strategy=strategy.st,portfolios=portfolio.st )
t2 <- Sys.time()
print(t2-t1)

	[[alternative HTML version deleted]]


From george.schmoll at sbcglobal.net  Thu Mar  3 18:28:35 2016
From: george.schmoll at sbcglobal.net (George Schmoll)
Date: Thu, 3 Mar 2016 11:28:35 -0600
Subject: [R-SIG-Finance] addTA not working
Message-ID: <56D87443.3040109@sbcglobal.net>

I have been trying to display multiple chart using a TDNN creating a 
forecast. When done on a individual time series, there is no problem. 
When trying to do multiple charts, the forecast line is missing.
The entire source code follows.

library(quantmod)
library(TTR)
library(forecast)
library(nnet)

from<-as.Date("2010-12-01")

tickers<-c("MSFT")#,"ORCL","IBM","HPQ")
getSymbols(tickers,from=from,auto.assign=TRUE)

for(ticker in tickers)
   {
   sym        <-eval((parse(text=ticker)))
   clse       <- Cl(sym)
   hi         <- Hi(sym)
   lo         <- Lo(sym)
   vo         <- Vo(sym)
   DataLength <-length(clse)
   MidPoint   <- DataLength-10
   MaxHigh    <- max(hi);
   MinLow     <- min(lo);
   MaxVol     <- max(vo)
   MinVol     <- min(vo)
   xiLag0     <- (clse-MinLow)/(MaxHigh-MinLow)
   xiLag1     <- lag(xiLag0,1,na.pad=TRUE)
   xiLag2     <- lag(xiLag0,2,na.pad=TRUE)
   xiLag3     <- lag(xiLag0,3,na.pad=TRUE)
   xiLag4     <- lag(xiLag0,4,na.pad=TRUE)
   volLag0    <- (vo-MinVol)/(MaxVol-MinVol)
   volLag1    <- lag(volLag0,1,na.pad=TRUE)
   volLag2    <- lag(volLag0,2,na.pad=TRUE)
   volLag3    <- lag(volLag0,3,na.pad=TRUE)
   volLag4    <- lag(volLag0,4,na.pad=TRUE)

   DeltaClose <- diff(clse)
   Max        <-max(na.omit(DeltaClose))
   Min        <-min(na.omit(DeltaClose))
   scaleDeltaClose<-(DeltaClose-Min)/(Max-Min)

   DeltaClose <-lag(DeltaClose,-1,na.pad=TRUE)
   scaleDeltaClose<-lag(scaleDeltaClose,-1,na.pad=TRUE)

   data.all   <-cbind(sym,xiLag0,
                   xiLag1,xiLag2,xiLag3,xiLag4,
                   volLag0,volLag1,volLag2,volLag3,
                   volLag4,scaleDeltaClose)
   colnames(data.all)<-c("Open","High","Low",
                         "Close","Volume","Adj",
                         "xiLag0","xiLag1","xiLag2",
                         "xiLag3","xiLag4","volLag0",
                         "volLag1","volLag2","volLag3",
                         "volLag4","scaleDeltaClose")
   data.train <-data.all[10:MidPoint]
   data.eval  <-data.all[MidPoint:DataLength]
   learn<-nnet(scaleDeltaClose~
               xiLag0+xiLag1+xiLag2+xiLag3+xiLag4+
               volLag0+volLag1+volLag2+volLag3+volLag4,
               data=data.train,size=5,maxit=10000)
   prdct<-predict(learn,data.eval,type="raw")
   Change<-prdct*(Max-Min)+Min
   Forecast<-data.eval$Close+Change
candleChart(sym,subset='2016-01::2016',name=ticker,theme="white",TA=NULL)
   addTA(Forecast,col="blue",on=1)
   }

Thanks in advance. George
-- 
<mailto:gschmoll at acm.org>


	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Thu Mar  3 19:27:05 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 3 Mar 2016 12:27:05 -0600
Subject: [R-SIG-Finance] addTA not working
In-Reply-To: <56D87443.3040109@sbcglobal.net>
References: <56D87443.3040109@sbcglobal.net>
Message-ID: <CAPPM_gQHgBep1zmfuY7y3t3543cGZfqBOiq2+arAcUu5axxb_w@mail.gmail.com>

This question has been asked many, many times on this list and on
StackOverflow.  You need to either 1) include the addTA call in your
chartSeries call, or 2) wrap the addTA call in plot().

# 1)
candleChart(sym, subset='2016-01::2016', name=ticker,
  theme="white", TA='addTA(Forecast,col="blue",on=1)')
# 2)
candleChart(sym, subset='2016-01::2016', name=ticker, theme="white", TA=NULL)
plot(addTA(Forecast,col="blue",on=1))

On Thu, Mar 3, 2016 at 11:28 AM, George Schmoll
<george.schmoll at sbcglobal.net> wrote:
> I have been trying to display multiple chart using a TDNN creating a
> forecast. When done on a individual time series, there is no problem.
> When trying to do multiple charts, the forecast line is missing.
> The entire source code follows.
>
> library(quantmod)
> library(TTR)
> library(forecast)
> library(nnet)
>
> from<-as.Date("2010-12-01")
>
> tickers<-c("MSFT")#,"ORCL","IBM","HPQ")
> getSymbols(tickers,from=from,auto.assign=TRUE)
>
> for(ticker in tickers)
>    {
>    sym        <-eval((parse(text=ticker)))
>    clse       <- Cl(sym)
>    hi         <- Hi(sym)
>    lo         <- Lo(sym)
>    vo         <- Vo(sym)
>    DataLength <-length(clse)
>    MidPoint   <- DataLength-10
>    MaxHigh    <- max(hi);
>    MinLow     <- min(lo);
>    MaxVol     <- max(vo)
>    MinVol     <- min(vo)
>    xiLag0     <- (clse-MinLow)/(MaxHigh-MinLow)
>    xiLag1     <- lag(xiLag0,1,na.pad=TRUE)
>    xiLag2     <- lag(xiLag0,2,na.pad=TRUE)
>    xiLag3     <- lag(xiLag0,3,na.pad=TRUE)
>    xiLag4     <- lag(xiLag0,4,na.pad=TRUE)
>    volLag0    <- (vo-MinVol)/(MaxVol-MinVol)
>    volLag1    <- lag(volLag0,1,na.pad=TRUE)
>    volLag2    <- lag(volLag0,2,na.pad=TRUE)
>    volLag3    <- lag(volLag0,3,na.pad=TRUE)
>    volLag4    <- lag(volLag0,4,na.pad=TRUE)
>
>    DeltaClose <- diff(clse)
>    Max        <-max(na.omit(DeltaClose))
>    Min        <-min(na.omit(DeltaClose))
>    scaleDeltaClose<-(DeltaClose-Min)/(Max-Min)
>
>    DeltaClose <-lag(DeltaClose,-1,na.pad=TRUE)
>    scaleDeltaClose<-lag(scaleDeltaClose,-1,na.pad=TRUE)
>
>    data.all   <-cbind(sym,xiLag0,
>                    xiLag1,xiLag2,xiLag3,xiLag4,
>                    volLag0,volLag1,volLag2,volLag3,
>                    volLag4,scaleDeltaClose)
>    colnames(data.all)<-c("Open","High","Low",
>                          "Close","Volume","Adj",
>                          "xiLag0","xiLag1","xiLag2",
>                          "xiLag3","xiLag4","volLag0",
>                          "volLag1","volLag2","volLag3",
>                          "volLag4","scaleDeltaClose")
>    data.train <-data.all[10:MidPoint]
>    data.eval  <-data.all[MidPoint:DataLength]
>    learn<-nnet(scaleDeltaClose~
>                xiLag0+xiLag1+xiLag2+xiLag3+xiLag4+
>                volLag0+volLag1+volLag2+volLag3+volLag4,
>                data=data.train,size=5,maxit=10000)
>    prdct<-predict(learn,data.eval,type="raw")
>    Change<-prdct*(Max-Min)+Min
>    Forecast<-data.eval$Close+Change
> candleChart(sym,subset='2016-01::2016',name=ticker,theme="white",TA=NULL)
>    addTA(Forecast,col="blue",on=1)
>    }
>
> Thanks in advance. George
> --
> <mailto:gschmoll at acm.org>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From george.schmoll at sbcglobal.net  Thu Mar  3 20:00:20 2016
From: george.schmoll at sbcglobal.net (George Schmoll)
Date: Thu, 3 Mar 2016 13:00:20 -0600
Subject: [R-SIG-Finance] addTA not working
In-Reply-To: <CAPPM_gQHgBep1zmfuY7y3t3543cGZfqBOiq2+arAcUu5axxb_w@mail.gmail.com>
References: <56D87443.3040109@sbcglobal.net>
	<CAPPM_gQHgBep1zmfuY7y3t3543cGZfqBOiq2+arAcUu5axxb_w@mail.gmail.com>
Message-ID: <56D889C4.7090907@sbcglobal.net>

Thank you for your time. I guess I did not search enough. Both 
techniques worked. George

On 3/3/2016 12:27 PM, Joshua Ulrich wrote:
> This question has been asked many, many times on this list and on
> StackOverflow.  You need to either 1) include the addTA call in your
> chartSeries call, or 2) wrap the addTA call in plot().
>
> # 1)
> candleChart(sym, subset='2016-01::2016', name=ticker,
>    theme="white", TA='addTA(Forecast,col="blue",on=1)')
> # 2)
> candleChart(sym, subset='2016-01::2016', name=ticker, theme="white", TA=NULL)
> plot(addTA(Forecast,col="blue",on=1))
>
> On Thu, Mar 3, 2016 at 11:28 AM, George Schmoll
> <george.schmoll at sbcglobal.net> wrote:
>> I have been trying to display multiple chart using a TDNN creating a
>> forecast. When done on a individual time series, there is no problem.
>> When trying to do multiple charts, the forecast line is missing.
>> The entire source code follows.
>>
>> library(quantmod)
>> library(TTR)
>> library(forecast)
>> library(nnet)
>>
>> from<-as.Date("2010-12-01")
>>
>> tickers<-c("MSFT")#,"ORCL","IBM","HPQ")
>> getSymbols(tickers,from=from,auto.assign=TRUE)
>>
>> for(ticker in tickers)
>>     {
>>     sym        <-eval((parse(text=ticker)))
>>     clse       <- Cl(sym)
>>     hi         <- Hi(sym)
>>     lo         <- Lo(sym)
>>     vo         <- Vo(sym)
>>     DataLength <-length(clse)
>>     MidPoint   <- DataLength-10
>>     MaxHigh    <- max(hi);
>>     MinLow     <- min(lo);
>>     MaxVol     <- max(vo)
>>     MinVol     <- min(vo)
>>     xiLag0     <- (clse-MinLow)/(MaxHigh-MinLow)
>>     xiLag1     <- lag(xiLag0,1,na.pad=TRUE)
>>     xiLag2     <- lag(xiLag0,2,na.pad=TRUE)
>>     xiLag3     <- lag(xiLag0,3,na.pad=TRUE)
>>     xiLag4     <- lag(xiLag0,4,na.pad=TRUE)
>>     volLag0    <- (vo-MinVol)/(MaxVol-MinVol)
>>     volLag1    <- lag(volLag0,1,na.pad=TRUE)
>>     volLag2    <- lag(volLag0,2,na.pad=TRUE)
>>     volLag3    <- lag(volLag0,3,na.pad=TRUE)
>>     volLag4    <- lag(volLag0,4,na.pad=TRUE)
>>
>>     DeltaClose <- diff(clse)
>>     Max        <-max(na.omit(DeltaClose))
>>     Min        <-min(na.omit(DeltaClose))
>>     scaleDeltaClose<-(DeltaClose-Min)/(Max-Min)
>>
>>     DeltaClose <-lag(DeltaClose,-1,na.pad=TRUE)
>>     scaleDeltaClose<-lag(scaleDeltaClose,-1,na.pad=TRUE)
>>
>>     data.all   <-cbind(sym,xiLag0,
>>                     xiLag1,xiLag2,xiLag3,xiLag4,
>>                     volLag0,volLag1,volLag2,volLag3,
>>                     volLag4,scaleDeltaClose)
>>     colnames(data.all)<-c("Open","High","Low",
>>                           "Close","Volume","Adj",
>>                           "xiLag0","xiLag1","xiLag2",
>>                           "xiLag3","xiLag4","volLag0",
>>                           "volLag1","volLag2","volLag3",
>>                           "volLag4","scaleDeltaClose")
>>     data.train <-data.all[10:MidPoint]
>>     data.eval  <-data.all[MidPoint:DataLength]
>>     learn<-nnet(scaleDeltaClose~
>>                 xiLag0+xiLag1+xiLag2+xiLag3+xiLag4+
>>                 volLag0+volLag1+volLag2+volLag3+volLag4,
>>                 data=data.train,size=5,maxit=10000)
>>     prdct<-predict(learn,data.eval,type="raw")
>>     Change<-prdct*(Max-Min)+Min
>>     Forecast<-data.eval$Close+Change
>> candleChart(sym,subset='2016-01::2016',name=ticker,theme="white",TA=NULL)
>>     addTA(Forecast,col="blue",on=1)
>>     }
>>
>> Thanks in advance. George
>> --
>> <mailto:gschmoll at acm.org>
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>
>


From stephen at organicfoodmarkets.com.au  Fri Mar  4 04:38:36 2016
From: stephen at organicfoodmarkets.com.au (Stephen Choularton)
Date: Fri, 4 Mar 2016 14:38:36 +1100
Subject: [R-SIG-Finance] tick data and one minute bar data appear out of
	line (IBrokers)
Message-ID: <56D9033C.4010508@organicfoodmarkets.com.au>

Hi

I have been working on the spread between Commonwealth Bank (CBA.ASX) 
and National Australia Bank (NAB.ASX).

I was a bit confused by the performance of my dealing loop so I took out 
the spread movement from rqHistoricData 1 minute bars using the close 
and plotted it and also the spread derived from the tick data from 
reqMktData which is being used to drive my dealing algorithm.

They are in the same ballpark but really rather different.  The graph 
shows the position best and can be viewed at this url: 
http://www.organicfoodmarkets.com.au/bar-n-tick-plots.pdf

I am not experienced with this so I wondered if this sort of discrepancy 
is typical or am I just making a mess of it.  If they are typical so it 
makes setting trigger levels a bit difficult as mine are derived from 
bar data but implemented by tick data movement.  I'm surprised the tick 
data doesn't fall within the one minute bar so any comments would be of 
great interest.  Am I better to only work with tick data for example?

Stephen Choularton PhD, FIoD


From josh.m.ulrich at gmail.com  Fri Mar  4 04:50:26 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 3 Mar 2016 21:50:26 -0600
Subject: [R-SIG-Finance] tick data and one minute bar data appear out of
 line (IBrokers)
In-Reply-To: <56D9033C.4010508@organicfoodmarkets.com.au>
References: <56D9033C.4010508@organicfoodmarkets.com.au>
Message-ID: <CAPPM_gSLkGMdJDLb7eDn9rY6H8SKDTN=F08S8DAOmB_vevtiWw@mail.gmail.com>

On Thu, Mar 3, 2016 at 9:38 PM, Stephen Choularton
<stephen at organicfoodmarkets.com.au> wrote:
> Hi
>
> I have been working on the spread between Commonwealth Bank (CBA.ASX) and
> National Australia Bank (NAB.ASX).
>
> I was a bit confused by the performance of my dealing loop so I took out the
> spread movement from rqHistoricData 1 minute bars using the close and
> plotted it and also the spread derived from the tick data from reqMktData
> which is being used to drive my dealing algorithm.
>
> They are in the same ballpark but really rather different.  The graph shows
> the position best and can be viewed at this url:
> http://www.organicfoodmarkets.com.au/bar-n-tick-plots.pdf
>
The 1-minute close price is a (potentially very small) sample of all
the price changes that occur in a given minute interval.  The fact
that they're similar is likely because the price wasn't moving much
during the hours in your plot.  If prices were moving a lot, I
wouldn't expect them to be very similar at all.

If you look at the tick data versus the high-low range, you should see
that all the tick prices fall within that range for every aggregate
interval.

> I am not experienced with this so I wondered if this sort of discrepancy is
> typical or am I just making a mess of it.  If they are typical so it makes
> setting trigger levels a bit difficult as mine are derived from bar data but
> implemented by tick data movement.  I'm surprised the tick data doesn't fall
> within the one minute bar so any comments would be of great interest.  Am I
> better to only work with tick data for example?
>
> Stephen Choularton PhD, FIoD
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From stephen at organicfoodmarkets.com.au  Fri Mar  4 06:47:59 2016
From: stephen at organicfoodmarkets.com.au (Stephen Choularton)
Date: Fri, 4 Mar 2016 16:47:59 +1100
Subject: [R-SIG-Finance] tick data and one minute bar data appear out of
 line (IBrokers)
In-Reply-To: <CAPPM_gSLkGMdJDLb7eDn9rY6H8SKDTN=F08S8DAOmB_vevtiWw@mail.gmail.com>
References: <56D9033C.4010508@organicfoodmarkets.com.au>
	<CAPPM_gSLkGMdJDLb7eDn9rY6H8SKDTN=F08S8DAOmB_vevtiWw@mail.gmail.com>
Message-ID: <56D9218F.7030805@organicfoodmarkets.com.au>

Hi Joshua

Just trying to follow that comment 'If you look at the tick data versus 
the high-low range, you should see that all the tick prices fall within 
that range for every aggregate interval.'

The summary of the two datasets is:

  summary(bars)
      Index                       CBA.Close
  Min.   :2016-03-03 10:06:00   Min.   :48.31
  1st Qu.:2016-03-03 11:37:00   1st Qu.:48.38
  Median :2016-03-03 13:08:00   Median :48.45
  Mean   :2016-03-03 13:08:00   Mean   :48.46
  3rd Qu.:2016-03-03 14:39:00   3rd Qu.:48.53
  Max.   :2016-03-03 16:10:00   Max.   :48.73


and

summary(ticks)
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
   47.82   48.41   48.44   48.47   48.49   49.00

Now that min figure is the result of some market closing phenomena and 
it really never went much below 48.3 so yes its true that they have a 
similar range and min and max but ticks gets up into the just under 49.0 
level around 10:15 and bars only gets to that level around 11:30 and 
again at noon while ticks is under 48.6 at that point.

Sounds like you don't think there is anything that unusual in the two 
datasets so I guess I had better take that on board and keep on trying 
to make this work.

Thanks for looking at it

Stephen Choularton PhD, FIoD

On 4/03/2016 2:50 PM, Joshua Ulrich wrote:
> On Thu, Mar 3, 2016 at 9:38 PM, Stephen Choularton
> <stephen at organicfoodmarkets.com.au> wrote:
>> Hi
>>
>> I have been working on the spread between Commonwealth Bank (CBA.ASX) and
>> National Australia Bank (NAB.ASX).
>>
>> I was a bit confused by the performance of my dealing loop so I took out the
>> spread movement from rqHistoricData 1 minute bars using the close and
>> plotted it and also the spread derived from the tick data from reqMktData
>> which is being used to drive my dealing algorithm.
>>
>> They are in the same ballpark but really rather different.  The graph shows
>> the position best and can be viewed at this url:
>> http://www.organicfoodmarkets.com.au/bar-n-tick-plots.pdf
>>
> The 1-minute close price is a (potentially very small) sample of all
> the price changes that occur in a given minute interval.  The fact
> that they're similar is likely because the price wasn't moving much
> during the hours in your plot.  If prices were moving a lot, I
> wouldn't expect them to be very similar at all.
>
> If you look at the tick data versus the high-low range, you should see
> that all the tick prices fall within that range for every aggregate
> interval.
>
>> I am not experienced with this so I wondered if this sort of discrepancy is
>> typical or am I just making a mess of it.  If they are typical so it makes
>> setting trigger levels a bit difficult as mine are derived from bar data but
>> implemented by tick data movement.  I'm surprised the tick data doesn't fall
>> within the one minute bar so any comments would be of great interest.  Am I
>> better to only work with tick data for example?
>>
>> Stephen Choularton PhD, FIoD
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>


From lhvan at u.nus.edu  Sun Mar  6 11:21:54 2016
From: lhvan at u.nus.edu (Le Hoang Van)
Date: Sun, 6 Mar 2016 10:21:54 +0000
Subject: [R-SIG-Finance] Copula-GARCH with rmgarch package
Message-ID: <51A3921C-96F2-4F94-AD95-0BAA662119A9@u.nus.edu>

Hi all,

I'm using the rmgarch package to model asset returns using the function cgarchfit function. The latest version of this package currently supports Gaussian copula and Student-t copula with time varying correlation rho_t. I have read the vignette but still not sure how the rho_t is modeled. There is, however, a brief mention of the seminal paper of Patton (2006) [1] on extension of static copulas to dynamic models, so is it safe to assume that the rho_t is modeled as per Patton?s approach? Or is it just a by-product of fitting a DCC-GARCH model a la Engle's?

If anyone could clarify that for me it would be great, thank you!

References
[1] A.J. Patton. Modelling asymmetric exchange rate dependence. International Economic Review, 47(2):527?556, 2006.

-Van

	[[alternative HTML version deleted]]


From peter.neumaier at gmail.com  Sun Mar  6 17:47:45 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Sun, 6 Mar 2016 16:47:45 +0000
Subject: [R-SIG-Finance] Trailing stop not working in R (Luxor example)
Message-ID: <CAHDRDJVtF+U06FdeCyB6MH96W=xALo9PH-MepmsxUY-9txQuSw@mail.gmail.com>

I am trying to implement a trailing stop in the Luxor example.

I have tried many approaches to debug/find the error, i.e.

   - run with and without stoploss enabled
   - different levels of stoptrailingpercent
   - the list goes on

But my orderbook (ob.df at the of code) simply is not showing any trailing
stops executed.

Anyone got any suggestions why my trailing stop is not working? Here is my
code:


## ----results='hide'------------------------------------------------------
library(quantstrat)

options(width = 240)#options(warn=1)

Sys.setenv(TZ="UTC")
###
initDate = '2003-10-21'
.from='2012-01-01'
.to='2016-03-01'

currency(c('EUR', 'USD'))
exchange_rate('EURUSD', tick_size=0.0001)

# moving average lengths
.fast = 6
.slow = 21
# optimization range
.FastSMA = (1:30)
.SlowSMA = (20:80)
# trade parameters
.threshold = 0.0005
.orderqty = 100000
.txnfees = -6  # round-trip fee
# stop loss amount
.stoploss <- 0.30/100
# trading window
.timespan = 'T00:00/T23:59'
# number of optimization samples
.nsamples=80

## ------------------------------------------------------------------------portfolio.st
= 'forex'account.st = 'IB1'strategy.st = 'luxor'

.trailingStopPercent <- 0.001

rm.strat(portfolio.st)
rm.strat(account.st)
rm.strat(strategy.st)
## ----results='hide'------------------------------------------------------
initPortf(portfolio.st, symbols='EURUSD', initDate=initDate, currency='USD')
addPosLimit(portfolio=portfolio.st,symbol='EURUSD',
timestamp=initDate,maxpos=.orderqty)

    initAcct(account.st,portfolios=portfolio.st,initDate=initDate,currency='USD')
initOrders(portfolio.st, initDate=initDate)
strategy(strategy.st, store=TRUE)

getSymbols("EUR/USD", src="oanda", from=.from, to=.to,
index.class="POSIXct",adjust=T)

EURUSD = to.minutes30(EURUSD)
EURUSD = align.time(EURUSD, 1800)



add.indicator(strategy.st, name = "SMA",
          arguments = list(
            x = quote(Cl(mktdata)[,1]),
            n = .fast
          ),
          label="nFast")

add.indicator(strategy.st, name="SMA",
          arguments = list(
            x = quote(Cl(mktdata)[,1]),
            n = .slow
          ),
          label="nSlow")


add.signal(strategy.st, name='sigCrossover',
       arguments = list(
         columns=c("nFast","nSlow"),
         relationship="gte"
       ),
       label='long')

add.signal(strategy.st, name='sigCrossover',
       arguments = list(
         columns=c("nFast","nSlow"),
         relationship="lt"
       ),
       label='short')


add.rule(strategy.st, name = 'ruleSignal',
     arguments=list(sigcol='long' , sigval=TRUE,
                    replace=FALSE,
                    orderside='long' ,
                    ordertype='stoplimit',
                    prefer='High',
                    threshold=.threshold,
                    TxnFees=0,
                    orderqty=+.orderqty,
                    osFUN=osMaxPos,
                    orderset='ocolong'
     ),
     type='enter',
     timespan = .timespan,
     label='EnterLONG')


add.rule(strategy.st, name = 'ruleSignal',
     arguments=list(sigcol='short', sigval=TRUE,
                    replace=FALSE,
                    orderside='short',
                    ordertype='stoplimit',
                    prefer='Low',
                    threshold=.threshold,
                    TxnFees=0,
                    orderqty=-.orderqty,
                    osFUN=osMaxPos,
                    orderset='ocoshort'
     ),
     type='enter',
     timespan = .timespan,
     label='EnterSHORT')


add.rule(strategy.st, name = 'ruleSignal',
     arguments=list(sigcol='short', sigval=TRUE,
                    replace=TRUE,
                    orderside='long' ,
                    ordertype='market',
                    TxnFees=.txnfees,
                    orderqty='all',
                    orderset='ocolong'
     ),
     type='exit',
     timespan = .timespan,
     label='Exit2SHORT')


add.rule(strategy.st, name = 'ruleSignal',
     arguments=list(sigcol='long' , sigval=TRUE,
                    replace=TRUE,
                    orderside='short',
                    ordertype='market',
                    TxnFees=.txnfees,
                    orderqty='all',
                    orderset='ocoshort'
     ),
     type='exit',
     timespan = .timespan,
     label='Exit2LONG')


add.rule(strategy.st, name = 'ruleSignal',
     arguments=list(sigcol='long' , sigval=TRUE,
                    replace=FALSE,
                    orderside='long',
                    ordertype='stoplimit',
                    tmult=TRUE,
                    threshold=quote(.stoploss),
                    TxnFees=.txnfees,
                    orderqty='all',
                    orderset='ocolong'
     ),
     type='chain', parent='EnterLONG',
     label='StopLossLONG',
     enabled=FALSE)

add.rule(strategy.st, name = 'ruleSignal',
     arguments=list(sigcol='long' , sigval=TRUE,
                    replace=FALSE,
                    orderside='long',
                    ordertype='stoptrailing',
                    tmult=TRUE,
                    threshold=quote(.trailingStopPercent),
                    orderqty='all',
                    orderset='ocolong'
     ),
     type='chain', parent='EnterLong',
     label='StopTrailingLong',
     enabled=FALSE)

add.rule(strategy.st, name = 'ruleSignal',
     arguments=list(sigcol='short' , sigval=TRUE,
                    replace=FALSE,
                    orderside='short',
                    ordertype='stoplimit',
                    tmult=TRUE,
                    threshold=quote(.stoploss),
                    TxnFees=.txnfees,
                    orderqty='all',
                    orderset='ocoshort'
     ),
     type='chain', parent='EnterSHORT',
     label='StopLossSHORT',
     enabled=FALSE)
# add.rule(strategy.st, name = 'ruleSignal',#
arguments=list(sigcol='short' , sigval=TRUE,#
replace=FALSE,#                         orderside='short',#
             ordertype='stoptrailing',#
tmult=TRUE,#
threshold=quote(trailingStopPercent),#
orderqty='all',#                         orderset='ocoshort'#
),#          type='chain', parent='EnterShort',#
label='StopTrailingShort',#          enabled=FALSE# )

enable.rule('luxor', 'chain', 'StopLoss')
enable.rule('luxor', 'chain', 'StopTrailingLong')


out <- applyStrategy(strategy.st, portfolio.st)
updatePortf(portfolio.st, Symbols='EURUSD',
        Dates=paste('::',as.Date(Sys.time()),sep=''))

ob <- getOrderBook(portfolio.st)$forex$EURUSD
ob.df <- data.frame(Date=time(ob),coredata(ob))
View(ob.df)

	[[alternative HTML version deleted]]


From treydog999 at gmail.com  Mon Mar  7 01:44:31 2016
From: treydog999 at gmail.com (Derek Wong)
Date: Mon, 7 Mar 2016 08:44:31 +0800
Subject: [R-SIG-Finance] Trailing stop not working in R (Luxor example)
In-Reply-To: <CAHDRDJVtF+U06FdeCyB6MH96W=xALo9PH-MepmsxUY-9txQuSw@mail.gmail.com>
References: <CAHDRDJVtF+U06FdeCyB6MH96W=xALo9PH-MepmsxUY-9txQuSw@mail.gmail.com>
Message-ID: <CALQudT9vnrpbadpA7wYKrsZXiv=tDR9fn5gtNEf1dCDPw29Z9w@mail.gmail.com>

Hi Peter,

I had submitted a problem with the trailing stop in quantstrat 2 weeks
ago. I have looked at the code in the orders.R and ruleproc.R and
still have not discovered the problem. It does not update on every
higher high, or lower low. But in a more jumpy fashion, especially if
you use prefer= anything other than close. Although diving in to that
code, the logic seemed correct. I just have not found that the
trailingstop is reliable at this time in quantstrat.

-Derek

On Mon, Mar 7, 2016 at 12:47 AM, Peter Neumaier
<peter.neumaier at gmail.com> wrote:
> I am trying to implement a trailing stop in the Luxor example.
>
> I have tried many approaches to debug/find the error, i.e.
>
>    - run with and without stoploss enabled
>    - different levels of stoptrailingpercent
>    - the list goes on
>
> But my orderbook (ob.df at the of code) simply is not showing any trailing
> stops executed.
>
> Anyone got any suggestions why my trailing stop is not working? Here is my
> code:
>
>
> ## ----results='hide'------------------------------------------------------
> library(quantstrat)
>
> options(width = 240)#options(warn=1)
>
> Sys.setenv(TZ="UTC")
> ###
> initDate = '2003-10-21'
> .from='2012-01-01'
> .to='2016-03-01'
>
> currency(c('EUR', 'USD'))
> exchange_rate('EURUSD', tick_size=0.0001)
>
> # moving average lengths
> .fast = 6
> .slow = 21
> # optimization range
> .FastSMA = (1:30)
> .SlowSMA = (20:80)
> # trade parameters
> .threshold = 0.0005
> .orderqty = 100000
> .txnfees = -6  # round-trip fee
> # stop loss amount
> .stoploss <- 0.30/100
> # trading window
> .timespan = 'T00:00/T23:59'
> # number of optimization samples
> .nsamples=80
>
> ## ------------------------------------------------------------------------portfolio.st
> = 'forex'account.st = 'IB1'strategy.st = 'luxor'
>
> .trailingStopPercent <- 0.001
>
> rm.strat(portfolio.st)
> rm.strat(account.st)
> rm.strat(strategy.st)
> ## ----results='hide'------------------------------------------------------
> initPortf(portfolio.st, symbols='EURUSD', initDate=initDate, currency='USD')
> addPosLimit(portfolio=portfolio.st,symbol='EURUSD',
> timestamp=initDate,maxpos=.orderqty)
>
>     initAcct(account.st,portfolios=portfolio.st,initDate=initDate,currency='USD')
> initOrders(portfolio.st, initDate=initDate)
> strategy(strategy.st, store=TRUE)
>
> getSymbols("EUR/USD", src="oanda", from=.from, to=.to,
> index.class="POSIXct",adjust=T)
>
> EURUSD = to.minutes30(EURUSD)
> EURUSD = align.time(EURUSD, 1800)
>
>
>
> add.indicator(strategy.st, name = "SMA",
>           arguments = list(
>             x = quote(Cl(mktdata)[,1]),
>             n = .fast
>           ),
>           label="nFast")
>
> add.indicator(strategy.st, name="SMA",
>           arguments = list(
>             x = quote(Cl(mktdata)[,1]),
>             n = .slow
>           ),
>           label="nSlow")
>
>
> add.signal(strategy.st, name='sigCrossover',
>        arguments = list(
>          columns=c("nFast","nSlow"),
>          relationship="gte"
>        ),
>        label='long')
>
> add.signal(strategy.st, name='sigCrossover',
>        arguments = list(
>          columns=c("nFast","nSlow"),
>          relationship="lt"
>        ),
>        label='short')
>
>
> add.rule(strategy.st, name = 'ruleSignal',
>      arguments=list(sigcol='long' , sigval=TRUE,
>                     replace=FALSE,
>                     orderside='long' ,
>                     ordertype='stoplimit',
>                     prefer='High',
>                     threshold=.threshold,
>                     TxnFees=0,
>                     orderqty=+.orderqty,
>                     osFUN=osMaxPos,
>                     orderset='ocolong'
>      ),
>      type='enter',
>      timespan = .timespan,
>      label='EnterLONG')
>
>
> add.rule(strategy.st, name = 'ruleSignal',
>      arguments=list(sigcol='short', sigval=TRUE,
>                     replace=FALSE,
>                     orderside='short',
>                     ordertype='stoplimit',
>                     prefer='Low',
>                     threshold=.threshold,
>                     TxnFees=0,
>                     orderqty=-.orderqty,
>                     osFUN=osMaxPos,
>                     orderset='ocoshort'
>      ),
>      type='enter',
>      timespan = .timespan,
>      label='EnterSHORT')
>
>
> add.rule(strategy.st, name = 'ruleSignal',
>      arguments=list(sigcol='short', sigval=TRUE,
>                     replace=TRUE,
>                     orderside='long' ,
>                     ordertype='market',
>                     TxnFees=.txnfees,
>                     orderqty='all',
>                     orderset='ocolong'
>      ),
>      type='exit',
>      timespan = .timespan,
>      label='Exit2SHORT')
>
>
> add.rule(strategy.st, name = 'ruleSignal',
>      arguments=list(sigcol='long' , sigval=TRUE,
>                     replace=TRUE,
>                     orderside='short',
>                     ordertype='market',
>                     TxnFees=.txnfees,
>                     orderqty='all',
>                     orderset='ocoshort'
>      ),
>      type='exit',
>      timespan = .timespan,
>      label='Exit2LONG')
>
>
> add.rule(strategy.st, name = 'ruleSignal',
>      arguments=list(sigcol='long' , sigval=TRUE,
>                     replace=FALSE,
>                     orderside='long',
>                     ordertype='stoplimit',
>                     tmult=TRUE,
>                     threshold=quote(.stoploss),
>                     TxnFees=.txnfees,
>                     orderqty='all',
>                     orderset='ocolong'
>      ),
>      type='chain', parent='EnterLONG',
>      label='StopLossLONG',
>      enabled=FALSE)
>
> add.rule(strategy.st, name = 'ruleSignal',
>      arguments=list(sigcol='long' , sigval=TRUE,
>                     replace=FALSE,
>                     orderside='long',
>                     ordertype='stoptrailing',
>                     tmult=TRUE,
>                     threshold=quote(.trailingStopPercent),
>                     orderqty='all',
>                     orderset='ocolong'
>      ),
>      type='chain', parent='EnterLong',
>      label='StopTrailingLong',
>      enabled=FALSE)
>
> add.rule(strategy.st, name = 'ruleSignal',
>      arguments=list(sigcol='short' , sigval=TRUE,
>                     replace=FALSE,
>                     orderside='short',
>                     ordertype='stoplimit',
>                     tmult=TRUE,
>                     threshold=quote(.stoploss),
>                     TxnFees=.txnfees,
>                     orderqty='all',
>                     orderset='ocoshort'
>      ),
>      type='chain', parent='EnterSHORT',
>      label='StopLossSHORT',
>      enabled=FALSE)
> # add.rule(strategy.st, name = 'ruleSignal',#
> arguments=list(sigcol='short' , sigval=TRUE,#
> replace=FALSE,#                         orderside='short',#
>              ordertype='stoptrailing',#
> tmult=TRUE,#
> threshold=quote(trailingStopPercent),#
> orderqty='all',#                         orderset='ocoshort'#
> ),#          type='chain', parent='EnterShort',#
> label='StopTrailingShort',#          enabled=FALSE# )
>
> enable.rule('luxor', 'chain', 'StopLoss')
> enable.rule('luxor', 'chain', 'StopTrailingLong')
>
>
> out <- applyStrategy(strategy.st, portfolio.st)
> updatePortf(portfolio.st, Symbols='EURUSD',
>         Dates=paste('::',as.Date(Sys.time()),sep=''))
>
> ob <- getOrderBook(portfolio.st)$forex$EURUSD
> ob.df <- data.frame(Date=time(ob),coredata(ob))
> View(ob.df)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From edd at debian.org  Mon Mar  7 02:11:04 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 6 Mar 2016 19:11:04 -0600
Subject: [R-SIG-Finance] Rblpapi 'rc' 0.3.2.5 available for testing
Message-ID: <22236.54568.716153.446651@max.nulle.part>


Rblpapi has seen a lot of exciting changes since the 0.3.2 release in early
December.  We have a version that may be getting ready for release, and would
apprecicate extra eyeballs and tests.  I wrote a quick blog post which you
see at the short URL http://goo.gl/K9blmX --- and thanks to drat you can
install this with two commands from source or as Windows binaries.  We'd love
some more unit test suggestions, or better still, PRs, as the blog posts says.

Cheers, Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From josh.m.ulrich at gmail.com  Mon Mar  7 15:53:48 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 7 Mar 2016 08:53:48 -0600
Subject: [R-SIG-Finance] tick data and one minute bar data appear out of
 line (IBrokers)
In-Reply-To: <56D9218F.7030805@organicfoodmarkets.com.au>
References: <56D9033C.4010508@organicfoodmarkets.com.au>
	<CAPPM_gSLkGMdJDLb7eDn9rY6H8SKDTN=F08S8DAOmB_vevtiWw@mail.gmail.com>
	<56D9218F.7030805@organicfoodmarkets.com.au>
Message-ID: <CAPPM_gQo2YSmNBk0tci0Ndy_-AcDwP+PqyzjuEz6cHR062y1Lg@mail.gmail.com>

On Thu, Mar 3, 2016 at 11:47 PM, Stephen Choularton
<stephen at organicfoodmarkets.com.au> wrote:
> Hi Joshua
>
> Just trying to follow that comment 'If you look at the tick data versus the
> high-low range, you should see that all the tick prices fall within that
> range for every aggregate interval.'
>
> The summary of the two datasets is:
>
>  summary(bars)
>      Index                       CBA.Close
>  Min.   :2016-03-03 10:06:00   Min.   :48.31
>  1st Qu.:2016-03-03 11:37:00   1st Qu.:48.38
>  Median :2016-03-03 13:08:00   Median :48.45
>  Mean   :2016-03-03 13:08:00   Mean   :48.46
>  3rd Qu.:2016-03-03 14:39:00   3rd Qu.:48.53
>  Max.   :2016-03-03 16:10:00   Max.   :48.73
>
>
> and
>
> summary(ticks)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>   47.82   48.41   48.44   48.47   48.49   49.00
>
> Now that min figure is the result of some market closing phenomena and it
> really never went much below 48.3 so yes its true that they have a similar
> range and min and max but ticks gets up into the just under 49.0 level
> around 10:15 and bars only gets to that level around 11:30 and again at noon
> while ticks is under 48.6 at that point.
>
> Sounds like you don't think there is anything that unusual in the two
> datasets so I guess I had better take that on board and keep on trying to
> make this work.
>
I don't think there's anything unusual, unless the close prices are
outside the high-low range.  I think the piece you're missing is that
"high-low range" means the high and low prices (ticks) for a 1-minute
interval; not the max/min of the close price.

> Thanks for looking at it
>
> Stephen Choularton PhD, FIoD
>
>
> On 4/03/2016 2:50 PM, Joshua Ulrich wrote:
>>
>> On Thu, Mar 3, 2016 at 9:38 PM, Stephen Choularton
>> <stephen at organicfoodmarkets.com.au> wrote:
>>>
>>> Hi
>>>
>>> I have been working on the spread between Commonwealth Bank (CBA.ASX) and
>>> National Australia Bank (NAB.ASX).
>>>
>>> I was a bit confused by the performance of my dealing loop so I took out
>>> the
>>> spread movement from rqHistoricData 1 minute bars using the close and
>>> plotted it and also the spread derived from the tick data from reqMktData
>>> which is being used to drive my dealing algorithm.
>>>
>>> They are in the same ballpark but really rather different.  The graph
>>> shows
>>> the position best and can be viewed at this url:
>>> http://www.organicfoodmarkets.com.au/bar-n-tick-plots.pdf
>>>
>> The 1-minute close price is a (potentially very small) sample of all
>> the price changes that occur in a given minute interval.  The fact
>> that they're similar is likely because the price wasn't moving much
>> during the hours in your plot.  If prices were moving a lot, I
>> wouldn't expect them to be very similar at all.
>>
>> If you look at the tick data versus the high-low range, you should see
>> that all the tick prices fall within that range for every aggregate
>> interval.
>>
>>> I am not experienced with this so I wondered if this sort of discrepancy
>>> is
>>> typical or am I just making a mess of it.  If they are typical so it
>>> makes
>>> setting trigger levels a bit difficult as mine are derived from bar data
>>> but
>>> implemented by tick data movement.  I'm surprised the tick data doesn't
>>> fall
>>> within the one minute bar so any comments would be of great interest.  Am
>>> I
>>> better to only work with tick data for example?
>>>
>>> Stephen Choularton PhD, FIoD
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>
>>
>>
>



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From thomas.fuller at coherentlogic.com  Tue Mar  8 14:19:57 2016
From: thomas.fuller at coherentlogic.com (Thomas Fuller)
Date: Tue, 8 Mar 2016 08:19:57 -0500
Subject: [R-SIG-Finance] Coherent Data Adapter: CUSIP Global Services Web
	Edition
Message-ID: <CAM0JZ3nEMzZuP2fRTC6g2WvmWa8GUUx2W=8aeewYRMHZFSHxCg@mail.gmail.com>

Hi Folks,

I'd like to announce that the Coherent Data Adapter: CUSIP Global Services
Web Edition is feature complete as of yesterday.

This package allows users of both Java and The R Project for Statistical
Computing to access the entire universe of CUSIP identifiers for corporate,
municipal, government and mortgage-backed issues, and private placements.

Installation instructions as well as comprehensive examples in R script can
be found at the link below.

https://coherentlogic.com/middleware-development/coherent-data-adapter-cusip-global-services-web-edition/

Questions and comments are welcomed.

Tom

	[[alternative HTML version deleted]]


From peter.neumaier at gmail.com  Tue Mar  8 20:13:03 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Tue, 8 Mar 2016 19:13:03 +0000
Subject: [R-SIG-Finance] Position size in order book
Message-ID: <CAHDRDJV6W5VKA-AMJbXbWUF8ZUEHqJ7O_Ks9nx1H-dGeEV5d0g@mail.gmail.com>

Hi, I am debugging a strategy by going through my order book, but missing
the net position of my strategy in the output:

ob <- getOrderBook("xyz")$xyz$ABC
ob.df <- data.frame(Date=time(ob),coredata(ob))

View(ob.df)


Is there a way to display the actual position size line by line with each
trade in ob.df?

Many thanks in advance,
Peter

	[[alternative HTML version deleted]]


From brian at braverock.com  Tue Mar  8 21:22:46 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 08 Mar 2016 21:22:46 +0100
Subject: [R-SIG-Finance] Position size in order book
Message-ID: <1eltsbb9vtfkhqymj6nmkfb4.1457468566184@email.android.com>


    
Orders are not transactions. Do you perhaps want getTxns () or perTradeStats () ?


--Brian G. Peterson?ph: 773-459-4973im: bgpbraverockSent from my mobile, please excuse my brevity.?

-------- Original message --------
From: Peter Neumaier <peter.neumaier at gmail.com> 
Date: 2016/03/08  20:13  (GMT+01:00) 
To: r-sig-finance at r-project.org 
Subject: [R-SIG-Finance] Position size in order book 

Hi, I am debugging a strategy by going through my order book, but missing
the net position of my strategy in the output:

ob <- getOrderBook("xyz")$xyz$ABC
ob.df <- data.frame(Date=time(ob),coredata(ob))

View(ob.df)


Is there a way to display the actual position size line by line with each
trade in ob.df?

Many thanks in advance,
Peter

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.

	[[alternative HTML version deleted]]


From peter.neumaier at gmail.com  Tue Mar  8 22:36:09 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Tue, 8 Mar 2016 21:36:09 +0000
Subject: [R-SIG-Finance] Position size in order book
In-Reply-To: <1eltsbb9vtfkhqymj6nmkfb4.1457468566184@email.android.com>
References: <1eltsbb9vtfkhqymj6nmkfb4.1457468566184@email.android.com>
Message-ID: <CAHDRDJXisVrLch0=vxftH4MT_oEE1yr5F-JtSF8Wg2Pqk2MxoA@mail.gmail.com>

Spot on Brian: I got confused.

Many Thanks.
Peter.

On Tue, Mar 8, 2016 at 8:22 PM, Brian G. Peterson <brian at braverock.com>
wrote:

> Orders are not transactions. Do you perhaps want getTxns () or
> perTradeStats () ?
>
>
>
> --
> Brian G. Peterson
> ph: 773-459-4973
> im: bgpbraverock
> Sent from my mobile, please excuse my brevity.
>
>
> -------- Original message --------
> From: Peter Neumaier <peter.neumaier at gmail.com>
> Date: 2016/03/08 20:13 (GMT+01:00)
> To: r-sig-finance at r-project.org
> Subject: [R-SIG-Finance] Position size in order book
>
> Hi, I am debugging a strategy by going through my order book, but missing
> the net position of my strategy in the output:
>
> ob <- getOrderBook("xyz")$xyz$ABC
> ob.df <- data.frame(Date=time(ob),coredata(ob))
>
> View(ob.df)
>
>
> Is there a way to display the actual position size line by line with each
> trade in ob.df?
>
> Many thanks in advance,
> Peter
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From karve.amod at gmail.com  Tue Mar  8 23:25:33 2016
From: karve.amod at gmail.com (=?UTF-8?B?QW1vZCBLYXJ2ZSAo4KSF4KSu4KWL4KSmKQ==?=)
Date: Tue, 8 Mar 2016 17:25:33 -0500
Subject: [R-SIG-Finance] Tax consideration when calling Return.portfolio
Message-ID: <CAFauerN8zkx9O6tPbnOd8_aT0WshP56fx4mb=mtsD6ziJ15Ffg@mail.gmail.com>

Hey All,

 First of all thank you all for the amazing R libraries that you guys have
built. I was playing around with Return.portfolio from the
PerformanceAnalytics package and simulating a simple 50/50 portfolio with
monthly rebalancing. I now wanted to see how the strategy changes if I tax
my gains as they happen during rebalancing. Is there an already known way
to handle this (e.g. if I can specify the tax rate, then I presume a bite
can be taken out at each rebalancing interval if there is a gain).

Thanks for all the help
Amod Karve

	[[alternative HTML version deleted]]


From peter.neumaier at gmail.com  Wed Mar  9 13:47:40 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Wed, 9 Mar 2016 12:47:40 +0000
Subject: [R-SIG-Finance] Add.Distribution on signal "BBands" ?
Message-ID: <CAHDRDJU0KjT1Le-thaFZ7WadBDyVTVWtuc1LTS6aEwfhTEYBLQ@mail.gmail.com>

Hi everyone,

I have created a signal based on BBands with

add.indicator(strat.st, name = "BBands",
  arguments = list(HLC = quote(HLC(mktdata)), maType='SMA'), label='BBands')

and passing my BBand parameters with:
out <- applyStrategy(strat.st, "opt",parameters=list(sd=1,n=20))

I have not found any documentation online on how to optimise
SD and N (when called with applystrategy). Is it possible at all or
am I going the wrong direction?


Many Thanks
Peter

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Wed Mar  9 13:50:49 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 9 Mar 2016 06:50:49 -0600
Subject: [R-SIG-Finance] Add.Distribution on signal "BBands" ?
In-Reply-To: <CAHDRDJU0KjT1Le-thaFZ7WadBDyVTVWtuc1LTS6aEwfhTEYBLQ@mail.gmail.com>
References: <CAHDRDJU0KjT1Le-thaFZ7WadBDyVTVWtuc1LTS6aEwfhTEYBLQ@mail.gmail.com>
Message-ID: <CAPPM_gTw-EOyYV_pvdMaPU0PG3O0bDbfimSw2-TDV-u2Z3uV8A@mail.gmail.com>

On Wed, Mar 9, 2016 at 6:47 AM, Peter Neumaier <peter.neumaier at gmail.com> wrote:
> Hi everyone,
>
> I have created a signal based on BBands with
>
> add.indicator(strat.st, name = "BBands",
>   arguments = list(HLC = quote(HLC(mktdata)), maType='SMA'), label='BBands')
>
> and passing my BBand parameters with:
> out <- applyStrategy(strat.st, "opt",parameters=list(sd=1,n=20))
>
> I have not found any documentation online on how to optimise
> SD and N (when called with applystrategy). Is it possible at all or
> am I going the wrong direction?
>
See the demo:
R> demo("bbandParameters", package="quantstrat")

>
> Many Thanks
> Peter
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From peter.neumaier at gmail.com  Wed Mar  9 14:58:04 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Wed, 9 Mar 2016 13:58:04 +0000
Subject: [R-SIG-Finance] Add.Distribution on signal "BBands" ?
In-Reply-To: <CAPPM_gTw-EOyYV_pvdMaPU0PG3O0bDbfimSw2-TDV-u2Z3uV8A@mail.gmail.com>
References: <CAHDRDJU0KjT1Le-thaFZ7WadBDyVTVWtuc1LTS6aEwfhTEYBLQ@mail.gmail.com>
	<CAPPM_gTw-EOyYV_pvdMaPU0PG3O0bDbfimSw2-TDV-u2Z3uV8A@mail.gmail.com>
Message-ID: <CAHDRDJVhY24sP12GXaxdB6gnVArEeiW79XF1zL+yOGXCRd9ZzQ@mail.gmail.com>

Josh thanks for your lighting fast answer and it works pretty good!

Just one newbie question: why does the BBand simulation run without
the parallel package and without initialization for doParallel() ?

Thanks
Peter

On Wed, Mar 9, 2016 at 12:50 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>
wrote:

> On Wed, Mar 9, 2016 at 6:47 AM, Peter Neumaier <peter.neumaier at gmail.com>
> wrote:
> > Hi everyone,
> >
> > I have created a signal based on BBands with
> >
> > add.indicator(strat.st, name = "BBands",
> >   arguments = list(HLC = quote(HLC(mktdata)), maType='SMA'),
> label='BBands')
> >
> > and passing my BBand parameters with:
> > out <- applyStrategy(strat.st, "opt",parameters=list(sd=1,n=20))
> >
> > I have not found any documentation online on how to optimise
> > SD and N (when called with applystrategy). Is it possible at all or
> > am I going the wrong direction?
> >
> See the demo:
> R> demo("bbandParameters", package="quantstrat")
>
> >
> > Many Thanks
> > Peter
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
> R/Finance 2016 | www.rinfinance.com
>

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Wed Mar  9 15:00:51 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 9 Mar 2016 08:00:51 -0600
Subject: [R-SIG-Finance] Add.Distribution on signal "BBands" ?
In-Reply-To: <CAHDRDJVhY24sP12GXaxdB6gnVArEeiW79XF1zL+yOGXCRd9ZzQ@mail.gmail.com>
References: <CAHDRDJU0KjT1Le-thaFZ7WadBDyVTVWtuc1LTS6aEwfhTEYBLQ@mail.gmail.com>
	<CAPPM_gTw-EOyYV_pvdMaPU0PG3O0bDbfimSw2-TDV-u2Z3uV8A@mail.gmail.com>
	<CAHDRDJVhY24sP12GXaxdB6gnVArEeiW79XF1zL+yOGXCRd9ZzQ@mail.gmail.com>
Message-ID: <CAPPM_gQ4pE=bzRfjc4+UF7kQ+0WPGuDMBD3csSRWgU-UPM4Taw@mail.gmail.com>

On Wed, Mar 9, 2016 at 7:58 AM, Peter Neumaier <peter.neumaier at gmail.com> wrote:
> Josh thanks for your lighting fast answer and it works pretty good!
>
> Just one newbie question: why does the BBand simulation run without
> the parallel package and without initialization for doParallel() ?
>
Because it's not strictly necessary and is a potential complication.
Look at the source file for the demo, and you'll see comments about
how to run it in parallel.

> Thanks
> Peter
>
> On Wed, Mar 9, 2016 at 12:50 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>
> wrote:
>>
>> On Wed, Mar 9, 2016 at 6:47 AM, Peter Neumaier <peter.neumaier at gmail.com>
>> wrote:
>> > Hi everyone,
>> >
>> > I have created a signal based on BBands with
>> >
>> > add.indicator(strat.st, name = "BBands",
>> >   arguments = list(HLC = quote(HLC(mktdata)), maType='SMA'),
>> > label='BBands')
>> >
>> > and passing my BBand parameters with:
>> > out <- applyStrategy(strat.st, "opt",parameters=list(sd=1,n=20))
>> >
>> > I have not found any documentation online on how to optimise
>> > SD and N (when called with applystrategy). Is it possible at all or
>> > am I going the wrong direction?
>> >
>> See the demo:
>> R> demo("bbandParameters", package="quantstrat")
>>
>> >
>> > Many Thanks
>> > Peter
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only. If you want to post, subscribe first.
>> > -- Also note that this is not the r-help list where general R questions
>> > should go.
>>
>>
>>
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com
>> R/Finance 2016 | www.rinfinance.com
>
>



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From peter.neumaier at gmail.com  Wed Mar  9 15:08:09 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Wed, 9 Mar 2016 14:08:09 +0000
Subject: [R-SIG-Finance] Add.Distribution on signal "BBands" ?
In-Reply-To: <CAPPM_gQ4pE=bzRfjc4+UF7kQ+0WPGuDMBD3csSRWgU-UPM4Taw@mail.gmail.com>
References: <CAHDRDJU0KjT1Le-thaFZ7WadBDyVTVWtuc1LTS6aEwfhTEYBLQ@mail.gmail.com>
	<CAPPM_gTw-EOyYV_pvdMaPU0PG3O0bDbfimSw2-TDV-u2Z3uV8A@mail.gmail.com>
	<CAHDRDJVhY24sP12GXaxdB6gnVArEeiW79XF1zL+yOGXCRd9ZzQ@mail.gmail.com>
	<CAPPM_gQ4pE=bzRfjc4+UF7kQ+0WPGuDMBD3csSRWgU-UPM4Taw@mail.gmail.com>
Message-ID: <CAHDRDJWRBTvgX8nNoJE6XKeZC==RM1Rb7fnYPwbxR2jyXTb3fw@mail.gmail.com>

So in theory I could run any optimisation without parallel?

On Wed, Mar 9, 2016 at 2:00 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>
wrote:

> On Wed, Mar 9, 2016 at 7:58 AM, Peter Neumaier <peter.neumaier at gmail.com>
> wrote:
> > Josh thanks for your lighting fast answer and it works pretty good!
> >
> > Just one newbie question: why does the BBand simulation run without
> > the parallel package and without initialization for doParallel() ?
> >
> Because it's not strictly necessary and is a potential complication.
> Look at the source file for the demo, and you'll see comments about
> how to run it in parallel.
>
> > Thanks
> > Peter
> >
> > On Wed, Mar 9, 2016 at 12:50 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>
> > wrote:
> >>
> >> On Wed, Mar 9, 2016 at 6:47 AM, Peter Neumaier <
> peter.neumaier at gmail.com>
> >> wrote:
> >> > Hi everyone,
> >> >
> >> > I have created a signal based on BBands with
> >> >
> >> > add.indicator(strat.st, name = "BBands",
> >> >   arguments = list(HLC = quote(HLC(mktdata)), maType='SMA'),
> >> > label='BBands')
> >> >
> >> > and passing my BBand parameters with:
> >> > out <- applyStrategy(strat.st, "opt",parameters=list(sd=1,n=20))
> >> >
> >> > I have not found any documentation online on how to optimise
> >> > SD and N (when called with applystrategy). Is it possible at all or
> >> > am I going the wrong direction?
> >> >
> >> See the demo:
> >> R> demo("bbandParameters", package="quantstrat")
> >>
> >> >
> >> > Many Thanks
> >> > Peter
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-SIG-Finance at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >> > -- Subscriber-posting only. If you want to post, subscribe first.
> >> > -- Also note that this is not the r-help list where general R
> questions
> >> > should go.
> >>
> >>
> >>
> >> --
> >> Joshua Ulrich  |  about.me/joshuaulrich
> >> FOSS Trading  |  www.fosstrading.com
> >> R/Finance 2016 | www.rinfinance.com
> >
> >
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
> R/Finance 2016 | www.rinfinance.com
>

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Wed Mar  9 15:08:43 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 9 Mar 2016 08:08:43 -0600
Subject: [R-SIG-Finance] Add.Distribution on signal "BBands" ?
In-Reply-To: <CAHDRDJWRBTvgX8nNoJE6XKeZC==RM1Rb7fnYPwbxR2jyXTb3fw@mail.gmail.com>
References: <CAHDRDJU0KjT1Le-thaFZ7WadBDyVTVWtuc1LTS6aEwfhTEYBLQ@mail.gmail.com>
	<CAPPM_gTw-EOyYV_pvdMaPU0PG3O0bDbfimSw2-TDV-u2Z3uV8A@mail.gmail.com>
	<CAHDRDJVhY24sP12GXaxdB6gnVArEeiW79XF1zL+yOGXCRd9ZzQ@mail.gmail.com>
	<CAPPM_gQ4pE=bzRfjc4+UF7kQ+0WPGuDMBD3csSRWgU-UPM4Taw@mail.gmail.com>
	<CAHDRDJWRBTvgX8nNoJE6XKeZC==RM1Rb7fnYPwbxR2jyXTb3fw@mail.gmail.com>
Message-ID: <CAPPM_gRGSTjh1DWjdsvauP=GLwfQ6i0k3URqi7cVe_HThAASZg@mail.gmail.com>

Yes.

On Wed, Mar 9, 2016 at 8:08 AM, Peter Neumaier <peter.neumaier at gmail.com> wrote:
> So in theory I could run any optimisation without parallel?
>
> On Wed, Mar 9, 2016 at 2:00 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>
> wrote:
>>
>> On Wed, Mar 9, 2016 at 7:58 AM, Peter Neumaier <peter.neumaier at gmail.com>
>> wrote:
>> > Josh thanks for your lighting fast answer and it works pretty good!
>> >
>> > Just one newbie question: why does the BBand simulation run without
>> > the parallel package and without initialization for doParallel() ?
>> >
>> Because it's not strictly necessary and is a potential complication.
>> Look at the source file for the demo, and you'll see comments about
>> how to run it in parallel.
>>
>> > Thanks
>> > Peter
>> >
>> > On Wed, Mar 9, 2016 at 12:50 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>
>> > wrote:
>> >>
>> >> On Wed, Mar 9, 2016 at 6:47 AM, Peter Neumaier
>> >> <peter.neumaier at gmail.com>
>> >> wrote:
>> >> > Hi everyone,
>> >> >
>> >> > I have created a signal based on BBands with
>> >> >
>> >> > add.indicator(strat.st, name = "BBands",
>> >> >   arguments = list(HLC = quote(HLC(mktdata)), maType='SMA'),
>> >> > label='BBands')
>> >> >
>> >> > and passing my BBand parameters with:
>> >> > out <- applyStrategy(strat.st, "opt",parameters=list(sd=1,n=20))
>> >> >
>> >> > I have not found any documentation online on how to optimise
>> >> > SD and N (when called with applystrategy). Is it possible at all or
>> >> > am I going the wrong direction?
>> >> >
>> >> See the demo:
>> >> R> demo("bbandParameters", package="quantstrat")
>> >>
>> >> >
>> >> > Many Thanks
>> >> > Peter
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > _______________________________________________
>> >> > R-SIG-Finance at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >> > -- Subscriber-posting only. If you want to post, subscribe first.
>> >> > -- Also note that this is not the r-help list where general R
>> >> > questions
>> >> > should go.
>> >>
>> >>
>> >>
>> >> --
>> >> Joshua Ulrich  |  about.me/joshuaulrich
>> >> FOSS Trading  |  www.fosstrading.com
>> >> R/Finance 2016 | www.rinfinance.com
>> >
>> >
>>
>>
>>
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com
>> R/Finance 2016 | www.rinfinance.com
>
>



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From peter.neumaier at gmail.com  Thu Mar 10 09:20:35 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Thu, 10 Mar 2016 08:20:35 +0000
Subject: [R-SIG-Finance] Convert double to date
Message-ID: <CAHDRDJWH1PcXrL8yP-mTydesxP7+WqqA-ipnZA5Sj4YbMZqPxg@mail.gmail.com>

Hi all, what appeared to be an easy task turns into a mystery - at least
judged
from my previous experience with other languages.

I queried some historical data from an exchange and stored into a double
array
a_fetchdata:

> typeof(a_fetchdata)
[1] "double"
> a_fetchdata[1,1:2]
                        NGFJ6.Open  NGFJ6.High
2016-02-09 07:30:00     0.2897      0.2897
#### Please note above result has no header for the date/time column

My goal is to take the date, deduct one day and arrive at "2016-02-08".

So I tried converting into a date (with paste/without paste)
>as.Date(c(strhead(paste(a_fetchdata[1,0]),10)),"%Y-%m-%d")
or
strptime(c(a_fetchdata[1,0]),format="%Y%m%d")

But I keep running into the same error message:

*Error in dimnames(cd) <- list(as.character(index(x)), colnames(x)) :
'dimnames' applied to non-array*

Can anyone please shed some light on that?

Many thanks in advance,
Peter

	[[alternative HTML version deleted]]


From peter.neumaier at gmail.com  Thu Mar 10 11:43:28 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Thu, 10 Mar 2016 10:43:28 +0000
Subject: [R-SIG-Finance] write.csv conversion problem
Message-ID: <CAHDRDJXMq6VD1sGzRy-ptMA+hdxyAH0K9fgKb7QoDaazb6TTmA@mail.gmail.com>

Hi all,

I am writing a matrix (typeof = double) into a CSV file with write.csv.

My first column of the matrix is a date in the form yyyy-mm-dd hh:mm:ss:

> a_fetchdata[1,0]

2016-02-09 07:30:00
> typeof(a_fetchdata[1,0])
[1] "double"


My CSV file contains a sequence of integers (from 1 to x) instead of the
expected date.

How can I prevent that conversion to happen when writing into CSV?

Thanks
Peter

	[[alternative HTML version deleted]]


From roger.bos at gmail.com  Thu Mar 10 11:50:04 2016
From: roger.bos at gmail.com (Roger J. Bos)
Date: Thu, 10 Mar 2016 05:50:04 -0500
Subject: [R-SIG-Finance] write.csv conversion problem
Message-ID: <w6yqog8dp1qw5cp20s9ujdhr.1457607004206@email.android.com>

Peter,

Dates are always stored as integers, so that is expected. You would need to use as.character() to convert the date before you output it to the file, but then it won't be of type double. 

Also, thee is a general r-help list where these types of questions should go. 

Thanks,,

Roger

On March 10, 2016, at 5:44 AM, Peter Neumaier <peter.neumaier at gmail.com> wrote:

Hi all,

I am writing a matrix (typeof = double) into a CSV file with write.csv.

My first column of the matrix is a date in the form yyyy-mm-dd hh:mm:ss:

> a_fetchdata[1,0]

2016-02-09 07:30:00
> typeof(a_fetchdata[1,0])
[1] "double"


My CSV file contains a sequence of integers (from 1 to x) instead of the
expected date.

How can I prevent that conversion to happen when writing into CSV?

Thanks
Peter

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.

From josh.m.ulrich at gmail.com  Thu Mar 10 12:58:39 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 10 Mar 2016 05:58:39 -0600
Subject: [R-SIG-Finance] write.csv conversion problem
In-Reply-To: <CAHDRDJXMq6VD1sGzRy-ptMA+hdxyAH0K9fgKb7QoDaazb6TTmA@mail.gmail.com>
References: <CAHDRDJXMq6VD1sGzRy-ptMA+hdxyAH0K9fgKb7QoDaazb6TTmA@mail.gmail.com>
Message-ID: <CAPPM_gSznvjWiqUd5YTPid2Jm4+rGEBqDPf4+YmjfzcyZO2vRQ@mail.gmail.com>

On Thu, Mar 10, 2016 at 4:43 AM, Peter Neumaier
<peter.neumaier at gmail.com> wrote:
> Hi all,
>
> I am writing a matrix (typeof = double) into a CSV file with write.csv.
>
> My first column of the matrix is a date in the form yyyy-mm-dd hh:mm:ss:
>
>> a_fetchdata[1,0]
>
> 2016-02-09 07:30:00
>> typeof(a_fetchdata[1,0])
> [1] "double"
>
Your a_fetchdatra object isn't a matrix.  It looks like it's either an
xts or a zoo object.  I'm not sure how you concluded that the first
column is a date-time, based on the result of extracting the 0-th
column.

>
> My CSV file contains a sequence of integers (from 1 to x) instead of the
> expected date.
>
> How can I prevent that conversion to happen when writing into CSV?
>
Use write.zoo.

> Thanks
> Peter
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From maechler at stat.math.ethz.ch  Thu Mar 10 19:08:04 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 10 Mar 2016 19:08:04 +0100
Subject: [R-SIG-Finance] write.csv conversion problem
In-Reply-To: <w6yqog8dp1qw5cp20s9ujdhr.1457607004206@email.android.com>
References: <w6yqog8dp1qw5cp20s9ujdhr.1457607004206@email.android.com>
Message-ID: <22241.47108.524082.485452@stat.math.ethz.ch>

>>>>> Roger J Bos <roger.bos at gmail.com>
>>>>>     on Thu, 10 Mar 2016 05:50:04 -0500 writes:

    > Peter,

    > Dates are always stored as integers, so that is expected. 

but what you say, Roger, is not correct.  They *are* integer
valued, but they are double --- so that they will not suffer
from integer overflow for dates in the distant past or future:

> str(unclass(print(as.Date(Sys.Date()))))
[1] "2016-03-10"
 num 16870
 ^^^

Martin Maechler, ETH Zurich

    > You would need to use as.character() to convert
    > the date before you output it to the file, but then it
    > won't be of type double.
    

    > Also, thee is a general r-help list where these types of questions should go. 

    > Thanks,,

    > Roger

    > On March 10, 2016, at 5:44 AM, Peter Neumaier <peter.neumaier at gmail.com> wrote:

    > Hi all,

    > I am writing a matrix (typeof = double) into a CSV file with write.csv.

    > My first column of the matrix is a date in the form yyyy-mm-dd hh:mm:ss:

    >> a_fetchdata[1,0]

    > 2016-02-09 07:30:00
    >> typeof(a_fetchdata[1,0])
    > [1] "double"


    > My CSV file contains a sequence of integers (from 1 to x) instead of the
    > expected date.

    > How can I prevent that conversion to happen when writing into CSV?

    > Thanks
    > Peter

    > [[alternative HTML version deleted]]

    > _______________________________________________
    > R-SIG-Finance at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
    > -- Subscriber-posting only. If you want to post, subscribe first.
    > -- Also note that this is not the r-help list where general R questions should go.
    > _______________________________________________
    > R-SIG-Finance at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
    > -- Subscriber-posting only. If you want to post, subscribe first.
    > -- Also note that this is not the r-help list where general R questions should go.


From peter.neumaier at gmail.com  Thu Mar 10 21:34:28 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Thu, 10 Mar 2016 20:34:28 +0000
Subject: [R-SIG-Finance] write.csv conversion problem
In-Reply-To: <CAPPM_gSznvjWiqUd5YTPid2Jm4+rGEBqDPf4+YmjfzcyZO2vRQ@mail.gmail.com>
References: <CAHDRDJXMq6VD1sGzRy-ptMA+hdxyAH0K9fgKb7QoDaazb6TTmA@mail.gmail.com>
	<CAPPM_gSznvjWiqUd5YTPid2Jm4+rGEBqDPf4+YmjfzcyZO2vRQ@mail.gmail.com>
Message-ID: <CAHDRDJUmZpZM+r3zdo3nEbKiri7R5nvoj5Uz+zE66yrQ9AkAvA@mail.gmail.com>

On Thu, Mar 10, 2016 at 11:58 AM, Joshua Ulrich <josh.m.ulrich at gmail.com>
wrote:

> On Thu, Mar 10, 2016 at 4:43 AM, Peter Neumaier
> <peter.neumaier at gmail.com> wrote:
> > Hi all,
> >
> > I am writing a matrix (typeof = double) into a CSV file with write.csv.
> >
> > My first column of the matrix is a date in the form yyyy-mm-dd hh:mm:ss:
> >
> >> a_fetchdata[1,0]
> >
> > 2016-02-09 07:30:00
> >> typeof(a_fetchdata[1,0])
> > [1] "double"
> >
> Your a_fetchdatra object isn't a matrix.  It looks like it's either an
> xts or a zoo object.  I'm not sure how you concluded that the first
> column is a date-time, based on the result of extracting the 0-th
> column.
>
You are totally right: it is an xts object.
I probably mis-phrased it but I meant to say that the format inside the
cell is yyyy-mm-dd
while purely focusing on the problem of losing that date format with the
column being
converted into an integer...sorry bad language.


>
> >
> > My CSV file contains a sequence of integers (from 1 to x) instead of the
> > expected date.
> >
> > How can I prevent that conversion to happen when writing into CSV?
> >
> Use write.zoo.
>
All problems solved now:

- I am reading/writing from/to zoo objects and casting back to xts with
as.xts:

write.zoo("myfile.csv", sep = ",", quote = FALSE)

myData <- as.xts(read.zoo("myFile.csv",sep=",",tz="",header=T))

Thanks to everyone.
Peter

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Sat Mar 12 04:26:34 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 11 Mar 2016 21:26:34 -0600
Subject: [R-SIG-Finance] stoptrailing mechanics question in MACD example
	- Quantstrat
In-Reply-To: <CALQudT-OuA_xp5ntfjTnrHzzmf3UHMsy4F-kD6B4eaWBTCF0yg@mail.gmail.com>
References: <CALQudT-OuA_xp5ntfjTnrHzzmf3UHMsy4F-kD6B4eaWBTCF0yg@mail.gmail.com>
Message-ID: <CAPPM_gRK7DV2jkqUcWB7EpKZTGSE-aeUYro05eE6d7GvDtc=SA@mail.gmail.com>

On Wed, Feb 17, 2016 at 2:22 AM, Derek Wong <treydog999 at gmail.com> wrote:
> Hello All,
>
> I am using Quantstrat 0.9.1709 with Microsoft R Open 3.2.3 on Rstudio.
>
> I am having a problem understanding the trailing methodology of the
> stoptrailing order type in Quantstrat. It seems to me that the
> trailing stop is not replaced as frequently as it should. Only for
> larger price changes (threshold value?) it moves but for smaller
> increments it remains the same. Is this the intended result?
>
> I am using the MACD example and commenting out the original exit rule
> and un-commenting the trailing exit.
>
> <snip>
> #alternatives for risk stops:
> # simple stoplimit order, with threshold multiplier
> #add.rule(strat.st,name='ruleSignal', arguments =
> list(sigcol="signal.gt.zero",sigval=TRUE, orderqty='all',
> ordertype='stoplimit', orderside='long', threshold=-.05,tmult=TRUE,
> orderset='exit2'),type='chain', parent='enter',
> label='risk',storefun=FALSE)
> # alternately, use a trailing order, also with a threshold multiplier
> add.rule(strat.st,name='ruleSignal',
>          arguments = list(sigcol="signal.gt.zero",
>                           sigval=TRUE,
>                           orderqty='all',
>                           ordertype='stoptrailing',
>                           orderside='long',
>                           threshold=-1,
>                           tmult=FALSE,
>                           orderset='exit2'),
>          type='chain',
>          parent='enter',
>          label='trailingexit')
>
> # # exit
> # add.rule(strat.st,name='ruleSignal',
> #          arguments = list(sigcol="signal.lt.zero",
> #                           sigval=TRUE,
> #                           orderqty='all',
> #                           ordertype='market',
> #                           orderside='long',
> #                           threshold=NULL,
> #                           orderset='exit2'),
> #          type='exit',
> #          label='exit'
> # )
>
> <snip>
>
>
> I am looking at the orderbook and comparing it to the portfolio and
> price of AAPL. I can see that the trailing stop moves but not on every
> new high created during the trade. The first trade is an example.
>
> <output>
>> AAPL["2007-03-15/2007-03-26"]
>            AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted
> 2007-03-15     89.96     90.36    89.31      89.57   139874700      11.84997
> 2007-03-16     89.54     89.99    89.32      89.59   142926000      11.85262
> 2007-03-19     90.24     91.55    89.59      91.13   178240300      12.05636
> 2007-03-20     91.35     91.84    91.06      91.48   122229100      12.10266
> 2007-03-21     91.99     94.00    91.65      93.87   171724000      12.41886
> 2007-03-22     93.73     94.36    93.00      93.96   140373100      12.43076
> 2007-03-23     93.35     94.07    93.30      93.52   112721000      12.37255
> 2007-03-26     93.99     95.90    93.30      95.85   216246800      12.68081
>> obook$macd$AAPL["2007-03-15/2007-03-26"]
>            Order.Qty Order.Price Order.Type     Order.Side
> Order.Threshold Order.Status Order.StatusTime      Prefer
> 2007-03-15 "100"     "89.570001" "market"       "long"     NA
>     "closed"     "2007-03-16 00:00:00" ""
> 2007-03-16 "all"     "88.590001" "stoptrailing" "long"     "-1"
>     "replaced"   "2007-03-19 00:00:00" ""
> 2007-03-19 "all"     "90.549999" "stoptrailing" "long"     "-1"
>     "replaced"   "2007-03-21 00:00:00" ""
> 2007-03-21 "all"     "93.000002" "stoptrailing" "long"     "-1"
>     "replaced"   "2007-03-26 00:00:00" ""
> 2007-03-26 "all"     "94.899999" "stoptrailing" "long"     "-1"
>     "closed"     "2007-03-28 00:00:00" ""
>            Order.Set Txn.Fees Rule           Time.In.Force
> 2007-03-15 NA        "0"      "enter"        ""
> 2007-03-16 "exit2"   "0"      "trailingexit" ""
> 2007-03-19 "exit2"   "0"      "trailingexit" ""
> 2007-03-21 "exit2"   "0"      "trailingexit" ""
> 2007-03-26 "exit2"   "0"      "trailingexit" ""
>
> <output>
>
> You can see that for the date 2007-03-15 to 2007-03-21 we would have
> what I would believe to be the expected behavior. However at
> 2007-03-22 we have a new high of 94.36 so i thought the new
> Order.Price would be at 93.36 given a threshold =-1 but the order is
> not adjusted. The order is however adjusted to the correct value on
> 2007-03-26 after a new AAPL.High at 95.90 and Order Price is 94.899999
>
> I am very curious if the threshold works not only as the distance
> between price but also the threshold of a new high price change in
> order for the new Order.Price to be changed. I was expecting every new
> AAPL.high to generate a new Order.Price for a stoptrailing order type.
>
> If someone could explain this to me or tell me the expected behavior
> and mechanics of the trailing methodology I would very much appreciate
> it.
>
For OHLC data, the sell stoplimit order price will be based on the
high price, but the order evaluation is based on the close price.
That means the stoplimit will only be moved if the close is >= order
price + threshold.  And when it is moved, the new order price will be
high - threshold.

For BBO data, a sell stoplimit order price *and* evaluation would be
based on the offer price.

I don't recall at the moment why they're different.  Perhaps someone
else will remember.

> Thank you
>
> Derek
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From josh.m.ulrich at gmail.com  Sat Mar 12 04:28:25 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 11 Mar 2016 21:28:25 -0600
Subject: [R-SIG-Finance] Trailing stop not working in R (Luxor example)
In-Reply-To: <CALQudT9vnrpbadpA7wYKrsZXiv=tDR9fn5gtNEf1dCDPw29Z9w@mail.gmail.com>
References: <CAHDRDJVtF+U06FdeCyB6MH96W=xALo9PH-MepmsxUY-9txQuSw@mail.gmail.com>
	<CALQudT9vnrpbadpA7wYKrsZXiv=tDR9fn5gtNEf1dCDPw29Z9w@mail.gmail.com>
Message-ID: <CAPPM_gSyY1R5qZf2cLvTUssdJ6ojUJ4ObutQPQmY2g_1jUXwQQ@mail.gmail.com>

Hi Derek,

I just replied to your earlier email and wanted to note here that the
issue only seems to be with stoptrailing orders on OHLC data.  Using
them on BBO data should work correctly.

Best,
Josh

On Sun, Mar 6, 2016 at 6:44 PM, Derek Wong <treydog999 at gmail.com> wrote:
> Hi Peter,
>
> I had submitted a problem with the trailing stop in quantstrat 2 weeks
> ago. I have looked at the code in the orders.R and ruleproc.R and
> still have not discovered the problem. It does not update on every
> higher high, or lower low. But in a more jumpy fashion, especially if
> you use prefer= anything other than close. Although diving in to that
> code, the logic seemed correct. I just have not found that the
> trailingstop is reliable at this time in quantstrat.
>
> -Derek
>
> On Mon, Mar 7, 2016 at 12:47 AM, Peter Neumaier
> <peter.neumaier at gmail.com> wrote:
>> I am trying to implement a trailing stop in the Luxor example.
>>
>> I have tried many approaches to debug/find the error, i.e.
>>
>>    - run with and without stoploss enabled
>>    - different levels of stoptrailingpercent
>>    - the list goes on
>>
>> But my orderbook (ob.df at the of code) simply is not showing any trailing
>> stops executed.
>>
>> Anyone got any suggestions why my trailing stop is not working? Here is my
>> code:
>>
>>
>> ## ----results='hide'------------------------------------------------------
>> library(quantstrat)
>>
>> options(width = 240)#options(warn=1)
>>
>> Sys.setenv(TZ="UTC")
>> ###
>> initDate = '2003-10-21'
>> .from='2012-01-01'
>> .to='2016-03-01'
>>
>> currency(c('EUR', 'USD'))
>> exchange_rate('EURUSD', tick_size=0.0001)
>>
>> # moving average lengths
>> .fast = 6
>> .slow = 21
>> # optimization range
>> .FastSMA = (1:30)
>> .SlowSMA = (20:80)
>> # trade parameters
>> .threshold = 0.0005
>> .orderqty = 100000
>> .txnfees = -6  # round-trip fee
>> # stop loss amount
>> .stoploss <- 0.30/100
>> # trading window
>> .timespan = 'T00:00/T23:59'
>> # number of optimization samples
>> .nsamples=80
>>
>> ## ------------------------------------------------------------------------portfolio.st
>> = 'forex'account.st = 'IB1'strategy.st = 'luxor'
>>
>> .trailingStopPercent <- 0.001
>>
>> rm.strat(portfolio.st)
>> rm.strat(account.st)
>> rm.strat(strategy.st)
>> ## ----results='hide'------------------------------------------------------
>> initPortf(portfolio.st, symbols='EURUSD', initDate=initDate, currency='USD')
>> addPosLimit(portfolio=portfolio.st,symbol='EURUSD',
>> timestamp=initDate,maxpos=.orderqty)
>>
>>     initAcct(account.st,portfolios=portfolio.st,initDate=initDate,currency='USD')
>> initOrders(portfolio.st, initDate=initDate)
>> strategy(strategy.st, store=TRUE)
>>
>> getSymbols("EUR/USD", src="oanda", from=.from, to=.to,
>> index.class="POSIXct",adjust=T)
>>
>> EURUSD = to.minutes30(EURUSD)
>> EURUSD = align.time(EURUSD, 1800)
>>
>>
>>
>> add.indicator(strategy.st, name = "SMA",
>>           arguments = list(
>>             x = quote(Cl(mktdata)[,1]),
>>             n = .fast
>>           ),
>>           label="nFast")
>>
>> add.indicator(strategy.st, name="SMA",
>>           arguments = list(
>>             x = quote(Cl(mktdata)[,1]),
>>             n = .slow
>>           ),
>>           label="nSlow")
>>
>>
>> add.signal(strategy.st, name='sigCrossover',
>>        arguments = list(
>>          columns=c("nFast","nSlow"),
>>          relationship="gte"
>>        ),
>>        label='long')
>>
>> add.signal(strategy.st, name='sigCrossover',
>>        arguments = list(
>>          columns=c("nFast","nSlow"),
>>          relationship="lt"
>>        ),
>>        label='short')
>>
>>
>> add.rule(strategy.st, name = 'ruleSignal',
>>      arguments=list(sigcol='long' , sigval=TRUE,
>>                     replace=FALSE,
>>                     orderside='long' ,
>>                     ordertype='stoplimit',
>>                     prefer='High',
>>                     threshold=.threshold,
>>                     TxnFees=0,
>>                     orderqty=+.orderqty,
>>                     osFUN=osMaxPos,
>>                     orderset='ocolong'
>>      ),
>>      type='enter',
>>      timespan = .timespan,
>>      label='EnterLONG')
>>
>>
>> add.rule(strategy.st, name = 'ruleSignal',
>>      arguments=list(sigcol='short', sigval=TRUE,
>>                     replace=FALSE,
>>                     orderside='short',
>>                     ordertype='stoplimit',
>>                     prefer='Low',
>>                     threshold=.threshold,
>>                     TxnFees=0,
>>                     orderqty=-.orderqty,
>>                     osFUN=osMaxPos,
>>                     orderset='ocoshort'
>>      ),
>>      type='enter',
>>      timespan = .timespan,
>>      label='EnterSHORT')
>>
>>
>> add.rule(strategy.st, name = 'ruleSignal',
>>      arguments=list(sigcol='short', sigval=TRUE,
>>                     replace=TRUE,
>>                     orderside='long' ,
>>                     ordertype='market',
>>                     TxnFees=.txnfees,
>>                     orderqty='all',
>>                     orderset='ocolong'
>>      ),
>>      type='exit',
>>      timespan = .timespan,
>>      label='Exit2SHORT')
>>
>>
>> add.rule(strategy.st, name = 'ruleSignal',
>>      arguments=list(sigcol='long' , sigval=TRUE,
>>                     replace=TRUE,
>>                     orderside='short',
>>                     ordertype='market',
>>                     TxnFees=.txnfees,
>>                     orderqty='all',
>>                     orderset='ocoshort'
>>      ),
>>      type='exit',
>>      timespan = .timespan,
>>      label='Exit2LONG')
>>
>>
>> add.rule(strategy.st, name = 'ruleSignal',
>>      arguments=list(sigcol='long' , sigval=TRUE,
>>                     replace=FALSE,
>>                     orderside='long',
>>                     ordertype='stoplimit',
>>                     tmult=TRUE,
>>                     threshold=quote(.stoploss),
>>                     TxnFees=.txnfees,
>>                     orderqty='all',
>>                     orderset='ocolong'
>>      ),
>>      type='chain', parent='EnterLONG',
>>      label='StopLossLONG',
>>      enabled=FALSE)
>>
>> add.rule(strategy.st, name = 'ruleSignal',
>>      arguments=list(sigcol='long' , sigval=TRUE,
>>                     replace=FALSE,
>>                     orderside='long',
>>                     ordertype='stoptrailing',
>>                     tmult=TRUE,
>>                     threshold=quote(.trailingStopPercent),
>>                     orderqty='all',
>>                     orderset='ocolong'
>>      ),
>>      type='chain', parent='EnterLong',
>>      label='StopTrailingLong',
>>      enabled=FALSE)
>>
>> add.rule(strategy.st, name = 'ruleSignal',
>>      arguments=list(sigcol='short' , sigval=TRUE,
>>                     replace=FALSE,
>>                     orderside='short',
>>                     ordertype='stoplimit',
>>                     tmult=TRUE,
>>                     threshold=quote(.stoploss),
>>                     TxnFees=.txnfees,
>>                     orderqty='all',
>>                     orderset='ocoshort'
>>      ),
>>      type='chain', parent='EnterSHORT',
>>      label='StopLossSHORT',
>>      enabled=FALSE)
>> # add.rule(strategy.st, name = 'ruleSignal',#
>> arguments=list(sigcol='short' , sigval=TRUE,#
>> replace=FALSE,#                         orderside='short',#
>>              ordertype='stoptrailing',#
>> tmult=TRUE,#
>> threshold=quote(trailingStopPercent),#
>> orderqty='all',#                         orderset='ocoshort'#
>> ),#          type='chain', parent='EnterShort',#
>> label='StopTrailingShort',#          enabled=FALSE# )
>>
>> enable.rule('luxor', 'chain', 'StopLoss')
>> enable.rule('luxor', 'chain', 'StopTrailingLong')
>>
>>
>> out <- applyStrategy(strategy.st, portfolio.st)
>> updatePortf(portfolio.st, Symbols='EURUSD',
>>         Dates=paste('::',as.Date(Sys.time()),sep=''))
>>
>> ob <- getOrderBook(portfolio.st)$forex$EURUSD
>> ob.df <- data.frame(Date=time(ob),coredata(ob))
>> View(ob.df)
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From treydog999 at gmail.com  Sat Mar 12 06:44:34 2016
From: treydog999 at gmail.com (Derek Wong)
Date: Sat, 12 Mar 2016 13:44:34 +0800
Subject: [R-SIG-Finance] stoptrailing mechanics question in MACD example
	- Quantstrat
In-Reply-To: <CAPPM_gRK7DV2jkqUcWB7EpKZTGSE-aeUYro05eE6d7GvDtc=SA@mail.gmail.com>
References: <CALQudT-OuA_xp5ntfjTnrHzzmf3UHMsy4F-kD6B4eaWBTCF0yg@mail.gmail.com>
	<CAPPM_gRK7DV2jkqUcWB7EpKZTGSE-aeUYro05eE6d7GvDtc=SA@mail.gmail.com>
Message-ID: <CALQudT9o2TZnpsra1556x2QteFMJFNqFKPHqjzuN2g4PO5fWfw@mail.gmail.com>

Hi Joshua,

Thank you for that reply. I will take a look at that. But what you
explained seems to be the conditions I found by digging into the order
book and order update logic. The confusing part for that was using the
OHLC data and mixing the close price as a "filter" rather than just
highest high lowest low. Also for the fills as well, as a close below
the stop limit order is not really realistic. As you can be filled by
the low of the day and still have the close above (high of the day and
close below for a short), in reality you would have obtained a fill in
the market. This is assuming that the stoptrailing order is in the
market as it executes at the limit price. But in the back test you
would still be maintaining a position as the order would not be
filled. This leads to some disparity in the results as only winners
would not be filled and continue higher but any losers would be cut
off properly. When in reality both would have been closed. I believe
this backtesting behavior biases the returns upwards when using the
stoptrailing order.

Thanks again,

Derek

On Sat, Mar 12, 2016 at 11:26 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> On Wed, Feb 17, 2016 at 2:22 AM, Derek Wong <treydog999 at gmail.com> wrote:
>> Hello All,
>>
>> I am using Quantstrat 0.9.1709 with Microsoft R Open 3.2.3 on Rstudio.
>>
>> I am having a problem understanding the trailing methodology of the
>> stoptrailing order type in Quantstrat. It seems to me that the
>> trailing stop is not replaced as frequently as it should. Only for
>> larger price changes (threshold value?) it moves but for smaller
>> increments it remains the same. Is this the intended result?
>>
>> I am using the MACD example and commenting out the original exit rule
>> and un-commenting the trailing exit.
>>
>> <snip>
>> #alternatives for risk stops:
>> # simple stoplimit order, with threshold multiplier
>> #add.rule(strat.st,name='ruleSignal', arguments =
>> list(sigcol="signal.gt.zero",sigval=TRUE, orderqty='all',
>> ordertype='stoplimit', orderside='long', threshold=-.05,tmult=TRUE,
>> orderset='exit2'),type='chain', parent='enter',
>> label='risk',storefun=FALSE)
>> # alternately, use a trailing order, also with a threshold multiplier
>> add.rule(strat.st,name='ruleSignal',
>>          arguments = list(sigcol="signal.gt.zero",
>>                           sigval=TRUE,
>>                           orderqty='all',
>>                           ordertype='stoptrailing',
>>                           orderside='long',
>>                           threshold=-1,
>>                           tmult=FALSE,
>>                           orderset='exit2'),
>>          type='chain',
>>          parent='enter',
>>          label='trailingexit')
>>
>> # # exit
>> # add.rule(strat.st,name='ruleSignal',
>> #          arguments = list(sigcol="signal.lt.zero",
>> #                           sigval=TRUE,
>> #                           orderqty='all',
>> #                           ordertype='market',
>> #                           orderside='long',
>> #                           threshold=NULL,
>> #                           orderset='exit2'),
>> #          type='exit',
>> #          label='exit'
>> # )
>>
>> <snip>
>>
>>
>> I am looking at the orderbook and comparing it to the portfolio and
>> price of AAPL. I can see that the trailing stop moves but not on every
>> new high created during the trade. The first trade is an example.
>>
>> <output>
>>> AAPL["2007-03-15/2007-03-26"]
>>            AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted
>> 2007-03-15     89.96     90.36    89.31      89.57   139874700      11.84997
>> 2007-03-16     89.54     89.99    89.32      89.59   142926000      11.85262
>> 2007-03-19     90.24     91.55    89.59      91.13   178240300      12.05636
>> 2007-03-20     91.35     91.84    91.06      91.48   122229100      12.10266
>> 2007-03-21     91.99     94.00    91.65      93.87   171724000      12.41886
>> 2007-03-22     93.73     94.36    93.00      93.96   140373100      12.43076
>> 2007-03-23     93.35     94.07    93.30      93.52   112721000      12.37255
>> 2007-03-26     93.99     95.90    93.30      95.85   216246800      12.68081
>>> obook$macd$AAPL["2007-03-15/2007-03-26"]
>>            Order.Qty Order.Price Order.Type     Order.Side
>> Order.Threshold Order.Status Order.StatusTime      Prefer
>> 2007-03-15 "100"     "89.570001" "market"       "long"     NA
>>     "closed"     "2007-03-16 00:00:00" ""
>> 2007-03-16 "all"     "88.590001" "stoptrailing" "long"     "-1"
>>     "replaced"   "2007-03-19 00:00:00" ""
>> 2007-03-19 "all"     "90.549999" "stoptrailing" "long"     "-1"
>>     "replaced"   "2007-03-21 00:00:00" ""
>> 2007-03-21 "all"     "93.000002" "stoptrailing" "long"     "-1"
>>     "replaced"   "2007-03-26 00:00:00" ""
>> 2007-03-26 "all"     "94.899999" "stoptrailing" "long"     "-1"
>>     "closed"     "2007-03-28 00:00:00" ""
>>            Order.Set Txn.Fees Rule           Time.In.Force
>> 2007-03-15 NA        "0"      "enter"        ""
>> 2007-03-16 "exit2"   "0"      "trailingexit" ""
>> 2007-03-19 "exit2"   "0"      "trailingexit" ""
>> 2007-03-21 "exit2"   "0"      "trailingexit" ""
>> 2007-03-26 "exit2"   "0"      "trailingexit" ""
>>
>> <output>
>>
>> You can see that for the date 2007-03-15 to 2007-03-21 we would have
>> what I would believe to be the expected behavior. However at
>> 2007-03-22 we have a new high of 94.36 so i thought the new
>> Order.Price would be at 93.36 given a threshold =-1 but the order is
>> not adjusted. The order is however adjusted to the correct value on
>> 2007-03-26 after a new AAPL.High at 95.90 and Order Price is 94.899999
>>
>> I am very curious if the threshold works not only as the distance
>> between price but also the threshold of a new high price change in
>> order for the new Order.Price to be changed. I was expecting every new
>> AAPL.high to generate a new Order.Price for a stoptrailing order type.
>>
>> If someone could explain this to me or tell me the expected behavior
>> and mechanics of the trailing methodology I would very much appreciate
>> it.
>>
> For OHLC data, the sell stoplimit order price will be based on the
> high price, but the order evaluation is based on the close price.
> That means the stoplimit will only be moved if the close is >= order
> price + threshold.  And when it is moved, the new order price will be
> high - threshold.
>
> For BBO data, a sell stoplimit order price *and* evaluation would be
> based on the offer price.
>
> I don't recall at the moment why they're different.  Perhaps someone
> else will remember.
>
>> Thank you
>>
>> Derek
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
> R/Finance 2016 | www.rinfinance.com


From peter.neumaier at gmail.com  Sat Mar 12 10:26:14 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Sat, 12 Mar 2016 09:26:14 +0000
Subject: [R-SIG-Finance] Sum volume by day and plot in xts
Message-ID: <CAHDRDJVQ-QJBCc=WX8DrAsTx4ZXYGvSQ1VUC5O40iavqrLYjUg@mail.gmail.com>

Hi all,

I am looking at half hourly OHLC in xts:

                   NGFH6.Open NGFH6.High NGFH6.Low NGFH6.Close NGFH6.Volume
2016-01-06 07:30:00     0.3395     0.3395    0.3375      0.3380           45
2016-01-06 08:00:00     0.3400     0.3400    0.3387      0.3395          140
2016-01-06 08:30:00     0.3395     0.3395    0.3379      0.3379           70

I'd like to plot my closing price for the day and sum up the volume (for
that day).

My current work around is

cbind(NGF[,"NGFH6.Close"],NGF[,"NGFH6.Volume"])

Summing up the daily volume and then plot (in manual steps).

Is there a more elegant way than above work around, i.e. select columns to
plot (without cbind), sum up volume by day and the plot closing price and
the daily sum (probably in one statement)?

I am thankful for any directions on that.
Peter

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Sat Mar 12 14:57:27 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 12 Mar 2016 07:57:27 -0600
Subject: [R-SIG-Finance] Sum volume by day and plot in xts
In-Reply-To: <CAHDRDJVQ-QJBCc=WX8DrAsTx4ZXYGvSQ1VUC5O40iavqrLYjUg@mail.gmail.com>
References: <CAHDRDJVQ-QJBCc=WX8DrAsTx4ZXYGvSQ1VUC5O40iavqrLYjUg@mail.gmail.com>
Message-ID: <CAPPM_gQ3NVV4ruRAa+=4QokCHYdH7qRPG39phqGOmU9NvpKNVg@mail.gmail.com>

On Sat, Mar 12, 2016 at 3:26 AM, Peter Neumaier
<peter.neumaier at gmail.com> wrote:
> Hi all,
>
> I am looking at half hourly OHLC in xts:
>
>                    NGFH6.Open NGFH6.High NGFH6.Low NGFH6.Close NGFH6.Volume
> 2016-01-06 07:30:00     0.3395     0.3395    0.3375      0.3380           45
> 2016-01-06 08:00:00     0.3400     0.3400    0.3387      0.3395          140
> 2016-01-06 08:30:00     0.3395     0.3395    0.3379      0.3379           70
>
> I'd like to plot my closing price for the day and sum up the volume (for
> that day).
>
> My current work around is
>
> cbind(NGF[,"NGFH6.Close"],NGF[,"NGFH6.Volume"])
>
> Summing up the daily volume and then plot (in manual steps).
>
> Is there a more elegant way than above work around, i.e. select columns to
> plot (without cbind), sum up volume by day and the plot closing price and
> the daily sum (probably in one statement)?
>
As I said in my reply to one of your other messages: please read the
manuals.  What you want is described in section 3.4 of the xts
vignette.  Use to.period.

> I am thankful for any directions on that.
> Peter
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From josh.m.ulrich at gmail.com  Sat Mar 12 17:19:13 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 12 Mar 2016 10:19:13 -0600
Subject: [R-SIG-Finance] Time in Force conditions with Quantstrat
In-Reply-To: <CANf4qfjuqJ2Ps1+nwd+=hZXUbMpY2oNL_SnkiHxucderLXy_mw@mail.gmail.com>
References: <CANf4qfjuqJ2Ps1+nwd+=hZXUbMpY2oNL_SnkiHxucderLXy_mw@mail.gmail.com>
Message-ID: <CAPPM_gTenMQX8F6CQtrAgEiepU=dZMfFicT4=xDShJF8HwOrpw@mail.gmail.com>

On Sun, Feb 28, 2016 at 9:10 PM, Ryan <suchislife27 at gmail.com> wrote:
> I'm having some difficulty getting time in force to work with quanstrat.
>
> I've studied the documentation and it states that:
>
> timestamp time-in-force; either a time stamp, or a number of seconds, or
> 'GTC' / ?, 'GTC' and ? both meaning 'Good Till Canceled'; order expires if
> still 'open' at this timestamp, default is ?
>
> I have been trying to enter a limit order, 5% below the Close price, as
> when I study the orderbook and mktdata object, it appears that a limit
> order is based on the bar in which the signal occurs. Hence the limit price
> would be 5% below the Close.
>
> I've tried to enter a time in seconds, which is the equivalent to two days,
> for the sake of the example. If I remove timestamp it runs however
> time.in.force remains blank in the orderbook as I would expect timestamp +
> time.in.force is the time when the order is cancelled.
>
> As laid out below I get the following error:
>
> Error in if (prefer == "Close") { : argument is of length zero
>
The error is because you included `timestamp` as one of the arguments
to `ruleSignal`. `timestamp` is a function in the utils package, so
you're essentially passing a function via '...' which is causing
problems.  I'm not sure why this is causing this particular issue, but
the fix is "don't do that."

You also specified the time.in.force argument incorrectly.  It's
supposed to be either: a timestamp (e.g. a Date or POSIXct object), a
number of seconds, or "GTC".  You specified time.in.force="172800",
which is a character string.

>
> Below is a reproducible example that produces the error. Any assistance
> would be greatly appreciated.
>
<snip>

Here's a modified version of your example that works for me using the
latest development versions of quantstrat and xts.

require(quantstrat)
require(IKTrading)

# Set the currency and the timezone
currency('USD')
Sys.setenv(TZ = "UTC")

# Define symbols of interest
symbols <- c("AMP.AX", "BHP.AX", "ANZ.AX",
   "CBA.AX", "BXB.AX", "CSL.AX", "IAG.AX",
   "MQG.AX", "NAB.AX", "ORG.AX", "QBE.AX",
   "RIO.AX", "SCG.AX", "SUN.AX", "TLS.AX",
   "WBC.AX", "WES.AX", "WOW.AX", "WPL.AX",
   "TCL.AX", "WFD.AX", "AMC.AX")

#Get Symbols
getSymbols(Symbols=symbols, from="2010-01-01", to="2015-12-31")

# Define the instrument type
stock(symbols, currency = "USD", multiplier = 1)

#Boilerplate
from = "2010-01-01"
to = "2015-12-31"

#trade sizing and initial equity settings
tradeSize <- 2500
initEq <- 100000

strategy.st <- portfolio.st <- account.st <- "Timeinforce"
rm.strat(portfolio.st)
rm.strat(strategy.st)
initAcct(account.st, portfolio.st, currency='USD', initEq=initEq)
initPortf(portfolio.st, symbols, currency='USD')
initOrders(portfolio.st)
strategy(strategy.st, store=TRUE)

#Add Indicators
add.indicator(strategy.st, name="SMA",
              arguments=list(x=quote(Cl(mktdata)), n=20),
              label="sma")

#Add Entry and Exit Signals
add.signal(strategy.st, name="sigComparison",
  arguments=list(columns=c("Close", "SMA.sma"),
                 relationship="gt"),
  label="longentry")

#enter signal rule
add.rule(strategy.st, name="ruleSignal",
  arguments=list(sigcol="longentry",
                 sigval=TRUE,
                 ordertype="limit",
                 orderside="long",
                 replace=TRUE,
                 prefer="Close",
                 tmult = TRUE,
                 threshold = 0.05,
                 time.in.force=172800,
                 orderqty=tradeSize,
                 osFUN=osMaxDollar,
                 tradeSize=tradeSize,
                 maxSize=tradeSize),
  type="enter",
  path.dep=TRUE,
  label="enterlong")

#stop loss.
add.rule(strategy.st, name="ruleSignal",
  arguments=list(sigcol="longentry",
                 sigval=TRUE,
                 ordertype="stoptrailing",
                 orderside="long",
                 replace=FALSE,
                 orderqty="all",
                 threshold=0.05,
                 tmult=TRUE,
                 orderset="ocolong"),
  type="chain",
  parent="enterlong",
  label="stopLossLong",
  path.dep=TRUE,
  enable=TRUE)

#apply strategy
out2 <- applyStrategy(strategy=strategy.st,portfolios=portfolio.st )


-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From josh.m.ulrich at gmail.com  Sat Mar 12 23:43:15 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 12 Mar 2016 16:43:15 -0600
Subject: [R-SIG-Finance] quartstrat applyStrategy error when starting
 one month earlier (endDate not found)
In-Reply-To: <0765308CD028654885F30322557308D81F072366@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D81F072366@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <CAPPM_gRFuB21f6770kMaRj9x_uJ-N0J8=sp8bv259PtZYtpjWw@mail.gmail.com>

Hi Roger,

I don't get an error using either data object.  Ensure you have the
latest quantstrat and blotter from R-Forge and try running the example
in the email again.  If you still get an error, please provide the
output from traceback() and sessionInfo().

Best,
Josh

On Fri, Feb 26, 2016 at 11:28 AM, Bos, Roger <roger.bos at rothschild.com> wrote:
> Dear all quantstrat users,
>
> I am trying to learn how to use quantstrat with pricing data read in from a csv file using getSymbols(symbols, src='csv'). I think I have that part working, but I am having a problem that I cannot debug myself.  The following code is from the faber_rebal demo. To make it reproducible I have used dput() to generate a truncated version of the csv pricing data for my example symbol G12 (actually XLF).  I have truncated the data to make it easier to post this message.  The first version of G12 does not work and the second version does.  The only difference is the starting point.  If the G12 data starts in 1/31/1999 the code works fine, but if the G12 data starts in 12/31/1998 the code gives an error in applyStrategy.rebalancing:
>
>> out<-applyStrategy.rebalancing(strategy='faber' , portfolios='faber')
> Error in if (is.na(endDate)) endDate <- NULL : argument is of length zero
>
> Thanks in advance for any advice on this, Roger
>
>
> # Not Working (starting at 12/31/1998)
> G12 <- structure(c(23.4375, 23.84375, 24.21875, 24.9375, 26.6875, 25.078125,
> 26.09375, 24.5, 23.421875, 22.125, 25.5625, 24.4375, 23.765625,
> 23.0625, 20.59375, 24.265625, 24.5, 25.046875, 23.75, 25.984375,
> 28.46875, 29, 28.75, 27.28125, 29.5, 23.8125, 25.0625, 24.875,
> 26.3125, 29.28125, 27.28125, 26.3125, 26.84375, 25.796875, 24.25,
> 26.15625, 26.78125, 25.40625, 24.078125, 23.234375, 25.1875,
> 25.796875, 25.1875, 27.15625, 26.34375, 28.625, 29.625, 29.625,
> 29.21875, 30.0625, 23.21875, 22.71875, 22.0625, 24.015625, 24.75,
> 24.375, 24.15625, 24.46875, 22.65625, 21.5, 20.875, 24.03125,
> 22.71875, 21.46875, 19.65625, 19.46875, 22.125, 22.65625, 23.40625,
> 23.5625, 25.875, 27.125, 24.875, 25.75, 26.71875, 23.4375, 23.84375,
> 24.21875, 24.9375, 26.6875, 25.078125, 26.09375, 24.5, 23.421875,
> 22.125, 25.5625, 24.4375, 23.765625, 23.0625, 20.59375, 24.265625,
> 24.5, 25.046875, 23.75, 25.984375, 28.46875, 29, 28.75, 27.28125,
> 29.5, 447800, 2057500, 2334300, 3122300, 2662900, 3307500, 2091900,
> 2333800, 3945700, 5653600, 9955200, 5993600, 14715300, 8663400,
> 8425500, 15117400, 8647800, 5391700, 9438800, 4609900, 4224100,
> 9112300, 18210900, 17317600, 21173200, 23.4375, 23.84375, 24.21875,
> 24.9375, 26.6875, 25.078125, 26.09375, 24.5, 23.421875, 22.125,
> 25.5625, 24.4375, 23.765625, 23.0625, 20.59375, 24.265625, 24.5,
> 25.046875, 23.75, 25.984375, 28.46875, 29, 28.75, 27.28125, 29.5),
> .Dim = c(25L, 6L), .Dimnames = list(NULL, c("G12.Open", "G12.High",
> "G12.Low", "G12.Close", "G12.Volume", "G12.Adjusted")), index = structure(c(915062400,
>                                    917740800, 920160000, 922838400, 925430400, 928108800, 930700800,
>                                    933379200, 936057600, 938649600, 941328000, 943920000, 946598400,
>                                    949276800, 951782400, 954460800, 957052800, 959731200, 962323200,
>                                    965001600, 967680000, 970272000, 972950400, 975542400, 978220800
> ), tclass = "Date"), tclass = "Date", tzone = "UTC", src = "csv", updated = structure(1456505311.48799, class = c("POSIXct",
>                                                                          "POSIXt")), .indexCLASS = "Date", .indexTZ = "UTC", .indexFORMAT = "%Y-%m-%d", class = c("xts","zoo"))
>
>
> # Working (starting at 1/31/1999)
> G12 <- structure(c(23.84375, 24.21875, 24.9375, 26.6875, 25.078125,
> 26.09375, 24.5, 23.421875, 22.125, 25.5625, 24.4375, 23.765625,
> 23.0625, 20.59375, 24.265625, 24.5, 25.046875, 23.75, 25.984375,
> 28.46875, 29, 28.75, 27.28125, 29.5, 25.0625, 24.875, 26.3125,
> 29.28125, 27.28125, 26.3125, 26.84375, 25.796875, 24.25, 26.15625,
> 26.78125, 25.40625, 24.078125, 23.234375, 25.1875, 25.796875,
> 25.1875, 27.15625, 26.34375, 28.625, 29.625, 29.625, 29.21875,
> 30.0625, 22.71875, 22.0625, 24.015625, 24.75, 24.375, 24.15625,
> 24.46875, 22.65625, 21.5, 20.875, 24.03125, 22.71875, 21.46875,
> 19.65625, 19.46875, 22.125, 22.65625, 23.40625, 23.5625, 25.875,
> 27.125, 24.875, 25.75, 26.71875, 23.84375, 24.21875, 24.9375,
> 26.6875, 25.078125, 26.09375, 24.5, 23.421875, 22.125, 25.5625,
> 24.4375, 23.765625, 23.0625, 20.59375, 24.265625, 24.5, 25.046875,
> 23.75, 25.984375, 28.46875, 29, 28.75, 27.28125, 29.5, 2057500,
> 2334300, 3122300, 2662900, 3307500, 2091900, 2333800, 3945700,
> 5653600, 9955200, 5993600, 14715300, 8663400, 8425500, 15117400,
> 8647800, 5391700, 9438800, 4609900, 4224100, 9112300, 18210900,
> 17317600, 21173200, 23.84375, 24.21875, 24.9375, 26.6875, 25.078125,
> 26.09375, 24.5, 23.421875, 22.125, 25.5625, 24.4375, 23.765625,
> 23.0625, 20.59375, 24.265625, 24.5, 25.046875, 23.75, 25.984375,
> 28.46875, 29, 28.75, 27.28125, 29.5), .Dim = c(24L, 6L), .Dimnames = list(
> NULL, c("G12.Open", "G12.High", "G12.Low", "G12.Close", "G12.Volume",
> "G12.Adjusted")), index = structure(c(917740800, 920160000,
> 922838400, 925430400, 928108800, 930700800, 933379200, 936057600,
> 938649600, 941328000, 943920000, 946598400, 949276800, 951782400,
> 954460800, 957052800, 959731200, 962323200, 965001600, 967680000,
> 970272000, 972950400, 975542400, 978220800), tclass = "Date"), tclass = "Date", tzone = "UTC", src = "csv",
> updated = structure(1456505447.82159, class = c("POSIXct",
> "POSIXt")), .indexCLASS = "Date", .indexTZ = "UTC", .indexFORMAT = "%Y-%m-%d", class = c("xts","zoo"))
>
>
>
> # Load required libraries
> require(quantstrat)
>
> #correct for TZ issues if they crop up
> oldtz <- Sys.getenv('TZ')
> if(oldtz=='') {
>   Sys.setenv(TZ="UTC")
> }
>
> # Try to clean up in case the demo was run previously
> suppressWarnings(rm("account.faber","portfolio.faber",pos=.blotter))
> suppressWarnings(rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate", "equity",
>             "GSPC", "stratFaber", "startDate", "initEq", "Posn", "UnitSize", "verbose"))
> suppressWarnings(rm("order_book.faber",pos=.strategy))
>
> # Set initial values
> startDate='1997-12-31'
> initEq=100000
>
> # Set up instruments with FinancialInstruments package
> currency("USD")
> #symbols = c("XLF", "XLP", "XLE", "XLY", "XLV", "XLI", "XLB", "XLK", "XLU")
> symbols = c("G12")
> for(symbol in symbols){ # establish tradable instruments
>     stock(symbol, currency="USD",multiplier=1)
> }
>
> # Load data with quantmod
> #getSymbols(symbols, src='yahoo', index.class=c("POSIXt","POSIXct"), from='1998-01-01')
> ### Download monthly data instead?
> ### GSPC=to.monthly(GSPC, indexAt='endof')
> #getSymbols(symbols, src='yahoo', index.class=c("POSIXt","POSIXct"), from='1999-01-01')
> #getSymbols(symbols, src='csv')
> for(symbol in symbols) {
>     x<-get(symbol)
>     x<-to.monthly(x,indexAt='lastof',drop.time=TRUE)
>     indexFormat(x)<-'%Y-%m-%d'
>     colnames(x)<-gsub("x",symbol,colnames(x))
>     assign(symbol,x)
> }
>
> # Initialize portfolio and account
> initPortf('faber', symbols=symbols)
> initAcct('faber', portfolios='faber', initEq=100000)
> initOrders(portfolio='faber')
>
> # set intial position limits
> posval <- initEq/length(symbols)
> for(symbol in symbols){
>   #pos <- round((posval/first(getPrice(get(symbol)))[,1]),-2)
>   pos <- round((posval/first(getPrice(get(symbol)))),-2)
>   addPosLimit('faber', symbol, startDate, maxpos=pos, minpos=-pos)
> }
> print("setup completed")
>
> # Initialize a strategy object
> strategy("faber", store=TRUE)
>
> # Add an indicator
> add.indicator('faber', name = "SMA", arguments = list(x = quote(Cl(mktdata)), n=10), label="SMA10")
>
> # There are two signals:
> # The first is when monthly price crosses over the 10-month SMA
> add.signal('faber',name="sigCrossover",arguments = list(columns=c("Close","SMA10"),relationship="gte"),label="Cl.gt.SMA")
> # The second is when the monthly price crosses under the 10-month SMA
> add.signal('faber',name="sigCrossover",arguments = list(columns=c("Close","SMA10"),relationship="lt"),label="Cl.lt.SMA")
>
> # There are two rules:
> # The first is to buy when the price crosses above the SMA
> add.rule('faber', name='ruleSignal', arguments = list(sigcol="Cl.gt.SMA", sigval=TRUE, orderqty=100000, osFUN='osMaxPos', ordertype='market', orderside='long', pricemethod='market',TxnFees=-5), type='enter', path.dep=TRUE)
> # The second is to sell when the price crosses below the SMA
> add.rule('faber', name='ruleSignal', arguments = list(sigcol="Cl.lt.SMA", sigval=TRUE, orderqty='all', ordertype='market', orderside='long', pricemethod='market',TxnFees=-5), type='exit', path.dep=TRUE)
>
> # add quaterly rebalancing
> add.rule('faber', 'rulePctEquity',
>         arguments=list(rebalance_on='quarters',
>                 trade.percent=1/length(symbols),
>                 refprice=quote(last(getPrice(mktdata)[paste('::',as.character(curIndex),sep='')][,1])),
>                 digits=0
>         ),
>         type='rebalance',
>         label='rebalance'
> )
>
> # Process the strategy and generate trades
> start_t<-Sys.time()
> out<-applyStrategy.rebalancing(strategy='faber' , portfolios='faber')
> end_t<-Sys.time()
> print("Strategy Loop:")
> print(end_t-start_t)
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From aschmid1 at stevens.edu  Sun Mar 13 02:30:36 2016
From: aschmid1 at stevens.edu (Alec Schmidt)
Date: Sun, 13 Mar 2016 01:30:36 +0000
Subject: [R-SIG-Finance] Solver for a generic optimal portfolio
Message-ID: <1457832636634.41311@stevens.edu>

I'd like to estimate weights of an optimal portfolio other than min variance portfolio by replacing covariance matrix with something else. Is there an R package that can do this (my understanding is that solve.QP is not helpful for this task).


Thanks! Alec

	[[alternative HTML version deleted]]


From patrick at burns-stat.com  Sun Mar 13 02:36:17 2016
From: patrick at burns-stat.com (Patrick Burns)
Date: Sun, 13 Mar 2016 01:36:17 +0000
Subject: [R-SIG-Finance] Solver for a generic optimal portfolio
In-Reply-To: <1457832636634.41311@stevens.edu>
References: <1457832636634.41311@stevens.edu>
Message-ID: <56E4C411.8050303@burns-stat.com>

Alec,

I think you need to explain more fully
what you would like to do.

What objective do you want to optimize?
What constraints do you want?

Pat

On 13/03/2016 01:30, Alec Schmidt wrote:
> I'd like to estimate weights of an optimal portfolio other than min variance portfolio by replacing covariance matrix with something else. Is there an R package that can do this (my understanding is that solve.QP is not helpful for this task).
>
>
> Thanks! Alec
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com
http://www.portfolioprobe.com/blog
twitter: @burnsstat @portfolioprobe


From markleeds2 at gmail.com  Sun Mar 13 02:37:13 2016
From: markleeds2 at gmail.com (Mark Leeds)
Date: Sat, 12 Mar 2016 20:37:13 -0500
Subject: [R-SIG-Finance] Solver for a generic optimal portfolio
In-Reply-To: <1457832636634.41311@stevens.edu>
References: <1457832636634.41311@stevens.edu>
Message-ID: <CAHz+bWZRRB=OzjrgsxUKCneH5L_bSTMiSpuK-9OJxC6k0sdNFg@mail.gmail.com>

solve.QP probably assumes the standard markowitz style mean-variance
framework where the objective function is quadratic.  So, if you want some
other objective function, you'd have to describe it exactly in order for
others to figure out whether the objective function is still quadratic.



On Sat, Mar 12, 2016 at 8:30 PM, Alec Schmidt <aschmid1 at stevens.edu> wrote:

> I'd like to estimate weights of an optimal portfolio other than min
> variance portfolio by replacing covariance matrix with something else. Is
> there an R package that can do this (my understanding is that solve.QP is
> not helpful for this task).
>
>
> Thanks! Alec
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From brian at braverock.com  Sun Mar 13 02:38:52 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 12 Mar 2016 19:38:52 -0600
Subject: [R-SIG-Finance] Solver for a generic optimal portfolio
In-Reply-To: <1457832636634.41311@stevens.edu>
References: <1457832636634.41311@stevens.edu>
Message-ID: <56E4C4AC.60202@braverock.com>

On 03/12/2016 07:30 PM, Alec Schmidt wrote:
> I'd like to estimate weights of an optimal portfolio other than min
> variance portfolio by replacing covariance matrix with something
> else. Is there an R package that can do this (my understanding is
> that solve.QP is not helpful for this task).

Alec,

You'll need to be a little more specific about what your target 
objectives and constraints are if someone is going to be able to help you.

For some objectives and constraints, quadratic, linear, or conical 
solvers can be used.  For other objective and constraint combinations, 
you'll need a global stochastic solver.

Without understanding precisely what you're trying to do, no one can 
give you an answer about which package(s) will be best for your problem.

I can say that I think of any portfolio formulation I can come up with 
may be solved with R.

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From aschmid1 at stevens.edu  Sun Mar 13 02:47:39 2016
From: aschmid1 at stevens.edu (Alec Schmidt)
Date: Sun, 13 Mar 2016 01:47:39 +0000
Subject: [R-SIG-Finance] Solver for a generic optimal portfolio
In-Reply-To: <56E4C4AC.60202@braverock.com>
References: <1457832636634.41311@stevens.edu>,<56E4C4AC.60202@braverock.com>
Message-ID: <1457833659586.95230@stevens.edu>

Brian/Mark/Patrick,
Thanks for answering my curiosity on Saturday night. I just come across the Willenbrock's paper http://arxiv.org/abs/1109.1256
and wonder if it makes sense to optimize so-called diversification return (eq 13) and, if yes, what tool you might suggest.
Best, Alec

________________________________________
From: R-SIG-Finance <r-sig-finance-bounces at r-project.org> on behalf of Brian G. Peterson <brian at braverock.com>
Sent: Saturday, March 12, 2016 8:38 PM
To: r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] Solver for a generic optimal portfolio

On 03/12/2016 07:30 PM, Alec Schmidt wrote:
> I'd like to estimate weights of an optimal portfolio other than min
> variance portfolio by replacing covariance matrix with something
> else. Is there an R package that can do this (my understanding is
> that solve.QP is not helpful for this task).

Alec,

You'll need to be a little more specific about what your target
objectives and constraints are if someone is going to be able to help you.

For some objectives and constraints, quadratic, linear, or conical
solvers can be used.  For other objective and constraint combinations,
you'll need a global stochastic solver.

Without understanding precisely what you're trying to do, no one can
give you an answer about which package(s) will be best for your problem.

I can say that I think of any portfolio formulation I can come up with
may be solved with R.

Regards,

Brian

--
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


From brian at braverock.com  Sun Mar 13 03:00:55 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 12 Mar 2016 20:00:55 -0600
Subject: [R-SIG-Finance] Solver for a generic optimal portfolio
In-Reply-To: <1457833659586.95230@stevens.edu>
References: <1457832636634.41311@stevens.edu> <56E4C4AC.60202@braverock.com>
	<1457833659586.95230@stevens.edu>
Message-ID: <56E4C9D7.6010100@braverock.com>

The diversification return is a side effect of rebalancing.

To 'optimize' for diversification return, you'll still need some other 
objectives and constraints.

In any complex feasible space for optimization with a non-trivial number 
of assets, you can often find multiple portfolios with similar base 
properties (like return and variance).  You could, in theory, maximize 
diversification return by finding neighboring 'near-optimal' portfolios 
on your other objectives and constraints and then choosing among them 
with a preference for higher turnover.

This, of course, will incur significant rebalancing costs. These 
associated costs are why a continuously rebalanced portfolio is 
unrealistic, and why most portfolio construction methodologies try to 
minimize turnover. (There are other reasons for minimizing turnover too, 
but those are the ones most often discussed).

We still don't know enough about what the other objectives and 
constraints you have for your portfolio to recommend a specific solver.

Regards,

Brian


On 03/12/2016 07:47 PM, Alec Schmidt wrote:
> Brian/Mark/Patrick,
> Thanks for answering my curiosity on Saturday night. I just come across the Willenbrock's paper http://arxiv.org/abs/1109.1256
> and wonder if it makes sense to optimize so-called diversification return (eq 13) and, if yes, what tool you might suggest.
> Best, Alec
>
> ________________________________________
> From: R-SIG-Finance <r-sig-finance-bounces at r-project.org> on behalf of Brian G. Peterson <brian at braverock.com>
> Sent: Saturday, March 12, 2016 8:38 PM
> To: r-sig-finance at r-project.org
> Subject: Re: [R-SIG-Finance] Solver for a generic optimal portfolio
>
> On 03/12/2016 07:30 PM, Alec Schmidt wrote:
>> I'd like to estimate weights of an optimal portfolio other than min
>> variance portfolio by replacing covariance matrix with something
>> else. Is there an R package that can do this (my understanding is
>> that solve.QP is not helpful for this task).
>
> Alec,
>
> You'll need to be a little more specific about what your target
> objectives and constraints are if someone is going to be able to help you.
>
> For some objectives and constraints, quadratic, linear, or conical
> solvers can be used.  For other objective and constraint combinations,
> you'll need a global stochastic solver.
>
> Without understanding precisely what you're trying to do, no one can
> give you an answer about which package(s) will be best for your problem.
>
> I can say that I think of any portfolio formulation I can come up with
> may be solved with R.
>
> Regards,
>
> Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From aschmid1 at stevens.edu  Sun Mar 13 03:15:50 2016
From: aschmid1 at stevens.edu (Alec Schmidt)
Date: Sun, 13 Mar 2016 02:15:50 +0000
Subject: [R-SIG-Finance] Solver for a generic optimal portfolio
In-Reply-To: <56E4C9D7.6010100@braverock.com>
References: <1457832636634.41311@stevens.edu> <56E4C4AC.60202@braverock.com>
	<1457833659586.95230@stevens.edu>,<56E4C9D7.6010100@braverock.com>
Message-ID: <1457835350166.23214@stevens.edu>

Brian, 
My goals are still very fluid. As you certainly know, Markowitz theory does not guarantee good diversification, and its out of sample performance is less than perfect. So I just started thinking about other formulations, leaving for now  the same Markowitz constraints: sum of weights is unity, mean portfolio return is given; also all weights are positive. Does this make sense?

Best, Alec  
________________________________________
From: R-SIG-Finance <r-sig-finance-bounces at r-project.org> on behalf of Brian G. Peterson <brian at braverock.com>
Sent: Saturday, March 12, 2016 9:00 PM
To: r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] Solver for a generic optimal portfolio

The diversification return is a side effect of rebalancing.

To 'optimize' for diversification return, you'll still need some other
objectives and constraints.

In any complex feasible space for optimization with a non-trivial number
of assets, you can often find multiple portfolios with similar base
properties (like return and variance).  You could, in theory, maximize
diversification return by finding neighboring 'near-optimal' portfolios
on your other objectives and constraints and then choosing among them
with a preference for higher turnover.

This, of course, will incur significant rebalancing costs. These
associated costs are why a continuously rebalanced portfolio is
unrealistic, and why most portfolio construction methodologies try to
minimize turnover. (There are other reasons for minimizing turnover too,
but those are the ones most often discussed).

We still don't know enough about what the other objectives and
constraints you have for your portfolio to recommend a specific solver.

Regards,

Brian


On 03/12/2016 07:47 PM, Alec Schmidt wrote:
> Brian/Mark/Patrick,
> Thanks for answering my curiosity on Saturday night. I just come across the Willenbrock's paper http://arxiv.org/abs/1109.1256
> and wonder if it makes sense to optimize so-called diversification return (eq 13) and, if yes, what tool you might suggest.
> Best, Alec
>
> ________________________________________
> From: R-SIG-Finance <r-sig-finance-bounces at r-project.org> on behalf of Brian G. Peterson <brian at braverock.com>
> Sent: Saturday, March 12, 2016 8:38 PM
> To: r-sig-finance at r-project.org
> Subject: Re: [R-SIG-Finance] Solver for a generic optimal portfolio
>
> On 03/12/2016 07:30 PM, Alec Schmidt wrote:
>> I'd like to estimate weights of an optimal portfolio other than min
>> variance portfolio by replacing covariance matrix with something
>> else. Is there an R package that can do this (my understanding is
>> that solve.QP is not helpful for this task).
>
> Alec,
>
> You'll need to be a little more specific about what your target
> objectives and constraints are if someone is going to be able to help you.
>
> For some objectives and constraints, quadratic, linear, or conical
> solvers can be used.  For other objective and constraint combinations,
> you'll need a global stochastic solver.
>
> Without understanding precisely what you're trying to do, no one can
> give you an answer about which package(s) will be best for your problem.
>
> I can say that I think of any portfolio formulation I can come up with
> may be solved with R.
>
> Regards,
>
> Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


--
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


From peter.neumaier at gmail.com  Tue Mar 15 13:52:11 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Tue, 15 Mar 2016 12:52:11 +0000
Subject: [R-SIG-Finance] Unexpected StopLoss order placed and triggered
Message-ID: <CAHDRDJWi0CCmTL7xeK==uDnODOyw_kOOm8o6tUXUenZNs0K_Xg@mail.gmail.com>

Hi all,

I am testing a simple Bollinger-Breakout:

if Close > UpperBand Then Long
if Close < LowerbandBand Then Short
if Close Crosses MidBand Then Exit

Here is what happens:

- I am entering as expected a short position on closing below the lower band
- Immediately after entering the short position, in the order book I can
see a stop loss limit order being created: BELOW the entry price of my
short position
- Price drops further, stop loss is getting triggered and my short gets
closed at the stop loss threshhold, but BELOW the entry price

I would expect the stop loss to be triggered when losing money and not when
making. What am I doing wrong here?

I am not sure which parts of my code would help, and before flooding you
with orderbook, transactions etc. I'll start with my signal and rules
(below).
Your input is greatly appreciated. Thanks!

add.indicator(strat.st, name = "BBands",
  arguments = list(HLC = quote(HLC(mktdata)), maType='SMA'), label='BBands')

add.signal(strat.st, name="sigCrossover",
  arguments=list(columns=c("Close","up"),relationship="gt"),
  label="Cl.gt.UpperBand")

add.signal(strat.st, name="sigCrossover",
  arguments=list(columns=c("Close","dn"),relationship="lt"),
  label="Cl.lt.LowerBand")

add.signal(strat.st, name="sigCrossover",
  arguments=list(columns=c("Close","mavg"),relationship="gt"),
  label="Cross.Mid.GT")

add.signal(strat.st, name="sigCrossover",
           arguments=list(columns=c("Close","mavg"),relationship="lt"),
           label="Cross.Mid.LT")

add.rule(strat.st, name='ruleSignal',
  arguments=list(sigcol="Cl.gt.UpperBand",sigval=TRUE, orderqty=1,
    ordertype='market', orderside=NULL, threshold=NULL, osFUN=osFixedDollar,
    orderset='ocolong'),
    type='enter',label="LE")

add.rule(strat.st, name='ruleSignal',
  arguments=list(sigcol="Cl.lt.LowerBand",sigval=TRUE, orderqty= -1,
    ordertype='market', orderside=NULL, threshold=NULL, osFUN=osFixedDollar,
    orderset='ocoshort'),
  type='enter',label="SE")

add.rule(strat.st, name='ruleSignal',
  arguments=list(sigcol="Cross.Mid.GT",sigval=TRUE, orderqty= 'all',
    ordertype='market', orderside=NULL, threshold=NULL),
  type='exit', label="midCrossGT")

add.rule(strat.st, name='ruleSignal',
         arguments=list(sigcol="Cross.Mid.LT",sigval=TRUE, orderqty= 'all',
                        ordertype='market', orderside=NULL, threshold=NULL),
         type='exit', label="midCrossLT")

add.rule(strat.st, name = 'ruleSignal',
         arguments=list(sigcol='Cl.gt.UpperBand' , sigval=TRUE,
                        replace=FALSE,
                        orderside=NULL,
                        ordertype='limit',
                        tmult=TRUE,
                        threshold=quote(.stoploss),
                        orderqty='all',
                        orderset='ocolong'
         ),
         type='chain', parent='LE',
         label='StopLossLONG',
         enabled=FALSE
)

add.rule(strat.st, name = 'ruleSignal',
         arguments=list(sigcol='Cl.lt.LowerBand' , sigval=TRUE,
                        replace=FALSE,
                        orderside=NULL,
                        ordertype='limit',
                        tmult=TRUE,
                        threshold=quote(.stoploss),
                        orderqty='all',
                        orderset='ocoshort'
         ),
         type='chain', parent='SE',
         label='StopLossSHORT',
         enabled=FALSE
)

	[[alternative HTML version deleted]]


From matt at considine.net  Wed Mar 16 19:06:29 2016
From: matt at considine.net (matt at considine.net)
Date: Wed, 16 Mar 2016 13:06:29 -0500
Subject: [R-SIG-Finance] PortfolioAnalytics question re: showing results
Message-ID: <715fde38520f15d3c03d41125cc58ca2@considine.net>

Hi,
I have a sense I have overlooked something pretty basic here, but I'll 
risk asking an obvious question.  I am trying to use PortfolioAnalytics 
as a complement to information provided by an investment consultant.  
They are presenting their efficient frontier results with annualized 
expected return data.  I'm feeding PortfolioAnalytics monthly historical 
data, so the resulting chart/summary data is on a monthly basis (I 
believe).

Is there a flag for results to be presented on an annualized basis?

Thank in advance - and apologies for overlooking something clear.  I did 
try to search the docs first :)
Regards,
Matt


From ilya.kipnis at gmail.com  Wed Mar 16 19:12:01 2016
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Wed, 16 Mar 2016 14:12:01 -0400
Subject: [R-SIG-Finance] PortfolioAnalytics question re: showing results
In-Reply-To: <715fde38520f15d3c03d41125cc58ca2@considine.net>
References: <715fde38520f15d3c03d41125cc58ca2@considine.net>
Message-ID: <CA+oJuEGPRLOger8L7GB2-s_k-cGHZfCu1QvYy+JB53KZXOyT3w@mail.gmail.com>

Matt,

PerformanceAnalytics has all the tools you need for those things. EG
Return.annualized, and so on.

-Ilya

On Wed, Mar 16, 2016 at 2:06 PM, <matt at considine.net> wrote:

> Hi,
> I have a sense I have overlooked something pretty basic here, but I'll
> risk asking an obvious question.  I am trying to use PortfolioAnalytics as
> a complement to information provided by an investment consultant.  They are
> presenting their efficient frontier results with annualized expected return
> data.  I'm feeding PortfolioAnalytics monthly historical data, so the
> resulting chart/summary data is on a monthly basis (I believe).
>
> Is there a flag for results to be presented on an annualized basis?
>
> Thank in advance - and apologies for overlooking something clear.  I did
> try to search the docs first :)
> Regards,
> Matt
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From matt at considine.net  Wed Mar 16 19:52:40 2016
From: matt at considine.net (matt at considine.net)
Date: Wed, 16 Mar 2016 13:52:40 -0500
Subject: [R-SIG-Finance] PortfolioAnalytics question re: showing results
In-Reply-To: <CA+oJuEGPRLOger8L7GB2-s_k-cGHZfCu1QvYy+JB53KZXOyT3w@mail.gmail.com>
References: <715fde38520f15d3c03d41125cc58ca2@considine.net>
	<CA+oJuEGPRLOger8L7GB2-s_k-cGHZfCu1QvYy+JB53KZXOyT3w@mail.gmail.com>
Message-ID: <8328ac1c237f5d7cdadaab9f84f0746f@considine.net>

 

Hi Ilya, 

Thank you for the heads up on that. I'm thinking what I need to do is
pass the functions calculated moments, as seen here 


http://stackoverflow.com/questions/26745976/create-efficient-frontier-in-portfolioanalytics-without-an-xts-object


So I'll play with that. 

Regards, 

Matt 

On 2016-03-16 13:12, Ilya Kipnis wrote: 

> Matt,
> 
> PerformanceAnalytics has all the tools you need for those things. EG Return.annualized, and so on. 
> 
> -Ilya 
> 
> On Wed, Mar 16, 2016 at 2:06 PM, <matt at considine.net> wrote:
> 
>> Hi,
>> I have a sense I have overlooked something pretty basic here, but I'll risk asking an obvious question. I am trying to use PortfolioAnalytics as a complement to information provided by an investment consultant. They are presenting their efficient frontier results with annualized expected return data. I'm feeding PortfolioAnalytics monthly historical data, so the resulting chart/summary data is on a monthly basis (I believe).
>> 
>> Is there a flag for results to be presented on an annualized basis?
>> 
>> Thank in advance - and apologies for overlooking something clear. I did try to search the docs first :)
>> Regards,
>> Matt
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance [1]
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.

 

Links:
------
[1] https://stat.ethz.ch/mailman/listinfo/r-sig-finance

	[[alternative HTML version deleted]]


From brian at braverock.com  Wed Mar 16 20:43:58 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 16 Mar 2016 14:43:58 -0500
Subject: [R-SIG-Finance] PortfolioAnalytics question re: showing results
In-Reply-To: <715fde38520f15d3c03d41125cc58ca2@considine.net>
References: <715fde38520f15d3c03d41125cc58ca2@considine.net>
Message-ID: <1458157438.20553.12.camel@brian-rcg>

On Wed, 2016-03-16 at 13:06 -0500, matt at considine.net wrote:
> Hi,
> I have a sense I have overlooked something pretty basic here, but I'll 
> risk asking an obvious question.  I am trying to use PortfolioAnalytics 
> as a complement to information provided by an investment consultant.  
> They are presenting their efficient frontier results with annualized 
> expected return data.  I'm feeding PortfolioAnalytics monthly historical 
> data, so the resulting chart/summary data is on a monthly basis (I 
> believe).
> 
> Is there a flag for results to be presented on an annualized basis?
> 
> Thank in advance - and apologies for overlooking something clear.  I did 
> try to search the docs first :)

Matt, 

It's simple, but not as simple as a flag.

You need to add the annualized metrics to the portfolio specification
with a multiplier of 0.

Then you can plot your efficient frontier using all the standard
PortfolioAnalytics tools calling those metrics as axes of your plots.

Let me know if you need a fully worked out example, but I think there
are examples in some of the vignettes and presentations that do
something similar with annualized standard deviation.

Regards,

Brian


From rvince99 at gmail.com  Thu Mar 17 21:02:22 2016
From: rvince99 at gmail.com (R Vince)
Date: Thu, 17 Mar 2016 16:02:22 -0400
Subject: [R-SIG-Finance] Ubuntu Installation
Message-ID: <CAAHNhKW+EMNXK09ot+5z0jTng1Kdv4AZqXvzTOtKZCgOVPn3mg@mail.gmail.com>

I'm upgrading from one version of Ubiubta (14) to 17.

On 14, I had a directory structure as follows:

R/--i686-pc-linux-gnu-library

	[[alternative HTML version deleted]]


From rvince99 at gmail.com  Thu Mar 17 21:07:32 2016
From: rvince99 at gmail.com (R Vince)
Date: Thu, 17 Mar 2016 16:07:32 -0400
Subject: [R-SIG-Finance] Ubuntu Installation
In-Reply-To: <CAAHNhKW+EMNXK09ot+5z0jTng1Kdv4AZqXvzTOtKZCgOVPn3mg@mail.gmail.com>
References: <CAAHNhKW+EMNXK09ot+5z0jTng1Kdv4AZqXvzTOtKZCgOVPn3mg@mail.gmail.com>
Message-ID: <CAAHNhKXrCv6yHOz0K-KtaxQqLGVjk7qshDvUE9Zo28i5yXX-Fg@mail.gmail.com>

I'm upgrading from one version of Ubiubta (14) to 17.

On 14, I had a directory structure as follows:

/home/rvince/R/--i686-pc-linux-gnu-library
                         --Packages (which contains all my packages )
                          --Work (which contains all my scripts)


So when I invoke a commnd like:

R CMD BATCH /home/rvince/R/Work/ES50update.R R/Work/outfile.txt

it runs my script (ES50Update.R) properly.

I;ve moved the entire directory /home/rvince/R/ and all under it unto the
new Ubuntu install in my home directory again.

I've installed R-Base in Ububtu

When I invole the same command in the new Ubuntu install, my outfile.txt
shows the following. Clearly I've got something installed imporperly or
improperly configured:

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> require(quantmod)
Loading required package: quantmod
Warning message:
In library(package, lib.loc = lib.loc, character.only = TRUE,
logical.return = TRUE,  :
  there is no package called ?quantmod?
> library(plan)
Error in library(plan) : there is no package called ?plan?
Execution halted


Thanks for looking at this. Ralph Vince

On Thu, Mar 17, 2016 at 4:02 PM, R Vince <rvince99 at gmail.com> wrote:

> I'm upgrading from one version of Ubiubta (14) to 17.
>
> On 14, I had a directory structure as follows:
>
> R/--i686-pc-linux-gnu-library
>
>

	[[alternative HTML version deleted]]


From rvince99 at gmail.com  Thu Mar 17 21:19:10 2016
From: rvince99 at gmail.com (R Vince)
Date: Thu, 17 Mar 2016 16:19:10 -0400
Subject: [R-SIG-Finance] Ubuntu Installation
In-Reply-To: <CAAHNhKXrCv6yHOz0K-KtaxQqLGVjk7qshDvUE9Zo28i5yXX-Fg@mail.gmail.com>
References: <CAAHNhKW+EMNXK09ot+5z0jTng1Kdv4AZqXvzTOtKZCgOVPn3mg@mail.gmail.com>
	<CAAHNhKXrCv6yHOz0K-KtaxQqLGVjk7qshDvUE9Zo28i5yXX-Fg@mail.gmail.com>
Message-ID: <CAAHNhKVNf6EBD47N8JztEqA8qcuZ=GF8v2ebY-TsOCGqBiZM_A@mail.gmail.com>

My apologies to the group -- I understand this is for finance-related
questions only, not system ones. Sorry.

On Thu, Mar 17, 2016 at 4:07 PM, R Vince <rvince99 at gmail.com> wrote:

> I'm upgrading from one version of Ubiubta (14) to 17.
>
> On 14, I had a directory structure as follows:
>
> /home/rvince/R/--i686-pc-linux-gnu-library
>                          --Packages (which contains all my packages )
>                           --Work (which contains all my scripts)
>
>
> So when I invoke a commnd like:
>
> R CMD BATCH /home/rvince/R/Work/ES50update.R R/Work/outfile.txt
>
> it runs my script (ES50Update.R) properly.
>
> I;ve moved the entire directory /home/rvince/R/ and all under it unto the
> new Ubuntu install in my home directory again.
>
> I've installed R-Base in Ububtu
>
> When I invole the same command in the new Ubuntu install, my outfile.txt
> shows the following. Clearly I've got something installed imporperly or
> improperly configured:
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
> > require(quantmod)
> Loading required package: quantmod
> Warning message:
> In library(package, lib.loc = lib.loc, character.only = TRUE,
> logical.return = TRUE,  :
>   there is no package called ?quantmod?
> > library(plan)
> Error in library(plan) : there is no package called ?plan?
> Execution halted
>
>
> Thanks for looking at this. Ralph Vince
>
> On Thu, Mar 17, 2016 at 4:02 PM, R Vince <rvince99 at gmail.com> wrote:
>
>> I'm upgrading from one version of Ubiubta (14) to 17.
>>
>> On 14, I had a directory structure as follows:
>>
>> R/--i686-pc-linux-gnu-library
>>
>>
>

	[[alternative HTML version deleted]]


From edd at debian.org  Thu Mar 17 21:25:32 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 17 Mar 2016 15:25:32 -0500
Subject: [R-SIG-Finance] Ubuntu Installation
In-Reply-To: <CAAHNhKW+EMNXK09ot+5z0jTng1Kdv4AZqXvzTOtKZCgOVPn3mg@mail.gmail.com>
References: <CAAHNhKW+EMNXK09ot+5z0jTng1Kdv4AZqXvzTOtKZCgOVPn3mg@mail.gmail.com>
Message-ID: <22251.4796.892419.918069@max.nulle.part>


Ralph,

On 17 March 2016 at 16:02, R Vince wrote:
| I'm upgrading from one version of Ubiubta (14) to 17.
| 
| On 14, I had a directory structure as follows:
| 
| R/--i686-pc-linux-gnu-library

I religiously turn off R_LIBS_USER in /etc/R/Renviron to avoid that [1]. I
recommended to everybody who cares to listen to do the same.

If you do that, your path becomes

R> .libPaths()
[1] "/usr/local/lib/R/site-library" "/usr/lib/R/site-library"       "/usr/lib/R/library"           
R>

and all local installations go into the first of those three directories and
survive upgrades.

Hth, Dirk


[1] And for a while had this globally turned in the official Debian and hence
Ubuntu package but then the regexp broke.

| 
| 	[[alternative HTML version deleted]]
| 
| _______________________________________________
| R-SIG-Finance at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-sig-finance
| -- Subscriber-posting only. If you want to post, subscribe first.
| -- Also note that this is not the r-help list where general R questions should go.

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From matt at considine.net  Fri Mar 18 14:13:00 2016
From: matt at considine.net (matt at considine.net)
Date: Fri, 18 Mar 2016 08:13:00 -0500
Subject: [R-SIG-Finance] PortfolioAnalytics question re: showing results
Message-ID: <dc18c1892c57494a4f2f104f010ceb74@considine.net>

Hi Brian,

Thanks for the offer of some code.  I had wanted to try to figure this 
out for myself, but I'm not making the headway I thought.  IF you have 
some code or a worked example you can send, I'd be appreciative.

That said here is what I am working with.   Perhaps someone can suggest 
what I am doing wrong?

Goal : generate/plot an efficient frontier (with annualized axes) using 
PortfolioAnalytics, using monthly return data.  (Ideally, I'd also want 
to isolate the tangency/max Sharpe portfolio, a portfolio with max 
return at a specific risk level and a portfolio with a min risk at a 
specific return.  But I'll deal with that later.)

Code : I tried to use code from some of the presentations, demos 
(DEoptim and random portfolios, specifically) and vignettes.  Also, I'm 
using the latest version of the code from R-forge.

#-----------------------------
library(PortfolioAnalytics)

# Define pamean function
pamean1 <- function(R, weights, n=60, geometric=FALSE){
   as.vector(sum(Return.annualized(last(R,n), 
geometric=geometric)*weights))
}

# Define pasd function
pasd1 <- function(R, weights=NULL){
   as.numeric(StdDev(R=R, weights=weights)*sqrt(12)) # hardcoded for 
monthly data
}

data(edhec)

# Use the first 4 columns in edhec for a returns object
R <- edhec[, 1:4]
colnames(R) <- c("CA", "CTAG", "DS", "EM")
head(R, 5)

# Get a character vector of the fund names
funds <- colnames(R)

# Construct initial portfolio with basic constraints.
init.portf <- portfolio.spec(assets=funds)
init.portf <- add.constraint(portfolio=init.portf, 
type="full_investment")
init.portf <- add.constraint(portfolio=init.portf, type="box", min=0.0, 
max=1.0)

# Portfolio with standard deviation as an objective
#SD.portf <- add.objective(portfolio=init.portf, type="risk", 
name="pasd1") #pasd1 doesn't work?
#SD.portf <- add.objective(portfolio=SD.portf, type="return", 
name="mean") #pamean1 doesn't work?

#Ok, let's try this :
#Add measure 1, annualized return
SD.portf <- add.objective(portfolio=init.portf,
                             type="return", # the kind of objective this 
is
                             name="pamean1", # name of the function
                             enabled=TRUE, # enable or disable the 
objective
                             multiplier=0 # calculate it but don't use it 
in the objective
)

# Add measure 2, annualized standard deviation
SD.portf <- add.objective(portfolio=init.portf,
                             type="risk", # the kind of objective this is
                             name="pasd1", # to minimize from the sample
                             enabled=TRUE, # enable or disable the 
objective
                             multiplier=0 # calculate it but don't use it 
in the objective
)

#Create efficient frontier
init.portf.ef <- create.EfficientFrontier(R=R, portfolio=SD.portf, 
type="mean-StdDev")

#This chart never seems to show annualized axes
chart.EfficientFrontier(init.portf.ef, match.col="StdDev")

sd.moments <- set.portfolio.moments(R, SD.portf)
names(sd.moments) #returning NULL with pasd1/pamean1
print(sd.moments) #returning NULL with pasd1/pamean1

#Just a reality check to see what the axes ranges should roughly look 
like
ra <- Return.annualized(R[, , drop = FALSE], scale = 12, geometric = 
FALSE)
sda <- StdDev.annualized(R[, , drop = FALSE], scale = 12)
sra <- SharpeRatio.annualized(R[, , drop = FALSE], scale = 12, Rf = 
0.00, geometric = FALSE)

pamean1(R)
ra

pasd1(R)
sda
#----------------------------------
Regards,
Matt


From aschmid1 at stevens.edu  Fri Mar 18 14:56:49 2016
From: aschmid1 at stevens.edu (Alec Schmidt)
Date: Fri, 18 Mar 2016 13:56:49 +0000
Subject: [R-SIG-Finance] comparing solve.pq and nloptr for min variance
	portfolio
Message-ID: <1458309416883.39021@stevens.edu>

I'm puzzled that I cannot reproduce results for asset weights using solve.pq and nloptr even in the case of just three assets.  E.g. if I use NLOPT_LD_SLSQP and start with initial weights of 1/3, I may obtain (0.47, 0, 0.53) vs (0.52, 0, 0.47).  If I start with  (0.52, 0, 0.47), I do get  (0.52, 0, 0.47)...

When I use NLOPT_GN_ISRES or other nloptr solvers that permit equality constraint sum(weights)=1 with initial weights of 1/3, I obtain (almost) the same initial weights after 20000 iterations with xtol_rel=1.0e-8...

I remember from my MC simulations of protein structures (20 years ago) that sampling is key due to multiple local minimums  but is it so bad for a simple portfolio?


I'll greatly appreciate relevant comments.

Alec


	[[alternative HTML version deleted]]


From es at enricoschumann.net  Fri Mar 18 15:25:18 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Fri, 18 Mar 2016 15:25:18 +0100
Subject: [R-SIG-Finance] comparing solve.pq and nloptr for min variance
	portfolio
In-Reply-To: <1458309416883.39021@stevens.edu> (Alec Schmidt's message of
	"Fri, 18 Mar 2016 13:56:49 +0000")
References: <1458309416883.39021@stevens.edu>
Message-ID: <874mc3amnl.fsf@enricoschumann.net>

On Fri, 18 Mar 2016, Alec Schmidt <aschmid1 at stevens.edu> writes:

> I'm puzzled that I cannot reproduce results for asset weights using
> solve.pq and nloptr even in the case of just three assets.  E.g. if I
> use NLOPT_LD_SLSQP and start with initial weights of 1/3, I may obtain
> (0.47, 0, 0.53) vs (0.52, 0, 0.47).  If I start with (0.52, 0, 0.47),
> I do get (0.52, 0, 0.47)...
>
> When I use NLOPT_GN_ISRES or other nloptr solvers that permit equality
> constraint sum(weights)=1 with initial weights of 1/3, I obtain
> (almost) the same initial weights after 20000 iterations with
> xtol_rel=1.0e-8...
>
> I remember from my MC simulations of protein structures (20 years ago)
> that sampling is key due to multiple local minimums but is it so bad
> for a simple portfolio?
>
>
> I'll greatly appreciate relevant comments.
>
> Alec

[...]

Unless your covariance matrix is 'broken' in some way, a
minimum-variance portfolio with only a budget constraint should be
fairly easy to compute (no multiple local minima, smooth objective
function, ...). Please provide a reproducible example.

Kind regards,
        Enrico

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From aschmid1 at stevens.edu  Fri Mar 18 15:39:45 2016
From: aschmid1 at stevens.edu (Alec Schmidt)
Date: Fri, 18 Mar 2016 14:39:45 +0000
Subject: [R-SIG-Finance] comparing solve.pq and nloptr for min variance
 portfolio
In-Reply-To: <874mc3amnl.fsf@enricoschumann.net>
References: <1458309416883.39021@stevens.edu>,
	<874mc3amnl.fsf@enricoschumann.net>
Message-ID: <1458311992838.14954@stevens.edu>

Hi Enrico,
Many thanks for your interest. I attach my script and input file with asset tickers. Sorry for lots of unrelated stuff - it's a working draft.

Alec
________________________________________
From: Enrico Schumann <es at enricoschumann.net>
Sent: Friday, March 18, 2016 10:25 AM
To: Alec Schmidt
Cc: R-SIG-Finance at r-project.org
Subject: Re: [R-SIG-Finance] comparing solve.pq and nloptr for min variance portfolio

On Fri, 18 Mar 2016, Alec Schmidt <aschmid1 at stevens.edu> writes:

> I'm puzzled that I cannot reproduce results for asset weights using
> solve.pq and nloptr even in the case of just three assets.  E.g. if I
> use NLOPT_LD_SLSQP and start with initial weights of 1/3, I may obtain
> (0.47, 0, 0.53) vs (0.52, 0, 0.47).  If I start with (0.52, 0, 0.47),
> I do get (0.52, 0, 0.47)...
>
> When I use NLOPT_GN_ISRES or other nloptr solvers that permit equality
> constraint sum(weights)=1 with initial weights of 1/3, I obtain
> (almost) the same initial weights after 20000 iterations with
> xtol_rel=1.0e-8...
>
> I remember from my MC simulations of protein structures (20 years ago)
> that sampling is key due to multiple local minimums but is it so bad
> for a simple portfolio?
>
>
> I'll greatly appreciate relevant comments.
>
> Alec

[...]

Unless your covariance matrix is 'broken' in some way, a
minimum-variance portfolio with only a budget constraint should be
fairly easy to compute (no multiple local minima, smooth objective
function, ...). Please provide a reproducible example.

Kind regards,
        Enrico

--
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net
-------------- next part --------------
A non-text attachment was scrubbed...
Name: divers_portfolio3.r
Type: application/octet-stream
Size: 4730 bytes
Desc: divers_portfolio3.r
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20160318/c89afb42/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: SPYETF3.csv
Type: application/vnd.ms-excel
Size: 75 bytes
Desc: SPYETF3.csv
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20160318/c89afb42/attachment.xlb>

From es at enricoschumann.net  Fri Mar 18 16:08:16 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Fri, 18 Mar 2016 16:08:16 +0100
Subject: [R-SIG-Finance] comparing solve.pq and nloptr for min variance
	portfolio
In-Reply-To: <1458311992838.14954@stevens.edu> (Alec Schmidt's message of
	"Fri, 18 Mar 2016 14:39:45 +0000")
References: <1458309416883.39021@stevens.edu>
	<874mc3amnl.fsf@enricoschumann.net> <1458311992838.14954@stevens.edu>
Message-ID: <87vb4j963j.fsf@enricoschumann.net>

On Fri, 18 Mar 2016, Alec Schmidt <aschmid1 at stevens.edu> writes:

> Hi Enrico,
> Many thanks for your interest. I attach my script and input file with
> asset tickers. Sorry for lots of unrelated stuff - it's a working
> draft.
>
> Alec

Thanks for sending the script, Alec. But you will need to
simplify it if people are to help you. [My bad: I should have
said _minimal_ reproducible example:
https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
]



> ________________________________________
> From: Enrico Schumann <es at enricoschumann.net>
> Sent: Friday, March 18, 2016 10:25 AM
> To: Alec Schmidt
> Cc: R-SIG-Finance at r-project.org
> Subject: Re: [R-SIG-Finance] comparing solve.pq and nloptr for min variance portfolio
>
> On Fri, 18 Mar 2016, Alec Schmidt <aschmid1 at stevens.edu> writes:
>
>> I'm puzzled that I cannot reproduce results for asset weights using
>> solve.pq and nloptr even in the case of just three assets.  E.g. if I
>> use NLOPT_LD_SLSQP and start with initial weights of 1/3, I may obtain
>> (0.47, 0, 0.53) vs (0.52, 0, 0.47).  If I start with (0.52, 0, 0.47),
>> I do get (0.52, 0, 0.47)...
>>
>> When I use NLOPT_GN_ISRES or other nloptr solvers that permit equality
>> constraint sum(weights)=1 with initial weights of 1/3, I obtain
>> (almost) the same initial weights after 20000 iterations with
>> xtol_rel=1.0e-8...
>>
>> I remember from my MC simulations of protein structures (20 years ago)
>> that sampling is key due to multiple local minimums but is it so bad
>> for a simple portfolio?
>>
>>
>> I'll greatly appreciate relevant comments.
>>
>> Alec
>
> [...]
>
> Unless your covariance matrix is 'broken' in some way, a
> minimum-variance portfolio with only a budget constraint should be
> fairly easy to compute (no multiple local minima, smooth objective
> function, ...). Please provide a reproducible example.
>
> Kind regards,
>         Enrico

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From aschmid1 at stevens.edu  Fri Mar 18 16:32:10 2016
From: aschmid1 at stevens.edu (Alec Schmidt)
Date: Fri, 18 Mar 2016 15:32:10 +0000
Subject: [R-SIG-Finance] comparing solve.pq and nloptr for min variance
 portfolio
In-Reply-To: <87vb4j963j.fsf@enricoschumann.net>
References: <1458309416883.39021@stevens.edu>
	<874mc3amnl.fsf@enricoschumann.net>
	<1458311992838.14954@stevens.edu>,<87vb4j963j.fsf@enricoschumann.net>
Message-ID: <1458315137518.8340@stevens.edu>

Enrico,
Here we're. I attach two scripts: one for solve.pq, another for nloptr. Both run with the same input file and print output on the screen.

Thanks again, Alec
________________________________________
From: Enrico Schumann <es at enricoschumann.net>
Sent: Friday, March 18, 2016 11:08 AM
To: Alec Schmidt
Cc: R-SIG-Finance at r-project.org
Subject: Re: [R-SIG-Finance] comparing solve.pq and nloptr for min variance portfolio

On Fri, 18 Mar 2016, Alec Schmidt <aschmid1 at stevens.edu> writes:

> Hi Enrico,
> Many thanks for your interest. I attach my script and input file with
> asset tickers. Sorry for lots of unrelated stuff - it's a working
> draft.
>
> Alec

Thanks for sending the script, Alec. But you will need to
simplify it if people are to help you. [My bad: I should have
said _minimal_ reproducible example:
https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
]



> ________________________________________
> From: Enrico Schumann <es at enricoschumann.net>
> Sent: Friday, March 18, 2016 10:25 AM
> To: Alec Schmidt
> Cc: R-SIG-Finance at r-project.org
> Subject: Re: [R-SIG-Finance] comparing solve.pq and nloptr for min variance portfolio
>
> On Fri, 18 Mar 2016, Alec Schmidt <aschmid1 at stevens.edu> writes:
>
>> I'm puzzled that I cannot reproduce results for asset weights using
>> solve.pq and nloptr even in the case of just three assets.  E.g. if I
>> use NLOPT_LD_SLSQP and start with initial weights of 1/3, I may obtain
>> (0.47, 0, 0.53) vs (0.52, 0, 0.47).  If I start with (0.52, 0, 0.47),
>> I do get (0.52, 0, 0.47)...
>>
>> When I use NLOPT_GN_ISRES or other nloptr solvers that permit equality
>> constraint sum(weights)=1 with initial weights of 1/3, I obtain
>> (almost) the same initial weights after 20000 iterations with
>> xtol_rel=1.0e-8...
>>
>> I remember from my MC simulations of protein structures (20 years ago)
>> that sampling is key due to multiple local minimums but is it so bad
>> for a simple portfolio?
>>
>>
>> I'll greatly appreciate relevant comments.
>>
>> Alec
>
> [...]
>
> Unless your covariance matrix is 'broken' in some way, a
> minimum-variance portfolio with only a budget constraint should be
> fairly easy to compute (no multiple local minima, smooth objective
> function, ...). Please provide a reproducible example.
>
> Kind regards,
>         Enrico

--
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net
-------------- next part --------------
A non-text attachment was scrubbed...
Name: solve.pq_portfolio.R
Type: application/octet-stream
Size: 3193 bytes
Desc: solve.pq_portfolio.R
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20160318/11bac887/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: nloptr_portfolio.R
Type: application/octet-stream
Size: 2934 bytes
Desc: nloptr_portfolio.R
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20160318/11bac887/attachment-0001.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: SPYETF3.csv
Type: application/vnd.ms-excel
Size: 75 bytes
Desc: SPYETF3.csv
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20160318/11bac887/attachment.xlb>

From rossbennett34 at gmail.com  Fri Mar 18 16:54:17 2016
From: rossbennett34 at gmail.com (Ross Bennett)
Date: Fri, 18 Mar 2016 10:54:17 -0500
Subject: [R-SIG-Finance] PortfolioAnalytics question re: showing results
In-Reply-To: <dc18c1892c57494a4f2f104f010ceb74@considine.net>
References: <dc18c1892c57494a4f2f104f010ceb74@considine.net>
Message-ID: <CAEESW=UR43bRy4f7wmbJsnsHDEtiV=tJWhpfWW0n6K3a+ZnR6A@mail.gmail.com>

Hi Matt,

You are very close in your script. Note that create.EfficientFrontier with
type="mean-StdDev" is a special case for an efficient frontier that can be
formulated and solved with a QP solver.

Also note that your second call to add.objective should add to the SD.portf
portfolio and not init.portf
# Add measure 2, annualized standard deviation
# note that you want to add this to the SD.portf portfolio, not init.portf
SD.portf <- add.objective(portfolio=SD.portf,
                            type="risk", # the kind of objective this is
                            name="pasd1", # to minimize from the sample
                            enabled=TRUE, # enable or disable the objective
                            multiplier=0 # calculate it but don't use it in
the objective
)

I recommend actually running an optimization using random portfolios so you
get the entire feasible space given the constraints and objectives in your
portfolio.

rp <- random_portfolios(SD.portf, 5000)
# make sure to run with trace=TRUE for the extract stats output
opt <- optimize.portfolio(R, SD.portf, optimize_method="random", trace=TRUE)
chart.RiskReward(opt, risk.col="pasd1.pasd1", return.col="pamean1.pamean1")

# use the output of extractStats to find portfolio with max return at a
given
# risk level and portfolio with min risk at a given return level
ex <- extractStats(opt)
head(ex)

# This should get you started
# order by max pamean1
head(ex[order(ex[,"pamean1.pamean1"], decreasing=TRUE),])

# order by min pasd1
head(ex[order(ex[,"pasd1.pasd1"], decreasing=FALSE),])

Hope this helps, let me know if you need any other pointers.

Regards,
Ross

On Fri, Mar 18, 2016 at 8:13 AM, <matt at considine.net> wrote:

> Hi Brian,
>
> Thanks for the offer of some code.  I had wanted to try to figure this out
> for myself, but I'm not making the headway I thought.  IF you have some
> code or a worked example you can send, I'd be appreciative.
>
> That said here is what I am working with.   Perhaps someone can suggest
> what I am doing wrong?
>
> Goal : generate/plot an efficient frontier (with annualized axes) using
> PortfolioAnalytics, using monthly return data.  (Ideally, I'd also want to
> isolate the tangency/max Sharpe portfolio, a portfolio with max return at a
> specific risk level and a portfolio with a min risk at a specific return.
> But I'll deal with that later.)
>
> Code : I tried to use code from some of the presentations, demos (DEoptim
> and random portfolios, specifically) and vignettes.  Also, I'm using the
> latest version of the code from R-forge.
>
> #-----------------------------
> library(PortfolioAnalytics)
>
> # Define pamean function
> pamean1 <- function(R, weights, n=60, geometric=FALSE){
>   as.vector(sum(Return.annualized(last(R,n), geometric=geometric)*weights))
> }
>
> # Define pasd function
> pasd1 <- function(R, weights=NULL){
>   as.numeric(StdDev(R=R, weights=weights)*sqrt(12)) # hardcoded for
> monthly data
> }
>
> data(edhec)
>
> # Use the first 4 columns in edhec for a returns object
> R <- edhec[, 1:4]
> colnames(R) <- c("CA", "CTAG", "DS", "EM")
> head(R, 5)
>
> # Get a character vector of the fund names
> funds <- colnames(R)
>
> # Construct initial portfolio with basic constraints.
> init.portf <- portfolio.spec(assets=funds)
> init.portf <- add.constraint(portfolio=init.portf, type="full_investment")
> init.portf <- add.constraint(portfolio=init.portf, type="box", min=0.0,
> max=1.0)
>
> # Portfolio with standard deviation as an objective
> #SD.portf <- add.objective(portfolio=init.portf, type="risk",
> name="pasd1") #pasd1 doesn't work?
> #SD.portf <- add.objective(portfolio=SD.portf, type="return", name="mean")
> #pamean1 doesn't work?
>
> #Ok, let's try this :
> #Add measure 1, annualized return
> SD.portf <- add.objective(portfolio=init.portf,
>                             type="return", # the kind of objective this is
>                             name="pamean1", # name of the function
>                             enabled=TRUE, # enable or disable the objective
>                             multiplier=0 # calculate it but don't use it
> in the objective
> )
>
> # Add measure 2, annualized standard deviation
> SD.portf <- add.objective(portfolio=init.portf,
>                             type="risk", # the kind of objective this is
>                             name="pasd1", # to minimize from the sample
>                             enabled=TRUE, # enable or disable the objective
>                             multiplier=0 # calculate it but don't use it
> in the objective
> )
>
> #Create efficient frontier
> init.portf.ef <- create.EfficientFrontier(R=R, portfolio=SD.portf,
> type="mean-StdDev")
>
> #This chart never seems to show annualized axes
> chart.EfficientFrontier(init.portf.ef, match.col="StdDev")
>
> sd.moments <- set.portfolio.moments(R, SD.portf)
> names(sd.moments) #returning NULL with pasd1/pamean1
> print(sd.moments) #returning NULL with pasd1/pamean1
>
> #Just a reality check to see what the axes ranges should roughly look like
> ra <- Return.annualized(R[, , drop = FALSE], scale = 12, geometric = FALSE)
> sda <- StdDev.annualized(R[, , drop = FALSE], scale = 12)
> sra <- SharpeRatio.annualized(R[, , drop = FALSE], scale = 12, Rf = 0.00,
> geometric = FALSE)
>
> pamean1(R)
> ra
>
> pasd1(R)
> sda
> #----------------------------------
> Regards,
> Matt
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From matt at considine.net  Fri Mar 18 20:37:32 2016
From: matt at considine.net (matt at considine.net)
Date: Fri, 18 Mar 2016 14:37:32 -0500
Subject: [R-SIG-Finance] PortfolioAnalytics question re: showing results
In-Reply-To: <CAEESW=UR43bRy4f7wmbJsnsHDEtiV=tJWhpfWW0n6K3a+ZnR6A@mail.gmail.com>
References: <dc18c1892c57494a4f2f104f010ceb74@considine.net>
	<CAEESW=UR43bRy4f7wmbJsnsHDEtiV=tJWhpfWW0n6K3a+ZnR6A@mail.gmail.com>
Message-ID: <d8bfc9e0f203d6a7201beed03af7974e@considine.net>

 

Hi Ross, 

Thanks - that helps alot. It looks like part of what was tripping me up
is that the guts of the create/chart EfficientFrontier functions expect
hard-coded column headings. I.e. that those routines as written aren't
flexible enough to deal with the custom optimizing functions. Is that
correct or is there a more flexible set of those that I have overlooked?
The presentation graphs the create are quite clean. 

In any case, thank you for the example and feedback. 

Matt 

On 2016-03-18 10:54, Ross Bennett wrote: 

> Hi Matt,
> 
> You are very close in your script. Note that create.EfficientFrontier with type="mean-StdDev" is a special case for an efficient frontier that can be formulated and solved with a QP solver. 
> 
> Also note that your second call to add.objective should add to the SD.portf portfolio and not init.portf
> # Add measure 2, annualized standard deviation
> # note that you want to add this to the SD.portf portfolio, not init.portf
> SD.portf <- add.objective(portfolio=SD.portf,
> type="risk", # the kind of objective this is
> name="pasd1", # to minimize from the sample
> enabled=TRUE, # enable or disable the objective
> multiplier=0 # calculate it but don't use it in the objective
> )
> 
> I recommend actually running an optimization using random portfolios so you get the entire feasible space given the constraints and objectives in your portfolio. 
> 
> rp <- random_portfolios(SD.portf, 5000)
> # make sure to run with trace=TRUE for the extract stats output
> opt <- optimize.portfolio(R, SD.portf, optimize_method="random", trace=TRUE) 
> chart.RiskReward(opt, risk.col="pasd1.pasd1", return.col="pamean1.pamean1")
> 
> # use the output of extractStats to find portfolio with max return at a given 
> # risk level and portfolio with min risk at a given return level
> ex <- extractStats(opt)
> head(ex)
> 
> # This should get you started
> # order by max pamean1
> head(ex[order(ex[,"pamean1.pamean1"], decreasing=TRUE),])
> 
> # order by min pasd1
> head(ex[order(ex[,"pasd1.pasd1"], decreasing=FALSE),])
> 
> Hope this helps, let me know if you need any other pointers. 
> 
> Regards, 
> Ross 
> 
> On Fri, Mar 18, 2016 at 8:13 AM, <matt at considine.net> wrote:
> 
>> Hi Brian,
>> 
>> Thanks for the offer of some code. I had wanted to try to figure this out for myself, but I'm not making the headway I thought. IF you have some code or a worked example you can send, I'd be appreciative.
>> 
>> That said here is what I am working with. Perhaps someone can suggest what I am doing wrong?
>> 
>> Goal : generate/plot an efficient frontier (with annualized axes) using PortfolioAnalytics, using monthly return data. (Ideally, I'd also want to isolate the tangency/max Sharpe portfolio, a portfolio with max return at a specific risk level and a portfolio with a min risk at a specific return. But I'll deal with that later.)
>> 
>> Code : I tried to use code from some of the presentations, demos (DEoptim and random portfolios, specifically) and vignettes. Also, I'm using the latest version of the code from R-forge.
>> 
>> #-----------------------------
>> library(PortfolioAnalytics)
>> 
>> # Define pamean function
>> pamean1 <- function(R, weights, n=60, geometric=FALSE){
>> as.vector(sum(Return.annualized(last(R,n), geometric=geometric)*weights))
>> }
>> 
>> # Define pasd function
>> pasd1 <- function(R, weights=NULL){
>> as.numeric(StdDev(R=R, weights=weights)*sqrt(12)) # hardcoded for monthly data
>> }
>> 
>> data(edhec)
>> 
>> # Use the first 4 columns in edhec for a returns object
>> R <- edhec[, 1:4]
>> colnames(R) <- c("CA", "CTAG", "DS", "EM")
>> head(R, 5)
>> 
>> # Get a character vector of the fund names
>> funds <- colnames(R)
>> 
>> # Construct initial portfolio with basic constraints.
>> init.portf <- portfolio.spec(assets=funds)
>> init.portf <- add.constraint(portfolio=init.portf, type="full_investment")
>> init.portf <- add.constraint(portfolio=init.portf, type="box", min=0.0, max=1.0)
>> 
>> # Portfolio with standard deviation as an objective
>> #SD.portf <- add.objective(portfolio=init.portf, type="risk", name="pasd1") #pasd1 doesn't work?
>> #SD.portf <- add.objective(portfolio=SD.portf, type="return", name="mean") #pamean1 doesn't work?
>> 
>> #Ok, let's try this :
>> #Add measure 1, annualized return
>> SD.portf <- add.objective(portfolio=init.portf,
>> type="return", # the kind of objective this is
>> name="pamean1", # name of the function
>> enabled=TRUE, # enable or disable the objective
>> multiplier=0 # calculate it but don't use it in the objective
>> )
>> 
>> # Add measure 2, annualized standard deviation
>> SD.portf <- add.objective(portfolio=init.portf,
>> type="risk", # the kind of objective this is
>> name="pasd1", # to minimize from the sample
>> enabled=TRUE, # enable or disable the objective
>> multiplier=0 # calculate it but don't use it in the objective
>> )
>> 
>> #Create efficient frontier
>> init.portf.ef <- create.EfficientFrontier(R=R, portfolio=SD.portf, type="mean-StdDev")
>> 
>> #This chart never seems to show annualized axes
>> chart.EfficientFrontier(init.portf.ef, match.col="StdDev")
>> 
>> sd.moments <- set.portfolio.moments(R, SD.portf)
>> names(sd.moments) #returning NULL with pasd1/pamean1
>> print(sd.moments) #returning NULL with pasd1/pamean1
>> 
>> #Just a reality check to see what the axes ranges should roughly look like
>> ra <- Return.annualized(R[, , drop = FALSE], scale = 12, geometric = FALSE)
>> sda <- StdDev.annualized(R[, , drop = FALSE], scale = 12)
>> sra <- SharpeRatio.annualized(R[, , drop = FALSE], scale = 12, Rf = 0.00, geometric = FALSE)
>> 
>> pamean1(R)
>> ra
>> 
>> pasd1(R)
>> sda
>> #----------------------------------
>> Regards,
>> Matt 
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance [1]
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.

 

Links:
------
[1] https://stat.ethz.ch/mailman/listinfo/r-sig-finance

	[[alternative HTML version deleted]]


From rossbennett34 at gmail.com  Fri Mar 18 21:17:31 2016
From: rossbennett34 at gmail.com (Ross Bennett)
Date: Fri, 18 Mar 2016 15:17:31 -0500
Subject: [R-SIG-Finance] PortfolioAnalytics question re: showing results
In-Reply-To: <d8bfc9e0f203d6a7201beed03af7974e@considine.net>
References: <dc18c1892c57494a4f2f104f010ceb74@considine.net>
	<CAEESW=UR43bRy4f7wmbJsnsHDEtiV=tJWhpfWW0n6K3a+ZnR6A@mail.gmail.com>
	<d8bfc9e0f203d6a7201beed03af7974e@considine.net>
Message-ID: <CAEESW=Wn+x0=we=Me_ex54=HK32mYXGdfE8ww4A_K+xZ0PrLsg@mail.gmail.com>

Matt,

I'm glad it was helpful. That is correct, the *.EfficientFrontier routines
are not flexible in some cases. create.EfficientFrontier can create an
efficient.frontier object with custom objective/moment functions by
specifying type="random" or type="DEoptim". Under the hood, it is just
running an optimization and handing back the data needed for the chart. In
most cases, it is better to run the optimization with trace=TRUE so that
you have all the data you need for creating charts and doing other analysis.

Ross

On Fri, Mar 18, 2016 at 2:37 PM, <matt at considine.net> wrote:

> Hi Ross,
>
> Thanks - that helps alot.  It looks like part of what was tripping me up
> is that the guts of the create/chart EfficientFrontier functions expect
> hard-coded column headings.  I.e. that those routines as written aren't
> flexible enough to deal with the custom optimizing functions.  Is that
> correct or is there a more flexible set of those that I have overlooked?
> The presentation graphs the create are quite clean.
>
> In any case, thank you for the example and feedback.
>
> Matt
>
> On 2016-03-18 10:54, Ross Bennett wrote:
>
> Hi Matt,
>
> You are very close in your script. Note that create.EfficientFrontier with
> type="mean-StdDev" is a special case for an efficient frontier that can be
> formulated and solved with a QP solver.
>
> Also note that your second call to add.objective should add to the
> SD.portf portfolio and not init.portf
> # Add measure 2, annualized standard deviation
> # note that you want to add this to the SD.portf portfolio, not init.portf
> SD.portf <- add.objective(portfolio=SD.portf,
>                             type="risk", # the kind of objective this is
>                             name="pasd1", # to minimize from the sample
>                             enabled=TRUE, # enable or disable the objective
>                             multiplier=0 # calculate it but don't use it
> in the objective
> )
>
> I recommend actually running an optimization using random portfolios so
> you get the entire feasible space given the constraints and objectives in
> your portfolio.
>
> rp <- random_portfolios(SD.portf, 5000)
> # make sure to run with trace=TRUE for the extract stats output
> opt <- optimize.portfolio(R, SD.portf, optimize_method="random",
> trace=TRUE)
> chart.RiskReward(opt, risk.col="pasd1.pasd1", return.col="pamean1.pamean1")
>
> # use the output of extractStats to find portfolio with max return at a
> given
> # risk level and portfolio with min risk at a given return level
> ex <- extractStats(opt)
> head(ex)
>
> # This should get you started
> # order by max pamean1
> head(ex[order(ex[,"pamean1.pamean1"], decreasing=TRUE),])
>
> # order by min pasd1
> head(ex[order(ex[,"pasd1.pasd1"], decreasing=FALSE),])
>
> Hope this helps, let me know if you need any other pointers.
>
> Regards,
> Ross
>
> On Fri, Mar 18, 2016 at 8:13 AM, <matt at considine.net> wrote:
>
>> Hi Brian,
>>
>> Thanks for the offer of some code.  I had wanted to try to figure this
>> out for myself, but I'm not making the headway I thought.  IF you have some
>> code or a worked example you can send, I'd be appreciative.
>>
>> That said here is what I am working with.   Perhaps someone can suggest
>> what I am doing wrong?
>>
>> Goal : generate/plot an efficient frontier (with annualized axes) using
>> PortfolioAnalytics, using monthly return data.  (Ideally, I'd also want to
>> isolate the tangency/max Sharpe portfolio, a portfolio with max return at a
>> specific risk level and a portfolio with a min risk at a specific return.
>> But I'll deal with that later.)
>>
>> Code : I tried to use code from some of the presentations, demos (DEoptim
>> and random portfolios, specifically) and vignettes.  Also, I'm using the
>> latest version of the code from R-forge.
>>
>> #-----------------------------
>> library(PortfolioAnalytics)
>>
>> # Define pamean function
>> pamean1 <- function(R, weights, n=60, geometric=FALSE){
>>   as.vector(sum(Return.annualized(last(R,n),
>> geometric=geometric)*weights))
>> }
>>
>> # Define pasd function
>> pasd1 <- function(R, weights=NULL){
>>   as.numeric(StdDev(R=R, weights=weights)*sqrt(12)) # hardcoded for
>> monthly data
>> }
>>
>> data(edhec)
>>
>> # Use the first 4 columns in edhec for a returns object
>> R <- edhec[, 1:4]
>> colnames(R) <- c("CA", "CTAG", "DS", "EM")
>> head(R, 5)
>>
>> # Get a character vector of the fund names
>> funds <- colnames(R)
>>
>> # Construct initial portfolio with basic constraints.
>> init.portf <- portfolio.spec(assets=funds)
>> init.portf <- add.constraint(portfolio=init.portf, type="full_investment")
>> init.portf <- add.constraint(portfolio=init.portf, type="box", min=0.0,
>> max=1.0)
>>
>> # Portfolio with standard deviation as an objective
>> #SD.portf <- add.objective(portfolio=init.portf, type="risk",
>> name="pasd1") #pasd1 doesn't work?
>> #SD.portf <- add.objective(portfolio=SD.portf, type="return",
>> name="mean") #pamean1 doesn't work?
>>
>> #Ok, let's try this :
>> #Add measure 1, annualized return
>> SD.portf <- add.objective(portfolio=init.portf,
>>                             type="return", # the kind of objective this is
>>                             name="pamean1", # name of the function
>>                             enabled=TRUE, # enable or disable the
>> objective
>>                             multiplier=0 # calculate it but don't use it
>> in the objective
>> )
>>
>> # Add measure 2, annualized standard deviation
>> SD.portf <- add.objective(portfolio=init.portf,
>>                             type="risk", # the kind of objective this is
>>                             name="pasd1", # to minimize from the sample
>>                             enabled=TRUE, # enable or disable the
>> objective
>>                             multiplier=0 # calculate it but don't use it
>> in the objective
>> )
>>
>> #Create efficient frontier
>> init.portf.ef <- create.EfficientFrontier(R=R, portfolio=SD.portf,
>> type="mean-StdDev")
>>
>> #This chart never seems to show annualized axes
>> chart.EfficientFrontier(init.portf.ef, match.col="StdDev")
>>
>> sd.moments <- set.portfolio.moments(R, SD.portf)
>> names(sd.moments) #returning NULL with pasd1/pamean1
>> print(sd.moments) #returning NULL with pasd1/pamean1
>>
>> #Just a reality check to see what the axes ranges should roughly look like
>> ra <- Return.annualized(R[, , drop = FALSE], scale = 12, geometric =
>> FALSE)
>> sda <- StdDev.annualized(R[, , drop = FALSE], scale = 12)
>> sra <- SharpeRatio.annualized(R[, , drop = FALSE], scale = 12, Rf = 0.00,
>> geometric = FALSE)
>>
>> pamean1(R)
>> ra
>>
>> pasd1(R)
>> sda
>> #----------------------------------
>> Regards,
>> Matt
>>
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>
>

	[[alternative HTML version deleted]]


From brian at braverock.com  Fri Mar 18 22:07:44 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 18 Mar 2016 16:07:44 -0500
Subject: [R-SIG-Finance] PortfolioAnalytics question re: showing results
In-Reply-To: <d8bfc9e0f203d6a7201beed03af7974e@considine.net>
References: <dc18c1892c57494a4f2f104f010ceb74@considine.net>
	<CAEESW=UR43bRy4f7wmbJsnsHDEtiV=tJWhpfWW0n6K3a+ZnR6A@mail.gmail.com>
	<d8bfc9e0f203d6a7201beed03af7974e@considine.net>
Message-ID: <1458335264.29692.1.camel@brian-rcg>

create.EfficientFrontier should be able to create an efficient frontier
with arbitrary return/risk columns to compare.

chart.EfficientFrontier has a hardcoded 'mean' and a flexible x axis
column.  It should be pretty straightforward to allow it to use
arbitrary columns as well.

Regards,

Brian


On Fri, 2016-03-18 at 14:37 -0500, matt at considine.net wrote:
>  
> Hi Ross, 
> 
> Thanks - that helps alot. It looks like part of what was tripping me up
> is that the guts of the create/chart EfficientFrontier functions expect
> hard-coded column headings. I.e. that those routines as written aren't
> flexible enough to deal with the custom optimizing functions. Is that
> correct or is there a more flexible set of those that I have overlooked?
> The presentation graphs the create are quite clean. 
> 
> In any case, thank you for the example and feedback. 
> 
> Matt 
> 
> On 2016-03-18 10:54, Ross Bennett wrote: 
> 
> > Hi Matt,
> > 
> > You are very close in your script. Note that create.EfficientFrontier with type="mean-StdDev" is a special case for an efficient frontier that can be formulated and solved with a QP solver. 
> > 
> > Also note that your second call to add.objective should add to the SD.portf portfolio and not init.portf
> > # Add measure 2, annualized standard deviation
> > # note that you want to add this to the SD.portf portfolio, not init.portf
> > SD.portf <- add.objective(portfolio=SD.portf,
> > type="risk", # the kind of objective this is
> > name="pasd1", # to minimize from the sample
> > enabled=TRUE, # enable or disable the objective
> > multiplier=0 # calculate it but don't use it in the objective
> > )
> > 
> > I recommend actually running an optimization using random portfolios so you get the entire feasible space given the constraints and objectives in your portfolio. 
> > 
> > rp <- random_portfolios(SD.portf, 5000)
> > # make sure to run with trace=TRUE for the extract stats output
> > opt <- optimize.portfolio(R, SD.portf, optimize_method="random", trace=TRUE) 
> > chart.RiskReward(opt, risk.col="pasd1.pasd1", return.col="pamean1.pamean1")
> > 
> > # use the output of extractStats to find portfolio with max return at a given 
> > # risk level and portfolio with min risk at a given return level
> > ex <- extractStats(opt)
> > head(ex)
> > 
> > # This should get you started
> > # order by max pamean1
> > head(ex[order(ex[,"pamean1.pamean1"], decreasing=TRUE),])
> > 
> > # order by min pasd1
> > head(ex[order(ex[,"pasd1.pasd1"], decreasing=FALSE),])
> > 
> > Hope this helps, let me know if you need any other pointers. 
> > 
> > Regards, 
> > Ross 
> > 
> > On Fri, Mar 18, 2016 at 8:13 AM, <matt at considine.net> wrote:
> > 
> >> Hi Brian,
> >> 
> >> Thanks for the offer of some code. I had wanted to try to figure this out for myself, but I'm not making the headway I thought. IF you have some code or a worked example you can send, I'd be appreciative.
> >> 
> >> That said here is what I am working with. Perhaps someone can suggest what I am doing wrong?
> >> 
> >> Goal : generate/plot an efficient frontier (with annualized axes) using PortfolioAnalytics, using monthly return data. (Ideally, I'd also want to isolate the tangency/max Sharpe portfolio, a portfolio with max return at a specific risk level and a portfolio with a min risk at a specific return. But I'll deal with that later.)
> >> 
> >> Code : I tried to use code from some of the presentations, demos (DEoptim and random portfolios, specifically) and vignettes. Also, I'm using the latest version of the code from R-forge.
> >> 
> >> #-----------------------------
> >> library(PortfolioAnalytics)
> >> 
> >> # Define pamean function
> >> pamean1 <- function(R, weights, n=60, geometric=FALSE){
> >> as.vector(sum(Return.annualized(last(R,n), geometric=geometric)*weights))
> >> }
> >> 
> >> # Define pasd function
> >> pasd1 <- function(R, weights=NULL){
> >> as.numeric(StdDev(R=R, weights=weights)*sqrt(12)) # hardcoded for monthly data
> >> }
> >> 
> >> data(edhec)
> >> 
> >> # Use the first 4 columns in edhec for a returns object
> >> R <- edhec[, 1:4]
> >> colnames(R) <- c("CA", "CTAG", "DS", "EM")
> >> head(R, 5)
> >> 
> >> # Get a character vector of the fund names
> >> funds <- colnames(R)
> >> 
> >> # Construct initial portfolio with basic constraints.
> >> init.portf <- portfolio.spec(assets=funds)
> >> init.portf <- add.constraint(portfolio=init.portf, type="full_investment")
> >> init.portf <- add.constraint(portfolio=init.portf, type="box", min=0.0, max=1.0)
> >> 
> >> # Portfolio with standard deviation as an objective
> >> #SD.portf <- add.objective(portfolio=init.portf, type="risk", name="pasd1") #pasd1 doesn't work?
> >> #SD.portf <- add.objective(portfolio=SD.portf, type="return", name="mean") #pamean1 doesn't work?
> >> 
> >> #Ok, let's try this :
> >> #Add measure 1, annualized return
> >> SD.portf <- add.objective(portfolio=init.portf,
> >> type="return", # the kind of objective this is
> >> name="pamean1", # name of the function
> >> enabled=TRUE, # enable or disable the objective
> >> multiplier=0 # calculate it but don't use it in the objective
> >> )
> >> 
> >> # Add measure 2, annualized standard deviation
> >> SD.portf <- add.objective(portfolio=init.portf,
> >> type="risk", # the kind of objective this is
> >> name="pasd1", # to minimize from the sample
> >> enabled=TRUE, # enable or disable the objective
> >> multiplier=0 # calculate it but don't use it in the objective
> >> )
> >> 
> >> #Create efficient frontier
> >> init.portf.ef <- create.EfficientFrontier(R=R, portfolio=SD.portf, type="mean-StdDev")
> >> 
> >> #This chart never seems to show annualized axes
> >> chart.EfficientFrontier(init.portf.ef, match.col="StdDev")
> >> 
> >> sd.moments <- set.portfolio.moments(R, SD.portf)
> >> names(sd.moments) #returning NULL with pasd1/pamean1
> >> print(sd.moments) #returning NULL with pasd1/pamean1
> >> 
> >> #Just a reality check to see what the axes ranges should roughly look like
> >> ra <- Return.annualized(R[, , drop = FALSE], scale = 12, geometric = FALSE)
> >> sda <- StdDev.annualized(R[, , drop = FALSE], scale = 12)
> >> sra <- SharpeRatio.annualized(R[, , drop = FALSE], scale = 12, Rf = 0.00, geometric = FALSE)
> >> 
> >> pamean1(R)
> >> ra
> >> 
> >> pasd1(R)
> >> sda
> >> #----------------------------------
> >> Regards,
> >> Matt 
> >> 
> >> _______________________________________________
> >> R-SIG-Finance at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance [1]
> >> -- Subscriber-posting only. If you want to post, subscribe first.
> >> -- Also note that this is not the r-help list where general R questions should go.
> 
>  
> 
> Links:
> ------
> [1] https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From es at enricoschumann.net  Sat Mar 19 21:14:11 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Sat, 19 Mar 2016 21:14:11 +0100
Subject: [R-SIG-Finance] comparing solve.pq and nloptr for min variance
	portfolio
In-Reply-To: <1458315137518.8340@stevens.edu> (Alec Schmidt's message of "Fri, 
	18 Mar 2016 15:32:10 +0000")
References: <1458309416883.39021@stevens.edu>
	<874mc3amnl.fsf@enricoschumann.net> <1458311992838.14954@stevens.edu>
	<87vb4j963j.fsf@enricoschumann.net> <1458315137518.8340@stevens.edu>
Message-ID: <87y49e5ip8.fsf@enricoschumann.net>

On Fri, 18 Mar 2016, Alec Schmidt <aschmid1 at stevens.edu> writes:

> Enrico,
> Here we're. I attach two scripts: one for solve.pq, another for
> nloptr. Both run with the same input file and print output on the
> screen.
>
> Thanks again, Alec

Hi Alec,

but these are still long programmes, which makes it hard to
figure out what exactly is wrong. For a start, I would not
compute the whole frontier, but concentrate on one point.

I computed the minimum-variance portfolio (without short
sales) with an alternative method, and it matches your
output for 'solve.QP'. So, one thing to check is your
implementation of the objective function for 'nloptr'.

Kind regards (and good luck)
     Enrico


> ________________________________________
> From: Enrico Schumann <es at enricoschumann.net>
> Sent: Friday, March 18, 2016 11:08 AM
> To: Alec Schmidt
> Cc: R-SIG-Finance at r-project.org
> Subject: Re: [R-SIG-Finance] comparing solve.pq and nloptr for min variance portfolio
>
> On Fri, 18 Mar 2016, Alec Schmidt <aschmid1 at stevens.edu> writes:
>
>> Hi Enrico,
>> Many thanks for your interest. I attach my script and input file with
>> asset tickers. Sorry for lots of unrelated stuff - it's a working
>> draft.
>>
>> Alec
>
> Thanks for sending the script, Alec. But you will need to
> simplify it if people are to help you. [My bad: I should have
> said _minimal_ reproducible example:
> https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ]
>
>
>
>> ________________________________________
>> From: Enrico Schumann <es at enricoschumann.net>
>> Sent: Friday, March 18, 2016 10:25 AM
>> To: Alec Schmidt
>> Cc: R-SIG-Finance at r-project.org
>> Subject: Re: [R-SIG-Finance] comparing solve.pq and nloptr for min variance portfolio
>>
>> On Fri, 18 Mar 2016, Alec Schmidt <aschmid1 at stevens.edu> writes:
>>
>>> I'm puzzled that I cannot reproduce results for asset weights using
>>> solve.pq and nloptr even in the case of just three assets.  E.g. if I
>>> use NLOPT_LD_SLSQP and start with initial weights of 1/3, I may obtain
>>> (0.47, 0, 0.53) vs (0.52, 0, 0.47).  If I start with (0.52, 0, 0.47),
>>> I do get (0.52, 0, 0.47)...
>>>
>>> When I use NLOPT_GN_ISRES or other nloptr solvers that permit equality
>>> constraint sum(weights)=1 with initial weights of 1/3, I obtain
>>> (almost) the same initial weights after 20000 iterations with
>>> xtol_rel=1.0e-8...
>>>
>>> I remember from my MC simulations of protein structures (20 years ago)
>>> that sampling is key due to multiple local minimums but is it so bad
>>> for a simple portfolio?
>>>
>>>
>>> I'll greatly appreciate relevant comments.
>>>
>>> Alec
>>
>> [...]
>>
>> Unless your covariance matrix is 'broken' in some way, a
>> minimum-variance portfolio with only a budget constraint should be
>> fairly easy to compute (no multiple local minima, smooth objective
>> function, ...). Please provide a reproducible example.
>>
>> Kind regards,
>>         Enrico

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From matt at considine.net  Mon Mar 21 13:42:46 2016
From: matt at considine.net (matt at considine.net)
Date: Mon, 21 Mar 2016 07:42:46 -0500
Subject: [R-SIG-Finance] PortfolioAnalytics question re: showing results
In-Reply-To: <d8bfc9e0f203d6a7201beed03af7974e@considine.net>
References: <dc18c1892c57494a4f2f104f010ceb74@considine.net>
	<CAEESW=UR43bRy4f7wmbJsnsHDEtiV=tJWhpfWW0n6K3a+ZnR6A@mail.gmail.com>
	<d8bfc9e0f203d6a7201beed03af7974e@considine.net>
Message-ID: <f6a341cba23a5f298f2f727b5414f647@considine.net>

 

Hi again, 

In running the chart.RiskReward code, the "Optimal" portfolio is being
plotted in the middle of the feasible portfolio set. Why would that be
happening? Or is it because I am using customized risk/return calcs and
the corresponding values for the optimal portfolio are not being scaled?


I tried to get at the underlying plotting code, but the View function
returns "uses method chart.RiskReward". Is there an easy way to see and
edit that underlying code? Apologies if the answer to this is incredibly
straightforward, but the answer will also help me create versions of the
*.EfficientFrontier functions to use with customized risk/return
functions 

Thanks, 

Matt 

On 2016-03-18 14:37, matt at considine.net wrote: 

> Hi Ross, 
> 
> Thanks - that helps alot. It looks like part of what was tripping me up is that the guts of the create/chart EfficientFrontier functions expect hard-coded column headings. I.e. that those routines as written aren't flexible enough to deal with the custom optimizing functions. Is that correct or is there a more flexible set of those that I have overlooked? The presentation graphs the create are quite clean. 
> 
> In any case, thank you for the example and feedback. 
> 
> Matt 
> 
> On 2016-03-18 10:54, Ross Bennett wrote: 
> 
> Hi Matt,
> 
> You are very close in your script. Note that create.EfficientFrontier with type="mean-StdDev" is a special case for an efficient frontier that can be formulated and solved with a QP solver. 
> 
> Also note that your second call to add.objective should add to the SD.portf portfolio and not init.portf
> # Add measure 2, annualized standard deviation
> # note that you want to add this to the SD.portf portfolio, not init.portf
> SD.portf <- add.objective(portfolio=SD.portf,
> type="risk", # the kind of objective this is
> name="pasd1", # to minimize from the sample
> enabled=TRUE, # enable or disable the objective
> multiplier=0 # calculate it but don't use it in the objective
> )
> 
> I recommend actually running an optimization using random portfolios so you get the entire feasible space given the constraints and objectives in your portfolio. 
> 
> rp <- random_portfolios(SD.portf, 5000)
> # make sure to run with trace=TRUE for the extract stats output
> opt <- optimize.portfolio(R, SD.portf, optimize_method="random", trace=TRUE) 
> chart.RiskReward(opt, risk.col="pasd1.pasd1", return.col="pamean1.pamean1")
> 
> # use the output of extractStats to find portfolio with max return at a given 
> # risk level and portfolio with min risk at a given return level
> ex <- extractStats(opt)
> head(ex)
> 
> # This should get you started
> # order by max pamean1
> head(ex[order(ex[,"pamean1.pamean1"], decreasing=TRUE),])
> 
> # order by min pasd1
> head(ex[order(ex[,"pasd1.pasd1"], decreasing=FALSE),])
> 
> Hope this helps, let me know if you need any other pointers. 
> 
> Regards, 
> Ross 
> 
> On Fri, Mar 18, 2016 at 8:13 AM, <matt at considine.net> wrote:
> Hi Brian,
> 
> Thanks for the offer of some code. I had wanted to try to figure this out for myself, but I'm not making the headway I thought. IF you have some code or a worked example you can send, I'd be appreciative.
> 
> That said here is what I am working with. Perhaps someone can suggest what I am doing wrong?
> 
> Goal : generate/plot an efficient frontier (with annualized axes) using PortfolioAnalytics, using monthly return data. (Ideally, I'd also want to isolate the tangency/max Sharpe portfolio, a portfolio with max return at a specific risk level and a portfolio with a min risk at a specific return. But I'll deal with that later.)
> 
> Code : I tried to use code from some of the presentations, demos (DEoptim and random portfolios, specifically) and vignettes. Also, I'm using the latest version of the code from R-forge.
> 
> #-----------------------------
> library(PortfolioAnalytics)
> 
> # Define pamean function
> pamean1 <- function(R, weights, n=60, geometric=FALSE){
> as.vector(sum(Return.annualized(last(R,n), geometric=geometric)*weights))
> }
> 
> # Define pasd function
> pasd1 <- function(R, weights=NULL){
> as.numeric(StdDev(R=R, weights=weights)*sqrt(12)) # hardcoded for monthly data
> }
> 
> data(edhec)
> 
> # Use the first 4 columns in edhec for a returns object
> R <- edhec[, 1:4]
> colnames(R) <- c("CA", "CTAG", "DS", "EM")
> head(R, 5)
> 
> # Get a character vector of the fund names
> funds <- colnames(R)
> 
> # Construct initial portfolio with basic constraints.
> init.portf <- portfolio.spec(assets=funds)
> init.portf <- add.constraint(portfolio=init.portf, type="full_investment")
> init.portf <- add.constraint(portfolio=init.portf, type="box", min=0.0, max=1.0)
> 
> # Portfolio with standard deviation as an objective
> #SD.portf <- add.objective(portfolio=init.portf, type="risk", name="pasd1") #pasd1 doesn't work?
> #SD.portf <- add.objective(portfolio=SD.portf, type="return", name="mean") #pamean1 doesn't work?
> 
> #Ok, let's try this :
> #Add measure 1, annualized return
> SD.portf <- add.objective(portfolio=init.portf,
> type="return", # the kind of objective this is
> name="pamean1", # name of the function
> enabled=TRUE, # enable or disable the objective
> multiplier=0 # calculate it but don't use it in the objective
> )
> 
> # Add measure 2, annualized standard deviation
> SD.portf <- add.objective(portfolio=init.portf,
> type="risk", # the kind of objective this is
> name="pasd1", # to minimize from the sample
> enabled=TRUE, # enable or disable the objective
> multiplier=0 # calculate it but don't use it in the objective
> )
> 
> #Create efficient frontier
> init.portf.ef <- create.EfficientFrontier(R=R, portfolio=SD.portf, type="mean-StdDev")
> 
> #This chart never seems to show annualized axes
> chart.EfficientFrontier(init.portf.ef, match.col="StdDev")
> 
> sd.moments <- set.portfolio.moments(R, SD.portf)
> names(sd.moments) #returning NULL with pasd1/pamean1
> print(sd.moments) #returning NULL with pasd1/pamean1
> 
> #Just a reality check to see what the axes ranges should roughly look like
> ra <- Return.annualized(R[, , drop = FALSE], scale = 12, geometric = FALSE)
> sda <- StdDev.annualized(R[, , drop = FALSE], scale = 12)
> sra <- SharpeRatio.annualized(R[, , drop = FALSE], scale = 12, Rf = 0.00, geometric = FALSE)
> 
> pamean1(R)
> ra
> 
> pasd1(R)
> sda
> #----------------------------------
> Regards,
> Matt 
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance [1]
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

 

Links:
------
[1] https://stat.ethz.ch/mailman/listinfo/r-sig-finance

	[[alternative HTML version deleted]]


From brian at braverock.com  Mon Mar 21 14:31:52 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 21 Mar 2016 08:31:52 -0500
Subject: [R-SIG-Finance] PortfolioAnalytics question re: showing results
In-Reply-To: <f6a341cba23a5f298f2f727b5414f647@considine.net>
References: <dc18c1892c57494a4f2f104f010ceb74@considine.net>
	<CAEESW=UR43bRy4f7wmbJsnsHDEtiV=tJWhpfWW0n6K3a+ZnR6A@mail.gmail.com>
	<d8bfc9e0f203d6a7201beed03af7974e@considine.net>
	<f6a341cba23a5f298f2f727b5414f647@considine.net>
Message-ID: <1458567112.29692.20.camel@brian-rcg>

On Mon, 2016-03-21 at 07:42 -0500, matt at considine.net wrote:
> In running the chart.RiskReward code, the "Optimal" portfolio is being
> plotted in the middle of the feasible portfolio set. Why would that be
> happening? Or is it because I am using customized risk/return calcs
> and the corresponding values for the optimal portfolio are not being
> scaled?
> 
If the optimal portfolio was calculated with the objectives that agree
with your axes, it should be on the outer hull of the feasible space.

If, however, the optimal portfolio was calculated with different
objectives or constraints, then it may indeed be inside the overall
feasible space.

The addition or constraints or additional objectives will shrink the
feasible space.  This is why comparing the efficient frontiers of
portfolios built with different objectives and constraints will alway
sweep out a smaller area for the more constrained portfolios.  It is
also why if you plot a mean-ES objective against a mean-var set of axes
that your optimal portfolio may show up inside the feasible cloud.

> I tried to get at the underlying plotting code, but the View function
> returns "uses method chart.RiskReward". Is there an easy way to see
> and edit that underlying code? Apologies if the answer to this is
> incredibly straightforward, but the answer will also help me create
> versions of the
> *.EfficientFrontier functions to use with customized risk/return
> functions 


The changes to do what you want to do may be rather simple.

chart.EfficientFrontier should be modified to take a risk.col and a
return.col argument.  The same should happen to the
extractEfficientFrontier function and its methods.  Most of the
underlying code lives in a non-exported function called
extract.efficient.frontier 

All of these functions live in file extract.efficient.frontier.R 

It would be simplest to work from the original source file from svn,
since that is commented.  the code you look at from inside R will have
the comments stripped out.

If you don't make any progress on this, it is now on our list to improve
based on your questions, but I don't know when we'll get to it.

Regards,

Brian. 

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From rossbennett34 at gmail.com  Mon Mar 21 14:51:49 2016
From: rossbennett34 at gmail.com (Ross Bennett)
Date: Mon, 21 Mar 2016 08:51:49 -0500
Subject: [R-SIG-Finance] PortfolioAnalytics question re: showing results
In-Reply-To: <f6a341cba23a5f298f2f727b5414f647@considine.net>
References: <dc18c1892c57494a4f2f104f010ceb74@considine.net>
	<CAEESW=UR43bRy4f7wmbJsnsHDEtiV=tJWhpfWW0n6K3a+ZnR6A@mail.gmail.com>
	<d8bfc9e0f203d6a7201beed03af7974e@considine.net>
	<f6a341cba23a5f298f2f727b5414f647@considine.net>
Message-ID: <CAEESW=VYMFuCt6eMsC0OD5=o9zp_mz7B8EMpSKuZykSB6Yf+Tg@mail.gmail.com>

On Mon, Mar 21, 2016 at 7:42 AM, <matt at considine.net> wrote:

> Hi again,
>
> In running the chart.RiskReward code, the "Optimal" portfolio is being
> plotted in the middle of the feasible portfolio set.  Why would that be
> happening?  Or is it because I am using customized risk/return calcs and
> the corresponding values for the optimal portfolio are not being scaled?
>
In general, the optimal portfolio is the portfolio with the minimum
objective function value. In this specific case, the objective functions in
the portfolio you defined have multipler=0 so the objective value for every
portfolio is 0 (note: this is the "out" column in the output of
extractStats). The first row in the extractStats output is the equal weight
portfolio which is being interpreted as the optimal portfolio since it has
a value of 0 for 'out'.

Ross

	[[alternative HTML version deleted]]


From ksabol at dsaco.com  Mon Mar 21 19:33:10 2016
From: ksabol at dsaco.com (Keith Sabol)
Date: Mon, 21 Mar 2016 18:33:10 +0000
Subject: [R-SIG-Finance] Rblpapi - Fundamental Data
Message-ID: <537FBDB80913A3439703E0CF2DCDECFEA6BD20@BOXWOOD.davis.local>

Hi,

In the old Rbbg package one can use relative dates expressed, for example,  as "-4FY" to obtain the last four fiscal years of information.  Is it possible to do something similar in Rblpapi or will it be necessary to do some date math around the last report date to get to the same place?

Thanks in advance.


Keith Sabol

	[[alternative HTML version deleted]]


From armstrong.whit at gmail.com  Mon Mar 21 19:50:17 2016
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Mon, 21 Mar 2016 14:50:17 -0400
Subject: [R-SIG-Finance] Rblpapi - Fundamental Data
In-Reply-To: <537FBDB80913A3439703E0CF2DCDECFEA6BD20@BOXWOOD.davis.local>
References: <537FBDB80913A3439703E0CF2DCDECFEA6BD20@BOXWOOD.davis.local>
Message-ID: <CAMi=pg4GAoCT_gbJW7ACkrTReo+HDgD8DKruswf1wwxx245yyw@mail.gmail.com>

Why don't you give it a try and let us know whether it works.

-Whit


On Mon, Mar 21, 2016 at 2:33 PM, Keith Sabol <ksabol at dsaco.com> wrote:

> Hi,
>
> In the old Rbbg package one can use relative dates expressed, for
> example,  as "-4FY" to obtain the last four fiscal years of information.
> Is it possible to do something similar in Rblpapi or will it be necessary
> to do some date math around the last report date to get to the same place?
>
> Thanks in advance.
>
>
> Keith Sabol
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From diegoperoni at vodafone.it  Tue Mar 22 09:37:26 2016
From: diegoperoni at vodafone.it (Diego Peroni)
Date: Tue, 22 Mar 2016 09:37:26 +0100
Subject: [R-SIG-Finance] need apply.paramset logging
Message-ID: <56F10446.3090601@vodafone.it>

Hi all,

I'm testing paramset combinations with:

.....
library(doMC)
registerDoMC(cores=detectCores())
paramsetenv = new.env()
results = apply.paramset(qs.strategy, paramset.label = "MACDOPT", 
verbose = TRUE,
                          portfolio=qs.strategy, account=qs.strategy, 
nsamples=0, audit=paramsetenv)

but the procedure returns NULL object with this message:

error calling combine function:
<simpleError: $ operator is invalid for atomic vectors>

Is there a way to log threads errors?

Or how can I modify "apply.paramset" function to "catch" single 
simultation error or void result and discard it?


Thanks in advance

Diego


	[[alternative HTML version deleted]]


From brian at braverock.com  Tue Mar 22 09:46:16 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 22 Mar 2016 03:46:16 -0500
Subject: [R-SIG-Finance] need apply.paramset logging
In-Reply-To: <56F10446.3090601@vodafone.it>
References: <56F10446.3090601@vodafone.it>
Message-ID: <56F10658.9000302@braverock.com>

On 03/22/2016 03:37 AM, Diego Peroni wrote:
> I'm testing paramset combinations with:
>
> .....
> library(doMC)
> registerDoMC(cores=detectCores())
> paramsetenv = new.env()
> results = apply.paramset(qs.strategy, paramset.label = "MACDOPT",
> verbose = TRUE,
>                            portfolio=qs.strategy, account=qs.strategy,
> nsamples=0, audit=paramsetenv)
>
> but the procedure returns NULL object with this message:
>
> error calling combine function:
> <simpleError: $ operator is invalid for atomic vectors>
>
> Is there a way to log threads errors?
>
> Or how can I modify "apply.paramset" function to "catch" single
> simultation error or void result and discard it?

you're setting

nsamples=0

so you have zero results to combine.

In this case, you told it to run no samples, but I can conceive of a 
strategy using some MCMC sampler that could fail spontaneously in some 
circumstances.

In a more general sense, you could specify a custom .combine function 
that could trap errors if there was some possibility that your strategy 
would fail to return a viable result.

A strategy that runs fine in a single core should run fine in 
apply.paramset.  A reasonable way to start testing this beyond a single 
parameterization would be to set a small number of samples, like 
nsamples=50 and run it with registerDoSEQ() to run it sequentially.

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From johannes.lips at gmail.com  Tue Mar 22 10:14:19 2016
From: johannes.lips at gmail.com (Johannes Lips)
Date: Tue, 22 Mar 2016 10:14:19 +0100
Subject: [R-SIG-Finance] Time-Varying Cointegration in R
Message-ID: <56F10CEB.2020107@gmail.com>

Dear list,

I've implemented the time-varying cointegration framework by Bierens and 
Martins (2010) in R [1], based on the gauss implementation of Luis 
Martins [2]. I do get the same results as in gauss, when using lower 
chebyshev dimensions, but when the number of dimensions is increasing, I 
run into issues with complex eigenvalues and eigenvectors.
Additionally the eigenvalues and eigenvectors differ quite a bit between 
gauss and R and I do not really know how to find out why that is. I also 
experimented with different implementations of eigenvalues 
determination, based on the C++ routine eigen, but was not able to 
replicate the gauss results exactly.
One notable difference is that gauss does not normalize the 
eigenvectors, but even after considering this a discrepancy remains. 
Perhaps someone with a better knowledge of gauss may shed some light on 
possible sources for these differences.



[1] https://github.com/hannes101/TimeVaryingCointegration
[2] http://home.iscte-iul.pt/~lfsm/

	[[alternative HTML version deleted]]


From diegoperoni at vodafone.it  Tue Mar 22 15:45:19 2016
From: diegoperoni at vodafone.it (Diego Peroni)
Date: Tue, 22 Mar 2016 15:45:19 +0100
Subject: [R-SIG-Finance] need apply.paramset logging
In-Reply-To: <56F10658.9000302@braverock.com>
References: <56F10446.3090601@vodafone.it> <56F10658.9000302@braverock.com>
Message-ID: <56F15A7F.3070908@vodafone.it>

Brain thanks for your answers!

My strategy take a long time to run because it is "minute" based and 
runs over 6 years.

I've just 100 combinations so it is not the best to reduce nsamples to 
find errors.

If I reduce time range (2 o 3 years) it doesn't fail.

If I run sequentially it take a very long time.

The best solution remains the last you have indicated: "custom .combine 
function that could trap errors".
Does exist some documentation or example to read?

Regards

Diego Peroni




On 22/03/2016 09:46, Brian G. Peterson wrote:
> On 03/22/2016 03:37 AM, Diego Peroni wrote:
>> I'm testing paramset combinations with:
>>
>> .....
>> library(doMC)
>> registerDoMC(cores=detectCores())
>> paramsetenv = new.env()
>> results = apply.paramset(qs.strategy, paramset.label = "MACDOPT",
>> verbose = TRUE,
>>                            portfolio=qs.strategy, account=qs.strategy,
>> nsamples=0, audit=paramsetenv)
>>
>> but the procedure returns NULL object with this message:
>>
>> error calling combine function:
>> <simpleError: $ operator is invalid for atomic vectors>
>>
>> Is there a way to log threads errors?
>>
>> Or how can I modify "apply.paramset" function to "catch" single
>> simultation error or void result and discard it?
>
> you're setting
>
> nsamples=0
>
> so you have zero results to combine.
>
> In this case, you told it to run no samples, but I can conceive of a 
> strategy using some MCMC sampler that could fail spontaneously in some 
> circumstances.
>
> In a more general sense, you could specify a custom .combine function 
> that could trap errors if there was some possibility that your 
> strategy would fail to return a viable result.
>
> A strategy that runs fine in a single core should run fine in 
> apply.paramset.  A reasonable way to start testing this beyond a 
> single parameterization would be to set a small number of samples, 
> like nsamples=50 and run it with registerDoSEQ() to run it sequentially.
>
> Regards,
>
> Brian
>


From brian at braverock.com  Tue Mar 22 16:03:16 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 22 Mar 2016 10:03:16 -0500
Subject: [R-SIG-Finance] need apply.paramset logging
In-Reply-To: <56F15A7F.3070908@vodafone.it>
References: <56F10446.3090601@vodafone.it> <56F10658.9000302@braverock.com>
	<56F15A7F.3070908@vodafone.it>
Message-ID: <1458658996.29692.43.camel@brian-rcg>

Executing on minute data won't drive the speed of the path-dependent
rules loop, the total number of signals which need to be evaluated will,
or the inclusion of things like trailing stops.

You should be able to sort out which parameter combination is failing
from the print statements.  you should also be able to look at the audit
environment to see which portfolio you're expecting is missing.

Ultimately, this is a problem in your strategy specification...  You've
created an infeasible parameter combination.  You likely want to debug
what, specifically, is failing, rather than just skipping the failing
parameter set.

If you're determined to work with the combine funtion...

The .combine argument for foreach is described in the documentation for
foreach.  See ?foreach. 

The combine function in apply.paramset is inside the apply.paramset
function.  We could probably check for a user-supplied combine, or you
could modify the combine function inside apply.paramset yourself.



On Tue, 2016-03-22 at 15:45 +0100, Diego Peroni wrote:
> Brain thanks for your answers!
> 
> My strategy take a long time to run because it is "minute" based and 
> runs over 6 years.
> 
> I've just 100 combinations so it is not the best to reduce nsamples to 
> find errors.
> 
> If I reduce time range (2 o 3 years) it doesn't fail.
> 
> If I run sequentially it take a very long time.
> 
> The best solution remains the last you have indicated: "custom .combine 
> function that could trap errors".
> Does exist some documentation or example to read?
> 
> Regards
> 
> Diego Peroni
> 
> 
> 
> 
> On 22/03/2016 09:46, Brian G. Peterson wrote:
> > On 03/22/2016 03:37 AM, Diego Peroni wrote:
> >> I'm testing paramset combinations with:
> >>
> >> .....
> >> library(doMC)
> >> registerDoMC(cores=detectCores())
> >> paramsetenv = new.env()
> >> results = apply.paramset(qs.strategy, paramset.label = "MACDOPT",
> >> verbose = TRUE,
> >>                            portfolio=qs.strategy, account=qs.strategy,
> >> nsamples=0, audit=paramsetenv)
> >>
> >> but the procedure returns NULL object with this message:
> >>
> >> error calling combine function:
> >> <simpleError: $ operator is invalid for atomic vectors>
> >>
> >> Is there a way to log threads errors?
> >>
> >> Or how can I modify "apply.paramset" function to "catch" single
> >> simultation error or void result and discard it?
> >
> > you're setting
> >
> > nsamples=0
> >
> > so you have zero results to combine.
> >
> > In this case, you told it to run no samples, but I can conceive of a 
> > strategy using some MCMC sampler that could fail spontaneously in some 
> > circumstances.
> >
> > In a more general sense, you could specify a custom .combine function 
> > that could trap errors if there was some possibility that your 
> > strategy would fail to return a viable result.
> >
> > A strategy that runs fine in a single core should run fine in 
> > apply.paramset.  A reasonable way to start testing this beyond a 
> > single parameterization would be to set a small number of samples, 
> > like nsamples=50 and run it with registerDoSEQ() to run it sequentially.
> >
> > Regards,
> >
> > Brian
> >
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From diegoperoni at vodafone.it  Tue Mar 22 16:21:31 2016
From: diegoperoni at vodafone.it (Diego Peroni)
Date: Tue, 22 Mar 2016 16:21:31 +0100
Subject: [R-SIG-Finance] need apply.paramset logging
In-Reply-To: <1458658996.29692.43.camel@brian-rcg>
References: <56F10446.3090601@vodafone.it> <56F10658.9000302@braverock.com>
	<56F15A7F.3070908@vodafone.it> <1458658996.29692.43.camel@brian-rcg>
Message-ID: <56F162FB.8010709@vodafone.it>



On 22/03/2016 16:03, Brian G. Peterson wrote:
> Executing on minute data won't drive the speed of the path-dependent
> rules loop, the total number of signals which need to be evaluated will,
> or the inclusion of things like trailing stops.
Trailing Stops is my case :-)
>
> You should be able to sort out which parameter combination is failing
> from the print statements.  you should also be able to look at the audit
> environment to see which portfolio you're expecting is missing.
During multicore execution I'm enable to see print out.
I'm sure there is a way to redirect each thread print out to a file but 
I don't know how.
>
> Ultimately, this is a problem in your strategy specification...  You've
> created an infeasible parameter combination.  You likely want to debug
> what, specifically, is failing, rather than just skipping the failing
> parameter set.
>
> If you're determined to work with the combine funtion...
Sure :)
>
> The .combine argument for foreach is described in the documentation for
> foreach.  See ?foreach.
>
> The combine function in apply.paramset is inside the apply.paramset
> function.  We could probably check for a user-supplied combine, or you
> could modify the combine function inside apply.paramset yourself.
Thanks a lot, I take a look


Regards

Diego


>
>
>
> On Tue, 2016-03-22 at 15:45 +0100, Diego Peroni wrote:
>> Brain thanks for your answers!
>>
>> My strategy take a long time to run because it is "minute" based and
>> runs over 6 years.
>>
>> I've just 100 combinations so it is not the best to reduce nsamples to
>> find errors.
>>
>> If I reduce time range (2 o 3 years) it doesn't fail.
>>
>> If I run sequentially it take a very long time.
>>
>> The best solution remains the last you have indicated: "custom .combine
>> function that could trap errors".
>> Does exist some documentation or example to read?
>>
>> Regards
>>
>> Diego Peroni
>>
>>
>>
>>
>> On 22/03/2016 09:46, Brian G. Peterson wrote:
>>> On 03/22/2016 03:37 AM, Diego Peroni wrote:
>>>> I'm testing paramset combinations with:
>>>>
>>>> .....
>>>> library(doMC)
>>>> registerDoMC(cores=detectCores())
>>>> paramsetenv = new.env()
>>>> results = apply.paramset(qs.strategy, paramset.label = "MACDOPT",
>>>> verbose = TRUE,
>>>>                             portfolio=qs.strategy, account=qs.strategy,
>>>> nsamples=0, audit=paramsetenv)
>>>>
>>>> but the procedure returns NULL object with this message:
>>>>
>>>> error calling combine function:
>>>> <simpleError: $ operator is invalid for atomic vectors>
>>>>
>>>> Is there a way to log threads errors?
>>>>
>>>> Or how can I modify "apply.paramset" function to "catch" single
>>>> simultation error or void result and discard it?
>>> you're setting
>>>
>>> nsamples=0
>>>
>>> so you have zero results to combine.
>>>
>>> In this case, you told it to run no samples, but I can conceive of a
>>> strategy using some MCMC sampler that could fail spontaneously in some
>>> circumstances.
>>>
>>> In a more general sense, you could specify a custom .combine function
>>> that could trap errors if there was some possibility that your
>>> strategy would fail to return a viable result.
>>>
>>> A strategy that runs fine in a single core should run fine in
>>> apply.paramset.  A reasonable way to start testing this beyond a
>>> single parameterization would be to set a small number of samples,
>>> like nsamples=50 and run it with registerDoSEQ() to run it sequentially.
>>>
>>> Regards,
>>>
>>> Brian
>>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.


From josh.m.ulrich at gmail.com  Tue Mar 22 18:22:37 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 22 Mar 2016 12:22:37 -0500
Subject: [R-SIG-Finance] need apply.paramset logging
In-Reply-To: <56F162FB.8010709@vodafone.it>
References: <56F10446.3090601@vodafone.it> <56F10658.9000302@braverock.com>
	<56F15A7F.3070908@vodafone.it> <1458658996.29692.43.camel@brian-rcg>
	<56F162FB.8010709@vodafone.it>
Message-ID: <CAPPM_gStyeYBYGf2XagxBL28+zrdPk42Cxcp-6tT24C5r5tQYw@mail.gmail.com>

On Tue, Mar 22, 2016 at 10:21 AM, Diego Peroni <diegoperoni at vodafone.it> wrote:
>
>
> On 22/03/2016 16:03, Brian G. Peterson wrote:
>>
>> Executing on minute data won't drive the speed of the path-dependent
>> rules loop, the total number of signals which need to be evaluated will,
>> or the inclusion of things like trailing stops.
>
> Trailing Stops is my case :-)
>>
>>
>> You should be able to sort out which parameter combination is failing
>> from the print statements.  you should also be able to look at the audit
>> environment to see which portfolio you're expecting is missing.
>
> During multicore execution I'm enable to see print out.
> I'm sure there is a way to redirect each thread print out to a file but I
> don't know how.

doMC runs in separate processes, not threads.  You could add some code
to print the process ID before each message, or write to a file named
with the process ID.
> Sys.getpid()
[1] 29236
> registerDoMC(2)
> foreach(1:6) %dopar% { Sys.getpid() }
[[1]]
[1] 29345

[[2]]
[1] 29346

[[3]]
[1] 29345

[[4]]
[1] 29346

[[5]]
[1] 29345

[[6]]
[1] 29346

>>
>>
>> Ultimately, this is a problem in your strategy specification...  You've
>> created an infeasible parameter combination.  You likely want to debug
>> what, specifically, is failing, rather than just skipping the failing
>> parameter set.
>>
>> If you're determined to work with the combine funtion...
>
> Sure :)
>>
>>
>> The .combine argument for foreach is described in the documentation for
>> foreach.  See ?foreach.
>>
>> The combine function in apply.paramset is inside the apply.paramset
>> function.  We could probably check for a user-supplied combine, or you
>> could modify the combine function inside apply.paramset yourself.
>
> Thanks a lot, I take a look
>
>
> Regards
>
> Diego
>
>
>
>>
>>
>>
>> On Tue, 2016-03-22 at 15:45 +0100, Diego Peroni wrote:
>>>
>>> Brain thanks for your answers!
>>>
>>> My strategy take a long time to run because it is "minute" based and
>>> runs over 6 years.
>>>
>>> I've just 100 combinations so it is not the best to reduce nsamples to
>>> find errors.
>>>
>>> If I reduce time range (2 o 3 years) it doesn't fail.
>>>
>>> If I run sequentially it take a very long time.
>>>
>>> The best solution remains the last you have indicated: "custom .combine
>>> function that could trap errors".
>>> Does exist some documentation or example to read?
>>>
>>> Regards
>>>
>>> Diego Peroni
>>>
>>>
>>>
>>>
>>> On 22/03/2016 09:46, Brian G. Peterson wrote:
>>>>
>>>> On 03/22/2016 03:37 AM, Diego Peroni wrote:
>>>>>
>>>>> I'm testing paramset combinations with:
>>>>>
>>>>> .....
>>>>> library(doMC)
>>>>> registerDoMC(cores=detectCores())
>>>>> paramsetenv = new.env()
>>>>> results = apply.paramset(qs.strategy, paramset.label = "MACDOPT",
>>>>> verbose = TRUE,
>>>>>                             portfolio=qs.strategy, account=qs.strategy,
>>>>> nsamples=0, audit=paramsetenv)
>>>>>
>>>>> but the procedure returns NULL object with this message:
>>>>>
>>>>> error calling combine function:
>>>>> <simpleError: $ operator is invalid for atomic vectors>
>>>>>
>>>>> Is there a way to log threads errors?
>>>>>
>>>>> Or how can I modify "apply.paramset" function to "catch" single
>>>>> simultation error or void result and discard it?
>>>>
>>>> you're setting
>>>>
>>>> nsamples=0
>>>>
>>>> so you have zero results to combine.
>>>>
>>>> In this case, you told it to run no samples, but I can conceive of a
>>>> strategy using some MCMC sampler that could fail spontaneously in some
>>>> circumstances.
>>>>
A point of clarification: nsamples = 0 is the default for
apply.paramset. While confusing, that means that no sampling is done
and all parameter combinations are evaluated.  Sampling is only done
when nsamples > 0.

>>>> In a more general sense, you could specify a custom .combine function
>>>> that could trap errors if there was some possibility that your
>>>> strategy would fail to return a viable result.
>>>>
>>>> A strategy that runs fine in a single core should run fine in
>>>> apply.paramset.  A reasonable way to start testing this beyond a
>>>> single parameterization would be to set a small number of samples,
>>>> like nsamples=50 and run it with registerDoSEQ() to run it sequentially.
>>>>
>>>> Regards,
>>>>
>>>> Brian
>>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From aschmid1 at stevens.edu  Tue Mar 22 18:37:08 2016
From: aschmid1 at stevens.edu (Alec Schmidt)
Date: Tue, 22 Mar 2016 17:37:08 +0000
Subject: [R-SIG-Finance] comparing solve.pq and nloptr for min variance
 portfolio: nloptr needs resampling
In-Reply-To: <87y49e5ip8.fsf@enricoschumann.net>
References: <1458309416883.39021@stevens.edu>
	<874mc3amnl.fsf@enricoschumann.net> <1458311992838.14954@stevens.edu>
	<87vb4j963j.fsf@enricoschumann.net>
	<1458315137518.8340@stevens.edu>,<87y49e5ip8.fsf@enricoschumann.net>
Message-ID: <1458668240225.24155@stevens.edu>

Hi  Enrico,
Indeed I had a bug in defining gradient. I attach the corrected script. But nloptr still needs resampling:

Say when I use the initial condition   x0<-rep(1/n, n), I get
        XLY XLF       XLV     Std.Dev  Exp.Return    sharpe
0.4957209   0 0.5042791 0.007334353 0.001318627 0.1797878

For x0<-c(0,1,0), I get
        XLY XLF       XLV     Std.Dev  Exp.Return    sharpe
0.4352796   0 0.5647204 0.007322604 0.001316634 0.1798041

For x0<-c(1,0,0), I get
       XLY XLF      XLV     Std.Dev  Exp.Return    sharpe
0.594686   0 0.405314 0.007378273 0.001321891 0.1791599

And finally for x0<-c(0,0,1), the  nloptr result 
        XLY          XLF       XLV     Std.Dev  Exp.Return    sharpe
0.4752062 3.665469e-19 0.5247938 0.007329077 0.001317951 0.1798249

practically coincides with that for solve.QP (with default initial condition) with max Sharpe value:
        XLY          XLF       XLV     Std.Dev  Exp.Return    sharpe
0.4752112 4.308351e-18 0.5247888 0.007329079 0.001317951 0.1798249

For other data samples (say for 2011-2013),  x0<-rep(1/n, n) may give the same result as solve.qp.

I wonder what is default initial condiiton in solve.qp and if nloptr sensitivity to initial conditions was ever discussed.

Best, Alec 
________________________________________
From: Enrico Schumann <es at enricoschumann.net>
Sent: Saturday, March 19, 2016 4:14 PM
To: Alec Schmidt
Cc: R-SIG-Finance at r-project.org
Subject: Re: [R-SIG-Finance] comparing solve.pq and nloptr for min variance portfolio

On Fri, 18 Mar 2016, Alec Schmidt <aschmid1 at stevens.edu> writes:

> Enrico,
> Here we're. I attach two scripts: one for solve.pq, another for
> nloptr. Both run with the same input file and print output on the
> screen.
>
> Thanks again, Alec

Hi Alec,

but these are still long programmes, which makes it hard to
figure out what exactly is wrong. For a start, I would not
compute the whole frontier, but concentrate on one point.

I computed the minimum-variance portfolio (without short
sales) with an alternative method, and it matches your
output for 'solve.QP'. So, one thing to check is your
implementation of the objective function for 'nloptr'.

Kind regards (and good luck)
     Enrico


> ________________________________________
> From: Enrico Schumann <es at enricoschumann.net>
> Sent: Friday, March 18, 2016 11:08 AM
> To: Alec Schmidt
> Cc: R-SIG-Finance at r-project.org
> Subject: Re: [R-SIG-Finance] comparing solve.pq and nloptr for min variance portfolio
>
> On Fri, 18 Mar 2016, Alec Schmidt <aschmid1 at stevens.edu> writes:
>
>> Hi Enrico,
>> Many thanks for your interest. I attach my script and input file with
>> asset tickers. Sorry for lots of unrelated stuff - it's a working
>> draft.
>>
>> Alec
>
> Thanks for sending the script, Alec. But you will need to
> simplify it if people are to help you. [My bad: I should have
> said _minimal_ reproducible example:
> https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ]
>
>
>
>> ________________________________________
>> From: Enrico Schumann <es at enricoschumann.net>
>> Sent: Friday, March 18, 2016 10:25 AM
>> To: Alec Schmidt
>> Cc: R-SIG-Finance at r-project.org
>> Subject: Re: [R-SIG-Finance] comparing solve.pq and nloptr for min variance portfolio
>>
>> On Fri, 18 Mar 2016, Alec Schmidt <aschmid1 at stevens.edu> writes:
>>
>>> I'm puzzled that I cannot reproduce results for asset weights using
>>> solve.pq and nloptr even in the case of just three assets.  E.g. if I
>>> use NLOPT_LD_SLSQP and start with initial weights of 1/3, I may obtain
>>> (0.47, 0, 0.53) vs (0.52, 0, 0.47).  If I start with (0.52, 0, 0.47),
>>> I do get (0.52, 0, 0.47)...
>>>
>>> When I use NLOPT_GN_ISRES or other nloptr solvers that permit equality
>>> constraint sum(weights)=1 with initial weights of 1/3, I obtain
>>> (almost) the same initial weights after 20000 iterations with
>>> xtol_rel=1.0e-8...
>>>
>>> I remember from my MC simulations of protein structures (20 years ago)
>>> that sampling is key due to multiple local minimums but is it so bad
>>> for a simple portfolio?
>>>
>>>
>>> I'll greatly appreciate relevant comments.
>>>
>>> Alec
>>
>> [...]
>>
>> Unless your covariance matrix is 'broken' in some way, a
>> minimum-variance portfolio with only a budget constraint should be
>> fairly easy to compute (no multiple local minima, smooth objective
>> function, ...). Please provide a reproducible example.
>>
>> Kind regards,
>>         Enrico

--
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net
-------------- next part --------------
A non-text attachment was scrubbed...
Name: nloptr_portfolio.R
Type: application/octet-stream
Size: 2982 bytes
Desc: nloptr_portfolio.R
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20160322/5082c6c5/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: SPYETF3.csv
Type: application/vnd.ms-excel
Size: 75 bytes
Desc: SPYETF3.csv
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20160322/5082c6c5/attachment.xlb>

From diegoperoni at vodafone.it  Tue Mar 22 18:56:16 2016
From: diegoperoni at vodafone.it (Diego Peroni)
Date: Tue, 22 Mar 2016 18:56:16 +0100
Subject: [R-SIG-Finance] need apply.paramset logging
In-Reply-To: <CAPPM_gStyeYBYGf2XagxBL28+zrdPk42Cxcp-6tT24C5r5tQYw@mail.gmail.com>
References: <56F10446.3090601@vodafone.it> <56F10658.9000302@braverock.com>
	<56F15A7F.3070908@vodafone.it> <1458658996.29692.43.camel@brian-rcg>
	<56F162FB.8010709@vodafone.it>
	<CAPPM_gStyeYBYGf2XagxBL28+zrdPk42Cxcp-6tT24C5r5tQYw@mail.gmail.com>
Message-ID: <56F18740.9010604@vodafone.it>

Thanks Ulrich,

process ID as file name seem a valid solution!

Is there a documented way to redirect quantstrat default system out and 
ERROR messages to a file?

Regards

Diego


On 22/03/2016 18:22, Joshua Ulrich wrote:
> On Tue, Mar 22, 2016 at 10:21 AM, Diego Peroni <diegoperoni at vodafone.it> wrote:
>>
>> On 22/03/2016 16:03, Brian G. Peterson wrote:
>>> Executing on minute data won't drive the speed of the path-dependent
>>> rules loop, the total number of signals which need to be evaluated will,
>>> or the inclusion of things like trailing stops.
>> Trailing Stops is my case :-)
>>>
>>> You should be able to sort out which parameter combination is failing
>>> from the print statements.  you should also be able to look at the audit
>>> environment to see which portfolio you're expecting is missing.
>> During multicore execution I'm enable to see print out.
>> I'm sure there is a way to redirect each thread print out to a file but I
>> don't know how.
> doMC runs in separate processes, not threads.  You could add some code
> to print the process ID before each message, or write to a file named
> with the process ID.
>> Sys.getpid()
> [1] 29236
>> registerDoMC(2)
>> foreach(1:6) %dopar% { Sys.getpid() }
> [[1]]
> [1] 29345
>
> [[2]]
> [1] 29346
>
> [[3]]
> [1] 29345
>
> [[4]]
> [1] 29346
>
> [[5]]
> [1] 29345
>
> [[6]]
> [1] 29346
>
>>>
>>> Ultimately, this is a problem in your strategy specification...  You've
>>> created an infeasible parameter combination.  You likely want to debug
>>> what, specifically, is failing, rather than just skipping the failing
>>> parameter set.
>>>
>>> If you're determined to work with the combine funtion...
>> Sure :)
>>>
>>> The .combine argument for foreach is described in the documentation for
>>> foreach.  See ?foreach.
>>>
>>> The combine function in apply.paramset is inside the apply.paramset
>>> function.  We could probably check for a user-supplied combine, or you
>>> could modify the combine function inside apply.paramset yourself.
>> Thanks a lot, I take a look
>>
>>
>> Regards
>>
>> Diego
>>
>>
>>
>>>
>>>
>>> On Tue, 2016-03-22 at 15:45 +0100, Diego Peroni wrote:
>>>> Brain thanks for your answers!
>>>>
>>>> My strategy take a long time to run because it is "minute" based and
>>>> runs over 6 years.
>>>>
>>>> I've just 100 combinations so it is not the best to reduce nsamples to
>>>> find errors.
>>>>
>>>> If I reduce time range (2 o 3 years) it doesn't fail.
>>>>
>>>> If I run sequentially it take a very long time.
>>>>
>>>> The best solution remains the last you have indicated: "custom .combine
>>>> function that could trap errors".
>>>> Does exist some documentation or example to read?
>>>>
>>>> Regards
>>>>
>>>> Diego Peroni
>>>>
>>>>
>>>>
>>>>
>>>> On 22/03/2016 09:46, Brian G. Peterson wrote:
>>>>> On 03/22/2016 03:37 AM, Diego Peroni wrote:
>>>>>> I'm testing paramset combinations with:
>>>>>>
>>>>>> .....
>>>>>> library(doMC)
>>>>>> registerDoMC(cores=detectCores())
>>>>>> paramsetenv = new.env()
>>>>>> results = apply.paramset(qs.strategy, paramset.label = "MACDOPT",
>>>>>> verbose = TRUE,
>>>>>>                              portfolio=qs.strategy, account=qs.strategy,
>>>>>> nsamples=0, audit=paramsetenv)
>>>>>>
>>>>>> but the procedure returns NULL object with this message:
>>>>>>
>>>>>> error calling combine function:
>>>>>> <simpleError: $ operator is invalid for atomic vectors>
>>>>>>
>>>>>> Is there a way to log threads errors?
>>>>>>
>>>>>> Or how can I modify "apply.paramset" function to "catch" single
>>>>>> simultation error or void result and discard it?
>>>>> you're setting
>>>>>
>>>>> nsamples=0
>>>>>
>>>>> so you have zero results to combine.
>>>>>
>>>>> In this case, you told it to run no samples, but I can conceive of a
>>>>> strategy using some MCMC sampler that could fail spontaneously in some
>>>>> circumstances.
>>>>>
> A point of clarification: nsamples = 0 is the default for
> apply.paramset. While confusing, that means that no sampling is done
> and all parameter combinations are evaluated.  Sampling is only done
> when nsamples > 0.
>
>>>>> In a more general sense, you could specify a custom .combine function
>>>>> that could trap errors if there was some possibility that your
>>>>> strategy would fail to return a viable result.
>>>>>
>>>>> A strategy that runs fine in a single core should run fine in
>>>>> apply.paramset.  A reasonable way to start testing this beyond a
>>>>> single parameterization would be to set a small number of samples,
>>>>> like nsamples=50 and run it with registerDoSEQ() to run it sequentially.
>>>>>
>>>>> Regards,
>>>>>
>>>>> Brian
>>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions
>>>> should go.
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>


From brian at braverock.com  Tue Mar 22 19:33:02 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 22 Mar 2016 13:33:02 -0500
Subject: [R-SIG-Finance] need apply.paramset logging
In-Reply-To: <56F18740.9010604@vodafone.it>
References: <56F10446.3090601@vodafone.it> <56F10658.9000302@braverock.com>
	<56F15A7F.3070908@vodafone.it> <1458658996.29692.43.camel@brian-rcg>
	<56F162FB.8010709@vodafone.it>
	<CAPPM_gStyeYBYGf2XagxBL28+zrdPk42Cxcp-6tT24C5r5tQYw@mail.gmail.com>
	<56F18740.9010604@vodafone.it>
Message-ID: <1458671582.29692.51.camel@brian-rcg>




On Tue, 2016-03-22 at 18:56 +0100, Diego Peroni wrote:
> Is there a documented way to redirect quantstrat default system out and 
> ERROR messages to a file?

see:


?sink


From pgilbert902 at gmail.com  Tue Mar 22 19:55:22 2016
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Tue, 22 Mar 2016 14:55:22 -0400
Subject: [R-SIG-Finance] Time-Varying Cointegration in R
In-Reply-To: <56F10CEB.2020107@gmail.com>
References: <56F10CEB.2020107@gmail.com>
Message-ID: <56F1951A.1010401@gmail.com>

Johannes

Ordering complex numbers is not obvious, so one likely thing would be 
that you have the same result but in a different order. If the 
eigenvalues are the same, only the vectors are different, it is a 
normalization issue. If it is not that, then verify that you are 
calculating eigenvalues with the same matrix in both systems. A matrix 
that has several orders of magnitude difference between the largest and 
smallest eigenvalues (in abs value) will be ill-conditioned, in which 
case the result can differ a lot based on seemingly small differences in 
the matrix. You can verify if this is a problem by copy and paste of 
exactly the same matrix into both systems. (Round to a reasonable number 
of digits and truncate the rest.)

BTW, if ill-conditioning is the problem, and the results depend 
critically on this calculation, there is a problem with the technique.

If those are not the problem, then you might consider checking which 
result is correct. This problem does have an answer that can be 
verified.  From ?eigen

    If ?r <- eigen(A)?, and ?V <- r$vectors; lam <- r$values?, then

                               A = V Lmbd V^(-1)

      (up to numerical fuzz), where Lmbd =?diag(lam)?.

Please let us know if R is getting an incorrect result. It seems highly 
unlikely, but it might affect a lot of calculations.

HTH,
Paul

On 03/22/2016 05:14 AM, Johannes Lips wrote:
> Dear list,
>
> I've implemented the time-varying cointegration framework by Bierens and
> Martins (2010) in R [1], based on the gauss implementation of Luis
> Martins [2]. I do get the same results as in gauss, when using lower
> chebyshev dimensions, but when the number of dimensions is increasing, I
> run into issues with complex eigenvalues and eigenvectors.
> Additionally the eigenvalues and eigenvectors differ quite a bit between
> gauss and R and I do not really know how to find out why that is. I also
> experimented with different implementations of eigenvalues
> determination, based on the C++ routine eigen, but was not able to
> replicate the gauss results exactly.
> One notable difference is that gauss does not normalize the
> eigenvectors, but even after considering this a discrepancy remains.
> Perhaps someone with a better knowledge of gauss may shed some light on
> possible sources for these differences.
>
>
>
> [1] https://github.com/hannes101/TimeVaryingCointegration
> [2] http://home.iscte-iul.pt/~lfsm/
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From theraybao at gmail.com  Tue Mar 22 23:05:01 2016
From: theraybao at gmail.com (Ray Bao)
Date: Tue, 22 Mar 2016 15:05:01 -0700
Subject: [R-SIG-Finance] Optimizing Quanstrat MACD with apply.paramset
	returns combine error
Message-ID: <CAE=+br3ciEQGSDY_Yd=5Xk5shj=HMO0P1_wfiGA1iF7p1ND-Kw@mail.gmail.com>

I am trying to test some trading strategies involving digital
currency. One such strategy involves MACD crossovers, but I would like
to optimize the nSlow & nFast parameters. Here's a reproducible
example (which runs):

###########################################################################################

library(httr)
library(plyr)
library(quantstrat)
library(PerformanceAnalytics)
library(IKTrading)  # install_github("IlyaKipnis/IKTrading")

poloniex.ohlc.30m <-
content(GET("https://poloniex.com/public?command=returnChartData&currencyPair=BTC_ETH&start=1439010600&end=9999999999&period=1800"))
 # https://poloniex.com/support/api/
ETHBTC.30m <- ldply(poloniex.ohlc.30m, data.frame)  # Convert OHLCV to
data.frame
ETHBTC.30m$date <- as.POSIXct(ETHBTC.30m$date, origin = "1970-01-01")

# Create 'xts' object:
ethbtc.30m.xts <- xts(ETHBTC.30m[, 2:8], order.by = ETHBTC.30m$date)
# is.OHLCV(ETHBTC.30m)

# Rebuild empty environments if RStudio's "Clear All" has been used:
if (!exists('.instrument')) .instrument <- new.env()
if (!exists('.blotter')) .blotter <- new.env()
if (!exists('.strategy')) .strategy <- new.env()

## Optional: Subset timeframe
ETHBTC <- ethbtc.30m.xts[,c("open", "high", "low", "close",
"volume")]["2016-02-01::"]

## Define instruments
currency(c('BTC', 'ETH'))  # ls_currencies()
exchange_rate('ETHBTC', currency = 'BTC', counter_currency = 'ETH',
tick_size = 0.00001)

initDate = '2016-02-01'
initBTC <- 100
initETH <- 0

portfolio.name <- "crypto"
account.name <- "poloniex"
strategy.name <- "accumulator"
symbols <- "ETHBTC"

## To rerun
rm.strat(portfolio.name)
rm.strat(account.name)
rm.strat(strategy.name)

## Initialize Portfolio, Account, and Orderbook
initPortf(name = portfolio.name, symbols = symbols, initPosQty = 0,
initDate = initDate, currency = "BTC")  # getPortfolio(portfolio.name)
initAcct(name = account.name, portfolios = portfolio.name, initDate =
initDate, initEq = 0, currency = "BTC")  # getAccount(account.name)
initOrders(portfolio = portfolio.name, symbols = symbols, initDate =
initDate)  # getOrderBook(portfolio.name)
strategy(strategy.name, store = TRUE)  # summary(getStrategy(strategy.name))

## Indicators
# Parameters
.nFast = 60 # 90
.nSlow = 130
.nSig = 45 # 75

add.indicator(strategy.name, name = "MACD", arguments =
list(x=quote(Cl(mktdata))), label=NULL)

## Signals
# See Also: applySignals add.indicator link{add.rule} sigComparison
sigCrossover sigFormula sigPeak sigThreshold
# MACD
add.signal(strategy.name, "sigCrossover",
           arguments = list(columns = c("macd.MACD.ind",
"signal.MACD.ind"), relationship = "gt"),
           label = 'longEntry')
add.signal(strategy.name, "sigCrossover",
           arguments = list(columns = c("signal.MACD.ind",
"macd.MACD.ind"), relationship = "gt"),
           label = 'signal.gt.macd')
add.signal(strategy.name, "sigThreshold",
           arguments = list(column = "macd.MACD.ind", threshold = 0,
relationship = "gte"),
           label = 'macd.gte.threshold')
add.signal(strategy.name, "sigAND",
           arguments=list(columns=c('signal.gt.macd',
'macd.gte.threshold'), cross=FALSE),
           label="longExit")

# Order sizing
osFixedDollar <- function(timestamp, orderqty, portfolio, symbol, ruletype, ...)
{
  ClosePrice <- as.numeric(Cl(mktdata[timestamp,]))
  orderqty <- round(tradeSize/ClosePrice,-2)
  return(orderqty)
}
tradeSize <- initBTC/2

## Rules
# Entry
add.rule(strategy.name,name='ruleSignal',
         arguments = list(sigcol="longEntry",
                          sigval=TRUE,
                          orderqty=1000,
                          ordertype='market',
                          orderside='long',
                          osFUN='osFixedDollar'),
         type='enter',
         label='EnterLONG',
         storefun=FALSE)

# Exit
add.rule(strategy.name,name='ruleSignal',
         arguments = list(sigcol="longExit",
                          sigval=TRUE,
                          orderqty='all',
                          ordertype='market',
                          orderside='long',
                          osFUN='osFixedDollar'),
         type='exit',
         label='ExitLONG',
         storefun=FALSE)

## Run it
applyStrategy(strategy.name,
              portfolios=portfolio.name,
              parameters=list(nFast = .nFast, nSlow = .nSlow, nSig =
.nSig, maType = 'EMA'),
              verbose=TRUE)

updatePortf(Portfolio=portfolio.name,Dates=paste('::',as.Date(Sys.time()),sep=''))
updateAcct(account.name)
updateEndEq(account.name)

## Evaluate
t(tradeStats(portfolio.name))
getTxns(portfolio.name, Symbol = 'ETHBTC')
perTradeStats(portfolio.name, "ETHBTC")

chart.Posn(Portfolio=portfolio.name,Symbol=symbols, type = "line",
log.scale = T)
plot(add_Vo())
plot(add_MACD(fast=.nFast, slow=.nSlow, signal=.nSig,maType="EMA"))  #
nFast = 60, nSlow = 180, nSig = 40, maType = 'EMA'

###########################################################################################

The above runs perfectly-fine. However, I want to vary the nFast and
nSlow parameters to the MACD() function:

## Parameter distribution testing
add.distribution(strategy.name,
                 paramset.label = 'optEMA',
                 component.type = 'indicator',
                 component.label = 'nFast',
                 variable = list(nFast = 60:80),
                 label = 'NFAST')

add.distribution(strategy.name,
                 paramset.label = 'optEMA',
                 component.type = 'indicator',
                 component.label = 'nSlow',
                 variable = list(nFast = 180:200),
                 label = 'NSLOW')

library(doMC)
registerDoMC(cores=detectCores())

results <- apply.paramset(strategy.name, paramset.label = "optEMA",
portfolio=portfolio.name, account=account.name, nsamples=0)

###########################################################################################

This gives me the following error, which I'm not sure how to debug:

error calling combine function:
<simpleError in fun(result.1, result.2, result.3, result.4, result.5,
result.6, ... result.439, result.440, result.441): attempt to select
less than one element>

What am I doing wrong? FWIW, I am using Ubuntu 12.04/14.04. Any help
is much appreciated. Thanks!!

-- 
Ray Bao
T: 925.272.9226
M: 510.292.3438
iamraybao.com


From josh.m.ulrich at gmail.com  Wed Mar 23 01:21:06 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 22 Mar 2016 19:21:06 -0500
Subject: [R-SIG-Finance] Optimizing Quanstrat MACD with apply.paramset
 returns combine error
In-Reply-To: <CAE=+br3ciEQGSDY_Yd=5Xk5shj=HMO0P1_wfiGA1iF7p1ND-Kw@mail.gmail.com>
References: <CAE=+br3ciEQGSDY_Yd=5Xk5shj=HMO0P1_wfiGA1iF7p1ND-Kw@mail.gmail.com>
Message-ID: <CAPPM_gS=bq0fNroOvYRQ-OKriUt1E_9c4CFc__nBLD1MFstjtA@mail.gmail.com>

Please don't cross post: http://stackoverflow.com/q/36165926/271616

Or, at the very minimum, tell people you're cross posting so they
don't waste their time answering a question that's already been
answered on a forum they don't follow.

On Tue, Mar 22, 2016 at 5:05 PM, Ray Bao <theraybao at gmail.com> wrote:
> I am trying to test some trading strategies involving digital
> currency. One such strategy involves MACD crossovers, but I would like
> to optimize the nSlow & nFast parameters. Here's a reproducible
> example (which runs):
>
> ###########################################################################################
>
> library(httr)
> library(plyr)
> library(quantstrat)
> library(PerformanceAnalytics)
> library(IKTrading)  # install_github("IlyaKipnis/IKTrading")
>
> poloniex.ohlc.30m <-
> content(GET("https://poloniex.com/public?command=returnChartData&currencyPair=BTC_ETH&start=1439010600&end=9999999999&period=1800"))
>  # https://poloniex.com/support/api/
> ETHBTC.30m <- ldply(poloniex.ohlc.30m, data.frame)  # Convert OHLCV to
> data.frame
> ETHBTC.30m$date <- as.POSIXct(ETHBTC.30m$date, origin = "1970-01-01")
>
> # Create 'xts' object:
> ethbtc.30m.xts <- xts(ETHBTC.30m[, 2:8], order.by = ETHBTC.30m$date)
> # is.OHLCV(ETHBTC.30m)
>
> # Rebuild empty environments if RStudio's "Clear All" has been used:
> if (!exists('.instrument')) .instrument <- new.env()
> if (!exists('.blotter')) .blotter <- new.env()
> if (!exists('.strategy')) .strategy <- new.env()
>
> ## Optional: Subset timeframe
> ETHBTC <- ethbtc.30m.xts[,c("open", "high", "low", "close",
> "volume")]["2016-02-01::"]
>
> ## Define instruments
> currency(c('BTC', 'ETH'))  # ls_currencies()
> exchange_rate('ETHBTC', currency = 'BTC', counter_currency = 'ETH',
> tick_size = 0.00001)
>
> initDate = '2016-02-01'
> initBTC <- 100
> initETH <- 0
>
> portfolio.name <- "crypto"
> account.name <- "poloniex"
> strategy.name <- "accumulator"
> symbols <- "ETHBTC"
>
> ## To rerun
> rm.strat(portfolio.name)
> rm.strat(account.name)
> rm.strat(strategy.name)
>
> ## Initialize Portfolio, Account, and Orderbook
> initPortf(name = portfolio.name, symbols = symbols, initPosQty = 0,
> initDate = initDate, currency = "BTC")  # getPortfolio(portfolio.name)
> initAcct(name = account.name, portfolios = portfolio.name, initDate =
> initDate, initEq = 0, currency = "BTC")  # getAccount(account.name)
> initOrders(portfolio = portfolio.name, symbols = symbols, initDate =
> initDate)  # getOrderBook(portfolio.name)
> strategy(strategy.name, store = TRUE)  # summary(getStrategy(strategy.name))
>
> ## Indicators
> # Parameters
> .nFast = 60 # 90
> .nSlow = 130
> .nSig = 45 # 75
>
> add.indicator(strategy.name, name = "MACD", arguments =
> list(x=quote(Cl(mktdata))), label=NULL)
>
> ## Signals
> # See Also: applySignals add.indicator link{add.rule} sigComparison
> sigCrossover sigFormula sigPeak sigThreshold
> # MACD
> add.signal(strategy.name, "sigCrossover",
>            arguments = list(columns = c("macd.MACD.ind",
> "signal.MACD.ind"), relationship = "gt"),
>            label = 'longEntry')
> add.signal(strategy.name, "sigCrossover",
>            arguments = list(columns = c("signal.MACD.ind",
> "macd.MACD.ind"), relationship = "gt"),
>            label = 'signal.gt.macd')
> add.signal(strategy.name, "sigThreshold",
>            arguments = list(column = "macd.MACD.ind", threshold = 0,
> relationship = "gte"),
>            label = 'macd.gte.threshold')
> add.signal(strategy.name, "sigAND",
>            arguments=list(columns=c('signal.gt.macd',
> 'macd.gte.threshold'), cross=FALSE),
>            label="longExit")
>
> # Order sizing
> osFixedDollar <- function(timestamp, orderqty, portfolio, symbol, ruletype, ...)
> {
>   ClosePrice <- as.numeric(Cl(mktdata[timestamp,]))
>   orderqty <- round(tradeSize/ClosePrice,-2)
>   return(orderqty)
> }
> tradeSize <- initBTC/2
>
> ## Rules
> # Entry
> add.rule(strategy.name,name='ruleSignal',
>          arguments = list(sigcol="longEntry",
>                           sigval=TRUE,
>                           orderqty=1000,
>                           ordertype='market',
>                           orderside='long',
>                           osFUN='osFixedDollar'),
>          type='enter',
>          label='EnterLONG',
>          storefun=FALSE)
>
> # Exit
> add.rule(strategy.name,name='ruleSignal',
>          arguments = list(sigcol="longExit",
>                           sigval=TRUE,
>                           orderqty='all',
>                           ordertype='market',
>                           orderside='long',
>                           osFUN='osFixedDollar'),
>          type='exit',
>          label='ExitLONG',
>          storefun=FALSE)
>
> ## Run it
> applyStrategy(strategy.name,
>               portfolios=portfolio.name,
>               parameters=list(nFast = .nFast, nSlow = .nSlow, nSig =
> .nSig, maType = 'EMA'),
>               verbose=TRUE)
>
> updatePortf(Portfolio=portfolio.name,Dates=paste('::',as.Date(Sys.time()),sep=''))
> updateAcct(account.name)
> updateEndEq(account.name)
>
> ## Evaluate
> t(tradeStats(portfolio.name))
> getTxns(portfolio.name, Symbol = 'ETHBTC')
> perTradeStats(portfolio.name, "ETHBTC")
>
> chart.Posn(Portfolio=portfolio.name,Symbol=symbols, type = "line",
> log.scale = T)
> plot(add_Vo())
> plot(add_MACD(fast=.nFast, slow=.nSlow, signal=.nSig,maType="EMA"))  #
> nFast = 60, nSlow = 180, nSig = 40, maType = 'EMA'
>
> ###########################################################################################
>
> The above runs perfectly-fine. However, I want to vary the nFast and
> nSlow parameters to the MACD() function:
>
> ## Parameter distribution testing
> add.distribution(strategy.name,
>                  paramset.label = 'optEMA',
>                  component.type = 'indicator',
>                  component.label = 'nFast',
>                  variable = list(nFast = 60:80),
>                  label = 'NFAST')
>
> add.distribution(strategy.name,
>                  paramset.label = 'optEMA',
>                  component.type = 'indicator',
>                  component.label = 'nSlow',
>                  variable = list(nFast = 180:200),
>                  label = 'NSLOW')
>
> library(doMC)
> registerDoMC(cores=detectCores())
>
> results <- apply.paramset(strategy.name, paramset.label = "optEMA",
> portfolio=portfolio.name, account=account.name, nsamples=0)
>
> ###########################################################################################
>
> This gives me the following error, which I'm not sure how to debug:
>
> error calling combine function:
> <simpleError in fun(result.1, result.2, result.3, result.4, result.5,
> result.6, ... result.439, result.440, result.441): attempt to select
> less than one element>
>
> What am I doing wrong? FWIW, I am using Ubuntu 12.04/14.04. Any help
> is much appreciated. Thanks!!
>
> --
> Ray Bao
> T: 925.272.9226
> M: 510.292.3438
> iamraybao.com
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From diegoperoni at vodafone.it  Wed Mar 23 08:46:12 2016
From: diegoperoni at vodafone.it (Diego Peroni)
Date: Wed, 23 Mar 2016 08:46:12 +0100
Subject: [R-SIG-Finance] need apply.paramset logging
In-Reply-To: <1458671582.29692.51.camel@brian-rcg>
References: <56F10446.3090601@vodafone.it> <56F10658.9000302@braverock.com>
	<56F15A7F.3070908@vodafone.it> <1458658996.29692.43.camel@brian-rcg>
	<56F162FB.8010709@vodafone.it>
	<CAPPM_gStyeYBYGf2XagxBL28+zrdPk42Cxcp-6tT24C5r5tQYw@mail.gmail.com>
	<56F18740.9010604@vodafone.it> <1458671582.29692.51.camel@brian-rcg>
Message-ID: <56F249C4.1080302@vodafone.it>

Hi,

I'm trying to override "apply.paramset" function to define my nested 
custom "combine" function in it as you suggested to me.

I got this error:

Error in apply.paramset(qs.strategy, paramset.label = "MACDOPT", 
portfolio = qs.strategy,  :
   could not find function "must.have.args"

I've understood that "must.have.args" (and others in 
quantstrat/R/utils.R) is a local function that is not exported from 
quantstrat package.

Is there a way to pass my custom "combine" function to "apply.paramset"?

Or, more in general, how can I override "apply.paramset" without failing 
with private functions in it?
How can I export private functions to use them?

Thanks in advance

Diego


From brian at braverock.com  Wed Mar 23 09:37:03 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 23 Mar 2016 03:37:03 -0500
Subject: [R-SIG-Finance] need apply.paramset logging
In-Reply-To: <56F249C4.1080302@vodafone.it>
References: <56F10446.3090601@vodafone.it> <56F10658.9000302@braverock.com>
	<56F15A7F.3070908@vodafone.it> <1458658996.29692.43.camel@brian-rcg>
	<56F162FB.8010709@vodafone.it>
	<CAPPM_gStyeYBYGf2XagxBL28+zrdPk42Cxcp-6tT24C5r5tQYw@mail.gmail.com>
	<56F18740.9010604@vodafone.it> <1458671582.29692.51.camel@brian-rcg>
	<56F249C4.1080302@vodafone.it>
Message-ID: <56F255AF.6080200@braverock.com>

On 03/23/2016 02:46 AM, Diego Peroni wrote:
> I'm trying to override "apply.paramset" function to define my nested
> custom "combine" function in it as you suggested to me.
>
> I got this error:
>
> Error in apply.paramset(qs.strategy, paramset.label = "MACDOPT",
> portfolio = qs.strategy,  :
>    could not find function "must.have.args"
>
> I've understood that "must.have.args" (and others in
> quantstrat/R/utils.R) is a local function that is not exported from
> quantstrat package.
>
> Is there a way to pass my custom "combine" function to "apply.paramset"?
>
> Or, more in general, how can I override "apply.paramset" without failing
> with private functions in it?
> How can I export private functions to use them?

In either case, you'll have to rebuild the package with your modified 
function in it or with a modified NAMESPACE file which changes the exports.

In any event, as I told you yesterday, it would likely be more valuable 
for you to examine the audit environment created up to the point that 
apply.paramset's included combine function fails to figure out where 
your strategy is failing.




-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From diegoperoni at vodafone.it  Wed Mar 23 09:48:24 2016
From: diegoperoni at vodafone.it (Diego Peroni)
Date: Wed, 23 Mar 2016 09:48:24 +0100
Subject: [R-SIG-Finance] need apply.paramset logging
In-Reply-To: <56F255AF.6080200@braverock.com>
References: <56F10446.3090601@vodafone.it> <56F10658.9000302@braverock.com>
	<56F15A7F.3070908@vodafone.it> <1458658996.29692.43.camel@brian-rcg>
	<56F162FB.8010709@vodafone.it>
	<CAPPM_gStyeYBYGf2XagxBL28+zrdPk42Cxcp-6tT24C5r5tQYw@mail.gmail.com>
	<56F18740.9010604@vodafone.it> <1458671582.29692.51.camel@brian-rcg>
	<56F249C4.1080302@vodafone.it> <56F255AF.6080200@braverock.com>
Message-ID: <56F25858.3000904@vodafone.it>

Thanks Brian

Diego


On 23/03/2016 09:37, Brian G. Peterson wrote:
> On 03/23/2016 02:46 AM, Diego Peroni wrote:
>> I'm trying to override "apply.paramset" function to define my nested
>> custom "combine" function in it as you suggested to me.
>>
>> I got this error:
>>
>> Error in apply.paramset(qs.strategy, paramset.label = "MACDOPT",
>> portfolio = qs.strategy,  :
>>    could not find function "must.have.args"
>>
>> I've understood that "must.have.args" (and others in
>> quantstrat/R/utils.R) is a local function that is not exported from
>> quantstrat package.
>>
>> Is there a way to pass my custom "combine" function to "apply.paramset"?
>>
>> Or, more in general, how can I override "apply.paramset" without failing
>> with private functions in it?
>> How can I export private functions to use them?
>
> In either case, you'll have to rebuild the package with your modified 
> function in it or with a modified NAMESPACE file which changes the 
> exports.
>
> In any event, as I told you yesterday, it would likely be more 
> valuable for you to examine the audit environment created up to the 
> point that apply.paramset's included combine function fails to figure 
> out where your strategy is failing.
>
>
>
>


From johannes.lips at gmail.com  Wed Mar 23 11:54:34 2016
From: johannes.lips at gmail.com (Johannes Lips)
Date: Wed, 23 Mar 2016 11:54:34 +0100
Subject: [R-SIG-Finance] Time-Varying Cointegration in R
In-Reply-To: <56F1951A.1010401@gmail.com>
References: <56F10CEB.2020107@gmail.com> <56F1951A.1010401@gmail.com>
Message-ID: <56F275EA.6060304@gmail.com>

Paul,

thanks a lot for your reply. I think I can confirm that for basic 3x3 
matrices both yield the same results, only gauss does not normalize them 
to unit length, but if you do that, the eigenvectors are the same. This 
can be seen, when comparing the results of R with the results in the 
gauss manual [1] (p. 464-465).
I can also confirm, that the matrix A, for which the eigenvectors need 
to be computed are exactly the same between R and gauss. The matrix is 
calculated based on the example data set, which is also part of the 
gauss code and available in R as well.
I confirmed, that for all non-complex eigenvalues the eigenvectors are 
the same, when normalizing the vectors in gauss, at least for the two 
and three dimensional chebyshev polynomials. So that leaves me with the 
problem, that the results of eigen() are stored in a matrix which 
converts everything into complex numbers.

Perhaps someone could help me out to make sure the calculations are done 
correctly.

Thanks a lot in advance,
johannes

[1] http://www.aptech.com/wp-content/uploads/2014/01/GAUSS14_LR.pdf
[2] https://gist.github.com/hannes101/eeda2411b480cbeaee16

On 22.03.2016 19:55, Paul Gilbert wrote:
> Johannes
>
> Ordering complex numbers is not obvious, so one likely thing would be 
> that you have the same result but in a different order. If the 
> eigenvalues are the same, only the vectors are different, it is a 
> normalization issue. If it is not that, then verify that you are 
> calculating eigenvalues with the same matrix in both systems. A matrix 
> that has several orders of magnitude difference between the largest 
> and smallest eigenvalues (in abs value) will be ill-conditioned, in 
> which case the result can differ a lot based on seemingly small 
> differences in the matrix. You can verify if this is a problem by copy 
> and paste of exactly the same matrix into both systems. (Round to a 
> reasonable number of digits and truncate the rest.)
>
> BTW, if ill-conditioning is the problem, and the results depend 
> critically on this calculation, there is a problem with the technique.
>
> If those are not the problem, then you might consider checking which 
> result is correct. This problem does have an answer that can be 
> verified.  From ?eigen
>
>    If ?r <- eigen(A)?, and ?V <- r$vectors; lam <- r$values?, then
>
>                               A = V Lmbd V^(-1)
>
>      (up to numerical fuzz), where Lmbd =?diag(lam)?.
>
> Please let us know if R is getting an incorrect result. It seems 
> highly unlikely, but it might affect a lot of calculations.
>
> HTH,
> Paul
>
> On 03/22/2016 05:14 AM, Johannes Lips wrote:
>> Dear list,
>>
>> I've implemented the time-varying cointegration framework by Bierens and
>> Martins (2010) in R [1], based on the gauss implementation of Luis
>> Martins [2]. I do get the same results as in gauss, when using lower
>> chebyshev dimensions, but when the number of dimensions is increasing, I
>> run into issues with complex eigenvalues and eigenvectors.
>> Additionally the eigenvalues and eigenvectors differ quite a bit between
>> gauss and R and I do not really know how to find out why that is. I also
>> experimented with different implementations of eigenvalues
>> determination, based on the C++ routine eigen, but was not able to
>> replicate the gauss results exactly.
>> One notable difference is that gauss does not normalize the
>> eigenvectors, but even after considering this a discrepancy remains.
>> Perhaps someone with a better knowledge of gauss may shed some light on
>> possible sources for these differences.
>>
>>
>>
>> [1] https://github.com/hannes101/TimeVaryingCointegration
>> [2] http://home.iscte-iul.pt/~lfsm/
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R 
>> questions should go.
>>


From theraybao at gmail.com  Wed Mar 23 22:17:54 2016
From: theraybao at gmail.com (Ray Bao)
Date: Wed, 23 Mar 2016 14:17:54 -0700
Subject: [R-SIG-Finance] Optimizing Quanstrat MACD with apply.paramset
 returns combine error
In-Reply-To: <CAPPM_gS=bq0fNroOvYRQ-OKriUt1E_9c4CFc__nBLD1MFstjtA@mail.gmail.com>
References: <CAE=+br3ciEQGSDY_Yd=5Xk5shj=HMO0P1_wfiGA1iF7p1ND-Kw@mail.gmail.com>
	<CAPPM_gS=bq0fNroOvYRQ-OKriUt1E_9c4CFc__nBLD1MFstjtA@mail.gmail.com>
Message-ID: <CAE=+br19zj97cda9JuJwtQuUiSNtOQfpbPNjyANXYyG+ueNjaQ@mail.gmail.com>

OK, I figured this out.

The component.label argument in the add.distribution function needs to
match the labelargument from add.indicator. So in this particular
case, I changed my add.indicator to:

add.indicator(strategy.name, name = "MACD", arguments =
list(x=quote(Cl(mktdata))), label='MACD')

And then changed my add.distribution to:

add.distribution(strategy.name,
                 paramset.label = 'optEMA',
                 component.type = 'indicator',
                 component.label = 'MACD',
                 variable = list(nFast = 60:80),
                 label = 'NFAST')

add.distribution(strategy.name,
                 paramset.label = 'optEMA',
                 component.type = 'indicator',
                 component.label = 'MACD',
                 variable = list(nSlow = 180:200),
                 label = 'NSLOW')

Now, it runs. So the lesson learned for me is: pay attention to
parameter names/labels (especially if you copy-paste from an example
like I did).

On Tue, Mar 22, 2016 at 5:21 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> Please don't cross post: http://stackoverflow.com/q/36165926/271616
>
> Or, at the very minimum, tell people you're cross posting so they
> don't waste their time answering a question that's already been
> answered on a forum they don't follow.
>
> On Tue, Mar 22, 2016 at 5:05 PM, Ray Bao <theraybao at gmail.com> wrote:
>> I am trying to test some trading strategies involving digital
>> currency. One such strategy involves MACD crossovers, but I would like
>> to optimize the nSlow & nFast parameters. Here's a reproducible
>> example (which runs):
>>
>> ###########################################################################################
>>
>> library(httr)
>> library(plyr)
>> library(quantstrat)
>> library(PerformanceAnalytics)
>> library(IKTrading)  # install_github("IlyaKipnis/IKTrading")
>>
>> poloniex.ohlc.30m <-
>> content(GET("https://poloniex.com/public?command=returnChartData&currencyPair=BTC_ETH&start=1439010600&end=9999999999&period=1800"))
>>  # https://poloniex.com/support/api/
>> ETHBTC.30m <- ldply(poloniex.ohlc.30m, data.frame)  # Convert OHLCV to
>> data.frame
>> ETHBTC.30m$date <- as.POSIXct(ETHBTC.30m$date, origin = "1970-01-01")
>>
>> # Create 'xts' object:
>> ethbtc.30m.xts <- xts(ETHBTC.30m[, 2:8], order.by = ETHBTC.30m$date)
>> # is.OHLCV(ETHBTC.30m)
>>
>> # Rebuild empty environments if RStudio's "Clear All" has been used:
>> if (!exists('.instrument')) .instrument <- new.env()
>> if (!exists('.blotter')) .blotter <- new.env()
>> if (!exists('.strategy')) .strategy <- new.env()
>>
>> ## Optional: Subset timeframe
>> ETHBTC <- ethbtc.30m.xts[,c("open", "high", "low", "close",
>> "volume")]["2016-02-01::"]
>>
>> ## Define instruments
>> currency(c('BTC', 'ETH'))  # ls_currencies()
>> exchange_rate('ETHBTC', currency = 'BTC', counter_currency = 'ETH',
>> tick_size = 0.00001)
>>
>> initDate = '2016-02-01'
>> initBTC <- 100
>> initETH <- 0
>>
>> portfolio.name <- "crypto"
>> account.name <- "poloniex"
>> strategy.name <- "accumulator"
>> symbols <- "ETHBTC"
>>
>> ## To rerun
>> rm.strat(portfolio.name)
>> rm.strat(account.name)
>> rm.strat(strategy.name)
>>
>> ## Initialize Portfolio, Account, and Orderbook
>> initPortf(name = portfolio.name, symbols = symbols, initPosQty = 0,
>> initDate = initDate, currency = "BTC")  # getPortfolio(portfolio.name)
>> initAcct(name = account.name, portfolios = portfolio.name, initDate =
>> initDate, initEq = 0, currency = "BTC")  # getAccount(account.name)
>> initOrders(portfolio = portfolio.name, symbols = symbols, initDate =
>> initDate)  # getOrderBook(portfolio.name)
>> strategy(strategy.name, store = TRUE)  # summary(getStrategy(strategy.name))
>>
>> ## Indicators
>> # Parameters
>> .nFast = 60 # 90
>> .nSlow = 130
>> .nSig = 45 # 75
>>
>> add.indicator(strategy.name, name = "MACD", arguments =
>> list(x=quote(Cl(mktdata))), label=NULL)
>>
>> ## Signals
>> # See Also: applySignals add.indicator link{add.rule} sigComparison
>> sigCrossover sigFormula sigPeak sigThreshold
>> # MACD
>> add.signal(strategy.name, "sigCrossover",
>>            arguments = list(columns = c("macd.MACD.ind",
>> "signal.MACD.ind"), relationship = "gt"),
>>            label = 'longEntry')
>> add.signal(strategy.name, "sigCrossover",
>>            arguments = list(columns = c("signal.MACD.ind",
>> "macd.MACD.ind"), relationship = "gt"),
>>            label = 'signal.gt.macd')
>> add.signal(strategy.name, "sigThreshold",
>>            arguments = list(column = "macd.MACD.ind", threshold = 0,
>> relationship = "gte"),
>>            label = 'macd.gte.threshold')
>> add.signal(strategy.name, "sigAND",
>>            arguments=list(columns=c('signal.gt.macd',
>> 'macd.gte.threshold'), cross=FALSE),
>>            label="longExit")
>>
>> # Order sizing
>> osFixedDollar <- function(timestamp, orderqty, portfolio, symbol, ruletype, ...)
>> {
>>   ClosePrice <- as.numeric(Cl(mktdata[timestamp,]))
>>   orderqty <- round(tradeSize/ClosePrice,-2)
>>   return(orderqty)
>> }
>> tradeSize <- initBTC/2
>>
>> ## Rules
>> # Entry
>> add.rule(strategy.name,name='ruleSignal',
>>          arguments = list(sigcol="longEntry",
>>                           sigval=TRUE,
>>                           orderqty=1000,
>>                           ordertype='market',
>>                           orderside='long',
>>                           osFUN='osFixedDollar'),
>>          type='enter',
>>          label='EnterLONG',
>>          storefun=FALSE)
>>
>> # Exit
>> add.rule(strategy.name,name='ruleSignal',
>>          arguments = list(sigcol="longExit",
>>                           sigval=TRUE,
>>                           orderqty='all',
>>                           ordertype='market',
>>                           orderside='long',
>>                           osFUN='osFixedDollar'),
>>          type='exit',
>>          label='ExitLONG',
>>          storefun=FALSE)
>>
>> ## Run it
>> applyStrategy(strategy.name,
>>               portfolios=portfolio.name,
>>               parameters=list(nFast = .nFast, nSlow = .nSlow, nSig =
>> .nSig, maType = 'EMA'),
>>               verbose=TRUE)
>>
>> updatePortf(Portfolio=portfolio.name,Dates=paste('::',as.Date(Sys.time()),sep=''))
>> updateAcct(account.name)
>> updateEndEq(account.name)
>>
>> ## Evaluate
>> t(tradeStats(portfolio.name))
>> getTxns(portfolio.name, Symbol = 'ETHBTC')
>> perTradeStats(portfolio.name, "ETHBTC")
>>
>> chart.Posn(Portfolio=portfolio.name,Symbol=symbols, type = "line",
>> log.scale = T)
>> plot(add_Vo())
>> plot(add_MACD(fast=.nFast, slow=.nSlow, signal=.nSig,maType="EMA"))  #
>> nFast = 60, nSlow = 180, nSig = 40, maType = 'EMA'
>>
>> ###########################################################################################
>>
>> The above runs perfectly-fine. However, I want to vary the nFast and
>> nSlow parameters to the MACD() function:
>>
>> ## Parameter distribution testing
>> add.distribution(strategy.name,
>>                  paramset.label = 'optEMA',
>>                  component.type = 'indicator',
>>                  component.label = 'nFast',
>>                  variable = list(nFast = 60:80),
>>                  label = 'NFAST')
>>
>> add.distribution(strategy.name,
>>                  paramset.label = 'optEMA',
>>                  component.type = 'indicator',
>>                  component.label = 'nSlow',
>>                  variable = list(nFast = 180:200),
>>                  label = 'NSLOW')
>>
>> library(doMC)
>> registerDoMC(cores=detectCores())
>>
>> results <- apply.paramset(strategy.name, paramset.label = "optEMA",
>> portfolio=portfolio.name, account=account.name, nsamples=0)
>>
>> ###########################################################################################
>>
>> This gives me the following error, which I'm not sure how to debug:
>>
>> error calling combine function:
>> <simpleError in fun(result.1, result.2, result.3, result.4, result.5,
>> result.6, ... result.439, result.440, result.441): attempt to select
>> less than one element>
>>
>> What am I doing wrong? FWIW, I am using Ubuntu 12.04/14.04. Any help
>> is much appreciated. Thanks!!
>>
>> --
>> Ray Bao
>> T: 925.272.9226
>> M: 510.292.3438
>> iamraybao.com
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
> R/Finance 2016 | www.rinfinance.com



-- 
Ray Bao
T: 925.272.9226
M: 510.292.3438
iamraybao.com


From joakimlb90 at gmail.com  Tue Mar 29 15:27:57 2016
From: joakimlb90 at gmail.com (=?UTF-8?Q?Joakim_Lindboe_Br=C3=BCchmann_=2E?=)
Date: Tue, 29 Mar 2016 15:27:57 +0200
Subject: [R-SIG-Finance] Asymmetry parameter misspecification in EGARCH
 model using the rugarch package
Message-ID: <CAGPkpwA4qZsCQzKxZEZPuOYTmvC43oZr8rmqkG1_MNWUpfKjhQ@mail.gmail.com>

Dear Alexios,

First of all thanks for a wonderful package that I frequently use.

I have estimated an ARMA(1,1)-EGARCH(1) model, and was puzzled by the
outcome for a very long time since I got an insignificant estimate for the
|z_t-1| term (regular ARCH effects) while the asymmetric parameter in front
of z_t-1 was indeed statistically significant. My data looks like normal
financial data.

I based this on the specifications using the ?ugarchspec function in my
script where it says:

*Variance Model (GJR, EGARCH)*
- assymetry term: gamma1

By drawing the news impact curves and reviewing my code and plots, I came
to the conclusion that there was no asymmetry apparent from the data but
that there indeed should bed regular ARCH effects. By running the code for
gjrGARCH also, I noticed that this model confirmed my hypothesis.

Thereby my question:
Isn't there an error in the instructions? Doesn't gamma1 represent regular
ARCH effects while alpha1 is the correct leverage parameter representing
asymmetry?

Best Regards,
Joakim

	[[alternative HTML version deleted]]


From diegoperoni at vodafone.it  Tue Mar 29 16:46:31 2016
From: diegoperoni at vodafone.it (Diego Peroni)
Date: Tue, 29 Mar 2016 16:46:31 +0200
Subject: [R-SIG-Finance] stoplimit market price with OHLC
In-Reply-To: <CAGPkpwA4qZsCQzKxZEZPuOYTmvC43oZr8rmqkG1_MNWUpfKjhQ@mail.gmail.com>
References: <CAGPkpwA4qZsCQzKxZEZPuOYTmvC43oZr8rmqkG1_MNWUpfKjhQ@mail.gmail.com>
Message-ID: <56FA9547.2020303@vodafone.it>

Hi All,

my strategy exit an open position with a simple Signal based on 1 minute 
OHLC bars.

This is my exit rule:

add.rule(qs.strategy, name='ruleSignal',
          arguments=list(sigcol='upTrend', sigval=TRUE,
                         replace=TRUE,
                         orderside='short',
                         ordertype='market',
                         orderqty='all',
                         orderset='ocoshort'
          ),
          type='exit',
          label='ExitShort',
          enabled=TRUE)

My question is: which price quantstrat use to sell market by default?
- Current Bar Close Price?
- Next Bar Open Price?
- Next Bar "worst"/"best" Price?

Thanks in advance

Diego


From alexios at 4dscape.com  Tue Mar 29 17:45:43 2016
From: alexios at 4dscape.com (Alexios Ghalanos)
Date: Tue, 29 Mar 2016 10:45:43 -0500
Subject: [R-SIG-Finance] Asymmetry parameter misspecification in EGARCH
	model using the rugarch package
In-Reply-To: <CAGPkpwA4qZsCQzKxZEZPuOYTmvC43oZr8rmqkG1_MNWUpfKjhQ@mail.gmail.com>
References: <CAGPkpwA4qZsCQzKxZEZPuOYTmvC43oZr8rmqkG1_MNWUpfKjhQ@mail.gmail.com>
Message-ID: <C2EB7A6C-E5DF-430E-9B3B-70967F28609E@4dscape.com>

See the vignette section 2.2.3 equation 14. There is no confusion as to why gamma is the asymmetry effect (or more correctly the magnitude effect), whereas alpha is the sign effect (as the vignette states).

You can also check ugarchbench("published") and the underlying code for more details.

Alexios

Sent from my iPhone

> On Mar 29, 2016, at 8:27 AM, Joakim Lindboe Br?chmann . <joakimlb90 at gmail.com> wrote:
> 
> Dear Alexios,
> 
> First of all thanks for a wonderful package that I frequently use.
> 
> I have estimated an ARMA(1,1)-EGARCH(1) model, and was puzzled by the
> outcome for a very long time since I got an insignificant estimate for the
> |z_t-1| term (regular ARCH effects) while the asymmetric parameter in front
> of z_t-1 was indeed statistically significant. My data looks like normal
> financial data.
> 
> I based this on the specifications using the ?ugarchspec function in my
> script where it says:
> 
> *Variance Model (GJR, EGARCH)*
> - assymetry term: gamma1
> 
> By drawing the news impact curves and reviewing my code and plots, I came
> to the conclusion that there was no asymmetry apparent from the data but
> that there indeed should bed regular ARCH effects. By running the code for
> gjrGARCH also, I noticed that this model confirmed my hypothesis.
> 
> Thereby my question:
> Isn't there an error in the instructions? Doesn't gamma1 represent regular
> ARCH effects while alpha1 is the correct leverage parameter representing
> asymmetry?
> 
> Best Regards,
> Joakim
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 


From peter.neumaier at gmail.com  Thu Mar 31 12:50:52 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Thu, 31 Mar 2016 11:50:52 +0100
Subject: [R-SIG-Finance] Remove first two weeks of data in half hourly
	resolution
Message-ID: <CAHDRDJVkLjiCSRdE2rPegazncH898ttjJA0WyaxaWUebVhxLrA@mail.gmail.com>

Hi all,

I am doing some analysis on monthly futures contracts from 2011-2016.
Each monthly contract goes for eight weeks, in half hourly resolution.

I'd like to remove first two weeks of eight weeks history for each monthly
contract.
My approach was to work out the start and end date and cut the 1st two weeks
data off, but problem is that the half hourly resolution is sometimes
incomplete(
i.e. a trading day goes from 7:00am - 4:00pm but sometimes starts at
7:30am).

Any suggestion on how to resolve this? Below a sample trading day in half
hourly:

                    NGFH6.Open NGFH6.High NGFH6.Low NGFH6.Close
NGFH6.Volume NGFH6.WAP NGFH6.hasGaps NGFH6.Count
2016-01-06 07:30:00     0.3395     0.3395    0.3375      0.3380
45   0.33811             0           5
2016-01-06 08:00:00     0.3400     0.3400    0.3387      0.3395
140   0.33928             0          12
2016-01-06 08:30:00     0.3395     0.3395    0.3379      0.3379
70   0.33884             0           5
2016-01-06 09:00:00     0.3379     0.3379    0.3379      0.3379
0   0.33790             0           0
2016-01-06 09:30:00     0.3379     0.3379    0.3379      0.3379
0   0.33790             0           0
2016-01-06 10:00:00     0.3375     0.3380    0.3373      0.3373
230   0.33738             0          14
2016-01-06 10:30:00     0.3376     0.3379    0.3376      0.3379
20   0.33775             0           2
2016-01-06 11:00:00     0.3370     0.3370    0.3370      0.3370
105   0.33700             0           5
2016-01-06 11:30:00     0.3366     0.3366    0.3365      0.3365
65   0.33658             0           4
2016-01-06 12:00:00     0.3370     0.3370    0.3370      0.3370
10   0.33700             0           1
2016-01-06 12:30:00     0.3372     0.3372    0.3361      0.3361
125   0.33686             0           9
2016-01-06 13:00:00     0.3360     0.3360    0.3357      0.3360
225   0.33585             0          17
2016-01-06 13:30:00     0.3357     0.3357    0.3355      0.3355
50   0.33560             0           5
2016-01-06 14:00:00     0.3350     0.3359    0.3350      0.3359
25   0.33554             0           2
2016-01-06 14:30:00     0.3359     0.3359    0.3359      0.3359
0   0.33590             0           0
2016-01-06 15:00:00     0.3352     0.3352    0.3348      0.3352
150   0.33492             0          15
2016-01-06 15:30:00     0.3352     0.3352    0.3334      0.3341
280   0.33364             0          24
2016-01-06 16:00:00     0.3341     0.3375    0.3341      0.3370
145   0.33543             0          17
2016-01-06 16:30:00     0.3380     0.3385    0.3380      0.3385
25   0.33830             0           3

Many Thanks
Peter

	[[alternative HTML version deleted]]


From brian at braverock.com  Thu Mar 31 13:24:04 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 31 Mar 2016 06:24:04 -0500
Subject: [R-SIG-Finance] Remove first two weeks of data in half hourly
 resolution
In-Reply-To: <CAHDRDJVkLjiCSRdE2rPegazncH898ttjJA0WyaxaWUebVhxLrA@mail.gmail.com>
References: <CAHDRDJVkLjiCSRdE2rPegazncH898ttjJA0WyaxaWUebVhxLrA@mail.gmail.com>
Message-ID: <1459423444.7774.63.camel@brian-rcg>

Peter,

You haven't published a reproducible example, and I'm not going to take
the time to write a complete example from scratch.

We use xts subsetting for this type of thing, so I suggest using xts for
your time series (this is always good advice for time series in R).

Here's a partial example to get you started.

#######################

#load some data from the PerformanceAnalytics package
data(edhec)

#check the range
range(index(edhec))

#add 14 days from the start
first(index(edhec))+14

#now assume that you have an object 'z' with  intraday data
range(z)

#check the range of Dates by forcing the index to Date type
range(as.Date(index(z)))

#add 114 days, as before
first(as.Date(index(z)))+14

# now subset by cutting off the first 14 calendar days 
# from the start of the series
zs <- z[paste0(first(as.Date(index(z)))+14,'/')]

#check the range
range(as.Date(index(zs)))

##################

Regards,

Brian
 
-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


On Thu, 2016-03-31 at 11:50 +0100, Peter Neumaier wrote:
> Hi all,
> 
> I am doing some analysis on monthly futures contracts from 2011-2016.
> Each monthly contract goes for eight weeks, in half hourly resolution.
> 
> I'd like to remove first two weeks of eight weeks history for each monthly
> contract.
> My approach was to work out the start and end date and cut the 1st two weeks
> data off, but problem is that the half hourly resolution is sometimes
> incomplete(
> i.e. a trading day goes from 7:00am - 4:00pm but sometimes starts at
> 7:30am).
> 
> Any suggestion on how to resolve this? Below a sample trading day in half
> hourly:
> 
>                     NGFH6.Open NGFH6.High NGFH6.Low NGFH6.Close
> NGFH6.Volume NGFH6.WAP NGFH6.hasGaps NGFH6.Count
> 2016-01-06 07:30:00     0.3395     0.3395    0.3375      0.3380
> 45   0.33811             0           5
> 2016-01-06 08:00:00     0.3400     0.3400    0.3387      0.3395
> 140   0.33928             0          12
> 2016-01-06 08:30:00     0.3395     0.3395    0.3379      0.3379
> 70   0.33884             0           5
> 2016-01-06 09:00:00     0.3379     0.3379    0.3379      0.3379
> 0   0.33790             0           0
> 2016-01-06 09:30:00     0.3379     0.3379    0.3379      0.3379
> 0   0.33790             0           0
> 2016-01-06 10:00:00     0.3375     0.3380    0.3373      0.3373
> 230   0.33738             0          14
> 2016-01-06 10:30:00     0.3376     0.3379    0.3376      0.3379
> 20   0.33775             0           2
> 2016-01-06 11:00:00     0.3370     0.3370    0.3370      0.3370
> 105   0.33700             0           5
> 2016-01-06 11:30:00     0.3366     0.3366    0.3365      0.3365
> 65   0.33658             0           4
> 2016-01-06 12:00:00     0.3370     0.3370    0.3370      0.3370
> 10   0.33700             0           1
> 2016-01-06 12:30:00     0.3372     0.3372    0.3361      0.3361
> 125   0.33686             0           9
> 2016-01-06 13:00:00     0.3360     0.3360    0.3357      0.3360
> 225   0.33585             0          17
> 2016-01-06 13:30:00     0.3357     0.3357    0.3355      0.3355
> 50   0.33560             0           5
> 2016-01-06 14:00:00     0.3350     0.3359    0.3350      0.3359
> 25   0.33554             0           2
> 2016-01-06 14:30:00     0.3359     0.3359    0.3359      0.3359
> 0   0.33590             0           0
> 2016-01-06 15:00:00     0.3352     0.3352    0.3348      0.3352
> 150   0.33492             0          15
> 2016-01-06 15:30:00     0.3352     0.3352    0.3334      0.3341
> 280   0.33364             0          24
> 2016-01-06 16:00:00     0.3341     0.3375    0.3341      0.3370
> 145   0.33543             0          17
> 2016-01-06 16:30:00     0.3380     0.3385    0.3380      0.3385
> 25   0.33830             0           3
> 
> Many Thanks
> Peter
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From gsee000 at gmail.com  Thu Mar 31 13:57:43 2016
From: gsee000 at gmail.com (G See)
Date: Thu, 31 Mar 2016 06:57:43 -0500
Subject: [R-SIG-Finance] Remove first two weeks of data in half hourly
	resolution
In-Reply-To: <1459423444.7774.63.camel@brian-rcg>
References: <CAHDRDJVkLjiCSRdE2rPegazncH898ttjJA0WyaxaWUebVhxLrA@mail.gmail.com>
	<1459423444.7774.63.camel@brian-rcg>
Message-ID: <CA+xi=qaysdMHW_fB_wO5ac23Vb5dcMXXvwmrCDV03=eggDVmdQ@mail.gmail.com>

Brian's example is good if you want to remove the first 14 calendar
days.  If you want to remove the first 14 dates that appear in your
data, it's even simpler

    #create sample data
    x <- .xts(1:1000, .POSIXct(1:1000*60*30))
    # remove 1st 14 days by using a negative with first()
    first(x, "-14 days")

Garrett


On Thu, Mar 31, 2016 at 6:24 AM, Brian G. Peterson <brian at braverock.com> wrote:
> Peter,
>
> You haven't published a reproducible example, and I'm not going to take
> the time to write a complete example from scratch.
>
> We use xts subsetting for this type of thing, so I suggest using xts for
> your time series (this is always good advice for time series in R).
>
> Here's a partial example to get you started.
>
> #######################
>
> #load some data from the PerformanceAnalytics package
> data(edhec)
>
> #check the range
> range(index(edhec))
>
> #add 14 days from the start
> first(index(edhec))+14
>
> #now assume that you have an object 'z' with  intraday data
> range(z)
>
> #check the range of Dates by forcing the index to Date type
> range(as.Date(index(z)))
>
> #add 114 days, as before
> first(as.Date(index(z)))+14
>
> # now subset by cutting off the first 14 calendar days
> # from the start of the series
> zs <- z[paste0(first(as.Date(index(z)))+14,'/')]
>
> #check the range
> range(as.Date(index(zs)))
>
> ##################
>
> Regards,
>
> Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
>
> On Thu, 2016-03-31 at 11:50 +0100, Peter Neumaier wrote:
>> Hi all,
>>
>> I am doing some analysis on monthly futures contracts from 2011-2016.
>> Each monthly contract goes for eight weeks, in half hourly resolution.
>>
>> I'd like to remove first two weeks of eight weeks history for each monthly
>> contract.
>> My approach was to work out the start and end date and cut the 1st two weeks
>> data off, but problem is that the half hourly resolution is sometimes
>> incomplete(
>> i.e. a trading day goes from 7:00am - 4:00pm but sometimes starts at
>> 7:30am).
>>
>> Any suggestion on how to resolve this? Below a sample trading day in half
>> hourly:
>>
>>                     NGFH6.Open NGFH6.High NGFH6.Low NGFH6.Close
>> NGFH6.Volume NGFH6.WAP NGFH6.hasGaps NGFH6.Count
>> 2016-01-06 07:30:00     0.3395     0.3395    0.3375      0.3380
>> 45   0.33811             0           5
>> 2016-01-06 08:00:00     0.3400     0.3400    0.3387      0.3395
>> 140   0.33928             0          12
>> 2016-01-06 08:30:00     0.3395     0.3395    0.3379      0.3379
>> 70   0.33884             0           5
>> 2016-01-06 09:00:00     0.3379     0.3379    0.3379      0.3379
>> 0   0.33790             0           0
>> 2016-01-06 09:30:00     0.3379     0.3379    0.3379      0.3379
>> 0   0.33790             0           0
>> 2016-01-06 10:00:00     0.3375     0.3380    0.3373      0.3373
>> 230   0.33738             0          14
>> 2016-01-06 10:30:00     0.3376     0.3379    0.3376      0.3379
>> 20   0.33775             0           2
>> 2016-01-06 11:00:00     0.3370     0.3370    0.3370      0.3370
>> 105   0.33700             0           5
>> 2016-01-06 11:30:00     0.3366     0.3366    0.3365      0.3365
>> 65   0.33658             0           4
>> 2016-01-06 12:00:00     0.3370     0.3370    0.3370      0.3370
>> 10   0.33700             0           1
>> 2016-01-06 12:30:00     0.3372     0.3372    0.3361      0.3361
>> 125   0.33686             0           9
>> 2016-01-06 13:00:00     0.3360     0.3360    0.3357      0.3360
>> 225   0.33585             0          17
>> 2016-01-06 13:30:00     0.3357     0.3357    0.3355      0.3355
>> 50   0.33560             0           5
>> 2016-01-06 14:00:00     0.3350     0.3359    0.3350      0.3359
>> 25   0.33554             0           2
>> 2016-01-06 14:30:00     0.3359     0.3359    0.3359      0.3359
>> 0   0.33590             0           0
>> 2016-01-06 15:00:00     0.3352     0.3352    0.3348      0.3352
>> 150   0.33492             0          15
>> 2016-01-06 15:30:00     0.3352     0.3352    0.3334      0.3341
>> 280   0.33364             0          24
>> 2016-01-06 16:00:00     0.3341     0.3375    0.3341      0.3370
>> 145   0.33543             0          17
>> 2016-01-06 16:30:00     0.3380     0.3385    0.3380      0.3385
>> 25   0.33830             0           3
>>
>> Many Thanks
>> Peter
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From eyh2 at princeton.edu  Thu Mar 31 20:47:16 2016
From: eyh2 at princeton.edu (Eric Huang)
Date: Thu, 31 Mar 2016 14:47:16 -0400
Subject: [R-SIG-Finance] Passing external regressors to rugarchspec
Message-ID: <CAMFjgEy2B-R3gJmbtmhcrQwOx_W+kv01MheEgxHhxCawoqbSQw@mail.gmail.com>

Hi all,

I have a pair of correlated time series of financial returns, and am using
GARCH(1,1) through rugarch to forecast realized volatilties, which I have
calculated separately. If I would like to include one series's realized
volatilities as an external regressor for the other's GARCH model, do I
need to prelag the realized volatilities before passing it to ugarchspec?

Thanks for the help,

Eric

	[[alternative HTML version deleted]]


