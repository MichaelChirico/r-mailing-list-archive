From patrick at burns-stat.com  Mon Jan  3 11:59:25 2005
From: patrick at burns-stat.com (Patrick Burns)
Date: Mon Jan  3 12:01:16 2005
Subject: [R-sig-finance] spreadsheet addiction
Message-ID: <41D9258D.60907@burns-stat.com>

There's a new page on the Burns Statistics website
http://www.burns-stat.com/pages/Tutor/spreadsheet_addiction.html
that looks at spreadsheets from a quality assurance perspective. It
presents R as a suitable alternative to spreadsheets.  Also there are
several specific problems with Excel that are highlighted, including
the status of statistical functionality in Excel.

Patrick Burns

Burns Statistics
patrick@burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

From matmsh at yahoo.com  Mon Jan  3 13:03:07 2005
From: matmsh at yahoo.com (Shing Hing Man)
Date: Mon Jan  3 13:03:13 2005
Subject: [R-sig-finance] RollGeskeWhaleyOption with maturity time close to 0
Message-ID: <20050103120307.86336.qmail@web52409.mail.yahoo.com>

Hi,
I have used RollGeskeWhaleyOption
from the package fOptions with the following
paremeters. (It is for an American call option
with maturity close to time 0 and a dividend paid
at close to time 0.)


RollGeskeWhaleyOption(S = 90, X = 78, time1 = 0.001,
     Time2 = 0.01, r = 0, D =5, sigma = 0.2)


The returned answer was 12.
Should it be something close to  7 ( 90 - 78 - 5) ?

My version of fOptions is from the tar file
fOptions_200.10058.tar.gz .

Any assistance would be appreciated.

Shing Hing Man


=====
Home page :
  http://uk.geocities.com/matmsh/index.html

From vograno at evafunds.com  Sat Jan 15 00:30:11 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Sat Jan 15 00:30:17 2005
Subject: [R-sig-finance] recursive penalized regression
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A57D8F30@phost015.EVAFUNDS.intermedia.net>

Hi,
 
I have a question which I believe has been discussed a number of times
on both r-sig-finance and r-help, but somehow I am not able to locate
relevant messages. My apologies for bringing it up again.
 
I want to do a univariate no frills autoregression. The major
non-standard requirements are:
1. When estimating model parameters at time t the algorithm can only use
data up to time t.
2. The weights of the past observations should decay with time, e.g
exponentially
3. ability to apply some penalty, e.g. L2 (ridge), L1 (lasso), etc., to
model coefficients.
 
I think that all of these fall under the Kalman Filter title (except
probably for lasso), but a) search for "Kalman Filter" turns up zillions
of messages and it's hard for me to tell their relevance or suitability
for the task at hand and b) maybe some relevant code hides under some
other title. For example I remember reading about a function which
satisfies 1., but as far as I remember it had nothing to do with the
Kalman filters .
 
Thanks in advance for your help,
Vadim

	[[alternative HTML version deleted]]

From arshia22 at yahoo.com  Sun Jan 16 21:22:04 2005
From: arshia22 at yahoo.com (ebashi)
Date: Sun Jan 16 21:22:12 2005
Subject: [R-sig-finance] CGIwithR
Message-ID: <20050116202204.41470.qmail@web81001.mail.yahoo.com>

Dear R users;
I'm trying to use CGIwithR on a linux machine, I have
followed the instructions on the package manual but
still it does not run,
the message that I get is as follows: 
    The requested URL was not found on this server
I used the example trivial, I put trivial.html under
Web directory and trivial.R in cgi-bin directory,
which itself is a subdirectory of Web directory, ( I
have changed the modes of R.cgi and .Rprofile
according to what package says) but i still get
the same message, do you have any tips for me? my
question is that where should for example myscript.R
that is mentioned in the manual, be
placed? (under Web directory or   
under cgi-bin).
besides the path to R and GS, should anything else in
the R.cgi be changed?

many tanx in advance
Sean

From zubin.al.genubi at gmail.com  Sun Jan 23 00:08:25 2005
From: zubin.al.genubi at gmail.com (James Sogi)
Date: Mon Jan 24 08:13:40 2005
Subject: [R-sig-finance] Price change after breakout
Message-ID: <2374a37e050122150864c34b32@mail.gmail.com>

R-Sig Finance List:

May I ask your help  (or where  to look, or who to consult)to find 
the appropriate functions or data set up to reference price on  prior
days, and subsequent days to answer  a question typical of the  query
below   on the data base sample SP mini CME shown below without having
to do separate columns for all combinations of changes over many days.
I was able to use subset or apply for intraday changes  using columns,
but wanted to be able to report changes upon certain conditions by
reference to prior days and subsequent days.  Many thanks.

Query:  What is the change to open tomorrow  after price today 
exceeds yesterday's high when yesterdays close < the day before
yesterdays close.

sample data  ES3.t column is 1= 9:30 2=11:00 3= 2:30 4=4:00
ES3.p is price open at specified time
ES3.jd is julian date.
c1-c4 are changes one bar to the next
oc is change from open to close

        ES3.d ES3.jd ES3.dw ES3.t   ES3.p      c ES3.c1 ES3.c2 ES3.c3
ES3.c4     oc
1  1998-06-11  10388    Thu     1 1321.25   5.00  -6.00  -7.00  -8.00 
 1.75 -21.00
2  1998-06-11  10388    Thu     2 1315.25  -6.00  -7.00  -8.00   1.75 
-3.25 -13.25
3  1998-06-11  10388    Thu     3 1308.25  -7.00  -8.00   1.75  -3.25 
-6.00  -9.50
4  1998-06-11  10388    Thu     4 1300.25  -8.00   1.75  -3.25  -6.00 
15.75  -7.50
5  1998-06-12  10389    Fri     1 1302.00   1.75  -3.25  -6.00  15.75
-14.50   6.50
6  1998-06-12  10389    Fri     2 1298.75  -3.25  -6.00  15.75 -14.50 
 6.75  -4.75
7  1998-06-12  10389    Fri     3 1292.75  -6.00  15.75 -14.50   6.75 
-4.75   8.00
8  1998-06-12  10389    Fri     4 1308.50  15.75 -14.50   6.75  -4.75
-15.25 -12.50
9  1998-06-15  10392    Mon     1 1294.00 -14.50   6.75  -4.75 -15.25 
 8.50 -13.25
10 1998-06-15  10392    Mon     2 1300.75   6.75  -4.75 -15.25   8.50 
 3.25 -11.50
11 1998-06-15  10392    Mon     3 1296.00  -4.75 -15.25   8.50   3.25 
-6.00  -3.50
12 1998-06-15  10392    Mon     4 1280.75 -15.25   8.50   3.25  -6.00 
 8.00   5.75
13 1998-06-16  10393    Tue     1 1289.25   8.50   3.25  -6.00   8.00 
 9.50   5.25
14 1998-06-16  10393    Tue     2 1292.50   3.25  -6.00   8.00   9.50 
10.25  11.50
15 1998-06-16  10393    Tue     3 1286.50  -6.00   8.00   9.50  10.25 
 6.75  27.75
16 1998-06-16  10393    Tue     4 1294.50   8.00   9.50  10.25   6.75 
-3.75  26.50
17 1998-06-17  10394    Wed     1 1304.00   9.50  10.25   6.75  -3.75 
-2.25  13.25
18 1998-06-17  10394    Wed     2 1314.25  10.25   6.75  -3.75  -2.25 
-0.75   0.75
19 1998-06-17  10394    Wed     3 1321.00   6.75  -3.75  -2.25  -0.75 
 1.25  -6.75


-- 
James Sogi
Kona, Hawaii
zubin.al.genubi@g.mail.com

From arshia22 at yahoo.com  Tue Jan 25 21:58:07 2005
From: arshia22 at yahoo.com (ebashi)
Date: Tue Jan 25 21:58:20 2005
Subject: [R-sig-finance] How to make R faster?
Message-ID: <20050125205807.67486.qmail@web81004.mail.yahoo.com>

Dear R users;
I am using R for a project. I have some PHP forms that
pass parameters to R for calculations, and publish the
result in HTML format by CGIwithR. I'm using a Linux
machine and every things work perfectly. However, it
is  too slow, it takes 5 to 10 seconds to run, and
even  if I start R from the Shell it takes the same
amount of time, which is probably due to installing
packages. My first question is that how can i make R
run faster? and second if I am supposed to reduce the
packages which are being loaded at initiation of R,
how can I limit it to only the packages that i want?
and third how can i make R not to get open each time,
and let it sit on the server so that, when i pass
something to it , i get result faster?

Sincerely,
Sean

From spencer.graves at pdf.com  Tue Jan 25 22:26:15 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed Jan 26 02:18:05 2005
Subject: [R-sig-finance] Re: [R] How to make R faster?
In-Reply-To: <20050125205807.67486.qmail@web81004.mail.yahoo.com>
References: <20050125205807.67486.qmail@web81004.mail.yahoo.com>
Message-ID: <41F6B977.3080500@pdf.com>

      My standard algorithm for improving speed is as follows: 

      1.  Identify what takes the most time. 

      2.  Try to find ways in R to speed it up, e.g., converting loops 
to vector operations.  Many tasks in R can be performed in a variety of 
different ways to get the same result but with different time. 

      3.  If that fails, convert the most time consuming part into 
compiled code and link to it. 

      Use "system.time" to time a single expression and "proc.time" to 
store the time at multiple places in your code;  precede any test with 
garbage collection (gc) to reduce variations in the answers. 

      An "R site search" (www.r-project.org -> Search -> "R site 
search") for "timing R" produced 126 hits, the second of which gave 
"system.time";  you might skim the rest for other ideas.  A similar 
search for "compute speed" produced 64 hits, some of which will 
doubtless interest you if you haven't already read them. 

      For more help on this, please be more specific, e.g., following 
the posting guide! "http://www.R-project.org/posting-guide.html". 

      hope this helps.  spencer graves

ebashi wrote:

>Dear R users;
>I am using R for a project. I have some PHP forms that
>pass parameters to R for calculations, and publish the
>result in HTML format by CGIwithR. I'm using a Linux
>machine and every things work perfectly. However, it
>is  too slow, it takes 5 to 10 seconds to run, and
>even  if I start R from the Shell it takes the same
>amount of time, which is probably due to installing
>packages. My first question is that how can i make R
>run faster? and second if I am supposed to reduce the
>packages which are being loaded at initiation of R,
>how can I limit it to only the packages that i want?
>and third how can i make R not to get open each time,
>and let it sit on the server so that, when i pass
>something to it , i get result faster?
>
>Sincerely,
>Sean
>
>______________________________________________
>R-help@stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

From tchur at optushome.com.au  Wed Jan 26 00:07:37 2005
From: tchur at optushome.com.au (Tim Churches)
Date: Wed Jan 26 02:18:05 2005
Subject: [R-sig-finance] Re: [R] How to make R faster?
In-Reply-To: <20050125205807.67486.qmail@web81004.mail.yahoo.com>
References: <20050125205807.67486.qmail@web81004.mail.yahoo.com>
Message-ID: <41F6D139.2010201@optushome.com.au>

ebashi wrote:

>Dear R users;
>I am using R for a project. I have some PHP forms that
>pass parameters to R for calculations, and publish the
>result in HTML format by CGIwithR. I'm using a Linux
>machine and every things work perfectly. However, it
>is  too slow, it takes 5 to 10 seconds to run, and
>even  if I start R from the Shell it takes the same
>amount of time, which is probably due to installing
>packages. My first question is that how can i make R
>run faster? and second if I am supposed to reduce the
>packages which are being loaded at initiation of R,
>how can I limit it to only the packages that i want?
>and third how can i make R not to get open each time,
>and let it sit on the server so that, when i pass
>something to it , i get result faster?
>  
>
Have a look at RSOAP, which does exactly what you suggest and allows you 
to commuicate with the R session via SOAP. I'm sure there are SOAP 
libraries available for PHP. See 
http://research.warnes.net/projects/rzope/rsoap/

Tim C

From andy_liaw at merck.com  Wed Jan 26 00:06:58 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed Jan 26 02:18:05 2005
Subject: [R-sig-finance] RE: [R] How to make R faster?
Message-ID: <3A822319EB35174CA3714066D590DCD50994E5B3@usrymx25.merck.com>

A few things to add to what Spencer said:

- Please give more info about your setup, as the posting guide asks you to
(e.g., R version, OS [which Linux distro and which release?], hardware).
These things matter!  As an example, the time it takes to start an R process
was dramatically reduced since R-2.0.0.  If you are using older version, you
need to upgrade.

- See the example section of ?Startup, which has an example of how to
specify packages to be loaded at startup.

- There's a section on profiling R code in the `Writing R Extensions'
manual, that may help you pinpoint the bottleneck.

- Sometimes re-thinking the organization of the computation or algorithm can
make a huge difference.  I remember reading in an old computing book the
staggering difference between FFT and doing the computation the na?ve way.

Andy

> From: Spencer Graves
> 
>       My standard algorithm for improving speed is as follows: 
> 
>       1.  Identify what takes the most time. 
> 
>       2.  Try to find ways in R to speed it up, e.g., 
> converting loops 
> to vector operations.  Many tasks in R can be performed in a 
> variety of 
> different ways to get the same result but with different time. 
> 
>       3.  If that fails, convert the most time consuming part into 
> compiled code and link to it. 
> 
>       Use "system.time" to time a single expression and 
> "proc.time" to 
> store the time at multiple places in your code;  precede any 
> test with 
> garbage collection (gc) to reduce variations in the answers. 
> 
>       An "R site search" (www.r-project.org -> Search -> "R site 
> search") for "timing R" produced 126 hits, the second of which gave 
> "system.time";  you might skim the rest for other ideas.  A similar 
> search for "compute speed" produced 64 hits, some of which will 
> doubtless interest you if you haven't already read them. 
> 
>       For more help on this, please be more specific, e.g., following 
> the posting guide! "http://www.R-project.org/posting-guide.html". 
> 
>       hope this helps.  spencer graves
> 
> ebashi wrote:
> 
> >Dear R users;
> >I am using R for a project. I have some PHP forms that
> >pass parameters to R for calculations, and publish the
> >result in HTML format by CGIwithR. I'm using a Linux
> >machine and every things work perfectly. However, it
> >is  too slow, it takes 5 to 10 seconds to run, and
> >even  if I start R from the Shell it takes the same
> >amount of time, which is probably due to installing
> >packages. My first question is that how can i make R
> >run faster? and second if I am supposed to reduce the
> >packages which are being loaded at initiation of R,
> >how can I limit it to only the packages that i want?
> >and third how can i make R not to get open each time,
> >and let it sit on the server so that, when i pass
> >something to it , i get result faster?
> >
> >Sincerely,
> >Sean
> >
> >______________________________________________
> >R-help@stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >  
> >
> 
> 
> ______________________________________________
> R-help@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>

From johnn at neurionpharma.com  Wed Jan 26 18:35:14 2005
From: johnn at neurionpharma.com (John Nicholas)
Date: Thu Jan 27 05:41:04 2005
Subject: [R-sig-finance] singluar spectrum analysis/PCA/EVD
Message-ID: <20050126173513.IMHJ2104.mm-ismta3.bizmailsrvcs.net@jbn>

Hi,

 

I have been doing time series EVD using decevf in pastecs. Does anyone have
code, or can point me to code,

that will do forecasts of the eigenvectors? Does anyone have code to do SSA?

 

Thanks in advance.

 

John

 

 

 

John B. Nicholas, Ph.D.   

Associate Director, Computational Drug Design 

Neurion Pharmaceuticals

180 N. Vinedo Avenue 

Pasadena, CA 91107

 <mailto:91107johnn@neurionpharma.com> johnn@neurionpharma.com 

Phone: 626-685-5964 

Fax: 626-685-5983

 


	[[alternative HTML version deleted]]

From arshia22 at yahoo.com  Fri Jan 28 21:30:53 2005
From: arshia22 at yahoo.com (ebashi)
Date: Fri Jan 28 21:31:02 2005
Subject: [R-sig-finance] R for CGI
Message-ID: <20050128203053.93820.qmail@web81003.mail.yahoo.com>

Dear R Users;
Perl is the common language to write CGI scripts which
handle Forms. My question is that can R be as fast as
perl 
to do the same job(with using CGIwithR package). Is it
an optimal solution to connect R directly to a
commercial HTML webpages,
Sincerely,
Sean

From wojciech.slusarski at gmail.com  Wed Feb  9 01:06:31 2005
From: wojciech.slusarski at gmail.com (=?UTF-8?Q?Wojciech_=C5=9Alusarski?=)
Date: Wed Feb  9 01:06:40 2005
Subject: [R-sig-finance] APARCH residuals and fitted values
Message-ID: <5e64e5be050208160628f2fe23@mail.gmail.com>

I know that, there has already been a question about that, but I am
deep in trouble at the moment, because I need to do volatility
forecasts of one stock index and as far as I am concerned, those taken
from GARCH models are not the best when compared with the realized
volatility. Is there maybe any way to get those values through
aparchSim() or any other?  If anyone faced this problem (I am sure
that, there is lot of people) and found a solution, I would be very
glad for any advice.

Best regards
Wojciech Slusarski

From brett at scmi.com  Fri Feb 11 17:37:49 2005
From: brett at scmi.com (Brett F. Sumsion)
Date: Sat Feb 12 02:20:06 2005
Subject: [R-sig-finance] Multivariate GARCH
Message-ID: <200502111637.j1BGbmnc061637@scmi.com>

Dr. Burns,
 
I have read your procedure posted on the internet for using univariate garch
estimates to form a multivariate result.  I am a new to this stuff and just
learning. I follow the procedure very well until I get to the end of step 5,
where you need to "rotate" the diagonal variance matrix back into asset
co-ordinates.  I don't understand what this means? Can you clarify.
 
Step six appears to describing the same procedure outlined in step 5, is
that the case?  I appreciate any insight you can provide.  I have attached
the post.
 
Thanks,
 
Brett
 
 
 
Below I will outline a method of getting multivariate GARCH estimates
by using only univariate GARCH estimates.  I actually did it (years ago)
not for lack of a multivariate GARCH estimator, but to get estimates for
large problems (that is, a large number of assets) in a reasonable amount
of time.  For being ad hoc, it performs remarkably well.
 
Here is the recipe.  Assume there are n observations (dates) for each of
the p assets.
 
Step 1)  Perform a univariate GARCH estimation on each asset.
 
Step 2)  Form the standardized residuals of all of the assets.  This is 
an n by p
matrix where each value theoretically has mean 0 and variance 1.
 
Step 3)  Perform a principal component rotation on the standardized 
residuals.
 
Step 4)  Perform a univariate GARCH estimate on each of the principal
components.
 
Step 5)  At each point in time we have a variance for each of the principal
components.  If we cross our fingers real hard, we can assume that there is
no correlation between the principal components at each of the times.  (On
average throughout the sample period, this is true, but it is very 
doubtful that
it is always true.)
 
With our assumption the variance matrix for the principal components at a
point in time is diagonal.  Rotate this diagonal matrix back into asset
co-ordinates.
 
Step 6)  The end result of step 5 is conceptually the correlation matrix 
of the
assets at the point in time.  In actuality the diagonals will not all be 
1.  Perform
the transformation of a variance matrix into a correlation matrix on the 
result
of step 5.  (This may or may not undo some of the damage from the assumption
of constant zero correlation of the principal components.)
 
Step 7)  Scale the correlation matrix created in step 6 by the variances 
estimated
in step 1 to arrive at the estimate of the variance matrix at a point in 
time.
 
 
Predictions are straightforward -- just predict the principal component 
GARCH
models, do the transformation into assets, then predict the asset GARCH 
models
and put them together.
 
Patrick Burns
 
Burns Statistics
patrick at burns-stat.com
<https://stat.ethz.ch/mailman/listinfo/r-sig-finance> 
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

 

 

Brett F. Sumsion, CFA

Strategis Financial Group, Inc.

(800) 279-3377

brett@strategisfinancial.com

 


	[[alternative HTML version deleted]]

From uofiowa at gmail.com  Wed Feb 16 16:06:14 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Wed Feb 16 16:06:22 2005
Subject: [R-sig-finance] nearby
Message-ID: <3f87cc6d050216070653a7e6ec@mail.gmail.com>

In Splus there is a function called "nearby" (description below). Is
there an equivalent utility in R?

Futures Nearby Creation Function 

DESCRIPTION: 
Create a nearby series from a multivariate time series representing
multiple futures  contracts.

USAGE: 
nearby(x, rule, contracts)  

REQUIRED ARGUMENTS: 
<b>x </b>
multivariate time series containing futures prices for the contracts. 
<b>rule</b> 
rule giving the roll date (last date to use each contract) from one
futures contract  to the next, relative to the beginning of the
contract month. This can be given as a  time span or relative time
object, or a character string which can be coerced into a  relative
time object.
<b>contracts</b> 
the contract months for the columns of the time series, given as
character strings  of the form "F95", or "F1995", where the first
letter is the month code and the  remainder is the year, and where
two?digit years are converted to four?digit years  using
options("time.century"). These should be in ascending order.

VALUE: 
a single?column time series containing the specified nearby series. 

DETAILS: 
The series is generated with the following steps. First, the contract
months are  converted to dates of the first of the month, e.g. Z98
becomes December 1, 1998. Then  the roll rule is added to each date,
to calculate the last day each column of the data set  should be used.
The time series positions and the end dates are then passed to the cut
 function to determine which column is needed for each output date,
and these data  values are subscripted from x and returned. NA will be
the result for positions that have  no valid column data.

SEE ALSO: 
timeRelative, timeSeries 

EXAMPLES: 
# make a 5?column time series  
x <? timeSeries(data=matrix(1:750, ncol=5),      
         pos=timeDate("1/1/1995", format="%a %02m/%02d/%Y")+1:150)  
# make a nearby series, assuming this are Feb?June 1995 contracts (ignori 
# the fact that there should be NAs in the matrix), rolling on the 3rd  
# Friday of the month before the contract month  
nearby(x, timeRelative("?1mth ?1day +3fri"), 
         paste(c("G", "H", "J", "K", "M"), 1995, sep=""))

From davidr at rhotrading.com  Wed Feb 16 19:29:12 2005
From: davidr at rhotrading.com (davidr@rhotrading.com)
Date: Wed Feb 16 19:29:26 2005
Subject: [R-sig-finance] nearby
Message-ID: <12AE52872B5C5348BE5CF47C707FF53A50245B@rhosvr02.rhotrading.com>

Even if this were available, I wouldn't use it.
This method will give you jumps when the contracts roll
(for almost all products.)
I would roll my own, blending from the old to the new over some period to 
smooth out the jumps. This results in more realistic volatilities and 
correlations.
At least, that's what I've been doing for 20 years.

David Reiner

-----Original Message-----
From: Omar Lakkis [mailto:uofiowa@gmail.com] 
Sent: Wednesday, February 16, 2005 9:06 AM
To: r-sig-finance@stat.math.ethz.ch
Subject: [R-sig-finance] nearby

In Splus there is a function called "nearby" (description below). Is
there an equivalent utility in R?

Futures Nearby Creation Function 

DESCRIPTION: 
Create a nearby series from a multivariate time series representing
multiple futures  contracts.

USAGE: 
nearby(x, rule, contracts)  

REQUIRED ARGUMENTS: 
<b>x </b>
multivariate time series containing futures prices for the contracts. 
<b>rule</b> 
rule giving the roll date (last date to use each contract) from one
futures contract  to the next, relative to the beginning of the
contract month. This can be given as a  time span or relative time
object, or a character string which can be coerced into a  relative
time object.
<b>contracts</b> 
the contract months for the columns of the time series, given as
character strings  of the form "F95", or "F1995", where the first
letter is the month code and the  remainder is the year, and where
two?digit years are converted to four?digit years  using
options("time.century"). These should be in ascending order.

VALUE: 
a single?column time series containing the specified nearby series. 

DETAILS: 
The series is generated with the following steps. First, the contract
months are  converted to dates of the first of the month, e.g. Z98
becomes December 1, 1998. Then  the roll rule is added to each date,
to calculate the last day each column of the data set  should be used.
The time series positions and the end dates are then passed to the cut
 function to determine which column is needed for each output date,
and these data  values are subscripted from x and returned. NA will be
the result for positions that have  no valid column data.

SEE ALSO: 
timeRelative, timeSeries 

EXAMPLES: 
# make a 5?column time series  
x <? timeSeries(data=matrix(1:750, ncol=5),      
         pos=timeDate("1/1/1995", format="%a %02m/%02d/%Y")+1:150)  
# make a nearby series, assuming this are Feb?June 1995 contracts (ignori 
# the fact that there should be NAs in the matrix), rolling on the 3rd  
# Friday of the month before the contract month  
nearby(x, timeRelative("?1mth ?1day +3fri"), 
         paste(c("G", "H", "J", "K", "M"), 1995, sep=""))

_______________________________________________
R-sig-finance@stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance

From wojciech.slusarski at gmail.com  Thu Feb 17 20:14:30 2005
From: wojciech.slusarski at gmail.com (=?UTF-8?Q?Wojciech_=C5=9Alusarski?=)
Date: Thu Feb 17 20:14:40 2005
Subject: [R-sig-finance] Computing implied volatility using fOptions
Message-ID: <5e64e5be05021711144c8ffecd@mail.gmail.com>

Hello,
I have calculated the implied volatility, for the whole history of
option quotes on WIG20 stock index on Warsaw Stock Exchange. The thing
that is wondering me is that for some particular days I get volatility
nearly 0 (e.g. 3.12236893483001e-11). Is it happening because the
option was badly priced those thays (in comparison to Black-Scholes
price) or is it a problem of the algorithm. I am usin the
GBSVolatility() function with settings:

tol <- 10^(-10)
maxiter <- 100000

Are those values good for that, or should I use some other values.

Best regards,
Wojtek

From ml2 at ametrano.net  Fri Feb 18 18:42:12 2005
From: ml2 at ametrano.net (Ferdinando Ametrano)
Date: Fri Feb 18 18:41:37 2005
Subject: [R-sig-finance] what is the R equivalent of S+ Finmetrics
In-Reply-To: <5e64e5be05021711144c8ffecd@mail.gmail.com>
References: <5e64e5be05021711144c8ffecd@mail.gmail.com>
Message-ID: <6.2.1.2.0.20050218184003.04cc9e88@mail.ametrano.net>

Hi all

sorry for being so naif, but what is the R equivalent of S+ Finmetrics?
Googling around I've found Rmetrics. Is Rmetrics the best candidate?

thank you in advance for your attention

ciao -- Nando

From davidr at rhotrading.com  Fri Feb 18 20:29:33 2005
From: davidr at rhotrading.com (davidr@rhotrading.com)
Date: Fri Feb 18 20:29:41 2005
Subject: [R-sig-finance] Computing implied volatility using fOptions
Message-ID: <12AE52872B5C5348BE5CF47C707FF53A5024A3@rhosvr02.rhotrading.com>

Seems excessive to me. Usually implied vol calcs converge in relatively few iterations with a simple NR solver. Given the accuracy and precision of the option prices, I wouldn't ask for such precision in the implieds.
Chances are you have some bad prices, which is not unusual even in very active markets. You should probably concentrate on the out-of-the-money
options, since they usually give more relevant information.

(BTW, I looked on Bloomberg for these options, and it says there are no options in WIG20, either on the cash index or on the futures. Are these OTC's? If so, then, somewhat different cautions may apply.)

David Reiner

-----Original Message-----
From: Wojciech ?lusarski [mailto:wojciech.slusarski@gmail.com] 
Sent: Thursday, February 17, 2005 1:15 PM
To: r-sig-finance@stat.math.ethz.ch
Subject: [R-sig-finance] Computing implied volatility using fOptions

Hello,
I have calculated the implied volatility, for the whole history of
option quotes on WIG20 stock index on Warsaw Stock Exchange. The thing
that is wondering me is that for some particular days I get volatility
nearly 0 (e.g. 3.12236893483001e-11). Is it happening because the
option was badly priced those thays (in comparison to Black-Scholes
price) or is it a problem of the algorithm. I am usin the
GBSVolatility() function with settings:

tol <- 10^(-10)
maxiter <- 100000

Are those values good for that, or should I use some other values.

Best regards,
Wojtek

_______________________________________________
R-sig-finance@stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance

From davidr at rhotrading.com  Fri Feb 18 20:36:42 2005
From: davidr at rhotrading.com (davidr@rhotrading.com)
Date: Fri Feb 18 20:36:50 2005
Subject: [R-sig-finance] Computing implied volatility using fOptions
Message-ID: <12AE52872B5C5348BE5CF47C707FF53A5024A4@rhosvr02.rhotrading.com>

I see by looking at the exchange's website that there are options on the index. - dlr

-----Original Message-----
From: David Reiner <davidr@rhotrading.com> 
Sent: Friday, February 18, 2005 1:30 PM
To: Wojciech ?lusarski; r-sig-finance@stat.math.ethz.ch
Subject: RE: [R-sig-finance] Computing implied volatility using fOptions

 (BTW, I looked on Bloomberg for these options, and it says there are no options in WIG20, either on the cash index or on the futures. Are these OTC's? If so, then, somewhat different cautions may apply.)

David Reiner

From wojciech.slusarski at gmail.com  Fri Feb 18 20:58:52 2005
From: wojciech.slusarski at gmail.com (Wojciech Slusarski)
Date: Fri Feb 18 20:59:05 2005
Subject: [R-sig-finance] Computing implied volatility using fOptions
In-Reply-To: <12AE52872B5C5348BE5CF47C707FF53A5024A3@rhosvr02.rhotrading.com>
References: <12AE52872B5C5348BE5CF47C707FF53A5024A3@rhosvr02.rhotrading.com>
Message-ID: <5e64e5be05021811586c126cb5@mail.gmail.com>

Those options are traded on Warsaw Stock Exchange since 22.09.2003. I
have calculated all historical implied volatilities and try to compare
them with volatility forecasts. This is a very flat market, sometimes
there are only few transactions, that's why the prices sometimes are
really bad and probably that's the reason why I get such strange
implied volatilities. Unfourtunately, because of that I have problem
with comparison of those implied volatilities with volatilities
forecasts, because each observation like that in time series is
seriuosly changing the value of any forecast accuracy measure. Below I
enclose a link to the page of Warsaw Stock Exchange describing the
standard of the options:

http://www.gpw.com.pl/gpw_e.asp?cel=e_papiery&k=261&n=26&i=/derivatives/options/options_WIG20

Best regards,
Wojtek




On Fri, 18 Feb 2005 13:29:33 -0600, davidr@rhotrading.com
<davidr@rhotrading.com> wrote:
> Seems excessive to me. Usually implied vol calcs converge in relatively few iterations with a simple NR solver. Given the accuracy and precision of the option prices, I wouldn't ask for such precision in the implieds.
> Chances are you have some bad prices, which is not unusual even in very active markets. You should probably concentrate on the out-of-the-money
> options, since they usually give more relevant information.
> 
> (BTW, I looked on Bloomberg for these options, and it says there are no options in WIG20, either on the cash index or on the futures. Are these OTC's? If so, then, somewhat different cautions may apply.)
> 
> David Reiner
> 
> -----Original Message-----
> From: Wojciech ?lusarski [mailto:wojciech.slusarski@gmail.com]
> Sent: Thursday, February 17, 2005 1:15 PM
> To: r-sig-finance@stat.math.ethz.ch
> Subject: [R-sig-finance] Computing implied volatility using fOptions
> 
> Hello,
> I have calculated the implied volatility, for the whole history of
> option quotes on WIG20 stock index on Warsaw Stock Exchange. The thing
> that is wondering me is that for some particular days I get volatility
> nearly 0 (e.g. 3.12236893483001e-11). Is it happening because the
> option was badly priced those thays (in comparison to Black-Scholes
> price) or is it a problem of the algorithm. I am usin the
> GBSVolatility() function with settings:
> 
> tol <- 10^(-10)
> maxiter <- 100000
> 
> Are those values good for that, or should I use some other values.
> 
> Best regards,
> Wojtek
> 
> _______________________________________________
> R-sig-finance@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> 
>

From edd at debian.org  Sat Feb 19 02:00:19 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat Feb 19 02:00:30 2005
Subject: [R-sig-finance] what is the R equivalent of S+ Finmetrics
In-Reply-To: <6.2.1.2.0.20050218184003.04cc9e88@mail.ametrano.net>
References: <5e64e5be05021711144c8ffecd@mail.gmail.com>
	<6.2.1.2.0.20050218184003.04cc9e88@mail.ametrano.net>
Message-ID: <16918.36771.918179.927459@basebud.nulle.part>


On 18 February 2005 at 18:42, Ferdinando Ametrano wrote:
| sorry for being so naif, but what is the R equivalent of S+ Finmetrics?
| Googling around I've found Rmetrics. Is Rmetrics the best candidate?

Yup, and pretty much the only one :)   

Before Diethelm came out with Rmetrics, we only had isolated bits and pieces,
e.g. some code was in the tseries package.  Rmetrics added a lot of code and
documentation, and also provide more consistent wrapper for existing code
(i.e. similar interfaces to ARIMA and GARCH). There are some areas which
little or missing code, but then that isn't that different in QuantLib :)

Best regards, Dirk

-- 
Better to have an approximate answer to the right question than a precise 
answer to the wrong question.  --  John Tukey as quoted by John Chambers

From kahra at mpsgr.it  Mon Feb 21 10:27:40 2005
From: kahra at mpsgr.it (Kahra Hannu)
Date: Mon Feb 21 10:26:56 2005
Subject: [R-sig-finance] Computing implied volatility using fOptions
Message-ID: <C9FC71F7E9356F40AFE2ACC2099DE14722526A@MAILSERVER-B.mpsgr.it>

Wojciech,

in the early 90s I wrote a working paper, where I studied the behavior of the implicit volatilities of the Finnish FOX index options (as a function of time to expiry). In some cases I got similar results. In those cases time to expiry was commonly less than a week. I reasoned that the prices implied negative volatilities. The market was quite young, inefficient and not very liquid.

Regards,
Hannu

Hannu Kahra 
Progetti Speciali 
Monte Paschi Asset Management SGR S.p.A. 
Via San Vittore, 37
IT-20123 Milano, Italia 

Tel.: +39 02 43828 754 
Mobile: +39 333 876 1558 
Fax: +39 02 43828 247 
E-mail: kahra@mpsgr.it 
Web: www.mpsam.it 



-----Original Message-----
From: r-sig-finance-bounces@stat.math.ethz.ch
[mailto:r-sig-finance-bounces@stat.math.ethz.ch]On Behalf Of Wojciech
Slusarski
Sent: Thursday, February 17, 2005 8:15 PM
To: r-sig-finance@stat.math.ethz.ch
Subject: [R-sig-finance] Computing implied volatility using fOptions


Hello,
I have calculated the implied volatility, for the whole history of
option quotes on WIG20 stock index on Warsaw Stock Exchange. The thing
that is wondering me is that for some particular days I get volatility
nearly 0 (e.g. 3.12236893483001e-11). Is it happening because the
option was badly priced those thays (in comparison to Black-Scholes
price) or is it a problem of the algorithm. I am usin the
GBSVolatility() function with settings:

tol <- 10^(-10)
maxiter <- 100000

Are those values good for that, or should I use some other values.

Best regards,
Wojtek

_______________________________________________
R-sig-finance@stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance

From mvida at mitre.org  Fri Feb 25 19:02:14 2005
From: mvida at mitre.org (Melanie Vida)
Date: Fri Feb 25 19:02:32 2005
Subject: [R-sig-finance] Outlier Threshold for Temporal Analysis of variable
	x
Message-ID: <421F6826.9080308@mitre.org>

For a financial data set with large variance, I'm trying to find the 
outlier threshold of one variable "x" over a two year period. I 
qqplot(x2001, x2002) and found a normal distribution. The latter part of 
the normal distribution did not look linear though. Is there a best way 
to find the outlier threshold of this variable from 2001 and 2002  in R?

From mvida at mac.com  Fri Feb 25 17:53:44 2005
From: mvida at mac.com (Melanie Vida)
Date: Sat Feb 26 02:07:57 2005
Subject: [R-sig-finance] Outlier Threshold
Message-ID: <13805569.1109350424560.JavaMail.mvida@mac.com>

I am trying to do a temporal analysis of the same variable "x" over a period of 2 years. I did a qqplot(x) and discovered an almost normal relationship between the variable x over 2001 and 2002.
However, there were some outliers in the latter half of the qqplot. To select an outlier threshold what is the recommended way when you have financial data with large variance?

From Achim.Zeileis at wu-wien.ac.at  Sat Feb 26 04:30:58 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Sat Feb 26 04:31:08 2005
Subject: [R-sig-finance] Outlier Threshold
In-Reply-To: <13805569.1109350424560.JavaMail.mvida@mac.com>
References: <13805569.1109350424560.JavaMail.mvida@mac.com>
Message-ID: <Pine.LNX.4.58.0502260428280.26558@thorin.ci.tuwien.ac.at>

This is your fourth post today, again with only a marginally modified
question. Please stop sending it. You won't get better answers if you
annoy readers of various mailing lists by asking the same bad question
over and over again.
Z

On Fri, 25 Feb 2005, Melanie Vida wrote:

> I am trying to do a temporal analysis of the same variable "x" over a period of 2 years. I did a qqplot(x) and discovered an almost normal relationship between the variable x over 2001 and 2002.
> However, there were some outliers in the latter half of the qqplot. To select an outlier threshold what is the recommended way when you have financial data with large variance?
>
> _______________________________________________
> R-sig-finance@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>

From patrick at burns-stat.com  Tue Mar  1 19:46:23 2005
From: patrick at burns-stat.com (Patrick Burns)
Date: Tue Mar  1 19:47:31 2005
Subject: [R-sig-finance] Multivariate GARCH with only univariate estimation
Message-ID: <4224B87F.9020203@burns-stat.com>

Partially in response to the question that was asked here a couple weeks
ago, the following paper now exists.


In the working papers section of the Burns Statistics website 
http://www.burns-stat.com/
is the following:

                      Multivariate GARCH with Only Univariate Estimation

Abstract:  This brief note offers an explicit algorithm for a 
multivariate GARCH model,
called PC-GARCH, that requires only univariate GARCH estimation.  It is 
suitable for
problems with hundreds or even thousands of variables.  PC-GARCH is 
compared to
two other techniques of getting multivariate GARCH using univariate 
estimates.

Patrick Burns

Burns Statistics
patrick@burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com

From rbertolusso at yahoo.com  Wed Mar 23 22:12:21 2005
From: rbertolusso at yahoo.com (Roberto Bertolusso)
Date: Wed Mar 23 22:09:03 2005
Subject: [R-sig-finance] Error in unitrootTest
Message-ID: <1111612342.9479.5.camel@localhost>

Hello, I am getting the following error message from unitrootTest.
Do you have any clue of what could be wrong.

Details: AMD64 (x86_64) Gentoo Linux system.


library(fSeries)
kmodel <- list(ar=c(.3,0,0,0,0.7,-.4*.7),d=1)
x=armaSim(nobs,model=kmodel)
unitrootTest(x,trend="c",statistic="t",method="adf",lags=2)
Error in file(file, "r") : unable to open connection
In addition: Warning message: 
cannot open file `library/fSeries/libs/.urc1.tab' 


Thank you very much
Roberto
-- 
Roberto Bertolusso <rbertolusso@yahoo.com>

From rahul.maniar at feri.de  Thu Mar 24 12:01:41 2005
From: rahul.maniar at feri.de (Maniar, Rahul)
Date: Thu Mar 24 12:02:56 2005
Subject: [R-sig-finance] FastICA
Message-ID: <A05FF736A3208846B04D74334040A7B9022DAFDC@feriex.FERI.DE>

Hi,

I want to use FastICA algorithm on a set of performance data. Can anybody
tell whether it requires pre-whitening of data or we can use raw data?

Thanks 

Rahul Maniar

	[[alternative HTML version deleted]]

From davidr at rhotrading.com  Thu Mar 31 23:14:26 2005
From: davidr at rhotrading.com (davidr@rhotrading.com)
Date: Thu Mar 31 23:14:47 2005
Subject: [R-sig-finance] RE: [R] Bloomberg data import SOLVED
Message-ID: <12AE52872B5C5348BE5CF47C707FF53A502B1B@rhosvr02.rhotrading.com>

Together with Enrique's running start and Prasad's work, we figured out
how to get tick data and bulk data from Bloomberg into R. Here is a code
snippet which builds on Enrique's.

----------------------------
require("RDCOMClient")

blCon <<- try(blCon <- COMCreate("Bloomberg.Data.1"), silent=TRUE)
# Always check the class of blCon before proceeding!

# First tick data

ticker <- "IBM US Equity"
fields <- c("Last Price","Volume")

comFrom <- new("COMDate",38442.4583333333)
comTo <- new("COMDate",38442.58247696760)
z <- as.integer(0)

histData <- try(blCon$BLPGetHistoricalData(Security=ticker,
Fields=fields, StartDate=comFrom, EndDate=comTo, BarSize=z))

# Notes:
# Passing in just a 0 instead of an int 0 (as z) crashes Rgui
# For tick data, only one ticker is allowed in each call.
# Beware of asking for a long date range; tick data can be very
voluminous.
# I'm sure someone can do some R-magic to fix my start and end datetimes
(please!)

# Bulk data is just like getting prices, except for the return object
being more complex
tickers <- c("TYM5 Comdty", "USM5 Comdty")
fields <- c("FUT_DELIVERABLE_BONDS", "FUT_DLVRBLE_BNDS_CUSIPS")
bulkData <- try(blCon$BlpSubscribe(Security=tickers, Fields=fields))
----------------------------

Note that my original idea about GetHistoricalData was wrong since that
isn't a function. (At least I couldn't get it to work.)

As a last note, it would be very nice if RDCOMClient were directly
available from CRAN so we could use install.packages, etc. (hint, hint!)

Enjoy,
David L. Reiner

p.s. I know cross-posting is discouraged, but I thought some people
might be looking for this information on r-sig-finance someday.

