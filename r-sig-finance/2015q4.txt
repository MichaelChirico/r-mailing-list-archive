From grgkumar4 at gmail.com  Thu Oct  1 03:16:52 2015
From: grgkumar4 at gmail.com (George Kumar)
Date: Wed, 30 Sep 2015 18:16:52 -0700
Subject: [R-SIG-Finance] How to get data from another source when the first
	one fails...
Message-ID: <CAJDeD2rDR0iOMU=4BH6zX13Ym0rHiibo6Q0jV79rT=f08pSapg@mail.gmail.com>

Hi all,

I use following command to make getSymbols (from quantmod package) get data
from locally stored csv files.

setDefaults(getSymbols,src='csv')

My problem is that if the data is not found locally, I want it to get it
from yahoo/google. How to go about doing this. If setDefaults allowed
multiple sources, it would have been possible. Something like the following:

setDefaults(getSymbols,src='csv yahoo')

Please let me know how this can be done.

Thanks.
George

	[[alternative HTML version deleted]]


From playtawin at yandex.com  Thu Oct  1 18:29:09 2015
From: playtawin at yandex.com (Evgeny Laba)
Date: Thu, 1 Oct 2015 19:29:09 +0300
Subject: [R-SIG-Finance] Rugarch non convergent forecasts.
Message-ID: <B8508995-E04D-46E6-A71E-9B38BF669900@yandex.com>

Hi everybody,

I?m doing some VaR backtesting with garch modeling applied to stocks using rugarch package, my backtesting period is 10 years and my moving.window length is 252 & refitting parameter is one, so unsurprisingly that setup and forecast length result in some few non converged samples in some series (no more than 100), so my question is what is the best practice, rule of thumb etc., in case if I want to fill these gaps??? Changing refitting parameter to higher number, say 30 or 50 eliminate non convergence, but of cause the forecasting result is significantly different in that case?     

From brian at braverock.com  Thu Oct  1 18:37:00 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 01 Oct 2015 11:37:00 -0500
Subject: [R-SIG-Finance] Rugarch non convergent forecasts.
In-Reply-To: <B8508995-E04D-46E6-A71E-9B38BF669900@yandex.com>
References: <B8508995-E04D-46E6-A71E-9B38BF669900@yandex.com>
Message-ID: <1443717420.4432.39.camel@brian-rcg>

On Thu, 2015-10-01 at 19:29 +0300, Evgeny Laba wrote:
> I?m doing some VaR backtesting with garch modeling applied to stocks
> using rugarch package, my backtesting period is 10 years and my
> moving.window length is 252 & refitting parameter is one, so
> unsurprisingly that setup and forecast length result in some few non
> converged samples in some series (no more than 100), so my question is
> what is the best practice, rule of thumb etc., in case if I want to
> fill these gaps??? Changing refitting parameter to higher number, say
> 30 or 50 eliminate non convergence, but of cause the forecasting result
> is significantly different in that case?  

I would generally suggest a larger rolling window, or an expanding
window, for your estimates.  Windowing effects can be quite severe on
daily data, so for volatility forecasts I would tend towards larger data
sets rather than smaller ones.

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From josh.m.ulrich at gmail.com  Fri Oct  2 04:04:00 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 1 Oct 2015 21:04:00 -0500
Subject: [R-SIG-Finance] How to get data from another source when the
 first one fails...
In-Reply-To: <CAJDeD2rDR0iOMU=4BH6zX13Ym0rHiibo6Q0jV79rT=f08pSapg@mail.gmail.com>
References: <CAJDeD2rDR0iOMU=4BH6zX13Ym0rHiibo6Q0jV79rT=f08pSapg@mail.gmail.com>
Message-ID: <CAPPM_gSebnwbiHLWVis_J8Ncjuj_qMVmW3i2gbrp_ZyaTEqsdg@mail.gmail.com>

On Wed, Sep 30, 2015 at 8:16 PM, George Kumar <grgkumar4 at gmail.com> wrote:
> Hi all,
>
> I use following command to make getSymbols (from quantmod package) get data
> from locally stored csv files.
>
> setDefaults(getSymbols,src='csv')
>
> My problem is that if the data is not found locally, I want it to get it
> from yahoo/google. How to go about doing this. If setDefaults allowed
> multiple sources, it would have been possible. Something like the following:
>
> setDefaults(getSymbols,src='csv yahoo')
>
> Please let me know how this can be done.
>
Write your own getSymbols function, e.g. getSymbols.csv2yahoo.  Then
wrap your call to getSymbols.csv in a try or tryCatch call.  If the
getSymbols.csv call fails, you can then call getSymbols.yahoo.

> Thanks.
> George
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From playtawin at yandex.com  Fri Oct  2 15:23:18 2015
From: playtawin at yandex.com (Evgeny Laba)
Date: Fri, 2 Oct 2015 16:23:18 +0300
Subject: [R-SIG-Finance] Rugarch non convergent forecasts.
In-Reply-To: <1443717420.4432.39.camel@brian-rcg>
References: <B8508995-E04D-46E6-A71E-9B38BF669900@yandex.com>
	<1443717420.4432.39.camel@brian-rcg>
Message-ID: <DDF6D2DF-E3FC-4AB2-85D0-C7AECA014735@yandex.com>

Brian thanks for reply, I?m leaning towards your suggestion by expanding window length for non converged samples.

And here I got some more specific questions about rugarch package. Does anybody know is there a way in rugarch to resume ugarchroll class with new window parameters, it seems that I can resume with different solver parameters, but not with new specification. Second question is there some prebuilt method to return forecast with non converged samples filled by NAs, cause by default if non converged samples present the forecast info with vars and density don?t returns at all.          

On Oct 1, 2015, at 19:37, Brian G. Peterson <brian at braverock.com> wrote:

> On Thu, 2015-10-01 at 19:29 +0300, Evgeny Laba wrote:
>> I?m doing some VaR backtesting with garch modeling applied to stocks
>> using rugarch package, my backtesting period is 10 years and my
>> moving.window length is 252 & refitting parameter is one, so
>> unsurprisingly that setup and forecast length result in some few non
>> converged samples in some series (no more than 100), so my question is
>> what is the best practice, rule of thumb etc., in case if I want to
>> fill these gaps??? Changing refitting parameter to higher number, say
>> 30 or 50 eliminate non convergence, but of cause the forecasting result
>> is significantly different in that case?  
> 
> I would generally suggest a larger rolling window, or an expanding
> window, for your estimates.  Windowing effects can be quite severe on
> daily data, so for volatility forecasts I would tend towards larger data
> sets rather than smaller ones.
> 
> Regards,
> 
> Brian
> 
> -- 
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
> 


From akanefortuna at gmail.com  Sat Oct  3 16:34:07 2015
From: akanefortuna at gmail.com (Akane Fortuna)
Date: Sat, 3 Oct 2015 17:34:07 +0300
Subject: [R-SIG-Finance] Using custom TxnFee function with apply.paramset()
Message-ID: <CACf9SC+FVLNomUhyZt5Qd9e++pS99ToJ2V3Kyi9sxNqW0vtqsw@mail.gmail.com>

Hi everyone,

I made a script that runs apply.paramset() and applyStrategy() on the same
data. applyStrategy() uses a combination of parameters that are in the
indicator's distribution. However, the statistic of Net Trading PnL
returned from apply.paramset and applyStrategy for the same combination of
parameters are not the same. applyStrategy returns a much smaller number
which I assume is the effect of TxnFee working. I checked the documentation
for apply.paramset() but couldn't figure it out, checked the source code
for it too, it didn't help either. Maybe it is due to my ignorance, but I
appreciate any help.

So the question is:
How can I make apply.paramset() use a custom txn.fee function that I
created?

	[[alternative HTML version deleted]]


From brian at braverock.com  Sat Oct  3 18:17:52 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 3 Oct 2015 11:17:52 -0500
Subject: [R-SIG-Finance] Using custom TxnFee function with
 apply.paramset()
In-Reply-To: <CACf9SC+FVLNomUhyZt5Qd9e++pS99ToJ2V3Kyi9sxNqW0vtqsw@mail.gmail.com>
References: <CACf9SC+FVLNomUhyZt5Qd9e++pS99ToJ2V3Kyi9sxNqW0vtqsw@mail.gmail.com>
Message-ID: <560FFFB0.6000702@braverock.com>

On 10/03/2015 09:34 AM, Akane Fortuna wrote:
> I made a script that runs apply.paramset() and applyStrategy() on the same
> data. applyStrategy() uses a combination of parameters that are in the
> indicator's distribution. However, the statistic of Net Trading PnL
> returned from apply.paramset and applyStrategy for the same combination of
> parameters are not the same. applyStrategy returns a much smaller number
> which I assume is the effect of TxnFee working. I checked the documentation
> for apply.paramset() but couldn't figure it out, checked the source code
> for it too, it didn't help either. Maybe it is due to my ignorance, but I
> appreciate any help.
>
> So the question is:
> How can I make apply.paramset() use a custom txn.fee function that I
> created?


Yes, that should work.

If it isn't working, it may be a bug.

For anyone to help you, you'll need to strip things down to  a minimal 
reproducible example.

Regards,

Brian


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From samitpaulin at gmail.com  Sun Oct  4 17:52:07 2015
From: samitpaulin at gmail.com (Samit Paul)
Date: Sun, 4 Oct 2015 21:22:07 +0530
Subject: [R-SIG-Finance] Starting value of conditional mean and variance
Message-ID: <CALROeVGtXK1128kV3Tra4Spn_da4ZS22TK6enDcULzbh-hWXbQ@mail.gmail.com>

Dear R users,

I am trying to estimate conditional mean and variance of a financial return
series using UGARCHSPEC and UGARCHFIt function of "rugarch" package. I am
trying to fit basic ARMA(1,1)-GARCH(1,1) with Student - t distribution.

Now, I am not sure how the starting values are considered in this case or
whether I need to set it manually. Since the starting value is very
important for the estimation purpose, there could be some robust method for
calculation of the same.

Any help in this regard will be highly appreciated.

Regards,

Samit Paul

	[[alternative HTML version deleted]]


From patrick at burns-stat.com  Sun Oct  4 20:24:54 2015
From: patrick at burns-stat.com (Patrick Burns)
Date: Sun, 4 Oct 2015 19:24:54 +0100
Subject: [R-SIG-Finance] Starting value of conditional mean and variance
In-Reply-To: <CALROeVGtXK1128kV3Tra4Spn_da4ZS22TK6enDcULzbh-hWXbQ@mail.gmail.com>
References: <CALROeVGtXK1128kV3Tra4Spn_da4ZS22TK6enDcULzbh-hWXbQ@mail.gmail.com>
Message-ID: <56116EF6.60503@burns-stat.com>

I have two possible interpretations
of "starting values":

1) initial values of coefficients given
to the optimizer of the likelihood

2) the value of the conditional variance
at the time point before the first observation

If you are talking about the first, I
think you have little to worry about.
The default optimization in 'rugarch' is
reasonably good.  But there are options
to use different optimizers if you want to
check the quality of the optimum.

If you are talking about the second, then
that won't be an issue as long as you have
enough observations to make estimating a
garch model useful.  See:
http://www.portfolioprobe.com/2012/07/06/a-practical-introduction-to-garch-modeling/

Pat

On 04/10/2015 16:52, Samit Paul wrote:
> Dear R users,
>
> I am trying to estimate conditional mean and variance of a financial return
> series using UGARCHSPEC and UGARCHFIt function of "rugarch" package. I am
> trying to fit basic ARMA(1,1)-GARCH(1,1) with Student - t distribution.
>
> Now, I am not sure how the starting values are considered in this case or
> whether I need to set it manually. Since the starting value is very
> important for the estimation purpose, there could be some robust method for
> calculation of the same.
>
> Any help in this regard will be highly appreciated.
>
> Regards,
>
> Samit Paul
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com
http://www.portfolioprobe.com/blog
twitter: @burnsstat @portfolioprobe


From samitpaulin at gmail.com  Mon Oct  5 05:43:54 2015
From: samitpaulin at gmail.com (Samit Paul)
Date: Mon, 5 Oct 2015 09:13:54 +0530
Subject: [R-SIG-Finance] Starting value of conditional mean and variance
In-Reply-To: <56116EF6.60503@burns-stat.com>
References: <CALROeVGtXK1128kV3Tra4Spn_da4ZS22TK6enDcULzbh-hWXbQ@mail.gmail.com>
	<56116EF6.60503@burns-stat.com>
Message-ID: <CALROeVHxJEL1BaMF5Sk6V1fwS1bCf=_-oo9mHwn0WLKf2AL5zw@mail.gmail.com>

Thanks a lot Pat,

I was more concerned about the second issue which you have pointed out
well. From the link given (thanks again for the same), I understand that if
the number of observations are more (around 2000), choice of starting value
won't matter much in conditional variance estimation by GARCH(1,1) model.

But is the same logic applicable for conditional mean estimation with the
help of ARIMA model, too? Or do I have to take any precaution for the same?

Best regards,

Samit Paul


On Sun, Oct 4, 2015 at 11:54 PM, Patrick Burns <patrick at burns-stat.com>
wrote:

> I have two possible interpretations
> of "starting values":
>
> 1) initial values of coefficients given
> to the optimizer of the likelihood
>
> 2) the value of the conditional variance
> at the time point before the first observation
>
> If you are talking about the first, I
> think you have little to worry about.
> The default optimization in 'rugarch' is
> reasonably good.  But there are options
> to use different optimizers if you want to
> check the quality of the optimum.
>
> If you are talking about the second, then
> that won't be an issue as long as you have
> enough observations to make estimating a
> garch model useful.  See:
>
> http://www.portfolioprobe.com/2012/07/06/a-practical-introduction-to-garch-modeling/
>
> Pat
>
>
> On 04/10/2015 16:52, Samit Paul wrote:
>
>> Dear R users,
>>
>> I am trying to estimate conditional mean and variance of a financial
>> return
>> series using UGARCHSPEC and UGARCHFIt function of "rugarch" package. I am
>> trying to fit basic ARMA(1,1)-GARCH(1,1) with Student - t distribution.
>>
>> Now, I am not sure how the starting values are considered in this case or
>> whether I need to set it manually. Since the starting value is very
>> important for the estimation purpose, there could be some robust method
>> for
>> calculation of the same.
>>
>> Any help in this regard will be highly appreciated.
>>
>> Regards,
>>
>> Samit Paul
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>>
> --
> Patrick Burns
> patrick at burns-stat.com
> http://www.burns-stat.com
> http://www.portfolioprobe.com/blog
> twitter: @burnsstat @portfolioprobe
>

	[[alternative HTML version deleted]]


From patrick at burns-stat.com  Mon Oct  5 08:49:53 2015
From: patrick at burns-stat.com (Patrick Burns)
Date: Mon, 5 Oct 2015 07:49:53 +0100
Subject: [R-SIG-Finance] Starting value of conditional mean and variance
In-Reply-To: <CALROeVHxJEL1BaMF5Sk6V1fwS1bCf=_-oo9mHwn0WLKf2AL5zw@mail.gmail.com>
References: <CALROeVGtXK1128kV3Tra4Spn_da4ZS22TK6enDcULzbh-hWXbQ@mail.gmail.com>
	<56116EF6.60503@burns-stat.com>
	<CALROeVHxJEL1BaMF5Sk6V1fwS1bCf=_-oo9mHwn0WLKf2AL5zw@mail.gmail.com>
Message-ID: <56121D91.50109@burns-stat.com>

I haven't studied the issue with
ARIMA, but it is my belief that it
is even less of an issue there.

Maybe someone on the list has looked
into it and has a better sense of the
sensitivity -- rather than being like
the rest of us and not worrying about
it because no one else does.

Pat

On 05/10/2015 04:43, Samit Paul wrote:
> Thanks a lot Pat,
>
> I was more concerned about the second issue which you have pointed out
> well. From the link given (thanks again for the same), I understand that
> if the number of observations are more (around 2000), choice of starting
> value won't matter much in conditional variance estimation by GARCH(1,1)
> model.
>
> But is the same logic applicable for conditional mean estimation with
> the help of ARIMA model, too? Or do I have to take any precaution for
> the same?
>
> Best regards,
>
> Samit Paul
>
>
> On Sun, Oct 4, 2015 at 11:54 PM, Patrick Burns <patrick at burns-stat.com
> <mailto:patrick at burns-stat.com>> wrote:
>
>     I have two possible interpretations
>     of "starting values":
>
>     1) initial values of coefficients given
>     to the optimizer of the likelihood
>
>     2) the value of the conditional variance
>     at the time point before the first observation
>
>     If you are talking about the first, I
>     think you have little to worry about.
>     The default optimization in 'rugarch' is
>     reasonably good.  But there are options
>     to use different optimizers if you want to
>     check the quality of the optimum.
>
>     If you are talking about the second, then
>     that won't be an issue as long as you have
>     enough observations to make estimating a
>     garch model useful.  See:
>     http://www.portfolioprobe.com/2012/07/06/a-practical-introduction-to-garch-modeling/
>
>     Pat
>
>
>     On 04/10/2015 16:52, Samit Paul wrote:
>
>         Dear R users,
>
>         I am trying to estimate conditional mean and variance of a
>         financial return
>         series using UGARCHSPEC and UGARCHFIt function of "rugarch"
>         package. I am
>         trying to fit basic ARMA(1,1)-GARCH(1,1) with Student - t
>         distribution.
>
>         Now, I am not sure how the starting values are considered in
>         this case or
>         whether I need to set it manually. Since the starting value is very
>         important for the estimation purpose, there could be some robust
>         method for
>         calculation of the same.
>
>         Any help in this regard will be highly appreciated.
>
>         Regards,
>
>         Samit Paul
>
>                  [[alternative HTML version deleted]]
>
>         _______________________________________________
>         R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org>
>         mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>         -- Subscriber-posting only. If you want to post, subscribe first.
>         -- Also note that this is not the r-help list where general R
>         questions should go.
>
>
>     --
>     Patrick Burns
>     patrick at burns-stat.com <mailto:patrick at burns-stat.com>
>     http://www.burns-stat.com
>     http://www.portfolioprobe.com/blog
>     twitter: @burnsstat @portfolioprobe
>
>

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com
http://www.portfolioprobe.com/blog
twitter: @burnsstat @portfolioprobe


From alexios at 4dscape.com  Mon Oct  5 13:17:47 2015
From: alexios at 4dscape.com (alexios galanos)
Date: Mon, 5 Oct 2015 06:17:47 -0500
Subject: [R-SIG-Finance] Starting value of conditional mean and variance
In-Reply-To: <56121D91.50109@burns-stat.com>
References: <CALROeVGtXK1128kV3Tra4Spn_da4ZS22TK6enDcULzbh-hWXbQ@mail.gmail.com>
	<56116EF6.60503@burns-stat.com>
	<CALROeVHxJEL1BaMF5Sk6V1fwS1bCf=_-oo9mHwn0WLKf2AL5zw@mail.gmail.com>
	<56121D91.50109@burns-stat.com>
Message-ID: <56125C5B.6030002@4dscape.com>

A few years ago, on the suggestion of Pat, I implemented an option
which allows to choose whether to use all the data for the initialization
of the variance recursion or some other value e.g. for exponential smoothing
backast. This can be found in the fit.control option (of ugarchfit) under
'rec.init':

>From the documentation:

"The rec.init option determines the type of initialization for the
variance recursion.
Valid options are ?all? which uses all the values for the unconditional
variance
calculation, an integer greater than or equal to 1 denoting the number
of data
points to use for the calculation, or a positive numeric value less than
one
which determines the weighting for use in an exponential smoothing
backcast."

This is only for the variance recursion initialization, and not the
conditional mean.

Best,

Alexios

On 05/10/2015 01:49, Patrick Burns wrote:
> I haven't studied the issue with
> ARIMA, but it is my belief that it
> is even less of an issue there.
>
> Maybe someone on the list has looked
> into it and has a better sense of the
> sensitivity -- rather than being like
> the rest of us and not worrying about
> it because no one else does.
>
> Pat
>
> On 05/10/2015 04:43, Samit Paul wrote:
>> Thanks a lot Pat,
>>
>> I was more concerned about the second issue which you have pointed out
>> well. From the link given (thanks again for the same), I understand that
>> if the number of observations are more (around 2000), choice of starting
>> value won't matter much in conditional variance estimation by GARCH(1,1)
>> model.
>>
>> But is the same logic applicable for conditional mean estimation with
>> the help of ARIMA model, too? Or do I have to take any precaution for
>> the same?
>>
>> Best regards,
>>
>> Samit Paul
>>
>>
>> On Sun, Oct 4, 2015 at 11:54 PM, Patrick Burns <patrick at burns-stat.com
>> <mailto:patrick at burns-stat.com>> wrote:
>>
>>     I have two possible interpretations
>>     of "starting values":
>>
>>     1) initial values of coefficients given
>>     to the optimizer of the likelihood
>>
>>     2) the value of the conditional variance
>>     at the time point before the first observation
>>
>>     If you are talking about the first, I
>>     think you have little to worry about.
>>     The default optimization in 'rugarch' is
>>     reasonably good.  But there are options
>>     to use different optimizers if you want to
>>     check the quality of the optimum.
>>
>>     If you are talking about the second, then
>>     that won't be an issue as long as you have
>>     enough observations to make estimating a
>>     garch model useful.  See:
>>    
>> http://www.portfolioprobe.com/2012/07/06/a-practical-introduction-to-garch-modeling/
>>
>>     Pat
>>
>>
>>     On 04/10/2015 16:52, Samit Paul wrote:
>>
>>         Dear R users,
>>
>>         I am trying to estimate conditional mean and variance of a
>>         financial return
>>         series using UGARCHSPEC and UGARCHFIt function of "rugarch"
>>         package. I am
>>         trying to fit basic ARMA(1,1)-GARCH(1,1) with Student - t
>>         distribution.
>>
>>         Now, I am not sure how the starting values are considered in
>>         this case or
>>         whether I need to set it manually. Since the starting value
>> is very
>>         important for the estimation purpose, there could be some robust
>>         method for
>>         calculation of the same.
>>
>>         Any help in this regard will be highly appreciated.
>>
>>         Regards,
>>
>>         Samit Paul
>>
>>                  [[alternative HTML version deleted]]
>>
>>         _______________________________________________
>>         R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org>
>>         mailing list
>>         https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>         -- Subscriber-posting only. If you want to post, subscribe
>> first.
>>         -- Also note that this is not the r-help list where general R
>>         questions should go.
>>
>>
>>     --
>>     Patrick Burns
>>     patrick at burns-stat.com <mailto:patrick at burns-stat.com>
>>     http://www.burns-stat.com
>>     http://www.portfolioprobe.com/blog
>>     twitter: @burnsstat @portfolioprobe
>>
>>
>


From samitpaulin at gmail.com  Mon Oct  5 13:57:09 2015
From: samitpaulin at gmail.com (Samit Paul)
Date: Mon, 5 Oct 2015 17:27:09 +0530
Subject: [R-SIG-Finance] Starting value of conditional mean and variance
In-Reply-To: <56125C5B.6030002@4dscape.com>
References: <CALROeVGtXK1128kV3Tra4Spn_da4ZS22TK6enDcULzbh-hWXbQ@mail.gmail.com>
	<56116EF6.60503@burns-stat.com>
	<CALROeVHxJEL1BaMF5Sk6V1fwS1bCf=_-oo9mHwn0WLKf2AL5zw@mail.gmail.com>
	<56121D91.50109@burns-stat.com> <56125C5B.6030002@4dscape.com>
Message-ID: <CALROeVEOMeQiE228XQM3V-FhNsbhX+uosB6wQXmhGOTSMkGsEw@mail.gmail.com>

Thanks a lot Pat and Alexios,

The explanations and insights shared by you are really helpful for me to
develop my understanding.

I sincerely appreciate your time and effort.

Best regards,

Samit Paul

On Mon, Oct 5, 2015 at 4:47 PM, alexios galanos <alexios at 4dscape.com> wrote:

> A few years ago, on the suggestion of Pat, I implemented an option
> which allows to choose whether to use all the data for the initialization
> of the variance recursion or some other value e.g. for exponential
> smoothing
> backast. This can be found in the fit.control option (of ugarchfit) under
> 'rec.init':
>
> From the documentation:
>
> "The rec.init option determines the type of initialization for the
> variance recursion.
> Valid options are ?all? which uses all the values for the unconditional
> variance
> calculation, an integer greater than or equal to 1 denoting the number
> of data
> points to use for the calculation, or a positive numeric value less than
> one
> which determines the weighting for use in an exponential smoothing
> backcast."
>
> This is only for the variance recursion initialization, and not the
> conditional mean.
>
> Best,
>
> Alexios
>
> On 05/10/2015 01:49, Patrick Burns wrote:
> > I haven't studied the issue with
> > ARIMA, but it is my belief that it
> > is even less of an issue there.
> >
> > Maybe someone on the list has looked
> > into it and has a better sense of the
> > sensitivity -- rather than being like
> > the rest of us and not worrying about
> > it because no one else does.
> >
> > Pat
> >
> > On 05/10/2015 04:43, Samit Paul wrote:
> >> Thanks a lot Pat,
> >>
> >> I was more concerned about the second issue which you have pointed out
> >> well. From the link given (thanks again for the same), I understand that
> >> if the number of observations are more (around 2000), choice of starting
> >> value won't matter much in conditional variance estimation by GARCH(1,1)
> >> model.
> >>
> >> But is the same logic applicable for conditional mean estimation with
> >> the help of ARIMA model, too? Or do I have to take any precaution for
> >> the same?
> >>
> >> Best regards,
> >>
> >> Samit Paul
> >>
> >>
> >> On Sun, Oct 4, 2015 at 11:54 PM, Patrick Burns <patrick at burns-stat.com
> >> <mailto:patrick at burns-stat.com>> wrote:
> >>
> >>     I have two possible interpretations
> >>     of "starting values":
> >>
> >>     1) initial values of coefficients given
> >>     to the optimizer of the likelihood
> >>
> >>     2) the value of the conditional variance
> >>     at the time point before the first observation
> >>
> >>     If you are talking about the first, I
> >>     think you have little to worry about.
> >>     The default optimization in 'rugarch' is
> >>     reasonably good.  But there are options
> >>     to use different optimizers if you want to
> >>     check the quality of the optimum.
> >>
> >>     If you are talking about the second, then
> >>     that won't be an issue as long as you have
> >>     enough observations to make estimating a
> >>     garch model useful.  See:
> >>
> >>
> http://www.portfolioprobe.com/2012/07/06/a-practical-introduction-to-garch-modeling/
> >>
> >>     Pat
> >>
> >>
> >>     On 04/10/2015 16:52, Samit Paul wrote:
> >>
> >>         Dear R users,
> >>
> >>         I am trying to estimate conditional mean and variance of a
> >>         financial return
> >>         series using UGARCHSPEC and UGARCHFIt function of "rugarch"
> >>         package. I am
> >>         trying to fit basic ARMA(1,1)-GARCH(1,1) with Student - t
> >>         distribution.
> >>
> >>         Now, I am not sure how the starting values are considered in
> >>         this case or
> >>         whether I need to set it manually. Since the starting value
> >> is very
> >>         important for the estimation purpose, there could be some robust
> >>         method for
> >>         calculation of the same.
> >>
> >>         Any help in this regard will be highly appreciated.
> >>
> >>         Regards,
> >>
> >>         Samit Paul
> >>
> >>                  [[alternative HTML version deleted]]
> >>
> >>         _______________________________________________
> >>         R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org
> >
> >>         mailing list
> >>         https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >>         -- Subscriber-posting only. If you want to post, subscribe
> >> first.
> >>         -- Also note that this is not the r-help list where general R
> >>         questions should go.
> >>
> >>
> >>     --
> >>     Patrick Burns
> >>     patrick at burns-stat.com <mailto:patrick at burns-stat.com>
> >>     http://www.burns-stat.com
> >>     http://www.portfolioprobe.com/blog
> >>     twitter: @burnsstat @portfolioprobe
> >>
> >>
> >
>
>

	[[alternative HTML version deleted]]


From samitpaulin at gmail.com  Tue Oct  6 22:00:36 2015
From: samitpaulin at gmail.com (Samit Paul)
Date: Wed, 7 Oct 2015 01:30:36 +0530
Subject: [R-SIG-Finance] Multivariate dependence with copula
Message-ID: <CALROeVEafm6Q1kA8PbLhF+zrvBAgx1soAU3Yu=ysYs_zuwte-A@mail.gmail.com>

Dear R users,

I want to fit copula function to more than two marginals and based on the
value of copula fitted parameter I want to simulate the same number of
random marginal series. I can do the same for bivariate copula using
"copula" and "fcopulae" package. But, I can't do it when the number of
marginals are more than two.

Can anyone please guide me with which package or function I can perform the
same?

Thanks in advance.

Regards

Samit Paul

	[[alternative HTML version deleted]]


From tstoyc at gmail.com  Sat Oct 10 01:29:34 2015
From: tstoyc at gmail.com (Tsvetan Stoyanov)
Date: Fri, 9 Oct 2015 16:29:34 -0700
Subject: [R-SIG-Finance] segfault while running quantstrat
Message-ID: <29473F24-B5BA-431A-BABD-925C8E0E365D@gmail.com>

Hi,

While running a simple strategy on 5min data I got a segfault after about 2 years and 7 months, or
200,000 bars. Is this expected, are these the limits or quantstrat/R?

Tsvetan

*** caught segfault ***
address 0x119b32000, cause 'memory not mapped'

Traceback:
 1: .External("rbindXts", dup = FALSE, ..., PACKAGE = "xts")
 2: rbind(deparse.level, ...)
 3: rbind(Portfolio$symbols[[Symbol]]$txn, NewTxn)
 4: addTxn(Portfolio = portfolio, Symbol = symbol, TxnDate = txntime,     TxnQty = orderQty, TxnPrice = txnprice, ... = ..., TxnFees = txnfees)
 5: ruleOrderProc(portfolio = portfolio, symbol = symbol, mktdata = mktdata,     timestamp = timestamp, periodicity = freq, curIndex = curIndex,     ...)
 6: applyRules(portfolio = portfolio, symbol = symbol, strategy = strategy,     mktdata = mktdata, Dates = NULL, indicators = sret$indicators,     signals = sret$signals, parameters = parameters, ..., path.dep = TRUE,     debug = debug)
 7: applyStrategy(strategy.st, portfolio.st)

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection: 

From josh.m.ulrich at gmail.com  Sat Oct 10 01:33:44 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 9 Oct 2015 18:33:44 -0500
Subject: [R-SIG-Finance] segfault while running quantstrat
In-Reply-To: <29473F24-B5BA-431A-BABD-925C8E0E365D@gmail.com>
References: <29473F24-B5BA-431A-BABD-925C8E0E365D@gmail.com>
Message-ID: <CAPPM_gRzi-4wuLxf86nhxa=1GNp8bhADcn6gib7FpM2DRR9TXg@mail.gmail.com>

On Fri, Oct 9, 2015 at 6:29 PM, Tsvetan Stoyanov <tstoyc at gmail.com> wrote:
> Hi,
>
> While running a simple strategy on 5min data I got a segfault after about 2 years and 7 months, or
> 200,000 bars. Is this expected, are these the limits or quantstrat/R?
>
Segfaults are always bugs, never "expected".  In this case, the
problem is in the compiled code in xts:::rbind.xts.  Please provide
the output of sessionInfo().

> Tsvetan
>
> *** caught segfault ***
> address 0x119b32000, cause 'memory not mapped'
>
> Traceback:
>  1: .External("rbindXts", dup = FALSE, ..., PACKAGE = "xts")
>  2: rbind(deparse.level, ...)
>  3: rbind(Portfolio$symbols[[Symbol]]$txn, NewTxn)
>  4: addTxn(Portfolio = portfolio, Symbol = symbol, TxnDate = txntime,     TxnQty = orderQty, TxnPrice = txnprice, ... = ..., TxnFees = txnfees)
>  5: ruleOrderProc(portfolio = portfolio, symbol = symbol, mktdata = mktdata,     timestamp = timestamp, periodicity = freq, curIndex = curIndex,     ...)
>  6: applyRules(portfolio = portfolio, symbol = symbol, strategy = strategy,     mktdata = mktdata, Dates = NULL, indicators = sret$indicators,     signals = sret$signals, parameters = parameters, ..., path.dep = TRUE,     debug = debug)
>  7: applyStrategy(strategy.st, portfolio.st)
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection:
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From tstoyc at gmail.com  Sat Oct 10 01:46:30 2015
From: tstoyc at gmail.com (Tsvetan Stoyanov)
Date: Fri, 9 Oct 2015 16:46:30 -0700
Subject: [R-SIG-Finance] segfault while running quantstrat
In-Reply-To: <CAPPM_gRzi-4wuLxf86nhxa=1GNp8bhADcn6gib7FpM2DRR9TXg@mail.gmail.com>
References: <29473F24-B5BA-431A-BABD-925C8E0E365D@gmail.com>
	<CAPPM_gRzi-4wuLxf86nhxa=1GNp8bhADcn6gib7FpM2DRR9TXg@mail.gmail.com>
Message-ID: <BAFBE092-FBEB-43AF-9F65-E63CCDAD42FE@gmail.com>

Just before I run applyStrategy(), I have

> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] quantstrat_0.9.1687           foreach_1.4.2                
[3] blotter_0.9.1695              PerformanceAnalytics_1.4.3541
[5] FinancialInstrument_1.2.0     quantmod_0.4-5               
[7] TTR_0.23-0                    xts_0.9-7                    
[9] zoo_1.7-12                   

loaded via a namespace (and not attached):
[1] compiler_3.2.2   tools_3.2.2      codetools_0.2-14 grid_3.2.2      
[5] iterators_1.0.7  lattice_0.20-33 

> On Oct 9, 2015, at 4:33 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> 
> On Fri, Oct 9, 2015 at 6:29 PM, Tsvetan Stoyanov <tstoyc at gmail.com <mailto:tstoyc at gmail.com>> wrote:
>> Hi,
>> 
>> While running a simple strategy on 5min data I got a segfault after about 2 years and 7 months, or
>> 200,000 bars. Is this expected, are these the limits or quantstrat/R?
>> 
> Segfaults are always bugs, never "expected".  In this case, the
> problem is in the compiled code in xts:::rbind.xts.  Please provide
> the output of sessionInfo().
> 
>> Tsvetan
>> 
>> *** caught segfault ***
>> address 0x119b32000, cause 'memory not mapped'
>> 
>> Traceback:
>> 1: .External("rbindXts", dup = FALSE, ..., PACKAGE = "xts")
>> 2: rbind(deparse.level, ...)
>> 3: rbind(Portfolio$symbols[[Symbol]]$txn, NewTxn)
>> 4: addTxn(Portfolio = portfolio, Symbol = symbol, TxnDate = txntime,     TxnQty = orderQty, TxnPrice = txnprice, ... = ..., TxnFees = txnfees)
>> 5: ruleOrderProc(portfolio = portfolio, symbol = symbol, mktdata = mktdata,     timestamp = timestamp, periodicity = freq, curIndex = curIndex,     ...)
>> 6: applyRules(portfolio = portfolio, symbol = symbol, strategy = strategy,     mktdata = mktdata, Dates = NULL, indicators = sret$indicators,     signals = sret$signals, parameters = parameters, ..., path.dep = TRUE,     debug = debug)
>> 7: applyStrategy(strategy.st, portfolio.st)
>> 
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>> Selection:
>> _______________________________________________
>> R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance <https://stat.ethz.ch/mailman/listinfo/r-sig-finance>
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
> 
> 
> 
> -- 
> Joshua Ulrich  |  about.me/joshuaulrich <http://about.me/joshuaulrich>
> FOSS Trading  |  www.fosstrading.com <http://www.fosstrading.com/>

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Sat Oct 10 01:58:46 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 9 Oct 2015 18:58:46 -0500
Subject: [R-SIG-Finance] segfault while running quantstrat
In-Reply-To: <BAFBE092-FBEB-43AF-9F65-E63CCDAD42FE@gmail.com>
References: <29473F24-B5BA-431A-BABD-925C8E0E365D@gmail.com>
	<CAPPM_gRzi-4wuLxf86nhxa=1GNp8bhADcn6gib7FpM2DRR9TXg@mail.gmail.com>
	<BAFBE092-FBEB-43AF-9F65-E63CCDAD42FE@gmail.com>
Message-ID: <CAPPM_gT4p9jt7qu+oG_E-AG=rZr49nGhTkT64fEApT_4Mhuy0A@mail.gmail.com>

Thank you. You're running the latest xts on CRAN, and the rbind C code
hasn't been touched in years... so this is likely still an issue in
the development version of xts.

Unfortunately, this is going to be very hard for me to reproduce
without your strategy and data.  Would it be possible for you to
provide it (off-list, if you prefer)?

On Fri, Oct 9, 2015 at 6:46 PM, Tsvetan Stoyanov <tstoyc at gmail.com> wrote:
> Just before I run applyStrategy(), I have
>
>> sessionInfo()
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.11 (El Capitan)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] quantstrat_0.9.1687           foreach_1.4.2
> [3] blotter_0.9.1695              PerformanceAnalytics_1.4.3541
> [5] FinancialInstrument_1.2.0     quantmod_0.4-5
> [7] TTR_0.23-0                    xts_0.9-7
> [9] zoo_1.7-12
>
> loaded via a namespace (and not attached):
> [1] compiler_3.2.2   tools_3.2.2      codetools_0.2-14 grid_3.2.2
> [5] iterators_1.0.7  lattice_0.20-33
>
> On Oct 9, 2015, at 4:33 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>
> On Fri, Oct 9, 2015 at 6:29 PM, Tsvetan Stoyanov <tstoyc at gmail.com> wrote:
>
> Hi,
>
> While running a simple strategy on 5min data I got a segfault after about 2
> years and 7 months, or
> 200,000 bars. Is this expected, are these the limits or quantstrat/R?
>
> Segfaults are always bugs, never "expected".  In this case, the
> problem is in the compiled code in xts:::rbind.xts.  Please provide
> the output of sessionInfo().
>
> Tsvetan
>
> *** caught segfault ***
> address 0x119b32000, cause 'memory not mapped'
>
> Traceback:
> 1: .External("rbindXts", dup = FALSE, ..., PACKAGE = "xts")
> 2: rbind(deparse.level, ...)
> 3: rbind(Portfolio$symbols[[Symbol]]$txn, NewTxn)
> 4: addTxn(Portfolio = portfolio, Symbol = symbol, TxnDate = txntime,
> TxnQty = orderQty, TxnPrice = txnprice, ... = ..., TxnFees = txnfees)
> 5: ruleOrderProc(portfolio = portfolio, symbol = symbol, mktdata = mktdata,
> timestamp = timestamp, periodicity = freq, curIndex = curIndex,     ...)
> 6: applyRules(portfolio = portfolio, symbol = symbol, strategy = strategy,
> mktdata = mktdata, Dates = NULL, indicators = sret$indicators,     signals =
> sret$signals, parameters = parameters, ..., path.dep = TRUE,     debug =
> debug)
> 7: applyStrategy(strategy.st, portfolio.st)
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection:
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
>
>



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From mshammaa at uchicago.edu  Mon Oct 12 00:02:57 2015
From: mshammaa at uchicago.edu (Mahmoud Shammaa)
Date: Sun, 11 Oct 2015 17:02:57 -0500
Subject: [R-SIG-Finance] Reading the GSW spot rates from fed 2006 website
Message-ID: <CAFaOq5NaXMfrfKhjg7uHscxVR2F2gT9KqXp7_KHpUE+EYcgPSg@mail.gmail.com>

Hello,
Does anyone have any tips or suggestions regarding reading the rates that
Gurkaynak, Sack and Wright are updating on this website:
http://www.federalreserve.gov/econresdata/researchdata/feds200628_1.html
While I know how to scrape an html page the issue is that they have the
pages going from oldest to newest so It is not easily apparent where the
latest data is:
As of right now it is on page 29...
http://www.federalreserve.gov/econresdata/researchdata/feds200628_29.html
.

the problem is that this will change
What is even more frustrating that if you go to
http://www.federalreserve.gov/econresdata/researchdata/feds200628_30.html
data exists but it is not clear in what sequence ... it seems to be draft
data..

So I am not sure if anyone on this list has recommendations regarding
unruly webpages ..

Thanks,
Mido Shammaa

	[[alternative HTML version deleted]]


From alexzemnitskiy at gmail.com  Mon Oct 12 00:26:28 2015
From: alexzemnitskiy at gmail.com (Alexey Zemnitskiy)
Date: Sun, 11 Oct 2015 18:26:28 -0400
Subject: [R-SIG-Finance] Reading the GSW spot rates from fed 2006 website
In-Reply-To: <CAFaOq5NaXMfrfKhjg7uHscxVR2F2gT9KqXp7_KHpUE+EYcgPSg@mail.gmail.com>
References: <CAFaOq5NaXMfrfKhjg7uHscxVR2F2gT9KqXp7_KHpUE+EYcgPSg@mail.gmail.com>
Message-ID: <CADY2e71OOPfJPjBJmBuHUALi4BUwYOhX+eAzjxzp8VcWuLB0wA@mail.gmail.com>

Hi Mahmoud,

You could also let the guys from Quandl know if some major rates time
series is missing from their current set

https://www.quandl.com/collections/usa/usa-interest-rates

They have an R package on CRAN to consume their data.

Best,

Alex Zemnitskiy

2015-10-11 18:02 GMT-04:00 Mahmoud Shammaa <mshammaa at uchicago.edu>:

> Hello,
> Does anyone have any tips or suggestions regarding reading the rates that
> Gurkaynak, Sack and Wright are updating on this website:
> http://www.federalreserve.gov/econresdata/researchdata/feds200628_1.html
> While I know how to scrape an html page the issue is that they have the
> pages going from oldest to newest so It is not easily apparent where the
> latest data is:
> As of right now it is on page 29...
> http://www.federalreserve.gov/econresdata/researchdata/feds200628_29.html
> .
>
> the problem is that this will change
> What is even more frustrating that if you go to
> http://www.federalreserve.gov/econresdata/researchdata/feds200628_30.html
> data exists but it is not clear in what sequence ... it seems to be draft
> data..
>
> So I am not sure if anyone on this list has recommendations regarding
> unruly webpages ..
>
> Thanks,
> Mido Shammaa
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Mon Oct 12 03:14:35 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 11 Oct 2015 20:14:35 -0500
Subject: [R-SIG-Finance] segfault while running quantstrat
In-Reply-To: <CAPPM_gT4p9jt7qu+oG_E-AG=rZr49nGhTkT64fEApT_4Mhuy0A@mail.gmail.com>
References: <29473F24-B5BA-431A-BABD-925C8E0E365D@gmail.com>
	<CAPPM_gRzi-4wuLxf86nhxa=1GNp8bhADcn6gib7FpM2DRR9TXg@mail.gmail.com>
	<BAFBE092-FBEB-43AF-9F65-E63CCDAD42FE@gmail.com>
	<CAPPM_gT4p9jt7qu+oG_E-AG=rZr49nGhTkT64fEApT_4Mhuy0A@mail.gmail.com>
Message-ID: <CAPPM_gRFZS9xR1J-ZhWLbYJD=DohutiEFzA0sRi8shoi+-ZSpQ@mail.gmail.com>

Tsvetan,

Thanks for sharing your data and code with me off-list.  I was able to
find and fix two possible causes, which you can find here:
https://github.com/joshuaulrich/xts/issues/117
https://github.com/joshuaulrich/xts/issues/118

Please see if you can still reproduce the segfault with the latest
code from GitHub.

Best,
Josh

On Fri, Oct 9, 2015 at 6:58 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> Thank you. You're running the latest xts on CRAN, and the rbind C code
> hasn't been touched in years... so this is likely still an issue in
> the development version of xts.
>
> Unfortunately, this is going to be very hard for me to reproduce
> without your strategy and data.  Would it be possible for you to
> provide it (off-list, if you prefer)?
>
> On Fri, Oct 9, 2015 at 6:46 PM, Tsvetan Stoyanov <tstoyc at gmail.com> wrote:
>> Just before I run applyStrategy(), I have
>>
>>> sessionInfo()
>> R version 3.2.2 (2015-08-14)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: OS X 10.11 (El Capitan)
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] quantstrat_0.9.1687           foreach_1.4.2
>> [3] blotter_0.9.1695              PerformanceAnalytics_1.4.3541
>> [5] FinancialInstrument_1.2.0     quantmod_0.4-5
>> [7] TTR_0.23-0                    xts_0.9-7
>> [9] zoo_1.7-12
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.2.2   tools_3.2.2      codetools_0.2-14 grid_3.2.2
>> [5] iterators_1.0.7  lattice_0.20-33
>>
>> On Oct 9, 2015, at 4:33 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>>
>> On Fri, Oct 9, 2015 at 6:29 PM, Tsvetan Stoyanov <tstoyc at gmail.com> wrote:
>>
>> Hi,
>>
>> While running a simple strategy on 5min data I got a segfault after about 2
>> years and 7 months, or
>> 200,000 bars. Is this expected, are these the limits or quantstrat/R?
>>
>> Segfaults are always bugs, never "expected".  In this case, the
>> problem is in the compiled code in xts:::rbind.xts.  Please provide
>> the output of sessionInfo().
>>
>> Tsvetan
>>
>> *** caught segfault ***
>> address 0x119b32000, cause 'memory not mapped'
>>
>> Traceback:
>> 1: .External("rbindXts", dup = FALSE, ..., PACKAGE = "xts")
>> 2: rbind(deparse.level, ...)
>> 3: rbind(Portfolio$symbols[[Symbol]]$txn, NewTxn)
>> 4: addTxn(Portfolio = portfolio, Symbol = symbol, TxnDate = txntime,
>> TxnQty = orderQty, TxnPrice = txnprice, ... = ..., TxnFees = txnfees)
>> 5: ruleOrderProc(portfolio = portfolio, symbol = symbol, mktdata = mktdata,
>> timestamp = timestamp, periodicity = freq, curIndex = curIndex,     ...)
>> 6: applyRules(portfolio = portfolio, symbol = symbol, strategy = strategy,
>> mktdata = mktdata, Dates = NULL, indicators = sret$indicators,     signals =
>> sret$signals, parameters = parameters, ..., path.dep = TRUE,     debug =
>> debug)
>> 7: applyStrategy(strategy.st, portfolio.st)
>>
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>> Selection:
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>>
>>
>>
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com
>>
>>
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From gsee000 at gmail.com  Mon Oct 12 03:17:49 2015
From: gsee000 at gmail.com (G See)
Date: Sun, 11 Oct 2015 20:17:49 -0500
Subject: [R-SIG-Finance] Reading the GSW spot rates from fed 2006 website
In-Reply-To: <CAFaOq5NaXMfrfKhjg7uHscxVR2F2gT9KqXp7_KHpUE+EYcgPSg@mail.gmail.com>
References: <CAFaOq5NaXMfrfKhjg7uHscxVR2F2gT9KqXp7_KHpUE+EYcgPSg@mail.gmail.com>
Message-ID: <CA+xi=qbmrKLuq21_7CXTyj7YPhuFVfssOdsh0Y1K9Zc2Sm+oqQ@mail.gmail.com>

It might be easier to work with the .xls file that you can download
from a link on this page:
http://www.federalreserve.gov/pubs/feds/2006/200628/200628abs.html

hope it helps,
Garrett

On Sun, Oct 11, 2015 at 5:02 PM, Mahmoud Shammaa <mshammaa at uchicago.edu> wrote:
> Hello,
> Does anyone have any tips or suggestions regarding reading the rates that
> Gurkaynak, Sack and Wright are updating on this website:
> http://www.federalreserve.gov/econresdata/researchdata/feds200628_1.html
> While I know how to scrape an html page the issue is that they have the
> pages going from oldest to newest so It is not easily apparent where the
> latest data is:
> As of right now it is on page 29...
> http://www.federalreserve.gov/econresdata/researchdata/feds200628_29.html
> .
>
> the problem is that this will change
> What is even more frustrating that if you go to
> http://www.federalreserve.gov/econresdata/researchdata/feds200628_30.html
> data exists but it is not clear in what sequence ... it seems to be draft
> data..
>
> So I am not sure if anyone on this list has recommendations regarding
> unruly webpages ..
>
> Thanks,
> Mido Shammaa
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From tstoyc at gmail.com  Mon Oct 12 07:10:48 2015
From: tstoyc at gmail.com (Tsvetan Stoyanov)
Date: Sun, 11 Oct 2015 22:10:48 -0700
Subject: [R-SIG-Finance] segfault while running quantstrat
In-Reply-To: <CAPPM_gRFZS9xR1J-ZhWLbYJD=DohutiEFzA0sRi8shoi+-ZSpQ@mail.gmail.com>
References: <29473F24-B5BA-431A-BABD-925C8E0E365D@gmail.com>
	<CAPPM_gRzi-4wuLxf86nhxa=1GNp8bhADcn6gib7FpM2DRR9TXg@mail.gmail.com>
	<BAFBE092-FBEB-43AF-9F65-E63CCDAD42FE@gmail.com>
	<CAPPM_gT4p9jt7qu+oG_E-AG=rZr49nGhTkT64fEApT_4Mhuy0A@mail.gmail.com>
	<CAPPM_gRFZS9xR1J-ZhWLbYJD=DohutiEFzA0sRi8shoi+-ZSpQ@mail.gmail.com>
Message-ID: <AF349DE6-AD78-49B0-A14B-A661BF056170@gmail.com>

Josh,
The example ran fine with v0.9-8.
Thank you for fixing the bug,
Tsvetan

> On Oct 11, 2015, at 6:14 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> 
> Tsvetan,
> 
> Thanks for sharing your data and code with me off-list.  I was able to
> find and fix two possible causes, which you can find here:
> https://github.com/joshuaulrich/xts/issues/117
> https://github.com/joshuaulrich/xts/issues/118
> 
> Please see if you can still reproduce the segfault with the latest
> code from GitHub.
> 
> Best,
> Josh
> 
> On Fri, Oct 9, 2015 at 6:58 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>> Thank you. You're running the latest xts on CRAN, and the rbind C code
>> hasn't been touched in years... so this is likely still an issue in
>> the development version of xts.
>> 
>> Unfortunately, this is going to be very hard for me to reproduce
>> without your strategy and data.  Would it be possible for you to
>> provide it (off-list, if you prefer)?
>> 
>> On Fri, Oct 9, 2015 at 6:46 PM, Tsvetan Stoyanov <tstoyc at gmail.com> wrote:
>>> Just before I run applyStrategy(), I have
>>> 
>>>> sessionInfo()
>>> R version 3.2.2 (2015-08-14)
>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>> Running under: OS X 10.11 (El Capitan)
>>> 
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> other attached packages:
>>> [1] quantstrat_0.9.1687           foreach_1.4.2
>>> [3] blotter_0.9.1695              PerformanceAnalytics_1.4.3541
>>> [5] FinancialInstrument_1.2.0     quantmod_0.4-5
>>> [7] TTR_0.23-0                    xts_0.9-7
>>> [9] zoo_1.7-12
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.2.2   tools_3.2.2      codetools_0.2-14 grid_3.2.2
>>> [5] iterators_1.0.7  lattice_0.20-33
>>> 
>>> On Oct 9, 2015, at 4:33 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>>> 
>>> On Fri, Oct 9, 2015 at 6:29 PM, Tsvetan Stoyanov <tstoyc at gmail.com> wrote:
>>> 
>>> Hi,
>>> 
>>> While running a simple strategy on 5min data I got a segfault after about 2
>>> years and 7 months, or
>>> 200,000 bars. Is this expected, are these the limits or quantstrat/R?
>>> 
>>> Segfaults are always bugs, never "expected".  In this case, the
>>> problem is in the compiled code in xts:::rbind.xts.  Please provide
>>> the output of sessionInfo().
>>> 
>>> Tsvetan
>>> 
>>> *** caught segfault ***
>>> address 0x119b32000, cause 'memory not mapped'
>>> 
>>> Traceback:
>>> 1: .External("rbindXts", dup = FALSE, ..., PACKAGE = "xts")
>>> 2: rbind(deparse.level, ...)
>>> 3: rbind(Portfolio$symbols[[Symbol]]$txn, NewTxn)
>>> 4: addTxn(Portfolio = portfolio, Symbol = symbol, TxnDate = txntime,
>>> TxnQty = orderQty, TxnPrice = txnprice, ... = ..., TxnFees = txnfees)
>>> 5: ruleOrderProc(portfolio = portfolio, symbol = symbol, mktdata = mktdata,
>>> timestamp = timestamp, periodicity = freq, curIndex = curIndex,     ...)
>>> 6: applyRules(portfolio = portfolio, symbol = symbol, strategy = strategy,
>>> mktdata = mktdata, Dates = NULL, indicators = sret$indicators,     signals =
>>> sret$signals, parameters = parameters, ..., path.dep = TRUE,     debug =
>>> debug)
>>> 7: applyStrategy(strategy.st, portfolio.st)
>>> 
>>> Possible actions:
>>> 1: abort (with core dump, if enabled)
>>> 2: normal R exit
>>> 3: exit R without saving workspace
>>> 4: exit R saving workspace
>>> Selection:
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>> 
>>> 
>>> 
>>> 
>>> --
>>> Joshua Ulrich  |  about.me/joshuaulrich
>>> FOSS Trading  |  www.fosstrading.com
>>> 
>>> 
>> 
>> 
>> 
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com
> 
> 
> 
> -- 
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com


From n.manganaro at alum.mit.edu  Mon Oct 12 17:07:11 2015
From: n.manganaro at alum.mit.edu (Nicholas Manganaro)
Date: Mon, 12 Oct 2015 11:07:11 -0400 (EDT)
Subject: [R-SIG-Finance] Congrats!RE: Reading the GSW spot rates from fed
 2006 website
Message-ID: <84607639.48783.1444662431710.JavaMail.help@alum.mit.edu>

Alternatively, the US Treasury H-15 rates are available for automated download from the Fed's website, with a few days' delay. You can download a long historical dataset from the following:
http://www.federalreserve.gov/datadownload/Choose.aspx?rel=H15 .
and update the latest using a link at the following site:
http://www.federalreserve.gov/datadownload/Download.aspx?rel=H15&series=bf17364827e38702b42a58cf8eaa3f78&filetype=csv&label=include&layout=seriescolumn&lastObs=7
Information about setting that up are at: http://www.federalreserve.gov/datadownload/help/default.htm#systems
-----Original Message-----
From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of G See
Sent: Sunday, October 11, 2015 9:18 PM
To: Mahmoud Shammaa <mshammaa at uchicago.edu>
Cc: r-sig-finance <r-sig-finance at r-project.org>
Subject: Re: [R-SIG-Finance] Reading the GSW spot rates from fed 2006 website

It might be easier to work with the .xls file that you can download from a link on this page:
http://www.federalreserve.gov/pubs/feds/2006/200628/200628abs.html

hope it helps,
Garrett

On Sun, Oct 11, 2015 at 5:02 PM, Mahmoud Shammaa <mshammaa at uchicago.edu> wrote:
> Hello,
> Does anyone have any tips or suggestions regarding reading the rates 
> that Gurkaynak, Sack and Wright are updating on this website:
> http://www.federalreserve.gov/econresdata/researchdata/feds200628_1.ht
> ml While I know how to scrape an html page the issue is that they have 
> the pages going from oldest to newest so It is not easily apparent 
> where the latest data is:
> As of right now it is on page 29...
> http://www.federalreserve.gov/econresdata/researchdata/feds200628_29.h
> tml
> .
>
> the problem is that this will change
> What is even more frustrating that if you go to 
> http://www.federalreserve.gov/econresdata/researchdata/feds200628_30.h
> tml data exists but it is not clear in what sequence ... it seems to 
> be draft data..
>
> So I am not sure if anyone on this list has recommendations regarding 
> unruly webpages ..
>
> Thanks,
> Mido Shammaa
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

_______________________________________________
R-SIG-Finance at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.

From mcewan.gareth at gmail.com  Wed Oct 14 09:20:58 2015
From: mcewan.gareth at gmail.com (Gareth McEwan)
Date: Wed, 14 Oct 2015 09:20:58 +0200
Subject: [R-SIG-Finance] Error check on "pspd" function from SPD package
Message-ID: <CALGfFMYBW7GUW1U4+fxtmoXCNnAeex3oUh2MnemP3VO5rLw0OQ@mail.gmail.com>

Hi all

I used the "pspd" function from the SPD package last year and I'm running
the code again, but it seems to throw an error now.

I checked with data from the "rugarch" package and the error is still
thrown.

data(sp500ret)   # in the "rugarch" package
sp = sp500ret
class(sp)   # is a "data.frame" class
sp=as.ts(sp)  #  I tried with and without this step

# standard GARCH model:
spec = ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1),
            submodel=NULL,external.regressors=NULL,variance.targeting=F),

mean.model=list(armaOrder=c(0,0),include.mean=T,external.regressors=NULL),
            distribution.model="std")
tempgarch = ugarchfit(spec=spec,data=sp,solver="hybrid")

# fitting the SPD:
(1)
std.resid.sp = residuals(tempgarch,standardize=T)
class(std.resid.sp) #  "xts"  "zoo"

(2)
stdResid.sp = as.ts(std.resid.sp)  #  NOTE: I tried (1) with and (2)
without this step
class(stdResid.sp)  #  "ts"

# the problem:
(1)
fit.sp = spdfit(std.resid.sp, upper=0.9, lower=0.1, tailfit="GPD",
type="mle", kernelfit="normal",
            information="observed", title=NULL, description=NULL)
sp.unif.variates = pspd(std.resid.sp, fit.sp, linear=T)

Error in UseMethod("pspd") :
  no applicable method for 'pspd' applied to an object of class "c('xts',
'zoo')"

(2)
fit.sp = spdfit(stdResid.sp, upper=0.9, lower=0.1, tailfit="GPD",
type="mle", kernelfit="normal",
            information="observed", title=NULL, description=NULL)
sp.unif.variates = pspd(stdResid.sp, fit.sp, linear=T)

Error in UseMethod("pspd") :
  no applicable method for 'pspd' applied to an object of class "ts"

>From sessionInfo(), I have SPD package version as: spd_2.0-1 (i.e., it
seems to be up to date).

I don't think Can anyone help out with a solution?

Many thanks
Gareth


Additional:
packageDescription("spd")
Package: spd
Type: Package
Title: Semi Parametric Distribution
Version: 2.0-1
Date: 2015-07-02
...

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Thu Oct 15 18:02:41 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 15 Oct 2015 11:02:41 -0500
Subject: [R-SIG-Finance] R/Finance 2016 Call for Papers
Message-ID: <CAPPM_gSgYv3=9Eu=0jvi2SYNes3nDdJh8iZm9isB6nynQ7qG8w@mail.gmail.com>

Call for Papers:

R/Finance 2016: Applied Finance with R
May 20 and 21, 2016
University of Illinois at Chicago

The eighth annual R/Finance conference for applied finance using R
will be held on May 20 and 21, 2016 in Chicago, IL, USA at the
University of Illinois at Chicago.  The conference will cover topics
including portfolio management, time series analysis, advanced risk
tools, high-performance computing, market microstructure, and
econometrics.  All will be discussed within the context of using R as
a primary tool for financial risk management, portfolio construction,
and trading.

Over the past seven years, R/Finance has included attendees from
around the world.  It has featured presentations from prominent
academics and practitioners, and we anticipate another exciting
line-up for 2016.

We invite you to submit complete papers in pdf format for
consideration.  We will also consider one-page abstracts (in txt or
pdf format) although more complete papers are preferred.  We welcome
submissions for both full talks and abbreviated "lightning talks."
Both academic and practitioner proposals related to R are encouraged.

All slides will be made publicly available at conference time.
Presenters are strongly encouraged to provide working R code to
accompany the slides.  Data sets should also be made public for the
purposes of reproducibility (though we realize this may be limited due
to contracts with data vendors).  Preference may be given to
presenters who have released R packages.

The conference will award two (or more) $1000 prizes for best papers.
A submission must be a full paper to be eligible for a best paper
award.  Extended abstracts, even if a full paper is provided by
conference time, are not eligible for a best paper award.  Financial
assistance for travel and accommodation may be available to
presenters, however requests must be made at the time of submission.
Assistance will be granted at the discretion of the conference
committee.

Please make your submission online at: http://www.cvent.com/d/3fqnb8.

The submission deadline is January 29, 2015.  Submitters will be
notified via email by February 29, 2016 of acceptance, presentation
length, and financial assistance (if requested).

Additional details will be announced via the conference website

http://www.RinFinance.com/

as they become available.  Information on previous years' presenters
and their presentations are also at the conference website.  We will
make a separate announcement when registration opens.

For the program committee:
Gib Bassett, Peter Carl, Dirk Eddelbuettel, Brian Peterson, Dale
Rosenthal, Jeffrey Ryan, Joshua Ulrich


-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From josh.m.ulrich at gmail.com  Thu Oct 15 18:20:58 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 15 Oct 2015 11:20:58 -0500
Subject: [R-SIG-Finance] R/Finance 2016 Call for Papers
In-Reply-To: <CAPPM_gSgYv3=9Eu=0jvi2SYNes3nDdJh8iZm9isB6nynQ7qG8w@mail.gmail.com>
References: <CAPPM_gSgYv3=9Eu=0jvi2SYNes3nDdJh8iZm9isB6nynQ7qG8w@mail.gmail.com>
Message-ID: <CAPPM_gTmEyeKrsDteeN+2s7=bHeWYhAWP3bjWNgO0OcQqLWX0Q@mail.gmail.com>

Correction: submission deadline is January 29, *2016*.

On Thu, Oct 15, 2015 at 11:02 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> Call for Papers:
>
> R/Finance 2016: Applied Finance with R
> May 20 and 21, 2016
> University of Illinois at Chicago
>
> The eighth annual R/Finance conference for applied finance using R
> will be held on May 20 and 21, 2016 in Chicago, IL, USA at the
> University of Illinois at Chicago.  The conference will cover topics
> including portfolio management, time series analysis, advanced risk
> tools, high-performance computing, market microstructure, and
> econometrics.  All will be discussed within the context of using R as
> a primary tool for financial risk management, portfolio construction,
> and trading.
>
> Over the past seven years, R/Finance has included attendees from
> around the world.  It has featured presentations from prominent
> academics and practitioners, and we anticipate another exciting
> line-up for 2016.
>
> We invite you to submit complete papers in pdf format for
> consideration.  We will also consider one-page abstracts (in txt or
> pdf format) although more complete papers are preferred.  We welcome
> submissions for both full talks and abbreviated "lightning talks."
> Both academic and practitioner proposals related to R are encouraged.
>
> All slides will be made publicly available at conference time.
> Presenters are strongly encouraged to provide working R code to
> accompany the slides.  Data sets should also be made public for the
> purposes of reproducibility (though we realize this may be limited due
> to contracts with data vendors).  Preference may be given to
> presenters who have released R packages.
>
> The conference will award two (or more) $1000 prizes for best papers.
> A submission must be a full paper to be eligible for a best paper
> award.  Extended abstracts, even if a full paper is provided by
> conference time, are not eligible for a best paper award.  Financial
> assistance for travel and accommodation may be available to
> presenters, however requests must be made at the time of submission.
> Assistance will be granted at the discretion of the conference
> committee.
>
> Please make your submission online at: http://www.cvent.com/d/3fqnb8.
>
> The submission deadline is January 29, 2016.  Submitters will be
> notified via email by February 29, 2016 of acceptance, presentation
> length, and financial assistance (if requested).
>
> Additional details will be announced via the conference website
>
> http://www.RinFinance.com/
>
> as they become available.  Information on previous years' presenters
> and their presentations are also at the conference website.  We will
> make a separate announcement when registration opens.
>
> For the program committee:
> Gib Bassett, Peter Carl, Dirk Eddelbuettel, Brian Peterson, Dale
> Rosenthal, Jeffrey Ryan, Joshua Ulrich
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com


From johannes.lips at gmail.com  Fri Oct 16 14:27:23 2015
From: johannes.lips at gmail.com (Johannes Lips)
Date: Fri, 16 Oct 2015 14:27:23 +0200
Subject: [R-SIG-Finance] Extension of Johansen Procedure ca.jo
Message-ID: <5620ED2B.6090603@gmail.com>

Dear list,

I am currently working on an extension of the basic ca.jo() function to 
also make it possible to incorporate structural breaks, like in Johansen 
et al. (2000). What I basically do is to add a matrix, which 
incorporates possible structural breaks in the cointegration vector. 
Therefore I added the function paramter break.matrix, which so far takes 
the break matrix according to the H_l(r) case of Johansen et al. (2000).
I construct the dummy matrix according to Joyeux (2007) and add them to 
the dumvar and the break.matrix parameter of the ca.jo function.
So far it "works", but I am unsure if I made all the adjustments of the 
ca.jo function correctly and I would be really glad if someone could 
also take a look at the function and see if it does, what it's supposed 
to do.
I uploaded the function to my github repo at [1], where I also provide 
the code to create the dummy matrix incorporating the possible 
structural breaks. Please note, that the creation of the dummy matrix is 
also not yet finished and most probably also needs some changes and is 
only for the purpose of testing the ca.jomoni() function.

Thanks in advance,
Johannes

[1] https://github.com/hannes101/CointegrationAnalysis



References:
Johansen, S?ren, Rocco Mosconi, and Bent Nielsen (2000). ?Cointegration 
analysis in the presence of structural breaks in the deterministic 
trend?. en. In: Econometrics Journal 3.2, pp. 216?249. doi: 
10.1111/1368- 423X.00047 (cit. on p. 6).

Joyeux, Roselyne (2007). ?How to Deal with Structural Breaks in 
Practical Cointegration
Analysis?. English. In: Cointegration for the Applied Economist. Ed. by
B. Bhaskara Rao. 2nd edition. Palgrave Macmillan, p. 256 (cit. on p. 6).


From gutembergfernandes at hotmail.com  Fri Oct 16 15:37:46 2015
From: gutembergfernandes at hotmail.com (Gutemberg schiessl)
Date: Fri, 16 Oct 2015 13:37:46 +0000
Subject: [R-SIG-Finance] DATABASE
Message-ID: <COL128-W1654884DA6BD2DC24177FED13D0@phx.gbl>

somebody knows how to download the data intraday by 15 minutes for the last 12 years? 		 	   		  
	[[alternative HTML version deleted]]


From gambulator at gmail.com  Sat Oct 17 18:15:45 2015
From: gambulator at gmail.com (Gambulator Gambulator)
Date: Sat, 17 Oct 2015 09:15:45 -0700
Subject: [R-SIG-Finance] sample code for a custom rule to replace ruleSignal
Message-ID: <CAFSUCtuUdr7i9KA_p1pkJTQPO37nxNuShoT2QXLe9jZhxVbfAA@mail.gmail.com>

Hi

I saw this
http://r.789695.n4.nabble.com/Writing-sell-rules-with-quantstrat-td4389599.html

by Sergey Pisarenko
<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=user_nodes&user=344717>
and I am trying to implement something similar by starting out with what
he's got (firstProfitable function below)

The program would run and give me the 1st buy and sell signal but then it
keeps saying
"Error in if (!orderPrefer == "") prefer = orderPrefer :
  missing value where TRUE/FALSE needed"

and die right after the 1st signal.


So, I went into debug mode and see what's happening. I am only testing 1
symbol SPY and there is only one order of buy and one order to sell. I
don't add positions in-between. Somehow, Ithis orderPrice variable has 2
entries and I think that's why the prefer is also expecting 2 entries. Does
anyone have a simple sample ? By the way, for the entry, I am still using
signalRule, I only want to replace the exit with this custom function.

add.rule(qs.strategy, name="ruleSignal",
         arguments=list(sigcol="longEntry", sigval=TRUE, orderqty=100,
                        ordertype="market", orderside="long",
                        replace=FALSE, prefer="Close",orderset='rsilong',
allowMagicalThinking=TRUE,osFUN=osMaxEquity),
         type='enter', label="long RDM"
)

add.rule(qs.strategy, name="firstProfitable",
         arguments=list(sigcol="longExit", sigval=TRUE,
orderqty='all',data=mktdata,symbol,maxHold=5,orderside="long",prefer="Close"
                        ),
         type='exit', label="sell RDM"
)





firstProfitable<-function(data, timestamp, portfolio,
symbol,maxHold,prefer) {
  posn <- getPosQty(portfolio, symbol, timestamp)
  if (posn != 0) {
    pos         <- getPos(portfolio, symbol, timestamp)
    holdPeriod  <- as.Date(timestamp) - as.Date(index(pos) )
    print(index(pos))
    print((pos))
    print(as.POSIXlt(timestamp))
    print(as.Date(index(pos)))
    orderprice <- as.numeric(Cl(data[timestamp,]))
    print(orderprice)
    #qty        <- as.vector(pos[, 1])

    if (holdPeriod > maxHold) {
      addOrder(portfolio=portfolio, symbol=symbol,
               timestamp=timestamp, qty='all',
price=as.numeric(orderprice),
               ordertype='market',
side='long',prefer='Close',label='maxHold')
    }

    buy_price   <- as.numeric(pos[1, 2])
    close_price <- as.numeric(Cl(mktdata[timestamp,]))
    profit      <- (close_price - buy_price) / buy_price

    if (profit > 0) {
      addOrder(portfolio=portfolio, symbol=symbol,
               timestamp=timestamp, qty='all',
price=as.numeric(orderprice),
               ordertype='market',
side='long',prefer='Close',label='maxHold')
    }
  }
}

	[[alternative HTML version deleted]]


From gambulator at gmail.com  Sun Oct 18 02:40:14 2015
From: gambulator at gmail.com (Gambulator Gambulator)
Date: Sat, 17 Oct 2015 17:40:14 -0700
Subject: [R-SIG-Finance] sample code for a custom rule to replace
	ruleSignal
In-Reply-To: <CAFSUCtuUdr7i9KA_p1pkJTQPO37nxNuShoT2QXLe9jZhxVbfAA@mail.gmail.com>
References: <CAFSUCtuUdr7i9KA_p1pkJTQPO37nxNuShoT2QXLe9jZhxVbfAA@mail.gmail.com>
Message-ID: <CAFSUCtv5-U_5=DTWW-ryEROA-mWu2WRyY3XLWtGoPmCqSHisrw@mail.gmail.com>

I figured this out.My indicator has an extra XXX.Close column... Sorry
about that.

On Sat, Oct 17, 2015 at 9:15 AM, Gambulator Gambulator <gambulator at gmail.com
> wrote:

> Hi
>
> I saw this
> http://r.789695.n4.nabble.com/Writing-sell-rules-with-quantstrat-td4389599.html
>
> by Sergey Pisarenko
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=user_nodes&user=344717>
> and I am trying to implement something similar by starting out with what
> he's got (firstProfitable function below)
>
> The program would run and give me the 1st buy and sell signal but then it
> keeps saying
> "Error in if (!orderPrefer == "") prefer = orderPrefer :
>   missing value where TRUE/FALSE needed"
>
> and die right after the 1st signal.
>
>
> So, I went into debug mode and see what's happening. I am only testing 1
> symbol SPY and there is only one order of buy and one order to sell. I
> don't add positions in-between. Somehow, Ithis orderPrice variable has 2
> entries and I think that's why the prefer is also expecting 2 entries. Does
> anyone have a simple sample ? By the way, for the entry, I am still using
> signalRule, I only want to replace the exit with this custom function.
>
> add.rule(qs.strategy, name="ruleSignal",
>          arguments=list(sigcol="longEntry", sigval=TRUE, orderqty=100,
>                         ordertype="market", orderside="long",
>                         replace=FALSE, prefer="Close",orderset='rsilong',
> allowMagicalThinking=TRUE,osFUN=osMaxEquity),
>          type='enter', label="long RDM"
> )
>
> add.rule(qs.strategy, name="firstProfitable",
>          arguments=list(sigcol="longExit", sigval=TRUE,
> orderqty='all',data=mktdata,symbol,maxHold=5,orderside="long",prefer="Close"
>                         ),
>          type='exit', label="sell RDM"
> )
>
>
>
>
>
> firstProfitable<-function(data, timestamp, portfolio,
> symbol,maxHold,prefer) {
>   posn <- getPosQty(portfolio, symbol, timestamp)
>   if (posn != 0) {
>     pos         <- getPos(portfolio, symbol, timestamp)
>     holdPeriod  <- as.Date(timestamp) - as.Date(index(pos) )
>     print(index(pos))
>     print((pos))
>     print(as.POSIXlt(timestamp))
>     print(as.Date(index(pos)))
>     orderprice <- as.numeric(Cl(data[timestamp,]))
>     print(orderprice)
>     #qty        <- as.vector(pos[, 1])
>
>     if (holdPeriod > maxHold) {
>       addOrder(portfolio=portfolio, symbol=symbol,
>                timestamp=timestamp, qty='all',
> price=as.numeric(orderprice),
>                ordertype='market',
> side='long',prefer='Close',label='maxHold')
>     }
>
>     buy_price   <- as.numeric(pos[1, 2])
>     close_price <- as.numeric(Cl(mktdata[timestamp,]))
>     profit      <- (close_price - buy_price) / buy_price
>
>     if (profit > 0) {
>       addOrder(portfolio=portfolio, symbol=symbol,
>                timestamp=timestamp, qty='all',
> price=as.numeric(orderprice),
>                ordertype='market',
> side='long',prefer='Close',label='maxHold')
>     }
>   }
> }
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From alexios at 4dscape.com  Sun Oct 18 16:13:38 2015
From: alexios at 4dscape.com (alexios galanos)
Date: Sun, 18 Oct 2015 09:13:38 -0500
Subject: [R-SIG-Finance] Error check on "pspd" function from SPD package
In-Reply-To: <CALGfFMYBW7GUW1U4+fxtmoXCNnAeex3oUh2MnemP3VO5rLw0OQ@mail.gmail.com>
References: <CALGfFMYBW7GUW1U4+fxtmoXCNnAeex3oUh2MnemP3VO5rLw0OQ@mail.gmail.com>
Message-ID: <5623A912.5040502@4dscape.com>

Once again, it's just a matter of reading the documentation.

1. rugarch "prefers" xts
2. spd "requires" numeric:

>From the documentation of pspd:
###########################
x,q    [pspd,dspd] -
a numeric vector of quantiles.
###########################

So I don't see any problem as the following works just fine:

library(rugarch)
library(spd)
library(xts)
data(sp500ret)   # in the "rugarch" package
sp = xts(sp500ret[,1], as.Date(rownames(sp500ret)))
# standard GARCH model:
spec =
ugarchspec(mean.model=list(armaOrder=c(0,0)),distribution.model="std")
tempgarch = ugarchfit(spec=spec,data=sp,solver="hybrid")
# fitting the SPD:
std.resid.sp = as.numeric(residuals(tempgarch,standardize=T))
fit.sp = spdfit(std.resid.sp, upper=0.9, lower=0.1, tailfit="GPD",
type="mle", kernelfit="information="observed")
sp.unif.variates = pspd(std.resid.sp, fit.sp, linear=T)


-A

On 14/10/2015 02:20, Gareth McEwan wrote:
> Hi all
>
> I used the "pspd" function from the SPD package last year and I'm running
> the code again, but it seems to throw an error now.
>
> I checked with data from the "rugarch" package and the error is still
> thrown.
>
> data(sp500ret)   # in the "rugarch" package
> sp = sp500ret
> class(sp)   # is a "data.frame" class
> sp=as.ts(sp)  #  I tried with and without this step
>
> # standard GARCH model:
> spec = ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1),
>             submodel=NULL,external.regressors=NULL,variance.targeting=F),
>
> mean.model=list(armaOrder=c(0,0),include.mean=T,external.regressors=NULL),
>             distribution.model="std")
> tempgarch = ugarchfit(spec=spec,data=sp,solver="hybrid")
>
> # fitting the SPD:
> (1)
> std.resid.sp = residuals(tempgarch,standardize=T)
> class(std.resid.sp) #  "xts"  "zoo"
>
> (2)
> stdResid.sp = as.ts(std.resid.sp)  #  NOTE: I tried (1) with and (2)
> without this step
> class(stdResid.sp)  #  "ts"
>
> # the problem:
> (1)
> fit.sp = spdfit(std.resid.sp, upper=0.9, lower=0.1, tailfit="GPD",
> type="mle", kernelfit="normal",
>             information="observed", title=NULL, description=NULL)
> sp.unif.variates = pspd(std.resid.sp, fit.sp, linear=T)
>
> Error in UseMethod("pspd") :
>   no applicable method for 'pspd' applied to an object of class "c('xts',
> 'zoo')"
>
> (2)
> fit.sp = spdfit(stdResid.sp, upper=0.9, lower=0.1, tailfit="GPD",
> type="mle", kernelfit="normal",
>             information="observed", title=NULL, description=NULL)
> sp.unif.variates = pspd(stdResid.sp, fit.sp, linear=T)
>
> Error in UseMethod("pspd") :
>   no applicable method for 'pspd' applied to an object of class "ts"
>
> >From sessionInfo(), I have SPD package version as: spd_2.0-1 (i.e., it
> seems to be up to date).
>
> I don't think Can anyone help out with a solution?
>
> Many thanks
> Gareth
>
>
> Additional:
> packageDescription("spd")
> Package: spd
> Type: Package
> Title: Semi Parametric Distribution
> Version: 2.0-1
> Date: 2015-07-02
> ...
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From agquantr at gmail.com  Wed Oct 21 21:05:50 2015
From: agquantr at gmail.com (Am Gut)
Date: Wed, 21 Oct 2015 15:05:50 -0400
Subject: [R-SIG-Finance] Creating an index based on a time variable
Message-ID: <CACpG4GCRFEm3-r4nxugbk+Ek5OQHK+mHZrt1qCry2DyD3cn6=A@mail.gmail.com>

Everyone,

I would appreciate some help on a very basic topic that I have been
struggling with for quite a while. I am using the xts packages and have
gone through quite a bit of documentation in search of how to create a time
index based on a time column in my dataset.

I am following the code used directly in the xts package documentation and
would greatly appreciate it if someone would help. The beginning of my
imported dataset looks like:

row.names Consumer Discretionary Consumer Staples 1/31/1995 0.6468773
2.047813 2/28/1995 3.39433 2.866054 3/31/1995 3.0161 2.887118 4/28/1995
-1.341188 2.826405 5/31/1995 4.459739 4.309547 6/30/1995 2.636647 1.610363
7/31/1995 3.298938 -0.002974272

I am using the following code:

require(xts)
sector_returns = read.csv("Sector.csv", head=TRUE)
class(sector_returns)

sector_returns = as.matrix(sector_returns)
sector_xts = as.xts(sector_returns,dateFormat='Date')

the last line gives me the following error:

Error in as.xts.matrix(sector_returns, dateFormat = "Date") :
  order.by must be either 'rownames()' or otherwise specified

I have tried a few different ways of using the rownames function and have
had zero success. I apologize if this question is extremely basic, as I
have made significant effort trying to get this to work. Any help on
assigning the rownames to my date variable (row.names column) would be
extremely helpful.

Thanks in advance,

AG

	[[alternative HTML version deleted]]


From brian at braverock.com  Wed Oct 21 21:16:02 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 21 Oct 2015 14:16:02 -0500
Subject: [R-SIG-Finance] Creating an index based on a time variable
In-Reply-To: <CACpG4GCRFEm3-r4nxugbk+Ek5OQHK+mHZrt1qCry2DyD3cn6=A@mail.gmail.com>
References: <CACpG4GCRFEm3-r4nxugbk+Ek5OQHK+mHZrt1qCry2DyD3cn6=A@mail.gmail.com>
Message-ID: <1445454962.4147.8.camel@brian-rcg>

You didn't follow the posting guide.  Your example is not reproducible,
and posting HTML that just gets converted to plain text doesn't help.

I assume that you currently have a data.frame as is output by read.csv.

Why are you converting it to a matrix?

I guess that what you want from your data.frame is most likely something
like this:

sector_returns <- read.csv("Sector.csv", head=TRUE)
sector_returns <- xts(sector_returns[,-1],
order.by=as.Date(sector_returns[,1], format="%m/%d/%Y"))


see 

?xts

and

?strftime

for more information.


Regards,

Brian


On Wed, 2015-10-21 at 15:05 -0400, Am Gut wrote:
> Everyone,
> 
> I would appreciate some help on a very basic topic that I have been
> struggling with for quite a while. I am using the xts packages and have
> gone through quite a bit of documentation in search of how to create a time
> index based on a time column in my dataset.
> 
> I am following the code used directly in the xts package documentation and
> would greatly appreciate it if someone would help. The beginning of my
> imported dataset looks like:
> 
> row.names Consumer Discretionary Consumer Staples 1/31/1995 0.6468773
> 2.047813 2/28/1995 3.39433 2.866054 3/31/1995 3.0161 2.887118 4/28/1995
> -1.341188 2.826405 5/31/1995 4.459739 4.309547 6/30/1995 2.636647 1.610363
> 7/31/1995 3.298938 -0.002974272
> 
> I am using the following code:
> 
> require(xts)
> sector_returns = read.csv("Sector.csv", head=TRUE)
> class(sector_returns)
> 
> sector_returns = as.matrix(sector_returns)
> sector_xts = as.xts(sector_returns,dateFormat='Date')
> 
> the last line gives me the following error:
> 
> Error in as.xts.matrix(sector_returns, dateFormat = "Date") :
>   order.by must be either 'rownames()' or otherwise specified
> 
> I have tried a few different ways of using the rownames function and have
> had zero success. I apologize if this question is extremely basic, as I
> have made significant effort trying to get this to work. Any help on
> assigning the rownames to my date variable (row.names column) would be
> extremely helpful.
> 
> Thanks in advance,
> 
> AG
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From hlinder33 at gmail.com  Wed Oct 21 21:19:15 2015
From: hlinder33 at gmail.com (Hannah Linder)
Date: Wed, 21 Oct 2015 12:19:15 -0700
Subject: [R-SIG-Finance] GARCH convergence error in for-loop
Message-ID: <CAKqaSd-6reEcTsxhzRk-zLZQGe9v-4jDM=5UysdmM3gVN825+Q@mail.gmail.com>

Hello,

I am using the rugarch package to fit to simulated data. I am fitting the
same garch model to 1000 simulated data sets (all very similar with
slightly different error). Within each data set I am using 10-fold CV, so I
am fitting the model to 10 training sets. When I run the code (shown below)
I occasionally receive the error:

Solver Message: Error in is.nloptr(ret) : at least one element in x0 < lb

When I re-run the exact same code starting from the iteration that caused
and error, the error goes away. Does anyone know if this may be an error
with R or if I am missing a problem in the model?

Thank-you very much for your time!

Code:


library(rugarch)

fit.spec1=array(list(),c(1000,10))
fit1=array(list(),c(1000,10))


for (j in 1:1000){
  for (i in 1:10){
    fit.spec1[[j,i]]=ugarchspec(variance.model = list(model = "sGARCH",
                                       garchOrder = c(1,
1),external.regressors=as.matrix(train.all[[j]][[i]][,c(5,6)])),
                                mean.model= list(armaOrder = c(1,1),
                                                 include.mean = T,

 external.regressors=as.matrix(train.all[[j]][[i]][,c(2,4,5,6)])),
                                distribution.model = "sstd")
    fit1[[j,i]] <- ugarchfit(data=train.all[[j]][[i]][,c(1)],spec =
fit.spec1[[j,i]],solver="hybrid")
 }}

I am actually using the model on biological data, rather than finance. The
regressors in the model are  Julian day count (2), tidal range (4), and a
sin and cos (5,6) transform for time-of-day (24-hr period).

	[[alternative HTML version deleted]]


From agquantr at gmail.com  Thu Oct 22 19:27:26 2015
From: agquantr at gmail.com (Am Gut)
Date: Thu, 22 Oct 2015 13:27:26 -0400
Subject: [R-SIG-Finance] Creating an index based on a time variable
In-Reply-To: <1445454962.4147.8.camel@brian-rcg>
References: <CACpG4GCRFEm3-r4nxugbk+Ek5OQHK+mHZrt1qCry2DyD3cn6=A@mail.gmail.com>
	<1445454962.4147.8.camel@brian-rcg>
Message-ID: <CACpG4GDojQVoT4squhDPySUtgcW-AWDWK4nU28B8O_txeeFuEw@mail.gmail.com>

Brian,

Thank you very much. I will read the instructions before I post next time.
I was just converting to matrix only to replicate exactly what the
documentation was doing so there would not be any issue. Your feedback is
helpful and I appreciate your speed as well.

Kind Regards,

AG

On Wed, Oct 21, 2015 at 3:16 PM, Brian G. Peterson <brian at braverock.com>
wrote:

> You didn't follow the posting guide.  Your example is not reproducible,
> and posting HTML that just gets converted to plain text doesn't help.
>
> I assume that you currently have a data.frame as is output by read.csv.
>
> Why are you converting it to a matrix?
>
> I guess that what you want from your data.frame is most likely something
> like this:
>
> sector_returns <- read.csv("Sector.csv", head=TRUE)
> sector_returns <- xts(sector_returns[,-1],
> order.by=as.Date(sector_returns[,1], format="%m/%d/%Y"))
>
>
> see
>
> ?xts
>
> and
>
> ?strftime
>
> for more information.
>
>
> Regards,
>
> Brian
>
>
> On Wed, 2015-10-21 at 15:05 -0400, Am Gut wrote:
> > Everyone,
> >
> > I would appreciate some help on a very basic topic that I have been
> > struggling with for quite a while. I am using the xts packages and have
> > gone through quite a bit of documentation in search of how to create a
> time
> > index based on a time column in my dataset.
> >
> > I am following the code used directly in the xts package documentation
> and
> > would greatly appreciate it if someone would help. The beginning of my
> > imported dataset looks like:
> >
> > row.names Consumer Discretionary Consumer Staples 1/31/1995 0.6468773
> > 2.047813 2/28/1995 3.39433 2.866054 3/31/1995 3.0161 2.887118 4/28/1995
> > -1.341188 2.826405 5/31/1995 4.459739 4.309547 6/30/1995 2.636647
> 1.610363
> > 7/31/1995 3.298938 -0.002974272
> >
> > I am using the following code:
> >
> > require(xts)
> > sector_returns = read.csv("Sector.csv", head=TRUE)
> > class(sector_returns)
> >
> > sector_returns = as.matrix(sector_returns)
> > sector_xts = as.xts(sector_returns,dateFormat='Date')
> >
> > the last line gives me the following error:
> >
> > Error in as.xts.matrix(sector_returns, dateFormat = "Date") :
> >   order.by must be either 'rownames()' or otherwise specified
> >
> > I have tried a few different ways of using the rownames function and have
> > had zero success. I apologize if this question is extremely basic, as I
> > have made significant effort trying to get this to work. Any help on
> > assigning the rownames to my date variable (row.names column) would be
> > extremely helpful.
> >
> > Thanks in advance,
> >
> > AG
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
>

	[[alternative HTML version deleted]]


From gambulator at gmail.com  Thu Oct 22 19:41:22 2015
From: gambulator at gmail.com (Gambulator Gambulator)
Date: Thu, 22 Oct 2015 10:41:22 -0700
Subject: [R-SIG-Finance] How to find out if a signal was active within the
	last X days
Message-ID: <CAFSUCttLA9zaSsY7CUhzudxZrQM4kedY4BcRQc2oqUsQMH86qg@mail.gmail.com>

Hi All

I want to prevent another buy signal to be triggered if it was just active
within the past X days. For example, if I always buy on Monday and exit on
Tuesday, but I only want to do this every other week. Is there a way to
tell if this signal was active within the past 5 business days already so
it won't be triggered this week but it will be triggered next week since it
has been 5 days ?

thanks

	[[alternative HTML version deleted]]


From ilya.kipnis at gmail.com  Fri Oct 23 00:34:47 2015
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Thu, 22 Oct 2015 18:34:47 -0400
Subject: [R-SIG-Finance] How to find out if a signal was active within
 the last X days
In-Reply-To: <CAFSUCttLA9zaSsY7CUhzudxZrQM4kedY4BcRQc2oqUsQMH86qg@mail.gmail.com>
References: <CAFSUCttLA9zaSsY7CUhzudxZrQM4kedY4BcRQc2oqUsQMH86qg@mail.gmail.com>
Message-ID: <CA+oJuEGrS04Fp9uS3+SP-W_eRr23PgGc1S3mrGK+7SJ92Aujig@mail.gmail.com>

Use a streak calculation, like the one Larry Connors uses in his Connors
RSI.

On Thu, Oct 22, 2015 at 1:41 PM, Gambulator Gambulator <gambulator at gmail.com
> wrote:

> Hi All
>
> I want to prevent another buy signal to be triggered if it was just active
> within the past X days. For example, if I always buy on Monday and exit on
> Tuesday, but I only want to do this every other week. Is there a way to
> tell if this signal was active within the past 5 business days already so
> it won't be triggered this week but it will be triggered next week since it
> has been 5 days ?
>
> thanks
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From gambulator at gmail.com  Fri Oct 23 03:03:19 2015
From: gambulator at gmail.com (Gambulator Gambulator)
Date: Thu, 22 Oct 2015 18:03:19 -0700
Subject: [R-SIG-Finance] How to find out if a signal was active within
 the last X days
In-Reply-To: <CA+oJuEGrS04Fp9uS3+SP-W_eRr23PgGc1S3mrGK+7SJ92Aujig@mail.gmail.com>
References: <CAFSUCttLA9zaSsY7CUhzudxZrQM4kedY4BcRQc2oqUsQMH86qg@mail.gmail.com>
	<CA+oJuEGrS04Fp9uS3+SP-W_eRr23PgGc1S3mrGK+7SJ92Aujig@mail.gmail.com>
Message-ID: <CAFSUCtuJbD-xKsaEs9SqhkEJhAX5eQ0npijyEfZEm11e=yyMrw@mail.gmail.com>

I see that I actually have access to the mktdata in any osFun so I am set.
Thanks

On Thu, Oct 22, 2015 at 3:34 PM, Ilya Kipnis <ilya.kipnis at gmail.com> wrote:

> Use a streak calculation, like the one Larry Connors uses in his Connors
> RSI.
>
> On Thu, Oct 22, 2015 at 1:41 PM, Gambulator Gambulator <
> gambulator at gmail.com> wrote:
>
>> Hi All
>>
>> I want to prevent another buy signal to be triggered if it was just active
>> within the past X days. For example, if I always buy on Monday and exit on
>> Tuesday, but I only want to do this every other week. Is there a way to
>> tell if this signal was active within the past 5 business days already so
>> it won't be triggered this week but it will be triggered next week since
>> it
>> has been 5 days ?
>>
>> thanks
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>

	[[alternative HTML version deleted]]


From amelia_marsh08 at yahoo.com  Mon Oct 26 08:47:04 2015
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Mon, 26 Oct 2015 07:47:04 +0000 (UTC)
Subject: [R-SIG-Finance] Monte Carlo Convergence test
References: <532058447.2459603.1445845624626.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <532058447.2459603.1445845624626.JavaMail.yahoo@mail.yahoo.com>

Dear Forum, 

I have series of say 100 (say equity) instrument prices. From these prices, for each of these 100 instruments, I generate returns using ln(current price / previous price). 

Assuming originally I had 251 prices available for each of these 100 instruments over last one year period, I have matrix of 250X100 returns. 

I assume that these returns follow Multivariate Normal Distribution. Using the returns, I generate a mean Vector of returns 'M' and also generate the Variance - covariance matrix of returns 'S'. 

Then using MASS library, I simulate say 10000 returns for each of the 100 instruments as : 

sim_rates = mvrnorm(10000, M, S) 

This gives me 10000 simulated returns for each of the 100 instruments and using these simulated returns carry out further analysis. 

My query is how do I carry out convergence test in R to arrive at sufficint number of simulations? 

With regards 

Amelia


From agquantr at gmail.com  Mon Oct 26 15:21:48 2015
From: agquantr at gmail.com (Am Gut)
Date: Mon, 26 Oct 2015 10:21:48 -0400
Subject: [R-SIG-Finance] Calculating trailing returns
Message-ID: <CACpG4GAo-Hdw56Cma+ayO9Uo-BWQn8p5omZNEOJAawmkThPjGw@mail.gmail.com>

Dear R Users,

I am trying to calculate trailing month and annual returns with daily data.
The data is already in returns, and not in price. I have been looking for a
handy function to calculate trailing returns where I can specify the look
back period (number of lags), but have been completely unsuccessful. Can
anyone please suggest a way that I can calculate trailing returns from my
dataset of many different return streams? Any help would be greatly
appreciated.

Kind Regards,

AG

	[[alternative HTML version deleted]]


From michael.weylandt at gmail.com  Mon Oct 26 15:32:34 2015
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Mon, 26 Oct 2015 09:32:34 -0500
Subject: [R-SIG-Finance] Monte Carlo Convergence test
In-Reply-To: <532058447.2459603.1445845624626.JavaMail.yahoo@mail.yahoo.com>
References: <532058447.2459603.1445845624626.JavaMail.yahoo@mail.yahoo.com>
	<532058447.2459603.1445845624626.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <442075E8-8932-41F2-980B-6A0C06788A68@gmail.com>


> On Oct 26, 2015, at 2:47, Amelia Marsh via R-SIG-Finance <r-sig-finance at r-project.org> wrote:
> 
> Dear Forum, 
> 
> I have series of say 100 (say equity) instrument prices. From these prices, for each of these 100 instruments, I generate returns using ln(current price / previous price). 
> 
> Assuming originally I had 251 prices available for each of these 100 instruments over last one year period, I have matrix of 250X100 returns. 
> 
> I assume that these returns follow Multivariate Normal Distribution. Using the returns, I generate a mean Vector of returns 'M' and also generate the Variance - covariance matrix of returns 'S'. 
> 
> Then using MASS library, I simulate say 10000 returns for each of the 100 instruments as : 
> 
> sim_rates = mvrnorm(10000, M, S) 
> 
> This gives me 10000 simulated returns for each of the 100 instruments and using these simulated returns carry out further analysis. 
> 
> My query is how do I carry out convergence test in R to arrive at sufficint number of simulations? 

Hi Amelia,

It's not clear to me what you're asking. 

It sounds like you might be confusing the variance of MC (Monte Carlo -- simulation models) estimates with convergence of MCMC (Markov Chain Monte Carlo -- a means of simulating from a distribution you can't write down explicitly). Since it doesn't sound like you're doing MCMC, I'm going to go ahead and assume you're asking how to estimate the variance of your MC estimates. Once you can do that, you can just bump up the number of simulations till you reach some point which is 'good enough' for your goal. 

Since you've assumed a distribution and are sampling directly from it, you've already converged.  End of story. (If your starting point and destination are the same, your travel time is quite short) The predictions you make, however, will have very high variance -- a single sample won't necessarily give you the right result. (Not specific to MC -- same issue comes up with variance of estimates from small amounts of observed data) The key point here is that you need to look at the variability of the final result of your analysis, not the simulated data you feed into further analysis. 

MC estimates typically use the sample mean and you can use the sample variance as a estimate of the variance of your estimator. (This should be covered in any intro stats course -- https://en.m.wikipedia.org/wiki/Standard_error#Standard_error_of_the_mean) A bit more advanced would be to divide your data into multiple 'chunks' and see how your estimate varies across these. 

(Paul Glasserman's book would be a good reference for these sorts of questions if you have access to a good library; Sheldon Ross's simulation book is more introductory, but not bad. Additionally, these issues will be discussed in most Bayesian textbooks, but those books also have to worry about MCMC convergence and that gets more air-time)

A final word of caution: increasing the number of simulations isn't going to make your analyses more accurate, only more precise. (In Machine Learning speak, by increasing the number of samples, you're reducing variance only -- not touching bias).  You're making a very strong assumption with multivariate Gaussianity. If you're worried about this, I'd look into resampling methods. 

 Michael


> 
> With regards 
> 
> Amelia
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From michael.weylandt at gmail.com  Mon Oct 26 15:34:57 2015
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Mon, 26 Oct 2015 09:34:57 -0500
Subject: [R-SIG-Finance] Calculating trailing returns
In-Reply-To: <CACpG4GAo-Hdw56Cma+ayO9Uo-BWQn8p5omZNEOJAawmkThPjGw@mail.gmail.com>
References: <CACpG4GAo-Hdw56Cma+ayO9Uo-BWQn8p5omZNEOJAawmkThPjGw@mail.gmail.com>
Message-ID: <C498A5CE-C52F-413A-A7BD-218A89EE3156@gmail.com>


> On Oct 26, 2015, at 9:21, Am Gut <agquantr at gmail.com> wrote:
> 
> Dear R Users,
> 
> I am trying to calculate trailing month and annual returns with daily data.
> The data is already in returns, and not in price. I have been looking for a
> handy function to calculate trailing returns where I can specify the look
> back period (number of lags), but have been completely unsuccessful. Can
> anyone please suggest a way that I can calculate trailing returns from my
> dataset of many different return streams? Any help would be greatly
> appreciated.

Assuming you have geometric/log/continuously-compounded returns, aren't you just looking for a rolling sum? TTR and zoo both provide this. 

> 
> Kind Regards,
> 
> AG
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From agquantr at gmail.com  Mon Oct 26 15:53:03 2015
From: agquantr at gmail.com (Am Gut)
Date: Mon, 26 Oct 2015 10:53:03 -0400
Subject: [R-SIG-Finance] Calculating trailing returns
In-Reply-To: <C498A5CE-C52F-413A-A7BD-218A89EE3156@gmail.com>
References: <CACpG4GAo-Hdw56Cma+ayO9Uo-BWQn8p5omZNEOJAawmkThPjGw@mail.gmail.com>
	<C498A5CE-C52F-413A-A7BD-218A89EE3156@gmail.com>
Message-ID: <CACpG4GAyuk4Uqop2RmZKMe7HhzbW5jot-90B_+kjNmyZMKOhPw@mail.gmail.com>

Good Morning Michael,

I have simple return data, in a daily periodicity. I am essentially trying
to calculate the trailing returns for say 252 periods, assuming I am trying
to look at trailing 12 month returns. So I have been trying to use a
product function, but I am having trouble specifying a look back period. I
did use the apply.rolling function from the PerformanceAnalytics package,
but was unable to us the prod function with it- the function was simply
returning an average:

##compute 12-month (lookback variable) returnm
List = list()
for (i in 1:ncol(sector_xts))
{
  List[[i]] = apply.rolling(sector_xts[,i], function(x) prod(1+x)-1, width
= 252)

}
lookback_returns = do.call(cbind,List)

Is there any way to set a look back or trailing period number on the
product function? If not is there any ways that you guys can suggest to
calculate trailing returns of larger periodicity from daily return data?

Kind Regards,

AG

On Mon, Oct 26, 2015 at 10:34 AM, Michael Weylandt <
michael.weylandt at gmail.com> wrote:

>
> > On Oct 26, 2015, at 9:21, Am Gut <agquantr at gmail.com> wrote:
> >
> > Dear R Users,
> >
> > I am trying to calculate trailing month and annual returns with daily
> data.
> > The data is already in returns, and not in price. I have been looking
> for a
> > handy function to calculate trailing returns where I can specify the look
> > back period (number of lags), but have been completely unsuccessful. Can
> > anyone please suggest a way that I can calculate trailing returns from my
> > dataset of many different return streams? Any help would be greatly
> > appreciated.
>
> Assuming you have geometric/log/continuously-compounded returns, aren't
> you just looking for a rolling sum? TTR and zoo both provide this.
>
> >
> > Kind Regards,
> >
> > AG
> >
> >    [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From michael.weylandt at gmail.com  Mon Oct 26 17:01:11 2015
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Mon, 26 Oct 2015 11:01:11 -0500
Subject: [R-SIG-Finance] Calculating trailing returns
In-Reply-To: <CACpG4GAyuk4Uqop2RmZKMe7HhzbW5jot-90B_+kjNmyZMKOhPw@mail.gmail.com>
References: <CACpG4GAo-Hdw56Cma+ayO9Uo-BWQn8p5omZNEOJAawmkThPjGw@mail.gmail.com>
	<C498A5CE-C52F-413A-A7BD-218A89EE3156@gmail.com>
	<CACpG4GAyuk4Uqop2RmZKMe7HhzbW5jot-90B_+kjNmyZMKOhPw@mail.gmail.com>
Message-ID: <CAAmySGPi1_qnaMf5-F=dJrtDvfKxWOKZpNGT6XHnF3tYoiHcVQ@mail.gmail.com>

On Mon, Oct 26, 2015 at 9:53 AM, Am Gut <agquantr at gmail.com> wrote:

> Good Morning Michael,
>
> I have simple return data, in a daily periodicity. I am essentially trying
> to calculate the trailing returns for say 252 periods, assuming I am trying
> to look at trailing 12 month returns. So I have been trying to use a
> product function, but I am having trouble specifying a look back period. I
> did use the apply.rolling function from the PerformanceAnalytics package,
> but was unable to us the prod function with it- the function was simply
> returning an average:
>

You're not passing the function argument correctly (you're passing
'trim=function(x) prod(1+x)-1'). Check the function signature.

library(PerformanceAnalytics)
data(managers)
M1 <- managers[, 1, drop=FALSE]

apply.rolling(M1, width=5, FUN=function(x) prod(1+x)-1)[5] ## cumulative
return of first 5 observations

## compare to manual calculation
prod(M1[1:5]+1) - 1


Michael


> ##compute 12-month (lookback variable) returnm
> List = list()
> for (i in 1:ncol(sector_xts))
> {
>   List[[i]] = apply.rolling(sector_xts[,i], function(x) prod(1+x)-1, width
> = 252)
>
> }
> lookback_returns = do.call(cbind,List)
>

	[[alternative HTML version deleted]]


From felipe.boralli at itau-unibanco.com.br  Mon Oct 26 18:53:27 2015
From: felipe.boralli at itau-unibanco.com.br (Felipe Bergamin Boralli)
Date: Mon, 26 Oct 2015 15:53:27 -0200
Subject: [R-SIG-Finance] VAR identified by sign restrictions
Message-ID: <3488_1445882009_562E6899_3488_2350_17_413C6D1511B0F344BFE96ECA861FD8BD1E8DE184BE@VCMTP0007CLD.corp1.rc.itau>

Hello,
I would like to run a Vector Autoregression (VAR) identified by sign restrictions, as in this paper:
Sign Restrictions, Structural Vector Autoregressions, and Useful Prior Information - Baumeister et al
http://econweb.ucsd.edu/~jhamilto/bh1.pdf

Before implementing this, I would like to see if someone else has already done it, and I have not found it either in CRAN or in this list archives.

Is there somewhere this routine is implemented?

Thanks for your help.

Felipe 




"Esta mensagem e reservada e sua divulgacao, distribuicao, reproducao ou qualquer forma de uso e proibida e depende de previa autorizacao desta instituicao. O remetente utiliza o correio eletronico no exercicio do seu trabalho ou em razao dele, eximindo esta instituicao de qualquer responsabilidade por utilizacao indevida. Se voce recebeu esta mensagem por engano, favor elimina-la imediatamente."

"This message is reserved and its disclosure, distribution, reproduction or any other form of use is prohibited and shall depend upon previous proper authorization. The sender uses the electronic mail in the exercise of his/her work or by virtue thereof, and the institution accepts no liability for its undue use. If you have received this e-mail by mistake, please delete it immediately."


From gambulator at gmail.com  Mon Oct 26 19:20:44 2015
From: gambulator at gmail.com (Gambulator Gambulator)
Date: Mon, 26 Oct 2015 11:20:44 -0700
Subject: [R-SIG-Finance] parallel processing
In-Reply-To: <CAFSUCtsWm8DSA=ZXJnH=O8pj7X0gTp9OMGPYTF=_3Xw66WtoBQ@mail.gmail.com>
References: <CAFSUCttYLqLncuoupqOMa81_YEAPFLHzzPJnrCnVtPCO48XnLQ@mail.gmail.com>
	<CAFSUCtsWm8DSA=ZXJnH=O8pj7X0gTp9OMGPYTF=_3Xw66WtoBQ@mail.gmail.com>
Message-ID: <CAFSUCtvZoW-=8cNTadWJshiW=7gPHc=jLHDJ7dPSOQL7ibn9rw@mail.gmail.com>

I did quite a bit of googling. it is not clear to me if it works now on
Windows or not. it is pretty slow even if I have turned off my
debug,verbose or print. any idea?

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Mon Oct 26 19:24:05 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 26 Oct 2015 13:24:05 -0500
Subject: [R-SIG-Finance] parallel processing
In-Reply-To: <CAFSUCtvZoW-=8cNTadWJshiW=7gPHc=jLHDJ7dPSOQL7ibn9rw@mail.gmail.com>
References: <CAFSUCttYLqLncuoupqOMa81_YEAPFLHzzPJnrCnVtPCO48XnLQ@mail.gmail.com>
	<CAFSUCtsWm8DSA=ZXJnH=O8pj7X0gTp9OMGPYTF=_3Xw66WtoBQ@mail.gmail.com>
	<CAFSUCtvZoW-=8cNTadWJshiW=7gPHc=jLHDJ7dPSOQL7ibn9rw@mail.gmail.com>
Message-ID: <CAPPM_gTiWP5iHuq0BDUN3_0tQsipAOPjZDG2tSuXfApPzTSjuw@mail.gmail.com>

On Mon, Oct 26, 2015 at 1:20 PM, Gambulator Gambulator
<gambulator at gmail.com> wrote:
> I did quite a bit of googling. it is not clear to me if it works now on
> Windows or not. it is pretty slow even if I have turned off my
> debug,verbose or print. any idea?
>
You need to be a lot more specific.  There are several parallel
processing methods that work on Windows.  And whether or not parallel
processing will be any faster than sequential processing depends on
the nature of the problem.

>         [[alternative HTML version deleted]]
>
^^^
Please do not post HTML, as it says in the posting guide.

> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
^^^
Note that this question has nothing to do with finance, and should be on R-help.

-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From ezivot at uw.edu  Mon Oct 26 19:40:46 2015
From: ezivot at uw.edu (Eric Zivot)
Date: Mon, 26 Oct 2015 11:40:46 -0700
Subject: [R-SIG-Finance] VAR identified by sign restrictions
In-Reply-To: <3488_1445882009_562E6899_3488_2350_17_413C6D1511B0F344BFE96ECA861FD8BD1E8DE184BE@VCMTP0007CLD.corp1.rc.itau>
References: <3488_1445882009_562E6899_3488_2350_17_413C6D1511B0F344BFE96ECA861FD8BD1E8DE184BE@VCMTP0007CLD.corp1.rc.itau>
Message-ID: <07c601d1101d$d410c5a0$7c3250e0$@uw.edu>

Jim Hamilton mentions in his blog post about the paper
(http://econbrowser.com/archives/2015/10/economic-effects-of-shocks-to-oil-s
upply-and-demand ) that he has Matlab code for the calculations that can be
downloaded from his webpage (http://econweb.ucsd.edu/~jhamilton/BHcode.zip
). I would start there to convert to R. 
HTH
ez

-----Original Message-----
From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On Behalf
Of Felipe Bergamin Boralli
Sent: Monday, October 26, 2015 10:53 AM
To: 'r-sig-finance at r-project.org' <r-sig-finance at r-project.org>
Subject: [R-SIG-Finance] VAR identified by sign restrictions

Hello,
I would like to run a Vector Autoregression (VAR) identified by sign
restrictions, as in this paper:
Sign Restrictions, Structural Vector Autoregressions, and Useful Prior
Information - Baumeister et al http://econweb.ucsd.edu/~jhamilto/bh1.pdf

Before implementing this, I would like to see if someone else has already
done it, and I have not found it either in CRAN or in this list archives.

Is there somewhere this routine is implemented?

Thanks for your help.

Felipe 




"Esta mensagem e reservada e sua divulgacao, distribuicao, reproducao ou
qualquer forma de uso e proibida e depende de previa autorizacao desta
instituicao. O remetente utiliza o correio eletronico no exercicio do seu
trabalho ou em razao dele, eximindo esta instituicao de qualquer
responsabilidade por utilizacao indevida. Se voce recebeu esta mensagem por
engano, favor elimina-la imediatamente."

"This message is reserved and its disclosure, distribution, reproduction or
any other form of use is prohibited and shall depend upon previous proper
authorization. The sender uses the electronic mail in the exercise of
his/her work or by virtue thereof, and the institution accepts no liability
for its undue use. If you have received this e-mail by mistake, please
delete it immediately."

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From gambulator at gmail.com  Mon Oct 26 23:31:22 2015
From: gambulator at gmail.com (Gambulator Gambulator)
Date: Mon, 26 Oct 2015 15:31:22 -0700
Subject: [R-SIG-Finance] parallel processing
In-Reply-To: <0765308CD028654885F30322557308D81EFBAFE6@NYCSM0208.rth.ad.rothschild.com>
References: <CAFSUCttYLqLncuoupqOMa81_YEAPFLHzzPJnrCnVtPCO48XnLQ@mail.gmail.com>
	<CAFSUCtsWm8DSA=ZXJnH=O8pj7X0gTp9OMGPYTF=_3Xw66WtoBQ@mail.gmail.com>
	<CAFSUCtvZoW-=8cNTadWJshiW=7gPHc=jLHDJ7dPSOQL7ibn9rw@mail.gmail.com>
	<0765308CD028654885F30322557308D81EFBAFE6@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <CAFSUCtuJTSOoqcUFCEZ0snco-7VsNRDsN90CJ1SXWKA-fA0cpA@mail.gmail.com>

thanks. I am running the optimization and yeah it is pretty slow so I
figure that I should put it on more cores. It seems/sounds like it 'd work
fine on Linux but now that you mention Windows, may be I will give it a
shot before firing up AWS and go through the pain to make an image and all
that.

thx

On Mon, Oct 26, 2015 at 11:28 AM, Bos, Roger <roger.bos at rothschild.com>
wrote:

> Not all of the parallel packages with in Windows, but doParallel is one
> that does.  Here is how to start it with 3 cores:
>
> library(doParallel)
> cl <- makeCluster(3)
> registerDoParallel(cl)
>
> It will automatically load the foreach package provided you have it
> installed.  Please see the documentation for foreach for examples.
>
> Thanks,
>
> Roger
>
>
>
> ***************************************************************
> This message and any attachments are for the intended recipient's use only.
> This message may contain confidential, proprietary or legally privileged
> information. No right to confidential or privileged treatment
> of this message is waived or lost by an error in transmission.
> If you have received this message in error, please immediately
> notify the sender by e-mail, delete the message, any attachments and all
> copies from your system and destroy any hard copies.  You must
> not, directly or indirectly, use, disclose, distribute,
> print or copy any part of this message or any attachments if you are not
> the intended recipient.
>
>
> -----Original Message-----
> From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On
> Behalf Of Gambulator Gambulator
> Sent: Monday, October 26, 2015 2:21 PM
> To: r-sig-finance at r-project.org
> Subject: [R-SIG-Finance] parallel processing
>
> I did quite a bit of googling. it is not clear to me if it works now on
> Windows or not. it is pretty slow even if I have turned off my
> debug,verbose or print. any idea?
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From gambulator at gmail.com  Tue Oct 27 01:32:57 2015
From: gambulator at gmail.com (Gambulator Gambulator)
Date: Mon, 26 Oct 2015 17:32:57 -0700
Subject: [R-SIG-Finance] parallel processing
In-Reply-To: <CAFSUCtuJTSOoqcUFCEZ0snco-7VsNRDsN90CJ1SXWKA-fA0cpA@mail.gmail.com>
References: <CAFSUCttYLqLncuoupqOMa81_YEAPFLHzzPJnrCnVtPCO48XnLQ@mail.gmail.com>
	<CAFSUCtsWm8DSA=ZXJnH=O8pj7X0gTp9OMGPYTF=_3Xw66WtoBQ@mail.gmail.com>
	<CAFSUCtvZoW-=8cNTadWJshiW=7gPHc=jLHDJ7dPSOQL7ibn9rw@mail.gmail.com>
	<0765308CD028654885F30322557308D81EFBAFE6@NYCSM0208.rth.ad.rothschild.com>
	<CAFSUCtuJTSOoqcUFCEZ0snco-7VsNRDsN90CJ1SXWKA-fA0cpA@mail.gmail.com>
Message-ID: <CAFSUCttTsX9c-VkBaTM4pgPFShwbwBixpR97BNNrZg-+_wHwwA@mail.gmail.com>

I tried to use the parallel core again and I get this error message. Note
that the non-parallel version works fine for me and I am using the
optimization feature.


This is how I call the parallel version:

if( Sys.info()['sysname'] == "Windows" )
{
  library(doParallel)
  cl=makeCluster(detectCores())
  registerDoParallel(cl)
  #registerDoSEQ()
} else {
  library(doMC)

  registerDoMC(cores=detectCores())
}

This is how I call the serial version:

if( Sys.info()['sysname'] == "Windows" )
{
  library(doParallel)

  registerDoSEQ()
} else {
  library(doMC)

  registerDoMC(cores=detectCores())
}

****************************error message for parallel below:

error calling combine function:
<simpleError in fun(result.1, result.2, result.3, result.4, result.5,
result.6,     result.7, result.8, result.9, result.10, result.11,
result.12,     result.13, result.14, result.15, result.16, result.17,
result.18,     result.19, result.20, result.21, result.22, result.23,
result.24,     result.25, result.26, result.27, result.28, result.29,
result.30,     result.31, result.32, result.33, result.34, result.35,
result.36,     result.37, result.38, result.39, result.40, result.41,
result.42,     result.43, result.44, result.45, result.46, result.47,
result.48,     result.49, result.50, result.51, result.52, result.53,
result.54,     result.55, result.56, result.57, result.58, result.59,
result.60,     result.61, result.62, result.63, result.64, result.65,
result.66,     result.67, result.68, result.69, result.70, result.71,
result.72,     result.73, result.74, result.75, result.76, result.77,
result.78,     result.79, result.80, result.81, result.82, result.83,
result.84,     result.85, result.86, result.87, result.88, result.89,
result.90,     result.91, result.92, result.93, result.94, result.95,
result.96,     result.97, result.98, result.99, result.100, result.101,
result.102, result.103, result.104, result.105, result.106,     result.107,
result.108, result.109, result.110, result.111,     result.112, result.113,
result.114, result.115, result.116,     result.117, result.118, result.119,
result.120, result.121,     result.122, result.123, result.124, result.125,
result.126,     result.127, result.128, result.129, result.130, result.131,
    result.132, result.133, result.134, result.135, result.136,
result.137, result.138, result.139, result.140, result.141,     result.142,
result.143, result.144, result.145, result.146,     result.147, result.148,
result.149, result.150, result.151,     result.152, result.153, result.154,
result.155, result.156,     result.157, result.158, result.159, result.160,
result.161,     result.162, result.163, result.164, result.165, result.166,
    result.167, result.168, result.169, result.170, result.171,
result.172, result.173, result.174, result.175, result.176,     result.177,
result.178, result.179, result.180, result.181,     result.182, result.183,
result.184, result.185, result.186,     result.187, result.188, result.189,
result.190, result.191,     result.192, result.193, result.194, result.195,
result.196,     result.197, result.198, result.199, result.200, result.201,
    result.202, result.203, result.204, result.205, result.206,
result.207, result.208, result.209, result.210, result.211,     result.212,
result.213, result.214, result.215, result.216,     result.217, result.218,
result.219, result.220, result.221,     result.222, result.223, result.224,
result.225, result.226,     result.227, result.228, result.229, result.230,
result.231,     result.232, result.233, result.234, result.235, result.236,
    result.237, result.238, result.239, result.240, result.241,
result.242, result.243, result.244, result.245, result.246,     result.247,
result.248, result.249, result.250, result.251,     result.252, result.253,
result.254, result.255, result.256,     result.257, result.258, result.259,
result.260, result.261,     result.262, result.263, result.264, result.265,
result.266,     result.267, result.268, result.269, result.270, result.271,
    result.272, result.273, result.274, result.275, result.276,
result.277, result.278, result.279, result.280, result.281,     result.282,
result.283, result.284, result.285, result.286,     result.287,
result.288): attempt to select less than one element>
>

On Mon, Oct 26, 2015 at 3:31 PM, Gambulator Gambulator <gambulator at gmail.com
> wrote:

> thanks. I am running the optimization and yeah it is pretty slow so I
> figure that I should put it on more cores. It seems/sounds like it 'd work
> fine on Linux but now that you mention Windows, may be I will give it a
> shot before firing up AWS and go through the pain to make an image and all
> that.
>
> thx
>
> On Mon, Oct 26, 2015 at 11:28 AM, Bos, Roger <roger.bos at rothschild.com>
> wrote:
>
>> Not all of the parallel packages with in Windows, but doParallel is one
>> that does.  Here is how to start it with 3 cores:
>>
>> library(doParallel)
>> cl <- makeCluster(3)
>> registerDoParallel(cl)
>>
>> It will automatically load the foreach package provided you have it
>> installed.  Please see the documentation for foreach for examples.
>>
>> Thanks,
>>
>> Roger
>>
>>
>>
>> ***************************************************************
>> This message and any attachments are for the intended recipient's use
>> only.
>> This message may contain confidential, proprietary or legally privileged
>> information. No right to confidential or privileged treatment
>> of this message is waived or lost by an error in transmission.
>> If you have received this message in error, please immediately
>> notify the sender by e-mail, delete the message, any attachments and all
>> copies from your system and destroy any hard copies.  You must
>> not, directly or indirectly, use, disclose, distribute,
>> print or copy any part of this message or any attachments if you are not
>> the intended recipient.
>>
>>
>> -----Original Message-----
>> From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On
>> Behalf Of Gambulator Gambulator
>> Sent: Monday, October 26, 2015 2:21 PM
>> To: r-sig-finance at r-project.org
>> Subject: [R-SIG-Finance] parallel processing
>>
>> I did quite a bit of googling. it is not clear to me if it works now on
>> Windows or not. it is pretty slow even if I have turned off my
>> debug,verbose or print. any idea?
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>

	[[alternative HTML version deleted]]


From roger.bos at rothschild.com  Mon Oct 26 19:28:05 2015
From: roger.bos at rothschild.com (Bos, Roger)
Date: Mon, 26 Oct 2015 18:28:05 +0000
Subject: [R-SIG-Finance] parallel processing
In-Reply-To: <CAFSUCtvZoW-=8cNTadWJshiW=7gPHc=jLHDJ7dPSOQL7ibn9rw@mail.gmail.com>
References: <CAFSUCttYLqLncuoupqOMa81_YEAPFLHzzPJnrCnVtPCO48XnLQ@mail.gmail.com>
	<CAFSUCtsWm8DSA=ZXJnH=O8pj7X0gTp9OMGPYTF=_3Xw66WtoBQ@mail.gmail.com>
	<CAFSUCtvZoW-=8cNTadWJshiW=7gPHc=jLHDJ7dPSOQL7ibn9rw@mail.gmail.com>
Message-ID: <0765308CD028654885F30322557308D81EFBAFE6@NYCSM0208.rth.ad.rothschild.com>

Not all of the parallel packages with in Windows, but doParallel is one that does.  Here is how to start it with 3 cores:

library(doParallel)
cl <- makeCluster(3)
registerDoParallel(cl)

It will automatically load the foreach package provided you have it installed.  Please see the documentation for foreach for examples.

Thanks,

Roger



***************************************************************
This message and any attachments are for the intended recipient's use only.
This message may contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message, any attachments and all
copies from your system and destroy any hard copies.  You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message or any attachments if you are not
the intended recipient.


-----Original Message-----
From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Gambulator Gambulator
Sent: Monday, October 26, 2015 2:21 PM
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] parallel processing

I did quite a bit of googling. it is not clear to me if it works now on Windows or not. it is pretty slow even if I have turned off my debug,verbose or print. any idea?

        [[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.

From johannes.lips at gmail.com  Tue Oct 27 12:46:44 2015
From: johannes.lips at gmail.com (Johannes Lips)
Date: Tue, 27 Oct 2015 12:46:44 +0100
Subject: [R-SIG-Finance] Extension of Johansen Procedure ca.jo
In-Reply-To: <5620ED2B.6090603@gmail.com>
References: <5620ED2B.6090603@gmail.com>
Message-ID: <562F6424.1040909@gmail.com>

Dear all,

I extended the basics of the ca.jo function to incorporate five 
different cases:
nc: no constant
rc: restricted constant, i.e. constant in cointegration vector
uc: unrestricted constant, i.e. constant in the deterministic part of 
the model
crt: restricted constant + trend, i.e. constant and trend in the 
cointegration vector
ct: constant + unrestricted trend, i.e. constant and trend in the 
deterministic part of the model
I checked the results against the results of JMulti with the same data 
set and the same case.
Please mind, that the results can't be used for further analysis in the 
"vars" package yet, since this will need some more work on the 
underlying ca.jo class of results.
Also I didn't pay a lot of attention to the "transitory" specification, 
so if there are any errors, please let me know.

Best,
Johannes




On 16.10.2015 14:27, Johannes Lips wrote:
> Dear list,
>
> I am currently working on an extension of the basic ca.jo() function 
> to also make it possible to incorporate structural breaks, like in 
> Johansen et al. (2000). What I basically do is to add a matrix, which 
> incorporates possible structural breaks in the cointegration vector. 
> Therefore I added the function paramter break.matrix, which so far 
> takes the break matrix according to the H_l(r) case of Johansen et al. 
> (2000).
> I construct the dummy matrix according to Joyeux (2007) and add them 
> to the dumvar and the break.matrix parameter of the ca.jo function.
> So far it "works", but I am unsure if I made all the adjustments of 
> the ca.jo function correctly and I would be really glad if someone 
> could also take a look at the function and see if it does, what it's 
> supposed to do.
> I uploaded the function to my github repo at [1], where I also provide 
> the code to create the dummy matrix incorporating the possible 
> structural breaks. Please note, that the creation of the dummy matrix 
> is also not yet finished and most probably also needs some changes and 
> is only for the purpose of testing the ca.jomoni() function.
>
> Thanks in advance,
> Johannes
>
> [1] https://github.com/hannes101/CointegrationAnalysis
>
>
>
> References:
> Johansen, S?ren, Rocco Mosconi, and Bent Nielsen (2000). 
> ?Cointegration analysis in the presence of structural breaks in the 
> deterministic trend?. en. In: Econometrics Journal 3.2, pp. 216?249. 
> doi: 10.1111/1368- 423X.00047 (cit. on p. 6).
>
> Joyeux, Roselyne (2007). ?How to Deal with Structural Breaks in 
> Practical Cointegration
> Analysis?. English. In: Cointegration for the Applied Economist. Ed. by
> B. Bhaskara Rao. 2nd edition. Palgrave Macmillan, p. 256 (cit. on p. 6).
>
>


From erol.biceroglu at alumni.utoronto.ca  Tue Oct 27 13:26:52 2015
From: erol.biceroglu at alumni.utoronto.ca (Erol Biceroglu)
Date: Tue, 27 Oct 2015 08:26:52 -0400
Subject: [R-SIG-Finance] parallel processing
In-Reply-To: <CAFSUCttTsX9c-VkBaTM4pgPFShwbwBixpR97BNNrZg-+_wHwwA@mail.gmail.com>
References: <CAFSUCttYLqLncuoupqOMa81_YEAPFLHzzPJnrCnVtPCO48XnLQ@mail.gmail.com>
	<CAFSUCtsWm8DSA=ZXJnH=O8pj7X0gTp9OMGPYTF=_3Xw66WtoBQ@mail.gmail.com>
	<CAFSUCtvZoW-=8cNTadWJshiW=7gPHc=jLHDJ7dPSOQL7ibn9rw@mail.gmail.com>
	<0765308CD028654885F30322557308D81EFBAFE6@NYCSM0208.rth.ad.rothschild.com>
	<CAFSUCtuJTSOoqcUFCEZ0snco-7VsNRDsN90CJ1SXWKA-fA0cpA@mail.gmail.com>
	<CAFSUCttTsX9c-VkBaTM4pgPFShwbwBixpR97BNNrZg-+_wHwwA@mail.gmail.com>
Message-ID: <CACjNfmnWBDL+BY=QjjzmvV3Voj6EZou-PPkaerbqx4QVKY+MMQ@mail.gmail.com>

FYI, this gentleman has setup R studio AWS images for everyone to use.  So
there's no "pain" to set it up:

http://www.louisaslett.com/RStudio_AMI/



On Monday, October 26, 2015, Gambulator Gambulator <gambulator at gmail.com>
wrote:

> I tried to use the parallel core again and I get this error message. Note
> that the non-parallel version works fine for me and I am using the
> optimization feature.
>
>
> This is how I call the parallel version:
>
> if( Sys.info()['sysname'] == "Windows" )
> {
>   library(doParallel)
>   cl=makeCluster(detectCores())
>   registerDoParallel(cl)
>   #registerDoSEQ()
> } else {
>   library(doMC)
>
>   registerDoMC(cores=detectCores())
> }
>
> This is how I call the serial version:
>
> if( Sys.info()['sysname'] == "Windows" )
> {
>   library(doParallel)
>
>   registerDoSEQ()
> } else {
>   library(doMC)
>
>   registerDoMC(cores=detectCores())
> }
>
> ****************************error message for parallel below:
>
> error calling combine function:
> <simpleError in fun(result.1, result.2, result.3, result.4, result.5,
> result.6,     result.7, result.8, result.9, result.10, result.11,
> result.12,     result.13, result.14, result.15, result.16, result.17,
> result.18,     result.19, result.20, result.21, result.22, result.23,
> result.24,     result.25, result.26, result.27, result.28, result.29,
> result.30,     result.31, result.32, result.33, result.34, result.35,
> result.36,     result.37, result.38, result.39, result.40, result.41,
> result.42,     result.43, result.44, result.45, result.46, result.47,
> result.48,     result.49, result.50, result.51, result.52, result.53,
> result.54,     result.55, result.56, result.57, result.58, result.59,
> result.60,     result.61, result.62, result.63, result.64, result.65,
> result.66,     result.67, result.68, result.69, result.70, result.71,
> result.72,     result.73, result.74, result.75, result.76, result.77,
> result.78,     result.79, result.80, result.81, result.82, result.83,
> result.84,     result.85, result.86, result.87, result.88, result.89,
> result.90,     result.91, result.92, result.93, result.94, result.95,
> result.96,     result.97, result.98, result.99, result.100, result.101,
> result.102, result.103, result.104, result.105, result.106,     result.107,
> result.108, result.109, result.110, result.111,     result.112, result.113,
> result.114, result.115, result.116,     result.117, result.118, result.119,
> result.120, result.121,     result.122, result.123, result.124, result.125,
> result.126,     result.127, result.128, result.129, result.130, result.131,
>     result.132, result.133, result.134, result.135, result.136,
> result.137, result.138, result.139, result.140, result.141,     result.142,
> result.143, result.144, result.145, result.146,     result.147, result.148,
> result.149, result.150, result.151,     result.152, result.153, result.154,
> result.155, result.156,     result.157, result.158, result.159, result.160,
> result.161,     result.162, result.163, result.164, result.165, result.166,
>     result.167, result.168, result.169, result.170, result.171,
> result.172, result.173, result.174, result.175, result.176,     result.177,
> result.178, result.179, result.180, result.181,     result.182, result.183,
> result.184, result.185, result.186,     result.187, result.188, result.189,
> result.190, result.191,     result.192, result.193, result.194, result.195,
> result.196,     result.197, result.198, result.199, result.200, result.201,
>     result.202, result.203, result.204, result.205, result.206,
> result.207, result.208, result.209, result.210, result.211,     result.212,
> result.213, result.214, result.215, result.216,     result.217, result.218,
> result.219, result.220, result.221,     result.222, result.223, result.224,
> result.225, result.226,     result.227, result.228, result.229, result.230,
> result.231,     result.232, result.233, result.234, result.235, result.236,
>     result.237, result.238, result.239, result.240, result.241,
> result.242, result.243, result.244, result.245, result.246,     result.247,
> result.248, result.249, result.250, result.251,     result.252, result.253,
> result.254, result.255, result.256,     result.257, result.258, result.259,
> result.260, result.261,     result.262, result.263, result.264, result.265,
> result.266,     result.267, result.268, result.269, result.270, result.271,
>     result.272, result.273, result.274, result.275, result.276,
> result.277, result.278, result.279, result.280, result.281,     result.282,
> result.283, result.284, result.285, result.286,     result.287,
> result.288): attempt to select less than one element>
> >
>
> On Mon, Oct 26, 2015 at 3:31 PM, Gambulator Gambulator <
> gambulator at gmail.com <javascript:;>
> > wrote:
>
> > thanks. I am running the optimization and yeah it is pretty slow so I
> > figure that I should put it on more cores. It seems/sounds like it 'd
> work
> > fine on Linux but now that you mention Windows, may be I will give it a
> > shot before firing up AWS and go through the pain to make an image and
> all
> > that.
> >
> > thx
> >
> > On Mon, Oct 26, 2015 at 11:28 AM, Bos, Roger <roger.bos at rothschild.com
> <javascript:;>>
> > wrote:
> >
> >> Not all of the parallel packages with in Windows, but doParallel is one
> >> that does.  Here is how to start it with 3 cores:
> >>
> >> library(doParallel)
> >> cl <- makeCluster(3)
> >> registerDoParallel(cl)
> >>
> >> It will automatically load the foreach package provided you have it
> >> installed.  Please see the documentation for foreach for examples.
> >>
> >> Thanks,
> >>
> >> Roger
> >>
> >>
> >>
> >> ***************************************************************
> >> This message and any attachments are for the intended recipient's use
> >> only.
> >> This message may contain confidential, proprietary or legally privileged
> >> information. No right to confidential or privileged treatment
> >> of this message is waived or lost by an error in transmission.
> >> If you have received this message in error, please immediately
> >> notify the sender by e-mail, delete the message, any attachments and all
> >> copies from your system and destroy any hard copies.  You must
> >> not, directly or indirectly, use, disclose, distribute,
> >> print or copy any part of this message or any attachments if you are not
> >> the intended recipient.
> >>
> >>
> >> -----Original Message-----
> >> From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org
> <javascript:;>] On
> >> Behalf Of Gambulator Gambulator
> >> Sent: Monday, October 26, 2015 2:21 PM
> >> To: r-sig-finance at r-project.org <javascript:;>
> >> Subject: [R-SIG-Finance] parallel processing
> >>
> >> I did quite a bit of googling. it is not clear to me if it works now on
> >> Windows or not. it is pretty slow even if I have turned off my
> >> debug,verbose or print. any idea?
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-SIG-Finance at r-project.org <javascript:;> mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >> -- Subscriber-posting only. If you want to post, subscribe first.
> >> -- Also note that this is not the r-help list where general R questions
> >> should go.
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>


-- 

Erol Biceroglu


*erol.biceroglu at alumni.utoronto.ca
<erol.biceroglu at alumni.utoronto.ca>416-275-7970*

	[[alternative HTML version deleted]]


From gambulator at gmail.com  Tue Oct 27 15:28:57 2015
From: gambulator at gmail.com (Gambulator Gambulator)
Date: Tue, 27 Oct 2015 07:28:57 -0700
Subject: [R-SIG-Finance] parallel processing
In-Reply-To: <CACjNfmnWBDL+BY=QjjzmvV3Voj6EZou-PPkaerbqx4QVKY+MMQ@mail.gmail.com>
References: <CAFSUCttYLqLncuoupqOMa81_YEAPFLHzzPJnrCnVtPCO48XnLQ@mail.gmail.com>
	<CAFSUCtsWm8DSA=ZXJnH=O8pj7X0gTp9OMGPYTF=_3Xw66WtoBQ@mail.gmail.com>
	<CAFSUCtvZoW-=8cNTadWJshiW=7gPHc=jLHDJ7dPSOQL7ibn9rw@mail.gmail.com>
	<0765308CD028654885F30322557308D81EFBAFE6@NYCSM0208.rth.ad.rothschild.com>
	<CAFSUCtuJTSOoqcUFCEZ0snco-7VsNRDsN90CJ1SXWKA-fA0cpA@mail.gmail.com>
	<CAFSUCttTsX9c-VkBaTM4pgPFShwbwBixpR97BNNrZg-+_wHwwA@mail.gmail.com>
	<CACjNfmnWBDL+BY=QjjzmvV3Voj6EZou-PPkaerbqx4QVKY+MMQ@mail.gmail.com>
Message-ID: <CAFSUCtutUO1fUMGE9FDUvLN7Zgh-w=m3oduhU4v6z5ZpcjJD7A@mail.gmail.com>

thanks. I was trying this last night and I think R just released 3.2.2 and
nothing seems to be compatible with it... I gave up last night.... but now
that you showed me this post, I am going to try it again.

thanks

On Tue, Oct 27, 2015 at 5:26 AM, Erol Biceroglu <
erol.biceroglu at alumni.utoronto.ca> wrote:

> FYI, this gentleman has setup R studio AWS images for everyone to use.  So
> there's no "pain" to set it up:
>
> http://www.louisaslett.com/RStudio_AMI/
>
>
>
> On Monday, October 26, 2015, Gambulator Gambulator <gambulator at gmail.com>
> wrote:
>
>> I tried to use the parallel core again and I get this error message. Note
>> that the non-parallel version works fine for me and I am using the
>> optimization feature.
>>
>>
>> This is how I call the parallel version:
>>
>> if( Sys.info()['sysname'] == "Windows" )
>> {
>>   library(doParallel)
>>   cl=makeCluster(detectCores())
>>   registerDoParallel(cl)
>>   #registerDoSEQ()
>> } else {
>>   library(doMC)
>>
>>   registerDoMC(cores=detectCores())
>> }
>>
>> This is how I call the serial version:
>>
>> if( Sys.info()['sysname'] == "Windows" )
>> {
>>   library(doParallel)
>>
>>   registerDoSEQ()
>> } else {
>>   library(doMC)
>>
>>   registerDoMC(cores=detectCores())
>> }
>>
>> ****************************error message for parallel below:
>>
>> error calling combine function:
>> <simpleError in fun(result.1, result.2, result.3, result.4, result.5,
>> result.6,     result.7, result.8, result.9, result.10, result.11,
>> result.12,     result.13, result.14, result.15, result.16, result.17,
>> result.18,     result.19, result.20, result.21, result.22, result.23,
>> result.24,     result.25, result.26, result.27, result.28, result.29,
>> result.30,     result.31, result.32, result.33, result.34, result.35,
>> result.36,     result.37, result.38, result.39, result.40, result.41,
>> result.42,     result.43, result.44, result.45, result.46, result.47,
>> result.48,     result.49, result.50, result.51, result.52, result.53,
>> result.54,     result.55, result.56, result.57, result.58, result.59,
>> result.60,     result.61, result.62, result.63, result.64, result.65,
>> result.66,     result.67, result.68, result.69, result.70, result.71,
>> result.72,     result.73, result.74, result.75, result.76, result.77,
>> result.78,     result.79, result.80, result.81, result.82, result.83,
>> result.84,     result.85, result.86, result.87, result.88, result.89,
>> result.90,     result.91, result.92, result.93, result.94, result.95,
>> result.96,     result.97, result.98, result.99, result.100, result.101,
>> result.102, result.103, result.104, result.105, result.106,
>>  result.107,
>> result.108, result.109, result.110, result.111,     result.112,
>> result.113,
>> result.114, result.115, result.116,     result.117, result.118,
>> result.119,
>> result.120, result.121,     result.122, result.123, result.124,
>> result.125,
>> result.126,     result.127, result.128, result.129, result.130,
>> result.131,
>>     result.132, result.133, result.134, result.135, result.136,
>> result.137, result.138, result.139, result.140, result.141,
>>  result.142,
>> result.143, result.144, result.145, result.146,     result.147,
>> result.148,
>> result.149, result.150, result.151,     result.152, result.153,
>> result.154,
>> result.155, result.156,     result.157, result.158, result.159,
>> result.160,
>> result.161,     result.162, result.163, result.164, result.165,
>> result.166,
>>     result.167, result.168, result.169, result.170, result.171,
>> result.172, result.173, result.174, result.175, result.176,
>>  result.177,
>> result.178, result.179, result.180, result.181,     result.182,
>> result.183,
>> result.184, result.185, result.186,     result.187, result.188,
>> result.189,
>> result.190, result.191,     result.192, result.193, result.194,
>> result.195,
>> result.196,     result.197, result.198, result.199, result.200,
>> result.201,
>>     result.202, result.203, result.204, result.205, result.206,
>> result.207, result.208, result.209, result.210, result.211,
>>  result.212,
>> result.213, result.214, result.215, result.216,     result.217,
>> result.218,
>> result.219, result.220, result.221,     result.222, result.223,
>> result.224,
>> result.225, result.226,     result.227, result.228, result.229,
>> result.230,
>> result.231,     result.232, result.233, result.234, result.235,
>> result.236,
>>     result.237, result.238, result.239, result.240, result.241,
>> result.242, result.243, result.244, result.245, result.246,
>>  result.247,
>> result.248, result.249, result.250, result.251,     result.252,
>> result.253,
>> result.254, result.255, result.256,     result.257, result.258,
>> result.259,
>> result.260, result.261,     result.262, result.263, result.264,
>> result.265,
>> result.266,     result.267, result.268, result.269, result.270,
>> result.271,
>>     result.272, result.273, result.274, result.275, result.276,
>> result.277, result.278, result.279, result.280, result.281,
>>  result.282,
>> result.283, result.284, result.285, result.286,     result.287,
>> result.288): attempt to select less than one element>
>> >
>>
>> On Mon, Oct 26, 2015 at 3:31 PM, Gambulator Gambulator <
>> gambulator at gmail.com
>> > wrote:
>>
>> > thanks. I am running the optimization and yeah it is pretty slow so I
>> > figure that I should put it on more cores. It seems/sounds like it 'd
>> work
>> > fine on Linux but now that you mention Windows, may be I will give it a
>> > shot before firing up AWS and go through the pain to make an image and
>> all
>> > that.
>> >
>> > thx
>> >
>> > On Mon, Oct 26, 2015 at 11:28 AM, Bos, Roger <roger.bos at rothschild.com>
>> > wrote:
>> >
>> >> Not all of the parallel packages with in Windows, but doParallel is one
>> >> that does.  Here is how to start it with 3 cores:
>> >>
>> >> library(doParallel)
>> >> cl <- makeCluster(3)
>> >> registerDoParallel(cl)
>> >>
>> >> It will automatically load the foreach package provided you have it
>> >> installed.  Please see the documentation for foreach for examples.
>> >>
>> >> Thanks,
>> >>
>> >> Roger
>> >>
>> >>
>> >>
>> >> ***************************************************************
>> >> This message and any attachments are for the intended recipient's use
>> >> only.
>> >> This message may contain confidential, proprietary or legally
>> privileged
>> >> information. No right to confidential or privileged treatment
>> >> of this message is waived or lost by an error in transmission.
>> >> If you have received this message in error, please immediately
>> >> notify the sender by e-mail, delete the message, any attachments and
>> all
>> >> copies from your system and destroy any hard copies.  You must
>> >> not, directly or indirectly, use, disclose, distribute,
>> >> print or copy any part of this message or any attachments if you are
>> not
>> >> the intended recipient.
>> >>
>> >>
>> >> -----Original Message-----
>> >> From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On
>> >> Behalf Of Gambulator Gambulator
>> >> Sent: Monday, October 26, 2015 2:21 PM
>> >> To: r-sig-finance at r-project.org
>> >> Subject: [R-SIG-Finance] parallel processing
>> >>
>> >> I did quite a bit of googling. it is not clear to me if it works now on
>> >> Windows or not. it is pretty slow even if I have turned off my
>> >> debug,verbose or print. any idea?
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> _______________________________________________
>> >> R-SIG-Finance at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >> -- Subscriber-posting only. If you want to post, subscribe first.
>> >> -- Also note that this is not the r-help list where general R questions
>> >> should go.
>> >>
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>
> --
>
> Erol Biceroglu
>
>
> *erol.biceroglu at alumni.utoronto.ca
> <erol.biceroglu at alumni.utoronto.ca>416-275-7970 <416-275-7970>*
>

	[[alternative HTML version deleted]]


From agquantr at gmail.com  Tue Oct 27 21:16:12 2015
From: agquantr at gmail.com (Am Gut)
Date: Tue, 27 Oct 2015 16:16:12 -0400
Subject: [R-SIG-Finance] Calculating trailing returns
In-Reply-To: <CAAmySGPi1_qnaMf5-F=dJrtDvfKxWOKZpNGT6XHnF3tYoiHcVQ@mail.gmail.com>
References: <CACpG4GAo-Hdw56Cma+ayO9Uo-BWQn8p5omZNEOJAawmkThPjGw@mail.gmail.com>
	<C498A5CE-C52F-413A-A7BD-218A89EE3156@gmail.com>
	<CACpG4GAyuk4Uqop2RmZKMe7HhzbW5jot-90B_+kjNmyZMKOhPw@mail.gmail.com>
	<CAAmySGPi1_qnaMf5-F=dJrtDvfKxWOKZpNGT6XHnF3tYoiHcVQ@mail.gmail.com>
Message-ID: <CACpG4GDHufm3P3ft6V86SOQY3G9dj3KgCrC+CMriQnE1dqXEEw@mail.gmail.com>

Thanks Michael! This has solved my problem!

On Mon, Oct 26, 2015 at 12:01 PM, Michael Weylandt <
michael.weylandt at gmail.com> wrote:

> On Mon, Oct 26, 2015 at 9:53 AM, Am Gut <agquantr at gmail.com> wrote:
>
>> Good Morning Michael,
>>
>> I have simple return data, in a daily periodicity. I am essentially
>> trying to calculate the trailing returns for say 252 periods, assuming I am
>> trying to look at trailing 12 month returns. So I have been trying to use a
>> product function, but I am having trouble specifying a look back period. I
>> did use the apply.rolling function from the PerformanceAnalytics package,
>> but was unable to us the prod function with it- the function was simply
>> returning an average:
>>
>
> You're not passing the function argument correctly (you're passing
> 'trim=function(x) prod(1+x)-1'). Check the function signature.
>
> library(PerformanceAnalytics)
> data(managers)
> M1 <- managers[, 1, drop=FALSE]
>
> apply.rolling(M1, width=5, FUN=function(x) prod(1+x)-1)[5] ## cumulative
> return of first 5 observations
>
> ## compare to manual calculation
> prod(M1[1:5]+1) - 1
>
>
> Michael
>
>
>> ##compute 12-month (lookback variable) returnm
>> List = list()
>> for (i in 1:ncol(sector_xts))
>> {
>>   List[[i]] = apply.rolling(sector_xts[,i], function(x) prod(1+x)-1,
>> width = 252)
>>
>> }
>> lookback_returns = do.call(cbind,List)
>>
>
>

	[[alternative HTML version deleted]]


From gambulator at gmail.com  Wed Oct 28 18:10:37 2015
From: gambulator at gmail.com (Gambulator Gambulator)
Date: Wed, 28 Oct 2015 10:10:37 -0700
Subject: [R-SIG-Finance] parallel processing
In-Reply-To: <CAFSUCtutUO1fUMGE9FDUvLN7Zgh-w=m3oduhU4v6z5ZpcjJD7A@mail.gmail.com>
References: <CAFSUCttYLqLncuoupqOMa81_YEAPFLHzzPJnrCnVtPCO48XnLQ@mail.gmail.com>
	<CAFSUCtsWm8DSA=ZXJnH=O8pj7X0gTp9OMGPYTF=_3Xw66WtoBQ@mail.gmail.com>
	<CAFSUCtvZoW-=8cNTadWJshiW=7gPHc=jLHDJ7dPSOQL7ibn9rw@mail.gmail.com>
	<0765308CD028654885F30322557308D81EFBAFE6@NYCSM0208.rth.ad.rothschild.com>
	<CAFSUCtuJTSOoqcUFCEZ0snco-7VsNRDsN90CJ1SXWKA-fA0cpA@mail.gmail.com>
	<CAFSUCttTsX9c-VkBaTM4pgPFShwbwBixpR97BNNrZg-+_wHwwA@mail.gmail.com>
	<CACjNfmnWBDL+BY=QjjzmvV3Voj6EZou-PPkaerbqx4QVKY+MMQ@mail.gmail.com>
	<CAFSUCtutUO1fUMGE9FDUvLN7Zgh-w=m3oduhU4v6z5ZpcjJD7A@mail.gmail.com>
Message-ID: <CAFSUCtsoTmypDPmtk9jgah3RoqqTFAECFL-N-PgGcXF=i6ja+Q@mail.gmail.com>

I used the AMI image and kickoff the parallel processing. It works well.
Thanks everyone  for your help

On Tue, Oct 27, 2015 at 7:28 AM, Gambulator Gambulator <gambulator at gmail.com
> wrote:

> thanks. I was trying this last night and I think R just released 3.2.2 and
> nothing seems to be compatible with it... I gave up last night.... but now
> that you showed me this post, I am going to try it again.
>
> thanks
>
> On Tue, Oct 27, 2015 at 5:26 AM, Erol Biceroglu <
> erol.biceroglu at alumni.utoronto.ca> wrote:
>
>> FYI, this gentleman has setup R studio AWS images for everyone to use.
>> So there's no "pain" to set it up:
>>
>> http://www.louisaslett.com/RStudio_AMI/
>>
>>
>>
>> On Monday, October 26, 2015, Gambulator Gambulator <gambulator at gmail.com>
>> wrote:
>>
>>> I tried to use the parallel core again and I get this error message. Note
>>> that the non-parallel version works fine for me and I am using the
>>> optimization feature.
>>>
>>>
>>> This is how I call the parallel version:
>>>
>>> if( Sys.info()['sysname'] == "Windows" )
>>> {
>>>   library(doParallel)
>>>   cl=makeCluster(detectCores())
>>>   registerDoParallel(cl)
>>>   #registerDoSEQ()
>>> } else {
>>>   library(doMC)
>>>
>>>   registerDoMC(cores=detectCores())
>>> }
>>>
>>> This is how I call the serial version:
>>>
>>> if( Sys.info()['sysname'] == "Windows" )
>>> {
>>>   library(doParallel)
>>>
>>>   registerDoSEQ()
>>> } else {
>>>   library(doMC)
>>>
>>>   registerDoMC(cores=detectCores())
>>> }
>>>
>>> ****************************error message for parallel below:
>>>
>>> error calling combine function:
>>> <simpleError in fun(result.1, result.2, result.3, result.4, result.5,
>>> result.6,     result.7, result.8, result.9, result.10, result.11,
>>> result.12,     result.13, result.14, result.15, result.16, result.17,
>>> result.18,     result.19, result.20, result.21, result.22, result.23,
>>> result.24,     result.25, result.26, result.27, result.28, result.29,
>>> result.30,     result.31, result.32, result.33, result.34, result.35,
>>> result.36,     result.37, result.38, result.39, result.40, result.41,
>>> result.42,     result.43, result.44, result.45, result.46, result.47,
>>> result.48,     result.49, result.50, result.51, result.52, result.53,
>>> result.54,     result.55, result.56, result.57, result.58, result.59,
>>> result.60,     result.61, result.62, result.63, result.64, result.65,
>>> result.66,     result.67, result.68, result.69, result.70, result.71,
>>> result.72,     result.73, result.74, result.75, result.76, result.77,
>>> result.78,     result.79, result.80, result.81, result.82, result.83,
>>> result.84,     result.85, result.86, result.87, result.88, result.89,
>>> result.90,     result.91, result.92, result.93, result.94, result.95,
>>> result.96,     result.97, result.98, result.99, result.100, result.101,
>>> result.102, result.103, result.104, result.105, result.106,
>>>  result.107,
>>> result.108, result.109, result.110, result.111,     result.112,
>>> result.113,
>>> result.114, result.115, result.116,     result.117, result.118,
>>> result.119,
>>> result.120, result.121,     result.122, result.123, result.124,
>>> result.125,
>>> result.126,     result.127, result.128, result.129, result.130,
>>> result.131,
>>>     result.132, result.133, result.134, result.135, result.136,
>>> result.137, result.138, result.139, result.140, result.141,
>>>  result.142,
>>> result.143, result.144, result.145, result.146,     result.147,
>>> result.148,
>>> result.149, result.150, result.151,     result.152, result.153,
>>> result.154,
>>> result.155, result.156,     result.157, result.158, result.159,
>>> result.160,
>>> result.161,     result.162, result.163, result.164, result.165,
>>> result.166,
>>>     result.167, result.168, result.169, result.170, result.171,
>>> result.172, result.173, result.174, result.175, result.176,
>>>  result.177,
>>> result.178, result.179, result.180, result.181,     result.182,
>>> result.183,
>>> result.184, result.185, result.186,     result.187, result.188,
>>> result.189,
>>> result.190, result.191,     result.192, result.193, result.194,
>>> result.195,
>>> result.196,     result.197, result.198, result.199, result.200,
>>> result.201,
>>>     result.202, result.203, result.204, result.205, result.206,
>>> result.207, result.208, result.209, result.210, result.211,
>>>  result.212,
>>> result.213, result.214, result.215, result.216,     result.217,
>>> result.218,
>>> result.219, result.220, result.221,     result.222, result.223,
>>> result.224,
>>> result.225, result.226,     result.227, result.228, result.229,
>>> result.230,
>>> result.231,     result.232, result.233, result.234, result.235,
>>> result.236,
>>>     result.237, result.238, result.239, result.240, result.241,
>>> result.242, result.243, result.244, result.245, result.246,
>>>  result.247,
>>> result.248, result.249, result.250, result.251,     result.252,
>>> result.253,
>>> result.254, result.255, result.256,     result.257, result.258,
>>> result.259,
>>> result.260, result.261,     result.262, result.263, result.264,
>>> result.265,
>>> result.266,     result.267, result.268, result.269, result.270,
>>> result.271,
>>>     result.272, result.273, result.274, result.275, result.276,
>>> result.277, result.278, result.279, result.280, result.281,
>>>  result.282,
>>> result.283, result.284, result.285, result.286,     result.287,
>>> result.288): attempt to select less than one element>
>>> >
>>>
>>> On Mon, Oct 26, 2015 at 3:31 PM, Gambulator Gambulator <
>>> gambulator at gmail.com
>>> > wrote:
>>>
>>> > thanks. I am running the optimization and yeah it is pretty slow so I
>>> > figure that I should put it on more cores. It seems/sounds like it 'd
>>> work
>>> > fine on Linux but now that you mention Windows, may be I will give it a
>>> > shot before firing up AWS and go through the pain to make an image and
>>> all
>>> > that.
>>> >
>>> > thx
>>> >
>>> > On Mon, Oct 26, 2015 at 11:28 AM, Bos, Roger <roger.bos at rothschild.com
>>> >
>>> > wrote:
>>> >
>>> >> Not all of the parallel packages with in Windows, but doParallel is
>>> one
>>> >> that does.  Here is how to start it with 3 cores:
>>> >>
>>> >> library(doParallel)
>>> >> cl <- makeCluster(3)
>>> >> registerDoParallel(cl)
>>> >>
>>> >> It will automatically load the foreach package provided you have it
>>> >> installed.  Please see the documentation for foreach for examples.
>>> >>
>>> >> Thanks,
>>> >>
>>> >> Roger
>>> >>
>>> >>
>>> >>
>>> >> ***************************************************************
>>> >> This message and any attachments are for the intended recipient's use
>>> >> only.
>>> >> This message may contain confidential, proprietary or legally
>>> privileged
>>> >> information. No right to confidential or privileged treatment
>>> >> of this message is waived or lost by an error in transmission.
>>> >> If you have received this message in error, please immediately
>>> >> notify the sender by e-mail, delete the message, any attachments and
>>> all
>>> >> copies from your system and destroy any hard copies.  You must
>>> >> not, directly or indirectly, use, disclose, distribute,
>>> >> print or copy any part of this message or any attachments if you are
>>> not
>>> >> the intended recipient.
>>> >>
>>> >>
>>> >> -----Original Message-----
>>> >> From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On
>>> >> Behalf Of Gambulator Gambulator
>>> >> Sent: Monday, October 26, 2015 2:21 PM
>>> >> To: r-sig-finance at r-project.org
>>> >> Subject: [R-SIG-Finance] parallel processing
>>> >>
>>> >> I did quite a bit of googling. it is not clear to me if it works now
>>> on
>>> >> Windows or not. it is pretty slow even if I have turned off my
>>> >> debug,verbose or print. any idea?
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> _______________________________________________
>>> >> R-SIG-Finance at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> >> -- Subscriber-posting only. If you want to post, subscribe first.
>>> >> -- Also note that this is not the r-help list where general R
>>> questions
>>> >> should go.
>>> >>
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>>
>>
>>
>> --
>>
>> Erol Biceroglu
>>
>>
>> *erol.biceroglu at alumni.utoronto.ca
>> <erol.biceroglu at alumni.utoronto.ca>416-275-7970 <416-275-7970>*
>>
>
>

	[[alternative HTML version deleted]]


From agquantr at gmail.com  Wed Oct 28 18:34:50 2015
From: agquantr at gmail.com (Am Gut)
Date: Wed, 28 Oct 2015 13:34:50 -0400
Subject: [R-SIG-Finance] Subsetting Second to Last Day of the Month
Message-ID: <CACpG4GAazi61fvrhJ4c6uzAvA2Ov4M3Ec3P73S5XY5FYYycYEQ@mail.gmail.com>

Good Morning Everyone,

I have essentially two questions. I am trying to subset a an existing
dataset based on the last two business days of each month in the dataset. I
am able to subset based on the last business day of each month (or the last
day as I am only using business days in my dataset) via the following code:

##identify second to last business day of every month
month_end = lookback_returns_nona[endpoints(lookback_returns_nona,
on="months"),]

However, I do not have to make this the second to last day instead. In
addition, can someone help me understand how I could do the last business
day of each month and the second to last business day of each month?

My dataset simply contains a date index, and a few variables with daily
returns:


[image: Inline image 1]

As a side note, I am new to the forum so please feel free to let me know if
I am not observing proper posing rules. Thanks in advance as any help would
be extremely useful.

Kind Regards,

AG
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/59da0575/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 5672 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/59da0575/attachment.png>

From ilya.kipnis at gmail.com  Wed Oct 28 18:36:38 2015
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Wed, 28 Oct 2015 13:36:38 -0400
Subject: [R-SIG-Finance] Subsetting Second to Last Day of the Month
In-Reply-To: <CACpG4GAazi61fvrhJ4c6uzAvA2Ov4M3Ec3P73S5XY5FYYycYEQ@mail.gmail.com>
References: <CACpG4GAazi61fvrhJ4c6uzAvA2Ov4M3Ec3P73S5XY5FYYycYEQ@mail.gmail.com>
Message-ID: <CA+oJuEGAJLxUEVnaEoHPxigw=kKsLSks_DtE4PHfrKZp8YAtPA@mail.gmail.com>

Do you know what the output of the endpoints function is? It's trivial from
there.
On Oct 28, 2015 12:35 PM, "Am Gut" <agquantr at gmail.com> wrote:

> Good Morning Everyone,
>
> I have essentially two questions. I am trying to subset a an existing
> dataset based on the last two business days of each month in the dataset. I
> am able to subset based on the last business day of each month (or the last
> day as I am only using business days in my dataset) via the following code:
>
> ##identify second to last business day of every month
> month_end = lookback_returns_nona[endpoints(lookback_returns_nona,
> on="months"),]
>
> However, I do not have to make this the second to last day instead. In
> addition, can someone help me understand how I could do the last business
> day of each month and the second to last business day of each month?
>
> My dataset simply contains a date index, and a few variables with daily
> returns:
>
>
> [image: Inline image 1]
>
> As a side note, I am new to the forum so please feel free to let me know
> if I am not observing proper posing rules. Thanks in advance as any help
> would be extremely useful.
>
> Kind Regards,
>
> AG
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/6004cbcb/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 5672 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/6004cbcb/attachment.png>

From agquantr at gmail.com  Wed Oct 28 18:40:14 2015
From: agquantr at gmail.com (Am Gut)
Date: Wed, 28 Oct 2015 13:40:14 -0400
Subject: [R-SIG-Finance] Subsetting Second to Last Day of the Month
In-Reply-To: <CA+oJuEGAJLxUEVnaEoHPxigw=kKsLSks_DtE4PHfrKZp8YAtPA@mail.gmail.com>
References: <CACpG4GAazi61fvrhJ4c6uzAvA2Ov4M3Ec3P73S5XY5FYYycYEQ@mail.gmail.com>
	<CA+oJuEGAJLxUEVnaEoHPxigw=kKsLSks_DtE4PHfrKZp8YAtPA@mail.gmail.com>
Message-ID: <CACpG4GBy5gVE7c_i0m+AKKK1PKoRJ=w8ywQ1u_PYtZE=Z1t0Cw@mail.gmail.com>

Ilya,

Thanks for such a fast reply. The output is the last day of each month in
my dataset - so sometimes not necessarily the last day of each month - but
the last day of the month within my dataset (which is just the business
days):

[image: Inline image 1]

Please let me know if you have any suggestions on how I can progress along
with this issue and thanks in advance.

Kind Regards,

AG

On Wed, Oct 28, 2015 at 1:36 PM, Ilya Kipnis <ilya.kipnis at gmail.com> wrote:

> Do you know what the output of the endpoints function is? It's trivial
> from there.
> On Oct 28, 2015 12:35 PM, "Am Gut" <agquantr at gmail.com> wrote:
>
>> Good Morning Everyone,
>>
>> I have essentially two questions. I am trying to subset a an existing
>> dataset based on the last two business days of each month in the dataset. I
>> am able to subset based on the last business day of each month (or the last
>> day as I am only using business days in my dataset) via the following code:
>>
>> ##identify second to last business day of every month
>> month_end = lookback_returns_nona[endpoints(lookback_returns_nona,
>> on="months"),]
>>
>> However, I do not have to make this the second to last day instead. In
>> addition, can someone help me understand how I could do the last business
>> day of each month and the second to last business day of each month?
>>
>> My dataset simply contains a date index, and a few variables with daily
>> returns:
>>
>>
>> [image: Inline image 1]
>>
>> As a side note, I am new to the forum so please feel free to let me know
>> if I am not observing proper posing rules. Thanks in advance as any help
>> would be extremely useful.
>>
>> Kind Regards,
>>
>> AG
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/edad95f1/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 7735 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/edad95f1/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 5672 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/edad95f1/attachment-0001.png>

From ilya.kipnis at gmail.com  Wed Oct 28 18:42:50 2015
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Wed, 28 Oct 2015 13:42:50 -0400
Subject: [R-SIG-Finance] Subsetting Second to Last Day of the Month
In-Reply-To: <CACpG4GBy5gVE7c_i0m+AKKK1PKoRJ=w8ywQ1u_PYtZE=Z1t0Cw@mail.gmail.com>
References: <CACpG4GAazi61fvrhJ4c6uzAvA2Ov4M3Ec3P73S5XY5FYYycYEQ@mail.gmail.com>
	<CA+oJuEGAJLxUEVnaEoHPxigw=kKsLSks_DtE4PHfrKZp8YAtPA@mail.gmail.com>
	<CACpG4GBy5gVE7c_i0m+AKKK1PKoRJ=w8ywQ1u_PYtZE=Z1t0Cw@mail.gmail.com>
Message-ID: <CA+oJuEEZ-+idbPsVYOE8s+V4BqmxeQMp_Zv1P6F+Vp9-n7tOhw@mail.gmail.com>

No. The output of the actual endpoints function is a set of numbered
indices specifying that particular day. E.g. if you look at JUST the output
of endpoints, before plugging it into your dataset, you'd see something
like 0, 10, 31, etc.

To get the second to last day, you just subtract 1 from that output and set
negatives to zero.
On Oct 28, 2015 12:40 PM, "Am Gut" <agquantr at gmail.com> wrote:

> Ilya,
>
> Thanks for such a fast reply. The output is the last day of each month in
> my dataset - so sometimes not necessarily the last day of each month - but
> the last day of the month within my dataset (which is just the business
> days):
>
> [image: Inline image 1]
>
> Please let me know if you have any suggestions on how I can progress along
> with this issue and thanks in advance.
>
> Kind Regards,
>
> AG
>
> On Wed, Oct 28, 2015 at 1:36 PM, Ilya Kipnis <ilya.kipnis at gmail.com>
> wrote:
>
>> Do you know what the output of the endpoints function is? It's trivial
>> from there.
>> On Oct 28, 2015 12:35 PM, "Am Gut" <agquantr at gmail.com> wrote:
>>
>>> Good Morning Everyone,
>>>
>>> I have essentially two questions. I am trying to subset a an existing
>>> dataset based on the last two business days of each month in the dataset. I
>>> am able to subset based on the last business day of each month (or the last
>>> day as I am only using business days in my dataset) via the following code:
>>>
>>> ##identify second to last business day of every month
>>> month_end = lookback_returns_nona[endpoints(lookback_returns_nona,
>>> on="months"),]
>>>
>>> However, I do not have to make this the second to last day instead. In
>>> addition, can someone help me understand how I could do the last business
>>> day of each month and the second to last business day of each month?
>>>
>>> My dataset simply contains a date index, and a few variables with daily
>>> returns:
>>>
>>>
>>> [image: Inline image 1]
>>>
>>> As a side note, I am new to the forum so please feel free to let me know
>>> if I am not observing proper posing rules. Thanks in advance as any help
>>> would be extremely useful.
>>>
>>> Kind Regards,
>>>
>>> AG
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/18305d30/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 7735 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/18305d30/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 5672 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/18305d30/attachment-0001.png>

From ilya.kipnis at gmail.com  Wed Oct 28 18:43:55 2015
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Wed, 28 Oct 2015 13:43:55 -0400
Subject: [R-SIG-Finance] Subsetting Second to Last Day of the Month
In-Reply-To: <CACpG4GBy5gVE7c_i0m+AKKK1PKoRJ=w8ywQ1u_PYtZE=Z1t0Cw@mail.gmail.com>
References: <CACpG4GAazi61fvrhJ4c6uzAvA2Ov4M3Ec3P73S5XY5FYYycYEQ@mail.gmail.com>
	<CA+oJuEGAJLxUEVnaEoHPxigw=kKsLSks_DtE4PHfrKZp8YAtPA@mail.gmail.com>
	<CACpG4GBy5gVE7c_i0m+AKKK1PKoRJ=w8ywQ1u_PYtZE=Z1t0Cw@mail.gmail.com>
Message-ID: <CA+oJuEEH1krcWjK48b3g7GNq8b+mYOGHfu26SQaD_p-SULpxcA@mail.gmail.com>

As for the last day of each month as opposed to business day, then you need
to have those holidays and weekends in your data set.
On Oct 28, 2015 12:40 PM, "Am Gut" <agquantr at gmail.com> wrote:

> Ilya,
>
> Thanks for such a fast reply. The output is the last day of each month in
> my dataset - so sometimes not necessarily the last day of each month - but
> the last day of the month within my dataset (which is just the business
> days):
>
> [image: Inline image 1]
>
> Please let me know if you have any suggestions on how I can progress along
> with this issue and thanks in advance.
>
> Kind Regards,
>
> AG
>
> On Wed, Oct 28, 2015 at 1:36 PM, Ilya Kipnis <ilya.kipnis at gmail.com>
> wrote:
>
>> Do you know what the output of the endpoints function is? It's trivial
>> from there.
>> On Oct 28, 2015 12:35 PM, "Am Gut" <agquantr at gmail.com> wrote:
>>
>>> Good Morning Everyone,
>>>
>>> I have essentially two questions. I am trying to subset a an existing
>>> dataset based on the last two business days of each month in the dataset. I
>>> am able to subset based on the last business day of each month (or the last
>>> day as I am only using business days in my dataset) via the following code:
>>>
>>> ##identify second to last business day of every month
>>> month_end = lookback_returns_nona[endpoints(lookback_returns_nona,
>>> on="months"),]
>>>
>>> However, I do not have to make this the second to last day instead. In
>>> addition, can someone help me understand how I could do the last business
>>> day of each month and the second to last business day of each month?
>>>
>>> My dataset simply contains a date index, and a few variables with daily
>>> returns:
>>>
>>>
>>> [image: Inline image 1]
>>>
>>> As a side note, I am new to the forum so please feel free to let me know
>>> if I am not observing proper posing rules. Thanks in advance as any help
>>> would be extremely useful.
>>>
>>> Kind Regards,
>>>
>>> AG
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/7018c3a5/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 5672 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/7018c3a5/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 7735 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/7018c3a5/attachment-0001.png>

From agquantr at gmail.com  Wed Oct 28 20:35:50 2015
From: agquantr at gmail.com (Am Gut)
Date: Wed, 28 Oct 2015 15:35:50 -0400
Subject: [R-SIG-Finance] Subsetting Second to Last Day of the Month
In-Reply-To: <CA+oJuEEH1krcWjK48b3g7GNq8b+mYOGHfu26SQaD_p-SULpxcA@mail.gmail.com>
References: <CACpG4GAazi61fvrhJ4c6uzAvA2Ov4M3Ec3P73S5XY5FYYycYEQ@mail.gmail.com>
	<CA+oJuEGAJLxUEVnaEoHPxigw=kKsLSks_DtE4PHfrKZp8YAtPA@mail.gmail.com>
	<CACpG4GBy5gVE7c_i0m+AKKK1PKoRJ=w8ywQ1u_PYtZE=Z1t0Cw@mail.gmail.com>
	<CA+oJuEEH1krcWjK48b3g7GNq8b+mYOGHfu26SQaD_p-SULpxcA@mail.gmail.com>
Message-ID: <CACpG4GBZ+Ts61tTz-J=_Z_MKW2Gkm7Wkbq=_9VAiPJ7Hx_1JZg@mail.gmail.com>

Illya,

Thanks for the help as I was able to get the intended result with the
following code (still one question remains):

##identify second to last business day of every month
month_end_rank = endpoints(matrix_rank, on ="months")
month_end_rank_minus = month_end_rank - 1
month_end_rank_minus = rbind(month_end_rank_minus)
for (i in 1:nrow(month_end_rank_minus))
{
    if (month_end_rank_minus[i]< 0)
    {
        month_end_rank_minus = month_end_rank_minus[-i]
    }
}
matrix_rank_minus = matrix_rank[month_end_rank_minus,]


However, if I wanted the second to last business day of each month and all
days of the year were loaded in the dataset, how would I communicate with R
that I want the second to last *business* day now that business days and
non-business days are loaded in the dataset. I would be going back a
different number of days different times. I have been looking through the
packages and still was unable to find an application. If you know of how, I
would also appreciate that insight.

Thanks for all of your help today. I am up and running for now.

AG

On Wed, Oct 28, 2015 at 1:43 PM, Ilya Kipnis <ilya.kipnis at gmail.com> wrote:

> As for the last day of each month as opposed to business day, then you
> need to have those holidays and weekends in your data set.
> On Oct 28, 2015 12:40 PM, "Am Gut" <agquantr at gmail.com> wrote:
>
>> Ilya,
>>
>> Thanks for such a fast reply. The output is the last day of each month in
>> my dataset - so sometimes not necessarily the last day of each month - but
>> the last day of the month within my dataset (which is just the business
>> days):
>>
>> [image: Inline image 1]
>>
>> Please let me know if you have any suggestions on how I can progress
>> along with this issue and thanks in advance.
>>
>> Kind Regards,
>>
>> AG
>>
>> On Wed, Oct 28, 2015 at 1:36 PM, Ilya Kipnis <ilya.kipnis at gmail.com>
>> wrote:
>>
>>> Do you know what the output of the endpoints function is? It's trivial
>>> from there.
>>> On Oct 28, 2015 12:35 PM, "Am Gut" <agquantr at gmail.com> wrote:
>>>
>>>> Good Morning Everyone,
>>>>
>>>> I have essentially two questions. I am trying to subset a an existing
>>>> dataset based on the last two business days of each month in the dataset. I
>>>> am able to subset based on the last business day of each month (or the last
>>>> day as I am only using business days in my dataset) via the following code:
>>>>
>>>> ##identify second to last business day of every month
>>>> month_end = lookback_returns_nona[endpoints(lookback_returns_nona,
>>>> on="months"),]
>>>>
>>>> However, I do not have to make this the second to last day instead. In
>>>> addition, can someone help me understand how I could do the last business
>>>> day of each month and the second to last business day of each month?
>>>>
>>>> My dataset simply contains a date index, and a few variables with daily
>>>> returns:
>>>>
>>>>
>>>> [image: Inline image 1]
>>>>
>>>> As a side note, I am new to the forum so please feel free to let me
>>>> know if I am not observing proper posing rules. Thanks in advance as any
>>>> help would be extremely useful.
>>>>
>>>> Kind Regards,
>>>>
>>>> AG
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions
>>>> should go.
>>>>
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/4947770d/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 5672 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/4947770d/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 7735 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/4947770d/attachment-0001.png>

From ilya.kipnis at gmail.com  Wed Oct 28 20:38:08 2015
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Wed, 28 Oct 2015 15:38:08 -0400
Subject: [R-SIG-Finance] Subsetting Second to Last Day of the Month
In-Reply-To: <CACpG4GBZ+Ts61tTz-J=_Z_MKW2Gkm7Wkbq=_9VAiPJ7Hx_1JZg@mail.gmail.com>
References: <CACpG4GAazi61fvrhJ4c6uzAvA2Ov4M3Ec3P73S5XY5FYYycYEQ@mail.gmail.com>
	<CA+oJuEGAJLxUEVnaEoHPxigw=kKsLSks_DtE4PHfrKZp8YAtPA@mail.gmail.com>
	<CACpG4GBy5gVE7c_i0m+AKKK1PKoRJ=w8ywQ1u_PYtZE=Z1t0Cw@mail.gmail.com>
	<CA+oJuEEH1krcWjK48b3g7GNq8b+mYOGHfu26SQaD_p-SULpxcA@mail.gmail.com>
	<CACpG4GBZ+Ts61tTz-J=_Z_MKW2Gkm7Wkbq=_9VAiPJ7Hx_1JZg@mail.gmail.com>
Message-ID: <CA+oJuEE6yJN-QaxhZEPAs6xwC9merKF4o0Zzzq6H2e2fAxx=fA@mail.gmail.com>

Use two different data sets and then cabins them. Its will figure it out,
if you need to combine them.
On Oct 28, 2015 2:35 PM, "Am Gut" <agquantr at gmail.com> wrote:

> Illya,
>
> Thanks for the help as I was able to get the intended result with the
> following code (still one question remains):
>
> ##identify second to last business day of every month
> month_end_rank = endpoints(matrix_rank, on ="months")
> month_end_rank_minus = month_end_rank - 1
> month_end_rank_minus = rbind(month_end_rank_minus)
> for (i in 1:nrow(month_end_rank_minus))
> {
>     if (month_end_rank_minus[i]< 0)
>     {
>         month_end_rank_minus = month_end_rank_minus[-i]
>     }
> }
> matrix_rank_minus = matrix_rank[month_end_rank_minus,]
>
>
> However, if I wanted the second to last business day of each month and all
> days of the year were loaded in the dataset, how would I communicate with R
> that I want the second to last *business* day now that business days and
> non-business days are loaded in the dataset. I would be going back a
> different number of days different times. I have been looking through the
> packages and still was unable to find an application. If you know of how, I
> would also appreciate that insight.
>
> Thanks for all of your help today. I am up and running for now.
>
> AG
>
> On Wed, Oct 28, 2015 at 1:43 PM, Ilya Kipnis <ilya.kipnis at gmail.com>
> wrote:
>
>> As for the last day of each month as opposed to business day, then you
>> need to have those holidays and weekends in your data set.
>> On Oct 28, 2015 12:40 PM, "Am Gut" <agquantr at gmail.com> wrote:
>>
>>> Ilya,
>>>
>>> Thanks for such a fast reply. The output is the last day of each month
>>> in my dataset - so sometimes not necessarily the last day of each month -
>>> but the last day of the month within my dataset (which is just the business
>>> days):
>>>
>>> [image: Inline image 1]
>>>
>>> Please let me know if you have any suggestions on how I can progress
>>> along with this issue and thanks in advance.
>>>
>>> Kind Regards,
>>>
>>> AG
>>>
>>> On Wed, Oct 28, 2015 at 1:36 PM, Ilya Kipnis <ilya.kipnis at gmail.com>
>>> wrote:
>>>
>>>> Do you know what the output of the endpoints function is? It's trivial
>>>> from there.
>>>> On Oct 28, 2015 12:35 PM, "Am Gut" <agquantr at gmail.com> wrote:
>>>>
>>>>> Good Morning Everyone,
>>>>>
>>>>> I have essentially two questions. I am trying to subset a an existing
>>>>> dataset based on the last two business days of each month in the dataset. I
>>>>> am able to subset based on the last business day of each month (or the last
>>>>> day as I am only using business days in my dataset) via the following code:
>>>>>
>>>>> ##identify second to last business day of every month
>>>>> month_end = lookback_returns_nona[endpoints(lookback_returns_nona,
>>>>> on="months"),]
>>>>>
>>>>> However, I do not have to make this the second to last day instead. In
>>>>> addition, can someone help me understand how I could do the last business
>>>>> day of each month and the second to last business day of each month?
>>>>>
>>>>> My dataset simply contains a date index, and a few variables with
>>>>> daily returns:
>>>>>
>>>>>
>>>>> [image: Inline image 1]
>>>>>
>>>>> As a side note, I am new to the forum so please feel free to let me
>>>>> know if I am not observing proper posing rules. Thanks in advance as any
>>>>> help would be extremely useful.
>>>>>
>>>>> Kind Regards,
>>>>>
>>>>> AG
>>>>>
>>>>> _______________________________________________
>>>>> R-SIG-Finance at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>> -- Also note that this is not the r-help list where general R
>>>>> questions should go.
>>>>>
>>>>
>>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/27b1961e/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 5672 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/27b1961e/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 7735 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151028/27b1961e/attachment-0001.png>

From josh.m.ulrich at gmail.com  Mon Nov  2 18:50:15 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 2 Nov 2015 11:50:15 -0600
Subject: [R-SIG-Finance] Bug in ruleOrderProc (as.Date(tif.xts)
In-Reply-To: <CAPPM_gT+nk8F089eGN3aUb4BBPxuhP8PFsK81X1D-wy5ii10=Q@mail.gmail.com>
References: <CAFauerN+6xZNARiryuopphvYM7t39ix5mHxdoK4ZtSf2F1UUJA@mail.gmail.com>
	<CAPPM_gT+nk8F089eGN3aUb4BBPxuhP8PFsK81X1D-wy5ii10=Q@mail.gmail.com>
Message-ID: <CAPPM_gTVLL5UKThcR1wFe1JVFkH8+ngu7US7WRMiDktJ8iVpVQ@mail.gmail.com>

On Wed, Sep 2, 2015 at 5:23 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> Hi Amod,
>
> On Tue, Sep 1, 2015 at 9:36 PM, Amod Karve (????) <karve.amod at gmail.com> wrote:
>> I ran into a bug when trying to use time.in.force in ruleOrderProc. When
>> specifying a numeric value for time.in.force, I was getting an error in
>> ruleOrderProc when calling:
>>
>>  tif <- as.Date(tif.xts)
>>
>> I think the problem is that the underlying tif.xts is a zoo object and
>> as.Date() fails on it. When I removed the as.Date(), the backtest ran fine.
>>
>> What's the process for patching in bug fixes?
>>
> Thanks for the feedback.  The best way to contribute a patch is to
> create a minimal strategy that allows us to reproduce the issue you
> see, along with your patch.  That will allow us to verify the issue,
> and evaluate your patch.
>
> Once you have that, please open an issue on the TradeAnalytics tracker
> on R-Forge:
> https://r-forge.r-project.org/tracker/?group_id=316
>
I've tracked this down and it should be fixed in r1712.

>> Thanks
>> amod
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From josh.m.ulrich at gmail.com  Wed Nov  4 16:13:09 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 4 Nov 2015 09:13:09 -0600
Subject: [R-SIG-Finance] Help activating stop loss order.
In-Reply-To: <CAFauerOCNZPgK6PzFySWmwDUEjPr01DO-faGg8dPb0szGWw3NQ@mail.gmail.com>
References: <CAFauerNdNhXc+uN2_OxSk+AgmSECo7iwnxiQGEA43L0U+9yj=Q@mail.gmail.com>
	<CAFauerOCNZPgK6PzFySWmwDUEjPr01DO-faGg8dPb0szGWw3NQ@mail.gmail.com>
Message-ID: <CAPPM_gRtaF5BVm5gNKVj7Pn-TBE0vJo9wDTHZNNAarqSK9ifuQ@mail.gmail.com>

Thanks for the reproducible example.  Your chain rule isn't executing
because of timezone issues.  Your script works if you call
Sys.setenv(TZ="UTC") before calling applyStrategy.

On Thu, Aug 27, 2015 at 12:00 AM, Amod Karve (????)
<karve.amod at gmail.com> wrote:
> forgot to add the contents of position_sizing.r. Here it is:
>
> osFixedDollar <- function(data, timestamp, orderqty, portfolio, symbol,
> ruletype, ...) {
>   ClosePrice <- as.numeric(Cl(mktdata[timestamp,]))
>   orderqty <- round(tradeSize / ClosePrice, -2)
>   return(orderqty)
> }
>
>
> On Thu, Aug 27, 2015 at 12:51 AM, Amod Karve (????) <karve.amod at gmail.com>
> wrote:
>
>> Hey All,
>>
>>  For the life of me I can't figure out why my stop loss order is not
>> getting triggered. I am trying to play around with a simple Trend vigor
>> strategy as illustrated in Ilya kipnis's blog. Everything else works except
>> for the stop loss order which doesn't seem to take effect. I can't even see
>> the stop loss in my order book (I see it only if I set type='risk' instead
>> of chain).
>>
>> Could someone help me figure out where the problem might be?
>>
>> Attached please find the code.
>>
>> Thanks
>> amod
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From pastirs at gmail.com  Mon Nov  9 22:37:02 2015
From: pastirs at gmail.com (Milos Cipovic)
Date: Mon, 9 Nov 2015 22:37:02 +0100
Subject: [R-SIG-Finance] Estimating credit rating transition matrices
Message-ID: <CAKoFBbe6DeGbOkMweVc4J29RUALTWdSwJyNJe6nRQ30D0cCpig@mail.gmail.com>

Hello guys,

Has anybody done this with one of the markov chain packages? I've been
trying to find a function for hazard rate (or duration, or homogeneous
time) approach but I kinda get confused with every vignete i find. I've
tried markovchain, semimarkovchain, msm, hmm packages, and I think that
hazard rate is nested in one of models from these packages, but I'm not
shore.

I noticed that some of them use two columns for states (start state and end
state), although this is not a big deal, it would be great if I could fit
data with one column of states.

Also, in discrete case, how did you solve non rating state?

Thank you.

	[[alternative HTML version deleted]]


From KOU001 at e.ntu.edu.sg  Sun Nov 15 14:46:12 2015
From: KOU001 at e.ntu.edu.sg (#OU KUN#)
Date: Sun, 15 Nov 2015 13:46:12 +0000
Subject: [R-SIG-Finance] Pckg mftsr and Book Modeling Financial Time Series
 with R by Prof. Eric Zivot
Message-ID: <KL1PR01MB0839FF287C6D529DFAD3F6D3FE1F0@KL1PR01MB0839.apcprd01.prod.exchangelabs.com>

Dear all,

I am not sure whether this is the right place to raise this question. Do you notice a book called Modeling Financial Time Series with R by Prof. Eric Zivot should have been published according to his website http://faculty.washington.edu/ezivot/ezresearch.htm It looks like a great book judging from its content as well as predecessor, Modeling Financial Time Series with S-PLUS.

However, I just cannot find it on amazon or from the publisher website. Any one has any idea?

Thank you.

Regards,
Kun OU

	[[alternative HTML version deleted]]


From adamno227 at gmail.com  Sun Nov 15 16:09:57 2015
From: adamno227 at gmail.com (Adam Ginensky)
Date: Sun, 15 Nov 2015 07:09:57 -0800
Subject: [R-SIG-Finance] Pckg mftsr and Book Modeling Financial Time
 Series with R by Prof. Eric Zivot
In-Reply-To: <KL1PR01MB0839FF287C6D529DFAD3F6D3FE1F0@KL1PR01MB0839.apcprd01.prod.exchangelabs.com>
References: <KL1PR01MB0839FF287C6D529DFAD3F6D3FE1F0@KL1PR01MB0839.apcprd01.prod.exchangelabs.com>
Message-ID: <CAEEj48mrL0H8h8NqxYiAro4KzxOGrewLmEBjCV0h=7tMe8QJWA@mail.gmail.com>

I went to the website.  There is only a link to the S book.  The R book
says coming Oct. 2015, but there is no link.

On Sun, Nov 15, 2015 at 5:46 AM, #OU KUN# <KOU001 at e.ntu.edu.sg> wrote:

> Dear all,
>
> I am not sure whether this is the right place to raise this question. Do
> you notice a book called Modeling Financial Time Series with R by Prof.
> Eric Zivot should have been published according to his website
> http://faculty.washington.edu/ezivot/ezresearch.htm It looks like a great
> book judging from its content as well as predecessor, Modeling Financial
> Time Series with S-PLUS.
>
> However, I just cannot find it on amazon or from the publisher website.
> Any one has any idea?
>
> Thank you.
>
> Regards,
> Kun OU
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From dmack10 at verizon.net  Wed Nov 18 02:11:57 2015
From: dmack10 at verizon.net (Dan Mack)
Date: Tue, 17 Nov 2015 20:11:57 -0500
Subject: [R-SIG-Finance] Advice on Forecasting
Message-ID: <2DF8F7C0-E7CE-4558-8698-736FE083628E@verizon.net>

Hello,  I could use some advice on a problem I have trying to solve for projecting forward some predict functions.  I have a backtest that is working very well but would like a more sound projection because I am feel I not doing this as well as I could.   I feel I am at the limit of the predict() function and need a bridge to a forecast() like function.

I am interested in making a next prediction on a stock going up or down and use the following equation.  This is one of many algorithms I use but they are all set up the same way.

I run the follow example code to fit and predict the model:

 strat.fit <- glm(DirNDay ~l_UUP.Close + l_FXE.Close + MA50 + +MA10 + RSI06 + BIAS10 + BBands05, data=STCK.df,family="binomial")


strat.probs <- predict(strat.fit, STCK.test.df,type="response")

I am also trying to predict the direction DirNDay (Direction Next Day).  I have moved the next day up t+1 against day t EOD Data.  This collectively works well with many algorithms in a stacking scheme.   

What I would really like to do is to be able use my algorithms (a combination of regression classifiers, decision trees and meta learners) and get them to do a forecast like function like used with a time series.   An example would be to use something like an ADABoost to fit and then merge it with an ARIMA like function.   Any suggested methods or functions (packages) would be helpful.

Thanks,  Dan
	[[alternative HTML version deleted]]


From ilya.kipnis at gmail.com  Wed Nov 18 02:14:45 2015
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Tue, 17 Nov 2015 20:14:45 -0500
Subject: [R-SIG-Finance] Advice on Forecasting
In-Reply-To: <2DF8F7C0-E7CE-4558-8698-736FE083628E@verizon.net>
References: <2DF8F7C0-E7CE-4558-8698-736FE083628E@verizon.net>
Message-ID: <CA+oJuEEBMrTEFbjgtpBnS1O2D9jzS1uUrksekkpmSsumMJo3YA@mail.gmail.com>

Please provide a minimum reproducible example to the mailing list, not just
one line.

Thank you.

On Tue, Nov 17, 2015 at 8:11 PM, Dan Mack <dmack10 at verizon.net> wrote:

> Hello,  I could use some advice on a problem I have trying to solve for
> projecting forward some predict functions.  I have a backtest that is
> working very well but would like a more sound projection because I am feel
> I not doing this as well as I could.   I feel I am at the limit of the
> predict() function and need a bridge to a forecast() like function.
>
> I am interested in making a next prediction on a stock going up or down
> and use the following equation.  This is one of many algorithms I use but
> they are all set up the same way.
>
> I run the follow example code to fit and predict the model:
>
>  strat.fit <- glm(DirNDay ~l_UUP.Close + l_FXE.Close + MA50 + +MA10 +
> RSI06 + BIAS10 + BBands05, data=STCK.df,family="binomial")
>
>
> strat.probs <- predict(strat.fit, STCK.test.df,type="response")
>
> I am also trying to predict the direction DirNDay (Direction Next Day).  I
> have moved the next day up t+1 against day t EOD Data.  This collectively
> works well with many algorithms in a stacking scheme.
>
> What I would really like to do is to be able use my algorithms (a
> combination of regression classifiers, decision trees and meta learners)
> and get them to do a forecast like function like used with a time series.
>  An example would be to use something like an ADABoost to fit and then
> merge it with an ARIMA like function.   Any suggested methods or functions
> (packages) would be helpful.
>
> Thanks,  Dan
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From n-e-w at qtradr.net  Thu Nov 19 05:02:59 2015
From: n-e-w at qtradr.net (Nick White)
Date: Thu, 19 Nov 2015 15:02:59 +1100
Subject: [R-SIG-Finance] Advice on Forecasting
In-Reply-To: <2DF8F7C0-E7CE-4558-8698-736FE083628E@verizon.net>
References: <2DF8F7C0-E7CE-4558-8698-736FE083628E@verizon.net>
Message-ID: <CAH+4RFt+Vti9h=ARPS+Lnsw-VAy_sV24Cg4VFQL81SEp962WTw@mail.gmail.com>

Dan,

this sounds like an interesting problem and one that several members of the
list could help you with. As Ilya said, please give us a reproducible
example so we can help you out.

On Wed, Nov 18, 2015 at 12:11 PM, Dan Mack <dmack10 at verizon.net> wrote:

> Hello,  I could use some advice on a problem I have trying to solve for
> projecting forward some predict functions.  I have a backtest that is
> working very well but would like a more sound projection because I am feel
> I not doing this as well as I could.   I feel I am at the limit of the
> predict() function and need a bridge to a forecast() like function.
>
> I am interested in making a next prediction on a stock going up or down
> and use the following equation.  This is one of many algorithms I use but
> they are all set up the same way.
>
> I run the follow example code to fit and predict the model:
>
>  strat.fit <- glm(DirNDay ~l_UUP.Close + l_FXE.Close + MA50 + +MA10 +
> RSI06 + BIAS10 + BBands05, data=STCK.df,family="binomial")
>
>
> strat.probs <- predict(strat.fit, STCK.test.df,type="response")
>
> I am also trying to predict the direction DirNDay (Direction Next Day).  I
> have moved the next day up t+1 against day t EOD Data.  This collectively
> works well with many algorithms in a stacking scheme.
>
> What I would really like to do is to be able use my algorithms (a
> combination of regression classifiers, decision trees and meta learners)
> and get them to do a forecast like function like used with a time series.
>  An example would be to use something like an ADABoost to fit and then
> merge it with an ARIMA like function.   Any suggested methods or functions
> (packages) would be helpful.
>
> Thanks,  Dan
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From dmack10 at verizon.net  Thu Nov 19 10:44:54 2015
From: dmack10 at verizon.net (Dan Mack)
Date: Thu, 19 Nov 2015 04:44:54 -0500
Subject: [R-SIG-Finance] Advice on Forecasting
In-Reply-To: <CAH+4RFt+Vti9h=ARPS+Lnsw-VAy_sV24Cg4VFQL81SEp962WTw@mail.gmail.com>
References: <2DF8F7C0-E7CE-4558-8698-736FE083628E@verizon.net>
	<CAH+4RFt+Vti9h=ARPS+Lnsw-VAy_sV24Cg4VFQL81SEp962WTw@mail.gmail.com>
Message-ID: <5EFD4D58-1D0A-44A9-88CD-BEF7A22FA57C@verizon.net>

Nick, IIyla,   Thanks,  I will post some this weekend.  I am finishing my grad school semester this week so my time is limited until the week end.  My code to get to this point is about 800 lines of code and this is a very reduced snippet of it.  Let me get it in a form where I can share and show where I had questions.

Thanks,  Dan 


On Nov 18, 2015, at 11:02 PM, Nick White <n-e-w at qtradr.net> wrote:

> Dan,
> 
> this sounds like an interesting problem and one that several members of the list could help you with. As Ilya said, please give us a reproducible example so we can help you out.
> 
> On Wed, Nov 18, 2015 at 12:11 PM, Dan Mack <dmack10 at verizon.net> wrote:
> Hello,  I could use some advice on a problem I have trying to solve for projecting forward some predict functions.  I have a backtest that is working very well but would like a more sound projection because I am feel I not doing this as well as I could.   I feel I am at the limit of the predict() function and need a bridge to a forecast() like function.
> 
> I am interested in making a next prediction on a stock going up or down and use the following equation.  This is one of many algorithms I use but they are all set up the same way.
> 
> I run the follow example code to fit and predict the model:
> 
>  strat.fit <- glm(DirNDay ~l_UUP.Close + l_FXE.Close + MA50 + +MA10 + RSI06 + BIAS10 + BBands05, data=STCK.df,family="binomial")
> 
> 
> strat.probs <- predict(strat.fit, STCK.test.df,type="response")
> 
> I am also trying to predict the direction DirNDay (Direction Next Day).  I have moved the next day up t+1 against day t EOD Data.  This collectively works well with many algorithms in a stacking scheme.
> 
> What I would really like to do is to be able use my algorithms (a combination of regression classifiers, decision trees and meta learners) and get them to do a forecast like function like used with a time series.   An example would be to use something like an ADABoost to fit and then merge it with an ARIMA like function.   Any suggested methods or functions (packages) would be helpful.
> 
> Thanks,  Dan
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 


	[[alternative HTML version deleted]]


From markknecht at gmail.com  Mon Nov 23 20:33:18 2015
From: markknecht at gmail.com (Mark Knecht)
Date: Mon, 23 Nov 2015 11:33:18 -0800
Subject: [R-SIG-Finance] Older financials?
Message-ID: <CAK2H+ecuFK2-8g-EEiCfcf-1wRbWSTLvHXF9vgNWSJqT7QC+dQ@mail.gmail.com>

I'm reading a book on quant value investing that wants to look at more
financial data than I'm getting with the small program below. Looking at
the getFinancials help page I'm not seeing anything that tells it to go
back more than 4 years. Is there a way to do that with free data or is this
a limitation WRT what Google provides and you have to go somewhere else/pay
money to get it?

Thanks,
Mark

library(quantmod);

SymList=c("MCD","GD","AAPL");
Quotes = getQuote(SymList, src="yahoo");

for (Sym in SymList){
  getFinancials(Sym, src="google");
  getDividends(Sym, src="google");
}

print(Quotes)

print(viewFinancials(MCD.f, period="Q", type="IS"))
print(viewFinancials(MCD.f, period="A", type="CF"))
print(viewFinancials(MCD.f, period="Q", type="BS"))

	[[alternative HTML version deleted]]


From erol.biceroglu at alumni.utoronto.ca  Mon Nov 23 22:35:53 2015
From: erol.biceroglu at alumni.utoronto.ca (Erol Biceroglu)
Date: Mon, 23 Nov 2015 16:35:53 -0500
Subject: [R-SIG-Finance] Older financials?
In-Reply-To: <CAK2H+ecuFK2-8g-EEiCfcf-1wRbWSTLvHXF9vgNWSJqT7QC+dQ@mail.gmail.com>
References: <CAK2H+ecuFK2-8g-EEiCfcf-1wRbWSTLvHXF9vgNWSJqT7QC+dQ@mail.gmail.com>
Message-ID: <CACjNfm=nBFviQC_TqCCT7rDhKWquv80TGBNOJFSk7-L=4889Xg@mail.gmail.com>

Hi Mark,

The only data source I've been able to find that's affordable is Sharadar's
fundamental data, which can be downloaded with the "quandl" R Package.
Note, it's a premium database (not free), details are on quandl's website.
Lastly, they are adding de-listed companies, but my understanding is that
it's not completely free from survivorship bias.  Note, I personally have
not used it yet.

I'd be interested to hear if anyone has any other thoughts as well.  My
apologies if my the comments above are not completely on topic.




Erol Biceroglu


*erol.biceroglu at alumni.utoronto.ca
<erol.biceroglu at alumni.utoronto.ca>416-275-7970*

On Mon, Nov 23, 2015 at 2:33 PM, Mark Knecht <markknecht at gmail.com> wrote:

> I'm reading a book on quant value investing that wants to look at more
> financial data than I'm getting with the small program below. Looking at
> the getFinancials help page I'm not seeing anything that tells it to go
> back more than 4 years. Is there a way to do that with free data or is this
> a limitation WRT what Google provides and you have to go somewhere else/pay
> money to get it?
>
> Thanks,
> Mark
>
> library(quantmod);
>
> SymList=c("MCD","GD","AAPL");
> Quotes = getQuote(SymList, src="yahoo");
>
> for (Sym in SymList){
>   getFinancials(Sym, src="google");
>   getDividends(Sym, src="google");
> }
>
> print(Quotes)
>
> print(viewFinancials(MCD.f, period="Q", type="IS"))
> print(viewFinancials(MCD.f, period="A", type="CF"))
> print(viewFinancials(MCD.f, period="Q", type="BS"))
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From wizardchef at gmail.com  Wed Nov 25 01:27:19 2015
From: wizardchef at gmail.com (Ernest Stokely)
Date: Tue, 24 Nov 2015 18:27:19 -0600
Subject: [R-SIG-Finance] Computing stop probability
Message-ID: <CA1CB4F2-72E7-45B6-A124-A12BDAB33CE0@gmail.com>

Maybe a naive question but given the price and SD of an asset, is there a way to calculate the probability of hitting a stop set at X over the next N days? I know making appropriate assumptions, this is a Wiener process but can't find the correct equation.

A) Is there a closed form solution for this?
B) Is there an R function related to this?

Ernie

Sent from my iPhone

From n-e-w at qtradr.net  Wed Nov 25 01:31:32 2015
From: n-e-w at qtradr.net (Nick White)
Date: Wed, 25 Nov 2015 11:31:32 +1100
Subject: [R-SIG-Finance] Computing stop probability
In-Reply-To: <CA1CB4F2-72E7-45B6-A124-A12BDAB33CE0@gmail.com>
References: <CA1CB4F2-72E7-45B6-A124-A12BDAB33CE0@gmail.com>
Message-ID: <CAH+4RFuzFbgrp484UwkoX7N3KGhMpk9okF_BNiNvDbCs8DoEqw@mail.gmail.com>

You might want to check out the derivation of the Thorp /
Black-Scholes-Merton formula as it deals with essentially the same
concepts...

On Wed, Nov 25, 2015 at 11:27 AM, Ernest Stokely <wizardchef at gmail.com>
wrote:

> Maybe a naive question but given the price and SD of an asset, is there a
> way to calculate the probability of hitting a stop set at X over the next N
> days? I know making appropriate assumptions, this is a Wiener process but
> can't find the correct equation.
>
> A) Is there a closed form solution for this?
> B) Is there an R function related to this?
>
> Ernie
>
> Sent from my iPhone
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From michael.weylandt at gmail.com  Wed Nov 25 02:23:57 2015
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Tue, 24 Nov 2015 19:23:57 -0600
Subject: [R-SIG-Finance] Computing stop probability
In-Reply-To: <CAH+4RFuzFbgrp484UwkoX7N3KGhMpk9okF_BNiNvDbCs8DoEqw@mail.gmail.com>
References: <CA1CB4F2-72E7-45B6-A124-A12BDAB33CE0@gmail.com>
	<CAH+4RFuzFbgrp484UwkoX7N3KGhMpk9okF_BNiNvDbCs8DoEqw@mail.gmail.com>
Message-ID: <CAAmySGNDhY2dES61-DfeB9+BTfJSihSWWoiqc0bgNhbreG2afw@mail.gmail.com>

On Tue, Nov 24, 2015 at 6:31 PM, Nick White <n-e-w at qtradr.net> wrote:
> You might want to check out the derivation of the Thorp /
> Black-Scholes-Merton formula as it deals with essentially the same
> concepts...
>
> On Wed, Nov 25, 2015 at 11:27 AM, Ernest Stokely <wizardchef at gmail.com>
> wrote:
>
>> Maybe a naive question but given the price and SD of an asset, is there a
>> way to calculate the probability of hitting a stop set at X over the next N
>> days? I know making appropriate assumptions, this is a Wiener process but
>> can't find the correct equation.
>>
>> A) Is there a closed form solution for this?
>> B) Is there an R function related to this?
>>

Black-Scholes (and stochastic volatility extensions) can give you a
probability of hitting a price under the equivalent martingale measure
("Q") but that can be pretty far from the "real-world" ("P")
probability of the same event happening. Or it may be close, depends
on your market.

If you don't want to do the math (it really is easy though -- half a
page at most), the relevant delta is decent approximation.


From rex at nosyntax.net  Wed Nov 25 03:51:07 2015
From: rex at nosyntax.net (rex)
Date: Tue, 24 Nov 2015 18:51:07 -0800
Subject: [R-SIG-Finance] Computing stop probability
In-Reply-To: <CA1CB4F2-72E7-45B6-A124-A12BDAB33CE0@gmail.com>
References: <CA1CB4F2-72E7-45B6-A124-A12BDAB33CE0@gmail.com>
Message-ID: <20151125025107.GC18255@nosyntax.net>

Ernest Stokely <wizardchef at gmail.com> [2015-11-24 16:28]:
> Maybe a naive question but given the price and SD of an asset, is there a way to calculate the probability of hitting a stop set at X over the next N days? I know making appropriate assumptions, this is a Wiener process but can't find the correct equation.
> 
> A) Is there a closed form solution for this?
> B) Is there an R function related to this?

A) NAFAIK.

My solution using iteration is here:

http://www.nosyntax.net/cfwiki/index.php/Probability_of_Touch-lognormal-3


Note that this is not the same as the probability the price is not less than X N days hence.

HTH,

-rex
--
Classical economists look for their keys under a streetlight
after losing them in an alley.


From michael.weylandt at gmail.com  Wed Nov 25 04:39:24 2015
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Tue, 24 Nov 2015 21:39:24 -0600
Subject: [R-SIG-Finance] Computing stop probability
In-Reply-To: <CAAmySGNDhY2dES61-DfeB9+BTfJSihSWWoiqc0bgNhbreG2afw@mail.gmail.com>
References: <CA1CB4F2-72E7-45B6-A124-A12BDAB33CE0@gmail.com>
	<CAH+4RFuzFbgrp484UwkoX7N3KGhMpk9okF_BNiNvDbCs8DoEqw@mail.gmail.com>
	<CAAmySGNDhY2dES61-DfeB9+BTfJSihSWWoiqc0bgNhbreG2afw@mail.gmail.com>
Message-ID: <CAAmySGOBB16kgeZQN6PRfjMAeopubceq=BXfzXBBFRz3n3+7-A@mail.gmail.com>

I misread your question: delta is only an approximation to being below
a level at a fixed time, not during an interval.

If you want the probability of hitting a stop over an interval, you
want the running max (or running min -- Weiner process is symmetrical)
of a Weiner process. This is a bit trickier to derive and I can't find
a simple derivation to point you to, so I typed one up quickly.

Also see: https://en.wikipedia.org/wiki/Wiener_process#Running_maximum
and http://math.stackexchange.com/questions/946968/law-of-a-geometric-brownian-motion-first-hitting-time-proof-checking?rq=1
(though note there's a mistake in the latter)

Hope this helps,
Michael

On Tue, Nov 24, 2015 at 7:23 PM, Michael Weylandt
<michael.weylandt at gmail.com> wrote:
> On Tue, Nov 24, 2015 at 6:31 PM, Nick White <n-e-w at qtradr.net> wrote:
>> You might want to check out the derivation of the Thorp /
>> Black-Scholes-Merton formula as it deals with essentially the same
>> concepts...
>>
>> On Wed, Nov 25, 2015 at 11:27 AM, Ernest Stokely <wizardchef at gmail.com>
>> wrote:
>>
>>> Maybe a naive question but given the price and SD of an asset, is there a
>>> way to calculate the probability of hitting a stop set at X over the next N
>>> days? I know making appropriate assumptions, this is a Wiener process but
>>> can't find the correct equation.
>>>
>>> A) Is there a closed form solution for this?
>>> B) Is there an R function related to this?
>>>
>
> Black-Scholes (and stochastic volatility extensions) can give you a
> probability of hitting a price under the equivalent martingale measure
> ("Q") but that can be pretty far from the "real-world" ("P")
> probability of the same event happening. Or it may be close, depends
> on your market.
>
> If you don't want to do the math (it really is easy though -- half a
> page at most), the relevant delta is decent approximation.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: WP_RunningMax.pdf
Type: application/pdf
Size: 97446 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151124/f2bb76e0/attachment.pdf>

From adrian at trapletti.org  Wed Nov 25 13:23:30 2015
From: adrian at trapletti.org (Adrian Trapletti)
Date: Wed, 25 Nov 2015 13:23:30 +0100
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 138, Issue 8
In-Reply-To: <mailman.17.1448449204.6307.r-sig-finance@r-project.org>
References: <mailman.17.1448449204.6307.r-sig-finance@r-project.org>
Message-ID: <5655A842.20009@trapletti.org>

Using simulation

p <- 100
sd <- 0.2
X <- 90
N <- 10
n <- 1000000
hit <- double(n)
for (i in 1:n) {
  hit[i] <- as.numeric(any(p * exp(cumsum(
    rnorm(N, sd = sd / sqrt(250))
  )) < X))
}
sum(hit)/n

Instead of using rnorm you may want to use e.g. rt() or an (G)ARCH
process or...

Best Adrian

On 25.11.2015 12:00, r-sig-finance-request at r-project.org wrote:
> Message: 1
> Date: Tue, 24 Nov 2015 18:27:19 -0600
> From: Ernest Stokely <wizardchef at gmail.com>
> To: R-SIG-Finance at r-project.org
> Subject: [R-SIG-Finance] Computing stop probability
> Message-ID: <CA1CB4F2-72E7-45B6-A124-A12BDAB33CE0 at gmail.com>
> Content-Type: text/plain;	charset=us-ascii
>
> Maybe a naive question but given the price and SD of an asset, is there a way to calculate the probability of hitting a stop set at X over the next N days? I know making appropriate assumptions, this is a Wiener process but can't find the correct equation.
>
> A) Is there a closed form solution for this?
> B) Is there an R function related to this?
>
> Ernie
>
> Sent from my iPhone

-- 
Dr. Adrian Trapletti
Steinstrasse 9b
CH-8610 Uster
Switzerland

Phone : +41 (0) 44 994 56 30
Mobile : +41 (0) 79 103 71 31

Email : adrian at trapletti.org
WWW : www.trapletti.org


From markknecht at gmail.com  Wed Nov 25 14:17:46 2015
From: markknecht at gmail.com (Mark Knecht)
Date: Wed, 25 Nov 2015 05:17:46 -0800
Subject: [R-SIG-Finance] Older financials?
In-Reply-To: <CACjNfm=nBFviQC_TqCCT7rDhKWquv80TGBNOJFSk7-L=4889Xg@mail.gmail.com>
References: <CAK2H+ecuFK2-8g-EEiCfcf-1wRbWSTLvHXF9vgNWSJqT7QC+dQ@mail.gmail.com>
	<CACjNfm=nBFviQC_TqCCT7rDhKWquv80TGBNOJFSk7-L=4889Xg@mail.gmail.com>
Message-ID: <CAK2H+ecSsRpxNYWEaNGjMntbH0c-953VCiskpEOKcvwCZHR0+A@mail.gmail.com>

Thanks Erol. I'll give it a look.

Cheers,
Mark
On Nov 23, 2015 1:35 PM, "Erol Biceroglu" <erol.biceroglu at alumni.utoronto.ca>
wrote:

> Hi Mark,
>
> The only data source I've been able to find that's affordable is
> Sharadar's fundamental data, which can be downloaded with the "quandl" R
> Package.  Note, it's a premium database (not free), details are on quandl's
> website.  Lastly, they are adding de-listed companies, but my understanding
> is that it's not completely free from survivorship bias.  Note, I
> personally have not used it yet.
>
> I'd be interested to hear if anyone has any other thoughts as well.  My
> apologies if my the comments above are not completely on topic.
>
>
>
>
> Erol Biceroglu
>
>
> *erol.biceroglu at alumni.utoronto.ca
> <erol.biceroglu at alumni.utoronto.ca>416-275-7970 <416-275-7970>*
>
> On Mon, Nov 23, 2015 at 2:33 PM, Mark Knecht <markknecht at gmail.com> wrote:
>
>> I'm reading a book on quant value investing that wants to look at more
>> financial data than I'm getting with the small program below. Looking at
>> the getFinancials help page I'm not seeing anything that tells it to go
>> back more than 4 years. Is there a way to do that with free data or is
>> this
>> a limitation WRT what Google provides and you have to go somewhere
>> else/pay
>> money to get it?
>>
>> Thanks,
>> Mark
>>
>> library(quantmod);
>>
>> SymList=c("MCD","GD","AAPL");
>> Quotes = getQuote(SymList, src="yahoo");
>>
>> for (Sym in SymList){
>>   getFinancials(Sym, src="google");
>>   getDividends(Sym, src="google");
>> }
>>
>> print(Quotes)
>>
>> print(viewFinancials(MCD.f, period="Q", type="IS"))
>> print(viewFinancials(MCD.f, period="A", type="CF"))
>> print(viewFinancials(MCD.f, period="Q", type="BS"))
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>

	[[alternative HTML version deleted]]


From rex at macey.us  Sat Nov 28 18:20:29 2015
From: rex at macey.us (Rex Macey)
Date: Sat, 28 Nov 2015 12:20:29 -0500
Subject: [R-SIG-Finance] Older financials?
Message-ID: <5659E25D.3010004@macey.us>

A suggestion on where to get extensive fundamental data cheaply.
This is a response to Mark's Nov 23rd message.

Consider data from the American Association of Individual Investor?s 
Stock Investor Pro (SIP) software. I?ve had a lifetime membership to the 
AAII for many years. For the additional, but more than reasonable price 
of $198/yr, one can license SIP. What makes this source valuable is that 
it is survivorship-bias free historical data. Subscribers have access to 
the old software and data as it was when it was distributed going back 
to 2003. The data include balance sheet, income statement, cash flow, 
price, and many calculated fields. The list of fields 
<https://www.aaii.com/files/sipro/Stock%20Investor%20Pro%20Field%20List.pdf> runs 
to 22 pages. In 2003, over 8,500 companies were covered.
For info on SIP, check out the AAII 
<file:///C:/Users/Rex/Documents/Quant%20Trading/SMW/www.aaii.com> webpage and 
this presentation 
<http://www.aaii.com/files/presentations/2011/20%20Joe%20Lan%20-%20Introduction%20to%20Stock%20Investor%20Pro.pdf>. 
I downloaded about 150 install files from the AAII archives 
<http://www.aaii.com/stock-investor-pro/archives> page site access to 
which requires membership ($29) and a subscription. I installed them one 
by one putting each into its own directory. I downloaded the month-end 
updates though weekly data was sometime available. I watched an entire 
season of Friends while doing this and probably lost three IQ points. 
Each install includes about 7 years of annual data and 8 quarters of 
quarterly data.
The AAII data files are in a Foxpro/DBF format. Fortunately R has the 
read.dbf 
<https://stat.ethz.ch/R-manual/R-devel/library/foreign/html/read.dbf.html> function 
in the foreign package to handle this.

Let me emphasize that this data is (almost) free of survivor-ship and 
look-ahead biases.  You are getting the data as SIP released it back in 
the day.  So companies around in 2003 that are not are in the data set.  
The data only has data that was available at the time of the release, so 
there is no look-ahead problem.  I added "almost" to cover 2 caveats.  
As an example, if you use the first install (end of 2002) to figure out 
companies with P/E's less than X in 2001, you've got a survivor-ship 
bias problem.  The SIP data is available pretty much at month end, but 
you won't be able to trade at month-end.  If you assume that you can, 
you have a look-ahead bias.

Weekly data is available beginning in 2005.

I hope this helps.  If you use SIP and find data errors, I'd like to 
know about them.

	[[alternative HTML version deleted]]


From edd at debian.org  Mon Nov 30 16:11:21 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 30 Nov 2015 09:11:21 -0600
Subject: [R-SIG-Finance] [Help Neeeded] QuantLib 1.7 windows build
Message-ID: <22108.26393.172955.68761@max.nulle.part>


QuantLib 1.7 came out a week ago. Among the new features is an optional use
of Boost Date_Time for intra-daily time.  I added support for this (for all
the option prices and implied volatility computation) to RQuantLib (see the
GitHub repo) but before releasing to CRAN I was wondering if someone could do
us the favour and update the Windows builds accordingly?

Jeroen helped with the previous issues but ran into a snag related to use of
Boost Threads.  That can probably be worked around by means of a proper
configure call before compilation (as some threading features are also new).

It would be awesome if someone could volunteer and look into this. If so,
please get in touch with Jerome and myself off-list.

Thanks,  Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From pedro.sim.oliveira at gmail.com  Tue Dec  1 12:47:57 2015
From: pedro.sim.oliveira at gmail.com (Pedro Oliveira)
Date: Tue, 1 Dec 2015 11:47:57 +0000
Subject: [R-SIG-Finance] fPortfolio (version 3011.81) - solveRglpk.CVAR -
 lower bound constraints (z_i >= 0) allows negative values
Message-ID: <CAHUwa6Pge3OfzMhsghwDACtJxWkfPSsKt5Q1FVOv7OXVUc=sRg@mail.gmail.com>

Hi,

I have been looking at the code of the solveRglpk.CVAR function, in order
to create a similar function but where the objective function will be a
trade-off between the expected return and a risk aversion factor times the
CVaR risk measure. In the hidden function .cvarRglpkArguments, where the
matrices, served as input for the Rglpk solver, are built, I think the
lower bounds are not properly defined. Namely, the optimization problem has
the following constraints z_i >= 0 where i = 1:nScenarios, thus the lower
bound should not be -Inf, but 0. Am I making any mistake?

Lines of code (164-166):
    bounds <- list(
        lower = list(ind = nInd, val = c(rep(-Inf, 1+nScenarios), minW)),
        upper = list(ind = nInd, val = c(rep( Inf, 1+nScenarios), maxW)) )


Note: z_i is the term being summed after we discretized the integral.

Thanks and regards

Pedro Oliveira

	[[alternative HTML version deleted]]


From EBiceroglu at optrust.com  Tue Dec  1 20:18:20 2015
From: EBiceroglu at optrust.com (Erol Biceroglu)
Date: Tue, 1 Dec 2015 19:18:20 +0000
Subject: [R-SIG-Finance] R-Forge TradeAnalytics packages for R 3.2.2
Message-ID: <70C28E80655BFC46978030281154E85862211814@EXCHMBOX001P.optrust.local>

Hello,

I'm attempting to install quantstrat, and I'm getting the following message:

> install.packages("quantstrat", repos="http://R-Forge.R-project.org")
Installing package into '/home/optdev/R_libs'
(as 'lib' is unspecified)
Warning in install.packages :
  package 'quantstrat' is not available (for R version 3.2.2)
>

Would anyone happen to know if I'm missing anything?  Thanks

Here's my session info:
> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.3 LTS

locale:
[1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8
 [4] LC_COLLATE=en_CA.UTF-8     LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
 [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                  LC_ADDRESS=C
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] devtools_1.9.1

loaded via a namespace (and not attached):
[1] tools_3.2.2   memoise_0.2.1 digest_0.6.8



Erol Biceroglu



Disclaimer 
--------------- 
This e-mail and files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are addressed. If you have received this in error, contact OPTrust by telephone toll free at 1-800-906-7738 and delete the email without making a paper or electronic copy. The recipient should check this e-mail and attachments for the presence of viruses. OPTrust accepts no liability for any damage caused by any virus transmitted by e-mail. 
Please consider the environment before printing this e-mail message.
 
Avis de non-responsabilit? 
-------------------------------------- 
Ce message et toutes les pi?ces jointes sont ?tablis ? l'intention exclusive de leur destinataire et sont confidentiels. Si vous recevez ce message par erreur, veuillez le d?truire sans produire de copie papier ou ?lectronique, et avertir imm?diatement OPTrust par t?l?phone ou sans frais au 1-800-906-7738. Le destinataire doit s?assurer que ce message et toutes les pi?ces jointes ne contiennent pas de virus. OPTrust n?accepte aucune responsabilit? pour les dommages caus?s par d??ventuels virus transmis par courriel. 
Pensez ? l?environnement avant d?imprimer ce message. 


	[[alternative HTML version deleted]]


From ingo.boland at gmail.com  Thu Dec  3 10:03:04 2015
From: ingo.boland at gmail.com (Ingo Boland)
Date: Thu, 3 Dec 2015 10:03:04 +0100
Subject: [R-SIG-Finance] Trailing stop in Andreas Clenow trend-following
	system
Message-ID: <CA+ZLyiW1VCf-vryZjToK9kwXuWBkhT5vMnCRmrOp62JCynn+Gw@mail.gmail.com>

Good morning,

I'm trying to rebuild the basic strategy out of Andreas Clenow's book
"Following the trend in quantstrat but struggling with the trailing stop.
The rules are as follows (only for long trades):

1.     *Entry rule*: Buy open tomorrow when close is higher or equal to the
highest close of the past 50 days

2*.*     *Filter*: Long entries only if SMA50 >= SMA100

3.     *Closing*: Sell open tomorrow when breakout to the downside or SMA50
< SMA100

4.     *Trailing stop (and this seems to be the difficult one)*: Sell open
tomorrow when close price is lower than highest high since deal entry minus
3 times the current ATR (100days) - current ATR and not the ATR at deal
entry

5.     *Position sizing*: Risking always a fixed amount

I read about the idea of just adding an indicator which is triggering the
stop but the problem is that this indicator has to depend on the entry
dates of the strategy. My idea was to alter the indicator in the mktdata
object every time I enter a trade via the ordersizing function osFUN. But
this didn't work.

Does anyone have a solution for this problem?

Kind regards,

Ingo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151203/57473725/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Quantstrat_ClenowTrend.R
Type: application/octet-stream
Size: 5106 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20151203/57473725/attachment.obj>

From thomas.fuller at coherentlogic.com  Fri Dec  4 17:09:12 2015
From: thomas.fuller at coherentlogic.com (Thomas Fuller)
Date: Fri, 4 Dec 2015 11:09:12 -0500
Subject: [R-SIG-Finance] Coherent Datafeed: Thomson Reuters Elektron Edition
Message-ID: <CAM0JZ3kTjg8LaSDr11Uc37=rF2-qzThgWmgN8DmOKsXwALqH2g@mail.gmail.com>

Hi Folks,

We have an update for the *Coherent Datafeed*: *Thomson Reuters Elektron
Edition* available here:

https://coherentlogic.com/middleware-development/solutions-for-traders-using-thomson-reuters-market-data/version101-update-elektron-migration/

This software is available under the open source LGPL license for both Java
developers and users of the R Project for Statistical Computing.

We have a new version which will be released in the coming weeks which will
provide market by order (currently available), market by price, and market
maker (in development) functionality -- if you're interested in using these
new functions, please get in touch as I'd appreciate some help with testing.

Questions and comments are welcomed.

Tom

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Sat Dec  5 16:25:17 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 5 Dec 2015 09:25:17 -0600
Subject: [R-SIG-Finance] R-Forge TradeAnalytics packages for R 3.2.2
In-Reply-To: <70C28E80655BFC46978030281154E85862211814@EXCHMBOX001P.optrust.local>
References: <70C28E80655BFC46978030281154E85862211814@EXCHMBOX001P.optrust.local>
Message-ID: <CAPPM_gSkuYwomtHmxZ-bnjHks+AYBSafraiyXv-yz2EbZepMWQ@mail.gmail.com>

On Tue, Dec 1, 2015 at 1:18 PM, Erol Biceroglu <EBiceroglu at optrust.com> wrote:
> Hello,
>
> I'm attempting to install quantstrat, and I'm getting the following message:
>
>> install.packages("quantstrat", repos="http://R-Forge.R-project.org")
> Installing package into '/home/optdev/R_libs'
> (as 'lib' is unspecified)
> Warning in install.packages :
>   package 'quantstrat' is not available (for R version 3.2.2)
>>
>
> Would anyone happen to know if I'm missing anything?  Thanks
>
The R-Forge build system can be quirky at times. The most reliable
thing you can do is check out the source and build/install from that.

Here's a Q/A on Stack Overflow that describes the process:
http://stackoverflow.com/q/11105131/271616

> Here's my session info:
>> sessionInfo()
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.3 LTS
>
> locale:
> [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8
>  [4] LC_COLLATE=en_CA.UTF-8     LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                  LC_ADDRESS=C
> [10] LC_TELEPHONE=C             LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] devtools_1.9.1
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.2   memoise_0.2.1 digest_0.6.8
>
>
>
> Erol Biceroglu
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From m.ashton at enduringinvestments.com  Tue Dec 15 01:13:01 2015
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Mon, 14 Dec 2015 16:13:01 -0800
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
Message-ID: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>

I must admit to being flummoxed here, mainly because my linear algebra was 25 years ago and I can't remember what a Hessian is.

I have a matrix of 60 securities' weekly returns, along with 60 projected returns. The returns are in a vector called Ret.vect and the covariance matrix of weekly returns in cov.mat . I have the minConstraints and maxConstraints that the parameters are permitted to take. I cycle through targeted risks and get the same error for each risk targeted...below I have removed the loop to focus on the risk=0.002.

wgt.vect=c(rep(1/60, 60))
constr.fun <- function(wgt.vect) {;
                c1 = sqrt(crossprod(t(wgt.vect %*% cov.mat),wgt.vect));
                c2 = sum(wgt.vect);
                return(c(c1,c2));
                }
ineqconstr.fun <- function(wgt.vect) {
                wgt.vect[1:60];
                }
opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}

OptimSolution <- solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ineqLB=minConstraints,ineqUB=maxConstraints)

I get the following error:
solnp--> Solution not reliable....Problem Inverting Hessian.

Well, that doesn't tell me very much! The parameters (weights) that are output for each run, as I cycle through the weights, are very scrambled...lots of little allocations, rather than clumping as you would expect to happen especially at the risky and riskless ends of the spectrum.

Can anyone with more math than me give me a helping hand on the Hessian?

Thanks,


Mike

Michael Ashton, CFA
Managing Principal

Enduring Investments LLC
W: 973.457.4602
C: 551.655.8006


________________________________
This email and any attachments are confidential and inte...{{dropped:9}}


From michael.weylandt at gmail.com  Tue Dec 15 02:31:38 2015
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Mon, 14 Dec 2015 19:31:38 -0600
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
In-Reply-To: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
References: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
Message-ID: <CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>

The Hessian is the matrix of second derivatives
(https://en.wikipedia.org/wiki/Hessian_matrix) -- in scalar terms,
you're finding a point where the second derivative is zero and then
trying to divide by the second derivative to calculate the step size.

I haven't gone through your code in any detail, but I'd start by
checking the covariance matrix since that's proportional to the
Hessian of your objective function. Is it (comfortably) non-singular?

Since you're just solving the standard Markowitz problem, you might
try a simpler (quadratic/convex) solver instead of a general
non-linear solver. Should behave a bit better.

Michael


On Mon, Dec 14, 2015 at 6:13 PM, Michael Ashton
<m.ashton at enduringinvestments.com> wrote:
> I must admit to being flummoxed here, mainly because my linear algebra was 25 years ago and I can't remember what a Hessian is.
>
> I have a matrix of 60 securities' weekly returns, along with 60 projected returns. The returns are in a vector called Ret.vect and the covariance matrix of weekly returns in cov.mat . I have the minConstraints and maxConstraints that the parameters are permitted to take. I cycle through targeted risks and get the same error for each risk targeted...below I have removed the loop to focus on the risk=0.002.
>
> wgt.vect=c(rep(1/60, 60))
> constr.fun <- function(wgt.vect) {;
>                 c1 = sqrt(crossprod(t(wgt.vect %*% cov.mat),wgt.vect));
>                 c2 = sum(wgt.vect);
>                 return(c(c1,c2));
>                 }
> ineqconstr.fun <- function(wgt.vect) {
>                 wgt.vect[1:60];
>                 }
> opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}
>
> OptimSolution <- solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ineqLB=minConstraints,ineqUB=maxConstraints)
>
> I get the following error:
> solnp--> Solution not reliable....Problem Inverting Hessian.
>
> Well, that doesn't tell me very much! The parameters (weights) that are output for each run, as I cycle through the weights, are very scrambled...lots of little allocations, rather than clumping as you would expect to happen especially at the risky and riskless ends of the spectrum.
>
> Can anyone with more math than me give me a helping hand on the Hessian?
>
> Thanks,
>
>
> Mike
>
> Michael Ashton, CFA
> Managing Principal
>
> Enduring Investments LLC
> W: 973.457.4602
> C: 551.655.8006
>
>
> ________________________________
> This email and any attachments are confidential and inte...{{dropped:9}}
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From m.ashton at enduringinvestments.com  Tue Dec 15 03:06:15 2015
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Mon, 14 Dec 2015 18:06:15 -0800
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
In-Reply-To: <CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>
References: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>
Message-ID: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>

Do you have a suggestion for such? I have in the past tried fPortfolio, but it would not allow me to specify my own projected return vectors rather than the historical returns of the series (which is exactly backwards).

As for whether the matrix is comfortably non-singular...I suppose it depends in a Clintonian way on the meaning of "comfortably," but I can create a Cholesky decomposition without it blowing up, which is usually how I can tell if I have done something stupid. Well, stupider than normal.

-----Original Message-----
From: Michael Weylandt [mailto:michael.weylandt at gmail.com]
Sent: Monday, December 14, 2015 8:32 PM
To: Michael Ashton
Cc: r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian

The Hessian is the matrix of second derivatives
(https://en.wikipedia.org/wiki/Hessian_matrix) -- in scalar terms, you're finding a point where the second derivative is zero and then trying to divide by the second derivative to calculate the step size.

I haven't gone through your code in any detail, but I'd start by checking the covariance matrix since that's proportional to the Hessian of your objective function. Is it (comfortably) non-singular?

Since you're just solving the standard Markowitz problem, you might try a simpler (quadratic/convex) solver instead of a general non-linear solver. Should behave a bit better.

Michael


On Mon, Dec 14, 2015 at 6:13 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
> I must admit to being flummoxed here, mainly because my linear algebra was 25 years ago and I can't remember what a Hessian is.
>
> I have a matrix of 60 securities' weekly returns, along with 60 projected returns. The returns are in a vector called Ret.vect and the covariance matrix of weekly returns in cov.mat . I have the minConstraints and maxConstraints that the parameters are permitted to take. I cycle through targeted risks and get the same error for each risk targeted...below I have removed the loop to focus on the risk=0.002.
>
> wgt.vect=c(rep(1/60, 60))
> constr.fun <- function(wgt.vect) {;
>                 c1 = sqrt(crossprod(t(wgt.vect %*% cov.mat),wgt.vect));
>                 c2 = sum(wgt.vect);
>                 return(c(c1,c2));
>                 }
> ineqconstr.fun <- function(wgt.vect) {
>                 wgt.vect[1:60];
>                 }
> opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}
>
> OptimSolution <-
> solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ineqLB
> =minConstraints,ineqUB=maxConstraints)
>
> I get the following error:
> solnp--> Solution not reliable....Problem Inverting Hessian.
>
> Well, that doesn't tell me very much! The parameters (weights) that are output for each run, as I cycle through the weights, are very scrambled...lots of little allocations, rather than clumping as you would expect to happen especially at the risky and riskless ends of the spectrum.
>
> Can anyone with more math than me give me a helping hand on the Hessian?
>
> Thanks,
>
>
> Mike
>
> Michael Ashton, CFA
> Managing Principal
>
> Enduring Investments LLC
> W: 973.457.4602
> C: 551.655.8006
>
>
> ________________________________
> This email and any attachments are confidential and
> inte...{{dropped:9}}
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

This email and any attachments are confidential and intended only for the recipient noted above. You are hereby notified that any use, printing, copying or disclosure is strictly prohibited without the permission of Enduring Investments LLC. For further information please contact: Management at EnduringInvestments.com; (973) 457-4602.

From kk2250 at optonline.net  Tue Dec 15 03:27:11 2015
From: kk2250 at optonline.net (Krishna Kumar)
Date: Mon, 14 Dec 2015 21:27:11 -0500
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
In-Reply-To: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>
References: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>
Message-ID: <4459A915-39FA-4074-B601-DB12AA1166DE@optonline.net>

Michael,


Perhaps your covariance matrix is singular (non positive definite) so you can "fix" this matrix by finding the nearest correlation matrix that is non singular. 

The simplest recipe is to  set the negative eigenvalues to a small positive number and rescale the  matrix.
Also look at nearPD in the Matrix package.

Best
Krishna

----

> On Dec 14, 2015, at 9:06 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
> 
> Do you have a suggestion for such? I have in the past tried fPortfolio, but it would not allow me to specify my own projected return vectors rather than the historical returns of the series (which is exactly backwards).
> 
> As for whether the matrix is comfortably non-singular...I suppose it depends in a Clintonian way on the meaning of "comfortably," but I can create a Cholesky decomposition without it blowing up, which is usually how I can tell if I have done something stupid. Well, stupider than normal.
> 
> -----Original Message-----
> From: Michael Weylandt [mailto:michael.weylandt at gmail.com]
> Sent: Monday, December 14, 2015 8:32 PM
> To: Michael Ashton
> Cc: r-sig-finance at r-project.org
> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
> 
> The Hessian is the matrix of second derivatives
> (https://en.wikipedia.org/wiki/Hessian_matrix) -- in scalar terms, you're finding a point where the second derivative is zero and then trying to divide by the second derivative to calculate the step size.
> 
> I haven't gone through your code in any detail, but I'd start by checking the covariance matrix since that's proportional to the Hessian of your objective function. Is it (comfortably) non-singular?
> 
> Since you're just solving the standard Markowitz problem, you might try a simpler (quadratic/convex) solver instead of a general non-linear solver. Should behave a bit better.
> 
> Michael
> 
> 
>> On Mon, Dec 14, 2015 at 6:13 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
>> I must admit to being flummoxed here, mainly because my linear algebra was 25 years ago and I can't remember what a Hessian is.
>> 
>> I have a matrix of 60 securities' weekly returns, along with 60 projected returns. The returns are in a vector called Ret.vect and the covariance matrix of weekly returns in cov.mat . I have the minConstraints and maxConstraints that the parameters are permitted to take. I cycle through targeted risks and get the same error for each risk targeted...below I have removed the loop to focus on the risk=0.002.
>> 
>> wgt.vect=c(rep(1/60, 60))
>> constr.fun <- function(wgt.vect) {;
>>                c1 = sqrt(crossprod(t(wgt.vect %*% cov.mat),wgt.vect));
>>                c2 = sum(wgt.vect);
>>                return(c(c1,c2));
>>                }
>> ineqconstr.fun <- function(wgt.vect) {
>>                wgt.vect[1:60];
>>                }
>> opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}
>> 
>> OptimSolution <-
>> solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ineqLB
>> =minConstraints,ineqUB=maxConstraints)
>> 
>> I get the following error:
>> solnp--> Solution not reliable....Problem Inverting Hessian.
>> 
>> Well, that doesn't tell me very much! The parameters (weights) that are output for each run, as I cycle through the weights, are very scrambled...lots of little allocations, rather than clumping as you would expect to happen especially at the risky and riskless ends of the spectrum.
>> 
>> Can anyone with more math than me give me a helping hand on the Hessian?
>> 
>> Thanks,
>> 
>> 
>> Mike
>> 
>> Michael Ashton, CFA
>> Managing Principal
>> 
>> Enduring Investments LLC
>> W: 973.457.4602
>> C: 551.655.8006
>> 
>> 
>> ________________________________
>> This email and any attachments are confidential and
>> inte...{{dropped:9}}
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
> 
> This email and any attachments are confidential and in...{{dropped:10}}


From michael.weylandt at gmail.com  Tue Dec 15 03:28:50 2015
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Mon, 14 Dec 2015 20:28:50 -0600
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
In-Reply-To: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>
References: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>
Message-ID: <CAAmySGMXqikXMhO7r7Ofz8E1C2nD0O5YjNr_9ua9NT7O8RVbbQ@mail.gmail.com>

What's the condition number of your correlation/covariance matrix? (?kappa)

I think I've used quadprog for portfolio optimization with success,
but it's been a while.

MW

On Mon, Dec 14, 2015 at 8:06 PM, Michael Ashton
<m.ashton at enduringinvestments.com> wrote:
> Do you have a suggestion for such? I have in the past tried fPortfolio, but it would not allow me to specify my own projected return vectors rather than the historical returns of the series (which is exactly backwards).
>
> As for whether the matrix is comfortably non-singular...I suppose it depends in a Clintonian way on the meaning of "comfortably," but I can create a Cholesky decomposition without it blowing up, which is usually how I can tell if I have done something stupid. Well, stupider than normal.
>
> -----Original Message-----
> From: Michael Weylandt [mailto:michael.weylandt at gmail.com]
> Sent: Monday, December 14, 2015 8:32 PM
> To: Michael Ashton
> Cc: r-sig-finance at r-project.org
> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
>
> The Hessian is the matrix of second derivatives
> (https://en.wikipedia.org/wiki/Hessian_matrix) -- in scalar terms, you're finding a point where the second derivative is zero and then trying to divide by the second derivative to calculate the step size.
>
> I haven't gone through your code in any detail, but I'd start by checking the covariance matrix since that's proportional to the Hessian of your objective function. Is it (comfortably) non-singular?
>
> Since you're just solving the standard Markowitz problem, you might try a simpler (quadratic/convex) solver instead of a general non-linear solver. Should behave a bit better.
>
> Michael
>
>
> On Mon, Dec 14, 2015 at 6:13 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
>> I must admit to being flummoxed here, mainly because my linear algebra was 25 years ago and I can't remember what a Hessian is.
>>
>> I have a matrix of 60 securities' weekly returns, along with 60 projected returns. The returns are in a vector called Ret.vect and the covariance matrix of weekly returns in cov.mat . I have the minConstraints and maxConstraints that the parameters are permitted to take. I cycle through targeted risks and get the same error for each risk targeted...below I have removed the loop to focus on the risk=0.002.
>>
>> wgt.vect=c(rep(1/60, 60))
>> constr.fun <- function(wgt.vect) {;
>>                 c1 = sqrt(crossprod(t(wgt.vect %*% cov.mat),wgt.vect));
>>                 c2 = sum(wgt.vect);
>>                 return(c(c1,c2));
>>                 }
>> ineqconstr.fun <- function(wgt.vect) {
>>                 wgt.vect[1:60];
>>                 }
>> opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}
>>
>> OptimSolution <-
>> solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ineqLB
>> =minConstraints,ineqUB=maxConstraints)
>>
>> I get the following error:
>> solnp--> Solution not reliable....Problem Inverting Hessian.
>>
>> Well, that doesn't tell me very much! The parameters (weights) that are output for each run, as I cycle through the weights, are very scrambled...lots of little allocations, rather than clumping as you would expect to happen especially at the risky and riskless ends of the spectrum.
>>
>> Can anyone with more math than me give me a helping hand on the Hessian?
>>
>> Thanks,
>>
>>
>> Mike
>>
>> Michael Ashton, CFA
>> Managing Principal
>>
>> Enduring Investments LLC
>> W: 973.457.4602
>> C: 551.655.8006
>>
>>
>> ________________________________
>> This email and any attachments are confidential and
>> inte...{{dropped:9}}
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>
> This email and any attachments are confidential and in...{{dropped:6}}


From m.ashton at enduringinvestments.com  Tue Dec 15 05:14:17 2015
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Mon, 14 Dec 2015 20:14:17 -0800
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
In-Reply-To: <4459A915-39FA-4074-B601-DB12AA1166DE@optonline.net>
References: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>
	<4459A915-39FA-4074-B601-DB12AA1166DE@optonline.net>
Message-ID: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9F@EXVMBX018-3.exch018.msoutlookonline.net>

All eigenvalues are positive.

From: Krishna Kumar [mailto:kk2250 at optonline.net]
Sent: Monday, December 14, 2015 9:27 PM
To: Michael Ashton
Cc: Michael Weylandt; r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian

Michael,


Perhaps your covariance matrix is singular (non positive definite) so you can "fix" this matrix by finding the nearest correlation matrix that is non singular.


The simplest recipe is to  set the negative eigenvalues to a small positive number and rescale the  matrix.

Also look at nearPD in the Matrix package.



Best

Krishna

----

On Dec 14, 2015, at 9:06 PM, Michael Ashton <m.ashton at enduringinvestments.com<mailto:m.ashton at enduringinvestments.com>> wrote:
Do you have a suggestion for such? I have in the past tried fPortfolio, but it would not allow me to specify my own projected return vectors rather than the historical returns of the series (which is exactly backwards).

As for whether the matrix is comfortably non-singular...I suppose it depends in a Clintonian way on the meaning of "comfortably," but I can create a Cholesky decomposition without it blowing up, which is usually how I can tell if I have done something stupid. Well, stupider than normal.

-----Original Message-----
From: Michael Weylandt [mailto:michael.weylandt at gmail.com]
Sent: Monday, December 14, 2015 8:32 PM
To: Michael Ashton
Cc: r-sig-finance at r-project.org<mailto:r-sig-finance at r-project.org>
Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian

The Hessian is the matrix of second derivatives
(https://en.wikipedia.org/wiki/Hessian_matrix) -- in scalar terms, you're finding a point where the second derivative is zero and then trying to divide by the second derivative to calculate the step size.

I haven't gone through your code in any detail, but I'd start by checking the covariance matrix since that's proportional to the Hessian of your objective function. Is it (comfortably) non-singular?

Since you're just solving the standard Markowitz problem, you might try a simpler (quadratic/convex) solver instead of a general non-linear solver. Should behave a bit better.

Michael


On Mon, Dec 14, 2015 at 6:13 PM, Michael Ashton <m.ashton at enduringinvestments.com<mailto:m.ashton at enduringinvestments.com>> wrote:

I must admit to being flummoxed here, mainly because my linear algebra was 25 years ago and I can't remember what a Hessian is.

I have a matrix of 60 securities' weekly returns, along with 60 projected returns. The returns are in a vector called Ret.vect and the covariance matrix of weekly returns in cov.mat . I have the minConstraints and maxConstraints that the parameters are permitted to take. I cycle through targeted risks and get the same error for each risk targeted...below I have removed the loop to focus on the risk=0.002.

wgt.vect=c(rep(1/60, 60))
constr.fun <- function(wgt.vect) {;
               c1 = sqrt(crossprod(t(wgt.vect %*% cov.mat),wgt.vect));
               c2 = sum(wgt.vect);
               return(c(c1,c2));
               }
ineqconstr.fun <- function(wgt.vect) {
               wgt.vect[1:60];
               }
opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}

OptimSolution <-
solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ineqLB
=minConstraints,ineqUB=maxConstraints)

I get the following error:
solnp--> Solution not reliable....Problem Inverting Hessian.

Well, that doesn't tell me very much! The parameters (weights) that are output for each run, as I cycle through the weights, are very scrambled...lots of little allocations, rather than clumping as you would expect to happen especially at the risky and riskless ends of the spectrum.

Can anyone with more math than me give me a helping hand on the Hessian?

Thanks,


Mike

Michael Ashton, CFA
Managing Principal

Enduring Investments LLC
W: 973.457.4602
C: 551.655.8006


________________________________
This email and any attachments are confidential and
inte...{{dropped:9}}

_______________________________________________
R-SIG-Finance at r-project.org<mailto:R-SIG-Finance at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.

This email and any attachments are confidential and intended only for the recipient noted above. You are hereby notified that any use, printing, copying or disclosure is strictly prohibited without the permission of Enduring Investments LLC. For further information please contact: Management at EnduringInvestments.com<mailto:Management at enduringinvestments.com>; (973) 457-4602.
_______________________________________________
R-SIG-Finance at r-project.org<mailto:R-SIG-Finance at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.

________________________________
This email and any attachments are confidential and intended only for the recipient noted above. You are hereby notified that any use, printing, copying or disclosure is strictly prohibited without the permission of Enduring Investments LLC. For further information please contact: Management at EnduringInvestments.com; (973) 457-4602.

	[[alternative HTML version deleted]]


From michael.weylandt at gmail.com  Tue Dec 15 05:39:28 2015
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Mon, 14 Dec 2015 22:39:28 -0600
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
In-Reply-To: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9E@EXVMBX018-3.exch018.msoutlookonline.net>
References: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGMXqikXMhO7r7Ofz8E1C2nD0O5YjNr_9ua9NT7O8RVbbQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9E@EXVMBX018-3.exch018.msoutlookonline.net>
Message-ID: <CAAmySGN3RTee9puDqURXvXE3ndWx4=wTuyRhhq6W_mjGpYOkVQ@mail.gmail.com>

(+list -- I'm not a numerical linear algebra expert or portfolio
optimization expert, but there are a number on this list who might
chime in)

That is quite high, and almost certainly problematic.

I'm not sure what an acceptable bound is (will depend on your solver),
but that's almost certainly above it for any algorithm which will
require inverting cov.mat.

Two things you could try:
- use a different (non-Hessian-using) optimization algorithm;
- use some form of shrinkage/regularization (Ledoit-Wolf is a common
choice) to tame your covariance matrix.

Michael

On Mon, Dec 14, 2015 at 10:10 PM, Michael Ashton
<m.ashton at enduringinvestments.com> wrote:
> Well, not sure whether this makes any sense but kappa(cov.mat) gives me 11148245007.
>
> That seems large. But I am not sure what it is supposed to be.
>
> -----Original Message-----
> From: Michael Weylandt [mailto:michael.weylandt at gmail.com]
> Sent: Monday, December 14, 2015 9:29 PM
> To: Michael Ashton
> Cc: r-sig-finance at r-project.org
> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
>
> What's the condition number of your correlation/covariance matrix? (?kappa)
>
> I think I've used quadprog for portfolio optimization with success, but it's been a while.
>
> MW
>
> On Mon, Dec 14, 2015 at 8:06 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
>> Do you have a suggestion for such? I have in the past tried fPortfolio, but it would not allow me to specify my own projected return vectors rather than the historical returns of the series (which is exactly backwards).
>>
>> As for whether the matrix is comfortably non-singular...I suppose it depends in a Clintonian way on the meaning of "comfortably," but I can create a Cholesky decomposition without it blowing up, which is usually how I can tell if I have done something stupid. Well, stupider than normal.
>>
>> -----Original Message-----
>> From: Michael Weylandt [mailto:michael.weylandt at gmail.com]
>> Sent: Monday, December 14, 2015 8:32 PM
>> To: Michael Ashton
>> Cc: r-sig-finance at r-project.org
>> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
>>
>> The Hessian is the matrix of second derivatives
>> (https://en.wikipedia.org/wiki/Hessian_matrix) -- in scalar terms, you're finding a point where the second derivative is zero and then trying to divide by the second derivative to calculate the step size.
>>
>> I haven't gone through your code in any detail, but I'd start by checking the covariance matrix since that's proportional to the Hessian of your objective function. Is it (comfortably) non-singular?
>>
>> Since you're just solving the standard Markowitz problem, you might try a simpler (quadratic/convex) solver instead of a general non-linear solver. Should behave a bit better.
>>
>> Michael
>>
>>
>> On Mon, Dec 14, 2015 at 6:13 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
>>> I must admit to being flummoxed here, mainly because my linear algebra was 25 years ago and I can't remember what a Hessian is.
>>>
>>> I have a matrix of 60 securities' weekly returns, along with 60 projected returns. The returns are in a vector called Ret.vect and the covariance matrix of weekly returns in cov.mat . I have the minConstraints and maxConstraints that the parameters are permitted to take. I cycle through targeted risks and get the same error for each risk targeted...below I have removed the loop to focus on the risk=0.002.
>>>
>>> wgt.vect=c(rep(1/60, 60))
>>> constr.fun <- function(wgt.vect) {;
>>>                 c1 = sqrt(crossprod(t(wgt.vect %*% cov.mat),wgt.vect));
>>>                 c2 = sum(wgt.vect);
>>>                 return(c(c1,c2));
>>>                 }
>>> ineqconstr.fun <- function(wgt.vect) {
>>>                 wgt.vect[1:60];
>>>                 }
>>> opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}
>>>
>>> OptimSolution <-
>>> solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ineqL
>>> B
>>> =minConstraints,ineqUB=maxConstraints)
>>>
>>> I get the following error:
>>> solnp--> Solution not reliable....Problem Inverting Hessian.
>>>
>>> Well, that doesn't tell me very much! The parameters (weights) that are output for each run, as I cycle through the weights, are very scrambled...lots of little allocations, rather than clumping as you would expect to happen especially at the risky and riskless ends of the spectrum.
>>>
>>> Can anyone with more math than me give me a helping hand on the Hessian?
>>>
>>> Thanks,
>>>
>>>
>>> Mike
>>>
>>> Michael Ashton, CFA
>>> Managing Principal
>>>
>>> Enduring Investments LLC
>>> W: 973.457.4602
>>> C: 551.655.8006
>>>
>>>
>>> ________________________________
>>> This email and any attachments are confidential and
>>> inte...{{dropped:9}}
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions should go.
>>
>> This email and any attachments are confidential and intended only for the recipient noted above. You are hereby notified that any use, printing, copying or disclosure is strictly prohibited without the permission of Enduring Investments LLC. For further information please contact: Management at EnduringInvestments.com; (973) 457-4602.
>
> This email and any attachments are confidential and in...{{dropped:6}}


From verial.damon at gmail.com  Tue Dec 15 09:51:07 2015
From: verial.damon at gmail.com (Damon Verial)
Date: Tue, 15 Dec 2015 17:51:07 +0900
Subject: [R-SIG-Finance] Quantstrat code works for long position but not
	short position
Message-ID: <CA+3g=Dcapp5AEwwKQOkt9SMDU=8PQsc4WWFUzMMGUi1tax1R7A@mail.gmail.com>

So I have this code that works fine for long positions. However, when I
reversed the code to make a short version, it breaks, giving me an error of:

Error in osFUN(strategy = strategy, data = mktdata, timestamp = timestamp,
:
  ATR corresponding to atrX is invalid at this point in time.
               Add a logical operator to account for this.

Why does this occur with the short position but not the long position? The
code follows, for reference:

library("quantstrat")
require(IKTrading)

initDate<-startDate<-'2015-01-01'
endDate<-'2015-12-09'

rm(list = ls(.blotter), envir = .blotter)
currency("USD")
Sys.setenv(TZ = "UTC")
symbols<-"SPY"

strategy.st <- portfolio.st <- account.st <- "Gaps"
getSymbols(symbols, src="yahoo",
index.class=c("POSIXt","POSIXct"),from=startDate,
to=endDate, adjust=T)
stock(symbols,currency="USD",multiplier=1)
tradeSize <- 100000
initEq <- tradeSize*length(symbols)

strategy.st <- portfolio.st <- account.st <- "Gaps"
rm.strat(strategy.st)
initPortf(portfolio.st, symbols=symbols, initDate=initDate, currency='USD')
initAcct(account.st, portfolios=portfolio.st, initDate=initDate,
currency='USD',initEq=initEq)
initOrders(portfolio.st, initDate=initDate)
strategy(strategy.st, store=TRUE)


period=10
pctATR=.1

####################
## UP GAPS ##
####################

#necessary functions

gap <- function(x,k) {
 low <- Lo(x)
 high<- Hi(x)
 yesHigh <- lag.xts(high,k=1)
 gapDay <- low > yesHigh
 gapDay[1] <- 0
 gaps <- x[gapDay==1,]
 gaps$takeProfit <- yesHigh[gapDay==1,]
 gaps<-cbind(gapDay,gaps$takeProfit)
 gaps$takeProfit<-na.locf(gaps$takeProfit)
 colnames(gaps) <- c("gap","TP")
 return(gaps)
}


period=10
pctATR=.1


#indicators

add.indicator(strategy.st, name="lagATR",
              arguments=list(HLC=quote(HLC(mktdata)),
                             n=period),
              label="atrX")

add.indicator(strategy.st, name="gap",
              arguments=list(x=quote(HLC(mktdata))),
              label="gap")


test <- applyIndicators(strategy.st, mktdata=SPY)
tail(test, 50)

#signals
add.signal(strategy.st, name="sigThreshold",
           arguments=list(column="gap.gap", threshold=.5,
                          relationship="gt", cross=TRUE),
           label="shortEntry")

test <- applySignals(strategy.st, test)
tail(test,50)

#Add rules
#rules
add.rule(strategy.st, name="ruleSignal",
         arguments=list(sigcol="shortEntry",
                        sigval=TRUE,
                        ordertype="market",
                        orderside="short",
                        replace=FALSE,
                        osFUN=osDollarATR,
                        tradeSize=tradeSize,
                        prefer="Open",
                        pctATR=pctATR,
                        atrMod="X",
                        orderset="orders"),
         type="enter", path.dep=TRUE,
         label="gapEntry")

add.rule(strategy.st, name="ruleSignal",
         arguments=list(sigcol="shortEntry",
                        sigval=TRUE,
                        ordertype="limit",
                        orderside="short",
                        replace=FALSE,
                        orderqty='all',
                        order.price=quote(mktdata$TP.gap[timestamp]),
                        orderset="orders"),
         type="chain",
         parent="gapEntry",
         label="takeProfitShort",
         path.dep=TRUE)


#apply strategy
t1 <- Sys.time()
out <- applyStrategy(strategy=strategy.st,portfolios=portfolio.st)

Damon Verial
Office: (206) 395-3688
Skype: DamonVerial
LinkedIn: https://www.linkedin.com/profile/view?id=175736313
A Seasonal Healthcare Portfolio
<http://seekingalpha.com/article/3693506-a-seasonal-healthcare-portfolio-using-vht>
I purposely keep my emails to 5 sentences or fewer - which is a miracle for
a writer.
I do this to show that I respect both your time and mine.

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Tue Dec 15 13:39:06 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 15 Dec 2015 06:39:06 -0600
Subject: [R-SIG-Finance] Quantstrat code works for long position but not
 short position
In-Reply-To: <CA+3g=Dcapp5AEwwKQOkt9SMDU=8PQsc4WWFUzMMGUi1tax1R7A@mail.gmail.com>
References: <CA+3g=Dcapp5AEwwKQOkt9SMDU=8PQsc4WWFUzMMGUi1tax1R7A@mail.gmail.com>
Message-ID: <CAPPM_gRwt6e87MkFv3850ufaNLfnab6cZn0-hSeMDsV5kjjuaw@mail.gmail.com>

On Tue, Dec 15, 2015 at 2:51 AM, Damon Verial <verial.damon at gmail.com> wrote:
> So I have this code that works fine for long positions. However, when I
> reversed the code to make a short version, it breaks, giving me an error of:
>
> Error in osFUN(strategy = strategy, data = mktdata, timestamp = timestamp,
> :
>   ATR corresponding to atrX is invalid at this point in time.
>                Add a logical operator to account for this.
>
The error could be more informative ('at this point in time' should be
'for this timestamp', and it would be nice if the specific timestamp
were reported in the error), but it does give you hints about what's
wrong.  Look at your mktdata:

           atr.atrX gap.gap   TP.gap shortEntry
2015-01-02       NA       0       NA         NA
2015-01-05       NA       0       NA          0
2015-01-06       NA       0       NA          0
2015-01-07       NA       0       NA          0
2015-01-08       NA       1 199.8034          1
2015-01-09       NA       0 199.8034          0
2015-01-12       NA       0 199.8034          0
2015-01-13       NA       0 199.8034          0
2015-01-14       NA       0 199.8034          0
2015-01-15       NA       0 199.8034          0
2015-01-16       NA       0 199.8034          0
2015-01-20 3.465414       0 199.8034          0

Your first sell signal is on 2015-01-08, but atr.atrX is NA at that
point.  So the order sizing function doesn't know how to size that
sell order.

I think the "IKTrading-way" to fix this is to change your signals to:

#signals
add.signal(strategy.st, name="sigThreshold",
           arguments=list(column="gap.gap", threshold=.5,
                          relationship="gt", cross=TRUE),
           label="shortEntryRaw")

add.signal(strategy.st, name="sigAND",
           arguments=list(columns=c("atr.atrX","shortEntryRaw")),
           label="shortEntry")

Which will make 'shortEntry' NA if 'shortEntryRaw' is true before
atr.atrX is non-NA.

It might be more user-friendly if the osDollarATR function returned an
order size of zero, with a warning, if the ATR column it references is
NA.

> Why does this occur with the short position but not the long position? The
> code follows, for reference:
>
Thank you for the reproducible example.

> library("quantstrat")
> require(IKTrading)
>
> initDate<-startDate<-'2015-01-01'
> endDate<-'2015-12-09'
>
> rm(list = ls(.blotter), envir = .blotter)
> currency("USD")
> Sys.setenv(TZ = "UTC")
> symbols<-"SPY"
>
> strategy.st <- portfolio.st <- account.st <- "Gaps"
> getSymbols(symbols, src="yahoo",
> index.class=c("POSIXt","POSIXct"),from=startDate,
> to=endDate, adjust=T)
> stock(symbols,currency="USD",multiplier=1)
> tradeSize <- 100000
> initEq <- tradeSize*length(symbols)
>
> strategy.st <- portfolio.st <- account.st <- "Gaps"
> rm.strat(strategy.st)
> initPortf(portfolio.st, symbols=symbols, initDate=initDate, currency='USD')
> initAcct(account.st, portfolios=portfolio.st, initDate=initDate,
> currency='USD',initEq=initEq)
> initOrders(portfolio.st, initDate=initDate)
> strategy(strategy.st, store=TRUE)
>
You do not need to specify initDate in the calls to initPortf,
initAcct, and initOrders.  The defaults (1950-01-01, and 1997-12-31
for initOrders until recently) should be sufficient.  Specifying them
has the potential to cause errors that are hard for users to recognize
and fix, so you should only specify them if you know what you're doing
(or need them to be earlier than Jan-1950).

>
> period=10
> pctATR=.1
>
> ####################
> ## UP GAPS ##
> ####################
>
> #necessary functions
>
> gap <- function(x,k) {
>  low <- Lo(x)
>  high<- Hi(x)
>  yesHigh <- lag.xts(high,k=1)
>  gapDay <- low > yesHigh
>  gapDay[1] <- 0
>  gaps <- x[gapDay==1,]
>  gaps$takeProfit <- yesHigh[gapDay==1,]
>  gaps<-cbind(gapDay,gaps$takeProfit)
>  gaps$takeProfit<-na.locf(gaps$takeProfit)
>  colnames(gaps) <- c("gap","TP")
>  return(gaps)
> }
>
>
> period=10
> pctATR=.1
>
>
> #indicators
>
> add.indicator(strategy.st, name="lagATR",
>               arguments=list(HLC=quote(HLC(mktdata)),
>                              n=period),
>               label="atrX")
>
> add.indicator(strategy.st, name="gap",
>               arguments=list(x=quote(HLC(mktdata))),
>               label="gap")
>
>
> test <- applyIndicators(strategy.st, mktdata=SPY)
> tail(test, 50)
>
> #signals
> add.signal(strategy.st, name="sigThreshold",
>            arguments=list(column="gap.gap", threshold=.5,
>                           relationship="gt", cross=TRUE),
>            label="shortEntry")
>
> test <- applySignals(strategy.st, test)
> tail(test,50)
>
> #Add rules
> #rules
> add.rule(strategy.st, name="ruleSignal",
>          arguments=list(sigcol="shortEntry",
>                         sigval=TRUE,
>                         ordertype="market",
>                         orderside="short",
>                         replace=FALSE,
>                         osFUN=osDollarATR,
>                         tradeSize=tradeSize,
>                         prefer="Open",
>                         pctATR=pctATR,
>                         atrMod="X",
>                         orderset="orders"),
>          type="enter", path.dep=TRUE,
>          label="gapEntry")
>
> add.rule(strategy.st, name="ruleSignal",
>          arguments=list(sigcol="shortEntry",
>                         sigval=TRUE,
>                         ordertype="limit",
>                         orderside="short",
>                         replace=FALSE,
>                         orderqty='all',
>                         order.price=quote(mktdata$TP.gap[timestamp]),
>                         orderset="orders"),
>          type="chain",
>          parent="gapEntry",
>          label="takeProfitShort",
>          path.dep=TRUE)
>
>
> #apply strategy
> t1 <- Sys.time()
> out <- applyStrategy(strategy=strategy.st,portfolios=portfolio.st)
>
> Damon Verial
> Office: (206) 395-3688
> Skype: DamonVerial
> LinkedIn: https://www.linkedin.com/profile/view?id=175736313
> A Seasonal Healthcare Portfolio
> <http://seekingalpha.com/article/3693506-a-seasonal-healthcare-portfolio-using-vht>
> I purposely keep my emails to 5 sentences or fewer - which is a miracle for
> a writer.
> I do this to show that I respect both your time and mine.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From pgilbert902 at gmail.com  Tue Dec 15 15:57:44 2015
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Tue, 15 Dec 2015 09:57:44 -0500
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
In-Reply-To: <CAAmySGN3RTee9puDqURXvXE3ndWx4=wTuyRhhq6W_mjGpYOkVQ@mail.gmail.com>
References: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGMXqikXMhO7r7Ofz8E1C2nD0O5YjNr_9ua9NT7O8RVbbQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9E@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGN3RTee9puDqURXvXE3ndWx4=wTuyRhhq6W_mjGpYOkVQ@mail.gmail.com>
Message-ID: <56702A68.8010304@gmail.com>

I have not been paying close attention and I've missed something in this 
thread, but ...

I think the hessian in the optimization will be the second derivative of 
this function

 >>>>opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}

WRT  wgt.vect. If there are zero elements in Ret.vect then that hessian 
will be singular. And if there are orders of magnitude difference 
between the largest and smallest elements in Ret.vect then the hessian 
will be ill-conditioned.

The ill-conditioned case is a numerical problem and you might solve it 
with a different algorithm, or by better scaling. The zero case is a 
theoretical problem, there is not a unique optimal point but rather 
whole continuum of optimal points (your parameters corresponding to the 
zero elements will not make any difference in the function value).

HTH,
Paul

On 12/14/2015 11:39 PM, Michael Weylandt wrote:
> (+list -- I'm not a numerical linear algebra expert or portfolio
> optimization expert, but there are a number on this list who might
> chime in)
>
> That is quite high, and almost certainly problematic.
>
> I'm not sure what an acceptable bound is (will depend on your solver),
> but that's almost certainly above it for any algorithm which will
> require inverting cov.mat.
>
> Two things you could try:
> - use a different (non-Hessian-using) optimization algorithm;
> - use some form of shrinkage/regularization (Ledoit-Wolf is a common
> choice) to tame your covariance matrix.
>
> Michael
>
> On Mon, Dec 14, 2015 at 10:10 PM, Michael Ashton
> <m.ashton at enduringinvestments.com> wrote:
>> Well, not sure whether this makes any sense but kappa(cov.mat) gives me 11148245007.
>>
>> That seems large. But I am not sure what it is supposed to be.
>>
>> -----Original Message-----
>> From: Michael Weylandt [mailto:michael.weylandt at gmail.com]
>> Sent: Monday, December 14, 2015 9:29 PM
>> To: Michael Ashton
>> Cc: r-sig-finance at r-project.org
>> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
>>
>> What's the condition number of your correlation/covariance matrix? (?kappa)
>>
>> I think I've used quadprog for portfolio optimization with success, but it's been a while.
>>
>> MW
>>
>> On Mon, Dec 14, 2015 at 8:06 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
>>> Do you have a suggestion for such? I have in the past tried fPortfolio, but it would not allow me to specify my own projected return vectors rather than the historical returns of the series (which is exactly backwards).
>>>
>>> As for whether the matrix is comfortably non-singular...I suppose it depends in a Clintonian way on the meaning of "comfortably," but I can create a Cholesky decomposition without it blowing up, which is usually how I can tell if I have done something stupid. Well, stupider than normal.
>>>
>>> -----Original Message-----
>>> From: Michael Weylandt [mailto:michael.weylandt at gmail.com]
>>> Sent: Monday, December 14, 2015 8:32 PM
>>> To: Michael Ashton
>>> Cc: r-sig-finance at r-project.org
>>> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
>>>
>>> The Hessian is the matrix of second derivatives
>>> (https://en.wikipedia.org/wiki/Hessian_matrix) -- in scalar terms, you're finding a point where the second derivative is zero and then trying to divide by the second derivative to calculate the step size.
>>>
>>> I haven't gone through your code in any detail, but I'd start by checking the covariance matrix since that's proportional to the Hessian of your objective function. Is it (comfortably) non-singular?
>>>
>>> Since you're just solving the standard Markowitz problem, you might try a simpler (quadratic/convex) solver instead of a general non-linear solver. Should behave a bit better.
>>>
>>> Michael
>>>
>>>
>>> On Mon, Dec 14, 2015 at 6:13 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
>>>> I must admit to being flummoxed here, mainly because my linear algebra was 25 years ago and I can't remember what a Hessian is.
>>>>
>>>> I have a matrix of 60 securities' weekly returns, along with 60 projected returns. The returns are in a vector called Ret.vect and the covariance matrix of weekly returns in cov.mat . I have the minConstraints and maxConstraints that the parameters are permitted to take. I cycle through targeted risks and get the same error for each risk targeted...below I have removed the loop to focus on the risk=0.002.
>>>>
>>>> wgt.vect=c(rep(1/60, 60))
>>>> constr.fun <- function(wgt.vect) {;
>>>>                  c1 = sqrt(crossprod(t(wgt.vect %*% cov.mat),wgt.vect));
>>>>                  c2 = sum(wgt.vect);
>>>>                  return(c(c1,c2));
>>>>                  }
>>>> ineqconstr.fun <- function(wgt.vect) {
>>>>                  wgt.vect[1:60];
>>>>                  }
>>>> opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}
>>>>
>>>> OptimSolution <-
>>>> solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ineqL
>>>> B
>>>> =minConstraints,ineqUB=maxConstraints)
>>>>
>>>> I get the following error:
>>>> solnp--> Solution not reliable....Problem Inverting Hessian.
>>>>
>>>> Well, that doesn't tell me very much! The parameters (weights) that are output for each run, as I cycle through the weights, are very scrambled...lots of little allocations, rather than clumping as you would expect to happen especially at the risky and riskless ends of the spectrum.
>>>>
>>>> Can anyone with more math than me give me a helping hand on the Hessian?
>>>>
>>>> Thanks,
>>>>
>>>>
>>>> Mike
>>>>
>>>> Michael Ashton, CFA
>>>> Managing Principal
>>>>
>>>> Enduring Investments LLC
>>>> W: 973.457.4602
>>>> C: 551.655.8006
>>>>
>>>>
>>>> ________________________________
>>>> This email and any attachments are confidential and
>>>> inte...{{dropped:9}}
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions should go.
>>>
>>> This email and any attachments are confidential and intended only for the recipient noted above. You are hereby notified that any use, printing, copying or disclosure is strictly prohibited without the permission of Enduring Investments LLC. For further information please contact: Management at EnduringInvestments.com; (973) 457-4602.
>>
>> This email and any attachments are confidential and in...{{dropped:6}}
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From m.ashton at enduringinvestments.com  Tue Dec 15 16:17:48 2015
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Tue, 15 Dec 2015 07:17:48 -0800
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
In-Reply-To: <56702A68.8010304@gmail.com>
References: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGMXqikXMhO7r7Ofz8E1C2nD0O5YjNr_9ua9NT7O8RVbbQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9E@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGN3RTee9puDqURXvXE3ndWx4=wTuyRhhq6W_mjGpYOkVQ@mail.gmail.com>
	<56702A68.8010304@gmail.com>
Message-ID: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10AB6@EXVMBX018-3.exch018.msoutlookonline.net>

That is very interesting. Actually some of the projected returns are negative, some are very close to zero. None is exactly zero, which I guess is why it's not singular, but that's why it's ill-conditioned. Very interesting. And hard to solve...if I add 5% to all returns will I still get the same portfolio? Seems to me intuitively I shouldn't since the proportional risk/return tradeoff then is greater for the assets on the low end of the spectrum, but I might be wrong.

-----Original Message-----
From: Paul Gilbert [mailto:pgilbert902 at gmail.com]
Sent: Tuesday, December 15, 2015 9:58 AM
To: Michael Ashton
Cc: Michael Weylandt; r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian

I have not been paying close attention and I've missed something in this thread, but ...

I think the hessian in the optimization will be the second derivative of this function

 >>>>opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}

WRT  wgt.vect. If there are zero elements in Ret.vect then that hessian will be singular. And if there are orders of magnitude difference between the largest and smallest elements in Ret.vect then the hessian will be ill-conditioned.

The ill-conditioned case is a numerical problem and you might solve it with a different algorithm, or by better scaling. The zero case is a theoretical problem, there is not a unique optimal point but rather whole continuum of optimal points (your parameters corresponding to the zero elements will not make any difference in the function value).

HTH,
Paul

On 12/14/2015 11:39 PM, Michael Weylandt wrote:
> (+list -- I'm not a numerical linear algebra expert or portfolio
> optimization expert, but there are a number on this list who might
> chime in)
>
> That is quite high, and almost certainly problematic.
>
> I'm not sure what an acceptable bound is (will depend on your solver),
> but that's almost certainly above it for any algorithm which will
> require inverting cov.mat.
>
> Two things you could try:
> - use a different (non-Hessian-using) optimization algorithm;
> - use some form of shrinkage/regularization (Ledoit-Wolf is a common
> choice) to tame your covariance matrix.
>
> Michael
>
> On Mon, Dec 14, 2015 at 10:10 PM, Michael Ashton
> <m.ashton at enduringinvestments.com> wrote:
>> Well, not sure whether this makes any sense but kappa(cov.mat) gives me 11148245007.
>>
>> That seems large. But I am not sure what it is supposed to be.
>>
>> -----Original Message-----
>> From: Michael Weylandt [mailto:michael.weylandt at gmail.com]
>> Sent: Monday, December 14, 2015 9:29 PM
>> To: Michael Ashton
>> Cc: r-sig-finance at r-project.org
>> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
>>
>> What's the condition number of your correlation/covariance matrix?
>> (?kappa)
>>
>> I think I've used quadprog for portfolio optimization with success, but it's been a while.
>>
>> MW
>>
>> On Mon, Dec 14, 2015 at 8:06 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
>>> Do you have a suggestion for such? I have in the past tried fPortfolio, but it would not allow me to specify my own projected return vectors rather than the historical returns of the series (which is exactly backwards).
>>>
>>> As for whether the matrix is comfortably non-singular...I suppose it depends in a Clintonian way on the meaning of "comfortably," but I can create a Cholesky decomposition without it blowing up, which is usually how I can tell if I have done something stupid. Well, stupider than normal.
>>>
>>> -----Original Message-----
>>> From: Michael Weylandt [mailto:michael.weylandt at gmail.com]
>>> Sent: Monday, December 14, 2015 8:32 PM
>>> To: Michael Ashton
>>> Cc: r-sig-finance at r-project.org
>>> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
>>>
>>> The Hessian is the matrix of second derivatives
>>> (https://en.wikipedia.org/wiki/Hessian_matrix) -- in scalar terms, you're finding a point where the second derivative is zero and then trying to divide by the second derivative to calculate the step size.
>>>
>>> I haven't gone through your code in any detail, but I'd start by checking the covariance matrix since that's proportional to the Hessian of your objective function. Is it (comfortably) non-singular?
>>>
>>> Since you're just solving the standard Markowitz problem, you might try a simpler (quadratic/convex) solver instead of a general non-linear solver. Should behave a bit better.
>>>
>>> Michael
>>>
>>>
>>> On Mon, Dec 14, 2015 at 6:13 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
>>>> I must admit to being flummoxed here, mainly because my linear algebra was 25 years ago and I can't remember what a Hessian is.
>>>>
>>>> I have a matrix of 60 securities' weekly returns, along with 60 projected returns. The returns are in a vector called Ret.vect and the covariance matrix of weekly returns in cov.mat . I have the minConstraints and maxConstraints that the parameters are permitted to take. I cycle through targeted risks and get the same error for each risk targeted...below I have removed the loop to focus on the risk=0.002.
>>>>
>>>> wgt.vect=c(rep(1/60, 60))
>>>> constr.fun <- function(wgt.vect) {;
>>>>                  c1 = sqrt(crossprod(t(wgt.vect %*% cov.mat),wgt.vect));
>>>>                  c2 = sum(wgt.vect);
>>>>                  return(c(c1,c2));
>>>>                  }
>>>> ineqconstr.fun <- function(wgt.vect) {
>>>>                  wgt.vect[1:60];
>>>>                  }
>>>> opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}
>>>>
>>>> OptimSolution <-
>>>> solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ine
>>>> qL
>>>> B
>>>> =minConstraints,ineqUB=maxConstraints)
>>>>
>>>> I get the following error:
>>>> solnp--> Solution not reliable....Problem Inverting Hessian.
>>>>
>>>> Well, that doesn't tell me very much! The parameters (weights) that are output for each run, as I cycle through the weights, are very scrambled...lots of little allocations, rather than clumping as you would expect to happen especially at the risky and riskless ends of the spectrum.
>>>>
>>>> Can anyone with more math than me give me a helping hand on the Hessian?
>>>>
>>>> Thanks,
>>>>
>>>>
>>>> Mike
>>>>
>>>> Michael Ashton, CFA
>>>> Managing Principal
>>>>
>>>> Enduring Investments LLC
>>>> W: 973.457.4602
>>>> C: 551.655.8006
>>>>
>>>>
>>>> ________________________________
>>>> This email and any attachments are confidential and
>>>> inte...{{dropped:9}}
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions should go.
>>>
>>> This email and any attachments are confidential and intended only for the recipient noted above. You are hereby notified that any use, printing, copying or disclosure is strictly prohibited without the permission of Enduring Investments LLC. For further information please contact: Management at EnduringInvestments.com; (973) 457-4602.
>>
>> This email and any attachments are confidential and
>> in...{{dropped:6}}
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>

This email and any attachments are confidential and inte...{{dropped:6}}


From thomas.fuller at coherentlogic.com  Tue Dec 15 16:25:54 2015
From: thomas.fuller at coherentlogic.com (Thomas Fuller)
Date: Tue, 15 Dec 2015 10:25:54 -0500
Subject: [R-SIG-Finance] CUSIP Data in R
Message-ID: <CAM0JZ3=syOBQ9FBD13g3viKoh3UX_C1HL2PfwGx9iCpC+vEzMg@mail.gmail.com>

Hi Folks,

Development has officially started on the *Coherent Data Adapter*: *CUSIP
Global Services Web Edition* package -- see here
<https://coherentlogic.com/middleware-development/coherent-data-adapter-cusip-global-services-web-edition/>
.

This package utilizes CUSIP Global Services <https://www.cusip.com/> web
services to access the entire universe of CUSIP identifiers for corporate,
municipal, government and mortgage-backed issues, and private placements.
The CUSIP Global Services database contains issuer and issue identifiers,
standardized descriptions and related data for more than 9.1 million unique
financial instruments.

Please get in touch if you would like to use this package.

Questions and comments are welcomed.

Tom

	[[alternative HTML version deleted]]


From pgilbert902 at gmail.com  Tue Dec 15 16:42:45 2015
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Tue, 15 Dec 2015 10:42:45 -0500
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
In-Reply-To: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10AB6@EXVMBX018-3.exch018.msoutlookonline.net>
References: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGMXqikXMhO7r7Ofz8E1C2nD0O5YjNr_9ua9NT7O8RVbbQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9E@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGN3RTee9puDqURXvXE3ndWx4=wTuyRhhq6W_mjGpYOkVQ@mail.gmail.com>
	<56702A68.8010304@gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10AB6@EXVMBX018-3.exch018.msoutlookonline.net>
Message-ID: <567034F5.7090909@gmail.com>

Just to be clear, when I said "difference between the largest and 
smallest elements" I am think of the absolute value. It is the scale not 
the sign that causes problems in optimization. And I cannot commenting 
on whether you have the correct objective function, just pointing out 
what would happen numerically with the one you specified.

Paul

On 12/15/2015 10:17 AM, Michael Ashton wrote:
> That is very interesting. Actually some of the projected returns are
> negative, some are very close to zero. None is exactly zero, which I
> guess is why it's not singular, but that's why it's ill-conditioned.
> Very interesting. And hard to solve...if I add 5% to all returns will
> I still get the same portfolio? Seems to me intuitively I shouldn't
> since the proportional risk/return tradeoff then is greater for the
> assets on the low end of the spectrum, but I might be wrong.
>
> -----Original Message----- From: Paul Gilbert
> [mailto:pgilbert902 at gmail.com] Sent: Tuesday, December 15, 2015 9:58
> AM To: Michael Ashton Cc: Michael Weylandt;
> r-sig-finance at r-project.org Subject: Re: [R-SIG-Finance] solnp
> Problem Inverting Hessian
>
> I have not been paying close attention and I've missed something in
> this thread, but ...
>
> I think the hessian in the optimization will be the second derivative
> of this function
>
>>>>> opt.fun <- function(wgt.vect)
>>>>> {-crossprod(wgt.vect,t(Ret.vect))}
>
> WRT  wgt.vect. If there are zero elements in Ret.vect then that
> hessian will be singular. And if there are orders of magnitude
> difference between the largest and smallest elements in Ret.vect then
> the hessian will be ill-conditioned.
>
> The ill-conditioned case is a numerical problem and you might solve
> it with a different algorithm, or by better scaling. The zero case is
> a theoretical problem, there is not a unique optimal point but rather
> whole continuum of optimal points (your parameters corresponding to
> the zero elements will not make any difference in the function
> value).
>
> HTH, Paul
>
> On 12/14/2015 11:39 PM, Michael Weylandt wrote:
>> (+list -- I'm not a numerical linear algebra expert or portfolio
>> optimization expert, but there are a number on this list who might
>> chime in)
>>
>> That is quite high, and almost certainly problematic.
>>
>> I'm not sure what an acceptable bound is (will depend on your
>> solver), but that's almost certainly above it for any algorithm
>> which will require inverting cov.mat.
>>
>> Two things you could try: - use a different (non-Hessian-using)
>> optimization algorithm; - use some form of shrinkage/regularization
>> (Ledoit-Wolf is a common choice) to tame your covariance matrix.
>>
>> Michael
>>
>> On Mon, Dec 14, 2015 at 10:10 PM, Michael Ashton
>> <m.ashton at enduringinvestments.com> wrote:
>>> Well, not sure whether this makes any sense but kappa(cov.mat)
>>> gives me 11148245007.
>>>
>>> That seems large. But I am not sure what it is supposed to be.
>>>
>>> -----Original Message----- From: Michael Weylandt
>>> [mailto:michael.weylandt at gmail.com] Sent: Monday, December 14,
>>> 2015 9:29 PM To: Michael Ashton Cc: r-sig-finance at r-project.org
>>> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
>>>
>>> What's the condition number of your correlation/covariance
>>> matrix? (?kappa)
>>>
>>> I think I've used quadprog for portfolio optimization with
>>> success, but it's been a while.
>>>
>>> MW
>>>
>>> On Mon, Dec 14, 2015 at 8:06 PM, Michael Ashton
>>> <m.ashton at enduringinvestments.com> wrote:
>>>> Do you have a suggestion for such? I have in the past tried
>>>> fPortfolio, but it would not allow me to specify my own
>>>> projected return vectors rather than the historical returns of
>>>> the series (which is exactly backwards).
>>>>
>>>> As for whether the matrix is comfortably non-singular...I
>>>> suppose it depends in a Clintonian way on the meaning of
>>>> "comfortably," but I can create a Cholesky decomposition
>>>> without it blowing up, which is usually how I can tell if I
>>>> have done something stupid. Well, stupider than normal.
>>>>
>>>> -----Original Message----- From: Michael Weylandt
>>>> [mailto:michael.weylandt at gmail.com] Sent: Monday, December 14,
>>>> 2015 8:32 PM To: Michael Ashton Cc:
>>>> r-sig-finance at r-project.org Subject: Re: [R-SIG-Finance] solnp
>>>> Problem Inverting Hessian
>>>>
>>>> The Hessian is the matrix of second derivatives
>>>> (https://en.wikipedia.org/wiki/Hessian_matrix) -- in scalar
>>>> terms, you're finding a point where the second derivative is
>>>> zero and then trying to divide by the second derivative to
>>>> calculate the step size.
>>>>
>>>> I haven't gone through your code in any detail, but I'd start
>>>> by checking the covariance matrix since that's proportional to
>>>> the Hessian of your objective function. Is it (comfortably)
>>>> non-singular?
>>>>
>>>> Since you're just solving the standard Markowitz problem, you
>>>> might try a simpler (quadratic/convex) solver instead of a
>>>> general non-linear solver. Should behave a bit better.
>>>>
>>>> Michael
>>>>
>>>>
>>>> On Mon, Dec 14, 2015 at 6:13 PM, Michael Ashton
>>>> <m.ashton at enduringinvestments.com> wrote:
>>>>> I must admit to being flummoxed here, mainly because my
>>>>> linear algebra was 25 years ago and I can't remember what a
>>>>> Hessian is.
>>>>>
>>>>> I have a matrix of 60 securities' weekly returns, along with
>>>>> 60 projected returns. The returns are in a vector called
>>>>> Ret.vect and the covariance matrix of weekly returns in
>>>>> cov.mat . I have the minConstraints and maxConstraints that
>>>>> the parameters are permitted to take. I cycle through
>>>>> targeted risks and get the same error for each risk
>>>>> targeted...below I have removed the loop to focus on the
>>>>> risk=0.002.
>>>>>
>>>>> wgt.vect=c(rep(1/60, 60)) constr.fun <- function(wgt.vect)
>>>>> {; c1 = sqrt(crossprod(t(wgt.vect %*% cov.mat),wgt.vect)); c2
>>>>> = sum(wgt.vect); return(c(c1,c2)); } ineqconstr.fun <-
>>>>> function(wgt.vect) { wgt.vect[1:60]; } opt.fun <-
>>>>> function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}
>>>>>
>>>>> OptimSolution <-
>>>>> solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ine
>>>>>
>>>>>
qL
>>>>> B =minConstraints,ineqUB=maxConstraints)
>>>>>
>>>>> I get the following error: solnp--> Solution not
>>>>> reliable....Problem Inverting Hessian.
>>>>>
>>>>> Well, that doesn't tell me very much! The parameters
>>>>> (weights) that are output for each run, as I cycle through
>>>>> the weights, are very scrambled...lots of little allocations,
>>>>> rather than clumping as you would expect to happen especially
>>>>> at the risky and riskless ends of the spectrum.
>>>>>
>>>>> Can anyone with more math than me give me a helping hand on
>>>>> the Hessian?
>>>>>
>>>>> Thanks,
>>>>>
>>>>>
>>>>> Mike
>>>>>
>>>>> Michael Ashton, CFA Managing Principal
>>>>>
>>>>> Enduring Investments LLC W: 973.457.4602 C: 551.655.8006
>>>>>
>>>>>
>>>>> ________________________________ This email and any
>>>>> attachments are confidential and inte...{{dropped:9}}
>>>>>
>>>>> _______________________________________________
>>>>> R-SIG-Finance at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance --
>>>>> Subscriber-posting only. If you want to post, subscribe
>>>>> first. -- Also note that this is not the r-help list where
>>>>> general R questions should go.
>>>>
>>>> This email and any attachments are confidential and intended
>>>> only for the recipient noted above. You are hereby notified
>>>> that any use, printing, copying or disclosure is strictly
>>>> prohibited without the permission of Enduring Investments LLC.
>>>> For further information please contact:
>>>> Management at EnduringInvestments.com; (973) 457-4602.
>>>
>>> This email and any attachments are confidential and
>>> in...{{dropped:6}}
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance --
>> Subscriber-posting only. If you want to post, subscribe first. --
>> Also note that this is not the r-help list where general R
>> questions should go.
>>
>
> This email and any attachments are confidential and in...{{dropped:7}}


From m.ashton at enduringinvestments.com  Tue Dec 15 16:45:42 2015
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Tue, 15 Dec 2015 07:45:42 -0800
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
In-Reply-To: <567034F5.7090909@gmail.com>
References: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGMXqikXMhO7r7Ofz8E1C2nD0O5YjNr_9ua9NT7O8RVbbQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9E@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGN3RTee9puDqURXvXE3ndWx4=wTuyRhhq6W_mjGpYOkVQ@mail.gmail.com>
	<56702A68.8010304@gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10AB6@EXVMBX018-3.exch018.msoutlookonline.net>
	<567034F5.7090909@gmail.com>
Message-ID: <3A100961-A8BC-4C8A-85BF-A73C1BCCFE5B@enduringinvestments.com>

Understood. I was just noting that Ret.vect spans zero, and thus some projected returns will always be pretty close to zero.

> On Dec 15, 2015, at 10:43 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>
> Just to be clear, when I said "difference between the largest and
> smallest elements" I am think of the absolute value. It is the scale not
> the sign that causes problems in optimization. And I cannot commenting
> on whether you have the correct objective function, just pointing out
> what would happen numerically with the one you specified.
>
> Paul
>
>> On 12/15/2015 10:17 AM, Michael Ashton wrote:
>> That is very interesting. Actually some of the projected returns are
>> negative, some are very close to zero. None is exactly zero, which I
>> guess is why it's not singular, but that's why it's ill-conditioned.
>> Very interesting. And hard to solve...if I add 5% to all returns will
>> I still get the same portfolio? Seems to me intuitively I shouldn't
>> since the proportional risk/return tradeoff then is greater for the
>> assets on the low end of the spectrum, but I might be wrong.
>>
>> -----Original Message----- From: Paul Gilbert
>> [mailto:pgilbert902 at gmail.com] Sent: Tuesday, December 15, 2015 9:58
>> AM To: Michael Ashton Cc: Michael Weylandt;
>> r-sig-finance at r-project.org Subject: Re: [R-SIG-Finance] solnp
>> Problem Inverting Hessian
>>
>> I have not been paying close attention and I've missed something in
>> this thread, but ...
>>
>> I think the hessian in the optimization will be the second derivative
>> of this function
>>
>>>>>> opt.fun <- function(wgt.vect)
>>>>>> {-crossprod(wgt.vect,t(Ret.vect))}
>>
>> WRT  wgt.vect. If there are zero elements in Ret.vect then that
>> hessian will be singular. And if there are orders of magnitude
>> difference between the largest and smallest elements in Ret.vect then
>> the hessian will be ill-conditioned.
>>
>> The ill-conditioned case is a numerical problem and you might solve
>> it with a different algorithm, or by better scaling. The zero case is
>> a theoretical problem, there is not a unique optimal point but rather
>> whole continuum of optimal points (your parameters corresponding to
>> the zero elements will not make any difference in the function
>> value).
>>
>> HTH, Paul
>>
>>> On 12/14/2015 11:39 PM, Michael Weylandt wrote:
>>> (+list -- I'm not a numerical linear algebra expert or portfolio
>>> optimization expert, but there are a number on this list who might
>>> chime in)
>>>
>>> That is quite high, and almost certainly problematic.
>>>
>>> I'm not sure what an acceptable bound is (will depend on your
>>> solver), but that's almost certainly above it for any algorithm
>>> which will require inverting cov.mat.
>>>
>>> Two things you could try: - use a different (non-Hessian-using)
>>> optimization algorithm; - use some form of shrinkage/regularization
>>> (Ledoit-Wolf is a common choice) to tame your covariance matrix.
>>>
>>> Michael
>>>
>>> On Mon, Dec 14, 2015 at 10:10 PM, Michael Ashton
>>> <m.ashton at enduringinvestments.com> wrote:
>>>> Well, not sure whether this makes any sense but kappa(cov.mat)
>>>> gives me 11148245007.
>>>>
>>>> That seems large. But I am not sure what it is supposed to be.
>>>>
>>>> -----Original Message----- From: Michael Weylandt
>>>> [mailto:michael.weylandt at gmail.com] Sent: Monday, December 14,
>>>> 2015 9:29 PM To: Michael Ashton Cc: r-sig-finance at r-project.org
>>>> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
>>>>
>>>> What's the condition number of your correlation/covariance
>>>> matrix? (?kappa)
>>>>
>>>> I think I've used quadprog for portfolio optimization with
>>>> success, but it's been a while.
>>>>
>>>> MW
>>>>
>>>> On Mon, Dec 14, 2015 at 8:06 PM, Michael Ashton
>>>> <m.ashton at enduringinvestments.com> wrote:
>>>>> Do you have a suggestion for such? I have in the past tried
>>>>> fPortfolio, but it would not allow me to specify my own
>>>>> projected return vectors rather than the historical returns of
>>>>> the series (which is exactly backwards).
>>>>>
>>>>> As for whether the matrix is comfortably non-singular...I
>>>>> suppose it depends in a Clintonian way on the meaning of
>>>>> "comfortably," but I can create a Cholesky decomposition
>>>>> without it blowing up, which is usually how I can tell if I
>>>>> have done something stupid. Well, stupider than normal.
>>>>>
>>>>> -----Original Message----- From: Michael Weylandt
>>>>> [mailto:michael.weylandt at gmail.com] Sent: Monday, December 14,
>>>>> 2015 8:32 PM To: Michael Ashton Cc:
>>>>> r-sig-finance at r-project.org Subject: Re: [R-SIG-Finance] solnp
>>>>> Problem Inverting Hessian
>>>>>
>>>>> The Hessian is the matrix of second derivatives
>>>>> (https://en.wikipedia.org/wiki/Hessian_matrix) -- in scalar
>>>>> terms, you're finding a point where the second derivative is
>>>>> zero and then trying to divide by the second derivative to
>>>>> calculate the step size.
>>>>>
>>>>> I haven't gone through your code in any detail, but I'd start
>>>>> by checking the covariance matrix since that's proportional to
>>>>> the Hessian of your objective function. Is it (comfortably)
>>>>> non-singular?
>>>>>
>>>>> Since you're just solving the standard Markowitz problem, you
>>>>> might try a simpler (quadratic/convex) solver instead of a
>>>>> general non-linear solver. Should behave a bit better.
>>>>>
>>>>> Michael
>>>>>
>>>>>
>>>>> On Mon, Dec 14, 2015 at 6:13 PM, Michael Ashton
>>>>> <m.ashton at enduringinvestments.com> wrote:
>>>>>> I must admit to being flummoxed here, mainly because my
>>>>>> linear algebra was 25 years ago and I can't remember what a
>>>>>> Hessian is.
>>>>>>
>>>>>> I have a matrix of 60 securities' weekly returns, along with
>>>>>> 60 projected returns. The returns are in a vector called
>>>>>> Ret.vect and the covariance matrix of weekly returns in
>>>>>> cov.mat . I have the minConstraints and maxConstraints that
>>>>>> the parameters are permitted to take. I cycle through
>>>>>> targeted risks and get the same error for each risk
>>>>>> targeted...below I have removed the loop to focus on the
>>>>>> risk=0.002.
>>>>>>
>>>>>> wgt.vect=c(rep(1/60, 60)) constr.fun <- function(wgt.vect)
>>>>>> {; c1 = sqrt(crossprod(t(wgt.vect %*% cov.mat),wgt.vect)); c2
>>>>>> = sum(wgt.vect); return(c(c1,c2)); } ineqconstr.fun <-
>>>>>> function(wgt.vect) { wgt.vect[1:60]; } opt.fun <-
>>>>>> function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}
>>>>>>
>>>>>> OptimSolution <-
>>>>>> solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ine
> qL
>>>>>> B =minConstraints,ineqUB=maxConstraints)
>>>>>>
>>>>>> I get the following error: solnp--> Solution not
>>>>>> reliable....Problem Inverting Hessian.
>>>>>>
>>>>>> Well, that doesn't tell me very much! The parameters
>>>>>> (weights) that are output for each run, as I cycle through
>>>>>> the weights, are very scrambled...lots of little allocations,
>>>>>> rather than clumping as you would expect to happen especially
>>>>>> at the risky and riskless ends of the spectrum.
>>>>>>
>>>>>> Can anyone with more math than me give me a helping hand on
>>>>>> the Hessian?
>>>>>>
>>>>>> Thanks,
>>>>>>
>>>>>>
>>>>>> Mike
>>>>>>
>>>>>> Michael Ashton, CFA Managing Principal
>>>>>>
>>>>>> Enduring Investments LLC W: 973.457.4602 C: 551.655.8006
>>>>>>
>>>>>>
>>>>>> ________________________________ This email and any
>>>>>> attachments are confidential and inte...{{dropped:9}}
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-SIG-Finance at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance --
>>>>>> Subscriber-posting only. If you want to post, subscribe
>>>>>> first. -- Also note that this is not the r-help list where
>>>>>> general R questions should go.
>>>>>
>>>>> This email and any attachments are confidential and intended
>>>>> only for the recipient noted above. You are hereby notified
>>>>> that any use, printing, copying or disclosure is strictly
>>>>> prohibited without the permission of Enduring Investments LLC.
>>>>> For further information please contact:
>>>>> Management at EnduringInvestments.com; (973) 457-4602.
>>>>
>>>> This email and any attachments are confidential and
>>>> in...{{dropped:6}}
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance --
>>> Subscriber-posting only. If you want to post, subscribe first. --
>>> Also note that this is not the r-help list where general R
>>> questions should go.
>>
>> This email and any attachments are confidential and intended only for
>> the recipient noted above. You are hereby notified that any use,
>> printing, copying or disclosure is strictly prohibited without the
>> permission of Enduring Investments LLC. For further information
>> please contact: Management at EnduringInvestments.com; (973) 457-4602.
>>

This email and any attachments are confidential and inte...{{dropped:6}}


From pgilbert902 at gmail.com  Tue Dec 15 19:09:54 2015
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Tue, 15 Dec 2015 13:09:54 -0500
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
In-Reply-To: <3A100961-A8BC-4C8A-85BF-A73C1BCCFE5B@enduringinvestments.com>
References: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGMXqikXMhO7r7Ofz8E1C2nD0O5YjNr_9ua9NT7O8RVbbQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9E@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGN3RTee9puDqURXvXE3ndWx4=wTuyRhhq6W_mjGpYOkVQ@mail.gmail.com>
	<56702A68.8010304@gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10AB6@EXVMBX018-3.exch018.msoutlookonline.net>
	<567034F5.7090909@gmail.com>
	<3A100961-A8BC-4C8A-85BF-A73C1BCCFE5B@enduringinvestments.com>
Message-ID: <56705772.5080506@gmail.com>

WRT scaling I should also add that, while it is almost always the right 
thing to do numerically, it does not always make sense in a particular 
application. One often does optimization in a situation where the 
parameters have different units, or have no units, so the scales are 
arbitrary to begin with and rescaling is numerically convenient. In 
application like yours, you may be summing things that are all in the 
same unit, dollars. Rescaling could mean some are in dollars and some in 
millions or billions of dollars. Theoretically, at the maximum of an 
unconstrained problem, scaling will not make any difference because the 
gradient will be zero in all directions. Practically, there is a 
difficulty that the numerical solution stops according to some rule when 
it gets "close enough". By rescaling you will be emphasizing the 
importance of parameters that really have no effect on the portfolio. It 
might be better to simply eliminate the parameters that have no 
contribution to the objective. (Take this all with a grain of salt, I 
don't know anything about portfolio optimization.)

Paul

On 12/15/2015 10:45 AM, Michael Ashton wrote:
> Understood. I was just noting that Ret.vect spans zero, and thus some
> projected returns will always be pretty close to zero.
>
>> On Dec 15, 2015, at 10:43 AM, Paul Gilbert <pgilbert902 at gmail.com>
>> wrote:
>>
>> Just to be clear, when I said "difference between the largest and
>> smallest elements" I am think of the absolute value. It is the
>> scale not the sign that causes problems in optimization. And I
>> cannot commenting on whether you have the correct objective
>> function, just pointing out what would happen numerically with the
>> one you specified.
>>
>> Paul
>>
>>> On 12/15/2015 10:17 AM, Michael Ashton wrote: That is very
>>> interesting. Actually some of the projected returns are negative,
>>> some are very close to zero. None is exactly zero, which I guess
>>> is why it's not singular, but that's why it's ill-conditioned.
>>> Very interesting. And hard to solve...if I add 5% to all returns
>>> will I still get the same portfolio? Seems to me intuitively I
>>> shouldn't since the proportional risk/return tradeoff then is
>>> greater for the assets on the low end of the spectrum, but I
>>> might be wrong.
>>>
>>> -----Original Message----- From: Paul Gilbert
>>> [mailto:pgilbert902 at gmail.com] Sent: Tuesday, December 15, 2015
>>> 9:58 AM To: Michael Ashton Cc: Michael Weylandt;
>>> r-sig-finance at r-project.org Subject: Re: [R-SIG-Finance] solnp
>>> Problem Inverting Hessian
>>>
>>> I have not been paying close attention and I've missed something
>>> in this thread, but ...
>>>
>>> I think the hessian in the optimization will be the second
>>> derivative of this function
>>>
>>>>>>> opt.fun <- function(wgt.vect)
>>>>>>> {-crossprod(wgt.vect,t(Ret.vect))}
>>>
>>> WRT  wgt.vect. If there are zero elements in Ret.vect then that
>>> hessian will be singular. And if there are orders of magnitude
>>> difference between the largest and smallest elements in Ret.vect
>>> then the hessian will be ill-conditioned.
>>>
>>> The ill-conditioned case is a numerical problem and you might
>>> solve it with a different algorithm, or by better scaling. The
>>> zero case is a theoretical problem, there is not a unique optimal
>>> point but rather whole continuum of optimal points (your
>>> parameters corresponding to the zero elements will not make any
>>> difference in the function value).
>>>
>>> HTH, Paul
>>>
>>>> On 12/14/2015 11:39 PM, Michael Weylandt wrote: (+list -- I'm
>>>> not a numerical linear algebra expert or portfolio optimization
>>>> expert, but there are a number on this list who might chime
>>>> in)
>>>>
>>>> That is quite high, and almost certainly problematic.
>>>>
>>>> I'm not sure what an acceptable bound is (will depend on your
>>>> solver), but that's almost certainly above it for any
>>>> algorithm which will require inverting cov.mat.
>>>>
>>>> Two things you could try: - use a different
>>>> (non-Hessian-using) optimization algorithm; - use some form of
>>>> shrinkage/regularization (Ledoit-Wolf is a common choice) to
>>>> tame your covariance matrix.
>>>>
>>>> Michael
>>>>
>>>> On Mon, Dec 14, 2015 at 10:10 PM, Michael Ashton
>>>> <m.ashton at enduringinvestments.com> wrote:
>>>>> Well, not sure whether this makes any sense but
>>>>> kappa(cov.mat) gives me 11148245007.
>>>>>
>>>>> That seems large. But I am not sure what it is supposed to
>>>>> be.
>>>>>
>>>>> -----Original Message----- From: Michael Weylandt
>>>>> [mailto:michael.weylandt at gmail.com] Sent: Monday, December
>>>>> 14, 2015 9:29 PM To: Michael Ashton Cc:
>>>>> r-sig-finance at r-project.org Subject: Re: [R-SIG-Finance]
>>>>> solnp Problem Inverting Hessian
>>>>>
>>>>> What's the condition number of your correlation/covariance
>>>>> matrix? (?kappa)
>>>>>
>>>>> I think I've used quadprog for portfolio optimization with
>>>>> success, but it's been a while.
>>>>>
>>>>> MW
>>>>>
>>>>> On Mon, Dec 14, 2015 at 8:06 PM, Michael Ashton
>>>>> <m.ashton at enduringinvestments.com> wrote:
>>>>>> Do you have a suggestion for such? I have in the past
>>>>>> tried fPortfolio, but it would not allow me to specify my
>>>>>> own projected return vectors rather than the historical
>>>>>> returns of the series (which is exactly backwards).
>>>>>>
>>>>>> As for whether the matrix is comfortably non-singular...I
>>>>>> suppose it depends in a Clintonian way on the meaning of
>>>>>> "comfortably," but I can create a Cholesky decomposition
>>>>>> without it blowing up, which is usually how I can tell if
>>>>>> I have done something stupid. Well, stupider than normal.
>>>>>>
>>>>>> -----Original Message----- From: Michael Weylandt
>>>>>> [mailto:michael.weylandt at gmail.com] Sent: Monday, December
>>>>>> 14, 2015 8:32 PM To: Michael Ashton Cc:
>>>>>> r-sig-finance at r-project.org Subject: Re: [R-SIG-Finance]
>>>>>> solnp Problem Inverting Hessian
>>>>>>
>>>>>> The Hessian is the matrix of second derivatives
>>>>>> (https://en.wikipedia.org/wiki/Hessian_matrix) -- in
>>>>>> scalar terms, you're finding a point where the second
>>>>>> derivative is zero and then trying to divide by the second
>>>>>> derivative to calculate the step size.
>>>>>>
>>>>>> I haven't gone through your code in any detail, but I'd
>>>>>> start by checking the covariance matrix since that's
>>>>>> proportional to the Hessian of your objective function. Is
>>>>>> it (comfortably) non-singular?
>>>>>>
>>>>>> Since you're just solving the standard Markowitz problem,
>>>>>> you might try a simpler (quadratic/convex) solver instead
>>>>>> of a general non-linear solver. Should behave a bit
>>>>>> better.
>>>>>>
>>>>>> Michael
>>>>>>
>>>>>>
>>>>>> On Mon, Dec 14, 2015 at 6:13 PM, Michael Ashton
>>>>>> <m.ashton at enduringinvestments.com> wrote:
>>>>>>> I must admit to being flummoxed here, mainly because my
>>>>>>> linear algebra was 25 years ago and I can't remember what
>>>>>>> a Hessian is.
>>>>>>>
>>>>>>> I have a matrix of 60 securities' weekly returns, along
>>>>>>> with 60 projected returns. The returns are in a vector
>>>>>>> called Ret.vect and the covariance matrix of weekly
>>>>>>> returns in cov.mat . I have the minConstraints and
>>>>>>> maxConstraints that the parameters are permitted to take.
>>>>>>> I cycle through targeted risks and get the same error for
>>>>>>> each risk targeted...below I have removed the loop to
>>>>>>> focus on the risk=0.002.
>>>>>>>
>>>>>>> wgt.vect=c(rep(1/60, 60)) constr.fun <-
>>>>>>> function(wgt.vect) {; c1 = sqrt(crossprod(t(wgt.vect %*%
>>>>>>> cov.mat),wgt.vect)); c2 = sum(wgt.vect);
>>>>>>> return(c(c1,c2)); } ineqconstr.fun <- function(wgt.vect)
>>>>>>> { wgt.vect[1:60]; } opt.fun <- function(wgt.vect)
>>>>>>> {-crossprod(wgt.vect,t(Ret.vect))}
>>>>>>>
>>>>>>> OptimSolution <-
>>>>>>> solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ine
>>
>>>>>>>
qL
>>>>>>> B =minConstraints,ineqUB=maxConstraints)
>>>>>>>
>>>>>>> I get the following error: solnp--> Solution not
>>>>>>> reliable....Problem Inverting Hessian.
>>>>>>>
>>>>>>> Well, that doesn't tell me very much! The parameters
>>>>>>> (weights) that are output for each run, as I cycle
>>>>>>> through the weights, are very scrambled...lots of little
>>>>>>> allocations, rather than clumping as you would expect to
>>>>>>> happen especially at the risky and riskless ends of the
>>>>>>> spectrum.
>>>>>>>
>>>>>>> Can anyone with more math than me give me a helping hand
>>>>>>> on the Hessian?
>>>>>>>
>>>>>>> Thanks,
>>>>>>>
>>>>>>>
>>>>>>> Mike
>>>>>>>
>>>>>>> Michael Ashton, CFA Managing Principal
>>>>>>>
>>>>>>> Enduring Investments LLC W: 973.457.4602 C: 551.655.8006
>>>>>>>
>>>>>>>
>>>>>>> ________________________________ This email and any
>>>>>>> attachments are confidential and inte...{{dropped:9}}
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-SIG-Finance at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance --
>>>>>>> Subscriber-posting only. If you want to post, subscribe
>>>>>>> first. -- Also note that this is not the r-help list
>>>>>>> where general R questions should go.
>>>>>>
>>>>>> This email and any attachments are confidential and
>>>>>> intended only for the recipient noted above. You are hereby
>>>>>> notified that any use, printing, copying or disclosure is
>>>>>> strictly prohibited without the permission of Enduring
>>>>>> Investments LLC. For further information please contact:
>>>>>> Management at EnduringInvestments.com; (973) 457-4602.
>>>>>
>>>>> This email and any attachments are confidential and
>>>>> in...{{dropped:6}}
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance --
>>>> Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R
>>>> questions should go.
>>>
>>> This email and any attachments are confidential and intended only
>>> for the recipient noted above. You are hereby notified that any
>>> use, printing, copying or disclosure is strictly prohibited
>>> without the permission of Enduring Investments LLC. For further
>>> information please contact: Management at EnduringInvestments.com;
>>> (973) 457-4602.
>>>
>
> This email and any attachments are confidential and in...{{dropped:7}}


From kk2250 at optonline.net  Wed Dec 16 00:16:35 2015
From: kk2250 at optonline.net (Krishna Kumar)
Date: Tue, 15 Dec 2015 18:16:35 -0500
Subject: [R-SIG-Finance] solnp Problem Inverting Hessian
In-Reply-To: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10AB6@EXVMBX018-3.exch018.msoutlookonline.net>
References: <E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9C@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGPpMNsbsZQ+sDtd+owdhG3c-j3mdBj_ywe21dT6FnoEfQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9D@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGMXqikXMhO7r7Ofz8E1C2nD0O5YjNr_9ua9NT7O8RVbbQ@mail.gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10A9E@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAAmySGN3RTee9puDqURXvXE3ndWx4=wTuyRhhq6W_mjGpYOkVQ@mail.gmail.com>
	<56702A68.8010304@gmail.com>
	<E30D0E7822EEB443A5B9CC8273D99C74C0FEC10AB6@EXVMBX018-3.exch018.msoutlookonline.net>
Message-ID: <F37F7E97-81A6-41D6-9311-1058D2F5DF46@optonline.net>

In addition to Paul's comments I have noticed with a large number of assets when the correlation matrix is hand cooked  (not estimated) it often could end up with small eigenvalues which are arbitrarily close to zero and hessian blows up this could well be the cause of the issue here. A minimum reproducible example would help diagnose your problem better.

----

> On Dec 15, 2015, at 10:17 AM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
> 
> That is very interesting. Actually some of the projected returns are negative, some are very close to zero. None is exactly zero, which I guess is why it's not singular, but that's why it's ill-conditioned. Very interesting. And hard to solve...if I add 5% to all returns will I still get the same portfolio? Seems to me intuitively I shouldn't since the proportional risk/return tradeoff then is greater for the assets on the low end of the spectrum, but I might be wrong.
> 
> -----Original Message-----
> From: Paul Gilbert [mailto:pgilbert902 at gmail.com]
> Sent: Tuesday, December 15, 2015 9:58 AM
> To: Michael Ashton
> Cc: Michael Weylandt; r-sig-finance at r-project.org
> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
> 
> I have not been paying close attention and I've missed something in this thread, but ...
> 
> I think the hessian in the optimization will be the second derivative of this function
> 
>>>>> opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}
> 
> WRT  wgt.vect. If there are zero elements in Ret.vect then that hessian will be singular. And if there are orders of magnitude difference between the largest and smallest elements in Ret.vect then the hessian will be ill-conditioned.
> 
> The ill-conditioned case is a numerical problem and you might solve it with a different algorithm, or by better scaling. The zero case is a theoretical problem, there is not a unique optimal point but rather whole continuum of optimal points (your parameters corresponding to the zero elements will not make any difference in the function value).
> 
> HTH,
> Paul
> 
>> On 12/14/2015 11:39 PM, Michael Weylandt wrote:
>> (+list -- I'm not a numerical linear algebra expert or portfolio
>> optimization expert, but there are a number on this list who might
>> chime in)
>> 
>> That is quite high, and almost certainly problematic.
>> 
>> I'm not sure what an acceptable bound is (will depend on your solver),
>> but that's almost certainly above it for any algorithm which will
>> require inverting cov.mat.
>> 
>> Two things you could try:
>> - use a different (non-Hessian-using) optimization algorithm;
>> - use some form of shrinkage/regularization (Ledoit-Wolf is a common
>> choice) to tame your covariance matrix.
>> 
>> Michael
>> 
>> On Mon, Dec 14, 2015 at 10:10 PM, Michael Ashton
>> <m.ashton at enduringinvestments.com> wrote:
>>> Well, not sure whether this makes any sense but kappa(cov.mat) gives me 11148245007.
>>> 
>>> That seems large. But I am not sure what it is supposed to be.
>>> 
>>> -----Original Message-----
>>> From: Michael Weylandt [mailto:michael.weylandt at gmail.com]
>>> Sent: Monday, December 14, 2015 9:29 PM
>>> To: Michael Ashton
>>> Cc: r-sig-finance at r-project.org
>>> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
>>> 
>>> What's the condition number of your correlation/covariance matrix?
>>> (?kappa)
>>> 
>>> I think I've used quadprog for portfolio optimization with success, but it's been a while.
>>> 
>>> MW
>>> 
>>>> On Mon, Dec 14, 2015 at 8:06 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
>>>> Do you have a suggestion for such? I have in the past tried fPortfolio, but it would not allow me to specify my own projected return vectors rather than the historical returns of the series (which is exactly backwards).
>>>> 
>>>> As for whether the matrix is comfortably non-singular...I suppose it depends in a Clintonian way on the meaning of "comfortably," but I can create a Cholesky decomposition without it blowing up, which is usually how I can tell if I have done something stupid. Well, stupider than normal.
>>>> 
>>>> -----Original Message-----
>>>> From: Michael Weylandt [mailto:michael.weylandt at gmail.com]
>>>> Sent: Monday, December 14, 2015 8:32 PM
>>>> To: Michael Ashton
>>>> Cc: r-sig-finance at r-project.org
>>>> Subject: Re: [R-SIG-Finance] solnp Problem Inverting Hessian
>>>> 
>>>> The Hessian is the matrix of second derivatives
>>>> (https://en.wikipedia.org/wiki/Hessian_matrix) -- in scalar terms, you're finding a point where the second derivative is zero and then trying to divide by the second derivative to calculate the step size.
>>>> 
>>>> I haven't gone through your code in any detail, but I'd start by checking the covariance matrix since that's proportional to the Hessian of your objective function. Is it (comfortably) non-singular?
>>>> 
>>>> Since you're just solving the standard Markowitz problem, you might try a simpler (quadratic/convex) solver instead of a general non-linear solver. Should behave a bit better.
>>>> 
>>>> Michael
>>>> 
>>>> 
>>>>> On Mon, Dec 14, 2015 at 6:13 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
>>>>> I must admit to being flummoxed here, mainly because my linear algebra was 25 years ago and I can't remember what a Hessian is.
>>>>> 
>>>>> I have a matrix of 60 securities' weekly returns, along with 60 projected returns. The returns are in a vector called Ret.vect and the covariance matrix of weekly returns in cov.mat . I have the minConstraints and maxConstraints that the parameters are permitted to take. I cycle through targeted risks and get the same error for each risk targeted...below I have removed the loop to focus on the risk=0.002.
>>>>> 
>>>>> wgt.vect=c(rep(1/60, 60))
>>>>> constr.fun <- function(wgt.vect) {;
>>>>>                 c1 = sqrt(crossprod(t(wgt.vect %*% cov.mat),wgt.vect));
>>>>>                 c2 = sum(wgt.vect);
>>>>>                 return(c(c1,c2));
>>>>>                 }
>>>>> ineqconstr.fun <- function(wgt.vect) {
>>>>>                 wgt.vect[1:60];
>>>>>                 }
>>>>> opt.fun <- function(wgt.vect) {-crossprod(wgt.vect,t(Ret.vect))}
>>>>> 
>>>>> OptimSolution <-
>>>>> solnp(wgt.vect,opt.fun,constr.fun,eqB=c(0.002,1),ineqconstr.fun,ine
>>>>> qL
>>>>> B
>>>>> =minConstraints,ineqUB=maxConstraints)
>>>>> 
>>>>> I get the following error:
>>>>> solnp--> Solution not reliable....Problem Inverting Hessian.
>>>>> 
>>>>> Well, that doesn't tell me very much! The parameters (weights) that are output for each run, as I cycle through the weights, are very scrambled...lots of little allocations, rather than clumping as you would expect to happen especially at the risky and riskless ends of the spectrum.
>>>>> 
>>>>> Can anyone with more math than me give me a helping hand on the Hessian?
>>>>> 
>>>>> Thanks,
>>>>> 
>>>>> 
>>>>> Mike
>>>>> 
>>>>> Michael Ashton, CFA
>>>>> Managing Principal
>>>>> 
>>>>> Enduring Investments LLC
>>>>> W: 973.457.4602
>>>>> C: 551.655.8006
>>>>> 
>>>>> 
>>>>> ________________________________
>>>>> This email and any attachments are confidential and
>>>>> inte...{{dropped:9}}
>>>>> 
>>>>> _______________________________________________
>>>>> R-SIG-Finance at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>> -- Also note that this is not the r-help list where general R questions should go.
>>>> 
>>>> This email and any attachments are confidential and intended only for the recipient noted above. You are hereby notified that any use, printing, copying or disclosure is strictly prohibited without the permission of Enduring Investments LLC. For further information please contact: Management at EnduringInvestments.com; (973) 457-4602.
>>> 
>>> This email and any attachments are confidential and
>>> in...{{dropped:6}}
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
> 
> This email and any attachments are confidential and in...{{dropped:8}}


From kw1958 at gmail.com  Fri Dec 18 17:06:36 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Fri, 18 Dec 2015 11:06:36 -0500
Subject: [R-SIG-Finance] LIBOR Yield Curve.
Message-ID: <E19EDD28-2353-4313-9F4A-BA4E9543A405@gmail.com>

Folks,

Recently I lost my access to LIBOR rates from a large financial institution.

I was able to retrieve the values on any given day in the following form:
(Note that I am using plain text here):

ISIN Bond Name, Maturity, Swap NYK
USD Swap 3m, 0.247, 0.372
USD Swap 6m, 0.493, 0.462
USD Swap 9m, 0.740, 0.549
USD Swap 1y, 1.000, 0.626
USD Swap 2y, 2.000, 0.939
USD Swap 3y, 3.000, 1.211
USD Swap 4y, 4.000, 1.430
USD Swap 5y, 5.000, 1.607
  ...
USD Swap 10y, 10.000, 2.158
USD Swap 11y, 11.000, 2.226
 ...
USD Swap 50y 50.000, 2.641

I have the following questions:
1) I looked at FRED data and I wonder if anyone can tell me what and why the differences between: 
       USD12MD156N (12-Month London Interbank Offered Rate (LIBOR), based on U.S. Dollar?) 
and 
       DSWP1 (1-Year Swap Rate)

For the date 2015-11-30 FRED has 0.9806 for USD12MD156N and 0.69 for DSWP1

2) Is there a reliable place to download LIBOR yield curve data?
3) I have been using the SmithWilson package. Note that at most I need the (closing) rates daily. Any better ideas?
4) It would be ideal if I could get GBP and EUR as well.

Thanks so much for your time,
Best,
KW


From armstrong.whit at gmail.com  Fri Dec 18 17:32:46 2015
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Fri, 18 Dec 2015 11:32:46 -0500
Subject: [R-SIG-Finance] LIBOR Yield Curve.
In-Reply-To: <E19EDD28-2353-4313-9F4A-BA4E9543A405@gmail.com>
References: <E19EDD28-2353-4313-9F4A-BA4E9543A405@gmail.com>
Message-ID: <CAMi=pg4KRJCt=4eZeTX481752_mm7Zx16SO6CHVRVb1r9qZ50A@mail.gmail.com>

I'm not sure what you consider 'reliable' but bbg is usually good enough.
 buy some icap or superD data if you want something high quality, or get it
directly from your brokers and take the weighted avg.

(just change the curve id below to use the USD libor curve, and you should
be all set)

warmstrong at krypton:~$ R
> library(Rblpapi)
> bds("YCGT0111
Index","CURVE_TENOR_RATES",overrides=c("CURVE_DATE"="20151218"))
   Ask Yield Bid Yield Last Update Mid Yield Tenor  Tenor Ticker
1      0.163     0.168  2015-12-18     0.165    1M 912796GX Govt
2      0.183     0.188  2015-12-18     0.186    3M 912796HG Govt
3      0.443     0.448  2015-12-18     0.446    6M 912796HX Govt
4      0.659     0.664  2015-12-18     0.661    1Y 912796HU Govt
5      0.960     0.964  2015-12-18     0.962    2Y 912828M7 Govt
6      1.279     1.282  2015-12-18     1.281    3Y 912828N2 Govt
7      1.529     1.537  2015-12-18     1.533    4Y 912828G6 Govt
8      1.676     1.678  2015-12-18     1.677    5Y 912828M9 Govt
9      1.872     1.875  2015-12-18     1.874    6Y 912828G5 Govt
10     2.005     2.007  2015-12-18     2.006    7Y 912828M8 Govt
11     2.069     2.073  2015-12-18     2.071    8Y 912828WE Govt
12     2.186     2.188  2015-12-18     2.187    9Y 912828G3 Govt
13     2.200     2.202  2015-12-18     2.201   10Y 912828M5 Govt
14     2.424     2.428  2015-12-18     2.426   15Y 912810FP Govt
15     2.557     2.559  2015-12-18     2.558   20Y 912810FT Govt
16     2.798     2.800  2015-12-18     2.799   25Y 912810QL Govt
17     2.916     2.917  2015-12-18     2.916   30Y 912810RP Govt


On Fri, Dec 18, 2015 at 11:06 AM, Keith S Weintraub <kw1958 at gmail.com>
wrote:

> Folks,
>
> Recently I lost my access to LIBOR rates from a large financial
> institution.
>
> I was able to retrieve the values on any given day in the following form:
> (Note that I am using plain text here):
>
> ISIN Bond Name, Maturity, Swap NYK
> USD Swap 3m, 0.247, 0.372
> USD Swap 6m, 0.493, 0.462
> USD Swap 9m, 0.740, 0.549
> USD Swap 1y, 1.000, 0.626
> USD Swap 2y, 2.000, 0.939
> USD Swap 3y, 3.000, 1.211
> USD Swap 4y, 4.000, 1.430
> USD Swap 5y, 5.000, 1.607
>   ...
> USD Swap 10y, 10.000, 2.158
> USD Swap 11y, 11.000, 2.226
>  ...
> USD Swap 50y 50.000, 2.641
>
> I have the following questions:
> 1) I looked at FRED data and I wonder if anyone can tell me what and why
> the differences between:
>        USD12MD156N (12-Month London Interbank Offered Rate (LIBOR), based
> on U.S. Dollar?)
> and
>        DSWP1 (1-Year Swap Rate)
>
> For the date 2015-11-30 FRED has 0.9806 for USD12MD156N and 0.69 for DSWP1
>
> 2) Is there a reliable place to download LIBOR yield curve data?
> 3) I have been using the SmithWilson package. Note that at most I need the
> (closing) rates daily. Any better ideas?
> 4) It would be ideal if I could get GBP and EUR as well.
>
> Thanks so much for your time,
> Best,
> KW
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.

	[[alternative HTML version deleted]]


From kw1958 at gmail.com  Fri Dec 18 17:59:56 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Fri, 18 Dec 2015 11:59:56 -0500
Subject: [R-SIG-Finance] LIBOR Yield Curve.
In-Reply-To: <CAMi=pg4KRJCt=4eZeTX481752_mm7Zx16SO6CHVRVb1r9qZ50A@mail.gmail.com>
References: <E19EDD28-2353-4313-9F4A-BA4E9543A405@gmail.com>
	<CAMi=pg4KRJCt=4eZeTX481752_mm7Zx16SO6CHVRVb1r9qZ50A@mail.gmail.com>
Message-ID: <528C117C-DF37-4FD6-847A-59DEE97040B0@gmail.com>

Wouldn?t I need a Bloomberg password/account/terminal?

In addition I got some errors just trying to install the software on my Mac.

Sorry that I did not mention that I was on a Mac.
---
KW

PS I was able to download the software on my Windows (via Parallels) but the command blpConnect() doesn?t work. Again I think it is because I don?t have Bloomberg. 





> On Dec 18, 2015, at 11:32 AM, Whit Armstrong <armstrong.whit at gmail.com> wrote:
> 
> I'm not sure what you consider 'reliable' but bbg is usually good enough.  buy some icap or superD data if you want something high quality, or get it directly from your brokers and take the weighted avg.
> 
> (just change the curve id below to use the USD libor curve, and you should be all set)
> 
> warmstrong at krypton:~$ R
> > library(Rblpapi)
> > bds("YCGT0111 Index","CURVE_TENOR_RATES",overrides=c("CURVE_DATE"="20151218"))
>    Ask Yield Bid Yield Last Update Mid Yield Tenor  Tenor Ticker
> 1      0.163     0.168  2015-12-18     0.165    1M 912796GX Govt
> 2      0.183     0.188  2015-12-18     0.186    3M 912796HG Govt
> 3      0.443     0.448  2015-12-18     0.446    6M 912796HX Govt
> 4      0.659     0.664  2015-12-18     0.661    1Y 912796HU Govt
> 5      0.960     0.964  2015-12-18     0.962    2Y 912828M7 Govt
> 6      1.279     1.282  2015-12-18     1.281    3Y 912828N2 Govt
> 7      1.529     1.537  2015-12-18     1.533    4Y 912828G6 Govt
> 8      1.676     1.678  2015-12-18     1.677    5Y 912828M9 Govt
> 9      1.872     1.875  2015-12-18     1.874    6Y 912828G5 Govt
> 10     2.005     2.007  2015-12-18     2.006    7Y 912828M8 Govt
> 11     2.069     2.073  2015-12-18     2.071    8Y 912828WE Govt
> 12     2.186     2.188  2015-12-18     2.187    9Y 912828G3 Govt
> 13     2.200     2.202  2015-12-18     2.201   10Y 912828M5 Govt
> 14     2.424     2.428  2015-12-18     2.426   15Y 912810FP Govt
> 15     2.557     2.559  2015-12-18     2.558   20Y 912810FT Govt
> 16     2.798     2.800  2015-12-18     2.799   25Y 912810QL Govt
> 17     2.916     2.917  2015-12-18     2.916   30Y 912810RP Govt
> 
> 
> On Fri, Dec 18, 2015 at 11:06 AM, Keith S Weintraub <kw1958 at gmail.com> wrote:
> Folks,
> 
> Recently I lost my access to LIBOR rates from a large financial institution.
> 
> I was able to retrieve the values on any given day in the following form:
> (Note that I am using plain text here):
> 
> ISIN Bond Name, Maturity, Swap NYK
> USD Swap 3m, 0.247, 0.372
> USD Swap 6m, 0.493, 0.462
> USD Swap 9m, 0.740, 0.549
> USD Swap 1y, 1.000, 0.626
> USD Swap 2y, 2.000, 0.939
> USD Swap 3y, 3.000, 1.211
> USD Swap 4y, 4.000, 1.430
> USD Swap 5y, 5.000, 1.607
>   ...
> USD Swap 10y, 10.000, 2.158
> USD Swap 11y, 11.000, 2.226
>  ...
> USD Swap 50y 50.000, 2.641
> 
> I have the following questions:
> 1) I looked at FRED data and I wonder if anyone can tell me what and why the differences between:
>        USD12MD156N (12-Month London Interbank Offered Rate (LIBOR), based on U.S. Dollar?)
> and
>        DSWP1 (1-Year Swap Rate)
> 
> For the date 2015-11-30 FRED has 0.9806 for USD12MD156N and 0.69 for DSWP1
> 
> 2) Is there a reliable place to download LIBOR yield curve data?
> 3) I have been using the SmithWilson package. Note that at most I need the (closing) rates daily. Any better ideas?
> 4) It would be ideal if I could get GBP and EUR as well.
> 
> Thanks so much for your time,
> Best,
> KW
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 


From matt at considine.net  Sat Dec 19 16:16:46 2015
From: matt at considine.net (Matt Considine)
Date: Sat, 19 Dec 2015 10:16:46 -0500
Subject: [R-SIG-Finance] LIBOR Yield Curve.
In-Reply-To: <mailman.8.1450522802.18613.r-sig-finance@r-project.org>
References: <mailman.8.1450522802.18613.r-sig-finance@r-project.org>
Message-ID: <567574DE.1060309@considine.net>

On 12/19/2015 6:00 AM, r-sig-finance-request at r-project.org wrote:
> LIBOR Yield Curve.
Here is a markdown file I use to print out a list of recent LIBOR 
rates.  The URL and code might be of help.  I recognize too that it may 
not be the most elegant/efficient, but it has worked for my ad hoc purposes
Matt

---
title: "LIBOR"
output: pdf_document
---

```{r echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library(Quandl)
library(quantmod)
library(XML)
library(lubridate)
library(xtable)

currentDate <- Sys.Date()
eopm <- currentDate - days(day(currentDate))
sopm <- currentDate - days(day(currentDate))
sopm <- sopm - days(day(sopm) - 1)
##for just latest date
##eopm <- currentDate
##sopm <- currentDate - days(day(currentDate))
LIBOR <- getSymbols(src="FRED",Symbols=c("USD1MTD156N","USD3MTD156N"))

all_webpage     <- 
'http://www.global-rates.com/interest-rates/libor/american-dollar/american-dollar.aspx'

all_web.table = readHTMLTable(all_webpage, header=T, which=14, 
stringsAsFactors=F)

all_data <- gsub("[^a-zA-Z0-9\\.\\ -]","",as.matrix(all_web.table[,]))
colnames(all_data) <- c("data",colnames(all_data[,2:ncol(all_data)]))
all_dates <- as.Date(colnames(all_data[,2:ncol(all_data)]), "%m-%d-%Y")

datarows <- c(match("USD LIBOR - 1 month",all_data[,1]),match("USD LIBOR 
- 3 months",all_data[,1]))

newdata <- as.xts(t(all_data[datarows,2:ncol(all_data)]), 
order.by=all_dates)
colnames(newdata) <- LIBOR
storage.mode(newdata)<-"numeric"

LIBORdata <- cbind(USD1MTD156N,USD3MTD156N)
newdata2 <- rbind(LIBORdata,newdata)
newdata2 <- newdata2[!duplicated(index(newdata2))]
colnames(newdata2) <- c("1mo LIBOR","3mo LIBOR")

datablock <- newdata2[paste(sopm,"::",eopm,sep=''),]
newdatablock <- as.matrix(datablock)[NROW(datablock):1,,drop=FALSE]

print(xtable(newdatablock,digits=5),floating=TRUE,comment=FALSE,type="latex")
```



---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From naiden_v at abv.bg  Mon Dec 21 14:06:47 2015
From: naiden_v at abv.bg (Nayden Valev)
Date: Mon, 21 Dec 2015 15:06:47 +0200 (EET)
Subject: [R-SIG-Finance] Backtesting VaR model
Message-ID: <434667025.1606072.1450703207262.JavaMail.apache@nm62.abv.bg>

 Hi guys,  
 I am a student from Germany and I need help for my R-class project. I want to validate Value-at-Risk model. For this purpose a time series of values in{0, 1}is available, where the value 1 represents a VaR violation, i.e. a higher loss than the Value-at-Risk, and respectively, the value 0 represents a VaR non-violation. The Value-at-Risk estimation was conducted with a con?dence level of 95%. In the following denote p as the probability for a VaR violation (here 5%) and T as the number of observations. To begin with, a simple Kupiec test is to be carried out, which is based on the number of VaR violations. The time series that is given is: 0...0 (88)
 1
 0...0 (9)
 1
 0...0 (28)
 11 
0...0 (16)
 111 
0...0 (33)
 1
 0....0 (15)
 1 
0....0 (8)
 1 
0....0 (15)
 1 
0....0 (17). These are 240 observations with binom. distrib. sum of 11 exceptions.  I want to compute the 95% non-rejection regions (i.e. upper and lower bounds of the regions) for a Kupiec test given p, T, and cf (where cf is chosen as 0.95). The code 
should offer the possibility to choose between the computational method to determine the non-rejection regions. For that matter the regions can either be calculated by using the asymptotic distribution or using Monte-Carlo simulation. I want to fill up the following table  
   Non-rejection region  
 
 
 
 
 
 
 
 T= 100 
 T= 250 
 T= 500 
 T=1000  p=10.0%
  p=7.5%  p=5.0%
  p=2.5%
  p=1.0%   
  
and then extend the analysis using the Christoffersen test. Should I use the empirical distribution instead of normal distribution for the MC simulation?
  
  I will be very grateful if someone can help with some advice or example!  
  Nayden
  
	[[alternative HTML version deleted]]


From uchiharj at gmail.com  Wed Dec 23 01:02:00 2015
From: uchiharj at gmail.com (Rods)
Date: Tue, 22 Dec 2015 18:02:00 -0600
Subject: [R-SIG-Finance] xts timeBasedSeq
Message-ID: <CAJLULw=MB_catzPU5LDeF-D0t2=mB2Uob71fkSwoFO4nca+2Jw@mail.gmail.com>

Hi,

I'm trying to make a time sequence using the length.out argument but it
just outputs a list without the sequence. I'm just running the example
shown in the xts package:

timeBasedSeq('20080101 0830',length=100)

Is there something wrong with my installation?

Thanks in advance,
Rod

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Wed Dec 23 04:40:59 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 22 Dec 2015 21:40:59 -0600
Subject: [R-SIG-Finance] xts timeBasedSeq
In-Reply-To: <CAJLULw=MB_catzPU5LDeF-D0t2=mB2Uob71fkSwoFO4nca+2Jw@mail.gmail.com>
References: <CAJLULw=MB_catzPU5LDeF-D0t2=mB2Uob71fkSwoFO4nca+2Jw@mail.gmail.com>
Message-ID: <CAPPM_gR-tcyuJs=ssgN=xG7i4R34N8isV8SkMD5Pn165LxOhCA@mail.gmail.com>

Hi Rod,

On Tue, Dec 22, 2015 at 6:02 PM, Rods <uchiharj at gmail.com> wrote:
> Hi,
>
> I'm trying to make a time sequence using the length.out argument but it
> just outputs a list without the sequence. I'm just running the example
> shown in the xts package:
>
> timeBasedSeq('20080101 0830',length=100)
>
> Is there something wrong with my installation?
>
Hard to know, since you haven't told us anything about your installation. ;)

That said, most of the code in that function has not been touched
since mid-2008. There was a commit in early 2009 that attempted to fix
a bug, and the commit message says the fix is incomplete:
https://github.com/joshuaulrich/xts/commit/743c686c8e2819d0991821d8965ccbe4b7782f3

So that's likely what you're seeing.  I'll investigate and open an
issue once I can put a bit more context into the report.

> Thanks in advance,
> Rod
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From oanufriyev at gmail.com  Wed Dec 23 09:11:52 2015
From: oanufriyev at gmail.com (Oleksandr Anufriyev)
Date: Wed, 23 Dec 2015 09:11:52 +0100
Subject: [R-SIG-Finance] R-Fiddle
Message-ID: <CAJOpux23hb=wVEwi2zLRE=5Uy7Ta+7CJs7FNDiQHT2k+H9RkNQ@mail.gmail.com>

Hi, everybody,

When I have free time I program in R in the office as well. However, I need
to use here only R-Fiddle http://www.r-fiddle.org (online R compiler).
Pretty cool stuff, however, one problem: getSymbols from quantmod doesn't
work. May be someone could help?

Thx a lot.

Alex

Details:
library(quantmod)
getSymbols("SPY")
Error: cannot open destfile '(null).65534.65534/filed1f450ed0a0', reason
'No such file or directory'

I tried already with defining env, auto.assign etc. Didn't help.

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Wed Dec 23 16:16:25 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 23 Dec 2015 09:16:25 -0600
Subject: [R-SIG-Finance] R-Fiddle
In-Reply-To: <CAJOpux23hb=wVEwi2zLRE=5Uy7Ta+7CJs7FNDiQHT2k+H9RkNQ@mail.gmail.com>
References: <CAJOpux23hb=wVEwi2zLRE=5Uy7Ta+7CJs7FNDiQHT2k+H9RkNQ@mail.gmail.com>
Message-ID: <CAPPM_gRSanqwtxksxF9V0-wTKwHkUT=huS_c4YAyaPVFeYEXOg@mail.gmail.com>

On Wed, Dec 23, 2015 at 2:11 AM, Oleksandr Anufriyev
<oanufriyev at gmail.com> wrote:
> Hi, everybody,
>
> When I have free time I program in R in the office as well. However, I need
> to use here only R-Fiddle http://www.r-fiddle.org (online R compiler).
> Pretty cool stuff, however, one problem: getSymbols from quantmod doesn't
> work. May be someone could help?
>
The problem isn't with quantmod::getSymbols. The problem is that
R-Fiddle (apparently) does not allow code to create temporary
files/directories in the usual way.  So any code that requires
temporary files/directories won't work with R-Fiddle.

So you need to contact them and ask why it doesn't work.

> Thx a lot.
>
> Alex
>
> Details:
> library(quantmod)
> getSymbols("SPY")
> Error: cannot open destfile '(null).65534.65534/filed1f450ed0a0', reason
> 'No such file or directory'
>
> I tried already with defining env, auto.assign etc. Didn't help.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From oanufriyev at gmail.com  Wed Dec 23 16:27:17 2015
From: oanufriyev at gmail.com (Oleksandr Anufriyev)
Date: Wed, 23 Dec 2015 16:27:17 +0100
Subject: [R-SIG-Finance] R-Fiddle
In-Reply-To: <CAPPM_gRSanqwtxksxF9V0-wTKwHkUT=huS_c4YAyaPVFeYEXOg@mail.gmail.com>
References: <CAJOpux23hb=wVEwi2zLRE=5Uy7Ta+7CJs7FNDiQHT2k+H9RkNQ@mail.gmail.com>
	<CAPPM_gRSanqwtxksxF9V0-wTKwHkUT=huS_c4YAyaPVFeYEXOg@mail.gmail.com>
Message-ID: <CAJOpux0X-YH5gRR=T9sDnq7vkQLvu9mo+1tSpzQOX9qbssmn3Q@mail.gmail.com>

Thanks a lot, Joshua. That's what I thought. Already waiting for the reply
from Datacamp. If smth valuable comes, I'll share it here.

Happy holidays!

Alex

On Wed, Dec 23, 2015 at 4:16 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>
wrote:

> On Wed, Dec 23, 2015 at 2:11 AM, Oleksandr Anufriyev
> <oanufriyev at gmail.com> wrote:
> > Hi, everybody,
> >
> > When I have free time I program in R in the office as well. However, I
> need
> > to use here only R-Fiddle http://www.r-fiddle.org (online R compiler).
> > Pretty cool stuff, however, one problem: getSymbols from quantmod doesn't
> > work. May be someone could help?
> >
> The problem isn't with quantmod::getSymbols. The problem is that
> R-Fiddle (apparently) does not allow code to create temporary
> files/directories in the usual way.  So any code that requires
> temporary files/directories won't work with R-Fiddle.
>
> So you need to contact them and ask why it doesn't work.
>
> > Thx a lot.
> >
> > Alex
> >
> > Details:
> > library(quantmod)
> > getSymbols("SPY")
> > Error: cannot open destfile '(null).65534.65534/filed1f450ed0a0', reason
> > 'No such file or directory'
> >
> > I tried already with defining env, auto.assign etc. Didn't help.
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
>

	[[alternative HTML version deleted]]


From tjclifford at yahoo.com  Wed Dec 23 19:22:30 2015
From: tjclifford at yahoo.com (Tom Clifford)
Date: Wed, 23 Dec 2015 18:22:30 +0000 (UTC)
Subject: [R-SIG-Finance] xts timeBasedSeq
In-Reply-To: <CAJLULw=MB_catzPU5LDeF-D0t2=mB2Uob71fkSwoFO4nca+2Jw@mail.gmail.com>
References: <CAJLULw=MB_catzPU5LDeF-D0t2=mB2Uob71fkSwoFO4nca+2Jw@mail.gmail.com>
Message-ID: <800052531.2657341.1450894950675.JavaMail.yahoo@mail.yahoo.com>

Rod, if you're looking to get a sequence of incrementing minutes, you can use

timeBasedSeq("20080101 0830/M", length.out = 100)

this will give you:

?[1] "2008-01-01 08:30:00 EST" "2008-01-01 08:31:00 EST" "2008-01-01 08:32:00 EST" "2008-01-01 08:33:00 EST"
?[5] "2008-01-01 08:34:00 EST" "2008-01-01 08:35:00 EST" "2008-01-01 08:36:00 EST" "2008-01-01 08:37:00 EST"
?[9] "2008-01-01 08:38:00 EST" "2008-01-01 08:39:00 EST" "2008-01-01 08:40:00 EST" "2008-01-01 08:41:00 EST"

.....


[93] "2008-01-01 10:02:00 EST" "2008-01-01 10:03:00 EST" "2008-01-01 10:04:00 EST" "2008-01-01 10:05:00 EST"
[97] "2008-01-01 10:06:00 EST" "2008-01-01 10:07:00 EST" "2008-01-01 10:08:00 EST" "2008-01-01 10:09:00 EST"?Tom Clifford Northwood Univ MBA '13 Lansing, Michigan 48912 tjclifford at yahoo.com
 

      From: Rods <uchiharj at gmail.com>
 To: r-sig-finance at r-project.org 
 Sent: Tuesday, December 22, 2015 7:02 PM
 Subject: [R-SIG-Finance] xts timeBasedSeq
   
Hi,

I'm trying to make a time sequence using the length.out argument but it
just outputs a list without the sequence. I'm just running the example
shown in the xts package:

timeBasedSeq('20080101 0830',length=100)

Is there something wrong with my installation?

Thanks in advance,
Rod

??? [[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


  
	[[alternative HTML version deleted]]


From uchiharj at gmail.com  Wed Dec 23 22:56:53 2015
From: uchiharj at gmail.com (Rods)
Date: Wed, 23 Dec 2015 15:56:53 -0600
Subject: [R-SIG-Finance] xts timeBasedSeq
In-Reply-To: <800052531.2657341.1450894950675.JavaMail.yahoo@mail.yahoo.com>
References: <CAJLULw=MB_catzPU5LDeF-D0t2=mB2Uob71fkSwoFO4nca+2Jw@mail.gmail.com>
	<800052531.2657341.1450894950675.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAJLULwn7=KbpW-yPdxpCyFvnXD2P53KCeoosOM7_2B9fsKN+zw@mail.gmail.com>

Thank you that works!

On Wed, Dec 23, 2015 at 12:22 PM, Tom Clifford via R-SIG-Finance <
r-sig-finance at r-project.org> wrote:

> Rod, if you're looking to get a sequence of incrementing minutes, you can
> use
>
> timeBasedSeq("20080101 0830/M", length.out = 100)
>
> this will give you:
>
>  [1] "2008-01-01 08:30:00 EST" "2008-01-01 08:31:00 EST" "2008-01-01
> 08:32:00 EST" "2008-01-01 08:33:00 EST"
>  [5] "2008-01-01 08:34:00 EST" "2008-01-01 08:35:00 EST" "2008-01-01
> 08:36:00 EST" "2008-01-01 08:37:00 EST"
>  [9] "2008-01-01 08:38:00 EST" "2008-01-01 08:39:00 EST" "2008-01-01
> 08:40:00 EST" "2008-01-01 08:41:00 EST"
>
> .....
>
>
> [93] "2008-01-01 10:02:00 EST" "2008-01-01 10:03:00 EST" "2008-01-01
> 10:04:00 EST" "2008-01-01 10:05:00 EST"
> [97] "2008-01-01 10:06:00 EST" "2008-01-01 10:07:00 EST" "2008-01-01
> 10:08:00 EST" "2008-01-01 10:09:00 EST" Tom Clifford Northwood Univ MBA '13
> Lansing, Michigan 48912 tjclifford at yahoo.com
>
>
>       From: Rods <uchiharj at gmail.com>
>  To: r-sig-finance at r-project.org
>  Sent: Tuesday, December 22, 2015 7:02 PM
>  Subject: [R-SIG-Finance] xts timeBasedSeq
>
> Hi,
>
> I'm trying to make a time sequence using the length.out argument but it
> just outputs a list without the sequence. I'm just running the example
> shown in the xts package:
>
> timeBasedSeq('20080101 0830',length=100)
>
> Is there something wrong with my installation?
>
> Thanks in advance,
> Rod
>
>     [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From smiletobehappy27 at gmail.com  Sun Dec 27 16:02:56 2015
From: smiletobehappy27 at gmail.com (Gayatri Nesarikar)
Date: Sun, 27 Dec 2015 20:32:56 +0530
Subject: [R-SIG-Finance] Not able to install fOptions R package on ec2 spark
	cluster
Message-ID: <CAOqQqq2VzrXgN975i1HV6uZ=Q0jKx=Xt24LEmt_Pgnu=Eygw4w@mail.gmail.com>

Hello,

I have deployed a spark cluster on ec2 using the spark-ec2 script. I am
trying to install the 'fOptions' R package in Rstudio on the master but I
am getting the following errors while the install.packages() tries to
install a depedency called 'gss'

/usr/bin/ld: cannot find -lRlapack
/usr/bin/ld: cannot find -lRblas

There are many more warnings too. I also tried yum install liblpack3
libperl-dev but I get another error - no package libperl-dev available and
same for other packages.

Other packages like ggplot2 were successfully installed and some sample
codes are running fine on the spark cluster.

Is there any solution to this error or any work around to install fOptions
and its dependencies?

Thanks,
Gayatri

	[[alternative HTML version deleted]]


From edd at debian.org  Sun Dec 27 16:47:15 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 27 Dec 2015 09:47:15 -0600
Subject: [R-SIG-Finance] Not able to install fOptions R package on ec2
	spark	cluster
In-Reply-To: <CAOqQqq2VzrXgN975i1HV6uZ=Q0jKx=Xt24LEmt_Pgnu=Eygw4w@mail.gmail.com>
References: <CAOqQqq2VzrXgN975i1HV6uZ=Q0jKx=Xt24LEmt_Pgnu=Eygw4w@mail.gmail.com>
Message-ID: <22144.2051.814803.123823@max.nulle.part>


On 27 December 2015 at 20:32, Gayatri Nesarikar wrote:
| Hello,
| 
| I have deployed a spark cluster on ec2 using the spark-ec2 script. I am
| trying to install the 'fOptions' R package in Rstudio on the master but I
| am getting the following errors while the install.packages() tries to
| install a depedency called 'gss'
| 
| /usr/bin/ld: cannot find -lRlapack
| /usr/bin/ld: cannot find -lRblas
| 
| There are many more warnings too. I also tried yum install liblpack3
| libperl-dev but I get another error - no package libperl-dev available and
| same for other packages.
| 
| Other packages like ggplot2 were successfully installed and some sample
| codes are running fine on the spark cluster.
| 
| Is there any solution to this error or any work around to install fOptions
| and its dependencies?

Please do not crosspost!  I already replied on StackOverflow:
  http://stackoverflow.com/a/34481640/143305

Let me add that if you weren't on RedHat it would be as easy as
  sudo apt-get install r-cran-foptions
which  would also install gss and all other dependencies of fOptions (as I
happen to have been maintaining this for Debian/Ubuntu for a decade+).

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From tr206 at kent.ac.uk  Sun Dec 27 20:36:23 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sun, 27 Dec 2015 19:36:23 +0000
Subject: [R-SIG-Finance] rugarch package: VaR exceedances plot
Message-ID: <3e8e7bce90e34f5f828d7992abae3a32@ex13-live-mbn1.ad.kent.ac.uk>

Dear all,



I am trying to backtest my VaR model in R using the rugarch package. Hence, I am trying to plot the VaR exceedances using following code from the rugarch package:



VaRplot(alpha=0.025,actual = returns,VaR = VaR,ylab = "daily log returns",xlab = "date")



Unfortunately, I get this error message and do not know the reason for this



Error in plot.window(...) : invalid 'ylim' value In addition: Warning message:

In as.double.xts(actual) : NAs introduced by coercion



If I take the ylim error message into account I get the error:



Error in VaRplot(alpha = 0.025, actual = returns, VaR = VaR, ylab = "daily log returns",  :

  unused argument (ylim = rangereturns)



I thought that it could be a mistake in my dataset. I converted the dataset into a xts object using following codes but this seems to be correct:


VaR<-xts(BuVaR_Chapter_13_4_VaR[,4],order.by=as.POSIXct(BuVaR_Chapter_13_4_VaR$Date))

returns<-xts(BuVaR_Chapter_13_4_VaR[,3],order.by=as.POSIXct(BuVaR_Chapter_13_4_VaR$Date))



Does anyone have an idea? Many thanks in advance.


	[[alternative HTML version deleted]]


From grgkumar4 at gmail.com  Tue Dec 29 07:34:06 2015
From: grgkumar4 at gmail.com (George Kumar)
Date: Mon, 28 Dec 2015 22:34:06 -0800
Subject: [R-SIG-Finance] How to suppress getSymbols error message
Message-ID: <CAJDeD2r0nSBw0owc-++oV5crGeHGA+m8JSjjn+F_EH=0REK65w@mail.gmail.com>

Hi all,

I am using getSymbols to with the following options:

setDefaults(getSymbols,src='csv')

The problem is that when it cannot find the file locally it gives an error
message like the following:

file  abcd.csv does not exist  in   ....skipping ..

It is coming from the following lines of source code:

 if(!file.exists(sym.file)) {
      cat("\nfile ",paste(Symbols[[i]],extension,sep='.')," does not exist ",
          "in ",dir,"....skipping\n")
      next
 }

If would have been nice if the cat statement above was under a if (verbose)

check.

Anyway to suppress this message ? I have tried using try statement too.
Still no luck.

Thanks in advance.
George

	[[alternative HTML version deleted]]


From michael.weylandt at gmail.com  Tue Dec 29 18:38:40 2015
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Tue, 29 Dec 2015 11:38:40 -0600
Subject: [R-SIG-Finance] How to suppress getSymbols error message
In-Reply-To: <CAJDeD2r0nSBw0owc-++oV5crGeHGA+m8JSjjn+F_EH=0REK65w@mail.gmail.com>
References: <CAJDeD2r0nSBw0owc-++oV5crGeHGA+m8JSjjn+F_EH=0REK65w@mail.gmail.com>
Message-ID: <CAAmySGNj4pji3Ga8N5jyW_No1Hs0NKa3a6jF33at3i+HwuhRQQ@mail.gmail.com>

You can use a sink(NULL) (R equivalent of >/dev/null) to suppress all
output temporarily.

As far as I know, there's no simple way to just catch this one cat().

On Tue, Dec 29, 2015 at 12:34 AM, George Kumar <grgkumar4 at gmail.com> wrote:
> Hi all,
>
> I am using getSymbols to with the following options:
>
> setDefaults(getSymbols,src='csv')
>
> The problem is that when it cannot find the file locally it gives an error
> message like the following:
>
> file  abcd.csv does not exist  in   ....skipping ..
>
> It is coming from the following lines of source code:
>
>  if(!file.exists(sym.file)) {
>       cat("\nfile ",paste(Symbols[[i]],extension,sep='.')," does not exist ",
>           "in ",dir,"....skipping\n")
>       next
>  }
>
> If would have been nice if the cat statement above was under a if (verbose)
>
> check.
>
> Anyway to suppress this message ? I have tried using try statement too.
> Still no luck.
>
> Thanks in advance.
> George
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From grgkumar4 at gmail.com  Tue Dec 29 20:58:37 2015
From: grgkumar4 at gmail.com (George Kumar)
Date: Tue, 29 Dec 2015 11:58:37 -0800
Subject: [R-SIG-Finance] How to suppress getSymbols error message
In-Reply-To: <CAAmySGNj4pji3Ga8N5jyW_No1Hs0NKa3a6jF33at3i+HwuhRQQ@mail.gmail.com>
References: <CAJDeD2r0nSBw0owc-++oV5crGeHGA+m8JSjjn+F_EH=0REK65w@mail.gmail.com>
	<CAAmySGNj4pji3Ga8N5jyW_No1Hs0NKa3a6jF33at3i+HwuhRQQ@mail.gmail.com>
Message-ID: <CAJDeD2ps6NHtkxyg-6uKPzLV-dyW4=6E4_+1OcSV4xPzXJbAXQ@mail.gmail.com>

Hi Michael,

Thanks a lot for replying. This is exactly I ended up doing. I wrapped the
offending code around sink("/dev/null") and sink(). This seems to have
solved my problem for the time being.

Best Regards.
George

On Tue, Dec 29, 2015 at 9:38 AM, Michael Weylandt <
michael.weylandt at gmail.com> wrote:

> You can use a sink(NULL) (R equivalent of >/dev/null) to suppress all
> output temporarily.
>
> As far as I know, there's no simple way to just catch this one cat().
>
> On Tue, Dec 29, 2015 at 12:34 AM, George Kumar <grgkumar4 at gmail.com>
> wrote:
> > Hi all,
> >
> > I am using getSymbols to with the following options:
> >
> > setDefaults(getSymbols,src='csv')
> >
> > The problem is that when it cannot find the file locally it gives an
> error
> > message like the following:
> >
> > file  abcd.csv does not exist  in   ....skipping ..
> >
> > It is coming from the following lines of source code:
> >
> >  if(!file.exists(sym.file)) {
> >       cat("\nfile ",paste(Symbols[[i]],extension,sep='.')," does not
> exist ",
> >           "in ",dir,"....skipping\n")
> >       next
> >  }
> >
> > If would have been nice if the cat statement above was under a if
> (verbose)
> >
> > check.
> >
> > Anyway to suppress this message ? I have tried using try statement too.
> > Still no luck.
> >
> > Thanks in advance.
> > George
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


