From optionsraghu at gmail.com  Tue Apr  1 11:42:46 2014
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Tue, 1 Apr 2014 10:42:46 +0100
Subject: [R-SIG-Finance] specifyModel error in fitting a model
Message-ID: <CADgEnDkmN859YtfPrtbm3X1_MkL22jLFYpDtcYPv+h1btbHrMw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140401/7dcf7116/attachment.pl>

From ravi.kulk at gmail.com  Thu Apr  3 08:05:05 2014
From: ravi.kulk at gmail.com (Ravi Kulkarni)
Date: Wed, 2 Apr 2014 23:05:05 -0700 (PDT)
Subject: [R-SIG-Finance] Problem with GoogleFinanceSource function: Error in
	get...
Message-ID: <1396505105090-4688071.post@n4.nabble.com>

Hello,
  I am new to using Rmetrics. When I try to use the GoogleFinanceSource
function thus:

    x <- GoogleFinanceSource('INFY')

  I get an error message saying;

    Error in get(name, envir = asNamespace(pkg), inherits = FALSE) : object
'.Source' not found  

  I am just trying to reproduce results from code at:

   
http://cran.r-project.org/web/packages/tm.plugin.webmining/vignettes/ShortIntro.pdf

  Any help appreciated...

  Ravi



--
View this message in context: http://r.789695.n4.nabble.com/Problem-with-GoogleFinanceSource-function-Error-in-get-tp4688071.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From a.chandhial at btinternet.com  Thu Apr  3 10:00:18 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Thu, 3 Apr 2014 09:00:18 +0100 (BST)
Subject: [R-SIG-Finance] quantstrat - stochastic oscillator
	overbought-oversold (OBOS) strategy
In-Reply-To: <1396254858.41457.YahooMailNeo@web186004.mail.ir2.yahoo.com>
References: <1396254858.41457.YahooMailNeo@web186004.mail.ir2.yahoo.com>
Message-ID: <1396512018.52814.YahooMailNeo@web186002.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140403/438755b2/attachment.pl>

From ilya.kipnis at gmail.com  Thu Apr  3 11:01:43 2014
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Thu, 3 Apr 2014 05:01:43 -0400
Subject: [R-SIG-Finance] Fwd: quantstrat - stochastic oscillator
 overbought-oversold (OBOS) strategy
In-Reply-To: <CA+oJuEG0fgvUN=P-g0ARSsutLRFqu=_X0_Wt0Sp6PkPP_OqcNQ@mail.gmail.com>
References: <1396254858.41457.YahooMailNeo@web186004.mail.ir2.yahoo.com>
	<1396512018.52814.YahooMailNeo@web186002.mail.ir2.yahoo.com>
	<CA+oJuEE1fpLs2ZZMEZ4cG7_vZJwdFzUcUs-J_tSocFdm9b-S-w@mail.gmail.com>
	<CA+oJuEG0fgvUN=P-g0ARSsutLRFqu=_X0_Wt0Sp6PkPP_OqcNQ@mail.gmail.com>
Message-ID: <CA+oJuEHcvZUbFRxOSuf5ENt1w_Cowg7sxn69c-Z4MGp+OebEJg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140403/74e51eb7/attachment.pl>

From spillihp.kcin.61 at gmail.com  Thu Apr  3 18:54:30 2014
From: spillihp.kcin.61 at gmail.com (Nick Phillips)
Date: Thu, 3 Apr 2014 11:54:30 -0500
Subject: [R-SIG-Finance] GARCH-M Modeling in R (rugarch) vs EVIEWS
Message-ID: <CA+VRTu6O4CWH4dBN8vFd0C4peXzQYT9qK4fr6DMFug2Mg_Rfsw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140403/fa4d43df/attachment.pl>

From alexios at 4dscape.com  Thu Apr  3 20:31:39 2014
From: alexios at 4dscape.com (Alexios Ghalanos)
Date: Thu, 3 Apr 2014 21:31:39 +0300
Subject: [R-SIG-Finance] GARCH-M Modeling in R (rugarch) vs EVIEWS
In-Reply-To: <CA+VRTu6O4CWH4dBN8vFd0C4peXzQYT9qK4fr6DMFug2Mg_Rfsw@mail.gmail.com>
References: <CA+VRTu6O4CWH4dBN8vFd0C4peXzQYT9qK4fr6DMFug2Mg_Rfsw@mail.gmail.com>
Message-ID: <8C7F0CA5-6D84-4F15-8B09-A140626EFCAA@4dscape.com>

1. See archm and archpow options for ARCH in mean.
2. Don't use model='fGARCH' and submodel='GARCH'. Use model='sGARCH'.
3. Read the vignette to see the notation used (alpha is the ARCH coefficient and beta the GARCH coefficient).


Alexios

> On 3 Apr 2014, at 19:54, Nick Phillips <spillihp.kcin.61 at gmail.com> wrote:
> 
> Hi,
> 
> Im trying to compare some GARCH moedling outputs from EVIEWS to the rugarch
> package, specifically what EVIEWS refers to as the 'GARCH coefficient' when
> modelling a GARCH-M(1,1) process.
> 
> Is anyone familiar with this and if so how to calculate it from the rugarch
> or anther garch package in R?
> 
> Any help would be appreciated
> 
> Thanks,
> 
> Nick
> 
> 
> 
> my R code to fit the rugarch garch-m (1,1) model is
> 
> rm(list = ls())
> 
> library(PerformanceAnalytics)
> 
> library(quantmod)
> 
> library(forecast)
> 
> library(rugarch)
> 
> ###############################################
> 
> # Get Data ##
> 
> ###############################################
> 
> data.df = read.table(file = 'RP_Orig.csv', sep = ',',
> 
>                     header = TRUE, as.is = TRUE)
> 
> data.xts <- xts(data.df[,2:ncol(data.df)], order.by = as.Date(data.df[,1]))
> 
> 
> spec = ugarchspec(variance.model = list(model = "fGARCH", submodel =
> 'GARCH', garchOrder =                   c(1, 1), variance.targeting =
> FALSE),
> 
>                  mean.model = list(armaOrder = c(0,0), archm = TRUE),
> 
>                  distribution.model = "std")
> 
> 
> fit = ugarchfit(data = na.omit(data.xts['/2013-10-01','sp500']), spec =
> spec)
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 


From spillihp.kcin.61 at gmail.com  Thu Apr  3 20:51:43 2014
From: spillihp.kcin.61 at gmail.com (Nick Phillips)
Date: Thu, 3 Apr 2014 13:51:43 -0500
Subject: [R-SIG-Finance] GARCH-M Modeling in R (rugarch) vs EVIEWS
In-Reply-To: <8C7F0CA5-6D84-4F15-8B09-A140626EFCAA@4dscape.com>
References: <CA+VRTu6O4CWH4dBN8vFd0C4peXzQYT9qK4fr6DMFug2Mg_Rfsw@mail.gmail.com>
	<8C7F0CA5-6D84-4F15-8B09-A140626EFCAA@4dscape.com>
Message-ID: <CA+VRTu4B6g+7L0ATkbgKNFy_4q2oBadBuFQ6sB04w-OrRnaRGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140403/16c06d1f/attachment.pl>

From ilya.kipnis at gmail.com  Fri Apr  4 02:27:10 2014
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Thu, 3 Apr 2014 17:27:10 -0700
Subject: [R-SIG-Finance] Fwd: quantstrat - stochastic oscillator
 overbought-oversold (OBOS) strategy
In-Reply-To: <1396559205.95669.YahooMailNeo@web186004.mail.ir2.yahoo.com>
References: <1396254858.41457.YahooMailNeo@web186004.mail.ir2.yahoo.com>
	<1396512018.52814.YahooMailNeo@web186002.mail.ir2.yahoo.com>
	<CA+oJuEE1fpLs2ZZMEZ4cG7_vZJwdFzUcUs-J_tSocFdm9b-S-w@mail.gmail.com>
	<CA+oJuEG0fgvUN=P-g0ARSsutLRFqu=_X0_Wt0Sp6PkPP_OqcNQ@mail.gmail.com>
	<CA+oJuEHcvZUbFRxOSuf5ENt1w_Cowg7sxn69c-Z4MGp+OebEJg@mail.gmail.com>
	<1396559205.95669.YahooMailNeo@web186004.mail.ir2.yahoo.com>
Message-ID: <CA+oJuEFeoBfA2jbUxEwOc_y+MRytyXrbeg965HfvvH7NnDpmdg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140403/b726736f/attachment.pl>

From a.chandhial at btinternet.com  Fri Apr  4 09:46:53 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Fri, 4 Apr 2014 08:46:53 +0100 (BST)
Subject: [R-SIG-Finance] Fwd: quantstrat - stochastic oscillator
	overbought-oversold (OBOS) strategy
In-Reply-To: <CA+oJuEFeoBfA2jbUxEwOc_y+MRytyXrbeg965HfvvH7NnDpmdg@mail.gmail.com>
References: <1396254858.41457.YahooMailNeo@web186004.mail.ir2.yahoo.com>
	<1396512018.52814.YahooMailNeo@web186002.mail.ir2.yahoo.com>
	<CA+oJuEE1fpLs2ZZMEZ4cG7_vZJwdFzUcUs-J_tSocFdm9b-S-w@mail.gmail.com>
	<CA+oJuEG0fgvUN=P-g0ARSsutLRFqu=_X0_Wt0Sp6PkPP_OqcNQ@mail.gmail.com>
	<CA+oJuEHcvZUbFRxOSuf5ENt1w_Cowg7sxn69c-Z4MGp+OebEJg@mail.gmail.com>
	<1396559205.95669.YahooMailNeo@web186004.mail.ir2.yahoo.com>
	<CA+oJuEFeoBfA2jbUxEwOc_y+MRytyXrbeg965HfvvH7NnDpmdg@mail.gmail.com>
Message-ID: <1396597613.34216.YahooMailNeo@web186004.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140404/adfaa75d/attachment.pl>

From ilya.kipnis at gmail.com  Wed Apr  9 23:54:07 2014
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Wed, 9 Apr 2014 14:54:07 -0700
Subject: [R-SIG-Finance] stochastic oscillator OBOS - intraday data &
	optimization
In-Reply-To: <1397079989.63977.YahooMailNeo@web186001.mail.ir2.yahoo.com>
References: <1397079989.63977.YahooMailNeo@web186001.mail.ir2.yahoo.com>
Message-ID: <CA+oJuEHhXfLqoYYAv4k=1tj3T4w7AWv+X1KXatxYun5OOVOAkQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140409/c9149743/attachment.pl>

From a.chandhial at btinternet.com  Thu Apr 10 09:57:38 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Thu, 10 Apr 2014 08:57:38 +0100 (BST)
Subject: [R-SIG-Finance] stochastic oscillator OBOS - intraday data &
	optimization
In-Reply-To: <CA+oJuEHhXfLqoYYAv4k=1tj3T4w7AWv+X1KXatxYun5OOVOAkQ@mail.gmail.com>
References: <1397079989.63977.YahooMailNeo@web186001.mail.ir2.yahoo.com>
	<CA+oJuEHhXfLqoYYAv4k=1tj3T4w7AWv+X1KXatxYun5OOVOAkQ@mail.gmail.com>
Message-ID: <1397116658.59463.YahooMailNeo@web186004.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140410/8804f560/attachment.pl>

From Uniraf at gmail.com  Thu Apr 10 11:14:51 2014
From: Uniraf at gmail.com (Chris Urlaub)
Date: Thu, 10 Apr 2014 02:14:51 -0700 (PDT)
Subject: [R-SIG-Finance] GARCH MIDAS model
Message-ID: <1397121291464-4688514.post@n4.nabble.com>

Hi,

I'm trying to implement the GARCH MIDAS model proposed by Engle, Ghysels and
Sohn (2013) in R. Since I just started using R for programming I cannot find
out what's wrong with my programming code. After simulation I get the
following error messages:

Error in optim(param, loglikely, method = "BFGS", hessian = T) : 
  non-finite finite-difference value [4]
In addition: There were 50 or more warnings (use warnings() to see the first
50)

I don't know how to interpret this error messages and the warnings do not
help me either. 
For better understanding I post the code, I programmed. There I use beta
weightings, three lags and generated a mini artificial data set with 24
monthly return data and 8 quarterly unemployment rates.

###GARCH MIDAS###

################
###parameters###
################

y_mini = rnorm(24, 0.0004, 0.016)     # pseudo monthly returns
x_mini=c(0.3779791,3.1863575,-0.3611527,2.2541529,1.7124367,-2.6186178,0.7241506,
4.5503754) #pseudo quarterly data
mpq=length(y_mini)/length(x_mini) #months per quarter
N=length(y_mini) #number of months (i=1,...,24)
T_q=length(x_mini) #number of quarters  (t=1,...,8)
maxlag=4 #use actually 3 lags since the weight of the last lag is zero by
construction
#############################
###Log Likelyhood function###
#############################

loglikely=function(param){
  mu=param[1]
  alpha=param[2]
  beta=param[3]
  m=param[4]
  theta=param[5]
  w_1=param[6]
  w_2=param[7]
  
###beta weighting function###

  phi=phi_nominator=rep(0,maxlag)
  phi_denominator=0
  
  for (k in seq(1:maxlag)) {
    
   
phi_denominator=phi_denominator+((k/maxlag)^(param[6]-1))*((1-k/maxlag)^(param[7]-1))
    phi_nominator[k]=((k/maxlag)^(param[6]-1))*((1-k/maxlag)^(param[7]-1))
    
  }
  
  phi <<- phi_nominator/phi_denominator
  
###tau-specification###
  
  tau=rep(0,T)
  
  for (t in maxlag:T){
    
    tau_sum=rep(0,(maxlag-1))
    
    for (k in 1:(maxlag-1)){
      
      tau_sum[k] = phi[k]* x_mini[t-k]
    }
    
    tau[t]=param[4]+param[5]*sum(tau_sum)
  }
  tau<<-tau

###GARCH component###

  g=rep(0,N)
  g[(maxlag-1)*mpq]=1
  
  for(t in maxlag:T){
    
    for(i in ((t-1)*mpq):((t-1)*mpq+mpq-1)) {
      g[i + 1] <- (
        1-param[2]-param[3] +
          param[2] * (((y_mini[i] - param[1]) ^ 2)/tau[t]) +
          param[3]* g[i])
    }
  }
  g<<-g
  
##LL function##
  L=0
  
  for (t in maxlag:T){
    
    for(i in ((t-1)*mpq+1):((t-1)*mpq+mpq)) {
      
     
LL=-0.5*(log(2*pi)-0.5*log(g[i]*tau[t])-0.5*(((y_mini[i]-param[1])^2)/(g[i]*tau[t])))
      L=L+LL
    }
  }
L
}

### MLE ###
start = param= c(0.1,0.1,0.1,0.1,0.1,0.1,0.1)

estResults <- optim(param, loglikely, method="BFGS", hessian=T)
param <- estResults$par
hess <- estResults$hessian




Is anyone familiar with this and could give me a clue?

Any help would be appreciated!

Thanks,

Chris



--
View this message in context: http://r.789695.n4.nabble.com/GARCH-MIDAS-model-tp4688514.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From bilandi at outlook.com  Thu Apr 10 11:31:10 2014
From: bilandi at outlook.com (Majid M Bilandi)
Date: Thu, 10 Apr 2014 14:01:10 +0430
Subject: [R-SIG-Finance] EVT
Message-ID: <DUB129-W1FA23BA03E18875DD2FC9B9550@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140410/510c9aa8/attachment.pl>

From swjang at knu.ac.kr  Thu Apr 10 19:56:37 2014
From: swjang at knu.ac.kr (=?UTF-8?B?7J6l7Iq57Jqx?=)
Date: Fri, 11 Apr 2014 02:56:37 +0900 (KST)
Subject: [R-SIG-Finance] plz
Message-ID: <3324640.150966.1397152597195.JavaMail.root@mail>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140411/a7bb9005/attachment.html>

From edd at debian.org  Thu Apr 10 20:18:49 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 10 Apr 2014 13:18:49 -0500
Subject: [R-SIG-Finance] GARCH MIDAS model
In-Reply-To: <1397121291464-4688514.post@n4.nabble.com>
References: <1397121291464-4688514.post@n4.nabble.com>
Message-ID: <21318.57481.715812.931225@max.nulle.part>


On 10 April 2014 at 02:14, Chris Urlaub wrote:
| I'm trying to implement the GARCH MIDAS model proposed by Engle, Ghysels and
| Sohn (2013) in R. Since I just started using R for programming I cannot find
| out what's wrong with my programming code. After simulation I get the

One nice thing about R is just rich the ecosystem is. There *is* in fact a
MIDAS package for R, based on Eric Ghysel's code and with help by him.

See  http://cran.r-project.org/web/packages/midasr/   and its documentation
including the site at  http://mpiktas.github.io/midasr/   

It does volatility modeling in its examples but I am not sure if it does
GARCH in the way that particular paper.

Hth,  Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From michael.weylandt at gmail.com  Thu Apr 10 22:15:31 2014
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Thu, 10 Apr 2014 16:15:31 -0400
Subject: [R-SIG-Finance] plz
In-Reply-To: <3324640.150966.1397152597195.JavaMail.root@mail>
References: <3324640.150966.1397152597195.JavaMail.root@mail>
Message-ID: <6D502046-F36D-48FB-9C96-85935EEA1580@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140410/0b920f9a/attachment.pl>

From a.chandhial at btinternet.com  Thu Apr 10 23:26:44 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Thu, 10 Apr 2014 22:26:44 +0100 (BST)
Subject: [R-SIG-Finance] stochastic oscillator OBOS - intraday data &
	optimization
Message-ID: <1397165204.93071.YahooMailNeo@web186001.mail.ir2.yahoo.com>



All,


Iiya and I?have implemented a stochastic oscillator OBOS strategy?within quantstrat.

I?have?then?applied quantstrat's intraday GBPUSD data, 30min frequency with the strategy, including transaction costs (as in the other demos).

Thereafter I have attempted to optimize various values e.g.

(i) nSlowD, vary from 1-to-10
(ii) the lower level (over-sold) vary from .10-to-.30
(ii) the upper level (over-bought) vary from .70-to-.90


I get the error 

error calling combine function:
<simpleError in fun(result.1, result.2, result.3, result.4, result.5, result.6, result.7, result.8, result.9,..., result.100): attempt to select less than one element>

Attached are both programs: initial strategy and optimization.



An?error?corresponding to this from last month?http://r-forge.r-project.org/forum/forum.php?set=custom&forum_id=1032&style=nested&max_rows=100&submit=Change+View


Please help!

Amarjit
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140410/78a267d1/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD.R
Type: application/octet-stream
Size: 8077 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140410/78a267d1/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_optimization.R
Type: application/octet-stream
Size: 4060 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140410/78a267d1/attachment-0001.obj>

From noahsilverman at ucla.edu  Fri Apr 11 05:17:50 2014
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Thu, 10 Apr 2014 20:17:50 -0700
Subject: [R-SIG-Finance] Options in Blotter
Message-ID: <53475EDE.5050000@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140410/98346139/attachment.pl>

From chinmay.patil at gmail.com  Fri Apr 11 05:55:44 2014
From: chinmay.patil at gmail.com (Chinmay Patil)
Date: Fri, 11 Apr 2014 11:55:44 +0800
Subject: [R-SIG-Finance] Options in Blotter
In-Reply-To: <53475EDE.5050000@ucla.edu>
References: <53475EDE.5050000@ucla.edu>
Message-ID: <CA+kDFFXSK+jBxMLXxtKtaA8G5dZ=5gWqe-JBxkEDs+1n3wQTcQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140411/52527fd9/attachment.pl>

From dougedmunds at gmail.com  Sun Apr 13 01:26:55 2014
From: dougedmunds at gmail.com (Doug Edmunds)
Date: Sat, 12 Apr 2014 16:26:55 -0700
Subject: [R-SIG-Finance] Corn futures tick dataset available
Message-ID: <5349CBBF.3090302@gmail.com>

I have posted a dataset of commodity trades for testing purposes at 
r.dougedmunds.com.  The file is corn_tick_dataset_V01.zip

The dataset represents the tick by tick electronic trading of CME 
(Chicago Merchantile Exchange) May 2014 corn futures for 11 trading 
days, from Friday March 28, 2014 to through April 11, 2014. There are 
over 600,000 trades recorded.

Also provided is an R script to convert the csv file into xts format.
The included ReadMe file explains what the data represents.

-DAE


From kevin.j.owens at gmail.com  Sun Apr 13 04:21:51 2014
From: kevin.j.owens at gmail.com (Kevin Owens)
Date: Sat, 12 Apr 2014 21:21:51 -0500
Subject: [R-SIG-Finance] do any packages exist with short rate bond pricing
	models?
Message-ID: <5349F4BF.7030005@gmail.com>

I know short rate models aren't very realistic, but I'm interested in 
using a short rate model for the purposes of prototyping. By short rate 
model I mean a Vasicek(sp?) or CIR model. I could find the formulas and 
program it if I had to, but I would think this has to be in a package 
somewhere. I haven't seen it in the packages on the empirical finance 
page, but maybe I missed it. Does anyone know if these are already in a 
package somewhere?

Thank you,

Kevin


From pedrobtz at gmail.com  Sun Apr 13 13:17:50 2014
From: pedrobtz at gmail.com (Pedro Baltazar)
Date: Sun, 13 Apr 2014 12:17:50 +0100
Subject: [R-SIG-Finance] do any packages exist with short rate bond
 pricing models?
In-Reply-To: <5349F4BF.7030005@gmail.com>
References: <5349F4BF.7030005@gmail.com>
Message-ID: <CABN+XoS8NW+hOLfW-_Xh2=nO9w=ON9uWDm=kOKugj_OJ6ZGnPg@mail.gmail.com>

I believe 'sde' can be used for that!

http://cran.r-project.org/web/packages/sde/index.html

Pedro

On Sun, Apr 13, 2014 at 3:21 AM, Kevin Owens <kevin.j.owens at gmail.com> wrote:
> I know short rate models aren't very realistic, but I'm interested in using
> a short rate model for the purposes of prototyping. By short rate model I
> mean a Vasicek(sp?) or CIR model. I could find the formulas and program it
> if I had to, but I would think this has to be in a package somewhere. I
> haven't seen it in the packages on the empirical finance page, but maybe I
> missed it. Does anyone know if these are already in a package somewhere?
>
> Thank you,
>
> Kevin
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.



-- 
Pedro Baltazar


From mikhailbeketov at googlemail.com  Tue Apr 15 21:07:08 2014
From: mikhailbeketov at googlemail.com (Mikhail Beketov)
Date: Tue, 15 Apr 2014 21:07:08 +0200
Subject: [R-SIG-Finance] Aligning time series
Message-ID: <CAFPVqzy-Qc6WzDRejwxZJfTbDeRfhJ4e7KEEbkYjgTNJTJmFJg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140415/38b14c95/attachment.pl>

From ilya.kipnis at gmail.com  Tue Apr 15 21:09:25 2014
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Tue, 15 Apr 2014 12:09:25 -0700
Subject: [R-SIG-Finance] Aligning time series
In-Reply-To: <CAFPVqzy-Qc6WzDRejwxZJfTbDeRfhJ4e7KEEbkYjgTNJTJmFJg@mail.gmail.com>
References: <CAFPVqzy-Qc6WzDRejwxZJfTbDeRfhJ4e7KEEbkYjgTNJTJmFJg@mail.gmail.com>
Message-ID: <CA+oJuEEC_-p_ectS_QDHo2OAzuRX_QGC1KAWvbmFWPvz0pcLfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140415/00f61131/attachment.pl>

From anand.chirag at gmail.com  Wed Apr 16 08:12:41 2014
From: anand.chirag at gmail.com (Chirag Anand)
Date: Wed, 16 Apr 2014 11:42:41 +0530
Subject: [R-SIG-Finance] Aligning time series
In-Reply-To: <CA+oJuEEC_-p_ectS_QDHo2OAzuRX_QGC1KAWvbmFWPvz0pcLfw@mail.gmail.com>
References: <CAFPVqzy-Qc6WzDRejwxZJfTbDeRfhJ4e7KEEbkYjgTNJTJmFJg@mail.gmail.com>
	<CA+oJuEEC_-p_ectS_QDHo2OAzuRX_QGC1KAWvbmFWPvz0pcLfw@mail.gmail.com>
Message-ID: <CAOS9=_9-EUt3MxA-=_FUjSi7iAgARgf=y7JGFVcJwS+YjxpLjg@mail.gmail.com>

Hi Mikhail,

As Ilya said, xts takes care of it. You can use "merge.zoo" (if using
zoo) or "merge.xts" to merge two series. The missing timestamps are
taken care of by the "all" argument. You can use it to specify whether
to take missing timestamps from both the series, an individual series,
or not at all. The details are available in the respective man pages
of the functions.

On 16 April 2014 00:39, Ilya Kipnis <ilya.kipnis at gmail.com> wrote:
> Mikhail, are you using the xts package? Because when you cbind two xts time
> series, it takes care of alignment for you.
>
> -Ilya
>
>
> On Tue, Apr 15, 2014 at 12:07 PM, Mikhail Beketov <
> mikhailbeketov at googlemail.com> wrote:
>
>> Hello,
>> I have to analyze a large data-set of 1-min stock prices. The problem is
>> that the time-series for different stocks in my data-set have different
>> length, as some time points are missing in one series but present in
>> another etc. So, I have to create a table with aligned time series (all
>> dates/times should correspond to all the stocks). My questions are:
>> 1) Is there some efficient way to do it? Is there anything that is already
>> programmed.
>> 2) Does it make sense to align all of them to shortest time series (so,
>> delete the time points that are not given for all stocks)? Or, is better to
>> copy the preceding price values for the absent time points, and therefore
>> to align all of them to the longest time series?
>> Thanks,
>> Michael
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Chirag Anand
http://atvariance.in/chiraganand


From David.Reiner at xrtrading.com  Wed Apr 16 16:26:07 2014
From: David.Reiner at xrtrading.com (David Reiner)
Date: Wed, 16 Apr 2014 09:26:07 -0500
Subject: [R-SIG-Finance] Aligning time series
Message-ID: <9DE405308A6AA24AA794B76282C6C00F4A59367C44@HQ-POST1>

Definitely use xts !

For Question 2, I would merge all, leaving NA's for missing data.
Then what you do next depends on what you are trying to accomplish,
but sometimes LOCF can be appropriate,
for example if these are trades for less liquid instruments.
However, you may need to do some hard thinking about which of the many ways of dealing with missing data would be best for your specific task.

David L. Reiner, Ph.D.
Head Quant
XR Trading LLC

PS: better to post in plain text rather than html.

-----Original Message-----
From: r-sig-finance-bounces at r-project.org [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Chirag Anand
Sent: Wednesday, April 16, 2014 1:13 AM
To: r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] Aligning time series

Hi Mikhail,

As Ilya said, xts takes care of it. You can use "merge.zoo" (if using
zoo) or "merge.xts" to merge two series. The missing timestamps are
taken care of by the "all" argument. You can use it to specify whether
to take missing timestamps from both the series, an individual series,
or not at all. The details are available in the respective man pages
of the functions.

On 16 April 2014 00:39, Ilya Kipnis <ilya.kipnis at gmail.com> wrote:
> Mikhail, are you using the xts package? Because when you cbind two xts time
> series, it takes care of alignment for you.
>
> -Ilya
>
>
> On Tue, Apr 15, 2014 at 12:07 PM, Mikhail Beketov <
> mikhailbeketov at googlemail.com> wrote:
>
>> Hello,
>> I have to analyze a large data-set of 1-min stock prices. The problem is
>> that the time-series for different stocks in my data-set have different
>> length, as some time points are missing in one series but present in
>> another etc. So, I have to create a table with aligned time series (all
>> dates/times should correspond to all the stocks). My questions are:
>> 1) Is there some efficient way to do it? Is there anything that is already
>> programmed.
>> 2) Does it make sense to align all of them to shortest time series (so,
>> delete the time points that are not given for all stocks)? Or, is better to
>> copy the preceding price values for the absent time points, and therefore
>> to align all of them to the longest time series?
>> Thanks,
>> Michael
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



--
Chirag Anand
http://atvariance.in/chiraganand

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.

THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON'S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.


From henaff.iae at univ-paris1.fr  Wed Apr 16 20:29:19 2014
From: henaff.iae at univ-paris1.fr (P. Henaff)
Date: Wed, 16 Apr 2014 20:29:19 +0200
Subject: [R-SIG-Finance] Second Announcement: 8th R/Rmetrics Workshop and
 Summer School, Paris 26-28 June 2014
Message-ID: <534ECBFF.1090702@univ-paris1.fr>

R/Rmetrics in Finance and Insurance
8th R/Rmetrics Workshop and Summer School
First Shiny App Contest

Paris, 26-28 June 2014

After seven successful years in Meielisalp, the R/Rmetrics Workshop and 
Summer School moves to the Latin Quarter in Paris. As usual, the 
workshop will consist of Summer School-like tutorial sessions and 
user/developer meetings.

The workshop will focus on computational issues in statistics, empirical 
finance and insurance. In addition,  we will take a close look at modern 
ways of delivering R-based analytics through web applications.

Keynote Speakers
================

Christian Robert (Universit? Paris-Dauphine)
Bayesian inference and Markov chain Monte Carlo

Jean-Philippe Bouchaud (Ecole Polytechnique and CFM)
Anomalous price impact and critical liquidity in financial markets

Fr?d?ric Planchet (ISFA - Universit? Lyon I)
Economic scenario generation for Solvency II: theory and practice

Speaker to be announced (RStudio)
Web applications with Shiny and R

The afternoon sessions are dedicated to invited and contributed talks
and presentations reflecting the many uses of R and Rmetrics in  finance
and insurance.

Call for Papers
===============

We invite the submission of abstracts presenting innovations or exciting 
applications  covering the whole spectrum of computational topics in 
finance, insurance and related fields. To submit an abstract, send your 
one-page pdf file to submissions at rmetrics.org. Practitioners  are 
encouraged to submit papers.

First Shiny App Contest
=======================

The Rmetrics Open Source Association and RStudio are pleased to announce 
the first "Shiny App Contest".  The contest will take place during the 
conference.

Shiny makes it very simple for R users to turn analyses into interactive 
web applications that anyone can use.  We invite the submission of Shiny 
applications presenting innovations covering the whole spectrum of 
topics in finance, insurance and related fields.

To submit your Shiny application, first get in contact with us
(shiny at rmetrics.org). We will provide a Shiny Server to demo your app.
The applications will be presented and discussed in a special session.
The workshop participants will vote on the best app, which will be
honored with a certificate and a prize sponsored by the  Rmetrics
Association and RStudio.

Registration
============

For detailed informations and on-line registration, please see the
*Conference Site <https://sites.google.com/site/rmetricsparis2014>*.

Early registration is encouraged, not only to facilitate the
organization, but also because the conference falls during the French
Open (Rolland Garros) tennis tournament. Accommodation becomes tight in
Paris during that event.

We are looking forward to seeing you in Paris.

Mahendra Mehta, Stefan Theussl, Diethelm Wuertz, Patrick H?naff

-- 
Patrick H?naff
Ma?tre de Conf?rences
IAE Paris
Universit? Paris I | Panth?on Sorbonne

+33 (0)1 53 55 27 70
+33 (0)6 01 30 13 57
skype: pahenaff

8th R/Rmetrics conference in Paris | June 26-28, 2014
https://sites.google.com/site/rmetricsparis2014

Reproducible research in quantitative finance
www.zanadu.io

-- 
Ce message a ete verifie par MailScanner
pour des virus ou des polluriels et rien de
suspect n'a ete trouve.


From noahsilverman at ucla.edu  Thu Apr 17 01:51:57 2014
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Wed, 16 Apr 2014 16:51:57 -0700
Subject: [R-SIG-Finance] Blotter and historical options
Message-ID: <534F179D.4060505@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140416/e3e4abd4/attachment.pl>

From a.chandhial at btinternet.com  Thu Apr 17 08:41:17 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Thu, 17 Apr 2014 07:41:17 +0100 (BST)
Subject: [R-SIG-Finance] Fw: stochastic oscillator OBOS - intraday data &
	optimization
In-Reply-To: <1397165204.93071.YahooMailNeo@web186001.mail.ir2.yahoo.com>
References: <1397165204.93071.YahooMailNeo@web186001.mail.ir2.yahoo.com>
Message-ID: <1397716877.71309.YahooMailNeo@web186002.mail.ir2.yahoo.com>





Can someone provide guidance on getting the optimization working.


Amarjit



 
----- Forwarded Message -----
From: amarjit chandhial <a.chandhial at btinternet.com>
To: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org> 
Sent: Thursday, 10 April 2014, 22:26
Subject: [R-SIG-Finance] stochastic oscillator OBOS - intraday data & optimization
  




All,


Iiya and I?have implemented a stochastic oscillator OBOS strategy?within quantstrat.

I?have?then?applied quantstrat's intraday GBPUSD data, 30min frequency with the strategy, including transaction costs (as in the other demos).

Thereafter I have attempted to optimize various values e.g.

(i) nSlowD, vary from 1-to-10
(ii) the lower level (over-sold) vary from .10-to-.30
(ii) the upper level (over-bought) vary from .70-to-.90


I get the error 

error calling combine function:
<simpleError in fun(result.1, result.2, result.3, result.4, result.5, result.6, result.7, result.8, result.9,..., result.100):
 attempt to select less than one element>

Attached are both programs: initial strategy and optimization.



An?error?corresponding to this from last month?http://r-forge.r-project.org/forum/forum.php?set=custom&forum_id=1032&style=nested&max_rows=100&submit=Change+View


Please help!

Amarjit






_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140417/f4cd6a3d/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD.R
Type: application/octet-stream
Size: 8077 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140417/f4cd6a3d/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_optimization.R
Type: application/octet-stream
Size: 4060 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140417/f4cd6a3d/attachment-0001.obj>

From pedrobtz at gmail.com  Thu Apr 17 14:54:17 2014
From: pedrobtz at gmail.com (Pedro Baltazar)
Date: Thu, 17 Apr 2014 13:54:17 +0100
Subject: [R-SIG-Finance] RQuantLib - Options value at maturity
Message-ID: <CABN+XoQg00UWNqY4ayn_uK3Pw2wmEm4KOCT7OrXz5USbvn88-w@mail.gmail.com>

Hello,

why this package gives the value zero, and not (underlying - strike) =
50, at maturity?

> EuropeanOption("call", underlying=150, strike=100, dividendYield=0.00, riskFreeRate=0.03, maturity=0.0,volatility=0.2)
Concise summary of valuation for EuropeanOption
 value  delta  gamma   vega  theta    rho divRho
     0      0      0      0      0      0      0

Thanks

-- 
Pedro Baltazar


From dominykasgrigonis at gmail.com  Thu Apr 17 14:58:04 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Thu, 17 Apr 2014 13:58:04 +0100
Subject: [R-SIG-Finance] RQuantLib - Options value at maturity
In-Reply-To: <CABN+XoQg00UWNqY4ayn_uK3Pw2wmEm4KOCT7OrXz5USbvn88-w@mail.gmail.com>
References: <CABN+XoQg00UWNqY4ayn_uK3Pw2wmEm4KOCT7OrXz5USbvn88-w@mail.gmail.com>
Message-ID: <10C95E9291EB468697A481B4F2BDAA75@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140417/89504b06/attachment.pl>

From pedrobtz at gmail.com  Thu Apr 17 15:14:43 2014
From: pedrobtz at gmail.com (Pedro Baltazar)
Date: Thu, 17 Apr 2014 14:14:43 +0100
Subject: [R-SIG-Finance] RQuantLib - Options value at maturity
In-Reply-To: <CABRT3xBo+PzQX4G6=cnRcpmz9m1jsu0WvjQSvO7-BBy614KEVw@mail.gmail.com>
References: <CABN+XoQg00UWNqY4ayn_uK3Pw2wmEm4KOCT7OrXz5USbvn88-w@mail.gmail.com>
	<CABRT3xBo+PzQX4G6=cnRcpmz9m1jsu0WvjQSvO7-BBy614KEVw@mail.gmail.com>
Message-ID: <CABN+XoQVksUQTgCQMq02JsGBixyC+J9Zr+ghyJzhyxPGyEhZhQ@mail.gmail.com>

The "theoretical" value of a call option at maturity is max(S-K,0).

So, I am wondering  if there is any a implementation justification not
to put an some extra "if"s to check this corner cases

Also, when using this function to calibrate other quantitities (where
maturity is a variable) the fact that it gives zero for maturity=0,
might have impact in finding max ou min.

Thanks

On Thu, Apr 17, 2014 at 2:04 PM, Ryan Abbate <ryan.abbate at gmail.com> wrote:
> The reason is that you define the maturity date as zero, even though this
> particular option is otherwise in-the-money. Try entering maturity = 1 and
> you'll have values that are intuitive.
>
> Hope this helps.
> -Ryan
>
>
> On Thu, Apr 17, 2014 at 8:54 AM, Pedro Baltazar <pedrobtz at gmail.com> wrote:
>>
>> Hello,
>>
>> why this package gives the value zero, and not (underlying - strike) =
>> 50, at maturity?
>>
>> > EuropeanOption("call", underlying=150, strike=100, dividendYield=0.00,
>> > riskFreeRate=0.03, maturity=0.0,volatility=0.2)
>> Concise summary of valuation for EuropeanOption
>>  value  delta  gamma   vega  theta    rho divRho
>>      0      0      0      0      0      0      0
>>
>> Thanks
>>
>> --
>> Pedro Baltazar
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>



-- 
Pedro Baltazar


From frankm60606 at gmail.com  Thu Apr 17 15:30:07 2014
From: frankm60606 at gmail.com (Frank)
Date: Thu, 17 Apr 2014 08:30:07 -0500
Subject: [R-SIG-Finance] Blotter and historical options
In-Reply-To: <534F179D.4060505@ucla.edu>
References: <534F179D.4060505@ucla.edu>
Message-ID: <A69F601DBA2049A19DA1CE9A722F27A6@Franki7PC>

Hi,

I have an interest in analyzing option data. I work with data from the CBOE
using an Access 2003 template and export it to cvs format. The analysis is
done on the cvs data using a C program. 

I am thinking of writing a simple C program to process the CBOE data
directly to the cvs format I use. You could potentially use this program as
a starting point for conversion.

CBOE introduced new symbols for options in two stages, which I think is now
complete. You may want to consider using this format.

What is the source of your data? Hopefully CBOE?

Frank
Chicago, IL

-----Original Message-----
From: r-sig-finance-bounces at r-project.org
[mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Noah Silverman
Sent: Wednesday, April 16, 2014 6:52 PM
To: r-sig-finance at r-project.org; Joshua Ulrich
Subject: [R-SIG-Finance] Blotter and historical options

Hi,

I'm a bit stuck trying to figure out how to integrate historical option
data into the blotter package.

Trying to take a log of trading history and insert it all into Blotter.

I have:
    1) historical data for a bunch of options as CSV files.
    2) A log of trades

Processing the trades for equities was easy:
    1) Use quantmod to fetch the symbols (historical data)
    2) Loop through trade log and use addTxn function of blotter.

Not sure what to do with the options.  I see a function named
"getOptionChain" in the quantmod package, but that just returns a list
of puts and calls for a single date.  I have historical data for a few
years, and need to somehow munge it into a format that I can run through
blotter.

Thoughts:
    1) Lie to blotter.  Just makeup a symbol for the option.  (i.e Apple
April 15 calls at $200 becomes "AAPL_Call_0415_200")  and then set it up
in the environment to look/act like an equity.

    2) Figure out how blotter/quantmod expects to see option data,
format my data accordingly and then pass it off to blotter as a proper
option.

Can anyone provide some insight on this?

Thanks!

-- 
*Noah Silverman, PhD* | UCLA Department of Statistics
8117 Math Sciences Building, Los Angeles, CA 90095

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From dominykasgrigonis at gmail.com  Thu Apr 17 15:38:38 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Thu, 17 Apr 2014 14:38:38 +0100
Subject: [R-SIG-Finance] RQuantLib - Options value at maturity
In-Reply-To: <CABN+XoQVksUQTgCQMq02JsGBixyC+J9Zr+ghyJzhyxPGyEhZhQ@mail.gmail.com>
References: <CABN+XoQg00UWNqY4ayn_uK3Pw2wmEm4KOCT7OrXz5USbvn88-w@mail.gmail.com>
	<CABRT3xBo+PzQX4G6=cnRcpmz9m1jsu0WvjQSvO7-BBy614KEVw@mail.gmail.com>
	<CABN+XoQVksUQTgCQMq02JsGBixyC+J9Zr+ghyJzhyxPGyEhZhQ@mail.gmail.com>
Message-ID: <93C59B8A24824E1F934AC302ABB8D8DD@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140417/cb77492d/attachment.pl>

From chinmay.patil at gmail.com  Thu Apr 17 16:01:05 2014
From: chinmay.patil at gmail.com (Chinmay Patil)
Date: Thu, 17 Apr 2014 22:01:05 +0800
Subject: [R-SIG-Finance] Blotter and historical options
In-Reply-To: <534F179D.4060505@ucla.edu>
References: <534F179D.4060505@ucla.edu>
Message-ID: <3AA7B5E4-C7CB-4499-B1C7-7A6F317110AB@gmail.com>

I believe option 1 is the way to go. And it's not lying to blotter. Each option is supposed to be a FinancialInstrument. 

Chinmay

> On 17 Apr, 2014, at 7:51 am, Noah Silverman <noahsilverman at ucla.edu> wrote:
> 
>  1) Lie to blotter.  Just makeup a symbol for the option.  (i.e Apple
> April 15 calls at $200 becomes "AAPL_Call_0415_200")  and then set it up
> in the environment to look/act like an equity.


From pedrobtz at gmail.com  Thu Apr 17 16:11:30 2014
From: pedrobtz at gmail.com (Pedro Baltazar)
Date: Thu, 17 Apr 2014 15:11:30 +0100
Subject: [R-SIG-Finance] RQuantLib - Options value at maturity
In-Reply-To: <93C59B8A24824E1F934AC302ABB8D8DD@gmail.com>
References: <CABN+XoQg00UWNqY4ayn_uK3Pw2wmEm4KOCT7OrXz5USbvn88-w@mail.gmail.com>
	<CABRT3xBo+PzQX4G6=cnRcpmz9m1jsu0WvjQSvO7-BBy614KEVw@mail.gmail.com>
	<CABN+XoQVksUQTgCQMq02JsGBixyC+J9Zr+ghyJzhyxPGyEhZhQ@mail.gmail.com>
	<93C59B8A24824E1F934AC302ABB8D8DD@gmail.com>
Message-ID: <CABN+XoQ-Q3VRJvDG0Xf=YJhV8+PXVbZwcB_22vZ1TL=3ftTtAw@mail.gmail.com>

If they don't exists the function should return NA, right?

On Thu, Apr 17, 2014 at 2:38 PM, Dominykas Grigonis
<dominykasgrigonis at gmail.com> wrote:
> Theoretically greeks at maturity do not exist. If you want this, then you
> could just write your own if statement: value = max(S-K,0), delta =
> ifelse(S>K,1,0), gamma = ifelse(S=K, Inf, 0), vega = 0, theta =0?, rho = 0,
> divRho = 0
>
>
> Kind regards,
> --
> Dominykas Grigonis
>
> On Thursday, 17 April 2014 at 14:14, Pedro Baltazar wrote:
>
> The "theoretical" value of a call option at maturity is max(S-K,0).
>
> So, I am wondering if there is any a implementation justification not
> to put an some extra "if"s to check this corner cases
>
> Also, when using this function to calibrate other quantitities (where
> maturity is a variable) the fact that it gives zero for maturity=0,
> might have impact in finding max ou min.
>
> Thanks
>
> On Thu, Apr 17, 2014 at 2:04 PM, Ryan Abbate <ryan.abbate at gmail.com> wrote:
>
> The reason is that you define the maturity date as zero, even though this
> particular option is otherwise in-the-money. Try entering maturity = 1 and
> you'll have values that are intuitive.
>
> Hope this helps.
> -Ryan
>
>
> On Thu, Apr 17, 2014 at 8:54 AM, Pedro Baltazar <pedrobtz at gmail.com> wrote:
>
>
> Hello,
>
> why this package gives the value zero, and not (underlying - strike) =
> 50, at maturity?
>
> EuropeanOption("call", underlying=150, strike=100, dividendYield=0.00,
> riskFreeRate=0.03, maturity=0.0,volatility=0.2)
>
> Concise summary of valuation for EuropeanOption
> value delta gamma vega theta rho divRho
> 0 0 0 0 0 0 0
>
> Thanks
>
> --
> Pedro Baltazar
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
>
>
>
> --
> Pedro Baltazar
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
>



-- 
Pedro Baltazar


From dominykasgrigonis at gmail.com  Thu Apr 17 20:49:33 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Thu, 17 Apr 2014 19:49:33 +0100
Subject: [R-SIG-Finance] RQuantLib - Options value at maturity
In-Reply-To: <CABN+XoQ-Q3VRJvDG0Xf=YJhV8+PXVbZwcB_22vZ1TL=3ftTtAw@mail.gmail.com>
References: <CABN+XoQg00UWNqY4ayn_uK3Pw2wmEm4KOCT7OrXz5USbvn88-w@mail.gmail.com>
	<CABRT3xBo+PzQX4G6=cnRcpmz9m1jsu0WvjQSvO7-BBy614KEVw@mail.gmail.com>
	<CABN+XoQVksUQTgCQMq02JsGBixyC+J9Zr+ghyJzhyxPGyEhZhQ@mail.gmail.com>
	<93C59B8A24824E1F934AC302ABB8D8DD@gmail.com>
	<CABN+XoQ-Q3VRJvDG0Xf=YJhV8+PXVbZwcB_22vZ1TL=3ftTtAw@mail.gmail.com>
Message-ID: <28BA80517B0C4F73AD9758336F618A9A@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140417/5ce79871/attachment.pl>

From pedrobtz at gmail.com  Thu Apr 17 21:50:59 2014
From: pedrobtz at gmail.com (Pedro Baltazar)
Date: Thu, 17 Apr 2014 20:50:59 +0100
Subject: [R-SIG-Finance] RQuantLib - Options value at maturity
In-Reply-To: <28BA80517B0C4F73AD9758336F618A9A@gmail.com>
References: <CABN+XoQg00UWNqY4ayn_uK3Pw2wmEm4KOCT7OrXz5USbvn88-w@mail.gmail.com>
	<CABRT3xBo+PzQX4G6=cnRcpmz9m1jsu0WvjQSvO7-BBy614KEVw@mail.gmail.com>
	<CABN+XoQVksUQTgCQMq02JsGBixyC+J9Zr+ghyJzhyxPGyEhZhQ@mail.gmail.com>
	<93C59B8A24824E1F934AC302ABB8D8DD@gmail.com>
	<CABN+XoQ-Q3VRJvDG0Xf=YJhV8+PXVbZwcB_22vZ1TL=3ftTtAw@mail.gmail.com>
	<28BA80517B0C4F73AD9758336F618A9A@gmail.com>
Message-ID: <CABN+XoTPJDQY5Ot3VY4mVA_zS2G2RznXyR8HJBE8jVmQ6xb9Cg@mail.gmail.com>

Maybe with

    if (tau==0){
        out <- c(max(S0-K,0),rep(NA,8))
        colnames(out) <-
c("value","delta","lambda","gamma","vega","vomma","theta","rho","rhoQ")
    }else{

and the

Concise summary of valuation for EuropeanOption
 value  delta  gamma   vega  theta    rho divRho
     50     NA      NA      NA      NA      NA      NA



On Thu, Apr 17, 2014 at 7:49 PM, Dominykas Grigonis
<dominykasgrigonis at gmail.com> wrote:
> I guess you have a point?
>
> vaBSgreeks <- function(S0, K, r, d, tau, vol, opt){
>     if (tau==0){
>         out <- rep(NA,9)
>         colnames(out) <-
> c("value","delta","lambda","gamma","vega","vomma","theta","rho","rhoQ")
>     }else{
>         b = r-d
>         d_1  <- (log(S0/K)+(b+vol^2/2)*tau)/(vol*sqrt(tau));
>         d_2  <- (log(S0/K)+(b-vol^2/2)*tau)/(vol*sqrt(tau));
>         if(opt==0){
>             value   <-  S0*exp(-d*tau)*stats::pnorm(
> d_1,0,1)-K*exp(-r*tau)*stats::pnorm(d_2,0,1)
>             delta   <-  exp(-d*tau)*stats::pnorm( d_1,0,1)
>             gamma   <-
> (1/sqrt(2*pi)*exp(-d_1^2/2))/(S0*vol*sqrt(tau))*exp(-d*tau)
>             vega    <- S0*sqrt(tau)*(1/sqrt(2*pi)*exp(-d_1^2/2))*exp(-d*tau)
>             vomma   <- vega*d_1*d_2/vol
>             theta   <-
> -S0*(1/sqrt(2*pi)*exp(-d_1^2/2))*vol*exp(-d*tau)/(2*sqrt(tau))+
>
> d*S0*stats::pnorm(d_1,0,1)*exp(-d*tau)-r*K*exp(-r*tau)*stats::pnorm(d_2,0,1)
>             rho     <- K*tau*exp(-r*tau)*stats::pnorm(d_2,0,1)
>             rhoQ    <- -tau*exp(-d*tau)*S0*stats::pnorm(d_1,0,1)
>             lambda  <- delta*S0/value
>         }else if(opt==1){
>             value   <-
> -S0*exp(-d*tau)*stats::pnorm(-d_1,0,1)+K*exp(-r*tau)*stats::pnorm(-d_2,0,1)
>             delta   <- -exp(-d*tau)*stats::pnorm(-d_1,0,1)
>             gamma   <-
> (1/sqrt(2*pi)*exp(-d_1^2/2))/(S0*vol*sqrt(tau))*exp(-d*tau)
>             vega    <- S0*sqrt(tau)*(1/sqrt(2*pi)*exp(-d_1^2/2))*exp(-d*tau)
>             vomma   <- vega*d_1*d_2/vol
>             theta   <-
> -S0*(1/sqrt(2*pi)*exp(-d_1^2/2))*vol*exp(-d*tau)/(2*sqrt(tau))-
>
> d*S0*stats::pnorm(-d_1,0,1)*exp(-d*tau)+r*K*exp(-r*tau)*stats::pnorm(-d_2,0,1)
>             rho     <- -K*tau*exp(-r*tau)*stats::pnorm(-d_2,0,1)
>             rhoQ    <- tau*exp(-d*tau)*S0*stats::pnorm(-d_1,0,1)
>             lambda  <- delta*S0/value
>         }else{
>             stop("opt=0 means CALL; opt=1 means PUT")
>         }
>         return(cbind(value,delta,lambda,gamma,vega,vomma,theta,rho,rhoQ))
>     }
> }
>
> vaBSgreeks(100,100,0.05,0.05,1, 0.1,0)
>
>
> Kind regards,
> --
> Dominykas Grigonis
>
> On Thursday, 17 April 2014 at 15:11, Pedro Baltazar wrote:
>
> If they don't exists the function should return NA, right?
>
> On Thu, Apr 17, 2014 at 2:38 PM, Dominykas Grigonis
> <dominykasgrigonis at gmail.com> wrote:
>
> Theoretically greeks at maturity do not exist. If you want this, then you
> could just write your own if statement: value = max(S-K,0), delta =
> ifelse(S>K,1,0), gamma = ifelse(S=K, Inf, 0), vega = 0, theta =0?, rho = 0,
> divRho = 0
>
>
> Kind regards,
> --
> Dominykas Grigonis
>
> On Thursday, 17 April 2014 at 14:14, Pedro Baltazar wrote:
>
> The "theoretical" value of a call option at maturity is max(S-K,0).
>
> So, I am wondering if there is any a implementation justification not
> to put an some extra "if"s to check this corner cases
>
> Also, when using this function to calibrate other quantitities (where
> maturity is a variable) the fact that it gives zero for maturity=0,
> might have impact in finding max ou min.
>
> Thanks
>
> On Thu, Apr 17, 2014 at 2:04 PM, Ryan Abbate <ryan.abbate at gmail.com> wrote:
>
> The reason is that you define the maturity date as zero, even though this
> particular option is otherwise in-the-money. Try entering maturity = 1 and
> you'll have values that are intuitive.
>
> Hope this helps.
> -Ryan
>
>
> On Thu, Apr 17, 2014 at 8:54 AM, Pedro Baltazar <pedrobtz at gmail.com> wrote:
>
>
> Hello,
>
> why this package gives the value zero, and not (underlying - strike) =
> 50, at maturity?
>
> EuropeanOption("call", underlying=150, strike=100, dividendYield=0.00,
> riskFreeRate=0.03, maturity=0.0,volatility=0.2)
>
> Concise summary of valuation for EuropeanOption
> value delta gamma vega theta rho divRho
> 0 0 0 0 0 0 0
>
> Thanks
>
> --
> Pedro Baltazar
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
>
>
>
> --
> Pedro Baltazar
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
>
>
>
> --
> Pedro Baltazar
>
>



-- 
Pedro Baltazar


From dominykasgrigonis at gmail.com  Thu Apr 17 22:51:35 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Thu, 17 Apr 2014 21:51:35 +0100
Subject: [R-SIG-Finance] RQuantLib - Options value at maturity
In-Reply-To: <CABN+XoTPJDQY5Ot3VY4mVA_zS2G2RznXyR8HJBE8jVmQ6xb9Cg@mail.gmail.com>
References: <CABN+XoQg00UWNqY4ayn_uK3Pw2wmEm4KOCT7OrXz5USbvn88-w@mail.gmail.com>
	<CABRT3xBo+PzQX4G6=cnRcpmz9m1jsu0WvjQSvO7-BBy614KEVw@mail.gmail.com>
	<CABN+XoQVksUQTgCQMq02JsGBixyC+J9Zr+ghyJzhyxPGyEhZhQ@mail.gmail.com>
	<93C59B8A24824E1F934AC302ABB8D8DD@gmail.com>
	<CABN+XoQ-Q3VRJvDG0Xf=YJhV8+PXVbZwcB_22vZ1TL=3ftTtAw@mail.gmail.com>
	<28BA80517B0C4F73AD9758336F618A9A@gmail.com>
	<CABN+XoTPJDQY5Ot3VY4mVA_zS2G2RznXyR8HJBE8jVmQ6xb9Cg@mail.gmail.com>
Message-ID: <ADA338EF14434AC6B1D7762E7D6C7B2A@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140417/d39acc45/attachment.pl>

From kk2250 at optonline.net  Fri Apr 18 22:30:13 2014
From: kk2250 at optonline.net (Kris)
Date: Fri, 18 Apr 2014 16:30:13 -0400
Subject: [R-SIG-Finance] RQuantLib - Options value at maturity
In-Reply-To: <CABN+XoQg00UWNqY4ayn_uK3Pw2wmEm4KOCT7OrXz5USbvn88-w@mail.gmail.com>
References: <CABN+XoQg00UWNqY4ayn_uK3Pw2wmEm4KOCT7OrXz5USbvn88-w@mail.gmail.com>
Message-ID: <687C862F-9467-42AD-A678-48D2AFFCFBD3@optonline.net>

A workaround is instead of maturity =0, pass something very close to zero e.g.  maturity=1e-14 

Cheers
Krishna



> On Apr 17, 2014, at 8:54 AM, Pedro Baltazar <pedrobtz at gmail.com> wrote:
> 
> Hello,
> 
> why this package gives the value zero, and not (underlying - strike) =
> 50, at maturity?
> 
>> EuropeanOption("call", underlying=150, strike=100, dividendYield=0.00, riskFreeRate=0.03, maturity=0.0,volatility=0.2)
> Concise summary of valuation for EuropeanOption
> value  delta  gamma   vega  theta    rho divRho
>     0      0      0      0      0      0      0
> 
> Thanks
> 
> -- 
> Pedro Baltazar
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From gmonaie at gmail.com  Sat Apr 19 00:52:25 2014
From: gmonaie at gmail.com (Gei Lin)
Date: Fri, 18 Apr 2014 18:52:25 -0400
Subject: [R-SIG-Finance] Aligning time series
In-Reply-To: <9DE405308A6AA24AA794B76282C6C00F4A59367C44@HQ-POST1>
References: <9DE405308A6AA24AA794B76282C6C00F4A59367C44@HQ-POST1>
Message-ID: <CAJFvkccnjWBWHgZGn04EkWiLJxmX37hq9a5YQnAhYeyajhwW+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140418/42761ade/attachment.pl>

From faiube at gmail.com  Sat Apr 19 21:02:53 2014
From: faiube at gmail.com (fernando)
Date: Sat, 19 Apr 2014 12:02:53 -0700 (PDT)
Subject: [R-SIG-Finance] Multiple regression information criterion
Message-ID: <1397934173170-4689113.post@n4.nabble.com>

Please,
I am running a multiple regression
on assets excess returns on mkt excess returns.
I would like to get the AIC from these regressions
and the response was

Error in logLik.lm(object) : 
  'logLik.lm' does not support multiple responses

Does anyone could help me with this issue?
Thanks
Fernando



--
View this message in context: http://r.789695.n4.nabble.com/Multiple-regression-information-criterion-tp4689113.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From dominykasgrigonis at gmail.com  Sat Apr 19 21:30:22 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sat, 19 Apr 2014 20:30:22 +0100
Subject: [R-SIG-Finance] Multiple regression information criterion
In-Reply-To: <1397934173170-4689113.post@n4.nabble.com>
References: <1397934173170-4689113.post@n4.nabble.com>
Message-ID: <4CC61E7D7F664AADAD4C9CC094C1B246@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140419/6914b276/attachment.pl>

From faiube at gmail.com  Sat Apr 19 21:49:09 2014
From: faiube at gmail.com (fernando)
Date: Sat, 19 Apr 2014 12:49:09 -0700 (PDT)
Subject: [R-SIG-Finance] Multiple regression information criterion
In-Reply-To: <4CC61E7D7F664AADAD4C9CC094C1B246@gmail.com>
References: <1397934173170-4689113.post@n4.nabble.com>
	<4CC61E7D7F664AADAD4C9CC094C1B246@gmail.com>
Message-ID: <1397936949378-4689115.post@n4.nabble.com>

Hi Dominykas,

No, it is a plain vanilla code. Thanks
Fernando



--
View this message in context: http://r.789695.n4.nabble.com/Multiple-regression-information-criterion-tp4689113p4689115.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From dominykasgrigonis at gmail.com  Sat Apr 19 21:54:02 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sat, 19 Apr 2014 20:54:02 +0100
Subject: [R-SIG-Finance] Multiple regression information criterion
In-Reply-To: <1397936949378-4689115.post@n4.nabble.com>
References: <1397934173170-4689113.post@n4.nabble.com>
	<4CC61E7D7F664AADAD4C9CC094C1B246@gmail.com>
	<1397936949378-4689115.post@n4.nabble.com>
Message-ID: <4B486AAB7C7341FBA9745A13C49AC56A@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140419/17422c1c/attachment.pl>

From dominykasgrigonis at gmail.com  Sat Apr 19 22:20:54 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sat, 19 Apr 2014 21:20:54 +0100
Subject: [R-SIG-Finance] Multiple regression information criterion
In-Reply-To: <1397934173170-4689113.post@n4.nabble.com>
References: <1397934173170-4689113.post@n4.nabble.com>
Message-ID: <CB8EB1D2231243C0B440AD30EEA55EA6@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140419/cddf1cf8/attachment.pl>

From ilya.kipnis at gmail.com  Sun Apr 20 04:19:05 2014
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Sat, 19 Apr 2014 19:19:05 -0700
Subject: [R-SIG-Finance] Fw: stochastic oscillator OBOS - intraday data
	& optimization
In-Reply-To: <1397716877.71309.YahooMailNeo@web186002.mail.ir2.yahoo.com>
References: <1397165204.93071.YahooMailNeo@web186001.mail.ir2.yahoo.com>
	<1397716877.71309.YahooMailNeo@web186002.mail.ir2.yahoo.com>
Message-ID: <CA+oJuEG70Zf1UeP7Tg8qxke6NfwVzAtgv9BPPEpcEL1Dk2zBQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140419/7d8016e5/attachment.pl>

From ilya.kipnis at gmail.com  Mon Apr 21 00:38:12 2014
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Sun, 20 Apr 2014 15:38:12 -0700
Subject: [R-SIG-Finance] Fw: stochastic oscillator OBOS - intraday data
	& optimization
In-Reply-To: <1398029149.47283.YahooMailNeo@web186002.mail.ir2.yahoo.com>
References: <1397165204.93071.YahooMailNeo@web186001.mail.ir2.yahoo.com>
	<1397716877.71309.YahooMailNeo@web186002.mail.ir2.yahoo.com>
	<CA+oJuEG70Zf1UeP7Tg8qxke6NfwVzAtgv9BPPEpcEL1Dk2zBQA@mail.gmail.com>
	<1398029149.47283.YahooMailNeo@web186002.mail.ir2.yahoo.com>
Message-ID: <CA+oJuEERywhrMxvMtn3nV8VvK53h-XBJ8BJG6A3SCCzKZh7MSg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140420/77fda9fb/attachment.pl>

From a.chandhial at btinternet.com  Mon Apr 21 09:03:04 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Mon, 21 Apr 2014 08:03:04 +0100 (BST)
Subject: [R-SIG-Finance] Fw: stochastic oscillator OBOS - intraday data
	& optimization
In-Reply-To: <CA+oJuEERywhrMxvMtn3nV8VvK53h-XBJ8BJG6A3SCCzKZh7MSg@mail.gmail.com>
References: <1397165204.93071.YahooMailNeo@web186001.mail.ir2.yahoo.com>
	<1397716877.71309.YahooMailNeo@web186002.mail.ir2.yahoo.com>
	<CA+oJuEG70Zf1UeP7Tg8qxke6NfwVzAtgv9BPPEpcEL1Dk2zBQA@mail.gmail.com>
	<1398029149.47283.YahooMailNeo@web186002.mail.ir2.yahoo.com>
	<CA+oJuEERywhrMxvMtn3nV8VvK53h-XBJ8BJG6A3SCCzKZh7MSg@mail.gmail.com>
Message-ID: <1398063784.81321.YahooMailNeo@web186001.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140421/0524f658/attachment.pl>

From Uniraf at gmail.com  Mon Apr 21 12:18:37 2014
From: Uniraf at gmail.com (Chris Urlaub)
Date: Mon, 21 Apr 2014 03:18:37 -0700 (PDT)
Subject: [R-SIG-Finance] simple GARCH model
Message-ID: <1398075517214-4689179.post@n4.nabble.com>

Hi,

I'm still trying to implement the GARCH MIDAS model of Engle et al (2013) in
R, but I've still many problems. Therefore I wanted to start with
programming a simple GARCH (1,1) model and refine it step by step.
Surprisingly, the simple model already does not run and gives warnings and
I've no idea what's wrong. Maybe someone knows why the code doesn't work and
warnings are produced.
The code is taken from the "We think before we R" blog and only differs from
the original code in the data used. Here it is:

pseudoreturns= rnorm(3000, 0.0004, 0.016) 
data=list(Component1 = pseudoreturns)

# Specifying functions:

CalcResiduals <- function(th, data) {

  th[1] -> mean
  th[2] -> alpha.0
  th[3] -> alpha.1
  th[4] -> beta.1

  
  e <- data$Component1
  
  
  n <- length(y)
  sigma.sqs <- vector(length=n)
  sigma.sqs[1] <- 1
  for(ii in c(1:(n-1))) { ## This loop is where the h_t are calculated
    sigma.sqs[ii + 1] <- (
      alpha.0 +
        alpha.1 * (e[ii] - mean) ^ 2 +
        beta.1 * sigma.sqs[ii])
  }
  
  return(list(et = e, ht = sigma.sqs)) # Returns the list of e_t and h_t
}




GarchLogL <- function(th, data) {
  
  res <- CalcResiduals(th, data) ## Recall our earlier function
CalcResiduals()
  sigma.sqs <- res$ht
  e <- res$et
  
  # Assuming normal density of the errors dnorm() gives the density of
normal dist.
  # this will return the negative of the log likelihood.
  return (-sum(dnorm(e[-1], mean=th[1] , sd=sqrt(sigma.sqs[-1]), log=TRUE)))
}


fit2 <- nlm(GarchLogL, # function call
            p = c(0.1,0.1,0.1,0.8), 
            hessian = TRUE,
            data <- data , 
            iterlim = 500) 



Any help would be appreciated!

Thanks,

Chris



--
View this message in context: http://r.789695.n4.nabble.com/simple-GARCH-model-tp4689179.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From markknecht at gmail.com  Mon Apr 21 16:15:39 2014
From: markknecht at gmail.com (Mark Knecht)
Date: Mon, 21 Apr 2014 07:15:39 -0700
Subject: [R-SIG-Finance] simple GARCH model
In-Reply-To: <1398075517214-4689179.post@n4.nabble.com>
References: <1398075517214-4689179.post@n4.nabble.com>
Message-ID: <CAK2H+eeQZLcgnHhhz8_jWxUdTeqEu0_F3a-k3XY3cCBxafrehg@mail.gmail.com>

<SNIP>
>   n <- length(y)
<SNIP>


Tried running your code here. y is undefined. Fix that for a start.

HTH,
Mark


From markknecht at gmail.com  Mon Apr 21 16:28:52 2014
From: markknecht at gmail.com (Mark Knecht)
Date: Mon, 21 Apr 2014 07:28:52 -0700
Subject: [R-SIG-Finance] simple GARCH model
In-Reply-To: <CAK2H+eeQZLcgnHhhz8_jWxUdTeqEu0_F3a-k3XY3cCBxafrehg@mail.gmail.com>
References: <1398075517214-4689179.post@n4.nabble.com>
	<CAK2H+eeQZLcgnHhhz8_jWxUdTeqEu0_F3a-k3XY3cCBxafrehg@mail.gmail.com>
Message-ID: <CAK2H+edAQ3jJn3iBQG84k=m8BypEr-eLjpgHa8=i_ihF-g3Y_w@mail.gmail.com>

On Mon, Apr 21, 2014 at 7:15 AM, Mark Knecht <markknecht at gmail.com> wrote:
> <SNIP>
>>   n <- length(y)
> <SNIP>
>
>
> Tried running your code here. y is undefined. Fix that for a start.
>
> HTH,
> Mark

Additionally, it looks like when you call nl, at the bottom:

fit2 <- nlm(GarchLogL, # function call
            p = c(0.1,0.1,0.1,0.8),
            hessian = TRUE,
            data <- data ,
            iterlim = 500)

that the call to GarchLogL function isn't given any inputs.  For
clarity about my comment (not your code) I'd expect to see something
more like the following with X1 & Y1 supplied?

temp1 = GarchLogL(X1,Y1)

fit2 <- nlm(temp1, # function call
            p = c(0.1,0.1,0.1,0.8),
            hessian = TRUE,
            data <- data ,
            iterlim = 500)


From adamno227 at gmail.com  Wed Apr 23 16:53:01 2014
From: adamno227 at gmail.com (Adam Ginensky)
Date: Wed, 23 Apr 2014 09:53:01 -0500
Subject: [R-SIG-Finance] Scaling and Clustering of Financial Data
Message-ID: <CAEEj48kpiWhKyusHWEhDQCPShF80hup2__jzvSQBK47YTnt7OA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140423/038aa3a4/attachment.pl>

From aschmid1 at stevens.edu  Wed Apr 23 17:41:31 2014
From: aschmid1 at stevens.edu (aschmid1)
Date: Wed, 23 Apr 2014 11:41:31 -0400
Subject: [R-SIG-Finance] Scaling and Clustering of Financial Data
In-Reply-To: <CAEEj48kpiWhKyusHWEhDQCPShF80hup2__jzvSQBK47YTnt7OA@mail.gmail.com>
References: <CAEEj48kpiWhKyusHWEhDQCPShF80hup2__jzvSQBK47YTnt7OA@mail.gmail.com>
Message-ID: <2f7c8f3cb7132ce2ca423fb6d62d2531@stevens.edu>

One way to deal with variables of different nature/units is to scale 
them with their standard deviations.

On 04/23/2014 10:53 AM, Adam Ginensky wrote:
> I'm looking at clustering of stocks based on their fundamental 
> financial
> data.  I have about 80 variables per stock.  I have the standard 
> k-means
> package.  Firstly, I am wondering if there are any other R packages 
> that
> may be more useful for clustering of financial data.
> My second, and more important (to me), question is- Should one scale 
> the
> data before clustering.  I'm particularly worried  that since  certain
> variables can be orders of magnitude larger than other equally 
> interesting
> variables (-think market cap and p/e).  I realize this is not an R 
> question
> per se, but I feel I am more likely to get a good answer out of this 
> forum
> than any other because of the concentration of financial practitioners. 
> Of
> course, I apologize in advance, if it is too 'off-topic' and then 
> simply
> ask for a better place to post.  Thanks.
> 
> Adam Ginensky
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R
> questions should go.


From berkorbay at gmail.com  Wed Apr 23 20:57:02 2014
From: berkorbay at gmail.com (Berk Orbay)
Date: Wed, 23 Apr 2014 21:57:02 +0300
Subject: [R-SIG-Finance] Scaling and Clustering of Financial Data
In-Reply-To: <2f7c8f3cb7132ce2ca423fb6d62d2531@stevens.edu>
References: <CAEEj48kpiWhKyusHWEhDQCPShF80hup2__jzvSQBK47YTnt7OA@mail.gmail.com>
	<2f7c8f3cb7132ce2ca423fb6d62d2531@stevens.edu>
Message-ID: <CAGKHJd9_GAHFF+yYxBgkh0gn2es0Zvrce7n405GxJhSL0v5wEQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140423/be7fcc13/attachment.pl>

From dominykasgrigonis at gmail.com  Wed Apr 23 21:40:00 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Wed, 23 Apr 2014 20:40:00 +0100
Subject: [R-SIG-Finance] Scaling and Clustering of Financial Data
In-Reply-To: <CAEEj48kpiWhKyusHWEhDQCPShF80hup2__jzvSQBK47YTnt7OA@mail.gmail.com>
References: <CAEEj48kpiWhKyusHWEhDQCPShF80hup2__jzvSQBK47YTnt7OA@mail.gmail.com>
Message-ID: <6C1BD35E98B9463496EDC83F07F742A9@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140423/6788e2e1/attachment.pl>

From a.chandhial at btinternet.com  Thu Apr 24 09:00:26 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Thu, 24 Apr 2014 08:00:26 +0100 (BST)
Subject: [R-SIG-Finance] Fw: stochastic oscillator OBOS - intraday data
	& optimization
In-Reply-To: <1398063784.81321.YahooMailNeo@web186001.mail.ir2.yahoo.com>
References: <1397165204.93071.YahooMailNeo@web186001.mail.ir2.yahoo.com>
	<1397716877.71309.YahooMailNeo@web186002.mail.ir2.yahoo.com>
	<CA+oJuEG70Zf1UeP7Tg8qxke6NfwVzAtgv9BPPEpcEL1Dk2zBQA@mail.gmail.com>
	<1398029149.47283.YahooMailNeo@web186002.mail.ir2.yahoo.com>
	<CA+oJuEERywhrMxvMtn3nV8VvK53h-XBJ8BJG6A3SCCzKZh7MSg@mail.gmail.com>
	<1398063784.81321.YahooMailNeo@web186001.mail.ir2.yahoo.com> 
Message-ID: <1398322826.12657.YahooMailNeo@web186003.mail.ir2.yahoo.com>



Hi IIya,


I have run optimizations for GBPUSD 30min data, 3528 (8*21*21) combinations. Thereafter, I divided the tradeStats on the?nSlowD variable and generated heat-maps?& 3D-Graphs for various parameters, viewing lowThresh?vs highThresh.?Maybe there's a better way?of doing this.?I have checked the values given?via the optimizations?with an individual run of the strategy and the results equate. Please check???As of only?10 days of data,?the strategy does not generate many trades. It's up to the reader to?determine values for nSlowD, lowThresh?& highThresh given the plethora of graphs; indeed?rationale for 'optimal'?values along these lines is given on p51-p55? Jaekle & Tomasini (2009). With more data I'd like to do an IS vs OOS test,?in addition to a?periodic optimized walk-forward,?that's for later; of course?being mindful of?the pitfalls of over-optimization and non-parsimony. 


Question:


(a) Are the inequalities correct with regard to add.distribution ?

The inequalities?in the add.distributions for the?long-only GBPUSD (enter a trade?buy GBP sell USD; and to exit a trade sell GBP and buy USD) strategy are:
slowD.stoch.ind.gt.20
slowD.stoch.ind.gte.80


Likewise, to include a short-side?(enter a trade?sell GBP?buy USD; and to exit a trade?buy GBP and?sell USD)?the add.distributions would be:
slowD.stoch.ind.lte.20
slowD.stoch.ind.lt.80



Attached are:
(a)?program for?calculating the optimizations?& generating the?graphs. NB: half-way in?the program the reader can load the RData tradeStats data and simply generate the graphs?not?running the optimizations.
(b) RData file with tradeStats of 3528 optimizations


Please check if all is okay with optimizations. If there's a better way of graphing be free to make?the improvements.


Thereafter?I'd like?to get the timefilter optimized. 



Amarjit





 
 From: amarjit chandhial <a.chandhial at btinternet.com>
To: Ilya Kipnis <ilya.kipnis at gmail.com>; "r-sig-finance at r-project.org" <r-sig-finance at r-project.org> 
Sent: Monday, 21 April 2014, 8:03
Subject: Re: [R-SIG-Finance] Fw: stochastic oscillator OBOS - intraday data & optimization
  


Hi IIya,


Have reinstalled quantstrat and I get results! Hooorrraaayyy ;-)

I will try on GBPUSD, produce graphs, and then try a relevant intraday timefilter with optimization.


Amarjit

?




________________________________
From: Ilya Kipnis <ilya.kipnis at gmail.com>
To: amarjit chandhial <a.chandhial at btinternet.com>; "r-sig-finance at r-project.org" <r-sig-finance at r-project.org> 
Sent: Sunday, 20 April 2014, 23:38
Subject: Re:
 [R-SIG-Finance] Fw: stochastic oscillator OBOS - intraday data & optimization



Amarjit,

Can you reinstall the quantstrat package and copy and paste the applyStrategy call from inside apply.paramset says?

Thanks.

-Ilya


On Sun, Apr 20, 2014 at 2:25 PM, amarjit chandhial <a.chandhial at btinternet.com> wrote:


>
>Hi IIya,
>
>
>
>
>Have run the program as in email and I cannot generate results on either windows or linux. 
>
>
>
>with 
>
>
>
>error calling combine function:
><simpleError in fun(result.1, result.2, result.3, result.4, result.5, result.6,????
result.7, result.8, result.9, result.10, result.11, result.12,???? result.13,
 result.14, result.15, result.16,
 result.17, result.18,???? result.19, result.20, result.21, result.22, result.23, result.24,???? result.25, result.26, result.27, result.28, result.29, result.30,???? result.31, result.32, result.33, result.34, result.35, result.36,???? result.37, result.38, result.39, result.40, result.41, result.42,???? result.43, result.44, result.45, result.46, result.47, result.48,???? result.49,
result.50): attempt to select less than one element>
>
>
>
>
>Have also tried variations on labels e.g. add.distribution?component.label="slowD.stoch.ind.gte.80", as the signal is applied in the add.rule.
>
>
>
>Here's the packages on linux with rev. 
>
>
>
>Please
 advise.
>
>
>
>
>
>Amarjit
>
>
>
>
>
>
>
>
>
>R version 3.1.0 (2014-04-10)
>Platform:
x86_64-pc-linux-gnu (64-bit)
>
>locale:
>?[1] LC_CTYPE=en_GB.UTF-8?????? LC_NUMERIC=C??????????????
LC_TIME=en_GB.UTF-8??????? LC_COLLATE=en_GB.UTF-8???? LC_MONETARY=en_GB.UTF-8?? 
>?[6] LC_MESSAGES=en_GB.UTF-8??? LC_PAPER=en_GB.UTF-8?????? LC_NAME=C?????????????????
LC_ADDRESS=C??????????????
 LC_TELEPHONE=C??????????? 
>[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C??????
>
>attached base packages:
>[1] stats???? graphics? grDevices utils???? datasets? methods?? base???? 
>
>other attached packages:
>?[1] quantstrat_0.8.2 (1598) ???????? foreach_1.4.2 (25) ??????????? blotter_0.8.18 (1599) ?????????? PerformanceAnalytics_1.1.4 (3362) ??? FinancialInstrument_1.1.9 (1529)
>?[6] quantmod_0.4-1 (610)
??????????
 Defaults_1.1-1????????????????? TTR_0.22-0.1 (177) ???????????? xts_0.9-7 (803) ???????????????????????????????? zoo_1.7-11 (973) ????????????? 
>
>loaded via a namespace (and not attached):
>[1] codetools_0.2-8 grid_3.1.0????? iterators_1.0.7 lattice_0.20-29 tools_3.1.0??? 
>
>
>
>
>
>
>From: Ilya Kipnis <ilya.kipnis at gmail.com>
>To: amarjit chandhial <a.chandhial at btinternet.com>; "r-sig-finance at r-project.org" <r-sig-finance at r-project.org> 
>Sent: Sunday, 20 April 2014, 3:19
>Subject: Re: [R-SIG-Finance] Fw: stochastic oscillator OBOS - intraday data & optimization
> 
>
>
>Amarjit,
>
>I got it. While I didn't fix up the GBPUSD demo, I did this using the google demo.
>
>The critical issue is that in order to optimize a component, the component needs a label. The reason you were getting your error (as far as I can deduce) is that you didn't label the indicator, and
 therefore, had no label to which to hook the indicator optimization distribution.
>
>In any case, I've attached the salient
 aspects of the demo to demonstrate.
>
>
>###INITIAL STRATEGY
>
>
>library(quantstrat)
>
>
>osMaxDollar <- function(data, timestamp, orderqty, ordertype, orderside,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? portfolio, symbol, prefer="Open", tradeSize,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? maxSize, integerShares=FALSE,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ...) {
>? pos <- getPosQty(portfolio, symbol, timestamp)
>? if(prefer=="Close") {
>? ? price <- as.numeric(Cl(mktdata[timestamp,]))
>? } else {
>? ? price <- as.numeric(Op(mktdata[timestamp,]))
>? }
>? posVal <-
 pos*price
>? if (orderside=="short") {
>? ? dollarsToTransact <- max(tradeSize, posVal-maxSize)
>? } else {
>? ? dollarsToTransact <- min(tradeSize, maxSize-posVal)
>? }
>? qty <- dollarsToTransact/price
>? if(integerShares) {
>? ? if(qty > 0) {
>? ? ? qty <- floor(qty)
>? ? }?
>? ? if(qty < 0) {
>? ? ? qty <- ceiling(qty)
>? ? }
>? }
>? return(qty)
>}
>
>
>rm(list=ls(.blotter), envir=.blotter)
>initDate='2000-12-31'
>initEq=10000
>
>
>currency('USD')
>Sys.setenv(TZ="UTC")
>
>
>symbols <- c("USO")
>
>
>stock(symbols, currency="USD", multiplier=1)
>getSymbols(symbols, src='yahoo',?
>? ? ?
 ? ? ?index.class=c("POSIXt","POSIXct"),
>? ? ? ? ? ?from = "2009-01-01", to="2013-12-31", adjust=TRUE)
>
>
>strategy.st="GOOGstoch"
>portfolio.st="GOOGstoch"
>account.st="GOOGstoch"
>
>
>rm.strat(portfolio.st)
>rm.strat(strategy.st)
>initPortf(portfolio.st, symbols=symbols, initDate=initDate, currency='USD')
>initAcct(account.st, portfolios=portfolio.st, initDate=initDate, currency='USD', initEq=initEq)
>initOrders(portfolio.st, initDate=initDate)
>strategy(strategy.st, store=TRUE)
>
>
>################## indicators and parameters ##############
>
>
>nFastK = 20
>nFastD = 3
>nSlowD = 5
>maType="SMA"
>.orderqty=1000
>.txn=0
>
>
>add.indicator(strategy.st, name = "stoch",
>? ? ? ? ? ? ? arguments =
 list(HLC = quote(HLC(mktdata)), nFastK=nFastK,?
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?nFastD=nFastD,nSlowD=nSlowD, maType=maType),
>? ? ? ? ? ? ? label="stoch") ?#NOTICE THE LABEL HERE.
>
>
>
>
>################### signals ###################3#######
>add.signal(strategy.st, name="sigThreshold",
>? ? ? ? ? ?arguments = list(threshold=0.20,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? column="slowD.stoch",
>? ? ? ? ? ? ? ? ? ? ? ? ? ? relationship="gt",
>? ? ? ? ? ? ? ? ? ? ? ? ? ? cross=TRUE),
>? ? ? ? ?
 ?label="slowD.stoch.ind.gt.20")
>
>
>add.signal(strategy.st,
>? ? ? ? ? ?name="sigThreshold",
>? ? ? ? ? ?arguments = list(threshold=0.80,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? column="slowD.stoch",
>? ? ? ? ? ? ? ? ? ? ? ? ? ? relationship="lt",
>? ? ? ? ? ? ? ? ? ? ? ? ? ? cross=TRUE),
>? ? ? ? ? ?label="slowD.stoch.ind.lt.80")
>
>
>add.signal(strategy.st,
>? ? ? ? ? ?name="sigThreshold",
>? ? ? ? ? ?arguments = list(threshold=0.80,
>? ? ? ? ? ? ? ? ? ? ?
 ? ? ? column="slowD.stoch",
>? ? ? ? ? ? ? ? ? ? ? ? ? ? relationship="gte",
>? ? ? ? ? ? ? ? ? ? ? ? ? ? cross=TRUE),
>? ? ? ? ? ?label="slowD.stoch.ind.gte.80")
>
>
>add.signal(strategy.st,
>? ? ? ? ? ?name="sigThreshold",
>? ? ? ? ? ?arguments = list(threshold=0.20,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? column="slowD.stoch",
>? ? ? ? ? ? ? ? ? ? ? ? ? ? relationship="lte",
>? ? ? ? ? ? ? ? ? ? ? ? ? ? cross=TRUE),
>? ? ? ?
 ? ?label="slowD.stoch.ind.lte.20")
>
>
>################# long rules ########################
>
>
>add.rule(strategy.st,
>? ? ? ? ?name='ruleSignal',
>? ? ? ? ?arguments = list(sigcol="slowD.stoch.ind.gte.80",
>? ? ? ? ? ? ? ? ? ? ? ? ? sigval=TRUE,
>? ? ? ? ? ? ? ? ? ? ? ? ? orderqty='all',
>? ? ? ? ? ? ? ? ? ? ? ? ? ordertype='market',
>? ? ? ? ? ? ? ? ? ? ? ? ? TxnFees=.txn,
>? ? ? ? ? ? ? ? ? ? ? ? ? orderside='long',
>? ? ? ? ? ? ? ? ? ?
 ? ? ? #pricemethod='market',
>? ? ? ? ? ? ? ? ? ? ? ? ? replace=FALSE),
>? ? ? ? ?label='Exit2SHORT', type='exit', path.dep=TRUE)
>
>
>stratstoch <- add.rule(strategy.st,
>? ? ? ? ? ? ? ? ? ? ? ?name='ruleSignal',
>? ? ? ? ? ? ? ? ? ? ? ?arguments = list(sigcol="slowD.stoch.ind.gt.20",
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sigval=TRUE,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? orderqty=100,
>? ? ? ? ? ? ? ? ? ? ?
 ? ? ? ? ? ? ? ? ? ordertype='market',
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? TxnFees=0,?
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? orderside='long',
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? #pricemethod='market',
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? tradeSize=.orderqty,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? maxSize=initEq,
>? ? ? ? ? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? replace=FALSE,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? osFUN=osMaxDollar),?
>? ? ? ? ? ? ? ? ? ? ? ?label='EnterLONG', type='enter', path.dep=TRUE)
>
>
>############# short rules ##################
>
>
>#stratstoch <- add.rule(strategy.st,
># ? ? ? ? ? ? ? ? ? ? ? name='ruleSignal',
># ? ? ? ? ? ? ? ? ? ? ? arguments = list(sigcol="slowD.stoch.ind.lte.20",
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?sigval=TRUE,
>#
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?orderqty='all',
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?ordertype='market',
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?TxnFees=.txn,
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?orderside='short',
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?#pricemethod='market',
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 ?replace=FALSE),
># ? ? ? ? ? ? ? ? ? ? ? label='Exit2LONG', type='exit', path.dep=TRUE)
>
>
>#stratstoch <- add.rule(strategy.st,
># ? ? ? ? ? ? ? ? ? ? ? name='ruleSignal',
># ? ? ? ? ? ? ? ? ? ? ? arguments = list(sigcol="slowD.stoch.ind.lt.80",
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?sigval=TRUE,
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?orderqty=100,
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?ordertype='market',
># ?
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?TxnFees=0, ?
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?orderside='short',
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?#pricemethod='market',
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?replace=FALSE,
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?tradeSize=-.orderqty,
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 ?maxSize=initEq,
># ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?osFUN=osMaxDollar),
># ? ? ? ? ? ? ? ? ? ? ? label='EnterSHORT', type='enter', path.dep=TRUE)
>
>
>Optimization:
>
>
>.nSlowD <- seq(from=3, to=10, by=1)
>.nLower <- seq(from=.10, to=.30, by=.05)
>.nUpper <- seq(from=.70, to=.90, by=.05)
>.nsamples = 50
>
>
>add.distribution(strategy.st,
>? ? ? ? ? ? ? ? ?paramset.label="stochDist",
>? ? ? ? ? ? ? ? ?component.type='indicator',
>? ? ? ? ? ? ? ? ?component.label="stoch", #THE COMPONENT LABEL IS THE LABEL ARGUMENT FROM THE ADD.INDICATOR
 FUNCTION.
>? ? ? ? ? ? ? ? ?variable=list(nSlowD=.nSlowD),
>? ? ? ? ? ? ? ? ?label="nSlowDdist")
>
>
>add.distribution(strategy.st,
>? ? ? ? ? ? ? ? ?paramset.label="stochDist",
>? ? ? ? ? ? ? ? ?component.type="signal",
>? ? ? ? ? ? ? ? ?component.label="slowD.stoch.ind.gt.20",
>? ? ? ? ? ? ? ? ?variable=list(threshold=.nLower),
>? ? ? ? ? ? ? ? ?label="lowThreshDist"
>? ? ? ? ? ? ? ? ?)
>
>
>add.distribution(strategy.st,
>? ? ? ? ? ? ? ?
 ?paramset.label="stochDist",
>? ? ? ? ? ? ? ? ?component.type="signal",
>? ? ? ? ? ? ? ? ?component.label="slowD.stoch.ind.lt.80",
>? ? ? ? ? ? ? ? ?variable=list(threshold=.nUpper),
>? ? ? ? ? ? ? ? ?label="highThreshDist"
>)
>
>
>save.strategy(strategy.st)
>
>
>require(doMC)
>registerDoMC(cores=8)
>
>
>results <- apply.paramset(strategy.st,
>? ? ? ? ? ? ? ? ? ? ? ? ? paramset.label='stochDist',
>? ? ? ? ? ? ? ? ? ? ? ? ? portfolio.st=portfolio.st,
>? ? ? ? ? ? ? ? ? ? ? ?
 ? account.st=account.st,
>? ? ? ? ? ? ? ? ? ? ? ? ? nsamples = .nsamples,
>? ? ? ? ? ? ? ? ? ? ? ? ? audit = NULL,
>? ? ? ? ? ? ? ? ? ? ? ? ? verbose=TRUE)
>
>
>print(results$tradeStats)
>
>
>
>
>
>On Wed, Apr 16, 2014 at 11:41 PM, amarjit chandhial <a.chandhial at btinternet.com> wrote:
>
>
>>
>>
>>
>>
>>
>>Can someone provide guidance on getting the optimization
 working.
>>
>>
>>
>>
>>Amarjit
>>
>>
>>
>>
>>
>>
>>
>>
>>----- Forwarded Message -----
>>From: amarjit chandhial <a.chandhial at btinternet.com>
>>To: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org> 
>>Sent: Thursday, 10 April 2014, 22:26
>>Subject: [R-SIG-Finance] stochastic oscillator OBOS - intraday data & optimization
>> 
>>
>>
>>
>>
>>All,
>>
>>
>>
>>
>>Iiya and I?have implemented a
 stochastic oscillator OBOS strategy?within quantstrat.
>>
>>
>>I?have?then?applied quantstrat's intraday GBPUSD data, 30min frequency with the strategy, including transaction costs (as in the other demos).
>>
>>
>>Thereafter I have attempted to optimize various values e.g.
>>
>>
>>(i) nSlowD, vary from 1-to-10
>>(ii) the lower level (over-sold) vary from .10-to-.30
>>(ii) the upper level (over-bought) vary from .70-to-.90
>>
>>
>>
>>
>>I get the error 
>>
>>
>>error calling combine function:
>><simpleError in fun(result.1, result.2, result.3, result.4, result.5, result.6, result.7, result.8, result.9,..., result.100):
attempt to select less than one element>
>>
>>
>>Attached are both programs: initial strategy and
 optimization.
>>
>>
>>
>>
>>
>>
>>An?error?corresponding to this from last month?http://r-forge.r-project.org/forum/forum.php?set=custom&forum_id=1032&style=nested&max_rows=100&submit=Change+View
>>
>>
>>
>>
>>Please help!
>>
>>
>>Amarjit
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>_______________________________________________
>>R-SIG-Finance at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>-- Subscriber-posting only. If you want to post, subscribe first.
>>-- Also note that this is not the r-help list where general R questions should go.
>>
>>
>>_______________________________________________
>>R-SIG-Finance at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>-- Subscriber-posting only. If you want to post, subscribe first.
>>-- Also note that this is not the r-help list where general R questions should go.
>>
>
>
>
???
 [[alternative HTML version deleted]]


_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140424/e487e75e/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_vanilla_and_optimization.R
Type: application/octet-stream
Size: 12842 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140424/e487e75e/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: GBPUSDStoch.ALLcombinations.RData
Type: application/x-gzip-compressed
Size: 212404 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140424/e487e75e/attachment.bin>

From bbands at gmail.com  Thu Apr 24 23:01:48 2014
From: bbands at gmail.com (BBands)
Date: Thu, 24 Apr 2014 14:01:48 -0700
Subject: [R-SIG-Finance] index creation
Message-ID: <CAGS5yBV4aF6mttQ1cXnWyZnuQRtg_LXgke+tB1bKSftrBqoJgA@mail.gmail.com>

Hi All,

Is there are elegant way to create security indices in R? I am
specifically thinking of things like equal-weighted industry group or
market sector indexes. I can do it the brute force way, but I can't
help but suspecting that there is a nice index constructor or
something similar lying about in some package that I haven't noticed.

Best regards to all,

      John


From adamno227 at gmail.com  Thu Apr 24 23:21:20 2014
From: adamno227 at gmail.com (Adam Ginensky)
Date: Thu, 24 Apr 2014 16:21:20 -0500
Subject: [R-SIG-Finance] Scaling and Clustering of Financial Data
In-Reply-To: <6C1BD35E98B9463496EDC83F07F742A9@gmail.com>
References: <CAEEj48kpiWhKyusHWEhDQCPShF80hup2__jzvSQBK47YTnt7OA@mail.gmail.com>
	<6C1BD35E98B9463496EDC83F07F742A9@gmail.com>
Message-ID: <CAEEj48mfTu2d7MU0LiNzQo99XkNLgoQd9hA2-dnkyHy0o_16kg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140424/23e5a843/attachment.pl>

From jzmoser at gmail.com  Thu Apr 24 23:35:11 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Thu, 24 Apr 2014 23:35:11 +0200
Subject: [R-SIG-Finance] RUGARCH --- "pdist" peculiarities wrt. a numerical
	optimization problem
In-Reply-To: <52B30BEB.8080902@googlemail.com>
References: <52B30BEB.8080902@googlemail.com>
Message-ID: <5359838F.3060700@googlemail.com>

Dear R-Users and Contributors,

to back out a Value at Risk quantile from a student t mixture distribution need to utilize standardized student t distributions (mean zero, unti variance).
However, there seems to be an issue when working with the pdist-function implemented in the RUGARCH-package (and to my knowledge this is the only implementation of a standardized student t distribution in R).

My problem can easier be demonstrated by means of a standard normal distribution:


###########################################################################

### direct way to the 1% standard normal quantile
qnorm( 0.01 , 0 , 1 )


### indirect way (leads nearly to the same result)
find_quant <- function(quant) {
      pdist( distribution = "norm" , quant, mu = 0 , sigma = 1) - 0.01
}
bestquant <- uniroot(f = find_quant, interval = c(-5, 2)); bestquant$root


### this should give the same result, BUT IT DOES NOT ???
find_quant <- function(quant) {
      0.5*pdist( distribution = "norm" , quant, mu = 0 , sigma = 1)
      + 0.5*pdist( distribution = "norm" , quant, mu = 0 , sigma = 1) - 0.01
}
bestquant <- uniroot(f = find_quant, interval = c(-5, 2)); bestquant$root
# interestingly, the result changes when modifying the mixing law to e.g. 0.1 and 0.9, respectively.


### using the R-base functions, there seems to be no problem here:
find_quant <- function(quant) {
      0.5*pnorm(quant,0,1) + 0.5*pnorm(quant,0,1) - 0.01
}
bestquant <- uniroot(f = find_quant, interval = c(-5, 2)); bestquant$root
# this method gives the correct result and is insensitive to the mixing law.
# however, as mentioned above, I have to do a similar thing using a standardized student t
# distribution which is not implemented in base R.

###########################################################################


Thanks a lot for any ideas or suggestions!!
Best,
Johannes


From alexios at 4dscape.com  Thu Apr 24 23:44:40 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Thu, 24 Apr 2014 22:44:40 +0100
Subject: [R-SIG-Finance] RUGARCH --- "pdist" peculiarities wrt. a
 numerical optimization problem
In-Reply-To: <5359838F.3060700@googlemail.com>
References: <52B30BEB.8080902@googlemail.com> <5359838F.3060700@googlemail.com>
Message-ID: <535985C8.7020704@4dscape.com>

Try again:


find_quant <- function(quant) {
0.5*pdist( distribution = "norm" , quant, mu = 0 , sigma =1)+0.5*pdist(
distribution = "norm" , quant, mu = 0 , sigma = 1) - 0.01
}

Your code had a space in the wrong place and the function evaluated only
the second line.

Alexios


On 24/04/2014 22:35, Johannes Moser wrote:
> Dear R-Users and Contributors,
> 
> to back out a Value at Risk quantile from a student t mixture
> distribution need to utilize standardized student t distributions (mean
> zero, unti variance).
> However, there seems to be an issue when working with the pdist-function
> implemented in the RUGARCH-package (and to my knowledge this is the only
> implementation of a standardized student t distribution in R).
> 
> My problem can easier be demonstrated by means of a standard normal
> distribution:
> 
> 
> ###########################################################################
> 
> ### direct way to the 1% standard normal quantile
> qnorm( 0.01 , 0 , 1 )
> 
> 
> ### indirect way (leads nearly to the same result)
> find_quant <- function(quant) {
>      pdist( distribution = "norm" , quant, mu = 0 , sigma = 1) - 0.01
> }
> bestquant <- uniroot(f = find_quant, interval = c(-5, 2)); bestquant$root
> 
> 
> ### this should give the same result, BUT IT DOES NOT ???
> find_quant <- function(quant) {
>      0.5*pdist( distribution = "norm" , quant, mu = 0 , sigma = 1)
>      + 0.5*pdist( distribution = "norm" , quant, mu = 0 , sigma = 1) - 0.01
> }
> bestquant <- uniroot(f = find_quant, interval = c(-5, 2)); bestquant$root
> # interestingly, the result changes when modifying the mixing law to
> e.g. 0.1 and 0.9, respectively.
> 
> 
> ### using the R-base functions, there seems to be no problem here:
> find_quant <- function(quant) {
>      0.5*pnorm(quant,0,1) + 0.5*pnorm(quant,0,1) - 0.01
> }
> bestquant <- uniroot(f = find_quant, interval = c(-5, 2)); bestquant$root
> # this method gives the correct result and is insensitive to the mixing
> law.
> # however, as mentioned above, I have to do a similar thing using a
> standardized student t
> # distribution which is not implemented in base R.
> 
> ###########################################################################
> 
> 
> Thanks a lot for any ideas or suggestions!!
> Best,
> Johannes
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
> 
>


From edd at debian.org  Fri Apr 25 05:13:28 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 24 Apr 2014 22:13:28 -0500
Subject: [R-SIG-Finance]  Reminder regarding R/Finance 2014 Registration
In-Reply-To: <21302.60648.374619.87454@max.nulle.part>
References: <21302.60648.374619.87454@max.nulle.part>
Message-ID: <21337.53976.392766.38862@max.nulle.part>


A quick reminder that R/Finance 2014 will take place in three weeks.

We are approaching the point where registrations are at 50% of capacity, so
if you are thinking about attending, the next few days would be a good time
to finalize this.

We are looking forward to seeing many of you in Chicago in May!

On behalf of the committee,  Dirk


On 29 March 2014 at 10:55, Dirk Eddelbuettel wrote:
| 
| Now open for registrations --- and more details as always at http://www.RinFinance.com :
| 
|   R / Finance 2014: Applied Finance with R
|   May 16 and 17, 2014 
|   Chicago, IL, USA
| 
|   The registration for R/Finance 2014 -- which will take place May 16 and 17
|   in Chicago -- is NOW OPEN!
| 
|   Building on the success of the previous conferences in 2009, 2010, 2011,
|   2012 and 2013, we expect around 300 attendees from around the world. R
|   users from industry, academia, and government will joining 30+ presenters
|   covering all areas of finance with R.
| 
|   We are very excited about the four keynotes by Luke Tierney, Alexios Ghalanos,
|   Bob McDonald and Bill Cleveland.  The main agenda (currently) includes sixteen
|   full presentations and twenty-one shorter "lightning talks". We are also
|   excited to offer four optional pre-conference seminars on Friday morning.
| 
|   To celebrate the sixth year of the conference in style, the dinner will be
|   returning to The Terrace of the Trump Hotel. Overlooking the Chicago River and
|   skyline, it is a perfect venue to continue conversations while dining and
|   drinking.
|                                                                                                           
|   More details of the agenda are available at:
|                                                                                                           
|     http://www.RinFinance.com/agenda/
|                                                                                                           
|   Registration information is available at
|                                                                                                           
|     http://www.RinFinance.com/register/
|                                                                                                           
|   and can also be directly accessed by going to
|                                                                                                           
|     http://www.regonline.com/RFinance2014
|                                                                                                           
|   We would to thank our 2014 Sponsors for the continued support enabling us
|   to host such an exciting conference:
|                                                                                                           
|     International Center for Futures and Derivatives at UIC
|                                                                                                           
|     Revolution Analytics
|     MS-Computational Finance at University of Washington
|                                                                                                           
|     OneMarketData
|     RStudio
|                                                                                                           
|   On behalf of the committee and sponsors, we look forward to seeing you in
|   Chicago!
| 
|     Gib Bassett, Peter Carl, Dirk Eddelbuettel, Brian Peterson, 
|     Dale Rosenthal, Jeffrey Ryan, Joshua Ulrich
| 
| See you in Chicago in May!!
| 
| Dirk
| 
| -- 
| Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
| 
| _______________________________________________
| R-SIG-Finance at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-sig-finance
| -- Subscriber-posting only. If you want to post, subscribe first.
| -- Also note that this is not the r-help list where general R questions should go.

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From jzmoser at gmail.com  Fri Apr 25 10:49:26 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Fri, 25 Apr 2014 10:49:26 +0200
Subject: [R-SIG-Finance] student t mixture VaR in R // imitate example 2.23
 in C.Alexander: Market Risk IV
Message-ID: <535A2196.20501@googlemail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140425/25cc96ee/attachment.pl>

From alexios at 4dscape.com  Fri Apr 25 11:46:30 2014
From: alexios at 4dscape.com (Alexios Ghalanos)
Date: Fri, 25 Apr 2014 10:46:30 +0100
Subject: [R-SIG-Finance] student t mixture VaR in R // imitate example
	2.23 in C.Alexander: Market Risk IV
In-Reply-To: <535A2196.20501@googlemail.com>
References: <535A2196.20501@googlemail.com>
Message-ID: <3AD18F1A-CCCA-4CA1-9D6A-F0A5669DBF7B@4dscape.com>

A quick look at your code suggests that you should use "std" (student) not "sstd" (skew student) for distribution.

Alexios

> On 25 Apr 2014, at 09:49, Johannes Moser <jzmoser at gmail.com> wrote:
> 
> Dear R community,
> 
> in trying to set up a little simulation study I adapt the ideas found in 
> "Carol Alexander: Market Risk IV - Value at Risk Models" on page 111 ff. 
> and implement them in R.
> This project is about student t mixture distributions and Value at Risk 
> / Expected Shortfall.
> 
> The following code is my setup so far, and the syntax is calibrated to 
> resemble the Example 2.23 on page 118 in the mentioned book of 
> Alexander. There is a  EXCEL-file coming with the book and I noticed 
> that my results don`t match the results of the EXCEL implementation.
> 
> e.g. my result for theta=0.001 is
> 
> 0.0841052 (method 1) and
> 
> 0.0842109 (method 2)
> ... but the EXCEL-file coming with the book says that it was 0.1152
> 
> 
> setting theta=0.01 gives
> 
> 0.04493586 (method 1) and
> 
> 0.04490717 (method 2)
> 
> ... but the EXCEL-file coming with the book says that it was 0.0616
> 
> 
> Maybe some of you guys have this book at hand and are able to verify and 
> hopefully find a solution for my worries.
> Or even if you don`t have the book you might still be able to assess the 
> correctness of my approach and implementation?
> 
> 
> 
> 
> ##################################################################################################
> # SET UP MIXTURE INGREDIENTS (calibrate to C.Alexander Market Risk 
> Analysis IV Exercise 2.23)
> 
> p_quiet <- 0.75
> mu_quiet <- 0.0
> mu_stress <- -0.0004
> df_quiet <- 10
> df_stress <- 5
> variance_quiet <- 0.0126^2
> variance_stress <- 0.0253^2
> theta <- 0.001
> 
> 
> # METHOD_1)   Backing out mixture VaR from implicit analytic formula:
> find_quant <- function(quant) {
>      (p_quiet*pdist(distribution = "sstd", 
> (quant-mu_quiet)/sqrt(variance_quiet)  , mu = 0, sigma = 1, shape = 
> df_quiet)
>      + (1-p_quiet)*pdist(distribution = "sstd", 
> (quant-mu_stress)/sqrt(variance_stress)  , mu = 0, sigma = 1, shape = 
> df_stress) - theta)
> }
> bestquant <- uniroot(f = find_quant, interval = c(-5, 1))
> t_mix_VaR1 <- -bestquant$root
> 
> 
> # METHOD_2)   Estimating mixture VaR by simulation:
> nsim <- 10000000
> u_mix <- x <- 1*(runif(nsim) < p_quiet)
> t_quiet <- rdist(distribution = "sstd", nsim  , mu = mu_quiet, sigma = 
> sqrt(variance_quiet), shape = df_quiet)
> t_stress <- rdist(distribution = "sstd", nsim  , mu = mu_stress, sigma = 
> sqrt(variance_stress), shape = df_stress)
> t_mixture <- u_mix*t_quiet + (1-u_mix)*t_stress
> t_mix_VaR2 <- as.numeric(-quantile( t_mixture , probs=theta  ))
> 
> # Compare results
> t_mix_VaR1
> t_mix_VaR2
> ##################################################################################################
> 
> 
> 
> 
> The EXCEL spreadsheet "EX_IV.2.23" in the workbook "Examples_IV.2.xls" 
> has been used and modified as follows:
> 1) change the risk horizon to 1 day (so that there would be no scaling 
> and the autocorrelation doesn`t matter)
> 2) if necessary change the significance level (1% or 0,1% in my example)
> 3) press F11 to recalcualte the mixture parameters over the risk horizon
> 4) apply EXCEL SOLVER to line C24 while allowing for changing cell C25 
> to get the t Mixture VaR
> 
> Thanks a lot for any ideas or suggestions!
> Johannes
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 


From jzmoser at gmail.com  Fri Apr 25 12:23:14 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Fri, 25 Apr 2014 12:23:14 +0200
Subject: [R-SIG-Finance] student t mixture VaR in R // imitate example
 2.23 in C.Alexander: Market Risk IV
In-Reply-To: <3AD18F1A-CCCA-4CA1-9D6A-F0A5669DBF7B@4dscape.com>
References: <535A2196.20501@googlemail.com>
	<3AD18F1A-CCCA-4CA1-9D6A-F0A5669DBF7B@4dscape.com>
Message-ID: <535A3792.3050105@googlemail.com>

Thanks a lot, Alexios!
I have corrected this issue. The result is the same, though.

I forgot to mention that the RUGARCH-package is required to run the code.

At the moment I try to find the error in either
- my own theoretical thoughts (e.g. confusing the scale parameter with 
the standard deviation)
- the implementation made by C.Alexander (on page 117 she writes in a 
footnote: "In general, if X has distribution F(x) and Y=aX, a being a 
constant, then y has distribution function a^(?1) * F(x)". Either I am 
completely burnout right now, or this must be "F(a^(?1)*x)" in the end. 
So maybe this is not just a typo, but also incorrectly implemented in 
the quite complicated EXCEL formula.)
- some EXCEL or R issue. I think her EXCEL syntax has been programmed in 
version 2003, but I`m running 2010.

Any help is appreciated a lot!



Am 25.04.2014 11:46, schrieb Alexios Ghalanos:
> A quick look at your code suggests that you should use "std" (student) not "sstd" (skew student) for distribution.
>
> Alexios
>
>> On 25 Apr 2014, at 09:49, Johannes Moser <jzmoser at gmail.com> wrote:
>>
>> Dear R community,
>>
>> in trying to set up a little simulation study I adapt the ideas found in
>> "Carol Alexander: Market Risk IV - Value at Risk Models" on page 111 ff.
>> and implement them in R.
>> This project is about student t mixture distributions and Value at Risk
>> / Expected Shortfall.
>>
>> The following code is my setup so far, and the syntax is calibrated to
>> resemble the Example 2.23 on page 118 in the mentioned book of
>> Alexander. There is a  EXCEL-file coming with the book and I noticed
>> that my results don`t match the results of the EXCEL implementation.
>>
>> e.g. my result for theta=0.001 is
>>
>> 0.0841052 (method 1) and
>>
>> 0.0842109 (method 2)
>> ... but the EXCEL-file coming with the book says that it was 0.1152
>>
>>
>> setting theta=0.01 gives
>>
>> 0.04493586 (method 1) and
>>
>> 0.04490717 (method 2)
>>
>> ... but the EXCEL-file coming with the book says that it was 0.0616
>>
>>
>> Maybe some of you guys have this book at hand and are able to verify and
>> hopefully find a solution for my worries.
>> Or even if you don`t have the book you might still be able to assess the
>> correctness of my approach and implementation?
>>
>>
>>
>>
>> ##################################################################################################
>> # SET UP MIXTURE INGREDIENTS (calibrate to C.Alexander Market Risk
>> Analysis IV Exercise 2.23)
>>
>> p_quiet <- 0.75
>> mu_quiet <- 0.0
>> mu_stress <- -0.0004
>> df_quiet <- 10
>> df_stress <- 5
>> variance_quiet <- 0.0126^2
>> variance_stress <- 0.0253^2
>> theta <- 0.001
>>
>>
>> # METHOD_1)   Backing out mixture VaR from implicit analytic formula:
>> find_quant <- function(quant) {
>>       (p_quiet*pdist(distribution = "sstd",
>> (quant-mu_quiet)/sqrt(variance_quiet)  , mu = 0, sigma = 1, shape =
>> df_quiet)
>>       + (1-p_quiet)*pdist(distribution = "sstd",
>> (quant-mu_stress)/sqrt(variance_stress)  , mu = 0, sigma = 1, shape =
>> df_stress) - theta)
>> }
>> bestquant <- uniroot(f = find_quant, interval = c(-5, 1))
>> t_mix_VaR1 <- -bestquant$root
>>
>>
>> # METHOD_2)   Estimating mixture VaR by simulation:
>> nsim <- 10000000
>> u_mix <- x <- 1*(runif(nsim) < p_quiet)
>> t_quiet <- rdist(distribution = "sstd", nsim  , mu = mu_quiet, sigma =
>> sqrt(variance_quiet), shape = df_quiet)
>> t_stress <- rdist(distribution = "sstd", nsim  , mu = mu_stress, sigma =
>> sqrt(variance_stress), shape = df_stress)
>> t_mixture <- u_mix*t_quiet + (1-u_mix)*t_stress
>> t_mix_VaR2 <- as.numeric(-quantile( t_mixture , probs=theta  ))
>>
>> # Compare results
>> t_mix_VaR1
>> t_mix_VaR2
>> ##################################################################################################
>>
>>
>>
>>
>> The EXCEL spreadsheet "EX_IV.2.23" in the workbook "Examples_IV.2.xls"
>> has been used and modified as follows:
>> 1) change the risk horizon to 1 day (so that there would be no scaling
>> and the autocorrelation doesn`t matter)
>> 2) if necessary change the significance level (1% or 0,1% in my example)
>> 3) press F11 to recalcualte the mixture parameters over the risk horizon
>> 4) apply EXCEL SOLVER to line C24 while allowing for changing cell C25
>> to get the t Mixture VaR
>>
>> Thanks a lot for any ideas or suggestions!
>> Johannes
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>>

-- 
_________________________
Johannes Moser
Sophie-Charlotten-Str. 35
14059 Berlin
Tel: 0176 2171 2196


From alexios at 4dscape.com  Fri Apr 25 14:15:04 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Fri, 25 Apr 2014 13:15:04 +0100
Subject: [R-SIG-Finance] student t mixture VaR in R // imitate example
 2.23 in C.Alexander: Market Risk IV
In-Reply-To: <535A3792.3050105@googlemail.com>
References: <535A2196.20501@googlemail.com>	<3AD18F1A-CCCA-4CA1-9D6A-F0A5669DBF7B@4dscape.com>
	<535A3792.3050105@googlemail.com>
Message-ID: <535A51C8.70606@4dscape.com>

I suggest you take a break and consider that in order to help you, it is
required that you state ALL the assumptions and provide a complete
example. Since the book is not generally available, and you have told us
very little about the problem and its assumptions (other than a page and
example number), then you shouldn't expect much help.

Alexios

PS How did you come up with the numbers for mu_stress, variance_quiet
and variance_stress? From what I am told, the book example provides the
annualized values and you are required to calculate the 10-day VaR (so
you are required to rescale the numbers to their 10-day equivalents).

On 25/04/2014 11:23, Johannes Moser wrote:
> Thanks a lot, Alexios!
> I have corrected this issue. The result is the same, though.
> 
> I forgot to mention that the RUGARCH-package is required to run the code.
> 
> At the moment I try to find the error in either
> - my own theoretical thoughts (e.g. confusing the scale parameter with
> the standard deviation)
> - the implementation made by C.Alexander (on page 117 she writes in a
> footnote: "In general, if X has distribution F(x) and Y=aX, a being a
> constant, then y has distribution function a^(?1) * F(x)". Either I am
> completely burnout right now, or this must be "F(a^(?1)*x)" in the end.
> So maybe this is not just a typo, but also incorrectly implemented in
> the quite complicated EXCEL formula.)
> - some EXCEL or R issue. I think her EXCEL syntax has been programmed in
> version 2003, but I`m running 2010.
> 
> Any help is appreciated a lot!
> 
> 
> 
> Am 25.04.2014 11:46, schrieb Alexios Ghalanos:
>> A quick look at your code suggests that you should use "std" (student)
>> not "sstd" (skew student) for distribution.
>>
>> Alexios
>>
>>> On 25 Apr 2014, at 09:49, Johannes Moser <jzmoser at gmail.com> wrote:
>>>
>>> Dear R community,
>>>
>>> in trying to set up a little simulation study I adapt the ideas found in
>>> "Carol Alexander: Market Risk IV - Value at Risk Models" on page 111 ff.
>>> and implement them in R.
>>> This project is about student t mixture distributions and Value at Risk
>>> / Expected Shortfall.
>>>
>>> The following code is my setup so far, and the syntax is calibrated to
>>> resemble the Example 2.23 on page 118 in the mentioned book of
>>> Alexander. There is a  EXCEL-file coming with the book and I noticed
>>> that my results don`t match the results of the EXCEL implementation.
>>>
>>> e.g. my result for theta=0.001 is
>>>
>>> 0.0841052 (method 1) and
>>>
>>> 0.0842109 (method 2)
>>> ... but the EXCEL-file coming with the book says that it was 0.1152
>>>
>>>
>>> setting theta=0.01 gives
>>>
>>> 0.04493586 (method 1) and
>>>
>>> 0.04490717 (method 2)
>>>
>>> ... but the EXCEL-file coming with the book says that it was 0.0616
>>>
>>>
>>> Maybe some of you guys have this book at hand and are able to verify and
>>> hopefully find a solution for my worries.
>>> Or even if you don`t have the book you might still be able to assess the
>>> correctness of my approach and implementation?
>>>
>>>
>>>
>>>
>>> ##################################################################################################
>>>
>>> # SET UP MIXTURE INGREDIENTS (calibrate to C.Alexander Market Risk
>>> Analysis IV Exercise 2.23)
>>>
>>> p_quiet <- 0.75
>>> mu_quiet <- 0.0
>>> mu_stress <- -0.0004
>>> df_quiet <- 10
>>> df_stress <- 5
>>> variance_quiet <- 0.0126^2
>>> variance_stress <- 0.0253^2
>>> theta <- 0.001
>>>
>>>
>>> # METHOD_1)   Backing out mixture VaR from implicit analytic formula:
>>> find_quant <- function(quant) {
>>>       (p_quiet*pdist(distribution = "sstd",
>>> (quant-mu_quiet)/sqrt(variance_quiet)  , mu = 0, sigma = 1, shape =
>>> df_quiet)
>>>       + (1-p_quiet)*pdist(distribution = "sstd",
>>> (quant-mu_stress)/sqrt(variance_stress)  , mu = 0, sigma = 1, shape =
>>> df_stress) - theta)
>>> }
>>> bestquant <- uniroot(f = find_quant, interval = c(-5, 1))
>>> t_mix_VaR1 <- -bestquant$root
>>>
>>>
>>> # METHOD_2)   Estimating mixture VaR by simulation:
>>> nsim <- 10000000
>>> u_mix <- x <- 1*(runif(nsim) < p_quiet)
>>> t_quiet <- rdist(distribution = "sstd", nsim  , mu = mu_quiet, sigma =
>>> sqrt(variance_quiet), shape = df_quiet)
>>> t_stress <- rdist(distribution = "sstd", nsim  , mu = mu_stress, sigma =
>>> sqrt(variance_stress), shape = df_stress)
>>> t_mixture <- u_mix*t_quiet + (1-u_mix)*t_stress
>>> t_mix_VaR2 <- as.numeric(-quantile( t_mixture , probs=theta  ))
>>>
>>> # Compare results
>>> t_mix_VaR1
>>> t_mix_VaR2
>>> ##################################################################################################
>>>
>>>
>>>
>>>
>>>
>>> The EXCEL spreadsheet "EX_IV.2.23" in the workbook "Examples_IV.2.xls"
>>> has been used and modified as follows:
>>> 1) change the risk horizon to 1 day (so that there would be no scaling
>>> and the autocorrelation doesn`t matter)
>>> 2) if necessary change the significance level (1% or 0,1% in my example)
>>> 3) press F11 to recalcualte the mixture parameters over the risk horizon
>>> 4) apply EXCEL SOLVER to line C24 while allowing for changing cell C25
>>> to get the t Mixture VaR
>>>
>>> Thanks a lot for any ideas or suggestions!
>>> Johannes
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R
>>> questions should go.
>>>
>


From jzmoser at gmail.com  Fri Apr 25 15:17:07 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Fri, 25 Apr 2014 15:17:07 +0200
Subject: [R-SIG-Finance] student t mixture VaR in R // imitate example
 2.23 in C.Alexander: Market Risk IV
In-Reply-To: <535A51C8.70606@4dscape.com>
References: <535A2196.20501@googlemail.com>	<3AD18F1A-CCCA-4CA1-9D6A-F0A5669DBF7B@4dscape.com>
	<535A3792.3050105@googlemail.com> <535A51C8.70606@4dscape.com>
Message-ID: <535A6053.3080304@googlemail.com>

Thanks for your help so far, Alexios!

I didn`t want to write down all the datails of the exercise because my 
text alredy was lengthly and also because I didn`t want to violate any 
copyrights.
Rather, I was hoping that someone has the book and the CD at hand 
because I think that the book is pretty popular.

To answer your question: The EXCEL example from the book was adapted by 
me in the following way:

1) change the risk horizon to 1 day (so that there would be no scaling
and the autocorrelation doesn`t matter)
2) if necessary change the significance level (1% or 0,1% in my example)

this has already been stated in my first mail. So the numbers for for 
mu_stress, variance_quiet and variance_stress are the (annualized) 
numbers given in the example scaled to one day.
I just did copy and paste with the down-scaled numbers from the EXCEL 
spreadsheet to check if my own R syntax leads to the same results as the 
EXCEL setup given by the CD in the book of C.Alexander.

A general description of my approach might be given by the following sketch:
Calculate 1-day VaR with confidence level 99% (and 99,9%) of a bivariate 
student t mixture distribution by means of backing out the quantile from 
the formula
     L * P(X < (q-m)/r) + (1-L) * P(Y < (q-n)/s) = theta
(see C.Alexander p.113)
(the VaR is just minus the 1% or 0.1% quantile "q")
"L" is the mixing law giving the probability for the mixture random 
variable to follow the same student-t distribution as the random 
variable "X" with mean "m", standard deviation "r" and degrees of 
freedom "df1".
The  mixture random variable follows a student t distribution with mean 
"n", standard deviation "s" and degrees of freedom "df2" with 
probability "(1-L)". This is the distribution for the random variable "Y".
"q" ist the required "theta"-quantile (as pointed out, "theta" is set to 
0.01 and 0.001 in my example)

The notation in my R code is:

p_quiet = L
mu_quiet = m
mu_stress = n
df_quiet = df1
df_stress = df2
variance_quiet = r^2
variance_stress = s^2
theta = theta

I hope that with these details everyone can evaluate if my syntax is set 
up correctly.
The values for these variables as to the modified example from 
Alexanders book can be  read in the R syntax given in my first mail.

My aim (later!) is to simulate a fictive return series in a 
regime-switching manner using student t mixture models and calculate the 
analytical VaR and Expected Shortfall in a dynamical way.
Then I want to apply several other estimation techniques to the 
simulated mixture series and examine their performance in relation to 
the analytic results.
But first I have to make sure that my analytic VaR for the student t 
mixture model is correct.
However, verification of the Example given by C.Alexander indeed 
requires her book and the enclosed CD with the EXCEL workbooks.
I just can`t post all this stuff here.




Am 25.04.2014 14:15, schrieb alexios ghalanos:
> I suggest you take a break and consider that in order to help you, it is
> required that you state ALL the assumptions and provide a complete
> example. Since the book is not generally available, and you have told us
> very little about the problem and its assumptions (other than a page and
> example number), then you shouldn't expect much help.
>
> Alexios
>
> PS How did you come up with the numbers for mu_stress, variance_quiet
> and variance_stress? From what I am told, the book example provides the
> annualized values and you are required to calculate the 10-day VaR (so
> you are required to rescale the numbers to their 10-day equivalents).
>
> On 25/04/2014 11:23, Johannes Moser wrote:
>> Thanks a lot, Alexios!
>> I have corrected this issue. The result is the same, though.
>>
>> I forgot to mention that the RUGARCH-package is required to run the code.
>>
>> At the moment I try to find the error in either
>> - my own theoretical thoughts (e.g. confusing the scale parameter with
>> the standard deviation)
>> - the implementation made by C.Alexander (on page 117 she writes in a
>> footnote: "In general, if X has distribution F(x) and Y=aX, a being a
>> constant, then y has distribution function a^(?1) * F(x)". Either I am
>> completely burnout right now, or this must be "F(a^(?1)*x)" in the end.
>> So maybe this is not just a typo, but also incorrectly implemented in
>> the quite complicated EXCEL formula.)
>> - some EXCEL or R issue. I think her EXCEL syntax has been programmed in
>> version 2003, but I`m running 2010.
>>
>> Any help is appreciated a lot!
>>
>>
>>
>> Am 25.04.2014 11:46, schrieb Alexios Ghalanos:
>>> A quick look at your code suggests that you should use "std" (student)
>>> not "sstd" (skew student) for distribution.
>>>
>>> Alexios
>>>
>>>> On 25 Apr 2014, at 09:49, Johannes Moser <jzmoser at gmail.com> wrote:
>>>>
>>>> Dear R community,
>>>>
>>>> in trying to set up a little simulation study I adapt the ideas found in
>>>> "Carol Alexander: Market Risk IV - Value at Risk Models" on page 111 ff.
>>>> and implement them in R.
>>>> This project is about student t mixture distributions and Value at Risk
>>>> / Expected Shortfall.
>>>>
>>>> The following code is my setup so far, and the syntax is calibrated to
>>>> resemble the Example 2.23 on page 118 in the mentioned book of
>>>> Alexander. There is a  EXCEL-file coming with the book and I noticed
>>>> that my results don`t match the results of the EXCEL implementation.
>>>>
>>>> e.g. my result for theta=0.001 is
>>>>
>>>> 0.0841052 (method 1) and
>>>>
>>>> 0.0842109 (method 2)
>>>> ... but the EXCEL-file coming with the book says that it was 0.1152
>>>>
>>>>
>>>> setting theta=0.01 gives
>>>>
>>>> 0.04493586 (method 1) and
>>>>
>>>> 0.04490717 (method 2)
>>>>
>>>> ... but the EXCEL-file coming with the book says that it was 0.0616
>>>>
>>>>
>>>> Maybe some of you guys have this book at hand and are able to verify and
>>>> hopefully find a solution for my worries.
>>>> Or even if you don`t have the book you might still be able to assess the
>>>> correctness of my approach and implementation?
>>>>
>>>>
>>>>
>>>>
>>>> ##################################################################################################
>>>>
>>>> # SET UP MIXTURE INGREDIENTS (calibrate to C.Alexander Market Risk
>>>> Analysis IV Exercise 2.23)
>>>>
>>>> p_quiet <- 0.75
>>>> mu_quiet <- 0.0
>>>> mu_stress <- -0.0004
>>>> df_quiet <- 10
>>>> df_stress <- 5
>>>> variance_quiet <- 0.0126^2
>>>> variance_stress <- 0.0253^2
>>>> theta <- 0.001
>>>>
>>>>
>>>> # METHOD_1)   Backing out mixture VaR from implicit analytic formula:
>>>> find_quant <- function(quant) {
>>>>        (p_quiet*pdist(distribution = "sstd",
>>>> (quant-mu_quiet)/sqrt(variance_quiet)  , mu = 0, sigma = 1, shape =
>>>> df_quiet)
>>>>        + (1-p_quiet)*pdist(distribution = "sstd",
>>>> (quant-mu_stress)/sqrt(variance_stress)  , mu = 0, sigma = 1, shape =
>>>> df_stress) - theta)
>>>> }
>>>> bestquant <- uniroot(f = find_quant, interval = c(-5, 1))
>>>> t_mix_VaR1 <- -bestquant$root
>>>>
>>>>
>>>> # METHOD_2)   Estimating mixture VaR by simulation:
>>>> nsim <- 10000000
>>>> u_mix <- x <- 1*(runif(nsim) < p_quiet)
>>>> t_quiet <- rdist(distribution = "sstd", nsim  , mu = mu_quiet, sigma =
>>>> sqrt(variance_quiet), shape = df_quiet)
>>>> t_stress <- rdist(distribution = "sstd", nsim  , mu = mu_stress, sigma =
>>>> sqrt(variance_stress), shape = df_stress)
>>>> t_mixture <- u_mix*t_quiet + (1-u_mix)*t_stress
>>>> t_mix_VaR2 <- as.numeric(-quantile( t_mixture , probs=theta  ))
>>>>
>>>> # Compare results
>>>> t_mix_VaR1
>>>> t_mix_VaR2
>>>> ##################################################################################################
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> The EXCEL spreadsheet "EX_IV.2.23" in the workbook "Examples_IV.2.xls"
>>>> has been used and modified as follows:
>>>> 1) change the risk horizon to 1 day (so that there would be no scaling
>>>> and the autocorrelation doesn`t matter)
>>>> 2) if necessary change the significance level (1% or 0,1% in my example)
>>>> 3) press F11 to recalcualte the mixture parameters over the risk horizon
>>>> 4) apply EXCEL SOLVER to line C24 while allowing for changing cell C25
>>>> to get the t Mixture VaR
>>>>
>>>> Thanks a lot for any ideas or suggestions!
>>>> Johannes
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>      [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R
>>>> questions should go.
>>>>

-- 
_________________________
Johannes Moser
Sophie-Charlotten-Str. 35
14059 Berlin
Tel: 0176 2171 2196


From philippe.kappeler at hotmail.com  Fri Apr 25 21:36:57 2014
From: philippe.kappeler at hotmail.com (philippe)
Date: Fri, 25 Apr 2014 12:36:57 -0700 (PDT)
Subject: [R-SIG-Finance] Independence test rugarch package
Message-ID: <1398454617034-4689473.post@n4.nabble.com>

Dear contributors, dear alexhios

I am trying to get the log-likelihood ratio values of the independence test
of christopherson (1988). I identified the problem when I received -Inf for
the uncond. coverage test due to too small number and in the end the log of
zero  and thus, wanted to run the independence test solely. I have the CHF
which is in the following file
https://drive.google.com/folderview?id=0BwSzkfw3xUH3REsxRHprZEU1R00&usp=sharing 

I built a parametric VaR model with the normal distributions at 4 confidence
levels. The problem arose with the following code of your package below 

I checked your code an fully agree with your computation, however I do not
know why the T01 and T10 values are both zero and the T11 value is equal to
N -> the which() function below in the code clearly indicates that there are
definitely not 163 "ones" in VaR.ind followed by "ones"! However, I can't
find the error in your code or the difference to the one of my slightly
adapted to compute 4 p-values at a time!

In advance, thanks for your support and a nice weekend! Best, 
philippe 

############
library(rugarch)
ret <- CHF
seq <- 2000 #alternatively 500, 1000, 1500

#Normal Distribution VaR
VaRdistn <- function(ret, prob=.05) {
  ans <- -qnorm(prob, mean=0, sd=sd(ret)) 
  signif(ans, digits=7)
}

### VaR 
fun <- VaRdistn
p <- c(0.05, 0.01, 0.005, 0.001) # confidence values for VaR
act <- ret[(seq+1):length(ret)] # actual return
VaRmatrix <- matrix(nrow=length(ret)-seq, ncol=length(p))
for (i in 1:nrow(VaRmatrix) ) {
  VaRmatrix[i,]<-  sapply(X=p, FUN=VaRdistn,ret=ret[i:(seq+i-1)] )
  colnames(VaRmatrix) <- c("0.05", "0.01", "0.005", "0.001")
}

#### RUGARCH package (getAnywhere(.LR.cc))
VaR <- -VaRmatrix[,2]
p <- 0.01

VaR.ind = ifelse(act < VaR, 1, 0)
N = sum(VaR.ind)
TN = length(VaR.ind)
T00 = sum(c(0, ifelse(VaR.ind[2:TN] == 0 & VaR.ind[1:(TN-1)] == 0, 1, 0)))
T11 = sum(c(0, ifelse(VaR.ind[2:TN] == 1 & VaR.ind[1:(TN-1)] == 1, 1, 0)))
T01 = sum(c(0, ifelse(VaR.ind[2:TN] == 1 & VaR.ind[1:(TN-1)] == 0, 1, 0)))
T10 = sum(c(0, ifelse(VaR.ind[2:TN] == 0 & VaR.ind[1:(TN-1)] == 1, 1, 0)))
T0 = T00 + T01
T1 = T10 + T11
pi0 = T01/T0
pi1 = T11/T1
pe = (T01 + T11)/(T0 + T1)
stat.ind = -2 * log((1 - pe)^(T00 + T10) * pe^(T01 + T11)) + 
  2 * log((1 - pi0)^T00 * pi0^T01 * (1 - pi1)^T10 * pi1^T11)
stat.ind
which(VaR.ind == 1)

##### my code
conf <- 0.95 
p <- c(0.05, 0.01, 0.005, 0.001)
#fill vectors
uc.LR <- cc.LR <- numeric(length(p))
uc.pval <- cc.pval <- numeric(length(p))
uc.statement <- cc.statement <- numeric(length(p))
ind.LR <- ind.pval <- numeric(length(p))
VaR.ind <- matrix(nrow=length(ret)-seq, ncol=length(p))
N <- TN <- T00 <- T11 <- T01 <- T10 <- T0 <- T1 <- pi0 <- pi1 <- pe <-
numeric(length(p))
for(i in 1:length(p)){
  uc.LR[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
conf)$uc.LRstat
  uc.pval[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
conf)$uc.LRp
  VaR.ind[,i] = ifelse(act < -VaRmatrix[,i], 1, 0)
  N[i] = sum(VaR.ind[,i])
  TN[i] = length(VaR.ind[,i])
  T00[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 0 & VaR.ind[,i][1:(TN[i]
- 1)] == 0, 1, 0)))
  T11[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 1 & VaR.ind[,i][1:(TN[i]
- 1)] == 1, 1, 0)))
  T01[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 1 & VaR.ind[,i][1:(TN[i]
- 1)] == 0, 1, 0)))
  T10[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 0 & VaR.ind[,i][1:(TN[i]
- 1)] == 1, 1, 0)))
  T0[i] = T00[i] + T01[i]
  T1[i] = T10[i] + T11[i]
  pi0[i] = T01[i]/T0[i]
  pi1[i] = T11[i]/T1[i]
  pe[i] = (T01[i] + T11[i])/(T0[i] + T1[i])
  ind.LR[i] = -2 * log((1 - pe[i])^(T00[i] + T10[i]) * pe[i]^(T01[i] +
T11[i])) + 
    2 * log((1 - pi0[i])^T00[i] * pi0[i]^T01[i] * (1 - pi1[i])^T10[i] *
pi1[i]^T11[i])
  ind.pval[i] <- 1 - pchisq(ind.LR[i], df = 1)
  cc.LR[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
conf)$cc.LRstat
  cc.pval[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
conf)$cc.LRp
}
ind.LR



--
View this message in context: http://r.789695.n4.nabble.com/Independence-test-rugarch-package-tp4689473.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From alexios at 4dscape.com  Sat Apr 26 01:38:02 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sat, 26 Apr 2014 00:38:02 +0100
Subject: [R-SIG-Finance] Independence test rugarch package
In-Reply-To: <1398454617034-4689473.post@n4.nabble.com>
References: <1398454617034-4689473.post@n4.nabble.com>
Message-ID: <535AF1DA.6060105@4dscape.com>

Hi,

Please download latest version from bitbucket, re-test and report back.
I've made some changes to the way the test is calculated in order to
avoid problems when N is large (leading ot NaN or -Inf).

To download use the following code:
require(devtools)
install_bitbucket("rugarch","alexiosg")


Alexios


On 25/04/2014 20:36, philippe wrote:
> Dear contributors, dear alexhios
> 
> I am trying to get the log-likelihood ratio values of the independence test
> of christopherson (1988). I identified the problem when I received -Inf for
> the uncond. coverage test due to too small number and in the end the log of
> zero  and thus, wanted to run the independence test solely. I have the CHF
> which is in the following file
> https://drive.google.com/folderview?id=0BwSzkfw3xUH3REsxRHprZEU1R00&usp=sharing 
> 
> I built a parametric VaR model with the normal distributions at 4 confidence
> levels. The problem arose with the following code of your package below 
> 
> I checked your code an fully agree with your computation, however I do not
> know why the T01 and T10 values are both zero and the T11 value is equal to
> N -> the which() function below in the code clearly indicates that there are
> definitely not 163 "ones" in VaR.ind followed by "ones"! However, I can't
> find the error in your code or the difference to the one of my slightly
> adapted to compute 4 p-values at a time!
> 
> In advance, thanks for your support and a nice weekend! Best, 
> philippe 
> 
> ############
> library(rugarch)
> ret <- CHF
> seq <- 2000 #alternatively 500, 1000, 1500
> 
> #Normal Distribution VaR
> VaRdistn <- function(ret, prob=.05) {
>   ans <- -qnorm(prob, mean=0, sd=sd(ret)) 
>   signif(ans, digits=7)
> }
> 
> ### VaR 
> fun <- VaRdistn
> p <- c(0.05, 0.01, 0.005, 0.001) # confidence values for VaR
> act <- ret[(seq+1):length(ret)] # actual return
> VaRmatrix <- matrix(nrow=length(ret)-seq, ncol=length(p))
> for (i in 1:nrow(VaRmatrix) ) {
>   VaRmatrix[i,]<-  sapply(X=p, FUN=VaRdistn,ret=ret[i:(seq+i-1)] )
>   colnames(VaRmatrix) <- c("0.05", "0.01", "0.005", "0.001")
> }
> 
> #### RUGARCH package (getAnywhere(.LR.cc))
> VaR <- -VaRmatrix[,2]
> p <- 0.01
> 
> VaR.ind = ifelse(act < VaR, 1, 0)
> N = sum(VaR.ind)
> TN = length(VaR.ind)
> T00 = sum(c(0, ifelse(VaR.ind[2:TN] == 0 & VaR.ind[1:(TN-1)] == 0, 1, 0)))
> T11 = sum(c(0, ifelse(VaR.ind[2:TN] == 1 & VaR.ind[1:(TN-1)] == 1, 1, 0)))
> T01 = sum(c(0, ifelse(VaR.ind[2:TN] == 1 & VaR.ind[1:(TN-1)] == 0, 1, 0)))
> T10 = sum(c(0, ifelse(VaR.ind[2:TN] == 0 & VaR.ind[1:(TN-1)] == 1, 1, 0)))
> T0 = T00 + T01
> T1 = T10 + T11
> pi0 = T01/T0
> pi1 = T11/T1
> pe = (T01 + T11)/(T0 + T1)
> stat.ind = -2 * log((1 - pe)^(T00 + T10) * pe^(T01 + T11)) + 
>   2 * log((1 - pi0)^T00 * pi0^T01 * (1 - pi1)^T10 * pi1^T11)
> stat.ind
> which(VaR.ind == 1)
> 
> ##### my code
> conf <- 0.95 
> p <- c(0.05, 0.01, 0.005, 0.001)
> #fill vectors
> uc.LR <- cc.LR <- numeric(length(p))
> uc.pval <- cc.pval <- numeric(length(p))
> uc.statement <- cc.statement <- numeric(length(p))
> ind.LR <- ind.pval <- numeric(length(p))
> VaR.ind <- matrix(nrow=length(ret)-seq, ncol=length(p))
> N <- TN <- T00 <- T11 <- T01 <- T10 <- T0 <- T1 <- pi0 <- pi1 <- pe <-
> numeric(length(p))
> for(i in 1:length(p)){
>   uc.LR[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
> conf)$uc.LRstat
>   uc.pval[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
> conf)$uc.LRp
>   VaR.ind[,i] = ifelse(act < -VaRmatrix[,i], 1, 0)
>   N[i] = sum(VaR.ind[,i])
>   TN[i] = length(VaR.ind[,i])
>   T00[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 0 & VaR.ind[,i][1:(TN[i]
> - 1)] == 0, 1, 0)))
>   T11[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 1 & VaR.ind[,i][1:(TN[i]
> - 1)] == 1, 1, 0)))
>   T01[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 1 & VaR.ind[,i][1:(TN[i]
> - 1)] == 0, 1, 0)))
>   T10[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 0 & VaR.ind[,i][1:(TN[i]
> - 1)] == 1, 1, 0)))
>   T0[i] = T00[i] + T01[i]
>   T1[i] = T10[i] + T11[i]
>   pi0[i] = T01[i]/T0[i]
>   pi1[i] = T11[i]/T1[i]
>   pe[i] = (T01[i] + T11[i])/(T0[i] + T1[i])
>   ind.LR[i] = -2 * log((1 - pe[i])^(T00[i] + T10[i]) * pe[i]^(T01[i] +
> T11[i])) + 
>     2 * log((1 - pi0[i])^T00[i] * pi0[i]^T01[i] * (1 - pi1[i])^T10[i] *
> pi1[i]^T11[i])
>   ind.pval[i] <- 1 - pchisq(ind.LR[i], df = 1)
>   cc.LR[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
> conf)$cc.LRstat
>   cc.pval[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
> conf)$cc.LRp
> }
> ind.LR
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Independence-test-rugarch-package-tp4689473.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 
>


From philippe.kappeler at hotmail.com  Sat Apr 26 08:43:01 2014
From: philippe.kappeler at hotmail.com (philippe)
Date: Fri, 25 Apr 2014 23:43:01 -0700 (PDT)
Subject: [R-SIG-Finance] Independence test rugarch package
In-Reply-To: <535AF1DA.6060105@4dscape.com>
References: <1398454617034-4689473.post@n4.nabble.com>
	<535AF1DA.6060105@4dscape.com>
Message-ID: <1398494581095-4689499.post@n4.nabble.com>

Hi Alexios,

Thanks for the quick response. I downloaded the package from "bitbucket" and
retested. The test now reports values for the UC test, where before I
received NaN for a confidence level 0f 0.95 (p=0.05) and rolling windows
500, 1000, 1500. The rolling window of 2000 was working fine before and
still does. So this is fine and thanks. 

But now the CC test returns NaN's at all windows, whereas before window 2000
was working. I copy pasted again the function (.LR.cc) out of getAnywhere
and rerun the function in a sort of "traceback mode". I note that T11 is
still equal to N, which in my eyes is still incorrect as the
which(VaR.ind==1) results show. Please advise me if I misunderstood or
overlooked something. 

Thank you very much.

The code slightly updated is again. 

###############
require(devtools) 
install_bitbucket("rugarch","alexiosg") 

ret <- CHF
seq <- 2000 #alternativly 500, 1000, 1500

#Normal Distribution VaR
VaRdistn <- function(ret, prob=.05) {
  ans <- -qnorm(prob, mean=0, sd=sd(ret)) 
  signif(ans, digits=7)
}

### VaR 
p <- c(0.05, 0.01, 0.005, 0.001) # confidence values for VaR
act <- ret[(seq+1):length(ret)] # actual return
VaRmatrix <- matrix(nrow=length(ret)-seq, ncol=length(p))
for (i in 1:nrow(VaRmatrix) ) {
  VaRmatrix[i,]<-  sapply(X=p, FUN=VaRdistn,ret=ret[i:(seq+i-1)] )
  colnames(VaRmatrix) <- c("0.05", "0.01", "0.005", "0.001")
}

#### RUGARCH package (getAnywhere(.LR.cc))
VaR <- -VaRmatrix[,1] #change column and p value respectively to 2 for 0.01,
3 for 0.005 and 4 for 0.001
p <- 0.05
actual <- act
#function (p, actual, VaR) 
#{
  VaR.ind = ifelse(actual < VaR, 1, 0)
  N = sum(VaR.ind)
  TN = length(VaR.ind)
  T00 = sum(c(0, ifelse(VaR.ind[2:TN] == 0 & VaR.ind[1:(TN - 
                                                          1)] == 0, 1, 0)))
  T11 = sum(c(0, ifelse(VaR.ind[2:TN] == 1 & VaR.ind[1:(TN - 
                                                          1)] == 1, 1, 0)))
  T01 = sum(c(0, ifelse(VaR.ind[2:TN] == 1 & VaR.ind[1:(TN - 
                                                          1)] == 0, 1, 0)))
  T10 = sum(c(0, ifelse(VaR.ind[2:TN] == 0 & VaR.ind[1:(TN - 
                                                          1)] == 1, 1, 0)))
  T0 = T00 + T01
  T1 = T10 + T11
  pi0 = T01/T0
  pi1 = T11/T1
  pe = (T01 + T11)/(T0 + T1)
  stat.ind = -2 * ((T00 + T10) * log(1 - pe) + (T01 + T11) * 
                     log(pe)) + 2 * (T00 * log(1 - pi0) + T01 * log(pi0) + 
                                       T10 * log(1 - pi1) + T11 * log(pi1))
  #stat.uc = .LR.uc(p = p, TN = TN, N = N)
  #stat.cc = stat.uc + stat.ind
  #return(list(stat.cc = stat.cc, stat.uc = stat.uc, N = N, 
   #           TN = TN))
#}
#### your results out of R-studio console #######
> N
[1] 163

> T00
[1] 3048

> T00
[1] 3048

> T11
[1] 163

> T01
[1] 0

> T10
[1] 0

> which(VaR.ind == 1)
  [1]   10   55  106  117  151  174  178  186  191  213  227  238  246  302 
334  368  373  388  395  438  486  496  497  503
 [25]  544  581  606  614  623  637  655  664  670  672  697  722  727  754 
767  771  778  815  818  835  864  874  880  901
 [49]  999 1000 1025 1031 1086 1100 1151 1159 1168 1184 1189 1212 1231 1272
1316 1468 1502 1526 1596 1598 1638 1639 1651 1656
 [73] 1657 1675 1696 1709 1719 1723 1736 1763 1783 1785 1812 1830 1831 1840
1844 1845 1847 1848 1851 1854 1860 1873 1879 1883
 [97] 1893 1902 1910 1911 1919 1927 1936 1939 1947 1954 1956 1961 1978 1981
2006 2007 2025 2032 2119 2175 2227 2230 2237 2240
[121] 2250 2260 2266 2272 2275 2292 2293 2299 2319 2328 2330 2351 2357 2370
2387 2405 2425 2443 2475 2478 2508 2516 2520 2522
[145] 2527 2528 2543 2544 2545 2573 2580 2584 2647 2757 2776 2782 2812 2954
2991 3000 3022 3072 3091

> stat.ind
[1] NaN

##### my code
conf <- 0.95 
p <- c(0.05, 0.01, 0.005, 0.001)
#fill vectors
uc.LR <- cc.LR <- numeric(length(p))
uc.pval <- cc.pval <- numeric(length(p))
uc.statement <- cc.statement <- numeric(length(p))
ind.LR <- ind.pval <- numeric(length(p))
VaR.ind <- matrix(nrow=length(ret)-seq, ncol=length(p))
N <- TN <- T00 <- T11 <- T01 <- T10 <- T0 <- T1 <- pi0 <- pi1 <- pe <-
numeric(length(p))
for(i in 1:length(p)){
  uc.LR[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
conf)$uc.LRstat
  uc.pval[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
conf)$uc.LRp
  VaR.ind[,i] = ifelse(act < -VaRmatrix[,i], 1, 0)
  N[i] = sum(VaR.ind[,i])
  TN[i] = length(VaR.ind[,i])
  T00[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 0 & VaR.ind[,i][1:(TN[i]
- 1)] == 0, 1, 0)))
  T11[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 1 & VaR.ind[,i][1:(TN[i]
- 1)] == 1, 1, 0)))
  T01[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 1 & VaR.ind[,i][1:(TN[i]
- 1)] == 0, 1, 0)))
  T10[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 0 & VaR.ind[,i][1:(TN[i]
- 1)] == 1, 1, 0)))
  T0[i] = T00[i] + T01[i]
  T1[i] = T10[i] + T11[i]
  pi0[i] = T01[i]/T0[i]
  pi1[i] = T11[i]/T1[i]
  pe[i] = (T01[i] + T11[i])/(T0[i] + T1[i])
  ind.LR[i] = -2 * log((1 - pe[i])^(T00[i] + T10[i]) * pe[i]^(T01[i] +
T11[i])) + 
    2 * log((1 - pi0[i])^T00[i] * pi0[i]^T01[i] * (1 - pi1[i])^T10[i] *
pi1[i]^T11[i])
  ind.pval[i] <- 1 - pchisq(ind.LR[i], df = 1)
  cc.LR[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
conf)$cc.LRstat
  cc.pval[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
conf)$cc.LRp
}

###my results out of R-studio console #####
> uc.LR #from rugarch::VaRTest
[1]  0.0360193 11.4504151 10.9552213  6.9767907

> ind.LR #should be the difference between uc.LR and cc.LR
[1] 2.597815 1.107278 1.044127 5.630994

> cc.LR #from rugarch::VaRTest
[1] NaN NaN NaN NaN




--
View this message in context: http://r.789695.n4.nabble.com/Independence-test-rugarch-package-tp4689473p4689499.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From kw1958 at gmail.com  Sat Apr 26 14:24:16 2014
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Sat, 26 Apr 2014 08:24:16 -0400
Subject: [R-SIG-Finance] CVA for swaps
Message-ID: <131AAB23-D561-4D06-8E13-EFD86A918D8D@gmail.com>

Folks,

I was wondering if any of you have any pointers to *an* implementation or the *best* implementation of CVA for an interest rate swap?

Do they look at the correlation between interest rates and credit?

Thanks for your time,
KW

--


From alexios at 4dscape.com  Sat Apr 26 14:33:33 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sat, 26 Apr 2014 13:33:33 +0100
Subject: [R-SIG-Finance] Independence test rugarch package
In-Reply-To: <1398494581095-4689499.post@n4.nabble.com>
References: <1398454617034-4689473.post@n4.nabble.com>
	<535AF1DA.6060105@4dscape.com>
	<1398494581095-4689499.post@n4.nabble.com>
Message-ID: <9F9727F8-0ECA-4A01-940B-0164724224CB@4dscape.com>

Philippe,

The code is correct and returns the right results. The problem is that you are passing xts objects whereas the code cannot deal with this (ifelse and the comparison operators). The help page on VaRTest does state:

"actual: A numeric vector of the actual (realized) values.?
"VaR: The numeric vector of VaR."

Simply transform to numeric (as.numeric(actual) and as.numeric(VaR)) and you should get the correct answer. This was already covered in a previous post to this list.

Regards,

Alexios

On 26 Apr 2014, at 07:43, philippe <philippe.kappeler at hotmail.com> wrote:

> Hi Alexios,
> 
> Thanks for the quick response. I downloaded the package from "bitbucket" and
> retested. The test now reports values for the UC test, where before I
> received NaN for a confidence level 0f 0.95 (p=0.05) and rolling windows
> 500, 1000, 1500. The rolling window of 2000 was working fine before and
> still does. So this is fine and thanks. 
> 
> But now the CC test returns NaN's at all windows, whereas before window 2000
> was working. I copy pasted again the function (.LR.cc) out of getAnywhere
> and rerun the function in a sort of "traceback mode". I note that T11 is
> still equal to N, which in my eyes is still incorrect as the
> which(VaR.ind==1) results show. Please advise me if I misunderstood or
> overlooked something. 
> 
> Thank you very much.
> 
> The code slightly updated is again. 
> 
> ###############
> require(devtools) 
> install_bitbucket("rugarch","alexiosg") 
> 
> ret <- CHF
> seq <- 2000 #alternativly 500, 1000, 1500
> 
> #Normal Distribution VaR
> VaRdistn <- function(ret, prob=.05) {
>  ans <- -qnorm(prob, mean=0, sd=sd(ret)) 
>  signif(ans, digits=7)
> }
> 
> ### VaR 
> p <- c(0.05, 0.01, 0.005, 0.001) # confidence values for VaR
> act <- ret[(seq+1):length(ret)] # actual return
> VaRmatrix <- matrix(nrow=length(ret)-seq, ncol=length(p))
> for (i in 1:nrow(VaRmatrix) ) {
>  VaRmatrix[i,]<-  sapply(X=p, FUN=VaRdistn,ret=ret[i:(seq+i-1)] )
>  colnames(VaRmatrix) <- c("0.05", "0.01", "0.005", "0.001")
> }
> 
> #### RUGARCH package (getAnywhere(.LR.cc))
> VaR <- -VaRmatrix[,1] #change column and p value respectively to 2 for 0.01,
> 3 for 0.005 and 4 for 0.001
> p <- 0.05
> actual <- act
> #function (p, actual, VaR) 
> #{
>  VaR.ind = ifelse(actual < VaR, 1, 0)
>  N = sum(VaR.ind)
>  TN = length(VaR.ind)
>  T00 = sum(c(0, ifelse(VaR.ind[2:TN] == 0 & VaR.ind[1:(TN - 
>                                                          1)] == 0, 1, 0)))
>  T11 = sum(c(0, ifelse(VaR.ind[2:TN] == 1 & VaR.ind[1:(TN - 
>                                                          1)] == 1, 1, 0)))
>  T01 = sum(c(0, ifelse(VaR.ind[2:TN] == 1 & VaR.ind[1:(TN - 
>                                                          1)] == 0, 1, 0)))
>  T10 = sum(c(0, ifelse(VaR.ind[2:TN] == 0 & VaR.ind[1:(TN - 
>                                                          1)] == 1, 1, 0)))
>  T0 = T00 + T01
>  T1 = T10 + T11
>  pi0 = T01/T0
>  pi1 = T11/T1
>  pe = (T01 + T11)/(T0 + T1)
>  stat.ind = -2 * ((T00 + T10) * log(1 - pe) + (T01 + T11) * 
>                     log(pe)) + 2 * (T00 * log(1 - pi0) + T01 * log(pi0) + 
>                                       T10 * log(1 - pi1) + T11 * log(pi1))
>  #stat.uc = .LR.uc(p = p, TN = TN, N = N)
>  #stat.cc = stat.uc + stat.ind
>  #return(list(stat.cc = stat.cc, stat.uc = stat.uc, N = N, 
>   #           TN = TN))
> #}
> #### your results out of R-studio console #######
>> N
> [1] 163
> 
>> T00
> [1] 3048
> 
>> T00
> [1] 3048
> 
>> T11
> [1] 163
> 
>> T01
> [1] 0
> 
>> T10
> [1] 0
> 
>> which(VaR.ind == 1)
>  [1]   10   55  106  117  151  174  178  186  191  213  227  238  246  302 
> 334  368  373  388  395  438  486  496  497  503
> [25]  544  581  606  614  623  637  655  664  670  672  697  722  727  754 
> 767  771  778  815  818  835  864  874  880  901
> [49]  999 1000 1025 1031 1086 1100 1151 1159 1168 1184 1189 1212 1231 1272
> 1316 1468 1502 1526 1596 1598 1638 1639 1651 1656
> [73] 1657 1675 1696 1709 1719 1723 1736 1763 1783 1785 1812 1830 1831 1840
> 1844 1845 1847 1848 1851 1854 1860 1873 1879 1883
> [97] 1893 1902 1910 1911 1919 1927 1936 1939 1947 1954 1956 1961 1978 1981
> 2006 2007 2025 2032 2119 2175 2227 2230 2237 2240
> [121] 2250 2260 2266 2272 2275 2292 2293 2299 2319 2328 2330 2351 2357 2370
> 2387 2405 2425 2443 2475 2478 2508 2516 2520 2522
> [145] 2527 2528 2543 2544 2545 2573 2580 2584 2647 2757 2776 2782 2812 2954
> 2991 3000 3022 3072 3091
> 
>> stat.ind
> [1] NaN
> 
> ##### my code
> conf <- 0.95 
> p <- c(0.05, 0.01, 0.005, 0.001)
> #fill vectors
> uc.LR <- cc.LR <- numeric(length(p))
> uc.pval <- cc.pval <- numeric(length(p))
> uc.statement <- cc.statement <- numeric(length(p))
> ind.LR <- ind.pval <- numeric(length(p))
> VaR.ind <- matrix(nrow=length(ret)-seq, ncol=length(p))
> N <- TN <- T00 <- T11 <- T01 <- T10 <- T0 <- T1 <- pi0 <- pi1 <- pe <-
> numeric(length(p))
> for(i in 1:length(p)){
>  uc.LR[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
> conf)$uc.LRstat
>  uc.pval[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
> conf)$uc.LRp
>  VaR.ind[,i] = ifelse(act < -VaRmatrix[,i], 1, 0)
>  N[i] = sum(VaR.ind[,i])
>  TN[i] = length(VaR.ind[,i])
>  T00[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 0 & VaR.ind[,i][1:(TN[i]
> - 1)] == 0, 1, 0)))
>  T11[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 1 & VaR.ind[,i][1:(TN[i]
> - 1)] == 1, 1, 0)))
>  T01[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 1 & VaR.ind[,i][1:(TN[i]
> - 1)] == 0, 1, 0)))
>  T10[i] = sum(c(0, ifelse(VaR.ind[,i][2:TN[i]] == 0 & VaR.ind[,i][1:(TN[i]
> - 1)] == 1, 1, 0)))
>  T0[i] = T00[i] + T01[i]
>  T1[i] = T10[i] + T11[i]
>  pi0[i] = T01[i]/T0[i]
>  pi1[i] = T11[i]/T1[i]
>  pe[i] = (T01[i] + T11[i])/(T0[i] + T1[i])
>  ind.LR[i] = -2 * log((1 - pe[i])^(T00[i] + T10[i]) * pe[i]^(T01[i] +
> T11[i])) + 
>    2 * log((1 - pi0[i])^T00[i] * pi0[i]^T01[i] * (1 - pi1[i])^T10[i] *
> pi1[i]^T11[i])
>  ind.pval[i] <- 1 - pchisq(ind.LR[i], df = 1)
>  cc.LR[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
> conf)$cc.LRstat
>  cc.pval[i] <- VaRTest(alpha = p[i], act, -VaRmatrix[,i], conf.level =
> conf)$cc.LRp
> }
> 
> ###my results out of R-studio console #####
>> uc.LR #from rugarch::VaRTest
> [1]  0.0360193 11.4504151 10.9552213  6.9767907
> 
>> ind.LR #should be the difference between uc.LR and cc.LR
> [1] 2.597815 1.107278 1.044127 5.630994
> 
>> cc.LR #from rugarch::VaRTest
> [1] NaN NaN NaN NaN
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Independence-test-rugarch-package-tp4689473p4689499.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 


From philippe.kappeler at hotmail.com  Sat Apr 26 14:41:49 2014
From: philippe.kappeler at hotmail.com (philippe)
Date: Sat, 26 Apr 2014 05:41:49 -0700 (PDT)
Subject: [R-SIG-Finance] Independence test rugarch package
In-Reply-To: <9F9727F8-0ECA-4A01-940B-0164724224CB@4dscape.com>
References: <1398454617034-4689473.post@n4.nabble.com>
	<535AF1DA.6060105@4dscape.com>
	<1398494581095-4689499.post@n4.nabble.com>
	<9F9727F8-0ECA-4A01-940B-0164724224CB@4dscape.com>
Message-ID: <1398516109113-4689515.post@n4.nabble.com>

Thank you very much. I totally overlooked that. Have a nice weekend, Philippe



--
View this message in context: http://r.789695.n4.nabble.com/Independence-test-rugarch-package-tp4689473p4689515.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From jzmoser at gmail.com  Sun Apr 27 14:07:06 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Sun, 27 Apr 2014 14:07:06 +0200
Subject: [R-SIG-Finance] student t mixture VaR in R // imitate example
 2.23 in C.Alexander: Market Risk IV
In-Reply-To: <535A6053.3080304@googlemail.com>
References: <535A2196.20501@googlemail.com>	<3AD18F1A-CCCA-4CA1-9D6A-F0A5669DBF7B@4dscape.com>
	<535A3792.3050105@googlemail.com> <535A51C8.70606@4dscape.com>
	<535A6053.3080304@googlemail.com>
Message-ID: <535CF2EA.9000906@googlemail.com>

Finally things are clear. R users who want to work with a Student t 
mixture distribution in the context of Value at Risk or Expected 
Shortfall can feel safe to use an implementation similar to the one 
given below (in an older mail of mine), but choosing "std" instead of 
"sstd" when using the "rugarch" package or alternatively applying the 
function "pTF2" when using the "gamlss.dist" package.

The following corrections will be interesting mainly for people who work 
with the book (Market Risk Analysis IV - first edition printed in 2009) 
of C.Alexander.

The implementation of the objective function (details were given earlier)
      L * P(X < (q-m)/r) + (1-L) * P(Y < (q-n)/s) - theta = 0
by C.Alexander is wrong, both in theory (see p. 117) and practice (see 
e.g. the Excel Example IV.2.23 on the CD).

TDIST(-(-C25-D8)/D10*SQRT(C22/(C22-2)),C22,1)

would be the correct transformation of the random variable to be Student 
t with variance C22/(C22-2), which is the variance of a standard Student 
t (NOT a STANDARDIZED one!) random variable with degrees of freedom 
"C22" - given that "C22" > 2 of course.
This is because Excel has only the standard Student t distribution 
implemented (in a quite cumbersome form).

(Remark: In this example "C25" is the desired quantile, "D8" is the mean 
of the respective Student t and "D10" is its standard deviation.)

The implementation given in the spreadsheets which can be found on the 
CD contained in the book is however

SQRT(C22/(C22-2))*TDIST(-(-C25-D8)/D10,C22,1)

Which makes the same mistake as the footnote on page 117:
"In general, if X has distribution F(x) and Y=aX, a being a constant, 
then y has distribution function a^(?1) * F(x)"

I want to thank Alexios for his support in clearifying things!
Best,
Johannes





Am 25.04.2014 15:17, schrieb Johannes Moser:
> Thanks for your help so far, Alexios!
>
> I didn`t want to write down all the datails of the exercise because my 
> text alredy was lengthly and also because I didn`t want to violate any 
> copyrights.
> Rather, I was hoping that someone has the book and the CD at hand 
> because I think that the book is pretty popular.
>
> To answer your question: The EXCEL example from the book was adapted 
> by me in the following way:
>
> 1) change the risk horizon to 1 day (so that there would be no scaling
> and the autocorrelation doesn`t matter)
> 2) if necessary change the significance level (1% or 0,1% in my example)
>
> this has already been stated in my first mail. So the numbers for for 
> mu_stress, variance_quiet and variance_stress are the (annualized) 
> numbers given in the example scaled to one day.
> I just did copy and paste with the down-scaled numbers from the EXCEL 
> spreadsheet to check if my own R syntax leads to the same results as 
> the EXCEL setup given by the CD in the book of C.Alexander.
>
> A general description of my approach might be given by the following 
> sketch:
> Calculate 1-day VaR with confidence level 99% (and 99,9%) of a 
> bivariate student t mixture distribution by means of backing out the 
> quantile from the formula
>     L * P(X < (q-m)/r) + (1-L) * P(Y < (q-n)/s) = theta
> (see C.Alexander p.113)
> (the VaR is just minus the 1% or 0.1% quantile "q")
> "L" is the mixing law giving the probability for the mixture random 
> variable to follow the same student-t distribution as the random 
> variable "X" with mean "m", standard deviation "r" and degrees of 
> freedom "df1".
> The  mixture random variable follows a student t distribution with 
> mean "n", standard deviation "s" and degrees of freedom "df2" with 
> probability "(1-L)". This is the distribution for the random variable 
> "Y".
> "q" ist the required "theta"-quantile (as pointed out, "theta" is set 
> to 0.01 and 0.001 in my example)
>
> The notation in my R code is:
>
> p_quiet = L
> mu_quiet = m
> mu_stress = n
> df_quiet = df1
> df_stress = df2
> variance_quiet = r^2
> variance_stress = s^2
> theta = theta
>
> I hope that with these details everyone can evaluate if my syntax is 
> set up correctly.
> The values for these variables as to the modified example from 
> Alexanders book can be  read in the R syntax given in my first mail.
>
> My aim (later!) is to simulate a fictive return series in a 
> regime-switching manner using student t mixture models and calculate 
> the analytical VaR and Expected Shortfall in a dynamical way.
> Then I want to apply several other estimation techniques to the 
> simulated mixture series and examine their performance in relation to 
> the analytic results.
> But first I have to make sure that my analytic VaR for the student t 
> mixture model is correct.
> However, verification of the Example given by C.Alexander indeed 
> requires her book and the enclosed CD with the EXCEL workbooks.
> I just can`t post all this stuff here.
>
>
>
>
> Am 25.04.2014 14:15, schrieb alexios ghalanos:
>> I suggest you take a break and consider that in order to help you, it is
>> required that you state ALL the assumptions and provide a complete
>> example. Since the book is not generally available, and you have told us
>> very little about the problem and its assumptions (other than a page and
>> example number), then you shouldn't expect much help.
>>
>> Alexios
>>
>> PS How did you come up with the numbers for mu_stress, variance_quiet
>> and variance_stress? From what I am told, the book example provides the
>> annualized values and you are required to calculate the 10-day VaR (so
>> you are required to rescale the numbers to their 10-day equivalents).
>>
>> On 25/04/2014 11:23, Johannes Moser wrote:
>>> Thanks a lot, Alexios!
>>> I have corrected this issue. The result is the same, though.
>>>
>>> I forgot to mention that the RUGARCH-package is required to run the 
>>> code.
>>>
>>> At the moment I try to find the error in either
>>> - my own theoretical thoughts (e.g. confusing the scale parameter with
>>> the standard deviation)
>>> - the implementation made by C.Alexander (on page 117 she writes in a
>>> footnote: "In general, if X has distribution F(x) and Y=aX, a being a
>>> constant, then y has distribution function a^(?1) * F(x)". Either I am
>>> completely burnout right now, or this must be "F(a^(?1)*x)" in the end.
>>> So maybe this is not just a typo, but also incorrectly implemented in
>>> the quite complicated EXCEL formula.)
>>> - some EXCEL or R issue. I think her EXCEL syntax has been 
>>> programmed in
>>> version 2003, but I`m running 2010.
>>>
>>> Any help is appreciated a lot!
>>>
>>>
>>>
>>> Am 25.04.2014 11:46, schrieb Alexios Ghalanos:
>>>> A quick look at your code suggests that you should use "std" (student)
>>>> not "sstd" (skew student) for distribution.
>>>>
>>>> Alexios
>>>>
>>>>> On 25 Apr 2014, at 09:49, Johannes Moser <jzmoser at gmail.com> wrote:
>>>>>
>>>>> Dear R community,
>>>>>
>>>>> in trying to set up a little simulation study I adapt the ideas 
>>>>> found in
>>>>> "Carol Alexander: Market Risk IV - Value at Risk Models" on page 
>>>>> 111 ff.
>>>>> and implement them in R.
>>>>> This project is about student t mixture distributions and Value at 
>>>>> Risk
>>>>> / Expected Shortfall.
>>>>>
>>>>> The following code is my setup so far, and the syntax is 
>>>>> calibrated to
>>>>> resemble the Example 2.23 on page 118 in the mentioned book of
>>>>> Alexander. There is a  EXCEL-file coming with the book and I noticed
>>>>> that my results don`t match the results of the EXCEL implementation.
>>>>>
>>>>> e.g. my result for theta=0.001 is
>>>>>
>>>>> 0.0841052 (method 1) and
>>>>>
>>>>> 0.0842109 (method 2)
>>>>> ... but the EXCEL-file coming with the book says that it was 0.1152
>>>>>
>>>>>
>>>>> setting theta=0.01 gives
>>>>>
>>>>> 0.04493586 (method 1) and
>>>>>
>>>>> 0.04490717 (method 2)
>>>>>
>>>>> ... but the EXCEL-file coming with the book says that it was 0.0616
>>>>>
>>>>>
>>>>> Maybe some of you guys have this book at hand and are able to 
>>>>> verify and
>>>>> hopefully find a solution for my worries.
>>>>> Or even if you don`t have the book you might still be able to 
>>>>> assess the
>>>>> correctness of my approach and implementation?
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ################################################################################################## 
>>>>>
>>>>>
>>>>> # SET UP MIXTURE INGREDIENTS (calibrate to C.Alexander Market Risk
>>>>> Analysis IV Exercise 2.23)
>>>>>
>>>>> p_quiet <- 0.75
>>>>> mu_quiet <- 0.0
>>>>> mu_stress <- -0.0004
>>>>> df_quiet <- 10
>>>>> df_stress <- 5
>>>>> variance_quiet <- 0.0126^2
>>>>> variance_stress <- 0.0253^2
>>>>> theta <- 0.001
>>>>>
>>>>>
>>>>> # METHOD_1)   Backing out mixture VaR from implicit analytic formula:
>>>>> find_quant <- function(quant) {
>>>>>        (p_quiet*pdist(distribution = "sstd",
>>>>> (quant-mu_quiet)/sqrt(variance_quiet)  , mu = 0, sigma = 1, shape =
>>>>> df_quiet)
>>>>>        + (1-p_quiet)*pdist(distribution = "sstd",
>>>>> (quant-mu_stress)/sqrt(variance_stress)  , mu = 0, sigma = 1, shape =
>>>>> df_stress) - theta)
>>>>> }
>>>>> bestquant <- uniroot(f = find_quant, interval = c(-5, 1))
>>>>> t_mix_VaR1 <- -bestquant$root
>>>>>
>>>>>
>>>>> # METHOD_2)   Estimating mixture VaR by simulation:
>>>>> nsim <- 10000000
>>>>> u_mix <- x <- 1*(runif(nsim) < p_quiet)
>>>>> t_quiet <- rdist(distribution = "sstd", nsim  , mu = mu_quiet, 
>>>>> sigma =
>>>>> sqrt(variance_quiet), shape = df_quiet)
>>>>> t_stress <- rdist(distribution = "sstd", nsim  , mu = mu_stress, 
>>>>> sigma =
>>>>> sqrt(variance_stress), shape = df_stress)
>>>>> t_mixture <- u_mix*t_quiet + (1-u_mix)*t_stress
>>>>> t_mix_VaR2 <- as.numeric(-quantile( t_mixture , probs=theta  ))
>>>>>
>>>>> # Compare results
>>>>> t_mix_VaR1
>>>>> t_mix_VaR2
>>>>> ################################################################################################## 
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> The EXCEL spreadsheet "EX_IV.2.23" in the workbook 
>>>>> "Examples_IV.2.xls"
>>>>> has been used and modified as follows:
>>>>> 1) change the risk horizon to 1 day (so that there would be no 
>>>>> scaling
>>>>> and the autocorrelation doesn`t matter)
>>>>> 2) if necessary change the significance level (1% or 0,1% in my 
>>>>> example)
>>>>> 3) press F11 to recalcualte the mixture parameters over the risk 
>>>>> horizon
>>>>> 4) apply EXCEL SOLVER to line C24 while allowing for changing cell 
>>>>> C25
>>>>> to get the t Mixture VaR
>>>>>
>>>>> Thanks a lot for any ideas or suggestions!
>>>>> Johannes
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>      [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-SIG-Finance at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>> -- Also note that this is not the r-help list where general R
>>>>> questions should go.
>>>>>
>

-- 
_________________________
Johannes Moser
Sophie-Charlotten-Str. 35
14059 Berlin
Tel: 0176 2171 2196


From jzmoser at gmail.com  Mon Apr 28 22:51:35 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Mon, 28 Apr 2014 22:51:35 +0200
Subject: [R-SIG-Finance] student t mixture VaR in R // imitate example
 2.23 in C.Alexander: Market Risk IV
In-Reply-To: <535CF2EA.9000906@googlemail.com>
References: <535A2196.20501@googlemail.com>	<3AD18F1A-CCCA-4CA1-9D6A-F0A5669DBF7B@4dscape.com>
	<535A3792.3050105@googlemail.com> <535A51C8.70606@4dscape.com>
	<535A6053.3080304@googlemail.com> <535CF2EA.9000906@googlemail.com>
Message-ID: <535EBF57.9010301@googlemail.com>

A final remark with respect to the expected shortfall:
The formula (p.133 IV.2.90) in the book of Alexander is not right either.

There are some helping analytical formulas for the ES in a book of 
Cizek, H?rdle and Weron (2011): "Statistical Tools for Finance and 
Insurance". They are helping at least once one finds out (the notation 
is a mess!) that in this book "c" and "\sigma" BOTH denote the scaling 
factor of the student t distribution (p.60f. and  p.73) and NOT the 
standard deviation.

The following syntax works fine (as to my best knowledge):


#############################################################################
# VaR and ES for bivariate student t mixtures

# arbitrary values for the two component Student t distributions:
p_quiet <- 0.9                        # mixing law
mu_quiet <- 0.5                     # first mean
mu_stress <- -0.3                    # second mean
df_quiet <- 25                        # first degrees of freedom
df_stress <- 3                            # second degrees of freedom
variance_quiet <- 0.0285^2    # first variance
variance_stress <- 1^2               # second variance
theta <- 0.01                            # coverage of VaR and ES (the 
latter being called "Expected Tail Loss" in C.Alexander)

#############################################################################
# VaR

find_quant <- function(quant) {
      (p_quiet*pt( 
(quant-mu_quiet)/sqrt(variance_quiet)*sqrt(df_quiet/(df_quiet-2))  , df 
= df_quiet)
       + (1-p_quiet)*pt( 
(quant-mu_stress)/sqrt(variance_stress)*sqrt(df_stress/(df_stress-2)) , 
df = df_stress) - theta)
}
t_mix_VaR <- -uniroot(f = find_quant, interval = c(-5, 1), 
maxiter=10000, tol = 1e-12)$root

#############################################################################
# ES

scale_quiet <-  sqrt( variance_quiet ) * sqrt( (df_quiet-2)/df_quiet )
scale_stress <-  sqrt( variance_stress ) * sqrt( (df_stress-2)/df_stress )
c_quiet <- (-t_mix_VaR-mu_quiet)/scale_quiet
c_stress <- (-t_mix_VaR-mu_stress)/scale_stress
Ttail_quiet <- dt( c_quiet ,df=df_quiet ) * (df_quiet+ c_quiet^2) / 
(df_quiet-1)
Ttail_stress <- dt( c_stress ,df=df_stress ) * (df_stress+ c_stress^2) / 
(df_stress-1)
t_mix_ETL <-  ( 1/theta*( p_quiet*( scale_quiet*Ttail_quiet - 
mu_quiet*pt(c_quiet , df=df_quiet ) )
                + (1-p_quiet)*( scale_stress*Ttail_stress  - 
mu_stress*pt(c_stress , df=df_stress ) )   ) )

### Results
t_mix_VaR
t_mix_ETL

#############################################################################







Am 4/27/2014 2:07 PM, schrieb Johannes Moser:
> Finally things are clear. R users who want to work with a Student t 
> mixture distribution in the context of Value at Risk or Expected 
> Shortfall can feel safe to use an implementation similar to the one 
> given below (in an older mail of mine), but choosing "std" instead of 
> "sstd" when using the "rugarch" package or alternatively applying the 
> function "pTF2" when using the "gamlss.dist" package.
>
> The following corrections will be interesting mainly for people who 
> work with the book (Market Risk Analysis IV - first edition printed in 
> 2009) of C.Alexander.
>
> The implementation of the objective function (details were given earlier)
>      L * P(X < (q-m)/r) + (1-L) * P(Y < (q-n)/s) - theta = 0
> by C.Alexander is wrong, both in theory (see p. 117) and practice (see 
> e.g. the Excel Example IV.2.23 on the CD).
>
> TDIST(-(-C25-D8)/D10*SQRT(C22/(C22-2)),C22,1)
>
> would be the correct transformation of the random variable to be 
> Student t with variance C22/(C22-2), which is the variance of a 
> standard Student t (NOT a STANDARDIZED one!) random variable with 
> degrees of freedom "C22" - given that "C22" > 2 of course.
> This is because Excel has only the standard Student t distribution 
> implemented (in a quite cumbersome form).
>
> (Remark: In this example "C25" is the desired quantile, "D8" is the 
> mean of the respective Student t and "D10" is its standard deviation.)
>
> The implementation given in the spreadsheets which can be found on the 
> CD contained in the book is however
>
> SQRT(C22/(C22-2))*TDIST(-(-C25-D8)/D10,C22,1)
>
> Which makes the same mistake as the footnote on page 117:
> "In general, if X has distribution F(x) and Y=aX, a being a constant, 
> then y has distribution function a^(?1) * F(x)"
>
> I want to thank Alexios for his support in clearifying things!
> Best,
> Johannes
>
>
>
>
>
> Am 25.04.2014 15:17, schrieb Johannes Moser:
>> Thanks for your help so far, Alexios!
>>
>> I didn`t want to write down all the datails of the exercise because 
>> my text alredy was lengthly and also because I didn`t want to violate 
>> any copyrights.
>> Rather, I was hoping that someone has the book and the CD at hand 
>> because I think that the book is pretty popular.
>>
>> To answer your question: The EXCEL example from the book was adapted 
>> by me in the following way:
>>
>> 1) change the risk horizon to 1 day (so that there would be no scaling
>> and the autocorrelation doesn`t matter)
>> 2) if necessary change the significance level (1% or 0,1% in my example)
>>
>> this has already been stated in my first mail. So the numbers for for 
>> mu_stress, variance_quiet and variance_stress are the (annualized) 
>> numbers given in the example scaled to one day.
>> I just did copy and paste with the down-scaled numbers from the EXCEL 
>> spreadsheet to check if my own R syntax leads to the same results as 
>> the EXCEL setup given by the CD in the book of C.Alexander.
>>
>> A general description of my approach might be given by the following 
>> sketch:
>> Calculate 1-day VaR with confidence level 99% (and 99,9%) of a 
>> bivariate student t mixture distribution by means of backing out the 
>> quantile from the formula
>>     L * P(X < (q-m)/r) + (1-L) * P(Y < (q-n)/s) = theta
>> (see C.Alexander p.113)
>> (the VaR is just minus the 1% or 0.1% quantile "q")
>> "L" is the mixing law giving the probability for the mixture random 
>> variable to follow the same student-t distribution as the random 
>> variable "X" with mean "m", standard deviation "r" and degrees of 
>> freedom "df1".
>> The  mixture random variable follows a student t distribution with 
>> mean "n", standard deviation "s" and degrees of freedom "df2" with 
>> probability "(1-L)". This is the distribution for the random variable 
>> "Y".
>> "q" ist the required "theta"-quantile (as pointed out, "theta" is set 
>> to 0.01 and 0.001 in my example)
>>
>> The notation in my R code is:
>>
>> p_quiet = L
>> mu_quiet = m
>> mu_stress = n
>> df_quiet = df1
>> df_stress = df2
>> variance_quiet = r^2
>> variance_stress = s^2
>> theta = theta
>>
>> I hope that with these details everyone can evaluate if my syntax is 
>> set up correctly.
>> The values for these variables as to the modified example from 
>> Alexanders book can be  read in the R syntax given in my first mail.
>>
>> My aim (later!) is to simulate a fictive return series in a 
>> regime-switching manner using student t mixture models and calculate 
>> the analytical VaR and Expected Shortfall in a dynamical way.
>> Then I want to apply several other estimation techniques to the 
>> simulated mixture series and examine their performance in relation to 
>> the analytic results.
>> But first I have to make sure that my analytic VaR for the student t 
>> mixture model is correct.
>> However, verification of the Example given by C.Alexander indeed 
>> requires her book and the enclosed CD with the EXCEL workbooks.
>> I just can`t post all this stuff here.
>>
>>
>>
>>
>> Am 25.04.2014 14:15, schrieb alexios ghalanos:
>>> I suggest you take a break and consider that in order to help you, 
>>> it is
>>> required that you state ALL the assumptions and provide a complete
>>> example. Since the book is not generally available, and you have 
>>> told us
>>> very little about the problem and its assumptions (other than a page 
>>> and
>>> example number), then you shouldn't expect much help.
>>>
>>> Alexios
>>>
>>> PS How did you come up with the numbers for mu_stress, variance_quiet
>>> and variance_stress? From what I am told, the book example provides the
>>> annualized values and you are required to calculate the 10-day VaR (so
>>> you are required to rescale the numbers to their 10-day equivalents).
>>>
>>> On 25/04/2014 11:23, Johannes Moser wrote:
>>>> Thanks a lot, Alexios!
>>>> I have corrected this issue. The result is the same, though.
>>>>
>>>> I forgot to mention that the RUGARCH-package is required to run the 
>>>> code.
>>>>
>>>> At the moment I try to find the error in either
>>>> - my own theoretical thoughts (e.g. confusing the scale parameter with
>>>> the standard deviation)
>>>> - the implementation made by C.Alexander (on page 117 she writes in a
>>>> footnote: "In general, if X has distribution F(x) and Y=aX, a being a
>>>> constant, then y has distribution function a^(?1) * F(x)". Either I am
>>>> completely burnout right now, or this must be "F(a^(?1)*x)" in the 
>>>> end.
>>>> So maybe this is not just a typo, but also incorrectly implemented in
>>>> the quite complicated EXCEL formula.)
>>>> - some EXCEL or R issue. I think her EXCEL syntax has been 
>>>> programmed in
>>>> version 2003, but I`m running 2010.
>>>>
>>>> Any help is appreciated a lot!
>>>>
>>>>
>>>>
>>>> Am 25.04.2014 11:46, schrieb Alexios Ghalanos:
>>>>> A quick look at your code suggests that you should use "std" 
>>>>> (student)
>>>>> not "sstd" (skew student) for distribution.
>>>>>
>>>>> Alexios
>>>>>
>>>>>> On 25 Apr 2014, at 09:49, Johannes Moser <jzmoser at gmail.com> wrote:
>>>>>>
>>>>>> Dear R community,
>>>>>>
>>>>>> in trying to set up a little simulation study I adapt the ideas 
>>>>>> found in
>>>>>> "Carol Alexander: Market Risk IV - Value at Risk Models" on page 
>>>>>> 111 ff.
>>>>>> and implement them in R.
>>>>>> This project is about student t mixture distributions and Value 
>>>>>> at Risk
>>>>>> / Expected Shortfall.
>>>>>>
>>>>>> The following code is my setup so far, and the syntax is 
>>>>>> calibrated to
>>>>>> resemble the Example 2.23 on page 118 in the mentioned book of
>>>>>> Alexander. There is a  EXCEL-file coming with the book and I noticed
>>>>>> that my results don`t match the results of the EXCEL implementation.
>>>>>>
>>>>>> e.g. my result for theta=0.001 is
>>>>>>
>>>>>> 0.0841052 (method 1) and
>>>>>>
>>>>>> 0.0842109 (method 2)
>>>>>> ... but the EXCEL-file coming with the book says that it was 0.1152
>>>>>>
>>>>>>
>>>>>> setting theta=0.01 gives
>>>>>>
>>>>>> 0.04493586 (method 1) and
>>>>>>
>>>>>> 0.04490717 (method 2)
>>>>>>
>>>>>> ... but the EXCEL-file coming with the book says that it was 0.0616
>>>>>>
>>>>>>
>>>>>> Maybe some of you guys have this book at hand and are able to 
>>>>>> verify and
>>>>>> hopefully find a solution for my worries.
>>>>>> Or even if you don`t have the book you might still be able to 
>>>>>> assess the
>>>>>> correctness of my approach and implementation?
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> ################################################################################################## 
>>>>>>
>>>>>>
>>>>>> # SET UP MIXTURE INGREDIENTS (calibrate to C.Alexander Market Risk
>>>>>> Analysis IV Exercise 2.23)
>>>>>>
>>>>>> p_quiet <- 0.75
>>>>>> mu_quiet <- 0.0
>>>>>> mu_stress <- -0.0004
>>>>>> df_quiet <- 10
>>>>>> df_stress <- 5
>>>>>> variance_quiet <- 0.0126^2
>>>>>> variance_stress <- 0.0253^2
>>>>>> theta <- 0.001
>>>>>>
>>>>>>
>>>>>> # METHOD_1)   Backing out mixture VaR from implicit analytic 
>>>>>> formula:
>>>>>> find_quant <- function(quant) {
>>>>>>        (p_quiet*pdist(distribution = "sstd",
>>>>>> (quant-mu_quiet)/sqrt(variance_quiet)  , mu = 0, sigma = 1, shape =
>>>>>> df_quiet)
>>>>>>        + (1-p_quiet)*pdist(distribution = "sstd",
>>>>>> (quant-mu_stress)/sqrt(variance_stress)  , mu = 0, sigma = 1, 
>>>>>> shape =
>>>>>> df_stress) - theta)
>>>>>> }
>>>>>> bestquant <- uniroot(f = find_quant, interval = c(-5, 1))
>>>>>> t_mix_VaR1 <- -bestquant$root
>>>>>>
>>>>>>
>>>>>> # METHOD_2)   Estimating mixture VaR by simulation:
>>>>>> nsim <- 10000000
>>>>>> u_mix <- x <- 1*(runif(nsim) < p_quiet)
>>>>>> t_quiet <- rdist(distribution = "sstd", nsim  , mu = mu_quiet, 
>>>>>> sigma =
>>>>>> sqrt(variance_quiet), shape = df_quiet)
>>>>>> t_stress <- rdist(distribution = "sstd", nsim  , mu = mu_stress, 
>>>>>> sigma =
>>>>>> sqrt(variance_stress), shape = df_stress)
>>>>>> t_mixture <- u_mix*t_quiet + (1-u_mix)*t_stress
>>>>>> t_mix_VaR2 <- as.numeric(-quantile( t_mixture , probs=theta  ))
>>>>>>
>>>>>> # Compare results
>>>>>> t_mix_VaR1
>>>>>> t_mix_VaR2
>>>>>> ################################################################################################## 
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> The EXCEL spreadsheet "EX_IV.2.23" in the workbook 
>>>>>> "Examples_IV.2.xls"
>>>>>> has been used and modified as follows:
>>>>>> 1) change the risk horizon to 1 day (so that there would be no 
>>>>>> scaling
>>>>>> and the autocorrelation doesn`t matter)
>>>>>> 2) if necessary change the significance level (1% or 0,1% in my 
>>>>>> example)
>>>>>> 3) press F11 to recalcualte the mixture parameters over the risk 
>>>>>> horizon
>>>>>> 4) apply EXCEL SOLVER to line C24 while allowing for changing 
>>>>>> cell C25
>>>>>> to get the t Mixture VaR
>>>>>>
>>>>>> Thanks a lot for any ideas or suggestions!
>>>>>> Johannes
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>      [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-SIG-Finance at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>>> -- Also note that this is not the r-help list where general R
>>>>>> questions should go.
>>>>>>
>>
>

--


From aidan.corcoran11 at gmail.com  Wed Apr 30 19:35:45 2014
From: aidan.corcoran11 at gmail.com (Aidan Corcoran)
Date: Wed, 30 Apr 2014 13:35:45 -0400
Subject: [R-SIG-Finance] rbbg connection problem
Message-ID: <CADv5Py5t4K-WASiDDkiQFYBMcLDh17M2ZP2K6SXq054iOEvL8Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140430/31d10e33/attachment.pl>

From john.laing at gmail.com  Wed Apr 30 19:55:45 2014
From: john.laing at gmail.com (John Laing)
Date: Wed, 30 Apr 2014 13:55:45 -0400
Subject: [R-SIG-Finance] rbbg connection problem
In-Reply-To: <CADv5Py5t4K-WASiDDkiQFYBMcLDh17M2ZP2K6SXq054iOEvL8Q@mail.gmail.com>
References: <CADv5Py5t4K-WASiDDkiQFYBMcLDh17M2ZP2K6SXq054iOEvL8Q@mail.gmail.com>
Message-ID: <CAA3Wa=s7rJjzB3G3eSXOOG0jAN9A_Wf2=jEetJjKyum_8f+=fQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140430/0c023078/attachment.pl>

From pastirs at gmail.com  Wed Apr 30 21:21:37 2014
From: pastirs at gmail.com (Milos Cipovic)
Date: Wed, 30 Apr 2014 21:21:37 +0200
Subject: [R-SIG-Finance] efficient code for nonlinear garch model
Message-ID: <CAKoFBbd8dQPm8EMKmZDejOQKk9sWP66pH6ZC3+d3UAvbbtgAzw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140430/4df50b2e/attachment.pl>

From aidan.corcoran11 at gmail.com  Thu May  1 00:13:45 2014
From: aidan.corcoran11 at gmail.com (Aidan Corcoran)
Date: Wed, 30 Apr 2014 18:13:45 -0400
Subject: [R-SIG-Finance] rbbg connection problem
In-Reply-To: <CAA3Wa=s7rJjzB3G3eSXOOG0jAN9A_Wf2=jEetJjKyum_8f+=fQ@mail.gmail.com>
References: <CADv5Py5t4K-WASiDDkiQFYBMcLDh17M2ZP2K6SXq054iOEvL8Q@mail.gmail.com>
	<CAA3Wa=s7rJjzB3G3eSXOOG0jAN9A_Wf2=jEetJjKyum_8f+=fQ@mail.gmail.com>
Message-ID: <CADv5Py5_O8e6Jt5Gdy+T7i+HkSQ9iWnMB=9AGA4Mb=625VdudQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140430/6d5ea1ac/attachment.pl>

From patrick at burns-stat.com  Thu May  1 00:42:02 2014
From: patrick at burns-stat.com (Patrick Burns)
Date: Wed, 30 Apr 2014 23:42:02 +0100
Subject: [R-SIG-Finance] efficient code for nonlinear garch model
In-Reply-To: <CAKoFBbd8dQPm8EMKmZDejOQKk9sWP66pH6ZC3+d3UAvbbtgAzw@mail.gmail.com>
References: <CAKoFBbd8dQPm8EMKmZDejOQKk9sWP66pH6ZC3+d3UAvbbtgAzw@mail.gmail.com>
Message-ID: <53617C3A.1020807@burns-stat.com>

It should be easy enough to use 'Rcpp' to
write the likelihood in C++ and gain a
bunch of speed.

Pat

On 30/04/2014 20:21, Milos Cipovic wrote:
> Hi,
> I'm trying to think of efficient code for NGARCH model,
> sigma[t]^2=omega + alpha*(R[t-1]-theta*sigma[t-1])^2 + beta*(sigma[t-1)]^2
> from book (Elements of Financial Risk Menagment-Peter F Christoffersen page
> 77).
>
> I already coded it the "usual way" but it's taking too long (around 30 s).
> Now I'm trying somehow to implement -filter- function like in paper -
> Parameter Estimation of ARMA Models with
> GARCH/APARCH Errors An R and SPlus Software Implementation - page 6.
> The problem I can't overcome is that in this model I can't figure out how
> to present the middle part ( 2 * Alpha * R[t-1]*theta*sigma[t-1]) with
> filter function or is it even possible to code it this way.
>
> Any help would appreciated.Here is my slower code:
>
> "Ngarch" <- function(rtn,value){
>    # Estimation of a non-symmertic GARCH, NGARCH(1,1), model.
>    # Assume normal innovations
>    # rtn: return series
>    #
>    # The likelihood function "mxlk" can be modified to fit more general
> NGARCH
>    #  models.
>    # obtain initial estimates
>    rtn=as.matrix(rtn)
>    mu=mean(rtn)
>    par=c(0.0001,0.8,0.01,0.7)
>    #
>    mxlk <- function(par){
>      mxlk=0
>      ht=var(rtn)
>      T=length(rtn)
>      if(T > 40)ht=var(rtn[1:40])
>      at=rtn-mu
>      for (i in 2:T){
>
> sig2t=par[1]+par[2]*ht[i-1]+par[3]*ht[i-1]*(at[i-1]/sqrt(ht[i-1])-par[4])^2
>        ht[i]=sig2t
>        mxlk=mxlk+0.5*(log(sig2t) + (at[i])^2/ht[i])
>      }
>      mxlk
>    }
>
>    low=c(1e-6,1e-6,1e-6,1e-6)
>    upp=c(100*var(rtn),1-1e-6,1-1e-6,5)
>    mm=optim(par,mxlk,method="Nelder-Mead",hessian=T)
>    #mm=nlminb(par,mxlk,hessian=T,scale=1,lower=low,upper=upp)
>    #mm=optimx(par,mxlk,method="L-BFGS-B",hessian=T,lower=low,upper=upp)
>    ## Print the results
>    par=mm$par
>    H=mm$hessian
>    Hi = solve(H)
>    cat(" ","\n")
>    cat("Estimation results of NGARCH(1,1) model:","\n")
>    cat("estimates: ",par,"\n")
>    se=sqrt(diag(Hi))
>    cat("std.errors: ",se,"\n")
>    tra=par/se
>    cat("t-ratio: ",tra,"\n")
>    # compute the volatility series and residuals
>
>    ht=var(rtn)
>    T=length(rtn)
>    if(T > 40)ht=var(rtn[1:40])
>    at=rtn-mu
>    for (i in 2:T){
>      sig2t=par[1]+par[2]*ht[i-1]+par[3]*(at[i-1]-par[4]*sqrt(ht[i-1]))^2
>      ht=c(ht,sig2t)
>    }
>    sigma.t=sqrt(ht)
>    Ngarch <- as.matrix(cbind(as.numeric(at),as.numeric(sigma.t)))
>    colnames(Ngarch)=c("residuals","volatility")
>    Ngarch
> }
>
>
>
>
> I think that Alexios has this function in his package (called NAGARCH) but
> I need to code this myself for my master work.
> I already implemented (read ported) his ugarch function in mathematica
> wolfram and it's working great.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com
http://www.portfolioprobe.com/blog
twitter: @burnsstat @portfolioprobe


From john.laing at gmail.com  Thu May  1 03:43:14 2014
From: john.laing at gmail.com (John Laing)
Date: Wed, 30 Apr 2014 21:43:14 -0400
Subject: [R-SIG-Finance] rbbg connection problem
In-Reply-To: <CADv5Py5_O8e6Jt5Gdy+T7i+HkSQ9iWnMB=9AGA4Mb=625VdudQ@mail.gmail.com>
References: <CADv5Py5t4K-WASiDDkiQFYBMcLDh17M2ZP2K6SXq054iOEvL8Q@mail.gmail.com>
	<CAA3Wa=s7rJjzB3G3eSXOOG0jAN9A_Wf2=jEetJjKyum_8f+=fQ@mail.gmail.com>
	<CADv5Py5_O8e6Jt5Gdy+T7i+HkSQ9iWnMB=9AGA4Mb=625VdudQ@mail.gmail.com>
Message-ID: <CAA3Wa=v10W2Z=zUGPWRvzzxvNvWb=TqKdZey=LR0y7kg+yW1kw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140430/36ef4f65/attachment.pl>

From ilya.kipnis at gmail.com  Thu May  1 05:06:20 2014
From: ilya.kipnis at gmail.com (ilya.kipnis at gmail.com)
Date: Wed, 30 Apr 2014 20:06:20 -0700 (PDT)
Subject: [R-SIG-Finance] efficient code for nonlinear garch model
Message-ID: <5361ba2c.115d8c0a.b77f.6d28@mx.google.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140430/bf92527f/attachment.html>

From aidan.corcoran11 at gmail.com  Thu May  1 15:25:44 2014
From: aidan.corcoran11 at gmail.com (Aidan Corcoran)
Date: Thu, 1 May 2014 09:25:44 -0400
Subject: [R-SIG-Finance] rbbg connection problem
In-Reply-To: <CAA3Wa=tmXNmsLu6ZLQ097SV4dLUnJ3+5oDZo4T0q2c6HjVe=PQ@mail.gmail.com>
References: <CADv5Py5t4K-WASiDDkiQFYBMcLDh17M2ZP2K6SXq054iOEvL8Q@mail.gmail.com>
	<CAA3Wa=s7rJjzB3G3eSXOOG0jAN9A_Wf2=jEetJjKyum_8f+=fQ@mail.gmail.com>
	<CADv5Py5_O8e6Jt5Gdy+T7i+HkSQ9iWnMB=9AGA4Mb=625VdudQ@mail.gmail.com>
	<CAA3Wa=v10W2Z=zUGPWRvzzxvNvWb=TqKdZey=LR0y7kg+yW1kw@mail.gmail.com>
	<CADv5Py45kjb1OiP3pWhi9jR902Yi1-uUz9rsDDa85X2Tjbm84w@mail.gmail.com>
	<CAA3Wa=tmXNmsLu6ZLQ097SV4dLUnJ3+5oDZo4T0q2c6HjVe=PQ@mail.gmail.com>
Message-ID: <CADv5Py5yQADHK2QYNJe_xyf+QK-bQ4VYmniyAZV-y0zAzCWeUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140501/253e83d4/attachment.pl>

From sgreiner at factset.com  Thu May  1 15:47:57 2014
From: sgreiner at factset.com (Steve Greiner)
Date: Thu, 1 May 2014 13:47:57 +0000
Subject: [R-SIG-Finance] Mode list to mode numerical.... fast..
Message-ID: <D603B8CA9A18844FB6D4BE02C5C764C31AE930DA@EXCHMBOXA01.pc.factset.com>

Okay, I've had it!!!..   Every time I read in a dataset using something like:
returnmatrix = read.csv("S&P.csv", header=TRUE, sep=",")    

It comes back with "returnmatrix" as mode list.   How can I quickly convert the dataset to mode numerical?   This is pissing me off.  I can do it manually by creating a new matrix and assigning values of the list matrix to the values of the numerical matrix element by element, but it's time consuming.  What can anybody recommend me?
Steve

Steven P. Greiner, Ph.D.
Director of Portfolio Risk
FactSet Research Systems, Inc.
sgreiner at factset.com


From josh.m.ulrich at gmail.com  Thu May  1 16:04:02 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 1 May 2014 09:04:02 -0500
Subject: [R-SIG-Finance] Mode list to mode numerical.... fast..
In-Reply-To: <D603B8CA9A18844FB6D4BE02C5C764C31AE930DA@EXCHMBOXA01.pc.factset.com>
References: <D603B8CA9A18844FB6D4BE02C5C764C31AE930DA@EXCHMBOXA01.pc.factset.com>
Message-ID: <CAPPM_gTZoM8FLUwEVDxAVuQTKdvn-xZye+GgahdP-6U61gVPgA@mail.gmail.com>

On Thu, May 1, 2014 at 8:47 AM, Steve Greiner <sgreiner at factset.com> wrote:
> Okay, I've had it!!!..   Every time I read in a dataset using something like:
> returnmatrix = read.csv("S&P.csv", header=TRUE, sep=",")
>
> It comes back with "returnmatrix" as mode list.   How can I quickly convert the dataset to mode numerical?   This is pissing me off.  I can do it manually by creating a new matrix and assigning values of the list matrix to the values of the numerical matrix element by element, but it's time consuming.  What can anybody recommend me?

?read.csv says it returns a data.frame (which is a list with some
specific attributes).  If you want to convert it to a matrix, just
use:
returnmatrix = as.matrix(read.csv("S&P.csv", header=TRUE, sep=","))

You don't say exactly what data "S&P.csv" contains... but if it's a
large matrix, then you can get some fairly substantial performance
improvement by following the advice in the "Memory usage" section of
?read.csv, which says:

'read.table' is not the right tool for reading large matrices,
especially those with many columns: it is designed to read _data
frames_ which may have columns of very different classes.  Use
'scan' instead for matrices.

So you could try something like:

column_names = scan("S&P.csv", n=1, sep=",", what="")
returnmatrix = matrix(scan("S&P.csv", skip=1, sep=","),
ncol=length(column_names), dimnames=list(NULL, column_names))

You might need to specify byrow=TRUE in the above matrix() call... I
can't remember off the top of my head.

> Steve
>
> Steven P. Greiner, Ph.D.
> Director of Portfolio Risk
> FactSet Research Systems, Inc.
> sgreiner at factset.com
>

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From edd at debian.org  Thu May  1 16:26:49 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 1 May 2014 09:26:49 -0500
Subject: [R-SIG-Finance] Mode list to mode numerical.... fast..
In-Reply-To: <CAPPM_gTZoM8FLUwEVDxAVuQTKdvn-xZye+GgahdP-6U61gVPgA@mail.gmail.com>
References: <D603B8CA9A18844FB6D4BE02C5C764C31AE930DA@EXCHMBOXA01.pc.factset.com>
	<CAPPM_gTZoM8FLUwEVDxAVuQTKdvn-xZye+GgahdP-6U61gVPgA@mail.gmail.com>
Message-ID: <21346.22953.200220.256446@max.nulle.part>


On 1 May 2014 at 09:04, Joshua Ulrich wrote:
| On Thu, May 1, 2014 at 8:47 AM, Steve Greiner <sgreiner at factset.com> wrote:
| > Okay, I've had it!!!..   Every time I read in a dataset using something like:
| > returnmatrix = read.csv("S&P.csv", header=TRUE, sep=",")
| >
| > It comes back with "returnmatrix" as mode list.   How can I quickly convert the dataset to mode numerical?   This is pissing me off.  I can do it manually by creating a new matrix and assigning values of the list matrix to the values of the numerical matrix element by element, but it's time consuming.  What can anybody recommend me?
| 
| ?read.csv says it returns a data.frame (which is a list with some
| specific attributes).  If you want to convert it to a matrix, just
| use:
| returnmatrix = as.matrix(read.csv("S&P.csv", header=TRUE, sep=","))
| 
| You don't say exactly what data "S&P.csv" contains... but if it's a
| large matrix, then you can get some fairly substantial performance
| improvement by following the advice in the "Memory usage" section of
| ?read.csv, which says:
| 
| 'read.table' is not the right tool for reading large matrices,
| especially those with many columns: it is designed to read _data
| frames_ which may have columns of very different classes.  Use
| 'scan' instead for matrices.
| 
| So you could try something like:
| 
| column_names = scan("S&P.csv", n=1, sep=",", what="")
| returnmatrix = matrix(scan("S&P.csv", skip=1, sep=","),
| ncol=length(column_names), dimnames=list(NULL, column_names))
| 
| You might need to specify byrow=TRUE in the above matrix() call... I
| can't remember off the top of my head.

All very good points. But if your file is large (not uncommon in finance)
consider alternatives such as fread in the data.table package, or direct
connections to the underlying server / service, or batch jobs doing the
parsing once and then storing as binary files (R's RDS format is good) etc

To me use of csv files is a last resort used chiefly for one-off
explorations. For "production" one can do much better.

Dirk


-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From baydoganmustafa at gmail.com  Thu May  1 17:24:30 2014
From: baydoganmustafa at gmail.com (Mustafa Baydogan)
Date: Thu, 1 May 2014 18:24:30 +0300
Subject: [R-SIG-Finance] Mode list to mode numerical.... fast..
In-Reply-To: <D603B8CA9A18844FB6D4BE02C5C764C31AE930DA@EXCHMBOXA01.pc.factset.com>
References: <D603B8CA9A18844FB6D4BE02C5C764C31AE930DA@EXCHMBOXA01.pc.factset.com>
Message-ID: <CANfR6+=XoRzwEswr53xnkg_E4bodC9u+Q0gZGra4Yo9-7woBfQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140501/4b0aba92/attachment.pl>

From baydoganmustafa at gmail.com  Thu May  1 17:31:34 2014
From: baydoganmustafa at gmail.com (Mustafa Baydogan)
Date: Thu, 1 May 2014 18:31:34 +0300
Subject: [R-SIG-Finance] Mode list to mode numerical.... fast..
In-Reply-To: <CANfR6+=XoRzwEswr53xnkg_E4bodC9u+Q0gZGra4Yo9-7woBfQ@mail.gmail.com>
References: <D603B8CA9A18844FB6D4BE02C5C764C31AE930DA@EXCHMBOXA01.pc.factset.com>
	<CANfR6+=XoRzwEswr53xnkg_E4bodC9u+Q0gZGra4Yo9-7woBfQ@mail.gmail.com>
Message-ID: <CANfR6+kqx6=OGXNYojHVxEpAhMr0sQTXBUnrRFB2wFyfUDdxNA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140501/6bb4fc18/attachment.pl>

From aschmid1 at stevens.edu  Thu May  1 18:34:38 2014
From: aschmid1 at stevens.edu (aschmid1)
Date: Thu, 01 May 2014 12:34:38 -0400
Subject: [R-SIG-Finance] preserving dates in output of tseries
Message-ID: <fe425fa4244d1d01f1707ec190bc1525@stevens.edu>

I've been stuck for a while with seemingly simple task. I calculate 
returns using data from yahoo:
etf = "SPY"
startDate = "2008-12-01"
endDate = "2014-04-04"
prc <- get.hist.quote(instrument = etf, startDate, endDate, quote = 
"AdjClose", provider = "yahoo" )
tt<-as.zoo(prc)
dates<-index(tt)
r<-diff(log(tt))
tab<-r
> head(tab)
               AdjClose
2008-12-02  0.03776569
2008-12-03  0.02372065
2008-12-04 -0.02345690
2008-12-05  0.03038800
2008-12-08  0.03432357
2008-12-09 -0.01657462

But when I save results to a file, dates are replaced:

write.table(tab, file=filename, quote=F)

Here is the contents of the output file:
AdjClose
1 0.0377656920201943
2 0.0237206482126213
3 -0.0234569003540432
4 0.0303880024180421
5 0.0343235654549394
6 -0.0165746208209656

What can be done about this?
Thanks! Alec


From sf99167 at yahoo.com  Thu May  1 20:52:27 2014
From: sf99167 at yahoo.com (sean fallon)
Date: Thu, 1 May 2014 11:52:27 -0700 (PDT)
Subject: [R-SIG-Finance] preserving dates in output of tseries
In-Reply-To: <fe425fa4244d1d01f1707ec190bc1525@stevens.edu>
References: <fe425fa4244d1d01f1707ec190bc1525@stevens.edu>
Message-ID: <1398970347.26195.YahooMailNeo@web164603.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140501/d76fd0c3/attachment.pl>

From chinmay.patil at gmail.com  Fri May  2 05:29:37 2014
From: chinmay.patil at gmail.com (Chinmay Patil)
Date: Fri, 2 May 2014 11:29:37 +0800
Subject: [R-SIG-Finance] preserving dates in output of tseries
In-Reply-To: <fe425fa4244d1d01f1707ec190bc1525@stevens.edu>
References: <fe425fa4244d1d01f1707ec190bc1525@stevens.edu>
Message-ID: <CA+kDFFXpk3EeWWyXiSuA3cVpfpBjS5Mw-+aEqH_n=bhFEGOroQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140502/c39f9171/attachment.pl>

From jzmoser at gmail.com  Fri May  2 12:42:15 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Fri, 02 May 2014 12:42:15 +0200
Subject: [R-SIG-Finance] moments (and/or density) for "std" in the
 "rugarch"-package or "TF2" in the "gamlss.dist"-package
Message-ID: <53637687.1000400@googlemail.com>

Dear R community,

in order to get a formula for the kurtosis of a mixture distribution 
with noncentral scaled student t components I need to get some raw 
moments of the components (which will then be applied to the law of 
total expectation).

As I am working with the noncentral scaled student t implementations 
"std" in the "rugarch"-package and "TF2" in the "gamlss.dist"-package I 
would be happy to get more details about the particular implementation 
of the distributions.
As to my knowledge the two mentioned implementations are equivalent.
Importantly, the scaling factor equals the standard deviation.

The particular density of the noncentral scaled student t distributions 
as implemented in those packages would be helping.
And if there exist nice formulas for the (noncentral or central) moments 
up to order 4 for this distribution I would be more than thankful for 
any link or comment!

Best,
Johannes


From aschmid1 at stevens.edu  Fri May  2 14:39:18 2014
From: aschmid1 at stevens.edu (aschmid1)
Date: Fri, 02 May 2014 08:39:18 -0400
Subject: [R-SIG-Finance] preserving dates in output of tseries
In-Reply-To: <CA+kDFFXpk3EeWWyXiSuA3cVpfpBjS5Mw-+aEqH_n=bhFEGOroQ@mail.gmail.com>
References: <fe425fa4244d1d01f1707ec190bc1525@stevens.edu>
	<CA+kDFFXpk3EeWWyXiSuA3cVpfpBjS5Mw-+aEqH_n=bhFEGOroQ@mail.gmail.com>
Message-ID: <37689a81e0122a896a3043ca5ac6f3e4@stevens.edu>

Thanks everyone. I found that casting data.frame
write.table(data.frame(tab), file=filename, quote=F)

does the trick.
Alec

On 05/01/2014 11:29 PM, Chinmay Patil wrote:
> Try?
> 
> write.zoo function. works out of the box.?
> 
> write.zoo(head(tab))
> ## "Index" "AdjClose"
> ## 2008-12-02 0.0377656920201943
> ## 2008-12-03 0.0237206482126213
> ## 2008-12-04 -0.0234569003540432
> ## 2008-12-05 0.0303880024180421
> ## 2008-12-08 0.0343235654549394
> ## 2008-12-09 -0.0165746208209656
> 
> On Fri, May 2, 2014 at 12:34 AM, aschmid1 <aschmid1 at stevens.edu>
> wrote:
> 
>> I've been stuck for a while with seemingly simple task. I calculate
>> returns using data from yahoo:
>> etf = "SPY"
>> startDate = "2008-12-01"
>> endDate = "2014-04-04"
>> prc <- get.hist.quote(instrument = etf, startDate, endDate, quote =
>> "AdjClose", provider = "yahoo" )
>> tt<-as.zoo(prc)
>> dates<-index(tt)
>> r<-diff(log(tt))
>> tab<-r
>> 
>>> head(tab)
>> ? ? ? ? ? ? ? AdjClose
>> 2008-12-02 ?0.03776569
>> 2008-12-03 ?0.02372065
>> 2008-12-04 -0.02345690
>> 2008-12-05 ?0.03038800
>> 2008-12-08 ?0.03432357
>> 2008-12-09 -0.01657462
>> 
>> But when I save results to a file, dates are replaced:
>> 
>> write.table(tab, file=filename, quote=F)
>> 
>> Here is the contents of the output file:
>> AdjClose
>> 1 0.0377656920201943
>> 2 0.0237206482126213
>> 3 -0.0234569003540432
>> 4 0.0303880024180421
>> 5 0.0343235654549394
>> 6 -0.0165746208209656
>> 
>> What can be done about this?
>> Thanks! Alec
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance [1]
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R
>> questions should go.
> 
> 
> 
> Links:
> ------
> [1] https://stat.ethz.ch/mailman/listinfo/r-sig-finance


From jyorio at gmail.com  Sat May  3 23:16:52 2014
From: jyorio at gmail.com (fc_11)
Date: Sat, 3 May 2014 14:16:52 -0700 (PDT)
Subject: [R-SIG-Finance] Writing sell rules with quantstrat
In-Reply-To: <CAEGu7FsjEJ3oARUx=ktMB=6V_b4PVtv56LpekR1=qjSQnwm5=A@mail.gmail.com>
References: <CAEGu7Fs3Y6suXh8ntbUWjPuL3-fC+n-hn7rbFJk=9Hf1mrs3jg@mail.gmail.com>
	<1329304310.12375.15.camel@brian-desktop>
	<CAEGu7FvD9uC=2c7hi5Vp0TXEcoAu2adUofjrFV=YX0pHeG13uw@mail.gmail.com>
	<CAEGu7FuYn=zjf5+NgC42QycM7TLb8t8tWUQBfGnV_vHX9y8MfA@mail.gmail.com>
	<1329324082.8901.51.camel@brian-rcg>
	<CAEGu7FsP7TjhNyL5mEyhT21ao7QOi2333+o2Fptm50J4512w_w@mail.gmail.com>
	<CAEGu7FuHD8DgeA0NYXVqJbBmZ8a2v20Pog3xMcpSvB=xZShhbw@mail.gmail.com>
	<CAEGu7Ft7eZrKU9Tp9R=1h7Yshqp-WLHJMUG-Mp0Vs6JpE17dng@mail.gmail.com>
	<CAEGu7FsjEJ3oARUx=ktMB=6V_b4PVtv56LpekR1=qjSQnwm5=A@mail.gmail.com>
Message-ID: <1399151812447-4689930.post@n4.nabble.com>

i've been trying to implement a similar 'holding period based' exit in a
similar fashion and tried Sergey's code today.  i get the following error
upon running applyStrategy using either sergey's 'seller' function and rule
or mine:

Error in .firstCross(dindex, curIndex, "gt") : 
  REAL() can only be applied to a 'numeric', not a 'integer'



my exit logic:
add.rule(strategy.st, name = 'maxHoldingPeriod',arguments=list(x =
quote(Cl(mktdata)[,1]),timestamp,portfolio.st,maxp=10),type='exit',
enabled=TRUE)



maxHoldingPeriod <- function (x, timestamp, portfolio, symbol,maxp) 
{
  # updatePortf(portfolio, Symbols=symbol) #may or maynot work
  position<-(getPos(portfolio,symbol,timestamp,Columns=c("Pos.Qty")))
  position_init<-index(position)
  pheld<-paste0(position_init, "/", timestamp)
  period<-as.numeric(nrow(x[pheld]))
  result<-as.xts(0,order.by=timestamp)
  colnames(result)<-c('HoldingPeriod')
  if(period>=maxp)
  { 
    if(position[,1]>0) 
    {
      result<-1
      addOrder(portfolio, symbol, timestamp, qty='all', ordertype='market',
side='long', prefer = 'Open',replace = TRUE,
               return = FALSE, ..., TxnFees = 0, label = "MaxBarLong")
    }
    if(position[,1]<0) 
    {
      result<-1
      addOrder(portfolio, symbol, timestamp, qty='all', ordertype='market',
side='short', prefer = 'Open',replace = TRUE,
               return = FALSE, ..., TxnFees = 0, label = "MaxBarShort")
    }
  }
  return(result)
}



--
View this message in context: http://r.789695.n4.nabble.com/Writing-sell-rules-with-quantstrat-tp4389599p4689930.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From josh.m.ulrich at gmail.com  Sun May  4 16:33:58 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 4 May 2014 09:33:58 -0500
Subject: [R-SIG-Finance] Writing sell rules with quantstrat
In-Reply-To: <1399151812447-4689930.post@n4.nabble.com>
References: <CAEGu7Fs3Y6suXh8ntbUWjPuL3-fC+n-hn7rbFJk=9Hf1mrs3jg@mail.gmail.com>
	<1329304310.12375.15.camel@brian-desktop>
	<CAEGu7FvD9uC=2c7hi5Vp0TXEcoAu2adUofjrFV=YX0pHeG13uw@mail.gmail.com>
	<CAEGu7FuYn=zjf5+NgC42QycM7TLb8t8tWUQBfGnV_vHX9y8MfA@mail.gmail.com>
	<1329324082.8901.51.camel@brian-rcg>
	<CAEGu7FsP7TjhNyL5mEyhT21ao7QOi2333+o2Fptm50J4512w_w@mail.gmail.com>
	<CAEGu7FuHD8DgeA0NYXVqJbBmZ8a2v20Pog3xMcpSvB=xZShhbw@mail.gmail.com>
	<CAEGu7Ft7eZrKU9Tp9R=1h7Yshqp-WLHJMUG-Mp0Vs6JpE17dng@mail.gmail.com>
	<CAEGu7FsjEJ3oARUx=ktMB=6V_b4PVtv56LpekR1=qjSQnwm5=A@mail.gmail.com>
	<1399151812447-4689930.post@n4.nabble.com>
Message-ID: <CAPPM_gQe=j32NXi-nDatRHxwLqxmqPbZ_+qouWtXJDEYBHxpng@mail.gmail.com>

On Sat, May 3, 2014 at 4:16 PM, fc_11 <jyorio at gmail.com> wrote:
> i've been trying to implement a similar 'holding period based' exit in a
> similar fashion and tried Sergey's code today.  i get the following error
> upon running applyStrategy using either sergey's 'seller' function and rule
> or mine:
>
> Error in .firstCross(dindex, curIndex, "gt") :
>   REAL() can only be applied to a 'numeric', not a 'integer'
>
Thanks for the report. Patched in r1608 on R-Forge.

>
>
> my exit logic:
> add.rule(strategy.st, name = 'maxHoldingPeriod',arguments=list(x =
> quote(Cl(mktdata)[,1]),timestamp,portfolio.st,maxp=10),type='exit',
> enabled=TRUE)
>
>
>
> maxHoldingPeriod <- function (x, timestamp, portfolio, symbol,maxp)
> {
>   # updatePortf(portfolio, Symbols=symbol) #may or maynot work
>   position<-(getPos(portfolio,symbol,timestamp,Columns=c("Pos.Qty")))
>   position_init<-index(position)
>   pheld<-paste0(position_init, "/", timestamp)
>   period<-as.numeric(nrow(x[pheld]))
>   result<-as.xts(0,order.by=timestamp)
>   colnames(result)<-c('HoldingPeriod')
>   if(period>=maxp)
>   {
>     if(position[,1]>0)
>     {
>       result<-1
>       addOrder(portfolio, symbol, timestamp, qty='all', ordertype='market',
> side='long', prefer = 'Open',replace = TRUE,
>                return = FALSE, ..., TxnFees = 0, label = "MaxBarLong")
>     }
>     if(position[,1]<0)
>     {
>       result<-1
>       addOrder(portfolio, symbol, timestamp, qty='all', ordertype='market',
> side='short', prefer = 'Open',replace = TRUE,
>                return = FALSE, ..., TxnFees = 0, label = "MaxBarShort")
>     }
>   }
>   return(result)
> }
>
>

--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From ilya.kipnis at gmail.com  Sun May  4 17:37:36 2014
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Sun, 4 May 2014 11:37:36 -0400
Subject: [R-SIG-Finance] Writing sell rules with quantstrat
In-Reply-To: <1399151812447-4689930.post@n4.nabble.com>
References: <CAEGu7Fs3Y6suXh8ntbUWjPuL3-fC+n-hn7rbFJk=9Hf1mrs3jg@mail.gmail.com>
	<1329304310.12375.15.camel@brian-desktop>
	<CAEGu7FvD9uC=2c7hi5Vp0TXEcoAu2adUofjrFV=YX0pHeG13uw@mail.gmail.com>
	<CAEGu7FuYn=zjf5+NgC42QycM7TLb8t8tWUQBfGnV_vHX9y8MfA@mail.gmail.com>
	<1329324082.8901.51.camel@brian-rcg>
	<CAEGu7FsP7TjhNyL5mEyhT21ao7QOi2333+o2Fptm50J4512w_w@mail.gmail.com>
	<CAEGu7FuHD8DgeA0NYXVqJbBmZ8a2v20Pog3xMcpSvB=xZShhbw@mail.gmail.com>
	<CAEGu7Ft7eZrKU9Tp9R=1h7Yshqp-WLHJMUG-Mp0Vs6JpE17dng@mail.gmail.com>
	<CAEGu7FsjEJ3oARUx=ktMB=6V_b4PVtv56LpekR1=qjSQnwm5=A@mail.gmail.com>
	<1399151812447-4689930.post@n4.nabble.com>
Message-ID: <CA+oJuEFbt9FcPMzj7N1eDCHZ3Pu5=2tf3B6ru12Po8mkEpR+sA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140504/b69c2fb1/attachment.pl>

From henaff.iae at univ-paris1.fr  Mon May  5 22:30:41 2014
From: henaff.iae at univ-paris1.fr (P. Henaff)
Date: Mon, 05 May 2014 22:30:41 +0200
Subject: [R-SIG-Finance] Paris R/Rmetrics Conference registration deadline -
	15 May 2014
In-Reply-To: <mailman.1.1399284002.18224.r-sig-finance@r-project.org>
References: <mailman.1.1399284002.18224.r-sig-finance@r-project.org>
Message-ID: <5367F4F1.2020902@univ-paris1.fr>

R/Rmetrics in Finance and Insurance
8th R/Rmetrics Workshop and Summer School
First RStudio/Shiny App Contest

Paris, 26-28 June 2014

www.rmetrics.org
https://sites.google.com/site/rmetricsparis2014

The deadline for registering and submitting abstract is fast approaching!

If you plan to attend, please register by May 15th, 2014.
---------------------------------------------------------

Conference Announcement and Call for Papers
===========================================

After 7 successful years in Meielisalp, the R/Rmetrics Workshop and 
Summer School
moves to the Latin Quarter of Paris.

The workshop consists of Summer School-like tutorial sessions and a 
user/developer meeting.
The workshop will focus on computational issues in statistics, empirical 
finance and
insurance.

Invited Lectures (preliminary list)
-----------------------------------

     * Advanced Statistical Methods
       Christian Robert (Universit? Paris-Dauphine)
          Bayesian Inference and Markov Chain Monte Carlo

     * Market Micro-Structure:
       Jean-Philippe Bouchaud (Ecole Polytechnique and CFM)
          Anomalous price impact and critical liquidity in financial 
markets

     * Risk Measurement for Solvency II:
       Fr?d?ric Planchet (ISFA - Universit? Lyon I)
         Economic Scenario Generation: Theory and Practice

The afternoon sessions are dedicated to invited and contributed talks and
presentations reflecting the many uses of R and Rmetrics in
finance and insurance.

Call for Papers
---------------

We invite the submission of abstracts presenting innovations or exciting 
applications
covering the whole spectrum of computational topics in finance, 
insurance and related fields.
To submit an abstract, email your pdf file to 
submissions[at]rmetrics.org. Practitioners
are encouraged to submit papers.
Please keep abstracts to one page. The abstracts will become available 
in an online
abstract booklet. Submit your abstract by May 15th.

First RStudio/Shiny App Contest
-------------------------------

The Rmetrics Open Source Association and RStudio is pleased to announce 
the first RStudio/Shiny App Contest.
The contest will take place during the conference.

Shiny makes it very simple for R users to turn analyses into interactive 
web applications that anyone can use.
We invite the submission of Shiny applications presenting innovations 
covering the whole spectrum of topics in finance, insurance and related 
fields.
To submit your Shiny application, first get in contact with us 
(shiny at rmetrics.org).
We will provide a Shiny Server to demo your app. The applications will 
be presented and discussed in a special session.
The Workshop participants will vote on the best app, which will be 
honored with a certificate and a prize sponsored by the
Rmetrics Association and RStudio.

Further information and on-line registration
--------------------------------------------

Early registration is encouraged.
https://sites.google.com/site/rmetricsparis2014

For the program committee:
Patrick H?naff, Mahendra Mehta, Stefan Theussl, Diethelm Wuertz


Patrick H?naff
Ma?tre de Conf?rences
IAE Paris
Universit? Paris I | Panth?on Sorbonne

+33 (0)1 53 55 27 70
+33 (0)6 01 30 13 57
skype: pahenaff

8th R/Rmetrics conference in Paris | June 26-28, 2014
https://sites.google.com/site/rmetricsparis2014

Reproducible research in quantitative finance
www.zanadu.io


-- 
Ce message a ete verifie par MailScanner
pour des virus ou des polluriels et rien de
suspect n'a ete trouve.


From ivan.popivanov at gmail.com  Tue May  6 17:03:47 2014
From: ivan.popivanov at gmail.com (Ivan Popivanov)
Date: Tue, 6 May 2014 11:03:47 -0400
Subject: [R-SIG-Finance] Is TTR::volatility(..., calc="close") correct?
Message-ID: <CAK7-yAiHBZnW+AyB_s10jYjpnGd4LWMSgfQso7wah269NHR44w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140506/c8cf9eba/attachment.pl>

From pablo.javier.rios at gmail.com  Tue May  6 19:58:37 2014
From: pablo.javier.rios at gmail.com (Pablo Rios)
Date: Tue, 6 May 2014 14:58:37 -0300
Subject: [R-SIG-Finance] Luxor strategy (quantstrat) - Why are successive
 short (and long) trades happening ?
Message-ID: <CAPA9880DQtewHBRi=B-9PzonLuvU-gEHbCXYN7ZY0zMkvTrABw@mail.gmail.com>

Hi R/Finance community, blotter/quantstrat developers,

I'm running the Luxor basic strategy available in the quantstrat package
(file demo\luxor.1.strategy.basic.R) with its demo data (.rda files in
extdata\GBPUSD), and I don't understand why are successive short trades
occurring. This is making the position quantity going above +100,000 (or
below -100,000). Is this the expected behaviour of this strategy ? Isn't it
supposed to alternate between long and short trades of .orderqty = 100000
each (i.e., enter long, leave long, enter short, leave short, ...) ?

I'm attaching an screenshot of the well-known three panels chart from
blotter (output of chart.Posn() function) to quickly visualize this
situation, and a .csv file for the order book, per trade stats, market
data, transactions table and P&L values.

I'm running this example with revision 1608 of the source repository (svn://
svn.r-forge.r-project.org/svnroot/blotter), but I observed exactly the same
behaviour with previous versions of blotter/quantstrat code, though with
different time period of the GBP/USD forex data.

Furthermore, with revision 1608 I started to see the following warning
messages never seen before:

> applyStrategy(strategy.st, portfolio.st)
Warning: stack imbalance in 'lapply', 14 then 15
[1] "2002-10-22 02:00:00 GBPUSD 1e+05 @ 1.5447"
Warning: stack imbalance in 'lapply', 18 then 19
[1] "2002-10-22 17:30:00 GBPUSD -1e+05 @ 1.5435"
[1] "2002-10-22 17:30:00 GBPUSD -1e+05 @ 1.5447"
Warning: stack imbalance in 'lapply', 20 then 21
[1] "2002-10-23 03:00:00 GBPUSD 1e+05 @ 1.5486"
[1] "2002-10-23 03:00:00 GBPUSD 1e+05 @ 1.5492"
Warning: stack imbalance in 'lapply', 22 then 23
[1] "2002-10-23 17:30:00 GBPUSD -1e+05 @ 1.5468"
Warning: stack imbalance in 'lapply', 24 then 26
Warning: stack imbalance in 'lapply', 28 then 31
[1] "2002-10-24 02:00:00 GBPUSD -1e+05 @ 1.5463"
[1] "2002-10-24 03:00:00 GBPUSD -1e+05 @ 1.5459"
Warning: stack imbalance in 'lapply', 34 then 35
[1] "2002-10-24 11:30:00 GBPUSD 2e+05 @ 1.5484"
[1] "2002-10-24 12:00:00 GBPUSD 1e+05 @ 1.5493"
Warning: stack imbalance in 'lapply', 37 then 38
[1] "2002-10-25 04:00:00 GBPUSD -1e+05 @ 1.553"
[1] "2002-10-25 04:00:00 GBPUSD -1e+05 @ 1.553"
Warning: stack imbalance in 'lapply', 39 then 40
[1] "2002-10-25 12:00:00 GBPUSD 1e+05 @ 1.5513"
Warning: stack imbalance in 'lapply', 40 then 42
[1] "2002-10-27 23:30:00 GBPUSD -1e+05 @ 1.5475"
[1] "2002-10-28 09:30:00 GBPUSD 1e+05 @ 1.5533"
Warning: stack imbalance in 'lapply', 46 then 47
[1] "2002-10-28 10:30:00 GBPUSD 1e+05 @ 1.555"
Warning: stack imbalance in 'lapply', 49 then 50
[1] "2002-10-29 00:00:00 GBPUSD -1e+05 @ 1.5583"
Warning: stack imbalance in 'lapply', 51 then 53
Warning: stack imbalance in 'lapply', 54 then 57
[1] "2002-10-29 07:30:00 GBPUSD -1e+05 @ 1.5572"
[1] "2002-10-29 07:30:00 GBPUSD -1e+05 @ 1.5572"
[1] "2002-10-29 09:30:00 GBPUSD 1e+05 @ 1.5594"
Warning: stack imbalance in 'lapply', 60 then 61
[1] "2002-10-30 05:30:00 GBPUSD 1e+05 @ 1.5568"
[1] "2002-10-30 09:30:00 GBPUSD 1e+05 @ 1.5578"
Warning: stack imbalance in 'lapply', 63 then 64
[1] "2002-10-30 11:30:00 GBPUSD -1e+05 @ 1.5568"
Warning: stack imbalance in 'lapply', 65 then 67
[1] "2002-10-30 13:00:00 GBPUSD 1e+05 @ 1.5579"
[1] "2002-10-30 19:00:00 GBPUSD -1e+05 @ 1.5558"

Thank you
Pablo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140506/6b0e2f00/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: defect.in.blotter.png
Type: image/png
Size: 47442 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140506/6b0e2f00/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mktdata.csv
Type: text/csv
Size: 31910 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140506/6b0e2f00/attachment.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: pertradestats.csv
Type: text/csv
Size: 1557 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140506/6b0e2f00/attachment-0001.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: orderbook.csv
Type: text/csv
Size: 3333 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140506/6b0e2f00/attachment-0002.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: posPL.csv
Type: text/csv
Size: 23393 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140506/6b0e2f00/attachment-0003.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: txn.csv
Type: text/csv
Size: 2228 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140506/6b0e2f00/attachment-0004.bin>

From ilya.kipnis at gmail.com  Wed May  7 05:01:10 2014
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Tue, 6 May 2014 23:01:10 -0400
Subject: [R-SIG-Finance] getSymbols not properly accounting for GOOGL's
	stock split.
Message-ID: <CA+oJuEGUOrBPdLnCi67mtZm1-VoHk3Q268YN0RRRqDVZsY_tPQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140506/58f7b680/attachment.pl>

From josh.m.ulrich at gmail.com  Wed May  7 10:47:32 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 7 May 2014 03:47:32 -0500
Subject: [R-SIG-Finance] getSymbols not properly accounting for GOOGL's
 stock split.
In-Reply-To: <CA+oJuEGUOrBPdLnCi67mtZm1-VoHk3Q268YN0RRRqDVZsY_tPQ@mail.gmail.com>
References: <CA+oJuEGUOrBPdLnCi67mtZm1-VoHk3Q268YN0RRRqDVZsY_tPQ@mail.gmail.com>
Message-ID: <CAPPM_gRDttPSVyuexHh=wZPc6kbOZvnEuPR5bx_svPPmnhNqiQ@mail.gmail.com>

On Tue, May 6, 2014 at 10:01 PM, Ilya Kipnis <ilya.kipnis at gmail.com> wrote:
> I'm trying adjust=TRUE on getSymbols("GOOGL", src="yahoo",
> from="1900-01-01", adjust=TRUE), then doing plot(Cl(GOOGL)) and I'm seeing
> that massive spike down when the stock split, instead of it being accounted
> for.
>
> Can someone confirm this for me?
>
Perhaps this is relevant?
http://quant.stackexchange.com/q/11100/56

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From bbands at gmail.com  Wed May  7 23:37:12 2014
From: bbands at gmail.com (BBands)
Date: Wed, 7 May 2014 14:37:12 -0700
Subject: [R-SIG-Finance] clustering
Message-ID: <CAGS5yBWPdO8SEbAUtoJMp6oKq0RjY=vtoeBgcsxAQOuGHBR2xQ@mail.gmail.com>

Hello,

Has anyone had any experience with clustering involving large numbers
of series? For example kmeans() or hclust(). We maintain a database of
5000 stocks, 200 industry groups and 15 market sectors. The groups and
sectors are calced by us and are equal weighted. We require both a
fundamental fit and a solid correlation for inclusion and maintain
non-correlated buckets, one in each sector, for stocks that don't fit
in the group they are 'supposed to' belong to. The idea of doing the
cluster work is to provide a rational check and balance. Are new
groups forming, old groups deteriorating, have we missed existing
groups and so forth? (If kmeans is chosen an estimate of the number of
groups and sectors is needed and it is not clear how best to get to
that estimate.) So: Have you had any relevant experience? Especially
with feeding large numbers and mostly positively correlated price
series to cluster analysis?

Thanks in advance,

     John
-- 
John Bollinger
www.BollingerBands.com


From jyorio at gmail.com  Thu May  8 02:05:05 2014
From: jyorio at gmail.com (fc_11)
Date: Wed, 7 May 2014 17:05:05 -0700 (PDT)
Subject: [R-SIG-Finance] Luxor strategy (quantstrat) - Why are
 successive short (and long) trades happening ?
In-Reply-To: <CAPA9880DQtewHBRi=B-9PzonLuvU-gEHbCXYN7ZY0zMkvTrABw@mail.gmail.com>
References: <CAPA9880DQtewHBRi=B-9PzonLuvU-gEHbCXYN7ZY0zMkvTrABw@mail.gmail.com>
Message-ID: <1399507505595-4690163.post@n4.nabble.com>

i also am getting the "Warning: stack imbalance in 'lapply'," warning since
the 1608 upgrade



--
View this message in context: http://r.789695.n4.nabble.com/Luxor-strategy-quantstrat-Why-are-successive-short-and-long-trades-happening-tp4690069p4690163.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From rpaulseymour at gmail.com  Thu May  8 11:48:58 2014
From: rpaulseymour at gmail.com (rPaulS)
Date: Thu, 8 May 2014 02:48:58 -0700 (PDT)
Subject: [R-SIG-Finance] quantstrat - object 'prefer' not found?
Message-ID: <1399542538728-4690181.post@n4.nabble.com>

hello, 
have been trying to get a handle on quantstrat by editing the demo scripts,
and seem to be stuck. basically, i am trying to use data where there is only
a close value (so, not OHLC or BBO). i did a search on this list, and found
an  older post
<http://r.789695.n4.nabble.com/quantstrat-and-nonstandard-column-names-in-the-price-series-td3297855.html>  
that had a similar situation and error:

> Error in getPrice(mktdata, prefer = prefer) : object 'prefer' not found

there was an example script in that thread that i have been mimicking, and
it seems like my prefer statements were not working. it eventually dawned on
me to try to run the original script, and it also returns the same error.
here is a direct link to the script to test or try -  vladimir.R
<http://r.789695.n4.nabble.com/attachment/3298067/0/vladimir.R>   - i am
guessing whatever is wrong with that script, i am also doing wrong. if
anyone has any insight, please let me know. i've pretty much exhausted all
ideas to try to figure out what it is. thank you. 

FYI i am using R version 3.1.0 (2014-04-10) on x86_64-apple-darwin13.1.0
(64-bit), and have installed the latest related packages - including
quantstrat_0.8.2, blotter_0.8.19 and FinancialInstrument_1.1.9. 



--
View this message in context: http://r.789695.n4.nabble.com/quantstrat-object-prefer-not-found-tp4690181.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From josh.m.ulrich at gmail.com  Thu May  8 13:09:02 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 8 May 2014 06:09:02 -0500
Subject: [R-SIG-Finance] Luxor strategy (quantstrat) - Why are
 successive short (and long) trades happening ?
In-Reply-To: <1399507505595-4690163.post@n4.nabble.com>
References: <CAPA9880DQtewHBRi=B-9PzonLuvU-gEHbCXYN7ZY0zMkvTrABw@mail.gmail.com>
	<1399507505595-4690163.post@n4.nabble.com>
Message-ID: <CAPPM_gREytDoV27xBLpZ-M_3L8Ni=arsGb7gkPo0H-aEGS+U+A@mail.gmail.com>

On Wed, May 7, 2014 at 7:05 PM, fc_11 <jyorio at gmail.com> wrote:
> i also am getting the "Warning: stack imbalance in 'lapply'," warning since
> the 1608 upgrade
>
Fixed in r1609.
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From katherine_gobin at yahoo.com  Thu May  8 13:56:10 2014
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Thu, 8 May 2014 19:56:10 +0800 (SGT)
Subject: [R-SIG-Finance] Implied Volatility
Message-ID: <1399550170.17678.YahooMailNeo@web193305.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140508/b9e0f6b3/attachment.pl>

From neilt at neiltiffin.com  Thu May  8 14:05:53 2014
From: neilt at neiltiffin.com (Neil Tiffin)
Date: Thu, 8 May 2014 07:05:53 -0500
Subject: [R-SIG-Finance] clustering
In-Reply-To: <CAGS5yBWPdO8SEbAUtoJMp6oKq0RjY=vtoeBgcsxAQOuGHBR2xQ@mail.gmail.com>
References: <CAGS5yBWPdO8SEbAUtoJMp6oKq0RjY=vtoeBgcsxAQOuGHBR2xQ@mail.gmail.com>
Message-ID: <3CCF725F-75DC-4A36-A012-E2179BB6A709@neiltiffin.com>


On May 7, 2014, at 4:37 PM, BBands <bbands at gmail.com> wrote:

> Hello,
> 
> Has anyone had any experience with clustering involving large numbers
> of series? For example kmeans() or hclust(). We maintain a database of
> 5000 stocks, 200 industry groups and 15 market sectors. The groups and
> sectors are calced by us and are equal weighted. We require both a
> fundamental fit and a solid correlation for inclusion and maintain
> non-correlated buckets, one in each sector, for stocks that don't fit
> in the group they are 'supposed to' belong to. The idea of doing the
> cluster work is to provide a rational check and balance. Are new
> groups forming, old groups deteriorating, have we missed existing
> groups and so forth? (If kmeans is chosen an estimate of the number of
> groups and sectors is needed and it is not clear how best to get to
> that estimate.) So: Have you had any relevant experience? Especially
> with feeding large numbers and mostly positively correlated price
> series to cluster analysis?
> 

I am also interested in this exact question.

Neil


From oleg.mubarakshin at gmail.com  Thu May  8 19:35:39 2014
From: oleg.mubarakshin at gmail.com (Oleg Mubarakshin)
Date: Thu, 8 May 2014 21:35:39 +0400
Subject: [R-SIG-Finance] Implied Volatility
In-Reply-To: <1399550170.17678.YahooMailNeo@web193305.mail.sg3.yahoo.com>
References: <1399550170.17678.YahooMailNeo@web193305.mail.sg3.yahoo.com>
Message-ID: <EBB0CF547BC2416182B74C09283D01EE@OLEHP>

Dear Katherine,

I'm an option trader not a risk manager and it is my own opinion only:
you need simulate both: dynamics of underlying and volatility. I would use 
physical volatility to pricing an option, and apply the GARCH models to do 
it. But only for simplifying.

If you want to do it "difficult and correct" you need to model mutual 
dynamics: underlying, ATM volatility, and skew of volatility - it is "a 
little bit" more difficult task. Ask Google about "value at risk for 
derivatives"


Best regards,
Oleg Mubarakshin


-----???????? ?????????----- 
From: Katherine Gobin
Sent: Thursday, May 08, 2014 3:56 PM
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] Implied Volatility

Dear Forum,

I am not sure if I can raise this query here. I am trying to use Monte Carlo 
simulation for Call option VaR and for this I have simulated 1000 values 
each of the risk factors. I am using the Black Scholes for finding the 
premium. One of the input required to use Black Scholes is volatility 
besides Strike price, spot price, time to maturity and risk free rate.

My question is am I supposed to use Implied volatility or historical 
volatility? I tried to find out the answer through some sources but yet to 
get some concrete answer. I am using RQuantLib for calculating the Implied 
Volatility and its an European option.

If possible kindly guide.


Regards

Katherine Gobin
[[alternative HTML version deleted]]







_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions 
should go.


From pablo.javier.rios at gmail.com  Fri May  9 06:09:35 2014
From: pablo.javier.rios at gmail.com (Pablo Rios)
Date: Fri, 9 May 2014 01:09:35 -0300
Subject: [R-SIG-Finance] Luxor strategy (quantstrat) - Why are
 successive short (and long) trades happening ?
In-Reply-To: <CAPPM_gREytDoV27xBLpZ-M_3L8Ni=arsGb7gkPo0H-aEGS+U+A@mail.gmail.com>
References: <CAPA9880DQtewHBRi=B-9PzonLuvU-gEHbCXYN7ZY0zMkvTrABw@mail.gmail.com>
	<1399507505595-4690163.post@n4.nabble.com>
	<CAPPM_gREytDoV27xBLpZ-M_3L8Ni=arsGb7gkPo0H-aEGS+U+A@mail.gmail.com>
Message-ID: <CAPA9881vntWtiyjr9NrymAu==+PxD7HVfdQ2cxWp7j9M_crOOg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140509/59f8c96c/attachment.pl>

From pablo.javier.rios at gmail.com  Fri May  9 06:32:46 2014
From: pablo.javier.rios at gmail.com (Pablo Rios)
Date: Fri, 9 May 2014 01:32:46 -0300
Subject: [R-SIG-Finance] Luxor strategy (quantstrat) - Why are
 successive short (and long) trades happening ?
In-Reply-To: <CAPA9881vntWtiyjr9NrymAu==+PxD7HVfdQ2cxWp7j9M_crOOg@mail.gmail.com>
References: <CAPA9880DQtewHBRi=B-9PzonLuvU-gEHbCXYN7ZY0zMkvTrABw@mail.gmail.com>
	<1399507505595-4690163.post@n4.nabble.com>
	<CAPPM_gREytDoV27xBLpZ-M_3L8Ni=arsGb7gkPo0H-aEGS+U+A@mail.gmail.com>
	<CAPA9881vntWtiyjr9NrymAu==+PxD7HVfdQ2cxWp7j9M_crOOg@mail.gmail.com>
Message-ID: <CAPA98824xmQBNZ6t6x0SDsQgO5159utVNboDoAaZgzMWHzMXkw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140509/b744ea1c/attachment.pl>

From chinmay.patil at gmail.com  Fri May  9 07:05:44 2014
From: chinmay.patil at gmail.com (Chinmay Patil)
Date: Fri, 9 May 2014 13:05:44 +0800
Subject: [R-SIG-Finance] Luxor strategy (quantstrat) - Why are
 successive short (and long) trades happening ?
In-Reply-To: <CAPA98824xmQBNZ6t6x0SDsQgO5159utVNboDoAaZgzMWHzMXkw@mail.gmail.com>
References: <CAPA9880DQtewHBRi=B-9PzonLuvU-gEHbCXYN7ZY0zMkvTrABw@mail.gmail.com>
	<1399507505595-4690163.post@n4.nabble.com>
	<CAPPM_gREytDoV27xBLpZ-M_3L8Ni=arsGb7gkPo0H-aEGS+U+A@mail.gmail.com>
	<CAPA9881vntWtiyjr9NrymAu==+PxD7HVfdQ2cxWp7j9M_crOOg@mail.gmail.com>
	<CAPA98824xmQBNZ6t6x0SDsQgO5159utVNboDoAaZgzMWHzMXkw@mail.gmail.com>
Message-ID: <CA+kDFFXL6HmxhinymK82ka2GjHfHarqLVAa=0g4GQijJ_DS1Qw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140509/80f03f38/attachment.pl>

From josh.m.ulrich at gmail.com  Fri May  9 13:26:49 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 9 May 2014 06:26:49 -0500
Subject: [R-SIG-Finance] Luxor strategy (quantstrat) - Why are
 successive short (and long) trades happening ?
In-Reply-To: <CAPA9881vntWtiyjr9NrymAu==+PxD7HVfdQ2cxWp7j9M_crOOg@mail.gmail.com>
References: <CAPA9880DQtewHBRi=B-9PzonLuvU-gEHbCXYN7ZY0zMkvTrABw@mail.gmail.com>
	<1399507505595-4690163.post@n4.nabble.com>
	<CAPPM_gREytDoV27xBLpZ-M_3L8Ni=arsGb7gkPo0H-aEGS+U+A@mail.gmail.com>
	<CAPA9881vntWtiyjr9NrymAu==+PxD7HVfdQ2cxWp7j9M_crOOg@mail.gmail.com>
Message-ID: <CAPPM_gSa1=ZZa66ceVz7vjcqVvUEuJemQSUbUwY1B-0KridEUg@mail.gmail.com>

On Thu, May 8, 2014 at 11:09 PM, Pablo Rios <pablo.javier.rios at gmail.com> wrote:
> Thanks for your quick response Joshua.
>
> Does the code changes in r1609 intend to fix the successive short (or long)
> trades that I'm describing in my email, or only the Warning: stack imbalance
> in 'lapply' message ? Although this warning message is no longer reported,
> and the results of the Luxor strategy changed after r1609 (ex.:
> Net.Trading.PL value changed, among other variables), I'm still observing
> the same behaviour of successive short (or long) trades running the Luxor
> demo code with the GBP/USD demo data available in quantstrat.
>
r1609 only intended to fix the stack imbalance warning (as it says in
the commit log).

> Moreover, if I run luxor.1.strategy.basic.R demo code with a longer GBP/USD
> time series, using 30 minutes bars as in the demo data (ex.: three years), I
> observed up to 5 successive short trades (i.e., Pos.Qty value of
> GBPUSD$posPL xts object equal to -500,000) and 4 successive long trades.
>
> Further, looking at the firstCross.c in r1609 I'm seeing in the
> switch(int_rel) statement that all comparisons are done by greater than
> ('>'). I don't know whether this is correct or not.
>
That was a careless error on my part.  r1610 corrects the comparisons.
 Thank you very much for catching this.

> Thanks for your support, I'm eager to finally adopt quantstrat !
>
> Pablo
>
>
> On Thu, May 8, 2014 at 8:09 AM, Joshua Ulrich <josh.m.ulrich at gmail.com>
> wrote:
>>
>> On Wed, May 7, 2014 at 7:05 PM, fc_11 <jyorio at gmail.com> wrote:
>> > i also am getting the "Warning: stack imbalance in 'lapply'," warning
>> > since
>> > the 1608 upgrade
>> >
>> Fixed in r1609.
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>


From jzmoser at gmail.com  Fri May  9 13:58:34 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Fri, 09 May 2014 13:58:34 +0200
Subject: [R-SIG-Finance] timout using "evalWithTimeout" in looped rugarch
	estimation
Message-ID: <536CC2EA.5020105@googlemail.com>

Dear all,

I`ve set up a double loop which loops through different GARCH-orders and 
ARMA-orders in a rugarch estimation (of several models and error 
distributions) and each time writes the AIC and other information into a 
data frame.
The resulting data frame should be used for the pre-selection of a 
model, which then will be examined manually.

A small part of the model estimation steps using "ugarchfit" take very 
long time. So I implemented a timeout function using "evalWithTimeout" 
which stops the current estimation step and proceeds with the next step 
in the loop and estimates the next model.

The timeout function is wrapped into a "tryCatch" function which assures 
thet the loop keeps running after e.g. convergence problems.

A small toy model works fine:


#######################################################################
require('R.utils')
abc <- matrix(NA,10,3)

foo <- function() {
      print("Tic");
      for (kk in 1:50) {
           print(kk);
           Sys.sleep(0.1);
      }
      print("Tac");
}


for (i in 1:10){
      ptm <- proc.time()
tryCatch( { abc[i,1] <- evalWithTimeout({foo()} ,timeout=(4+i*0.2) 
,onTimeout="silent" )
             abc[i,2] <- 1
}
, error = function(x) x)
tt<- proc.time() - ptm
abc[i,3]<-tt[3]
}

abc
#####################################################################


However, in the rugarch setup the "evalWithTimeout" doesn't seem to stop 
the "ugarchfit" estimation reliably. E.g. in one instance the recorded 
time for a step was 1388.03 seconds even though the limit was set to be 
300 seconds. The next example illustrates my setup in a simplified 
version (unfortunately my results depend on the data I have used, so you 
will not be able to reproduce them):


#####################################################################
require('rugarch')
quiet1 <- read.table( "dax_quiet1.txt" , header=T)
tempdata <- quiet1$logreturns

g_order <- matrix(NA,5,2)
g_order[1,]<-c(1,1)
g_order[2,]<-c(1,8)
g_order[3,]<-c(9,6)
g_order[4,]<-c(9,8)
g_order[5,]<-c(3,10)

overview <- data.frame(matrix(NA,5,2))

for(i in 1:5){
      ptm <- proc.time()

      spec <- ugarchspec(
           variance.model = list(model = "fGARCH", garchOrder = 
g_order[i,], submodel = "TGARCH", external.regressors = NULL, 
variance.targeting = FALSE),
           mean.model = list(armaOrder = c(0,0), external.regressors = 
NULL), distribution.model = "sged")

      tryCatch( {tempgarch <- evalWithTimeout({ugarchfit(spec=spec, 
data=tempdata ,solver="hybrid")} ,timeout=20 ,onTimeout="silent" )
                 overview[i,1]<-infocriteria(tempgarch)[1]
      }
      , error = function(x) x)

      tt<- proc.time() - ptm
      overview[i,2]<-tt[3]
}

overview

# If the timeout is set set to 20, this setup leads to:
# 2.87 sec.
# 6.95 sec.
# 125 sec.     ... here, tryCatch interrupted the process
# 51.73 sec.
# 27.11 sec.
# for the 5 different estimation steps.

# timeout set to 300:
# 2.81 sec.
# 6.85 sec.
# 743.58 sec.
# 41.70 sec.
# 26.85 sec.
# no process was interrupted by tryCatch
#######################################################################


As can be seen even from this simplified example, when the timeout was 
set to be 20 there still was a process that took 125 seconds (which is 
more than 5 times longer!).
I would be very thankful for any ideas or comments!

Best, Johannes


From adamno227 at gmail.com  Fri May  9 20:01:08 2014
From: adamno227 at gmail.com (Adam Ginensky)
Date: Fri, 9 May 2014 13:01:08 -0500
Subject: [R-SIG-Finance] Volume data
Message-ID: <CAEEj48=g3E5PGBxnGRyd8adU-fopRSEJ01jf6HwrsF+4D8PXuQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140509/88a1ef1a/attachment.pl>

From max.nissman at gmail.com  Fri May  9 20:46:44 2014
From: max.nissman at gmail.com (max nissman)
Date: Fri, 9 May 2014 14:46:44 -0400
Subject: [R-SIG-Finance] Volume data
In-Reply-To: <CAEEj48=g3E5PGBxnGRyd8adU-fopRSEJ01jf6HwrsF+4D8PXuQ@mail.gmail.com>
References: <CAEEj48=g3E5PGBxnGRyd8adU-fopRSEJ01jf6HwrsF+4D8PXuQ@mail.gmail.com>
Message-ID: <CA+PXKNBaiC1up9+tY4LBwJh-S4B8CGqH83UXVfRtfx9Bj8xXBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140509/5aa98cb7/attachment.pl>

From stefano.iacus at unimi.it  Sat May 10 06:11:45 2014
From: stefano.iacus at unimi.it (stefano iacus)
Date: Sat, 10 May 2014 13:11:45 +0900
Subject: [R-SIG-Finance] Scaling and Clustering of Financial Data
In-Reply-To: <CAEEj48mfTu2d7MU0LiNzQo99XkNLgoQd9hA2-dnkyHy0o_16kg@mail.gmail.com>
References: <CAEEj48kpiWhKyusHWEhDQCPShF80hup2__jzvSQBK47YTnt7OA@mail.gmail.com>
	<6C1BD35E98B9463496EDC83F07F742A9@gmail.com>
	<CAEEj48mfTu2d7MU0LiNzQo99XkNLgoQd9hA2-dnkyHy0o_16kg@mail.gmail.com>
Message-ID: <A8D866B1-0081-4C69-BDBB-EDF771841BEE@unimi.it>

Hi Alan,
if the interest is in the time series per se, maybe you can have a look at MOdist function in the sde package and related paper. MOdist does not need any normalization as it clusters on the whole Markov property of the process.
dtw is another option, but there you may want to standardize.
As usual it depends on the purpose of your study.

Stefano

Il giorno 25/apr/2014, alle ore 06:21, Adam Ginensky <adamno227 at gmail.com> ha scritto:

> All,
> 
> Thank you for your comments.  It definitely reinforced my feeling that
> scaling is absolutely necessary and gave me some pointers on where to look
> for further thoughts.
> 
> Adam
> 
> 
> On Wed, Apr 23, 2014 at 2:40 PM, Dominykas Grigonis <
> dominykasgrigonis at gmail.com> wrote:
> 
>> Standard standardising would be subtract mean and divide by standard
>> deviation. i.e. it would be clustering by mahalanobis distance.
>> 
>> 
>> Kind regards,
>> --
>> Dominykas Grigonis
>> 
>> On Wednesday, 23 April 2014 at 15:53, Adam Ginensky wrote:
>> 
>> I'm looking at clustering of stocks based on their fundamental financial
>> data. I have about 80 variables per stock. I have the standard k-means
>> package. Firstly, I am wondering if there are any other R packages that
>> may be more useful for clustering of financial data.
>> My second, and more important (to me), question is- Should one scale the
>> data before clustering. I'm particularly worried that since certain
>> variables can be orders of magnitude larger than other equally interesting
>> variables (-think market cap and p/e). I realize this is not an R question
>> per se, but I feel I am more likely to get a good answer out of this forum
>> than any other because of the concentration of financial practitioners. Of
>> course, I apologize in advance, if it is too 'off-topic' and then simply
>> ask for a better place to post. Thanks.
>> 
>> Adam Ginensky
>> 
>> [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


****************
Il 5 x mille alla nostra Universit? ? un investimento sui giovani,
sui loro migliori progetti.

Sostiene la libera ricerca.
Alimenta le loro speranze nel futuro.

Investi il tuo 5 x mille sui giovani.

Universit? degli Studi di Milano
codice fiscale 80012650158

http://www.unimi.it/13084.htm?utm_source=firmaMail&utm_medium=email&utm_content=linkFirmaEmail&utm_campaign=5xmille


From stefano.iacus at unimi.it  Sat May 10 06:21:20 2014
From: stefano.iacus at unimi.it (stefano iacus)
Date: Sat, 10 May 2014 13:21:20 +0900
Subject: [R-SIG-Finance] [Announce] YUIMA package on CRAN
Message-ID: <58CF6224-EA45-4294-9D6B-7D2C7A2A738F@unimi.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140510/26714a10/attachment.pl>

From jzmoser at gmail.com  Sat May 10 09:23:28 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Sat, 10 May 2014 09:23:28 +0200
Subject: [R-SIG-Finance] timout using "evalWithTimeout" in looped
	rugarch estimation
In-Reply-To: <536CC2EA.5020105@googlemail.com>
References: <536CC2EA.5020105@googlemail.com>
Message-ID: <536DD3F0.3000405@googlemail.com>

I guess that the problem is due to the processing in C as part of the 
ugarchfit routine.

Is there any way to timeout a ugarchfit command or to constrain the 
number if iterations?

At one time the loop seems to be stuck completely.
I waited for several hours for a single ugarchfit step which just didn`t 
complete. Then I manually stopped the process.

Separate calculation of the respective model also seems to be "stuck" 
(CPU is still working, the "hybrid" algorithms seem to find no solution 
though and just keep running).

As I want to set up a GARCH model-preselection battery there hopefully 
is a way to handle such problems?

Best, Johannes





Am 09.05.2014 13:58, schrieb Johannes Moser:
> Dear all,
>
> I`ve set up a double loop which loops through different GARCH-orders 
> and ARMA-orders in a rugarch estimation (of several models and error 
> distributions) and each time writes the AIC and other information into 
> a data frame.
> The resulting data frame should be used for the pre-selection of a 
> model, which then will be examined manually.
>
> A small part of the model estimation steps using "ugarchfit" take very 
> long time. So I implemented a timeout function using "evalWithTimeout" 
> which stops the current estimation step and proceeds with the next 
> step in the loop and estimates the next model.
>
> The timeout function is wrapped into a "tryCatch" function which 
> assures thet the loop keeps running after e.g. convergence problems.
>
> A small toy model works fine:
>
>
> #######################################################################
> require('R.utils')
> abc <- matrix(NA,10,3)
>
> foo <- function() {
>      print("Tic");
>      for (kk in 1:50) {
>           print(kk);
>           Sys.sleep(0.1);
>      }
>      print("Tac");
> }
>
>
> for (i in 1:10){
>      ptm <- proc.time()
> tryCatch( { abc[i,1] <- evalWithTimeout({foo()} ,timeout=(4+i*0.2) 
> ,onTimeout="silent" )
>             abc[i,2] <- 1
> }
> , error = function(x) x)
> tt<- proc.time() - ptm
> abc[i,3]<-tt[3]
> }
>
> abc
> #####################################################################
>
>
> However, in the rugarch setup the "evalWithTimeout" doesn't seem to 
> stop the "ugarchfit" estimation reliably. E.g. in one instance the 
> recorded time for a step was 1388.03 seconds even though the limit was 
> set to be 300 seconds. The next example illustrates my setup in a 
> simplified version (unfortunately my results depend on the data I have 
> used, so you will not be able to reproduce them):
>
>
> #####################################################################
> require('rugarch')
> quiet1 <- read.table( "dax_quiet1.txt" , header=T)
> tempdata <- quiet1$logreturns
>
> g_order <- matrix(NA,5,2)
> g_order[1,]<-c(1,1)
> g_order[2,]<-c(1,8)
> g_order[3,]<-c(9,6)
> g_order[4,]<-c(9,8)
> g_order[5,]<-c(3,10)
>
> overview <- data.frame(matrix(NA,5,2))
>
> for(i in 1:5){
>      ptm <- proc.time()
>
>      spec <- ugarchspec(
>           variance.model = list(model = "fGARCH", garchOrder = 
> g_order[i,], submodel = "TGARCH", external.regressors = NULL, 
> variance.targeting = FALSE),
>           mean.model = list(armaOrder = c(0,0), external.regressors = 
> NULL), distribution.model = "sged")
>
>      tryCatch( {tempgarch <- evalWithTimeout({ugarchfit(spec=spec, 
> data=tempdata ,solver="hybrid")} ,timeout=20 ,onTimeout="silent" )
>                 overview[i,1]<-infocriteria(tempgarch)[1]
>      }
>      , error = function(x) x)
>
>      tt<- proc.time() - ptm
>      overview[i,2]<-tt[3]
> }
>
> overview
>
> # If the timeout is set set to 20, this setup leads to:
> # 2.87 sec.
> # 6.95 sec.
> # 125 sec.     ... here, tryCatch interrupted the process
> # 51.73 sec.
> # 27.11 sec.
> # for the 5 different estimation steps.
>
> # timeout set to 300:
> # 2.81 sec.
> # 6.85 sec.
> # 743.58 sec.
> # 41.70 sec.
> # 26.85 sec.
> # no process was interrupted by tryCatch
> #######################################################################
>
>
> As can be seen even from this simplified example, when the timeout was 
> set to be 20 there still was a process that took 125 seconds (which is 
> more than 5 times longer!).
> I would be very thankful for any ideas or comments!
>
> Best, Johannes
>
>
>
>
>
>
>
>
>
>
>

--


From alexios at 4dscape.com  Sat May 10 11:34:38 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sat, 10 May 2014 10:34:38 +0100
Subject: [R-SIG-Finance] timout using "evalWithTimeout" in looped
 rugarch estimation
In-Reply-To: <536DD3F0.3000405@googlemail.com>
References: <536CC2EA.5020105@googlemail.com> <536DD3F0.3000405@googlemail.com>
Message-ID: <536DF2AE.50900@4dscape.com>

Johannes,

I suggest the following:

1. Don't use hybrid, use instead solnp or nlminb.

2. You can control a number of solver convergence criteria (e.g. number
of iterations) using the solver.control argument.

3. Before running the code, do consider a little more how reasonable it
is to be modelling a TGARCH(7,8) model. Investigate the model first
(don't just return the AIC or BIC). Are any of the higher order
ARCH/GARCH parameters different from zero or even significant? I have
not seen a single study which shows that such very high order GARCH
models have better performance than more parsimonious alternatives.

4. At the best of times it takes a considerable amount of data to
estimate the GARCH persistence. Try running a simulation exercise using
for example the ugarchdistribution function to obtain some insight into
higher order GARCH models.

5. Finally, as mentioned numerous times on this forum, the fGARCH model
is a highly parameterized omnibus model. Imposing stationarity during
the optimization, particularly for non-symmetric distributions such as
the ged, is a costly exercise.  Consider using the GJR instead and a
distribution which is a little faster to evaluate such as the JSU.
Alternatively consider using the normal distribution to estimate the
GARCH parameters for the purpose of model comparison.

-Alexios

On 10/05/2014 08:23, Johannes Moser wrote:
> I guess that the problem is due to the processing in C as part of the
> ugarchfit routine.
> 
> Is there any way to timeout a ugarchfit command or to constrain the
> number if iterations?
> 
> At one time the loop seems to be stuck completely.
> I waited for several hours for a single ugarchfit step which just didn`t
> complete. Then I manually stopped the process.
> 
> Separate calculation of the respective model also seems to be "stuck"
> (CPU is still working, the "hybrid" algorithms seem to find no solution
> though and just keep running).
> 
> As I want to set up a GARCH model-preselection battery there hopefully
> is a way to handle such problems?
> 
> Best, Johannes
> 
> 
> 
> 
> 
> Am 09.05.2014 13:58, schrieb Johannes Moser:
>> Dear all,
>>
>> I`ve set up a double loop which loops through different GARCH-orders
>> and ARMA-orders in a rugarch estimation (of several models and error
>> distributions) and each time writes the AIC and other information into
>> a data frame.
>> The resulting data frame should be used for the pre-selection of a
>> model, which then will be examined manually.
>>
>> A small part of the model estimation steps using "ugarchfit" take very
>> long time. So I implemented a timeout function using "evalWithTimeout"
>> which stops the current estimation step and proceeds with the next
>> step in the loop and estimates the next model.
>>
>> The timeout function is wrapped into a "tryCatch" function which
>> assures thet the loop keeps running after e.g. convergence problems.
>>
>> A small toy model works fine:
>>
>>
>> #######################################################################
>> require('R.utils')
>> abc <- matrix(NA,10,3)
>>
>> foo <- function() {
>>      print("Tic");
>>      for (kk in 1:50) {
>>           print(kk);
>>           Sys.sleep(0.1);
>>      }
>>      print("Tac");
>> }
>>
>>
>> for (i in 1:10){
>>      ptm <- proc.time()
>> tryCatch( { abc[i,1] <- evalWithTimeout({foo()} ,timeout=(4+i*0.2)
>> ,onTimeout="silent" )
>>             abc[i,2] <- 1
>> }
>> , error = function(x) x)
>> tt<- proc.time() - ptm
>> abc[i,3]<-tt[3]
>> }
>>
>> abc
>> #####################################################################
>>
>>
>> However, in the rugarch setup the "evalWithTimeout" doesn't seem to
>> stop the "ugarchfit" estimation reliably. E.g. in one instance the
>> recorded time for a step was 1388.03 seconds even though the limit was
>> set to be 300 seconds. The next example illustrates my setup in a
>> simplified version (unfortunately my results depend on the data I have
>> used, so you will not be able to reproduce them):
>>
>>
>> #####################################################################
>> require('rugarch')
>> quiet1 <- read.table( "dax_quiet1.txt" , header=T)
>> tempdata <- quiet1$logreturns
>>
>> g_order <- matrix(NA,5,2)
>> g_order[1,]<-c(1,1)
>> g_order[2,]<-c(1,8)
>> g_order[3,]<-c(9,6)
>> g_order[4,]<-c(9,8)
>> g_order[5,]<-c(3,10)
>>
>> overview <- data.frame(matrix(NA,5,2))
>>
>> for(i in 1:5){
>>      ptm <- proc.time()
>>
>>      spec <- ugarchspec(
>>           variance.model = list(model = "fGARCH", garchOrder =
>> g_order[i,], submodel = "TGARCH", external.regressors = NULL,
>> variance.targeting = FALSE),
>>           mean.model = list(armaOrder = c(0,0), external.regressors =
>> NULL), distribution.model = "sged")
>>
>>      tryCatch( {tempgarch <- evalWithTimeout({ugarchfit(spec=spec,
>> data=tempdata ,solver="hybrid")} ,timeout=20 ,onTimeout="silent" )
>>                 overview[i,1]<-infocriteria(tempgarch)[1]
>>      }
>>      , error = function(x) x)
>>
>>      tt<- proc.time() - ptm
>>      overview[i,2]<-tt[3]
>> }
>>
>> overview
>>
>> # If the timeout is set set to 20, this setup leads to:
>> # 2.87 sec.
>> # 6.95 sec.
>> # 125 sec.     ... here, tryCatch interrupted the process
>> # 51.73 sec.
>> # 27.11 sec.
>> # for the 5 different estimation steps.
>>
>> # timeout set to 300:
>> # 2.81 sec.
>> # 6.85 sec.
>> # 743.58 sec.
>> # 41.70 sec.
>> # 26.85 sec.
>> # no process was interrupted by tryCatch
>> #######################################################################
>>
>>
>> As can be seen even from this simplified example, when the timeout was
>> set to be 20 there still was a process that took 125 seconds (which is
>> more than 5 times longer!).
>> I would be very thankful for any ideas or comments!
>>
>> Best, Johannes
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
> 
> -- 
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
> 
>


From jzmoser at gmail.com  Sat May 10 13:19:47 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Sat, 10 May 2014 13:19:47 +0200
Subject: [R-SIG-Finance] timout using "evalWithTimeout" in looped
 rugarch estimation
In-Reply-To: <536DF2AE.50900@4dscape.com>
References: <536CC2EA.5020105@googlemail.com>
	<536DD3F0.3000405@googlemail.com> <536DF2AE.50900@4dscape.com>
Message-ID: <536E0B53.10400@googlemail.com>

Many thanks Alexios!!

1. In my TGARCH setup nlminb doesn`t converge even at smaller GARCH 
order. So I will stick to solnp then.

2. Unfortunately I couldn`t find the correct command which limits the 
number of iterations via the solver.control options.
The details from the manual mention n.sim and n.restarts, but these seem 
to control other parameters.
For the nloptr solver the option maxeval is mentioned. But I don`t work 
with this solver and trial-and-error-implementation of this option to 
sonnp leaded to no success.
Other packages inspired me to try "maxiter" , "iter.max" , "n.iter" , 
but they didn`t work either.

E.g.              ugarchfit( spec=spec, data=tempdata , solver="solnp",  
solver.control=list( maxeval=20, rseed=9876 ) )

3. You`re surely right. The whole study should actually investigate this 
issue empirically.
E.g. in one case there was a surprising result in a sample of size 1200:
An ARMA(0,0) eGARCH(5,5) model with a skewed normal for the innovations 
yielded very good results.
No sign biases, nice gof, no autocorrelation in standardized and squared 
standardized residuals up to order p+q+10, nice AIC and BIC as well as 
only highly significant coefficients (6 out of 18 were not significant 
as to the robust SE, though). I will compare this model to a more 
parsimonious one and also investigate parameter uncertainty.

Best, Johannes



Am 10.05.2014 11:34, schrieb alexios ghalanos:
> Johannes,
>
> I suggest the following:
>
> 1. Don't use hybrid, use instead solnp or nlminb.
>
> 2. You can control a number of solver convergence criteria (e.g. number
> of iterations) using the solver.control argument.
>
> 3. Before running the code, do consider a little more how reasonable it
> is to be modelling a TGARCH(7,8) model. Investigate the model first
> (don't just return the AIC or BIC). Are any of the higher order
> ARCH/GARCH parameters different from zero or even significant? I have
> not seen a single study which shows that such very high order GARCH
> models have better performance than more parsimonious alternatives.
>
> 4. At the best of times it takes a considerable amount of data to
> estimate the GARCH persistence. Try running a simulation exercise using
> for example the ugarchdistribution function to obtain some insight into
> higher order GARCH models.
>
> 5. Finally, as mentioned numerous times on this forum, the fGARCH model
> is a highly parameterized omnibus model. Imposing stationarity during
> the optimization, particularly for non-symmetric distributions such as
> the ged, is a costly exercise.  Consider using the GJR instead and a
> distribution which is a little faster to evaluate such as the JSU.
> Alternatively consider using the normal distribution to estimate the
> GARCH parameters for the purpose of model comparison.
>
> -Alexios
>
> On 10/05/2014 08:23, Johannes Moser wrote:
>> I guess that the problem is due to the processing in C as part of the
>> ugarchfit routine.
>>
>> Is there any way to timeout a ugarchfit command or to constrain the
>> number if iterations?
>>
>> At one time the loop seems to be stuck completely.
>> I waited for several hours for a single ugarchfit step which just didn`t
>> complete. Then I manually stopped the process.
>>
>> Separate calculation of the respective model also seems to be "stuck"
>> (CPU is still working, the "hybrid" algorithms seem to find no solution
>> though and just keep running).
>>
>> As I want to set up a GARCH model-preselection battery there hopefully
>> is a way to handle such problems?
>>
>> Best, Johannes
>>
>>
>>
>>
>>
>> Am 09.05.2014 13:58, schrieb Johannes Moser:
>>> Dear all,
>>>
>>> I`ve set up a double loop which loops through different GARCH-orders
>>> and ARMA-orders in a rugarch estimation (of several models and error
>>> distributions) and each time writes the AIC and other information into
>>> a data frame.
>>> The resulting data frame should be used for the pre-selection of a
>>> model, which then will be examined manually.
>>>
>>> A small part of the model estimation steps using "ugarchfit" take very
>>> long time. So I implemented a timeout function using "evalWithTimeout"
>>> which stops the current estimation step and proceeds with the next
>>> step in the loop and estimates the next model.
>>>
>>> The timeout function is wrapped into a "tryCatch" function which
>>> assures thet the loop keeps running after e.g. convergence problems.
>>>
>>> A small toy model works fine:
>>>
>>>
>>> #######################################################################
>>> require('R.utils')
>>> abc <- matrix(NA,10,3)
>>>
>>> foo <- function() {
>>>       print("Tic");
>>>       for (kk in 1:50) {
>>>            print(kk);
>>>            Sys.sleep(0.1);
>>>       }
>>>       print("Tac");
>>> }
>>>
>>>
>>> for (i in 1:10){
>>>       ptm <- proc.time()
>>> tryCatch( { abc[i,1] <- evalWithTimeout({foo()} ,timeout=(4+i*0.2)
>>> ,onTimeout="silent" )
>>>              abc[i,2] <- 1
>>> }
>>> , error = function(x) x)
>>> tt<- proc.time() - ptm
>>> abc[i,3]<-tt[3]
>>> }
>>>
>>> abc
>>> #####################################################################
>>>
>>>
>>> However, in the rugarch setup the "evalWithTimeout" doesn't seem to
>>> stop the "ugarchfit" estimation reliably. E.g. in one instance the
>>> recorded time for a step was 1388.03 seconds even though the limit was
>>> set to be 300 seconds. The next example illustrates my setup in a
>>> simplified version (unfortunately my results depend on the data I have
>>> used, so you will not be able to reproduce them):
>>>
>>>
>>> #####################################################################
>>> require('rugarch')
>>> quiet1 <- read.table( "dax_quiet1.txt" , header=T)
>>> tempdata <- quiet1$logreturns
>>>
>>> g_order <- matrix(NA,5,2)
>>> g_order[1,]<-c(1,1)
>>> g_order[2,]<-c(1,8)
>>> g_order[3,]<-c(9,6)
>>> g_order[4,]<-c(9,8)
>>> g_order[5,]<-c(3,10)
>>>
>>> overview <- data.frame(matrix(NA,5,2))
>>>
>>> for(i in 1:5){
>>>       ptm <- proc.time()
>>>
>>>       spec <- ugarchspec(
>>>            variance.model = list(model = "fGARCH", garchOrder =
>>> g_order[i,], submodel = "TGARCH", external.regressors = NULL,
>>> variance.targeting = FALSE),
>>>            mean.model = list(armaOrder = c(0,0), external.regressors =
>>> NULL), distribution.model = "sged")
>>>
>>>       tryCatch( {tempgarch <- evalWithTimeout({ugarchfit(spec=spec,
>>> data=tempdata ,solver="hybrid")} ,timeout=20 ,onTimeout="silent" )
>>>                  overview[i,1]<-infocriteria(tempgarch)[1]
>>>       }
>>>       , error = function(x) x)
>>>
>>>       tt<- proc.time() - ptm
>>>       overview[i,2]<-tt[3]
>>> }
>>>
>>> overview
>>>
>>> # If the timeout is set set to 20, this setup leads to:
>>> # 2.87 sec.
>>> # 6.95 sec.
>>> # 125 sec.     ... here, tryCatch interrupted the process
>>> # 51.73 sec.
>>> # 27.11 sec.
>>> # for the 5 different estimation steps.
>>>
>>> # timeout set to 300:
>>> # 2.81 sec.
>>> # 6.85 sec.
>>> # 743.58 sec.
>>> # 41.70 sec.
>>> # 26.85 sec.
>>> # no process was interrupted by tryCatch
>>> #######################################################################
>>>
>>>
>>> As can be seen even from this simplified example, when the timeout was
>>> set to be 20 there still was a process that took 125 seconds (which is
>>> more than 5 times longer!).
>>> I would be very thankful for any ideas or comments!
>>>
>>> Best, Johannes
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>> -- 
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>>

--


From alexios at 4dscape.com  Sat May 10 13:25:52 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sat, 10 May 2014 12:25:52 +0100
Subject: [R-SIG-Finance] timout using "evalWithTimeout" in looped
	rugarch estimation
In-Reply-To: <536E0B53.10400@googlemail.com>
References: <536CC2EA.5020105@googlemail.com>
	<536DD3F0.3000405@googlemail.com> <536DF2AE.50900@4dscape.com>
	<536E0B53.10400@googlemail.com>
Message-ID: <2B20C361-99E7-4B46-9D5A-252C590F5C85@4dscape.com>

Hi Johannes,

On 10 May 2014, at 12:19, Johannes Moser <jzmoser at gmail.com> wrote:

> Many thanks Alexios!!
> 
> 1. In my TGARCH setup nlminb doesn`t converge even at smaller GARCH order. So I will stick to solnp then.
> 
> 2. Unfortunately I couldn`t find the correct command which limits the number of iterations via the solver.control options.
> The details from the manual mention n.sim and n.restarts, but these seem to control other parameters.
> For the nloptr solver the option maxeval is mentioned. But I don`t work with this solver and trial-and-error-implementation of this option to sonnp leaded to no success.
> Other packages inspired me to try "maxiter" , "iter.max" , "n.iter" , but they didn`t work either.
> 
> E.g.              ugarchfit( spec=spec, data=tempdata , solver="solnp",  solver.control=list( maxeval=20, rseed=9876 ) )

See the documentation for solnp (?solnp). The ?inner.iter? and ?outer.iter? are what you are likely looking for. The n.sim and n.restarts if for the gosolnp solver (multi-start solnp).
> 
> 3. You`re surely right. The whole study should actually investigate this issue empirically.
> E.g. in one case there was a surprising result in a sample of size 1200:
> An ARMA(0,0) eGARCH(5,5) model with a skewed normal for the innovations yielded very good results.
> No sign biases, nice gof, no autocorrelation in standardized and squared standardized residuals up to order p+q+10, nice AIC and BIC as well as only highly significant coefficients (6 out of 18 were not significant as to the robust SE, though). I will compare this model to a more parsimonious one and also investigate parameter uncertainty.

Yes, in-sample of course?.but I was referring to forecast performance (out of sample).
> 
> Best, Johannes
> 
Regards,
Alexios
> 
> 
> Am 10.05.2014 11:34, schrieb alexios ghalanos:
>> Johannes,
>> 
>> I suggest the following:
>> 
>> 1. Don't use hybrid, use instead solnp or nlminb.
>> 
>> 2. You can control a number of solver convergence criteria (e.g. number
>> of iterations) using the solver.control argument.
>> 
>> 3. Before running the code, do consider a little more how reasonable it
>> is to be modelling a TGARCH(7,8) model. Investigate the model first
>> (don't just return the AIC or BIC). Are any of the higher order
>> ARCH/GARCH parameters different from zero or even significant? I have
>> not seen a single study which shows that such very high order GARCH
>> models have better performance than more parsimonious alternatives.
>> 
>> 4. At the best of times it takes a considerable amount of data to
>> estimate the GARCH persistence. Try running a simulation exercise using
>> for example the ugarchdistribution function to obtain some insight into
>> higher order GARCH models.
>> 
>> 5. Finally, as mentioned numerous times on this forum, the fGARCH model
>> is a highly parameterized omnibus model. Imposing stationarity during
>> the optimization, particularly for non-symmetric distributions such as
>> the ged, is a costly exercise.  Consider using the GJR instead and a
>> distribution which is a little faster to evaluate such as the JSU.
>> Alternatively consider using the normal distribution to estimate the
>> GARCH parameters for the purpose of model comparison.
>> 
>> -Alexios
>> 
>> On 10/05/2014 08:23, Johannes Moser wrote:
>>> I guess that the problem is due to the processing in C as part of the
>>> ugarchfit routine.
>>> 
>>> Is there any way to timeout a ugarchfit command or to constrain the
>>> number if iterations?
>>> 
>>> At one time the loop seems to be stuck completely.
>>> I waited for several hours for a single ugarchfit step which just didn`t
>>> complete. Then I manually stopped the process.
>>> 
>>> Separate calculation of the respective model also seems to be "stuck"
>>> (CPU is still working, the "hybrid" algorithms seem to find no solution
>>> though and just keep running).
>>> 
>>> As I want to set up a GARCH model-preselection battery there hopefully
>>> is a way to handle such problems?
>>> 
>>> Best, Johannes
>>> 
>>> 
>>> 
>>> 
>>> 
>>> Am 09.05.2014 13:58, schrieb Johannes Moser:
>>>> Dear all,
>>>> 
>>>> I`ve set up a double loop which loops through different GARCH-orders
>>>> and ARMA-orders in a rugarch estimation (of several models and error
>>>> distributions) and each time writes the AIC and other information into
>>>> a data frame.
>>>> The resulting data frame should be used for the pre-selection of a
>>>> model, which then will be examined manually.
>>>> 
>>>> A small part of the model estimation steps using "ugarchfit" take very
>>>> long time. So I implemented a timeout function using "evalWithTimeout"
>>>> which stops the current estimation step and proceeds with the next
>>>> step in the loop and estimates the next model.
>>>> 
>>>> The timeout function is wrapped into a "tryCatch" function which
>>>> assures thet the loop keeps running after e.g. convergence problems.
>>>> 
>>>> A small toy model works fine:
>>>> 
>>>> 
>>>> #######################################################################
>>>> require('R.utils')
>>>> abc <- matrix(NA,10,3)
>>>> 
>>>> foo <- function() {
>>>>      print("Tic");
>>>>      for (kk in 1:50) {
>>>>           print(kk);
>>>>           Sys.sleep(0.1);
>>>>      }
>>>>      print("Tac");
>>>> }
>>>> 
>>>> 
>>>> for (i in 1:10){
>>>>      ptm <- proc.time()
>>>> tryCatch( { abc[i,1] <- evalWithTimeout({foo()} ,timeout=(4+i*0.2)
>>>> ,onTimeout="silent" )
>>>>             abc[i,2] <- 1
>>>> }
>>>> , error = function(x) x)
>>>> tt<- proc.time() - ptm
>>>> abc[i,3]<-tt[3]
>>>> }
>>>> 
>>>> abc
>>>> #####################################################################
>>>> 
>>>> 
>>>> However, in the rugarch setup the "evalWithTimeout" doesn't seem to
>>>> stop the "ugarchfit" estimation reliably. E.g. in one instance the
>>>> recorded time for a step was 1388.03 seconds even though the limit was
>>>> set to be 300 seconds. The next example illustrates my setup in a
>>>> simplified version (unfortunately my results depend on the data I have
>>>> used, so you will not be able to reproduce them):
>>>> 
>>>> 
>>>> #####################################################################
>>>> require('rugarch')
>>>> quiet1 <- read.table( "dax_quiet1.txt" , header=T)
>>>> tempdata <- quiet1$logreturns
>>>> 
>>>> g_order <- matrix(NA,5,2)
>>>> g_order[1,]<-c(1,1)
>>>> g_order[2,]<-c(1,8)
>>>> g_order[3,]<-c(9,6)
>>>> g_order[4,]<-c(9,8)
>>>> g_order[5,]<-c(3,10)
>>>> 
>>>> overview <- data.frame(matrix(NA,5,2))
>>>> 
>>>> for(i in 1:5){
>>>>      ptm <- proc.time()
>>>> 
>>>>      spec <- ugarchspec(
>>>>           variance.model = list(model = "fGARCH", garchOrder =
>>>> g_order[i,], submodel = "TGARCH", external.regressors = NULL,
>>>> variance.targeting = FALSE),
>>>>           mean.model = list(armaOrder = c(0,0), external.regressors =
>>>> NULL), distribution.model = "sged")
>>>> 
>>>>      tryCatch( {tempgarch <- evalWithTimeout({ugarchfit(spec=spec,
>>>> data=tempdata ,solver="hybrid")} ,timeout=20 ,onTimeout="silent" )
>>>>                 overview[i,1]<-infocriteria(tempgarch)[1]
>>>>      }
>>>>      , error = function(x) x)
>>>> 
>>>>      tt<- proc.time() - ptm
>>>>      overview[i,2]<-tt[3]
>>>> }
>>>> 
>>>> overview
>>>> 
>>>> # If the timeout is set set to 20, this setup leads to:
>>>> # 2.87 sec.
>>>> # 6.95 sec.
>>>> # 125 sec.     ... here, tryCatch interrupted the process
>>>> # 51.73 sec.
>>>> # 27.11 sec.
>>>> # for the 5 different estimation steps.
>>>> 
>>>> # timeout set to 300:
>>>> # 2.81 sec.
>>>> # 6.85 sec.
>>>> # 743.58 sec.
>>>> # 41.70 sec.
>>>> # 26.85 sec.
>>>> # no process was interrupted by tryCatch
>>>> #######################################################################
>>>> 
>>>> 
>>>> As can be seen even from this simplified example, when the timeout was
>>>> set to be 20 there still was a process that took 125 seconds (which is
>>>> more than 5 times longer!).
>>>> I would be very thankful for any ideas or comments!
>>>> 
>>>> Best, Johannes
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>> -- 
>>> 
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>> 
>>> 
> 
> -- 
> 
> 


From jzmoser at gmail.com  Sat May 10 19:55:27 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Sat, 10 May 2014 19:55:27 +0200
Subject: [R-SIG-Finance] timout using "evalWithTimeout" in looped
 rugarch estimation
In-Reply-To: <2B20C361-99E7-4B46-9D5A-252C590F5C85@4dscape.com>
References: <536CC2EA.5020105@googlemail.com>
	<536DD3F0.3000405@googlemail.com> <536DF2AE.50900@4dscape.com>
	<536E0B53.10400@googlemail.com>
	<2B20C361-99E7-4B46-9D5A-252C590F5C85@4dscape.com>
Message-ID: <536E680F.4010105@googlemail.com>

Once again many thanks, Alexios!

It was not clear to me that the solvers are contained in separate 
packages with separate manuals.
I still have got three questions

QUESTION 1: I`ve experimented a bit with the outer.iter and inner.iter 
values. Can you recommend any minimal values for them? Should they be 
kept in a certain relationship when being modified (default is 
outer.iter=400 and inner.iter=800)?

QUESTION 2: Moreover, there seems to be NO direct relationship between 
lowering the values and shortening the estimation time (until abortion).
Is this as expected or is it a bug?
E.g. holding outer.iter fixed and lowering the inner.iter parameter from 
130 to 115 decreases time until "no convergence"-message, but lowering 
it from 130 to only 120 strongly INCREASES time (actually I`m not sure 
if the solver in this case would finish at all one time or if it`s 
somehow stuck).
I tried 3 times. The results are:

#################
require('rugarch')
ptm <- proc.time()
spec <- ugarchspec(
      variance.model =
           list(model = "eGARCH", garchOrder = c(0,7), submodel = NULL
                , external.regressors = NULL, variance.targeting = FALSE),
      mean.model = list(armaOrder = c(0,0), external.regressors = NULL),
      distribution.model = "sged")
tempgarch <- ugarchfit(spec=spec, data=tempdata , solver="solnp" , 
solver.control=list( outer.iter = 70, inner.iter=130 ) )
tempgarch
(proc.time()-ptm)[3]

# trial 1:
# outer.iter = 70, inner.iter=115  elapsed 79.87 ugarchfit-->warning: 
solver FAILER to converge. (there`s a typo in the error message)
# outer.iter = 70, inner.iter=120  +++stopped manually after 15 minutes+++
# outer.iter = 70, inner.iter=130  elapsed 135.8 ugarchfit-->warning: 
solver failer to converge.

# trial 2:
# outer.iter = 70, inner.iter=115  elapsed 79.2 ugarchfit-->warning: 
solver failer to converge.
# outer.iter = 70, inner.iter=120  +++stopped manually after 15 minutes+++
# outer.iter = 70, inner.iter=130  elapsed 135.09 ugarchfit-->warning: 
solver failer to converge.

# trial 3:
# outer.iter = 70, inner.iter=115  elapsed 79.3 ugarchfit-->warning: 
solver failer to converge.
# outer.iter = 70, inner.iter=120  +++stopped manually after 15 minutes+++
# outer.iter = 70, inner.iter=130  elapsed 136.13 ugarchfit-->warning: 
solver failer to converge.
#################

QUESTION 3: I`m a bit confused about the parallel computing 
implementation in ugarchfit.
In the vignette it says (on p. 44) "Since version 1.0-14, rugarch makes 
exclusive use of the parallel package for all parallel computations."
But in the manual on p. 70 only the packages "snowfall" or "multicore" 
seem to be supported for the solver used in ugarchfit.
So either EXCLUSIVELY parallel or not?
As I could not find any example about how to set up snowfall in this 
context I simply tried this way (without speed improvement):

##################
require('rugarch')
require('snowfall')
spec <- ugarchspec(
      variance.model=list( model = "eGARCH", garchOrder=c(1,3), 
submodel=NULL, external.regressors=NULL, variance.targeting=FALSE ),
      mean.model=list( armaOrder=c(0,0), external.regressors=NULL ), 
distribution.model = "std")
ptm <- proc.time()
tempgarch <- ugarchfit( spec=spec, data=tempdata ,solver="solnp" ,  
solver.control=list( parallel=TRUE, pkg="snowfall", cores=4 ) )
(proc.time()-ptm)[3]
tempgarch
##################

What am I doing wrong? Do I have to wrap the ugarchfit function into 
something like the following?

##################
sfInit( parallel=TRUE, cpus=4 )
...
sfStop()
##################

(I`d expect a "no" as an answer assuming that the solver itself will do 
something alike if the relevant solver.control options are set)

Best, Johannes




Am 10.05.2014 13:25, schrieb alexios ghalanos:
> Hi Johannes,
>
> On 10 May 2014, at 12:19, Johannes Moser <jzmoser at gmail.com> wrote:
>
>> Many thanks Alexios!!
>>
>> 1. In my TGARCH setup nlminb doesn`t converge even at smaller GARCH order. So I will stick to solnp then.
>>
>> 2. Unfortunately I couldn`t find the correct command which limits the number of iterations via the solver.control options.
>> The details from the manual mention n.sim and n.restarts, but these seem to control other parameters.
>> For the nloptr solver the option maxeval is mentioned. But I don`t work with this solver and trial-and-error-implementation of this option to sonnp leaded to no success.
>> Other packages inspired me to try "maxiter" , "iter.max" , "n.iter" , but they didn`t work either.
>>
>> E.g.              ugarchfit( spec=spec, data=tempdata , solver="solnp",  solver.control=list( maxeval=20, rseed=9876 ) )
> See the documentation for solnp (?solnp). The ?inner.iter? and ?outer.iter? are what you are likely looking for. The n.sim and n.restarts if for the gosolnp solver (multi-start solnp).
>> 3. You`re surely right. The whole study should actually investigate this issue empirically.
>> E.g. in one case there was a surprising result in a sample of size 1200:
>> An ARMA(0,0) eGARCH(5,5) model with a skewed normal for the innovations yielded very good results.
>> No sign biases, nice gof, no autocorrelation in standardized and squared standardized residuals up to order p+q+10, nice AIC and BIC as well as only highly significant coefficients (6 out of 18 were not significant as to the robust SE, though). I will compare this model to a more parsimonious one and also investigate parameter uncertainty.
> Yes, in-sample of course?.but I was referring to forecast performance (out of sample).
>> Best, Johannes
>>
> Regards,
> Alexios
>>
>> Am 10.05.2014 11:34, schrieb alexios ghalanos:
>>> Johannes,
>>>
>>> I suggest the following:
>>>
>>> 1. Don't use hybrid, use instead solnp or nlminb.
>>>
>>> 2. You can control a number of solver convergence criteria (e.g. number
>>> of iterations) using the solver.control argument.
>>>
>>> 3. Before running the code, do consider a little more how reasonable it
>>> is to be modelling a TGARCH(7,8) model. Investigate the model first
>>> (don't just return the AIC or BIC). Are any of the higher order
>>> ARCH/GARCH parameters different from zero or even significant? I have
>>> not seen a single study which shows that such very high order GARCH
>>> models have better performance than more parsimonious alternatives.
>>>
>>> 4. At the best of times it takes a considerable amount of data to
>>> estimate the GARCH persistence. Try running a simulation exercise using
>>> for example the ugarchdistribution function to obtain some insight into
>>> higher order GARCH models.
>>>
>>> 5. Finally, as mentioned numerous times on this forum, the fGARCH model
>>> is a highly parameterized omnibus model. Imposing stationarity during
>>> the optimization, particularly for non-symmetric distributions such as
>>> the ged, is a costly exercise.  Consider using the GJR instead and a
>>> distribution which is a little faster to evaluate such as the JSU.
>>> Alternatively consider using the normal distribution to estimate the
>>> GARCH parameters for the purpose of model comparison.
>>>
>>> -Alexios
>>>
>>> On 10/05/2014 08:23, Johannes Moser wrote:
>>>> I guess that the problem is due to the processing in C as part of the
>>>> ugarchfit routine.
>>>>
>>>> Is there any way to timeout a ugarchfit command or to constrain the
>>>> number if iterations?
>>>>
>>>> At one time the loop seems to be stuck completely.
>>>> I waited for several hours for a single ugarchfit step which just didn`t
>>>> complete. Then I manually stopped the process.
>>>>
>>>> Separate calculation of the respective model also seems to be "stuck"
>>>> (CPU is still working, the "hybrid" algorithms seem to find no solution
>>>> though and just keep running).
>>>>
>>>> As I want to set up a GARCH model-preselection battery there hopefully
>>>> is a way to handle such problems?
>>>>
>>>> Best, Johannes
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Am 09.05.2014 13:58, schrieb Johannes Moser:
>>>>> Dear all,
>>>>>
>>>>> I`ve set up a double loop which loops through different GARCH-orders
>>>>> and ARMA-orders in a rugarch estimation (of several models and error
>>>>> distributions) and each time writes the AIC and other information into
>>>>> a data frame.
>>>>> The resulting data frame should be used for the pre-selection of a
>>>>> model, which then will be examined manually.
>>>>>
>>>>> A small part of the model estimation steps using "ugarchfit" take very
>>>>> long time. So I implemented a timeout function using "evalWithTimeout"
>>>>> which stops the current estimation step and proceeds with the next
>>>>> step in the loop and estimates the next model.
>>>>>
>>>>> The timeout function is wrapped into a "tryCatch" function which
>>>>> assures thet the loop keeps running after e.g. convergence problems.
>>>>>
>>>>> A small toy model works fine:
>>>>>
>>>>>
>>>>> #######################################################################
>>>>> require('R.utils')
>>>>> abc <- matrix(NA,10,3)
>>>>>
>>>>> foo <- function() {
>>>>>       print("Tic");
>>>>>       for (kk in 1:50) {
>>>>>            print(kk);
>>>>>            Sys.sleep(0.1);
>>>>>       }
>>>>>       print("Tac");
>>>>> }
>>>>>
>>>>>
>>>>> for (i in 1:10){
>>>>>       ptm <- proc.time()
>>>>> tryCatch( { abc[i,1] <- evalWithTimeout({foo()} ,timeout=(4+i*0.2)
>>>>> ,onTimeout="silent" )
>>>>>              abc[i,2] <- 1
>>>>> }
>>>>> , error = function(x) x)
>>>>> tt<- proc.time() - ptm
>>>>> abc[i,3]<-tt[3]
>>>>> }
>>>>>
>>>>> abc
>>>>> #####################################################################
>>>>>
>>>>>
>>>>> However, in the rugarch setup the "evalWithTimeout" doesn't seem to
>>>>> stop the "ugarchfit" estimation reliably. E.g. in one instance the
>>>>> recorded time for a step was 1388.03 seconds even though the limit was
>>>>> set to be 300 seconds. The next example illustrates my setup in a
>>>>> simplified version (unfortunately my results depend on the data I have
>>>>> used, so you will not be able to reproduce them):
>>>>>
>>>>>
>>>>> #####################################################################
>>>>> require('rugarch')
>>>>> quiet1 <- read.table( "dax_quiet1.txt" , header=T)
>>>>> tempdata <- quiet1$logreturns
>>>>>
>>>>> g_order <- matrix(NA,5,2)
>>>>> g_order[1,]<-c(1,1)
>>>>> g_order[2,]<-c(1,8)
>>>>> g_order[3,]<-c(9,6)
>>>>> g_order[4,]<-c(9,8)
>>>>> g_order[5,]<-c(3,10)
>>>>>
>>>>> overview <- data.frame(matrix(NA,5,2))
>>>>>
>>>>> for(i in 1:5){
>>>>>       ptm <- proc.time()
>>>>>
>>>>>       spec <- ugarchspec(
>>>>>            variance.model = list(model = "fGARCH", garchOrder =
>>>>> g_order[i,], submodel = "TGARCH", external.regressors = NULL,
>>>>> variance.targeting = FALSE),
>>>>>            mean.model = list(armaOrder = c(0,0), external.regressors =
>>>>> NULL), distribution.model = "sged")
>>>>>
>>>>>       tryCatch( {tempgarch <- evalWithTimeout({ugarchfit(spec=spec,
>>>>> data=tempdata ,solver="hybrid")} ,timeout=20 ,onTimeout="silent" )
>>>>>                  overview[i,1]<-infocriteria(tempgarch)[1]
>>>>>       }
>>>>>       , error = function(x) x)
>>>>>
>>>>>       tt<- proc.time() - ptm
>>>>>       overview[i,2]<-tt[3]
>>>>> }
>>>>>
>>>>> overview
>>>>>
>>>>> # If the timeout is set set to 20, this setup leads to:
>>>>> # 2.87 sec.
>>>>> # 6.95 sec.
>>>>> # 125 sec.     ... here, tryCatch interrupted the process
>>>>> # 51.73 sec.
>>>>> # 27.11 sec.
>>>>> # for the 5 different estimation steps.
>>>>>
>>>>> # timeout set to 300:
>>>>> # 2.81 sec.
>>>>> # 6.85 sec.
>>>>> # 743.58 sec.
>>>>> # 41.70 sec.
>>>>> # 26.85 sec.
>>>>> # no process was interrupted by tryCatch
>>>>> #######################################################################
>>>>>
>>>>>
>>>>> As can be seen even from this simplified example, when the timeout was
>>>>> set to be 20 there still was a process that took 125 seconds (which is
>>>>> more than 5 times longer!).
>>>>> I would be very thankful for any ideas or comments!
>>>>>
>>>>> Best, Johannes
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>> -- 
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions
>>>> should go.
>>>>
>>>>
>> -- 
>>
>>

--


From a.chandhial at btinternet.com  Sat May 10 20:17:41 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Sat, 10 May 2014 19:17:41 +0100 (BST)
Subject: [R-SIG-Finance] Luxor strategy (quantstrat) - Why are
	successive short (and long) trades happening ?
In-Reply-To: <CAPPM_gSa1=ZZa66ceVz7vjcqVvUEuJemQSUbUwY1B-0KridEUg@mail.gmail.com>
References: <CAPA9880DQtewHBRi=B-9PzonLuvU-gEHbCXYN7ZY0zMkvTrABw@mail.gmail.com>
	<1399507505595-4690163.post@n4.nabble.com>
	<CAPPM_gREytDoV27xBLpZ-M_3L8Ni=arsGb7gkPo0H-aEGS+U+A@mail.gmail.com>
	<CAPA9881vntWtiyjr9NrymAu==+PxD7HVfdQ2cxWp7j9M_crOOg@mail.gmail.com>
	<CAPPM_gSa1=ZZa66ceVz7vjcqVvUEuJemQSUbUwY1B-0KridEUg@mail.gmail.com>
Message-ID: <1399745861.24638.YahooMailNeo@web186003.mail.ir2.yahoo.com>




I am unclear. There are 3 different results, which of these is correct ?


(a) Humme, Peterson pp.34/78? http://www.rinfinance.com/agenda/2013/workshop/Humme+Peterson.pdf



(b) Guy Yollin pp.24/78 
https://4310b1a9-a-a8fb2076-s-sites.googlegroups.com/a/r-programming.org/home/files/quantstrat-IV.pdf?attachauth=ANoY7cojS8K93NCMEI2gr1eWPE6nFGkEZAncLma__qYUXHgRzbbQCi1zrOZa5DnAANVw6nGZU9ppV1s69und3U7_uErEyb18pGOyH0UJsXtCsndrvcZWR4fB4mIJePELsQcuf3ksoDg3w7JV0TH_kpR3NDGBiDYzX9f43piDIk6vhfK5JMK68K1K7yqCZcHZ0krZzhRJ9Wq3KIZt5-399IqQ-Eeytar1o2n-VpqgoBIefXlC5iT6rlM%3D&attredirects=0



(c) The latest run of the demo, blotter(rev 1607), quantstrat(rev 1610) - chart.Posn attached.



Amarjit


 

________________________________
 From: Joshua Ulrich <josh.m.ulrich at gmail.com>
To: Pablo Rios <pablo.javier.rios at gmail.com> 
Cc: r-sig-finance <r-sig-finance at r-project.org> 
Sent: Friday, 9 May 2014, 12:26
Subject: Re: [R-SIG-Finance] Luxor strategy (quantstrat) - Why are successive short (and long) trades happening ?
  

On Thu, May 8, 2014 at 11:09 PM, Pablo Rios <pablo.javier.rios at gmail.com> wrote:
> Thanks for your quick response Joshua.
>
> Does the code changes in r1609 intend to fix the successive short (or long)
> trades that I'm describing in my email, or only the Warning: stack imbalance
> in 'lapply' message ? Although this warning message is no longer reported,
> and the results of the Luxor strategy changed after r1609 (ex.:
> Net.Trading.PL value changed, among other variables), I'm still observing
> the same behaviour of successive short (or long) trades running the Luxor
> demo code with the GBP/USD demo data available in quantstrat.
>
r1609 only intended to fix the stack imbalance warning (as it says in
the commit log).

> Moreover, if I run luxor.1.strategy.basic.R demo code with a longer GBP/USD
> time series, using 30 minutes bars as in the demo data (ex.: three years), I
> observed up to 5 successive short trades (i.e., Pos.Qty value of
> GBPUSD$posPL xts object equal to -500,000) and 4 successive long trades.
>
> Further, looking at the firstCross.c in r1609 I'm seeing in the
> switch(int_rel) statement that all comparisons are done by greater than
> ('>'). I don't know whether this is correct or not.
>
That was a careless error on my part.? r1610 corrects the comparisons.
Thank you very much for catching this.

> Thanks for your support, I'm eager to finally adopt quantstrat !
>
> Pablo
>
>
> On Thu, May 8, 2014 at 8:09 AM, Joshua Ulrich <josh.m.ulrich at gmail.com>
> wrote:
>>
>> On Wed, May 7, 2014 at 7:05 PM, fc_11 <jyorio at gmail.com> wrote:
>> > i also am getting the "Warning: stack imbalance in 'lapply'," warning
>> > since
>> > the 1608 upgrade
>> >
>> Fixed in r1609.
>> --
>> Joshua Ulrich? |? about.me/joshuaulrich
>> FOSS Trading? |? www.fosstrading.com
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140510/7f1dd3c4/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: latest.jpg
Type: image/jpeg
Size: 189364 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140510/7f1dd3c4/attachment.jpg>

From alexios at 4dscape.com  Sat May 10 21:22:57 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sat, 10 May 2014 20:22:57 +0100
Subject: [R-SIG-Finance] timout using "evalWithTimeout" in looped
 rugarch estimation
In-Reply-To: <536E680F.4010105@googlemail.com>
References: <536CC2EA.5020105@googlemail.com>
	<536DD3F0.3000405@googlemail.com> <536DF2AE.50900@4dscape.com>
	<536E0B53.10400@googlemail.com>
	<2B20C361-99E7-4B46-9D5A-252C590F5C85@4dscape.com>
	<536E680F.4010105@googlemail.com>
Message-ID: <536E7C91.1020108@4dscape.com>

On 10/05/2014 18:55, Johannes Moser wrote:
> Once again many thanks, Alexios!
> 
> It was not clear to me that the solvers are contained in separate
> packages with separate manuals.
> I still have got three questions
> 
> QUESTION 1: I`ve experimented a bit with the outer.iter and inner.iter
> values. Can you recommend any minimal values for them? Should they be
> kept in a certain relationship when being modified (default is
> outer.iter=400 and inner.iter=800)?
> 

No. Depends on your problem. Obviously, if it does not converge in N
iterations then it will certainly NOT converge in less than N.

> QUESTION 2: Moreover, there seems to be NO direct relationship between
> lowering the values and shortening the estimation time (until abortion).
> Is this as expected or is it a bug?
> E.g. holding outer.iter fixed and lowering the inner.iter parameter from
> 130 to 115 decreases time until "no convergence"-message, but lowering
> it from 130 to only 120 strongly INCREASES time (actually I`m not sure
> if the solver in this case would finish at all one time or if it`s
> somehow stuck).
> I tried 3 times. The results are:
> 
> #################
> require('rugarch')
> ptm <- proc.time()
> spec <- ugarchspec(
>      variance.model =
>           list(model = "eGARCH", garchOrder = c(0,7), submodel = NULL
>                , external.regressors = NULL, variance.targeting = FALSE),
>      mean.model = list(armaOrder = c(0,0), external.regressors = NULL),
>      distribution.model = "sged")
> tempgarch <- ugarchfit(spec=spec, data=tempdata , solver="solnp" ,
> solver.control=list( outer.iter = 70, inner.iter=130 ) )
> tempgarch
> (proc.time()-ptm)[3]
> 
> # trial 1:
> # outer.iter = 70, inner.iter=115  elapsed 79.87 ugarchfit-->warning:
> solver FAILER to converge. (there`s a typo in the error message)
> # outer.iter = 70, inner.iter=120  +++stopped manually after 15 minutes+++
> # outer.iter = 70, inner.iter=130  elapsed 135.8 ugarchfit-->warning:
> solver failer to converge.
> 
> # trial 2:
> # outer.iter = 70, inner.iter=115  elapsed 79.2 ugarchfit-->warning:
> solver failer to converge.
> # outer.iter = 70, inner.iter=120  +++stopped manually after 15 minutes+++
> # outer.iter = 70, inner.iter=130  elapsed 135.09 ugarchfit-->warning:
> solver failer to converge.
> 
> # trial 3:
> # outer.iter = 70, inner.iter=115  elapsed 79.3 ugarchfit-->warning:
> solver failer to converge.
> # outer.iter = 70, inner.iter=120  +++stopped manually after 15 minutes+++
> # outer.iter = 70, inner.iter=130  elapsed 136.13 ugarchfit-->warning:
> solver failer to converge.
> #################

There are many parameters and many options to consider (fit.control and
solver.control). See the FAQ in the vignette on model convergence. I'll
have nothing more to say on this, particularly for a GARCH(0,7) model,
whatever that means.

> 
> QUESTION 3: I`m a bit confused about the parallel computing
> implementation in ugarchfit.
> In the vignette it says (on p. 44) "Since version 1.0-14, rugarch makes
> exclusive use of the parallel package for all parallel computations."
> But in the manual on p. 70 only the packages "snowfall" or "multicore"
> seem to be supported for the solver used in ugarchfit.
> So either EXCLUSIVELY parallel or not?
> As I could not find any example about how to set up snowfall in this
> context I simply tried this way (without speed improvement):

Parallel is a wrapper for multicore and snowfall. However, for making
use of the parallel functionality of ANOTHER package (Rsolnp) the
instructions are quite clear on what to pass (see Details of ?ugarchfit).
But where exactly do you expect the parallel functionality to play a
role in the univariate estimation? For ugarchfit it is only used when
the solver is gosolnp (and you have set n.restarts>1), which is again
stated in the manual. Parallel functionality otherwise is used for the
simulation routines (multiple runs), rolling estimation i.e. where it
makes sense to use parallel resources.
> 
> ##################
> require('rugarch')
> require('snowfall')
> spec <- ugarchspec(
>      variance.model=list( model = "eGARCH", garchOrder=c(1,3),
> submodel=NULL, external.regressors=NULL, variance.targeting=FALSE ),
>      mean.model=list( armaOrder=c(0,0), external.regressors=NULL ),
> distribution.model = "std")
> ptm <- proc.time()
> tempgarch <- ugarchfit( spec=spec, data=tempdata ,solver="solnp" , 
> solver.control=list( parallel=TRUE, pkg="snowfall", cores=4 ) )
> (proc.time()-ptm)[3]
> tempgarch
> ##################
> 
> What am I doing wrong? Do I have to wrap the ugarchfit function into
> something like the following?
> 
> ##################
> sfInit( parallel=TRUE, cpus=4 )
> ...
> sfStop()
> ##################
> 
> (I`d expect a "no" as an answer assuming that the solver itself will do
> something alike if the relevant solver.control options are set)
> 
> Best, Johannes
> 
> 
Regards,

Alexios

> 
> 
> Am 10.05.2014 13:25, schrieb alexios ghalanos:
>> Hi Johannes,
>>
>> On 10 May 2014, at 12:19, Johannes Moser <jzmoser at gmail.com> wrote:
>>
>>> Many thanks Alexios!!
>>>
>>> 1. In my TGARCH setup nlminb doesn`t converge even at smaller GARCH
>>> order. So I will stick to solnp then.
>>>
>>> 2. Unfortunately I couldn`t find the correct command which limits the
>>> number of iterations via the solver.control options.
>>> The details from the manual mention n.sim and n.restarts, but these
>>> seem to control other parameters.
>>> For the nloptr solver the option maxeval is mentioned. But I don`t
>>> work with this solver and trial-and-error-implementation of this
>>> option to sonnp leaded to no success.
>>> Other packages inspired me to try "maxiter" , "iter.max" , "n.iter" ,
>>> but they didn`t work either.
>>>
>>> E.g.              ugarchfit( spec=spec, data=tempdata ,
>>> solver="solnp",  solver.control=list( maxeval=20, rseed=9876 ) )
>> See the documentation for solnp (?solnp). The ?inner.iter? and
>> ?outer.iter? are what you are likely looking for. The n.sim and
>> n.restarts if for the gosolnp solver (multi-start solnp).
>>> 3. You`re surely right. The whole study should actually investigate
>>> this issue empirically.
>>> E.g. in one case there was a surprising result in a sample of size 1200:
>>> An ARMA(0,0) eGARCH(5,5) model with a skewed normal for the
>>> innovations yielded very good results.
>>> No sign biases, nice gof, no autocorrelation in standardized and
>>> squared standardized residuals up to order p+q+10, nice AIC and BIC
>>> as well as only highly significant coefficients (6 out of 18 were not
>>> significant as to the robust SE, though). I will compare this model
>>> to a more parsimonious one and also investigate parameter uncertainty.
>> Yes, in-sample of course?.but I was referring to forecast performance
>> (out of sample).
>>> Best, Johannes
>>>
>> Regards,
>> Alexios
>>>
>>> Am 10.05.2014 11:34, schrieb alexios ghalanos:
>>>> Johannes,
>>>>
>>>> I suggest the following:
>>>>
>>>> 1. Don't use hybrid, use instead solnp or nlminb.
>>>>
>>>> 2. You can control a number of solver convergence criteria (e.g. number
>>>> of iterations) using the solver.control argument.
>>>>
>>>> 3. Before running the code, do consider a little more how reasonable it
>>>> is to be modelling a TGARCH(7,8) model. Investigate the model first
>>>> (don't just return the AIC or BIC). Are any of the higher order
>>>> ARCH/GARCH parameters different from zero or even significant? I have
>>>> not seen a single study which shows that such very high order GARCH
>>>> models have better performance than more parsimonious alternatives.
>>>>
>>>> 4. At the best of times it takes a considerable amount of data to
>>>> estimate the GARCH persistence. Try running a simulation exercise using
>>>> for example the ugarchdistribution function to obtain some insight into
>>>> higher order GARCH models.
>>>>
>>>> 5. Finally, as mentioned numerous times on this forum, the fGARCH model
>>>> is a highly parameterized omnibus model. Imposing stationarity during
>>>> the optimization, particularly for non-symmetric distributions such as
>>>> the ged, is a costly exercise.  Consider using the GJR instead and a
>>>> distribution which is a little faster to evaluate such as the JSU.
>>>> Alternatively consider using the normal distribution to estimate the
>>>> GARCH parameters for the purpose of model comparison.
>>>>
>>>> -Alexios
>>>>
>>>> On 10/05/2014 08:23, Johannes Moser wrote:
>>>>> I guess that the problem is due to the processing in C as part of the
>>>>> ugarchfit routine.
>>>>>
>>>>> Is there any way to timeout a ugarchfit command or to constrain the
>>>>> number if iterations?
>>>>>
>>>>> At one time the loop seems to be stuck completely.
>>>>> I waited for several hours for a single ugarchfit step which just
>>>>> didn`t
>>>>> complete. Then I manually stopped the process.
>>>>>
>>>>> Separate calculation of the respective model also seems to be "stuck"
>>>>> (CPU is still working, the "hybrid" algorithms seem to find no
>>>>> solution
>>>>> though and just keep running).
>>>>>
>>>>> As I want to set up a GARCH model-preselection battery there hopefully
>>>>> is a way to handle such problems?
>>>>>
>>>>> Best, Johannes
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Am 09.05.2014 13:58, schrieb Johannes Moser:
>>>>>> Dear all,
>>>>>>
>>>>>> I`ve set up a double loop which loops through different GARCH-orders
>>>>>> and ARMA-orders in a rugarch estimation (of several models and error
>>>>>> distributions) and each time writes the AIC and other information
>>>>>> into
>>>>>> a data frame.
>>>>>> The resulting data frame should be used for the pre-selection of a
>>>>>> model, which then will be examined manually.
>>>>>>
>>>>>> A small part of the model estimation steps using "ugarchfit" take
>>>>>> very
>>>>>> long time. So I implemented a timeout function using
>>>>>> "evalWithTimeout"
>>>>>> which stops the current estimation step and proceeds with the next
>>>>>> step in the loop and estimates the next model.
>>>>>>
>>>>>> The timeout function is wrapped into a "tryCatch" function which
>>>>>> assures thet the loop keeps running after e.g. convergence problems.
>>>>>>
>>>>>> A small toy model works fine:
>>>>>>
>>>>>>
>>>>>> #######################################################################
>>>>>>
>>>>>> require('R.utils')
>>>>>> abc <- matrix(NA,10,3)
>>>>>>
>>>>>> foo <- function() {
>>>>>>       print("Tic");
>>>>>>       for (kk in 1:50) {
>>>>>>            print(kk);
>>>>>>            Sys.sleep(0.1);
>>>>>>       }
>>>>>>       print("Tac");
>>>>>> }
>>>>>>
>>>>>>
>>>>>> for (i in 1:10){
>>>>>>       ptm <- proc.time()
>>>>>> tryCatch( { abc[i,1] <- evalWithTimeout({foo()} ,timeout=(4+i*0.2)
>>>>>> ,onTimeout="silent" )
>>>>>>              abc[i,2] <- 1
>>>>>> }
>>>>>> , error = function(x) x)
>>>>>> tt<- proc.time() - ptm
>>>>>> abc[i,3]<-tt[3]
>>>>>> }
>>>>>>
>>>>>> abc
>>>>>> #####################################################################
>>>>>>
>>>>>>
>>>>>> However, in the rugarch setup the "evalWithTimeout" doesn't seem to
>>>>>> stop the "ugarchfit" estimation reliably. E.g. in one instance the
>>>>>> recorded time for a step was 1388.03 seconds even though the limit
>>>>>> was
>>>>>> set to be 300 seconds. The next example illustrates my setup in a
>>>>>> simplified version (unfortunately my results depend on the data I
>>>>>> have
>>>>>> used, so you will not be able to reproduce them):
>>>>>>
>>>>>>
>>>>>> #####################################################################
>>>>>> require('rugarch')
>>>>>> quiet1 <- read.table( "dax_quiet1.txt" , header=T)
>>>>>> tempdata <- quiet1$logreturns
>>>>>>
>>>>>> g_order <- matrix(NA,5,2)
>>>>>> g_order[1,]<-c(1,1)
>>>>>> g_order[2,]<-c(1,8)
>>>>>> g_order[3,]<-c(9,6)
>>>>>> g_order[4,]<-c(9,8)
>>>>>> g_order[5,]<-c(3,10)
>>>>>>
>>>>>> overview <- data.frame(matrix(NA,5,2))
>>>>>>
>>>>>> for(i in 1:5){
>>>>>>       ptm <- proc.time()
>>>>>>
>>>>>>       spec <- ugarchspec(
>>>>>>            variance.model = list(model = "fGARCH", garchOrder =
>>>>>> g_order[i,], submodel = "TGARCH", external.regressors = NULL,
>>>>>> variance.targeting = FALSE),
>>>>>>            mean.model = list(armaOrder = c(0,0),
>>>>>> external.regressors =
>>>>>> NULL), distribution.model = "sged")
>>>>>>
>>>>>>       tryCatch( {tempgarch <- evalWithTimeout({ugarchfit(spec=spec,
>>>>>> data=tempdata ,solver="hybrid")} ,timeout=20 ,onTimeout="silent" )
>>>>>>                  overview[i,1]<-infocriteria(tempgarch)[1]
>>>>>>       }
>>>>>>       , error = function(x) x)
>>>>>>
>>>>>>       tt<- proc.time() - ptm
>>>>>>       overview[i,2]<-tt[3]
>>>>>> }
>>>>>>
>>>>>> overview
>>>>>>
>>>>>> # If the timeout is set set to 20, this setup leads to:
>>>>>> # 2.87 sec.
>>>>>> # 6.95 sec.
>>>>>> # 125 sec.     ... here, tryCatch interrupted the process
>>>>>> # 51.73 sec.
>>>>>> # 27.11 sec.
>>>>>> # for the 5 different estimation steps.
>>>>>>
>>>>>> # timeout set to 300:
>>>>>> # 2.81 sec.
>>>>>> # 6.85 sec.
>>>>>> # 743.58 sec.
>>>>>> # 41.70 sec.
>>>>>> # 26.85 sec.
>>>>>> # no process was interrupted by tryCatch
>>>>>> #######################################################################
>>>>>>
>>>>>>
>>>>>>
>>>>>> As can be seen even from this simplified example, when the timeout
>>>>>> was
>>>>>> set to be 20 there still was a process that took 125 seconds
>>>>>> (which is
>>>>>> more than 5 times longer!).
>>>>>> I would be very thankful for any ideas or comments!
>>>>>>
>>>>>> Best, Johannes
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>> -- 
>>>>>
>>>>> _______________________________________________
>>>>> R-SIG-Finance at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>> -- Also note that this is not the r-help list where general R
>>>>> questions
>>>>> should go.
>>>>>
>>>>>
>>> -- 
>>>
>>>
>


From jzmoser at gmail.com  Sat May 10 22:22:50 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Sat, 10 May 2014 22:22:50 +0200
Subject: [R-SIG-Finance] timout using "evalWithTimeout" in looped
 rugarch estimation
In-Reply-To: <536E7C91.1020108@4dscape.com>
References: <536CC2EA.5020105@googlemail.com>
	<536DD3F0.3000405@googlemail.com> <536DF2AE.50900@4dscape.com>
	<536E0B53.10400@googlemail.com>
	<2B20C361-99E7-4B46-9D5A-252C590F5C85@4dscape.com>
	<536E680F.4010105@googlemail.com> <536E7C91.1020108@4dscape.com>
Message-ID: <536E8A9A.1050607@googlemail.com>

In the context of question2 I was actually looking for a model that does 
NOT converge.
But in being so focussed on the ways to handle long convergence times I 
indeed picked a totally meaningless model which is a bit embarassing.
I`ll keep playing around with numbers and have another look at the manuals.

Thank you very much for the hints and your patience, Alexios!



Am 10.05.2014 21:22, schrieb alexios ghalanos:
> On 10/05/2014 18:55, Johannes Moser wrote:
>> Once again many thanks, Alexios!
>>
>> It was not clear to me that the solvers are contained in separate
>> packages with separate manuals.
>> I still have got three questions
>>
>> QUESTION 1: I`ve experimented a bit with the outer.iter and inner.iter
>> values. Can you recommend any minimal values for them? Should they be
>> kept in a certain relationship when being modified (default is
>> outer.iter=400 and inner.iter=800)?
>>
> No. Depends on your problem. Obviously, if it does not converge in N
> iterations then it will certainly NOT converge in less than N.
>
>> QUESTION 2: Moreover, there seems to be NO direct relationship between
>> lowering the values and shortening the estimation time (until abortion).
>> Is this as expected or is it a bug?
>> E.g. holding outer.iter fixed and lowering the inner.iter parameter from
>> 130 to 115 decreases time until "no convergence"-message, but lowering
>> it from 130 to only 120 strongly INCREASES time (actually I`m not sure
>> if the solver in this case would finish at all one time or if it`s
>> somehow stuck).
>> I tried 3 times. The results are:
>>
>> #################
>> require('rugarch')
>> ptm <- proc.time()
>> spec <- ugarchspec(
>>       variance.model =
>>            list(model = "eGARCH", garchOrder = c(0,7), submodel = NULL
>>                 , external.regressors = NULL, variance.targeting = FALSE),
>>       mean.model = list(armaOrder = c(0,0), external.regressors = NULL),
>>       distribution.model = "sged")
>> tempgarch <- ugarchfit(spec=spec, data=tempdata , solver="solnp" ,
>> solver.control=list( outer.iter = 70, inner.iter=130 ) )
>> tempgarch
>> (proc.time()-ptm)[3]
>>
>> # trial 1:
>> # outer.iter = 70, inner.iter=115  elapsed 79.87 ugarchfit-->warning:
>> solver FAILER to converge. (there`s a typo in the error message)
>> # outer.iter = 70, inner.iter=120  +++stopped manually after 15 minutes+++
>> # outer.iter = 70, inner.iter=130  elapsed 135.8 ugarchfit-->warning:
>> solver failer to converge.
>>
>> # trial 2:
>> # outer.iter = 70, inner.iter=115  elapsed 79.2 ugarchfit-->warning:
>> solver failer to converge.
>> # outer.iter = 70, inner.iter=120  +++stopped manually after 15 minutes+++
>> # outer.iter = 70, inner.iter=130  elapsed 135.09 ugarchfit-->warning:
>> solver failer to converge.
>>
>> # trial 3:
>> # outer.iter = 70, inner.iter=115  elapsed 79.3 ugarchfit-->warning:
>> solver failer to converge.
>> # outer.iter = 70, inner.iter=120  +++stopped manually after 15 minutes+++
>> # outer.iter = 70, inner.iter=130  elapsed 136.13 ugarchfit-->warning:
>> solver failer to converge.
>> #################
> There are many parameters and many options to consider (fit.control and
> solver.control). See the FAQ in the vignette on model convergence. I'll
> have nothing more to say on this, particularly for a GARCH(0,7) model,
> whatever that means.
>
>> QUESTION 3: I`m a bit confused about the parallel computing
>> implementation in ugarchfit.
>> In the vignette it says (on p. 44) "Since version 1.0-14, rugarch makes
>> exclusive use of the parallel package for all parallel computations."
>> But in the manual on p. 70 only the packages "snowfall" or "multicore"
>> seem to be supported for the solver used in ugarchfit.
>> So either EXCLUSIVELY parallel or not?
>> As I could not find any example about how to set up snowfall in this
>> context I simply tried this way (without speed improvement):
> Parallel is a wrapper for multicore and snowfall. However, for making
> use of the parallel functionality of ANOTHER package (Rsolnp) the
> instructions are quite clear on what to pass (see Details of ?ugarchfit).
> But where exactly do you expect the parallel functionality to play a
> role in the univariate estimation? For ugarchfit it is only used when
> the solver is gosolnp (and you have set n.restarts>1), which is again
> stated in the manual. Parallel functionality otherwise is used for the
> simulation routines (multiple runs), rolling estimation i.e. where it
> makes sense to use parallel resources.
>> ##################
>> require('rugarch')
>> require('snowfall')
>> spec <- ugarchspec(
>>       variance.model=list( model = "eGARCH", garchOrder=c(1,3),
>> submodel=NULL, external.regressors=NULL, variance.targeting=FALSE ),
>>       mean.model=list( armaOrder=c(0,0), external.regressors=NULL ),
>> distribution.model = "std")
>> ptm <- proc.time()
>> tempgarch <- ugarchfit( spec=spec, data=tempdata ,solver="solnp" ,
>> solver.control=list( parallel=TRUE, pkg="snowfall", cores=4 ) )
>> (proc.time()-ptm)[3]
>> tempgarch
>> ##################
>>
>> What am I doing wrong? Do I have to wrap the ugarchfit function into
>> something like the following?
>>
>> ##################
>> sfInit( parallel=TRUE, cpus=4 )
>> ...
>> sfStop()
>> ##################
>>
>> (I`d expect a "no" as an answer assuming that the solver itself will do
>> something alike if the relevant solver.control options are set)
>>
>> Best, Johannes
>>
>>
> Regards,
>
> Alexios
>
>>
>> Am 10.05.2014 13:25, schrieb alexios ghalanos:
>>> Hi Johannes,
>>>
>>> On 10 May 2014, at 12:19, Johannes Moser <jzmoser at gmail.com> wrote:
>>>
>>>> Many thanks Alexios!!
>>>>
>>>> 1. In my TGARCH setup nlminb doesn`t converge even at smaller GARCH
>>>> order. So I will stick to solnp then.
>>>>
>>>> 2. Unfortunately I couldn`t find the correct command which limits the
>>>> number of iterations via the solver.control options.
>>>> The details from the manual mention n.sim and n.restarts, but these
>>>> seem to control other parameters.
>>>> For the nloptr solver the option maxeval is mentioned. But I don`t
>>>> work with this solver and trial-and-error-implementation of this
>>>> option to sonnp leaded to no success.
>>>> Other packages inspired me to try "maxiter" , "iter.max" , "n.iter" ,
>>>> but they didn`t work either.
>>>>
>>>> E.g.              ugarchfit( spec=spec, data=tempdata ,
>>>> solver="solnp",  solver.control=list( maxeval=20, rseed=9876 ) )
>>> See the documentation for solnp (?solnp). The ?inner.iter? and
>>> ?outer.iter? are what you are likely looking for. The n.sim and
>>> n.restarts if for the gosolnp solver (multi-start solnp).
>>>> 3. You`re surely right. The whole study should actually investigate
>>>> this issue empirically.
>>>> E.g. in one case there was a surprising result in a sample of size 1200:
>>>> An ARMA(0,0) eGARCH(5,5) model with a skewed normal for the
>>>> innovations yielded very good results.
>>>> No sign biases, nice gof, no autocorrelation in standardized and
>>>> squared standardized residuals up to order p+q+10, nice AIC and BIC
>>>> as well as only highly significant coefficients (6 out of 18 were not
>>>> significant as to the robust SE, though). I will compare this model
>>>> to a more parsimonious one and also investigate parameter uncertainty.
>>> Yes, in-sample of course?.but I was referring to forecast performance
>>> (out of sample).
>>>> Best, Johannes
>>>>
>>> Regards,
>>> Alexios
>>>> Am 10.05.2014 11:34, schrieb alexios ghalanos:
>>>>> Johannes,
>>>>>
>>>>> I suggest the following:
>>>>>
>>>>> 1. Don't use hybrid, use instead solnp or nlminb.
>>>>>
>>>>> 2. You can control a number of solver convergence criteria (e.g. number
>>>>> of iterations) using the solver.control argument.
>>>>>
>>>>> 3. Before running the code, do consider a little more how reasonable it
>>>>> is to be modelling a TGARCH(7,8) model. Investigate the model first
>>>>> (don't just return the AIC or BIC). Are any of the higher order
>>>>> ARCH/GARCH parameters different from zero or even significant? I have
>>>>> not seen a single study which shows that such very high order GARCH
>>>>> models have better performance than more parsimonious alternatives.
>>>>>
>>>>> 4. At the best of times it takes a considerable amount of data to
>>>>> estimate the GARCH persistence. Try running a simulation exercise using
>>>>> for example the ugarchdistribution function to obtain some insight into
>>>>> higher order GARCH models.
>>>>>
>>>>> 5. Finally, as mentioned numerous times on this forum, the fGARCH model
>>>>> is a highly parameterized omnibus model. Imposing stationarity during
>>>>> the optimization, particularly for non-symmetric distributions such as
>>>>> the ged, is a costly exercise.  Consider using the GJR instead and a
>>>>> distribution which is a little faster to evaluate such as the JSU.
>>>>> Alternatively consider using the normal distribution to estimate the
>>>>> GARCH parameters for the purpose of model comparison.
>>>>>
>>>>> -Alexios
>>>>>
>>>>> On 10/05/2014 08:23, Johannes Moser wrote:
>>>>>> I guess that the problem is due to the processing in C as part of the
>>>>>> ugarchfit routine.
>>>>>>
>>>>>> Is there any way to timeout a ugarchfit command or to constrain the
>>>>>> number if iterations?
>>>>>>
>>>>>> At one time the loop seems to be stuck completely.
>>>>>> I waited for several hours for a single ugarchfit step which just
>>>>>> didn`t
>>>>>> complete. Then I manually stopped the process.
>>>>>>
>>>>>> Separate calculation of the respective model also seems to be "stuck"
>>>>>> (CPU is still working, the "hybrid" algorithms seem to find no
>>>>>> solution
>>>>>> though and just keep running).
>>>>>>
>>>>>> As I want to set up a GARCH model-preselection battery there hopefully
>>>>>> is a way to handle such problems?
>>>>>>
>>>>>> Best, Johannes
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Am 09.05.2014 13:58, schrieb Johannes Moser:
>>>>>>> Dear all,
>>>>>>>
>>>>>>> I`ve set up a double loop which loops through different GARCH-orders
>>>>>>> and ARMA-orders in a rugarch estimation (of several models and error
>>>>>>> distributions) and each time writes the AIC and other information
>>>>>>> into
>>>>>>> a data frame.
>>>>>>> The resulting data frame should be used for the pre-selection of a
>>>>>>> model, which then will be examined manually.
>>>>>>>
>>>>>>> A small part of the model estimation steps using "ugarchfit" take
>>>>>>> very
>>>>>>> long time. So I implemented a timeout function using
>>>>>>> "evalWithTimeout"
>>>>>>> which stops the current estimation step and proceeds with the next
>>>>>>> step in the loop and estimates the next model.
>>>>>>>
>>>>>>> The timeout function is wrapped into a "tryCatch" function which
>>>>>>> assures thet the loop keeps running after e.g. convergence problems.
>>>>>>>
>>>>>>> A small toy model works fine:
>>>>>>>
>>>>>>>
>>>>>>> #######################################################################
>>>>>>>
>>>>>>> require('R.utils')
>>>>>>> abc <- matrix(NA,10,3)
>>>>>>>
>>>>>>> foo <- function() {
>>>>>>>        print("Tic");
>>>>>>>        for (kk in 1:50) {
>>>>>>>             print(kk);
>>>>>>>             Sys.sleep(0.1);
>>>>>>>        }
>>>>>>>        print("Tac");
>>>>>>> }
>>>>>>>
>>>>>>>
>>>>>>> for (i in 1:10){
>>>>>>>        ptm <- proc.time()
>>>>>>> tryCatch( { abc[i,1] <- evalWithTimeout({foo()} ,timeout=(4+i*0.2)
>>>>>>> ,onTimeout="silent" )
>>>>>>>               abc[i,2] <- 1
>>>>>>> }
>>>>>>> , error = function(x) x)
>>>>>>> tt<- proc.time() - ptm
>>>>>>> abc[i,3]<-tt[3]
>>>>>>> }
>>>>>>>
>>>>>>> abc
>>>>>>> #####################################################################
>>>>>>>
>>>>>>>
>>>>>>> However, in the rugarch setup the "evalWithTimeout" doesn't seem to
>>>>>>> stop the "ugarchfit" estimation reliably. E.g. in one instance the
>>>>>>> recorded time for a step was 1388.03 seconds even though the limit
>>>>>>> was
>>>>>>> set to be 300 seconds. The next example illustrates my setup in a
>>>>>>> simplified version (unfortunately my results depend on the data I
>>>>>>> have
>>>>>>> used, so you will not be able to reproduce them):
>>>>>>>
>>>>>>>
>>>>>>> #####################################################################
>>>>>>> require('rugarch')
>>>>>>> quiet1 <- read.table( "dax_quiet1.txt" , header=T)
>>>>>>> tempdata <- quiet1$logreturns
>>>>>>>
>>>>>>> g_order <- matrix(NA,5,2)
>>>>>>> g_order[1,]<-c(1,1)
>>>>>>> g_order[2,]<-c(1,8)
>>>>>>> g_order[3,]<-c(9,6)
>>>>>>> g_order[4,]<-c(9,8)
>>>>>>> g_order[5,]<-c(3,10)
>>>>>>>
>>>>>>> overview <- data.frame(matrix(NA,5,2))
>>>>>>>
>>>>>>> for(i in 1:5){
>>>>>>>        ptm <- proc.time()
>>>>>>>
>>>>>>>        spec <- ugarchspec(
>>>>>>>             variance.model = list(model = "fGARCH", garchOrder =
>>>>>>> g_order[i,], submodel = "TGARCH", external.regressors = NULL,
>>>>>>> variance.targeting = FALSE),
>>>>>>>             mean.model = list(armaOrder = c(0,0),
>>>>>>> external.regressors =
>>>>>>> NULL), distribution.model = "sged")
>>>>>>>
>>>>>>>        tryCatch( {tempgarch <- evalWithTimeout({ugarchfit(spec=spec,
>>>>>>> data=tempdata ,solver="hybrid")} ,timeout=20 ,onTimeout="silent" )
>>>>>>>                   overview[i,1]<-infocriteria(tempgarch)[1]
>>>>>>>        }
>>>>>>>        , error = function(x) x)
>>>>>>>
>>>>>>>        tt<- proc.time() - ptm
>>>>>>>        overview[i,2]<-tt[3]
>>>>>>> }
>>>>>>>
>>>>>>> overview
>>>>>>>
>>>>>>> # If the timeout is set set to 20, this setup leads to:
>>>>>>> # 2.87 sec.
>>>>>>> # 6.95 sec.
>>>>>>> # 125 sec.     ... here, tryCatch interrupted the process
>>>>>>> # 51.73 sec.
>>>>>>> # 27.11 sec.
>>>>>>> # for the 5 different estimation steps.
>>>>>>>
>>>>>>> # timeout set to 300:
>>>>>>> # 2.81 sec.
>>>>>>> # 6.85 sec.
>>>>>>> # 743.58 sec.
>>>>>>> # 41.70 sec.
>>>>>>> # 26.85 sec.
>>>>>>> # no process was interrupted by tryCatch
>>>>>>> #######################################################################
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> As can be seen even from this simplified example, when the timeout
>>>>>>> was
>>>>>>> set to be 20 there still was a process that took 125 seconds
>>>>>>> (which is
>>>>>>> more than 5 times longer!).
>>>>>>> I would be very thankful for any ideas or comments!
>>>>>>>
>>>>>>> Best, Johannes
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>> -- 
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-SIG-Finance at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>>> -- Also note that this is not the r-help list where general R
>>>>>> questions
>>>>>> should go.
>>>>>>
>>>>>>
>>>> -- 
>>>>
>>>>

--


From pablo.javier.rios at gmail.com  Sun May 11 00:02:26 2014
From: pablo.javier.rios at gmail.com (Pablo Rios)
Date: Sat, 10 May 2014 19:02:26 -0300
Subject: [R-SIG-Finance] Luxor strategy (quantstrat) - Why are
 successive short (and long) trades happening ?
In-Reply-To: <1399745861.24638.YahooMailNeo@web186003.mail.ir2.yahoo.com>
References: <CAPA9880DQtewHBRi=B-9PzonLuvU-gEHbCXYN7ZY0zMkvTrABw@mail.gmail.com>
	<1399507505595-4690163.post@n4.nabble.com>
	<CAPPM_gREytDoV27xBLpZ-M_3L8Ni=arsGb7gkPo0H-aEGS+U+A@mail.gmail.com>
	<CAPA9881vntWtiyjr9NrymAu==+PxD7HVfdQ2cxWp7j9M_crOOg@mail.gmail.com>
	<CAPPM_gSa1=ZZa66ceVz7vjcqVvUEuJemQSUbUwY1B-0KridEUg@mail.gmail.com>
	<1399745861.24638.YahooMailNeo@web186003.mail.ir2.yahoo.com>
Message-ID: <CAPA9881wO=uLHE0-V1sh_8gHtWLFOEV0hOcyV0cFQFw2yH4bRg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140510/44de7d0f/attachment.pl>

From sebastian.ivanciu at gmail.com  Mon May 12 22:21:39 2014
From: sebastian.ivanciu at gmail.com (Sebastian Ivanciu)
Date: Mon, 12 May 2014 23:21:39 +0300
Subject: [R-SIG-Finance] GARCH fitted parametric distributions for copula
	fitting
Message-ID: <CAMO-YyUTrPT39VzOhgSzpkdx42oqPYjZ3Z27FotdXeXwL_C9nA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140512/09f435aa/attachment.pl>

From alexios at 4dscape.com  Mon May 12 22:43:11 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Mon, 12 May 2014 21:43:11 +0100
Subject: [R-SIG-Finance] GARCH fitted parametric distributions for
 copula fitting
In-Reply-To: <CAMO-YyUTrPT39VzOhgSzpkdx42oqPYjZ3Z27FotdXeXwL_C9nA@mail.gmail.com>
References: <CAMO-YyUTrPT39VzOhgSzpkdx42oqPYjZ3Z27FotdXeXwL_C9nA@mail.gmail.com>
Message-ID: <5371325F.3060505@4dscape.com>

Sebastian,

1. It is not the @fit$fitted.values you should use (which BTW you should
extract using the 'fitted' method), but the standardized residuals.

>z = residuals(fit, standardize=TRUE)

2. Once you have these, you should then convert them to U(0,1) by
applying the parametric transformation (IFM). Since you've used the
student distribution:

>pdist("std", z, 0, 1, shape = coef(fit)["shape"])

Alternatively, use the probability integral transformation method (pit):

>pit(fit)

which will return the U(0,1) in one step.


It is the U(0,1) values that you pass to the copula.

The copula-GARCH with student and normal margins are already available
in the rmgarch package whose functions (source) or documentation you may
want to consult to see the steps.

Regards,

Alexios



On 12/05/2014 21:21, Sebastian Ivanciu wrote:
> Hello,
> 
> I would greatly appreciate any insights into the problem described below,
> regarding using the data obtained from applying the functions of the
> 'rugarch' package into those from the 'copula' package.
> 
> I am endeavouring an investigation of dependencies between variables (i.e.
> stock quotes, exchange rates etc.) using copula functions. I first model
> each of my variables as an ARMA-GARCH process (or EGARCH/GJR to account for
> asymmetries) and then use these models in order to determine the
> best-fitting copula.
> 
> Take for example the case of stock quotes. After transforming them to log
> returns ( using diff(log(stockData)) ), and investigating their correlation
> with Kendall's thau and Spearman's rho, I fit an ARMA-GARCH model to each
> variable (resulting in the so-called margin functions):
> 
> ## Choose conditional mean model for each variable i in the retStock xts
> object
> autoarfima(data = retStock[,i], ar.max = 3, ma.max = 3, criterion = "AIC",
> method = "full", distr = "std")
> 
> ## Choose conditional variance model by comparing AICs for all combinations
> of GARCH orders limited to 3, with the ARMA(p,q) mean model selected above
> for (i in 1:3){
>       for (j in 1:3){
> 
> spec <- ugarchspec(variance.model=list(model="sGARCH", garchOrder =
> c(i,j)), mean.model=list(armaOrder=c(p,q), distribution.model = "std")
> 
> fit <- ugarchfit(spec = spec, data = retStock[,n])
> 
> # record AIC for overall comparison after exiting the loop
> }
> 
> }
> 
> Keeping the uGARCHfit object with the best-fitting model, I move on to the
> bivariate copulas. For completing the "Inference Functions for Margins"
> method, I specifically need to input the observations from the *fitted
> parametric marginal distribution functions*, for which I use the
> *@fit$fitted.values* of each uGARCHfit object.
> 
> However, the fitted values of the two models are, for some variables,
> negatively correlated (as indicated by Kendall's tau and Spearman's rho),
> whereas the original observations were positively correlated, leading to
> the copula fitting breaking down (for Gumbel and Clayton copulas, but I
> won't go into copula details, as my question only concerns the output data
> from the 'rugarch' package).
> 
> My overall question is, considering my approach and the need for inputting
> fitted parametric marginal distribution functions, are the fitted values
> from the uGARCHfit objects the right input data to be taking further into
> the copula functions? Why are the fitted values negatively correlated, when
> the originals were positively correlated?
> 
> I am running everything in RStudio 0.98.501 with R 3.0.2 on Windows 8.1. If
> any further information is needed regarding my system specs or other
> implementation details, let me know and I'll provide them as soon as
> possible.
> 
> Thank you very much for your assistance,
> Sebastian
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 
>


From albert.darenberg at gmail.com  Tue May 13 01:01:32 2014
From: albert.darenberg at gmail.com (Albert Darenberg)
Date: Tue, 13 May 2014 01:01:32 +0200
Subject: [R-SIG-Finance] fPortfolio and minimum variance portfolio
Message-ID: <CACu79pZGCOC2mQRCTbHPd5rvjGDn_7kqAQmKoSKM2b2in6KtXA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140513/e27d3149/attachment.pl>

From weihanliu2002 at yahoo.com  Tue May 13 05:07:29 2014
From: weihanliu2002 at yahoo.com (Wei-han Liu)
Date: Mon, 12 May 2014 20:07:29 -0700 (PDT)
Subject: [R-SIG-Finance] (no subject)
Message-ID: <1399950449.51365.YahooMailNeo@web163802.mail.gq1.yahoo.com>

Dear R users:

I have encountered a problem on R package GeneralizedHyperbolic. It fails to integrate for the lower tail area but I do not know how to solve it. Listed below are my coding and the error message:

require(GeneralizedHyperbolic)
return = read.csv("d://UK.R.csv",blank.lines.skip=TRUE,stringsAsFactors=FALSE)
# return <- apply(series, function(x) diff(log(x)))
UK= as.numeric(return[,2])

UK.R=diff(log(na.omit(UK)))

period=50 # moving-window length
n=length(UK.R)
VaR05.UK.qghyp <- numeric(n-period)
for (p in 1:(n-period))
{
? temp = UK.R[p:(period+p)]
?? probabilities6 <- 0.05
? VaR0001.UK.qghyp[p]<- qhyperb(probabilities6,param =c(hyperbFit(temp)[1]$param[1],hyperbFit(temp)[1]$param[2],hyperbFit(temp)[1]$param[3],hyperbFit(temp)[1]$param[4]),lower.tail = TRUE, method = c("spline"),subdivisions = 50)

?}?

ERROR message:?Error in integrate(dghypInt, q[i], Inf, subdivisions = subdivisions, rel.tol = intTol, ?:?
? the integral is probably divergent

If I change the method to integrate, it shows the error message below:
Error in uniroot(zeroFun, interval = c(mode, xHigh), ...) :?
? f() values at end points not of opposite sign
In addition: Warning messages:
1: In optimize(f = modeFun, interval = range, maximum = TRUE) :
? NA/Inf replaced by maximum positive value
2: In optimize(f = modeFun, interval = range, maximum = TRUE) :
? NA/Inf replaced by maximum positive value
3: In optimize(f = modeFun, interval = range, maximum = TRUE) :
? NA/Inf replaced by maximum positive value
4: In optimize(f = modeFun, interval = range, maximum = TRUE) :
? NA/Inf replaced by maximum positive value
5: In optimize(f = modeFun, interval = range, maximum = TRUE) :
? NA/Inf replaced by maximum positive value
6: In optimize(f = modeFun, interval = range, maximum = TRUE) :
? NA/Inf replaced by maximum positive value

Does any people can help solve this problem?

Best regards,

Weihan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140512/975cdae6/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: UK.R.csv
Type: application/vnd.ms-excel
Size: 196752 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140512/975cdae6/attachment.xlb>

From alexios at 4dscape.com  Tue May 13 09:23:00 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Tue, 13 May 2014 08:23:00 +0100
Subject: [R-SIG-Finance] (no subject)
In-Reply-To: <1399950449.51365.YahooMailNeo@web163802.mail.gq1.yahoo.com>
References: <1399950449.51365.YahooMailNeo@web163802.mail.gq1.yahoo.com>
Message-ID: <5371C854.8030304@4dscape.com>

The problem is in the scaling of the dataset and the optimizer used.

Try either:

>temp = UK.R[p:(period+p)]*100

and/or

>tmp = hyperbFit(temp, method="nlminb")

Also, don't have the hyperbFit inside the qhyperb function (you are
estimating the same parameters 4 times!). Instead use something like:

>tmp = hyperbFit(temp, method="nlminb")[1]$param
>VaR05.UK.qghyp2[p] = qhyperb(probabilities6,param = tmp)

Regards,

Alexios

On 13/05/2014 04:07, Wei-han Liu wrote:
> Dear R users:
> 
> I have encountered a problem on R package GeneralizedHyperbolic. It
> fails to integrate for the lower tail area but I do not know how to
> solve it. Listed below are my coding and the error message:
> 
> require(GeneralizedHyperbolic)
> return =
> read.csv("d://UK.R.csv",blank.lines.skip=TRUE,stringsAsFactors=FALSE)
> # return <- apply(series, function(x) diff(log(x)))
> UK= as.numeric(return[,2])
> UK.R=diff(log(na.omit(UK)))
> period=50 # moving-window length
> n=length(UK.R)
> VaR05.UK.qghyp <- numeric(n-period)
> for (p in 1:(n-period))
> {
>   temp = UK.R[p:(period+p)]
>    probabilities6 <- 0.05
>   VaR0001.UK.qghyp[p]<- qhyperb(probabilities6,param
> =c(hyperbFit(temp)[1]$param[1],hyperbFit(temp)[1]$param[2],hyperbFit(temp)[1]$param[3],hyperbFit(temp)[1]$param[4]),lower.tail
> = TRUE, method = c("spline"),subdivisions = 50)
>  } 
> 
> ERROR message: Error in integrate(dghypInt, q[i], Inf, subdivisions =
> subdivisions, rel.tol = intTol,  : 
>   the integral is probably divergent
> 
> If I change the method to integrate, it shows the error message below:
> Error in uniroot(zeroFun, interval = c(mode, xHigh), ...) : 
>   f() values at end points not of opposite sign
> In addition: Warning messages:
> 1: In optimize(f = modeFun, interval = range, maximum = TRUE) :
>   NA/Inf replaced by maximum positive value
> 2: In optimize(f = modeFun, interval = range, maximum = TRUE) :
>   NA/Inf replaced by maximum positive value
> 3: In optimize(f = modeFun, interval = range, maximum = TRUE) :
>   NA/Inf replaced by maximum positive value
> 4: In optimize(f = modeFun, interval = range, maximum = TRUE) :
>   NA/Inf replaced by maximum positive value
> 5: In optimize(f = modeFun, interval = range, maximum = TRUE) :
>   NA/Inf replaced by maximum positive value
> 6: In optimize(f = modeFun, interval = range, maximum = TRUE) :
>   NA/Inf replaced by maximum positive value
> 
> Does any people can help solve this problem?
> 
> Best regards,
> 
> Weihan
> 
> 
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From a.chandhial at btinternet.com  Tue May 13 10:19:55 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Tue, 13 May 2014 09:19:55 +0100 (BST)
Subject: [R-SIG-Finance] fPortfolio and minimum variance portfolio
In-Reply-To: <CACu79pZGCOC2mQRCTbHPd5rvjGDn_7kqAQmKoSKM2b2in6KtXA@mail.gmail.com>
References: <CACu79pZGCOC2mQRCTbHPd5rvjGDn_7kqAQmKoSKM2b2in6KtXA@mail.gmail.com>
Message-ID: <1399969195.87488.YahooMailNeo@web186002.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140513/7c68dbc5/attachment.pl>

From katherine_gobin at yahoo.com  Wed May 14 11:31:44 2014
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Wed, 14 May 2014 17:31:44 +0800 (SGT)
Subject: [R-SIG-Finance] Excel price function
Message-ID: <1400059904.38733.YahooMailNeo@web193305.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140514/278ea626/attachment.pl>

From albert.darenberg at gmail.com  Wed May 14 13:36:32 2014
From: albert.darenberg at gmail.com (Albert Darenberg)
Date: Wed, 14 May 2014 13:36:32 +0200
Subject: [R-SIG-Finance] fPortfolio and Matlab: Different results for the
	tagency portfolio
Message-ID: <CACu79pYzQGi_kVvAAx87EXkYYCgm_giLy9akyHEcLjD1dZtAwA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140514/d8f2619e/attachment.pl>

From albert.darenberg at gmail.com  Wed May 14 14:54:48 2014
From: albert.darenberg at gmail.com (Albert Darenberg)
Date: Wed, 14 May 2014 14:54:48 +0200
Subject: [R-SIG-Finance] fPortfolio and Matlab: Different results for
	the tagency portfolio
Message-ID: <CACu79pb7fkiHv57qWbEtcELv8_KBqjfukvSHYUwp+KoX_RZnKw@mail.gmail.com>

The problem seems to be that the tangency portfolio that fPortfolio
calculates is not correct. It cuts through the efficient frontier,
much like described here
http://r.789695.n4.nabble.com/fPortfolio-and-tangency-portfolio-for-two-assets-td4677700.html
Is there a general problem with tangencyPortfolio() in fPortfolio?


On Wed, May 14, 2014 at 1:36 PM, Albert Darenberg
<albert.darenberg at gmail.com> wrote:
>
> I'm trying to recreate the Matlab 2013 result for the tagency portfolio in fPortfolio. However, the resulting weights are not the same. I use the standard parameters in both Matlab and fPortfolio. The Markowitz efficient frontier is correct in both software suites. To validate this, I compared the minimum variance portfolio and a few random portfolios with a given variance on the efficient frontier.
> In Matlab I use "[PortRisk, PortReturn, PortWts] = portopt(ExpReturn, ExpCovariance, 50)" to calculate the efficient frontier and "portalloc (PortRisk, PortReturn, PortWts, RisklessRate, BorrowRate, RiskAversion)" for the tangency portfolio.
> Is there a catch that I'm missing when recreating results with Matlab and fPortfolio?
>


From albert.darenberg at gmail.com  Wed May 14 15:12:13 2014
From: albert.darenberg at gmail.com (allbert.darenberg)
Date: Wed, 14 May 2014 06:12:13 -0700 (PDT)
Subject: [R-SIG-Finance] fPortfolio and tangency portfolio for two assets
In-Reply-To: <1381061210125-4677700.post@n4.nabble.com>
References: <1381061210125-4677700.post@n4.nabble.com>
Message-ID: <1400073133552-4690524.post@n4.nabble.com>

Have you been able to find the reason for the cutting through problem? Have
you tried conforming your results with other Software, e.g. Matlab as
described here?
http://www.mathworks.com/help/finance/portfolio-selection-and-risk-aversion.html



--
View this message in context: http://r.789695.n4.nabble.com/fPortfolio-and-tangency-portfolio-for-two-assets-tp4677700p4690524.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From weihanliu2002 at yahoo.com  Thu May 15 12:48:23 2014
From: weihanliu2002 at yahoo.com (Wei-han Liu)
Date: Thu, 15 May 2014 03:48:23 -0700 (PDT)
Subject: [R-SIG-Finance] (no subject)
Message-ID: <1400150903.2984.YahooMailNeo@web163805.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140515/4da41471/attachment.pl>

From bogaso.christofer at gmail.com  Thu May 15 20:32:03 2014
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Fri, 16 May 2014 00:17:03 +0545
Subject: [R-SIG-Finance] A question on Time series analysis
Message-ID: <CA+dpOJnW6sziE=j41aerRX+KJVoQsLAVhcSuhfGj9sgkX1Gv6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140516/0a37c4fe/attachment.pl>

From dominykasgrigonis at gmail.com  Thu May 15 23:23:26 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Thu, 15 May 2014 22:23:26 +0100
Subject: [R-SIG-Finance] A question on Time series analysis
In-Reply-To: <CA+dpOJnW6sziE=j41aerRX+KJVoQsLAVhcSuhfGj9sgkX1Gv6Q@mail.gmail.com>
References: <CA+dpOJnW6sziE=j41aerRX+KJVoQsLAVhcSuhfGj9sgkX1Gv6Q@mail.gmail.com>
Message-ID: <1F88F31A9D8744CB8E001E5DAF4EEA21@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140515/592526a9/attachment.pl>

From dominykasgrigonis at gmail.com  Thu May 15 23:32:05 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Thu, 15 May 2014 22:32:05 +0100
Subject: [R-SIG-Finance] A question on Time series analysis
In-Reply-To: <1F88F31A9D8744CB8E001E5DAF4EEA21@gmail.com>
References: <CA+dpOJnW6sziE=j41aerRX+KJVoQsLAVhcSuhfGj9sgkX1Gv6Q@mail.gmail.com>
	<1F88F31A9D8744CB8E001E5DAF4EEA21@gmail.com>
Message-ID: <7A281AB466624F1FAE4A0D5C45DF475A@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140515/52380750/attachment.pl>

From weihanliu2002 at yahoo.com  Fri May 16 03:18:21 2014
From: weihanliu2002 at yahoo.com (Wei-han Liu)
Date: Thu, 15 May 2014 18:18:21 -0700 (PDT)
Subject: [R-SIG-Finance] generalized beta G distribution
Message-ID: <1400203101.76120.YahooMailNeo@web163802.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140515/9748f796/attachment.pl>

From jzmoser at gmail.com  Fri May 16 11:15:13 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Fri, 16 May 2014 11:15:13 +0200
Subject: [R-SIG-Finance] change-point detection in highly dependent time
	series
Message-ID: <5375D721.3050201@googlemail.com>

Dear all,

in the context of a scenario analysis framework I manually selected some 
quiet and some stressful periods in the last 25 years of DAX returns. 
Now I wish to confirm this choices by means of a change-point detection 
test in R. The test ideally should pick changes in the conditional mean, 
more importantly in the conditional variance and covariance structure.

The test should be able to handle highly-dependent time series. So tests 
that assume e.g. structural breaks in iid gaussian noise or assume 
independence between the breaks in another way are not the right thing 
(chow test etc.). I've already tried to apply tests that assume 
independence to the standardized returns (after fitting a GARCH model 
and extracting the volatility estimates) as the standardized returns can 
be considered close to iid. But this approach didn't seem to work well 
(package 'changepoint', test 'segneigh.var.css').  The results seem 
intuitive when this test is applied to the rough returns series. But 
this is clearly a violation of the independence assumption.

I further tried the wavelet test for covariance stationarity (test 
'hwtos2' in the 'locits' package) but it is much too sensitive (e.g. it 
rejects covariance stationarity in a simulated Gaussian GARCH(1,1) ). 
Also, the test (and R syntax) that comes with the paper of Fryzlewicz 
(2014) "Multiple-change-point detection for auto-regressive conditional 
heteroscedastic processe" has been applied to the returns series, but 
I'm not quite satisfied with the results.

There are many more change-point detection packages and tests in R that 
I have considered. But so far none seems to be appropriate for financial 
returns and gives results that are interpretable in the context of 
knowledge of crisis periods and visual examination of the series.

Is there any test for change-points in highly-dependent data (such as 
financial returns) that someone could recommend from his own experience? 
I'd be more that thankful for any advice!

Kind regards, Johannes


From a.chandhial at btinternet.com  Fri May 16 13:53:58 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Fri, 16 May 2014 12:53:58 +0100 (BST)
Subject: [R-SIG-Finance] stochastic oscillator OBOS - intraday data &
	optimization TIMEFILTER & TIMESPANS
Message-ID: <1400241238.34408.YahooMailNeo@web186002.mail.ir2.yahoo.com>



Hi Ilya,


Have returned with our stochastic oscillator OBOS strategy.

Where we were last time was optimizing nSlowD?& the OBOS?thresholds. I will?guess that everything was correct there, inequalities etc, if not let me know! Therefore I'll carry-on with including?a timefilter to our strategy and optimizing timespans (various timefilters). As this is for demo and given only a few days of intraday data the values for nSlowD and OBOS thresholds can remain at 5, 80, & 20, respectively (ordinarily?this'll be on the optimized values).?I have also?uncommented the short-side as?we have an fx rate?GBPUSD, not a stock.


Attached:
(1)?Vanilla +?inclusion of a timefilter, chosen arbitrarily as 'T07:00/T20:00'. This appears to be filtering correctly.
(2)??Various timefilters i.e. timespans for optimization. Although the program runs,?it does not appear to be optimizing. I am having problems with add.distribution and apply.paramset functions. Please help!
?


Amarjit?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140516/07b2c5b1/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_vanilla_TIMEFILTER.R
Type: application/octet-stream
Size: 7604 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140516/07b2c5b1/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_vanilla_TIMESPAN.R
Type: application/octet-stream
Size: 3735 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140516/07b2c5b1/attachment-0001.obj>

From a.chandhial at btinternet.com  Fri May 16 14:50:08 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Fri, 16 May 2014 13:50:08 +0100 (BST)
Subject: [R-SIG-Finance] Fw: stochastic oscillator OBOS - intraday data &
	optimization TIMEFILTER & TIMESPANS
In-Reply-To: <1400241238.34408.YahooMailNeo@web186002.mail.ir2.yahoo.com>
References: <1400241238.34408.YahooMailNeo@web186002.mail.ir2.yahoo.com>
Message-ID: <1400244608.96988.YahooMailNeo@web186005.mail.ir2.yahoo.com>



Opps, forgot the .RData strategy file for the TIMESPAN program.
?
?
Amarjit
?
?
?
----- Forwarded Message -----
>From: amarjit chandhial <a.chandhial at btinternet.com>
>To: "ilya.kipnis at gmail.com" <ilya.kipnis at gmail.com>; "r-sig-finance at r-project.org" <r-sig-finance at r-project.org> 
>Sent: Friday, 16 May 2014, 12:53
>Subject: [R-SIG-Finance] stochastic oscillator OBOS - intraday data & optimization TIMEFILTER & TIMESPANS
>
>
>
>
>
>Hi Ilya,
>
>
>Have returned with our stochastic oscillator OBOS strategy.
>
>Where we were last time was optimizing nSlowD?& the OBOS?thresholds. I will?guess that everything was correct there, inequalities etc, if not let me know! Therefore I'll carry-on with including?a timefilter to our strategy and optimizing timespans (various timefilters). As this is for demo and given only a few days of intraday data the values for nSlowD and OBOS thresholds can remain at 5, 80, & 20, respectively (ordinarily?this'll be on the optimized values).?I have also?uncommented the short-side as?we have an fx rate?GBPUSD, not a stock.
>
>
>Attached:
>(1)?Vanilla +?inclusion of a timefilter, chosen arbitrarily as 'T07:00/T20:00'. This appears to be filtering correctly.
>(2)??Various timefilters i.e. timespans for optimization. Although the program runs,?it does not appear to be optimizing. I am having problems with add.distribution and apply.paramset functions. Please help!
>?
>
>
>Amarjit?
>_______________________________________________
>R-SIG-Finance at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>-- Subscriber-posting only. If you want to post, subscribe first.
>-- Also note that this is not the r-help list where general R questions should go.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140516/77224e6a/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_vanilla_TIMEFILTER.R
Type: application/octet-stream
Size: 7604 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140516/77224e6a/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_vanilla_TIMESPAN.R
Type: application/octet-stream
Size: 3735 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140516/77224e6a/attachment-0001.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: GBPUSDstoch.RData
Type: application/x-gzip-compressed
Size: 25945 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140516/77224e6a/attachment.bin>

From censix0 at gmail.com  Fri May 16 19:12:40 2014
From: censix0 at gmail.com (cen six)
Date: Fri, 16 May 2014 19:12:40 +0200
Subject: [R-SIG-Finance] change-point detection in highly dependent time
	series
In-Reply-To: <5375D721.3050201@googlemail.com>
References: <5375D721.3050201@googlemail.com>
Message-ID: <CAOGDGTawsm2bVUHPgb0Qv-c8NW+bmg=CBcMZdfKPWHG9endLzw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140516/71314872/attachment.pl>

From jzmoser at gmail.com  Fri May 16 20:15:17 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Fri, 16 May 2014 20:15:17 +0200
Subject: [R-SIG-Finance] change-point detection in highly dependent time
 series
In-Reply-To: <CAOGDGTawsm2bVUHPgb0Qv-c8NW+bmg=CBcMZdfKPWHG9endLzw@mail.gmail.com>
References: <5375D721.3050201@googlemail.com>
	<CAOGDGTawsm2bVUHPgb0Qv-c8NW+bmg=CBcMZdfKPWHG9endLzw@mail.gmail.com>
Message-ID: <537655B5.6060001@googlemail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140516/4b9d171b/attachment.pl>

From a.chandhial at btinternet.com  Sun May 18 10:59:40 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Sun, 18 May 2014 09:59:40 +0100 (BST)
Subject: [R-SIG-Finance] Fw: Fw: stochastic oscillator OBOS - intraday data
	& optimization TIMEFILTER & TIMESPANS
In-Reply-To: <1400244608.96988.YahooMailNeo@web186005.mail.ir2.yahoo.com>
References: <1400241238.34408.YahooMailNeo@web186002.mail.ir2.yahoo.com>
	<1400244608.96988.YahooMailNeo@web186005.mail.ir2.yahoo.com> 
Message-ID: <1400403580.63886.YahooMailNeo@web186001.mail.ir2.yahoo.com>

??
Via? the TIMEFILTER program,?tradestats e.g.?Gross.Profits are:
?
T07:00/T20:00????Gross.Profits????1571.112
T08:00/T21:00????Gross.Profits?????601.9379?
T09:00/T22:00????Gross.Profits???? 601.9379?
T10:00/T23:00????Gross.Profits???? 783.9936
?
?
?

I have altered add.distribution in the TIMESPAN program
?
?add.distribution(strategy.st,
????????????????????????paramset.label = 'Timespan',
????????????????????????component.type = 'indicator',?????# one of c('indicator', 'signal', 'order', 'enter', 'exit', 'chain')? --- have tried all of these!
????????????????????????component.label = 'timespan',
????????????????????????variable = list(n = .timespans),
????????????????????????label = 'TIMESPAN')

?


However, the tradestats?remain only for T07:00/T20:00.
?
?
Amarjit
?
?

?


----- Forwarded Message -----
>From: amarjit chandhial <a.chandhial at btinternet.com>
>To: ""ilya.kipnis at gmail.com"" <ilya.kipnis at gmail.com>; ""r-sig-finance at r-project.org"" <r-sig-finance at r-project.org> 
>Sent: Friday, 16 May 2014, 13:50
>Subject: [R-SIG-Finance] Fw: stochastic oscillator OBOS - intraday data & optimization TIMEFILTER & TIMESPANS
>
>
>
>
>
>Opps, forgot the .RData strategy file for the TIMESPAN program.
>
>
>Amarjit
>
>
>
>----- Forwarded Message -----
>>From: amarjit chandhial <a.chandhial at btinternet.com>
>>To: "ilya.kipnis at gmail.com" <ilya.kipnis at gmail.com>; "r-sig-finance at r-project.org" <r-sig-finance at r-project.org> 
>>Sent: Friday, 16 May 2014, 12:53
>>Subject: [R-SIG-Finance] stochastic oscillator OBOS - intraday data & optimization TIMEFILTER & TIMESPANS
>>
>>
>>
>>
>>
>>Hi Ilya,
>>
>>
>>Have returned with our stochastic oscillator OBOS strategy.
>>
>>Where we were last time was optimizing nSlowD?& the OBOS?thresholds. I will?guess that everything was correct there, inequalities etc, if not let me know! Therefore I'll carry-on with including?a timefilter to our strategy and optimizing timespans (various timefilters). As this is for demo and given only a few days of intraday data the values for nSlowD and OBOS thresholds can remain at 5, 80, & 20, respectively (ordinarily?this'll be on the optimized values).?I have also?uncommented the short-side as?we have an fx rate?GBPUSD, not a stock.
>>
>>
>>Attached:
>>(1)?Vanilla +?inclusion of a timefilter, chosen arbitrarily as 'T07:00/T20:00'. This appears to be filtering correctly.
>>(2)??Various timefilters i.e. timespans for optimization. Although the program runs,?it does not appear to be optimizing. I am having problems with add.distribution and apply.paramset functions. Please help!
>>?
>>
>>
>>Amarjit?
>>_______________________________________________
>>R-SIG-Finance at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>-- Subscriber-posting only. If you want to post, subscribe first.
>>-- Also note that this is not the r-help list where general R questions should go.
>>
>>
>_______________________________________________
>R-SIG-Finance at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>-- Subscriber-posting only. If you want to post, subscribe first.
>-- Also note that this is not the r-help list where general R questions should go.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140518/fd67a474/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_vanilla_TIMEFILTER.R
Type: application/octet-stream
Size: 7604 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140518/fd67a474/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_vanilla_TIMESPAN.R
Type: application/octet-stream
Size: 3735 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140518/fd67a474/attachment-0001.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: GBPUSDstoch.RData
Type: application/x-gzip-compressed
Size: 25945 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140518/fd67a474/attachment.bin>

From josh.m.ulrich at gmail.com  Mon May 19 11:54:03 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 19 May 2014 04:54:03 -0500
Subject: [R-SIG-Finance] quantstrat - object 'prefer' not found?
In-Reply-To: <1399542538728-4690181.post@n4.nabble.com>
References: <1399542538728-4690181.post@n4.nabble.com>
Message-ID: <CAPPM_gTdCD1+mz0qZtktD-HGYw2DQ_B+7VPiDe7bb5tL7pVt8g@mail.gmail.com>

On Thu, May 8, 2014 at 4:48 AM, rPaulS <rpaulseymour at gmail.com> wrote:
> hello,
> have been trying to get a handle on quantstrat by editing the demo scripts,
> and seem to be stuck. basically, i am trying to use data where there is only
> a close value (so, not OHLC or BBO). i did a search on this list, and found
> an  older post
> <http://r.789695.n4.nabble.com/quantstrat-and-nonstandard-column-names-in-the-price-series-td3297855.html>
> that had a similar situation and error:
>
>> Error in getPrice(mktdata, prefer = prefer) : object 'prefer' not found
>
FWIW, this is the same error, but a different underlying cause.

> there was an example script in that thread that i have been mimicking, and
> it seems like my prefer statements were not working. it eventually dawned on
> me to try to run the original script, and it also returns the same error.
> here is a direct link to the script to test or try -  vladimir.R
> <http://r.789695.n4.nabble.com/attachment/3298067/0/vladimir.R>   - i am
> guessing whatever is wrong with that script, i am also doing wrong. if
> anyone has any insight, please let me know. i've pretty much exhausted all
> ideas to try to figure out what it is. thank you.
>
Thanks for the report.  Sorry for my delay in responding; I've been
very busy helping organize the R/Finance conference that took place
this past weekend.

This is a bug I introduced when I moved the mktdata price subsetting
outside of the main loop in order to improve performance.  I must not
have tested it on univariate series at the time.  It's now fixed in
r1611.  Apologies for the trouble.

> FYI i am using R version 3.1.0 (2014-04-10) on x86_64-apple-darwin13.1.0
> (64-bit), and have installed the latest related packages - including
> quantstrat_0.8.2, blotter_0.8.19 and FinancialInstrument_1.1.9.
>
Thanks for including this info.

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From padarn at gmail.com  Tue May 20 00:10:52 2014
From: padarn at gmail.com (PoddyOne)
Date: Mon, 19 May 2014 15:10:52 -0700 (PDT)
Subject: [R-SIG-Finance] Changing (seasonal) conditional distribution in a
	fGarch model
Message-ID: <1400537452329-4690850.post@n4.nabble.com>

Hi there, 

I'm working with a time series that has a clear seasonal component in it's
conditional distribution. Not only does the variance increase at certain
parts of the seasonal cycle, but also the distribution becomes skewed.

I would like to fit an fGarch model to this time series, but with a
conditional distribution which depends on a dummy variable. I was wondering
if anyone knew if this was possible in fGarch or any of the similar
packages?

/(As an aside, I recognise that this may not be the easiest way to go about
modelling this. For a little more detail: This is a time series with a
strong diurnal cycle in it. The series has been 'detrended' and is
stationary at least under the usual metrics. However, still clearly during
the midnight hours, the residuals are strongly positively skewed. I have
tried transforming the series, but the large disparity in both the skew and
scale see to prohibit this working nicely.

Any other suggestions are welcome)/



--
View this message in context: http://r.789695.n4.nabble.com/Changing-seasonal-conditional-distribution-in-a-fGarch-model-tp4690850.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From alexios at 4dscape.com  Tue May 20 00:34:31 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Mon, 19 May 2014 23:34:31 +0100
Subject: [R-SIG-Finance] Changing (seasonal) conditional distribution in
	a fGarch model
In-Reply-To: <1400537452329-4690850.post@n4.nabble.com>
References: <1400537452329-4690850.post@n4.nabble.com>
Message-ID: <4A68E0AD-6B2F-4B31-9D6E-7487F38C8DCA@4dscape.com>

Hi,

Try reading this:
http://www.unstarched.net/2013/03/20/high-frequency-garch-the-multiplicative-component-garch-mcsgarch-model/
You?ll have to switch to using rugarch, but hopefully it should not be too much of a sacrifice...

Alexios

On 19 May 2014, at 23:10, PoddyOne <padarn at gmail.com> wrote:

> Hi there, 
> 
> I'm working with a time series that has a clear seasonal component in it's
> conditional distribution. Not only does the variance increase at certain
> parts of the seasonal cycle, but also the distribution becomes skewed.
> 
> I would like to fit an fGarch model to this time series, but with a
> conditional distribution which depends on a dummy variable. I was wondering
> if anyone knew if this was possible in fGarch or any of the similar
> packages?
> 
> /(As an aside, I recognise that this may not be the easiest way to go about
> modelling this. For a little more detail: This is a time series with a
> strong diurnal cycle in it. The series has been 'detrended' and is
> stationary at least under the usual metrics. However, still clearly during
> the midnight hours, the residuals are strongly positively skewed. I have
> tried transforming the series, but the large disparity in both the skew and
> scale see to prohibit this working nicely.
> 
> Any other suggestions are welcome)/
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Changing-seasonal-conditional-distribution-in-a-fGarch-model-tp4690850.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 


From padarn at gmail.com  Tue May 20 02:17:15 2014
From: padarn at gmail.com (PoddyOne)
Date: Mon, 19 May 2014 17:17:15 -0700 (PDT)
Subject: [R-SIG-Finance] Changing (seasonal) conditional distribution in
	a fGarch model
In-Reply-To: <4A68E0AD-6B2F-4B31-9D6E-7487F38C8DCA@4dscape.com>
References: <1400537452329-4690850.post@n4.nabble.com>
	<4A68E0AD-6B2F-4B31-9D6E-7487F38C8DCA@4dscape.com>
Message-ID: <1400545035633-4690853.post@n4.nabble.com>

Great! Thanks for that, this looks like pretty much exactly what I am looking
for.



--
View this message in context: http://r.789695.n4.nabble.com/Changing-seasonal-conditional-distribution-in-a-fGarch-model-tp4690850p4690853.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From padarn at gmail.com  Tue May 20 03:36:38 2014
From: padarn at gmail.com (PoddyOne)
Date: Mon, 19 May 2014 18:36:38 -0700 (PDT)
Subject: [R-SIG-Finance] Changing (seasonal) conditional distribution in
	a fGarch model
In-Reply-To: <1400545035633-4690853.post@n4.nabble.com>
References: <1400537452329-4690850.post@n4.nabble.com>
	<4A68E0AD-6B2F-4B31-9D6E-7487F38C8DCA@4dscape.com>
	<1400545035633-4690853.post@n4.nabble.com>
Message-ID: <1400549798601-4690858.post@n4.nabble.com>

Hi Alexios 

After having (somewhat) digested the link you sent me to the seasonal
variance models in your package, I'm under the impression that the
conditional distribution is still restricted to being normally distributed
(with varying variance)? I was hoping to use a skewed-normal as the
conditional distribution at certain times of day.

Another thing is that at the bottom of the page you say:

" Another possible direction for expansion would be to treat the diurnal
effect separately for each day of the week."

This is an interesting idea, and is something I thought about, but was a
little uneasy about the ideas that popped into my head about how to go about
this. For example, one simple approach might be (at least in my case) to
transform each hour of the diurnal cycle separately to try and match the
conditional distributions as closely as possible. However, this seems like
it would leave to an overly complicated model.

Cheers



--
View this message in context: http://r.789695.n4.nabble.com/Changing-seasonal-conditional-distribution-in-a-fGarch-model-tp4690850p4690858.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From alexios at 4dscape.com  Tue May 20 10:18:52 2014
From: alexios at 4dscape.com (Alexios Ghalanos)
Date: Tue, 20 May 2014 03:18:52 -0500
Subject: [R-SIG-Finance] Changing (seasonal) conditional distribution in
	a fGarch model
In-Reply-To: <1400549798601-4690858.post@n4.nabble.com>
References: <1400537452329-4690850.post@n4.nabble.com>
	<4A68E0AD-6B2F-4B31-9D6E-7487F38C8DCA@4dscape.com>
	<1400545035633-4690853.post@n4.nabble.com>
	<1400549798601-4690858.post@n4.nabble.com>
Message-ID: <8531EA42-C8AD-4F0A-810B-A551E6BDA916@4dscape.com>

Hi,

Yes, you have a wide choice of skewed and shaped distributions which are covered in detail in the vignette.

As to the expansion, I'm a little busy right now to look at this but feel free to contribute an enhancement if you are able to.

Best,

Alexios

> On 19 May 2014, at 20:36, PoddyOne <padarn at gmail.com> wrote:
> 
> Hi Alexios 
> 
> After having (somewhat) digested the link you sent me to the seasonal
> variance models in your package, I'm under the impression that the
> conditional distribution is still restricted to being normally distributed
> (with varying variance)? I was hoping to use a skewed-normal as the
> conditional distribution at certain times of day.
> 
> Another thing is that at the bottom of the page you say:
> 
> " Another possible direction for expansion would be to treat the diurnal
> effect separately for each day of the week."
> 
> This is an interesting idea, and is something I thought about, but was a
> little uneasy about the ideas that popped into my head about how to go about
> this. For example, one simple approach might be (at least in my case) to
> transform each hour of the diurnal cycle separately to try and match the
> conditional distributions as closely as possible. However, this seems like
> it would leave to an overly complicated model.
> 
> Cheers
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Changing-seasonal-conditional-distribution-in-a-fGarch-model-tp4690850p4690858.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 


From a.chandhial at btinternet.com  Tue May 20 15:17:28 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Tue, 20 May 2014 14:17:28 +0100 (BST)
Subject: [R-SIG-Finance] Fw: Fw: Fw: stochastic oscillator OBOS - intraday
	data & optimization TIMEFILTER & TIMESPANS
In-Reply-To: <1400403580.63886.YahooMailNeo@web186001.mail.ir2.yahoo.com>
References: <1400241238.34408.YahooMailNeo@web186002.mail.ir2.yahoo.com>
	<1400244608.96988.YahooMailNeo@web186005.mail.ir2.yahoo.com>
	<1400403580.63886.YahooMailNeo@web186001.mail.ir2.yahoo.com>
Message-ID: <1400591848.53525.YahooMailNeo@web186004.mail.ir2.yahoo.com>

?
?
Am throwing this open to all on the quantstrat team, or others.
?
?
Amarjit
?
?
?
?
?
?
?
?
?
?
?

----- Forwarded Message -----
>From: amarjit chandhial <a.chandhial at btinternet.com>
>To: "ilya.kipnis at gmail.com" <ilya.kipnis at gmail.com>; "r-sig-finance at r-project.org" <r-sig-finance at r-project.org> 
>Sent: Sunday, 18 May 2014, 9:59
>Subject: [R-SIG-Finance] Fw: Fw: stochastic oscillator OBOS - intraday data & optimization TIMEFILTER & TIMESPANS
>
>
>
>??
>Via? the TIMEFILTER program,?tradestats e.g.?Gross.Profits are:
>?
>T07:00/T20:00????Gross.Profits????1571.112
>T08:00/T21:00????Gross.Profits?????601.9379?
>T09:00/T22:00????Gross.Profits???? 601.9379?
>T10:00/T23:00????Gross.Profits???? 783.9936
>?
>?
>?
>
>I have altered add.distribution in the TIMESPAN program
>?
>?add.distribution(strategy.st,
>????????????????????????paramset.label = 'Timespan',
>????????????????????????component.type = 'indicator',?????# one of c('indicator', 'signal', 'order', 'enter', 'exit', 'chain')? --- have tried all of these!
>????????????????????????component.label = 'timespan',
>????????????????????????variable = list(n = .timespans),
>????????????????????????label = 'TIMESPAN')
>
>?
>
>
>However, the tradestats?remain only for T07:00/T20:00.
>?
>?
>Amarjit
>?
>?
>
>?
>
>
>----- Forwarded Message -----
>>From: amarjit chandhial <a.chandhial at btinternet.com>
>>To: ""ilya.kipnis at gmail.com"" <ilya.kipnis at gmail.com>; ""r-sig-finance at r-project.org"" <r-sig-finance at r-project.org> 
>>Sent: Friday, 16 May 2014, 13:50
>>Subject: [R-SIG-Finance] Fw: stochastic oscillator OBOS - intraday data & optimization TIMEFILTER & TIMESPANS
>>
>>
>>
>>
>>
>>Opps, forgot the .RData strategy file for the TIMESPAN program.
>>
>>
>>Amarjit
>>
>>
>>
>>----- Forwarded Message -----
>>>From: amarjit chandhial <a.chandhial at btinternet.com>
>>>To: "ilya.kipnis at gmail.com" <ilya.kipnis at gmail.com>; "r-sig-finance at r-project.org" <r-sig-finance at r-project.org> 
>>>Sent: Friday, 16 May 2014, 12:53
>>>Subject: [R-SIG-Finance] stochastic oscillator OBOS - intraday data & optimization TIMEFILTER & TIMESPANS
>>>
>>>
>>>
>>>
>>>
>>>Hi Ilya,
>>>
>>>
>>>Have returned with our stochastic oscillator OBOS strategy.
>>>
>>>Where we were last time was optimizing nSlowD?& the OBOS?thresholds. I will?guess that everything was correct there, inequalities etc, if not let me know! Therefore I'll carry-on with including?a timefilter to our strategy and optimizing timespans (various timefilters). As this is for demo and given only a few days of intraday data the values for nSlowD and OBOS thresholds can remain at 5, 80, & 20, respectively (ordinarily?this'll be on the optimized values).?I have also?uncommented the short-side as?we have an fx rate?GBPUSD, not a stock.
>>>
>>>
>>>Attached:
>>>(1)?Vanilla +?inclusion of a timefilter, chosen arbitrarily as 'T07:00/T20:00'. This appears to be filtering correctly.
>>>(2)??Various timefilters i.e. timespans for optimization. Although the program runs,?it does not appear to be optimizing. I am having problems with add.distribution and apply.paramset functions. Please help!
>>>?
>>>
>>>
>>>Amarjit?
>>>_______________________________________________
>>>R-SIG-Finance at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>-- Subscriber-posting only. If you want to post, subscribe first.
>>>-- Also note that this is not the r-help list where general R questions should go.
>>>
>>>
>>_______________________________________________
>>R-SIG-Finance at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>-- Subscriber-posting only. If you want to post, subscribe first.
>>-- Also note that this is not the r-help list where general R questions should go.
>>
>>
>_______________________________________________
>R-SIG-Finance at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>-- Subscriber-posting only. If you want to post, subscribe first.
>-- Also note that this is not the r-help list where general R questions should go.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140520/a908d57d/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_vanilla_TIMEFILTER.R
Type: application/octet-stream
Size: 7604 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140520/a908d57d/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_vanilla_TIMESPAN.R
Type: application/octet-stream
Size: 3735 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140520/a908d57d/attachment-0001.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: GBPUSDstoch.RData
Type: application/x-gzip-compressed
Size: 25945 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140520/a908d57d/attachment.bin>

From fdiebold at sas.upenn.edu  Tue May 20 18:50:08 2014
From: fdiebold at sas.upenn.edu (Francis X. Diebold)
Date: Tue, 20 May 2014 12:50:08 -0400
Subject: [R-SIG-Finance] Changing (seasonal) conditional distribution
In-Reply-To: <mailman.3.1400580001.2663.r-sig-finance@r-project.org>
References: <mailman.3.1400580001.2663.r-sig-finance@r-project.org>
Message-ID: <000301cf744b$8f121590$ad3640b0$@upenn.edu>

Just add seasonals as "exogenous" variables in the GARCH equation.  Use of
Fourier terms can achieve significant economy relative to a full set of
dummies.  See http://www.ssc.upenn.edu/~fdiebold/papers/paper53/reprint.pdf.

--

Francis X. Diebold

Paul F. and Warren S. Miller Professor of Economics? 
Professor of Finance and Statistics? 
University of Pennsylvania 
www.ssc.upenn.edu/~fdiebold/     
@FrancisDiebold
No Hesitations: www.fxdiebold.blogspot.com    

  
  


-----Original Message-----
From: r-sig-finance-bounces at r-project.org
[mailto:r-sig-finance-bounces at r-project.org] On Behalf Of
r-sig-finance-request at r-project.org
Sent: Tuesday, May 20, 2014 6:00 AM
To: r-sig-finance at r-project.org
Subject: R-SIG-Finance Digest, Vol 120, Issue 19

Send R-SIG-Finance mailing list submissions to
	r-sig-finance at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-finance
or, via email, send a message with subject or body 'help' to
	r-sig-finance-request at r-project.org

You can reach the person managing the list at
	r-sig-finance-owner at r-project.org

When replying, please edit your Subject line so it is more specific than
"Re: Contents of R-SIG-Finance digest..."


Today's Topics:

   1. Changing (seasonal) conditional distribution in a	fGarch
      model (PoddyOne)
   2. Re: Changing (seasonal) conditional distribution in	a fGarch
      model (alexios ghalanos)
   3. Re: Changing (seasonal) conditional distribution in	a fGarch
      model (PoddyOne)
   4. Re: Changing (seasonal) conditional distribution in	a fGarch
      model (PoddyOne)
   5. Re: Changing (seasonal) conditional distribution in	a fGarch
      model (Alexios Ghalanos)


----------------------------------------------------------------------

Message: 1
Date: Mon, 19 May 2014 15:10:52 -0700 (PDT)
From: PoddyOne <padarn at gmail.com>
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] Changing (seasonal) conditional distribution
	in a	fGarch model
Message-ID: <1400537452329-4690850.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

Hi there, 

I'm working with a time series that has a clear seasonal component in it's
conditional distribution. Not only does the variance increase at certain
parts of the seasonal cycle, but also the distribution becomes skewed.

I would like to fit an fGarch model to this time series, but with a
conditional distribution which depends on a dummy variable. I was wondering
if anyone knew if this was possible in fGarch or any of the similar
packages?

/(As an aside, I recognise that this may not be the easiest way to go about
modelling this. For a little more detail: This is a time series with a
strong diurnal cycle in it. The series has been 'detrended' and is
stationary at least under the usual metrics. However, still clearly during
the midnight hours, the residuals are strongly positively skewed. I have
tried transforming the series, but the large disparity in both the skew and
scale see to prohibit this working nicely.

Any other suggestions are welcome)/



--
View this message in context:
http://r.789695.n4.nabble.com/Changing-seasonal-conditional-distribution-in-
a-fGarch-model-tp4690850.html
Sent from the Rmetrics mailing list archive at Nabble.com.



------------------------------

Message: 2
Date: Mon, 19 May 2014 23:34:31 +0100
From: alexios ghalanos <alexios at 4dscape.com>
To: PoddyOne <padarn at gmail.com>
Cc: r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] Changing (seasonal) conditional
	distribution in	a fGarch model
Message-ID: <4A68E0AD-6B2F-4B31-9D6E-7487F38C8DCA at 4dscape.com>
Content-Type: text/plain; charset=windows-1252

Hi,

Try reading this:
http://www.unstarched.net/2013/03/20/high-frequency-garch-the-multiplicative
-component-garch-mcsgarch-model/
You?ll have to switch to using rugarch, but hopefully it should not be too
much of a sacrifice...

Alexios

On 19 May 2014, at 23:10, PoddyOne <padarn at gmail.com> wrote:

> Hi there,
> 
> I'm working with a time series that has a clear seasonal component in 
> it's conditional distribution. Not only does the variance increase at 
> certain parts of the seasonal cycle, but also the distribution becomes
skewed.
> 
> I would like to fit an fGarch model to this time series, but with a 
> conditional distribution which depends on a dummy variable. I was 
> wondering if anyone knew if this was possible in fGarch or any of the 
> similar packages?
> 
> /(As an aside, I recognise that this may not be the easiest way to go 
> about modelling this. For a little more detail: This is a time series 
> with a strong diurnal cycle in it. The series has been 'detrended' and 
> is stationary at least under the usual metrics. However, still clearly 
> during the midnight hours, the residuals are strongly positively 
> skewed. I have tried transforming the series, but the large disparity 
> in both the skew and scale see to prohibit this working nicely.
> 
> Any other suggestions are welcome)/
> 
> 
> 
> --
> View this message in context: 
> http://r.789695.n4.nabble.com/Changing-seasonal-conditional-distributi
> on-in-a-fGarch-model-tp4690850.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
should go.
> 



------------------------------

Message: 3
Date: Mon, 19 May 2014 17:17:15 -0700 (PDT)
From: PoddyOne <padarn at gmail.com>
To: r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] Changing (seasonal) conditional
	distribution in	a fGarch model
Message-ID: <1400545035633-4690853.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

Great! Thanks for that, this looks like pretty much exactly what I am
looking for.



--
View this message in context:
http://r.789695.n4.nabble.com/Changing-seasonal-conditional-distribution-in-
a-fGarch-model-tp4690850p4690853.html
Sent from the Rmetrics mailing list archive at Nabble.com.



------------------------------

Message: 4
Date: Mon, 19 May 2014 18:36:38 -0700 (PDT)
From: PoddyOne <padarn at gmail.com>
To: r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] Changing (seasonal) conditional
	distribution in	a fGarch model
Message-ID: <1400549798601-4690858.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

Hi Alexios 

After having (somewhat) digested the link you sent me to the seasonal
variance models in your package, I'm under the impression that the
conditional distribution is still restricted to being normally distributed
(with varying variance)? I was hoping to use a skewed-normal as the
conditional distribution at certain times of day.

Another thing is that at the bottom of the page you say:

" Another possible direction for expansion would be to treat the diurnal
effect separately for each day of the week."

This is an interesting idea, and is something I thought about, but was a
little uneasy about the ideas that popped into my head about how to go about
this. For example, one simple approach might be (at least in my case) to
transform each hour of the diurnal cycle separately to try and match the
conditional distributions as closely as possible. However, this seems like
it would leave to an overly complicated model.

Cheers



--
View this message in context:
http://r.789695.n4.nabble.com/Changing-seasonal-conditional-distribution-in-
a-fGarch-model-tp4690850p4690858.html
Sent from the Rmetrics mailing list archive at Nabble.com.



------------------------------

Message: 5
Date: Tue, 20 May 2014 03:18:52 -0500
From: Alexios Ghalanos <alexios at 4dscape.com>
To: PoddyOne <padarn at gmail.com>
Cc: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
Subject: Re: [R-SIG-Finance] Changing (seasonal) conditional
	distribution in	a fGarch model
Message-ID: <8531EA42-C8AD-4F0A-810B-A551E6BDA916 at 4dscape.com>
Content-Type: text/plain;	charset=us-ascii

Hi,

Yes, you have a wide choice of skewed and shaped distributions which are
covered in detail in the vignette.

As to the expansion, I'm a little busy right now to look at this but feel
free to contribute an enhancement if you are able to.

Best,

Alexios

> On 19 May 2014, at 20:36, PoddyOne <padarn at gmail.com> wrote:
> 
> Hi Alexios
> 
> After having (somewhat) digested the link you sent me to the seasonal 
> variance models in your package, I'm under the impression that the 
> conditional distribution is still restricted to being normally 
> distributed (with varying variance)? I was hoping to use a 
> skewed-normal as the conditional distribution at certain times of day.
> 
> Another thing is that at the bottom of the page you say:
> 
> " Another possible direction for expansion would be to treat the 
> diurnal effect separately for each day of the week."
> 
> This is an interesting idea, and is something I thought about, but was 
> a little uneasy about the ideas that popped into my head about how to 
> go about this. For example, one simple approach might be (at least in 
> my case) to transform each hour of the diurnal cycle separately to try 
> and match the conditional distributions as closely as possible. 
> However, this seems like it would leave to an overly complicated model.
> 
> Cheers
> 
> 
> 
> --
> View this message in context: 
> http://r.789695.n4.nabble.com/Changing-seasonal-conditional-distributi
> on-in-a-fGarch-model-tp4690850p4690858.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
should go.
> 



------------------------------

_______________________________________________
R-SIG-Finance mailing list
R-SIG-Finance at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-finance


End of R-SIG-Finance Digest, Vol 120, Issue 19


From oleg.mubarakshin at gmail.com  Wed May 21 23:03:04 2014
From: oleg.mubarakshin at gmail.com (Oleg Mubarakshin)
Date: Thu, 22 May 2014 01:03:04 +0400
Subject: [R-SIG-Finance] R/Finance 2014 photos
Message-ID: <F96549905E14416DB988E05A8F853977@OLEHP>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140522/f6d10298/attachment.pl>

From edd at debian.org  Thu May 22 13:30:41 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 22 May 2014 06:30:41 -0500
Subject: [R-SIG-Finance] R/Finance 2014 slides
Message-ID: <21373.57313.978226.860749@max.nulle.part>


Thanks to everybody who helped make R/Finance 2014 another success!  We had
a very good turnout, excellent presentation and a lot of opportunity to chat.

Particular thanks goes to our sponsors, and the local team at UIC without
whom this would not be possible.

Thanks also to Oleg for posting a short review here (which undercounted registered
attendees by a 100 though) and most excellent pictures, and to Alexios who
posted a kind summary on his blog.

Slides are now up.  A few which were in html are missed as they were done
from local laptops. If you know of any other ones, let me know / send me
copies and I'll add them.

Cheers,  Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From edd at debian.org  Thu May 22 14:00:20 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 22 May 2014 07:00:20 -0500
Subject: [R-SIG-Finance] R/Finance 2014 slides
In-Reply-To: <21373.57313.978226.860749@max.nulle.part>
References: <21373.57313.978226.860749@max.nulle.part>
Message-ID: <21373.59092.646065.16156@max.nulle.part>


On 22 May 2014 at 06:30, Dirk Eddelbuettel wrote:
| 
| Thanks to everybody who helped make R/Finance 2014 another success!  We had
| a very good turnout, excellent presentation and a lot of opportunity to chat.
| 
| Particular thanks goes to our sponsors, and the local team at UIC without
| whom this would not be possible.
| 
| Thanks also to Oleg for posting a short review here (which undercounted registered
| attendees by a 100 though) and most excellent pictures, and to Alexios who
| posted a kind summary on his blog.
| 
| Slides are now up.  A few which were in html are missed as they were done

And there even is a link:   http://www.rinfinance.com/agenda/

Sorry for the omission in the first email.

Dirk

| from local laptops. If you know of any other ones, let me know / send me
| copies and I'll add them.
| 
| Cheers,  Dirk
| 
| -- 
| Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
| 
| _______________________________________________
| R-SIG-Finance at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-sig-finance
| -- Subscriber-posting only. If you want to post, subscribe first.
| -- Also note that this is not the r-help list where general R questions should go.

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From matt at plot.ly  Thu May 22 15:13:03 2014
From: matt at plot.ly (Matt Sundquist)
Date: Thu, 22 May 2014 06:13:03 -0700
Subject: [R-SIG-Finance] Collaborative R, Python, MATLAB,
	and Excel plotting. Also Streaming Graphs.
Message-ID: <CAJfh0Rek_Ycee2bi_=NfEap749TSsHQsK_vCc+a7b5uP5OryEQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140522/c04c5faa/attachment.pl>

From psarran at mesirowfinancial.com  Fri May 23 01:01:50 2014
From: psarran at mesirowfinancial.com (Sarran, Paul)
Date: Thu, 22 May 2014 23:01:50 +0000
Subject: [R-SIG-Finance] Rbbg (formerly RBloomberg) -- Pulling portfolio data
Message-ID: <755A902DD501F5468B7A64CD3FAA3DE90887A44E@chwnexchg2.mesirow.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140522/219fc272/attachment.pl>

From zirael at 10g.pl  Sat May 24 21:44:30 2014
From: zirael at 10g.pl (=?UTF-8?Q?Zirael?=)
Date: Sat, 24 May 2014 21:44:30 +0200
Subject: [R-SIG-Finance] =?utf-8?q?=5Brugarch_package=5D_SIgn_Bias_Test?=
Message-ID: <5385dcf7.76aee17e.5380f69e.16077@10g.pl>

Hi,

I have a question about the regression used in the Sign Bias test of Engle
and Ng. In the original paper the regression is for squared standardized
residuals but not against their non-squared values (as it is described in
the "introduction" to rugarch package) - in the paper it is against the
innovations (y(t)). Is it the same?

Or should we even rather use here the "fitted" values of innovations
(y^(t)= y(t)-mi(theta,x(t)), because in fact the standardized residuals
come grom ARMA-GARCH model, not GARCH itself, as it is in the original
paper od Engle and Ng. 

Many thanks for any help. 


From alexios at 4dscape.com  Sat May 24 22:18:33 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sat, 24 May 2014 21:18:33 +0100
Subject: [R-SIG-Finance] [rugarch package] SIgn Bias Test
In-Reply-To: <5385dcf7.76aee17e.5380f69e.16077@10g.pl>
References: <5385dcf7.76aee17e.5380f69e.16077@10g.pl>
Message-ID: <5380FE99.6090806@4dscape.com>

1. Actually, in the paper it is the squared standardized innovations
(z^2) against the non-standardized innovations (residuals) multiplied by
the sign.
2. "fitted" is not what is defined as 'y(t)-mi(theta, x(t))'. This is
called "residuals".
3. The vignette has a typo. The actual test (.signbiasTest) in the
rugarch-tests.R file uses the residuals not the standardized residuals
for the right hand side.

-Alexios

On 24/05/2014 20:44, Zirael wrote:
> Hi,
> 
> I have a question about the regression used in the Sign Bias test of Engle
> and Ng. In the original paper the regression is for squared standardized
> residuals but not against their non-squared values (as it is described in
> the "introduction" to rugarch package) - in the paper it is against the
> innovations (y(t)). Is it the same?
> 
> Or should we even rather use here the "fitted" values of innovations
> (y^(t)= y(t)-mi(theta,x(t)), because in fact the standardized residuals
> come grom ARMA-GARCH model, not GARCH itself, as it is in the original
> paper od Engle and Ng. 
> 
> Many thanks for any help. 
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 
>


From zirael at 10g.pl  Sat May 24 22:49:34 2014
From: zirael at 10g.pl (=?UTF-8?Q?Zirael?=)
Date: Sat, 24 May 2014 22:49:34 +0200
Subject: [R-SIG-Finance] =?utf-8?q?=5Brugarch_package=5D_SIgn_Bias_Test?=
In-Reply-To: <5380FE99.6090806@4dscape.com>
References: <5385dcf7.76aee17e.5380f69e.16077@10g.pl>
	<5380FE99.6090806@4dscape.com>
Message-ID: <6a46ab1.1de16148.538105de.9cd26@10g.pl>

Thanks for help! It's clear to me now :-)

Dnia 24 maja 2014 22:18 alexios ghalanos <alexios at 4dscape.com> napisa?(a):

> 1\. Actually, in the paper it is the squared standardized innovations
> (z^2) against the non-standardized innovations (residuals) multiplied by
> the sign.
> 2\. "fitted" is not what is defined as 'y(t)-mi(theta, x(t))'. This is
> called "residuals".
> 3\. The vignette has a typo. The actual test (.signbiasTest) in the
> rugarch-tests.R file uses the residuals not the standardized residuals
> for the right hand side.
> 
> -Alexios
> 
> On 24/05/2014 20:44, Zirael wrote:
> > Hi,
> > 
> > I have a question about the regression used in the Sign Bias test of> Engle
> > and Ng. In the original paper the regression is for squared standardized
> > residuals but not against their non-squared values (as it is described> in
> > the "introduction" to rugarch package) - in the paper it is against the
> > innovations (y(t)). Is it the same?
> > 
> > Or should we even rather use here the "fitted" values of innovations
> > (y^(t)= y(t)-mi(theta,x(t)), because in fact the standardized residuals
> > come grom ARMA-GARCH model, not GARCH itself, as it is in the original
> > paper od Engle and Ng. 
> > 
> > Many thanks for any help. 
> > 
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions> should go.
> > 
> > 
> >
> 


From thomas.fuller at coherentlogic.com  Mon May 26 15:28:04 2014
From: thomas.fuller at coherentlogic.com (Thomas Fuller)
Date: Mon, 26 May 2014 06:28:04 -0700 (PDT)
Subject: [R-SIG-Finance] R Bitcoin Charts API packge 1.0.1 released
Message-ID: <1401110884.14124.YahooMailNeo@web142703.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140526/1e3ddcdd/attachment.pl>

From a.chandhial at btinternet.com  Mon May 26 18:48:34 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Mon, 26 May 2014 17:48:34 +0100 (BST)
Subject: [R-SIG-Finance] Fwd: Fw: Fw: stochastic oscillator OBOS - intraday
 data	& optimization TIMEFILTER & TIMESPANS
In-Reply-To: <1400403580.63886.YahooMailNeo@web186001.mail.ir2.yahoo.com>
References: <1400241238.34408.YahooMailNeo@web186002.mail.ir2.yahoo.com>
	<1400244608.96988.YahooMailNeo@web186005.mail.ir2.yahoo.com>
	<1400403580.63886.YahooMailNeo@web186001.mail.ir2.yahoo.com>
Message-ID: <7203777.184713.1401122914830.JavaMail.defaultUser@defaultHost>

A reminder.
Amarjit
----Original message----
>From : a.chandhial at btinternet.com
Date : 18/05/2014 - 09:59 (GMTDT)
To : ilya.kipnis at gmail.com, r-sig-finance at r-project.org
Subject : [R-SIG-Finance] Fw: Fw: stochastic oscillator OBOS - intraday data	& optimization TIMEFILTER & TIMESPANS
 
 
Via  the TIMEFILTER program, tradestats e.g. Gross.Profits are:
 
T07:00/T20:00    Gross.Profits    1571.112
T08:00/T21:00    Gross.Profits     601.9379 
T09:00/T22:00    Gross.Profits     601.9379 
T10:00/T23:00    Gross.Profits     783.9936
 
 
 
 
I have altered add.distribution in the TIMESPAN program
 
 add.distribution(strategy.st,
                        paramset.label = 'Timespan',
                        component.type = 'indicator',     # one of c('indicator', 'signal', 'order', 'enter', 'exit', 'chain')  --- have tried all of these!
                        component.label = 'timespan',
                        variable = list(n = .timespans),
                        label = 'TIMESPAN')
 
 
 
However, the tradestats remain only for T07:00/T20:00.
 
 
Amarjit
 
 
 
 
----- Forwarded Message -----
From: amarjit chandhial <a.chandhial at btinternet.com>
To: ""ilya.kipnis at gmail.com"" <ilya.kipnis at gmail.com>; ""r-sig-finance at r-project.org"" <r-sig-finance at r-project.org> 
Sent: Friday, 16 May 2014, 13:50
Subject: [R-SIG-Finance] Fw: stochastic oscillator OBOS - intraday data & optimization TIMEFILTER & TIMESPANS
Opps, forgot the .RData strategy file for the TIMESPAN program.
 
 
Amarjit
----- Forwarded Message -----
From: amarjit chandhial <a.chandhial at btinternet.com>
To: "ilya.kipnis at gmail.com" <ilya.kipnis at gmail.com>; "r-sig-finance at r-project.org" <r-sig-finance at r-project.org> 
Sent: Friday, 16 May 2014, 12:53
Subject: [R-SIG-Finance] stochastic oscillator OBOS - intraday data & optimization TIMEFILTER & TIMESPANS
 
Hi Ilya,
 
 
Have returned with our stochastic oscillator OBOS strategy.
 
Where we were last time was optimizing nSlowD & the OBOS thresholds. I will guess that everything was correct there, inequalities etc, if not let me know! Therefore I'll carry-on with including a timefilter to our strategy and optimizing timespans (various timefilters). As this is for demo and given only a few days of intraday data the values for nSlowD and OBOS thresholds can remain at 5, 80, & 20, respectively (ordinarily this'll be on the optimized values). I have also uncommented the short-side as we have an fx rate GBPUSD, not a stock.
 
 
Attached:
(1) Vanilla + inclusion of a timefilter, chosen arbitrarily as 'T07:00/T20:00'. This appears to be filtering correctly.
(2)  Various timefilters i.e. timespans for optimization. Although the program runs, it does not appear to be optimizing. I am having problems with add.distribution and apply.paramset functions. Please help!
 
 
 
Amarjit 
_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.
_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140526/064a99ca/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_vanilla_TIMEFILTER.R
Type: application/octet-stream
Size: 7353 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140526/064a99ca/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ac_stochOSC_OBOS_GBPUSD_vanilla_TIMESPAN.R
Type: application/octet-stream
Size: 3573 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140526/064a99ca/attachment-0001.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: GBPUSDstoch.RData
Type: application/x-gzip-compressed
Size: 25945 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140526/064a99ca/attachment.bin>

From firhat.nawfan.h at gmail.com  Tue May 27 19:32:11 2014
From: firhat.nawfan.h at gmail.com (firhat.nawfan.h)
Date: Tue, 27 May 2014 10:32:11 -0700 (PDT)
Subject: [R-SIG-Finance] understanding an error from ugarchfit
In-Reply-To: <93E95D04-B6D4-49AD-B60C-E51EDF32D96A@4dscape.com>
References: <1391682044269-4684836.post@n4.nabble.com>
	<BDCC496D-72F7-445D-8424-7AC78BFE2754@4dscape.com>
	<1392738243146-4685490.post@n4.nabble.com>
	<93E95D04-B6D4-49AD-B60C-E51EDF32D96A@4dscape.com>
Message-ID: <1401211931020-4691313.post@n4.nabble.com>

hi Alexios i have recently also experienced the same error "Error in ans$res
: $ operator is invalid for atomic vectors" but for another function:
"dccforecast"



--
View this message in context: http://r.789695.n4.nabble.com/understanding-an-error-from-ugarchfit-tp4684836p4691313.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From alexios at 4dscape.com  Tue May 27 20:31:21 2014
From: alexios at 4dscape.com (Alexios Ghalanos)
Date: Tue, 27 May 2014 19:31:21 +0100
Subject: [R-SIG-Finance] understanding an error from ugarchfit
In-Reply-To: <1401211931020-4691313.post@n4.nabble.com>
References: <1391682044269-4684836.post@n4.nabble.com>
	<BDCC496D-72F7-445D-8424-7AC78BFE2754@4dscape.com>
	<1392738243146-4685490.post@n4.nabble.com>
	<93E95D04-B6D4-49AD-B60C-E51EDF32D96A@4dscape.com>
	<1401211931020-4691313.post@n4.nabble.com>
Message-ID: <0B94CACC-699B-4CC3-901D-84B9128B3132@4dscape.com>

That probably means you submitted an object of class DCCfit to dccforecast without checking whether it had converged first. Of course,  with such limited information I can only but speculate. Please sign your messages with you real name if you expect future replies.

-Alexios


> On 27 May 2014, at 18:32, "firhat.nawfan.h" <firhat.nawfan.h at gmail.com> wrote:
> 
> hi Alexios i have recently also experienced the same error "Error in ans$res
> : $ operator is invalid for atomic vectors" but for another function:
> "dccforecast"
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/understanding-an-error-from-ugarchfit-tp4684836p4691313.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 


From markknecht at gmail.com  Tue May 27 20:54:55 2014
From: markknecht at gmail.com (Mark Knecht)
Date: Tue, 27 May 2014 11:54:55 -0700
Subject: [R-SIG-Finance] Time Varying Higher Moments - racd?
Message-ID: <CAK2H+efzgZ-uDsVqGs_cPCmJCJhEXL42C7dMWD405d9xdc1k-w@mail.gmail.com>

In this presentation:

http://www.rinfinance.com/agenda/2013/talk/AlexiosGhalanos.pdf

there is a bit of code on page 16 (and copied below) that loads a
library called racd. I cannot seem to find racd. Can someone point me
in the right direction?

Thanks,
Mark



library(racd)
library(rugarch)
data(sp500ret)
spec = acdspec(variance.model=list(model=?sGARCH?, variance.targeting=TRUE),
distribution.model=list(model=?nig?,skewOrder=c(1,0,1),
shapeOrder=c(1,1,1),skewmodel=?quad?,shapemodel=?pwl?))
mod = acdfit(spec, sp500ret, solver=?msoptim?,solver.control=list(restarts=5))


From josh.m.ulrich at gmail.com  Tue May 27 20:56:17 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 27 May 2014 13:56:17 -0500
Subject: [R-SIG-Finance] Time Varying Higher Moments - racd?
In-Reply-To: <CAK2H+efzgZ-uDsVqGs_cPCmJCJhEXL42C7dMWD405d9xdc1k-w@mail.gmail.com>
References: <CAK2H+efzgZ-uDsVqGs_cPCmJCJhEXL42C7dMWD405d9xdc1k-w@mail.gmail.com>
Message-ID: <CAPPM_gTntMs7AWDCSBd0BCrioe16dOx9vXVU8qo-e_bFDGzXFA@mail.gmail.com>

See p15 of the presentation.
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


On Tue, May 27, 2014 at 1:54 PM, Mark Knecht <markknecht at gmail.com> wrote:
> In this presentation:
>
> http://www.rinfinance.com/agenda/2013/talk/AlexiosGhalanos.pdf
>
> there is a bit of code on page 16 (and copied below) that loads a
> library called racd. I cannot seem to find racd. Can someone point me
> in the right direction?
>
> Thanks,
> Mark
>
>
>
> library(racd)
> library(rugarch)
> data(sp500ret)
> spec = acdspec(variance.model=list(model=?sGARCH?, variance.targeting=TRUE),
> distribution.model=list(model=?nig?,skewOrder=c(1,0,1),
> shapeOrder=c(1,1,1),skewmodel=?quad?,shapemodel=?pwl?))
> mod = acdfit(spec, sp500ret, solver=?msoptim?,solver.control=list(restarts=5))
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From firhat.nawfan.h at gmail.com  Tue May 27 21:02:25 2014
From: firhat.nawfan.h at gmail.com (firhat.nawfan.h)
Date: Tue, 27 May 2014 12:02:25 -0700 (PDT)
Subject: [R-SIG-Finance] understanding an error from ugarchfit
In-Reply-To: <0B94CACC-699B-4CC3-901D-84B9128B3132@4dscape.com>
References: <1391682044269-4684836.post@n4.nabble.com>
	<BDCC496D-72F7-445D-8424-7AC78BFE2754@4dscape.com>
	<1392738243146-4685490.post@n4.nabble.com>
	<93E95D04-B6D4-49AD-B60C-E51EDF32D96A@4dscape.com>
	<1401211931020-4691313.post@n4.nabble.com>
	<0B94CACC-699B-4CC3-901D-84B9128B3132@4dscape.com>
Message-ID: <1401217345854-4691323.post@n4.nabble.com>

the dccfit had converged already, perhaps it have something to do with how
the dccspec? there are 2 kind of data fin series, and cg series, bot dccfit
converged in the first run, however when applied dccforecast the fin series
give error message while cg series have no problem

note: how to sign my messages with my real name?, i;m new here, usually i
visited in stackexchange to get answer

this is my code

mspec.ret.fin<-c()
for(i in 1:15)
	{

mspec.ret.fin<-c(mspec.ret.fin,get(paste("spec.ugarch.ret.fin.",colnames(base.name[i]),sep="")))
	}
mspec.ret.fin=multispec(mspec.ret.fin)

# specify dccspec
assign(paste("dcc.spec.ret.fin"),dccspec(get(paste("mspec.ret.fin")), VAR =
FALSE, robust = FALSE, lag = 1, lag.max = NULL, lag.criterion = c("AIC",
"HQ", "SC", "FPE"), external.regressors = NULL, robust.control =
list("gamma" = 0.25, "delta" = 0.01, "nc" = 10, "ns" = 500), dccOrder =
c(1,1), model = c("DCC"), groups = rep(1, length(uspec at spec)), distribution
= c("mvnorm"), start.pars = list(), fixed.pars = list()))

# specify data for dcc.fit
merge.list.data.dcc.fit.ret.fin<-as.character(list())
for (i in 1:15)
{
merge.list.data.dcc.fit.ret.fin<-append(merge.list.data.dcc.fit.ret.fin,paste("resid.ret.fin.",colnames(base.name[i]),sep=""))
}
merge.name.data.dcc.fit.ret.fin<-lapply(merge.list.data.dcc.fit.ret.fin,get)
names(merge.name.data.dcc.fit.ret.fin)<-merge.list.data.dcc.fit.ret.fin
data.dcc.fit.ret.fin<-do.call(merge,merge.name.data.dcc.fit.ret.fin)

# adjust data for dcc.fit for different starting point in coloumn
if (exists("dcc.fit.adj.ret.fin")==TRUE)
{
if(dcc.fit.adj.ret.fin>=0)
	{
	set.data.dcc.fit.ret.fin<-data.dcc.fit.ret.fin[-c(1:dcc.fit.adj.ret.fin),]
	}
else
	{
	set.data.dcc.fit.ret.fin<-data.dcc.fit.ret.fin
	}
}
if (exists("dcc.fit.adj.ret.fin")==FALSE)
{
set.data.dcc.fit.ret.fin<-data.dcc.fit.ret.fin
}

# performing dcc.fit
dcc.fit.ret.fin<-dccfit(dcc.spec.ret.fin, set.data.dcc.fit.ret.fin,
out.sample = 30, solver = "gosolnp", solver.control = list(),fit.control =
list(eval.se = TRUE, stationarity = TRUE, scale = FALSE), cluster = NULL,
fit = NULL, VAR.fit = NULL)
dcc.fit.ret.cg<-dccfit(dcc.spec.ret.cg, set.data.dcc.fit.ret.cg, out.sample
= 30,



--
View this message in context: http://r.789695.n4.nabble.com/understanding-an-error-from-ugarchfit-tp4684836p4691323.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From alexios at 4dscape.com  Tue May 27 21:59:12 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Tue, 27 May 2014 20:59:12 +0100
Subject: [R-SIG-Finance] Time Varying Higher Moments - racd?
In-Reply-To: <CAPPM_gTntMs7AWDCSBd0BCrioe16dOx9vXVU8qo-e_bFDGzXFA@mail.gmail.com>
References: <CAK2H+efzgZ-uDsVqGs_cPCmJCJhEXL42C7dMWD405d9xdc1k-w@mail.gmail.com>
	<CAPPM_gTntMs7AWDCSBd0BCrioe16dOx9vXVU8qo-e_bFDGzXFA@mail.gmail.com>
Message-ID: <5384EE90.2080309@4dscape.com>

Since 2013 the development repository for my packages has moved (a
couple of time). See:
http://www.unstarched.net/r-downloads/
for latest details.

-Alexios

On 27/05/2014 19:56, Joshua Ulrich wrote:
> See p15 of the presentation.
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
> 
> 
> On Tue, May 27, 2014 at 1:54 PM, Mark Knecht <markknecht at gmail.com> wrote:
>> In this presentation:
>>
>> http://www.rinfinance.com/agenda/2013/talk/AlexiosGhalanos.pdf
>>
>> there is a bit of code on page 16 (and copied below) that loads a
>> library called racd. I cannot seem to find racd. Can someone point me
>> in the right direction?
>>
>> Thanks,
>> Mark
>>
>>
>>
>> library(racd)
>> library(rugarch)
>> data(sp500ret)
>> spec = acdspec(variance.model=list(model=?sGARCH?, variance.targeting=TRUE),
>> distribution.model=list(model=?nig?,skewOrder=c(1,0,1),
>> shapeOrder=c(1,1,1),skewmodel=?quad?,shapemodel=?pwl?))
>> mod = acdfit(spec, sp500ret, solver=?msoptim?,solver.control=list(restarts=5))
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From alexios at 4dscape.com  Tue May 27 22:02:48 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Tue, 27 May 2014 21:02:48 +0100
Subject: [R-SIG-Finance] understanding an error from ugarchfit
In-Reply-To: <1401217345854-4691323.post@n4.nabble.com>
References: <1391682044269-4684836.post@n4.nabble.com>	<BDCC496D-72F7-445D-8424-7AC78BFE2754@4dscape.com>	<1392738243146-4685490.post@n4.nabble.com>	<93E95D04-B6D4-49AD-B60C-E51EDF32D96A@4dscape.com>	<1401211931020-4691313.post@n4.nabble.com>	<0B94CACC-699B-4CC3-901D-84B9128B3132@4dscape.com>
	<1401217345854-4691323.post@n4.nabble.com>
Message-ID: <5384EF68.9060201@4dscape.com>

This is NOT stackexchange.

1. Real name
2. Reproducible example (what you've provided below is NOT).

-Alexios

On 27/05/2014 20:02, firhat.nawfan.h wrote:
> the dccfit had converged already, perhaps it have something to do with how
> the dccspec? there are 2 kind of data fin series, and cg series, bot dccfit
> converged in the first run, however when applied dccforecast the fin series
> give error message while cg series have no problem
> 
> note: how to sign my messages with my real name?, i;m new here, usually i
> visited in stackexchange to get answer
> 
> this is my code
> 
> mspec.ret.fin<-c()
> for(i in 1:15)
> 	{
> 
> mspec.ret.fin<-c(mspec.ret.fin,get(paste("spec.ugarch.ret.fin.",colnames(base.name[i]),sep="")))
> 	}
> mspec.ret.fin=multispec(mspec.ret.fin)
> 
> # specify dccspec
> assign(paste("dcc.spec.ret.fin"),dccspec(get(paste("mspec.ret.fin")), VAR =
> FALSE, robust = FALSE, lag = 1, lag.max = NULL, lag.criterion = c("AIC",
> "HQ", "SC", "FPE"), external.regressors = NULL, robust.control =
> list("gamma" = 0.25, "delta" = 0.01, "nc" = 10, "ns" = 500), dccOrder =
> c(1,1), model = c("DCC"), groups = rep(1, length(uspec at spec)), distribution
> = c("mvnorm"), start.pars = list(), fixed.pars = list()))
> 
> # specify data for dcc.fit
> merge.list.data.dcc.fit.ret.fin<-as.character(list())
> for (i in 1:15)
> {
> merge.list.data.dcc.fit.ret.fin<-append(merge.list.data.dcc.fit.ret.fin,paste("resid.ret.fin.",colnames(base.name[i]),sep=""))
> }
> merge.name.data.dcc.fit.ret.fin<-lapply(merge.list.data.dcc.fit.ret.fin,get)
> names(merge.name.data.dcc.fit.ret.fin)<-merge.list.data.dcc.fit.ret.fin
> data.dcc.fit.ret.fin<-do.call(merge,merge.name.data.dcc.fit.ret.fin)
> 
> # adjust data for dcc.fit for different starting point in coloumn
> if (exists("dcc.fit.adj.ret.fin")==TRUE)
> {
> if(dcc.fit.adj.ret.fin>=0)
> 	{
> 	set.data.dcc.fit.ret.fin<-data.dcc.fit.ret.fin[-c(1:dcc.fit.adj.ret.fin),]
> 	}
> else
> 	{
> 	set.data.dcc.fit.ret.fin<-data.dcc.fit.ret.fin
> 	}
> }
> if (exists("dcc.fit.adj.ret.fin")==FALSE)
> {
> set.data.dcc.fit.ret.fin<-data.dcc.fit.ret.fin
> }
> 
> # performing dcc.fit
> dcc.fit.ret.fin<-dccfit(dcc.spec.ret.fin, set.data.dcc.fit.ret.fin,
> out.sample = 30, solver = "gosolnp", solver.control = list(),fit.control =
> list(eval.se = TRUE, stationarity = TRUE, scale = FALSE), cluster = NULL,
> fit = NULL, VAR.fit = NULL)
> dcc.fit.ret.cg<-dccfit(dcc.spec.ret.cg, set.data.dcc.fit.ret.cg, out.sample
> = 30,
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/understanding-an-error-from-ugarchfit-tp4684836p4691323.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 
>


From markknecht at gmail.com  Tue May 27 22:43:58 2014
From: markknecht at gmail.com (Mark Knecht)
Date: Tue, 27 May 2014 13:43:58 -0700
Subject: [R-SIG-Finance] Time Varying Higher Moments - racd?
In-Reply-To: <5384EE90.2080309@4dscape.com>
References: <CAK2H+efzgZ-uDsVqGs_cPCmJCJhEXL42C7dMWD405d9xdc1k-w@mail.gmail.com>
	<CAPPM_gTntMs7AWDCSBd0BCrioe16dOx9vXVU8qo-e_bFDGzXFA@mail.gmail.com>
	<5384EE90.2080309@4dscape.com>
Message-ID: <CAK2H+eeyHukPn0L0XaUzU2VjetX4-HAEUfCMgRwqPmTxA0GUrw@mail.gmail.com>

On Tue, May 27, 2014 at 12:59 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
> Since 2013 the development repository for my packages has moved (a
> couple of time). See:
> http://www.unstarched.net/r-downloads/
> for latest details.
>
> -Alexios

Thanks Alexios. I started reading that based on Pierre's response but
I'm hung up:

1) I needed the fftw  package to install but it wouldn't as it was not
finding fftw3. I then  found fftw-3.3.3-r2 in Gentoo portage and think
I got past that problem.

2) I'm now just trying to install all the packages shown on yor
r-downloads page but rmgarch won't install apparently due to (I think)
Latex issues. I got as far as failing due to something called texi2dvi
which I found and installed from portage again, but now I have this
problem due to a missing appendix.sty file I think.

Thanks for any pointers into what I'm doing wrong here.

Cheers,
Mark


R version 3.1.0 (2014-04-10) -- "Spring Dance"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> require(devtools)
Loading required package: devtools

Attaching package: ?devtools?

The following objects are masked from ?package:utils?:

    ?, help

The following object is masked from ?package:base?:

    system.file

> install_bitbucket("rmgarch","alexiosg")
Installing bitbucket repo(s) rmgarch/master from alexiosg
Downloading master.zip from
https://bitbucket.org/alexiosg/rmgarch/get/master.zip
Installing package from /tmp/Rtmpwt0Tnh/master.zip
arguments 'minimized' and 'invisible' are for Windows only
Installing rmgarch
'/usr/lib64/R/bin/R' --vanilla CMD build
'/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925'
\
  --no-manual --no-resave-data

* checking for file
'/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925/DESCRIPTION'
... OK
* preparing 'rmgarch':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* installing the package to build vignettes
* creating vignettes ... ERROR
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
  Running 'texi2dvi' on 'The_rmgarch_models.tex' failed.
LaTeX errors:
! LaTeX Error: File `appendix.sty' not found.

Type X to quit or <RETURN> to proceed,
or enter new name. (Default extension: sty)

! Emergency stop.
<read *>

l.9 \usepackage
               [round]{natbib}^^M
!  ==> Fatal error occurred, no output PDF file produced!
Calls: <Anonymous> -> texi2pdf -> texi2dvi
Execution halted
Error: Command failed (1)

>


From alexios at 4dscape.com  Tue May 27 23:08:56 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Tue, 27 May 2014 22:08:56 +0100
Subject: [R-SIG-Finance] Time Varying Higher Moments - racd?
In-Reply-To: <CAK2H+eeyHukPn0L0XaUzU2VjetX4-HAEUfCMgRwqPmTxA0GUrw@mail.gmail.com>
References: <CAK2H+efzgZ-uDsVqGs_cPCmJCJhEXL42C7dMWD405d9xdc1k-w@mail.gmail.com>	<CAPPM_gTntMs7AWDCSBd0BCrioe16dOx9vXVU8qo-e_bFDGzXFA@mail.gmail.com>	<5384EE90.2080309@4dscape.com>
	<CAK2H+eeyHukPn0L0XaUzU2VjetX4-HAEUfCMgRwqPmTxA0GUrw@mail.gmail.com>
Message-ID: <5384FEE8.5060704@4dscape.com>

Hi Mark,

1. Have a look at the "install_bitbucket" documentation. There is the
option I believe to pass some extra arguments to "install" via '...'.
Specifically the "dependencies" (logical) and "build_vignettes" arguments.
2. You need to have the "appendix" package in your latex installation
(see the documentation of your linux flavor on how to do this).
3. fftw on CRAN builds ok for everything but OSX Mavericks...I may
remove it going forward and use the base implementation to avoid too
many problematic dependencies, but would welcome any feedback on speed
comparisons.

Best,

Alexios

On 27/05/2014 21:43, Mark Knecht wrote:
> On Tue, May 27, 2014 at 12:59 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
>> Since 2013 the development repository for my packages has moved (a
>> couple of time). See:
>> http://www.unstarched.net/r-downloads/
>> for latest details.
>>
>> -Alexios
> 
> Thanks Alexios. I started reading that based on Pierre's response but
> I'm hung up:
> 
> 1) I needed the fftw  package to install but it wouldn't as it was not
> finding fftw3. I then  found fftw-3.3.3-r2 in Gentoo portage and think
> I got past that problem.
> 
> 2) I'm now just trying to install all the packages shown on yor
> r-downloads page but rmgarch won't install apparently due to (I think)
> Latex issues. I got as far as failing due to something called texi2dvi
> which I found and installed from portage again, but now I have this
> problem due to a missing appendix.sty file I think.
> 
> Thanks for any pointers into what I'm doing wrong here.
> 
> Cheers,
> Mark
> 
> 
> R version 3.1.0 (2014-04-10) -- "Spring Dance"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
>> require(devtools)
> Loading required package: devtools
> 
> Attaching package: ?devtools?
> 
> The following objects are masked from ?package:utils?:
> 
>     ?, help
> 
> The following object is masked from ?package:base?:
> 
>     system.file
> 
>> install_bitbucket("rmgarch","alexiosg")
> Installing bitbucket repo(s) rmgarch/master from alexiosg
> Downloading master.zip from
> https://bitbucket.org/alexiosg/rmgarch/get/master.zip
> Installing package from /tmp/Rtmpwt0Tnh/master.zip
> arguments 'minimized' and 'invisible' are for Windows only
> Installing rmgarch
> '/usr/lib64/R/bin/R' --vanilla CMD build
> '/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925'
> \
>   --no-manual --no-resave-data
> 
> * checking for file
> '/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925/DESCRIPTION'
> ... OK
> * preparing 'rmgarch':
> * checking DESCRIPTION meta-information ... OK
> * cleaning src
> * installing the package to build vignettes
> * creating vignettes ... ERROR
> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>   Running 'texi2dvi' on 'The_rmgarch_models.tex' failed.
> LaTeX errors:
> ! LaTeX Error: File `appendix.sty' not found.
> 
> Type X to quit or <RETURN> to proceed,
> or enter new name. (Default extension: sty)
> 
> ! Emergency stop.
> <read *>
> 
> l.9 \usepackage
>                [round]{natbib}^^M
> !  ==> Fatal error occurred, no output PDF file produced!
> Calls: <Anonymous> -> texi2pdf -> texi2dvi
> Execution halted
> Error: Command failed (1)
> 
>>
> 
>


From markknecht at gmail.com  Wed May 28 17:13:18 2014
From: markknecht at gmail.com (Mark Knecht)
Date: Wed, 28 May 2014 08:13:18 -0700
Subject: [R-SIG-Finance] Time Varying Higher Moments - racd?
In-Reply-To: <5384FEE8.5060704@4dscape.com>
References: <CAK2H+efzgZ-uDsVqGs_cPCmJCJhEXL42C7dMWD405d9xdc1k-w@mail.gmail.com>
	<CAPPM_gTntMs7AWDCSBd0BCrioe16dOx9vXVU8qo-e_bFDGzXFA@mail.gmail.com>
	<5384EE90.2080309@4dscape.com>
	<CAK2H+eeyHukPn0L0XaUzU2VjetX4-HAEUfCMgRwqPmTxA0GUrw@mail.gmail.com>
	<5384FEE8.5060704@4dscape.com>
Message-ID: <CAK2H+edkd8U+TXAmpcZowmHCmD-pPAvx2FJFW0Q-KUV2zQWhCg@mail.gmail.com>

Thanks Alexios. With a bit of guessing about Latex packages I got the
appendix directory installed and the R code runs. (Mostly - The first
3 plots are created. I've been waiting for about 20 minutes for the
quantile plot to finish but no results on that one yet.

Anyway, it works well enough for me to go a bit deeper now.

Cheers,
Mark

On Tue, May 27, 2014 at 2:08 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
> Hi Mark,
>
> 1. Have a look at the "install_bitbucket" documentation. There is the
> option I believe to pass some extra arguments to "install" via '...'.
> Specifically the "dependencies" (logical) and "build_vignettes" arguments.
> 2. You need to have the "appendix" package in your latex installation
> (see the documentation of your linux flavor on how to do this).
> 3. fftw on CRAN builds ok for everything but OSX Mavericks...I may
> remove it going forward and use the base implementation to avoid too
> many problematic dependencies, but would welcome any feedback on speed
> comparisons.
>
> Best,
>
> Alexios
>
> On 27/05/2014 21:43, Mark Knecht wrote:
>> On Tue, May 27, 2014 at 12:59 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
>>> Since 2013 the development repository for my packages has moved (a
>>> couple of time). See:
>>> http://www.unstarched.net/r-downloads/
>>> for latest details.
>>>
>>> -Alexios
>>
>> Thanks Alexios. I started reading that based on Pierre's response but
>> I'm hung up:
>>
>> 1) I needed the fftw  package to install but it wouldn't as it was not
>> finding fftw3. I then  found fftw-3.3.3-r2 in Gentoo portage and think
>> I got past that problem.
>>
>> 2) I'm now just trying to install all the packages shown on yor
>> r-downloads page but rmgarch won't install apparently due to (I think)
>> Latex issues. I got as far as failing due to something called texi2dvi
>> which I found and installed from portage again, but now I have this
>> problem due to a missing appendix.sty file I think.
>>
>> Thanks for any pointers into what I'm doing wrong here.
>>
>> Cheers,
>> Mark
>>
>>
>> R version 3.1.0 (2014-04-10) -- "Spring Dance"
>> Copyright (C) 2014 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>>> require(devtools)
>> Loading required package: devtools
>>
>> Attaching package: ?devtools?
>>
>> The following objects are masked from ?package:utils?:
>>
>>     ?, help
>>
>> The following object is masked from ?package:base?:
>>
>>     system.file
>>
>>> install_bitbucket("rmgarch","alexiosg")
>> Installing bitbucket repo(s) rmgarch/master from alexiosg
>> Downloading master.zip from
>> https://bitbucket.org/alexiosg/rmgarch/get/master.zip
>> Installing package from /tmp/Rtmpwt0Tnh/master.zip
>> arguments 'minimized' and 'invisible' are for Windows only
>> Installing rmgarch
>> '/usr/lib64/R/bin/R' --vanilla CMD build
>> '/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925'
>> \
>>   --no-manual --no-resave-data
>>
>> * checking for file
>> '/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925/DESCRIPTION'
>> ... OK
>> * preparing 'rmgarch':
>> * checking DESCRIPTION meta-information ... OK
>> * cleaning src
>> * installing the package to build vignettes
>> * creating vignettes ... ERROR
>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>>   Running 'texi2dvi' on 'The_rmgarch_models.tex' failed.
>> LaTeX errors:
>> ! LaTeX Error: File `appendix.sty' not found.
>>
>> Type X to quit or <RETURN> to proceed,
>> or enter new name. (Default extension: sty)
>>
>> ! Emergency stop.
>> <read *>
>>
>> l.9 \usepackage
>>                [round]{natbib}^^M
>> !  ==> Fatal error occurred, no output PDF file produced!
>> Calls: <Anonymous> -> texi2pdf -> texi2dvi
>> Execution halted
>> Error: Command failed (1)
>>
>>>
>>
>>
>


From guillaume.pealat at gmail.com  Wed May 28 17:53:05 2014
From: guillaume.pealat at gmail.com (Guillaume PEALAT)
Date: Wed, 28 May 2014 16:53:05 +0100
Subject: [R-SIG-Finance] Simulating returns using copula and SPD distribution
Message-ID: <CAD0NpoB_DvotgaS2t0-cXcXUieHDejvU0PQttquYv9xRpjxGDA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140528/5502c9f6/attachment.pl>

From alexios at 4dscape.com  Wed May 28 19:10:08 2014
From: alexios at 4dscape.com (Alexios Ghalanos)
Date: Wed, 28 May 2014 18:10:08 +0100
Subject: [R-SIG-Finance] Time Varying Higher Moments - racd?
In-Reply-To: <CAK2H+edkd8U+TXAmpcZowmHCmD-pPAvx2FJFW0Q-KUV2zQWhCg@mail.gmail.com>
References: <CAK2H+efzgZ-uDsVqGs_cPCmJCJhEXL42C7dMWD405d9xdc1k-w@mail.gmail.com>
	<CAPPM_gTntMs7AWDCSBd0BCrioe16dOx9vXVU8qo-e_bFDGzXFA@mail.gmail.com>
	<5384EE90.2080309@4dscape.com>
	<CAK2H+eeyHukPn0L0XaUzU2VjetX4-HAEUfCMgRwqPmTxA0GUrw@mail.gmail.com>
	<5384FEE8.5060704@4dscape.com>
	<CAK2H+edkd8U+TXAmpcZowmHCmD-pPAvx2FJFW0Q-KUV2zQWhCg@mail.gmail.com>
Message-ID: <27D96CA5-36CB-41AD-80B2-2C1550FA5007@4dscape.com>

Hi Mark,

You are probably using the nig or ghyp distributions which do not have a closed form quantile function so it is evaluating it for every point (which is expensive!). Try the jsu distribution instead...it is very flexible and fast to evaluate.

Best,

Alexios

> On 28 May 2014, at 16:13, Mark Knecht <markknecht at gmail.com> wrote:
> 
> Thanks Alexios. With a bit of guessing about Latex packages I got the
> appendix directory installed and the R code runs. (Mostly - The first
> 3 plots are created. I've been waiting for about 20 minutes for the
> quantile plot to finish but no results on that one yet.
> 
> Anyway, it works well enough for me to go a bit deeper now.
> 
> Cheers,
> Mark
> 
>> On Tue, May 27, 2014 at 2:08 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
>> Hi Mark,
>> 
>> 1. Have a look at the "install_bitbucket" documentation. There is the
>> option I believe to pass some extra arguments to "install" via '...'.
>> Specifically the "dependencies" (logical) and "build_vignettes" arguments.
>> 2. You need to have the "appendix" package in your latex installation
>> (see the documentation of your linux flavor on how to do this).
>> 3. fftw on CRAN builds ok for everything but OSX Mavericks...I may
>> remove it going forward and use the base implementation to avoid too
>> many problematic dependencies, but would welcome any feedback on speed
>> comparisons.
>> 
>> Best,
>> 
>> Alexios
>> 
>>> On 27/05/2014 21:43, Mark Knecht wrote:
>>>> On Tue, May 27, 2014 at 12:59 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
>>>> Since 2013 the development repository for my packages has moved (a
>>>> couple of time). See:
>>>> http://www.unstarched.net/r-downloads/
>>>> for latest details.
>>>> 
>>>> -Alexios
>>> 
>>> Thanks Alexios. I started reading that based on Pierre's response but
>>> I'm hung up:
>>> 
>>> 1) I needed the fftw  package to install but it wouldn't as it was not
>>> finding fftw3. I then  found fftw-3.3.3-r2 in Gentoo portage and think
>>> I got past that problem.
>>> 
>>> 2) I'm now just trying to install all the packages shown on yor
>>> r-downloads page but rmgarch won't install apparently due to (I think)
>>> Latex issues. I got as far as failing due to something called texi2dvi
>>> which I found and installed from portage again, but now I have this
>>> problem due to a missing appendix.sty file I think.
>>> 
>>> Thanks for any pointers into what I'm doing wrong here.
>>> 
>>> Cheers,
>>> Mark
>>> 
>>> 
>>> R version 3.1.0 (2014-04-10) -- "Spring Dance"
>>> Copyright (C) 2014 The R Foundation for Statistical Computing
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> 
>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>> You are welcome to redistribute it under certain conditions.
>>> Type 'license()' or 'licence()' for distribution details.
>>> 
>>> R is a collaborative project with many contributors.
>>> Type 'contributors()' for more information and
>>> 'citation()' on how to cite R or R packages in publications.
>>> 
>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>> 'help.start()' for an HTML browser interface to help.
>>> Type 'q()' to quit R.
>>> 
>>>> require(devtools)
>>> Loading required package: devtools
>>> 
>>> Attaching package: ?devtools?
>>> 
>>> The following objects are masked from ?package:utils?:
>>> 
>>>    ?, help
>>> 
>>> The following object is masked from ?package:base?:
>>> 
>>>    system.file
>>> 
>>>> install_bitbucket("rmgarch","alexiosg")
>>> Installing bitbucket repo(s) rmgarch/master from alexiosg
>>> Downloading master.zip from
>>> https://bitbucket.org/alexiosg/rmgarch/get/master.zip
>>> Installing package from /tmp/Rtmpwt0Tnh/master.zip
>>> arguments 'minimized' and 'invisible' are for Windows only
>>> Installing rmgarch
>>> '/usr/lib64/R/bin/R' --vanilla CMD build
>>> '/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925'
>>> \
>>>  --no-manual --no-resave-data
>>> 
>>> * checking for file
>>> '/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925/DESCRIPTION'
>>> ... OK
>>> * preparing 'rmgarch':
>>> * checking DESCRIPTION meta-information ... OK
>>> * cleaning src
>>> * installing the package to build vignettes
>>> * creating vignettes ... ERROR
>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>>>  Running 'texi2dvi' on 'The_rmgarch_models.tex' failed.
>>> LaTeX errors:
>>> ! LaTeX Error: File `appendix.sty' not found.
>>> 
>>> Type X to quit or <RETURN> to proceed,
>>> or enter new name. (Default extension: sty)
>>> 
>>> ! Emergency stop.
>>> <read *>
>>> 
>>> l.9 \usepackage
>>>               [round]{natbib}^^M
>>> !  ==> Fatal error occurred, no output PDF file produced!
>>> Calls: <Anonymous> -> texi2pdf -> texi2dvi
>>> Execution halted
>>> Error: Command failed (1)
>>> 
>>>> 
>>> 
>>> 
>> 
> 


From alexios at 4dscape.com  Wed May 28 19:18:23 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 28 May 2014 18:18:23 +0100
Subject: [R-SIG-Finance] Simulating returns using copula and SPD
	distribution
In-Reply-To: <CAD0NpoB_DvotgaS2t0-cXcXUieHDejvU0PQttquYv9xRpjxGDA@mail.gmail.com>
References: <CAD0NpoB_DvotgaS2t0-cXcXUieHDejvU0PQttquYv9xRpjxGDA@mail.gmail.com>
Message-ID: <53861A5F.2060500@4dscape.com>

You've missed a step. Think about it:
1. You take z.
2. Fit an spd.
3. Transform it to U using pspd.
4. Fit a copula on U.
5. Sample from copula to generate u.
6. Need to translate u back to z (step 1) using the quantile function
(qspd) and the estimated parameters from step 2.

i.e. you've missed step 6.


-Alexios

On 28/05/2014 16:53, Guillaume PEALAT wrote:
> Hi,
> 
> I am fitting some SPD distributions to past returns and some Copula to
> simulate the dependance.
> I am struggling with the simulation part, as the returns I simulate a
> clearly out of line after some time.
> 
> I have attached some sample code in order to clarify the point.
> 
> I first calibrate the SPD distribution on the past returns:
> 
> #Calibrating the SPD distributioon the residuals of an ARMA+GARCH
> 
> *spec.u1 = ugarchspec(mean.model=list(armaOrder=c(1,1)),
> distribution="std")*
> 
> *fit.u1 = ugarchfit(spec.u1, return.u1)*
> 
> *z.u1= residuals(fit.u1, standardize=TRUE)*
> 
> *gpd.u1 = spdfit(z.u1, upper=1. - tailFraction, lower=tailFraction)*
> 
> 
> #Calibrating the SPD distributioon the residuals of an ARMA+GARCH
> 
> *spec.u2 = ugarchspec(mean.model=list(armaOrder=c(1,1)),
> distribution="std")*
> 
> *fit.u2 = ugarchfit(spec.u2, return.u1)*
> 
> *z.u2= residuals(fit.u2, standardize=TRUE)*
> 
> *gpd.u2 = spdfit(z.u2, upper=1. - tailFraction, lower=tailFraction)*
> 
> 
> Then, once we have all this set, we need to calibrate the Copula of our
> choice
> 
> 
> #Calibrate the Copula
> 
> #We extract the residuals from the xts into a vector
> 
> *res.u1 = as.vector(z.u1[,1])*
> 
> *res.u2 = as.vector(z.u2[,1])*
> 
> #We transform the margin to uniform
> 
> *U.u1 = pspd(res.u1, gpd.u1)*
> 
> *U.u2 = pspd(res.u2, gpd.u2)*
> 
> 
> 
> #We create the matrix to help us calibrate the Copula
> 
> *test <-list()*
> 
> *test[[1]] = U.u1*
> 
> *test[[2]] = U.u2*
> 
> *test_matrix = do.call(rbind, test)*
> 
> 
> 
> *set.seed(123)*
> 
> 
> 
> #We define the Copula we want to use
> 
> *tcopula<-tCopula(param=0.5, dim=2, dispstr = "ex", df =6)*
> 
> #We fit the Copula with maximum Likelihood
> 
> *fit.mpl <- fitCopula(tcopula, t(test_matrix), method="ml")*
> 
> 
> 
> #We get back the parameters
> 
> #Rho
> 
> *rho.fit = fit.mpl at copula@parameters[1]*
> 
> #Degrees of Freedom
> 
> *df.fit = fit.mpl at copula@parameters[2]*
> 
> 
> 
> #Create fitted t-copula object
> 
> *t.cop.fit = tCopula(param=rho.fit, dim=2, df=df.fit)*
> 
> 
> 
> *margins = c("t", "t")*
> 
> *paramMargins = list(list(df=df.fit),list(df=df.fit))*
> 
> 
> 
> #Create fitted custom distribution object
> 
> *myBvd.tcop.fit = mvdc(copula=t.cop.fit, margins = margins, paramMargins=
> paramMargins)*
> 
> 
> 
> If all is well, I should be able to run some simulations and simulate my
> returns from this set up:
> 
> 
> #Generate random numbers from the Copula
> 
> *u = rMvdc(nsim, myBvd.tcop.fit)*
> 
> *u.1 = u[,1]*
> 
> #Generate the simulated returns
> 
> *sim.u1 = ugarchsim(fit.u1, n.sim=nsim, startMethod="sample", m.sim=1,*
> 
> *                    custom.dist=list(name="sample",distfit=matrix(u.1,
> ncol=1)))*
> 
> #Get back the simulated returns
> 
> *sim.u1.returns = sim.u1 at simulation$seriesSim*
> 
> 
> 
> The problem lies in the order of magnitude the simulated returns. I can get
> some occurrence of +26% for example, which is clearly wrong.
> 
> 
> Could someone point me on the wrong part?
> 
> I have also a remaining question:
> 
> In the univariate case, we can simulate the random number with *rspd(n =
> days, gpd.u1)*, and they will be in accordance with the gpd distribtuion
> calibrated.
> 
> In the multivariate case, can I consider this step to be taken care of by
> the random number of the Copula since it has been calibrated on the margins
> transformed to Uniform by the gpd distribution function?
> 
> 
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 
>


From guillaume.pealat at gmail.com  Wed May 28 19:29:04 2014
From: guillaume.pealat at gmail.com (Guillaume PEALAT)
Date: Wed, 28 May 2014 18:29:04 +0100
Subject: [R-SIG-Finance] Simulating returns using copula and SPD
	distribution
In-Reply-To: <53861A5F.2060500@4dscape.com>
References: <CAD0NpoB_DvotgaS2t0-cXcXUieHDejvU0PQttquYv9xRpjxGDA@mail.gmail.com>
	<53861A5F.2060500@4dscape.com>
Message-ID: <CAD0NpoD=FtSZ9LKtvguWSoikQzvqw0Mdjir9TC=o3kQUimLYCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140528/452b2dc8/attachment.pl>

From markknecht at gmail.com  Wed May 28 19:35:37 2014
From: markknecht at gmail.com (Mark Knecht)
Date: Wed, 28 May 2014 10:35:37 -0700
Subject: [R-SIG-Finance] Time Varying Higher Moments - racd?
In-Reply-To: <27D96CA5-36CB-41AD-80B2-2C1550FA5007@4dscape.com>
References: <CAK2H+efzgZ-uDsVqGs_cPCmJCJhEXL42C7dMWD405d9xdc1k-w@mail.gmail.com>
	<CAPPM_gTntMs7AWDCSBd0BCrioe16dOx9vXVU8qo-e_bFDGzXFA@mail.gmail.com>
	<5384EE90.2080309@4dscape.com>
	<CAK2H+eeyHukPn0L0XaUzU2VjetX4-HAEUfCMgRwqPmTxA0GUrw@mail.gmail.com>
	<5384FEE8.5060704@4dscape.com>
	<CAK2H+edkd8U+TXAmpcZowmHCmD-pPAvx2FJFW0Q-KUV2zQWhCg@mail.gmail.com>
	<27D96CA5-36CB-41AD-80B2-2C1550FA5007@4dscape.com>
Message-ID: <CAK2H+ec76V1OpJX_8Xg1tk6=b=fAhoEx9vX1N7pF0sGYNBdk7w@mail.gmail.com>

Thanks Alexios. "jsu" returns a solution quickly. The sigma and
quantile plots appear to be pretty much identical to what was in your
paper. The skewness and kertosis plots do look somewhat different but
I expect that's probably cause by using this different model.

Anyway, the code as supplied in the paper works fine now.

The last issue is not overly important but twinkle didn't install due
to (I think) some missing color definitions in Latex. I'll need to see
if I can find some info on fixing that but the hard stuff appears to
be working.

Cheers,
Mark


Installing twinkle
'/usr/lib64/R/bin/R' --vanilla CMD build
'/tmp/Rtmp5b80e3/devtools9e055940c74/alexiosg-twinkle-9461ed2d91a9'  \
  --no-manual --no-resave-data

* checking for file
'/tmp/Rtmp5b80e3/devtools9e055940c74/alexiosg-twinkle-9461ed2d91a9/DESCRIPTION'
... OK
* preparing 'twinkle':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* installing the package to build vignettes
* creating vignettes ... ERROR
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
  Running 'texi2dvi' on 'The_Twinkle_Package.tex' failed.
LaTeX errors:
! LaTeX Error: Undefined color `violet'.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help.
 ...
! LaTeX Error: Undefined color `violet'.




On Wed, May 28, 2014 at 10:10 AM, Alexios Ghalanos <alexios at 4dscape.com> wrote:
> Hi Mark,
>
> You are probably using the nig or ghyp distributions which do not have a closed form quantile function so it is evaluating it for every point (which is expensive!). Try the jsu distribution instead...it is very flexible and fast to evaluate.
>
> Best,
>
> Alexios
>
>> On 28 May 2014, at 16:13, Mark Knecht <markknecht at gmail.com> wrote:
>>
>> Thanks Alexios. With a bit of guessing about Latex packages I got the
>> appendix directory installed and the R code runs. (Mostly - The first
>> 3 plots are created. I've been waiting for about 20 minutes for the
>> quantile plot to finish but no results on that one yet.
>>
>> Anyway, it works well enough for me to go a bit deeper now.
>>
>> Cheers,
>> Mark
>>
>>> On Tue, May 27, 2014 at 2:08 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
>>> Hi Mark,
>>>
>>> 1. Have a look at the "install_bitbucket" documentation. There is the
>>> option I believe to pass some extra arguments to "install" via '...'.
>>> Specifically the "dependencies" (logical) and "build_vignettes" arguments.
>>> 2. You need to have the "appendix" package in your latex installation
>>> (see the documentation of your linux flavor on how to do this).
>>> 3. fftw on CRAN builds ok for everything but OSX Mavericks...I may
>>> remove it going forward and use the base implementation to avoid too
>>> many problematic dependencies, but would welcome any feedback on speed
>>> comparisons.
>>>
>>> Best,
>>>
>>> Alexios
>>>
>>>> On 27/05/2014 21:43, Mark Knecht wrote:
>>>>> On Tue, May 27, 2014 at 12:59 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
>>>>> Since 2013 the development repository for my packages has moved (a
>>>>> couple of time). See:
>>>>> http://www.unstarched.net/r-downloads/
>>>>> for latest details.
>>>>>
>>>>> -Alexios
>>>>
>>>> Thanks Alexios. I started reading that based on Pierre's response but
>>>> I'm hung up:
>>>>
>>>> 1) I needed the fftw  package to install but it wouldn't as it was not
>>>> finding fftw3. I then  found fftw-3.3.3-r2 in Gentoo portage and think
>>>> I got past that problem.
>>>>
>>>> 2) I'm now just trying to install all the packages shown on yor
>>>> r-downloads page but rmgarch won't install apparently due to (I think)
>>>> Latex issues. I got as far as failing due to something called texi2dvi
>>>> which I found and installed from portage again, but now I have this
>>>> problem due to a missing appendix.sty file I think.
>>>>
>>>> Thanks for any pointers into what I'm doing wrong here.
>>>>
>>>> Cheers,
>>>> Mark
>>>>
>>>>
>>>> R version 3.1.0 (2014-04-10) -- "Spring Dance"
>>>> Copyright (C) 2014 The R Foundation for Statistical Computing
>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>>
>>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>>> You are welcome to redistribute it under certain conditions.
>>>> Type 'license()' or 'licence()' for distribution details.
>>>>
>>>> R is a collaborative project with many contributors.
>>>> Type 'contributors()' for more information and
>>>> 'citation()' on how to cite R or R packages in publications.
>>>>
>>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>>> 'help.start()' for an HTML browser interface to help.
>>>> Type 'q()' to quit R.
>>>>
>>>>> require(devtools)
>>>> Loading required package: devtools
>>>>
>>>> Attaching package: ?devtools?
>>>>
>>>> The following objects are masked from ?package:utils?:
>>>>
>>>>    ?, help
>>>>
>>>> The following object is masked from ?package:base?:
>>>>
>>>>    system.file
>>>>
>>>>> install_bitbucket("rmgarch","alexiosg")
>>>> Installing bitbucket repo(s) rmgarch/master from alexiosg
>>>> Downloading master.zip from
>>>> https://bitbucket.org/alexiosg/rmgarch/get/master.zip
>>>> Installing package from /tmp/Rtmpwt0Tnh/master.zip
>>>> arguments 'minimized' and 'invisible' are for Windows only
>>>> Installing rmgarch
>>>> '/usr/lib64/R/bin/R' --vanilla CMD build
>>>> '/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925'
>>>> \
>>>>  --no-manual --no-resave-data
>>>>
>>>> * checking for file
>>>> '/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925/DESCRIPTION'
>>>> ... OK
>>>> * preparing 'rmgarch':
>>>> * checking DESCRIPTION meta-information ... OK
>>>> * cleaning src
>>>> * installing the package to build vignettes
>>>> * creating vignettes ... ERROR
>>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>>>>  Running 'texi2dvi' on 'The_rmgarch_models.tex' failed.
>>>> LaTeX errors:
>>>> ! LaTeX Error: File `appendix.sty' not found.
>>>>
>>>> Type X to quit or <RETURN> to proceed,
>>>> or enter new name. (Default extension: sty)
>>>>
>>>> ! Emergency stop.
>>>> <read *>
>>>>
>>>> l.9 \usepackage
>>>>               [round]{natbib}^^M
>>>> !  ==> Fatal error occurred, no output PDF file produced!
>>>> Calls: <Anonymous> -> texi2pdf -> texi2dvi
>>>> Execution halted
>>>> Error: Command failed (1)
>>>>
>>>>>
>>>>
>>>>
>>>
>>


From alexios at 4dscape.com  Wed May 28 19:55:23 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 28 May 2014 18:55:23 +0100
Subject: [R-SIG-Finance] Simulating returns using copula and SPD
	distribution
In-Reply-To: <CAD0NpoD=FtSZ9LKtvguWSoikQzvqw0Mdjir9TC=o3kQUimLYCA@mail.gmail.com>
References: <CAD0NpoB_DvotgaS2t0-cXcXUieHDejvU0PQttquYv9xRpjxGDA@mail.gmail.com>
	<53861A5F.2060500@4dscape.com>
	<CAD0NpoD=FtSZ9LKtvguWSoikQzvqw0Mdjir9TC=o3kQUimLYCA@mail.gmail.com>
Message-ID: <6E15E64C-813E-471C-BA04-963913ED811F@4dscape.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140528/f5b6aae9/attachment.pl>

From alexios at 4dscape.com  Wed May 28 20:01:31 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 28 May 2014 19:01:31 +0100
Subject: [R-SIG-Finance] Time Varying Higher Moments - racd?
In-Reply-To: <CAK2H+ec76V1OpJX_8Xg1tk6=b=fAhoEx9vX1N7pF0sGYNBdk7w@mail.gmail.com>
References: <CAK2H+efzgZ-uDsVqGs_cPCmJCJhEXL42C7dMWD405d9xdc1k-w@mail.gmail.com>
	<CAPPM_gTntMs7AWDCSBd0BCrioe16dOx9vXVU8qo-e_bFDGzXFA@mail.gmail.com>
	<5384EE90.2080309@4dscape.com>
	<CAK2H+eeyHukPn0L0XaUzU2VjetX4-HAEUfCMgRwqPmTxA0GUrw@mail.gmail.com>
	<5384FEE8.5060704@4dscape.com>
	<CAK2H+edkd8U+TXAmpcZowmHCmD-pPAvx2FJFW0Q-KUV2zQWhCg@mail.gmail.com>
	<27D96CA5-36CB-41AD-80B2-2C1550FA5007@4dscape.com>
	<CAK2H+ec76V1OpJX_8Xg1tk6=b=fAhoEx9vX1N7pF0sGYNBdk7w@mail.gmail.com>
Message-ID: <8AD115E4-ED67-4BB9-A9FD-9397EF3FD49B@4dscape.com>

Mark,

Have you tried passing ?build_vignettes=FALSE? to install_bitbucket? Else I think violet comes from the xcolor package.

Alexios

On 28 May 2014, at 18:35, Mark Knecht <markknecht at gmail.com> wrote:

> Thanks Alexios. "jsu" returns a solution quickly. The sigma and
> quantile plots appear to be pretty much identical to what was in your
> paper. The skewness and kertosis plots do look somewhat different but
> I expect that's probably cause by using this different model.
> 
> Anyway, the code as supplied in the paper works fine now.
> 
> The last issue is not overly important but twinkle didn't install due
> to (I think) some missing color definitions in Latex. I'll need to see
> if I can find some info on fixing that but the hard stuff appears to
> be working.
> 
> Cheers,
> Mark
> 
> 
> Installing twinkle
> '/usr/lib64/R/bin/R' --vanilla CMD build
> '/tmp/Rtmp5b80e3/devtools9e055940c74/alexiosg-twinkle-9461ed2d91a9'  \
>  --no-manual --no-resave-data
> 
> * checking for file
> '/tmp/Rtmp5b80e3/devtools9e055940c74/alexiosg-twinkle-9461ed2d91a9/DESCRIPTION'
> ... OK
> * preparing 'twinkle':
> * checking DESCRIPTION meta-information ... OK
> * cleaning src
> * installing the package to build vignettes
> * creating vignettes ... ERROR
> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>  Running 'texi2dvi' on 'The_Twinkle_Package.tex' failed.
> LaTeX errors:
> ! LaTeX Error: Undefined color `violet'.
> 
> See the LaTeX manual or LaTeX Companion for explanation.
> Type  H <return>  for immediate help.
> ...
> ! LaTeX Error: Undefined color `violet'.
> 
> 
> 
> 
> On Wed, May 28, 2014 at 10:10 AM, Alexios Ghalanos <alexios at 4dscape.com> wrote:
>> Hi Mark,
>> 
>> You are probably using the nig or ghyp distributions which do not have a closed form quantile function so it is evaluating it for every point (which is expensive!). Try the jsu distribution instead...it is very flexible and fast to evaluate.
>> 
>> Best,
>> 
>> Alexios
>> 
>>> On 28 May 2014, at 16:13, Mark Knecht <markknecht at gmail.com> wrote:
>>> 
>>> Thanks Alexios. With a bit of guessing about Latex packages I got the
>>> appendix directory installed and the R code runs. (Mostly - The first
>>> 3 plots are created. I've been waiting for about 20 minutes for the
>>> quantile plot to finish but no results on that one yet.
>>> 
>>> Anyway, it works well enough for me to go a bit deeper now.
>>> 
>>> Cheers,
>>> Mark
>>> 
>>>> On Tue, May 27, 2014 at 2:08 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
>>>> Hi Mark,
>>>> 
>>>> 1. Have a look at the "install_bitbucket" documentation. There is the
>>>> option I believe to pass some extra arguments to "install" via '...'.
>>>> Specifically the "dependencies" (logical) and "build_vignettes" arguments.
>>>> 2. You need to have the "appendix" package in your latex installation
>>>> (see the documentation of your linux flavor on how to do this).
>>>> 3. fftw on CRAN builds ok for everything but OSX Mavericks...I may
>>>> remove it going forward and use the base implementation to avoid too
>>>> many problematic dependencies, but would welcome any feedback on speed
>>>> comparisons.
>>>> 
>>>> Best,
>>>> 
>>>> Alexios
>>>> 
>>>>> On 27/05/2014 21:43, Mark Knecht wrote:
>>>>>> On Tue, May 27, 2014 at 12:59 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
>>>>>> Since 2013 the development repository for my packages has moved (a
>>>>>> couple of time). See:
>>>>>> http://www.unstarched.net/r-downloads/
>>>>>> for latest details.
>>>>>> 
>>>>>> -Alexios
>>>>> 
>>>>> Thanks Alexios. I started reading that based on Pierre's response but
>>>>> I'm hung up:
>>>>> 
>>>>> 1) I needed the fftw  package to install but it wouldn't as it was not
>>>>> finding fftw3. I then  found fftw-3.3.3-r2 in Gentoo portage and think
>>>>> I got past that problem.
>>>>> 
>>>>> 2) I'm now just trying to install all the packages shown on yor
>>>>> r-downloads page but rmgarch won't install apparently due to (I think)
>>>>> Latex issues. I got as far as failing due to something called texi2dvi
>>>>> which I found and installed from portage again, but now I have this
>>>>> problem due to a missing appendix.sty file I think.
>>>>> 
>>>>> Thanks for any pointers into what I'm doing wrong here.
>>>>> 
>>>>> Cheers,
>>>>> Mark
>>>>> 
>>>>> 
>>>>> R version 3.1.0 (2014-04-10) -- "Spring Dance"
>>>>> Copyright (C) 2014 The R Foundation for Statistical Computing
>>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>>> 
>>>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>>>> You are welcome to redistribute it under certain conditions.
>>>>> Type 'license()' or 'licence()' for distribution details.
>>>>> 
>>>>> R is a collaborative project with many contributors.
>>>>> Type 'contributors()' for more information and
>>>>> 'citation()' on how to cite R or R packages in publications.
>>>>> 
>>>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>>>> 'help.start()' for an HTML browser interface to help.
>>>>> Type 'q()' to quit R.
>>>>> 
>>>>>> require(devtools)
>>>>> Loading required package: devtools
>>>>> 
>>>>> Attaching package: ?devtools?
>>>>> 
>>>>> The following objects are masked from ?package:utils?:
>>>>> 
>>>>>   ?, help
>>>>> 
>>>>> The following object is masked from ?package:base?:
>>>>> 
>>>>>   system.file
>>>>> 
>>>>>> install_bitbucket("rmgarch","alexiosg")
>>>>> Installing bitbucket repo(s) rmgarch/master from alexiosg
>>>>> Downloading master.zip from
>>>>> https://bitbucket.org/alexiosg/rmgarch/get/master.zip
>>>>> Installing package from /tmp/Rtmpwt0Tnh/master.zip
>>>>> arguments 'minimized' and 'invisible' are for Windows only
>>>>> Installing rmgarch
>>>>> '/usr/lib64/R/bin/R' --vanilla CMD build
>>>>> '/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925'
>>>>> \
>>>>> --no-manual --no-resave-data
>>>>> 
>>>>> * checking for file
>>>>> '/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925/DESCRIPTION'
>>>>> ... OK
>>>>> * preparing 'rmgarch':
>>>>> * checking DESCRIPTION meta-information ... OK
>>>>> * cleaning src
>>>>> * installing the package to build vignettes
>>>>> * creating vignettes ... ERROR
>>>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>>>>> Running 'texi2dvi' on 'The_rmgarch_models.tex' failed.
>>>>> LaTeX errors:
>>>>> ! LaTeX Error: File `appendix.sty' not found.
>>>>> 
>>>>> Type X to quit or <RETURN> to proceed,
>>>>> or enter new name. (Default extension: sty)
>>>>> 
>>>>> ! Emergency stop.
>>>>> <read *>
>>>>> 
>>>>> l.9 \usepackage
>>>>>              [round]{natbib}^^M
>>>>> !  ==> Fatal error occurred, no output PDF file produced!
>>>>> Calls: <Anonymous> -> texi2pdf -> texi2dvi
>>>>> Execution halted
>>>>> Error: Command failed (1)
>>>>> 
>>>>>> 
>>>>> 
>>>>> 
>>>> 
>>> 
> 


From markknecht at gmail.com  Wed May 28 23:30:46 2014
From: markknecht at gmail.com (Mark Knecht)
Date: Wed, 28 May 2014 14:30:46 -0700
Subject: [R-SIG-Finance] Time Varying Higher Moments - racd?
In-Reply-To: <8AD115E4-ED67-4BB9-A9FD-9397EF3FD49B@4dscape.com>
References: <CAK2H+efzgZ-uDsVqGs_cPCmJCJhEXL42C7dMWD405d9xdc1k-w@mail.gmail.com>
	<CAPPM_gTntMs7AWDCSBd0BCrioe16dOx9vXVU8qo-e_bFDGzXFA@mail.gmail.com>
	<5384EE90.2080309@4dscape.com>
	<CAK2H+eeyHukPn0L0XaUzU2VjetX4-HAEUfCMgRwqPmTxA0GUrw@mail.gmail.com>
	<5384FEE8.5060704@4dscape.com>
	<CAK2H+edkd8U+TXAmpcZowmHCmD-pPAvx2FJFW0Q-KUV2zQWhCg@mail.gmail.com>
	<27D96CA5-36CB-41AD-80B2-2C1550FA5007@4dscape.com>
	<CAK2H+ec76V1OpJX_8Xg1tk6=b=fAhoEx9vX1N7pF0sGYNBdk7w@mail.gmail.com>
	<8AD115E4-ED67-4BB9-A9FD-9397EF3FD49B@4dscape.com>
Message-ID: <CAK2H+ecUA__BM+tZ=1rGHa2bxn0deO+uOP8-tuHoR9Hq3q4p1Q@mail.gmail.com>

Alexios,
   build_vignettes=FALSE allows twinkle to install without error.

   xcolor was already installed but it appears to put stuff in a
slightly different latex path:

/usr/share/texmf-site/tex/latex/xcolor/xcolor.sty

vs

/usr/share/texmf-dist/tex/latex/appendix/appendix.sty

   I know nothing about latex at all and this is using much more of
your time than I intended so I'm not sure we should go much further at
this point but if there's something here to fix I'm happy to help.

Cheers,
Mark


mark at c2RAID6 ~ $ equery files xcolor
 * Searching for xcolor ...
 * Contents of dev-tex/xcolor-2.11:
/usr
/usr/share
/usr/share/doc
/usr/share/doc/xcolor-2.11
/usr/share/doc/xcolor-2.11/ChangeLog.bz2
/usr/share/doc/xcolor-2.11/README.bz2
/usr/share/doc/xcolor-2.11/xcolor.pdf
/usr/share/doc/xcolor-2.11/xcolor1.dvi
/usr/share/doc/xcolor-2.11/xcolor2.pdf
/usr/share/doc/xcolor-2.11/xcolor3.dvi
/usr/share/doc/xcolor-2.11/xcolor4.dvi
/usr/share/texmf-site
/usr/share/texmf-site/doc
/usr/share/texmf-site/doc/latex
/usr/share/texmf-site/doc/latex/xcolor
/usr/share/texmf-site/doc/latex/xcolor/xcolor.pdf ->
/usr/share/doc/xcolor-2.11/xcolor.pdf
/usr/share/texmf-site/doc/latex/xcolor/xcolor1.dvi ->
/usr/share/doc/xcolor-2.11/xcolor1.dvi
/usr/share/texmf-site/doc/latex/xcolor/xcolor2.pdf ->
/usr/share/doc/xcolor-2.11/xcolor2.pdf
/usr/share/texmf-site/doc/latex/xcolor/xcolor3.dvi ->
/usr/share/doc/xcolor-2.11/xcolor3.dvi
/usr/share/texmf-site/doc/latex/xcolor/xcolor4.dvi ->
/usr/share/doc/xcolor-2.11/xcolor4.dvi
/usr/share/texmf-site/tex
/usr/share/texmf-site/tex/latex
/usr/share/texmf-site/tex/latex/xcolor
/usr/share/texmf-site/tex/latex/xcolor/svgnam.def
/usr/share/texmf-site/tex/latex/xcolor/x11nam.def
/usr/share/texmf-site/tex/latex/xcolor/xcolor.sty
mark at c2RAID6 ~ $ locate appendix.sty
/usr/share/texmf-dist/tex/latex/appendix/appendix.sty
/usr/share/texmf-dist/tex/latex/interfaces/interfaces-appendix.sty
/usr/share/texmf-dist/tex/latex/ltxmisc/thrmappendix.sty
mark at c2RAID6 ~ $

On Wed, May 28, 2014 at 11:01 AM, alexios ghalanos <alexios at 4dscape.com> wrote:
> Mark,
>
> Have you tried passing ?build_vignettes=FALSE? to install_bitbucket? Else I think violet comes from the xcolor package.
>
> Alexios
>
> On 28 May 2014, at 18:35, Mark Knecht <markknecht at gmail.com> wrote:
>
>> Thanks Alexios. "jsu" returns a solution quickly. The sigma and
>> quantile plots appear to be pretty much identical to what was in your
>> paper. The skewness and kertosis plots do look somewhat different but
>> I expect that's probably cause by using this different model.
>>
>> Anyway, the code as supplied in the paper works fine now.
>>
>> The last issue is not overly important but twinkle didn't install due
>> to (I think) some missing color definitions in Latex. I'll need to see
>> if I can find some info on fixing that but the hard stuff appears to
>> be working.
>>
>> Cheers,
>> Mark
>>
>>
>> Installing twinkle
>> '/usr/lib64/R/bin/R' --vanilla CMD build
>> '/tmp/Rtmp5b80e3/devtools9e055940c74/alexiosg-twinkle-9461ed2d91a9'  \
>>  --no-manual --no-resave-data
>>
>> * checking for file
>> '/tmp/Rtmp5b80e3/devtools9e055940c74/alexiosg-twinkle-9461ed2d91a9/DESCRIPTION'
>> ... OK
>> * preparing 'twinkle':
>> * checking DESCRIPTION meta-information ... OK
>> * cleaning src
>> * installing the package to build vignettes
>> * creating vignettes ... ERROR
>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>>  Running 'texi2dvi' on 'The_Twinkle_Package.tex' failed.
>> LaTeX errors:
>> ! LaTeX Error: Undefined color `violet'.
>>
>> See the LaTeX manual or LaTeX Companion for explanation.
>> Type  H <return>  for immediate help.
>> ...
>> ! LaTeX Error: Undefined color `violet'.
>>
>>
>>
>>
>> On Wed, May 28, 2014 at 10:10 AM, Alexios Ghalanos <alexios at 4dscape.com> wrote:
>>> Hi Mark,
>>>
>>> You are probably using the nig or ghyp distributions which do not have a closed form quantile function so it is evaluating it for every point (which is expensive!). Try the jsu distribution instead...it is very flexible and fast to evaluate.
>>>
>>> Best,
>>>
>>> Alexios
>>>
>>>> On 28 May 2014, at 16:13, Mark Knecht <markknecht at gmail.com> wrote:
>>>>
>>>> Thanks Alexios. With a bit of guessing about Latex packages I got the
>>>> appendix directory installed and the R code runs. (Mostly - The first
>>>> 3 plots are created. I've been waiting for about 20 minutes for the
>>>> quantile plot to finish but no results on that one yet.
>>>>
>>>> Anyway, it works well enough for me to go a bit deeper now.
>>>>
>>>> Cheers,
>>>> Mark
>>>>
>>>>> On Tue, May 27, 2014 at 2:08 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
>>>>> Hi Mark,
>>>>>
>>>>> 1. Have a look at the "install_bitbucket" documentation. There is the
>>>>> option I believe to pass some extra arguments to "install" via '...'.
>>>>> Specifically the "dependencies" (logical) and "build_vignettes" arguments.
>>>>> 2. You need to have the "appendix" package in your latex installation
>>>>> (see the documentation of your linux flavor on how to do this).
>>>>> 3. fftw on CRAN builds ok for everything but OSX Mavericks...I may
>>>>> remove it going forward and use the base implementation to avoid too
>>>>> many problematic dependencies, but would welcome any feedback on speed
>>>>> comparisons.
>>>>>
>>>>> Best,
>>>>>
>>>>> Alexios
>>>>>
>>>>>> On 27/05/2014 21:43, Mark Knecht wrote:
>>>>>>> On Tue, May 27, 2014 at 12:59 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
>>>>>>> Since 2013 the development repository for my packages has moved (a
>>>>>>> couple of time). See:
>>>>>>> http://www.unstarched.net/r-downloads/
>>>>>>> for latest details.
>>>>>>>
>>>>>>> -Alexios
>>>>>>
>>>>>> Thanks Alexios. I started reading that based on Pierre's response but
>>>>>> I'm hung up:
>>>>>>
>>>>>> 1) I needed the fftw  package to install but it wouldn't as it was not
>>>>>> finding fftw3. I then  found fftw-3.3.3-r2 in Gentoo portage and think
>>>>>> I got past that problem.
>>>>>>
>>>>>> 2) I'm now just trying to install all the packages shown on yor
>>>>>> r-downloads page but rmgarch won't install apparently due to (I think)
>>>>>> Latex issues. I got as far as failing due to something called texi2dvi
>>>>>> which I found and installed from portage again, but now I have this
>>>>>> problem due to a missing appendix.sty file I think.
>>>>>>
>>>>>> Thanks for any pointers into what I'm doing wrong here.
>>>>>>
>>>>>> Cheers,
>>>>>> Mark
>>>>>>
>>>>>>
>>>>>> R version 3.1.0 (2014-04-10) -- "Spring Dance"
>>>>>> Copyright (C) 2014 The R Foundation for Statistical Computing
>>>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>>>>
>>>>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>>>>> You are welcome to redistribute it under certain conditions.
>>>>>> Type 'license()' or 'licence()' for distribution details.
>>>>>>
>>>>>> R is a collaborative project with many contributors.
>>>>>> Type 'contributors()' for more information and
>>>>>> 'citation()' on how to cite R or R packages in publications.
>>>>>>
>>>>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>>>>> 'help.start()' for an HTML browser interface to help.
>>>>>> Type 'q()' to quit R.
>>>>>>
>>>>>>> require(devtools)
>>>>>> Loading required package: devtools
>>>>>>
>>>>>> Attaching package: ?devtools?
>>>>>>
>>>>>> The following objects are masked from ?package:utils?:
>>>>>>
>>>>>>   ?, help
>>>>>>
>>>>>> The following object is masked from ?package:base?:
>>>>>>
>>>>>>   system.file
>>>>>>
>>>>>>> install_bitbucket("rmgarch","alexiosg")
>>>>>> Installing bitbucket repo(s) rmgarch/master from alexiosg
>>>>>> Downloading master.zip from
>>>>>> https://bitbucket.org/alexiosg/rmgarch/get/master.zip
>>>>>> Installing package from /tmp/Rtmpwt0Tnh/master.zip
>>>>>> arguments 'minimized' and 'invisible' are for Windows only
>>>>>> Installing rmgarch
>>>>>> '/usr/lib64/R/bin/R' --vanilla CMD build
>>>>>> '/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925'
>>>>>> \
>>>>>> --no-manual --no-resave-data
>>>>>>
>>>>>> * checking for file
>>>>>> '/tmp/Rtmpwt0Tnh/devtools2a9e1a643c4a/alexiosg-rmgarch-d012deb54925/DESCRIPTION'
>>>>>> ... OK
>>>>>> * preparing 'rmgarch':
>>>>>> * checking DESCRIPTION meta-information ... OK
>>>>>> * cleaning src
>>>>>> * installing the package to build vignettes
>>>>>> * creating vignettes ... ERROR
>>>>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>>>>>> Running 'texi2dvi' on 'The_rmgarch_models.tex' failed.
>>>>>> LaTeX errors:
>>>>>> ! LaTeX Error: File `appendix.sty' not found.
>>>>>>
>>>>>> Type X to quit or <RETURN> to proceed,
>>>>>> or enter new name. (Default extension: sty)
>>>>>>
>>>>>> ! Emergency stop.
>>>>>> <read *>
>>>>>>
>>>>>> l.9 \usepackage
>>>>>>              [round]{natbib}^^M
>>>>>> !  ==> Fatal error occurred, no output PDF file produced!
>>>>>> Calls: <Anonymous> -> texi2pdf -> texi2dvi
>>>>>> Execution halted
>>>>>> Error: Command failed (1)
>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>
>>
>


From walmir-rodrigues at uol.com.br  Fri May 30 19:26:26 2014
From: walmir-rodrigues at uol.com.br (walmir-rodrigues)
Date: Fri, 30 May 2014 14:26:26 -0300
Subject: [R-SIG-Finance] simple question
Message-ID: <5388bf42935da_43e548402c19845@a4-weasel19.mail>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140530/be3a87bf/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Indices.csv
Type: text/csv
Size: 170415 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140530/be3a87bf/attachment.bin>

From clay9 at outlook.com  Mon Jun  2 05:59:38 2014
From: clay9 at outlook.com (Clay .)
Date: Sun, 1 Jun 2014 23:59:38 -0400
Subject: [R-SIG-Finance] Unable to run the risk stops in the quantstrat
	"macd" demo?
Message-ID: <BAY182-W9CF4B62506FF9E97D7D03F2200@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140601/04155d35/attachment.pl>

From clay9 at outlook.com  Tue Jun  3 21:42:06 2014
From: clay9 at outlook.com (Clay .)
Date: Tue, 3 Jun 2014 15:42:06 -0400
Subject: [R-SIG-Finance] Unable to run the risk stops in the quantstrat
 "macd" demo?
In-Reply-To: <BAY182-W9CF4B62506FF9E97D7D03F2200@phx.gbl>
References: <BAY182-W9CF4B62506FF9E97D7D03F2200@phx.gbl>
Message-ID: <BAY182-W2280AA2CA0A00FBED70310F2230@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140603/6caaafae/attachment.pl>

From efm at linsomniac.com  Wed Jun  4 16:41:45 2014
From: efm at linsomniac.com (Evelyn Mitchell)
Date: Wed, 04 Jun 2014 08:41:45 -0600
Subject: [R-SIG-Finance] MACD demo fix
Message-ID: <538F3029.5040207@linsomniac.com>

I've fixed the quantstrat macd demo to save and restore the time zone.

Thank you Clay9 for reporting this.

Evelyn Mitchell
efm at linsomniac.com


From wilson.freitas at gmail.com  Sun Jun  8 23:38:45 2014
From: wilson.freitas at gmail.com (Wilson Freitas)
Date: Sun, 8 Jun 2014 18:38:45 -0300
Subject: [R-SIG-Finance] simple question
In-Reply-To: <5388bf42935da_43e548402c19845@a4-weasel19.mail>
References: <5388bf42935da_43e548402c19845@a4-weasel19.mail>
Message-ID: <CANOw85rNeYp2A7qeSuw=31FD-PP9ebFWoh=+B8M9QoBoQPcYqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140608/1d640f2c/attachment.pl>

From wuertz at phys.ethz.ch  Tue Jun 10 09:07:47 2014
From: wuertz at phys.ethz.ch (Diethelm Wuertz)
Date: Tue, 10 Jun 2014 09:07:47 +0200
Subject: [R-SIG-Finance] R/Rmetrics Paris 26-28 June 2014
Message-ID: <C5FFD3A0-5A1A-40C0-B721-4845948A3A40@phys.ethz.ch>



*** FINAL ANNOUNCEMENT ***


R/Rmetrics in Finance and Insurance: www.rmetrics.org
8th R/Rmetrics Workshop and Summer School
First Shiny App Contest, Paris, 26-?28 June 2014


After seven successful years at Meielisalp, the R/Rmetrics
Workshop and Summer School moves to the Latin Quarter of Paris.

The workshop consists of Summer School like tutorial sessions and 
a user/developer meeting. The workshop will focus on computational 
issues in statistics, empirical finance and insurance.

Key Note Presentations:
	Christian Robert
		Bayesian Inference and Markov Chain Monte Carlo
	Jean-Philippe Bouchaud:
		Anomalous Price Impact and Critical Liquidity 
	Frederic Planchet:
		Economic Scenario Generation: Theory and Practice
	
Portfolio Design Tutorial --
	Diethelm Wuertz:
	Bayesian Stability and Morphological Shape Factors

In addition we have several contributed talks and presentations 
from the first R Shiny Contest.

>>>>> Registration and Paper Submissions are on a rolling base 
and still open: https://sites.google.com/site/rmetricsparis2014

We would very appreciate it to welcome you in Paris
For the organization Committee:
Patrick Henaff and Diethelm Wuertz


If you have any questions, please contact:  info at rmetrics.org


PS:
Please also note the satellite events in Zurich, 20/21 June:
"How to get the Most out of R Studio and Shiny",  and 
"How to Speed up your R Performance": www.rmetrics.org


From wuertz at phys.ethz.ch  Tue Jun 10 10:23:50 2014
From: wuertz at phys.ethz.ch (Diethelm Wuertz)
Date: Tue, 10 Jun 2014 10:23:50 +0200
Subject: [R-SIG-Finance] R Shiny
Message-ID: <F0849D72-1AE1-45CB-AECF-5A0E1ECCE517@phys.ethz.ch>

*** FINAL ANNOUNCEMENT ***


First Shiny App Contest in Finance and Insurance
A Satellite Event to the R/Rmetrics Meeting 
Paris, 26-?28 June 2014


The Rmetrics Open Source Association organizes the ?1st Shiny 
App Contest? for web applications in Finance and Insurance 
as a Satellite Event to the 8th  R/Rmetrics Workshop held in 
Paris, 26 ? 28 June, 2014. 

?Shiny makes it super simple for R users to turn analyses into 
interactive web applications that anyone can use. Users can 
choose input parameters using friendly controls like sliders, 
dropdowns, and text fields. They can incorporate any number of 
outputs like plots, tables, and summaries. Shiny makes HTML
or JavaScript knowledge obsolete. With some experience in R 
one can combine the statistical power of R with the simplicity 
of a web page.? 

We invite the subsmission of Shiny applications presenting 
innovations covering the whole spectrum of topics in finance, 
insurance and related fields. To submit your Shiny application, 
first get in contact with us, mail to: submissions at rmetrics.org. 

For the upload of your app we provide a Shiny Server. 
Submissions will be considered on a rolling admission basis, 
there is no definite deadline. 

The applications will be presented and discussed in a special 
session. The Workshop participants can judge on the best app, 
which will be honored with a certificate and a price sponsored 
by Rmetrics Association and RStudio.  




Rmetrics Association
For the Oranisation Committee
Patrick Henaff and Diethelm W?rtz



www.rmetrics.org

From 2427580722 at qq.com  Fri Jun 13 09:40:41 2014
From: 2427580722 at qq.com (=?ISO-8859-1?B?QWx1?=)
Date: Fri, 13 Jun 2014 15:40:41 +0800
Subject: [R-SIG-Finance] Does the current packages support getting the
	sector->industry(for example Money Center Bks (^YHOh750))
	data from yahoo?
Message-ID: <tencent_1D513A597EFC11DF3EE579F0@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140613/18b0a27c/attachment.pl>

From josh.m.ulrich at gmail.com  Fri Jun 13 12:39:37 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 13 Jun 2014 05:39:37 -0500
Subject: [R-SIG-Finance] Does the current packages support getting the
 sector->industry(for example Money Center Bks (^YHOh750)) data from yahoo?
In-Reply-To: <tencent_1D513A597EFC11DF3EE579F0@qq.com>
References: <tencent_1D513A597EFC11DF3EE579F0@qq.com>
Message-ID: <CAPPM_gQjjEGMvRTQJkR-GAL6zy2CignAem=QS0fF1XQ85Za2RQ@mail.gmail.com>

On Fri, Jun 13, 2014 at 2:40 AM, Alu <2427580722 at qq.com> wrote:
> Dears, Does the current packages support getting the sector->industry(for example Money Center Bks (^YHOh750)) data from yahoo? I have tried "getSymbols("^YHOh750", src="yahoo", from="2014-01-01", to="2014-01-20")" , it seems that it doesn't work, any ideas?
>         [[alternative HTML version deleted]]
>
"Doesn't work" is not helpful when describing a problem.  In this
case, the error tells you exactly why it doesn't work.

> getSymbols("^YHOh750", src="yahoo", from="2014-01-01", to="2014-01-20")
Error in download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
  cannot open URL
'http://chart.yahoo.com/table.csv?s=^YHOh750&a=0&b=01&c=2014&d=0&e=20&f=2014&g=d&q=q&y=0&z=^YHOh750&x=.csv'
In addition: Warning message:
In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
  cannot open: HTTP status was '404 Not Found'

The historical data do not exist on Yahoo, so you shouldn't expect
getSymbols to be able to somehow "work".

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From jzmoser at gmail.com  Sat Jun 14 19:25:01 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Sat, 14 Jun 2014 19:25:01 +0200
Subject: [R-SIG-Finance] News impact curves for various GARCH models in the
	rugarch-package
Message-ID: <539C856D.5000604@googlemail.com>

Dear all,

I'm working with the really nice "rugarch"-package and currently have an 
issue with respect to the news impact curves (NIC).

In an attempt to plot several NIC into the same plot I realized that 
while the NIC for the sGARCH, the gjrGARCH and the eGARCH are given with 
respect to the epsilon_{t-1}, the NICs for the submodels of the fGARCH 
model are given in terms of z_{t-1}.

Firstly I am a bit confused since just like the fGARCH model, the eGARCH 
model (as to the eGARCH-model-setup in the vignette) is also given in 
terms of the z_{t-k} , k={1,...,q}.
But nevertheless the NIC of the eGARCH is given in terms of epsilon_{t-1} .
At least this is what the "newsimpact(fit)"-output tells me.
Why is it this way for the eGARCH but not for the fGARCH?

Secondly I'd like to have the NIC of all the different models depending 
on the epsilon_{t-1} for better comparison.
So for the fGARCH case I thought about calculating the epsilon_{t-1} 
values given the z_{t-1} values and the conditional mean and volatility.
Is this a good idea or is there an important reason why the NICs for the 
fGARCH submodels are NOT given this way?

Many thanks and kind regards,
Johannes


From jzmoser at gmail.com  Sun Jun 15 10:53:14 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Sun, 15 Jun 2014 10:53:14 +0200
Subject: [R-SIG-Finance] News impact curves for various GARCH models in
	the rugarch-package
In-Reply-To: <539C856D.5000604@googlemail.com>
References: <539C856D.5000604@googlemail.com>
Message-ID: <539D5EFA.6050509@googlemail.com>

After having slept on it for a nightI now think that both the fGARCH 
submodels (I am especially interested in the NAGARCH) and the eGARCH 
model have a NIC that has to be expressed in terms of the z_{t-1} since 
in both cases the effect of epsilon_{t-1} on sigma_t does depend on 
sigma_{t-1} which is of course nonconstant.

But as stated before, the "newsimpact(fit)"-output of the eGARCH model 
tells me that here the NIC was given in terms of epsilon_{t-1}.
Is this a typo?  Should it mean "z_{t-1}"?


Am 2014-06-14 7:25 PM, schrieb Johannes Moser:
> Dear all,
>
> I'm working with the really nice "rugarch"-package and currently have 
> an issue with respect to the news impact curves (NIC).
>
> In an attempt to plot several NIC into the same plot I realized that 
> while the NIC for the sGARCH, the gjrGARCH and the eGARCH are given 
> with respect to the epsilon_{t-1}, the NICs for the submodels of the 
> fGARCH model are given in terms of z_{t-1}.
>
> Firstly I am a bit confused since just like the fGARCH model, the 
> eGARCH model (as to the eGARCH-model-setup in the vignette) is also 
> given in terms of the z_{t-k} , k={1,...,q}.
> But nevertheless the NIC of the eGARCH is given in terms of 
> epsilon_{t-1} .
> At least this is what the "newsimpact(fit)"-output tells me.
> Why is it this way for the eGARCH but not for the fGARCH?
>
> Secondly I'd like to have the NIC of all the different models 
> depending on the epsilon_{t-1} for better comparison.
> So for the fGARCH case I thought about calculating the epsilon_{t-1} 
> values given the z_{t-1} values and the conditional mean and volatility.
> Is this a good idea or is there an important reason why the NICs for 
> the fGARCH submodels are NOT given this way?
>
> Many thanks and kind regards,
> Johannes
>

--


From alexios at 4dscape.com  Sun Jun 15 11:16:31 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sun, 15 Jun 2014 10:16:31 +0100
Subject: [R-SIG-Finance] News impact curves for various GARCH models in
 the rugarch-package
In-Reply-To: <539D5EFA.6050509@googlemail.com>
References: <539C856D.5000604@googlemail.com> <539D5EFA.6050509@googlemail.com>
Message-ID: <539D646F.7080001@4dscape.com>

No, it doesn't "have to be" expressed in that way...but instead of
sleeping on it and writing ANOTHER email to this list before your first
one was answered, you could perhaps have looked at the source code, seen
how it was done, adjusted what you want for your own purpose or if you
found something which merited serious rethink, suggest a patch to the
developer.

-Alexios


On 15/06/2014 09:53, Johannes Moser wrote:
> After having slept on it for a nightI now think that both the fGARCH
> submodels (I am especially interested in the NAGARCH) and the eGARCH
> model have a NIC that has to be expressed in terms of the z_{t-1} since
> in both cases the effect of epsilon_{t-1} on sigma_t does depend on
> sigma_{t-1} which is of course nonconstant.
> 
> But as stated before, the "newsimpact(fit)"-output of the eGARCH model
> tells me that here the NIC was given in terms of epsilon_{t-1}.
> Is this a typo?  Should it mean "z_{t-1}"?
> 
> 
> Am 2014-06-14 7:25 PM, schrieb Johannes Moser:
>> Dear all,
>>
>> I'm working with the really nice "rugarch"-package and currently have
>> an issue with respect to the news impact curves (NIC).
>>
>> In an attempt to plot several NIC into the same plot I realized that
>> while the NIC for the sGARCH, the gjrGARCH and the eGARCH are given
>> with respect to the epsilon_{t-1}, the NICs for the submodels of the
>> fGARCH model are given in terms of z_{t-1}.
>>
>> Firstly I am a bit confused since just like the fGARCH model, the
>> eGARCH model (as to the eGARCH-model-setup in the vignette) is also
>> given in terms of the z_{t-k} , k={1,...,q}.
>> But nevertheless the NIC of the eGARCH is given in terms of
>> epsilon_{t-1} .
>> At least this is what the "newsimpact(fit)"-output tells me.
>> Why is it this way for the eGARCH but not for the fGARCH?
>>
>> Secondly I'd like to have the NIC of all the different models
>> depending on the epsilon_{t-1} for better comparison.
>> So for the fGARCH case I thought about calculating the epsilon_{t-1}
>> values given the z_{t-1} values and the conditional mean and volatility.
>> Is this a good idea or is there an important reason why the NICs for
>> the fGARCH submodels are NOT given this way?
>>
>> Many thanks and kind regards,
>> Johannes
>>
> 
> -- 
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
> 
>


From aschmid1 at stevens.edu  Sun Jun 15 15:58:31 2014
From: aschmid1 at stevens.edu (aschmid1)
Date: Sun, 15 Jun 2014 09:58:31 -0400
Subject: [R-SIG-Finance] News impact curves for various GARCH models in
 the rugarch-package
In-Reply-To: <539D5EFA.6050509@googlemail.com>
References: <539C856D.5000604@googlemail.com> <539D5EFA.6050509@googlemail.com>
Message-ID: <bd2c71c0a10e106045694caa9f89bfba@stevens.edu>

For those interested in news impact, I actually implemented a 
rugarch-based model for analysis of macroeconomic announcements:
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2364077

Regards, Alec

On 06/15/2014 4:53 AM, Johannes Moser wrote:
> After having slept on it for a nightI now think that both the fGARCH
> submodels (I am especially interested in the NAGARCH) and the eGARCH
> model have a NIC that has to be expressed in terms of the z_{t-1}
> since in both cases the effect of epsilon_{t-1} on sigma_t does depend
> on sigma_{t-1} which is of course nonconstant.
> 
> But as stated before, the "newsimpact(fit)"-output of the eGARCH model
> tells me that here the NIC was given in terms of epsilon_{t-1}.
> Is this a typo?  Should it mean "z_{t-1}"?
> 
> 
> Am 2014-06-14 7:25 PM, schrieb Johannes Moser:
>> Dear all,
>> 
>> I'm working with the really nice "rugarch"-package and currently have 
>> an issue with respect to the news impact curves (NIC).
>> 
>> In an attempt to plot several NIC into the same plot I realized that 
>> while the NIC for the sGARCH, the gjrGARCH and the eGARCH are given 
>> with respect to the epsilon_{t-1}, the NICs for the submodels of the 
>> fGARCH model are given in terms of z_{t-1}.
>> 
>> Firstly I am a bit confused since just like the fGARCH model, the 
>> eGARCH model (as to the eGARCH-model-setup in the vignette) is also 
>> given in terms of the z_{t-k} , k={1,...,q}.
>> But nevertheless the NIC of the eGARCH is given in terms of 
>> epsilon_{t-1} .
>> At least this is what the "newsimpact(fit)"-output tells me.
>> Why is it this way for the eGARCH but not for the fGARCH?
>> 
>> Secondly I'd like to have the NIC of all the different models 
>> depending on the epsilon_{t-1} for better comparison.
>> So for the fGARCH case I thought about calculating the epsilon_{t-1} 
>> values given the z_{t-1} values and the conditional mean and 
>> volatility.
>> Is this a good idea or is there an important reason why the NICs for 
>> the fGARCH submodels are NOT given this way?
>> 
>> Many thanks and kind regards,
>> Johannes
>> 
> 
> --
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R
> questions should go.


From pierre at lequeux.org  Mon Jun 16 11:00:10 2014
From: pierre at lequeux.org (pierrelequeux)
Date: Mon, 16 Jun 2014 02:00:10 -0700 (PDT)
Subject: [R-SIG-Finance] fPortfolio and maxreturnPortfolio
Message-ID: <1402909210175-4692180.post@n4.nabble.com>

I am trying to use the maxreturnPortfolio  to maximise the return of a
multiasset portfolio for a given level of risk. Somehow I do not seem to be
able to produce any result with it. As anyone used this before and could
give me a sample code on how to use it. basically I have a matrix of etf and
try to generate a portfolio for 10% target risk. my code is as follows:


rm(list=ls(all=TRUE))

library(quantmod)
library(PerformanceAnalytics)
require(fPortfolio)

ETF <-  c('VGSIX','VUSTX','VGTSX','VFISX','VTSMX','VFITX','VEIEX','VIPSX')
getSymbols(ETF,source = 'yahoo')
datamat <-
as.xts(cbind(get("VGTSX")[,4],get("VTSMX")[,4],get("VEIEX")[,4],get("VGSIX")[,4],get("VUSTX")[,4],get("VFITX")[,4],get("VFISX")[,4],get("VIPSX")[,4]))

datamatrix <-  apply(datamat,2,function(x) diff(log(x)))

colnames(datamatrix) <-  c('Global Equities Ex US','US Equities','Emerging
Markets Stocks',"REITs",'Treasuries 15 - 30Y','Treasuries 5-10Y','Treasuries
1-4Y','US Inflation Linked 7 - 20Y')
datamatrix <- as.xts(datamatrix)
Spec <- portfolioSpec()
setTargetRisk(Spec)  <- 0.10
maxreturnPortfolio(as.timeSeries(datamatrix),spec=Spec,constraints="LongOnly")




Whatever the risk target I set I get zero weights for all of the assets.
What  I get from my R session is as below. :

Title:
 MV Return Maximized Efficient Portfolio 
 Estimator:         covEstimator 
 Solver:            solveRquadprog 
 Optimize:          maxReturn 
 Constraints:       LongOnly 

Portfolio Weights:
      Global Equities Ex US                 US Equities     Emerging Markets
Stocks                       REITs 
                          0                           0                          
0                           0 
        Treasuries 15 - 30Y            Treasuries 5-10Y            
Treasuries 1-4Y US Inflation Linked 7 - 20Y 
                          0                           0                          
0                           0 

Covariance Risk Budgets:
      Global Equities Ex US                 US Equities     Emerging Markets
Stocks                       REITs 
                                                                                                                
        Treasuries 15 - 30Y            Treasuries 5-10Y            
Treasuries 1-4Y US Inflation Linked 7 - 20Y 
                                                                                                                

Target Return and Risks:
 mean    mu   Cov Sigma  CVaR   VaR 
    0     0     0     0     0     0 

Description:
 Mon Jun 16 09:56:39 2014 by user: Pierre 





Any help appreciated.



--
View this message in context: http://r.789695.n4.nabble.com/fPortfolio-and-maxreturnPortfolio-tp4692180.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From mg211 at st-andrews.ac.uk  Mon Jun 16 11:21:06 2014
From: mg211 at st-andrews.ac.uk (Manuj Goel)
Date: Mon, 16 Jun 2014 10:21:06 +0100
Subject: [R-SIG-Finance] Kalman Filter Implementation in R
Message-ID: <CADmjYeULhv9Gd6xy8ZguXUrSH0_zxfV=Rtvvnu=uLUJ_pKL5aw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140616/c69cec7b/attachment.pl>

From msuzen at gmail.com  Mon Jun 16 13:15:39 2014
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Mon, 16 Jun 2014 13:15:39 +0200
Subject: [R-SIG-Finance] Kalman Filter Implementation in R
In-Reply-To: <CADmjYeULhv9Gd6xy8ZguXUrSH0_zxfV=Rtvvnu=uLUJ_pKL5aw@mail.gmail.com>
References: <CADmjYeULhv9Gd6xy8ZguXUrSH0_zxfV=Rtvvnu=uLUJ_pKL5aw@mail.gmail.com>
Message-ID: <CAPtbhHxaYagprMKLOfMND2yih-eXXQd7HBrq6Ym=W=yG-s2xZQ@mail.gmail.com>

I suggest you to read the paper by Fernando Tusell from University of
Basque Country,
Kalman Filtering in R, JSS Vol. 39, Issue 2, Mar 2011


On 16 June 2014 11:21, Manuj Goel <mg211 at st-andrews.ac.uk> wrote:
> Hello everyone,
>
> I am an applied statistics post-graduate student and am doing my
> dissertation on kalman filters and its application on financial models. I
> have read quite a lot papers on kalman filters and I am able to understand
> their methodology. But I am unable to work my way through to build a basic
> Kalman model in R. Can someone help me with this please. Any and all help
> really appreciated. Thanks.
>
> Kind Regards,
> M
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From markknecht at gmail.com  Mon Jun 16 14:29:03 2014
From: markknecht at gmail.com (Mark Knecht)
Date: Mon, 16 Jun 2014 05:29:03 -0700
Subject: [R-SIG-Finance] Kalman Filter Implementation in R
In-Reply-To: <CADmjYeULhv9Gd6xy8ZguXUrSH0_zxfV=Rtvvnu=uLUJ_pKL5aw@mail.gmail.com>
References: <CADmjYeULhv9Gd6xy8ZguXUrSH0_zxfV=Rtvvnu=uLUJ_pKL5aw@mail.gmail.com>
Message-ID: <CAK2H+ecHCZB4Fz4T88-eSz8a3QpTycywSySs+9siumHoLgVCAQ@mail.gmail.com>

On Mon, Jun 16, 2014 at 2:21 AM, Manuj Goel <mg211 at st-andrews.ac.uk> wrote:
> Hello everyone,
>
> I am an applied statistics post-graduate student and am doing my
> dissertation on kalman filters and its application on financial models. I
> have read quite a lot papers on kalman filters and I am able to understand
> their methodology. But I am unable to work my way through to build a basic
> Kalman model in R. Can someone help me with this please. Any and all help
> really appreciated. Thanks.
>
> Kind Regards,
> M

http://www.jstatsoft.org/v39/i02/paper

HTH,
Mark


From atp at piskorski.com  Mon Jun 16 19:22:12 2014
From: atp at piskorski.com (Andrew Piskorski)
Date: Mon, 16 Jun 2014 13:22:12 -0400
Subject: [R-SIG-Finance] Kalman Filter Implementation in R
In-Reply-To: <CADmjYeULhv9Gd6xy8ZguXUrSH0_zxfV=Rtvvnu=uLUJ_pKL5aw@mail.gmail.com>
References: <CADmjYeULhv9Gd6xy8ZguXUrSH0_zxfV=Rtvvnu=uLUJ_pKL5aw@mail.gmail.com>
Message-ID: <20140616172212.GA58406@piskorski.com>

You likely want to start with this paper:

Fernando Tusell, 211, "Kalman Filtering in R":
http://www.jstatsoft.org/v39/i02
http://stat-www.berkeley.edu/~brill/Stat248/kalmanfiltering.pdf
http://www.et.bs.ehu.es/~etptupaf/nuevo/en/papiros.php

It says there are at least five different implementations of the
Kalman filter available in R packages, and gives a nice breakdown of
some of their features.

-- 
Andrew Piskorski <atp at piskorski.com>


From ignacio.rodrigo at gmx.com  Fri Jun 20 14:14:56 2014
From: ignacio.rodrigo at gmx.com (nacho)
Date: Fri, 20 Jun 2014 05:14:56 -0700 (PDT)
Subject: [R-SIG-Finance] Applying transformations to timeSeries objects
Message-ID: <1403266496370-4692438.post@n4.nabble.com>

Hi guys,

First of all, apologies for the simplicity of the question, I am a complete
R and Rmetrics newbie so I am just trying to learn. I have searched forums
and the internet in general for the answer but I have found none that I
could understand or matched my query.

So, using the Rmetrics package, I created a timeSeries object with a set of
closing prices, e.g.

> data

GMT
                Close
1974-12-31  191
1975-01-02  184
1975-01-03  173
1975-01-06  172
1975-01-07  171
1975-01-08  176
1975-01-09  179
1975-01-10  177
1975-01-13  181
1975-01-14  177

My first question is how to apply a transformation of one row relative to
the previous row to the 'data' timeSeries object and store it in a new
timeSeries object. I am aware that you can simply run:

> returns(data)

...and it will generate a returns timeSeries object. However, what if I want
to create a new timeSeries object from 'data' that applies a more custom
transformation that references other rows? e.g. one that subtracts the
previous observation from the current one

GMT
                Close
1975-01-02  -7
1975-01-03  -11
1975-01-06  -1
1975-01-07  -1
1975-01-08  5
1975-01-09  3
1975-01-10  -2
1975-01-13  4
1975-01-14  -4

I have tried doing it writing a for-loop but something tells me that it is
possible to do it in a much simpler way through timeSeries' fapply() or
applySeries() functions. Would anyone know how to do it?

Thanks a lot for taking the time to read this and for your help in advance,
much appreciated!



--
View this message in context: http://r.789695.n4.nabble.com/Applying-transformations-to-timeSeries-objects-tp4692438.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From rharlow86 at gmail.com  Fri Jun 20 14:43:51 2014
From: rharlow86 at gmail.com (Robert Harlow)
Date: Fri, 20 Jun 2014 08:43:51 -0400
Subject: [R-SIG-Finance] Applying transformations to timeSeries objects
In-Reply-To: <1403266496370-4692438.post@n4.nabble.com>
References: <1403266496370-4692438.post@n4.nabble.com>
Message-ID: <CAHdfS94d2FWSo1Bi55g=iScJCh4TNk3pMcNoVwM8SDSrsn1BCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140620/cfd14b6c/attachment.pl>

From ignacio.rodrigo at gmx.com  Fri Jun 20 15:15:44 2014
From: ignacio.rodrigo at gmx.com (nacho)
Date: Fri, 20 Jun 2014 06:15:44 -0700 (PDT)
Subject: [R-SIG-Finance] Applying transformations to timeSeries objects
In-Reply-To: <CAHdfS94d2FWSo1Bi55g=iScJCh4TNk3pMcNoVwM8SDSrsn1BCw@mail.gmail.com>
References: <1403266496370-4692438.post@n4.nabble.com>
	<CAHdfS94d2FWSo1Bi55g=iScJCh4TNk3pMcNoVwM8SDSrsn1BCw@mail.gmail.com>
Message-ID: <1403270144392-4692443.post@n4.nabble.com>

Thank you so much, Bob! I'll check out xts and the example you gave me!



--
View this message in context: http://r.789695.n4.nabble.com/Applying-transformations-to-timeSeries-objects-tp4692438p4692443.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From jaimie.villanueva at gmail.com  Fri Jun 20 18:06:51 2014
From: jaimie.villanueva at gmail.com (Jaimie Villanueva)
Date: Fri, 20 Jun 2014 18:06:51 +0200
Subject: [R-SIG-Finance] Scale parameter in fit.control option from
	"ugarchfit" rugarch function
Message-ID: <CAEXmNQBk5_EYCMkejNN=p9MGr_TDOcKM9ekMzGyJgEhmxG-U2g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140620/c579aab5/attachment.pl>

From alexios at 4dscape.com  Fri Jun 20 18:39:55 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Fri, 20 Jun 2014 17:39:55 +0100
Subject: [R-SIG-Finance] Scale parameter in fit.control option from
 "ugarchfit" rugarch function
In-Reply-To: <CAEXmNQBk5_EYCMkejNN=p9MGr_TDOcKM9ekMzGyJgEhmxG-U2g@mail.gmail.com>
References: <CAEXmNQBk5_EYCMkejNN=p9MGr_TDOcKM9ekMzGyJgEhmxG-U2g@mail.gmail.com>
Message-ID: <53A463DB.2030300@4dscape.com>

Scaling of the data is just an optimization "trick" used in order to
make some of the variables (mainly the conditional mean and GARCH
intercepts) comparable in "scale" to the other variables during
optimization, WITHOUT having to tinker with solver control parameters.
After the optimization is completed, the parameters which are impacted
(mean, xreg and GARCH intercept) are transformed back to their original
scale.

I really don't consider the results you provide as making "much"
difference, but if you insist, you can always adjust the solver.control
parameters with varying degrees of success:

model0=ugarchfit(spec,as.xts(sp500ret),solver = "hybrid", fit.control =
list(scale = 0), solver.control=list(tol=1e-12,delta=1e-11))
        Estimate  Std. Error  t value Pr(>|t|)
omega   0.000001    0.000000   5.1105        0
alpha1  0.087436    0.007733  11.3066        0
beta1   0.905252    0.008547 105.9204        0

model1=ugarchfit(spec,as.xts(sp500ret),solver = "hybrid", fit.control =
list(scale = 1))
        Estimate  Std. Error  t value Pr(>|t|)
omega   0.000001    0.000000   5.1084        0
alpha1  0.087479    0.007742  11.2994        0
beta1   0.905254    0.008547 105.9109        0


cf1 = coef(model1)
cf0 = coef(model0)

se1 = sqrt(diag(vcov(model1)))
se0 = sqrt(diag(vcov(model0)))

(Log Relative Error :  number of digits of accuracy)
LRE.vars = -log(abs(cf1-cf0)/abs(cf0), base = 10)
LRE.se   = -log(abs(se1-se0)/abs(se1), base = 10)
(likelihood(model0)/likelihood(model1))-1

Note that scaling is not always available e.g. when using the eGARCH
model or when using external variables in the conditional variance equation.

Regards,

Alexios


On 20/06/2014 17:06, Jaimie Villanueva wrote:
> Hi R users
> 
> I'm interested in to know a bit more on what the scale parameter of
> the "ugarchfit" fit.control option is about. I took a look inside the code
> and i found out that the data is divided by the standard deviation when the
> scale option is turned on (scale=1).
> 
> Parameters estimated are slightly different when this option is on,
> compared with when it is off. I would like to get some reference in which i
> can read about, just to make myself sure that i'm not missing anything when
> using this option. Scaling the data provides successful estimates that
> couldn't be achieved without it.
> Is it recommended to leave this option on (scale=1) or just to use it
> whenever is strictly necessary?
> 
> Here is the comparison i got, switching scaling option on/off.
> The model is a standard Garch(1,1) with normal innovations
> 
> *The code:*
> 
> library(rugarch)
> library(xts)
> 
> data(sp500ret)
> 
>  spec=ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
> c(1,1)),
>                  mean.model = list(armaOrder = c(0,0), include.mean =
> FALSE),
>                  distribution.model = "norm")
> 
>  modelo=ugarchfit(spec,as.xts(sp500ret),solver = "hybrid", fit.control =
> list(scale = 1))
>  modelo
> 
> *Results:*
> 
> Scale Off
> 
>              Estimate  Std. Error  t value  Pr(>|t|)
> omega   0.000001    0.000001   1.4048  0.16007
> alpha1  0.087257    0.013596   6.4179  0.00000
> beta1   0.905045    0.013744  65.8483  0.00000
> 
> 
> Scale On
> 
>               Estimate  Std. Error  t value  Pr(>|t|)
> omega   0.000001    0.000001   1.3055  0.19173
> alpha1  0.087479    0.014530   6.0206  0.00000
> beta1   0.905254    0.014614  61.9434  0.00000
> 
> 
> Thanks a lot and have a great weekend.
> 
> Jaimie
>


From jaimie.villanueva at gmail.com  Fri Jun 20 19:12:52 2014
From: jaimie.villanueva at gmail.com (Jaimie)
Date: Fri, 20 Jun 2014 19:12:52 +0200
Subject: [R-SIG-Finance] Scale parameter in fit.control option from
	"ugarchfit" rugarch function
In-Reply-To: <53A463DB.2030300@4dscape.com>
References: <CAEXmNQBk5_EYCMkejNN=p9MGr_TDOcKM9ekMzGyJgEhmxG-U2g@mail.gmail.com>
	<53A463DB.2030300@4dscape.com>
Message-ID: <B51036F6-CA5C-4B4B-B9BF-CB6535BE523F@gmail.com>

Alright. It's pretty clear now. 
Thanks for your quick response. 

Bests
Jaimie
Sent from my iPhone

> On Jun 20, 2014, at 6:39 PM, alexios ghalanos <alexios at 4dscape.com> wrote:
> 
> Scaling of the data is just an optimization "trick" used in order to
> make some of the variables (mainly the conditional mean and GARCH
> intercepts) comparable in "scale" to the other variables during
> optimization, WITHOUT having to tinker with solver control parameters.
> After the optimization is completed, the parameters which are impacted
> (mean, xreg and GARCH intercept) are transformed back to their original
> scale.
> 
> I really don't consider the results you provide as making "much"
> difference, but if you insist, you can always adjust the solver.control
> parameters with varying degrees of success:
> 
> model0=ugarchfit(spec,as.xts(sp500ret),solver = "hybrid", fit.control =
> list(scale = 0), solver.control=list(tol=1e-12,delta=1e-11))
>        Estimate  Std. Error  t value Pr(>|t|)
> omega   0.000001    0.000000   5.1105        0
> alpha1  0.087436    0.007733  11.3066        0
> beta1   0.905252    0.008547 105.9204        0
> 
> model1=ugarchfit(spec,as.xts(sp500ret),solver = "hybrid", fit.control =
> list(scale = 1))
>        Estimate  Std. Error  t value Pr(>|t|)
> omega   0.000001    0.000000   5.1084        0
> alpha1  0.087479    0.007742  11.2994        0
> beta1   0.905254    0.008547 105.9109        0
> 
> 
> cf1 = coef(model1)
> cf0 = coef(model0)
> 
> se1 = sqrt(diag(vcov(model1)))
> se0 = sqrt(diag(vcov(model0)))
> 
> (Log Relative Error :  number of digits of accuracy)
> LRE.vars = -log(abs(cf1-cf0)/abs(cf0), base = 10)
> LRE.se   = -log(abs(se1-se0)/abs(se1), base = 10)
> (likelihood(model0)/likelihood(model1))-1
> 
> Note that scaling is not always available e.g. when using the eGARCH
> model or when using external variables in the conditional variance equation.
> 
> Regards,
> 
> Alexios
> 
> 
>> On 20/06/2014 17:06, Jaimie Villanueva wrote:
>> Hi R users
>> 
>> I'm interested in to know a bit more on what the scale parameter of
>> the "ugarchfit" fit.control option is about. I took a look inside the code
>> and i found out that the data is divided by the standard deviation when the
>> scale option is turned on (scale=1).
>> 
>> Parameters estimated are slightly different when this option is on,
>> compared with when it is off. I would like to get some reference in which i
>> can read about, just to make myself sure that i'm not missing anything when
>> using this option. Scaling the data provides successful estimates that
>> couldn't be achieved without it.
>> Is it recommended to leave this option on (scale=1) or just to use it
>> whenever is strictly necessary?
>> 
>> Here is the comparison i got, switching scaling option on/off.
>> The model is a standard Garch(1,1) with normal innovations
>> 
>> *The code:*
>> 
>> library(rugarch)
>> library(xts)
>> 
>> data(sp500ret)
>> 
>> spec=ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>> c(1,1)),
>>                 mean.model = list(armaOrder = c(0,0), include.mean =
>> FALSE),
>>                 distribution.model = "norm")
>> 
>> modelo=ugarchfit(spec,as.xts(sp500ret),solver = "hybrid", fit.control =
>> list(scale = 1))
>> modelo
>> 
>> *Results:*
>> 
>> Scale Off
>> 
>>             Estimate  Std. Error  t value  Pr(>|t|)
>> omega   0.000001    0.000001   1.4048  0.16007
>> alpha1  0.087257    0.013596   6.4179  0.00000
>> beta1   0.905045    0.013744  65.8483  0.00000
>> 
>> 
>> Scale On
>> 
>>              Estimate  Std. Error  t value  Pr(>|t|)
>> omega   0.000001    0.000001   1.3055  0.19173
>> alpha1  0.087479    0.014530   6.0206  0.00000
>> beta1   0.905254    0.014614  61.9434  0.00000
>> 
>> 
>> Thanks a lot and have a great weekend.
>> 
>> Jaimie
> 


From aschmid1 at stevens.edu  Sun Jun 22 16:49:50 2014
From: aschmid1 at stevens.edu (aschmid1)
Date: Sun, 22 Jun 2014 10:49:50 -0400
Subject: [R-SIG-Finance] Fwd: Re: News impact curves for various GARCH
 models in the rugarch-package
Message-ID: <16e5d8bd42a87fe6f8814be42ba3bf88@stevens.edu>

Thanks for the interest. Here is part 2:
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2449796
Comments appreciated.
Alec

-------- Original Message --------
Subject: Re: [R-SIG-Finance] News impact curves for various GARCH models 
in the rugarch-package
Date: 06/15/2014 9:58 AM
 From: aschmid1 <aschmid1 at stevens.edu>
To: r-sig-finance at r-project.org

For those interested in news impact, I actually implemented a 
rugarch-based model for analysis of macroeconomic announcements:
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2364077

Regards, Alec

On 06/15/2014 4:53 AM, Johannes Moser wrote:
> After having slept on it for a nightI now think that both the fGARCH
> submodels (I am especially interested in the NAGARCH) and the eGARCH
> model have a NIC that has to be expressed in terms of the z_{t-1}
> since in both cases the effect of epsilon_{t-1} on sigma_t does depend
> on sigma_{t-1} which is of course nonconstant.
> 
> But as stated before, the "newsimpact(fit)"-output of the eGARCH model
> tells me that here the NIC was given in terms of epsilon_{t-1}.
> Is this a typo?  Should it mean "z_{t-1}"?
> 
> 
> Am 2014-06-14 7:25 PM, schrieb Johannes Moser:
>> Dear all,
>> 
>> I'm working with the really nice "rugarch"-package and currently have 
>> an issue with respect to the news impact curves (NIC).
>> 
>> In an attempt to plot several NIC into the same plot I realized that 
>> while the NIC for the sGARCH, the gjrGARCH and the eGARCH are given 
>> with respect to the epsilon_{t-1}, the NICs for the submodels of the 
>> fGARCH model are given in terms of z_{t-1}.
>> 
>> Firstly I am a bit confused since just like the fGARCH model, the 
>> eGARCH model (as to the eGARCH-model-setup in the vignette) is also 
>> given in terms of the z_{t-k} , k={1,...,q}.
>> But nevertheless the NIC of the eGARCH is given in terms of 
>> epsilon_{t-1} .
>> At least this is what the "newsimpact(fit)"-output tells me.
>> Why is it this way for the eGARCH but not for the fGARCH?
>> 
>> Secondly I'd like to have the NIC of all the different models 
>> depending on the epsilon_{t-1} for better comparison.
>> So for the fGARCH case I thought about calculating the epsilon_{t-1} 
>> values given the z_{t-1} values and the conditional mean and 
>> volatility.
>> Is this a good idea or is there an important reason why the NICs for 
>> the fGARCH submodels are NOT given this way?
>> 
>> Many thanks and kind regards,
>> Johannes
>> 
> 
> --
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R
> questions should go.


From junluke at gmail.com  Sun Jun 22 19:16:22 2014
From: junluke at gmail.com (jun wang)
Date: Sun, 22 Jun 2014 13:16:22 -0400
Subject: [R-SIG-Finance] rugarch question
Message-ID: <CAPD4hGA387X0QYXX3ktawZSmwgH=A=h-FYitd8DB3zW-MsLPfQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140622/6bcdbc22/attachment.pl>

From alexios at 4dscape.com  Sun Jun 22 19:25:14 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sun, 22 Jun 2014 18:25:14 +0100
Subject: [R-SIG-Finance] rugarch question
In-Reply-To: <CAPD4hGA387X0QYXX3ktawZSmwgH=A=h-FYitd8DB3zW-MsLPfQ@mail.gmail.com>
References: <CAPD4hGA387X0QYXX3ktawZSmwgH=A=h-FYitd8DB3zW-MsLPfQ@mail.gmail.com>
Message-ID: <63E978D0-6857-42DD-B34D-B6CCDD66750B@4dscape.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140622/0154ee3d/attachment.pl>

From junluke at gmail.com  Sun Jun 22 19:52:21 2014
From: junluke at gmail.com (jun wang)
Date: Sun, 22 Jun 2014 13:52:21 -0400
Subject: [R-SIG-Finance] rugarch question
In-Reply-To: <63E978D0-6857-42DD-B34D-B6CCDD66750B@4dscape.com>
References: <CAPD4hGA387X0QYXX3ktawZSmwgH=A=h-FYitd8DB3zW-MsLPfQ@mail.gmail.com>
	<63E978D0-6857-42DD-B34D-B6CCDD66750B@4dscape.com>
Message-ID: <CAPD4hGBn9ky54NvgdXx3WVtqHStr7zBWq-AjXeLyYT8orvGc0w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140622/01ab5da6/attachment.pl>

From alexios at 4dscape.com  Sun Jun 22 19:56:03 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sun, 22 Jun 2014 18:56:03 +0100
Subject: [R-SIG-Finance] rugarch question
In-Reply-To: <CAPD4hGBn9ky54NvgdXx3WVtqHStr7zBWq-AjXeLyYT8orvGc0w@mail.gmail.com>
References: <CAPD4hGA387X0QYXX3ktawZSmwgH=A=h-FYitd8DB3zW-MsLPfQ@mail.gmail.com>
	<63E978D0-6857-42DD-B34D-B6CCDD66750B@4dscape.com>
	<CAPD4hGBn9ky54NvgdXx3WVtqHStr7zBWq-AjXeLyYT8orvGc0w@mail.gmail.com>
Message-ID: <C814926C-DFE1-4CB7-8C54-E18CC5C8AE05@4dscape.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140622/b845a732/attachment.pl>

From william.ferguson02 at imperial.ac.uk  Tue Jun 24 11:23:24 2014
From: william.ferguson02 at imperial.ac.uk (Ferguson, William)
Date: Tue, 24 Jun 2014 09:23:24 +0000
Subject: [R-SIG-Finance] Query about mcsGARCH (rugarch package)
Message-ID: <18BAA4B21DB28B498B2E8947CFE256C241DE973C@icexch-m6.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140624/73ec236d/attachment.pl>

From alexios at 4dscape.com  Tue Jun 24 14:27:02 2014
From: alexios at 4dscape.com (alexios ghalanos)
Date: Tue, 24 Jun 2014 13:27:02 +0100
Subject: [R-SIG-Finance] Query about mcsGARCH (rugarch package)
In-Reply-To: <18BAA4B21DB28B498B2E8947CFE256C241DE973C@icexch-m6.ic.ac.uk>
References: <18BAA4B21DB28B498B2E8947CFE256C241DE973C@icexch-m6.ic.ac.uk>
Message-ID: <53A96E96.8070604@4dscape.com>

Hi Will,

The model presented in the blog used the mean function to calculate the
diurnal component, but I had since (and noted that in the post) changed
the mean to the median. It was perhaps not a good idea to do so without
allowing for the choice to be set by the user. For the time being, I've
reversed the change to use the mean again until such time as I provide
an option for choosing between the two. You can download the latest
revision from my bitbucket repository (see the downloads section of blog).

Cheers,

Alexios


On 24/06/2014 10:23, Ferguson, William wrote:
> Hi,
> 
> I have looked at the article on the multiplicative component GARCH model found at http://unstarched.net/2013/03/20/high-frequency-garch-the-multiplicative-component-garch-mcsgarch-model/, and would like to adapt the example given for FX data.
> 
> I am trying to reproduce the initial plots that show the four volatility components of the model (second figure), and only the plot of Daily-Forecast is the same. My Diurnal plot seems to be lower than that in the example, which presumably then affects the Stochastic and Total plots.
> 
> I think that both data sets used are fine as the ACF plot and Daily_Forecast plot are both the same as in the example. I assume therefore that the problem lies in the following lines:
> 
> spec = ugarchspec(mean.model = list(armaOrder = c(1, 1), include.mean = TRUE), variance.model = list(model = 'mcsGARCH'), distribution = 'nig')
> fit = ugarchfit(data = R_i, spec = spec, DailyVar = f_sigma^2)
> 
> Is anyone able to explain the discrepancy? I wonder whether perhaps different versions have different function defaults, or something like that, though I can't spot a problem. I am using R version 3.1.0 and rugarch version 1.3-1.
> 
> Many thanks!
> 
> Will
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 
>


From bogaso.christofer at gmail.com  Sun Jun 29 22:07:38 2014
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 30 Jun 2014 01:52:38 +0545
Subject: [R-SIG-Finance] A question on Forward Price
Message-ID: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>

Hi again,

I would like ask a small question however not really related to R.

We all know that non-arbitrage Forward price of any underlying (except
perhaps Interest Rate) is just the spot price plus the cost of carry.
Cost of carry again depends on cost of borrowing and convenience
yield.

Therefore my question is, is it true that for most consumable
commodity like agricultural commodity, crude oil, the Forward market
will mostly remain in backwardination? Specially for Crude oil it
looks always remains in Backwardination. Because since they are
consumable then buying now and storing would be more economical than
buying it Forward for future use, hence CY would be higher.

Another related question is, for Crude oil if Forward market becomes
more in Backwardination then does it imply that, in Future it's price
is expected to increase, keeping everything else same?

I really appreciate your thought on the same.

Thanks and regards,


From michael.weylandt at gmail.com  Sun Jun 29 23:00:44 2014
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Sun, 29 Jun 2014 17:00:44 -0400
Subject: [R-SIG-Finance] A question on Forward Price
In-Reply-To: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>
References: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>
Message-ID: <6780CAC2-478B-4E8A-A161-8BD53D716407@gmail.com>



> On Jun 29, 2014, at 4:07 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> 
> Hi again,
> 
> I would like ask a small question however not really related to R.
> 
> We all know that non-arbitrage Forward price of any underlying (except
> perhaps Interest Rate) is just the spot price plus the cost of carry.
> Cost of carry again depends on cost of borrowing and convenience
> yield.

Do we know that? 

Consider energy (electricity) futures....

> 
> Therefore my question is, is it true that for most consumable
> commodity like agricultural commodity, crude oil, the Forward market
> will mostly remain in backwardination? Specially for Crude oil it
> looks always remains in Backwardination. Because since they are
> consumable then buying now and storing would be more economical than
> buying it Forward for future use, hence CY would be higher.
> 
> Another related question is, for Crude oil if Forward market becomes
> more in Backwardination then does it imply that, in Future it's price
> is expected to increase, keeping everything else same?
> 
> I really appreciate your thought on the same.
> 
> Thanks and regards,
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From bogaso.christofer at gmail.com  Sun Jun 29 23:09:36 2014
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 30 Jun 2014 02:54:36 +0545
Subject: [R-SIG-Finance] A question on Forward Price
In-Reply-To: <6780CAC2-478B-4E8A-A161-8BD53D716407@gmail.com>
References: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>
	<6780CAC2-478B-4E8A-A161-8BD53D716407@gmail.com>
Message-ID: <CA+dpOJ=e34W7XJ3Nsmo=nE6biO4dtKK3SGvQNoykMtH=uoKb-A@mail.gmail.com>

Ofcourse Electricity can not be stored or storage cost would be
extraordinarily high. Therefore it would have zero CY. I feel Power
prices should always be in contango

On Mon, Jun 30, 2014 at 2:45 AM, Michael Weylandt
<michael.weylandt at gmail.com> wrote:
>
>
>> On Jun 29, 2014, at 4:07 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>
>> Hi again,
>>
>> I would like ask a small question however not really related to R.
>>
>> We all know that non-arbitrage Forward price of any underlying (except
>> perhaps Interest Rate) is just the spot price plus the cost of carry.
>> Cost of carry again depends on cost of borrowing and convenience
>> yield.
>
> Do we know that?
>
> Consider energy (electricity) futures....
>
>>
>> Therefore my question is, is it true that for most consumable
>> commodity like agricultural commodity, crude oil, the Forward market
>> will mostly remain in backwardination? Specially for Crude oil it
>> looks always remains in Backwardination. Because since they are
>> consumable then buying now and storing would be more economical than
>> buying it Forward for future use, hence CY would be higher.
>>
>> Another related question is, for Crude oil if Forward market becomes
>> more in Backwardination then does it imply that, in Future it's price
>> is expected to increase, keeping everything else same?
>>
>> I really appreciate your thought on the same.
>>
>> Thanks and regards,
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.


From dominykasgrigonis at gmail.com  Sun Jun 29 23:16:22 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sun, 29 Jun 2014 14:16:22 -0700 (PDT)
Subject: [R-SIG-Finance] A question on Forward Price
In-Reply-To: <CA+dpOJ=e34W7XJ3Nsmo=nE6biO4dtKK3SGvQNoykMtH=uoKb-A@mail.gmail.com>
References: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>
	<6780CAC2-478B-4E8A-A161-8BD53D716407@gmail.com>
	<CA+dpOJ=e34W7XJ3Nsmo=nE6biO4dtKK3SGvQNoykMtH=uoKb-A@mail.gmail.com>
Message-ID: <C7BA9622-A528-4751-A2A6-AE79DF618E20@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140629/50a64b99/attachment.pl>

From michael.weylandt at gmail.com  Sun Jun 29 23:22:11 2014
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Sun, 29 Jun 2014 17:22:11 -0400
Subject: [R-SIG-Finance] A question on Forward Price
In-Reply-To: <CA+dpOJ=e34W7XJ3Nsmo=nE6biO4dtKK3SGvQNoykMtH=uoKb-A@mail.gmail.com>
References: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>
	<6780CAC2-478B-4E8A-A161-8BD53D716407@gmail.com>
	<CA+dpOJ=e34W7XJ3Nsmo=nE6biO4dtKK3SGvQNoykMtH=uoKb-A@mail.gmail.com>
Message-ID: <A4D65EC1-80C2-4B86-928C-8217D3F1FDDE@gmail.com>

If p => q, and we can observe ~q, we should doubt p. 

More directly, electricity is a case where your assumptions (F=S+C) about forwards pricing are transparently wrong. 

You need to think more about how forwards are really priced and then your questions about crude futures will sort themselves out. 

> On Jun 29, 2014, at 5:09 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> 
> Ofcourse Electricity can not be stored or storage cost would be
> extraordinarily high. Therefore it would have zero CY. I feel Power
> prices should always be in contango
> 
> On Mon, Jun 30, 2014 at 2:45 AM, Michael Weylandt
> <michael.weylandt at gmail.com> wrote:
>> 
>> 
>>> On Jun 29, 2014, at 4:07 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>> 
>>> Hi again,
>>> 
>>> I would like ask a small question however not really related to R.
>>> 
>>> We all know that non-arbitrage Forward price of any underlying (except
>>> perhaps Interest Rate) is just the spot price plus the cost of carry.
>>> Cost of carry again depends on cost of borrowing and convenience
>>> yield.
>> 
>> Do we know that?
>> 
>> Consider energy (electricity) futures....
>> 
>>> 
>>> Therefore my question is, is it true that for most consumable
>>> commodity like agricultural commodity, crude oil, the Forward market
>>> will mostly remain in backwardination? Specially for Crude oil it
>>> looks always remains in Backwardination. Because since they are
>>> consumable then buying now and storing would be more economical than
>>> buying it Forward for future use, hence CY would be higher.
>>> 
>>> Another related question is, for Crude oil if Forward market becomes
>>> more in Backwardination then does it imply that, in Future it's price
>>> is expected to increase, keeping everything else same?
>>> 
>>> I really appreciate your thought on the same.
>>> 
>>> Thanks and regards,
>>> 
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions should go.


From bogaso.christofer at gmail.com  Mon Jun 30 00:16:52 2014
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 30 Jun 2014 04:01:52 +0545
Subject: [R-SIG-Finance] A question on Forward Price
In-Reply-To: <A4D65EC1-80C2-4B86-928C-8217D3F1FDDE@gmail.com>
References: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>
	<6780CAC2-478B-4E8A-A161-8BD53D716407@gmail.com>
	<CA+dpOJ=e34W7XJ3Nsmo=nE6biO4dtKK3SGvQNoykMtH=uoKb-A@mail.gmail.com>
	<A4D65EC1-80C2-4B86-928C-8217D3F1FDDE@gmail.com>
Message-ID: <CA+dpOJkTPS2+cvyBWqnW_NaxPyPWQG0AnemwwD41-HFy4C-HoQ@mail.gmail.com>

Could you please elaborate why you are saying F = s+C is wrong? What
is right then? I assumed CoC consists of cost of financing, storage
cost, CY and other related costs

My original question was very straightforward. If I see for a
underlying which is storable and consumable, and forward curve for
that is moving more and more in backwardination then is it not
straightforward to think that market is expecting future spot price
would be higher due to future supply disruption?

I was looking for some yes/no answer and why...

Thanks and regards,

On Mon, Jun 30, 2014 at 3:07 AM, Michael Weylandt
<michael.weylandt at gmail.com> wrote:
> If p => q, and we can observe ~q, we should doubt p.
>
> More directly, electricity is a case where your assumptions (F=S+C) about forwards pricing are transparently wrong.
>
> You need to think more about how forwards are really priced and then your questions about crude futures will sort themselves out.
>
>> On Jun 29, 2014, at 5:09 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>
>> Ofcourse Electricity can not be stored or storage cost would be
>> extraordinarily high. Therefore it would have zero CY. I feel Power
>> prices should always be in contango
>>
>> On Mon, Jun 30, 2014 at 2:45 AM, Michael Weylandt
>> <michael.weylandt at gmail.com> wrote:
>>>
>>>
>>>> On Jun 29, 2014, at 4:07 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>>>
>>>> Hi again,
>>>>
>>>> I would like ask a small question however not really related to R.
>>>>
>>>> We all know that non-arbitrage Forward price of any underlying (except
>>>> perhaps Interest Rate) is just the spot price plus the cost of carry.
>>>> Cost of carry again depends on cost of borrowing and convenience
>>>> yield.
>>>
>>> Do we know that?
>>>
>>> Consider energy (electricity) futures....
>>>
>>>>
>>>> Therefore my question is, is it true that for most consumable
>>>> commodity like agricultural commodity, crude oil, the Forward market
>>>> will mostly remain in backwardination? Specially for Crude oil it
>>>> looks always remains in Backwardination. Because since they are
>>>> consumable then buying now and storing would be more economical than
>>>> buying it Forward for future use, hence CY would be higher.
>>>>
>>>> Another related question is, for Crude oil if Forward market becomes
>>>> more in Backwardination then does it imply that, in Future it's price
>>>> is expected to increase, keeping everything else same?
>>>>
>>>> I really appreciate your thought on the same.
>>>>
>>>> Thanks and regards,
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions should go.


From dominykasgrigonis at gmail.com  Mon Jun 30 00:29:10 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sun, 29 Jun 2014 15:29:10 -0700 (PDT)
Subject: [R-SIG-Finance] A question on Forward Price
In-Reply-To: <CA+dpOJkTPS2+cvyBWqnW_NaxPyPWQG0AnemwwD41-HFy4C-HoQ@mail.gmail.com>
References: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>
	<6780CAC2-478B-4E8A-A161-8BD53D716407@gmail.com>
	<CA+dpOJ=e34W7XJ3Nsmo=nE6biO4dtKK3SGvQNoykMtH=uoKb-A@mail.gmail.com>
	<A4D65EC1-80C2-4B86-928C-8217D3F1FDDE@gmail.com>
	<CA+dpOJkTPS2+cvyBWqnW_NaxPyPWQG0AnemwwD41-HFy4C-HoQ@mail.gmail.com>
Message-ID: <55D644B1-58EE-4E99-AD99-46C08643A965@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140629/105d2b8d/attachment.pl>

From bogaso.christofer at gmail.com  Mon Jun 30 00:32:35 2014
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 30 Jun 2014 04:17:35 +0545
Subject: [R-SIG-Finance] A question on Forward Price
In-Reply-To: <55D644B1-58EE-4E99-AD99-46C08643A965@gmail.com>
References: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>
	<6780CAC2-478B-4E8A-A161-8BD53D716407@gmail.com>
	<CA+dpOJ=e34W7XJ3Nsmo=nE6biO4dtKK3SGvQNoykMtH=uoKb-A@mail.gmail.com>
	<A4D65EC1-80C2-4B86-928C-8217D3F1FDDE@gmail.com>
	<CA+dpOJkTPS2+cvyBWqnW_NaxPyPWQG0AnemwwD41-HFy4C-HoQ@mail.gmail.com>
	<55D644B1-58EE-4E99-AD99-46C08643A965@gmail.com>
Message-ID: <CA+dpOJm=_fac1Pr-HLVynr94Q_-y_6RJz8L9AYF2xFmytVo24A@mail.gmail.com>

I defined backwardination as forward curve is downward sloping as
compared to spot. So you may term it as you said 'forward prices
increasing/decreasing'. I felt this is bit different than what you
said as 'difference between expected and futures'.

On Mon, Jun 30, 2014 at 4:14 AM, Dominykas Grigonis
<dominykasgrigonis at gmail.com> wrote:
> Can you please define what backwardation is?
>
> An answer to your question would be yes if instead of using fancy terms as
> backwardation, you would substitute it with ?forward prices increasing?.
>
> Why? Supply and demand.
>
> Kind regards,
> Dominykas Grigonis
>
> On Jun 29, 2014, at 11:16 PM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>
> Could you please elaborate why you are saying F = s+C is wrong? What
> is right then? I assumed CoC consists of cost of financing, storage
> cost, CY and other related costs
>
> My original question was very straightforward. If I see for a
> underlying which is storable and consumable, and forward curve for
> that is moving more and more in backwardination then is it not
> straightforward to think that market is expecting future spot price
> would be higher due to future supply disruption?
>
> I was looking for some yes/no answer and why...
>
> Thanks and regards,
>
> On Mon, Jun 30, 2014 at 3:07 AM, Michael Weylandt
> <michael.weylandt at gmail.com> wrote:
>
> If p => q, and we can observe ~q, we should doubt p.
>
> More directly, electricity is a case where your assumptions (F=S+C) about
> forwards pricing are transparently wrong.
>
> You need to think more about how forwards are really priced and then your
> questions about crude futures will sort themselves out.
>
> On Jun 29, 2014, at 5:09 PM, Christofer Bogaso <bogaso.christofer at gmail.com>
> wrote:
>
> Ofcourse Electricity can not be stored or storage cost would be
> extraordinarily high. Therefore it would have zero CY. I feel Power
> prices should always be in contango
>
> On Mon, Jun 30, 2014 at 2:45 AM, Michael Weylandt
> <michael.weylandt at gmail.com> wrote:
>
>
>
> On Jun 29, 2014, at 4:07 PM, Christofer Bogaso <bogaso.christofer at gmail.com>
> wrote:
>
> Hi again,
>
> I would like ask a small question however not really related to R.
>
> We all know that non-arbitrage Forward price of any underlying (except
> perhaps Interest Rate) is just the spot price plus the cost of carry.
> Cost of carry again depends on cost of borrowing and convenience
> yield.
>
>
> Do we know that?
>
> Consider energy (electricity) futures....
>
>
> Therefore my question is, is it true that for most consumable
> commodity like agricultural commodity, crude oil, the Forward market
> will mostly remain in backwardination? Specially for Crude oil it
> looks always remains in Backwardination. Because since they are
> consumable then buying now and storing would be more economical than
> buying it Forward for future use, hence CY would be higher.
>
> Another related question is, for Crude oil if Forward market becomes
> more in Backwardination then does it imply that, in Future it's price
> is expected to increase, keeping everything else same?
>
> I really appreciate your thought on the same.
>
> Thanks and regards,
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>


From dominykasgrigonis at gmail.com  Mon Jun 30 00:35:26 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sun, 29 Jun 2014 15:35:26 -0700 (PDT)
Subject: [R-SIG-Finance] A question on Forward Price
In-Reply-To: <CA+dpOJm=_fac1Pr-HLVynr94Q_-y_6RJz8L9AYF2xFmytVo24A@mail.gmail.com>
References: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>
	<6780CAC2-478B-4E8A-A161-8BD53D716407@gmail.com>
	<CA+dpOJ=e34W7XJ3Nsmo=nE6biO4dtKK3SGvQNoykMtH=uoKb-A@mail.gmail.com>
	<A4D65EC1-80C2-4B86-928C-8217D3F1FDDE@gmail.com>
	<CA+dpOJkTPS2+cvyBWqnW_NaxPyPWQG0AnemwwD41-HFy4C-HoQ@mail.gmail.com>
	<55D644B1-58EE-4E99-AD99-46C08643A965@gmail.com>
	<CA+dpOJm=_fac1Pr-HLVynr94Q_-y_6RJz8L9AYF2xFmytVo24A@mail.gmail.com>
Message-ID: <10754BE3-82CE-4CFE-B849-AD6D53A0DBD1@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140629/c72f7a26/attachment.pl>

From michael.weylandt at gmail.com  Mon Jun 30 01:00:21 2014
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Sun, 29 Jun 2014 19:00:21 -0400
Subject: [R-SIG-Finance] A question on Forward Price
In-Reply-To: <CA+dpOJm=_fac1Pr-HLVynr94Q_-y_6RJz8L9AYF2xFmytVo24A@mail.gmail.com>
References: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>
	<6780CAC2-478B-4E8A-A161-8BD53D716407@gmail.com>
	<CA+dpOJ=e34W7XJ3Nsmo=nE6biO4dtKK3SGvQNoykMtH=uoKb-A@mail.gmail.com>
	<A4D65EC1-80C2-4B86-928C-8217D3F1FDDE@gmail.com>
	<CA+dpOJkTPS2+cvyBWqnW_NaxPyPWQG0AnemwwD41-HFy4C-HoQ@mail.gmail.com>
	<55D644B1-58EE-4E99-AD99-46C08643A965@gmail.com>
	<CA+dpOJm=_fac1Pr-HLVynr94Q_-y_6RJz8L9AYF2xFmytVo24A@mail.gmail.com>
Message-ID: <6708D66E-19CC-411E-A026-03196B5A316D@gmail.com>

> On Jun 29, 2014, at 18:32, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> 
> I defined backwardination as forward curve is downward sloping as
> compared to spot. So you may term it as you said 'forward prices
> increasing/decreasing'. I felt this is bit different than what you
> said as 'difference between expected and futures'.

This is very non-R so the listmaster may tell us off, but until he does:

What does it mean for a curve to be 'downward sloping *as compared to a point*'?

Leaving aside the finance, I'm not sure what geometry you're describing here. 

Michael

From bogaso.christofer at gmail.com  Mon Jun 30 01:05:46 2014
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 30 Jun 2014 04:50:46 +0545
Subject: [R-SIG-Finance] A question on Forward Price
In-Reply-To: <6708D66E-19CC-411E-A026-03196B5A316D@gmail.com>
References: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>
	<6780CAC2-478B-4E8A-A161-8BD53D716407@gmail.com>
	<CA+dpOJ=e34W7XJ3Nsmo=nE6biO4dtKK3SGvQNoykMtH=uoKb-A@mail.gmail.com>
	<A4D65EC1-80C2-4B86-928C-8217D3F1FDDE@gmail.com>
	<CA+dpOJkTPS2+cvyBWqnW_NaxPyPWQG0AnemwwD41-HFy4C-HoQ@mail.gmail.com>
	<55D644B1-58EE-4E99-AD99-46C08643A965@gmail.com>
	<CA+dpOJm=_fac1Pr-HLVynr94Q_-y_6RJz8L9AYF2xFmytVo24A@mail.gmail.com>
	<6708D66E-19CC-411E-A026-03196B5A316D@gmail.com>
Message-ID: <CA+dpOJmAJkJGayL603cEha1irvNQXb5mgSTA9Q1F0nPhVhJs+Q@mail.gmail.com>

Just mentioned it on light manner in plain english...

I meant to say all forward quotes are less then spot and for distant
forward months it would be more lesser. English is not my primary
language so if I could not explain it properly, then as an example I
would like to point here
http://www.cmegroup.com/trading/energy/crude-oil/light-sweet-crude.html

On Mon, Jun 30, 2014 at 4:45 AM, Michael Weylandt
<michael.weylandt at gmail.com> wrote:
>> On Jun 29, 2014, at 18:32, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>
>> I defined backwardination as forward curve is downward sloping as
>> compared to spot. So you may term it as you said 'forward prices
>> increasing/decreasing'. I felt this is bit different than what you
>> said as 'difference between expected and futures'.
>
> This is very non-R so the listmaster may tell us off, but until he does:
>
> What does it mean for a curve to be 'downward sloping *as compared to a point*'?
>
> Leaving aside the finance, I'm not sure what geometry you're describing here.
>
> Michael


From dominykasgrigonis at gmail.com  Mon Jun 30 01:07:03 2014
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sun, 29 Jun 2014 16:07:03 -0700 (PDT)
Subject: [R-SIG-Finance] A question on Forward Price
In-Reply-To: <CA+dpOJmAJkJGayL603cEha1irvNQXb5mgSTA9Q1F0nPhVhJs+Q@mail.gmail.com>
References: <CA+dpOJkNA3wmccu7bnAnXoWba1hLb5iLTgaUPpL8Sg8HrmkP2Q@mail.gmail.com>
	<6780CAC2-478B-4E8A-A161-8BD53D716407@gmail.com>
	<CA+dpOJ=e34W7XJ3Nsmo=nE6biO4dtKK3SGvQNoykMtH=uoKb-A@mail.gmail.com>
	<A4D65EC1-80C2-4B86-928C-8217D3F1FDDE@gmail.com>
	<CA+dpOJkTPS2+cvyBWqnW_NaxPyPWQG0AnemwwD41-HFy4C-HoQ@mail.gmail.com>
	<55D644B1-58EE-4E99-AD99-46C08643A965@gmail.com>
	<CA+dpOJm=_fac1Pr-HLVynr94Q_-y_6RJz8L9AYF2xFmytVo24A@mail.gmail.com>
	<6708D66E-19CC-411E-A026-03196B5A316D@gmail.com>
	<CA+dpOJmAJkJGayL603cEha1irvNQXb5mgSTA9Q1F0nPhVhJs+Q@mail.gmail.com>
Message-ID: <B025B566-4B2B-4FE9-A5FC-79845983F562@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20140629/ef7dd520/attachment.pl>

