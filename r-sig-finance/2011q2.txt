From algotr8der at gmail.com  Fri Apr  1 03:09:49 2011
From: algotr8der at gmail.com (s)
Date: Thu, 31 Mar 2011 21:09:49 -0400
Subject: [R-SIG-Finance] R-project Nabble server
In-Reply-To: <793523183-1301487535-cardhu_decombobulator_blackberry.rim.net-237855112-@bda834.bisx.prod.on.blackberry>
References: <1301441988233-3416574.post@n4.nabble.com><F15AA09E242F834FA21B03F1590005BE1C05AD4522@M0173.s-mxs.net><4D9311A3.3050804@braverock.com>
	<793523183-1301487535-cardhu_decombobulator_blackberry.rim.net-237855112-@bda834.bisx.prod.on.blackberry>
Message-ID: <4D9525DD.40905@gmail.com>

Sorry for the mass email but are people having problems connecting to
the R-project nabble server today?

I've been trying to gain access all day without success.

Kind Regards,
AT


From gcreamer at gmail.com  Fri Apr  1 08:29:14 2011
From: gcreamer at gmail.com (German Creamer)
Date: Fri, 1 Apr 2011 02:29:14 -0400
Subject: [R-SIG-Finance] Fwd: Computational Finance and Microstructure
	Models session
In-Reply-To: <AANLkTi=fNXb5WkUhJtkwrjE7=aqyDYT6QXQ_NizbTiwh@mail.gmail.com>
References: <AANLkTi=fNXb5WkUhJtkwrjE7=aqyDYT6QXQ_NizbTiwh@mail.gmail.com>
Message-ID: <AANLkTi=4TwEK7Vj9mKVnLCEk_Q-2Mgbt4DyagjHqAYhn@mail.gmail.com>

Call for Papers: Computational Finance and Microstructure Models
Modeling High Frequency Data in Finance 3 Conference
(http://kolmogorov.math.stevens.edu/conference2011)
July 27 - July 31, 2011
Stevens Institute of Technology, Hoboken, NJ,

The transformation of the major stock exchanges into electronic
financial markets has encouraged the development of automated trading
systems; ?these systems process streams of data and make instantaneous
investment decisions. Such automated trading systems have often been
built using agent-based modeling and machine learning; many other
approaches are also possible.

The Center for Decision Technologies at Stevens
(http://howe.stevens.edu/research/research-centers/decision-technologies)
is organizing a special session on computational finance and
microstructure models at the "Modeling
High Frequency Data in Finance 3" Conference. The Center invites
researchers interested to present and discuss their work using
computational intense methods to either analyze market activity or
construct trading systems. This special session puts emphasis on
microstructure models. Machine learning methods, time series methods,
complex systems, and agent-based models might be applied. In addition,
we are particularly interested in methods that model trading behavior
using social network analysis techniques, applied to the interactions
between traders, human and machine. Models that address the cognitive
aspects of traders? decision making are also encouraged. Such work
might analyze the shape and content of social media that bear on
market transactions, and might propose new indicators of systemic
risk.

The National Science Foundation will mostly support US travel costs,
the registration fee and ?housing in student dorms for one of the
authors of the papers accepted in this session. See the conference's
website for further details:
(http://kolmogorov.math.stevens.edu/conference2011/index.php/registration-and-support)

If you would like to submit a paper for presentation, please submit
your name, affiliation, email, and a (short) draft paper to: Germ?n
Creamer, Stevens Institute of Technology, gcreamer at stevens.edu

Deadline for paper submission: May 1st., 2011.


From bbands at gmail.com  Fri Apr  1 12:50:40 2011
From: bbands at gmail.com (BBands)
Date: Fri, 1 Apr 2011 18:50:40 +0800
Subject: [R-SIG-Finance] editors
Message-ID: <BANLkTimt_wt8hL1u2xSZ45EStNWV4AyU6g@mail.gmail.com>

Notepad++, my editor of choice for some years, dropped the Scientology
bomb today. So it is time to move on as I'd prefer my editors to be
without religion. I'd like an open-source, cross-platform editor with
code folding, outlining, code completion for Python, R and other
common languages and basic encryption support. Recommendations? (In
China just now, so replies may be problematic.)

John -- who has tried emacs in the past and didn't love it

-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.


From tony at lewistribe.com  Fri Apr  1 13:01:37 2011
From: tony at lewistribe.com (Tony Lewis)
Date: Fri, 01 Apr 2011 22:01:37 +1100
Subject: [R-SIG-Finance] editors
In-Reply-To: <BANLkTimt_wt8hL1u2xSZ45EStNWV4AyU6g@mail.gmail.com>
References: <BANLkTimt_wt8hL1u2xSZ45EStNWV4AyU6g@mail.gmail.com>
Message-ID: <4D95B091.4010804@lewistribe.com>

On 01/04/11 21:50, BBands wrote:
> Notepad++, my editor of choice for some years, dropped the Scientology
> bomb today.

April 1 perhaps?  Just a guess.

Tony


From ggrothendieck at gmail.com  Fri Apr  1 13:59:38 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 1 Apr 2011 07:59:38 -0400
Subject: [R-SIG-Finance] editors
In-Reply-To: <BANLkTimt_wt8hL1u2xSZ45EStNWV4AyU6g@mail.gmail.com>
References: <BANLkTimt_wt8hL1u2xSZ45EStNWV4AyU6g@mail.gmail.com>
Message-ID: <AANLkTikbbQ6Xu2r2Y4kp5Sf2zQcmLyugO4Q8Ufy6O6X-@mail.gmail.com>

On Fri, Apr 1, 2011 at 6:50 AM, BBands <bbands at gmail.com> wrote:
> Notepad++, my editor of choice for some years, dropped the Scientology
> bomb today. So it is time to move on as I'd prefer my editors to be
> without religion. I'd like an open-source, cross-platform editor with
> code folding, outlining, code completion for Python, R and other
> common languages and basic encryption support. Recommendations? (In
> China just now, so replies may be problematic.)
>
> John -- who has tried emacs in the past and didn't love it

People tend to greatly prefer the editor solution they have invested
time in so its very difficult to get an unbiased opinion here but here
is an overview of your choices:

http://sciviews.org/_rgui/projects/Editors.html

vim and gvim (a Gui-ized variant of vim) have all the features you
mention as well as many more plus literally thousands of add-on
packages but do have a steep learning curve.  They are free with a GPL
compatible license and if you wish to become a "sponsor" then the
author donates such monies to help Ugandan children.  There is an
add-on called Cream (on sourceforge) that adopts Common User Access
standards in place of the native interface and it would be
superficially closer to Notepad while being vim underneath.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jh at jameshoward.us  Fri Apr  1 14:40:46 2011
From: jh at jameshoward.us (James P. Howard, II)
Date: Fri, 1 Apr 2011 08:40:46 -0400
Subject: [R-SIG-Finance] editors
In-Reply-To: <BANLkTimt_wt8hL1u2xSZ45EStNWV4AyU6g@mail.gmail.com>
References: <BANLkTimt_wt8hL1u2xSZ45EStNWV4AyU6g@mail.gmail.com>
Message-ID: <AANLkTinMfX8EhTwfpXiSCO2EpnfmMZcYTcYvm2=YK7ye@mail.gmail.com>

On Fri, Apr 1, 2011 at 06:50, BBands <bbands at gmail.com> wrote:
> Notepad++, my editor of choice for some years, dropped the Scientology
> bomb today. So it is time to move on as I'd prefer my editors to be
> without religion. I'd like an open-source, cross-platform editor with
> code folding, outlining, code completion for Python, R and other
> common languages and basic encryption support. Recommendations? (In
> China just now, so replies may be problematic.)

I have recently rediscovered the joy of Emacs, but that probably
violates the religion-free requirement!

James


From jeff.a.ryan at gmail.com  Fri Apr  1 18:28:19 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 1 Apr 2011 11:28:19 -0500
Subject: [R-SIG-Finance] R/Finance 2011 Conference Agenda
Message-ID: <AANLkTi=9jJk5zdGW4+BwdAQ6Gjc9C1ROwuD_E_=-Xc17@mail.gmail.com>

R community:

We're excited to post a preliminary agenda for the upcoming 3rd
conference on R and Applied Finance, to be held in Chicago on April
29th and 30th.

In addition to keynotes from John Bollinger, Mebane Faber, Stefano
Iacus and Louis Kates, we are excited to have 31 additional talks
covering the state of R and applied finance.

This represents a phenomenal opportunity to meet and interact with
some of the leading contributors in the field of finance, all with
relevant contributions using R.  We expect more than 200 participants
from industry, government, and academia for the 2 day event.  In
addition, a conference dinner Friday evening in the heart of the
financial district along Chicago's picturesque river will offer an
unprecedented opportunity to enjoy amazing food, drink and
conversation.

http://www.rinfinance.com/agenda/index.html

Registration is open, though pre-conference workshops are rapidly filling up.

Register now and join your fellow colleagues at R/Finance 2011!
http://www.rinfinance.com/register/



Thanks to our 2011 Co-Sponsors and Sponsors:

  International Center for Futures and Derivatives at UIC
  REvolution Analytics

  OneMarketData
  RStudio
  lemnica


From paulteetor at yahoo.com  Fri Apr  1 22:52:52 2011
From: paulteetor at yahoo.com (Paul Teetor)
Date: Fri, 1 Apr 2011 15:52:52 -0500
Subject: [R-SIG-Finance] ANNOUNCEMENT: Worlds' First Open Source Futures
	Exchange
Message-ID: <8D14CD2AC5F44584B743A2B42BD67FC7@XI>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110401/606e065d/attachment.pl>

From bbands at gmail.com  Sat Apr  2 02:36:13 2011
From: bbands at gmail.com (BBands)
Date: Sat, 2 Apr 2011 08:36:13 +0800
Subject: [R-SIG-Finance] editors
In-Reply-To: <25492B412B325B4FB1FED95013D3E5CE0CA3797B@NLDNC105PEX1.ubsw.net>
References: <BANLkTimt_wt8hL1u2xSZ45EStNWV4AyU6g@mail.gmail.com>
	<25492B412B325B4FB1FED95013D3E5CE0CA3797B@NLDNC105PEX1.ubsw.net>
Message-ID: <BANLkTimrZG-U9xPE+m_fthY8r8FF5LLV=A@mail.gmail.com>

On Fri, Apr 1, 2011 at 6:55 PM,  <david.jessop at ubs.com> wrote:
> One hopes it's an April Fool's joke but ...

Breathing a sigh of relief he types: From "Men in Black". Kay:
"No, ma'am. We at the FBI do not have a sense of humor we're aware
of... May we come in?"

Before I switched to Notepad++ I used Tinn which was orphanned by its
developer and then forked into Tinn-R. I rather liked that, but it
seems to be orphanned as well. Anyone know what's up with that?

Best.

    jab


From landronimirc at gmail.com  Sat Apr  2 06:42:56 2011
From: landronimirc at gmail.com (Liviu Andronic)
Date: Sat, 2 Apr 2011 06:42:56 +0200
Subject: [R-SIG-Finance] editors
In-Reply-To: <BANLkTimt_wt8hL1u2xSZ45EStNWV4AyU6g@mail.gmail.com>
References: <BANLkTimt_wt8hL1u2xSZ45EStNWV4AyU6g@mail.gmail.com>
Message-ID: <AANLkTik6CZAMxhUeqr=8o8FEarwfvhroi0DC8m=L+CxX@mail.gmail.com>

On Fri, Apr 1, 2011 at 12:50 PM, BBands <bbands at gmail.com> wrote:
> Notepad++, my editor of choice for some years, dropped the Scientology
> bomb today. So it is time to move on as I'd prefer my editors to be
> without religion. I'd like an open-source, cross-platform editor with
> code folding, outlining, code completion for Python, R and other
> common languages and basic encryption support.
>
I don't know if it would perfectly fit your requirements, but I like
Geany and RStudio. Many like Eclipse StatET or Emacs ESS.

Regards
Liviu


> Recommendations? (In
> China just now, so replies may be problematic.)
>
> John -- who has tried emacs in the past and didn't love it
>
> --
> John Bollinger, CFA, CMT
> www.BollingerBands.com
>
> If you advance far enough, you arrive at the beginning.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From kriskumar at earthlink.net  Sat Apr  2 17:02:10 2011
From: kriskumar at earthlink.net (Krishna)
Date: Sat, 2 Apr 2011 11:02:10 -0400
Subject: [R-SIG-Finance] ANNOUNCEMENT: Worlds' First Open Source Futures
	Exchange
In-Reply-To: <8D14CD2AC5F44584B743A2B42BD67FC7@XI>
References: <8D14CD2AC5F44584B743A2B42BD67FC7@XI>
Message-ID: <8DBA50BC-4698-45BC-8565-61A84EB5F3D6@earthlink.net>


I have some Zambian kwacha and facebook credits that I am more than  
happy to contribute.
I would n?ed a blank cheque from you so that I can send it your way.



On Apr 1, 2011, at 4:52 PM, "Paul Teetor" <paulteetor at yahoo.com> wrote:

> To the R Finance Community:
>
> I have some exciting news. I am announcing the formation of the  
> worlds'
> first futures exchange built entirely on open source software, pending
> regulatory approval.
>
> As modern exchanges become all-electronic, the cost of sofware has  
> driven up
> exchange fees. We can end that by creating an exchange built on free
> software. That will lower transaction costs, creating a market place  
> where
> anyone can trade inexpensively. By publishing the key software  
> components,
> we hope to encourage the formation of other, new futures exchanges,
> literally around the globe; or, for that matter, in your basement.
>
> The initial implementation will be written in R and LISP. Volunteers  
> are
> needed immediately to begin the important work of coding the system  
> before
> core team members can iron out the specifications.
>
> A large, Chicago-based futures exchange has tentatively agreed to  
> provide
> the necessary server farm, although no public announcement is  
> available at
> this time. A highly-placed exchange official, wishing to remain  
> anonymous
> for obvious reasons, says, "Many of us at [the exchange] are sick  
> and tired
> of running a for-profit corporation. We long for the good old days  
> when the
> exchange existed solely for the public good, not just for the  
> benefit of
> some greedy bastards in Chicago. This is our way of giving back to the
> community."
>
> Initial products will include futures on the most under-served  
> segments of
> the commodity markets, including fuel oil for delivery in Cushing,  
> Oklahoma
> (symbol: FOO), West Texas fuel oil (WTF), and natural fertilizer (BS).
>
> The new exchange is tentatively named the Fully Open On-Line  
> Exchange. Our
> schedule is ambitious, but we hope to be fully operational one year  
> from now
> on April 1.
>
> Please consider supporting this important project. I'll be accepting  
> cash
> donations very soon. Thank you.
>
> Paul Teetor
> Elgin, IL   USA
> http://www.linkedin.com/in/paulteetor
>
> "For quant traders, there are no bad days in the market. It's just  
> more
> data."
>
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R  
> questions should go.


From johannes.lips at googlemail.com  Sat Apr  2 17:04:40 2011
From: johannes.lips at googlemail.com (Johannes Lips)
Date: Sat, 02 Apr 2011 17:04:40 +0200
Subject: [R-SIG-Finance] editors
In-Reply-To: <AANLkTik6CZAMxhUeqr=8o8FEarwfvhroi0DC8m=L+CxX@mail.gmail.com>
References: <BANLkTimt_wt8hL1u2xSZ45EStNWV4AyU6g@mail.gmail.com>
	<AANLkTik6CZAMxhUeqr=8o8FEarwfvhroi0DC8m=L+CxX@mail.gmail.com>
Message-ID: <4D973B08.9070806@googlemail.com>

Everything seems to be fine!
http://notepad-plus-plus.org/news/no-donation-to-scientology-cult

On 04/02/2011 06:42 AM, Liviu Andronic wrote:
> On Fri, Apr 1, 2011 at 12:50 PM, BBands<bbands at gmail.com>  wrote:
>> Notepad++, my editor of choice for some years, dropped the Scientology
>> bomb today. So it is time to move on as I'd prefer my editors to be
>> without religion. I'd like an open-source, cross-platform editor with
>> code folding, outlining, code completion for Python, R and other
>> common languages and basic encryption support.
>>
> I don't know if it would perfectly fit your requirements, but I like
> Geany and RStudio. Many like Eclipse StatET or Emacs ESS.
>
> Regards
> Liviu
>
>
>> Recommendations? (In
>> China just now, so replies may be problematic.)
>>
>> John -- who has tried emacs in the past and didn't love it
>>
>> --
>> John Bollinger, CFA, CMT
>> www.BollingerBands.com
>>
>> If you advance far enough, you arrive at the beginning.
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>>
>
>
>


From xripro at gmail.com  Sun Apr  3 01:11:50 2011
From: xripro at gmail.com (xri pro)
Date: Sun, 3 Apr 2011 02:11:50 +0300
Subject: [R-SIG-Finance] Please help make an obv trade rule
Message-ID: <BANLkTimGEVoj15XJ=k2MH2On5mQ6AHVsJg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110403/585a7bc7/attachment.pl>

From xripro at gmail.com  Sun Apr  3 01:45:58 2011
From: xripro at gmail.com (xri pro)
Date: Sun, 3 Apr 2011 02:45:58 +0300
Subject: [R-SIG-Finance] Please help in a trade rule based on obv
Message-ID: <BANLkTinOep22As+5gkpnPXwfKHQjsa70kg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110403/a8ec63be/attachment.pl>

From xripro at gmail.com  Sun Apr  3 01:45:58 2011
From: xripro at gmail.com (xri pro)
Date: Sun, 3 Apr 2011 02:45:58 +0300
Subject: [R-SIG-Finance] Please help in a trade rule based on obv
Message-ID: <BANLkTinOep22As+5gkpnPXwfKHQjsa70kg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110403/a8ec63be/attachment-0001.pl>

From brian at braverock.com  Sun Apr  3 13:07:47 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 03 Apr 2011 06:07:47 -0500
Subject: [R-SIG-Finance] Please help in a trade rule based on obv
In-Reply-To: <BANLkTinOep22As+5gkpnPXwfKHQjsa70kg@mail.gmail.com>
References: <BANLkTinOep22As+5gkpnPXwfKHQjsa70kg@mail.gmail.com>
Message-ID: <4D985503.7060804@braverock.com>

On 04/02/2011 06:45 PM, xri pro wrote:
> Hi to all
> I am new to R and I would like to test the scenario that it is mentioned to
> this paper "Tsang, William Wai Him and Chong, Terence Tai Leung, (2009),
> Profitability of the On-Balance Volume Indicator, Economics Bulletin, 29,
> issue 3, p. 2424-2431."
>
> The trading rule examined in the paper is the crossover of OBV and its
>   simple 20-day moving average (OBVMA).
>
> Trading Rule
> Buy at day t: OBVt-1<  OBVMAt-1 and OBVt>  OBVMAt
> Buy at day t: OBVt-1>  OBVMAt-1 and OBVt<  OBVMAt
> long position is taken when OBV rises above its 20-day moving average, and
> the position is
> liquidated once OBV drops below the 20-day OBVMA .
>
> So far i managed to write a few lines for the script of this trading rule
> because just i said above i am new to R
> Here are the commands
> require(quantmod)
> getSymbols("GEK.AT", from="2006-01-01")
> obv<- OBV(Cl(GEK.AT), Vo(GEK.AT))
> obvma.20<- SMA(obv, n=20)
>
> I would like to help me to write the commands
> 1)for the trade rule,
> 2)to show up the plots of the obv and the obvma in the same graph and
> 3)the outcome of this trade rule.

The 'TTR' package has OBV and MA functions.

'quantmod' has chartSeries and chart_Series that will let you chart 
price/volume information along with your OBV and OBVMA indicators.

You can see some excellent blog posts by Josh Ulrich on backtesting 
trading ideas 'by hand' in R, or the 'quantstrat' has functions for 
merging all this into a full strategy definition containing indicators, 
signals, and rules,  It also has several demo strategies that, if 
examined, should give you an idea of how to construct the OBV strategy 
that you describe above.

Regards,

    - Brian


From johnny.jp.22 at gmail.com  Mon Apr  4 17:01:07 2011
From: johnny.jp.22 at gmail.com (Johnny Paulo)
Date: Mon, 4 Apr 2011 16:01:07 +0100
Subject: [R-SIG-Finance] reqMktData in IBrokers
In-Reply-To: <BANLkTi=B52YxctD_Vpr6fqXKEYuuAYqqAA@mail.gmail.com>
References: <BANLkTi=B52YxctD_Vpr6fqXKEYuuAYqqAA@mail.gmail.com>
Message-ID: <BANLkTi=cUaKygwyxBM+kU+699WkeSei=zw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110404/ddab58fb/attachment.pl>

From i.petzev at gmail.com  Tue Apr  5 00:20:43 2011
From: i.petzev at gmail.com (ivan)
Date: Tue, 5 Apr 2011 00:20:43 +0200
Subject: [R-SIG-Finance] Granger Causality in VAR Model
Message-ID: <BANLkTik7OwjU+pHKGbqcotvYZeFL5mhPEA@mail.gmail.com>

Dear Community,

I am new to R and have a question concerning the causality () test in
the vars package. I need to test whether, say, the variable y Granger
causes the variable x, given z as a control variable.

I estimated the VAR model as follows: >model<-VAR(cbind(x,y,z),p=2)

Then I did the following: >causality(model, cause="y"). I thing this
tests the Granger causality of y on the vector (x,z), though. How can
I implement the test for y causing x controlled for z? Thus, the
F-test comparing the two models M1:x~lagged(x)+lagged(z) and
M2:x~lagged(x)+lagged(y)+lagged(z)?

Thank you in advance.

Best Regards


From paulteetor at yahoo.com  Tue Apr  5 00:43:33 2011
From: paulteetor at yahoo.com (Paul Teetor)
Date: Mon, 4 Apr 2011 15:43:33 -0700 (PDT)
Subject: [R-SIG-Finance] ANNOUNCEMENT: Worlds' First Open Source Futures
	Exchange
Message-ID: <880920.81115.qm@web65902.mail.ac4.yahoo.com>

OMG!! I am so sorry!!!!

It seems that someone used my e-mail account and sent this bogus April Fool's Day message to the entire R-SIG-Finance list. I apologize for the confusion.

Just for the record, I am not planning to implement an open-source futures exchange. I certainly would not implement one in R or LISP. I'd use FORTRAN and COBOL, of course.

Again, I apologize, and I can assure you this will not happen again soon.

Paul

Paul Teetor, Elgin, IL??USA
http://quanttrader.info/public


----- Original Message -----
From:Paul Teetor <paulteetor at yahoo.com>
To:R-SIG-Finance at r-project.org
Cc:
Sent:Friday, April 1, 2011 3:52 PM
Subject:[R-SIG-Finance] ANNOUNCEMENT: Worlds' First Open Source Futures Exchange

To the R Finance Community:

I have some exciting news. I am announcing the formation of the worlds'
first futures exchange built entirely on open source software, pending
regulatory approval.

As modern exchanges become all-electronic, the cost of sofware has driven up
exchange fees. We can end that by creating an exchange built on free
software. That will lower transaction costs, creating a market place where
anyone can trade inexpensively. By publishing the key software components,
we hope to encourage the formation of other, new futures exchanges,
literally around the globe; or, for that matter, in your basement.

The initial implementation will be written in R and LISP. Volunteers are
needed immediately to begin the important work of coding the system before
core team members can iron out the specifications.

A large, Chicago-based futures exchange has tentatively agreed to provide
the necessary server farm, although no public announcement is available at
this time. A highly-placed exchange official, wishing to remain anonymous
for obvious reasons, says, "Many of us at [the exchange] are sick and tired
of running a for-profit corporation. We long for the good old days when the
exchange existed solely for the public good, not just for the benefit of
some greedy bastards in Chicago. This is our way of giving back to the
community."

Initial products will include futures on the most under-served segments of
the commodity markets, including fuel oil for delivery in Cushing, Oklahoma
(symbol: FOO), West Texas fuel oil (WTF), and natural fertilizer (BS).

The new exchange is tentatively named the Fully Open On-Line Exchange. Our
schedule is ambitious, but we hope to be fully operational one year from now
on April 1.

Please consider supporting this important project. I'll be accepting cash
donations very soon. Thank you.

Paul Teetor
Elgin, IL???USA
http://www.linkedin.com/in/paulteetor

"For quant traders, there are no bad days in the market. It's just more
data."


??? [[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


From savio.debian at gmail.com  Tue Apr  5 03:43:22 2011
From: savio.debian at gmail.com (=?ISO-8859-1?Q?S=E1vio_Ramos?=)
Date: Mon, 4 Apr 2011 22:43:22 -0300
Subject: [R-SIG-Finance] addBBands don't work
Message-ID: <BANLkTi=S98sHzyH9dEVX20-aoySpR8O96g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110404/6b107815/attachment.pl>

From josh.m.ulrich at gmail.com  Tue Apr  5 03:52:16 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 4 Apr 2011 20:52:16 -0500
Subject: [R-SIG-Finance] addBBands don't work
In-Reply-To: <BANLkTi=S98sHzyH9dEVX20-aoySpR8O96g@mail.gmail.com>
References: <BANLkTi=S98sHzyH9dEVX20-aoySpR8O96g@mail.gmail.com>
Message-ID: <BANLkTikte1MXZGbs0oemFbeigWPoyb_b1A@mail.gmail.com>

On Mon, Apr 4, 2011 at 8:43 PM, S?vio Ramos <savio.debian at gmail.com> wrote:
> The command addBBands don't work. The error message is:
>
> PETR4<- as.xts(read.zoo("
> http://ichart.finance.yahoo.com/table.csv?s=PETR4.SA&d=3&e=3&f=2011&g=d&a=0&b=3&c=2000&ignore=.csv",
> sep=",", format="%Y-%m-%d", header=TRUE))
>
You're already using quantmod, why not just use:
PETR4 <- getSymbols("PETR4.SA, auto.assign=FALSE)

> candleChart(PETR4,multi.col=TRUE,theme="white",subset='last 7 months',
> line.type="0.1")
>
>
>> addBBands()
>
> ## Erro em BBands(xx, n = n, maType = maType, sd = sd) :
> ## ? Price series must be either High-Low-Close, or Close/univariate.
>
This is because the data has two columns that match "Close" (Close and
Adj.Close).  Either rename the columns after you pull the data, or
just use getSymbols.

PETR4 <- getSymbols("PETR4.SA", auto.assign=FALSE)
candleChart(PETR4,multi.col=TRUE,theme="white",subset='last 7
months',line.type="0.1")
addBBands()

>
>
> The format of data is:
>
>> head(PETR4)
> ? ? ? ? ? ? Open ? High ? ?Low ?Close ? ? Volume Adj.Close
> 2000-01-03 115.25 118.25 114.50 117.49 1105920000 ? ? 37.32
> 2000-01-04 115.00 115.00 110.25 111.00 ?901920000 ? ? 35.25
> 2000-01-05 110.25 112.50 106.25 109.88 1344800000 ? ? 34.90
> 2000-01-06 109.25 112.38 108.50 109.50 1064240000 ? ? 34.78
> 2000-01-07 111.25 113.25 110.00 110.00 ?653520000 ? ? 34.94
> 2000-01-10 112.38 113.75 112.00 112.25 ?611360000 ? ? 35.65
>
>
> Any help?
> Thanks.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From Bernhard_Pfaff at fra.invesco.com  Tue Apr  5 10:01:30 2011
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Tue, 5 Apr 2011 09:01:30 +0100
Subject: [R-SIG-Finance] Granger Causality in VAR Model
In-Reply-To: <BANLkTik7OwjU+pHKGbqcotvYZeFL5mhPEA@mail.gmail.com>
References: <BANLkTik7OwjU+pHKGbqcotvYZeFL5mhPEA@mail.gmail.com>
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C328577587@GBHENXMB02.corp.amvescap.net>

Hello Ivan,

this is most easily achieved, if you supply z as an exogenous variable. Hence, the dimension of your VAR reduces from three (x, y, z) to two (x, y). See ?VAR for available arguments.

Best,
Bernhard  

> -----Urspr?ngliche Nachricht-----
> Von: r-sig-finance-bounces at r-project.org 
> [mailto:r-sig-finance-bounces at r-project.org] Im Auftrag von ivan
> Gesendet: Dienstag, 5. April 2011 00:21
> An: r-sig-finance at r-project.org
> Betreff: [R-SIG-Finance] Granger Causality in VAR Model
> 
> Dear Community,
> 
> I am new to R and have a question concerning the causality () 
> test in the vars package. I need to test whether, say, the 
> variable y Granger causes the variable x, given z as a 
> control variable.
> 
> I estimated the VAR model as follows: >model<-VAR(cbind(x,y,z),p=2)
> 
> Then I did the following: >causality(model, cause="y"). I 
> thing this tests the Granger causality of y on the vector 
> (x,z), though. How can I implement the test for y causing x 
> controlled for z? Thus, the F-test comparing the two models 
> M1:x~lagged(x)+lagged(z) and M2:x~lagged(x)+lagged(y)+lagged(z)?
> 
> Thank you in advance.
> 
> Best Regards
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R 
> questions should go.
> 
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:10}}


From i.petzev at gmail.com  Tue Apr  5 13:42:24 2011
From: i.petzev at gmail.com (ivan)
Date: Tue, 5 Apr 2011 13:42:24 +0200
Subject: [R-SIG-Finance] Granger Causality in VAR Model
In-Reply-To: <B89F0CE41D45644A97CCC93DF548C1C328577587@GBHENXMB02.corp.amvescap.net>
References: <BANLkTik7OwjU+pHKGbqcotvYZeFL5mhPEA@mail.gmail.com>
	<B89F0CE41D45644A97CCC93DF548C1C328577587@GBHENXMB02.corp.amvescap.net>
Message-ID: <BANLkTimGPd8A2+p+20h__pqmAXEGEJ6ObA@mail.gmail.com>

Hello, thank you very much. You were a great help.

On Tue, Apr 5, 2011 at 10:01 AM, Pfaff, Bernhard Dr.
<Bernhard_Pfaff at fra.invesco.com> wrote:
> Hello Ivan,
>
> this is most easily achieved, if you supply z as an exogenous variable. Hence, the dimension of your VAR reduces from three (x, y, z) to two (x, y). See ?VAR for available arguments.
>
> Best,
> Bernhard
>
>> -----Urspr?ngliche Nachricht-----
>> Von: r-sig-finance-bounces at r-project.org
>> [mailto:r-sig-finance-bounces at r-project.org] Im Auftrag von ivan
>> Gesendet: Dienstag, 5. April 2011 00:21
>> An: r-sig-finance at r-project.org
>> Betreff: [R-SIG-Finance] Granger Causality in VAR Model
>>
>> Dear Community,
>>
>> I am new to R and have a question concerning the causality ()
>> test in the vars package. I need to test whether, say, the
>> variable y Granger causes the variable x, given z as a
>> control variable.
>>
>> I estimated the VAR model as follows: >model<-VAR(cbind(x,y,z),p=2)
>>
>> Then I did the following: >causality(model, cause="y"). I
>> thing this tests the Granger causality of y on the vector
>> (x,z), though. How can I implement the test for y causing x
>> controlled for z? Thus, the F-test comparing the two models
>> M1:x~lagged(x)+lagged(z) and M2:x~lagged(x)+lagged(y)+lagged(z)?
>>
>> Thank you in advance.
>>
>> Best Regards
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R
>> questions should go.
>>
> *****************************************************************
> Confidentiality Note: The information contained in this message,
> and any attachments, may contain confidential and/or privileged
> material. It is intended solely for the person(s) or entity to
> which it is addressed. Any review, retransmission, dissemination,
> or taking of any action in reliance upon this information by
> persons or entities other than the intended recipient(s) is
> prohibited. If you received this in error, please contact the
> sender and delete the material from any computer.
> *****************************************************************
>
>


From worik.stanton at gmail.com  Wed Apr  6 00:16:42 2011
From: worik.stanton at gmail.com (Worik)
Date: Wed, 06 Apr 2011 10:16:42 +1200
Subject: [R-SIG-Finance] Sullivan, Timmerman and White 1999: TA rules,
 and R
In-Reply-To: <4D91CD49.4070203@braverock.com>
References: <4D90FEA1.2030800@gmail.com>	<AANLkTikuLF=h-hzxrKrFPcmWJ7MSVke7zPLZBk9nLZ3A@mail.gmail.com>
	<4D91CD49.4070203@braverock.com>
Message-ID: <4D9B94CA.5000108@gmail.com>


I am just pushing ahead and coding these.  Using some TTR stuff where 
applicable,  but only SMA has been so far (I have  not completed the 
task yet).  But I am grateful for that.  Thank you TTR.

>   I don't understand how the support and
> resistance rules differ from the channel break-outs, but that could be
> due to the time of day and my lack of sleep.  Regardless, I doubt they
> would be difficult to code.

Me too!  I decided to interpret it as:

support & resistance: Long when P_t > max(P, t, t-n)

And for channel breakout:  Long when P_t > min(P, t-1, t-n) x (1+x)

And the rule is used when max(P, t-1, t-n) < min(P, t-1, t-n) x (1+n)
Subtle but it does make them different.

The Sullivan et. el. paper does have some serious shortcomings, not the 
least that there are insufficient references to proper descriptions of 
these rules, that I only notice as I implement them.  Such is life!
> DonchianChannel, or OBV, es needed.  Channel Break-outs are also often 
> called pivots.  We have some code for this, and will endeavor to 
> document it and get it into TTR. 
Channel Breakouts / Pivots?  Interesting.  Have you any where I can go 
to look for more information?

Thanks for your attention people.  This is fun!

cheers
Worik

-- 
If we amplify everything, we hear nothing.
--


From worik.stanton at gmail.com  Wed Apr  6 00:20:16 2011
From: worik.stanton at gmail.com (Worik)
Date: Wed, 06 Apr 2011 10:20:16 +1200
Subject: [R-SIG-Finance] Sullivan, Timmerman and  White 1999:  TA rules,
 and R
In-Reply-To: <4D91C78F.8010905@braverock.com>
References: <4D90FEA1.2030800@gmail.com> <4D91C78F.8010905@braverock.com>
Message-ID: <4D9B95A0.8070509@gmail.com>

On 30/03/11 00:50, Brian G. Peterson wrote:
> So, for example, you would use the signal generator functions 
> sigCrossover sigThreshold, sigPeak, and maybe sigFormula to generate 
> your entry and exit signals.  Then, rule generation for entry and exit 
> rules proceeds as normal using ruleSignal. 

I must have missed some thing.  What are ruleSignal, sigFormula etcetera?

W

-- 
If we amplify everything, we hear nothing.
--


From Luis.Pacheco at asurion.com  Thu Apr  7 04:23:12 2011
From: Luis.Pacheco at asurion.com (Pacheco, Luis)
Date: Wed, 6 Apr 2011 21:23:12 -0500
Subject: [R-SIG-Finance] Calculate AGG monthly returns using Quantmod
Message-ID: <5E3C0A528DFD7049B6CCF5C070D37BEFF29717@NDCEXCUS703.int.asurion.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110406/79e39ec5/attachment.pl>

From kent.russell at live.com  Thu Apr  7 13:42:16 2011
From: kent.russell at live.com (Kent Russell)
Date: Thu, 7 Apr 2011 06:42:16 -0500
Subject: [R-SIG-Finance] agg monthly returns
Message-ID: <BLU0-SMTP18175C2E1F7B9E4F64AAD44FBA40@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110407/a25ee80b/attachment.pl>

From babel at centrum.sk  Thu Apr  7 18:32:32 2011
From: babel at centrum.sk (babel at centrum.sk)
Date: Thu, 07 Apr 2011 18:32:32 +0200
Subject: [R-SIG-Finance] Vasicek,CIR or RiskMetrics
In-Reply-To: <BLU0-SMTP18175C2E1F7B9E4F64AAD44FBA40@phx.gbl>
References: <BLU0-SMTP18175C2E1F7B9E4F64AAD44FBA40@phx.gbl>
Message-ID: <20110407183232.CBA31420@centrum.sk>


Hello researchers

Do you have some experience with risk measurement by Vasicek, CIR models or geometric Brownian distribution? Are there any R packages supporting these models?  
I found these 2 links, that are quite helpful 
http://www.r-bloggers.com/basket-option-pricing-step-by-step/   
http://www.r-bloggers.com/fun-with-the-vasicek-interest-rate-model/

and I also searched ??? in R, but found only simulations.

I would like to model few currency pairs by mentioned models and consequently their future influence on costs, revenues and sales. Or can you point off some better techniques,solutions or references for modeling corporate risk  in R?
Thank you very much.


From ezivot at u.washington.edu  Thu Apr  7 18:38:18 2011
From: ezivot at u.washington.edu (Eric Zivot)
Date: Thu, 7 Apr 2011 09:38:18 -0700
Subject: [R-SIG-Finance] Vasicek,CIR or RiskMetrics
In-Reply-To: <20110407183232.CBA31420@centrum.sk>
References: <BLU0-SMTP18175C2E1F7B9E4F64AAD44FBA40@phx.gbl>
	<20110407183232.CBA31420@centrum.sk>
Message-ID: <004b01cbf542$33502c50$99f084f0$@washington.edu>

Check out the sde package and the very nice book by Stefano Iacus that goes
with it

http://www.amazon.com/Simulation-Inference-Stochastic-Differential-Equations
/dp/1441926070/ref=sr_1_1?ie=UTF8&s=books&qid=1302194109&sr=8-1


-----Original Message-----
From: r-sig-finance-bounces at r-project.org
[mailto:r-sig-finance-bounces at r-project.org] On Behalf Of babel at centrum.sk
Sent: Thursday, April 07, 2011 9:33 AM
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] Vasicek,CIR or RiskMetrics


Hello researchers

Do you have some experience with risk measurement by Vasicek, CIR models or
geometric Brownian distribution? Are there any R packages supporting these
models?  
I found these 2 links, that are quite helpful 
http://www.r-bloggers.com/basket-option-pricing-step-by-step/   
http://www.r-bloggers.com/fun-with-the-vasicek-interest-rate-model/

and I also searched ??? in R, but found only simulations.

I would like to model few currency pairs by mentioned models and
consequently their future influence on costs, revenues and sales. Or can you
point off some better techniques,solutions or references for modeling
corporate risk  in R?
Thank you very much.

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From cmdr_rogue at hotmail.com  Sun Apr 10 02:37:54 2011
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Sat, 9 Apr 2011 20:37:54 -0400
Subject: [R-SIG-Finance] Vasicek,CIR or RiskMetrics
In-Reply-To: <20110407183232.CBA31420@centrum.sk>
References: <BLU0-SMTP18175C2E1F7B9E4F64AAD44FBA40@phx.gbl>
	<20110407183232.CBA31420@centrum.sk>
Message-ID: <BLU0-SMTP112F997ADAE9EC31AD321D8E2A90@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110409/7f1d4c43/attachment.pl>

From elliot.bernstein at fdopartners.com  Sun Apr 10 17:49:18 2011
From: elliot.bernstein at fdopartners.com (Elliot Joel Bernstein)
Date: Sun, 10 Apr 2011 11:49:18 -0400
Subject: [R-SIG-Finance] R Memory Usage
Message-ID: <BANLkTimDoH+uRs09WpzOad8R7Qwh+xzF-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110410/4c1d6617/attachment.pl>

From brian at braverock.com  Sun Apr 10 18:11:31 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 10 Apr 2011 11:11:31 -0500
Subject: [R-SIG-Finance] R Memory Usage
In-Reply-To: <BANLkTimDoH+uRs09WpzOad8R7Qwh+xzF-Q@mail.gmail.com>
References: <BANLkTimDoH+uRs09WpzOad8R7Qwh+xzF-Q@mail.gmail.com>
Message-ID: <4DA1D6B3.80305@braverock.com>

On 04/10/2011 10:49 AM, Elliot Joel Bernstein wrote:
> This is not specifically a finance question, but I'm working with financial
> data (daily stock returns), and I suspect many people using R for financial
> analysis face similar issues. The basic problem I'm having is that with a
> moderately large data set (800 stocks x 11 years), performing a few
> operations such as data transformations, fitting regressions, etc., results
> in R using an enormous amount of memory -- sometimes upwards of 5GB -- even
> after using gc() to try and free some memory up. I've read several posts to
> various R mailing lists over the years indicating that R does not release
> memory back to the system on certain OSs (64 bit Linux in my case), so I
> understand that this is "normal" behavior for R. How do people typically
> work around this to do exploratory analysis on large data sets without
> having to constantly restart R to free up memory?

Your data set isn't very large.  We use R on months of tick data at a time.

You are correct that R keeps the memory allocated for its use, but it 
*will* release it to the OS in large chunks if the OS asks for more 
memory back.  So, once you've used a lot of RAM, R will keep it 
available, expecting you to use it again, but release it to the OS if 
the kernel asks.  This shouldn't negatively affect performance on 64 bit 
linux (it's the environment we use too).

You *do* want to be careful how many copies you make and keep around. 
Things like overwriting the original var with your transformed data, 
using environments, etc can vastly improve your memory profile.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From jeffrey.ryan at lemnica.com  Sun Apr 10 21:14:42 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Sun, 10 Apr 2011 14:14:42 -0500
Subject: [R-SIG-Finance] R Memory Usage
In-Reply-To: <BANLkTimDoH+uRs09WpzOad8R7Qwh+xzF-Q@mail.gmail.com>
References: <BANLkTimDoH+uRs09WpzOad8R7Qwh+xzF-Q@mail.gmail.com>
Message-ID: <BANLkTi=+U=PSos6GDi7CUk0UJ3EXQ7tb0A@mail.gmail.com>

Elliot,

One of the advantages to posting to the finance list is that those of
us who work around large data in finance can comment on tools that you
use as well.

One thing you didn't mention specifically was which packages you are
using and maybe examples of specific code you are calling.

Within financial time-series, one of the most optimized tools is xts -
precisely for the reason of memory management and optimizations for
large data.  Using something ad-hoc, for example strings and
data.frames - would cause tremendous issues.

Another issue would be whether or not you need the full data resident
in memory at all times.  R's rds format, or a database, or use of
out-of-core objects such as with mmap or indexing - can greatly
improve things.

If you are able to come to the R/Finance conference in Chicago on the
29th and 30th of this month, you'll have a chance to talk to some of
those 'in the trenches' with respect to using R on big data.  And as
you point our (as well as Brian) - 800x3000 isn't very large, so your
case isn't unique.

Would be great to see you later this month in Chicago!  www.RinFinance.com

Best,
Jeff



On Sun, Apr 10, 2011 at 10:49 AM, Elliot Joel Bernstein
<elliot.bernstein at fdopartners.com> wrote:
> This is not specifically a finance question, but I'm working with financial
> data (daily stock returns), and I suspect many people using R for financial
> analysis face similar issues. The basic problem I'm having is that with a
> moderately large data set (800 stocks x 11 years), performing a few
> operations such as data transformations, fitting regressions, etc., results
> in R using an enormous amount of memory -- sometimes upwards of 5GB -- even
> after using gc() to try and free some memory up. I've read several posts to
> various R mailing lists over the years indicating that R does not release
> memory back to the system on certain OSs (64 bit Linux in my case), so I
> understand that this is "normal" behavior for R. How do people typically
> work around this to do exploratory analysis on large data sets without
> having to constantly restart R to free up memory?
>
> Thanks.
>
> - Elliot Joel Bernstein
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com

R/Finance 2011 April 29th and 30th in Chicago | www.RinFinance.com


From worik.stanton at gmail.com  Mon Apr 11 23:53:34 2011
From: worik.stanton at gmail.com (Worik)
Date: Tue, 12 Apr 2011 09:53:34 +1200
Subject: [R-SIG-Finance] Artificial price series
Message-ID: <4DA3785E.9040302@gmail.com>

Friends

Is there some where a straight forward method for generating an 
artificial price or return series?

I have been playing around with simple random walks but they are not 
very satisfactory.  Very monotonic when compared to actual time series.  
I guess because of the constant return.

I am assuming that this is a common need but my last hour of Googling 
has gotten me nowhere

cheers
Worik

-- 
If we amplify everything, we hear nothing.
--


From Patrick.Caldon at morningstar.com  Tue Apr 12 02:29:01 2011
From: Patrick.Caldon at morningstar.com (Patrick Caldon)
Date: Mon, 11 Apr 2011 19:29:01 -0500
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <4DA3785E.9040302@gmail.com>
Message-ID: <3E65933CA88B4245AA00080ED5F79E0A77192A@MSEX891.morningstar.com>


>Is there some where a straight forward method for generating an 
>artificial price or return series?

Have a look at "MonteCarloOption" in the fOptions package for a
reasonably simple example Monte-Carlo simulator for univariate time
series. 

Patrick.

____
Patrick Caldon,
Analyst
Morningstar Australasia Pty. Ltd.


From kent.russell at live.com  Tue Apr 12 16:56:03 2011
From: kent.russell at live.com (Kent Russell)
Date: Tue, 12 Apr 2011 09:56:03 -0500
Subject: [R-SIG-Finance] Importing shiller xls from http://
References: <E3CE3F88-EBE1-45C9-8F0E-58FFC0903BA6@gmail.com>
Message-ID: <BLU0-SMTP6785A4C52182DE959D690AFBAB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110412/103277bc/attachment.pl>

From dstjohn at math.uic.edu  Tue Apr 12 18:38:06 2011
From: dstjohn at math.uic.edu (David St John)
Date: Tue, 12 Apr 2011 11:38:06 -0500
Subject: [R-SIG-Finance] Artificial price series
Message-ID: <BANLkTi=xGGmKLfeVvxMF=OV+uPhE+kGzyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110412/722bc952/attachment.pl>

From dstjohn at math.uic.edu  Tue Apr 12 18:44:13 2011
From: dstjohn at math.uic.edu (David St John)
Date: Tue, 12 Apr 2011 11:44:13 -0500
Subject: [R-SIG-Finance] Artificial price series
Message-ID: <BANLkTin-TnB2gSTossneaMxYN8d0KywWqg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110412/3f62ea6f/attachment.pl>

From breman.mark at gmail.com  Tue Apr 12 19:28:10 2011
From: breman.mark at gmail.com (Mark Breman)
Date: Tue, 12 Apr 2011 19:28:10 +0200
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <BANLkTin-TnB2gSTossneaMxYN8d0KywWqg@mail.gmail.com>
References: <BANLkTin-TnB2gSTossneaMxYN8d0KywWqg@mail.gmail.com>
Message-ID: <BANLkTiniQ8rBPsHSPtm9kZip6iLdqO5Grw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110412/cb988b65/attachment.pl>

From markleeds2 at gmail.com  Tue Apr 12 20:05:13 2011
From: markleeds2 at gmail.com (Mark Leeds)
Date: Tue, 12 Apr 2011 14:05:13 -0400
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <BANLkTiniQ8rBPsHSPtm9kZip6iLdqO5Grw@mail.gmail.com>
References: <BANLkTin-TnB2gSTossneaMxYN8d0KywWqg@mail.gmail.com>
	<BANLkTiniQ8rBPsHSPtm9kZip6iLdqO5Grw@mail.gmail.com>
Message-ID: <BANLkTimj=1XQvdmXSD5i+hkyYwEcYYeieg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110412/293b8969/attachment.pl>

From josh.m.ulrich at gmail.com  Tue Apr 12 20:06:17 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 12 Apr 2011 13:06:17 -0500
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <BANLkTi=xGGmKLfeVvxMF=OV+uPhE+kGzyg@mail.gmail.com>
References: <BANLkTi=xGGmKLfeVvxMF=OV+uPhE+kGzyg@mail.gmail.com>
Message-ID: <BANLkTi=oV-uy+UUVwq+nAQssWHL5iBsSLg@mail.gmail.com>

Hi David,

On Tue, Apr 12, 2011 at 11:38 AM, David St John <dstjohn at math.uic.edu> wrote:
> Worik,
>
> See bootstrap() and generateSample() in the ttrTests package. ?If you have a
> real price series these functions create a randomly resampled series.
> Bootstrapping using the 'block' method has many desirable statistical
> properties, given minimal assumptions on the underlying process that
> generated the original price data.
>
What's the benefit of using ttrTests::bootstrap versus boot::tsboot
and tseries::tsbootstrap that come with R?

> If you don't have a real price series you're trying to mimic, then you're on
> your own picking a distribution and hoping that a sample from that
> distribution resembles a stock price series!
>
> Best,
> -David
>

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From Horace.Tso at pgn.com  Tue Apr 12 21:02:41 2011
From: Horace.Tso at pgn.com (Horace Tso)
Date: Tue, 12 Apr 2011 12:02:41 -0700
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <BANLkTimj=1XQvdmXSD5i+hkyYwEcYYeieg@mail.gmail.com>
References: <BANLkTin-TnB2gSTossneaMxYN8d0KywWqg@mail.gmail.com>
	<BANLkTiniQ8rBPsHSPtm9kZip6iLdqO5Grw@mail.gmail.com>
	<BANLkTimj=1XQvdmXSD5i+hkyYwEcYYeieg@mail.gmail.com>
Message-ID: <5C3F9922B1D5FB4886B2D2045AB952F3057A338563@IPEXMAIL.corp.dom>

Mark, except in some rare instances, evidence is clear that financial prices are anything but brownian motion. And i think that's the reason Worik notices in some qualitative way random walk simulation appears unreal. One of the key differences is real price series have jumps. All these recent papers by Ait-Sahalia (2010, 2009, 2008, 2004) and others have shown one is better off with a semimartingale model with some compound Poisson process. 

In fact, the guy is arguing whether brownian motion is even necessary to model high frequency data (Annals of Statistics 2010, Vol. 38, No. 5, 3093-3128). 

H
 

-----Original Message-----
From: r-sig-finance-bounces at r-project.org [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Mark Leeds
Sent: Tuesday, April 12, 2011 11:05 AM
To: Mark Breman
Cc: r-sig-finance at stat.math.ethz.ch; David St John
Subject: Re: [R-SIG-Finance] Artificial price series

Hi: if you can assume that returns follow brownian motion, then, in his book
Simulation and Infernce for Stochastic Differential equations  on pg 26,
Stefano Iacus shows how to generate the  trajectory of the stock price of
S_N starting at S_0 and using increments of deltaT.  The code below is from
the book directory of his sde package and is labelled ex1.10.R. If you don't
have his book, the explanation for below is also in Hull and any other
decent derivatives text.

#==============================================================================

set.seed(123)
r <- 1
sigma <- 0.5
x <- 10
N <- 100   # number of end points of the grid including T
T <- 1 # length of the interval [0,T] in time units
Delta <- T/N # time increment
W <- numeric(N+1) # initialization of the vector W
t <- seq(0,T, length=N+1)
for(i in 2:(N+1))
        W[i] <- W[i-1] + rnorm(1) * sqrt(Delta)
S <- x * exp((r-sigma^2/2)*t + sigma*W)
plot(t,S,type="l",main="geometric Brownian motion")










On Tue, Apr 12, 2011 at 1:28 PM, Mark Breman <breman.mark at gmail.com> wrote:

> Hi David,
>
> That's what i like so much about following this list: you regularly read
> about things you never knew existed!
> This package looks great David.
>
> -Mark-
>
> 2011/4/12 David St John <dstjohn at math.uic.edu>
>
> > Make sure to use bootstrap() for returns data and generateSample() for
> > price
> > data.  bootstrap() only makes sense for a stationary series.  The
> > stationarity assumptions make it desirable to sample from the returns.
> > generateSample() creates returns from prices, bootstraps them, then
> > calculates the random prices from the bootstrapped returns.
> > -David
> >
> >        [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> > should go.
> >
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


From markleeds2 at gmail.com  Tue Apr 12 21:08:52 2011
From: markleeds2 at gmail.com (Mark Leeds)
Date: Tue, 12 Apr 2011 15:08:52 -0400
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <5C3F9922B1D5FB4886B2D2045AB952F3057A338563@IPEXMAIL.corp.dom>
References: <BANLkTin-TnB2gSTossneaMxYN8d0KywWqg@mail.gmail.com>
	<BANLkTiniQ8rBPsHSPtm9kZip6iLdqO5Grw@mail.gmail.com>
	<BANLkTimj=1XQvdmXSD5i+hkyYwEcYYeieg@mail.gmail.com>
	<5C3F9922B1D5FB4886B2D2045AB952F3057A338563@IPEXMAIL.corp.dom>
Message-ID: <BANLkTikf-kdTkrHcU=rF+pkLNicCvrdDUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110412/91d6abac/attachment.pl>

From Horace.Tso at pgn.com  Tue Apr 12 21:32:54 2011
From: Horace.Tso at pgn.com (Horace Tso)
Date: Tue, 12 Apr 2011 12:32:54 -0700
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <BANLkTikf-kdTkrHcU=rF+pkLNicCvrdDUA@mail.gmail.com>
References: <BANLkTin-TnB2gSTossneaMxYN8d0KywWqg@mail.gmail.com>
	<BANLkTiniQ8rBPsHSPtm9kZip6iLdqO5Grw@mail.gmail.com>
	<BANLkTimj=1XQvdmXSD5i+hkyYwEcYYeieg@mail.gmail.com>
	<5C3F9922B1D5FB4886B2D2045AB952F3057A338563@IPEXMAIL.corp.dom>
	<BANLkTikf-kdTkrHcU=rF+pkLNicCvrdDUA@mail.gmail.com>
Message-ID: <5C3F9922B1D5FB4886B2D2045AB952F3057A3385C8@IPEXMAIL.corp.dom>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110412/9d379831/attachment.pl>

From markleeds2 at gmail.com  Tue Apr 12 21:40:39 2011
From: markleeds2 at gmail.com (Mark Leeds)
Date: Tue, 12 Apr 2011 15:40:39 -0400
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <5C3F9922B1D5FB4886B2D2045AB952F3057A3385C8@IPEXMAIL.corp.dom>
References: <BANLkTin-TnB2gSTossneaMxYN8d0KywWqg@mail.gmail.com>
	<BANLkTiniQ8rBPsHSPtm9kZip6iLdqO5Grw@mail.gmail.com>
	<BANLkTimj=1XQvdmXSD5i+hkyYwEcYYeieg@mail.gmail.com>
	<5C3F9922B1D5FB4886B2D2045AB952F3057A338563@IPEXMAIL.corp.dom>
	<BANLkTikf-kdTkrHcU=rF+pkLNicCvrdDUA@mail.gmail.com>
	<5C3F9922B1D5FB4886B2D2045AB952F3057A3385C8@IPEXMAIL.corp.dom>
Message-ID: <BANLkTi=hHSgU7-ocBU7N0x8h5xaPJHTEgA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110412/1ec0bf0d/attachment.pl>

From dstjohn at math.uic.edu  Tue Apr 12 21:42:40 2011
From: dstjohn at math.uic.edu (David St John)
Date: Tue, 12 Apr 2011 14:42:40 -0500
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <BANLkTi=oV-uy+UUVwq+nAQssWHL5iBsSLg@mail.gmail.com>
References: <BANLkTi=xGGmKLfeVvxMF=OV+uPhE+kGzyg@mail.gmail.com>
	<BANLkTi=oV-uy+UUVwq+nAQssWHL5iBsSLg@mail.gmail.com>
Message-ID: <BANLkTi=P8aN79g4D9Sa4fem+2C9Mp2aBVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110412/cc7dfecb/attachment.pl>

From edd at debian.org  Tue Apr 12 21:48:02 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 12 Apr 2011 14:48:02 -0500
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <BANLkTiniQ8rBPsHSPtm9kZip6iLdqO5Grw@mail.gmail.com>
References: <BANLkTin-TnB2gSTossneaMxYN8d0KywWqg@mail.gmail.com>
	<BANLkTiniQ8rBPsHSPtm9kZip6iLdqO5Grw@mail.gmail.com>
Message-ID: <19876.44146.717502.351769@max.nulle.part>


On 12 April 2011 at 19:28, Mark Breman wrote:
| That's what i like so much about following this list: you regularly read
| about things you never knew existed!

<shameless "ad" for a free product or two> 

  In fact, that's why I wrote CRANberries (which has been at your service 
  at http://dirk.eddelbuettel.com/cranberries/ for both html or, preferably,
  rss aggregation) and why I extended it to tweet via the @CRANberriesFeed
  handle.

  There is so much good change in the R world that you need the help of a
  diligent bot to keep up.

</shameless "ad" for a free product or two> 

That said, the list is still very good :)

Hope this helps, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From jeffrey.ryan at lemnica.com  Tue Apr 12 22:02:05 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Tue, 12 Apr 2011 15:02:05 -0500
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <19876.44146.717502.351769@max.nulle.part>
References: <BANLkTin-TnB2gSTossneaMxYN8d0KywWqg@mail.gmail.com>
	<BANLkTiniQ8rBPsHSPtm9kZip6iLdqO5Grw@mail.gmail.com>
	<19876.44146.717502.351769@max.nulle.part>
Message-ID: <BANLkTi=QBe8_=FCbreq7KQ-a-SE+1S5TuA@mail.gmail.com>

Dirk forgot to add in his shameless plug:



You can even talk *in person* with Stefano, David, Dirk, myself, Josh,
Mark Leeds, and many, many others about this topic and more at the
upcoming R/Finance 2011 held in Chicago on April 29 and 30th!

It is an awesome opportunity to meet, network, and discuss the state
of R in finance.  If you haven't been, you're are missing out on some
great "off-list" discussions.

http://www.RinFinance.com
http://www.RinFinance.com/agenda
http://www.RinFinance.com/register

</end of Dirk's plug>

;-)

Jeff



On Tue, Apr 12, 2011 at 2:48 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 12 April 2011 at 19:28, Mark Breman wrote:
> | That's what i like so much about following this list: you regularly read
> | about things you never knew existed!
>
> <shameless "ad" for a free product or two>
>
> ?In fact, that's why I wrote CRANberries (which has been at your service
> ?at http://dirk.eddelbuettel.com/cranberries/ for both html or, preferably,
> ?rss aggregation) and why I extended it to tweet via the @CRANberriesFeed
> ?handle.
>
> ?There is so much good change in the R world that you need the help of a
> ?diligent bot to keep up.
>
> </shameless "ad" for a free product or two>
>
> That said, the list is still very good :)
>
> Hope this helps, Dirk
>
> --
> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com

R/Finance 2011 April 29th and 30th in Chicago | www.RinFinance.com


From worik.stanton at gmail.com  Wed Apr 13 01:02:01 2011
From: worik.stanton at gmail.com (Worik)
Date: Wed, 13 Apr 2011 11:02:01 +1200
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <BANLkTi=hHSgU7-ocBU7N0x8h5xaPJHTEgA@mail.gmail.com>
References: <BANLkTin-TnB2gSTossneaMxYN8d0KywWqg@mail.gmail.com>	<BANLkTiniQ8rBPsHSPtm9kZip6iLdqO5Grw@mail.gmail.com>	<BANLkTimj=1XQvdmXSD5i+hkyYwEcYYeieg@mail.gmail.com>	<5C3F9922B1D5FB4886B2D2045AB952F3057A338563@IPEXMAIL.corp.dom>	<BANLkTikf-kdTkrHcU=rF+pkLNicCvrdDUA@mail.gmail.com>	<5C3F9922B1D5FB4886B2D2045AB952F3057A3385C8@IPEXMAIL.corp.dom>
	<BANLkTi=hHSgU7-ocBU7N0x8h5xaPJHTEgA@mail.gmail.com>
Message-ID: <4DA4D9E9.80908@gmail.com>

On 13/04/11 07:40, Mark Leeds wrote:
> Hi Horace: I'm actually not looking for anything. Someone sent in a question
> asking for a way
> of simulating a stock price series in a realistic way. So, some people said
> take a stock series
> and bootstrap it. My suggestion was totally different but depending on the
> goal in mind,
> could possibly be realistic enough ? I don't have any more details but
> that's why I sent it.
This is all very good, thanks people.

The bootstrapping idea I should have thought of.   Intriguing idea.

The Brownian motion code is better than the code I had - I have not 
looked closely at the differences yet, but it gave me what I need.

The Jump Diffusion process I'll leave for another day.  I did not need 
data too realistic.

cheers
Worik

>
>
> On Tue, Apr 12, 2011 at 3:32 PM, Horace Tso<Horace.Tso at pgn.com>  wrote:
>
>>   Mark, not sure what you're looking for. Simulating a compound Poisson or
>> a Cauchy process is not hard. I'm aware of EMJumpDiffusion to fit and
>> simulate these sort of things. I'm sure other R packages could do similar
>> simulation, too.
>>
>> H
>>
>>   ------------------------------
>> *From:* Mark Leeds [mailto:markleeds2 at gmail.com]
>> *Sent:* Tuesday, April 12, 2011 12:09 PM
>> *To:* Horace Tso
>> *Cc:* Mark Breman; r-sig-finance at stat.math.ethz.ch; David St John
>>
>> *Subject:* Re: [R-SIG-Finance] Artificial price series
>>
>> Thanks Horace. That type of thing might be in the book too ? I don't know.
>> I just glanced and saw that one method. but your'e right. and , if anyone
>> knew exactly, they probably wouldn't say anyway !!!!!!
>>
>>
>> Mark
>>
>>
>> On Tue, Apr 12, 2011 at 3:02 PM, Horace Tso<Horace.Tso at pgn.com>  wrote:
>>
>>> Mark, except in some rare instances, evidence is clear that financial
>>> prices are anything but brownian motion. And i think that's the reason Worik
>>> notices in some qualitative way random walk simulation appears unreal. One
>>> of the key differences is real price series have jumps. All these recent
>>> papers by Ait-Sahalia (2010, 2009, 2008, 2004) and others have shown one is
>>> better off with a semimartingale model with some compound Poisson process.
>>>
>>> In fact, the guy is arguing whether brownian motion is even necessary to
>>> model high frequency data (Annals of Statistics 2010, Vol. 38, No. 5,
>>> 3093-3128).
>>>
>>> H
>>>
>>>
>>> -----Original Message-----
>>> From: r-sig-finance-bounces at r-project.org [mailto:
>>> r-sig-finance-bounces at r-project.org] On Behalf Of Mark Leeds
>>> Sent: Tuesday, April 12, 2011 11:05 AM
>>> To: Mark Breman
>>> Cc: r-sig-finance at stat.math.ethz.ch; David St John
>>> Subject: Re: [R-SIG-Finance] Artificial price series
>>>
>>> Hi: if you can assume that returns follow brownian motion, then, in his
>>> book
>>> Simulation and Infernce for Stochastic Differential equations  on pg 26,
>>> Stefano Iacus shows how to generate the  trajectory of the stock price of
>>> S_N starting at S_0 and using increments of deltaT.  The code below is
>>> from
>>> the book directory of his sde package and is labelled ex1.10.R. If you
>>> don't
>>> have his book, the explanation for below is also in Hull and any other
>>> decent derivatives text.
>>>
>>>
>>> #==============================================================================
>>>
>>> set.seed(123)
>>> r<- 1
>>> sigma<- 0.5
>>> x<- 10
>>> N<- 100   # number of end points of the grid including T
>>> T<- 1 # length of the interval [0,T] in time units
>>> Delta<- T/N # time increment
>>> W<- numeric(N+1) # initialization of the vector W
>>> t<- seq(0,T, length=N+1)
>>> for(i in 2:(N+1))
>>>         W[i]<- W[i-1] + rnorm(1) * sqrt(Delta)
>>> S<- x * exp((r-sigma^2/2)*t + sigma*W)
>>> plot(t,S,type="l",main="geometric Brownian motion")
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> On Tue, Apr 12, 2011 at 1:28 PM, Mark Breman<breman.mark at gmail.com>
>>> wrote:
>>>
>>>> Hi David,
>>>>
>>>> That's what i like so much about following this list: you regularly read
>>>> about things you never knew existed!
>>>> This package looks great David.
>>>>
>>>> -Mark-
>>>>
>>>> 2011/4/12 David St John<dstjohn at math.uic.edu>
>>>>
>>>>> Make sure to use bootstrap() for returns data and generateSample() for
>>>>> price
>>>>> data.  bootstrap() only makes sense for a stationary series.  The
>>>>> stationarity assumptions make it desirable to sample from the returns.
>>>>> generateSample() creates returns from prices, bootstraps them, then
>>>>> calculates the random prices from the bootstrapped returns.
>>>>> -David
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-SIG-Finance at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>> -- Also note that this is not the r-help list where general R
>>> questions
>>>>> should go.
>>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions
>>>> should go.
>>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>>
>>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


-- 
If we amplify everything, we hear nothing.
--


From stefano.iacus at unimi.it  Wed Apr 13 12:06:43 2011
From: stefano.iacus at unimi.it (stefano iacus)
Date: Wed, 13 Apr 2011 12:06:43 +0200
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <BANLkTi=QBe8_=FCbreq7KQ-a-SE+1S5TuA@mail.gmail.com>
References: <BANLkTin-TnB2gSTossneaMxYN8d0KywWqg@mail.gmail.com>
	<BANLkTiniQ8rBPsHSPtm9kZip6iLdqO5Grw@mail.gmail.com>
	<19876.44146.717502.351769@max.nulle.part>
	<BANLkTi=QBe8_=FCbreq7KQ-a-SE+1S5TuA@mail.gmail.com>
Message-ID: <46E8D4E4-029C-470C-92AC-2C3CFBBD1674@unimi.it>

"shamelessly" speaking, you can also have a look at the Yuima package (on R-forge). It can help you with the simulation of jump and/or fractional processes as well... and it is "book"-free :-) (compared with sde)

stefano




On 12 Apr 2011, at 22:02, Jeffrey Ryan wrote:

> Dirk forgot to add in his shameless plug:
> 
> 
> 
> You can even talk *in person* with Stefano, David, Dirk, myself, Josh,
> Mark Leeds, and many, many others about this topic and more at the
> upcoming R/Finance 2011 held in Chicago on April 29 and 30th!
> 
> It is an awesome opportunity to meet, network, and discuss the state
> of R in finance.  If you haven't been, you're are missing out on some
> great "off-list" discussions.
> 
> http://www.RinFinance.com
> http://www.RinFinance.com/agenda
> http://www.RinFinance.com/register
> 
> </end of Dirk's plug>
> 
> ;-)
> 
> Jeff
> 
> 
> 
> On Tue, Apr 12, 2011 at 2:48 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>> 
>> On 12 April 2011 at 19:28, Mark Breman wrote:
>> | That's what i like so much about following this list: you regularly read
>> | about things you never knew existed!
>> 
>> <shameless "ad" for a free product or two>
>> 
>>  In fact, that's why I wrote CRANberries (which has been at your service
>>  at http://dirk.eddelbuettel.com/cranberries/ for both html or, preferably,
>>  rss aggregation) and why I extended it to tweet via the @CRANberriesFeed
>>  handle.
>> 
>>  There is so much good change in the R world that you need the help of a
>>  diligent bot to keep up.
>> 
>> </shameless "ad" for a free product or two>
>> 
>> That said, the list is still very good :)
>> 
>> Hope this helps, Dirk
>> 
>> --
>> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>> 
> 
> 
> 
> -- 
> Jeffrey Ryan
> jeffrey.ryan at lemnica.com
> 
> www.lemnica.com
> 
> R/Finance 2011 April 29th and 30th in Chicago | www.RinFinance.com
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


-----------------------------------
Stefano M. Iacus
Department of Economics,
Business and Statistics
University of Milan
Via Conservatorio, 7
I-20123 Milan - Italy
Ph.: +39 02 50321 461
Fax: +39 02 50321 505
http://www.economia.unimi.it/iacus
------------------------------------------------------------------------------------
Please don't send me Word or PowerPoint attachments if not 
absolutely necessary. See:
http://www.gnu.org/philosophy/no-word-attachments.html


From abechan_99 at yahoo.com  Thu Apr 14 07:07:48 2011
From: abechan_99 at yahoo.com (abe chan)
Date: Wed, 13 Apr 2011 22:07:48 -0700 (PDT)
Subject: [R-SIG-Finance] curve fitting using lm with constraints
Message-ID: <969559.67327.qm@web57602.mail.re1.yahoo.com>

Hi Everyone,

I am using "lm" to fit a curve with the form y=ax^2 + bx +c

out = lm(y~x+I(x^2)

My question is..if I have 2 set of equations that need to be satisfied at the 
same time..
for example, the coefficients of a and b of the above regression need to 
satisfy:
          a+b=5 
 and    a-b=2

How should I tackle this type of problem? I really appreciate if someone can 
shed some light.
Thanks.
Imagineer.


From hans.radtke at gutmark.net  Thu Apr 14 12:19:42 2011
From: hans.radtke at gutmark.net (Hans Radtke)
Date: Thu, 14 Apr 2011 12:19:42 +0200
Subject: [R-SIG-Finance] curve fitting using lm with constraints
References: <mailman.3.1302775201.10653.r-sig-finance@r-project.org>
Message-ID: <6BC17AB6B99BC441ABC83269178375A33BAAE9@grcserver.gutmark.de>

Abe,

You should probably look at the systemfit package for this, which can be used to estimate systems of simultaneous equations.

http://cran.r-project.org/web/packages/systemfit/vignettes/systemfit.pdf

Mit besten Gr??en / With kind regards
Hans Radtke


From samo.pahor at gmail.com  Thu Apr 14 23:02:28 2011
From: samo.pahor at gmail.com (Samo Pahor)
Date: Thu, 14 Apr 2011 23:02:28 +0200
Subject: [R-SIG-Finance] Finding all the tickers for common stock from Yahoo
	or Interactive Brokers
Message-ID: <BANLkTinK8wfUGKS5EO5T9SUANKRG8Hrxrg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110414/fd033a29/attachment.pl>

From J_Cuisinier at hotmail.com  Fri Apr 15 08:55:02 2011
From: J_Cuisinier at hotmail.com (julien cuisinier)
Date: Fri, 15 Apr 2011 07:55:02 +0100
Subject: [R-SIG-Finance] Finding all the tickers for common stock from
	Yahoo or Interactive Brokers
In-Reply-To: <BANLkTinK8wfUGKS5EO5T9SUANKRG8Hrxrg@mail.gmail.com>
References: <BANLkTinK8wfUGKS5EO5T9SUANKRG8Hrxrg@mail.gmail.com>
Message-ID: <BLU0-SMTP1950C8D8AE8532D8D0A82C38FAC0@phx.gbl>

Hi Samo,



Personally I would keep it simple & start by downloading an index  
components (e.g. S&P500, available through quantmod from Yahoo I  
believe - sure Jeffrey will contradict me if I am wrong).

Bear in mind that downloading "all" the stocks available for trading  
from Yahoo finance you will probably quickly run into time out issues  
from the website itself. I do not now the IB package.

  & I am not sure you will need to bother yourself to download all  
that stocks' info to get a sensible signal + building a breath  
indicator mixing small cap & large cap (e.g. if you can find the  
S&P1500 components on Yahoo) might not be what you want - hence  
focusing on "smaller" subset of the market might be more relevant.

I am interested by this topic, let us know how you get along...



Rgds,
Julien





On Apr 14, 2011, at 10:02 PM, Samo Pahor wrote:

> Hello R Finance experts!
>
> I would like to calculate market breadth indicators using data from  
> Yahoo (I
> would use quantmod) or Interactive Brokers (using another great  
> package
> IBrokers). I would like to create something simmilar as Stockbee  
> Market
> Monitor
> http://stockbee.blogspot.com/2010/08/understanding-market-monitor-part1.html
> using
> data from Yahoo or IB using R.
>
> First I need all the symbols/tickers of common stocks available for  
> trading
> from either Yahoo or IB on a particular day. How can I get the list  
> of all
> common stocks traded from this two sources?
>
> Are there any market breadth indicators R code available in existing
> packages? Is there any article/blog post showing how to approach data
> collection from Yahoo or IB in order to calculate market breadth  
> indicators?
>
> Best regards,
> Samo.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R  
> questions should go.
>


From minkymorgan at gmail.com  Fri Apr 15 12:21:58 2011
From: minkymorgan at gmail.com (andrew morgan)
Date: Fri, 15 Apr 2011 11:21:58 +0100
Subject: [R-SIG-Finance] Finding all the tickers for common stock from
 Yahoo or Interactive Brokers
Message-ID: <BANLkTi=fLnbaQc+u1S=-5ecmgQLsnEJ8=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110415/497a4be3/attachment.pl>

From zach.mayer at gmail.com  Fri Apr 15 14:44:13 2011
From: zach.mayer at gmail.com (Zachary Mayer)
Date: Fri, 15 Apr 2011 08:44:13 -0400
Subject: [R-SIG-Finance] Finding all the tickers for common stock from
 Yahoo or Interactive Brokers
In-Reply-To: <mailman.1.1302861601.24531.r-sig-finance@r-project.org>
References: <mailman.1.1302861601.24531.r-sig-finance@r-project.org>
Message-ID: <-5783474438883413230@unknownmsgid>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110415/c09e52aa/attachment.pl>

From elliot.bernstein at fdopartners.com  Fri Apr 15 16:19:09 2011
From: elliot.bernstein at fdopartners.com (Elliot Joel Bernstein)
Date: Fri, 15 Apr 2011 10:19:09 -0400
Subject: [R-SIG-Finance] R Memory Usage
In-Reply-To: <BANLkTi=+U=PSos6GDi7CUk0UJ3EXQ7tb0A@mail.gmail.com>
References: <BANLkTimDoH+uRs09WpzOad8R7Qwh+xzF-Q@mail.gmail.com>
	<BANLkTi=+U=PSos6GDi7CUk0UJ3EXQ7tb0A@mail.gmail.com>
Message-ID: <20110415141909.GA18463@cake.fdo.local>

Jeff -

Thanks for your feedback. I was attempting to use data frame, and that -- specifically the use of the 'merge' function -- seemed to be the root of the problem. I read the xts vignette, and it looks interesting, but it's not clear how I should use it for my data. The example in the vignette (using 'sample_matrix') seems to have several variables ('Open', 'Close', etc.) measured over time for a single stock. How would you handle multiple variables measured on multiple stocks over time? Ideally I think I would like to have multiple matrices contained in the xts object, one for each variable, with rows indexing time and columns indexing stocks (or a 3-D array, with the third dimension indexing the variable).

Thanks.

- Elliot

On Sun, Apr 10, 2011 at 02:14:42PM -0500, Jeffrey Ryan wrote:
> Elliot,
> 
> One of the advantages to posting to the finance list is that those of
> us who work around large data in finance can comment on tools that you
> use as well.
> 
> One thing you didn't mention specifically was which packages you are
> using and maybe examples of specific code you are calling.
> 
> Within financial time-series, one of the most optimized tools is xts -
> precisely for the reason of memory management and optimizations for
> large data.  Using something ad-hoc, for example strings and
> data.frames - would cause tremendous issues.
> 
> Another issue would be whether or not you need the full data resident
> in memory at all times.  R's rds format, or a database, or use of
> out-of-core objects such as with mmap or indexing - can greatly
> improve things.
> 
> If you are able to come to the R/Finance conference in Chicago on the
> 29th and 30th of this month, you'll have a chance to talk to some of
> those 'in the trenches' with respect to using R on big data.  And as
> you point our (as well as Brian) - 800x3000 isn't very large, so your
> case isn't unique.
> 
> Would be great to see you later this month in Chicago!  www.RinFinance.com
> 
> Best,
> Jeff
> 
> 
> 
> On Sun, Apr 10, 2011 at 10:49 AM, Elliot Joel Bernstein
> <elliot.bernstein at fdopartners.com> wrote:
> > This is not specifically a finance question, but I'm working with financial
> > data (daily stock returns), and I suspect many people using R for financial
> > analysis face similar issues. The basic problem I'm having is that with a
> > moderately large data set (800 stocks x 11 years), performing a few
> > operations such as data transformations, fitting regressions, etc., results
> > in R using an enormous amount of memory -- sometimes upwards of 5GB -- even
> > after using gc() to try and free some memory up. I've read several posts to
> > various R mailing lists over the years indicating that R does not release
> > memory back to the system on certain OSs (64 bit Linux in my case), so I
> > understand that this is "normal" behavior for R. How do people typically
> > work around this to do exploratory analysis on large data sets without
> > having to constantly restart R to free up memory?
> >
> > Thanks.
> >
> > - Elliot Joel Bernstein
> >
> > ? ? ? ?[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions should go.
> >
> 
> 
> 
> -- 
> Jeffrey Ryan
> jeffrey.ryan at lemnica.com
> 
> www.lemnica.com
> 
> R/Finance 2011 April 29th and 30th in Chicago | www.RinFinance.com

-- 
Elliot Joel Bernstein, Ph.D. | Research Associate | FDO Partners, LLC
134 Mount Auburn Street | Cambridge, MA | 02138
Phone: (617) 503-4619 | Email: elliot.bernstein at fdopartners.com


From brian at braverock.com  Fri Apr 15 16:36:54 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 15 Apr 2011 09:36:54 -0500
Subject: [R-SIG-Finance] R Memory Usage
In-Reply-To: <20110415141909.GA18463@cake.fdo.local>
References: <BANLkTimDoH+uRs09WpzOad8R7Qwh+xzF-Q@mail.gmail.com>	<BANLkTi=+U=PSos6GDi7CUk0UJ3EXQ7tb0A@mail.gmail.com>
	<20110415141909.GA18463@cake.fdo.local>
Message-ID: <4DA85806.3050700@braverock.com>

Since we seem to be top-posting for this thread, I'll continue (ick).

Typically, we store daily, minute, or tick data as xts objects, one per 
instrument.  Much as you would get from getSymbols in quantmod, for 
comparison.  (we've written getSymbols methods that are in the 
FinancialInstrument package that are more amenable to disk-based 
persistent storage of tick data).

When necessary, we subset, align, and cbind this data into combined xts 
objects to get multi-column xts objects.  About the only thing it is 
convenient to do with a data.frame that is inconvenient in xts is data 
which contains mixed numeric and text data.  I typically still use xts 
for these if they will be large objects, but you then have to be aware 
that (like with a matrix) all your numeric data will be stored as 
character data, and you'll need to use as.numeric.  If you only have 
numeric data, this proviso does not apply.  You'll find that merge, 
cbind, and rbind on xts are massively more efficient than the data.frame 
equivalents.

With your example of 800 stocks, I would likely store each stock as a 
separate xts object, and subset and bind as necessary for your analysis. 
  Perhaps in an environment, to keep from cluttering the .GlobalEnv, and 
make it easier to save/load all your data at once.

We avoid data.frame for any object that doesn't absolutely require the 
mixed types and factor support of data.frame.  It's too inefficient in 
memory and speed for truly large data.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


On 04/15/2011 09:19 AM, Elliot Joel Bernstein wrote:
> Jeff -
>
> Thanks for your feedback. I was attempting to use data frame, and that -- specifically the use of the 'merge' function -- seemed to be the root of the problem. I read the xts vignette, and it looks interesting, but it's not clear how I should use it for my data. The example in the vignette (using 'sample_matrix') seems to have several variables ('Open', 'Close', etc.) measured over time for a single stock. How would you handle multiple variables measured on multiple stocks over time? Ideally I think I would like to have multiple matrices contained in the xts object, one for each variable, with rows indexing time and columns indexing stocks (or a 3-D array, with the third dimension indexing the variable).
>
> Thanks.
>
> - Elliot
>
> On Sun, Apr 10, 2011 at 02:14:42PM -0500, Jeffrey Ryan wrote:
>> Elliot,
>>
>> One of the advantages to posting to the finance list is that those of
>> us who work around large data in finance can comment on tools that you
>> use as well.
>>
>> One thing you didn't mention specifically was which packages you are
>> using and maybe examples of specific code you are calling.
>>
>> Within financial time-series, one of the most optimized tools is xts -
>> precisely for the reason of memory management and optimizations for
>> large data.  Using something ad-hoc, for example strings and
>> data.frames - would cause tremendous issues.
>>
>> Another issue would be whether or not you need the full data resident
>> in memory at all times.  R's rds format, or a database, or use of
>> out-of-core objects such as with mmap or indexing - can greatly
>> improve things.
>>
>> If you are able to come to the R/Finance conference in Chicago on the
>> 29th and 30th of this month, you'll have a chance to talk to some of
>> those 'in the trenches' with respect to using R on big data.  And as
>> you point our (as well as Brian) - 800x3000 isn't very large, so your
>> case isn't unique.
>>
>> Would be great to see you later this month in Chicago!  www.RinFinance.com
>>
>> Best,
>> Jeff
>>
>>
>>
>> On Sun, Apr 10, 2011 at 10:49 AM, Elliot Joel Bernstein
>> <elliot.bernstein at fdopartners.com>  wrote:
>>> This is not specifically a finance question, but I'm working with financial
>>> data (daily stock returns), and I suspect many people using R for financial
>>> analysis face similar issues. The basic problem I'm having is that with a
>>> moderately large data set (800 stocks x 11 years), performing a few
>>> operations such as data transformations, fitting regressions, etc., results
>>> in R using an enormous amount of memory -- sometimes upwards of 5GB -- even
>>> after using gc() to try and free some memory up. I've read several posts to
>>> various R mailing lists over the years indicating that R does not release
>>> memory back to the system on certain OSs (64 bit Linux in my case), so I
>>> understand that this is "normal" behavior for R. How do people typically
>>> work around this to do exploratory analysis on large data sets without
>>> having to constantly restart R to free up memory?
>>>
>>> Thanks.
>>>
>>> - Elliot Joel Bernstein
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions should go.
>>>
>>
>>
>>
>> --
>> Jeffrey Ryan
>> jeffrey.ryan at lemnica.com
>>
>> www.lemnica.com
>>
>> R/Finance 2011 April 29th and 30th in Chicago | www.RinFinance.com
>


From mdowle at mdowle.plus.com  Fri Apr 15 17:24:51 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Fri, 15 Apr 2011 16:24:51 +0100
Subject: [R-SIG-Finance] R Memory Usage
References: <BANLkTimDoH+uRs09WpzOad8R7Qwh+xzF-Q@mail.gmail.com>	<BANLkTi=+U=PSos6GDi7CUk0UJ3EXQ7tb0A@mail.gmail.com><20110415141909.GA18463@cake.fdo.local>
	<4DA85806.3050700@braverock.com>
Message-ID: <io9o09$4it$1@dough.gmane.org>

Another option is data.table :
http://datatable.r-forge.r-project.org/

"Brian G. Peterson" <brian at braverock.com> wrote in message 
news:4DA85806.3050700 at braverock.com...
> Since we seem to be top-posting for this thread, I'll continue (ick).
>
> Typically, we store daily, minute, or tick data as xts objects, one per 
> instrument.  Much as you would get from getSymbols in quantmod, for 
> comparison.  (we've written getSymbols methods that are in the 
> FinancialInstrument package that are more amenable to disk-based 
> persistent storage of tick data).
>
> When necessary, we subset, align, and cbind this data into combined xts 
> objects to get multi-column xts objects.  About the only thing it is 
> convenient to do with a data.frame that is inconvenient in xts is data 
> which contains mixed numeric and text data.  I typically still use xts for 
> these if they will be large objects, but you then have to be aware that 
> (like with a matrix) all your numeric data will be stored as character 
> data, and you'll need to use as.numeric.  If you only have numeric data, 
> this proviso does not apply.  You'll find that merge, cbind, and rbind on 
> xts are massively more efficient than the data.frame equivalents.
>
> With your example of 800 stocks, I would likely store each stock as a 
> separate xts object, and subset and bind as necessary for your analysis. 
> Perhaps in an environment, to keep from cluttering the .GlobalEnv, and 
> make it easier to save/load all your data at once.
>
> We avoid data.frame for any object that doesn't absolutely require the 
> mixed types and factor support of data.frame.  It's too inefficient in 
> memory and speed for truly large data.
>
> Regards,
>
>   - Brian
>
> -- 
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
>
> On 04/15/2011 09:19 AM, Elliot Joel Bernstein wrote:
>> Jeff -
>>
>> Thanks for your feedback. I was attempting to use data frame, and that --  
>> specifically the use of the 'merge' function -- seemed to be the root of 
>> the problem. I read the xts vignette, and it looks interesting, but it's 
>> not clear how I should use it for my data. The example in the vignette 
>> (using 'sample_matrix') seems to have several variables ('Open', 'Close', 
>> etc.) measured over time for a single stock. How would you handle 
>> multiple variables measured on multiple stocks over time? Ideally I think 
>> I would like to have multiple matrices contained in the xts object, one 
>> for each variable, with rows indexing time and columns indexing stocks 
>> (or a 3-D array, with the third dimension indexing the variable).
>>
>> Thanks.
>>
>> - Elliot
>>
>> On Sun, Apr 10, 2011 at 02:14:42PM -0500, Jeffrey Ryan wrote:
>>> Elliot,
>>>
>>> One of the advantages to posting to the finance list is that those of
>>> us who work around large data in finance can comment on tools that you
>>> use as well.
>>>
>>> One thing you didn't mention specifically was which packages you are
>>> using and maybe examples of specific code you are calling.
>>>
>>> Within financial time-series, one of the most optimized tools is xts -
>>> precisely for the reason of memory management and optimizations for
>>> large data.  Using something ad-hoc, for example strings and
>>> data.frames - would cause tremendous issues.
>>>
>>> Another issue would be whether or not you need the full data resident
>>> in memory at all times.  R's rds format, or a database, or use of
>>> out-of-core objects such as with mmap or indexing - can greatly
>>> improve things.
>>>
>>> If you are able to come to the R/Finance conference in Chicago on the
>>> 29th and 30th of this month, you'll have a chance to talk to some of
>>> those 'in the trenches' with respect to using R on big data.  And as
>>> you point our (as well as Brian) - 800x3000 isn't very large, so your
>>> case isn't unique.
>>>
>>> Would be great to see you later this month in Chicago! 
>>> www.RinFinance.com
>>>
>>> Best,
>>> Jeff
>>>
>>>
>>>
>>> On Sun, Apr 10, 2011 at 10:49 AM, Elliot Joel Bernstein
>>> <elliot.bernstein at fdopartners.com>  wrote:
>>>> This is not specifically a finance question, but I'm working with 
>>>> financial
>>>> data (daily stock returns), and I suspect many people using R for 
>>>> financial
>>>> analysis face similar issues. The basic problem I'm having is that with 
>>>> a
>>>> moderately large data set (800 stocks x 11 years), performing a few
>>>> operations such as data transformations, fitting regressions, etc., 
>>>> results
>>>> in R using an enormous amount of memory -- sometimes upwards of 5GB --  
>>>> even
>>>> after using gc() to try and free some memory up. I've read several 
>>>> posts to
>>>> various R mailing lists over the years indicating that R does not 
>>>> release
>>>> memory back to the system on certain OSs (64 bit Linux in my case), so 
>>>> I
>>>> understand that this is "normal" behavior for R. How do people 
>>>> typically
>>>> work around this to do exploratory analysis on large data sets without
>>>> having to constantly restart R to free up memory?
>>>>
>>>> Thanks.
>>>>
>>>> - Elliot Joel Bernstein
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions 
>>>> should go.
>>>>
>>>
>>>
>>>
>>> --
>>> Jeffrey Ryan
>>> jeffrey.ryan at lemnica.com
>>>
>>> www.lemnica.com
>>>
>>> R/Finance 2011 April 29th and 30th in Chicago | www.RinFinance.com
>>
>


From josh.m.ulrich at gmail.com  Fri Apr 15 18:08:55 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 15 Apr 2011 11:08:55 -0500
Subject: [R-SIG-Finance] Finding all the tickers for common stock from
 Yahoo or Interactive Brokers
In-Reply-To: <BANLkTinK8wfUGKS5EO5T9SUANKRG8Hrxrg@mail.gmail.com>
References: <BANLkTinK8wfUGKS5EO5T9SUANKRG8Hrxrg@mail.gmail.com>
Message-ID: <BANLkTik5OgQa3S8Auw3UyxvW2rmR4+=ZtQ@mail.gmail.com>

On Thu, Apr 14, 2011 at 4:02 PM, Samo Pahor <samo.pahor at gmail.com> wrote:
> Hello R Finance experts!
>
> I would like to calculate market breadth indicators using data from Yahoo (I
> would use quantmod) or Interactive Brokers (using another great package
> IBrokers). I would like to create something simmilar as Stockbee Market
> Monitor
> http://stockbee.blogspot.com/2010/08/understanding-market-monitor-part1.html
> using
> data from Yahoo or IB using R.
>
> First I need all the symbols/tickers of common stocks available for trading
> from either Yahoo or IB on a particular day. How can I get the list of all
> common stocks traded from this two sources?
>
I don't know of a way to get all common stocks from Yahoo, but the
stockSymbols function in TTR will download AMEX, NYSE, and NASDAQ
instrument symbols from nasdaq.com and tries to adjust the symbols to
make the compatible with Yahoo Finance.

Look at the source code of stockSymbols to see how it adjusts the
ticker symbols.  This Yahoo web page will help you filter out the
common stocks:
http://help.yahoo.com/l/us/yahoo/finance/quotes/quote-02.html

> Are there any market breadth indicators R code available in existing
> packages? Is there any article/blog post showing how to approach data
> collection from Yahoo or IB in order to calculate market breadth indicators?
>
There are a few I've planned to include in TTR.  They're generally
very simple and I don't personally use breadth indicators, so adding
them hasn't been a high priority.

> Best regards,
> Samo.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From noah at smartmediacorp.com  Sat Apr 16 01:32:06 2011
From: noah at smartmediacorp.com (Noah Silverman)
Date: Fri, 15 Apr 2011 16:32:06 -0700
Subject: [R-SIG-Finance] Irregular time series and tick data
Message-ID: <A058AC7D-AAA1-4A8F-A2F0-F0A03A7D7161@smartmediacorp.com>

Hi,

I have some tick data that I want to analyze.

The file given to me has date and time in separate columns.
There may be multiple transactions with the same date and time stamps

I tried using the its package to convert them into a nice time series object, but it complains about multiple items with the same index.

Does anyone have any guidance as to how to best do this in R??

Below are a few lines of the data
  symbol as_of_date as_of_time close_price volume
1  WCH07 2007-01-01   18:32:01      882.50     20
2  WCH07 2007-01-01   18:32:01      882.50      5
3  WCH07 2007-01-01   18:32:06      882.75      2
4  WCH07 2007-01-01   18:32:06      883.00      1
5  WCH07 2007-01-01   18:32:06      883.00      2
6  WCH07 2007-01-01   18:32:07      883.00      1

Thanks!

-N

From jeff.a.ryan at gmail.com  Sat Apr 16 02:36:38 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 15 Apr 2011 19:36:38 -0500
Subject: [R-SIG-Finance] Irregular time series and tick data
In-Reply-To: <A058AC7D-AAA1-4A8F-A2F0-F0A03A7D7161@smartmediacorp.com>
References: <A058AC7D-AAA1-4A8F-A2F0-F0A03A7D7161@smartmediacorp.com>
Message-ID: <C33DCFAB-A756-4294-8861-9BF2C6DA7B8D@gmail.com>

Hi Noah. 

Take a look through the list archives, you'll find this is a very common question. 

My (biased) reply is use xts. Highly optimized for tick data, very fast (mostly C) and widely used/depended upon. 

Aside from that, zoo is stellar - though might be tougher with tick data and will also complain about duplicate times. 

fts and timeSeries are quite good as well, though different (fts is actually a wrapper to a C++ library by the same author). timeSeries is part of rmetrics, and is nice, though not really built for big/high freq data. 

ts, its, irts, are really quite old and exist only for particular legacy reasons best I can tell. 

data.table isn't a time series per se, but is quite a cool replacement for data.frames. 

Check the list (as recently as the last few posts even!), and give them all a test - that's the best part of OSS. 

Jeff

Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com

www.lemnica.com

On Apr 15, 2011, at 6:32 PM, Noah Silverman <noah at smartmediacorp.com> wrote:

> Hi,
> 
> I have some tick data that I want to analyze.
> 
> The file given to me has date and time in separate columns.
> There may be multiple transactions with the same date and time stamps
> 
> I tried using the its package to convert them into a nice time series object, but it complains about multiple items with the same index.
> 
> Does anyone have any guidance as to how to best do this in R??
> 
> Below are a few lines of the data
>  symbol as_of_date as_of_time close_price volume
> 1  WCH07 2007-01-01   18:32:01      882.50     20
> 2  WCH07 2007-01-01   18:32:01      882.50      5
> 3  WCH07 2007-01-01   18:32:06      882.75      2
> 4  WCH07 2007-01-01   18:32:06      883.00      1
> 5  WCH07 2007-01-01   18:32:06      883.00      2
> 6  WCH07 2007-01-01   18:32:07      883.00      1
> 
> Thanks!
> 
> -N
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From noah at smartmediacorp.com  Sat Apr 16 02:49:40 2011
From: noah at smartmediacorp.com (Noah Silverman)
Date: Fri, 15 Apr 2011 17:49:40 -0700
Subject: [R-SIG-Finance] Irregular time series and tick data
In-Reply-To: <C33DCFAB-A756-4294-8861-9BF2C6DA7B8D@gmail.com>
References: <A058AC7D-AAA1-4A8F-A2F0-F0A03A7D7161@smartmediacorp.com>
	<C33DCFAB-A756-4294-8861-9BF2C6DA7B8D@gmail.com>
Message-ID: <A7535870-F5F6-4C2A-9019-258699CE0A98@smartmediacorp.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110415/3083a429/attachment.pl>

From noah at smartmediacorp.com  Sat Apr 16 02:52:14 2011
From: noah at smartmediacorp.com (Noah Silverman)
Date: Fri, 15 Apr 2011 17:52:14 -0700
Subject: [R-SIG-Finance] Irregular time series and tick data
In-Reply-To: <C33DCFAB-A756-4294-8861-9BF2C6DA7B8D@gmail.com>
References: <A058AC7D-AAA1-4A8F-A2F0-F0A03A7D7161@smartmediacorp.com>
	<C33DCFAB-A756-4294-8861-9BF2C6DA7B8D@gmail.com>
Message-ID: <91CCFDD3-A15B-4D6F-8DB8-AFA4E61B0EF0@smartmediacorp.com>

Additionally,

I currently have date and time in two columns.  How would I coerce that into a proper timestamp for xts?

Thanks!!


--
Noah Silverman
Smart Media Corp.
WebClipping.com
Tel: (323) 653-1900 x5207

On Apr 15, 2011, at 5:36 PM, Jeff Ryan wrote:

> Hi Noah. 
> 
> Take a look through the list archives, you'll find this is a very common question. 
> 
> My (biased) reply is use xts. Highly optimized for tick data, very fast (mostly C) and widely used/depended upon. 
> 
> Aside from that, zoo is stellar - though might be tougher with tick data and will also complain about duplicate times. 
> 
> fts and timeSeries are quite good as well, though different (fts is actually a wrapper to a C++ library by the same author). timeSeries is part of rmetrics, and is nice, though not really built for big/high freq data. 
> 
> ts, its, irts, are really quite old and exist only for particular legacy reasons best I can tell. 
> 
> data.table isn't a time series per se, but is quite a cool replacement for data.frames. 
> 
> Check the list (as recently as the last few posts even!), and give them all a test - that's the best part of OSS. 
> 
> Jeff
> 
> Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com
> 
> www.lemnica.com
> 
> On Apr 15, 2011, at 6:32 PM, Noah Silverman <noah at smartmediacorp.com> wrote:
> 
>> Hi,
>> 
>> I have some tick data that I want to analyze.
>> 
>> The file given to me has date and time in separate columns.
>> There may be multiple transactions with the same date and time stamps
>> 
>> I tried using the its package to convert them into a nice time series object, but it complains about multiple items with the same index.
>> 
>> Does anyone have any guidance as to how to best do this in R??
>> 
>> Below are a few lines of the data
>> symbol as_of_date as_of_time close_price volume
>> 1  WCH07 2007-01-01   18:32:01      882.50     20
>> 2  WCH07 2007-01-01   18:32:01      882.50      5
>> 3  WCH07 2007-01-01   18:32:06      882.75      2
>> 4  WCH07 2007-01-01   18:32:06      883.00      1
>> 5  WCH07 2007-01-01   18:32:06      883.00      2
>> 6  WCH07 2007-01-01   18:32:07      883.00      1
>> 
>> Thanks!
>> 
>> -N
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.


From jeff.a.ryan at gmail.com  Sat Apr 16 03:31:12 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 15 Apr 2011 20:31:12 -0500
Subject: [R-SIG-Finance] Irregular time series and tick data
In-Reply-To: <A7535870-F5F6-4C2A-9019-258699CE0A98@smartmediacorp.com>
References: <A058AC7D-AAA1-4A8F-A2F0-F0A03A7D7161@smartmediacorp.com>
	<C33DCFAB-A756-4294-8861-9BF2C6DA7B8D@gmail.com>
	<A7535870-F5F6-4C2A-9019-258699CE0A98@smartmediacorp.com>
Message-ID: <FF98A3D6-EE2A-4A25-90F8-8BAFBB44836B@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110415/397d4514/attachment.pl>

From jeff.a.ryan at gmail.com  Sat Apr 16 03:35:34 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 15 Apr 2011 20:35:34 -0500
Subject: [R-SIG-Finance] Irregular time series and tick data
In-Reply-To: <91CCFDD3-A15B-4D6F-8DB8-AFA4E61B0EF0@smartmediacorp.com>
References: <A058AC7D-AAA1-4A8F-A2F0-F0A03A7D7161@smartmediacorp.com>
	<C33DCFAB-A756-4294-8861-9BF2C6DA7B8D@gmail.com>
	<91CCFDD3-A15B-4D6F-8DB8-AFA4E61B0EF0@smartmediacorp.com>
Message-ID: <EE887EEB-85C4-4EE8-8B17-1F905CFE0B92@gmail.com>

Again, searching the list is the best bet - especially as I am replying via phone at this point and can't provide the full examples I'd like to. 

In general, you need to do something like as.POSIXct(paste(date,time)), which should work for the example data you posted.  That gets you a proper time based object for xts. 

Jeff

Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com

www.lemnica.com

On Apr 15, 2011, at 7:52 PM, Noah Silverman <noah at smartmediacorp.com> wrote:

> Additionally,
> 
> I currently have date and time in two columns.  How would I coerce that into a proper timestamp for xts?
> 
> Thanks!!
> 
> 
> --
> Noah Silverman
> Smart Media Corp.
> WebClipping.com
> Tel: (323) 653-1900 x5207
> 
> On Apr 15, 2011, at 5:36 PM, Jeff Ryan wrote:
> 
>> Hi Noah. 
>> 
>> Take a look through the list archives, you'll find this is a very common question. 
>> 
>> My (biased) reply is use xts. Highly optimized for tick data, very fast (mostly C) and widely used/depended upon. 
>> 
>> Aside from that, zoo is stellar - though might be tougher with tick data and will also complain about duplicate times. 
>> 
>> fts and timeSeries are quite good as well, though different (fts is actually a wrapper to a C++ library by the same author). timeSeries is part of rmetrics, and is nice, though not really built for big/high freq data. 
>> 
>> ts, its, irts, are really quite old and exist only for particular legacy reasons best I can tell. 
>> 
>> data.table isn't a time series per se, but is quite a cool replacement for data.frames. 
>> 
>> Check the list (as recently as the last few posts even!), and give them all a test - that's the best part of OSS. 
>> 
>> Jeff
>> 
>> Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com
>> 
>> www.lemnica.com
>> 
>> On Apr 15, 2011, at 6:32 PM, Noah Silverman <noah at smartmediacorp.com> wrote:
>> 
>>> Hi,
>>> 
>>> I have some tick data that I want to analyze.
>>> 
>>> The file given to me has date and time in separate columns.
>>> There may be multiple transactions with the same date and time stamps
>>> 
>>> I tried using the its package to convert them into a nice time series object, but it complains about multiple items with the same index.
>>> 
>>> Does anyone have any guidance as to how to best do this in R??
>>> 
>>> Below are a few lines of the data
>>> symbol as_of_date as_of_time close_price volume
>>> 1  WCH07 2007-01-01   18:32:01      882.50     20
>>> 2  WCH07 2007-01-01   18:32:01      882.50      5
>>> 3  WCH07 2007-01-01   18:32:06      882.75      2
>>> 4  WCH07 2007-01-01   18:32:06      883.00      1
>>> 5  WCH07 2007-01-01   18:32:06      883.00      2
>>> 6  WCH07 2007-01-01   18:32:07      883.00      1
>>> 
>>> Thanks!
>>> 
>>> -N
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions should go.
> 


From rui.antunes at sgcib.com  Sat Apr 16 12:03:48 2011
From: rui.antunes at sgcib.com (Rui ANTUNES)
Date: Sat, 16 Apr 2011 12:03:48 +0200
Subject: [R-SIG-Finance] ANTUNES, Rui
Message-ID: <OFACB1C87A.A34A645E-ONC1257874.003747E0-C1257874.003747E0@fr.world.socgen>


I will be out of the office starting  15/04/2011 and will not return until
09/05/2011.

I am away at the moment, in case of an urgent request please contact George
Oikonomou.

*************************************************************************
This message and any attachments (the "message") are con...{{dropped:12}}


From sujiangdong at gmail.com  Sat Apr 16 16:47:57 2011
From: sujiangdong at gmail.com (=?UTF-8?B?6IuP5rGf5LicU3UgSmlhbmdkb25n?=)
Date: Sat, 16 Apr 2011 15:47:57 +0100
Subject: [R-SIG-Finance] 600 people's time series
In-Reply-To: <BANLkTimhGSOQ2TYCqGy4ebAdKXgQ035AZA@mail.gmail.com>
References: <BANLkTimhGSOQ2TYCqGy4ebAdKXgQ035AZA@mail.gmail.com>
Message-ID: <BANLkTinAVoH+D0ZvC7gt2oj9QcPEKh4svQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110416/38f43025/attachment.pl>

From noah at smartmediacorp.com  Sat Apr 16 19:01:06 2011
From: noah at smartmediacorp.com (Noah Silverman)
Date: Sat, 16 Apr 2011 10:01:06 -0700
Subject: [R-SIG-Finance] select subset from xts time series object.
Message-ID: <F65601AF-FBA2-4AE2-A0B5-97EB5AF78675@smartmediacorp.com>

Hi,

Thanks to Jeff Ryan's help, I was able to get my data into a nice XTS format.  I then followed his suggestion to use the make.index.unique() function to ensure that each tick had a slightly different time.  Everything looks great!

Now, I want to select subsets of the data for short intervals - perhaps 5 minutes in size.

For example, I want all the entries between:
2010-08-04 11:50:00   and   2010-08-04 11:55:00

I tried:      ticks[' 2010-08-04 11:50:00' :'2010-08-04 11:55:00' , ]    It failed
Then:      ticks[as.POSIXct(' 2010-08-04 11:50:00')  : asPOSIXct('2010-08-04 11:55:00' ), ]  Also fails

Can anyone point me in the right direction?

Thanks!

--
Noah Silverman
Smart Media Corp.
WebClipping.com
Tel: (323) 653-1900 x5207


From jeff.a.ryan at gmail.com  Sat Apr 16 19:11:44 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sat, 16 Apr 2011 12:11:44 -0500
Subject: [R-SIG-Finance] select subset from xts time series object.
In-Reply-To: <F65601AF-FBA2-4AE2-A0B5-97EB5AF78675@smartmediacorp.com>
References: <F65601AF-FBA2-4AE2-A0B5-97EB5AF78675@smartmediacorp.com>
Message-ID: <66912930-4254-4D9C-B89E-EF18403D0741@gmail.com>

Very close. 

Try:
ticks[' 2010-08-04 11:50:00/2010-08-04 11:55:00' , ]

The subsetting works off of one string, your were applying the : operator in R to a character string instead. 

HTH
Jeff

Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com

www.lemnica.com

On Apr 16, 2011, at 12:01 PM, Noah Silverman <noah at smartmediacorp.com> wrote:

> Hi,
> 
> Thanks to Jeff Ryan's help, I was able to get my data into a nice XTS format.  I then followed his suggestion to use the make.index.unique() function to ensure that each tick had a slightly different time.  Everything looks great!
> 
> Now, I want to select subsets of the data for short intervals - perhaps 5 minutes in size.
> 
> For example, I want all the entries between:
> 2010-08-04 11:50:00   and   2010-08-04 11:55:00
> 
> I tried:      ticks[' 2010-08-04 11:50:00' :'2010-08-04 11:55:00' , ]    It failed
> Then:      ticks[as.POSIXct(' 2010-08-04 11:50:00')  : asPOSIXct('2010-08-04 11:55:00' ), ]  Also fails
> 
> Can anyone point me in the right direction?
> 
> Thanks!
> 
> --
> Noah Silverman
> Smart Media Corp.
> WebClipping.com
> Tel: (323) 653-1900 x5207
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From hasan.diwan at gmail.com  Sat Apr 16 19:12:57 2011
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Sat, 16 Apr 2011 10:12:57 -0700
Subject: [R-SIG-Finance] select subset from xts time series object.
In-Reply-To: <F65601AF-FBA2-4AE2-A0B5-97EB5AF78675@smartmediacorp.com>
References: <F65601AF-FBA2-4AE2-A0B5-97EB5AF78675@smartmediacorp.com>
Message-ID: <BANLkTi=reDvmNRN_iu_gyenkaps4GeFR+w@mail.gmail.com>

On 16 April 2011 10:01, Noah Silverman <noah at smartmediacorp.com> wrote:
> Hi,
>
> Thanks to Jeff Ryan's help, I was able to get my data into a nice XTS format. ?I then followed his suggestion to use the make.index.unique() function to ensure that each tick had a slightly different time. ?Everything looks great!
>
> Now, I want to select subsets of the data for short intervals - perhaps 5 minutes in size.
>
> For example, I want all the entries between:
> 2010-08-04 11:50:00 ? and ? 2010-08-04 11:55:00
>
> I tried: ? ? ?ticks[' 2010-08-04 11:50:00' :'2010-08-04 11:55:00' , ] ? ?It failed
> Then: ? ? ?ticks[as.POSIXct(' 2010-08-04 11:50:00') ?: asPOSIXct('2010-08-04 11:55:00' ), ] ?Also fails

ticks['2010-08-04 11:50:00::2011-08-04 11:55:00'] works brilliantly
-- 
Sent from my mobile device
Envoyait de mon telephone mobil


From noah at smartmediacorp.com  Sat Apr 16 19:28:43 2011
From: noah at smartmediacorp.com (Noah Silverman)
Date: Sat, 16 Apr 2011 10:28:43 -0700
Subject: [R-SIG-Finance] select subset from xts time series object.
In-Reply-To: <BANLkTi=reDvmNRN_iu_gyenkaps4GeFR+w@mail.gmail.com>
References: <F65601AF-FBA2-4AE2-A0B5-97EB5AF78675@smartmediacorp.com>
	<BANLkTi=reDvmNRN_iu_gyenkaps4GeFR+w@mail.gmail.com>
Message-ID: <E3E90749-477B-4B96-B47F-7FC7646EA718@smartmediacorp.com>

Perfect!

I never thought about using a double colon.  Works quickly and cleanly.

Now for the harder part.

If I want to define my timestamps as variables first, how I can I subselect:

a <- '2010-08-04 11:50:00'
b <- '2010-08-04 11:55:00'


ticks[a::b, ]   fails

Ideas?

--
Noah Silverman
Smart Media Corp.
WebClipping.com
Tel: (323) 653-1900 x5207



On Apr 16, 2011, at 10:12 AM, Hasan Diwan wrote:

> On 16 April 2011 10:01, Noah Silverman <noah at smartmediacorp.com> wrote:
>> Hi,
>> 
>> Thanks to Jeff Ryan's help, I was able to get my data into a nice XTS format.  I then followed his suggestion to use the make.index.unique() function to ensure that each tick had a slightly different time.  Everything looks great!
>> 
>> Now, I want to select subsets of the data for short intervals - perhaps 5 minutes in size.
>> 
>> For example, I want all the entries between:
>> 2010-08-04 11:50:00   and   2010-08-04 11:55:00
>> 
>> I tried:      ticks[' 2010-08-04 11:50:00' :'2010-08-04 11:55:00' , ]    It failed
>> Then:      ticks[as.POSIXct(' 2010-08-04 11:50:00')  : asPOSIXct('2010-08-04 11:55:00' ), ]  Also fails
> 
> ticks['2010-08-04 11:50:00::2011-08-04 11:55:00'] works brilliantly
> -- 
> Sent from my mobile device
> Envoyait de mon telephone mobil


From josh.m.ulrich at gmail.com  Sat Apr 16 19:38:57 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 16 Apr 2011 12:38:57 -0500
Subject: [R-SIG-Finance] select subset from xts time series object.
In-Reply-To: <E3E90749-477B-4B96-B47F-7FC7646EA718@smartmediacorp.com>
References: <F65601AF-FBA2-4AE2-A0B5-97EB5AF78675@smartmediacorp.com>
	<BANLkTi=reDvmNRN_iu_gyenkaps4GeFR+w@mail.gmail.com>
	<E3E90749-477B-4B96-B47F-7FC7646EA718@smartmediacorp.com>
Message-ID: <BANLkTik3+A7UmCBHPfPALSR5Af2WxykdzQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110416/5d686b88/attachment.pl>

From noah at smartmediacorp.com  Sat Apr 16 19:48:34 2011
From: noah at smartmediacorp.com (Noah Silverman)
Date: Sat, 16 Apr 2011 10:48:34 -0700
Subject: [R-SIG-Finance] select subset from xts time series object.
In-Reply-To: <BANLkTik3+A7UmCBHPfPALSR5Af2WxykdzQ@mail.gmail.com>
References: <F65601AF-FBA2-4AE2-A0B5-97EB5AF78675@smartmediacorp.com>
	<BANLkTi=reDvmNRN_iu_gyenkaps4GeFR+w@mail.gmail.com>
	<E3E90749-477B-4B96-B47F-7FC7646EA718@smartmediacorp.com>
	<BANLkTik3+A7UmCBHPfPALSR5Af2WxykdzQ@mail.gmail.com>
Message-ID: <7C25535E-C916-4C9B-9DB9-95ED0A1A5856@smartmediacorp.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110416/3cff2192/attachment.pl>

From jeff.a.ryan at gmail.com  Sat Apr 16 19:50:11 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sat, 16 Apr 2011 12:50:11 -0500
Subject: [R-SIG-Finance] select subset from xts time series object.
In-Reply-To: <BANLkTik3+A7UmCBHPfPALSR5Af2WxykdzQ@mail.gmail.com>
References: <F65601AF-FBA2-4AE2-A0B5-97EB5AF78675@smartmediacorp.com>
	<BANLkTi=reDvmNRN_iu_gyenkaps4GeFR+w@mail.gmail.com>
	<E3E90749-477B-4B96-B47F-7FC7646EA718@smartmediacorp.com>
	<BANLkTik3+A7UmCBHPfPALSR5Af2WxykdzQ@mail.gmail.com>
Message-ID: <8605122E-471E-46CE-A21B-E8E1CFB763FC@gmail.com>

paste(a,b,sep="/")

The "::" works as well, but / is more proper since it is in the ISO 8601 standard. 

Best,
Jeff

Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com

www.lemnica.com

On Apr 16, 2011, at 12:38 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:

> On Apr 16, 2011 12:29 PM, "Noah Silverman" <noah at smartmediacorp.com> wrote:
>> 
>> Perfect!
>> 
>> I never thought about using a double colon.  Works quickly and cleanly.
>> 
>> Now for the harder part.
>> 
>> If I want to define my timestamps as variables first, how I can I
> subselect:
>> 
>> a <- '2010-08-04 11:50:00'
>> b <- '2010-08-04 11:55:00'
>> 
>> 
>> ticks[a::b, ]   fails
>> 
> Take a careful look ay what others have already suggested and what you're
> trying.  You're trying to apply a :: operator to two character vectors.
> 
> xts subsetting requires a single string, which you can create via paste(a,
> b, sep="::").
> 
>> Ideas?
>> 
>> --
>> Noah Silverman
>> Smart Media Corp.
>> WebClipping.com
>> Tel: (323) 653-1900 x5207
>> 
>> 
>> 
>> On Apr 16, 2011, at 10:12 AM, Hasan Diwan wrote:
>> 
>>> On 16 April 2011 10:01, Noah Silverman <noah at smartmediacorp.com> wrote:
>>>> Hi,
>>>> 
>>>> Thanks to Jeff Ryan's help, I was able to get my data into a nice XTS
> format.  I then followed his suggestion to use the make.index.unique()
> function to ensure that each tick had a slightly different time.  Everything
> looks great!
>>>> 
>>>> Now, I want to select subsets of the data for short intervals - perhaps
> 5 minutes in size.
>>>> 
>>>> For example, I want all the entries between:
>>>> 2010-08-04 11:50:00   and   2010-08-04 11:55:00
>>>> 
>>>> I tried:      ticks[' 2010-08-04 11:50:00' :'2010-08-04 11:55:00' , ]
> It failed
>>>> Then:      ticks[as.POSIXct(' 2010-08-04 11:50:00')  :
> asPOSIXct('2010-08-04 11:55:00' ), ]  Also fails
>>> 
>>> ticks['2010-08-04 11:50:00::2011-08-04 11:55:00'] works brilliantly
>>> --
>>> Sent from my mobile device
>>> Envoyait de mon telephone mobil
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
> should go.
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From jeff.a.ryan at gmail.com  Sat Apr 16 20:33:46 2011
From: jeff.a.ryan at gmail.com (jeff.a.ryan at gmail.com)
Date: Sat, 16 Apr 2011 18:33:46 +0000
Subject: [R-SIG-Finance] select subset from xts time series object.
In-Reply-To: <7C25535E-C916-4C9B-9DB9-95ED0A1A5856@smartmediacorp.com>
References: <F65601AF-FBA2-4AE2-A0B5-97EB5AF78675@smartmediacorp.com><BANLkTi=reDvmNRN_iu_gyenkaps4GeFR+w@mail.gmail.com><E3E90749-477B-4B96-B47F-7FC7646EA718@smartmediacorp.com><BANLkTik3+A7UmCBHPfPALSR5Af2WxykdzQ@mail.gmail.com><7C25535E-C916-4C9B-9DB9-95ED0A1A5856@smartmediacorp.com>
Message-ID: <119460941-1302978824-cardhu_decombobulator_blackberry.rim.net-367984845-@bda307.bisx.prod.on.blackberry>

xts on R-forge has something like this in adj.time, syntax is something like

adj.time(Sys.Date(), hour+2)

Still in progress. 

Hadley et al has a (silly name) package called lubridate (I personally can't say it without smirking). That will likely do what you want as well. Though syntax is peculiar IMO. 

Check the most recent JSS on that. 

Jeff
Jeffrey A. Ryan
jeff.a.ryan at gmail.com

-----Original Message-----
From: Noah Silverman <noah at smartmediacorp.com>
Sender: r-sig-finance-bounces at r-project.orgDate: Sat, 16 Apr 2011 10:48:34 
To: Joshua Ulrich<josh.m.ulrich at gmail.com>
Cc: R-SIG-Finance<r-sig-finance at stat.math.ethz.ch>
Subject: Re: [R-SIG-Finance] select subset from xts time series object.

Nice,

Thanks!

Next challenge:  Is there a package in R to do "date math".  (There is great stuff in other languages, so must be in R)

If I have a timetamp, It would be great to just "add 1 hour" or "add 7 minutes" and get back the proper date-time for it.

I'm looking at a lot of timeseries data this weekend and need to learn how to do some of this simple stuff in R to play with some ideas.

Thanks!

--
Noah Silverman
Smart Media Corp.
WebClipping.com
Tel: (323) 653-1900 x5207



On Apr 16, 2011, at 10:38 AM, Joshua Ulrich wrote:

> 
> On Apr 16, 2011 12:29 PM, "Noah Silverman" <noah at smartmediacorp.com> wrote:
> >
> > Perfect!
> >
> > I never thought about using a double colon.  Works quickly and cleanly.
> >
> > Now for the harder part.
> >
> > If I want to define my timestamps as variables first, how I can I subselect:
> >
> > a <- '2010-08-04 11:50:00'
> > b <- '2010-08-04 11:55:00'
> >
> >
> > ticks[a::b, ]   fails
> >
> Take a careful look ay what others have already suggested and what you're trying.  You're trying to apply a :: operator to two character vectors.
> 
> xts subsetting requires a single string, which you can create via paste(a, b, sep="::").
> 
> > Ideas?
> >
> > --
> > Noah Silverman
> > Smart Media Corp.
> > WebClipping.com
> > Tel: (323) 653-1900 x5207
> >
> >
> >
> > On Apr 16, 2011, at 10:12 AM, Hasan Diwan wrote:
> >
> > > On 16 April 2011 10:01, Noah Silverman <noah at smartmediacorp.com> wrote:
> > >> Hi,
> > >>
> > >> Thanks to Jeff Ryan's help, I was able to get my data into a nice XTS format.  I then followed his suggestion to use the make.index.unique() function to ensure that each tick had a slightly different time.  Everything looks great!
> > >>
> > >> Now, I want to select subsets of the data for short intervals - perhaps 5 minutes in size.
> > >>
> > >> For example, I want all the entries between:
> > >> 2010-08-04 11:50:00   and   2010-08-04 11:55:00
> > >>
> > >> I tried:      ticks[' 2010-08-04 11:50:00' :'2010-08-04 11:55:00' , ]    It failed
> > >> Then:      ticks[as.POSIXct(' 2010-08-04 11:50:00')  : asPOSIXct('2010-08-04 11:55:00' ), ]  Also fails
> > >
> > > ticks['2010-08-04 11:50:00::2011-08-04 11:55:00'] works brilliantly
> > > --
> > > Sent from my mobile device
> > > Envoyait de mon telephone mobil
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions should go.


	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.

From jeffrey.ryan at lemnica.com  Sat Apr 16 21:26:41 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Sat, 16 Apr 2011 14:26:41 -0500
Subject: [R-SIG-Finance] select subset from xts time series object.
In-Reply-To: <7C25535E-C916-4C9B-9DB9-95ED0A1A5856@smartmediacorp.com>
References: <F65601AF-FBA2-4AE2-A0B5-97EB5AF78675@smartmediacorp.com>
	<BANLkTi=reDvmNRN_iu_gyenkaps4GeFR+w@mail.gmail.com>
	<E3E90749-477B-4B96-B47F-7FC7646EA718@smartmediacorp.com>
	<BANLkTik3+A7UmCBHPfPALSR5Af2WxykdzQ@mail.gmail.com>
	<7C25535E-C916-4C9B-9DB9-95ED0A1A5856@smartmediacorp.com>
Message-ID: <BANLkTik4B5d1Xx5ncZigpR3roAds6TnjfA@mail.gmail.com>

One additional comment as well.

You might want to think about what you are trying to accomplish with
the date math.  xts/zoo has covered many common items that come up.

?to.period
?endpoints
?align.time
?period.apply
?split.xts

HTH,
Jeff



On Sat, Apr 16, 2011 at 12:48 PM, Noah Silverman
<noah at smartmediacorp.com> wrote:
> Nice,
>
> Thanks!
>
> Next challenge: ?Is there a package in R to do "date math". ?(There is great stuff in other languages, so must be in R)
>
> If I have a timetamp, It would be great to just "add 1 hour" or "add 7 minutes" and get back the proper date-time for it.
>
> I'm looking at a lot of timeseries data this weekend and need to learn how to do some of this simple stuff in R to play with some ideas.
>
> Thanks!
>
> --
> Noah Silverman
> Smart Media Corp.
> WebClipping.com
> Tel: (323) 653-1900 x5207
>
>
>
> On Apr 16, 2011, at 10:38 AM, Joshua Ulrich wrote:
>
>>
>> On Apr 16, 2011 12:29 PM, "Noah Silverman" <noah at smartmediacorp.com> wrote:
>> >
>> > Perfect!
>> >
>> > I never thought about using a double colon. ?Works quickly and cleanly.
>> >
>> > Now for the harder part.
>> >
>> > If I want to define my timestamps as variables first, how I can I subselect:
>> >
>> > a <- '2010-08-04 11:50:00'
>> > b <- '2010-08-04 11:55:00'
>> >
>> >
>> > ticks[a::b, ] ? fails
>> >
>> Take a careful look ay what others have already suggested and what you're trying. ?You're trying to apply a :: operator to two character vectors.
>>
>> xts subsetting requires a single string, which you can create via paste(a, b, sep="::").
>>
>> > Ideas?
>> >
>> > --
>> > Noah Silverman
>> > Smart Media Corp.
>> > WebClipping.com
>> > Tel: (323) 653-1900 x5207
>> >
>> >
>> >
>> > On Apr 16, 2011, at 10:12 AM, Hasan Diwan wrote:
>> >
>> > > On 16 April 2011 10:01, Noah Silverman <noah at smartmediacorp.com> wrote:
>> > >> Hi,
>> > >>
>> > >> Thanks to Jeff Ryan's help, I was able to get my data into a nice XTS format. ?I then followed his suggestion to use the make.index.unique() function to ensure that each tick had a slightly different time. ?Everything looks great!
>> > >>
>> > >> Now, I want to select subsets of the data for short intervals - perhaps 5 minutes in size.
>> > >>
>> > >> For example, I want all the entries between:
>> > >> 2010-08-04 11:50:00 ? and ? 2010-08-04 11:55:00
>> > >>
>> > >> I tried: ? ? ?ticks[' 2010-08-04 11:50:00' :'2010-08-04 11:55:00' , ] ? ?It failed
>> > >> Then: ? ? ?ticks[as.POSIXct(' 2010-08-04 11:50:00') ?: asPOSIXct('2010-08-04 11:55:00' ), ] ?Also fails
>> > >
>> > > ticks['2010-08-04 11:50:00::2011-08-04 11:55:00'] works brilliantly
>> > > --
>> > > Sent from my mobile device
>> > > Envoyait de mon telephone mobil
>> >
>> > _______________________________________________
>> > R-SIG-Finance at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only. If you want to post, subscribe first.
>> > -- Also note that this is not the r-help list where general R questions should go.
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com

R/Finance 2011 April 29th and 30th in Chicago | www.RinFinance.com


From samo.pahor at gmail.com  Sun Apr 17 15:18:55 2011
From: samo.pahor at gmail.com (Samo Pahor)
Date: Sun, 17 Apr 2011 15:18:55 +0200
Subject: [R-SIG-Finance] Finding all the tickers for common stock from
 Yahoo or Interactive Brokers
In-Reply-To: <BANLkTik5OgQa3S8Auw3UyxvW2rmR4+=ZtQ@mail.gmail.com>
References: <BANLkTinK8wfUGKS5EO5T9SUANKRG8Hrxrg@mail.gmail.com>
	<BANLkTik5OgQa3S8Auw3UyxvW2rmR4+=ZtQ@mail.gmail.com>
Message-ID: <BANLkTi=xPyBcRiWPrfjAKQqV2Pp56TzP1Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110417/eb0f11e5/attachment.pl>

From eric.thungstrom at gmail.com  Sun Apr 17 23:26:10 2011
From: eric.thungstrom at gmail.com (Eric Thungstom)
Date: Sun, 17 Apr 2011 17:26:10 -0400
Subject: [R-SIG-Finance] Performance Analytics Question
Message-ID: <BANLkTi=7xzVFsiArc64SQoFcbB0HHyDkJQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110417/78b7072e/attachment.pl>

From brian at braverock.com  Mon Apr 18 00:17:16 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 17 Apr 2011 17:17:16 -0500
Subject: [R-SIG-Finance] Performance Analytics Question
In-Reply-To: <BANLkTi=7xzVFsiArc64SQoFcbB0HHyDkJQ@mail.gmail.com>
References: <BANLkTi=7xzVFsiArc64SQoFcbB0HHyDkJQ@mail.gmail.com>
Message-ID: <4DAB66EC.4080003@braverock.com>

On 04/17/2011 04:26 PM, Eric Thungstom wrote:
> Just starting to use this package. What type of return data does the
> maxDrawdown function require; log returns or simple returns ?
>
> If I use dailyReturns() from quantmod package, use the default returns (i
> don't specify type), and plug those into maxDrawdown, will I get the correct
> value ?

As indicated in the documentation, the drawdown (and most other) 
functions in PerformanceAnalytics can support either simple or log 
(geometric) returns.

geometric defaults to TRUE.


From andres.susrud at gmail.com  Mon Apr 18 13:16:13 2011
From: andres.susrud at gmail.com (Andres Susrud)
Date: Mon, 18 Apr 2011 13:16:13 +0200
Subject: [R-SIG-Finance] backtest export to openOffice calc
Message-ID: <BANLkTi=mXBD9Ct19q9PETYOXV3o0jDMG3A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110418/f512e44b/attachment.pl>

From brian at braverock.com  Mon Apr 18 13:37:01 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 18 Apr 2011 06:37:01 -0500
Subject: [R-SIG-Finance] backtest export to openOffice calc
In-Reply-To: <BANLkTi=mXBD9Ct19q9PETYOXV3o0jDMG3A@mail.gmail.com>
References: <BANLkTi=mXBD9Ct19q9PETYOXV3o0jDMG3A@mail.gmail.com>
Message-ID: <4DAC225D.6000604@braverock.com>

On 04/18/2011 06:16 AM, Andres Susrud wrote:
> Hi,
>
> wondering if anyone has a good solution for writing backtests to openoffice
> Calc? (for windows x64)
> I've been using xlsReadWritePro, but it's not supported for either x64 or
> openoffice. (only excel 32 bit)

?write.csv


From ron_michael70 at yahoo.com  Mon Apr 18 17:04:35 2011
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Mon, 18 Apr 2011 08:04:35 -0700 (PDT)
Subject: [R-SIG-Finance] Artificial price series
Message-ID: <589350.83340.qm@web125705.mail.ne1.yahoo.com>

Hi Worik, I have been following this thread in "http://r.789695.n4.nabble.com/Artificial-price-series-td3443230.html", for quite a time now, however could not convince myself in one aspect. You said that simple RW model is not quite satisfactory (Horace Tso:: evidence is clear that financial prices are anything but brownian motion) hence, many people suggested GBM for that. But I could not understand why they are essentially different. I have:

for vanilla RW:???log(S[t+1]) = log(S[t]) + epsilon~N(.,.)
for vanilla GBM:? log(S[t+1]) = log(S[t]) + (mu - 0.5sigma^2) + epsilon~N(.,.)

Of course hare I am comparing both **vanilla** type and if I want to incorporate other features like jump, heavy tail etc., then I can incorporate those features in either case. Therefore driven by some common sense, why those 2 models would be fundamentally different? Only difference I see that, I generally do not include Intercept in RW, because including an Intercept signifies some deterministic trend in the underlying price, which also makes sense.

Additionally Mark says, "returns follow brownian motion", did he mean to say that **price** follows brownian motion?

Any clarification would be highly appreciated.

Thanks,


From markleeds2 at gmail.com  Mon Apr 18 17:19:06 2011
From: markleeds2 at gmail.com (Mark Leeds)
Date: Mon, 18 Apr 2011 11:19:06 -0400
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <589350.83340.qm@web125705.mail.ne1.yahoo.com>
References: <589350.83340.qm@web125705.mail.ne1.yahoo.com>
Message-ID: <BANLkTikMgsmxyHoi7GdCm0H3XT0DNT8_Yg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110418/c72ec2cb/attachment.pl>

From Horace.Tso at pgn.com  Mon Apr 18 20:44:12 2011
From: Horace.Tso at pgn.com (Horace Tso)
Date: Mon, 18 Apr 2011 11:44:12 -0700
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <589350.83340.qm@web125705.mail.ne1.yahoo.com>
References: <589350.83340.qm@web125705.mail.ne1.yahoo.com>
Message-ID: <5C3F9922B1D5FB4886B2D2045AB952F3057A4BF1F8@IPEXMAIL.corp.dom>

Ron & others,

I venture to give my 2 cent worth of opinion here. Many (the Professors on the list please weigh in) have more insight than I do. 

Here is what I find curious. As Worik pointed out in his original post, if you use any of the R simulation functions to generate a random walk or a fancier brownian motion series, plot it with some real price data, let's say daily closing level of the Dow Jones Industrial Average, you could tell they are different. But it's hard to say exactly what makes them look different to the human eyes. 

Not too long ago I played this trick on a friend of mine, who claimed he had no prior knowledge of finance nor familiar with securities price patterns. I sampled a number of time series from Bloomberg. I think I picked daily S&P, minute ticks of gold, nymex natural gas, the Shanghai Composite stock index, and other unrelated real prices. Then I simulated equal number of artificial data series using different stochastic models. A few were just straightforward random walk with varying sigma, others were jump diffusion (EMJumpDiffusion) with different jump prob and size. I plotted them along side and I was careful to remove the axis labels so he couldn't see the scale of things. 

I asked my friend to tell me which were real and which were artificial data. Amazingly he got many of them right. (OK, full disclosure here: this occurred in a bar after he had a couple of beers.)

I could see how even the most sophisticated simulation models couldn't quite imitate reality. First, many stock data have trend. The buy-and-hold crowd is right. Secondly, the unobserved volatility parameter is in itself a stochastic process (huge literature on this). Third, the jump processes in simulation models are probably too simplistic. Just plot Dow Jones from July to Dec, 1987. 

Horace








 

-----Original Message-----
From: r-sig-finance-bounces at r-project.org [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Ron Michael
Sent: Monday, April 18, 2011 8:05 AM
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] Artificial price series

Hi Worik, I have been following this thread in "http://r.789695.n4.nabble.com/Artificial-price-series-td3443230.html", for quite a time now, however could not convince myself in one aspect. You said that simple RW model is not quite satisfactory (Horace Tso:: evidence is clear that financial prices are anything but brownian motion) hence, many people suggested GBM for that. But I could not understand why they are essentially different. I have:

for vanilla RW:???log(S[t+1]) = log(S[t]) + epsilon~N(.,.)
for vanilla GBM:? log(S[t+1]) = log(S[t]) + (mu - 0.5sigma^2) + epsilon~N(.,.)

Of course hare I am comparing both **vanilla** type and if I want to incorporate other features like jump, heavy tail etc., then I can incorporate those features in either case. Therefore driven by some common sense, why those 2 models would be fundamentally different? Only difference I see that, I generally do not include Intercept in RW, because including an Intercept signifies some deterministic trend in the underlying price, which also makes sense.

Additionally Mark says, "returns follow brownian motion", did he mean to say that **price** follows brownian motion?

Any clarification would be highly appreciated.

Thanks,

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


From dzidorius at gmail.com  Mon Apr 18 22:52:53 2011
From: dzidorius at gmail.com (Dzidas)
Date: Mon, 18 Apr 2011 13:52:53 -0700
Subject: [R-SIG-Finance] IBrokers and timezone
Message-ID: <1303159973665-3458674.post@n4.nabble.com>

How can I specify the timezone in reqHistoricalData method? I tried this way: 
reqHistoricalData(tws,twsSTK('IBM'),'20110417 00:00:26 EST',"5 mins","5
D","1") 
but it returns based on my locale or tws. 
For an example: 

2011-04-11  21:55:00,163.76,163.95,163.69,163.89,1361,163.8,0,949 <-end of
trading session, CET time 
2011-04-12  15:30:00,163.49,163.57,163.2,163.41,1331,163.37,0,418 <-start of
trading session, CET time 

I can convert it later on, but it is very difficult, because I use CET by
default and there is a lag in summer time between CET and EST. And it gets
very messy.

--
View this message in context: http://r.789695.n4.nabble.com/IBrokers-and-timezone-tp3458674p3458674.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From ron_michael70 at yahoo.com  Mon Apr 18 23:46:34 2011
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Mon, 18 Apr 2011 14:46:34 -0700 (PDT)
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <5C3F9922B1D5FB4886B2D2045AB952F3057A4BF1F8@IPEXMAIL.corp.dom>
Message-ID: <812300.48343.qm@web125710.mail.ne1.yahoo.com>

Thanks Horace and Mark for replying on my query. However I believe that my question was not properly understood or may be I could not understand your statement. Whatever it happened, I believe there is some miscommunication.

I want to understand that: between these 2 candidates GBM & RW (form of them I already mentioned in my previous mail), which could be better. I understand that both are very simplistic in modelling any price, however if I have to chose anyone from them then what should I chose? GBM or RW.

Many previous mails seems to me that, they are in support of GBM, where I believe that there are no fundamental difference between them. Or perhaps I am missing something?

Thanks,

--- On Tue, 19/4/11, Horace Tso <Horace.Tso at pgn.com> wrote:

> From: Horace Tso <Horace.Tso at pgn.com>
> Subject: RE: [R-SIG-Finance] Artificial price series
> To: "Ron Michael" <ron_michael70 at yahoo.com>, "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
> Date: Tuesday, 19 April, 2011, 1:44 AM
> Ron & others,
> 
> I venture to give my 2 cent worth of opinion here. Many
> (the Professors on the list please weigh in) have more
> insight than I do. 
> 
> Here is what I find curious. As Worik pointed out in his
> original post, if you use any of the R simulation functions
> to generate a random walk or a fancier brownian motion
> series, plot it with some real price data, let's say daily
> closing level of the Dow Jones Industrial Average, you could
> tell they are different. But it's hard to say exactly what
> makes them look different to the human eyes. 
> 
> Not too long ago I played this trick on a friend of mine,
> who claimed he had no prior knowledge of finance nor
> familiar with securities price patterns. I sampled a number
> of time series from Bloomberg. I think I picked daily
> S&P, minute ticks of gold, nymex natural gas, the
> Shanghai Composite stock index, and other unrelated real
> prices. Then I simulated equal number of artificial data
> series using different stochastic models. A few were just
> straightforward random walk with varying sigma, others were
> jump diffusion (EMJumpDiffusion) with different jump prob
> and size. I plotted them along side and I was careful to
> remove the axis labels so he couldn't see the scale of
> things. 
> 
> I asked my friend to tell me which were real and which were
> artificial data. Amazingly he got many of them right. (OK,
> full disclosure here: this occurred in a bar after he had a
> couple of beers.)
> 
> I could see how even the most sophisticated simulation
> models couldn't quite imitate reality. First, many stock
> data have trend. The buy-and-hold crowd is right. Secondly,
> the unobserved volatility parameter is in itself a
> stochastic process (huge literature on this). Third, the
> jump processes in simulation models are probably too
> simplistic. Just plot Dow Jones from July to Dec, 1987. 
> 
> Horace
> 
> 
> 
> 
> 
> 
> 
> 
>  
> 
> -----Original Message-----
> From: r-sig-finance-bounces at r-project.org
> [mailto:r-sig-finance-bounces at r-project.org]
> On Behalf Of Ron Michael
> Sent: Monday, April 18, 2011 8:05 AM
> To: r-sig-finance at r-project.org
> Subject: [R-SIG-Finance] Artificial price series
> 
> Hi Worik, I have been following this thread in "http://r.789695.n4.nabble.com/Artificial-price-series-td3443230.html",
> for quite a time now, however could not convince myself in
> one aspect. You said that simple RW model is not quite
> satisfactory (Horace Tso:: evidence is clear that financial
> prices are anything but brownian motion) hence, many people
> suggested GBM for that. But I could not understand why they
> are essentially different. I have:
> 
> for vanilla RW:???log(S[t+1]) = log(S[t]) +
> epsilon~N(.,.)
> for vanilla GBM:? log(S[t+1]) = log(S[t]) + (mu -
> 0.5sigma^2) + epsilon~N(.,.)
> 
> Of course hare I am comparing both **vanilla** type and if
> I want to incorporate other features like jump, heavy tail
> etc., then I can incorporate those features in either case.
> Therefore driven by some common sense, why those 2 models
> would be fundamentally different? Only difference I see
> that, I generally do not include Intercept in RW, because
> including an Intercept signifies some deterministic trend in
> the underlying price, which also makes sense.
> 
> Additionally Mark says, "returns follow brownian motion",
> did he mean to say that **price** follows brownian motion?
> 
> Any clarification would be highly appreciated.
> 
> Thanks,
> 
> _______________________________________________
> R-SIG-Finance at r-project.org
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe
> first.
> -- Also note that this is not the r-help list where general
> R questions should go.
>


From worik.stanton at gmail.com  Tue Apr 19 00:32:25 2011
From: worik.stanton at gmail.com (Worik)
Date: Tue, 19 Apr 2011 10:32:25 +1200
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <812300.48343.qm@web125710.mail.ne1.yahoo.com>
References: <812300.48343.qm@web125710.mail.ne1.yahoo.com>
Message-ID: <4DACBBF9.2040907@gmail.com>

This is very interesting.  My take is that it is futile to try to 
generate artificial price series using simple algorithmic processes that 
have the properties of real price series.  (Return series are 
equivalent, but price series make pretty graphs!)

My reasoning is theoretical so suspect.  Here goes:  Prices are self 
referencing systems.  In that they are set by a group of intelligent 
agents (not just people, there are plenty of robots with varying degrees 
of intelligence trading out there).  They analyse price movements and 
the surrounding systems (the "ecosystem" of prices if you like) and the 
decisions they make are dependant on all the inputs in a very non-linear 
manner.

Sorry that is not clear, I cannot do better right now in an email.

I am not saying that markets (the collection of these agents, their 
interactions and the prices that result) are efficient, they are not in 
a EMH sense.  I am saying that the price series that results is 
unreproducible by simple algorithmic processes.

But that said, an artificial price series is a nice thing to have to 
hand as its properties are well known.  For some one like me who is 
studying and reproducing results from TA literature it is very useful.  
If I feed the artificial price series to my TA algorithms I expect 
random results.  It is just another test, neither sufficient nor 
necessary, but nice to have, for all sorts of reasons.

So all in all there is no point putting a lot of research effort into 
simple methods of generating artificial price series.

This is what I used, good enough for me....


getArtificialDataBrownian <- function(length=10000, 
seed=round(exp(1)*1000)){
   set.seed(seed)
   r <- 1
   sigma <- 0.5
   x <- 10
   N <- length   # number of end points of the grid including T
   T <- 1 # length of the interval [0,T] in time units
   Delta <- T/N # time increment
   W <- numeric(N+1) # initialization of the vector W
   t <- seq(0,T, length=N+1)
   for(i in 2:(N+1))
     W[i] <- W[i-1] + rnorm(1) * sqrt(Delta)
   S <- x * exp((r-sigma^2/2)*t + sigma*W)

   start <- as.Date("1900-01-01")
   end <- start+length
   dates <- seq(start, end, by="day")
   ret <- xts(S, dates)
   return(ret)
}


cheers
Worik

On 19/04/11 09:46, Ron Michael wrote:
> Thanks Horace and Mark for replying on my query. However I believe that my question was not properly understood or may be I could not understand your statement. Whatever it happened, I believe there is some miscommunication.
>
> I want to understand that: between these 2 candidates GBM&  RW (form of them I already mentioned in my previous mail), which could be better. I understand that both are very simplistic in modelling any price, however if I have to chose anyone from them then what should I chose? GBM or RW.
>
> Many previous mails seems to me that, they are in support of GBM, where I believe that there are no fundamental difference between them. Or perhaps I am missing something?
>
> Thanks,
>
> --- On Tue, 19/4/11, Horace Tso<Horace.Tso at pgn.com>  wrote:
>
>> From: Horace Tso<Horace.Tso at pgn.com>
>> Subject: RE: [R-SIG-Finance] Artificial price series
>> To: "Ron Michael"<ron_michael70 at yahoo.com>, "r-sig-finance at r-project.org"<r-sig-finance at r-project.org>
>> Date: Tuesday, 19 April, 2011, 1:44 AM
>> Ron&  others,
>>
>> I venture to give my 2 cent worth of opinion here. Many
>> (the Professors on the list please weigh in) have more
>> insight than I do.
>>
>> Here is what I find curious. As Worik pointed out in his
>> original post, if you use any of the R simulation functions
>> to generate a random walk or a fancier brownian motion
>> series, plot it with some real price data, let's say daily
>> closing level of the Dow Jones Industrial Average, you could
>> tell they are different. But it's hard to say exactly what
>> makes them look different to the human eyes.
>>
>> Not too long ago I played this trick on a friend of mine,
>> who claimed he had no prior knowledge of finance nor
>> familiar with securities price patterns. I sampled a number
>> of time series from Bloomberg. I think I picked daily
>> S&P, minute ticks of gold, nymex natural gas, the
>> Shanghai Composite stock index, and other unrelated real
>> prices. Then I simulated equal number of artificial data
>> series using different stochastic models. A few were just
>> straightforward random walk with varying sigma, others were
>> jump diffusion (EMJumpDiffusion) with different jump prob
>> and size. I plotted them along side and I was careful to
>> remove the axis labels so he couldn't see the scale of
>> things.
>>
>> I asked my friend to tell me which were real and which were
>> artificial data. Amazingly he got many of them right. (OK,
>> full disclosure here: this occurred in a bar after he had a
>> couple of beers.)
>>
>> I could see how even the most sophisticated simulation
>> models couldn't quite imitate reality. First, many stock
>> data have trend. The buy-and-hold crowd is right. Secondly,
>> the unobserved volatility parameter is in itself a
>> stochastic process (huge literature on this). Third, the
>> jump processes in simulation models are probably too
>> simplistic. Just plot Dow Jones from July to Dec, 1987.
>>
>> Horace
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> -----Original Message-----
>> From: r-sig-finance-bounces at r-project.org
>> [mailto:r-sig-finance-bounces at r-project.org]
>> On Behalf Of Ron Michael
>> Sent: Monday, April 18, 2011 8:05 AM
>> To: r-sig-finance at r-project.org
>> Subject: [R-SIG-Finance] Artificial price series
>>
>> Hi Worik, I have been following this thread in "http://r.789695.n4.nabble.com/Artificial-price-series-td3443230.html",
>> for quite a time now, however could not convince myself in
>> one aspect. You said that simple RW model is not quite
>> satisfactory (Horace Tso:: evidence is clear that financial
>> prices are anything but brownian motion) hence, many people
>> suggested GBM for that. But I could not understand why they
>> are essentially different. I have:
>>
>> for vanilla RW:   log(S[t+1]) = log(S[t]) +
>> epsilon~N(.,.)
>> for vanilla GBM:  log(S[t+1]) = log(S[t]) + (mu -
>> 0.5sigma^2) + epsilon~N(.,.)
>>
>> Of course hare I am comparing both **vanilla** type and if
>> I want to incorporate other features like jump, heavy tail
>> etc., then I can incorporate those features in either case.
>> Therefore driven by some common sense, why those 2 models
>> would be fundamentally different? Only difference I see
>> that, I generally do not include Intercept in RW, because
>> including an Intercept signifies some deterministic trend in
>> the underlying price, which also makes sense.
>>
>> Additionally Mark says, "returns follow brownian motion",
>> did he mean to say that **price** follows brownian motion?
>>
>> Any clarification would be highly appreciated.
>>
>> Thanks,
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org
>> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe
>> first.
>> -- Also note that this is not the r-help list where general
>> R questions should go.
>>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


-- 
If we amplify everything, we hear nothing.
--


From markleeds2 at gmail.com  Tue Apr 19 06:34:31 2011
From: markleeds2 at gmail.com (Mark Leeds)
Date: Tue, 19 Apr 2011 00:34:31 -0400
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <812300.48343.qm@web125710.mail.ne1.yahoo.com>
References: <5C3F9922B1D5FB4886B2D2045AB952F3057A4BF1F8@IPEXMAIL.corp.dom>
	<812300.48343.qm@web125710.mail.ne1.yahoo.com>
Message-ID: <BANLkTimzmsaCMhq5pAaP+wHhX1DVRL5V1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110419/ff0c7b3a/attachment.pl>

From edd at debian.org  Tue Apr 19 15:28:46 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 19 Apr 2011 08:28:46 -0500
Subject: [R-SIG-Finance] R/Finance 2011: Ten days remaining
Message-ID: <19885.36366.806199.96118@max.nulle.part>


R/Finance 2011 will take place in about ten days on April 29-30 in Chicago.
The conference agenda is attached in pdf format.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: agenda.pdf
Type: application/pdf
Size: 163424 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110419/8517317f/attachment.pdf>
-------------- next part --------------

Building on the success of the two previous conferences in 2009 and
2010, we are expecting more than 200 attendees from around the world
representing both industry and academia to join a record 30+
presentations covering all areas of finance with R.

This year we are excited to have longer tutorial sessions. These tree
optional pre-conference tutorials are offered on the morning of April 29:

  J Ryan              Automated Trading with R		3 slots remaining
  G Yollin/S Payseur  High-Freq Analysis with R		sold out
  E Zivot    	      Financial Risk Models with R	3 slots remaining

Also, and for the first time, an optional full-day workshop is offered by D
Eddelbuettel and R Francois on Rcpp and R / C++ integration; and a few slots
are still open.

In addition, we have worked hard to extend the great networking opportunities
on both days with longer breaks and more hallway time between sessions.

New for 2011 is a special conference dinner that is held on Friday
evening. Overlooking the river from the famed Chicago Mercantile
Exchange, we have designed it to be a great way to continue the
conversations from the first day, as well as offering a chance to dine
and drink in Chicago style.

More details of the agenda are available at:

 http://www.RinFinance.com

Registration can be directly accessed by going to

 http://www.regonline.com/RinFinance2011

On behalf of the committee and sponsors, we look forward to seeing you
in Chicago!

 Gib Bassett, Peter Carl, Dirk Eddelbuettel, Brian Peterson,
 Dale Rosenthal, Jeffrey Ryan, Joshua Ulrich

Sponsors:
 International Center for Futures and Derivatives at UIC
 Revolution Analytics

 Rstudio
 One Market Data
 lemnica

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com

From bharatram.mnit at gmail.com  Tue Apr 19 15:58:53 2011
From: bharatram.mnit at gmail.com (Bharat Kherwa)
Date: Tue, 19 Apr 2011 06:58:53 -0700
Subject: [R-SIG-Finance] Artificial price series
In-Reply-To: <BANLkTimzmsaCMhq5pAaP+wHhX1DVRL5V1A@mail.gmail.com>
References: <5C3F9922B1D5FB4886B2D2045AB952F3057A4BF1F8@IPEXMAIL.corp.dom>
	<812300.48343.qm@web125710.mail.ne1.yahoo.com>
	<BANLkTimzmsaCMhq5pAaP+wHhX1DVRL5V1A@mail.gmail.com>
Message-ID: <BANLkTim8+51U+7YWG7Ruw6pBkqrY4mdwfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110419/41cfe2c1/attachment.pl>

From me at censix.com  Wed Apr 20 12:04:50 2011
From: me at censix.com (soren wilkening)
Date: Wed, 20 Apr 2011 03:04:50 -0700
Subject: [R-SIG-Finance] IBrokers and timezone
In-Reply-To: <1303159973665-3458674.post@n4.nabble.com>
References: <1303159973665-3458674.post@n4.nabble.com>
Message-ID: <1303293890267-3462584.post@n4.nabble.com>

I havent had this problem, but my best guess is that it could have something
to do with the way you specify your  contract for IBM

since your locale seems to be in Europe, defining a contract like this

twsSTK('IBM')

and without specifying a US exchange explicitly with the exch=... argument,
the IB system may default to assigning the exchange that is geographically
closest to you, means a european exchange where you can trade IBM. When you
then submit a 'US Eastern Standard Time' timestamp

'20110417 00:00:26 EST'

the european exchange will likely not know what to do with that timezone and
return its own default 'CET' instead.

So to cut it short:

try 

twsSTK('IBM', exch=...SOME US ECHANGE..)

instead.

Would be interested to see if this works.

Cheers

Soren

-----
http://censix.com
--
View this message in context: http://r.789695.n4.nabble.com/IBrokers-and-timezone-tp3458674p3462584.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From stephen at organicfoodmarkets.com.au  Wed Apr 20 12:41:30 2011
From: stephen at organicfoodmarkets.com.au (Stephen Choularton)
Date: Wed, 20 Apr 2011 20:41:30 +1000
Subject: [R-SIG-Finance] chart types
Message-ID: <4DAEB85A.3090106@organicfoodmarkets.com.au>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110420/8de5bef0/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: logo_new.jpg
Type: image/jpeg
Size: 5414 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110420/8de5bef0/attachment.jpg>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: CoS2010Winner.JPG
Type: image/jpeg
Size: 16091 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110420/8de5bef0/attachment.jpe>

From santosh.srinivas at gmail.com  Wed Apr 20 12:56:00 2011
From: santosh.srinivas at gmail.com (Santosh Srinivas)
Date: Wed, 20 Apr 2011 16:26:00 +0530
Subject: [R-SIG-Finance] chart types
In-Reply-To: <4DAEB85A.3090106@organicfoodmarkets.com.au>
References: <4DAEB85A.3090106@organicfoodmarkets.com.au>
Message-ID: <BANLkTimMtKQ11RdaMH6C=CX+R2K8J5He7A@mail.gmail.com>

I believe it is still experimental (/incomplete). Have you seen
chartSeries already?

You have options there. type = c("auto", "candlesticks",
"matchsticks", "bars","line"),

On Wed, Apr 20, 2011 at 4:11 PM, Stephen Choularton
<stephen at organicfoodmarkets.com.au> wrote:
>
> Hi
>
> ?Where can I find the options for type in:
>
>
> chart_Series(x,
>              name = deparse(substitute(x)),
>              type = "candlesticks",
>              subset = "",
>              TA = "",
>              pars = chart_pars(),
>              theme = chart_theme(),
>              clev = 0)
>
> The manual says:
>
> Arguments
>
> x time series object
> name name for chart
> type one of:
> subset an ISO8601 style character string indicating date range
> TA a character string of semi-colon seperated TA calls.
> pars chart parameters
> theme chart theme
>
> --
> Stephen Choularton Ph.D., FIoD
>
> 9999 2226
> 0413 545 182
>
>
> for insurance go to www.netinsure.com.au
> for markets go to www.organicfoodmarkets.com.au
> for equipment go to www.organicfoodmarkets.com.au/equipment
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From brian at braverock.com  Wed Apr 20 13:01:54 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 20 Apr 2011 06:01:54 -0500
Subject: [R-SIG-Finance] chart types
In-Reply-To: <4DAEB85A.3090106@organicfoodmarkets.com.au>
References: <4DAEB85A.3090106@organicfoodmarkets.com.au>
Message-ID: <1303297314.2761.41.camel@brian-desktop>

On Wed, 2011-04-20 at 20:41 +1000, Stephen Choularton wrote:
>  Where can I find the options for type in:
> 
> 
> chart_Series(
<...>

Stephen,

chart_Series (and the older chartSeries) is (are) not plot()

They are basically optimized *only* to be a line chart of xts time
series data (or such data coercible to xts).

add_TA (and the older addTA) can do some additional things, like doing
points, vertical bars, or symbols on top of the chart or in additional
chart panes.

chart_Series and add_TA do *not* currently have a generalized bar plot
method, and were never intended to do non-time-series things like
boxplots.  R core or more finance-oriented alternatives in the chart.*
functions in PerformanceAnalytics may be more what you're looking for in
this case.

What are you trying to do, specifically?

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From brian at braverock.com  Wed Apr 20 13:09:42 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 20 Apr 2011 06:09:42 -0500
Subject: [R-SIG-Finance] chart types
In-Reply-To: <BANLkTimMtKQ11RdaMH6C=CX+R2K8J5He7A@mail.gmail.com>
References: <4DAEB85A.3090106@organicfoodmarkets.com.au>
	<BANLkTimMtKQ11RdaMH6C=CX+R2K8J5He7A@mail.gmail.com>
Message-ID: <4DAEBEF6.5020304@braverock.com>

On 04/20/2011 05:56 AM, Santosh Srinivas wrote:
> I believe it is still experimental (/incomplete). Have you seen
> chartSeries already?
>
> You have options there. type = c("auto", "candlesticks",
> "matchsticks", "bars","line"),

you are correct.  chart_Series will (automatically) display either a 
line chart for univariate data or OHLC bars for OHLC data, but I don't 
know of a way to force this.

Perhaps Jeff will comment further.

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From rashaad at aeonim.co.za  Wed Apr 20 13:27:25 2011
From: rashaad at aeonim.co.za (Rashaad Tayob)
Date: Wed, 20 Apr 2011 13:27:25 +0200
Subject: [R-SIG-Finance] (no subject)
Message-ID: <BANLkTin0hNZFEtYeNt=rX+DbaZ1ET1HfRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110420/f5b5aea9/attachment.pl>

From paulteetor at yahoo.com  Wed Apr 20 16:23:57 2011
From: paulteetor at yahoo.com (Paul Teetor)
Date: Wed, 20 Apr 2011 07:23:57 -0700 (PDT)
Subject: [R-SIG-Finance] (no subject)
In-Reply-To: <BANLkTin0hNZFEtYeNt=rX+DbaZ1ET1HfRA@mail.gmail.com>
References: <BANLkTin0hNZFEtYeNt=rX+DbaZ1ET1HfRA@mail.gmail.com>
Message-ID: <766600.44250.qm@web65901.mail.ac4.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110420/8b27ef05/attachment.pl>

From edd at debian.org  Wed Apr 20 16:30:15 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 20 Apr 2011 09:30:15 -0500
Subject: [R-SIG-Finance] (no subject)
In-Reply-To: <BANLkTin0hNZFEtYeNt=rX+DbaZ1ET1HfRA@mail.gmail.com>
References: <BANLkTin0hNZFEtYeNt=rX+DbaZ1ET1HfRA@mail.gmail.com>
Message-ID: <19886.60919.147653.449049@max.nulle.part>


Rashaad,

(Posting with '(no subject)' does not help those of use getting too much mail
already. Please use a proper subject; chances are you will get better replies.)

On 20 April 2011 at 13:27, Rashaad Tayob wrote:
| Regarding the upcoming R conference, some further details on the venue would
| be appreciated for those not familiar with Chicago.
| 
| The address is given as University of Illinois at Chicago (UIC), but i am
| sure that it is quite a big campus and the google maps link provided in the
| registration confo is not very precise. Can someone please provide detailed
| directions, including name and address of the building where the conference
| is to be held. Also the nearest metro station.

Does the page

     http://www.RinFinance.com/travel/

help?  If not, what information would you like to see?

We will be at Student Center East, and I find googling "student center east
uic" works pretty well.  But please do let us know how we could improve the
travel page for you.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From jeffrey.ryan at lemnica.com  Wed Apr 20 16:34:19 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Wed, 20 Apr 2011 09:34:19 -0500
Subject: [R-SIG-Finance] Conference Details for R/Finance 2011 in Chicago
Message-ID: <BANLkTimmZ7g4mcrzsr1opiV57SvhJeMz8Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110420/74559afb/attachment.pl>

From jeffrey.ryan at lemnica.com  Wed Apr 20 18:18:32 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Wed, 20 Apr 2011 11:18:32 -0500
Subject: [R-SIG-Finance] IBrokers and timezone
In-Reply-To: <1303159973665-3458674.post@n4.nabble.com>
References: <1303159973665-3458674.post@n4.nabble.com>
Message-ID: <BANLkTinGPuftBs0VsM2SHCoW9W+eTa1fkg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110420/86118716/attachment.pl>

From jorge.nieves at moorecap.com  Wed Apr 20 18:48:00 2011
From: jorge.nieves at moorecap.com (Jorge Nieves)
Date: Wed, 20 Apr 2011 12:48:00 -0400
Subject: [R-SIG-Finance] Rbloomberg problem
Message-ID: <D595C0E05185614C90515F1E8A2D4CBF02B180AB@NYC-XCH3.win.moorecap.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110420/0d4161fa/attachment.pl>

From rashaad at aeonim.co.za  Wed Apr 20 19:07:42 2011
From: rashaad at aeonim.co.za (Rashaad Tayob)
Date: Wed, 20 Apr 2011 19:07:42 +0200
Subject: [R-SIG-Finance] Conference Details for R/Finance 2011 in Chicago
In-Reply-To: <BANLkTimmZ7g4mcrzsr1opiV57SvhJeMz8Q@mail.gmail.com>
References: <BANLkTimmZ7g4mcrzsr1opiV57SvhJeMz8Q@mail.gmail.com>
Message-ID: <BANLkTino7JD70tZgzdqrSoeiZraUgiKxsA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110420/a09a2b8e/attachment.pl>

From nelson.ana at gmail.com  Wed Apr 20 19:15:57 2011
From: nelson.ana at gmail.com (Ana Nelson)
Date: Wed, 20 Apr 2011 18:15:57 +0100
Subject: [R-SIG-Finance] Rbloomberg problem
In-Reply-To: <D595C0E05185614C90515F1E8A2D4CBF02B180AB@NYC-XCH3.win.moorecap.com>
References: <D595C0E05185614C90515F1E8A2D4CBF02B180AB@NYC-XCH3.win.moorecap.com>
Message-ID: <BANLkTimmMHarBR8fbrE8532VuMYtGo7mbg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110420/3824bdc2/attachment.pl>

From edd at debian.org  Wed Apr 20 20:59:47 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 20 Apr 2011 13:59:47 -0500
Subject: [R-SIG-Finance] Conference Details for R/Finance 2011 in Chicago
In-Reply-To: <BANLkTino7JD70tZgzdqrSoeiZraUgiKxsA@mail.gmail.com>
References: <BANLkTimmZ7g4mcrzsr1opiV57SvhJeMz8Q@mail.gmail.com>
	<BANLkTino7JD70tZgzdqrSoeiZraUgiKxsA@mail.gmail.com>
Message-ID: <19887.11555.420760.838339@max.nulle.part>


Rashaad,

On 20 April 2011 at 19:07, Rashaad Tayob wrote:
| thanks,?
| 
| Dirk the detail on "Student Center East" is a big help. Its not listed on the
| travel page.

I just fixed that -- there is now a link to the Google search I suggested.
We also have a pdf map we could link but it is no better than the campus wide
info accessible via the link.

Hope this helps, and thanks for the pointer. See you next week!

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From stephen at organicfoodmarkets.com.au  Thu Apr 21 00:21:08 2011
From: stephen at organicfoodmarkets.com.au (Stephen Choularton)
Date: Thu, 21 Apr 2011 08:21:08 +1000
Subject: [R-SIG-Finance] chart types
In-Reply-To: <1303297314.2761.41.camel@brian-desktop>
References: <4DAEB85A.3090106@organicfoodmarkets.com.au>
	<1303297314.2761.41.camel@brian-desktop>
Message-ID: <4DAF5C54.4050708@organicfoodmarkets.com.au>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110421/10fcb0cc/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: logo_new.jpg
Type: image/jpeg
Size: 5414 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110421/10fcb0cc/attachment.jpg>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: CoS2010Winner.JPG
Type: image/jpeg
Size: 16091 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110421/10fcb0cc/attachment.jpe>

From stephen at organicfoodmarkets.com.au  Thu Apr 21 07:45:24 2011
From: stephen at organicfoodmarkets.com.au (Stephen Choularton)
Date: Thu, 21 Apr 2011 15:45:24 +1000
Subject: [R-SIG-Finance] bbands demo
Message-ID: <4DAFC474.9020500@organicfoodmarkets.com.au>

Hi

I've been playing around with bbands demo but I cannot got it working.

  I think the problem is that on the same day the close both fell below 
the upper boundary and below the mean and the second got ignored.

Can anyone help me to get this code to do what it should be doing?

code;

# btest.R

# code to backtest spread trading based on cointegration and reversion 
to mean ('cir')

# ok, what I will do is to see if I can write a rule that goes short if 
price is above two standard deviations and goes below and closes at 
average and vice versa.

require(quantstrat)

try(rm("order_book.cir",pos=.strategy),silent=TRUE)
try(rm("account.cir","portfolio.cir",pos=.blotter),silent=TRUE)
try(rm("account.st","portfolio.st","stock.str","s","initDate","initEq",'start_t','end_t'),silent=TRUE)

# some things to set up here
stock.str='IBM' # what are we trying it on
SD = 2 # how many standard deviations, traditionally 2
N = 20 # how many periods for the moving average


currency('USD')
stock(stock.str,currency='USD',multiplier=1)

initDate='2011-01-31' # use a short period for eyeballing
initEq=1000000

portfolio.st='cir'
account.st='cir'

initPortf(portfolio.st,symbols=stock.str, initDate=initDate)
initAcct(account.st,portfolios='cir', initDate=initDate)
initOrders(portfolio=portfolio.st,initDate=initDate)

s <- strategy("cir")

####### INDICATOR #######

#s <- add.indicator(strategy = s, name = "SMA", arguments = list(x = 
quote(Cl(mktdata)), n=10), label="SMA10")
# thus puts dn    mavg    up    pctB onto the mktdata table

#this adds a col of data to the table
s <- add.indicator(strategy = s, name = "BBands", arguments = list(HLC = 
quote(HLC(mktdata)), sd=SD, n=N, maType=quote(SMA)))


#if you wanted to manually apply a signal function for demonstration
#cbind(IBM.mod,sigComparison(label="Close.gt.Open",data=IBM.inds,columns=c("Close","Open"),">"))
#cbind(IBM.mod,sigComparison(label="Adjusted.gt.SMA",data=IBM.inds,columns=c("Adjusted","SMA10"),">"))

####### SIGNALS #######

#do it properly and add it to the strategy:
#s<- add.signal(s,name="sigComparison",arguments = 
list(data=quote(mktdata),columns=c("Close","Open"),relationship="gt"),label="Cl.gt.Op")
# what does this do?
# this then add further cols which contain signals
# it adds a col named eg label="Cl.gt.UpperBand" which contains a 1 when 
it is triggered
# lets try

############### kill s<- add.signal(s,name="sigCrossover",arguments = 
list(data=quote(mktdata),columns=c("Close","up"),relationship="gt"),label="Cl.gt.UpperBand")



############### lets see if we can find it coming down through the top 
band ##############
s<- add.signal(s,name="sigCrossover",arguments = 
list(data=quote(mktdata),columns=c("Close","up"),relationship="lt"),label="Cl.lt.UpperBand")

############### kill s<- add.signal(s,name="sigCrossover",arguments = 
list(data=quote(mktdata),columns=c("Close","dn"),relationship="lt"),label="Cl.lt.LowerBand")

############### lets see if we can find it coming up through the bottom 
band ##############
s<- add.signal(s,name="sigCrossover",arguments = 
list(data=quote(mktdata),columns=c("Close","dn"),relationship="gt"),label="Cl.gt.LowerBand")

#s<- add.signal(s,name="sigCrossover",arguments = 
list(data=quote(mktdata),columns=c("Low","up"),  
relationship="gt"),label="Lo.gt.UpperBand")

#s<- add.signal(s,name="sigCrossover",arguments = 
list(data=quote(mktdata),columns=c("High","dn"), 
relationship="lt"),label="Hi.lt.LowerBand")



#s<- add.signal(s,name="sigCrossover",arguments = 
list(data=quote(mktdata),columns=c("Close","mavg"),relationship="op"),label="Cross.Mid")

s<- add.signal(s,name="sigCrossover",arguments = 
list(data=quote(mktdata),columns=c("High","Low","mavg"),relationship="op"),label="Cross.Mid")

s<- add.signal(s,name="sigCrossover",arguments = 
list(data=quote(mktdata),columns=c("Close","mavg"),relationship="lt"),label="Cross.Mid.Down")

s<- add.signal(s,name="sigCrossover",arguments = 
list(data=quote(mktdata),columns=c("Close","mavg"),relationship="gt"),label="Cross.Mid.Up")



#IBM.sigs<-applySignals(s,mktdata=IBM.inds)

# you can review the strategy by uncommenting this s

####### RULES #######

# lets add some rules
# what does this do?
# this then uses a signal to effect a trade in accordance with the rule.




# go short on down through top barrier

##### SHORT

s <- add.rule(s,name='ruleSignal', arguments = 
list(data=quote(mktdata),sigcol="Cl.lt.UpperBand",sigval=TRUE, 
orderqty=-100, ordertype='market', orderside='short', 
threshold=NULL),type='enter')

##### LONG

s <- add.rule(s,name='ruleSignal', arguments = 
list(data=quote(mktdata),sigcol="Cl.gt.LowerBand",sigval=TRUE, orderqty= 
100, ordertype='market', orderside='long', threshold=NULL),type='enter')

s <- add.rule(s,name='ruleSignal', arguments = 
list(data=quote(mktdata),sigcol="Cross.Mid.Down",sigval=TRUE, orderqty= 
'all', ordertype='market', orderside='short', threshold=NULL),type='exit')

#s <- add.rule(s,name='ruleSignal', arguments = 
list(data=quote(mktdata),sigcol="Cross.Mid.Up",sigval=TRUE, orderqty= 
'all', ordertype='market', orderside='long', threshold=NULL),type='exit')

#s <- add.rule(s,name='ruleSignal', arguments = 
list(data=quote(mktdata),sigcol="Cross.Mid",sigval=TRUE, orderqty= 
'all', ordertype='market', orderside=NULL, threshold=NULL),type='exit')




#TODO add thresholds and stop-entry and stop-exit handling to test

getSymbols(stock.str,from=initDate)
start_t<-Sys.time()
out<-try(applyStrategy(strategy='s' , portfolios='cir'))
# look at the order book
#getOrderBook('cir')
end_t<-Sys.time()
end_t-start_t
updatePortf(Portfolio='cir',Dates=paste('::',as.Date(Sys.time()),sep=''))
chart.Posn(Portfolio='cir',Symbol=stock.str)
plot(add_BBands(on=1,sd=SD,n=N))

#get/save some data

write.table(mktdata, 'C:/Elliot btest/mktdata.csv', col.name=TRUE, 
row.names=FALSE, sep=',')

print ('order book')


getOrderBook(portfolio.st)

print('transactions')


getTxns(Portfolio=portfolio.st, Symbol=stock.str)

print('account')

getAccount(portfolio.st)

# end
-- 
Stephen Choularton Ph.D., FIoD


From jorge.nieves at moorecap.com  Thu Apr 21 16:50:00 2011
From: jorge.nieves at moorecap.com (Jorge Nieves)
Date: Thu, 21 Apr 2011 10:50:00 -0400
Subject: [R-SIG-Finance] Rbloomberg problem
In-Reply-To: <BANLkTimmMHarBR8fbrE8532VuMYtGo7mbg@mail.gmail.com>
Message-ID: <D595C0E05185614C90515F1E8A2D4CBF02B180BD@NYC-XCH3.win.moorecap.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110421/0e45ccfa/attachment.pl>

From jorge.nieves at moorecap.com  Thu Apr 21 17:57:09 2011
From: jorge.nieves at moorecap.com (Jorge Nieves)
Date: Thu, 21 Apr 2011 11:57:09 -0400
Subject: [R-SIG-Finance] Rbloomberg problem
In-Reply-To: <BANLkTimmMHarBR8fbrE8532VuMYtGo7mbg@mail.gmail.com>
Message-ID: <D595C0E05185614C90515F1E8A2D4CBF02B180C3@NYC-XCH3.win.moorecap.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110421/298f986a/attachment.pl>

From johannes.lips at googlemail.com  Thu Apr 21 21:55:55 2011
From: johannes.lips at googlemail.com (Johannes Lips)
Date: Thu, 21 Apr 2011 21:55:55 +0200
Subject: [R-SIG-Finance] Transforming Price Timeseries
Message-ID: <4DB08BCB.7010205@googlemail.com>

Hello,

I have a little problem for which I don't have a solution. I have 
electricity prices for each hour of the day, since that's the normal 
form of contracts traded at energy exchanges.

The current format looks like this:
         Date EEXHR01 EEXHR02 EEXHR03 ... EEXHR22 EEXHR23 EEXHR24
1 2000-06-16   12.43   12.40   12.40 ... 15.45   14.57   14.57
2 2000-06-17   10.06   10.04   10.04 ... 12.82   12.83   12.82
3 2000-06-18   10.08   10.08    9.00 ... 11.78   11.80   11.78
4 2000-06-19   12.05   12.05   10.05 ...  16.42   14.95   14.95

I now would to transform this daily data into hourly data and make a 
'continous' time series. Something like:
Date			EEXPrice
2000-06-16-01:00	12.43
2000-06-16-02:00	12.40
.			.
.			.
.			.
2000-06-16-24:00	14.57

Is this possible with R or should I use something different?
If you need more information, just ask, pleas.

Thanks in advance!

Best Regards,

Johannes


From alexios at 4dscape.com  Thu Apr 21 22:42:28 2011
From: alexios at 4dscape.com (alexios)
Date: Thu, 21 Apr 2011 21:42:28 +0100
Subject: [R-SIG-Finance] Transforming Price Timeseries
In-Reply-To: <4DB08BCB.7010205@googlemail.com>
References: <4DB08BCB.7010205@googlemail.com>
Message-ID: <4DB096B4.5080107@4dscape.com>

You can do this with base R:

Assuming your data is called "dat", and it is in the format you 
presented, then the following code should work:

# create 4 digit hour (note that 2400 is 0000).
tm = c(paste(0,seq(100,900,by=100),sep = ""), seq(1000,2300,by = 100), 
"0000")

# date column assuming character vector
dt = as.character( dat[,1] )

# the 24 price columns
price = as.matrix( dat[,-1] )

# create a composite date-time character vector
newdt = as.vector( apply(as.data.frame(dt), 1, FUN = function(x) 
as.character(strptime(paste(x," ", tm,sep = ""), "%Y-%m-%d %H"))) )

# transform from matrix to vector by row
newprice = as.vector(price)

newdat = data.frame(Date = newdt, price = newprice)

See the ?DateTimeClasses for more information and also timezone codes.

Hope that helps.

Best,

Alexios


On 21/04/2011 20:55, Johannes Lips wrote:
> Hello,
>
> I have a little problem for which I don't have a solution. I have
> electricity prices for each hour of the day, since that's the normal
> form of contracts traded at energy exchanges.
>
> The current format looks like this:
> Date EEXHR01 EEXHR02 EEXHR03 ... EEXHR22 EEXHR23 EEXHR24
> 1 2000-06-16 12.43 12.40 12.40 ... 15.45 14.57 14.57
> 2 2000-06-17 10.06 10.04 10.04 ... 12.82 12.83 12.82
> 3 2000-06-18 10.08 10.08 9.00 ... 11.78 11.80 11.78
> 4 2000-06-19 12.05 12.05 10.05 ... 16.42 14.95 14.95
>
> I now would to transform this daily data into hourly data and make a
> 'continous' time series. Something like:
> Date EEXPrice
> 2000-06-16-01:00 12.43
> 2000-06-16-02:00 12.40
> . .
> . .
> . .
> 2000-06-16-24:00 14.57
>
> Is this possible with R or should I use something different?
> If you need more information, just ask, pleas.
>
> Thanks in advance!
>
> Best Regards,
>
> Johannes
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
>


From Peter.Brecknock at bp.com  Sat Apr 23 21:15:58 2011
From: Peter.Brecknock at bp.com (Pete Brecknock)
Date: Sat, 23 Apr 2011 12:15:58 -0700
Subject: [R-SIG-Finance] xts metadata
Message-ID: <1303586158420-3470514.post@n4.nabble.com>

I would like to attach metadata to an xts series that will hold the name of
the data source system of that series. When this series is subsequently
merged with other xts data objects I would be able to recover this name and
identify its original source system.

My effort below is not returning what I expect. 

# Generate Data
x1 = xts(1:10,Sys.Date()+1:10)
x2 = xts(11:20,Sys.Date()+1:10)
x3 = xts(21:30,Sys.Date()+1:10)
x4 = xts(31:40,Sys.Date()+1:10)
x5 = xts(41:50,Sys.Date()+1:10)

# Simulate Data from Two Different Sources
x12  = merge(x1,x2)   # Data from Data System A
x345 = merge(x3,x4,x5)  # Data from Data System B

# Set metadata
attr(x12,"source") = "A"
attr(x345,"source") = "B"

# All Systems Data
x12345 = merge(x12,x345)

# Query Sources
attr(x12345,"source")      # returns "A"
attr(x12345[,1],"source") # returns "A" 
attr(x12345[,5],"source") # returns "A" expecting "B"

I would gratefully receive any suggestions.

Thanks and kind regards

Pete

--
View this message in context: http://r.789695.n4.nabble.com/xts-metadata-tp3470514p3470514.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From jeff.a.ryan at gmail.com  Sat Apr 23 23:28:56 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sat, 23 Apr 2011 16:28:56 -0500
Subject: [R-SIG-Finance] xts metadata
In-Reply-To: <1303586158420-3470514.post@n4.nabble.com>
References: <1303586158420-3470514.post@n4.nabble.com>
Message-ID: <F74C1042-2AB1-467A-8325-38D096D06BB0@gmail.com>

Hi Pete,

I short, zoo and xts don't support column based attributes, though it has been discussed at least a few times that I am aware of. 

My advice would be to "overload" the colnames with some sort of internally designed naming convention - much as quantmod does with AAPL.Open etc.

In terms of potential for col attributes to be built-in -- it is possible, but not probable at this point is my guess. Given that the above naming scheme will work, it hasn't caused too much trouble in the past, and getting it to be consistent/logical across all of the ops and expectations, I would sooner leave it alone to concentrate on more pressing needs. 

HTH
Jeff



On Apr 23, 2011, at 2:15 PM, Pete Brecknock <Peter.Brecknock at bp.com> wrote:

> I would like to attach metadata to an xts series that will hold the name of
> the data source system of that series. When this series is subsequently
> merged with other xts data objects I would be able to recover this name and
> identify its original source system.
> 
> My effort below is not returning what I expect. 
> 
> # Generate Data
> x1 = xts(1:10,Sys.Date()+1:10)
> x2 = xts(11:20,Sys.Date()+1:10)
> x3 = xts(21:30,Sys.Date()+1:10)
> x4 = xts(31:40,Sys.Date()+1:10)
> x5 = xts(41:50,Sys.Date()+1:10)
> 
> # Simulate Data from Two Different Sources
> x12  = merge(x1,x2)   # Data from Data System A
> x345 = merge(x3,x4,x5)  # Data from Data System B
> 
> # Set metadata
> attr(x12,"source") = "A"
> attr(x345,"source") = "B"
> 
> # All Systems Data
> x12345 = merge(x12,x345)
> 
> # Query Sources
> attr(x12345,"source")      # returns "A"
> attr(x12345[,1],"source") # returns "A" 
> attr(x12345[,5],"source") # returns "A" expecting "B"
> 
> I would gratefully receive any suggestions.
> 
> Thanks and kind regards
> 
> Pete
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/xts-metadata-tp3470514p3470514.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From brian at braverock.com  Sat Apr 23 23:36:06 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 23 Apr 2011 16:36:06 -0500
Subject: [R-SIG-Finance] xts metadata
In-Reply-To: <F74C1042-2AB1-467A-8325-38D096D06BB0@gmail.com>
References: <1303586158420-3470514.post@n4.nabble.com>
	<F74C1042-2AB1-467A-8325-38D096D06BB0@gmail.com>
Message-ID: <1303594566.2141.254.camel@brian-desktop>

Peter,

We stored information like the data source with the instrument metadata
in FinancialInstrument, since we also used that to control our calls to
getSymbols, we could always look up info in the instrument metadata with
getInstrument.

Regards,

  - Brian

On Sat, 2011-04-23 at 16:28 -0500, Jeff Ryan wrote:
> Hi Pete,
> 
> I short, zoo and xts don't support column based attributes, though it has been discussed at least a few times that I am aware of. 
> 
> My advice would be to "overload" the colnames with some sort of internally designed naming convention - much as quantmod does with AAPL.Open etc.
> 
> In terms of potential for col attributes to be built-in -- it is possible, but not probable at this point is my guess. Given that the above naming scheme will work, it hasn't caused too much trouble in the past, and getting it to be consistent/logical across all of the ops and expectations, I would sooner leave it alone to concentrate on more pressing needs. 
> 
> HTH
> Jeff
> 
> 
> 
> On Apr 23, 2011, at 2:15 PM, Pete Brecknock <Peter.Brecknock at bp.com> wrote:
> 
> > I would like to attach metadata to an xts series that will hold the name of
> > the data source system of that series. When this series is subsequently
> > merged with other xts data objects I would be able to recover this name and
> > identify its original source system.
> > 
> > My effort below is not returning what I expect. 
> > 
> > # Generate Data
> > x1 = xts(1:10,Sys.Date()+1:10)
> > x2 = xts(11:20,Sys.Date()+1:10)
> > x3 = xts(21:30,Sys.Date()+1:10)
> > x4 = xts(31:40,Sys.Date()+1:10)
> > x5 = xts(41:50,Sys.Date()+1:10)
> > 
> > # Simulate Data from Two Different Sources
> > x12  = merge(x1,x2)   # Data from Data System A
> > x345 = merge(x3,x4,x5)  # Data from Data System B
> > 
> > # Set metadata
> > attr(x12,"source") = "A"
> > attr(x345,"source") = "B"
> > 
> > # All Systems Data
> > x12345 = merge(x12,x345)
> > 
> > # Query Sources
> > attr(x12345,"source")      # returns "A"
> > attr(x12345[,1],"source") # returns "A" 
> > attr(x12345[,5],"source") # returns "A" expecting "B"
> > 
> > I would gratefully receive any suggestions.
> > 
> > Thanks and kind regards
> > 
> > Pete
> > 
> > --
> > View this message in context: http://r.789695.n4.nabble.com/xts-metadata-tp3470514p3470514.html
> > Sent from the Rmetrics mailing list archive at Nabble.com.
> > 
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions should go.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From eric.thungstrom at gmail.com  Sun Apr 24 17:21:39 2011
From: eric.thungstrom at gmail.com (Eric Thungstom)
Date: Sun, 24 Apr 2011 11:21:39 -0400
Subject: [R-SIG-Finance] rollapply + lowess indicator
Message-ID: <BANLkTi=7wy3V5H+sRNLw4Cw876iWgmx51w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110424/47bf37ac/attachment.pl>

From me at censix.com  Sun Apr 24 18:00:11 2011
From: me at censix.com (me at censix.com)
Date: Sun, 24 Apr 2011 18:00:11 +0200 (CEST)
Subject: [R-SIG-Finance] rollapply + lowess indicator
In-Reply-To: <BANLkTi=7wy3V5H+sRNLw4Cw876iWgmx51w@mail.gmail.com>
References: <BANLkTi=7wy3V5H+sRNLw4Cw876iWgmx51w@mail.gmail.com>
Message-ID: <57978.78.234.67.201.1303660811.squirrel@censix.com>


> Playing around a little with the lowess smoother. I tried the following
> and
> it doesn't seem to work. What am I doing wrong ?
>
> require(quantmod)
> getSymbols("^GSPC", src="yahoo", from="2000-01-01", to=Sys.Date())
> GSPC <-na.omit(Ad(GSPC))
> ind <- rollapply(GSPC, 200, lowess , align="right")
> print(head(ind))
>
> I get the following output :
>
>            GSPC.Adjusted
> 2000-10-16 List,2
> 2000-10-17 List,2
> 2000-10-18 List,2
> 2000-10-19 List,2
> 2000-10-20 List,2
> 2000-10-23 List,2
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

Maybe you want to do this ?

ind <- rollapply(GSPC, 200, function(z) {lowess(z)$y} , align="right")


-- 
http://censix.com


From garychin9 at gmail.com  Sun Apr 24 19:49:54 2011
From: garychin9 at gmail.com (Gary Chin)
Date: Mon, 25 Apr 2011 01:49:54 +0800
Subject: [R-SIG-Finance] Where can I download the latest RBloomberg package ?
Message-ID: <BANLkTinMja=-tnzffBBwk3M794VNkBuq=w@mail.gmail.com>

Hi there,

I am now using RBloomberg package 0.1 version which I download from
CRAN, the latest version at CRAN.

As I know, the latest version is 0.4. I have tried to install it from
repository that I know, but all failed with following message.

Am I missing something ? Can anyone give me a clue?

Thanks

Gary


> install.packages("RBloomberg", repos="r.findata.org")

Warning in install.packages("RBloomberg", repos = "r.findata.org") :
  argument 'lib' is missing: using
'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
Warning: unable to access index for repository
r.findata.org/bin/windows/contrib/2.11
Warning message:
In getDependencies(pkgs, dependencies, available, lib) :
  package 'RBloomberg' is not available


> install.packages("RBloomberg", repos="http://R-Forge.R-project.org")

Warning in install.packages("RBloomberg", repos =
"http://R-Forge.R-project.org") :
  argument 'lib' is missing: using
'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
Warning: unable to access index for repository
http://R-Forge.R-project.org/bin/windows/contrib/2.11
Warning message:
In getDependencies(pkgs, dependencies, available, lib) :
  package 'RBloomberg' is not available


> install.packages("RBloomberg", repos="http://r.bloombergapi.com")

Warning in install.packages("RBloomberg", repos = "http://r.bloombergapi.com") :
  argument 'lib' is missing: using
'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
Error in read.dcf(file = tmpf) : Line starting '<html> ...' is malformed!


From gmonaie at gmail.com  Sun Apr 24 23:14:38 2011
From: gmonaie at gmail.com (Gei Lin)
Date: Sun, 24 Apr 2011 17:14:38 -0400
Subject: [R-SIG-Finance] Where can I download the latest RBloomberg
 package ?
In-Reply-To: <BANLkTinMja=-tnzffBBwk3M794VNkBuq=w@mail.gmail.com>
References: <BANLkTinMja=-tnzffBBwk3M794VNkBuq=w@mail.gmail.com>
Message-ID: <BANLkTimzB0UQ7tg4sysQ6FTU53_QZ6Xgww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110424/7b6ee33b/attachment.pl>

From garychin9 at gmail.com  Mon Apr 25 09:21:25 2011
From: garychin9 at gmail.com (Gary Chin)
Date: Mon, 25 Apr 2011 15:21:25 +0800
Subject: [R-SIG-Finance] Where can I download the latest RBloomberg
 package ?
In-Reply-To: <BANLkTimzB0UQ7tg4sysQ6FTU53_QZ6Xgww@mail.gmail.com>
References: <BANLkTinMja=-tnzffBBwk3M794VNkBuq=w@mail.gmail.com>
	<BANLkTimzB0UQ7tg4sysQ6FTU53_QZ6Xgww@mail.gmail.com>
Message-ID: <BANLkTi=2nLnROR3_Cd4kwwX=WoK3G-b+sA@mail.gmail.com>

Dear Lin,

I tried your suggestion, doesn't work neither.

The return message said "unable to access index for repository.....".
(see below)

Does it mean the package not there?

I already tried both repos = "http://r.findata.org/" and repos =
"http://r.findata.org/rbloomberg/".

thanks,

Gary


Here is the output.

>install.packages("RBloomberg",repos="http://r.findata.org/rbloomberg/")

Warning in install.packages("RBloomberg", repos =
"http://r.findata.org/rbloomberg/") :
  argument 'lib' is missing: using
'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
Warning: unable to access index for repository
http://r.findata.org/rbloomberg/bin/windows/contrib/2.11
Warning message:
In getDependencies(pkgs, dependencies, available, lib) :
  package 'RBloomberg' is not available



On Mon, Apr 25, 2011 at 5:14 AM, Gei Lin <gmonaie at gmail.com> wrote:
> I think here:
>
> http://findata.org/rbloomberg/
>
> On Sun, Apr 24, 2011 at 1:49 PM, Gary Chin <garychin9 at gmail.com> wrote:
>>
>> Hi there,
>>
>> I am now using RBloomberg package 0.1 version which I download from
>> CRAN, the latest version at CRAN.
>>
>> As I know, the latest version is 0.4. I have tried to install it from
>> repository that I know, but all failed with following message.
>>
>> Am I missing something ? Can anyone give me a clue?
>>
>> Thanks
>>
>> Gary
>>
>>
>> > install.packages("RBloomberg", repos="r.findata.org")
>>
>> Warning in install.packages("RBloomberg", repos = "r.findata.org") :
>> ?argument 'lib' is missing: using
>> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>> Warning: unable to access index for repository
>> r.findata.org/bin/windows/contrib/2.11
>> Warning message:
>> In getDependencies(pkgs, dependencies, available, lib) :
>> ?package 'RBloomberg' is not available
>>
>>
>> > install.packages("RBloomberg", repos="http://R-Forge.R-project.org")
>>
>> Warning in install.packages("RBloomberg", repos =
>> "http://R-Forge.R-project.org") :
>> ?argument 'lib' is missing: using
>> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>> Warning: unable to access index for repository
>> http://R-Forge.R-project.org/bin/windows/contrib/2.11
>> Warning message:
>> In getDependencies(pkgs, dependencies, available, lib) :
>> ?package 'RBloomberg' is not available
>>
>>
>> > install.packages("RBloomberg", repos="http://r.bloombergapi.com")
>>
>> Warning in install.packages("RBloomberg", repos =
>> "http://r.bloombergapi.com") :
>> ?argument 'lib' is missing: using
>> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>> Error in read.dcf(file = tmpf) : Line starting '<html> ...' is malformed!
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>


From garychin9 at gmail.com  Mon Apr 25 09:52:17 2011
From: garychin9 at gmail.com (Gary Chin)
Date: Mon, 25 Apr 2011 15:52:17 +0800
Subject: [R-SIG-Finance] nabble.com r-sig-finance/Rmetrics mailing list -
	wrong email address
Message-ID: <BANLkTi=0afuFtrF9Bh-buUAgZKTpZ444BQ@mail.gmail.com>

Hi there,

Nabble.com has an archive of r-sig-finance mailing list
http://r.789695.n4.nabble.com/Rmetrics-f925806.html

Nabble registered users can subscribe mailing list there and also able
to post after subscribed.

However, I find that at the section of r-sig-finance / Rmetrics, both
the subscribe and posting email are wrong.

It is r-sig-finance at r-project.org , NOT r-sig-finance at stat.math.ethz.ch.

if anyone who has authorization to change it, please do so.

Thanks

Gary


From me at censix.com  Mon Apr 25 14:06:57 2011
From: me at censix.com (soren wilkening)
Date: Mon, 25 Apr 2011 05:06:57 -0700
Subject: [R-SIG-Finance] Quantstrat - Error while applying strategy
In-Reply-To: <1303695984905-3472438.post@n4.nabble.com>
References: <1303695984905-3472438.post@n4.nabble.com>
Message-ID: <1303733217149-3473009.post@n4.nabble.com>

Hi

I had a look. the main bug was that your 'randPos' function needs to return
a vector instead of a scalar. See the code. Seems to run ok. no credit for
elegance though :)

Soren

#
=================================================================================================
# The code provided here is from the crossMA example in quantstrat except in
the middle where said
#
=================================================================================================
require(quantstrat)
try(rm("order_book.macross",pos=.strategy),silent=TRUE)
try(rm("account.macross","portfolio.macross",pos=.blotter),silent=TRUE)
try(rm("account.st","portfolio.st","stock.str","stratMACROSS","initDate","initEq",'start_t','end_t'),
silent=TRUE)
stock.str='AAPL' # what are we trying it on
currency('USD')
stock(stock.str,currency='USD',multiplier=1)
initDate = '2007-12-31'
initEq = 3000
portfolio.st='macross'
account.st='macross'
initPortf(portfolio.st,symbols=stock.str, initDate=initDate)
initAcct(account.st,portfolios=portfolio.st, initDate=initDate)
initOrders(portfolio=portfolio.st,initDate=initDate)


#
=================================================================================================
# Here is my own part of the code
# randPos is a function that provides an output -1, 0 or 1 for short,
neutral or long respectively.
# Up signal if random indicator = 1
# Down signal if random indicator = -1
# Enter rules: long or short if respectively up or down signal
# Exit rules: exit long or exit short if respectively down or up signal 
#
=================================================================================================

# need to redefine this. indicators have to be vector-valued functions
nDays <- 20
probDn <- 1/2
probUp <- 1/2
# Random rebalancing
randPos <- function(x, nDays, probDn, probUp) {
.randPos <- function(i) {
    # random rebalancing (no rebalancing = 0, rebalancing = 1)
    rebal <- ifelse(runif(1) < 1/nDays, 1, 0)
    # random position (short = -1, long = 1, neutral = 0)
    a <- runif(1)
    if (a < probDn) {
        pos <- -1 
    } else {
        pos <- ifelse(a > (1 - probUp), 1, 0)
    }
    # no rebalancing or neutral = 0, long = 1, short = -1
    return(rebal*pos)
}

return( xts( sapply(1:nrow(x), .randPos), order.by=index(x)) )
}


stratMACROSS<- strategy(portfolio.st)
stratMACROSS <- add.indicator(strategy = stratMACROSS, name = "randPos", 
    arguments = list(x = quote(mktdata), nDays = nDays, probDn = probDn,
probUp = probUp), label = "randInd")  #need to use quote(mktdata)

stratMACROSS <- add.signal(strategy = stratMACROSS, name = "sigThreshold", 
    arguments = list(label = "randInd", column = "randInd", threshold = -1,
relationship = "eq"), label = "sigDn")  #need to omit data=mktdata
stratMACROSS <- add.signal(strategy = stratMACROSS, name = "sigThreshold", 
    arguments = list(label = "randInd", column = "randInd", threshold = 1,
relationship = "eq"), label = "sigUp")   #need to omit data=mktdata
     
stratMACROSS <- add.rule(strategy = stratMACROSS, name = "ruleSignal", 
    arguments = list(sigcol = "sigDn", sigval = TRUE, orderqty = -100,
ordertype = "market", orderside = "short", TxnFees = -5), type = "enter")
stratMACROSS <- add.rule(strategy = stratMACROSS, name = "ruleSignal", 
    arguments = list(sigcol = "sigUp", sigval = TRUE, orderqty = 100,
ordertype = "market", orderside = "short", TxnFees = -5), type = "exit")
    
stratMACROSS <- add.rule(strategy = stratMACROSS, name = "ruleSignal", 
    arguments = list(sigcol = "sigUp", sigval = TRUE, orderqty = 100,
ordertype = "market", orderside = "long", TxnFees = -5), type = "enter")
stratMACROSS <- add.rule(strategy = stratMACROSS, name = "ruleSignal", 
    arguments = list(sigcol = "sigDn", sigval = TRUE, orderqty = -100,
ordertype = "market", orderside = "long", TxnFees = -5), type = "exit")
#
=================================================================================================
# End of my part
#
=================================================================================================

getSymbols(stock.str,from=initDate)
for (i in stock.str) {
  assign(i, adjustOHLC(get(i),use.Adjusted = TRUE))
}

start_t <-Sys.time()
out <-try(applyStrategy(strategy = stratMACROSS, portfolios=portfolio.st))
end_t <-Sys.time()
print(end_t-start_t)

start_t <-Sys.time()
updatePortf(Portfolio='macross',Dates=paste('::',as.Date(Sys.time()),sep=''))
end_t <-Sys.time()
print("trade blotter portfolio update:")
print(end_t-start_t)

chart.Posn(Portfolio='macross',Symbol=stock.str)



-----
http://censix.com
--
View this message in context: http://r.789695.n4.nabble.com/Quantstrat-Error-while-applying-strategy-tp3472438p3473009.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From nelson.ana at gmail.com  Mon Apr 25 18:53:28 2011
From: nelson.ana at gmail.com (Ana Nelson)
Date: Mon, 25 Apr 2011 12:53:28 -0400
Subject: [R-SIG-Finance] Where can I download the latest RBloomberg
 package ?
In-Reply-To: <BANLkTi=2nLnROR3_Cd4kwwX=WoK3G-b+sA@mail.gmail.com>
References: <BANLkTinMja=-tnzffBBwk3M794VNkBuq=w@mail.gmail.com>
	<BANLkTimzB0UQ7tg4sysQ6FTU53_QZ6Xgww@mail.gmail.com>
	<BANLkTi=2nLnROR3_Cd4kwwX=WoK3G-b+sA@mail.gmail.com>
Message-ID: <BANLkTikgutR2v8C13s_z-0f87FzfuS-Jfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110425/af241a80/attachment.pl>

From vrramnath at gmail.com  Mon Apr 25 18:57:19 2011
From: vrramnath at gmail.com (Ramnath R)
Date: Mon, 25 Apr 2011 22:27:19 +0530
Subject: [R-SIG-Finance] Where can I download the latest RBloomberg
 package ?
In-Reply-To: <BANLkTikgutR2v8C13s_z-0f87FzfuS-Jfg@mail.gmail.com>
References: <BANLkTinMja=-tnzffBBwk3M794VNkBuq=w@mail.gmail.com>
	<BANLkTimzB0UQ7tg4sysQ6FTU53_QZ6Xgww@mail.gmail.com>
	<BANLkTi=2nLnROR3_Cd4kwwX=WoK3G-b+sA@mail.gmail.com>
	<BANLkTikgutR2v8C13s_z-0f87FzfuS-Jfg@mail.gmail.com>
Message-ID: <BANLkTinqmUTK_DM_YdmBoQEJ-dZvZsVDiQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110425/10c7be75/attachment.pl>

From carlos.ifisica at gmail.com  Tue Apr 26 02:37:05 2011
From: carlos.ifisica at gmail.com (=?ISO-8859-1?Q?Carlos_L=F3pez?=)
Date: Mon, 25 Apr 2011 19:37:05 -0500
Subject: [R-SIG-Finance] Possibly offtopic, about actuar package.
Message-ID: <4DB613B1.1040202@gmail.com>

Hello, sorry if this is offtopic, I'm trying to simulate using the 
aggregateDist function from the actuar package in R, but I want to 
simulate taking the shape from some data I have instead of the 
parametric function, for example I have two vectors with some 
probabilities from a severity model and from a frecuency model, what I 
want is to simulate the aggregate loss using these two sets of data, can 
this be possible using actuar?

Thank you very much
Carlos L?pez


From carlos.ifisica at gmail.com  Tue Apr 26 02:37:26 2011
From: carlos.ifisica at gmail.com (=?ISO-8859-1?Q?Carlos_L=F3pez?=)
Date: Mon, 25 Apr 2011 19:37:26 -0500
Subject: [R-SIG-Finance] Possibly offtopic, about actuar package.
Message-ID: <4DB613C6.2040004@gmail.com>

Hello, sorry if this is offtopic, I'm trying to simulate using the 
aggregateDist function from the actuar package in R, but I want to 
simulate taking the shape from some data I have instead of the 
parametric function, for example I have two vectors with some 
probabilities from a severity model and from a frecuency model, what I 
want is to simulate the aggregate loss using these two sets of data, can 
this be possible using actuar? in case this can' t be done using actuar, 
can you recommend any other R package to do this?

Thank you very much
Carlos L?pez


From algotr8der at gmail.com  Tue Apr 26 04:30:13 2011
From: algotr8der at gmail.com (algotr8der)
Date: Mon, 25 Apr 2011 19:30:13 -0700 (PDT)
Subject: [R-SIG-Finance] cointegration using Johansen for VAR
Message-ID: <1303785013626-3474574.post@n4.nabble.com>

Hello everyone - 

I am trying to reconcile the methodology used by Enders to estimate a VAR
and determine the cointegration vector using the Johansen framework (Enders
pages 397-to-401) with the same as highlighted by Dr. Bernhard Pfaff in his
book.

My intent for the moment is to determine whether a cointegration vector
exists among X variables and if so the value of the estimates in the
cointegration vector. 

According to Enders - the methodology is as follows:

1) Determine order of integration of each variable. 

I have 4 variables that are I(1) - all are stock prices.

2) Determine optimal number of lag length to be included in the VAR. 

I do this via the VARselect function in the 'vars' package in R as
highlighted in Dr. Pfaff's book.

> infocrit <- VARselect(vardat, lag.max=20, type="const")

> infocrit
$selection
AIC(n)  HQ(n)  SC(n) FPE(n) 
    17      3      2     17 

FIRST QUESTION: As you can see I have a conflict with the information
criteria. How does one reconcile the conflict in terms of the number of lags
to include in the VAR? Enders uses another method that estimates VARs with
different lag lengths and then uses the likelihood ratio test (page 397
Enders).

3) Estimate the model and determine the rank of ?.

> H1 <- ca.jo(vardat, type='trace', ecdet='const', K=17)

On a side note I also estimated the VAR by using "varestimate <- VAR(vardat,
p=17, type="const")".
I checked the residuals of each equation in the VAR for serial correlation
and normality (the residuals were white noise).

---------- snippet of output of ca.jo()-------------

          test 10pct  5pct  1pct
r <= 3 |  2.20  7.52  9.24 12.97
r <= 2 |  6.63 17.85 19.96 24.60
r <= 1 | 15.47 32.00 34.91 41.07
r = 0  | 50.11 49.65 53.12 60.16

Eigenvectors, normalised to first column:
(These are the cointegration relations)

              V1.l17          V2.l17           V3.l17           V4.l17      
constant
V1.l17     1.0000000     1.0000000     1.0000000     1.0000000   1.00000000
V2.l17    -0.2041193    -1.1345264    -0.3982231    -0.4862289  -0.21197975
V3.l17    -0.2584363     2.6858123    -0.8965070    -0.7727329  -0.43277884
V4.l17    -0.5167626    -0.8169243    -0.4955091     0.5102647   0.06214863
constant  5.2281138   -65.4213338    84.4998981    28.3856062  0.05660371


SECOND QUESTION: Since I supplied K=17 lags (as per the AIC and FPE
criterion) I'm not quite sure how to interpret the output of ca.jo(). 

Here is my understanding. Based on the trace test, I can reject the null:
r=0 at the 90% critical value and accept r > 0. However, I must accept the
null: r<= 1 given 15.47 is less than the critical values at all significance
levels. So this means I have 1 cointegration vector and from documentation
for ca.jo() I believe it is that depicted in the first column under the
"These are the cointegration relations" heading.

However, I am confused by the 'l17' suffix in each of the variables in the
output. I know I have up to 17 lags in my VAR as per the AIC and FPE
criterion but what does this actually say about the equilibrium
relationship? 

Would I be incorrect to say that the equilibrium (cointegration equation) is
the following:

V1 - 0.2041193*V2 - 0.2584363*V3 - 0.5167626*V4 + 5.2281138 =  residuals 

I would greatly appreciate it if someone could help steer me in the right
direction. Thank you.

--
View this message in context: http://r.789695.n4.nabble.com/cointegration-using-Johansen-for-VAR-tp3474574p3474574.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From Bernhard_Pfaff at fra.invesco.com  Tue Apr 26 15:58:27 2011
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Tue, 26 Apr 2011 14:58:27 +0100
Subject: [R-SIG-Finance] cointegration using Johansen for VAR
In-Reply-To: <1303785013626-3474574.post@n4.nabble.com>
References: <1303785013626-3474574.post@n4.nabble.com>
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C3285775EA@GBHENXMB02.corp.amvescap.net>

Dear Algotrader,

it is encountered quite often that IC will lead to different lag-specifications. In your case, I would opt for the SC or the HQ, i.e. a more parsimonuous specification and the values reported for the AIC and FPE look suspiciously high. Next, a VECM can be specified in different flavors and here you have used its long-run form. See ?ca.jo for a description and the arguments. 

Best,
Bernhard

> -----Urspr?ngliche Nachricht-----
> Von: r-sig-finance-bounces at r-project.org 
> [mailto:r-sig-finance-bounces at r-project.org] Im Auftrag von algotr8der
> Gesendet: Dienstag, 26. April 2011 04:30
> An: r-sig-finance at r-project.org
> Betreff: [R-SIG-Finance] cointegration using Johansen for VAR
> 
> Hello everyone - 
> 
> I am trying to reconcile the methodology used by Enders to 
> estimate a VAR and determine the cointegration vector using 
> the Johansen framework (Enders pages 397-to-401) with the 
> same as highlighted by Dr. Bernhard Pfaff in his book.
> 
> My intent for the moment is to determine whether a 
> cointegration vector exists among X variables and if so the 
> value of the estimates in the cointegration vector. 
> 
> According to Enders - the methodology is as follows:
> 
> 1) Determine order of integration of each variable. 
> 
> I have 4 variables that are I(1) - all are stock prices.
> 
> 2) Determine optimal number of lag length to be included in the VAR. 
> 
> I do this via the VARselect function in the 'vars' package in 
> R as highlighted in Dr. Pfaff's book.
> 
> > infocrit <- VARselect(vardat, lag.max=20, type="const")
> 
> > infocrit
> $selection
> AIC(n)  HQ(n)  SC(n) FPE(n) 
>     17      3      2     17 
> 
> FIRST QUESTION: As you can see I have a conflict with the 
> information criteria. How does one reconcile the conflict in 
> terms of the number of lags to include in the VAR? Enders 
> uses another method that estimates VARs with different lag 
> lengths and then uses the likelihood ratio test (page 397 Enders).
> 
> 3) Estimate the model and determine the rank of ?.
> 
> > H1 <- ca.jo(vardat, type='trace', ecdet='const', K=17)
> 
> On a side note I also estimated the VAR by using "varestimate 
> <- VAR(vardat, p=17, type="const")".
> I checked the residuals of each equation in the VAR for 
> serial correlation and normality (the residuals were white noise).
> 
> ---------- snippet of output of ca.jo()-------------
> 
>           test 10pct  5pct  1pct
> r <= 3 |  2.20  7.52  9.24 12.97
> r <= 2 |  6.63 17.85 19.96 24.60
> r <= 1 | 15.47 32.00 34.91 41.07
> r = 0  | 50.11 49.65 53.12 60.16
> 
> Eigenvectors, normalised to first column:
> (These are the cointegration relations)
> 
>               V1.l17          V2.l17           V3.l17         
>   V4.l17      
> constant
> V1.l17     1.0000000     1.0000000     1.0000000     
> 1.0000000   1.00000000
> V2.l17    -0.2041193    -1.1345264    -0.3982231    
> -0.4862289  -0.21197975
> V3.l17    -0.2584363     2.6858123    -0.8965070    
> -0.7727329  -0.43277884
> V4.l17    -0.5167626    -0.8169243    -0.4955091     
> 0.5102647   0.06214863
> constant  5.2281138   -65.4213338    84.4998981    28.3856062 
>  0.05660371
> 
> 
> SECOND QUESTION: Since I supplied K=17 lags (as per the AIC and FPE
> criterion) I'm not quite sure how to interpret the output of ca.jo(). 
> 
> Here is my understanding. Based on the trace test, I can 
> reject the null:
> r=0 at the 90% critical value and accept r > 0. However, I 
> must accept the
> null: r<= 1 given 15.47 is less than the critical values at 
> all significance levels. So this means I have 1 cointegration 
> vector and from documentation for ca.jo() I believe it is 
> that depicted in the first column under the "These are the 
> cointegration relations" heading.
> 
> However, I am confused by the 'l17' suffix in each of the 
> variables in the output. I know I have up to 17 lags in my 
> VAR as per the AIC and FPE criterion but what does this 
> actually say about the equilibrium relationship? 
> 
> Would I be incorrect to say that the equilibrium 
> (cointegration equation) is the following:
> 
> V1 - 0.2041193*V2 - 0.2584363*V3 - 0.5167626*V4 + 5.2281138 = 
>  residuals 
> 
> I would greatly appreciate it if someone could help steer me 
> in the right direction. Thank you.
> 
> --
> View this message in context: 
> http://r.789695.n4.nabble.com/cointegration-using-Johansen-for
> -VAR-tp3474574p3474574.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R 
> questions should go.
> 
*****************************************************************
Confidentiality Note: The information contained in this message,
and any attachments, may contain confidential and/or privileged
material. It is intended solely for the person(s) or entity to
which it is addressed. Any review, retransmission, dissemination,
or taking of any action in reliance upon this information by
persons or entities other than the intended recipient(s) is
prohibited. If you received this in error, please contact the
sender and delete the material from any computer.
*****************************************************************

From Murali.Menon at avivainvestors.com  Tue Apr 26 16:40:24 2011
From: Murali.Menon at avivainvestors.com (Murali.Menon at avivainvestors.com)
Date: Tue, 26 Apr 2011 15:40:24 +0100
Subject: [R-SIG-Finance] PerformanceAnalytics: periodicity() function
Message-ID: <05C1ABBB41112A4DB61380AD45F18EB61A240673E3@SWVLONCUEXDP01.im.root-domain.net>

Folks,

The variable scale is initialised as "years" in the function periodicity(), whereas the usage for other periods is 'quarterly', 'monthly' etc. This causes chart.TimeSeries() to throw an error in the

switch(freq$scale, ) code because that is looking for 'yearly', not 'years'.

E.g.

> x <- structure(c(0.000452526685891801, 0.000807277725566065, -0.00263743291162857, 
0.00565791169977606, 0.000493819538511648, 0.000231269431065556, 
0.00255725013533005, -0.000576682024023798, 0.00890528425766388, 
0.00172948824027563, 0.00586017066434493, 0.00033513487703795, 
0.00281930488908796, -0.00400888331693709, -0.00336887385144884, 
-0.000525136255385699, -0.0064468192138384, 0.0064614590751907, 
-0.00111345878301972), .indexCLASS = c("POSIXt", "POSIXct"), .indexTZ = "", .CLASS = "xts", na.action = structure(c(736L, 
1082L), class = "omit", index = c(1261699200, 1303772400)), index = structure(c(1176073200, 
1178492400, 1188169200, 1198627200, 1206316800, 1209942000, 1219618800, 
1230249600, 1239577200, 1241391600, 1251673200, 1261958400, 1270422000, 
1272841200, 1283122800, 1293408000, 1293494400, 1294012800, 1303686000
), tzone = "", tclass = c("POSIXt", "POSIXct")), .Dim = c(19L, 
1L), .Dimnames = list(NULL, "AHA"), class = c("xts", "zoo"))

> chart.TimeSeries(x)
Error in if (format == "") { : argument is of length zero

> periodicity(x)$scale
[1] "years"

Is this a bug in periodicity()?

I am using PerformanceAnalytics 1.0.3.2 and R 2.11.1

Thanks,
Murali


From peter at braverock.com  Tue Apr 26 17:16:00 2011
From: peter at braverock.com (Peter Carl)
Date: Tue, 26 Apr 2011 10:16:00 -0500
Subject: [R-SIG-Finance] PerformanceAnalytics: periodicity() function
In-Reply-To: <05C1ABBB41112A4DB61380AD45F18EB61A240673E3@SWVLONCUEXDP01.im.root-domain.
	net>
References: <05C1ABBB41112A4DB61380AD45F18EB61A240673E3@SWVLONCUEXDP01.im.root-domain.net>
Message-ID: <f30d7868d493654e21d36e90d6178310.squirrel@mail.braverock.com>

If we go by the documentation in ?periodicity, it looks like a bug:

"Possible scale values are:

?minute?,?hourly?, ?daily?,?weekly?, ?monthly?,?quarterly?, and ?yearly?. "

Of course, I have a vested interest in it being Jeff's issue :).

pcc
-- 
Peter Carl
http://www.braverock.com/~peter

> Folks,
>
> The variable scale is initialised as "years" in the function
> periodicity(), whereas the usage for other periods is 'quarterly',
> 'monthly' etc. This causes chart.TimeSeries() to throw an error in the
>
> switch(freq$scale, ) code because that is looking for 'yearly', not
> 'years'.
>
> E.g.
>
>> x <- structure(c(0.000452526685891801, 0.000807277725566065,
>> -0.00263743291162857,
> 0.00565791169977606, 0.000493819538511648, 0.000231269431065556,
> 0.00255725013533005, -0.000576682024023798, 0.00890528425766388,
> 0.00172948824027563, 0.00586017066434493, 0.00033513487703795,
> 0.00281930488908796, -0.00400888331693709, -0.00336887385144884,
> -0.000525136255385699, -0.0064468192138384, 0.0064614590751907,
> -0.00111345878301972), .indexCLASS = c("POSIXt", "POSIXct"), .indexTZ =
> "", .CLASS = "xts", na.action = structure(c(736L,
> 1082L), class = "omit", index = c(1261699200, 1303772400)), index =
> structure(c(1176073200,
> 1178492400, 1188169200, 1198627200, 1206316800, 1209942000, 1219618800,
> 1230249600, 1239577200, 1241391600, 1251673200, 1261958400, 1270422000,
> 1272841200, 1283122800, 1293408000, 1293494400, 1294012800, 1303686000
> ), tzone = "", tclass = c("POSIXt", "POSIXct")), .Dim = c(19L,
> 1L), .Dimnames = list(NULL, "AHA"), class = c("xts", "zoo"))
>
>> chart.TimeSeries(x)
> Error in if (format == "") { : argument is of length zero
>
>> periodicity(x)$scale
> [1] "years"
>
> Is this a bug in periodicity()?
>
> I am using PerformanceAnalytics 1.0.3.2 and R 2.11.1
>
> Thanks,
> Murali
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>


From jeffrey.ryan at lemnica.com  Tue Apr 26 17:37:05 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Tue, 26 Apr 2011 10:37:05 -0500
Subject: [R-SIG-Finance] PerformanceAnalytics: periodicity() function
In-Reply-To: <f30d7868d493654e21d36e90d6178310.squirrel@mail.braverock.com>
References: <05C1ABBB41112A4DB61380AD45F18EB61A240673E3@SWVLONCUEXDP01.im.root-domain.net>
	<f30d7868d493654e21d36e90d6178310.squirrel@mail.braverock.com>
Message-ID: <BANLkTikr1VSfoaUfMWcSU6oBJXh9vSz=Lw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110426/bed65923/attachment.pl>

From algotr8der at gmail.com  Tue Apr 26 20:11:43 2011
From: algotr8der at gmail.com (algotr8der)
Date: Tue, 26 Apr 2011 11:11:43 -0700 (PDT)
Subject: [R-SIG-Finance] cointegration using Johansen for VAR
In-Reply-To: <B89F0CE41D45644A97CCC93DF548C1C3285775EA@GBHENXMB02.corp.amvescap.net>
References: <1303785013626-3474574.post@n4.nabble.com>
	<B89F0CE41D45644A97CCC93DF548C1C3285775EA@GBHENXMB02.corp.amvescap.net>
Message-ID: <1303841503820-3476132.post@n4.nabble.com>

Hi Dr. Bernhard,

Thank you for the clarification on the lag terms. I will use your advice in
building my model.

That being said, the output of ca.jo still confuses me. THe cointegration
vector should describe the long-run (in my case) equilibrium in the levels
of the variables and I guess the 'l17' suffix attached to the variables in
the output of ca.jo is confusing me. This is not explained in the
documentation. 

Eigenvectors, normalised to first column: 
(These are the cointegration relations) 

              V1.l17          V2.l17           V3.l17           V4.l17      
constant 
V1.l17     1.0000000     1.0000000     1.0000000     1.0000000   1.00000000 
V2.l17    -0.2041193    -1.1345264    -0.3982231    -0.4862289  -0.21197975 
V3.l17    -0.2584363     2.6858123    -0.8965070    -0.7727329  -0.43277884 
V4.l17    -0.5167626    -0.8169243    -0.4955091     0.5102647   0.06214863 
constant  5.2281138   -65.4213338    84.4998981    28.3856062  0.05660371 

My understanding is that the long-run equilibrium cointegration relationship
is in the levels of the variables as follows:

V1 - 0.2041193*V2 - 0.2584363*V3 - 0.5167626*V4 + 5.2281138 =  residuals 

Would this be an accurate statement? Thank you kindly for your help.



--
View this message in context: http://r.789695.n4.nabble.com/cointegration-using-Johansen-for-VAR-tp3474574p3476132.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From Bernhard_Pfaff at fra.invesco.com  Tue Apr 26 20:27:19 2011
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Tue, 26 Apr 2011 19:27:19 +0100
Subject: [R-SIG-Finance] cointegration using Johansen for VAR
In-Reply-To: <1303841503820-3476132.post@n4.nabble.com>
References: <1303785013626-3474574.post@n4.nabble.com><B89F0CE41D45644A97CCC93DF548C1C3285775EA@GBHENXMB02.corp.amvescap.net>
	<1303841503820-3476132.post@n4.nabble.com>
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C3285775ED@GBHENXMB02.corp.amvescap.net>

`l17` signify the seventeenth lag of a variable. Choose the other specification, and you will observe `l1`. You are confused by VECM and the Two-step Engle-Granger procedure. The available specifications of a VECM are given in ?ca.jo from the meaning of the `lfoo` could be interferred, too.

Best,
Bernhard

> -----Urspr?ngliche Nachricht-----
> Von: r-sig-finance-bounces at r-project.org 
> [mailto:r-sig-finance-bounces at r-project.org] Im Auftrag von algotr8der
> Gesendet: Dienstag, 26. April 2011 20:12
> An: r-sig-finance at r-project.org
> Betreff: Re: [R-SIG-Finance] cointegration using Johansen for VAR
> 
> Hi Dr. Bernhard,
> 
> Thank you for the clarification on the lag terms. I will use 
> your advice in building my model.
> 
> That being said, the output of ca.jo still confuses me. THe 
> cointegration vector should describe the long-run (in my 
> case) equilibrium in the levels of the variables and I guess 
> the 'l17' suffix attached to the variables in the output of 
> ca.jo is confusing me. This is not explained in the documentation. 
> 
> Eigenvectors, normalised to first column: 
> (These are the cointegration relations) 
> 
>               V1.l17          V2.l17           V3.l17         
>   V4.l17      
> constant 
> V1.l17     1.0000000     1.0000000     1.0000000     
> 1.0000000   1.00000000 
> V2.l17    -0.2041193    -1.1345264    -0.3982231    
> -0.4862289  -0.21197975 
> V3.l17    -0.2584363     2.6858123    -0.8965070    
> -0.7727329  -0.43277884 
> V4.l17    -0.5167626    -0.8169243    -0.4955091     
> 0.5102647   0.06214863 
> constant  5.2281138   -65.4213338    84.4998981    28.3856062 
>  0.05660371 
> 
> My understanding is that the long-run equilibrium 
> cointegration relationship is in the levels of the variables 
> as follows:
> 
> V1 - 0.2041193*V2 - 0.2584363*V3 - 0.5167626*V4 + 5.2281138 = 
>  residuals 
> 
> Would this be an accurate statement? Thank you kindly for your help.
> 
> 
> 
> --
> View this message in context: 
> http://r.789695.n4.nabble.com/cointegration-using-Johansen-for
> -VAR-tp3474574p3476132.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R 
> questions should go.
> 
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:10}}


From alsguimaraes at gmail.com  Wed Apr 27 00:17:39 2011
From: alsguimaraes at gmail.com (Andre Guimaraes)
Date: Tue, 26 Apr 2011 19:17:39 -0300
Subject: [R-SIG-Finance] logistic regression:weights and unbalanced samples
Message-ID: <BANLkTinKwxdqroKV1YvaJoGp9vm4QoxdRw@mail.gmail.com>

Greetings from Rio de Janeiro, Brazil.

I am looking for advice / references on binary logistic regression
with weighted least squares (using lrm & weights), on the following
context:

1) unbalanced sample (n0=10000, n1=700);
2) sampling weights used to rebalance the sample (w0=1, w1=14.29); e
3) after modelling, adjust the intercept in order to reflect the
expected % of 1?s in the population (e.g., circa 7%, as opposed to
50%).

I have identified references that deal with the last point, but no
conclusive article or book dealing with this specific use of weights
in unbalaced samples.

The area under the ROC is about 0.70, and the estimated probabilities
are close to the frequencies of 1?s in different ranges, which looks
satisfactory. Hosmer & Lemeshow?s test is not significant, as
expected.

Can someone comment on the adopted strategy, or suggest some specific
bibliography that might address the issue of weights and unbalanced
samples in logistic regression?

Thanks in advance,

Andr? Guimar?es


From garychin9 at gmail.com  Wed Apr 27 16:42:20 2011
From: garychin9 at gmail.com (Gary C)
Date: Wed, 27 Apr 2011 22:42:20 +0800
Subject: [R-SIG-Finance] Where can I download the latest RBloomberg
 package ?
In-Reply-To: <BANLkTikgutR2v8C13s_z-0f87FzfuS-Jfg@mail.gmail.com>
References: <BANLkTinMja=-tnzffBBwk3M794VNkBuq=w@mail.gmail.com>
	<BANLkTimzB0UQ7tg4sysQ6FTU53_QZ6Xgww@mail.gmail.com>
	<BANLkTi=2nLnROR3_Cd4kwwX=WoK3G-b+sA@mail.gmail.com>
	<BANLkTikgutR2v8C13s_z-0f87FzfuS-Jfg@mail.gmail.com>
Message-ID: <BANLkTinoy+q6xeyTfjrPdowr7umD7trX+A@mail.gmail.com>

Dear Ana,

I see, thankyou.
I would like to thank Robert to start the package, making connect to
Bloomberg possible.
I also want to thank for your continuous maintaining and developing of
the package .

Gary




On Tue, Apr 26, 2011 at 12:53 AM, Ana Nelson <nelson.ana at gmail.com> wrote:
> You'll need to use R 2.12 or higher to install this.
>
> On Mon, Apr 25, 2011 at 3:21 AM, Gary Chin <garychin9 at gmail.com> wrote:
>>
>> Dear Lin,
>>
>> I tried your suggestion, doesn't work neither.
>>
>> The return message said "unable to access index for repository.....".
>> (see below)
>>
>> Does it mean the package not there?
>>
>> I already tried both repos = "http://r.findata.org/" and repos =
>> "http://r.findata.org/rbloomberg/".
>>
>> thanks,
>>
>> Gary
>>
>>
>> Here is the output.
>>
>> >install.packages("RBloomberg",repos="http://r.findata.org/rbloomberg/")
>>
>> Warning in install.packages("RBloomberg", repos =
>> "http://r.findata.org/rbloomberg/") :
>> ?argument 'lib' is missing: using
>> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>> Warning: unable to access index for repository
>> http://r.findata.org/rbloomberg/bin/windows/contrib/2.11
>> Warning message:
>> In getDependencies(pkgs, dependencies, available, lib) :
>> ?package 'RBloomberg' is not available
>>
>>
>>
>> On Mon, Apr 25, 2011 at 5:14 AM, Gei Lin <gmonaie at gmail.com> wrote:
>> > I think here:
>> >
>> > http://findata.org/rbloomberg/
>> >
>> > On Sun, Apr 24, 2011 at 1:49 PM, Gary Chin <garychin9 at gmail.com> wrote:
>> >>
>> >> Hi there,
>> >>
>> >> I am now using RBloomberg package 0.1 version which I download from
>> >> CRAN, the latest version at CRAN.
>> >>
>> >> As I know, the latest version is 0.4. I have tried to install it from
>> >> repository that I know, but all failed with following message.
>> >>
>> >> Am I missing something ? Can anyone give me a clue?
>> >>
>> >> Thanks
>> >>
>> >> Gary
>> >>
>> >>
>> >> > install.packages("RBloomberg", repos="r.findata.org")
>> >>
>> >> Warning in install.packages("RBloomberg", repos = "r.findata.org") :
>> >> ?argument 'lib' is missing: using
>> >> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>> >> Warning: unable to access index for repository
>> >> r.findata.org/bin/windows/contrib/2.11
>> >> Warning message:
>> >> In getDependencies(pkgs, dependencies, available, lib) :
>> >> ?package 'RBloomberg' is not available
>> >>
>> >>
>> >> > install.packages("RBloomberg", repos="http://R-Forge.R-project.org")
>> >>
>> >> Warning in install.packages("RBloomberg", repos =
>> >> "http://R-Forge.R-project.org") :
>> >> ?argument 'lib' is missing: using
>> >> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>> >> Warning: unable to access index for repository
>> >> http://R-Forge.R-project.org/bin/windows/contrib/2.11
>> >> Warning message:
>> >> In getDependencies(pkgs, dependencies, available, lib) :
>> >> ?package 'RBloomberg' is not available
>> >>
>> >>
>> >> > install.packages("RBloomberg", repos="http://r.bloombergapi.com")
>> >>
>> >> Warning in install.packages("RBloomberg", repos =
>> >> "http://r.bloombergapi.com") :
>> >> ?argument 'lib' is missing: using
>> >> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>> >> Error in read.dcf(file = tmpf) : Line starting '<html> ...' is
>> >> malformed!
>> >>
>> >> _______________________________________________
>> >> R-SIG-Finance at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >> -- Subscriber-posting only. If you want to post, subscribe first.
>> >> -- Also note that this is not the r-help list where general R questions
>> >> should go.
>> >
>> >
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>


From sunduck at gmail.com  Wed Apr 27 17:01:16 2011
From: sunduck at gmail.com (Alex Bird)
Date: Wed, 27 Apr 2011 19:01:16 +0400
Subject: [R-SIG-Finance] Dynamic asset allocation among hedge fund's
	strategies
Message-ID: <BANLkTindoTpCC+ozUwYgGPkBmg+GnAOuSg@mail.gmail.com>

Hi there,

  I am trying to solve a dynamic asset allocation problem among some
hedge fund?s strategies (managed futures, gamma scalping, etc.) For
these purposes I decided to use (after a lot of experiments with
alternative models) MCMC techniques to fit a model similar to a
multivariate stochastic volatility with some minor changes (like
seasonality, regimes, periods of strategy inactivity, etc.) and then
to use n-days ahead forecasted return distributions produced with the
model to decide how much to allocate to a specific strategy via CARA
approximated by Taylor (to account for 1st 4 moments).  Rebalancing
occurs several times per months.

  Now I would like to compare the model with some alternatives I
missed during the experimentation phase. Markowitz mean-variance and
its modifications are of zero interest because of their low
performance compared to the model mentioned above. Could anyone please
give me maybe some advice on where the pitfalls could be or suggest a
good alternative to play around with.

Many thanks in advance!
Alex


From garychin9 at gmail.com  Wed Apr 27 21:18:05 2011
From: garychin9 at gmail.com (Gary C)
Date: Thu, 28 Apr 2011 03:18:05 +0800
Subject: [R-SIG-Finance] Where can I download the latest RBloomberg
 package ?
In-Reply-To: <BANLkTinoy+q6xeyTfjrPdowr7umD7trX+A@mail.gmail.com>
References: <BANLkTinMja=-tnzffBBwk3M794VNkBuq=w@mail.gmail.com>
	<BANLkTimzB0UQ7tg4sysQ6FTU53_QZ6Xgww@mail.gmail.com>
	<BANLkTi=2nLnROR3_Cd4kwwX=WoK3G-b+sA@mail.gmail.com>
	<BANLkTikgutR2v8C13s_z-0f87FzfuS-Jfg@mail.gmail.com>
	<BANLkTinoy+q6xeyTfjrPdowr7umD7trX+A@mail.gmail.com>
Message-ID: <BANLkTinSENxmw9VSuqqhS0qL3NjkK0=QGw@mail.gmail.com>

Dear Ana,

I had updated my R to the latest version as you suggested.

But it is still not working, error message below.

Gary

>  install.packages("RBloomberg",repos="http://r.findata.org/")
Installing package(s) into ?F:/PortableApps/R-Portable/Data/library?
(as ?lib? is unspecified)
Warning: unable to access index for repository
http://r.findata.org/bin/windows/contrib/2.13
Warning message:
In getDependencies(pkgs, dependencies, available, lib) :
  package ?RBloomberg? is not available (for R version 2.13.0)




On Wed, Apr 27, 2011 at 10:42 PM, Gary C <garychin9 at gmail.com> wrote:
> Dear Ana,
>
> I see, thankyou.
> I would like to thank Robert to start the package, making connect to
> Bloomberg possible.
> I also want to thank for your continuous maintaining and developing of
> the package .
>
> Gary
>
>
>
>
> On Tue, Apr 26, 2011 at 12:53 AM, Ana Nelson <nelson.ana at gmail.com> wrote:
>> You'll need to use R 2.12 or higher to install this.
>>
>> On Mon, Apr 25, 2011 at 3:21 AM, Gary Chin <garychin9 at gmail.com> wrote:
>>>
>>> Dear Lin,
>>>
>>> I tried your suggestion, doesn't work neither.
>>>
>>> The return message said "unable to access index for repository.....".
>>> (see below)
>>>
>>> Does it mean the package not there?
>>>
>>> I already tried both repos = "http://r.findata.org/" and repos =
>>> "http://r.findata.org/rbloomberg/".
>>>
>>> thanks,
>>>
>>> Gary
>>>
>>>
>>> Here is the output.
>>>
>>> >install.packages("RBloomberg",repos="http://r.findata.org/rbloomberg/")
>>>
>>> Warning in install.packages("RBloomberg", repos =
>>> "http://r.findata.org/rbloomberg/") :
>>> ?argument 'lib' is missing: using
>>> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>>> Warning: unable to access index for repository
>>> http://r.findata.org/rbloomberg/bin/windows/contrib/2.11
>>> Warning message:
>>> In getDependencies(pkgs, dependencies, available, lib) :
>>> ?package 'RBloomberg' is not available
>>>
>>>
>>>
>>> On Mon, Apr 25, 2011 at 5:14 AM, Gei Lin <gmonaie at gmail.com> wrote:
>>> > I think here:
>>> >
>>> > http://findata.org/rbloomberg/
>>> >
>>> > On Sun, Apr 24, 2011 at 1:49 PM, Gary Chin <garychin9 at gmail.com> wrote:
>>> >>
>>> >> Hi there,
>>> >>
>>> >> I am now using RBloomberg package 0.1 version which I download from
>>> >> CRAN, the latest version at CRAN.
>>> >>
>>> >> As I know, the latest version is 0.4. I have tried to install it from
>>> >> repository that I know, but all failed with following message.
>>> >>
>>> >> Am I missing something ? Can anyone give me a clue?
>>> >>
>>> >> Thanks
>>> >>
>>> >> Gary
>>> >>
>>> >>
>>> >> > install.packages("RBloomberg", repos="r.findata.org")
>>> >>
>>> >> Warning in install.packages("RBloomberg", repos = "r.findata.org") :
>>> >> ?argument 'lib' is missing: using
>>> >> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>>> >> Warning: unable to access index for repository
>>> >> r.findata.org/bin/windows/contrib/2.11
>>> >> Warning message:
>>> >> In getDependencies(pkgs, dependencies, available, lib) :
>>> >> ?package 'RBloomberg' is not available
>>> >>
>>> >>
>>> >> > install.packages("RBloomberg", repos="http://R-Forge.R-project.org")
>>> >>
>>> >> Warning in install.packages("RBloomberg", repos =
>>> >> "http://R-Forge.R-project.org") :
>>> >> ?argument 'lib' is missing: using
>>> >> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>>> >> Warning: unable to access index for repository
>>> >> http://R-Forge.R-project.org/bin/windows/contrib/2.11
>>> >> Warning message:
>>> >> In getDependencies(pkgs, dependencies, available, lib) :
>>> >> ?package 'RBloomberg' is not available
>>> >>
>>> >>
>>> >> > install.packages("RBloomberg", repos="http://r.bloombergapi.com")
>>> >>
>>> >> Warning in install.packages("RBloomberg", repos =
>>> >> "http://r.bloombergapi.com") :
>>> >> ?argument 'lib' is missing: using
>>> >> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>>> >> Error in read.dcf(file = tmpf) : Line starting '<html> ...' is
>>> >> malformed!
>>> >>
>>> >> _______________________________________________
>>> >> R-SIG-Finance at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> >> -- Subscriber-posting only. If you want to post, subscribe first.
>>> >> -- Also note that this is not the r-help list where general R questions
>>> >> should go.
>>> >
>>> >
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>
>>
>


From nelson.ana at gmail.com  Wed Apr 27 23:05:12 2011
From: nelson.ana at gmail.com (Ana Nelson)
Date: Wed, 27 Apr 2011 16:05:12 -0500
Subject: [R-SIG-Finance] Where can I download the latest RBloomberg
 package ?
In-Reply-To: <BANLkTinSENxmw9VSuqqhS0qL3NjkK0=QGw@mail.gmail.com>
References: <BANLkTinMja=-tnzffBBwk3M794VNkBuq=w@mail.gmail.com>
	<BANLkTimzB0UQ7tg4sysQ6FTU53_QZ6Xgww@mail.gmail.com>
	<BANLkTi=2nLnROR3_Cd4kwwX=WoK3G-b+sA@mail.gmail.com>
	<BANLkTikgutR2v8C13s_z-0f87FzfuS-Jfg@mail.gmail.com>
	<BANLkTinoy+q6xeyTfjrPdowr7umD7trX+A@mail.gmail.com>
	<BANLkTinSENxmw9VSuqqhS0qL3NjkK0=QGw@mail.gmail.com>
Message-ID: <BANLkTinGai0rzTa4COuinKbmLTRZiumJPQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110427/4bcaaa5f/attachment.pl>

From costas.vorlow at gmail.com  Thu Apr 28 09:22:53 2011
From: costas.vorlow at gmail.com (Costas Vorlow)
Date: Thu, 28 Apr 2011 10:22:53 +0300
Subject: [R-SIG-Finance] Quantmod ChartThemes
Message-ID: <BANLkTimKohc9jCM0GEp0DDVjX1gyQtdqUw@mail.gmail.com>

I am having trouble with selecting themes in quantmod

getSymbols("GS")
 chartSeries(GS, theme=chartTheme('white.mono'),type="line")

How many themes (predefined) exist?

Best,
Costas


From rhelpacc at gmail.com  Fri Apr 29 02:02:11 2011
From: rhelpacc at gmail.com (Robert A'gata)
Date: Thu, 28 Apr 2011 20:02:11 -0400
Subject: [R-SIG-Finance] Handling of irregular time series in lineChart
Message-ID: <BANLkTin3rnFPjHA5yy_nRi8fEANAUiPhBA@mail.gmail.com>

Hi,

I realized that when I have irregular series to feed into lineChart,
the interval of each point in the chart does not seem to take care of
irregular time interval I specified in my input xts time series. But
rather, lineChart seems to take each point as equal spaced time
series. For example, I have the following code:

library(quantmod)
options(digits.sec=3)

t0 <- as.POSIXct("2010-04-20 09:30:00.000");
tvec1 <- runif(1000,0,1000);
tvec1 <- sort(tvec1);
tvec1 <- t0+tvec1;

t0 <- as.POSIXct("2010-04-20 12:30:00.000");
tvec2 <- runif(1000,0,1000);
tvec2 <- sort(tvec2);
tvec2 <- t0+tvec2;

tvec <- c(tvec1,tvec2);
data <- cumsum(rnorm(length(tvec)));

tseries <- xts(data,tvec);

lineChart(tseries);

There are two clusters of data points around 9:30AM and 12:30PM.
However, when lineChart displays result, it is quite clear that all
points are set to be equally spaced in time. I'm wondering if I
miss-specified any parameters or not. Any advice would be much
appreciated. Thank you in advance.

Robert


From brian at braverock.com  Fri Apr 29 06:17:19 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 28 Apr 2011 23:17:19 -0500
Subject: [R-SIG-Finance] Handling of irregular time series in lineChart
In-Reply-To: <BANLkTin3rnFPjHA5yy_nRi8fEANAUiPhBA@mail.gmail.com>
References: <BANLkTin3rnFPjHA5yy_nRi8fEANAUiPhBA@mail.gmail.com>
Message-ID: <1304050639.6868.10.camel@brian-desktop>

chartSeries and its cousins plot each period as one observation.  all
observations have equal time.  It 'takes care of' irregular data by
assuming that the rate of information is equal to the number of
observations, which is a perfectly correct intuition and useful for many
things.  If you want instead to force a regular series, then you may do
that instead.

You could create bars, or use a different plotting mechanism.

Often, I will create regular bars (1 minute or even 1 second is
sufficient) from the raw price data, and then use some addTA
overplotting to plot items of interest.

Regards,

   - Brian


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

On Thu, 2011-04-28 at 20:02 -0400, Robert A'gata wrote:
> Hi,
> 
> I realized that when I have irregular series to feed into lineChart,
> the interval of each point in the chart does not seem to take care of
> irregular time interval I specified in my input xts time series. But
> rather, lineChart seems to take each point as equal spaced time
> series. For example, I have the following code:
> 
> library(quantmod)
> options(digits.sec=3)
> 
> t0 <- as.POSIXct("2010-04-20 09:30:00.000");
> tvec1 <- runif(1000,0,1000);
> tvec1 <- sort(tvec1);
> tvec1 <- t0+tvec1;
> 
> t0 <- as.POSIXct("2010-04-20 12:30:00.000");
> tvec2 <- runif(1000,0,1000);
> tvec2 <- sort(tvec2);
> tvec2 <- t0+tvec2;
> 
> tvec <- c(tvec1,tvec2);
> data <- cumsum(rnorm(length(tvec)));
> 
> tseries <- xts(data,tvec);
> 
> lineChart(tseries);
> 
> There are two clusters of data points around 9:30AM and 12:30PM.
> However, when lineChart displays result, it is quite clear that all
> points are set to be equally spaced in time. I'm wondering if I
> miss-specified any parameters or not. Any advice would be much
> appreciated. Thank you in advance.
> 
> Robert


From johannes.lips at googlemail.com  Fri Apr 29 14:33:08 2011
From: johannes.lips at googlemail.com (Johannes Lips)
Date: Fri, 29 Apr 2011 14:33:08 +0200
Subject: [R-SIG-Finance] Daily Natural Gas Price Data for Europe?
Message-ID: <BANLkTi=_L4NWHVrL+_sB_cUZywCJvTyjGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110429/9b1dfe6f/attachment.pl>

From rhelpacc at gmail.com  Sat Apr 30 03:00:22 2011
From: rhelpacc at gmail.com (Robert A'gata)
Date: Fri, 29 Apr 2011 21:00:22 -0400
Subject: [R-SIG-Finance] How to add data to secondary axis in chartSeries
Message-ID: <BANLkTin_7iQFRbw3sUSV5AOFGOk+W8uGiA@mail.gmail.com>

Hi,

I'm wondering if it is possible to add data to secondary axis in the
main panel in chartSeries. For example, I have a signal that is
correlated with the price but of different scale. I'm wondering if
there's any possibility at all? And how to do it?

Secondly, I'm wondering how to delete the "Last" legend that shows up
in the main panel? Thank you.

Bests,

Robert


From rhelpacc at gmail.com  Sat Apr 30 05:26:38 2011
From: rhelpacc at gmail.com (Robert A'gata)
Date: Fri, 29 Apr 2011 23:26:38 -0400
Subject: [R-SIG-Finance] Computation on xts
Message-ID: <BANLkTi=9QPK6kxpvKTsU8-u+cN-Q5Dmf8g@mail.gmail.com>

Hi,

I have the following time series in xts

> getSymbols("SBUX");
[1] "SBUX"
Warning message:
In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
  downloaded length 53650 != reported length 200

Then I tried to compute something row-wise. In my below example, I
simple compute daily notional using close price. I want to add the
result back as a new column in my existing time series. But it doesn't
seem to work. I'm not sure if I have missed anything. Thank you.

>SBUX[,"TurnOver"] <- SBUX[,"SBUX.Close"]*SBUX[,"SBUX.Volume"]
Error in NextMethod(.Generic) : subscript out of bounds

Cheers,

Robert


From brian at braverock.com  Sat Apr 30 06:26:57 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 29 Apr 2011 23:26:57 -0500
Subject: [R-SIG-Finance] How to add data to secondary axis in chartSeries
In-Reply-To: <BANLkTin_7iQFRbw3sUSV5AOFGOk+W8uGiA@mail.gmail.com>
References: <BANLkTin_7iQFRbw3sUSV5AOFGOk+W8uGiA@mail.gmail.com>
Message-ID: <1304137617.6868.25.camel@brian-desktop>

chart_Series can do this, but not the older chartSeries.


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

On Fri, 2011-04-29 at 21:00 -0400, Robert A'gata wrote:
> Hi,
> 
> I'm wondering if it is possible to add data to secondary axis in the
> main panel in chartSeries. For example, I have a signal that is
> correlated with the price but of different scale. I'm wondering if
> there's any possibility at all? And how to do it?
> 
> Secondly, I'm wondering how to delete the "Last" legend that shows up
> in the main panel? Thank you.
> 
> Bests,
> 
> Robert


From me at censix.com  Sat Apr 30 07:39:48 2011
From: me at censix.com (me at censix.com)
Date: Sat, 30 Apr 2011 07:39:48 +0200
Subject: [R-SIG-Finance] Computation on xts
In-Reply-To: <BANLkTi=9QPK6kxpvKTsU8-u+cN-Q5Dmf8g@mail.gmail.com>
References: <BANLkTi=9QPK6kxpvKTsU8-u+cN-Q5Dmf8g@mail.gmail.com>
Message-ID: <54885.78.234.67.201.1304141988.squirrel@censix.com>


> Hi,
>
> I have the following time series in xts
>
>> getSymbols("SBUX");
> [1] "SBUX"
> Warning message:
> In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
>   downloaded length 53650 != reported length 200
>
> Then I tried to compute something row-wise. In my below example, I
> simple compute daily notional using close price. I want to add the
> result back as a new column in my existing time series. But it doesn't
> seem to work. I'm not sure if I have missed anything. Thank you.
>
>>SBUX[,"TurnOver"] <- SBUX[,"SBUX.Close"]*SBUX[,"SBUX.Volume"]
> Error in NextMethod(.Generic) : subscript out of bounds
>
> Cheers,
>
> Robert
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

Hi,

I guess one way to do it would be

   SBUX <-cbind(SBUX, SBUX[,"SBUX.Close"]*SBUX[,"SBUX.Volume"])

and then you can rename the new column using colnames

   colnames(SBUX) <- c("SBUX.Open" , "SBUX.High"  ,   "SBUX.Low" ,  
"SBUX.Close" , "SBUX.Volume" ,  "SBUX.Adjusted", "TurnOver" )


Cheers

Soren

-- 
http://censix.com


From matmsh at yahoo.com  Sat Apr 30 14:45:44 2011
From: matmsh at yahoo.com (Shing Hing Man)
Date: Sat, 30 Apr 2011 05:45:44 -0700
Subject: [R-SIG-Finance] fExoticOptions -  CashOrNothingOption discrepancy
Message-ID: <174992.26596.qm@web130208.mail.mud.yahoo.com>

Hi,
   I am using CashOrOrNothingOption in fExoticOptions to verify 
Example 2.11.2 in the book
  The complete guide to option pricing formulas (first edition) , by Espen Haug

  > CashOrNothingOption(TypeFlag = "p",  S=100,  X=80, Time=0.75, K=10, r = 0.06,b = 0, sigma = 0.35)@price
[1] 2.215541


In the book, the answer is 2.6710. 
However, if I changed b to -0.06, I have the answer matching the one in the book.
> CashOrNothingOption(TypeFlag = "p",  S=100,  X=80, Time=0.75, K=10, r = 0.06,b = -0.06, sigma = 0.35)@price
[1] 2.671045

Is this is a bug or I have misunderstood the b ?

Thanks in advance for any assistance !

Shing 



From costas.vorlow at gmail.com  Sat Apr 30 20:48:12 2011
From: costas.vorlow at gmail.com (Costas Vorlow)
Date: Sat, 30 Apr 2011 21:48:12 +0300
Subject: [R-SIG-Finance] FRED prob
Message-ID: <BANLkTimWWT+ixTR3Bu1pH_mPcD92LyT4vw@mail.gmail.com>

I have a problem with getting data from fRED under windows with getSymbols.
Any clues?

Thanks in advance,
Costas

> version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          13.0
year           2011
month          04
day            13
svn rev        55427
language       R
version.string R version 2.13.0 (2011-04-13)
>
>
> getSymbols("GS10",src="FRED") #load US Treasury 10y from Fed Fred
Error in as.POSIXlt.character(x, tz, ...) :
  character string is not in a standard unambiguous format
>
>
>


From josh.m.ulrich at gmail.com  Sat Apr 30 20:53:02 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 30 Apr 2011 13:53:02 -0500
Subject: [R-SIG-Finance] Computation on xts
In-Reply-To: <54885.78.234.67.201.1304141988.squirrel@censix.com>
References: <BANLkTi=9QPK6kxpvKTsU8-u+cN-Q5Dmf8g@mail.gmail.com>
	<54885.78.234.67.201.1304141988.squirrel@censix.com>
Message-ID: <BANLkTikzBsh4B-WtgOD+W_JpAQtFa7_oWQ@mail.gmail.com>

Hi Robert,

On Sat, Apr 30, 2011 at 12:39 AM,  <me at censix.com> wrote:
>
>> Hi,
>>
>> I have the following time series in xts
>>
>>> getSymbols("SBUX");
>> [1] "SBUX"
>> Warning message:
>> In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m, ?:
>> ? downloaded length 53650 != reported length 200
>>
>> Then I tried to compute something row-wise. In my below example, I
>> simple compute daily notional using close price. I want to add the
>> result back as a new column in my existing time series. But it doesn't
>> seem to work. I'm not sure if I have missed anything. Thank you.
>>
>>>SBUX[,"TurnOver"] <- SBUX[,"SBUX.Close"]*SBUX[,"SBUX.Volume"]
>> Error in NextMethod(.Generic) : subscript out of bounds
>>
>> Cheers,
>>
>> Robert
>>
>>
>
> Hi,
>
> I guess one way to do it would be
>
> ? SBUX <-cbind(SBUX, SBUX[,"SBUX.Close"]*SBUX[,"SBUX.Volume"])
>
> and then you can rename the new column using colnames
>
> ? colnames(SBUX) <- c("SBUX.Open" , "SBUX.High" ?, ? "SBUX.Low" ,
> "SBUX.Close" , "SBUX.Volume" , ?"SBUX.Adjusted", "TurnOver" )
>
>
> Cheers
>
> Soren
>
> --
> http://censix.com
>

Another way is via the `$<-` operator:

SBUX$TurnOver <- SBUX[,"SBUX.Close"]*SBUX[,"SBUX.Volume"]

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From pzulfugarli at gmail.com  Sat Apr 30 21:29:24 2011
From: pzulfugarli at gmail.com (Pasha Zulfuqali)
Date: Sat, 30 Apr 2011 20:29:24 +0100
Subject: [R-SIG-Finance] How to calculate coskewness or coskewness matrix
Message-ID: <BANLkTini8ed5UaHBgsFWNtuR-7kTkcJXGw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110430/cd205f2e/attachment.pl>

From brian at braverock.com  Sat Apr 30 22:45:22 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 30 Apr 2011 15:45:22 -0500
Subject: [R-SIG-Finance] How to calculate coskewness or coskewness matrix
In-Reply-To: <BANLkTini8ed5UaHBgsFWNtuR-7kTkcJXGw@mail.gmail.com>
References: <BANLkTini8ed5UaHBgsFWNtuR-7kTkcJXGw@mail.gmail.com>
Message-ID: <7a47f41a-9436-4fe0-8701-64323b4dee24@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110430/bc935497/attachment.pl>

From arun.kumar.saha at gmail.com  Sun May  1 15:10:31 2011
From: arun.kumar.saha at gmail.com (Arun.stat)
Date: Sun, 1 May 2011 06:10:31 -0700 (PDT)
Subject: [R-SIG-Finance] FRED prob
In-Reply-To: <BANLkTimWWT+ixTR3Bu1pH_mPcD92LyT4vw@mail.gmail.com>
References: <BANLkTimWWT+ixTR3Bu1pH_mPcD92LyT4vw@mail.gmail.com>
Message-ID: <1304255431359-3487735.post@n4.nabble.com>

Hi Costas, it is working fine in my system. May be you should try with the
latest version?


> library(quantmod)
Loading required package: Defaults
Loading required package: xts
Loading required package: zoo
Loading required package: TTR
> getSymbols("GS10",src="FRED")
[1] "GS10"
> sessionInfo()
R version 2.13.0 (2011-04-13)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252   
LC_MONETARY=English_India.1252 LC_NUMERIC=C                  
[5] LC_TIME=English_India.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] quantmod_0.3-16 TTR_0.20-3      xts_0.8-0       zoo_1.6-5      
Defaults_1.1-1 

loaded via a namespace (and not attached):
[1] grid_2.13.0     lattice_0.19-23

Thanks and regards,
_____________________________________________________

Arun Kumar Saha, FRM
QUANTITATIVE RISK AND HEDGE CONSULTING SPECIALIST
Visit me at: http://in.linkedin.com/in/ArunFRM
_____________________________________________________--
View this message in context: http://r.789695.n4.nabble.com/FRED-prob-tp3486372p3487735.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From daniel319 at gmail.com  Sun May  1 16:06:55 2011
From: daniel319 at gmail.com (daniel)
Date: Sun, 1 May 2011 11:06:55 -0300
Subject: [R-SIG-Finance] FRED prob
In-Reply-To: <1304255431359-3487735.post@n4.nabble.com>
References: <BANLkTimWWT+ixTR3Bu1pH_mPcD92LyT4vw@mail.gmail.com>
	<1304255431359-3487735.post@n4.nabble.com>
Message-ID: <BANLkTi=rPeTMCPVUm29uLZE=HJJMvX+E4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110501/ead745da/attachment.pl>

From algotr8der at gmail.com  Mon May  2 04:10:17 2011
From: algotr8der at gmail.com (algotr8der)
Date: Sun, 1 May 2011 19:10:17 -0700 (PDT)
Subject: [R-SIG-Finance] Strategy performance summary report
In-Reply-To: <4D1B6B27.4050606@braverock.com>
References: <AANLkTimMpau4cDNhit6rtRhY6HGk3wQC5mPwx968Onrw@mail.gmail.com>
	<4D1B6B27.4050606@braverock.com>
Message-ID: <1304302217386-3489164.post@n4.nabble.com>

Hello everyone.

I have been searching for documentation for the blotter package and I am
confused as to what is the official documentation. I have version 193 of
blotter installed and there are no user guides or package vignettes
associated with the install.

I too am looking for ways to extract trade statistics.

So - my questions are:

1) Can someone please point me to the official documentation for blotter

2) Are functions such as table.TradeStats.R and the likes implemented in new
versions of blotter.

Thank you very kindly.


--
View this message in context: http://r.789695.n4.nabble.com/Strategy-performance-summary-report-tp3166698p3489164.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From daniel.cegielka at gmail.com  Mon May  2 11:15:20 2011
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Mon, 2 May 2011 11:15:20 +0200
Subject: [R-SIG-Finance] Strategy performance summary report
In-Reply-To: <1304302217386-3489164.post@n4.nabble.com>
References: <AANLkTimMpau4cDNhit6rtRhY6HGk3wQC5mPwx968Onrw@mail.gmail.com>
	<4D1B6B27.4050606@braverock.com>
	<1304302217386-3489164.post@n4.nabble.com>
Message-ID: <BANLkTimDGtCSUB3GC7CmONk7YW04pJG7VQ@mail.gmail.com>

Hi algotr8der,

As you can see on r-forge, Blotter has alpha development status. This
project isn't finished and there is no the final version. Be
forgiving, please.. or help to develop this package.

The latest documentation can be found at this link:

https://r-forge.r-project.org/scm/viewvc.php/pkg/blotter/man/?root=blotter

The _main_ purpose of Blotter is the PnL - it's neither backtesting
nor portfolio analysis tool. If you are interested in analysis and
statistics of the portfolio (or strategy) rather see the
PerformanceAnalytics package.

Here you have a stable version of the documentation and examples:

http://cran.r-project.org/web/packages/PerformanceAnalytics/index.html

Development version:

https://r-forge.r-project.org/projects/returnanalytics/

Best regards,
daniel



2011/5/2 algotr8der <algotr8der at gmail.com>:
> Hello everyone.
>
> I have been searching for documentation for the blotter package and I am
> confused as to what is the official documentation. I have version 193 of
> blotter installed and there are no user guides or package vignettes
> associated with the install.
>
> I too am looking for ways to extract trade statistics.
>
> So - my questions are:
>
> 1) Can someone please point me to the official documentation for blotter
>
> 2) Are functions such as table.TradeStats.R and the likes implemented in new
> versions of blotter.
>
> Thank you very kindly.
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Strategy-performance-summary-report-tp3166698p3489164.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From brian at braverock.com  Mon May  2 13:25:04 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 02 May 2011 06:25:04 -0500
Subject: [R-SIG-Finance] Strategy performance summary report
In-Reply-To: <1304302217386-3489164.post@n4.nabble.com>
References: <AANLkTimMpau4cDNhit6rtRhY6HGk3wQC5mPwx968Onrw@mail.gmail.com>
	<4D1B6B27.4050606@braverock.com>
	<1304302217386-3489164.post@n4.nabble.com>
Message-ID: <1304335504.6868.67.camel@brian-desktop>

On Sun, 2011-05-01 at 19:10 -0700, algotr8der wrote:
> I have been searching for documentation for the blotter package and I am
> confused as to what is the official documentation. I have version 193 of
> blotter installed and there are no user guides or package vignettes
> associated with the install.
> 
> I too am looking for ways to extract trade statistics.
> 
> So - my questions are:
> 
> 1) Can someone please point me to the official documentation for blotter
> 
> 2) Are functions such as table.TradeStats.R and the likes implemented in new
> versions of blotter.
> 
> Thank you very kindly.

Daniel's response is close to the mark.

Obviously, the documentation for any R package is included with the
installation of the package, and is available from within R with help(),
'?', '??' and help.search().

R-Forge, however, does not generate PDF versions of the manual for you.
You would need to do that yourself using 'R CMD check' or similar. As
I've said before on this list, this may be done easily on *nix and Mac
systems, and with Duncan's Rtools for Windows.

http://www.murdoch-sutherland.com/Rtools/

Anyone who wants to use development packages in Windows should be able
to build those packages from source.

SVN r193 of blotter is *very* old (2010-01-21).  The current SVN commit
is r596.  Since r512(2010-12-30), blotter has have the 'tradeStats' and
related functions which I believe answer algotr8der's question number 2.
(more recent versions of blotter include better versions of these
functions).  Since r516(2010-10-10) , blotter has had function
PortfReturns(), which provides per-instrument return contribution on
account equity.  PortfReturns may be used to extract return-based
numbers for use with analysis ala PerformanceAnalytics.

As Daniel said in his reply to this thread, blotter only (and will only)
deal with P&L for a set of transactions. It knows nothing of 'strategy'.
For defining 'strategy' rules, I will refer you to the 'quantstrat'
package, also on R-Forge in the TradeAnalytics project.  quantstrat uses
blotter transparently for P&L.  I rarely call blotter by hand, except to
use chart.Posn().  I let quantstrat manage the rest of the mechanics.

As an aside: The entire TradeAnalytics set of packages (specifically
quantstrat and blotter) are listed as alpha code because they are still
under heavy development, interfaces and functions may change.  That
said, they are robust to their intended purpose, and are used on real,
large, production strategies with very high correlations between
theoretical and actual trading results.

Regards,

   - Brian


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From algotr8der at gmail.com  Mon May  2 14:59:14 2011
From: algotr8der at gmail.com (algotr8der)
Date: Mon, 2 May 2011 05:59:14 -0700 (PDT)
Subject: [R-SIG-Finance] Strategy performance summary report
In-Reply-To: <1304335504.6868.67.camel@brian-desktop>
References: <AANLkTimMpau4cDNhit6rtRhY6HGk3wQC5mPwx968Onrw@mail.gmail.com>
	<4D1B6B27.4050606@braverock.com>
	<1304302217386-3489164.post@n4.nabble.com>
	<1304335504.6868.67.camel@brian-desktop>
Message-ID: <1304341154880-3489960.post@n4.nabble.com>

Thank you Daniel and Brian for the detailed summary - it is very helpful.

I didn't mean to sound unforgiving and so if I did my sincere apologies. I
know the development team has been working very hard and I'm sure everyone
who uses blotter and related packages (myself included) are grateful for the
contribution you guys have made. I recently began using these packages and
so right now I am learning as much as I can. I hope to get involved and
contribute once I have a firmer grasp of the functionality. 




--
View this message in context: http://r.789695.n4.nabble.com/Strategy-performance-summary-report-tp3166698p3489960.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From peter at braverock.com  Mon May  2 16:28:51 2011
From: peter at braverock.com (Peter Carl)
Date: Mon, 2 May 2011 09:28:51 -0500
Subject: [R-SIG-Finance] Strategy performance summary report
In-Reply-To: <1304335504.6868.67.camel@brian-desktop>
References: <AANLkTimMpau4cDNhit6rtRhY6HGk3wQC5mPwx968Onrw@mail.gmail.com>
	<4D1B6B27.4050606@braverock.com>
	<1304302217386-3489164.post@n4.nabble.com>
	<1304335504.6868.67.camel@brian-desktop>
Message-ID: <1a6ba88f6b527c45be2ce63b5551cce3.squirrel@mail.braverock.com>

Two small additional things.  First, look at the demo directory in blotter
for code examples.  I do, however, agree with Brian's assertion that
blotter is best used indirectly through a framework like quantstrat.  You
will, however, want to analyze the results using blotter's data and
objects, and tracking through those demos might help you understand how to
do that better.

We've spent a fair amount of time improving blotter's documentation with
the aim of moving it and a companion package, FinancialInstrument, to CRAN
relatively soon.  That said, this is an area where contributions would be
much appreciated.  If you've got an example, a demo, notes that you've
kept for your own use, etc. that you think would be additive, we'd like to
know.  Tests are deeply appreciated.  Please feel free to contact either
Brian or I with ideas.

pcc
-- 
Peter Carl
http://www.braverock.com/~peter

> On Sun, 2011-05-01 at 19:10 -0700, algotr8der wrote:
>> I have been searching for documentation for the blotter package and I am
>> confused as to what is the official documentation. I have version 193 of
>> blotter installed and there are no user guides or package vignettes
>> associated with the install.
>>
>> I too am looking for ways to extract trade statistics.
>>
>> So - my questions are:
>>
>> 1) Can someone please point me to the official documentation for blotter
>>
>> 2) Are functions such as table.TradeStats.R and the likes implemented in
>> new
>> versions of blotter.
>>
>> Thank you very kindly.
>
> Daniel's response is close to the mark.
>
> Obviously, the documentation for any R package is included with the
> installation of the package, and is available from within R with help(),
> '?', '??' and help.search().
>
> R-Forge, however, does not generate PDF versions of the manual for you.
> You would need to do that yourself using 'R CMD check' or similar. As
> I've said before on this list, this may be done easily on *nix and Mac
> systems, and with Duncan's Rtools for Windows.
>
> http://www.murdoch-sutherland.com/Rtools/
>
> Anyone who wants to use development packages in Windows should be able
> to build those packages from source.
>
> SVN r193 of blotter is *very* old (2010-01-21).  The current SVN commit
> is r596.  Since r512(2010-12-30), blotter has have the 'tradeStats' and
> related functions which I believe answer algotr8der's question number 2.
> (more recent versions of blotter include better versions of these
> functions).  Since r516(2010-10-10) , blotter has had function
> PortfReturns(), which provides per-instrument return contribution on
> account equity.  PortfReturns may be used to extract return-based
> numbers for use with analysis ala PerformanceAnalytics.
>
> As Daniel said in his reply to this thread, blotter only (and will only)
> deal with P&L for a set of transactions. It knows nothing of 'strategy'.
> For defining 'strategy' rules, I will refer you to the 'quantstrat'
> package, also on R-Forge in the TradeAnalytics project.  quantstrat uses
> blotter transparently for P&L.  I rarely call blotter by hand, except to
> use chart.Posn().  I let quantstrat manage the rest of the mechanics.
>
> As an aside: The entire TradeAnalytics set of packages (specifically
> quantstrat and blotter) are listed as alpha code because they are still
> under heavy development, interfaces and functions may change.  That
> said, they are robust to their intended purpose, and are used on real,
> large, production strategies with very high correlations between
> theoretical and actual trading results.
>
> Regards,
>
>    - Brian
>
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>


From arun.kumar.saha at gmail.com  Mon May  2 16:44:15 2011
From: arun.kumar.saha at gmail.com (Arun.stat)
Date: Mon, 2 May 2011 07:44:15 -0700 (PDT)
Subject: [R-SIG-Finance] How to add data to secondary axis in chartSeries
In-Reply-To: <BANLkTin_7iQFRbw3sUSV5AOFGOk+W8uGiA@mail.gmail.com>
References: <BANLkTin_7iQFRbw3sUSV5AOFGOk+W8uGiA@mail.gmail.com>
Message-ID: <1304347455476-3490157.post@n4.nabble.com>

Hi R_help Help, think again to put a Secondary axis in you plot window. It is
completely meaningless. It seems that there are 2 Suns in the sky. Ofcourse
there are many Binary star systems in the Universe
(http://en.wikipedia.org/wiki/Binary_star), but life doesn't exist there,
right? (just due to inhospitable weather!)

You may better consider to plot your series in Logarithmic scale. Another
good possibility could be to change the base of both series to some
meaningful number, may be 100, and then plot the joint movement of your
series (on same scale).

Thanks and regards,
_____________________________________________________

Arun Kumar Saha, FRM
QUANTITATIVE RISK AND HEDGE CONSULTING SPECIALIST
Visit me at: http://in.linkedin.com/in/ArunFRM
_____________________________________________________


--
View this message in context: http://r.789695.n4.nabble.com/How-to-add-data-to-secondary-axis-in-chartSeries-tp3484927p3490157.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From bbands at gmail.com  Mon May  2 20:03:32 2011
From: bbands at gmail.com (BBands)
Date: Mon, 2 May 2011 11:03:32 -0700
Subject: [R-SIG-Finance] R/Finance 2011
Message-ID: <BANLkTimxJtGmz2TZFj3zf2hJM1-+hU=U1Q@mail.gmail.com>

Wow! Great conference. Superb in every way. Congrats to the committee!

Some of the highlights for me were:

Meeting Stephano Iacus and learning of his MOdist function for cluster analysis.

Meeting Louis Kates and listening to his talk on prototype programming.

Meeting Paul Teetor, author to"R Cookbook" and listening to his talk
on better hedge ratios.

Meeting Bryan Lewis who shares a passion for pu-erh, a kind of Chinese tea.

A long conversation I had with a New York spread trader who had some
interesting ideas about the math of Bollinger Bands.

Meeting Doug Martin, founder of S-Plus and now an R convert!

Long evenings at Haymarket and Jacks chatting with a wide range of people.

In short, this was a well organized conference that was everything an
R/Finance conference ought to be. I'd like to thank Dirk Eddelbuettel
for introducing me to the group, Jeff Ryan for being relentless in
convincing me to attend and Ralph Vince for convincing me that Jeff
was right.

See you next year,

    John
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.


From daniel.cegielka at gmail.com  Mon May  2 22:16:54 2011
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Mon, 2 May 2011 22:16:54 +0200
Subject: [R-SIG-Finance] Strategy performance summary report
In-Reply-To: <1a6ba88f6b527c45be2ce63b5551cce3.squirrel@mail.braverock.com>
References: <AANLkTimMpau4cDNhit6rtRhY6HGk3wQC5mPwx968Onrw@mail.gmail.com>
	<4D1B6B27.4050606@braverock.com>
	<1304302217386-3489164.post@n4.nabble.com>
	<1304335504.6868.67.camel@brian-desktop>
	<1a6ba88f6b527c45be2ce63b5551cce3.squirrel@mail.braverock.com>
Message-ID: <BANLkTikPXbM_4ui8CnASJBYBZmudEiyFQA@mail.gmail.com>

Peter,

Of course you right - someone can test strategies using the blotter.
When I first used the blotter, I was convinced that this is how it
should work (for backtesting). Next I thought, if I use the blotter
backtest, it can also be used for real trading. I noticed that blotter
is too slow and I started to look for ways to make it faster with a C.
But I was wrong completely and I presume that this mistake is
committing a lot of people who begin to use the blotter.

You and Brian have a great experience in finance. In my opinion
blotter is written by professionals for professionals. Beginners often
commits the same mistake that I committed - that is, believes that eg
blotter is a whole platform. But the truth is that this is only a
small part which is designed specifically for PnL (blotter). To
analyze the strategy can be used with some packages from
ReturnAnalytics - all specialized in selected uses.

This is one of the main differences between beginners and professionals.

These are my thoughts and I hope that they will be useful for all
begins to work with R and eg blotter. I also want to thank you, Brian,
Jeff and others that you share with others your experience.


btw. "Strategy summary performance report" is an interesting idea to
develop a package (?? TradeReport...) of useful templates for
generating reports (pdf) using Sweave, blotter and others R's finance
tools.

Best regards,
daniel



2011/5/2 Peter Carl <peter at braverock.com>:
> Two small additional things. ?First, look at the demo directory in blotter
> for code examples. ?I do, however, agree with Brian's assertion that
> blotter is best used indirectly through a framework like quantstrat. ?You
> will, however, want to analyze the results using blotter's data and
> objects, and tracking through those demos might help you understand how to
> do that better.
>
> We've spent a fair amount of time improving blotter's documentation with
> the aim of moving it and a companion package, FinancialInstrument, to CRAN
> relatively soon. ?That said, this is an area where contributions would be
> much appreciated. ?If you've got an example, a demo, notes that you've
> kept for your own use, etc. that you think would be additive, we'd like to
> know. ?Tests are deeply appreciated. ?Please feel free to contact either
> Brian or I with ideas.
>
> pcc
> --
> Peter Carl
> http://www.braverock.com/~peter
>
>> On Sun, 2011-05-01 at 19:10 -0700, algotr8der wrote:
>>> I have been searching for documentation for the blotter package and I am
>>> confused as to what is the official documentation. I have version 193 of
>>> blotter installed and there are no user guides or package vignettes
>>> associated with the install.
>>>
>>> I too am looking for ways to extract trade statistics.
>>>
>>> So - my questions are:
>>>
>>> 1) Can someone please point me to the official documentation for blotter
>>>
>>> 2) Are functions such as table.TradeStats.R and the likes implemented in
>>> new
>>> versions of blotter.
>>>
>>> Thank you very kindly.
>>
>> Daniel's response is close to the mark.
>>
>> Obviously, the documentation for any R package is included with the
>> installation of the package, and is available from within R with help(),
>> '?', '??' and help.search().
>>
>> R-Forge, however, does not generate PDF versions of the manual for you.
>> You would need to do that yourself using 'R CMD check' or similar. As
>> I've said before on this list, this may be done easily on *nix and Mac
>> systems, and with Duncan's Rtools for Windows.
>>
>> http://www.murdoch-sutherland.com/Rtools/
>>
>> Anyone who wants to use development packages in Windows should be able
>> to build those packages from source.
>>
>> SVN r193 of blotter is *very* old (2010-01-21). ?The current SVN commit
>> is r596. ?Since r512(2010-12-30), blotter has have the 'tradeStats' and
>> related functions which I believe answer algotr8der's question number 2.
>> (more recent versions of blotter include better versions of these
>> functions). ?Since r516(2010-10-10) , blotter has had function
>> PortfReturns(), which provides per-instrument return contribution on
>> account equity. ?PortfReturns may be used to extract return-based
>> numbers for use with analysis ala PerformanceAnalytics.
>>
>> As Daniel said in his reply to this thread, blotter only (and will only)
>> deal with P&L for a set of transactions. It knows nothing of 'strategy'.
>> For defining 'strategy' rules, I will refer you to the 'quantstrat'
>> package, also on R-Forge in the TradeAnalytics project. ?quantstrat uses
>> blotter transparently for P&L. ?I rarely call blotter by hand, except to
>> use chart.Posn(). ?I let quantstrat manage the rest of the mechanics.
>>
>> As an aside: The entire TradeAnalytics set of packages (specifically
>> quantstrat and blotter) are listed as alpha code because they are still
>> under heavy development, interfaces and functions may change. ?That
>> said, they are robust to their intended purpose, and are used on real,
>> large, production strategies with very high correlations between
>> theoretical and actual trading results.
>>
>> Regards,
>>
>> ? ?- Brian
>>
>>
>> --
>> Brian G. Peterson
>> http://braverock.com/brian/
>> Ph: 773-459-4973
>> IM: bgpbraverock
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From avneetaquarian at yahoo.com  Mon May  2 22:25:05 2011
From: avneetaquarian at yahoo.com (Avneet Singh)
Date: Mon, 2 May 2011 13:25:05 -0700
Subject: [R-SIG-Finance] R/Finance 2011
Message-ID: <761403.16638.qm@smtp115-mob.biz.mail.ac4.yahoo.com>

Are there any videos of talks available ?

Thanks
Avneet

-----Original Message-----
From: BBands
Sent: Monday, May 02, 2011 11:03 AM
To: R-sig-finance
Subject: [R-SIG-Finance] R/Finance 2011

Wow! Great conference. Superb in every way. Congrats to the committee!

Some of the highlights for me were:

Meeting Stephano Iacus and learning of his MOdist function for cluster analysis.

Meeting Louis Kates and listening to his talk on prototype programming.

Meeting Paul Teetor, author to"R Cookbook" and listening to his talk
on better hedge ratios.

Meeting Bryan Lewis who shares a passion for pu-erh, a kind of Chinese tea.

A long conversation I had with a New York spread trader who had some
interesting ideas about the math of Bollinger Bands.

Meeting Doug Martin, founder of S-Plus and now an R convert!

Long evenings at Haymarket and Jacks chatting with a wide range of people.

In short, this was a well organized conference that was everything an
R/Finance conference ought to be. I'd like to thank Dirk Eddelbuettel
for introducing me to the group, Jeff Ryan for being relentless in
convincing me to attend and Ralph Vince for convincing me that Jeff
was right.

See you next year,

    John
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


From tlaugle at gmail.com  Mon May  2 22:33:50 2011
From: tlaugle at gmail.com (Thomas Laugle)
Date: Mon, 2 May 2011 16:33:50 -0400
Subject: [R-SIG-Finance] R/Finance 2011
In-Reply-To: <761403.16638.qm@smtp115-mob.biz.mail.ac4.yahoo.com>
References: <761403.16638.qm@smtp115-mob.biz.mail.ac4.yahoo.com>
Message-ID: <BANLkTikMwqg2qpLXsYNyOcvdByNMz8C+uQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110502/4e95080b/attachment.pl>

From brian at braverock.com  Mon May  2 22:35:44 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 2 May 2011 15:35:44 -0500
Subject: [R-SIG-Finance] R/Finance 2011
In-Reply-To: <761403.16638.qm@smtp115-mob.biz.mail.ac4.yahoo.com>
References: <761403.16638.qm@smtp115-mob.biz.mail.ac4.yahoo.com>
Message-ID: <1304368544.23274.44.camel@brian-desktop>

On Mon, 2011-05-02 at 13:25 -0700, Avneet Singh wrote:
> Are there any videos of talks available ?

No.

Slides of the talks will, as in prior years, make their way (eventually)
to the http://www.RinFinance.com/ website.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From josh.m.ulrich at gmail.com  Mon May  2 22:50:39 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 2 May 2011 15:50:39 -0500
Subject: [R-SIG-Finance] R/Finance 2011
In-Reply-To: <1304368544.23274.44.camel@brian-desktop>
References: <761403.16638.qm@smtp115-mob.biz.mail.ac4.yahoo.com>
	<1304368544.23274.44.camel@brian-desktop>
Message-ID: <BANLkTinULPpx1bpsoHeLU+Edc=7FfRVnPQ@mail.gmail.com>

On Mon, May 2, 2011 at 3:35 PM, Brian G. Peterson <brian at braverock.com> wrote:
> On Mon, 2011-05-02 at 13:25 -0700, Avneet Singh wrote:
>> Are there any videos of talks available ?
>
> No.
>
Notice that most of John's "highlights" were related to interacting
with people at the conference.  While the presentations are great,
there is a ton of value from talking with other attendees and that
cannot be captured via video.

> Slides of the talks will, as in prior years, make their way (eventually)
> to the http://www.RinFinance.com/ website.
>
Also, we will notify the list when the slides are on the website.

> Regards,
>
> ? - Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>

Also, there is a LinkedIn group specifically for the R/Finance 2011
conference.  Hopefully the group will help attendees stay in touch and
discuss the presentations, while giving those who have not attended an
idea of what the conference is like.  You can find the group here:
http://www.linkedin.com/groups?mostPopular=&gid=3866213

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From vijay at myemailforever.com  Mon May  2 22:53:11 2011
From: vijay at myemailforever.com (Vijay Vaidyanathan)
Date: Mon, 2 May 2011 13:53:11 -0700
Subject: [R-SIG-Finance] Strategy performance summary report
In-Reply-To: <BANLkTikPXbM_4ui8CnASJBYBZmudEiyFQA@mail.gmail.com>
References: <AANLkTimMpau4cDNhit6rtRhY6HGk3wQC5mPwx968Onrw@mail.gmail.com>
	<4D1B6B27.4050606@braverock.com>
	<1304302217386-3489164.post@n4.nabble.com>
	<1304335504.6868.67.camel@brian-desktop>
	<1a6ba88f6b527c45be2ce63b5551cce3.squirrel@mail.braverock.com>
	<BANLkTikPXbM_4ui8CnASJBYBZmudEiyFQA@mail.gmail.com>
Message-ID: <FBA9667D-1BC6-4372-9E19-2727B5082916@myemailforever.com>

Hi Daniel,

On May 2, 2011, at 1:16 PM, Daniel Cegie?ka wrote:

> Peter,
> 
> Of course you right - someone can test strategies using the blotter.

Well, Blotter, PerformanceAnalytics/ReturnAnalytics and other packages are key ingredients *around* a strategy simulator (of which a backtester is a special case). You still need something like quantstrat to "drive" the test.

> When I first used the blotter, I was convinced that this is how it
> should work (for backtesting). Next I thought, if I use the blotter
> backtest, it can also be used for real trading. I noticed that blotter
> is too slow and I started to look for ways to make it faster with a C.

I'm not sure what you found slow - I've played with it a little bit and considering the early state, it seemed like speed was not an issue for me. Could you post an example or some specifics?

> :
> Beginners often
> commits the same mistake that I committed - that is, believes that eg
> blotter is a whole platform. But the truth is that this is only a
> small part which is designed specifically for PnL (blotter). To
> analyze the strategy can be used with some packages from
> ReturnAnalytics - all specialized in selected uses.

Yes, you do need a separate "strategy simulator" (which I'll just call a backtester for now, although you can forward test just as easily, with simulated data). You can backtest using blotter and custom code, or quantstrat which uses a signal based strategy testing paradigm.  A few years ago, I wrote a backtesting framework for some academic research (which tends to use screening based strategies, rather than signal based strategies). While you can use screen based frameworks for signal based strategy testing, and vice-versa, as a broad sweeping generalization, academics tend to think in terms of screening/sorted portfolios, while practitioners, particularly traders, tend to think of signal-driven portfolios.

If you are interested in the screening/sorting approach, feel free to look at my screening-based backtesting framework PAST.  Its a different paradigm than signal based trading, so you need to wrap your head around that if you are used to thinking of backtesting "trading signals". The docs (such as they are) and code are here if you want to look at it (although, it is definitely slow!).

http://www.returnmetrics.com/sw/past/docs/

That page also has a link to the code, which I have been using on a fairly regular basis for about 5 years. Unfortunately, it has been stuck in a "works for me" status for the past two years :-(

The good news is that I'm currently reviewing resumes for a Research Assistant hire over the summer, and the first thing he or she will be working with me on is getting PAST to the point where it is documented and on CRAN. Next, I hope to integrate blotter and/or quantstrat either tightly as a required package, or loosely (as I do with PerformanceAnalytics now, as a recommended package). 

Unfortunately, until then. all I have is very meager documentation and a few data base drivers for the AAII database and for historical data loaded into a dataframe.

regards,

- Vijay
======
[PS: If anyone on this list knows of a good RA candidate to work on this over the summer, I'd appreciate any leads. It's a paid gig (albeit at grad-student rates) and also presents the opportunity to learn an enormous amount in a short time, while working on an open-source project and making the world a better place!]


From daniel.cegielka at gmail.com  Tue May  3 01:07:47 2011
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Tue, 3 May 2011 01:07:47 +0200
Subject: [R-SIG-Finance] Strategy performance summary report
In-Reply-To: <FBA9667D-1BC6-4372-9E19-2727B5082916@myemailforever.com>
References: <AANLkTimMpau4cDNhit6rtRhY6HGk3wQC5mPwx968Onrw@mail.gmail.com>
	<4D1B6B27.4050606@braverock.com>
	<1304302217386-3489164.post@n4.nabble.com>
	<1304335504.6868.67.camel@brian-desktop>
	<1a6ba88f6b527c45be2ce63b5551cce3.squirrel@mail.braverock.com>
	<BANLkTikPXbM_4ui8CnASJBYBZmudEiyFQA@mail.gmail.com>
	<FBA9667D-1BC6-4372-9E19-2727B5082916@myemailforever.com>
Message-ID: <BANLkTi=Bw1YMTHo3jnus3z3+asRSqBv5+w@mail.gmail.com>

2011/5/2 Vijay Vaidyanathan <vijay at myemailforever.com>:
> Hi Daniel,
>
> On May 2, 2011, at 1:16 PM, Daniel Cegie?ka wrote:
>
>> Peter,
>>
>> Of course you right - someone can test strategies using the blotter.
>
> Well, Blotter, PerformanceAnalytics/ReturnAnalytics and other packages are key ingredients *around* a strategy simulator (of which a backtester is a special case). You still need something like quantstrat to "drive" the test.


That's right. And I can only add that I forgot about quantstrat intentionally :)

quantstrat is generally very good backtester... but, it is not right
for me. Anything related to trading I have written in raw C, so I do
not use R for trading.

If someone wants to properly model the real market, as most should
reflect the tasks that will take place in reality. So I use exactly
the same code in the backtests and the trading... and the models
I have written in C (and not in R).

You can use eg syslog (linux, unix) and save information about the
orders and transactions on the disk (or use some databases), and then
import it to the blotter for further analysis. And this is just the
way I like.


>> When I first used the blotter, I was convinced that this is how it
>> should work (for backtesting). Next I thought, if I use the blotter
>> backtest, it can also be used for real trading. I noticed that blotter
>> is too slow and I started to look for ways to make it faster with a C.
>
> I'm not sure what you found slow - I've played with it a little bit and considering the early state, it seemed like speed was not an issue for me. Could you post an example or some specifics?


Blotter is fast enough for the analysis of PnL. It is not suitable, to
ensure that it build a platform that will be able to operate on real
market data (in my opinion).

Even for simple models written in R will be difficult to process such
amount of data that are generated out of the exchanges. So to be able
to use R to the real trading should be placed between the connection
with broker/exchange (eg FIX engine) some fast layer (writen in
C/C++), which will be efficient enough to capture all messages from
the market, and the model (written in R) would be recalculated for
example, every 5 minutes or less.

Just why complicate your life when you can immediately write everything in eg C?

..but for pre/post trade processing R is the best! :)


>> :
>> Beginners often
>> commits the same mistake that I committed - that is, believes that eg
>> blotter is a whole platform. But the truth is that this is only a
>> small part which is designed specifically for PnL (blotter). To
>> analyze the strategy can be used with some packages from
>> ReturnAnalytics - all specialized in selected uses.
>
> Yes, you do need a separate "strategy simulator" (which I'll just call a backtester for now, although you can forward test just as easily, with simulated data). You can backtest using blotter and custom code, or quantstrat which uses a signal based strategy testing paradigm. ?A few years ago, I wrote a backtesting framework for some academic research (which tends to use screening based strategies, rather than signal based strategies). While you can use screen based frameworks for signal based strategy testing, and vice-versa, as a broad sweeping generalization, academics tend to think in terms of screening/sorted portfolios, while practitioners, particularly traders, tend to think of signal-driven portfolios.
>
> If you are interested in the screening/sorting approach, feel free to look at my screening-based backtesting framework PAST. ?Its a different paradigm than signal based trading, so you need to wrap your head around that if you are used to thinking of backtesting "trading signals". The docs (such as they are) and code are here if you want to look at it (although, it is definitely slow!).
>
> http://www.returnmetrics.com/sw/past/docs/
>
> That page also has a link to the code, which I have been using on a fairly regular basis for about 5 years. Unfortunately, it has been stuck in a "works for me" status for the past two years :-(
>
> The good news is that I'm currently reviewing resumes for a Research Assistant hire over the summer, and the first thing he or she will be working with me on is getting PAST to the point where it is documented and on CRAN. Next, I hope to integrate blotter and/or quantstrat either tightly as a required package, or loosely (as I do with PerformanceAnalytics now, as a recommended package).
>
> Unfortunately, until then. all I have is very meager documentation and a few data base drivers for the AAII database and for historical data loaded into a dataframe.


Already interested in your project. But I have not used it enough to
write something more.

regards,
daniel



>
> regards,
>
> - Vijay
> ======
> [PS: If anyone on this list knows of a good RA candidate to work on this over the summer, I'd appreciate any leads. It's a paid gig (albeit at grad-student rates) and also presents the opportunity to learn an enormous amount in a short time, while working on an open-source project and making the world a better place!]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From algotr8der at gmail.com  Tue May  3 01:10:05 2011
From: algotr8der at gmail.com (algotr8der)
Date: Mon, 2 May 2011 16:10:05 -0700 (PDT)
Subject: [R-SIG-Finance] quantstrat & custom indicators
Message-ID: <1304377805506-3491259.post@n4.nabble.com>

I have read through the documentation for quantstrat and gone through some
examples (RSI, MACD, Faber) but am a bit lost as to whether I can creatively
use the features of this package to create a custom indicator as follows:

-I have N securities 
-I want to pass each of those N securities along with N+1 constants to a
user created function called myfunction().
-the user created function myfunction() performs some arithmetic operations
and returns a single time series.

In this example, lets say N = 4

c1 <- 1
c2 <- 2
c3 <- 3
c4 <- 4
c5 <- 5

myStrat <- strategy("myStrat")
myStrat <- add.indicator(strategy = myStrat, name = "myfunction", arguments
= list(symbols[1], symbols[2], symbols[3], symbols[4], c1, c2, c3, c4, c5))

I have tried this and when I call applyStrategy I get multiple errors -

a) c1 is not found
b) when I removed c1-c5 and defined them in myfunction instead, I got:

Error in .Internal(get(x, envir, mode, inherits)) : 'x' is missing

It seems its expecting arguments in the form x=quote(Cl(mktdata)). I'm not
sure I can use that as my argument to myfunction as this user created
function needs to treat each individual time series in a unique way i.e. it
is performing a proprietary arithmetic operation.

Any guidance would be greatly appreciated.





--
View this message in context: http://r.789695.n4.nabble.com/quantstrat-custom-indicators-tp3491259p3491259.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Tue May  3 02:42:32 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 02 May 2011 19:42:32 -0500
Subject: [R-SIG-Finance] quantstrat & custom indicators
In-Reply-To: <1304377805506-3491259.post@n4.nabble.com>
References: <1304377805506-3491259.post@n4.nabble.com>
Message-ID: <1304383352.30824.47.camel@brian-desktop>

On Mon, 2011-05-02 at 16:10 -0700, algotr8der wrote:
> I have read through the documentation for quantstrat and gone through some
> examples (RSI, MACD, Faber) but am a bit lost as to whether I can creatively
> use the features of this package to create a custom indicator as follows:
> 
> -I have N securities 
> -I want to pass each of those N securities along with N+1 constants to a
> user created function called myfunction().
> -the user created function myfunction() performs some arithmetic operations
> and returns a single time series.
> 
> In this example, lets say N = 4
> 
> c1 <- 1
> c2 <- 2
> c3 <- 3
> c4 <- 4
> c5 <- 5
> 
> myStrat <- strategy("myStrat")
> myStrat <- add.indicator(strategy = myStrat, name = "myfunction", arguments
> = list(symbols[1], symbols[2], symbols[3], symbols[4], c1, c2, c3, c4, c5))
> 
> I have tried this and when I call applyStrategy I get multiple errors -
> 
> a) c1 is not found
> b) when I removed c1-c5 and defined them in myfunction instead, I got:
> 
> Error in .Internal(get(x, envir, mode, inherits)) : 'x' is missing
> 
> It seems its expecting arguments in the form x=quote(Cl(mktdata)). I'm not
> sure I can use that as my argument to myfunction as this user created
> function needs to treat each individual time series in a unique way i.e. it
> is performing a proprietary arithmetic operation.
> 
> Any guidance would be greatly appreciated.

You're being (deliberately) a little unclear.  I'll try to unpack it
anyway...

We routinely write custom indicator and signal functions.

You can do that with either little or much work required on your end.

'mktdata' is constructed inside quantstrat in the applyRules loop
(currently the loop over symbols, though this may change if was add a
'portfolio' evaluation mode this summer during GSoC).  If it mktdata is
not passed in, it is created by get()'ing the variable named for the
symbol.  I believe this is precisely as described in the documentation.
Cases where you may want to pass mktdata would include some complex
portfolio-based or basket-based approach.

In typical usage, an indicator or signal function will return either an
xts time series with the same index as mktdata, or a vector of the same
length as nrow(mktdata).  I believe this is also described in the
documentation.  The indicator function may also retrieve any information
known to the calling environment (the applyStrategy and applyRules
functions), including the symbol that is currently being evaluated.  If
you need custom logic per symbol, you can do that based on some
proprietary lookup function.

In your calling logic, 'myfunction' is *both* the name= argument to
add.indicator *and* the name of a function you do not define.  All of
the name= arguments in quantstrat refer to named functions.  This too
is, I believe, spelled out in the documentation.  I would assume that
c1,c2,c3,c4,c5 are arguments to the function.  The largest problem is
that you need to NAME the arguments in your arguments=list().  These are
used for argument matching to your function.  Since you do not name
them, they are in the list slots as [[1]],[[2]],[[3]], etc.  We can't
magically match from that.  the documentation for add.indicator says
"arguments and parameters are named lists".  Note that we say *named*
lists...

There is no problem whatsoever with your 'proprietary arithmetic
operation'. I do it all the time.  You just need to be explicit about
where and how quantstrat is to match your (named) arguments list up with
the named function parameters of your custom proprietary indicator.

Now, if you want to make things more difficult on yourself, you don't
*need* to return a time series or a proper-length vector.  You can
return any object at all.  In that case, your returned object will be
stuck in the $indicators slot.  All good so far.  The difficulty lies in
the fact that your signal and rule functions will need to know precisely
what you've stuck there and how to act on that data.  So, I typically
(though not always), make things easy on myself and return time series
indicators and boolean signal time series, even with proprietary
indicator and signal logic.  I don't always do that, which is why the
framework can handle arbitrary returns, but do realize that it makes
things harder.

Regards,

   - Brian


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From josh.m.ulrich at gmail.com  Tue May  3 03:06:37 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 2 May 2011 20:06:37 -0500
Subject: [R-SIG-Finance] Quantmod ChartThemes
In-Reply-To: <BANLkTimKohc9jCM0GEp0DDVjX1gyQtdqUw@mail.gmail.com>
References: <BANLkTimKohc9jCM0GEp0DDVjX1gyQtdqUw@mail.gmail.com>
Message-ID: <BANLkTi=aS+Hk6aAhZAUcv5u5DRkW9H022A@mail.gmail.com>

On Thu, Apr 28, 2011 at 2:22 AM, Costas Vorlow <costas.vorlow at gmail.com> wrote:
> I am having trouble with selecting themes in quantmod
>
> getSymbols("GS")
> ?chartSeries(GS, theme=chartTheme('white.mono'),type="line")
>
> How many themes (predefined) exist?
>
Use the source! ;-)

> chartTheme
function (theme = "black", ...)
{
    ctheme <- get(".chart.theme", as.environment("package:quantmod"))
    attr(ctheme, ".Environment") <- NULL
    current.theme <- ctheme[[theme]]
    ll <- list(...)
    for (i in names(ll)) {
        current.theme[[i]] <- ll[[i]]
    }
    return(structure(current.theme, class = "chart.theme"))
}
<environment: namespace:quantmod>
> names(quantmod:::.chart.theme)
[1] "white"      "white.mono" "black"      "black.mono" "beige"
[6] "wsj"


> Best,
> Costas
>

Hope that helps,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From algotr8der at gmail.com  Tue May  3 04:16:02 2011
From: algotr8der at gmail.com (s)
Date: Mon, 02 May 2011 22:16:02 -0400
Subject: [R-SIG-Finance] quantstrat & custom indicators
In-Reply-To: <1304383352.30824.47.camel@brian-desktop>
References: <1304377805506-3491259.post@n4.nabble.com>
	<1304383352.30824.47.camel@brian-desktop>
Message-ID: <4DBF6562.4060201@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110502/e15fb825/attachment.pl>

From William.Alpert at barrons.com  Tue May  3 15:40:38 2011
From: William.Alpert at barrons.com (Alpert, William)
Date: Tue, 3 May 2011 09:40:38 -0400
Subject: [R-SIG-Finance] RinFinance documentation
Message-ID: <02BF89F8F8F5434281FB674D2BC513C361905934A9@SBKMXSMB09.win.dowjones.net>

As the Boswell to all you Samuel Johnsons, I've already planted one story in my tabloid about a conference presentation, and expect to write about a couple more. Don't ever shy from alerting me to newsworthy innovations.

Your mascot,

Bill Alpert
Sr. Editor
Barron's
1.212.416.2742 w
william.alpert at barrons.com


From algotr8der at gmail.com  Tue May  3 18:57:31 2011
From: algotr8der at gmail.com (algotr8der)
Date: Tue, 3 May 2011 09:57:31 -0700 (PDT)
Subject: [R-SIG-Finance] quantstrat & custom indicators
In-Reply-To: <4DBF6562.4060201@gmail.com>
References: <1304377805506-3491259.post@n4.nabble.com>
	<1304383352.30824.47.camel@brian-desktop>
	<4DBF6562.4060201@gmail.com>
Message-ID: <1304441851002-3492994.post@n4.nabble.com>

For a portfolio based approach like the one I described in my previous post
would it make more sense to define a portfolio per symbol and use a for/if
statement to loop through each symbol, create a portfolio for the symbol,
create rues for that symbol (i.e. num shares and direction of trade may
depend on the symbol) and call applyStrategy on that portfolio. The
initAcct() function can be called once all of the trades in each of the
portfolio's have been executed.

Here is an example (I have also attached the .R file for this code). There
seems to be various problems. Firstly, the number of shares executed does
not correspond to that specified in the If condition. For instance, only 348
shares should be traded in CAT (the 2nd symbol in the character vector
'symbols') and the entry position should be short. What happens is that the
opening trade is long 65 shares (which is what was intended for the previous
symbol i.e. IBM). This is followed by a trade that is short 348 shares
(which was intended for CAT). The same type of error progresses through the
remainder of the symbols.

I guess I am seeking guidance on the big picture for portfolio based
approaches as the direction and number of shares will depend on the symbol.

http://r.789695.n4.nabble.com/file/n3492994/basketStrategy.R
basketStrategy.R )
http://r.789695.n4.nabble.com/file/n3492994/error.txt error.txt 

require(quantstrat)
initDate = '2007-07-01'
endDate = '2007-08-30'
startdate = '2007-07-02'
initEq = 500000

symbols <- c("IBM", "CAT", "UTX", "MSFT")
currency("USD")

getSymbols(symbols, from=startdate, to=endDate)

stratBasket <- strategy('default')

stratBasket <- add.indicator(strategy = stratBasket, label="ma10", name =
"SMA", arguments = list(x=quote(Cl(mktdata)), n=10))
stratBasket <- add.signal(strategy = stratBasket, name = "sigCrossover",
arguments= list(column=c("Close", "ma10"), relationship="gt"),
label="close.gt.ma10")
stratBasket <- add.signal(strategy = stratBasket, name = "sigCrossover",
arguments= list(column=c("Close", "ma10"), relationship="lt"),
label="close.lt.ma10")


for (symbol in symbols) {
	if (symbol == 'IBM') {
	
	stock(symbol, currency="USD", multiplier=1)	
	portfolio.st = symbol
	initPortf(name=portfolio.st, symbols=symbol, initDate=initDate,
currency="USD")
	initOrders(portfolio=portfolio.st,initDate=initDate)
		
	numshares <- 65
	entertrade <- c("long")
	exittrade <- c("short")
	stratBasket <- add.rule(strategy = stratBasket, name='ruleSignal',
arguments = list(sigcol="close.gt.ma10",sigval=TRUE, orderqty=numshares,
ordertype='market', orderside=entertrade), type='enter')
	stratBasket <- add.rule(strategy = stratBasket, name='ruleSignal',
arguments = list(sigcol="close.lt.ma10",sigval=TRUE, orderqty=all,
ordertype='market', orderside=exittrade), type='exit')
	out<-try(applyStrategy(strategy=stratBasket , portfolios=portfolio.st))
		
	} else if (symbol == 'CAT') {
		
	stock(symbol, currency="USD", multiplier=1)	
	portfolio.st = symbol
	initPortf(name=portfolio.st, symbols=symbol, initDate=initDate,
currency="USD")
	initOrders(portfolio=portfolio.st,initDate=initDate)
			
	numshares <- -348
	entertrade <- c("short")
	exittrade <- c("long")
	stratBasket <- add.rule(strategy = stratBasket, name='ruleSignal',
arguments = list(sigcol="close.gt.ma10",sigval=TRUE, orderqty=numshares,
ordertype='market', orderside=entertrade), type='enter')
	stratBasket <- add.rule(strategy = stratBasket, name='ruleSignal',
arguments = list(sigcol="close.lt.ma10",sigval=TRUE, orderqty=all,
ordertype='market', orderside=exittrade), type='exit')
	out<-try(applyStrategy(strategy=stratBasket , portfolios=portfolio.st))
		
	} else if (symbol == 'UTX') {
		
	stock(symbol, currency="USD", multiplier=1)		
	portfolio.st = symbol
	initPortf(name=portfolio.st, symbols=symbol, initDate=initDate,
currency="USD")
	initOrders(portfolio=portfolio.st,initDate=initDate)
		
	numshares <- 648
	entertrade <- c("long")
	exittrade <- c("short")
	stratBasket <- add.rule(strategy = stratBasket, name='ruleSignal',
arguments = list(sigcol="close.gt.ma10",sigval=TRUE, orderqty=numshares,
ordertype='market', orderside=entertrade), type='enter')
	stratBasket <- add.rule(strategy = stratBasket, name='ruleSignal',
arguments = list(sigcol="close.lt.ma10",sigval=TRUE, orderqty=all,
ordertype='market', orderside=exittrade), type='exit')
	out<-try(applyStrategy(strategy=stratBasket , portfolios=portfolio.st))
		
	} else if (symbol == 'MSFT') {
		
	stock(symbol, currency="USD", multiplier=1)		
	portfolio.st = symbol
	initPortf(name=portfolio.st, symbols=symbol, initDate=initDate,
currency="USD")
	initOrders(portfolio=portfolio.st,initDate=initDate)
		
	numshares <- -1000
	entertrade <- c("short")
	exittrade <- c("long")
	stratBasket <- add.rule(strategy = stratBasket, name='ruleSignal',
arguments = list(sigcol="close.gt.ma10",sigval=TRUE, orderqty=numshares,
ordertype='market', orderside=entertrade), type='enter')
	stratBasket <- add.rule(strategy = stratBasket, name='ruleSignal',
arguments = list(sigcol="close.lt.ma10",sigval=TRUE, orderqty=all,
ordertype='market', orderside=exittrade), type='exit')
	out<-try(applyStrategy(strategy=stratBasket , portfolios=portfolio.st))
		
	}
}

account.st <- c("basket")
initAcct(account.st, portfolios=symbols, initDate=initDate, initEq=initEq)



--
View this message in context: http://r.789695.n4.nabble.com/quantstrat-custom-indicators-tp3491259p3492994.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From algotr8der at gmail.com  Tue May  3 21:28:50 2011
From: algotr8der at gmail.com (algotr8der)
Date: Tue, 3 May 2011 12:28:50 -0700 (PDT)
Subject: [R-SIG-Finance] quantstrat & custom indicators
In-Reply-To: <1304441851002-3492994.post@n4.nabble.com>
References: <1304377805506-3491259.post@n4.nabble.com>
	<1304383352.30824.47.camel@brian-desktop>
	<4DBF6562.4060201@gmail.com>
	<1304441851002-3492994.post@n4.nabble.com>
Message-ID: <1304450930095-3493332.post@n4.nabble.com>

So I changed the following:

1) orderqty = all 

in all of the exit rules to 

2) orderqty = -numshares

So essentially reversing the original trade. This allowed the code to
generate trades. I also lengthened the date range to include data from
2007-07-02 to 2007-12-30 to get more data points for the test. 

http://r.789695.n4.nabble.com/file/n3493332/basketStrategy.R
basketStrategy.R 

As you can see the trades for IBM are generated based on the rule specified.
However, one of the trades for CAT is using the rule added to the strategy
for IBM (it's trading 65 shares). I'm not sure if this is the entry trade
because the entry trade should be a short sale of 348 shares. Instead a
purchase of 65 shares is made as the first ever trade for CAT. You can see
the same theme progress for UTX and MSFT.

I think there is some rule overlapping going on here and its likely because
I am not using the features of this package correctly. If there was a way to
remove a rule once processing of a symbol has completed I think that might
work. But you guys might have more 'clean' and 'efficient' ways to think
about this problem.

[1] "2007-08-10 IBM 65 @ 112.64"
[1] "2007-08-14 IBM -65 @ 112.05"
[1] "2007-08-23 IBM 65 @ 111.45"
[1] "2007-09-12 IBM -65 @ 116"
[1] "2007-09-18 IBM 65 @ 116.63"
[1] "2007-10-03 IBM -65 @ 116.4"
[1] "2007-10-08 IBM 65 @ 117.77"
[1] "2007-10-17 IBM -65 @ 115.78"
[1] "2007-10-29 IBM 65 @ 114.8"
[1] "2007-11-01 IBM -65 @ 113.65"
[1] "2007-11-02 IBM 65 @ 114.59"
[1] "2007-11-05 IBM -65 @ 113.4"
[1] "2007-11-23 IBM 65 @ 104.05"
[1] "2007-11-26 IBM -65 @ 101.97"
[1] "2007-11-27 IBM 65 @ 103.83"
[1] "2007-12-11 IBM -65 @ 106.99"
[1] "2007-12-12 IBM 65 @ 108.47"
[1] "2007-12-14 IBM -65 @ 105.77"
[1] "2007-12-20 IBM 65 @ 108.84"
[1] "2007-08-02 CAT 65 @ 80.67"
[1] "2007-08-02 CAT -348 @ 80.67"
[1] "2007-08-03 CAT -65 @ 78.96"
[1] "2007-08-03 CAT 348 @ 78.96"
[1] "2007-08-06 CAT 65 @ 81"
[1] "2007-08-06 CAT -348 @ 81"
[1] "2007-08-09 CAT -65 @ 78.48"
[1] "2007-08-09 CAT 348 @ 78.48"
[1] "2007-08-23 CAT 65 @ 75.17"
[1] "2007-08-23 CAT -348 @ 75.17"
[1] "2007-08-28 CAT -65 @ 74.16"
[1] "2007-08-28 CAT 348 @ 74.16"
[1] "2007-08-29 CAT 65 @ 75.04"
[1] "2007-08-29 CAT -348 @ 75.04"
[1] "2007-08-30 CAT -65 @ 74.66"
[1] "2007-08-30 CAT 348 @ 74.66"
[1] "2007-08-31 CAT 65 @ 75.77"
[1] "2007-08-31 CAT -348 @ 75.77"
[1] "2007-09-07 CAT -65 @ 73.44"
[1] "2007-09-07 CAT 348 @ 73.44"
[1] "2007-09-18 CAT 65 @ 77.46"
[1] "2007-09-18 CAT -348 @ 77.46"
[1] "2007-10-11 CAT -65 @ 79.44"
[1] "2007-10-11 CAT 348 @ 79.44"
[1] "2007-10-12 CAT 65 @ 80.3"
[1] "2007-10-12 CAT -348 @ 80.3"
[1] "2007-10-15 CAT -65 @ 78.84"
[1] "2007-10-15 CAT 348 @ 78.84"
[1] "2007-11-02 CAT 65 @ 74.76"
[1] "2007-11-02 CAT -348 @ 74.76"
[1] "2007-11-05 CAT -65 @ 73.5"
[1] "2007-11-05 CAT 348 @ 73.5"
[1] "2007-11-06 CAT 65 @ 74.92"
[1] "2007-11-06 CAT -348 @ 74.92"
[1] "2007-11-07 CAT -65 @ 73.6"
[1] "2007-11-07 CAT 348 @ 73.6"
[1] "2007-11-28 CAT 65 @ 71.19"
[1] "2007-11-28 CAT -348 @ 71.19"
[1] "2007-12-14 CAT -65 @ 73.39"
[1] "2007-12-14 CAT 348 @ 73.39"
[1] "2007-12-24 CAT 65 @ 72.7"
[1] "2007-12-24 CAT -348 @ 72.7"
[1] "2007-08-02 UTX -348 @ 74.76"
[1] "2007-08-02 UTX 648 @ 74.76"
[1] "2007-08-03 UTX 348 @ 73.93"
[1] "2007-08-03 UTX -648 @ 73.93"
[1] "2007-08-06 UTX -348 @ 74.85"
[1] "2007-08-06 UTX 648 @ 74.85"
[1] "2007-08-07 UTX 348 @ 74.15"
[1] "2007-08-07 UTX -648 @ 74.15"
[1] "2007-08-13 UTX -348 @ 74.01"
[1] "2007-08-13 UTX 648 @ 74.01"
[1] "2007-08-14 UTX 348 @ 72.78"
[1] "2007-08-14 UTX -648 @ 72.78"
[1] "2007-08-17 UTX -348 @ 73.82"
[1] "2007-08-17 UTX 648 @ 73.82"
[1] "2007-08-21 UTX 348 @ 72.94"
[1] "2007-08-21 UTX -648 @ 72.94"
[1] "2007-08-22 UTX -348 @ 73.87"
[1] "2007-08-22 UTX 648 @ 73.87"
[1] "2007-08-28 UTX 348 @ 72"
[1] "2007-08-28 UTX -648 @ 72"
[1] "2007-08-29 UTX -348 @ 74.35"
[1] "2007-08-29 UTX 648 @ 74.35"
[1] "2007-09-05 UTX 348 @ 73.45"
[1] "2007-09-05 UTX -648 @ 73.45"
[1] "2007-09-06 UTX -348 @ 75.01"
[1] "2007-09-06 UTX 648 @ 75.01"
[1] "2007-09-07 UTX 348 @ 73.79"
[1] "2007-09-07 UTX -648 @ 73.79"
[1] "2007-09-10 UTX -348 @ 74.49"
[1] "2007-09-10 UTX 648 @ 74.49"
[1] "2007-10-03 UTX 348 @ 79.67"
[1] "2007-10-03 UTX -648 @ 79.67"
[1] "2007-10-05 UTX -348 @ 80.84"
[1] "2007-10-05 UTX 648 @ 80.84"
[1] "2007-10-08 UTX 348 @ 80.36"
[1] "2007-10-08 UTX -648 @ 80.36"
[1] "2007-10-09 UTX -348 @ 81.2"
[1] "2007-10-09 UTX 648 @ 81.2"
[1] "2007-10-10 UTX 348 @ 80.5"
[1] "2007-10-10 UTX -648 @ 80.5"
[1] "2007-10-31 UTX -348 @ 76.59"
[1] "2007-10-31 UTX 648 @ 76.59"
[1] "2007-11-01 UTX 348 @ 74.72"
[1] "2007-11-01 UTX -648 @ 74.72"
[1] "2007-11-05 UTX -348 @ 76.11"
[1] "2007-11-05 UTX 648 @ 76.11"
[1] "2007-11-07 UTX 348 @ 74.46"
[1] "2007-11-07 UTX -648 @ 74.46"
[1] "2007-11-13 UTX -348 @ 75.33"
[1] "2007-11-13 UTX 648 @ 75.33"
[1] "2007-11-14 UTX 348 @ 74.92"
[1] "2007-11-14 UTX -648 @ 74.92"
[1] "2007-11-20 UTX -348 @ 74.32"
[1] "2007-11-20 UTX 648 @ 74.32"
[1] "2007-11-21 UTX 348 @ 72.78"
[1] "2007-11-21 UTX -648 @ 72.78"
[1] "2007-11-27 UTX -348 @ 74"
[1] "2007-11-27 UTX 648 @ 74"
[1] "2007-12-14 UTX 348 @ 76.69"
[1] "2007-12-14 UTX -648 @ 76.69"
[1] "2007-12-21 UTX -348 @ 77.83"
[1] "2007-12-21 UTX 648 @ 77.83"
[1] "2007-08-07 MSFT 648 @ 29.55"
[1] "2007-08-07 MSFT -1000 @ 29.55"
[1] "2007-08-09 MSFT -648 @ 29.3"
[1] "2007-08-09 MSFT 1000 @ 29.3"
[1] "2007-08-23 MSFT 648 @ 28.3"
[1] "2007-08-23 MSFT -1000 @ 28.3"
[1] "2007-08-28 MSFT -648 @ 27.93"
[1] "2007-08-28 MSFT 1000 @ 27.93"
[1] "2007-08-29 MSFT 648 @ 28.59"
[1] "2007-08-29 MSFT -1000 @ 28.59"
[1] "2007-09-05 MSFT -648 @ 28.48"
[1] "2007-09-05 MSFT 1000 @ 28.48"
[1] "2007-09-06 MSFT 648 @ 28.91"
[1] "2007-09-06 MSFT -1000 @ 28.91"
[1] "2007-09-07 MSFT -648 @ 28.44"
[1] "2007-09-07 MSFT 1000 @ 28.44"
[1] "2007-09-11 MSFT 648 @ 28.93"
[1] "2007-09-11 MSFT -1000 @ 28.93"
[1] "2007-09-17 MSFT -648 @ 28.73"
[1] "2007-09-17 MSFT 1000 @ 28.73"
[1] "2007-09-18 MSFT 648 @ 28.93"
[1] "2007-09-18 MSFT -1000 @ 28.93"
[1] "2007-09-19 MSFT -648 @ 28.67"
[1] "2007-09-19 MSFT 1000 @ 28.67"
[1] "2007-09-24 MSFT 648 @ 29.08"
[1] "2007-09-24 MSFT -1000 @ 29.08"
[1] "2007-10-19 MSFT -648 @ 30.17"
[1] "2007-10-19 MSFT 1000 @ 30.17"
[1] "2007-10-22 MSFT 648 @ 30.51"
[1] "2007-10-22 MSFT -1000 @ 30.51"
[1] "2007-11-07 MSFT -648 @ 35.52"
[1] "2007-11-07 MSFT 1000 @ 35.52"
[1] "2007-11-20 MSFT 648 @ 34.58"
[1] "2007-11-20 MSFT -1000 @ 34.58"
[1] "2007-11-26 MSFT -648 @ 32.97"
[1] "2007-11-26 MSFT 1000 @ 32.97"
[1] "2007-12-05 MSFT 648 @ 34.15"
[1] "2007-12-05 MSFT -1000 @ 34.15"
[1] "2007-12-17 MSFT -648 @ 34.39"
[1] "2007-12-17 MSFT 1000 @ 34.39"
[1] "2007-12-18 MSFT 648 @ 34.74"
[1] "2007-12-18 MSFT -1000 @ 34.74"

--
View this message in context: http://r.789695.n4.nabble.com/quantstrat-custom-indicators-tp3491259p3493332.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Tue May  3 21:45:32 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 03 May 2011 14:45:32 -0500
Subject: [R-SIG-Finance] quantstrat & custom indicators
In-Reply-To: <1304450930095-3493332.post@n4.nabble.com>
References: <1304377805506-3491259.post@n4.nabble.com>
	<1304383352.30824.47.camel@brian-desktop> <4DBF6562.4060201@gmail.com>
	<1304441851002-3492994.post@n4.nabble.com>
	<1304450930095-3493332.post@n4.nabble.com>
Message-ID: <1304451932.30824.93.camel@brian-desktop>

If you look a the strategy object, you'll see that you have four sets of
rules by the time you're done.  This is likely not what you want.
Strategies should normally be agnostic to the instrument to trade, and
you're not really doing that.

I don't have time to rewrite this for you right now, but here's what I 
suggest.

build two portfolios, one for your longs, and one for your shorts
(alternately, you could have a portfolio for each instrument, but this
shouldn't be necessary)

build one account to hold it all

Have *two* strategy objects, ignoring symbols for now.  One will be your
'long' strategy, and one will be your 'short' strategy.  use some
arbitrarily large order quantity for your entries and 'all' for your
exits. (I'll explain this in a minute). have the rules use
osFUN='osMaxPos'

Use setPosLimit to set your maximum long and short position limits by
symbol.  

This should then work as you expect when you apply the long strategy to
the longs and the short strategy to the shorts.

#############

Now...  onto something more like what I suspect you're really trying to
do ...

Normally, what you'd really want to do is have a only a single strategy
object, regardless of symbol. So forget all about the symbols when
specifying the indicators, signals, and rules.

The sophisticated part lies in (maybe) using setPosLimit or some other
function to store things like limits/direction by symbol, and *then*
writing a custom order sizing function.  The order sizing function gets
a rule fire on a symbol, checks your custom metadata, and decides how
large (if any) an order to place.

You'll notice that several times in the documentation we refer to
signals as places where you *may* want to trade.  Rules and order sizing
functions take the *may* and can then decide to turn that into an
affirmative trade action and also decide how much.

HTH,

   - Brian

On Tue, 2011-05-03 at 12:28 -0700, algotr8der wrote:
> So I changed the following:
> 
> 1) orderqty = all 
> 
> in all of the exit rules to 
> 
> 2) orderqty = -numshares
> 
> So essentially reversing the original trade. This allowed the code to
> generate trades. I also lengthened the date range to include data from
> 2007-07-02 to 2007-12-30 to get more data points for the test. 
> 
> http://r.789695.n4.nabble.com/file/n3493332/basketStrategy.R
> basketStrategy.R 
> 
> As you can see the trades for IBM are generated based on the rule specified.
> However, one of the trades for CAT is using the rule added to the strategy
> for IBM (it's trading 65 shares). I'm not sure if this is the entry trade
> because the entry trade should be a short sale of 348 shares. Instead a
> purchase of 65 shares is made as the first ever trade for CAT. You can see
> the same theme progress for UTX and MSFT.
> 
> I think there is some rule overlapping going on here and its likely because
> I am not using the features of this package correctly. If there was a way to
> remove a rule once processing of a symbol has completed I think that might
> work. But you guys might have more 'clean' and 'efficient' ways to think
> about this problem.
> 
> [1] "2007-08-10 IBM 65 @ 112.64"
> [1] "2007-08-14 IBM -65 @ 112.05"
> [1] "2007-08-23 IBM 65 @ 111.45"
> [1] "2007-09-12 IBM -65 @ 116"
> [1] "2007-09-18 IBM 65 @ 116.63"
> [1] "2007-10-03 IBM -65 @ 116.4"
> [1] "2007-10-08 IBM 65 @ 117.77"
> [1] "2007-10-17 IBM -65 @ 115.78"
> [1] "2007-10-29 IBM 65 @ 114.8"
> [1] "2007-11-01 IBM -65 @ 113.65"
> [1] "2007-11-02 IBM 65 @ 114.59"
> [1] "2007-11-05 IBM -65 @ 113.4"
> [1] "2007-11-23 IBM 65 @ 104.05"
> [1] "2007-11-26 IBM -65 @ 101.97"
> [1] "2007-11-27 IBM 65 @ 103.83"
> [1] "2007-12-11 IBM -65 @ 106.99"
> [1] "2007-12-12 IBM 65 @ 108.47"
> [1] "2007-12-14 IBM -65 @ 105.77"
> [1] "2007-12-20 IBM 65 @ 108.84"
> [1] "2007-08-02 CAT 65 @ 80.67"
> [1] "2007-08-02 CAT -348 @ 80.67"
> [1] "2007-08-03 CAT -65 @ 78.96"
> [1] "2007-08-03 CAT 348 @ 78.96"
> [1] "2007-08-06 CAT 65 @ 81"
> [1] "2007-08-06 CAT -348 @ 81"
> [1] "2007-08-09 CAT -65 @ 78.48"
> [1] "2007-08-09 CAT 348 @ 78.48"
> [1] "2007-08-23 CAT 65 @ 75.17"
> [1] "2007-08-23 CAT -348 @ 75.17"
> [1] "2007-08-28 CAT -65 @ 74.16"
> [1] "2007-08-28 CAT 348 @ 74.16"
> [1] "2007-08-29 CAT 65 @ 75.04"
> [1] "2007-08-29 CAT -348 @ 75.04"
> [1] "2007-08-30 CAT -65 @ 74.66"
> [1] "2007-08-30 CAT 348 @ 74.66"
> [1] "2007-08-31 CAT 65 @ 75.77"
> [1] "2007-08-31 CAT -348 @ 75.77"
> [1] "2007-09-07 CAT -65 @ 73.44"
> [1] "2007-09-07 CAT 348 @ 73.44"
> [1] "2007-09-18 CAT 65 @ 77.46"
> [1] "2007-09-18 CAT -348 @ 77.46"
> [1] "2007-10-11 CAT -65 @ 79.44"
> [1] "2007-10-11 CAT 348 @ 79.44"
> [1] "2007-10-12 CAT 65 @ 80.3"
> [1] "2007-10-12 CAT -348 @ 80.3"
> [1] "2007-10-15 CAT -65 @ 78.84"
> [1] "2007-10-15 CAT 348 @ 78.84"
> [1] "2007-11-02 CAT 65 @ 74.76"
> [1] "2007-11-02 CAT -348 @ 74.76"
> [1] "2007-11-05 CAT -65 @ 73.5"
> [1] "2007-11-05 CAT 348 @ 73.5"
> [1] "2007-11-06 CAT 65 @ 74.92"
> [1] "2007-11-06 CAT -348 @ 74.92"
> [1] "2007-11-07 CAT -65 @ 73.6"
> [1] "2007-11-07 CAT 348 @ 73.6"
> [1] "2007-11-28 CAT 65 @ 71.19"
> [1] "2007-11-28 CAT -348 @ 71.19"
> [1] "2007-12-14 CAT -65 @ 73.39"
> [1] "2007-12-14 CAT 348 @ 73.39"
> [1] "2007-12-24 CAT 65 @ 72.7"
> [1] "2007-12-24 CAT -348 @ 72.7"
> [1] "2007-08-02 UTX -348 @ 74.76"
> [1] "2007-08-02 UTX 648 @ 74.76"
> [1] "2007-08-03 UTX 348 @ 73.93"
> [1] "2007-08-03 UTX -648 @ 73.93"
> [1] "2007-08-06 UTX -348 @ 74.85"
> [1] "2007-08-06 UTX 648 @ 74.85"
> [1] "2007-08-07 UTX 348 @ 74.15"
> [1] "2007-08-07 UTX -648 @ 74.15"
> [1] "2007-08-13 UTX -348 @ 74.01"
> [1] "2007-08-13 UTX 648 @ 74.01"
> [1] "2007-08-14 UTX 348 @ 72.78"
> [1] "2007-08-14 UTX -648 @ 72.78"
> [1] "2007-08-17 UTX -348 @ 73.82"
> [1] "2007-08-17 UTX 648 @ 73.82"
> [1] "2007-08-21 UTX 348 @ 72.94"
> [1] "2007-08-21 UTX -648 @ 72.94"
> [1] "2007-08-22 UTX -348 @ 73.87"
> [1] "2007-08-22 UTX 648 @ 73.87"
> [1] "2007-08-28 UTX 348 @ 72"
> [1] "2007-08-28 UTX -648 @ 72"
> [1] "2007-08-29 UTX -348 @ 74.35"
> [1] "2007-08-29 UTX 648 @ 74.35"
> [1] "2007-09-05 UTX 348 @ 73.45"
> [1] "2007-09-05 UTX -648 @ 73.45"
> [1] "2007-09-06 UTX -348 @ 75.01"
> [1] "2007-09-06 UTX 648 @ 75.01"
> [1] "2007-09-07 UTX 348 @ 73.79"
> [1] "2007-09-07 UTX -648 @ 73.79"
> [1] "2007-09-10 UTX -348 @ 74.49"
> [1] "2007-09-10 UTX 648 @ 74.49"
> [1] "2007-10-03 UTX 348 @ 79.67"
> [1] "2007-10-03 UTX -648 @ 79.67"
> [1] "2007-10-05 UTX -348 @ 80.84"
> [1] "2007-10-05 UTX 648 @ 80.84"
> [1] "2007-10-08 UTX 348 @ 80.36"
> [1] "2007-10-08 UTX -648 @ 80.36"
> [1] "2007-10-09 UTX -348 @ 81.2"
> [1] "2007-10-09 UTX 648 @ 81.2"
> [1] "2007-10-10 UTX 348 @ 80.5"
> [1] "2007-10-10 UTX -648 @ 80.5"
> [1] "2007-10-31 UTX -348 @ 76.59"
> [1] "2007-10-31 UTX 648 @ 76.59"
> [1] "2007-11-01 UTX 348 @ 74.72"
> [1] "2007-11-01 UTX -648 @ 74.72"
> [1] "2007-11-05 UTX -348 @ 76.11"
> [1] "2007-11-05 UTX 648 @ 76.11"
> [1] "2007-11-07 UTX 348 @ 74.46"
> [1] "2007-11-07 UTX -648 @ 74.46"
> [1] "2007-11-13 UTX -348 @ 75.33"
> [1] "2007-11-13 UTX 648 @ 75.33"
> [1] "2007-11-14 UTX 348 @ 74.92"
> [1] "2007-11-14 UTX -648 @ 74.92"
> [1] "2007-11-20 UTX -348 @ 74.32"
> [1] "2007-11-20 UTX 648 @ 74.32"
> [1] "2007-11-21 UTX 348 @ 72.78"
> [1] "2007-11-21 UTX -648 @ 72.78"
> [1] "2007-11-27 UTX -348 @ 74"
> [1] "2007-11-27 UTX 648 @ 74"
> [1] "2007-12-14 UTX 348 @ 76.69"
> [1] "2007-12-14 UTX -648 @ 76.69"
> [1] "2007-12-21 UTX -348 @ 77.83"
> [1] "2007-12-21 UTX 648 @ 77.83"
> [1] "2007-08-07 MSFT 648 @ 29.55"
> [1] "2007-08-07 MSFT -1000 @ 29.55"
> [1] "2007-08-09 MSFT -648 @ 29.3"
> [1] "2007-08-09 MSFT 1000 @ 29.3"
> [1] "2007-08-23 MSFT 648 @ 28.3"
> [1] "2007-08-23 MSFT -1000 @ 28.3"
> [1] "2007-08-28 MSFT -648 @ 27.93"
> [1] "2007-08-28 MSFT 1000 @ 27.93"
> [1] "2007-08-29 MSFT 648 @ 28.59"
> [1] "2007-08-29 MSFT -1000 @ 28.59"
> [1] "2007-09-05 MSFT -648 @ 28.48"
> [1] "2007-09-05 MSFT 1000 @ 28.48"
> [1] "2007-09-06 MSFT 648 @ 28.91"
> [1] "2007-09-06 MSFT -1000 @ 28.91"
> [1] "2007-09-07 MSFT -648 @ 28.44"
> [1] "2007-09-07 MSFT 1000 @ 28.44"
> [1] "2007-09-11 MSFT 648 @ 28.93"
> [1] "2007-09-11 MSFT -1000 @ 28.93"
> [1] "2007-09-17 MSFT -648 @ 28.73"
> [1] "2007-09-17 MSFT 1000 @ 28.73"
> [1] "2007-09-18 MSFT 648 @ 28.93"
> [1] "2007-09-18 MSFT -1000 @ 28.93"
> [1] "2007-09-19 MSFT -648 @ 28.67"
> [1] "2007-09-19 MSFT 1000 @ 28.67"
> [1] "2007-09-24 MSFT 648 @ 29.08"
> [1] "2007-09-24 MSFT -1000 @ 29.08"
> [1] "2007-10-19 MSFT -648 @ 30.17"
> [1] "2007-10-19 MSFT 1000 @ 30.17"
> [1] "2007-10-22 MSFT 648 @ 30.51"
> [1] "2007-10-22 MSFT -1000 @ 30.51"
> [1] "2007-11-07 MSFT -648 @ 35.52"
> [1] "2007-11-07 MSFT 1000 @ 35.52"
> [1] "2007-11-20 MSFT 648 @ 34.58"
> [1] "2007-11-20 MSFT -1000 @ 34.58"
> [1] "2007-11-26 MSFT -648 @ 32.97"
> [1] "2007-11-26 MSFT 1000 @ 32.97"
> [1] "2007-12-05 MSFT 648 @ 34.15"
> [1] "2007-12-05 MSFT -1000 @ 34.15"
> [1] "2007-12-17 MSFT -648 @ 34.39"
> [1] "2007-12-17 MSFT 1000 @ 34.39"
> [1] "2007-12-18 MSFT 648 @ 34.74"
> [1] "2007-12-18 MSFT -1000 @ 34.74"
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/quantstrat-custom-indicators-tp3491259p3493332.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From algotr8der at gmail.com  Tue May  3 23:56:06 2011
From: algotr8der at gmail.com (s)
Date: Tue, 03 May 2011 17:56:06 -0400
Subject: [R-SIG-Finance] quantstrat & custom indicators
In-Reply-To: <1304451932.30824.93.camel@brian-desktop>
References: <1304377805506-3491259.post@n4.nabble.com>	
	<1304383352.30824.47.camel@brian-desktop>
	<4DBF6562.4060201@gmail.com>	
	<1304441851002-3492994.post@n4.nabble.com>	
	<1304450930095-3493332.post@n4.nabble.com>
	<1304451932.30824.93.camel@brian-desktop>
Message-ID: <4DC079F6.8070102@gmail.com>

On 5/3/11 3:45 PM, Brian G. Peterson wrote:

Brian - thank you for the thorough detail. This all is very valuable and
I'm going to have to let this sync in my mind to help form my thinking
about the logic and the operation of this package. I do have a couple of
follow-up questions.
> If you look a the strategy object, you'll see that you have four sets of
> rules by the time you're done.  This is likely not what you want.
> Strategies should normally be agnostic to the instrument to trade, and
> you're not really doing that.
>
> I don't have time to rewrite this for you right now, but here's what I 
> suggest.
>
> build two portfolios, one for your longs, and one for your shorts
> (alternately, you could have a portfolio for each instrument, but this
> shouldn't be necessary)
>
> build one account to hold it all
>
> Have *two* strategy objects, ignoring symbols for now.  One will be your
> 'long' strategy, and one will be your 'short' strategy.  use some
> arbitrarily large order quantity for your entries and 'all' for your
> exits. (I'll explain this in a minute). have the rules use
> osFUN='osMaxPos'
>
> Use setPosLimit to set your maximum long and short position limits by
> symbol.  
I don't believe there is an argument named 'setPosLimit' for the
osMaxPos function. However, there is a function named AddPosLimit - not
sure if you are referring to that one.

Based on the documentation for osMaxPos, it seems the values set in
orderqty= should override that specified in the rule. If I should be
using AddPosLimit instead please let me know.

Here is an example, where longBasket = strategy for long positions, and
portfolio1.st is the portfolio to hold long positions.

Note: the rules have been created with osFun='osMasPos'.

longBasket <- osMaxPos(portfolio=portfolio1.st, ordertype = 'market',
orderqty='65', orderside='long', symbol='IBM')
longBasket <- osMaxPos(portfolio=portfolio1.st, ordertype = 'market',
orderqty='648', orderside='long', symbol='UTX')
shortBasket <- osMaxPos(portfolio=portfolio2.st, ordertype = 'market',
orderqty='-348', orderside='short', symbol='CAT')
shortBasket <- osMaxPos(portfolio=portfolio2.st, ordertype = 'market',
orderqty='-1000', orderside='short', symbol='MSFT')

I unfortunately am missing the timestamp named argument and R throws up
an error exception as a result:

> longBasket <- osMaxPos(portfolio=portfolio1.st, ordertype = 'market',
orderqty='65', orderside='long', symbol='IBM')
Error in paste("::", timestamp, sep = "") :
  argument "timestamp" is missing, with no default

Since in my case these maximum position limits should be enforced per
symbol at all times I'm not sure what to specify in the 'timestamp'
argument.

> This should then work as you expect when you apply the long strategy to
> the longs and the short strategy to the shorts.
>
> #############
>
> Now...  onto something more like what I suspect you're really trying to
> do ...
>
> Normally, what you'd really want to do is have a only a single strategy
> object, regardless of symbol. So forget all about the symbols when
> specifying the indicators, signals, and rules.
>
> The sophisticated part lies in (maybe) using setPosLimit or some other
> function to store things like limits/direction by symbol, and *then*
> writing a custom order sizing function.  The order sizing function gets
> a rule fire on a symbol, checks your custom metadata, and decides how
> large (if any) an order to place.
>
> You'll notice that several times in the documentation we refer to
> signals as places where you *may* want to trade.  Rules and order sizing
> functions take the *may* and can then decide to turn that into an
> affirmative trade action and also decide how much.
>
> HTH,
>
>    - Brian
>
> On Tue, 2011-05-03 at 12:28 -0700, algotr8der wrote:
>> So I changed the following:
>>
>> 1) orderqty = all 
>>
>> in all of the exit rules to 
>>
>> 2) orderqty = -numshares
>>
>> So essentially reversing the original trade. This allowed the code to
>> generate trades. I also lengthened the date range to include data from
>> 2007-07-02 to 2007-12-30 to get more data points for the test. 
>>
>> http://r.789695.n4.nabble.com/file/n3493332/basketStrategy.R
>> basketStrategy.R 
>>
>> As you can see the trades for IBM are generated based on the rule specified.
>> However, one of the trades for CAT is using the rule added to the strategy
>> for IBM (it's trading 65 shares). I'm not sure if this is the entry trade
>> because the entry trade should be a short sale of 348 shares. Instead a
>> purchase of 65 shares is made as the first ever trade for CAT. You can see
>> the same theme progress for UTX and MSFT.
>>
>> I think there is some rule overlapping going on here and its likely because
>> I am not using the features of this package correctly. If there was a way to
>> remove a rule once processing of a symbol has completed I think that might
>> work. But you guys might have more 'clean' and 'efficient' ways to think
>> about this problem.
>>
>> [1] "2007-08-10 IBM 65 @ 112.64"
>> [1] "2007-08-14 IBM -65 @ 112.05"
>> [1] "2007-08-23 IBM 65 @ 111.45"
>> [1] "2007-09-12 IBM -65 @ 116"
>> [1] "2007-09-18 IBM 65 @ 116.63"
>> [1] "2007-10-03 IBM -65 @ 116.4"
>> [1] "2007-10-08 IBM 65 @ 117.77"
>> [1] "2007-10-17 IBM -65 @ 115.78"
>> [1] "2007-10-29 IBM 65 @ 114.8"
>> [1] "2007-11-01 IBM -65 @ 113.65"
>> [1] "2007-11-02 IBM 65 @ 114.59"
>> [1] "2007-11-05 IBM -65 @ 113.4"
>> [1] "2007-11-23 IBM 65 @ 104.05"
>> [1] "2007-11-26 IBM -65 @ 101.97"
>> [1] "2007-11-27 IBM 65 @ 103.83"
>> [1] "2007-12-11 IBM -65 @ 106.99"
>> [1] "2007-12-12 IBM 65 @ 108.47"
>> [1] "2007-12-14 IBM -65 @ 105.77"
>> [1] "2007-12-20 IBM 65 @ 108.84"
>> [1] "2007-08-02 CAT 65 @ 80.67"
>> [1] "2007-08-02 CAT -348 @ 80.67"
>> [1] "2007-08-03 CAT -65 @ 78.96"
>> [1] "2007-08-03 CAT 348 @ 78.96"
>> [1] "2007-08-06 CAT 65 @ 81"
>> [1] "2007-08-06 CAT -348 @ 81"
>> [1] "2007-08-09 CAT -65 @ 78.48"
>> [1] "2007-08-09 CAT 348 @ 78.48"
>> [1] "2007-08-23 CAT 65 @ 75.17"
>> [1] "2007-08-23 CAT -348 @ 75.17"
>> [1] "2007-08-28 CAT -65 @ 74.16"
>> [1] "2007-08-28 CAT 348 @ 74.16"
>> [1] "2007-08-29 CAT 65 @ 75.04"
>> [1] "2007-08-29 CAT -348 @ 75.04"
>> [1] "2007-08-30 CAT -65 @ 74.66"
>> [1] "2007-08-30 CAT 348 @ 74.66"
>> [1] "2007-08-31 CAT 65 @ 75.77"
>> [1] "2007-08-31 CAT -348 @ 75.77"
>> [1] "2007-09-07 CAT -65 @ 73.44"
>> [1] "2007-09-07 CAT 348 @ 73.44"
>> [1] "2007-09-18 CAT 65 @ 77.46"
>> [1] "2007-09-18 CAT -348 @ 77.46"
>> [1] "2007-10-11 CAT -65 @ 79.44"
>> [1] "2007-10-11 CAT 348 @ 79.44"
>> [1] "2007-10-12 CAT 65 @ 80.3"
>> [1] "2007-10-12 CAT -348 @ 80.3"
>> [1] "2007-10-15 CAT -65 @ 78.84"
>> [1] "2007-10-15 CAT 348 @ 78.84"
>> [1] "2007-11-02 CAT 65 @ 74.76"
>> [1] "2007-11-02 CAT -348 @ 74.76"
>> [1] "2007-11-05 CAT -65 @ 73.5"
>> [1] "2007-11-05 CAT 348 @ 73.5"
>> [1] "2007-11-06 CAT 65 @ 74.92"
>> [1] "2007-11-06 CAT -348 @ 74.92"
>> [1] "2007-11-07 CAT -65 @ 73.6"
>> [1] "2007-11-07 CAT 348 @ 73.6"
>> [1] "2007-11-28 CAT 65 @ 71.19"
>> [1] "2007-11-28 CAT -348 @ 71.19"
>> [1] "2007-12-14 CAT -65 @ 73.39"
>> [1] "2007-12-14 CAT 348 @ 73.39"
>> [1] "2007-12-24 CAT 65 @ 72.7"
>> [1] "2007-12-24 CAT -348 @ 72.7"
>> [1] "2007-08-02 UTX -348 @ 74.76"
>> [1] "2007-08-02 UTX 648 @ 74.76"
>> [1] "2007-08-03 UTX 348 @ 73.93"
>> [1] "2007-08-03 UTX -648 @ 73.93"
>> [1] "2007-08-06 UTX -348 @ 74.85"
>> [1] "2007-08-06 UTX 648 @ 74.85"
>> [1] "2007-08-07 UTX 348 @ 74.15"
>> [1] "2007-08-07 UTX -648 @ 74.15"
>> [1] "2007-08-13 UTX -348 @ 74.01"
>> [1] "2007-08-13 UTX 648 @ 74.01"
>> [1] "2007-08-14 UTX 348 @ 72.78"
>> [1] "2007-08-14 UTX -648 @ 72.78"
>> [1] "2007-08-17 UTX -348 @ 73.82"
>> [1] "2007-08-17 UTX 648 @ 73.82"
>> [1] "2007-08-21 UTX 348 @ 72.94"
>> [1] "2007-08-21 UTX -648 @ 72.94"
>> [1] "2007-08-22 UTX -348 @ 73.87"
>> [1] "2007-08-22 UTX 648 @ 73.87"
>> [1] "2007-08-28 UTX 348 @ 72"
>> [1] "2007-08-28 UTX -648 @ 72"
>> [1] "2007-08-29 UTX -348 @ 74.35"
>> [1] "2007-08-29 UTX 648 @ 74.35"
>> [1] "2007-09-05 UTX 348 @ 73.45"
>> [1] "2007-09-05 UTX -648 @ 73.45"
>> [1] "2007-09-06 UTX -348 @ 75.01"
>> [1] "2007-09-06 UTX 648 @ 75.01"
>> [1] "2007-09-07 UTX 348 @ 73.79"
>> [1] "2007-09-07 UTX -648 @ 73.79"
>> [1] "2007-09-10 UTX -348 @ 74.49"
>> [1] "2007-09-10 UTX 648 @ 74.49"
>> [1] "2007-10-03 UTX 348 @ 79.67"
>> [1] "2007-10-03 UTX -648 @ 79.67"
>> [1] "2007-10-05 UTX -348 @ 80.84"
>> [1] "2007-10-05 UTX 648 @ 80.84"
>> [1] "2007-10-08 UTX 348 @ 80.36"
>> [1] "2007-10-08 UTX -648 @ 80.36"
>> [1] "2007-10-09 UTX -348 @ 81.2"
>> [1] "2007-10-09 UTX 648 @ 81.2"
>> [1] "2007-10-10 UTX 348 @ 80.5"
>> [1] "2007-10-10 UTX -648 @ 80.5"
>> [1] "2007-10-31 UTX -348 @ 76.59"
>> [1] "2007-10-31 UTX 648 @ 76.59"
>> [1] "2007-11-01 UTX 348 @ 74.72"
>> [1] "2007-11-01 UTX -648 @ 74.72"
>> [1] "2007-11-05 UTX -348 @ 76.11"
>> [1] "2007-11-05 UTX 648 @ 76.11"
>> [1] "2007-11-07 UTX 348 @ 74.46"
>> [1] "2007-11-07 UTX -648 @ 74.46"
>> [1] "2007-11-13 UTX -348 @ 75.33"
>> [1] "2007-11-13 UTX 648 @ 75.33"
>> [1] "2007-11-14 UTX 348 @ 74.92"
>> [1] "2007-11-14 UTX -648 @ 74.92"
>> [1] "2007-11-20 UTX -348 @ 74.32"
>> [1] "2007-11-20 UTX 648 @ 74.32"
>> [1] "2007-11-21 UTX 348 @ 72.78"
>> [1] "2007-11-21 UTX -648 @ 72.78"
>> [1] "2007-11-27 UTX -348 @ 74"
>> [1] "2007-11-27 UTX 648 @ 74"
>> [1] "2007-12-14 UTX 348 @ 76.69"
>> [1] "2007-12-14 UTX -648 @ 76.69"
>> [1] "2007-12-21 UTX -348 @ 77.83"
>> [1] "2007-12-21 UTX 648 @ 77.83"
>> [1] "2007-08-07 MSFT 648 @ 29.55"
>> [1] "2007-08-07 MSFT -1000 @ 29.55"
>> [1] "2007-08-09 MSFT -648 @ 29.3"
>> [1] "2007-08-09 MSFT 1000 @ 29.3"
>> [1] "2007-08-23 MSFT 648 @ 28.3"
>> [1] "2007-08-23 MSFT -1000 @ 28.3"
>> [1] "2007-08-28 MSFT -648 @ 27.93"
>> [1] "2007-08-28 MSFT 1000 @ 27.93"
>> [1] "2007-08-29 MSFT 648 @ 28.59"
>> [1] "2007-08-29 MSFT -1000 @ 28.59"
>> [1] "2007-09-05 MSFT -648 @ 28.48"
>> [1] "2007-09-05 MSFT 1000 @ 28.48"
>> [1] "2007-09-06 MSFT 648 @ 28.91"
>> [1] "2007-09-06 MSFT -1000 @ 28.91"
>> [1] "2007-09-07 MSFT -648 @ 28.44"
>> [1] "2007-09-07 MSFT 1000 @ 28.44"
>> [1] "2007-09-11 MSFT 648 @ 28.93"
>> [1] "2007-09-11 MSFT -1000 @ 28.93"
>> [1] "2007-09-17 MSFT -648 @ 28.73"
>> [1] "2007-09-17 MSFT 1000 @ 28.73"
>> [1] "2007-09-18 MSFT 648 @ 28.93"
>> [1] "2007-09-18 MSFT -1000 @ 28.93"
>> [1] "2007-09-19 MSFT -648 @ 28.67"
>> [1] "2007-09-19 MSFT 1000 @ 28.67"
>> [1] "2007-09-24 MSFT 648 @ 29.08"
>> [1] "2007-09-24 MSFT -1000 @ 29.08"
>> [1] "2007-10-19 MSFT -648 @ 30.17"
>> [1] "2007-10-19 MSFT 1000 @ 30.17"
>> [1] "2007-10-22 MSFT 648 @ 30.51"
>> [1] "2007-10-22 MSFT -1000 @ 30.51"
>> [1] "2007-11-07 MSFT -648 @ 35.52"
>> [1] "2007-11-07 MSFT 1000 @ 35.52"
>> [1] "2007-11-20 MSFT 648 @ 34.58"
>> [1] "2007-11-20 MSFT -1000 @ 34.58"
>> [1] "2007-11-26 MSFT -648 @ 32.97"
>> [1] "2007-11-26 MSFT 1000 @ 32.97"
>> [1] "2007-12-05 MSFT 648 @ 34.15"
>> [1] "2007-12-05 MSFT -1000 @ 34.15"
>> [1] "2007-12-17 MSFT -648 @ 34.39"
>> [1] "2007-12-17 MSFT 1000 @ 34.39"
>> [1] "2007-12-18 MSFT 648 @ 34.74"
>> [1] "2007-12-18 MSFT -1000 @ 34.74"
>>
>> --
>> View this message in context: http://r.789695.n4.nabble.com/quantstrat-custom-indicators-tp3491259p3493332.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.


From algotr8der at gmail.com  Wed May  4 01:36:11 2011
From: algotr8der at gmail.com (algotr8der)
Date: Tue, 3 May 2011 16:36:11 -0700 (PDT)
Subject: [R-SIG-Finance] quantstrat & custom indicators
In-Reply-To: <4DC079F6.8070102@gmail.com>
References: <1304377805506-3491259.post@n4.nabble.com>
	<1304383352.30824.47.camel@brian-desktop>
	<4DBF6562.4060201@gmail.com>
	<1304441851002-3492994.post@n4.nabble.com>
	<1304450930095-3493332.post@n4.nabble.com>
	<1304451932.30824.93.camel@brian-desktop>
	<4DC079F6.8070102@gmail.com>
Message-ID: <1304465771170-3493901.post@n4.nabble.com>

So I re-wrote the code to accommodate 2 portfolio objects, 2 strategy objects
and rules that utilize position limits. Unfortunately, I cant seem to get it
working. I've used debug() to walk through applyRules (and other functions)
and for some reason it doesnt seem to be checking for position limits (or at
least not that I can determine).

I have attached a copy of my code. It is fairly clean to read. If anyone
wants to take a stab at running it I would be grateful. 

http://r.789695.n4.nabble.com/file/n3493901/basketStrategy.R
basketStrategy.R 


> out<-try(applyStrategy(strategy=longBasket, portfolios=portfolio1.st))
[1] "2007-08-10 IBM 10000 @ 112.64"
Error in orderqty == 0 : 
  comparison (1) is possible only for atomic and list types
In addition: Warning messages:
1: In match.names(columns, colnames(data)) :
  all columns not located in Close ma10 for IBM.Open IBM.High IBM.Low
IBM.Close IBM.Volume IBM.Adjusted ma10 close.gt.ma10
2: In max(i) : no non-missing arguments to max; returning -Inf
> 




--
View this message in context: http://r.789695.n4.nabble.com/quantstrat-custom-indicators-tp3491259p3493901.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From bbands at gmail.com  Wed May  4 02:05:55 2011
From: bbands at gmail.com (BBands)
Date: Tue, 3 May 2011 17:05:55 -0700
Subject: [R-SIG-Finance] Expected lengths of streaks
Message-ID: <BANLkTi=ToyN2ZZYHgpafSuaDPk0wQRoXdw@mail.gmail.com>

About 1,000 years ago I calculated the expected length of a losing
streak by iterative simulation using rle

    trades <- sample(c("W", "L"), 1000, replace = TRUE, prob =
c("0.66", "0.33"))
    trades.rle <- rle(trades)
    tapply(trades.rle$lengths, trades.rle$values, max)

There must be other, better ways today...

    jab
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.


From markleeds2 at gmail.com  Wed May  4 02:39:38 2011
From: markleeds2 at gmail.com (Mark Leeds)
Date: Tue, 3 May 2011 20:39:38 -0400
Subject: [R-SIG-Finance] Expected lengths of streaks
In-Reply-To: <BANLkTi=ToyN2ZZYHgpafSuaDPk0wQRoXdw@mail.gmail.com>
References: <BANLkTi=ToyN2ZZYHgpafSuaDPk0wQRoXdw@mail.gmail.com>
Message-ID: <BANLkTimvg+L6cjzG3gdorPk_1saT2pEVRg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110503/da3b8292/attachment.pl>

From bbands at gmail.com  Wed May  4 16:56:51 2011
From: bbands at gmail.com (BBands)
Date: Wed, 4 May 2011 07:56:51 -0700
Subject: [R-SIG-Finance]  Expected lengths of streaks
In-Reply-To: <BANLkTikuC3fbCoYD1CwvnArMqErwq5huxA@mail.gmail.com>
References: <BANLkTi=ToyN2ZZYHgpafSuaDPk0wQRoXdw@mail.gmail.com>
	<BANLkTimvg+L6cjzG3gdorPk_1saT2pEVRg@mail.gmail.com>
	<BANLkTikuC3fbCoYD1CwvnArMqErwq5huxA@mail.gmail.com>
Message-ID: <BANLkTimiBmTGVofF_pCLtZzXFhy31qkw7w@mail.gmail.com>

On Tue, May 3, 2011 at 5:39 PM, Mark Leeds <markleeds2 at gmail.com> wrote:
> hi john:
>
> I'm not clear on whether you want expected value of the max length or the
> expected value
> of the length. but, if you want the latter in closed form and you know , p,
> the probability of sucess ( in your case , the probability of winning
> trade), then the number of trials before you win ( so the length would be
> the number of losses )? can be thought as having a geometric distribution.
> this distribution has expected value of (1-p)/p. and no, I definitely had to
> look that up because I didn't remember the formula.
>
> I'm not sure how one would handle the expected value of the max length
> analytically. maybe
> simulation is the only way but you might be able to do it faster using the
> analytical result above.

Hi Mark, nice chatting with you at R/Finance.

The nice thing about doing this by simulation using rle is that it
lets you model "Pushes" as well. I define a Push as a win or loss so
small as to be noise. This lets me focus more clearly on the actual
wins and losses that are contributing to performance. I hinted at this
when I spoke about a three-state logic in my presentation.

> Trades <- sample(c("W", "P", "L"), 1000000, replace = TRUE, prob = c("0.60", "0.10", "0.30"))
> TradesRle <- rle(Trades)
> tapply(TradesRle$lengths, TradesRle$values, max)
?L ?P ?W
11 ?6 25

I accumulate those over a large number of trials and use the means as
my expected run lengths. If the account cannot withstand an expected
run of losses the system will fail eventually in the real world. I
wrote that simulation long ago and was wondering if there was a better
way today.

? ?jab
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.


From algotr8der at gmail.com  Thu May  5 01:05:22 2011
From: algotr8der at gmail.com (algotr8der)
Date: Wed, 4 May 2011 16:05:22 -0700 (PDT)
Subject: [R-SIG-Finance] quantstrat & custom indicators
In-Reply-To: <1304544124079-3496840.post@n4.nabble.com>
References: <1304383352.30824.47.camel@brian-desktop>
	<4DBF6562.4060201@gmail.com>
	<1304441851002-3492994.post@n4.nabble.com>
	<1304450930095-3493332.post@n4.nabble.com>
	<1304451932.30824.93.camel@brian-desktop>
	<4DC079F6.8070102@gmail.com>
	<1304465771170-3493901.post@n4.nabble.com>
	<1304540702864-3496710.post@n4.nabble.com>
	<1304543276291-3496808.post@n4.nabble.com>
	<1304544124079-3496840.post@n4.nabble.com>
Message-ID: <1304550322871-3497029.post@n4.nabble.com>

Hi gsee,

Thank you kindly for spending the time to look at my code and making the
appropriate changes. The challenge for me is that I am new to
blotter/quantstrat and have only used R for the past 1.5 months. Thank you
all for you patience.

I just ran your new code and it generates the trades as I would expect based
on the rules. :)

I did get warnings after executing 'applyStrategy' on both the long and
short strategies (please see below). I don't know whether these warnings are
benign or serious in nature.

In any case I am now in a position to continue my research. 

I do think this strategy highlights use cases that could be beneficial for
users. Perhaps we can include the code for this strategy (or some variant
of) more formally as a demo in the documentation i.e. a long / short
portfolio strategy.


Warning messages:
1: In match.names(columns, colnames(data)) :
  all columns not located in Close ma10 for IBM.Open IBM.High IBM.Low
IBM.Close IBM.Volume IBM.Adjusted ma10 close.gt.ma10
2: In max(i) : no non-missing arguments to max; returning -Inf
3: In min(dindex[dindex > curIndex]) :
  no non-missing arguments to min; returning Inf
4: In match.names(columns, colnames(data)) :
  all columns not located in Close ma10 for UTX.Open UTX.High UTX.Low
UTX.Close UTX.Volume UTX.Adjusted ma10 close.gt.ma10
5: In max(i) : no non-missing arguments to max; returning -Inf
6: In min(dindex[dindex > curIndex]) :
  no non-missing arguments to min; returning Inf


Warning messages:
1: In match.names(columns, colnames(data)) :
  all columns not located in Close ma10 for CAT.Open CAT.High CAT.Low
CAT.Close CAT.Volume CAT.Adjusted ma10 close.gt.ma10
2: In max(i) : no non-missing arguments to max; returning -Inf
3: In min(dindex[dindex > curIndex]) :
  no non-missing arguments to min; returning Inf
4: In match.names(columns, colnames(data)) :
  all columns not located in Close ma10 for MSFT.Open MSFT.High MSFT.Low
MSFT.Close MSFT.Volume MSFT.Adjusted ma10 close.gt.ma10
5: In max(i) : no non-missing arguments to max; returning -Inf
6: In min(dindex[dindex > curIndex]) :
  no non-missing arguments to min; returning Inf


--
View this message in context: http://r.789695.n4.nabble.com/quantstrat-custom-indicators-tp3491259p3497029.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From massimo.salese at gmail.com  Thu May  5 11:49:16 2011
From: massimo.salese at gmail.com (msalese)
Date: Thu, 5 May 2011 02:49:16 -0700 (PDT)
Subject: [R-SIG-Finance] quantmod/Rmetrics-timeSeries and
	RQuantLib/Rmetrics-fOptions ?
Message-ID: <1304588956743-3497966.post@n4.nabble.com>

Hi guys,
I'm a no-pro option trader and I'm learning to use R + packages that can
help me to do better analysis and quit spreadsheets.
I bought the book "R in a Nutshell" and booked the on-line classes from
statistics.com on R language  (introduction classes will start on 20 of
May).

There are some doubts on which I need some help, I'm going to spent a lot of
time on learning steeps and R has a lot of packages for time series analysis
and options, the point is on which packages it's better to stay focused ?
a. quantmod or timeSeries/Rmetrics ?
b. RQuantLib or fOptions/Rmetrics ?
c. Do you recommend eBooks from Rmetrics ?

Thanks very much
Massimo


--
View this message in context: http://r.789695.n4.nabble.com/quantmod-Rmetrics-timeSeries-and-RQuantLib-Rmetrics-fOptions-tp3497966p3497966.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Thu May  5 13:33:48 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 05 May 2011 06:33:48 -0500
Subject: [R-SIG-Finance] quantmod/Rmetrics-timeSeries and
 RQuantLib/Rmetrics-fOptions ?
In-Reply-To: <1304588956743-3497966.post@n4.nabble.com>
References: <1304588956743-3497966.post@n4.nabble.com>
Message-ID: <1304595228.2156.126.camel@brian-desktop>

On Thu, 2011-05-05 at 02:49 -0700, msalese wrote:
> Hi guys,
> I'm a no-pro option trader and I'm learning to use R + packages that can
> help me to do better analysis and quit spreadsheets.
> I bought the book "R in a Nutshell" and booked the on-line classes from
> statistics.com on R language  (introduction classes will start on 20 of
> May).

Paul Teetor's book is excellent as well: 'R Cookbook'

I can't speak to the quality or lack thereof of any commercial R
training.  When evaluating it, I would suggest that you evaluate the
published contributions of the author or instructor to R.

> There are some doubts on which I need some help, I'm going to spent a lot of
> time on learning steeps and R has a lot of packages for time series analysis
> and options, the point is on which packages it's better to stay focused ?
> a. quantmod or timeSeries/Rmetrics ?

These are very different things.

Rmetrics has a huge number of functions, many of them useful.  For
those, you will need timeSeries data.

xts is the fastest, highest capacity time series class in R. Many of us
use xts with huge amounts of tick data (tens of billions of
observations).  This is observable, verifiable, fact. Period. xts is
also most easily convertible to and from other time series classes and
other R object types so that you can most easily use other packages in
R.

quantmod is mostly used for the excellent charting chartSeries and
chart_Series addTA/add_TA.  getSymbols is also extremely useful, even
with custom proprietary data sources.
  
> b. RQuantLib or fOptions/Rmetrics ?

fOptions is likely easier to learn, in no small part because of the
ebooks you mention below.  As with all of the Rmetrics suite, it is
primarily aimed at *teaching* and *research*, not necessarily
application to real markets.

quantlib and RQuantlib are widely reviewed and used by many
institutional investors, so you can believe that the calculations in the
quantlib library have been extensively checked for correctness.

> c. Do you recommend eBooks from Rmetrics ?

The portfolio optimization book, the only one I have a copy of, is good
as far as it goes, but lacks more advanced topics.

HTH,

 - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From algotr8der at gmail.com  Thu May  5 20:18:53 2011
From: algotr8der at gmail.com (algotr8der)
Date: Thu, 5 May 2011 11:18:53 -0700 (PDT)
Subject: [R-SIG-Finance] EndEquity lower than initEq despite positive p/l
Message-ID: <1304619533742-3499089.post@n4.nabble.com>

-I back tested a basket (long / short) strategy from 2007-07-01 to 2010-07-30
using TWO portfolios. 
-I created an account that holds the TWO portfolio's
-I set the initEq = 100,000 (see attribute 'initEq' in the snippet output of
getAccounts() below).

2010-07-27            0.00 34818.13
2010-07-28            0.00 34818.13
2010-07-29            0.00 34818.13
2010-07-30            0.00 34818.13

attr(,"currency")
[1] "USD"
attr(,"initEq")
[1] 1e+05
attr(,"class")
[1] "portfolio_account" "account"

-The End equity is = 34818.13 after running updatePortf, updateAcct, and
updateEndEq, 

> getEndEq(Account=account.st, Date='2010-07-31')
[1] 34818.13

-However, the net P/L is positive, and you can see that in the output of
tradeStats for each symbol in the basket (see file below). If you add the
Net.Trading.PL.2 parameter for each symbol you get a total p/l = 34,818.13,
which is equal to the End Equity. 

http://r.789695.n4.nabble.com/file/n3499089/tradeStats_output.txt
tradeStats_output.txt 

-You can also see the equity curve as per the output of
'charts.PerformanceSummary' (see file below).

charts.PerformanceSummary(ROC(getAccount(account.st)$summary$End.Eq)[-1],
main="Basket Strategy Return")

http://r.789695.n4.nabble.com/file/n3499089/BasketStrategyReturn.pdf
BasketStrategyReturn.pdf 

For some reason it appears that the starting equity is = 0 instead of
100,000.

Perhaps I have missed a step that is required to set the initEq = 100,000. I
created the account with argument initEq = 100000.

> initEq
[1] 1e+05

initAcct(account.st, portfolios=allportfolios, initDate=initDate,
initEq=initEq)

Appreciate some guidance.


--
View this message in context: http://r.789695.n4.nabble.com/EndEquity-lower-than-initEq-despite-positive-p-l-tp3499089p3499089.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From paulteetor at yahoo.com  Thu May  5 20:44:05 2011
From: paulteetor at yahoo.com (Paul Teetor)
Date: Thu, 5 May 2011 13:44:05 -0500
Subject: [R-SIG-Finance] R, Finance, and Statistical Computing at JSM
Message-ID: <DD44F8008C2C47D9B2FDF3FCF1B48E11@XI>

R/Finance community:
 
The Joint Statistical Meetings (JSM) conference will be held in Miami Beach,
Florida this summer. I hope you will join me for the Roundtable discussion
entitled "R, Finance, and Statistical Computing." It will be a great
opportunity to discuss what we're doing with R in quantitative finance and
what challenges we are tackling.
 
The Roundtable will be held over lunch on Tuesday. Simply select the
Roundtable when you register on-line for JSM at
http://www.amstat.org/jsmregistration.
 
See you in Miami Beach!
 
Paul
 
 
Paul Teetor
Elgin, IL   USA
http://www.linkedin.com/in/paulteetor
 
"For quant traders, there are no bad days in the market. It's just more
data."


From algotr8der at gmail.com  Fri May  6 00:23:10 2011
From: algotr8der at gmail.com (algotr8der)
Date: Thu, 5 May 2011 15:23:10 -0700 (PDT)
Subject: [R-SIG-Finance] EndEquity lower than initEq despite positive p/l
In-Reply-To: <1304620241723-3499116.post@n4.nabble.com>
References: <1304619533742-3499089.post@n4.nabble.com>
	<1304620241723-3499116.post@n4.nabble.com>
Message-ID: <1304634190942-3499834.post@n4.nabble.com>

It seems a bit buggy. 

If I re-set the initEq variable and then execute getAccount() it seems the
initial equity is captured correctly. However, for some reason it fails to
read this variable despite the fact that it is set and supplied as an
argument in initAcct() when the account is first created. 

I've tinkered around with this some more this afternoon and I noticed that
it does not happen all the time. I'm trying to narrow down the circumstances
that lead to this problem. I will provide further details when I find out
more.



--
View this message in context: http://r.789695.n4.nabble.com/EndEquity-lower-than-initEq-despite-positive-p-l-tp3499089p3499834.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From rhelpacc at gmail.com  Fri May  6 02:47:31 2011
From: rhelpacc at gmail.com (Robert A'gata)
Date: Thu, 5 May 2011 20:47:31 -0400
Subject: [R-SIG-Finance] Aggregating time series to every 30sec
Message-ID: <BANLkTinC=M6K=Q2BOues649SKFRdQzKgQA@mail.gmail.com>

Hi,

I have an irregular return time series that looks like below:

> head(r.xts)
                             [,1]
2011-05-05 09:30:04.929 0.3264757
2011-05-05 09:30:14.907 0.0934498
2011-05-05 09:30:19.917 0.8956367
2011-05-05 09:30:35.114 1.6632110
2011-05-05 09:30:45.193 1.1666715
2011-05-05 09:31:12.417 0.2861861

I'd like to sum them for every 30-second bucket such that the output
looks like below. The key is that I want to aggregate every 30 seconds
by clock time NOT 30 seconds starting from my first observation time
stamp. rollapply does not satisfy my objective as it takes number of
rows instead. to.period function doesn't seem to let me specify that I
want to start at 09:30 and sum returns every 30 seconds. I'm wondering
if there's any tool that I can achieve this?

2011-05-05 09:30:00   1.316
2011-05-05 09:30:30   ...
2011-05-05 09:31:00   ...

Thank you in advance.

Cheers,

Robert


From algotr8der at gmail.com  Fri May  6 02:51:22 2011
From: algotr8der at gmail.com (algotr8der)
Date: Thu, 5 May 2011 17:51:22 -0700 (PDT)
Subject: [R-SIG-Finance] EndEquity lower than initEq despite positive p/l
In-Reply-To: <1304634190942-3499834.post@n4.nabble.com>
References: <1304619533742-3499089.post@n4.nabble.com>
	<1304620241723-3499116.post@n4.nabble.com>
	<1304634190942-3499834.post@n4.nabble.com>
Message-ID: <1304643082257-3500326.post@n4.nabble.com>

Okay - here is a bogus strategy just to test this -

http://r.789695.n4.nabble.com/file/n3500326/bogusStrategy.R bogusStrategy.R 

a) portfolio_1 = IBM, UTX, CAT

b) portfolio_2 = MSFT

Indicators = 10 DSMA, 15 DSMA, 20 DSMA

Rules

a) if 10_DSMA Crosses Above 20_DSMA BUY stocks in portfolio_1 AND COVER
existing SHORTS in portfolio_1
b) if 10_DSMA Crosses Below 20_DSMA SELL existing long positions in
portfolio_1 AND SHORT all stocks in portfolio_1

c) if 15_DSMA Crosses Above 20_DSMA BUY stocks in portfolio_2 AND COVER
existing SHORTS in portfolio_2
d) if 15_DSMA Crosses Below 20_DSMA SELL existing long positions in
portfolio_2 AND SHORT all stocks in portfolio_2

Once you have updated the portfolios and accounts type the following:

> getAccounts(account.st)

Look at the 'End.Eq' column (this is the last column). You will see that the
portfolio begins with 0 as the initial value and each day's p/l is added to
0 until the last day.

2010-07-02         -989.49  85836.10

Maybe I am misunderstanding something but it appears to me that the p/l of
this strategy = 85836.10 and so that amount should be added to the initEq. 

In my real strategy I know the p/l is ~34800, which should be added to the
initEq.






--
View this message in context: http://r.789695.n4.nabble.com/EndEquity-lower-than-initEq-despite-positive-p-l-tp3499089p3500326.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From jeffrey.ryan at lemnica.com  Fri May  6 03:50:15 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Thu, 5 May 2011 20:50:15 -0500
Subject: [R-SIG-Finance] Aggregating time series to every 30sec
In-Reply-To: <BANLkTinC=M6K=Q2BOues649SKFRdQzKgQA@mail.gmail.com>
References: <BANLkTinC=M6K=Q2BOues649SKFRdQzKgQA@mail.gmail.com>
Message-ID: <BANLkTinPen35vcvkgDmzs49+MM8X++EAZw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110505/d8258dcc/attachment.pl>

From rhelpacc at gmail.com  Fri May  6 03:54:09 2011
From: rhelpacc at gmail.com (Robert A'gata)
Date: Thu, 5 May 2011 21:54:09 -0400
Subject: [R-SIG-Finance] Aggregating time series to every 30sec
In-Reply-To: <BANLkTinPen35vcvkgDmzs49+MM8X++EAZw@mail.gmail.com>
References: <BANLkTinC=M6K=Q2BOues649SKFRdQzKgQA@mail.gmail.com>
	<BANLkTinPen35vcvkgDmzs49+MM8X++EAZw@mail.gmail.com>
Message-ID: <BANLkTi=Wig9OKxz2peibEUNRmtKyWT+osg@mail.gmail.com>

Thank you so much Jeff! This is exactly what I'm looking for.

On Thu, May 5, 2011 at 9:50 PM, Jeffrey Ryan <jeffrey.ryan at lemnica.com> wrote:
> Something like this should work:
> r.xts <- read.table(textConnection("
> 2011-05-05 09:30:04.929 0.3264757
> 2011-05-05 09:30:14.907 0.0934498
> 2011-05-05 09:30:19.917 0.8956367
> 2011-05-05 09:30:35.114 1.6632110
> 2011-05-05 09:30:45.193 1.1666715
> 2011-05-05 09:31:12.417 0.2861861"))
> r.xts
> ?? ? ? ? ?V1 ? ? ? ? ? V2 ? ? ? ?V3
> 1 2011-05-05 09:30:04.929 0.3264757
> 2 2011-05-05 09:30:14.907 0.0934498
> 3 2011-05-05 09:30:19.917 0.8956367
> 4 2011-05-05 09:30:35.114 1.6632110
> 5 2011-05-05 09:30:45.193 1.1666715
> 6 2011-05-05 09:31:12.417 0.2861861
> r.xts <- xts(r.xts$V3, as.POSIXct(paste(r.xts$V1,r.xts$V2)))
> r.xts
> ?? ? ? ? ? ? ? ? ? ? ? ? [,1]
> 2011-05-05 09:30:04 0.3264757
> 2011-05-05 09:30:14 0.0934498
> 2011-05-05 09:30:19 0.8956367
> 2011-05-05 09:30:35 1.6632110
> 2011-05-05 09:30:45 1.1666715
> 2011-05-05 09:31:12 0.2861861
> align.time(period.sum(r.xts,endpoints(r.xts,'secs',k=30)),30)
> ?? ? ? ? ? ? ? ? ? ? ? ? [,1]
> 2011-05-05 09:30:30 1.3155622
> 2011-05-05 09:31:00 2.8298825
> 2011-05-05 09:31:30 0.2861861
> ?endpoints to find the 30m endpoints in time
> ?period.sum (or period.apply) to sum up by period
> ?align.time to fix/round the times to something a little more even
> HTH
> Jeff
> On Thu, May 5, 2011 at 7:47 PM, Robert A'gata <rhelpacc at gmail.com> wrote:
>>
>> Hi,
>>
>> I have an irregular return time series that looks like below:
>>
>> > head(r.xts)
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? [,1]
>> 2011-05-05 09:30:04.929 0.3264757
>> 2011-05-05 09:30:14.907 0.0934498
>> 2011-05-05 09:30:19.917 0.8956367
>> 2011-05-05 09:30:35.114 1.6632110
>> 2011-05-05 09:30:45.193 1.1666715
>> 2011-05-05 09:31:12.417 0.2861861
>>
>> I'd like to sum them for every 30-second bucket such that the output
>> looks like below. The key is that I want to aggregate every 30 seconds
>> by clock time NOT 30 seconds starting from my first observation time
>> stamp. rollapply does not satisfy my objective as it takes number of
>> rows instead. to.period function doesn't seem to let me specify that I
>> want to start at 09:30 and sum returns every 30 seconds. I'm wondering
>> if there's any tool that I can achieve this?
>>
>> 2011-05-05 09:30:00 ? 1.316
>> 2011-05-05 09:30:30 ? ...
>> 2011-05-05 09:31:00 ? ...
>>
>> Thank you in advance.
>>
>> Cheers,
>>
>> Robert
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>
>
> --
> Jeffrey Ryan
> jeffrey.ryan at lemnica.com
>
> www.lemnica.com
>
> R/Finance 2011 April 29th and 30th in Chicago | www.RinFinance.com
>
>


From massimo.salese at gmail.com  Fri May  6 09:51:32 2011
From: massimo.salese at gmail.com (msalese)
Date: Fri, 6 May 2011 00:51:32 -0700 (PDT)
Subject: [R-SIG-Finance] quantmod/Rmetrics-timeSeries and
	RQuantLib/Rmetrics-fOptions ?
In-Reply-To: <1304595228.2156.126.camel@brian-desktop>
References: <1304588956743-3497966.post@n4.nabble.com>
	<1304595228.2156.126.camel@brian-desktop>
Message-ID: <1304668292061-3501585.post@n4.nabble.com>

Thanks for very deep advice.
Well I think that for first I'll stay with RMetrics for two reason:

first: I'm not a pro like You so my analysis  is based on one day sampling
time series and daily range.
This mean that even if xts is fastest, for my work timeSeries/Rmetrics
should be enough !

second: RMetrics organize a lot of events (like seminaries and lectures) in
Switzerland and Austria not so far from Milan where I live.

You got me, I saw the "R Cookbook" in book shop and I'm planning to buy it
with RMetrics/eBooks this Saturday.

I'm just working on R and reading help on RMetrics library now  so when the
lectures on statistics.com will start for me will be like a repetition
(repetita juvant !).

Thanks very much
Massimo






--
View this message in context: http://r.789695.n4.nabble.com/quantmod-Rmetrics-timeSeries-and-RQuantLib-Rmetrics-fOptions-tp3497966p3501585.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From markknecht at gmail.com  Fri May  6 17:58:10 2011
From: markknecht at gmail.com (Mark Knecht)
Date: Fri, 6 May 2011 08:58:10 -0700
Subject: [R-SIG-Finance] quantmod/Rmetrics-timeSeries and
 RQuantLib/Rmetrics-fOptions ?
In-Reply-To: <1304595228.2156.126.camel@brian-desktop>
References: <1304588956743-3497966.post@n4.nabble.com>
	<1304595228.2156.126.camel@brian-desktop>
Message-ID: <BANLkTimdHXWMnBc7+4yNHak3E5GVFJj4HQ@mail.gmail.com>

On Thu, May 5, 2011 at 4:33 AM, Brian G. Peterson <brian at braverock.com> wrote:
> On Thu, 2011-05-05 at 02:49 -0700, msalese wrote:
>> Hi guys,
>> I'm a no-pro option trader and I'm learning to use R + packages that can
>> help me to do better analysis and quit spreadsheets.
>> I bought the book "R in a Nutshell" and booked the on-line classes from
>> statistics.com on R language ?(introduction classes will start on 20 of
>> May).
>
> Paul Teetor's book is excellent as well: 'R Cookbook'
>

++ for 'R Cookbook', and note that on Amazon the Kindle version was
less than $18 vs. $33 for real paper so a nice opportunity to save a
tree if one is so inclined.

- Mark


From garychin9 at gmail.com  Fri May  6 18:09:54 2011
From: garychin9 at gmail.com (Gary C)
Date: Sat, 7 May 2011 00:09:54 +0800
Subject: [R-SIG-Finance] nabble.com r-sig-finance/Rmetrics mailing list
	- wrong email address
In-Reply-To: <BANLkTi=0afuFtrF9Bh-buUAgZKTpZ444BQ@mail.gmail.com>
References: <BANLkTi=0afuFtrF9Bh-buUAgZKTpZ444BQ@mail.gmail.com>
Message-ID: <BANLkTinMZkK+OZvPbTtXVWH2mkHwMXh8hw@mail.gmail.com>

reply this email from my email.

On Mon, Apr 25, 2011 at 3:52 PM, Gary Chin <garychin9 at gmail.com> wrote:
> Hi there,
>
> Nabble.com has an archive of r-sig-finance mailing list
> http://r.789695.n4.nabble.com/Rmetrics-f925806.html
>
> Nabble registered users can subscribe mailing list there and also able
> to post after subscribed.
>
> However, I find that at the section of r-sig-finance / Rmetrics, both
> the subscribe and posting email are wrong.
>
> It is r-sig-finance at r-project.org , NOT r-sig-finance at stat.math.ethz.ch.
>
> if anyone who has authorization to change it, please do so.
>
> Thanks
>
> Gary
>


From algotr8der at gmail.com  Fri May  6 21:24:10 2011
From: algotr8der at gmail.com (s)
Date: Fri, 06 May 2011 15:24:10 -0400
Subject: [R-SIG-Finance] EndEquity lower than initEq despite positive p/l
In-Reply-To: <1304685087.2156.143.camel@brian-desktop>
References: <1304619533742-3499089.post@n4.nabble.com>	
	<1304620241723-3499116.post@n4.nabble.com>	
	<1304634190942-3499834.post@n4.nabble.com>	
	<1304643082257-3500326.post@n4.nabble.com>
	<1304685087.2156.143.camel@brian-desktop>
Message-ID: <4DC44ADA.10401@gmail.com>

On 5/6/11 8:31 AM, Brian G. Peterson wrote:
> Looks like a bug in initAcct.  My suspicion is that if the first row of
> the Acct table had the initiEq, all else would work fine.
>
> We changed some things around there a couple months ago to deal with
> multi-currency accounts (accounts with a different measurement currency
> than portfolios) and with vectorizing as many of the calculations as
> possible.  I'll look at the older code and see what changed.
>
> Thanks for the report.  As an institutional investor, I basically never
> think about account equity.
>
> I'll try to get back to you later today once I've fixed it.
>
> Cheers,
>
>   - Brian
Thank you Brian for taking a look at this. I appreciate your time.

This problem feeds into other functionalities, which you probably
already know but I thought I would provide more details just in case.

For example:

charts.PerformanceSummary(ROC(getAccount(account.st)$summary$End.Eq)[-1])

What happens is that the call to log(x), where x is the daily equity
value produces -Inf for Log(0) and NaN for log(-negative values). As a
result the log(x) values you see below are fed to chart.TimeSeries where
it fails.

exiting from: checkData(R)
Error in plot.window(xlim, ylim, xaxs = "r", log = logaxis) :
  need finite 'ylim' values

debug: {
    if (type == "discrete") {
        roc <- x/lag(x, n, na.pad = na.pad) - 1
    }
    if (type == "continuous") {
        roc <- diff(log(x), n, na.pad = na.pad)
    }
    reclass(roc, x)
}

----snippet of log(end equity) below ---

2008-09-30     -Inf
2008-10-01     -Inf
2008-10-02     -Inf
2008-10-03     -Inf
2008-10-06     -Inf
2008-10-07     -Inf
2008-10-08     -Inf
2008-10-09     -Inf
2008-10-10 8.191097
2008-10-13      NaN
2008-10-14      NaN
2008-10-15      NaN
2008-10-16      NaN
2008-10-17      NaN
2008-10-20      NaN
2008-10-21      NaN
2008-10-22      NaN

----snippet of end equity below ----

2008-09-30     0.00
2008-10-01     0.00
2008-10-02     0.00
2008-10-03     0.00
2008-10-06     0.00
2008-10-07     0.00
2008-10-08     0.00
2008-10-09     0.00
2008-10-10  3608.68
2008-10-13 -3053.23
2008-10-14 -2154.78
2008-10-15 -2518.47
2008-10-16  -705.72
2008-10-17  -671.87
2008-10-20   -20.29
2008-10-21 -1837.16
2008-10-22 -4495.50

This leads me to think about the situation where initial equity is set
correctly but draw downs have wiped out the equity and are again
producing negative end equity values. In real life this wouldnt be an
issue as your trading would end if that were to happen. But for purposes
of backtesting I could set an initial equity value that could be easily
wiped out by draw downs.  Not sure if you want to address that or leave
it up to the user to set initial equity values that are appropriate for
the size of their trading.
> On Thu, 2011-05-05 at 17:51 -0700, algotr8der wrote:
>> Okay - here is a bogus strategy just to test this -
>>
>> http://r.789695.n4.nabble.com/file/n3500326/bogusStrategy.R bogusStrategy.R 
>>
>> a) portfolio_1 = IBM, UTX, CAT
>>
>> b) portfolio_2 = MSFT
>>
>> Indicators = 10 DSMA, 15 DSMA, 20 DSMA
>>
>> Rules
>>
>> a) if 10_DSMA Crosses Above 20_DSMA BUY stocks in portfolio_1 AND COVER
>> existing SHORTS in portfolio_1
>> b) if 10_DSMA Crosses Below 20_DSMA SELL existing long positions in
>> portfolio_1 AND SHORT all stocks in portfolio_1
>>
>> c) if 15_DSMA Crosses Above 20_DSMA BUY stocks in portfolio_2 AND COVER
>> existing SHORTS in portfolio_2
>> d) if 15_DSMA Crosses Below 20_DSMA SELL existing long positions in
>> portfolio_2 AND SHORT all stocks in portfolio_2
>>
>> Once you have updated the portfolios and accounts type the following:
>>
>>> getAccounts(account.st)
>> Look at the 'End.Eq' column (this is the last column). You will see that the
>> portfolio begins with 0 as the initial value and each day's p/l is added to
>> 0 until the last day.
>>
>> 2010-07-02         -989.49  85836.10
>>
>> Maybe I am misunderstanding something but it appears to me that the p/l of
>> this strategy = 85836.10 and so that amount should be added to the initEq. 
>>
>> In my real strategy I know the p/l is ~34800, which should be added to the
>> initEq.
>>
>>
>>
>>
>>
>>
>> --
>> View this message in context: http://r.789695.n4.nabble.com/EndEquity-lower-than-initEq-despite-positive-p-l-tp3499089p3500326.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.


From johannes.lips at googlemail.com  Sat May  7 16:46:15 2011
From: johannes.lips at googlemail.com (Johannes Lips)
Date: Sat, 07 May 2011 16:46:15 +0200
Subject: [R-SIG-Finance] Include only distinct lags into a GARCH
	specification (rgarch)
Message-ID: <4DC55B37.1030001@googlemail.com>

Hello,

I am trying to fit a GARCH-model to an hourly price series with 24 
values each day.
Therefore I got relatively high autocorrelation in the data, especially 
for the lag=24. I don't want to fit a GARCH with 24 AR-Terms but rather 
would add one distinct external regressor for the lagged variable.

So far I tried the following:
	LaggedDiffHourlyPriceSeries <- lag(DiffHourlyPriceSeries,-24)

	spec.hourly.lagged.gjr <- ugarchspec(variance.model = 	list(model = 
"gjrGARCH", garchOrder = c(1,1), external.regressors = 
LaggedDiffHourlyPriceSeries, distribution.model = "std"))

	fit.hourly.lagged.gjr <- ugarchfit(DiffHourlyPriceSeries, spec = 
spec.hourly.lagged.gjr,  fit.control = list(scale = 1),solver = "solnp", 
solver.control = list(outer.iter=500,inner.iter=1000))

That obviously won't work because of the NAs in the whole data set.
A little bit of the whole dataset
dput(DiffHourlyPriceSeries[1:1000],file="output.csv")
could be found here:
http://dl.dropbox.com/u/3917796/output.csv

I would be glad if someone could point me to a feasible solution!

Thanks in advance

johannes


From gsee000 at gmail.com  Sun May  8 03:16:26 2011
From: gsee000 at gmail.com (G See)
Date: Sat, 7 May 2011 20:16:26 -0500
Subject: [R-SIG-Finance] EndEquity lower than initEq despite positive p/l
In-Reply-To: <4DC44ADA.10401@gmail.com>
References: <1304619533742-3499089.post@n4.nabble.com>
	<1304620241723-3499116.post@n4.nabble.com>
	<1304634190942-3499834.post@n4.nabble.com>
	<1304643082257-3500326.post@n4.nabble.com>
	<1304685087.2156.143.camel@brian-desktop>
	<4DC44ADA.10401@gmail.com>
Message-ID: <BANLkTinV2YwQbw+mBGqR-eS4BChvEV=ocg@mail.gmail.com>

In your code I changed

updateAcct(name=account.st, Dates='2007-07-01::2010-07-03') #old

to start on the startDate instead of initDate:

updateAcct(name=account.st, Dates='2007-07-02::2010-07-03') #new

The updateEndEq function is finding the location of the first row and then
subtracting 1 which returns

integer(0)

Then when it calls getEndEq with that value, 0 is returned.

So, in the updateEndEq function I changed

if (is.null(Dates))
        Dates = time(Account$summary)   #old

to:

if (is.null(Dates))
        Dates = time(Account$summary)[-1]  #new

Now your code works.  See attached

I don't know if that fix makes sense or if it will cause problems other
places in quantstrat, but it seems to work here.

Garrett

On Fri, May 6, 2011 at 2:24 PM, s <algotr8der at gmail.com> wrote:

> On 5/6/11 8:31 AM, Brian G. Peterson wrote:
> > Looks like a bug in initAcct.  My suspicion is that if the first row of
> > the Acct table had the initiEq, all else would work fine.
> >
> > We changed some things around there a couple months ago to deal with
> > multi-currency accounts (accounts with a different measurement currency
> > than portfolios) and with vectorizing as many of the calculations as
> > possible.  I'll look at the older code and see what changed.
> >
> > Thanks for the report.  As an institutional investor, I basically never
> > think about account equity.
> >
> > I'll try to get back to you later today once I've fixed it.
> >
> > Cheers,
> >
> >   - Brian
> Thank you Brian for taking a look at this. I appreciate your time.
>
> This problem feeds into other functionalities, which you probably
> already know but I thought I would provide more details just in case.
>
> For example:
>
> charts.PerformanceSummary(ROC(getAccount(account.st)$summary$End.Eq)[-1])
>
> What happens is that the call to log(x), where x is the daily equity
> value produces -Inf for Log(0) and NaN for log(-negative values). As a
> result the log(x) values you see below are fed to chart.TimeSeries where
> it fails.
>
> exiting from: checkData(R)
> Error in plot.window(xlim, ylim, xaxs = "r", log = logaxis) :
>  need finite 'ylim' values
>
> debug: {
>    if (type == "discrete") {
>        roc <- x/lag(x, n, na.pad = na.pad) - 1
>    }
>    if (type == "continuous") {
>        roc <- diff(log(x), n, na.pad = na.pad)
>    }
>    reclass(roc, x)
> }
>
> ----snippet of log(end equity) below ---
>
> 2008-09-30     -Inf
> 2008-10-01     -Inf
> 2008-10-02     -Inf
> 2008-10-03     -Inf
> 2008-10-06     -Inf
> 2008-10-07     -Inf
> 2008-10-08     -Inf
> 2008-10-09     -Inf
> 2008-10-10 8.191097
> 2008-10-13      NaN
> 2008-10-14      NaN
> 2008-10-15      NaN
> 2008-10-16      NaN
> 2008-10-17      NaN
> 2008-10-20      NaN
> 2008-10-21      NaN
> 2008-10-22      NaN
>
> ----snippet of end equity below ----
>
> 2008-09-30     0.00
> 2008-10-01     0.00
> 2008-10-02     0.00
> 2008-10-03     0.00
> 2008-10-06     0.00
> 2008-10-07     0.00
> 2008-10-08     0.00
> 2008-10-09     0.00
> 2008-10-10  3608.68
> 2008-10-13 -3053.23
> 2008-10-14 -2154.78
> 2008-10-15 -2518.47
> 2008-10-16  -705.72
> 2008-10-17  -671.87
> 2008-10-20   -20.29
> 2008-10-21 -1837.16
> 2008-10-22 -4495.50
>
> This leads me to think about the situation where initial equity is set
> correctly but draw downs have wiped out the equity and are again
> producing negative end equity values. In real life this wouldnt be an
> issue as your trading would end if that were to happen. But for purposes
> of backtesting I could set an initial equity value that could be easily
> wiped out by draw downs.  Not sure if you want to address that or leave
> it up to the user to set initial equity values that are appropriate for
> the size of their trading.
> > On Thu, 2011-05-05 at 17:51 -0700, algotr8der wrote:
> >> Okay - here is a bogus strategy just to test this -
> >>
> >> http://r.789695.n4.nabble.com/file/n3500326/bogusStrategy.RbogusStrategy.R
> >>
> >> a) portfolio_1 = IBM, UTX, CAT
> >>
> >> b) portfolio_2 = MSFT
> >>
> >> Indicators = 10 DSMA, 15 DSMA, 20 DSMA
> >>
> >> Rules
> >>
> >> a) if 10_DSMA Crosses Above 20_DSMA BUY stocks in portfolio_1 AND COVER
> >> existing SHORTS in portfolio_1
> >> b) if 10_DSMA Crosses Below 20_DSMA SELL existing long positions in
> >> portfolio_1 AND SHORT all stocks in portfolio_1
> >>
> >> c) if 15_DSMA Crosses Above 20_DSMA BUY stocks in portfolio_2 AND COVER
> >> existing SHORTS in portfolio_2
> >> d) if 15_DSMA Crosses Below 20_DSMA SELL existing long positions in
> >> portfolio_2 AND SHORT all stocks in portfolio_2
> >>
> >> Once you have updated the portfolios and accounts type the following:
> >>
> >>> getAccounts(account.st)
> >> Look at the 'End.Eq' column (this is the last column). You will see that
> the
> >> portfolio begins with 0 as the initial value and each day's p/l is added
> to
> >> 0 until the last day.
> >>
> >> 2010-07-02         -989.49  85836.10
> >>
> >> Maybe I am misunderstanding something but it appears to me that the p/l
> of
> >> this strategy = 85836.10 and so that amount should be added to the
> initEq.
> >>
> >> In my real strategy I know the p/l is ~34800, which should be added to
> the
> >> initEq.
> >>
> >>
> >>
> >>
> >>
> >>
> >> --
> >> View this message in context:
> http://r.789695.n4.nabble.com/EndEquity-lower-than-initEq-despite-positive-p-l-tp3499089p3500326.html
> >> Sent from the Rmetrics mailing list archive at Nabble.com.
> >>
> >> _______________________________________________
> >> R-SIG-Finance at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >> -- Subscriber-posting only. If you want to post, subscribe first.
> >> -- Also note that this is not the r-help list where general R questions
> should go.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110507/3c403839/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: algotr8der_bugfix.r
Type: application/octet-stream
Size: 7293 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110507/3c403839/attachment.obj>

From brian at braverock.com  Sun May  8 03:25:50 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 07 May 2011 20:25:50 -0500
Subject: [R-SIG-Finance] EndEquity lower than initEq despite positive p/l
In-Reply-To: <BANLkTinV2YwQbw+mBGqR-eS4BChvEV=ocg@mail.gmail.com>
References: <1304619533742-3499089.post@n4.nabble.com>
	<1304620241723-3499116.post@n4.nabble.com>
	<1304634190942-3499834.post@n4.nabble.com>
	<1304643082257-3500326.post@n4.nabble.com>
	<1304685087.2156.143.camel@brian-desktop> <4DC44ADA.10401@gmail.com>
	<BANLkTinV2YwQbw+mBGqR-eS4BChvEV=ocg@mail.gmail.com>
Message-ID: <1304817950.27042.3.camel@brian-desktop>

Garrett,

Thank you for your patch.  I have applied it as svn r601 on R-Forge.  It
is safe enough as far as it goes, though there is more work to do to
really eliminate the issues.

You correctly figured out that a Dates range on the startDate rather
than the initDate does not cause the problem.  Your patch fixes the
issue if Dates is NULL (the default).  I'll need to do a little more
work to detect if the Dates range that is passed in includes the first
index, and remove it.  But this is a good start.

Thanks again,

   - Brian 

On Sat, 2011-05-07 at 20:16 -0500, G See wrote:
> In your code I changed 
> 
> updateAcct(name=account.st, Dates='2007-07-01::2010-07-03') #old 
> 
> to start on the startDate instead of initDate: 
> 
> updateAcct(name=account.st, Dates='2007-07-02::2010-07-03') #new 
> 
> The updateEndEq function is finding the location of the first row and
> then subtracting 1 which returns
> 
> 
> integer(0)
> 
> 
> Then when it calls getEndEq with that value, 0 is returned.
> 
> So, in the updateEndEq function I changed 
> 
> if (is.null(Dates)) 
>         Dates = time(Account$summary)   #old 
> 
> to: 
> 
> if (is.null(Dates)) 
>         Dates = time(Account$summary)[-1]  #new 
> 
> Now your code works.  See attached
> 
> I don't know if that fix makes sense or if it will cause problems
> other places in quantstrat, but it seems to work here.
> 
> 
> Garrett
> 
> On Fri, May 6, 2011 at 2:24 PM, s <algotr8der at gmail.com> wrote:
>         On 5/6/11 8:31 AM, Brian G. Peterson wrote:
>         > Looks like a bug in initAcct.  My suspicion is that if the
>         first row of
>         > the Acct table had the initiEq, all else would work fine.
>         >
>         > We changed some things around there a couple months ago to
>         deal with
>         > multi-currency accounts (accounts with a different
>         measurement currency
>         > than portfolios) and with vectorizing as many of the
>         calculations as
>         > possible.  I'll look at the older code and see what changed.
>         >
>         > Thanks for the report.  As an institutional investor, I
>         basically never
>         > think about account equity.
>         >
>         > I'll try to get back to you later today once I've fixed it.
>         >
>         > Cheers,
>         >
>         >   - Brian
>         Thank you Brian for taking a look at this. I appreciate your
>         time.
>         
>         This problem feeds into other functionalities, which you
>         probably
>         already know but I thought I would provide more details just
>         in case.
>         
>         For example:
>         
>         charts.PerformanceSummary(ROC(getAccount(account.st)$summary
>         $End.Eq)[-1])
>         
>         What happens is that the call to log(x), where x is the daily
>         equity
>         value produces -Inf for Log(0) and NaN for log(-negative
>         values). As a
>         result the log(x) values you see below are fed to
>         chart.TimeSeries where
>         it fails.
>         
>         exiting from: checkData(R)
>         Error in plot.window(xlim, ylim, xaxs = "r", log = logaxis) :
>          need finite 'ylim' values
>         
>         debug: {
>            if (type == "discrete") {
>                roc <- x/lag(x, n, na.pad = na.pad) - 1
>            }
>            if (type == "continuous") {
>                roc <- diff(log(x), n, na.pad = na.pad)
>            }
>            reclass(roc, x)
>         }
>         
>         ----snippet of log(end equity) below ---
>         
>         2008-09-30     -Inf
>         2008-10-01     -Inf
>         2008-10-02     -Inf
>         2008-10-03     -Inf
>         2008-10-06     -Inf
>         2008-10-07     -Inf
>         2008-10-08     -Inf
>         2008-10-09     -Inf
>         2008-10-10 8.191097
>         2008-10-13      NaN
>         2008-10-14      NaN
>         2008-10-15      NaN
>         2008-10-16      NaN
>         2008-10-17      NaN
>         2008-10-20      NaN
>         2008-10-21      NaN
>         2008-10-22      NaN
>         
>         ----snippet of end equity below ----
>         
>         2008-09-30     0.00
>         2008-10-01     0.00
>         2008-10-02     0.00
>         2008-10-03     0.00
>         2008-10-06     0.00
>         2008-10-07     0.00
>         2008-10-08     0.00
>         2008-10-09     0.00
>         2008-10-10  3608.68
>         2008-10-13 -3053.23
>         2008-10-14 -2154.78
>         2008-10-15 -2518.47
>         2008-10-16  -705.72
>         2008-10-17  -671.87
>         2008-10-20   -20.29
>         2008-10-21 -1837.16
>         2008-10-22 -4495.50
>         
>         This leads me to think about the situation where initial
>         equity is set
>         correctly but draw downs have wiped out the equity and are
>         again
>         producing negative end equity values. In real life this
>         wouldnt be an
>         issue as your trading would end if that were to happen. But
>         for purposes
>         of backtesting I could set an initial equity value that could
>         be easily
>         wiped out by draw downs.  Not sure if you want to address that
>         or leave
>         it up to the user to set initial equity values that are
>         appropriate for
>         the size of their trading.
>         
>         > On Thu, 2011-05-05 at 17:51 -0700, algotr8der wrote:
>         >> Okay - here is a bogus strategy just to test this -
>         >>
>         >> http://r.789695.n4.nabble.com/file/n3500326/bogusStrategy.R
>         bogusStrategy.R
>         >>
>         >> a) portfolio_1 = IBM, UTX, CAT
>         >>
>         >> b) portfolio_2 = MSFT
>         >>
>         >> Indicators = 10 DSMA, 15 DSMA, 20 DSMA
>         >>
>         >> Rules
>         >>
>         >> a) if 10_DSMA Crosses Above 20_DSMA BUY stocks in
>         portfolio_1 AND COVER
>         >> existing SHORTS in portfolio_1
>         >> b) if 10_DSMA Crosses Below 20_DSMA SELL existing long
>         positions in
>         >> portfolio_1 AND SHORT all stocks in portfolio_1
>         >>
>         >> c) if 15_DSMA Crosses Above 20_DSMA BUY stocks in
>         portfolio_2 AND COVER
>         >> existing SHORTS in portfolio_2
>         >> d) if 15_DSMA Crosses Below 20_DSMA SELL existing long
>         positions in
>         >> portfolio_2 AND SHORT all stocks in portfolio_2
>         >>
>         >> Once you have updated the portfolios and accounts type the
>         following:
>         >>
>         >>> getAccounts(account.st)
>         >> Look at the 'End.Eq' column (this is the last column). You
>         will see that the
>         >> portfolio begins with 0 as the initial value and each day's
>         p/l is added to
>         >> 0 until the last day.
>         >>
>         >> 2010-07-02         -989.49  85836.10
>         >>
>         >> Maybe I am misunderstanding something but it appears to me
>         that the p/l of
>         >> this strategy = 85836.10 and so that amount should be added
>         to the initEq.
>         >>
>         >> In my real strategy I know the p/l is ~34800, which should
>         be added to the
>         >> initEq.
>         >>
>         >>
>         >>
>         >>
>         >>
>         >>
>         >> --
>         >> View this message in context:
>         http://r.789695.n4.nabble.com/EndEquity-lower-than-initEq-despite-positive-p-l-tp3499089p3500326.html
>         >> Sent from the Rmetrics mailing list archive at Nabble.com.
>         >>
>         >> _______________________________________________
>         >> R-SIG-Finance at r-project.org mailing list
>         >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>         >> -- Subscriber-posting only. If you want to post, subscribe
>         first.
>         >> -- Also note that this is not the r-help list where general
>         R questions should go.
>         
>         _______________________________________________
>         R-SIG-Finance at r-project.org mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>         -- Subscriber-posting only. If you want to post, subscribe
>         first.
>         -- Also note that this is not the r-help list where general R
>         questions should go.
>         
> 
> 

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From gsee000 at gmail.com  Sun May  8 03:40:31 2011
From: gsee000 at gmail.com (G See)
Date: Sat, 7 May 2011 20:40:31 -0500
Subject: [R-SIG-Finance] Quantstrat pair trade
Message-ID: <BANLkTi=tPrj8B+j_p0Cy9afx+gujTV0NMA@mail.gmail.com>

Normally, I would calculate a spread ahead of time and treat it like a
single stock, but in the interest of creating examples for quantstrat, I
created a strategy that will enter each leg separately.

The idea is to calculate a *ratio* of the 2 stocks (StockA / StockB).  If
that *ratio* goes above it's 2 stdev band, then, when it crosses back
through it, sell StockA and buy Stock B.  If the *ratio* goes below it's 2
stdev band, then, when it crosses back above it, buy StockA and sell Stock
B.  When the *ratio* cross it's moving average, flatten out.

I needed to make a *rule* act differently for different symbols.  i.e. when
the *ratio* crosses it's upper bound, the *rule* for StockA should be buy
and the *rule* for StockB should be sell.  But, that would only work if the
*rule* knew which stock it was operating on.  So, the plan was to have an
order sizing function check the symbol and return the opposite quantity if
it is the second symbol.  (e.g. -100 instead of 100).

But, it is not as easy to change the orderside.

I modified osMaxPos and *ruleSignal*, but that's not enough.

What function writes to the orderbook object?
Is there a better way to do this?
I tried setting orderside with the <<- operator, but that doesn't help.

My code is attached.  Sorry it's so long, but it has to include custom
osMaxPos and *ruleSignal* functions.  You'll see in the orderbook for XOM
that where orderside is "short" I have a positive orderqty and vice versa.

thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110507/62ed10ba/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: quantstrat pair trade.r
Type: application/octet-stream
Size: 13384 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110507/62ed10ba/attachment.obj>

From bogaso.christofer at gmail.com  Sun May  8 18:21:19 2011
From: bogaso.christofer at gmail.com (Bogaso Christofer)
Date: Sun, 8 May 2011 21:51:19 +0530
Subject: [R-SIG-Finance] Creating Binomial tree
Message-ID: <01aa01cc0d9b$f9bd5a90$ed380fb0$@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110508/cee5e04a/attachment.pl>

From gsee000 at gmail.com  Mon May  9 16:55:49 2011
From: gsee000 at gmail.com (G See)
Date: Mon, 9 May 2011 09:55:49 -0500
Subject: [R-SIG-Finance] Quantstrat pair trade
In-Reply-To: <1304937001.27042.48.camel@brian-desktop>
References: <BANLkTi=tPrj8B+j_p0Cy9afx+gujTV0NMA@mail.gmail.com>
	<1304851847.27042.31.camel@brian-desktop>
	<BANLkTin=y4twMpRPg=tpba54fyBpRfjWuQ@mail.gmail.com>
	<1304937001.27042.48.camel@brian-desktop>
Message-ID: <BANLkTikf3-U7ufLRpwSTip5abnHeT19qiA@mail.gmail.com>

See attached for an example of a pair trade in quantstrat using a single
portfolio and custom order sizing function.

On Mon, May 9, 2011 at 5:30 AM, Brian G. Peterson <brian at braverock.com>wrote:

> On Sun, 2011-05-08 at 13:46 -0500, G See wrote:
> > Thank you Brian. That was extremely helpful.  It now runs, and I think
> > it does what I wanted it to do.
>
> Thank you!  This is a much cleaner example of how you can extend
> existing functionality without having to extensively rewrite the
> infrastructure!  This version should probably go to algotr8der and to
> the list. It's much better than the first attempt.
>
> > I will probably make it a little more sophisticated with regard to
> > order sizing and dividend accounting, but here's what I've got.
>
> May I include this example in the quantstrat demos ?
> (credited to you, of course)


Of course.  That's why I made it.


> Incidentally, I am in the middle of changing function buildSpread (in
> FinancialInstrument) to allow for other spreading methods (there is an
> unexposed function that does this now), and will eventually add ratio
> calculator utility functions too.
>
> Regards,
>
>  - Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
>
Garrett
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110509/3cd802c0/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: quantstrat_pair_trade_3.r
Type: application/octet-stream
Size: 8357 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110509/3cd802c0/attachment.obj>

From ezivot at u.washington.edu  Mon May  9 17:32:54 2011
From: ezivot at u.washington.edu (Eric Zivot)
Date: Mon, 9 May 2011 08:32:54 -0700
Subject: [R-SIG-Finance] Creating Binomial tree
In-Reply-To: <01aa01cc0d9b$f9bd5a90$ed380fb0$@gmail.com>
References: <01aa01cc0d9b$f9bd5a90$ed380fb0$@gmail.com>
Message-ID: <000601cc0e5e$5d6e82e0$184b88a0$@washington.edu>

You might find the following paper useful

http://comisef.eu/files/wps008.pdf


-----Original Message-----
From: r-sig-finance-bounces at r-project.org
[mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Bogaso Christofer
Sent: Sunday, May 08, 2011 9:21 AM
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] Creating Binomial tree

Dear all, I am trying to create a binomial tree over some big number of
nodes. Generally I work with this code "expand.grid(rep(list(c(0,1)), 4))"
however, R is getting memory allocation problem if the node number is quite
big (more than 25).

 

I need to build a complete grid because, I need to value some path-dependent
option. Has anybody come across this type of problem on build some big tree?
Then how you have solved that?

 

Thanks and regards,


	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From riccardovisca at yahoo.it  Mon May  9 19:46:57 2011
From: riccardovisca at yahoo.it (riccardo visca)
Date: Mon, 9 May 2011 18:46:57 +0100 (BST)
Subject: [R-SIG-Finance] Exponential smoothing and WLS
Message-ID: <614369.9562.qm@web27304.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110509/190a07d0/attachment.pl>

From wuertz at itp.phys.ethz.ch  Mon May  9 20:33:55 2011
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Mon, 9 May 2011 20:33:55 +0200
Subject: [R-SIG-Finance] Don't miss: 5th R/Rmetrics Meielisalp Workshop 2011,
	June 26-30
Message-ID: <0C60F0F7-E7A6-4E65-9177-C31E1EC4C786@itp.phys.ethz.ch>

R-SIG-Finance


5th R/Rmetrics Meielisalp Workshop 
Computational Finance and Financial Engineering 


Meielisalp, Lake Thune, Switzerland, June 26-30, 2011
www.rmetrics.org


The workshop consists of Summer School-like tutorial sessions and a user/developer meeting. Both focus on topics from "Computational Finance and Financial Engineering" and on the use of R/Rmetrics in finance, insurance and related fields. The morning sessions have tutorials covering topics from quantile regression, wavelet methods, measuring model risk, continuous-time systems, and financial time series analysis. Some of the tutorials incorporate practical exercises. It is a honor to welcome our 


Keynote Speaker:

    Professor Brian Ripley
       Department of Statistics, University of Oxford, UK


Tutorial Speakers and Topics:

    Professor Roger Koenker - Topic: Quantile Regression
       Department of Economics, University of Illinois, Urbana-Champaign, USA
    Professor Guy Nason - Topic: Wavelet Methods in Statistics 
       Department of Mathematics, University of Bristol, Bristol, UK
    Professor Ganti Prasada Rao - Topic: Continuous-Time Systems
       Inventive Pathways-Management Consultancy, UAE
    Professor Gerhard Stahl - Topic: Measuring Model Risk
       Talanx Hanover, and University of Hanover, DE
    Professor Ruey Tsay - Topic: Financial Time Series Analysis
       Booth School of Business, The University of Chicago, Chicago, USA
       
   
The afternoon sessions are dedicated to invited and contributed talks and presentations reflecting the wide range of fields in which R and Rmetrics are used in finance and insurance to analyze and model data.


The goal is to bring together students, researchers, developers, practitioners, and users from finance and insurance providing a platform for common discussions and exchange of ideas.


Participation: 
    The workshop is limited to about 50 participants, early registration is recommended.


Call for Papers: 
    We invite the submission of abstracts presenting innovations or exciting applications covering the whole spectrum of computational topics in finance, insurance and related fields. Submission to submissions at rmetrics.org will be considered on a rolling admission basis.

    
Scholarship for Students: 
    A limited number of student scholarships are available. Please send a letter of motivation and a recommendation letter from your supervisor to submissions at rmetrics.org. 


Organization: 
    Swiss Federal Institute of Technology, Zurich, and Rmetrics Associations, Zuric.


Conference Chair:
    Diethelm W?rtz, Swiss Federal Institute of Technology, Zurich Switzerland.


Workshop Committee:
    Patrick H?naff, University of Brest, France
    Stefano Iacus, University of Milano, Milano, Italy
    Mahendra Mehta, Neural Technologies, Mumbai, India
    David Scott, University of Auckland, Auckland, New Zealand


Conference Office:
    Yohan Chalabi, Swiss Federal Institute of Technology, Zurich Switzerland


More Information:
    http://www.rmetrics.org/meielisalp2011
    http://www.rmetrics.org/meielisalp2011-registration
    
    
We would very appreciate it to welcome you at the Meielisalp
best wishes and kind regards

Diethelm Wuertz


From ezivot at u.washington.edu  Mon May  9 21:58:34 2011
From: ezivot at u.washington.edu (Eric Zivot)
Date: Mon, 9 May 2011 12:58:34 -0700
Subject: [R-SIG-Finance] Exponential smoothing and WLS
In-Reply-To: <614369.9562.qm@web27304.mail.ukl.yahoo.com>
References: <614369.9562.qm@web27304.mail.ukl.yahoo.com>
Message-ID: <000601cc0e83$7a4ea1e0$6eebe5a0$@washington.edu>

My understanding is that regression on exponentially weighted data and
one-step ahead prediction (sometimes called discounted least squares) is a
"poor man's" Kalman filtering technique in which the underlying state space
model is a related to an exponential smoothing model. The optimal way to do
estimation is to explicitly write the underlying state space model (e.g. use
the dlm package) and then estimate the parameters by the prediction error
decomposition of the log-likelihood, and then do prediction from the
estimated model. For example, you could write your regression model as a
time varying parameter model where the regression coefficient follow pure
random walk or stationary autoregressive processes.


-----Original Message-----
From: r-sig-finance-bounces at r-project.org
[mailto:r-sig-finance-bounces at r-project.org] On Behalf Of riccardo visca
Sent: Monday, May 09, 2011 10:47 AM
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] Exponential smoothing and WLS

Hello all,

I am estimating a gaussian linear model

y_t+1 = X_t B + u_t

and I noticed that I can actually predict very well a transformation of y_t

(R^2=0.82)
where yhat_t is in fact an exponential smoothed version of y_t with some 
smoothing parameter H

y_t is stationary in mean, eteroschedastic and full of outliers daily
returns 
series
X_t are (optionally) smoothed values too

It is quite straightforward using weighted least squares to predict the
trend 
value Et( yhat_t+1 ) but apparently and quite obviously 


y_t+1 = E(yhat_t+1)+N_t+1
N_t+1 = y_t+1 - E(yhat_t+1) 

were the noise N_t is full of jumps, autocorrelated, nearly unit root and 
eteroschedastic
 
Now my question is:

is there a way to estimate efficiently this family of models in one step
and/or 
can we forecast efficiently yt+1-E(yhat_t+1) ?
Other than Crane-Crotty model that uses exponential weights?

Maybe an obvious R implementation I missed?
	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From me at censix.com  Mon May  9 23:09:53 2011
From: me at censix.com (soren wilkening)
Date: Mon, 9 May 2011 14:09:53 -0700 (PDT)
Subject: [R-SIG-Finance] Quantstrat pair trade
In-Reply-To: <BANLkTi=tPrj8B+j_p0Cy9afx+gujTV0NMA@mail.gmail.com>
References: <BANLkTi=tPrj8B+j_p0Cy9afx+gujTV0NMA@mail.gmail.com>
Message-ID: <1304975393004-3510338.post@n4.nabble.com>

Hi Garrett

I managed to get your example to run smoothly. Have a look to see if it
still does what you wanted it to do. If not, you only need to re-adapt the
indicator (sigCrossing) or the rule definition slighlty. (too tired to check
myself now)

Cheers

Soren
http://r.789695.n4.nabble.com/file/n3510338/quantstrat_pair_trade_-_FIX01-somehowfunctional2.r
quantstrat_pair_trade_-_FIX01-somehowfunctional2.r 

-----
http://censix.com
--
View this message in context: http://r.789695.n4.nabble.com/Quantstrat-pair-trade-tp3506390p3510338.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From gsee000 at gmail.com  Mon May  9 23:27:35 2011
From: gsee000 at gmail.com (G See)
Date: Mon, 9 May 2011 16:27:35 -0500
Subject: [R-SIG-Finance] Quantstrat pair trade
In-Reply-To: <1304975393004-3510338.post@n4.nabble.com>
References: <BANLkTi=tPrj8B+j_p0Cy9afx+gujTV0NMA@mail.gmail.com>
	<1304975393004-3510338.post@n4.nabble.com>
Message-ID: <BANLkTi=XUrxZM8ZS8PR1h8Vo72Qna4Vpdg@mail.gmail.com>

Soren,

Thank you, that does appear to work.  However, I think I have gotten a much
cleaner version working.  The attached version also uses a hedge ratio equal
to the ratio of the two stock prices instead of trading them 1 to 1.

How does it look?  Thanks again for taking an interest!

Garrett

On Mon, May 9, 2011 at 4:09 PM, soren wilkening <me at censix.com> wrote:

> Hi Garrett
>
> I managed to get your example to run smoothly. Have a look to see if it
> still does what you wanted it to do. If not, you only need to re-adapt the
> indicator (sigCrossing) or the rule definition slighlty. (too tired to
> check
> myself now)
>
> Cheers
>
> Soren
>
> http://r.789695.n4.nabble.com/file/n3510338/quantstrat_pair_trade_-_FIX01-somehowfunctional2.r
> quantstrat_pair_trade_-_FIX01-somehowfunctional2.r
>
> -----
> http://censix.com
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Quantstrat-pair-trade-tp3506390p3510338.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110509/3909662a/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: quantstrat_pair_trade_5b.r
Type: application/octet-stream
Size: 8652 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110509/3909662a/attachment.obj>

From nands31 at gmail.com  Tue May 10 15:50:50 2011
From: nands31 at gmail.com (Subhrangshu Nandi)
Date: Tue, 10 May 2011 08:50:50 -0500
Subject: [R-SIG-Finance] xts, period.apply question
Message-ID: <BANLkTimTvPn28zFxwRKD0CWEqgNSw-6PVA@mail.gmail.com>

Is anyone else having issues with the latest update of xts and/or zoo? Some
of my functions that use *apply.weekly* or *apply.daily* are not working any
more. I'm attaching a sample dataset to help you replicate the error. Below
is a copy of my RConsole:

*> str(Data.xts)*
An ?xts? object from 2010-03-23 04:20:00 to 2011-05-06 15:10:00 containing:
  Data: num [1:17902, 1:2] 1508 1508 1507 1507 1506 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:2] "Close" "Close.1"
  Indexed by objects of class: [POSIXt,POSIXct] TZ:
  Original class: 'data.frame'
  xts Attributes:
List of 2
 $ tclass   : chr [1:2] "POSIXt" "POSIXct"
 $ na.action:Class 'omit'  atomic [1:1] 1
  .. ..- attr(*, "index")= num 1.27e+09
*> head(Data.xts)*
                       Close Close.1
2010-03-23 04:20:00 1507.750  537.75
2010-03-23 04:30:00 1507.875  538.50
2010-03-23 04:40:00 1506.875  538.25
2010-03-23 04:50:00 1507.000  538.00
2010-03-23 05:00:00 1506.500  538.00
2010-03-23 05:10:00 1506.500  538.00
*> fn_checkApply*
*function(Data=Data_D){*
*
*
*        MaxDiff <- max(Data[,1]) - max(Data[,2])*
*        return(MaxDiff)*
*}*
*> apply.daily(x=Data.xts, FUN=fn_checkApply)*
*Error in dimnames(x) <- dn : *
*  length of 'dimnames' [2] not equal to array extent*
*> traceback()*
*3: `colnames<-`(`*tmp*`, value = c("Close", "Close.1"))*
*2: period.apply(x, ep, FUN, ...)*
*1: apply.daily(x = Data.xts, FUN = fn_checkApply)*


Any help would be greatly appreciated. Everything was working fine until I
updated the packages on 05/02.
-- 
I'm a great believer in luck, and I find the harder I work the more I have
of it.  ~Thomas Jefferson

Subhrangshu Nandi
Algorithmic Stat-Arb Trader
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110510/b590acc6/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Data.RData
Type: application/octet-stream
Size: 101911 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110510/b590acc6/attachment.obj>

From massimo.salese at gmail.com  Tue May 10 16:14:34 2011
From: massimo.salese at gmail.com (msalese)
Date: Tue, 10 May 2011 07:14:34 -0700 (PDT)
Subject: [R-SIG-Finance] xts, period.apply question
In-Reply-To: <BANLkTimTvPn28zFxwRKD0CWEqgNSw-6PVA@mail.gmail.com>
References: <BANLkTimTvPn28zFxwRKD0CWEqgNSw-6PVA@mail.gmail.com>
Message-ID: <1305036874742-3512019.post@n4.nabble.com>

Hi, I'm new to R and I'm learning Rmetrics library but here I wrote some code
using quantmod/xts.
#############################################################
R.version
               _                            
platform       x86_64-pc-linux-gnu          
arch           x86_64                       
os             linux-gnu                    
system         x86_64, linux-gnu            
status                                      
major          2                            
minor          13.0                         
year           2011                         
month          04                           
day            13                           
svn rev        55427                        
language       R                            
version.string R version 2.13.0 (2011-04-13)
######################################################
> sessionInfo()
R version 2.13.0 (2011-04-13)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=C             
LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] quantmod_0.3-15    TTR_0.20-2         xts_0.8-0          zoo_1.6-5         
 [5] Defaults_1.1-1     fOptions_2110.78   fBasics_2110.79    MASS_7.3-13       
 [9] timeSeries_2130.92 timeDate_2130.93  

loaded via a namespace (and not attached):
[1] grid_2.13.0     lattice_0.19-26 tools_2.13.0   
#######################################################
running on :
######################################################
Linux plutok 2.6.32-31-generic #61-Ubuntu SMP Fri Apr 8 18:25:51 UTC 2011
x86_64 GNU/Linux
Distributor ID:	Ubuntu
Description:	Ubuntu 10.04.2 LTS
Release:	10.04
Codename:	lucid
#######################################################
Here the code that to me semes to work fine:
######################################################??
#Load quantmod library ---> call xts/zoo too 
library(quantmod) 
#download data from yahoo (Generali Assurance - Italian Company )
getSymbols(Symbols="G.MI",src="yahoo")
#define function to compute max relative drawdown
relMxDD<-function(x){
  rdd<-cummax(log(x))-log(x)
  rdd<-1-(1/exp(rdd))
  max(rdd)
}
# apply relMxDD monthly
maxRelDD.sample<-period.apply(x=Cl(G.MI),endpoints(x=Cl(G.MI),on="months"),FUN=relMxDD)
#the same if you use 
#apply.monthly(x=Cl(G.MI),FUN=relMxDD))
plot(maxRelDD.sample,type='h')
hist(x=maxRelDD.sample)





--
View this message in context: http://r.789695.n4.nabble.com/xts-period-apply-question-tp3511933p3512019.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From costas.vorlow at gmail.com  Tue May 10 17:48:40 2011
From: costas.vorlow at gmail.com (Costas Vorlow)
Date: Tue, 10 May 2011 15:48:40 +0000
Subject: [R-SIG-Finance] findDrawdowns {PerformanceAnalytics}
Message-ID: <BANLkTimipO1e1qUcQA4q+KJTXN0Qb7q2fw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110510/bcd3768f/attachment.pl>

From brian at braverock.com  Tue May 10 18:03:51 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 10 May 2011 11:03:51 -0500
Subject: [R-SIG-Finance] findDrawdowns {PerformanceAnalytics}
In-Reply-To: <BANLkTimipO1e1qUcQA4q+KJTXN0Qb7q2fw@mail.gmail.com>
References: <BANLkTimipO1e1qUcQA4q+KJTXN0Qb7q2fw@mail.gmail.com>
Message-ID: <1305043431.22156.14.camel@brian-desktop>

On Tue, 2011-05-10 at 15:48 +0000, Costas Vorlow wrote:
> I am not sure I understand the output:
> 
> > table.Drawdowns(ret, top=10)
>          From     Trough         To   Depth Length To Trough Recovery
> 1  1999-07-19 2000-09-29 2008-10-09 -0.4059   2323       306     2017
> 2  2009-03-10 2009-07-13       <NA> -0.3721    548        87       NA
> 3  1987-10-20 1988-11-22 1993-10-14 -0.2995   1515       278     1237
> 4  1974-10-04 1980-05-16 1982-10-11 -0.2902   2026      1420      606
> 5  1998-07-20 1998-10-29 1999-07-16 -0.2253    251        73      178
> 6  2008-11-21 2009-01-06 2009-03-02 -0.2073     67        30       37
> 7  1971-04-29 1973-10-31 1974-05-22 -0.1826    774       634      140
> 8  2008-10-28 2008-11-04 2008-11-19 -0.1618     17         6       11
> 9  1985-07-18 1985-10-11 1986-02-13 -0.1461    146        60       86
> 10 1994-04-05 1995-01-03 1995-06-05 -0.1412    295       189      106
> >
> 
> Is it Peak-to-Trough-to-next_peak ???
> 
> Does it pick the local (sequencial) maxima/minima (inflection points)
> in the (cumulative) returns cycles ?

I'm pretty certain this is all spelled out in the documentation.  

From: high water mark
Trough: low point in this drawdown
To: when the initial high water mark is recovered
Depth: drawdown to trough
Length: number of periods of From-To
To Trough: how many periods to the bottom
Recovery: how many periods Trough->end of drawdown

Perhaps you can be specific about what part of the documentation doesn't
make sense to you?

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From costas.vorlow at gmail.com  Tue May 10 18:16:36 2011
From: costas.vorlow at gmail.com (Costas Vorlow)
Date: Tue, 10 May 2011 16:16:36 +0000
Subject: [R-SIG-Finance] findDrawdowns {PerformanceAnalytics}
In-Reply-To: <1305043431.22156.14.camel@brian-desktop>
References: <BANLkTimipO1e1qUcQA4q+KJTXN0Qb7q2fw@mail.gmail.com>
	<1305043431.22156.14.camel@brian-desktop>
Message-ID: <BANLkTi=CDrtDvJv_x80qpT7-Ajf0nxBNKg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110510/b5f7598d/attachment.pl>

From gsee000 at gmail.com  Tue May 10 18:50:41 2011
From: gsee000 at gmail.com (G See)
Date: Tue, 10 May 2011 11:50:41 -0500
Subject: [R-SIG-Finance] Quantstrat pair trade
In-Reply-To: <BANLkTi=XUrxZM8ZS8PR1h8Vo72Qna4Vpdg@mail.gmail.com>
References: <BANLkTi=tPrj8B+j_p0Cy9afx+gujTV0NMA@mail.gmail.com>
	<1304975393004-3510338.post@n4.nabble.com>
	<BANLkTi=XUrxZM8ZS8PR1h8Vo72Qna4Vpdg@mail.gmail.com>
Message-ID: <BANLkTin-6yj8kc=gmXgyeFZrhz1OjuO3Zg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110510/a1958687/attachment.pl>

From brian at braverock.com  Tue May 10 19:06:21 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 10 May 2011 12:06:21 -0500
Subject: [R-SIG-Finance] Quantstrat pair trade
In-Reply-To: <BANLkTin-6yj8kc=gmXgyeFZrhz1OjuO3Zg@mail.gmail.com>
References: <BANLkTi=tPrj8B+j_p0Cy9afx+gujTV0NMA@mail.gmail.com>
	<1304975393004-3510338.post@n4.nabble.com>
	<BANLkTi=XUrxZM8ZS8PR1h8Vo72Qna4Vpdg@mail.gmail.com>
	<BANLkTin-6yj8kc=gmXgyeFZrhz1OjuO3Zg@mail.gmail.com>
Message-ID: <1305047181.22156.21.camel@brian-desktop>

On Tue, 2011-05-10 at 11:50 -0500, G See wrote:
> It seems like either getSymbols should support this (i.e. when you
> call getSymbols to get more than one symbol at once there should be an
> option in getSymbols to only return rows that all of the symbols have
> in common), or that there should be a function in xts, quantmod, or
> quantstrat that does this, but I haven't found it.  Is there? 

does na.omit() not work for you?

-- 
Brian


From gsee000 at gmail.com  Tue May 10 19:13:09 2011
From: gsee000 at gmail.com (G See)
Date: Tue, 10 May 2011 12:13:09 -0500
Subject: [R-SIG-Finance] Quantstrat pair trade
In-Reply-To: <1305047181.22156.21.camel@brian-desktop>
References: <BANLkTi=tPrj8B+j_p0Cy9afx+gujTV0NMA@mail.gmail.com>
	<1304975393004-3510338.post@n4.nabble.com>
	<BANLkTi=XUrxZM8ZS8PR1h8Vo72Qna4Vpdg@mail.gmail.com>
	<BANLkTin-6yj8kc=gmXgyeFZrhz1OjuO3Zg@mail.gmail.com>
	<1305047181.22156.21.camel@brian-desktop>
Message-ID: <BANLkTik+7wxWBXD3VgjfyF02rmL3f-amCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110510/c715c9be/attachment.pl>

From gsee000 at gmail.com  Tue May 10 20:11:42 2011
From: gsee000 at gmail.com (G See)
Date: Tue, 10 May 2011 13:11:42 -0500
Subject: [R-SIG-Finance] Quantstrat pair trade
In-Reply-To: <BANLkTin-6yj8kc=gmXgyeFZrhz1OjuO3Zg@mail.gmail.com>
References: <BANLkTi=tPrj8B+j_p0Cy9afx+gujTV0NMA@mail.gmail.com>
	<1304975393004-3510338.post@n4.nabble.com>
	<BANLkTi=XUrxZM8ZS8PR1h8Vo72Qna4Vpdg@mail.gmail.com>
	<BANLkTin-6yj8kc=gmXgyeFZrhz1OjuO3Zg@mail.gmail.com>
Message-ID: <BANLkTindwrUg4A6PYvf_rddghTe3+pEUdQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110510/707c16f0/attachment.pl>

From ben.nachtrieb at gmail.com  Wed May 11 03:50:27 2011
From: ben.nachtrieb at gmail.com (Ben Nachtrieb)
Date: Tue, 10 May 2011 19:50:27 -0600
Subject: [R-SIG-Finance] performance attribution
Message-ID: <BANLkTi=k1X0Q_4_90BPrWX-akLHTZWAfAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110510/7b35e643/attachment.pl>

From brian at braverock.com  Wed May 11 13:16:00 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 11 May 2011 06:16:00 -0500
Subject: [R-SIG-Finance] performance attribution
In-Reply-To: <BANLkTi=k1X0Q_4_90BPrWX-akLHTZWAfAA@mail.gmail.com>
References: <BANLkTi=k1X0Q_4_90BPrWX-akLHTZWAfAA@mail.gmail.com>
Message-ID: <1305112560.22156.35.camel@brian-desktop>

On Tue, 2011-05-10 at 19:50 -0600, Ben Nachtrieb wrote:
> Can someone point me to a package that has portfolio performance
> attribution? I searched, but could not find what I was looking for.

Could you be more specific, please?

Which particular attribution methods are you looking for?  References?

That would help me (and others) narrow in on functions that may do what
you want.

Regards,

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From josh.m.ulrich at gmail.com  Wed May 11 17:00:53 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 11 May 2011 10:00:53 -0500
Subject: [R-SIG-Finance] xts, period.apply question
In-Reply-To: <BANLkTimTvPn28zFxwRKD0CWEqgNSw-6PVA@mail.gmail.com>
References: <BANLkTimTvPn28zFxwRKD0CWEqgNSw-6PVA@mail.gmail.com>
Message-ID: <BANLkTimr_OtrtQukRVS9DCXC4Hg0Ffk_5A@mail.gmail.com>

Hi Subhrangshu,

This is a bug that was introduced when I attempted to change
period.apply to nicely handle functions that provide multi-column
output.  I've patched on R-forge -- revision 593.

The R-forge servers will re-build the package soon, at which point can
install via:
R> install.packages("xts", repos="http://r-forge.r-project.org").

Thanks for the report!

Best,
--
Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com



On Tue, May 10, 2011 at 8:50 AM, Subhrangshu Nandi <nands31 at gmail.com> wrote:
> Is anyone else having issues with the latest update of xts and/or zoo? Some
> of my functions that use apply.weekly or apply.daily are not working any
> more. I'm attaching a sample dataset to help you replicate the error. Below
> is a copy of my RConsole:
>> str(Data.xts)
> An ?xts? object from 2010-03-23 04:20:00 to 2011-05-06 15:10:00 containing:
> ? Data: num [1:17902, 1:2] 1508 1508 1507 1507 1506 ...
> ?- attr(*, "dimnames")=List of 2
> ? ..$ : NULL
> ? ..$ : chr [1:2] "Close" "Close.1"
> ? Indexed by objects of class: [POSIXt,POSIXct] TZ:
> ? Original class: 'data.frame'
> ? xts Attributes:
> List of 2
> ?$ tclass ? : chr [1:2] "POSIXt" "POSIXct"
> ?$ na.action:Class 'omit' ?atomic [1:1] 1
> ? .. ..- attr(*, "index")= num 1.27e+09
>> head(Data.xts)
> ? ? ? ? ? ? ? ? ? ? ? ?Close Close.1
> 2010-03-23 04:20:00 1507.750 ?537.75
> 2010-03-23 04:30:00 1507.875 ?538.50
> 2010-03-23 04:40:00 1506.875 ?538.25
> 2010-03-23 04:50:00 1507.000 ?538.00
> 2010-03-23 05:00:00 1506.500 ?538.00
> 2010-03-23 05:10:00 1506.500 ?538.00
>> fn_checkApply
> function(Data=Data_D){
> ? ? ? ? MaxDiff <- max(Data[,1]) - max(Data[,2])
> ? ? ? ? return(MaxDiff)
> }
>> apply.daily(x=Data.xts, FUN=fn_checkApply)
> Error in dimnames(x) <- dn :
> ? length of 'dimnames' [2] not equal to array extent
>> traceback()
> 3: `colnames<-`(`*tmp*`, value = c("Close", "Close.1"))
> 2: period.apply(x, ep, FUN, ...)
> 1: apply.daily(x = Data.xts, FUN = fn_checkApply)
>
> Any help would be greatly appreciated. Everything was working fine until I
> updated the packages on 05/02.
> --
> I'm a great believer in luck, and I find the harder I work the more I have
> of it.? ~Thomas Jefferson
>
> Subhrangshu Nandi
> Algorithmic Stat-Arb Trader
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>


From algotr8der at gmail.com  Thu May 12 00:56:03 2011
From: algotr8der at gmail.com (algotr8der)
Date: Wed, 11 May 2011 15:56:03 -0700 (PDT)
Subject: [R-SIG-Finance] EndEquity lower than initEq despite positive p/l
In-Reply-To: <1304817950.27042.3.camel@brian-desktop>
References: <1304619533742-3499089.post@n4.nabble.com>
	<1304620241723-3499116.post@n4.nabble.com>
	<1304634190942-3499834.post@n4.nabble.com>
	<1304643082257-3500326.post@n4.nabble.com>
	<4DC44ADA.10401@gmail.com>
	<BANLkTinV2YwQbw+mBGqR-eS4BChvEV=ocg@mail.gmail.com>
	<1304817950.27042.3.camel@brian-desktop>
Message-ID: <1305154563582-3516083.post@n4.nabble.com>

I was wondering if this fix has been included in the latest download for
blotter available on r-forge:

http://r-forge.r-project.org/src/contrib/blotter_0.8.tar.gz

It says the last change was: 2011-05-08 05:02:59+02 | Rev.: 601

I downloaded this package as well as the latest quantstrat package (v603)
and installed them manually but ran into the same problem.

Appreciate the guidance.



--
View this message in context: http://r.789695.n4.nabble.com/EndEquity-lower-than-initEq-despite-positive-p-l-tp3499089p3516083.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Thu May 12 01:10:29 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 11 May 2011 18:10:29 -0500
Subject: [R-SIG-Finance] EndEquity lower than initEq despite positive p/l
In-Reply-To: <1305154563582-3516083.post@n4.nabble.com>
References: <1304619533742-3499089.post@n4.nabble.com>
	<1304620241723-3499116.post@n4.nabble.com>
	<1304634190942-3499834.post@n4.nabble.com>
	<1304643082257-3500326.post@n4.nabble.com> <4DC44ADA.10401@gmail.com>
	<BANLkTinV2YwQbw+mBGqR-eS4BChvEV=ocg@mail.gmail.com>
	<1304817950.27042.3.camel@brian-desktop>
	<1305154563582-3516083.post@n4.nabble.com>
Message-ID: <1305155429.22156.150.camel@brian-desktop>

yes, the fix made it in.  Change your strategy to not specify the Dates
grouping at all.  Let the function take care of itself.  Or take a look
at the 'pairs_trade' demo in quantstrat contributed by Garrett See for a
more sophisticated treatment.

Regards,

   - Brian

On Wed, 2011-05-11 at 15:56 -0700, algotr8der wrote:
> I was wondering if this fix has been included in the latest download for
> blotter available on r-forge:
> 
> http://r-forge.r-project.org/src/contrib/blotter_0.8.tar.gz
> 
> It says the last change was: 2011-05-08 05:02:59+02 | Rev.: 601
> 
> I downloaded this package as well as the latest quantstrat package (v603)
> and installed them manually but ran into the same problem.
> 
> Appreciate the guidance.
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/EndEquity-lower-than-initEq-despite-positive-p-l-tp3499089p3516083.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From gsee000 at gmail.com  Thu May 12 02:13:21 2011
From: gsee000 at gmail.com (G See)
Date: Wed, 11 May 2011 19:13:21 -0500
Subject: [R-SIG-Finance] EndEquity lower than initEq despite positive p/l
In-Reply-To: <1305155429.22156.150.camel@brian-desktop>
References: <1304619533742-3499089.post@n4.nabble.com>
	<1304620241723-3499116.post@n4.nabble.com>
	<1304634190942-3499834.post@n4.nabble.com>
	<1304643082257-3500326.post@n4.nabble.com>
	<4DC44ADA.10401@gmail.com>
	<BANLkTinV2YwQbw+mBGqR-eS4BChvEV=ocg@mail.gmail.com>
	<1304817950.27042.3.camel@brian-desktop>
	<1305154563582-3516083.post@n4.nabble.com>
	<1305155429.22156.150.camel@brian-desktop>
Message-ID: <BANLkTik0RDMup1wO-2ZDqqu3mmmBdysPqA@mail.gmail.com>

Slightly newer version of my demo attached

On Wed, May 11, 2011 at 6:10 PM, Brian G. Peterson <brian at braverock.com>wrote:

> yes, the fix made it in.  Change your strategy to not specify the Dates
> grouping at all.  Let the function take care of itself.  Or take a look
> at the 'pairs_trade' demo in quantstrat contributed by Garrett See for a
> more sophisticated treatment.
>

Garrett
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110511/951e663d/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: quantstrat_pair_trade_6b.r
Type: text/x-r
Size: 11223 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110511/951e663d/attachment.bin>

From emmanuel.senyo at gmail.com  Thu May 12 12:38:00 2011
From: emmanuel.senyo at gmail.com (Emmanuel Senyo)
Date: Thu, 12 May 2011 12:38:00 +0200
Subject: [R-SIG-Finance] Value-at-risk
Message-ID: <BANLkTi=x-QeOu6-mR8ZzaMPQkPnYJx1PHQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110512/a2aded44/attachment.pl>

From brian at braverock.com  Thu May 12 13:21:05 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 12 May 2011 06:21:05 -0500
Subject: [R-SIG-Finance] Value-at-risk
In-Reply-To: <BANLkTi=x-QeOu6-mR8ZzaMPQkPnYJx1PHQ@mail.gmail.com>
References: <BANLkTi=x-QeOu6-mR8ZzaMPQkPnYJx1PHQ@mail.gmail.com>
Message-ID: <1305199265.22156.171.camel@brian-desktop>

On Thu, 2011-05-12 at 12:38 +0200, Emmanuel Senyo wrote:
> Dear All,
> I am currently work on Value-at-risk and would like to know the package that
> is helpful in this regard. It consist of three method, that is variance
> covariance method, Monte carlo simulation, and Historical simulation.
> Regards
> Em

The Gaussian and Historical methods are available in
PerformanceAnalytics.

You can easily use the Monte Carlo method of your choice to create a
longer sample, and then use PerformanceAnalytics to calculate the VaR.

There are also several bootstrap Monte Carlo methods in
PerformanceAnalytics that have been contributed by Eric Zivot, but which
we have not yet documented and exposed.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From brian at braverock.com  Thu May 12 13:57:38 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 12 May 2011 06:57:38 -0500
Subject: [R-SIG-Finance] Value-at-risk
In-Reply-To: <BANLkTik_JrYuhtZgHpApUZGDgt+XZ1JZrw@mail.gmail.com>
References: <BANLkTi=x-QeOu6-mR8ZzaMPQkPnYJx1PHQ@mail.gmail.com>
	<1305199265.22156.171.camel@brian-desktop>
	<BANLkTik_JrYuhtZgHpApUZGDgt+XZ1JZrw@mail.gmail.com>
Message-ID: <1305201458.22156.176.camel@brian-desktop>

There is over 100 pages of documentation available with
PerformanceAnalytics.

I suggest you start with 

install.packages("PerformanceAnalytics") 
#you only need to do the install the first time

require(PerformanceAnalytics)
?VaR  

from the R prompt.  See the examples at the bottom of the VaR
documentation.

Hopefully that will get you started.  If you have trouble, you may email
the R-SIG-Finance list or me with an example of what you're trying to
do.  Ideally, start with some publicly available data (use the edhec or
managers data in Performanceanalytics, or use getSymbols to pull stock
data from Yahoo or Google) so that others can replicate what you're
trying to do and help you with code rather than vague suggestions.

Regards,

   - Brian

On Thu, 2011-05-12 at 13:47 +0200, Emmanuel Senyo wrote:
> Dear Brian,
> Thanks for the mail, I have now located the PerformanceAnalytics.
> Could you please elaborate on it how I could use this package, the
> fact is that I am new to R, how i would like compute value at risk
> for prices and volumes. If I can get a sample scripts with explanation
> that would be very helpful to me to enable me build my own scripts.
> Regards
> Emma
> 
> On Thu, May 12, 2011 at 1:21 PM, Brian G. Peterson
> <brian at braverock.com> wrote:
>         
>         On Thu, 2011-05-12 at 12:38 +0200, Emmanuel Senyo wrote:
>         > Dear All,
>         > I am currently work on Value-at-risk and would like to know
>         the package that
>         > is helpful in this regard. It consist of three method, that
>         is variance
>         > covariance method, Monte carlo simulation, and Historical
>         simulation.
>         > Regards
>         > Em
>         
>         
>         The Gaussian and Historical methods are available in
>         PerformanceAnalytics.
>         
>         You can easily use the Monte Carlo method of your choice to
>         create a
>         longer sample, and then use PerformanceAnalytics to calculate
>         the VaR.
>         
>         There are also several bootstrap Monte Carlo methods in
>         PerformanceAnalytics that have been contributed by Eric Zivot,
>         but which
>         we have not yet documented and exposed.
>         
>         Regards,
>         
>           - Brian
>         
>         --
>         Brian G. Peterson
>         http://braverock.com/brian/
>         Ph: 773-459-4973
>         IM: bgpbraverock
>         
> 

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From ben.nachtrieb at gmail.com  Fri May 13 02:08:20 2011
From: ben.nachtrieb at gmail.com (Ben Nachtrieb)
Date: Thu, 12 May 2011 18:08:20 -0600
Subject: [R-SIG-Finance] performance attribution
Message-ID: <BANLkTi=8JqumZHpALMPXJi3g9YnZ--isqQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110512/016ea28c/attachment.pl>

From brian at braverock.com  Fri May 13 03:15:15 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 12 May 2011 20:15:15 -0500
Subject: [R-SIG-Finance] performance attribution
In-Reply-To: <BANLkTi=8JqumZHpALMPXJi3g9YnZ--isqQ@mail.gmail.com>
References: <BANLkTi=8JqumZHpALMPXJi3g9YnZ--isqQ@mail.gmail.com>
Message-ID: <1305249315.22156.291.camel@brian-desktop>

Ben,

The Brinson model is a multi-factor model.

We're working on a package with Eric Zivot to do generalized
multi-factor modeling for finance in R, but right now you can reference
Eric's website for two recent seminars he's given on factor models for
attribution here:

http://faculty.washington.edu/ezivot/ezresearch.htm#Invited%20Lectures

code and slides are all there.

Regards,

   - Brian


On Thu, 2011-05-12 at 18:08 -0600, Ben Nachtrieb wrote:
> Hello,
> 
> Posting again with more detail...
> 
> Can someone point me to a package that has portfolio performance and
> exposure
> attribution? I searched, but could not find what I was looking for.
> Something like what our Bloomberg Terminal has, but I need to have the
> ability to modify it so it includes non-equities related exposures and
> returns etc. I realized there is a benchmark issue with non-equity
> securities...
> 
> I'm looking to determine return from selection, allocation, currency, and
> interaction (Brinson Attribution). I also want to look at exposures and
> associated returns from exposures. Standard PA stuff. We will have daily
> portfolio transaction data.
> 
> Thanks!
> 
> Ben
> 
> On Tue, 2011-05-10 at 19:50 -0600, Ben Nachtrieb wrote:
> > Can someone point me to a package that has portfolio performance
> > attribution? I searched, but could not find what I was looking for.
> 
> Could you be more specific, please?
> 
> Which particular attribution methods are you looking for?  References?
> 
> That would help me (and others) narrow in on functions that may do what
> you want.
> 
> Regards,
> 
>  - Brian
> 
> 

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From algotr8der at gmail.com  Fri May 13 17:54:33 2011
From: algotr8der at gmail.com (algotr8der)
Date: Fri, 13 May 2011 08:54:33 -0700 (PDT)
Subject: [R-SIG-Finance] is there a function that will compute a cumulative
 return times series
Message-ID: <1305302073598-3520559.post@n4.nabble.com>

Hello,

Do any of you know whether there exists a function that I can use to produce
a cumulative return time series of an xts object (stock price). I have
created my own code to do this but I was wondering if there already exists a
function that does what I want as I would like the resulting object to
remain as a XTS object so I can plot various studies on the same chart.

I have attached an image of a chart that shows the cumulative return time
series of an ETF and its components.

http://r.789695.n4.nabble.com/file/n3520559/Screen_shot_2011-05-13_at_11.31.53_AM.png
Screen_shot_2011-05-13_at_11.31.53_AM.png 

I looked through the 'TTR' package and found very useful functions that
compute running/window SDs, Means, Cov etc...    but was wondering if there
is something similar for cumulative returns.

--
View this message in context: http://r.789695.n4.nabble.com/is-there-a-function-that-will-compute-a-cumulative-return-times-series-tp3520559p3520559.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From gsee000 at gmail.com  Fri May 13 18:18:46 2011
From: gsee000 at gmail.com (G See)
Date: Fri, 13 May 2011 11:18:46 -0500
Subject: [R-SIG-Finance] is there a function that will compute a
 cumulative return times series
In-Reply-To: <1305302073598-3520559.post@n4.nabble.com>
References: <1305302073598-3520559.post@n4.nabble.com>
Message-ID: <BANLkTikXAvhG8+xQDgzN7Syb-XYpiSw=9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110513/1230e10b/attachment.pl>

From brian at braverock.com  Fri May 13 18:23:06 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 13 May 2011 11:23:06 -0500
Subject: [R-SIG-Finance] is there a function that will compute a
 cumulative return times series
In-Reply-To: <1305302073598-3520559.post@n4.nabble.com>
References: <1305302073598-3520559.post@n4.nabble.com>
Message-ID: <1305303786.22156.332.camel@brian-desktop>

Package PerformanceAnalytics will do this for you.

?Return.calculate
?charts.PerformanceSummary
?chart.CumReturns

for starters.

Regards,

   - Brian

On Fri, 2011-05-13 at 08:54 -0700, algotr8der wrote:
> Hello,
> 
> Do any of you know whether there exists a function that I can use to produce
> a cumulative return time series of an xts object (stock price). I have
> created my own code to do this but I was wondering if there already exists a
> function that does what I want as I would like the resulting object to
> remain as a XTS object so I can plot various studies on the same chart.
> 
> I have attached an image of a chart that shows the cumulative return time
> series of an ETF and its components.
> 
> http://r.789695.n4.nabble.com/file/n3520559/Screen_shot_2011-05-13_at_11.31.53_AM.png
> Screen_shot_2011-05-13_at_11.31.53_AM.png 
> 
> I looked through the 'TTR' package and found very useful functions that
> compute running/window SDs, Means, Cov etc...    but was wondering if there
> is something similar for cumulative returns.
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/is-there-a-function-that-will-compute-a-cumulative-return-times-series-tp3520559p3520559.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From algotr8der at gmail.com  Fri May 13 18:22:59 2011
From: algotr8der at gmail.com (s)
Date: Fri, 13 May 2011 12:22:59 -0400
Subject: [R-SIG-Finance] is there a function that will compute a
 cumulative return times series
In-Reply-To: <BANLkTikXAvhG8+xQDgzN7Syb-XYpiSw=9w@mail.gmail.com>
References: <1305302073598-3520559.post@n4.nabble.com>
	<BANLkTikXAvhG8+xQDgzN7Syb-XYpiSw=9w@mail.gmail.com>
Message-ID: <4DCD5AE3.7@gmail.com>

Thanks you. I will give that a try. Another gentleman also informed me
that I could use cumsum() of returns.

Thank you all.

On 5/13/11 12:18 PM, G See wrote:
> Maybe you want to see the PerfomanceAnalytics package?
>
> Or, maybe you're just looking for cumprod?
>
> library(quantmod)
> getSymbols('SPY')
> ret <- dailyReturn(SPY)
> cumret <- cumprod(1+ret)
> str(cumret)
>
>
> On Fri, May 13, 2011 at 10:54 AM, algotr8der <algotr8der at gmail.com> wrote:
>
>> Hello,
>>
>> Do any of you know whether there exists a function that I can use to
>> produce
>> a cumulative return time series of an xts object (stock price). I have
>> created my own code to do this but I was wondering if there already exists
>> a
>> function that does what I want as I would like the resulting object to
>> remain as a XTS object so I can plot various studies on the same chart.
>>
>> I have attached an image of a chart that shows the cumulative return time
>> series of an ETF and its components.
>>
>>
>> http://r.789695.n4.nabble.com/file/n3520559/Screen_shot_2011-05-13_at_11.31.53_AM.png
>> Screen_shot_2011-05-13_at_11.31.53_AM.png
>>
>> I looked through the 'TTR' package and found very useful functions that
>> compute running/window SDs, Means, Cov etc...    but was wondering if there
>> is something similar for cumulative returns.
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/is-there-a-function-that-will-compute-a-cumulative-return-times-series-tp3520559p3520559.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>


From algotr8der at gmail.com  Fri May 13 18:24:29 2011
From: algotr8der at gmail.com (s)
Date: Fri, 13 May 2011 12:24:29 -0400
Subject: [R-SIG-Finance] is there a function that will compute a
 cumulative return times series
In-Reply-To: <1305303786.22156.332.camel@brian-desktop>
References: <1305302073598-3520559.post@n4.nabble.com>
	<1305303786.22156.332.camel@brian-desktop>
Message-ID: <4DCD5B3D.7010802@gmail.com>

On 5/13/11 12:23 PM, Brian G. Peterson wrote:
> Package PerformanceAnalytics will do this for you.
>
> ?Return.calculate
> ?charts.PerformanceSummary
> ?chart.CumReturns
>
This is great. Thank you Brian. I tried a suggestion from another
gentlemen who indicated I could use the cumsum() function. I will try
out the functions in PerformanceAnalytics now.
> for starters.
>
> Regards,
>
>    - Brian
>
> On Fri, 2011-05-13 at 08:54 -0700, algotr8der wrote:
>> Hello,
>>
>> Do any of you know whether there exists a function that I can use to produce
>> a cumulative return time series of an xts object (stock price). I have
>> created my own code to do this but I was wondering if there already exists a
>> function that does what I want as I would like the resulting object to
>> remain as a XTS object so I can plot various studies on the same chart.
>>
>> I have attached an image of a chart that shows the cumulative return time
>> series of an ETF and its components.
>>
>> http://r.789695.n4.nabble.com/file/n3520559/Screen_shot_2011-05-13_at_11.31.53_AM.png
>> Screen_shot_2011-05-13_at_11.31.53_AM.png 
>>
>> I looked through the 'TTR' package and found very useful functions that
>> compute running/window SDs, Means, Cov etc...    but was wondering if there
>> is something similar for cumulative returns.
>>
>> --
>> View this message in context: http://r.789695.n4.nabble.com/is-there-a-function-that-will-compute-a-cumulative-return-times-series-tp3520559p3520559.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.


From gsee000 at gmail.com  Fri May 13 18:39:15 2011
From: gsee000 at gmail.com (G See)
Date: Fri, 13 May 2011 11:39:15 -0500
Subject: [R-SIG-Finance] is there a function that will compute a
 cumulative return times series
In-Reply-To: <4DCD5B3D.7010802@gmail.com>
References: <1305302073598-3520559.post@n4.nabble.com>
	<1305303786.22156.332.camel@brian-desktop>
	<4DCD5B3D.7010802@gmail.com>
Message-ID: <BANLkTi=_obR__ENOpPwm5SnQXqhtRYQzkA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110513/cbe187b8/attachment.pl>

From algotr8der at gmail.com  Sat May 14 03:48:20 2011
From: algotr8der at gmail.com (algotr8der)
Date: Fri, 13 May 2011 18:48:20 -0700 (PDT)
Subject: [R-SIG-Finance] Process used to manage workspace and large data
	files
Message-ID: <1305337700030-3521586.post@n4.nabble.com>

I think I have been working inefficiently with how I manage my workspace and
large data files. I was working with daily stock price data so my
inefficiencies were manageable but now I have moved to intraday data and
need to optimize. As such, I installed mySQL db on the same machine I
operate R to store the intraday data (minute frequency). 

However, I find that loading minute stock data using dbGetQuery is very
slow. I have read several comments here on using RData files or
getSymbols.mySQL but would greatly appreciate further insight.

The structure of the table in mySQL that stores the minute data is as
follows:

date, time, open, high, low, close, volume

Every time I load data into R I have to perform manipulations on the date
and time column to get the data into the right format before I can generate
an XTS object of the data. I'm wondering whether I need to combine the date
and time columns in mySQL into one date column with the format as follows so
that I can use getSymbols.mySQL:

%m/%d/%Y %h:%i:%s %p

It seems to me that getSymbols.mySQL would need the date to be in the
aforementioned format as otherwise how else is it going to produce an XTS
object if time is stored in a separate column. 

As a note - I am the only one who accesses the data.

I would greatly appreciate it if you could share your experiences and
possibly your data/workspace set up.



--
View this message in context: http://r.789695.n4.nabble.com/Process-used-to-manage-workspace-and-large-data-files-tp3521586p3521586.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Sat May 14 04:08:25 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 13 May 2011 21:08:25 -0500
Subject: [R-SIG-Finance] Process used to manage workspace and large data
 files
In-Reply-To: <1305337700030-3521586.post@n4.nabble.com>
References: <1305337700030-3521586.post@n4.nabble.com>
Message-ID: <1305338905.22156.356.camel@brian-desktop>

We stored tick data as binary xts (not XTS, R is case sensitive)
rda/RData objects on disk.  This was more than fast enough, and far
faster than MySQL.

   - Brian

On Fri, 2011-05-13 at 18:48 -0700, algotr8der wrote:
> I think I have been working inefficiently with how I manage my workspace and
> large data files. I was working with daily stock price data so my
> inefficiencies were manageable but now I have moved to intraday data and
> need to optimize. As such, I installed mySQL db on the same machine I
> operate R to store the intraday data (minute frequency). 
> 
> However, I find that loading minute stock data using dbGetQuery is very
> slow. I have read several comments here on using RData files or
> getSymbols.mySQL but would greatly appreciate further insight.
> 
> The structure of the table in mySQL that stores the minute data is as
> follows:
> 
> date, time, open, high, low, close, volume
> 
> Every time I load data into R I have to perform manipulations on the date
> and time column to get the data into the right format before I can generate
> an XTS object of the data. I'm wondering whether I need to combine the date
> and time columns in mySQL into one date column with the format as follows so
> that I can use getSymbols.mySQL:
> 
> %m/%d/%Y %h:%i:%s %p
> 
> It seems to me that getSymbols.mySQL would need the date to be in the
> aforementioned format as otherwise how else is it going to produce an XTS
> object if time is stored in a separate column. 
> 
> As a note - I am the only one who accesses the data.
> 
> I would greatly appreciate it if you could share your experiences and
> possibly your data/workspace set up.
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Process-used-to-manage-workspace-and-large-data-files-tp3521586p3521586.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From algotr8der at gmail.com  Sat May 14 15:54:30 2011
From: algotr8der at gmail.com (s)
Date: Sat, 14 May 2011 09:54:30 -0400
Subject: [R-SIG-Finance] Process used to manage workspace and large data
 files
In-Reply-To: <1305338905.22156.356.camel@brian-desktop>
References: <1305337700030-3521586.post@n4.nabble.com>
	<1305338905.22156.356.camel@brian-desktop>
Message-ID: <4DCE8996.90202@gmail.com>

On 5/13/11 10:08 PM, Brian G. Peterson wrote:
> We stored tick data as binary xts (not XTS, R is case sensitive)
> rda/RData objects on disk.  This was more than fast enough, and far
> faster than MySQL.
Thank you Brian.

I tried this and I was successful in saving an xts object and retrieving
it using getSymbols(Symbols, src='rda').

Now how do you maintain these rda files as new data arrives each day -
is there some way of adding incremental data to the object? For example
if I have minute data for QQQ from 2002-01-01 to 2011-05-13 I don't want
to pull all of the data beginning 2002-01-01 from my source to update
one day's worth of data at the end of business this coming Monday.


>    - Brian
>
> On Fri, 2011-05-13 at 18:48 -0700, algotr8der wrote:
>> I think I have been working inefficiently with how I manage my workspace and
>> large data files. I was working with daily stock price data so my
>> inefficiencies were manageable but now I have moved to intraday data and
>> need to optimize. As such, I installed mySQL db on the same machine I
>> operate R to store the intraday data (minute frequency). 
>>
>> However, I find that loading minute stock data using dbGetQuery is very
>> slow. I have read several comments here on using RData files or
>> getSymbols.mySQL but would greatly appreciate further insight.
>>
>> The structure of the table in mySQL that stores the minute data is as
>> follows:
>>
>> date, time, open, high, low, close, volume
>>
>> Every time I load data into R I have to perform manipulations on the date
>> and time column to get the data into the right format before I can generate
>> an XTS object of the data. I'm wondering whether I need to combine the date
>> and time columns in mySQL into one date column with the format as follows so
>> that I can use getSymbols.mySQL:
>>
>> %m/%d/%Y %h:%i:%s %p
>>
>> It seems to me that getSymbols.mySQL would need the date to be in the
>> aforementioned format as otherwise how else is it going to produce an XTS
>> object if time is stored in a separate column. 
>>
>> As a note - I am the only one who accesses the data.
>>
>> I would greatly appreciate it if you could share your experiences and
>> possibly your data/workspace set up.
>>
>>
>>
>> --
>> View this message in context: http://r.789695.n4.nabble.com/Process-used-to-manage-workspace-and-large-data-files-tp3521586p3521586.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.


From gsee000 at gmail.com  Sat May 14 18:02:21 2011
From: gsee000 at gmail.com (G See)
Date: Sat, 14 May 2011 11:02:21 -0500
Subject: [R-SIG-Finance] Process used to manage workspace and large data
	files
In-Reply-To: <4DCE8996.90202@gmail.com>
References: <1305337700030-3521586.post@n4.nabble.com>
	<1305338905.22156.356.camel@brian-desktop>
	<4DCE8996.90202@gmail.com>
Message-ID: <BANLkTinLBTG1SHOBfynWCmRtj=4zkxsg5w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110514/c150d922/attachment.pl>

From algotr8der at gmail.com  Sat May 14 18:08:19 2011
From: algotr8der at gmail.com (s)
Date: Sat, 14 May 2011 12:08:19 -0400
Subject: [R-SIG-Finance] Process used to manage workspace and large data
 files
In-Reply-To: <BANLkTinLBTG1SHOBfynWCmRtj=4zkxsg5w@mail.gmail.com>
References: <1305337700030-3521586.post@n4.nabble.com>	<1305338905.22156.356.camel@brian-desktop>	<4DCE8996.90202@gmail.com>
	<BANLkTinLBTG1SHOBfynWCmRtj=4zkxsg5w@mail.gmail.com>
Message-ID: <4DCEA8F3.1090607@gmail.com>

Thank you Garrett and Brian. I will take a look.

In the mean time I just saved one of my symbols in mySQL to an rda file.
I want to be able to retrieve a subset of the data using one of the
getSymbols variants. Is this possible?

For example, the time series for AMKR starts on 2002-04-08. I want to
grab the subset between 2009-01-01 and end of day 2010-10-06. It appears
the entire object is loaded. Appreciate the help.

> getSymbols('AMKR', from="2009-01-01 09:31:00", to="2010-10-06
16:00:00", src='rda', col.names=c("open", "high", "low", "close", "volume"))
[1] "AMKR"

> head(AMKR)
                    AMKR.open AMKR.high AMKR.low AMKR.close AMKR.volume
2002-04-08 09:31:00     21.50     21.50    21.42      21.42        7300
2002-04-08 09:32:00     21.41     21.46    21.39      21.40        1100
2002-04-08 09:33:00     21.35     21.35    21.30      21.30         900
2002-04-08 09:34:00     21.37     21.44    21.37      21.43        4100
2002-04-08 09:35:00     21.43     21.43    21.43      21.43         400
2002-04-08 09:36:00     21.43     21.43    21.35      21.37        3200

Or even everything from 2009-01-01 onwards

> getSymbols('AMKR', from="2009-01-01", src='rda', col.names=c("open",
"high", "low", "close", "volume"))

[1] "AMKR"

> head(AMKR)
                    AMKR.open AMKR.high AMKR.low AMKR.close AMKR.volume
2002-04-08 09:31:00     21.50     21.50    21.42      21.42        7300
2002-04-08 09:32:00     21.41     21.46    21.39      21.40        1100
2002-04-08 09:33:00     21.35     21.35    21.30      21.30         900
2002-04-08 09:34:00     21.37     21.44    21.37      21.43        4100
2002-04-08 09:35:00     21.43     21.43    21.43      21.43         400
2002-04-08 09:36:00     21.43     21.43    21.35      21.37        3200

On 5/14/11 12:02 PM, G See wrote:
> You could have different data files for different days, and write a wrapper
> for getSymbols to rbind it all together when you need it. I think
> getSymbols.FI, in the FinancialInstrument package, does this.
>
> On Sat, May 14, 2011 at 8:54 AM, s <algotr8der at gmail.com> wrote:
>
>> Now how do you maintain these rda files as new data arrives each day -
>> is there some way of adding incremental data to the object? For example
>> if I have minute data for QQQ from 2002-01-01 to 2011-05-13 I don't want
>> to pull all of the data beginning 2002-01-01 from my source to update
>> one day's worth of data at the end of business this coming Monday.
>>
>>


From nealsmith314 at gmail.com  Sat May 14 18:22:24 2011
From: nealsmith314 at gmail.com (neal smith)
Date: Sat, 14 May 2011 12:22:24 -0400
Subject: [R-SIG-Finance] options/BS/MC
Message-ID: <BANLkTikH5o8wGt-qmm+Oj6yGg0uhP3XRYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110514/65b2fd0d/attachment.pl>

From gsee000 at gmail.com  Sat May 14 18:28:13 2011
From: gsee000 at gmail.com (G See)
Date: Sat, 14 May 2011 11:28:13 -0500
Subject: [R-SIG-Finance] Process used to manage workspace and large data
	files
In-Reply-To: <4DCEA8F3.1090607@gmail.com>
References: <1305337700030-3521586.post@n4.nabble.com>
	<1305338905.22156.356.camel@brian-desktop>
	<4DCE8996.90202@gmail.com>
	<BANLkTinLBTG1SHOBfynWCmRtj=4zkxsg5w@mail.gmail.com>
	<4DCEA8F3.1090607@gmail.com>
Message-ID: <BANLkTimd+wOOoMaRJbU+MHNd3weOEZP4Cg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110514/23f85e58/attachment.pl>

From gsee000 at gmail.com  Sat May 14 18:32:10 2011
From: gsee000 at gmail.com (G See)
Date: Sat, 14 May 2011 11:32:10 -0500
Subject: [R-SIG-Finance] Process used to manage workspace and large data
	files
In-Reply-To: <BANLkTimd+wOOoMaRJbU+MHNd3weOEZP4Cg@mail.gmail.com>
References: <1305337700030-3521586.post@n4.nabble.com>
	<1305338905.22156.356.camel@brian-desktop>
	<4DCE8996.90202@gmail.com>
	<BANLkTinLBTG1SHOBfynWCmRtj=4zkxsg5w@mail.gmail.com>
	<4DCEA8F3.1090607@gmail.com>
	<BANLkTimd+wOOoMaRJbU+MHNd3weOEZP4Cg@mail.gmail.com>
Message-ID: <BANLkTinLju=-FCV7NXQO4ELNbc4xh_X3_g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110514/36957e40/attachment.pl>

From arun.kumar.saha at gmail.com  Sat May 14 18:46:42 2011
From: arun.kumar.saha at gmail.com (Arun.stat)
Date: Sat, 14 May 2011 09:46:42 -0700 (PDT)
Subject: [R-SIG-Finance] options/BS/MC
In-Reply-To: <BANLkTikH5o8wGt-qmm+Oj6yGg0uhP3XRYA@mail.gmail.com>
References: <BANLkTikH5o8wGt-qmm+Oj6yGg0uhP3XRYA@mail.gmail.com>
Message-ID: <1305391602981-3522696.post@n4.nabble.com>

Well, a good discussion on why your second approach is completely meaningless
can be found here:

http://www.wilmott.com/messageview.cfm?catid=8&threadid=84115

Thanks and regards,
_____________________________________________________

Arun Kumar Saha, FRM
QUANTITATIVE RISK AND HEDGE CONSULTING SPECIALIST
Visit me at: http://in.linkedin.com/in/ArunFRM
_____________________________________________________

--
View this message in context: http://r.789695.n4.nabble.com/options-BS-MC-tp3522642p3522696.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From jeffrey.ryan at lemnica.com  Sat May 14 22:02:08 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Sat, 14 May 2011 15:02:08 -0500
Subject: [R-SIG-Finance] Process used to manage workspace and large data
	files
In-Reply-To: <BANLkTimd+wOOoMaRJbU+MHNd3weOEZP4Cg@mail.gmail.com>
References: <1305337700030-3521586.post@n4.nabble.com>
	<1305338905.22156.356.camel@brian-desktop>
	<4DCE8996.90202@gmail.com>
	<BANLkTinLBTG1SHOBfynWCmRtj=4zkxsg5w@mail.gmail.com>
	<4DCEA8F3.1090607@gmail.com>
	<BANLkTimd+wOOoMaRJbU+MHNd3weOEZP4Cg@mail.gmail.com>
Message-ID: <BANLkTi=VwP8S4KK77ZJ0cOriwUEiQrU7LQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110514/b68c0600/attachment.pl>

From nealsmith314 at gmail.com  Sun May 15 01:32:43 2011
From: nealsmith314 at gmail.com (neal smith)
Date: Sat, 14 May 2011 19:32:43 -0400
Subject: [R-SIG-Finance] options/BS/MC
Message-ID: <BANLkTin2uFsm+7ZbFaLVtvrLqsi2yddyUA@mail.gmail.com>

Hi

I'm not saying the mean call value .165 with mu=.14 equals the call
price.   i am not hedging the call in this case, and i am exposed to 0
payoff and hence loss of the price of the call if the call expires out
of the money. as the thread you mention explains, the call price
equals the price of the risk-free replicating/hedging portfolio, and
any other price exposes one to arbitrage.? so i'm not going to pay
.165 for this call, i agree it's worth only  .05, the BS risk-neutral
arbitrage-free price.

my question is, now if i go ahead and buy the call for BS/arb-free
price of .05 and hold it until expiration, the distribution of returns
seems to be very high and favorable:

mustocks<-exp(rnorm(10000, mean=.15, sd=vol))
mucallvals<-pmax(0.,mustocks-strike)
print(summary(exp(-.02)*mucallvals))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
0.00000 0.08153 0.15670 0.16590 0.23860 0.73860

i can ask this question on the tree also, suppose s0=1, and at t=1,
either s1=1.5 or s1=.5, and i have a call with K=1, and r=0, then as
the lyceum/hull/etc explain, i can hold the riskless hedging portfolio
of long .5 stock and short (borrow) $.25, so that i risklessly
replicate the payoffs, meaning the option is worth .5(1)-.25=.25.  i
have no question about that, and that is well explained in the wilmott
thread mentioned along with hull etc.

instead, i want to specifically understand the real world probability.
suppose i move to the real world, and i know p(up)=.99 and
p(down)=.01.  so i play 100 times, of course i am exposing myself to a
risk of loss, and my  payoff if i have x ups (and hence 100-x downs)
in the 100 trials is given by

(.25x-(.25(100-x)))*binomial(p=.99,n=100,x)=(.5x-25)*binomial(.99,100,x).

for instance why shouldn't i buy the call for .25, and then, on
average, 99 out of 100 times, pick up the.25*99=$24.75, and the
(typically) 1 time lose the .25, so i end up with $24.50 on average
(which equals the expectation of the above payoff)?

is this just the result of the fact that i am exposing myself to a
range of losses upto the maximum -$25 loss (wp .01^100)? is this
related to "market price of risk" etc?

thanks
-neal


From algotr8der at gmail.com  Sun May 15 02:14:53 2011
From: algotr8der at gmail.com (s)
Date: Sat, 14 May 2011 20:14:53 -0400
Subject: [R-SIG-Finance] Process used to manage workspace and large data
 files
In-Reply-To: <BANLkTi=VwP8S4KK77ZJ0cOriwUEiQrU7LQ@mail.gmail.com>
References: <1305337700030-3521586.post@n4.nabble.com>	<1305338905.22156.356.camel@brian-desktop>	<4DCE8996.90202@gmail.com>	<BANLkTinLBTG1SHOBfynWCmRtj=4zkxsg5w@mail.gmail.com>	<4DCEA8F3.1090607@gmail.com>	<BANLkTimd+wOOoMaRJbU+MHNd3weOEZP4Cg@mail.gmail.com>
	<BANLkTi=VwP8S4KK77ZJ0cOriwUEiQrU7LQ@mail.gmail.com>
Message-ID: <4DCF1AFD.1060506@gmail.com>

On 5/14/11 4:02 PM, Jeffrey Ryan wrote:
> Yes, this should be altering the actual SQL to avoid reading the full series
> from the database.  Thanks for the report.
The problem I am having is with the retrieval of subset data from an
.rda file although this may also be the case with retrieving data from SQL.


> Jeff
>
> On Sat, May 14, 2011 at 11:28 AM, G See <gsee000 at gmail.com> wrote:
>
>> I've had this problem before.  I think it is a bug.  I got around it as
>> follows.
>>
>> rewrite getSymbols in your .GlobalEnv.  Just type getSymbols, and copy and
>> paste all the code, adding "<-" without the quotes between getSymbols and
>> function(...
>>
>> Now replace this line towards the end:
>> fr <- convert.time.series(fr = fr, return.class = return.class)
>>
>> with these lines:
>> fr <- quantmod:::convert.time.series(fr = fr, return.class = return.class)
>> fr <- fr[paste(from,to,sep='::')] #I added this so that from and to work
>>
>> It will still download all the data, but before returning it, it will
>> subset
>> it.
>>
>> HTH,
>> Garret
>>
>> On Sat, May 14, 2011 at 11:08 AM, s <algotr8der at gmail.com> wrote:
>>
>>> Thank you Garrett and Brian. I will take a look.
>>>
>>> In the mean time I just saved one of my symbols in mySQL to an rda file.
>>> I want to be able to retrieve a subset of the data using one of the
>>> getSymbols variants. Is this possible?
>>>
>>> For example, the time series for AMKR starts on 2002-04-08. I want to
>>> grab the subset between 2009-01-01 and end of day 2010-10-06. It appears
>>> the entire object is loaded. Appreciate the help.
>>>
>>>> getSymbols('AMKR', from="2009-01-01 09:31:00", to="2010-10-06
>>> 16:00:00", src='rda', col.names=c("open", "high", "low", "close",
>>> "volume"))
>>> [1] "AMKR"
>>>
>>>> head(AMKR)
>>>                    AMKR.open AMKR.high AMKR.low AMKR.close AMKR.volume
>>> 2002-04-08 09:31:00     21.50     21.50    21.42      21.42        7300
>>> 2002-04-08 09:32:00     21.41     21.46    21.39      21.40        1100
>>> 2002-04-08 09:33:00     21.35     21.35    21.30      21.30         900
>>> 2002-04-08 09:34:00     21.37     21.44    21.37      21.43        4100
>>> 2002-04-08 09:35:00     21.43     21.43    21.43      21.43         400
>>> 2002-04-08 09:36:00     21.43     21.43    21.35      21.37        3200
>>>
>>> Or even everything from 2009-01-01 onwards
>>>
>>>> getSymbols('AMKR', from="2009-01-01", src='rda', col.names=c("open",
>>> "high", "low", "close", "volume"))
>>>
>>> [1] "AMKR"
>>>
>>>> head(AMKR)
>>>                    AMKR.open AMKR.high AMKR.low AMKR.close AMKR.volume
>>> 2002-04-08 09:31:00     21.50     21.50    21.42      21.42        7300
>>> 2002-04-08 09:32:00     21.41     21.46    21.39      21.40        1100
>>> 2002-04-08 09:33:00     21.35     21.35    21.30      21.30         900
>>> 2002-04-08 09:34:00     21.37     21.44    21.37      21.43        4100
>>> 2002-04-08 09:35:00     21.43     21.43    21.43      21.43         400
>>> 2002-04-08 09:36:00     21.43     21.43    21.35      21.37        3200
>>>
>>> On 5/14/11 12:02 PM, G See wrote:
>>>> You could have different data files for different days, and write a
>>> wrapper
>>>> for getSymbols to rbind it all together when you need it. I think
>>>> getSymbols.FI, in the FinancialInstrument package, does this.
>>>>
>>>> On Sat, May 14, 2011 at 8:54 AM, s <algotr8der at gmail.com> wrote:
>>>>
>>>>> Now how do you maintain these rda files as new data arrives each day -
>>>>> is there some way of adding incremental data to the object? For
>> example
>>>>> if I have minute data for QQQ from 2002-01-01 to 2011-05-13 I don't
>> want
>>>>> to pull all of the data beginning 2002-01-01 from my source to update
>>>>> one day's worth of data at the end of business this coming Monday.
>>>>>
>>>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>


From arun.kumar.saha at gmail.com  Sun May 15 08:34:41 2011
From: arun.kumar.saha at gmail.com (Arun Kumar Saha)
Date: Sun, 15 May 2011 12:04:41 +0530
Subject: [R-SIG-Finance] options/BS/MC
In-Reply-To: <BANLkTin2uFsm+7ZbFaLVtvrLqsi2yddyUA@mail.gmail.com>
References: <BANLkTikH5o8wGt-qmm+Oj6yGg0uhP3XRYA@mail.gmail.com>
	<BANLkTin2uFsm+7ZbFaLVtvrLqsi2yddyUA@mail.gmail.com>
Message-ID: <BANLkTi=cP7OJXdKOBm9qiM0ZQjg3rHY9GA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110515/c8f6b774/attachment.pl>

From jgalt70 at yahoo.com  Sun May 15 11:55:44 2011
From: jgalt70 at yahoo.com (Andrew West)
Date: Sun, 15 May 2011 02:55:44 -0700
Subject: [R-SIG-Finance] 1
Message-ID: <250613.21748.qm@web65414.mail.ac4.yahoo.com>

Forget about overweight!... http://kristiang.kr.funpic.de/friends_links.php?axjID=20to0


From edd at debian.org  Sun May 15 16:09:12 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 15 May 2011 09:09:12 -0500
Subject: [R-SIG-Finance] 1
In-Reply-To: <250613.21748.qm@web65414.mail.ac4.yahoo.com>
References: <250613.21748.qm@web65414.mail.ac4.yahoo.com>
Message-ID: <19919.56968.520105.601909@max.nulle.part>


On 15 May 2011 at 02:55, Andrew West wrote:
| Forget about overweight!... http://kristiang.kr.funpic.de/friends_links.php?axjID=20to0

I unsubscribed this account as it is either a spambot, or coming from an
once-legit account now owned by a spambot.

Dirk, as admin

-- 
Gauss once played himself in a zero-sum game and won $50.
                      -- #11 at http://www.gaussfacts.com


From nealsmith314 at gmail.com  Sun May 15 17:04:59 2011
From: nealsmith314 at gmail.com (neal smith)
Date: Sun, 15 May 2011 11:04:59 -0400
Subject: [R-SIG-Finance] options/BS/MC
Message-ID: <BANLkTi=WSjPYAQ0pNucXhope-i1xrRH+GQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110515/afc304de/attachment.pl>

From breman.mark at gmail.com  Sun May 15 20:27:08 2011
From: breman.mark at gmail.com (Mark Breman)
Date: Sun, 15 May 2011 20:27:08 +0200
Subject: [R-SIG-Finance] 1
In-Reply-To: <19919.56968.520105.601909@max.nulle.part>
References: <250613.21748.qm@web65414.mail.ac4.yahoo.com>
	<19919.56968.520105.601909@max.nulle.part>
Message-ID: <BANLkTi=9VjR9RnQr1ksZJsELf7+Ls5GRZw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110515/05b0e533/attachment.pl>

From gsee000 at gmail.com  Sun May 15 22:39:01 2011
From: gsee000 at gmail.com (G See)
Date: Sun, 15 May 2011 15:39:01 -0500
Subject: [R-SIG-Finance] getSymbols.yahoo 'adjusting' to NA
Message-ID: <BANLkTinJUkHQYFoJBcoeiGn2TEhQaQF-CA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110515/ccf9f360/attachment.pl>

From josh.m.ulrich at gmail.com  Sun May 15 22:54:27 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 15 May 2011 15:54:27 -0500
Subject: [R-SIG-Finance] getSymbols.yahoo 'adjusting' to NA
In-Reply-To: <BANLkTinJUkHQYFoJBcoeiGn2TEhQaQF-CA@mail.gmail.com>
References: <BANLkTinJUkHQYFoJBcoeiGn2TEhQaQF-CA@mail.gmail.com>
Message-ID: <BANLkTimsiWWLntcwL6rM-hRQmR45p-DcOQ@mail.gmail.com>

On Sun, May 15, 2011 at 3:39 PM, G See <gsee000 at gmail.com> wrote:
> I think there is a bug somewhere in getSymbols.yahoo, but I haven't quite
> tracked it down.
>
> #First, an example of it working
> getSymbols('SPY', to='2011-01-01')
> SPY.adj <- adjustOHLC(SPY)
> head(SPY.adj) #as expected
>
> #Now, try again with earlier 'to' date
> getSymbols('SPY', to='2010-01-01')
> SPY.adj <- adjustOHLC(SPY)
> head(SPY.adj) #NA for Op,Hi,Lo,Cl
>
> # Try to do, "by hand," the same thing
> # that getSymbols.yahoo does
> getSymbols('SPY', to='2010-01-01')
> div <- getDividends('SPY',to='2010-01-01')
> spl <- getSplits('SPY',to='2010-01-01')
>
> adj <- na.omit(adjRatios(spl, div, Cl(SPY)))
> #head(adj); tail(adj)
>
> fr <- SPY
> fr[,1] <- fr[,1] * adj[, "Split"] * adj[, "Div"]
> fr[,2] <- fr[,2] * adj[, "Split"] * adj[, "Div"]
> fr[,3] <- fr[,3] * adj[, "Split"] * adj[, "Div"]
> fr[,4] <- fr[,4] * adj[, "Split"] * adj[, "Div"]
> fr[,5] <- fr[,5] * (1/adj[, "Div"])
>
> head(fr) #Why did that work?
>
Because you included the 'to' argument in your call to getDividends
and getSplits; and it's not included in those calls within
getSymbols.yahoo.  I'll take a closer look at this...

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


> ########### End code
>
> R> sessionInfo()
> R version 2.13.0 (2011-04-13)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
> LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
> ?LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] quantmod_0.3-15 TTR_0.20-3 ? ? ?xts_0.8-0 ? ? ? zoo_1.6-4
> Defaults_1.1-1
>
> loaded via a namespace (and not attached):
> [1] grid_2.13.0 ? ? lattice_0.19-26
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From gsee000 at gmail.com  Sun May 15 23:07:56 2011
From: gsee000 at gmail.com (G See)
Date: Sun, 15 May 2011 16:07:56 -0500
Subject: [R-SIG-Finance] getSymbols.yahoo 'adjusting' to NA
In-Reply-To: <BANLkTimsiWWLntcwL6rM-hRQmR45p-DcOQ@mail.gmail.com>
References: <BANLkTinJUkHQYFoJBcoeiGn2TEhQaQF-CA@mail.gmail.com>
	<BANLkTimsiWWLntcwL6rM-hRQmR45p-DcOQ@mail.gmail.com>
Message-ID: <BANLkTi=uOMYwhe_UGcaAwcRN7S_7qKOS6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110515/dd8743d0/attachment.pl>

From gsee000 at gmail.com  Sun May 15 23:13:55 2011
From: gsee000 at gmail.com (G See)
Date: Sun, 15 May 2011 16:13:55 -0500
Subject: [R-SIG-Finance] getSymbols.yahoo 'adjusting' to NA
In-Reply-To: <BANLkTimsiWWLntcwL6rM-hRQmR45p-DcOQ@mail.gmail.com>
References: <BANLkTinJUkHQYFoJBcoeiGn2TEhQaQF-CA@mail.gmail.com>
	<BANLkTimsiWWLntcwL6rM-hRQmR45p-DcOQ@mail.gmail.com>
Message-ID: <BANLkTi=cd46Ru1hiywsKoG8vefenQpt9Sg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110515/a55fe6b9/attachment.pl>

From gsee000 at gmail.com  Sun May 15 23:33:41 2011
From: gsee000 at gmail.com (G See)
Date: Sun, 15 May 2011 16:33:41 -0500
Subject: [R-SIG-Finance] getSymbols.yahoo 'adjusting' to NA
In-Reply-To: <BANLkTi=cd46Ru1hiywsKoG8vefenQpt9Sg@mail.gmail.com>
References: <BANLkTinJUkHQYFoJBcoeiGn2TEhQaQF-CA@mail.gmail.com>
	<BANLkTimsiWWLntcwL6rM-hRQmR45p-DcOQ@mail.gmail.com>
	<BANLkTi=cd46Ru1hiywsKoG8vefenQpt9Sg@mail.gmail.com>
Message-ID: <BANLkTinPwGLRQmXN3O4EtKdG=9TAUm-i4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110515/06b339f5/attachment.pl>

From rex at nosyntax.net  Mon May 16 00:20:36 2011
From: rex at nosyntax.net (rex)
Date: Sun, 15 May 2011 15:20:36 -0700
Subject: [R-SIG-Finance] options/BS/MC
In-Reply-To: <BANLkTikH5o8wGt-qmm+Oj6yGg0uhP3XRYA@mail.gmail.com>
References: <BANLkTikH5o8wGt-qmm+Oj6yGg0uhP3XRYA@mail.gmail.com>
Message-ID: <20110515222036.GA3954@honker>

neal smith <nealsmith314 at gmail.com> [2011-05-14 09:23]:
>However we are told that the option price doesn't depend on the mu of
>the stock, and there are stocks which have consistently higher mu's
>(BRK, GOOG) than other stocks (YHOO) for a similar level of vol.  So
>let's say I have a high-mu stock:
>
>mustocks<-exp(rnorm(10000, mean=.15, sd=vol))
>mucallvals<-pmax(0.,mustocks-strike)
>print(summary(mustocks))
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> 0.8155  1.0850  1.1630  1.1680  1.2440  1.7400
>
>print(summary(exp(-.02)*mucallvals))
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>0.00000 0.08153 0.15670 0.16590 0.23860 0.73860
>
>so i can buy this call for the BS price of $.05, which equals its
>discounted payoff in RN, but now on this high-mu underlying i get a mean
>discounted value of .165, ie. 200% mean roi, with the lower quartile
>giving a paltry 60% return.
>
>what am i doing wrong?

Nothing, unless you expect the values to be equal. The BSM value is
based on a hypothetical riskless hedge, but buying the option is
anything but riskless, and the expected future price of a high-mu
stock (and hence the call option) will be far different from the
expected future price of a stock with a mu equal to the riskless rate.

I found the Wilmott thread mostly unhelpful, and so I've put up a page
using R to illustrate the issues. I hope it's useful.

http://www.nosyntax.net/cfwiki/index.php/Trend_vs_option_value

Anyone may edit the page or the discussion page, and I encourage
comments on the discussion page. There may well be typos, but I hope
there are no conceptual blunders.

-rex
-- 
Democracy is the art and science of running the circus from 
the monkey cage. --H. L. Mencken


From Danilo.Mercurio at Sparinvest.com  Mon May 16 10:32:53 2011
From: Danilo.Mercurio at Sparinvest.com (Mercurio Danilo 1850 SPI)
Date: Mon, 16 May 2011 08:32:53 +0000
Subject: [R-SIG-Finance] strange trouble with timeSeries....
Message-ID: <1438F6C5E7F7884293F0B114502EA6F2016231@m0187.s-mxs.net>

Hi!

I very often use the time series library is "timeSeries".

In general I am very happy however a strange error occurs once in a while. At least I could not identifiy a tipical example.

Say  I have a multivariate time series X and X is a "timeSeries" object. It may happen that after manipulations on X, which should not change X
but give some output (i.e. input X in a function which gives the output Y), X is no more a "timeSeries" object, but simply a matrix.

When I realize it I usually coerce X to be a timeSeries once again (  X <- as.timeSeries(X) ).

However, this is a dirty workaround.

I am sorry that I cannot explain the problem in more detail.

Did anyone else experience the same problem?
Maybe I am not programming in a clean robust way? Can anyone send advice?

Many thanks!

Dr. Danilo Mercurio
ERSTE-SPARINVEST Kapitalanlagegesellschaft m.b.H
Quantitative Analyst, Global Strategies and Research

AT00951850 Global Strategies & Research
Sitz des Unternehmens: 1010 Wien, Habsburgergasse 1a
Tel.:   +43 (0) 50100 - 19957
Fax.:  +43 (0) 50100 9 - 19957
Mob.: +43 (0) 50100 6 - 19957

www.sparinvest.com
Handelsgericht Wien - FN 81876 g

ERSTE-SPARINVEST Kapitalanlagegesellschaft m.b.H. - Member of Erste Group


From josh.m.ulrich at gmail.com  Mon May 16 17:43:05 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 16 May 2011 10:43:05 -0500
Subject: [R-SIG-Finance] getSymbols.yahoo 'adjusting' to NA
In-Reply-To: <BANLkTinPwGLRQmXN3O4EtKdG=9TAUm-i4Q@mail.gmail.com>
References: <BANLkTinJUkHQYFoJBcoeiGn2TEhQaQF-CA@mail.gmail.com>
	<BANLkTimsiWWLntcwL6rM-hRQmR45p-DcOQ@mail.gmail.com>
	<BANLkTi=cd46Ru1hiywsKoG8vefenQpt9Sg@mail.gmail.com>
	<BANLkTinPwGLRQmXN3O4EtKdG=9TAUm-i4Q@mail.gmail.com>
Message-ID: <BANLkTimYw3hsbBTnKcEMBx19ReYykxM-Ng@mail.gmail.com>

Hi Garrett,

On Sun, May 15, 2011 at 4:33 PM, G See <gsee000 at gmail.com> wrote:
> Sorry. I see what you mean. adjustOHLC calls getDividends() without 'to'
> # Try to do, "by hand," the same thing
> # that getSymbols.yahoo does
> getSymbols('SPY', to='2010-01-01')
> div <- getDividends('SPY')
> spl <- getSplits('SPY')
> adj <- na.omit(adjRatios(spl, div, Cl(SPY)))
> #head(adj); tail(adj)
> fr <- SPY
> fr[,1] <- fr[,1] * adj[, "Split"] * adj[, "Div"]
> ###End code
> Now it hangs here
> Thanks for looking into this.
>
I consider this a bug in TTR::adjRatios.  It should discard any
split/dividend data that lie outside the range of the close data.  I
will patch tonight.

This issue manifests in adjustOHLC because all historical
split/dividend data for "x" is pulled, not just historical data up to
the last date in "x".  Perhaps adjustOHLC should use a "to=" argument
for getDividends and getSymbols as well...

Thanks for the report!

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com



> On Sun, May 15, 2011 at 4:13 PM, G See <gsee000 at gmail.com> wrote:
>>
>>> Because you included the 'to' argument in your call to getDividends
>>> and getSplits; and it's not included in those calls within
>>> getSymbols.yahoo. ?I'll take a closer look at this...
>>>
>>
>> I think it is worth mentioning that getSymbols.yahoo does, in fact, use
>> the 'to' argument to call getDividends and getSplits and is at least one
>> reason you get big differences in yahoo's Adjusted price and the Close price
>> after you adjust using either?adjustOHLC(), or?getSymbols() with
>> adjust=TRUE.
>>
>>>
>>> Best,
>>> --
>>> Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com
>>>
>>
>> Garrett
>


From noahsilverman at ucla.edu  Mon May 16 18:48:28 2011
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Mon, 16 May 2011 09:48:28 -0700
Subject: [R-SIG-Finance] Trading Platforms and APIs
Message-ID: <52CECF61-B5EA-4A41-9D6B-7F6A3CE930C8@ucla.edu>

Hi,

I'm looking for some suggestions as to a "good" trading platform/API for both academic research and possibly my own trading.  

The Interactive Brokers library for R is really very nice, but they have a rather large minimum account balance that I can't really meet as a student.  (They do have a "student level" rate, but I'm over the age limit, even though I'm 100% a full time student.)

So, does anyone in the group have any suggestions for an alternative.  While an R API would be ideal, I'm willing to work in C++, Java, or something else reasonable.

Thanks in advance for any and all suggestions!


--
Noah Silverman
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095


From bkheijonathan at gmail.com  Mon May 16 22:13:48 2011
From: bkheijonathan at gmail.com (B. Jonathan B. Jonathan)
Date: Tue, 17 May 2011 01:43:48 +0530
Subject: [R-SIG-Finance] A question on Hull
Message-ID: <BANLkTimvWVPQKPmgTk2t5xqFoq50DVU9Zw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110517/9572ce89/attachment.pl>

From gsee000 at gmail.com  Mon May 16 22:45:47 2011
From: gsee000 at gmail.com (G See)
Date: Mon, 16 May 2011 15:45:47 -0500
Subject: [R-SIG-Finance] quantstrat orders
Message-ID: <BANLkTimKRDsSa6cuMfSfgVu7S-7_HHLNNQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110516/87a759bd/attachment.pl>

From worik.stanton at gmail.com  Tue May 17 00:59:02 2011
From: worik.stanton at gmail.com (Worik Stanton)
Date: Tue, 17 May 2011 10:59:02 +1200
Subject: [R-SIG-Finance] na.omit.xts unsupported type error
Message-ID: <4DD1AC36.4090105@gmail.com>

Friends

I cannot see what I am doing wrong.

I have xts

 > Q.x
            return                 colour
1977-01-05 "0.00657131520848225"  "RED"
1977-01-06 "-0.012214299603114"   "RED"
1977-01-10 "-0.0104483453737235"  "RED"
1977-01-12 "-0.012253432045205"   "RED"
1977-01-17 "-0.00435933050375995" "RED"
1977-01-19 "0.00186556754505644"  "RED"

 > na.omit(Q.x)
Error in na.omit.xts(Q.x) : unsupported type

 > class(Q.x)
[1] "xts" "zoo"

I know there are no NAs in Q.x, but na.omit should still work surely?

cheers
Worik


From josh.m.ulrich at gmail.com  Tue May 17 02:02:30 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 16 May 2011 19:02:30 -0500
Subject: [R-SIG-Finance] na.omit.xts unsupported type error
In-Reply-To: <4DD1AC36.4090105@gmail.com>
References: <4DD1AC36.4090105@gmail.com>
Message-ID: <BANLkTimqxTki7wEsFHH-wxf8R50xdGrz-g@mail.gmail.com>

On Mon, May 16, 2011 at 5:59 PM, Worik Stanton <worik.stanton at gmail.com> wrote:
> Friends
>
> I cannot see what I am doing wrong.
>
> I have xts
>
>> Q.x
> ? ? ? ? ? return ? ? ? ? ? ? ? ? colour
> 1977-01-05 "0.00657131520848225" ?"RED"
> 1977-01-06 "-0.012214299603114" ? "RED"
> 1977-01-10 "-0.0104483453737235" ?"RED"
> 1977-01-12 "-0.012253432045205" ? "RED"
> 1977-01-17 "-0.00435933050375995" "RED"
> 1977-01-19 "0.00186556754505644" ?"RED"
>
>> na.omit(Q.x)
> Error in na.omit.xts(Q.x) : unsupported type
>
>> class(Q.x)
> [1] "xts" "zoo"
>
> I know there are no NAs in Q.x, but na.omit should still work surely?
>
> cheers
> Worik
>

You're not doing anything wrong, but the error tells you exactly
what's going on.  na.omit.xts doesn't currently support character
vectors.

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From jeff.a.ryan at gmail.com  Tue May 17 03:06:46 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 16 May 2011 20:06:46 -0500
Subject: [R-SIG-Finance] na.omit.xts unsupported type error
In-Reply-To: <BANLkTimqxTki7wEsFHH-wxf8R50xdGrz-g@mail.gmail.com>
References: <4DD1AC36.4090105@gmail.com>
	<BANLkTimqxTki7wEsFHH-wxf8R50xdGrz-g@mail.gmail.com>
Message-ID: <DCEEDB03-6495-4DDC-8440-F6B402C4441C@gmail.com>

Yes, currently only logical, integer and reals are supported at the C level. Mostly due to time/demand constraints.  

Since changing it, you are the first to mention it - so my suspicion is that it is reasonable. That said, I will add what I can in the C and try an cover remaining cases in R logic around. 

I'll also add something in the docs. 

Thanks,
Jeff

Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com

www.lemnica.com

On May 16, 2011, at 7:02 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:

> On Mon, May 16, 2011 at 5:59 PM, Worik Stanton <worik.stanton at gmail.com> wrote:
>> Friends
>> 
>> I cannot see what I am doing wrong.
>> 
>> I have xts
>> 
>>> Q.x
>>          return                 colour
>> 1977-01-05 "0.00657131520848225"  "RED"
>> 1977-01-06 "-0.012214299603114"   "RED"
>> 1977-01-10 "-0.0104483453737235"  "RED"
>> 1977-01-12 "-0.012253432045205"   "RED"
>> 1977-01-17 "-0.00435933050375995" "RED"
>> 1977-01-19 "0.00186556754505644"  "RED"
>> 
>>> na.omit(Q.x)
>> Error in na.omit.xts(Q.x) : unsupported type
>> 
>>> class(Q.x)
>> [1] "xts" "zoo"
>> 
>> I know there are no NAs in Q.x, but na.omit should still work surely?
>> 
>> cheers
>> Worik
>> 
> 
> You're not doing anything wrong, but the error tells you exactly
> what's going on.  na.omit.xts doesn't currently support character
> vectors.
> 
> Best,
> --
> Joshua Ulrich  |  FOSS Trading: www.fosstrading.com
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From worik.stanton at gmail.com  Tue May 17 03:27:18 2011
From: worik.stanton at gmail.com (Worik Stanton)
Date: Tue, 17 May 2011 13:27:18 +1200
Subject: [R-SIG-Finance] na.omit.xts unsupported type error
In-Reply-To: <BANLkTimqxTki7wEsFHH-wxf8R50xdGrz-g@mail.gmail.com>
References: <4DD1AC36.4090105@gmail.com>
	<BANLkTimqxTki7wEsFHH-wxf8R50xdGrz-g@mail.gmail.com>
Message-ID: <4DD1CEF6.8000100@gmail.com>

On 17/05/11 12:02, Joshua Ulrich wrote:
> You're not doing anything wrong, but the error tells you exactly
> what's going on.  na.omit.xts doesn't currently support character
> vectors.
Okidoki.  I can manage.

> Since changing it, you are the first to mention it - so my suspicion is that it is reasonable. That said, I will add what I can in the C and try an cover remaining cases in R logic around.
If it is only me, why bother.  An error message that said what column 
the unsupported type was in would have helped.  That may be more 
straightforward?
> I'll also add something in the docs.
Duh!  I did not even check ?na.omit.xts!

Thanks for the help, I can cope splendidly from here!

cheers
Worik


From worik.stanton at gmail.com  Tue May 17 03:31:51 2011
From: worik.stanton at gmail.com (Worik Stanton)
Date: Tue, 17 May 2011 13:31:51 +1200
Subject: [R-SIG-Finance] na.omit.xts unsupported type error
In-Reply-To: <BANLkTimqxTki7wEsFHH-wxf8R50xdGrz-g@mail.gmail.com>
References: <4DD1AC36.4090105@gmail.com>
	<BANLkTimqxTki7wEsFHH-wxf8R50xdGrz-g@mail.gmail.com>
Message-ID: <4DD1D007.4010106@gmail.com>

Dang!

 > Q.x[,1] <- as.numeric(Q.x[,1])
 > na.omit(Q.x[,1])
Error in na.omit.xts(Q.x[, 1]) : unsupported type

That is surprising.  Any ideas why I cannot coerce it to numeric?

 > Z.x <- xts(as.numeric(Q.x[,1]), index(Q.x))
 > Z.x
                    [,1]
1977-01-05  0.006571315
1977-01-06 -0.012214300
1977-01-10 -0.010448345
1977-01-12 -0.012253432
1977-01-17 -0.004359331
1977-01-19  0.001865568

That works.  So I have no crises, but it is odd.

W

On 17/05/11 12:02, Joshua Ulrich wrote:
> On Mon, May 16, 2011 at 5:59 PM, Worik Stanton<worik.stanton at gmail.com>  wrote:
>> Friends
>>
>> I cannot see what I am doing wrong.
>>
>> I have xts
>>
>>> Q.x
>>            return                 colour
>> 1977-01-05 "0.00657131520848225"  "RED"
>> 1977-01-06 "-0.012214299603114"   "RED"
>> 1977-01-10 "-0.0104483453737235"  "RED"
>> 1977-01-12 "-0.012253432045205"   "RED"
>> 1977-01-17 "-0.00435933050375995" "RED"
>> 1977-01-19 "0.00186556754505644"  "RED"
>>
>>> na.omit(Q.x)
>> Error in na.omit.xts(Q.x) : unsupported type
>>
>>> class(Q.x)
>> [1] "xts" "zoo"
>>
>> I know there are no NAs in Q.x, but na.omit should still work surely?
>>
>> cheers
>> Worik
>>
> You're not doing anything wrong, but the error tells you exactly
> what's going on.  na.omit.xts doesn't currently support character
> vectors.
>
> Best,
> --
> Joshua Ulrich  |  FOSS Trading: www.fosstrading.com
>


From josh.m.ulrich at gmail.com  Tue May 17 03:36:13 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 16 May 2011 20:36:13 -0500
Subject: [R-SIG-Finance] na.omit.xts unsupported type error
In-Reply-To: <4DD1D007.4010106@gmail.com>
References: <4DD1AC36.4090105@gmail.com>
	<BANLkTimqxTki7wEsFHH-wxf8R50xdGrz-g@mail.gmail.com>
	<4DD1D007.4010106@gmail.com>
Message-ID: <BANLkTikidasVtXbBWXRbfwbOEsvWumPKoA@mail.gmail.com>

On Mon, May 16, 2011 at 8:31 PM, Worik Stanton <worik.stanton at gmail.com> wrote:
> Dang!
>
>> Q.x[,1] <- as.numeric(Q.x[,1])
>> na.omit(Q.x[,1])
> Error in na.omit.xts(Q.x[, 1]) : unsupported type
>
> That is surprising. ?Any ideas why I cannot coerce it to numeric?
>
xts / zoo objects are a matrix with an index attribute.  You can't mix
types in a matrix.

>> Z.x <- xts(as.numeric(Q.x[,1]), index(Q.x))
>> Z.x
> ? ? ? ? ? ? ? ? ? [,1]
> 1977-01-05 ?0.006571315
> 1977-01-06 -0.012214300
> 1977-01-10 -0.010448345
> 1977-01-12 -0.012253432
> 1977-01-17 -0.004359331
> 1977-01-19 ?0.001865568
>
> That works. ?So I have no crises, but it is odd.
>
> W
>

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com



> On 17/05/11 12:02, Joshua Ulrich wrote:
>>
>> On Mon, May 16, 2011 at 5:59 PM, Worik Stanton<worik.stanton at gmail.com>
>> ?wrote:
>>>
>>> Friends
>>>
>>> I cannot see what I am doing wrong.
>>>
>>> I have xts
>>>
>>>> Q.x
>>>
>>> ? ? ? ? ? return ? ? ? ? ? ? ? ? colour
>>> 1977-01-05 "0.00657131520848225" ?"RED"
>>> 1977-01-06 "-0.012214299603114" ? "RED"
>>> 1977-01-10 "-0.0104483453737235" ?"RED"
>>> 1977-01-12 "-0.012253432045205" ? "RED"
>>> 1977-01-17 "-0.00435933050375995" "RED"
>>> 1977-01-19 "0.00186556754505644" ?"RED"
>>>
>>>> na.omit(Q.x)
>>>
>>> Error in na.omit.xts(Q.x) : unsupported type
>>>
>>>> class(Q.x)
>>>
>>> [1] "xts" "zoo"
>>>
>>> I know there are no NAs in Q.x, but na.omit should still work surely?
>>>
>>> cheers
>>> Worik
>>>
>> You're not doing anything wrong, but the error tells you exactly
>> what's going on. ?na.omit.xts doesn't currently support character
>> vectors.
>>
>> Best,
>> --
>> Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com
>>
>
>


From massimo.salese at gmail.com  Tue May 17 11:36:36 2011
From: massimo.salese at gmail.com (msalese)
Date: Tue, 17 May 2011 02:36:36 -0700 (PDT)
Subject: [R-SIG-Finance] fOptions American options Implied Volatility
Message-ID: <1305624996795-3528629.post@n4.nabble.com>

Hi guys,
working with RMetrics/fOptions library I see there isn't a function to
compute iv on American Options so I've build this function to do the job:

library(fOptions)

impVolAmCall<-function(pmkPrice,Und,Strike,expTime,rInt,pb){
  auxAmCall<-function(pVol,pmkPrice,pUnd,pStrike,pexpTime,prInt){
    at<-CRRBinomialTreeOption(TypeFlag = "ca", S = pUnd, X=pStrike,Time
=pexpTime, r = prInt, b = pb, sigma = pVol, n = 15)
    return(pmkPrice-at at price)
  }
  
limpVol<-uniroot(f=auxAmCall,lower=0.05,upper=2,tol=0.001,pmkPrice=pmkPrice,pUnd=Und,pStrike=Strike,pexpTime=expTime,prInt=rInt)
  return(limpVol$root)
} 

After that I downloaded options price from Italian IDEM on G.MI (Generali
Assurance) and loaded all in the obsPrice3 data.frame:

str(obsPrice3)
'data.frame':	12 obs. of  6 variables:
 $ expDays : num  59 59 59 59 59 59 59 59 59 59 ...
 $ YExpDays: num  0.234 0.234 0.234 0.234 0.234 ...
 $ Bid     : num  2.219 1.726 1.249 0.845 0.544 ...
 $ Ask     : num  2.266 1.769 1.293 0.883 0.579 ...
 $ Strike  : num  13.5 14 14.5 15 15.5 16 16.5 17 17.5 18 ...
 $ MidPrice: num  2.242 1.747 1.271 0.864 0.561 ...


expDays YExpDays    Bid    Ask Strike MidPrice
1       59 0.234127 2.2190 2.2660   13.5  2.24250
2       59 0.234127 1.7255 1.7690   14.0  1.74725
3       59 0.234127 1.2490 1.2930   14.5  1.27100
4       59 0.234127 0.8450 0.8830   15.0  0.86400
5       59 0.234127 0.5445 0.5785   15.5  0.56150
6       59 0.234127 0.3325 0.3670   16.0  0.34975
7       59 0.234127 0.1895 0.2180   16.5  0.20375
8       59 0.234127 0.1010 0.1280   17.0  0.11450
9       59 0.234127 0.0485 0.0760   17.5  0.06225
10      59 0.234127 0.0115 0.0445   18.0  0.02800
11      59 0.234127 0.0005 0.0830   18.5  0.04175
12      59 0.234127 0.0005 0.0775   19.0  0.03900

Now I'd like to compute the iv for all the chain so I've used mapply:

mapply(FUN=impVolAmCall,obsPrice3$MidPrice,obsPrice3$Strike,Und=15.75,expTime=59/252,rInt=0.01,pb=0.01)
but R replay with:

Error in uniroot(f = auxAmCall, lower = 0.05, upper = 2, tol = 0.001,  : 
  f() values at end points not of opposite sign

The point is that for otm options I'm not able to find zero in auxAmCall
(auxiliary function) coded inside impVolAmCall function. 
I'm new to R so I think that something is wrong in my code, can someone help
me ? 

Thanks
Massimo
http://r.789695.n4.nabble.com/file/n3528629/obsPrice3.rda obsPrice3.rda 

--
View this message in context: http://r.789695.n4.nabble.com/fOptions-American-options-Implied-Volatility-tp3528629p3528629.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From David.Reiner at xrtrading.com  Tue May 17 15:44:41 2011
From: David.Reiner at xrtrading.com (David Reiner)
Date: Tue, 17 May 2011 08:44:41 -0500
Subject: [R-SIG-Finance] [SPAM] - fOptions American options Implied
 Volatility - Email found in subject
In-Reply-To: <1305624996795-3528629.post@n4.nabble.com>
References: <1305624996795-3528629.post@n4.nabble.com>
Message-ID: <9DE405308A6AA24AA794B76282C6C00F1A19BA80@HQ-POST1>

Massimo,
This stock has dividends, so you might have to use a different valuation model for American valuation.
Some sort of discrete dividend model should work.
HTH,
-- David


-----Original Message-----
From: r-sig-finance-bounces at r-project.org [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of msalese
Sent: Tuesday, May 17, 2011 4:37 AM
To: r-sig-finance at r-project.org
Subject: [SPAM] - [R-SIG-Finance] fOptions American options Implied Volatility - Email found in subject

Hi guys,
working with RMetrics/fOptions library I see there isn't a function to
compute iv on American Options so I've build this function to do the job:

library(fOptions)

impVolAmCall<-function(pmkPrice,Und,Strike,expTime,rInt,pb){
  auxAmCall<-function(pVol,pmkPrice,pUnd,pStrike,pexpTime,prInt){
    at<-CRRBinomialTreeOption(TypeFlag = "ca", S = pUnd, X=pStrike,Time
=pexpTime, r = prInt, b = pb, sigma = pVol, n = 15)
    return(pmkPrice-at at price)
  }

limpVol<-uniroot(f=auxAmCall,lower=0.05,upper=2,tol=0.001,pmkPrice=pmkPrice,pUnd=Und,pStrike=Strike,pexpTime=expTime,prInt=rInt)
  return(limpVol$root)
}

After that I downloaded options price from Italian IDEM on G.MI (Generali
Assurance) and loaded all in the obsPrice3 data.frame:

str(obsPrice3)
'data.frame':   12 obs. of  6 variables:
 $ expDays : num  59 59 59 59 59 59 59 59 59 59 ...
 $ YExpDays: num  0.234 0.234 0.234 0.234 0.234 ...
 $ Bid     : num  2.219 1.726 1.249 0.845 0.544 ...
 $ Ask     : num  2.266 1.769 1.293 0.883 0.579 ...
 $ Strike  : num  13.5 14 14.5 15 15.5 16 16.5 17 17.5 18 ...
 $ MidPrice: num  2.242 1.747 1.271 0.864 0.561 ...


expDays YExpDays    Bid    Ask Strike MidPrice
1       59 0.234127 2.2190 2.2660   13.5  2.24250
2       59 0.234127 1.7255 1.7690   14.0  1.74725
3       59 0.234127 1.2490 1.2930   14.5  1.27100
4       59 0.234127 0.8450 0.8830   15.0  0.86400
5       59 0.234127 0.5445 0.5785   15.5  0.56150
6       59 0.234127 0.3325 0.3670   16.0  0.34975
7       59 0.234127 0.1895 0.2180   16.5  0.20375
8       59 0.234127 0.1010 0.1280   17.0  0.11450
9       59 0.234127 0.0485 0.0760   17.5  0.06225
10      59 0.234127 0.0115 0.0445   18.0  0.02800
11      59 0.234127 0.0005 0.0830   18.5  0.04175
12      59 0.234127 0.0005 0.0775   19.0  0.03900

Now I'd like to compute the iv for all the chain so I've used mapply:

mapply(FUN=impVolAmCall,obsPrice3$MidPrice,obsPrice3$Strike,Und=15.75,expTime=59/252,rInt=0.01,pb=0.01)
but R replay with:

Error in uniroot(f = auxAmCall, lower = 0.05, upper = 2, tol = 0.001,  :
  f() values at end points not of opposite sign

The point is that for otm options I'm not able to find zero in auxAmCall
(auxiliary function) coded inside impVolAmCall function.
I'm new to R so I think that something is wrong in my code, can someone help
me ?

Thanks
Massimo
http://r.789695.n4.nabble.com/file/n3528629/obsPrice3.rda obsPrice3.rda

--
View this message in context: http://r.789695.n4.nabble.com/fOptions-American-options-Implied-Volatility-tp3528629p3528629.html
Sent from the Rmetrics mailing list archive at Nabble.com.

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.

THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON'S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.


From p.desmazis at gmail.com  Tue May 17 17:19:20 2011
From: p.desmazis at gmail.com (des Mazis, Pierre-Alexandre)
Date: Tue, 17 May 2011 15:19:20 +0000
Subject: [R-SIG-Finance] Universal Portfolios
Message-ID: <1930696726-1305645563-cardhu_decombobulator_blackberry.rim.net-82949334-@b13.c12.bise7.blackberry>

Hi everyone,

Have you ever heard of any implementation in R of the theory developped by Thomas Cover regarding "Universal Portfolios"? Any help would be greatly appreciated.

Thank you.

Regards,
Sent using BlackBerry? from Orange

From massimo.salese at gmail.com  Tue May 17 18:02:01 2011
From: massimo.salese at gmail.com (msalese)
Date: Tue, 17 May 2011 09:02:01 -0700 (PDT)
Subject: [R-SIG-Finance]  fOptions American options Implied Volatility
In-Reply-To: <9DE405308A6AA24AA794B76282C6C00F1A19BA80@HQ-POST1>
References: <1305624996795-3528629.post@n4.nabble.com>
	<9DE405308A6AA24AA794B76282C6C00F1A19BA80@HQ-POST1>
Message-ID: <1305648121072-3529697.post@n4.nabble.com>

Thanks much David ,
the problem is that RMetrics/fOptions has only this valuation code:

RollGeskeWhaleyOption	         Roll, Geske and Whaley Approximation,
BAWAmericanApproxOption	 Barone-Adesi and Whaley Approximation,
BSAmericanApproxOption	        Bjerksund and Stensland Approximation.

Only the first one take care of dividends !

What I'm trying to do is to valuate the iv smile in the same way as Sheldon
Natenberg or Robert G. Tompkins does in their books, build an iv function
and use that to run a what-if scenario on my positions.
  
So I'll tray to use RollGeskeWhaleyOption approx in the same way as done for
CRRBinomialTreeOption.




--
View this message in context: http://r.789695.n4.nabble.com/fOptions-American-options-Implied-Volatility-tp3528629p3529697.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From stefano.iacus at unimi.it  Tue May 17 18:09:15 2011
From: stefano.iacus at unimi.it (stefano iacus)
Date: Tue, 17 May 2011 18:09:15 +0200
Subject: [R-SIG-Finance] fOptions American options Implied Volatility
In-Reply-To: <1305624996795-3528629.post@n4.nabble.com>
References: <1305624996795-3528629.post@n4.nabble.com>
Message-ID: <DAF5685C-D64E-4B9C-A72B-17F85E4A5E89@unimi.it>


On 17 May 2011, at 11:36, msalese wrote:

> Hi guys,
> working with RMetrics/fOptions library I see there isn't a function to
> compute iv on American Options so I've build this function to do the job:
> 
> library(fOptions)
> 
> impVolAmCall<-function(pmkPrice,Und,Strike,expTime,rInt,pb){
> auxAmCall<-function(pVol,pmkPrice,pUnd,pStrike,pexpTime,prInt){
>   at<-CRRBinomialTreeOption(TypeFlag = "ca", S = pUnd, X=pStrike,Time
> =pexpTime, r = prInt, b = pb, sigma = pVol, n = 15)
>   return(pmkPrice-at at price)
> }
> 
> limpVol<-uniroot(f=auxAmCall,lower=0.05,upper=2,tol=0.001,pmkPrice=pmkPrice,pUnd=Und,pStrike=Strike,pexpTime=expTime,prInt=rInt)
> return(limpVol$root)
> } 
> 
> After that I downloaded options price from Italian IDEM on G.MI (Generali
> Assurance) and loaded all in the obsPrice3 data.frame:
> 
> str(obsPrice3)
> 'data.frame':	12 obs. of  6 variables:
> $ expDays : num  59 59 59 59 59 59 59 59 59 59 ...
> $ YExpDays: num  0.234 0.234 0.234 0.234 0.234 ...
> $ Bid     : num  2.219 1.726 1.249 0.845 0.544 ...
> $ Ask     : num  2.266 1.769 1.293 0.883 0.579 ...
> $ Strike  : num  13.5 14 14.5 15 15.5 16 16.5 17 17.5 18 ...
> $ MidPrice: num  2.242 1.747 1.271 0.864 0.561 ...
> 
> 
> expDays YExpDays    Bid    Ask Strike MidPrice
> 1       59 0.234127 2.2190 2.2660   13.5  2.24250
> 2       59 0.234127 1.7255 1.7690   14.0  1.74725
> 3       59 0.234127 1.2490 1.2930   14.5  1.27100
> 4       59 0.234127 0.8450 0.8830   15.0  0.86400
> 5       59 0.234127 0.5445 0.5785   15.5  0.56150
> 6       59 0.234127 0.3325 0.3670   16.0  0.34975
> 7       59 0.234127 0.1895 0.2180   16.5  0.20375
> 8       59 0.234127 0.1010 0.1280   17.0  0.11450
> 9       59 0.234127 0.0485 0.0760   17.5  0.06225
> 10      59 0.234127 0.0115 0.0445   18.0  0.02800
> 11      59 0.234127 0.0005 0.0830   18.5  0.04175
> 12      59 0.234127 0.0005 0.0775   19.0  0.03900
> 
> Now I'd like to compute the iv for all the chain so I've used mapply:
> 
> mapply(FUN=impVolAmCall,obsPrice3$MidPrice,obsPrice3$Strike,Und=15.75,expTime=59/252,rInt=0.01,pb=0.01)
> but R replay with:
> 
> Error in uniroot(f = auxAmCall, lower = 0.05, upper = 2, tol = 0.001,  : 
> f() values at end points not of opposite sign

this means that f() never crosses zero, either always negative or always positive. This happens a bunch of times when you try to estimate IV from, say, a "wrong" model or if market prices are way too off the theoretical (up to the wrong model for these data) price.

no real clue, just some experience

stefano


> 
> The point is that for otm options I'm not able to find zero in auxAmCall
> (auxiliary function) coded inside impVolAmCall function. 
> I'm new to R so I think that something is wrong in my code, can someone help
> me ? 
> 
> Thanks
> Massimo
> http://r.789695.n4.nabble.com/file/n3528629/obsPrice3.rda obsPrice3.rda 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/fOptions-American-options-Implied-Volatility-tp3528629p3528629.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


-----------------------------------
Stefano M. Iacus
Department of Economics,
Business and Statistics
University of Milan
Via Conservatorio, 7
I-20123 Milan - Italy
Ph.: +39 02 50321 461
Fax: +39 02 50321 505
http://www.economia.unimi.it/iacus
------------------------------------------------------------------------------------
Please don't send me Word or PowerPoint attachments if not 
absolutely necessary. See:
http://www.gnu.org/philosophy/no-word-attachments.html


From mdelvaux at gmail.com  Tue May 17 20:17:01 2011
From: mdelvaux at gmail.com (Marc Delvaux)
Date: Tue, 17 May 2011 11:17:01 -0700
Subject: [R-SIG-Finance] Universal Portfolios
In-Reply-To: <1930696726-1305645563-cardhu_decombobulator_blackberry.rim.net-82949334-@b13.c12.bise7.blackberry>
References: <1930696726-1305645563-cardhu_decombobulator_blackberry.rim.net-82949334-@b13.c12.bise7.blackberry>
Message-ID: <BANLkTi=VSAHBAM0+KLBp-nJkhpJsyaG-oA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110517/b09fb1b7/attachment.pl>

From lfanff at gmail.com  Tue May 17 20:41:03 2011
From: lfanff at gmail.com (Lu Fan)
Date: Tue, 17 May 2011 14:41:03 -0400
Subject: [R-SIG-Finance] rolling regression estimate std. error / t value
Message-ID: <BANLkTin8jFyL-0-Y9r9g+R+MD+nM1=PfGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110517/38bd75c0/attachment.pl>

From p.desmazis at gmail.com  Tue May 17 21:32:30 2011
From: p.desmazis at gmail.com (des Mazis, Pierre-Alexandre)
Date: Tue, 17 May 2011 19:32:30 +0000
Subject: [R-SIG-Finance] Universal Portfolios
In-Reply-To: <BANLkTi=VSAHBAM0+KLBp-nJkhpJsyaG-oA@mail.gmail.com>
References: <1930696726-1305645563-cardhu_decombobulator_blackberry.rim.net-82949334-@b13.c12.bise7.blackberry><BANLkTi=VSAHBAM0+KLBp-nJkhpJsyaG-oA@mail.gmail.com>
Message-ID: <2053372727-1305660758-cardhu_decombobulator_blackberry.rim.net-1950199072-@b13.c12.bise7.blackberry>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110517/7d4b6674/attachment.pl>

From brian at braverock.com  Tue May 17 18:10:26 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 17 May 2011 11:10:26 -0500
Subject: [R-SIG-Finance] Universal Portfolios
Message-ID: <db0f79a2-074a-4074-8030-7e4135b4b15d@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110517/e3801ae0/attachment.pl>

From p.desmazis at gmail.com  Tue May 17 22:04:34 2011
From: p.desmazis at gmail.com (des Mazis, Pierre-Alexandre)
Date: Tue, 17 May 2011 20:04:34 +0000
Subject: [R-SIG-Finance] rolling regression estimate std. error / t value
In-Reply-To: <BANLkTin8jFyL-0-Y9r9g+R+MD+nM1=PfGA@mail.gmail.com>
References: <BANLkTin8jFyL-0-Y9r9g+R+MD+nM1=PfGA@mail.gmail.com>
Message-ID: <534356054-1305662689-cardhu_decombobulator_blackberry.rim.net-318484145-@b13.c12.bise7.blackberry>

Hi Lu Fan,

I think you should change the FUN function in your rollapply to something that computes the coefficients and the stats you are interested in and returns the concatenation of the results using as.numeric format.

Regards
Sent using BlackBerry? from Orange

-----Original Message-----
From: Lu Fan <lfanff at gmail.com>
Sender: r-sig-finance-bounces at r-project.orgDate: Tue, 17 May 2011 14:41:03 
To: <r-sig-finance at r-project.org>
Subject: [R-SIG-Finance] rolling regression estimate std. error / t value

Dear all,

The following codes is for a multi-factor rolling regression with rolling
window = 60:

> z<-read.table("C:/.../dataset.txt")
> library(zoo)
> mydata=zoo(z)
> coef=rollapply(mydata,width=60,function(x) coef(lm(y~f1+f2+f3+f4+f5,
data=as.data.frame(x))),by.column=FALSE,align="right")

The result is shown below:

     (Intercept)          f1          f2           f3          f4         f5
60    2.61433094  0.16136881 -0.72852878  -1.62169901 -28.7663294 -1.0079586
61    2.36795263  0.14779184 -0.72893841  -1.42712190 -28.9783777 -1.0877425
62    1.80016092  0.13134766 -0.75010570  -0.92525342 -27.2138634 -1.0736837
63    1.76904728  0.05141441 -0.94569512  -0.34299478 -19.7857978 -0.6615184
64    2.29169442  0.13725741 -0.65519163  -1.44045686 -24.1101822 -0.8517188
65    2.19904020  0.16520775 -0.58812883  -1.52981468 -24.9350513 -0.9234610
66    1.84645778  0.23440231 -0.54350214  -1.42709733 -21.7792819 -0.8785267
67    1.60558115  0.30913187 -0.25909438  -1.82122203 -21.1839368 -0.8866916
68    1.49679459  0.31441766 -0.40952404  -1.52307138 -18.5434502 -1.0317272
69    2.02789774  0.20500137 -0.65737973  -1.34524065 -17.1654126 -0.8685087
70    2.11604869  0.09416856 -0.93294824  -0.74672358 -16.8795155 -0.8370804
71    1.73134487 -0.01723606 -1.41291550   0.53813772 -15.0169149 -0.9722847

So these are the regression coefficients; my question is how can I get
estimate std. error or t-value for these coefficients on a rolling basis?
Can I also add multicollinearity testing in this code?

Thank you in advance!

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.

From lfanff at gmail.com  Tue May 17 22:15:08 2011
From: lfanff at gmail.com (Lu Fan)
Date: Tue, 17 May 2011 16:15:08 -0400
Subject: [R-SIG-Finance] rolling regression estimate std. error / t value
In-Reply-To: <534356054-1305662689-cardhu_decombobulator_blackberry.rim.net-318484145-@b13.c12.bise7.blackberry>
References: <BANLkTin8jFyL-0-Y9r9g+R+MD+nM1=PfGA@mail.gmail.com>
	<534356054-1305662689-cardhu_decombobulator_blackberry.rim.net-318484145-@b13.c12.bise7.blackberry>
Message-ID: <BANLkTinNBXNZMYdp2OQoGBe97Xfx8hEk5g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110517/a971e884/attachment.pl>

From p.desmazis at gmail.com  Tue May 17 22:31:39 2011
From: p.desmazis at gmail.com (des Mazis, Pierre-Alexandre)
Date: Tue, 17 May 2011 20:31:39 +0000
Subject: [R-SIG-Finance] rolling regression estimate std. error / t value
In-Reply-To: <BANLkTinNBXNZMYdp2OQoGBe97Xfx8hEk5g@mail.gmail.com>
References: <BANLkTin8jFyL-0-Y9r9g+R+MD+nM1=PfGA@mail.gmail.com><534356054-1305662689-cardhu_decombobulator_blackberry.rim.net-318484145-@b13.c12.bise7.blackberry><BANLkTinNBXNZMYdp2OQoGBe97Xfx8hEk5g@mail.gmail.com>
Message-ID: <379001603-1305664331-cardhu_decombobulator_blackberry.rim.net-985701696-@b13.c12.bise7.blackberry>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110517/e3bedeba/attachment.pl>

From lfanff at gmail.com  Tue May 17 22:41:08 2011
From: lfanff at gmail.com (Lu Fan)
Date: Tue, 17 May 2011 16:41:08 -0400
Subject: [R-SIG-Finance] rolling regression estimate std. error / t value
In-Reply-To: <379001603-1305664331-cardhu_decombobulator_blackberry.rim.net-985701696-@b13.c12.bise7.blackberry>
References: <BANLkTin8jFyL-0-Y9r9g+R+MD+nM1=PfGA@mail.gmail.com>
	<534356054-1305662689-cardhu_decombobulator_blackberry.rim.net-318484145-@b13.c12.bise7.blackberry>
	<BANLkTinNBXNZMYdp2OQoGBe97Xfx8hEk5g@mail.gmail.com>
	<379001603-1305664331-cardhu_decombobulator_blackberry.rim.net-985701696-@b13.c12.bise7.blackberry>
Message-ID: <BANLkTimtDgYDtuEsZTJD3rmkkjf4iYUMHA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110517/fd3d40bf/attachment.pl>

From p.desmazis at gmail.com  Tue May 17 22:44:52 2011
From: p.desmazis at gmail.com (des Mazis, Pierre-Alexandre)
Date: Tue, 17 May 2011 20:44:52 +0000
Subject: [R-SIG-Finance] rolling regression estimate std. error / t value
In-Reply-To: <BANLkTimtDgYDtuEsZTJD3rmkkjf4iYUMHA@mail.gmail.com>
References: <BANLkTin8jFyL-0-Y9r9g+R+MD+nM1=PfGA@mail.gmail.com><534356054-1305662689-cardhu_decombobulator_blackberry.rim.net-318484145-@b13.c12.bise7.blackberry><BANLkTinNBXNZMYdp2OQoGBe97Xfx8hEk5g@mail.gmail.com><379001603-1305664331-cardhu_decombobulator_blackberry.rim.net-985701696-@b13.c12.bise7.blackberry><BANLkTimtDgYDtuEsZTJD3rmkkjf4iYUMHA@mail.gmail.com>
Message-ID: <854339777-1305665109-cardhu_decombobulator_blackberry.rim.net-362558289-@b13.c12.bise7.blackberry>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110517/d113b309/attachment.pl>

From jyan at alphabetfunds.com  Tue May 17 22:54:41 2011
From: jyan at alphabetfunds.com (Jeff Yan)
Date: Tue, 17 May 2011 16:54:41 -0400
Subject: [R-SIG-Finance] Multivariate cointegration framework in R?
In-Reply-To: <BANLkTi=VSAHBAM0+KLBp-nJkhpJsyaG-oA@mail.gmail.com>
References: <1930696726-1305645563-cardhu_decombobulator_blackberry.rim.net-82949334-@b13.c12.bise7.blackberry>
	<BANLkTi=VSAHBAM0+KLBp-nJkhpJsyaG-oA@mail.gmail.com>
Message-ID: <DA86665BCA2EEB4C9D98F7006B30D6B3032C24D426@pit-exmbx-02>

Hey everyone


I was wondering if there is any library/framework in R that handles multivariate cointegration, like one-variate is handled.

Thanks, Jeff

The information contained in this electronic message is ...{{dropped:21}}


From algotr8der at gmail.com  Tue May 17 23:02:27 2011
From: algotr8der at gmail.com (s)
Date: Tue, 17 May 2011 17:02:27 -0400
Subject: [R-SIG-Finance] Multivariate cointegration framework in R?
In-Reply-To: <DA86665BCA2EEB4C9D98F7006B30D6B3032C24D426@pit-exmbx-02>
References: <1930696726-1305645563-cardhu_decombobulator_blackberry.rim.net-82949334-@b13.c12.bise7.blackberry>	<BANLkTi=VSAHBAM0+KLBp-nJkhpJsyaG-oA@mail.gmail.com>
	<DA86665BCA2EEB4C9D98F7006B30D6B3032C24D426@pit-exmbx-02>
Message-ID: <4DD2E263.2080504@gmail.com>

check out the 'ca.jo' function in the 'urca' package.

HTH
On 5/17/11 4:54 PM, Jeff Yan wrote:
> Hey everyone
>
>
> I was wondering if there is any library/framework in R that handles multivariate cointegration, like one-variate is handled.
>
> Thanks, Jeff
>
> The information contained in this electronic message is ...{{dropped:21}}
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From lfanff at gmail.com  Wed May 18 15:34:33 2011
From: lfanff at gmail.com (Lu Fan)
Date: Wed, 18 May 2011 09:34:33 -0400
Subject: [R-SIG-Finance] rolling regression estimate std. error / t value
In-Reply-To: <854339777-1305665109-cardhu_decombobulator_blackberry.rim.net-362558289-@b13.c12.bise7.blackberry>
References: <BANLkTin8jFyL-0-Y9r9g+R+MD+nM1=PfGA@mail.gmail.com>
	<534356054-1305662689-cardhu_decombobulator_blackberry.rim.net-318484145-@b13.c12.bise7.blackberry>
	<BANLkTinNBXNZMYdp2OQoGBe97Xfx8hEk5g@mail.gmail.com>
	<379001603-1305664331-cardhu_decombobulator_blackberry.rim.net-985701696-@b13.c12.bise7.blackberry>
	<BANLkTimtDgYDtuEsZTJD3rmkkjf4iYUMHA@mail.gmail.com>
	<854339777-1305665109-cardhu_decombobulator_blackberry.rim.net-362558289-@b13.c12.bise7.blackberry>
Message-ID: <BANLkTinGHT0xEwDz1raHsiAr+Gyex1+qAg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110518/1bafac3f/attachment.pl>

From p.desmazis at gmail.com  Wed May 18 15:42:25 2011
From: p.desmazis at gmail.com (des Mazis, Pierre-Alexandre)
Date: Wed, 18 May 2011 13:42:25 +0000
Subject: [R-SIG-Finance] rolling regression estimate std. error / t value
In-Reply-To: <BANLkTinGHT0xEwDz1raHsiAr+Gyex1+qAg@mail.gmail.com>
References: <BANLkTin8jFyL-0-Y9r9g+R+MD+nM1=PfGA@mail.gmail.com><534356054-1305662689-cardhu_decombobulator_blackberry.rim.net-318484145-@b13.c12.bise7.blackberry><BANLkTinNBXNZMYdp2OQoGBe97Xfx8hEk5g@mail.gmail.com><379001603-1305664331-cardhu_decombobulator_blackberry.rim.net-985701696-@b13.c12.bise7.blackberry><BANLkTimtDgYDtuEsZTJD3rmkkjf4iYUMHA@mail.gmail.com><854339777-1305665109-cardhu_decombobulator_blackberry.rim.net-362558289-@b13.c12.bise7.blackberry><BANLkTinGHT0xEwDz1raHsiAr+Gyex1+qAg@mail.gmail.com>
Message-ID: <587911609-1305726146-cardhu_decombobulator_blackberry.rim.net-788379450-@b13.c12.bise7.blackberry>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110518/36ed3a27/attachment.pl>

From algotr8der at gmail.com  Wed May 18 21:33:04 2011
From: algotr8der at gmail.com (algotr8der)
Date: Wed, 18 May 2011 12:33:04 -0700 (PDT)
Subject: [R-SIG-Finance] IBrokers - reqHistory results in missing random data
Message-ID: <1305747184282-3533694.post@n4.nabble.com>

Has anyone come across situations where the export of historical data from
IB's API has missing data points that occur randomly? 

I did the following to download data for the Select SPDR etfs:

> tws <- twsConnect()
> contract <- twsEquity('XHB','SMART','ISLAND')
> reqHistory(tws, Contract=contract) -> XHB

By default this is set to retrieve 1 years worth of minute data. I received
all of the data for XLE but noticed that XHB has fewer data points. I pulled
up the chart of XHB to examine whether those missing data points showed up
on the chart but all was well on the TWS Chart. As per IB, the backfilling
on the TWS Chart uses the same data export framework as that used by
reqHistoricalData. So I decided to re-download XHB. This time the missing
data points were different from the previous download. 

I used IB's TswDde Excel file to cross verify and I noticed that the data is
present using the Excel API. It could be that the problem did not surface
because TwsDde limits the export of 1 minute data to 2 days worth of data.
I'm speculating here but I do know that downloading via reqHistory produces
data with missing data points that occur randomly.

The other thing I noticed was that the data pulled by reqHistory begins at
9:30:00 and ends at 15:59:00 while the same using TswDde begins at 9:31:00
and ends at 16:00:00. 

2010-06-18 15:58:00    15.85    15.85   15.84     15.84       1569  15.843          
0       337
2010-06-18 15:59:00    15.84    15.85   15.81     15.81       3518  15.828          
0       527
2010-06-21 09:30:00    16.04    16.10   16.03     16.09        240  16.047          
0        47
2010-06-21 09:31:00    16.09    16.09   16.07     16.08        226  16.081          
0       119
2010-05-17 09:31:00    18.00    18.03   18.00     18.02        115  18.020          
0        39

--
View this message in context: http://r.789695.n4.nabble.com/IBrokers-reqHistory-results-in-missing-random-data-tp3533694p3533694.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From jeffrey.ryan at lemnica.com  Wed May 18 22:25:28 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Wed, 18 May 2011 15:25:28 -0500
Subject: [R-SIG-Finance] IBrokers - reqHistory results in missing random
	data
In-Reply-To: <1305747184282-3533694.post@n4.nabble.com>
References: <1305747184282-3533694.post@n4.nabble.com>
Message-ID: <BANLkTimPYi24usacrCqEjVPiWp9n1VACDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110518/6ee3e536/attachment.pl>

From algotr8der at gmail.com  Thu May 19 01:51:40 2011
From: algotr8der at gmail.com (s)
Date: Wed, 18 May 2011 19:51:40 -0400
Subject: [R-SIG-Finance] IBrokers - reqHistory results in missing random
 data
In-Reply-To: <BANLkTimPYi24usacrCqEjVPiWp9n1VACDg@mail.gmail.com>
References: <1305747184282-3533694.post@n4.nabble.com>
	<BANLkTimPYi24usacrCqEjVPiWp9n1VACDg@mail.gmail.com>
Message-ID: <4DD45B8C.9050805@gmail.com>

On 5/18/11 4:25 PM, Jeffrey Ryan wrote:
> On Wed, May 18, 2011 at 2:33 PM, algotr8der <algotr8der at gmail.com> wrote:
>
>> Has anyone come across situations where the export of historical data from
>> IB's API has missing data points that occur randomly?
>>
>> I'm not too sure about 'randomly' but I have seen something similar in
> terms of missing dates/times/contracts on occasion.
>
>
>> I did the following to download data for the Select SPDR etfs:
>>
>>> tws <- twsConnect()
>>> contract <- twsEquity('XHB','SMART','ISLAND')
>>> reqHistory(tws, Contract=contract) -> XHB
>> By default this is set to retrieve 1 years worth of minute data. I received
>> all of the data for XLE but noticed that XHB has fewer data points. I
>> pulled
>> up the chart of XHB to examine whether those missing data points showed up
>> on the chart but all was well on the TWS Chart. As per IB, the backfilling
>> on the TWS Chart uses the same data export framework as that used by
>> reqHistoricalData. So I decided to re-download XHB. This time the missing
>> data points were different from the previous download.
>>
> reqHistory isn't much more than an lapply over/around the max download limit
> per call.  Maybe you could send me off-list the output of your request to
> see if I get the same issue.  Another thing to help debug is to run this on
> the IBGateway - and send me a copy of the log file.  setServerLogLevel(tws,
> 5) might do the same as well.
>
> I also would argue with IB that they aren't using the same framework for the
> backfills - since you can do more in the TWS than the API allows - something
> *is* different even at the user level.
Thanks for looking at this Jeff. Appreciate it.

I share your feelings in that something *is* different between the two
frameworks. I had a long discussion with one of IB's API representatives
today in regards to that but did not make much progress there. I have to
write up a ticket but I thought I would do further investigation first.

So I executed reHistory() using the IBGateway as you suggested. I will
upload the logs in a follow-up post as the api log is rather large and I
don't want to plug peoples inboxes.

This time I downloaded XHB the following dates (see below) had
incomplete data. Note the number below the date is a count of the number
of individual data points present for that day. The day post
Thanksgiving should be the only exception as it represents a half
trading day.

split.xts(XHB, f="days") -> testXHB
N <- length(testXHB)
for (i in 1:N) {
        print(index(testXHB[[i]])[1])
        print(dim(testXHB[[i]])[1])
}

[1] "2010-07-19 09:30:00 EDT"
[1] 389
[1] "2010-09-08 09:30:00 EDT"
[1] 389
[1] "2010-10-22 09:30:00 EDT"
[1] 389
[1] "2010-10-26 09:30:00 EDT"
[1] 389
[1] "2010-11-17 09:30:00 EST"
[1] 389
[1] "2010-11-26 09:30:00 EST"
[1] 210
[1] "2010-11-30 09:30:00 EST"
[1] 389
[1] "2010-12-30 09:30:00 EST"
[1] 389
[1] "2010-12-31 09:30:00 EST"
[1] 389
[1] "2011-02-14 09:30:00 EST"
[1] 389
[1] "2011-03-11 09:30:00 EST"
[1] 386
[1] "2011-04-14 09:30:00 EDT"
[1] 389
[1] "2011-04-25 09:30:00 EDT"
[1] 387


>> I used IB's TswDde Excel file to cross verify and I noticed that the data
>> is
>> present using the Excel API. It could be that the problem did not surface
>> because TwsDde limits the export of 1 minute data to 2 days worth of data.
>> I'm speculating here but I do know that downloading via reqHistory produces
>> data with missing data points that occur randomly.
>>
> The excel variant uses ActiveX - and I suspect it isn't really the same as
> the socket version (Java, IBrokers, etc).  Test using the distributed Java
> example program (or write one).  That would be more apples to apples.
Later today or sometime tomorrow I will test a Java example program to
compare to the ActiveX. Will provide further feedback.
>> The other thing I noticed was that the data pulled by reqHistory begins at
>> 9:30:00 and ends at 15:59:00 while the same using TswDde begins at 9:31:00
>> and ends at 16:00:00.
>>
>> 2010-06-18 15:58:00    15.85    15.85   15.84     15.84       1569  15.843
>> 0       337
>> 2010-06-18 15:59:00    15.84    15.85   15.81     15.81       3518  15.828
>> 0       527
>> 2010-06-21 09:30:00    16.04    16.10   16.03     16.09        240  16.047
>> 0        47
>> 2010-06-21 09:31:00    16.09    16.09   16.07     16.08        226  16.081
>> 0       119
>> 2010-05-17 09:31:00    18.00    18.03   18.00     18.02        115  18.020
>> 0        39
>>
> This is a potential indication of the differences internal to the socket vs.
> activeX.  From the log I get 20100611 14:59:00 as the last data stamp.  That
> is how bars get printed by the API as well - they use the time from the
> start of the minute, not the following one.  It is dumb - as this can then
> introduce a lookahead bias if you aren't aware/paying attention.  Or if you
> are merging with other data sources it causes havoc as well.  Point is,
> IBrokers isn't doing anything to the timestamp - it is coming from the
> TWS/IBG that way. You can set the output to be in POSIX seconds since the
> epoch, though I am not too sure what that would do in terms of stamps.  I'll
> check ...
>
> Best,
> Jeff
This is an issue and I really wonder why they are doing this. I need to
follow-up with IB on this.
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/IBrokers-reqHistory-results-in-missing-random-data-tp3533694p3533694.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>


From algotr8der at gmail.com  Thu May 19 02:21:28 2011
From: algotr8der at gmail.com (algotr8der)
Date: Wed, 18 May 2011 17:21:28 -0700 (PDT)
Subject: [R-SIG-Finance] IBrokers - reqHistory results in missing random
	data
In-Reply-To: <1305747184282-3533694.post@n4.nabble.com>
References: <1305747184282-3533694.post@n4.nabble.com>
Message-ID: <1305764488158-3534372.post@n4.nabble.com>

Logs:

http://r.789695.n4.nabble.com/file/n3534372/ibgateway.Wed.log
ibgateway.Wed.log 
http://r.789695.n4.nabble.com/file/n3534372/api.1.Wed.log.zip
api.1.Wed.log.zip 


--
View this message in context: http://r.789695.n4.nabble.com/IBrokers-reqHistory-results-in-missing-random-data-tp3533694p3534372.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From algotr8der at gmail.com  Thu May 19 21:15:12 2011
From: algotr8der at gmail.com (algotr8der)
Date: Thu, 19 May 2011 12:15:12 -0700 (PDT)
Subject: [R-SIG-Finance] IBrokers - reqHistory results in missing random
	data
In-Reply-To: <4DD45B8C.9050805@gmail.com>
References: <1305747184282-3533694.post@n4.nabble.com>
	<BANLkTimPYi24usacrCqEjVPiWp9n1VACDg@mail.gmail.com>
	<4DD45B8C.9050805@gmail.com>
Message-ID: <1305832512102-3536670.post@n4.nabble.com>

I must have spoken too soon. Here is what I have discovered.

1) the time issue is not present when you use TswDde, however it is present
when you use TswActiveX. The first 1 minute intraday bar occurs at 09:30:00
and the last bar at 15:59:00 when you export historical data using
tswActiveX. The same does not occur when you use TswDde.

2) the missing data issue occurs with both TswDde and TswActiveX.

I haven't been able to use the distributed Java API client yet because I've
had technical issues which I am trying to sort out at the moment.



--
View this message in context: http://r.789695.n4.nabble.com/IBrokers-reqHistory-results-in-missing-random-data-tp3533694p3536670.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Fri May 20 17:21:50 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 20 May 2011 10:21:50 -0500
Subject: [R-SIG-Finance] EGARCH/TGARCH
In-Reply-To: <BANLkTinoGP0x6kO2zQwj=tOKSvKx6qdXew@mail.gmail.com>
References: <mailman.3.1305885601.23987.r-sig-finance@r-project.org>
	<BANLkTinoGP0x6kO2zQwj=tOKSvKx6qdXew@mail.gmail.com>
Message-ID: <1305904910.27623.16.camel@brian-desktop>

On Fri, 2011-05-20 at 16:51 +0200, Emmanuel Senyo wrote:
> I am wondering how we can carry out EGARCH and TGARCH analysis in R.
> Please, any assistance.
> Thanks

Please don't reply to digest messages, it messes up thread readers in
other people's mail readers.  Construct a new message to the list using
a relevant subject line.

Have you looked at 

RSiteSearch('garch')

?

Or the task view?

http://cran.r-project.org/web/views/Finance.html

Regards,

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From bogaso.christofer at gmail.com  Fri May 20 17:38:52 2011
From: bogaso.christofer at gmail.com (Bogaso Christofer)
Date: Fri, 20 May 2011 21:08:52 +0530
Subject: [R-SIG-Finance] Value-at-risk
In-Reply-To: <1305201458.22156.176.camel@brian-desktop>
References: <BANLkTi=x-QeOu6-mR8ZzaMPQkPnYJx1PHQ@mail.gmail.com>	<1305199265.22156.171.camel@brian-desktop>	<BANLkTik_JrYuhtZgHpApUZGDgt+XZ1JZrw@mail.gmail.com>
	<1305201458.22156.176.camel@brian-desktop>
Message-ID: <006401cc1704$08a1ef00$19e5cd00$@gmail.com>

Hi,

After Emmanuel's post in R-finance and the reply from Brian, I spent few
times on the VaR() function and on the underlying theory. Just to admit
that, this is great. However, I don't think I could understand the theory of
component VaR calculation, although it seems the coding within the VaR()
function for the same is completely okay.

My problem is, how should I interpret component VaR? Having searched over
net and after going through few materials, I understand that, I can read
CVaR as the change of PVaR if underlying asset is removed from the
portfolio. Here my problem of interpretation starts from! Please consider
following hypothetical return (a zoo object, as needed for VaR())

> Ret
                    Ret1         Ret2         Ret3          Ret4
Ret5         Ret6         Ret7
2010-04-15 -0.0009783093  0.000000000 -0.003752350 -0.0006021985
-0.012384059 -0.012539349 -0.034979719
2010-04-16 -0.0004805344  0.003863495  0.003752350  0.0009617784
0.003110422  0.003149609  0.003231021
2010-04-19 -0.0273642188 -0.010336009 -0.003752350 -0.0104916573
-0.009360443 -0.009478744 -0.006472515
2010-04-20  0.0154788565 -0.002600782 -0.007547206 -0.0036357217
-0.006289329 -0.006369448  0.006472515
2010-04-21 -0.0094613433  0.000000000  0.000000000  0.0005484261
0.000000000  0.000000000  0.000000000
2010-04-22  0.0062536421  0.000000000  0.003780723 -0.0001143766
0.009419222  0.009539023  0.006430890
2010-04-23  0.0237922090  0.015504187  0.007518832  0.0097156191
0.006230550  0.006309169  0.000000000
2010-04-26  0.0133441736  0.012739026  0.003738322  0.0049317586
0.018462063  0.018692133  0.012739026
2010-04-28 -0.0105522323  0.000000000  0.000000000 -0.0037038049
-0.006116227 -0.006191970  0.000000000
2010-04-29  0.0030733546 -0.006349228 -0.011215071 -0.0071195792
-0.003072199 -0.003110422  0.000000000


I have a long-short portfolio, I want to estimate component VaR for the 2nd
asset, using VaR() function:


> WtVector <- c( -49895159,  734677735,   51037536,   -7126937, -283834066,
-161147892,   13652772)
> VaR(R = Ret, p = 0.05, method = "gaussian", portfolio_method =
"component", weights = WtVector)
$VaR
        [,1]
[1,] 5434285
$contribution
      Ret1       Ret2       Ret3       Ret4       Ret5       Ret6       Ret7

-316156.24 5211014.96  266249.91  -50021.42  260904.17  149986.52  -87692.49
$pct_contrib_VaR
        Ret1         Ret2         Ret3         Ret4         Ret5
Ret6         Ret7 
-0.058178070  0.958914480  0.048994465 -0.009204784  0.048010759
0.027600044 -0.016136894

This says (if my interpretation is correct) that if I remove my 1st asset
then, portfolio VaR will increase by -316156.24 (negative sign tells to have
hedging effect)
So I recalculate the portfolio VaR without having 1st asset:
> WtVector <- c( 0,  734677735,   51037536,   -7126937, -283834066,
-161147892,   13652772)
> VaR(R = Ret, p = 0.05, method = "gaussian", portfolio_method =
"component", weights = WtVector)
$VaR
        [,1]
[1,] 5849476
$contribution
      Ret1       Ret2       Ret3       Ret4       Ret5       Ret6       Ret7

      0.00 5987199.26  274456.46  -55685.39 -185776.60 -106798.21  -63919.72
$pct_contrib_VaR
        Ret1         Ret2         Ret3         Ret4         Ret5
Ret6         Ret7 
 0.000000000  1.023544581  0.046919839 -0.009519723 -0.031759529
-0.018257741 -0.010927428

I am just surprised to see that, my portfolio VaR indeed ***increased!!!***

I have found that, this kind of discrepancy comes as possible non-linear
relationship between VaR and it's constituent assets. It happens that x-y
plot for VaR and weight for the 1st asset is highly non-linear. sign of the
Slope changes if I move from current point (resemble to weight for 1st
asset) to origin (i.e. no 1st asset in the portfolio.)

So My question is, how can I trust on the sign (at least) of component VaR.
Isn't it is giving completely misleading figure? How risk managers handle
these issue? Does the solution like:
1. I should include higher term of the Taylor's expansion of the portfolio
VaR function
2. Do not simply trust those component VaR figures. I should completely
re-estimate my VaR number with and without having underlying asset.

Any thoughtful point(s) will be highly appreciated.

Thanks and regards,

-----Original Message-----
From: r-sig-finance-bounces at r-project.org
[mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Brian G. Peterson
Sent: 12 May 2011 17:28
To: Emmanuel Senyo
Cc: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Value-at-risk

There is over 100 pages of documentation available with
PerformanceAnalytics.

I suggest you start with 

install.packages("PerformanceAnalytics")
#you only need to do the install the first time

require(PerformanceAnalytics)
?VaR  

from the R prompt.  See the examples at the bottom of the VaR documentation.

Hopefully that will get you started.  If you have trouble, you may email the
R-SIG-Finance list or me with an example of what you're trying to do.
Ideally, start with some publicly available data (use the edhec or managers
data in Performanceanalytics, or use getSymbols to pull stock data from
Yahoo or Google) so that others can replicate what you're trying to do and
help you with code rather than vague suggestions.

Regards,

   - Brian

On Thu, 2011-05-12 at 13:47 +0200, Emmanuel Senyo wrote:
> Dear Brian,
> Thanks for the mail, I have now located the PerformanceAnalytics.
> Could you please elaborate on it how I could use this package, the 
> fact is that I am new to R, how i would like compute value at risk for 
> prices and volumes. If I can get a sample scripts with explanation 
> that would be very helpful to me to enable me build my own scripts.
> Regards
> Emma
> 
> On Thu, May 12, 2011 at 1:21 PM, Brian G. Peterson 
> <brian at braverock.com> wrote:
>         
>         On Thu, 2011-05-12 at 12:38 +0200, Emmanuel Senyo wrote:
>         > Dear All,
>         > I am currently work on Value-at-risk and would like to know
>         the package that
>         > is helpful in this regard. It consist of three method, that
>         is variance
>         > covariance method, Monte carlo simulation, and Historical
>         simulation.
>         > Regards
>         > Em
>         
>         
>         The Gaussian and Historical methods are available in
>         PerformanceAnalytics.
>         
>         You can easily use the Monte Carlo method of your choice to
>         create a
>         longer sample, and then use PerformanceAnalytics to calculate
>         the VaR.
>         
>         There are also several bootstrap Monte Carlo methods in
>         PerformanceAnalytics that have been contributed by Eric Zivot,
>         but which
>         we have not yet documented and exposed.
>         
>         Regards,
>         
>           - Brian
>         
>         --
>         Brian G. Peterson
>         http://braverock.com/brian/
>         Ph: 773-459-4973
>         IM: bgpbraverock
>         
> 

--
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From brian at braverock.com  Fri May 20 17:36:44 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 20 May 2011 10:36:44 -0500
Subject: [R-SIG-Finance] Value-at-risk
In-Reply-To: <006401cc1704$08a1ef00$19e5cd00$@gmail.com>
References: <BANLkTi=x-QeOu6-mR8ZzaMPQkPnYJx1PHQ@mail.gmail.com>
	<1305199265.22156.171.camel@brian-desktop>
	<BANLkTik_JrYuhtZgHpApUZGDgt+XZ1JZrw@mail.gmail.com>
	<1305201458.22156.176.camel@brian-desktop>
	<006401cc1704$08a1ef00$19e5cd00$@gmail.com>
Message-ID: <1305905804.27623.29.camel@brian-desktop>

On Fri, 2011-05-20 at 21:08 +0530, Bogaso Christofer wrote:
> Hi,
> 
> After Emmanuel's post in R-finance and the reply from Brian, I spent few
> times on the VaR() function and on the underlying theory. Just to admit
> that, this is great. However, I don't think I could understand the theory of
> component VaR calculation, although it seems the coding within the VaR()
> function for the same is completely okay.
> 
> My problem is, how should I interpret component VaR? Having searched over
> net and after going through few materials, I understand that, I can read
> CVaR as the change of PVaR if underlying asset is removed from the
> portfolio. Here my problem of interpretation starts from! Please consider
> following hypothetical return (a zoo object, as needed for VaR())
> 
> > Ret
>                     Ret1         Ret2         Ret3          Ret4
> Ret5         Ret6         Ret7
> 2010-04-15 -0.0009783093  0.000000000 -0.003752350 -0.0006021985
> -0.012384059 -0.012539349 -0.034979719
> 2010-04-16 -0.0004805344  0.003863495  0.003752350  0.0009617784
> 0.003110422  0.003149609  0.003231021
> 2010-04-19 -0.0273642188 -0.010336009 -0.003752350 -0.0104916573
> -0.009360443 -0.009478744 -0.006472515
> 2010-04-20  0.0154788565 -0.002600782 -0.007547206 -0.0036357217
> -0.006289329 -0.006369448  0.006472515
> 2010-04-21 -0.0094613433  0.000000000  0.000000000  0.0005484261
> 0.000000000  0.000000000  0.000000000
> 2010-04-22  0.0062536421  0.000000000  0.003780723 -0.0001143766
> 0.009419222  0.009539023  0.006430890
> 2010-04-23  0.0237922090  0.015504187  0.007518832  0.0097156191
> 0.006230550  0.006309169  0.000000000
> 2010-04-26  0.0133441736  0.012739026  0.003738322  0.0049317586
> 0.018462063  0.018692133  0.012739026
> 2010-04-28 -0.0105522323  0.000000000  0.000000000 -0.0037038049
> -0.006116227 -0.006191970  0.000000000
> 2010-04-29  0.0030733546 -0.006349228 -0.011215071 -0.0071195792
> -0.003072199 -0.003110422  0.000000000
> 
> 
> I have a long-short portfolio, I want to estimate component VaR for the 2nd
> asset, using VaR() function:
> 
> 
> > WtVector <- c( -49895159,  734677735,   51037536,   -7126937, -283834066,
> -161147892,   13652772)
> > VaR(R = Ret, p = 0.05, method = "gaussian", portfolio_method =
> "component", weights = WtVector)
> $VaR
>         [,1]
> [1,] 5434285
> $contribution
>       Ret1       Ret2       Ret3       Ret4       Ret5       Ret6       Ret7
> 
> -316156.24 5211014.96  266249.91  -50021.42  260904.17  149986.52  -87692.49
> $pct_contrib_VaR
>         Ret1         Ret2         Ret3         Ret4         Ret5
> Ret6         Ret7 
> -0.058178070  0.958914480  0.048994465 -0.009204784  0.048010759
> 0.027600044 -0.016136894
> 
> This says (if my interpretation is correct) that if I remove my 1st asset
> then, portfolio VaR will increase by -316156.24 (negative sign tells to have
> hedging effect)

You're speaking of *marginal* VaR, not component VaR.

Marginal (or Incremental) VaR is the contribution of that instrument to
the VaR of the portfolio "at the margin" (this is how I keep them
straight).  Marginal VaR is not additive, it may add up to more than
100% of the total portfolio VaR.  I find it to be a relatively poor risk
measure overall, and generally don't recommend using it (there are some
exceptions that are mentioned in the documentation for the VaR
function).  Your description describes Marginal VaR, not Component VaR.

Component VaR is the *contribution* to the portfolio VaR of each
component in the portfolio.  It adds up to the value of the entire
portfolio VaR. The value returned has three slots.
$VaR # the portfolio VaR
$contribution
  the scalar contributions of each instrument, 
  this adds up to the portfolio VaR
$pct_contribution_VaR
  the percentage contributions to VaR,
  this adds up to 1
  negative numbers are diversifiers, *decreasing*
  the total portfolio VaR 

So, given that this is component VaR we're looking at, not marginal VaR,
asset 1 is your *largest diversifier*.  Removing it would be expected to
increase the portfolio VaR, as you report below.

Hopefully this clears things up...

Regards,

   - Brian

> So I recalculate the portfolio VaR without having 1st asset:
> > WtVector <- c( 0,  734677735,   51037536,   -7126937, -283834066,
> -161147892,   13652772)
> > VaR(R = Ret, p = 0.05, method = "gaussian", portfolio_method =
> "component", weights = WtVector)
> $VaR
>         [,1]
> [1,] 5849476
> $contribution
>       Ret1       Ret2       Ret3       Ret4       Ret5       Ret6       Ret7
> 
>       0.00 5987199.26  274456.46  -55685.39 -185776.60 -106798.21  -63919.72
> $pct_contrib_VaR
>         Ret1         Ret2         Ret3         Ret4         Ret5
> Ret6         Ret7 
>  0.000000000  1.023544581  0.046919839 -0.009519723 -0.031759529
> -0.018257741 -0.010927428
> 
> I am just surprised to see that, my portfolio VaR indeed ***increased!!!***
> 
> I have found that, this kind of discrepancy comes as possible non-linear
> relationship between VaR and it's constituent assets. It happens that x-y
> plot for VaR and weight for the 1st asset is highly non-linear. sign of the
> Slope changes if I move from current point (resemble to weight for 1st
> asset) to origin (i.e. no 1st asset in the portfolio.)
> 
> So My question is, how can I trust on the sign (at least) of component VaR.
> Isn't it is giving completely misleading figure? How risk managers handle
> these issue? Does the solution like:
> 1. I should include higher term of the Taylor's expansion of the portfolio
> VaR function
> 2. Do not simply trust those component VaR figures. I should completely
> re-estimate my VaR number with and without having underlying asset.
> 
> Any thoughtful point(s) will be highly appreciated.
> 
> Thanks and regards,
> 
> -----Original Message-----
> From: r-sig-finance-bounces at r-project.org
> [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Brian G. Peterson
> Sent: 12 May 2011 17:28
> To: Emmanuel Senyo
> Cc: r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] Value-at-risk
> 
> There is over 100 pages of documentation available with
> PerformanceAnalytics.
> 
> I suggest you start with 
> 
> install.packages("PerformanceAnalytics")
> #you only need to do the install the first time
> 
> require(PerformanceAnalytics)
> ?VaR  
> 
> from the R prompt.  See the examples at the bottom of the VaR documentation.
> 
> Hopefully that will get you started.  If you have trouble, you may email the
> R-SIG-Finance list or me with an example of what you're trying to do.
> Ideally, start with some publicly available data (use the edhec or managers
> data in Performanceanalytics, or use getSymbols to pull stock data from
> Yahoo or Google) so that others can replicate what you're trying to do and
> help you with code rather than vague suggestions.
> 
> Regards,
> 
>    - Brian
> 
> On Thu, 2011-05-12 at 13:47 +0200, Emmanuel Senyo wrote:
> > Dear Brian,
> > Thanks for the mail, I have now located the PerformanceAnalytics.
> > Could you please elaborate on it how I could use this package, the 
> > fact is that I am new to R, how i would like compute value at risk for 
> > prices and volumes. If I can get a sample scripts with explanation 
> > that would be very helpful to me to enable me build my own scripts.
> > Regards
> > Emma
> > 
> > On Thu, May 12, 2011 at 1:21 PM, Brian G. Peterson 
> > <brian at braverock.com> wrote:
> >         
> >         On Thu, 2011-05-12 at 12:38 +0200, Emmanuel Senyo wrote:
> >         > Dear All,
> >         > I am currently work on Value-at-risk and would like to know
> >         the package that
> >         > is helpful in this regard. It consist of three method, that
> >         is variance
> >         > covariance method, Monte carlo simulation, and Historical
> >         simulation.
> >         > Regards
> >         > Em
> >         
> >         
> >         The Gaussian and Historical methods are available in
> >         PerformanceAnalytics.
> >         
> >         You can easily use the Monte Carlo method of your choice to
> >         create a
> >         longer sample, and then use PerformanceAnalytics to calculate
> >         the VaR.
> >         
> >         There are also several bootstrap Monte Carlo methods in
> >         PerformanceAnalytics that have been contributed by Eric Zivot,
> >         but which
> >         we have not yet documented and exposed.
> >         
> >         Regards,
> >         
> >           - Brian
> >         
> >         --
> >         Brian G. Peterson
> >         http://braverock.com/brian/
> >         Ph: 773-459-4973
> >         IM: bgpbraverock
> >         
> > 
> 
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From p.desmazis at gmail.com  Fri May 20 17:38:36 2011
From: p.desmazis at gmail.com (des Mazis, Pierre-Alexandre)
Date: Fri, 20 May 2011 15:38:36 +0000
Subject: [R-SIG-Finance] Lorenz Curve
Message-ID: <689146093-1305905914-cardhu_decombobulator_blackberry.rim.net-1241431555-@b13.c12.bise7.blackberry>

Hi,

Quick question. I am using a zoo of two columns and i would like to plot the cumulative distribution of the first one as a function of the second one (sort increasing). I would like not to use a package and none of the functions i tried gave the good result.

Marc Delvaux: very good package! You worked on Cover's examples which is really helpful.

Thanks
Sent using BlackBerry? from Orange

From bogaso.christofer at gmail.com  Fri May 20 18:22:08 2011
From: bogaso.christofer at gmail.com (Bogaso Christofer)
Date: Fri, 20 May 2011 21:52:08 +0530
Subject: [R-SIG-Finance] Value-at-risk
In-Reply-To: <1305905804.27623.29.camel@brian-desktop>
References: <BANLkTi=x-QeOu6-mR8ZzaMPQkPnYJx1PHQ@mail.gmail.com>	
	<1305199265.22156.171.camel@brian-desktop>	
	<BANLkTik_JrYuhtZgHpApUZGDgt+XZ1JZrw@mail.gmail.com>	
	<1305201458.22156.176.camel@brian-desktop>	
	<006401cc1704$08a1ef00$19e5cd00$@gmail.com>
	<1305905804.27623.29.camel@brian-desktop>
Message-ID: <009b01cc170a$13981eb0$3ac85c10$@gmail.com>

Thanks Brian, for your mail:

On regard of the 1st asset your said: " Removing it would be expected to increase the portfolio VaR, as you report below "

Therefore, if I consider 2nd asset, it has +ve sign. Therefore there is not diversification effect for this 2nd asset. Hence ** Removing it would be expected to "decrease" the portfolio VaR **. Right? However in reality I see different thing:

> VaR(R = Ret, p = 0.05, method = "gaussian", portfolio_method = "component", weights = WtVector)
$VaR
        [,1]
[1,] 5434285

$contribution
      Ret1       Ret2       Ret3       Ret4       Ret5       Ret6       Ret7 
-316156.24 5211014.96  266249.91  -50021.42  260904.17  149986.52  -87692.49 

$pct_contrib_VaR
        Ret1         Ret2         Ret3         Ret4         Ret5         Ret6         Ret7 
-0.058178070  0.958914480  0.048994465 -0.009204784  0.048010759  0.027600044 -0.016136894 

> 
> WtVector1 <- WtVector; WtVector1[2] <- 0 ## I remove 2nd asset, therefore portfolio VaR is expected to decrease
> VaR(R = Ret, p = 0.05, method = "gaussian", portfolio_method = "component", weights = WtVector1)
$VaR
        [,1]
[1,] 7340057

$contribution
      Ret1       Ret2       Ret3       Ret4       Ret5       Ret6       Ret7 
 868217.23       0.00 -260061.45   41235.95 4359025.20 2505891.43 -174251.63 

$pct_contrib_VaR
        Ret1         Ret2         Ret3         Ret4         Ret5         Ret6         Ret7 
 0.118284812  0.000000000 -0.035430442  0.005617933  0.593868053  0.341399463 -0.023739820 

With 2nd asset, port VaR is 5434285, and without 2nd asset port VaR is 7340057. How can it be justified?

Here I plotted the relationship between port VaR with the 2nd asset weight:

Mod_Wt <- seq(0, abs(WtVector[2]), by = 150000)
VaRi <- vector(length = length(Mod_Wt))
for (i in 1:length(VaRi)) {
					Wt1 <- WtVector; Wt1[2] <- 1 * Mod_Wt[i]
					VaRi[i] <- VaR(R = Ret, p = 0.95,  method = "gaussian", portfolio_method = "component", weights = Wt1)$VaR
                }
tail(Mod_Wt)
tail(VaRi)
plot(Mod_Wt, VaRi, type = "l")


-----Original Message-----
From: Brian G. Peterson [mailto:brian at braverock.com] 
Sent: 20 May 2011 21:07
To: Bogaso Christofer
Cc: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Value-at-risk

On Fri, 2011-05-20 at 21:08 +0530, Bogaso Christofer wrote:
> Hi,
> 
> After Emmanuel's post in R-finance and the reply from Brian, I spent 
> few times on the VaR() function and on the underlying theory. Just to 
> admit that, this is great. However, I don't think I could understand 
> the theory of component VaR calculation, although it seems the coding 
> within the VaR() function for the same is completely okay.
> 
> My problem is, how should I interpret component VaR? Having searched 
> over net and after going through few materials, I understand that, I 
> can read CVaR as the change of PVaR if underlying asset is removed 
> from the portfolio. Here my problem of interpretation starts from! 
> Please consider following hypothetical return (a zoo object, as needed 
> for VaR())
> 
> > Ret
>                     Ret1         Ret2         Ret3          Ret4
> Ret5         Ret6         Ret7
> 2010-04-15 -0.0009783093  0.000000000 -0.003752350 -0.0006021985
> -0.012384059 -0.012539349 -0.034979719
> 2010-04-16 -0.0004805344  0.003863495  0.003752350  0.0009617784
> 0.003110422  0.003149609  0.003231021
> 2010-04-19 -0.0273642188 -0.010336009 -0.003752350 -0.0104916573
> -0.009360443 -0.009478744 -0.006472515
> 2010-04-20  0.0154788565 -0.002600782 -0.007547206 -0.0036357217
> -0.006289329 -0.006369448  0.006472515
> 2010-04-21 -0.0094613433  0.000000000  0.000000000  0.0005484261
> 0.000000000  0.000000000  0.000000000
> 2010-04-22  0.0062536421  0.000000000  0.003780723 -0.0001143766
> 0.009419222  0.009539023  0.006430890
> 2010-04-23  0.0237922090  0.015504187  0.007518832  0.0097156191
> 0.006230550  0.006309169  0.000000000
> 2010-04-26  0.0133441736  0.012739026  0.003738322  0.0049317586
> 0.018462063  0.018692133  0.012739026
> 2010-04-28 -0.0105522323  0.000000000  0.000000000 -0.0037038049
> -0.006116227 -0.006191970  0.000000000
> 2010-04-29  0.0030733546 -0.006349228 -0.011215071 -0.0071195792
> -0.003072199 -0.003110422  0.000000000
> 
> 
> I have a long-short portfolio, I want to estimate component VaR for 
> the 2nd asset, using VaR() function:
> 
> 
> > WtVector <- c( -49895159,  734677735,   51037536,   -7126937, -283834066,
> -161147892,   13652772)
> > VaR(R = Ret, p = 0.05, method = "gaussian", portfolio_method =
> "component", weights = WtVector)
> $VaR
>         [,1]
> [1,] 5434285
> $contribution
>       Ret1       Ret2       Ret3       Ret4       Ret5       Ret6       Ret7
> 
> -316156.24 5211014.96  266249.91  -50021.42  260904.17  149986.52  
> -87692.49 $pct_contrib_VaR
>         Ret1         Ret2         Ret3         Ret4         Ret5
> Ret6         Ret7 
> -0.058178070  0.958914480  0.048994465 -0.009204784  0.048010759
> 0.027600044 -0.016136894
> 
> This says (if my interpretation is correct) that if I remove my 1st 
> asset then, portfolio VaR will increase by -316156.24 (negative sign 
> tells to have hedging effect)

You're speaking of *marginal* VaR, not component VaR.

Marginal (or Incremental) VaR is the contribution of that instrument to the VaR of the portfolio "at the margin" (this is how I keep them straight).  Marginal VaR is not additive, it may add up to more than 100% of the total portfolio VaR.  I find it to be a relatively poor risk measure overall, and generally don't recommend using it (there are some exceptions that are mentioned in the documentation for the VaR function).  Your description describes Marginal VaR, not Component VaR.

Component VaR is the *contribution* to the portfolio VaR of each component in the portfolio.  It adds up to the value of the entire portfolio VaR. The value returned has three slots.
$VaR # the portfolio VaR
$contribution
  the scalar contributions of each instrument,
  this adds up to the portfolio VaR
$pct_contribution_VaR
  the percentage contributions to VaR,
  this adds up to 1
  negative numbers are diversifiers, *decreasing*
  the total portfolio VaR 

So, given that this is component VaR we're looking at, not marginal VaR, asset 1 is your *largest diversifier*.  Removing it would be expected to increase the portfolio VaR, as you report below.

Hopefully this clears things up...

Regards,

   - Brian

> So I recalculate the portfolio VaR without having 1st asset:
> > WtVector <- c( 0,  734677735,   51037536,   -7126937, -283834066,
> -161147892,   13652772)
> > VaR(R = Ret, p = 0.05, method = "gaussian", portfolio_method =
> "component", weights = WtVector)
> $VaR
>         [,1]
> [1,] 5849476
> $contribution
>       Ret1       Ret2       Ret3       Ret4       Ret5       Ret6       Ret7
> 
>       0.00 5987199.26  274456.46  -55685.39 -185776.60 -106798.21  
> -63919.72 $pct_contrib_VaR
>         Ret1         Ret2         Ret3         Ret4         Ret5
> Ret6         Ret7 
>  0.000000000  1.023544581  0.046919839 -0.009519723 -0.031759529
> -0.018257741 -0.010927428
> 
> I am just surprised to see that, my portfolio VaR indeed 
> ***increased!!!***
> 
> I have found that, this kind of discrepancy comes as possible 
> non-linear relationship between VaR and it's constituent assets. It 
> happens that x-y plot for VaR and weight for the 1st asset is highly 
> non-linear. sign of the Slope changes if I move from current point 
> (resemble to weight for 1st
> asset) to origin (i.e. no 1st asset in the portfolio.)
> 
> So My question is, how can I trust on the sign (at least) of component VaR.
> Isn't it is giving completely misleading figure? How risk managers 
> handle these issue? Does the solution like:
> 1. I should include higher term of the Taylor's expansion of the 
> portfolio VaR function 2. Do not simply trust those component VaR 
> figures. I should completely re-estimate my VaR number with and 
> without having underlying asset.
> 
> Any thoughtful point(s) will be highly appreciated.
> 
> Thanks and regards,
> 
> -----Original Message-----
> From: r-sig-finance-bounces at r-project.org
> [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Brian G. 
> Peterson
> Sent: 12 May 2011 17:28
> To: Emmanuel Senyo
> Cc: r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] Value-at-risk
> 
> There is over 100 pages of documentation available with 
> PerformanceAnalytics.
> 
> I suggest you start with
> 
> install.packages("PerformanceAnalytics")
> #you only need to do the install the first time
> 
> require(PerformanceAnalytics)
> ?VaR
> 
> from the R prompt.  See the examples at the bottom of the VaR documentation.
> 
> Hopefully that will get you started.  If you have trouble, you may 
> email the R-SIG-Finance list or me with an example of what you're trying to do.
> Ideally, start with some publicly available data (use the edhec or 
> managers data in Performanceanalytics, or use getSymbols to pull stock 
> data from Yahoo or Google) so that others can replicate what you're 
> trying to do and help you with code rather than vague suggestions.
> 
> Regards,
> 
>    - Brian
> 
> On Thu, 2011-05-12 at 13:47 +0200, Emmanuel Senyo wrote:
> > Dear Brian,
> > Thanks for the mail, I have now located the PerformanceAnalytics.
> > Could you please elaborate on it how I could use this package, the 
> > fact is that I am new to R, how i would like compute value at risk 
> > for prices and volumes. If I can get a sample scripts with 
> > explanation that would be very helpful to me to enable me build my own scripts.
> > Regards
> > Emma
> > 
> > On Thu, May 12, 2011 at 1:21 PM, Brian G. Peterson 
> > <brian at braverock.com> wrote:
> >         
> >         On Thu, 2011-05-12 at 12:38 +0200, Emmanuel Senyo wrote:
> >         > Dear All,
> >         > I am currently work on Value-at-risk and would like to know
> >         the package that
> >         > is helpful in this regard. It consist of three method, that
> >         is variance
> >         > covariance method, Monte carlo simulation, and Historical
> >         simulation.
> >         > Regards
> >         > Em
> >         
> >         
> >         The Gaussian and Historical methods are available in
> >         PerformanceAnalytics.
> >         
> >         You can easily use the Monte Carlo method of your choice to
> >         create a
> >         longer sample, and then use PerformanceAnalytics to calculate
> >         the VaR.
> >         
> >         There are also several bootstrap Monte Carlo methods in
> >         PerformanceAnalytics that have been contributed by Eric Zivot,
> >         but which
> >         we have not yet documented and exposed.
> >         
> >         Regards,
> >         
> >           - Brian
> >         
> >         --
> >         Brian G. Peterson
> >         http://braverock.com/brian/
> >         Ph: 773-459-4973
> >         IM: bgpbraverock
> >         
> > 
> 
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R 
> questions should go.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

--
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From brian at braverock.com  Fri May 20 18:31:40 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 20 May 2011 11:31:40 -0500
Subject: [R-SIG-Finance] Value-at-risk
In-Reply-To: <009b01cc170a$13981eb0$3ac85c10$@gmail.com>
References: <BANLkTi=x-QeOu6-mR8ZzaMPQkPnYJx1PHQ@mail.gmail.com>
	<1305199265.22156.171.camel@brian-desktop>
	<BANLkTik_JrYuhtZgHpApUZGDgt+XZ1JZrw@mail.gmail.com>
	<1305201458.22156.176.camel@brian-desktop>
	<006401cc1704$08a1ef00$19e5cd00$@gmail.com>
	<1305905804.27623.29.camel@brian-desktop>
	<009b01cc170a$13981eb0$3ac85c10$@gmail.com>
Message-ID: <1305909100.27623.45.camel@brian-desktop>

You can't do what you're trying to do, in the way you are trying to do
it.

Since your weights are obviously dollar weights, I assumed that you were
trying to get the *entire* portfolio, knowing that these weights don't
add up to 1.  

If you want to work in returns space, and be able to make apples to
apples portfolio comparisons, then your weights should be a vector that
adds up to 100% of your total capital.  If you're really talking about
taking a $734M position out of the portfolio, you're replacing it with
something....  cash, spreading the money to other things, whatever...

That position, in your example, is the largest position you have by far,
and contributes 95% of the total portfolio risk.  This shouldn't be
entirely surprising, as it is three times the size of your biggest short
position.

If you're going to *rebalance* the portfolio and see what the new VaR
is, you need to adjust more than just one weight.

If you really want Marginal VaR, then use Marginal VaR.  Please don't
try to permute component VaR into something it is not.

Regards,

   - Brian

On Fri, 2011-05-20 at 21:52 +0530, Bogaso Christofer wrote:
> Thanks Brian, for your mail:
> 
> On regard of the 1st asset your said: " Removing it would be expected to increase the portfolio VaR, as you report below "
> 
> Therefore, if I consider 2nd asset, it has +ve sign. Therefore there is not diversification effect for this 2nd asset. Hence ** Removing it would be expected to "decrease" the portfolio VaR **. Right? However in reality I see different thing:
> 
> > VaR(R = Ret, p = 0.05, method = "gaussian", portfolio_method = "component", weights = WtVector)
> $VaR
>         [,1]
> [1,] 5434285
> 
> $contribution
>       Ret1       Ret2       Ret3       Ret4       Ret5       Ret6       Ret7 
> -316156.24 5211014.96  266249.91  -50021.42  260904.17  149986.52  -87692.49 
> 
> $pct_contrib_VaR
>         Ret1         Ret2         Ret3         Ret4         Ret5         Ret6         Ret7 
> -0.058178070  0.958914480  0.048994465 -0.009204784  0.048010759  0.027600044 -0.016136894 
> 
> > 
> > WtVector1 <- WtVector; WtVector1[2] <- 0 ## I remove 2nd asset, therefore portfolio VaR is expected to decrease
> > VaR(R = Ret, p = 0.05, method = "gaussian", portfolio_method = "component", weights = WtVector1)
> $VaR
>         [,1]
> [1,] 7340057
> 
> $contribution
>       Ret1       Ret2       Ret3       Ret4       Ret5       Ret6       Ret7 
>  868217.23       0.00 -260061.45   41235.95 4359025.20 2505891.43 -174251.63 
> 
> $pct_contrib_VaR
>         Ret1         Ret2         Ret3         Ret4         Ret5         Ret6         Ret7 
>  0.118284812  0.000000000 -0.035430442  0.005617933  0.593868053  0.341399463 -0.023739820 
> 
> With 2nd asset, port VaR is 5434285, and without 2nd asset port VaR is 7340057. How can it be justified?
> 
> Here I plotted the relationship between port VaR with the 2nd asset weight:
> 
> Mod_Wt <- seq(0, abs(WtVector[2]), by = 150000)
> VaRi <- vector(length = length(Mod_Wt))
> for (i in 1:length(VaRi)) {
> 					Wt1 <- WtVector; Wt1[2] <- 1 * Mod_Wt[i]
> 					VaRi[i] <- VaR(R = Ret, p = 0.95,  method = "gaussian", portfolio_method = "component", weights = Wt1)$VaR
>                 }
> tail(Mod_Wt)
> tail(VaRi)
> plot(Mod_Wt, VaRi, type = "l")
> 
> 
> -----Original Message-----
> From: Brian G. Peterson [mailto:brian at braverock.com] 
> Sent: 20 May 2011 21:07
> To: Bogaso Christofer
> Cc: r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] Value-at-risk
> 
> On Fri, 2011-05-20 at 21:08 +0530, Bogaso Christofer wrote:
> > Hi,
> > 
> > After Emmanuel's post in R-finance and the reply from Brian, I spent 
> > few times on the VaR() function and on the underlying theory. Just to 
> > admit that, this is great. However, I don't think I could understand 
> > the theory of component VaR calculation, although it seems the coding 
> > within the VaR() function for the same is completely okay.
> > 
> > My problem is, how should I interpret component VaR? Having searched 
> > over net and after going through few materials, I understand that, I 
> > can read CVaR as the change of PVaR if underlying asset is removed 
> > from the portfolio. Here my problem of interpretation starts from! 
> > Please consider following hypothetical return (a zoo object, as needed 
> > for VaR())
> > 
> > > Ret
> >                     Ret1         Ret2         Ret3          Ret4
> > Ret5         Ret6         Ret7
> > 2010-04-15 -0.0009783093  0.000000000 -0.003752350 -0.0006021985
> > -0.012384059 -0.012539349 -0.034979719
> > 2010-04-16 -0.0004805344  0.003863495  0.003752350  0.0009617784
> > 0.003110422  0.003149609  0.003231021
> > 2010-04-19 -0.0273642188 -0.010336009 -0.003752350 -0.0104916573
> > -0.009360443 -0.009478744 -0.006472515
> > 2010-04-20  0.0154788565 -0.002600782 -0.007547206 -0.0036357217
> > -0.006289329 -0.006369448  0.006472515
> > 2010-04-21 -0.0094613433  0.000000000  0.000000000  0.0005484261
> > 0.000000000  0.000000000  0.000000000
> > 2010-04-22  0.0062536421  0.000000000  0.003780723 -0.0001143766
> > 0.009419222  0.009539023  0.006430890
> > 2010-04-23  0.0237922090  0.015504187  0.007518832  0.0097156191
> > 0.006230550  0.006309169  0.000000000
> > 2010-04-26  0.0133441736  0.012739026  0.003738322  0.0049317586
> > 0.018462063  0.018692133  0.012739026
> > 2010-04-28 -0.0105522323  0.000000000  0.000000000 -0.0037038049
> > -0.006116227 -0.006191970  0.000000000
> > 2010-04-29  0.0030733546 -0.006349228 -0.011215071 -0.0071195792
> > -0.003072199 -0.003110422  0.000000000
> > 
> > 
> > I have a long-short portfolio, I want to estimate component VaR for 
> > the 2nd asset, using VaR() function:
> > 
> > 
> > > WtVector <- c( -49895159,  734677735,   51037536,   -7126937, -283834066,
> > -161147892,   13652772)
> > > VaR(R = Ret, p = 0.05, method = "gaussian", portfolio_method =
> > "component", weights = WtVector)
> > $VaR
> >         [,1]
> > [1,] 5434285
> > $contribution
> >       Ret1       Ret2       Ret3       Ret4       Ret5       Ret6       Ret7
> > 
> > -316156.24 5211014.96  266249.91  -50021.42  260904.17  149986.52  
> > -87692.49 $pct_contrib_VaR
> >         Ret1         Ret2         Ret3         Ret4         Ret5
> > Ret6         Ret7 
> > -0.058178070  0.958914480  0.048994465 -0.009204784  0.048010759
> > 0.027600044 -0.016136894
> > 
> > This says (if my interpretation is correct) that if I remove my 1st 
> > asset then, portfolio VaR will increase by -316156.24 (negative sign 
> > tells to have hedging effect)
> 
> You're speaking of *marginal* VaR, not component VaR.
> 
> Marginal (or Incremental) VaR is the contribution of that instrument to the VaR of the portfolio "at the margin" (this is how I keep them straight).  Marginal VaR is not additive, it may add up to more than 100% of the total portfolio VaR.  I find it to be a relatively poor risk measure overall, and generally don't recommend using it (there are some exceptions that are mentioned in the documentation for the VaR function).  Your description describes Marginal VaR, not Component VaR.
> 
> Component VaR is the *contribution* to the portfolio VaR of each component in the portfolio.  It adds up to the value of the entire portfolio VaR. The value returned has three slots.
> $VaR # the portfolio VaR
> $contribution
>   the scalar contributions of each instrument,
>   this adds up to the portfolio VaR
> $pct_contribution_VaR
>   the percentage contributions to VaR,
>   this adds up to 1
>   negative numbers are diversifiers, *decreasing*
>   the total portfolio VaR 
> 
> So, given that this is component VaR we're looking at, not marginal VaR, asset 1 is your *largest diversifier*.  Removing it would be expected to increase the portfolio VaR, as you report below.
> 
> Hopefully this clears things up...
> 
> Regards,
> 
>    - Brian
> 
> > So I recalculate the portfolio VaR without having 1st asset:
> > > WtVector <- c( 0,  734677735,   51037536,   -7126937, -283834066,
> > -161147892,   13652772)
> > > VaR(R = Ret, p = 0.05, method = "gaussian", portfolio_method =
> > "component", weights = WtVector)
> > $VaR
> >         [,1]
> > [1,] 5849476
> > $contribution
> >       Ret1       Ret2       Ret3       Ret4       Ret5       Ret6       Ret7
> > 
> >       0.00 5987199.26  274456.46  -55685.39 -185776.60 -106798.21  
> > -63919.72 $pct_contrib_VaR
> >         Ret1         Ret2         Ret3         Ret4         Ret5
> > Ret6         Ret7 
> >  0.000000000  1.023544581  0.046919839 -0.009519723 -0.031759529
> > -0.018257741 -0.010927428
> > 
> > I am just surprised to see that, my portfolio VaR indeed 
> > ***increased!!!***
> > 
> > I have found that, this kind of discrepancy comes as possible 
> > non-linear relationship between VaR and it's constituent assets. It 
> > happens that x-y plot for VaR and weight for the 1st asset is highly 
> > non-linear. sign of the Slope changes if I move from current point 
> > (resemble to weight for 1st
> > asset) to origin (i.e. no 1st asset in the portfolio.)
> > 
> > So My question is, how can I trust on the sign (at least) of component VaR.
> > Isn't it is giving completely misleading figure? How risk managers 
> > handle these issue? Does the solution like:
> > 1. I should include higher term of the Taylor's expansion of the 
> > portfolio VaR function 2. Do not simply trust those component VaR 
> > figures. I should completely re-estimate my VaR number with and 
> > without having underlying asset.
> > 
> > Any thoughtful point(s) will be highly appreciated.
> > 
> > Thanks and regards,
> > 
> > -----Original Message-----
> > From: r-sig-finance-bounces at r-project.org
> > [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Brian G. 
> > Peterson
> > Sent: 12 May 2011 17:28
> > To: Emmanuel Senyo
> > Cc: r-sig-finance at stat.math.ethz.ch
> > Subject: Re: [R-SIG-Finance] Value-at-risk
> > 
> > There is over 100 pages of documentation available with 
> > PerformanceAnalytics.
> > 
> > I suggest you start with
> > 
> > install.packages("PerformanceAnalytics")
> > #you only need to do the install the first time
> > 
> > require(PerformanceAnalytics)
> > ?VaR
> > 
> > from the R prompt.  See the examples at the bottom of the VaR documentation.
> > 
> > Hopefully that will get you started.  If you have trouble, you may 
> > email the R-SIG-Finance list or me with an example of what you're trying to do.
> > Ideally, start with some publicly available data (use the edhec or 
> > managers data in Performanceanalytics, or use getSymbols to pull stock 
> > data from Yahoo or Google) so that others can replicate what you're 
> > trying to do and help you with code rather than vague suggestions.
> > 
> > Regards,
> > 
> >    - Brian
> > 
> > On Thu, 2011-05-12 at 13:47 +0200, Emmanuel Senyo wrote:
> > > Dear Brian,
> > > Thanks for the mail, I have now located the PerformanceAnalytics.
> > > Could you please elaborate on it how I could use this package, the 
> > > fact is that I am new to R, how i would like compute value at risk 
> > > for prices and volumes. If I can get a sample scripts with 
> > > explanation that would be very helpful to me to enable me build my own scripts.
> > > Regards
> > > Emma
> > > 
> > > On Thu, May 12, 2011 at 1:21 PM, Brian G. Peterson 
> > > <brian at braverock.com> wrote:
> > >         
> > >         On Thu, 2011-05-12 at 12:38 +0200, Emmanuel Senyo wrote:
> > >         > Dear All,
> > >         > I am currently work on Value-at-risk and would like to know
> > >         the package that
> > >         > is helpful in this regard. It consist of three method, that
> > >         is variance
> > >         > covariance method, Monte carlo simulation, and Historical
> > >         simulation.
> > >         > Regards
> > >         > Em
> > >         
> > >         
> > >         The Gaussian and Historical methods are available in
> > >         PerformanceAnalytics.
> > >         
> > >         You can easily use the Monte Carlo method of your choice to
> > >         create a
> > >         longer sample, and then use PerformanceAnalytics to calculate
> > >         the VaR.
> > >         
> > >         There are also several bootstrap Monte Carlo methods in
> > >         PerformanceAnalytics that have been contributed by Eric Zivot,
> > >         but which
> > >         we have not yet documented and exposed.
> > >         
> > >         Regards,
> > >         
> > >           - Brian
> > >         
> > >         --
> > >         Brian G. Peterson
> > >         http://braverock.com/brian/
> > >         Ph: 773-459-4973
> > >         IM: bgpbraverock
> > >         
> > > 
> > 
> > --
> > Brian G. Peterson
> > http://braverock.com/brian/
> > Ph: 773-459-4973
> > IM: bgpbraverock
> > 
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R 
> > questions should go.
> > 
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions should go.
> 
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From optionsraghu at gmail.com  Sun May 22 11:50:43 2011
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Sun, 22 May 2011 10:50:43 +0100
Subject: [R-SIG-Finance] Volatility Models?
Message-ID: <BANLkTimnMT4FYST+15Wss+Bk-h3Et=+RuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110522/67b87c39/attachment.pl>

From nelson.ana at gmail.com  Sun May 22 13:53:23 2011
From: nelson.ana at gmail.com (Ana Nelson)
Date: Sun, 22 May 2011 12:53:23 +0100
Subject: [R-SIG-Finance] RBloomberg builds
Message-ID: <BANLkTi=x6A2tZH=6Z4oTkNNCxJUiR2gVsg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110522/34ea813c/attachment.pl>

From gps at asu.edu  Mon May 23 21:21:21 2011
From: gps at asu.edu (Geoffrey Smith)
Date: Mon, 23 May 2011 12:21:21 -0700
Subject: [R-SIG-Finance] trading days between dates
Message-ID: <BANLkTimOqGo_W05XUUXMfwxaXAosm5pcVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110523/b7e0c31a/attachment.pl>

From andre.mirabelli at gmail.com  Mon May 23 23:42:19 2011
From: andre.mirabelli at gmail.com (aamm)
Date: Mon, 23 May 2011 14:42:19 -0700 (PDT)
Subject: [R-SIG-Finance] performance attribution
In-Reply-To: <BANLkTi=8JqumZHpALMPXJi3g9YnZ--isqQ@mail.gmail.com>
References: <BANLkTi=8JqumZHpALMPXJi3g9YnZ--isqQ@mail.gmail.com>
Message-ID: <1306186939552-3545594.post@n4.nabble.com>

Ben,

?Performance attribution? means different things to different people. There
are two different questions addressed under this term. 
One seeks an explanation of performance in terms of controllable investment
decisions. (?Interaction? is not a well-formed investment decision and,
thus, any well-formed investment-decision-attribution analysis will not have
?Interaction? as one of its explanatory variables.) Decision attribution is
normally associated with the name Brinson and the most general and robust
implementation I know of is from Opturo. Opturo?s approach allows for
balanced funds, since it allows the user to input their customized decision
structure (employing, in any given order and structure, any parameter
selection, such as duration, convexity, cap, and bucket allocation, such as
asset, sector and/or industry, and currency decisions) rather than forcing
the analysis into predetermined and, thus, inappropriate evaluations. So it
can also address both equity and fixed alone and the decisions appropriate
to each. It also provides the necessary correlate of risk attribution since,
as modern portfolio theory insists, performance analysis without parallel
risk analysis can only be dangerously misleading. Finally, it is the only
system that correctly includes trades in its evaluation of the weighs and
returns that decision attribution requires. The common daily trade-inclusive
performance calculations employed by other systems are all variations on
Deitz calculations, which are all deeply flawed and can easily be shown to
produce absurd results. These absurdities show that even when the results do
not appear absurd to the intuition, they are always unreliable.
The other kind of performance attribution seeks an explanation of
performance in terms of uncontrollable market factors. I presume this is
part of what you are seeking since you use the word ?exposure.? All these
models are difficult to significantly tinker with. Thus, their issue-level
exposures are usually provided as a coherent unit by providers such as
Barra, Northfield and APT. 
Specifically in regards to these market factor models, the other question
you should consider is whether you are interested in using them ex ante or
ex post. If you are considering using them ex post then be sure that the
weights that you employ are properly trade-adjusted. You do not want to be
attributing exposure to a factor that you traded out of. Again, Opturo is
the only package that I believe gets these trade-inclusive weights correct.
Others, it they adjust for trades at all, employ some version of Dietz
calculations, which are always flawed. Opturo allows you to take whatever
factor exposure models you employ and join them with its properly
trade-adjusted weights.
Most dangerous are models that conflate the investment-decision and the
market-factor approaches. Their mixed methodologies do not provide answers
to any clearly formulated economic questions. So you end up with numbers
that have names that sound informative but all these actual values are not
correct answers to the questions that their names imply or to any coherent
question at all.


--
View this message in context: http://r.789695.n4.nabble.com/performance-attribution-tp3519023p3545594.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From pucek8 at gmail.com  Tue May 24 12:53:34 2011
From: pucek8 at gmail.com (=?UTF-8?Q?Marcin_P=3F=EF=BF=BDciennik?=)
Date: Tue, 24 May 2011 12:53:34 +0200
Subject: [R-SIG-Finance] DCC-GARCH model and AR(1)-GARCH(1,
	1) regression model
In-Reply-To: <BANLkTinV6AivoOT9WhS7oF=NOoMdPFRXkQ@mail.gmail.com>
References: <BANLkTin5bUKEz8h5QxNTUydw46ExBA+ULg@mail.gmail.com>
	<BANLkTinV6AivoOT9WhS7oF=NOoMdPFRXkQ@mail.gmail.com>
Message-ID: <BANLkTindHRRZLfsPk3VXJjtPy2SSfnRNwA@mail.gmail.com>

Hello,
I sent this message a couple of times to r-help group but unfortunately did
not get any response that would be helpful...

I have a rather complex problem... I will have to explain everything in
detail because I cannot solve it by myself...i just ran out of ideas. So
here is what I want to do:
I take quotes of two indices - S&P500 and DJ. And my first aim is to
estimate coefficients of the DCC-GARCH model for them. This is how I do it:


library(tseries)
p1 = get.hist.quote(instrument = "^gspc",start = "2005-01-07",end =
"2009-09-04",compression = "w", quote="AdjClose")
p2 = get.hist.quote(instrument = "^dji",start = "2005-01-07",end =
"2009-09-04",compression = "w", quote="AdjClose")
p = cbind(p1,p2)
y = diff(log(p))*100
y[,1] = y[,1]-mean(y[,1])
y[,2] = y[,2]-mean(y[,2])
T = length(y[,1])

library(ccgarch)
library(fGarch)

f1 = garchFit(~ garch(1,1), data=y[,1],include.mean=FALSE)
f1 = f1 at fit$coef
f2 = garchFit(~ garch(1,1), data=y[,2],include.mean=FALSE)
f2 = f2 at fit$coef

a = c(f1[1], f2[1])
A = diag(c(f1[2],f2[2]))
B = diag(c(f1[3], f2[3]))
dccpara = c(0.2,0.6)
dccresults = dcc.estimation(inia=a, iniA=A, iniB=B, ini.dcc=dccpara,dvar=y,
model="diagonal")

dccresults$out
DCCrho = dccresults$DCC[,2]
matplot(DCCrho, type='l')

dccresults$out deliver me the estimated coefficients of the DCC-GARCH model.
And here is my first question:
How can I check if these coefficients are significant or not? How can I test
them for significance?

and the second one:
What is actually dccpara and why do I get totally different DCC-alpha and
DCC-beta coefficients if I change dccpara from c(0.2,0.6) to, let's say,
c(0.01, 0.98) ? What determines which values should be chosen?

Ok. This would be it when it comes to DCC-GARCH.

Now, using conditional correlation obtained from the DCC-GARCH model, I want
to test for structural shifts in conditional correlations. To be precise, I
want to test whether the conditional correlations significantly increase in
the turmoil period / during the Subprime crisis.
The regression model is AR(1)-GARCH(1,1), using a dummy variable specified
as:



*** the equations, you can find in the attachment ***



where the first equation is the conditional correlation among the two
indices during the Subprime crisis, Dt is a dummy variable for the turmoil
period, and the second equation (hij,t) is the conditional variance of eij,t

The aim is, of course, to find the estimates of the regression model on
structural shifts in the conditional correlations obtained in the DCC-GARCH
model.

I found an information that there is no function for AR(1)-GARCH(1,1)
regression model. That's why it has to be done in two steps:
1) estimate the AR parameters
2) estimate the GARCH part of the model on the residuals from the AR model

And this would be my rather poor idea of how to do it...


library(timeSeries)
library(fSeries)
library(tseries)
step1 = arma(DCCrho, order = c(1,0), include.intercept = TRUE)
step1$res
step11 = na.remove(step1$res)
step2 = garch (step11, order = c(1,1), include.intercept = TRUE)


To be honest I have no clue how to do it. I don't even now why do I get a
missing value as a result of step1 (step1$res[1]) and how to account for it?
Above, I just removed it but then I have a smaller number of
observations...and this is probably wrong.
And then these GARCH estimates on the residuals...does the code for that
make sense at all?


Hopefully, someone will find time to give me a hand because I have to solve
the problem and I reached the point where I cannot move forward without
someone's help. There is not much information on how to apply DCC-GARCH
model and AR(1)-GARCH(1,1) regression model in the Internet. Hopefully, some
of you are familiar with it.

Thank you very much in advance, people of good will, for looking at what I
wrote and helping me.

Best regards
Marcin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110524/9dd036ff/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Equations.pdf
Type: application/pdf
Size: 47651 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110524/9dd036ff/attachment.pdf>

From aeolus_lu at hotmail.com  Tue May 24 17:49:04 2011
From: aeolus_lu at hotmail.com (Yihao Lu aeolus_lu)
Date: Tue, 24 May 2011 11:49:04 -0400
Subject: [R-SIG-Finance] garchFit NaNs produced
In-Reply-To: <BANLkTindHRRZLfsPk3VXJjtPy2SSfnRNwA@mail.gmail.com>
References: <BANLkTin5bUKEz8h5QxNTUydw46ExBA+ULg@mail.gmail.com>,
	<BANLkTinV6AivoOT9WhS7oF=NOoMdPFRXkQ@mail.gmail.com>,
	<BANLkTindHRRZLfsPk3VXJjtPy2SSfnRNwA@mail.gmail.com>
Message-ID: <COL120-W469A1F17951004B992739088750@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110524/3520fd72/attachment.pl>

From algotr8der at gmail.com  Tue May 24 19:59:35 2011
From: algotr8der at gmail.com (algotr8der)
Date: Tue, 24 May 2011 10:59:35 -0700 (PDT)
Subject: [R-SIG-Finance] IBrokers - reqHistory results in missing random
	data
In-Reply-To: <1305832512102-3536670.post@n4.nabble.com>
References: <1305747184282-3533694.post@n4.nabble.com>
	<BANLkTimPYi24usacrCqEjVPiWp9n1VACDg@mail.gmail.com>
	<4DD45B8C.9050805@gmail.com>
	<1305832512102-3536670.post@n4.nabble.com>
Message-ID: <1306259975996-3547787.post@n4.nabble.com>

I am told there is a bug on IB's end. I have asked for further detail. I will
provide further information as I become aware.


--
View this message in context: http://r.789695.n4.nabble.com/IBrokers-reqHistory-results-in-missing-random-data-tp3533694p3547787.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From arun.kumar.saha at gmail.com  Tue May 24 21:07:43 2011
From: arun.kumar.saha at gmail.com (Arun.stat)
Date: Tue, 24 May 2011 12:07:43 -0700 (PDT)
Subject: [R-SIG-Finance] garchFit NaNs produced
In-Reply-To: <COL120-W469A1F17951004B992739088750@phx.gbl>
References: <BANLkTindHRRZLfsPk3VXJjtPy2SSfnRNwA@mail.gmail.com>
	<COL120-W469A1F17951004B992739088750@phx.gbl>
Message-ID: <1306264063889-3547947.post@n4.nabble.com>

Hi Yihao, not very sure on your situation, but are you sure that your data
have any Garch effect at all? Prima-facie it seems that your data dont have.
Why you want to fit garch model in such case?

Thanks and regards,
_____________________________________________________

Arun Kumar Saha, FRM
QUANTITATIVE RISK AND HEDGE CONSULTING SPECIALIST
Visit me at: http://in.linkedin.com/in/ArunFRM
_____________________________________________________

--
View this message in context: http://r.789695.n4.nabble.com/DCC-GARCH-model-and-AR-1-GARCH-1-1-regression-model-tp3546727p3547947.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From aeolus_lu at hotmail.com  Tue May 24 22:25:18 2011
From: aeolus_lu at hotmail.com (Yihao Lu aeolus_lu)
Date: Tue, 24 May 2011 16:25:18 -0400
Subject: [R-SIG-Finance] garchFit NaNs produced
In-Reply-To: <1306264063889-3547947.post@n4.nabble.com>
References: <BANLkTindHRRZLfsPk3VXJjtPy2SSfnRNwA@mail.gmail.com>,
	<COL120-W469A1F17951004B992739088750@phx.gbl>,
	<1306264063889-3547947.post@n4.nabble.com>
Message-ID: <COL120-W6010A5BE665A6FC85A643388750@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110524/072b56f5/attachment.pl>

From kent.russell at live.com  Tue May 24 22:52:25 2011
From: kent.russell at live.com (Kent Russell)
Date: Tue, 24 May 2011 15:52:25 -0500
Subject: [R-SIG-Finance] DCC-GARCH model and AR(1)-GARCH(1,
	1) regression model
In-Reply-To: <BANLkTindHRRZLfsPk3VXJjtPy2SSfnRNwA@mail.gmail.com>
References: <BANLkTin5bUKEz8h5QxNTUydw46ExBA+ULg@mail.gmail.com>
	<BANLkTinV6AivoOT9WhS7oF=NOoMdPFRXkQ@mail.gmail.com>
	<BANLkTindHRRZLfsPk3VXJjtPy2SSfnRNwA@mail.gmail.com>
Message-ID: <BLU0-SMTP588833F3F1523B7DEDE63BFB750@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110524/d7327f87/attachment.pl>

From edd at debian.org  Thu May 26 03:20:36 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 25 May 2011 20:20:36 -0500
Subject: [R-SIG-Finance] R/Finance 2011 slides and follow-up
Message-ID: <19933.43748.95664.461328@max.nulle.part>


The organizing committee for the R/Finance 2011 conference is pleased to
announce the availability of presentation slides from the 3rd annual
R/Finance conference.  This year's two-day conference once again attracted
over 200 participants from across the globe. Academics, students and industry
professionals enjoyed almost 30 talks covering trading, optimization, risk
management and more --- all using R!

The majority of these presentations are now available for download at:
 
    http://www.RinFinance.com/agenda/

This year we began offering prizes for the best paper submissions.  The 2011
recipients are Robert Gramacy (University of Chicago) and David Matteson
(Cornell University) who each won USD 1000.  Also new was a graduate student
travel award: Mikko Niemenmaa (Aalto University) and Cl?ment Dunand-Ch?tellet
(?cole Polytechnique) each received USD 500.

With this, the organizing committee would like to thank our lead conference
sponsors, the International Center for Futures and Derivatives at UIC and
Revolution Analytics, as well as our conference sponsors OneMarketData,
RStudio and Lemnica for their continued support.

The organising committee would also like to thank all of the presenters and
participants for making R/Finance 2011 so successful.  We look forward to
seeing you in 2012, with the prospective dates of May 17 - 19 to be
confirmed.

For the organizing committee,   

    Gib Bassett, Peter Carl, Dirk Eddelbuettel, Brian Peterson, 
    Dale Rosenthal, Jeffrey Ryan, Joshua Ulrich

-- 
Gauss once played himself in a zero-sum game and won $50.
                      -- #11 at http://www.gaussfacts.com


From sunduck at gmail.com  Fri May 27 17:14:10 2011
From: sunduck at gmail.com (Alex Bird)
Date: Fri, 27 May 2011 19:14:10 +0400
Subject: [R-SIG-Finance] objective function optimization in JAGS/BUGS rather
 then in optim-like R tools
Message-ID: <BANLkTikWP8Oi3hFEJTWzFz_DDBw7qWJbXQ@mail.gmail.com>

Hi there!

  I'm not sure whether this place is the right one to ask my question
so sorry in advance.
  My problem consists of two steps: on the first one I fit some model
parameters using R2jags and do n-days ahead prediction, then on the
second step I use doptim package to optimize my objective function
based on the predicted data. So I wonder is there a way to find
minimum/maximum of some function directly in JAGS or Win/OpenBUGS.

  To get an idea of what I am looking for please take a look at the
following code

require(R2jags)

### first step - fitting params
#########################################
#helper function
write.jags.model<-function(model,filename="model.bug",dir=getwd()){
    old.dir <- getwd()
    setwd(dir)
    on.exit(setwd(old.dir))
    if (file.exists(filename)) {
        sn <- unlist(strsplit(filename, "\\."))
        if (length(sn) > 2) {
            sn[(length(sn) - 1)] <- paste(sn[-length(sn)], collapse = ".")
            sn <- sn[-c(1:(length(sn) - 2))]
        }
        ff <- tempfile("model", "")
        filename2 <- paste(substr(ff, 2, nchar(ff)), "bug", sep = ".")
        if (file.exists(filename2)) {
            while (!file.exists(filename2)) {
                ff <- tempfile("model", "")
                filename2 <- paste(substr(ff, 2, nchar(ff)),
                  "bug", sep = ".")
            }
        }
    }
    else {
        filename2 <- filename
    }
    if (inherits(model, "custommodel")) {
        writeLines(model, filename2)
    }
    else {
        write.model(model, filename2)
    }
    invisible(filename2)
}

#simulated data
N<-100
y<-rnorm(N,.001,.01)

#model to fit (actually wrong one)
jmodel<-function(){
	for (i in 1:N){
		size[i]~dnorm(muj,precj)
		j[i]~dbern(lambda)
		dummy[i]<-mu+j[i]*size[i]
		y[i]~dnorm(dummy[i],prec)
	}
	mu~dnorm(0,0.01)
	prec~dgamma(2,0.01)
	lambda~dbeta(1,5)
	muj~dnorm(0,0.01)
	precj~dgamma(5,20)
	
	for (i in 1:5){
		size.pred[i]~dnorm(muj,precj)
		j.pred[i]~dbern(lambda)
		dummy.pred[i]<-mu+j.pred[i]*size.pred[i]
		y.pred[i]~dnorm(dummy.pred[i],prec)		
	}
}
model.file<-write.jags.model(jmodel)
jparams<-c('mu','prec','lambda','muj','precj','y.pred')
jags.data<-list('y','N')
jfit<-jags(data=jags.data,inits=NULL,jparams,n.iter=10000,model.file=model.file,DIC=T,n.chains=3)


### second step - function optimization based on y.pred
#########################################
y.pred<-colMeans(jfit$BUGSoutput$sims.list$y.pred)
x.pred<-rnorm(5,.001,.01)

#some objective function - just to get an idea
utf<-function(w=1/2){-c(mean(y.pred),mean(x.known))%*%c(w,1-w)}
w.opt<-optimize(utf,lower=-1,upper=1)$minimum
w.opt


where the second step I want to put somehow directly into jmodel

Thanks!
Alex


From jctoll at gmail.com  Sat May 28 01:52:00 2011
From: jctoll at gmail.com (J Toll)
Date: Fri, 27 May 2011 18:52:00 -0500
Subject: [R-SIG-Finance] Excessive data needed for volatility{TTR}
	calculation?
Message-ID: <BANLkTikKos4D9x4Ast3Yw9=RYzCnZnen7g@mail.gmail.com>

Hi,

I have been using the volatility function from the TTR package and I
noticed something that I thought was a bit unusual. I expected that I
should be able to calculate the default 10-day volatility using the
close estimator starting with 10 or maybe 11 days of data.  That's not
what I found.  It appears that 18 days of data is necessary to
calculate a 10-day volatility.  For example:

> getSymbols("SPY")
[1] "SPY"
> volatility(tail(SPY, 10), n = 10, calc = "close", N = 260)
Error in `[.xts`(x, beg:(n + beg - 1)) : subscript out of bounds
> volatility(tail(SPY, 11), n = 10, calc = "close", N = 260)
Error in `[.xts`(x, beg:(n + beg - 1)) : subscript out of bounds
> volatility(tail(SPY, 18), n = 10, calc = "close", N = 260)
                 [,1]
2011-05-03         NA
2011-05-04         NA
2011-05-05         NA
- edited for brevity -
2011-05-23         NA
2011-05-24         NA
2011-05-25         NA
2011-05-26 0.09481466

Stranger still (at least to me), it appears that 38 days worth of data
is necessary to start calculating a 20-day volatility.

> volatility(tail(SPY, 37), n = 20, calc = "close", N = 260)
Error in `[.xts`(x, beg:(n + beg - 1)) : subscript out of bounds
> volatility(tail(SPY, 38), n = 20, calc = "close", N = 260)
                [,1]
2011-04-04        NA
2011-04-05        NA
2011-04-06        NA
 - edited for brevity -
2011-05-23        NA
2011-05-24        NA
2011-05-25        NA
2011-05-26 0.1088309

58 days of data is necessary for a 30-day volatility calculation.
>From looking at the code for the volatility function, I'm not seeing
why so much additional data is needed to calculate the volatility.
Does anybody have an idea of why so much additional data is necessary?
 Thanks.

James

R version 2.13.0 (2011-04-13)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)


From jctoll at gmail.com  Sat May 28 04:33:56 2011
From: jctoll at gmail.com (J Toll)
Date: Fri, 27 May 2011 21:33:56 -0500
Subject: [R-SIG-Finance] Excessive data needed for volatility{TTR}
	calculation?
In-Reply-To: <BANLkTikKos4D9x4Ast3Yw9=RYzCnZnen7g@mail.gmail.com>
References: <BANLkTikKos4D9x4Ast3Yw9=RYzCnZnen7g@mail.gmail.com>
Message-ID: <BANLkTingmwkSs=L2vpOTDvqC+wJqLf0d0A@mail.gmail.com>

Hi again,

I've been trying to figure out the problem and I believe there is a
problem with the vectorization in volatility, which results in the
volatility calculations for the close to close method being
inaccurate.  I believe the issue is with this part of line 14.

runSum((r - rBar)^2, n - 1)

The first 9 r all have to be differenced against the same rBar, not a
running sum of rBars.  I believe a better way to accomplish this would
be:

s <- sqrt(N) * runSD(r, (n -1))

> volatility
function (OHLC, n = 10, calc = "close", N = 260, ...)
{
    OHLC <- try.xts(OHLC, error = as.matrix)
    calc <- match.arg(calc, c("close", "garman.klass", "parkinson",
        "rogers.satchell", "gk.yz", "yang.zhang"))
    if (calc == "close") {
        if (NCOL(OHLC) == 1) {
            r <- ROC(OHLC[, 1], 1, ...)
        }
        else {
            r <- ROC(OHLC[, 4], 1, ...)
        }
        rBar <- runSum(r, n - 1)/(n - 1)
        s <- sqrt(N/(n - 2) * runSum((r - rBar)^2, n - 1))       # line 14
    }

Please let me know if this makes sense to anyone else, or if I'm
mistaken.  Thanks.

James



On Fri, May 27, 2011 at 6:52 PM, J Toll <jctoll at gmail.com> wrote:
> Hi,
>
> I have been using the volatility function from the TTR package and I
> noticed something that I thought was a bit unusual. I expected that I
> should be able to calculate the default 10-day volatility using the
> close estimator starting with 10 or maybe 11 days of data. ?That's not
> what I found. ?It appears that 18 days of data is necessary to
> calculate a 10-day volatility. ?For example:
>
>> getSymbols("SPY")
> [1] "SPY"
>> volatility(tail(SPY, 10), n = 10, calc = "close", N = 260)
> Error in `[.xts`(x, beg:(n + beg - 1)) : subscript out of bounds
>> volatility(tail(SPY, 11), n = 10, calc = "close", N = 260)
> Error in `[.xts`(x, beg:(n + beg - 1)) : subscript out of bounds
>> volatility(tail(SPY, 18), n = 10, calc = "close", N = 260)
> ? ? ? ? ? ? ? ? [,1]
> 2011-05-03 ? ? ? ? NA
> 2011-05-04 ? ? ? ? NA
> 2011-05-05 ? ? ? ? NA
> - edited for brevity -
> 2011-05-23 ? ? ? ? NA
> 2011-05-24 ? ? ? ? NA
> 2011-05-25 ? ? ? ? NA
> 2011-05-26 0.09481466
>
> Stranger still (at least to me), it appears that 38 days worth of data
> is necessary to start calculating a 20-day volatility.
>
>> volatility(tail(SPY, 37), n = 20, calc = "close", N = 260)
> Error in `[.xts`(x, beg:(n + beg - 1)) : subscript out of bounds
>> volatility(tail(SPY, 38), n = 20, calc = "close", N = 260)
> ? ? ? ? ? ? ? ?[,1]
> 2011-04-04 ? ? ? ?NA
> 2011-04-05 ? ? ? ?NA
> 2011-04-06 ? ? ? ?NA
> ?- edited for brevity -
> 2011-05-23 ? ? ? ?NA
> 2011-05-24 ? ? ? ?NA
> 2011-05-25 ? ? ? ?NA
> 2011-05-26 0.1088309
>
> 58 days of data is necessary for a 30-day volatility calculation.
> From looking at the code for the volatility function, I'm not seeing
> why so much additional data is needed to calculate the volatility.
> Does anybody have an idea of why so much additional data is necessary?
> ?Thanks.
>
> James
>
> R version 2.13.0 (2011-04-13)
> Copyright (C) 2011 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>


From josh.m.ulrich at gmail.com  Sat May 28 05:39:58 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 27 May 2011 22:39:58 -0500
Subject: [R-SIG-Finance] Excessive data needed for volatility{TTR}
	calculation?
In-Reply-To: <BANLkTingmwkSs=L2vpOTDvqC+wJqLf0d0A@mail.gmail.com>
References: <BANLkTikKos4D9x4Ast3Yw9=RYzCnZnen7g@mail.gmail.com>
	<BANLkTingmwkSs=L2vpOTDvqC+wJqLf0d0A@mail.gmail.com>
Message-ID: <BANLkTikMGOLQCu2rq9tyFH9_WW4QUmJ3jg@mail.gmail.com>

Hi James,

On Fri, May 27, 2011 at 9:33 PM, J Toll <jctoll at gmail.com> wrote:
> Hi again,
>
> I've been trying to figure out the problem and I believe there is a
> problem with the vectorization in volatility, which results in the
> volatility calculations for the close to close method being
> inaccurate. ?I believe the issue is with this part of line 14.
>
> runSum((r - rBar)^2, n - 1)
>
> The first 9 r all have to be differenced against the same rBar, not a
> running sum of rBars. ?I believe a better way to accomplish this would
> be:
>
> s <- sqrt(N) * runSD(r, (n -1))
>
>> volatility
> function (OHLC, n = 10, calc = "close", N = 260, ...)
> {
> ? ?OHLC <- try.xts(OHLC, error = as.matrix)
> ? ?calc <- match.arg(calc, c("close", "garman.klass", "parkinson",
> ? ? ? ?"rogers.satchell", "gk.yz", "yang.zhang"))
> ? ?if (calc == "close") {
> ? ? ? ?if (NCOL(OHLC) == 1) {
> ? ? ? ? ? ?r <- ROC(OHLC[, 1], 1, ...)
> ? ? ? ?}
> ? ? ? ?else {
> ? ? ? ? ? ?r <- ROC(OHLC[, 4], 1, ...)
> ? ? ? ?}
> ? ? ? ?rBar <- runSum(r, n - 1)/(n - 1)
> ? ? ? ?s <- sqrt(N/(n - 2) * runSum((r - rBar)^2, n - 1)) ? ? ? # line 14
> ? ?}
>
> Please let me know if this makes sense to anyone else, or if I'm
> mistaken. ?Thanks.
>
> James
>
>
>
Thanks for digging into this.  I've recently received one or two
emails about this off-list, but have not had time to look into the
issue.

I think your solution will work, but using 'n' instead of 'n-1'.  The
code below shows the same results using your solution and a formula
similar to the one found here (which I mis-interpreted when I
originally wrote the function):
http://web.archive.org/web/20081224134043/http://www.sitmo.com/eq/172

set.seed(21)
N <- 260
n <- 100
r <- rnorm(n)/100
last(sqrt(N) * runSD(r, n))
sqrt(N/(n-1)*sum((r-mean(r))^2))

Thanks!
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com



> On Fri, May 27, 2011 at 6:52 PM, J Toll <jctoll at gmail.com> wrote:
>> Hi,
>>
>> I have been using the volatility function from the TTR package and I
>> noticed something that I thought was a bit unusual. I expected that I
>> should be able to calculate the default 10-day volatility using the
>> close estimator starting with 10 or maybe 11 days of data. ?That's not
>> what I found. ?It appears that 18 days of data is necessary to
>> calculate a 10-day volatility. ?For example:
>>
>>> getSymbols("SPY")
>> [1] "SPY"
>>> volatility(tail(SPY, 10), n = 10, calc = "close", N = 260)
>> Error in `[.xts`(x, beg:(n + beg - 1)) : subscript out of bounds
>>> volatility(tail(SPY, 11), n = 10, calc = "close", N = 260)
>> Error in `[.xts`(x, beg:(n + beg - 1)) : subscript out of bounds
>>> volatility(tail(SPY, 18), n = 10, calc = "close", N = 260)
>> ? ? ? ? ? ? ? ? [,1]
>> 2011-05-03 ? ? ? ? NA
>> 2011-05-04 ? ? ? ? NA
>> 2011-05-05 ? ? ? ? NA
>> - edited for brevity -
>> 2011-05-23 ? ? ? ? NA
>> 2011-05-24 ? ? ? ? NA
>> 2011-05-25 ? ? ? ? NA
>> 2011-05-26 0.09481466
>>
>> Stranger still (at least to me), it appears that 38 days worth of data
>> is necessary to start calculating a 20-day volatility.
>>
>>> volatility(tail(SPY, 37), n = 20, calc = "close", N = 260)
>> Error in `[.xts`(x, beg:(n + beg - 1)) : subscript out of bounds
>>> volatility(tail(SPY, 38), n = 20, calc = "close", N = 260)
>> ? ? ? ? ? ? ? ?[,1]
>> 2011-04-04 ? ? ? ?NA
>> 2011-04-05 ? ? ? ?NA
>> 2011-04-06 ? ? ? ?NA
>> ?- edited for brevity -
>> 2011-05-23 ? ? ? ?NA
>> 2011-05-24 ? ? ? ?NA
>> 2011-05-25 ? ? ? ?NA
>> 2011-05-26 0.1088309
>>
>> 58 days of data is necessary for a 30-day volatility calculation.
>> From looking at the code for the volatility function, I'm not seeing
>> why so much additional data is needed to calculate the volatility.
>> Does anybody have an idea of why so much additional data is necessary?
>> ?Thanks.
>>
>> James
>>
>> R version 2.13.0 (2011-04-13)
>> Copyright (C) 2011 The R Foundation for Statistical Computing
>> ISBN 3-900051-07-0
>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From jctoll at gmail.com  Sat May 28 06:25:00 2011
From: jctoll at gmail.com (J Toll)
Date: Fri, 27 May 2011 23:25:00 -0500
Subject: [R-SIG-Finance] Excessive data needed for volatility{TTR}
	calculation?
In-Reply-To: <BANLkTikMGOLQCu2rq9tyFH9_WW4QUmJ3jg@mail.gmail.com>
References: <BANLkTikKos4D9x4Ast3Yw9=RYzCnZnen7g@mail.gmail.com>
	<BANLkTingmwkSs=L2vpOTDvqC+wJqLf0d0A@mail.gmail.com>
	<BANLkTikMGOLQCu2rq9tyFH9_WW4QUmJ3jg@mail.gmail.com>
Message-ID: <BANLkTinH92DxCfuAs0hxV1bHYy2AtmMALQ@mail.gmail.com>

On Fri, May 27, 2011 at 10:39 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> I think your solution will work, but using 'n' instead of 'n-1'. ?The
> code below shows the same results using your solution and a formula
> similar to the one found here (which I mis-interpreted when I
> originally wrote the function):
> http://web.archive.org/web/20081224134043/http://www.sitmo.com/eq/172
>
> set.seed(21)
> N <- 260
> n <- 100
> r <- rnorm(n)/100
> last(sqrt(N) * runSD(r, n))
> sqrt(N/(n-1)*sum((r-mean(r))^2))
>
> Thanks!
> --
> Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com
>

Hi Joshua,

Thanks for replying and confirming my suspicions. However, I'm curious
why you would use 'n' rather than 'n-1'.  My thinking is that a 10-day
volatility (n = 10) is calculated as the annualized standard deviation
of 9 (n - 1) price returns (i.e. ln(p1/p0), ROC()).  The sample
standard deviation of 9 price returns would be the sum of the squared
deviations divided by 9 - 1, or n - 2.  Therefore, I believe your line

sqrt(N / (n - 1) * sum((r - mean(r)) ^ 2))

should actually be

sqrt(N / (n - 2) * sum((r - mean(r)) ^ 2))

I've been double-checking my work and went ahead and calculated 10 and
20-day vols by hand and I'm pretty sure

s <- sqrt(N) * runSD(r, (n - 1))

is correct, unless your defining 10-day volatility as 11 days of data
and 10 price returns.  Please let me know otherwise. Thanks.

James


From thomas.browne at mac.com  Sat May 28 11:43:28 2011
From: thomas.browne at mac.com (Thomas Browne)
Date: Sat, 28 May 2011 10:43:28 +0100
Subject: [R-SIG-Finance] Curve fitting the South African yield curve
Message-ID: <FBC39A66-CA97-46D3-8F59-0AA1E4C3AB38@mac.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110528/f33e535c/attachment.pl>

From josh.m.ulrich at gmail.com  Sat May 28 14:13:49 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 28 May 2011 07:13:49 -0500
Subject: [R-SIG-Finance] Excessive data needed for volatility{TTR}
	calculation?
In-Reply-To: <BANLkTinH92DxCfuAs0hxV1bHYy2AtmMALQ@mail.gmail.com>
References: <BANLkTikKos4D9x4Ast3Yw9=RYzCnZnen7g@mail.gmail.com>
	<BANLkTingmwkSs=L2vpOTDvqC+wJqLf0d0A@mail.gmail.com>
	<BANLkTikMGOLQCu2rq9tyFH9_WW4QUmJ3jg@mail.gmail.com>
	<BANLkTinH92DxCfuAs0hxV1bHYy2AtmMALQ@mail.gmail.com>
Message-ID: <BANLkTi=U=jVKZhRVu+oBwayYO5exhMz6HQ@mail.gmail.com>

Hi James,

On Fri, May 27, 2011 at 11:25 PM, J Toll <jctoll at gmail.com> wrote:
> On Fri, May 27, 2011 at 10:39 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>> I think your solution will work, but using 'n' instead of 'n-1'. ?The
>> code below shows the same results using your solution and a formula
>> similar to the one found here (which I mis-interpreted when I
>> originally wrote the function):
>> http://web.archive.org/web/20081224134043/http://www.sitmo.com/eq/172
>>
>> set.seed(21)
>> N <- 260
>> n <- 100
>> r <- rnorm(n)/100
>> last(sqrt(N) * runSD(r, n))
>> sqrt(N/(n-1)*sum((r-mean(r))^2))
>>
>> Thanks!
>> --
>> Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com
>>
>
> Hi Joshua,
>
> Thanks for replying and confirming my suspicions. However, I'm curious
> why you would use 'n' rather than 'n-1'. ?My thinking is that a 10-day
> volatility (n = 10) is calculated as the annualized standard deviation
> of 9 (n - 1) price returns (i.e. ln(p1/p0), ROC()). ?The sample
> standard deviation of 9 price returns would be the sum of the squared
> deviations divided by 9 - 1, or n - 2. ?Therefore, I believe your line
>
> sqrt(N / (n - 1) * sum((r - mean(r)) ^ 2))
>
> should actually be
>
> sqrt(N / (n - 2) * sum((r - mean(r)) ^ 2))
>
Actually, because the first return in the moving window would always
be NA, it should be:
sqrt(N/(n-2)*sum((r[-1]-mean(r[-1]))^2))

which yields the same result as:
last(sqrt(N) * runSD(r, n-1))

> I've been double-checking my work and went ahead and calculated 10 and
> 20-day vols by hand and I'm pretty sure
>
> s <- sqrt(N) * runSD(r, (n - 1))
>
> is correct, unless your defining 10-day volatility as 11 days of data
> and 10 price returns. ?Please let me know otherwise. Thanks.
>
> James
>
After getting some sleep, it's clear that your initial solution (n-1)
is correct.

Your patch will be on R-forge shortly.  Many thanks again!

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From jctoll at gmail.com  Sat May 28 16:44:56 2011
From: jctoll at gmail.com (J Toll)
Date: Sat, 28 May 2011 09:44:56 -0500
Subject: [R-SIG-Finance] Excessive data needed for volatility{TTR}
	calculation?
In-Reply-To: <BANLkTi=U=jVKZhRVu+oBwayYO5exhMz6HQ@mail.gmail.com>
References: <BANLkTikKos4D9x4Ast3Yw9=RYzCnZnen7g@mail.gmail.com>
	<BANLkTingmwkSs=L2vpOTDvqC+wJqLf0d0A@mail.gmail.com>
	<BANLkTikMGOLQCu2rq9tyFH9_WW4QUmJ3jg@mail.gmail.com>
	<BANLkTinH92DxCfuAs0hxV1bHYy2AtmMALQ@mail.gmail.com>
	<BANLkTi=U=jVKZhRVu+oBwayYO5exhMz6HQ@mail.gmail.com>
Message-ID: <BANLkTi=bT-PckNVORZBXQpFkyrZsWCSOOA@mail.gmail.com>

Joshua,

On Sat, May 28, 2011 at 7:13 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> Actually, because the first return in the moving window would always
> be NA, it should be:
> sqrt(N/(n-2)*sum((r[-1]-mean(r[-1]))^2))
>
> which yields the same result as:
> last(sqrt(N) * runSD(r, n-1))

I've been trying both lines of code and unfortunately I'm not getting
the same results.  The first line seems to only work properly for me
in those instances when NCOL(OHLC) = n.  For the more common situation
where NCOL(OHLC) > n, you would want a rolling window of vol
calculations.  I'm still thinking that the code should be:

s <- sqrt(N) * runSD(r, (n - 1))

As a frame of reference, I believe the output should be:
> getSymbols("SPY")
> tail(volatility(SPY))
                [,1]
2011-05-20 0.1206382
2011-05-23 0.1181380
2011-05-24 0.1095445
2011-05-25 0.1069024
2011-05-26 0.1068434
2011-05-27 0.1038008

I've manually calculated the value for 2011-05-27 using a spreadsheet
to confirm the value. I believe the other values to be correct also.

> After getting some sleep, it's clear that your initial solution (n-1)
> is correct.
>
> Your patch will be on R-forge shortly. ?Many thanks again!
>
> Best,
> --
> Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com

You may want to hold off on a patch in the short term.  I still think
there might be an error in there.  I'm sorry to be such a nuisance
about this, but thanks so much for your help.

James


From 20977 at gaffa.net  Sat May 28 17:18:33 2011
From: 20977 at gaffa.net (Kostas Evangelinos)
Date: Sat, 28 May 2011 11:18:33 -0400
Subject: [R-SIG-Finance] IBrokers - reqHistory results in missing random
 data
In-Reply-To: <1306259975996-3547787.post@n4.nabble.com>
References: <1305747184282-3533694.post@n4.nabble.com>
	<BANLkTimPYi24usacrCqEjVPiWp9n1VACDg@mail.gmail.com>
	<4DD45B8C.9050805@gmail.com>
	<1305832512102-3536670.post@n4.nabble.com>
	<1306259975996-3547787.post@n4.nabble.com>
Message-ID: <20110528151832.GA13551@sanchez.localnet>

On Tue, May 24, 2011 at 10:59:35AM -0700, algotr8der wrote:
| I am told there is a bug on IB's end. I have asked for further detail. I will
| provide further information as I become aware.

You might want to try ibfetch - I use this to download historical and realtime
data from IB into csv files daily. I haven't seen issues like the ones you
describe.

http://www.gaffa.net/stuff/ibfetch-0.2.tar.gz

Example:
$ ibfetch -i 20 -l 2 -s 20110402 -S '1 min' AUD.JPY ESc1

Kostas


From jeffrey.ryan at lemnica.com  Sat May 28 18:06:04 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Sat, 28 May 2011 11:06:04 -0500
Subject: [R-SIG-Finance] IBrokers - reqHistory results in missing random
	data
In-Reply-To: <20110528151832.GA13551@sanchez.localnet>
References: <1305747184282-3533694.post@n4.nabble.com>
	<BANLkTimPYi24usacrCqEjVPiWp9n1VACDg@mail.gmail.com>
	<4DD45B8C.9050805@gmail.com>
	<1305832512102-3536670.post@n4.nabble.com>
	<1306259975996-3547787.post@n4.nabble.com>
	<20110528151832.GA13551@sanchez.localnet>
Message-ID: <BANLkTimprv2JW8xwgXJAo_WUix2OY=krKg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110528/5cea1d05/attachment.pl>

From algotr8der at gmail.com  Sat May 28 19:07:38 2011
From: algotr8der at gmail.com (algotr8der)
Date: Sat, 28 May 2011 10:07:38 -0700 (PDT)
Subject: [R-SIG-Finance] IBrokers - reqHistory results in missing random
	data
In-Reply-To: <BANLkTimprv2JW8xwgXJAo_WUix2OY=krKg@mail.gmail.com>
References: <1305747184282-3533694.post@n4.nabble.com>
	<BANLkTimPYi24usacrCqEjVPiWp9n1VACDg@mail.gmail.com>
	<4DD45B8C.9050805@gmail.com>
	<1305832512102-3536670.post@n4.nabble.com>
	<1306259975996-3547787.post@n4.nabble.com>
	<20110528151832.GA13551@sanchez.localnet>
	<BANLkTimprv2JW8xwgXJAo_WUix2OY=krKg@mail.gmail.com>
Message-ID: <1306602458537-3557764.post@n4.nabble.com>

>>For one, if this uses the sockets there would be zero difference. IBrokers 
>>is a raw translation (open to read!) of the socket protocol, and simply 
>>would fail if incorrect (it is not).  Unless you are running on the same 
>>data, at the same time, with the same requests your conclusion has no
basis 
>>in fact - as it is nothing more than conjecture. 

Hi Jeff - I must have not been clear in my latest post in this thread -
sincere apologies for that. When I said 'I am told there is a bug on IB's
end' I meant IB = Interactive Brokers and not IBrokers. Sorry for the
confusion. This is something internal to Interactive Brokers so nothing to
do with the IBrokers R package.

>>Second, linking to a binary(?!) without some context around it (google 
>>search and directories of .net domain provide nothing) is about as useless 
>>as saying nothing.  Certainly nothing to do with R, or even a 
>>solution/insight - except for those naive enough to run it. Your email and 
>>name aren't anywhere in my records of contributors to R-sig-finance, or R. 

I'm not sure what you are trying to say in the above paragraph. 

>>I'd suggest this has nothing to do with an R solution and nothing to do
with 
>>R at all.  There are myriad ways to accomplish requests - all of the
others 
>>aren't suitable to the thread in question. 

I agree that this has nothing to do with an R solution hence why I posted an
update indicating that the problem occurs with Interactive Broker's own
tools:

1) the time issue is not present when you use TswDde, however it is present
when you use TswActiveX. The first 1 minute intraday bar occurs at 09:30:00
and the last bar at 15:59:00 when you export historical data using
tswActiveX. The same does not occur when you use TswDde. 

2) the missing data issue occurs with both TswDde and TswActiveX. 

I thought that issue #2 may have had to do with 'poor quality' data rather
than a problem with the export mechanism. But Interactive Brokers technical
support rep I was working with indicated on several occasions that he did
not have missing data during his testing using the same said tools for the
same time periods and same symbol. Now this is his *claim* and not something
that I can independently verify other than indicate that there are gaps in
the data exported from Interactive Brokers using their tools in my testing.

All the best.
AT




--
View this message in context: http://r.789695.n4.nabble.com/IBrokers-reqHistory-results-in-missing-random-data-tp3533694p3557764.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From josh.m.ulrich at gmail.com  Sat May 28 20:16:37 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 28 May 2011 13:16:37 -0500
Subject: [R-SIG-Finance] Excessive data needed for volatility{TTR}
	calculation?
In-Reply-To: <BANLkTi=bT-PckNVORZBXQpFkyrZsWCSOOA@mail.gmail.com>
References: <BANLkTikKos4D9x4Ast3Yw9=RYzCnZnen7g@mail.gmail.com>
	<BANLkTingmwkSs=L2vpOTDvqC+wJqLf0d0A@mail.gmail.com>
	<BANLkTikMGOLQCu2rq9tyFH9_WW4QUmJ3jg@mail.gmail.com>
	<BANLkTinH92DxCfuAs0hxV1bHYy2AtmMALQ@mail.gmail.com>
	<BANLkTi=U=jVKZhRVu+oBwayYO5exhMz6HQ@mail.gmail.com>
	<BANLkTi=bT-PckNVORZBXQpFkyrZsWCSOOA@mail.gmail.com>
Message-ID: <BANLkTinJoPre0R7tx4Ym7gp6KHc4OLpvww@mail.gmail.com>

Hi James,

On Sat, May 28, 2011 at 9:44 AM, J Toll <jctoll at gmail.com> wrote:
> Joshua,
>
> On Sat, May 28, 2011 at 7:13 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>> Actually, because the first return in the moving window would always
>> be NA, it should be:
>> sqrt(N/(n-2)*sum((r[-1]-mean(r[-1]))^2))
>>
>> which yields the same result as:
>> last(sqrt(N) * runSD(r, n-1))
>
> I've been trying both lines of code and unfortunately I'm not getting
> the same results. ?The first line seems to only work properly for me
> in those instances when NCOL(OHLC) = n. ?For the more common situation
> where NCOL(OHLC) > n, you would want a rolling window of vol
> calculations. ?I'm still thinking that the code should be:
>
> s <- sqrt(N) * runSD(r, (n - 1))
>
<snip>
>
> You may want to hold off on a patch in the short term. ?I still think
> there might be an error in there. ?I'm sorry to be such a nuisance
> about this, but thanks so much for your help.
>
> James
>

My last email wasn't very clear; I apologize.

I still agree with your suggestion and plan to use it as a patch.  The
first line in my prior email was to illustrate (and convince myself)
that your solution matched the formula here:
http://web.archive.org/web/20081224134043/http://www.sitmo.com/eq/172

And it only matches when NROW(OHLC) == n because your solution
operates on a rolling window and my first line operates on everything.
 Try something like this:

n <- 5
R <- cumprod(1+r)
FUN <- function(x) {
  r <- ROC(x); n <- NROW(x)
  sqrt(252/(n-2)*sum((r-mean(r, na.rm=TRUE))^2, na.rm=TRUE))
}
head(sqrt(N) * runSD(ROC(R), n-1),15)
head(rollapply(R, n, FUN, align="right", fill=NA),15)
n <- 10
head(sqrt(N) * runSD(ROC(R), n-1),15)
head(rollapply(R, n, FUN, align="right", fill=NA),15)

Sorry for the confusion.

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From josh.m.ulrich at gmail.com  Sun May 29 04:18:45 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 28 May 2011 21:18:45 -0500
Subject: [R-SIG-Finance] Curve fitting the South African yield curve
In-Reply-To: <FBC39A66-CA97-46D3-8F59-0AA1E4C3AB38@mac.com>
References: <FBC39A66-CA97-46D3-8F59-0AA1E4C3AB38@mac.com>
Message-ID: <BANLkTinyCEwzZxJSFr6ozkstvcuRAsd_9g@mail.gmail.com>

Hi Tom,

On Sat, May 28, 2011 at 4:43 AM, Thomas Browne <thomas.browne at mac.com> wrote:
> Hi,
>
> I am looking to do historic cheap/dear analysis on the South African
> bond and IRS yield curves. What I'd like to do is fit a curve each day
> and see what the historic deviation from that fitted curve each bond
> has exhibited. The curve I guess should not be a cubic spline type
> since that would go through all the bonds). I want a fairly simple
> model because to start with and I've heard of Nelson-Siegel. How would
> I go about doing this using R? Is there a library which could help?
>
A search for "Nelson Siegel" on www.rseek.org returned 3 packages on
the first page.
1) YieldCurve
2) fBonds
3) termstruc

I've used YieldCurve.  I've never used fBonds.  I looked at termstruc
but I needed to modify some of the functions and it was easier to
understand the YieldCurve code (it's very simple and straight
forward).

> As I'm just starting out I don't really want to have to bootstrap the
> zero curve first (too much work! Unless there's help in R for that
> too!). I'd just like to fit a fairly simple curve which makes sense to
> the YTM versus Mduration (or PV01) scatterplot.
>
> Thanks for any help.
>
> Tom
>

Hope that helps,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From veepsirtt at gmail.com  Sun May 29 13:31:01 2011
From: veepsirtt at gmail.com (Velappan Periasamy)
Date: Sun, 29 May 2011 17:01:01 +0530
Subject: [R-SIG-Finance] How to test pairs trading strategy
Message-ID: <BANLkTiksZ8-Xu6zXPWJApE4G4Y49eDxocw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110529/50cbb90c/attachment.pl>

From daniel.cegielka at gmail.com  Sun May 29 13:43:33 2011
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Sun, 29 May 2011 13:43:33 +0200
Subject: [R-SIG-Finance] How to test pairs trading strategy
In-Reply-To: <BANLkTiksZ8-Xu6zXPWJApE4G4Y49eDxocw@mail.gmail.com>
References: <BANLkTiksZ8-Xu6zXPWJApE4G4Y49eDxocw@mail.gmail.com>
Message-ID: <BANLkTinEO+EaA2Erua5hkm8kUErrc4a8_A@mail.gmail.com>

> Why I am not getting any plot?.

I have chart.. but eq_* == 1

> How to test pairs trading strategy?

Try quantstrat package - this is a high-quality backtester. In demo
you have a pair trading script... so install and run demo.

https://r-forge.r-project.org/scm/viewvc.php/pkg/quantstrat/demo/pair_trade.R?view=markup&revision=605&root=blotter

https://r-forge.r-project.org/R/?group_id=316

Best regards,
Daniel


2011/5/29 Velappan Periasamy <veepsirtt at gmail.com>:
> How to test pairs trading strategy?
>
> Why I am not getting any plot?.
> Kindly help me
> with regards
> veepsirtt
>
> # We will need the quantmod package for charting and pulling data
> # You can install packages via: install.packages("packageName")
> # install.packages(c("quantmod","TTR"))
> library(quantmod)
>
> # Pull "KO", "PEP" stock data from Yahoo! Finance
> tckr1<-"KO"
> tckr2<-"PEP"
> start<-Sys.Date()-500
> end<- format(Sys.Date(),"%Y-%m-%d") # yyyy-mm-dd
> getSymbols(tckr1, from=start, to=end)
> getSymbols(tckr2, from=start, to=end)
>
> #Calculate the pair ratio
> ra <- Cl(KO)/Cl(PEP)
>
> #Create a long (up) signal
> #if the current ratio is less than 2.7*STD from mean.
> sigup <- ifelse(ra < mean(ra)-2.7*sd(ra) , 1, 0)
>
> # Create the short (dn) signals
> #if the current ratio is more ?than 0.5*STD from mean.
> sigdn <- ifelse(ra > mean(ra)-0.5*sd(ra) -1, 0)
>
> sigup[is.na(sigup)] <- 0
> sigdn[is.na(sigdn)] <- 0
>
> # Lag signals to align with days in market,
> # not days signals were generated
> #sigup <- Lag(sigup,1) # Use lag() to avoid Toby's error
> #sigdn <- Lag(sigdn,1) # Use lag() to avoid Toby's error
> sigup <- lag(sigup,1) # Note k=1 implies a move *forward*
> sigdn <- lag(sigdn,1) # Note k=1 implies a move *forward*
>
> # Replace missing signals with no position
> # (generally just at beginning of series)
> sigup[is.na(sigup)] <- 0
> sigdn[is.na(sigdn)] <- 0
>
> # Combine both signals into one vector
> sig <- sigup + sigdn
>
> # Calculate Close-to-Close returns
> ret <- ROC(Cl(KO))
> ret[1] <- 0
>
> # Calculate equity curves
> eq_up <- cumprod(1+ret*sigup)
> eq_dn <- cumprod(1+ret*sigdn*-1)
> eq_all <- cumprod(1+ret*sig)
>
> # Replicate Michael's nice chart
> plot.zoo( cbind(eq_up, eq_dn),
> ylab=c("Long","Short"), col=c("green","red"),
> main="Simple Pair Trading Strategy")
> # Wait a few seconds before making next chart...
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From cmdr_rogue at hotmail.com  Sun May 29 13:47:43 2011
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Sun, 29 May 2011 07:47:43 -0400
Subject: [R-SIG-Finance] Volatility Models?
In-Reply-To: <BANLkTimnMT4FYST+15Wss+Bk-h3Et=+RuA@mail.gmail.com>
References: <BANLkTimnMT4FYST+15Wss+Bk-h3Et=+RuA@mail.gmail.com>
Message-ID: <BLU0-SMTP168440BB42A207BA265C1D3E2780@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110529/f7ffb3f0/attachment.pl>

From gsee000 at gmail.com  Sun May 29 17:26:49 2011
From: gsee000 at gmail.com (G See)
Date: Sun, 29 May 2011 10:26:49 -0500
Subject: [R-SIG-Finance] How to test pairs trading strategy
In-Reply-To: <BANLkTinEO+EaA2Erua5hkm8kUErrc4a8_A@mail.gmail.com>
References: <BANLkTiksZ8-Xu6zXPWJApE4G4Y49eDxocw@mail.gmail.com>
	<BANLkTinEO+EaA2Erua5hkm8kUErrc4a8_A@mail.gmail.com>
Message-ID: <BANLkTin26-iJRE8Sta4Ug3rdijcKA_enWg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110529/9c999628/attachment.pl>

From josh.m.ulrich at gmail.com  Mon May 30 05:01:42 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 29 May 2011 22:01:42 -0500
Subject: [R-SIG-Finance] getSymbols.yahoo 'adjusting' to NA
In-Reply-To: <BANLkTimYw3hsbBTnKcEMBx19ReYykxM-Ng@mail.gmail.com>
References: <BANLkTinJUkHQYFoJBcoeiGn2TEhQaQF-CA@mail.gmail.com>
	<BANLkTimsiWWLntcwL6rM-hRQmR45p-DcOQ@mail.gmail.com>
	<BANLkTi=cd46Ru1hiywsKoG8vefenQpt9Sg@mail.gmail.com>
	<BANLkTinPwGLRQmXN3O4EtKdG=9TAUm-i4Q@mail.gmail.com>
	<BANLkTimYw3hsbBTnKcEMBx19ReYykxM-Ng@mail.gmail.com>
Message-ID: <BANLkTiksKar8nF6AYiA6dSuzM-E5B_macQ@mail.gmail.com>

Garrett,

My attempt to patch this a couple weeks ago uncovered some other
issues (via R CMD check) that I wanted to resolve before responding.
As of revision 111 on R-forge, adjRatios() ignores split/dividend data
that do not have corresponding close prices.

Sorry for the delay.

Best,
--
Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com



On Mon, May 16, 2011 at 10:43 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> Hi Garrett,
>
> On Sun, May 15, 2011 at 4:33 PM, G See <gsee000 at gmail.com> wrote:
>> Sorry. I see what you mean. adjustOHLC calls getDividends() without 'to'
>> # Try to do, "by hand," the same thing
>> # that getSymbols.yahoo does
>> getSymbols('SPY', to='2010-01-01')
>> div <- getDividends('SPY')
>> spl <- getSplits('SPY')
>> adj <- na.omit(adjRatios(spl, div, Cl(SPY)))
>> #head(adj); tail(adj)
>> fr <- SPY
>> fr[,1] <- fr[,1] * adj[, "Split"] * adj[, "Div"]
>> ###End code
>> Now it hangs here
>> Thanks for looking into this.
>>
> I consider this a bug in TTR::adjRatios. ?It should discard any
> split/dividend data that lie outside the range of the close data. ?I
> will patch tonight.
>
> This issue manifests in adjustOHLC because all historical
> split/dividend data for "x" is pulled, not just historical data up to
> the last date in "x". ?Perhaps adjustOHLC should use a "to=" argument
> for getDividends and getSymbols as well...
>
> Thanks for the report!
>
> Best,
> --
> Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com
>
>
>
>> On Sun, May 15, 2011 at 4:13 PM, G See <gsee000 at gmail.com> wrote:
>>>
>>>> Because you included the 'to' argument in your call to getDividends
>>>> and getSplits; and it's not included in those calls within
>>>> getSymbols.yahoo. ?I'll take a closer look at this...
>>>>
>>>
>>> I think it is worth mentioning that getSymbols.yahoo does, in fact, use
>>> the 'to' argument to call getDividends and getSplits and is at least one
>>> reason you get big differences in yahoo's Adjusted price and the Close price
>>> after you adjust using either?adjustOHLC(), or?getSymbols() with
>>> adjust=TRUE.
>>>
>>>>
>>>> Best,
>>>> --
>>>> Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com
>>>>
>>>
>>> Garrett
>>
>


From thomas.browne at mac.com  Mon May 30 19:07:55 2011
From: thomas.browne at mac.com (Thomas Browne)
Date: Mon, 30 May 2011 18:07:55 +0100
Subject: [R-SIG-Finance] Curve fitting the South African yield curve
In-Reply-To: <BANLkTinyCEwzZxJSFr6ozkstvcuRAsd_9g@mail.gmail.com>
References: <FBC39A66-CA97-46D3-8F59-0AA1E4C3AB38@mac.com>
	<BANLkTinyCEwzZxJSFr6ozkstvcuRAsd_9g@mail.gmail.com>
Message-ID: <9724EEE8-7EB7-4255-AE65-0AEDF425C6E4@mac.com>

Thanks very much for this. And what would you suggest I use to obtain  
the zero curve from the coupon curve (for the inputs to Nelson Siegel)?

South African bonds are quoated semi-annual Act/365.



On 29 May 2011, at 03:18, Joshua Ulrich wrote:

> Hi Tom,
>
> On Sat, May 28, 2011 at 4:43 AM, Thomas Browne  
> <thomas.browne at mac.com> wrote:
>> Hi,
>>
>> I am looking to do historic cheap/dear analysis on the South African
>> bond and IRS yield curves. What I'd like to do is fit a curve each  
>> day
>> and see what the historic deviation from that fitted curve each bond
>> has exhibited. The curve I guess should not be a cubic spline type
>> since that would go through all the bonds). I want a fairly simple
>> model because to start with and I've heard of Nelson-Siegel. How  
>> would
>> I go about doing this using R? Is there a library which could help?
>>
> A search for "Nelson Siegel" on www.rseek.org returned 3 packages on
> the first page.
> 1) YieldCurve
> 2) fBonds
> 3) termstruc
>
> I've used YieldCurve.  I've never used fBonds.  I looked at termstruc
> but I needed to modify some of the functions and it was easier to
> understand the YieldCurve code (it's very simple and straight
> forward).
>
>> As I'm just starting out I don't really want to have to bootstrap the
>> zero curve first (too much work! Unless there's help in R for that
>> too!). I'd just like to fit a fairly simple curve which makes sense  
>> to
>> the YTM versus Mduration (or PV01) scatterplot.
>>
>> Thanks for any help.
>>
>> Tom
>>
>
> Hope that helps,
> --
> Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From emmanuel.senyo at gmail.com  Mon May 30 19:27:44 2011
From: emmanuel.senyo at gmail.com (Emmanuel Senyo)
Date: Mon, 30 May 2011 19:27:44 +0200
Subject: [R-SIG-Finance] xts
Message-ID: <BANLkTimt0dBfLbRA2m=EarNWjG+Zm48v2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110530/64381f46/attachment.pl>

From jeffrey.ryan at lemnica.com  Mon May 30 19:33:50 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Mon, 30 May 2011 12:33:50 -0500
Subject: [R-SIG-Finance] xts
In-Reply-To: <BANLkTimt0dBfLbRA2m=EarNWjG+Zm48v2w@mail.gmail.com>
References: <BANLkTimt0dBfLbRA2m=EarNWjG+Zm48v2w@mail.gmail.com>
Message-ID: <BANLkTim2bRx9_hVzc9EtOJr3kKtbfHb7pA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110530/1366c229/attachment.pl>

From josh.m.ulrich at gmail.com  Mon May 30 19:34:25 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 30 May 2011 12:34:25 -0500
Subject: [R-SIG-Finance] xts
In-Reply-To: <BANLkTimt0dBfLbRA2m=EarNWjG+Zm48v2w@mail.gmail.com>
References: <BANLkTimt0dBfLbRA2m=EarNWjG+Zm48v2w@mail.gmail.com>
Message-ID: <BANLkTinD0SfMcheP6T4kPk3CuMxdgYdOcw@mail.gmail.com>

Hi Emmanuel,

On Mon, May 30, 2011 at 12:27 PM, Emmanuel Senyo
<emmanuel.senyo at gmail.com> wrote:
> Dear All,
> I am creating an xts object for a univariate time series data , EXX.dm but
> it does not work. The data starts from 01/01/2008 to 09/05/2011 and I use
> 01/01/1970 as the base year. Below is my code.
> library(PerformanceAnalytics)
> library(xts)
> b<-as.xts(EXX.dm, order.by=as.Date(13880:15104), origin=1970-01-01)
> C<-VaR(b, p=0.5,method = c("historical"),portfolio_method =
> c("single"),weights = NULL, mu = NULL, sigma = NULL,
> ? ?m3 = NULL, m4 = NULL, invert = TRUE))
>
> I got the following error message:
> Error in xts(x, order.by = order.by, frequency = frequency, ...) :
> ?NROW(x) must match length(order.by)

Please provide a minimal, reproducible example.  We need to know the
exact structure of EXX.dm and exactly where the error occurs.

> I am new to R and need an assistance.
> Regards
> Emma
>
>

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From jeffrey.ryan at lemnica.com  Mon May 30 22:11:06 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Mon, 30 May 2011 15:11:06 -0500
Subject: [R-SIG-Finance] xts
In-Reply-To: <BANLkTinBWHnfeH5Hwh7NujX=JR62PdHtnA@mail.gmail.com>
References: <BANLkTimt0dBfLbRA2m=EarNWjG+Zm48v2w@mail.gmail.com>
	<BANLkTim2bRx9_hVzc9EtOJr3kKtbfHb7pA@mail.gmail.com>
	<BANLkTinBWHnfeH5Hwh7NujX=JR62PdHtnA@mail.gmail.com>
Message-ID: <BANLkTinNoKJF2=mih6JZBLPaCSCO4KyRZw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110530/37378440/attachment.pl>

From cmdr_rogue at hotmail.com  Mon May 30 22:17:09 2011
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Mon, 30 May 2011 16:17:09 -0400
Subject: [R-SIG-Finance] A question on Hull
In-Reply-To: <BANLkTimvWVPQKPmgTk2t5xqFoq50DVU9Zw@mail.gmail.com>
References: <BANLkTimvWVPQKPmgTk2t5xqFoq50DVU9Zw@mail.gmail.com>
Message-ID: <BLU0-SMTP199C7E6ADDB28D594A5FB87E27B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110530/da51971c/attachment.pl>

From jeffrey.ryan at lemnica.com  Mon May 30 22:17:29 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Mon, 30 May 2011 15:17:29 -0500
Subject: [R-SIG-Finance] xts
In-Reply-To: <BANLkTinNoKJF2=mih6JZBLPaCSCO4KyRZw@mail.gmail.com>
References: <BANLkTimt0dBfLbRA2m=EarNWjG+Zm48v2w@mail.gmail.com>
	<BANLkTim2bRx9_hVzc9EtOJr3kKtbfHb7pA@mail.gmail.com>
	<BANLkTinBWHnfeH5Hwh7NujX=JR62PdHtnA@mail.gmail.com>
	<BANLkTinNoKJF2=mih6JZBLPaCSCO4KyRZw@mail.gmail.com>
Message-ID: <BANLkTin-4G61y+VhLQXpcE8rg3qGf15WwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110530/5fba1ab9/attachment.pl>

From singhalblr at gmail.com  Tue May 31 11:00:53 2011
From: singhalblr at gmail.com (Harsh)
Date: Tue, 31 May 2011 14:30:53 +0530
Subject: [R-SIG-Finance] New to Quantitative Modeling (Looking for starting
	resources/suggestions)
Message-ID: <BANLkTin7Bf2Q4uq=0fQ43hGdGrfC1uzzTQ@mail.gmail.com>

Hi R Finance Users,
At the outset, please pardon my vague query to this list.

I have a few years of experience in the Predictive Modeling space
having primarily worked in the Business applications industry (Market
Mix Modeling, Customer Profiling and the like).
I would like to get involved with quantitative modeling for equity and
derivatives (target market would be the National Stock Exchange (NSE)
in India)

Are there introductory resources that would allow me to get started in
a small way and work my way towards the more complex ideas ? I
primarily use R and what I want to do is to get familiar with the
jargon (betas, alphas and such) of quantitative modeling for the stock
market.
My intention is to model daily data and make predictions on which I
can trade for profit (but of course!).

If this question has been asked before, then I apologize for re-posting.

Looking forward to your response.
Regards,
Harsh Singhal
Bangalore, India


From cmdr_rogue at hotmail.com  Tue May 31 11:43:38 2011
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Tue, 31 May 2011 05:43:38 -0400
Subject: [R-SIG-Finance] New to Quantitative Modeling (Looking for
 starting resources/suggestions)
In-Reply-To: <BANLkTin7Bf2Q4uq=0fQ43hGdGrfC1uzzTQ@mail.gmail.com>
References: <BANLkTin7Bf2Q4uq=0fQ43hGdGrfC1uzzTQ@mail.gmail.com>
Message-ID: <BLU0-SMTP98BCC82BBAAF8857F677F0E27A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110531/dcbe55bb/attachment.pl>

From singhalblr at gmail.com  Tue May 31 11:58:38 2011
From: singhalblr at gmail.com (Harsh)
Date: Tue, 31 May 2011 15:28:38 +0530
Subject: [R-SIG-Finance] New to Quantitative Modeling (Looking for
 starting resources/suggestions)
In-Reply-To: <BLU0-SMTP98BCC82BBAAF8857F677F0E27A0@phx.gbl>
References: <BANLkTin7Bf2Q4uq=0fQ43hGdGrfC1uzzTQ@mail.gmail.com>
	<BLU0-SMTP98BCC82BBAAF8857F677F0E27A0@phx.gbl>
Message-ID: <BANLkTimfTk=JDdg2t8ZUgLU=5dfGkFGnUg@mail.gmail.com>

Hi Sarbo,
Thank you for your prompt response. Really appreciate it.

I had earlier looked at Tsay's book on Financial Time Series Analysis
http://faculty.chicagobooth.edu/ruey.tsay/teaching/
but found it a bit heavy on math than I wanted at that time.

My very near-term requirement is to create simplistic models that
would allow me to generate buy/sell signals which I could leverage to
take a market position. I understand I cannot (and should not) be
asking for trading strategies but are there ways to develop some
'intuitions' that could allow me to hypothesize and test trading
strategies? Some mental navigational aides ?

Regards,
Harsh

On Tue, May 31, 2011 at 3:13 PM, Sarbo <cmdr_rogue at hotmail.com> wrote:
> Harsh,
>
> The best introductory resource I know of is Hull's book, Options, Futures, &
> Other Derivatives. Other very good volumes exist for specialised
> applications- Fabozzi's book is indispensable for fixed income markets, for
> instance, while Wilmott's 3-volume set contains pretty much everything you
> need to know about equities and fixed income, and other things besides.
>
> On Tue, 2011-05-31 at 14:30 +0530, Harsh wrote:
>
> Hi R Finance Users,
> At the outset, please pardon my vague query to this list.
>
> I have a few years of experience in the Predictive Modeling space
> having primarily worked in the Business applications industry (Market
> Mix Modeling, Customer Profiling and the like).
> I would like to get involved with quantitative modeling for equity and
> derivatives (target market would be the National Stock Exchange (NSE)
> in India)
>
> Are there introductory resources that would allow me to get started in
> a small way and work my way towards the more complex ideas ? I
> primarily use R and what I want to do is to get familiar with the
> jargon (betas, alphas and such) of quantitative modeling for the stock
> market.
> My intention is to model daily data and make predictions on which I
> can trade for profit (but of course!).
>
> If this question has been asked before, then I apologize for re-posting.
>
> Looking forward to your response.
> Regards,
> Harsh Singhal
> Bangalore, India
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
>
>


From massimo.salese at gmail.com  Tue May 31 12:18:03 2011
From: massimo.salese at gmail.com (msalese)
Date: Tue, 31 May 2011 03:18:03 -0700 (PDT)
Subject: [R-SIG-Finance] New to Quantitative Modeling (Looking for
 starting resources/suggestions)
In-Reply-To: <BANLkTimfTk=JDdg2t8ZUgLU=5dfGkFGnUg@mail.gmail.com>
References: <BANLkTin7Bf2Q4uq=0fQ43hGdGrfC1uzzTQ@mail.gmail.com>
	<BLU0-SMTP98BCC82BBAAF8857F677F0E27A0@phx.gbl>
	<BANLkTimfTk=JDdg2t8ZUgLU=5dfGkFGnUg@mail.gmail.com>
Message-ID: <1306837083321-3562721.post@n4.nabble.com>

May be this books can help you:

Statistics and Data Analysis for Financial Engineering (Springer Texts in
Statistics)
David Ruppert 

Option Pricing and Estimation of Financial Models with R 
Stefano M. Iacus

Financial Risk Forecasting: The Theory and Practice of Forecasting Market
Risk with Implementation in R and Matlab (The Wiley Finance Series) 
Jon Danielsson  

Time Series: Applications to Finance with R and S-Plus(R) (Wiley Series in
Probability and Statistics) 
Ngai Hang Chan 

All of that are with R code samples, but the last one teaches you how to
test a pair trading strategy (built with coitegration)

--
View this message in context: http://r.789695.n4.nabble.com/New-to-Quantitative-Modeling-Looking-for-starting-resources-suggestions-tp3562593p3562721.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From bogaso.christofer at gmail.com  Tue May 31 12:20:35 2011
From: bogaso.christofer at gmail.com (Bogaso)
Date: Tue, 31 May 2011 03:20:35 -0700 (PDT)
Subject: [R-SIG-Finance] New to Quantitative Modeling (Looking for
 starting resources/suggestions)
In-Reply-To: <BLU0-SMTP98BCC82BBAAF8857F677F0E27A0@phx.gbl>
References: <BANLkTin7Bf2Q4uq=0fQ43hGdGrfC1uzzTQ@mail.gmail.com>
	<BLU0-SMTP98BCC82BBAAF8857F677F0E27A0@phx.gbl>
Message-ID: <1306837235167-3562727.post@n4.nabble.com>

I dont agree with Sarbo in saying Hull is any 'introductory book!' This book
is quite advanced and very thorough. However what I would say with that is,
the information flow in this book in really fantastic and the way of
explanation and lot of numerical examples make this book and advanced topics
very very readable.

Because it is very readable (at least compared to other related), many
people term it as Introductory!

Thanks, and regards,

--
View this message in context: http://r.789695.n4.nabble.com/New-to-Quantitative-Modeling-Looking-for-starting-resources-suggestions-tp3562593p3562727.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From 20977 at gaffa.net  Wed Jun  1 03:26:44 2011
From: 20977 at gaffa.net (Kostas Evangelinos)
Date: Tue, 31 May 2011 21:26:44 -0400
Subject: [R-SIG-Finance] New to Quantitative Modeling (Looking for
 starting resources/suggestions)
In-Reply-To: <BANLkTin7Bf2Q4uq=0fQ43hGdGrfC1uzzTQ@mail.gmail.com>
References: <BANLkTin7Bf2Q4uq=0fQ43hGdGrfC1uzzTQ@mail.gmail.com>
Message-ID: <20110601012644.GA8234@sanchez.localnet>

Hi Harsh,

On Tue, May 31, 2011 at 02:30:53PM +0530, Harsh wrote:
| Are there introductory resources that would allow me to get started in
| a small way and work my way towards the more complex ideas ? I
| primarily use R and what I want to do is to get familiar with the
| jargon (betas, alphas and such) of quantitative modeling for the stock
| market.
| My intention is to model daily data and make predictions on which I
| can trade for profit (but of course!).

In regards to getting acquainted with the jargon, I'd suggest taking a
look at online syllabi from various academic institutions as a starting
point. For example, NTU-SGX:

http://www.ntusgxcfe.ntu.edu.sg/images/Algorithmic%20Trading%20Course%20Module%201%20Brochure.pdf
http://www.ntusgxcfe.ntu.edu.sg/NTUSGXedm/may2011/Algorithmic%20Trading%20Course%20Module%202%20brochure.pdf

Assuming you'd want to follow a hands on approach to start with, you can
take a look at say Mebane Faber's Tactical Asset Allocation:
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=962461

There's a clear implementation of this strategy on Joshua's blog:
http://blog.fosstrading.com/2009/11/tactical-asset-allocation-using-blotter.html

And more generally, using R and quantmod/xts/PerformanceAnalytics:
http://blog.fosstrading.com/2011/03/how-to-backtest-strategy-in-r.html

Finally, NSE have wonderfully archived end of day data here:
http://www.nse-india.com/archives/archives.htm

best,
Kostas


From dengyishuo at 163.com  Wed Jun  1 09:07:50 2011
From: dengyishuo at 163.com (=?UTF-8?B?6YKT5LiA56GV?=)
Date: Wed, 1 Jun 2011 15:07:50 +0800 (CST)
Subject: [R-SIG-Finance] rolling regression estimate std. error / t value
In-Reply-To: <BANLkTin8jFyL-0-Y9r9g+R+MD+nM1=PfGA@mail.gmail.com>
References: <BANLkTin8jFyL-0-Y9r9g+R+MD+nM1=PfGA@mail.gmail.com>
Message-ID: <10db872.5ac6.1304a079ccb.Coremail.dengyishuo@163.com>

??????Lu?Fan, r-sig-finance
At 2011-05-18 02:41:03?"Lu Fan" <lfanff at gmail.com> wrote:
>Dear all,
>
>The following codes is for a multi-factor rolling regression with rolling
>window = 60:
>
>> z<-read.table("C:/.../dataset.txt")
>> library(zoo)
>> mydata=zoo(z)
>> coef=rollapply(mydata,width=60,function(x) coef(lm(y~f1+f2+f3+f4+f5,
>data=as.data.frame(x))),by.column=FALSE,align="right")
>
>The result is shown below:
>
>     (Intercept)          f1          f2           f3          f4         f5
>60    2.61433094  0.16136881 -0.72852878  -1.62169901 -28.7663294 -1.0079586
>61    2.36795263  0.14779184 -0.72893841  -1.42712190 -28.9783777 -1.0877425
>62    1.80016092  0.13134766 -0.75010570  -0.92525342 -27.2138634 -1.0736837
>63    1.76904728  0.05141441 -0.94569512  -0.34299478 -19.7857978 -0.6615184
>64    2.29169442  0.13725741 -0.65519163  -1.44045686 -24.1101822 -0.8517188
>65    2.19904020  0.16520775 -0.58812883  -1.52981468 -24.9350513 -0.9234610
>66    1.84645778  0.23440231 -0.54350214  -1.42709733 -21.7792819 -0.8785267
>67    1.60558115  0.30913187 -0.25909438  -1.82122203 -21.1839368 -0.8866916
>68    1.49679459  0.31441766 -0.40952404  -1.52307138 -18.5434502 -1.0317272
>69    2.02789774  0.20500137 -0.65737973  -1.34524065 -17.1654126 -0.8685087
>70    2.11604869  0.09416856 -0.93294824  -0.74672358 -16.8795155 -0.8370804
>71    1.73134487 -0.01723606 -1.41291550   0.53813772 -15.0169149 -0.9722847
>
>So these are the regression coefficients; my question is how can I get
>estimate std. error or t-value for these coefficients on a rolling basis?
>Can I also add multicollinearity testing in this code?
>
>Thank you in advance!
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-SIG-Finance at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>-- Subscriber-posting only. If you want to post, subscribe first.
>-- Also note that this is not the r-help list where general R questions should go.


From singhalblr at gmail.com  Wed Jun  1 12:04:58 2011
From: singhalblr at gmail.com (Harsh)
Date: Wed, 1 Jun 2011 15:34:58 +0530
Subject: [R-SIG-Finance] New to Quantitative Modeling (Looking for
 starting resources/suggestions)
In-Reply-To: <20110601012644.GA8234@sanchez.localnet>
References: <BANLkTin7Bf2Q4uq=0fQ43hGdGrfC1uzzTQ@mail.gmail.com>
	<20110601012644.GA8234@sanchez.localnet>
Message-ID: <BANLkTikDC8WNFfvEuz+J9Xyg1mTwug=XBw@mail.gmail.com>

Thank you Kostas for the great links.

On Wed, Jun 1, 2011 at 6:56 AM, Kostas Evangelinos <20977 at gaffa.net> wrote:
> Hi Harsh,
>
> On Tue, May 31, 2011 at 02:30:53PM +0530, Harsh wrote:
> | Are there introductory resources that would allow me to get started in
> | a small way and work my way towards the more complex ideas ? I
> | primarily use R and what I want to do is to get familiar with the
> | jargon (betas, alphas and such) of quantitative modeling for the stock
> | market.
> | My intention is to model daily data and make predictions on which I
> | can trade for profit (but of course!).
>
> In regards to getting acquainted with the jargon, I'd suggest taking a
> look at online syllabi from various academic institutions as a starting
> point. For example, NTU-SGX:
>
> http://www.ntusgxcfe.ntu.edu.sg/images/Algorithmic%20Trading%20Course%20Module%201%20Brochure.pdf
> http://www.ntusgxcfe.ntu.edu.sg/NTUSGXedm/may2011/Algorithmic%20Trading%20Course%20Module%202%20brochure.pdf
>
> Assuming you'd want to follow a hands on approach to start with, you can
> take a look at say Mebane Faber's Tactical Asset Allocation:
> http://papers.ssrn.com/sol3/papers.cfm?abstract_id=962461
>
> There's a clear implementation of this strategy on Joshua's blog:
> http://blog.fosstrading.com/2009/11/tactical-asset-allocation-using-blotter.html
>
> And more generally, using R and quantmod/xts/PerformanceAnalytics:
> http://blog.fosstrading.com/2011/03/how-to-backtest-strategy-in-r.html
>
> Finally, NSE have wonderfully archived end of day data here:
> http://www.nse-india.com/archives/archives.htm
>
> best,
> Kostas
>



-- 
http://about.me/harshsinghal


From emmanuel.senyo at gmail.com  Wed Jun  1 15:54:59 2011
From: emmanuel.senyo at gmail.com (Emmanuel Senyo)
Date: Wed, 1 Jun 2011 15:54:59 +0200
Subject: [R-SIG-Finance] xts
In-Reply-To: <BANLkTinD0SfMcheP6T4kPk3CuMxdgYdOcw@mail.gmail.com>
References: <BANLkTimt0dBfLbRA2m=EarNWjG+Zm48v2w@mail.gmail.com>
	<BANLkTinD0SfMcheP6T4kPk3CuMxdgYdOcw@mail.gmail.com>
Message-ID: <BANLkTi==PR8uiBzp=yBtXjBXkzMfE0wtrQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110601/e2d80360/attachment.pl>

From josh.m.ulrich at gmail.com  Wed Jun  1 16:08:29 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 1 Jun 2011 09:08:29 -0500
Subject: [R-SIG-Finance] xts
In-Reply-To: <BANLkTi==PR8uiBzp=yBtXjBXkzMfE0wtrQ@mail.gmail.com>
References: <BANLkTimt0dBfLbRA2m=EarNWjG+Zm48v2w@mail.gmail.com>
	<BANLkTinD0SfMcheP6T4kPk3CuMxdgYdOcw@mail.gmail.com>
	<BANLkTi==PR8uiBzp=yBtXjBXkzMfE0wtrQ@mail.gmail.com>
Message-ID: <BANLkTi=MA2f7uHnMEUSWhohiJ8a+YSU-eg@mail.gmail.com>

Emmanuel,

This does not help.  Jeff asked for the output from dput() and he
asked you *not* to send 600+ lines.  We also asked for a reproducible
example, which you still have not provided.  Give us code that we can
copy from your email to our R session that will show us the error,
then we will be able to help you.

For example:
EXX.dm <- structure(c(25.13083, 58.50875, 54.98292, 55.98917, 68.47125,
68.13833, 61.83625, 66.03333, 64.29583, 66.32458), class = c("xts",
"zoo"), .indexCLASS = "Date", .indexTZ = "", index = structure(c(1199167200,
1199253600, 1199340000, 1199426400, 1199685600, 1199772000, 1199858400,
1199944800, 1200031200, 1200290400), tzone = "", tclass = "Date"),
.Dim = c(10L,
1L))

We are all extremely busy, so you need to make it as easy as possible
for us if you want our help for free.

Best,
--
Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com


On Wed, Jun 1, 2011 at 8:54 AM, Emmanuel Senyo <emmanuel.senyo at gmail.com> wrote:
>
> Dear Jeffrey,
> Sorry if you misunderstood what I posted, I guess it was it quite clear.
> Find below the structure of EXX.dm I hope this help.

<snip>

>
> On Mon, May 30, 2011 at 7:34 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>>
>> Hi Emmanuel,
>>
>> On Mon, May 30, 2011 at 12:27 PM, Emmanuel Senyo
>> <emmanuel.senyo at gmail.com> wrote:
>> > Dear All,
>> > I am creating an xts object for a univariate time series data , EXX.dm but
>> > it does not work. The data starts from 01/01/2008 to 09/05/2011 and I use
>> > 01/01/1970 as the base year. Below is my code.
>> > library(PerformanceAnalytics)
>> > library(xts)
>> > b<-as.xts(EXX.dm, order.by=as.Date(13880:15104), origin=1970-01-01)
>> > C<-VaR(b, p=0.5,method = c("historical"),portfolio_method =
>> > c("single"),weights = NULL, mu = NULL, sigma = NULL,
>> > ? ?m3 = NULL, m4 = NULL, invert = TRUE))
>> >
>> > I got the following error message:
>> > Error in xts(x, order.by = order.by, frequency = frequency, ...) :
>> > ?NROW(x) must match length(order.by)
>>
>> Please provide a minimal, reproducible example. ?We need to know the
>> exact structure of EXX.dm and exactly where the error occurs.
>>
>> > I am new to R and need an assistance.
>> > Regards
>> > Emma
>> >
>> >
>>
>> Best,
>> --
>> Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com
>


From emmanuel.senyo at gmail.com  Fri Jun  3 11:23:16 2011
From: emmanuel.senyo at gmail.com (Emmanuel Senyo)
Date: Fri, 3 Jun 2011 11:23:16 +0200
Subject: [R-SIG-Finance] rgarch package
Message-ID: <BANLkTikOHr3ahWAAzy6sLKz3xkdDuo-6Pg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110603/21ca562f/attachment.pl>

From johannes.lips at googlemail.com  Fri Jun  3 11:26:44 2011
From: johannes.lips at googlemail.com (Johannes Lips)
Date: Fri, 03 Jun 2011 11:26:44 +0200
Subject: [R-SIG-Finance] rgarch package
In-Reply-To: <BANLkTikOHr3ahWAAzy6sLKz3xkdDuo-6Pg@mail.gmail.com>
References: <BANLkTikOHr3ahWAAzy6sLKz3xkdDuo-6Pg@mail.gmail.com>
Message-ID: <4DE8A8D4.7080909@googlemail.com>

Hi,

you could download it from there:
https://r-forge.r-project.org/R/?group_id=339
Choose the package which fits your OS and just install it from the 
download directory.

johannes

On 06/03/2011 11:23 AM, Emmanuel Senyo wrote:
> Dear all,
> I would like to use the "rgarch package" but finding it difficult to get it
> to download. It is not in the list of packages.
> Thanks
> Emmanuel
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From emmanuel.senyo at gmail.com  Fri Jun  3 12:15:33 2011
From: emmanuel.senyo at gmail.com (Emmanuel Senyo)
Date: Fri, 3 Jun 2011 12:15:33 +0200
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 85, Issue 3
In-Reply-To: <mailman.3.1307095202.23516.r-sig-finance@r-project.org>
References: <mailman.3.1307095202.23516.r-sig-finance@r-project.org>
Message-ID: <BANLkTikcyiJfaXqHShdiEsLsDwWKjDc3Wg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110603/38390800/attachment.pl>

From brian at braverock.com  Fri Jun  3 12:47:16 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 03 Jun 2011 05:47:16 -0500
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 85, Issue 3
In-Reply-To: <BANLkTikcyiJfaXqHShdiEsLsDwWKjDc3Wg@mail.gmail.com>
References: <mailman.3.1307095202.23516.r-sig-finance@r-project.org>
	<BANLkTikcyiJfaXqHShdiEsLsDwWKjDc3Wg@mail.gmail.com>
Message-ID: <1307098036.27623.12621.camel@brian-desktop>

It looks as though the Windows build host for R-Forge is having issues,
as there are no packages in the 'latest' dir for Windows, and the last
date is June 1.

I suggest that you consider installing the Rtools code, and then
building the package from the source .tar.gz tarball.

Regards,

   - Brian

On Fri, 2011-06-03 at 12:15 +0200, Emmanuel Senyo wrote:
> Dear Johannes,
> Please, find below what I did and the output unedited.
> 
> > install.packages("rgarch", repos="http://R-Forge.R-project.org")
> Installing package(s) into C:\Users\Emmanuel\Documents/R/win-library/2.13
> (as lib is unspecified)
> Warning: unable to access index for repository
> http://R-Forge.R-project.org/bin/windows/contrib/2.13
> Warning message:
> In getDependencies(pkgs, dependencies, available, lib) :
>   package rgarch is not available *(for R version 2.13.0 alpha)*
> 
> Thanks
> Emm
> >
> 
> On Fri, Jun 3, 2011 at 12:00 PM, <r-sig-finance-request at r-project.org>wrote:
> 
> > Send R-SIG-Finance mailing list submissions to
> >        r-sig-finance at r-project.org
> >
> > To subscribe or unsubscribe via the World Wide Web, visit
> >        https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > or, via email, send a message with subject or body 'help' to
> >        r-sig-finance-request at r-project.org
> >
> > You can reach the person managing the list at
> >        r-sig-finance-owner at r-project.org
> >
> > When replying, please edit your Subject line so it is more specific
> > than "Re: Contents of R-SIG-Finance digest..."
> >
> >
> > Today's Topics:
> >
> >   1. rgarch package (Emmanuel Senyo)
> >   2. Re: rgarch package (Johannes Lips)
> >
> >
> > ----------------------------------------------------------------------
> >
> > Message: 1
> > Date: Fri, 3 Jun 2011 11:23:16 +0200
> > From: Emmanuel Senyo <emmanuel.senyo at gmail.com>
> > To: r-sig-finance at r-project.org
> > Subject: [R-SIG-Finance] rgarch package
> > Message-ID: <BANLkTikOHr3ahWAAzy6sLKz3xkdDuo-6Pg at mail.gmail.com>
> > Content-Type: text/plain
> >
> > Dear all,
> > I would like to use the "rgarch package" but finding it difficult to get it
> > to download. It is not in the list of packages.
> > Thanks
> > Emmanuel
> >
> >        [[alternative HTML version deleted]]
> >
> >
> >
> > ------------------------------
> >
> > Message: 2
> > Date: Fri, 03 Jun 2011 11:26:44 +0200
> > From: Johannes Lips <johannes.lips at googlemail.com>
> > To: r-sig-finance at r-project.org
> > Subject: Re: [R-SIG-Finance] rgarch package
> > Message-ID: <4DE8A8D4.7080909 at googlemail.com>
> > Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> >
> > Hi,
> >
> > you could download it from there:
> > https://r-forge.r-project.org/R/?group_id=339
> > Choose the package which fits your OS and just install it from the
> > download directory.
> >
> > johannes
> >
> > On 06/03/2011 11:23 AM, Emmanuel Senyo wrote:
> > > Dear all,
> > > I would like to use the "rgarch package" but finding it difficult to get
> > it
> > > to download. It is not in the list of packages.
> > > Thanks
> > > Emmanuel
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-SIG-Finance at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > > -- Subscriber-posting only. If you want to post, subscribe first.
> > > -- Also note that this is not the r-help list where general R questions
> > should go.
> >
> >
> >
> > ------------------------------
> >
> > _______________________________________________
> > R-SIG-Finance mailing list
> > R-SIG-Finance at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >
> >
> > End of R-SIG-Finance Digest, Vol 85, Issue 3
> > ********************************************
> >
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From rhelpacc at gmail.com  Sat Jun  4 05:46:19 2011
From: rhelpacc at gmail.com (Robert A'gata)
Date: Fri, 3 Jun 2011 23:46:19 -0400
Subject: [R-SIG-Finance] Measure quality of fit for MA(q), ARMA(p,
	q) and GARCH(p, q)
Message-ID: <BANLkTimDLZSOe-WEnRftD+itOu7TncwC5w@mail.gmail.com>

Hi,

I would like to ask for a guideline on how to assess quality of fit
for MA, ARMA and GARCH process. For AR, it still looks like a
regression for me. So I still can rely on R-square as long as the time
series itself is stationary. However, for MA, ARMA or GARCH, I do not
know what measure I should use to assess fit quality. Any suggestions
would be appreciated. Thank you.

Robert


From patrick at burns-stat.com  Sat Jun  4 09:36:49 2011
From: patrick at burns-stat.com (Patrick Burns)
Date: Sat, 04 Jun 2011 08:36:49 +0100
Subject: [R-SIG-Finance] Measure quality of fit for MA(q), ARMA(p,
 q) and GARCH(p, q)
In-Reply-To: <BANLkTimDLZSOe-WEnRftD+itOu7TncwC5w@mail.gmail.com>
References: <BANLkTimDLZSOe-WEnRftD+itOu7TncwC5w@mail.gmail.com>
Message-ID: <4DE9E091.4060108@burns-stat.com>

A common thing to do is the Ljung-Box
test on the residuals.  For garch it
would be the residuals squared.

Actually for garch it should be the
rank of the squared residuals -- see
http://www.burns-stat.com/pages/Working/ljungbox.pdf

However, this is an in-sample test.  Much
better is to do out-of-sample tests.

On 04/06/2011 04:46, Robert A'gata wrote:
> Hi,
>
> I would like to ask for a guideline on how to assess quality of fit
> for MA, ARMA and GARCH process. For AR, it still looks like a
> regression for me. So I still can rely on R-square as long as the time
> series itself is stationary. However, for MA, ARMA or GARCH, I do not
> know what measure I should use to assess fit quality. Any suggestions
> would be appreciated. Thank you.
>
> Robert
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com
http://www.portfolioprobe.com/blog
twitter: @portfolioprobe


From alexios at 4dscape.com  Sat Jun  4 10:21:40 2011
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sat, 04 Jun 2011 09:21:40 +0100
Subject: [R-SIG-Finance] Measure quality of fit for MA(q), ARMA(p,
 q) and GARCH(p, q)
In-Reply-To: <4DE9E091.4060108@burns-stat.com>
References: <BANLkTimDLZSOe-WEnRftD+itOu7TncwC5w@mail.gmail.com>
	<4DE9E091.4060108@burns-stat.com>
Message-ID: <1307175700.31362.2.camel@Metis>

For out of sample in particular you might like to look at the Predictive
Density Tests (e.g. Berkowitz), and maybe Directional Accuracy Tests
(e.g. Pesaran & Timmermann, Anatolyev & Gerko).

Best,
Alexios Ghalanos

On Sat, 2011-06-04 at 08:36 +0100, Patrick Burns wrote:
> A common thing to do is the Ljung-Box
> test on the residuals.  For garch it
> would be the residuals squared.
> 
> Actually for garch it should be the
> rank of the squared residuals -- see
> http://www.burns-stat.com/pages/Working/ljungbox.pdf
> 
> However, this is an in-sample test.  Much
> better is to do out-of-sample tests.
> 
> On 04/06/2011 04:46, Robert A'gata wrote:
> > Hi,
> >
> > I would like to ask for a guideline on how to assess quality of fit
> > for MA, ARMA and GARCH process. For AR, it still looks like a
> > regression for me. So I still can rely on R-square as long as the time
> > series itself is stationary. However, for MA, ARMA or GARCH, I do not
> > know what measure I should use to assess fit quality. Any suggestions
> > would be appreciated. Thank you.
> >
> > Robert
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions should go.
> >
>


From jeff.a.ryan at gmail.com  Sat Jun  4 11:14:05 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sat, 4 Jun 2011 04:14:05 -0500
Subject: [R-SIG-Finance] Measure quality of fit for MA(q), ARMA(p,
	q) and GARCH(p, q)
In-Reply-To: <BANLkTimDLZSOe-WEnRftD+itOu7TncwC5w@mail.gmail.com>
References: <BANLkTimDLZSOe-WEnRftD+itOu7TncwC5w@mail.gmail.com>
Message-ID: <E2D2B482-70B3-4378-B186-0D9126F84A1F@gmail.com>

Intuitively the idea is to have no structure remaining in the residuals. 

The practical has been answered by Pat and Alexios. 

Jeff

Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com

www.lemnica.com

On Jun 3, 2011, at 10:46 PM, "Robert A'gata" <rhelpacc at gmail.com> wrote:

> Hi,
> 
> I would like to ask for a guideline on how to assess quality of fit
> for MA, ARMA and GARCH process. For AR, it still looks like a
> regression for me. So I still can rely on R-square as long as the time
> series itself is stationary. However, for MA, ARMA or GARCH, I do not
> know what measure I should use to assess fit quality. Any suggestions
> would be appreciated. Thank you.
> 
> Robert
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From rhelpacc at gmail.com  Sat Jun  4 15:16:51 2011
From: rhelpacc at gmail.com (Robert A'gata)
Date: Sat, 4 Jun 2011 09:16:51 -0400
Subject: [R-SIG-Finance] Measure quality of fit for MA(q), ARMA(p,
 q) and GARCH(p, q)
In-Reply-To: <4DE9E091.4060108@burns-stat.com>
References: <BANLkTimDLZSOe-WEnRftD+itOu7TncwC5w@mail.gmail.com>
	<4DE9E091.4060108@burns-stat.com>
Message-ID: <BANLkTim-kgKzd5Vs7s6FAGQf4q4iWY4jrQ@mail.gmail.com>

Thank you so much all for your invaluable inputs.

On Sat, Jun 4, 2011 at 3:36 AM, Patrick Burns <patrick at burns-stat.com> wrote:
> A common thing to do is the Ljung-Box
> test on the residuals. ?For garch it
> would be the residuals squared.
>
> Actually for garch it should be the
> rank of the squared residuals -- see
> http://www.burns-stat.com/pages/Working/ljungbox.pdf
>
> However, this is an in-sample test. ?Much
> better is to do out-of-sample tests.
>
> On 04/06/2011 04:46, Robert A'gata wrote:
>>
>> Hi,
>>
>> I would like to ask for a guideline on how to assess quality of fit
>> for MA, ARMA and GARCH process. For AR, it still looks like a
>> regression for me. So I still can rely on R-square as long as the time
>> series itself is stationary. However, for MA, ARMA or GARCH, I do not
>> know what measure I should use to assess fit quality. Any suggestions
>> would be appreciated. Thank you.
>>
>> Robert
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
> --
> Patrick Burns
> patrick at burns-stat.com
> http://www.burns-stat.com
> http://www.portfolioprobe.com/blog
> twitter: @portfolioprobe
>


From pkaddo2000 at gmail.com  Sat Jun  4 23:47:47 2011
From: pkaddo2000 at gmail.com (Peter Addo)
Date: Sat, 4 Jun 2011 21:47:47 +0000
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 85, Issue 3
In-Reply-To: <BANLkTikcyiJfaXqHShdiEsLsDwWKjDc3Wg@mail.gmail.com>
References: <mailman.3.1307095202.23516.r-sig-finance@r-project.org>
	<BANLkTikcyiJfaXqHShdiEsLsDwWKjDc3Wg@mail.gmail.com>
Message-ID: <BANLkTin+Nu-N=D-_RMb=UOpbdeqSALa_=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110604/0829c974/attachment.pl>

From ustaudinger at gmail.com  Sun Jun  5 18:41:48 2011
From: ustaudinger at gmail.com (Ulrich Staudinger)
Date: Sun, 5 Jun 2011 18:41:48 +0200
Subject: [R-SIG-Finance] millisec timestamps for rows of xts/zoo object
Message-ID: <BANLkTi=4OzCfwSksJMp628LR0QBVXYp5Ow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110605/4a1fc567/attachment.pl>

From brian at braverock.com  Sun Jun  5 19:23:53 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 05 Jun 2011 12:23:53 -0500
Subject: [R-SIG-Finance] millisec timestamps for rows of xts/zoo object
In-Reply-To: <BANLkTi=4OzCfwSksJMp628LR0QBVXYp5Ow@mail.gmail.com>
References: <BANLkTi=4OzCfwSksJMp628LR0QBVXYp5Ow@mail.gmail.com>
Message-ID: <1307294634.27623.12665.camel@brian-desktop>

On Sun, 2011-06-05 at 18:41 +0200, Ulrich Staudinger wrote:
> I have an xts/zoo object called tempBs, which has nicely assigned the
> timestamps to each row (see below). How can I convert the row-label to
> seconds or milliseconds since the epoch beginning (or any other
> integer or double number)? 

How about just using the POSIXct mode?

options(digits.secs=6)

should do it.

see 

?POSIXct


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From ustaudinger at gmail.com  Sun Jun  5 19:41:07 2011
From: ustaudinger at gmail.com (Ulrich Staudinger)
Date: Sun, 5 Jun 2011 19:41:07 +0200
Subject: [R-SIG-Finance] millisec timestamps for rows of xts/zoo object
In-Reply-To: <1307294634.27623.12665.camel@brian-desktop>
References: <BANLkTi=4OzCfwSksJMp628LR0QBVXYp5Ow@mail.gmail.com>
	<1307294634.27623.12665.camel@brian-desktop>
Message-ID: <BANLkTinv4iYvPkLuDg0Ua91gCt=U=UWY1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110605/37fc1a3b/attachment.pl>

From edd at debian.org  Sun Jun  5 19:57:34 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 5 Jun 2011 12:57:34 -0500
Subject: [R-SIG-Finance] millisec timestamps for rows of xts/zoo object
In-Reply-To: <BANLkTinv4iYvPkLuDg0Ua91gCt=U=UWY1w@mail.gmail.com>
References: <BANLkTi=4OzCfwSksJMp628LR0QBVXYp5Ow@mail.gmail.com>
	<1307294634.27623.12665.camel@brian-desktop>
	<BANLkTinv4iYvPkLuDg0Ua91gCt=U=UWY1w@mail.gmail.com>
Message-ID: <19947.50062.553687.173087@max.nulle.part>


On 5 June 2011 at 19:41, Ulrich Staudinger wrote:
| Misunderstanding ...
| 
| rowse[1]> options(digits.secs=6)
| Browse[1]> head(tempBs)
|                         ..1   ..2 ..3 pnlSlice
| 2011-06-03 13:32:24.975 242 99125   1      -75
| 2011-06-03 13:32:55.036 242 99100  -1      -25
| 2011-06-03 13:36:10.490 242 98850  -1      -50
| 2011-06-03 13:36:59.064 242 98775   2       25
| 2011-06-03 13:38:21.795 242 98550  -2     -200
| 2011-06-03 13:40:01.725 242 98825   1     -450
| Browse[1]>
| 
| 
| that's not what I need. A bit of digging revealed:
| 
| Browse[1]> as.double(as.POSIXct("2011-06-03 13:32:24"))
| [1] 1307100744
| Browse[1]>
| 
| I would like to get the timestamp instead of a date string ...
| some matrix where the first column contains the timestamp in milliseconds
| since epoch start ...

Just use as.numeric() on your POSIXct object:

R> print( as.numeric( Sys.time() ), digits=20 )
[1] 1307296635.9376249313
R> 


Dirk

-- 
Gauss once played himself in a zero-sum game and won $50.
                      -- #11 at http://www.gaussfacts.com


From ustaudinger at gmail.com  Sun Jun  5 20:14:08 2011
From: ustaudinger at gmail.com (Ulrich Staudinger)
Date: Sun, 5 Jun 2011 20:14:08 +0200
Subject: [R-SIG-Finance] millisec timestamps for rows of xts/zoo object
In-Reply-To: <19947.50062.553687.173087@max.nulle.part>
References: <BANLkTi=4OzCfwSksJMp628LR0QBVXYp5Ow@mail.gmail.com>
	<1307294634.27623.12665.camel@brian-desktop>
	<BANLkTinv4iYvPkLuDg0Ua91gCt=U=UWY1w@mail.gmail.com>
	<19947.50062.553687.173087@max.nulle.part>
Message-ID: <BANLkTi=UoF=UpzV8OpuatCEU0VhnKSfswg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110605/e8ce1a69/attachment.pl>

From ggrothendieck at gmail.com  Sun Jun  5 20:16:48 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 5 Jun 2011 14:16:48 -0400
Subject: [R-SIG-Finance] millisec timestamps for rows of xts/zoo object
In-Reply-To: <BANLkTi=UoF=UpzV8OpuatCEU0VhnKSfswg@mail.gmail.com>
References: <BANLkTi=4OzCfwSksJMp628LR0QBVXYp5Ow@mail.gmail.com>
	<1307294634.27623.12665.camel@brian-desktop>
	<BANLkTinv4iYvPkLuDg0Ua91gCt=U=UWY1w@mail.gmail.com>
	<19947.50062.553687.173087@max.nulle.part>
	<BANLkTi=UoF=UpzV8OpuatCEU0VhnKSfswg@mail.gmail.com>
Message-ID: <BANLkTim3ux0YGYLFxUorpZ8YiN1szewMYg@mail.gmail.com>

On Sun, Jun 5, 2011 at 2:14 PM, Ulrich Staudinger <ustaudinger at gmail.com> wrote:
> Hi Dirk,
>
> but I don't have a POSIXct object, I have an xts time series object and want
> the timestamps as seconds/milliseconds with the goal to save it to a
> database ...
>

Try this assuming x is an xts object with POSIXct times:

z <- as.zoo(x)
time(z) <- as.numeric(time(z) - start(z))


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From edd at debian.org  Sun Jun  5 20:33:37 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 5 Jun 2011 13:33:37 -0500
Subject: [R-SIG-Finance] millisec timestamps for rows of xts/zoo object
In-Reply-To: <BANLkTi=UoF=UpzV8OpuatCEU0VhnKSfswg@mail.gmail.com>
References: <BANLkTi=4OzCfwSksJMp628LR0QBVXYp5Ow@mail.gmail.com>
	<1307294634.27623.12665.camel@brian-desktop>
	<BANLkTinv4iYvPkLuDg0Ua91gCt=U=UWY1w@mail.gmail.com>
	<19947.50062.553687.173087@max.nulle.part>
	<BANLkTi=UoF=UpzV8OpuatCEU0VhnKSfswg@mail.gmail.com>
Message-ID: <19947.52225.461540.252702@max.nulle.part>


On 5 June 2011 at 20:14, Ulrich Staudinger wrote:
| Hi Dirk,
| 
| but I don't have a POSIXct object, I have an xts time series object and want

Are you sure?  What does 

    class( index ( tempBs ) )

return?  And are you sure that time index for xts cannot be casted into POSIXct?

| the timestamps as seconds/milliseconds with the goal to save it to a database
| ...

Yes. POSIXct is 'just' a double with millseconds resolution which can be
passed down to C/C++, stored in a DB, etc pp with ease just because it can
reduce to a double (if you are willing to forego attributes such as local
timezones etc).

Dirk

-- 
Gauss once played himself in a zero-sum game and won $50.
                      -- #11 at http://www.gaussfacts.com


From stephen at organicfoodmarkets.com.au  Sun Jun  5 21:56:32 2011
From: stephen at organicfoodmarkets.com.au (Stephen Choularton)
Date: Mon, 06 Jun 2011 05:56:32 +1000
Subject: [R-SIG-Finance] running two reqMktData's using IBroker
Message-ID: <4DEBDF70.7060609@organicfoodmarkets.com.au>

Hi

If I am running reqMktData once at the prompt and once in the console. 
Can the data in eventWrapper be affected?

These are my two calls:



tws <- twsConnect(33)
tws


reqMktData(tws, twsContract("", "SPI", "FUT", "SNFE", "", "20110616", 
"0", "AUD", "","APM1","25",NULL,NULL,0),  eventWrapper=eWrapper.data(1), 
CALLBACK = MONITOR_SPI)





closeAllConnections()


and



tws <- twsConnect(25)
tws



reqMktData(tws, twsContract("", "SPI", "FUT", "SNFE", "", "20110616", 
"0", "AUD", "","APM1","25",NULL,NULL,0),  eventWrapper=eWrapper.data(1), 
CALLBACK = GET_DATA_FUTURE)




closeAllConnections()

I imagine that each process creates its own objects independently but is 
that right?

-- 
Stephen Choularton Ph.D., FIoD

<http://twitter.com/share>


From ustaudinger at gmail.com  Sun Jun  5 22:49:53 2011
From: ustaudinger at gmail.com (Ulrich Staudinger)
Date: Sun, 5 Jun 2011 22:49:53 +0200
Subject: [R-SIG-Finance] millisec timestamps for rows of xts/zoo object
In-Reply-To: <19947.52225.461540.252702@max.nulle.part>
References: <BANLkTi=4OzCfwSksJMp628LR0QBVXYp5Ow@mail.gmail.com>
	<1307294634.27623.12665.camel@brian-desktop>
	<BANLkTinv4iYvPkLuDg0Ua91gCt=U=UWY1w@mail.gmail.com>
	<19947.50062.553687.173087@max.nulle.part>
	<BANLkTi=UoF=UpzV8OpuatCEU0VhnKSfswg@mail.gmail.com>
	<19947.52225.461540.252702@max.nulle.part>
Message-ID: <BANLkTim2BW6zW4qWQHfEQLnPZfss_4sx_g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110605/26b25074/attachment.pl>

From bogaso.christofer at gmail.com  Tue Jun  7 21:45:29 2011
From: bogaso.christofer at gmail.com (Bogaso Christofer)
Date: Wed, 8 Jun 2011 01:15:29 +0530
Subject: [R-SIG-Finance] Need some help on zoo object
Message-ID: <00b401cc254b$77368b60$65a3a220$@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110608/daa96f24/attachment.pl>

From ggrothendieck at gmail.com  Tue Jun  7 22:00:06 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 7 Jun 2011 16:00:06 -0400
Subject: [R-SIG-Finance] Need some help on zoo object
In-Reply-To: <00b401cc254b$77368b60$65a3a220$@gmail.com>
References: <00b401cc254b$77368b60$65a3a220$@gmail.com>
Message-ID: <BANLkTi=2HtWb5YGUcCV1UjBRn2jLH=VeBA@mail.gmail.com>

On Tue, Jun 7, 2011 at 3:45 PM, Bogaso Christofer
<bogaso.christofer at gmail.com> wrote:
> Dear all, I have some problem with zoo object. So it will really be very
> helpful if somebody helps me to fix that. Here I have created a zoo object:
>
>
>
> library(zoo)
>
> MyData <- zooreg(1:20, start = as.Date("2010-02-03"))
>
>
>
> This is vector, so I want to convert it a matrix with number of columns as

Try this:

library(zoo)
z <- zooreg(matrix(1:20, nc = 1), start = as.Date("2010-02-03"))

or

MyData <- zooreg(1:20, start = as.Date("2010-02-03"))
dim(MyData) <- c(length(MyData), 1)


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From edd at debian.org  Tue Jun  7 22:14:42 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 7 Jun 2011 15:14:42 -0500
Subject: [R-SIG-Finance] millisec timestamps for rows of xts/zoo object
In-Reply-To: <BANLkTim2BW6zW4qWQHfEQLnPZfss_4sx_g@mail.gmail.com>
References: <BANLkTi=4OzCfwSksJMp628LR0QBVXYp5Ow@mail.gmail.com>
	<1307294634.27623.12665.camel@brian-desktop>
	<BANLkTinv4iYvPkLuDg0Ua91gCt=U=UWY1w@mail.gmail.com>
	<19947.50062.553687.173087@max.nulle.part>
	<BANLkTi=UoF=UpzV8OpuatCEU0VhnKSfswg@mail.gmail.com>
	<19947.52225.461540.252702@max.nulle.part>
	<BANLkTim2BW6zW4qWQHfEQLnPZfss_4sx_g@mail.gmail.com>
Message-ID: <19950.34482.718584.24419@max.nulle.part>


On 5 June 2011 at 22:49, Ulrich Staudinger wrote:
| Last question here, as.numeric(time(t)) returns seconds since 1970, but not the
| milliseconds, although I enabled it through setting the mentioned options. Any
| hint on that?

Wrong. You once again fell for displayed precision != stored precision:

Here is the example I use days ago:

   R> print( as.numeric( Sys.time() ), digits=20 )
   [1] 1307296635.9376249313
   R> 

whereas when I do it now without the digits= override:

   R> print( as.numeric( Sys.time() ) )
   [1] 1307477616
   R> 

Also:

   R> typeof( as.numeric( Sys.time() ) )
   [1] "double"
   R> 

Dirk

-- 
Gauss once played himself in a zero-sum game and won $50.
                      -- #11 at http://www.gaussfacts.com


From ustaudinger at gmail.com  Tue Jun  7 22:57:22 2011
From: ustaudinger at gmail.com (Ulrich Staudinger)
Date: Tue, 7 Jun 2011 22:57:22 +0200
Subject: [R-SIG-Finance] millisec timestamps for rows of xts/zoo object
In-Reply-To: <19950.34482.718584.24419@max.nulle.part>
References: <BANLkTi=4OzCfwSksJMp628LR0QBVXYp5Ow@mail.gmail.com>
	<1307294634.27623.12665.camel@brian-desktop>
	<BANLkTinv4iYvPkLuDg0Ua91gCt=U=UWY1w@mail.gmail.com>
	<19947.50062.553687.173087@max.nulle.part>
	<BANLkTi=UoF=UpzV8OpuatCEU0VhnKSfswg@mail.gmail.com>
	<19947.52225.461540.252702@max.nulle.part>
	<BANLkTim2BW6zW4qWQHfEQLnPZfss_4sx_g@mail.gmail.com>
	<19950.34482.718584.24419@max.nulle.part>
Message-ID: <BANLkTi=ViQOUD=Q+RJt6_iTKsdSFUiQ1Pg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110607/9663ec2a/attachment.pl>

From veepsirtt at gmail.com  Wed Jun  8 11:19:37 2011
From: veepsirtt at gmail.com (veepsirtt)
Date: Wed, 8 Jun 2011 02:19:37 -0700 (PDT)
Subject: [R-SIG-Finance] How to test pairs trading strategy
In-Reply-To: <BANLkTinEO+EaA2Erua5hkm8kUErrc4a8_A@mail.gmail.com>
References: <BANLkTiksZ8-Xu6zXPWJApE4G4Y49eDxocw@mail.gmail.com>
	<BANLkTinEO+EaA2Erua5hkm8kUErrc4a8_A@mail.gmail.com>
Message-ID: <1307524777548-3582036.post@n4.nabble.com>

Dear Daniel Cegie?ka,

  I iinstalled and run the  demo.

https://r-forge.r-project.org/scm/viewvc.php/pkg/quantstrat/demo/pair_trade.R?view=markup&revision=605&root=blotter

Now I want to change the pair trading strategy as follows.

## given 2 stocks, calculate the ratio of their notional values.  If the
ratio falls below it's
# 2 stdev band, then when it crosses back above it, buy stock 1 and sell
stock 2.
 
# If the ratio rises above it's 1 stdev band, then  flatten any open
positions.

For this condition how to modify the following lines,

# Create signals -*** BBands for 2 Stdev

pairStrat <- add.signal(strategy = pairStrat, name = "sigCrossover",
arguments= list(columns=c("Ratio","up"), relationship="lt"),
label="cross.up")
pairStrat <- add.signal(strategy = pairStrat, name = "sigCrossover",
arguments= list(columns=c("Ratio","dn"), relationship="gt"),
label="cross.dn")

# Create entry and exit rules for longs  and for shorts..****here BBands for
1 stdev

pairStrat <- add.rule(strategy = pairStrat, name='ruleSignal', arguments =
list(sigcol="cross.up", sigval=TRUE, orderqty=-1e6, ordertype='market',
orderside=NULL, osFUN='osSpreadMaxPos'), type='enter')

 How to exit ?

Thanking you
veepsirtt



--
View this message in context: http://r.789695.n4.nabble.com/How-to-test-pairs-trading-strategy-tp3558776p3582036.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From gsee000 at gmail.com  Wed Jun  8 13:46:50 2011
From: gsee000 at gmail.com (G See)
Date: Wed, 8 Jun 2011 06:46:50 -0500
Subject: [R-SIG-Finance] How to test pairs trading strategy
In-Reply-To: <1307524777548-3582036.post@n4.nabble.com>
References: <BANLkTiksZ8-Xu6zXPWJApE4G4Y49eDxocw@mail.gmail.com>
	<BANLkTinEO+EaA2Erua5hkm8kUErrc4a8_A@mail.gmail.com>
	<1307524777548-3582036.post@n4.nabble.com>
Message-ID: <BANLkTikXZu=YmPHbmtYbJLzkk1aGwYdV=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110608/0181d20c/attachment.pl>

From babel at centrum.sk  Thu Jun  9 16:36:19 2011
From: babel at centrum.sk (babel at centrum.sk)
Date: Thu, 9 Jun 2011 16:36:19 +0200
Subject: [R-SIG-Finance] Copula and Portfolio
Message-ID: <20110609163619.EFC4F84D@centrum.sk>


Dear users

Can you please advice some books that deals with Portfolio optimalization and copula models with R examples? Thank you

Jan


From gyollin at r-programming.org  Thu Jun  9 19:12:28 2011
From: gyollin at r-programming.org (Guy Yollin)
Date: Thu, 09 Jun 2011 10:12:28 -0700
Subject: [R-SIG-Finance] Copula and Portfolio
In-Reply-To: <20110609163619.EFC4F84D@centrum.sk>
References: <20110609163619.EFC4F84D@centrum.sk>
Message-ID: <4DF0FEFC.7040206@r-programming.org>

Hi Jan,

A very good resource for learning about copulas in R is the paper "Enjoy 
the Joy of Copulas: With a Package copula" by Jun Yan.  It was published 
in the Journal of Statistical Software in 2007 and is available here:

http://www.jstatsoft.org/v21/i04/paper

Working through the examples in this paper will be very informative.  
Also the nice thing about the copula package is that it is able to fit 
copulas of more the 2 dimensions which allows you to solve real-world 
problems compared to other copula packages that only fit 2-dimensional 
copulas.  Another feature of this package is the capability to create a 
multivariate distribution object from the fitted copula (mvdc) and 
simulate from the multivariate distribution (rmvdc).

There are a number of tools for performing portfolio optimization with 
R.  Without being self-serving, perhaps a good overview is provided in 
this presentation for R/Finance 2009:

http://www.rinfinance.com/RinFinance2009/presentations/yollin_slides.pdf

There are also a number of discussions on using portfolio.optim from the 
tseries package on this board which may be a good way to get started.

Best,

Guy


On 6/9/2011 7:36 AM, babel at centrum.sk wrote:
> Dear users
>
> Can you please advice some books that deals with Portfolio optimalization and copula models with R examples? Thank you
>
> Jan
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From garychin9 at gmail.com  Thu Jun  9 19:33:20 2011
From: garychin9 at gmail.com (Gary C)
Date: Fri, 10 Jun 2011 01:33:20 +0800
Subject: [R-SIG-Finance] Where can I download the latest RBloomberg
 package ?
In-Reply-To: <BANLkTinGai0rzTa4COuinKbmLTRZiumJPQ@mail.gmail.com>
References: <BANLkTinMja=-tnzffBBwk3M794VNkBuq=w@mail.gmail.com>
	<BANLkTimzB0UQ7tg4sysQ6FTU53_QZ6Xgww@mail.gmail.com>
	<BANLkTi=2nLnROR3_Cd4kwwX=WoK3G-b+sA@mail.gmail.com>
	<BANLkTikgutR2v8C13s_z-0f87FzfuS-Jfg@mail.gmail.com>
	<BANLkTinoy+q6xeyTfjrPdowr7umD7trX+A@mail.gmail.com>
	<BANLkTinSENxmw9VSuqqhS0qL3NjkK0=QGw@mail.gmail.com>
	<BANLkTinGai0rzTa4COuinKbmLTRZiumJPQ@mail.gmail.com>
Message-ID: <BANLkTikWqQEekYeiyo5=f9=Bt4+HOR+7zg@mail.gmail.com>

Dear Ana,

Thanks for the new Rbloomberg build.
http://r.789695.n4.nabble.com/RBloomberg-builds-td3541941.html

It works perfect in my case, I am using 2.13, 32bit.

Cheers

Gary

On Thu, Apr 28, 2011 at 5:05 AM, Ana Nelson <nelson.ana at gmail.com> wrote:
> Ok, someone else had it installed on 2.13 but maybe they did some trick to
> get that like downloading the file and installing it manually. I thought
> maybe 2.13 was looking for earlier versions if it couldn't find one for
> itself.
>
> If you use R 2.12 you can install it automatically. Or go here
> http://r.findata.org/bin/windows/contrib/2.12/ download the zip and install
> it locally.
>
> I'll build a 2.13 version soon.
>
> Sorry for the confusion.
>
>
>
> On Wed, Apr 27, 2011 at 2:18 PM, Gary C <garychin9 at gmail.com> wrote:
>>
>> Dear Ana,
>>
>> I had updated my R to the latest version as you suggested.
>>
>> But it is still not working, error message below.
>>
>> Gary
>>
>> > ?install.packages("RBloomberg",repos="http://r.findata.org/")
>> Installing package(s) into ?F:/PortableApps/R-Portable/Data/library?
>> (as ?lib? is unspecified)
>> Warning: unable to access index for repository
>> http://r.findata.org/bin/windows/contrib/2.13
>> Warning message:
>> In getDependencies(pkgs, dependencies, available, lib) :
>> ?package ?RBloomberg? is not available (for R version 2.13.0)
>>
>>
>>
>>
>> On Wed, Apr 27, 2011 at 10:42 PM, Gary C <garychin9 at gmail.com> wrote:
>> > Dear Ana,
>> >
>> > I see, thankyou.
>> > I would like to thank Robert to start the package, making connect to
>> > Bloomberg possible.
>> > I also want to thank for your continuous maintaining and developing of
>> > the package .
>> >
>> > Gary
>> >
>> >
>> >
>> >
>> > On Tue, Apr 26, 2011 at 12:53 AM, Ana Nelson <nelson.ana at gmail.com>
>> > wrote:
>> >> You'll need to use R 2.12 or higher to install this.
>> >>
>> >> On Mon, Apr 25, 2011 at 3:21 AM, Gary Chin <garychin9 at gmail.com> wrote:
>> >>>
>> >>> Dear Lin,
>> >>>
>> >>> I tried your suggestion, doesn't work neither.
>> >>>
>> >>> The return message said "unable to access index for repository.....".
>> >>> (see below)
>> >>>
>> >>> Does it mean the package not there?
>> >>>
>> >>> I already tried both repos = "http://r.findata.org/" and repos =
>> >>> "http://r.findata.org/rbloomberg/".
>> >>>
>> >>> thanks,
>> >>>
>> >>> Gary
>> >>>
>> >>>
>> >>> Here is the output.
>> >>>
>> >>>
>> >>> > >install.packages("RBloomberg",repos="http://r.findata.org/rbloomberg/")
>> >>>
>> >>> Warning in install.packages("RBloomberg", repos =
>> >>> "http://r.findata.org/rbloomberg/") :
>> >>> ?argument 'lib' is missing: using
>> >>> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>> >>> Warning: unable to access index for repository
>> >>> http://r.findata.org/rbloomberg/bin/windows/contrib/2.11
>> >>> Warning message:
>> >>> In getDependencies(pkgs, dependencies, available, lib) :
>> >>> ?package 'RBloomberg' is not available
>> >>>
>> >>>
>> >>>
>> >>> On Mon, Apr 25, 2011 at 5:14 AM, Gei Lin <gmonaie at gmail.com> wrote:
>> >>> > I think here:
>> >>> >
>> >>> > http://findata.org/rbloomberg/
>> >>> >
>> >>> > On Sun, Apr 24, 2011 at 1:49 PM, Gary Chin <garychin9 at gmail.com>
>> >>> > wrote:
>> >>> >>
>> >>> >> Hi there,
>> >>> >>
>> >>> >> I am now using RBloomberg package 0.1 version which I download from
>> >>> >> CRAN, the latest version at CRAN.
>> >>> >>
>> >>> >> As I know, the latest version is 0.4. I have tried to install it
>> >>> >> from
>> >>> >> repository that I know, but all failed with following message.
>> >>> >>
>> >>> >> Am I missing something ? Can anyone give me a clue?
>> >>> >>
>> >>> >> Thanks
>> >>> >>
>> >>> >> Gary
>> >>> >>
>> >>> >>
>> >>> >> > install.packages("RBloomberg", repos="r.findata.org")
>> >>> >>
>> >>> >> Warning in install.packages("RBloomberg", repos = "r.findata.org")
>> >>> >> :
>> >>> >> ?argument 'lib' is missing: using
>> >>> >> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>> >>> >> Warning: unable to access index for repository
>> >>> >> r.findata.org/bin/windows/contrib/2.11
>> >>> >> Warning message:
>> >>> >> In getDependencies(pkgs, dependencies, available, lib) :
>> >>> >> ?package 'RBloomberg' is not available
>> >>> >>
>> >>> >>
>> >>> >> > install.packages("RBloomberg",
>> >>> >> > repos="http://R-Forge.R-project.org")
>> >>> >>
>> >>> >> Warning in install.packages("RBloomberg", repos =
>> >>> >> "http://R-Forge.R-project.org") :
>> >>> >> ?argument 'lib' is missing: using
>> >>> >> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>> >>> >> Warning: unable to access index for repository
>> >>> >> http://R-Forge.R-project.org/bin/windows/contrib/2.11
>> >>> >> Warning message:
>> >>> >> In getDependencies(pkgs, dependencies, available, lib) :
>> >>> >> ?package 'RBloomberg' is not available
>> >>> >>
>> >>> >>
>> >>> >> > install.packages("RBloomberg", repos="http://r.bloombergapi.com")
>> >>> >>
>> >>> >> Warning in install.packages("RBloomberg", repos =
>> >>> >> "http://r.bloombergapi.com") :
>> >>> >> ?argument 'lib' is missing: using
>> >>> >> 'F:/PortableApps/R-Portable/App/R-2.11.1/../../Data/library'
>> >>> >> Error in read.dcf(file = tmpf) : Line starting '<html> ...' is
>> >>> >> malformed!
>> >>> >>
>> >>> >> _______________________________________________
>> >>> >> R-SIG-Finance at r-project.org mailing list
>> >>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >>> >> -- Subscriber-posting only. If you want to post, subscribe first.
>> >>> >> -- Also note that this is not the r-help list where general R
>> >>> >> questions
>> >>> >> should go.
>> >>> >
>> >>> >
>> >>>
>> >>> _______________________________________________
>> >>> R-SIG-Finance at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >>> -- Subscriber-posting only. If you want to post, subscribe first.
>> >>> -- Also note that this is not the r-help list where general R
>> >>> questions
>> >>> should go.
>> >>
>> >>
>> >
>
>


From avishn at gmail.com  Thu Jun  9 20:30:24 2011
From: avishn at gmail.com (Andrew Vishnyakov)
Date: Thu, 9 Jun 2011 13:30:24 -0500
Subject: [R-SIG-Finance] possible bug in PerformanceAnalytics 1.0.3.2
	(Return.rebalancing)
Message-ID: <BANLkTikfY0-6kMJKbMuq2gaJRPuWsOYgWw@mail.gmail.com>

When calculating Return.rebalancing, if the last rebalancing date
falls on the last date of the R (input) timeseries, the function
returns dups for the next to last rebalancing period.

Return.portfolio.R --

 # loop:
    for (row in 1:nrow(weights)){
        from =as.Date(index(weights[row,]))+1
        if (row == nrow(weights)){
           to = as.Date(index(last(R))) # this is correct
        } else {
           to = as.Date(index(weights[(row+1),]))
        }
        if(row==1){
            startingwealth=1
        }
        tmpR<-R[paste(from,to,sep="/"),]
        if (nrow(tmpR)>=1){
            resultreturns=Return.portfolio(tmpR,weights=weights[row,], ...=...)
        }
        if(row==1){
            result = resultreturns
        } else {
            result = rbind(result,resultreturns)
        }
        startingwealth=last(cumprod(1+result)*startingwealth)
    }

In the loop above if row == nrow(weights) and the last date in weights
== last date in R, then "from" date ends up being beyond the last row
of R. This causes tmpR to be empty and the last "if" statement ends up
rbind'ing resultreturns from the previous iteration to result the
second time.


From me at censix.com  Fri Jun 10 11:11:52 2011
From: me at censix.com (soren wilkening)
Date: Fri, 10 Jun 2011 02:11:52 -0700 (PDT)
Subject: [R-SIG-Finance] XTS: creating daily bars from tick data with
 specific starting/ending times
In-Reply-To: <1307481258276-3580825.post@n4.nabble.com>
References: <1307481258276-3580825.post@n4.nabble.com>
Message-ID: <1307697112061-3587912.post@n4.nabble.com>

Hi

you may want to look at the endpoints() function. I think it is either
included in the 'xts' package or in 'quantmod'. You can pretty much generate
endpoints for any scale that you can think of. Use the k=... parameter of
the function to do funky aggregates.

Soren

http://censix.com 

-----
http://censix.com
--
View this message in context: http://r.789695.n4.nabble.com/XTS-creating-daily-bars-from-tick-data-with-specific-starting-ending-times-tp3580825p3587912.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From costas.vorlow at gmail.com  Fri Jun 10 21:09:13 2011
From: costas.vorlow at gmail.com (Costas Vorlow)
Date: Fri, 10 Jun 2011 22:09:13 +0300
Subject: [R-SIG-Finance] Fwd: Problems with charts.PerformanceSummary
In-Reply-To: <BANLkTimn5epMCJaxiv_tLatapmEVQ0w3Wg@mail.gmail.com>
References: <BANLkTimn5epMCJaxiv_tLatapmEVQ0w3Wg@mail.gmail.com>
Message-ID: <BANLkTiknQ0saJSM12HzhsJBB-CQrz1QGgA@mail.gmail.com>

Hello,

When I try to run example(charts.PerformanceSummary) I get an error
message. I think there is some sort of incompatibility with the data
type and the drawdown part of the command. Maybe the locale?

Any clues would be greatly appreciated....

Many thanks in advance,
Costas

> example(charts.PerformanceSummary)

chr.PS> data(edhec)

chr.PS> charts.PerformanceSummary(edhec[,c(1,13)])
Hit <Return> to see next plot:
Error in UseMethod("time<-") :
?no applicable method for 'time<-' applied to an object of class
"c('xts', 'zoo')"
> sessionInfo()
R version 2.13.0 (2011-04-13)
Platform: i686-pc-linux-gnu (32-bit)

locale:
?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base

other attached packages:
?[1] quantmod_0.3-15 ? ? ? ? ? ? ?TTR_0.20-2
?[3] Defaults_1.1-1 ? ? ? ? ? ? ? PerformanceAnalytics_1.0.3.2
?[5] xts_0.8-0 ? ? ? ? ? ? ? ? ? ?e1071_1.5-26
?[7] class_7.3-3 ? ? ? ? ? ? ? ? ?fMarkovSwitching_1.0
?[9] Rdonlp2_0.3-1 ? ? ? ? ? ? ? ?tseries_0.10-25
[11] quadprog_1.5-4 ? ? ? ? ? ? ? fImport_2110.79
[13] timeSeries_2130.92 ? ? ? ? ? timeDate_2130.93
[15] zoo_1.6-5


From kent.russell at live.com  Sat Jun 11 05:31:06 2011
From: kent.russell at live.com (Kent Russell)
Date: Fri, 10 Jun 2011 22:31:06 -0500
Subject: [R-SIG-Finance] Fwd: Problems with charts.PerformanceSummary
In-Reply-To: <BANLkTiknQ0saJSM12HzhsJBB-CQrz1QGgA@mail.gmail.com>
References: <BANLkTimn5epMCJaxiv_tLatapmEVQ0w3Wg@mail.gmail.com>
	<BANLkTiknQ0saJSM12HzhsJBB-CQrz1QGgA@mail.gmail.com>
Message-ID: <BLU0-SMTP14135E3F055C1D8FA90131BFB670@phx.gbl>

I get that error everytime I use a fPortfolio or other f package and PerformanceAnalytics simultaneously.  Guess time is used in both.

Kent

On Jun 10, 2011, at 2:09 PM, Costas Vorlow <costas.vorlow at gmail.com> wrote:

> Hello,
> 
> When I try to run example(charts.PerformanceSummary) I get an error
> message. I think there is some sort of incompatibility with the data
> type and the drawdown part of the command. Maybe the locale?
> 
> Any clues would be greatly appreciated....
> 
> Many thanks in advance,
> Costas
> 
>> example(charts.PerformanceSummary)
> 
> chr.PS> data(edhec)
> 
> chr.PS> charts.PerformanceSummary(edhec[,c(1,13)])
> Hit <Return> to see next plot:
> Error in UseMethod("time<-") :
>  no applicable method for 'time<-' applied to an object of class
> "c('xts', 'zoo')"
>> sessionInfo()
> R version 2.13.0 (2011-04-13)
> Platform: i686-pc-linux-gnu (32-bit)
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
>  [1] quantmod_0.3-15              TTR_0.20-2
>  [3] Defaults_1.1-1               PerformanceAnalytics_1.0.3.2
>  [5] xts_0.8-0                    e1071_1.5-26
>  [7] class_7.3-3                  fMarkovSwitching_1.0
>  [9] Rdonlp2_0.3-1                tseries_0.10-25
> [11] quadprog_1.5-4               fImport_2110.79
> [13] timeSeries_2130.92           timeDate_2130.93
> [15] zoo_1.6-5
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 


From veepsirtt at gmail.com  Sat Jun 11 06:50:33 2011
From: veepsirtt at gmail.com (veepsirtt)
Date: Fri, 10 Jun 2011 21:50:33 -0700 (PDT)
Subject: [R-SIG-Finance] How to test pairs trading strategy
In-Reply-To: <BANLkTikXZu=YmPHbmtYbJLzkk1aGwYdV=g@mail.gmail.com>
References: <BANLkTiksZ8-Xu6zXPWJApE4G4Y49eDxocw@mail.gmail.com>
	<BANLkTinEO+EaA2Erua5hkm8kUErrc4a8_A@mail.gmail.com>
	<1307524777548-3582036.post@n4.nabble.com>
	<BANLkTikXZu=YmPHbmtYbJLzkk1aGwYdV=g@mail.gmail.com>
Message-ID: <1307767833261-3589963.post@n4.nabble.com>

Please visit the link


http://webcache.googleusercontent.com/search?q=cache:2lWmiYG4KB4J:www.pairtradefinder.com/PTF_UserManual_v297.pdf+pair+trade+finder+mannual&cd=4&hl=en&ct=clnk&gl=in&source=www.google.co.in


in page 18
they say how the entry and exit signals are generated in PAIRTRADEFINDER
software

Using the default signal settings, trading signals are generated at 2.70
standard deviations from the 100 day mean average of the ratio, an exit
signal is generated when the pair goes past 1.00 standard deviations;
i.e.?.its goes closer than 1 standard deviation to the mean. The current
reading on each pair is shown in the +/- column in the home page.
To analyse each pair further, you can select a pair in the home page then
click on the pair charts button.

How  could this be incorporated  in the quantstrat pair trader demo ?.

thanks
veepsirtt

--
View this message in context: http://r.789695.n4.nabble.com/How-to-test-pairs-trading-strategy-tp3558776p3589963.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From costas.vorlow at gmail.com  Sat Jun 11 09:31:39 2011
From: costas.vorlow at gmail.com (Costas Vorlow)
Date: Sat, 11 Jun 2011 10:31:39 +0300
Subject: [R-SIG-Finance] Fwd: Problems with charts.PerformanceSummary
In-Reply-To: <9ec7cc11-1086-49a1-9d12-36daac6e890f@email.android.com>
References: <BANLkTimn5epMCJaxiv_tLatapmEVQ0w3Wg@mail.gmail.com>
	<BANLkTiknQ0saJSM12HzhsJBB-CQrz1QGgA@mail.gmail.com>
	<9ec7cc11-1086-49a1-9d12-36daac6e890f@email.android.com>
Message-ID: <BANLkTinudOpxDdjLhxH0Hc4YZo1X0-QGjg@mail.gmail.com>

Thanks to all replies. It seems tseries and fImport were creating conflicts.

Thanks again,
Costas

On 10 June 2011 23:25, Brian G. Peterson <brian at braverock.com> wrote:
> Load the Rmetrics packages before loading xts/zoo
>
> The time() function is improperly declared as a generic by Rmetrics, ans
> stomps on zoo/xts/POSIX
> --
> Sent from my Android phone with K-9 Mail. Please excuse my brevity.
>
> Costas Vorlow <costas.vorlow at gmail.com> wrote:
>>
>> Hello, When I try to run example(charts.PerformanceSummary) I get an error
>> message. I think there is some sort of incompatibility with the data type
>> and the drawdown part of the command. Maybe the locale? Any clues would be
>> greatly appreciated.... Many thanks in advance, Costas >
>> example(charts.PerformanceSummary) chr.PS> data(edhec) chr.PS>
>> charts.PerformanceSummary(edhec[,c(1,13)]) Hit <Return> to see next plot:
>> Error in UseMethod("time<-") : ?no applicable method for 'time<-' applied to
>> an object of class "c('xts', 'zoo')" > sessionInfo() R version 2.13.0
>> (2011-04-13) Platform: i686-pc-linux-gnu (32-bit) locale: ?[1]
>> LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C ?[3] LC_TIME=en_US.UTF-8
>> ?LC_COLLATE=en_US.UTF-8 ?[5] LC_MONETARY=C
>> ?LC_MESSAGES=en_US.UTF-8 ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C ?[9]
>> LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8
>> LC_IDENTIFICATION=C attached base packages: [1] stats ? ? graphics
>> ?grDevices utils ? ? datasets ?methods ? base other attached packages: ?[1]
>> quantmod_0.3-15 ? ? ? ? ? ? ?TTR_0.20-2 ?[3] Defaults_1.1-1
>> PerformanceAnalytics_1.0.3.2 ?[5] xts_0.8-0 ? ? ? ? ? ? ? ? ? ?e1071_1.5-26
>> ?[7] class_7.3-3 ? ? ? ? ? ? ? ? ?fMarkovSwitching_1.0 ?[9] Rdonlp2_0.3-1
>> ? ? ? ? ? ? ?tseries_0.10-25 [11] quadprog_1.5-4
>> fImport_2110.79 [13] timeSeries_2130.92 ? ? ? ? ? timeDate_2130.93 [15]
>> zoo_1.6-5
>> ________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance -- Subscriber-posting
>> only. If you want to post, subscribe first. -- Also note that this is not
>> the r-help list where general R questions should go.


From me at censix.com  Sat Jun 11 13:48:48 2011
From: me at censix.com (soren wilkening)
Date: Sat, 11 Jun 2011 04:48:48 -0700 (PDT)
Subject: [R-SIG-Finance] XTS: creating daily bars from tick data with
 specific starting/ending times
In-Reply-To: <1307708728051-3588245.post@n4.nabble.com>
References: <1307481258276-3580825.post@n4.nabble.com>
	<1307697112061-3587912.post@n4.nabble.com>
	<1307708728051-3588245.post@n4.nabble.com>
Message-ID: <1307792928197-3590365.post@n4.nabble.com>

Well, if it does the job, don't try to fix it :) thats my motto anyway.

-----
http://censix.com
--
View this message in context: http://r.789695.n4.nabble.com/XTS-creating-daily-bars-from-tick-data-with-specific-starting-ending-times-tp3580825p3590365.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From costas.vorlow at gmail.com  Sun Jun 12 22:20:27 2011
From: costas.vorlow at gmail.com (Costas Vorlow)
Date: Sun, 12 Jun 2011 23:20:27 +0300
Subject: [R-SIG-Finance] Return.Calculate vs ROC
Message-ID: <BANLkTimWAjCTM1UwU=V_eEcFOOFtb7pW3w@mail.gmail.com>

Hi,

I am having a bit of trouble with  the following code:

require(PerformanceAnalytics)
require(quantmod)

getSymbols("^GSPC", from="1990-01-01")

	retorig<-Return.calculate(Cl(GSPC),method="simple")
	retroc<-ROC(Cl(GSPC), type="discrete")

strategiestest<-merge(retorig,retroc)
charts.PerformanceSummary(strategiestest, geometric=FALSE, wealth.index)


shouldn't in the above example retorig=retroc?

retorig appears to be 0....


> head(strategiestest)
           GSPC.Close GSPC.Close.1
1990-01-02          0  0.000000000
1990-01-03          0 -0.002585560
1990-01-04          0 -0.008613000
1990-01-05          0 -0.009756235
1990-01-08          0  0.004514480
1990-01-09          0 -0.011786653
>


Many thanks in advance,
Costas

-- 

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|c|o|s|t|a|s|@|v|o|r|l|o|w|.|o|r|g|
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+


From brian at braverock.com  Sun Jun 12 22:34:03 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 12 Jun 2011 15:34:03 -0500
Subject: [R-SIG-Finance] Return.Calculate vs ROC
In-Reply-To: <BANLkTimWAjCTM1UwU=V_eEcFOOFtb7pW3w@mail.gmail.com>
References: <BANLkTimWAjCTM1UwU=V_eEcFOOFtb7pW3w@mail.gmail.com>
Message-ID: <1307910843.22117.296.camel@brian-desktop>

On Sun, 2011-06-12 at 23:20 +0300, Costas Vorlow wrote:
> Hi,
> 
> I am having a bit of trouble with  the following code:
> 
> require(PerformanceAnalytics)
> require(quantmod)
> 
> getSymbols("^GSPC", from="1990-01-01")
> 
> 	retorig<-Return.calculate(Cl(GSPC),method="simple")
> 	retroc<-ROC(Cl(GSPC), type="discrete")

What is the ROC supposed to give you?

Return.calculate will give you simple returns on a buy and hold of GSPC.

for example, this code works fine:

require(PerformanceAnalytics)
require(quantmod)
getSymbols("^GSPC", from="1990-01-01")
retorig<-Return.calculate(Cl(GSPC),method="simple")
charts.PerformanceSummary(retorig, geometric=FALSE, wealth.index=TRUE)

> strategiestest<-merge(retorig,retroc)
> charts.PerformanceSummary(strategiestest, geometric=FALSE, wealth.index)
> shouldn't in the above example retorig=retroc?

Why would the rate of change of the returns be the same as the returns
themselves?  Perhapsnderstand you, but that doesn't make any sense to
me.

> retorig appears to be 0....
> 
> 
> > head(strategiestest)
>            GSPC.Close GSPC.Close.1
> 1990-01-02          0  0.000000000
> 1990-01-03          0 -0.002585560
> 1990-01-04          0 -0.008613000
> 1990-01-05          0 -0.009756235
> 1990-01-08          0  0.004514480
> 1990-01-09          0 -0.011786653
> >
> 
> 
> Many thanks in advance,
> Costas
> 

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From gsee000 at gmail.com  Sun Jun 12 22:43:02 2011
From: gsee000 at gmail.com (G See)
Date: Sun, 12 Jun 2011 15:43:02 -0500
Subject: [R-SIG-Finance] Return.Calculate vs ROC
In-Reply-To: <BANLkTimWAjCTM1UwU=V_eEcFOOFtb7pW3w@mail.gmail.com>
References: <BANLkTimWAjCTM1UwU=V_eEcFOOFtb7pW3w@mail.gmail.com>
Message-ID: <BANLkTi=xaFBXvD2uksUTs7kzqiCeRwvcWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110612/b2ae08a6/attachment.pl>

From gautam20feb at gmail.com  Mon Jun 13 11:52:33 2011
From: gautam20feb at gmail.com (Gautam Garg)
Date: Mon, 13 Jun 2011 02:52:33 -0700 (PDT)
Subject: [R-SIG-Finance] problem with getting Historical data for futures
 using I Brokers package
Message-ID: <1307958753258-3593480.post@n4.nabble.com>

Hi ,
I am trying to get historical data for futures using I brokers package. I am
able to do so with the expiry dates which are yet to come but not for the
dates that have passed.

Below is my code :

 >     t<-twsFUT(symbol="III",exch="NSE",expiry="201106",currency="INR")
 >    abb <- reqHistoricalData(tws,t ,file="III.csv" ,bar="1 day", dur="5
D")
waiting for TWS reply on III .... done.


but if the write the code below:
>       t<-twsFUT(symbol="III",exch="NSE",expiry="201105",currency="INR")
>       abb <- reqHistoricalData(tws,t ,file="LT.csv" ,bar="1 day", dur="5
> D")
TWS Message: 2 -1 2107 HMDS data farm connection is inactive but should be
available upon demand.hkhmds2
waiting for TWS reply on III ....failed.
Warning message:
In errorHandler(con, verbose, OK = c(165, 300, 366, 2104, 2106,  :
  No security definition has been found for the request




What is that I am missing?
Thanks in advance
Gautam Garg 

--
View this message in context: http://r.789695.n4.nabble.com/problem-with-getting-Historical-data-for-futures-using-I-Brokers-package-tp3593480p3593480.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From juandiq at gmail.com  Mon Jun 13 12:42:40 2011
From: juandiq at gmail.com (juandi)
Date: Mon, 13 Jun 2011 03:42:40 -0700 (PDT)
Subject: [R-SIG-Finance] Having troubles with timezone retrieving intraday
	bar data
Message-ID: <1307961760865-3593582.post@n4.nabble.com>

Hi All

I want to retrieve the intraday closing prices per minute of an ETF in the
US, namely EWQ UP Equity.
I am located in Amsterdam, my timezone in R is configured as "CET", nowdays
shown as "CEST" with the summer adjustment.

I make the following query:
startDate <- as.Date("2010-12-01")
endDate <- as.Date("2010-12-03")
firstSecurity <- "EWQ UP Equity"
intervalData <- "1"

startDateUTC <- paste(strptime(as.chron(startDate,
"01:00:00"),format="(%m/%d/%y %H:%M:%S)"),".000",sep="")
endDateUTC <- paste(strptime(as.chron(endDate, "22:00:00"),format="(%m/%d/%y
%H:%M:%S)"),".000",sep="")

dataFirstSec <- try(bar(conn, firstSecurity, "TRADE", start=startDateUTC,
end=endDateUTC, intervalData))

It works like a charm except that I get the first data point at 14:30 but
actually I expected it at 15:30 when is the US opening at CET. When
retrieving the data in Excel with the wizard I get the correct time stamps.

I get in R for instance:
                                           time  open  high   low close
2010-12-01T14:30:00.000 2010-12-01T14:30:00.000 23.00 23.00 22.98 22.98
2010-12-01T14:31:00.000 2010-12-01T14:31:00.000 23.01 23.02 23.00 23.00
2010-12-01T14:32:00.000 2010-12-01T14:32:00.000 23.01 23.01 23.01 23.01
2010-12-01T14:35:00.000 2010-12-01T14:35:00.000 23.00 23.00 23.00 23.00
2010-12-01T14:37:00.000 2010-12-01T14:37:00.000 23.01 23.01 23.01 23.01
2010-12-01T14:38:00.000 2010-12-01T14:38:00.000 23.04 23.04 23.04 23.04
                        numEvents volume
2010-12-01T14:30:00.000        16  15427
2010-12-01T14:31:00.000        29  62600
2010-12-01T14:32:00.000         3   1200
2010-12-01T14:35:00.000         1    100
2010-12-01T14:37:00.000         1   2500
2010-12-01T14:38:00.000         1    104

I wonder what I am doing wrong, what I am missing to get the correct time
stamps in my timezone ? Thanks in advance for any hints on this issue.

--
View this message in context: http://r.789695.n4.nabble.com/Having-troubles-with-timezone-retrieving-intraday-bar-data-tp3593582p3593582.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From enricoschumann at yahoo.de  Mon Jun 13 13:21:49 2011
From: enricoschumann at yahoo.de (Enrico Schumann)
Date: Mon, 13 Jun 2011 13:21:49 +0200
Subject: [R-SIG-Finance] problem with getting Historical data for
	futures using I Brokers package
In-Reply-To: <1307958753258-3593480.post@n4.nabble.com>
References: <1307958753258-3593480.post@n4.nabble.com>
Message-ID: <2AD512556AE54AEC9811E737A0F48CCA@EnricosPC>

 
try adding "include_expired = '1'" to the contract definition; see
?twsContract

regards, enrico

> -----Urspr?ngliche Nachricht-----
> Von: r-sig-finance-bounces at r-project.org 
> [mailto:r-sig-finance-bounces at r-project.org] Im Auftrag von 
> Gautam Garg
> Gesendet: Montag, 13. Juni 2011 11:53
> An: r-sig-finance at r-project.org
> Betreff: [R-SIG-Finance] problem with getting Historical data 
> for futures using I Brokers package
> 
> Hi ,
> I am trying to get historical data for futures using I 
> brokers package. I am able to do so with the expiry dates 
> which are yet to come but not for the dates that have passed.
> 
> Below is my code :
> 
>  >     
> t<-twsFUT(symbol="III",exch="NSE",expiry="201106",currency="INR")
>  >    abb <- reqHistoricalData(tws,t ,file="III.csv" ,bar="1 
> day", dur="5
> D")
> waiting for TWS reply on III .... done.
> 
> 
> but if the write the code below:
> >       
> t<-twsFUT(symbol="III",exch="NSE",expiry="201105",currency="INR")
> >       abb <- reqHistoricalData(tws,t ,file="LT.csv" ,bar="1 day", 
> > dur="5
> > D")
> TWS Message: 2 -1 2107 HMDS data farm connection is inactive 
> but should be available upon demand.hkhmds2 waiting for TWS 
> reply on III ....failed.
> Warning message:
> In errorHandler(con, verbose, OK = c(165, 300, 366, 2104, 2106,  :
>   No security definition has been found for the request
> 
> 
> 
> 
> What is that I am missing?
> Thanks in advance
> Gautam Garg 
> 
> --
> View this message in context: 
> http://r.789695.n4.nabble.com/problem-with-getting-Historical-
> data-for-futures-using-I-Brokers-package-tp3593480p3593480.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R 
> questions should go.


From costas.vorlow at gmail.com  Mon Jun 13 14:50:24 2011
From: costas.vorlow at gmail.com (Costas Vorlow)
Date: Mon, 13 Jun 2011 15:50:24 +0300
Subject: [R-SIG-Finance] Return.Calculate vs ROC
In-Reply-To: <BANLkTi=xaFBXvD2uksUTs7kzqiCeRwvcWQ@mail.gmail.com>
References: <BANLkTimWAjCTM1UwU=V_eEcFOOFtb7pW3w@mail.gmail.com>
	<BANLkTi=xaFBXvD2uksUTs7kzqiCeRwvcWQ@mail.gmail.com>
Message-ID: <BANLkTimOO29M2kixOwKtTP8masD-kvL7Lg@mail.gmail.com>

Thanks for all the replies.

There was something wrong with my installations of the relevant
packages. When I reinstalled, the problem seized...

Maybe some code overwritten or mixed up with some of my routines.

Thanks again for your time and replies,
Costas

On 12 June 2011 23:43, G See <gsee000 at gmail.com> wrote:
> Is it possible that you overwrote the function Return.calculate? ?Or, that
> you overwrote retorig before you merged? ?What is the output if you enter
> Return.calculate? ?i.e. what source code do you have for that function?
> I can't replicate your problem:
>> getSymbols("^GSPC", from="1990-01-01")
> [1] "GSPC"
>> retorig<-Return.calculate(Cl(GSPC),method="simple")
>> retroc<-ROC(Cl(GSPC), type="discrete")
>>
>> identical(retorig,retroc)
> [1] TRUE
>> strategiestest<-merge(retorig,retroc)
>> head(strategiestest)
> ? ? ? ? ? ? ?GSPC.Close GSPC.Close.1
> 1990-01-02 ? ? ? ? ? NA ? ? ? ? ? NA
> 1990-01-03 -0.002585560 -0.002585560
> 1990-01-04 -0.008613000 -0.008613000
> 1990-01-05 -0.009756235 -0.009756235
> 1990-01-08 ?0.004514480 ?0.004514480
> 1990-01-09 -0.011786653 -0.011786653
>> which(strategiestest[,1]!=strategiestest[,2])
> integer(0)
>
>
>
> On Sun, Jun 12, 2011 at 3:20 PM, Costas Vorlow <costas.vorlow at gmail.com>
> wrote:
>>
>> Hi,
>>
>> I am having a bit of trouble with ?the following code:
>>
>> require(PerformanceAnalytics)
>> require(quantmod)
>>
>> getSymbols("^GSPC", from="1990-01-01")
>>
>> ? ? ? ?retorig<-Return.calculate(Cl(GSPC),method="simple")
>> ? ? ? ?retroc<-ROC(Cl(GSPC), type="discrete")
>>
>> strategiestest<-merge(retorig,retroc)
>> charts.PerformanceSummary(strategiestest, geometric=FALSE, wealth.index)
>>
>>
>> shouldn't in the above example retorig=retroc?
>>
>> retorig appears to be 0....
>>
>>
>> > head(strategiestest)
>> ? ? ? ? ? GSPC.Close GSPC.Close.1
>> 1990-01-02 ? ? ? ? ?0 ?0.000000000
>> 1990-01-03 ? ? ? ? ?0 -0.002585560
>> 1990-01-04 ? ? ? ? ?0 -0.008613000
>> 1990-01-05 ? ? ? ? ?0 -0.009756235
>> 1990-01-08 ? ? ? ? ?0 ?0.004514480
>> 1990-01-09 ? ? ? ? ?0 -0.011786653
>> >
>>
>>
>> Many thanks in advance,
>> Costas
>>
>> --
>>
>> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
>> |c|o|s|t|a|s|@|v|o|r|l|o|w|.|o|r|g|
>> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>



-- 

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|c|o|s|t|a|s|@|v|o|r|l|o|w|.|o|r|g|
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+


From kennethrose82 at gmail.com  Mon Jun 13 15:55:09 2011
From: kennethrose82 at gmail.com (Kenneth Rose)
Date: Mon, 13 Jun 2011 15:55:09 +0200
Subject: [R-SIG-Finance] Converting data for use in TTR and
	PerformanceAnalytics
Message-ID: <BANLkTi=CenxoX1rcpSoqqs1WUOep=t9pmA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110613/e6eefbf2/attachment.pl>

From brian at braverock.com  Mon Jun 13 16:09:57 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 13 Jun 2011 09:09:57 -0500
Subject: [R-SIG-Finance] Converting data for use in TTR
	and	PerformanceAnalytics
In-Reply-To: <BANLkTi=CenxoX1rcpSoqqs1WUOep=t9pmA@mail.gmail.com>
References: <BANLkTi=CenxoX1rcpSoqqs1WUOep=t9pmA@mail.gmail.com>
Message-ID: <a7d68f38-4e5d-4c92-9f5a-92e3e72f0ae7@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110613/0cd3b7be/attachment.pl>

From josh.m.ulrich at gmail.com  Mon Jun 13 16:20:29 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 13 Jun 2011 09:20:29 -0500
Subject: [R-SIG-Finance] Converting data for use in TTR and
	PerformanceAnalytics
In-Reply-To: <BANLkTi=CenxoX1rcpSoqqs1WUOep=t9pmA@mail.gmail.com>
References: <BANLkTi=CenxoX1rcpSoqqs1WUOep=t9pmA@mail.gmail.com>
Message-ID: <BANLkTikLNePug+KVBjyBxo5kOhpqx+srVQ@mail.gmail.com>

On Mon, Jun 13, 2011 at 8:55 AM, Kenneth Rose <kennethrose82 at gmail.com> wrote:
> Hi guys,
>
> I'm a complete newbie so I'm not sure if my question is stupid. But anyway,
> I can't figure it out!
>
> I'm trying to do calculate returns in "TTR" and "PerformanceAnalytics"
> (inspired by this<http://www.milktrader.net/2011/04/chop-slice-and-dice-your-returns-in-r.html>article
> from milktrader) but I get the error below whenever I run the code:
> *
>
> "Error in inherits(x, "xts") :
> ?trying to get slot "Luk" from an object (class "data.frame") that is
> not an S4 object"
>
> *

It's not possible that you get this error from running the code in the
blog post you cite because it does not use the "@" operator.

> I have downloaded data from another source then to ones possible in
> PerformanceAnalytics because Yahoos dataset is incomplete. The dataset I
> have downloaded is not complete either but at least there are closing prices
> for the whole period.
>
> The dataset variables are in danish but can be translated as:
>
> Dato = Date
> ?bning = Open (or opening price)
> H?j = High
> Lav = Low
> Luk = Close (or closing price)
> Oms?tning = Volume
>
>
>
> This is the code:
>
> require("quantmod")
> require("TTR")
> require("PerformanceAnalytics")
>
> danske <- read.table("
> http://www.euroinvestor.dk/HistoricalQuotes/HistoricalQuotes.aspx?lang=DA&fn=DANSKE&outputmode=5&format=csv&separator=,&lcid=2057&stockid=235240",
> sep = ",", header = TRUE)
>
> danske at logreturns <- PerformanceAnalytics::Return.calculate(danske at Luk)
> danske at ROC <- TTR::ROC(danske at Luk)
>
>

The blog post you cite doesn't use "@" to access columns, so why are
you using it?  I strongly suggest you read the manuals rather than try
random code.  It's also useful to cross-reference the "See Also"
section of the manual pages.  For example, you could have looked at:

R> help("@")  # The @ operator
R> help("data.frame")  # data.frames (See Also: [.data.frame? for
subsetting methods)
R> help("S4")  # S4 objects

It would also be helpful to read "An Introduction to R".
Specifically, the section on lists and data.frames:
http://cran.r-project.org/doc/manuals/R-intro.html#Lists-and-data-frames

>
> I appreciate your help!
>
> Yours sincerely,
>
> Kenneth
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From kennethrose82 at gmail.com  Mon Jun 13 23:00:18 2011
From: kennethrose82 at gmail.com (Kenneth Rose)
Date: Mon, 13 Jun 2011 23:00:18 +0200
Subject: [R-SIG-Finance] Converting data for use in TTR and
	PerformanceAnalytics
In-Reply-To: <BANLkTikLNePug+KVBjyBxo5kOhpqx+srVQ@mail.gmail.com>
References: <BANLkTi=CenxoX1rcpSoqqs1WUOep=t9pmA@mail.gmail.com>
	<BANLkTikLNePug+KVBjyBxo5kOhpqx+srVQ@mail.gmail.com>
Message-ID: <BANLkTinpo6nYyUvKjrQo1Cz3Y0zhxESCuQ@mail.gmail.com>

Hi Joshua and Brian

Thank you for your replies. It was the "@" that messed things up. I
really don't know why I used the "@" instead of the "$". I think I'm
gonna work through some more examples before I start writing my own
"random code" :)

Thanks,

Kenneth

On Mon, Jun 13, 2011 at 4:20 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>
> On Mon, Jun 13, 2011 at 8:55 AM, Kenneth Rose <kennethrose82 at gmail.com> wrote:
> > Hi guys,
> >
> > I'm a complete newbie so I'm not sure if my question is stupid. But anyway,
> > I can't figure it out!
> >
> > I'm trying to do calculate returns in "TTR" and "PerformanceAnalytics"
> > (inspired by this<http://www.milktrader.net/2011/04/chop-slice-and-dice-your-returns-in-r.html>article
> > from milktrader) but I get the error below whenever I run the code:
> > *
> >
> > "Error in inherits(x, "xts") :
> > ?trying to get slot "Luk" from an object (class "data.frame") that is
> > not an S4 object"
> >
> > *
>
> It's not possible that you get this error from running the code in the
> blog post you cite because it does not use the "@" operator.
>
> > I have downloaded data from another source then to ones possible in
> > PerformanceAnalytics because Yahoos dataset is incomplete. The dataset I
> > have downloaded is not complete either but at least there are closing prices
> > for the whole period.
> >
> > The dataset variables are in danish but can be translated as:
> >
> > Dato = Date
> > ?bning = Open (or opening price)
> > H?j = High
> > Lav = Low
> > Luk = Close (or closing price)
> > Oms?tning = Volume
> >
> >
> >
> > This is the code:
> >
> > require("quantmod")
> > require("TTR")
> > require("PerformanceAnalytics")
> >
> > danske <- read.table("
> > http://www.euroinvestor.dk/HistoricalQuotes/HistoricalQuotes.aspx?lang=DA&fn=DANSKE&outputmode=5&format=csv&separator=,&lcid=2057&stockid=235240",
> > sep = ",", header = TRUE)
> >
> > danske at logreturns <- PerformanceAnalytics::Return.calculate(danske at Luk)
> > danske at ROC <- TTR::ROC(danske at Luk)
> >
> >
>
> The blog post you cite doesn't use "@" to access columns, so why are
> you using it? ?I strongly suggest you read the manuals rather than try
> random code. ?It's also useful to cross-reference the "See Also"
> section of the manual pages. ?For example, you could have looked at:
>
> R> help("@") ?# The @ operator
> R> help("data.frame") ?# data.frames (See Also: [.data.frame? for
> subsetting methods)
> R> help("S4") ?# S4 objects
>
> It would also be helpful to read "An Introduction to R".
> Specifically, the section on lists and data.frames:
> http://cran.r-project.org/doc/manuals/R-intro.html#Lists-and-data-frames
>
> >
> > I appreciate your help!
> >
> > Yours sincerely,
> >
> > Kenneth
> >
> > ? ? ? ?[[alternative HTML version deleted]]
> >
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions should go.
> >
>
> Best,
> --
> Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com


From gautam20feb at gmail.com  Tue Jun 14 06:44:46 2011
From: gautam20feb at gmail.com (Gautam Garg)
Date: Mon, 13 Jun 2011 21:44:46 -0700 (PDT)
Subject: [R-SIG-Finance] problem with getting Historical data for
 futures using I Brokers package
In-Reply-To: <2AD512556AE54AEC9811E737A0F48CCA@EnricosPC>
References: <1307958753258-3593480.post@n4.nabble.com>
	<2AD512556AE54AEC9811E737A0F48CCA@EnricosPC>
Message-ID: <1308026686049-3595654.post@n4.nabble.com>

Thanks that helped but now it is giving another error.

here is the code:

t<-twsFUT(symbol="WPRO",exch="NSE",expiry="201105",currency="INR",include_expired
= '1')
>        WPRO <- reqHistoricalData(tws,t ,file="Wipro.csv" ,bar="1 min",
> dur="5 D") 
TWS Message: 2 -1 2104 Market data farm connection is OK:hkfarm 
waiting for TWS reply on WPRO ......failed.
Warning message:
In errorHandler(con, verbose, OK = c(165, 300, 366, 2104, 2106,  :
  Historical Market Data Service error message:HMDS query returned no data:
WIPRO11MAYFUT at NSE Trades

Is it something to do the ticker?

--
View this message in context: http://r.789695.n4.nabble.com/problem-with-getting-Historical-data-for-futures-using-I-Brokers-package-tp3593480p3595654.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From gsee000 at gmail.com  Tue Jun 14 16:31:20 2011
From: gsee000 at gmail.com (G See)
Date: Tue, 14 Jun 2011 09:31:20 -0500
Subject: [R-SIG-Finance] problem with getting Historical data for
 futures using I Brokers package
In-Reply-To: <1308026686049-3595654.post@n4.nabble.com>
References: <1307958753258-3593480.post@n4.nabble.com>
	<2AD512556AE54AEC9811E737A0F48CCA@EnricosPC>
	<1308026686049-3595654.post@n4.nabble.com>
Message-ID: <BANLkTikJB5PtXXQU1gp_a2yPZNb5WZ5b9g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110614/651fcdfc/attachment.pl>

From gsee000 at gmail.com  Tue Jun 14 16:36:17 2011
From: gsee000 at gmail.com (G See)
Date: Tue, 14 Jun 2011 09:36:17 -0500
Subject: [R-SIG-Finance] problem with getting Historical data for
 futures using I Brokers package
In-Reply-To: <BANLkTikJB5PtXXQU1gp_a2yPZNb5WZ5b9g@mail.gmail.com>
References: <1307958753258-3593480.post@n4.nabble.com>
	<2AD512556AE54AEC9811E737A0F48CCA@EnricosPC>
	<1308026686049-3595654.post@n4.nabble.com>
	<BANLkTikJB5PtXXQU1gp_a2yPZNb5WZ5b9g@mail.gmail.com>
Message-ID: <BANLkTikBOm2PwdEp6VhdYOspYYZ_z18agQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110614/1b27d964/attachment.pl>

From gsee000 at gmail.com  Tue Jun 14 16:45:11 2011
From: gsee000 at gmail.com (G See)
Date: Tue, 14 Jun 2011 09:45:11 -0500
Subject: [R-SIG-Finance] problem with getting Historical data for
 futures using I Brokers package
In-Reply-To: <BANLkTikBOm2PwdEp6VhdYOspYYZ_z18agQ@mail.gmail.com>
References: <1307958753258-3593480.post@n4.nabble.com>
	<2AD512556AE54AEC9811E737A0F48CCA@EnricosPC>
	<1308026686049-3595654.post@n4.nabble.com>
	<BANLkTikJB5PtXXQU1gp_a2yPZNb5WZ5b9g@mail.gmail.com>
	<BANLkTikBOm2PwdEp6VhdYOspYYZ_z18agQ@mail.gmail.com>
Message-ID: <BANLkTimJ==PFv4G9ppXGnNsy5L+1ZGFDiw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110614/fc6646a0/attachment.pl>

From gautam20feb at gmail.com  Tue Jun 14 18:16:12 2011
From: gautam20feb at gmail.com (Gautam Garg)
Date: Tue, 14 Jun 2011 21:46:12 +0530
Subject: [R-SIG-Finance] problem with getting Historical data for
 futures using I Brokers package
In-Reply-To: <BANLkTimJ==PFv4G9ppXGnNsy5L+1ZGFDiw@mail.gmail.com>
References: <1307958753258-3593480.post@n4.nabble.com>
	<2AD512556AE54AEC9811E737A0F48CCA@EnricosPC>
	<1308026686049-3595654.post@n4.nabble.com>
	<BANLkTikJB5PtXXQU1gp_a2yPZNb5WZ5b9g@mail.gmail.com>
	<BANLkTikBOm2PwdEp6VhdYOspYYZ_z18agQ@mail.gmail.com>
	<BANLkTimJ==PFv4G9ppXGnNsy5L+1ZGFDiw@mail.gmail.com>
Message-ID: <BANLkTim+PyRdOZprB-m1ARsxCkztrU-zyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110614/c6e30fe7/attachment.pl>

From noahsilverman at ucla.edu  Wed Jun 15 05:40:05 2011
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Tue, 14 Jun 2011 20:40:05 -0700
Subject: [R-SIG-Finance] Find first trade of day in xts object
Message-ID: <1AD0CD5B-5EF8-4533-8B7A-5950AEE40511@ucla.edu>

Hi,

I have a long series of hourly bars.  They are not aligned on the exact hour.  I used xts to convert actual tick data to hourly bars.

I want to access the first trade of each day.  Is there an easy way to do this? 

Furthermore, what if I want to find the first trade that occurred after 6:30am each day?  (Or any other arbitrary time each day?)


Here are a few rows of data:

finalData[4880:4890,]
                    ds.Open ds.High  ds.Low ds.Close          ret
2008-02-27 02:59:47 1461.75 1477.75 1457.25  1465.25  0.002220515
2008-02-27 03:59:32 1467.25 1474.25 1425.75  1443.25 -0.015128361
2008-02-27 04:59:30 1442.75 1477.25 1410.00  1431.25 -0.008349327
2008-02-27 05:59:59 1434.00 1438.75 1366.75  1366.75 -0.046112530
2008-02-27 09:59:59 1378.25 1439.25 1378.25  1428.00  0.043839205
2008-02-27 10:59:58 1427.75 1636.75 1395.50  1591.00  0.108087885
2008-02-27 11:59:59 1591.00 1592.25 1505.75  1551.25 -0.025301692
2008-02-27 12:59:58 1550.50 1562.25 1495.75  1525.00 -0.017066647
2008-02-27 13:14:59 1524.75 1584.25 1521.75  1545.50  0.013353073
2008-02-27 18:59:56 1545.50 1560.25 1518.25  1551.00  0.003552402
2008-02-27 19:59:53 1549.50 1549.50 1523.50  1524.00 -0.017561427



Thanks!



--
Noah Silverman
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095


From noahsilverman at ucla.edu  Wed Jun 15 05:52:17 2011
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Tue, 14 Jun 2011 20:52:17 -0700
Subject: [R-SIG-Finance] Estimate parameters of a Kalman Filter
Message-ID: <775348E0-966D-47DA-A914-1C4BB84649F9@ucla.edu>

This isn't entirely an "R" question, but I thought the group would be the best place to ask.


I want to consider a Kalman filter on some time series data.  One of the hard parts is estimating the 4-5 parameters for the filter.  I assume some form of EM would be good, but am not clear on how to best implement it.  

There is probably an R package that will do this automatically, but I'd like to LEARN how to do this manually as it will lead to me developing some more advanced filters.

Any suggestions?

--
Noah Silverman
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095


From frainj at tcd.ie  Wed Jun 15 10:19:17 2011
From: frainj at tcd.ie (John C Frain)
Date: Wed, 15 Jun 2011 09:19:17 +0100
Subject: [R-SIG-Finance] Estimate parameters of a Kalman Filter
In-Reply-To: <775348E0-966D-47DA-A914-1C4BB84649F9@ucla.edu>
References: <775348E0-966D-47DA-A914-1C4BB84649F9@ucla.edu>
Message-ID: <10E60A39-7B3D-4B5D-99CC-972B76092DAE@tcd.ie>

There are two tasks involved.  The first is to set up the loglikelihood and the second is the optimisation.  The first is often more time consuming than the second.  They are well documented in the documentation for the packages listed in the various task views. You may find that the package dlmodeler of interest.  This package is a front end on the packages dlm, KFAS and FKF.  If you wish to do your own programming you would gain from looking at the way that they set up the various system matrices.

Best regards
John

Sent from my iPad

On 15 Jun 2011, at 04:52, Noah Silverman <noahsilverman at ucla.edu> wrote:

> This isn't entirely an "R" question, but I thought the group would be the best place to ask.
> 
> 
> I want to consider a Kalman filter on some time series data.  One of the hard parts is estimating the 4-5 parameters for the filter.  I assume some form of EM would be good, but am not clear on how to best implement it.  
> 
> There is probably an R package that will do this automatically, but I'd like to LEARN how to do this manually as it will lead to me developing some more advanced filters.
> 
> Any suggestions?
> 
> --
> Noah Silverman
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
> 


From ustaudinger at gmail.com  Wed Jun 15 10:49:01 2011
From: ustaudinger at gmail.com (Ulrich Staudinger)
Date: Wed, 15 Jun 2011 10:49:01 +0200
Subject: [R-SIG-Finance] Find first trade of day in xts object
In-Reply-To: <1AD0CD5B-5EF8-4533-8B7A-5950AEE40511@ucla.edu>
References: <1AD0CD5B-5EF8-4533-8B7A-5950AEE40511@ucla.edu>
Message-ID: <BANLkTikh45CWPJnrgWmcBeF3UmvpprFCBw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110615/d98c9d19/attachment.pl>

From john.kerpel at gmail.com  Wed Jun 15 14:42:47 2011
From: john.kerpel at gmail.com (John Kerpel)
Date: Wed, 15 Jun 2011 07:42:47 -0500
Subject: [R-SIG-Finance] Estimate parameters of a Kalman Filter
In-Reply-To: <775348E0-966D-47DA-A914-1C4BB84649F9@ucla.edu>
References: <775348E0-966D-47DA-A914-1C4BB84649F9@ucla.edu>
Message-ID: <BANLkTinbUY+qUypX0Jn8bfq=LOh4D2a-oQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110615/54e4c532/attachment.pl>

From matthieu.stigler at gmail.com  Wed Jun 15 15:30:47 2011
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Wed, 15 Jun 2011 15:30:47 +0200
Subject: [R-SIG-Finance] Estimate parameters of a Kalman Filter
In-Reply-To: <BANLkTinbUY+qUypX0Jn8bfq=LOh4D2a-oQ@mail.gmail.com>
References: <775348E0-966D-47DA-A914-1C4BB84649F9@ucla.edu>
	<BANLkTinbUY+qUypX0Jn8bfq=LOh4D2a-oQ@mail.gmail.com>
Message-ID: <4DF8B407.3020900@gmail.com>

Journal of Statistical software has a recent issue on Klaman filter 
(actualy state space):
http://www.jstatsoft.org/v41

and if you look well I think there was another paper in JSS presenting a 
package for Kalman filter..

M

Le 15/06/2011 14:42, John Kerpel a ?crit :
> Try package dlm.
>
> On Tue, Jun 14, 2011 at 10:52 PM, Noah Silverman<noahsilverman at ucla.edu>wrote:
>
>> This isn't entirely an "R" question, but I thought the group would be the
>> best place to ask.
>>
>>
>> I want to consider a Kalman filter on some time series data.  One of the
>> hard parts is estimating the 4-5 parameters for the filter.  I assume some
>> form of EM would be good, but am not clear on how to best implement it.
>>
>> There is probably an R package that will do this automatically, but I'd
>> like to LEARN how to do this manually as it will lead to me developing some
>> more advanced filters.
>>
>> Any suggestions?
>>
>> --
>> Noah Silverman
>> UCLA Department of Statistics
>> 8117 Math Sciences Building
>> Los Angeles, CA 90095
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From gsee000 at gmail.com  Wed Jun 15 16:10:57 2011
From: gsee000 at gmail.com (G See)
Date: Wed, 15 Jun 2011 09:10:57 -0500
Subject: [R-SIG-Finance] Find first trade of day in xts object
In-Reply-To: <BANLkTikh45CWPJnrgWmcBeF3UmvpprFCBw@mail.gmail.com>
References: <1AD0CD5B-5EF8-4533-8B7A-5950AEE40511@ucla.edu>
	<BANLkTikh45CWPJnrgWmcBeF3UmvpprFCBw@mail.gmail.com>
Message-ID: <BANLkTimfwSGpNJJ0ugzfy4jz4=rCeAKfcA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110615/507a1da9/attachment.pl>

From horstrwolf at msn.com  Wed Jun 15 17:12:34 2011
From: horstrwolf at msn.com (Horst R. Wolf)
Date: Wed, 15 Jun 2011 17:12:34 +0200
Subject: [R-SIG-Finance] Package "quantstrat"
Message-ID: <DUB107-w18C686C8CF17B495FEF67BD76B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110615/833ff3a8/attachment.pl>

From daniel.cegielka at gmail.com  Wed Jun 15 17:19:56 2011
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Wed, 15 Jun 2011 17:19:56 +0200
Subject: [R-SIG-Finance] Package "quantstrat"
In-Reply-To: <DUB107-w18C686C8CF17B495FEF67BD76B0@phx.gbl>
References: <DUB107-w18C686C8CF17B495FEF67BD76B0@phx.gbl>
Message-ID: <BANLkTikkaT1h=ygfDgAGXVy1yW=9YaTO8A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110615/672bc346/attachment.pl>

From gsee000 at gmail.com  Wed Jun 15 17:28:19 2011
From: gsee000 at gmail.com (G See)
Date: Wed, 15 Jun 2011 10:28:19 -0500
Subject: [R-SIG-Finance] Package "quantstrat"
In-Reply-To: <BANLkTikkaT1h=ygfDgAGXVy1yW=9YaTO8A@mail.gmail.com>
References: <DUB107-w18C686C8CF17B495FEF67BD76B0@phx.gbl>
	<BANLkTikkaT1h=ygfDgAGXVy1yW=9YaTO8A@mail.gmail.com>
Message-ID: <BANLkTikAm4JNndz10wimW1hcS6QHhH7yuQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110615/9c1bd60c/attachment.pl>

From daniel.cegielka at gmail.com  Wed Jun 15 17:36:59 2011
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Wed, 15 Jun 2011 17:36:59 +0200
Subject: [R-SIG-Finance] Package "quantstrat"
In-Reply-To: <BANLkTikAm4JNndz10wimW1hcS6QHhH7yuQ@mail.gmail.com>
References: <DUB107-w18C686C8CF17B495FEF67BD76B0@phx.gbl>
	<BANLkTikkaT1h=ygfDgAGXVy1yW=9YaTO8A@mail.gmail.com>
	<BANLkTikAm4JNndz10wimW1hcS6QHhH7yuQ@mail.gmail.com>
Message-ID: <BANLkTik497vgimvJ8LymR5+21Nr2ht-30Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110615/76656291/attachment.pl>

From jeffrey.ryan at lemnica.com  Wed Jun 15 17:42:01 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Wed, 15 Jun 2011 10:42:01 -0500
Subject: [R-SIG-Finance] Find first trade of day in xts object
In-Reply-To: <1AD0CD5B-5EF8-4533-8B7A-5950AEE40511@ucla.edu>
References: <1AD0CD5B-5EF8-4533-8B7A-5950AEE40511@ucla.edu>
Message-ID: <BANLkTimh4cznx0Cgh3SHaPs==m8GOsuFDA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110615/72ac150b/attachment.pl>

From gsee000 at gmail.com  Wed Jun 15 18:04:36 2011
From: gsee000 at gmail.com (G See)
Date: Wed, 15 Jun 2011 11:04:36 -0500
Subject: [R-SIG-Finance] Find first trade of day in xts object
In-Reply-To: <BANLkTimh4cznx0Cgh3SHaPs==m8GOsuFDA@mail.gmail.com>
References: <1AD0CD5B-5EF8-4533-8B7A-5950AEE40511@ucla.edu>
	<BANLkTimh4cznx0Cgh3SHaPs==m8GOsuFDA@mail.gmail.com>
Message-ID: <BANLkTikMD8jsna1bzQf2z3u2FdS56GN=eA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110615/9cd973c1/attachment.pl>

From jeffrey.ryan at lemnica.com  Wed Jun 15 18:23:10 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Wed, 15 Jun 2011 11:23:10 -0500
Subject: [R-SIG-Finance] Find first trade of day in xts object
In-Reply-To: <BANLkTikMD8jsna1bzQf2z3u2FdS56GN=eA@mail.gmail.com>
References: <1AD0CD5B-5EF8-4533-8B7A-5950AEE40511@ucla.edu>
	<BANLkTimh4cznx0Cgh3SHaPs==m8GOsuFDA@mail.gmail.com>
	<BANLkTikMD8jsna1bzQf2z3u2FdS56GN=eA@mail.gmail.com>
Message-ID: <BANLkTi=3fEMRfbmMEvWcGFS5Ny4L7sjfmg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110615/d5361d87/attachment.pl>

From daniel.cegielka at gmail.com  Wed Jun 15 19:01:24 2011
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Wed, 15 Jun 2011 19:01:24 +0200
Subject: [R-SIG-Finance] Package "quantstrat"
In-Reply-To: <DUB107-w178A3C486BD2727503CF78D76B0@phx.gbl>
References: <DUB107-w18C686C8CF17B495FEF67BD76B0@phx.gbl>
	<BANLkTikkaT1h=ygfDgAGXVy1yW=9YaTO8A@mail.gmail.com>
	<BANLkTikAm4JNndz10wimW1hcS6QHhH7yuQ@mail.gmail.com>
	<BANLkTik497vgimvJ8LymR5+21Nr2ht-30Q@mail.gmail.com>
	<DUB107-w178A3C486BD2727503CF78D76B0@phx.gbl>
Message-ID: <BANLkTik9fG5XH5heoxgbNbYKT6ng4kszNA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110615/031642e3/attachment.pl>

From noahsilverman at ucla.edu  Thu Jun 16 21:08:34 2011
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Thu, 16 Jun 2011 12:08:34 -0700
Subject: [R-SIG-Finance] Volume stats and 5 minute bars
Message-ID: <1FBDDEBD-B7E1-4322-B2AC-37E4B1C13C62@ucla.edu>

Hi,

I have some raw tick data. (Individual trades with 1 second resolution.)

I'd like to convert them to 5 minute bars - that is easy enough with the xts package.  

However, I'd also like to generate some other summary statistics for each 5 minute bar.  total volume, tick count, up ticks, down ticks, etc.

Any suggestions on an easy way to do this?

Thanks!


--
Noah Silverman
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095


From noahsilverman at ucla.edu  Thu Jun 16 21:25:14 2011
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Thu, 16 Jun 2011 12:25:14 -0700
Subject: [R-SIG-Finance] Align 5 minute bars
Message-ID: <A93F93DC-C6B4-4A8C-A830-65B654DD41BD@ucla.edu>

And another question...

When I use the xts function to.minutes5(), I get a nice OHLC summary, BUT the time stamps are "messy".  Since my first and/or last ticks are not exactly on the minute, every 5 minute bar is now on some mid-minute frequency. 

Example:

to.minutes5(ds, indexAt="endof")
                    ds.Open ds.High ds.Low ds.Close ds.Volume
2007-01-01 18:34:44  882.50  883.75 880.50   880.50        83
2007-01-01 18:39:46  880.75  881.00 880.00   880.50        18
2007-01-01 18:44:52  880.25  880.25 879.50   880.00        25
2007-01-01 18:49:03  880.25  881.75 880.25   881.50        83
2007-01-01 18:52:11  881.50  881.50 881.50   881.50         9



Ideally, I'd love to have my bars aligned with round minute numbers.  i.e.
18:30
18:35
18:40
etc...

Any suggestions?

--
Noah Silverman
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095


From jeff.a.ryan at gmail.com  Thu Jun 16 21:40:39 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Thu, 16 Jun 2011 14:40:39 -0500
Subject: [R-SIG-Finance] Align 5 minute bars
In-Reply-To: <A93F93DC-C6B4-4A8C-A830-65B654DD41BD@ucla.edu>
References: <A93F93DC-C6B4-4A8C-A830-65B654DD41BD@ucla.edu>
Message-ID: <67F47F37-02C9-4C0A-A7DB-EA9928E241F4@gmail.com>

Look at align.time. Bars are stamped to the last obs in the period in to.period. 

HTH
Jeff

Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com

www.lemnica.com

On Jun 16, 2011, at 2:25 PM, Noah Silverman <noahsilverman at ucla.edu> wrote:

> And another question...
> 
> When I use the xts function to.minutes5(), I get a nice OHLC summary, BUT the time stamps are "messy".  Since my first and/or last ticks are not exactly on the minute, every 5 minute bar is now on some mid-minute frequency. 
> 
> Example:
> 
> to.minutes5(ds, indexAt="endof")
>                    ds.Open ds.High ds.Low ds.Close ds.Volume
> 2007-01-01 18:34:44  882.50  883.75 880.50   880.50        83
> 2007-01-01 18:39:46  880.75  881.00 880.00   880.50        18
> 2007-01-01 18:44:52  880.25  880.25 879.50   880.00        25
> 2007-01-01 18:49:03  880.25  881.75 880.25   881.50        83
> 2007-01-01 18:52:11  881.50  881.50 881.50   881.50         9
> 
> 
> 
> Ideally, I'd love to have my bars aligned with round minute numbers.  i.e.
> 18:30
> 18:35
> 18:40
> etc...
> 
> Any suggestions?
> 
> --
> Noah Silverman
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From josh.m.ulrich at gmail.com  Thu Jun 16 22:08:22 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 16 Jun 2011 15:08:22 -0500
Subject: [R-SIG-Finance] Volume stats and 5 minute bars
In-Reply-To: <1FBDDEBD-B7E1-4322-B2AC-37E4B1C13C62@ucla.edu>
References: <1FBDDEBD-B7E1-4322-B2AC-37E4B1C13C62@ucla.edu>
Message-ID: <BANLkTim+xkdGNXFWXU5CBPFvEgyH6CWz=A@mail.gmail.com>

On Thu, Jun 16, 2011 at 2:08 PM, Noah Silverman <noahsilverman at ucla.edu> wrote:
> Hi,
>
> I have some raw tick data. (Individual trades with 1 second resolution.)
>
> I'd like to convert them to 5 minute bars - that is easy enough with the xts package.
>
> However, I'd also like to generate some other summary statistics for each 5 minute bar. ?total volume, tick count, up ticks, down ticks, etc.
>
> Any suggestions on an easy way to do this?
>
Look at the source for apply.daily and write an analogous
apply.minutely function (with an arg to specify the number of
minutes).  Or just use period.apply:

R> period.apply(x, endpoints(x, "minutes", 5), function(y) c(mean(y), sd(y)) )

> Thanks!
>
>
> --
> Noah Silverman
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>

HTH,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From noahsilverman at ucla.edu  Thu Jun 16 22:29:17 2011
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Thu, 16 Jun 2011 13:29:17 -0700
Subject: [R-SIG-Finance] Align 5 minute bars
In-Reply-To: <67F47F37-02C9-4C0A-A7DB-EA9928E241F4@gmail.com>
References: <A93F93DC-C6B4-4A8C-A830-65B654DD41BD@ucla.edu>
	<67F47F37-02C9-4C0A-A7DB-EA9928E241F4@gmail.com>
Message-ID: <3442D06A-7431-4168-B73D-FDB2B8ED51A7@ucla.edu>

Jeff,

If I understand the documentation correctly, align.time just shifts the time stamps of the existing bars.  That sounds dangerous as the individual ticks aren't moving.

For example, if a bar is currently set at:   18:39.46
We have a transaction at 18:39:48
As it stands, that transaction is in the *next* bar that would start at 18:39.47
If I use align.time, it will shift the bar to 18:40 BUT since we already have the OHLC summary, what happens to that transaction?


--
Noah Silverman
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095

On Jun 16, 2011, at 12:40 PM, Jeff Ryan wrote:

> Look at align.time. Bars are stamped to the last obs in the period in to.period. 
> 
> HTH
> Jeff
> 
> Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com
> 
> www.lemnica.com
> 
> On Jun 16, 2011, at 2:25 PM, Noah Silverman <noahsilverman at ucla.edu> wrote:
> 
>> And another question...
>> 
>> When I use the xts function to.minutes5(), I get a nice OHLC summary, BUT the time stamps are "messy".  Since my first and/or last ticks are not exactly on the minute, every 5 minute bar is now on some mid-minute frequency. 
>> 
>> Example:
>> 
>> to.minutes5(ds, indexAt="endof")
>>                   ds.Open ds.High ds.Low ds.Close ds.Volume
>> 2007-01-01 18:34:44  882.50  883.75 880.50   880.50        83
>> 2007-01-01 18:39:46  880.75  881.00 880.00   880.50        18
>> 2007-01-01 18:44:52  880.25  880.25 879.50   880.00        25
>> 2007-01-01 18:49:03  880.25  881.75 880.25   881.50        83
>> 2007-01-01 18:52:11  881.50  881.50 881.50   881.50         9
>> 
>> 
>> 
>> Ideally, I'd love to have my bars aligned with round minute numbers.  i.e.
>> 18:30
>> 18:35
>> 18:40
>> etc...
>> 
>> Any suggestions?
>> 
>> --
>> Noah Silverman
>> UCLA Department of Statistics
>> 8117 Math Sciences Building
>> Los Angeles, CA 90095
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.


From idris.raja at gmail.com  Thu Jun 16 23:19:26 2011
From: idris.raja at gmail.com (Idris Raja)
Date: Thu, 16 Jun 2011 14:19:26 -0700
Subject: [R-SIG-Finance] Add Bollinger Bands to Portfolio Equity Curve
Message-ID: <BANLkTinTU8Hx-zJscu7hAfX8W_sLH7cOsg@mail.gmail.com>

Hi all.

I am trying to add Bollinger Bands to an equity curve of one of my own
portfolios.

Is there a function in an R library to do this?

Cheers


From daniel.cegielka at gmail.com  Thu Jun 16 23:23:07 2011
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Thu, 16 Jun 2011 23:23:07 +0200
Subject: [R-SIG-Finance] Add Bollinger Bands to Portfolio Equity Curve
In-Reply-To: <BANLkTinTU8Hx-zJscu7hAfX8W_sLH7cOsg@mail.gmail.com>
References: <BANLkTinTU8Hx-zJscu7hAfX8W_sLH7cOsg@mail.gmail.com>
Message-ID: <BANLkTikh3hMtYd_hbgwv83h+59XUAyTkaw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110616/cdc2bd52/attachment.pl>

From pgilbert at bank-banque-canada.ca  Thu Jun 16 23:38:04 2011
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 16 Jun 2011 21:38:04 +0000
Subject: [R-SIG-Finance] Estimate parameters of a Kalman Filter
In-Reply-To: <4DF8B407.3020900@gmail.com>
References: <775348E0-966D-47DA-A914-1C4BB84649F9@ucla.edu>
	<BANLkTinbUY+qUypX0Jn8bfq=LOh4D2a-oQ@mail.gmail.com>
	<4DF8B407.3020900@gmail.com>
Message-ID: <6441154A9FF1CD4386AF4ABF141A056D215ADAC5@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>

There was also a review of various R packages for Kalman filtering, including a good explanation of the filter, in http://www.jstatsoft.org/v39/i02 .

Paul

> -----Original Message-----
> From: r-sig-finance-bounces at r-project.org [mailto:r-sig-finance-
> bounces at r-project.org] On Behalf Of Matthieu Stigler
> Sent: June 15, 2011 9:31 AM
> To: John Kerpel
> Cc: r-sig-finance at r-project.org
> Subject: Re: [R-SIG-Finance] Estimate parameters of a Kalman Filter
> 
> Journal of Statistical software has a recent issue on Klaman filter
> (actualy state space):
> http://www.jstatsoft.org/v41
> 
> and if you look well I think there was another paper in JSS presenting
> a
> package for Kalman filter..
> 
> M
> 
> Le 15/06/2011 14:42, John Kerpel a ?crit :
> > Try package dlm.
> >
> > On Tue, Jun 14, 2011 at 10:52 PM, Noah
> Silverman<noahsilverman at ucla.edu>wrote:
> >
> >> This isn't entirely an "R" question, but I thought the group would
> be the
> >> best place to ask.
> >>
> >>
> >> I want to consider a Kalman filter on some time series data.  One of
> the
> >> hard parts is estimating the 4-5 parameters for the filter.  I
> assume some
> >> form of EM would be good, but am not clear on how to best implement
> it.
> >>
> >> There is probably an R package that will do this automatically, but
> I'd
> >> like to LEARN how to do this manually as it will lead to me
> developing some
> >> more advanced filters.
> >>
> >> Any suggestions?
> >>
> >> --
> >> Noah Silverman
> >> UCLA Department of Statistics
> >> 8117 Math Sciences Building
> >> Los Angeles, CA 90095
> >>
> >> _______________________________________________
> >> R-SIG-Finance at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >> -- Subscriber-posting only. If you want to post, subscribe first.
> >> -- Also note that this is not the r-help list where general R
> questions
> >> should go.
> >>
> > 	[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R
> questions should go.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential in...{{dropped:26}}


From jeffrey.ryan at lemnica.com  Fri Jun 17 00:10:56 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Thu, 16 Jun 2011 17:10:56 -0500
Subject: [R-SIG-Finance] Add Bollinger Bands to Portfolio Equity Curve
In-Reply-To: <BANLkTinTU8Hx-zJscu7hAfX8W_sLH7cOsg@mail.gmail.com>
References: <BANLkTinTU8Hx-zJscu7hAfX8W_sLH7cOsg@mail.gmail.com>
Message-ID: <BANLkTinWOdcfL6qjEyr7jzob_TAWKnWsTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110616/20fc2254/attachment.pl>

From brian at braverock.com  Fri Jun 17 01:19:06 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 16 Jun 2011 18:19:06 -0500
Subject: [R-SIG-Finance] Align 5 minute bars
In-Reply-To: <3442D06A-7431-4168-B73D-FDB2B8ED51A7@ucla.edu>
References: <A93F93DC-C6B4-4A8C-A830-65B654DD41BD@ucla.edu>
	<67F47F37-02C9-4C0A-A7DB-EA9928E241F4@gmail.com>
	<3442D06A-7431-4168-B73D-FDB2B8ED51A7@ucla.edu>
Message-ID: <1308266346.22117.423.camel@brian-desktop>

Your trade would have been *in* the bar.

typically, you'd use something of the type:

align.time(to.period(x,...)...) 

to first aggregate your trades into bars, and *then* align the bars.
This doesn't create any look-ahead bias.

  - Brian

On Thu, 2011-06-16 at 13:29 -0700, Noah Silverman wrote:
> Jeff,
> 
> If I understand the documentation correctly, align.time just shifts the time stamps of the existing bars.  That sounds dangerous as the individual ticks aren't moving.
> 
> For example, if a bar is currently set at:   18:39.46
> We have a transaction at 18:39:48
> As it stands, that transaction is in the *next* bar that would start at 18:39.47
> If I use align.time, it will shift the bar to 18:40 BUT since we already have the OHLC summary, what happens to that transaction?
> 
> 
> --
> Noah Silverman
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
> 
> On Jun 16, 2011, at 12:40 PM, Jeff Ryan wrote:
> 
> > Look at align.time. Bars are stamped to the last obs in the period in to.period. 
> > 
> > HTH
> > Jeff
> > 
> > Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com
> > 
> > www.lemnica.com
> > 
> > On Jun 16, 2011, at 2:25 PM, Noah Silverman <noahsilverman at ucla.edu> wrote:
> > 
> >> And another question...
> >> 
> >> When I use the xts function to.minutes5(), I get a nice OHLC summary, BUT the time stamps are "messy".  Since my first and/or last ticks are not exactly on the minute, every 5 minute bar is now on some mid-minute frequency. 
> >> 
> >> Example:
> >> 
> >> to.minutes5(ds, indexAt="endof")
> >>                   ds.Open ds.High ds.Low ds.Close ds.Volume
> >> 2007-01-01 18:34:44  882.50  883.75 880.50   880.50        83
> >> 2007-01-01 18:39:46  880.75  881.00 880.00   880.50        18
> >> 2007-01-01 18:44:52  880.25  880.25 879.50   880.00        25
> >> 2007-01-01 18:49:03  880.25  881.75 880.25   881.50        83
> >> 2007-01-01 18:52:11  881.50  881.50 881.50   881.50         9
> >> 
> >> 
> >> 
> >> Ideally, I'd love to have my bars aligned with round minute numbers.  i.e.
> >> 18:30
> >> 18:35
> >> 18:40
> >> etc...
> >> 
> >> Any suggestions?
> >> 
> >> --
> >> Noah Silverman
> >> UCLA Department of Statistics
> >> 8117 Math Sciences Building
> >> Los Angeles, CA 90095
> >> 
> >> _______________________________________________
> >> R-SIG-Finance at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >> -- Subscriber-posting only. If you want to post, subscribe first.
> >> -- Also note that this is not the r-help list where general R questions should go.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From brian at braverock.com  Fri Jun 17 02:18:42 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 16 Jun 2011 19:18:42 -0500
Subject: [R-SIG-Finance] Volume stats and 5 minute bars
In-Reply-To: <1FBDDEBD-B7E1-4322-B2AC-37E4B1C13C62@ucla.edu>
References: <1FBDDEBD-B7E1-4322-B2AC-37E4B1C13C62@ucla.edu>
Message-ID: <1308269922.22117.475.camel@brian-desktop>

On Thu, 2011-06-16 at 12:08 -0700, Noah Silverman wrote:
> Hi,
> 
> I have some raw tick data. (Individual trades with 1 second resolution.)

1 second trade data is not raw tick data.  Just to be clear on
terminology.

> I'd like to convert them to 5 minute bars - that is easy enough with the xts package.  

yes, to.period()

> However, I'd also like to generate some other summary statistics for each 5 minute bar.  total volume, tick count, up ticks, down ticks, etc.

use aggregate() or one of the apply functions on endpoints() using your
five minute endpoints, cbind that aggregation to your 5 minute bars.

then use align.time on the resulting object to line it up to the next
even minute.

> Any suggestions on an easy way to do this?
> 
> Thanks!
> 
> 
> --
> Noah Silverman
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From noahsilverman at ucla.edu  Fri Jun 17 04:51:25 2011
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Thu, 16 Jun 2011 19:51:25 -0700
Subject: [R-SIG-Finance] Volume stats and 5 minute bars
In-Reply-To: <1308269922.22117.475.camel@brian-desktop>
References: <1FBDDEBD-B7E1-4322-B2AC-37E4B1C13C62@ucla.edu>
	<1308269922.22117.475.camel@brian-desktop>
Message-ID: <C38F800E-C92D-40DD-A6CF-0EE2275EA772@ucla.edu>

Nice,

Thanks!

--
Noah Silverman
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095

On Jun 16, 2011, at 5:18 PM, Brian G. Peterson wrote:

> On Thu, 2011-06-16 at 12:08 -0700, Noah Silverman wrote:
>> Hi,
>> 
>> I have some raw tick data. (Individual trades with 1 second resolution.)
> 
> 1 second trade data is not raw tick data.  Just to be clear on
> terminology.
> 
>> I'd like to convert them to 5 minute bars - that is easy enough with the xts package.  
> 
> yes, to.period()
> 
>> However, I'd also like to generate some other summary statistics for each 5 minute bar.  total volume, tick count, up ticks, down ticks, etc.
> 
> use aggregate() or one of the apply functions on endpoints() using your
> five minute endpoints, cbind that aggregation to your 5 minute bars.
> 
> then use align.time on the resulting object to line it up to the next
> even minute.
> 
>> Any suggestions on an easy way to do this?
>> 
>> Thanks!
>> 
>> 
>> --
>> Noah Silverman
>> UCLA Department of Statistics
>> 8117 Math Sciences Building
>> Los Angeles, CA 90095
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
> 
> -- 
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
> 


From noahsilverman at ucla.edu  Fri Jun 17 04:54:59 2011
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Thu, 16 Jun 2011 19:54:59 -0700
Subject: [R-SIG-Finance] Align 5 minute bars
In-Reply-To: <1308266346.22117.423.camel@brian-desktop>
References: <A93F93DC-C6B4-4A8C-A830-65B654DD41BD@ucla.edu>
	<67F47F37-02C9-4C0A-A7DB-EA9928E241F4@gmail.com>
	<3442D06A-7431-4168-B73D-FDB2B8ED51A7@ucla.edu>
	<1308266346.22117.423.camel@brian-desktop>
Message-ID: <62B69714-9B4A-4D7E-B2A4-DB2CFDF780BD@ucla.edu>

Good suggestion.  Exactly what I want.

However, in another message you suggested using aggregate or apply to generate my summary statistics.  I would need to do that before using to.period.  But, I want the summary states per-period.  (For example - number of transactions, number of up-ticks, etc.) 

The only way I can see to do this is the "long way".

1) Determine the endpoints of each bar, but don't convert to.period yet
2) Loop through each bar and generate the statistics from the transactions in that bar
3) Create a new data structure to hold the bar summaries

There must be a cleaner way.  Ideas?

--
Noah Silverman
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095

On Jun 16, 2011, at 4:19 PM, Brian G. Peterson wrote:

> Your trade would have been *in* the bar.
> 
> typically, you'd use something of the type:
> 
> align.time(to.period(x,...)...) 
> 
> to first aggregate your trades into bars, and *then* align the bars.
> This doesn't create any look-ahead bias.
> 
>  - Brian
> 
> On Thu, 2011-06-16 at 13:29 -0700, Noah Silverman wrote:
>> Jeff,
>> 
>> If I understand the documentation correctly, align.time just shifts the time stamps of the existing bars.  That sounds dangerous as the individual ticks aren't moving.
>> 
>> For example, if a bar is currently set at:   18:39.46
>> We have a transaction at 18:39:48
>> As it stands, that transaction is in the *next* bar that would start at 18:39.47
>> If I use align.time, it will shift the bar to 18:40 BUT since we already have the OHLC summary, what happens to that transaction?
>> 
>> 
>> --
>> Noah Silverman
>> UCLA Department of Statistics
>> 8117 Math Sciences Building
>> Los Angeles, CA 90095
>> 
>> On Jun 16, 2011, at 12:40 PM, Jeff Ryan wrote:
>> 
>>> Look at align.time. Bars are stamped to the last obs in the period in to.period. 
>>> 
>>> HTH
>>> Jeff
>>> 
>>> Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com
>>> 
>>> www.lemnica.com
>>> 
>>> On Jun 16, 2011, at 2:25 PM, Noah Silverman <noahsilverman at ucla.edu> wrote:
>>> 
>>>> And another question...
>>>> 
>>>> When I use the xts function to.minutes5(), I get a nice OHLC summary, BUT the time stamps are "messy".  Since my first and/or last ticks are not exactly on the minute, every 5 minute bar is now on some mid-minute frequency. 
>>>> 
>>>> Example:
>>>> 
>>>> to.minutes5(ds, indexAt="endof")
>>>>                  ds.Open ds.High ds.Low ds.Close ds.Volume
>>>> 2007-01-01 18:34:44  882.50  883.75 880.50   880.50        83
>>>> 2007-01-01 18:39:46  880.75  881.00 880.00   880.50        18
>>>> 2007-01-01 18:44:52  880.25  880.25 879.50   880.00        25
>>>> 2007-01-01 18:49:03  880.25  881.75 880.25   881.50        83
>>>> 2007-01-01 18:52:11  881.50  881.50 881.50   881.50         9
>>>> 
>>>> 
>>>> 
>>>> Ideally, I'd love to have my bars aligned with round minute numbers.  i.e.
>>>> 18:30
>>>> 18:35
>>>> 18:40
>>>> etc...
>>>> 
>>>> Any suggestions?
>>>> 
>>>> --
>>>> Noah Silverman
>>>> UCLA Department of Statistics
>>>> 8117 Math Sciences Building
>>>> Los Angeles, CA 90095
>>>> 
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions should go.
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
> 
> -- 
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
> 


From brian at braverock.com  Fri Jun 17 05:31:07 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 16 Jun 2011 22:31:07 -0500
Subject: [R-SIG-Finance] Align 5 minute bars
In-Reply-To: <62B69714-9B4A-4D7E-B2A4-DB2CFDF780BD@ucla.edu>
References: <A93F93DC-C6B4-4A8C-A830-65B654DD41BD@ucla.edu>
	<67F47F37-02C9-4C0A-A7DB-EA9928E241F4@gmail.com>
	<3442D06A-7431-4168-B73D-FDB2B8ED51A7@ucla.edu>
	<1308266346.22117.423.camel@brian-desktop>
	<62B69714-9B4A-4D7E-B2A4-DB2CFDF780BD@ucla.edu>
Message-ID: <1308281467.22117.484.camel@brian-desktop>

On Thu, 2011-06-16 at 19:54 -0700, Noah Silverman wrote:
> Good suggestion.  Exactly what I want.
> 
> However, in another message you suggested using aggregate or apply to generate my summary statistics.  I would need to do that before using to.period.  But, I want the summary states per-period.  (For example - number of transactions, number of up-ticks, etc.) 
> 
> The only way I can see to do this is the "long way".

Sort of the 'long way', I guess.

> 1) Determine the endpoints of each bar, but don't convert to.period yet
> 2) Loop through each bar and generate the statistics from the transactions in that bar
> 3) Create a new data structure to hold the bar summaries

Here's an approach you might consider a little better.

1. run to.period on the trade prices to create your bars, 
2. assign the bars to a new variable
3. on the original data, period.apply() to generate each column of
summary stats
4. cbind each of these to the bars

You could do this all in one line, but that seems a little silly...

> There must be a cleaner way.  Ideas?
> 
> --
> Noah Silverman
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
> 
> On Jun 16, 2011, at 4:19 PM, Brian G. Peterson wrote:
> 
> > Your trade would have been *in* the bar.
> > 
> > typically, you'd use something of the type:
> > 
> > align.time(to.period(x,...)...) 
> > 
> > to first aggregate your trades into bars, and *then* align the bars.
> > This doesn't create any look-ahead bias.
> > 
> >  - Brian
> > 
> > On Thu, 2011-06-16 at 13:29 -0700, Noah Silverman wrote:
> >> Jeff,
> >> 
> >> If I understand the documentation correctly, align.time just shifts the time stamps of the existing bars.  That sounds dangerous as the individual ticks aren't moving.
> >> 
> >> For example, if a bar is currently set at:   18:39.46
> >> We have a transaction at 18:39:48
> >> As it stands, that transaction is in the *next* bar that would start at 18:39.47
> >> If I use align.time, it will shift the bar to 18:40 BUT since we already have the OHLC summary, what happens to that transaction?
> >> 
> >> 
> >> --
> >> Noah Silverman
> >> UCLA Department of Statistics
> >> 8117 Math Sciences Building
> >> Los Angeles, CA 90095
> >> 
> >> On Jun 16, 2011, at 12:40 PM, Jeff Ryan wrote:
> >> 
> >>> Look at align.time. Bars are stamped to the last obs in the period in to.period. 
> >>> 
> >>> HTH
> >>> Jeff
> >>> 
> >>> Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com
> >>> 
> >>> www.lemnica.com
> >>> 
> >>> On Jun 16, 2011, at 2:25 PM, Noah Silverman <noahsilverman at ucla.edu> wrote:
> >>> 
> >>>> And another question...
> >>>> 
> >>>> When I use the xts function to.minutes5(), I get a nice OHLC summary, BUT the time stamps are "messy".  Since my first and/or last ticks are not exactly on the minute, every 5 minute bar is now on some mid-minute frequency. 
> >>>> 
> >>>> Example:
> >>>> 
> >>>> to.minutes5(ds, indexAt="endof")
> >>>>                  ds.Open ds.High ds.Low ds.Close ds.Volume
> >>>> 2007-01-01 18:34:44  882.50  883.75 880.50   880.50        83
> >>>> 2007-01-01 18:39:46  880.75  881.00 880.00   880.50        18
> >>>> 2007-01-01 18:44:52  880.25  880.25 879.50   880.00        25
> >>>> 2007-01-01 18:49:03  880.25  881.75 880.25   881.50        83
> >>>> 2007-01-01 18:52:11  881.50  881.50 881.50   881.50         9
> >>>> 
> >>>> 
> >>>> 
> >>>> Ideally, I'd love to have my bars aligned with round minute numbers.  i.e.
> >>>> 18:30
> >>>> 18:35
> >>>> 18:40
> >>>> etc...
> >>>> 
> >>>> Any suggestions?
> >>>> 
> >>>> --
> >>>> Noah Silverman
> >>>> UCLA Department of Statistics
> >>>> 8117 Math Sciences Building
> >>>> Los Angeles, CA 90095
> >>>> 
> >>>> _______________________________________________
> >>>> R-SIG-Finance at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >>>> -- Subscriber-posting only. If you want to post, subscribe first.
> >>>> -- Also note that this is not the r-help list where general R questions should go.
> >> 
> >> _______________________________________________
> >> R-SIG-Finance at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >> -- Subscriber-posting only. If you want to post, subscribe first.
> >> -- Also note that this is not the r-help list where general R questions should go.
> > 
> > -- 
> > Brian G. Peterson
> > http://braverock.com/brian/
> > Ph: 773-459-4973
> > IM: bgpbraverock
> > 
> 

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From stef_der_chef at yahoo.de  Fri Jun 17 08:20:31 2011
From: stef_der_chef at yahoo.de (stefan strunz)
Date: Fri, 17 Jun 2011 07:20:31 +0100 (BST)
Subject: [R-SIG-Finance] Berkowitz Truncated Likelihood Ratio tail Test
Message-ID: <428313.73833.qm@web27401.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110617/3828e5f3/attachment.pl>

From bbands at gmail.com  Fri Jun 17 18:25:34 2011
From: bbands at gmail.com (BBands)
Date: Fri, 17 Jun 2011 09:25:34 -0700
Subject: [R-SIG-Finance] Add Bollinger Bands to Portfolio Equity Curve
In-Reply-To: <BANLkTinTU8Hx-zJscu7hAfX8W_sLH7cOsg@mail.gmail.com>
References: <BANLkTinTU8Hx-zJscu7hAfX8W_sLH7cOsg@mail.gmail.com>
Message-ID: <BANLkTi==TkEo0Qpy_Bo_9jPxJw7RKQPXuA@mail.gmail.com>

On Thu, Jun 16, 2011 at 2:19 PM, Idris Raja <idris.raja at gmail.com> wrote:
> Hi all.
>
> I am trying to add Bollinger Bands to an equity curve of one of my own
> portfolios.

Wherever did you get that idea? ;-) The first two areas beyond price
which I explored using Bollinger Bands in were indicators -- replacing
fixed levels of significance like 70 and 30 or 80 and 20 with BBs --
and equity curves.

Enjoy,

    John
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.


From chd850 at gmail.com  Fri Jun 17 19:38:51 2011
From: chd850 at gmail.com (Hungte (Stanley) Chu)
Date: Fri, 17 Jun 2011 21:38:51 +0400
Subject: [R-SIG-Finance] quantmod - chart object (chob)
Message-ID: <30DD76E5-E76C-43F3-9CC6-60B201B838AE@gmail.com>

Hi everyone, 

I am curious that if I can collect a list of chob objects and later tile these plots in a pdf file. I have a function to handle this for r plot objects, but I am having trouble with chob. In simple words, print(chob) does not work. Can anyone point me a direction? 

Thanks,
Stanley


From alexios at 4dscape.com  Sat Jun 18 14:42:07 2011
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sat, 18 Jun 2011 13:42:07 +0100
Subject: [R-SIG-Finance] Berkowitz Truncated Likelihood Ratio tail Test
In-Reply-To: <428313.73833.qm@web27401.mail.ukl.yahoo.com>
References: <428313.73833.qm@web27401.mail.ukl.yahoo.com>
Message-ID: <4DFC9D1F.8050006@4dscape.com>

Stefan,

I suggest you have a look at Kevin Dowd's paper (?Backtesting Risk
Models within a Standard Normality Framework", and available on his webpage:
http://web.me.com/kevindowd1958/web.me.com_kevindowd1958_Site/Financial_risk_management.html).
Section 3 on the truncated distribution
is quite informative on the 'proper' implementation of the Berkowitz
test to the tail data.

Best,

Alexios

On 6/17/2011 7:20 AM, stefan strunz wrote:
> Hi guys,
>
> I'm getting quite desperate here and I hope you could help me out! I am trying to implement the tail Likelihood Ratio Test, that Berkowitz describes in his 2001 Paper "Testing Density Forecasts, with Applications to Risk Management", which can be found here:
>
> http://www.ims.nus.edu.sg/Programs/econometrics/files/kw_ref_2.pdf
>
> I know that Alexios has implemeneted Berkowitz "normal" LR test (see Equation (4) in rgarch (many thanks for that Alexios!) but I wanted to implement the one on page 469. It basically tests if the density forecasts were good in the tail, not on the whole distribution. The formula seems pretty simple and I think that I understand the concept, however, when I try to implement it - I get negative Likehood Ratios (see the histogram at the end of the code)! It would be really great if someone can get a fresh look at it and tell me where my error is. In particular, I am not sure that I've implemented Formula (9) on page 469 correctly. The way I see it, the first sum, sums all Z* which are below VAR and the second sum is just a constant * logarithm of the cdf.
>
> Here is my commented code:
>
> #I calculate 1000 Likelihood ratios, hence the sapply. But you can just run the inner part #for one example#
>
>   results <-  sapply(1:1000,function(x){ 
>
>     #generating some data which has to be forecasted
>     data_to_forecast<- rnorm(1000,0,1)        
>
>      #creating the probability integral transformations. 
>      z_1 <- pnorm(data_to_forecast,0,1)
>
>      #check: it has to be uniformly distributed, which it is.
>      #hist(z_1)
>
>      #creating the inverse (see page 467)
>      zt_norm <- qnorm(z_1)
>
>      #cutting off the VAR violations
>    
>      VAR <- qnorm(0.05)
>
>      zt_star <- NULL
>     
>     #creating the new variable z*, see page 469
>     for(i in 1:length(zt_norm))
>     {
>         if(zt_norm[i] >=  -1.64){zt_star[i] = VAR}  #if its bigger than VAR, just use VAR
>         else{
>             zt_star[i] = zt_norm[i]      #if it is smaller, use the realized value
>         }}
>    ##############
>    #implementing formula (9)
>    ############
>     
>     #all the Z* which are smaller than VAR
>     z_tail <- zt_star[zt_star < VAR]
>     
>     #length of the vector which contains all the Z* which are greater than VAR
>     length_z_nontail <- length(zt_norm) - length(z_tail)
>     
>     #unrestricted likelihood
>     likeun <- (-length(z_tail)/2*(log(2*pi*var(zt_norm))) - sum((z_tail -    mean(zt_norm))^2/(2*sd(zt_norm))) +
>                 length_z_nontail*(log(1-pnorm((VAR-mean(zt_norm))/sd(zt_norm)))))
>
>     #restricted likelihood
>     likere <- (-length(z_tail)/2*(log(2*pi*1)) - sum((z_tail - 0)^2/(2*1)) +
>                 length_z_nontail*(log(1-pnorm((VAR-0)/1))))
>     
>     #the likelihood ratio
>           2*(likeun-likere)
>   })
>
>   #Problem: Sometimes the likelihood of the restricted model is higher than that of the   #unrestricted! Which cannot be, according to theory (see Greene 2003 f.ex). So the ratio is #not chi squared distributed then.
>   hist(results)
>
> Many thanks in advance!
>
> Regards,
>
> Stefan
>
>
>
>
>     
>
>
>      
>
> 	[[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From brian at braverock.com  Fri Jun 17 20:10:29 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 17 Jun 2011 13:10:29 -0500
Subject: [R-SIG-Finance] quantmod - chart object (chob)
In-Reply-To: <30DD76E5-E76C-43F3-9CC6-60B201B838AE@gmail.com>
References: <30DD76E5-E76C-43F3-9CC6-60B201B838AE@gmail.com>
Message-ID: <1308334229.2011.4.camel@brian-rcg>

Using layout() is possible with the newer chart_Series, but not with the
older chartSeries.  The chob objects are different too, and not easy to
manipulate.

On Fri, 2011-06-17 at 21:38 +0400, Hungte (Stanley) Chu wrote:
> Hi everyone, 
> 
> I am curious that if I can collect a list of chob objects and later tile these plots in a pdf file. I have a function to handle this for r plot objects, but I am having trouble with chob. In simple words, print(chob) does not work. Can anyone point me a direction? 
> 
> Thanks,
> Stanley
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From st.helldiver at googlemail.com  Sat Jun 18 18:16:22 2011
From: st.helldiver at googlemail.com (Alex Grund)
Date: Sat, 18 Jun 2011 18:16:22 +0200
Subject: [R-SIG-Finance] New to R and Finance, backtest etc.
Message-ID: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110618/a82b16d6/attachment.pl>

From gsee000 at gmail.com  Sat Jun 18 18:51:55 2011
From: gsee000 at gmail.com (G See)
Date: Sat, 18 Jun 2011 11:51:55 -0500
Subject: [R-SIG-Finance] New to R and Finance, backtest etc.
In-Reply-To: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>
References: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>
Message-ID: <BANLkTik5UTG7-k1WWh1dXMJDCvebCPAfaw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110618/4fb1a1ba/attachment.pl>

From J_Cuisinier at hotmail.com  Sun Jun 19 09:55:55 2011
From: J_Cuisinier at hotmail.com (julien cuisinier)
Date: Sun, 19 Jun 2011 08:55:55 +0100
Subject: [R-SIG-Finance] New to R and Finance, backtest etc.
In-Reply-To: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>
References: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>
Message-ID: <BLU0-SMTP191F3B549AC987A609CEA0E8F6F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110619/0551b5d6/attachment.pl>

From guillaume.kovarcik at gmail.com  Sun Jun 19 12:19:38 2011
From: guillaume.kovarcik at gmail.com (sadako)
Date: Sun, 19 Jun 2011 03:19:38 -0700 (PDT)
Subject: [R-SIG-Finance] Value-at-risk
In-Reply-To: <1305909100.27623.45.camel@brian-desktop>
References: <BANLkTi=x-QeOu6-mR8ZzaMPQkPnYJx1PHQ@mail.gmail.com>
	<1305199265.22156.171.camel@brian-desktop>
	<1305201458.22156.176.camel@brian-desktop>
	<006401cc1704$08a1ef00$19e5cd00$@gmail.com>
	<1305905804.27623.29.camel@brian-desktop>
	<009b01cc170a$13981eb0$3ac85c10$@gmail.com>
	<1305909100.27623.45.camel@brian-desktop>
Message-ID: <1308478778856-3609051.post@n4.nabble.com>

I'm ok with the notions of component and marginal VaR but can't retrieve
results from marginal.

First what is the PortfolioVaR with the portfolio_method="marginal" ?
Except the sign, the 2 figures I get from these functions for PortfolioVaR
are differents :
VaR(tsdata,method="gaussian",portfolio_method="marginal")
VaR(tsdata,method="gaussian",portfolio_method="component")$VaR


Second -and it is maybe be related - how is the marginal VaR computed ?
I tried the following but the result is different from the function (here it
is the 5th marginal) :

VaR(tsdata,method="gaussian",portfolio_method="component")$VaR-VaR(tsdata[,-5],method="gaussian",portfolio_method="component")$VaR

Many thanks for any helpful comment,

PS : tsdata is any valid timeSeries.

--
View this message in context: http://r.789695.n4.nabble.com/Value-at-risk-tp3516991p3609051.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From st.helldiver at googlemail.com  Sun Jun 19 13:40:15 2011
From: st.helldiver at googlemail.com (Alex Grund)
Date: Sun, 19 Jun 2011 13:40:15 +0200
Subject: [R-SIG-Finance] New to R and Finance, backtest etc.
In-Reply-To: <BLU0-SMTP191F3B549AC987A609CEA0E8F6F0@phx.gbl>
References: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>
	<BLU0-SMTP191F3B549AC987A609CEA0E8F6F0@phx.gbl>
Message-ID: <BANLkTinz8QYF-+XQgU+T6fR4NL6YKaQFgA@mail.gmail.com>

Hi Julien,

thank you for the link to Brian Peterson's work. I played around with
the code, but some things do not work correctly.
Maybe you know, how to fix them:

The main problem is caused by this line:

`  out <- try(applyStrategy(strategy='s' , portfolios='faber'))

which, obviously, is the most important line :-) The error message I get is:

`  Error in if (length(j) == 0 || (length(j) == 1 && j == 0)) { :
`  Fehlender Wert, wo TRUE/FALSE n?tig ist (translates to: "Missing
value, where TRUE/FALSE is required")

Since I did not modify the code from the PDF I think this may be a bug
in the software or a missing line of code in the PDF.
However, help is really appreciated!

"tradeStats('faber')" of course, returns NULL.
"chart.Posn('faber')" gives this error:
`  Fehler in .Internal(get(x, envir, mode, inherits)) : 'x' fehlt
(translates to: error in ~: 'x' missing)

However, I have a veriable called x in my workspace, which is
displayed with "ls()", and it's non-empty:

`  > x[1]
`             XLU.Open XLU.High XLU.Low XLU.Close XLU.Volume XLU.Adjusted
`  1998-12-31    30.25    30.83   29.64     30.23     162900        20.12


Thank you very much!

Alex.


2011/6/19 julien cuisinier <J_Cuisinier at hotmail.com>:
> Hi Alex,
>
> www.rinfinance.com/agenda/2011/BrianPeterson.pdf
>>> reference main packages you will ever need I think... & as mentioned in
>>> previous feedback quantmod is excellent & think quantstrat better (i,e, more
>>> widely used) than the "backtest" package that I personally do not know
>>> and in general RFinance conference papers, could be good to throw a
>>> glance at them...
> http://www.statmethods.net/
>>> very well done (in my humble opinion) website for intro into R, its main
>>> data type etc..
> HTH,
> Julien
>
>
>
> On Jun 18, 2011, at 5:16 PM, Alex Grund wrote:
>
> Hi there,
>
> I am new to R and want to perform a few experiments with trading strategies
> with R.
>
> However, I have experience in programming, but not in R (it's very similar
> to what a programmer would expect).
>
> For now, I've parsed some data (Open, High, Low, Close) of a security via
> read.table, which works fine.
> What I want to do now, is to perform a backtest of a simple trading strategy
> with R. Say, for example "buy on cross of MA(200) and MA(100)". Of course I
> could write the backtest routine by myself, but I saw a package called
> backtest. However, I do not really get the point how this may work. How
> could I use backtest package to analyse a simple strategy as above?
>
> Additionally, I would like to know, if there are some websites, wikis etc.
> which give a basic introduction to R in Finance "for dummies"? Anything I've
> seen so far was more or less for professionals.
>
>
> Thank you in advance
> Alex
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
>
>


From brian at braverock.com  Sun Jun 19 13:53:44 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 19 Jun 2011 06:53:44 -0500
Subject: [R-SIG-Finance] New to R and Finance, backtest etc.
In-Reply-To: <BANLkTinz8QYF-+XQgU+T6fR4NL6YKaQFgA@mail.gmail.com>
References: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>
	<BLU0-SMTP191F3B549AC987A609CEA0E8F6F0@phx.gbl>
	<BANLkTinz8QYF-+XQgU+T6fR4NL6YKaQFgA@mail.gmail.com>
Message-ID: <1308484424.22117.501.camel@brian-desktop>

The slide code should work, but the full Faber demo is available with
either

demo('faber')

or you can find the file in the demos directory or here:

https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/quantstrat/demo/faber.R?root=blotter

If you have problems with the demo code, we'll try to sort it out.

Regards,

   - Brian

On Sun, 2011-06-19 at 13:40 +0200, Alex Grund wrote:
> Hi Julien,
> 
> thank you for the link to Brian Peterson's work. I played around with
> the code, but some things do not work correctly.
> Maybe you know, how to fix them:
> 
> The main problem is caused by this line:
> 
> `  out <- try(applyStrategy(strategy='s' , portfolios='faber'))
> 
> which, obviously, is the most important line :-) The error message I get is:
> 
> `  Error in if (length(j) == 0 || (length(j) == 1 && j == 0)) { :
> `  Fehlender Wert, wo TRUE/FALSE n?tig ist (translates to: "Missing
> value, where TRUE/FALSE is required")
> 
> Since I did not modify the code from the PDF I think this may be a bug
> in the software or a missing line of code in the PDF.
> However, help is really appreciated!
> 
> "tradeStats('faber')" of course, returns NULL.
> "chart.Posn('faber')" gives this error:
> `  Fehler in .Internal(get(x, envir, mode, inherits)) : 'x' fehlt
> (translates to: error in ~: 'x' missing)
> 
> However, I have a veriable called x in my workspace, which is
> displayed with "ls()", and it's non-empty:
> 
> `  > x[1]
> `             XLU.Open XLU.High XLU.Low XLU.Close XLU.Volume XLU.Adjusted
> `  1998-12-31    30.25    30.83   29.64     30.23     162900        20.12
> 
> 
> Thank you very much!
> 
> Alex.
> 
> 
> 2011/6/19 julien cuisinier <J_Cuisinier at hotmail.com>:
> > Hi Alex,
> >
> > www.rinfinance.com/agenda/2011/BrianPeterson.pdf
> >>> reference main packages you will ever need I think... & as mentioned in
> >>> previous feedback quantmod is excellent & think quantstrat better (i,e, more
> >>> widely used) than the "backtest" package that I personally do not know
> >>> and in general RFinance conference papers, could be good to throw a
> >>> glance at them...
> > http://www.statmethods.net/
> >>> very well done (in my humble opinion) website for intro into R, its main
> >>> data type etc..
> > HTH,
> > Julien
> >
> >
> >
> > On Jun 18, 2011, at 5:16 PM, Alex Grund wrote:
> >
> > Hi there,
> >
> > I am new to R and want to perform a few experiments with trading strategies
> > with R.
> >
> > However, I have experience in programming, but not in R (it's very similar
> > to what a programmer would expect).
> >
> > For now, I've parsed some data (Open, High, Low, Close) of a security via
> > read.table, which works fine.
> > What I want to do now, is to perform a backtest of a simple trading strategy
> > with R. Say, for example "buy on cross of MA(200) and MA(100)". Of course I
> > could write the backtest routine by myself, but I saw a package called
> > backtest. However, I do not really get the point how this may work. How
> > could I use backtest package to analyse a simple strategy as above?
> >
> > Additionally, I would like to know, if there are some websites, wikis etc.
> > which give a basic introduction to R in Finance "for dummies"? Anything I've
> > seen so far was more or less for professionals.
> >
> >
> > Thank you in advance
> > Alex
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> > should go.
> >
> >
> >
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From brian at braverock.com  Sun Jun 19 14:06:28 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 19 Jun 2011 07:06:28 -0500
Subject: [R-SIG-Finance] Value-at-risk
In-Reply-To: <1308478778856-3609051.post@n4.nabble.com>
References: <BANLkTi=x-QeOu6-mR8ZzaMPQkPnYJx1PHQ@mail.gmail.com>
	<1305199265.22156.171.camel@brian-desktop>
	<1305201458.22156.176.camel@brian-desktop>
	<006401cc1704$08a1ef00$19e5cd00$@gmail.com>
	<1305905804.27623.29.camel@brian-desktop>
	<009b01cc170a$13981eb0$3ac85c10$@gmail.com>
	<1305909100.27623.45.camel@brian-desktop>
	<1308478778856-3609051.post@n4.nabble.com>
Message-ID: <1308485188.22117.514.camel@brian-desktop>

On Sun, 2011-06-19 at 03:19 -0700, sadako wrote:
> I'm ok with the notions of component and marginal VaR but can't retrieve
> results from marginal.
> 
> First what is the PortfolioVaR with the portfolio_method="marginal" ?
> Except the sign, the 2 figures I get from these functions for PortfolioVaR
> are differents :
> VaR(tsdata,method="gaussian",portfolio_method="marginal")
> VaR(tsdata,method="gaussian",portfolio_method="component")$VaR

Marginal and component VaR *are* different.  So I'm not sure I
understand what you're asking, entirely.

Component VaR is a coherent risk measure per Artzner.  The component
risks will add up to the univariate VaR of the entire portfolio.  The
univariate portfolio VaR is given in the $VaR slot you reference in your
code.  The additive measures are available two different ways, in the
$contribution slot (which will add up to the univariate portfolio VaR)
and in the $pct_contrib_VaR slot which will add up to 1(100%)

> Second -and it is maybe be related - how is the marginal VaR computed ?

Marginal VaR is the difference between the univariate portfolio VaR of a
a portfolio with the instrument in question and the VaR of the portfolio
without that instrument.  It is not guaranteed to add up to anything.
Frankly, I think it is a useless measure *unless* you are comparing two
otherwise similar instruments for inclusion in a portfolio, and want to
see which of those two instruments would add less risk to the portfolio
"at the margin".

> I tried the following but the result is different from the function (here it
> is the 5th marginal) :
> 
> VaR(tsdata,method="gaussian",portfolio_method="component")$VaR-VaR(tsdata[,-5],method="gaussian",portfolio_method="component")$VaR

Component VaR and marginal VaR aren't interchangeable, as described
above, and as described in the documentation.

simple subtraction doesn't work, because the portfolio (capital) needs
to be redistributed.

The weighting factor is

weightfactor = sum(weightingvector)/sum(t(weightingvector)[, -column])

you can see the code with:

PerformanceAnalytics:::VaR.Marginal

> Many thanks for any helpful comment,

I hope this helps,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From me at censix.com  Sun Jun 19 15:08:11 2011
From: me at censix.com (me at censix.com)
Date: Sun, 19 Jun 2011 15:08:11 +0200 (CEST)
Subject: [R-SIG-Finance] New to R and Finance, backtest etc.
In-Reply-To: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>
References: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>
Message-ID: <60629.78.234.67.201.1308488891.squirrel@censix.com>

Alex

once you have developed a strategy in 'quantstrat' and if you feel
adventurous and want to use it for live trading, I can (shamelessly)
recommend that you have a look at my 'qsiblive' download here.

http://censix.com

It may be of interest.

regards

Soren



> Hi there,
>
> I am new to R and want to perform a few experiments with trading
> strategies
> with R.
>
> However, I have experience in programming, but not in R (it's very similar
> to what a programmer would expect).
>
> For now, I've parsed some data (Open, High, Low, Close) of a security via
> read.table, which works fine.
> What I want to do now, is to perform a backtest of a simple trading
> strategy
> with R. Say, for example "buy on cross of MA(200) and MA(100)". Of course
> I
> could write the backtest routine by myself, but I saw a package called
> backtest. However, I do not really get the point how this may work. How
> could I use backtest package to analyse a simple strategy as above?
>
> Additionally, I would like to know, if there are some websites, wikis etc.
> which give a basic introduction to R in Finance "for dummies"? Anything
> I've
> seen so far was more or less for professionals.
>
>
> Thank you in advance
> Alex
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>


-- 
http://censix.com


From ustaudinger at gmail.com  Sun Jun 19 15:44:43 2011
From: ustaudinger at gmail.com (Ulrich Staudinger)
Date: Sun, 19 Jun 2011 15:44:43 +0200
Subject: [R-SIG-Finance] New to R and Finance, backtest etc.
In-Reply-To: <60629.78.234.67.201.1308488891.squirrel@censix.com>
References: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>
	<60629.78.234.67.201.1308488891.squirrel@censix.com>
Message-ID: <BANLkTinBFAx4JSunrDXJ+SqhSdY+repxvA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110619/b7c4a7ca/attachment.pl>

From jeffrey.ryan at lemnica.com  Sun Jun 19 16:06:23 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Sun, 19 Jun 2011 09:06:23 -0500
Subject: [R-SIG-Finance] New to R and Finance, backtest etc.
In-Reply-To: <BANLkTinBFAx4JSunrDXJ+SqhSdY+repxvA@mail.gmail.com>
References: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>
	<60629.78.234.67.201.1308488891.squirrel@censix.com>
	<BANLkTinBFAx4JSunrDXJ+SqhSdY+repxvA@mail.gmail.com>
Message-ID: <BANLkTi=vztOL+hY+gpA26Xv85P2je8k6mQ@mail.gmail.com>

A few years back (!) I was testing the then current implementation of
IBrokers for throughput.  At the time on a laptop I could see 10k+
messages a second in R max throughput.  Within the context of IB, that
is more than sufficient to handle the incoming data (given symbol
limits and IB's snapshot data approach (300ms or so aggregations on
'mkt data').

This would push a single core to a pretty high cpu utilization, but
easy enough to share data between procs with R.

The 'testing' would really depend on you are doing in terms of trade
logic.  All in all though, aside from real high freq stuff, you can
easily have R running logic and trades - at least if you can temper
the incoming data to something like IB provides.

In terms of 'yes or no' ... I think the best you can get is
'sometimes' (or 'most times' if you aren't looking at the order book
or full market)

Jeff

On Sun, Jun 19, 2011 at 8:44 AM, Ulrich Staudinger
<ustaudinger at gmail.com> wrote:
> Hey guys,
>
> has anyone ever checked runtime statistics, in the sense of processing
> speed, etc. of R in live trading?
> Obviously, it is possible to also implement C equations, but I am wondering
> if R etc are used in real intraday trading and about the performance
> characteristics observed.
>
> Thanks
> Ulrich
>
>
>
>
> On Sun, Jun 19, 2011 at 3:08 PM, <me at censix.com> wrote:
>
>> Alex
>>
>> once you have developed a strategy in 'quantstrat' and if you feel
>> adventurous and want to use it for live trading, I can (shamelessly)
>> recommend that you have a look at my 'qsiblive' download here.
>>
>> http://censix.com
>>
>> It may be of interest.
>>
>> regards
>>
>> Soren
>>
>>
>>
>> > Hi there,
>> >
>> > I am new to R and want to perform a few experiments with trading
>> > strategies
>> > with R.
>> >
>> > However, I have experience in programming, but not in R (it's very
>> similar
>> > to what a programmer would expect).
>> >
>> > For now, I've parsed some data (Open, High, Low, Close) of a security via
>> > read.table, which works fine.
>> > What I want to do now, is to perform a backtest of a simple trading
>> > strategy
>> > with R. Say, for example "buy on cross of MA(200) and MA(100)". Of course
>> > I
>> > could write the backtest routine by myself, but I saw a package called
>> > backtest. However, I do not really get the point how this may work. How
>> > could I use backtest package to analyse a simple strategy as above?
>> >
>> > Additionally, I would like to know, if there are some websites, wikis
>> etc.
>> > which give a basic introduction to R in Finance "for dummies"? Anything
>> > I've
>> > seen so far was more or less for professionals.
>> >
>> >
>> > Thank you in advance
>> > Alex
>> >
>> > ? ? ? [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only. If you want to post, subscribe first.
>> > -- Also note that this is not the r-help list where general R questions
>> > should go.
>> >
>>
>>
>> --
>> http://censix.com
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>
>
> --
> Ulrich Staudinger
>
> http://www.activequant.org
> Connect online: https://www.xing.com/profile/Ulrich_Staudinger
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com
www.esotericR.com


From jeffrey.ryan at lemnica.com  Sun Jun 19 16:48:01 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Sun, 19 Jun 2011 09:48:01 -0500
Subject: [R-SIG-Finance] quantmod - chart object (chob)
In-Reply-To: <30DD76E5-E76C-43F3-9CC6-60B201B838AE@gmail.com>
References: <30DD76E5-E76C-43F3-9CC6-60B201B838AE@gmail.com>
Message-ID: <BANLkTinYEfckVgcP2jnqacguMVW9bp8ucQ@mail.gmail.com>

Stanley,

As Brian replied - you _can_ - but the trick is to use the new version
"chart_Series".  This creates single drawings with multiple 'panes'
all within what R *thinks* is a single graphic - whereas the old code
relied on layout internally - so was very difficult to use layout with
an existing layout.

It isn't very easy to build up a list to be plotted later though,
should be workable I suppose - I just haven't tried or needed I guess.

Best,
Jeff

On Fri, Jun 17, 2011 at 12:38 PM, Hungte (Stanley) Chu <chd850 at gmail.com> wrote:
> Hi everyone,
>
> I am curious that if I can collect a list of chob objects and later tile these plots in a pdf file. I have a function to handle this for r plot objects, but I am having trouble with chob. In simple words, print(chob) does not work. Can anyone point me a direction?
>
> Thanks,
> Stanley
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com
www.esotericR.com


From chd850 at gmail.com  Sun Jun 19 17:49:23 2011
From: chd850 at gmail.com (Stanley Chu)
Date: Sun, 19 Jun 2011 19:49:23 +0400
Subject: [R-SIG-Finance] quantmod - chart object (chob)
In-Reply-To: <BANLkTinYEfckVgcP2jnqacguMVW9bp8ucQ@mail.gmail.com>
References: <30DD76E5-E76C-43F3-9CC6-60B201B838AE@gmail.com>
	<BANLkTinYEfckVgcP2jnqacguMVW9bp8ucQ@mail.gmail.com>
Message-ID: <977F5FFA-BE2B-46BE-A77E-47DC21B5FCE8@gmail.com>

Hi Jeff & Brian,

Thanks for the reply. 

The idea is to be able to save the plot object for future reference, with minimal work to reproduce it, and to be able to use them freely in a document. For example, one may be able to use a viewport function to specify the layout. 
e.g. vplayout <- function(x, y) viewport(layout.pos.row = x, layout.pos.col = y), and use print(plot.list, vp = vplayout(x, y)) to place them in a document. Given a list of plot objects and defined "position" for each plot, the function should be able to render them accordingly in a document. 

I can probably use dev.copy2pdf and manually tile them, so no biggie. Thanks Jeff for your wonderful package(s). 


Thanks,
Stanley

On Jun 19, 2011, at 6:48 PM, Jeffrey Ryan wrote:

> Stanley,
> 
> As Brian replied - you _can_ - but the trick is to use the new version
> "chart_Series".  This creates single drawings with multiple 'panes'
> all within what R *thinks* is a single graphic - whereas the old code
> relied on layout internally - so was very difficult to use layout with
> an existing layout.
> 
> It isn't very easy to build up a list to be plotted later though,
> should be workable I suppose - I just haven't tried or needed I guess.
> 
> Best,
> Jeff
> 
> On Fri, Jun 17, 2011 at 12:38 PM, Hungte (Stanley) Chu <chd850 at gmail.com> wrote:
>> Hi everyone,
>> 
>> I am curious that if I can collect a list of chob objects and later tile these plots in a pdf file. I have a function to handle this for r plot objects, but I am having trouble with chob. In simple words, print(chob) does not work. Can anyone point me a direction?
>> 
>> Thanks,
>> Stanley
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>> 
> 
> 
> 
> -- 
> Jeffrey Ryan
> jeffrey.ryan at lemnica.com
> 
> www.lemnica.com
> www.esotericR.com


From jeffrey.ryan at lemnica.com  Sun Jun 19 17:59:13 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Sun, 19 Jun 2011 10:59:13 -0500
Subject: [R-SIG-Finance] quantmod - chart object (chob)
In-Reply-To: <977F5FFA-BE2B-46BE-A77E-47DC21B5FCE8@gmail.com>
References: <30DD76E5-E76C-43F3-9CC6-60B201B838AE@gmail.com>
	<BANLkTinYEfckVgcP2jnqacguMVW9bp8ucQ@mail.gmail.com>
	<977F5FFA-BE2B-46BE-A77E-47DC21B5FCE8@gmail.com>
Message-ID: <BANLkTik-mR2SXCV_dQ12yG2KhU0upHimTQ@mail.gmail.com>

One item to note - they are built with a custom tool built for
quantmod called 'replot'.  Essentially is a layout tool to align the x
(time) axis, but using base graphics (not grid).

Mixing traditional graphics and grid is really not easy - and grid is
really, really slow (see ggplot2) - so you probably will have a hard
time with the approach you are thinking of.  Luckily nothing is
impossible - so if you have success, please share your results!!

Best,
Jeff

On Sun, Jun 19, 2011 at 10:49 AM, Stanley Chu <chd850 at gmail.com> wrote:
> Hi Jeff & Brian,
>
> Thanks for the reply.
>
> The idea is to be able to save the plot object for future reference, with minimal work to reproduce it, and to be able to use them freely in a document. For example, one may be able to use a viewport function to specify the layout.
> e.g. vplayout <- function(x, y) viewport(layout.pos.row = x, layout.pos.col = y), and use print(plot.list, vp = vplayout(x, y)) to place them in a document. Given a list of plot objects and defined "position" for each plot, the function should be able to render them accordingly in a document.
>
> I can probably use dev.copy2pdf and manually tile them, so no biggie. Thanks Jeff for your wonderful package(s).
>
>
> Thanks,
> Stanley
>
> On Jun 19, 2011, at 6:48 PM, Jeffrey Ryan wrote:
>
>> Stanley,
>>
>> As Brian replied - you _can_ - but the trick is to use the new version
>> "chart_Series". ?This creates single drawings with multiple 'panes'
>> all within what R *thinks* is a single graphic - whereas the old code
>> relied on layout internally - so was very difficult to use layout with
>> an existing layout.
>>
>> It isn't very easy to build up a list to be plotted later though,
>> should be workable I suppose - I just haven't tried or needed I guess.
>>
>> Best,
>> Jeff
>>
>> On Fri, Jun 17, 2011 at 12:38 PM, Hungte (Stanley) Chu <chd850 at gmail.com> wrote:
>>> Hi everyone,
>>>
>>> I am curious that if I can collect a list of chob objects and later tile these plots in a pdf file. I have a function to handle this for r plot objects, but I am having trouble with chob. In simple words, print(chob) does not work. Can anyone point me a direction?
>>>
>>> Thanks,
>>> Stanley
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions should go.
>>>
>>
>>
>>
>> --
>> Jeffrey Ryan
>> jeffrey.ryan at lemnica.com
>>
>> www.lemnica.com
>> www.esotericR.com
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com
www.esotericR.com


From guillaume.kovarcik at gmail.com  Sun Jun 19 18:07:20 2011
From: guillaume.kovarcik at gmail.com (sadako)
Date: Sun, 19 Jun 2011 09:07:20 -0700 (PDT)
Subject: [R-SIG-Finance] Value-at-risk
In-Reply-To: <1308485188.22117.514.camel@brian-desktop>
References: <BANLkTi=x-QeOu6-mR8ZzaMPQkPnYJx1PHQ@mail.gmail.com>
	<1305199265.22156.171.camel@brian-desktop>
	<1305201458.22156.176.camel@brian-desktop>
	<006401cc1704$08a1ef00$19e5cd00$@gmail.com>
	<1305905804.27623.29.camel@brian-desktop>
	<009b01cc170a$13981eb0$3ac85c10$@gmail.com>
	<1305909100.27623.45.camel@brian-desktop>
	<1308478778856-3609051.post@n4.nabble.com>
	<1308485188.22117.514.camel@brian-desktop>
Message-ID: <1308499640217-3609482.post@n4.nabble.com>


braverock wrote:
> 
> On Sun, 2011-06-19 at 03:19 -0700, sadako wrote:
>> I'm ok with the notions of component and marginal VaR but can't retrieve
>> results from marginal.
>> 
>> First what is the PortfolioVaR with the portfolio_method="marginal" ?
>> Except the sign, the 2 figures I get from these functions for
>> PortfolioVaR
>> are differents :
>> VaR(tsdata,method="gaussian",portfolio_method="marginal")
>> VaR(tsdata,method="gaussian",portfolio_method="component")$VaR
> 
> Marginal and component VaR *are* different.  So I'm not sure I
> understand what you're asking, entirely.
> 
> Component VaR is a coherent risk measure per Artzner.  The component
> risks will add up to the univariate VaR of the entire portfolio.  The
> univariate portfolio VaR is given in the $VaR slot you reference in your
> code.
> 
> Marginal VaR is the difference between the univariate portfolio VaR of a 
> a portfolio with the instrument in question and the VaR of the portfolio 
> without that instrument.

Actually I didn't mean to compare marginal and component : I just use the
portfolio_method="component" to get the univariate VaR of the portfolio
($VaR slot). 
I have the same number using calculation like
qnorm(0.95,0,1)*sqrt(t(wghts)%*%var(tsdata)%*%wghts)-t(wghts)%*%colMeans(tsdata).

I would have expect to have the same number for this univariate portfolio
VaR in the "PortfolioVaR" column of VaR(...,portfolio_method="marginal"), -
all other parameters being equal - but this is not the case. 

Both should represent the univariate portfolio VaR aren't they ?



>> I tried the following but the result is different from the function (here
>> it
>> is the 5th marginal) :
>> 
>> VaR(tsdata,method="gaussian",portfolio_method="component")$VaR-VaR(tsdata[,-5],method="gaussian",portfolio_method="component")$VaR
> 
> Component VaR and marginal VaR aren't interchangeable, as described
> above, and as described in the documentation.
> 
> simple subtraction doesn't work, because the portfolio (capital) needs
> to be redistributed.
> 
> The weighting factor is
> 
> weightfactor = sum(weightingvector)/sum(t(weightingvector)[, -column])
> 

Nota : here again I just use the $VaR slot of component to get access to the
univariate VaR of portfolio.

I think I got the weight factor right implicitly since I don't set any
special weights vectors : the VaR functions sets these weights equally in
both members of my equation. 

Assume I'm working with 5 assets : 
- the univariate VaR of the portfolio :
VaR(tsdata,method="gaussian",portfolio_method="component")$VaR is computed
with default weights=c(0.2,0.2,0.2,0.2,0.2)
- the VaR of the portfolio without the asset 5 :
VaR(tsdata[,-5],method="gaussian",portfolio_method="component")$VaR is
computed with equally-weighted default weights=c(0.25,0.25,0.25,0.25). These
are indeed the weights of the 5-assets portfolio taking into account the
weight factor of sum(weightingvector)/sum(t(weightingvector)[, -5])=1.25


Marginal VaR is the difference between the univariate portfolio VaR of a 
> a portfolio with the instrument in question and the VaR of the portfolio 
> without that instrument.

So with no weight specification, the stricto-sensu calculation :

VaR(tsdata,method="gaussian",portfolio_method="component")$VaR-VaR(tsdata[,-columnAsset],method="gaussian",portfolio_method="component")$VaR 

should work or this is non-sense ?



> you can see the code with: PerformanceAnalytics:::VaR.Marginal
> 

I'm having a look, maybe the difference stems from the application of
Return.portfolio in the marginal case...



>> Many thanks for any helpful comment,
> 
> I hope this helps,
>     - Brian
> 

It did, thank you very much Brian !

--
View this message in context: http://r.789695.n4.nabble.com/Value-at-risk-tp3516991p3609482.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From guillaume.kovarcik at gmail.com  Sun Jun 19 19:20:30 2011
From: guillaume.kovarcik at gmail.com (sadako)
Date: Sun, 19 Jun 2011 10:20:30 -0700 (PDT)
Subject: [R-SIG-Finance] Value-at-risk
In-Reply-To: <1308499640217-3609482.post@n4.nabble.com>
References: <BANLkTi=x-QeOu6-mR8ZzaMPQkPnYJx1PHQ@mail.gmail.com>
	<1305199265.22156.171.camel@brian-desktop>
	<1305201458.22156.176.camel@brian-desktop>
	<006401cc1704$08a1ef00$19e5cd00$@gmail.com>
	<1305905804.27623.29.camel@brian-desktop>
	<009b01cc170a$13981eb0$3ac85c10$@gmail.com>
	<1305909100.27623.45.camel@brian-desktop>
	<1308478778856-3609051.post@n4.nabble.com>
	<1308485188.22117.514.camel@brian-desktop>
	<1308499640217-3609482.post@n4.nabble.com>
Message-ID: <1308504030048-3609604.post@n4.nabble.com>


sadako wrote:
> 
> 
> 
>> you can see the code with: PerformanceAnalytics:::VaR.Marginal
>> 
> 
> I'm having a look, maybe the difference stems from the application of
> Return.portfolio in the marginal case...
> 

I think we don't get the same univariate portfolio VaR with the two
portfolio_method "marginal" and "component" because of :

- in PerformanceAnalytics:::VaR.Marginal, the Return.portfolio are
calculated without the optional argument geometric (geometric=FALSE would
eventually match the stdev I compute).

- in PerformanceAnalytics:::VaR.Marginal, when calling the
portfolio_method="single" to compute the univariate portfolio VaR, we end up
in the PerformanceAnalytics:::VaR.Gaussian function. 
This function uses the PerformanceAnalytics:::centeredmoment function, which
uses the mean function. 
This does not give the same variance as stdev for instance since there's not
the ajustement of the estimator (division by n-1 instead of n if data set
has n observations). 
If we set m2 = centeredmoment(r, 2)*dim(r)[1]/(dim(r)[1]-1), it looks ok.

With these two modifications, I have the impression the univariate portfolio
VaR computed from portfolio_method="marginal" and
portfolio_method="component" are consistant.

--
View this message in context: http://r.789695.n4.nabble.com/Value-at-risk-tp3516991p3609604.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From petrovaa at gmail.com  Sun Jun 19 21:39:56 2011
From: petrovaa at gmail.com (tonyp)
Date: Sun, 19 Jun 2011 12:39:56 -0700 (PDT)
Subject: [R-SIG-Finance] Rolling Correlation Matrixes
Message-ID: <1308512396424-3609808.post@n4.nabble.com>

Hi, 

I am fairly new to R and I was hoping some of the great geniuses could help
me with my problem. Basically, I have 5 time series of daily data. Let's
say:

####
x1=rnorm(200, 0,1)
x2=rnorm(200, 10, 2)
x3=rnorm(200, 1,5)
x4=rnorm(200, 2,1)
x5=rnorm(200, 9,2)
x=cbind(x1,x2,x3,x4,x5)
rt=zoo(x, as.Date("2004-01-01") + 0:199)

and I want to calculate weekly rolling matrices (pairwise) correlations (not
average pairwise correlations). And I am looking to output the very last
(window) correlation a.k.a. the last period correlation matrix. So I did
this:

pw <- rollapply(rt, width = 5, FUN = function(x)
 y <- cor(x), by.column = FALSE, align='right')
p=tail(pw,1)

I get really messy output. Something like this: 

2004-07-18 1 0.5276424 -0.05103385
                                           
2004-07-18 -0.0783848 0.1752491 0.5276424 1
                                         
2004-07-18 -0.4639914 0.4708166 0.1443911
                                   
2004-07-18 -0.05103385 -0.4639914 1
                                          
2004-07-18 -0.8756658 0.3756958 -0.0783848
                                 
2004-07-18 0.4708166 -0.8756658 1
                                         
2004-07-18 0.01812455 0.1752491 0.1443911
                                 
2004-07-18 0.3756958 0.01812455 1


Can you help me with that please? In addition, if I want to calculate the
current percentile of each pair of this last period with respect to its
rolling correlation distribution how can I do that? I was reading that 
rank() may do the job but I am not sure. Thank you. :) 








--
View this message in context: http://r.789695.n4.nabble.com/Rolling-Correlation-Matrixes-tp3609808p3609808.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From Achim.Zeileis at uibk.ac.at  Sun Jun 19 22:45:14 2011
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sun, 19 Jun 2011 22:45:14 +0200 (CEST)
Subject: [R-SIG-Finance] Rolling Correlation Matrixes
In-Reply-To: <1308512396424-3609808.post@n4.nabble.com>
References: <1308512396424-3609808.post@n4.nabble.com>
Message-ID: <alpine.DEB.2.02.1106192240360.17009@paninaro.uibk.ac.at>

On Sun, 19 Jun 2011, tonyp wrote:

> Hi,
>
> I am fairly new to R and I was hoping some of the great geniuses could help
> me with my problem. Basically, I have 5 time series of daily data. Let's
> say:
>
> ####
> x1=rnorm(200, 0,1)
> x2=rnorm(200, 10, 2)
> x3=rnorm(200, 1,5)
> x4=rnorm(200, 2,1)
> x5=rnorm(200, 9,2)
> x=cbind(x1,x2,x3,x4,x5)
> rt=zoo(x, as.Date("2004-01-01") + 0:199)
>
> and I want to calculate weekly rolling matrices (pairwise) correlations (not
> average pairwise correlations). And I am looking to output the very last
> (window) correlation a.k.a. the last period correlation matrix. So I did
> this:
>
> pw <- rollapply(rt, width = 5, FUN = function(x)
> y <- cor(x), by.column = FALSE, align='right')
> p=tail(pw,1)
>
> I get really messy output. Something like this:
>
> 2004-07-18 1 0.5276424 -0.05103385
>
> 2004-07-18 -0.0783848 0.1752491 0.5276424 1
>
> 2004-07-18 -0.4639914 0.4708166 0.1443911
>
> 2004-07-18 -0.05103385 -0.4639914 1
>
> 2004-07-18 -0.8756658 0.3756958 -0.0783848
>
> 2004-07-18 0.4708166 -0.8756658 1
>
> 2004-07-18 0.01812455 0.1752491 0.1443911
>
> 2004-07-18 0.3756958 0.01812455 1

It's not that messy but it may be more than you expected. Your 200x5 
series is transformed into a 196x25. The 196 is due to "losing" four 
observations with a five observation window. The 25 is due to the 5x5 
correlation matrix that you compute. But it would be sufficient to use 
something like

   mycor <- function(x) {
     rval <- cor(x)
     rval[lower.tri(rval)]
   }

and then to use FUN = mycor in your rollapply() call. Maybe you can also 
improve the labeling somewhat.

> Can you help me with that please? In addition, if I want to calculate the
> current percentile of each pair of this last period with respect to its
> rolling correlation distribution how can I do that? I was reading that
> rank() may do the job but I am not sure. Thank you. :)

Maybe something like this?

   apply(pw, 2, function(x) mean(x <= tail(x, 1)))

hth,
Z

>
>
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Rolling-Correlation-Matrixes-tp3609808p3609808.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From petrovaa at gmail.com  Mon Jun 20 00:23:21 2011
From: petrovaa at gmail.com (tonyp)
Date: Sun, 19 Jun 2011 15:23:21 -0700 (PDT)
Subject: [R-SIG-Finance] Rolling Correlation Matrixes
In-Reply-To: <1308512396424-3609808.post@n4.nabble.com>
References: <1308512396424-3609808.post@n4.nabble.com>
Message-ID: <1308522201801-3610056.post@n4.nabble.com>

Hi Achim, 

Thanks for your prompt reply. Sounds R is a toy for you to play around with. 

 mycor <- function(x) {
     rval <- cor(x)
     rval[lower.tri(rval)]
   }

 I can see from the first code that you are suggesting a function for
calculating the lower triangle of the correlation matrix and the second
seems to apply a columnwise average somehow. I just don't see how it
calculates the empirical percentile to each entry of the last(pw) matrix.
maybe I misunderstand the function?

   apply(pw, 2, function(x) mean(x <= tail(x, 1))) 

Can you suggest me, if there is similar function as for pairs() that can be
customized. Once I calculate the last rolling correlation matrix and the
current percentiles I want to put in the lower half what your "mycor"
calculates and in the upper half the matched percentiles for the current
rolling cor matrix in a graphical way?

If anybody else can help me with it, I would totally appreciate it. :)

Thanks again. Seems that I have to learn this tool long way.

Best wishes, 

T



--
View this message in context: http://r.789695.n4.nabble.com/Rolling-Correlation-Matrixes-tp3609808p3610056.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From jctoll at gmail.com  Mon Jun 20 21:28:45 2011
From: jctoll at gmail.com (J Toll)
Date: Mon, 20 Jun 2011 14:28:45 -0500
Subject: [R-SIG-Finance] fix yahooKeystats
Message-ID: <BANLkTikh4h9GVwrzdbuPtjqWwbtG2k=P=Q@mail.gmail.com>

Hi,

I wanted to get some input from the more experienced R users regarding
the yahooKeystats function in the fImport package.  I believe that the
function is currently broken (Version: 2110.79).  It appears that
Yahoo changed their HTML slightly which has caused the function to
break.  Several months ago, I managed to get it working and posted
those changes to this list in case anyone else was interested.

https://stat.ethz.ch/pipermail/r-sig-finance/2011q1/007250.html

Since then, I rewrote the yahooKeystats function using the XML
package.  I tried contacting the Rmetrics Core Team to offer up this
working code as a possible alternative but haven't gotten a response.
What should I do?  It seems like it would be a good idea to
fix/replace the current function with something that works.  Or should
I just leave it be and not worry about it.  Thanks.

James


From dstjohn at math.uic.edu  Tue Jun 21 06:19:23 2011
From: dstjohn at math.uic.edu (David St John)
Date: Mon, 20 Jun 2011 23:19:23 -0500
Subject: [R-SIG-Finance] New to R and Finance, backtest etc.
Message-ID: <BANLkTikSjtNrW5rAk3Q42bXi9hdBbbRwRg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110620/80211c12/attachment.pl>

From irasharenow100 at yahoo.com  Tue Jun 21 07:03:15 2011
From: irasharenow100 at yahoo.com (Ira Sharenow)
Date: Mon, 20 Jun 2011 22:03:15 -0700
Subject: [R-SIG-Finance] Offset a vector by 1 to k months
Message-ID: <004c01cc2fd0$8823eaa0$4401a8c0@IraHP>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110620/b62d93d3/attachment.pl>

From me at censix.com  Tue Jun 21 07:48:32 2011
From: me at censix.com (me at censix.com)
Date: Tue, 21 Jun 2011 07:48:32 +0200 (CEST)
Subject: [R-SIG-Finance] New to R and Finance, backtest etc.
In-Reply-To: <BANLkTinBFAx4JSunrDXJ+SqhSdY+repxvA@mail.gmail.com>
References: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>
	<60629.78.234.67.201.1308488891.squirrel@censix.com>
	<BANLkTinBFAx4JSunrDXJ+SqhSdY+repxvA@mail.gmail.com>
Message-ID: <57357.78.234.67.201.1308635312.squirrel@censix.com>

Hi

well, I am currently testing an intraday version of the 'qsiblive'
function collection. For now everything above the 30sec bars seems to be
working fine (looking at realTimeBars only). One has to be mindful of
indicator and signal calculations though. If these  slow things down to
much, using longer bars may be the only option, aside from optimizing the
indicator/signal processing (which certainly needs to be done at some
point in the future)

Soren


> Hey guys,
>
> has anyone ever checked runtime statistics, in the sense of processing
> speed, etc. of R in live trading?
> Obviously, it is possible to also implement C equations, but I am
> wondering
> if R etc are used in real intraday trading and about the performance
> characteristics observed.
>
> Thanks
> Ulrich
>
>
>
>
> On Sun, Jun 19, 2011 at 3:08 PM, <me at censix.com> wrote:
>
>> Alex
>>
>> once you have developed a strategy in 'quantstrat' and if you feel
>> adventurous and want to use it for live trading, I can (shamelessly)
>> recommend that you have a look at my 'qsiblive' download here.
>>
>> http://censix.com
>>
>> It may be of interest.
>>
>> regards
>>
>> Soren
>>
>>
>>
>> > Hi there,
>> >
>> > I am new to R and want to perform a few experiments with trading
>> > strategies
>> > with R.
>> >
>> > However, I have experience in programming, but not in R (it's very
>> similar
>> > to what a programmer would expect).
>> >
>> > For now, I've parsed some data (Open, High, Low, Close) of a security
>> via
>> > read.table, which works fine.
>> > What I want to do now, is to perform a backtest of a simple trading
>> > strategy
>> > with R. Say, for example "buy on cross of MA(200) and MA(100)". Of
>> course
>> > I
>> > could write the backtest routine by myself, but I saw a package called
>> > backtest. However, I do not really get the point how this may work.
>> How
>> > could I use backtest package to analyse a simple strategy as above?
>> >
>> > Additionally, I would like to know, if there are some websites, wikis
>> etc.
>> > which give a basic introduction to R in Finance "for dummies"?
>> Anything
>> > I've
>> > seen so far was more or less for professionals.
>> >
>> >
>> > Thank you in advance
>> > Alex
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only. If you want to post, subscribe first.
>> > -- Also note that this is not the r-help list where general R
>> questions
>> > should go.
>> >
>>
>>
>> --
>> http://censix.com
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>
>
> --
> Ulrich Staudinger
>
> http://www.activequant.org
> Connect online: https://www.xing.com/profile/Ulrich_Staudinger
>


-- 
http://censix.com


From Adrian.Ladaniwskyj at hydro.com.au  Wed Jun 22 08:08:32 2011
From: Adrian.Ladaniwskyj at hydro.com.au (Adrian Ladaniwskyj)
Date: Wed, 22 Jun 2011 16:08:32 +1000
Subject: [R-SIG-Finance] Handling half hourly data from electricity markets
In-Reply-To: <mailman.3.1308650402.6191.r-sig-finance@r-project.org>
References: <mailman.3.1308650402.6191.r-sig-finance@r-project.org>
Message-ID: <42CD7E9FF8F8164CA3BBD8FD84D7C7210547611F@swhexprod.hydrotasmania.com.au>



Hi all;

I am attempting to conduct analysis on half hourly Australian NEM
electricity market wholesale price data.

I need a way to parse a half hourly dataset, and generate Yearly,
Quarterly, and Monthly peak/offpeak average prices, in line with the
form of quoted pricing for typical OTC and futures market energy swap
products.

Peak is defined between 7am and 10pm market time, offpeak 10pm-7am.

(For example , to get the average peak price for jan, 2011, I need to be
able to select ONLY price data from jan 2011, that occurred between 7am
and 10pm, sum the prices, then divide them by the number of instances
for the desired result)

I cannot seem to find an adequate coded example of how to achieve this
as yet.

An example of the data I am working with is set out below:

Iteration             Time $/MWh $/MWh $/MWh
2          1 2011-01-01 00:30 22.00 16.37 23.64
3          1 2011-01-01 01:00 17.69 16.53 15.49
4          1 2011-01-01 01:30 16.49 15.00 15.09
5          1 2011-01-01 02:00 12.17 11.73 10.96
6          1 2011-01-01 02:30  7.38  7.20  6.73
7          1 2011-01-01 03:00  6.10  6.24  5.36
8          1 2011-01-01 03:30  5.80  6.24  4.91
9          1 2011-01-01 04:00  4.98  5.40  4.10
10         1 2011-01-01 04:30  5.72  6.24  4.72

If anyone can assist me in this, it would be greatly appreciated.

Cheers;


Adrian Ladaniwskyj | Market Analyst, Spot Tactics

B.Bus, B.Ec(Hons), Dip.FS 

 logo	p +61 3 6230 5495 | f +61 3 6230 5416 | m +61 431 121 711
e adrian.ladaniwskyj at hydro.com.au
w www.hydro.com.au
Level 9, 4 Elizabeth Street, Hobart TAS 7000

Please consider the environment before printing my email
This e-mail and any attachments may contain confidential, proprietary or
legally privileged information. If you are not the intended recipient,
you must not keep, forward, disclose, adapt or copy the material and any
such action is unauthorised and prohibited. If you have received this
e-mail in error, please immediately advise the sender by return email
and delete this e-mail and any attachments from your system.


-----Original Message-----
From: r-sig-finance-bounces at r-project.org
[mailto:r-sig-finance-bounces at r-project.org] On Behalf Of
r-sig-finance-request at r-project.org
Sent: Tuesday, 21 June 2011 8:00 PM
To: r-sig-finance at r-project.org
Subject: R-SIG-Finance Digest, Vol 85, Issue 20

Send R-SIG-Finance mailing list submissions to
	r-sig-finance at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-finance
or, via email, send a message with subject or body 'help' to
	r-sig-finance-request at r-project.org

You can reach the person managing the list at
	r-sig-finance-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-SIG-Finance digest..."


Today's Topics:

   1. fix yahooKeystats (J Toll)
   2. Re: New to R and Finance, backtest etc. (David St John)
   3. Offset a vector by 1 to k months (Ira Sharenow)
   4. Re: New to R and Finance, backtest etc. (me at censix.com)


----------------------------------------------------------------------

Message: 1
Date: Mon, 20 Jun 2011 14:28:45 -0500
From: J Toll <jctoll at gmail.com>
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] fix yahooKeystats
Message-ID: <BANLkTikh4h9GVwrzdbuPtjqWwbtG2k=P=Q at mail.gmail.com>
Content-Type: text/plain; charset=UTF-8

Hi,

I wanted to get some input from the more experienced R users regarding
the yahooKeystats function in the fImport package.  I believe that the
function is currently broken (Version: 2110.79).  It appears that
Yahoo changed their HTML slightly which has caused the function to
break.  Several months ago, I managed to get it working and posted
those changes to this list in case anyone else was interested.

https://stat.ethz.ch/pipermail/r-sig-finance/2011q1/007250.html

Since then, I rewrote the yahooKeystats function using the XML
package.  I tried contacting the Rmetrics Core Team to offer up this
working code as a possible alternative but haven't gotten a response.
What should I do?  It seems like it would be a good idea to
fix/replace the current function with something that works.  Or should
I just leave it be and not worry about it.  Thanks.

James



------------------------------

Message: 2
Date: Mon, 20 Jun 2011 23:19:23 -0500
From: David St John <dstjohn at math.uic.edu>
To: <r-sig-finance at stat.math.ethz.ch>
Subject: Re: [R-SIG-Finance] New to R and Finance, backtest etc.
Message-ID: <BANLkTikSjtNrW5rAk3Q42bXi9hdBbbRwRg at mail.gmail.com>
Content-Type: text/plain

Another 'shameless' plug...if you're back-testing moving average
strategies,
consider a large family of parameter choices and the possibility of
data-snooping.  Also consider persistence across smaller sub-periods.
The
ttrTests package has some good references to papers on the subject, and
a
very limited implementation of the tests in the literature.

Perhaps the developers of quantstrat are interested in including data
snooping tests and tests for persistence from period to period?  I would
be
very happy to see the ttrTests package obsolete.  As much as I would
love to
make it look and behave more like the quant* packages, I won't have time
to
develop improvements any time soon.

-David

	[[alternative HTML version deleted]]



------------------------------

Message: 3
Date: Mon, 20 Jun 2011 22:03:15 -0700
From: "Ira Sharenow" <irasharenow100 at yahoo.com>
To: <r-sig-finance at r-project.org>
Subject: [R-SIG-Finance] Offset a vector by 1 to k months
Message-ID: <004c01cc2fd0$8823eaa0$4401a8c0 at IraHP>
Content-Type: text/plain

I am new to financial time series, zoo, and xts.



I have a length n vector (vDates) of dates. I have an n by k  matrix
(mDates). In row i and column j of the matrix, I would like the value to
be the row i value of the vector + j months. 



mDates[i,j]  = vDates[i] + j months.



I would like to do this without loops.



I solved the problem with just numbers.



v1 = 11:15

m1 = matrix(rep(0,20), nrow = 5)

m1 = v1 + col(m1)



I do not know how to add months in zoo or xts, so I tried lubridate.



library(lubridate)

vDate = as.Date(c("2011-06-01", "2011-06-02", "2011-06-03"), "%Y-%m-%d")

mDate2  = vDate  + months(1)  this works fine



But I do not know how to solve the problem for a matrix.





library(xts)

charvec = paste("2011-0", 1:2, "-01", sep = "")

theData = matrix(rep(0,6),nrow = 2)

z1 = xts(theData, as.Date(charvec))



I want the rows of z1 data to be

2011-02-01  2011-03-01 2011-04-01

2011-03-01  2011-04-01 2011-05-01



Thanks.



Ira

	[[alternative HTML version deleted]]



------------------------------

Message: 4
Date: Tue, 21 Jun 2011 07:48:32 +0200 (CEST)
From: me at censix.com
To: "Ulrich Staudinger" <ustaudinger at gmail.com>
Cc: me at censix.com, r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] New to R and Finance, backtest etc.
Message-ID: <57357.78.234.67.201.1308635312.squirrel at censix.com>
Content-Type: text/plain;charset=iso-8859-1

Hi

well, I am currently testing an intraday version of the 'qsiblive'
function collection. For now everything above the 30sec bars seems to be
working fine (looking at realTimeBars only). One has to be mindful of
indicator and signal calculations though. If these  slow things down to
much, using longer bars may be the only option, aside from optimizing
the
indicator/signal processing (which certainly needs to be done at some
point in the future)

Soren


> Hey guys,
>
> has anyone ever checked runtime statistics, in the sense of processing
> speed, etc. of R in live trading?
> Obviously, it is possible to also implement C equations, but I am
> wondering
> if R etc are used in real intraday trading and about the performance
> characteristics observed.
>
> Thanks
> Ulrich
>
>
>
>
> On Sun, Jun 19, 2011 at 3:08 PM, <me at censix.com> wrote:
>
>> Alex
>>
>> once you have developed a strategy in 'quantstrat' and if you feel
>> adventurous and want to use it for live trading, I can (shamelessly)
>> recommend that you have a look at my 'qsiblive' download here.
>>
>> http://censix.com
>>
>> It may be of interest.
>>
>> regards
>>
>> Soren
>>
>>
>>
>> > Hi there,
>> >
>> > I am new to R and want to perform a few experiments with trading
>> > strategies
>> > with R.
>> >
>> > However, I have experience in programming, but not in R (it's very
>> similar
>> > to what a programmer would expect).
>> >
>> > For now, I've parsed some data (Open, High, Low, Close) of a
security
>> via
>> > read.table, which works fine.
>> > What I want to do now, is to perform a backtest of a simple trading
>> > strategy
>> > with R. Say, for example "buy on cross of MA(200) and MA(100)". Of
>> course
>> > I
>> > could write the backtest routine by myself, but I saw a package
called
>> > backtest. However, I do not really get the point how this may work.
>> How
>> > could I use backtest package to analyse a simple strategy as above?
>> >
>> > Additionally, I would like to know, if there are some websites,
wikis
>> etc.
>> > which give a basic introduction to R in Finance "for dummies"?
>> Anything
>> > I've
>> > seen so far was more or less for professionals.
>> >
>> >
>> > Thank you in advance
>> > Alex
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only. If you want to post, subscribe first.
>> > -- Also note that this is not the r-help list where general R
>> questions
>> > should go.
>> >
>>
>>
>> --
>> http://censix.com
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R
questions
>> should go.
>>
>
>
>
> --
> Ulrich Staudinger
>
> http://www.activequant.org
> Connect online: https://www.xing.com/profile/Ulrich_Staudinger
>


-- 
http://censix.com



------------------------------

_______________________________________________
R-SIG-Finance mailing list
R-SIG-Finance at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-finance


End of R-SIG-Finance Digest, Vol 85, Issue 20


From ggrothendieck at gmail.com  Wed Jun 22 12:59:12 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 22 Jun 2011 06:59:12 -0400
Subject: [R-SIG-Finance] Handling half hourly data from electricity
	markets
In-Reply-To: <42CD7E9FF8F8164CA3BBD8FD84D7C7210547611F@swhexprod.hydrotasmania.com.au>
References: <mailman.3.1308650402.6191.r-sig-finance@r-project.org>
	<42CD7E9FF8F8164CA3BBD8FD84D7C7210547611F@swhexprod.hydrotasmania.com.au>
Message-ID: <BANLkTinhfX=Yo5KiP2Zs1Z6aUVpuxiX+ng@mail.gmail.com>

On Wed, Jun 22, 2011 at 2:08 AM, Adrian Ladaniwskyj
<Adrian.Ladaniwskyj at hydro.com.au> wrote:
>
>
> Hi all;
>
> I am attempting to conduct analysis on half hourly Australian NEM
> electricity market wholesale price data.
>
> I need a way to parse a half hourly dataset, and generate Yearly,
> Quarterly, and Monthly peak/offpeak average prices, in line with the
> form of quoted pricing for typical OTC and futures market energy swap
> products.
>
> Peak is defined between 7am and 10pm market time, offpeak 10pm-7am.
>
> (For example , to get the average peak price for jan, 2011, I need to be
> able to select ONLY price data from jan 2011, that occurred between 7am
> and 10pm, sum the prices, then divide them by the number of instances
> for the desired result)
>
> I cannot seem to find an adequate coded example of how to achieve this
> as yet.
>
> An example of the data I am working with is set out below:
>
> Iteration ? ? ? ? ? ? Time $/MWh $/MWh $/MWh
> 2 ? ? ? ? ?1 2011-01-01 00:30 22.00 16.37 23.64
> 3 ? ? ? ? ?1 2011-01-01 01:00 17.69 16.53 15.49
> 4 ? ? ? ? ?1 2011-01-01 01:30 16.49 15.00 15.09
> 5 ? ? ? ? ?1 2011-01-01 02:00 12.17 11.73 10.96
> 6 ? ? ? ? ?1 2011-01-01 02:30 ?7.38 ?7.20 ?6.73
> 7 ? ? ? ? ?1 2011-01-01 03:00 ?6.10 ?6.24 ?5.36
> 8 ? ? ? ? ?1 2011-01-01 03:30 ?5.80 ?6.24 ?4.91
> 9 ? ? ? ? ?1 2011-01-01 04:00 ?4.98 ?5.40 ?4.10
> 10 ? ? ? ? 1 2011-01-01 04:30 ?5.72 ?6.24 ?4.72
>
> If anyone can assist me in this, it would be greatly appreciated.
>

Set up a peak column (TRUE for peak, FALSE for offpeak) and then
aggregate by peak and month, quarter or year.  To get the month and
quarter use as.yearmon and as.yearqtr from zoo.

 Lines <- "Iteration             Time $/MWh $/MWh $/MWh
2          1 2011-01-01 03:30 22.00 16.37 23.64
3          1 2011-01-01 04:00 17.69 16.53 15.49
4          1 2011-01-01 11:30 16.49 15.00 15.09
5          1 2012-01-01 12:00 12.17 11.73 10.96
6          1 2012-01-01 12:30  7.38  7.20  6.73
7          1 2012-01-01 13:00  6.10  6.24  5.36
8          1 2012-01-01 13:30  5.80  6.24  4.91
9          1 2012-04-01 14:00  4.98  5.40  4.10
10         1 2012-04-01 14:30  5.72  6.24  4.72"

library(zoo)
# DF <- read.table("myfile", ...whatever...)
DF <- read.table(textConnection(Lines), skip = 1, as.is = TRUE,
	col.names = c("", "", "Date", "Time", "X1", "X2", "X3"))[-(1:2)]

DF <- transform(DF, peak = Time >= "07:00" & Time <= "22:00")
aggregate(cbind(X1, X2, X3) ~ peak + as.yearmon(Date), DF, mean)
aggregate(cbind(X1, X2, X3) ~ peak + as.yearqtr(Date), DF, mean)
aggregate(cbind(X1, X2, X3) ~ peak + years(Date), DF, mean)

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From arturo.sanchezcorrea at gmail.com  Wed Jun 22 23:31:32 2011
From: arturo.sanchezcorrea at gmail.com (=?ISO-8859-1?Q?Arturo_S=E1nchez_Correa?=)
Date: Wed, 22 Jun 2011 16:31:32 -0500
Subject: [R-SIG-Finance] RE  Handling half hourly data from electricity
Message-ID: <BANLkTinXtnAHx2F-kGZe+tbOerKhzBcgpA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110622/ef7d5c08/attachment.pl>

From edhenrilevi at gmail.com  Thu Jun 23 05:19:36 2011
From: edhenrilevi at gmail.com (Eduardo Henri-Levy)
Date: Wed, 22 Jun 2011 20:19:36 -0700
Subject: [R-SIG-Finance] Analyze Many Trading Systems Against a Metric
Message-ID: <BANLkTi=LytsG4LWkD_2G00jvqL=wrpKBRA@mail.gmail.com>

Hi,

I'm a data analyst new to the world of quantiative finance. I have at my
access a large history of performance data for around 150,000 different
automated trading systems. I have minute by minute data starting from 2003
to present.

One of the first thing's I'm trying to do is compare the daily performance
data of a subset of a few hundred of the total number of systems to a
baseline metric, call it MetricX.

My question is twofold, the first part about being more math-centric and the
2nd part being R based.

1st part:

I want a measure of the relation between a system and MetricX.
What would your first step be to see which systems have any kind of
relationship with MetricX?

2nd part:
how would you perform the above analysis using R? Are there particular
libraries that would simplify this analysis?

As an example of what I'm trying to do, see the code and graphs below. The
red line is MetricX, and the four plots are different systems. I am looking
for a way to find which systems have the strongest relationship wiht
MetricX, and the ones that have the weakest relationship with MetricX.

Thanks in advance,
EHL

require(ggplot2)
require(plyr)
set.seed(786)
n <- 100
sys1 <- rnorm(n, mean=100, sd=10)
sys2 <- rnorm(n, mean=80, sd=50)
sys3 <- rnorm(n, mean=120, sd=10)
sys4 <- rnorm(n, mean=90, sd=5)
date <- seq(1, n)
metricX <-  50*(sin(0.1*date)) + 100
temp_df <- data.frame(sys1, sys2, sys3, sys4, date, metricX)
df <- melt(temp_df, id=c("date", "metricX"))
p <- ggplot(df, aes(x=date, y=value)) + geom_line() + facet_wrap("variable")
p <- p + geom_line(aes(x=date, y=metricX), colour="red", size=1.0)
p
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110622/1575a1ac/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sys.png
Type: image/png
Size: 24200 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110622/1575a1ac/attachment.png>

From dlincke at lincke.net  Thu Jun 23 20:10:26 2011
From: dlincke at lincke.net (dlincke at lincke.net)
Date: Thu, 23 Jun 2011 14:10:26 -0400 (EDT)
Subject: [R-SIG-Finance] Trouble with RBloomberg on R 2.13.0
Message-ID: <2138811547.602262.1308852626379.JavaMail.open-xchange@oxusltgw07.schlund.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110623/3f461922/attachment.pl>

From thomas.browne at mac.com  Thu Jun 23 23:17:20 2011
From: thomas.browne at mac.com (thomas.browne at mac.com)
Date: Thu, 23 Jun 2011 22:17:20 +0100
Subject: [R-SIG-Finance] Smile pricing of FX options
References: <86C8EEBC-AA64-4389-872A-70C8827F40B1@me.com>
Message-ID: <E5A560AE-8A85-4E73-819D-F8C27E489112@mac.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110623/3228900a/attachment.pl>

From qian at wealthfront.com  Fri Jun 24 00:09:49 2011
From: qian at wealthfront.com (Qian Liu)
Date: Thu, 23 Jun 2011 15:09:49 -0700
Subject: [R-SIG-Finance] Is there a function to calculate internal rate of
	return in R?
Message-ID: <BANLkTi=Yj_Cn6cdxKF-2jn0z_D+XPoVv6g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110623/774e77fc/attachment.pl>

From aeolus_lu at hotmail.com  Fri Jun 24 00:36:58 2011
From: aeolus_lu at hotmail.com (Yihao Lu aeolus_lu)
Date: Thu, 23 Jun 2011 18:36:58 -0400
Subject: [R-SIG-Finance] Is there a function to calculate internal rate
 of return in R?
In-Reply-To: <BANLkTi=Yj_Cn6cdxKF-2jn0z_D+XPoVv6g@mail.gmail.com>
References: <BANLkTi=Yj_Cn6cdxKF-2jn0z_D+XPoVv6g@mail.gmail.com>
Message-ID: <COL120-W1229727698E5B7A00E14EB88530@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110623/77b0e7f7/attachment.pl>

From aeolus_lu at hotmail.com  Fri Jun 24 00:42:44 2011
From: aeolus_lu at hotmail.com (Yihao Lu aeolus_lu)
Date: Thu, 23 Jun 2011 18:42:44 -0400
Subject: [R-SIG-Finance] Is there a function to calculate internal rate
 of return in R?
In-Reply-To: <COL120-W1229727698E5B7A00E14EB88530@phx.gbl>
References: <BANLkTi=Yj_Cn6cdxKF-2jn0z_D+XPoVv6g@mail.gmail.com>,
	<COL120-W1229727698E5B7A00E14EB88530@phx.gbl>
Message-ID: <COL120-W102A60A4C7A8F946BBDB1B88530@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110623/cd595150/attachment.pl>

From aeolus_lu at hotmail.com  Fri Jun 24 04:25:46 2011
From: aeolus_lu at hotmail.com (Yihao Lu aeolus_lu)
Date: Thu, 23 Jun 2011 22:25:46 -0400
Subject: [R-SIG-Finance] plain mean variance optimization
In-Reply-To: <COL120-W102A60A4C7A8F946BBDB1B88530@phx.gbl>
References: <BANLkTi=Yj_Cn6cdxKF-2jn0z_D+XPoVv6g@mail.gmail.com>, ,
	<COL120-W1229727698E5B7A00E14EB88530@phx.gbl>,
	<COL120-W102A60A4C7A8F946BBDB1B88530@phx.gbl>
Message-ID: <COL120-W541503D059BA7E8308F52788520@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110623/a5f00f7e/attachment.pl>

From matthias.kornexl at raiffeisenbank.at  Fri Jun 24 08:03:29 2011
From: matthias.kornexl at raiffeisenbank.at (matthias.kornexl at raiffeisenbank.at)
Date: Fri, 24 Jun 2011 08:03:29 +0200
Subject: [R-SIG-Finance]  plain mean variance optimization
In-Reply-To: <COL120-W541503D059BA7E8308F52788520@phx.gbl>
References: <BANLkTi=Yj_Cn6cdxKF-2jn0z_D+XPoVv6g@mail.gmail.com>, ,
	<COL120-W1229727698E5B7A00E14EB88530@phx.gbl>, 
	<COL120-W102A60A4C7A8F946BBDB1B88530@phx.gbl>
	<COL120-W541503D059BA7E8308F52788520@phx.gbl>
Message-ID: <OFE38C5977.2B43944C-ONC12578B9.0020E5DE-C12578B9.002146F5@mdcs.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110624/45c2567a/attachment.pl>

From benjamin.sigel at gmail.com  Fri Jun 24 13:00:26 2011
From: benjamin.sigel at gmail.com (benjamin sigel)
Date: Fri, 24 Jun 2011 13:00:26 +0200
Subject: [R-SIG-Finance] High performance computing with R
Message-ID: <BANLkTim+HaNzwm0nZRCXkZ9RqsTfZfmj_Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110624/9cd03fb2/attachment.pl>

From me at censix.com  Fri Jun 24 13:13:52 2011
From: me at censix.com (soren wilkening)
Date: Fri, 24 Jun 2011 04:13:52 -0700 (PDT)
Subject: [R-SIG-Finance] High performance computing with R
In-Reply-To: <BANLkTim+HaNzwm0nZRCXkZ9RqsTfZfmj_Q@mail.gmail.com>
References: <BANLkTim+HaNzwm0nZRCXkZ9RqsTfZfmj_Q@mail.gmail.com>
Message-ID: <1308914032519-3622262.post@n4.nabble.com>

Hi

This will depend on what kind of tests you want to run and on what amount of
data. Find an answer to that question first. 

Then you trial-run these tests on your currently available hardware. And you
may see that not even the two setups you are suggesting will be sufficiently
fast for *some* tests. 

As for the hardware choices. I prefer simpler one-box solutions. less
hassle.

You may also want to look at the 'multicore' package (linux only).

regards

Soren

http://censix.com

-----
http://censix.com
--
View this message in context: http://r.789695.n4.nabble.com/High-performance-computing-with-R-tp3622249p3622262.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From daniel_krizian at tam.sk  Fri Jun 24 15:24:45 2011
From: daniel_krizian at tam.sk (Daniel Krizian)
Date: Fri, 24 Jun 2011 06:24:45 -0700 (PDT)
Subject: [R-SIG-Finance] New to R and Finance, backtest etc.
In-Reply-To: <BANLkTinz8QYF-+XQgU+T6fR4NL6YKaQFgA@mail.gmail.com>
References: <BANLkTi==AbTawv4sVNcz8xnBoMx78FiV8w@mail.gmail.com>
	<BLU0-SMTP191F3B549AC987A609CEA0E8F6F0@phx.gbl>
	<BANLkTinz8QYF-+XQgU+T6fR4NL6YKaQFgA@mail.gmail.com>
Message-ID: <1308921885406-3622522.post@n4.nabble.com>

Alex, 
I have had the same bug, and found that in line:
s <- add.signal(s, name="sigCrossover", arguments =
list(data=quote(mktdata), columns=c("Close","SMA"), relationship="gt"),
label="Cl.gt.SMA")

change 
columns=c("Close","SMA")
to
columns=c("Close","SMA10").

This bug was in a certain copy of the faber example only (don't remember
where I got that copy from).
Brian's latest link to a different copy of faber demo works fine.

Daniel

--
View this message in context: http://r.789695.n4.nabble.com/New-to-R-and-Finance-backtest-etc-tp3608005p3622522.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From cedrick at cedrickjohnson.com  Fri Jun 24 19:57:14 2011
From: cedrick at cedrickjohnson.com (Cedrick Johnson)
Date: Fri, 24 Jun 2011 13:57:14 -0400
Subject: [R-SIG-Finance] High performance computing with R
In-Reply-To: <BANLkTim+HaNzwm0nZRCXkZ9RqsTfZfmj_Q@mail.gmail.com>
References: <BANLkTim+HaNzwm0nZRCXkZ9RqsTfZfmj_Q@mail.gmail.com>
Message-ID: <4E04CFFA.7070905@cedrickjohnson.com>

The easiest probably would be to use the multicore package (linux) on 
one machine, but if you're feeling ambitious, there's also the 
possibility of using doSNOW, but there's some small idosyncracies that 
will leave you (or at least it did for me) pulling your hair out trying 
to figure out why certain things aren't working.

If you're on Windows only, another single box solution would be the 
"doSMP" and "foreach" packages that were released by Revolution into CRAN.

here's a short example of how I use it on Windows (I have a more 
complicated multiple computer script buried somewhere using doSNOW on 
linux32):

require(doSMP)
require(foreach)

clust <- startWorkers(4)
registerDoSMP(clust)

symbols = c("SPX","DIA","QQQQ")

# the function that you want to parallelize, gets exported to each 
"node" -- could insert your backtest code here
parallel.arima <- function(data) {
library(forecast)
library(quantmod)
tmp = get(data)
fit = auto.arima(ts(Cl(tmp)), approximation=TRUE, allowdrift=TRUE, 
stepwise=TRUE)
}

res <- foreach(dat=symbols, .export=symbols) %dopar% parallel.arima(dat))


There's more info on the r-sig-hpc list regarding some of the finer 
details of the packages mentioned above. Standard disclaimer, this 
probably isn't the "best" way to do it but it should give you some idea 
of where to start.

HTH,
C

On 06/24/2011 07:00 AM, benjamin sigel wrote:
> Hi,
>
> I would like to run multiple backtests with R on intraday data, using
> "quantstrat" and "backtest package" and I was wondering what would be the
> most time efficient hardware solution between these two:
>
> - 1 PC: *1 Quad-Core* (Intel? Core? i5-2300, 2.8 GHz (up to 3.1 GHz with
> Turbo Boost) /6GB installed DDR3 RAM (1066 MHz) + *16GB maximum RAM capacity
> *
>
> OR
>
> - *2 PC's Hooked-up:* 2 Dual-core (Intel? Core? i3-550 Processor, 3.20 GHz,
> 4 MB Smart Cache, 4GB DDR3 + *maximum expandable memory 16GB* *each*
>
> Many Thanks for your help,
>
> Ben
>
> 	[[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From gsee000 at gmail.com  Fri Jun 24 20:32:47 2011
From: gsee000 at gmail.com (G See)
Date: Fri, 24 Jun 2011 13:32:47 -0500
Subject: [R-SIG-Finance] High performance computing with R
In-Reply-To: <BANLkTim+HaNzwm0nZRCXkZ9RqsTfZfmj_Q@mail.gmail.com>
References: <BANLkTim+HaNzwm0nZRCXkZ9RqsTfZfmj_Q@mail.gmail.com>
Message-ID: <BANLkTi=BMU8WaMZFQdU_HMVWnNHCqaZZPA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110624/236b4377/attachment.pl>

From edd at debian.org  Fri Jun 24 20:35:39 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 24 Jun 2011 13:35:39 -0500
Subject: [R-SIG-Finance] plain mean variance optimization
In-Reply-To: <COL120-W541503D059BA7E8308F52788520@phx.gbl>
References: <BANLkTi=Yj_Cn6cdxKF-2jn0z_D+XPoVv6g@mail.gmail.com>
	<COL120-W1229727698E5B7A00E14EB88530@phx.gbl>
	<COL120-W102A60A4C7A8F946BBDB1B88530@phx.gbl>
	<COL120-W541503D059BA7E8308F52788520@phx.gbl>
Message-ID: <19972.55547.548020.847455@max.nulle.part>


On 23 June 2011 at 22:25, Yihao Lu aeolus_lu wrote:
| 
| Hi,I wonder if there is any good package to do portfolio allocation/optimization. I would like to start with some plain mean variance optimization, but I wish the package can do more, say with different type of constraints. It will also be great if the package can help estimate optimization parameters.

The tseries package has supported that for a decade already, and uses the
quadprog package as a solver.  About that long ago I had written a patch for
it which Adrian included which allowed for short as well as longs (following
the standard approach in Huang and Litzenberger).

Dirk

-- 
Gauss once played himself in a zero-sum game and won $50.
                      -- #11 at http://www.gaussfacts.com


From josh.m.ulrich at gmail.com  Sat Jun 25 04:03:14 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 24 Jun 2011 21:03:14 -0500
Subject: [R-SIG-Finance] Offset a vector by 1 to k months
In-Reply-To: <004c01cc2fd0$8823eaa0$4401a8c0@IraHP>
References: <004c01cc2fd0$8823eaa0$4401a8c0@IraHP>
Message-ID: <BANLkTi=QDqzYh8kX4ZH5EHo56WezrhSu8Q@mail.gmail.com>

On Tue, Jun 21, 2011 at 12:03 AM, Ira Sharenow <irasharenow100 at yahoo.com> wrote:
> I am new to financial time series, zoo, and xts.
>
> I have a length n vector (vDates) of dates. I have an n by k ?matrix (mDates). In row i and column j of the matrix, I would like the value to be the row i value of the vector + j months.
>
Adding a certain number of months isn't necessarily that easy.  You
need to choose a calendar convention.  For example, see
RQuantLib::advance().

> mDates[i,j] ?= vDates[i] + j months.
>
> I would like to do this without loops.
>
> I solved the problem with just numbers.
>
> v1 = 11:15
> m1 = matrix(rep(0,20), nrow = 5)
> m1 = v1 + col(m1)
>
> I do not know how to add months in zoo or xts, so I tried lubridate.
>
> library(lubridate)
> vDate = as.Date(c("2011-06-01", "2011-06-02", "2011-06-03"), "%Y-%m-%d")
> mDate2 ?= vDate ?+ months(1) ?this works fine
>
Are you sure this is fine?  Are you comfortable with the assumptions
being made?  For example:
mDate <- timeBasedSeq("201101/20110203")
tail(mDate + months(1))
# [1] "2011-03-01" "2011-03-02" "2011-03-03" "2011-03-01"
# [5] "2011-03-02" "2011-03-03"

> But I do not know how to solve the problem for a matrix.
>
> library(xts)
> charvec = paste("2011-0", 1:2, "-01", sep = "")
> theData = matrix(rep(0,6),nrow = 2)
> z1 = xts(theData, as.Date(charvec))
>
> I want the rows of z1 data to be
> 2011-02-01 ?2011-03-01 2011-04-01
> 2011-03-01 ?2011-04-01 2011-05-01
>
You can add a month to each index value via:
ISOdate(year(index(z1)),month(index(z1))+1,day(index(z1)))
# [1] "2011-02-01 12:00:00 GMT" "2011-03-01 12:00:00 GMT"

But you can't have Date class objects inside xts/zoo objects.  xts/zoo
objects are just matrix objects with an index attribute and matrix
objects can only contain atomic types (or list or expression).

Perhaps if you provide a bit more detail about your actual problem,
someone can show you a more "R-like" solution.

> Thanks.
> Ira
>

Hope that helps,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From irasharenow100 at yahoo.com  Sat Jun 25 10:07:08 2011
From: irasharenow100 at yahoo.com (Ira Sharenow)
Date: Sat, 25 Jun 2011 01:07:08 -0700
Subject: [R-SIG-Finance] Offset a vector by 1 to k months
References: <004c01cc2fd0$8823eaa0$4401a8c0@IraHP>
	<BANLkTi=QDqzYh8kX4ZH5EHo56WezrhSu8Q@mail.gmail.com>
Message-ID: <005e01cc330e$e1f8cf00$4401a8c0@IraHP>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110625/9a48afa8/attachment.pl>

From kriskumar at earthlink.net  Sun Jun 26 17:46:10 2011
From: kriskumar at earthlink.net (krishna)
Date: Sun, 26 Jun 2011 11:46:10 -0400
Subject: [R-SIG-Finance] Smile pricing of FX options
In-Reply-To: <E5A560AE-8A85-4E73-819D-F8C27E489112@mac.com>
References: <86C8EEBC-AA64-4389-872A-70C8827F40B1@me.com>
	<E5A560AE-8A85-4E73-819D-F8C27E489112@mac.com>
Message-ID: <677576B4-61A2-43A5-8B9F-77AEE3D8D13F@earthlink.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110626/6e739e4a/attachment.pl>

From thomas.browne at mac.com  Sun Jun 26 20:03:20 2011
From: thomas.browne at mac.com (tbrowne)
Date: Sun, 26 Jun 2011 19:03:20 +0100
Subject: [R-SIG-Finance] Smile pricing of FX options
In-Reply-To: <677576B4-61A2-43A5-8B9F-77AEE3D8D13F@earthlink.net>
References: <86C8EEBC-AA64-4389-872A-70C8827F40B1@me.com>
	<E5A560AE-8A85-4E73-819D-F8C27E489112@mac.com>
	<677576B4-61A2-43A5-8B9F-77AEE3D8D13F@earthlink.net>
Message-ID: <34454501-A464-4247-BB87-D9219F85FF30@mac.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110626/d8ed80a6/attachment.pl>

From thomas.browne at mac.com  Sun Jun 26 23:59:17 2011
From: thomas.browne at mac.com (thomas.browne at mac.com)
Date: Sun, 26 Jun 2011 22:59:17 +0100
Subject: [R-SIG-Finance] Smile pricing of FX options
In-Reply-To: <34454501-A464-4247-BB87-D9219F85FF30@mac.com>
References: <86C8EEBC-AA64-4389-872A-70C8827F40B1@me.com>
	<E5A560AE-8A85-4E73-819D-F8C27E489112@mac.com>
	<677576B4-61A2-43A5-8B9F-77AEE3D8D13F@earthlink.net>
	<34454501-A464-4247-BB87-D9219F85FF30@mac.com>
Message-ID: <25E4F04B-03ED-4288-B2AC-C95C0DD23C73@mac.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110626/8a88f559/attachment.pl>

From zach.mayer at gmail.com  Mon Jun 27 03:39:38 2011
From: zach.mayer at gmail.com (Zachary Mayer)
Date: Sun, 26 Jun 2011 21:39:38 -0400
Subject: [R-SIG-Finance] High performance computing with R
Message-ID: <BANLkTi=Az-bXKujR=_wawz0sy2U3Nzo4qA@mail.gmail.com>

Hello,

I'm not 100% sure how to respond to an individual message from the
daily digest, so I apologize if I am violating protocol here.

Ben-- I suggest you do a little research into the foreach package for
R, as well as the various foreach backends, which include doMC, doSMP,
doSnow, doMPI and doRedis. foreach is a generalized framework to
parallelize for loops in r. The various backends enable that
parallelism using different technologies: doMC uses the "fork" command
on linux, doSnow uses a "Snow" cluster, and doRedis uses a redis
server.  Each backend has various pros and cons. As stated before,
doMC (and it's sister package multicore) are probably the best
solution for a single machine: you can use the function 'mclapply' to
replace the vanilla function 'lapply' and have instant parallelism
with almost no extra work, but neither package works on windows or
with Rstudio.   doRedis is my current favorite solution for clusters
of multiple machines on amazon EC2, but it takes a small amount of
extra work to setup a redis server.

The answer to your question really depends on your operating system,
how many machines you have, and what technologies you are comfortable
with.  Do a some research before you commit to hardware, and re-write
your code to make use of the 'foreach' looping structure.

Good luck!

-Zach

> Hi,
>
> I would like to run multiple backtests with R on intraday data, using
> "quantstrat" and "backtest package" and I was wondering what would be the
> most time efficient hardware solution between these two:
>
> - 1 PC: *1 Quad-Core* (Intel? Core? i5-2300, 2.8 GHz (up to 3.1 GHz with
> Turbo Boost) /6GB installed DDR3 RAM (1066 MHz) + *16GB maximum RAM capacity
> *
>
> OR
>
> - *2 PC's Hooked-up:* 2 Dual-core (Intel? Core? i3-550 Processor, 3.20 GHz,
> 4 MB Smart Cache, 4GB DDR3 + *maximum expandable memory 16GB* *each*
>
> Many Thanks for your help,
>
> Ben
>


From kriskumar at earthlink.net  Mon Jun 27 04:24:36 2011
From: kriskumar at earthlink.net (Krishna)
Date: Sun, 26 Jun 2011 22:24:36 -0400
Subject: [R-SIG-Finance] Smile pricing of FX options
In-Reply-To: <25E4F04B-03ED-4288-B2AC-C95C0DD23C73@mac.com>
References: <86C8EEBC-AA64-4389-872A-70C8827F40B1@me.com>
	<E5A560AE-8A85-4E73-819D-F8C27E489112@mac.com>
	<677576B4-61A2-43A5-8B9F-77AEE3D8D13F@earthlink.net>
	<34454501-A464-4247-BB87-D9219F85FF30@mac.com>
	<25E4F04B-03ED-4288-B2AC-C95C0DD23C73@mac.com>
Message-ID: <18AF8907-6DB7-433D-996D-032531123A05@earthlink.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110626/da64ab2f/attachment.pl>

From schmidbe at in.tum.de  Mon Jun 27 14:22:13 2011
From: schmidbe at in.tum.de (Markus Schmidberger)
Date: Mon, 27 Jun 2011 14:22:13 +0200
Subject: [R-SIG-Finance]  High performance computing with R
Message-ID: <1309177333.2552.9.camel@schmidb-TravelMate8572TG>

Yes, there are some problems with Rstudio and multicore or computer
cluster systems. I hope they will fix that in one of the next releases!

If there is no computer cluster available you should try
cloudnumbers.com. You will get access to a computer cluster in the cloud
in less than 10 minutes. Everything is pre-configured, including R, all
R packages and parallel computing technologies. Actually the beta phase
is running. You will get free resources!

Best
Markus



Date: Sun, 26 Jun 2011 21:39:38 -0400
From: Zachary Mayer <zach.mayer at gmail.com>
To: r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] High performance computing with R
Message-ID: <BANLkTi=Az-bXKujR=_wawz0sy2U3Nzo4qA at mail.gmail.com>
Content-Type: text/plain; charset=windows-1252

Hello,

I'm not 100% sure how to respond to an individual message from the
daily digest, so I apologize if I am violating protocol here.

Ben-- I suggest you do a little research into the foreach package for
R, as well as the various foreach backends, which include doMC, doSMP,
doSnow, doMPI and doRedis. foreach is a generalized framework to
parallelize for loops in r. The various backends enable that
parallelism using different technologies: doMC uses the "fork" command
on linux, doSnow uses a "Snow" cluster, and doRedis uses a redis
server.  Each backend has various pros and cons. As stated before,
doMC (and it's sister package multicore) are probably the best
solution for a single machine: you can use the function 'mclapply' to
replace the vanilla function 'lapply' and have instant parallelism
with almost no extra work, but neither package works on windows or
with Rstudio.   doRedis is my current favorite solution for clusters
of multiple machines on amazon EC2, but it takes a small amount of
extra work to setup a redis server.

The answer to your question really depends on your operating system,
how many machines you have, and what technologies you are comfortable
with.  Do a some research before you commit to hardware, and re-write
your code to make use of the 'foreach' looping structure.

Good luck!



-- 
Dr. rer. nat. Markus Schmidberger 
Senior Community Manager 

Cloudnumbers.com GmbH
Chausseestra?e 6
10119 Berlin 

www.cloudnumbers.com 
E-Mail: markus.schmidberger at cloudnumbers.com 


************************* 
Amtsgericht M?nchen, HRB 191138 
Gesch?ftsf?hrer: Erik Muttersbach, Markus Fensterer, Moritz v. 
Petersdorff-Campen 



Diese Nachricht kann vertrauliche Informationen enthalten. Sollten Sie 
nicht der vorgesehene Empf?nger sein, so bitten wir um eine kurze 
Nachricht. Jede unbefugte Weiterleitung oder Fertigung einer Kopie ist 
unzul?ssig. Da wir nicht die Echtheit oder  Vollst?ndigkeit der in 
dieser Nachricht enthaltenen Informationen garantieren k?nnen, 
schlie?en wir die rechtliche Verbindlichkeit der vorstehenden 
Erkl?rungen und ?u?erungen aus. 
This message may contain confidential information. If yo...{{dropped:6}}


From rharlow86 at gmail.com  Mon Jun 27 20:49:35 2011
From: rharlow86 at gmail.com (Robert Harlow)
Date: Mon, 27 Jun 2011 14:49:35 -0400
Subject: [R-SIG-Finance] Rsolnp for Portfolio Optimization with Turnover
	Constraints
Message-ID: <BANLkTindRXNepqe+Djh4VR0RPaTa=XR4Eg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110627/2d207038/attachment.pl>

From alexios at 4dscape.com  Mon Jun 27 23:30:39 2011
From: alexios at 4dscape.com (alexios ghalanos)
Date: Mon, 27 Jun 2011 22:30:39 +0100
Subject: [R-SIG-Finance] Rsolnp for Portfolio Optimization with Turnover
 Constraints
In-Reply-To: <BANLkTindRXNepqe+Djh4VR0RPaTa=XR4Eg@mail.gmail.com>
References: <BANLkTindRXNepqe+Djh4VR0RPaTa=XR4Eg@mail.gmail.com>
Message-ID: <4E08F67F.8020802@4dscape.com>

Hi Bob,

This is likely a bug arising when there is no convergence (will upload a
fix for that soon) and introduced in the latest
version.
In your example, this arises because you set the starting parameters to
zero. Try instead:

x.init <- rep(1/14, 14)

Regards,

Alexios



On 6/27/2011 7:49 PM, Robert Harlow wrote:
> Hi,
>    I am trying to use Rsolnp in a portfolio optimization context.  While I
> know that my current example is solvable as QP, my risk function, which is
> variance right now, could become more complicated later.  Basically, I want
> to start with an equal weighted portfolio, and then minimize risk with a
> tracking error constraint.  I was able to achieve this relatively easily
> with fmincon in matlab, so I am wondering what the issue is here.
>
> My reproducible code is below:
>
> library(Matrix)
> library(Rsolnp)
> upper.tri <- c(17.82, 19.84, 4.96, 4, 3.79, 1.62, -.05,
>                35.67, 6.83, 3.52, 2.72, 1.07, -.07,
>                5.12, 3.52, 3.22, 1.81, .01,
>                6.18, 6.36, 3.24, .04,
>                7.95, 3.80, .05,
>                2.47, .06,
>                .04)
> cov.mat <- matrix(0, ncol = 7, nrow = 7)
> cov.mat[lower.tri(cov.mat, diag = TRUE)] <- upper.tri
> cov.mat <- t(cov.mat)
> cov.mat <- as.matrix(forceSymmetric(cov.mat))
> wInit <- rep(1,7)/7
> x.init <- rep(0, 2*7)
> eq.fun <- function(x, sigma, wInit){
>     sum(x[1:7]) - sum(x[8:14])
> }
> ob.fun <- function(x, sigma, wInit){
>     wgts <- wInit + x[1:7] - x[8:14]
>     as.numeric(wgts%*%sigma%*%wgts)
> }
> ineq.fun <- function(x, sigma, wInit){
>     sum(x[1:7])
> }
> tst <- solnp(x.init, fun = ob.fun, eqfun = eq.fun, eqB = 0, ineqfun =
> ineq.fun, ineqLB = 0, ineqUB = .1, LB = rep(0, 14), UB = rep(1,14), sigma =
> cov.mat, wInit = wInit)
>
> Thank you for the help,
> -Bob
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From andre.levy at stanfordalumni.org  Tue Jun 28 11:35:21 2011
From: andre.levy at stanfordalumni.org (wisdomtooth)
Date: Tue, 28 Jun 2011 02:35:21 -0700 (PDT)
Subject: [R-SIG-Finance] Reuters Tick History package
Message-ID: <1309253721527-3629889.post@n4.nabble.com>

Does anyone have a package for downloading data from TRTH (Thompson Reuters
Tick History) through its API?

I'm not referring to Reuters terminal, as in some of the replies here:
http://r.789695.n4.nabble.com/REUTERS-tp3013463p3013649.html

--
View this message in context: http://r.789695.n4.nabble.com/Reuters-Tick-History-package-tp3629889p3629889.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From fabian.lorenz at gmail.com  Wed Jun 29 16:45:43 2011
From: fabian.lorenz at gmail.com (Fabian Lorenz)
Date: Wed, 29 Jun 2011 16:45:43 +0200
Subject: [R-SIG-Finance] Quotes yahoo fin -> db > R > results
Message-ID: <BANLkTikUe99jQz7q7Rt229VEtEQEePjkZg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110629/6511bb60/attachment.pl>

From fabian.lorenz at gmail.com  Wed Jun 29 16:50:20 2011
From: fabian.lorenz at gmail.com (Fabian Lorenz)
Date: Wed, 29 Jun 2011 16:50:20 +0200
Subject: [R-SIG-Finance] Quotes yahoo fin -> db > R > results
In-Reply-To: <BANLkTikUe99jQz7q7Rt229VEtEQEePjkZg@mail.gmail.com>
References: <BANLkTikUe99jQz7q7Rt229VEtEQEePjkZg@mail.gmail.com>
Message-ID: <BANLkTikMA0EyaG-X9Z3fQ8E3cG8VM9K_UA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110629/9e3d59d4/attachment.pl>

From j_cuisinier at hotmail.com  Wed Jun 29 16:53:59 2011
From: j_cuisinier at hotmail.com (julien cuisinier)
Date: Wed, 29 Jun 2011 16:53:59 +0200
Subject: [R-SIG-Finance] Quotes yahoo fin -> db > R > results
In-Reply-To: <BANLkTikUe99jQz7q7Rt229VEtEQEePjkZg@mail.gmail.com>
References: <BANLkTikUe99jQz7q7Rt229VEtEQEePjkZg@mail.gmail.com>
Message-ID: <COL102-W51A3D80A3C57EDB43A52BC8F590@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110629/05d016d4/attachment.pl>

From mail at joeconway.com  Wed Jun 29 17:36:35 2011
From: mail at joeconway.com (Joe Conway)
Date: Wed, 29 Jun 2011 08:36:35 -0700
Subject: [R-SIG-Finance] Quotes yahoo fin -> db > R > results
In-Reply-To: <BANLkTikUe99jQz7q7Rt229VEtEQEePjkZg@mail.gmail.com>
References: <BANLkTikUe99jQz7q7Rt229VEtEQEePjkZg@mail.gmail.com>
Message-ID: <4E0B4683.7070300@joeconway.com>

On 06/29/2011 07:45 AM, Fabian Lorenz wrote:
> I'm trying to collect data automatically from yahoo finance to a mysql or
> postgresql  for further R data process.
> 
> Anybody knows how about?

For one possible way from within PostgreSQL see:

http://www.joeconway.com/presentations/pgday-lightning-2009.07.19.r00.pdf

HTH,

Joe

-- 
Joe Conway
credativ LLC: http://www.credativ.us
Linux, PostgreSQL, and general Open Source
Training, Service, Consulting, & 24x7 Support

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 899 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110629/66162ddf/attachment.bin>

From edd at debian.org  Wed Jun 29 18:00:08 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 29 Jun 2011 11:00:08 -0500
Subject: [R-SIG-Finance] Quotes yahoo fin -> db > R > results
In-Reply-To: <BANLkTikUe99jQz7q7Rt229VEtEQEePjkZg@mail.gmail.com>
References: <BANLkTikUe99jQz7q7Rt229VEtEQEePjkZg@mail.gmail.com>
Message-ID: <19979.19464.818032.314608@max.nulle.part>


On 29 June 2011 at 16:45, Fabian Lorenz wrote:
| I'm trying to collect data automatically from yahoo finance to a mysql or
| postgresql  for further R data process.
| 
| Anybody knows how about?

I can help with the first part in a fully automated fashion, see

   http://dirk.eddelbuettel.com/code/beancounter.hyml

Key features:

 - automated setup for either MySQL, Postgresql, SQLite or ODBC: creates the
   schema, loads sample data etc (but you still need to take care of the
   backend and things like ODBC drivers)

 - cross-platform for Windows, OS X, Linux

 - Written in Perl, mostly around 1999 to 2001; I still maintain it in the
   sense of fixing bugs, I have not added features in years

 - I (and others) use it for automated data download given a portfolio; for
   me it then creates a daily email with daily PNL and Risk Estimates for my
   little retail portfolios; "growing" the time series database is a (nice
   and desired) side-effect

 - Can also backpopulate for assets where Yahoo offers history (ie most
   stocks, no options, no fx)

 - Is used as a backend for some (non-R) charting software

I have been meaning to 

  a) rewrite it in R and/or 

  b) write R analysis modules

but I have a "writer's block" as I know so much that could be done leveraging
things like PortfolioAnalytics and PerformanceAnalytics that I still haven't
done it yet.  Would make a great student project for an investment analysis
with R class ...

Hope this helps, feel free to ping me off-list if interested.

Dirk

-- 
Gauss once played himself in a zero-sum game and won $50.
                      -- #11 at http://www.gaussfacts.com


From edd at debian.org  Wed Jun 29 18:01:04 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 29 Jun 2011 11:01:04 -0500
Subject: [R-SIG-Finance] Quotes yahoo fin -> db > R > results
In-Reply-To: <19979.19464.818032.314608@max.nulle.part>
References: <BANLkTikUe99jQz7q7Rt229VEtEQEePjkZg@mail.gmail.com>
	<19979.19464.818032.314608@max.nulle.part>
Message-ID: <19979.19520.148222.295320@max.nulle.part>


On 29 June 2011 at 11:00, Dirk Eddelbuettel wrote:
| 
| On 29 June 2011 at 16:45, Fabian Lorenz wrote:
| | I'm trying to collect data automatically from yahoo finance to a mysql or
| | postgresql  for further R data process.
| | 
| | Anybody knows how about?
| 
| I can help with the first part in a fully automated fashion, see
| 
|    http://dirk.eddelbuettel.com/code/beancounter.hyml

Sorry:  http://dirk.eddelbuettel.com/code/beancounter.html

Dirk
 
| Key features:
| 
|  - automated setup for either MySQL, Postgresql, SQLite or ODBC: creates the
|    schema, loads sample data etc (but you still need to take care of the
|    backend and things like ODBC drivers)
| 
|  - cross-platform for Windows, OS X, Linux
| 
|  - Written in Perl, mostly around 1999 to 2001; I still maintain it in the
|    sense of fixing bugs, I have not added features in years
| 
|  - I (and others) use it for automated data download given a portfolio; for
|    me it then creates a daily email with daily PNL and Risk Estimates for my
|    little retail portfolios; "growing" the time series database is a (nice
|    and desired) side-effect
| 
|  - Can also backpopulate for assets where Yahoo offers history (ie most
|    stocks, no options, no fx)
| 
|  - Is used as a backend for some (non-R) charting software
| 
| I have been meaning to 
| 
|   a) rewrite it in R and/or 
| 
|   b) write R analysis modules
| 
| but I have a "writer's block" as I know so much that could be done leveraging
| things like PortfolioAnalytics and PerformanceAnalytics that I still haven't
| done it yet.  Would make a great student project for an investment analysis
| with R class ...
| 
| Hope this helps, feel free to ping me off-list if interested.
| 
| Dirk
| 
| -- 
| Gauss once played himself in a zero-sum game and won $50.
|                       -- #11 at http://www.gaussfacts.com

-- 
Gauss once played himself in a zero-sum game and won $50.
                      -- #11 at http://www.gaussfacts.com


From pgilbert at bank-banque-canada.ca  Wed Jun 29 23:10:47 2011
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 29 Jun 2011 21:10:47 +0000
Subject: [R-SIG-Finance] Quotes yahoo fin -> db > R > results
In-Reply-To: <19979.19520.148222.295320@max.nulle.part>
References: <BANLkTikUe99jQz7q7Rt229VEtEQEePjkZg@mail.gmail.com>
	<19979.19464.818032.314608@max.nulle.part>
	<19979.19520.148222.295320@max.nulle.part>
Message-ID: <6441154A9FF1CD4386AF4ABF141A056D215B132B@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>

There are also examples that do this in package vinnette guides for TSPostgreSQL and TSMySQL, but not automated in the sense of a cron job.

Paul

> -----Original Message-----
> From: r-sig-finance-bounces at r-project.org [mailto:r-sig-finance-
> bounces at r-project.org] On Behalf Of Dirk Eddelbuettel
> Sent: June 29, 2011 12:01 PM
> To: Fabian Lorenz; r-sig-finance at r-project.org
> Subject: Re: [R-SIG-Finance] Quotes yahoo fin -> db > R > results
> 
> 
> On 29 June 2011 at 11:00, Dirk Eddelbuettel wrote:
> |
> | On 29 June 2011 at 16:45, Fabian Lorenz wrote:
> | | I'm trying to collect data automatically from yahoo finance to a
> mysql or
> | | postgresql  for further R data process.
> | |
> | | Anybody knows how about?
> |
> | I can help with the first part in a fully automated fashion, see
> |
> |    http://dirk.eddelbuettel.com/code/beancounter.hyml
> 
> Sorry:  http://dirk.eddelbuettel.com/code/beancounter.html
> 
> Dirk
> 
> | Key features:
> |
> |  - automated setup for either MySQL, Postgresql, SQLite or ODBC:
> creates the
> |    schema, loads sample data etc (but you still need to take care of
> the
> |    backend and things like ODBC drivers)
> |
> |  - cross-platform for Windows, OS X, Linux
> |
> |  - Written in Perl, mostly around 1999 to 2001; I still maintain it
> in the
> |    sense of fixing bugs, I have not added features in years
> |
> |  - I (and others) use it for automated data download given a
> portfolio; for
> |    me it then creates a daily email with daily PNL and Risk Estimates
> for my
> |    little retail portfolios; "growing" the time series database is a
> (nice
> |    and desired) side-effect
> |
> |  - Can also backpopulate for assets where Yahoo offers history (ie
> most
> |    stocks, no options, no fx)
> |
> |  - Is used as a backend for some (non-R) charting software
> |
> | I have been meaning to
> |
> |   a) rewrite it in R and/or
> |
> |   b) write R analysis modules
> |
> | but I have a "writer's block" as I know so much that could be done
> leveraging
> | things like PortfolioAnalytics and PerformanceAnalytics that I still
> haven't
> | done it yet.  Would make a great student project for an investment
> analysis
> | with R class ...
> |
> | Hope this helps, feel free to ping me off-list if interested.
> |
> | Dirk
> |
> | --
> | Gauss once played himself in a zero-sum game and won $50.
> |                       -- #11 at http://www.gaussfacts.com
> 
> --
> Gauss once played himself in a zero-sum game and won $50.
>                       -- #11 at http://www.gaussfacts.com
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

------------------------------------------------------------------------------------

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

From kwong at fortress.com  Thu Jun 30 02:55:29 2011
From: kwong at fortress.com (KengOnn)
Date: Wed, 29 Jun 2011 17:55:29 -0700 (PDT)
Subject: [R-SIG-Finance] Trouble with RBloomberg on R 2.13.0
In-Reply-To: <2138811547.602262.1308852626379.JavaMail.open-xchange@oxusltgw07.schlund.de>
References: <2138811547.602262.1308852626379.JavaMail.open-xchange@oxusltgw07.schlund.de>
Message-ID: <1309395329515-3634441.post@n4.nabble.com>

I am facing the same problem here:

Error in dimnames(x) <- dn : 'dimnames' applied to non-array 

when I used the same method call (bdp, and even for blh as well). When
googling, I found that another user resolved it by apparently changing the
source code (and I assume, recompiling it as well):

http://r.789695.n4.nabble.com/RBloomberg-Error-in-dimnames-x-lt-dn-dimnames-applied-to-non-array-td3356150.html

But I can't find the source-code (seems only the binaries are available). So
frustrating... (tempted to just use Excel and use RODBC instead..)

--
View this message in context: http://r.789695.n4.nabble.com/Trouble-with-RBloomberg-on-R-2-13-0-tp3620596p3634441.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From kel.graham at gmail.com  Thu Jun 30 10:15:17 2011
From: kel.graham at gmail.com (bb01100100)
Date: Thu, 30 Jun 2011 01:15:17 -0700 (PDT)
Subject: [R-SIG-Finance] setting quantstrat stoplimit threshold to a signal
	value
Message-ID: <1309421717396-3635067.post@n4.nabble.com>

Hello,

I am testing a simple strategy in quantstrat, whereby I would like to set a
'stoplimit' order equal to 75% of the Donchian Channel range.

If the Donchian Channel is as follows:

 a. low = 92.20
 b. high = 110.50

Then I would like to set my 'stoplimit' to: low + (high - low) * 0.75,
giving a price of 105.925

My question is: How can I correctly access mktdata's signal information,
e.g. mktdata$mySignalValue for use in the threshold parameter of add.rule()?

If my approach is wrong, then a backup question is: In quantstrat, how do I
set a long stop / stoplimit order above the market at a price derived from
the signals added to the strategy via add.signal()?



I have tried to use formulas in the add.rule() function's 'threshold'
parameter as below:

myStrat = add.rule(myStrat, name='ruleSignal',
 arguments=list(
   sigcol='trade.long',
   sigval=TRUE,
   orderqty=1,
   ordertype='stoplimit',
   orderside='long',
   threshold=(mktdata$tradeSignal.low + ((mktdata$tradeSignal.high -
mktdata$tradeSignal.low)*0.75) - mktdata$SPY.High),
   tmult=FALSE,
   TxnFees=-5
 ),
type='enter',
replace=TRUE
)


but I get an error:



[1] "Setup completed"
Added a position limit for  SPY 
Error in NextMethod(.Generic) : 
  dims [product 1] do not match the length of object [504]
In addition: Warning messages:
1: In max(i) : no non-missing arguments to max; returning -Inf
2: In max(getOrders(portfolio = portfolio, symbol = symbol, status = "open", 
:
  no non-missing arguments, returning NA
3: In if (!is.null(ordertype) & is.na(charmatch(ordertype, c("market",  :
  the condition has length > 1 and only the first element will be used
4: In if (is.na(charmatch(ordertype, c("market", "limit", "stoplimit",  :
  the condition has length > 1 and only the first element will be used

Which, I assume, means that I'm passing a big list of values from my
threshold formula instead of a specific value.

I have tried using last() on the above formula, but this uses the last value
of the entire mktdata series.

Also, I have searched quite a lot, but all of the examples I have seen look
for a signal and then buy at market, so I'm bit stuck. Any help, pointers or
guidance to a relevant example would be much appreciated.


Thanks,
Kel.


--
View this message in context: http://r.789695.n4.nabble.com/setting-quantstrat-stoplimit-threshold-to-a-signal-value-tp3635067p3635067.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Thu Jun 30 12:04:51 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 30 Jun 2011 05:04:51 -0500
Subject: [R-SIG-Finance] setting quantstrat stoplimit threshold to a
 signal value
In-Reply-To: <1309421717396-3635067.post@n4.nabble.com>
References: <1309421717396-3635067.post@n4.nabble.com>
Message-ID: <1309428291.3905.14.camel@brian-desktop>

On Thu, 2011-06-30 at 01:15 -0700, bb01100100 wrote:
> I am testing a simple strategy in quantstrat, whereby I would like to
> set a 'stoplimit' order equal to 75% of the Donchian Channel range. 

Please provide a reproducible example, per the posting guide. (put
another way, I'm not going to write an entire strategy to figure out
your bug).

Now, some general advice for when you rework your strategy:

You could do what you want with sigFormula, but it will be slow, because
of its flexibility.

Instead, look at how the other demo scipts make use of indicators and
signals.

What you've described is 
- one indicator which is the Donchian Channel
- another indicator which is 75% of the Donchian Channel range
- a rule which enters limit orders at your second indicator, likely
adjusting the limits whenever the indicator changes

Also, take a look at how the demos and documentation use the quote()
function.

If you post a complete example, odds are someone here will help you sort
out the details; and wouldn't a Donchian Channel demo strategy be a nice
addition to the package? ;)

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From petrovaa at gmail.com  Thu Jun 30 12:11:52 2011
From: petrovaa at gmail.com (tonyp)
Date: Thu, 30 Jun 2011 03:11:52 -0700 (PDT)
Subject: [R-SIG-Finance] Rolling Correlation Problem
Message-ID: <1309428712418-3635256.post@n4.nabble.com>

Hello Masters of R,

I was wondering if somebody can help with a problem I am facing. I have a
zoo object consisting of 500 vectors representing constituents of a
benchmark. I want to calculate the rolling correlation on 22 window period.
The observations are daily return series. However, when I run  my code 

x22=rollapply(spx,width = 22, FUN = function(x) {y <- cor(x);
 round(mean(y[lower.tri(y)]),3); }, by.column = FALSE, align='right')

I get warning message such as the underneath one due to too many 0000s in
some constituents. 

Warning messages:
1: In cor(x) : the standard deviation is zero
2: In cor(x) : the standard deviation is zero
3: In cor(x) : the standard deviation is zero
4: In cor(x) : the standard deviation is zero
5: In cor(x) : the standard deviation is zero
6: In cor(x) : the standard deviation is zero
7: In cor(x) : the standard deviation is zero
8: In cor(x) : the standard deviation is zero


Do you know how to calculate the rolling correlations in the presence of too
many zeros?

Thanks.

AP

--
View this message in context: http://r.789695.n4.nabble.com/Rolling-Correlation-Problem-tp3635256p3635256.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From petrovaa at gmail.com  Thu Jun 30 12:29:06 2011
From: petrovaa at gmail.com (tonyp)
Date: Thu, 30 Jun 2011 03:29:06 -0700 (PDT)
Subject: [R-SIG-Finance] Help GARCH forecasting
In-Reply-To: <1308723742324-3616117.post@n4.nabble.com>
References: <1308723742324-3616117.post@n4.nabble.com>
Message-ID: <1309429746308-3635285.post@n4.nabble.com>

If I were you, I would think twice of using GARCH for prediction. Time Series
models are notorious for their unreliability into the financial quant space,
simply due to the stylized fact that even after correcting returns for
volatility clustering, the residual ts still exhibits heavy tails. Be
cautious!!! In addition, you apply the analysis on returns; preferrably log
returns not on prices! Good luck. There is planty of good sources outthere
of what you are looking for. 

--
View this message in context: http://r.789695.n4.nabble.com/Help-GARCH-forecasting-tp3616117p3635285.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From Scott.Hixon at invesco.com  Thu Jun 30 13:44:13 2011
From: Scott.Hixon at invesco.com (Hixon, Scott R.)
Date: Thu, 30 Jun 2011 11:44:13 +0000
Subject: [R-SIG-Finance] (no subject)
Message-ID: <893208BCB4D35A4586D63F9015EB46BF19DFF3@USHOUXMB12.corp.amvescap.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110630/3dcaa453/attachment.pl>

From brian at braverock.com  Thu Jun 30 13:44:08 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 30 Jun 2011 06:44:08 -0500
Subject: [R-SIG-Finance] Rolling Correlation Problem
In-Reply-To: <1309428712418-3635256.post@n4.nabble.com>
References: <1309428712418-3635256.post@n4.nabble.com>
Message-ID: <1309434248.18549.73.camel@brian-rcg>

On Thu, 2011-06-30 at 03:11 -0700, tonyp wrote:
> Hello Masters of R,
> 
> I was wondering if somebody can help with a problem I am facing. I have a
> zoo object consisting of 500 vectors representing constituents of a
> benchmark. I want to calculate the rolling correlation on 22 window period.
> The observations are daily return series. However, when I run  my code 
> 
> x22=rollapply(spx,width = 22, FUN = function(x) {y <- cor(x);
>  round(mean(y[lower.tri(y)]),3); }, by.column = FALSE, align='right')
> 
> I get warning message such as the underneath one due to too many 0000s in
> some constituents. 
> 
> Warning messages:
> 1: In cor(x) : the standard deviation is zero
<...>
> Do you know how to calculate the rolling correlations in the presence of too
> many zeros?

See:

require(TTR)
?runCor

Regards,

  - Brian


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From brian at braverock.com  Thu Jun 30 13:58:01 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 30 Jun 2011 06:58:01 -0500
Subject: [R-SIG-Finance] (no subject)
In-Reply-To: <893208BCB4D35A4586D63F9015EB46BF19DFF3@USHOUXMB12.corp.amvescap.net>
References: <893208BCB4D35A4586D63F9015EB46BF19DFF3@USHOUXMB12.corp.amvescap.net>
Message-ID: <1309435081.18549.77.camel@brian-rcg>

On Thu, 2011-06-30 at 11:44 +0000, Hixon, Scott R. wrote:
> Hello R community.
> 
> I am trying to construct a portfolio subject to a few risk contribution constraints and have created the following function...
> 
> fnc <- function (wtsmat)
> {
>       q <- c(tail(SAA.BondWts, 1), wtsmat)
>       a <- c(sqrt(t(q) %*% cov.mat %*% q))
>       b <- cov.mat %*% q
>       c <- q * b/a
>       d <- sd(c[colnames(Equity.Rtn), ])
>       e <- sd(c[colnames(Cmdty.Rtn), ])
>       f <- sd(c(sum(c[colnames(Bond.Rtn), ]), sum(c[colnames(Equity.Rtn), ]), sum(c[colnames(Cmdty.Rtn), ])))
>       g <- c(d, e, f)
>       return(g)
> }
> 
> Where:
> wtsmat <- c(0.1610060, 0.1254689, 0.1994601, 0.1804945, 0.1851957, 0.1483748, 0.2178142, 0.3390351, 0.2049340, 0.2382168)
> SAA.BondWts <- c(0.2160611, 0.1804805, 0.1950128, 0.1095015, 0.1982830, 0.0000000, 0.1006611)
> and "cov.mat" represents the covariance matrix of all of the assets (17 x 17). If it is necessary to include the matrix for a proper answer to my question I will be happy to attach it.
> 
> The function above calculates the risk contribution of each asset in the portfolio.  Ideally I would like to optimize the values of wtsmat given that d, e, and f in the function should all equal zero.
> I am however, having some trouble setting this up in R.  Has anyone solved a problem like this in the past?
> 
> Thanks for any help and advice.
> Scott

The function StdDev in package PerformanceAnalytics can calculate
contribution to portfolio standard deviation.

The R-Forge package PortfolioAnalytics can construct risk-budget
constrained portfolios, and allows you to vary the constraints and
objectives without limiting yourself to what's possible with a closed
form solver.

I know that a single set of box constraints on contribution to portfolio
standard deviation may be solved with a closed form solver, but I don't
remember the paper reference offhand to go look it up.  As you add more
constraints or other objectives to the portfolio, it is likely that you
will violate the conditions that allow for a closed form solution, and
require a global solution such as that provided by PortfolioAnalytics.

Regards,

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From matthias.kornexl at raiffeisenbank.at  Thu Jun 30 14:00:40 2011
From: matthias.kornexl at raiffeisenbank.at (matthias.kornexl at raiffeisenbank.at)
Date: Thu, 30 Jun 2011 14:00:40 +0200
Subject: [R-SIG-Finance]  Rolling Correlation Problem
In-Reply-To: <1309428712418-3635256.post@n4.nabble.com>
References: <1309428712418-3635256.post@n4.nabble.com>
Message-ID: <OF9A12675E.9D1A1A18-ONC12578BF.00412D2A-C12578BF.0041FB01@mdcs.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110630/9c9c8ffc/attachment.pl>

From nelson.ana at gmail.com  Thu Jun 30 17:36:21 2011
From: nelson.ana at gmail.com (Ana Nelson)
Date: Thu, 30 Jun 2011 16:36:21 +0100
Subject: [R-SIG-Finance] Trouble with RBloomberg on R 2.13.0
In-Reply-To: <1309395329515-3634441.post@n4.nabble.com>
References: <2138811547.602262.1308852626379.JavaMail.open-xchange@oxusltgw07.schlund.de>
	<1309395329515-3634441.post@n4.nabble.com>
Message-ID: <BANLkTikzvui0Wz-s14t48+Bhuj13F5yXVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20110630/46e4afc4/attachment.pl>

