From luke.gower at cba.com.au  Thu Oct  1 01:01:11 2009
From: luke.gower at cba.com.au (Gower, Luke)
Date: Thu, 1 Oct 2009 09:01:11 +1000
Subject: [R-SIG-Finance] what should I be reading?
In-Reply-To: <5aebc8960909300724t3356ff86l9c898073d7e48cff@mail.gmail.com>
References: <5aebc8960909300724t3356ff86l9c898073d7e48cff@mail.gmail.com>
Message-ID: <A3B7C29F9599CC4BBF25F9830FA0138D1C010E84BE@VAUNSW137.au.cbainet.com>

I was not quite sure what specific problems interest you - whether options pricing, stat arb - or whatever. So I'm going to suggest something general: Ruey Tsay's book, Analysis of Financial Time Series'. Apart from covering a wide spread of topics, this is written with an S-Plus user in mind, so the analogy with R is close. In fact, I think there might even be a CRAN R package that translates the book's examples into R.

Another one that is seriously worth a look is 'Introduction to Wavelets and Other Filtering Methods in Economics and Finance', by Whitcher et al. The book is available in one of the R packages on wavelets. Quite a few of the examples relate to FX.


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Aleks Clark
Sent: Thursday, 1 October 2009 12:25 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] what should I be reading?

Hey List,

I'm pretty new at this whole computational finance thing, and am
looking for some reading recommendations. I am currently working on
automated forex trading using SVMs, but looking over the Finance and
Econometrics tasks in CRAN, I realize I don't understand 70% of the
/summaries/ of what those packages do.

the question is:

What kind of reading would be suitable for someone starting out with
economic models? I realize there's not going to be much out there
specifically aimed at forex, but I'd think there'd be some R-focused
material dealing with modeling of other financial markets. I've got a
pretty good grasp of how SVMs behave and work, and a somewhat lesser
understanding of neural nets, but the caret package has a profusion of
other modelling techniques that beckon to me! And I don't know much
about any of them, or if any of them will actually suit my purposes,
so any reading recommendations would be appreciated :)

Thanks,

-- 
Aleks Clark

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.

************** IMPORTANT MESSAGE *****************************       
This e-mail message is intended only for the addressee(s) and contains information which may be
confidential. 
If you are not the intended recipient please advise the sender by return email, do not use or
disclose the contents, and delete the message and any attachments from your system. Unless
specifically indicated, this email does not constitute formal advice or commitment by the sender
or the Commonwealth Bank of Australia (ABN 48 123 123 124) or its subsidiaries. 
We can be contacted through our web site: commbank.com.au. 
If you no longer wish to receive commercial electronic messages from us, please reply to this
e-mail by typing Unsubscribe in the subject line. 


From elise at predictiveanalyticsworld.com  Thu Oct  1 08:23:40 2009
From: elise at predictiveanalyticsworld.com (EliseJ)
Date: Wed, 30 Sep 2009 23:23:40 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Announcing: Predictive Analytics
 World, Oct. 20-21 in Washington DC
Message-ID: <25693421.post@talk.nabble.com>


Hi everyone,

I wanted to make sure you know about the next Predictive Analytics World
conference, Oct. 20-21 in Washington DC (www.pawcon.com).  

-----------------------------

Predictive Analytics World is the business-focused event for predictive
analytics professionals, managers and commercial practitioners, covering
today's commercial deployment of predictive analytics, across industries and
across software vendors.  The conference delivers case studies, expertise
and resources to achieve two objectives:

1) Bigger wins: Strengthen the business impact delivered by predictive
analytics

2) Broader capabilities: Establish new opportunities with predictive
analytics


PAW's October 2009 program is packed with the top predictive analytics
experts, practitioners, authors and business thought leaders, including
keynote speakers Stephen Baker (author of The Numerati and Senior writer at
BusinessWeek), Usama Fayyad, Ph.D. (CEO, Open Insights and formerly Yahoo!'s
Chief Data Officer and Executive Vice President), and Program Chair Eric
Siegel, Ph.D. (President of Prediction Impact and former Columbia University
professor).


Case Studies: How the Leading Enterprises Do It

Predictive Analytics World focuses on concrete examples of deployed
predictive analytics. Hear from the horse's mouth precisely how Fortune 500
analytics competitors and other top practitioners deploy predictive
modeling, and what kind of business impact it delivers.

And the leading enterprises have responded, signing up to tell their
stories. PAW-09 will have 25 sessions across two tracks, so you can witness
how predictive analytics is applied at Aflac, Amway, Citizens Bank, The
Coca-Cola Company, Financial Times, Hewlett-Packard, Infinity Insurance,
IRS, Lifeline Screening, National Center for Dropout Prevention, The
National Rifle Association, The New York Times, Optus (Australian telecom),
PREMIER Bankcard, Reed Elsevier, Sprint-Nextel, Sunrise Communications
(Switzerland), Target, US Bank, U.S. Department of Defense, Walden
University, Zurich -- plus special examples from Anheuser-Busch, Disney,
HSBC, Pfizer, Social Security Administration, WestWind Foundation and
others.


Workshops

Three pre- and post-event workshops complement the core conference program:

"The Best and the Worst of Predictive Analytics: Predictive Modeling Methods
and Common Data Mining Mistakes"
Instructor: John F. Elder, Ph.D., CEO and Founder, Elder Research, Inc.
www.predictiveanalyticsworld.com/dc/2009/predictive_modeling_methods.php

"Hands-On Predictive Analytics"
Instructor: Dean Abbott, President, Abbott Analytics
www.predictiveanalyticsworld.com/dc/2009/handson_predictive_analytics.php

"Putting Predictive Analytics to Work"
Instructor: James Taylor, CEO, Decision Management Solutions
www.predictiveanalyticsworld.com/dc/2009/predictive_analytics_work.php


Cross-Industry Applications

Predictive Analytics World is the only conference of its kind, delivering
vendor-neutral sessions across verticals such as banking, financial
services, e-commerce, education, government, healthcare, high technology,
insurance, non-profits, publishing, retail and telecommunications.

And PAW covers the gamut of commercial applications of predictive analytics,
including response modeling, customer retention with churn modeling, product
recommendations, fraud detection, online marketing optimization,
behavior-based advertising, insurance pricing, sales forecasting, text
mining and credit scoring.

Why bring together such a wide range of endeavors? No matter how you use
predictive analytics, the story is the same: Predictively scoring customers
optimizes business performance. Predictive analytics initiatives across
industries leverage the same core predictive modeling technology, share
similar project overhead and data requirements, and face common process
challenges and analytical hurdles.


Rave Reviews

February's inaugural Predictive Analytics World was an acclaimed success,
with over 200 attendees from 12 countries witnessing case studies from over
20 named companies that represent 11 industries. Excitement and buzz ran
high as participants learned how to improve efficiency and optimize across
more than 10 business applications of predictive analytics.

"Predictive Analytics World was probably the best analytics conference I
have attended, from a knowledge point of view, in a long time...[and] turned
into my new must-go-to conference."

      Dennis R. Mortensen
      Director of Data Insights
      Yahoo!

Read more:  Articles and blog entries about February's PAW can be found at
www.predictiveanalyticsworld.com/pressroom.php


Vendors.

* Meet the vendors and learn about their solutions, software and services
* Discover the best predictive analytics vendors available to serve your
needs
* Learn what they do and see how they compare

Colleagues.

* Mingle, network and hang out with your best and brightest colleagues
* Exchange experiences over lunch, breaks and the conference reception,
connecting with those professionals who face the same challenges as you


For more information, see:
www.predictiveanalyticsworld.com

What is predictive analytics? See the Predictive Analytics Guide:
www.predictiveanalyticsworld.com/predictive_analytics.php

If you'd like our informative event updates, sign up at:
www.predictiveanalyticsworld.com/notifications.php

To sign up for the PAW group on LinkedIn, see:
www.linkedin.com/e/gis/1005097

For inquiries, e-mail us at registration at predictiveanalyticsworld.com or
call (866) 223-2579.


Let us know if you have any questions!

Thanks  --Elise Johnson, Predictive Analytics World

-- 
View this message in context: http://www.nabble.com/Announcing%3A-Predictive-Analytics-World%2C-Oct.-20-21-in-Washington-DC-tp25693421p25693421.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From elise at predictiveanalyticsworld.com  Thu Oct  1 08:54:13 2009
From: elise at predictiveanalyticsworld.com (Elise Johnson)
Date: Wed, 30 Sep 2009 23:54:13 -0700
Subject: [R-SIG-Finance] Can you post next Predictive Analytics World
	conference on forum?
Message-ID: <7896264a0909302354hf4098fdn21bf0c070e0f4931@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20090930/9fa96742/attachment.pl>

From nelson.ana at gmail.com  Thu Oct  1 12:06:00 2009
From: nelson.ana at gmail.com (Ana Nelson)
Date: Thu, 1 Oct 2009 11:06:00 +0100
Subject: [R-SIG-Finance] RBloomberg News and Upcoming Versions
Message-ID: <a7d6d2740910010306i480fd9cfw180b5a8d7e9cf881@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091001/784deb53/attachment.pl>

From jorge.nieves at moorecap.com  Thu Oct  1 18:47:40 2009
From: jorge.nieves at moorecap.com (Jorge Nieves)
Date: Thu, 1 Oct 2009 12:47:40 -0400
Subject: [R-SIG-Finance] Static Portfolio Optimization
In-Reply-To: <4AC10085.4000105@gmx.de>
Message-ID: <D595C0E05185614C90515F1E8A2D4CBF02B3CA25@NYC-XCH3.win.moorecap.com>

Hi,

I tested Thomas' code, but I get an error message in windows R 9.2
1(2009-06-26).

Error: class(data) == "timeSeries" is not TRUE
> 

I have already spoken with Thomas. He indicated that his code seems to
work ok in LINUX. However, Thomas gets the same error message I get in
windows.


I was wondering if anyone else has tested the code? Has anyone found a
work around the problem?  It just happens that I too have the need for
this functionality.

Any leads or recommendations will be highly appreciated.



Jorge Nieves


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Thomas
Etheber
Sent: Monday, September 28, 2009 02:29 PM
To: Brian G. Peterson
Cc: r-sig-finance at stat.math.ethz.ch; Jesse Velez
Subject: Re: [R-SIG-Finance] Static Portfolio Optimization

Brian G. Peterson wrote:
> Jesse Velez wrote:
>> Is there any function or example in R or Rmetrics of static portfolio

>> optimization, where I have a vector of expected returns for N assets 
>> and a expected covariance matrix of said N assets all at a fixed time

>> (say generated from a MFM risk and return model).
>>
>> fPortfolio, Portfolio, portfolio.optim appear to all require time 
>> series of returns to generate the expected return and historical 
>> covariance matrix for use in creating weights.
>>
>> Ideally, I hope to find an example that allows easily allows 
>> Long/Short weights to make the portfolio  market neutral (i.e. 
>> Summation of Weights =0).
>>   
> All the implementations of Markowitz style mean/variance optmization 
> use quadprog in R.
>
> Plenty of information on the list archives from before all these 
> packages existed about using quadprog for optimization.
>
> Regards,
>
>  - Brian
>

Hi there,

I also had the problem with fixed parameter inputs some time ago.
Implementing methods to perform this tasks would certainly be a nice
improvement of the library (as would be some help/error messages if the
covariance matrix is not positive semidefinite).  
Although Brian's comment is helpful as usual, using basic quadprog
sounds like reinventing the wheel, but might nevertheless be needed to
solve your second task of a market-neutral portfolio.

In order to use prespecified estimates as inputs I helped myself with
overwriting some of the methods. It's not a nice solution, but it worked
for me. You will find the methods attached below.
I didn't check the code again, but I think it should work. Please note,
some other methods of Rmetrics and fPortfolio might rely on the
timeseries objects and might not work properly.

Hth
Thomas

>>>
require(MBESS)
require(fPortfolio)
rm(list=ls())
spec <- portfolioSpec()
constraints <- NULL

portfolioData <- function (data, spec = portfolioSpec()) {  
    ans = NULL
    if(class(data) == "timeSeries") {
       data = sort(data)
       nAssets = dim(data)[2]
       statistics = portfolioStatistics(data, spec)
       tailRisk = spec at model$tailRisk
       ans <- new("fPFOLIODATA", data = list(series = data, nAssets =
nAssets),
           statistics = statistics, tailRisk = tailRisk)
    }
    if(class(data) == "list") {
      statistics = list(mu = data$mu, Sigma = data$Sigma )
      attr(statistics, "estimator") = spec at model$estimator
      ans <- new("fPFOLIODATA", data = list( nAssets = length(data$mu)
), statistics = statistics, tailRisk = list() )
    }
    ans
}


########################################################################
############

.efficientConstrainedMVPortfolio <- function (data, spec, constraints) {
    if (!inherits(data, "fPFOLIODATA"))
        data = portfolioData(data, spec)
    mu = getMu(data)
    Sigma = getSigma(data)
    nAssets = getNumberOfAssets(data)
    targetAlpha = getTargetAlpha(spec)
    solver = getSolver(spec)
    stopifnot(solver == "quadprog" | solver == "Rdonlp2")
    if (solver == "quadprog") {
        portfolio = solveRQuadprog(data, spec, constraints)
    }
    else if (solver == "Rdonlp2") {
        portfolio = solveRDonlp2(data, spec, constraints)
    }
    weights = portfolio$weights
    attr(weights, "status") <- portfolio$status
    names(weights) = names(mu)
    targetReturn = matrix(as.numeric(mu %*% weights), nrow = 1)
    colnames(targetReturn) <- getEstimator(spec)[1]
    covTargetRisk = sqrt(as.numeric(weights %*% Sigma %*% weights))
#   x = getSeries(data)@Data %*% weights
#   VaR = quantile(x, targetAlpha, type = 1)
#   CVaR = VaR - 0.5 * mean(((VaR - x) + abs(VaR - x)))/targetAlpha
#   targetRisk = matrix(c(covTargetRisk, CVaR, VaR), nrow = 1)
#   colnames(targetRisk) <- c("cov", paste(c("CVaR.", "VaR."),
#   targetAlpha * 100, "%", sep = ""))
    targetRisk = matrix(c(covTargetRisk), nrow = 1)
    ## is needed to use the plotting functions....
    targetRisk = matrix(c(covTargetRisk, covTargetRisk ), nrow = 1)
    colnames(targetRisk) <- c( "cov", "dummy" )
    new("fPORTFOLIO", call = match.call(), data = list(data = data),
        spec = list(spec = spec), constraints =
as.character(constraints),
        portfolio = list(weights = weights, targetReturn = targetReturn,
            targetRisk = targetRisk, targetAlpha = targetAlpha,
            status = portfolio$status), title = paste("Constrained MV
Portfolio - Solver:",
            solver), description = .description()) }

########################################################################
############

.minvarianceConstrainedMVPortfolio <- function (data, spec, constraints)
{
    if (!inherits(data, "fPFOLIODATA"))
        data = portfolioData(data, spec)
    mu = getMu(data)
    Sigma = getSigma(data)
    nAssets = getNumberOfAssets(data)
    targetAlpha = getTargetAlpha(spec)
    .minVariancePortfolioFun = function(x, data, spec, constraints) {
        spec at portfolio$targetReturn = x
        ans = .efficientConstrainedMVPortfolio(data = data, spec = spec,
            constraints = constraints)
        f = getTargetRisk(ans)[1]
        attr(f, "targetReturn") <- getTargetReturn(ans)
        attr(f, "targetRisk") <- getTargetRisk(ans)[1]
        attr(f, "weights") <- getWeights(ans)
        f
    }
    minVar = optimize(.minVariancePortfolioFun, interval = range(mu),
        data = data, spec = spec, constraints = constraints,
        tol = .Machine$double.eps^0.5)
    weights = attr(minVar$objective, "weights")
    names(weights) = names(mu)
    targetReturn = spec at portfolio$targetReturn =
as.numeric(attr(minVar$objective,
        "targetReturn"))
    targetReturn = matrix(targetReturn, nrow = 1)
    colnames(targetReturn) <- spec at model$estimator[1]
    covTargetRisk = as.numeric(attr(minVar$objective, "targetRisk"))
    # x = getSeries(data)@Data %*% weights
    # VaR = quantile(x, targetAlpha, type = 1)
    # CVaR = VaR - 0.5 * mean(((VaR - x) + abs(VaR - x)))/targetAlpha
    #targetRisk = matrix(c(covTargetRisk, CVaR, VaR), nrow = 1)
    #colnames(targetRisk) <- c("cov", paste(c("CVaR.", "VaR."),
    targetRisk = matrix(c(covTargetRisk), nrow = 1)
    ## is needed to use the plotting functions....
    targetRisk = matrix(c(covTargetRisk, covTargetRisk ), nrow = 1)
    colnames(targetRisk) <- c( "cov", "dummy" )
    new("fPORTFOLIO", call = match.call(), data = list(data = data),
        spec = list(spec = spec), constraints =
as.character(constraints),
        portfolio = list(weights = weights, targetReturn = targetReturn,
            targetRisk = targetRisk, targetAlpha = targetAlpha,
            status = 0), title = "Minimum Variance Portfolio",
        description = .description())
}

show.fPORTFOLIO <- function (object)
{
    cat("\nTitle:\n ")
    cat(getTitle(object), "\n")
    cat("\nCall:\n ")
    print.default(getCall(object))
    cat("\nPortfolio Weight(s):\n")
    weights = round(getWeights(object), digits = 4)
    if (length(weights) == 1) {
        cat(" ", weights, "\n")
    }
    else {
        print.table(weights)
    }
    cat("\nRiskBudget(s):\n")
    riskBudgets = round(getCovRiskBudgets(object), digits = 4)
    if (length(riskBudgets) == 1) {
        cat(" ", riskBudgets, "\n")
    }
    else {
        print.table(riskBudgets)
    }
    if (FALSE) {
        if (!is.na(getTailRiskBudgets(object))) {
            cat("\nRiskBudget(s):\n")
            riskBudgets = round(getTailRiskBudgets(object), digits = 4)
            if (length(riskBudgets) == 1) {
                cat(" ", riskBudgets, "\n")
            }
            else {
                print.table(riskBudgets)
            }
        }
    }
    targetReturn = object at portfolio$targetReturn
    targetRisk = object at portfolio$targetRisk
    spec = getSpec(object)
    cat("\nTarget Risk(s) and Return(s):\n")
    if (is.null(dim(targetReturn))) {
        targetReturn = matrix(targetReturn, nrow = 1)
        colnames(targetReturn) = getEstimator(spec)[1]
    }
    if (is.null(dim(targetRisk))) {
        targetRisk = matrix(targetRisk, nrow = length(targetRisk) )
        colnames(targetRisk) = getEstimator(spec)[2]
    }
    target = cbind(targetReturn, targetRisk)
    colnames(target) = c(colnames(targetReturn), colnames(targetRisk) )
    if (nrow(target) == 1) {
        print(target[1, ])
    }
    else {
        print(target)
    }
    cat("\nDescription:\n ")
    cat(getDescription(object), "\n")
    invisible(object)
}

setMethod("show", "fPORTFOLIO", show.fPORTFOLIO)

########################################################################
############

.portfolioConstrainedMVFrontier <- function (data, spec, constraints) {
    if (!inherits(data, "fPFOLIODATA"))
        data = portfolioData(data, spec)
    mu = getMu(data)
    Sigma = getSigma(data)
    nAssets = getNumberOfAssets(data)
    targetAlpha = getTargetAlpha(spec)
    nFrontierPoints = getNFrontierPoints(spec)
    targetReturn = targetRisk = targetWeights = error = NULL
    Spec = spec
    solver = spec at solver$solver
    Spec at portfolio$weights = rep(1/nAssets, nAssets)
    k = 0
    solverType = spec at solver$solver
    status = NULL
    for (nTargetReturn in seq(min(mu), max(mu), length =
nFrontierPoints)) {
        k = k + 1
        setTargetReturn(Spec) <- nTargetReturn
        nextPortfolio = .efficientConstrainedMVPortfolio(data = data,
            spec = Spec, constraints = constraints)
        Spec at portfolio$weights = nextPortfolio at portfolio$weights
        targetReturn = rbind(targetReturn,
nextPortfolio at portfolio$targetReturn)
        targetRisk = rbind(targetRisk,
nextPortfolio at portfolio$targetRisk)
        nextWeights = nextPortfolio at portfolio$weights
        names(nextWeights) = names(mu)
        status = c(status, nextPortfolio at portfolio$status)
        targetWeights = rbind(targetWeights, t(nextWeights))
    }
    Index = (1:length(status))[status == 0]
    weights = targetWeights
    colnames(weights) = names(mu)
    weights = weights[Index, ]
    DIM = dim(targetReturn)[2]
    targetReturn = targetReturn[Index, ]
    targetReturn = matrix(targetReturn, ncol = DIM)
    colnames(targetReturn) = getEstimator(spec)[1]
    targetRisk = targetRisk[Index, ]
    new("fPORTFOLIO", call = match.call(), data = list(data = data),
        spec = list(spec = spec), constraints =
as.character(constraints),
        portfolio = list(weights = weights, targetReturn = targetReturn,
            targetRisk = targetRisk, targetAlpha = targetAlpha,
            status = status), title = "Constrained MV Frontier",
        description = .description())
}

########################################################################
############

# You should be able to specify the data in this form:
mu <- c( 0.1, 0.08, 0.065)
sigma <- c( 0.18, 0.12, 0.09 )

correlationMatrix <- rbind( c( 1, 0.8, 0.9 ),
                                              c( 0.8, 1, 0.75),
                                              c( 0.9, 0.75, 1) )

covarianceMatrix <- cor2cov(correlationMatrix, sigma )


data = list( mu = mu, Sigma = covarianceMatrix )

# And then do the optimisation
frontier <- portfolioFrontier(data, spec = spec, constraints )

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From edd at debian.org  Thu Oct  1 19:29:50 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 1 Oct 2009 12:29:50 -0500
Subject: [R-SIG-Finance] Can you post next Predictive Analytics
	World	conference on forum?
In-Reply-To: <7896264a0909302354hf4098fdn21bf0c070e0f4931@mail.gmail.com>
References: <7896264a0909302354hf4098fdn21bf0c070e0f4931@mail.gmail.com>
Message-ID: <19140.59150.275151.235291@ron.nulle.part>


Elise.

On 30 September 2009 at 23:54, Elise Johnson wrote:
| Dear moderator,

You sent the query to the list and all its subscribers.  That may be due to
the fact that I ignore email to r-$list-owner as there are so many spam
bounces to make the -owner handle practically useless.

My 'real' email address is however listed on the info page for all the lists
I look after, including r-sig-finance.
 
| Was wondering if you could please post an announcement regarding the next
| Predictive Analytics World conference, taking place 10/20-10/21/09 in
| Washington DC.  Thank you for your consideration and let me know if you have
| questions; posting text  is below the bold "Event Posting Description"
| below.

I guess this is rather moot as you seem to have sent to the list _before_ you
sent this query to me:

   From: EliseJ <elise at predictiveanalyticsworld.com>
   To: r-sig-finance at stat.math.ethz.ch
   Subject: [R-SIG-Finance] [R-sig-finance] Announcing: Predictive Analytics World, Oct. 20-21 in Washington DC
   Date: Wed, 30 Sep 2009 23:23:40 -0700 (PDT)

23:23 is 22 minutes before this email from 23:54 I am replying to now.

We do have working policy here of "lots of signal, little noise" and I have
inform you that at least to my eyes, this adds only to the noise and not to
the signal so I'd prefer it if you did not repost the next time around.

Readers disagreeing with are kindly requested to make themselved heard,
preferably in an __off-list__ email to me; feel free to CC Elise.

Dirk, with his listmaster hat on


| 
| -- 
| Elise Johnson
| Marketing
| Predictive Analytics World
| 
| Join us for the Predictive Analytics World Conference
| October 20-21, 2009 in Washington, DC
| www.predictiveanalyticsworld.com
| ------------------------------
| 
| 
| *EVENT POSTING DESCRIPTION*
| 
| *Subject:*  Announcing: Predictive Analytics World, Oct. 20-21 in Washington
| DC
| 
| *Text:*
| 
| Predictive Analytics World is the business-focused event for predictive
| analytics professionals, managers and commercial practitioners, covering
| today's commercial deployment of predictive analytics, across industries and
| across software vendors.  The conference delivers case studies, expertise
| and resources to achieve two objectives:
| 
| 1) Bigger wins: Strengthen the business impact delivered by predictive
| analytics
| 
| 2) Broader capabilities: Establish new opportunities with predictive
| analytics
| 
| PAW's October 2009 program is packed with the top predictive analytics
| experts, practitioners, authors and business thought leaders, including
| keynote speakers Stephen Baker (author of The Numerati and Senior writer at
| BusinessWeek), Usama Fayyad, Ph.D. (CEO, Open Insights and formerly Yahoo!'s
| Chief Data Officer and Executive Vice President), and Program Chair Eric
| Siegel, Ph.D. (President of Prediction Impact and former Columbia University
| professor).
| 
| 
| *Case Studies: How the Leading Enterprises Do It*
| 
| Predictive Analytics World focuses on concrete examples of deployed
| predictive analytics. Hear from the horse's mouth precisely how Fortune 500
| analytics competitors and other top practitioners deploy predictive
| modeling, and what kind of business impact it delivers.
| 
| And the leading enterprises have responded, signing up to tell their
| stories. PAW-09 will have 25 sessions across two tracks, so you can witness
| how predictive analytics is applied at Aflac, Amway, Citizens Bank, The
| Coca-Cola Company, Financial Times, Hewlett-Packard, Infinity Insurance,
| IRS, Lifeline Screening, National Center for Dropout Prevention, The
| National Rifle Association, The New York Times, Optus (Australian telecom),
| PREMIER Bankcard, Reed Elsevier, Sprint-Nextel, Sunrise Communications
| (Switzerland), Target, US Bank, U.S. Department of Defense, Walden
| University, Zurich -- plus special examples from Anheuser-Busch, Disney,
| HSBC, Pfizer, Social Security Administration, WestWind Foundation and
| others.
| 
| 
| *Workshops*
| 
| Three pre- and post-event workshops complement the core conference program:
| 
| "The Best and the Worst of Predictive Analytics: Predictive Modeling Methods
| and Common Data Mining Mistakes"
| Instructor: John F. Elder, Ph.D., CEO and Founder, Elder Research, Inc.
| www.predictiveanalyticsworld.com/dc/2009/predictive_modeling_methods.php
| 
| "Hands-On Predictive Analytics"
| Instructor: Dean Abbott, President, Abbott Analytics
| www.predictiveanalyticsworld.com/dc/2009/handson_predictive_analytics.php
| 
| "Putting Predictive Analytics to Work"
| Instructor: James Taylor, CEO, Decision Management Solutions
| www.predictiveanalyticsworld.com/dc/2009/predictive_analytics_work.php
| 
| *
| Cross-Industry Applications*
| 
| Predictive Analytics World is the only conference of its kind, delivering
| vendor-neutral sessions across verticals such as banking, financial
| services, e-commerce, education, government, healthcare, high technology,
| insurance, non-profits, publishing, retail and telecommunications.
| 
| And PAW covers the gamut of commercial applications of predictive analytics,
| including response modeling, customer retention with churn modeling, product
| recommendations, fraud detection, online marketing optimization,
| behavior-based advertising, insurance pricing, sales forecasting, text
| mining and credit scoring.
| 
| Why bring together such a wide range of endeavors? No matter how you use
| predictive analytics, the story is the same: Predictively scoring customers
| optimizes business performance. Predictive analytics initiatives across
| industries leverage the same core predictive modeling technology, share
| similar project overhead and data requirements, and face common process
| challenges and analytical hurdles.
| 
| 
| *Rave Reviews*
| 
| February's inaugural Predictive Analytics World was an acclaimed success,
| with over 200 attendees from 12 countries witnessing case studies from over
| 20 named companies that represent 11 industries. Excitement and buzz ran
| high as participants learned how to improve efficiency and optimize across
| more than 10 business applications of predictive analytics.
| 
| "Predictive Analytics World was probably the best analytics conference I
| have attended, from a knowledge point of view, in a long time...[and] turned
| into my new must-go-to conference."
| 
| Dennis R. Mortensen
| Director of Data Insights
| Yahoo!
| 
| Read more:  Articles and blog entries about February's PAW can be found at
| www.predictiveanalyticsworld.com/pressroom.php
| 
| 
| *Vendors.*
| 
| * Meet the vendors and learn about their solutions, software and services
| * Discover the best predictive analytics vendors available to serve your
| needs
| * Learn what they do and see how they compare
| 
| *Colleagues.*
| 
| * Mingle, network and hang out with your best and brightest colleagues
| * Exchange experiences over lunch, breaks and the conference reception,
| connecting with those professionals who face the same challenges as you
| 
| 
| For more information, see:
| www.predictiveanalyticsworld.com
| 
| What is predictive analytics? See the Predictive Analytics Guide:
| www.predictiveanalyticsworld.com/predictive_analytics.php
| 
| If you'd like our informative event updates, sign up at:
| www.predictiveanalyticsworld.com/notifications.php
| 
| To sign up for the PAW group on LinkedIn, see:
| www.linkedin.com/e/gis/1005097
| 
| For inquiries, e-mail us at registration at predictiveanalyticsworld.com or
| call (866) 223-2579.
| 
| 	[[alternative HTML version deleted]]
| 
| _______________________________________________
| R-SIG-Finance at stat.math.ethz.ch mailing list
| https://stat.ethz.ch/mailman/listinfo/r-sig-finance
| -- Subscriber-posting only.
| -- If you want to post, subscribe first.

-- 
Three out of two people have difficulties with fractions.


From markleeds at verizon.net  Thu Oct  1 22:01:29 2009
From: markleeds at verizon.net (markleeds at verizon.net)
Date: Thu, 01 Oct 2009 15:01:29 -0500 (CDT)
Subject: [R-SIG-Finance] Static Portfolio Optimization
Message-ID: <1013266921.17975.1254427289806.JavaMail.root@vms229.mailsrvcs.net>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091001/d086a9ce/attachment.html>

From edd at debian.org  Thu Oct  1 22:25:08 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 1 Oct 2009 15:25:08 -0500
Subject: [R-SIG-Finance] Static Portfolio Optimization
In-Reply-To: <1013266921.17975.1254427289806.JavaMail.root@vms229.mailsrvcs.net>
References: <1013266921.17975.1254427289806.JavaMail.root@vms229.mailsrvcs.net>
Message-ID: <19141.4132.406691.539249@ron.nulle.part>


On 1 October 2009 at 15:01, markleeds at verizon.net wrote:
| I think I remember Adrian Trapletti implemented static portfolio
| optimization using quadprog in tseries. It's been a long time so I don't
| remember the details ( it may be restricted to long only but you can add
| variables to make<br />it handle long short ) but you may want to check
| tseries out. 

Correct -- the tseries package has done since time immportal. 

And some seven or eight years ago I sent Adrian a patch, styled after the
discussion in Huang and Litzenberger, that adds the ability to have long and
short positions.  

Which Adrian promptly added and which has been there ever since:

R> head(as.zoo(EuStockMarkets))
           DAX  SMI  CAC FTSE
1991(130) 1629 1678 1773 2444
1991(131) 1614 1688 1750 2460
1991(132) 1607 1679 1718 2448
1991(133) 1621 1684 1708 2470
1991(134) 1618 1687 1723 2485
1991(135) 1611 1672 1714 2467
R> X <- diff(log(as.zoo(EuStockMarkets)))
R> res <- portfolio.optim(X)                 ## Long only
R> res$pw
[1] 0.0000 0.3958 0.0000 0.6042
R> res <- portfolio.optim(X, shorts=TRUE)    ## Long/Short
R> res$pw
[1]  0.02550  0.38213 -0.06377  0.65614
R> 

This is arguably a better example than the one in help(portfolio.optim) so
maybe I should send Kurt a new patch :)

Dirk

-- 
Three out of two people have difficulties with fractions.


From jorge.nieves at moorecap.com  Thu Oct  1 22:33:59 2009
From: jorge.nieves at moorecap.com (Jorge Nieves)
Date: Thu, 1 Oct 2009 16:33:59 -0400
Subject: [R-SIG-Finance] Static Portfolio Optimization
In-Reply-To: <19141.4132.406691.539249@ron.nulle.part>
Message-ID: <D595C0E05185614C90515F1E8A2D4CBF02B3CA28@NYC-XCH3.win.moorecap.com>

Thanks for your responses. I found the function "portfolio.optim" and
the tseries series package and a document with explanations. The
function indeed allows for shorts. However, I still do not see how to
pass into the function the vector of expected values and the covariance
matrix. The function's input is the time series themselves. It seems
that the function internally computes both the expected values and the
covariance matrix, and then it performs the optimization.  Please
correct me if I am not reading right the function description and its
specifications.

Thanks, 


Jorge Nieves


-----Original Message-----
From: Dirk Eddelbuettel [mailto:edd at debian.org] 
Sent: Thursday, October 01, 2009 04:25 PM
To: markleeds at verizon.net
Cc: Jorge Nieves; r-sig-finance at stat.math.ethz.ch;
jessevel at andrew.cmu.edu
Subject: Re: [R-SIG-Finance] Static Portfolio Optimization


On 1 October 2009 at 15:01, markleeds at verizon.net wrote:
| I think I remember Adrian Trapletti implemented static portfolio 
| optimization using quadprog in tseries. It's been a long time so I 
| don't remember the details ( it may be restricted to long only but you

| can add variables to make<br />it handle long short ) but you may want

| to check tseries out.

Correct -- the tseries package has done since time immportal. 

And some seven or eight years ago I sent Adrian a patch, styled after
the discussion in Huang and Litzenberger, that adds the ability to have
long and short positions.  

Which Adrian promptly added and which has been there ever since:

R> head(as.zoo(EuStockMarkets))
           DAX  SMI  CAC FTSE
1991(130) 1629 1678 1773 2444
1991(131) 1614 1688 1750 2460
1991(132) 1607 1679 1718 2448
1991(133) 1621 1684 1708 2470
1991(134) 1618 1687 1723 2485
1991(135) 1611 1672 1714 2467
R> X <- diff(log(as.zoo(EuStockMarkets)))
R> res <- portfolio.optim(X)                 ## Long only
R> res$pw
[1] 0.0000 0.3958 0.0000 0.6042
R> res <- portfolio.optim(X, shorts=TRUE)    ## Long/Short
R> res$pw
[1]  0.02550  0.38213 -0.06377  0.65614
R> 

This is arguably a better example than the one in help(portfolio.optim)
so maybe I should send Kurt a new patch :)

Dirk

--
Three out of two people have difficulties with fractions.


From edd at debian.org  Thu Oct  1 22:40:45 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 1 Oct 2009 15:40:45 -0500
Subject: [R-SIG-Finance] Static Portfolio Optimization
In-Reply-To: <19141.4132.406691.539249@ron.nulle.part>
References: <1013266921.17975.1254427289806.JavaMail.root@vms229.mailsrvcs.net>
	<19141.4132.406691.539249@ron.nulle.part>
Message-ID: <19141.5069.38045.898276@ron.nulle.part>


On 1 October 2009 at 15:25, Dirk Eddelbuettel wrote:
| Correct -- the tseries package has done since time immportal. 

Oops: "... has done this since time immortal" is what I meant.  Someone
please write semantic and syntactic checker for Emacs....

Sorry, Dirk
 
| And some seven or eight years ago I sent Adrian a patch, styled after the
| discussion in Huang and Litzenberger, that adds the ability to have long and
| short positions.  
| 
| Which Adrian promptly added and which has been there ever since:
| 
| R> head(as.zoo(EuStockMarkets))
|            DAX  SMI  CAC FTSE
| 1991(130) 1629 1678 1773 2444
| 1991(131) 1614 1688 1750 2460
| 1991(132) 1607 1679 1718 2448
| 1991(133) 1621 1684 1708 2470
| 1991(134) 1618 1687 1723 2485
| 1991(135) 1611 1672 1714 2467
| R> X <- diff(log(as.zoo(EuStockMarkets)))
| R> res <- portfolio.optim(X)                 ## Long only
| R> res$pw
| [1] 0.0000 0.3958 0.0000 0.6042
| R> res <- portfolio.optim(X, shorts=TRUE)    ## Long/Short
| R> res$pw
| [1]  0.02550  0.38213 -0.06377  0.65614
| R> 
| 
| This is arguably a better example than the one in help(portfolio.optim) so
| maybe I should send Kurt a new patch :)
| 
| Dirk
| 
| -- 
| Three out of two people have difficulties with fractions.
| 
| _______________________________________________
| R-SIG-Finance at stat.math.ethz.ch mailing list
| https://stat.ethz.ch/mailman/listinfo/r-sig-finance
| -- Subscriber-posting only.
| -- If you want to post, subscribe first.

-- 
Three out of two people have difficulties with fractions.


From lara.shocron at gmail.com  Fri Oct  2 06:34:27 2009
From: lara.shocron at gmail.com (Lara Shocron)
Date: Fri, 2 Oct 2009 12:34:27 +0800
Subject: [R-SIG-Finance] fPortfolio - Portfolio Optimization
Message-ID: <5a8ae12f0910012134u34723883t9f5974d4bf62638f@mail.gmail.com>

Dear all,
I am trying to optimize a portfolio of 5 assets, *G1e1a*, *G1e1b*, *G35e8 *and
*G1b28. *I installed the fPortfolio package but so far I'm stuck since I
can't manage to put my .csv file in the right object class.

This is what my current file looks like (see below), it holds information on
*daily returns* of the respective assets.
I suppose I have to modify the .csv file itself (delete the date column for
instance) before I can turn it into a timeSeries object. How exactly should
I modify my .csv file?

How then can I transform the file in a timeSeries object that corresponds as
much as possible to the file I currently have?

Then, since the data I will have are already returns do I still need to use
the *return functions* from fPortfolio or can I jump straight to setting the
Spec parameters? Or is there some other step I should follow first (sort,
bind, align, merge...??) my assets? If so how should I do that?

Thank you very much for your help,
I have been looking at this for the last two days and am turning crazy!!

Lara

[image: ScreenShot037.jpg]

-- 
Lara Shocron
lara.shocron at gmail.com
+ 852 9765 4623
+ 33 6 12 89 97 08
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091002/f9c51427/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 315073 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091002/f9c51427/attachment.jpe>

From etheber at gmx.de  Fri Oct  2 06:40:54 2009
From: etheber at gmx.de (Thomas Etheber)
Date: Fri, 02 Oct 2009 06:40:54 +0200
Subject: [R-SIG-Finance] Static Portfolio Optimization
In-Reply-To: <D595C0E05185614C90515F1E8A2D4CBF02B3CA25@NYC-XCH3.win.moorecap.com>
References: <D595C0E05185614C90515F1E8A2D4CBF02B3CA25@NYC-XCH3.win.moorecap.com>
Message-ID: <4AC58456.5000506@gmx.de>

Jorge Nieves schrieb:
> Hi,
>
> I tested Thomas' code, but I get an error message in windows R 9.2
> 1(2009-06-26).
>
> Error: class(data) == "timeSeries" is not TRUE
>   
>
> I have already spoken with Thomas. He indicated that his code seems to
> work ok in LINUX. However, Thomas gets the same error message I get in
> windows.
>
>   
I don't think the OS is relevant for the code. As I told Jorge the code 
worked on an older R Version (R version 2.6.1).

Btw Dirk mentioned a nice alternative - the tseries package. I was 
wondering, if one can also prespecify further restrictions to 
portfolio.optim or is there just support for long-only portfolios?
As the results of the optimizer are often quite sensitive, one might 
want to specify some minimum or maximum portfolio weights to get more 
suitable results.

Hth,
Thomas

> I was wondering if anyone else has tested the code? Has anyone found a
> work around the problem?  It just happens that I too have the need for
> this functionality.
>
> Any leads or recommendations will be highly appreciated.
>
>
>
> Jorge Nieves
>
>
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Thomas
> Etheber
> Sent: Monday, September 28, 2009 02:29 PM
> To: Brian G. Peterson
> Cc: r-sig-finance at stat.math.ethz.ch; Jesse Velez
> Subject: Re: [R-SIG-Finance] Static Portfolio Optimization
>
> Brian G. Peterson wrote:
>   
>> Jesse Velez wrote:
>>     
>>> Is there any function or example in R or Rmetrics of static portfolio
>>>       
>
>   
>>> optimization, where I have a vector of expected returns for N assets 
>>> and a expected covariance matrix of said N assets all at a fixed time
>>>       
>
>   
>>> (say generated from a MFM risk and return model).
>>>
>>> fPortfolio, Portfolio, portfolio.optim appear to all require time 
>>> series of returns to generate the expected return and historical 
>>> covariance matrix for use in creating weights.
>>>
>>> Ideally, I hope to find an example that allows easily allows 
>>> Long/Short weights to make the portfolio  market neutral (i.e. 
>>> Summation of Weights =0).
>>>   
>>>       
>> All the implementations of Markowitz style mean/variance optmization 
>> use quadprog in R.
>>
>> Plenty of information on the list archives from before all these 
>> packages existed about using quadprog for optimization.
>>
>> Regards,
>>
>>  - Brian
>>
>>     
>
> Hi there,
>
> I also had the problem with fixed parameter inputs some time ago.
> Implementing methods to perform this tasks would certainly be a nice
> improvement of the library (as would be some help/error messages if the
> covariance matrix is not positive semidefinite).  
> Although Brian's comment is helpful as usual, using basic quadprog
> sounds like reinventing the wheel, but might nevertheless be needed to
> solve your second task of a market-neutral portfolio.
>
> In order to use prespecified estimates as inputs I helped myself with
> overwriting some of the methods. It's not a nice solution, but it worked
> for me. You will find the methods attached below.
> I didn't check the code again, but I think it should work. Please note,
> some other methods of Rmetrics and fPortfolio might rely on the
> timeseries objects and might not work properly.
>
> Hth
> Thomas
>
>   
> require(MBESS)
> require(fPortfolio)
> rm(list=ls())
> spec <- portfolioSpec()
> constraints <- NULL
>
> portfolioData <- function (data, spec = portfolioSpec()) {  
>     ans = NULL
>     if(class(data) == "timeSeries") {
>        data = sort(data)
>        nAssets = dim(data)[2]
>        statistics = portfolioStatistics(data, spec)
>        tailRisk = spec at model$tailRisk
>        ans <- new("fPFOLIODATA", data = list(series = data, nAssets =
> nAssets),
>            statistics = statistics, tailRisk = tailRisk)
>     }
>     if(class(data) == "list") {
>       statistics = list(mu = data$mu, Sigma = data$Sigma )
>       attr(statistics, "estimator") = spec at model$estimator
>       ans <- new("fPFOLIODATA", data = list( nAssets = length(data$mu)
> ), statistics = statistics, tailRisk = list() )
>     }
>     ans
> }
>
>
> ########################################################################
> ############
>
> .efficientConstrainedMVPortfolio <- function (data, spec, constraints) {
>     if (!inherits(data, "fPFOLIODATA"))
>         data = portfolioData(data, spec)
>     mu = getMu(data)
>     Sigma = getSigma(data)
>     nAssets = getNumberOfAssets(data)
>     targetAlpha = getTargetAlpha(spec)
>     solver = getSolver(spec)
>     stopifnot(solver == "quadprog" | solver == "Rdonlp2")
>     if (solver == "quadprog") {
>         portfolio = solveRQuadprog(data, spec, constraints)
>     }
>     else if (solver == "Rdonlp2") {
>         portfolio = solveRDonlp2(data, spec, constraints)
>     }
>     weights = portfolio$weights
>     attr(weights, "status") <- portfolio$status
>     names(weights) = names(mu)
>     targetReturn = matrix(as.numeric(mu %*% weights), nrow = 1)
>     colnames(targetReturn) <- getEstimator(spec)[1]
>     covTargetRisk = sqrt(as.numeric(weights %*% Sigma %*% weights))
> #   x = getSeries(data)@Data %*% weights
> #   VaR = quantile(x, targetAlpha, type = 1)
> #   CVaR = VaR - 0.5 * mean(((VaR - x) + abs(VaR - x)))/targetAlpha
> #   targetRisk = matrix(c(covTargetRisk, CVaR, VaR), nrow = 1)
> #   colnames(targetRisk) <- c("cov", paste(c("CVaR.", "VaR."),
> #   targetAlpha * 100, "%", sep = ""))
>     targetRisk = matrix(c(covTargetRisk), nrow = 1)
>     ## is needed to use the plotting functions....
>     targetRisk = matrix(c(covTargetRisk, covTargetRisk ), nrow = 1)
>     colnames(targetRisk) <- c( "cov", "dummy" )
>     new("fPORTFOLIO", call = match.call(), data = list(data = data),
>         spec = list(spec = spec), constraints =
> as.character(constraints),
>         portfolio = list(weights = weights, targetReturn = targetReturn,
>             targetRisk = targetRisk, targetAlpha = targetAlpha,
>             status = portfolio$status), title = paste("Constrained MV
> Portfolio - Solver:",
>             solver), description = .description()) }
>
> ########################################################################
> ############
>
> .minvarianceConstrainedMVPortfolio <- function (data, spec, constraints)
> {
>     if (!inherits(data, "fPFOLIODATA"))
>         data = portfolioData(data, spec)
>     mu = getMu(data)
>     Sigma = getSigma(data)
>     nAssets = getNumberOfAssets(data)
>     targetAlpha = getTargetAlpha(spec)
>     .minVariancePortfolioFun = function(x, data, spec, constraints) {
>         spec at portfolio$targetReturn = x
>         ans = .efficientConstrainedMVPortfolio(data = data, spec = spec,
>             constraints = constraints)
>         f = getTargetRisk(ans)[1]
>         attr(f, "targetReturn") <- getTargetReturn(ans)
>         attr(f, "targetRisk") <- getTargetRisk(ans)[1]
>         attr(f, "weights") <- getWeights(ans)
>         f
>     }
>     minVar = optimize(.minVariancePortfolioFun, interval = range(mu),
>         data = data, spec = spec, constraints = constraints,
>         tol = .Machine$double.eps^0.5)
>     weights = attr(minVar$objective, "weights")
>     names(weights) = names(mu)
>     targetReturn = spec at portfolio$targetReturn =
> as.numeric(attr(minVar$objective,
>         "targetReturn"))
>     targetReturn = matrix(targetReturn, nrow = 1)
>     colnames(targetReturn) <- spec at model$estimator[1]
>     covTargetRisk = as.numeric(attr(minVar$objective, "targetRisk"))
>     # x = getSeries(data)@Data %*% weights
>     # VaR = quantile(x, targetAlpha, type = 1)
>     # CVaR = VaR - 0.5 * mean(((VaR - x) + abs(VaR - x)))/targetAlpha
>     #targetRisk = matrix(c(covTargetRisk, CVaR, VaR), nrow = 1)
>     #colnames(targetRisk) <- c("cov", paste(c("CVaR.", "VaR."),
>     targetRisk = matrix(c(covTargetRisk), nrow = 1)
>     ## is needed to use the plotting functions....
>     targetRisk = matrix(c(covTargetRisk, covTargetRisk ), nrow = 1)
>     colnames(targetRisk) <- c( "cov", "dummy" )
>     new("fPORTFOLIO", call = match.call(), data = list(data = data),
>         spec = list(spec = spec), constraints =
> as.character(constraints),
>         portfolio = list(weights = weights, targetReturn = targetReturn,
>             targetRisk = targetRisk, targetAlpha = targetAlpha,
>             status = 0), title = "Minimum Variance Portfolio",
>         description = .description())
> }
>
> show.fPORTFOLIO <- function (object)
> {
>     cat("\nTitle:\n ")
>     cat(getTitle(object), "\n")
>     cat("\nCall:\n ")
>     print.default(getCall(object))
>     cat("\nPortfolio Weight(s):\n")
>     weights = round(getWeights(object), digits = 4)
>     if (length(weights) == 1) {
>         cat(" ", weights, "\n")
>     }
>     else {
>         print.table(weights)
>     }
>     cat("\nRiskBudget(s):\n")
>     riskBudgets = round(getCovRiskBudgets(object), digits = 4)
>     if (length(riskBudgets) == 1) {
>         cat(" ", riskBudgets, "\n")
>     }
>     else {
>         print.table(riskBudgets)
>     }
>     if (FALSE) {
>         if (!is.na(getTailRiskBudgets(object))) {
>             cat("\nRiskBudget(s):\n")
>             riskBudgets = round(getTailRiskBudgets(object), digits = 4)
>             if (length(riskBudgets) == 1) {
>                 cat(" ", riskBudgets, "\n")
>             }
>             else {
>                 print.table(riskBudgets)
>             }
>         }
>     }
>     targetReturn = object at portfolio$targetReturn
>     targetRisk = object at portfolio$targetRisk
>     spec = getSpec(object)
>     cat("\nTarget Risk(s) and Return(s):\n")
>     if (is.null(dim(targetReturn))) {
>         targetReturn = matrix(targetReturn, nrow = 1)
>         colnames(targetReturn) = getEstimator(spec)[1]
>     }
>     if (is.null(dim(targetRisk))) {
>         targetRisk = matrix(targetRisk, nrow = length(targetRisk) )
>         colnames(targetRisk) = getEstimator(spec)[2]
>     }
>     target = cbind(targetReturn, targetRisk)
>     colnames(target) = c(colnames(targetReturn), colnames(targetRisk) )
>     if (nrow(target) == 1) {
>         print(target[1, ])
>     }
>     else {
>         print(target)
>     }
>     cat("\nDescription:\n ")
>     cat(getDescription(object), "\n")
>     invisible(object)
> }
>
> setMethod("show", "fPORTFOLIO", show.fPORTFOLIO)
>
> ########################################################################
> ############
>
> .portfolioConstrainedMVFrontier <- function (data, spec, constraints) {
>     if (!inherits(data, "fPFOLIODATA"))
>         data = portfolioData(data, spec)
>     mu = getMu(data)
>     Sigma = getSigma(data)
>     nAssets = getNumberOfAssets(data)
>     targetAlpha = getTargetAlpha(spec)
>     nFrontierPoints = getNFrontierPoints(spec)
>     targetReturn = targetRisk = targetWeights = error = NULL
>     Spec = spec
>     solver = spec at solver$solver
>     Spec at portfolio$weights = rep(1/nAssets, nAssets)
>     k = 0
>     solverType = spec at solver$solver
>     status = NULL
>     for (nTargetReturn in seq(min(mu), max(mu), length =
> nFrontierPoints)) {
>         k = k + 1
>         setTargetReturn(Spec) <- nTargetReturn
>         nextPortfolio = .efficientConstrainedMVPortfolio(data = data,
>             spec = Spec, constraints = constraints)
>         Spec at portfolio$weights = nextPortfolio at portfolio$weights
>         targetReturn = rbind(targetReturn,
> nextPortfolio at portfolio$targetReturn)
>         targetRisk = rbind(targetRisk,
> nextPortfolio at portfolio$targetRisk)
>         nextWeights = nextPortfolio at portfolio$weights
>         names(nextWeights) = names(mu)
>         status = c(status, nextPortfolio at portfolio$status)
>         targetWeights = rbind(targetWeights, t(nextWeights))
>     }
>     Index = (1:length(status))[status == 0]
>     weights = targetWeights
>     colnames(weights) = names(mu)
>     weights = weights[Index, ]
>     DIM = dim(targetReturn)[2]
>     targetReturn = targetReturn[Index, ]
>     targetReturn = matrix(targetReturn, ncol = DIM)
>     colnames(targetReturn) = getEstimator(spec)[1]
>     targetRisk = targetRisk[Index, ]
>     new("fPORTFOLIO", call = match.call(), data = list(data = data),
>         spec = list(spec = spec), constraints =
> as.character(constraints),
>         portfolio = list(weights = weights, targetReturn = targetReturn,
>             targetRisk = targetRisk, targetAlpha = targetAlpha,
>             status = status), title = "Constrained MV Frontier",
>         description = .description())
> }
>
> ########################################################################
> ############
>
> # You should be able to specify the data in this form:
> mu <- c( 0.1, 0.08, 0.065)
> sigma <- c( 0.18, 0.12, 0.09 )
>
> correlationMatrix <- rbind( c( 1, 0.8, 0.9 ),
>                                               c( 0.8, 1, 0.75),
>                                               c( 0.9, 0.75, 1) )
>
> covarianceMatrix <- cor2cov(correlationMatrix, sigma )
>
>
> data = list( mu = mu, Sigma = covarianceMatrix )
>
> # And then do the optimisation
> frontier <- portfolioFrontier(data, spec = spec, constraints )
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
>


From lara.shocron at gmail.com  Fri Oct  2 10:53:32 2009
From: lara.shocron at gmail.com (Lara Shocron)
Date: Fri, 2 Oct 2009 16:53:32 +0800
Subject: [R-SIG-Finance] Portfolio Optimization
Message-ID: <5a8ae12f0910020153s23d677d6q99d52e4527940722@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091002/3e9d933d/attachment.pl>

From Reena.Bansal at moorecap.com  Fri Oct  2 17:19:19 2009
From: Reena.Bansal at moorecap.com (Reena Bansal)
Date: Fri, 2 Oct 2009 11:19:19 -0400
Subject: [R-SIG-Finance] Engle Granger test critical values
Message-ID: <4AAD56F399C8564C9EB6817C17618CDD0251EE59@NYC-XCH3.win.moorecap.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091002/742a2939/attachment.pl>

From ezivot at u.washington.edu  Fri Oct  2 17:44:29 2009
From: ezivot at u.washington.edu (Eric Zivot)
Date: Fri, 2 Oct 2009 08:44:29 -0700
Subject: [R-SIG-Finance] Static Portfolio Optimization
In-Reply-To: <4AC58456.5000506@gmx.de>
References: <D595C0E05185614C90515F1E8A2D4CBF02B3CA25@NYC-XCH3.win.moorecap.com>
	<4AC58456.5000506@gmx.de>
Message-ID: <005601ca4377$3a618800$af249800$@washington.edu>

I would like to point out a very nice presentation by Guy Yollen at the R in
Finance conference that describes portfolio optimization using the
portfolio.optim function and modifications thereof

http://rinfinance.quantmod.com/presentations/yollin_slides.pdf


Eric Zivot
Professor and Gary Waterman Distinguished Scholar
Department of Economics
Adjunct Professor of Finance, Foster School of Business
Adjunct Professor of Statistics
Box 353330
University of Washington
Seattle, WA 98195-3330
206-543-6715
http://faculty.washington.edu/ezivot



-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Thomas Etheber
Sent: Thursday, October 01, 2009 9:41 PM
To: Jorge Nieves
Cc: r-sig-finance at stat.math.ethz.ch; Jesse Velez
Subject: Re: [R-SIG-Finance] Static Portfolio Optimization

Jorge Nieves schrieb:
> Hi,
>
> I tested Thomas' code, but I get an error message in windows R 9.2
> 1(2009-06-26).
>
> Error: class(data) == "timeSeries" is not TRUE
>   
>
> I have already spoken with Thomas. He indicated that his code seems to
> work ok in LINUX. However, Thomas gets the same error message I get in
> windows.
>
>   
I don't think the OS is relevant for the code. As I told Jorge the code 
worked on an older R Version (R version 2.6.1).

Btw Dirk mentioned a nice alternative - the tseries package. I was 
wondering, if one can also prespecify further restrictions to 
portfolio.optim or is there just support for long-only portfolios?
As the results of the optimizer are often quite sensitive, one might 
want to specify some minimum or maximum portfolio weights to get more 
suitable results.

Hth,
Thomas

> I was wondering if anyone else has tested the code? Has anyone found a
> work around the problem?  It just happens that I too have the need for
> this functionality.
>
> Any leads or recommendations will be highly appreciated.
>
>
>
> Jorge Nieves
>
>
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Thomas
> Etheber
> Sent: Monday, September 28, 2009 02:29 PM
> To: Brian G. Peterson
> Cc: r-sig-finance at stat.math.ethz.ch; Jesse Velez
> Subject: Re: [R-SIG-Finance] Static Portfolio Optimization
>
> Brian G. Peterson wrote:
>   
>> Jesse Velez wrote:
>>     
>>> Is there any function or example in R or Rmetrics of static portfolio
>>>       
>
>   
>>> optimization, where I have a vector of expected returns for N assets 
>>> and a expected covariance matrix of said N assets all at a fixed time
>>>       
>
>   
>>> (say generated from a MFM risk and return model).
>>>
>>> fPortfolio, Portfolio, portfolio.optim appear to all require time 
>>> series of returns to generate the expected return and historical 
>>> covariance matrix for use in creating weights.
>>>
>>> Ideally, I hope to find an example that allows easily allows 
>>> Long/Short weights to make the portfolio  market neutral (i.e. 
>>> Summation of Weights =0).
>>>   
>>>       
>> All the implementations of Markowitz style mean/variance optmization 
>> use quadprog in R.
>>
>> Plenty of information on the list archives from before all these 
>> packages existed about using quadprog for optimization.
>>
>> Regards,
>>
>>  - Brian
>>
>>     
>
> Hi there,
>
> I also had the problem with fixed parameter inputs some time ago.
> Implementing methods to perform this tasks would certainly be a nice
> improvement of the library (as would be some help/error messages if the
> covariance matrix is not positive semidefinite).  
> Although Brian's comment is helpful as usual, using basic quadprog
> sounds like reinventing the wheel, but might nevertheless be needed to
> solve your second task of a market-neutral portfolio.
>
> In order to use prespecified estimates as inputs I helped myself with
> overwriting some of the methods. It's not a nice solution, but it worked
> for me. You will find the methods attached below.
> I didn't check the code again, but I think it should work. Please note,
> some other methods of Rmetrics and fPortfolio might rely on the
> timeseries objects and might not work properly.
>
> Hth
> Thomas
>
>   
> require(MBESS)
> require(fPortfolio)
> rm(list=ls())
> spec <- portfolioSpec()
> constraints <- NULL
>
> portfolioData <- function (data, spec = portfolioSpec()) {  
>     ans = NULL
>     if(class(data) == "timeSeries") {
>        data = sort(data)
>        nAssets = dim(data)[2]
>        statistics = portfolioStatistics(data, spec)
>        tailRisk = spec at model$tailRisk
>        ans <- new("fPFOLIODATA", data = list(series = data, nAssets =
> nAssets),
>            statistics = statistics, tailRisk = tailRisk)
>     }
>     if(class(data) == "list") {
>       statistics = list(mu = data$mu, Sigma = data$Sigma )
>       attr(statistics, "estimator") = spec at model$estimator
>       ans <- new("fPFOLIODATA", data = list( nAssets = length(data$mu)
> ), statistics = statistics, tailRisk = list() )
>     }
>     ans
> }
>
>
> ########################################################################
> ############
>
> .efficientConstrainedMVPortfolio <- function (data, spec, constraints) {
>     if (!inherits(data, "fPFOLIODATA"))
>         data = portfolioData(data, spec)
>     mu = getMu(data)
>     Sigma = getSigma(data)
>     nAssets = getNumberOfAssets(data)
>     targetAlpha = getTargetAlpha(spec)
>     solver = getSolver(spec)
>     stopifnot(solver == "quadprog" | solver == "Rdonlp2")
>     if (solver == "quadprog") {
>         portfolio = solveRQuadprog(data, spec, constraints)
>     }
>     else if (solver == "Rdonlp2") {
>         portfolio = solveRDonlp2(data, spec, constraints)
>     }
>     weights = portfolio$weights
>     attr(weights, "status") <- portfolio$status
>     names(weights) = names(mu)
>     targetReturn = matrix(as.numeric(mu %*% weights), nrow = 1)
>     colnames(targetReturn) <- getEstimator(spec)[1]
>     covTargetRisk = sqrt(as.numeric(weights %*% Sigma %*% weights))
> #   x = getSeries(data)@Data %*% weights
> #   VaR = quantile(x, targetAlpha, type = 1)
> #   CVaR = VaR - 0.5 * mean(((VaR - x) + abs(VaR - x)))/targetAlpha
> #   targetRisk = matrix(c(covTargetRisk, CVaR, VaR), nrow = 1)
> #   colnames(targetRisk) <- c("cov", paste(c("CVaR.", "VaR."),
> #   targetAlpha * 100, "%", sep = ""))
>     targetRisk = matrix(c(covTargetRisk), nrow = 1)
>     ## is needed to use the plotting functions....
>     targetRisk = matrix(c(covTargetRisk, covTargetRisk ), nrow = 1)
>     colnames(targetRisk) <- c( "cov", "dummy" )
>     new("fPORTFOLIO", call = match.call(), data = list(data = data),
>         spec = list(spec = spec), constraints =
> as.character(constraints),
>         portfolio = list(weights = weights, targetReturn = targetReturn,
>             targetRisk = targetRisk, targetAlpha = targetAlpha,
>             status = portfolio$status), title = paste("Constrained MV
> Portfolio - Solver:",
>             solver), description = .description()) }
>
> ########################################################################
> ############
>
> .minvarianceConstrainedMVPortfolio <- function (data, spec, constraints)
> {
>     if (!inherits(data, "fPFOLIODATA"))
>         data = portfolioData(data, spec)
>     mu = getMu(data)
>     Sigma = getSigma(data)
>     nAssets = getNumberOfAssets(data)
>     targetAlpha = getTargetAlpha(spec)
>     .minVariancePortfolioFun = function(x, data, spec, constraints) {
>         spec at portfolio$targetReturn = x
>         ans = .efficientConstrainedMVPortfolio(data = data, spec = spec,
>             constraints = constraints)
>         f = getTargetRisk(ans)[1]
>         attr(f, "targetReturn") <- getTargetReturn(ans)
>         attr(f, "targetRisk") <- getTargetRisk(ans)[1]
>         attr(f, "weights") <- getWeights(ans)
>         f
>     }
>     minVar = optimize(.minVariancePortfolioFun, interval = range(mu),
>         data = data, spec = spec, constraints = constraints,
>         tol = .Machine$double.eps^0.5)
>     weights = attr(minVar$objective, "weights")
>     names(weights) = names(mu)
>     targetReturn = spec at portfolio$targetReturn =
> as.numeric(attr(minVar$objective,
>         "targetReturn"))
>     targetReturn = matrix(targetReturn, nrow = 1)
>     colnames(targetReturn) <- spec at model$estimator[1]
>     covTargetRisk = as.numeric(attr(minVar$objective, "targetRisk"))
>     # x = getSeries(data)@Data %*% weights
>     # VaR = quantile(x, targetAlpha, type = 1)
>     # CVaR = VaR - 0.5 * mean(((VaR - x) + abs(VaR - x)))/targetAlpha
>     #targetRisk = matrix(c(covTargetRisk, CVaR, VaR), nrow = 1)
>     #colnames(targetRisk) <- c("cov", paste(c("CVaR.", "VaR."),
>     targetRisk = matrix(c(covTargetRisk), nrow = 1)
>     ## is needed to use the plotting functions....
>     targetRisk = matrix(c(covTargetRisk, covTargetRisk ), nrow = 1)
>     colnames(targetRisk) <- c( "cov", "dummy" )
>     new("fPORTFOLIO", call = match.call(), data = list(data = data),
>         spec = list(spec = spec), constraints =
> as.character(constraints),
>         portfolio = list(weights = weights, targetReturn = targetReturn,
>             targetRisk = targetRisk, targetAlpha = targetAlpha,
>             status = 0), title = "Minimum Variance Portfolio",
>         description = .description())
> }
>
> show.fPORTFOLIO <- function (object)
> {
>     cat("\nTitle:\n ")
>     cat(getTitle(object), "\n")
>     cat("\nCall:\n ")
>     print.default(getCall(object))
>     cat("\nPortfolio Weight(s):\n")
>     weights = round(getWeights(object), digits = 4)
>     if (length(weights) == 1) {
>         cat(" ", weights, "\n")
>     }
>     else {
>         print.table(weights)
>     }
>     cat("\nRiskBudget(s):\n")
>     riskBudgets = round(getCovRiskBudgets(object), digits = 4)
>     if (length(riskBudgets) == 1) {
>         cat(" ", riskBudgets, "\n")
>     }
>     else {
>         print.table(riskBudgets)
>     }
>     if (FALSE) {
>         if (!is.na(getTailRiskBudgets(object))) {
>             cat("\nRiskBudget(s):\n")
>             riskBudgets = round(getTailRiskBudgets(object), digits = 4)
>             if (length(riskBudgets) == 1) {
>                 cat(" ", riskBudgets, "\n")
>             }
>             else {
>                 print.table(riskBudgets)
>             }
>         }
>     }
>     targetReturn = object at portfolio$targetReturn
>     targetRisk = object at portfolio$targetRisk
>     spec = getSpec(object)
>     cat("\nTarget Risk(s) and Return(s):\n")
>     if (is.null(dim(targetReturn))) {
>         targetReturn = matrix(targetReturn, nrow = 1)
>         colnames(targetReturn) = getEstimator(spec)[1]
>     }
>     if (is.null(dim(targetRisk))) {
>         targetRisk = matrix(targetRisk, nrow = length(targetRisk) )
>         colnames(targetRisk) = getEstimator(spec)[2]
>     }
>     target = cbind(targetReturn, targetRisk)
>     colnames(target) = c(colnames(targetReturn), colnames(targetRisk) )
>     if (nrow(target) == 1) {
>         print(target[1, ])
>     }
>     else {
>         print(target)
>     }
>     cat("\nDescription:\n ")
>     cat(getDescription(object), "\n")
>     invisible(object)
> }
>
> setMethod("show", "fPORTFOLIO", show.fPORTFOLIO)
>
> ########################################################################
> ############
>
> .portfolioConstrainedMVFrontier <- function (data, spec, constraints) {
>     if (!inherits(data, "fPFOLIODATA"))
>         data = portfolioData(data, spec)
>     mu = getMu(data)
>     Sigma = getSigma(data)
>     nAssets = getNumberOfAssets(data)
>     targetAlpha = getTargetAlpha(spec)
>     nFrontierPoints = getNFrontierPoints(spec)
>     targetReturn = targetRisk = targetWeights = error = NULL
>     Spec = spec
>     solver = spec at solver$solver
>     Spec at portfolio$weights = rep(1/nAssets, nAssets)
>     k = 0
>     solverType = spec at solver$solver
>     status = NULL
>     for (nTargetReturn in seq(min(mu), max(mu), length =
> nFrontierPoints)) {
>         k = k + 1
>         setTargetReturn(Spec) <- nTargetReturn
>         nextPortfolio = .efficientConstrainedMVPortfolio(data = data,
>             spec = Spec, constraints = constraints)
>         Spec at portfolio$weights = nextPortfolio at portfolio$weights
>         targetReturn = rbind(targetReturn,
> nextPortfolio at portfolio$targetReturn)
>         targetRisk = rbind(targetRisk,
> nextPortfolio at portfolio$targetRisk)
>         nextWeights = nextPortfolio at portfolio$weights
>         names(nextWeights) = names(mu)
>         status = c(status, nextPortfolio at portfolio$status)
>         targetWeights = rbind(targetWeights, t(nextWeights))
>     }
>     Index = (1:length(status))[status == 0]
>     weights = targetWeights
>     colnames(weights) = names(mu)
>     weights = weights[Index, ]
>     DIM = dim(targetReturn)[2]
>     targetReturn = targetReturn[Index, ]
>     targetReturn = matrix(targetReturn, ncol = DIM)
>     colnames(targetReturn) = getEstimator(spec)[1]
>     targetRisk = targetRisk[Index, ]
>     new("fPORTFOLIO", call = match.call(), data = list(data = data),
>         spec = list(spec = spec), constraints =
> as.character(constraints),
>         portfolio = list(weights = weights, targetReturn = targetReturn,
>             targetRisk = targetRisk, targetAlpha = targetAlpha,
>             status = status), title = "Constrained MV Frontier",
>         description = .description())
> }
>
> ########################################################################
> ############
>
> # You should be able to specify the data in this form:
> mu <- c( 0.1, 0.08, 0.065)
> sigma <- c( 0.18, 0.12, 0.09 )
>
> correlationMatrix <- rbind( c( 1, 0.8, 0.9 ),
>                                               c( 0.8, 1, 0.75),
>                                               c( 0.9, 0.75, 1) )
>
> covarianceMatrix <- cor2cov(correlationMatrix, sigma )
>
>
> data = list( mu = mu, Sigma = covarianceMatrix )
>
> # And then do the optimisation
> frontier <- portfolioFrontier(data, spec = spec, constraints )
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
>

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From guy.yollin at rotellacapital.com  Fri Oct  2 18:38:24 2009
From: guy.yollin at rotellacapital.com (Guy Yollin)
Date: Fri, 2 Oct 2009 11:38:24 -0500
Subject: [R-SIG-Finance] Engle Granger test critical values
In-Reply-To: <4AAD56F399C8564C9EB6817C17618CDD0251EE59@NYC-XCH3.win.moorecap.com>
References: <4AAD56F399C8564C9EB6817C17618CDD0251EE59@NYC-XCH3.win.moorecap.com>
Message-ID: <E4259A82356E7F46B4F911FB27B0D725183B98C5CD@AUSP01VMBX02.collaborationhost.net>

Hi Reena,

If you're looking for residual based cointegration tests in R, you can use po.test in the package tseries or ca.po in the package urca.

If you're just looking for critical values for residual based cointegration tests, see table 10 here:

http://www2.warwick.ac.uk/fac/soc/economics/staff/faculty/jeremysmith/manual/statisticaltables.pdf

Or the classic Phillips Ouliaris paper available here:

http://cowles.econ.yale.edu/P/cp/p07a/p0746.pdf

Personally, I use the function ur.df from the package urca and the critical values from tables IIa/IIb/IIc from Phillips Ouliaris.

Hope this helps.

Best,

-- G


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Reena Bansal
Sent: Friday, October 02, 2009 8:19 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] Engle Granger test critical values

Hi,

I am looking at the Engle Granger Cointegration methodology for two
variables. After testing for unit roots, the methodology requires to
perform the OLS on the two variable and check the residuals for unit
root using the Engle Granger test critical values instead of the
Augmented Dickey Fuller test critical values. 

Specifically I am looking for Table C in Applied Econometric Time Series
by Walter Enders (Second Edition, page 441) implementation in R. Does
anybody know if this is available in R?

Many thanks in advance,
Reena


	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From patrick at burns-stat.com  Fri Oct  2 20:57:58 2009
From: patrick at burns-stat.com (Patrick Burns)
Date: Fri, 02 Oct 2009 19:57:58 +0100
Subject: [R-SIG-Finance] Static Portfolio Optimization
In-Reply-To: <D595C0E05185614C90515F1E8A2D4CBF02B3CA28@NYC-XCH3.win.moorecap.com>
References: <D595C0E05185614C90515F1E8A2D4CBF02B3CA28@NYC-XCH3.win.moorecap.com>
Message-ID: <4AC64D36.5010003@burns-stat.com>

Jorge Nieves wrote:
> Thanks for your responses. I found the function "portfolio.optim" and
> the tseries series package [...] However, I still do not see how to
> pass into the function the vector of expected values and the covariance
> matrix. 
[...]

This bothers me on two counts:

1) computational
2) subject matter

That Jorge is not finding the functionality
that he wants means that modular programming
is not being used.  The modular approach
would have a function that does the optimization
with the expected returns and variance as
arguments.  That function would then be
used by a function that does the larger task.

Okay, an advantage of R is that it is generally
easy to modify functions for your own purposes.
But it is better to organize ocmputations so
that people don't feel compelled to do that.
Let's abandon the SAS monolith culture.

I haven't investigated the functions that are
under discussion, so perhaps I am misunderstanding
what they are doing.  But if they are using the
history of returns to predict future returns, that
is almost always going to be pretty much complete
nonsense -- with or without the Efficient Market
Hypothesis.

I would hope the R community embrace quality in
subject matter decisions as well as computational
quality.


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of "The R Inferno" and "A Guide for the Unwilling S User")


> 
> Thanks, 
> 
> 
> Jorge Nieves
> 
> 
> -----Original Message-----
> From: Dirk Eddelbuettel [mailto:edd at debian.org] 
> Sent: Thursday, October 01, 2009 04:25 PM
> To: markleeds at verizon.net
> Cc: Jorge Nieves; r-sig-finance at stat.math.ethz.ch;
> jessevel at andrew.cmu.edu
> Subject: Re: [R-SIG-Finance] Static Portfolio Optimization
> 
> 
> On 1 October 2009 at 15:01, markleeds at verizon.net wrote:
> | I think I remember Adrian Trapletti implemented static portfolio 
> | optimization using quadprog in tseries. It's been a long time so I 
> | don't remember the details ( it may be restricted to long only but you
> 
> | can add variables to make<br />it handle long short ) but you may want
> 
> | to check tseries out.
> 
> Correct -- the tseries package has done since time immportal. 
> 
> And some seven or eight years ago I sent Adrian a patch, styled after
> the discussion in Huang and Litzenberger, that adds the ability to have
> long and short positions.  
> 
> Which Adrian promptly added and which has been there ever since:
> 
> R> head(as.zoo(EuStockMarkets))
>            DAX  SMI  CAC FTSE
> 1991(130) 1629 1678 1773 2444
> 1991(131) 1614 1688 1750 2460
> 1991(132) 1607 1679 1718 2448
> 1991(133) 1621 1684 1708 2470
> 1991(134) 1618 1687 1723 2485
> 1991(135) 1611 1672 1714 2467
> R> X <- diff(log(as.zoo(EuStockMarkets)))
> R> res <- portfolio.optim(X)                 ## Long only
> R> res$pw
> [1] 0.0000 0.3958 0.0000 0.6042
> R> res <- portfolio.optim(X, shorts=TRUE)    ## Long/Short
> R> res$pw
> [1]  0.02550  0.38213 -0.06377  0.65614
> R> 
> 
> This is arguably a better example than the one in help(portfolio.optim)
> so maybe I should send Kurt a new patch :)
> 
> Dirk
> 
> --
> Three out of two people have difficulties with fractions.
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
>


From sig.lorenzo.bertolini at googlemail.com  Sat Oct  3 01:51:29 2009
From: sig.lorenzo.bertolini at googlemail.com (Lorenzo Bertolini)
Date: Sat, 3 Oct 2009 01:51:29 +0200
Subject: [R-SIG-Finance] fPortfolio question and edited code
Message-ID: <fbe1429f0910021651k527cc9b7t33eefffd1aacf05e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091003/358e8fee/attachment.pl>

From kriskumar at earthlink.net  Sun Oct  4 17:29:55 2009
From: kriskumar at earthlink.net (Krishna Kumar)
Date: Sun, 4 Oct 2009 11:29:55 -0400
Subject: [R-SIG-Finance] RBloomberg News and Upcoming Versions
In-Reply-To: <a7d6d2740910010306i480fd9cfw180b5a8d7e9cf881@mail.gmail.com>
References: <a7d6d2740910010306i480fd9cfw180b5a8d7e9cf881@mail.gmail.com>
Message-ID: <1CF64BBE-695B-49B6-9640-3065F0E5353D@earthlink.net>

Just a quick note to thank the original creator and you for the work  
on this. This is a work-horse for a lot of routine things I do.  I  
will have a look at the new beta and let you know my feedback.  If  
there is one wish it is not so much RBloomberg (specific) but the  
quirky behavior of the BBG api and the data limits (for large  
retrievals) needs to be better documented. There has been a few posts  
here on this very topic.

On Oct 1, 2009, at 6:06 AM, Ana Nelson wrote:
>
>
>
> If you would like to help test the 0.2-x development versions, then  
> they are
> available from a new website at http://bloombergapi.com/rbloomberg.  
> A number
> of new features are available (compared with the CRAN version), such  
> as
> support for overrides. There is also the start of a PDF user guide.  
> There
> are some changes to the API, so I wouldn't recommend installing 0.2  
> unless
> you are the early adopter type and it is definitely not ready for  
> production
> use yet. I'm very keen to receive feedback, bug reports, feature  
> requests
> and such via launchpad or via email. The launchpad site where you  
> can report
> bugs etc. is here:
>
> https://launchpad.net/rbloomberg
>
> If you are interested in contributing, I'd be delighted to hear from  
> you,
> particularly with regard to the C or Java APIs.


From a.trapletti at swissonline.ch  Mon Oct  5 10:28:36 2009
From: a.trapletti at swissonline.ch (Adrian Trapletti)
Date: Mon, 05 Oct 2009 10:28:36 +0200
Subject: [R-SIG-Finance] Static Portfolio Optimization
Message-ID: <4AC9AE34.3010608@swissonline.ch>

I agree with Patrick. I wrote tseries about 10(?) years ago and for 
sure, it may be possible to improve it. Concerning the second point, it 
is in fact highly non-trivial if not impossible to construct portfolios 
that are "better" out-of-sample than naive portfolios. Raman Uppal from 
the London Business School and other authors wrote several nice papers 
about the subject. Googling I found the following one: 
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=911512

Best regards
Adrian

> Message: 4
> Date: Fri, 02 Oct 2009 19:57:58 +0100
> From: Patrick Burns <patrick at burns-stat.com>
> Subject: Re: [R-SIG-Finance] Static Portfolio Optimization
> To: Jorge Nieves <jorge.nieves at moorecap.com>
> Cc: r-sig-finance at stat.math.ethz.ch, jessevel at andrew.cmu.edu
> Message-ID: <4AC64D36.5010003 at burns-stat.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Jorge Nieves wrote:
>   
>> > Thanks for your responses. I found the function "portfolio.optim" and
>> > the tseries series package [...] However, I still do not see how to
>> > pass into the function the vector of expected values and the covariance
>> > matrix. 
>>     
> [...]
>
> This bothers me on two counts:
>
> 1) computational
> 2) subject matter
>
> That Jorge is not finding the functionality
> that he wants means that modular programming
> is not being used.  The modular approach
> would have a function that does the optimization
> with the expected returns and variance as
> arguments.  That function would then be
> used by a function that does the larger task.
>
> Okay, an advantage of R is that it is generally
> easy to modify functions for your own purposes.
> But it is better to organize ocmputations so
> that people don't feel compelled to do that.
> Let's abandon the SAS monolith culture.
>
> I haven't investigated the functions that are
> under discussion, so perhaps I am misunderstanding
> what they are doing.  But if they are using the
> history of returns to predict future returns, that
> is almost always going to be pretty much complete
> nonsense -- with or without the Efficient Market
> Hypothesis.
>
> I would hope the R community embrace quality in
> subject matter decisions as well as computational
> quality.
>
>
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of "The R Inferno" and "A Guide for the Unwilling S User")
>
>
>   

-- 
Adrian Trapletti
Steinstrasse 9b
8610 Uster
Switzerland

Phone : +41 (0) 44 9945630
Mobile : +41 (0) 76 3705631

Email : a.trapletti at swissonline.ch


From wuertz at itp.phys.ethz.ch  Tue Oct  6 02:50:38 2009
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Tue, 06 Oct 2009 02:50:38 +0200
Subject: [R-SIG-Finance] fPortfolio question and edited code
In-Reply-To: <fbe1429f0910021651k527cc9b7t33eefffd1aacf05e@mail.gmail.com>
References: <fbe1429f0910021651k527cc9b7t33eefffd1aacf05e@mail.gmail.com>
Message-ID: <4ACA945E.4060007@itp.phys.ethz.ch>

Lorenzo Bertolini wrote:
> DeaR List,
>
> I have been going through the fPortfolio package and changed some code in
> the eqsumWConstraints function.
> Now, if I use the String "Free" (instead of e.g. c("LongOnly","Partial")), I
> can specify weights constraints with
> more flexibility (also e.g. "eqsumW[1:6]=0", or "eqsumW[1:6]=-1" , which
> were problematic before).
>   
why ????

"Partial" (is still untested and) was thought to work together wit 
solveRquadprog together setting the meq
argument properly. Unfortunately it is not well documented. This is on 
the ToDo list.

> I have pasted the modified eqsumWConstraints() below and marked the changed
> parts.
>
> I have an actual problem which I find difficult to resolve, maybe someone
> can point me out in the right direction:
>
> I want to replicate the example in Diethelm Wurz' Chicago presentation in
> April (ppt slide 18):
>
> # Specification:
> data = LPP2005.RET[, 1:6]
> spec <- portfolioSpec()
> setTargetReturn(spec) <- 4*mean(data) # 17.2%
> setObjective(spec) = c("Objective", "Return", "Risk")
>   
do not forget to define the Data object Used later ...

Data = portfolioData(data, spec)

> Return <- function(weights) (getMu(Data) %*% weights)
> Risk <- function(weights) (sqrt(weights %*% getSigma(Data) %*% weights))
>   
in the previous 2 lines you called the Data object ...
> Objective <- function(weights) Risk(weights)
>
> setSolver(spec) <- "solveRdonlp2"
> # 130/30 Extension Constraints:
>
> lowerExtension <- function(w) sum(w[w<0])
> upperExtension <- function(w) sum(w[w>0])
>
> cons <- c(
>    "minW[1:nAssets] = rep(-0.30, times = nAssets)",
>    "maxW[1:nAssets] = rep( 1.30, times = nAssets)",
>    "minsumW[1:nAssets] = -0.30",
>    "maxsumW[1:nAssets] = 1.30",
>    "listF = list(lowerExtension, upperExtension)",
>    "minF = c(-0.30, 0.00)",
>    "maxF = c( 0.00, 1.30)")
>
> # Portfolio:
> efficientPortfolio(data, spec, cons)
>   

Title:
 MV Efficient Portfolio
 Estimator:         covEstimator
 Solver:            solveRdonlp2
 Optimize:          minRisk
 Constraints:       minW maxW minsumW maxsumW

Portfolio Weights:
    SBI     SPI     SII     LMI     MPI     ALT
-0.2954  0.0018 -0.0001 -0.0045  0.0000  1.1888

Covariance Risk Budgets:
   SBI    SPI    SII    LMI    MPI    ALT
0.0129 0.0014 0.0000 0.0002 0.0000 0.9854

Target Return and Risks:
  mean     mu    Cov  Sigma   CVaR    VaR
0.0010 0.0010 0.0068 0.0068 0.0161 0.0110



Diethelm Wuertz

> ... I get the error message: Error in UseMethod("getSigma") : no applicable
> method for "getSigma"
>
> I loaded fPortfolioSolver and can trace the origin of the error back to:
>
>
> [...]
> debug(Rdonlp2::donlp2)
>
> [...]
> debug: tryCatch(ans <- .Call("call_donlp2", as.double(par),
> as.integer(num.lin),
>     as.integer(num.nlin), fsilent, name, nchar(name), as.double(lbd),
>     as.double(ubd), as.double(conmat), control, accfun, confun,
>     environment(confun), PACKAGE = "Rdonlp2"), finally = .Call("teardown",
>     0, PACKAGE = "Rdonlp2"))
> Browse[1]>
> Error in UseMethod("getSigma") : no applicable method for "getSigma"
>
>
> Can someone give me a clue how to proceed? I would be very happy about that
> ;-)
>
> Best regards,
>
> Lorenzo Bertolini
>
>
>
> Here is the edited eqsumWConstraints() function:
>
>
> eqsumWConstraints <-
>     function(data, spec = portfolioSpec(), constraints = "LongOnly")
> {
>     # Description:
>     #   Returns a list with group equal matrix and vectors constraints
>
>     # Details:
>     #   Takes care of "eqsumW" strings
>     #   A_eq W = c_eq
>
>     # Arguments:
>     #   data - a timeSeries or a fPFOLIODATA object
>     #   spec - a fPFOLIOSPEC object
>     #   constraints - a constraints string
>
>     # Example:
>     #   data = as.timeSeries(data(LPP2005REC))[, 1:6]
>     #   spec = portfolioSpec(); setTargetReturn(spec) = mean(data)
>     #   constraints = "eqsumW[1:6]=1"
>     #   eqsumWConstraints(data, spec, constraints)
>     #   eqsumWConstraints(data, spec, constraints = "LongOnly")
>     #   eqsumWConstraints(data, spec, constraints = c("LongOnly","Partial"))
>
>     # FUNCTION:
>
>     # Get Statistics:
>     data = portfolioData(data, spec)
>     targetReturn = getTargetReturn(spec)[1]
>     if (is.null(targetReturn)) {
>         targetReturn = NA
>         stop("Target Return is Missing")
>     }
>
>     # Get Specifications:
>     mu <- getMu(data)
>     nAssets <- getNAssets(data)
>     assetsNames <- getNames(data)
>
>     # Target Return:
>     Aeq <- matrix(mu, byrow = TRUE, ncol = nAssets)
>
>     # Full or partial Investment?
>     if ("partial" %in% tolower(constraints))
>         fullInvest = FALSE else fullInvest = TRUE
>
>     if ("free" %in% tolower(constraints))                        ## added
> this
>         fullInvest = FALSE else fullInvest = TRUE                    ##
> added this
>
>     # Full Investment:
>     #   - negative to handle better partial Investment in Rquadprog:
>     if (fullInvest) Aeq <- rbind(Aeq, -rep(1, nAssets))
>
>     # Dimension Names:
>     colnames(Aeq) <- assetsNames
>     if (fullInvest)
>         rownames(Aeq) <- c("Return", "Budget")
>     else
>         rownames(Aeq) <- "Return"
>
>     # RHS Vector:
>     if (fullInvest)
>         ceq <- c(Return = targetReturn, Budget = -1)
>     else
>         ceq <- c(Return = targetReturn)
>
>     # Extract and Compose Matrix and Vector:
>     what6 = substr(constraints, 1, 6)
>     if (!is.null(constraints)) {
>         nC = length(constraints)
>         for (i in 1:nC) {
>             if (what6[i] == "eqsumW")  {
>                 eqsumW = rep(0, times = nAssets)
>                 names(eqsumW) <- assetsNames
>
>         alternateTextA <-strsplit(constraints[i], "=")[[1]][1]            ##
> added this
>         alternateTextB <-"=1"                            ## added this
>         alternateText <- paste(alternateTextA,alternateTextB,sep="")
> ## added this
>                 eval(parse(text = alternateText))                    ##
> changed this
>                 #####eval(parse(text = constraints[i]))
> ##
>
>                 Aeq = rbind(Aeq, eqsumW = sign(eqsumW))
>                 a = strsplit(constraints[i], "=")[[1]][2]
>                 ceq = c(ceq, eqsumW = as.numeric(a))
>             }
>         }
>     }
>
>     # Return Value:
>     cbind(ceq, Aeq)
> }
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
>


From lara.shocron at gmail.com  Tue Oct  6 06:12:26 2009
From: lara.shocron at gmail.com (Lara Shocron)
Date: Tue, 6 Oct 2009 12:12:26 +0800
Subject: [R-SIG-Finance] portfolio.optim - RiskFreeRate
Message-ID: <5a8ae12f0910052112r685a72c3nf356147837bb7ed@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091006/857f8148/attachment.pl>

From sig.lorenzo.bertolini at googlemail.com  Tue Oct  6 11:01:12 2009
From: sig.lorenzo.bertolini at googlemail.com (Lorenzo Bertolini)
Date: Tue, 6 Oct 2009 11:01:12 +0200
Subject: [R-SIG-Finance] fPortfolio question and edited code
In-Reply-To: <4ACA945E.4060007@itp.phys.ethz.ch>
References: <fbe1429f0910021651k527cc9b7t33eefffd1aacf05e@mail.gmail.com>
	<4ACA945E.4060007@itp.phys.ethz.ch>
Message-ID: <fbe1429f0910060201x4d2c4fcayc2b7f1b691463a29@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091006/cef034eb/attachment.ksh>

From brian at braverock.com  Tue Oct  6 11:45:47 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 06 Oct 2009 04:45:47 -0500
Subject: [R-SIG-Finance] portfolio.optim - RiskFreeRate
In-Reply-To: <5a8ae12f0910052112r685a72c3nf356147837bb7ed@mail.gmail.com>
References: <5a8ae12f0910052112r685a72c3nf356147837bb7ed@mail.gmail.com>
Message-ID: <4ACB11CB.7010400@braverock.com>

Lara Shocron wrote:
> One of the arguments of portfolio.optim is rf, and corresponds to the risk
> free rate.
> Do you know if it's considered as an annual, monthly or daily rate?

rf should have the same periodicity as your return series.

   - Brian


From wuertz at itp.phys.ethz.ch  Tue Oct  6 12:09:49 2009
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Tue, 06 Oct 2009 12:09:49 +0200
Subject: [R-SIG-Finance] portfolio.optim - RiskFreeRate
In-Reply-To: <5a8ae12f0910052112r685a72c3nf356147837bb7ed@mail.gmail.com>
References: <5a8ae12f0910052112r685a72c3nf356147837bb7ed@mail.gmail.com>
Message-ID: <4ACB176D.8090301@itp.phys.ethz.ch>

Lara Shocron wrote:
> Dear All,
> One of the arguments of portfolio.optim is rf, and corresponds to the risk
> free rate.
> Do you know if it's considered as an annual, monthly or daily rate?
>
> Thanks,
> Lara
>
>
>   
It should be on the same time scale as your time series data

Diethelm Wuertz


From breman.mark at gmail.com  Wed Oct  7 10:05:07 2009
From: breman.mark at gmail.com (Mark Breman)
Date: Wed, 7 Oct 2009 10:05:07 +0200
Subject: [R-SIG-Finance] Vectorized rolling computation on xts series
Message-ID: <5e6a2e670910070105k7538d4b1m83187d46c7429805@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091007/ae681124/attachment.pl>

From shane.conway at gmail.com  Wed Oct  7 10:12:47 2009
From: shane.conway at gmail.com (Shane)
Date: Wed, 7 Oct 2009 04:12:47 -0400
Subject: [R-SIG-Finance] Vectorized rolling computation on xts series
In-Reply-To: <5e6a2e670910070105k7538d4b1m83187d46c7429805@mail.gmail.com>
References: <5e6a2e670910070105k7538d4b1m83187d46c7429805@mail.gmail.com>
Message-ID: <6487EC6C-10E1-4506-9838-A278B9EED121@gmail.com>

I think you want the apply.monthly function in xts. It also has other  
time periods (eg daily).

You may also want to look at rollapply in zoo.

Sent from my iPhone

On Oct 7, 2009, at 4:05 AM, Mark Breman <breman.mark at gmail.com> wrote:

> Hi,
> I have a univariate xts timeseries (daily data) for which I need to  
> apply a
> computation for each element. The computation for element x needs  
> the last y
> months of the data from the timeseries. What's more, I need a  
> "vectorized"
> computation because looping over all elements is too slow (it's a  
> large
> timeseries).
>
> I think this is what is called a "rolling" or "running" computation  
> in R.
>
> The computation I need to do for element x is:
> - calculate the percentage of the value x within the range of values  
> from
> the last y months, i.e. determine the min() and max() of the last y  
> months
> of data (including x), and determine what percentage of this range  
> the value
> x is. For example: min(last 1 months) == 10, max(last 1 months) ==  
> 50, x ==
> 20 would yield: 25%
> - elements for which y months of previous data (including x itself)  
> is not
> available should become NaN or some other "special value".
>
> An example
> So let's say I have a timeseries called "data":
>
>> data
>           NonCommNet
> 1995-01-03      44580
> 1995-01-04      44580
> 1995-01-05      44580
> 1995-01-06      44580
> 1995-01-09      44580
> 1995-01-10      32835
> 1995-01-11      32835
> 1995-01-12      32835
> 1995-01-13      32835
> 1995-01-16      32835
> 1995-01-17      38385
> 1995-01-18      38385
> 1995-01-19      38385
> 1995-01-20      38385
> 1995-01-23      38385
> 1995-01-24      19150
> 1995-01-25      19150
> 1995-01-26      19150
> 1995-01-27      19150
> 1995-01-30      19150
> 1995-01-31      15245
> 1995-02-01      15245
> 1995-02-02      15245
> 1995-02-03      15245
> 1995-02-06      15245
> 1995-02-07      24110
> 1995-02-08      24110
> 1995-02-09      24110
> 1995-02-10      24110
> 1995-02-13      24110
> 1995-02-14      17615
> 1995-02-15      17615
> 1995-02-16      17615
> 1995-02-17      17615
> 1995-02-21     -23080
> 1995-02-22     -23080
> 1995-02-23     -23080
> 1995-02-24     -23080
> 1995-02-27     -23080
> 1995-02-28     -17445
>
> I tried the following "vectorized" solution ( example with y = 1  
> month):
>> ((data - min(last(data, "1 months"))) / (max(last(data, "1  
>> months")) -
> min(last(data, "1 months")))) * 100
>           NonCommNet
> 1995-01-03  143.37783
> 1995-01-04  143.37783
> 1995-01-05  143.37783
> 1995-01-06  143.37783
> 1995-01-09  143.37783
> 1995-01-10  118.48909
> 1995-01-11  118.48909
> 1995-01-12  118.48909
> 1995-01-13  118.48909
> 1995-01-16  118.48909
> 1995-01-17  130.25005
> 1995-01-18  130.25005
> 1995-01-19  130.25005
> 1995-01-20  130.25005
> 1995-01-23  130.25005
> 1995-01-24   89.48930
> 1995-01-25   89.48930
> 1995-01-26   89.48930
> 1995-01-27   89.48930
> 1995-01-30   89.48930
> 1995-01-31   81.21424
> 1995-02-01   81.21424
> 1995-02-02   81.21424
> 1995-02-03   81.21424
> 1995-02-06   81.21424
> 1995-02-07  100.00000
> 1995-02-08  100.00000
> 1995-02-09  100.00000
> 1995-02-10  100.00000
> 1995-02-13  100.00000
> 1995-02-14   86.23649
> 1995-02-15   86.23649
> 1995-02-16   86.23649
> 1995-02-17   86.23649
> 1995-02-21    0.00000
> 1995-02-22    0.00000
> 1995-02-23    0.00000
> 1995-02-24    0.00000
> 1995-02-27    0.00000
> 1995-02-28   11.94109
>
> This does not satisfy my constraints because:
> 1) the first month of data should have become NaN or some other  
> special
> value as there is not a full month of previous data available. I  
> think this
> is caused by the last() function which simply returns the available  
> data if
> the requested amount of data is greater than the available amount of  
> data.
> 2) the results for the second month of data are wrong. For instance  
> look at
> the result for 1995-02-06 which is 81.21424%. This should have been  
> 0%. The
> last months min() is 15245 (from 1995-02-06), the max() is 44580 (from
> element 1995-01-06) so it should yield 0%.
>
>> From analyzing the results I get the impression that the last()  
>> function is
> not suited for a "vectorized" solution but I'm not really sure...
>
> I also had a look at runMin() and runMax() from the TTR package, but  
> you
> can't specify a calendar range with these functions as you can with  
> last()
> and first() from the xts package.
>
> Now my question is: am I doing something wrong here or do you know  
> another
> vectorized function that satisfies my constraints?
>
> Kind regards,
>
> -Mark-
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From breman.mark at gmail.com  Wed Oct  7 10:30:57 2009
From: breman.mark at gmail.com (Mark Breman)
Date: Wed, 7 Oct 2009 10:30:57 +0200
Subject: [R-SIG-Finance] Vectorized rolling computation on xts series
In-Reply-To: <6487EC6C-10E1-4506-9838-A278B9EED121@gmail.com>
References: <5e6a2e670910070105k7538d4b1m83187d46c7429805@mail.gmail.com>
	<6487EC6C-10E1-4506-9838-A278B9EED121@gmail.com>
Message-ID: <5e6a2e670910070130p6d987317s31d56eb5bb3899be@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091007/f0e39e36/attachment.pl>

From aleks.clark at gmail.com  Wed Oct  7 11:11:17 2009
From: aleks.clark at gmail.com (Aleks Clark)
Date: Wed, 7 Oct 2009 04:11:17 -0500
Subject: [R-SIG-Finance] Vectorized rolling computation on xts series
In-Reply-To: <5e6a2e670910070130p6d987317s31d56eb5bb3899be@mail.gmail.com>
References: <5e6a2e670910070105k7538d4b1m83187d46c7429805@mail.gmail.com>
	<6487EC6C-10E1-4506-9838-A278B9EED121@gmail.com>
	<5e6a2e670910070130p6d987317s31d56eb5bb3899be@mail.gmail.com>
Message-ID: <5aebc8960910070211l4451fd66rd69c0b081f357c3f@mail.gmail.com>

Another approach would be to use zoo or xts's lag function to to
generate a dataframe or matrix with the current day's data and N
previous periods in a table. If your data is fairly univariate, this
shouldn't prove a problem, just do a little math and you can specify
easily how many days of data to "go back". You'd do something like
this:

starting with:

d1
d2
d3
d4
d5

use Lag (or lag, they behave differently), then t() and apply() and end up with:

d1 na na na
d2 d1 na na
d3 d2 d1 na
d4 d3 d2 d1
d5 d4 d3 d2

you can then easily run your computations in a vectored form using the
apply family of functions.

On Wed, Oct 7, 2009 at 3:30 AM, Mark Breman <breman.mark at gmail.com> wrote:
> Hi Shane,
> I had a look at these functions but they do not satisfy my constraints:
>
> - apply.monthly works with 'calendar months', but I need a function that
> allows me to specify for instance 1995-01-06 until 1995-02-06 (i.e.
> 'duration' of one month) for the computation of element x = 1995-02-06
>
> - rollapply (and also rollmax, rollmin) need a specification of the number
> of previous elements from the series if I understand it correctly. As you
> can see in the example it is daily data but with lots of gaps, so this would
> be very difficult to do if at all possible.
>
> Thanks for your quick response though,
>
> Kind regards,
>
> -Mark-
>
> 2009/10/7 Shane <shane.conway at gmail.com>
>
>> I think you want the apply.monthly function in xts. It also has other time
>> periods (eg daily).
>>
>> You may also want to look at rollapply in zoo.
>>
>> Sent from my iPhone
>>
>>
>> On Oct 7, 2009, at 4:05 AM, Mark Breman <breman.mark at gmail.com> wrote:
>>
>> ?Hi,
>>> I have a univariate xts timeseries (daily data) for which I need to apply
>>> a
>>> computation for each element. The computation for element x needs the last
>>> y
>>> months of the data from the timeseries. What's more, I need a "vectorized"
>>> computation because looping over all elements is too slow (it's a large
>>> timeseries).
>>>
>>> I think this is what is called a "rolling" or "running" computation in R.
>>>
>>> The computation I need to do for element x is:
>>> - calculate the percentage of the value x within the range of values from
>>> the last y months, i.e. determine the min() and max() of the last y months
>>> of data (including x), and determine what percentage of this range the
>>> value
>>> x is. For example: min(last 1 months) == 10, max(last 1 months) == 50, x
>>> ==
>>> 20 would yield: 25%
>>> - elements for which y months of previous data (including x itself) is not
>>> available should become NaN or some other "special value".
>>>
>>> An example
>>> So let's say I have a timeseries called "data":
>>>
>>> ?data
>>>>
>>> ? ? ? ? ?NonCommNet
>>> 1995-01-03 ? ? ?44580
>>> 1995-01-04 ? ? ?44580
>>> 1995-01-05 ? ? ?44580
>>> 1995-01-06 ? ? ?44580
>>> 1995-01-09 ? ? ?44580
>>> 1995-01-10 ? ? ?32835
>>> 1995-01-11 ? ? ?32835
>>> 1995-01-12 ? ? ?32835
>>> 1995-01-13 ? ? ?32835
>>> 1995-01-16 ? ? ?32835
>>> 1995-01-17 ? ? ?38385
>>> 1995-01-18 ? ? ?38385
>>> 1995-01-19 ? ? ?38385
>>> 1995-01-20 ? ? ?38385
>>> 1995-01-23 ? ? ?38385
>>> 1995-01-24 ? ? ?19150
>>> 1995-01-25 ? ? ?19150
>>> 1995-01-26 ? ? ?19150
>>> 1995-01-27 ? ? ?19150
>>> 1995-01-30 ? ? ?19150
>>> 1995-01-31 ? ? ?15245
>>> 1995-02-01 ? ? ?15245
>>> 1995-02-02 ? ? ?15245
>>> 1995-02-03 ? ? ?15245
>>> 1995-02-06 ? ? ?15245
>>> 1995-02-07 ? ? ?24110
>>> 1995-02-08 ? ? ?24110
>>> 1995-02-09 ? ? ?24110
>>> 1995-02-10 ? ? ?24110
>>> 1995-02-13 ? ? ?24110
>>> 1995-02-14 ? ? ?17615
>>> 1995-02-15 ? ? ?17615
>>> 1995-02-16 ? ? ?17615
>>> 1995-02-17 ? ? ?17615
>>> 1995-02-21 ? ? -23080
>>> 1995-02-22 ? ? -23080
>>> 1995-02-23 ? ? -23080
>>> 1995-02-24 ? ? -23080
>>> 1995-02-27 ? ? -23080
>>> 1995-02-28 ? ? -17445
>>>
>>> I tried the following "vectorized" solution ( example with y = 1 month):
>>>
>>>> ((data - min(last(data, "1 months"))) / (max(last(data, "1 months")) -
>>>>
>>> min(last(data, "1 months")))) * 100
>>> ? ? ? ? ?NonCommNet
>>> 1995-01-03 ?143.37783
>>> 1995-01-04 ?143.37783
>>> 1995-01-05 ?143.37783
>>> 1995-01-06 ?143.37783
>>> 1995-01-09 ?143.37783
>>> 1995-01-10 ?118.48909
>>> 1995-01-11 ?118.48909
>>> 1995-01-12 ?118.48909
>>> 1995-01-13 ?118.48909
>>> 1995-01-16 ?118.48909
>>> 1995-01-17 ?130.25005
>>> 1995-01-18 ?130.25005
>>> 1995-01-19 ?130.25005
>>> 1995-01-20 ?130.25005
>>> 1995-01-23 ?130.25005
>>> 1995-01-24 ? 89.48930
>>> 1995-01-25 ? 89.48930
>>> 1995-01-26 ? 89.48930
>>> 1995-01-27 ? 89.48930
>>> 1995-01-30 ? 89.48930
>>> 1995-01-31 ? 81.21424
>>> 1995-02-01 ? 81.21424
>>> 1995-02-02 ? 81.21424
>>> 1995-02-03 ? 81.21424
>>> 1995-02-06 ? 81.21424
>>> 1995-02-07 ?100.00000
>>> 1995-02-08 ?100.00000
>>> 1995-02-09 ?100.00000
>>> 1995-02-10 ?100.00000
>>> 1995-02-13 ?100.00000
>>> 1995-02-14 ? 86.23649
>>> 1995-02-15 ? 86.23649
>>> 1995-02-16 ? 86.23649
>>> 1995-02-17 ? 86.23649
>>> 1995-02-21 ? ?0.00000
>>> 1995-02-22 ? ?0.00000
>>> 1995-02-23 ? ?0.00000
>>> 1995-02-24 ? ?0.00000
>>> 1995-02-27 ? ?0.00000
>>> 1995-02-28 ? 11.94109
>>>
>>> This does not satisfy my constraints because:
>>> 1) the first month of data should have become NaN or some other special
>>> value as there is not a full month of previous data available. I think
>>> this
>>> is caused by the last() function which simply returns the available data
>>> if
>>> the requested amount of data is greater than the available amount of data.
>>> 2) the results for the second month of data are wrong. For instance look
>>> at
>>> the result for 1995-02-06 which is 81.21424%. This should have been 0%.
>>> The
>>> last months min() is 15245 (from 1995-02-06), the max() is 44580 (from
>>> element 1995-01-06) so it should yield 0%.
>>>
>>> ?From analyzing the results I get the impression that the last() function
>>>> is
>>>>
>>> not suited for a "vectorized" solution but I'm not really sure...
>>>
>>> I also had a look at runMin() and runMax() from the TTR package, but you
>>> can't specify a calendar range with these functions as you can with last()
>>> and first() from the xts package.
>>>
>>> Now my question is: am I doing something wrong here or do you know another
>>> vectorized function that satisfies my constraints?
>>>
>>> Kind regards,
>>>
>>> -Mark-
>>>
>>> ? [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Aleks Clark


From aleks.clark at gmail.com  Wed Oct  7 11:23:17 2009
From: aleks.clark at gmail.com (Aleks Clark)
Date: Wed, 7 Oct 2009 04:23:17 -0500
Subject: [R-SIG-Finance] interpolating missing values from a TS
Message-ID: <5aebc8960910070223y713abce7i8d028ac0f949ab46@mail.gmail.com>

I've got a large TS with occasional NAs I'd like to roughly
interpolate, I'm currently doing this but it's pretty slow:

	lapply(1:nrow(delta), function(i) {
		lapply(1:ncol(delta), function(j) {
			if (is.na(delta[i,j])) {
				if ((i==1)||is.na(delta[i-1,j])) {
				  delta[i,j] <- delta[i+1,j]
				} else { delta[i,j] <- delta[i-1,j]}
			}
		})
	})

any ideas for a better solution?


-- 
Aleks Clark


From sandor.benczik at crabel.ro  Wed Oct  7 11:28:39 2009
From: sandor.benczik at crabel.ro (Sandor Benczik)
Date: Wed, 7 Oct 2009 12:28:39 +0300
Subject: [R-SIG-Finance] Vectorized rolling computation on xts series
Message-ID: <1DD3BDB66DD5A34BAB9D8C9AA6A422EF5341CE@crabelmain.crabel.ro>

| -----Original Message-----
| From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-
| bounces at stat.math.ethz.ch] On Behalf Of Mark Breman

| The computation I need to do for element x is:
| - calculate the percentage of the value x within the range of values
from
| the last y months, i.e. determine the min() and max() of the last y
months
| of data (including x), and determine what percentage of this range the
| value
| x is. For example: min(last 1 months) == 10, max(last 1 months) == 50,
x
| ==
| 20 would yield: 25%
| - elements for which y months of previous data (including x itself) is
not
| available should become NaN or some other "special value".

| I tried the following "vectorized" solution ( example with y = 1
month):
| > ((data - min(last(data, "1 months"))) / (max(last(data, "1 months"))
-
| min(last(data, "1 months")))) * 100

| This does not satisfy my constraints because:
| 1) the first month of data should have become NaN or some other
special
| value as there is not a full month of previous data available. I think
| this
| is caused by the last() function which simply returns the available
data
| if
| the requested amount of data is greater than the available amount of
data.

As you said, your data has frequent gaps, so you will never have a full
month of previous data. Does that mean that you want a time-series full
of NaN's? You should be careful how do you define a 'full month'.

| 2) the results for the second month of data are wrong. 
| >From analyzing the results I get the impression that the last()
function
| is
| not suited for a "vectorized" solution but I'm not really sure...

In your code you are not applying a 'vectorized' last. You are taking
the last one month of the whole time-series, which is the reason for the
strange results. 

A couple of ideas: build an empty (0-column) xts with all dates
(including those not in your series), and merge it with your series, and
then you can apply zoo's rollmax & rollmin on a constant 30 or 31 day
lookback window. (Both commands are fast, you may want to lookup na.locf
for zoo or na.rm argument for max/min to deal with the extra dates.)

Even simpler: assume 21 business days per month and do a rollmin/max on
a window of 21. (Is it that big a problem if you are 1-2 days off?)

If neither works for you and speed is important, this might be a good
candidate for C code.

HTH,
Sandor


From matthieu.stigler at gmail.com  Wed Oct  7 11:38:54 2009
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Wed, 7 Oct 2009 11:38:54 +0200
Subject: [R-SIG-Finance] interpolating missing values from a TS
In-Reply-To: <5aebc8960910070223y713abce7i8d028ac0f949ab46@mail.gmail.com>
References: <5aebc8960910070223y713abce7i8d028ac0f949ab46@mail.gmail.com>
Message-ID: <111060c20910070238m648933f5n4300f97c1066024b@mail.gmail.com>

Have a look on
http://www.rmetrics.org/ebooks/TimeSeriesFAQ.pdf

p 101, which discusses interpolation ( na.approx, na.splines) for
different time series classes.

Matthieu

2009/10/7 Aleks Clark <aleks.clark at gmail.com>:
> I've got a large TS with occasional NAs I'd like to roughly
> interpolate, I'm currently doing this but it's pretty slow:
>
> ? ? ? ?lapply(1:nrow(delta), function(i) {
> ? ? ? ? ? ? ? ?lapply(1:ncol(delta), function(j) {
> ? ? ? ? ? ? ? ? ? ? ? ?if (is.na(delta[i,j])) {
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?if ((i==1)||is.na(delta[i-1,j])) {
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?delta[i,j] <- delta[i+1,j]
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?} else { delta[i,j] <- delta[i-1,j]}
> ? ? ? ? ? ? ? ? ? ? ? ?}
> ? ? ? ? ? ? ? ?})
> ? ? ? ?})
>
> any ideas for a better solution?
>
>
> --
> Aleks Clark
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From brian at braverock.com  Wed Oct  7 14:44:58 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 07 Oct 2009 07:44:58 -0500
Subject: [R-SIG-Finance] interpolating missing values from a TS
In-Reply-To: <5aebc8960910070223y713abce7i8d028ac0f949ab46@mail.gmail.com>
References: <5aebc8960910070223y713abce7i8d028ac0f949ab46@mail.gmail.com>
Message-ID: <4ACC8D4A.5030501@braverock.com>

Aleks Clark wrote:
> I've got a large TS with occasional NAs I'd like to roughly
> interpolate, I'm currently doing this but it's pretty slow:
>
> 	lapply(1:nrow(delta), function(i) {
> 		lapply(1:ncol(delta), function(j) {
> 			if (is.na(delta[i,j])) {
> 				if ((i==1)||is.na(delta[i-1,j])) {
> 				  delta[i,j] <- delta[i+1,j]
> 				} else { delta[i,j] <- delta[i-1,j]}
> 			}
> 		})
> 	})
>
> any ideas for a better solution
?na.approx


From ggrothendieck at gmail.com  Wed Oct  7 15:55:02 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 7 Oct 2009 09:55:02 -0400
Subject: [R-SIG-Finance] interpolating missing values from a TS
In-Reply-To: <5aebc8960910070223y713abce7i8d028ac0f949ab46@mail.gmail.com>
References: <5aebc8960910070223y713abce7i8d028ac0f949ab46@mail.gmail.com>
Message-ID: <971536df0910070655q5dbf283fo7d7f4d18d165fe09@mail.gmail.com>

Try this (time series with values of 2, NA , etc. at indicated times
(1, 3, etc.) which has NAs removed by linear approx:

> library(zoo)
> z <- zoo(c(2,NA,1,4,5,2), c(1,3,4,6,7,8))
> na.approx(z)
       1        3        4        6        7        8
2.000000 1.333333 1.000000 4.000000 5.000000 2.000000

zoo has otherl na.* routines too.  They work the same way.  You just
give them the series and the NAs are filled in as in the example
above.

na.approx - linear approximation to NAs
na.contiguous - only keep portion of series with no NAs
na.locf - fill NAs from last non-NA
na.omit - remove NAs
na.spline - spline approximation to NAs
na.trim - remove NAs at ends

And also in the stinepack package:

na.stinterp - use Stineman approxmation to remove NAs

See ?na.approx for a few more examples.

On Wed, Oct 7, 2009 at 5:23 AM, Aleks Clark <aleks.clark at gmail.com> wrote:
> I've got a large TS with occasional NAs I'd like to roughly
> interpolate, I'm currently doing this but it's pretty slow:
>
> ? ? ? ?lapply(1:nrow(delta), function(i) {
> ? ? ? ? ? ? ? ?lapply(1:ncol(delta), function(j) {
> ? ? ? ? ? ? ? ? ? ? ? ?if (is.na(delta[i,j])) {
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?if ((i==1)||is.na(delta[i-1,j])) {
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?delta[i,j] <- delta[i+1,j]
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?} else { delta[i,j] <- delta[i-1,j]}
> ? ? ? ? ? ? ? ? ? ? ? ?}
> ? ? ? ? ? ? ? ?})
> ? ? ? ?})
>
> any ideas for a better solution?
>
>
> --
> Aleks Clark
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From gps at asu.edu  Thu Oct  8 02:34:15 2009
From: gps at asu.edu (Geoffrey Smith)
Date: Wed, 7 Oct 2009 17:34:15 -0700
Subject: [R-SIG-Finance] treynor black (1973)
Message-ID: <4b5c27440910071734o279a3d72oc94ed0e39b82b694@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091007/6dd8aed6/attachment.pl>

From rhelpacc at gmail.com  Thu Oct  8 02:55:22 2009
From: rhelpacc at gmail.com (R_help Help)
Date: Wed, 7 Oct 2009 20:55:22 -0400
Subject: [R-SIG-Finance] Evaluating/comparing dynamic linear model
Message-ID: <ad1ead5f0910071755m2005d30flc12b973d967421d8@mail.gmail.com>

Hi,

I have two DLM model specifications (x[t] and y[t] are univariate):

MODEL1:
y[t] = b[t]x[t]+e[t], e[t] ~ N(0,v1^2)
b[t] = b[t-1]+eta[t], eta[t] ~ N(0,w1^2)

MODEL2:
y[t] = a[t]+e[t], e[t] ~ N(0,v2^2)
a[t] = a[t-1]+eta[t], eta[t] ~ N(0,w2^2)

I run the filter through data recursively to obtain state variables
for each model. However, how do I know if b[t]x[t] in MODEL1 is
different from MODEL2? In other words, how do I know if x[t] makes a
difference in explaining dynamic of y[t]?

Another question is that how do I compare MODEL1 and MODEL2? From
model specification point of view, how can one say that MODEL1 is
better than MODEL2? Any suggestion/reference would be greatly
appreciated. Thank you.

ac


From ssmith88 at umd.edu  Thu Oct  8 03:52:53 2009
From: ssmith88 at umd.edu (ssmith88 at umd.edu)
Date: Wed,  7 Oct 2009 21:52:53 -0400 (EDT)
Subject: [R-SIG-Finance] treynor black (1973)
In-Reply-To: <4b5c27440910071734o279a3d72oc94ed0e39b82b694@mail.gmail.com>
References: <4b5c27440910071734o279a3d72oc94ed0e39b82b694@mail.gmail.com>
Message-ID: <20091007215253.AMR20022@po7.mail.umd.edu>

Not familiar with the theory, but i googled it and made this as an exercise.  I assumed you had all the inputs already though you'll probably want to start from raw price data.  Shouldn't be too hard to write something to find the inputs from the price data and then follow with this function.  Note this is sloppy as all variables are saved globally, you can clean it as you like.  Also, not sure if there is a package for this already or not. Hope this helps, there's an example below.       


treynorBlack<-function(mret,mvar,beta,alpha,var)
{
#n mispriced assets
#beta,alpha,var are vectors of length n
#mvar and mret are the market variance/return
num<<-numeric(length(beta))

for(i in 1:(length(beta)))
{
num[i]=(alpha[i])/(var[i])
}
denom<<-sum(num)
weights<<-numeric(length(beta))
for(i in 1:length(beta))
{
weights[i]<<-num[i]/denom
}
activeAlpha<<-weights%*%alpha
activeBeta<<-weights%*%beta
activeVar<<-weights%*%var
w<<-(activeAlpha/activeVar)/(mret/mvar)
activeFraction<<-w/(1+w*(1-activeBeta))
passiveFraction<<-1-activeFraction
}


> beta1<-c(1.5,1.2,.7)
> alpha1<-c(.01,.005,.02)
> var1<-c(.15,.17,.25)
> mret<-.09
> mret1<-.09
> mvar1<-.18
> treynorBlack(mret=mret1,mvar=mvar1,beta=beta1,alpha=alpha1,var=var1)
> activeFraction
[1,] 0.1395909
> passiveFraction
[1,] 0.860409
> weights
0.3786192 0.1670379 0.4543430


From josh.m.ulrich at gmail.com  Thu Oct  8 03:57:03 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 7 Oct 2009 20:57:03 -0500
Subject: [R-SIG-Finance] Vectorized rolling computation on xts series
In-Reply-To: <5e6a2e670910070105k7538d4b1m83187d46c7429805@mail.gmail.com>
References: <5e6a2e670910070105k7538d4b1m83187d46c7429805@mail.gmail.com>
Message-ID: <8cca69990910071857q5eead74dxc7d7932814d5801e@mail.gmail.com>

On Wed, Oct 7, 2009 at 3:05 AM, Mark Breman <breman.mark at gmail.com> wrote:
> Hi,
> I have a univariate xts timeseries (daily data) for which I need to apply a
> computation for each element. The computation for element x needs the last y
> months of the data from the timeseries. What's more, I need a "vectorized"
> computation because looping over all elements is too slow (it's a large
> timeseries).
>
> I think this is what is called a "rolling" or "running" computation in R.
>
> The computation I need to do for element x is:
> - calculate the percentage of the value x within the range of values from
> the last y months, i.e. determine the min() and max() of the last y months
> of data (including x), and determine what percentage of this range the value
> x is. For example: min(last 1 months) == 10, max(last 1 months) == 50, x ==
> 20 would yield: 25%
> - elements for which y months of previous data (including x itself) is not
> available should become NaN or some other "special value".
>
> An example
> So let's say I have a timeseries called "data":
>
>> data
> ? ? ? ? ? NonCommNet
> 1995-01-03 ? ? ?44580
> 1995-01-04 ? ? ?44580
> 1995-01-05 ? ? ?44580
> 1995-01-06 ? ? ?44580
> 1995-01-09 ? ? ?44580
> 1995-01-10 ? ? ?32835
> 1995-01-11 ? ? ?32835
> 1995-01-12 ? ? ?32835
> 1995-01-13 ? ? ?32835
> 1995-01-16 ? ? ?32835
> 1995-01-17 ? ? ?38385
> 1995-01-18 ? ? ?38385
> 1995-01-19 ? ? ?38385
> 1995-01-20 ? ? ?38385
> 1995-01-23 ? ? ?38385
> 1995-01-24 ? ? ?19150
> 1995-01-25 ? ? ?19150
> 1995-01-26 ? ? ?19150
> 1995-01-27 ? ? ?19150
> 1995-01-30 ? ? ?19150
> 1995-01-31 ? ? ?15245
> 1995-02-01 ? ? ?15245
> 1995-02-02 ? ? ?15245
> 1995-02-03 ? ? ?15245
> 1995-02-06 ? ? ?15245
> 1995-02-07 ? ? ?24110
> 1995-02-08 ? ? ?24110
> 1995-02-09 ? ? ?24110
> 1995-02-10 ? ? ?24110
> 1995-02-13 ? ? ?24110
> 1995-02-14 ? ? ?17615
> 1995-02-15 ? ? ?17615
> 1995-02-16 ? ? ?17615
> 1995-02-17 ? ? ?17615
> 1995-02-21 ? ? -23080
> 1995-02-22 ? ? -23080
> 1995-02-23 ? ? -23080
> 1995-02-24 ? ? -23080
> 1995-02-27 ? ? -23080
> 1995-02-28 ? ? -17445
>
> I tried the following "vectorized" solution ( example with y = 1 month):
>> ((data - min(last(data, "1 months"))) / (max(last(data, "1 months")) -
> min(last(data, "1 months")))) * 100
> ? ? ? ? ? NonCommNet
> 1995-01-03 ?143.37783
> 1995-01-04 ?143.37783
> 1995-01-05 ?143.37783
> 1995-01-06 ?143.37783
> 1995-01-09 ?143.37783
> 1995-01-10 ?118.48909
> 1995-01-11 ?118.48909
> 1995-01-12 ?118.48909
> 1995-01-13 ?118.48909
> 1995-01-16 ?118.48909
> 1995-01-17 ?130.25005
> 1995-01-18 ?130.25005
> 1995-01-19 ?130.25005
> 1995-01-20 ?130.25005
> 1995-01-23 ?130.25005
> 1995-01-24 ? 89.48930
> 1995-01-25 ? 89.48930
> 1995-01-26 ? 89.48930
> 1995-01-27 ? 89.48930
> 1995-01-30 ? 89.48930
> 1995-01-31 ? 81.21424
> 1995-02-01 ? 81.21424
> 1995-02-02 ? 81.21424
> 1995-02-03 ? 81.21424
> 1995-02-06 ? 81.21424
> 1995-02-07 ?100.00000
> 1995-02-08 ?100.00000
> 1995-02-09 ?100.00000
> 1995-02-10 ?100.00000
> 1995-02-13 ?100.00000
> 1995-02-14 ? 86.23649
> 1995-02-15 ? 86.23649
> 1995-02-16 ? 86.23649
> 1995-02-17 ? 86.23649
> 1995-02-21 ? ?0.00000
> 1995-02-22 ? ?0.00000
> 1995-02-23 ? ?0.00000
> 1995-02-24 ? ?0.00000
> 1995-02-27 ? ?0.00000
> 1995-02-28 ? 11.94109
>
> This does not satisfy my constraints because:
> 1) the first month of data should have become NaN or some other special
> value as there is not a full month of previous data available. I think this
> is caused by the last() function which simply returns the available data if
> the requested amount of data is greater than the available amount of data.
> 2) the results for the second month of data are wrong. For instance look at
> the result for 1995-02-06 which is 81.21424%. This should have been 0%. The
> last months min() is 15245 (from 1995-02-06), the max() is 44580 (from
> element 1995-01-06) so it should yield 0%.
>
> >From analyzing the results I get the impression that the last() function is
> not suited for a "vectorized" solution but I'm not really sure...
>
> I also had a look at runMin() and runMax() from the TTR package, but you
> can't specify a calendar range with these functions as you can with last()
> and first() from the xts package.
>
> Now my question is: am I doing something wrong here or do you know another
> vectorized function that satisfies my constraints?
>
> Kind regards,
>
> -Mark-
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>

Hi Mark,

I don't think there's currently a "vectorized" way to do what you
want.  That said, I've started working on rolling analysis functions
in xts, so this type functionality may make its way into the package
at some point.

I think the function below is close to what you want.  It would be
faster to subset the xts object by numeric values rather than strings,
but I'm not sure how to do that given your constraints...

pctRank <- function(x, n=1, freq='months') {
  x <- try.xts(x, error=stop("'x' must be coercible to xts"))
  if(NCOL(x) != 1) stop("'x' must be univariate")

  seqPos <- paste(n," ",freq,sep="")
  seqNeg <- paste("-",n," ",freq,sep="")

  naRange <- seq(index(first(x)),by=seqPos,length.out=2)
  naRangeStr <- paste(naRange[1],naRange[2]-1,sep='/')

  res <- sapply(1:NROW(x),
    function(i) {
      seq_i <- rev(seq(index(x[i]),by=seqNeg,length.out=2))
      rng_i <- range(x[paste(seq_i,collapse="/")])
      res_i <- (x[i]-rng_i[1])/(rng_i[2]-rng_i[1])
      return(res_i)
    })
  res <- xts(res, index(x))
  res[naRangeStr] <- rep(NA,NROW(res[naRangeStr]))
  return(res)
}

> (out <- pctRank(data))
                [,1]
1995-01-03        NA
1995-01-04        NA
1995-01-05        NA
1995-01-06        NA
1995-01-09        NA
1995-01-10        NA
1995-01-11        NA
1995-01-12        NA
1995-01-13        NA
1995-01-16        NA
1995-01-17        NA
1995-01-18        NA
1995-01-19        NA
1995-01-20        NA
1995-01-23        NA
1995-01-24        NA
1995-01-25        NA
1995-01-26        NA
1995-01-27        NA
1995-01-30        NA
1995-01-31        NA
1995-02-01        NA
1995-02-02        NA
1995-02-03 0.0000000
1995-02-06 0.0000000
1995-02-07 0.3021987
1995-02-08 0.3021987
1995-02-09 0.3021987
1995-02-10 0.3831029
1995-02-13 0.3831029
1995-02-14 0.1024201
1995-02-15 0.1024201
1995-02-16 0.1024201
1995-02-17 0.1024201
1995-02-21 0.0000000
1995-02-22 0.0000000
1995-02-23 0.0000000
1995-02-24 0.0000000
1995-02-27 0.0000000
1995-02-28 0.1194109

HTH,
Josh
--
http://www.fosstrading.com


From erbp at zhaw.ch  Thu Oct  8 08:32:21 2009
From: erbp at zhaw.ch (Erb Philipp (erbp))
Date: Thu, 8 Oct 2009 08:32:21 +0200
Subject: [R-SIG-Finance] Evaluating/comparing dynamic linear model
In-Reply-To: <ad1ead5f0910071755m2005d30flc12b973d967421d8@mail.gmail.com>
References: <ad1ead5f0910071755m2005d30flc12b973d967421d8@mail.gmail.com>
Message-ID: <E3C4AB44AC837145A80A1795288123A806C3B2@scampi.zhaw.ch>

What kind of filter are you using? Since your models are expressed in state space form I suggest that you fit your models by maximizing the log likelihood function of the Kalman filter output (see e.g. FKF-package). Using the obtained log likelihood values you might perform a likelihood ratio test to test the hypothesis whether model 1 explains yt "better" than model 2.

HTH, Phil


-----Urspr?ngliche Nachricht-----
Von: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] Im Auftrag von R_help Help
Gesendet: Donnerstag, 8. Oktober 2009 02:55
An: r-sig-finance at stat.math.ethz.ch; r-help at r-project.org
Betreff: [R-SIG-Finance] Evaluating/comparing dynamic linear model

Hi,

I have two DLM model specifications (x[t] and y[t] are univariate):

MODEL1:
y[t] = b[t]x[t]+e[t], e[t] ~ N(0,v1^2)
b[t] = b[t-1]+eta[t], eta[t] ~ N(0,w1^2)

MODEL2:
y[t] = a[t]+e[t], e[t] ~ N(0,v2^2)
a[t] = a[t-1]+eta[t], eta[t] ~ N(0,w2^2)

I run the filter through data recursively to obtain state variables
for each model. However, how do I know if b[t]x[t] in MODEL1 is
different from MODEL2? In other words, how do I know if x[t] makes a
difference in explaining dynamic of y[t]?

Another question is that how do I compare MODEL1 and MODEL2? From
model specification point of view, how can one say that MODEL1 is
better than MODEL2? Any suggestion/reference would be greatly
appreciated. Thank you.

ac

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From breman.mark at gmail.com  Thu Oct  8 11:22:49 2009
From: breman.mark at gmail.com (Mark Breman)
Date: Thu, 8 Oct 2009 11:22:49 +0200
Subject: [R-SIG-Finance] Vectorized rolling computation on xts series
In-Reply-To: <8cca69990910071857q5eead74dxc7d7932814d5801e@mail.gmail.com>
References: <5e6a2e670910070105k7538d4b1m83187d46c7429805@mail.gmail.com>
	<8cca69990910071857q5eead74dxc7d7932814d5801e@mail.gmail.com>
Message-ID: <5e6a2e670910080222v422ed099ha80f6ce6ddbf3a01@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091008/7e430dd7/attachment.pl>

From kagba2006 at yahoo.com  Fri Oct  9 18:57:12 2009
From: kagba2006 at yahoo.com (FMH)
Date: Fri, 9 Oct 2009 09:57:12 -0700 (PDT)
Subject: [R-SIG-Finance] How to do multiple time series modelling in R?
Message-ID: <352655.39608.qm@web38301.mail.mud.yahoo.com>

Dear All,

I am planning to?use multiple time series?modelling on data series from several?groups.

Is there any package that can be used to do this operation, and i really appreciate for any suggestion/advice on this matter.

Thank you?





From binabina at bellsouth.net  Fri Oct  9 19:43:08 2009
From: binabina at bellsouth.net (zubin)
Date: Fri, 09 Oct 2009 13:43:08 -0400
Subject: [R-SIG-Finance] recommended zoo merge for multiple objects
Message-ID: <4ACF762C.40206@bellsouth.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091009/ed04de80/attachment.pl>

From brian at braverock.com  Fri Oct  9 19:46:05 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 09 Oct 2009 12:46:05 -0500
Subject: [R-SIG-Finance] recommended zoo merge for multiple objects
In-Reply-To: <4ACF762C.40206@bellsouth.net>
References: <4ACF762C.40206@bellsouth.net>
Message-ID: <4ACF76DD.7040000@braverock.com>

zubin wrote:
> Hello, i have about 20 objects, each object is a zoo object, a ticker 
> symbol. 
>
> I am using merge.zoo to merge 2 objects successfully and using return 
> class to create a data frame.  However it looks like merge.zoo can only 
> handle 2 objects.  What's the recommended approach to merge multiple zoo 
> objects by the time index into a data frame?
>
> example of 2 objects:
>
> df <- merge.zoo(XLF,SPY,all=TRUE, retclass="data.frame")
> where XLF and SPY are zoo objects.
>
>   
Use cbind with xts.  xts extends zoo, and should be preferred for 
financial time series.

Regards,

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From brian at braverock.com  Fri Oct  9 19:48:00 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 09 Oct 2009 12:48:00 -0500
Subject: [R-SIG-Finance] How to do multiple time series modelling in R?
In-Reply-To: <352655.39608.qm@web38301.mail.mud.yahoo.com>
References: <352655.39608.qm@web38301.mail.mud.yahoo.com>
Message-ID: <4ACF7750.8070005@braverock.com>

FMH wrote:
> Dear All,
>
> I am planning to use multiple time series modelling on data series from several groups.
>
> Is there any package that can be used to do this operation, and i really appreciate for any suggestion/advice on this matter.
>   
Your question is so general it is hard to figure out what you want to do.

You may want to start with Brian Everitt's book "An R and S-Plus 
Companion to Multivariate Analysis" and then maybe move on to Ruppert or 
Shumway and Stoffer.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From binabina at bellsouth.net  Fri Oct  9 19:49:02 2009
From: binabina at bellsouth.net (zubin)
Date: Fri, 09 Oct 2009 13:49:02 -0400
Subject: [R-SIG-Finance] recommended zoo merge for multiple objects
In-Reply-To: <4ACF76DD.7040000@braverock.com>
References: <4ACF762C.40206@bellsouth.net> <4ACF76DD.7040000@braverock.com>
Message-ID: <4ACF778E.9020908@bellsouth.net>

Thx!

One question:  Will cbind use the time index?  I want to make sure 
everything lines up, as i have lags in the data.

Brian G. Peterson wrote:
> zubin wrote:
>> Hello, i have about 20 objects, each object is a zoo object, a ticker 
>> symbol.
>> I am using merge.zoo to merge 2 objects successfully and using return 
>> class to create a data frame.  However it looks like merge.zoo can 
>> only handle 2 objects.  What's the recommended approach to merge 
>> multiple zoo objects by the time index into a data frame?
>>
>> example of 2 objects:
>>
>> df <- merge.zoo(XLF,SPY,all=TRUE, retclass="data.frame")
>> where XLF and SPY are zoo objects.
>>
>>   
> Use cbind with xts.  xts extends zoo, and should be preferred for 
> financial time series.
>
> Regards,
>
>  - Brian
>


From josh.m.ulrich at gmail.com  Fri Oct  9 19:49:35 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 9 Oct 2009 12:49:35 -0500
Subject: [R-SIG-Finance] recommended zoo merge for multiple objects
In-Reply-To: <4ACF762C.40206@bellsouth.net>
References: <4ACF762C.40206@bellsouth.net>
Message-ID: <8cca69990910091049k2a903c94w48d632bf54bae18c@mail.gmail.com>

On Fri, Oct 9, 2009 at 12:43 PM, zubin <binabina at bellsouth.net> wrote:
> Hello, i have about 20 objects, each object is a zoo object, a ticker
> symbol.
>
> I am using merge.zoo to merge 2 objects successfully and using return
> class to create a data frame. ?However it looks like merge.zoo can only
> handle 2 objects. ?What's the recommended approach to merge multiple zoo
> objects by the time index into a data frame?
>
How did you conclude merge.zoo can only handle 2 objects?  Read ?merge.zoo...

Arguments:

     ...: two or more objects, usually of class '"zoo"'.

Best,
Josh
--
http://www.fosstrading.com


> example of 2 objects:
>
> df <- merge.zoo(XLF,SPY,all=TRUE, retclass="data.frame")
> where XLF and SPY are zoo objects.
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From brian at braverock.com  Fri Oct  9 19:55:58 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 09 Oct 2009 12:55:58 -0500
Subject: [R-SIG-Finance] recommended zoo merge for multiple objects
In-Reply-To: <4ACF778E.9020908@bellsouth.net>
References: <4ACF762C.40206@bellsouth.net> <4ACF76DD.7040000@braverock.com>
	<4ACF778E.9020908@bellsouth.net>
Message-ID: <4ACF792E.6080508@braverock.com>

zubin wrote:
> Thx!
>
> One question:  Will cbind use the time index?  I want to make sure 
> everything lines up, as i have lags in the data.
>

Yes, xts will use the time index for cbind, rbind, merge, etc.  I 
regularly use xts to line up irregular high frequency data.  xts has 
date and time-based subsetting which is very useful for financial time 
series.

As Josh has already pointed out, merge.zoo will take more than two 
objects to merge as well, but in my opinion you should be using xts 
anyway for most financial time series data.  I "fall back" to zoo when I 
need to make things that look more like data frames, or sometimes for 
loading data into R from poorly organized files.

Regards,

    - Brian
> Brian G. Peterson wrote:
>> zubin wrote:
>>> Hello, i have about 20 objects, each object is a zoo object, a 
>>> ticker symbol.
>>> I am using merge.zoo to merge 2 objects successfully and using 
>>> return class to create a data frame.  However it looks like 
>>> merge.zoo can only handle 2 objects.  What's the recommended 
>>> approach to merge multiple zoo objects by the time index into a data 
>>> frame?
>>>
>>> example of 2 objects:
>>>
>>> df <- merge.zoo(XLF,SPY,all=TRUE, retclass="data.frame")
>>> where XLF and SPY are zoo objects.
>>>
>>>   
>> Use cbind with xts.  xts extends zoo, and should be preferred for 
>> financial time series.
>>
>> Regards,
>>
>>  - Brian
>>


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From ggrothendieck at gmail.com  Fri Oct  9 20:18:25 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 Oct 2009 14:18:25 -0400
Subject: [R-SIG-Finance] recommended zoo merge for multiple objects
In-Reply-To: <4ACF762C.40206@bellsouth.net>
References: <4ACF762C.40206@bellsouth.net>
Message-ID: <971536df0910091118x25c64f68tbac9ea94117b0e99@mail.gmail.com>

merge.zoo can handle any number of zoo objects.  There is *no*
limitation to two objects. There are examples in the examples section
at the end of ?merge.zoo

On Fri, Oct 9, 2009 at 1:43 PM, zubin <binabina at bellsouth.net> wrote:
> Hello, i have about 20 objects, each object is a zoo object, a ticker
> symbol.
>
> I am using merge.zoo to merge 2 objects successfully and using return
> class to create a data frame. ?However it looks like merge.zoo can only
> handle 2 objects. ?What's the recommended approach to merge multiple zoo
> objects by the time index into a data frame?
>
> example of 2 objects:
>
> df <- merge.zoo(XLF,SPY,all=TRUE, retclass="data.frame")
> where XLF and SPY are zoo objects.
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From jeff.a.ryan at gmail.com  Fri Oct  9 21:54:31 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 9 Oct 2009 14:54:31 -0500
Subject: [R-SIG-Finance] How to do multiple time series modelling in R?
In-Reply-To: <4ACF7750.8070005@braverock.com>
References: <352655.39608.qm@web38301.mail.mud.yahoo.com>
	<4ACF7750.8070005@braverock.com>
Message-ID: <e8e755250910091254p399ecdf6j6523a375f1f6b40a@mail.gmail.com>

Take a look at the task views:

http://cran.r-project.org/web/views/TimeSeries.html
http://cran.r-project.org/web/views/Econometrics.html
http://cran.r-project.org/web/views/Finance.html

HTH
Jeff


On Fri, Oct 9, 2009 at 12:48 PM, Brian G. Peterson <brian at braverock.com> wrote:
> FMH wrote:
>>
>> Dear All,
>>
>> I am planning to use multiple time series modelling on data series from
>> several groups.
>>
>> Is there any package that can be used to do this operation, and i really
>> appreciate for any suggestion/advice on this matter.
>>
>
> Your question is so general it is hard to figure out what you want to do.
>
> You may want to start with Brian Everitt's book "An R and S-Plus Companion
> to Multivariate Analysis" and then maybe move on to Ruppert or Shumway and
> Stoffer.
>
> Regards,
>
> ?- Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From markleeds at verizon.net  Fri Oct  9 22:24:31 2009
From: markleeds at verizon.net (markleeds at verizon.net)
Date: Fri, 09 Oct 2009 15:24:31 -0500 (CDT)
Subject: [R-SIG-Finance] How to do multiple time series modelling in R?
Message-ID: <178750888.160410.1255119871611.JavaMail.root@vms184.mailsrvcs.net>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091009/42dff290/attachment.html>

From cevans at chyden.net  Fri Oct  9 23:17:25 2009
From: cevans at chyden.net (Charles Evans)
Date: Fri, 9 Oct 2009 17:17:25 -0400
Subject: [R-SIG-Finance] How to do multiple time series modelling in R?
In-Reply-To: <178750888.160410.1255119871611.JavaMail.root@vms184.mailsrvcs.net>
References: <178750888.160410.1255119871611.JavaMail.root@vms184.mailsrvcs.net>
Message-ID: <17998DB6-4F68-4974-8DFF-B647DB4E8B51@chyden.net>


On 09 Oct 2009, at 16:24, markleeds at verizon.net wrote:

> some books specifically for multiple time series that weren't  
> mentioned I don't think:
>
> Eric Zivot's : S+Finmetrics
> Enders: ( forget title ).

_Applied Econometric Time Series_

You can get an international edition from a seller at AbeBooks.com.

> Lutkepohl:  An Introduction to Multiple Time Series Analysis
>
> The first two are more introductory compared to Lutkepohl. His book  
> is like Hamilton but totally focuses on VARS.


From markknecht at gmail.com  Sun Oct 11 00:29:09 2009
From: markknecht at gmail.com (Mark Knecht)
Date: Sat, 10 Oct 2009 15:29:09 -0700
Subject: [R-SIG-Finance] QuantMod trading models docs?
Message-ID: <5bdc1c8b0910101529r7af48ad5id93fcb8fb2a7829b@mail.gmail.com>

Hi,
   I was wondering if there is any documentation on QuantMod trading
models? It looks like this is a goal of the project but I don't see
any documentation. Does it work? I have a number of automated systems
I'm trading in TradeStation EasyLanguage and I'm interested in
possibly converting a few of these to R for study reasons.

Thanks,
Mark


From binabina at bellsouth.net  Sun Oct 11 01:56:14 2009
From: binabina at bellsouth.net (zubin)
Date: Sat, 10 Oct 2009 19:56:14 -0400
Subject: [R-SIG-Finance] xts: xts/xts not an xts? and subsetting on hours
	across all dates
Message-ID: <4AD11F1E.8050506@bellsouth.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091010/06baffc3/attachment.pl>

From ggrothendieck at gmail.com  Sun Oct 11 02:19:05 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 10 Oct 2009 20:19:05 -0400
Subject: [R-SIG-Finance] xts: xts/xts not an xts? and subsetting on
	hours across all dates
In-Reply-To: <4AD11F1E.8050506@bellsouth.net>
References: <4AD11F1E.8050506@bellsouth.net>
Message-ID: <971536df0910101719j1e2287abt632ebc93f5425fc6@mail.gmail.com>

1. Its caused by ifelse, not by the division.  Read the Value section
of ?ifelse to better understand how ifelse works.  Its not what your
seem to expect.

2. Modulo time zone problems:

hhmm <- format(time(x), "%H:%M")
x[ hhmm > "09:00" & hhmm < "16:30" ]

Use dput next time to display your data (rather than str) so it can be
reproduced.



On Sat, Oct 10, 2009 at 7:56 PM, zubin <binabina at bellsouth.net> wrote:
> Hello, 2 xts/zoo questions:
>
> 1) experiencing a behavior i can't explain with zoo or xts objects and
> can't seem to rectify
>
> Dividing two zoo or xts objects and I don't get the result as a zoo or
> xts object, i get a number vector with no time index, ?pulling my hair
> on this, any recommendations?
>
> ?> str(XJZLN.X)
> 'zoo' series from 2009-10-06 09:30:07 to 2009-10-06 15:59:54
> ?Data: num [1:2813] 0 0 0 0 0 0 0 0 0 0 ...
> ?Index: ?POSIXct[1:2813], format: "2009-10-06 09:30:07" "2009-10-06
> 09:30:15" ...
>
> ?> str(XJZXN.X)
> 'zoo' series from 2009-10-06 09:30:07 to 2009-10-06 15:59:54
> ?Data: num [1:2813] 0 0 0 0 0 0 0 0 0 0 ...
> ?Index: ?POSIXct[1:2813], format: "2009-10-06 09:30:07" "2009-10-06
> 09:30:15" ...
>
> # fixing the division by zero in the dataset, inserting a constant
> ?> dec14callput = ifelse(is.nan(XJZLN.X / XJZXN.X),2.23,XJZLN.X / XJZXN.X)
>
> #however the resulting object is not zoo anymore?
> ?> str(dec14callput)
> ?num [1:2813] 2.23 2.23 2.23 2.23 2.23 2.23 2.23 2.23 2.23 2.23 ...
>
> ok lets try coercing to a zoo, but now we lose the index?
>
> ?> dec14callput = zoo(ifelse(is.nan(XJZLN.X / XJZXN.X),2.23,XJZLN.X /
> XJZXN.X))
>
> 'zoo' series from 1 to 2813
> ?Data: num [1:2813] 2.23 2.23 2.23 2.23 2.23 2.23 2.23 2.23 2.23 2.23 ...
> ?Index: ?int [1:2813] 1 2 3 4 5 6 7 8 9 10 ...
>
>
> 2) How does one subset only hours from an XTS (or zoo) object across
> many days. ?I have some ticker data from 10/1/2009 thru 10/8/2009 for
> example. ?It is data that contains pre /post session data as well as the
> active trading session. ?I want to pull from 9:30 to 4:00 only across
> ALL the dates, in an elegant way.
>
> I have tried window as well as the :: operator for XTS, no luck.
>
> Something like this i was trying for a ZOO object:
>
> tmpfile <- window(XJXLN.X, start = as.POSIXct(("XXXX-XX-XX
> 09:30:00"),end = as.POSIXct("XXXX-XX-XX 16:00:00")))
>
> Any type of wildcard for the dates, so given any date, but only pull
> rows that are between 9:30 and 16:00.
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From windspeedo99 at gmail.com  Sun Oct 11 11:15:52 2009
From: windspeedo99 at gmail.com (Wind)
Date: Sun, 11 Oct 2009 17:15:52 +0800
Subject: [R-SIG-Finance] how to handle both the symbol names and prices in
	one xts
Message-ID: <d718c8210910110215k5462fb97q717d4b7dc84d7ab3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091011/836980d2/attachment.pl>

From jeff.a.ryan at gmail.com  Sun Oct 11 14:33:37 2009
From: jeff.a.ryan at gmail.com (J Ryan)
Date: Sun, 11 Oct 2009 07:33:37 -0500
Subject: [R-SIG-Finance] how to handle both the symbol names and prices
	in one xts
In-Reply-To: <d718c8210910110215k5462fb97q717d4b7dc84d7ab3@mail.gmail.com>
References: <d718c8210910110215k5462fb97q717d4b7dc84d7ab3@mail.gmail.com>
Message-ID: <CD5ECBC4-54A6-480E-9064-CE8634459501@gmail.com>

Wind,

This isn't possible, as an xts object is fundamentally a matrix with  
an attribute ("index") for keeping track of time, and a matrix is just  
a contiuous block of memory (array) with a dimension.

Building two objects using a common index would be as close as you can  
get. Long term there has been some discussion and work done on having  
something akin to a list of xts objects, but that isn't implemented yet.

HTH
Jeff

Jeffrey A. Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com

On Oct 11, 2009, at 4:15 AM, Wind <windspeedo99 at gmail.com> wrote:

> I wonder how to convert a dataframe with character columns and prices
> columns into xts,  while maintaing the character class and numeric  
> class of
> each column.
>
> Regards,
> wind
>
>>
>> dput(d1)
> list(c("sym1", "sym1", "sym1", "sym2", "sym2", "sym2"), structure(c 
> (14426L,
> 14427L, 14428L, 14426L, 14427L, 14428L), class = "Date"), c(23.06,
> 24.21, 24.3, 9.57, 9.65, 9.57), c(24.19, 24.99, 24.96, 9.67,
> 9.75, 9.8), c(22.92, 24.15, 24.2, 9.54, 9.56, 9.57), c(24.14,
> 24.48, 24.93, 9.62, 9.65, 9.76), c(6787, 7974, 6116, 1370, 1527,
> 1414))
>> str(d1)
> List of 7
> $ : chr [1:6] "sym1" "sym1" "sym1" "sym2" ...
> $ :Class 'Date'  int [1:6] 14426 14427 14428 14426 14427 14428
> $ : num [1:6] 23.06 24.21 24.3 9.57 9.65 ...
> $ : num [1:6] 24.19 24.99 24.96 9.67 9.75 ...
> $ : num [1:6] 22.92 24.15 24.2 9.54 9.56 ...
> $ : num [1:6] 24.14 24.48 24.93 9.62 9.65 ...
> $ : num [1:6] 6787 7974 6116 1370 1527 ...
>> d2 <- do.call(cbind,d1[c(3,4,5,6,7)])
>> str(d2)
> num [1:6, 1:5] 23.06 24.21 24.3 9.57 9.65 ...
>> d3 <- data.frame(symbol=d1[[1]], d2,stringsAsFactors=FALSE)
>> str(d3)
> 'data.frame': 6 obs. of  6 variables:
> $ symbol: chr  "sym1" "sym1" "sym1" "sym2" ...
> $ X1    : num  23.06 24.21 24.3 9.57 9.65 ...
> $ X2    : num  24.19 24.99 24.96 9.67 9.75 ...
> $ X3    : num  22.92 24.15 24.2 9.54 9.56 ...
> $ X4    : num  24.14 24.48 24.93 9.62 9.65 ...
> $ X5    : num  6787 7974 6116 1370 1527 ...
>> d4 <- as.xts(d3,order.by=d1[[2]],unique=FALSE)
>> str(d4)
> An 'xts' object from 2009-07-01 to 2009-07-03 containing:
>  Data: chr [1:6, 1:6] "sym1" "sym2" "sym1" "sym2" "sym1" "sym2" ...
> - attr(*, "dimnames")=List of 2
>  ..$ : NULL
>  ..$ : chr [1:6] "symbol" "X1" "X2" "X3" ...
>  Indexed by objects of class: [Date] TZ: CST-8
>  Original class: 'data.frame'
>  xts Attributes:
> NULL
>>
>
>
>> sessionInfo()
> R version 2.9.2 (2009-08-24)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Chinese (Simplified)_People's Republic of
> China.936;LC_CTYPE=Chinese (Simplified)_People's Republic of
> China.936;LC_MONETARY=Chinese (Simplified)_People's Republic of
> China.936;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] quantmod_0.3-11 TTR_0.20-1      Defaults_1.1-1  xts_0.6-7
> [5] zoo_1.5-8
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.2      lattice_0.17-25
>>
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From daniel.cegielka at gmail.com  Sun Oct 11 16:20:16 2009
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Sun, 11 Oct 2009 16:20:16 +0200
Subject: [R-SIG-Finance] QuantMod trading models docs?
In-Reply-To: <5bdc1c8b0910110711o1ecbbe93uaef321d7f6c07c6d@mail.gmail.com>
References: <5bdc1c8b0910101529r7af48ad5id93fcb8fb2a7829b@mail.gmail.com>
	<5ddf2c610910110616u1c84d7dfr6894ae049abba73a@mail.gmail.com>
	<5bdc1c8b0910110643q289bd07bjba68f7454cb4ef8@mail.gmail.com>
	<5ddf2c610910110658p7f2e0ae7u33dc117c2607c942@mail.gmail.com>
	<5bdc1c8b0910110711o1ecbbe93uaef321d7f6c07c6d@mail.gmail.com>
Message-ID: <5ddf2c610910110720p46f89903ub9ae064085326a3d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091011/c040b0d4/attachment.pl>

From markknecht at gmail.com  Sun Oct 11 16:42:03 2009
From: markknecht at gmail.com (Mark Knecht)
Date: Sun, 11 Oct 2009 07:42:03 -0700
Subject: [R-SIG-Finance] QuantMod trading models docs?
In-Reply-To: <5ddf2c610910110720p46f89903ub9ae064085326a3d@mail.gmail.com>
References: <5bdc1c8b0910101529r7af48ad5id93fcb8fb2a7829b@mail.gmail.com>
	<5ddf2c610910110616u1c84d7dfr6894ae049abba73a@mail.gmail.com>
	<5bdc1c8b0910110643q289bd07bjba68f7454cb4ef8@mail.gmail.com>
	<5ddf2c610910110658p7f2e0ae7u33dc117c2607c942@mail.gmail.com>
	<5bdc1c8b0910110711o1ecbbe93uaef321d7f6c07c6d@mail.gmail.com>
	<5ddf2c610910110720p46f89903ub9ae064085326a3d@mail.gmail.com>
Message-ID: <5bdc1c8b0910110742r1fe39ac1s55941b7a288f5785@mail.gmail.com>

Yes, that's the command on the blotter page, but it seems that the
files have gone missing or something...

> install.packages("blotter",repos="http://R-Forge.R-project.org")
Warning: unable to access index for repository
http://R-Forge.R-project.org/bin/windows/contrib/2.9
Warning message:
In getDependencies(pkgs, dependencies, available, lib) :
  package ?blotter? is not available
>

As I said earlier, if I go to the download link and try to download
the Windows zip version it says there's nothing there. Same as this
command is saying.

I'll try again later. Maybe it's just having problems right now.

Thanks,
Mark

2009/10/11 Daniel Cegie?ka <daniel.cegielka at gmail.com>:
> install.packages("blotter",repos="http://R-Forge.R-project.org")
>
> regards
> daniel
>


From daniel.cegielka at gmail.com  Sun Oct 11 17:02:39 2009
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Sun, 11 Oct 2009 17:02:39 +0200
Subject: [R-SIG-Finance] QuantMod trading models docs?
In-Reply-To: <5bdc1c8b0910110742r1fe39ac1s55941b7a288f5785@mail.gmail.com>
References: <5bdc1c8b0910101529r7af48ad5id93fcb8fb2a7829b@mail.gmail.com>
	<5ddf2c610910110616u1c84d7dfr6894ae049abba73a@mail.gmail.com>
	<5bdc1c8b0910110643q289bd07bjba68f7454cb4ef8@mail.gmail.com>
	<5ddf2c610910110658p7f2e0ae7u33dc117c2607c942@mail.gmail.com>
	<5bdc1c8b0910110711o1ecbbe93uaef321d7f6c07c6d@mail.gmail.com>
	<5ddf2c610910110720p46f89903ub9ae064085326a3d@mail.gmail.com>
	<5bdc1c8b0910110742r1fe39ac1s55941b7a288f5785@mail.gmail.com>
Message-ID: <5ddf2c610910110802g4e47de87tbd2bfe8c4420a7ae@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091011/5ae7ed3c/attachment.pl>

From jeff.a.ryan at gmail.com  Sun Oct 11 21:09:46 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sun, 11 Oct 2009 14:09:46 -0500
Subject: [R-SIG-Finance] QuantMod trading models docs?
In-Reply-To: <5bdc1c8b0910101529r7af48ad5id93fcb8fb2a7829b@mail.gmail.com>
References: <5bdc1c8b0910101529r7af48ad5id93fcb8fb2a7829b@mail.gmail.com>
Message-ID: <e8e755250910111209n7c760197j1409a9f471ff05bb@mail.gmail.com>

Hi Mark,

The following thread is a good start in terms of why the functionality
of specify/build/tradeModel in quantmod isn't quite capable of what
you want:

http://www.nabble.com/Backtesting-trade-systems-td24517282.html#a24517282

As Daniel points out, the blotter package makes some great strides in
the area, though from a more restrictive perspective than
'backtesting'...

Love to hear successes and failures, as well as any code you end up
with and would like to share with the list.

Best,
Jeff

On Sat, Oct 10, 2009 at 5:29 PM, Mark Knecht <markknecht at gmail.com> wrote:
> Hi,
> ? I was wondering if there is any documentation on QuantMod trading
> models? It looks like this is a goal of the project but I don't see
> any documentation. Does it work? I have a number of automated systems
> I'm trading in TradeStation EasyLanguage and I'm interested in
> possibly converting a few of these to R for study reasons.
>
> Thanks,
> Mark
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From aleks.clark at gmail.com  Mon Oct 12 00:47:22 2009
From: aleks.clark at gmail.com (Aleks Clark)
Date: Sun, 11 Oct 2009 17:47:22 -0500
Subject: [R-SIG-Finance] Evaluating equity curves
Message-ID: <5aebc8960910111547kf94e314q6530b607124bad7e@mail.gmail.com>

As part of a project I'm working on that uses genetic algorithms to
optimize trading parameters, I find myself seeking a way to evaluate
the equity curve that results from a given set of trading rules. It
seems to be an obvious area of research, so I was wondering what's
available in R-land or just in the world of finance in general. I've
poked around with splines as a way to express how 'nice' an equity
curve is (steady upward rise as opposed to a "jagged" line), but I
feel that there are probably better ways to do things...


Thanks,


-- 
Aleks Clark


From rvince99 at earthlink.net  Mon Oct 12 01:19:03 2009
From: rvince99 at earthlink.net (R. Vince)
Date: Sun, 11 Oct 2009 19:19:03 -0400
Subject: [R-SIG-Finance] Evaluating equity curves
References: <5aebc8960910111547kf94e314q6530b607124bad7e@mail.gmail.com>
Message-ID: <D9E635B3CF6546E6B8EF10825387110E@XP1>

Do NOT bother with this, Aleks, until you first read about the First and 
particularly Second Arc Sine Laws and how they might pertain to equity 
curves. (To avoid fitting splinies or anything else to unicorn 
costumes) -Ralph Vince
----- Original Message ----- 
From: "Aleks Clark" <aleks.clark at gmail.com>
To: <r-sig-finance at stat.math.ethz.ch>
Sent: Sunday, October 11, 2009 6:47 PM
Subject: [R-SIG-Finance] Evaluating equity curves


> As part of a project I'm working on that uses genetic algorithms to
> optimize trading parameters, I find myself seeking a way to evaluate
> the equity curve that results from a given set of trading rules. It
> seems to be an obvious area of research, so I was wondering what's
> available in R-land or just in the world of finance in general. I've
> poked around with splines as a way to express how 'nice' an equity
> curve is (steady upward rise as opposed to a "jagged" line), but I
> feel that there are probably better ways to do things...
>
>
> Thanks,
>
>
> -- 
> Aleks Clark
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From brian at braverock.com  Mon Oct 12 02:46:57 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 11 Oct 2009 19:46:57 -0500
Subject: [R-SIG-Finance] Evaluating equity curves
In-Reply-To: <5aebc8960910111547kf94e314q6530b607124bad7e@mail.gmail.com>
References: <5aebc8960910111547kf94e314q6530b607124bad7e@mail.gmail.com>
Message-ID: <4AD27C81.1010901@braverock.com>

Aleks Clark wrote:
> As part of a project I'm working on that uses genetic algorithms to
> optimize trading parameters, I find myself seeking a way to evaluate
> the equity curve that results from a given set of trading rules. It
> seems to be an obvious area of research, so I was wondering what's
> available in R-land or just in the world of finance in general. I've
> poked around with splines as a way to express how 'nice' an equity
> curve is (steady upward rise as opposed to a "jagged" line), but I
> feel that there are probably better ways to do things...

Having worked both in quantitative trading and in more traditional asset 
management roles, I've never quite understood the artificial distinction 
between "equity curves" and any other kind of returns.  In my experience, all 
the usual performance and risk analysis tools (amply provided for in R) as well 
as attribution (e.g. Bacon, much of which is implemented in fPortfolio) are 
equally applicable to trading strategies as they are to more traditional 
investment.  Also see Pat Burns' paper on evaluatinfg trading strategies for 
additional ideas.

Regards,

   - Brian


From rvince99 at earthlink.net  Mon Oct 12 03:05:36 2009
From: rvince99 at earthlink.net (R. Vince)
Date: Sun, 11 Oct 2009 21:05:36 -0400
Subject: [R-SIG-Finance] Evaluating equity curves
References: <5aebc8960910111547kf94e314q6530b607124bad7e@mail.gmail.com>
	<4AD27C81.1010901@braverock.com>
Message-ID: <6CAF74EF3EAA421593E58A9B8230E45D@XP1>

Brian,

Isn't any stream of cumulative returns, de facto, an equity curve? Or am I 
misunderstanding this? Thanks, Ralph Vince

----- Original Message ----- 
From: "Brian G. Peterson" <brian at braverock.com>
To: "Aleks Clark" <aleks.clark at gmail.com>
Cc: <r-sig-finance at stat.math.ethz.ch>
Sent: Sunday, October 11, 2009 8:46 PM
Subject: Re: [R-SIG-Finance] Evaluating equity curves


> Aleks Clark wrote:
>> As part of a project I'm working on that uses genetic algorithms to
>> optimize trading parameters, I find myself seeking a way to evaluate
>> the equity curve that results from a given set of trading rules. It
>> seems to be an obvious area of research, so I was wondering what's
>> available in R-land or just in the world of finance in general. I've
>> poked around with splines as a way to express how 'nice' an equity
>> curve is (steady upward rise as opposed to a "jagged" line), but I
>> feel that there are probably better ways to do things...
>
> Having worked both in quantitative trading and in more traditional asset 
> management roles, I've never quite understood the artificial distinction 
> between "equity curves" and any other kind of returns.  In my experience, 
> all the usual performance and risk analysis tools (amply provided for in 
> R) as well as attribution (e.g. Bacon, much of which is implemented in 
> fPortfolio) are equally applicable to trading strategies as they are to 
> more traditional investment.  Also see Pat Burns' paper on evaluatinfg 
> trading strategies for additional ideas.
>
> Regards,
>
>   - Brian
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From brian at braverock.com  Mon Oct 12 03:15:21 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 11 Oct 2009 20:15:21 -0500
Subject: [R-SIG-Finance] Evaluating equity curves
In-Reply-To: <6CAF74EF3EAA421593E58A9B8230E45D@XP1>
References: <5aebc8960910111547kf94e314q6530b607124bad7e@mail.gmail.com>
	<4AD27C81.1010901@braverock.com>
	<6CAF74EF3EAA421593E58A9B8230E45D@XP1>
Message-ID: <4AD28329.3050901@braverock.com>

R. Vince wrote:
> Brian,
> 
> Isn't any stream of cumulative returns, de facto, an equity curve? Or am 
> I misunderstanding this? Thanks, Ralph Vince

You're absolutely correct.  This is why I described it as an artificial 
distinction.  Many traders seem to believe that there is something magical 
about an "equity curve" when it is really just a way of describing cumulative 
returns. Thus my point that there is indeed nothing magical, and all the usual 
suspects on return, risk, and attribution analysis may be readily applied to 
analysis of trading strategies.

Regards,

     - Brian

> ----- Original Message ----- 
 > From: "Brian G. Peterson" <brian at braverock.com>
>> Aleks Clark wrote:>>> As part of a project I'm working on that uses genetic algorithms to
>>> optimize trading parameters, I find myself seeking a way to evaluate
>>> the equity curve that results from a given set of trading rules. It
>>> seems to be an obvious area of research, so I was wondering what's
>>> available in R-land or just in the world of finance in general. I've
>>> poked around with splines as a way to express how 'nice' an equity
>>> curve is (steady upward rise as opposed to a "jagged" line), but I
>>> feel that there are probably better ways to do things...
>>
>> Having worked both in quantitative trading and in more traditional 
>> asset management roles, I've never quite understood the artificial 
>> distinction between "equity curves" and any other kind of returns.  In 
>> my experience, all the usual performance and risk analysis tools 
>> (amply provided for in R) as well as attribution (e.g. Bacon, much of 
>> which is implemented in fPortfolio) are equally applicable to trading 
>> strategies as they are to more traditional investment.  Also see Pat 
>> Burns' paper on evaluatinfg trading strategies for additional ideas.
>>
>> Regards,
>>
>>   - Brian
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first. 


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From robert at sanctumfi.com  Mon Oct 12 13:45:35 2009
From: robert at sanctumfi.com (Robert Sams)
Date: Mon, 12 Oct 2009 12:45:35 +0100
Subject: [R-SIG-Finance] Evaluating equity curves
References: <5aebc8960910111547kf94e314q6530b607124bad7e@mail.gmail.com><4AD27C81.1010901@braverock.com>
	<SANCTUMFISERVERICNP0000422c@sanctumfi.com>
Message-ID: <SANCTUMFISERVERA3Ix00004307@sanctumfi.com>

Quite right, Ralph. More precisely: any series of cumulative returns
plotted against time on a 2d chart is, *by definition*, an equity curve.


Aleks, I'm not sure you're after. To me, the return series of a trading
strategy isn't 'evaluated' per se, it's evaluated with respect to some
specific questions or conjectures you have regarding it. Articulating
this is logically prior to choosing the appropriate mathematical
technique.

If you can be more specific, we might be able to point you in the right
direction.

Robert

> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch 
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of R. Vince
> Sent: 12 October 2009 02:06
> To: Brian G. Peterson; Aleks Clark
> Cc: r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] Evaluating equity curves
> 
> Brian,
> 
> Isn't any stream of cumulative returns, de facto, an equity 
> curve? Or am I misunderstanding this? Thanks, Ralph Vince
> 
> ----- Original Message -----
> From: "Brian G. Peterson" <brian at braverock.com>
> To: "Aleks Clark" <aleks.clark at gmail.com>
> Cc: <r-sig-finance at stat.math.ethz.ch>
> Sent: Sunday, October 11, 2009 8:46 PM
> Subject: Re: [R-SIG-Finance] Evaluating equity curves
> 
> 
> > Aleks Clark wrote:
> >> As part of a project I'm working on that uses genetic algorithms to
> >> optimize trading parameters, I find myself seeking a way 
> to evaluate
> >> the equity curve that results from a given set of trading rules. It
> >> seems to be an obvious area of research, so I was wondering what's
> >> available in R-land or just in the world of finance in 
> general. I've
> >> poked around with splines as a way to express how 'nice' an equity
> >> curve is (steady upward rise as opposed to a "jagged" line), but I
> >> feel that there are probably better ways to do things...
> >
> > Having worked both in quantitative trading and in more 
> traditional asset 
> > management roles, I've never quite understood the 
> artificial distinction 
> > between "equity curves" and any other kind of returns.  In 
> my experience, 
> > all the usual performance and risk analysis tools (amply 
> provided for in 
> > R) as well as attribution (e.g. Bacon, much of which is 
> implemented in 
> > fPortfolio) are equally applicable to trading strategies as 
> they are to 
> > more traditional investment.  Also see Pat Burns' paper on 
> evaluatinfg 
> > trading strategies for additional ideas.
> >
> > Regards,
> >
> >   - Brian
> >
> > _______________________________________________
> > R-SIG-Finance at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only.
> > -- If you want to post, subscribe first.
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 


From markknecht at gmail.com  Mon Oct 12 19:05:20 2009
From: markknecht at gmail.com (Mark Knecht)
Date: Mon, 12 Oct 2009 10:05:20 -0700
Subject: [R-SIG-Finance] QuantMod trading models docs?
In-Reply-To: <5ddf2c610910110802g4e47de87tbd2bfe8c4420a7ae@mail.gmail.com>
References: <5bdc1c8b0910101529r7af48ad5id93fcb8fb2a7829b@mail.gmail.com>
	<5ddf2c610910110616u1c84d7dfr6894ae049abba73a@mail.gmail.com>
	<5bdc1c8b0910110643q289bd07bjba68f7454cb4ef8@mail.gmail.com>
	<5ddf2c610910110658p7f2e0ae7u33dc117c2607c942@mail.gmail.com>
	<5bdc1c8b0910110711o1ecbbe93uaef321d7f6c07c6d@mail.gmail.com>
	<5ddf2c610910110720p46f89903ub9ae064085326a3d@mail.gmail.com>
	<5bdc1c8b0910110742r1fe39ac1s55941b7a288f5785@mail.gmail.com>
	<5ddf2c610910110802g4e47de87tbd2bfe8c4420a7ae@mail.gmail.com>
Message-ID: <5bdc1c8b0910121005vfb2e9e4m146645c25a09e2a5@mail.gmail.com>

Hi Daniel,
   Thanks for your help. this morning I see that the Blotter package
was once again available for download using the command below so I'm
able to load it and run the turtles demo. (VERY slowly by the way!)

   Anyway, this is extremely helpful and fives me something to study
to see if what I'd like to do is possible in R.

Cheers,
Mark

2009/10/11 Daniel Cegie?ka <daniel.cegielka at gmail.com>:
> You can download and install this manually:
> http://r-forge.r-project.org/src/contrib/blotter_0.3.tar.gz
> unpack this and save as a zip file (if you have windows).
> copy this in to your R-work folder and:
> install.packages("blotter_0.3.zip",repos=NULL)
> best
> daniel
>
> W dniu 11 pa?dziernika 2009 16:42 u?ytkownik Mark Knecht
> <markknecht at gmail.com> napisa?:
>>
>> Yes, that's the command on the blotter page, but it seems that the
>> files have gone missing or something...
>>
>> > install.packages("blotter",repos="http://R-Forge.R-project.org")
>> Warning: unable to access index for repository
>> http://R-Forge.R-project.org/bin/windows/contrib/2.9
>> Warning message:
>> In getDependencies(pkgs, dependencies, available, lib) :
>> ?package ?blotter? is not available
>> >
>>
>> As I said earlier, if I go to the download link and try to download
>> the Windows zip version it says there's nothing there. Same as this
>> command is saying.
>>
>> I'll try again later. Maybe it's just having problems right now.
>>
>> Thanks,
>> Mark
>>
>> 2009/10/11 Daniel Cegie?ka <daniel.cegielka at gmail.com>:
>> > install.packages("blotter",repos="http://R-Forge.R-project.org")
>> >
>> > regards
>> > daniel
>> >
>
>


From jeff.a.ryan at gmail.com  Mon Oct 12 19:14:30 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 12 Oct 2009 12:14:30 -0500
Subject: [R-SIG-Finance] QuantMod trading models docs?
In-Reply-To: <5bdc1c8b0910121005vfb2e9e4m146645c25a09e2a5@mail.gmail.com>
References: <5bdc1c8b0910101529r7af48ad5id93fcb8fb2a7829b@mail.gmail.com>
	<5ddf2c610910110616u1c84d7dfr6894ae049abba73a@mail.gmail.com>
	<5bdc1c8b0910110643q289bd07bjba68f7454cb4ef8@mail.gmail.com>
	<5ddf2c610910110658p7f2e0ae7u33dc117c2607c942@mail.gmail.com>
	<5bdc1c8b0910110711o1ecbbe93uaef321d7f6c07c6d@mail.gmail.com>
	<5ddf2c610910110720p46f89903ub9ae064085326a3d@mail.gmail.com>
	<5bdc1c8b0910110742r1fe39ac1s55941b7a288f5785@mail.gmail.com>
	<5ddf2c610910110802g4e47de87tbd2bfe8c4420a7ae@mail.gmail.com>
	<5bdc1c8b0910121005vfb2e9e4m146645c25a09e2a5@mail.gmail.com>
Message-ID: <e8e755250910121014x71afba36h60ec26bbabc89846@mail.gmail.com>

One comment on blotter and speed.

The most recent CRAN version of xts doesn't handle repeated subsetting
by time-class objects very efficiently.

This is the primary cause of pain in the blotter you are trying (likely).

The recent R-forge version of xts has had this corrected, and should
represent something close to 60x better performance.

HTH,
Jeff

2009/10/12 Mark Knecht <markknecht at gmail.com>:
> Hi Daniel,
>   Thanks for your help. this morning I see that the Blotter package
> was once again available for download using the command below so I'm
> able to load it and run the turtles demo. (VERY slowly by the way!)
>
>   Anyway, this is extremely helpful and fives me something to study
> to see if what I'd like to do is possible in R.
>
> Cheers,
> Mark
>
> 2009/10/11 Daniel Cegie?ka <daniel.cegielka at gmail.com>:
>> You can download and install this manually:
>> http://r-forge.r-project.org/src/contrib/blotter_0.3.tar.gz
>> unpack this and save as a zip file (if you have windows).
>> copy this in to your R-work folder and:
>> install.packages("blotter_0.3.zip",repos=NULL)
>> best
>> daniel
>>
>> W dniu 11 pa?dziernika 2009 16:42 u?ytkownik Mark Knecht
>> <markknecht at gmail.com> napisa?:
>>>
>>> Yes, that's the command on the blotter page, but it seems that the
>>> files have gone missing or something...
>>>
>>> > install.packages("blotter",repos="http://R-Forge.R-project.org")
>>> Warning: unable to access index for repository
>>> http://R-Forge.R-project.org/bin/windows/contrib/2.9
>>> Warning message:
>>> In getDependencies(pkgs, dependencies, available, lib) :
>>>  package 'blotter' is not available
>>> >
>>>
>>> As I said earlier, if I go to the download link and try to download
>>> the Windows zip version it says there's nothing there. Same as this
>>> command is saying.
>>>
>>> I'll try again later. Maybe it's just having problems right now.
>>>
>>> Thanks,
>>> Mark
>>>
>>> 2009/10/11 Daniel Cegie?ka <daniel.cegielka at gmail.com>:
>>> > install.packages("blotter",repos="http://R-Forge.R-project.org")
>>> >
>>> > regards
>>> > daniel
>>> >
>>
>>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From daniel.cegielka at gmail.com  Mon Oct 12 19:25:03 2009
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Mon, 12 Oct 2009 19:25:03 +0200
Subject: [R-SIG-Finance] QuantMod trading models docs?
In-Reply-To: <e8e755250910121014x71afba36h60ec26bbabc89846@mail.gmail.com>
References: <5bdc1c8b0910101529r7af48ad5id93fcb8fb2a7829b@mail.gmail.com>
	<5ddf2c610910110616u1c84d7dfr6894ae049abba73a@mail.gmail.com>
	<5bdc1c8b0910110643q289bd07bjba68f7454cb4ef8@mail.gmail.com>
	<5ddf2c610910110658p7f2e0ae7u33dc117c2607c942@mail.gmail.com>
	<5bdc1c8b0910110711o1ecbbe93uaef321d7f6c07c6d@mail.gmail.com>
	<5ddf2c610910110720p46f89903ub9ae064085326a3d@mail.gmail.com>
	<5bdc1c8b0910110742r1fe39ac1s55941b7a288f5785@mail.gmail.com>
	<5ddf2c610910110802g4e47de87tbd2bfe8c4420a7ae@mail.gmail.com>
	<5bdc1c8b0910121005vfb2e9e4m146645c25a09e2a5@mail.gmail.com>
	<e8e755250910121014x71afba36h60ec26bbabc89846@mail.gmail.com>
Message-ID: <5ddf2c610910121025u38292bc4ha4c23c899f648d3e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091012/4be80914/attachment.pl>

From markknecht at gmail.com  Mon Oct 12 19:30:32 2009
From: markknecht at gmail.com (Mark Knecht)
Date: Mon, 12 Oct 2009 10:30:32 -0700
Subject: [R-SIG-Finance] QuantMod trading models docs?
In-Reply-To: <e8e755250910121014x71afba36h60ec26bbabc89846@mail.gmail.com>
References: <5bdc1c8b0910101529r7af48ad5id93fcb8fb2a7829b@mail.gmail.com>
	<5ddf2c610910110616u1c84d7dfr6894ae049abba73a@mail.gmail.com>
	<5bdc1c8b0910110643q289bd07bjba68f7454cb4ef8@mail.gmail.com>
	<5ddf2c610910110658p7f2e0ae7u33dc117c2607c942@mail.gmail.com>
	<5bdc1c8b0910110711o1ecbbe93uaef321d7f6c07c6d@mail.gmail.com>
	<5ddf2c610910110720p46f89903ub9ae064085326a3d@mail.gmail.com>
	<5bdc1c8b0910110742r1fe39ac1s55941b7a288f5785@mail.gmail.com>
	<5ddf2c610910110802g4e47de87tbd2bfe8c4420a7ae@mail.gmail.com>
	<5bdc1c8b0910121005vfb2e9e4m146645c25a09e2a5@mail.gmail.com>
	<e8e755250910121014x71afba36h60ec26bbabc89846@mail.gmail.com>
Message-ID: <5bdc1c8b0910121030q5fec5770i9114abe95dfda442@mail.gmail.com>

Jeff,
   Thanks. Can I just install that over the top of the currently
installed CRAN version? If so I'll give it a try today. If not then am
I required to so a remove.packages first?

   To keep the email list smaller thanks for the pointer over the
weekend to the previous conversation on this topic. It's clear folks
have given this a great deal of thought and there are a number of
tools out there that address at least portions of the problem. that
should make for many hours of investigation on my part.

   Maybe it's just a terminology thing but I'm surprised that
backtesting - to me simply executing the model on a given data set and
collecting the results - should be considered so difficult. I would
have thought that would be relatively straight forward and maybe
optimization would be the real problem.

   In terms of and code I'd certainly be happy to share non-system
specific portions but please don't hold your breath. I'm not a
programmer so all of this stuff is a struggle and results come very
slowly. That said my original thought on this would have turned some
of what I see in blotter into something that looks a bit more like
EasyLanguage on TradeStation, but that's just so I can go back and
forth between R and TS. EL really only has 4 commands for buy/sell
operations:

Buy
Sell
SellShort
BuyToCover

and then adds the modifiers "market", "stop" o r limit" to specify the
way the order executes against price. I was going to focus on creating
some code to do that and see where it led me.

   I am a bit concerned reading through your thread that possibly I'm
going to have real trouble with tick data in R? I'm not working on
end-of-day stuff as I'm a day trader and am flat every night. (Deity
willing) My tick data is has date and time but isn't guaranteed unique
in that respect. Is there any reason you or others know of why xts or
zoo should not handle tick data?

   Clearly I have a lot to study and since turtles now runs I can do that.

Cheers,
Mark

2009/10/12 Jeff Ryan <jeff.a.ryan at gmail.com>:
> One comment on blotter and speed.
>
> The most recent CRAN version of xts doesn't handle repeated subsetting
> by time-class objects very efficiently.
>
> This is the primary cause of pain in the blotter you are trying (likely).
>
> The recent R-forge version of xts has had this corrected, and should
> represent something close to 60x better performance.
>
> HTH,
> Jeff
>
> 2009/10/12 Mark Knecht <markknecht at gmail.com>:
>> Hi Daniel,
>> ? Thanks for your help. this morning I see that the Blotter package
>> was once again available for download using the command below so I'm
>> able to load it and run the turtles demo. (VERY slowly by the way!)
>>
>> ? Anyway, this is extremely helpful and fives me something to study
>> to see if what I'd like to do is possible in R.
>>
>> Cheers,
>> Mark
>>
>> 2009/10/11 Daniel Cegie?ka <daniel.cegielka at gmail.com>:
>>> You can download and install this manually:
>>> http://r-forge.r-project.org/src/contrib/blotter_0.3.tar.gz
>>> unpack this and save as a zip file (if you have windows).
>>> copy this in to your R-work folder and:
>>> install.packages("blotter_0.3.zip",repos=NULL)
>>> best
>>> daniel
>>>
>>> W dniu 11 pa?dziernika 2009 16:42 u?ytkownik Mark Knecht
>>> <markknecht at gmail.com> napisa?:
>>>>
>>>> Yes, that's the command on the blotter page, but it seems that the
>>>> files have gone missing or something...
>>>>
>>>> > install.packages("blotter",repos="http://R-Forge.R-project.org")
>>>> Warning: unable to access index for repository
>>>> http://R-Forge.R-project.org/bin/windows/contrib/2.9
>>>> Warning message:
>>>> In getDependencies(pkgs, dependencies, available, lib) :
>>>> ?package 'blotter' is not available
>>>> >
>>>>
>>>> As I said earlier, if I go to the download link and try to download
>>>> the Windows zip version it says there's nothing there. Same as this
>>>> command is saying.
>>>>
>>>> I'll try again later. Maybe it's just having problems right now.
>>>>
>>>> Thanks,
>>>> Mark
>>>>
>>>> 2009/10/11 Daniel Cegie?ka <daniel.cegielka at gmail.com>:
>>>> > install.packages("blotter",repos="http://R-Forge.R-project.org")
>>>> >
>>>> > regards
>>>> > daniel
>>>> >
>>>
>>>
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>
>
>
> --
> Jeffrey Ryan
> jeffrey.ryan at insightalgo.com
>
> ia: insight algorithmics
> www.insightalgo.com
>


From jeff.a.ryan at gmail.com  Mon Oct 12 19:37:00 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 12 Oct 2009 12:37:00 -0500
Subject: [R-SIG-Finance] QuantMod trading models docs?
In-Reply-To: <5bdc1c8b0910121030q5fec5770i9114abe95dfda442@mail.gmail.com>
References: <5bdc1c8b0910101529r7af48ad5id93fcb8fb2a7829b@mail.gmail.com>
	<5bdc1c8b0910110643q289bd07bjba68f7454cb4ef8@mail.gmail.com>
	<5ddf2c610910110658p7f2e0ae7u33dc117c2607c942@mail.gmail.com>
	<5bdc1c8b0910110711o1ecbbe93uaef321d7f6c07c6d@mail.gmail.com>
	<5ddf2c610910110720p46f89903ub9ae064085326a3d@mail.gmail.com>
	<5bdc1c8b0910110742r1fe39ac1s55941b7a288f5785@mail.gmail.com>
	<5ddf2c610910110802g4e47de87tbd2bfe8c4420a7ae@mail.gmail.com>
	<5bdc1c8b0910121005vfb2e9e4m146645c25a09e2a5@mail.gmail.com>
	<e8e755250910121014x71afba36h60ec26bbabc89846@mail.gmail.com>
	<5bdc1c8b0910121030q5fec5770i9114abe95dfda442@mail.gmail.com>
Message-ID: <e8e755250910121037x7eb6eb69l717016942380640b@mail.gmail.com>

> ? Thanks. Can I just install that over the top of the currently
> installed CRAN version? If so I'll give it a try today. If not then am
> I required to so a remove.packages first?
>

Should just be able to install over.  You will have to wait for the
updates on R-forge to get built, or you could always install from
source (the svn tree).

> ? To keep the email list smaller thanks for the pointer over the
> weekend to the previous conversation on this topic. It's clear folks
> have given this a great deal of thought and there are a number of
> tools out there that address at least portions of the problem. that
> should make for many hours of investigation on my part.

Usually does make things faster.
>
> ? Maybe it's just a terminology thing but I'm surprised that
> backtesting - to me simply executing the model on a given data set and
> collecting the results - should be considered so difficult. I would
> have thought that would be relatively straight forward and maybe
> optimization would be the real problem.
>
> ? In terms of and code I'd certainly be happy to share non-system
> specific portions but please don't hold your breath. I'm not a
> programmer so all of this stuff is a struggle and results come very
> slowly. That said my original thought on this would have turned some
> of what I see in blotter into something that looks a bit more like
> EasyLanguage on TradeStation, but that's just so I can go back and
> forth between R and TS. EL really only has 4 commands for buy/sell
> operations:
>
> Buy
> Sell
> SellShort
> BuyToCover
>
> and then adds the modifiers "market", "stop" o r limit" to specify the
> way the order executes against price. I was going to focus on creating
> some code to do that and see where it led me.
>
> ? I am a bit concerned reading through your thread that possibly I'm
> going to have real trouble with tick data in R? I'm not working on
> end-of-day stuff as I'm a day trader and am flat every night. (Deity
> willing) My tick data is has date and time but isn't guaranteed unique
> in that respect. Is there any reason you or others know of why xts or
> zoo should not handle tick data?
>
Tick data should be no problem for xts or zoo.  Many people use it for
that with good success.  Uniqueness is an issue outside of the time
representation.  You can always do something to make the timestamp
unique.  The question is whether or not you should treat it as unique.
 Depends on what you are doing really.

Others on this list are very active in the high-freq space, so one or
more may provide some detailed comments.

> ? Clearly I have a lot to study and since turtles now runs I can do that.

Keep us posted (on or off list).

Thanks,
Jeff

>
> Cheers,
> Mark
>
> 2009/10/12 Jeff Ryan <jeff.a.ryan at gmail.com>:
>> One comment on blotter and speed.
>>
>> The most recent CRAN version of xts doesn't handle repeated subsetting
>> by time-class objects very efficiently.
>>
>> This is the primary cause of pain in the blotter you are trying (likely).
>>
>> The recent R-forge version of xts has had this corrected, and should
>> represent something close to 60x better performance.
>>
>> HTH,
>> Jeff
>>
>> 2009/10/12 Mark Knecht <markknecht at gmail.com>:
>>> Hi Daniel,
>>> ? Thanks for your help. this morning I see that the Blotter package
>>> was once again available for download using the command below so I'm
>>> able to load it and run the turtles demo. (VERY slowly by the way!)
>>>
>>> ? Anyway, this is extremely helpful and fives me something to study
>>> to see if what I'd like to do is possible in R.
>>>
>>> Cheers,
>>> Mark
>>>
>>> 2009/10/11 Daniel Cegie?ka <daniel.cegielka at gmail.com>:
>>>> You can download and install this manually:
>>>> http://r-forge.r-project.org/src/contrib/blotter_0.3.tar.gz
>>>> unpack this and save as a zip file (if you have windows).
>>>> copy this in to your R-work folder and:
>>>> install.packages("blotter_0.3.zip",repos=NULL)
>>>> best
>>>> daniel
>>>>
>>>> W dniu 11 pa?dziernika 2009 16:42 u?ytkownik Mark Knecht
>>>> <markknecht at gmail.com> napisa?:
>>>>>
>>>>> Yes, that's the command on the blotter page, but it seems that the
>>>>> files have gone missing or something...
>>>>>
>>>>> > install.packages("blotter",repos="http://R-Forge.R-project.org")
>>>>> Warning: unable to access index for repository
>>>>> http://R-Forge.R-project.org/bin/windows/contrib/2.9
>>>>> Warning message:
>>>>> In getDependencies(pkgs, dependencies, available, lib) :
>>>>> ?package 'blotter' is not available
>>>>> >
>>>>>
>>>>> As I said earlier, if I go to the download link and try to download
>>>>> the Windows zip version it says there's nothing there. Same as this
>>>>> command is saying.
>>>>>
>>>>> I'll try again later. Maybe it's just having problems right now.
>>>>>
>>>>> Thanks,
>>>>> Mark
>>>>>
>>>>> 2009/10/11 Daniel Cegie?ka <daniel.cegielka at gmail.com>:
>>>>> > install.packages("blotter",repos="http://R-Forge.R-project.org")
>>>>> >
>>>>> > regards
>>>>> > daniel
>>>>> >
>>>>
>>>>
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>
>>
>>
>> --
>> Jeffrey Ryan
>> jeffrey.ryan at insightalgo.com
>>
>> ia: insight algorithmics
>> www.insightalgo.com
>>
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From markknecht at gmail.com  Mon Oct 12 20:05:55 2009
From: markknecht at gmail.com (Mark Knecht)
Date: Mon, 12 Oct 2009 11:05:55 -0700
Subject: [R-SIG-Finance] QuantMod trading models docs?
In-Reply-To: <e8e755250910121037x7eb6eb69l717016942380640b@mail.gmail.com>
References: <5bdc1c8b0910101529r7af48ad5id93fcb8fb2a7829b@mail.gmail.com>
	<5ddf2c610910110658p7f2e0ae7u33dc117c2607c942@mail.gmail.com>
	<5bdc1c8b0910110711o1ecbbe93uaef321d7f6c07c6d@mail.gmail.com>
	<5ddf2c610910110720p46f89903ub9ae064085326a3d@mail.gmail.com>
	<5bdc1c8b0910110742r1fe39ac1s55941b7a288f5785@mail.gmail.com>
	<5ddf2c610910110802g4e47de87tbd2bfe8c4420a7ae@mail.gmail.com>
	<5bdc1c8b0910121005vfb2e9e4m146645c25a09e2a5@mail.gmail.com>
	<e8e755250910121014x71afba36h60ec26bbabc89846@mail.gmail.com>
	<5bdc1c8b0910121030q5fec5770i9114abe95dfda442@mail.gmail.com>
	<e8e755250910121037x7eb6eb69l717016942380640b@mail.gmail.com>
Message-ID: <5bdc1c8b0910121105r34b3611fxdb2a1d918b6d73a6@mail.gmail.com>

2009/10/12 Jeff Ryan <jeff.a.ryan at gmail.com>:
>> ? Thanks. Can I just install that over the top of the currently
>> installed CRAN version? If so I'll give it a try today. If not then am
>> I required to so a remove.packages first?
>>
>
> Should just be able to install over. ?You will have to wait for the
> updates on R-forge to get built, or you could always install from
> source (the svn tree).

I guess I could switch to a Gentoo machine to do my own builds from
SVN but mostly I'm stuck on Windows during the day due to
TradeStation. I have no experience building anything from source on
Windows. I'll try Gentoo this afternoon as an experiment and see if it
works out at all.

>
>> ? To keep the email list smaller thanks for the pointer over the
>> weekend to the previous conversation on this topic. It's clear folks
>> have given this a great deal of thought and there are a number of
>> tools out there that address at least portions of the problem. that
>> should make for many hours of investigation on my part.
>
> Usually does make things faster.
>>
>> ? Maybe it's just a terminology thing but I'm surprised that
>> backtesting - to me simply executing the model on a given data set and
>> collecting the results - should be considered so difficult. I would
>> have thought that would be relatively straight forward and maybe
>> optimization would be the real problem.
>>
>> ? In terms of and code I'd certainly be happy to share non-system
>> specific portions but please don't hold your breath. I'm not a
>> programmer so all of this stuff is a struggle and results come very
>> slowly. That said my original thought on this would have turned some
>> of what I see in blotter into something that looks a bit more like
>> EasyLanguage on TradeStation, but that's just so I can go back and
>> forth between R and TS. EL really only has 4 commands for buy/sell
>> operations:
>>
>> Buy
>> Sell
>> SellShort
>> BuyToCover
>>
>> and then adds the modifiers "market", "stop" o r limit" to specify the
>> way the order executes against price. I was going to focus on creating
>> some code to do that and see where it led me.
>>
>> ? I am a bit concerned reading through your thread that possibly I'm
>> going to have real trouble with tick data in R? I'm not working on
>> end-of-day stuff as I'm a day trader and am flat every night. (Deity
>> willing) My tick data is has date and time but isn't guaranteed unique
>> in that respect. Is there any reason you or others know of why xts or
>> zoo should not handle tick data?
>>
> Tick data should be no problem for xts or zoo. ?Many people use it for
> that with good success. ?Uniqueness is an issue outside of the time
> representation. ?You can always do something to make the timestamp
> unique. ?The question is whether or not you should treat it as unique.
> ?Depends on what you are doing really.

Certainly. I can output BarNumber from TradeStation or just create my
own value in R.

>
> Others on this list are very active in the high-freq space, so one or
> more may provide some detailed comments.

Nothing high-frequency about my trading today. Seems like the futures
market is stuck in a few tick window this morning... :-)

>
>> ? Clearly I have a lot to study and since turtles now runs I can do that.
>
> Keep us posted (on or off list).
>

Will do.

Cheers,
Mark


From brian at braverock.com  Tue Oct 13 15:59:19 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 13 Oct 2009 08:59:19 -0500
Subject: [R-SIG-Finance] R CMD --meetup=Chicago --when=Oct 29
	--where=Jak'sTap
Message-ID: <4AD487B7.6050508@braverock.com>

For R Users who may be in or able to be in Chicagoland:

We are pleased to announce a Fall meetup for Chicagoland R users. This
is open to anyone with an interest in R: practioners, researchers,
casual users and other interested parties.

WHEN: October 29, 2009 @5:30
WHERE: Jak's Tap www.jakstap.com

A short series of so-called lightning talks from some noted R
contributors and users is on the agenda. Speakers include:

Gib Basset (UIC)
Bryan Lewis (Revolution Computing)
JD Long (Cerebral Mastication)
David St. John (UIC, ttrTests package)

Casual conversation and food will follow, courtesy of the
International Center for Futures and Derivatives at the University of
Illinois at Chicago and the organizers of the R/Finance conferences:
http://www.RinFinance.com

Regards,

   - Brian
     (for the organizing committee)


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From nordicgnome at gmail.com  Wed Oct 14 04:22:48 2009
From: nordicgnome at gmail.com (Jan Vandermeer)
Date: Tue, 13 Oct 2009 22:22:48 -0400
Subject: [R-SIG-Finance] Blotter package - problem with example.
Message-ID: <e64efa440910131922v544b941diaea9bb7ce400fe6b@mail.gmail.com>

Hi all;

I've been following the discussion here on backtesting
([R-SIG-Finance] Backtesting framework package -
<https://stat.ethz.ch/pipermail/r-sig-finance/2009q2/004404.html> and
the discussion  [R-SIG-Finance] QuantMod trading models docs?
initiated by Mark Knecht and decided to give the blotter package a
try.
I tried running  through the example provided by the blotter package.
</usr/lib64/R/library/blotter/html/blotter-package.html>
I installed the latest version from R-forge. I am running R version
2.9.1 (2009-06-26) on an AMD Turion 64 with a Gentoo 2.6.31 kernel.

Things ran smoothly as shown below until I got to the "p =
updatePortf(p,'2007-01')" step, where R kicked out

"Error in if (mid != 0 && key < vec[mid]) { :
  missing value where TRUE/FALSE needed".

So I went along and looked at the
"/usr/lib64/R/library/blotter/html/00Index.html", which sent me along
to "/usr/lib64/R/library/blotter/html/updatePosPL.html" and attempted
to adjust some of the values because the usage seems to indicate that
additional values may be required

"Usage
updatePosPL(Portfolio, Symbol, StartDate, EndDate, Prices = Cl(get(Symbol)))
updatePortf(Portfolio, StartDate, EndDate)"

I added an EndDate using the same format as in the getSymbols command.
and received the following error.

> p = updatePortf(p,'2007-01-01`, '2007-01-31')
Error: unexpected numeric constant in "p = updatePortf(p,'2007-01-01`, '2007"


I tried a couple of variations on the updatePosPL()

> updatePosPL(p, "IBM", '2007-01-01', '2007-01-31', Prices = Cl(get(Symbol)))
Error in updatePosPL(p, "IBM", "2007-01-01", "2007-01-31", Prices =
Cl(get(Symbol))) :
  unused argument(s) ("2007-01-31")
> updatePosPL(p, "IBM", '2007-01-01', '2007-01-31', Prices = Cl(get(Symbol)))
Error in updatePosPL(p, "IBM", "2007-01-01", "2007-01-31", Prices =
Cl(get(Symbol))) :
  unused argument(s) ("2007-01-31")
> updatePosPL(p, "IBM", '2007-01-01', Prices = Cl(get(Symbol)))
Error in get(Symbol) : object 'Symbol' not found
> updatePosPL(p, "IBM", '2007-01-01', Prices = Cl(get(symbol)))
Error in get(symbol) : object 'symbol' not found

I also tried:
> updatePosPL(p, "IBM", '2007-01-01', Prices = Cl(IBM))
Error in if (any(i < 0)) { : missing value where TRUE/FALSE needed


At this point I am at a bit of a loss. I tried looking through some of
the stuff on R-Project to see if there are guidelines for code
examples and where and if they should work. I guess I would expect the
code examples include in the library or
"/usr/lib64/R/library/blotter/R-ex" to just work.

So, I am I doing something glaringly wrong? Do I need to update my
version of R, xts, zoo or quantmod? I know I am on still on the steep
part of the learning curve as far as R in general is concerned and
specifically with time series and financial data with R but R texts
I've seen suggest that working through examples with real data and
known steps is a great way to learn. Successfully working through
examples allows one small sign posts of success along the way

Any assistance would be appreciated.

Jan



Blotter example entered into R and responses after the first _________

I tried looking at the output for "p", see below the second ______. It
appears to be included in the data.frame

Values obtained through quantmod are below the third _______

________________________________
> library(blotter)
Loading required package: xts
Loading required package: zoo

Attaching package: 'zoo'


        The following object(s) are masked from package:base :

         as.Date.numeric

xts now requires a valid TZ environment variable to be set
 no TZ var is set, setting to TZ=GMT
> symbols = c("IBM","F","MMM")
> require(quantmod)
Loading required package: quantmod
Loading required package: Defaults
Loading required package: TTR
> getSymbols(symbols, from='2007-01-01', to='2007-01-31', index.class="POSIXct")
[1] "IBM" "F"   "MMM"
> print('Creating portfolio \"p\"...')
[1] "Creating portfolio \"p\"..."
> p = initPortf(symbols=symbols)
> print('Adding trades to \"p\"...')
[1] "Adding trades to \"p\"..."
> # Make a couple of trades in IBM
> p = addTxn(p, "IBM", '2007-01-03', 50, 96.5, -0.05*50)
[1] "IBM 2007-01-03 50 @ 96.5"
> p = addTxn(p, "IBM", '2007-01-04', 50, 97.1, -0.05*50)
[1] "IBM 2007-01-04 50 @ 97.1"
> # ...a few in F.
> p = addTxn(p, "F", '2007-01-03', -100, 7.60, -0.05*100)
[1] "F 2007-01-03 -100 @ 7.6"
> p = addTxn(p, "F", '2007-01-04', 50, 7.70, -0.05*50)
[1] "F 2007-01-04 50 @ 7.7"
> p = addTxn(p, "F", '2007-01-10', 50, 7.78, -0.05*50)
[1] "F 2007-01-10 50 @ 7.78"
> # ...and some in MMM
> p = addTxn(p, "MMM", '2007-01-05', -50, 77.9, -0.05*50)
[1] "MMM 2007-01-05 -50 @ 77.9"
> p = addTxn(p, "MMM", '2007-01-08', 50, 77.6, -0.05*50)
[1] "MMM 2007-01-08 50 @ 77.6"
> p = addTxn(p, "MMM", '2007-01-09', 50, 77.6, -0.05*50)
[1] "MMM 2007-01-09 50 @ 77.6"
___________


It appears that the transactions have been posted correctly

> p
$IBM
$IBM$txn
           Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty
1950-01-01       0       0.0      0.0       0.0         0.00       0
2007-01-03      50      96.5     -2.5    4827.5        96.55      50
2007-01-04      50      97.1     -2.5    4857.5        97.15     100
           Pos.Avg.Cost Realized.PL
1950-01-01         0.00           0
2007-01-03        96.55           0
2007-01-04        96.85           0

$IBM$posPL
           Pos.Qty Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL
1950-01-01       0         0         0        0           0             0
           Trading.PL
1950-01-01          0


$F
$F$txn
           Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty
1950-01-01       0      0.00      0.0       0.0         0.00       0
2007-01-03    -100      7.60     -5.0    -755.0         7.55    -100
2007-01-04      50      7.70     -2.5     387.5         7.75     -50
2007-01-10      50      7.78     -2.5     391.5         7.83       0
           Pos.Avg.Cost Realized.PL
1950-01-01         0.00           0
2007-01-03         7.55           0
2007-01-04         7.35         -10
2007-01-10         0.00         -24

$F$posPL
           Pos.Qty Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL
1950-01-01       0         0         0        0           0             0
           Trading.PL
1950-01-01          0


$MMM
$MMM$txn
           Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty
1950-01-01       0       0.0      0.0       0.0         0.00       0
2007-01-05     -50      77.9     -2.5   -3892.5        77.85     -50
2007-01-08      50      77.6     -2.5    3882.5        77.65       0
2007-01-09      50      77.6     -2.5    3882.5        77.65      50
           Pos.Avg.Cost Realized.PL
1950-01-01         0.00           0
2007-01-05        77.85           0
2007-01-08         0.00          10
2007-01-09        77.65           0

$MMM$posPL
           Pos.Qty Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL
1950-01-01       0         0         0        0           0             0
           Trading.PL
1950-01-01

_________________________________________

> IBM
           IBM.Open IBM.High IBM.Low IBM.Close IBM.Volume IBM.Adjusted
2007-01-03    97.18    98.40   96.26     97.27    9196800        92.84
2007-01-04    97.25    98.79   96.88     98.31   10524500        93.83
2007-01-05    97.60    97.95   96.91     97.42    7221300        92.98
2007-01-08    98.50    99.50   98.35     98.90   10340000        94.40
2007-01-09    99.08   100.33   99.07    100.07   11108200        95.51
2007-01-10    98.50    99.05   97.93     98.89    8744800        94.39
2007-01-11    99.00    99.90   98.50     98.65    8000700        94.16
2007-01-12    98.99    99.69   98.50     99.34    6636500        94.82
2007-01-16    99.40   100.84   99.30    100.82    9602200        96.23
2007-01-17   100.69   100.90   99.90    100.02    8200700        95.47
2007-01-18    99.80    99.95   98.91     99.45   14725000        94.92
2007-01-19    95.00    96.85   94.55     96.17   26035800        91.79
2007-01-22    96.42    97.23   96.12     97.11   13539300        92.69
2007-01-23    96.91    97.38   96.20     97.08   10337400        92.66
2007-01-24    97.08    97.58   96.58     97.40    5700000        92.96
2007-01-25    97.22    97.92   97.22     97.51    6201300        93.07
2007-01-26    97.52    97.83   96.84     97.45    5771100        93.01
2007-01-29    97.70    98.66   97.45     98.54    7294800        94.05
2007-01-30    98.57    99.45   98.50     99.37    7177900        94.84
2007-01-31    98.80    99.48   98.35     99.15    6432600        94.63
> F
           F.Open F.High F.Low F.Close  F.Volume F.Adjusted
2007-01-03   7.56   7.67  7.44    7.51  78652200       7.51
2007-01-04   7.56   7.72  7.43    7.70  63454900       7.70
2007-01-05   7.72   7.75  7.57    7.62  40562100       7.62
2007-01-08   7.63   7.75  7.62    7.73  48938500       7.73
2007-01-09   7.75   7.86  7.73    7.79  56732200       7.79
2007-01-10   7.79   7.79  7.67    7.73  42397100       7.73
2007-01-11   7.73   7.80  7.68    7.77  40020800       7.77
2007-01-12   7.77   7.92  7.76    7.89  57053800       7.89
2007-01-16   7.89   8.01  7.87    7.94  66699800       7.94
2007-01-17   7.97   8.10  7.97    8.04  63728700       8.04
2007-01-18   8.06   8.24  8.06    8.18  78375700       8.18
2007-01-19   8.24   8.32  8.17    8.30  66023300       8.30
2007-01-22   8.33   8.43  8.25    8.41  53554600       8.41
2007-01-23   8.39   8.62  8.24    8.30 116406900       8.30
2007-01-24   8.31   8.35  8.11    8.20  76821900       8.20
2007-01-25   8.15   8.52  8.00    8.22  99688700       8.22
2007-01-26   8.15   8.48  8.14    8.42  54421900       8.42
2007-01-29   8.44   8.51  8.35    8.37  55791000       8.37
2007-01-30   8.38   8.42  8.19    8.20  28763200       8.20
2007-01-31   8.17   8.20  8.04    8.13  65038600       8.13
> MMM
           MMM.Open MMM.High MMM.Low MMM.Close MMM.Volume MMM.Adjusted
2007-01-03    77.53    78.85   77.38     78.26    3781500        72.40
2007-01-04    78.40    78.41   77.45     77.95    2968400        72.11
2007-01-05    77.89    77.90   77.01     77.42    2765200        71.62
2007-01-08    77.42    78.04   76.97     77.59    2434500        71.78
2007-01-09    78.00    78.23   77.44     77.68    1896800        71.86
2007-01-10    77.31    77.96   77.04     77.85    1787500        72.02
2007-01-11    78.05    79.03   77.88     78.65    2372500        72.76
2007-01-12    78.41    79.50   78.22     79.36    2582200        73.42
2007-01-16    79.48    79.62   78.92     79.56    2526600        73.60
2007-01-17    79.33    79.51   78.75     78.91    2711300        73.00
2007-01-18    78.71    79.70   78.60     78.81    1963000        72.91
2007-01-19    79.09    79.88   78.82     79.25    2912100        73.32
2007-01-22    79.25    79.29   78.13     78.49    2139300        72.61
2007-01-23    78.71    79.15   78.33     78.85    1949500        72.95
2007-01-24    78.85    79.66   78.85     79.49    1772700        73.54
2007-01-25    79.56    79.75   78.83     79.01    2888700        73.09
2007-01-26    78.97    79.19   78.23     78.69    1996300        72.80
2007-01-29    78.54    79.20   78.25     78.96    3420300        73.05
2007-01-30    74.92    76.18   74.24     74.70   15657900        69.11
2007-01-31    74.21    74.68   73.09     74.30    9284500        68.74


From jeff.a.ryan at gmail.com  Wed Oct 14 04:27:08 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 13 Oct 2009 21:27:08 -0500
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <e64efa440910131922v544b941diaea9bb7ce400fe6b@mail.gmail.com>
References: <e64efa440910131922v544b941diaea9bb7ce400fe6b@mail.gmail.com>
Message-ID: <e8e755250910131927l219db436h7a167439dbc40bc1@mail.gmail.com>

Try installing the latest versions of xts and quantmod as well.  As
blotter is under development, it is best to update all the
dependencies as well.

In this case, I think that should solve your problem.

Best,
Jeff

On Tue, Oct 13, 2009 at 9:22 PM, Jan Vandermeer <nordicgnome at gmail.com> wrote:
> Hi all;
>
> I've been following the discussion here on backtesting
> ([R-SIG-Finance] Backtesting framework package -
> <https://stat.ethz.ch/pipermail/r-sig-finance/2009q2/004404.html> and
> the discussion ?[R-SIG-Finance] QuantMod trading models docs?
> initiated by Mark Knecht and decided to give the blotter package a
> try.
> I tried running ?through the example provided by the blotter package.
> </usr/lib64/R/library/blotter/html/blotter-package.html>
> I installed the latest version from R-forge. I am running R version
> 2.9.1 (2009-06-26) on an AMD Turion 64 with a Gentoo 2.6.31 kernel.
>
> Things ran smoothly as shown below until I got to the "p =
> updatePortf(p,'2007-01')" step, where R kicked out
>
> "Error in if (mid != 0 && key < vec[mid]) { :
> ?missing value where TRUE/FALSE needed".
>
> So I went along and looked at the
> "/usr/lib64/R/library/blotter/html/00Index.html", which sent me along
> to "/usr/lib64/R/library/blotter/html/updatePosPL.html" and attempted
> to adjust some of the values because the usage seems to indicate that
> additional values may be required
>
> "Usage
> updatePosPL(Portfolio, Symbol, StartDate, EndDate, Prices = Cl(get(Symbol)))
> updatePortf(Portfolio, StartDate, EndDate)"
>
> I added an EndDate using the same format as in the getSymbols command.
> and received the following error.
>
>> p = updatePortf(p,'2007-01-01`, '2007-01-31')
> Error: unexpected numeric constant in "p = updatePortf(p,'2007-01-01`, '2007"
>
>
> I tried a couple of variations on the updatePosPL()
>
>> updatePosPL(p, "IBM", '2007-01-01', '2007-01-31', Prices = Cl(get(Symbol)))
> Error in updatePosPL(p, "IBM", "2007-01-01", "2007-01-31", Prices =
> Cl(get(Symbol))) :
> ?unused argument(s) ("2007-01-31")
>> updatePosPL(p, "IBM", '2007-01-01', '2007-01-31', Prices = Cl(get(Symbol)))
> Error in updatePosPL(p, "IBM", "2007-01-01", "2007-01-31", Prices =
> Cl(get(Symbol))) :
> ?unused argument(s) ("2007-01-31")
>> updatePosPL(p, "IBM", '2007-01-01', Prices = Cl(get(Symbol)))
> Error in get(Symbol) : object 'Symbol' not found
>> updatePosPL(p, "IBM", '2007-01-01', Prices = Cl(get(symbol)))
> Error in get(symbol) : object 'symbol' not found
>
> I also tried:
>> updatePosPL(p, "IBM", '2007-01-01', Prices = Cl(IBM))
> Error in if (any(i < 0)) { : missing value where TRUE/FALSE needed
>
>
> At this point I am at a bit of a loss. I tried looking through some of
> the stuff on R-Project to see if there are guidelines for code
> examples and where and if they should work. I guess I would expect the
> code examples include in the library or
> "/usr/lib64/R/library/blotter/R-ex" to just work.
>
> So, I am I doing something glaringly wrong? Do I need to update my
> version of R, xts, zoo or quantmod? I know I am on still on the steep
> part of the learning curve as far as R in general is concerned and
> specifically with time series and financial data with R but R texts
> I've seen suggest that working through examples with real data and
> known steps is a great way to learn. Successfully working through
> examples allows one small sign posts of success along the way
>
> Any assistance would be appreciated.
>
> Jan
>
>
>
> Blotter example entered into R and responses after the first _________
>
> I tried looking at the output for "p", see below the second ______. It
> appears to be included in the data.frame
>
> Values obtained through quantmod are below the third _______
>
> ________________________________
>> library(blotter)
> Loading required package: xts
> Loading required package: zoo
>
> Attaching package: 'zoo'
>
>
> ? ? ? ?The following object(s) are masked from package:base :
>
> ? ? ? ? as.Date.numeric
>
> xts now requires a valid TZ environment variable to be set
> ?no TZ var is set, setting to TZ=GMT
>> symbols = c("IBM","F","MMM")
>> require(quantmod)
> Loading required package: quantmod
> Loading required package: Defaults
> Loading required package: TTR
>> getSymbols(symbols, from='2007-01-01', to='2007-01-31', index.class="POSIXct")
> [1] "IBM" "F" ? "MMM"
>> print('Creating portfolio \"p\"...')
> [1] "Creating portfolio \"p\"..."
>> p = initPortf(symbols=symbols)
>> print('Adding trades to \"p\"...')
> [1] "Adding trades to \"p\"..."
>> # Make a couple of trades in IBM
>> p = addTxn(p, "IBM", '2007-01-03', 50, 96.5, -0.05*50)
> [1] "IBM 2007-01-03 50 @ 96.5"
>> p = addTxn(p, "IBM", '2007-01-04', 50, 97.1, -0.05*50)
> [1] "IBM 2007-01-04 50 @ 97.1"
>> # ...a few in F.
>> p = addTxn(p, "F", '2007-01-03', -100, 7.60, -0.05*100)
> [1] "F 2007-01-03 -100 @ 7.6"
>> p = addTxn(p, "F", '2007-01-04', 50, 7.70, -0.05*50)
> [1] "F 2007-01-04 50 @ 7.7"
>> p = addTxn(p, "F", '2007-01-10', 50, 7.78, -0.05*50)
> [1] "F 2007-01-10 50 @ 7.78"
>> # ...and some in MMM
>> p = addTxn(p, "MMM", '2007-01-05', -50, 77.9, -0.05*50)
> [1] "MMM 2007-01-05 -50 @ 77.9"
>> p = addTxn(p, "MMM", '2007-01-08', 50, 77.6, -0.05*50)
> [1] "MMM 2007-01-08 50 @ 77.6"
>> p = addTxn(p, "MMM", '2007-01-09', 50, 77.6, -0.05*50)
> [1] "MMM 2007-01-09 50 @ 77.6"
> ___________
>
>
> It appears that the transactions have been posted correctly
>
>> p
> $IBM
> $IBM$txn
> ? ? ? ? ? Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty
> 1950-01-01 ? ? ? 0 ? ? ? 0.0 ? ? ?0.0 ? ? ? 0.0 ? ? ? ? 0.00 ? ? ? 0
> 2007-01-03 ? ? ?50 ? ? ?96.5 ? ? -2.5 ? ?4827.5 ? ? ? ?96.55 ? ? ?50
> 2007-01-04 ? ? ?50 ? ? ?97.1 ? ? -2.5 ? ?4857.5 ? ? ? ?97.15 ? ? 100
> ? ? ? ? ? Pos.Avg.Cost Realized.PL
> 1950-01-01 ? ? ? ? 0.00 ? ? ? ? ? 0
> 2007-01-03 ? ? ? ?96.55 ? ? ? ? ? 0
> 2007-01-04 ? ? ? ?96.85 ? ? ? ? ? 0
>
> $IBM$posPL
> ? ? ? ? ? Pos.Qty Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL
> 1950-01-01 ? ? ? 0 ? ? ? ? 0 ? ? ? ? 0 ? ? ? ?0 ? ? ? ? ? 0 ? ? ? ? ? ? 0
> ? ? ? ? ? Trading.PL
> 1950-01-01 ? ? ? ? ?0
>
>
> $F
> $F$txn
> ? ? ? ? ? Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty
> 1950-01-01 ? ? ? 0 ? ? ?0.00 ? ? ?0.0 ? ? ? 0.0 ? ? ? ? 0.00 ? ? ? 0
> 2007-01-03 ? ?-100 ? ? ?7.60 ? ? -5.0 ? ?-755.0 ? ? ? ? 7.55 ? ?-100
> 2007-01-04 ? ? ?50 ? ? ?7.70 ? ? -2.5 ? ? 387.5 ? ? ? ? 7.75 ? ? -50
> 2007-01-10 ? ? ?50 ? ? ?7.78 ? ? -2.5 ? ? 391.5 ? ? ? ? 7.83 ? ? ? 0
> ? ? ? ? ? Pos.Avg.Cost Realized.PL
> 1950-01-01 ? ? ? ? 0.00 ? ? ? ? ? 0
> 2007-01-03 ? ? ? ? 7.55 ? ? ? ? ? 0
> 2007-01-04 ? ? ? ? 7.35 ? ? ? ? -10
> 2007-01-10 ? ? ? ? 0.00 ? ? ? ? -24
>
> $F$posPL
> ? ? ? ? ? Pos.Qty Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL
> 1950-01-01 ? ? ? 0 ? ? ? ? 0 ? ? ? ? 0 ? ? ? ?0 ? ? ? ? ? 0 ? ? ? ? ? ? 0
> ? ? ? ? ? Trading.PL
> 1950-01-01 ? ? ? ? ?0
>
>
> $MMM
> $MMM$txn
> ? ? ? ? ? Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty
> 1950-01-01 ? ? ? 0 ? ? ? 0.0 ? ? ?0.0 ? ? ? 0.0 ? ? ? ? 0.00 ? ? ? 0
> 2007-01-05 ? ? -50 ? ? ?77.9 ? ? -2.5 ? -3892.5 ? ? ? ?77.85 ? ? -50
> 2007-01-08 ? ? ?50 ? ? ?77.6 ? ? -2.5 ? ?3882.5 ? ? ? ?77.65 ? ? ? 0
> 2007-01-09 ? ? ?50 ? ? ?77.6 ? ? -2.5 ? ?3882.5 ? ? ? ?77.65 ? ? ?50
> ? ? ? ? ? Pos.Avg.Cost Realized.PL
> 1950-01-01 ? ? ? ? 0.00 ? ? ? ? ? 0
> 2007-01-05 ? ? ? ?77.85 ? ? ? ? ? 0
> 2007-01-08 ? ? ? ? 0.00 ? ? ? ? ?10
> 2007-01-09 ? ? ? ?77.65 ? ? ? ? ? 0
>
> $MMM$posPL
> ? ? ? ? ? Pos.Qty Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL
> 1950-01-01 ? ? ? 0 ? ? ? ? 0 ? ? ? ? 0 ? ? ? ?0 ? ? ? ? ? 0 ? ? ? ? ? ? 0
> ? ? ? ? ? Trading.PL
> 1950-01-01
>
> _________________________________________
>
>> IBM
> ? ? ? ? ? IBM.Open IBM.High IBM.Low IBM.Close IBM.Volume IBM.Adjusted
> 2007-01-03 ? ?97.18 ? ?98.40 ? 96.26 ? ? 97.27 ? ?9196800 ? ? ? ?92.84
> 2007-01-04 ? ?97.25 ? ?98.79 ? 96.88 ? ? 98.31 ? 10524500 ? ? ? ?93.83
> 2007-01-05 ? ?97.60 ? ?97.95 ? 96.91 ? ? 97.42 ? ?7221300 ? ? ? ?92.98
> 2007-01-08 ? ?98.50 ? ?99.50 ? 98.35 ? ? 98.90 ? 10340000 ? ? ? ?94.40
> 2007-01-09 ? ?99.08 ? 100.33 ? 99.07 ? ?100.07 ? 11108200 ? ? ? ?95.51
> 2007-01-10 ? ?98.50 ? ?99.05 ? 97.93 ? ? 98.89 ? ?8744800 ? ? ? ?94.39
> 2007-01-11 ? ?99.00 ? ?99.90 ? 98.50 ? ? 98.65 ? ?8000700 ? ? ? ?94.16
> 2007-01-12 ? ?98.99 ? ?99.69 ? 98.50 ? ? 99.34 ? ?6636500 ? ? ? ?94.82
> 2007-01-16 ? ?99.40 ? 100.84 ? 99.30 ? ?100.82 ? ?9602200 ? ? ? ?96.23
> 2007-01-17 ? 100.69 ? 100.90 ? 99.90 ? ?100.02 ? ?8200700 ? ? ? ?95.47
> 2007-01-18 ? ?99.80 ? ?99.95 ? 98.91 ? ? 99.45 ? 14725000 ? ? ? ?94.92
> 2007-01-19 ? ?95.00 ? ?96.85 ? 94.55 ? ? 96.17 ? 26035800 ? ? ? ?91.79
> 2007-01-22 ? ?96.42 ? ?97.23 ? 96.12 ? ? 97.11 ? 13539300 ? ? ? ?92.69
> 2007-01-23 ? ?96.91 ? ?97.38 ? 96.20 ? ? 97.08 ? 10337400 ? ? ? ?92.66
> 2007-01-24 ? ?97.08 ? ?97.58 ? 96.58 ? ? 97.40 ? ?5700000 ? ? ? ?92.96
> 2007-01-25 ? ?97.22 ? ?97.92 ? 97.22 ? ? 97.51 ? ?6201300 ? ? ? ?93.07
> 2007-01-26 ? ?97.52 ? ?97.83 ? 96.84 ? ? 97.45 ? ?5771100 ? ? ? ?93.01
> 2007-01-29 ? ?97.70 ? ?98.66 ? 97.45 ? ? 98.54 ? ?7294800 ? ? ? ?94.05
> 2007-01-30 ? ?98.57 ? ?99.45 ? 98.50 ? ? 99.37 ? ?7177900 ? ? ? ?94.84
> 2007-01-31 ? ?98.80 ? ?99.48 ? 98.35 ? ? 99.15 ? ?6432600 ? ? ? ?94.63
>> F
> ? ? ? ? ? F.Open F.High F.Low F.Close ?F.Volume F.Adjusted
> 2007-01-03 ? 7.56 ? 7.67 ?7.44 ? ?7.51 ?78652200 ? ? ? 7.51
> 2007-01-04 ? 7.56 ? 7.72 ?7.43 ? ?7.70 ?63454900 ? ? ? 7.70
> 2007-01-05 ? 7.72 ? 7.75 ?7.57 ? ?7.62 ?40562100 ? ? ? 7.62
> 2007-01-08 ? 7.63 ? 7.75 ?7.62 ? ?7.73 ?48938500 ? ? ? 7.73
> 2007-01-09 ? 7.75 ? 7.86 ?7.73 ? ?7.79 ?56732200 ? ? ? 7.79
> 2007-01-10 ? 7.79 ? 7.79 ?7.67 ? ?7.73 ?42397100 ? ? ? 7.73
> 2007-01-11 ? 7.73 ? 7.80 ?7.68 ? ?7.77 ?40020800 ? ? ? 7.77
> 2007-01-12 ? 7.77 ? 7.92 ?7.76 ? ?7.89 ?57053800 ? ? ? 7.89
> 2007-01-16 ? 7.89 ? 8.01 ?7.87 ? ?7.94 ?66699800 ? ? ? 7.94
> 2007-01-17 ? 7.97 ? 8.10 ?7.97 ? ?8.04 ?63728700 ? ? ? 8.04
> 2007-01-18 ? 8.06 ? 8.24 ?8.06 ? ?8.18 ?78375700 ? ? ? 8.18
> 2007-01-19 ? 8.24 ? 8.32 ?8.17 ? ?8.30 ?66023300 ? ? ? 8.30
> 2007-01-22 ? 8.33 ? 8.43 ?8.25 ? ?8.41 ?53554600 ? ? ? 8.41
> 2007-01-23 ? 8.39 ? 8.62 ?8.24 ? ?8.30 116406900 ? ? ? 8.30
> 2007-01-24 ? 8.31 ? 8.35 ?8.11 ? ?8.20 ?76821900 ? ? ? 8.20
> 2007-01-25 ? 8.15 ? 8.52 ?8.00 ? ?8.22 ?99688700 ? ? ? 8.22
> 2007-01-26 ? 8.15 ? 8.48 ?8.14 ? ?8.42 ?54421900 ? ? ? 8.42
> 2007-01-29 ? 8.44 ? 8.51 ?8.35 ? ?8.37 ?55791000 ? ? ? 8.37
> 2007-01-30 ? 8.38 ? 8.42 ?8.19 ? ?8.20 ?28763200 ? ? ? 8.20
> 2007-01-31 ? 8.17 ? 8.20 ?8.04 ? ?8.13 ?65038600 ? ? ? 8.13
>> MMM
> ? ? ? ? ? MMM.Open MMM.High MMM.Low MMM.Close MMM.Volume MMM.Adjusted
> 2007-01-03 ? ?77.53 ? ?78.85 ? 77.38 ? ? 78.26 ? ?3781500 ? ? ? ?72.40
> 2007-01-04 ? ?78.40 ? ?78.41 ? 77.45 ? ? 77.95 ? ?2968400 ? ? ? ?72.11
> 2007-01-05 ? ?77.89 ? ?77.90 ? 77.01 ? ? 77.42 ? ?2765200 ? ? ? ?71.62
> 2007-01-08 ? ?77.42 ? ?78.04 ? 76.97 ? ? 77.59 ? ?2434500 ? ? ? ?71.78
> 2007-01-09 ? ?78.00 ? ?78.23 ? 77.44 ? ? 77.68 ? ?1896800 ? ? ? ?71.86
> 2007-01-10 ? ?77.31 ? ?77.96 ? 77.04 ? ? 77.85 ? ?1787500 ? ? ? ?72.02
> 2007-01-11 ? ?78.05 ? ?79.03 ? 77.88 ? ? 78.65 ? ?2372500 ? ? ? ?72.76
> 2007-01-12 ? ?78.41 ? ?79.50 ? 78.22 ? ? 79.36 ? ?2582200 ? ? ? ?73.42
> 2007-01-16 ? ?79.48 ? ?79.62 ? 78.92 ? ? 79.56 ? ?2526600 ? ? ? ?73.60
> 2007-01-17 ? ?79.33 ? ?79.51 ? 78.75 ? ? 78.91 ? ?2711300 ? ? ? ?73.00
> 2007-01-18 ? ?78.71 ? ?79.70 ? 78.60 ? ? 78.81 ? ?1963000 ? ? ? ?72.91
> 2007-01-19 ? ?79.09 ? ?79.88 ? 78.82 ? ? 79.25 ? ?2912100 ? ? ? ?73.32
> 2007-01-22 ? ?79.25 ? ?79.29 ? 78.13 ? ? 78.49 ? ?2139300 ? ? ? ?72.61
> 2007-01-23 ? ?78.71 ? ?79.15 ? 78.33 ? ? 78.85 ? ?1949500 ? ? ? ?72.95
> 2007-01-24 ? ?78.85 ? ?79.66 ? 78.85 ? ? 79.49 ? ?1772700 ? ? ? ?73.54
> 2007-01-25 ? ?79.56 ? ?79.75 ? 78.83 ? ? 79.01 ? ?2888700 ? ? ? ?73.09
> 2007-01-26 ? ?78.97 ? ?79.19 ? 78.23 ? ? 78.69 ? ?1996300 ? ? ? ?72.80
> 2007-01-29 ? ?78.54 ? ?79.20 ? 78.25 ? ? 78.96 ? ?3420300 ? ? ? ?73.05
> 2007-01-30 ? ?74.92 ? ?76.18 ? 74.24 ? ? 74.70 ? 15657900 ? ? ? ?69.11
> 2007-01-31 ? ?74.21 ? ?74.68 ? 73.09 ? ? 74.30 ? ?9284500 ? ? ? ?68.74
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From breman.mark at gmail.com  Wed Oct 14 10:39:54 2009
From: breman.mark at gmail.com (Mark Breman)
Date: Wed, 14 Oct 2009 10:39:54 +0200
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
Message-ID: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091014/a93c3082/attachment.pl>

From aleks.clark at gmail.com  Wed Oct 14 10:45:13 2009
From: aleks.clark at gmail.com (Aleks Clark)
Date: Wed, 14 Oct 2009 03:45:13 -0500
Subject: [R-SIG-Finance] Evaluating equity curves
In-Reply-To: <SANCTUMFISERVERA3Ix00004307@sanctumfi.com>
References: <5aebc8960910111547kf94e314q6530b607124bad7e@mail.gmail.com>
	<4AD27C81.1010901@braverock.com>
	<SANCTUMFISERVERICNP0000422c@sanctumfi.com>
	<SANCTUMFISERVERA3Ix00004307@sanctumfi.com>
Message-ID: <5aebc8960910140145n41204207q2ad52249eaf30396@mail.gmail.com>

Well, the reasoning went like this...since I can instantly look at a
equity curve and say 'hey that's a nice steady upward slope' as
opposed to "wow that's a jaggy one with lots of drawdowns", I thought
to apply some sort of maths to turn this gestalt into a number that
could be taken along with the final balance as a measure of fitness,
thus the applying of splines. Now that you mention it however, there
are probably better ways of evaluating these strategies that aren't
'graphical' in nature.

On Mon, Oct 12, 2009 at 6:45 AM, Robert Sams <robert at sanctumfi.com> wrote:
> Quite right, Ralph. More precisely: any series of cumulative returns
> plotted against time on a 2d chart is, *by definition*, an equity curve.
>
>
> Aleks, I'm not sure you're after. To me, the return series of a trading
> strategy isn't 'evaluated' per se, it's evaluated with respect to some
> specific questions or conjectures you have regarding it. Articulating
> this is logically prior to choosing the appropriate mathematical
> technique.
>
> If you can be more specific, we might be able to point you in the right
> direction.
>
> Robert
>
>> -----Original Message-----
>> From: r-sig-finance-bounces at stat.math.ethz.ch
>> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of R. Vince
>> Sent: 12 October 2009 02:06
>> To: Brian G. Peterson; Aleks Clark
>> Cc: r-sig-finance at stat.math.ethz.ch
>> Subject: Re: [R-SIG-Finance] Evaluating equity curves
>>
>> Brian,
>>
>> Isn't any stream of cumulative returns, de facto, an equity
>> curve? Or am I misunderstanding this? Thanks, Ralph Vince
>>
>> ----- Original Message -----
>> From: "Brian G. Peterson" <brian at braverock.com>
>> To: "Aleks Clark" <aleks.clark at gmail.com>
>> Cc: <r-sig-finance at stat.math.ethz.ch>
>> Sent: Sunday, October 11, 2009 8:46 PM
>> Subject: Re: [R-SIG-Finance] Evaluating equity curves
>>
>>
>> > Aleks Clark wrote:
>> >> As part of a project I'm working on that uses genetic algorithms to
>> >> optimize trading parameters, I find myself seeking a way
>> to evaluate
>> >> the equity curve that results from a given set of trading rules. It
>> >> seems to be an obvious area of research, so I was wondering what's
>> >> available in R-land or just in the world of finance in
>> general. I've
>> >> poked around with splines as a way to express how 'nice' an equity
>> >> curve is (steady upward rise as opposed to a "jagged" line), but I
>> >> feel that there are probably better ways to do things...
>> >
>> > Having worked both in quantitative trading and in more
>> traditional asset
>> > management roles, I've never quite understood the
>> artificial distinction
>> > between "equity curves" and any other kind of returns. ?In
>> my experience,
>> > all the usual performance and risk analysis tools (amply
>> provided for in
>> > R) as well as attribution (e.g. Bacon, much of which is
>> implemented in
>> > fPortfolio) are equally applicable to trading strategies as
>> they are to
>> > more traditional investment. ?Also see Pat Burns' paper on
>> evaluatinfg
>> > trading strategies for additional ideas.
>> >
>> > Regards,
>> >
>> > ? - Brian
>> >
>> > _______________________________________________
>> > R-SIG-Finance at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only.
>> > -- If you want to post, subscribe first.
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>



-- 
Aleks Clark


From patrick at burns-stat.com  Wed Oct 14 11:26:13 2009
From: patrick at burns-stat.com (Patrick Burns)
Date: Wed, 14 Oct 2009 10:26:13 +0100
Subject: [R-SIG-Finance] Evaluating equity curves
In-Reply-To: <5aebc8960910140145n41204207q2ad52249eaf30396@mail.gmail.com>
References: <5aebc8960910111547kf94e314q6530b607124bad7e@mail.gmail.com>	<4AD27C81.1010901@braverock.com>	<SANCTUMFISERVERICNP0000422c@sanctumfi.com>	<SANCTUMFISERVERA3Ix00004307@sanctumfi.com>
	<5aebc8960910140145n41204207q2ad52249eaf30396@mail.gmail.com>
Message-ID: <4AD59935.6080000@burns-stat.com>

A traditional measure is the information
ratio.



Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of "The R Inferno" and "A Guide for the Unwilling S User")

Aleks Clark wrote:
> Well, the reasoning went like this...since I can instantly look at a
> equity curve and say 'hey that's a nice steady upward slope' as
> opposed to "wow that's a jaggy one with lots of drawdowns", I thought
> to apply some sort of maths to turn this gestalt into a number that
> could be taken along with the final balance as a measure of fitness,
> thus the applying of splines. Now that you mention it however, there
> are probably better ways of evaluating these strategies that aren't
> 'graphical' in nature.
> 
> On Mon, Oct 12, 2009 at 6:45 AM, Robert Sams <robert at sanctumfi.com> wrote:
>> Quite right, Ralph. More precisely: any series of cumulative returns
>> plotted against time on a 2d chart is, *by definition*, an equity curve.
>>
>>
>> Aleks, I'm not sure you're after. To me, the return series of a trading
>> strategy isn't 'evaluated' per se, it's evaluated with respect to some
>> specific questions or conjectures you have regarding it. Articulating
>> this is logically prior to choosing the appropriate mathematical
>> technique.
>>
>> If you can be more specific, we might be able to point you in the right
>> direction.
>>
>> Robert
>>
>>> -----Original Message-----
>>> From: r-sig-finance-bounces at stat.math.ethz.ch
>>> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of R. Vince
>>> Sent: 12 October 2009 02:06
>>> To: Brian G. Peterson; Aleks Clark
>>> Cc: r-sig-finance at stat.math.ethz.ch
>>> Subject: Re: [R-SIG-Finance] Evaluating equity curves
>>>
>>> Brian,
>>>
>>> Isn't any stream of cumulative returns, de facto, an equity
>>> curve? Or am I misunderstanding this? Thanks, Ralph Vince
>>>
>>> ----- Original Message -----
>>> From: "Brian G. Peterson" <brian at braverock.com>
>>> To: "Aleks Clark" <aleks.clark at gmail.com>
>>> Cc: <r-sig-finance at stat.math.ethz.ch>
>>> Sent: Sunday, October 11, 2009 8:46 PM
>>> Subject: Re: [R-SIG-Finance] Evaluating equity curves
>>>
>>>
>>>> Aleks Clark wrote:
>>>>> As part of a project I'm working on that uses genetic algorithms to
>>>>> optimize trading parameters, I find myself seeking a way
>>> to evaluate
>>>>> the equity curve that results from a given set of trading rules. It
>>>>> seems to be an obvious area of research, so I was wondering what's
>>>>> available in R-land or just in the world of finance in
>>> general. I've
>>>>> poked around with splines as a way to express how 'nice' an equity
>>>>> curve is (steady upward rise as opposed to a "jagged" line), but I
>>>>> feel that there are probably better ways to do things...
>>>> Having worked both in quantitative trading and in more
>>> traditional asset
>>>> management roles, I've never quite understood the
>>> artificial distinction
>>>> between "equity curves" and any other kind of returns.  In
>>> my experience,
>>>> all the usual performance and risk analysis tools (amply
>>> provided for in
>>>> R) as well as attribution (e.g. Bacon, much of which is
>>> implemented in
>>>> fPortfolio) are equally applicable to trading strategies as
>>> they are to
>>>> more traditional investment.  Also see Pat Burns' paper on
>>> evaluatinfg
>>>> trading strategies for additional ideas.
>>>>
>>>> Regards,
>>>>
>>>>   - Brian
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only.
>>>> -- If you want to post, subscribe first.
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
> 
> 
>


From patrick at burns-stat.com  Wed Oct 14 11:34:18 2009
From: patrick at burns-stat.com (Patrick Burns)
Date: Wed, 14 Oct 2009 10:34:18 +0100
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
Message-ID: <4AD59B1A.5080001@burns-stat.com>

You might get different answers, but
I think you are essentially asking
the impossible.  You might be able
to estimate P, but estimates will be
very noisy.  With any strategy sometimes
the market agrees with the strategy
and sometimes it doesn't.

A friend told me about hearing a talk
on a strategy that did very well over
the last 60 or 70 years.  My friend
raised his hand and pointed out that
the strategy lost money for about
40 years, so the speaker may not have
been in business any more to take
advantage of the big gains later.

What you care about is P in the immediate
future.  That's a hard problem.



Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of "The R Inferno" and "A Guide for the Unwilling S User")

Mark Breman wrote:
> Hello,
> In "The mathematics of money management" by Ralph Vince there is a formula
> for calculating the Mathematical Expectation of a game (in R pseudo code):
> 
> ME  =  for(i in 1:N) { Pi * Ai}
> 
> where
> P = Probability of winning or losing
> A = Amount won or lost
> N = Number of possible outcomes.
> 
> Or in text: "Mathematical expectation is the amount you expect to make or
> lose, on average, each bet".
> 
> Now suppose I want to know the Mathematical expectation of a trading system.
> 
> I have a series of trade returns:
> 
>> trades$PnL
>  [1]  -5.75  10.00  -1.25  96.00 -16.00 -35.00  29.00 -18.25  -2.25 -10.25
> -21.75  -5.50   8.50 -20.50  -6.00  14.25  18.00
> [18]   3.75  -4.25  24.00  17.75  -9.50  11.25 -33.75   6.25 -28.00   1.00
>  36.75  14.00 -30.75  -0.50   6.75  19.25   5.25
> [35] -10.00 -23.25   9.25  11.00 -33.00 -19.00 -17.50  -5.50  -5.75  -8.50
> -24.50 -24.00   2.25  -1.00   0.75  -1.75  -2.25
> [52]   9.25  15.00  -2.25  -6.75   5.25  -4.75 -10.00  -2.00  63.50 -18.00
> -18.00  58.00  -8.75   1.00 -36.75 -23.50 -64.00
> [69] -15.75 -10.00 -34.75  27.75 -57.00 204.75 -45.00 -71.00 133.75
> 
> So I have A = trades$PnL and N=77, but how do I calculate P?
> 
> -Mark-
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
>


From nordicgnome at gmail.com  Wed Oct 14 15:15:30 2009
From: nordicgnome at gmail.com (Jan Vandermeer)
Date: Wed, 14 Oct 2009 09:15:30 -0400
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <e8e755250910131927l219db436h7a167439dbc40bc1@mail.gmail.com>
References: <e64efa440910131922v544b941diaea9bb7ce400fe6b@mail.gmail.com>
	<e8e755250910131927l219db436h7a167439dbc40bc1@mail.gmail.com>
Message-ID: <e64efa440910140615j431ce6c9s3a9e1cae0b29059f@mail.gmail.com>

Hi Jeff;

Thanks for your speedy reply. I thought that I had a relatively up to
date R repository, kind of just short of SVN but updating to the
packages on R-forge, xts_0.6.8 and quantmod_0.3-12 allowed a clean
run.

I guess I was not living as close to the bleeding edge as I thought.

Jan

On Tue, Oct 13, 2009 at 10:27 PM, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:
> Try installing the latest versions of xts and quantmod as well. ?As
> blotter is under development, it is best to update all the
> dependencies as well.
>
> In this case, I think that should solve your problem.
>
> Best,
> Jeff
>
> On Tue, Oct 13, 2009 at 9:22 PM, Jan Vandermeer <nordicgnome at gmail.com> wrote:
>> Hi all;
>>
>> I've been following the discussion here on backtesting
>> ([R-SIG-Finance] Backtesting framework package -
>> <https://stat.ethz.ch/pipermail/r-sig-finance/2009q2/004404.html> and
>> the discussion ?[R-SIG-Finance] QuantMod trading models docs?
>> initiated by Mark Knecht and decided to give the blotter package a
>> try.
>> I tried running ?through the example provided by the blotter package.
>> </usr/lib64/R/library/blotter/html/blotter-package.html>
>> I installed the latest version from R-forge. I am running R version
>> 2.9.1 (2009-06-26) on an AMD Turion 64 with a Gentoo 2.6.31 kernel.
>>
>> Things ran smoothly as shown below until I got to the "p =
>> updatePortf(p,'2007-01')" step, where R kicked out
>>
>> "Error in if (mid != 0 && key < vec[mid]) { :
>> ?missing value where TRUE/FALSE needed".
>>
>> So I went along and looked at the
>> "/usr/lib64/R/library/blotter/html/00Index.html", which sent me along
>> to "/usr/lib64/R/library/blotter/html/updatePosPL.html" and attempted
>> to adjust some of the values because the usage seems to indicate that
>> additional values may be required
>>
>> "Usage
>> updatePosPL(Portfolio, Symbol, StartDate, EndDate, Prices = Cl(get(Symbol)))
>> updatePortf(Portfolio, StartDate, EndDate)"
>>
>> I added an EndDate using the same format as in the getSymbols command.
>> and received the following error.
>>
>>> p = updatePortf(p,'2007-01-01`, '2007-01-31')
>> Error: unexpected numeric constant in "p = updatePortf(p,'2007-01-01`, '2007"
>>
>>
>> I tried a couple of variations on the updatePosPL()
>>
>>> updatePosPL(p, "IBM", '2007-01-01', '2007-01-31', Prices = Cl(get(Symbol)))
>> Error in updatePosPL(p, "IBM", "2007-01-01", "2007-01-31", Prices =
>> Cl(get(Symbol))) :
>> ?unused argument(s) ("2007-01-31")
>>> updatePosPL(p, "IBM", '2007-01-01', '2007-01-31', Prices = Cl(get(Symbol)))
>> Error in updatePosPL(p, "IBM", "2007-01-01", "2007-01-31", Prices =
>> Cl(get(Symbol))) :
>> ?unused argument(s) ("2007-01-31")
>>> updatePosPL(p, "IBM", '2007-01-01', Prices = Cl(get(Symbol)))
>> Error in get(Symbol) : object 'Symbol' not found
>>> updatePosPL(p, "IBM", '2007-01-01', Prices = Cl(get(symbol)))
>> Error in get(symbol) : object 'symbol' not found
>>
>> I also tried:
>>> updatePosPL(p, "IBM", '2007-01-01', Prices = Cl(IBM))
>> Error in if (any(i < 0)) { : missing value where TRUE/FALSE needed
>>
>>
>> At this point I am at a bit of a loss. I tried looking through some of
>> the stuff on R-Project to see if there are guidelines for code
>> examples and where and if they should work. I guess I would expect the
>> code examples include in the library or
>> "/usr/lib64/R/library/blotter/R-ex" to just work.
>>
>> So, I am I doing something glaringly wrong? Do I need to update my
>> version of R, xts, zoo or quantmod? I know I am on still on the steep
>> part of the learning curve as far as R in general is concerned and
>> specifically with time series and financial data with R but R texts
>> I've seen suggest that working through examples with real data and
>> known steps is a great way to learn. Successfully working through
>> examples allows one small sign posts of success along the way
>>
>> Any assistance would be appreciated.
>>
>> Jan
>>
>>
>>
>> Blotter example entered into R and responses after the first _________
>>
>> I tried looking at the output for "p", see below the second ______. It
>> appears to be included in the data.frame
>>
>> Values obtained through quantmod are below the third _______
>>
>> ________________________________
>>> library(blotter)
>> Loading required package: xts
>> Loading required package: zoo
>>
>> Attaching package: 'zoo'
>>
>>
>> ? ? ? ?The following object(s) are masked from package:base :
>>
>> ? ? ? ? as.Date.numeric
>>
>> xts now requires a valid TZ environment variable to be set
>> ?no TZ var is set, setting to TZ=GMT
>>> symbols = c("IBM","F","MMM")
>>> require(quantmod)
>> Loading required package: quantmod
>> Loading required package: Defaults
>> Loading required package: TTR
>>> getSymbols(symbols, from='2007-01-01', to='2007-01-31', index.class="POSIXct")
>> [1] "IBM" "F" ? "MMM"
>>> print('Creating portfolio \"p\"...')
>> [1] "Creating portfolio \"p\"..."
>>> p = initPortf(symbols=symbols)
>>> print('Adding trades to \"p\"...')
>> [1] "Adding trades to \"p\"..."
>>> # Make a couple of trades in IBM
>>> p = addTxn(p, "IBM", '2007-01-03', 50, 96.5, -0.05*50)
>> [1] "IBM 2007-01-03 50 @ 96.5"
>>> p = addTxn(p, "IBM", '2007-01-04', 50, 97.1, -0.05*50)
>> [1] "IBM 2007-01-04 50 @ 97.1"
>>> # ...a few in F.
>>> p = addTxn(p, "F", '2007-01-03', -100, 7.60, -0.05*100)
>> [1] "F 2007-01-03 -100 @ 7.6"
>>> p = addTxn(p, "F", '2007-01-04', 50, 7.70, -0.05*50)
>> [1] "F 2007-01-04 50 @ 7.7"
>>> p = addTxn(p, "F", '2007-01-10', 50, 7.78, -0.05*50)
>> [1] "F 2007-01-10 50 @ 7.78"
>>> # ...and some in MMM
>>> p = addTxn(p, "MMM", '2007-01-05', -50, 77.9, -0.05*50)
>> [1] "MMM 2007-01-05 -50 @ 77.9"
>>> p = addTxn(p, "MMM", '2007-01-08', 50, 77.6, -0.05*50)
>> [1] "MMM 2007-01-08 50 @ 77.6"
>>> p = addTxn(p, "MMM", '2007-01-09', 50, 77.6, -0.05*50)
>> [1] "MMM 2007-01-09 50 @ 77.6"
>> ___________
>>
>>
>> It appears that the transactions have been posted correctly
>>
>>> p
>> $IBM
>> $IBM$txn
>> ? ? ? ? ? Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty
>> 1950-01-01 ? ? ? 0 ? ? ? 0.0 ? ? ?0.0 ? ? ? 0.0 ? ? ? ? 0.00 ? ? ? 0
>> 2007-01-03 ? ? ?50 ? ? ?96.5 ? ? -2.5 ? ?4827.5 ? ? ? ?96.55 ? ? ?50
>> 2007-01-04 ? ? ?50 ? ? ?97.1 ? ? -2.5 ? ?4857.5 ? ? ? ?97.15 ? ? 100
>> ? ? ? ? ? Pos.Avg.Cost Realized.PL
>> 1950-01-01 ? ? ? ? 0.00 ? ? ? ? ? 0
>> 2007-01-03 ? ? ? ?96.55 ? ? ? ? ? 0
>> 2007-01-04 ? ? ? ?96.85 ? ? ? ? ? 0
>>
>> $IBM$posPL
>> ? ? ? ? ? Pos.Qty Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL
>> 1950-01-01 ? ? ? 0 ? ? ? ? 0 ? ? ? ? 0 ? ? ? ?0 ? ? ? ? ? 0 ? ? ? ? ? ? 0
>> ? ? ? ? ? Trading.PL
>> 1950-01-01 ? ? ? ? ?0
>>
>>
>> $F
>> $F$txn
>> ? ? ? ? ? Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty
>> 1950-01-01 ? ? ? 0 ? ? ?0.00 ? ? ?0.0 ? ? ? 0.0 ? ? ? ? 0.00 ? ? ? 0
>> 2007-01-03 ? ?-100 ? ? ?7.60 ? ? -5.0 ? ?-755.0 ? ? ? ? 7.55 ? ?-100
>> 2007-01-04 ? ? ?50 ? ? ?7.70 ? ? -2.5 ? ? 387.5 ? ? ? ? 7.75 ? ? -50
>> 2007-01-10 ? ? ?50 ? ? ?7.78 ? ? -2.5 ? ? 391.5 ? ? ? ? 7.83 ? ? ? 0
>> ? ? ? ? ? Pos.Avg.Cost Realized.PL
>> 1950-01-01 ? ? ? ? 0.00 ? ? ? ? ? 0
>> 2007-01-03 ? ? ? ? 7.55 ? ? ? ? ? 0
>> 2007-01-04 ? ? ? ? 7.35 ? ? ? ? -10
>> 2007-01-10 ? ? ? ? 0.00 ? ? ? ? -24
>>
>> $F$posPL
>> ? ? ? ? ? Pos.Qty Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL
>> 1950-01-01 ? ? ? 0 ? ? ? ? 0 ? ? ? ? 0 ? ? ? ?0 ? ? ? ? ? 0 ? ? ? ? ? ? 0
>> ? ? ? ? ? Trading.PL
>> 1950-01-01 ? ? ? ? ?0
>>
>>
>> $MMM
>> $MMM$txn
>> ? ? ? ? ? Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty
>> 1950-01-01 ? ? ? 0 ? ? ? 0.0 ? ? ?0.0 ? ? ? 0.0 ? ? ? ? 0.00 ? ? ? 0
>> 2007-01-05 ? ? -50 ? ? ?77.9 ? ? -2.5 ? -3892.5 ? ? ? ?77.85 ? ? -50
>> 2007-01-08 ? ? ?50 ? ? ?77.6 ? ? -2.5 ? ?3882.5 ? ? ? ?77.65 ? ? ? 0
>> 2007-01-09 ? ? ?50 ? ? ?77.6 ? ? -2.5 ? ?3882.5 ? ? ? ?77.65 ? ? ?50
>> ? ? ? ? ? Pos.Avg.Cost Realized.PL
>> 1950-01-01 ? ? ? ? 0.00 ? ? ? ? ? 0
>> 2007-01-05 ? ? ? ?77.85 ? ? ? ? ? 0
>> 2007-01-08 ? ? ? ? 0.00 ? ? ? ? ?10
>> 2007-01-09 ? ? ? ?77.65 ? ? ? ? ? 0
>>
>> $MMM$posPL
>> ? ? ? ? ? Pos.Qty Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL
>> 1950-01-01 ? ? ? 0 ? ? ? ? 0 ? ? ? ? 0 ? ? ? ?0 ? ? ? ? ? 0 ? ? ? ? ? ? 0
>> ? ? ? ? ? Trading.PL
>> 1950-01-01
>>
>> _________________________________________
>>
>>> IBM
>> ? ? ? ? ? IBM.Open IBM.High IBM.Low IBM.Close IBM.Volume IBM.Adjusted
>> 2007-01-03 ? ?97.18 ? ?98.40 ? 96.26 ? ? 97.27 ? ?9196800 ? ? ? ?92.84
>> 2007-01-04 ? ?97.25 ? ?98.79 ? 96.88 ? ? 98.31 ? 10524500 ? ? ? ?93.83
>> 2007-01-05 ? ?97.60 ? ?97.95 ? 96.91 ? ? 97.42 ? ?7221300 ? ? ? ?92.98
>> 2007-01-08 ? ?98.50 ? ?99.50 ? 98.35 ? ? 98.90 ? 10340000 ? ? ? ?94.40
>> 2007-01-09 ? ?99.08 ? 100.33 ? 99.07 ? ?100.07 ? 11108200 ? ? ? ?95.51
>> 2007-01-10 ? ?98.50 ? ?99.05 ? 97.93 ? ? 98.89 ? ?8744800 ? ? ? ?94.39
>> 2007-01-11 ? ?99.00 ? ?99.90 ? 98.50 ? ? 98.65 ? ?8000700 ? ? ? ?94.16
>> 2007-01-12 ? ?98.99 ? ?99.69 ? 98.50 ? ? 99.34 ? ?6636500 ? ? ? ?94.82
>> 2007-01-16 ? ?99.40 ? 100.84 ? 99.30 ? ?100.82 ? ?9602200 ? ? ? ?96.23
>> 2007-01-17 ? 100.69 ? 100.90 ? 99.90 ? ?100.02 ? ?8200700 ? ? ? ?95.47
>> 2007-01-18 ? ?99.80 ? ?99.95 ? 98.91 ? ? 99.45 ? 14725000 ? ? ? ?94.92
>> 2007-01-19 ? ?95.00 ? ?96.85 ? 94.55 ? ? 96.17 ? 26035800 ? ? ? ?91.79
>> 2007-01-22 ? ?96.42 ? ?97.23 ? 96.12 ? ? 97.11 ? 13539300 ? ? ? ?92.69
>> 2007-01-23 ? ?96.91 ? ?97.38 ? 96.20 ? ? 97.08 ? 10337400 ? ? ? ?92.66
>> 2007-01-24 ? ?97.08 ? ?97.58 ? 96.58 ? ? 97.40 ? ?5700000 ? ? ? ?92.96
>> 2007-01-25 ? ?97.22 ? ?97.92 ? 97.22 ? ? 97.51 ? ?6201300 ? ? ? ?93.07
>> 2007-01-26 ? ?97.52 ? ?97.83 ? 96.84 ? ? 97.45 ? ?5771100 ? ? ? ?93.01
>> 2007-01-29 ? ?97.70 ? ?98.66 ? 97.45 ? ? 98.54 ? ?7294800 ? ? ? ?94.05
>> 2007-01-30 ? ?98.57 ? ?99.45 ? 98.50 ? ? 99.37 ? ?7177900 ? ? ? ?94.84
>> 2007-01-31 ? ?98.80 ? ?99.48 ? 98.35 ? ? 99.15 ? ?6432600 ? ? ? ?94.63
>>> F
>> ? ? ? ? ? F.Open F.High F.Low F.Close ?F.Volume F.Adjusted
>> 2007-01-03 ? 7.56 ? 7.67 ?7.44 ? ?7.51 ?78652200 ? ? ? 7.51
>> 2007-01-04 ? 7.56 ? 7.72 ?7.43 ? ?7.70 ?63454900 ? ? ? 7.70
>> 2007-01-05 ? 7.72 ? 7.75 ?7.57 ? ?7.62 ?40562100 ? ? ? 7.62
>> 2007-01-08 ? 7.63 ? 7.75 ?7.62 ? ?7.73 ?48938500 ? ? ? 7.73
>> 2007-01-09 ? 7.75 ? 7.86 ?7.73 ? ?7.79 ?56732200 ? ? ? 7.79
>> 2007-01-10 ? 7.79 ? 7.79 ?7.67 ? ?7.73 ?42397100 ? ? ? 7.73
>> 2007-01-11 ? 7.73 ? 7.80 ?7.68 ? ?7.77 ?40020800 ? ? ? 7.77
>> 2007-01-12 ? 7.77 ? 7.92 ?7.76 ? ?7.89 ?57053800 ? ? ? 7.89
>> 2007-01-16 ? 7.89 ? 8.01 ?7.87 ? ?7.94 ?66699800 ? ? ? 7.94
>> 2007-01-17 ? 7.97 ? 8.10 ?7.97 ? ?8.04 ?63728700 ? ? ? 8.04
>> 2007-01-18 ? 8.06 ? 8.24 ?8.06 ? ?8.18 ?78375700 ? ? ? 8.18
>> 2007-01-19 ? 8.24 ? 8.32 ?8.17 ? ?8.30 ?66023300 ? ? ? 8.30
>> 2007-01-22 ? 8.33 ? 8.43 ?8.25 ? ?8.41 ?53554600 ? ? ? 8.41
>> 2007-01-23 ? 8.39 ? 8.62 ?8.24 ? ?8.30 116406900 ? ? ? 8.30
>> 2007-01-24 ? 8.31 ? 8.35 ?8.11 ? ?8.20 ?76821900 ? ? ? 8.20
>> 2007-01-25 ? 8.15 ? 8.52 ?8.00 ? ?8.22 ?99688700 ? ? ? 8.22
>> 2007-01-26 ? 8.15 ? 8.48 ?8.14 ? ?8.42 ?54421900 ? ? ? 8.42
>> 2007-01-29 ? 8.44 ? 8.51 ?8.35 ? ?8.37 ?55791000 ? ? ? 8.37
>> 2007-01-30 ? 8.38 ? 8.42 ?8.19 ? ?8.20 ?28763200 ? ? ? 8.20
>> 2007-01-31 ? 8.17 ? 8.20 ?8.04 ? ?8.13 ?65038600 ? ? ? 8.13
>>> MMM
>> ? ? ? ? ? MMM.Open MMM.High MMM.Low MMM.Close MMM.Volume MMM.Adjusted
>> 2007-01-03 ? ?77.53 ? ?78.85 ? 77.38 ? ? 78.26 ? ?3781500 ? ? ? ?72.40
>> 2007-01-04 ? ?78.40 ? ?78.41 ? 77.45 ? ? 77.95 ? ?2968400 ? ? ? ?72.11
>> 2007-01-05 ? ?77.89 ? ?77.90 ? 77.01 ? ? 77.42 ? ?2765200 ? ? ? ?71.62
>> 2007-01-08 ? ?77.42 ? ?78.04 ? 76.97 ? ? 77.59 ? ?2434500 ? ? ? ?71.78
>> 2007-01-09 ? ?78.00 ? ?78.23 ? 77.44 ? ? 77.68 ? ?1896800 ? ? ? ?71.86
>> 2007-01-10 ? ?77.31 ? ?77.96 ? 77.04 ? ? 77.85 ? ?1787500 ? ? ? ?72.02
>> 2007-01-11 ? ?78.05 ? ?79.03 ? 77.88 ? ? 78.65 ? ?2372500 ? ? ? ?72.76
>> 2007-01-12 ? ?78.41 ? ?79.50 ? 78.22 ? ? 79.36 ? ?2582200 ? ? ? ?73.42
>> 2007-01-16 ? ?79.48 ? ?79.62 ? 78.92 ? ? 79.56 ? ?2526600 ? ? ? ?73.60
>> 2007-01-17 ? ?79.33 ? ?79.51 ? 78.75 ? ? 78.91 ? ?2711300 ? ? ? ?73.00
>> 2007-01-18 ? ?78.71 ? ?79.70 ? 78.60 ? ? 78.81 ? ?1963000 ? ? ? ?72.91
>> 2007-01-19 ? ?79.09 ? ?79.88 ? 78.82 ? ? 79.25 ? ?2912100 ? ? ? ?73.32
>> 2007-01-22 ? ?79.25 ? ?79.29 ? 78.13 ? ? 78.49 ? ?2139300 ? ? ? ?72.61
>> 2007-01-23 ? ?78.71 ? ?79.15 ? 78.33 ? ? 78.85 ? ?1949500 ? ? ? ?72.95
>> 2007-01-24 ? ?78.85 ? ?79.66 ? 78.85 ? ? 79.49 ? ?1772700 ? ? ? ?73.54
>> 2007-01-25 ? ?79.56 ? ?79.75 ? 78.83 ? ? 79.01 ? ?2888700 ? ? ? ?73.09
>> 2007-01-26 ? ?78.97 ? ?79.19 ? 78.23 ? ? 78.69 ? ?1996300 ? ? ? ?72.80
>> 2007-01-29 ? ?78.54 ? ?79.20 ? 78.25 ? ? 78.96 ? ?3420300 ? ? ? ?73.05
>> 2007-01-30 ? ?74.92 ? ?76.18 ? 74.24 ? ? 74.70 ? 15657900 ? ? ? ?69.11
>> 2007-01-31 ? ?74.21 ? ?74.68 ? 73.09 ? ? 74.30 ? ?9284500 ? ? ? ?68.74
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>
>
>
> --
> Jeffrey Ryan
> jeffrey.ryan at insightalgo.com
>
> ia: insight algorithmics
> www.insightalgo.com
>


From nordicgnome at gmail.com  Wed Oct 14 15:22:54 2009
From: nordicgnome at gmail.com (Jan Vandermeer)
Date: Wed, 14 Oct 2009 09:22:54 -0400
Subject: [R-SIG-Finance] Blotter package - problem with example (Jan
	Vandermeer)
In-Reply-To: <110cbaf80910140534x42250266w9284aee9d2fc0ca8@mail.gmail.com>
References: <110cbaf80910140534x42250266w9284aee9d2fc0ca8@mail.gmail.com>
Message-ID: <e64efa440910140622r4d95573ai8cc0c15e6e75b203@mail.gmail.com>

Hi Pradeep;

As noted in the reply to Jeff and the list, the latest versions of xts
and quantmod fixed this problem. I intalled xts_0.6.8 and
quantmod_0.3-12 from R-forge and the example ran without mishap.

As a matter of curiosity, what do you mean dump it down? Where did you
find the the code expression "if (mid != 0 && key < vec[mid])" to make
your addition of " if (isTrue(mid != 0 && key < vec[mid]))."?

I'm not sure if I am up to tinkering at the level that you suggest but
I figure the more I know about some of the underlying stuff the more
likely I will be able to understand the obvious and maybe attempt a
fix.

Thanks for your suggestion, I did not attempt it but willl look
further when I know where to start.

Jan

On Wed, Oct 14, 2009 at 8:34 AM, Pradeep Raje <raje.pradeep at gmail.com> wrote:
> Hi Jan:
> I lived with this irritating problem for a few days, and then decided to
> dumb it down.
> The problem in:
> "Error in if (mid != 0 && key < vec[mid]) { :
> ?missing value where TRUE/FALSE needed".
>
> can be fixed by adding a isTrue() ahead of the expression. Try
> if (isTrue(mid != 0 && key < vec[mid])).
> I know it shouldn't happen this way: if (TRUE) gives an error msg but
> if(isTrue(TRUE)) flies. See if it helps.
> pradeep
>
> 18?96?50??N 72?82?53?? E


From markknecht at gmail.com  Wed Oct 14 15:35:39 2009
From: markknecht at gmail.com (Mark Knecht)
Date: Wed, 14 Oct 2009 06:35:39 -0700
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <e64efa440910140615j431ce6c9s3a9e1cae0b29059f@mail.gmail.com>
References: <e64efa440910131922v544b941diaea9bb7ce400fe6b@mail.gmail.com>
	<e8e755250910131927l219db436h7a167439dbc40bc1@mail.gmail.com>
	<e64efa440910140615j431ce6c9s3a9e1cae0b29059f@mail.gmail.com>
Message-ID: <5bdc1c8b0910140635r68e0314cx2cfc4d588a435acb@mail.gmail.com>

Hi Jan,
   Yea! Another Gentoo user!

   OK, I had trouble with xts-0.6.8 on windows. I had to go with the
0.6.7 version in the Bezerkeley CRAN repo to get it to work at all. I
haven't tried anything with blotter on Gentoo yet.

HTH,
Mark

On Wed, Oct 14, 2009 at 6:15 AM, Jan Vandermeer <nordicgnome at gmail.com> wrote:
> Hi Jeff;
>
> Thanks for your speedy reply. I thought that I had a relatively up to
> date R repository, kind of just short of SVN but updating to the
> packages on R-forge, xts_0.6.8 and quantmod_0.3-12 allowed a clean
> run.
>
> I guess I was not living as close to the bleeding edge as I thought.
>
> Jan
>
> On Tue, Oct 13, 2009 at 10:27 PM, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:
>> Try installing the latest versions of xts and quantmod as well. ?As
>> blotter is under development, it is best to update all the
>> dependencies as well.
>>
>> In this case, I think that should solve your problem.
>>
>> Best,
>> Jeff
>>
>> On Tue, Oct 13, 2009 at 9:22 PM, Jan Vandermeer <nordicgnome at gmail.com> wrote:
>>> Hi all;
>>>
>>> I've been following the discussion here on backtesting
>>> ([R-SIG-Finance] Backtesting framework package -
>>> <https://stat.ethz.ch/pipermail/r-sig-finance/2009q2/004404.html> and
>>> the discussion ?[R-SIG-Finance] QuantMod trading models docs?
>>> initiated by Mark Knecht and decided to give the blotter package a
>>> try.
>>> I tried running ?through the example provided by the blotter package.
>>> </usr/lib64/R/library/blotter/html/blotter-package.html>
>>> I installed the latest version from R-forge. I am running R version
>>> 2.9.1 (2009-06-26) on an AMD Turion 64 with a Gentoo 2.6.31 kernel.
>>>
>>> Things ran smoothly as shown below until I got to the "p =
>>> updatePortf(p,'2007-01')" step, where R kicked out
>>>
>>> "Error in if (mid != 0 && key < vec[mid]) { :
>>> ?missing value where TRUE/FALSE needed".
>>>
>>> So I went along and looked at the
>>> "/usr/lib64/R/library/blotter/html/00Index.html", which sent me along
>>> to "/usr/lib64/R/library/blotter/html/updatePosPL.html" and attempted
>>> to adjust some of the values because the usage seems to indicate that
>>> additional values may be required
>>>
>>> "Usage
>>> updatePosPL(Portfolio, Symbol, StartDate, EndDate, Prices = Cl(get(Symbol)))
>>> updatePortf(Portfolio, StartDate, EndDate)"
>>>
>>> I added an EndDate using the same format as in the getSymbols command.
>>> and received the following error.
>>>
>>>> p = updatePortf(p,'2007-01-01`, '2007-01-31')
>>> Error: unexpected numeric constant in "p = updatePortf(p,'2007-01-01`, '2007"
>>>
>>>
>>> I tried a couple of variations on the updatePosPL()
>>>
>>>> updatePosPL(p, "IBM", '2007-01-01', '2007-01-31', Prices = Cl(get(Symbol)))
>>> Error in updatePosPL(p, "IBM", "2007-01-01", "2007-01-31", Prices =
>>> Cl(get(Symbol))) :
>>> ?unused argument(s) ("2007-01-31")
>>>> updatePosPL(p, "IBM", '2007-01-01', '2007-01-31', Prices = Cl(get(Symbol)))
>>> Error in updatePosPL(p, "IBM", "2007-01-01", "2007-01-31", Prices =
>>> Cl(get(Symbol))) :
>>> ?unused argument(s) ("2007-01-31")
>>>> updatePosPL(p, "IBM", '2007-01-01', Prices = Cl(get(Symbol)))
>>> Error in get(Symbol) : object 'Symbol' not found
>>>> updatePosPL(p, "IBM", '2007-01-01', Prices = Cl(get(symbol)))
>>> Error in get(symbol) : object 'symbol' not found
>>>
>>> I also tried:
>>>> updatePosPL(p, "IBM", '2007-01-01', Prices = Cl(IBM))
>>> Error in if (any(i < 0)) { : missing value where TRUE/FALSE needed
>>>
>>>
>>> At this point I am at a bit of a loss. I tried looking through some of
>>> the stuff on R-Project to see if there are guidelines for code
>>> examples and where and if they should work. I guess I would expect the
>>> code examples include in the library or
>>> "/usr/lib64/R/library/blotter/R-ex" to just work.
>>>
>>> So, I am I doing something glaringly wrong? Do I need to update my
>>> version of R, xts, zoo or quantmod? I know I am on still on the steep
>>> part of the learning curve as far as R in general is concerned and
>>> specifically with time series and financial data with R but R texts
>>> I've seen suggest that working through examples with real data and
>>> known steps is a great way to learn. Successfully working through
>>> examples allows one small sign posts of success along the way
>>>
>>> Any assistance would be appreciated.
>>>
>>> Jan
>>>
>>>
>>>
>>> Blotter example entered into R and responses after the first _________
>>>
>>> I tried looking at the output for "p", see below the second ______. It
>>> appears to be included in the data.frame
>>>
>>> Values obtained through quantmod are below the third _______
>>>
>>> ________________________________
>>>> library(blotter)
>>> Loading required package: xts
>>> Loading required package: zoo
>>>
>>> Attaching package: 'zoo'
>>>
>>>
>>> ? ? ? ?The following object(s) are masked from package:base :
>>>
>>> ? ? ? ? as.Date.numeric
>>>
>>> xts now requires a valid TZ environment variable to be set
>>> ?no TZ var is set, setting to TZ=GMT
>>>> symbols = c("IBM","F","MMM")
>>>> require(quantmod)
>>> Loading required package: quantmod
>>> Loading required package: Defaults
>>> Loading required package: TTR
>>>> getSymbols(symbols, from='2007-01-01', to='2007-01-31', index.class="POSIXct")
>>> [1] "IBM" "F" ? "MMM"
>>>> print('Creating portfolio \"p\"...')
>>> [1] "Creating portfolio \"p\"..."
>>>> p = initPortf(symbols=symbols)
>>>> print('Adding trades to \"p\"...')
>>> [1] "Adding trades to \"p\"..."
>>>> # Make a couple of trades in IBM
>>>> p = addTxn(p, "IBM", '2007-01-03', 50, 96.5, -0.05*50)
>>> [1] "IBM 2007-01-03 50 @ 96.5"
>>>> p = addTxn(p, "IBM", '2007-01-04', 50, 97.1, -0.05*50)
>>> [1] "IBM 2007-01-04 50 @ 97.1"
>>>> # ...a few in F.
>>>> p = addTxn(p, "F", '2007-01-03', -100, 7.60, -0.05*100)
>>> [1] "F 2007-01-03 -100 @ 7.6"
>>>> p = addTxn(p, "F", '2007-01-04', 50, 7.70, -0.05*50)
>>> [1] "F 2007-01-04 50 @ 7.7"
>>>> p = addTxn(p, "F", '2007-01-10', 50, 7.78, -0.05*50)
>>> [1] "F 2007-01-10 50 @ 7.78"
>>>> # ...and some in MMM
>>>> p = addTxn(p, "MMM", '2007-01-05', -50, 77.9, -0.05*50)
>>> [1] "MMM 2007-01-05 -50 @ 77.9"
>>>> p = addTxn(p, "MMM", '2007-01-08', 50, 77.6, -0.05*50)
>>> [1] "MMM 2007-01-08 50 @ 77.6"
>>>> p = addTxn(p, "MMM", '2007-01-09', 50, 77.6, -0.05*50)
>>> [1] "MMM 2007-01-09 50 @ 77.6"
>>> ___________
>>>
>>>
>>> It appears that the transactions have been posted correctly
>>>
>>>> p
>>> $IBM
>>> $IBM$txn
>>> ? ? ? ? ? Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty
>>> 1950-01-01 ? ? ? 0 ? ? ? 0.0 ? ? ?0.0 ? ? ? 0.0 ? ? ? ? 0.00 ? ? ? 0
>>> 2007-01-03 ? ? ?50 ? ? ?96.5 ? ? -2.5 ? ?4827.5 ? ? ? ?96.55 ? ? ?50
>>> 2007-01-04 ? ? ?50 ? ? ?97.1 ? ? -2.5 ? ?4857.5 ? ? ? ?97.15 ? ? 100
>>> ? ? ? ? ? Pos.Avg.Cost Realized.PL
>>> 1950-01-01 ? ? ? ? 0.00 ? ? ? ? ? 0
>>> 2007-01-03 ? ? ? ?96.55 ? ? ? ? ? 0
>>> 2007-01-04 ? ? ? ?96.85 ? ? ? ? ? 0
>>>
>>> $IBM$posPL
>>> ? ? ? ? ? Pos.Qty Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL
>>> 1950-01-01 ? ? ? 0 ? ? ? ? 0 ? ? ? ? 0 ? ? ? ?0 ? ? ? ? ? 0 ? ? ? ? ? ? 0
>>> ? ? ? ? ? Trading.PL
>>> 1950-01-01 ? ? ? ? ?0
>>>
>>>
>>> $F
>>> $F$txn
>>> ? ? ? ? ? Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty
>>> 1950-01-01 ? ? ? 0 ? ? ?0.00 ? ? ?0.0 ? ? ? 0.0 ? ? ? ? 0.00 ? ? ? 0
>>> 2007-01-03 ? ?-100 ? ? ?7.60 ? ? -5.0 ? ?-755.0 ? ? ? ? 7.55 ? ?-100
>>> 2007-01-04 ? ? ?50 ? ? ?7.70 ? ? -2.5 ? ? 387.5 ? ? ? ? 7.75 ? ? -50
>>> 2007-01-10 ? ? ?50 ? ? ?7.78 ? ? -2.5 ? ? 391.5 ? ? ? ? 7.83 ? ? ? 0
>>> ? ? ? ? ? Pos.Avg.Cost Realized.PL
>>> 1950-01-01 ? ? ? ? 0.00 ? ? ? ? ? 0
>>> 2007-01-03 ? ? ? ? 7.55 ? ? ? ? ? 0
>>> 2007-01-04 ? ? ? ? 7.35 ? ? ? ? -10
>>> 2007-01-10 ? ? ? ? 0.00 ? ? ? ? -24
>>>
>>> $F$posPL
>>> ? ? ? ? ? Pos.Qty Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL
>>> 1950-01-01 ? ? ? 0 ? ? ? ? 0 ? ? ? ? 0 ? ? ? ?0 ? ? ? ? ? 0 ? ? ? ? ? ? 0
>>> ? ? ? ? ? Trading.PL
>>> 1950-01-01 ? ? ? ? ?0
>>>
>>>
>>> $MMM
>>> $MMM$txn
>>> ? ? ? ? ? Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty
>>> 1950-01-01 ? ? ? 0 ? ? ? 0.0 ? ? ?0.0 ? ? ? 0.0 ? ? ? ? 0.00 ? ? ? 0
>>> 2007-01-05 ? ? -50 ? ? ?77.9 ? ? -2.5 ? -3892.5 ? ? ? ?77.85 ? ? -50
>>> 2007-01-08 ? ? ?50 ? ? ?77.6 ? ? -2.5 ? ?3882.5 ? ? ? ?77.65 ? ? ? 0
>>> 2007-01-09 ? ? ?50 ? ? ?77.6 ? ? -2.5 ? ?3882.5 ? ? ? ?77.65 ? ? ?50
>>> ? ? ? ? ? Pos.Avg.Cost Realized.PL
>>> 1950-01-01 ? ? ? ? 0.00 ? ? ? ? ? 0
>>> 2007-01-05 ? ? ? ?77.85 ? ? ? ? ? 0
>>> 2007-01-08 ? ? ? ? 0.00 ? ? ? ? ?10
>>> 2007-01-09 ? ? ? ?77.65 ? ? ? ? ? 0
>>>
>>> $MMM$posPL
>>> ? ? ? ? ? Pos.Qty Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL
>>> 1950-01-01 ? ? ? 0 ? ? ? ? 0 ? ? ? ? 0 ? ? ? ?0 ? ? ? ? ? 0 ? ? ? ? ? ? 0
>>> ? ? ? ? ? Trading.PL
>>> 1950-01-01
>>>
>>> _________________________________________
>>>
>>>> IBM
>>> ? ? ? ? ? IBM.Open IBM.High IBM.Low IBM.Close IBM.Volume IBM.Adjusted
>>> 2007-01-03 ? ?97.18 ? ?98.40 ? 96.26 ? ? 97.27 ? ?9196800 ? ? ? ?92.84
>>> 2007-01-04 ? ?97.25 ? ?98.79 ? 96.88 ? ? 98.31 ? 10524500 ? ? ? ?93.83
>>> 2007-01-05 ? ?97.60 ? ?97.95 ? 96.91 ? ? 97.42 ? ?7221300 ? ? ? ?92.98
>>> 2007-01-08 ? ?98.50 ? ?99.50 ? 98.35 ? ? 98.90 ? 10340000 ? ? ? ?94.40
>>> 2007-01-09 ? ?99.08 ? 100.33 ? 99.07 ? ?100.07 ? 11108200 ? ? ? ?95.51
>>> 2007-01-10 ? ?98.50 ? ?99.05 ? 97.93 ? ? 98.89 ? ?8744800 ? ? ? ?94.39
>>> 2007-01-11 ? ?99.00 ? ?99.90 ? 98.50 ? ? 98.65 ? ?8000700 ? ? ? ?94.16
>>> 2007-01-12 ? ?98.99 ? ?99.69 ? 98.50 ? ? 99.34 ? ?6636500 ? ? ? ?94.82
>>> 2007-01-16 ? ?99.40 ? 100.84 ? 99.30 ? ?100.82 ? ?9602200 ? ? ? ?96.23
>>> 2007-01-17 ? 100.69 ? 100.90 ? 99.90 ? ?100.02 ? ?8200700 ? ? ? ?95.47
>>> 2007-01-18 ? ?99.80 ? ?99.95 ? 98.91 ? ? 99.45 ? 14725000 ? ? ? ?94.92
>>> 2007-01-19 ? ?95.00 ? ?96.85 ? 94.55 ? ? 96.17 ? 26035800 ? ? ? ?91.79
>>> 2007-01-22 ? ?96.42 ? ?97.23 ? 96.12 ? ? 97.11 ? 13539300 ? ? ? ?92.69
>>> 2007-01-23 ? ?96.91 ? ?97.38 ? 96.20 ? ? 97.08 ? 10337400 ? ? ? ?92.66
>>> 2007-01-24 ? ?97.08 ? ?97.58 ? 96.58 ? ? 97.40 ? ?5700000 ? ? ? ?92.96
>>> 2007-01-25 ? ?97.22 ? ?97.92 ? 97.22 ? ? 97.51 ? ?6201300 ? ? ? ?93.07
>>> 2007-01-26 ? ?97.52 ? ?97.83 ? 96.84 ? ? 97.45 ? ?5771100 ? ? ? ?93.01
>>> 2007-01-29 ? ?97.70 ? ?98.66 ? 97.45 ? ? 98.54 ? ?7294800 ? ? ? ?94.05
>>> 2007-01-30 ? ?98.57 ? ?99.45 ? 98.50 ? ? 99.37 ? ?7177900 ? ? ? ?94.84
>>> 2007-01-31 ? ?98.80 ? ?99.48 ? 98.35 ? ? 99.15 ? ?6432600 ? ? ? ?94.63
>>>> F
>>> ? ? ? ? ? F.Open F.High F.Low F.Close ?F.Volume F.Adjusted
>>> 2007-01-03 ? 7.56 ? 7.67 ?7.44 ? ?7.51 ?78652200 ? ? ? 7.51
>>> 2007-01-04 ? 7.56 ? 7.72 ?7.43 ? ?7.70 ?63454900 ? ? ? 7.70
>>> 2007-01-05 ? 7.72 ? 7.75 ?7.57 ? ?7.62 ?40562100 ? ? ? 7.62
>>> 2007-01-08 ? 7.63 ? 7.75 ?7.62 ? ?7.73 ?48938500 ? ? ? 7.73
>>> 2007-01-09 ? 7.75 ? 7.86 ?7.73 ? ?7.79 ?56732200 ? ? ? 7.79
>>> 2007-01-10 ? 7.79 ? 7.79 ?7.67 ? ?7.73 ?42397100 ? ? ? 7.73
>>> 2007-01-11 ? 7.73 ? 7.80 ?7.68 ? ?7.77 ?40020800 ? ? ? 7.77
>>> 2007-01-12 ? 7.77 ? 7.92 ?7.76 ? ?7.89 ?57053800 ? ? ? 7.89
>>> 2007-01-16 ? 7.89 ? 8.01 ?7.87 ? ?7.94 ?66699800 ? ? ? 7.94
>>> 2007-01-17 ? 7.97 ? 8.10 ?7.97 ? ?8.04 ?63728700 ? ? ? 8.04
>>> 2007-01-18 ? 8.06 ? 8.24 ?8.06 ? ?8.18 ?78375700 ? ? ? 8.18
>>> 2007-01-19 ? 8.24 ? 8.32 ?8.17 ? ?8.30 ?66023300 ? ? ? 8.30
>>> 2007-01-22 ? 8.33 ? 8.43 ?8.25 ? ?8.41 ?53554600 ? ? ? 8.41
>>> 2007-01-23 ? 8.39 ? 8.62 ?8.24 ? ?8.30 116406900 ? ? ? 8.30
>>> 2007-01-24 ? 8.31 ? 8.35 ?8.11 ? ?8.20 ?76821900 ? ? ? 8.20
>>> 2007-01-25 ? 8.15 ? 8.52 ?8.00 ? ?8.22 ?99688700 ? ? ? 8.22
>>> 2007-01-26 ? 8.15 ? 8.48 ?8.14 ? ?8.42 ?54421900 ? ? ? 8.42
>>> 2007-01-29 ? 8.44 ? 8.51 ?8.35 ? ?8.37 ?55791000 ? ? ? 8.37
>>> 2007-01-30 ? 8.38 ? 8.42 ?8.19 ? ?8.20 ?28763200 ? ? ? 8.20
>>> 2007-01-31 ? 8.17 ? 8.20 ?8.04 ? ?8.13 ?65038600 ? ? ? 8.13
>>>> MMM
>>> ? ? ? ? ? MMM.Open MMM.High MMM.Low MMM.Close MMM.Volume MMM.Adjusted
>>> 2007-01-03 ? ?77.53 ? ?78.85 ? 77.38 ? ? 78.26 ? ?3781500 ? ? ? ?72.40
>>> 2007-01-04 ? ?78.40 ? ?78.41 ? 77.45 ? ? 77.95 ? ?2968400 ? ? ? ?72.11
>>> 2007-01-05 ? ?77.89 ? ?77.90 ? 77.01 ? ? 77.42 ? ?2765200 ? ? ? ?71.62
>>> 2007-01-08 ? ?77.42 ? ?78.04 ? 76.97 ? ? 77.59 ? ?2434500 ? ? ? ?71.78
>>> 2007-01-09 ? ?78.00 ? ?78.23 ? 77.44 ? ? 77.68 ? ?1896800 ? ? ? ?71.86
>>> 2007-01-10 ? ?77.31 ? ?77.96 ? 77.04 ? ? 77.85 ? ?1787500 ? ? ? ?72.02
>>> 2007-01-11 ? ?78.05 ? ?79.03 ? 77.88 ? ? 78.65 ? ?2372500 ? ? ? ?72.76
>>> 2007-01-12 ? ?78.41 ? ?79.50 ? 78.22 ? ? 79.36 ? ?2582200 ? ? ? ?73.42
>>> 2007-01-16 ? ?79.48 ? ?79.62 ? 78.92 ? ? 79.56 ? ?2526600 ? ? ? ?73.60
>>> 2007-01-17 ? ?79.33 ? ?79.51 ? 78.75 ? ? 78.91 ? ?2711300 ? ? ? ?73.00
>>> 2007-01-18 ? ?78.71 ? ?79.70 ? 78.60 ? ? 78.81 ? ?1963000 ? ? ? ?72.91
>>> 2007-01-19 ? ?79.09 ? ?79.88 ? 78.82 ? ? 79.25 ? ?2912100 ? ? ? ?73.32
>>> 2007-01-22 ? ?79.25 ? ?79.29 ? 78.13 ? ? 78.49 ? ?2139300 ? ? ? ?72.61
>>> 2007-01-23 ? ?78.71 ? ?79.15 ? 78.33 ? ? 78.85 ? ?1949500 ? ? ? ?72.95
>>> 2007-01-24 ? ?78.85 ? ?79.66 ? 78.85 ? ? 79.49 ? ?1772700 ? ? ? ?73.54
>>> 2007-01-25 ? ?79.56 ? ?79.75 ? 78.83 ? ? 79.01 ? ?2888700 ? ? ? ?73.09
>>> 2007-01-26 ? ?78.97 ? ?79.19 ? 78.23 ? ? 78.69 ? ?1996300 ? ? ? ?72.80
>>> 2007-01-29 ? ?78.54 ? ?79.20 ? 78.25 ? ? 78.96 ? ?3420300 ? ? ? ?73.05
>>> 2007-01-30 ? ?74.92 ? ?76.18 ? 74.24 ? ? 74.70 ? 15657900 ? ? ? ?69.11
>>> 2007-01-31 ? ?74.21 ? ?74.68 ? 73.09 ? ? 74.30 ? ?9284500 ? ? ? ?68.74
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
>>
>>
>>
>> --
>> Jeffrey Ryan
>> jeffrey.ryan at insightalgo.com
>>
>> ia: insight algorithmics
>> www.insightalgo.com
>>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From markknecht at gmail.com  Wed Oct 14 15:31:03 2009
From: markknecht at gmail.com (Mark Knecht)
Date: Wed, 14 Oct 2009 06:31:03 -0700
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
Message-ID: <5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>

On Wed, Oct 14, 2009 at 1:39 AM, Mark Breman <breman.mark at gmail.com> wrote:
> Hello,
> In "The mathematics of money management" by Ralph Vince there is a formula
> for calculating the Mathematical Expectation of a game (in R pseudo code):
>
> ME ?= ?for(i in 1:N) { Pi * Ai}
>
> where
> P = Probability of winning or losing
> A = Amount won or lost
> N = Number of possible outcomes.
>
> Or in text: "Mathematical expectation is the amount you expect to make or
> lose, on average, each bet".
>
> Now suppose I want to know the Mathematical expectation of a trading system.
>
> I have a series of trade returns:
>
>> trades$PnL
> ?[1] ?-5.75 ?10.00 ?-1.25 ?96.00 -16.00 -35.00 ?29.00 -18.25 ?-2.25 -10.25
> -21.75 ?-5.50 ? 8.50 -20.50 ?-6.00 ?14.25 ?18.00
> [18] ? 3.75 ?-4.25 ?24.00 ?17.75 ?-9.50 ?11.25 -33.75 ? 6.25 -28.00 ? 1.00
> ?36.75 ?14.00 -30.75 ?-0.50 ? 6.75 ?19.25 ? 5.25
> [35] -10.00 -23.25 ? 9.25 ?11.00 -33.00 -19.00 -17.50 ?-5.50 ?-5.75 ?-8.50
> -24.50 -24.00 ? 2.25 ?-1.00 ? 0.75 ?-1.75 ?-2.25
> [52] ? 9.25 ?15.00 ?-2.25 ?-6.75 ? 5.25 ?-4.75 -10.00 ?-2.00 ?63.50 -18.00
> -18.00 ?58.00 ?-8.75 ? 1.00 -36.75 -23.50 -64.00
> [69] -15.75 -10.00 -34.75 ?27.75 -57.00 204.75 -45.00 -71.00 133.75
>
> So I have A = trades$PnL and N=77, but how do I calculate P?
>
> -Mark-

Hi Mark,
   The simple answer would be:

1) Look at all the data you have today. How many trades won? How many
trades total? P = Total wins/ total trades

2) Start trading. After some fixed number of trades - say 30 more
trades - how did the win/loss ratio compare?

   Don't think only of the probability, but also how much does the
probability vary? I have systems that trade 4000 times in 6 months. I
constantly track win/loss ratios as a rolling calculation just to
watch how the system might be doing in a new market type. My system
might have a probability of winning 82% of the time over 4000 trades
but goes up and down by 5% when looking at any 100 consecutive trades.
(So 77%-87% wins) I consider that 'normal'. If it gets outside of 5% I
might stop trading it until it's back in the 'normal' range.

   Note that I do this also for what you call 'A' since the product
represents the potential for making money if everything works out
'normally'. ;-)

HTH,
Mark


From konrad.banachewicz at gmail.com  Wed Oct 14 16:58:05 2009
From: konrad.banachewicz at gmail.com (Konrad Banachewicz)
Date: Wed, 14 Oct 2009 16:58:05 +0200
Subject: [R-SIG-Finance] RBloomberg error?
Message-ID: <204e4c50910140758v458eaa23v5a1d18862c4de91c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091014/63466418/attachment.pl>

From elise at predictiveanalyticsworld.com  Thu Oct 15 08:10:51 2009
From: elise at predictiveanalyticsworld.com (EliseJ)
Date: Wed, 14 Oct 2009 23:10:51 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Predictive Analytics Seminar: Nov.
 11-12, San Francisco
Message-ID: <25903483.post@talk.nabble.com>


Hi all, 

I wanted to remind you of our final 2009 training seminar on predictive
analytics - coming Nov. 11-12 to San Francisco. This is intensive training
for marketers, managers and business professionals to make actionable sense
of customer data by predicting buying behavior, churn, etc.  Past attendees
provided rave reviews.

Here's more info:
----------------------

Training Program: Predictive Analytics for Business, Marketing and Web

A two-day intensive seminar brought to you by Prediction Impact, Inc. 

Dates/Location: Nov 11-12, 2009, San Francisco

93% rate this program Excellent or Very Good. 
**The official training program of Predictive Analytics World**
**Offered in conjunction with eMetrics events** 

Also see our Online Training: Predictive Analytics Applied - immediate
access at any time:
www.predictionimpact.com/predictive-analytics-online-training.html


ABOUT THIS SEMINAR:

Business metrics do a great job summarizing the past. But if you want to
predict how customers will respond in the future, there is one place to
turn--predictive analytics. By learning from your abundant historical data,
predictive analytics provides the marketer something beyond standard
business reports and sales forecasts: actionable predictions for each
customer. These predictions encompass all channels, both online and off,
foreseeing which customers will buy, click, respond, convert or cancel. If
you predict it, you own it. 

The customer predictions generated by predictive analytics deliver more
relevant content to each customer, improving response rates, click rates,
buying behavior, retention and overall profit. For online applications such
as e-marketing and customer care recommendations, predictive analytics acts
in real-time, dynamically selecting the ad, web content or cross-sell
product each visitor is most likely to click on or respond to, according to
that visitor's profile. This is AB selection, rather than just AB testing. 

Predictive Analytics for Business, Marketing and Web is a concentrated
training program that includes interactive breakout sessions and a brief
hands-on exercise. In two days we cover: 

- The techniques, tips and pointers you need in order to run a successful
predictive analytics and data mining initiative

- How to strategically position and tactically deploy predictive analytics
and data mining at your company

- How to bridge the prevalent gap between technical understanding and
practical use

- How a predictive model works, how it's created and how much revenue it
generates

- Several detailed case studies that demonstrate predictive analytics in
action and make the concepts concrete 

- NEW TOPIC: Five Ways to Lower Costs with Predictive Analytics 


No background in statistics or modeling is required. The only specific
knowledge assumed for this training program is moderate experience with
Microsoft Excel or equivalent. 

For more information, visit
www.predictionimpact.com/predictive-analytics-training.html, or e-mail us at
training at predictionimpact.com.  You may also call (415) 683-1146. 

Cross-Registration Special: Attendees earn $250 off the Predictive Analytics
World Conference 

SNEAK PREVIEW VIDEO:
www.predictionimpact.com/predictive-analytics-times.html 

$100 off early registration, 3 weeks ahead

-- 
View this message in context: http://www.nabble.com/Predictive-Analytics-Seminar%3A-Nov.-11-12%2C-San-Francisco-tp25903483p25903483.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From elise at predictionimpact.com  Thu Oct 15 09:02:01 2009
From: elise at predictionimpact.com (Elise Johnson)
Date: Thu, 15 Oct 2009 00:02:01 -0700
Subject: [R-SIG-Finance] Can we post following event to discussion board?
Message-ID: <a74230f40910150002i1902b6b0g42ee6eafae93d6b3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091015/28073727/attachment.pl>

From gero.schwenk at web.de  Thu Oct 15 10:12:57 2009
From: gero.schwenk at web.de (Gero Schwenk)
Date: Thu, 15 Oct 2009 10:12:57 +0200
Subject: [R-SIG-Finance] Perfect out-of-sample-fit in a model containing a
 lagged dependent variable?
Message-ID: <4AD6D989.8030709@web.de>

Hello there!
I'm new to quantitative finance and now experimenting with the various 
tools. While playing with day-to-day predictions for the returns on 
closing call of the DAX, I observed a really strange behavior of my 
regression models - namely a R-Square of approx 1, which gets replicated 
by a nearly perfect fit of out-of-sample predictions for a prediction 
horizon of 57 trading days. (!) (Model details at the bottom of this mail.)

I think, the issue is connected to the lagged dependent variable 
included as predictor in model. (However, the Durbin-Watson test 
indicates no autocorrelation in the series, which itself implies 
misspecification.) Excluding this term leads to models with an R-Square 
of approx 0.4, which is not satisfying, but fits my expecations given 
the ad-hoc-model. This is also replicated in terms of out-of-sample fit.

However- there remains the question of the nearly perfect out-of-sample 
fit for the model including the AR1-term. Has anybody experienced 
similar behavior? Answers would really be appreciated!

Kind regards,
Gero

#

Model detalis:

- Model setup: linear model:  close.DAX ~ lag(close.DAX) + 
lag(close.NYSE) + lag(close.HangSeng)
- Data is the respective returns (backshifted index data)
- Datasource: Yahoo-Finance
- Training-Dataset: 4000 days back - without the last 57 trading days
- Test-Dataset: the last 57 trading days
- Max. correlation of the model-variables: 0.59
- Augmented Dickey-Fuller-Test indicates stationarity
- Durbin-Watson-Test indicates no autocorrelation (! - contratry to 
model structure)
- CumSum-Test indicates no structural change between training- and test-data
- In the fitted linear model, the AR1-term (lag(close.DAX)) dominates 
the other parameters vastly and seemingly channels all the 
intraday-correlation between the independent variables, R^2 is 1. Out of 
sample fit is close to perfect
- Residuals don't really look normally distributed but generally 
generalized-pareto (extreme value) distributed, as mean residual life 
plots indicate
- Bootstrapping the model yields lots of not accessible NA regression 
coefficients, probably due to shirinking variance in the 
bootstrap-sample. (But this is also an issue with the model excluding 
the AR1-term.)


From breman.mark at gmail.com  Thu Oct 15 10:28:33 2009
From: breman.mark at gmail.com (Mark Breman)
Date: Thu, 15 Oct 2009 10:28:33 +0200
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
	<5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>
Message-ID: <5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091015/cfa96701/attachment.pl>

From nelson.ana at gmail.com  Thu Oct 15 12:07:04 2009
From: nelson.ana at gmail.com (Ana Nelson)
Date: Thu, 15 Oct 2009 11:07:04 +0100
Subject: [R-SIG-Finance] RBloomberg error?
In-Reply-To: <204e4c50910140758v458eaa23v5a1d18862c4de91c@mail.gmail.com>
References: <204e4c50910140758v458eaa23v5a1d18862c4de91c@mail.gmail.com>
Message-ID: <a7d6d2740910150307t49269a29gc23c9a2f7fd71183@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091015/04ba6aa1/attachment.pl>

From kagba2006 at yahoo.com  Thu Oct 15 12:58:54 2009
From: kagba2006 at yahoo.com (FMH)
Date: Thu, 15 Oct 2009 03:58:54 -0700 (PDT)
Subject: [R-SIG-Finance] Estimation in a changepoint regression with R
Message-ID: <608741.97965.qm@web38308.mail.mud.yahoo.com>

Dear All,

I'm trying to do the estimation in a changepoint regression problem via R, but never found any suitable function which might help me to do this. 

Could someone give me a hand?on this matter? Apologize if i am in?the wrong channel of discussion.

Thank you.





From a.trapletti at swissonline.ch  Thu Oct 15 13:57:12 2009
From: a.trapletti at swissonline.ch (Adrian Trapletti)
Date: Thu, 15 Oct 2009 13:57:12 +0200
Subject: [R-SIG-Finance] Perfect out-of-sample-fit in a model containing
 a lagged dependent variable?
Message-ID: <4AD70E18.6070501@swissonline.ch>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091015/8e5b92dc/attachment.html>

From gero.schwenk at web.de  Thu Oct 15 22:32:10 2009
From: gero.schwenk at web.de (Gero Schwenk)
Date: Thu, 15 Oct 2009 22:32:10 +0200
Subject: [R-SIG-Finance] Error found - [Perfect out-of-sample-fit in a model
 containing a lagged dependent variable?]
Message-ID: <4AD786CA.6030600@web.de>

Hi there!
Thanks for helping! Patrick was right: I predicted the future by knowing 
the future. The lag-operator is not applied to the model-data's 
dataframe for reasons I'll find out. In effect the model is not Y ~ 
lag(Y) + lag(X1) + lag(X2) but Y ~ Y + lag(X1) + lag(X2)...

Thanks again + good night:
Gero


From markknecht at gmail.com  Thu Oct 15 23:10:54 2009
From: markknecht at gmail.com (Mark Knecht)
Date: Thu, 15 Oct 2009 14:10:54 -0700
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
	<5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>
	<5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
Message-ID: <5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>

Hi Mark,

On Thu, Oct 15, 2009 at 1:28 AM, Mark Breman <breman.mark at gmail.com> wrote:
> Hhmmm, this is all very strange.
> The subject of "Mathematics of money management" is about optimizing trade
> size under reinvestment of profits (optimizing the Growth function G(f),
> i.e. finding the optimal f)

To be clear but somewhat off topic - Optimal f is only one of many
ways to size a position. Optimal f itself might not be appropriate for
your risk tolerances as it can cause large drawdowns.

> Ralph Vince warns the reader that the trade system to start with should have
> a positive Mathematical expectation to start with, because the optimal f can
> not turn a losing system into a winning system.

Independent of the calculations did your system make money
historically? If it did then it has a positive expectation.

> From the reactions here I conclude that it's impossible to calculate a
> reliable Mathematical expectation for the system to start with,

I do not understand this conclusion unless you are keying on the word
'reliable' and have some specific idea in mind about what that means.

> so what's
> the value of optimal f if you can never be confident that the system is
> profitable to start with?

The results of any sizing algorithm operating into the future is only
as valid as the idea that the system will continue to perform in a
similar manner. There is no guarantee trade by trade of anything, but
if the system's average return per trade was $1 over the past 1000
trades then we should expect that over the next 100 trades it will
also return $1 per trade. Further we should expect that we'll see
similar win/loss ratios and the largest winner and loser will
hopefully be smaller than the similar trades in the history of the
system. If that turns out to be true then we say the system is
continuing to operate as it did in the past.

However there are NO guarantees.


> Some reactions on this thread?referred?to the validity of historical data to
> future performance of the system.
> I think it's clear that there are no?guarantees?for the future whatsoever if
> we formulate expectations solely based on data from the past. I think
> this?uncertainty?is part of trading. But is it not possible to calculate a
> Mathematical expectation for a system based on historical results which only
> says something about the validity/performance of the system in the past?

I believe it is and that's what I do.

> Would the following approach be sensible/possible:
> Take the historical profits and loses from the system and look at the
> distribution of these results. If the distribution looks like a normal
> distribution (as expected for?stock market returns, at least in theory), use
> the normal distribution to calculate the P (probability of winning or
> losing) and calculate the Mathematical expectation?

I don't know about this, but I'm not clear why it's needed unless you
have a requirement to trade systems that have 'normal' distributions
of trade-by-trade returns.

Hope this helps,
Mark

> -Mark-
> 2009/10/14 Mark Knecht <markknecht at gmail.com>
>>
>> On Wed, Oct 14, 2009 at 1:39 AM, Mark Breman <breman.mark at gmail.com>
>> wrote:
>> > Hello,
>> > In "The mathematics of money management" by Ralph Vince there is a
>> > formula
>> > for calculating the Mathematical Expectation of a game (in R pseudo
>> > code):
>> >
>> > ME ?= ?for(i in 1:N) { Pi * Ai}
>> >
>> > where
>> > P = Probability of winning or losing
>> > A = Amount won or lost
>> > N = Number of possible outcomes.
>> >
>> > Or in text: "Mathematical expectation is the amount you expect to make
>> > or
>> > lose, on average, each bet".
>> >
>> > Now suppose I want to know the Mathematical expectation of a trading
>> > system.
>> >
>> > I have a series of trade returns:
>> >
>> >> trades$PnL
>> > ?[1] ?-5.75 ?10.00 ?-1.25 ?96.00 -16.00 -35.00 ?29.00 -18.25 ?-2.25
>> > -10.25
>> > -21.75 ?-5.50 ? 8.50 -20.50 ?-6.00 ?14.25 ?18.00
>> > [18] ? 3.75 ?-4.25 ?24.00 ?17.75 ?-9.50 ?11.25 -33.75 ? 6.25 -28.00
>> > 1.00
>> > ?36.75 ?14.00 -30.75 ?-0.50 ? 6.75 ?19.25 ? 5.25
>> > [35] -10.00 -23.25 ? 9.25 ?11.00 -33.00 -19.00 -17.50 ?-5.50 ?-5.75
>> > ?-8.50
>> > -24.50 -24.00 ? 2.25 ?-1.00 ? 0.75 ?-1.75 ?-2.25
>> > [52] ? 9.25 ?15.00 ?-2.25 ?-6.75 ? 5.25 ?-4.75 -10.00 ?-2.00 ?63.50
>> > -18.00
>> > -18.00 ?58.00 ?-8.75 ? 1.00 -36.75 -23.50 -64.00
>> > [69] -15.75 -10.00 -34.75 ?27.75 -57.00 204.75 -45.00 -71.00 133.75
>> >
>> > So I have A = trades$PnL and N=77, but how do I calculate P?
>> >
>> > -Mark-
>>
>> Hi Mark,
>> ? The simple answer would be:
>>
>> 1) Look at all the data you have today. How many trades won? How many
>> trades total? P = Total wins/ total trades
>>
>> 2) Start trading. After some fixed number of trades - say 30 more
>> trades - how did the win/loss ratio compare?
>>
>> ? Don't think only of the probability, but also how much does the
>> probability vary? I have systems that trade 4000 times in 6 months. I
>> constantly track win/loss ratios as a rolling calculation just to
>> watch how the system might be doing in a new market type. My system
>> might have a probability of winning 82% of the time over 4000 trades
>> but goes up and down by 5% when looking at any 100 consecutive trades.
>> (So 77%-87% wins) I consider that 'normal'. If it gets outside of 5% I
>> might stop trading it until it's back in the 'normal' range.
>>
>> ? Note that I do this also for what you call 'A' since the product
>> represents the potential for making money if everything works out
>> 'normally'. ;-)
>>
>> HTH,
>> Mark
>
>


From patrick at burns-stat.com  Fri Oct 16 09:55:29 2009
From: patrick at burns-stat.com (Patrick Burns)
Date: Fri, 16 Oct 2009 08:55:29 +0100
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>	<5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>	<5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
	<5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>
Message-ID: <4AD826F1.8040600@burns-stat.com>

Mark Knecht wrote:
> Hi Mark,
> 
> On Thu, Oct 15, 2009 at 1:28 AM, Mark Breman <breman.mark at gmail.com> wrote:

[...]

> 
>> Ralph Vince warns the reader that the trade system to start with should have
>> a positive Mathematical expectation to start with, because the optimal f can
>> not turn a losing system into a winning system.
> 
> Independent of the calculations did your system make money
> historically? If it did then it has a positive expectation.
> 

The truth of that assertion depends on at
least two assumptions:

* Selection bias is not very strong.

* The market will behave in the future like
it did over the historical period.




Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of "The R Inferno" and "A Guide for the Unwilling S User")


From sergeyg at gmail.com  Fri Oct 16 11:18:15 2009
From: sergeyg at gmail.com (Sergey Goriatchev)
Date: Fri, 16 Oct 2009 11:18:15 +0200
Subject: [R-SIG-Finance] Question related to RBloomberg
Message-ID: <7cb007bd0910160218q73e89e74w4a00cab29598f261@mail.gmail.com>

Hello, everyone

I have RBloomberg 0.1-11 on my machine.
I cannot extract futures contract value with this code:

conn <- blpConnect(show.days="week", na.action="previous.days",
periodicity="daily")
ty1.cvalue <- blpGetData(conn, c("TY1 Comdty"), "FUT_CONT_SIZE")
blpDisconnect(conn)

I get an error message:
Error in if (typ[n] == "character") { : argument is of length zero

By the way, the following example in blpGetData does not work either,
producing the same error message:
> conn <- blpConnect()
>
> ## Snapshot
> eda <- blpGetData(conn, c("ED5 Comdty","ED6 Comdty","ED7 Comdty",
+ "ED8 Comdty"), "BID")
Error in if (typ[n] == "character") { : argument is of length zero

I can always specify the contract size manually, of course, but I
wonder why these requests do not work with RBloomberg?

Thanks in advance for your help!

Best,
Sergey


From breman.mark at gmail.com  Fri Oct 16 11:46:57 2009
From: breman.mark at gmail.com (Mark Breman)
Date: Fri, 16 Oct 2009 11:46:57 +0200
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <4AD826F1.8040600@burns-stat.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
	<5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>
	<5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
	<5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>
	<4AD826F1.8040600@burns-stat.com>
Message-ID: <5e6a2e670910160246v7f178d49x515e0a9b5a8fd053@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091016/f1cd3253/attachment.pl>

From psmyth at yahoo.com  Fri Oct 16 14:31:42 2009
From: psmyth at yahoo.com (Phil Smyth)
Date: Fri, 16 Oct 2009 05:31:42 -0700 (PDT)
Subject: [R-SIG-Finance] Question related to RBloomberg
In-Reply-To: <7cb007bd0910160218q73e89e74w4a00cab29598f261@mail.gmail.com>
References: <7cb007bd0910160218q73e89e74w4a00cab29598f261@mail.gmail.com>
Message-ID: <56427.49637.qm@web33903.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091016/e6c76a18/attachment.pl>

From markknecht at gmail.com  Fri Oct 16 15:09:12 2009
From: markknecht at gmail.com (Mark Knecht)
Date: Fri, 16 Oct 2009 06:09:12 -0700
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <5e6a2e670910160246v7f178d49x515e0a9b5a8fd053@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
	<5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>
	<5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
	<5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>
	<4AD826F1.8040600@burns-stat.com>
	<5e6a2e670910160246v7f178d49x515e0a9b5a8fd053@mail.gmail.com>
Message-ID: <5bdc1c8b0910160609w5aa5c219q8078998e0bfb425d@mail.gmail.com>

On Fri, Oct 16, 2009 at 2:46 AM, Mark Breman <breman.mark at gmail.com> wrote:
> I think I found the answer for calculating the Mathematical Expectation (as
> intended by Ralph Vince):
> P = #winners / # losers

Is it #winner/#losers or is it #winner/#trades ?

Either can be true but I think the latter is more common in my
experience as it yields a value between 0 and 1.

good luck,
Mark


From breman.mark at gmail.com  Fri Oct 16 15:36:14 2009
From: breman.mark at gmail.com (Mark Breman)
Date: Fri, 16 Oct 2009 15:36:14 +0200
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <5bdc1c8b0910160609w5aa5c219q8078998e0bfb425d@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
	<5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>
	<5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
	<5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>
	<4AD826F1.8040600@burns-stat.com>
	<5e6a2e670910160246v7f178d49x515e0a9b5a8fd053@mail.gmail.com>
	<5bdc1c8b0910160609w5aa5c219q8078998e0bfb425d@mail.gmail.com>
Message-ID: <5e6a2e670910160636u4ac01941o29083df512541abb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091016/fac286c5/attachment.pl>

From sergeyg at gmail.com  Fri Oct 16 16:00:17 2009
From: sergeyg at gmail.com (Sergey Goriatchev)
Date: Fri, 16 Oct 2009 16:00:17 +0200
Subject: [R-SIG-Finance] Question related to RBloomberg
In-Reply-To: <7cb007bd0910160218q73e89e74w4a00cab29598f261@mail.gmail.com>
References: <7cb007bd0910160218q73e89e74w4a00cab29598f261@mail.gmail.com>
Message-ID: <7cb007bd0910160700o3f969494oe0ecebca33336324@mail.gmail.com>

Hello, everyone

I have RBloomberg 0.1-11 on my machine.
I cannot extract futures contract value with this code:

conn <- blpConnect(show.days="week", na.action="previous.days",
periodicity="daily")
ty1.cvalue <- blpGetData(conn, c("TY1 Comdty"), "FUT_CONT_SIZE")
blpDisconnect(conn)

I get an error message:
Error in if (typ[n] == "character") { : argument is of length zero

By the way, the following example in blpGetData does not work either,
producing the same error message:
> conn <- blpConnect()
>
> ## Snapshot
> eda <- blpGetData(conn, c("ED5 Comdty","ED6 Comdty","ED7 Comdty",
+ "ED8 Comdty"), "BID")
Error in if (typ[n] == "character") { : argument is of length zero

I can always specify the contract size manually, of course, but I
wonder why these requests do not work with RBloomberg?

Thanks in advance for your help!

Best,
Sergey



-- 
Kniven sk?rpes bara mot stenen.


From ustaudinger at gmail.com  Fri Oct 16 16:17:34 2009
From: ustaudinger at gmail.com (Ulrich Staudinger)
Date: Fri, 16 Oct 2009 16:17:34 +0200
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <5e6a2e670910160636u4ac01941o29083df512541abb@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
	<5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>
	<5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
	<5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>
	<4AD826F1.8040600@burns-stat.com>
	<5e6a2e670910160246v7f178d49x515e0a9b5a8fd053@mail.gmail.com>
	<5bdc1c8b0910160609w5aa5c219q8078998e0bfb425d@mail.gmail.com>
	<5e6a2e670910160636u4ac01941o29083df512541abb@mail.gmail.com>
Message-ID: <65daf6a60910160717t66f043a5y91c1eca9c8e5240b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091016/7bd4be6f/attachment.pl>

From markknecht at gmail.com  Fri Oct 16 16:28:51 2009
From: markknecht at gmail.com (Mark Knecht)
Date: Fri, 16 Oct 2009 07:28:51 -0700
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <5e6a2e670910160636u4ac01941o29083df512541abb@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
	<5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>
	<5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
	<5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>
	<4AD826F1.8040600@burns-stat.com>
	<5e6a2e670910160246v7f178d49x515e0a9b5a8fd053@mail.gmail.com>
	<5bdc1c8b0910160609w5aa5c219q8078998e0bfb425d@mail.gmail.com>
	<5e6a2e670910160636u4ac01941o29083df512541abb@mail.gmail.com>
Message-ID: <5bdc1c8b0910160728x6ff7a2b8g2e8e5b8d509955f9@mail.gmail.com>

Please see the first response I made to this thread.

Cheers,
Mark

On Fri, Oct 16, 2009 at 6:36 AM, Mark Breman <breman.mark at gmail.com> wrote:
> Hi Mark,
> You are right: it is P = #winners / #trades
> Thank you,
> -Mark-
>
> 2009/10/16 Mark Knecht <markknecht at gmail.com>
>>
>> On Fri, Oct 16, 2009 at 2:46 AM, Mark Breman <breman.mark at gmail.com>
>> wrote:
>> > I think I found the answer for calculating the Mathematical Expectation
>> > (as
>> > intended by Ralph Vince):
>> > P = #winners / # losers
>>
>> Is it #winner/#losers or is it #winner/#trades ?
>>
>> Either can be true but I think the latter is more common in my
>> experience as it yields a value between 0 and 1.
>>
>> good luck,
>> Mark
>
>


From markknecht at gmail.com  Fri Oct 16 16:34:56 2009
From: markknecht at gmail.com (Mark Knecht)
Date: Fri, 16 Oct 2009 07:34:56 -0700
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <65daf6a60910160717t66f043a5y91c1eca9c8e5240b@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
	<5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>
	<5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
	<5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>
	<4AD826F1.8040600@burns-stat.com>
	<5e6a2e670910160246v7f178d49x515e0a9b5a8fd053@mail.gmail.com>
	<5bdc1c8b0910160609w5aa5c219q8078998e0bfb425d@mail.gmail.com>
	<5e6a2e670910160636u4ac01941o29083df512541abb@mail.gmail.com>
	<65daf6a60910160717t66f043a5y91c1eca9c8e5240b@mail.gmail.com>
Message-ID: <5bdc1c8b0910160734p2029a79atdc7ab6faa2ecf935@mail.gmail.com>

Not enough information. Is this a long-only system? If it is then you
bought 4 and sold 7.

Is this a system that goes long and short? If so then I cannot tell
what completes a trade?

Most likely I'd start with some sort of LIFO (Last in first out) and
then try FIFO. (First in first out)

LIFO:
Buy 103 & 102, sell 2 at 102 - currently long 2
Buy 101 & 100, sell 2 at 101 - currently flat
Sell 2 at 99
Sell 98 - currently short 3

I'm not sure this is what you mean though. After matching them up it's
just winners/trades to me.

Other ideas?

- Mark

On Fri, Oct 16, 2009 at 7:17 AM, Ulrich Staudinger
<ustaudinger at gmail.com> wrote:
> Hi,
>
> out of curiosity,
> how would you define this statistic with a ramp up and ramp down trade
> system ?
> Trades could look like this:
>
> Buy 1 @ 100
> Buy 1 @ 101
> Buy 1 @ 102
> Buy 1 @ 103
> Sell 2 @ 102
> Sell 2 @ 101
> Sell 2 @ 99
> Sell 1 @ 98
>
> ?
>
> Thanks,
> kind regards,
> Ulrich
>
> On Fri, Oct 16, 2009 at 3:36 PM, Mark Breman <breman.mark at gmail.com> wrote:
>>
>> Hi Mark,
>> You are right: it is P = #winners / #trades
>>
>> Thank you,
>>
>> -Mark-
>>
>> 2009/10/16 Mark Knecht <markknecht at gmail.com>
>>
>> > On Fri, Oct 16, 2009 at 2:46 AM, Mark Breman <breman.mark at gmail.com>
>> > wrote:
>> > > I think I found the answer for calculating the Mathematical
>> > > Expectation
>> > (as
>> > > intended by Ralph Vince):
>> > > P = #winners / # losers
>> >
>> > Is it #winner/#losers or is it #winner/#trades ?
>> >
>> > Either can be true but I think the latter is more common in my
>> > experience as it yields a value between 0 and 1.
>> >
>> > good luck,
>> > Mark
>> >
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>
>
>
> --
> Ulrich B. Staudinger
>


From ustaudinger at gmail.com  Fri Oct 16 17:00:24 2009
From: ustaudinger at gmail.com (Ulrich Staudinger)
Date: Fri, 16 Oct 2009 17:00:24 +0200
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <5bdc1c8b0910160734p2029a79atdc7ab6faa2ecf935@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
	<5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>
	<5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
	<5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>
	<4AD826F1.8040600@burns-stat.com>
	<5e6a2e670910160246v7f178d49x515e0a9b5a8fd053@mail.gmail.com>
	<5bdc1c8b0910160609w5aa5c219q8078998e0bfb425d@mail.gmail.com>
	<5e6a2e670910160636u4ac01941o29083df512541abb@mail.gmail.com>
	<65daf6a60910160717t66f043a5y91c1eca9c8e5240b@mail.gmail.com>
	<5bdc1c8b0910160734p2029a79atdc7ab6faa2ecf935@mail.gmail.com>
Message-ID: <65daf6a60910160800w6b3cbf1em6484e6be050c7d6f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091016/2b531659/attachment.pl>

From markknecht at gmail.com  Fri Oct 16 17:07:31 2009
From: markknecht at gmail.com (Mark Knecht)
Date: Fri, 16 Oct 2009 08:07:31 -0700
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <65daf6a60910160800w6b3cbf1em6484e6be050c7d6f@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
	<5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
	<5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>
	<4AD826F1.8040600@burns-stat.com>
	<5e6a2e670910160246v7f178d49x515e0a9b5a8fd053@mail.gmail.com>
	<5bdc1c8b0910160609w5aa5c219q8078998e0bfb425d@mail.gmail.com>
	<5e6a2e670910160636u4ac01941o29083df512541abb@mail.gmail.com>
	<65daf6a60910160717t66f043a5y91c1eca9c8e5240b@mail.gmail.com>
	<5bdc1c8b0910160734p2029a79atdc7ab6faa2ecf935@mail.gmail.com>
	<65daf6a60910160800w6b3cbf1em6484e6be050c7d6f@mail.gmail.com>
Message-ID: <5bdc1c8b0910160807i1ba42c55w76009ee6d2830c6f@mail.gmail.com>

On Fri, Oct 16, 2009 at 8:00 AM, Ulrich Staudinger
<ustaudinger at gmail.com> wrote:
> Hi,
>
> On Fri, Oct 16, 2009 at 4:34 PM, Mark Knecht <markknecht at gmail.com> wrote:
>>
>> Not enough information. Is this a long-only system? If it is then you
>> bought 4 and sold 7.
>>
>> Is this a system that goes long and short? If so then I cannot tell
>> what completes a trade?
>
> the trade system in this case could have been any long/short trade system.
> I think the winners/loosers ratio is only applicable to a limited amount? of
> trade systems and does therefore provide only limited confidence about the
> expectation of trade systems.

Higher math - you
Lower math - me


>
> Other ratios like LiquidationPnl / Trades make more sense, or for example, a
> curve marked-to-market values of the position once a trade occurs.

Possibly. I don't disagree. Can't when my level of understanding is so low.

One comment I'd make is that I wouldn't include trades that are in
process as they aren't historical. Personally I look only at closed
trades when evaluating my systems historically.

>
> Another aspect is also the definition of a trade, i define, and i think
> that's also the mainstream definition a trade as a transaction. What you
> call a trade completion is something i know as a roundturn (buy and sell).
> The term round turns is? not applicable to pyramidizing systems, i think.
>

I don't disagree, but once we've matched buys to sells and thrown away
everything that's in process maybe the overall average expectation ($
Made/#trades) isn't any different but the largest winner, largest
losers are?

I do a lot of modeling on paper where I use what I call the 6 Tharp
numbers and generate trade sequences automatically to study things
like drawdowns, risk or ruin, etc. I think they are applicable to
pyramiding systems but as I said originally

Higher math - you
Lower math - me

;-)

>
> Kind regards,
> Ulrich
>
>
>
>
> --
> Ulrich B. Staudinger
>


From breman.mark at gmail.com  Fri Oct 16 19:35:45 2009
From: breman.mark at gmail.com (Mark Breman)
Date: Fri, 16 Oct 2009 19:35:45 +0200
Subject: [R-SIG-Finance] Mathematical Expectation for a trading system
In-Reply-To: <65daf6a60910160717t66f043a5y91c1eca9c8e5240b@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
	<5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>
	<5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
	<5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>
	<4AD826F1.8040600@burns-stat.com>
	<5e6a2e670910160246v7f178d49x515e0a9b5a8fd053@mail.gmail.com>
	<5bdc1c8b0910160609w5aa5c219q8078998e0bfb425d@mail.gmail.com>
	<5e6a2e670910160636u4ac01941o29083df512541abb@mail.gmail.com>
	<65daf6a60910160717t66f043a5y91c1eca9c8e5240b@mail.gmail.com>
Message-ID: <5e6a2e670910161035w323d114do94ef2d57d67f5939@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091016/a42f38af/attachment.pl>

From edd at debian.org  Fri Oct 16 19:59:55 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 16 Oct 2009 12:59:55 -0500
Subject: [R-SIG-Finance] Enough,
	please (Was:  Mathematical Expectation for a trading system)
In-Reply-To: <5e6a2e670910161035w323d114do94ef2d57d67f5939@mail.gmail.com>
References: <5e6a2e670910140139i217ca60g9c6c25340367c27a@mail.gmail.com>
	<5bdc1c8b0910140631l2172b2dr6eb82a2d35af1032@mail.gmail.com>
	<5e6a2e670910150128s5aac77cbuf85b0466c8cf6a2c@mail.gmail.com>
	<5bdc1c8b0910151410u2d0b64beh4dfc6764fb517f09@mail.gmail.com>
	<4AD826F1.8040600@burns-stat.com>
	<5e6a2e670910160246v7f178d49x515e0a9b5a8fd053@mail.gmail.com>
	<5bdc1c8b0910160609w5aa5c219q8078998e0bfb425d@mail.gmail.com>
	<5e6a2e670910160636u4ac01941o29083df512541abb@mail.gmail.com>
	<65daf6a60910160717t66f043a5y91c1eca9c8e5240b@mail.gmail.com>
	<5e6a2e670910161035w323d114do94ef2d57d67f5939@mail.gmail.com>
Message-ID: <19160.46235.859291.795028@ron.nulle.part>


Greetings from your listmaster!

Could you fellows please move this discussion somewhere else?  

I believe I speak for the readership at large when I say that its usefulness
in the context of using R in Finance has long declined beyond the point of
general measurability.  So please take it elsewhere.

Readers disagreeing with me are kindly invited to contact me off-list.

In related news, I also unsubscribed Elise J for her repeated spamming of the
list with unrelated conference commercials.  However, that may not protect us
from her re-subscribing. 

Back to our regularly scheduled R / Finance geekyness,   Dirk

-- 
Three out of two people have difficulties with fractions.


From gero.schwenk at web.de  Fri Oct 16 20:10:56 2009
From: gero.schwenk at web.de (Gero Schwenk)
Date: Fri, 16 Oct 2009 20:10:56 +0200
Subject: [R-SIG-Finance] Exploratory analyses: Experience using
 gputools-package for Nvidia graphics-accellerators?
Message-ID: <4AD8B730.9000709@web.de>

Hi, dear finance modelers!
I want to employ some systematic approach to explore promising 
predictors for trading models. Therefore I think about experimenting 
with parallel-processing on GPU's (Nvidia graphics accellerators) - 
these are quite cheap (150-300?) and contain usually more than 240 
processing units.

There is a package called "gputools" ( 
http://cran.r-project.org/web/packages/gputools/index.html ) which seems 
to originate from the bioinformatics-community and implements very 
interesting functionality for exploratory analysis and large scale 
predictive modeling. Among these are calculation of distance metrics for 
clustering, tests for granger causality, approximation of the mutual 
information, calculation of correlation coefficients, estimating and 
predicting support vector machines and support vector regression.

Now my question: Does anybody have experience using this package or GPU- 
resp. parallel-processing for exploration? Or do you use other 
environments, resp. approaches?

Thanks & a good evening!
Gero


From brian at braverock.com  Fri Oct 16 20:29:32 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 16 Oct 2009 13:29:32 -0500
Subject: [R-SIG-Finance] Exploratory analyses: Experience using
 gputools-package for Nvidia graphics-accellerators?
In-Reply-To: <4AD8B730.9000709@web.de>
References: <4AD8B730.9000709@web.de>
Message-ID: <4AD8BB8C.1060705@braverock.com>

Gero Schwenk wrote:
> Hi, dear finance modelers!
> I want to employ some systematic approach to explore promising 
> predictors for trading models. Therefore I think about experimenting 
> with parallel-processing on GPU's (Nvidia graphics accellerators) - 
> these are quite cheap (150-300?) and contain usually more than 240 
> processing units.
>
> There is a package called "gputools" ( 
> http://cran.r-project.org/web/packages/gputools/index.html ) which 
> seems to originate from the bioinformatics-community and implements 
> very interesting functionality for exploratory analysis and large 
> scale predictive modeling. Among these are calculation of distance 
> metrics for clustering, tests for granger causality, approximation of 
> the mutual information, calculation of correlation coefficients, 
> estimating and predicting support vector machines and support vector 
> regression.
>
> Now my question: Does anybody have experience using this package or 
> GPU- resp. parallel-processing for exploration? Or do you use other 
> environments, resp. approaches?
This is my personal experience and thoughts only, and not as 
well-informed as I might like, ymmv.

I know firms in finance that are making extensive use of different GPU 
architectures.  They are *all* doing a lot of low level C programming to 
do it, using the API directly in many cases, or reference 
implementations of linear and matrix algebra packages tuned for the GPU 
they've chosen.  I appreciate the approach if you have the resources to 
engage in it.

My personal feeling is that the "general purpose" in "general purpose 
GPU" will not be met until the linear algebra libraries that are hidden 
from most users transparently support execution on GPU's.  See for 
example the MAGMA project, run by the folks that brought us the widely 
deployed ATLAS.

After experimenting with some of the tools that are available now, I 
made the decision here at my work to not do anything serious with GPU's 
right now.  I expect to revisit that decision again in a few months, as 
the machines at my desk already have reasonably powerful GPU hardware in 
them.  However, right now, the potential hasn't gotten to the level 
where it makes it worth the work for what I do.

I think that over time, commonly available math libraries and 
parallelization frameworks will embrace GPU's, and *then* I'll have more 
reason to spend time working with them.

Cheers,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From edd at debian.org  Fri Oct 16 20:39:06 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 16 Oct 2009 13:39:06 -0500
Subject: [R-SIG-Finance] Exploratory analyses: Experience using
 gputools-package for Nvidia graphics-accellerators?
In-Reply-To: <4AD8B730.9000709@web.de>
References: <4AD8B730.9000709@web.de>
Message-ID: <19160.48586.915047.899624@ron.nulle.part>


On 16 October 2009 at 20:10, Gero Schwenk wrote:
| Hi, dear finance modelers!
| I want to employ some systematic approach to explore promising 
| predictors for trading models. Therefore I think about experimenting 
| with parallel-processing on GPU's (Nvidia graphics accellerators) - 
| these are quite cheap (150-300?) and contain usually more than 240 
| processing units.
| 
| There is a package called "gputools" ( 
| http://cran.r-project.org/web/packages/gputools/index.html ) which seems 
| to originate from the bioinformatics-community and implements very 
| interesting functionality for exploratory analysis and large scale 
| predictive modeling. Among these are calculation of distance metrics for 
| clustering, tests for granger causality, approximation of the mutual 
| information, calculation of correlation coefficients, estimating and 
| predicting support vector machines and support vector regression.
| 
| Now my question: Does anybody have experience using this package or GPU- 
| resp. parallel-processing for exploration? Or do you use other 
| environments, resp. approaches?

For what it is worth I started looking into this two days ago when I took
possession of such an NVidia card (with a list price considerably above EUR
300 for its 192 cores) and I also started with the (nice) gputools package as
a starting point.

However, I'd say that this belongs onto r-sig-hpc.  "Just because" you (and
even I) would like to use it in Finance doesn't make it Finance. It is still
a methodological question somewhat orthogonal to what we do here, and more at
home on the High-Performance Computing list.

Again, those disagreeing with me are kindly invited to let me know off-list
if there was in fact a consensus to having such a discussion here.

Dirk

-- 
Three out of two people have difficulties with fractions.


From eduard.pieterse at macquarie.com  Mon Oct 19 18:10:41 2009
From: eduard.pieterse at macquarie.com (ehxpieterse)
Date: Mon, 19 Oct 2009 09:10:41 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Rolling Beta
Message-ID: <25961048.post@talk.nabble.com>


Hi, 

I have had a *very* rough attempt at estimating the beta between indices. I
am convinced that someone on this list has had experience with this before,
but my search yielded little information. I have daily log returns from
01/01/2000 on 13 different equity indices. I am just looking for an
efficient way to produce a rolling beta for all index pairs.

I would appreciate any advice.

Thanks,
Eduard

CODE:

IndexLocal <- read.csv("IndexLocal.csv", header=TRUE, sep = ",")
MyLag <- 30
IndexDim <- dim(IndexLocal)
Results <- NULL
reg <- NULL
k <- 0

for (i in 2:14)
{
	for (j in 2:14)
	{
			k <- k + 1
			for (r in MyLag :IndexDim[1])
			{
				x. <- IndexLocal[(r-MyLag+1):r,i]
				y. <- IndexLocal[(r-MyLag+1):r,j]				
				glm.linear<-coef(glm(y. ~ x.))
				reg[r] <- glm.linear[2]
			}
				if (j >= i)
				{
					Results <- cbind(Results,reg)
				}
	}
}


-- 
View this message in context: http://www.nabble.com/Rolling-Beta-tp25961048p25961048.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Mon Oct 19 18:27:51 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 19 Oct 2009 11:27:51 -0500
Subject: [R-SIG-Finance] [R-sig-finance] Rolling Beta
In-Reply-To: <25961048.post@talk.nabble.com>
References: <25961048.post@talk.nabble.com>
Message-ID: <4ADC9387.40804@braverock.com>

see PerformanceAnalytics functions

CAPM.beta
and
chart.RollingRegression
and
charts.RollingRegression

Cheers,

  - Brian

ehxpieterse wrote:
> Hi, 
>
> I have had a *very* rough attempt at estimating the beta between indices. I
> am convinced that someone on this list has had experience with this before,
> but my search yielded little information. I have daily log returns from
> 01/01/2000 on 13 different equity indices. I am just looking for an
> efficient way to produce a rolling beta for all index pairs.
>
> I would appreciate any advice.
>
> Thanks,
> Eduard
>
> CODE:
>
> IndexLocal <- read.csv("IndexLocal.csv", header=TRUE, sep = ",")
> MyLag <- 30
> IndexDim <- dim(IndexLocal)
> Results <- NULL
> reg <- NULL
> k <- 0
>
> for (i in 2:14)
> {
> 	for (j in 2:14)
> 	{
> 			k <- k + 1
> 			for (r in MyLag :IndexDim[1])
> 			{
> 				x. <- IndexLocal[(r-MyLag+1):r,i]
> 				y. <- IndexLocal[(r-MyLag+1):r,j]				
> 				glm.linear<-coef(glm(y. ~ x.))
> 				reg[r] <- glm.linear[2]
> 			}
> 				if (j >= i)
> 				{
> 					Results <- cbind(Results,reg)
> 				}
> 	}
> }
>
>
>   


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From brian at braverock.com  Mon Oct 19 19:26:17 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 19 Oct 2009 12:26:17 -0500
Subject: [R-SIG-Finance] [R-sig-finance] Rolling Beta
In-Reply-To: <A4B987FA3EE557449BC63149ED42D3780578224D@ntlonexm01.pc.internal.macquarie.com>
References: <25961048.post@talk.nabble.com> <4ADC9387.40804@braverock.com>
	<A4B987FA3EE557449BC63149ED42D3780578224D@ntlonexm01.pc.internal.macquarie.com>
Message-ID: <4ADCA139.1010108@braverock.com>

As with most things in R, you can see the code by typing the function 
name without the parentheses.

In the case of rolling beta, the important line is this:

rollapply(na.omit(merged.assets[,, drop = FALSE]),
                  width = width, FUN = function(x) lm(x[,1, drop = FALSE]
                  ~ x[, 2, drop = FALSE])$coefficients[2],
                  by = 1, by.column = FALSE, na.pad = na.pad,
                  align = "right")

Regards,

   - Brian


Eduard Pieterse (Macquarie Securities) wrote:
> Hi Brian,
>
> Chart.rollingRegression seems to be exactly what I'm after. How would I
> "disconnect" the chart output and be able to save/use the data behind
> it?
>
> I am still finding my feet with R and know what I need to do, but my R
> language knowledge is lacking somewhat.
>
> Thanks,
> Eduard
>
> -----Original Message-----
> From: Brian G. Peterson [mailto:brian at braverock.com] 
> Sent: 19 October 2009 17:28
> To: Eduard Pieterse (Macquarie Securities)
> Cc: r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] [R-sig-finance] Rolling Beta
>
> see PerformanceAnalytics functions
>
> CAPM.beta
> and
> chart.RollingRegression
> and
> charts.RollingRegression
>
> Cheers,
>
>   - Brian
>
> ehxpieterse wrote:
>   
>> Hi,
>>
>> I have had a *very* rough attempt at estimating the beta between 
>> indices. I am convinced that someone on this list has had experience 
>> with this before, but my search yielded little information. I have 
>> daily log returns from 01/01/2000 on 13 different equity indices. I am
>>     
>
>   
>> just looking for an efficient way to produce a rolling beta for all
>>     
> index pairs.
>   
>> I would appreciate any advice.
>>
>> Thanks,
>> Eduard
>>
>> CODE:
>>
>> IndexLocal <- read.csv("IndexLocal.csv", header=TRUE, sep = ",") MyLag
>>     
>
>   
>> <- 30 IndexDim <- dim(IndexLocal) Results <- NULL reg <- NULL k <- 0
>>
>> for (i in 2:14)
>> {
>> 	for (j in 2:14)
>> 	{
>> 			k <- k + 1
>> 			for (r in MyLag :IndexDim[1])
>> 			{
>> 				x. <- IndexLocal[(r-MyLag+1):r,i]
>> 				y. <- IndexLocal[(r-MyLag+1):r,j]
>>     
>
>   
>> 				glm.linear<-coef(glm(y. ~ x.))
>> 				reg[r] <- glm.linear[2]
>> 			}
>> 				if (j >= i)
>> 				{
>> 					Results <- cbind(Results,reg)
>> 				}
>> 	}
>> }
>>
>>     

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From karlavhv142 at hotmail.com  Tue Oct 20 21:19:52 2009
From: karlavhv142 at hotmail.com (karla hernandez villafuerte)
Date: Tue, 20 Oct 2009 13:19:52 -0600
Subject: [R-SIG-Finance] seasonal dummy lm equation
Message-ID: <COL124-W8B4FA6F26E1E86FA5D3AFE5C00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091020/78062e2f/attachment.pl>

From matthieu.stigler at gmail.com  Wed Oct 21 08:39:00 2009
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Wed, 21 Oct 2009 08:39:00 +0200
Subject: [R-SIG-Finance] seasonal dummy lm equation
In-Reply-To: <COL124-W8B4FA6F26E1E86FA5D3AFE5C00@phx.gbl>
References: <COL124-W8B4FA6F26E1E86FA5D3AFE5C00@phx.gbl>
Message-ID: <111060c20910202339j6c043eb8id9666c7d2779599d@mail.gmail.com>

Give you a very "manual" to solve your problem, there are sure more
elegent way to do that.

Please provide completely reproducible code examples:
###data
[see below]
n<-nrow(dummymatrix)

X<-runif(n)
Y<-rnorm(n)
trend<-1:n

###your reg
reg<-lm(Y~ X+ trend+0+ dummymatrix)

###select less significant (from p values)
maxP<-which.max(summary(reg)$coefficients[-c(1,2),4])

#exclude it:
reg2<-lm(Y~ X+ trend+0+ dummymatrix[,-maxP])

There should be better way to handle seasonal dummies, already using
them as factors:
dummies<-factor(rep(1:12, 16))[1:n]
lm(Y~ X+ trend+0+ dummies)

#here if you add an intercept, first dummy will be dropped automatically:
lm(Y~ X+ trend+1+ dummies)


Hope this helps


2009/10/20 karla hernandez villafuerte <karlavhv142 at hotmail.com>:
>
> Dear people:
>
>
>
> I want to use the next seasonal dummy matrix:
>
>
>
> d2=ts(c(1,0,0,0,0,0,0,0,0,0,0,0),start=c(1990,2),end=c(2006,1),frequency=12)
> d3= ts(c(0,1,0,0,0,0,0,0,0,0,0,0),start=c(1990,2),end=c(2006,1),frequency=12)
> d4= ts(c(0,0,1,0,0,0,0,0,0,0,0,0),start=c(1990,2),end=c(2006,1),frequency=12)
> d5= ts(c(0,0,0,1,0,0,0,0,0,0,0,0),start=c(1990,2),end=c(2006,1),frequency=12)
> d6= ts(c(0,0,0,0,1,0,0,0,0,0,0,0),start=c(1990,2),end=c(2006,1),frequency=12)
> d7= ts(c(0,0,0,0,0,1,0,0,0,0,0,0),start=c(1990,2),end=c(2006,1),frequency=12)
> d8= ts(c(0,0,0,0,0,0,1,0,0,0,0,0),start=c(1990,2),end=c(2006,1),frequency=12)
> d9= ts(c(0,0,0,0,0,0,0,1,0,0,0,0),start=c(1990,2),end=c(2006,1),frequency=12)
> d10= ts(c(0,0,0,0,0,0,0,0,1,0,0,0),start=c(1990,2),end=c(2006,1),frequency=12)
> d11= ts(c(0,0,0,0,0,0,0,0,0,1,0,0),start=c(1990,2),end=c(2006,1),frequency=12)
> d12=ts(c(0,0,0,0,0,0,0,0,0,0,1,0),start=c(1990,2),end=c(2006,1),frequency=12)
> d1=ts(c(0,0,0,0,0,0,0,0,0,0,0,1),start=c(1990,2),end=c(2006,1),frequency=12)
>
> dummymatrix=cbind(d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12)
>
>
>
> in a times series equation:
>
>
>
> lm(Y~ X+ trend+ 0+ dummy, data=dat)
>
>
>
> but I want that the program excludes automatically the dummy which is less significant to explain the behavior of Y.
>
>
>
> I will be very grateful if someone has a idea to help me.
>
>
>
>
>
> Thank you very much!
>
>
>
> Karla Hern?ndez
>
>
>
> _________________________________________________________________
> ?Te gustar?a escuchar la mejor m?sica en internet y gratis? Disfr?tala aqu?
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From bjorn.skogtro at gmail.com  Wed Oct 21 15:46:52 2009
From: bjorn.skogtro at gmail.com (Bjorn Skogtro)
Date: Wed, 21 Oct 2009 15:46:52 +0200
Subject: [R-SIG-Finance] Multiply xts-series with different frequencies
Message-ID: <8baceaa70910210646u22c57b24odd98ab25780d97f3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091021/d75ae5d3/attachment.pl>

From jeff.a.ryan at gmail.com  Wed Oct 21 16:30:57 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Wed, 21 Oct 2009 09:30:57 -0500
Subject: [R-SIG-Finance] Multiply xts-series with different frequencies
In-Reply-To: <8baceaa70910210646u22c57b24odd98ab25780d97f3@mail.gmail.com>
References: <8baceaa70910210646u22c57b24odd98ab25780d97f3@mail.gmail.com>
Message-ID: <e8e755250910210730q7ef5536egfd799532d7cdc929@mail.gmail.com>

Bj?rn,

na.locf(merge(hourly,daily))

Depending on how/where your hourly lines up you may need to adjust the
daily series to map to a particular hour stamp that matches the hourly
series.

HTH,
Jeff

e.g.

hourly <- xts(1:33, timeBasedSeq('2009-01-01 8/2009-01-02 16'))
daily <- xts(1:2, as.POSIXct("2009-01-01")+c(8*60*60,86400))

na.locf(merge(hourly,daily))
                    hourly daily
2009-01-01 08:00:00      1     1
2009-01-01 09:00:00      2     1
2009-01-01 10:00:00      3     1
2009-01-01 11:00:00      4     1
2009-01-01 12:00:00      5     1
2009-01-01 13:00:00      6     1
2009-01-01 14:00:00      7     1
2009-01-01 15:00:00      8     1
2009-01-01 16:00:00      9     1
2009-01-01 17:00:00     10     1
2009-01-01 18:00:00     11     1
2009-01-01 19:00:00     12     1
2009-01-01 20:00:00     13     1
2009-01-01 21:00:00     14     1
2009-01-01 22:00:00     15     1
2009-01-01 23:00:00     16     1
2009-01-02 00:00:00     17     2
2009-01-02 01:00:00     18     2
2009-01-02 02:00:00     19     2
2009-01-02 03:00:00     20     2
2009-01-02 04:00:00     21     2
2009-01-02 05:00:00     22     2
2009-01-02 06:00:00     23     2
2009-01-02 07:00:00     24     2
2009-01-02 08:00:00     25     2
2009-01-02 09:00:00     26     2
2009-01-02 10:00:00     27     2
2009-01-02 11:00:00     28     2
2009-01-02 12:00:00     29     2
2009-01-02 13:00:00     30     2
2009-01-02 14:00:00     31     2
2009-01-02 15:00:00     32     2
2009-01-02 16:00:00     33     2

On Wed, Oct 21, 2009 at 8:46 AM, Bjorn Skogtro <bjorn.skogtro at gmail.com> wrote:
> Hi all,
> is there a cleaver way to multiply two (xts) time-series with different
> frequencies?
>
> One series is hourly, and the other daily. They consist of prices and
> exchangerates, respectively, and i want to use the same exchangerate for all
> hours on the same date.
>
> Is there perhaps some way to repeat the same exchange rate for all hours the
> same day? That was my initial idea, but I'd like to manage without the
> for-loops.
>
> Thanks, and all the best!
>
> Bj?rn
>
> --
> Up, down, turn around
> Please dont let me hit the ground
> Tonight I think Ill walk alone
> Ill find my soul as I go home.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From swtzang at gmail.com  Thu Oct 22 14:16:48 2009
From: swtzang at gmail.com (ShyhWeir Tzang)
Date: Thu, 22 Oct 2009 20:16:48 +0800
Subject: [R-SIG-Finance] garch model estimation
Message-ID: <c17037a10910220516h7e683570nfd55ede2e2c27fdc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091022/195c6368/attachment.pl>

From philipplincoln.au at gmail.com  Thu Oct 22 14:45:06 2009
From: philipplincoln.au at gmail.com (Philipp Lincoln)
Date: Thu, 22 Oct 2009 23:45:06 +1100
Subject: [R-SIG-Finance] Performance Analytics Package: Annualized
	Returns/Sharpe Ratios and Treynor Ratio
Message-ID: <333a47e20910220545m1565a09ch540e71061d1df62a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091022/bda3ac36/attachment.pl>

From chalabi at phys.ethz.ch  Thu Oct 22 15:08:56 2009
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Thu, 22 Oct 2009 15:08:56 +0200
Subject: [R-SIG-Finance] garch model estimation
In-Reply-To: <c17037a10910220516h7e683570nfd55ede2e2c27fdc@mail.gmail.com>
References: <c17037a10910220516h7e683570nfd55ede2e2c27fdc@mail.gmail.com>
Message-ID: <20091022150856.306a4b50@mimi>

>>>> "ST" == ShyhWeir Tzang <swtzang at gmail.com>
>>>> on Thu, 22 Oct 2009 20:16:48 +0800

   ST> I used the data from the package fPortfolio like the following.
   ST> But the results seem not right as the estimated parameters
   ST> such as alpha and
   ST> beta didn't change at all. Can someone or the authors help me
   ST> out? Another
   ST> question is how to compute the standard errors and t values
   ST> numerically by
   ST> the R code? Any hint or help is highly appreciated.


Hi ShyhWeir,

Your data set is badly scaled for the optimization and you should first
check if there is any GARCH process in it.

try out with the data from package fGarch :

# after your code
library(fGarch)
data(dem2gbp)
x <- dem2gbp[,1]
init<-garchInit(x)
garchllFit(x, init[,1], init[,2],init[,3])

This gives me the same fitted parameters as on the presentation.

You might be interested by the paper of Zivot on "Practical Issues in
the Analysis of GARCH Models" which is available on his website.

HTH,
Yohan

-- 
PhD candidate
Swiss Federal Institute of Technology
Zurich

www.ethz.ch


From brian at braverock.com  Thu Oct 22 15:31:32 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 22 Oct 2009 08:31:32 -0500
Subject: [R-SIG-Finance] Performance Analytics Package:
 Annualized	Returns/Sharpe Ratios and Treynor Ratio
In-Reply-To: <333a47e20910220545m1565a09ch540e71061d1df62a@mail.gmail.com>
References: <333a47e20910220545m1565a09ch540e71061d1df62a@mail.gmail.com>
Message-ID: <4AE05EB4.4000103@braverock.com>

Philipp,

I don't have a machine with the CRAN version of PA installed handy right 
now, so these results apply to the version we will be releasing to CRAN 
in a day or so. If you like, I can send you a pre-compiled version for 
the OS you are using and you can test and report (quickly I hope, this 
is *just* in under the wire).

Philipp Lincoln wrote:
> Dear all,
>
> I am encountering the following issues in the Package Performance Analytics
> (PA): Firstly, I have difficulties to reconcile annualized return and risk
> figures computed in the Package PA with manually recomputed figures. I
> assume that commands like SharpeRatio.annualized, table.AnnualizedReturns
> etc. use by default the geometric mean (e.g.: geometric mean ./. return on
> risk free asset). However, my understanding is that when utilising log
> returns, it is more common to use the arithmetic mean. For the
> Return.annualized command there exists an option to use the arithmetic mean
> (geometric=FALSE) while there appears to be none for the command
> SharpeRatio.annualized etc. Can someone please confirm my understanding (and
> possibly let me know a workaround that allows me to use the arithmetic
> return)?
>
You are correct that the SharpeRatio.annualized function did not provide 
the geometric option. I have added it to the code, so it will be in our 
new release.

 > SharpeRatio.annualized(R=managers[,1,drop=FALSE],Rf=.04/12)
HAM1
Annualized Sharpe Ratio (Rf=4%) 1.051
 > 
SharpeRatio.annualized(R=managers[,1,drop=FALSE],Rf=.04/12,geometric=FALSE)
HAM1
Annualized Sharpe Ratio (Rf=4%) 1.053

> Secondly, my Treynor Ratio in the table.CAPM output looks somewhat odd and
> I?d like to recompute it with TreynorRatio. However, I always get an NA as a
> result. Using for instance the EDHEC data I get the following:
>
>
>> TreynorRatio(managers[,1, drop=FALSE], managers[,8,drop=FALSE], rf =
> .04/12)
>
> [1] NA
I get:

 > TreynorRatio(managers[,1, drop=FALSE], managers[,8,drop=FALSE], Rf = 
.04/12)
[1] 0.2389

table.CAPM uses the excess return of the asset over the benchmark, for 
example:

 > table.CAPM(Ra=managers[,1,drop=FALSE],Rb=edhec[,c(5,9)],Rf=.04/12)
HAM1 to Equity Market Neutral HAM1 to Long/Short Equity
Alpha 0.0019 0.0031
Beta 1.4736 0.7612
Beta+ 0.4777 0.2625
Beta- 5.8438 1.3277
R-squared 0.1177 0.3477
Annualized Alpha 0.0229 0.0377
Correlation 0.3431 0.5897
Correlation p-value 0.0001 0.0000
Tracking Error 0.1446 0.0611
Active Premium 0.0443 0.0189
Information Ratio 0.3063 0.3092
Treynor Ratio 0.0634 0.1227

if you pass the same benchmarks into the Treynor Ratio function, you get 
the same results:

 > TreynorRatio(Ra=managers[,1,drop=FALSE],Rb=edhec[,c(5,9)],Rf=.04/12)
HAM1
Treynor Ratio: Equity Market Neutral 0.06332
Treynor Ratio: Long/Short Equity 0.12258

>
> Many thanks for a quick clarification.
No Problem. Hope this helps.

Regards,

- Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From michaelkristoffernagl at gmail.com  Fri Oct 23 01:33:03 2009
From: michaelkristoffernagl at gmail.com (Michael Kristoffer Nagl)
Date: Fri, 23 Oct 2009 01:33:03 +0200
Subject: [R-SIG-Finance] COPULA
Message-ID: <000001ca5370$016c7c90$044575b0$@com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091023/bfcbc451/attachment.pl>

From windspeedo99 at gmail.com  Fri Oct 23 07:21:34 2009
From: windspeedo99 at gmail.com (Wind)
Date: Fri, 23 Oct 2009 13:21:34 +0800
Subject: [R-SIG-Finance] little arrows on quantmod charts
Message-ID: <d718c8210910222221h6bd0e169re4e137ee975b263c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091023/5d253d99/attachment.pl>

From breman.mark at gmail.com  Fri Oct 23 07:45:30 2009
From: breman.mark at gmail.com (Mark Breman)
Date: Fri, 23 Oct 2009 07:45:30 +0200
Subject: [R-SIG-Finance] little arrows on quantmod charts
In-Reply-To: <d718c8210910222221h6bd0e169re4e137ee975b263c@mail.gmail.com>
References: <d718c8210910222221h6bd0e169re4e137ee975b263c@mail.gmail.com>
Message-ID: <5e6a2e670910222245o73232915o7a34965da2c45211@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091023/d02e5c44/attachment.pl>

From windspeedo99 at gmail.com  Fri Oct 23 08:14:37 2009
From: windspeedo99 at gmail.com (Wind)
Date: Fri, 23 Oct 2009 14:14:37 +0800
Subject: [R-SIG-Finance] little arrows on quantmod charts
In-Reply-To: <5e6a2e670910222245o73232915o7a34965da2c45211@mail.gmail.com>
References: <d718c8210910222221h6bd0e169re4e137ee975b263c@mail.gmail.com>
	<5e6a2e670910222245o73232915o7a34965da2c45211@mail.gmail.com>
Message-ID: <d718c8210910222314h45e77e4csc2f1e726168481da@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091023/19e4ccd7/attachment.pl>

From jeff.a.ryan at gmail.com  Fri Oct 23 17:35:31 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 23 Oct 2009 10:35:31 -0500
Subject: [R-SIG-Finance] little arrows on quantmod charts
In-Reply-To: <d718c8210910222221h6bd0e169re4e137ee975b263c@mail.gmail.com>
References: <d718c8210910222221h6bd0e169re4e137ee975b263c@mail.gmail.com>
Message-ID: <e8e755250910230835v2d4076bau4437fbb322454199@mail.gmail.com>

While this isn't yet in the released version of quantmod, the entire
graphical engine underlying charting via quantmod is being rewritten.

The net effect is that it will now render as one graphic, so enabling
the use of charts inside of standard mfcol/layout plot regions, as
well as a more robust mechanism regarding how additions get appended
to charts.  Things are much faster and quite a bit more pleasing to
the eye now.

Another facet of the new engine is that it will allow for base
graphics to be more easily incorporated _into_ the charts.  I will be
adding wrappers to make the process easy, but it will be possible even
without them.  Currently this is a challenge in the current system
(even for me -- having a decent knowledge of what I wrote.)

I will also add a mechanism to add more common types of additions,
like signals.  Requests for additional features would be much
appreciated!!

Brave souls are invited to contact me for access and a quick example
or two before the release.  All code is on R-forge as well.

Best,
Jeff



On Fri, Oct 23, 2009 at 12:21 AM, Wind <windspeedo99 at gmail.com> wrote:
> Stock charts in quantmod are as good as other commercial softwares'.
> Yet I wonder how to add little arrows to the barChart. ? Something as
> http://www.trendprognosis.com/wp-content/uploads/2009/05/VLE0612.gif
> Sometimes little arrows are better than shaded area on the charts.
> ?Several kinds of arrows for buy, sell, stop, warning would be enough.
> Thanks.
>
> Wind
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From breman.mark at gmail.com  Fri Oct 23 19:39:37 2009
From: breman.mark at gmail.com (Mark Breman)
Date: Fri, 23 Oct 2009 19:39:37 +0200
Subject: [R-SIG-Finance] little arrows on quantmod charts
In-Reply-To: <e8e755250910230835v2d4076bau4437fbb322454199@mail.gmail.com>
References: <d718c8210910222221h6bd0e169re4e137ee975b263c@mail.gmail.com>
	<e8e755250910230835v2d4076bau4437fbb322454199@mail.gmail.com>
Message-ID: <5e6a2e670910231039j34bcff39l923bf4c6c4361d39@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091023/0bc8353c/attachment.pl>

From jeff.a.ryan at gmail.com  Fri Oct 23 19:50:04 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 23 Oct 2009 12:50:04 -0500
Subject: [R-SIG-Finance] little arrows on quantmod charts
In-Reply-To: <5e6a2e670910231039j34bcff39l923bf4c6c4361d39@mail.gmail.com>
References: <d718c8210910222221h6bd0e169re4e137ee975b263c@mail.gmail.com>
	<e8e755250910230835v2d4076bau4437fbb322454199@mail.gmail.com>
	<5e6a2e670910231039j34bcff39l923bf4c6c4361d39@mail.gmail.com>
Message-ID: <e8e755250910231050j22603cfdrab64e3f4f7536c89@mail.gmail.com>

Hi Mark,

The issue isn't the R code, it is the device (and the underlying R
graphics engine).

This won't be readily doable, at least not in the true sense.
quantmod wasn't meant to replace RT charting, it was (like R) designed
to analyze data in R _as if_ you had it in a typical charting
platform.

The new use of a custom internal 'layout' will allow for updates
without redrawing the screen, but that has limits too.  Since R uses a
paint approach (overlying), you can get some strange artifacts.

When R gets a better device, I will likely rewrite to take advantage
of it.  I am not inclined to simply replicate what is available
elsewhere though (much to the surprise of some... :) )

Replotting everything every minute or so would probably be tolerable
of course... but tick by tick flashing/redraw would make your office
into a 1970's disco.

Best,
Jeff



On Fri, Oct 23, 2009 at 12:39 PM, Mark Breman <breman.mark at gmail.com> wrote:
> Hi Jeff,
> I was thinking about if it would be possible to chart streaming price data
> with the new engine. For instance candles that get updated tick by tick as
> prices come in. I know from other development tools and charting libraries
> that it is very important for speed to have a renderer that does not render
> the entire chart, but only the areas that changed.
> Would something like that be possible with the new engine?
> Regards,
> -Mark-
>
> 2009/10/23 Jeff Ryan <jeff.a.ryan at gmail.com>
>>
>> While this isn't yet in the released version of quantmod, the entire
>> graphical engine underlying charting via quantmod is being rewritten.
>>
>> The net effect is that it will now render as one graphic, so enabling
>> the use of charts inside of standard mfcol/layout plot regions, as
>> well as a more robust mechanism regarding how additions get appended
>> to charts. ?Things are much faster and quite a bit more pleasing to
>> the eye now.
>>
>> Another facet of the new engine is that it will allow for base
>> graphics to be more easily incorporated _into_ the charts. ?I will be
>> adding wrappers to make the process easy, but it will be possible even
>> without them. ?Currently this is a challenge in the current system
>> (even for me -- having a decent knowledge of what I wrote.)
>>
>> I will also add a mechanism to add more common types of additions,
>> like signals. ?Requests for additional features would be much
>> appreciated!!
>>
>> Brave souls are invited to contact me for access and a quick example
>> or two before the release. ?All code is on R-forge as well.
>>
>> Best,
>> Jeff
>>
>>
>>
>> On Fri, Oct 23, 2009 at 12:21 AM, Wind <windspeedo99 at gmail.com> wrote:
>> > Stock charts in quantmod are as good as other commercial softwares'.
>> > Yet I wonder how to add little arrows to the barChart. ? Something as
>> > http://www.trendprognosis.com/wp-content/uploads/2009/05/VLE0612.gif
>> > Sometimes little arrows are better than shaded area on the charts.
>> > ?Several kinds of arrows for buy, sell, stop, warning would be enough.
>> > Thanks.
>> >
>> > Wind
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only.
>> > -- If you want to post, subscribe first.
>> >
>>
>>
>>
>> --
>> Jeffrey Ryan
>> jeffrey.ryan at insightalgo.com
>>
>> ia: insight algorithmics
>> www.insightalgo.com
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From konrad.banachewicz at gmail.com  Sat Oct 24 13:50:46 2009
From: konrad.banachewicz at gmail.com (Konrad Banachewicz)
Date: Sat, 24 Oct 2009 13:50:46 +0200
Subject: [R-SIG-Finance] RBloomberg error?
In-Reply-To: <a7d6d2740910150307t49269a29gc23c9a2f7fd71183@mail.gmail.com>
References: <204e4c50910140758v458eaa23v5a1d18862c4de91c@mail.gmail.com>
	<a7d6d2740910150307t49269a29gc23c9a2f7fd71183@mail.gmail.com>
Message-ID: <204e4c50910240450i111d32aam25794a3a4dec358a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091024/d76031b2/attachment.pl>

From jeff.a.ryan at gmail.com  Mon Oct 26 16:08:23 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 26 Oct 2009 10:08:23 -0500
Subject: [R-SIG-Finance] R CMD --meetup=Chicago --where=JaksTap --when=THIS
	THURSDAY!! (Oct 29)
Message-ID: <e8e755250910260808v4fbfcf20u7367caa60985647c@mail.gmail.com>

Chicagoland R (Finance) Users:

We are pleased to (re)announce a Fall meetup for Chicagoland R users. This
is open to anyone with an interest in R: practioners, researchers,
casual users and other interested parties.

WHEN: October 29, 2009 @5:30 <<<<THIS THURSDAY>>>>
WHERE: Jak's Tap www.jakstap.com

A short series of so-called lightning talks from some noted R
contributors and users is on the agenda. Speakers include:

Gib Basset (UIC)
Bryan Lewis
JD Long (Cerebral Mastication)
David St. John (UIC, ttrTests package)

Casual conversation and food will follow, courtesy of the
International Center for Futures and Derivatives at the University of
Illinois at Chicago and the organizers of the R/Finance conferences:
http://www.RinFinance.com

As expected there will be a heavy dose of finance conversation from those
in attendance!!!


Best,
Jeffrey Ryan
(on behalf of the organizing committee)


From windspeedo99 at gmail.com  Tue Oct 27 11:22:31 2009
From: windspeedo99 at gmail.com (Wind)
Date: Tue, 27 Oct 2009 18:22:31 +0800
Subject: [R-SIG-Finance] how to use xts in setClass()
Message-ID: <d718c8210910270322h79ec3525va92637290c32a989@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091027/d5066c36/attachment.pl>

From raje.pradeep at gmail.com  Tue Oct 27 12:08:11 2009
From: raje.pradeep at gmail.com (Pradeep Raje)
Date: Tue, 27 Oct 2009 16:38:11 +0530
Subject: [R-SIG-Finance] agent-based models: any progress?
Message-ID: <110cbaf80910270408we369dycc2158d785662787@mail.gmail.com>

Dear all:

There was a thread sometime on 2007 on agent-based models, but no
updates. What is the latest status on implementation of agent-based
models after package simecol?

I was looking to implement  the evolution algorithm in Cont and
Bouchaud [Macroeconomic Dynamics, 4, 170 (2000)] or Eguiluz and
Zimmermann PRL 85(26) 5659?

any help or guidance will be much appreciated.

regards,
pradeep
18?96?50??N 72?82?53?? E


From windspeedo99 at gmail.com  Tue Oct 27 12:30:12 2009
From: windspeedo99 at gmail.com (Wind)
Date: Tue, 27 Oct 2009 19:30:12 +0800
Subject: [R-SIG-Finance] how to use xts in setClass()
In-Reply-To: <d718c8210910270322h79ec3525va92637290c32a989@mail.gmail.com>
References: <d718c8210910270322h79ec3525va92637290c32a989@mail.gmail.com>
Message-ID: <d718c8210910270430v3983dd67x3fe87c5867dd5e33@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091027/8457d465/attachment.pl>

From philipplincoln.au at gmail.com  Tue Oct 27 12:55:57 2009
From: philipplincoln.au at gmail.com (Philipp Lincoln)
Date: Tue, 27 Oct 2009 22:55:57 +1100
Subject: [R-SIG-Finance] Extracting a fitted series from an ARIMA model
Message-ID: <333a47e20910270455i4a388566mfbe6fff191e6e1d5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091027/bbc7d399/attachment.pl>

From nelson.ana at gmail.com  Tue Oct 27 14:44:53 2009
From: nelson.ana at gmail.com (Ana Nelson)
Date: Tue, 27 Oct 2009 13:44:53 +0000
Subject: [R-SIG-Finance] agent-based models: any progress?
In-Reply-To: <110cbaf80910270408we369dycc2158d785662787@mail.gmail.com>
References: <110cbaf80910270408we369dycc2158d785662787@mail.gmail.com>
Message-ID: <a7d6d2740910270644hef7f1a0icfe1c4e74e05d99@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091027/524cc2e8/attachment.pl>

From jeff.a.ryan at gmail.com  Tue Oct 27 16:29:39 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 27 Oct 2009 10:29:39 -0500
Subject: [R-SIG-Finance] how to use xts in setClass()
In-Reply-To: <d718c8210910270322h79ec3525va92637290c32a989@mail.gmail.com>
References: <d718c8210910270322h79ec3525va92637290c32a989@mail.gmail.com>
Message-ID: <e8e755250910270829s39ff496dqf65a3d9e7a90cda6@mail.gmail.com>

In fact zoo doesn't work for me by default.  I think the issue is that
quantmod calls setOldClass for you (to use S3 as S4 slots).

library(zoo)
setClass("trader",representation(prices="zoo",indicator="zoo"))

[1] "trader"
Warning message:
In .completeClassSlots(ClassDef, where) :
  undefined slot classes in definition of "trader": prices(class
"zoo"), indicator(class "zoo")


Keeping the environment as clean as possibly (don't attach other
packages that can change the game) is the best way to find the issue.

library(xts)
setClass("trader",representation(prices="xts",indicator="xts"))

[1] "trader"
Warning message:
In .completeClassSlots(ClassDef, where) :
  undefined slot classes in definition of "trader": prices(class
"xts"), indicator(class "xts")


# have to call setOldClass ... this really should be setS3Class IMO,
as "Old" implies bad...

setOldClass("xts")
setClass("trader",representation(prices="xts",indicator="xts"))
[1] "trader"

getClass("trader")
Class "trader" [in ".GlobalEnv"]

Slots:

Name:     prices indicator
Class:       xts       xts

As may be evident from my previous work, I'd petition you not to use
S4 classes until S5 comes out ;)  quantmod is in the process of
removing all S4 objects, instead migrating to more powerful (though
slightly less OO style in some sense) functional closures.  Yes
_functional closures_...

One other point, the newest xts_0.6-8 from CRAN should be used now, as
there were some major improvements and bug fixes implemented in the
release.

Best,
Jeff

On Tue, Oct 27, 2009 at 5:22 AM, Wind <windspeedo99 at gmail.com> wrote:
> I wonder how to ?use xts in setClass(). ? It seems that zoo is OK.
> Thanks.
>
> Wind
>
>
>> library(quantmod)
> Loading required package: xts
> Loading required package: zoo
>
> Attaching package: 'zoo'
>
>
> The following object(s) are masked from package:base :
>
> ?as.Date.numeric
>
> xts now requires a valid TZ environment variable to be set
> ?your current TZ:CST-8
> Loading required package: Defaults
> Loading required package: TTR
>> setClass("trader",representation(prices="zoo",indicator="zoo"))
> [1] "trader"
>> setClass("trader",representation(prices="xts",indicator="xts"))
> [1] "trader"
> Warning message:
> In .completeClassSlots(ClassDef, where) :
> ?undefined slot classes in definition of "trader": prices(class "xts"),
> indicator(class "xts")
>
>> sessionInfo()
> R version 2.9.2 (2009-08-24)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Chinese (Simplified)_People's Republic of
> China.936;LC_CTYPE=Chinese (Simplified)_People's Republic of
> China.936;LC_MONETARY=Chinese (Simplified)_People's Republic of
> China.936;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] quantmod_0.3-11 TTR_0.20-1 ? ? ?Defaults_1.1-1 ?xts_0.6-7
> [5] zoo_1.5-8
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.2 ? ? ?lattice_0.17-25
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From windspeedo99 at gmail.com  Tue Oct 27 17:09:07 2009
From: windspeedo99 at gmail.com (Wind)
Date: Wed, 28 Oct 2009 00:09:07 +0800
Subject: [R-SIG-Finance] how to use xts in setClass()
In-Reply-To: <e8e755250910270829s39ff496dqf65a3d9e7a90cda6@mail.gmail.com>
References: <d718c8210910270322h79ec3525va92637290c32a989@mail.gmail.com>
	<e8e755250910270829s39ff496dqf65a3d9e7a90cda6@mail.gmail.com>
Message-ID: <d718c8210910270909n10e13ac0x18d270f2dff8ea06@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091028/188d5974/attachment.pl>

From guillaume.yziquel at citycable.ch  Tue Oct 27 17:55:45 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Tue, 27 Oct 2009 17:55:45 +0100
Subject: [R-SIG-Finance] how to use xts in setClass()
In-Reply-To: <d718c8210910270909n10e13ac0x18d270f2dff8ea06@mail.gmail.com>
References: <d718c8210910270322h79ec3525va92637290c32a989@mail.gmail.com>	<e8e755250910270829s39ff496dqf65a3d9e7a90cda6@mail.gmail.com>
	<d718c8210910270909n10e13ac0x18d270f2dff8ea06@mail.gmail.com>
Message-ID: <4AE72611.1000603@citycable.ch>

Wind a ?crit :
> 
> I am a little curious on your functional closures design plan. I know
> functional language such as OCaml or kdb+ are good for time series
> calcualtions.
> 
> On Tue, Oct 27, 2009 at 11:29 PM, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:
> 
>> slightly less OO style in some sense) functional closures.  Yes
>> _functional closures_...

Grin...

Slightly off-topic: There's a binding allowing to embed R in OCaml.

	http://home.gna.org/ocaml-r/gettingstarted.en.html

And a debian package:

	http://yziquel.homelinux.org/topos/debian-ocamlr.html

A 0.2 version should be available in the coming month or so, with tricks 
inspired from littler to avoid calling R CMD all the time. Hopefully the 
whole stuff will be in Debian soon enough.

All the best,

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From binabina at bellsouth.net  Tue Oct 27 20:17:51 2009
From: binabina at bellsouth.net (zubin)
Date: Tue, 27 Oct 2009 15:17:51 -0400
Subject: [R-SIG-Finance] getQuote real time
Message-ID: <4AE7475F.4020904@bellsouth.net>

Hello,

Testing real time getQuote options, does not look like yahoo is 
providing real time quotes via this method call? anyone know of a  
workaround? Ask (RT) and Bid (RT) are the same as the delayed quotes.


library(quantmod)
getQuote("FAS;XLF;XLE",what=yahooQF(c("Open","Bid","Ask","Last Trade 
(Price Only)","Volume","Ask (Real-time)", "Bid (Real-time)")))

             Trade Time  Open   Bid   Ask  Last   Volume Ask (RT) Bid (RT)
FAS 2009-10-27 03:03:00 77.90 77.04 77.09 77.04 26999444    77.09    77.04
XLF 2009-10-27 03:03:00 14.72 14.66 14.67 14.66 79448224    14.67    14.66
XLE 2009-10-27 03:03:00 57.48 58.11 58.12 58.11 19884684    58.12    58.11


From brian at braverock.com  Tue Oct 27 20:22:31 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 27 Oct 2009 14:22:31 -0500
Subject: [R-SIG-Finance] getQuote real time
In-Reply-To: <4AE7475F.4020904@bellsouth.net>
References: <4AE7475F.4020904@bellsouth.net>
Message-ID: <4AE74877.3090007@braverock.com>

zubin wrote:
> Hello,
>
> Testing real time getQuote options, does not look like yahoo is 
> providing real time quotes via this method call? anyone know of a  
> workaround? 

Yes.  Pay for a data feed (see RBloomberg), or get data from your broker 
(see the IBrokers package, for eample)

You aren't going to get any non-delayed real-time data for free.

This topic has been discussed multiple times on this list.

   - Brian


From windspeedo99 at gmail.com  Wed Oct 28 02:28:54 2009
From: windspeedo99 at gmail.com (Wind)
Date: Wed, 28 Oct 2009 09:28:54 +0800
Subject: [R-SIG-Finance] how to use xts in setClass()
In-Reply-To: <4AE72611.1000603@citycable.ch>
References: <d718c8210910270322h79ec3525va92637290c32a989@mail.gmail.com>
	<e8e755250910270829s39ff496dqf65a3d9e7a90cda6@mail.gmail.com>
	<d718c8210910270909n10e13ac0x18d270f2dff8ea06@mail.gmail.com>
	<4AE72611.1000603@citycable.ch>
Message-ID: <d718c8210910271828k36748384i17d53277ed428587@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091028/8297559b/attachment.pl>

From guillaume.yziquel at citycable.ch  Wed Oct 28 03:55:17 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Wed, 28 Oct 2009 03:55:17 +0100
Subject: [R-SIG-Finance] how to use xts in setClass()
In-Reply-To: <d718c8210910271828k36748384i17d53277ed428587@mail.gmail.com>
References: <d718c8210910270322h79ec3525va92637290c32a989@mail.gmail.com>	
	<e8e755250910270829s39ff496dqf65a3d9e7a90cda6@mail.gmail.com>	
	<d718c8210910270909n10e13ac0x18d270f2dff8ea06@mail.gmail.com>	
	<4AE72611.1000603@citycable.ch>
	<d718c8210910271828k36748384i17d53277ed428587@mail.gmail.com>
Message-ID: <4AE7B295.3070903@citycable.ch>

Wind a ?crit :
> Does the OCaml-R support windows edition of OCaml?

Haven't tried yet (I do not have Windows). As it stands, no. 
Nevertheless, here's the current state of the whole stuff:

-1- You would need to have dynamic libraries for R. On Debian, it's 
there by default, but on Windows, I do not know.

-2- You would have to adjust the build system of OCaml-R on Windows. 
There's probably no real issue there, except taking time for it.

-3- Should stick with 0.1 of OCaml-R. 0.2 uses some trickery and Unix 
system calls to set environment variables to avoid launching everything 
with R CMD. Help on making it work on Windows would be appreciated.

Aside from these issues, I do not believe there is any real problem with 
using it on Windows. I'd nevertheless recommend using GODI & Cygwin & MinGW.

But all this talk would perhaps be better off on the ocaml-r-devel 
mailing list.

	https://gna.org/mail/?group=ocaml-r

> Thanks for your works making both R and OCaml more powerful.

Thanks for your interest.

> Wind
> 
> On Wed, Oct 28, 2009 at 12:55 AM, Guillaume Yziquel <
> guillaume.yziquel at citycable.ch> wrote:
> 
>> Wind a ?crit :
>>
>>> I am a little curious on your functional closures design plan. I know
>>> functional language such as OCaml or kdb+ are good for time series
>>> calcualtions.
>>>
>>> On Tue, Oct 27, 2009 at 11:29 PM, Jeff Ryan <jeff.a.ryan at gmail.com>
>>> wrote:
>>>
>>>  slightly less OO style in some sense) functional closures.  Yes
>>>> _functional closures_...
>>>>
>> Grin...
>>
>> Slightly off-topic: There's a binding allowing to embed R in OCaml.
>>
>>        http://home.gna.org/ocaml-r/gettingstarted.en.html
>>
>> And a debian package:
>>
>>        http://yziquel.homelinux.org/topos/debian-ocamlr.html
>>
>> A 0.2 version should be available in the coming month or so, with tricks
>> inspired from littler to avoid calling R CMD all the time. Hopefully the
>> whole stuff will be in Debian soon enough.
>>
>> All the best,
>>
>> --
>>     Guillaume Yziquel
>> http://yziquel.homelinux.org/
>>
> 


-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From clhis_alberty at yahoo.com.br  Wed Oct 28 19:26:31 2009
From: clhis_alberty at yahoo.com.br (Clhis Alberty)
Date: Wed, 28 Oct 2009 11:26:31 -0700 (PDT)
Subject: [R-SIG-Finance] Manipulate database
In-Reply-To: <d718c8210910271828k36748384i17d53277ed428587@mail.gmail.com>
References: <d718c8210910270322h79ec3525va92637290c32a989@mail.gmail.com>
	<e8e755250910270829s39ff496dqf65a3d9e7a90cda6@mail.gmail.com>
	<d718c8210910270909n10e13ac0x18d270f2dff8ea06@mail.gmail.com>
	<4AE72611.1000603@citycable.ch>
	<d718c8210910271828k36748384i17d53277ed428587@mail.gmail.com>
Message-ID: <821569.54592.qm@web54110.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091028/360feacb/attachment.pl>

From brian at braverock.com  Wed Oct 28 19:46:32 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 28 Oct 2009 13:46:32 -0500
Subject: [R-SIG-Finance] Manipulate database
In-Reply-To: <821569.54592.qm@web54110.mail.re2.yahoo.com>
References: <d718c8210910270322h79ec3525va92637290c32a989@mail.gmail.com>	<e8e755250910270829s39ff496dqf65a3d9e7a90cda6@mail.gmail.com>	<d718c8210910270909n10e13ac0x18d270f2dff8ea06@mail.gmail.com>	<4AE72611.1000603@citycable.ch>	<d718c8210910271828k36748384i17d53277ed428587@mail.gmail.com>
	<821569.54592.qm@web54110.mail.re2.yahoo.com>
Message-ID: <4AE89188.9060803@braverock.com>

While all this can be accomplished in R, this question would be best 
asked on R-help, as it has nothing to do with finance specifically.  If 
you want an answer here or on r-help, I would suggest providing a 
reproducible example and the code you've tried.

That said, if you have a "database", then write your database query to 
give you the data in the format you need it in.  A couple of "join" and 
"coalesce" statements in a "where" look like they would do the trick.

Regards,

    - Brian

Clhis Alberty wrote:
> Guys
> I have a problem.
> I have a  Big database (in the table below) that i need to manupulate the data across. But I?m not getting.
> I tried to use function aggragate,table and tapply, to a cross date whit the clossing price equit. But i din?t succeed.
>  exemplo
> My database
>
> Simbulo Per?odo      Data   hora Abertura M?ximo M?nimo Fechamento Quantidade Financeiro
> 1  ABCB11       D 24/9/2007 185000    93.89   93.9   93.7       93.8      16300    1529782
> 2  PETR4       D 21/9/2007 185000       92  94.06     92      92.95      91800    8448657
> 3  PETR3       D 20/9/2007 185000     93.4   93.5   92.5       92.5      11100    1031339
> 4  VALE5        D 19/9/2007 185000       94     94   93.5      93.99       3300     309885
> 5  VALE3       D 18/9/2007 185000    92.99     94   91.5         94      10500     976880
> 6  BBAS3       D 17/9/2007 185000       93     93     92       92.7      49700    4604635
>  
> I will need to do (date / Closing Equite)
>
>          Date ABCB11 PETR4 PETR3 VALE5 VALE3 BBAS3 
> 24/9/2007    93.7 93.7 93.7 93.7 93.7 93.7 
> 21/9/2007    92 92 92 92 92 92 
> 20/9/2007      92.5 92.5 92.5 92.5 92.5 92.5 
> 19/9/2007    93.5 93.5 93.5 93.5 93.5 93.5 
> 18/9/2007    91.5 91.5 91.5 91.5 91.5 91.5 
> 17/9/2007    92 92 92 92 92 92 
>
> what is the function to accomplishment this intersection?
> someone help me?
> Thank.
> Clhis Alberty
>
>
>       ____________________________________________________________________________________
> [[elided Yahoo spam]]
>
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From jeff.a.ryan at gmail.com  Wed Oct 28 21:41:19 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Wed, 28 Oct 2009 15:41:19 -0500
Subject: [R-SIG-Finance] R/Finance 2010: Applied Finance with R --- Call for
	Papers
Message-ID: <e8e755250910281341j44a79530m9c4b2f34bb39e717@mail.gmail.com>

Call for Papers:

R/Finance 2010: Applied Finance with R
April 16 and 17, 2010
Chicago, IL, USA

The second annual R/Finance conference for applied finance using R
will be held this spring in Chicago, IL, USA on April 16 and 17, 2010.
 The two-day conference will cover topics including portfolio
management, time series analysis, advanced risk tools,
high-performance computing, market microstructure and econometrics.
All will be discussed within the context of using R as a primary tool
for financial risk management and trading.

One-page abstracts or complete papers (in txt or pdf format) are
invited for consideration. Academic and practitioner research
proposals related to R are encouraged. We will accept submissions for
full talks, abbreviated "lightning talks", and a limited number of
pre-conference tutorial sessions.  Please indicate with your
submission if you would be willing to produce a formal paper (10-15
pages) for a peer-reviewed conference proceedings publication.

Presenters are strongly encouraged to provide working R code to
accompany the presentation/paper.  Data sets should also be made
public for the purposes of reproducibility (though we realize this may
be limited due to contracts with data vendors). Preference may be
given to presenters who have released R packages.

Please send submissions to: committee at RinFinance.com

The submission deadline is December 31st, 2010.

Submissions will be evaluated and submitters notified via email on a
rolling basis. Determination of whether a presentation will be a long
presentation or a lightning talk will be made once the full list of
presenters is known.

R/Finance 2009 included keynote presentations by Patrick Burns, Robert
Grossman, David Kane, Roger Koenker, David Ruppert, Diethelm Wuertz,
and Eric Zivot.  Attendees included practitioners, academics, and
government officials. We anticipate another exciting line-up for 2010
and will announce details at the conference website
http://www.RinFinance.com as they become available.

For the program committee:
    Gib Bassett, Peter Carl, Dirk Eddelbuettel, John Miller,
    Brian Peterson, Dale Rosenthal, Jeffrey Ryan


From michaelkristoffernagl at gmail.com  Thu Oct 29 02:30:42 2009
From: michaelkristoffernagl at gmail.com (Michael Kristoffer Nagl)
Date: Thu, 29 Oct 2009 02:30:42 +0100
Subject: [R-SIG-Finance] gofCopula - Intuition?
Message-ID: <000001ca5837$6e975ee0$4bc61ca0$@com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091029/74798a13/attachment.pl>

From lunamoonmoon at gmail.com  Thu Oct 29 04:45:54 2009
From: lunamoonmoon at gmail.com (Luna Moon)
Date: Wed, 28 Oct 2009 20:45:54 -0700
Subject: [R-SIG-Finance] modeling and forecasting commodity time series?
Message-ID: <ad7856ef0910282045g52363fcaqb4f172e73f1b0b96@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091028/152b527b/attachment.pl>

From val.neyman at gmail.com  Thu Oct 29 19:00:21 2009
From: val.neyman at gmail.com (Val Neyman)
Date: Thu, 29 Oct 2009 11:00:21 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Volatility Swaps
In-Reply-To: <26115913.post@talk.nabble.com>
References: <25530806.post@talk.nabble.com> <26115913.post@talk.nabble.com>
Message-ID: <26117900.post@talk.nabble.com>


I think you need a little more than that since an existing volatility swap
would need the current realized vol since effective date and the implied vol
until expiry. So something like this: vol(t,t_ef-t_ex) = RV(t-t_ef) +
IV(t_ex - t). Where t_e is the effective date of the vol swap, t_ex is the
expiration of the swap, IV is the implied vol, and RV is the realized vol.
The MV of the vol swap at t (where t>=t_ef) would be
PV(Notional*(vol(t_ef,t_ef-t_ex) - vol(t,t_ef-t_ex))). On t_ef, the value of
the swap = 0.

Any ideas on how to implement this would be appreciated. Thanks.


Luwingo wrote:
> 
> Hi Val- Not at present (to my knowledge), but it's not very hard to write
> one. Volatility swaps are after all just cashflow swaps, and those aren't
> hard to value even in a spreadsheet. You will basically need a volatility
> curve and a risk-free spot curve for discounting; after that, it's all
> just a PV calculation.
> 
> 
> Val Neyman wrote:
>> 
>> Does anyone know if there are any functions to price volatility swaps in
>> Rmetrics? Thanks.
>> 
> 
> 

-- 
View this message in context: http://www.nabble.com/Volatility-Swaps-tp25530806p26117900.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From cmdr_rogue at hotmail.com  Fri Oct 30 00:57:56 2009
From: cmdr_rogue at hotmail.com (Luwingo)
Date: Thu, 29 Oct 2009 16:57:56 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Volatility Swaps
In-Reply-To: <26117900.post@talk.nabble.com>
References: <25530806.post@talk.nabble.com> <26115913.post@talk.nabble.com>
	<26117900.post@talk.nabble.com>
Message-ID: <26122917.post@talk.nabble.com>


Actually I think Eydeland and Wolyniec cover vol swaps in Energy and Power
Risk Management. Their notation is a little cumbersome, but their methods
work, and that text is practically standard for the EPRM industry.


Val Neyman wrote:
> 
> I think you need a little more than that since an existing volatility swap
> would need the current realized vol since effective date and the implied
> vol until expiry. So something like this: vol(t,t_ef-t_ex) = RV(t-t_ef) +
> IV(t_ex - t). Where t_e is the effective date of the vol swap, t_ex is the
> expiration of the swap, IV is the implied vol, and RV is the realized vol.
> The MV of the vol swap at t (where t>=t_ef) would be
> PV(Notional*(vol(t_ef,t_ef-t_ex) - vol(t,t_ef-t_ex))). On t_ef, the value
> of the swap = 0.
> 
> Any ideas on how to implement this would be appreciated. Thanks.
> 
> 
> Luwingo wrote:
>> 
>> Hi Val- Not at present (to my knowledge), but it's not very hard to write
>> one. Volatility swaps are after all just cashflow swaps, and those aren't
>> hard to value even in a spreadsheet. You will basically need a volatility
>> curve and a risk-free spot curve for discounting; after that, it's all
>> just a PV calculation.
>> 
>> 
>> Val Neyman wrote:
>>> 
>>> Does anyone know if there are any functions to price volatility swaps in
>>> Rmetrics? Thanks.
>>> 
>> 
>> 
> 
> 

-- 
View this message in context: http://www.nabble.com/Volatility-Swaps-tp25530806p26122917.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From rhelpacc at gmail.com  Fri Oct 30 01:22:53 2009
From: rhelpacc at gmail.com (R_help Help)
Date: Thu, 29 Oct 2009 20:22:53 -0400
Subject: [R-SIG-Finance] Fast optimizer
Message-ID: <ad1ead5f0910291722y3d37ad21id55a53c8ee1e288d@mail.gmail.com>

Hi,

I'm using optim with box constraints to MLE on about 100 data points.
It goes quite slow even on 4GB machine. I'm wondering if R has any
faster implementation? Also, if I'd like to impose
equality/nonequality constraints on parameters, which package I should
use? Any help would be appreciated. Thank you.

rc


From josh.m.ulrich at gmail.com  Fri Oct 30 02:13:40 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 29 Oct 2009 20:13:40 -0500
Subject: [R-SIG-Finance] Fast optimizer
In-Reply-To: <ad1ead5f0910291722y3d37ad21id55a53c8ee1e288d@mail.gmail.com>
References: <ad1ead5f0910291722y3d37ad21id55a53c8ee1e288d@mail.gmail.com>
Message-ID: <8cca69990910291813w73ba05f6pe86344b88a8f5cb@mail.gmail.com>

Please, please, please stop posting non-finance questions to this
list.  Also please note the instructions here:
http://www.r-project.org/mail.html

Particularly:
"Additionally, there are several specific Special Interest Group (=:
SIG) mailing lists; however do post to only one list at time ('SIG' or
general one), cross-posting is considered to be impolite."

Thanks,
Josh
--
http://www.fosstrading.com



On Thu, Oct 29, 2009 at 7:22 PM, R_help Help <rhelpacc at gmail.com> wrote:
> Hi,
>
> I'm using optim with box constraints to MLE on about 100 data points.
> It goes quite slow even on 4GB machine. I'm wondering if R has any
> faster implementation? Also, if I'd like to impose
> equality/nonequality constraints on parameters, which package I should
> use? Any help would be appreciated. Thank you.
>
> rc
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From rhelpacc at gmail.com  Fri Oct 30 02:21:41 2009
From: rhelpacc at gmail.com (R_help Help)
Date: Thu, 29 Oct 2009 21:21:41 -0400
Subject: [R-SIG-Finance] [R] Fast optimizer
In-Reply-To: <f6bbaff75ceb.4aea02cf@johnshopkins.edu>
References: <ad1ead5f0910291722y3d37ad21id55a53c8ee1e288d@mail.gmail.com>
	<f6bbaff75ceb.4aea02cf@johnshopkins.edu>
Message-ID: <ad1ead5f0910291821y7ce151b4xd48cc3c1d19a222c@mail.gmail.com>

Ok. I have the following likelihood function.

L <- p*dpois(x,a)*dpois(y,b+c)+(1-p)*dpois(x,a+c)*dpois(y,b)

where I have 100 points of (x,y) and parameters c(a,b,c,p) to
estimate. Constraints are:

0 < p < 1
a,b,c > 0
c < a
c < b

I construct a loglikelihood function out of this. First ignoring the
last two constraints, it takes optim with box constraint about 1-2 min
to estimate this. I have to estimate the MLE on about 200 rolling
windows. This will take very long. Is there any faster implementation?

Secondly, I cannot incorporate the last two contraints using optim function.

Thank you,

rc



On Thu, Oct 29, 2009 at 9:02 PM, Ravi Varadhan <rvaradhan at jhmi.edu> wrote:
>
> You have hardly given us any information for us to be able to help you. ?Give us more information on your problem, and, if possible, a minimal, self-contained example of what you are trying to do.
>
> Ravi.
> ____________________________________________________________________
>
> Ravi Varadhan, Ph.D.
> Assistant Professor,
> Division of Geriatric Medicine and Gerontology
> School of Medicine
> Johns Hopkins University
>
> Ph. (410) 502-2619
> email: rvaradhan at jhmi.edu
>
>
> ----- Original Message -----
> From: R_help Help <rhelpacc at gmail.com>
> Date: Thursday, October 29, 2009 8:24 pm
> Subject: [R] Fast optimizer
> To: r-help at r-project.org, r-sig-finance at stat.math.ethz.ch
>
>
>> Hi,
>>
>> I'm using optim with box constraints to MLE on about 100 data points.
>> It goes quite slow even on 4GB machine. I'm wondering if R has any
>> faster implementation? Also, if I'd like to impose
>> equality/nonequality constraints on parameters, which package I should
>> use? Any help would be appreciated. Thank you.
>>
>> rc
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>>
>> PLEASE do read the posting guide
>> and provide commented, minimal, self-contained, reproducible code.
>


From jiri.hoogland at gmail.com  Fri Oct 30 02:46:35 2009
From: jiri.hoogland at gmail.com (Jiri Hoogland)
Date: Thu, 29 Oct 2009 21:46:35 -0400
Subject: [R-SIG-Finance] merging a list of xts objects
Message-ID: <1c08fa330910291846h61f583e0o22c0001b79a859ed@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091029/5f39ca4d/attachment.pl>

From luethid at gmail.com  Fri Oct 30 09:26:33 2009
From: luethid at gmail.com (=?ISO-8859-1?Q?David_L=FCthi?=)
Date: Fri, 30 Oct 2009 09:26:33 +0100
Subject: [R-SIG-Finance] modeling and forecasting commodity time series?
In-Reply-To: <ad7856ef0910282045g52363fcaqb4f172e73f1b0b96@mail.gmail.com>
References: <ad7856ef0910282045g52363fcaqb4f172e73f1b0b96@mail.gmail.com>
Message-ID: <4AEAA339.3030703@gmail.com>

Hi Luna

Some work has been done by Eduardo Schwartz and his collaborators in the 
1990s. The package 'schwartz97' deals with the 2-factor (spot price and 
spot convenience-yield) model. This package is available under the 
Rmetrics project on R-forge as a fairly stable beta.

david

Luna Moon wrote:
> Hi all,
> 
> Could anybody please shed some lights on me about good books/literature
> about modeling and forecasting financial time series in the commodity space?
> 
> 
> Thanks so much!
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From axel.leroix at yahoo.fr  Fri Oct 30 12:24:47 2009
From: axel.leroix at yahoo.fr (Axel Leroix)
Date: Fri, 30 Oct 2009 04:24:47 -0700 (PDT)
Subject: [R-SIG-Finance] Time series temporal disaggregation
Message-ID: <252006.563.qm@web28007.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091030/dd2ae31c/attachment.pl>

From brian at braverock.com  Fri Oct 30 12:39:38 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 30 Oct 2009 06:39:38 -0500
Subject: [R-SIG-Finance] Time series temporal disaggregation (or: going
 from low frequency to higher frequency)
In-Reply-To: <252006.563.qm@web28007.mail.ukl.yahoo.com>
References: <252006.563.qm@web28007.mail.ukl.yahoo.com>
Message-ID: <4AEAD07A.9010008@braverock.com>

Axel Leroix wrote:
> Hi,
> This is a newbie question. 
> I would to be able to convert annual time series of flow data into quarterly data. I wonder if there is any existing R-function which permits to do it? In what package ?
>  
> I the archive, i found that some poeple speak about "tempDis" package for performing time series temporal disaggregation, but when I try to download it I can not found it in the list of proposed packages. 
>  
> Thank you in advance for your help.
>   
Well, as discussed multiple times on this list, going from annual (or 
any lower frequency) data to quarterly (or any higher frequency) data is 
questionable at best.  Think data snooping or look-ahead bias in your 
modeling.

Going the other direction, from say daily (or any higher frequency)  to 
monthly (or any lower frequency) , is easily accomplished with to.period 
for price/value data or Return.cumulative for returns data.

If you really do want to go in the black-magic direction of going from 
annual to quarterly, first make sure that the "annual" data was not 
first reported as monthly data or quarterly data (this is true for 
almost all macroeconomic series) and then go back to the source data at 
a higher frequency.

If even this is not possible, and you insist on the highly dubious 
practice of taking an annual number and turning it into four quarterly 
numbers, see the various na handling methods provided by the zoo 
package, most likely na.approx or na.spline.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From frainj at tcd.ie  Fri Oct 30 13:36:51 2009
From: frainj at tcd.ie (John Frain)
Date: Fri, 30 Oct 2009 12:36:51 +0000
Subject: [R-SIG-Finance] Time series temporal disaggregation (or: going
	from low frequency to higher frequency)
In-Reply-To: <4AEAD07A.9010008@braverock.com>
References: <252006.563.qm@web28007.mail.ukl.yahoo.com>
	<4AEAD07A.9010008@braverock.com>
Message-ID: <cfdde1650910300536p53c9cb34nde65cdf475085f43@mail.gmail.com>

Several Official Bodies (Central Banks Eurostat etc) use Chow-Lin
interpolation to derive  quarterly data from annual or monthly from
quarterly.  It may be the case that the higher frequency data have
only recently been produced.  I don't know if anyone has produced any
R routines but if you google "Chow-Lin interpolation" you will
probably find implementations in Matlab or Gauss that should transfer
easily to R.  My implementation in RATS can  be accessed at
ideas.repec.org/p/cbi/wpaper/2-rt-04.html.  This contains an
explanation of the methodology and references to the original papers.

The research section of the Eurostat website also contained some
relevant material.

Best Regards

John

2009/10/30 Brian G. Peterson <brian at braverock.com>:
> Axel Leroix wrote:
>>
>> Hi,
>> This is a newbie question. I would to be able to convert annual time
>> series of flow data into quarterly data. I wonder if there is any existing
>> R-function which permits to do it? In what package ?
>> ?I the archive, i found that some poeple speak about "tempDis" package for
>> performing time series temporal disaggregation, but when I try to download
>> it I can not found it in the list of proposed packages. ?Thank you in
>> advance for your help.
>>
>
> Well, as discussed multiple times on this list, going from annual (or any
> lower frequency) data to quarterly (or any higher frequency) data is
> questionable at best. ?Think data snooping or look-ahead bias in your
> modeling.
>
> Going the other direction, from say daily (or any higher frequency) ?to
> monthly (or any lower frequency) , is easily accomplished with to.period for
> price/value data or Return.cumulative for returns data.
>
> If you really do want to go in the black-magic direction of going from
> annual to quarterly, first make sure that the "annual" data was not first
> reported as monthly data or quarterly data (this is true for almost all
> macroeconomic series) and then go back to the source data at a higher
> frequency.
>
> If even this is not possible, and you insist on the highly dubious practice
> of taking an annual number and turning it into four quarterly numbers, see
> the various na handling methods provided by the zoo package, most likely
> na.approx or na.spline.
>
> Regards,
>
> ? ?- Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
>



-- 
John C Frain, Ph.D.
Trinity College Dublin
Dublin 2
Ireland
www.tcd.ie/Economics/staff/frainj/home.htm
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


From brian at braverock.com  Fri Oct 30 14:01:10 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 30 Oct 2009 08:01:10 -0500
Subject: [R-SIG-Finance] Time series temporal disaggregation (or: going
 from low frequency to higher frequency)
In-Reply-To: <cfdde1650910300536p53c9cb34nde65cdf475085f43@mail.gmail.com>
References: <252006.563.qm@web28007.mail.ukl.yahoo.com>	
	<4AEAD07A.9010008@braverock.com>
	<cfdde1650910300536p53c9cb34nde65cdf475085f43@mail.gmail.com>
Message-ID: <4AEAE396.1090208@braverock.com>

John,

Thanks for the pointers.  I'll certainly research this method. 

It appears on first reading that the Chow-Lin method requires 
multivariate indicator series to attempt to remove biases potentially 
introduced by the higher frequency indicators.  Do I understand this 
correctly? 

If so, is the resulting series truly "unbiased", or are the biases 
introduced by construction via the indicator, and then minimized by the 
distribution of the residual?

Also, you would not be able to decompose a univariate series of annual 
numbers, as I thought was proposed by the original poster in this 
thread, without identifying indicators.  Correct?

Thanks again,

  - Brian

John Frain wrote:
> Several Official Bodies (Central Banks Eurostat etc) use Chow-Lin
> interpolation to derive  quarterly data from annual or monthly from
> quarterly.  It may be the case that the higher frequency data have
> only recently been produced.  I don't know if anyone has produced any
> R routines but if you google "Chow-Lin interpolation" you will
> probably find implementations in Matlab or Gauss that should transfer
> easily to R.  My implementation in RATS can  be accessed at
> ideas.repec.org/p/cbi/wpaper/2-rt-04.html.  This contains an
> explanation of the methodology and references to the original papers.
>
> The research section of the Eurostat website also contained some
> relevant material.
>
> Best Regards
>
> John
>
> 2009/10/30 Brian G. Peterson <brian at braverock.com>:
>   
>> Axel Leroix wrote:
>>     
>>> Hi,
>>> This is a newbie question. I would to be able to convert annual time
>>> series of flow data into quarterly data. I wonder if there is any existing
>>> R-function which permits to do it? In what package ?
>>>  I the archive, i found that some poeple speak about "tempDis" package for
>>> performing time series temporal disaggregation, but when I try to download
>>> it I can not found it in the list of proposed packages.  Thank you in
>>> advance for your help.
>>>
>>>       
>> Well, as discussed multiple times on this list, going from annual (or any
>> lower frequency) data to quarterly (or any higher frequency) data is
>> questionable at best.  Think data snooping or look-ahead bias in your
>> modeling.
>>
>> Going the other direction, from say daily (or any higher frequency)  to
>> monthly (or any lower frequency) , is easily accomplished with to.period for
>> price/value data or Return.cumulative for returns data.
>>
>> If you really do want to go in the black-magic direction of going from
>> annual to quarterly, first make sure that the "annual" data was not first
>> reported as monthly data or quarterly data (this is true for almost all
>> macroeconomic series) and then go back to the source data at a higher
>> frequency.
>>
>> If even this is not possible, and you insist on the highly dubious practice
>> of taking an annual number and turning it into four quarterly numbers, see
>> the various na handling methods provided by the zoo package, most likely
>> na.approx or na.spline.
>>
>> Regards,
>>
>>    - Brian
>>
>> --
>> Brian G. Peterson
>> http://braverock.com/brian/
>> Ph: 773-459-4973
>> IM: bgpbraverock
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>>
>>     
>
>
>
>


From jeff.a.ryan at gmail.com  Fri Oct 30 15:17:36 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 30 Oct 2009 09:17:36 -0500
Subject: [R-SIG-Finance] merging a list of xts objects
In-Reply-To: <1c08fa330910291846h61f583e0o22c0001b79a859ed@mail.gmail.com>
References: <1c08fa330910291846h61f583e0o22c0001b79a859ed@mail.gmail.com>
Message-ID: <e8e755250910300717k248244fdo38d0b61f79d81b9e@mail.gmail.com>

As L is now a list, you lose the xts dispatch.

Try:

do.call("merge",L)
           X1.1 X1.2 X1.3 X1.4 X2.1 X2.2 X2.3 X2.4 X3.1 X3.2 X3.3 X3.4
2009-10-19    1    1    1    1    2    2    2    2    3    3    3    3
2009-10-20    1    1    1    1    2    2    2    2    3    3    3    3
2009-10-21    1    1    1    1    2    2    2    2    3    3    3    3
2009-10-22    1    1    1    1    2    2    2    2    3    3    3    3
2009-10-23    1    1    1    1    2    2    2    2    3    3    3    3
2009-10-24    1    1    1    1    2    2    2    2    3    3    3    3
2009-10-25    1    1    1    1    2    2    2    2    3    3    3    3
2009-10-26    1    1    1    1    2    2    2    2    3    3    3    3
2009-10-27    1    1    1    1    2    2    2    2    3    3    3    3
2009-10-28    1    1    1    1    2    2    2    2    3    3    3    3

HTH
Jeff

On Thu, Oct 29, 2009 at 8:46 PM, Jiri Hoogland <jiri.hoogland at gmail.com> wrote:
> Hi,
> i thought this should be pretty trivial, but i am missing something here
> Why can't ?I merge a list L of xts objects (all even with the same index)
> Thanks,
> Jiri
>
> # code
> library(xts)
>
> random.xts <- function(x0=1.0,n=100,k=10,c="A",rnd=F) {
> ?n.c <- length(c)*k
> ?if (rnd)
> ? ?x <- matrix(rnorm(n*n.c,x0,1),n,n.c)
> ?else
> ? ?x <- matrix(x0,n,n.c)
>
> ?t <- Sys.Date() - (1:n) -1
> ?x <- xts(x,t)
> ?colnames(x) <- paste(c,1:n.c,sep=".")
> ?return(x)
> }
>
> test <- function(n=10,k=4,c=3) {
> ?lapply(c(1:c),function(x) random.xts(x,n,k,paste(x)))
> }
>
> L <- test()
> merge(L)
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From artk at congruent.com  Sun Nov  1 23:38:38 2009
From: artk at congruent.com (Arthur Kreitman)
Date: Sun, 1 Nov 2009 14:38:38 -0800
Subject: [R-SIG-Finance] Simple XTS Quantmod Problem
Message-ID: <8DB8983924798A41B27C1E76AA913FE81327E89622@EXVMBX020-11.exch020.serverdata.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091101/4691d54a/attachment.pl>

From scott.p.macdonald at gmail.com  Mon Nov  2 00:06:28 2009
From: scott.p.macdonald at gmail.com (Scott MacDonald)
Date: Sun, 1 Nov 2009 16:06:28 -0700
Subject: [R-SIG-Finance] Simple XTS Quantmod Problem
In-Reply-To: <8DB8983924798A41B27C1E76AA913FE81327E89622@EXVMBX020-11.exch020.serverdata.net>
References: <8DB8983924798A41B27C1E76AA913FE81327E89622@EXVMBX020-11.exch020.serverdata.net>
Message-ID: <c4adf6e90911011506w6bfdce2bp488a00e98dde8a15@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091101/736420bf/attachment.pl>

From guillaume.yziquel at citycable.ch  Mon Nov  2 00:08:36 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Mon, 02 Nov 2009 00:08:36 +0100
Subject: [R-SIG-Finance] Simple XTS Quantmod Problem
In-Reply-To: <8DB8983924798A41B27C1E76AA913FE81327E89622@EXVMBX020-11.exch020.serverdata.net>
References: <8DB8983924798A41B27C1E76AA913FE81327E89622@EXVMBX020-11.exch020.serverdata.net>
Message-ID: <4AEE14F4.8090704@citycable.ch>

Arthur Kreitman a ?crit :
> I just installed Quantmod.  Trying their data loading example, I get the following
> 
>> getSymbols("YHOO",src="google")
> Error: could not find function "getSymbols"
> 
> I'm sort of a newbi to r and r-sig, thanks

When you type library(quantmod), do you get the following kind of output?

> Le chargement a n?cessit? le package : xts
> Le chargement a n?cessit? le package : zoo
> 
> Attachement du package : 'zoo'
> 
> 
> 	The following object(s) are masked from package:base :
> 
> 	 as.Date.numeric 
> 
> xts now requires a valid TZ variable to be set
>  no TZ var is set, setting to TZ=GMT
> Le chargement a n?cessit? le package : Defaults
> Le chargement a n?cessit? le package : TTR
> TTR: Technical Trading Rules (version 0.2)

Seems to me that quantmod may be installed, but it is not loaded, in 
your case.

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From artk at congruent.com  Mon Nov  2 01:49:05 2009
From: artk at congruent.com (Arthur Kreitman)
Date: Sun, 1 Nov 2009 16:49:05 -0800
Subject: [R-SIG-Finance] Simple XTS Quantmod Problem
In-Reply-To: <4AEE14F4.8090704@citycable.ch>
References: <8DB8983924798A41B27C1E76AA913FE81327E89622@EXVMBX020-11.exch020.serverdata.net>
	<4AEE14F4.8090704@citycable.ch>
Message-ID: <8DB8983924798A41B27C1E76AA913FE81327E8962E@EXVMBX020-11.exch020.serverdata.net>

worked, thanks

-----Original Message-----
From: Guillaume Yziquel [mailto:guillaume.yziquel at citycable.ch] 
Sent: Sunday, November 01, 2009 6:09 PM
To: Arthur Kreitman
Cc: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Simple XTS Quantmod Problem

Arthur Kreitman a ?crit :
> I just installed Quantmod.  Trying their data loading example, I get the following
> 
>> getSymbols("YHOO",src="google")
> Error: could not find function "getSymbols"
> 
> I'm sort of a newbi to r and r-sig, thanks

When you type library(quantmod), do you get the following kind of output?

> Le chargement a n?cessit? le package : xts
> Le chargement a n?cessit? le package : zoo
> 
> Attachement du package : 'zoo'
> 
> 
> 	The following object(s) are masked from package:base :
> 
> 	 as.Date.numeric 
> 
> xts now requires a valid TZ variable to be set
>  no TZ var is set, setting to TZ=GMT
> Le chargement a n?cessit? le package : Defaults
> Le chargement a n?cessit? le package : TTR
> TTR: Technical Trading Rules (version 0.2)

Seems to me that quantmod may be installed, but it is not loaded, in 
your case.

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/

From guillaume.yziquel at citycable.ch  Mon Nov  2 01:55:58 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Mon, 02 Nov 2009 01:55:58 +0100
Subject: [R-SIG-Finance] Simple XTS Quantmod Problem
In-Reply-To: <8DB8983924798A41B27C1E76AA913FE81327E8962E@EXVMBX020-11.exch020.serverdata.net>
References: <8DB8983924798A41B27C1E76AA913FE81327E89622@EXVMBX020-11.exch020.serverdata.net>
	<4AEE14F4.8090704@citycable.ch>
	<8DB8983924798A41B27C1E76AA913FE81327E8962E@EXVMBX020-11.exch020.serverdata.net>
Message-ID: <4AEE2E1E.6060505@citycable.ch>

Arthur Kreitman a ?crit :
> worked, thanks

You're welcome.

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From kagba2006 at yahoo.com  Mon Nov  2 13:53:33 2009
From: kagba2006 at yahoo.com (FMH)
Date: Mon, 2 Nov 2009 04:53:33 -0800 (PST)
Subject: [R-SIG-Finance] Additive decomposition method
Message-ID: <215635.58533.qm@web38307.mail.mud.yahoo.com>

Dear All,

I'm?doing an ?imputation?on?few?missing data?and?is looking?for an additive decomposition method in R. Could someone please advice me the way to do this?

Thank you
Fir





From knguyen at cs.umb.edu  Mon Nov  2 17:41:52 2009
From: knguyen at cs.umb.edu (Khanh Nguyen)
Date: Mon, 2 Nov 2009 11:41:52 -0500
Subject: [R-SIG-Finance] plotting market cap heatmap
Message-ID: <2871c9e10911020841s107baa5ame89956d8ef111448@mail.gmail.com>

Hi,

Let say I have this data frame.

> tickers <- toupper(letters[1:5])
> market.cap <- c(100, 60, 700, 1500, 450)
> change <- c(0.02, 0.004, 0.0012, 0.001, 0.030
> data <- data.frame(tickers, market.cap, change)
> data
  tickers market.cap change
1       A        100 0.0200
2       B         60 0.0040
3       C        700 0.0012
4       D       1500 0.0010
5       E        450 0.0300

and I'd like to plot a heatmap whose market cap is proportional to the
size of the cell, similar to http://finviz.com/map.ashx. Could
somebody please give me a pointer? Thanks.

-k


From noah at smartmediacorp.com  Mon Nov  2 18:49:36 2009
From: noah at smartmediacorp.com (Noah Silverman)
Date: Mon, 02 Nov 2009 09:49:36 -0800
Subject: [R-SIG-Finance] Grouped Log Likelihood function??
Message-ID: <4AEF1BB0.90605@smartmediacorp.com>

Hi,

I'm still fairly new to R and this is my first time posting to this group.

I've searched rseek.org high and low and can't seem to find an answer to 
this.

I want to maximize likelihood for a set of training data, but the data 
is grouped.  (Think multiple trials.)

It would probably be possible to do this with some nested for loops 
manually, but would be painfully slow.

The general formula is this...  (Please excuse my notation, but I can't 
write proper math formulas in an email.)

L(a) = product(
for( trial in 1:length(groups)){
     exp(a(i) * X) / sum(exp(a(i) * X))
}
)

As you can see, a normal logLik function will lose all the group data. 
This seems like a common enough application that there must me some easy 
function in R.

THEN, just to complicate things, I need to run a second logLik with some 
trickier data. There are 14 variables and I need to adjust them all to 
find the maximum likelihood from a formula. (kelly criterion on entries 
in a portfolio.)

Any suggestions would be gratefully appreciated.

Thanks!


From brian at braverock.com  Mon Nov  2 19:01:01 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 02 Nov 2009 12:01:01 -0600
Subject: [R-SIG-Finance] Grouped Log Likelihood function??
In-Reply-To: <4AEF1BB0.90605@smartmediacorp.com>
References: <4AEF1BB0.90605@smartmediacorp.com>
Message-ID: <4AEF1E5D.1070602@braverock.com>

Noah,

You'll likely get more complete responses from the main r-help list, as 
your problem is more of a statistics problem than a finance problem.

Regards,

    - Brian

Noah Silverman wrote:
> Hi,
>
> I'm still fairly new to R and this is my first time posting to this 
> group.
>
> I've searched rseek.org high and low and can't seem to find an answer 
> to this.
>
> I want to maximize likelihood for a set of training data, but the data 
> is grouped.  (Think multiple trials.)
>
> It would probably be possible to do this with some nested for loops 
> manually, but would be painfully slow.
>
> The general formula is this...  (Please excuse my notation, but I 
> can't write proper math formulas in an email.)
>
> L(a) = product(
> for( trial in 1:length(groups)){
>     exp(a(i) * X) / sum(exp(a(i) * X))
> }
> )
>
> As you can see, a normal logLik function will lose all the group data. 
> This seems like a common enough application that there must me some 
> easy function in R.
>
> THEN, just to complicate things, I need to run a second logLik with 
> some trickier data. There are 14 variables and I need to adjust them 
> all to find the maximum likelihood from a formula. (kelly criterion on 
> entries in a portfolio.)
>
> Any suggestions would be gratefully appreciated.
>
> Thanks!
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From brian at braverock.com  Mon Nov  2 19:04:39 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 02 Nov 2009 12:04:39 -0600
Subject: [R-SIG-Finance] plotting market cap heatmap
In-Reply-To: <2871c9e10911020841s107baa5ame89956d8ef111448@mail.gmail.com>
References: <2871c9e10911020841s107baa5ame89956d8ef111448@mail.gmail.com>
Message-ID: <4AEF1F37.7020904@braverock.com>

The only heatmap code I've used in R is based on correlations, usually 
paired with a dendogram.  I don't know if that code could be adapted. 

Maybe a question for r-help since this seems a bit more generally 
related to plotting things in R than the specifics of what you're plotting?

Regards,

   - Brian

Khanh Nguyen wrote:
> Hi,
>
> Let say I have this data frame.
>
>   
>> tickers <- toupper(letters[1:5])
>> market.cap <- c(100, 60, 700, 1500, 450)
>> change <- c(0.02, 0.004, 0.0012, 0.001, 0.030
>> data <- data.frame(tickers, market.cap, change)
>> data
>>     
>   tickers market.cap change
> 1       A        100 0.0200
> 2       B         60 0.0040
> 3       C        700 0.0012
> 4       D       1500 0.0010
> 5       E        450 0.0300
>
> and I'd like to plot a heatmap whose market cap is proportional to the
> size of the cell, similar to http://finviz.com/map.ashx. Could
> somebody please give me a pointer? Thanks.
>
> -k
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From peter at braverock.com  Mon Nov  2 19:24:41 2009
From: peter at braverock.com (Peter Carl)
Date: Mon, 2 Nov 2009 12:24:41 -0600 (CST)
Subject: [R-SIG-Finance] plotting market cap heatmap
In-Reply-To: <2871c9e10911020841s107baa5ame89956d8ef111448@mail.gmail.com>
References: <2871c9e10911020841s107baa5ame89956d8ef111448@mail.gmail.com>
Message-ID: <6109.64.190.216.194.1257186281.squirrel@mail.braverock.com>

These kinds of things are sometimes called "treemaps".  Take a look at the
'portfolio' package, particularly at the function called 'map.market'.

pcc
-- 
Peter Carl
http://www.braverock.com/~peter

> Hi,
>
> Let say I have this data frame.
>
>> tickers <- toupper(letters[1:5])
>> market.cap <- c(100, 60, 700, 1500, 450)
>> change <- c(0.02, 0.004, 0.0012, 0.001, 0.030
>> data <- data.frame(tickers, market.cap, change)
>> data
>   tickers market.cap change
> 1       A        100 0.0200
> 2       B         60 0.0040
> 3       C        700 0.0012
> 4       D       1500 0.0010
> 5       E        450 0.0300
>
> and I'd like to plot a heatmap whose market cap is proportional to the
> size of the cell, similar to http://finviz.com/map.ashx. Could
> somebody please give me a pointer? Thanks.
>
> -k
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From knguyen at cs.umb.edu  Mon Nov  2 19:52:19 2009
From: knguyen at cs.umb.edu (Khanh Nguyen)
Date: Mon, 2 Nov 2009 13:52:19 -0500
Subject: [R-SIG-Finance] Additive decomposition method
In-Reply-To: <215635.58533.qm@web38307.mail.mud.yahoo.com>
References: <215635.58533.qm@web38307.mail.mud.yahoo.com>
Message-ID: <2871c9e10911021052vc7d7c0aq94cca6a7a4582c42@mail.gmail.com>

Not sure whether this is what you are looking for, but you can try
decompose() or stl()

-k

On Mon, Nov 2, 2009 at 7:53 AM, FMH <kagba2006 at yahoo.com> wrote:
> Dear All,
>
> I'm?doing an ?imputation?on?few?missing data?and?is looking?for an additive decomposition method in R. Could someone please advice me the way to do this?
>
> Thank you
> Fir
>
>
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From binabina at bellsouth.net  Tue Nov  3 00:18:17 2009
From: binabina at bellsouth.net (zubin)
Date: Mon, 02 Nov 2009 18:18:17 -0500
Subject: [R-SIG-Finance] save XTS
Message-ID: <4AEF68B9.9070700@bellsouth.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091102/776b1b40/attachment.pl>

From josh.m.ulrich at gmail.com  Tue Nov  3 00:23:05 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 2 Nov 2009 17:23:05 -0600
Subject: [R-SIG-Finance] save XTS
In-Reply-To: <4AEF68B9.9070700@bellsouth.net>
References: <4AEF68B9.9070700@bellsouth.net>
Message-ID: <8cca69990911021523j19b3be01idac330fe6151eef4@mail.gmail.com>

Did you load xts via "library(xts)" before you tried to use the xts object?

Best,
Josh
--
http://www.fosstrading.com



On Mon, Nov 2, 2009 at 5:18 PM, zubin <binabina at bellsouth.net> wrote:
> Hello, have an XTS object, simply trying to save, but when i open the
> saved file and review the XTS object, its different, and most of the
> data does not exist. ?How does one save an XTS object correctly?
>
> Found this link but no mention;
> http://old.nabble.com/write.xts%28%29-and-read.xts%28%29-td25613485.html
>
>
> example: ?XTS object called VDF
> ?> str(vdf)
> An 'xts' object from 2009-10-16 09:30:02 to 2009-10-16 15:59:56 containing:
> ?Data: num [1:2919, 1:9] 87.3 87.2 87.2 87.2 87.2 ...
> ?- attr(*, "dimnames")=List of 2
> ?..$ : NULL
> ?..$ : chr [1:9] "FAS" "VIX" "UUP" "USO" ...
> ?Indexed by objects of class: [POSIXt,POSIXct] TZ: GMT
> ?xts Attributes:
> ?NULL
> ?> head(vdf)
> ? ? ? ? ? ? ? ? ? ? ?FAS ? VIX ?UUP ? USO ? ?GLD ? HYG ?term ? spread ? TNX
> 2009-10-16 09:30:02 87.26 21.72 22.5 39.88 102.74 85.99 4.214 0.826827 3.443
> 2009-10-16 09:30:10 87.24 21.72 22.5 39.88 102.77 85.99 4.214 0.826827 3.443
> 2009-10-16 09:30:17 87.23 21.72 22.5 39.88 102.74 85.99 4.214 0.826827 3.443
> 2009-10-16 09:30:25 87.23 21.72 22.5 39.89 102.74 85.99 4.209 0.826827 3.438
> 2009-10-16 09:30:33 87.23 21.72 22.5 39.90 102.74 85.99 4.209 0.826827 3.438
> 2009-10-16 09:30:40 87.23 21.72 22.5 39.90 102.76 85.99 4.209 0.826827 3.438
>
> I now save:
> ?> save(vdf,file="vdf.Rdata")
>
> I then open up vdf.Rdata, very different and i lose data.
>
> str(vdf)
> ?xts [1:2919, 1:9] 87.3 87.2 87.2 87.2 87.2 ...
> ?- attr(*, "dimnames")=List of 2
> ?..$ : NULL
> ?..$ : chr [1:9] "FAS" "VIX" "UUP" "USO" ...
> ?- attr(*, "index")= num [1:2919] 1.26e+09 1.26e+09 1.26e+09 1.26e+09
> 1.26e+09 ...
> ?- attr(*, ".indexTZ")= Named chr "GMT"
> ?..- attr(*, "names")= chr "TZ"
> ?- attr(*, ".indexCLASS")= chr [1:2] "POSIXt" "POSIXct"
> ?- attr(*, "class")= chr [1:2] "xts" "zoo"
>
> ?> head(vdf)
> [1] 87.26 87.24 87.23 87.23 87.23 87.23
> ?>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From jeff.a.ryan at gmail.com  Tue Nov  3 00:41:06 2009
From: jeff.a.ryan at gmail.com (J Ryan)
Date: Mon, 2 Nov 2009 17:41:06 -0600
Subject: [R-SIG-Finance] save XTS
In-Reply-To: <8cca69990911021523j19b3be01idac330fe6151eef4@mail.gmail.com>
References: <4AEF68B9.9070700@bellsouth.net>
	<8cca69990911021523j19b3be01idac330fe6151eef4@mail.gmail.com>
Message-ID: <EF7EB6F3-D89D-4ECF-B24E-7ECD2554838E@gmail.com>

The fact that you see a class attribute is a red flag that you haven't  
loaded the appropriate package, as Josh has also alluded to.

This is due to the fact that R hasn't any methods to handle zoo or xts  
natively, so you just see attributes. print.xts hides this normally.

HTH
Jeff

Jeffrey A. Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com

On Nov 2, 2009, at 5:23 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>  
wrote:

> Did you load xts via "library(xts)" before you tried to use the xts  
> object?
>
> Best,
> Josh
> --
> http://www.fosstrading.com
>
>
>
> On Mon, Nov 2, 2009 at 5:18 PM, zubin <binabina at bellsouth.net> wrote:
>> Hello, have an XTS object, simply trying to save, but when i open the
>> saved file and review the XTS object, its different, and most of the
>> data does not exist.  How does one save an XTS object correctly?
>>
>> Found this link but no mention;
>> http://old.nabble.com/write.xts%28%29-and-read.xts%28%29-td25613485.html
>>
>>
>> example:  XTS object called VDF
>>  > str(vdf)
>> An 'xts' object from 2009-10-16 09:30:02 to 2009-10-16 15:59:56  
>> containing:
>>  Data: num [1:2919, 1:9] 87.3 87.2 87.2 87.2 87.2 ...
>>  - attr(*, "dimnames")=List of 2
>>  ..$ : NULL
>>  ..$ : chr [1:9] "FAS" "VIX" "UUP" "USO" ...
>>  Indexed by objects of class: [POSIXt,POSIXct] TZ: GMT
>>  xts Attributes:
>>  NULL
>>  > head(vdf)
>>                      FAS   VIX  UUP   USO    GLD   HYG  term    
>> spread   TNX
>> 2009-10-16 09:30:02 87.26 21.72 22.5 39.88 102.74 85.99 4.214 0.826827 
>>  3.443
>> 2009-10-16 09:30:10 87.24 21.72 22.5 39.88 102.77 85.99 4.214 0.826827 
>>  3.443
>> 2009-10-16 09:30:17 87.23 21.72 22.5 39.88 102.74 85.99 4.214 0.826827 
>>  3.443
>> 2009-10-16 09:30:25 87.23 21.72 22.5 39.89 102.74 85.99 4.209 0.826827 
>>  3.438
>> 2009-10-16 09:30:33 87.23 21.72 22.5 39.90 102.74 85.99 4.209 0.826827 
>>  3.438
>> 2009-10-16 09:30:40 87.23 21.72 22.5 39.90 102.76 85.99 4.209 0.826827 
>>  3.438
>>
>> I now save:
>>  > save(vdf,file="vdf.Rdata")
>>
>> I then open up vdf.Rdata, very different and i lose data.
>>
>> str(vdf)
>>  xts [1:2919, 1:9] 87.3 87.2 87.2 87.2 87.2 ...
>>  - attr(*, "dimnames")=List of 2
>>  ..$ : NULL
>>  ..$ : chr [1:9] "FAS" "VIX" "UUP" "USO" ...
>>  - attr(*, "index")= num [1:2919] 1.26e+09 1.26e+09 1.26e+09 1.26e+09
>> 1.26e+09 ...
>>  - attr(*, ".indexTZ")= Named chr "GMT"
>>  ..- attr(*, "names")= chr "TZ"
>>  - attr(*, ".indexCLASS")= chr [1:2] "POSIXt" "POSIXct"
>>  - attr(*, "class")= chr [1:2] "xts" "zoo"
>>
>>  > head(vdf)
>> [1] 87.26 87.24 87.23 87.23 87.23 87.23
>>  >
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From binabina at bellsouth.net  Tue Nov  3 00:57:50 2009
From: binabina at bellsouth.net (zubin)
Date: Mon, 02 Nov 2009 18:57:50 -0500
Subject: [R-SIG-Finance] save XTS
In-Reply-To: <EF7EB6F3-D89D-4ECF-B24E-7ECD2554838E@gmail.com>
References: <4AEF68B9.9070700@bellsouth.net>
	<8cca69990911021523j19b3be01idac330fe6151eef4@mail.gmail.com>
	<EF7EB6F3-D89D-4ECF-B24E-7ECD2554838E@gmail.com>
Message-ID: <4AEF71FE.8030400@bellsouth.net>

yep, that was it.  loaded quantmod library, all is well.  thx

-zubin


J Ryan wrote:
> The fact that you see a class attribute is a red flag that you haven't 
> loaded the appropriate package, as Josh has also alluded to.
>
> This is due to the fact that R hasn't any methods to handle zoo or xts 
> natively, so you just see attributes. print.xts hides this normally.
>
> HTH
> Jeff
>
> Jeffrey A. Ryan
> jeffrey.ryan at insightalgo.com
>
> ia: insight algorithmics
> www.insightalgo.com
>
> On Nov 2, 2009, at 5:23 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> 
> wrote:
>
>> Did you load xts via "library(xts)" before you tried to use the xts 
>> object?
>>
>> Best,
>> Josh
>> -- 
>> http://www.fosstrading.com
>>
>>
>>
>> On Mon, Nov 2, 2009 at 5:18 PM, zubin <binabina at bellsouth.net> wrote:
>>> Hello, have an XTS object, simply trying to save, but when i open the
>>> saved file and review the XTS object, its different, and most of the
>>> data does not exist.  How does one save an XTS object correctly?
>>>
>>> Found this link but no mention;
>>> http://old.nabble.com/write.xts%28%29-and-read.xts%28%29-td25613485.html 
>>>
>>>
>>>
>>> example:  XTS object called VDF
>>>  > str(vdf)
>>> An 'xts' object from 2009-10-16 09:30:02 to 2009-10-16 15:59:56 
>>> containing:
>>>  Data: num [1:2919, 1:9] 87.3 87.2 87.2 87.2 87.2 ...
>>>  - attr(*, "dimnames")=List of 2
>>>  ..$ : NULL
>>>  ..$ : chr [1:9] "FAS" "VIX" "UUP" "USO" ...
>>>  Indexed by objects of class: [POSIXt,POSIXct] TZ: GMT
>>>  xts Attributes:
>>>  NULL
>>>  > head(vdf)
>>>                      FAS   VIX  UUP   USO    GLD   HYG  term   
>>> spread   TNX
>>> 2009-10-16 09:30:02 87.26 21.72 22.5 39.88 102.74 85.99 4.214 
>>> 0.826827 3.443
>>> 2009-10-16 09:30:10 87.24 21.72 22.5 39.88 102.77 85.99 4.214 
>>> 0.826827 3.443
>>> 2009-10-16 09:30:17 87.23 21.72 22.5 39.88 102.74 85.99 4.214 
>>> 0.826827 3.443
>>> 2009-10-16 09:30:25 87.23 21.72 22.5 39.89 102.74 85.99 4.209 
>>> 0.826827 3.438
>>> 2009-10-16 09:30:33 87.23 21.72 22.5 39.90 102.74 85.99 4.209 
>>> 0.826827 3.438
>>> 2009-10-16 09:30:40 87.23 21.72 22.5 39.90 102.76 85.99 4.209 
>>> 0.826827 3.438
>>>
>>> I now save:
>>>  > save(vdf,file="vdf.Rdata")
>>>
>>> I then open up vdf.Rdata, very different and i lose data.
>>>
>>> str(vdf)
>>>  xts [1:2919, 1:9] 87.3 87.2 87.2 87.2 87.2 ...
>>>  - attr(*, "dimnames")=List of 2
>>>  ..$ : NULL
>>>  ..$ : chr [1:9] "FAS" "VIX" "UUP" "USO" ...
>>>  - attr(*, "index")= num [1:2919] 1.26e+09 1.26e+09 1.26e+09 1.26e+09
>>> 1.26e+09 ...
>>>  - attr(*, ".indexTZ")= Named chr "GMT"
>>>  ..- attr(*, "names")= chr "TZ"
>>>  - attr(*, ".indexCLASS")= chr [1:2] "POSIXt" "POSIXct"
>>>  - attr(*, "class")= chr [1:2] "xts" "zoo"
>>>
>>>  > head(vdf)
>>> [1] 87.26 87.24 87.23 87.23 87.23 87.23
>>>  >
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>


From kagba2006 at yahoo.com  Tue Nov  3 13:47:53 2009
From: kagba2006 at yahoo.com (FMH)
Date: Tue, 3 Nov 2009 04:47:53 -0800 (PST)
Subject: [R-SIG-Finance] Additive decomposition method
In-Reply-To: <2871c9e10911021052vc7d7c0aq94cca6a7a4582c42@mail.gmail.com>
References: <215635.58533.qm@web38307.mail.mud.yahoo.com>
	<2871c9e10911021052vc7d7c0aq94cca6a7a4582c42@mail.gmail.com>
Message-ID: <582578.2802.qm@web38304.mail.mud.yahoo.com>

Hi, 

Thank you for the function.

I was trying to use the decompose function, but the program cannot run as there?were several missing values in my data frame. 

Could?someone advice me the way to handle on this matter?

Thanks

F






From rhelpacc at gmail.com  Wed Nov  4 05:54:52 2009
From: rhelpacc at gmail.com (R_help Help)
Date: Tue, 3 Nov 2009 23:54:52 -0500
Subject: [R-SIG-Finance] Sequential MLE on time series with rolling window
Message-ID: <ad1ead5f0911032054j35721824ke01d7701698f9935@mail.gmail.com>

Hi,

Assuming I have a time series on which I will perform rolling-window
MLE. In other words, if I stand at time t, I'm using points t-L+1 to t
for my MLE estimate of parameters at time t (here L is my rolling
window width). Next, at t+1, I'll do the same.

My question is that is there anyway to avoid performing MLE each time
like does the above. My impression is that rolling from point t to
t+1, the likelihood function is equivalent to cutting out point t-L+1
and add back likelihood at point t+1. Is there any smart way to
sequentially update the MLE instead of brute force calculation every
time? Any suggestion or reference would be appreciated. Thank you.

rc


From ajayshah at mayin.org  Wed Nov  4 06:18:42 2009
From: ajayshah at mayin.org (Ajay Shah)
Date: Wed, 4 Nov 2009 10:48:42 +0530
Subject: [R-SIG-Finance] Sequential MLE on time series with
	rolling	window
In-Reply-To: <ad1ead5f0911032054j35721824ke01d7701698f9935@mail.gmail.com>
References: <ad1ead5f0911032054j35721824ke01d7701698f9935@mail.gmail.com>
Message-ID: <20091104051842.GH172@ajay-shahs-macbook-pro.local>

On Tue, Nov 03, 2009 at 11:54:52PM -0500, R_help Help wrote:
> Hi,
> 
> Assuming I have a time series on which I will perform rolling-window
> MLE. In other words, if I stand at time t, I'm using points t-L+1 to t
> for my MLE estimate of parameters at time t (here L is my rolling
> window width). Next, at t+1, I'll do the same.
> 
> My question is that is there anyway to avoid performing MLE each time
> like does the above. My impression is that rolling from point t to
> t+1, the likelihood function is equivalent to cutting out point t-L+1
> and add back likelihood at point t+1. Is there any smart way to
> sequentially update the MLE instead of brute force calculation every
> time? Any suggestion or reference would be appreciated. Thank you.

One thing you can certainly do is: Take the optimal parameter vector
obtained using observations n to n+T and use it as the starting value
for estimation from observations (n+1) to (n+T+1). The two $\hat theta$
values should be similar to each other, hence just one or two
iterations should be required in making each step.

-- 
Ajay Shah                                      http://www.mayin.org/ajayshah  
ajayshah at mayin.org                             http://ajayshahblog.blogspot.com
<*(:-? - wizard who doesn't know the answer.


From jon.wanxian at gmail.com  Wed Nov  4 08:43:17 2009
From: jon.wanxian at gmail.com (Jonathan Ling)
Date: Tue, 3 Nov 2009 23:43:17 -0800 (PST)
Subject: [R-SIG-Finance] [R-sig-finance] fPortfolio not loading Rsymphony
	package
Message-ID: <26192184.post@talk.nabble.com>


I recently upgraded my version of R to 2.10.0 and installed the fPortfolio
package.

I noticed that once I did that, my codes ran into errors whenever I tried to
run CVaR portfolio optimisation. I then noticed that fPortfolio wasn't
loading the Rsymphony package... is anyone having the same problem?

I've tried loading the package manually but the commands for how fPortfolio
runs solveRsymphony through Rsymphony is probably different (i.e. the
constraints).

Here's the relevant codes:

## Initial Settings
library(fPortfolio)

Loading required package: MASS
Loading required package: quadprog
Loading required package: robustbase
Loading required package: timeDate
Loading required package: timeSeries
Loading required package: fBasics
Loading required package: fAssets
Loading required package: sn
Loading required package: mnormt
Package 'sn', 0.4-12 (2009-03-21). Type 'help(SN)' for summary information
Loading required package: fCopulae

Attaching package: 'fAssets'


        The following object(s) are masked from package:fCopulae :

         .mvstFit 

Loading required package: Rglpk
Loading required package: slam

Attaching package: 'slam'


        The following object(s) are masked from package:timeSeries :

         colMeans,
         colSums 


        The following object(s) are masked from package:base :

         colMeans,
         colSums,
         rowMeans,
         rowSums 

Using the GLPK callable library version 4.37

## Portfolio Settings
cvarspec <- portfolioSpec()
setType(cvarspec) <- "CVaR"
setAlpha(cvarspec) <- 0.05
setSolver(cvarspec) <- "solveRsymphony"

cvarport1 <- tangencyPortfolio(pdata,cvarspec)

Error in get(as.character(FUN), mode = "function", envir = envir) : 
  object 'solveRsymphony' of mode 'function' was not found



Also, sessionInfo():

R version 2.10.0 (2009-10-26) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252   
LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                      
[5] LC_TIME=English_Australia.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] fPortfolio_2100.78 Rglpk_0.3-1        slam_0.1-6        
fAssets_2100.78    fCopulae_2110.78   sn_0.4-12          mnormt_1.3-3      
fBasics_2100.78   
 [9] timeSeries_2100.84 timeDate_2100.86   robustbase_0.4-5  
quadprog_1.4-11    MASS_7.3-3        

loaded via a namespace (and not attached):
[1] tools_2.10.0

Any help is greatly appreciated!
-- 
View this message in context: http://old.nabble.com/fPortfolio-not-loading-Rsymphony-package-tp26192184p26192184.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From vimsaa at gmail.com  Wed Nov  4 09:19:29 2009
From: vimsaa at gmail.com (Vimal B)
Date: Wed, 4 Nov 2009 13:49:29 +0530
Subject: [R-SIG-Finance] package(vars) and generalized impulse response
	functions
Message-ID: <32b3b02a0911040019p534a36e1tfe8707f248a75b85@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091104/af24b42d/attachment.pl>

From matthieu.stigler at gmail.com  Wed Nov  4 09:56:56 2009
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Wed, 4 Nov 2009 09:56:56 +0100
Subject: [R-SIG-Finance] package(vars) and generalized impulse response
	functions
In-Reply-To: <32b3b02a0911040019p534a36e1tfe8707f248a75b85@mail.gmail.com>
References: <32b3b02a0911040019p534a36e1tfe8707f248a75b85@mail.gmail.com>
Message-ID: <111060c20911040056v3d732db8n920291345605cda3@mail.gmail.com>

Hi Vimal

Do you refer to generalized impulse response functions such as in Koop
et al (1996) and Pesaran and Shin (1998) where focus is on
investigating the distribution of any shock at n, taking into account
further  shocks at n+1, n+2...?

If yes, this is not to my knowledge available in R. Package vars does
not provide it at least, options ortho just asks whether a Choleski
decomposition (with ordering as in the input matrix) should be done,
and cumulative whether effects of shocks should be added.

Note btw that even if very interesting, it seems that GIRF did not
have big sucess. I personally saw only a few paper using it, and I'm
not aware of any textbook presenting it, while they all discuss in
details usual IRF.

Best

Matthieu



2009/11/4 Vimal B <vimsaa at gmail.com>:
> Hi,
>
> I was wondering whether the package(vars) can estimate generalized impulse
> response functions for VARs / VECMs.
>
> The general option on package(vars) available is:-
>
> suppose I want to give a shock to 'a' and observe the response of 'b', then
>
> irf(x, impulse=a, response=b, n.ahead=10,
> boot=TRUE,ci=0.95,runs=100,seed=NULL...)
>
> The vignettes and manuals says that the default is 'ortho=TRUE' (and the
> other option is cumulative=NULL).
>
> Or is there any other package one would suggest?
>
> Thanks,
>
> Regards,
> Vimal
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From vimsaa at gmail.com  Wed Nov  4 10:01:17 2009
From: vimsaa at gmail.com (Vimal B)
Date: Wed, 4 Nov 2009 14:31:17 +0530
Subject: [R-SIG-Finance] package(vars) and generalized impulse response
	functions
In-Reply-To: <111060c20911040056v3d732db8n920291345605cda3@mail.gmail.com>
References: <32b3b02a0911040019p534a36e1tfe8707f248a75b85@mail.gmail.com> 
	<111060c20911040056v3d732db8n920291345605cda3@mail.gmail.com>
Message-ID: <32b3b02a0911040101w5953356dp1028eddf83ada18b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091104/0daa94a1/attachment.pl>

From jon.wanxian at gmail.com  Wed Nov  4 16:01:22 2009
From: jon.wanxian at gmail.com (Jonathan Ling)
Date: Wed, 4 Nov 2009 07:01:22 -0800 (PST)
Subject: [R-SIG-Finance] [R-sig-finance] fPortfolio not loading
	Rsymphony package
In-Reply-To: <26192184.post@talk.nabble.com>
References: <26192184.post@talk.nabble.com>
Message-ID: <26197792.post@talk.nabble.com>


Ah! Sorry, I've done a check and apparently Rsymphony was removed from
fPortfolio a while back. The current solver used for CVaR is "solveRglpk". 

Apologies for that!


Jonathan Ling wrote:
> 
> I recently upgraded my version of R to 2.10.0 and installed the fPortfolio
> package.
> 
> I noticed that once I did that, my codes ran into errors whenever I tried
> to run CVaR portfolio optimisation. I then noticed that fPortfolio wasn't
> loading the Rsymphony package... is anyone having the same problem?
> 
> I've tried loading the package manually but the commands for how
> fPortfolio runs solveRsymphony through Rsymphony is probably different
> (i.e. the constraints).
> 

-- 
View this message in context: http://old.nabble.com/fPortfolio-not-loading-Rsymphony-package-tp26192184p26197792.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From olivier.schmitt at gmail.com  Thu Nov  5 00:33:20 2009
From: olivier.schmitt at gmail.com (Olivier Schmitt)
Date: Wed, 4 Nov 2009 18:33:20 -0500
Subject: [R-SIG-Finance] RquantLib : FittedBondCurve function
Message-ID: <2c9fcb830911041533m67dd894eh25b872f72176865@mail.gmail.com>

Hi,

I am trying to run an example based on the one provided in the
documentation for FittedBondCurve, from RQuantLib but using current
data.


> library(RQuantLib)
Loading required package: Rcpp
> lengths <- c(2,5,7,10,30)
> coupons<- c(0.0090,0.024,0.03,0.035,0.043)
> dateparams <- list(settlementDays=0, period="Annual", dayCounter="SimpleDayCounter", businessDayConvention ="Unadjusted")
> curveparams <- list(method="ExponentialSplinesFitting", origDate = Sys.Date())
> curve <- FittedBondCurve(curveparams, lengths, coupons, dateparams)
>
> curve$table[2*365,]
          date  zeroRates  discount
730 2011-11-03 0.02553986 0.9502694
> curve$table[5*365,]
           date  zeroRates  discount
1825 2014-11-02 0.02658928 0.8756396

So, it seems the output curve does not fit the short end data very
well. Are there further parameters that I could adjust to improve
this?

Thanks!

Olivier


From michael at optirisk-systems.com  Thu Nov  5 02:35:14 2009
From: michael at optirisk-systems.com (Michael Sun)
Date: Thu, 5 Nov 2009 01:35:14 -0000
Subject: [R-SIG-Finance] Invitation to R users - Forum on News Analytics
	applied to Trading, Fund Management and Risk Control
Message-ID: <61F86A9166CACB40A35D88D0DCE52E4F0176A748@exch-be21.exchange.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091105/2e19ecb1/attachment.pl>

From allen_kuo at yahoo.com  Thu Nov  5 16:36:01 2009
From: allen_kuo at yahoo.com (Allen Kuo)
Date: Thu, 5 Nov 2009 07:36:01 -0800 (PST)
Subject: [R-SIG-Finance] RquantLib : FittedBondCurve function
In-Reply-To: <2c9fcb830911041533m67dd894eh25b872f72176865@mail.gmail.com>
Message-ID: <265563.3851.qm@web52611.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091105/7515c46f/attachment.pl>

From knguyen at cs.umb.edu  Thu Nov  5 17:14:16 2009
From: knguyen at cs.umb.edu (Khanh Nguyen)
Date: Thu, 5 Nov 2009 23:14:16 +0700
Subject: [R-SIG-Finance] RquantLib : FittedBondCurve function
In-Reply-To: <265563.3851.qm@web52611.mail.re2.yahoo.com>
References: <2c9fcb830911041533m67dd894eh25b872f72176865@mail.gmail.com>
	<265563.3851.qm@web52611.mail.re2.yahoo.com>
Message-ID: <2871c9e10911050814g547c58bejd4eb3301cc5d5b9c@mail.gmail.com>

Hi Oliver,

I implemented RQuantLib's FittedBondCurve. I put your data through
FittedBondCurve.cpp (QuantLib/Examples/FittedBondCurve.cpp) and the
result follows that of RQuantLib. I don't know all the detail about
how quantlib does its curve fitting, so perhaps you will get better
explanation from QuantLib's mailing list.

knguyen at knguyen-laptop:~/Desktop/FittedBondCurve$ g++ -o newbond
FittedBondCurve2.cpp -lQuantLib -lm && ./newbond

Today's date: November 5th, 2009
Calculating fit for 15 bonds.....

(a) exponential splines
reference date : November 5th, 2009
number of iterations : 7264

Value for ts1 on November 5th, 2011
2.554127 % Simple continuous compounding
Value for ts1 on November 4th, 2014
2.659071 % Simple continuous compounding

Enclosed is the source code.

-k


On Thu, Nov 5, 2009 at 10:36 PM, Allen Kuo <allen_kuo at yahoo.com> wrote:
> Olivier:
>
> I've never used Rquantlib but the key to note for the underlying QuantLib code is that it is based on a multidimensional optimization problem- the mathematical solutions you get (and there may be multiple solutions to the problem- nonuniqueness here) may very well depend on where you inititalize your search (guessSolution_ in the code below).
>
> http://quantlib.svn.sourceforge.net/viewvc/quantlib/trunk/QuantLib/ql/termstructures/yield/fittedbonddiscountcurve.cpp?revision=16281&view=markup
>
> There are also iteration?numbers and lamda parameters to play with in the original code. You can even change the optimization method if you have the time.
>
> Generally, that?two year point will get you a kink in the curve since it is more out of line with the other coupons. Since you are minimizing pricing errors subject to a duration adjustment (gives you approximately yield), my guess is a single outlier is probably never going to be fit well with this generic methodology. To pull the curve down closer to this point, you may have to artificially add other points close to this bond, with a similar coupon. Then the optimization will weight this part of the curve more (but now, to the possible detriment of other points on the curve....).
>
> Generally, best fitting from 2 to 30 years accurately will not be easy- this is a global best fit, which may lead to local issues. May also consider just fitting 0-10 years separately from the longer tenors (10-30 years). For fair value pricing purposes, this may be a better bet.
>
> Finally, note also you're comparing zero rates to the coupons (I think). This may not be the best comparison. Par rates should come closer to the coupons.
>
> Best,
> Allen
>
>
> --- On Wed, 11/4/09, Olivier Schmitt <olivier.schmitt at gmail.com> wrote:
>
>
> From: Olivier Schmitt <olivier.schmitt at gmail.com>
> Subject: [R-SIG-Finance] RquantLib : FittedBondCurve function
> To: r-sig-finance at stat.math.ethz.ch
> Date: Wednesday, November 4, 2009, 6:33 PM
>
>
> Hi,
>
> I am trying to run an example based on the one provided in the
> documentation for FittedBondCurve, from RQuantLib but using current
> data.
>
>
>> library(RQuantLib)
> Loading required package: Rcpp
>> lengths <- c(2,5,7,10,30)
>> coupons<- c(0.0090,0.024,0.03,0.035,0.043)
>> dateparams <- list(settlementDays=0, period="Annual", dayCounter="SimpleDayCounter", businessDayConvention ="Unadjusted")
>> curveparams <- list(method="ExponentialSplinesFitting", origDate = Sys.Date())
>> curve <- FittedBondCurve(curveparams, lengths, coupons, dateparams)
>>
>> curve$table[2*365,]
> ? ? ? ? ? date? zeroRates? discount
> 730 2011-11-03 0.02553986 0.9502694
>> curve$table[5*365,]
> ? ? ? ? ???date? zeroRates? discount
> 1825 2014-11-02 0.02658928 0.8756396
>
> So, it seems the output curve does not fit the short end data very
> well. Are there further parameters that I could adjust to improve
> this?
>
> Thanks!
>
> Olivier
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From olivier.schmitt at gmail.com  Thu Nov  5 20:34:31 2009
From: olivier.schmitt at gmail.com (Olivier Schmitt)
Date: Thu, 5 Nov 2009 14:34:31 -0500
Subject: [R-SIG-Finance] RquantLib : FittedBondCurve function
In-Reply-To: <2871c9e10911050814g547c58bejd4eb3301cc5d5b9c@mail.gmail.com>
References: <2c9fcb830911041533m67dd894eh25b872f72176865@mail.gmail.com>
	<265563.3851.qm@web52611.mail.re2.yahoo.com>
	<2871c9e10911050814g547c58bejd4eb3301cc5d5b9c@mail.gmail.com>
Message-ID: <2c9fcb830911051134x102bacb9n4a4fc0c5fdfafb49@mail.gmail.com>

Allen - Thanks for the suggestions, especially the one about fitting
several parts of the curves separately. I thought the splines method
had high enough dimensionality so that there would be a very close fit
all along the curve.

Khanh - Well, thanks and great job on working on adapting QuantLib to
R, it is an extremely helpful project! I have two question for you
then :
 - I believe the maturities need to be integer, would there be a way
around this, so that, in particular, the part of the curve between 0
and 1 year could be fitted as well?
 - I tried the example of the help file with
method="SimplePolynomialFitting" instead of
"ExponentialSplinesFitting" and it made R crash. Do you have an
example for simple polynomial fitting?



On Thu, Nov 5, 2009 at 11:14 AM, Khanh Nguyen <knguyen at cs.umb.edu> wrote:
> Hi Oliver,
>
> I implemented RQuantLib's FittedBondCurve. I put your data through
> FittedBondCurve.cpp (QuantLib/Examples/FittedBondCurve.cpp) and the
> result follows that of RQuantLib. I don't know all the detail about
> how quantlib does its curve fitting, so perhaps you will get better
> explanation from QuantLib's mailing list.
>
> knguyen at knguyen-laptop:~/Desktop/FittedBondCurve$ g++ -o newbond
> FittedBondCurve2.cpp -lQuantLib -lm && ./newbond
>
> Today's date: November 5th, 2009
> Calculating fit for 15 bonds.....
>
> (a) exponential splines
> reference date : November 5th, 2009
> number of iterations : 7264
>
> Value for ts1 on November 5th, 2011
> 2.554127 % Simple continuous compounding
> Value for ts1 on November 4th, 2014
> 2.659071 % Simple continuous compounding
>
> Enclosed is the source code.
>
> -k
>
>
> On Thu, Nov 5, 2009 at 10:36 PM, Allen Kuo <allen_kuo at yahoo.com> wrote:
>> Olivier:
>>
>> I've never used Rquantlib but the key to note for the underlying QuantLib code is that it is based on a multidimensional optimization problem- the mathematical solutions you get (and there may be multiple solutions to the problem- nonuniqueness here) may very well depend on where you inititalize your search (guessSolution_ in the code below).
>>
>> http://quantlib.svn.sourceforge.net/viewvc/quantlib/trunk/QuantLib/ql/termstructures/yield/fittedbonddiscountcurve.cpp?revision=16281&view=markup
>>
>> There are also iteration?numbers and lamda parameters to play with in the original code. You can even change the optimization method if you have the time.
>>
>> Generally, that?two year point will get you a kink in the curve since it is more out of line with the other coupons. Since you are minimizing pricing errors subject to a duration adjustment (gives you approximately yield), my guess is a single outlier is probably never going to be fit well with this generic methodology. To pull the curve down closer to this point, you may have to artificially add other points close to this bond, with a similar coupon. Then the optimization will weight this part of the curve more (but now, to the possible detriment of other points on the curve....).
>>
>> Generally, best fitting from 2 to 30 years accurately will not be easy- this is a global best fit, which may lead to local issues. May also consider just fitting 0-10 years separately from the longer tenors (10-30 years). For fair value pricing purposes, this may be a better bet.
>>
>> Finally, note also you're comparing zero rates to the coupons (I think). This may not be the best comparison. Par rates should come closer to the coupons.
>>
>> Best,
>> Allen
>>
>>
>> --- On Wed, 11/4/09, Olivier Schmitt <olivier.schmitt at gmail.com> wrote:
>>
>>
>> From: Olivier Schmitt <olivier.schmitt at gmail.com>
>> Subject: [R-SIG-Finance] RquantLib : FittedBondCurve function
>> To: r-sig-finance at stat.math.ethz.ch
>> Date: Wednesday, November 4, 2009, 6:33 PM
>>
>>
>> Hi,
>>
>> I am trying to run an example based on the one provided in the
>> documentation for FittedBondCurve, from RQuantLib but using current
>> data.
>>
>>
>>> library(RQuantLib)
>> Loading required package: Rcpp
>>> lengths <- c(2,5,7,10,30)
>>> coupons<- c(0.0090,0.024,0.03,0.035,0.043)
>>> dateparams <- list(settlementDays=0, period="Annual", dayCounter="SimpleDayCounter", businessDayConvention ="Unadjusted")
>>> curveparams <- list(method="ExponentialSplinesFitting", origDate = Sys.Date())
>>> curve <- FittedBondCurve(curveparams, lengths, coupons, dateparams)
>>>
>>> curve$table[2*365,]
>> ? ? ? ? ? date? zeroRates? discount
>> 730 2011-11-03 0.02553986 0.9502694
>>> curve$table[5*365,]
>> ? ? ? ? ???date? zeroRates? discount
>> 1825 2014-11-02 0.02658928 0.8756396
>>
>> So, it seems the output curve does not fit the short end data very
>> well. Are there further parameters that I could adjust to improve
>> this?
>>
>> Thanks!
>>
>> Olivier
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>>
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>


From masserna at gmail.com  Thu Nov  5 21:56:10 2009
From: masserna at gmail.com (Manuel Serna)
Date: Thu, 5 Nov 2009 15:56:10 -0500
Subject: [R-SIG-Finance] Creating a function for portfolio management
Message-ID: <b99eb5050911051256g5ee1e809k113e12f70a8340b9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091105/333a45e7/attachment.pl>

From knguyen at cs.umb.edu  Fri Nov  6 01:47:02 2009
From: knguyen at cs.umb.edu (Khanh Nguyen)
Date: Thu, 5 Nov 2009 19:47:02 -0500
Subject: [R-SIG-Finance] RquantLib : FittedBondCurve function
In-Reply-To: <2c9fcb830911051134x102bacb9n4a4fc0c5fdfafb49@mail.gmail.com>
References: <2c9fcb830911041533m67dd894eh25b872f72176865@mail.gmail.com>
	<265563.3851.qm@web52611.mail.re2.yahoo.com>
	<2871c9e10911050814g547c58bejd4eb3301cc5d5b9c@mail.gmail.com>
	<2c9fcb830911051134x102bacb9n4a4fc0c5fdfafb49@mail.gmail.com>
Message-ID: <2871c9e10911051647o236f5628x30184b25aaa5a54e@mail.gmail.com>

Hi Oliver,

Simply add degree to curveparams, something like this

> curveparams <- list(method="SimplePolynomialFitting", origDate = Sys.Date(), degree = 3)

'degree' is a parameter required for QuantLib's
SimplePolynimialFitting. I am terribly sorry that we neglected the
documentation on that (and possibly a few other parts :( ).


-k



On Thu, Nov 5, 2009 at 2:34 PM, Olivier Schmitt
<olivier.schmitt at gmail.com> wrote:
> Allen - Thanks for the suggestions, especially the one about fitting
> several parts of the curves separately. I thought the splines method
> had high enough dimensionality so that there would be a very close fit
> all along the curve.
>
> Khanh - Well, thanks and great job on working on adapting QuantLib to
> R, it is an extremely helpful project! I have two question for you
> then :
> ?- I believe the maturities need to be integer, would there be a way
> around this, so that, in particular, the part of the curve between 0
> and 1 year could be fitted as well?
> ?- I tried the example of the help file with
> method="SimplePolynomialFitting" instead of
> "ExponentialSplinesFitting" and it made R crash. Do you have an
> example for simple polynomial fitting?
>
>
>
> On Thu, Nov 5, 2009 at 11:14 AM, Khanh Nguyen <knguyen at cs.umb.edu> wrote:
>> Hi Oliver,
>>
>> I implemented RQuantLib's FittedBondCurve. I put your data through
>> FittedBondCurve.cpp (QuantLib/Examples/FittedBondCurve.cpp) and the
>> result follows that of RQuantLib. I don't know all the detail about
>> how quantlib does its curve fitting, so perhaps you will get better
>> explanation from QuantLib's mailing list.
>>
>> knguyen at knguyen-laptop:~/Desktop/FittedBondCurve$ g++ -o newbond
>> FittedBondCurve2.cpp -lQuantLib -lm && ./newbond
>>
>> Today's date: November 5th, 2009
>> Calculating fit for 15 bonds.....
>>
>> (a) exponential splines
>> reference date : November 5th, 2009
>> number of iterations : 7264
>>
>> Value for ts1 on November 5th, 2011
>> 2.554127 % Simple continuous compounding
>> Value for ts1 on November 4th, 2014
>> 2.659071 % Simple continuous compounding
>>
>> Enclosed is the source code.
>>
>> -k
>>
>>
>> On Thu, Nov 5, 2009 at 10:36 PM, Allen Kuo <allen_kuo at yahoo.com> wrote:
>>> Olivier:
>>>
>>> I've never used Rquantlib but the key to note for the underlying QuantLib code is that it is based on a multidimensional optimization problem- the mathematical solutions you get (and there may be multiple solutions to the problem- nonuniqueness here) may very well depend on where you inititalize your search (guessSolution_ in the code below).
>>>
>>> http://quantlib.svn.sourceforge.net/viewvc/quantlib/trunk/QuantLib/ql/termstructures/yield/fittedbonddiscountcurve.cpp?revision=16281&view=markup
>>>
>>> There are also iteration?numbers and lamda parameters to play with in the original code. You can even change the optimization method if you have the time.
>>>
>>> Generally, that?two year point will get you a kink in the curve since it is more out of line with the other coupons. Since you are minimizing pricing errors subject to a duration adjustment (gives you approximately yield), my guess is a single outlier is probably never going to be fit well with this generic methodology. To pull the curve down closer to this point, you may have to artificially add other points close to this bond, with a similar coupon. Then the optimization will weight this part of the curve more (but now, to the possible detriment of other points on the curve....).
>>>
>>> Generally, best fitting from 2 to 30 years accurately will not be easy- this is a global best fit, which may lead to local issues. May also consider just fitting 0-10 years separately from the longer tenors (10-30 years). For fair value pricing purposes, this may be a better bet.
>>>
>>> Finally, note also you're comparing zero rates to the coupons (I think). This may not be the best comparison. Par rates should come closer to the coupons.
>>>
>>> Best,
>>> Allen
>>>
>>>
>>> --- On Wed, 11/4/09, Olivier Schmitt <olivier.schmitt at gmail.com> wrote:
>>>
>>>
>>> From: Olivier Schmitt <olivier.schmitt at gmail.com>
>>> Subject: [R-SIG-Finance] RquantLib : FittedBondCurve function
>>> To: r-sig-finance at stat.math.ethz.ch
>>> Date: Wednesday, November 4, 2009, 6:33 PM
>>>
>>>
>>> Hi,
>>>
>>> I am trying to run an example based on the one provided in the
>>> documentation for FittedBondCurve, from RQuantLib but using current
>>> data.
>>>
>>>
>>>> library(RQuantLib)
>>> Loading required package: Rcpp
>>>> lengths <- c(2,5,7,10,30)
>>>> coupons<- c(0.0090,0.024,0.03,0.035,0.043)
>>>> dateparams <- list(settlementDays=0, period="Annual", dayCounter="SimpleDayCounter", businessDayConvention ="Unadjusted")
>>>> curveparams <- list(method="ExponentialSplinesFitting", origDate = Sys.Date())
>>>> curve <- FittedBondCurve(curveparams, lengths, coupons, dateparams)
>>>>
>>>> curve$table[2*365,]
>>> ? ? ? ? ? date? zeroRates? discount
>>> 730 2011-11-03 0.02553986 0.9502694
>>>> curve$table[5*365,]
>>> ? ? ? ? ???date? zeroRates? discount
>>> 1825 2014-11-02 0.02658928 0.8756396
>>>
>>> So, it seems the output curve does not fit the short end data very
>>> well. Are there further parameters that I could adjust to improve
>>> this?
>>>
>>> Thanks!
>>>
>>> Olivier
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
>>>
>>>
>>>
>>> ? ? ? ?[[alternative HTML version deleted]]
>>>
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
>>
>


From hgeorgako at hotmail.com  Fri Nov  6 03:29:09 2009
From: hgeorgako at hotmail.com (Harry Georgakopoulos)
Date: Thu, 5 Nov 2009 20:29:09 -0600
Subject: [R-SIG-Finance] How to properly compare a trading signal to a
	random strategy.
Message-ID: <BLU109-W286721A30F4772A48A4177BAAF0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091105/1bf26770/attachment.pl>

From lara.shocron at gmail.com  Fri Nov  6 04:57:58 2009
From: lara.shocron at gmail.com (Lara Shocron)
Date: Fri, 6 Nov 2009 11:57:58 +0800
Subject: [R-SIG-Finance] portfolio optimization - maximizing returns for a
	given risk.
Message-ID: <5a8ae12f0911051957i7607c58k42a6f781eb123b5e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091106/dc31dd68/attachment.pl>

From etheber at gmx.de  Fri Nov  6 08:01:43 2009
From: etheber at gmx.de (Thomas Etheber)
Date: Fri, 06 Nov 2009 08:01:43 +0100
Subject: [R-SIG-Finance] portfolio optimization - maximizing returns for
 a	given risk.
In-Reply-To: <5a8ae12f0911051957i7607c58k42a6f781eb123b5e@mail.gmail.com>
References: <5a8ae12f0911051957i7607c58k42a6f781eb123b5e@mail.gmail.com>
Message-ID: <4AF3C9D7.3070101@gmx.de>

Hi Lara,

there has been a thread dealing with this question some time ago.
You could have a look at:
https://stat.ethz.ch/pipermail/r-sig-finance/2008q4/003261.html

Hth
Thomas

Lara Shocron wrote:
> Dear All,
>
> I am doing some portfolio optimization using the portfolio.optim function in
> the tseries packages, which minimizes the risk of a portfolio for a given
> return objective.
> Do you know if it's possible to see things the other way around and maximize
> the return of a portfolio for a given risk objective?
>
> Many thanks,
>
> Lara
>
>
>


From brian at braverock.com  Fri Nov  6 11:51:20 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 06 Nov 2009 04:51:20 -0600
Subject: [R-SIG-Finance] How to properly compare a trading signal to a
 random strategy.
In-Reply-To: <BLU109-W286721A30F4772A48A4177BAAF0@phx.gbl>
References: <BLU109-W286721A30F4772A48A4177BAAF0@phx.gbl>
Message-ID: <4AF3FFA8.5070309@braverock.com>

Harry Georgakopoulos wrote:
> 
>  Set up ^^^^
>  Let's say i have an evenly spaced discrete time-series of bid-ask prices.  Let's also say that the total number of such bid-ask pairs is N for a given day. Given a signal that generates a buy opportunity on "n" such times (where n << N), how can I  reliably say that these n signals have a mean profit that is statistically significant?
>  For example, assume I get 35 buy signals throughout the day where I buy the offer, wait 5  minutes and then sell the bid.  This will generate a vector of 35 price-differences.  These price  differences will have a particular distribution. 
>  Thoughts  ^^^^^ 
>  1.  I can compare the distribution of the 35 price-differences generated from the signal against      the distribution of 35 randomly chosen entry points throughout the day. (maybe some kind        of t-test on the difference of the means of these distributions)
>  2.  I can compare the distribution of the 35 price-differences to a rolling window of all possible  buys throughout the day and selling after 5 mins.  (more data-points to compare against)
>  3.  I can compare the distribution of the 35 price-differences against an absolute value of 0.
> Any ideas on quantifying the significance of such a signal would be appreciated.  Is one method preferred over another?  Am I inadvertently introducing bias in the analysis?  I realize that the distribution of the price-differences might not be normally distributed.  This might make any analysis based on a t-test invalid.  
> Thank you in advance.
> H.

Pat Burns has a paper on this topic on his website.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From dstjohn at math.uic.edu  Fri Nov  6 14:28:58 2009
From: dstjohn at math.uic.edu (David St John)
Date: Fri, 6 Nov 2009 07:28:58 -0600
Subject: [R-SIG-Finance] How to properly compare a trading signal to a
	random strategy.
Message-ID: <998c123e0911060528p7193278g15e5f20b073096b6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091106/d771aa1d/attachment.pl>

From dstjohn at math.uic.edu  Fri Nov  6 14:46:00 2009
From: dstjohn at math.uic.edu (David St John)
Date: Fri, 6 Nov 2009 07:46:00 -0600
Subject: [R-SIG-Finance] How to properly compare a trading signal to a
	random strategy.
Message-ID: <998c123e0911060546q362ba41bwa319c59242da965d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091106/d0e9029f/attachment.pl>

From olivier.schmitt at gmail.com  Fri Nov  6 16:54:16 2009
From: olivier.schmitt at gmail.com (Olivier Schmitt)
Date: Fri, 6 Nov 2009 10:54:16 -0500
Subject: [R-SIG-Finance] RquantLib : FittedBondCurve function
In-Reply-To: <2871c9e10911051647o236f5628x30184b25aaa5a54e@mail.gmail.com>
References: <2c9fcb830911041533m67dd894eh25b872f72176865@mail.gmail.com>
	<265563.3851.qm@web52611.mail.re2.yahoo.com>
	<2871c9e10911050814g547c58bejd4eb3301cc5d5b9c@mail.gmail.com>
	<2c9fcb830911051134x102bacb9n4a4fc0c5fdfafb49@mail.gmail.com>
	<2871c9e10911051647o236f5628x30184b25aaa5a54e@mail.gmail.com>
Message-ID: <2c9fcb830911060754o781d7798y59bc24f757159467@mail.gmail.com>

Thanks a lot Khanh, SimplePolynomialFitting works much better with the
data I used in the example I sent earlier.

Olivier

On Thu, Nov 5, 2009 at 7:47 PM, Khanh Nguyen <knguyen at cs.umb.edu> wrote:
> Hi Oliver,
>
> Simply add degree to curveparams, something like this
>
>> curveparams <- list(method="SimplePolynomialFitting", origDate = Sys.Date(), degree = 3)
>
> 'degree' is a parameter required for QuantLib's
> SimplePolynimialFitting. I am terribly sorry that we neglected the
> documentation on that (and possibly a few other parts :( ).
>
>
> -k
>
>
>
> On Thu, Nov 5, 2009 at 2:34 PM, Olivier Schmitt
> <olivier.schmitt at gmail.com> wrote:
>> Allen - Thanks for the suggestions, especially the one about fitting
>> several parts of the curves separately. I thought the splines method
>> had high enough dimensionality so that there would be a very close fit
>> all along the curve.
>>
>> Khanh - Well, thanks and great job on working on adapting QuantLib to
>> R, it is an extremely helpful project! I have two question for you
>> then :
>> ?- I believe the maturities need to be integer, would there be a way
>> around this, so that, in particular, the part of the curve between 0
>> and 1 year could be fitted as well?
>> ?- I tried the example of the help file with
>> method="SimplePolynomialFitting" instead of
>> "ExponentialSplinesFitting" and it made R crash. Do you have an
>> example for simple polynomial fitting?
>>
>>
>>
>> On Thu, Nov 5, 2009 at 11:14 AM, Khanh Nguyen <knguyen at cs.umb.edu> wrote:
>>> Hi Oliver,
>>>
>>> I implemented RQuantLib's FittedBondCurve. I put your data through
>>> FittedBondCurve.cpp (QuantLib/Examples/FittedBondCurve.cpp) and the
>>> result follows that of RQuantLib. I don't know all the detail about
>>> how quantlib does its curve fitting, so perhaps you will get better
>>> explanation from QuantLib's mailing list.
>>>
>>> knguyen at knguyen-laptop:~/Desktop/FittedBondCurve$ g++ -o newbond
>>> FittedBondCurve2.cpp -lQuantLib -lm && ./newbond
>>>
>>> Today's date: November 5th, 2009
>>> Calculating fit for 15 bonds.....
>>>
>>> (a) exponential splines
>>> reference date : November 5th, 2009
>>> number of iterations : 7264
>>>
>>> Value for ts1 on November 5th, 2011
>>> 2.554127 % Simple continuous compounding
>>> Value for ts1 on November 4th, 2014
>>> 2.659071 % Simple continuous compounding
>>>
>>> Enclosed is the source code.
>>>
>>> -k
>>>
>>>
>>> On Thu, Nov 5, 2009 at 10:36 PM, Allen Kuo <allen_kuo at yahoo.com> wrote:
>>>> Olivier:
>>>>
>>>> I've never used Rquantlib but the key to note for the underlying QuantLib code is that it is based on a multidimensional optimization problem- the mathematical solutions you get (and there may be multiple solutions to the problem- nonuniqueness here) may very well depend on where you inititalize your search (guessSolution_ in the code below).
>>>>
>>>> http://quantlib.svn.sourceforge.net/viewvc/quantlib/trunk/QuantLib/ql/termstructures/yield/fittedbonddiscountcurve.cpp?revision=16281&view=markup
>>>>
>>>> There are also iteration?numbers and lamda parameters to play with in the original code. You can even change the optimization method if you have the time.
>>>>
>>>> Generally, that?two year point will get you a kink in the curve since it is more out of line with the other coupons. Since you are minimizing pricing errors subject to a duration adjustment (gives you approximately yield), my guess is a single outlier is probably never going to be fit well with this generic methodology. To pull the curve down closer to this point, you may have to artificially add other points close to this bond, with a similar coupon. Then the optimization will weight this part of the curve more (but now, to the possible detriment of other points on the curve....).
>>>>
>>>> Generally, best fitting from 2 to 30 years accurately will not be easy- this is a global best fit, which may lead to local issues. May also consider just fitting 0-10 years separately from the longer tenors (10-30 years). For fair value pricing purposes, this may be a better bet.
>>>>
>>>> Finally, note also you're comparing zero rates to the coupons (I think). This may not be the best comparison. Par rates should come closer to the coupons.
>>>>
>>>> Best,
>>>> Allen
>>>>
>>>>
>>>> --- On Wed, 11/4/09, Olivier Schmitt <olivier.schmitt at gmail.com> wrote:
>>>>
>>>>
>>>> From: Olivier Schmitt <olivier.schmitt at gmail.com>
>>>> Subject: [R-SIG-Finance] RquantLib : FittedBondCurve function
>>>> To: r-sig-finance at stat.math.ethz.ch
>>>> Date: Wednesday, November 4, 2009, 6:33 PM
>>>>
>>>>
>>>> Hi,
>>>>
>>>> I am trying to run an example based on the one provided in the
>>>> documentation for FittedBondCurve, from RQuantLib but using current
>>>> data.
>>>>
>>>>
>>>>> library(RQuantLib)
>>>> Loading required package: Rcpp
>>>>> lengths <- c(2,5,7,10,30)
>>>>> coupons<- c(0.0090,0.024,0.03,0.035,0.043)
>>>>> dateparams <- list(settlementDays=0, period="Annual", dayCounter="SimpleDayCounter", businessDayConvention ="Unadjusted")
>>>>> curveparams <- list(method="ExponentialSplinesFitting", origDate = Sys.Date())
>>>>> curve <- FittedBondCurve(curveparams, lengths, coupons, dateparams)
>>>>>
>>>>> curve$table[2*365,]
>>>> ? ? ? ? ? date? zeroRates? discount
>>>> 730 2011-11-03 0.02553986 0.9502694
>>>>> curve$table[5*365,]
>>>> ? ? ? ? ???date? zeroRates? discount
>>>> 1825 2014-11-02 0.02658928 0.8756396
>>>>
>>>> So, it seems the output curve does not fit the short end data very
>>>> well. Are there further parameters that I could adjust to improve
>>>> this?
>>>>
>>>> Thanks!
>>>>
>>>> Olivier
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only.
>>>> -- If you want to post, subscribe first.
>>>>
>>>>
>>>>
>>>>
>>>> ? ? ? ?[[alternative HTML version deleted]]
>>>>
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only.
>>>> -- If you want to post, subscribe first.
>>>>
>>>
>>
>


From dutt.debashis at gmail.com  Fri Nov  6 17:04:15 2009
From: dutt.debashis at gmail.com (debashis dutta)
Date: Fri, 6 Nov 2009 19:04:15 +0300
Subject: [R-SIG-Finance] Creating a function for portfolio management
In-Reply-To: <b99eb5050911051256g5ee1e809k113e12f70a8340b9@mail.gmail.com>
References: <b99eb5050911051256g5ee1e809k113e12f70a8340b9@mail.gmail.com>
Message-ID: <37673c2d0911060804g13cf1dd2nf4f556f65693688f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091106/2d334319/attachment.pl>

From dutt.debashis at gmail.com  Fri Nov  6 17:07:39 2009
From: dutt.debashis at gmail.com (debashis dutta)
Date: Fri, 6 Nov 2009 19:07:39 +0300
Subject: [R-SIG-Finance] Creating a function for portfolio management
In-Reply-To: <37673c2d0911060804g13cf1dd2nf4f556f65693688f@mail.gmail.com>
References: <b99eb5050911051256g5ee1e809k113e12f70a8340b9@mail.gmail.com>
	<37673c2d0911060804g13cf1dd2nf4f556f65693688f@mail.gmail.com>
Message-ID: <37673c2d0911060807h4e813a98m2b216b81fda3508f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091106/2881599c/attachment.pl>

From axel.leroix at yahoo.fr  Fri Nov  6 17:57:29 2009
From: axel.leroix at yahoo.fr (Axel Leroix)
Date: Fri, 6 Nov 2009 08:57:29 -0800 (PST)
Subject: [R-SIG-Finance] Systemfit package/Autocorrelation
Message-ID: <454722.10417.qm@web28006.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091106/412b2d8b/attachment.pl>

From peter at braverock.com  Fri Nov  6 18:24:09 2009
From: peter at braverock.com (Peter Carl)
Date: Fri, 6 Nov 2009 11:24:09 -0600 (CST)
Subject: [R-SIG-Finance] Systemfit package/Autocorrelation
In-Reply-To: <454722.10417.qm@web28006.mail.ukl.yahoo.com>
References: <454722.10417.qm@web28006.mail.ukl.yahoo.com>
Message-ID: <57527.75.22.195.112.1257528249.squirrel@mail.braverock.com>

You might use autocorrelation-adjusted returns, using the 'Return.Geltner'
function in PerformanceAnalytics.  That adjusts for first-order
autocorrelation.

Okunev and White propose a method for removing n-order autocorrelation in:
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=460641
... and if anyone is willing to contribute a function that implements it,
we'd be interested in including it in a future version of PA.

HTH,

pcc
-- 
Peter Carl
http://www.braverock.com/~peter

> ?
> Hello,
> ?
> I have question with regrad to the "systemfit" package.
> I'm estimating a simultaneous system of equations. I have 5 equations in
> my system. I use 3SLS for estimation since it permits to take into
> account, both, contemporaneous error terms correlation and simultaneity
> bias.
> ?
> After estimating my system, in which all equations are dynamic (each
> equation contain one lagged endogenous variable), I perform the
> Breusch-Godfrey test to test for the presence of residual autocorrelation
> between error terms of the same equation (E_1t ,E_1(t-1). The test results
> show that there is autocorrelation.
> ?
> My question is, in the case of simultaneous system of equations, how to
> correct for this problem of autocorrelation?(I note again that I speak
> about autocorrelation?between erros of the same equation and not
> autocorrelation between errors of different equations).
> ?
> I have seen that on the case for one single equation estimation, we use
> the function gls?to correct for residuals autocorrelation, but in the case
> od system of equations there is no indication about how deal with this
> problem.? I wonder if I should estimate separately equations in which
> there is evidence of autocorrelation by using simply OLS or?gls functions?
> ?
> Any idea please ?
> Help will be very appreciated.
> Thank you in advance
> ?
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From ezivot at u.washington.edu  Fri Nov  6 21:06:53 2009
From: ezivot at u.washington.edu (Eric Zivot)
Date: Fri, 6 Nov 2009 12:06:53 -0800
Subject: [R-SIG-Finance] Systemfit package/Autocorrelation
In-Reply-To: <454722.10417.qm@web28006.mail.ukl.yahoo.com>
References: <454722.10417.qm@web28006.mail.ukl.yahoo.com>
Message-ID: <007601ca5f1c$aee49760$0cadc620$@washington.edu>

You can treat the autocorrelation as nuisance parameters and correct for its
effect on the standard errors by estimating the model by GMM (see the nice
gmm pagckage for this) and using a heteroskedasticity and autocorrelation
consistent (HAC) covariance matrix.


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Axel Leroix
Sent: Friday, November 06, 2009 8:57 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] Systemfit package/Autocorrelation

 
Hello,
 
I have question with regrad to the "systemfit" package. 
I'm estimating a simultaneous system of equations. I have 5 equations in my
system. I use 3SLS for estimation since it permits to take into account,
both, contemporaneous error terms correlation and simultaneity bias. 
 
After estimating my system, in which all equations are dynamic (each
equation contain one lagged endogenous variable), I perform the
Breusch-Godfrey test to test for the presence of residual autocorrelation
between error terms of the same equation (E_1t ,E_1(t-1). The test results
show that there is autocorrelation.
 
My question is, in the case of simultaneous system of equations, how to
correct for this problem of autocorrelation (I note again that I speak about
autocorrelation between erros of the same equation and not autocorrelation
between errors of different equations).
 
I have seen that on the case for one single equation estimation, we use the
function gls to correct for residuals autocorrelation, but in the case od
system of equations there is no indication about how deal with this problem.
I wonder if I should estimate separately equations in which there is
evidence of autocorrelation by using simply OLS or gls functions?
 
Any idea please ? 
Help will be very appreciated.
Thank you in advance
 


      
	[[alternative HTML version deleted]]


From janet_watson_76 at yahoo.co.uk  Sat Nov  7 11:29:03 2009
From: janet_watson_76 at yahoo.co.uk (janet watson)
Date: Sat, 7 Nov 2009 10:29:03 +0000 (GMT)
Subject: [R-SIG-Finance] Question about tailSlider function in fExtremes
In-Reply-To: <mailman.3.1257505202.10406.r-sig-finance@stat.math.ethz.ch>
Message-ID: <163461.59015.qm@web25604.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091107/20d623db/attachment.pl>

From frainj at tcd.ie  Sun Nov  8 01:34:33 2009
From: frainj at tcd.ie (John Frain)
Date: Sun, 8 Nov 2009 00:34:33 +0000
Subject: [R-SIG-Finance] Time series temporal disaggregation (or: going
	from low frequency to higher frequency)
In-Reply-To: <4AEAE396.1090208@braverock.com>
References: <252006.563.qm@web28007.mail.ukl.yahoo.com>
	<4AEAD07A.9010008@braverock.com>
	<cfdde1650910300536p53c9cb34nde65cdf475085f43@mail.gmail.com>
	<4AEAE396.1090208@braverock.com>
Message-ID: <cfdde1650911071634s44255b55nff4e514656f9cd52@mail.gmail.com>

Brian

Sorry for not answering your questions sooner.  I appologise if this reply
is a bit off topic for this mailing list.

I have attached two pdf's which I hope explain in some way how we used the
Chow-Lin interpoalation/distribution  methods.  In the Central Bank of
Ireland we were interested  in modelling various aspects of the Irish
Economy but quarterly national accounts were not available in Ireland until
the late 90's.  In the early 80's I wrote  Chow-Lin routines first in TROLL
and then in Gauss and calculated several sets of quarterly national accounts
which were used in modelling various aspects of the economy.

Manual.pdf describes a RATS program used to produce a set of national
accounts for the Irish macro model component of the ECB systrm of
macro-models.  The implementation assumes a certain relationship between the
annual variable and the quarterly indicators.  If the model is valid then
the estimates are unbiased.  As the model is probably not valid some bias
certainly exists.  However analysis using the derived data has generally
produced reasonable useful results.

The methodology used differs from the original Chow-Lin methodology.  Given
the assumed model between the unobserved quarterly model and the indicators
one can calculate the distribution of the annual data and estimate the
parameters using maximum likelihood.

Manual2.pdf describes an extension of the methodology where quarterly data
are available for some of the period and the likelhodd estimation is based
on the distribution of the quarterly data where available and on the annual
observations otherwise.  I think that tis method has been used in the
Central Bank but I do not know the extent of that use as I retired from the
Central Bank about 5 years ago.

The method can be used to decompose a series by using a constant and/or
trend as indicators.  In most cases of interest there is some indicator.

In some cases one may set up some form of penalty function to be minimised
and assume that the quarterly series follows some form of time series.

A long time ago we also experimented a little with Kalman Filters with
limited sucess. These methods might be easier with current computer
facilities.

I

2009/10/30 Brian G. Peterson <brian at braverock.com>

> John,
>
> Thanks for the pointers.  I'll certainly research this method.
> It appears on first reading that the Chow-Lin method requires multivariate
> indicator series to attempt to remove biases potentially introduced by the
> higher frequency indicators.  Do I understand this correctly?
> If so, is the resulting series truly "unbiased", or are the biases
> introduced by construction via the indicator, and then minimized by the
> distribution of the residual?
>
> Also, you would not be able to decompose a univariate series of annual
> numbers, as I thought was proposed by the original poster in this thread,
> without identifying indicators.  Correct?
>
> Thanks again,
>
>  - Brian
>
>
> John Frain wrote:
>
>> Several Official Bodies (Central Banks Eurostat etc) use Chow-Lin
>> interpolation to derive  quarterly data from annual or monthly from
>> quarterly.  It may be the case that the higher frequency data have
>> only recently been produced.  I don't know if anyone has produced any
>> R routines but if you google "Chow-Lin interpolation" you will
>> probably find implementations in Matlab or Gauss that should transfer
>> easily to R.  My implementation in RATS can  be accessed at
>> ideas.repec.org/p/cbi/wpaper/2-rt-04.html.  This contains an
>> explanation of the methodology and references to the original papers.
>>
>> The research section of the Eurostat website also contained some
>> relevant material.
>>
>> Best Regards
>>
>> John
>>
>> 2009/10/30 Brian G. Peterson <brian at braverock.com>:
>>
>>
>>> Axel Leroix wrote:
>>>
>>>
>>>> Hi,
>>>> This is a newbie question. I would to be able to convert annual time
>>>> series of flow data into quarterly data. I wonder if there is any
>>>> existing
>>>> R-function which permits to do it? In what package ?
>>>>  I the archive, i found that some poeple speak about "tempDis" package
>>>> for
>>>> performing time series temporal disaggregation, but when I try to
>>>> download
>>>> it I can not found it in the list of proposed packages.  Thank you in
>>>> advance for your help.
>>>>
>>>>
>>>>
>>> Well, as discussed multiple times on this list, going from annual (or any
>>> lower frequency) data to quarterly (or any higher frequency) data is
>>> questionable at best.  Think data snooping or look-ahead bias in your
>>> modeling.
>>>
>>> Going the other direction, from say daily (or any higher frequency)  to
>>> monthly (or any lower frequency) , is easily accomplished with to.period
>>> for
>>> price/value data or Return.cumulative for returns data.
>>>
>>> If you really do want to go in the black-magic direction of going from
>>> annual to quarterly, first make sure that the "annual" data was not first
>>> reported as monthly data or quarterly data (this is true for almost all
>>> macroeconomic series) and then go back to the source data at a higher
>>> frequency.
>>>
>>> If even this is not possible, and you insist on the highly dubious
>>> practice
>>> of taking an annual number and turning it into four quarterly numbers,
>>> see
>>> the various na handling methods provided by the zoo package, most likely
>>> na.approx or na.spline.
>>>
>>> Regards,
>>>
>>>   - Brian
>>>
>>> --
>>> Brian G. Peterson
>>> http://braverock.com/brian/
>>> Ph: 773-459-4973
>>> IM: bgpbraverock
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
>>>
>>>
>>>
>>
>>
>>
>>
>>
>
>
>


-- 
John C Frain, Ph.D.
Trinity College Dublin
Dublin 2
Ireland
www.tcd.ie/Economics/staff/frainj/home.htm
mailto:frainj at tcd.ie
mailto:frainj at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091108/45a21da5/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: manual.pdf
Type: application/pdf
Size: 188670 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091108/45a21da5/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: MANUAL2.PDF
Type: application/pdf
Size: 87046 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091108/45a21da5/attachment-0001.pdf>

From ajayshah at mayin.org  Sun Nov  8 08:10:05 2009
From: ajayshah at mayin.org (Ajay Shah)
Date: Sun, 8 Nov 2009 12:40:05 +0530
Subject: [R-SIG-Finance] Discretising intra-day data using zoo?
Message-ID: <20091108071005.GA23944@ajay-shahs-macbook-pro.local>

Folks,

I have a zoo object where the time-stamps are intra-day with
sub-second resolution. Can you take a look:

  library(zoo)
  print(load(url("http://www.mayin.org/ajayshah/tmp/demo.rda")))
  options("digits.secs"=6)
  head(demo)
  tail(demo)

My question is: How do I force this down to a uniform grid of (say)
four second resolution. In that case, we'd have readings for

    10:30:00
    10:30:04
    10:30:08
    10:30:12

out of this dataset. As with the standard
  zoo::aggregate(blah, tail, 1)
we'd take the last available record as of 10:30:08 and put this
information for that timepoint.

Suppose there is not a single record in the raw data from 10:30:04 to
10:30:09. Despite this, the resulting object should contain a record
for 10:30:08 with NA values (which can then be filled out e.g. using
na.locf()). How would we do this? This problem is not present in this
data, where records are plentiful. But discretisation code should be
general and handle this case right.

-- 
Ajay Shah                                      http://www.mayin.org/ajayshah  
ajayshah at mayin.org                             http://ajayshahblog.blogspot.com
<*(:-? - wizard who doesn't know the answer.


From ggrothendieck at gmail.com  Sun Nov  8 13:20:02 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 8 Nov 2009 07:20:02 -0500
Subject: [R-SIG-Finance] Discretising intra-day data using zoo?
In-Reply-To: <20091108071005.GA23944@ajay-shahs-macbook-pro.local>
References: <20091108071005.GA23944@ajay-shahs-macbook-pro.local>
Message-ID: <971536df0911080420m51067166q81885a554781eade@mail.gmail.com>

See the aggregate.zoo example in vignette("zoo-quickref") but round up
to the next 4 seconds instead of next Friday:

> to4sec <- function(x) as.POSIXct(4*ceiling(as.numeric(x)/4), origin = "1970-01-01")
> aggregate(demo, to4sec, tail, 1)
                    spread    ltp
2009-02-16 05:00:04 0.0050 48.715
2009-02-16 05:00:08 0.0025 48.715
2009-02-16 05:00:12 0.0025 48.715
2009-02-16 05:00:16 0.0025 48.715


On Sun, Nov 8, 2009 at 2:10 AM, Ajay Shah <ajayshah at mayin.org> wrote:
> Folks,
>
> I have a zoo object where the time-stamps are intra-day with
> sub-second resolution. Can you take a look:
>
> ?library(zoo)
> ?print(load(url("http://www.mayin.org/ajayshah/tmp/demo.rda")))
> ?options("digits.secs"=6)
> ?head(demo)
> ?tail(demo)
>
> My question is: How do I force this down to a uniform grid of (say)
> four second resolution. In that case, we'd have readings for
>
> ? ?10:30:00
> ? ?10:30:04
> ? ?10:30:08
> ? ?10:30:12
>
> out of this dataset. As with the standard
> ?zoo::aggregate(blah, tail, 1)
> we'd take the last available record as of 10:30:08 and put this
> information for that timepoint.
>
> Suppose there is not a single record in the raw data from 10:30:04 to
> 10:30:09. Despite this, the resulting object should contain a record
> for 10:30:08 with NA values (which can then be filled out e.g. using
> na.locf()). How would we do this? This problem is not present in this
> data, where records are plentiful. But discretisation code should be
> general and handle this case right.
>
> --
> Ajay Shah ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?http://www.mayin.org/ajayshah
> ajayshah at mayin.org ? ? ? ? ? ? ? ? ? ? ? ? ? ? http://ajayshahblog.blogspot.com
> <*(:-? - wizard who doesn't know the answer.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From ajayshah at mayin.org  Sun Nov  8 13:58:57 2009
From: ajayshah at mayin.org (Ajay Shah)
Date: Sun, 8 Nov 2009 18:28:57 +0530
Subject: [R-SIG-Finance] Discretising intra-day data using zoo?
In-Reply-To: <971536df0911080420m51067166q81885a554781eade@mail.gmail.com>
References: <20091108071005.GA23944@ajay-shahs-macbook-pro.local>
	<971536df0911080420m51067166q81885a554781eade@mail.gmail.com>
Message-ID: <20091108125857.GC1524@ajay-shahs-macbook-pro.local>

library(zoo)
print(load(url("http://www.mayin.org/ajayshah/tmp/demo.rda")))
options("digits.secs"=6)
head(demo)
tail(demo)

On Sun, Nov 08, 2009 at 07:20:02AM -0500, Gabor Grothendieck wrote:
> See the aggregate.zoo example in vignette("zoo-quickref") but round up
> to the next 4 seconds instead of next Friday:
> 
> > to4sec <- function(x) as.POSIXct(4*ceiling(as.numeric(x)/4), origin = "1970-01-01")
> > aggregate(demo, to4sec, tail, 1)
>                     spread    ltp
> 2009-02-16 05:00:04 0.0050 48.715
> 2009-02-16 05:00:08 0.0025 48.715
> 2009-02-16 05:00:12 0.0025 48.715
> 2009-02-16 05:00:16 0.0025 48.715

Gabor, thanks! I am not as fluent with as.POSIXct() as I should be.

And, to continue with my original question:

> > Suppose there is not a single record in the raw data from 10:30:04 to
> > 10:30:09. Despite this, the resulting object should contain a record
> > for 10:30:08 with NA values (which can then be filled out e.g. using
> > na.locf()). How would we do this? This problem is not present in this
> > data, where records are plentiful. But discretisation code should be
> > general and handle this case right.

How would we do this? To illustrate:

  demo2 <- demo[-300:-700,]
  plot(index(demo2), 1:599, type="l")         # we see that 5th to 10th 
                                              # second is zapped out.
  to5sec <- function(x) as.POSIXct(5*ceiling(as.numeric(x)/5), origin = "1970-01-01")


Now :

> aggregate(demo, to5sec, tail, 1)
                    spread    ltp
2009-02-16 05:00:05 0.0050 48.715
2009-02-16 05:00:10 0.0025 48.715
2009-02-16 05:00:15 0.0025 48.715
2009-02-16 05:00:20 0.0025 48.715
> aggregate(demo2, to5sec, tail, 1)
                    spread    ltp
2009-02-16 05:00:05 0.0050 48.715
2009-02-16 05:00:15 0.0025 48.715
2009-02-16 05:00:20 0.0025 48.715  

We should get : 

                    spread    ltp
2009-02-16 05:00:05 0.0050 48.715
2009-02-16 05:00:10 NA     NA
2009-02-16 05:00:15 0.0025 48.715
2009-02-16 05:00:20 0.0025 48.715  

-- 
Ajay Shah                                      http://www.mayin.org/ajayshah  
ajayshah at mayin.org                             http://ajayshahblog.blogspot.com
<*(:-? - wizard who doesn't know the answer.


From ggrothendieck at gmail.com  Sun Nov  8 15:13:37 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 8 Nov 2009 09:13:37 -0500
Subject: [R-SIG-Finance] Discretising intra-day data using zoo?
In-Reply-To: <20091108125857.GC1524@ajay-shahs-macbook-pro.local>
References: <20091108071005.GA23944@ajay-shahs-macbook-pro.local> 
	<971536df0911080420m51067166q81885a554781eade@mail.gmail.com> 
	<20091108125857.GC1524@ajay-shahs-macbook-pro.local>
Message-ID: <971536df0911080613h1a2673c8j345c905f7ae1d3cd@mail.gmail.com>

On Sun, Nov 8, 2009 at 7:58 AM, Ajay Shah <ajayshah at mayin.org> wrote:
> library(zoo)
> print(load(url("http://www.mayin.org/ajayshah/tmp/demo.rda")))
> options("digits.secs"=6)
> head(demo)
> tail(demo)
>
> On Sun, Nov 08, 2009 at 07:20:02AM -0500, Gabor Grothendieck wrote:
>> See the aggregate.zoo example in vignette("zoo-quickref") but round up
>> to the next 4 seconds instead of next Friday:
>>
>> > to4sec <- function(x) as.POSIXct(4*ceiling(as.numeric(x)/4), origin = "1970-01-01")
>> > aggregate(demo, to4sec, tail, 1)
>> ? ? ? ? ? ? ? ? ? ? spread ? ?ltp
>> 2009-02-16 05:00:04 0.0050 48.715
>> 2009-02-16 05:00:08 0.0025 48.715
>> 2009-02-16 05:00:12 0.0025 48.715
>> 2009-02-16 05:00:16 0.0025 48.715
>
> Gabor, thanks! I am not as fluent with as.POSIXct() as I should be.
>
> And, to continue with my original question:
>
>> > Suppose there is not a single record in the raw data from 10:30:04 to
>> > 10:30:09. Despite this, the resulting object should contain a record
>> > for 10:30:08 with NA values (which can then be filled out e.g. using
>> > na.locf()). How would we do this? This problem is not present in this
>> > data, where records are plentiful. But discretisation code should be
>> > general and handle this case right.
>
> How would we do this? To illustrate:
>
> ?demo2 <- demo[-300:-700,]
> ?plot(index(demo2), 1:599, type="l") ? ? ? ? # we see that 5th to 10th
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?# second is zapped out.
> ?to5sec <- function(x) as.POSIXct(5*ceiling(as.numeric(x)/5), origin = "1970-01-01")
>
>
> Now :
>
>> aggregate(demo, to5sec, tail, 1)
> ? ? ? ? ? ? ? ? ? ?spread ? ?ltp
> 2009-02-16 05:00:05 0.0050 48.715
> 2009-02-16 05:00:10 0.0025 48.715
> 2009-02-16 05:00:15 0.0025 48.715
> 2009-02-16 05:00:20 0.0025 48.715
>> aggregate(demo2, to5sec, tail, 1)
> ? ? ? ? ? ? ? ? ? ?spread ? ?ltp
> 2009-02-16 05:00:05 0.0050 48.715
> 2009-02-16 05:00:15 0.0025 48.715
> 2009-02-16 05:00:20 0.0025 48.715
>
> We should get :
>
> ? ? ? ? ? ? ? ? ? ?spread ? ?ltp
> 2009-02-16 05:00:05 0.0050 48.715
> 2009-02-16 05:00:10 NA ? ? NA
> 2009-02-16 05:00:15 0.0025 48.715
> 2009-02-16 05:00:20 0.0025 48.715
>

The trick is that converting to ts makes the series regular (as that
is the only thing ts can represent) so just convert it to ts and then
back to zoo.  Since ts cannot represent POSIXct what you get back will
not have the POSIXct class= attribute set so just set it yourself.

> # aggregate to 5 seconds
> ag <- aggregate(demo2, to5sec, tail, 1)
>
> # make regular (this will strip class from time)
> ag.fill <- as.zoo(as.ts(ag))
>
> # put class back on time
> time(ag.fill) <- structure(time(ag.fill), class = class(time(ag)))
> ag.fill
                    spread    ltp
2009-02-16 05:00:05 0.0050 48.715
2009-02-16 05:00:10     NA     NA
2009-02-16 05:00:15 0.0025 48.715
2009-02-16 05:00:20 0.0025 48.715


From ggrothendieck at gmail.com  Sun Nov  8 15:25:54 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 8 Nov 2009 09:25:54 -0500
Subject: [R-SIG-Finance] Discretising intra-day data using zoo?
In-Reply-To: <971536df0911080613h1a2673c8j345c905f7ae1d3cd@mail.gmail.com>
References: <20091108071005.GA23944@ajay-shahs-macbook-pro.local> 
	<971536df0911080420m51067166q81885a554781eade@mail.gmail.com> 
	<20091108125857.GC1524@ajay-shahs-macbook-pro.local>
	<971536df0911080613h1a2673c8j345c905f7ae1d3cd@mail.gmail.com>
Message-ID: <971536df0911080625h994b336w57a3225fc336414a@mail.gmail.com>

On Sun, Nov 8, 2009 at 9:13 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> On Sun, Nov 8, 2009 at 7:58 AM, Ajay Shah <ajayshah at mayin.org> wrote:
>> library(zoo)
>> print(load(url("http://www.mayin.org/ajayshah/tmp/demo.rda")))
>> options("digits.secs"=6)
>> head(demo)
>> tail(demo)
>>
>> On Sun, Nov 08, 2009 at 07:20:02AM -0500, Gabor Grothendieck wrote:
>>> See the aggregate.zoo example in vignette("zoo-quickref") but round up
>>> to the next 4 seconds instead of next Friday:
>>>
>>> > to4sec <- function(x) as.POSIXct(4*ceiling(as.numeric(x)/4), origin = "1970-01-01")
>>> > aggregate(demo, to4sec, tail, 1)
>>> ? ? ? ? ? ? ? ? ? ? spread ? ?ltp
>>> 2009-02-16 05:00:04 0.0050 48.715
>>> 2009-02-16 05:00:08 0.0025 48.715
>>> 2009-02-16 05:00:12 0.0025 48.715
>>> 2009-02-16 05:00:16 0.0025 48.715
>>
>> Gabor, thanks! I am not as fluent with as.POSIXct() as I should be.
>>
>> And, to continue with my original question:
>>
>>> > Suppose there is not a single record in the raw data from 10:30:04 to
>>> > 10:30:09. Despite this, the resulting object should contain a record
>>> > for 10:30:08 with NA values (which can then be filled out e.g. using
>>> > na.locf()). How would we do this? This problem is not present in this
>>> > data, where records are plentiful. But discretisation code should be
>>> > general and handle this case right.
>>
>> How would we do this? To illustrate:
>>
>> ?demo2 <- demo[-300:-700,]
>> ?plot(index(demo2), 1:599, type="l") ? ? ? ? # we see that 5th to 10th
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?# second is zapped out.
>> ?to5sec <- function(x) as.POSIXct(5*ceiling(as.numeric(x)/5), origin = "1970-01-01")
>>
>>
>> Now :
>>
>>> aggregate(demo, to5sec, tail, 1)
>> ? ? ? ? ? ? ? ? ? ?spread ? ?ltp
>> 2009-02-16 05:00:05 0.0050 48.715
>> 2009-02-16 05:00:10 0.0025 48.715
>> 2009-02-16 05:00:15 0.0025 48.715
>> 2009-02-16 05:00:20 0.0025 48.715
>>> aggregate(demo2, to5sec, tail, 1)
>> ? ? ? ? ? ? ? ? ? ?spread ? ?ltp
>> 2009-02-16 05:00:05 0.0050 48.715
>> 2009-02-16 05:00:15 0.0025 48.715
>> 2009-02-16 05:00:20 0.0025 48.715
>>
>> We should get :
>>
>> ? ? ? ? ? ? ? ? ? ?spread ? ?ltp
>> 2009-02-16 05:00:05 0.0050 48.715
>> 2009-02-16 05:00:10 NA ? ? NA
>> 2009-02-16 05:00:15 0.0025 48.715
>> 2009-02-16 05:00:20 0.0025 48.715
>>
>
> The trick is that converting to ts makes the series regular (as that
> is the only thing ts can represent) so just convert it to ts and then
> back to zoo. ?Since ts cannot represent POSIXct what you get back will
> not have the POSIXct class= attribute set so just set it yourself.
>
>> # aggregate to 5 seconds
>> ag <- aggregate(demo2, to5sec, tail, 1)
>>
>> # make regular (this will strip class from time)
>> ag.fill <- as.zoo(as.ts(ag))
>>
>> # put class back on time
>> time(ag.fill) <- structure(time(ag.fill), class = class(time(ag)))
>> ag.fill
> ? ? ? ? ? ? ? ? ? ?spread ? ?ltp
> 2009-02-16 05:00:05 0.0050 48.715
> 2009-02-16 05:00:10 ? ? NA ? ? NA
> 2009-02-16 05:00:15 0.0025 48.715
> 2009-02-16 05:00:20 0.0025 48.715
>

A slightly shorter alternative to the time(ag.fill)<- line above is:

class(time(ag.fill)) <- class(time(ag))


From dsamperi at DecisionSynergy.com  Mon Nov  9 02:36:25 2009
From: dsamperi at DecisionSynergy.com (Dominick Samperi)
Date: Sun, 08 Nov 2009 20:36:25 -0500
Subject: [R-SIG-Finance] RcppTemplate
Message-ID: <4AF77219.3080208@DecisionSynergy.com>

The Rcpp R/C++ object mapping library and package template has
been updated on CRAN in package RcppTemplate. It allows you
to work with R objects like data frames and zoo time series in
C++ programs. R can call C++ functions, and C++ objects can
call R functions, with parameters and return values of any
of the most commonly used R data types (data frames,
factors, time series, etc.). By using as.zoo, as.irts, as.xts, etc. it
is possible to work with the other commonly used time series
on the C++ side. The main design goal was improved performance.

Dominick


From gian.cabaleiro at alumnos.usm.cl  Mon Nov  9 17:24:33 2009
From: gian.cabaleiro at alumnos.usm.cl (Paolo Cabaleiro)
Date: Mon, 09 Nov 2009 13:24:33 -0300
Subject: [R-SIG-Finance] [QuantMod] Load all stock symbols
Message-ID: <4AF84241.6070807@alumnos.usm.cl>

Hello everybody,

I was wondering how to load all the symbols at once using Quantmod.

I am trying to load them, so I will be able to test a set of parameters 
for each one.

For example, if the S&P where to have only 3 symbols, I could just write 
this...
 > getSymbols("KO;PEP;SBUX")
 > test(KO)
 > test(PEP)
 > test(SBUX)

but, how can I try this over all the S&P?
btw, test is a made-up function to illustrate the idea.

Thanks you


From Peter.Brecknock at bp.com  Mon Nov  9 18:03:57 2009
From: Peter.Brecknock at bp.com (Brecknock, Peter)
Date: Mon, 9 Nov 2009 17:03:57 -0000
Subject: [R-SIG-Finance] ARIMA, xreg and intercepts
Message-ID: <A206FD99F5C5344EB80F17EA93CB73DF0B8771DC@BP1XEUEX017-C.bp1.ad.bp.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091109/5a18235a/attachment.pl>

From jeff.a.ryan at gmail.com  Mon Nov  9 17:42:20 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 9 Nov 2009 10:42:20 -0600
Subject: [R-SIG-Finance] [QuantMod] Load all stock symbols
In-Reply-To: <4AF84241.6070807@alumnos.usm.cl>
References: <4AF84241.6070807@alumnos.usm.cl>
Message-ID: <e8e755250911090842x6cf999a8u1e5b734b0edc0333@mail.gmail.com>

Just extend the logic you have.

A full list of S&P symbols can be found via google (current and
historical), and you can just create a semi-colon delimited string to
pass into the function.

The function will pause 1s between requests after 5 symbols in one
call, so as to be kind to the Yahoo servers.  Left as a user exercise
if you are bent on bypassing.

HTH
Jeff

On Mon, Nov 9, 2009 at 10:24 AM, Paolo Cabaleiro
<gian.cabaleiro at alumnos.usm.cl> wrote:
> Hello everybody,
>
> I was wondering how to load all the symbols at once using Quantmod.
>
> I am trying to load them, so I will be able to test a set of parameters for
> each one.
>
> For example, if the S&P where to have only 3 symbols, I could just write
> this...
>> getSymbols("KO;PEP;SBUX")
>> test(KO)
>> test(PEP)
>> test(SBUX)
>
> but, how can I try this over all the S&P?
> btw, test is a made-up function to illustrate the idea.
>
> Thanks you
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From knguyen at cs.umb.edu  Mon Nov  9 17:48:24 2009
From: knguyen at cs.umb.edu (Khanh Nguyen)
Date: Mon, 9 Nov 2009 11:48:24 -0500
Subject: [R-SIG-Finance] [QuantMod] Load all stock symbols
In-Reply-To: <4AF84241.6070807@alumnos.usm.cl>
References: <4AF84241.6070807@alumnos.usm.cl>
Message-ID: <2871c9e10911090848m57b2a986t41b6425c19802e17@mail.gmail.com>

Assume you have all the stock tickers...

> tickers <- "KO;PEP;SBUX"
> tickers
[1] "KO;PEP;SBUX"
> getSymbols("KO;PEP;SBUX")
[1] "KO"   "PEP"  "SBUX"
> r <- getSymbols("KO;PEP;SBUX")
> r
[1] "KO"   "PEP"  "SBUX"
> f <- function(x) {
+ mean(get(x))
+ }
> lapply(r, f)
[[1]]
[1] 1850594

[[2]]
[1] 1216594

[[3]]
[1] 2232611

Hope it helps,

-k

On Mon, Nov 9, 2009 at 11:24 AM, Paolo Cabaleiro
<gian.cabaleiro at alumnos.usm.cl> wrote:
> Hello everybody,
>
> I was wondering how to load all the symbols at once using Quantmod.
>
> I am trying to load them, so I will be able to test a set of parameters for
> each one.
>
> For example, if the S&P where to have only 3 symbols, I could just write
> this...
>> getSymbols("KO;PEP;SBUX")
>> test(KO)
>> test(PEP)
>> test(SBUX)
>
> but, how can I try this over all the S&P?
> btw, test is a made-up function to illustrate the idea.
>
> Thanks you
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From julia_cains at yahoo.com  Tue Nov 10 12:31:04 2009
From: julia_cains at yahoo.com (Julia Cairns)
Date: Tue, 10 Nov 2009 03:31:04 -0800 (PST)
Subject: [R-SIG-Finance] Nelson- Siegel - (Yield Curve - Smoothening of
	curve)
Message-ID: <615842.98736.qm@web111608.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091110/06235ce6/attachment.pl>

From abhibera at gmail.com  Wed Nov 11 07:52:46 2009
From: abhibera at gmail.com (Abhijit Bera)
Date: Wed, 11 Nov 2009 11:52:46 +0500
Subject: [R-SIG-Finance] Help with fPortfolio
Message-ID: <fc212e850911102252h2ec4e719mdc660519365601e4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091111/fb0b0b32/attachment.pl>

From chalabi at phys.ethz.ch  Wed Nov 11 11:57:12 2009
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Wed, 11 Nov 2009 11:57:12 +0100
Subject: [R-SIG-Finance] Help with fPortfolio
In-Reply-To: <fc212e850911110234s572602a8n7ad7f2b7f5390841@mail.gmail.com>
References: <fc212e850911102252h2ec4e719mdc660519365601e4@mail.gmail.com>
	<fc212e850911110234s572602a8n7ad7f2b7f5390841@mail.gmail.com>
Message-ID: <20091111115712.4e5d4ce2@mimi>

>>>> "AB" == Abhijit Bera <abhibera at gmail.com>
>>>> on Wed, 11 Nov 2009 15:34:50 +0500

Hi Abhijit,

Please note that cross-posting is considered to be impolite.

   AB> I'm getting the following errors while using the
   AB> efficientPortfolio function
   AB> even though I'm setting the target return to the mean of the
   AB> TargetReturn I
   AB> obtain from the portfolio object created by the
   AB> feasiblePortfolio function.
   AB>
   AB> First Error:
   AB> Error: targetReturn >= min(mu) is not TRUE

As stated by the error message, the target return should be larger
or equal to the minimum return of your time series.

   AB>
   AB> Second Error:
   AB> Error in .rquadprog(Dmat = args, dvec = args, Amat = args, :
   AB>
   AB> NA/NaN/Inf in foreign function call (arg 8)

HTH,
Yohan

-- 
PhD candidate
Swiss Federal Institute of Technology
Zurich

www.ethz.ch


From bogaso.christofer at gmail.com  Thu Nov 12 10:19:55 2009
From: bogaso.christofer at gmail.com (Bogaso)
Date: Thu, 12 Nov 2009 01:19:55 -0800 (PST)
Subject: [R-SIG-Finance] [R-sig-finance] A VaR question
Message-ID: <26315142.post@talk.nabble.com>


Hi all,

My question is not directly R related but rather a finance related question.
Therefore I was wondering wheher I find a reliable answer here.

Here I wanted to calculate VaR for basis (spot-future). There could be two
approaches : 1: Assuming basis as a portfolio of two assets and then
calculate the risk of the spread, 2 : Create a historical price series of
basis then calculate VaR like single asset portfolio.

Which one would be correct approach? In my opinion 1st is correct because,
as basis can get any value like +ve & -ve, cashflow is not well defined in
the sense that, if I sell basis (as an asset) and that time basis is
negative, then I actually paying money for selling my asset !!! and secondly
I cannot calculate percentage/logarithmic return for basis as basis can take
zero-value as well.

Can anyone validate that? What is the standard approach for calculating risk
of a spread series? Should not we consider the fundamental risk factors
(like in basis-case they are spot & future)?

Best
-- 
View this message in context: http://old.nabble.com/A-VaR-question-tp26315142p26315142.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Thu Nov 12 13:05:54 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 12 Nov 2009 06:05:54 -0600
Subject: [R-SIG-Finance] [R-sig-finance] A VaR question
Message-ID: <4AFBFA22.4070907@braverock.com>

I calculate the risk of a particular spread using the underlying assets 
as you suggested in 1>

However, your risk if you are short the spread is (potentially) 
different than your risk if you are long the spread, so keep that in 
mind as well.

Another approach is to calculate the portfolio risk of the trading 
strategy, regardless of the underlying assets, but you need trade and P 
& L history for that approach.

Regards,

     - Brian

"Bogaso" <bogaso.christofer at gmail.com> wrote:

>
>Hi all,
>
>My question is not directly R related but rather a finance related question.
>Therefore I was wondering wheher I find a reliable answer here.
>
>Here I wanted to calculate VaR for basis (spot-future). There could be two
>approaches : 1: Assuming basis as a portfolio of two assets and then
>calculate the risk of the spread, 2 : Create a historical price series of
>basis then calculate VaR like single asset portfolio.
>
>Which one would be correct approach? In my opinion 1st is correct because,
>as basis can get any value like +ve & -ve, cashflow is not well defined in
>the sense that, if I sell basis (as an asset) and that time basis is
>negative, then I actually paying money for selling my asset !!! and secondly
>I cannot calculate percentage/logarithmic return for basis as basis can take
>zero-value as well.
>
>Can anyone validate that? What is the standard approach for calculating risk
>of a spread series? Should not we consider the fundamental risk factors
>(like in basis-case they are spot & future)?
>
>Best
>-- 

--
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From cedrick at cedrickjohnson.com  Thu Nov 12 13:27:14 2009
From: cedrick at cedrickjohnson.com (Cedrick W. Johnson)
Date: Thu, 12 Nov 2009 07:27:14 -0500
Subject: [R-SIG-Finance] [R-sig-finance] A VaR question
In-Reply-To: <4AFBFA22.4070907@braverock.com>
References: <4AFBFA22.4070907@braverock.com>
Message-ID: <4AFBFF22.2000908@cedrickjohnson.com>

<warning: coffee-has-not-kicked-in-yet>
A chime in regarding the calculation of VaR on spreads. I follow the 
approach Brian mentioned below, in addition to calculating the VaR for 
the actual  spread itself which yields yet another metric called 
'Diversification Benefit' (subtracting the spread VaR minus the combined 
VaR of the two legs). I'm trying to recall amongst the stacks of papers 
how to determine VaR on spreads that could be <= 0 (I admit, I've taken 
a rather haphazard approach and eliminated the timeseries minus the 0/- 
periods in question).

-cj



Brian G. Peterson wrote:
> I calculate the risk of a particular spread using the underlying 
> assets as you suggested in 1>
>
> However, your risk if you are short the spread is (potentially) 
> different than your risk if you are long the spread, so keep that in 
> mind as well.
>
> Another approach is to calculate the portfolio risk of the trading 
> strategy, regardless of the underlying assets, but you need trade and 
> P & L history for that approach.
>
> Regards,
>
>     - Brian
>
> "Bogaso" <bogaso.christofer at gmail.com> wrote:
>
>> Hi all,
>>
>> My question is not directly R related but rather a finance related 
>> question.
>> Therefore I was wondering wheher I find a reliable answer here.
>>
>> Here I wanted to calculate VaR for basis (spot-future). There could 
>> be two
>> approaches : 1: Assuming basis as a portfolio of two assets and then
>> calculate the risk of the spread, 2 : Create a historical price 
>> series of
>> basis then calculate VaR like single asset portfolio.
>>
>> Which one would be correct approach? In my opinion 1st is correct 
>> because,
>> as basis can get any value like +ve & -ve, cashflow is not well 
>> defined in
>> the sense that, if I sell basis (as an asset) and that time basis is
>> negative, then I actually paying money for selling my asset !!! and 
>> secondly
>> I cannot calculate percentage/logarithmic return for basis as basis 
>> can take
>> zero-value as well.
>>
>> Can anyone validate that? What is the standard approach for 
>> calculating risk
>> of a spread series? Should not we consider the fundamental risk factors
>> (like in basis-case they are spot & future)?
>>
>> Best
>> -- 
>
> -- 
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From Peter.Brecknock at bp.com  Thu Nov 12 15:22:07 2009
From: Peter.Brecknock at bp.com (Brecknock, Peter)
Date: Thu, 12 Nov 2009 14:22:07 -0000
Subject: [R-SIG-Finance] ARIMA, xreg and intercepts
Message-ID: <A206FD99F5C5344EB80F17EA93CB73DF0B8DC1DF@BP1XEUEX017-C.bp1.ad.bp.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091112/0df1aa32/attachment.pl>

From brian at braverock.com  Thu Nov 12 15:35:26 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 12 Nov 2009 08:35:26 -0600
Subject: [R-SIG-Finance] ARIMA, xreg and intercepts
In-Reply-To: <A206FD99F5C5344EB80F17EA93CB73DF0B8DC1DF@BP1XEUEX017-C.bp1.ad.bp.com>
References: <A206FD99F5C5344EB80F17EA93CB73DF0B8DC1DF@BP1XEUEX017-C.bp1.ad.bp.com>
Message-ID: <4AFC1D2E.1080104@braverock.com>

Rather than reposting, you might get more of a response if you followed 
the posting guide:

http://www.r-project.org/posting-guide.html

and provided a reproducible example.

It seems that from your pseudocode, you could test your own hypothesis, 
but you didn't provide data, so I can't check.  If your hypothesized 
behavior did not materialize, as seems likely, then providing the steps 
that you tried, what you expected/wanted to happen, and what happened 
instead would assist someone else who felt like helping you out.

Also, it is considered impolite to attach claims of confidentiality to a 
public mailing list.

Regards,

  - Brian

Brecknock, Peter wrote:
> Re-posting from Monday .......
>
> Hi All
>
> David Stoffer describes some challenges with R's output when fitting
> ARIMA models for different orders (see Issue 2 at
> http://www.stat.pitt.edu/stoffer/tsa2/Rissues.htm). R doesn't fit an
> intercept in the model if there is any differencing. David describes a
> workaround using the xreg parameter to force R to calculate an
> intercept.
>
> Assume I have a variable y and 3 explanatory variables a, b and c. 
>
> No intercept would be produced for the model .... fit = arima(y,
> order=c(1,1,0), xreg=c(a,b,c)) 
>
> 1. If I wish to force an intercept to be output is the following
> correct?
>
> intercept = 1:length(y) 
> fit1 = arima(y, order=c(1,1,0), xreg=c(intercept, a, b, c)) 
>
> 2. If 1 is correct, is the following code equivalent?
>
> data = ts.intersect(diff(y),intercept, a,b,c)
> fit2 = arima(data[,1], order=c(1,0,0), xreg=[,c(2:5)]) 
>
> 3. If I fit 2 and find the intercept is not significant would it then be
> correct to use the following?
>
> fit = arima(y, order=c(1,1,0), xreg=c(a,b,c)) 
>
>
> Thanks for your help
>
> Kind regards
>
> Pete
>   


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From Peter.Brecknock at bp.com  Thu Nov 12 16:58:59 2009
From: Peter.Brecknock at bp.com (Brecknock, Peter)
Date: Thu, 12 Nov 2009 15:58:59 -0000
Subject: [R-SIG-Finance] ARIMA, xreg and intercepts
In-Reply-To: <4AFC1D2E.1080104@braverock.com>
References: <A206FD99F5C5344EB80F17EA93CB73DF0B8DC1DF@BP1XEUEX017-C.bp1.ad.bp.com>
	<4AFC1D2E.1080104@braverock.com>
Message-ID: <A206FD99F5C5344EB80F17EA93CB73DF0B8DC387@BP1XEUEX017-C.bp1.ad.bp.com>

Brian

I have attached some code that I hope illustrates my issue.

y=c(-0.626,0.183,-0.835,1.595,0.329,-0.820,0.487,0.738,0.575,-0.305)
a=c(-0.896,0.184,1.587,-1.130,-0.080,0.132,0.707,-0.239,1.984,-0.138)
b=c(2.090,-1.199,1.589,1.954,0.004,-2.451,0.477,-0.596,0.792,0.289)
c=c(-0.383,-1.959,-0.841,1.903,0.622,1.990,-0.305,-0.090,-0.184,-1.198)

# No intercept fitted
fit = arima(y, order=c(1,1,0), xreg=cbind(a,b,c))

# Q1 - How would I fit an intercept along with explanatory variables
using the order=c(1,1,0) approach?

# My attempt ....
intercept = 1:length(y)
fit1 = arima(y, order=c(1,1,0), xreg=cbind(intercept, a, b, c))

# Q2 - What is the equivalent code to Q1 that would use order=c(1,0,0)?

# My attempt .... (gives different results to fit1)
data = ts.intersect(ts(diff(y)),ts(a),ts(b),ts(c))
fit2 = arima(data[,1], order=c(1,0,0), xreg=data[,c(2:4)])

# Q3 - Assume intercept non-significant. At that point would it make
sense to fit the following no intercept model?

fit = arima(y, order=c(1,1,0), xreg=cbind(a,b,c))


It's funny that it is considered impolite to (inadvertently) attach a
claim of confidentiality to a public mailing list but that it is not
considered impolite to publically rebuke someone for doing it! ;-)
 
Kind regards

Pete


-----Original Message-----
From: Brian G. Peterson [mailto:brian at braverock.com] 
Sent: Thursday, November 12, 2009 8:35 AM
To: Brecknock, Peter
Cc: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] ARIMA, xreg and intercepts

Rather than reposting, you might get more of a response if you followed 
the posting guide:

http://www.r-project.org/posting-guide.html

and provided a reproducible example.

It seems that from your pseudocode, you could test your own hypothesis, 
but you didn't provide data, so I can't check.  If your hypothesized 
behavior did not materialize, as seems likely, then providing the steps 
that you tried, what you expected/wanted to happen, and what happened 
instead would assist someone else who felt like helping you out.

Also, it is considered impolite to attach claims of confidentiality to a

public mailing list.

Regards,

  - Brian

Brecknock, Peter wrote:
> Re-posting from Monday .......
>
> Hi All
>
> David Stoffer describes some challenges with R's output when fitting
> ARIMA models for different orders (see Issue 2 at
> http://www.stat.pitt.edu/stoffer/tsa2/Rissues.htm). R doesn't fit an
> intercept in the model if there is any differencing. David describes a
> workaround using the xreg parameter to force R to calculate an
> intercept.
>
> Assume I have a variable y and 3 explanatory variables a, b and c. 
>
> No intercept would be produced for the model .... fit = arima(y,
> order=c(1,1,0), xreg=c(a,b,c)) 
>
> 1. If I wish to force an intercept to be output is the following
> correct?
>
> intercept = 1:length(y) 
> fit1 = arima(y, order=c(1,1,0), xreg=c(intercept, a, b, c)) 
>
> 2. If 1 is correct, is the following code equivalent?
>
> data = ts.intersect(diff(y),intercept, a,b,c)
> fit2 = arima(data[,1], order=c(1,0,0), xreg=[,c(2:5)]) 
>
> 3. If I fit 2 and find the intercept is not significant would it then
be
> correct to use the following?
>
> fit = arima(y, order=c(1,1,0), xreg=c(a,b,c)) 
>
>
> Thanks for your help
>
> Kind regards
>
> Pete
>   


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From guillaume.yziquel at citycable.ch  Thu Nov 12 19:19:53 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Thu, 12 Nov 2009 19:19:53 +0100
Subject: [R-SIG-Finance] ARIMA, xreg and intercepts
In-Reply-To: <A206FD99F5C5344EB80F17EA93CB73DF0B8DC387@BP1XEUEX017-C.bp1.ad.bp.com>
References: <A206FD99F5C5344EB80F17EA93CB73DF0B8DC1DF@BP1XEUEX017-C.bp1.ad.bp.com>	<4AFC1D2E.1080104@braverock.com>
	<A206FD99F5C5344EB80F17EA93CB73DF0B8DC387@BP1XEUEX017-C.bp1.ad.bp.com>
Message-ID: <4AFC51C9.80409@citycable.ch>

Brecknock, Peter a ?crit :
> 
> It's funny that it is considered impolite to (inadvertently) attach a
> claim of confidentiality to a public mailing list but that it is not
> considered impolite to publically rebuke someone for doing it! ;-)
>  
> Kind regards
> 
> Pete

No. It's not funny. At all.

Guillaume Yziquel.


From nands31 at gmail.com  Thu Nov 12 20:14:18 2009
From: nands31 at gmail.com (Subhrangshu Nandi)
Date: Thu, 12 Nov 2009 19:14:18 +0000
Subject: [R-SIG-Finance] xts conversion error
Message-ID: <de69a2b90911121114xae82b76wc203f55ac7d378b4@mail.gmail.com>

I have two data frames, with two columns each, the first being a Date
variable. I would like to convert them to xts objects, indexed by the Date
column. *I would like to use as.Date and not as.POSIXct as the
dateformat.*The puzzling fact is that it works for the first one but
not the other. Here
is a screenshot of the error:

*> str(DF1)*
'data.frame':   367 obs. of  2 variables:
 $ Date:Class 'Date'  num [1:367] 13515 13516 13517 13518 13521 ...
 $ X   : num  28.29 -53.58 58.33 -23.07 9.73 ...
*> str(DF2)*
'data.frame':   322 obs. of  2 variables:
 $ Date:Class 'Date'  num [1:322] 14061 14062 14063 14067 14068 ...
 $ X   : num  56.9 -16.6 50.1 -17.8 18.6 ...
*> DF1.xts <- as.xts(DF1, order.by=as.Date(DF1$Date))*
Warning messages:
1: In structure(.Internal(as.POSIXct(x, tz)), class = c("POSIXt",
"POSIXct"),  :
  unknown timezone 'merica/Chicago'
2: In structure(.Internal(as.POSIXct(x, tz)), class = c("POSIXt",
"POSIXct"),  :
  unknown timezone 'merica/Chicago'
3: In structure(.Internal(as.POSIXct(x, tz)), class = c("POSIXt",
"POSIXct"),  :
  unknown timezone 'merica/Chicago'
4: In structure(.Internal(as.POSIXct(x, tz)), class = c("POSIXt",
"POSIXct"),  :
  unknown timezone 'merica/Chicago'
5: In structure(.Internal(as.POSIXct(x, tz)), class = c("POSIXt",
"POSIXct"),  :
  unknown timezone 'merica/Chicago'
*> DF2.xts <- as.xts(DF2, order.by=as.Date(DF2$Date))*
*Error in as.POSIXlt.character(x, tz, ...) : *
*  character string is not in a standard unambiguous format*

I am using R2.10.0, and the latest version of xts (see below). I would like
to understand the cause of this error. I have been experiencing pretty
random errors with the latest version of R & xts. I was wondering if anyone
else is having similar issues. Thanks a lot.

*> version*
              _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          10.0
 year           2009
month          10
day            26
svn rev        50208
language       R
version.string R version 2.10.0 (2009-10-26)
*> packageDescription(pkg='xts')*
Package: xts
Type: Package
Title: Extensible Time Series
Version: 0.6-9
Date: 2009-10-14
Author: Jeffrey A. Ryan, Josh M. Ulrich
Depends: zoo
Suggests: timeSeries,timeDate,tseries,its,chron,fts,tis
LazyLoad: yes
Maintainer: Jeffrey A. Ryan <jeff.a.ryan at gmail.com>
Description: Provide for uniform handling of R's different time-based data
        classes by extending zoo, maximizing native format information
        preservation and allowing for user level customization and
        extension, while simplifying cross-class interoperability.
License: GPL-3
URL: http://r-forge.r-project.org/projects/xts/
 Repository: R-Forge
Repository/R-Forge/Project: xts
Repository/R-Forge/Revision: 463
Date/Publication: 2009-11-06 17:56:20
Packaged: 2009-11-06 21:12:13 UTC; rforge
Built: R 2.10.0; i386-pc-mingw32; 2009-11-11 00:09:42 UTC; windows

-- File: C:/PROGRA~1/R/R-210~1.0/library/xts/Meta/package.rds


-- 
I'm a great believer in luck, and I find the harder I work the more I have
of it.  ~Thomas Jefferson

Subhrangshu Nandi
High Frequency Trader
Breakwater Trading, LLC
Chicago, IL 60606
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091112/2253e40c/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: DF1.RData
Type: application/octet-stream
Size: 3757 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091112/2253e40c/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: DF2.RData
Type: application/octet-stream
Size: 3318 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091112/2253e40c/attachment-0001.obj>

From nands31 at gmail.com  Thu Nov 12 20:36:36 2009
From: nands31 at gmail.com (Subhrangshu Nandi)
Date: Thu, 12 Nov 2009 19:36:36 +0000
Subject: [R-SIG-Finance] xts conversion error
In-Reply-To: <de69a2b90911121114xae82b76wc203f55ac7d378b4@mail.gmail.com>
References: <de69a2b90911121114xae82b76wc203f55ac7d378b4@mail.gmail.com>
Message-ID: <de69a2b90911121136la81f8cbl494a9b7a75d4eb20@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091112/5f045557/attachment.pl>

From Heiko-Mayer at gmx.de  Thu Nov 12 21:00:11 2009
From: Heiko-Mayer at gmx.de (Heiko Mayer)
Date: Thu, 12 Nov 2009 21:00:11 +0100
Subject: [R-SIG-Finance] [R-sig-finance] A VaR question
In-Reply-To: <26315142.post@talk.nabble.com>
References: <26315142.post@talk.nabble.com>
Message-ID: <20091112200011.162710@gmx.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091112/c4f22916/attachment.pl>

From bogaso.christofer at gmail.com  Fri Nov 13 08:16:53 2009
From: bogaso.christofer at gmail.com (Bogaso)
Date: Thu, 12 Nov 2009 23:16:53 -0800 (PST)
Subject: [R-SIG-Finance] [R-sig-finance] A VaR question
In-Reply-To: <20091112200011.162710@gmx.net>
References: <26315142.post@talk.nabble.com> <20091112200011.162710@gmx.net>
Message-ID: <26332339.post@talk.nabble.com>


Hi  Heiko, I donot think there would be 100% correlation between 50% S&P and
+100% S&P 500 and  -50% S&P 500 future. Therefore I wondering how you can
take 1st series as a representative of 2nd series, if you really consider
daily P/L from them. Also I dont agree that "most difference arise from 
different trading times" because, generally we working with settlement price
in same exchange and therefore I have doubt whether this time effect is
anymore significant, however for intra-day trading they could be.

Best,



Heiko Mayer wrote:
> 
> I am afraid your question is quite confusing, a more precise sample would 
> be helpful. If you have an asset that should be hedged by a future and you 
> want to know historical VaR using daily data, you could just substract the 
> weight to get a good proxy for the HVaR.
> i.e. +100% S&P 500 and? -50% S&P 500 future => similar to 50% S&P 500
> Yes, I am aware that future returns can differ from spot (interests, 
> dividend expectations), however, in reality, most difference arise from 
> different trading times. Therefore, the proxy should be in most cases the 
> better choice.
> 
> Regards, 
> Heiko
> 
> 
> 
>>             
>> -------- Original-Nachricht --------
>> Datum: Thu, 12 Nov 2009 01:19:55 -0800 (PST)
>> Von: Bogaso <bogaso.christofer at gmail.com>
>> An: r-sig-finance at stat.math.ethz.ch
>> Betreff: [R-SIG-Finance] [R-sig-finance] A VaR question
>> 
>>             
>> Hi all,
>> 
>> My question is not directly R related but rather a finance related 
>> question.
>> Therefore I was wondering wheher I find a reliable answer here.
>> 
>> Here I wanted to calculate VaR for basis (spot-future). There could be 
>> two
>> approaches : 1: Assuming basis as a portfolio of two assets and then
>> calculate the risk of the spread, 2 : Create a historical price series of
>> basis then calculate VaR like single asset portfolio.
>> 
>> Which one would be correct approach? In my opinion 1st is correct 
>> because,
>> as basis can get any value like +ve & -ve, cashflow is not well defined 
>> in
>> the sense that, if I sell basis (as an asset) and that time basis is
>> negative, then I actually paying money for selling my asset !!! and 
>> secondly
>> I cannot calculate percentage/logarithmic return for basis as basis can 
>> take
>> zero-value as well.
>> 
>> Can anyone validate that? What is the standard approach for calculating 
>> risk
>> of a spread series? Should not we consider the fundamental risk factors
>> (like in basis-case they are spot & future)?
>> 
>> Best
>> -- 
>> View this message in context: 
>> http://old.nabble.com/A-VaR-question-tp26315142p26315142.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>> 
>> 
>> 
>         
> -- 
> GRATIS f?r alle GMX-Mitglieder: Die maxdome Movie-FLAT!
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 

-- 
View this message in context: http://old.nabble.com/A-VaR-question-tp26315142p26332339.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From Jose at erini.ac.uk  Fri Nov 13 11:24:07 2009
From: Jose at erini.ac.uk (Jose Iparraguirre D'Elia)
Date: Fri, 13 Nov 2009 10:24:07 -0000
Subject: [R-SIG-Finance] Residuals with Elliot-Rothenberg-Stock Unit Root
	Test
Message-ID: <C9328F0EEDC3BC439FDABD12060E9109AF163C@erini1.ERINI.local>

Does anyone know how to retrieve the residuals after running an Elliot-Rothenberg-Stock (ERS) unit root test on a time series (urca package)? There are no 'residuals' or 'res' (or similar) slots in the ur.ers-class, but a plot instruction - ie plot(ur.ers(....)) renders amongst other things a residual plot.

If an augmented Dickey-Fuller test is run, an object of ur.df-class is generated which does contain a 'res' slot vector of residuals, but with the ur.ers-class, I couldn't figure out how to send the residuals that are plotted to an object as I can't find the vector with the values that are automatically plotted.

Regards,

Jose


Mr Jos? Luis Iparraguirre
Senior Research Economist
Economic Research Institute of Northern Ireland
2 -14 East Bridge Street
Belfast BT1 3NQ
Northern Ireland
United Kingdom

Tel: +44 (0)28 9072 7365


From Heiko-Mayer at gmx.de  Fri Nov 13 21:05:10 2009
From: Heiko-Mayer at gmx.de (Heiko Mayer)
Date: Fri, 13 Nov 2009 21:05:10 +0100
Subject: [R-SIG-Finance] [R-sig-finance] A VaR question
In-Reply-To: <26332339.post@talk.nabble.com>
References: <26315142.post@talk.nabble.com> <20091112200011.162710@gmx.net>
	<26332339.post@talk.nabble.com>
Message-ID: <20091113200510.70040@gmx.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091113/685e52f7/attachment.pl>

From swtzang at gmail.com  Sat Nov 14 10:41:44 2009
From: swtzang at gmail.com (ShyhWeir Tzang)
Date: Sat, 14 Nov 2009 17:41:44 +0800
Subject: [R-SIG-Finance] nonlinear constraints in GARCH estimation
Message-ID: <c17037a10911140141l138891efra24493638c9779cd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091114/6131828e/attachment.pl>

From alexios at 4dscape.com  Sat Nov 14 15:17:04 2009
From: alexios at 4dscape.com (alexios)
Date: Sat, 14 Nov 2009 14:17:04 +0000
Subject: [R-SIG-Finance] nonlinear constraints in GARCH estimation
In-Reply-To: <c17037a10911140141l138891efra24493638c9779cd@mail.gmail.com>
References: <c17037a10911140141l138891efra24493638c9779cd@mail.gmail.com>
Message-ID: <4AFEBBE0.9080802@4dscape.com>

You probably need a nonlinear constraints solver to do this. You can try 
Rsolnp (an Augmented Lagrange type solver) in the RINO project on 
r-forge which accepts both nonlinear equalities and inequalities, or the 
nlminb2 solver in the Rmetrics project.

HTH,

-Alexios

ShyhWeir Tzang wrote:
> Dear R users:
> 
> I am trying to estimate the parameters using MLE of a GARCH-family model
> with some constraints like this: a>=0, b>=0, and a+b*c^2<1, where a, b and c
> are parameters to be estimted. I tried to use maxLik package which has
> unequal constraints in matrix form: A*theta+B>=0, where theta is the
> paramters to be estimated.  Parameters a and b can be easily set up, but I
> don't know how to set up the constraint a+b*c^2<1. Can anyone help me with
> this constraint? Thanks for help.
> 
> ShyhWeir
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
>


From gero.schwenk at web.de  Sun Nov 15 13:44:40 2009
From: gero.schwenk at web.de (Gero Schwenk)
Date: Sun, 15 Nov 2009 13:44:40 +0100
Subject: [R-SIG-Finance] fImport : where to get a list of ticker symbols?
Message-ID: <4AFFF7B8.7000900@web.de>

Hello together!
I want to undertake exploratory analyses (clustering, PCA, etc...) on 
historic data downloaded with yahooSeries (fImport-package). In order to 
download the data, I need a collection of ticker symbols. Is there some 
list or table out there, so that I don't need to look up the ticker 
symbols manually? Can anybody give me a hint?

Kind regards,
Gero


From brian at braverock.com  Sun Nov 15 13:59:59 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 15 Nov 2009 06:59:59 -0600
Subject: [R-SIG-Finance] fImport : where to get a list of ticker symbols?
In-Reply-To: <4AFFF7B8.7000900@web.de>
References: <4AFFF7B8.7000900@web.de>
Message-ID: <4AFFFB4F.1060700@braverock.com>

Gero Schwenk wrote:
> Hello together!
> I want to undertake exploratory analyses (clustering, PCA, etc...) on 
> historic data downloaded with yahooSeries (fImport-package). In order 
> to download the data, I need a collection of ticker symbols. Is there 
> some list or table out there, so that I don't need to look up the 
> ticker symbols manually? Can anybody give me a hint?
I don't know if fImport contains such a list.

In R:


require(quantmod)
?getSymbol

NASQAQ also used to publis spreadsheets or CSV files of all US-listed 
securities traded on major exchanges.

Bloomberg publishes their lists of symbols and identifiers as well.

Cheers,

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From J_Cuisinier at hotmail.com  Sun Nov 15 14:26:48 2009
From: J_Cuisinier at hotmail.com (julien cuisinier)
Date: Sun, 15 Nov 2009 14:26:48 +0100
Subject: [R-SIG-Finance] fImport : where to get a list of ticker symbols?
In-Reply-To: <4AFFF7B8.7000900@web.de>
References: <4AFFF7B8.7000900@web.de>
Message-ID: <BLU0-SMTP2924E23167DFE3E7F9118C8FA60@phx.gbl>

Hi Gero,


If you go on yahoo finance and choose an index, there is a link  
"components" that you can download in a spreadsheet. I guess that  
should cover your needs

e.g. for the SP500:
http://finance.yahoo.com/q/cp?s=^GSPC

hope that helps


Rgds,
Julien


On 15 Nov 2009, at 13:44, Gero Schwenk wrote:

> Hello together!
> I want to undertake exploratory analyses (clustering, PCA, etc...)  
> on historic data downloaded with yahooSeries (fImport-package). In  
> order to download the data, I need a collection of ticker symbols.  
> Is there some list or table out there, so that I don't need to look  
> up the ticker symbols manually? Can anybody give me a hint?
>
> Kind regards,
> Gero
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From josh.m.ulrich at gmail.com  Sun Nov 15 14:47:44 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 15 Nov 2009 07:47:44 -0600
Subject: [R-SIG-Finance] fImport : where to get a list of ticker symbols?
In-Reply-To: <4AFFFB4F.1060700@braverock.com>
References: <4AFFF7B8.7000900@web.de> <4AFFFB4F.1060700@braverock.com>
Message-ID: <8cca69990911150547v3dcab955ofda4b1a742303384@mail.gmail.com>

Gero,

The stockSymbols() function in the TTR package downloads all the
ticker symbols (from the NASDAQ CSV files Brian mentioned) into a
data.frame.

Best,
Josh
--
http://www.fosstrading.com



On Sun, Nov 15, 2009 at 6:59 AM, Brian G. Peterson <brian at braverock.com> wrote:
> Gero Schwenk wrote:
>>
>> Hello together!
>> I want to undertake exploratory analyses (clustering, PCA, etc...) on
>> historic data downloaded with yahooSeries (fImport-package). In order to
>> download the data, I need a collection of ticker symbols. Is there some list
>> or table out there, so that I don't need to look up the ticker symbols
>> manually? Can anybody give me a hint?
>
> I don't know if fImport contains such a list.
>
> In R:
>
>
> require(quantmod)
> ?getSymbol
>
> NASQAQ also used to publis spreadsheets or CSV files of all US-listed
> securities traded on major exchanges.
>
> Bloomberg publishes their lists of symbols and identifiers as well.
>
> Cheers,
>
> ?- Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From matthieu.stigler at gmail.com  Mon Nov 16 09:38:13 2009
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Mon, 16 Nov 2009 09:38:13 +0100
Subject: [R-SIG-Finance] Residuals with Elliot-Rothenberg-Stock Unit
	Root Test
In-Reply-To: <C9328F0EEDC3BC439FDABD12060E9109AF163C@erini1.ERINI.local>
References: <C9328F0EEDC3BC439FDABD12060E9109AF163C@erini1.ERINI.local>
Message-ID: <111060c20911160038p6d75b72dif16664652d215558@mail.gmail.com>

Dear Jos?

At best always provide code, even if trivial, as in:
library(urca)
ers<-ur.ers(sunspots)

For your question, I think:
res<-residuals(ers at testreg)

you could have found it using:
str(ers)
and then looking for the differents slots shown.

Hope this helps

Matthieu

2009/11/13 Jose Iparraguirre D'Elia <Jose at erini.ac.uk>:
> Does anyone know how to retrieve the residuals after running an Elliot-Rothenberg-Stock (ERS) unit root test on a time series (urca package)? There are no 'residuals' or 'res' (or similar) slots in the ur.ers-class, but a plot instruction - ie plot(ur.ers(....)) renders amongst other things a residual plot.
>
> If an augmented Dickey-Fuller test is run, an object of ur.df-class is generated which does contain a 'res' slot vector of residuals, but with the ur.ers-class, I couldn't figure out how to send the residuals that are plotted to an object as I can't find the vector with the values that are automatically plotted.
>
> Regards,
>
> Jose
>
>
> Mr Jos? Luis Iparraguirre
> Senior Research Economist
> Economic Research Institute of Northern Ireland
> 2 -14 East Bridge Street
> Belfast BT1 3NQ
> Northern Ireland
> United Kingdom
>
> Tel: +44 (0)28 9072 7365
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From mjenko at yahoo.com  Tue Nov 17 00:27:07 2009
From: mjenko at yahoo.com (Martin Jenkins)
Date: Mon, 16 Nov 2009 15:27:07 -0800 (PST)
Subject: [R-SIG-Finance]  Retrieving latest day's data
Message-ID: <650313.8369.qm@web113215.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091116/4a2f724d/attachment.pl>

From josh.m.ulrich at gmail.com  Tue Nov 17 01:30:00 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 16 Nov 2009 18:30:00 -0600
Subject: [R-SIG-Finance] Retrieving latest day's data
In-Reply-To: <650313.8369.qm@web113215.mail.gq1.yahoo.com>
References: <650313.8369.qm@web113215.mail.gq1.yahoo.com>
Message-ID: <8cca69990911161630ucc964e3re4147c6080271fe9@mail.gmail.com>

Martin,

Have you had a look at getQuote in quantmod?

Best,
Josh
--
http://www.fosstrading.com



On Mon, Nov 16, 2009 at 5:27 PM, Martin Jenkins <mjenko at yahoo.com> wrote:
> Hi,
>
> I realise that this isn't a 100% R-SIG question and is probably a more general R question, but I think it is related, and when I sort it it is leading to an R-SIG question, so if I could ask you to bear with me.
>
> I'm trying to build my own trading model, to test out some strategies.? Part of this involves downloading the stcok market data and then processing it, i.e. running my model on it, using R-SIG to build graphs etc.? However using Yahoo the historical data is always one day behind.? To get around this I'm attempting to use a screen scraper utility, called PageScrape.? It's command line based, however I'm trying to use system() to call the screen scraper from within R.? The problem is that the screen scraper use regex and this causes unexpected symbol errors when I try to run it inside the system function.
>
> So, I can run the below inside a batch file, so can you if you download PageScraper:
> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Day's Range:</td><td class=.yfnc_tabledata1.>[0-9]+\.[0-9]+ - ([0-9]+\.[0-9]+)</td></tr>"
> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Day's Range:</td><td class=.yfnc_tabledata1.>([0-9]+\.[0-9]+) - [0-9]+\.[0-9]+</td></tr>"
> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e">Last Trade:</td><td class=.yfnc_tabledata1.><big><b>([0-9]+\.[0-9]+) p"
> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Open:</td><td class=.yfnc_tabledata1.>([0-9]+\.[0-9]+)</td></tr>"
> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Volume:</td><td class=.yfnc_tabledata1.>([0-9]+,[0-9]+,[0-9]+)</td></tr>"
> pause
>
> This is actually 4 lines, which will bring back the open, high, low and volume from the URL after -u.? The bit inside the () is what's returned.
>
> What I'm after is to convert this to:
>
> system('cmd /c "pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Day's Range:</td><td class=.yfnc_tabledata1.>[0-9]+\.[0-9]+ - ([0-9]+\.[0-9]+)</td></tr>""')
>
> I've tried several attempts to get it working without any success.? If anyone here can help that would be terrific, and hopefully some of you may find it useful.
>
> Many thanks,
> Martin.
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From cedrick at cedrickjohnson.com  Tue Nov 17 03:52:47 2009
From: cedrick at cedrickjohnson.com (Cedrick W. Johnson)
Date: Mon, 16 Nov 2009 21:52:47 -0500
Subject: [R-SIG-Finance] Retrieving latest day's data
In-Reply-To: <650313.8369.qm@web113215.mail.gq1.yahoo.com>
References: <650313.8369.qm@web113215.mail.gq1.yahoo.com>
Message-ID: <4B020FFF.6040803@cedrickjohnson.com>

I have found that typically after the evening extended sessions finish 
(~8PM ET) I can get today's closing prices. I just ran this now @ 9:45P 
et and got my closing prices for today:

           GSPC.Open GSPC.High GSPC.Low GSPC.Close GSPC.Volume GSPC.Adjusted
2009-11-13   1087.59   1097.79  1085.33    1093.48  3792610000       1093.48
2009-11-16   1094.13   1113.69  1094.13    1109.30  4565850000       1109.30

I see you're getting UK tickers (this is what Joshua suggested, the 
getQuote function in quantmod):
 > getQuote("AML.L")
               Trade Time  Last Change % Change Open  High   Low  Volume
AML.L 2009-11-16 11:35:00 387.4   10.8   +2.87%  385 395.1 375.6 3375783

*edit*

While composing, I thought to check using Google:

 > getSymbols("AML.L", src="google")

 > tail(AML.L,2)
           AML.L.Open AML.L.High AML.L.Low AML.L.Close AML.L.Volume
2009-11-13      372.9      376.9     368.1       376.6      1403827
2009-11-16      385.0      395.1     375.6       387.4      3375783

Try that on the rest of your symbols to see what you get. Again, the 
time(s) that they update the closing price may be different. The same 
query I just did using Yahoo as a source yielded the 13th's closing 
price, while google is getting you what you want.

HTH,
Cedrick


Martin Jenkins wrote:
> Hi,
>
> I realise that this isn't a 100% R-SIG question and is probably a more general R question, but I think it is related, and when I sort it it is leading to an R-SIG question, so if I could ask you to bear with me.
>
> I'm trying to build my own trading model, to test out some strategies.  Part of this involves downloading the stcok market data and then processing it, i.e. running my model on it, using R-SIG to build graphs etc.  However using Yahoo the historical data is always one day behind.  To get around this I'm attempting to use a screen scraper utility, called PageScrape.  It's command line based, however I'm trying to use system() to call the screen scraper from within R.  The problem is that the screen scraper use regex and this causes unexpected symbol errors when I try to run it inside the system function.
>
> So, I can run the below inside a batch file, so can you if you download PageScraper:
> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Day's Range:</td><td class=.yfnc_tabledata1.>[0-9]+\.[0-9]+ - ([0-9]+\.[0-9]+)</td></tr>"
> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Day's Range:</td><td class=.yfnc_tabledata1.>([0-9]+\.[0-9]+) - [0-9]+\.[0-9]+</td></tr>"
> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e">Last Trade:</td><td class=.yfnc_tabledata1.><big><b>([0-9]+\.[0-9]+) p"
> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Open:</td><td class=.yfnc_tabledata1.>([0-9]+\.[0-9]+)</td></tr>"
> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Volume:</td><td class=.yfnc_tabledata1.>([0-9]+,[0-9]+,[0-9]+)</td></tr>"
> pause
>
> This is actually 4 lines, which will bring back the open, high, low and volume from the URL after -u.  The bit inside the () is what's returned.
>
> What I'm after is to convert this to:
>
> system('cmd /c "pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Day's Range:</td><td class=.yfnc_tabledata1.>[0-9]+\.[0-9]+ - ([0-9]+\.[0-9]+)</td></tr>""')
>
> I've tried several attempts to get it working without any success.  If anyone here can help that would be terrific, and hopefully some of you may find it useful.
>
> Many thanks,
> Martin.
>
>
>
>       
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From weihanliu2002 at yahoo.com  Tue Nov 17 07:40:56 2009
From: weihanliu2002 at yahoo.com (Wei-han Liu)
Date: Mon, 16 Nov 2009 22:40:56 -0800 (PST)
Subject: [R-SIG-Finance] varRisk in fPortfolio package
Message-ID: <329955.74628.qm@web53511.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091116/168dc184/attachment.pl>

From cedrick at cedrickjohnson.com  Tue Nov 17 07:43:36 2009
From: cedrick at cedrickjohnson.com (Cedrick W. Johnson)
Date: Tue, 17 Nov 2009 01:43:36 -0500
Subject: [R-SIG-Finance] varRisk in fPortfolio package
In-Reply-To: <329955.74628.qm@web53511.mail.re2.yahoo.com>
References: <329955.74628.qm@web53511.mail.re2.yahoo.com>
Message-ID: <4B024618.9060101@cedrickjohnson.com>

 > varRisk
function (data, weights, alpha = 0.05)
{
    if (inherits(data, "timeSeries"))
        data <- getDataPart(data)
    weights = as.vector(weights)
    X = as.matrix(data) %*% weights
    VaR = quantile(X, alpha, type = 1)
    names(VaR) <- paste("VaR.", alpha * 100, "%", sep = "")
    VaR
}
<environment: namespace:fPortfolio>

from ?varRisk


      References

Wuertz, D., Chalabi, Y., Chen W., Ellis A. (2009); /Portfolio 
Optimization with R/Rmetrics/, Rmetrics eBook, Rmetrics Association and 
Finance Online, Zurich


-cedrick




Wei-han Liu wrote:
> Hi R Users:
>  
> I am curious about the computational algorithm of the function listed below in fPortfolio package. Or there is some relevant literature to develop this function?
>  
> varRisk(data,weights,alpha=0.05)
>  
> Thanks.
>  
> Wei-han
>
>
>
>       
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>   


-- 

=============================
*Cedrick W. Johnson*
**note new updated phone #'s
office) 203.340.3442
cell) 646.434.8052
aolim) cedrickjcvgr
www.cedrickjohnson.com
*New York - Chicago*


From ecjbosu at aol.com  Tue Nov 17 11:37:43 2009
From: ecjbosu at aol.com (Joe W. Byers)
Date: Tue, 17 Nov 2009 04:37:43 -0600
Subject: [R-SIG-Finance] NYMEX/COMEX daily settle txt files
Message-ID: <4B027CF7.6010209@aol.com>

This is not an true R Finance question, but I thought some here might be 
able to help.  I have some R and perl scripts that download the NYMEX 
and Comex files every night then load them into a database.

The CME changed the file formats and URLs this past week and I missed 
three days before I fixed my download scripts.  The days were 10/9, 
10/10, and 10/12.  I was wondering if anyone out there also downloaded 
these files (formerly called innf, inno, inco, incf dot txt).  I am 
using the old test format.  I have continuous data since 2005 and would 
like to keep the series going.

If I can find the xml schema for the cme xml files I will add changing 
the data source to my to do list. :)

Thank you very much.

Joe Byers


From marco.zanella at inbox.com  Tue Nov 17 12:55:11 2009
From: marco.zanella at inbox.com (Zanella Marco)
Date: Tue, 17 Nov 2009 03:55:11 -0800
Subject: [R-SIG-Finance] Order a XTS object by value
In-Reply-To: <4B027CF7.6010209@aol.com>
Message-ID: <550E5894352.0000000Amarco.zanella@inbox.com>

Sirs,
a simple question about how I can order an XTS object by time series value (return, in my case). Can I do it only via a previous transformation to a matrix object and consequent ordering with classic order() command?

Many thanks.

Marco

PS: for the record I'm trying to run a time window analysis (es top 10 MAX returns,etc...) of funds time series.


From brian at braverock.com  Tue Nov 17 13:21:14 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 17 Nov 2009 06:21:14 -0600
Subject: [R-SIG-Finance] varRisk in fPortfolio package
In-Reply-To: <329955.74628.qm@web53511.mail.re2.yahoo.com>
References: <329955.74628.qm@web53511.mail.re2.yahoo.com>
Message-ID: <4B02953A.5050108@braverock.com>

Wei-han Liu wrote:
> Hi R Users:
>  
> I am curious about the computational algorithm of the function listed below in fPortfolio package. Or there is some relevant literature to develop this function?
>  
> varRisk(data,weights,alpha=0.05)
>   
All functions in R may be examined by simply typing the function name 
without parentesis or parameters, like so:

varRisk

?varRisk # should give you the documentation

Also, see package 'VaR'  for log-normal and general Pareto VaR 
calculated via Monte Carlo, and package PerformanceAnalytics for 
univariate, marginal, and portfolio component VaR and ES/CVaR calculated 
for historical, Gaussian, Cornish-Fisher, and kernel estimators, as well 
as charts showing rolling measures and sensitivity analysis.

Regards,

    - Brian  

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From jeff.a.ryan at gmail.com  Tue Nov 17 16:06:09 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 17 Nov 2009 09:06:09 -0600
Subject: [R-SIG-Finance] Order a XTS object by value
In-Reply-To: <550E5894352.0000000Amarco.zanella@inbox.com>
References: <4B027CF7.6010209@aol.com>
	<550E5894352.0000000Amarco.zanella@inbox.com>
Message-ID: <e8e755250911170706u73fef1a7y956de2054a318330@mail.gmail.com>

Marco,

xts, like zoo, only represents 'ordered' time series, so the answer is
no. If an xts object could be unordered the rest of the assumptions
made internally and externally for the class would be invalid.

You will need to use as.matrix() or coredata() to allow for re-ordering.

Best,
Jeff

On Tue, Nov 17, 2009 at 5:55 AM, Zanella Marco <marco.zanella at inbox.com> wrote:
> Sirs,
> a simple question about how I can order an XTS object by time series value (return, in my case). Can I do it only via a previous transformation to a matrix object and consequent ordering with classic order() command?
>
> Many thanks.
>
> Marco
>
> PS: for the record I'm trying to run a time window analysis (es top 10 MAX returns,etc...) of funds time series.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From dstjohn at math.uic.edu  Tue Nov 17 17:48:19 2009
From: dstjohn at math.uic.edu (David St John)
Date: Tue, 17 Nov 2009 10:48:19 -0600
Subject: [R-SIG-Finance] Daily Return of a Leveraged / Shorted Asset
Message-ID: <998c123e0911170848n322feda4lda27c6cfc5c094ee@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091117/2d068194/attachment.pl>

From patrick at burns-stat.com  Tue Nov 17 21:07:57 2009
From: patrick at burns-stat.com (Patrick Burns)
Date: Tue, 17 Nov 2009 20:07:57 +0000
Subject: [R-SIG-Finance] Daily Return of a Leveraged / Shorted Asset
In-Reply-To: <998c123e0911170848n322feda4lda27c6cfc5c094ee@mail.gmail.com>
References: <998c123e0911170848n322feda4lda27c6cfc5c094ee@mail.gmail.com>
Message-ID: <4B03029D.2080009@burns-stat.com>

I'm not following your notation, so I don't
really understand your question.  But I have
one comment that might help.

When you short an asset, you are really reversing
time in terms of returns.  What we normally think
of as time t-1 is really the "buy time" and time t
is the "sell time".



Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of "The R Inferno" and "A Guide for the Unwilling S User")

David St John wrote:
> Dear All,
> 
> In the literature, it seems to be popular / standard to use the percentage
> change:
> d(t) = x(t)-x(t-1) / x(t-1)
> To define the 'return' of an asset being held with position s(t) as:
> r(t) = ln(1+s(t)d(t))
> 
> This is already problematic, even if s(t) takes on values of only 1, -1, 0,
> since you could be short on a day when d(t)>1.  It's especially problematic
> when s(t) is allowed to take on any real (possibly bounded, possibly
> normalized) value corresponding to a more or less leveraged / cautious
> position.
> 
> So, is there some reason why the measure:
> r(t) = ln(1+s(t)d(t))
> Is preferable to the more obvious, never undefined (for nonzero prices):
> s(t)ln(x(t)/x(t-1))
> ???
> 
> Thanks,
> -David
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
>


From mjenko at yahoo.com  Tue Nov 17 23:34:13 2009
From: mjenko at yahoo.com (Martin Jenkins)
Date: Tue, 17 Nov 2009 14:34:13 -0800 (PST)
Subject: [R-SIG-Finance] Retrieving latest day's data
In-Reply-To: <4B020FFF.6040803@cedrickjohnson.com>
Message-ID: <879120.69033.qm@web113206.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091117/6560d1dc/attachment.pl>

From jeff.a.ryan at gmail.com  Tue Nov 17 23:38:07 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 17 Nov 2009 16:38:07 -0600
Subject: [R-SIG-Finance] Retrieving latest day's data
In-Reply-To: <879120.69033.qm@web113206.mail.gq1.yahoo.com>
References: <4B020FFF.6040803@cedrickjohnson.com>
	<879120.69033.qm@web113206.mail.gq1.yahoo.com>
Message-ID: <e8e755250911171438q5ca2db79n3e070ba33cc898db@mail.gmail.com>

Hi Martin,

The 'time' in an xts or zoo object isn't part of the data per se.

index() or time() will extract for you.

write.zoo() will also output what you expect to disk

> getSymbols("AAPL")
[1] "AAPL"
> head(index(AAPL))
[1] "2007-01-03" "2007-01-04" "2007-01-05" "2007-01-08" "2007-01-09"
[6] "2007-01-10"
> head(time(AAPL))
[1] "2007-01-03" "2007-01-04" "2007-01-05" "2007-01-08" "2007-01-09"
[6] "2007-01-10"
> write.zoo(tail(AAPL))
"Index" "AAPL.Open" "AAPL.High" "AAPL.Low" "AAPL.Close" "AAPL.Volume"
"AAPL.Adjusted"
2009-11-09 196.94 201.9 196.26 201.46 18854500 201.46
2009-11-10 201.02 204.98 201.01 202.98 14315400 202.98
2009-11-11 204.56 205 201.83 203.25 15852500 203.25
2009-11-12 203.14 204.87 201.43 201.99 12990400 201.99
2009-11-13 202.87 204.83 202.07 204.45 12220200 204.45
2009-11-16 205.48 208 205.01 206.63 17216900 206.63


Best,
Jeff

On Tue, Nov 17, 2009 at 4:34 PM, Martin Jenkins <mjenko at yahoo.com> wrote:
> Hi,
>
> Thanks for the suggestions, just what I need, however just one more thing...
>
> When I use:
>
> getSymbols("AML.L", src="google")
> x <- tail(AML.L,1)
>
> I get back:
>
> ?????????? AML.L.Open AML.L.High AML.L.Low AML.L.Close AML.L.Volume
> 2009-11-17????? 385.5????? 388.9???? 381.6?????? 382.6????? 1176883
>
> All the variables above are named, apart from the date.? What I would like to do is have an if x$AML.L.Date = Sys.Date() then update my text file.? This means that I can update the historical data that I download from Yahoo in the evening, run my model and look for any buys, so I can save a day and do my research in the evening before the next morning.? Unfortunately for some reason I can't access the date, high low close open and volume are there but not date.
>
> Any help please?
>
> Thanks again,
> Martin.
>
>
>
> --- On Tue, 11/17/09, Cedrick W. Johnson <cedrick at cedrickjohnson.com> wrote:
>
> From: Cedrick W. Johnson <cedrick at cedrickjohnson.com>
> Subject: Re: [R-SIG-Finance] ?Retrieving latest day's data
> To: "Martin Jenkins" <mjenko at yahoo.com>, "R-SIG-Finance" <r-sig-finance at stat.math.ethz.ch>
> Date: Tuesday, November 17, 2009, 2:52 AM
>
> I have found that typically after the evening extended sessions finish (~8PM ET) I can get today's closing prices. I just ran this now @ 9:45P et and got my closing prices for today:
>
> ? ? ? ? ? GSPC.Open GSPC.High GSPC.Low GSPC.Close GSPC.Volume GSPC.Adjusted
> 2009-11-13???1087.59???1097.79? 1085.33? ? 1093.48? 3792610000? ? ???1093.48
> 2009-11-16???1094.13???1113.69? 1094.13? ? 1109.30? 4565850000? ? ???1109.30
>
> I see you're getting UK tickers (this is what Joshua suggested, the getQuote function in quantmod):
>> getQuote("AML.L")
> ? ? ? ? ? ? ? Trade Time? Last Change % Change Open? High???Low? Volume
> AML.L 2009-11-16 11:35:00 387.4???10.8???+2.87%? 385 395.1 375.6 3375783
>
> *edit*
>
> While composing, I thought to check using Google:
>
>> getSymbols("AML.L", src="google")
>
>> tail(AML.L,2)
> ? ? ? ? ? AML.L.Open AML.L.High AML.L.Low AML.L.Close AML.L.Volume
> 2009-11-13? ? ? 372.9? ? ? 376.9? ???368.1? ? ???376.6? ? ? 1403827
> 2009-11-16? ? ? 385.0? ? ? 395.1? ???375.6? ? ???387.4? ? ? 3375783
>
> Try that on the rest of your symbols to see what you get. Again, the time(s) that they update the closing price may be different. The same query I just did using Yahoo as a source yielded the 13th's closing price, while google is getting you what you want.
>
> HTH,
> Cedrick
>
>
> Martin Jenkins wrote:
>> Hi,
>>
>> I realise that this isn't a 100% R-SIG question and is probably a more general R question, but I think it is related, and when I sort it it is leading to an R-SIG question, so if I could ask you to bear with me.
>>
>> I'm trying to build my own trading model, to test out some strategies.? Part of this involves downloading the stcok market data and then processing it, i.e. running my model on it, using R-SIG to build graphs etc.? However using Yahoo the historical data is always one day behind.? To get around this I'm attempting to use a screen scraper utility, called PageScrape.? It's command line based, however I'm trying to use system() to call the screen scraper from within R.? The problem is that the screen scraper use regex and this causes unexpected symbol errors when I try to run it inside the system function.
>>
>> So, I can run the below inside a batch file, so can you if you download PageScraper:
>> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Day's Range:</td><td class=.yfnc_tabledata1.>[0-9]+\.[0-9]+ - ([0-9]+\.[0-9]+)</td></tr>"
>> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Day's Range:</td><td class=.yfnc_tabledata1.>([0-9]+\.[0-9]+) - [0-9]+\.[0-9]+</td></tr>"
>> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e">Last Trade:</td><td class=.yfnc_tabledata1.><big><b>([0-9]+\.[0-9]+) p"
>> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Open:</td><td class=.yfnc_tabledata1.>([0-9]+\.[0-9]+)</td></tr>"
>> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Volume:</td><td class=.yfnc_tabledata1.>([0-9]+,[0-9]+,[0-9]+)</td></tr>"
>> pause
>>
>> This is actually 4 lines, which will bring back the open, high, low and volume from the URL after -u.? The bit inside the () is what's returned.
>>
>> What I'm after is to convert this to:
>>
>> system('cmd /c "pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Day's Range:</td><td class=.yfnc_tabledata1.>[0-9]+\.[0-9]+ - ([0-9]+\.[0-9]+)</td></tr>""')
>>
>> I've tried several attempts to get it working without any success.? If anyone here can help that would be terrific, and hopefully some of you may find it useful.
>>
>> Many thanks,
>> Martin.
>>
>>
>>
>>? ? ?????? [[alternative HTML version deleted]]
>>
>>???------------------------------------------------------------------------
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From binabina at bellsouth.net  Wed Nov 18 02:13:33 2009
From: binabina at bellsouth.net (zubin)
Date: Tue, 17 Nov 2009 20:13:33 -0500
Subject: [R-SIG-Finance] Ibrokers Future API
Message-ID: <4B034A3D.5070701@bellsouth.net>

Hello, been reading on the Ibrokers package, Future API Access:   Robust
order management functions to allow for data processing trade
workflow.   Sounds great. 

Can someone let me know the status of the Future API on order
management?  Can I add some resources to help this out if needed?


From jeff.a.ryan at gmail.com  Wed Nov 18 03:07:38 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 17 Nov 2009 20:07:38 -0600
Subject: [R-SIG-Finance] Ibrokers Future API
In-Reply-To: <4B034A3D.5070701@bellsouth.net>
References: <4B034A3D.5070701@bellsouth.net>
Message-ID: <e8e755250911171807t2817789cqeb98ffbb8098d1ab@mail.gmail.com>

Zubin,

The components to execute are in place in the package, though not
exported or documented as of yet.

I gave  a presentation in Switzerland and one in Vienna regarding the
trading with R idea:

http://www.quantmod.com/Rmetrics2009/
http://www.quantmod.com/Vienna2009/

The basic calls in IBrokers/R closely follow the official API Java/etc calls.

Specifically you want to look at:

-  placeOrder [exported - no docs]

-  .placeOrder [not exported.  This sends a message, but doesn't
process the return][only in IBrokers]

-  twsOrder [exported - no docs]

The additional messages returned from the API will need to be dealt
with by the user, as I don't have a public template for that. This can
occur inside the main CALLBACK loop, as all will be properly handled
and the respective eWrapper function will be dispatched (by default
they will just discard the messages)

eWrapper.MktData.CSV is a good example of what I mean by eWrapper
'functions'. (the eWrapper objects are closures).

I will be adding more documentation in the coming weeks to help this
project along.  Feedback is always welcome.

As always, reading the source as well as the IB API source (java!) and
API docs from IB will be very helpful.

Best,
Jeff


On Tue, Nov 17, 2009 at 7:13 PM, zubin <binabina at bellsouth.net> wrote:
> Hello, been reading on the Ibrokers package, Future API Access: ? Robust
> order management functions to allow for data processing trade
> workflow. ? Sounds great.
>
> Can someone let me know the status of the Future API on order
> management? ?Can I add some resources to help this out if needed?
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From binabina at bellsouth.net  Wed Nov 18 03:19:53 2009
From: binabina at bellsouth.net (zubin)
Date: Tue, 17 Nov 2009 21:19:53 -0500
Subject: [R-SIG-Finance] Ibrokers Future API
In-Reply-To: <e8e755250911171807t2817789cqeb98ffbb8098d1ab@mail.gmail.com>
References: <4B034A3D.5070701@bellsouth.net>
	<e8e755250911171807t2817789cqeb98ffbb8098d1ab@mail.gmail.com>
Message-ID: <4B0359C9.4050502@bellsouth.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091117/c8ff7284/attachment.pl>

From matthias.kornexl at raiffeisenbank.at  Wed Nov 18 15:31:37 2009
From: matthias.kornexl at raiffeisenbank.at (matthias.kornexl at raiffeisenbank.at)
Date: Wed, 18 Nov 2009 15:31:37 +0100
Subject: [R-SIG-Finance] fSeries/fGarch for R 2.7.0
Message-ID: <OFA6CE9D35.F286E80E-ONC1257672.004E3840-C1257672.004FD0CE@mdcs.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091118/12ddcf8d/attachment.pl>

From brian at braverock.com  Wed Nov 18 15:38:08 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 18 Nov 2009 08:38:08 -0600
Subject: [R-SIG-Finance] fSeries/fGarch for R 2.7.0
In-Reply-To: <OFA6CE9D35.F286E80E-ONC1257672.004E3840-C1257672.004FD0CE@mdcs.at>
References: <OFA6CE9D35.F286E80E-ONC1257672.004E3840-C1257672.004FD0CE@mdcs.at>
Message-ID: <4B0406D0.30804@braverock.com>

matthias.kornexl at raiffeisenbank.at wrote:
> Hi everyone!
>         I am using R (Windows R 2.7.0, no newer version available because 
> of restrictions from the IT-department) to model and backtest trading 
> strategies. I was also using some Rmetrics-packages (e.g. fSeries and 
> fGarch) and everything worked fine. Now I tried to update the 
> fCalendar-package and an error occured since fCalendar uses the MASS 
> package and MASS requires R >=2.10.0 (I don't know why this error hasn't 
> occured before). Changing the fCalendar-package to the version I used 
> until now didn't help. It is not possible to get the fSeries package 
> running again. Has anyone an idea what to do to get the system running 
> again.
>
> Thanks and best regards
>
> Matthias Kornexl
>   
Older versions are available on CRAN, and I suggest that your boss or 
your bosse's boss talk to IT about removing stupid restrictions so you 
can do your job.

Regards,

  - Brian

--
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From cedrick at cedrickjohnson.com  Wed Nov 18 15:37:49 2009
From: cedrick at cedrickjohnson.com (Cedrick W. Johnson)
Date: Wed, 18 Nov 2009 09:37:49 -0500
Subject: [R-SIG-Finance] fSeries/fGarch for R 2.7.0
In-Reply-To: <OFA6CE9D35.F286E80E-ONC1257672.004E3840-C1257672.004FD0CE@mdcs.at>
References: <OFA6CE9D35.F286E80E-ONC1257672.004E3840-C1257672.004FD0CE@mdcs.at>
Message-ID: <4B0406BD.2010203@cedrickjohnson.com>

One thing I can think of is to back out fSeries to your previous version:

http://cran.r-project.org/src/contrib/Archive/fSeries/

other than that, i'm stumped. You may find a better response on the 
general R-help list as this is dealing more with package management 
rather than finance per so..

Hope this helps,
cedrikc



matthias.kornexl at raiffeisenbank.at wrote:
> Hi everyone!
>         I am using R (Windows R 2.7.0, no newer version available because 
> of restrictions from the IT-department) to model and backtest trading 
> strategies. I was also using some Rmetrics-packages (e.g. fSeries and 
> fGarch) and everything worked fine. Now I tried to update the 
> fCalendar-package and an error occured since fCalendar uses the MASS 
> package and MASS requires R >=2.10.0 (I don't know why this error hasn't 
> occured before). Changing the fCalendar-package to the version I used 
> until now didn't help. It is not possible to get the fSeries package 
> running again. Has anyone an idea what to do to get the system running 
> again.
>
> Thanks and best regards
>
> Matthias Kornexl
>
> ----------------------------------------
> Raiffeisenlandesbank Nieder??sterreich-Wien AG  -  Firmensitz Wien -  FN 203160s - HG Wien - DVR-Nummer: 0031585
>
> Der Austausch von Nachrichten mit o.a. Absender via e-mail dient ausschliesslich Informationszwecken. Rechtsgeschaeftliche Erklaerungen duerfen ueber dieses Medium nicht ausgetauscht werden.
> Correspondence with a.m. sender via e-mail is only for information purposes. This medium is not to be used for the exchange of legally-binding communications.
> ----------------------------------------
>
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From jeff.a.ryan at gmail.com  Wed Nov 18 16:04:07 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Wed, 18 Nov 2009 09:04:07 -0600
Subject: [R-SIG-Finance] fSeries/fGarch for R 2.7.0
In-Reply-To: <OFA6CE9D35.F286E80E-ONC1257672.004E3840-C1257672.004FD0CE@mdcs.at>
References: <OFA6CE9D35.F286E80E-ONC1257672.004E3840-C1257672.004FD0CE@mdcs.at>
Message-ID: <e8e755250911180704n7dda2669h2b0353deafb3d97a@mail.gmail.com>

On aside is that fCalendar and fSeries have been replaced by the
timeDate and timeSeries package.

Jeff

On Wed, Nov 18, 2009 at 8:31 AM,  <matthias.kornexl at raiffeisenbank.at> wrote:
> Hi everyone!
> ? ? ? ?I am using R (Windows R 2.7.0, no newer version available because
> of restrictions from the IT-department) to model and backtest trading
> strategies. I was also using some Rmetrics-packages (e.g. fSeries and
> fGarch) and everything worked fine. Now I tried to update the
> fCalendar-package and an error occured since fCalendar uses the MASS
> package and MASS requires R >=2.10.0 (I don't know why this error hasn't
> occured before). Changing the fCalendar-package to the version I used
> until now didn't help. It is not possible to get the fSeries package
> running again. Has anyone an idea what to do to get the system running
> again.
>
> Thanks and best regards
>
> Matthias Kornexl
>
> ----------------------------------------
> Raiffeisenlandesbank Nieder?sterreich-Wien AG ?- ?Firmensitz Wien - ?FN 203160s - HG Wien - DVR-Nummer: 0031585
>
> Der Austausch von Nachrichten mit o.a. Absender via e-mail dient ausschliesslich Informationszwecken. Rechtsgeschaeftliche Erklaerungen duerfen ueber dieses Medium nicht ausgetauscht werden.
> Correspondence with a.m. sender via e-mail is only for information purposes. This medium is not to be used for the exchange of legally-binding communications.
> ----------------------------------------
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From wobwu22 at yahoo.de  Thu Nov 19 14:55:12 2009
From: wobwu22 at yahoo.de (wob wu)
Date: Thu, 19 Nov 2009 05:55:12 -0800 (PST)
Subject: [R-SIG-Finance] Fast way of replacing missing data points in xts
	object
Message-ID: <123077.19529.qm@web23407.mail.ird.yahoo.com>

Hello,
I keep on having the same problem over and over again and couldn't find a satisfying solution yet. I have some missing datapoints in my financial time series and am replacing them currently in the following way:

for (i in 2:length(SP$Far)) {
?? ?if (is.na(SP$Far[i])) {SP$Far[i] <- as.numeric(SP$Far[i-1]) + (as.numeric(SP$Near[i])-as.numeric(SP$Near[i-1]))}
?? ?if (is.na(SP$Near[i])) {SP$Near[i] <- as.numeric(SP$Near[i-1]) + (as.numeric(SP$Far[i])-as.numeric(SP$Far[i-1]))}
?? ?if (is.na(SP$Vix[i])) {SP$Vix[i] <- as.numeric(SP$Vix[i-1])}?? ?
}

SP is a xts object.

This works fine but is slow. Does anyone knows a better solution?

Thank you

Wob

-- 
Wob Wu



__________________________________________________
Do You Yahoo!?
Sie sind
Massenmails. 
http://mail.yahoo.com


From wobwu22 at yahoo.de  Thu Nov 19 15:06:17 2009
From: wobwu22 at yahoo.de (wob wu)
Date: Thu, 19 Nov 2009 14:06:17 +0000 (GMT)
Subject: [R-SIG-Finance] Fast way of replacing missing data points in
	xts object
In-Reply-To: <4B054F95.1000604@braverock.com>
Message-ID: <686796.52137.qm@web23401.mail.ird.yahoo.com>

I am sorry if this wasn't clear enough. The interpolation isn't the problem. The logic for it is stated below. I am looking for a faster/more elegant way to execute the loop and if statements given the logic in the loop.

--- Brian G. Peterson <brian at braverock.com> schrieb am Do, 19.11.2009:

> Von: Brian G. Peterson <brian at braverock.com>
> Betreff: Re: [R-SIG-Finance] Fast way of replacing missing data points in xts object
> An: "wob wu" <wobwu22 at yahoo.de>
> Datum: Donnerstag, 19. November 2009, 15:00
> wob wu wrote:
> > Hello,
> > I keep on having the same problem over and over again
> and couldn't find a satisfying solution yet. I have some
> missing datapoints in my financial time series and am
> replacing them currently in the following way:
> > 
> > for (i in 2:length(SP$Far)) {
> >? ???if (is.na(SP$Far[i]))
> {SP$Far[i] <- as.numeric(SP$Far[i-1]) +
> (as.numeric(SP$Near[i])-as.numeric(SP$Near[i-1]))}
> >? ???if (is.na(SP$Near[i]))
> {SP$Near[i] <- as.numeric(SP$Near[i-1]) +
> (as.numeric(SP$Far[i])-as.numeric(SP$Far[i-1]))}
> >? ???if (is.na(SP$Vix[i]))
> {SP$Vix[i] <- as.numeric(SP$Vix[i-1])}? ? }
> > 
> > SP is a xts object.
> > 
> > This works fine but is slow. Does anyone knows a
> better solution?
> >???
> See the list archives and the large variety of na
> interpolation actions in zoo.? They will work fine on
> your xts object.
> 
> ???- Brian
> 
> -- Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
> 
> 
> 





From brian at braverock.com  Thu Nov 19 15:19:45 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 19 Nov 2009 08:19:45 -0600
Subject: [R-SIG-Finance] Fast way of replacing missing data points in
 xts object
In-Reply-To: <686796.52137.qm@web23401.mail.ird.yahoo.com>
References: <686796.52137.qm@web23401.mail.ird.yahoo.com>
Message-ID: <4B055401.8090003@braverock.com>

I looks like with the Near and Far series you're doing linear 
interpolation, and with the VIX series you're doing  locf  interpolation.

Even if my glance at your code is incorrect, studying the way in which 
the na interpolation functions are implemented in zoo is likely to be 
your best way of improving your own code.

wob wu wrote:
> I am sorry if this wasn't clear enough. The interpolation isn't the problem. The logic for it is stated below. I am looking for a faster/more elegant way to execute the loop and if statements given the logic in the loop.
>
> --- Brian G. Peterson <brian at braverock.com> schrieb am Do, 19.11.2009:
>
>   
>> Von: Brian G. Peterson <brian at braverock.com>
>> Betreff: Re: [R-SIG-Finance] Fast way of replacing missing data points in xts object
>> An: "wob wu" <wobwu22 at yahoo.de>
>> Datum: Donnerstag, 19. November 2009, 15:00
>> wob wu wrote:
>>     
>>> Hello,
>>> I keep on having the same problem over and over again
>>>       
>> and couldn't find a satisfying solution yet. I have some
>> missing datapoints in my financial time series and am
>> replacing them currently in the following way:
>>     
>>> for (i in 2:length(SP$Far)) {
>>>      if (is.na(SP$Far[i]))
>>>       
>> {SP$Far[i] <- as.numeric(SP$Far[i-1]) +
>> (as.numeric(SP$Near[i])-as.numeric(SP$Near[i-1]))}
>>     
>>>      if (is.na(SP$Near[i]))
>>>       
>> {SP$Near[i] <- as.numeric(SP$Near[i-1]) +
>> (as.numeric(SP$Far[i])-as.numeric(SP$Far[i-1]))}
>>     
>>>      if (is.na(SP$Vix[i]))
>>>       
>> {SP$Vix[i] <- as.numeric(SP$Vix[i-1])}    }
>>     
>>> SP is a xts object.
>>>
>>> This works fine but is slow. Does anyone knows a
>>>       
>> better solution?
>>     
>>>    
>>>       
>> See the list archives and the large variety of na
>> interpolation actions in zoo.  They will work fine on
>> your xts object.
>>
>>    - Brian
>>
>> -- Brian G. Peterson
>> http://braverock.com/brian/
>> Ph: 773-459-4973
>> IM: bgpbraverock
>>
>>
>>
>>     
>
>
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>   


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From rechtsteiner at bgki.net  Thu Nov 19 15:32:41 2009
From: rechtsteiner at bgki.net (Josuah Rechtsteiner)
Date: Thu, 19 Nov 2009 15:32:41 +0100
Subject: [R-SIG-Finance] Add values to time series in DB directly
Message-ID: <E5BB21E7-F714-4FB0-B5CF-F2EAFD1D838A@bgki.net>

Dear members of the mighty list,

I have a PostgreSQL DB as storage for some time series. I access the  
DB from within R with TSPostgresql/TSdbi. Today I asked myself if it  
is possible to update an existing TS in the DB with new data points  
without having to load the whole time series into R first and then  
replacing it in the DB.
I tried

TSreplace(x, con, append=TRUE)

but this did not work. After reading the vignettes and manuals of the  
packages in use here without success, I thought I should probably  
conjure up the mighty list...

Best,

Josuah


From armstrong.whit at gmail.com  Thu Nov 19 15:52:30 2009
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Thu, 19 Nov 2009 09:52:30 -0500
Subject: [R-SIG-Finance] Add values to time series in DB directly
In-Reply-To: <E5BB21E7-F714-4FB0-B5CF-F2EAFD1D838A@bgki.net>
References: <E5BB21E7-F714-4FB0-B5CF-F2EAFD1D838A@bgki.net>
Message-ID: <8ec76080911190652l2d7a69b7wf3c3e37ed8697c5d@mail.gmail.com>

just append the new data to the table.  as long as you have a way of
subsetting just the new rows, this should be easy.  I haven't used
TSdbi, but I have a postgres package that uses binary write, so it's
pretty fast.  http://github.com/armstrtw/unifieddbi

-Whit


On Thu, Nov 19, 2009 at 9:32 AM, Josuah Rechtsteiner
<rechtsteiner at bgki.net> wrote:
> Dear members of the mighty list,
>
> I have a PostgreSQL DB as storage for some time series. I access the DB from
> within R with TSPostgresql/TSdbi. Today I asked myself if it is possible to
> update an existing TS in the DB with new data points without having to load
> the whole time series into R first and then replacing it in the DB.
> I tried
>
> TSreplace(x, con, append=TRUE)
>
> but this did not work. After reading the vignettes and manuals of the
> packages in use here without success, I thought I should probably conjure up
> the mighty list...
>
> Best,
>
> Josuah
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From sandor.benczik at crabel.ro  Thu Nov 19 18:25:03 2009
From: sandor.benczik at crabel.ro (Benczik Sandor)
Date: Thu, 19 Nov 2009 19:25:03 +0200
Subject: [R-SIG-Finance] Fast way of replacing missing data points
	in	xts object
In-Reply-To: <686796.52137.qm@web23401.mail.ird.yahoo.com>
References: <686796.52137.qm@web23401.mail.ird.yahoo.com>
Message-ID: <1258651503.3341.23.camel@localhost.localdomain>

For the first one try something along the lines:

replacement.far <- lag(SP$Far) + SP$Near - lag(SP$Near)
SP$Far[is.na(SP$Far)] <- replacement.far[is.na(SP$Far)]

The last one is simple locf as Brian said. 

HTH,
Sandor


On Thu, 2009-11-19 at 14:06 +0000, wob wu wrote:
> I am sorry if this wasn't clear enough. The interpolation isn't the problem. The logic for it is stated below. I am looking for a faster/more elegant way to execute the loop and if statements given the logic in the loop.
> 
> --- Brian G. Peterson <brian at braverock.com> schrieb am Do, 19.11.2009:
> 
> > Von: Brian G. Peterson <brian at braverock.com>
> > Betreff: Re: [R-SIG-Finance] Fast way of replacing missing data points in xts object
> > An: "wob wu" <wobwu22 at yahoo.de>
> > Datum: Donnerstag, 19. November 2009, 15:00
> > wob wu wrote:
> > > Hello,
> > > I keep on having the same problem over and over again
> > and couldn't find a satisfying solution yet. I have some
> > missing datapoints in my financial time series and am
> > replacing them currently in the following way:
> > > 
> > > for (i in 2:length(SP$Far)) {
> > >     if (is.na(SP$Far[i]))
> > {SP$Far[i] <- as.numeric(SP$Far[i-1]) +
> > (as.numeric(SP$Near[i])-as.numeric(SP$Near[i-1]))}
> > >     if (is.na(SP$Near[i]))
> > {SP$Near[i] <- as.numeric(SP$Near[i-1]) +
> > (as.numeric(SP$Far[i])-as.numeric(SP$Far[i-1]))}
> > >     if (is.na(SP$Vix[i]))
> > {SP$Vix[i] <- as.numeric(SP$Vix[i-1])}    }
> > > 
> > > SP is a xts object.
> > > 
> > > This works fine but is slow. Does anyone knows a
> > better solution?
> > >   
> > See the list archives and the large variety of na
> > interpolation actions in zoo.  They will work fine on
> > your xts object.
> > 
> >    - Brian
> > 
> > -- Brian G. Peterson
> > http://braverock.com/brian/
> > Ph: 773-459-4973
> > IM: bgpbraverock
> > 
> > 
> > 
> 
> 
> 
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From kabonline07 at yahoo.com  Thu Nov 19 18:28:23 2009
From: kabonline07 at yahoo.com (KAUSHIK BHATTACHARJEE)
Date: Thu, 19 Nov 2009 09:28:23 -0800 (PST)
Subject: [R-SIG-Finance] problems in GJR-GARCH with t-disrtibuted error
	terms in SAS
Message-ID: <516421.14174.qm@web110012.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091119/e9612317/attachment.pl>

From jeff.a.ryan at gmail.com  Thu Nov 19 19:06:51 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Thu, 19 Nov 2009 12:06:51 -0600
Subject: [R-SIG-Finance] problems in GJR-GARCH with t-disrtibuted error
	terms in SAS
In-Reply-To: <516421.14174.qm@web110012.mail.gq1.yahoo.com>
References: <516421.14174.qm@web110012.mail.gq1.yahoo.com>
Message-ID: <e8e755250911191006k2d8cf441m60a4b0dccb4c76ce@mail.gmail.com>

For R ... via google...

https://stat.ethz.ch/pipermail/r-help/2008-April/158763.html

And SAS questions don't belong on an R list. About as off-topic as on
could conceive.

Jeff

On Thu, Nov 19, 2009 at 11:28 AM, KAUSHIK BHATTACHARJEE
<kabonline07 at yahoo.com> wrote:
> Actually I am trying to fit an asymetric GARCH model in SAS ..and finding problems...I want to discuss..but I know this is a forum for R.?so ?any erstwhile sas-expert...whom I can talk to?
>
>
>
> Kaushik Bhattacharjee
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From neil.gup at gmail.com  Thu Nov 19 19:07:32 2009
From: neil.gup at gmail.com (Neil Gupta)
Date: Thu, 19 Nov 2009 12:07:32 -0600
Subject: [R-SIG-Finance] Interfacing R and LIM
Message-ID: <a51fe2df0911191007j734f9803w479fe6b6fab8da4f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091119/a45da6b6/attachment.pl>

From armstrong.whit at gmail.com  Thu Nov 19 19:27:09 2009
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Thu, 19 Nov 2009 13:27:09 -0500
Subject: [R-SIG-Finance] Interfacing R and LIM
In-Reply-To: <a51fe2df0911191007j734f9803w479fe6b6fab8da4f@mail.gmail.com>
References: <a51fe2df0911191007j734f9803w479fe6b6fab8da4f@mail.gmail.com>
Message-ID: <8ec76080911191027h2d6ef7cexa62c1301ee7d134b@mail.gmail.com>

here is my package:
http://github.com/armstrtw/rlim

there is a separate c++/tslib interface to lim here:
http://github.com/armstrtw/lim.tslib

if you don't have git, then you might have some trouble pulling in all
the pieces to RLIM as it uses git submodules for the supporting c++
libs.  ping me if you need help.

-Whit



On Thu, Nov 19, 2009 at 1:07 PM, Neil Gupta <neil.gup at gmail.com> wrote:
> Are there any R-LIM users out there. Is there a simple approach to interface
> the two?
>
> I have read through a presentation by Mr. Eddelbuttel on connecting R to Lim
> here:
> http://dirk.eddelbuettel.com/papers/r_lim_bloomberg.pdf
>
> Many Thanks.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From edd at debian.org  Thu Nov 19 19:38:54 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 19 Nov 2009 12:38:54 -0600
Subject: [R-SIG-Finance] Interfacing R and LIM
In-Reply-To: <a51fe2df0911191007j734f9803w479fe6b6fab8da4f@mail.gmail.com>
References: <a51fe2df0911191007j734f9803w479fe6b6fab8da4f@mail.gmail.com>
Message-ID: <19205.37054.136625.322737@ron.nulle.part>


On 19 November 2009 at 12:07, Neil Gupta wrote:
| Are there any R-LIM users out there. Is there a simple approach to interface
| the two?
| 
| I have read through a presentation by Mr. Eddelbuttel on connecting R to Lim

[ i)  As I usually joke, please use Dr Eddelbuettel if you require a long
      form, or just stick with Dirk which is so much simpler
  
  ii) You dropped the Umlaut-transcribed-to-7-bit e between u and tt so
      that's not even my name. ]
 
| here:
| http://dirk.eddelbuettel.com/papers/r_lim_bloomberg.pdf

That was never released as my (then) employer had yet not grasped the
benefits of Open Source.  I think they do a little better now.

However, Whit Armstrong rewrote a similar package which you can find on its
github page at 

       http://github.com/armstrtw/rlim

Hope this helps,  Dirk

-- 
Three out of two people have difficulties with fractions.


From fxongoing at hotmail.com  Sun Nov 22 05:18:02 2009
From: fxongoing at hotmail.com (FX Going)
Date: Sat, 21 Nov 2009 22:18:02 -0600
Subject: [R-SIG-Finance] How can I retrieve list of all companies listed of
 a given Index say S&P 500
Message-ID: <COL105-W14B6AD95C5EB4253072F3DB89F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091121/ad6be300/attachment.pl>

From fxongoing at hotmail.com  Sun Nov 22 06:29:39 2009
From: fxongoing at hotmail.com (FX Going)
Date: Sat, 21 Nov 2009 23:29:39 -0600
Subject: [R-SIG-Finance] How can I retrieve list of all companies listed
 of a given Index say S&P 500
In-Reply-To: <COL105-W14B6AD95C5EB4253072F3DB89F0@phx.gbl>
References: <COL105-W14B6AD95C5EB4253072F3DB89F0@phx.gbl>
Message-ID: <COL105-W28E83D796E64156518CE16B89F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091121/69b9a7e5/attachment.pl>

From edd at debian.org  Sun Nov 22 10:22:53 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 22 Nov 2009 03:22:53 -0600
Subject: [R-SIG-Finance] How can I retrieve list of all companies listed
 of a given Index say S&P 500
In-Reply-To: <COL105-W14B6AD95C5EB4253072F3DB89F0@phx.gbl>
References: <COL105-W14B6AD95C5EB4253072F3DB89F0@phx.gbl>
Message-ID: <19209.749.713242.787656@ron.nulle.part>


On 21 November 2009 at 22:18, FX Going wrote:
| Hey Folks,I understand I could grab list of all companies listed on S&P 500 from wikipedia http://en.wikipedia.org/wiki/List_of_S&P_500_companies 
| However what I am looking for is a function whose input is a User specified an Index {better yet, a list of indexes}..For each of the index, The function should be able to retrieve companies listed on that index alongwith their symbols  and dump into a flat file/database.. 
| Is there a function in R metrics or fImport You know  that can do the same.. If not , no problem, I guess I will write a function :-)..but before putting the effort just wanted to check if one already exists then I could use it.Thanksfoxonie.    		 	   		  

I don't think there is a function that does it for you given just an index
name. But starting with csv file for the SP500, I did exactly what you
describe for a little demo: loop over the symbols, and fetch the data with
one of the many data downloaders available for R.  As of mid-November, the
SP500 had 477 constituents ...

On 21 November 2009 at 23:29, FX Going wrote:
| My related question is.I am trying to download a list of stocks that meet specific criteria (say download all  penny stocks listed on all indexes).. Is there an easy way to do the same.Thanksfoxonie

Same thing: at some point you may have to start to do your own homework.

Hope this helps, Dirk

-- 
Three out of two people have difficulties with fractions.


From mjenko at yahoo.com  Sun Nov 22 15:49:18 2009
From: mjenko at yahoo.com (Martin Jenkins)
Date: Sun, 22 Nov 2009 06:49:18 -0800 (PST)
Subject: [R-SIG-Finance] How can I retrieve list of all companies listed
	of a given Index say S&P 500
In-Reply-To: <COL105-W14B6AD95C5EB4253072F3DB89F0@phx.gbl>
Message-ID: <331590.76195.qm@web113215.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091122/8c34f8a7/attachment.pl>

From artk at congruent.com  Mon Nov 23 01:44:48 2009
From: artk at congruent.com (Arthur Kreitman)
Date: Sun, 22 Nov 2009 16:44:48 -0800
Subject: [R-SIG-Finance] How can I retrieve list of all companies
	listed	of a given Index say S&P 500
In-Reply-To: <331590.76195.qm@web113215.mail.gq1.yahoo.com>
References: <COL105-W14B6AD95C5EB4253072F3DB89F0@phx.gbl>
	<331590.76195.qm@web113215.mail.gq1.yahoo.com>
Message-ID: <8DB8983924798A41B27C1E76AA913FE813281C7F36@EXVMBX020-11.exch020.serverdata.net>

I don't think that the S&P component list is conveniently available.  And you need more then the list, you also need the weighting.

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Martin Jenkins
Sent: Sunday, November 22, 2009 9:49 AM
To: r-sig-finance at stat.math.ethz.ch; FX Going
Subject: Re: [R-SIG-Finance] How can I retrieve list of all companies listed of a given Index say S&P 500

Hi,

Is something like this what you're after:

download.file("http://uk.old.finance.yahoo.com/d/quotes.csv?s=@%5EFTAI&f=sl1d1t1c1ohgv&e=.csv","C:/Users/Admin/Documents/AIM.csv" , "auto", quiet = FALSE, mode = "w", cacheOK = TRUE)

dledStocks=read.table("C:/Users/Admin/Documents/AIM.csv", header=FALSE, sep=",")

This will download the AIM list in the U.K., go to Yahoo any find the S&P500 list and do the same thing, then you can put the list into a table and do your analysis on it.



--- On Sun, 11/22/09, FX Going <fxongoing at hotmail.com> wrote:

From: FX Going <fxongoing at hotmail.com>
Subject: [R-SIG-Finance] How can I retrieve list of all companies listed of a given Index say S&P 500
To: r-sig-finance at stat.math.ethz.ch
Date: Sunday, November 22, 2009, 4:18 AM


Hey Folks,I understand I could grab list of all companies listed on S&P 500 from wikipedia http://en.wikipedia.org/wiki/List_of_S&P_500_companies
However what I am looking for is a function whose input is a User specified an Index {better yet, a list of indexes}..For each of the index, The function should be able to retrieve companies listed on that index alongwith their symbols? and dump into a flat file/database.. 
Is there a function in R metrics or fImport You know? that can do the same.. If not , no problem, I guess I will write a function :-)..but before putting the effort just wanted to check if one already exists then I could use it.Thanksfoxonie. _________________________________________________________________


ID24727::T:WLMTAGL:ON:WL:en-US:WWL_WIN_myidea:112009
??? [[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.



      
	[[alternative HTML version deleted]]


From edd at debian.org  Mon Nov 23 10:30:44 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 23 Nov 2009 03:30:44 -0600
Subject: [R-SIG-Finance] How can I retrieve list of all
	companies	listed	of a given Index say S&P 500
In-Reply-To: <8DB8983924798A41B27C1E76AA913FE813281C7F36@EXVMBX020-11.exch020.serverdata.net>
References: <COL105-W14B6AD95C5EB4253072F3DB89F0@phx.gbl>
	<331590.76195.qm@web113215.mail.gq1.yahoo.com>
	<8DB8983924798A41B27C1E76AA913FE813281C7F36@EXVMBX020-11.exch020.serverdata.net>
Message-ID: <19210.22084.793166.254688@ron.nulle.part>


On 22 November 2009 at 16:44, Arthur Kreitman wrote:
| I don't think that the S&P component list is conveniently available.  And
| you need more then the list, you also need the weighting.

I am travelling and am away from the machine on which I did this, but IIRC
the SP500 spreadsheet (in convenient csv format) contains not only the index
components but s also their industry code, weightings etc

I followed a link from the Wikipedia followed by maybe one or tow searches on
the SP site. It really was pretty straightforward.

Hope this helps, Dirk

-- 
Three out of two people have difficulties with fractions.


From kschriek at gmail.com  Mon Nov 23 14:06:27 2009
From: kschriek at gmail.com (Karl Schriek)
Date: Mon, 23 Nov 2009 15:06:27 +0200
Subject: [R-SIG-Finance] R: Use VAR model to predict response to change in
	values of certain variables
Message-ID: <88394bdb0911230506p1eff240u8b650d62f289b57f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091123/fad8231c/attachment.pl>

From matthieu.stigler at gmail.com  Mon Nov 23 14:46:44 2009
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Mon, 23 Nov 2009 14:46:44 +0100
Subject: [R-SIG-Finance] R: Use VAR model to predict response to change
	in values of certain variables
In-Reply-To: <88394bdb0911230506p1eff240u8b650d62f289b57f@mail.gmail.com>
References: <88394bdb0911230506p1eff240u8b650d62f289b57f@mail.gmail.com>
Message-ID: <111060c20911230546i6a79c6b5u964e802ab68dc4e4@mail.gmail.com>

Hi Karl

Please provide reproducible code when you ask questions, we don't have
access to your local drive!!
So use rather datasets in R, as for example:
data(Canada)
colnames(Canada)
 var.2c <- VAR(Canada, p = 1, type = "none")

You will note that there is a predict.varest function which does forecasts:
     pred<-predict(var.2c, n.ahead = 8, ci = 0.95)

This is not exactly what you want... you want to change some
forecasted values, and see the influence, right? This is not available
i the predict.varest. You will need to do some manipulations,
basically extracting the lm object and using predict(lm, newdata)


Construct data frame with forecasted values. It should include all
variables you see when in the output of var.2c. To keep simple, I used
the simplest model (1 lag, no intercept), so need only to give 4
values (the lag-1). For the example, I took last dat of data Canada,
change as you want:
:
yourPred<-as.data.frame(matrix(Canada[nrow(Canada),], nrow=1))
colnames(yourPred)<-colnames(model.frame(var.2c$varresult$e))[-1] #you
need to give same names as in var result!

predict(var.2c$varresult$e, newdata=yourPred)

Note that this is exactly the same as what does forecast.varest,
except you can now change it manually!

pred$fcst$e[1,1]

And now you can change the values in yourPred as you want.

Hope this helps

Mat

2009/11/23 Karl Schriek <kschriek at gmail.com>:
> Hi
>
> I've fitted a VECM model in R, and converted in to a VAR representation. I
> would like to use this model to predict the future value of a response
> variable based on different scenarios for the explanatory variables.
>
> Here is the code for the model:
>
> library(urca)
> library(vars)
>
> input <-read.csv("data.csv")
> ts <- ts(input[16:52,],c(2000,1),frequency=4)
> dat1 <- cbind(ts[,"dx"], ts[,"u"], ts[,"cci"],ts[,"bci"],ts[,"cpi"],ts[,"gdp"])
>
> args('ca.jo')
> vecm <- ca.jo(dat1, type = 'trace', K = 2, season =
> NULL,spec="longrun",dumvar=NULL)
> vecm.var <- vec2var(vecm,r=2)
>
> Now what I would like do is to predict "dx" into the future by varying the
> others. I am not sure if something like "predict dx if
> u=30,cpi=15,bci=50,gdp=..." in the next period would work. So what I have in
> mind is something along the lines of: increase "u" by 15% in the next period
> (which would obviously impact on all the other variables as well, including
> "dx") and predict the impact into the future.
>
> Also, I am not sure if the "vec2var" step is necessary, so please ignore it
> if you think it is redundant.
>
> Thanks
> Karl
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From Murali.MENON at fortisinvestments.com  Mon Nov 23 16:25:48 2009
From: Murali.MENON at fortisinvestments.com (Murali.MENON at fortisinvestments.com)
Date: Mon, 23 Nov 2009 16:25:48 +0100
Subject: [R-SIG-Finance] row-by-row operations on multiple xts matrices
Message-ID: <5A3D018CBDC36B4F8FF6DB52DDF3B82D01719F54@BE-S0500-V22.adroot.local>

Folks,
 
If I have two xts objects with some dates in common, and I want to
compute, say, the sum of products of their corresponding rows,
what is a good way of achieving it?
 
> a <- xts(matrix(1:10,ncol=2), as.Date(1:5))
> b <- xts(matrix(11:20,ncol=2), as.Date(2:6))
 
Were these matrices, I could just do something like (inefficiently):
 
> diag(a %*% t(b))
 
but that doesn't work here, because the transpose t() function removes
the xts-ness of b, and the multiplication occurs row-by-row
without date correspondence.
 
Is there a better way to achieve this than:
 
# First extract common indices
> aa <- a[index(a) %in% index(b)]
> bb <- b[index(b) %in% index(a)]

# Then use the common index to construct a new xts object
> xts(diag(aa %*% t(bb)), index(aa))
 
           [,1]
1970-01-03  134
1970-01-04  172
1970-01-05  214
1970-01-06  260

I think there's something obvious I'm missing... 

Thanks,
 
Murali


From josh.m.ulrich at gmail.com  Mon Nov 23 16:33:51 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 23 Nov 2009 09:33:51 -0600
Subject: [R-SIG-Finance] row-by-row operations on multiple xts matrices
In-Reply-To: <5A3D018CBDC36B4F8FF6DB52DDF3B82D01719F54@BE-S0500-V22.adroot.local>
References: <5A3D018CBDC36B4F8FF6DB52DDF3B82D01719F54@BE-S0500-V22.adroot.local>
Message-ID: <8cca69990911230733t4c011e73h5e152dc8b931ae99@mail.gmail.com>

Murali,

Try:
> x <- a*b
> (y <- xts(rowSums(x),index(x)))
           [,1]
1970-01-03  134
1970-01-04  172
1970-01-05  214
1970-01-06  260

HTH,
Josh
--
http://www.fosstrading.com



On Mon, Nov 23, 2009 at 9:25 AM,  <Murali.MENON at fortisinvestments.com> wrote:
> Folks,
>
> If I have two xts objects with some dates in common, and I want to
> compute, say, the sum of products of their corresponding rows,
> what is a good way of achieving it?
>
>> a <- xts(matrix(1:10,ncol=2), as.Date(1:5))
>> b <- xts(matrix(11:20,ncol=2), as.Date(2:6))
>
> Were these matrices, I could just do something like (inefficiently):
>
>> diag(a %*% t(b))
>
> but that doesn't work here, because the transpose t() function removes
> the xts-ness of b, and the multiplication occurs row-by-row
> without date correspondence.
>
> Is there a better way to achieve this than:
>
> # First extract common indices
>> aa <- a[index(a) %in% index(b)]
>> bb <- b[index(b) %in% index(a)]
>
> # Then use the common index to construct a new xts object
>> xts(diag(aa %*% t(bb)), index(aa))
>
> ? ? ? ? ? [,1]
> 1970-01-03 ?134
> 1970-01-04 ?172
> 1970-01-05 ?214
> 1970-01-06 ?260
>
> I think there's something obvious I'm missing...
>
> Thanks,
>
> Murali
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From Murali.MENON at fortisinvestments.com  Mon Nov 23 16:41:30 2009
From: Murali.MENON at fortisinvestments.com (Murali.MENON at fortisinvestments.com)
Date: Mon, 23 Nov 2009 16:41:30 +0100
Subject: [R-SIG-Finance] row-by-row operations on multiple xts matrices
In-Reply-To: <8cca69990911230733t4c011e73h5e152dc8b931ae99@mail.gmail.com>
References: <5A3D018CBDC36B4F8FF6DB52DDF3B82D01719F54@BE-S0500-V22.adroot.local>
	<8cca69990911230733t4c011e73h5e152dc8b931ae99@mail.gmail.com>
Message-ID: <5A3D018CBDC36B4F8FF6DB52DDF3B82D01719F6B@BE-S0500-V22.adroot.local>

Thanks, Josh. rowSums! So clear and, suddenly, so obvious.
I really need a vacation...
Murali 

-----Original Message-----
From: Joshua Ulrich [mailto:josh.m.ulrich at gmail.com] 
Sent: 23 November 2009 15:34
To: MENON Murali
Cc: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] row-by-row operations on multiple xts matrices

Murali,

Try:
> x <- a*b
> (y <- xts(rowSums(x),index(x)))
           [,1]
1970-01-03  134
1970-01-04  172
1970-01-05  214
1970-01-06  260

HTH,
Josh
--
http://www.fosstrading.com



On Mon, Nov 23, 2009 at 9:25 AM,  <Murali.MENON at fortisinvestments.com> wrote:
> Folks,
>
> If I have two xts objects with some dates in common, and I want to 
> compute, say, the sum of products of their corresponding rows, what is 
> a good way of achieving it?
>
>> a <- xts(matrix(1:10,ncol=2), as.Date(1:5)) b <- 
>> xts(matrix(11:20,ncol=2), as.Date(2:6))
>
> Were these matrices, I could just do something like (inefficiently):
>
>> diag(a %*% t(b))
>
> but that doesn't work here, because the transpose t() function removes 
> the xts-ness of b, and the multiplication occurs row-by-row without 
> date correspondence.
>
> Is there a better way to achieve this than:
>
> # First extract common indices
>> aa <- a[index(a) %in% index(b)]
>> bb <- b[index(b) %in% index(a)]
>
> # Then use the common index to construct a new xts object
>> xts(diag(aa %*% t(bb)), index(aa))
>
> ? ? ? ? ? [,1]
> 1970-01-03 ?134
> 1970-01-04 ?172
> 1970-01-05 ?214
> 1970-01-06 ?260
>
> I think there's something obvious I'm missing...
>
> Thanks,
>
> Murali
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From jeff.a.ryan at gmail.com  Mon Nov 23 17:27:10 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 23 Nov 2009 10:27:10 -0600
Subject: [R-SIG-Finance] How can I retrieve list of all companies listed
	of a given Index say S&P 500
In-Reply-To: <19210.22084.793166.254688@ron.nulle.part>
References: <COL105-W14B6AD95C5EB4253072F3DB89F0@phx.gbl>
	<331590.76195.qm@web113215.mail.gq1.yahoo.com>
	<8DB8983924798A41B27C1E76AA913FE813281C7F36@EXVMBX020-11.exch020.serverdata.net>
	<19210.22084.793166.254688@ron.nulle.part>
Message-ID: <e8e755250911230827o1db0210dvf9c638b1a76c1d50@mail.gmail.com>

I think careful digging will get you most of the information you want.

Bundling it up and distributing the tools are another story.  S&P 500
is the IP of Standard & Poor's.

http://www.standardandpoors.com/indices/index-licensing/en/us

In addition, the index itself isn't static, you would need a
time-series of index changes, which isn't readily available for free
(AFAIK).

If you are just looking to get a daily snapshot of the current
components, you can take the list scraped from Wikipedia and use the
getQuote function in quantmod to get the data from yahoo rather
quickly (200 symbol max per request).

Best,
Jeff

On Mon, Nov 23, 2009 at 3:30 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 22 November 2009 at 16:44, Arthur Kreitman wrote:
> | I don't think that the S&P component list is conveniently available. ?And
> | you need more then the list, you also need the weighting.
>
> I am travelling and am away from the machine on which I did this, but IIRC
> the SP500 spreadsheet (in convenient csv format) contains not only the index
> components but s also their industry code, weightings etc
>
> I followed a link from the Wikipedia followed by maybe one or tow searches on
> the SP site. It really was pretty straightforward.
>
> Hope this helps, Dirk
>
> --
> Three out of two people have difficulties with fractions.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From psmennie at yahoo.co.uk  Mon Nov 23 18:30:24 2009
From: psmennie at yahoo.co.uk (Peter Mennie)
Date: Mon, 23 Nov 2009 17:30:24 +0000 (GMT)
Subject: [R-SIG-Finance] How good is Black-Scholes vs actual option prices
Message-ID: <929455.48091.qm@web25505.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091123/18edfd9b/attachment.pl>

From jmbraun at gmail.com  Mon Nov 23 23:10:33 2009
From: jmbraun at gmail.com (Jeff Braun)
Date: Mon, 23 Nov 2009 17:10:33 -0500
Subject: [R-SIG-Finance] Estimating BEKK model with the mgarch package
Message-ID: <38562380911231410l5fa7f8a3q1f4d1bf3babc1417@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091123/d24bc3cb/attachment.pl>

From kschriek at gmail.com  Tue Nov 24 09:56:12 2009
From: kschriek at gmail.com (Karl Schriek)
Date: Tue, 24 Nov 2009 10:56:12 +0200
Subject: [R-SIG-Finance] Interpreting impluse response coefficients
Message-ID: <88394bdb0911240056v758f3974xb37780276c5fe280@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091124/083a373a/attachment.pl>

From kschriek at gmail.com  Tue Nov 24 10:00:08 2009
From: kschriek at gmail.com (Karl Schriek)
Date: Tue, 24 Nov 2009 11:00:08 +0200
Subject: [R-SIG-Finance] Fwd: Interpreting impluse response coefficients
In-Reply-To: <88394bdb0911240056v758f3974xb37780276c5fe280@mail.gmail.com>
References: <88394bdb0911240056v758f3974xb37780276c5fe280@mail.gmail.com>
Message-ID: <88394bdb0911240100p6f4eef38xa2999ada40a2624e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091124/160f3c36/attachment.pl>

From kschriek at gmail.com  Tue Nov 24 11:21:57 2009
From: kschriek at gmail.com (Karl Schriek)
Date: Tue, 24 Nov 2009 12:21:57 +0200
Subject: [R-SIG-Finance] R: Use VAR model to predict response to change
	in values of certain variables
In-Reply-To: <88394bdb0911240132s304f1a47h9ec39b58c51cef74@mail.gmail.com>
References: <88394bdb0911230506p1eff240u8b650d62f289b57f@mail.gmail.com>
	<111060c20911230546i6a79c6b5u964e802ab68dc4e4@mail.gmail.com>
	<88394bdb0911240132s304f1a47h9ec39b58c51cef74@mail.gmail.com>
Message-ID: <88394bdb0911240221y6d97fdb1ya264dab88e2c1cf4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091124/bb1c04d1/attachment.pl>

From matthieu.stigler at gmail.com  Tue Nov 24 13:23:44 2009
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Tue, 24 Nov 2009 13:23:44 +0100
Subject: [R-SIG-Finance] R: Use VAR model to predict response to change
	in values of certain variables
In-Reply-To: <88394bdb0911240221y6d97fdb1ya264dab88e2c1cf4@mail.gmail.com>
References: <88394bdb0911230506p1eff240u8b650d62f289b57f@mail.gmail.com>
	<111060c20911230546i6a79c6b5u964e802ab68dc4e4@mail.gmail.com>
	<88394bdb0911240132s304f1a47h9ec39b58c51cef74@mail.gmail.com>
	<88394bdb0911240221y6d97fdb1ya264dab88e2c1cf4@mail.gmail.com>
Message-ID: <111060c20911240423hd5c4e20ud4d887c4baeb7bfc@mail.gmail.com>

Same remark as before, please provide reproducible code!!

Ok, sorry, showed only the case for var, not vec2var. Well it is more
complicated as there is no corresponding lm object.
(reason is the var in level you obtain is estimated under constraint
of cointegration, so estimating yourself with usual lm won't lead to
same results).

So what you do is simply extract the coef and mutliply with your
predicted values, something like (using again last value, so can see
it's same as using predict):
data(Canada)
sjf.vecm <- ca.jo(Canada, ecdet = "none", type = "eigen", K = 2,spec =
"longrun")
converted<-   vec2var(sjf.vecm, r = 1)

coefe<-c( converted$A$A1[1,], converted$deterministic[1],converted$A$A2[1,])
predval<-converted$datamat[nrow(converted$datamat),c(1:9)]
coefe%*%predval
predict(converted, n.ahead=1)

Hope this helps

Mat


2009/11/24 Karl Schriek <kschriek at gmail.com>:
> Hi Mat
>
> Yes, this is exactly what I would like to do. Only problem this that I
> generate the model using VECM and and then convert to VAR form using
> vec2var. (i.e. the object is of type vec2var, not varest)
>
> I am not sure how to extract the lm from vec2var.
>
>
> Karl
>
>
> On Mon, Nov 23, 2009 at 3:46 PM, Matthieu Stigler <
> matthieu.stigler at gmail.com> wrote:
>
>> Hi Karl
>>
>> Please provide reproducible code when you ask questions, we don't have
>> access to your local drive!!
>> So use rather datasets in R, as for example:
>> data(Canada)
>> colnames(Canada)
>> ?var.2c <- VAR(Canada, p = 1, type = "none")
>>
>> You will note that there is a predict.varest function which does forecasts:
>> ? ? pred<-predict(var.2c, n.ahead = 8, ci = 0.95)
>>
>> This is not exactly what you want... you want to change some
>> forecasted values, and see the influence, right? This is not available
>> i the predict.varest. You will need to do some manipulations,
>> basically extracting the lm object and using predict(lm, newdata)
>>
>>
>> Construct data frame with forecasted values. It should include all
>> variables you see when in the output of var.2c. To keep simple, I used
>> the simplest model (1 lag, no intercept), so need only to give 4
>> values (the lag-1). For the example, I took last dat of data Canada,
>> change as you want:
>> :
>> yourPred<-as.data.frame(matrix(Canada[nrow(Canada),], nrow=1))
>> colnames(yourPred)<-colnames(model.frame(var.2c$varresult$e))[-1] #you
>> need to give same names as in var result!
>>
>> predict(var.2c$varresult$e, newdata=yourPred)
>>
>> Note that this is exactly the same as what does forecast.varest,
>> except you can now change it manually!
>>
>> pred$fcst$e[1,1]
>>
>> And now you can change the values in yourPred as you want.
>>
>> Hope this helps
>>
>> Mat
>>
>> 2009/11/23 Karl Schriek <kschriek at gmail.com>:
>> > Hi
>> >
>> > I've fitted a VECM model in R, and converted in to a VAR representation.
>> I
>> > would like to use this model to predict the future value of a response
>> > variable based on different scenarios for the explanatory variables.
>> >
>> > Here is the code for the model:
>> >
>> > library(urca)
>> > library(vars)
>> >
>> > input <-read.csv("data.csv")
>> > ts <- ts(input[16:52,],c(2000,1),frequency=4)
>> > dat1 <- cbind(ts[,"dx"], ts[,"u"],
>> ts[,"cci"],ts[,"bci"],ts[,"cpi"],ts[,"gdp"])
>> >
>> > args('ca.jo')
>> > vecm <- ca.jo(dat1, type = 'trace', K = 2, season =
>> > NULL,spec="longrun",dumvar=NULL)
>> > vecm.var <- vec2var(vecm,r=2)
>> >
>> > Now what I would like do is to predict "dx" into the future by varying
>> the
>> > others. I am not sure if something like "predict dx if
>> > u=30,cpi=15,bci=50,gdp=..." in the next period would work. So what I have
>> in
>> > mind is something along the lines of: increase "u" by 15% in the next
>> period
>> > (which would obviously impact on all the other variables as well,
>> including
>> > "dx") and predict the impact into the future.
>> >
>> > Also, I am not sure if the "vec2var" step is necessary, so please ignore
>> it
>> > if you think it is redundant.
>> >
>> > Thanks
>> > Karl
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only.
>> > -- If you want to post, subscribe first.
>> >
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From kschriek at gmail.com  Tue Nov 24 13:53:17 2009
From: kschriek at gmail.com (Karl Schriek)
Date: Tue, 24 Nov 2009 14:53:17 +0200
Subject: [R-SIG-Finance] R: Use VAR model to predict response to change
	in values of certain variables
In-Reply-To: <111060c20911240423hd5c4e20ud4d887c4baeb7bfc@mail.gmail.com>
References: <88394bdb0911230506p1eff240u8b650d62f289b57f@mail.gmail.com>
	<111060c20911230546i6a79c6b5u964e802ab68dc4e4@mail.gmail.com>
	<88394bdb0911240132s304f1a47h9ec39b58c51cef74@mail.gmail.com>
	<88394bdb0911240221y6d97fdb1ya264dab88e2c1cf4@mail.gmail.com>
	<111060c20911240423hd5c4e20ud4d887c4baeb7bfc@mail.gmail.com>
Message-ID: <88394bdb0911240453i3ef91d51q831ac72aa2818713@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091124/06162dbf/attachment.pl>

From jiri.hoogland at gmail.com  Wed Nov 25 05:38:34 2009
From: jiri.hoogland at gmail.com (Jiri Hoogland)
Date: Tue, 24 Nov 2009 23:38:34 -0500
Subject: [R-SIG-Finance] how use the results of rollapply in the previous
	row to the next row...
Message-ID: <1c08fa330911242038j1a4a8f0bs440055ad7049eb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091124/493cd6e1/attachment.pl>

From ron_michael70 at yahoo.com  Wed Nov 25 07:21:38 2009
From: ron_michael70 at yahoo.com (RON70)
Date: Tue, 24 Nov 2009 22:21:38 -0800 (PST)
Subject: [R-SIG-Finance] [R-sig-finance] A VaR question
Message-ID: <26508077.post@talk.nabble.com>


Hi all,

My problem seems to be bizzare, however I want to do like that. Here I have
estimated a VECM model from my dataset (seems not stationary) and once I
converted those into a VAR representation I have following estimates :

> A1; A2; A3; A4
     V1     V2     V3
1 0.985  0.283 -1.714
2 0.125  1.100 -1.491
3 0.071 -0.089  1.388
      V1     V2     V3
1  0.258 -0.493  1.459
2  0.252 -0.387  1.165
3 -0.057  0.076 -0.536
     V1     V2    V3
1 0.332 -0.459 0.251
2 0.482 -0.686 0.313
3 0.112 -0.104 0.218
      V1    V2     V3
1 -0.532 0.624 -0.006
2 -0.619 0.714 -0.044
3 -0.129 0.121 -0.069

Now I took them as an original DGP process and checked the solution of it's
ch. equation. I got following :

>  library(PolynomF)
>  z = polynom()
> 
> 
> p11 <- 1 - A1[1,1]*z - A2[1,1]*z^2 - A3[1,1]*z^3 - A4[1,1]*z^4
> p12 <- 0 - A1[1,2]*z - A2[1,2]*z^2 - A3[1,2]*z^3 - A4[1,2]*z^4
> p13 <- 0 - A1[1,3]*z - A2[1,3]*z^2 - A3[1,3]*z^3 - A4[1,3]*z^4
> 
> 
> p21 <- 0 - A1[2,1]*z - A2[2,1]*z^2 - A3[2,1]*z^3 - A4[2,1]*z^4
> p22 <- 1 - A1[2,2]*z - A2[2,2]*z^2 - A3[2,2]*z^3 - A4[2,2]*z^4
> p23 <- 0 - A1[2,3]*z - A2[2,3]*z^2 - A3[2,3]*z^3 - A4[2,3]*z^4
> 
> p31 <- 0 - A1[3,1]*z - A2[3,1]*z^2 - A3[3,1]*z^3 - A4[3,1]*z^4
> p32 <- 0 - A1[3,2]*z - A2[3,2]*z^2 - A3[3,2]*z^3 - A4[3,2]*z^4
> p33 <- 1 - A1[3,3]*z - A2[3,3]*z^2 - A3[3,3]*z^3 - A4[3,3]*z^4
> 
> p <- p11*(p22*p33 - p23*p32) - p12*(p21*p33 - p23*p31) + p13*(p21*p32 -
> p22*p31)
> 
> 
> abs(solve(p))
 [1] 1.521516 2.102119 2.102119 4.912478 4.912478 1.000233 1.000233 1.502034
1.502034 1.228100 2.536582 5.342635
> 

Now if I assume (upto a few significant digits) "1.000233 1.000233 " both
equal to "1" then, I am actually getting two unit roots here. Therefore I am
wondering how to tackle it as VAR is defined on max one unit root process. 

Am I missing anything? Can anyone please help me?

Best
-- 
View this message in context: http://old.nabble.com/A-VaR-question-tp26508077p26508077.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From ron_michael70 at yahoo.com  Wed Nov 25 10:29:15 2009
From: ron_michael70 at yahoo.com (RON70)
Date: Wed, 25 Nov 2009 01:29:15 -0800 (PST)
Subject: [R-SIG-Finance] [R-sig-finance] A VaR question
In-Reply-To: <26508077.post@talk.nabble.com>
References: <26508077.post@talk.nabble.com>
Message-ID: <26509688.post@talk.nabble.com>


I think I should be more clear on what I would like to do. From that
estimated model I would like to get a "Real" VAR DGP, perhaps by tweaking
some of the coeficients. Which I would use to simulate artrificial data, for
some study. If somebody shows me some lihgt on how I can achive that, I
would be truly grateful.

Best,



RON70 wrote:
> 
> Hi all,
> 
> My problem seems to be bizzare, however I want to do like that. Here I
> have estimated a VECM model from my dataset (seems not stationary) and
> once I converted those into a VAR representation I have following
> estimates :
> 
>> A1; A2; A3; A4
>      V1     V2     V3
> 1 0.985  0.283 -1.714
> 2 0.125  1.100 -1.491
> 3 0.071 -0.089  1.388
>       V1     V2     V3
> 1  0.258 -0.493  1.459
> 2  0.252 -0.387  1.165
> 3 -0.057  0.076 -0.536
>      V1     V2    V3
> 1 0.332 -0.459 0.251
> 2 0.482 -0.686 0.313
> 3 0.112 -0.104 0.218
>       V1    V2     V3
> 1 -0.532 0.624 -0.006
> 2 -0.619 0.714 -0.044
> 3 -0.129 0.121 -0.069
> 
> Now I took them as an original DGP process and checked the solution of
> it's ch. equation. I got following :
> 
>>  library(PolynomF)
>>  z = polynom()
>> 
>> 
>> p11 <- 1 - A1[1,1]*z - A2[1,1]*z^2 - A3[1,1]*z^3 - A4[1,1]*z^4
>> p12 <- 0 - A1[1,2]*z - A2[1,2]*z^2 - A3[1,2]*z^3 - A4[1,2]*z^4
>> p13 <- 0 - A1[1,3]*z - A2[1,3]*z^2 - A3[1,3]*z^3 - A4[1,3]*z^4
>> 
>> 
>> p21 <- 0 - A1[2,1]*z - A2[2,1]*z^2 - A3[2,1]*z^3 - A4[2,1]*z^4
>> p22 <- 1 - A1[2,2]*z - A2[2,2]*z^2 - A3[2,2]*z^3 - A4[2,2]*z^4
>> p23 <- 0 - A1[2,3]*z - A2[2,3]*z^2 - A3[2,3]*z^3 - A4[2,3]*z^4
>> 
>> p31 <- 0 - A1[3,1]*z - A2[3,1]*z^2 - A3[3,1]*z^3 - A4[3,1]*z^4
>> p32 <- 0 - A1[3,2]*z - A2[3,2]*z^2 - A3[3,2]*z^3 - A4[3,2]*z^4
>> p33 <- 1 - A1[3,3]*z - A2[3,3]*z^2 - A3[3,3]*z^3 - A4[3,3]*z^4
>> 
>> p <- p11*(p22*p33 - p23*p32) - p12*(p21*p33 - p23*p31) + p13*(p21*p32 -
>> p22*p31)
>> 
>> 
>> abs(solve(p))
>  [1] 1.521516 2.102119 2.102119 4.912478 4.912478 1.000233 1.000233
> 1.502034 1.502034 1.228100 2.536582 5.342635
>> 
> 
> Now if I assume (upto a few significant digits) "1.000233 1.000233 " both
> equal to "1" then, I am actually getting two unit roots here. Therefore I
> am wondering how to tackle it as VAR is defined on max one unit root
> process. 
> 
> Am I missing anything? Can anyone please help me?
> 
> Best
> 

-- 
View this message in context: http://old.nabble.com/A-VaR-question-tp26508077p26509688.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From sandor.benczik at crabel.ro  Wed Nov 25 12:59:52 2009
From: sandor.benczik at crabel.ro (Benczik Sandor)
Date: Wed, 25 Nov 2009 13:59:52 +0200
Subject: [R-SIG-Finance] how use the results of rollapply in
	the	previousrow to the next row...
In-Reply-To: <1c08fa330911242038j1a4a8f0bs440055ad7049eb@mail.gmail.com>
References: <1c08fa330911242038j1a4a8f0bs440055ad7049eb@mail.gmail.com>
Message-ID: <1259150392.30542.16.camel@localhost.localdomain>

Hi Jiri,

I found that problems with recursive definitions involving multiple
vectors/columns are usually next to impossible to tackle without for
loops, or without rewriting the formula in a non-recursive way. For your
case here is a kludge:

> a <- data.frame(c1 = 1:5, c2 = 1:5)
> sum.col <- apply(a, 1, sum)
> norms <- exp(c(1,-1) * cumsum(c(1,-1)*log(sum.col)))
Warning messages:
1: In c(1, -1) * log(sum.col) :
  longer object length is not a multiple of shorter object length
2: In c(1, -1) * cumsum(c(1, -1) * log(sum.col)) :
  longer object length is not a multiple of shorter object length
> sum.col / c(1, norms[-length(norms)])
[1] 2.000000 2.000000 3.000000 2.666667 3.750000

HTH,
Sandor

PS. I think the generally accepted view is that such questions belong to
the general R-help list, not being related to finance.

On Wed, 2009-11-25 at 06:38 +0200, Jiri Hoogland wrote:
> Hi,
> 
> say I have a xts object x with data I want to apply a function f over
> row by
> row (by.column=F)
> 
> x =
> index c1 c2  c3
> 1       1   1    0
> 2       2   2    0
> 3       3   3    0
> 4       4   4    0
> 5       5   5    0
> 
> what i would like to do and i am not sure that that is possible is the
> following
> 
> the result of operating on one row is put in the last column of x of
> that
> same row
> and is used in the operation on the next row, where f is some
> non-trivial
> function of the columns
> 
> So for example the simple function summing over the row
> and normalizing by the previous value of the last columns value in the
> previous row
> (first row does not normalize here)
> 
> x =
> index c1 c2   c3
> 1       1   1    2      = 1+1
> 2       2   2    2      = 2/2+2/2 = 2
> 3       3   3    3      = 3/2+3/2 = 3
> 4       4   4    8/3   = 4/3+4/3
> 5       5   5    15/4 = 5/8*3+5/8*3
> 
> Is there some way to sneak this into rollapply?
> Maybe I am asking too much, but if somebody
> can enlighten it would be greatly appreciated
> Thanks!
> Jiri
> 
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
>


From ggrothendieck at gmail.com  Wed Nov 25 13:36:39 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 25 Nov 2009 07:36:39 -0500
Subject: [R-SIG-Finance] how use the results of rollapply in the
	previous row to the next row...
In-Reply-To: <1c08fa330911242038j1a4a8f0bs440055ad7049eb@mail.gmail.com>
References: <1c08fa330911242038j1a4a8f0bs440055ad7049eb@mail.gmail.com>
Message-ID: <971536df0911250436w2b72833axe05c4d1d7f2429b1@mail.gmail.com>

Your example has an index not supported by xts so I will assume your
object is a zoo object.  All xts objects are zoo objects anyways.  If
your actual data has a different class of index than shown here then
the code below should also work with xts.

Try Reduce.  Note that if your real data is large this might not be very fast.

> library(zoo)
> x <- zoo(cbind(c1 = 1:5, c2 = 1:5))
> f <- function(acc, x) sum(x) / acc
> x$c3 <- Reduce(f, split(coredata(x), time(x)), 1, acc = TRUE)[-1]
> x
  c1 c2       c3
1  1  1 2.000000
2  2  2 2.000000
3  3  3 3.000000
4  4  4 2.666667
5  5  5 3.750000


On Tue, Nov 24, 2009 at 11:38 PM, Jiri Hoogland <jiri.hoogland at gmail.com> wrote:
> Hi,
>
> say I have a xts object x with data I want to apply a function f over row by
> row (by.column=F)
>
> x =
> index c1 c2 ?c3
> 1 ? ? ? 1 ? 1 ? ?0
> 2 ? ? ? 2 ? 2 ? ?0
> 3 ? ? ? 3 ? 3 ? ?0
> 4 ? ? ? 4 ? 4 ? ?0
> 5 ? ? ? 5 ? 5 ? ?0
>
> what i would like to do and i am not sure that that is possible is the
> following
>
> the result of operating on one row is put in the last column of x of that
> same row
> and is used in the operation on the next row, where f is some non-trivial
> function of the columns
>
> So for example the simple function summing over the row
> and normalizing by the previous value of the last columns value in the
> previous row
> (first row does not normalize here)
>
> x =
> index c1 c2 ? c3
> 1 ? ? ? 1 ? 1 ? ?2 ? ? ?= 1+1
> 2 ? ? ? 2 ? 2 ? ?2 ? ? ?= 2/2+2/2 = 2
> 3 ? ? ? 3 ? 3 ? ?3 ? ? ?= 3/2+3/2 = 3
> 4 ? ? ? 4 ? 4 ? ?8/3 ? = 4/3+4/3
> 5 ? ? ? 5 ? 5 ? ?15/4 = 5/8*3+5/8*3
>
> Is there some way to sneak this into rollapply?
> Maybe I am asking too much, but if somebody
> can enlighten it would be greatly appreciated
> Thanks!
> Jiri
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From matthieu.stigler at gmail.com  Thu Nov 26 21:52:56 2009
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Thu, 26 Nov 2009 21:52:56 +0100
Subject: [R-SIG-Finance] [R-sig-finance] A VaR question
In-Reply-To: <26509688.post@talk.nabble.com>
References: <26508077.post@talk.nabble.com> <26509688.post@talk.nabble.com>
Message-ID: <4B0EEAA8.2000003@gmail.com>

Hi RON70

Not sure about what you want to do... So you want to simulate a VAR with 
those parameters? There is the function TVAR.simin package tsDyn that 
allow you to simulate a VAR, see:

co<-matrix(c(0.985,  0.283, -1.714,  0.125,  1.100, -1.491,0.071, 
-0.089,  1.388), ncol=3, byrow=TRUE)
library(tsDyn)

TVAR.sim(B=cbind(co,co),nthresh=0, inc="none", lag=2)

Hope this is what you wanted?

MAT2009

RON70 a ?crit :
> I think I should be more clear on what I would like to do. From that
> estimated model I would like to get a "Real" VAR DGP, perhaps by tweaking
> some of the coeficients. Which I would use to simulate artrificial data, for
> some study. If somebody shows me some lihgt on how I can achive that, I
> would be truly grateful.
>
> Best,
>
>
>
> RON70 wrote:
>   
>> Hi all,
>>
>> My problem seems to be bizzare, however I want to do like that. Here I
>> have estimated a VECM model from my dataset (seems not stationary) and
>> once I converted those into a VAR representation I have following
>> estimates :
>>
>>     
>>> A1; A2; A3; A4
>>>       
>>      V1     V2     V3
>> 1 0.985  0.283 -1.714
>> 2 0.125  1.100 -1.491
>> 3 0.071 -0.089  1.388
>>       V1     V2     V3
>> 1  0.258 -0.493  1.459
>> 2  0.252 -0.387  1.165
>> 3 -0.057  0.076 -0.536
>>      V1     V2    V3
>> 1 0.332 -0.459 0.251
>> 2 0.482 -0.686 0.313
>> 3 0.112 -0.104 0.218
>>       V1    V2     V3
>> 1 -0.532 0.624 -0.006
>> 2 -0.619 0.714 -0.044
>> 3 -0.129 0.121 -0.069
>>
>> Now I took them as an original DGP process and checked the solution of
>> it's ch. equation. I got following :
>>
>>     
>>>  library(PolynomF)
>>>  z = polynom()
>>>
>>>
>>> p11 <- 1 - A1[1,1]*z - A2[1,1]*z^2 - A3[1,1]*z^3 - A4[1,1]*z^4
>>> p12 <- 0 - A1[1,2]*z - A2[1,2]*z^2 - A3[1,2]*z^3 - A4[1,2]*z^4
>>> p13 <- 0 - A1[1,3]*z - A2[1,3]*z^2 - A3[1,3]*z^3 - A4[1,3]*z^4
>>>
>>>
>>> p21 <- 0 - A1[2,1]*z - A2[2,1]*z^2 - A3[2,1]*z^3 - A4[2,1]*z^4
>>> p22 <- 1 - A1[2,2]*z - A2[2,2]*z^2 - A3[2,2]*z^3 - A4[2,2]*z^4
>>> p23 <- 0 - A1[2,3]*z - A2[2,3]*z^2 - A3[2,3]*z^3 - A4[2,3]*z^4
>>>
>>> p31 <- 0 - A1[3,1]*z - A2[3,1]*z^2 - A3[3,1]*z^3 - A4[3,1]*z^4
>>> p32 <- 0 - A1[3,2]*z - A2[3,2]*z^2 - A3[3,2]*z^3 - A4[3,2]*z^4
>>> p33 <- 1 - A1[3,3]*z - A2[3,3]*z^2 - A3[3,3]*z^3 - A4[3,3]*z^4
>>>
>>> p <- p11*(p22*p33 - p23*p32) - p12*(p21*p33 - p23*p31) + p13*(p21*p32 -
>>> p22*p31)
>>>
>>>
>>> abs(solve(p))
>>>       
>>  [1] 1.521516 2.102119 2.102119 4.912478 4.912478 1.000233 1.000233
>> 1.502034 1.502034 1.228100 2.536582 5.342635
>>     
>> Now if I assume (upto a few significant digits) "1.000233 1.000233 " both
>> equal to "1" then, I am actually getting two unit roots here. Therefore I
>> am wondering how to tackle it as VAR is defined on max one unit root
>> process. 
>>
>> Am I missing anything? Can anyone please help me?
>>
>> Best
>>
>>     
>
>


From ron_michael70 at yahoo.com  Fri Nov 27 07:24:20 2009
From: ron_michael70 at yahoo.com (RON70)
Date: Thu, 26 Nov 2009 22:24:20 -0800 (PST)
Subject: [R-SIG-Finance] [R-sig-finance] A VaR question
In-Reply-To: <4B0EEAA8.2000003@gmail.com>
References: <26508077.post@talk.nabble.com> <26509688.post@talk.nabble.com>
	<4B0EEAA8.2000003@gmail.com>
Message-ID: <26535884.post@talk.nabble.com>


Thanks Matifou for your reply. Yes I want to simulate VAR with those
parameters. However here my problem is those parameters are estimated
parameters not actual one. Therefore I dont think I can apply TVAR.simin()
directly on those parameters. You see, ch equation for those estimated
parameters doesnt give one unit root, which is the fundamental property for
a co-integrated VAR DGP. 

Therefore I want to do some some tweaks so that I can get a revised
parameter set from those estimated parameters such that ch. equation (based
on revised parameters) gives exactly one unit root. Then I can use
TVAR.simin() to generate data.

Therefore my question is : How can I tweak those estimated parameters?

Best,



matifou wrote:
> 
> Hi RON70
> 
> Not sure about what you want to do... So you want to simulate a VAR with 
> those parameters? There is the function TVAR.simin package tsDyn that 
> allow you to simulate a VAR, see:
> 
> co<-matrix(c(0.985,  0.283, -1.714,  0.125,  1.100, -1.491,0.071, 
> -0.089,  1.388), ncol=3, byrow=TRUE)
> library(tsDyn)
> 
> TVAR.sim(B=cbind(co,co),nthresh=0, inc="none", lag=2)
> 
> Hope this is what you wanted?
> 
> MAT2009
> 
> RON70 a ?crit :
>> I think I should be more clear on what I would like to do. From that
>> estimated model I would like to get a "Real" VAR DGP, perhaps by tweaking
>> some of the coeficients. Which I would use to simulate artrificial data,
>> for
>> some study. If somebody shows me some lihgt on how I can achive that, I
>> would be truly grateful.
>>
>> Best,
>>
>>
>>
>> RON70 wrote:
>>   
>>> Hi all,
>>>
>>> My problem seems to be bizzare, however I want to do like that. Here I
>>> have estimated a VECM model from my dataset (seems not stationary) and
>>> once I converted those into a VAR representation I have following
>>> estimates :
>>>
>>>     
>>>> A1; A2; A3; A4
>>>>       
>>>      V1     V2     V3
>>> 1 0.985  0.283 -1.714
>>> 2 0.125  1.100 -1.491
>>> 3 0.071 -0.089  1.388
>>>       V1     V2     V3
>>> 1  0.258 -0.493  1.459
>>> 2  0.252 -0.387  1.165
>>> 3 -0.057  0.076 -0.536
>>>      V1     V2    V3
>>> 1 0.332 -0.459 0.251
>>> 2 0.482 -0.686 0.313
>>> 3 0.112 -0.104 0.218
>>>       V1    V2     V3
>>> 1 -0.532 0.624 -0.006
>>> 2 -0.619 0.714 -0.044
>>> 3 -0.129 0.121 -0.069
>>>
>>> Now I took them as an original DGP process and checked the solution of
>>> it's ch. equation. I got following :
>>>
>>>     
>>>>  library(PolynomF)
>>>>  z = polynom()
>>>>
>>>>
>>>> p11 <- 1 - A1[1,1]*z - A2[1,1]*z^2 - A3[1,1]*z^3 - A4[1,1]*z^4
>>>> p12 <- 0 - A1[1,2]*z - A2[1,2]*z^2 - A3[1,2]*z^3 - A4[1,2]*z^4
>>>> p13 <- 0 - A1[1,3]*z - A2[1,3]*z^2 - A3[1,3]*z^3 - A4[1,3]*z^4
>>>>
>>>>
>>>> p21 <- 0 - A1[2,1]*z - A2[2,1]*z^2 - A3[2,1]*z^3 - A4[2,1]*z^4
>>>> p22 <- 1 - A1[2,2]*z - A2[2,2]*z^2 - A3[2,2]*z^3 - A4[2,2]*z^4
>>>> p23 <- 0 - A1[2,3]*z - A2[2,3]*z^2 - A3[2,3]*z^3 - A4[2,3]*z^4
>>>>
>>>> p31 <- 0 - A1[3,1]*z - A2[3,1]*z^2 - A3[3,1]*z^3 - A4[3,1]*z^4
>>>> p32 <- 0 - A1[3,2]*z - A2[3,2]*z^2 - A3[3,2]*z^3 - A4[3,2]*z^4
>>>> p33 <- 1 - A1[3,3]*z - A2[3,3]*z^2 - A3[3,3]*z^3 - A4[3,3]*z^4
>>>>
>>>> p <- p11*(p22*p33 - p23*p32) - p12*(p21*p33 - p23*p31) + p13*(p21*p32 -
>>>> p22*p31)
>>>>
>>>>
>>>> abs(solve(p))
>>>>       
>>>  [1] 1.521516 2.102119 2.102119 4.912478 4.912478 1.000233 1.000233
>>> 1.502034 1.502034 1.228100 2.536582 5.342635
>>>     
>>> Now if I assume (upto a few significant digits) "1.000233 1.000233 "
>>> both
>>> equal to "1" then, I am actually getting two unit roots here. Therefore
>>> I
>>> am wondering how to tackle it as VAR is defined on max one unit root
>>> process. 
>>>
>>> Am I missing anything? Can anyone please help me?
>>>
>>> Best
>>>
>>>     
>>
>>
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
> 

-- 
View this message in context: http://old.nabble.com/A-VaR-question-tp26508077p26535884.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From ron_michael70 at yahoo.com  Fri Nov 27 07:45:23 2009
From: ron_michael70 at yahoo.com (RON70)
Date: Thu, 26 Nov 2009 22:45:23 -0800 (PST)
Subject: [R-SIG-Finance] [R-sig-finance] A VaR question
In-Reply-To: <26535884.post@talk.nabble.com>
References: <26508077.post@talk.nabble.com> <26509688.post@talk.nabble.com>
	<4B0EEAA8.2000003@gmail.com> <26535884.post@talk.nabble.com>
Message-ID: <26535989.post@talk.nabble.com>


I want to make another point here. My question is can I take "co" matrix as
DGP for a VAR? Here I calculated the roots for the ch. equation :

A2 = A1 = co
library(PolynomF) 
  z = polynom() 
 
 
 p11 <- 1 - A1[1,1]*z - A2[1,1]*z^2
 p12 <- 0 - A1[1,2]*z - A2[1,2]*z^2
 p13 <- 0 - A1[1,3]*z - A2[1,3]*z^2
 
 
 p21 <- 0 - A1[2,1]*z - A2[2,1]*z^2
 p22 <- 1 - A1[2,2]*z - A2[2,2]*z^2 
 p23 <- 0 - A1[2,3]*z - A2[2,3]*z^2 
 
 p31 <- 0 - A1[3,1]*z - A2[3,1]*z^2 
 p32 <- 0 - A1[3,2]*z - A2[3,2]*z^2 
 p33 <- 1 - A1[3,3]*z - A2[3,3]*z^2 
 
 p <- p11*(p22*p33 - p23*p32) - p12*(p21*p33 - p23*p31) + p13*(p21*p32 -
p22*p31) 
 
 
 >  abs(solve(p)) 
[1] 1.6920982 1.5520308 1.4688865 0.4688865 0.5520308 0.6920982

You see there is no unit root, which is one of the fandamental properties
for a co-integrated VAR DGP.

Best,

RON70 wrote:
> 
> Thanks Matifou for your reply. Yes I want to simulate VAR with those
> parameters. However here my problem is those parameters are estimated
> parameters not actual one. Therefore I dont think I can apply TVAR.simin()
> directly on those parameters. You see, ch equation for those estimated
> parameters doesnt give one unit root, which is the fundamental property
> for a co-integrated VAR DGP. 
> 
> Therefore I want to do some some tweaks so that I can get a revised
> parameter set from those estimated parameters such that ch. equation
> (based on revised parameters) gives exactly one unit root. Then I can use
> TVAR.simin() to generate data.
> 
> Therefore my question is : How can I tweak those estimated parameters?
> 
> Best,
> 
> 
> 
> matifou wrote:
>> 
>> Hi RON70
>> 
>> Not sure about what you want to do... So you want to simulate a VAR with 
>> those parameters? There is the function TVAR.simin package tsDyn that 
>> allow you to simulate a VAR, see:
>> 
>> co<-matrix(c(0.985,  0.283, -1.714,  0.125,  1.100, -1.491,0.071, 
>> -0.089,  1.388), ncol=3, byrow=TRUE)
>> library(tsDyn)
>> 
>> TVAR.sim(B=cbind(co,co),nthresh=0, inc="none", lag=2)
>> 
>> Hope this is what you wanted?
>> 
>> MAT2009
>> 
>> RON70 a ?crit :
>>> I think I should be more clear on what I would like to do. From that
>>> estimated model I would like to get a "Real" VAR DGP, perhaps by
>>> tweaking
>>> some of the coeficients. Which I would use to simulate artrificial data,
>>> for
>>> some study. If somebody shows me some lihgt on how I can achive that, I
>>> would be truly grateful.
>>>
>>> Best,
>>>
>>>
>>>
>>> RON70 wrote:
>>>   
>>>> Hi all,
>>>>
>>>> My problem seems to be bizzare, however I want to do like that. Here I
>>>> have estimated a VECM model from my dataset (seems not stationary) and
>>>> once I converted those into a VAR representation I have following
>>>> estimates :
>>>>
>>>>     
>>>>> A1; A2; A3; A4
>>>>>       
>>>>      V1     V2     V3
>>>> 1 0.985  0.283 -1.714
>>>> 2 0.125  1.100 -1.491
>>>> 3 0.071 -0.089  1.388
>>>>       V1     V2     V3
>>>> 1  0.258 -0.493  1.459
>>>> 2  0.252 -0.387  1.165
>>>> 3 -0.057  0.076 -0.536
>>>>      V1     V2    V3
>>>> 1 0.332 -0.459 0.251
>>>> 2 0.482 -0.686 0.313
>>>> 3 0.112 -0.104 0.218
>>>>       V1    V2     V3
>>>> 1 -0.532 0.624 -0.006
>>>> 2 -0.619 0.714 -0.044
>>>> 3 -0.129 0.121 -0.069
>>>>
>>>> Now I took them as an original DGP process and checked the solution of
>>>> it's ch. equation. I got following :
>>>>
>>>>     
>>>>>  library(PolynomF)
>>>>>  z = polynom()
>>>>>
>>>>>
>>>>> p11 <- 1 - A1[1,1]*z - A2[1,1]*z^2 - A3[1,1]*z^3 - A4[1,1]*z^4
>>>>> p12 <- 0 - A1[1,2]*z - A2[1,2]*z^2 - A3[1,2]*z^3 - A4[1,2]*z^4
>>>>> p13 <- 0 - A1[1,3]*z - A2[1,3]*z^2 - A3[1,3]*z^3 - A4[1,3]*z^4
>>>>>
>>>>>
>>>>> p21 <- 0 - A1[2,1]*z - A2[2,1]*z^2 - A3[2,1]*z^3 - A4[2,1]*z^4
>>>>> p22 <- 1 - A1[2,2]*z - A2[2,2]*z^2 - A3[2,2]*z^3 - A4[2,2]*z^4
>>>>> p23 <- 0 - A1[2,3]*z - A2[2,3]*z^2 - A3[2,3]*z^3 - A4[2,3]*z^4
>>>>>
>>>>> p31 <- 0 - A1[3,1]*z - A2[3,1]*z^2 - A3[3,1]*z^3 - A4[3,1]*z^4
>>>>> p32 <- 0 - A1[3,2]*z - A2[3,2]*z^2 - A3[3,2]*z^3 - A4[3,2]*z^4
>>>>> p33 <- 1 - A1[3,3]*z - A2[3,3]*z^2 - A3[3,3]*z^3 - A4[3,3]*z^4
>>>>>
>>>>> p <- p11*(p22*p33 - p23*p32) - p12*(p21*p33 - p23*p31) + p13*(p21*p32
>>>>> -
>>>>> p22*p31)
>>>>>
>>>>>
>>>>> abs(solve(p))
>>>>>       
>>>>  [1] 1.521516 2.102119 2.102119 4.912478 4.912478 1.000233 1.000233
>>>> 1.502034 1.502034 1.228100 2.536582 5.342635
>>>>     
>>>> Now if I assume (upto a few significant digits) "1.000233 1.000233 "
>>>> both
>>>> equal to "1" then, I am actually getting two unit roots here. Therefore
>>>> I
>>>> am wondering how to tackle it as VAR is defined on max one unit root
>>>> process. 
>>>>
>>>> Am I missing anything? Can anyone please help me?
>>>>
>>>> Best
>>>>
>>>>     
>>>
>>>
>> 
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>> 
>> 
> 
> 

-- 
View this message in context: http://old.nabble.com/A-VaR-question-tp26508077p26535989.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From ajayshah at mayin.org  Fri Nov 27 12:56:52 2009
From: ajayshah at mayin.org (Ajay Shah)
Date: Fri, 27 Nov 2009 17:26:52 +0530
Subject: [R-SIG-Finance] Discretising intra-day data -- how to get by with
	less memory?
Message-ID: <20091127115652.GA28980@ajay-shahs-macbook-pro.local>

I'm using this function to convert intra-day data into a grid with an
observation each N seconds:

  # This function consumes "z" a zoo object where timestamps are intraday
  # and a period for discretisation Nseconds.
  # The key ideas are from this thread:
  #    https://stat.ethz.ch/pipermail/r-sig-finance/2009q4/005144.html
  intraday.discretise <- function(z, Nseconds) {
    toNsec <- function(x) as.POSIXct(Nseconds*ceiling(as.numeric(x)/Nseconds),
                                   origin = "1970-01-01")
    d <- aggregate(z, toNsec, tail, 1)
    # At this point there is one problem: NA records are not created
    # for blocks of time in which there were no records.

    # To solve this:
    dreg <- as.zoo(as.ts(d))
    class(time(dreg)) <- class(time(d))

    dreg
  }

This works correctly but it's incredibly memory-intensive. I'm running
out of core in running this for some problems.

Is there a way to write this which would use less RAM?

-- 
Ajay Shah                                      http://www.mayin.org/ajayshah  
ajayshah at mayin.org                             http://ajayshahblog.blogspot.com
<*(:-? - wizard who doesn't know the answer.


From ggrothendieck at gmail.com  Fri Nov 27 13:37:03 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 27 Nov 2009 07:37:03 -0500
Subject: [R-SIG-Finance] Discretising intra-day data -- how to get by
	with less memory?
In-Reply-To: <20091127115652.GA28980@ajay-shahs-macbook-pro.local>
References: <20091127115652.GA28980@ajay-shahs-macbook-pro.local>
Message-ID: <971536df0911270437ue218d07rf76228eecc0b5beb@mail.gmail.com>

What you are asking for has the potential to create huge data sets
depending on the time range of the data and N. What are they?   If
that is the problem then its not just a matter of how memory intensive
the code is but just about any manipulation will fail.  Do the
problems arise on the aggregate or moving back and forth between zoo
and ts?

On Fri, Nov 27, 2009 at 6:56 AM, Ajay Shah <ajayshah at mayin.org> wrote:
> I'm using this function to convert intra-day data into a grid with an
> observation each N seconds:
>
> ?# This function consumes "z" a zoo object where timestamps are intraday
> ?# and a period for discretisation Nseconds.
> ?# The key ideas are from this thread:
> ?# ? ?https://stat.ethz.ch/pipermail/r-sig-finance/2009q4/005144.html
> ?intraday.discretise <- function(z, Nseconds) {
> ? ?toNsec <- function(x) as.POSIXct(Nseconds*ceiling(as.numeric(x)/Nseconds),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? origin = "1970-01-01")
> ? ?d <- aggregate(z, toNsec, tail, 1)
> ? ?# At this point there is one problem: NA records are not created
> ? ?# for blocks of time in which there were no records.
>
> ? ?# To solve this:
> ? ?dreg <- as.zoo(as.ts(d))
> ? ?class(time(dreg)) <- class(time(d))
>
> ? ?dreg
> ?}
>
> This works correctly but it's incredibly memory-intensive. I'm running
> out of core in running this for some problems.
>
> Is there a way to write this which would use less RAM?
>
> --
> Ajay Shah ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?http://www.mayin.org/ajayshah
> ajayshah at mayin.org ? ? ? ? ? ? ? ? ? ? ? ? ? ? http://ajayshahblog.blogspot.com
> <*(:-? - wizard who doesn't know the answer.


From brian at braverock.com  Fri Nov 27 13:41:00 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 27 Nov 2009 06:41:00 -0600
Subject: [R-SIG-Finance] Discretising intra-day data -- how to get by
 with	less memory?
In-Reply-To: <20091127115652.GA28980@ajay-shahs-macbook-pro.local>
References: <20091127115652.GA28980@ajay-shahs-macbook-pro.local>
Message-ID: <4B0FC8DC.2060407@braverock.com>

Ajay Shah wrote:
> I'm using this function to convert intra-day data into a grid with an
> observation each N seconds:
>
>   # This function consumes "z" a zoo object where timestamps are intraday
>   # and a period for discretisation Nseconds.
>   # The key ideas are from this thread:
>   #    https://stat.ethz.ch/pipermail/r-sig-finance/2009q4/005144.html
>   intraday.discretise <- function(z, Nseconds) {
>     toNsec <- function(x) as.POSIXct(Nseconds*ceiling(as.numeric(x)/Nseconds),
>                                    origin = "1970-01-01")
>     d <- aggregate(z, toNsec, tail, 1)
>     # At this point there is one problem: NA records are not created
>     # for blocks of time in which there were no records.
>
>     # To solve this:
>     dreg <- as.zoo(as.ts(d))
>     class(time(dreg)) <- class(time(d))
>
>     dreg
>   }
>
> This works correctly but it's incredibly memory-intensive. I'm running
> out of core in running this for some problems.
>
> Is there a way to write this which would use less RAM?
>
>   
Jeff Ryan, Abe Winter, and I came up with an align.time function a few 
months back:

align.time <- function(x, n=30) {
  structure(unclass(x) + (n - unclass(x) %% n), class=c("POSIXt","POSIXct")) }

x is xts data
n is seconds

Regards,

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From brian at braverock.com  Fri Nov 27 14:00:23 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 27 Nov 2009 07:00:23 -0600
Subject: [R-SIG-Finance] Discretising intra-day data -- how to get by
 with	less memory?
In-Reply-To: <4B0FC8DC.2060407@braverock.com>
References: <20091127115652.GA28980@ajay-shahs-macbook-pro.local>
	<4B0FC8DC.2060407@braverock.com>
Message-ID: <4B0FCD67.6000005@braverock.com>

Brian G. Peterson wrote:
> Ajay Shah wrote:
>> I'm using this function to convert intra-day data into a grid with an
>> observation each N seconds:
>>
>>   # This function consumes "z" a zoo object where timestamps are 
>> intraday
>>   # and a period for discretisation Nseconds.
>>   # The key ideas are from this thread:
>>   #    https://stat.ethz.ch/pipermail/r-sig-finance/2009q4/005144.html
>>   intraday.discretise <- function(z, Nseconds) {
>>     toNsec <- function(x) 
>> as.POSIXct(Nseconds*ceiling(as.numeric(x)/Nseconds),
>>                                    origin = "1970-01-01")
>>     d <- aggregate(z, toNsec, tail, 1)
>>     # At this point there is one problem: NA records are not created
>>     # for blocks of time in which there were no records.
>>
>>     # To solve this:
>>     dreg <- as.zoo(as.ts(d))
>>     class(time(dreg)) <- class(time(d))
>>
>>     dreg
>>   }
>>
>> This works correctly but it's incredibly memory-intensive. I'm running
>> out of core in running this for some problems.
>>
>> Is there a way to write this which would use less RAM?
>>
>>   
> Jeff Ryan, Abe Winter, and I came up with an align.time function a few 
> months back:
>
> align.time <- function(x, n=30) {
>  structure(unclass(x) + (n - unclass(x) %% n), 
> class=c("POSIXt","POSIXct")) }
>
> x is xts data
> n is seconds
>
> Regards,
>
>  - Brian
>
Or, an earlier, slower version:

this works well enough to generate a new index on the output of to.period:

# stamp is POSIXct object, like index(x) of an xts object
# n is number of seconds to round to, so n=k in to.period
even_seconds = function(stamp,n=60)
{
  tzone = attr(stamp,"tzone")
  if (is.null(tzone)) { tzone = "" }
  base = as.POSIXct(strptime( format(stamp,"%Y%m%d"), "%Y%m%d" ),tz=tzone)
  i = as.numeric(stamp) - as.numeric(base)
  i = base + n*ceiling(i/n)
  i
}



-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From wobwu22 at yahoo.de  Fri Nov 27 15:52:33 2009
From: wobwu22 at yahoo.de (Wob Wu)
Date: Fri, 27 Nov 2009 14:52:33 +0000 (GMT)
Subject: [R-SIG-Finance] Creating a back adjusted continuous price series
	from log returns
Message-ID: <619350.48769.qm@web23401.mail.ird.yahoo.com>

I am trying to create a continuous daily futures contract time series. I've already calculated the log returns for this series and want to create an artificial price series starting with the most recent price (the one with the latest date).
Basically I am trying to create a price series with the following logic:

p(-1) := exp(ln(p(0)) - r)

I have got p(T) and the log return series r and am trying to create the price series.

with
p(0) = todays price
p(-1) = yesterdays price
p(T) = the price at time T (current available price)
r = log return between yesterdays price and todays price

Thanks

Wolfgang Wu

__________________________________________________
Do You Yahoo!?
Sie sind Spam leid? Yahoo! Mail verf?gt ?ber einen herausragenden Schutz gegen Massenmails. 


From jeff.a.ryan at gmail.com  Fri Nov 27 16:07:23 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 27 Nov 2009 09:07:23 -0600
Subject: [R-SIG-Finance] Discretising intra-day data -- how to get by
	with less memory?
In-Reply-To: <4B0FCD67.6000005@braverock.com>
References: <20091127115652.GA28980@ajay-shahs-macbook-pro.local>
	<4B0FC8DC.2060407@braverock.com> <4B0FCD67.6000005@braverock.com>
Message-ID: <e8e755250911270707v3325f6e6vc61e258b074da21@mail.gmail.com>

The three functions that can be found in xts to help here are:

(1) align.time:  (as Brian alluded to)
This will simply shift all times to the next n-th second specified.
e.g. align.time(x, n=300)  # 5 minutes

(2) endpoints:
Locate the last time-stamp (obs in time-series) for each "k" "on" periods
e.g. endpoints(x, on="minutes", k=5)  # 5 minutes

(3) merge.xts with a regular time index.
e.g. merge(x, xts(, timeBasedSeq('2009-11-01 08:30/2009-11-01 03:00')))



A complete example:
> x <- xts(1:10, Sys.time()+1:10*rnorm(10)*60)
> x
                    [,1]
2009-11-27 08:48:18    9
2009-11-27 08:51:03    7
2009-11-27 08:52:13    8
2009-11-27 08:53:10   10
2009-11-27 08:55:25    6
2009-11-27 08:55:56    1
2009-11-27 08:56:02    4
2009-11-27 08:56:44    3
2009-11-27 08:59:24    2
2009-11-27 09:02:46    5

> xa <- align.time(x,60)  # align to end of minutes
> xa
                    [,1]
2009-11-27 08:49:00    9
2009-11-27 08:52:00    7
2009-11-27 08:53:00    8
2009-11-27 08:54:00   10
2009-11-27 08:56:00    6
2009-11-27 08:56:00    1
2009-11-27 08:57:00    4
2009-11-27 08:57:00    3
2009-11-27 09:00:00    2
2009-11-27 09:03:00    5

> xa[endpoints(xa,'minutes')]  # get last obs with unique timestamp
                    [,1]
2009-11-27 08:49:00    9
2009-11-27 08:52:00    7
2009-11-27 08:53:00    8
2009-11-27 08:54:00   10
2009-11-27 08:56:00    1
2009-11-27 08:57:00    3
2009-11-27 09:00:00    2
2009-11-27 09:03:00    5

> # fill in 'regular' time series
> merge(xa[endpoints(xa,'minutes')], xts( ,seq(start(xa),end(xa),by="mins")))
                    xa.endpoints.xa...minutes...
2009-11-27 08:49:00                            9
2009-11-27 08:50:00                           NA
2009-11-27 08:51:00                           NA
2009-11-27 08:52:00                            7
2009-11-27 08:53:00                            8
2009-11-27 08:54:00                           10
2009-11-27 08:55:00                           NA
2009-11-27 08:56:00                            1
2009-11-27 08:57:00                            3
2009-11-27 08:58:00                           NA
2009-11-27 08:59:00                           NA
2009-11-27 09:00:00                            2
2009-11-27 09:01:00                           NA
2009-11-27 09:02:00                           NA
2009-11-27 09:03:00                            5

> # optional fill=na.locf will carry forward the last observation (last trade?)
> merge(xa[endpoints(xa,'minutes')], xts( ,seq(start(xa),end(xa),by="mins")),fill=na.locf)
                    xa.endpoints.xa...minutes...
2009-11-27 08:49:00                            9
2009-11-27 08:50:00                            9
2009-11-27 08:51:00                            9
2009-11-27 08:52:00                            7
2009-11-27 08:53:00                            8
2009-11-27 08:54:00                           10
2009-11-27 08:55:00                           10
2009-11-27 08:56:00                            1
2009-11-27 08:57:00                            3
2009-11-27 08:58:00                            3
2009-11-27 08:59:00                            3
2009-11-27 09:00:00                            2
2009-11-27 09:01:00                            2
2009-11-27 09:02:00                            2
2009-11-27 09:03:00                            5


I didn't test against your solution(s), but this should be very fast
and use as little memory as possible.  endpoints, align.time and
merge.xts have all been heavily optimized for speed and memory.

HTH
Jeff

On Fri, Nov 27, 2009 at 7:00 AM, Brian G. Peterson <brian at braverock.com> wrote:
> Brian G. Peterson wrote:
>>
>> Ajay Shah wrote:
>>>
>>> I'm using this function to convert intra-day data into a grid with an
>>> observation each N seconds:
>>>
>>> ?# This function consumes "z" a zoo object where timestamps are intraday
>>> ?# and a period for discretisation Nseconds.
>>> ?# The key ideas are from this thread:
>>> ?# ? ?https://stat.ethz.ch/pipermail/r-sig-finance/2009q4/005144.html
>>> ?intraday.discretise <- function(z, Nseconds) {
>>> ? ?toNsec <- function(x)
>>> as.POSIXct(Nseconds*ceiling(as.numeric(x)/Nseconds),
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? origin = "1970-01-01")
>>> ? ?d <- aggregate(z, toNsec, tail, 1)
>>> ? ?# At this point there is one problem: NA records are not created
>>> ? ?# for blocks of time in which there were no records.
>>>
>>> ? ?# To solve this:
>>> ? ?dreg <- as.zoo(as.ts(d))
>>> ? ?class(time(dreg)) <- class(time(d))
>>>
>>> ? ?dreg
>>> ?}
>>>
>>> This works correctly but it's incredibly memory-intensive. I'm running
>>> out of core in running this for some problems.
>>>
>>> Is there a way to write this which would use less RAM?
>>>
>>>
>>
>> Jeff Ryan, Abe Winter, and I came up with an align.time function a few
>> months back:
>>
>> align.time <- function(x, n=30) {
>> ?structure(unclass(x) + (n - unclass(x) %% n),
>> class=c("POSIXt","POSIXct")) }
>>
>> x is xts data
>> n is seconds
>>
>> Regards,
>>
>> ?- Brian
>>
> Or, an earlier, slower version:
>
> this works well enough to generate a new index on the output of to.period:
>
> # stamp is POSIXct object, like index(x) of an xts object
> # n is number of seconds to round to, so n=k in to.period
> even_seconds = function(stamp,n=60)
> {
> ?tzone = attr(stamp,"tzone")
> ?if (is.null(tzone)) { tzone = "" }
> ?base = as.POSIXct(strptime( format(stamp,"%Y%m%d"), "%Y%m%d" ),tz=tzone)
> ?i = as.numeric(stamp) - as.numeric(base)
> ?i = base + n*ceiling(i/n)
> ?i
> }
>
>
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From robert.nicholson at gmail.com  Fri Nov 27 16:33:19 2009
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Fri, 27 Nov 2009 09:33:19 -0600
Subject: [R-SIG-Finance] SMA on Volume?
Message-ID: <B1AD5175-DBC8-412D-9E1C-D914EB50F287@gmail.com>

If you're viewing a chart series and you have Volume displayed you can you specify "on" such that SMA will be overlaid on Volume graph?

From josh.m.ulrich at gmail.com  Fri Nov 27 16:52:48 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 27 Nov 2009 09:52:48 -0600
Subject: [R-SIG-Finance] SMA on Volume?
In-Reply-To: <B1AD5175-DBC8-412D-9E1C-D914EB50F287@gmail.com>
References: <B1AD5175-DBC8-412D-9E1C-D914EB50F287@gmail.com>
Message-ID: <8cca69990911270752pb974858i5447dd8928456673@mail.gmail.com>

Try:

> getSymbols("SPY")
[1] "SPY"
> chartSeries(SPY); addSMA(10,on=2)
>

Best,
Josh
--
http://www.fosstrading.com



On Fri, Nov 27, 2009 at 9:33 AM, Robert Nicholson
<robert.nicholson at gmail.com> wrote:
> If you're viewing a chart series and you have Volume displayed you can you specify "on" such that SMA will be overlaid on Volume graph?
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From armstrong.whit at gmail.com  Fri Nov 27 16:53:29 2009
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Fri, 27 Nov 2009 10:53:29 -0500
Subject: [R-SIG-Finance] Creating a back adjusted continuous price
	series from log returns
In-Reply-To: <619350.48769.qm@web23401.mail.ird.yahoo.com>
References: <619350.48769.qm@web23401.mail.ird.yahoo.com>
Message-ID: <8ec76080911270753r293718aar278bbffc1016cc78@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091127/dedd16ee/attachment.pl>

From noldo22 at gmail.com  Fri Nov 27 17:03:14 2009
From: noldo22 at gmail.com (Renato Costa)
Date: Fri, 27 Nov 2009 14:03:14 -0200
Subject: [R-SIG-Finance] Data
Message-ID: <53d3e3c70911270803t2d5e93b6m1f9e9fd1ead836b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091127/79bc7ed4/attachment.pl>

From cmdr_rogue at hotmail.com  Fri Nov 27 17:20:40 2009
From: cmdr_rogue at hotmail.com (Luwingo)
Date: Fri, 27 Nov 2009 08:20:40 -0800 (PST)
Subject: [R-SIG-Finance] [R-sig-finance] Data
In-Reply-To: <53d3e3c70911270803t2d5e93b6m1f9e9fd1ead836b@mail.gmail.com>
References: <53d3e3c70911270803t2d5e93b6m1f9e9fd1ead836b@mail.gmail.com>
Message-ID: <26544564.post@talk.nabble.com>


Hi Renato- option data is pretty valuable and somewhat complicated. It's
pretty unlikely that you will be able to find that data for free- especially
if you're looking for options on certain less liquid stocks. That said, the
CBOE has data that you can use, as do the CBOT, CME, and NYMEX. You probably
won't find that data too useful, though, since implied volatility data is
especially difficult to find for free. The best place you can find this data
is from any Bloomberg terminal. If you have one in your university, use that
to download the data onto a spreadsheet for use elsewhere.


Feanor22 wrote:
> 
> Dear all
> 
> I need to get some call option data to compare with some of my
> simulations.
> Stock prices are easy to find but for options most of the sites I looked
> for
> it I would have to pay for that.
> Does anyone know if I can get some option prices for free?
> 
> Any help is appreciated.
> 
> Regards
> 
> Renato
> 
> -- 
> PhD Student Renato Alencar Adelino da Costa (renato at ele.puc-rio.br)
> Department of Electrical Engineering (Mathematical Finance)
> Pontifical Catholic University (PUC-Rio)
> Rua Marques de Sao Vicente, 225, Sala 604L
> Gavea          CEP: 22453-900
> Rio de Janeiro
> BRASIL
> ( 9 months research at Curtin University of technology: Nov 2008 - July
> 2009)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
> 

-- 
View this message in context: http://old.nabble.com/Data-tp26544402p26544564.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From patrick at burns-stat.com  Fri Nov 27 17:29:34 2009
From: patrick at burns-stat.com (Patrick Burns)
Date: Fri, 27 Nov 2009 16:29:34 +0000
Subject: [R-SIG-Finance] Creating a back adjusted continuous
 price	series from log returns
In-Reply-To: <8ec76080911270753r293718aar278bbffc1016cc78@mail.gmail.com>
References: <619350.48769.qm@web23401.mail.ird.yahoo.com>
	<8ec76080911270753r293718aar278bbffc1016cc78@mail.gmail.com>
Message-ID: <4B0FFE6E.3050800@burns-stat.com>

I was interpreting the question as looking for:

price.vector <- original.price * exp(cumsum(return.vector))


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of "The R Inferno" and "A Guide for the Unwilling S User")

Whit Armstrong wrote:
> There are many ways of doing this. You need to decide what your strategy is
> for rolling the contracts (vol crossover, OI crossover, expiration, 10 days
> before expiration, first notice date, etc.).
> 
> Look here for a basic idea about how to do this:
> http://github.com/armstrtw/RCommodity
> 
> <http://github.com/armstrtw/RCommodity>-Whit
> 
> 
> On Fri, Nov 27, 2009 at 9:52 AM, Wob Wu <wobwu22 at yahoo.de> wrote:
> 
>> I am trying to create a continuous daily futures contract time series. I've
>> already calculated the log returns for this series and want to create an
>> artificial price series starting with the most recent price (the one with
>> the latest date).
>> Basically I am trying to create a price series with the following logic:
>>
>> p(-1) := exp(ln(p(0)) - r)
>>
>> I have got p(T) and the log return series r and am trying to create the
>> price series.
>>
>> with
>> p(0) = todays price
>> p(-1) = yesterdays price
>> p(T) = the price at time T (current available price)
>> r = log return between yesterdays price and todays price
>>
>> Thanks
>>
>> Wolfgang Wu
>>
>> __________________________________________________
>> Do You Yahoo!?
>> Sie sind Spam leid? Yahoo! Mail verf??gt ??ber einen herausragenden Schutz
>> gegen Massenmails.
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From ajayshah at mayin.org  Fri Nov 27 18:27:28 2009
From: ajayshah at mayin.org (Ajay Shah)
Date: Fri, 27 Nov 2009 22:57:28 +0530
Subject: [R-SIG-Finance] Discretising intra-day data -- how to get
	by	with less memory?
In-Reply-To: <971536df0911270437ue218d07rf76228eecc0b5beb@mail.gmail.com>
References: <20091127115652.GA28980@ajay-shahs-macbook-pro.local>
	<971536df0911270437ue218d07rf76228eecc0b5beb@mail.gmail.com>
Message-ID: <20091127172728.GD1586@ajay-shahs-macbook-pro.local>

On Fri, Nov 27, 2009 at 07:37:03AM -0500, Gabor Grothendieck wrote:
> What you are asking for has the potential to create huge data sets
> depending on the time range of the data and N. What are they?   If
> that is the problem then its not just a matter of how memory intensive
> the code is but just about any manipulation will fail.  Do the
> problems arise on the aggregate or moving back and forth between zoo
> and ts?

The object I'm dealing with has 13,667,891 rows and a lot of columns.

I thought it might make sense to:

  thinz <- z[,1]
  figure out the row numbers for the aggregate(blah, tail, 1) operation in thinz
  discretised <- z[therownums,]

So instead of doing an aggregate(blah,tail,1), we'd analyse thinz and
come up with an integer vector therownums, and use that to make the
discretised object.

This would be memory efficient since thinz has only one column.

-- 
Ajay Shah                                      http://www.mayin.org/ajayshah  
ajayshah at mayin.org                             http://ajayshahblog.blogspot.com
<*(:-? - wizard who doesn't know the answer.


From jeff.a.ryan at gmail.com  Fri Nov 27 18:54:20 2009
From: jeff.a.ryan at gmail.com (J Ryan)
Date: Fri, 27 Nov 2009 11:54:20 -0600
Subject: [R-SIG-Finance] Data
In-Reply-To: <53d3e3c70911270803t2d5e93b6m1f9e9fd1ead836b@mail.gmail.com>
References: <53d3e3c70911270803t2d5e93b6m1f9e9fd1ead836b@mail.gmail.com>
Message-ID: <00EE1E18-52F5-4B10-9A84-C557DBF05764@gmail.com>

Every day you have more than 300k equity option prices series. At EOD  
frequency, that is 300k prices. At 1min intervals your looking at 120  
million per day. You can see why it won't be free.

What sort of research are doing?  Do you need end of day?  Book data?   
How much data?  A year, a day, 10 years.

You can use getOptionChain in quantmod to download delayed data from  
yahoo, but that isn't historical.

With option data you'll find that you get what you pay for.

Best,
Jeff

Jeffrey A. Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com

On Nov 27, 2009, at 10:03 AM, Renato Costa <noldo22 at gmail.com> wrote:

> Dear all
>
> I need to get some call option data to compare with some of my  
> simulations.
> Stock prices are easy to find but for options most of the sites I  
> looked for
> it I would have to pay for that.
> Does anyone know if I can get some option prices for free?
>
> Any help is appreciated.
>
> Regards
>
> Renato
>
> -- 
> PhD Student Renato Alencar Adelino da Costa (renato at ele.puc-rio.br)
> Department of Electrical Engineering (Mathematical Finance)
> Pontifical Catholic University (PUC-Rio)
> Rua Marques de Sao Vicente, 225, Sala 604L
> Gavea          CEP: 22453-900
> Rio de Janeiro
> BRASIL
> ( 9 months research at Curtin University of technology: Nov 2008 -  
> July
> 2009)
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From cevans at chyden.net  Fri Nov 27 17:50:31 2009
From: cevans at chyden.net (Charles Evans)
Date: Fri, 27 Nov 2009 11:50:31 -0500
Subject: [R-SIG-Finance] [R-sig-finance] Data
In-Reply-To: <26544564.post@talk.nabble.com>
References: <53d3e3c70911270803t2d5e93b6m1f9e9fd1ead836b@mail.gmail.com>
	<26544564.post@talk.nabble.com>
Message-ID: <4FB05B92-787D-45DA-A68C-55959B52C2FB@chyden.net>

Hi Renato,

If you do not have access to a Bloomberg terminal, you could try  
someone like Trade Station.

http://tradestation.com/default_2.shtm

I do not have personal experience with them, but a colleague used to  
work for them, and he tells me that they have the sort of data that  
you are looking for.  Trade Station charges USD 100 per month, but I  
gather that you can join and cancel after only a month.  Not optimal,  
but when one is a graduate student, one does what one must.

I do not know if R can interface with Trade Station's systems, as it  
can with Bloomberg's.

Alternatively, you could try talking with local brokerages and banks  
in your area, and see if any will provide you with access to data in  
exchange for an acknowledgement of their sponsorship of your research.

I wish that I could be more helpful, but Luwingo is right.  This is  
one of the reasons that I abandoned options as my PhD thesis topic and  
switched to ETFs.

Yours,

C.Evans


On 27 Nov 2009, at 11:20, Luwingo wrote:

>
> Hi Renato- option data is pretty valuable and somewhat complicated.  
> It's
> pretty unlikely that you will be able to find that data for free-  
> especially
> if you're looking for options on certain less liquid stocks. That  
> said, the
> CBOE has data that you can use, as do the CBOT, CME, and NYMEX. You  
> probably
> won't find that data too useful, though, since implied volatility  
> data is
> especially difficult to find for free. The best place you can find  
> this data
> is from any Bloomberg terminal. If you have one in your university,  
> use that
> to download the data onto a spreadsheet for use elsewhere.
>
>
> Feanor22 wrote:
>>
>> Dear all
>>
>> I need to get some call option data to compare with some of my
>> simulations.
>> Stock prices are easy to find but for options most of the sites I  
>> looked
>> for
>> it I would have to pay for that.
>> Does anyone know if I can get some option prices for free?
>>
>> Any help is appreciated.
>>
>> Regards
>>
>> Renato
>>
>> -- 
>> PhD Student Renato Alencar Adelino da Costa (renato at ele.puc-rio.br)
>> Department of Electrical Engineering (Mathematical Finance)
>> Pontifical Catholic University (PUC-Rio)
>> Rua Marques de Sao Vicente, 225, Sala 604L
>> Gavea          CEP: 22453-900
>> Rio de Janeiro
>> BRASIL
>> ( 9 months research at Curtin University of technology: Nov 2008 -  
>> July
>> 2009)
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>>
>
> -- 
> View this message in context: http://old.nabble.com/Data-tp26544402p26544564.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


Most people's superstitions are beyond belief.
C.Nothing


From cmdr_rogue at hotmail.com  Fri Nov 27 19:28:36 2009
From: cmdr_rogue at hotmail.com (Luwingo)
Date: Fri, 27 Nov 2009 10:28:36 -0800 (PST)
Subject: [R-SIG-Finance] [R-sig-finance] How good is Black-Scholes vs
 actual option prices
In-Reply-To: <929455.48091.qm@web25505.mail.ukl.yahoo.com>
References: <929455.48091.qm@web25505.mail.ukl.yahoo.com>
Message-ID: <26545362.post@talk.nabble.com>


Hi Peter- the Black-Scholes-Merton closed-form solution is not a particularly
good approximation to real option prices, because of its inherent
assumptions. The BSM formulation assumes lognormally distributed asset
prices, constant dividend yield/risk-free rate/implied volatility, and
frictionless complete continuous markets. Not one of these assumptions holds
in practice.

However, the beauty of the BSM technique is that it is to a very large
extent self-correcting; that is, one can use the correct inputs to "tweak"
the option price until it most closely approximates the real world, as long
as you never violate risk-neutrality and no-arbitrage principles. In
practice, this means using bootstrapping techniques to build a zero rate
curve from market data, using volatility term structures to find the right
implied volatility, applying credit spreads to the risk-free rate to
preserve risk neutrality using CDS spreads, and possibly adjusting the BSM
formula for non-lognormal prices. I've done the first three in VBA using
FINCAD for mark-to-market accounting purposes.

Regarding the MSCI paper- if they're using options on a monthly basis to
hedge portfolios, the use of the 3M T-bill is not appropriate. I wouldn't
even use Treasury rates for risk-free rates anyway- they're too susceptible
to manipulation and are not "true" market rates. I would use the 1M LIBOR
rate for a monthly hedge, not a 3M rate. It is true that the LIBOR rate is
more of a swap rate, but this is conventional practice in the markets and
those are the rates used for bootstrapping zero curves.

Also, CBOE VIX data are "blended" across a variety of strikes, which means
that the implied volatility for the options used is not the "true" implied
volatility for each option. If you wanted to be really rigourous, you would
use the market implied volatility for a particular strike and, if you have
to smooth things, use a Kalman filter or some other kernel-smoothing
approach.

In answer to your question about the price: the VIX volatility is very
likely to be lower than the true volatility for an out-of-the-money option,
and very likely to be higher for an in-the-money option. So if the option is
far OTM, the price given by the BSM framework will be too low, and if the
option is far ITM, the price will be too high. This isn't a big deal in some
illiquid commodity markets but it's a VERY big deal in highly liquid equity
or rates markets.

I hope all of that helps to answer your question(s).


Peter Mennie wrote:
> 
> MSCI published this report recently:
> http://www.mscibarra.com/resources/pdfs/research/Portfolio_BCP_Nov_2009.pdf
> which basically looks at various methods of mitigating extreme event risk
> for equity portfolios.
> 
> One method they test is to buy options when their indicators suggest
> downside risk.  On pg 13 they mention they they use Black-Scholes to
> estimate the price of these options, using the VIX index as volatility and
> US 3m T-bills for the risk free rate
> 
> I was wondering if anyone had any experience of how accurate this
> assumption is likely to be in practice, and whether in practice the price
> would be likely to be greater or less than this estimate
> 
> Peter Mennie
> 
> 
> 
>       
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
> 

-- 
View this message in context: http://old.nabble.com/How-good-is-Black-Scholes-vs-actual-option-prices-tp26482604p26545362.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From noldo22 at gmail.com  Fri Nov 27 19:30:58 2009
From: noldo22 at gmail.com (Renato Costa)
Date: Fri, 27 Nov 2009 16:30:58 -0200
Subject: [R-SIG-Finance] Data
In-Reply-To: <00EE1E18-52F5-4B10-9A84-C557DBF05764@gmail.com>
References: <53d3e3c70911270803t2d5e93b6m1f9e9fd1ead836b@mail.gmail.com>
	<00EE1E18-52F5-4B10-9A84-C557DBF05764@gmail.com>
Message-ID: <53d3e3c70911271030s69184ee1lace11653368c9ee8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091127/eb621bf3/attachment.pl>

From jeff.a.ryan at gmail.com  Fri Nov 27 19:45:30 2009
From: jeff.a.ryan at gmail.com (J Ryan)
Date: Fri, 27 Nov 2009 12:45:30 -0600
Subject: [R-SIG-Finance] Data
In-Reply-To: <53d3e3c70911271030s69184ee1lace11653368c9ee8@mail.gmail.com>
References: <53d3e3c70911270803t2d5e93b6m1f9e9fd1ead836b@mail.gmail.com>
	<00EE1E18-52F5-4B10-9A84-C557DBF05764@gmail.com>
	<53d3e3c70911271030s69184ee1lace11653368c9ee8@mail.gmail.com>
Message-ID: <F0146AA3-5AC2-413E-95A2-8C6489A2F9CF@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091127/ae59bc6b/attachment.pl>

From ggrothendieck at gmail.com  Fri Nov 27 20:18:51 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 27 Nov 2009 14:18:51 -0500
Subject: [R-SIG-Finance] Discretising intra-day data -- how to get by
	with less memory?
In-Reply-To: <20091127172728.GD1586@ajay-shahs-macbook-pro.local>
References: <20091127115652.GA28980@ajay-shahs-macbook-pro.local> 
	<971536df0911270437ue218d07rf76228eecc0b5beb@mail.gmail.com> 
	<20091127172728.GD1586@ajay-shahs-macbook-pro.local>
Message-ID: <971536df0911271118l56805828u8b4906f1f99d5429@mail.gmail.com>

One other thing to consider is whether you could use zooreg instead of
zoo and in that case you might not need to fill in the gaps:

> z <- zoo(c(11, 13, 14), c(1, 3, 4))
> zz <- as.zooreg(z)
> zz
 1  3  4
11 13 14
> lag(zz)
 0  2  3
11 13 14

Note how time 3 was lagged to become time 2 even though the original
series had no time 2.

On Fri, Nov 27, 2009 at 12:27 PM, Ajay Shah <ajayshah at mayin.org> wrote:
> On Fri, Nov 27, 2009 at 07:37:03AM -0500, Gabor Grothendieck wrote:
>> What you are asking for has the potential to create huge data sets
>> depending on the time range of the data and N. What are they? ? If
>> that is the problem then its not just a matter of how memory intensive
>> the code is but just about any manipulation will fail. ?Do the
>> problems arise on the aggregate or moving back and forth between zoo
>> and ts?
>
> The object I'm dealing with has 13,667,891 rows and a lot of columns.
>
> I thought it might make sense to:
>
> ?thinz <- z[,1]
> ?figure out the row numbers for the aggregate(blah, tail, 1) operation in thinz
> ?discretised <- z[therownums,]
>
> So instead of doing an aggregate(blah,tail,1), we'd analyse thinz and
> come up with an integer vector therownums, and use that to make the
> discretised object.
>
> This would be memory efficient since thinz has only one column.
>
> --
> Ajay Shah ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?http://www.mayin.org/ajayshah
> ajayshah at mayin.org ? ? ? ? ? ? ? ? ? ? ? ? ? ? http://ajayshahblog.blogspot.com
> <*(:-? - wizard who doesn't know the answer.
>


From konradhoppe at hotmail.de  Fri Nov 27 23:37:53 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Fri, 27 Nov 2009 23:37:53 +0100
Subject: [R-SIG-Finance] quantmod addTA() How to scale the y axis
Message-ID: <SNT114-DS15ED9792F1C1E1930E6791D09A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091127/9378e0fb/attachment.pl>

From brian at braverock.com  Sat Nov 28 00:28:42 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 27 Nov 2009 17:28:42 -0600
Subject: [R-SIG-Finance] quantmod addTA() How to scale the y axis
In-Reply-To: <SNT114-DS15ED9792F1C1E1930E6791D09A0@phx.gbl>
References: <SNT114-DS15ED9792F1C1E1930E6791D09A0@phx.gbl>
Message-ID: <4B1060AA.8090304@braverock.com>

Konrad Hoppe wrote:
> Dear mailinglist members,
>
>  
>
> I'm new to the quantmod package and I got some trouble with the addTA()
> method. 
>
> I want to add some indicators in the plot on position 1, hence behind the
> original data. But the indicators are plotted to low, they don't have any
> intersections with the raw-data. 
>
> When I plot both lines with the standard plot function there are some
> intersections and also when I plot the difference between those two series
> on position 0, there are some intersections with the null-line. Hence I'm
> sure that the plot methods got the right data. 
>
> I've already tried the solution with setting the yrange (setting it for all
> plots to the same range), but that doesn't work.
>
> Does anybody have an idea?
>   
Yes, I have an idea.

Please construct a reproducible example, and provide your code.  It is 
nearly impossible to "have an idea" when you've described things in 
broad generalities.  If you take the time to construct an example of 
what you're talking about (disguise your data,create fake data, rename 
your indicators, whatever), then I'm almost certain someone here can 
help you.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From konradhoppe at hotmail.de  Sat Nov 28 14:33:10 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Sat, 28 Nov 2009 14:33:10 +0100
Subject: [R-SIG-Finance] WG:  quantmod addTA() How to scale the y axis
Message-ID: <SNT114-DS2032FE8B5A6A43AC221FC1D0990@phx.gbl>

Okay, I'm sorry. Now I've constructed an example. I would be very glad if
you can help me:

#--------------------------------------------------------#
install.packages("quantmod")
library(quantmod)

#use for example the 200-days average implemented by:

average <- function(thisVector,grad){
	res <- vector(length=length(thisVector))
	for(i in grad:length(res)){
		res[i] <- mean(thisVector[(i-(grad-1)):i], na.rm=T)
	}
	for(i in 1:(grad-1)){
		res[i] <- NA
	}
	return(as.numeric(res))
}

#construct the chartSeries plot and get the data:

from.dat <- as.Date("01/01/03", format="%m/%d/%y")
to.dat <- as.Date(Sys.Date(), format="%m/%d/%y")
getSymbols("BOS3.DE", src="yahoo", from = from.dat, to = to.dat)

chartSeries(BOS3.DE,theme="white",TA=NULL, yrange=c(5,50))
addTA(average(Ad(BOS3.DE),200), on=1,yrange=c(5,50))

# check the correctness of plot by the difference:
addTA(average(Ad(BOS3.DE),200)-Ad(BOS3.DE))

# but that looks quite different compared to:

boss <- as.vector(Ad(BOS3.DE))
plot(boss, type="l" , ylim=c(0,50))
par(new=T)
plot(average(boss,200) , type="l" , ylim=c(0,50),ylab="")
#-------------------------------------------------------------#

Thanks in advance.

Regards
Konrad


-----Urspr?ngliche Nachricht-----
Von: Brian G. Peterson [mailto:brian at braverock.com] 
Gesendet: Samstag, 28. November 2009 00:29
An: Konrad Hoppe
Cc: r-sig-finance at stat.math.ethz.ch
Betreff: Re: [R-SIG-Finance] quantmod addTA() How to scale the y axis

Konrad Hoppe wrote:
> Dear mailinglist members,
>
>  
>
> I'm new to the quantmod package and I got some trouble with the addTA()
> method. 
>
> I want to add some indicators in the plot on position 1, hence behind the
> original data. But the indicators are plotted to low, they don't have any
> intersections with the raw-data. 
>
> When I plot both lines with the standard plot function there are some
> intersections and also when I plot the difference between those two series
> on position 0, there are some intersections with the null-line. Hence I'm
> sure that the plot methods got the right data. 
>
> I've already tried the solution with setting the yrange (setting it for
all
> plots to the same range), but that doesn't work.
>
> Does anybody have an idea?
>   
Yes, I have an idea.

Please construct a reproducible example, and provide your code.  It is 
nearly impossible to "have an idea" when you've described things in 
broad generalities.  If you take the time to construct an example of 
what you're talking about (disguise your data,create fake data, rename 
your indicators, whatever), then I'm almost certain someone here can 
help you.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From josh.m.ulrich at gmail.com  Sat Nov 28 15:27:49 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 28 Nov 2009 08:27:49 -0600
Subject: [R-SIG-Finance] WG: quantmod addTA() How to scale the y axis
In-Reply-To: <SNT114-DS2032FE8B5A6A43AC221FC1D0990@phx.gbl>
References: <SNT114-DS2032FE8B5A6A43AC221FC1D0990@phx.gbl>
Message-ID: <8cca69990911280627u6e38b628k74c33c3cfb9687c2@mail.gmail.com>

Konrad,

There are no intersections because chartSeries() plots the unadjusted
data and you're overlaying an average of the split and dividend
adjusted series.  You need to adjust the raw data before charting.

BOS3.DE <- adjustOHLC(BOS3.DE)
chartSeries(BOS3.DE,theme="white",TA="addSMA(200)", yrange=c(5,50))

Note that "addSMA" replicates your "addTA(average(...))" call by using
the SMA function from TTR.

HTH,
Josh
--
http://www.fosstrading.com



On Sat, Nov 28, 2009 at 7:33 AM, Konrad Hoppe <konradhoppe at hotmail.de> wrote:
> Okay, I'm sorry. Now I've constructed an example. I would be very glad if
> you can help me:
>
> #--------------------------------------------------------#
> install.packages("quantmod")
> library(quantmod)
>
> #use for example the 200-days average implemented by:
>
> average <- function(thisVector,grad){
> ? ? ? ?res <- vector(length=length(thisVector))
> ? ? ? ?for(i in grad:length(res)){
> ? ? ? ? ? ? ? ?res[i] <- mean(thisVector[(i-(grad-1)):i], na.rm=T)
> ? ? ? ?}
> ? ? ? ?for(i in 1:(grad-1)){
> ? ? ? ? ? ? ? ?res[i] <- NA
> ? ? ? ?}
> ? ? ? ?return(as.numeric(res))
> }
>
> #construct the chartSeries plot and get the data:
>
> from.dat <- as.Date("01/01/03", format="%m/%d/%y")
> to.dat <- as.Date(Sys.Date(), format="%m/%d/%y")
> getSymbols("BOS3.DE", src="yahoo", from = from.dat, to = to.dat)
>
> chartSeries(BOS3.DE,theme="white",TA=NULL, yrange=c(5,50))
> addTA(average(Ad(BOS3.DE),200), on=1,yrange=c(5,50))
>
> # check the correctness of plot by the difference:
> addTA(average(Ad(BOS3.DE),200)-Ad(BOS3.DE))
>
> # but that looks quite different compared to:
>
> boss <- as.vector(Ad(BOS3.DE))
> plot(boss, type="l" , ylim=c(0,50))
> par(new=T)
> plot(average(boss,200) , type="l" , ylim=c(0,50),ylab="")
> #-------------------------------------------------------------#
>
> Thanks in advance.
>
> Regards
> Konrad
>
>
> -----Urspr?ngliche Nachricht-----
> Von: Brian G. Peterson [mailto:brian at braverock.com]
> Gesendet: Samstag, 28. November 2009 00:29
> An: Konrad Hoppe
> Cc: r-sig-finance at stat.math.ethz.ch
> Betreff: Re: [R-SIG-Finance] quantmod addTA() How to scale the y axis
>
> Konrad Hoppe wrote:
>> Dear mailinglist members,
>>
>>
>>
>> I'm new to the quantmod package and I got some trouble with the addTA()
>> method.
>>
>> I want to add some indicators in the plot on position 1, hence behind the
>> original data. But the indicators are plotted to low, they don't have any
>> intersections with the raw-data.
>>
>> When I plot both lines with the standard plot function there are some
>> intersections and also when I plot the difference between those two series
>> on position 0, there are some intersections with the null-line. Hence I'm
>> sure that the plot methods got the right data.
>>
>> I've already tried the solution with setting the yrange (setting it for
> all
>> plots to the same range), but that doesn't work.
>>
>> Does anybody have an idea?
>>
> Yes, I have an idea.
>
> Please construct a reproducible example, and provide your code. ?It is
> nearly impossible to "have an idea" when you've described things in
> broad generalities. ?If you take the time to construct an example of
> what you're talking about (disguise your data,create fake data, rename
> your indicators, whatever), then I'm almost certain someone here can
> help you.
>
> Regards,
>
> ? ? - Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From konradhoppe at hotmail.de  Sat Nov 28 15:36:58 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Sat, 28 Nov 2009 15:36:58 +0100
Subject: [R-SIG-Finance] WG: quantmod addTA() How to scale the y axis
In-Reply-To: <8cca69990911280627u6e38b628k74c33c3cfb9687c2@mail.gmail.com>
Message-ID: <SNT114-DS106B2CAE03EE1D64F4D6CCD0990@phx.gbl>

Thank you very much. I haven't seen that point, because I was unsure what
the method plots. 
And the 'addSMA' is a good hint because as I told you I'm new to the package
and actually don't know its whole functionality.

Regards
Konrad

-----Urspr?ngliche Nachricht-----
Von: Joshua Ulrich [mailto:josh.m.ulrich at gmail.com] 
Gesendet: Samstag, 28. November 2009 15:28
An: Konrad Hoppe
Cc: r-sig-finance at stat.math.ethz.ch
Betreff: Re: [R-SIG-Finance] WG: quantmod addTA() How to scale the y axis

Konrad,

There are no intersections because chartSeries() plots the unadjusted
data and you're overlaying an average of the split and dividend
adjusted series.  You need to adjust the raw data before charting.

BOS3.DE <- adjustOHLC(BOS3.DE)
chartSeries(BOS3.DE,theme="white",TA="addSMA(200)", yrange=c(5,50))

Note that "addSMA" replicates your "addTA(average(...))" call by using
the SMA function from TTR.

HTH,
Josh
--
http://www.fosstrading.com



On Sat, Nov 28, 2009 at 7:33 AM, Konrad Hoppe <konradhoppe at hotmail.de>
wrote:
> Okay, I'm sorry. Now I've constructed an example. I would be very glad if
> you can help me:
>
> #--------------------------------------------------------#
> install.packages("quantmod")
> library(quantmod)
>
> #use for example the 200-days average implemented by:
>
> average <- function(thisVector,grad){
> ? ? ? ?res <- vector(length=length(thisVector))
> ? ? ? ?for(i in grad:length(res)){
> ? ? ? ? ? ? ? ?res[i] <- mean(thisVector[(i-(grad-1)):i], na.rm=T)
> ? ? ? ?}
> ? ? ? ?for(i in 1:(grad-1)){
> ? ? ? ? ? ? ? ?res[i] <- NA
> ? ? ? ?}
> ? ? ? ?return(as.numeric(res))
> }
>
> #construct the chartSeries plot and get the data:
>
> from.dat <- as.Date("01/01/03", format="%m/%d/%y")
> to.dat <- as.Date(Sys.Date(), format="%m/%d/%y")
> getSymbols("BOS3.DE", src="yahoo", from = from.dat, to = to.dat)
>
> chartSeries(BOS3.DE,theme="white",TA=NULL, yrange=c(5,50))
> addTA(average(Ad(BOS3.DE),200), on=1,yrange=c(5,50))
>
> # check the correctness of plot by the difference:
> addTA(average(Ad(BOS3.DE),200)-Ad(BOS3.DE))
>
> # but that looks quite different compared to:
>
> boss <- as.vector(Ad(BOS3.DE))
> plot(boss, type="l" , ylim=c(0,50))
> par(new=T)
> plot(average(boss,200) , type="l" , ylim=c(0,50),ylab="")
> #-------------------------------------------------------------#
>
> Thanks in advance.
>
> Regards
> Konrad
>
>
> -----Urspr?ngliche Nachricht-----
> Von: Brian G. Peterson [mailto:brian at braverock.com]
> Gesendet: Samstag, 28. November 2009 00:29
> An: Konrad Hoppe
> Cc: r-sig-finance at stat.math.ethz.ch
> Betreff: Re: [R-SIG-Finance] quantmod addTA() How to scale the y axis
>
> Konrad Hoppe wrote:
>> Dear mailinglist members,
>>
>>
>>
>> I'm new to the quantmod package and I got some trouble with the addTA()
>> method.
>>
>> I want to add some indicators in the plot on position 1, hence behind the
>> original data. But the indicators are plotted to low, they don't have any
>> intersections with the raw-data.
>>
>> When I plot both lines with the standard plot function there are some
>> intersections and also when I plot the difference between those two
series
>> on position 0, there are some intersections with the null-line. Hence I'm
>> sure that the plot methods got the right data.
>>
>> I've already tried the solution with setting the yrange (setting it for
> all
>> plots to the same range), but that doesn't work.
>>
>> Does anybody have an idea?
>>
> Yes, I have an idea.
>
> Please construct a reproducible example, and provide your code. ?It is
> nearly impossible to "have an idea" when you've described things in
> broad generalities. ?If you take the time to construct an example of
> what you're talking about (disguise your data,create fake data, rename
> your indicators, whatever), then I'm almost certain someone here can
> help you.
>
> Regards,
>
> ? ? - Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From konradhoppe at hotmail.de  Sat Nov 28 17:14:19 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Sat, 28 Nov 2009 17:14:19 +0100
Subject: [R-SIG-Finance] WG: quantmod addTA() How to scale the y axis
In-Reply-To: <BLU0-SMTP79B080D1908D09C7D5E02BCA990@phx.gbl>
Message-ID: <SNT114-DS1561836D929A7202EC1904D0990@phx.gbl>

Hello Vince,

The whole code on that is the following:

install.packages("quantmod")
library(quantmod)

from.dat <- as.Date("01/01/03", format="%m/%d/%y")
to.dat <- as.Date(Sys.Date(), format="%m/%d/%y")

getSymbols("BOS3.DE", src="yahoo", from = from.dat, to = to.dat)
BOS3.DE <- adjustOHLC(BOS3.DE)
chartSeries(BOS3.DE,theme="white",TA="addSMA(200)", yrange=c(5,50))


regards
Konrad


-----Urspr?ngliche Nachricht-----
Von: R. Vince [mailto:rvince99 at hotmail.com] 
Gesendet: Samstag, 28. November 2009 15:59
An: Konrad Hoppe; 'Joshua Ulrich'
Cc: r-sig-finance at stat.math.ethz.ch
Betreff: Re: [R-SIG-Finance] WG: quantmod addTA() How to scale the y axis

Konrad,

Can you share your completed code on this with all? Thanks, R. Vince

----- Original Message ----- 
From: "Konrad Hoppe" <konradhoppe at hotmail.de>
To: "'Joshua Ulrich'" <josh.m.ulrich at gmail.com>
Cc: <r-sig-finance at stat.math.ethz.ch>
Sent: Saturday, November 28, 2009 9:36 AM
Subject: Re: [R-SIG-Finance] WG: quantmod addTA() How to scale the y axis


Thank you very much. I haven't seen that point, because I was unsure what
the method plots.
And the 'addSMA' is a good hint because as I told you I'm new to the package
and actually don't know its whole functionality.

Regards
Konrad

-----Urspr?ngliche Nachricht-----
Von: Joshua Ulrich [mailto:josh.m.ulrich at gmail.com]
Gesendet: Samstag, 28. November 2009 15:28
An: Konrad Hoppe
Cc: r-sig-finance at stat.math.ethz.ch
Betreff: Re: [R-SIG-Finance] WG: quantmod addTA() How to scale the y axis

Konrad,

There are no intersections because chartSeries() plots the unadjusted
data and you're overlaying an average of the split and dividend
adjusted series.  You need to adjust the raw data before charting.

BOS3.DE <- adjustOHLC(BOS3.DE)
chartSeries(BOS3.DE,theme="white",TA="addSMA(200)", yrange=c(5,50))

Note that "addSMA" replicates your "addTA(average(...))" call by using
the SMA function from TTR.

HTH,
Josh
--
http://www.fosstrading.com



On Sat, Nov 28, 2009 at 7:33 AM, Konrad Hoppe <konradhoppe at hotmail.de>
wrote:
> Okay, I'm sorry. Now I've constructed an example. I would be very glad if
> you can help me:
>
> #--------------------------------------------------------#
> install.packages("quantmod")
> library(quantmod)
>
> #use for example the 200-days average implemented by:
>
> average <- function(thisVector,grad){
> res <- vector(length=length(thisVector))
> for(i in grad:length(res)){
> res[i] <- mean(thisVector[(i-(grad-1)):i], na.rm=T)
> }
> for(i in 1:(grad-1)){
> res[i] <- NA
> }
> return(as.numeric(res))
> }
>
> #construct the chartSeries plot and get the data:
>
> from.dat <- as.Date("01/01/03", format="%m/%d/%y")
> to.dat <- as.Date(Sys.Date(), format="%m/%d/%y")
> getSymbols("BOS3.DE", src="yahoo", from = from.dat, to = to.dat)
>
> chartSeries(BOS3.DE,theme="white",TA=NULL, yrange=c(5,50))
> addTA(average(Ad(BOS3.DE),200), on=1,yrange=c(5,50))
>
> # check the correctness of plot by the difference:
> addTA(average(Ad(BOS3.DE),200)-Ad(BOS3.DE))
>
> # but that looks quite different compared to:
>
> boss <- as.vector(Ad(BOS3.DE))
> plot(boss, type="l" , ylim=c(0,50))
> par(new=T)
> plot(average(boss,200) , type="l" , ylim=c(0,50),ylab="")
> #-------------------------------------------------------------#
>
> Thanks in advance.
>
> Regards
> Konrad
>
>
> -----Urspr?ngliche Nachricht-----
> Von: Brian G. Peterson [mailto:brian at braverock.com]
> Gesendet: Samstag, 28. November 2009 00:29
> An: Konrad Hoppe
> Cc: r-sig-finance at stat.math.ethz.ch
> Betreff: Re: [R-SIG-Finance] quantmod addTA() How to scale the y axis
>
> Konrad Hoppe wrote:
>> Dear mailinglist members,
>>
>>
>>
>> I'm new to the quantmod package and I got some trouble with the addTA()
>> method.
>>
>> I want to add some indicators in the plot on position 1, hence behind the
>> original data. But the indicators are plotted to low, they don't have any
>> intersections with the raw-data.
>>
>> When I plot both lines with the standard plot function there are some
>> intersections and also when I plot the difference between those two
series
>> on position 0, there are some intersections with the null-line. Hence I'm
>> sure that the plot methods got the right data.
>>
>> I've already tried the solution with setting the yrange (setting it for
> all
>> plots to the same range), but that doesn't work.
>>
>> Does anybody have an idea?
>>
> Yes, I have an idea.
>
> Please construct a reproducible example, and provide your code. It is
> nearly impossible to "have an idea" when you've described things in
> broad generalities. If you take the time to construct an example of
> what you're talking about (disguise your data,create fake data, rename
> your indicators, whatever), then I'm almost certain someone here can
> help you.
>
> Regards,
>
> - Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list

-- Subscriber-posting only.
-- If you want to post, subscribe first.


From brian at braverock.com  Sat Nov 28 14:36:08 2009
From: brian at braverock.com (Brian Peterson)
Date: Sat, 28 Nov 2009 07:36:08 -0600
Subject: [R-SIG-Finance] Fwd: AW: quantmod addTA() How to scale the y axis
Message-ID: <3qynb7nhc2n2bjwk6kwhtrkm.1259415368701@email.android.com>

To the list.  Konrad, thank you for constructing an example.  
I am not currently at a machine with R installed, but I will take a look if no one beats me to your problem.

  - Brian
-------- Original Message --------
Subject: AW: [R-SIG-Finance] quantmod addTA() How to scale the y axis
From: "Konrad Hoppe" <konradhoppe at hotmail.de>
To: "'Brian G. Peterson'" <brian at braverock.com>
CC: 

Okay, I'm sorry. Now I've constructed an example. I would be very glad if
you can help me:

#--------------------------------------------------------#
install.packages("quantmod")
library(quantmod)

#use for example the 200-days average implemented by:

average <- function(thisVector,grad){
	res <- vector(length=length(thisVector))
	for(i in grad:length(res)){
		res[i] <- mean(thisVector[(i-(grad-1)):i], na.rm=T)
	}
	for(i in 1:(grad-1)){
		res[i] <- NA
	}
	return(as.numeric(res))
}

#construct the chartSeries plot and get the data:

from.dat <- as.Date("01/01/03", format="%m/%d/%y")
to.dat <- as.Date(Sys.Date(), format="%m/%d/%y")
getSymbols("BOS3.DE", src="yahoo", from = from.dat, to = to.dat)

chartSeries(BOS3.DE,theme="white",TA=NULL, yrange=c(5,50))
addTA(average(Ad(BOS3.DE),200), on=1,yrange=c(5,50))

# check the correctness of plot by the difference:
addTA(average(Ad(BOS3.DE),200)-Ad(BOS3.DE))

# but that looks quite different compared to:

boss <- as.vector(Ad(BOS3.DE))
plot(boss, type="l" , ylim=c(0,50))
par(new=T)
plot(average(boss,200) , type="l" , ylim=c(0,50),ylab="")
#-------------------------------------------------------------#

Thanks in advance.

Regards
Konrad


-----Urspr?ngliche Nachricht-----
Von: Brian G. Peterson [mailto:brian at braverock.com] 
Gesendet: Samstag, 28. November 2009 00:29
An: Konrad Hoppe
Cc: r-sig-finance at stat.math.ethz.ch
Betreff: Re: [R-SIG-Finance] quantmod addTA() How to scale the y axis

Konrad Hoppe wrote:
> Dear mailinglist members,
>
>  
>
> I'm new to the quantmod package and I got some trouble with the addTA()
> method. 
>
> I want to add some indicators in the plot on position 1, hence behind the
> original data. But the indicators are plotted to low, they don't have any
> intersections with the raw-data. 
>
> When I plot both lines with the standard plot function there are some
> intersections and also when I plot the difference between those two series
> on position 0, there are some intersections with the null-line. Hence I'm
> sure that the plot methods got the right data. 
>
> I've already tried the solution with setting the yrange (setting it for
all
> plots to the same range), but that doesn't work.
>
> Does anybody have an idea?
>   
Yes, I have an idea.

Please construct a reproducible example, and provide your code.  It is 
nearly impossible to "have an idea" when you've described things in 
broad generalities.  If you take the time to construct an example of 
what you're talking about (disguise your data,create fake data, rename 
your indicators, whatever), then I'm almost certain someone here can 
help you.


--
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

From arun.kumar.saha at gmail.com  Mon Nov 30 12:24:44 2009
From: arun.kumar.saha at gmail.com (Arun.stat)
Date: Mon, 30 Nov 2009 03:24:44 -0800 (PST)
Subject: [R-SIG-Finance] Quantmod: getFin; getFinancials
In-Reply-To: <1259553998828-931050.post@n4.nabble.com>
References: <1259553998828-931050.post@n4.nabble.com>
Message-ID: <1259580284210-931194.post@n4.nabble.com>


Use following :

library(quantmod)
> getSymbols('AAPL')
[1] "AAPL"


Best,


km wrote:
> 
> Hi All:
> 
> I get the following error when I issue the getFin command:
> 
>> getFin('AAPL')
> Error in getFin("AAPL") : subscript out of bounds
> 
> I would appreciate any help.
> 
> Thanks in advance,
> Krish
> 
> *************************************************************************************
> Additional Info:
>                 Information on package 'quantmod'
> 
> Description:
> 
> Package:            quantmod
> Type:               Package
> Title:              Quantitative Financial Modelling Framework
> Version:            0.3-13
> Date:               2009-10-14
> Author:             Jeffrey A. Ryan
> Depends:            methods,xts(>= 0.6-7),zoo,Defaults,TTR(>= 0.2)
> Suggests:           DBI,RMySQL,RSQLite,fSeries,its
> Maintainer:         Jeffrey A. Ryan <jeff.a.ryan at gmail.com>
> Description:        Specify, build, trade, and analyse quantitative
>                     financial trading strategies
> LazyLoad:           yes
> License:            GPL-3
> URL:                http://www.quantmod.com
>                     http://r-forge.r-project.org/projects/quantmod
> Packaged:           2009-10-31 15:33:39 UTC; jryan
> Repository:         CRAN
> Date/Publication:   2009-11-01 17:33:52
> Built:              R 2.10.0; ; 2009-11-25 13:35:06 UTC; windows
> 
> 

-- 
View this message in context: http://n4.nabble.com/Quantmod-getFin-getFinancials-tp931050p931194.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From konradhoppe at hotmail.de  Mon Nov 30 13:27:13 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Mon, 30 Nov 2009 13:27:13 +0100
Subject: [R-SIG-Finance] Quantmod: getFin; getFinancials
In-Reply-To: <1259580284210-931194.post@n4.nabble.com>
Message-ID: <SNT114-DS23CA3E81F9CEFED189224FD0970@phx.gbl>

Hi,

but getSymbols() does have another functionality?!
Is it possible to get the financial data from the dataset returned from the
getSymbols() method? And I mean with financial data for example the
quarterly results.

Regards

-----Urspr?ngliche Nachricht-----
Von: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] Im Auftrag von Arun.stat
Gesendet: Montag, 30. November 2009 12:25
An: r-sig-finance at stat.math.ethz.ch
Betreff: Re: [R-SIG-Finance] Quantmod: getFin; getFinancials


Use following :

library(quantmod)
> getSymbols('AAPL')
[1] "AAPL"


Best,


km wrote:
> 
> Hi All:
> 
> I get the following error when I issue the getFin command:
> 
>> getFin('AAPL')
> Error in getFin("AAPL") : subscript out of bounds
> 
> I would appreciate any help.
> 
> Thanks in advance,
> Krish
> 
>
****************************************************************************
*********
> Additional Info:
>                 Information on package 'quantmod'
> 
> Description:
> 
> Package:            quantmod
> Type:               Package
> Title:              Quantitative Financial Modelling Framework
> Version:            0.3-13
> Date:               2009-10-14
> Author:             Jeffrey A. Ryan
> Depends:            methods,xts(>= 0.6-7),zoo,Defaults,TTR(>= 0.2)
> Suggests:           DBI,RMySQL,RSQLite,fSeries,its
> Maintainer:         Jeffrey A. Ryan <jeff.a.ryan at gmail.com>
> Description:        Specify, build, trade, and analyse quantitative
>                     financial trading strategies
> LazyLoad:           yes
> License:            GPL-3
> URL:                http://www.quantmod.com
>                     http://r-forge.r-project.org/projects/quantmod
> Packaged:           2009-10-31 15:33:39 UTC; jryan
> Repository:         CRAN
> Date/Publication:   2009-11-01 17:33:52
> Built:              R 2.10.0; ; 2009-11-25 13:35:06 UTC; windows
> 
> 

-- 
View this message in context:

Sent from the Rmetrics mailing list archive at Nabble.com.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list

-- Subscriber-posting only.
-- If you want to post, subscribe first.


From krish.maheswaran at gmail.com  Tue Dec  1 03:25:53 2009
From: krish.maheswaran at gmail.com (Krishnan Maheswaran)
Date: Mon, 30 Nov 2009 21:25:53 -0500
Subject: [R-SIG-Finance] Quantmod: getFin; getFinancials
Message-ID: <fc85ab5b0911301825r2ee22c2ar4fd41050d080cd1b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091130/e92242e8/attachment.pl>

From jeff.a.ryan at gmail.com  Tue Dec  1 04:16:45 2009
From: jeff.a.ryan at gmail.com (J Ryan)
Date: Mon, 30 Nov 2009 21:16:45 -0600
Subject: [R-SIG-Finance] Quantmod: getFin; getFinancials
In-Reply-To: <fc85ab5b0911301825r2ee22c2ar4fd41050d080cd1b@mail.gmail.com>
References: <fc85ab5b0911301825r2ee22c2ar4fd41050d080cd1b@mail.gmail.com>
Message-ID: <2BA8E482-361F-446B-8FBC-D8A8F4642EC8@gmail.com>

Hi Krish,

I noticed this last week. It is due to an internal change in the  
google results that quantmod uses.

I should have a fix soon, just haven't had a chance since discovering  
it.

Thanks for the report.

Jeff

Jeffrey A. Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com

On Nov 30, 2009, at 8:25 PM, Krishnan Maheswaran <krish.maheswaran at gmail.com 
 > wrote:

> HiHi  All:
>
> Apologies for re-posting. I did not properly subscribe to the Rmetrics
> group.
>
>
> I get the following error when I issue the getFin command:
>
>> getFin('AAPL')
> Error in getFin("AAPL") : subscript out of bounds
>
> I would appreciate any help.
>
> Thanks in advance,
> Krish
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From r.rote12 at googlemail.com  Tue Dec  1 10:18:28 2009
From: r.rote12 at googlemail.com (Peter Rote)
Date: Tue, 1 Dec 2009 10:18:28 +0100
Subject: [R-SIG-Finance] Date problem
Message-ID: <c68c5d80912010118o40fbcc57hec5dc80fa24cd0d9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091201/a725e805/attachment.pl>

From sandor.benczik at crabel.ro  Tue Dec  1 10:35:16 2009
From: sandor.benczik at crabel.ro (Benczik Sandor)
Date: Tue, 01 Dec 2009 11:35:16 +0200
Subject: [R-SIG-Finance] Date problem
In-Reply-To: <c68c5d80912010118o40fbcc57hec5dc80fa24cd0d9@mail.gmail.com>
References: <c68c5d80912010118o40fbcc57hec5dc80fa24cd0d9@mail.gmail.com>
Message-ID: <1259660116.3761.22.camel@localhost.localdomain>

Read these help pages:
?as.Date
?strptime
?as.POSIXct

as.Date("January 1 16:00:00 2009", format="%B %d %k:%M:%S %Y")

HTH,
Sandor

On Tue, 2009-12-01 at 10:18 +0100, Peter Rote wrote:
> Hello everybody,
> 
> I'm loading data from Oanda trade Statistics (CSV File).
> 
>                     Date   Balance
> 1  January 1 16:00:00 2009 25980.34
> 2  January 2 16:00:00 2009 25480.22
> 3  January 3 16:00:00 2009 25580.24
> 4  January 4 16:00:00 2009 25680.31
> 
> How can I change the Date Column to a R Date format (Y-M-D Time)
> 
> Thanks you
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From konradhoppe at hotmail.de  Wed Dec  2 16:55:13 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Wed, 2 Dec 2009 16:55:13 +0100
Subject: [R-SIG-Finance] princomp(): how to get the component's names
Message-ID: <SNT114-DS138862B622DB7AC2930981D0950@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091202/e3484171/attachment.pl>

From Zeno.Adams at ebs.edu  Wed Dec  2 17:27:49 2009
From: Zeno.Adams at ebs.edu (Adams, Zeno)
Date: Wed, 2 Dec 2009 17:27:49 +0100
Subject: [R-SIG-Finance] princomp(): how to get the component's names
In-Reply-To: <SNT114-DS138862B622DB7AC2930981D0950@phx.gbl>
References: <SNT114-DS138862B622DB7AC2930981D0950@phx.gbl>
Message-ID: <9064522880125945B98983BBAECBA1CC98563F@exchsrv001.ebs.local>

You can look at the loadings by using summary(pca, loadings = TRUE)

In your case x,y, and z are uncorrelated so that each principal component has 100% loading on one factor but zero on all the others.

If you modify your example a little so that the series are at least somewhat correlated, e.g.
^
x <- 1:300 + rnorm(300)

y <- 0.8*x + runif(300)

z <- 0.2*x + rnorm(300, mean=10, sd=5)

dat <- data.frame(x,y,z)

pca <- princomp(dat, corr=T)


then

s <- summary(pca, loading = TRUE)

will give you more meaningful loadings.

For instance, if you are interested in creating an index of the three series you could use the command

PC1 <- as.matrix(dat) %*% as.matrix(loadings(s)[,1]/sum(loadings(s)[,1]))
(this is probably not the most elegant way of doing it, but I cant see a shorter way at the moment)

plot(x, type = "l")
lines(y, type = "l", col = 2)
lines(z, type = "l", col = 3)
lines(PC1, type = "l", col = 4, lty = 2, lwd = 2)


hope this helps

Zeno



-----Urspr?ngliche Nachricht-----
Von: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] Im Auftrag von Konrad Hoppe
Gesendet: Mittwoch, 2. Dezember 2009 16:55
An: r-sig-finance at stat.math.ethz.ch
Betreff: [R-SIG-Finance] princomp(): how to get the component's names

Dear mailing list members,

 

I got a question about principal component analysis. I know that's not the
main topic here, but perhaps somebody have used it already. I'm wondering
how to get the names of the particular components.

 

Let me give you an example:

 

x <- rnorm(300)

y <- runif(300)

z <- rnorm(300, mean=10, sd=5)

dat <- data.frame(x,y,z)

pca <- princomp(dat, corr=T)

summary(pca)

 

and now I would like to know which is for example the first component?

Can anybody help me?

 

regards


	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.

EBS European Business School gemeinnuetzige GmbH - Sitz der Gesellschaft: Wiesbaden, Amtsgericht Wiesbaden HRB 19951 - Umsatzsteuer-ID DE 113891213 Geschaeftsfuehrer: Prof. Dr. Christopher Jahns,  Praesident; Prof. Dr. Rolf Tilmes, Dekan; Sabine Fuchs, CMO; Aufsichtsrat: Dr. Hellmut K. Albrecht, Vorsitzender

From konradhoppe at hotmail.de  Wed Dec  2 18:43:17 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Wed, 2 Dec 2009 18:43:17 +0100
Subject: [R-SIG-Finance] princomp(): how to get the component's names
In-Reply-To: <9064522880125945B98983BBAECBA1CC98563F@exchsrv001.ebs.local>
References: <SNT114-DS138862B622DB7AC2930981D0950@phx.gbl>,
	<9064522880125945B98983BBAECBA1CC98563F@exchsrv001.ebs.local>
Message-ID: <SNT114-W14CBD37A66C83A9FA1D6B3D0950@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091202/172b3d7b/attachment.pl>

From jorge.nieves at moorecap.com  Fri Dec  4 16:16:37 2009
From: jorge.nieves at moorecap.com (Jorge Nieves)
Date: Fri, 4 Dec 2009 10:16:37 -0500
Subject: [R-SIG-Finance] Portfolio optimization & PCA
Message-ID: <D595C0E05185614C90515F1E8A2D4CBF060B3E43@NYC-XCH3.win.moorecap.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091204/9e1a460d/attachment.pl>

From konradhoppe at hotmail.de  Fri Dec  4 16:32:29 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Fri, 4 Dec 2009 16:32:29 +0100
Subject: [R-SIG-Finance] Portfolio optimization & PCA
In-Reply-To: <D595C0E05185614C90515F1E8A2D4CBF060B3E43@NYC-XCH3.win.moorecap.com>
References: <D595C0E05185614C90515F1E8A2D4CBF060B3E43@NYC-XCH3.win.moorecap.com>
Message-ID: <SNT114-W5030B5DB4FF7C9685AFF32D0930@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091204/69993311/attachment.pl>

From ngottlieb at marinercapital.com  Fri Dec  4 22:59:56 2009
From: ngottlieb at marinercapital.com (Gottlieb, Neil)
Date: Fri, 4 Dec 2009 16:59:56 -0500
Subject: [R-SIG-Finance] Portfolio optimization & PCA
In-Reply-To: <D595C0E05185614C90515F1E8A2D4CBF060B3E43@NYC-XCH3.win.moorecap.com>
References: <D595C0E05185614C90515F1E8A2D4CBF060B3E43@NYC-XCH3.win.moorecap.com>
Message-ID: <5AB6B736E9303149B6928CB914961831631B96F80C@500MAILBOX.goldbox.com>

Jorge:

There is a lot of work on using PCA to reduce the correlation matrix.

It has been a very long time, since I did such work however...

Most do PCA and then to an promax rotation to make the resulting factor set
orthogonal. Also some using a sample technique such as EM to build the correlation
Matrix rather than do it all at once. 

Try a search on EM Applications. That firm has done such work. 
Also these 2 papers might be of interest.

This search string in google returns plenty: "promax rotation factor analysis"

Hope this helps a bit!

Neil

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Jorge Nieves
Sent: Friday, December 04, 2009 10:17 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] Portfolio optimization & PCA

Hi,

I have a portfolio of securities that I like to determine the optimal
asset allocation using something simple as Markowitz (Mean-Variance). I
have the problem that some of the securities in the portfolio are highly
correlated. I would like to reduce my security set, or covariance matrix
before running the optimization, using something like PCA or clustering.
I was wondering if someone has done any work that might shed some like
on the process.? Is there piece of literature that some one can
recommend?

Thanks,

Jorge Nieves



	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: StroynyRowe.pdf
Type: application/pdf
Size: 152000 bytes
Desc: StroynyRowe.pdf
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091204/0cbfcbb3/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ACombinedLinearModel.pdf
Type: application/pdf
Size: 90849 bytes
Desc: ACombinedLinearModel.pdf
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091204/0cbfcbb3/attachment-0001.pdf>

From guillaume.yziquel at citycable.ch  Sat Dec  5 01:38:50 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Sat, 05 Dec 2009 01:38:50 +0100
Subject: [R-SIG-Finance] getSymbols is zoo or xts?
Message-ID: <4B19AB9A.3010109@citycable.ch>

Hello.

I'm currently wrapping up quantmod to Objective Caml using the OCaml-R 
binding I've recently been creating. It seems to be working fine, but 
I'm currently wondering things about the S3 typing of quotes retrieved 
via getSymbols.

> # show (R.s3_class yahoo);;
> - : R.PrettyTypes.t = STRINGS ["xts"; "zoo"]

It seems that getSymbols returns xts time series, but in the 
documentation, I only see zoo mentionned as output returned by getSymbols.

Should I assume that getSymbols returns zoo time series by default, or 
is it sytematically returning xts time series?

All the best,

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From jeff.a.ryan at gmail.com  Sat Dec  5 02:03:59 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 4 Dec 2009 19:03:59 -0600
Subject: [R-SIG-Finance] getSymbols is zoo or xts?
In-Reply-To: <4B19AB9A.3010109@citycable.ch>
References: <4B19AB9A.3010109@citycable.ch>
Message-ID: <e8e755250912041703x578b8322wca43779467a40deb@mail.gmail.com>

Hi Guillaume,

It depends on the ultimate getSymbols call (e.g. getSymbols.yahoo or
getSymbols.rda...) but most return xts.

Docs indicate an xts object with getSymbols.yahoo, though this is
settable with return.class=  Can be almost any time-series class.

Make sure you have the most recent documentation (i.e. using the docs
with the package, not the ones at quantmod.com or elsewhere).

Best,
Jeff

On Fri, Dec 4, 2009 at 6:38 PM, Guillaume Yziquel
<guillaume.yziquel at citycable.ch> wrote:
> Hello.
>
> I'm currently wrapping up quantmod to Objective Caml using the OCaml-R
> binding I've recently been creating. It seems to be working fine, but I'm
> currently wondering things about the S3 typing of quotes retrieved via
> getSymbols.
>
>> # show (R.s3_class yahoo);;
>> - : R.PrettyTypes.t = STRINGS ["xts"; "zoo"]
>
> It seems that getSymbols returns xts time series, but in the documentation,
> I only see zoo mentionned as output returned by getSymbols.
>
> Should I assume that getSymbols returns zoo time series by default, or is it
> sytematically returning xts time series?
>
> All the best,
>
> --
> ? ? Guillaume Yziquel
> http://yziquel.homelinux.org/
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From guillaume.yziquel at citycable.ch  Sat Dec  5 02:17:43 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Sat, 05 Dec 2009 02:17:43 +0100
Subject: [R-SIG-Finance] getSymbols is zoo or xts?
In-Reply-To: <e8e755250912041703x578b8322wca43779467a40deb@mail.gmail.com>
References: <4B19AB9A.3010109@citycable.ch>
	<e8e755250912041703x578b8322wca43779467a40deb@mail.gmail.com>
Message-ID: <4B19B4B7.70605@citycable.ch>

Jeff Ryan a ?crit :
> Hi Guillaume,
> 
> It depends on the ultimate getSymbols call (e.g. getSymbols.yahoo or
> getSymbols.rda...) but most return xts.

So, as far as I understand it, it mostly returns xts, but if I want to 
be conservative, zoo is guaranteed.

> Docs indicate an xts object with getSymbols.yahoo, though this is
> settable with return.class=  Can be almost any time-series class.

Yes, I saw that. I will have to think of a scheme to cleanly and 
correctly map this kind of dynamic typing to OCaml's static typing. This 
kind of problem is likely to happen often with OCaml-R.

> Make sure you have the most recent documentation (i.e. using the docs
> with the package, not the ones at quantmod.com or elsewhere).

I was indeed using help(getSymbols).

> Best,
> Jeff

Thanks a lot for the quick feedback.

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From jeff.a.ryan at gmail.com  Sat Dec  5 02:26:52 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 4 Dec 2009 19:26:52 -0600
Subject: [R-SIG-Finance] getSymbols is zoo or xts?
In-Reply-To: <4B19B4B7.70605@citycable.ch>
References: <4B19AB9A.3010109@citycable.ch>
	<e8e755250912041703x578b8322wca43779467a40deb@mail.gmail.com>
	<4B19B4B7.70605@citycable.ch>
Message-ID: <e8e755250912041726x781caabfm71fc7ff0e69f78d7@mail.gmail.com>

I don't know if guaranteed is correct.  I'd say it is xts more often
than not, but when 'not' it is zoo.

I think I would say xts to be conservative, but I certainly don't
understand your problem completely, so I am afraid I cannot be of more
help.

Jeff

On Fri, Dec 4, 2009 at 7:17 PM, Guillaume Yziquel
<guillaume.yziquel at citycable.ch> wrote:
> Jeff Ryan a ?crit :
>>
>> Hi Guillaume,
>>
>> It depends on the ultimate getSymbols call (e.g. getSymbols.yahoo or
>> getSymbols.rda...) but most return xts.
>
> So, as far as I understand it, it mostly returns xts, but if I want to be
> conservative, zoo is guaranteed.
>
>> Docs indicate an xts object with getSymbols.yahoo, though this is
>> settable with return.class= ?Can be almost any time-series class.
>
> Yes, I saw that. I will have to think of a scheme to cleanly and correctly
> map this kind of dynamic typing to OCaml's static typing. This kind of
> problem is likely to happen often with OCaml-R.
>
>> Make sure you have the most recent documentation (i.e. using the docs
>> with the package, not the ones at quantmod.com or elsewhere).
>
> I was indeed using help(getSymbols).
>
>> Best,
>> Jeff
>
> Thanks a lot for the quick feedback.
>
> --
> ? ? Guillaume Yziquel
> http://yziquel.homelinux.org/
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From guillaume.yziquel at citycable.ch  Sat Dec  5 02:42:59 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Sat, 05 Dec 2009 02:42:59 +0100
Subject: [R-SIG-Finance] getSymbols is zoo or xts?
In-Reply-To: <e8e755250912041726x781caabfm71fc7ff0e69f78d7@mail.gmail.com>
References: <4B19AB9A.3010109@citycable.ch>	
	<e8e755250912041703x578b8322wca43779467a40deb@mail.gmail.com>	
	<4B19B4B7.70605@citycable.ch>
	<e8e755250912041726x781caabfm71fc7ff0e69f78d7@mail.gmail.com>
Message-ID: <4B19BAA3.5000808@citycable.ch>

Jeff Ryan a ?crit :
> I don't know if guaranteed is correct.  I'd say it is xts more often
> than not, but when 'not' it is zoo.
> 
> I think I would say xts to be conservative, but I certainly don't
> understand your problem completely, so I am afraid I cannot be of more
> help.

My problem is very simple: I have to give a type to the timeseries 
object I receive. No type checking will be done at runtime (like Python, 
R). Only type checking at compile time (like C, C++, Java).

So I have to know what the type of the timeseries will be. zoo or xts?

As I understand it, xts is built over zoo. If that means that all zoo 
attributes and methods have the same semantics in xts, then I'd rather 
go for zoo. To be conservative.

Because if I type getSymbol's "output" as an xts timeseries, I will have to:

-1- make a type check at runtime, which isn't really sexy,

-2- if I get a zoo timeseries instead of an xts one, I'll have to throw 
and catch an exception at runtime, which would be cumbersome.

That's my issue: Type safety in OCaml.

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From hubert.colt at gmail.com  Sat Dec  5 14:58:24 2009
From: hubert.colt at gmail.com (Hubert Colt)
Date: Sat, 5 Dec 2009 14:58:24 +0100
Subject: [R-SIG-Finance] Which Kalman filter?
Message-ID: <be6b11010912050558y4076087do6ed55959c3b0f52b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091205/454ff00f/attachment.pl>

From ggrothendieck at gmail.com  Sat Dec  5 15:12:48 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 5 Dec 2009 09:12:48 -0500
Subject: [R-SIG-Finance] Which Kalman filter?
In-Reply-To: <be6b11010912050558y4076087do6ed55959c3b0f52b@mail.gmail.com>
References: <be6b11010912050558y4076087do6ed55959c3b0f52b@mail.gmail.com>
Message-ID: <971536df0912050612o20bf8bbr737d60d388b4bcd3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091205/bbd7b516/attachment.pl>

From markleeds at verizon.net  Sat Dec  5 21:17:53 2009
From: markleeds at verizon.net (markleeds at verizon.net)
Date: Sat, 05 Dec 2009 14:17:53 -0600 (CST)
Subject: [R-SIG-Finance] Which Kalman filter?
Message-ID: <664634252.143965.1260044273235.JavaMail.root@vms228.mailsrvcs.net>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091205/6bee450e/attachment.html>

From n_torenvliet at hotmail.com  Sun Dec  6 02:10:46 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Sat, 5 Dec 2009 20:10:46 -0500
Subject: [R-SIG-Finance] Time Series For ohlcPlot
Message-ID: <BAY143-W5308CCD59511E2C01DAC1FE910@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091205/0cdc6d00/attachment.pl>

From jeff.a.ryan at gmail.com  Sun Dec  6 03:16:23 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sat, 5 Dec 2009 20:16:23 -0600
Subject: [R-SIG-Finance] Time Series For ohlcPlot
In-Reply-To: <BAY143-W5308CCD59511E2C01DAC1FE910@phx.gbl>
References: <BAY143-W5308CCD59511E2C01DAC1FE910@phx.gbl>
Message-ID: <e8e755250912051816o74ce9a25hb2a40133db8235db@mail.gmail.com>

Hi Nick,

A more flexible visualization of OHLC data is available in quantmod.

See:

http://www.quantmod.com/examples/charting/

Assuming a data.frame you can do something like:

x <- xts(table[,-1], order.by=as.POSIXct(table[,1]))

Then:

barChart(x) OR
chartSeries(x)

HTH
Jeff

On Sat, Dec 5, 2009 at 7:10 PM, Nick Torenvliet
<n_torenvliet at hotmail.com> wrote:
>
> Hi,
>
> I've got daily historical ohlc data in a MySQL db.
>
> I can get the data into R and manage to get a data.frame that looks like this
>
>> table
> ? ?Date ? ? ? ? ? ? ? ? ? ? ? ? ? ?Open ? High ?Low ? ? Close
> 1 ?2009-12-04 00:00:00 ? 62.38 ? 63.37 ?61.53 ? ?62.06
> 2 ?2009-12-03 00:00:00 ? 63.00 ? 63.00 ?61.51 ? ?61.53
> 3 ?2009-12-02 00:00:00 ? 62.73 ? 64.18 ?62.45 ? ?62.88
> 4 ?2009-12-01 00:00:00 ? 61.37 ? 63.05 ?61.12 ? ?62.61
> 5 ?2009-11-30 00:00:00 ? 61.50 ? 62.93 ?60.92 ? ?60.97
> 6 ?2009-11-27 00:00:00 ? 61.80 ? 62.58 ?61.40 ? ?61.45
> 7 ?2009-11-26 00:00:00 ? 62.34 ? 62.39 ?61.51 ? ?61.60
> 8 ?2009-11-25 00:00:00 ? 62.70 ? 63.15 ?62.42 ? ?62.52
> 9 ?2009-11-24 00:00:00 ? 63.31 ? 63.43 ?62.69 ? ?62.98
> 10 2009-11-23 00:00:00 ? 64.10 ? 64.88 ?63.10 ? ?63.47
> 11 2009-11-20 00:00:00 ? 62.05 ? 64.25 ?61.90 ? ?63.66
> 12 2009-11-19 00:00:00 ? 63.00 ? 63.22 ?61.88 ? ?62.71
> 13 2009-11-18 00:00:00 ? 64.01 ? 64.01 ?62.52 ? ?63.25
> 14 2009-11-17 00:00:00 ? 64.57 ? 66.00 ?64.22 ? ?64.53
> 15 2009-11-16 00:00:00 ? 66.27 ? 66.27 ?63.69 ? ?64.25
> 16 2009-11-13 00:00:00 ? 66.57 ? 66.57 ?65.13 ? ?65.95
> 17 2009-11-12 00:00:00 ? 67.79 ? 68.13 ?66.22 ? ?66.63
> 18 2009-11-11 00:00:00 ? 67.73 ? 68.00 ?66.82 ? ?67.78
> 19 2009-11-10 00:00:00 ? 65.10 ? 67.98 ?65.10 ? ?66.80
> 20 2009-11-09 00:00:00 ? 62.77 ? 65.30 ?62.11 ? ?65.06
> 21 2009-11-06 00:00:00 ? 61.54 ? 63.30 ?60.59 ? ?63.20
> 22 2009-11-05 00:00:00 ? 62.93 ? 63.39 ?61.00 ? ?61.65
> 23 2009-11-04 00:00:00 ? 64.30 ? 64.30 ?61.14 ? ?61.39
> 24 2009-11-03 00:00:00 ? 59.83 ? 64.14 ?59.79 ? ?63.89
> 25 2009-11-02 00:00:00 ? 61.52 ? 61.52 ?58.64 ? ?60.15
>
> That was this morning, I've been struggling all day with time series concepts...
>
> Two Questions...
>
> 1/ How can get table into a time series object (usable with ohlcPlot)?
>
> Nick
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From ajayshah at mayin.org  Sun Dec  6 15:24:00 2009
From: ajayshah at mayin.org (Ajay Shah)
Date: Sun, 6 Dec 2009 19:54:00 +0530
Subject: [R-SIG-Finance] SUMMARY: Reducing an intra-day dataset into one obs
	per second
Message-ID: <20091206142400.GA31007@ajay-shahs-macbook-pro.local>

I was faced with the following problem:

  There is a zoo object containing intra-day data, where certain
  columns of information are observed at sub-second resolution. We
  want to reduce it to one record per second, containing the last
  record observed within each second. If there is no information for
  one full second, then an empty record containing NAs should be
  emitted.

For an example of this data, say
  library(zoo)
  load(url("http://www.mayin.org/ajayshah/tmp/demo.rda"))
  options("digits.secs"=6)
  head(b)
  tail(b)

The zoo object `b' in demo.rda happens to have 99,298 rows, 86 columns
and occupies 72 Megabytes of core. So it's a bulky object - and is
typical of the stuff happening on the top 20 exchanges in the world.

The immense genius of Gabor Grothendieck and Jeff Ryan guided me to
solutions that were incredibly better than mine. At
https://stat.ethz.ch/pipermail/r-sig-finance/2009q4/005144.html is an
earlier discussion on this same problem, but after that a good chunk
of conversation shifted to email. The results of this are summarised
here. After the code is some analysis of performance.

-----------------------------------------------snipsnipsnip------------------
    library(xts)
    
    print(load(url("http://www.mayin.org/ajayshah/tmp/demo.rda")))
    
    soln1 <- function(z) {
      # Note that x[1] - as.numeric(x[1]) is the origin (1970-01-01)
      toNsec <- function(x, Nsec = 1) Nsec * floor(as.numeric(x) / Nsec + 1.e-7) + (x[1] - as.numeric(x[1]))
    
      # aggregate by seconds
      d <- aggregate(z, toNsec, tail, 1)
    
      merge(d, zoo(, seq(start(d), end(d), "sec")))
    }
    
    # We aggregate 1:NROW(z) instead of z
    soln2 <- function(z) {
      # Note that x[1] - as.numeric(x[1]) is the origin (1970-01-01)
      toNsec <- function(x, Nsec = 1) Nsec * floor(as.numeric(x) / Nsec + 1e-7) + (x[1] - as.numeric(x[1]))
    
      # aggregate 1:nrow(z) by seconds - ix picks last among all at same time
      ix <- aggregate(zoo(seq_len(NROW(z))), toNsec(time(z)), tail, 1)
    
      # apply ix and merge onto grid - uses [,] so z must be 2d
      merge(zoo(coredata(z)[coredata(ix), ], time(ix)), zoo(, seq(start(ix), end(ix), "sec")))
    }
    
    # Use as.integer and duplicated instead of toNsec and aggregate.zoo
    soln3 <- function(b) {
    
      # discretize time into one second bins
      st <- start(b)
      time(b) <- as.integer(time(b)+1e-7) + st - as.numeric(st)
    
      ## find index of last value in each one second interval
      ix <- !duplicated(time(b), fromLast = TRUE)
    
      ## merge with grid
      merge(b[ix], zoo(, seq(start(b), end(b), "sec")))
    }
    
    # xts version by Jeff Ryan
    soln4 <- function(z, Nsec) {
      bx.1s <- align.time(z, Nsec)
      time(bx.1s) <- time(bx.1s) + 1
      merge(bx.1s[endpoints(bx.1s,"secs")], seq(start(bx.1s),end(bx.1s),by="secs"))
    }
    
    # Measure performance
    gc(reset=TRUE)
    cost.1 <- system.time({res.1 <- soln1(b)})
    gc(reset=TRUE)
    cost.2 <- system.time({res.2 <- soln2(b)})
    gc(reset=TRUE)
    cost.3 <- system.time({res.3 <- soln3(b)})
    gc(reset=TRUE)
    xts.conversion.cost <- system.time({bx <- as.xts(b)})
    cost.4 <- system.time({res.4 <- soln4(bx,1)})
    gc(reset=TRUE)
    
    cost.1/cost.2
    cost.1/cost.3
    cost.1/cost.4
    cost.1/(cost.4+xts.conversion.cost)
    
    summary <- rbind(cost.1, cost.2, cost.3, cost.4, xts.conversion.cost)[,1:3]
    rownames(summary) <- c("Soln1","Soln2","Soln3", "XTS","XTS Conversion")
    summary
    
    # Verify correctness
    nc <- ncol(b)
    all.equal(res.1, res.2, check.attributes = FALSE)
    all.equal(res.2, res.3, check.attributes = FALSE)
    all.equal(unclass(res.3), unclass(res.4), check.attributes = FALSE)

-----------------------------------------------snipsnipsnip------------------

Now here's the performance on my machine - a Macbook Pro with a Intel
Core 2 Duo processor running at 2.53 GHz. There is 4G of RAM so memory
isn't a constraint on this one -- for this small demo.rda. For
realistic problems I am finding memory to be a HUGE constraint, so
efficiency in use of memory is a crucial issue.

The cost seen on my machine is:

               user.self sys.self elapsed
Soln1             66.832    4.954  74.551
Soln2              1.566    0.437   2.069
Soln3              0.547    0.483   1.057
XTS                0.316    0.331   0.665
XTS Conversion     0.900    0.816   1.757

What do we see here?

  * Solution 1 seems reasonable but it's horribly slow - 74.55 seconds
    for this toy dataset.

  * Solution 2 and 3 are all-zoo and are 36x and 70x faster. This is
    great!

  * The xts solution is 112 times faster!

  * But xts conversion is costly, burning 0.665 ms. If we are converting
    to xts solely for the purpose of getting this done, then the gain
    compared with Solution 1 is only 31x. In this case, Solution 3
    is the best, particularly because it also does not require memory
    to house the xts object and the zoo object in core at the same time.

In short, it seems that if you are already using xts, then xts is the
fastest solution here. Xts is clearly doing something right with the
fastest solution (112x faster than Solution 1). But if you're
presently a zoo user, then switching to xts purely for the purpose of
doing this one thing is not efficient.

My code embeds gc(reset=TRUE) commands but I'm not able to understand
them fully. Efficiency of memory use *is* an important problem when
dealing with these gigantic intra-day datasets and it'll be great if
others can help in thinking more effectively about memory efficiency
using this information.

I am grateful to all on r-sig-finance who helped me steer towards
this, and particularly Gabor and Jeff who wrote the above code. And of
course, we in the R world are privileged to have outstanding software
systems like zoo and xts to choose from. It's a delight to build stuff
here.

-- 
Ajay Shah                                      http://www.mayin.org/ajayshah  
ajayshah at mayin.org                             http://ajayshahblog.blogspot.com
<*(:-? - wizard who doesn't know the answer.


From ggrothendieck at gmail.com  Sun Dec  6 15:53:16 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 6 Dec 2009 09:53:16 -0500
Subject: [R-SIG-Finance] SUMMARY: Reducing an intra-day dataset into one
	obs per second
In-Reply-To: <20091206142400.GA31007@ajay-shahs-macbook-pro.local>
References: <20091206142400.GA31007@ajay-shahs-macbook-pro.local>
Message-ID: <971536df0912060653l2385076dl7b3014aac62d5f9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091206/2de50fdf/attachment.pl>

From ajayshah at mayin.org  Sun Dec  6 15:57:42 2009
From: ajayshah at mayin.org (Ajay Shah)
Date: Sun, 6 Dec 2009 20:27:42 +0530
Subject: [R-SIG-Finance] SUMMARY: Reducing an intra-day dataset into one
	obs per second
In-Reply-To: <971536df0912060653l2385076dl7b3014aac62d5f9@mail.gmail.com>
References: <20091206142400.GA31007@ajay-shahs-macbook-pro.local>
	<971536df0912060653l2385076dl7b3014aac62d5f9@mail.gmail.com>
Message-ID: <dfa07a9d0912060657i3a293a41ycc1dd8fc2e228fde@mail.gmail.com>

On Sun, Dec 6, 2009 at 8:23 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> You might want to indicate what versions of the software and what platform
> you used since when I use the latest versions of those packages on a Windows
> Vista machine with R 2.10.0 Patched I get quite different relative timings
> with soln3 being the fastest this time as shown here starting in a fresh
> session of R:
>
>> R.version.string
> [1] "R version 2.10.0 Patched (2009-11-21 r50532)"
>> packageDescription("xts")$Version
> [1] "0.6-9"
>> packageDescription("zoo")$Version
> [1] "1.6-2"

How interesting! I am also on the same xts and zoo versions. I'm on
Mac OS X `Leopard' with R 2.10.0

What did R 2.10.0 Patched do which has changed the ordering of the
four solutions?

-- 
Ajay Shah
ajayshah at mayin.org
http://www.mayin.org/ajayshah
http://ajayshahblog.blogspot.com


From guillaume.yziquel at citycable.ch  Mon Dec  7 23:12:35 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Mon, 07 Dec 2009 23:12:35 +0100
Subject: [R-SIG-Finance] Futures prices in quantmod?
Message-ID: <4B1D7DD3.9010901@citycable.ch>

Hello.

I was wondering if there was a way for quantmod's getSymbols to retrieve 
prices for futures. Some information seems available on yahoo, for instance:

http://finance.yahoo.com/futures?t=indices

http://download.finance.yahoo.com/d/quotes.csv?s=%5EDJS2&f=sl1d1t1c1ohgv&e=.csv

So is it possible to do it with quantmod?

All the best,

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From josh.m.ulrich at gmail.com  Mon Dec  7 23:18:11 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 7 Dec 2009 16:18:11 -0600
Subject: [R-SIG-Finance] Futures prices in quantmod?
In-Reply-To: <4B1D7DD3.9010901@citycable.ch>
References: <4B1D7DD3.9010901@citycable.ch>
Message-ID: <8cca69990912071418we4f5cdao9f5899887aaa0c56@mail.gmail.com>

Hi Guillaume,

Try:

> getQuote("^DJS2")
               Trade Time   Last Change % Change   Open   High    Low Volume
^DJS2 2009-12-07 11:14:00 103.73  -1.08   -1.03% 103.73 103.73 103.73      0

HTH,
Josh
--
http://www.fosstrading.com



On Mon, Dec 7, 2009 at 4:12 PM, Guillaume Yziquel
<guillaume.yziquel at citycable.ch> wrote:
> Hello.
>
> I was wondering if there was a way for quantmod's getSymbols to retrieve
> prices for futures. Some information seems available on yahoo, for instance:
>
> http://finance.yahoo.com/futures?t=indices
>
> http://download.finance.yahoo.com/d/quotes.csv?s=%5EDJS2&f=sl1d1t1c1ohgv&e=.csv
>
> So is it possible to do it with quantmod?
>
> All the best,
>
> --
> ? ? Guillaume Yziquel
> http://yziquel.homelinux.org/
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From guillaume.yziquel at citycable.ch  Mon Dec  7 23:22:43 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Mon, 07 Dec 2009 23:22:43 +0100
Subject: [R-SIG-Finance] Futures prices in quantmod?
In-Reply-To: <8cca69990912071418we4f5cdao9f5899887aaa0c56@mail.gmail.com>
References: <4B1D7DD3.9010901@citycable.ch>
	<8cca69990912071418we4f5cdao9f5899887aaa0c56@mail.gmail.com>
Message-ID: <4B1D8033.4010905@citycable.ch>

Joshua Ulrich a ?crit :
> Hi Guillaume,
> 
> Try:
> 
>> getQuote("^DJS2")
>                Trade Time   Last Change % Change   Open   High    Low Volume
> ^DJS2 2009-12-07 11:14:00 103.73  -1.08   -1.03% 103.73 103.73 103.73      0
> 
> HTH,
> Josh
> --
> http://www.fosstrading.com

Ah, OK! I was deseperately trying with getSymbols.

Thanks for the quick help...

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From konradhoppe at hotmail.de  Mon Dec  7 23:30:30 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Mon, 7 Dec 2009 23:30:30 +0100
Subject: [R-SIG-Finance] Futures prices in quantmod?
In-Reply-To: <4B1D7DD3.9010901@citycable.ch>
Message-ID: <SNT114-DS2423BA957D0805C6AA302D0900@phx.gbl>

Hi Guillaume,

I tried a future from the first site you presented below. And you can load
futures prices in the same way you use for "normal" assets:

from.dat <- as.Date("01/01/03", format="%m/%d/%y")
to.dat <- as.Date(Sys.Date(), format="%m/%d/%y")

getSymbols("^XAU", src="yahoo", from = from.dat, to = to.dat)

regards
Konrad

-----Urspr?ngliche Nachricht-----
Von: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] Im Auftrag von Guillaume
Yziquel
Gesendet: Montag, 7. Dezember 2009 23:13
An: R-Finance
Betreff: [R-SIG-Finance] Futures prices in quantmod?

Hello.

I was wondering if there was a way for quantmod's getSymbols to retrieve 
prices for futures. Some information seems available on yahoo, for instance:

http://finance.yahoo.com/futures?t=indices

http://download.finance.yahoo.com/d/quotes.csv?s=%5EDJS2&f=sl1d1t1c1ohgv&e=.
csv

So is it possible to do it with quantmod?

All the best,

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list

-- Subscriber-posting only.
-- If you want to post, subscribe first.


From guillaume.yziquel at citycable.ch  Mon Dec  7 23:55:32 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Mon, 07 Dec 2009 23:55:32 +0100
Subject: [R-SIG-Finance] Futures prices in quantmod?
In-Reply-To: <SNT114-DS2423BA957D0805C6AA302D0900@phx.gbl>
References: <SNT114-DS2423BA957D0805C6AA302D0900@phx.gbl>
Message-ID: <4B1D87E4.6090103@citycable.ch>

Konrad Hoppe a ?crit :
> Hi Guillaume,

Hi, Konrad.

> I tried a future from the first site you presented below. And you can load
> futures prices in the same way you use for "normal" assets:
> 
> from.dat <- as.Date("01/01/03", format="%m/%d/%y")
> to.dat <- as.Date(Sys.Date(), format="%m/%d/%y")
> 
> getSymbols("^XAU", src="yahoo", from = from.dat, to = to.dat)
> 
> regards
> Konrad

It seems that this depends on the specific future:

> > from.dat <- as.Date("01/01/03", format="%m/%d/%y")
> > to.dat <- as.Date(Sys.Date(), format="%m/%d/%y")
> > getSymbols("^XAU", src="yahoo", from = from.dat, to = to.dat)
> [1] "XAU"
> > getSymbols("^DJS2", src="yahoo", from = from.dat, to = to.dat)
> Erreur dans download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  : 
>   impossible d'ouvrir l'URL 'http://chart.yahoo.com/table.csv?s=^DJS2&a=0&b=01&c=2003&d=11&e=07&f=2009&g=d&q=q&y=0&z=^DJS2&x=.csv'
> De plus : Message d'avis :
> In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
>   ouverture impossible : le statut HTTP ?tait '404 Not Found'

Perhaps yahoo's policy prevents from downloading the Dow Jones 
Industrial Average, but not less common futures... (getQuote works fine 
though, so I'm a bit surprised).

Anyone knows, or knows how to know?

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From josh.m.ulrich at gmail.com  Tue Dec  8 00:08:26 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 7 Dec 2009 17:08:26 -0600
Subject: [R-SIG-Finance] Futures prices in quantmod?
In-Reply-To: <4B1D87E4.6090103@citycable.ch>
References: <SNT114-DS2423BA957D0805C6AA302D0900@phx.gbl>
	<4B1D87E4.6090103@citycable.ch>
Message-ID: <8cca69990912071508s51805ad6r3f0b682b9190c4a5@mail.gmail.com>

>
> Perhaps yahoo's policy prevents from downloading the Dow Jones Industrial
> Average, but not less common futures... (getQuote works fine though, so I'm
> a bit surprised).
>
> Anyone knows, or knows how to know?
>

^DJC and ^XAU have historical data, thus you can retrieve their data
with getSymbols.
http://finance.yahoo.com/q/hp?s=^DJC
http://finance.yahoo.com/q/hp?s=^XAU

Most other futures symbols on this page
http://finance.yahoo.com/futures?t=indices
do not have historical data, so you're limited to what you can
retrieve with getQuote.  For example:
http://finance.yahoo.com/q/hp?s=^DJS2

HTH,
Josh
--
http://www.fosstrading.com

> --
> ? ? Guillaume Yziquel
> http://yziquel.homelinux.org/
>


From n_torenvliet at hotmail.com  Tue Dec  8 00:13:42 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Mon, 7 Dec 2009 18:13:42 -0500
Subject: [R-SIG-Finance] Suggestions
In-Reply-To: <8cca69990912071508s51805ad6r3f0b682b9190c4a5@mail.gmail.com>
References: <SNT114-DS2423BA957D0805C6AA302D0900@phx.gbl>,
	<4B1D87E4.6090103@citycable.ch>,
	<8cca69990912071508s51805ad6r3f0b682b9190c4a5@mail.gmail.com>
Message-ID: <BAY143-W101DB61A81E1AC2B9C15BFE900@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091207/10b6ad30/attachment.pl>

From josh.m.ulrich at gmail.com  Tue Dec  8 00:16:10 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 7 Dec 2009 17:16:10 -0600
Subject: [R-SIG-Finance] Suggestions
In-Reply-To: <BAY143-W101DB61A81E1AC2B9C15BFE900@phx.gbl>
References: <SNT114-DS2423BA957D0805C6AA302D0900@phx.gbl>
	<4B1D87E4.6090103@citycable.ch> 
	<8cca69990912071508s51805ad6r3f0b682b9190c4a5@mail.gmail.com> 
	<BAY143-W101DB61A81E1AC2B9C15BFE900@phx.gbl>
Message-ID: <8cca69990912071516t75850c90s76136df7ee30c7f0@mail.gmail.com>

Hi Nick,

Since this doesn't have anything to do with Finance, you'll probably
receive a better response from the R-help list.  To answer your
question, I use vim.

Best,
Josh
--
http://www.fosstrading.com



On Mon, Dec 7, 2009 at 5:13 PM, Nick Torenvliet
<n_torenvliet at hotmail.com> wrote:
>
>
> Hi again,
>
> So it appears I'm going to be doing some programming in R... what is general opinion on available IDEs? ?I've seen the Eclipse and the Emacs editor thus far.
>
> Nick
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From konradhoppe at hotmail.de  Tue Dec  8 00:23:42 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Tue, 8 Dec 2009 00:23:42 +0100
Subject: [R-SIG-Finance] Futures prices in quantmod?
In-Reply-To: <4B1D87E4.6090103@citycable.ch>
Message-ID: <SNT114-DS23862B963F9364806509A0D0900@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091208/4144b80a/attachment.pl>

From rhelpacc at gmail.com  Tue Dec  8 02:59:32 2009
From: rhelpacc at gmail.com (R_help Help)
Date: Mon, 7 Dec 2009 20:59:32 -0500
Subject: [R-SIG-Finance] Pricing guaranteed execution
Message-ID: <ad1ead5f0912071759mfab9365rd8f971050a2ccb80@mail.gmail.com>

Hi,

Sorry. This is probably not an R question. But I'd like to know if one
were to guarantee execution. Is there any framework to price the
markup? Thank you.

rhelp


From guillaume.yziquel at citycable.ch  Tue Dec  8 03:58:23 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Tue, 08 Dec 2009 03:58:23 +0100
Subject: [R-SIG-Finance] Futures prices in quantmod?
In-Reply-To: <SNT114-DS2423BA957D0805C6AA302D0900@phx.gbl>
References: <SNT114-DS2423BA957D0805C6AA302D0900@phx.gbl>
Message-ID: <4B1DC0CF.3050007@citycable.ch>

Konrad Hoppe a ?crit :
> Hi Guillaume,
> 
> I tried a future from the first site you presented below. And you can load
> futures prices in the same way you use for "normal" assets:
> 
> from.dat <- as.Date("01/01/03", format="%m/%d/%y")
> to.dat <- as.Date(Sys.Date(), format="%m/%d/%y")
> 
> getSymbols("^XAU", src="yahoo", from = from.dat, to = to.dat)
> 
> regards
> Konrad

Not so sure. ^XAU is quite weird, when you compare it to XAU: Exactly 
the same data, but XAU ends 7 months ago. I'm not even sure that ^XAU is 
a future. It seems to me (but I may well be mistaken) that one cannot 
downloads historical prices for futures.

Here's a real future:

> > getQuote("DJZ09.CBT")
>                    Trade Time  Last Change % Change  Open  High   Low Volume
> DJZ09.CBT 2009-12-07 04:14:00 10391     -9   -0.09% 10365 10430 10327      0
> > getSymbols("DJZ09.CBT")
> Erreur dans download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  : 
>   impossible d'ouvrir l'URL 'http://chart.yahoo.com/table.csv?s=DJZ09.CBT&a=0&b=01&c=2007&d=11&e=08&f=2009&g=d&q=q&y=0&z=DJZ09.CBT&x=.csv'
> De plus : Message d'avis :
> In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
>   ouverture impossible : le statut HTTP ?tait '404 Not Found'

getQuote works, getSymbols doesn't.

I believe the XAU/^XAU thing is not a future, but the Philadelphia index 
itself.

All the best,

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From rhelpacc at gmail.com  Tue Dec  8 05:23:52 2009
From: rhelpacc at gmail.com (R_help Help)
Date: Mon, 7 Dec 2009 23:23:52 -0500
Subject: [R-SIG-Finance] Pricing guaranteed execution
In-Reply-To: <1421212716.290319.1260245477755.JavaMail.root@vms228.mailsrvcs.net>
References: <1421212716.290319.1260245477755.JavaMail.root@vms228.mailsrvcs.net>
Message-ID: <ad1ead5f0912072023j7b451e76q600c0443d531140d@mail.gmail.com>

Well thanks Mark. My order horizon is usually much longer. So I'm
wondering if there's any framework for pricing such executions that
people have put thoughts on so far? Thanks.

On Mon, Dec 7, 2009 at 11:11 PM,  <markleeds at verizon.net> wrote:
> hi: you could assume the offer quote on a buy and the bid quote on a sale
> but even that's not guaranteed if you don't
> get there first.
>
>
>
> On Dec 7, 2009, R_help Help <rhelpacc at gmail.com> wrote:
>
> Hi,
>
> Sorry. This is probably not an R question. But I'd like to know if one
> were to guarantee execution. Is there any framework to price the
> markup? Thank you.
>
> rhelp
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From singhp5 at hotmail.com  Wed Dec  9 01:54:26 2009
From: singhp5 at hotmail.com (Pardeep Singh)
Date: Wed, 9 Dec 2009 00:54:26 +0000
Subject: [R-SIG-Finance]
 Re%3A%20%5BR-SIG-Finance%5D%20FinTS%20requires%20zoo%20to%20export%20as.Date.numeric
Message-ID: <BAY127-W27A6C98CEF1C47AB3144E4F18E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091209/388c340d/attachment.pl>

From HodgessE at uhd.edu  Wed Dec  9 04:02:16 2009
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Tue, 8 Dec 2009 21:02:16 -0600
Subject: [R-SIG-Finance] disaggregation, R and Matlab
Message-ID: <101CBF5360343B45B9C9B0B05D71474C25AE4F@BALI.uhd.campus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091208/b7df4b0b/attachment.pl>

From tallent_e at lycos.com  Wed Dec  9 12:38:58 2009
From: tallent_e at lycos.com (Edouard Tallent)
Date: Wed, 09 Dec 2009 06:38:58 -0500 (EST)
Subject: [R-SIG-Finance] troubles with quantmod
Message-ID: <20091209063858.HM.0000000000009m2@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091209/2ee749b7/attachment.html>

From konradhoppe at hotmail.de  Wed Dec  9 12:43:46 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Wed, 9 Dec 2009 12:43:46 +0100
Subject: [R-SIG-Finance] troubles with quantmod
In-Reply-To: <20091209063858.HM.0000000000009m2@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
Message-ID: <SNT114-DS10F1EAFB33F6B6A9109F1ED08E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091209/23617a14/attachment.pl>

From stefan.albrecht at allianz.com  Wed Dec  9 12:49:22 2009
From: stefan.albrecht at allianz.com (Albrecht, Dr. Stefan (AIM SE))
Date: Wed, 9 Dec 2009 12:49:22 +0100
Subject: [R-SIG-Finance] disaggregation, R and Matlab
Message-ID: <E9A6BE4BC902144594DE1610235B78050E8DF5AF62@VAXMUCJ1.wwg00m.rootdom.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091209/14d4b878/attachment.pl>

From landronimirc at gmail.com  Wed Dec  9 12:52:14 2009
From: landronimirc at gmail.com (Liviu Andronic)
Date: Wed, 9 Dec 2009 11:52:14 +0000
Subject: [R-SIG-Finance] disaggregation, R and Matlab
In-Reply-To: <101CBF5360343B45B9C9B0B05D71474C25AE4F@BALI.uhd.campus>
References: <101CBF5360343B45B9C9B0B05D71474C25AE4F@BALI.uhd.campus>
Message-ID: <68b1e2610912090352w6a30f1b3r2ecd7c31421f65f9@mail.gmail.com>

On 12/9/09, Hodgess, Erin <HodgessE at uhd.edu> wrote:
>  However, I don't have Matlab, but wondered what functions they have available.
>
You could also look at Octave, which is partly Matlab-compatible.
Liviu


From gmroot2004-ms at yahoo.it  Wed Dec  9 15:51:33 2009
From: gmroot2004-ms at yahoo.it (gmroot2004-ms at yahoo.it)
Date: Wed, 9 Dec 2009 14:51:33 +0000 (GMT)
Subject: [R-SIG-Finance] Probit model with specification for the conditional
	variance
Message-ID: <263895.61076.qm@web28502.mail.ukl.yahoo.com>

Guys,
 
Is 
there a ready made package/function to estimate a probit model where I can also 
specify a functional form for the conditional variance (something like 
Var(epsilon_i | x_i) = bZ)
 
I can?t 
see how you would do that wil polr (from MASS) or even 
MCMCoprobit.
 
Thanks!
 
//Giuseppe





From rex at nosyntax.net  Wed Dec  9 16:25:43 2009
From: rex at nosyntax.net (rex)
Date: Wed, 9 Dec 2009 07:25:43 -0800
Subject: [R-SIG-Finance] troubles with quantmod
In-Reply-To: <20091209063858.HM.0000000000009m2@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
References: <20091209063858.HM.0000000000009m2@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
Message-ID: <20091209152543.GZ4140@nosyntax.net>

Edouard Tallent <tallent_e at lycos.com> [2009-12-09 03:40]:
>   > install.packages(c('xts','Defaults','quantmod'))
>
>   That worked.
>
>   getQuote("AAPL")
>   getQuote("QQQQ;SPY;^VXN",what=yahooQF(c("Bid","Ask")))
>   standardQuote()
>   yahooFQ()
>
>   Then, after running, R tells that i cannot find the functions getQuote,
>   standardQuote(), yahooFQ()
>
>   That is pretty strange ! In fact, the html help through "Search Engine &
>   Keywords" is able to find all those functions.
>
>   What did I do wrong ?

You need to load the library into your R session. At the R prompt, type:

library(quantmod)

-rex
-- 
File not found: Loading something that looked similar.


From HodgessE at uhd.edu  Wed Dec  9 17:48:07 2009
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Wed, 9 Dec 2009 10:48:07 -0600
Subject: [R-SIG-Finance] disaggregation, R and Matlab
References: <101CBF5360343B45B9C9B0B05D71474C25AE4F@BALI.uhd.campus>
	<68b1e2610912090352w6a30f1b3r2ecd7c31421f65f9@mail.gmail.com>
Message-ID: <101CBF5360343B45B9C9B0B05D71474C25AE53@BALI.uhd.campus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091209/075575fc/attachment.pl>

From HodgessE at uhd.edu  Wed Dec  9 17:47:37 2009
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Wed, 9 Dec 2009 10:47:37 -0600
Subject: [R-SIG-Finance] disaggregation, R and Matlab
References: <E9A6BE4BC902144594DE1610235B78050E8DF5AF62@VAXMUCJ1.wwg00m.rootdom.net>
Message-ID: <101CBF5360343B45B9C9B0B05D71474C25AE52@BALI.uhd.campus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091209/c9c82663/attachment.pl>

From konradhoppe at hotmail.de  Wed Dec  9 18:39:12 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Wed, 9 Dec 2009 18:39:12 +0100
Subject: [R-SIG-Finance] how to plot a data frame of timeseries?
Message-ID: <SNT114-DS10E3ECB105DB643593E634D08E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091209/6285fb7c/attachment.pl>

From jeff.a.ryan at gmail.com  Wed Dec  9 18:48:11 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Wed, 9 Dec 2009 11:48:11 -0600
Subject: [R-SIG-Finance] how to plot a data frame of timeseries?
In-Reply-To: <SNT114-DS10E3ECB105DB643593E634D08E0@phx.gbl>
References: <SNT114-DS10E3ECB105DB643593E634D08E0@phx.gbl>
Message-ID: <e8e755250912090948p3e1a3bd3gea6f16a5c225d3c6@mail.gmail.com>

Hi Konrad

For time series you should really look to using one of the myriad of
time series classes that are in R.

zoo, xts and timeSeries will all do nicely for what you want.  Though
zoo and timeSeries have better plotting than xts (xts extends zoo, so
relies mostly on zoo for plotting)

Other options to explore at fts (which has a nice C++ backend) as well
as some of the older base ones, like 'ts' and 'its'.

library(zoo)
?plot.zoo

?as.zoo will also help

HTH
Jeff

On Wed, Dec 9, 2009 at 11:39 AM, Konrad Hoppe <konradhoppe at hotmail.de> wrote:
> Dear mailing list members,
>
> I would like to plot different time series in one plot, which are together
> in one data frame. In the columns are the different stocks and in the rows
> are the different time points. Every stock should have a different color,
> can be chosen randomly. I've already seen sth like this in the context of
> stochastic processes but I don't know how to create.
>
> Can anybody help me?
>
> All the best,
>
> --
>
> Konrad Hoppe
>
> http://www.konrad-hoppe.com/
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From brian at braverock.com  Wed Dec  9 18:51:55 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 09 Dec 2009 11:51:55 -0600
Subject: [R-SIG-Finance] how to plot a data frame of timeseries?
In-Reply-To: <SNT114-DS10E3ECB105DB643593E634D08E0@phx.gbl>
References: <SNT114-DS10E3ECB105DB643593E634D08E0@phx.gbl>
Message-ID: <4B1FE3BB.8070205@braverock.com>

Konrad Hoppe wrote:
> Dear mailing list members,
>
> I would like to plot different time series in one plot, which are together
> in one data frame. In the columns are the different stocks and in the rows
> are the different time points. Every stock should have a different color,
> can be chosen randomly. I've already seen sth like this in the context of
> stochastic processes but I don't know how to create.
>
> Can anybody help me?
>   
Tips:

1> use a time series class, like xts or timeSeries, rather than a data.frame

2> ?plot

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From jtl at saxobank.com  Wed Dec  9 18:54:43 2009
From: jtl at saxobank.com (Jeffrey Todd Lins)
Date: Wed, 9 Dec 2009 17:54:43 +0000
Subject: [R-SIG-Finance] how to plot a data frame of timeseries?
Message-ID: <C88C12BE4A7E7C44841FD636D869B3F60A8638743D@MALMB3-DK.mid.dom>

Dear Konrad,

This is actually a general R question, but since time series are a common interest within finance, let's answer it here to others' benefit, too.

I believe the simplest,  most direct first try might be with ts.plot.



Jeffrey Lins
Executive Director 
Quantitative Analysis and Advanced Research Center
Saxo Bank A/S

(Message sent from my BlackBerry)

----- Original Message -----
From: r-sig-finance-bounces at stat.math.ethz.ch <r-sig-finance-bounces at stat.math.ethz.ch>
To: 'R-Finance' <r-sig-finance at stat.math.ethz.ch>
Sent: Wed Dec 09 17:39:12 2009
Subject: [R-SIG-Finance] how to plot a data frame of timeseries?

Dear mailing list members,

I would like to plot different time series in one plot, which are together
in one data frame. In the columns are the different stocks and in the rows
are the different time points. Every stock should have a different color,
can be chosen randomly. I've already seen sth like this in the context of
stochastic processes but I don't know how to create.

Can anybody help me?

All the best,

--

Konrad Hoppe

http://www.konrad-hoppe.com/

 


	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.
This email may contain confidential and/or privileged information.
If you are not the intended recipient (or have received this email 
by mistake), please notify the sender immediately and destroy this 
email. Any unauthorised copying, disclosure or distribution of the
material in this email is strictly prohibited.

Email transmission security and error-free status cannot be guaranteed
as information could be intercepted, corrupted, destroyed, delayed,
incomplete, or contain viruses. The sender therefore does not accept
liability for any errors or omissions in the contents of this message 
which may arise as a result of email transmission.

From konradhoppe at hotmail.de  Wed Dec  9 19:06:29 2009
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Wed, 9 Dec 2009 19:06:29 +0100
Subject: [R-SIG-Finance] how to plot a data frame of timeseries?
In-Reply-To: <e8e755250912090948p3e1a3bd3gea6f16a5c225d3c6@mail.gmail.com>
Message-ID: <SNT114-DS20D590088CE91E08FA434FD08E0@phx.gbl>

Hi Jeff,

thank you so far, that works quite good. But I've still the problem with the
random but different colors. Could you please give me one more hint?

regards
--
Konrad Hoppe
http://www.konrad-hoppe.com/

-----Urspr?ngliche Nachricht-----
Von: Jeff Ryan [mailto:jeff.a.ryan at gmail.com] 
Gesendet: Mittwoch, 9. Dezember 2009 18:48
An: Konrad Hoppe
Cc: R-Finance
Betreff: Re: [R-SIG-Finance] how to plot a data frame of timeseries?

Hi Konrad

For time series you should really look to using one of the myriad of
time series classes that are in R.

zoo, xts and timeSeries will all do nicely for what you want.  Though
zoo and timeSeries have better plotting than xts (xts extends zoo, so
relies mostly on zoo for plotting)

Other options to explore at fts (which has a nice C++ backend) as well
as some of the older base ones, like 'ts' and 'its'.

library(zoo)
?plot.zoo

?as.zoo will also help

HTH
Jeff

On Wed, Dec 9, 2009 at 11:39 AM, Konrad Hoppe <konradhoppe at hotmail.de>
wrote:
> Dear mailing list members,
>
> I would like to plot different time series in one plot, which are together
> in one data frame. In the columns are the different stocks and in the rows
> are the different time points. Every stock should have a different color,
> can be chosen randomly. I've already seen sth like this in the context of
> stochastic processes but I don't know how to create.
>
> Can anybody help me?
>
> All the best,
>
> --
>
> Konrad Hoppe
>
> http://www.konrad-hoppe.com/
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From brian at braverock.com  Wed Dec  9 19:12:33 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 09 Dec 2009 12:12:33 -0600
Subject: [R-SIG-Finance] how to plot a data frame of timeseries?
In-Reply-To: <SNT114-DS20D590088CE91E08FA434FD08E0@phx.gbl>
References: <SNT114-DS20D590088CE91E08FA434FD08E0@phx.gbl>
Message-ID: <4B1FE891.7010603@braverock.com>

http://cran.r-project.org/web/packages/RColorBrewer/index.html

?par

Konrad Hoppe wrote:
> Hi Jeff,
>
> thank you so far, that works quite good. But I've still the problem with the
> random but different colors. Could you please give me one more hint?
>
> regards
> --
> Konrad Hoppe
> http://www.konrad-hoppe.com/
>
> -----Urspr?ngliche Nachricht-----
> Von: Jeff Ryan [mailto:jeff.a.ryan at gmail.com] 
> Gesendet: Mittwoch, 9. Dezember 2009 18:48
> An: Konrad Hoppe
> Cc: R-Finance
> Betreff: Re: [R-SIG-Finance] how to plot a data frame of timeseries?
>
> Hi Konrad
>
> For time series you should really look to using one of the myriad of
> time series classes that are in R.
>
> zoo, xts and timeSeries will all do nicely for what you want.  Though
> zoo and timeSeries have better plotting than xts (xts extends zoo, so
> relies mostly on zoo for plotting)
>
> Other options to explore at fts (which has a nice C++ backend) as well
> as some of the older base ones, like 'ts' and 'its'.
>
> library(zoo)
> ?plot.zoo
>
> ?as.zoo will also help
>
> HTH
> Jeff
>
> On Wed, Dec 9, 2009 at 11:39 AM, Konrad Hoppe <konradhoppe at hotmail.de>
> wrote:
>   
>> Dear mailing list members,
>>
>> I would like to plot different time series in one plot, which are together
>> in one data frame. In the columns are the different stocks and in the rows
>> are the different time points. Every stock should have a different color,
>> can be chosen randomly. I've already seen sth like this in the context of
>> stochastic processes but I don't know how to create.
>>
>> Can anybody help me?
>>
>> All the best,
>>
>> --
>>
>> Konrad Hoppe
>>
>> http://www.konrad-hoppe.com/
>>
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>>     
>
>
>
>   


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From jeff.a.ryan at gmail.com  Wed Dec  9 19:11:30 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Wed, 9 Dec 2009 12:11:30 -0600
Subject: [R-SIG-Finance] how to plot a data frame of timeseries?
In-Reply-To: <SNT114-DS20D590088CE91E08FA434FD08E0@phx.gbl>
References: <e8e755250912090948p3e1a3bd3gea6f16a5c225d3c6@mail.gmail.com>
	<SNT114-DS20D590088CE91E08FA434FD08E0@phx.gbl>
Message-ID: <e8e755250912091011m45d132a5m863bd171e194faa5@mail.gmail.com>

The ?plot.zoo example:

example(plot.zoo) will help.

For financial type charting you can also look at quantmod.

http://www.quantmod.com

Best,
Jeff

On Wed, Dec 9, 2009 at 12:06 PM, Konrad Hoppe <konradhoppe at hotmail.de> wrote:
> Hi Jeff,
>
> thank you so far, that works quite good. But I've still the problem with the
> random but different colors. Could you please give me one more hint?
>
> regards
> --
> Konrad Hoppe
> http://www.konrad-hoppe.com/
>
> -----Urspr?ngliche Nachricht-----
> Von: Jeff Ryan [mailto:jeff.a.ryan at gmail.com]
> Gesendet: Mittwoch, 9. Dezember 2009 18:48
> An: Konrad Hoppe
> Cc: R-Finance
> Betreff: Re: [R-SIG-Finance] how to plot a data frame of timeseries?
>
> Hi Konrad
>
> For time series you should really look to using one of the myriad of
> time series classes that are in R.
>
> zoo, xts and timeSeries will all do nicely for what you want. ?Though
> zoo and timeSeries have better plotting than xts (xts extends zoo, so
> relies mostly on zoo for plotting)
>
> Other options to explore at fts (which has a nice C++ backend) as well
> as some of the older base ones, like 'ts' and 'its'.
>
> library(zoo)
> ?plot.zoo
>
> ?as.zoo will also help
>
> HTH
> Jeff
>
> On Wed, Dec 9, 2009 at 11:39 AM, Konrad Hoppe <konradhoppe at hotmail.de>
> wrote:
>> Dear mailing list members,
>>
>> I would like to plot different time series in one plot, which are together
>> in one data frame. In the columns are the different stocks and in the rows
>> are the different time points. Every stock should have a different color,
>> can be chosen randomly. I've already seen sth like this in the context of
>> stochastic processes but I don't know how to create.
>>
>> Can anybody help me?
>>
>> All the best,
>>
>> --
>>
>> Konrad Hoppe
>>
>> http://www.konrad-hoppe.com/
>>
>>
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>
>
>
> --
> Jeffrey Ryan
> jeffrey.ryan at insightalgo.com
>
> ia: insight algorithmics
> www.insightalgo.com
>
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From hubert.colt at gmail.com  Thu Dec 10 13:05:50 2009
From: hubert.colt at gmail.com (Hubert Colt)
Date: Thu, 10 Dec 2009 13:05:50 +0100
Subject: [R-SIG-Finance] Which Kalman filter?
In-Reply-To: <664634252.143965.1260044273235.JavaMail.root@vms228.mailsrvcs.net>
References: <664634252.143965.1260044273235.JavaMail.root@vms228.mailsrvcs.net>
Message-ID: <be6b11010912100405q25c650b5hc0026377a8dae9b0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091210/7ad7603a/attachment.pl>

From f.pollastri at inrim.it  Thu Dec 10 15:12:13 2009
From: f.pollastri at inrim.it (Fabrizio Pollastri)
Date: Thu, 10 Dec 2009 15:12:13 +0100
Subject: [R-SIG-Finance] xts and na.omit "unsupported type"
Message-ID: <4B2101BD.60305@inrim.it>

Hello,
I have to remove NAs from a logical xts, but I get the error:

Error in na.omit.xts(x > y) : unsupported type

Example code:

library(xts)
x = xts(1:10,as.Date(1:10))
y = xts(c(NA,9:1),as.Date(1:10))
na.omit(x > y)

What I am missing?

Kind regards,
Fabrizio Pollastri


From Jose at erini.ac.uk  Thu Dec 10 15:29:57 2009
From: Jose at erini.ac.uk (Jose Iparraguirre D'Elia)
Date: Thu, 10 Dec 2009 14:29:57 -0000
Subject: [R-SIG-Finance] xts and na.omit "unsupported type"
Message-ID: <C9328F0EEDC3BC439FDABD12060E9109AF192F@erini1.ERINI.local>

Hello Fabrizio,

I guess that the problem lies in the class of object you create with
xts. 
na.omit works with data frames, etc., but not with the xts class.
So, I would do the following (it worked):

library(xts)
x = xts(1:10,as.Date(1:10))
y = xts(c(NA,9:1),as.Date(1:10))

> na.omit(as.data.frame(x>y))
              V1
1970-01-03 FALSE
1970-01-04 FALSE
1970-01-05 FALSE
1970-01-06 FALSE
1970-01-07  TRUE
1970-01-08  TRUE
1970-01-09  TRUE
1970-01-10  TRUE
1970-01-11  TRUE

Work from here. Hope this helps,

Jose


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Fabrizio
Pollastri
Sent: 10 December 2009 14:12
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] xts and na.omit "unsupported type"

Hello,
I have to remove NAs from a logical xts, but I get the error:

Error in na.omit.xts(x > y) : unsupported type

Example code:

library(xts)
x = xts(1:10,as.Date(1:10))
y = xts(c(NA,9:1),as.Date(1:10))
na.omit(x > y)

What I am missing?

Kind regards,
Fabrizio Pollastri

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From brian at braverock.com  Thu Dec 10 15:23:28 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 10 Dec 2009 08:23:28 -0600
Subject: [R-SIG-Finance] xts and na.omit "unsupported type"
In-Reply-To: <4B2101BD.60305@inrim.it>
References: <4B2101BD.60305@inrim.it>
Message-ID: <4B210460.6050108@braverock.com>

Fabrizio Pollastri wrote:
> Hello,
> I have to remove NAs from a logical xts, but I get the error:
>
> Error in na.omit.xts(x > y) : unsupported type
>
> Example code:
>
> library(xts)
> x = xts(1:10,as.Date(1:10))
> y = xts(c(NA,9:1),as.Date(1:10))
> na.omit(x > y)
x>y is a logical comparison. na.omit want s a single series as an argument.

so, cbind your series first, na.omit, and then compare

or skip all that and do:

x[which(x>y)]

and please note that this was a question for r-help, not R-SIG-Finance, 
as it has nothing to do with finance.

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From jeff.a.ryan at gmail.com  Thu Dec 10 16:07:42 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Thu, 10 Dec 2009 09:07:42 -0600
Subject: [R-SIG-Finance] xts and na.omit "unsupported type"
In-Reply-To: <4B210460.6050108@braverock.com>
References: <4B2101BD.60305@inrim.it> <4B210460.6050108@braverock.com>
Message-ID: <e8e755250912100707j4e14917eva1c1110ccdc4dea9@mail.gmail.com>

Actually more a question for the developers :)

Seems to be a bug in the code.  I will fix.
For now, Brian's suggestion is best.

Thanks,
Jeff

On Thu, Dec 10, 2009 at 8:23 AM, Brian G. Peterson <brian at braverock.com> wrote:
> Fabrizio Pollastri wrote:
>>
>> Hello,
>> I have to remove NAs from a logical xts, but I get the error:
>>
>> Error in na.omit.xts(x > y) : unsupported type
>>
>> Example code:
>>
>> library(xts)
>> x = xts(1:10,as.Date(1:10))
>> y = xts(c(NA,9:1),as.Date(1:10))
>> na.omit(x > y)
>
> x>y is a logical comparison. na.omit want s a single series as an argument.
>
> so, cbind your series first, na.omit, and then compare
>
> or skip all that and do:
>
> x[which(x>y)]
>
> and please note that this was a question for r-help, not R-SIG-Finance, as
> it has nothing to do with finance.
>
> Regards,
>
> ? - Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From jeff.a.ryan at gmail.com  Thu Dec 10 16:50:26 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Thu, 10 Dec 2009 09:50:26 -0600
Subject: [R-SIG-Finance] xts and na.omit "unsupported type"
In-Reply-To: <e8e755250912100707j4e14917eva1c1110ccdc4dea9@mail.gmail.com>
References: <4B2101BD.60305@inrim.it> <4B210460.6050108@braverock.com>
	<e8e755250912100707j4e14917eva1c1110ccdc4dea9@mail.gmail.com>
Message-ID: <e8e755250912100750p5c3ce93qb9d5e86e08ba337d@mail.gmail.com>

Just a quick update.

This has been patched in the R-forge repos. A new version for CRAN
will be out soon.

Thanks,
Jeff

On Thu, Dec 10, 2009 at 9:07 AM, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:
> Actually more a question for the developers :)
>
> Seems to be a bug in the code. ?I will fix.
> For now, Brian's suggestion is best.
>
> Thanks,
> Jeff
>
> On Thu, Dec 10, 2009 at 8:23 AM, Brian G. Peterson <brian at braverock.com> wrote:
>> Fabrizio Pollastri wrote:
>>>
>>> Hello,
>>> I have to remove NAs from a logical xts, but I get the error:
>>>
>>> Error in na.omit.xts(x > y) : unsupported type
>>>
>>> Example code:
>>>
>>> library(xts)
>>> x = xts(1:10,as.Date(1:10))
>>> y = xts(c(NA,9:1),as.Date(1:10))
>>> na.omit(x > y)
>>
>> x>y is a logical comparison. na.omit want s a single series as an argument.
>>
>> so, cbind your series first, na.omit, and then compare
>>
>> or skip all that and do:
>>
>> x[which(x>y)]
>>
>> and please note that this was a question for r-help, not R-SIG-Finance, as
>> it has nothing to do with finance.
>>
>> Regards,
>>
>> ? - Brian
>>
>> --
>> Brian G. Peterson
>> http://braverock.com/brian/
>> Ph: 773-459-4973
>> IM: bgpbraverock
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>
>
>
> --
> Jeffrey Ryan
> jeffrey.ryan at insightalgo.com
>
> ia: insight algorithmics
> www.insightalgo.com
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From krish.maheswaran at gmail.com  Fri Dec 11 04:28:28 2009
From: krish.maheswaran at gmail.com (km)
Date: Thu, 10 Dec 2009 19:28:28 -0800 (PST)
Subject: [R-SIG-Finance]  quantmod: get date column
Message-ID: <fc85ab5b0912101927k3a288840sac24bc0b0856f648@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091210/5369035a/attachment.pl>

From jeff.a.ryan at gmail.com  Fri Dec 11 05:14:54 2009
From: jeff.a.ryan at gmail.com (J Ryan)
Date: Thu, 10 Dec 2009 22:14:54 -0600
Subject: [R-SIG-Finance] quantmod: get date column
In-Reply-To: <fc85ab5b0912101927k3a288840sac24bc0b0856f648@mail.gmail.com>
References: <fc85ab5b0912101927k3a288840sac24bc0b0856f648@mail.gmail.com>
Message-ID: <E6764AF9-BB48-4413-9E8D-2319DC3F01E8@gmail.com>

There is no date column in most time series classes.

There is a wealth of carefully written documentation on xts and zoo  
that could be read to find the answer.

Searching this list archive would likely show you an answer too.

?xts
?index

HTH
Jeff

Jeffrey A. Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com

On Dec 10, 2009, at 9:28 PM, km <krish.maheswaran at gmail.com> wrote:

>
> Hi All:
>
> Is it possible to extract the date column from an xts object? For  
> example:
>
> library(quantmod)
> getSymbols("F")
>
> a <- head(F)
>
> a
>
>           F.Open F.High F.Low F.Close F.Volume F.Adjusted
> 2007-01-03   7.56   7.67  7.44    7.51 78652200       7.51
> 2007-01-04   7.56   7.72  7.43    7.70 63454900       7.70
> 2007-01-05   7.72   7.75  7.57    7.62 40562100       7.62
> 2007-01-08   7.63   7.75  7.62    7.73 48938500       7.73
> 2007-01-09   7.75   7.86  7.73    7.79 56732200       7.79
> 2007-01-10   7.79   7.79  7.67    7.73 42397100       7.73
>
> I want to extract the date column only and assign it to a new  
> variable.
>
>
> Thanks in advance,
> Krish
>
> -- 
> View this message in context: http://n4.nabble.com/quantmod-get-date-column-tp960769p960769.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From guillaume.yziquel at citycable.ch  Fri Dec 11 05:19:23 2009
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Fri, 11 Dec 2009 05:19:23 +0100
Subject: [R-SIG-Finance] quantmod: get date column
In-Reply-To: <fc85ab5b0912101927k3a288840sac24bc0b0856f648@mail.gmail.com>
References: <fc85ab5b0912101927k3a288840sac24bc0b0856f648@mail.gmail.com>
Message-ID: <4B21C84B.8090900@citycable.ch>

km a ?crit :
> Hi All:
> 
> Is it possible to extract the date column from an xts object? For example:
> 
> library(quantmod)
> getSymbols("F")
> 
>  a <- head(F)
> 
> a
> 
>            F.Open F.High F.Low F.Close F.Volume F.Adjusted
> 2007-01-03   7.56   7.67  7.44    7.51 78652200       7.51
> 2007-01-04   7.56   7.72  7.43    7.70 63454900       7.70
> 2007-01-05   7.72   7.75  7.57    7.62 40562100       7.62
> 2007-01-08   7.63   7.75  7.62    7.73 48938500       7.73
> 2007-01-09   7.75   7.86  7.73    7.79 56732200       7.79
> 2007-01-10   7.79   7.79  7.67    7.73 42397100       7.73
> 
> I want to extract the date column only and assign it to a new variable.
> 
> 
> Thanks in advance,
> Krish

Here you go:

>> getSymbols("F")
> [1] "F"
>> a <- head(F)
>> a
>            F.Open F.High F.Low F.Close F.Volume F.Adjusted
> 2007-01-03   7.56   7.67  7.44    7.51 78652200       7.51
> 2007-01-04   7.56   7.72  7.43    7.70 63454900       7.70
> 2007-01-05   7.72   7.75  7.57    7.62 40562100       7.62
> 2007-01-08   7.63   7.75  7.62    7.73 48938500       7.73
> 2007-01-09   7.75   7.86  7.73    7.79 56732200       7.79
> 2007-01-10   7.79   7.79  7.67    7.73 42397100       7.73
>> index(a)
> [1] "2007-01-03" "2007-01-04" "2007-01-05" "2007-01-08" "2007-01-09"
> [6] "2007-01-10"
>> 

All the best,

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From rhelpacc at gmail.com  Fri Dec 11 16:38:17 2009
From: rhelpacc at gmail.com (R_help Help)
Date: Fri, 11 Dec 2009 10:38:17 -0500
Subject: [R-SIG-Finance] Pricing guaranteed execution
In-Reply-To: <767632948.290804.1260246581432.JavaMail.root@vms228.mailsrvcs.net>
References: <767632948.290804.1260246581432.JavaMail.root@vms228.mailsrvcs.net>
Message-ID: <ad1ead5f0912110738n7afd0a1cx76e08cc7b2398bd8@mail.gmail.com>

Mark - Not really. Let me explain the setting a bit. You receive says
a day order of 1mio shares of stock XYZ. You guarantee client
execution price using some benchmark such as VWAP price of the day. In
return, you'll charge them for markup to compensate your risk. Just
wondering if anybody has put any thoughts on such a problem on how to
come up with this markup. Thanks.

On Mon, Dec 7, 2009 at 11:29 PM,  <markleeds at verizon.net> wrote:
> I doubt I can help but I'm not sure that I understand your question. Are you
> trying to simulate a strategy and
> buying and selling intraday ?
>
>
> On Dec 7, 2009, R_help Help <rhelpacc at gmail.com> wrote:
>
> Well thanks Mark. My order horizon is usually much longer. So I'm
> wondering if there's any framework for pricing such executions that
> people have put thoughts on so far? Thanks.
>
> On Mon, Dec 7, 2009 at 11:11 PM, <markleeds at verizon.net> wrote:
>> hi: you could assume the offer quote on a buy and the bid quote on a sale
>> but even that's not guaranteed if you don't
>> get there first.
>>
>>
>>
>> On Dec 7, 2009, R_help Help <rhelpacc at gmail.com> wrote:
>>
>> Hi,
>>
>> Sorry. This is probably not an R question. But I'd like to know if one
>> were to guarantee execution. Is there any framework to price the
>> markup? Thank you.
>>
>> rhelp
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>


From Christian.Prinoth at epsilonsgr.it  Fri Dec 11 17:04:23 2009
From: Christian.Prinoth at epsilonsgr.it (Christian Prinoth)
Date: Fri, 11 Dec 2009 17:04:23 +0100
Subject: [R-SIG-Finance] Pricing guaranteed execution
In-Reply-To: <ad1ead5f0912110738n7afd0a1cx76e08cc7b2398bd8@mail.gmail.com>
References: <767632948.290804.1260246581432.JavaMail.root@vms228.mailsrvcs.n
	et> <ad1ead5f0912110738n7afd0a1cx76e08cc7b2398bd8@mail.gmail.com>
Message-ID: <8D64D4652EB17048B874B0503309CFCA03BBF762@epsilon2003.epsilonsgr.it>

I don't have much direct experience on this issue, but I guess you would
take into account:
- distribution of intraday volumes
- expected tracking error volatility of the basket to be traded
(relative to whatever hedging instruments your desk has)

For instance, a sell side trading desk would price a risk trade so that
they do not lose in the worst case scenario setting price equal to
expected loss (which might be estimated by 2*expected tracking error of
the portion of the basket that they are unable to readily hedge).

Christian Prinoth <cp at epsilonsgr.it>
Epsilon SGR
+39-02-88102355


> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of
> R_help Help
> Sent: 11 December, 2009 16:38
> To: markleeds at verizon.net; r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] Pricing guaranteed execution
>
> Mark - Not really. Let me explain the setting a bit. You receive says
> a day order of 1mio shares of stock XYZ. You guarantee client
> execution price using some benchmark such as VWAP price of the day. In
> return, you'll charge them for markup to compensate your risk. Just
> wondering if anybody has put any thoughts on such a problem on how to
> come up with this markup. Thanks.
>
> On Mon, Dec 7, 2009 at 11:29 PM,  <markleeds at verizon.net> wrote:
> > I doubt I can help but I'm not sure that I understand your
> question. Are you
> > trying to simulate a strategy and
> > buying and selling intraday ?
> >
> >
> > On Dec 7, 2009, R_help Help <rhelpacc at gmail.com> wrote:
> >
> > Well thanks Mark. My order horizon is usually much longer. So I'm
> > wondering if there's any framework for pricing such executions that
> > people have put thoughts on so far? Thanks.
> >
> > On Mon, Dec 7, 2009 at 11:11 PM, <markleeds at verizon.net> wrote:
> >> hi: you could assume the offer quote on a buy and the bid
> quote on a sale
> >> but even that's not guaranteed if you don't
> >> get there first.
> >>
> >>
> >>
> >> On Dec 7, 2009, R_help Help <rhelpacc at gmail.com> wrote:
> >>
> >> Hi,
> >>
> >> Sorry. This is probably not an R question. But I'd like to
> know if one
> >> were to guarantee execution. Is there any framework to price the
> >> markup? Thank you.
> >>
> >> rhelp
> >>
> >> _______________________________________________
> >> R-SIG-Finance at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >> -- Subscriber-posting only.
> >> -- If you want to post, subscribe first.
> >>
> >
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>

DISCLAIMER:\ L'utilizzo non autorizzato del presente mes...{{dropped:16}}


From n_torenvliet at hotmail.com  Fri Dec 11 17:51:53 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Fri, 11 Dec 2009 11:51:53 -0500
Subject: [R-SIG-Finance] Accessing getSymbols data
In-Reply-To: <SNT114-DS20D590088CE91E08FA434FD08E0@phx.gbl>
References: <e8e755250912090948p3e1a3bd3gea6f16a5c225d3c6@mail.gmail.com>,
	<SNT114-DS20D590088CE91E08FA434FD08E0@phx.gbl>
Message-ID: <BAY143-W110AA33B1A8E6759335BB8FE8C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091211/67a9a27e/attachment.pl>

From josh.m.ulrich at gmail.com  Fri Dec 11 17:56:34 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 11 Dec 2009 10:56:34 -0600
Subject: [R-SIG-Finance] Accessing getSymbols data
In-Reply-To: <BAY143-W110AA33B1A8E6759335BB8FE8C0@phx.gbl>
References: <e8e755250912090948p3e1a3bd3gea6f16a5c225d3c6@mail.gmail.com> 
	<SNT114-DS20D590088CE91E08FA434FD08E0@phx.gbl>
	<BAY143-W110AA33B1A8E6759335BB8FE8C0@phx.gbl>
Message-ID: <8cca69990912110856q6cbd37c6j51ea65bd19e3ab93@mail.gmail.com>

>From ?getSymbols:

Details:

     'getSymbols' is a wrapper to load data from different sources - be
     them local or remote. Data is fetched through one of the available
     'getSymbols' methods and saved in the 'env' specified - the
     .GlobalEnv by default. Data is loaded in much the same way that
     'load' behaves. By default, it is assigned automatically to a
     variable in the specified environment, _without_ the user
     explicitly assigning the returned data to a variable.

     The previous sentence's point warrants repeating - getSymbols is
     called for its side effects, and _does not_ return the data object
     loaded. The data is ?loaded? silently by the function into a new
     environment by default - or the environment specified. This
     behavior can be overridden by setting auto.assign to FALSE, though
     it is not advised.

Best,
Josh
--
http://www.fosstrading.com



On Fri, Dec 11, 2009 at 10:51 AM, Nick Torenvliet
<n_torenvliet at hotmail.com> wrote:
>
> I'm working with the following code:
>
> ? ? ? ?atmpt <- try(table <- getSymbols(yahooSymbol))
> ? ? ? ?options(show.error.messages = TRUE)
> ? ? ? ?if(inherits(atmpt, "try-error"){
> ? ? ? ?} else {
> ? ? ? ? ? ?# insert data from table here
> ? ? ? ? ? ?for (i in 1:length(table)){
> ? ? ? ? ? ? ? ?sql <- paste("Insert into ", myDBSymbol," (dayDate, dayOpen, dayHigh, dayLow, dayClose, dayVolume, dayAdjustment) values (",index(table[i]),",", ?table[i,],",", table[i,2],",", table[i,3],",", table[i,4],",", table[i,5],",", symbolData[i,6],")")
> ? ? ? ? ? ? ? ?atmpt <- try(dbGetQuery( con, sql))
> ? ? ? ? ? ? ? ?options(show.error.messages = TRUE)
> ? ? ? ? ? ? ? ?if(inherits(dataEntry, "try-error")){
> ? ? ? ? ? ? ? ? ? ?dataEntry <- NA
> ? ? ? ? ? ? ? ?} else {
> ? ? ? ? ? ? ? ?}
> ? ? ? ? ? ?}
> ? ? ? ?}
>
> I imagine you can see a heap of errors in the code above but my first problem is that I'm not accessing the data returned from getSymbols properly and the insert statement fails on bad data.
>
> AAB.TO happens to be the value of ?yahooSymbol, from the R prompt I get
>
>> length(AAB.TO)
> [1] 4452
>> length(table)
> [1] 1
>> length(yahooSymbol)
> [1] 1
>
> Accessing AAB.TO is easy enough, but the code is part of a loop where the symbol in yahooSymbol changes each iteration, can anyone help me to access the values returned by getSymbol dynamically as by the insert statement above?
>
> Regards,
>
> Nick
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From n_torenvliet at hotmail.com  Fri Dec 11 18:00:57 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Fri, 11 Dec 2009 12:00:57 -0500
Subject: [R-SIG-Finance] Accessing getSymbols data
In-Reply-To: <8cca69990912110856q6cbd37c6j51ea65bd19e3ab93@mail.gmail.com>
References: <e8e755250912090948p3e1a3bd3gea6f16a5c225d3c6@mail.gmail.com>,
	<SNT114-DS20D590088CE91E08FA434FD08E0@phx.gbl>
	<BAY143-W110AA33B1A8E6759335BB8FE8C0@phx.gbl>,
	<8cca69990912110856q6cbd37c6j51ea65bd19e3ab93@mail.gmail.com>
Message-ID: <BAY143-W145AEF42F530E65D81F7B1FE8C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091211/98ac3f51/attachment.pl>

From patrick at burns-stat.com  Fri Dec 11 18:05:46 2009
From: patrick at burns-stat.com (Patrick Burns)
Date: Fri, 11 Dec 2009 17:05:46 +0000
Subject: [R-SIG-Finance] Pricing guaranteed execution
In-Reply-To: <ad1ead5f0912110738n7afd0a1cx76e08cc7b2398bd8@mail.gmail.com>
References: <767632948.290804.1260246581432.JavaMail.root@vms228.mailsrvcs.net>
	<ad1ead5f0912110738n7afd0a1cx76e08cc7b2398bd8@mail.gmail.com>
Message-ID: <4B227BEA.1050305@burns-stat.com>

I would think that the two main determinants
would be how good your trading is and how
much your competitions charges.

The connect to R would be to use it to analyze
historical records of trading.


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of "The R Inferno" and "A Guide for the Unwilling S User")

R_help Help wrote:
> Mark - Not really. Let me explain the setting a bit. You receive says
> a day order of 1mio shares of stock XYZ. You guarantee client
> execution price using some benchmark such as VWAP price of the day. In
> return, you'll charge them for markup to compensate your risk. Just
> wondering if anybody has put any thoughts on such a problem on how to
> come up with this markup. Thanks.
> 
> On Mon, Dec 7, 2009 at 11:29 PM,  <markleeds at verizon.net> wrote:
>> I doubt I can help but I'm not sure that I understand your question. Are you
>> trying to simulate a strategy and
>> buying and selling intraday ?
>>
>>
>> On Dec 7, 2009, R_help Help <rhelpacc at gmail.com> wrote:
>>
>> Well thanks Mark. My order horizon is usually much longer. So I'm
>> wondering if there's any framework for pricing such executions that
>> people have put thoughts on so far? Thanks.
>>
>> On Mon, Dec 7, 2009 at 11:11 PM, <markleeds at verizon.net> wrote:
>>> hi: you could assume the offer quote on a buy and the bid quote on a sale
>>> but even that's not guaranteed if you don't
>>> get there first.
>>>
>>>
>>>
>>> On Dec 7, 2009, R_help Help <rhelpacc at gmail.com> wrote:
>>>
>>> Hi,
>>>
>>> Sorry. This is probably not an R question. But I'd like to know if one
>>> were to guarantee execution. Is there any framework to price the
>>> markup? Thank you.
>>>
>>> rhelp
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
>


From n_torenvliet at hotmail.com  Fri Dec 11 18:07:24 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Fri, 11 Dec 2009 12:07:24 -0500
Subject: [R-SIG-Finance] Accessing getSymbols data
In-Reply-To: <BAY143-W145AEF42F530E65D81F7B1FE8C0@phx.gbl>
References: <e8e755250912090948p3e1a3bd3gea6f16a5c225d3c6@mail.gmail.com>, ,
	<SNT114-DS20D590088CE91E08FA434FD08E0@phx.gbl>,
	<BAY143-W110AA33B1A8E6759335BB8FE8C0@phx.gbl>, ,
	<8cca69990912110856q6cbd37c6j51ea65bd19e3ab93@mail.gmail.com>,
	<BAY143-W145AEF42F530E65D81F7B1FE8C0@phx.gbl>
Message-ID: <BAY143-W30CFC6EECE6FB263D92BDFE8C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091211/84a62f08/attachment.pl>

From josh.m.ulrich at gmail.com  Fri Dec 11 18:07:09 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 11 Dec 2009 11:07:09 -0600
Subject: [R-SIG-Finance] Accessing getSymbols data
In-Reply-To: <BAY143-W145AEF42F530E65D81F7B1FE8C0@phx.gbl>
References: <e8e755250912090948p3e1a3bd3gea6f16a5c225d3c6@mail.gmail.com> 
	<SNT114-DS20D590088CE91E08FA434FD08E0@phx.gbl>
	<BAY143-W110AA33B1A8E6759335BB8FE8C0@phx.gbl> 
	<8cca69990912110856q6cbd37c6j51ea65bd19e3ab93@mail.gmail.com> 
	<BAY143-W145AEF42F530E65D81F7B1FE8C0@phx.gbl>
Message-ID: <8cca69990912110907m5a97fa84t21498aab9529347@mail.gmail.com>

Specifically,

"By default, it is assigned automatically to a variable in the
specified environment, _without_ the user explicitly assigning the
returned data to a variable."
...
"This behavior can be overridden by setting auto.assign to FALSE,
though it is not advised."

So,
table <- getSymbols(yahooSymbol)
does not do what you think it does.  If you want to assign the results
of getSymbols() to a variable, you need to set auto.assign=FALSE.

> table <- getSymbols("SPY", auto.assign=FALSE)
> length(table)
[1] 4452

HTH,
Josh
--
http://www.fosstrading.com



On Fri, Dec 11, 2009 at 11:00 AM, Nick Torenvliet
<n_torenvliet at hotmail.com> wrote:
>
> Yeah I got but didn't get that part... the data is loaded in AAB.TO I can access it... e.g.
>
>> AAB.TO[1]
> ? ? ? ? ? AAB.TO.Open AAB.TO.High AAB.TO.Low AAB.TO.Close AAB.TO.Volume
> 2007-01-02 ? ? ? ?0.97 ? ? ? ? ? 1 ? ? ? 0.96 ? ? ? ? 0.96 ? ? ? ? 10500
> ? ? ? ? ? AAB.TO.Adjusted
> 2007-01-02 ? ? ? ? ? ?0.96
>
> does the R shell access all the environments by default whilst the R script does not?
>
>> From: josh.m.ulrich at gmail.com
>> Date: Fri, 11 Dec 2009 10:56:34 -0600
>> Subject: Re: [R-SIG-Finance] Accessing getSymbols data
>> To: n_torenvliet at hotmail.com
>> CC: r-sig-finance at stat.math.ethz.ch
>>
>> From ?getSymbols:
>>
>> Details:
>>
>> ? ? ?'getSymbols' is a wrapper to load data from different sources - be
>> ? ? ?them local or remote. Data is fetched through one of the available
>> ? ? ?'getSymbols' methods and saved in the 'env' specified - the
>> ? ? ?.GlobalEnv by default. Data is loaded in much the same way that
>> ? ? ?'load' behaves. By default, it is assigned automatically to a
>> ? ? ?variable in the specified environment, _without_ the user
>> ? ? ?explicitly assigning the returned data to a variable.
>>
>> ? ? ?The previous sentence's point warrants repeating - getSymbols is
>> ? ? ?called for its side effects, and _does not_ return the data object
>> ? ? ?loaded. The data is ?loaded? silently by the function into a new
>> ? ? ?environment by default - or the environment specified. This
>> ? ? ?behavior can be overridden by setting auto.assign to FALSE, though
>> ? ? ?it is not advised.
>>
>> Best,
>> Josh
>> --
>> http://www.fosstrading.com
>>
>>
>>
>> On Fri, Dec 11, 2009 at 10:51 AM, Nick Torenvliet
>> <n_torenvliet at hotmail.com> wrote:
>> >
>> > I'm working with the following code:
>> >
>> > ? ? ? ?atmpt <- try(table <- getSymbols(yahooSymbol))
>> > ? ? ? ?options(show.error.messages = TRUE)
>> > ? ? ? ?if(inherits(atmpt, "try-error"){
>> > ? ? ? ?} else {
>> > ? ? ? ? ? ?# insert data from table here
>> > ? ? ? ? ? ?for (i in 1:length(table)){
>> > ? ? ? ? ? ? ? ?sql <- paste("Insert into ", myDBSymbol," (dayDate, dayOpen, dayHigh, dayLow, dayClose, dayVolume, dayAdjustment) values (",index(table[i]),",", ?table[i,],",", table[i,2],",", table[i,3],",", table[i,4],",", table[i,5],",", symbolData[i,6],")")
>> > ? ? ? ? ? ? ? ?atmpt <- try(dbGetQuery( con, sql))
>> > ? ? ? ? ? ? ? ?options(show.error.messages = TRUE)
>> > ? ? ? ? ? ? ? ?if(inherits(dataEntry, "try-error")){
>> > ? ? ? ? ? ? ? ? ? ?dataEntry <- NA
>> > ? ? ? ? ? ? ? ?} else {
>> > ? ? ? ? ? ? ? ?}
>> > ? ? ? ? ? ?}
>> > ? ? ? ?}
>> >
>> > I imagine you can see a heap of errors in the code above but my first problem is that I'm not accessing the data returned from getSymbols properly and the insert statement fails on bad data.
>> >
>> > AAB.TO happens to be the value of ?yahooSymbol, from the R prompt I get
>> >
>> >> length(AAB.TO)
>> > [1] 4452
>> >> length(table)
>> > [1] 1
>> >> length(yahooSymbol)
>> > [1] 1
>> >
>> > Accessing AAB.TO is easy enough, but the code is part of a loop where the symbol in yahooSymbol changes each iteration, can anyone help me to access the values returned by getSymbol dynamically as by the insert statement above?
>> >
>> > Regards,
>> >
>> > Nick
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only.
>> > -- If you want to post, subscribe first.
>> >
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From n_torenvliet at hotmail.com  Fri Dec 11 18:10:38 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Fri, 11 Dec 2009 12:10:38 -0500
Subject: [R-SIG-Finance] Accessing getSymbols data
In-Reply-To: <8cca69990912110907m5a97fa84t21498aab9529347@mail.gmail.com>
References: <e8e755250912090948p3e1a3bd3gea6f16a5c225d3c6@mail.gmail.com>,
	<SNT114-DS20D590088CE91E08FA434FD08E0@phx.gbl>
	<BAY143-W110AA33B1A8E6759335BB8FE8C0@phx.gbl>,
	<8cca69990912110856q6cbd37c6j51ea65bd19e3ab93@mail.gmail.com>,
	<BAY143-W145AEF42F530E65D81F7B1FE8C0@phx.gbl>,
	<8cca69990912110907m5a97fa84t21498aab9529347@mail.gmail.com>
Message-ID: <BAY143-W11503529B4EFDFFBA607EAFE8C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091211/08368e04/attachment.pl>

From bjorn.hertzberg at gmail.com  Fri Dec 11 23:46:28 2009
From: bjorn.hertzberg at gmail.com (Bjorn Hertzberg)
Date: Fri, 11 Dec 2009 23:46:28 +0100
Subject: [R-SIG-Finance] Pricing guaranteed execution
In-Reply-To: <ad1ead5f0912110738n7afd0a1cx76e08cc7b2398bd8@mail.gmail.com>
References: <767632948.290804.1260246581432.JavaMail.root@vms228.mailsrvcs.net>
	<ad1ead5f0912110738n7afd0a1cx76e08cc7b2398bd8@mail.gmail.com>
Message-ID: <73B3E962-1FC3-485B-9E5C-4B8FD365DDF5@gmail.com>

The book "Optimal trading strategies" by Kissell & Glantz cover this  
if my memory servs me correctly.

Not aware of any implementations of it though...

/b


Skickat fr?n min iPhone

11 dec 2009 kl. 16.38 skrev R_help Help <rhelpacc at gmail.com>:

> Mark - Not really. Let me explain the setting a bit. You receive says
> a day order of 1mio shares of stock XYZ. You guarantee client
> execution price using some benchmark such as VWAP price of the day. In
> return, you'll charge them for markup to compensate your risk. Just
> wondering if anybody has put any thoughts on such a problem on how to
> come up with this markup. Thanks.
>
> On Mon, Dec 7, 2009 at 11:29 PM,  <markleeds at verizon.net> wrote:
>> I doubt I can help but I'm not sure that I understand your  
>> question. Are you
>> trying to simulate a strategy and
>> buying and selling intraday ?
>>
>>
>> On Dec 7, 2009, R_help Help <rhelpacc at gmail.com> wrote:
>>
>> Well thanks Mark. My order horizon is usually much longer. So I'm
>> wondering if there's any framework for pricing such executions that
>> people have put thoughts on so far? Thanks.
>>
>> On Mon, Dec 7, 2009 at 11:11 PM, <markleeds at verizon.net> wrote:
>>> hi: you could assume the offer quote on a buy and the bid quote on  
>>> a sale
>>> but even that's not guaranteed if you don't
>>> get there first.
>>>
>>>
>>>
>>> On Dec 7, 2009, R_help Help <rhelpacc at gmail.com> wrote:
>>>
>>> Hi,
>>>
>>> Sorry. This is probably not an R question. But I'd like to know if  
>>> one
>>> were to guarantee execution. Is there any framework to price the
>>> markup? Thank you.
>>>
>>> rhelp
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
>>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From marcolondonuk at googlemail.com  Sat Dec 12 12:45:10 2009
From: marcolondonuk at googlemail.com (Marco Bianchi)
Date: Sat, 12 Dec 2009 11:45:10 +0000
Subject: [R-SIG-Finance] download yahoo quotes using tseries
	get.hist.quote(), error 404
Message-ID: <91D9DAE4-E0BA-4F5F-AA8F-01CCD7C8B52F@gmail.com>

I am using the command get.hist.quote() from the tseries library to  
download daily equity prices for European stocks.
As I am looping over a long list of tickers, at some point the R code  
is crushing on some tickers giving error 404,
as if the ticker was unknown to Yahoo.

The problem is that I have experienced this 404 error with tickers  
like TEF.MC or HSBA.L (Telefonica and Barclays) which are liquid  
stocks and correct tickers in finance.yahoo.com.

Are other R-finance users experiencing the same problem? Is this  
related to R or the nature is more operating system problem (I am  
running R under Windows XP)?

I have also investigated the possibility to use getSymbols() command  
in quantmod library, but then it seems that a number of European  
stocks are not available? Also,
using get.hist.quote() gives the possibility to download the time  
series as calendar days (rather than trading days), hence producing a  
series of equal length for each ticker.
I do not seem to see the same feature available in quantmod  
getSymbols() command...

Any help from other R-finance users very much appreciated.

Marco


From jeff.a.ryan at gmail.com  Sat Dec 12 16:14:03 2009
From: jeff.a.ryan at gmail.com (J Ryan)
Date: Sat, 12 Dec 2009 09:14:03 -0600
Subject: [R-SIG-Finance] download yahoo quotes using tseries
	get.hist.quote(), error 404
In-Reply-To: <91D9DAE4-E0BA-4F5F-AA8F-01CCD7C8B52F@gmail.com>
References: <91D9DAE4-E0BA-4F5F-AA8F-01CCD7C8B52F@gmail.com>
Message-ID: <889EF5FE-51B8-4D22-9587-81BDB299D424@gmail.com>

You may just be getting timed out by the yahoo servers, as they have  
every right to throttle requests.

Try adding in Sys.sleep(1) between calls, as well as a try call.

getSymbols works on TEF.MC, though my testing is limited to ssh on an  
iPhone so it is a bit limited.

getSymbols also does no processing of raw data by design. Post  
download processing is better handled by tools in zoo/xts/R than  
trying to wrap into getSymbols was the thinking.

Using ?merge.xts against a common time index would be the best way to  
assure identical times across symbols.

Best,
Jeff

Jeffrey A. Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com

On Dec 12, 2009, at 5:45 AM, Marco Bianchi  
<marcolondonuk at googlemail.com> wrote:

> I am using the command get.hist.quote() from the tseries library to  
> download daily equity prices for European stocks.
> As I am looping over a long list of tickers, at some point the R  
> code is crushing on some tickers giving error 404,
> as if the ticker was unknown to Yahoo.
>
> The problem is that I have experienced this 404 error with tickers  
> like TEF.MC or HSBA.L (Telefonica and Barclays) which are liquid  
> stocks and correct tickers in finance.yahoo.com.
>
> Are other R-finance users experiencing the same problem? Is this  
> related to R or the nature is more operating system problem (I am  
> running R under Windows XP)?
>
> I have also investigated the possibility to use getSymbols() command  
> in quantmod library, but then it seems that a number of European  
> stocks are not available? Also,
> using get.hist.quote() gives the possibility to download the time  
> series as calendar days (rather than trading days), hence producing  
> a series of equal length for each ticker.
> I do not seem to see the same feature available in quantmod  
> getSymbols() command...
>
> Any help from other R-finance users very much appreciated.
>
> Marco
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From marcolondonuk at googlemail.com  Sat Dec 12 17:26:02 2009
From: marcolondonuk at googlemail.com (Marco Bianchi)
Date: Sat, 12 Dec 2009 16:26:02 +0000
Subject: [R-SIG-Finance] download yahoo quotes using tseries
	get.hist.quote(), error 404
In-Reply-To: <889EF5FE-51B8-4D22-9587-81BDB299D424@gmail.com>
References: <91D9DAE4-E0BA-4F5F-AA8F-01CCD7C8B52F@gmail.com>
	<889EF5FE-51B8-4D22-9587-81BDB299D424@gmail.com>
Message-ID: <531b284b0912120826u476703bck4ab54d79c19158a1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091212/139a44ba/attachment.pl>

From kriskumar at earthlink.net  Sun Dec 13 01:27:45 2009
From: kriskumar at earthlink.net (Krishna)
Date: Sat, 12 Dec 2009 19:27:45 -0500
Subject: [R-SIG-Finance] Pricing guaranteed execution
In-Reply-To: <73B3E962-1FC3-485B-9E5C-4B8FD365DDF5@gmail.com>
References: <767632948.290804.1260246581432.JavaMail.root@vms228.mailsrvcs.net>
	<ad1ead5f0912110738n7afd0a1cx76e08cc7b2398bd8@mail.gmail.com>
	<73B3E962-1FC3-485B-9E5C-4B8FD365DDF5@gmail.com>
Message-ID: <059AA3E0-E8D5-4320-91AE-F14D46EB1A79@earthlink.net>

Yes that book covers it, there is also a paper by Robert Almgren &  
Neil Chriss that goes into this in detail as well.


On Dec 11, 2009, at 5:46 PM, Bjorn Hertzberg  
<bjorn.hertzberg at gmail.com> wrote:

> The book "Optimal trading strategies" by Kissell & Glantz cover this  
> if my memory servs me correctly.
>
> Not aware of any implementations of it though...
>
> /b
>
>
> Skickat fr?n min iPhone
>
> 11 dec 2009 kl. 16.38 skrev R_help Help <rhelpacc at gmail.com>:
>
>> Mark - Not really. Let me explain the setting a bit. You receive says
>> a day order of 1mio shares of stock XYZ. You guarantee client
>> execution price using some benchmark such as VWAP price of the day.  
>> In
>> return, you'll charge them for markup to compensate your risk. Just
>> wondering if anybody has put any thoughts on such a problem on how to
>> come up with this markup. Thanks.
>>
>> On Mon, Dec 7, 2009 at 11:29 PM,  <markleeds at verizon.net> wrote:
>>> I doubt I can help but I'm not sure that I understand your  
>>> question. Are you
>>> trying to simulate a strategy and
>>> buying and selling intraday ?
>>>
>>>
>>> On Dec 7, 2009, R_help Help <rhelpacc at gmail.com> wrote:
>>>
>>> Well thanks Mark. My order horizon is usually much longer. So I'm
>>> wondering if there's any framework for pricing such executions that
>>> people have put thoughts on so far? Thanks.
>>>
>>> On Mon, Dec 7, 2009 at 11:11 PM, <markleeds at verizon.net> wrote:
>>>> hi: you could assume the offer quote on a buy and the bid quote  
>>>> on a sale
>>>> but even that's not guaranteed if you don't
>>>> get there first.
>>>>
>>>>
>>>>
>>>> On Dec 7, 2009, R_help Help <rhelpacc at gmail.com> wrote:
>>>>
>>>> Hi,
>>>>
>>>> Sorry. This is probably not an R question. But I'd like to know  
>>>> if one
>>>> were to guarantee execution. Is there any framework to price the
>>>> markup? Thank you.
>>>>
>>>> rhelp
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only.
>>>> -- If you want to post, subscribe first.
>>>>
>>>
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From heshriti at gmail.com  Sun Dec 13 18:26:02 2009
From: heshriti at gmail.com (Mahesh Krishnan)
Date: Sun, 13 Dec 2009 09:26:02 -0800
Subject: [R-SIG-Finance] seasonal model
Message-ID: <33f6aa6f0912130926x4ad6d231he96a2d88ad3e5502@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091213/7f4971b6/attachment.pl>

From kschriek at gmail.com  Mon Dec 14 07:05:52 2009
From: kschriek at gmail.com (Karl Schriek)
Date: Mon, 14 Dec 2009 08:05:52 +0200
Subject: [R-SIG-Finance] GLM correcting for serial correlation
Message-ID: <88394bdb0912132205w4a19b502k6ec7d3cb6a4097f4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091214/956758a5/attachment.pl>

From weihanliu2002 at yahoo.com  Mon Dec 14 11:02:32 2009
From: weihanliu2002 at yahoo.com (Wei-han Liu)
Date: Mon, 14 Dec 2009 02:02:32 -0800 (PST)
Subject: [R-SIG-Finance] numerical integration
Message-ID: <235578.80668.qm@web53504.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091214/957692b5/attachment.pl>

From brian at braverock.com  Mon Dec 14 11:12:01 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 14 Dec 2009 04:12:01 -0600
Subject: [R-SIG-Finance] numerical integration
In-Reply-To: <235578.80668.qm@web53504.mail.re2.yahoo.com>
References: <235578.80668.qm@web53504.mail.re2.yahoo.com>
Message-ID: <4B260F71.5060103@braverock.com>

Wei-han Liu wrote:
> Dear R Users:
> 
> 
> I am running ADAPT package for numerical integration. The speed is somewhat slow and I wonder if there is some way to improve it.
> 
> The whole computing process cannot be completed in one try because the program shuts down itself. Listed below is the error message
> 
>  
> file(file, ifelse(append, "a", "w"):cannot open connection
> Not enough space
> 
> Before I close the R session and save the workspace, it also show the error message las follows:
>  
> In gzfile(file, "wb") cannot open compressed file '.RDataTmp', probable reason 'Not enough space'
> 
> Could somebody be kind enough to share some tips to help out?

Get a bigger hard drive and more RAM.   Per these errors, you don't have enough 
space to complete the calculation.

Regards,

   - Brian


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From matthieu.stigler at gmail.com  Mon Dec 14 11:20:38 2009
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Mon, 14 Dec 2009 11:20:38 +0100
Subject: [R-SIG-Finance] GLM correcting for serial correlation
In-Reply-To: <88394bdb0912132205w4a19b502k6ec7d3cb6a4097f4@mail.gmail.com>
References: <88394bdb0912132205w4a19b502k6ec7d3cb6a4097f4@mail.gmail.com>
Message-ID: <111060c20912140220q5e048470u3e3c6ce9255e41f2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091214/2e13c973/attachment.pl>

From eduard.pieterse at macquarie.com  Mon Dec 14 14:35:51 2009
From: eduard.pieterse at macquarie.com (ehcpieterse)
Date: Mon, 14 Dec 2009 05:35:51 -0800 (PST)
Subject: [R-SIG-Finance]  RBloomberg
Message-ID: <1260797751328-963530.post@n4.nabble.com>


Hi,

I have updated my version of R to 2.10.0, as I have a new workstation. In
loading the RBloomberg package, I encounter the following message from the
RDCOMClient load: " package was built under 2.9.1 and will not work
properly"

I have downloaded the RDCOMClient shown on CRAN, but the message persists.
Does anyone know if an updated version of the package exists somewhere else?
Alternatively, how do I fix the problem? I have also ran the
update.packages() command.

Thanks,
Eduard
-- 
View this message in context: http://n4.nabble.com/RBloomberg-tp963530p963530.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Mon Dec 14 14:48:34 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 14 Dec 2009 07:48:34 -0600
Subject: [R-SIG-Finance] RBloomberg
In-Reply-To: <1260797751328-963530.post@n4.nabble.com>
References: <1260797751328-963530.post@n4.nabble.com>
Message-ID: <4B264232.5080809@braverock.com>

ehcpieterse wrote:
> Hi,
>
> I have updated my version of R to 2.10.0, as I have a new workstation. In
> loading the RBloomberg package, I encounter the following message from the
> RDCOMClient load: " package was built under 2.9.1 and will not work
> properly"
>
> I have downloaded the RDCOMClient shown on CRAN, but the message persists.
> Does anyone know if an updated version of the package exists somewhere else?
> Alternatively, how do I fix the problem? I have also ran the
> update.packages() command.
>   
Eduard,

I believe the message is likely a WARNING, not a stop error, and is just 
warning you that things *may* not work properly, mostly help files, iirc.

When reporting errors, please copy the entire error into your email as a 
general policy.  There is usually quite a lot of information contained 
in the error (or sequence of errors) if you pay close attention.

Also, Ana has previously posted to the list that RBloomberg is being 
moved off the RDCOMClient and posted details of the new version.  
Perhaps you should look in the archives and try the newer version of the 
code.

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From matthieu.stigler at gmail.com  Mon Dec 14 15:33:12 2009
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Mon, 14 Dec 2009 15:33:12 +0100
Subject: [R-SIG-Finance] RBloomberg
In-Reply-To: <4B264232.5080809@braverock.com>
References: <1260797751328-963530.post@n4.nabble.com>
	<4B264232.5080809@braverock.com>
Message-ID: <111060c20912140633p2f21a83dn9d9ebc101ab49405@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091214/c84e1d00/attachment.pl>

From Eduard.Pieterse at macquarie.com  Mon Dec 14 15:46:37 2009
From: Eduard.Pieterse at macquarie.com (Eduard Pieterse (Macquarie Securities))
Date: Mon, 14 Dec 2009 14:46:37 -0000
Subject: [R-SIG-Finance] RBloomberg
In-Reply-To: <111060c20912140633p2f21a83dn9d9ebc101ab49405@mail.gmail.com>
References: <1260797751328-963530.post@n4.nabble.com> 
	<4B264232.5080809@braverock.com> 
	<111060c20912140633p2f21a83dn9d9ebc101ab49405@mail.gmail.com>
Message-ID: <A4B987FA3EE557449BC63149ED42D378062F6B55@ntlonexm01.pc.internal.macquarie.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091214/0787d69d/attachment.pl>

From etheber at gmx.de  Mon Dec 14 17:55:56 2009
From: etheber at gmx.de (Thomas Etheber)
Date: Mon, 14 Dec 2009 17:55:56 +0100
Subject: [R-SIG-Finance] Regression & quantmod
Message-ID: <4B266E1C.9090402@gmx.de>

Hi all,

I just wanted to estimate a single index model using the quotes derived 
from the quantmod-package as pasted below.

Does somebody know why the first regression is not working as expected? 
Why do I have to cast the xts series to the datatype numeric or what am 
I missing?

Best regards,
Thomas

<<<<<<<<<<<<<<

require("quantmod")
getSymbols( "DTE.DE")
getSymbols( "^GDAXI")
dteReturns <- ClCl( DTE.DE )
daxReturns <- ClCl(GDAXI)
dteReturn <- merge( dteReturn, daxReturn, all=FALSE)[,1]
daxReturn <- merge( dteReturn, daxReturn, all=FALSE)[,2]
m <- lm ( dteReturn ~ daxReturn )
summary(m)

Call:
lm(formula = dteReturn ~ daxReturn)

Residuals:
Fehler in dimnames(x) <- dn :
L?nge von 'dimnames' [2] ungleich der Arrayausdehnung

 > m <- lm ( as.numeric(dteReturn) ~ as.numeric( daxReturn ) )
 > summary(m)

Call:
lm(formula = as.numeric(dteReturn) ~ as.numeric(daxReturn))

Residuals:
Min 1Q Median 3Q Max
-9.411e-02 -7.405e-03 2.835e-05 7.409e-03 1.524e-01

Coefficients:
Estimate Std. Error t value Pr(>|t|)
(Intercept) -0.0002645 0.0006123 -0.432 0.666
as.numeric(daxReturn) 0.6378738 0.0334159 19.089 <2e-16 ***
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.01661 on 734 degrees of freedom
(1 observation deleted due to missingness)
Multiple R-squared: 0.3317, Adjusted R-squared: 0.3308
F-statistic: 364.4 on 1 and 734 DF, p-value: < 2.2e-16


From dstjohn at math.uic.edu  Mon Dec 14 18:06:25 2009
From: dstjohn at math.uic.edu (David St John)
Date: Mon, 14 Dec 2009 11:06:25 -0600
Subject: [R-SIG-Finance] GLM correcting for serial correlation
Message-ID: <998c123e0912140906l505e9c37q8c7f291bcb23411e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091214/b218a498/attachment.pl>

From jeff.a.ryan at gmail.com  Mon Dec 14 18:12:23 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 14 Dec 2009 11:12:23 -0600
Subject: [R-SIG-Finance] Regression & quantmod
In-Reply-To: <4B266E1C.9090402@gmx.de>
References: <4B266E1C.9090402@gmx.de>
Message-ID: <e8e755250912140912t425c6c88x57e13879360c72d2@mail.gmail.com>

The likely problem is the dimensions inherent to xts.

as.numeric is a good approach, but you can also play with the quantmod
specifyModel tools.

An example working directly on your data:

> m <- specifyModel(ClCl(DTE.DE) ~ ClCl(GDAXI))

> periodicity(ClCl(DTE.DE))
Daily periodicity from 2007-01-02 to 2009-12-09

> mb <- buildModel(m,method="lm",training.per=c('2007-01-02','2009-12-09'))
> mb

quantmod object:   lm1260810442.68897   Build date:  2009-12-14 11:07:22

Model Specified:
     ClCl(DTE.DE) ~ ClCl(GDAXI)

Model Target:  ClCl.DTE.DE               Product:  DTE.DE
Model Inputs:  ClCl.GDAXI

Fitted Model:

        Modelling procedure:  lm
        Training window:  723  observations from  2007-01-03 to 2009-12-07

Call:
lm(formula = quantmod at model.formula, data = training.data)

Coefficients:
(Intercept)   ClCl.GDAXI
  3.889e-05    6.515e-01

> summary(mb)

quantmod object:   lm1260810442.68897   Build date:  2009-12-14 11:07:22

Model Specified:
     ClCl(DTE.DE) ~ ClCl(GDAXI)

Model Target:  ClCl.DTE.DE               Product:  DTE.DE
Model Inputs:  ClCl.GDAXI

Fitted Model:

        Modelling procedure:  lm
        Training window:  723  observations from  2007-01-03 to 2009-12-07

Call:
lm(formula = quantmod at model.formula, data = training.data)

Residuals:
       Min         1Q     Median         3Q        Max
-0.0892824 -0.0074720 -0.0002732  0.0070752  0.1521019

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept) 3.889e-05  6.033e-04   0.064    0.949
ClCl.GDAXI  6.515e-01  3.302e-02  19.732   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.01622 on 721 degrees of freedom
Multiple R-squared: 0.3507,     Adjusted R-squared: 0.3498
F-statistic: 389.4 on 1 and 721 DF,  p-value: < 2.2e-16


The method= can be (from the docs):

Details:

     Currently available methods include:

     lm, glm, loess, step, ppr, rpart[rpart], tree[tree],
     randomForest[randomForest], mars[mda], polymars[polspline],
     lars[lars], rq[quantreg], lqs[MASS], rlm[MASS], svm[e1071], and
     nnet[nnet].

It is quite experimental still, as its general use is often limited,
but for what you are looking at it may help.

Best,
Jeff

On Mon, Dec 14, 2009 at 10:55 AM, Thomas Etheber <etheber at gmx.de> wrote:
> Hi all,
>
> I just wanted to estimate a single index model using the quotes derived from
> the quantmod-package as pasted below.
>
> Does somebody know why the first regression is not working as expected? Why
> do I have to cast the xts series to the datatype numeric or what am I
> missing?
>
> Best regards,
> Thomas
>
> <<<<<<<<<<<<<<
>
> require("quantmod")
> getSymbols( "DTE.DE")
> getSymbols( "^GDAXI")
> dteReturns <- ClCl( DTE.DE )
> daxReturns <- ClCl(GDAXI)
> dteReturn <- merge( dteReturn, daxReturn, all=FALSE)[,1]
> daxReturn <- merge( dteReturn, daxReturn, all=FALSE)[,2]
> m <- lm ( dteReturn ~ daxReturn )
> summary(m)
>
> Call:
> lm(formula = dteReturn ~ daxReturn)
>
> Residuals:
> Fehler in dimnames(x) <- dn :
> L?nge von 'dimnames' [2] ungleich der Arrayausdehnung
>
>> m <- lm ( as.numeric(dteReturn) ~ as.numeric( daxReturn ) )
>> summary(m)
>
> Call:
> lm(formula = as.numeric(dteReturn) ~ as.numeric(daxReturn))
>
> Residuals:
> Min 1Q Median 3Q Max
> -9.411e-02 -7.405e-03 2.835e-05 7.409e-03 1.524e-01
>
> Coefficients:
> Estimate Std. Error t value Pr(>|t|)
> (Intercept) -0.0002645 0.0006123 -0.432 0.666
> as.numeric(daxReturn) 0.6378738 0.0334159 19.089 <2e-16 ***
> ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 0.01661 on 734 degrees of freedom
> (1 observation deleted due to missingness)
> Multiple R-squared: 0.3317, Adjusted R-squared: 0.3308
> F-statistic: 364.4 on 1 and 734 DF, p-value: < 2.2e-16
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From Peter.Brecknock at bp.com  Mon Dec 14 20:47:54 2009
From: Peter.Brecknock at bp.com (Brecknock, Peter)
Date: Mon, 14 Dec 2009 19:47:54 -0000
Subject: [R-SIG-Finance] GLM correcting for serial correlation
In-Reply-To: <111060c20912140220q5e048470u3e3c6ce9255e41f2@mail.gmail.com>
References: <88394bdb0912132205w4a19b502k6ec7d3cb6a4097f4@mail.gmail.com>
	<111060c20912140220q5e048470u3e3c6ce9255e41f2@mail.gmail.com>
Message-ID: <237BB61897E7FA4292E2F72B4E5D05574E1C11@BP1XEUEX042-C.bp1.ad.bp.com>

Karl 

Check out
http://www.stat.pitt.edu/stoffer/tsa2/R_time_series_quick_fix.htm

Search for "regression with autocorrelated errors" 

This offers two approaches ... using gls from the nlme package (as
suggested by Matthieu) or using arima with the xreg parameter

Best regards

Pete

-----Original Message-----
From: Matthieu Stigler [mailto:matthieu.stigler at gmail.com] 
Sent: Monday, December 14, 2009 4:21 AM
To: Karl Schriek
Cc: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] GLM correcting for serial correlation

?gls from package nlme?

2009/12/14 Karl Schriek <kschriek at gmail.com>

> Hi
>
> I have a stationary time series to which I want to fit a linear model
with
> an autoregressive term to correct for serial correlation, i.e. using
the
> formula At = c1*Bt + c2*Ct + ut, where ut = r*ut-1 + et
>
> (i.e. ut is an AR(1) term to correct for serial correlation in the
error
> terms)
>
>
> Does anyone know what to use in R to model this?
>
>
> Thanks
> Karl
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>

	[[alternative HTML version deleted]]


From kschriek at gmail.com  Tue Dec 15 13:42:04 2009
From: kschriek at gmail.com (Karl Schriek)
Date: Tue, 15 Dec 2009 14:42:04 +0200
Subject: [R-SIG-Finance] GLM correcting for serial correlation
In-Reply-To: <237BB61897E7FA4292E2F72B4E5D05574E1C11@BP1XEUEX042-C.bp1.ad.bp.com>
References: <88394bdb0912132205w4a19b502k6ec7d3cb6a4097f4@mail.gmail.com>
	<111060c20912140220q5e048470u3e3c6ce9255e41f2@mail.gmail.com>
	<237BB61897E7FA4292E2F72B4E5D05574E1C11@BP1XEUEX042-C.bp1.ad.bp.com>
Message-ID: <88394bdb0912150442l74bc7700i201a4d6ff3eb69a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091215/8603b5ca/attachment.pl>

From hubert.colt at gmail.com  Tue Dec 15 17:39:38 2009
From: hubert.colt at gmail.com (Hubert Colt)
Date: Tue, 15 Dec 2009 17:39:38 +0100
Subject: [R-SIG-Finance] dlm: dldMod Reg with constant alpha time-varying
	beta
Message-ID: <be6b11010912150839v29bb568bs7de6207afbb173d3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091215/7565a86d/attachment.pl>

From hubert.colt at gmail.com  Tue Dec 15 20:31:11 2009
From: hubert.colt at gmail.com (Hubert Colt)
Date: Tue, 15 Dec 2009 20:31:11 +0100
Subject: [R-SIG-Finance] dlm: dldMod Reg with constant alpha
	time-varying beta
In-Reply-To: <4B27DDCD.9020507@burns-stat.com>
References: <be6b11010912150839v29bb568bs7de6207afbb173d3@mail.gmail.com>
	<4B27DDCD.9020507@burns-stat.com>
Message-ID: <be6b11010912151131o319ffadewf251142963967765@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091215/28b29b68/attachment.pl>

From cipollini at ds.unifi.it  Tue Dec 15 23:21:56 2009
From: cipollini at ds.unifi.it (Fabrizio Cipollini)
Date: Tue, 15 Dec 2009 23:21:56 +0100
Subject: [R-SIG-Finance] seasonal model
Message-ID: <7b7492608de59ca5331b53501cde6ffe.squirrel@ds.unifi.it>


Dear Mahesh

Give a glance to

http://www.ds.unifi.it/ricerca/pubblicazioni/working_papers/2009/wp2009_01.pdf

The paper (currently under revision) includes also some useful references
on the topic of your interest.

Best regards
Fabrizio Cipollini


>
> Message: 1
> Date: Sun, 13 Dec 2009 09:26:02 -0800
> From: Mahesh Krishnan <heshriti at gmail.com>
> Subject: [R-SIG-Finance] seasonal model
> To: r-sig-finance at stat.math.ethz.ch
> Message-ID:
> 	<33f6aa6f0912130926x4ad6d231he96a2d88ad3e5502 at mail.gmail.com>
> Content-Type: text/plain
>
> Dear  R-modelers,
>
> I'm looking for references on modeling volume and volatility time series
> modeling with the following properties: long term trend, short term
> seasonality.
> My first guess is do something like a seasonally differenced ARMA. Has
> anyone had experience testing the properties such as out-of-sample
forecasts
> of such a model ?
> Thank you for your help.


/***************************************************
Fabrizio Cipollini
Dipartimento di Statistica Giuseppe Parenti
Viale Morgagni 59, 50134 Firenze
Skype: cipollini_fabrizio
Tel.: +39 055 4237253
Fax.: +39 055 4223560


From wuertz at itp.phys.ethz.ch  Wed Dec 16 11:39:32 2009
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Wed, 16 Dec 2009 11:39:32 +0100
Subject: [R-SIG-Finance] R/Rmetrics: Singapore Conference, Februar 19/20,
	2010
Message-ID: <4B28B8E4.2060708@itp.phys.ethz.ch>


Dear R/Rmetrics Community,

We would like to announce the first 'Computational Topics in Finance' 
conference, taking place on February 19/20, 2010, at the National 
University of Singapore.

The conference will bring together developers, practitioners, and users 
from academia, finance and insurance, providing a platform for common 
discussions and exchange of ideas in the field of computational finance 
and financial engineering.

The conference will cover the topics: Econometric Modeling, Financial 
Time Series Analysis, Volatility Forecasting, Trading and Decision 
Making Systems, Portfolio Selection and Optimization, Financial 
Stability Analysis, Stress Testing, Performance Analysis, Benchmarking, 
Risk Analysis and Measurement, Valuation of Financial Derivatives, 
Extreme Value Theory and Copulae, FX High Frequency Data Analysis, Time 
& Sales Data, Monte Carlo Simulation and Pricing, Robust Statistics in 
Finance. The topics will also include using R/Rmetrics in finance, but 
the conference is by no means confined to R.

Preceding the conference, February 17/18, 2010, the Rmetrics Association 
will be giving a two-day 'Basic R for Finance' course.

You can find out more about both events on our website, 
http://www.rmetrics.org/.

We would like to invite you to take part in the conference, and we are 
now accepting submissions; please send your one-page abstracts to 
submissions at rmetrics.org. The submission deadline is February 10, 2010.

We look forward to seeing you in Singapore.

Wishing you merry Christmas and a happy new year,

Diethelm Wuertz , Juri Hinz, Mahendra Mehta, David Scott


Organisation:
Rmetrics Association, Zurich

Supported and hosted by the
Institute for Theoretical Physics, ETH Zurich
Risk Management Institute, NUS Singapore


From mjenko at yahoo.com  Thu Dec 17 18:05:08 2009
From: mjenko at yahoo.com (Martin Jenkins)
Date: Thu, 17 Dec 2009 09:05:08 -0800 (PST)
Subject: [R-SIG-Finance] Retrieving latest day's data
In-Reply-To: <e8e755250911171438q5ca2db79n3e070ba33cc898db@mail.gmail.com>
Message-ID: <870582.94039.qm@web113204.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091217/57edc4d9/attachment.pl>

From ivan.zhang at bankofamerica.com  Thu Dec 17 19:46:35 2009
From: ivan.zhang at bankofamerica.com (Zhang, Ivan)
Date: Thu, 17 Dec 2009 13:46:35 -0500
Subject: [R-SIG-Finance] tseries and xts - time indexing in an easier way?
Message-ID: <338D58262CB96E438AD6AFEEE6D9482D978903@ex2k.bankofamerica.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091217/f67b72c7/attachment.pl>

From jeff.a.ryan at gmail.com  Thu Dec 17 19:54:34 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Thu, 17 Dec 2009 12:54:34 -0600
Subject: [R-SIG-Finance] tseries and xts - time indexing in an easier
	way?
In-Reply-To: <338D58262CB96E438AD6AFEEE6D9482D978903@ex2k.bankofamerica.com>
References: <338D58262CB96E438AD6AFEEE6D9482D978903@ex2k.bankofamerica.com>
Message-ID: <e8e755250912171054q447d2be1mdd8d982111a48994@mail.gmail.com>

Ivan,

xts requires ISO 8601 because it is the only agreed upon format that
is unambiguous in its definition.

You might be better of using zoo with yearmon.  While you'll lose the
ISO style subsetting, it seems like that isn't an issue now anyway.
The other advantage to xts is speed (as much is done with C code
internally).  For monthly data in finance this wouldn't seem to be of
much value though.  Since your series are likely not very long.

You could also use strptime or similar to format your 'request' string
into something along the lines if ISO.

HTH
Jeff

On Thu, Dec 17, 2009 at 12:46 PM, Zhang, Ivan
<ivan.zhang at bankofamerica.com> wrote:
> Hi all,
>
>
>
> I've been experimenting on tseries package, namely ts class and I've
> been having to do a workaround to have time indexing. I was wondering if
> there's an easier way. ?I am working with monthly data. i.e. I would
> like to be able to use yearmon class easily.
>
>
>
> Say I have a bunch of time series with different intervals but they have
> overlapping time frame.
>
>
>
> If I wanted to loop through them relative to some timepoint, I would
> either have to translate the time into an index, and do the
> corresponding arithmetic to calculate what that would correspond to in
> another time series.
>
>
>
> The alternate way would be to find the index by matching the time, but
> that doesn't work so well as match doesn't always come up due to
> numerical precision issues.
>
>
>
> ts1 = ts(1:10, start = c(2000,1), frequency = 12)
>
> specialtime = time(ts1)[ts1==5]
>
>
>
> ts2 = ts(1:20, start = c(2000,8), frequency = 12)
>
>
>
>
>
> ? ?for( i in 1:match(specialtime, time(ts2)))
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?ts2[i] = ...
>
>
>
>
>
> so what I end up doing is within the loop, or wherever I need to set a
> value, I end up doing:
>
>
>
> match(yearmon(specialtime), yearmon(time(ts2)))
>
>
>
> Somehow, that seems unusually unwieldly as compared to being directly
> able to index via time.
>
>
>
> So I've also tried xts with time index, however, the time index needs to
> be in ISO format whereas the times that I have is like variable
> specialtime where it's of the form 2005.3
>
>
>
> I tried converting all of the variables into xts, I also tried changing
> the indexing class into yearmon
>
> Ts3 = convertIndex(as.xts(ts2), "yearmon")
>
>
>
> Now I can do aa = time(Ts3)[1] and it is an yearmon class,
>
>
>
> however, I still can't access anything using Ts3[aa]. It gives me:
>
>
>
> Error in as.POSIXlt.character(x, tz, ...) :
>
> ?character string is not in a standard unambiguous format
>
>
>
> So I'm not sure if I'm missing something obvious, if anyone could help?
>
>
>
> Thanks,
>
>
>
> Ivan Zhang
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From mjenko at yahoo.com  Thu Dec 17 21:51:39 2009
From: mjenko at yahoo.com (Martin Jenkins)
Date: Thu, 17 Dec 2009 12:51:39 -0800 (PST)
Subject: [R-SIG-Finance] Retrieving latest day's data
In-Reply-To: <870582.94039.qm@web113204.mail.gq1.yahoo.com>
Message-ID: <163082.77991.qm@web113207.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091217/9abb5ee5/attachment.pl>

From n_torenvliet at hotmail.com  Fri Dec 18 02:02:35 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Thu, 17 Dec 2009 20:02:35 -0500
Subject: [R-SIG-Finance] getSymbols and PD-UN
In-Reply-To: <163082.77991.qm@web113207.mail.gq1.yahoo.com>
References: <870582.94039.qm@web113204.mail.gq1.yahoo.com>,
	<163082.77991.qm@web113207.mail.gq1.yahoo.com>
Message-ID: <BAY143-W203DCC6F13F621EF4A8705FE850@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091217/f8fa447c/attachment.pl>

From josh.m.ulrich at gmail.com  Fri Dec 18 02:17:40 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 17 Dec 2009 19:17:40 -0600
Subject: [R-SIG-Finance] getSymbols and PD-UN
In-Reply-To: <BAY143-W203DCC6F13F621EF4A8705FE850@phx.gbl>
References: <870582.94039.qm@web113204.mail.gq1.yahoo.com> 
	<163082.77991.qm@web113207.mail.gq1.yahoo.com>
	<BAY143-W203DCC6F13F621EF4A8705FE850@phx.gbl>
Message-ID: <8cca69990912171717r6101f4a8ha55ee2131491316a@mail.gmail.com>

Nick,

The error tells you.  The page doesn't exist because there's no
historical data for that symbol.
http://finance.yahoo.com/q/hp?s=PD-UN.TO

Best,
Josh
--
http://www.fosstrading.com



On Thu, Dec 17, 2009 at 7:02 PM, Nick Torenvliet
<n_torenvliet at hotmail.com> wrote:
>
>
> I've been playing around for some time with the Toronto Stock Exchange... I can't explain the following...
>
> Both
> atable <- getSymbols("RIM.TO",auto.assign=FALSE)
> atable <- getSymbols("PWT-UN.TO",auto.assign=FALSE)
> work fine
>
> But
>> atable <- getSymbols("PD-UN.TO",auto.assign=FALSE)
> Warning message:
> In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m, ?:
> ?cannot open: HTTP status was '404 Not Found'
> Bails
>
> PD-UN.TO is Precision Drilling Trust which can be found at http://finance.yahoo.com/q?s=PD-UN.TO
>
> Any ideas as to why I can't get PD-UN.TO to work?
>
> Nick
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From n_torenvliet at hotmail.com  Fri Dec 18 02:26:32 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Thu, 17 Dec 2009 20:26:32 -0500
Subject: [R-SIG-Finance] getSymbols and PD-UN
In-Reply-To: <8cca69990912171717r6101f4a8ha55ee2131491316a@mail.gmail.com>
References: <870582.94039.qm@web113204.mail.gq1.yahoo.com>,
	<163082.77991.qm@web113207.mail.gq1.yahoo.com>
	<BAY143-W203DCC6F13F621EF4A8705FE850@phx.gbl>,
	<8cca69990912171717r6101f4a8ha55ee2131491316a@mail.gmail.com>
Message-ID: <BAY143-W29B4C7A4D346F200F97CD7FE850@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091217/f287254c/attachment.pl>

From josh.m.ulrich at gmail.com  Fri Dec 18 02:41:11 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 17 Dec 2009 19:41:11 -0600
Subject: [R-SIG-Finance] getSymbols and PD-UN
In-Reply-To: <BAY143-W29B4C7A4D346F200F97CD7FE850@phx.gbl>
References: <870582.94039.qm@web113204.mail.gq1.yahoo.com> 
	<163082.77991.qm@web113207.mail.gq1.yahoo.com>
	<BAY143-W203DCC6F13F621EF4A8705FE850@phx.gbl> 
	<8cca69990912171717r6101f4a8ha55ee2131491316a@mail.gmail.com> 
	<BAY143-W29B4C7A4D346F200F97CD7FE850@phx.gbl>
Message-ID: <8cca69990912171741y5bc19a2fn836591c92db1eb62@mail.gmail.com>

On Thu, Dec 17, 2009 at 7:26 PM, Nick Torenvliet
<n_torenvliet at hotmail.com> wrote:
>
> Okay... I'm okay with that... why that symbol? ?Its pretty widely traded.
>
It's free data, you don't get to ask "why". ;-)

It may only be a temporary issue.  However, Google *shows* historical
data but does not let you download it.  Maybe something to do with
that exchange?
http://www.google.com/finance/historical?q=TSE:PD.UN
http://www.google.com/finance/historical?q=TSE:PD.UN&output=csv

Best,
Josh
--
http://www.fosstrading.com

>> From: josh.m.ulrich at gmail.com
>> Date: Thu, 17 Dec 2009 19:17:40 -0600
>> Subject: Re: [R-SIG-Finance] getSymbols and PD-UN
>> To: n_torenvliet at hotmail.com
>> CC: r-sig-finance at stat.math.ethz.ch
>>
>> Nick,
>>
>> The error tells you. ?The page doesn't exist because there's no
>> historical data for that symbol.
>> http://finance.yahoo.com/q/hp?s=PD-UN.TO
>>
>> Best,
>> Josh
>> --
>> http://www.fosstrading.com
>>
>>
>>
>> On Thu, Dec 17, 2009 at 7:02 PM, Nick Torenvliet
>> <n_torenvliet at hotmail.com> wrote:
>> >
>> >
>> > I've been playing around for some time with the Toronto Stock Exchange... I can't explain the following...
>> >
>> > Both
>> > atable <- getSymbols("RIM.TO",auto.assign=FALSE)
>> > atable <- getSymbols("PWT-UN.TO",auto.assign=FALSE)
>> > work fine
>> >
>> > But
>> >> atable <- getSymbols("PD-UN.TO",auto.assign=FALSE)
>> > Warning message:
>> > In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m, ?:
>> > ?cannot open: HTTP status was '404 Not Found'
>> > Bails
>> >
>> > PD-UN.TO is Precision Drilling Trust which can be found at http://finance.yahoo.com/q?s=PD-UN.TO
>> >
>> > Any ideas as to why I can't get PD-UN.TO to work?
>> >
>> > Nick
>> >
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only.
>> > -- If you want to post, subscribe first.
>> >
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From n_torenvliet at hotmail.com  Fri Dec 18 03:32:20 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Thu, 17 Dec 2009 21:32:20 -0500
Subject: [R-SIG-Finance] Examples IBrokers Code
In-Reply-To: <8cca69990912171741y5bc19a2fn836591c92db1eb62@mail.gmail.com>
References: <870582.94039.qm@web113204.mail.gq1.yahoo.com>,
	<163082.77991.qm@web113207.mail.gq1.yahoo.com>
	<BAY143-W203DCC6F13F621EF4A8705FE850@phx.gbl>,
	<8cca69990912171717r6101f4a8ha55ee2131491316a@mail.gmail.com>,
	<BAY143-W29B4C7A4D346F200F97CD7FE850@phx.gbl>,
	<8cca69990912171741y5bc19a2fn836591c92db1eb62@mail.gmail.com>
Message-ID: <BAY143-W16D2DD0B7DE819D5D49061FE850@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091217/534557d9/attachment.pl>

From krishna at primps.com.sg  Fri Dec 18 06:21:11 2009
From: krishna at primps.com.sg (SNV Krishna)
Date: Fri, 18 Dec 2009 13:21:11 +0800
Subject: [R-SIG-Finance] direct data download from metastock
Message-ID: <38A140A18F6C4D459BB55387804FCE6F@prpc01>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091218/0f742ba8/attachment.pl>

From cedrick at cedrickjohnson.com  Fri Dec 18 06:46:25 2009
From: cedrick at cedrickjohnson.com (Cedrick W. Johnson)
Date: Fri, 18 Dec 2009 00:46:25 -0500
Subject: [R-SIG-Finance] direct data download from metastock
In-Reply-To: <38A140A18F6C4D459BB55387804FCE6F@prpc01>
References: <38A140A18F6C4D459BB55387804FCE6F@prpc01>
Message-ID: <4B2B1731.2090202@cedrickjohnson.com>

You could try exporting the data from Metastock in csv format, then try

?read.csv


SNV Krishna wrote:
> Hi All,
>
> is there a way to download data from metastock to R-software. most of my data is in date,OHLC format downloaded from reuters to metastock software in my local pc. 
>
> many thanks for the help.,
>
> krishna
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From krishna at primps.com.sg  Fri Dec 18 07:11:45 2009
From: krishna at primps.com.sg (SNV Krishna)
Date: Fri, 18 Dec 2009 14:11:45 +0800
Subject: [R-SIG-Finance] direct data download from metastock
References: <38A140A18F6C4D459BB55387804FCE6F@prpc01>
	<4B2B1731.2090202@cedrickjohnson.com>
Message-ID: <7984FEAE3B464845B72FA1CC28743017@prpc01>

Hi Cedrick,

I can use the convert option in metastock downloader. the problem is with 
number. I have securities organized in 8 different folders with total no > 
2000. and every day these securities gets updated with reuters datalink. 
using the chain metastock (multiple securities in different folders) to csv 
and csv to r-software could be very cumbersome on a daily basis.

i am looking for better way possible.

many thanks and regards,

krishna



----- Original Message ----- 
From: "Cedrick W. Johnson" <cedrick at cedrickjohnson.com>
To: "SNV Krishna" <krishna at primps.com.sg>
Cc: <r-sig-finance at stat.math.ethz.ch>
Sent: Friday, December 18, 2009 1:46 PM
Subject: Re: [R-SIG-Finance] direct data download from metastock


> You could try exporting the data from Metastock in csv format, then try
>
> ?read.csv
>
>
> SNV Krishna wrote:
>> Hi All,
>>
>> is there a way to download data from metastock to R-software. most of my 
>> data is in date,OHLC format downloaded from reuters to metastock software 
>> in my local pc.
>> many thanks for the help.,
>>
>> krishna
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>
>


From alexios at 4dscape.com  Fri Dec 18 07:34:56 2009
From: alexios at 4dscape.com (alexios)
Date: Fri, 18 Dec 2009 06:34:56 +0000
Subject: [R-SIG-Finance] direct data download from metastock
In-Reply-To: <7984FEAE3B464845B72FA1CC28743017@prpc01>
References: <38A140A18F6C4D459BB55387804FCE6F@prpc01>	<4B2B1731.2090202@cedrickjohnson.com>
	<7984FEAE3B464845B72FA1CC28743017@prpc01>
Message-ID: <4B2B2290.5060805@4dscape.com>

There is also a metastock 2 ascii command line utility called 
MsCmdLineUtils on the net (opensource) which I have successfully used to 
automatically scan metastock folders, convert to ascii, concatenate into 
one large file and import into R. You can do all this in R with the use 
of the "system" and "file.copy" commands.

-Alexios


On 12/18/2009 6:11 AM, SNV Krishna wrote:
> Hi Cedrick,
>
> I can use the convert option in metastock downloader. the problem is
> with number. I have securities organized in 8 different folders with
> total no > 2000. and every day these securities gets updated with
> reuters datalink. using the chain metastock (multiple securities in
> different folders) to csv and csv to r-software could be very cumbersome
> on a daily basis.
>
> i am looking for better way possible.
>
> many thanks and regards,
>
> krishna
>
>
>
> ----- Original Message ----- From: "Cedrick W. Johnson"
> <cedrick at cedrickjohnson.com>
> To: "SNV Krishna" <krishna at primps.com.sg>
> Cc: <r-sig-finance at stat.math.ethz.ch>
> Sent: Friday, December 18, 2009 1:46 PM
> Subject: Re: [R-SIG-Finance] direct data download from metastock
>
>
>> You could try exporting the data from Metastock in csv format, then try
>>
>> ?read.csv
>>
>>
>> SNV Krishna wrote:
>>> Hi All,
>>>
>>> is there a way to download data from metastock to R-software. most of
>>> my data is in date,OHLC format downloaded from reuters to metastock
>>> software in my local pc.
>>> many thanks for the help.,
>>>
>>> krishna
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
>>
>>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
>


From krishna at primps.com.sg  Fri Dec 18 08:04:32 2009
From: krishna at primps.com.sg (SNV Krishna)
Date: Fri, 18 Dec 2009 15:04:32 +0800
Subject: [R-SIG-Finance] direct data download from metastock
References: <38A140A18F6C4D459BB55387804FCE6F@prpc01>	<4B2B1731.2090202@cedrickjohnson.com>
	<7984FEAE3B464845B72FA1CC28743017@prpc01>
	<4B2B2290.5060805@4dscape.com>
Message-ID: <AFE5E9631FC2445D8D5B18FA158A77EF@prpc01>

Hi Alexios,

I did a search on MsCmdLineUtils, but the geocities download link is not 
working. i just posted a query on the google group forum. in the mean time, 
is it possible for you to send me the link of package over mail so that i 
can install and try it.

thanks and regards,

krishna

----- Original Message ----- 
From: "alexios" <alexios at 4dscape.com>
To: "SNV Krishna" <krishna at primps.com.sg>
Cc: <r-sig-finance at stat.math.ethz.ch>
Sent: Friday, December 18, 2009 2:34 PM
Subject: Re: [R-SIG-Finance] direct data download from metastock


> There is also a metastock 2 ascii command line utility called 
> MsCmdLineUtils on the net (opensource) which I have successfully used to 
> automatically scan metastock folders, convert to ascii, concatenate into 
> one large file and import into R. You can do all this in R with the use of 
> the "system" and "file.copy" commands.
>
> -Alexios
>
>
> On 12/18/2009 6:11 AM, SNV Krishna wrote:
>> Hi Cedrick,
>>
>> I can use the convert option in metastock downloader. the problem is
>> with number. I have securities organized in 8 different folders with
>> total no > 2000. and every day these securities gets updated with
>> reuters datalink. using the chain metastock (multiple securities in
>> different folders) to csv and csv to r-software could be very cumbersome
>> on a daily basis.
>>
>> i am looking for better way possible.
>>
>> many thanks and regards,
>>
>> krishna
>>
>>
>>
>> ----- Original Message ----- From: "Cedrick W. Johnson"
>> <cedrick at cedrickjohnson.com>
>> To: "SNV Krishna" <krishna at primps.com.sg>
>> Cc: <r-sig-finance at stat.math.ethz.ch>
>> Sent: Friday, December 18, 2009 1:46 PM
>> Subject: Re: [R-SIG-Finance] direct data download from metastock
>>
>>
>>> You could try exporting the data from Metastock in csv format, then try
>>>
>>> ?read.csv
>>>
>>>
>>> SNV Krishna wrote:
>>>> Hi All,
>>>>
>>>> is there a way to download data from metastock to R-software. most of
>>>> my data is in date,OHLC format downloaded from reuters to metastock
>>>> software in my local pc.
>>>> many thanks for the help.,
>>>>
>>>> krishna
>>>> [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only.
>>>> -- If you want to post, subscribe first.
>>>>
>>>
>>>
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>>


From breman.mark at gmail.com  Fri Dec 18 12:30:42 2009
From: breman.mark at gmail.com (Mark Breman)
Date: Fri, 18 Dec 2009 12:30:42 +0100
Subject: [R-SIG-Finance] Counting consecutive equally signed items in a time
	series
Message-ID: <5e6a2e670912180330w6883ff2rf42ebfd0a566f954@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091218/ea5fb852/attachment.pl>

From ggrothendieck at gmail.com  Fri Dec 18 12:35:41 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 18 Dec 2009 06:35:41 -0500
Subject: [R-SIG-Finance] Counting consecutive equally signed items in a
	time series
In-Reply-To: <5e6a2e670912180330w6883ff2rf42ebfd0a566f954@mail.gmail.com>
References: <5e6a2e670912180330w6883ff2rf42ebfd0a566f954@mail.gmail.com>
Message-ID: <971536df0912180335h68cead27o52778b704e0dddf7@mail.gmail.com>

You can get the run lengths using rle:

> library(zoo)
> set.seed(1)
> z <- zoo(rnorm(25))
> rle(sign(coredata(z)))
Run Length Encoding
  lengths: int [1:14] 1 1 1 2 1 3 1 2 2 1 ...
  values : num [1:14] -1 1 -1 1 -1 1 -1 1 -1 1 ...


On Fri, Dec 18, 2009 at 6:30 AM, Mark Breman <breman.mark at gmail.com> wrote:
> Hello,
>
> I have a univariate financial time series with daily returns (xts or zoo)
> and I would like to count the number of consecutive equally signed returns
> in the series, i.e. the number of consecutive up- and down-days (this
> probably has some fancy mathematical name which I can't seem to find).
>
> Example:
>
>> usod
> ? ? ? ? ? ? ? Adjusted
> 2009-11-02 ? ? ? ? ? NA
> 2009-11-03 ?0.016001969
> 2009-11-04 ?0.009026592
> 2009-11-05 -0.004656863
> 2009-11-06 -0.027707809
> 2009-11-09 ?0.019753086
> 2009-11-10 -0.002227171
> 2009-11-11 ?0.003452528
> 2009-11-12 -0.032594856
> 2009-11-13 -0.003834356
> 2009-11-16 ?0.029039464
> 2009-11-17 ?0.004693676
> 2009-11-18 ?0.004671748
> 2009-11-19 -0.025466465
> 2009-11-20 -0.006088280
> 2009-11-23 -0.001015744
> 2009-11-24 -0.020736133
>
> I would like to get the following vector for this series:
>
> 2, -2, 1, -1, 1, -2, 3, -4
>
> meaning: 2 updays, 2 downdays, 1 upday, 1 downday etc.
>
> Is there a function in R which does that?
>
> Kind regards,
>
> -Mark-
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From n_torenvliet at hotmail.com  Fri Dec 18 12:45:21 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Fri, 18 Dec 2009 06:45:21 -0500
Subject: [R-SIG-Finance] Counting consecutive equally signed items in
	a	time series
In-Reply-To: <971536df0912180335h68cead27o52778b704e0dddf7@mail.gmail.com>
References: <5e6a2e670912180330w6883ff2rf42ebfd0a566f954@mail.gmail.com>,
	<971536df0912180335h68cead27o52778b704e0dddf7@mail.gmail.com>
Message-ID: <BAY143-W166877BB309651E5BA60B8FE850@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091218/20712446/attachment.pl>

From binabina at bellsouth.net  Sat Dec 19 19:40:27 2009
From: binabina at bellsouth.net (zubin)
Date: Sat, 19 Dec 2009 13:40:27 -0500
Subject: [R-SIG-Finance] API based Trading Lowest Commission
Message-ID: <4B2D1E1B.3040601@bellsouth.net>

Hello List,

Looking for recommendations for the lowest cost brokerage, that has an
API we can utilize for automated trading.  

Trading US listed ETFs. 

IBrokers, for about 700 shares a trade, 50$ a share, is about $8.00.  
Each trade will be in the $35K range, 500-700 shares. 

Does anyone recommend alternative brokers (with an API) that are less
expensive, i was erroneously assuming $2 to $3 per trade?


From artk at congruent.com  Sat Dec 19 23:49:54 2009
From: artk at congruent.com (Arthur Kreitman)
Date: Sat, 19 Dec 2009 14:49:54 -0800
Subject: [R-SIG-Finance] API based Trading Lowest Commission
In-Reply-To: <4B2D1E1B.3040601@bellsouth.net>
References: <4B2D1E1B.3040601@bellsouth.net>
Message-ID: <8DB8983924798A41B27C1E76AA913FE8133439F745@EXVMBX020-11.exch020.serverdata.net>

The actual cost on Interactive is .0035/share minus the liquidity discount, which is .0023/share on ARCA.  So, your effective cost is .0012/share.  
The two lowest cost brokerages I know of are Interactive and Lightspeed.  Interactive is .0035/share minus any liqudity rebate.  Lightspeed is a about the same. 

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of zubin
Sent: Saturday, December 19, 2009 1:40 PM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] API based Trading Lowest Commission

Hello List,

Looking for recommendations for the lowest cost brokerage, that has an
API we can utilize for automated trading.  

Trading US listed ETFs. 

IBrokers, for about 700 shares a trade, 50$ a share, is about $8.00.  
Each trade will be in the $35K range, 500-700 shares. 

Does anyone recommend alternative brokers (with an API) that are less
expensive, i was erroneously assuming $2 to $3 per trade?

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From me at censix.com  Sun Dec 20 11:50:18 2009
From: me at censix.com (me at censix.com)
Date: Sun, 20 Dec 2009 11:50:18 +0100 (CET)
Subject: [R-SIG-Finance] FinData provider Xiginte and R
Message-ID: <35562.91.4.69.224.1261306218.squirrel@censix.com>

Hi to the list

>From following the list discussions I get that there are R packages for
pulling Bloomberg and LIM(?) data into R. Does anybody know if there is
such a package for Xignite.com ? (I looked at xignite because they provide
the financial data that is used in wolframalpha.com. I like their "you
only pay what you use" pricing model)

http://www.xignite.com/Support/GettingStarted.aspx

If not, does anyone think that creating one would be a straightforward
thing, i.e. could such a package be derived from one of the existing
packages fairly quickly?

Thanks

Soren


From r.rote12 at googlemail.com  Sun Dec 20 12:32:05 2009
From: r.rote12 at googlemail.com (Peter Rote)
Date: Sun, 20 Dec 2009 12:32:05 +0100
Subject: [R-SIG-Finance] Cannot connect with tws
Message-ID: <c68c5d80912200332w44d361b1u38812ee7d0ad6e50@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091220/5162c516/attachment.pl>

From brian at braverock.com  Sun Dec 20 12:35:31 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 20 Dec 2009 05:35:31 -0600
Subject: [R-SIG-Finance] FinData provider Xiginte and R
In-Reply-To: <35562.91.4.69.224.1261306218.squirrel@censix.com>
References: <35562.91.4.69.224.1261306218.squirrel@censix.com>
Message-ID: <4B2E0C03.1030702@braverock.com>

me at censix.com wrote:
> Hi to the list
>
> >From following the list discussions I get that there are R packages for
> pulling Bloomberg and LIM(?) data into R. Does anybody know if there is
> such a package for Xignite.com ? (I looked at xignite because they provide
> the financial data that is used in wolframalpha.com. I like their "you
> only pay what you use" pricing model)
>
> http://www.xignite.com/Support/GettingStarted.aspx
>
> If not, does anyone think that creating one would be a straightforward
> thing, i.e. could such a package be derived from one of the existing
> packages fairly quickly?
>   
Soren,

There's nothing available that I'm aware of.

The Xignite.com API is a SOAP/WSDL web service.

To integrate to R, you could try two main approaches that I would try n 
the following order:

- There are a couple of R/SOAP integration projects out there. You could 
test and potentially use one of these as a 'Requires' for your Xignite 
integration.

- use some other SOAP client libraries in another language, and link 
that into your package.

I know that the biocep folks have done some work in SOAP/WSDL to 
integrate to Eucalyptus and Amazon's web services, so further discussion 
on the issues you have trying to develop some integration might be 
better served on a more general R list, as web services development is 
not finance specific (though I realize that the data is).

Regards,

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From tobias.verbeke at gmail.com  Sun Dec 20 17:44:39 2009
From: tobias.verbeke at gmail.com (Tobias Verbeke)
Date: Sun, 20 Dec 2009 17:44:39 +0100
Subject: [R-SIG-Finance] FinData provider Xiginte and R
In-Reply-To: <4B2E0C03.1030702@braverock.com>
References: <35562.91.4.69.224.1261306218.squirrel@censix.com>
	<4B2E0C03.1030702@braverock.com>
Message-ID: <4B2E5477.3060709@gmail.com>

Hi,

Brian G. Peterson wrote:
> me at censix.com wrote:

>> >From following the list discussions I get that there are R packages for
>> pulling Bloomberg and LIM(?) data into R. Does anybody know if there is
>> such a package for Xignite.com ? (I looked at xignite because they 
>> provide
>> the financial data that is used in wolframalpha.com. I like their "you
>> only pay what you use" pricing model)
>>
>> http://www.xignite.com/Support/GettingStarted.aspx
>>
>> If not, does anyone think that creating one would be a straightforward
>> thing, i.e. could such a package be derived from one of the existing
>> packages fairly quickly?
>>   
> Soren,
> 
> There's nothing available that I'm aware of.
> 
> The Xignite.com API is a SOAP/WSDL web service.
> 
> To integrate to R, you could try two main approaches that I would try n 
> the following order:
> 
> - There are a couple of R/SOAP integration projects out there. You could 
> test and potentially use one of these as a 'Requires' for your Xignite 
> integration.

http://www.omegahat.org/SSOAP/

for example.

> - use some other SOAP client libraries in another language, and link 
> that into your package.
> 
> I know that the biocep folks have done some work in SOAP/WSDL to 
> integrate to Eucalyptus and Amazon's web services, so further discussion 

IIRC Amazon's web services are RESTful (not SOAP based);
for this the R packages RCurl (in combination with XML
or rjson/RJSONIO)) can be used.

Best,
Tobias

> on the issues you have trying to develop some integration might be 
> better served on a more general R list, as web services development is 
> not finance specific (though I realize that the data is).
> 
> Regards,
> 
>  - Brian
>


From artk at congruent.com  Sun Dec 20 20:47:25 2009
From: artk at congruent.com (Arthur Kreitman)
Date: Sun, 20 Dec 2009 11:47:25 -0800
Subject: [R-SIG-Finance] Cannot connect with tws
In-Reply-To: <c68c5d80912200332w44d361b1u38812ee7d0ad6e50@mail.gmail.com>
References: <c68c5d80912200332w44d361b1u38812ee7d0ad6e50@mail.gmail.com>
Message-ID: <8DB8983924798A41B27C1E76AA913FE8133439F760@EXVMBX020-11.exch020.serverdata.net>

That's a very old version on TWS.  My build is 900.6 dates Dec 11.  You might want to try to update first.  Also, there's a way to get around that connection popup.  Under Configure->Api->All Api Functions add localhost to the trusted IP Address list

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Peter Rote
Sent: Sunday, December 20, 2009 6:32 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] Cannot connect with tws

Dear All,

I'm trying to Connect to tws demo/paper/real account with no success.

> tws <- twsConnect()

i can see the label from tws asking for confirmation, but after I
click on Yes I'm  getting the following error message:

Error in structure(list(s, clientId = clientId, port = port,
server.version = SERVER_VERSION,  :
  object 'SERVER_VERSION' not found

My R version is 2.10.0 (2009-10-26) and TWS Build 893.9b April 23,2009.

Does anyone have any ideas about that, please?

Thanks for any help,
Sincerely,
Peter

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From tallent_e at lycos.com  Mon Dec 21 00:23:09 2009
From: tallent_e at lycos.com (Edouard Tallent)
Date: Sun, 20 Dec 2009 18:23:09 -0500 (EST)
Subject: [R-SIG-Finance] how to deal with time series in R ??
Message-ID: <20091220182309.HM.0000000000009rC@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091220/9be6fcfd/attachment.html>

From tallent_e at lycos.com  Mon Dec 21 00:24:14 2009
From: tallent_e at lycos.com (Edouard Tallent)
Date: Sun, 20 Dec 2009 18:24:14 -0500 (EST)
Subject: [R-SIG-Finance] how to deal with time series in R ??
Message-ID: <20091220182414.HM.0000000000009rD@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091220/73aae1a9/attachment.pl>

From jeff.a.ryan at gmail.com  Mon Dec 21 01:59:45 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sun, 20 Dec 2009 18:59:45 -0600
Subject: [R-SIG-Finance] how to deal with time series in R ??
In-Reply-To: <20091220182309.HM.0000000000009rC@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
References: <20091220182309.HM.0000000000009rC@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
Message-ID: <e8e755250912201659i657b86e1nd7ea86cde54a4451@mail.gmail.com>

Hi Edouard,

This has been addressed in various forms many dozens (hundreds?) of
times on the list.

Take a look at the zoo, xts, timeSeries, timeDate or fts for packages
that do this well.

Functions of interest:

?read.zoo
?zoo
?xts

?strptime
?format

HTH,
Jeff

On Sun, Dec 20, 2009 at 5:23 PM, Edouard Tallent <tallent_e at lycos.com> wrote:
> hi everyone !
>
> i have a 4-row table, the first column being dates starting from the 5 of
> dec 2002 (the format actually is dd/mm/yyyy), the remainings being 3
> variables consisting of numeric variables. the first line contains the
> headers of the rows. some lines are missing as data may have been recorded
> not so regularly.
>
> Date, x, y, z
> 05/12/2002, 12, 11, 10
> 06/12/2002, 3, 5, 6
> 10/12/2002, 4, 12, 8
> 11/12/2002, 6, 7, 7
> ...
> ...
>
> what do i have to do so that R understands that this is a time series, the
> first row being the row for dates ??
>
> along the R documention i have read on read.table, ts, time and various
> other functions, but i have been unsuccessful til then.
>
> thank you for your hints
>
> cheers,
> ?douard.
>
>
>
>
>
>
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From ggrothendieck at gmail.com  Mon Dec 21 03:41:49 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 20 Dec 2009 21:41:49 -0500
Subject: [R-SIG-Finance] how to deal with time series in R ??
In-Reply-To: <20091220182309.HM.0000000000009rC@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
References: <20091220182309.HM.0000000000009rC@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
Message-ID: <971536df0912201841k33529569y1c1d61a21cac5c23@mail.gmail.com>

Try this and read the three vignettes (i.e. pdf documents) that come with zoo:

Lines <- "Date, x, y, z
05/12/2002, 12, 11, 10
06/12/2002, 3, 5, 6
10/12/2002, 4, 12, 8
11/12/2002, 6, 7, 7"

library(chron)
library(zoo)
z <- read.zoo(textConnection(Lines), header = TRUE, FUN = chron, sep = ",")
head(z)
plot(z)

There are also several other time series packages mentioned by others
in this thread.

On Sun, Dec 20, 2009 at 6:23 PM, Edouard Tallent <tallent_e at lycos.com> wrote:
> hi everyone !
>
> i have a 4-row table, the first column being dates starting from the 5 of
> dec 2002 (the format actually is dd/mm/yyyy), the remainings being 3
> variables consisting of numeric variables. the first line contains the
> headers of the rows. some lines are missing as data may have been recorded
> not so regularly.
>
> Date, x, y, z
> 05/12/2002, 12, 11, 10
> 06/12/2002, 3, 5, 6
> 10/12/2002, 4, 12, 8
> 11/12/2002, 6, 7, 7
> ...
> ...
>
> what do i have to do so that R understands that this is a time series, the
> first row being the row for dates ??
>
> along the R documention i have read on read.table, ts, time and various
> other functions, but i have been unsuccessful til then.
>
> thank you for your hints
>
> cheers,
> ?douard.
>
>
>
>
>
>
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From me at censix.com  Mon Dec 21 11:03:18 2009
From: me at censix.com (me at censix.com)
Date: Mon, 21 Dec 2009 11:03:18 +0100 (CET)
Subject: [R-SIG-Finance] FinData provider Xiginte and R
In-Reply-To: <4B2E5477.3060709@gmail.com>
References: <35562.91.4.69.224.1261306218.squirrel@censix.com>
	<4B2E0C03.1030702@braverock.com> <4B2E5477.3060709@gmail.com>
Message-ID: <43997.91.4.76.237.1261389798.squirrel@censix.com>

Thanks for the guidance and suggestions. unfortunately I am a bit short of
time, so won't make an attempt to build a package for this, but may work
on an ad-hoc solution instead.

Cheers

Soren

> Hi,
>
> Brian G. Peterson wrote:
>> me at censix.com wrote:
>
>>> >From following the list discussions I get that there are R packages
>>> for
>>> pulling Bloomberg and LIM(?) data into R. Does anybody know if there is
>>> such a package for Xignite.com ? (I looked at xignite because they
>>> provide
>>> the financial data that is used in wolframalpha.com. I like their "you
>>> only pay what you use" pricing model)
>>>
>>> http://www.xignite.com/Support/GettingStarted.aspx
>>>
>>> If not, does anyone think that creating one would be a straightforward
>>> thing, i.e. could such a package be derived from one of the existing
>>> packages fairly quickly?
>>>
>> Soren,
>>
>> There's nothing available that I'm aware of.
>>
>> The Xignite.com API is a SOAP/WSDL web service.
>>
>> To integrate to R, you could try two main approaches that I would try n
>> the following order:
>>
>> - There are a couple of R/SOAP integration projects out there. You could
>> test and potentially use one of these as a 'Requires' for your Xignite
>> integration.
>
> http://www.omegahat.org/SSOAP/
>
> for example.
>
>> - use some other SOAP client libraries in another language, and link
>> that into your package.
>>
>> I know that the biocep folks have done some work in SOAP/WSDL to
>> integrate to Eucalyptus and Amazon's web services, so further discussion
>
> IIRC Amazon's web services are RESTful (not SOAP based);
> for this the R packages RCurl (in combination with XML
> or rjson/RJSONIO)) can be used.
>
> Best,
> Tobias
>
>> on the issues you have trying to develop some integration might be
>> better served on a more general R list, as web services development is
>> not finance specific (though I realize that the data is).
>>
>> Regards,
>>
>>  - Brian
>>
>


From r.rote12 at googlemail.com  Tue Dec 22 16:38:49 2009
From: r.rote12 at googlemail.com (Peter Rote)
Date: Tue, 22 Dec 2009 16:38:49 +0100
Subject: [R-SIG-Finance] IBrokers
Message-ID: <c68c5d80912220738t3260a984u7e0daa1797b9254e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091222/3f7224bf/attachment.pl>

From n_torenvliet at hotmail.com  Tue Dec 22 23:22:16 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Tue, 22 Dec 2009 17:22:16 -0500
Subject: [R-SIG-Finance] Data service
In-Reply-To: <c68c5d80912220738t3260a984u7e0daa1797b9254e@mail.gmail.com>
References: <c68c5d80912220738t3260a984u7e0daa1797b9254e@mail.gmail.com>
Message-ID: <BAY143-W947D3FD4F00B81A1F3681FE810@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091222/77a7978b/attachment.pl>

From pierrelap at gmail.com  Wed Dec 23 01:09:04 2009
From: pierrelap at gmail.com (Pierre Lapointe)
Date: Tue, 22 Dec 2009 19:09:04 -0500
Subject: [R-SIG-Finance] Problem with plot.xts
Message-ID: <676b0d530912221609kd03bd97v20458af2d01ea25f@mail.gmail.com>

Hello,

I want to draw a plot.xts without any axis or labels (I need to
overlay 2 plots with par (new=TRUE). )

Unfortunately, the axes = FALSE argument is overridden in the function.

Here's my code. I only want the data line. No axes or labels.

library(xts)
data(sample_matrix)
sample.xts <- as.xts(sample_matrix)
plot(sample.xts[,1],type="l",axes=FALSE,xlab="",ylab="",auto.grid=FALSE)

I'm on Vista. R 2.10.0

BTW, what is the "ann" argument in the function supposed to do?

Thanks.


From n_torenvliet at hotmail.com  Wed Dec 23 02:33:09 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Tue, 22 Dec 2009 20:33:09 -0500
Subject: [R-SIG-Finance] Data service
In-Reply-To: <BAY143-W947D3FD4F00B81A1F3681FE810@phx.gbl>
References: <c68c5d80912220738t3260a984u7e0daa1797b9254e@mail.gmail.com>,
	<BAY143-W947D3FD4F00B81A1F3681FE810@phx.gbl>
Message-ID: <BAY143-W1844439D36297FA8208C77FE800@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091222/220ad984/attachment.pl>

From rhelpacc at gmail.com  Wed Dec 23 02:45:03 2009
From: rhelpacc at gmail.com (R_help Help)
Date: Tue, 22 Dec 2009 20:45:03 -0500
Subject: [R-SIG-Finance] Fitting ACD model
Message-ID: <ad1ead5f0912221745xd71808n59a3b2f9c05edaee@mail.gmail.com>

Hi - I'm wondering if there is any existing package in R that
facilitates ACD (Autoregressive Conditional Duration) model. I
googled. Apparently there were packages dynamo and fACD. However, they
do not seem to be on any CRAN. I am wondering if anyone could point me
to an existing package (if any). Thank you.

-r


From jeff.a.ryan at gmail.com  Wed Dec 23 04:05:42 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 22 Dec 2009 21:05:42 -0600
Subject: [R-SIG-Finance] Data service
In-Reply-To: <BAY143-W947D3FD4F00B81A1F3681FE810@phx.gbl>
References: <c68c5d80912220738t3260a984u7e0daa1797b9254e@mail.gmail.com>
	<BAY143-W947D3FD4F00B81A1F3681FE810@phx.gbl>
Message-ID: <e8e755250912221905o1de23ebfp3c7f0321d8782dc@mail.gmail.com>

I'll bite.

Take a look at DTN's IQFeed and DTN.IQ.  Both can function under Wine
on linux and have a good reputation. Plus, they have a trial period
and are quite reasonable.

HTH
Jeff

On Tue, Dec 22, 2009 at 4:22 PM, Nick Torenvliet
<n_torenvliet at hotmail.com> wrote:
>
> A couple of the other posts lately got me looking around the net for data services. ?I'm looking for historical markets, futures and econometrics from a linux friendly vendor and cheap. ?Any suggestions?
>
> Nick
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From jeff.a.ryan at gmail.com  Wed Dec 23 04:11:56 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 22 Dec 2009 21:11:56 -0600
Subject: [R-SIG-Finance] Problem with plot.xts
In-Reply-To: <676b0d530912221609kd03bd97v20458af2d01ea25f@mail.gmail.com>
References: <676b0d530912221609kd03bd97v20458af2d01ea25f@mail.gmail.com>
Message-ID: <e8e755250912221911v6312b62ck110c7aea32ba2728@mail.gmail.com>

Pierre,

xts wasn't meant to include much in the way of graphics. quantmod was
designed for that.

For more complete standard graphical capabilities simply convert to zoo.

plot(as.zoo(x))

If there is a need at some point that can't be sufficiently addressed
with zoo or quantmod, it may be a good case for extending xts in that
direction, but for now the above alternatives are better.

Best,
Jeff

On Tue, Dec 22, 2009 at 6:09 PM, Pierre Lapointe <pierrelap at gmail.com> wrote:
> Hello,
>
> I want to draw a plot.xts without any axis or labels (I need to
> overlay 2 plots with par (new=TRUE). )
>
> Unfortunately, the axes = FALSE argument is overridden in the function.
>
> Here's my code. I only want the data line. No axes or labels.
>
> library(xts)
> data(sample_matrix)
> sample.xts <- as.xts(sample_matrix)
> plot(sample.xts[,1],type="l",axes=FALSE,xlab="",ylab="",auto.grid=FALSE)
>
> I'm on Vista. R 2.10.0
>
> BTW, what is the "ann" argument in the function supposed to do?
>
> Thanks.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From qqjwl at 163.com  Wed Dec 23 07:24:32 2009
From: qqjwl at 163.com (qqjwl)
Date: Wed, 23 Dec 2009 14:24:32 +0800 (CST)
Subject: [R-SIG-Finance] How to estimate SV type models in R more
	efficiently?
Message-ID: <9941133.195251261549472208.JavaMail.coremail@bj163app119.163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091223/6f6504d9/attachment.pl>

From brian at braverock.com  Wed Dec 23 11:25:45 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 23 Dec 2009 04:25:45 -0600
Subject: [R-SIG-Finance] How to estimate SV type models in R
	more	efficiently?
In-Reply-To: <9941133.195251261549472208.JavaMail.coremail@bj163app119.163.com>
References: <9941133.195251261549472208.JavaMail.coremail@bj163app119.163.com>
Message-ID: <4B31F029.8010609@braverock.com>

qqjwl wrote:
> Hello everyone,
>     It seems that the estimation of the stochastic volatility model is inefficient in R. 
 > Is there a function in R to estimate these kind of model such as the paper
 > of Kim and Shephard(1998) "Stochastic volatility: likelihood inference and 
comparison with ARCH models" ?
 > Thank you for your attention.

Liya,

What, specifically, have you tried that seems to you to be inefficient?

Please provide references to code and packages that you have tried.  That makes 
it much easier for someone else to help you out.

I do not immediately recall the paper you reference, but I have estimated many 
different kinds of volatility models in R, and have usually been able to 
accomplish what I needed to.  There are a multitude of [G/AP]ARCH models 
available in R, which ones have you tried? What specific problems did you 
encounter?

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From brian at braverock.com  Wed Dec 23 14:32:24 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 23 Dec 2009 07:32:24 -0600
Subject: [R-SIG-Finance] Fitting ACD model
In-Reply-To: <ad1ead5f0912221745xd71808n59a3b2f9c05edaee@mail.gmail.com>
References: <ad1ead5f0912221745xd71808n59a3b2f9c05edaee@mail.gmail.com>
Message-ID: <4B321BE8.4070405@braverock.com>

R_help Help wrote:
> Hi - I'm wondering if there is any existing package in R that
> facilitates ACD (Autoregressive Conditional Duration) model. I
> googled. Apparently there were packages dynamo and fACD. However, they
> do not seem to be on any CRAN. I am wondering if anyone could point me
> to an existing package (if any). Thank you.
>   
You were close.  Try a little harder and perhaps use your real name next 
time...

dynamo looks to me like it's on CRAN:

http://cran.r-project.org/web/packages/dynamo/index.html

and fACD is on R-Forge

http://r-forge.r-project.org/R/?group_id=156

instructions for installnig R-Forge packages are on the page above.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From ggrothendieck at gmail.com  Wed Dec 23 15:39:16 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 23 Dec 2009 09:39:16 -0500
Subject: [R-SIG-Finance] Problem with plot.xts
In-Reply-To: <e8e755250912221911v6312b62ck110c7aea32ba2728@mail.gmail.com>
References: <676b0d530912221609kd03bd97v20458af2d01ea25f@mail.gmail.com> 
	<e8e755250912221911v6312b62ck110c7aea32ba2728@mail.gmail.com>
Message-ID: <971536df0912230639n7c6e49a7oc7059d166008fa51@mail.gmail.com>

Note that if you wish to use as.zoo then this will get rid of the axis markings:


library(xts)
data(sample_matrix)
sample.xts <- as.xts(sample_matrix)
plot(as.zoo(sample.xts[,1]), xaxt = "n", yaxt = "n", xlab = "", ylab = "")

Also note that zoo has both plot.zoo and xyplot.zoo where the latter
implements time series plotting in lattice.  The help files and the
three vignettes.

On Tue, Dec 22, 2009 at 10:11 PM, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:
> Pierre,
>
> xts wasn't meant to include much in the way of graphics. quantmod was
> designed for that.
>
> For more complete standard graphical capabilities simply convert to zoo.
>
> plot(as.zoo(x))
>
> If there is a need at some point that can't be sufficiently addressed
> with zoo or quantmod, it may be a good case for extending xts in that
> direction, but for now the above alternatives are better.
>
> Best,
> Jeff
>
> On Tue, Dec 22, 2009 at 6:09 PM, Pierre Lapointe <pierrelap at gmail.com> wrote:
>> Hello,
>>
>> I want to draw a plot.xts without any axis or labels (I need to
>> overlay 2 plots with par (new=TRUE). )
>>
>> Unfortunately, the axes = FALSE argument is overridden in the function.
>>
>> Here's my code. I only want the data line. No axes or labels.
>>
>> library(xts)
>> data(sample_matrix)
>> sample.xts <- as.xts(sample_matrix)
>> plot(sample.xts[,1],type="l",axes=FALSE,xlab="",ylab="",auto.grid=FALSE)
>>
>> I'm on Vista. R 2.10.0
>>
>> BTW, what is the "ann" argument in the function supposed to do?
>>
>> Thanks.
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>
>
>
> --
> Jeffrey Ryan
> jeffrey.ryan at insightalgo.com
>
> ia: insight algorithmics
> www.insightalgo.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From Reena.Bansal at moorecap.com  Wed Dec 23 16:33:52 2009
From: Reena.Bansal at moorecap.com (Reena Bansal)
Date: Wed, 23 Dec 2009 10:33:52 -0500
Subject: [R-SIG-Finance] Non parametric, unequal variance,
	equality of mean significance test
Message-ID: <4AAD56F399C8564C9EB6817C17618CDD04E67210@NYC-XCH3.win.moorecap.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091223/b713df00/attachment.pl>

From brian at braverock.com  Wed Dec 23 17:25:07 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 23 Dec 2009 10:25:07 -0600
Subject: [R-SIG-Finance] Non parametric, unequal variance,
 equality of mean significance test
In-Reply-To: <4AAD56F399C8564C9EB6817C17618CDD04E67210@NYC-XCH3.win.moorecap.com>
References: <4AAD56F399C8564C9EB6817C17618CDD04E67210@NYC-XCH3.win.moorecap.com>
Message-ID: <4B324463.6040607@braverock.com>

Reena Bansal wrote:
> Hello everyone,
>
> I have two samples of data of different sizes. Sample 1 is 30 points and
> sample 2 is 20 points. I have no reason to believe that the two sample
> are normally distributed or have the same variance. I am looking for
> significance test for the null that the two samples have same mean (or
> the two samples come from same population). 
>
> I found the unpaired Student's t test for unequal variance. However this
> test assumes normality.
> The non parametric test I found is the Mann Whitney U test. But this
> test requires equal variance.
>   
I seriously doubt your series are long enough for any standard 
statistical test to have high enough confidence.  Your error bands will 
be quite wide.

I would probably check the fit to non-normal and fat-tailed 
distributions such as the Cornish Fisher, the skewed Student-t and the 
general Pareto.  If your data seems to fit those well, you may be able 
to compare the fitted distributions.

There are a number of distribution fitting functions in 
PerformanceAnalytics, and most have been wrapped into chart.Histogram 
and chart.QQPlot.  Of course, R has a wealth of this kind of 
functionality, and I'm only referring to the code I am most familiar with.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From Zeno.Adams at ebs.edu  Wed Dec 23 17:36:18 2009
From: Zeno.Adams at ebs.edu (Adams, Zeno)
Date: Wed, 23 Dec 2009 17:36:18 +0100
Subject: [R-SIG-Finance] Non parametric, unequal variance,
	equality of mean significance test
References: <4AAD56F399C8564C9EB6817C17618CDD04E67210@NYC-XCH3.win.moorecap.com>
Message-ID: <9064522880125945B98983BBAECBA1CC0101BAEB@exchsrv001.ebs.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091223/63d41062/attachment.pl>

From Reena.Bansal at moorecap.com  Wed Dec 23 17:48:29 2009
From: Reena.Bansal at moorecap.com (Reena Bansal)
Date: Wed, 23 Dec 2009 11:48:29 -0500
Subject: [R-SIG-Finance] Non parametric, unequal variance,
	equality of mean significance test
In-Reply-To: <9064522880125945B98983BBAECBA1CC0101BAEB@exchsrv001.ebs.local>
Message-ID: <4AAD56F399C8564C9EB6817C17618CDD04E67212@NYC-XCH3.win.moorecap.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091223/74d9b8b1/attachment.pl>

From n_torenvliet at hotmail.com  Wed Dec 23 19:48:13 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Wed, 23 Dec 2009 13:48:13 -0500
Subject: [R-SIG-Finance] Data service
In-Reply-To: <e8e755250912221905o1de23ebfp3c7f0321d8782dc@mail.gmail.com>
References: <c68c5d80912220738t3260a984u7e0daa1797b9254e@mail.gmail.com>,
	<BAY143-W947D3FD4F00B81A1F3681FE810@phx.gbl>,
	<e8e755250912221905o1de23ebfp3c7f0321d8782dc@mail.gmail.com>
Message-ID: <BAY143-W16A6AC024F0A4D5DE56EEAFE800@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091223/80b5690e/attachment.pl>

From jeff.a.ryan at gmail.com  Wed Dec 23 22:15:50 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Wed, 23 Dec 2009 15:15:50 -0600
Subject: [R-SIG-Finance] Data service
In-Reply-To: <BAY143-W16A6AC024F0A4D5DE56EEAFE800@phx.gbl>
References: <c68c5d80912220738t3260a984u7e0daa1797b9254e@mail.gmail.com>
	<BAY143-W947D3FD4F00B81A1F3681FE810@phx.gbl>
	<e8e755250912221905o1de23ebfp3c7f0321d8782dc@mail.gmail.com>
	<BAY143-W16A6AC024F0A4D5DE56EEAFE800@phx.gbl>
Message-ID: <e8e755250912231315o330fbbddu69cd5aa6c93ef0f4@mail.gmail.com>

One caveat.

I recall in their terms of service that automated retrieval is a no go.

http://www.eoddata.com/About/Terms.aspx

6. AUTOMATED DOWNLOADS
5.1 Our data is intended for download via our webpage. Automated
downloads through scripts or utilities is not permitted. Any attempt
to access our data in an automated manner using download utilities
will be blocked.

Though they are looking for API contributors.

This may be important to you as well (it is for me):

3. USE OF INFORMATION
NOT FOR COMMERCIAL USE. The User is permitted to store, manipulate,
analyse, reformat, print and display the EODData Information and use
the Services only for the User's personal use. In no event shall the
User publish, sell, lease, disseminate, retransmit, redistribute,
broadcast, circulate or otherwise reproduce, provide or permit access
to any EODData Information or the Services in any format to anyone.
Except as permitted by this clause, no User shall use any EODData
Information or any of the Services in or in connection with any
business or for providing a service to any person including without
limitation any securities, investment, accounting, banking, legal or
media business or enterprise or service.

Best,
Jeff



Jeffrey A. Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com

On Dec 23, 2009, at 12:48 PM, Nick Torenvliet
<n_torenvliet at hotmail.com> wrote:

>
> Hey Jeff and others who've responded privately... thanks for the
> info...
>
> I think I've narrowed it down to www.eoddata.com ... cheap, pretty
> good symbol coverage, automatable ftp, all the adjustment data and
> symbol lists etc.... the suggestion for eoddata came from this
> pretty helpful little site... http://blog.fosstrading.com/ thanks to
> the blogger.
>
> I'm just about to get a platinum membership (go big or go home!!).
> I'd be into hearing if anyone has good/bad experience with them and
> if any code is available to interface with R.
>
> Happy Holidays to All!
>
> And please forgive this technically non-R-technical conversation.
>
> Nick
>
>> Date: Tue, 22 Dec 2009 21:05:42 -0600
>> Subject: Re: [R-SIG-Finance] Data service
>> From: jeff.a.ryan at gmail.com
>> To: n_torenvliet at hotmail.com
>> CC: r-sig-finance at stat.math.ethz.ch
>>
>> I'll bite.
>>
>> Take a look at DTN's IQFeed and DTN.IQ.  Both can function under Wine
>> on linux and have a good reputation. Plus, they have a trial period
>> and are quite reasonable.
>>
>> HTH
>> Jeff
>>
>> On Tue, Dec 22, 2009 at 4:22 PM, Nick Torenvliet
>> <n_torenvliet at hotmail.com> wrote:
>>>
>>> A couple of the other posts lately got me looking around the net
>>> for data services.  I'm looking for historical markets, futures
>>> and econometrics from a linux friendly vendor and cheap.  Any
>>> suggestions?
>>>
>>> Nick
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
>>
>>
>>
>> --
>> Jeffrey Ryan
>> jeffrey.ryan at insightalgo.com
>>
>> ia: insight algorithmics
>> www.insightalgo.com
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From renault.gautier at gmail.com  Wed Dec 23 23:26:13 2009
From: renault.gautier at gmail.com (Gautier RENAULT)
Date: Wed, 23 Dec 2009 23:26:13 +0100
Subject: [R-SIG-Finance] error correction model - general specification
Message-ID: <5bfb4a970912231426q553caa2drc6367c7e0b0dc451@mail.gmail.com>

Hi R-users,

I try to deal with cointegration in R and estimate an Error Correction Model
(ECM) in a bivariate case in which I consider two variables:

?         Pt: index house prices in France from 1996:Q1 to 2009:Q3 (log
dependent variable)

?         Xt: amount that households can borrow (log explanatory variable).
Xt captures the role of credit, income and interest rate as drivers of the
french housing demand.

Data are in ?fr-demand-house.csv?.

The final aim is to estimate the long run relationship between houses prices
(Pt) and the credit (Xt) in France :

Pt = ? + ? Xt

I wish to estimate a general specification of the ECM as follows :

?Pt=?(Pt-1-? - ? Xt-1)+?(?Xt-i)+?(?Pt-i)



First, following the methodology presented in the book of B. Pfaff I bought,
I already concluded that Pt and Xt are cointegrated  I(1) with ur.df (ADF
test ) and ca.po (Phillips-Ouliaris Method) functions.

Second, how can I do :

1.       to choose optimal number of lag in this general specification for
the two cointegrated variables Pt (?Pt-i) and Xt (?Xt-i)?

2.       to add a dummy variable for the first quarter of 2009 (dumQ1-2009)
to test the collapse of houses prices in France at the beginning of 2009 ?

Can anyone help?

thanking you in advance,



Gautier RENAULT
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091223/ed8fba81/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fr-house-demand.csv
Type: application/octet-stream
Size: 1819 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091223/ed8fba81/attachment.obj>

From markleeds at verizon.net  Wed Dec 23 23:35:11 2009
From: markleeds at verizon.net (markleeds at verizon.net)
Date: Wed, 23 Dec 2009 16:35:11 -0600 (CST)
Subject: [R-SIG-Finance] error correction model - general specification
Message-ID: <1274146568.70542.1261607711303.JavaMail.root@vms182.mailsrvcs.net>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091223/a26a5ed3/attachment.html>

From m_olshansky at yahoo.com  Thu Dec 24 01:02:36 2009
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Wed, 23 Dec 2009 16:02:36 -0800 (PST)
Subject: [R-SIG-Finance] Non parametric, unequal variance,
	equality of mean significance test
In-Reply-To: <4AAD56F399C8564C9EB6817C17618CDD04E67212@NYC-XCH3.win.moorecap.com>
Message-ID: <493986.12997.qm@web32204.mail.mud.yahoo.com>

Hi Reena,

There is Cramer's theorem stating that the sum of two independent variables has normal distribution if and only if each of them is normally distributed. So to strictly satisfy conditions for t-test you data must be normally distributed.
However, because of the Central Limit Theorem, if the sample is large enough (and has finite second moment/variance) you can use t-test (with unequal variances). I believe that 30 and 20 may be large enough.
As to Mann Whitney test, it checks for equal distributions - equal means are not enough.

Best regards,
Moshe.

--- On Thu, 24/12/09, Reena Bansal <Reena.Bansal at moorecap.com> wrote:

> From: Reena Bansal <Reena.Bansal at moorecap.com>
> Subject: Re: [R-SIG-Finance] Non parametric, unequal variance, equality of mean significance test
> To: "Adams, Zeno" <Zeno.Adams at ebs.edu>, r-sig-finance at stat.math.ethz.ch
> Received: Thursday, 24 December, 2009, 3:48 AM
> Hi Zeno,
>  
> No I am not aware of this assumption. So far the literature
> I have seen
> mentions that the data itself has to be normally populated.
> Do you have
> any references on this assumption?
>  
> Thanks.
> 
> ________________________________
> 
> From: Adams, Zeno [mailto:Zeno.Adams at ebs.edu]
> 
> Sent: Wednesday, December 23, 2009 11:36 AM
> To: Reena Bansal; r-sig-finance at stat.math.ethz.ch
> Subject: RE: [R-SIG-Finance] Non parametric, unequal
> variance,equality
> of mean significance test
> 
> 
> 
> I assume you are aware of the fact that the Student's t
> test assumes the
> means of the data to be normally distributed but does not
> require any
> normality assumptions concerning the data itself? If your
> data fulfills
> the requirements for the central limit theorem to hold
> (i.e. your
> observations are independently distributed) then I don't
> see any reason
> why you cannot use the simple t-test.
> 
> Zeno
> 
> 
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> on behalf of Reena Bansal
> Sent: Wed 12/23/2009 4:33 PM
> To: r-sig-finance at stat.math.ethz.ch
> Subject: [R-SIG-Finance] Non parametric, unequal
> variance,equality of
> mean significance test
> 
> Hello everyone,
> 
> I have two samples of data of different sizes. Sample 1 is
> 30 points and
> sample 2 is 20 points. I have no reason to believe that the
> two sample
> are normally distributed or have the same variance. I am
> looking for
> significance test for the null that the two samples have
> same mean (or
> the two samples come from same population).
> 
> I found the unpaired Student's t test for unequal variance.
> However this
> test assumes normality.
> The non parametric test I found is the Mann Whitney U test.
> But this
> test requires equal variance.
> 
> Any suggestions.
> 
> Thanks,
> Reena
> 
> ? ? ? ? [[alternative HTML version
> deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
> 
> 
> 
> 
> 
> ________________________________
> 
> EBS European Business School gemeinnuetzige GmbH - Sitz
> der
> Gesellschaft: Wiesbaden, Amtsgericht Wiesbaden HRB 19951 -
> Umsatzsteuer-ID DE 113891213 Geschaeftsfuehrer: Prof. Dr.
> Christopher
> Jahns, Praesident; Prof. Dr. Rolf Tilmes, Dekan; Sabine
> Fuchs, CMO;
> Aufsichtsrat: Dr. Hellmut K. Albrecht, Vorsitzender 
> 
> ________________________________
> 
> 
> 
> ??? [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From stephenjbarr at gmail.com  Thu Dec 24 01:50:57 2009
From: stephenjbarr at gmail.com (Stephen J. Barr)
Date: Wed, 23 Dec 2009 19:50:57 -0500
Subject: [R-SIG-Finance] general zoo tutorial available?
Message-ID: <9b4cc5750912231650i2396c7a1m4390018c52ed62fc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091223/7bce17d8/attachment.pl>

From ggrothendieck at gmail.com  Thu Dec 24 02:00:00 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 23 Dec 2009 20:00:00 -0500
Subject: [R-SIG-Finance] general zoo tutorial available?
In-Reply-To: <9b4cc5750912231650i2396c7a1m4390018c52ed62fc@mail.gmail.com>
References: <9b4cc5750912231650i2396c7a1m4390018c52ed62fc@mail.gmail.com>
Message-ID: <971536df0912231700l32558014icc9374e5e083b728@mail.gmail.com>

On Wed, Dec 23, 2009 at 7:50 PM, Stephen J. Barr <stephenjbarr at gmail.com> wrote:
> Hello,
>
> I am working on a dataset of some intraday data. I haven't used R for this
> too much, so I have a few general questions.
>
> 1) What is the best way to structure the data? The CSV is from WRDS, ordered
> by symbol and then by datetime. Should I dump this into 1 zoo object, or
> have one zoo object per symbol?

read.zoo can read such files creating a multivariate time series.
Note the aggregate argument.

>
> 2) The questions I would initially like to look at are:
> for a given [minute, 2 minute interval, hour, etc], what was the total
> volume, average volume, average price, etc. What is a good reference for
> learning how to do these kinds of things?

See the aggregation examples in the zoo-quickref vignette (and the
other two vignettes).

The xts package may also be of interest.

>
> 3) What is the best way to plot these time series?
>

See ?plot.zoo and and ?xyplot.zoo

The quantmod package may also be of interest.

> Thanks,
> -stephen
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From qqjwl at 163.com  Thu Dec 24 02:06:15 2009
From: qqjwl at 163.com (qqjwl)
Date: Thu, 24 Dec 2009 09:06:15 +0800 (CST)
Subject: [R-SIG-Finance] How to estimate SV type models in R
	more	efficiently?
In-Reply-To: <4B31F029.8010609@braverock.com>
References: <4B31F029.8010609@braverock.com>
	<9941133.195251261549472208.JavaMail.coremail@bj163app119.163.com>
Message-ID: <9859215.718251261616775168.JavaMail.coremail@app194.163.com>


 
I have attached the code what have made to deal with two factor SV model.
It takes me about 87 minites to finish 2000 interations with 1000 data which is too slow compare with other people who have done this kind of model with other language. I don't know why and very confused about it. Looking forward to get your help. Thank you very much! 
 
Yours,
Liya



?2009-12-23?"Brian G. Peterson" <brian at braverock.com> ???
>qqjwl wrote:
>> Hello everyone,
>>     It seems that the estimation of the stochastic volatility model is inefficient in R. 
> > Is there a function in R to estimate these kind of model such as the paper
> > of Kim and Shephard(1998) "Stochastic volatility: likelihood inference and 
>comparison with ARCH models" ?
> > Thank you for your attention.
>
>Liya,
>
>What, specifically, have you tried that seems to you to be inefficient?
>
>Please provide references to code and packages that you have tried.  That makes 
>it much easier for someone else to help you out.
>
>I do not immediately recall the paper you reference, but I have estimated many 
>different kinds of volatility models in R, and have usually been able to 
>accomplish what I needed to.  There are a multitude of [G/AP]ARCH models 
>available in R, which ones have you tried? What specific problems did you 
>encounter?
>
>Regards,
>
>     - Brian
>
>-- 
>Brian G. Peterson
>http://braverock.com/brian/
>Ph: 773-459-4973
>IM: bgpbraverock
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091224/5894b476/attachment.html>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Two scale SV model.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091224/5894b476/attachment.txt>

From ezivot at u.washington.edu  Thu Dec 24 02:06:26 2009
From: ezivot at u.washington.edu (Eric Zivot)
Date: Wed, 23 Dec 2009 17:06:26 -0800
Subject: [R-SIG-Finance] general zoo tutorial available?
In-Reply-To: <9b4cc5750912231650i2396c7a1m4390018c52ed62fc@mail.gmail.com>
References: <9b4cc5750912231650i2396c7a1m4390018c52ed62fc@mail.gmail.com>
Message-ID: <155501ca8435$5194cd80$f4be6880$@washington.edu>

I would like to mention the nice free tutorial on time series objects in R
by the Rmetrics folks, available here

http://www.rmetrics.org/ebooks

There's lots of good stuff in this tutorial on both zoo, xts, timeSeries and
timeDate objects. 

ez
-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Stephen J.
Barr
Sent: Wednesday, December 23, 2009 4:51 PM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] general zoo tutorial available?

Hello,

I am working on a dataset of some intraday data. I haven't used R for this
too much, so I have a few general questions.

1) What is the best way to structure the data? The CSV is from WRDS, ordered
by symbol and then by datetime. Should I dump this into 1 zoo object, or
have one zoo object per symbol?

2) The questions I would initially like to look at are:
for a given [minute, 2 minute interval, hour, etc], what was the total
volume, average volume, average price, etc. What is a good reference for
learning how to do these kinds of things?

3) What is the best way to plot these time series?

Thanks,
-stephen

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From markleeds at verizon.net  Thu Dec 24 02:17:07 2009
From: markleeds at verizon.net (markleeds at verizon.net)
Date: Wed, 23 Dec 2009 19:17:07 -0600 (CST)
Subject: [R-SIG-Finance] How to estimate SV type models in
	R	more	efficiently?
Message-ID: <1041448405.77479.1261617427495.JavaMail.root@vms182.mailsrvcs.net>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091223/fb724d7c/attachment.html>

From jeff.a.ryan at gmail.com  Thu Dec 24 03:51:11 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Wed, 23 Dec 2009 20:51:11 -0600
Subject: [R-SIG-Finance] general zoo tutorial available?
In-Reply-To: <9b4cc5750912231650i2396c7a1m4390018c52ed62fc@mail.gmail.com>
References: <9b4cc5750912231650i2396c7a1m4390018c52ed62fc@mail.gmail.com>
Message-ID: <e8e755250912231851q3d08197bp3e53b085e80ffbb7@mail.gmail.com>

The xts (a subclass of zoo) package has a comprehensive vignette as well:

http://cran.r-project.org/web/packages/xts/vignettes/xts.pdf

For general data manipulation and plotting of time-series in finance,
there are many examples on the quantmod site (of the package quantmod
and xts).

http://www.quantmod.com/examples/
http://www.quantmod.com/examples/data/
http://www.quantmod.com/examples/charting/

This list is quite an excellent way to see how people use the
zoo/xts/timeSeries/ etc.

Make some time to browse though some results on Nabble's archive:

http://n4.nabble.com/Rmetrics-f925806.html

HTH
Jeff


On Wed, Dec 23, 2009 at 6:50 PM, Stephen J. Barr <stephenjbarr at gmail.com> wrote:
> Hello,
>
> I am working on a dataset of some intraday data. I haven't used R for this
> too much, so I have a few general questions.
>
> 1) What is the best way to structure the data? The CSV is from WRDS, ordered
> by symbol and then by datetime. Should I dump this into 1 zoo object, or
> have one zoo object per symbol?
>
> 2) The questions I would initially like to look at are:
> for a given [minute, 2 minute interval, hour, etc], what was the total
> volume, average volume, average price, etc. What is a good reference for
> learning how to do these kinds of things?
>
> 3) What is the best way to plot these time series?
>
> Thanks,
> -stephen
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From stephenjbarr at gmail.com  Thu Dec 24 04:36:30 2009
From: stephenjbarr at gmail.com (Stephen J. Barr)
Date: Wed, 23 Dec 2009 22:36:30 -0500
Subject: [R-SIG-Finance] general zoo tutorial available?
In-Reply-To: <e8e755250912231851q3d08197bp3e53b085e80ffbb7@mail.gmail.com>
References: <9b4cc5750912231650i2396c7a1m4390018c52ed62fc@mail.gmail.com>
	<e8e755250912231851q3d08197bp3e53b085e80ffbb7@mail.gmail.com>
Message-ID: <9b4cc5750912231936l6291339ajcb32598c8d4f295c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091223/baffa712/attachment.pl>

From stock at ancientsaturn.com  Thu Dec 24 05:55:48 2009
From: stock at ancientsaturn.com (tradetree)
Date: Wed, 23 Dec 2009 20:55:48 -0800 (PST)
Subject: [R-SIG-Finance]  Live Algo Trading
Message-ID: <1261630548461-978300.post@n4.nabble.com>


I wanted to see if there are people using R and quantmod to trade live, or
only as an off-line tool for algorithm development?  I am evaluating
ActiveQuant and R to decide what to use for a live trading platform.  I am
coming from Tradestation and right now considering AQ and the IB interface.  

It is very hard to find an overview of approaches and pros/cons for
automated trading.  Some people use AQ for the trading engine but do algo
development in R and quantmod.  Is this a recommended direction?


-- 
View this message in context: http://n4.nabble.com/Live-Algo-Trading-tp978300p978300.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From jeff.a.ryan at gmail.com  Thu Dec 24 06:31:48 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Wed, 23 Dec 2009 23:31:48 -0600
Subject: [R-SIG-Finance] Live Algo Trading
In-Reply-To: <1261630548461-978300.post@n4.nabble.com>
References: <1261630548461-978300.post@n4.nabble.com>
Message-ID: <e8e755250912232131ta894bacx268039f761817c4f@mail.gmail.com>

Using R as a live trading platform is really on a case by case basis.

For 1 minute bar trading, with limited computational overhead, R is a
perfectly workable solution.  Inside of that time-frame, things may
get difficult.

A multitude of factors should be considered.  First and foremost would
be R proficiency.  quantmod isn't up to the plug and play task of
automated trading (yet?!).  So you'd need to do quite a bit of work to
get things up to speed.  It is doable, but you'll either be writing a
lot of code yourself to fill in some infrastructure bits, hiring
someone to do it for you, or most likely a combination of the two.
And it will take time.  All worthwhile things do.

The IBrokers package is a decent example of what you can do.  Run
across multiple sessions on a multicore platform, you can manage to
process as much data as IB will let you.  You'll not be able to take a
raw feed from a real data source of course (think millions of messages
a second).  Preprocessed (limited symbols, aggregation, many cores,
capture-engine intermediary, etc), and you are getting closer to
'real-time' reality.

The advantage to myself and those I know who *do use* the above
approach, is that you can think in "R".  If you are doing backtesting,
post-analysis, etc in R, it is a quasi-natural fit to move the
execution into R.

Another approach taken is to keep the execution stuff outside of R
(C++ or Java for example), and simply make calls to R when needed.  Of
course if your logic relies on the R code, you are still imposing the
same potential limit on the total process.

Simple take away: it is possible, but not easy.  You gain an
incredible amount of flexibility and speed of development (if R-versed
already), but the trade-off is in raw processing capacity.  A strategy
relying on ticks or orderbook data with only R would likely be
suicide.  15s to end-of-day style, very doable.

Best,
Jeff


On Wed, Dec 23, 2009 at 10:55 PM, tradetree <stock at ancientsaturn.com> wrote:
>
> I wanted to see if there are people using R and quantmod to trade live, or
> only as an off-line tool for algorithm development? ?I am evaluating
> ActiveQuant and R to decide what to use for a live trading platform. ?I am
> coming from Tradestation and right now considering AQ and the IB interface.
>
> It is very hard to find an overview of approaches and pros/cons for
> automated trading. ?Some people use AQ for the trading engine but do algo
> development in R and quantmod. ?Is this a recommended direction?
>
>
> --
> View this message in context: http://n4.nabble.com/Live-Algo-Trading-tp978300p978300.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From stock at ancientsaturn.com  Thu Dec 24 07:25:31 2009
From: stock at ancientsaturn.com (tradetree)
Date: Wed, 23 Dec 2009 22:25:31 -0800 (PST)
Subject: [R-SIG-Finance] Live Algo Trading
In-Reply-To: <e8e755250912232131ta894bacx268039f761817c4f@mail.gmail.com>
References: <1261630548461-978300.post@n4.nabble.com>
	<e8e755250912232131ta894bacx268039f761817c4f@mail.gmail.com>
Message-ID: <1261635931504-978313.post@n4.nabble.com>



That was a great overview and exactly what I needed to find out.  I saw very
quickly that R was powerful and could perform my tasks, but I also know how
interpretive and scripted platforms perform when in production.  I will
stick to AQ and keep control of the internals implementation.  I am just
realizing how much work it will be!...


Jeff Ryan wrote:
> 
> Using R as a live trading platform is really on a case by case basis.
> 
> For 1 minute bar trading, with limited computational overhead, R is a
> perfectly workable solution.  Inside of that time-frame, things may
> get difficult.
> 
> A multitude of factors should be considered.  First and foremost would
> be R proficiency.  quantmod isn't up to the plug and play task of
> automated trading (yet?!).  So you'd need to do quite a bit of work to
> get things up to speed.  It is doable, but you'll either be writing a
> lot of code yourself to fill in some infrastructure bits, hiring
> someone to do it for you, or most likely a combination of the two.
> And it will take time.  All worthwhile things do.
> 
> The IBrokers package is a decent example of what you can do.  Run
> across multiple sessions on a multicore platform, you can manage to
> process as much data as IB will let you.  You'll not be able to take a
> raw feed from a real data source of course (think millions of messages
> a second).  Preprocessed (limited symbols, aggregation, many cores,
> capture-engine intermediary, etc), and you are getting closer to
> 'real-time' reality.
> 
> The advantage to myself and those I know who *do use* the above
> approach, is that you can think in "R".  If you are doing backtesting,
> post-analysis, etc in R, it is a quasi-natural fit to move the
> execution into R.
> 
> Another approach taken is to keep the execution stuff outside of R
> (C++ or Java for example), and simply make calls to R when needed.  Of
> course if your logic relies on the R code, you are still imposing the
> same potential limit on the total process.
> 
> Simple take away: it is possible, but not easy.  You gain an
> incredible amount of flexibility and speed of development (if R-versed
> already), but the trade-off is in raw processing capacity.  A strategy
> relying on ticks or orderbook data with only R would likely be
> suicide.  15s to end-of-day style, very doable.
> 
> Best,
> Jeff
> 
> 
> On Wed, Dec 23, 2009 at 10:55 PM, tradetree <stock at ancientsaturn.com>
> wrote:
>>
>> I wanted to see if there are people using R and quantmod to trade live,
>> or
>> only as an off-line tool for algorithm development? ?I am evaluating
>> ActiveQuant and R to decide what to use for a live trading platform. ?I
>> am
>> coming from Tradestation and right now considering AQ and the IB
>> interface.
>>
>> It is very hard to find an overview of approaches and pros/cons for
>> automated trading. ?Some people use AQ for the trading engine but do algo
>> development in R and quantmod. ?Is this a recommended direction?
>>
>>
>> --
>> View this message in context:
>> http://n4.nabble.com/Live-Algo-Trading-tp978300p978300.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
> 
> 
> 
> -- 
> Jeffrey Ryan
> jeffrey.ryan at insightalgo.com
> 
> ia: insight algorithmics
> www.insightalgo.com
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
> 

-- 
View this message in context: http://n4.nabble.com/Live-Algo-Trading-tp978300p978313.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From Zeno.Adams at ebs.edu  Thu Dec 24 14:27:33 2009
From: Zeno.Adams at ebs.edu (Adams, Zeno)
Date: Thu, 24 Dec 2009 14:27:33 +0100
Subject: [R-SIG-Finance] Non parametric, unequal variance,
	equality of mean significance test
References: <4AAD56F399C8564C9EB6817C17618CDD04E67212@NYC-XCH3.win.moorecap.com>
Message-ID: <9064522880125945B98983BBAECBA1CC0101BAED@exchsrv001.ebs.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091224/b08d4e10/attachment.pl>

From matthieu.stigler at gmail.com  Thu Dec 24 16:26:23 2009
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Thu, 24 Dec 2009 16:26:23 +0100
Subject: [R-SIG-Finance] error correction model - general specification
In-Reply-To: <1274146568.70542.1261607711303.JavaMail.root@vms182.mailsrvcs.net>
References: <1274146568.70542.1261607711303.JavaMail.root@vms182.mailsrvcs.net>
Message-ID: <111060c20912240726ua5e0e76p7feab30e4c4a3118@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091224/edd86844/attachment.pl>

From arun.kumar.saha at gmail.com  Fri Dec 25 14:08:32 2009
From: arun.kumar.saha at gmail.com (Arun.stat)
Date: Fri, 25 Dec 2009 05:08:32 -0800 (PST)
Subject: [R-SIG-Finance] error correction model - general specification
In-Reply-To: <5bfb4a970912231426q553caa2drc6367c7e0b0dc451@mail.gmail.com>
References: <5bfb4a970912231426q553caa2drc6367c7e0b0dc451@mail.gmail.com>
Message-ID: <1261746512041-978772.post@n4.nabble.com>


Lutkepohl discusses explicitly on how to choose optimum number of lags and
how to incorporate seasonal dummy variables (like monthly, quarterly) with
asymptotic distributions of corresponding estimated parameters.

Best,



Gautier RENAULT wrote:
> 
> Hi R-users,
> 
> I try to deal with cointegration in R and estimate an Error Correction
> Model
> (ECM) in a bivariate case in which I consider two variables:
> 
> ?         Pt: index house prices in France from 1996:Q1 to 2009:Q3 (log
> dependent variable)
> 
> ?         Xt: amount that households can borrow (log explanatory
> variable).
> Xt captures the role of credit, income and interest rate as drivers of the
> french housing demand.
> 
> Data are in ?fr-demand-house.csv?.
> 
> The final aim is to estimate the long run relationship between houses
> prices
> (Pt) and the credit (Xt) in France :
> 
> Pt = ? + ? Xt
> 
> I wish to estimate a general specification of the ECM as follows :
> 
> ?Pt=?(Pt-1-? - ? Xt-1)+?(?Xt-i)+?(?Pt-i)
> 
> 
> 
> First, following the methodology presented in the book of B. Pfaff I
> bought,
> I already concluded that Pt and Xt are cointegrated  I(1) with ur.df (ADF
> test ) and ca.po (Phillips-Ouliaris Method) functions.
> 
> Second, how can I do :
> 
> 1.       to choose optimal number of lag in this general specification for
> the two cointegrated variables Pt (?Pt-i) and Xt (?Xt-i)?
> 
> 2.       to add a dummy variable for the first quarter of 2009
> (dumQ1-2009)
> to test the collapse of houses prices in France at the beginning of 2009 ?
> 
> Can anyone help?
> 
> thanking you in advance,
> 
> 
> 
> Gautier RENAULT
> 
>  
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 

-- 
View this message in context: http://n4.nabble.com/error-correction-model-general-specification-tp978136p978772.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From n_torenvliet at hotmail.com  Fri Dec 25 16:31:18 2009
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Fri, 25 Dec 2009 10:31:18 -0500
Subject: [R-SIG-Finance] Live Algo Trading
In-Reply-To: <1261635931504-978313.post@n4.nabble.com>
References: <1261630548461-978300.post@n4.nabble.com>,
	<e8e755250912232131ta894bacx268039f761817c4f@mail.gmail.com>,
	<1261635931504-978313.post@n4.nabble.com>
Message-ID: <BAY143-W291EEE47A41A8BA4206702FE7E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091225/b2e0862b/attachment.pl>

From jeff.a.ryan at gmail.com  Fri Dec 25 20:08:46 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 25 Dec 2009 13:08:46 -0600
Subject: [R-SIG-Finance] Live Algo Trading
In-Reply-To: <BAY143-W291EEE47A41A8BA4206702FE7E0@phx.gbl>
References: <1261630548461-978300.post@n4.nabble.com>
	<e8e755250912232131ta894bacx268039f761817c4f@mail.gmail.com>
	<1261635931504-978313.post@n4.nabble.com>
	<BAY143-W291EEE47A41A8BA4206702FE7E0@phx.gbl>
Message-ID: <e8e755250912251108v67ad8abcob35391ede59be2f5@mail.gmail.com>

On Fri, Dec 25, 2009 at 9:31 AM, Nick Torenvliet
<n_torenvliet at hotmail.com> wrote:
>
> Yeah, that was a good overview... ?Does anyone here have experience with activequant? ?I checked it out a while ago and was discrourage by the seeming lack of docs... but I'd be interested to know more.

As this is the R list, it isn't really appropriate to ask non-R questions.

Please post to other forums for answers regarding other software.

Thanks,
Jeff

>
> Happy Holidays all!
>
>> Date: Wed, 23 Dec 2009 22:25:31 -0800
>> From: stock at ancientsaturn.com
>> To: r-sig-finance at stat.math.ethz.ch
>> Subject: Re: [R-SIG-Finance] Live Algo Trading
>>
>>
>>
>> That was a great overview and exactly what I needed to find out. ?I saw very
>> quickly that R was powerful and could perform my tasks, but I also know how
>> interpretive and scripted platforms perform when in production. ?I will
>> stick to AQ and keep control of the internals implementation. ?I am just
>> realizing how much work it will be!...
>>
>>
>> Jeff Ryan wrote:
>> >
>> > Using R as a live trading platform is really on a case by case basis.
>> >
>> > For 1 minute bar trading, with limited computational overhead, R is a
>> > perfectly workable solution. ?Inside of that time-frame, things may
>> > get difficult.
>> >
>> > A multitude of factors should be considered. ?First and foremost would
>> > be R proficiency. ?quantmod isn't up to the plug and play task of
>> > automated trading (yet?!). ?So you'd need to do quite a bit of work to
>> > get things up to speed. ?It is doable, but you'll either be writing a
>> > lot of code yourself to fill in some infrastructure bits, hiring
>> > someone to do it for you, or most likely a combination of the two.
>> > And it will take time. ?All worthwhile things do.
>> >
>> > The IBrokers package is a decent example of what you can do. ?Run
>> > across multiple sessions on a multicore platform, you can manage to
>> > process as much data as IB will let you. ?You'll not be able to take a
>> > raw feed from a real data source of course (think millions of messages
>> > a second). ?Preprocessed (limited symbols, aggregation, many cores,
>> > capture-engine intermediary, etc), and you are getting closer to
>> > 'real-time' reality.
>> >
>> > The advantage to myself and those I know who *do use* the above
>> > approach, is that you can think in "R". ?If you are doing backtesting,
>> > post-analysis, etc in R, it is a quasi-natural fit to move the
>> > execution into R.
>> >
>> > Another approach taken is to keep the execution stuff outside of R
>> > (C++ or Java for example), and simply make calls to R when needed. ?Of
>> > course if your logic relies on the R code, you are still imposing the
>> > same potential limit on the total process.
>> >
>> > Simple take away: it is possible, but not easy. ?You gain an
>> > incredible amount of flexibility and speed of development (if R-versed
>> > already), but the trade-off is in raw processing capacity. ?A strategy
>> > relying on ticks or orderbook data with only R would likely be
>> > suicide. ?15s to end-of-day style, very doable.
>> >
>> > Best,
>> > Jeff
>> >
>> >
>> > On Wed, Dec 23, 2009 at 10:55 PM, tradetree <stock at ancientsaturn.com>
>> > wrote:
>> >>
>> >> I wanted to see if there are people using R and quantmod to trade live,
>> >> or
>> >> only as an off-line tool for algorithm development? ?I am evaluating
>> >> ActiveQuant and R to decide what to use for a live trading platform. ?I
>> >> am
>> >> coming from Tradestation and right now considering AQ and the IB
>> >> interface.
>> >>
>> >> It is very hard to find an overview of approaches and pros/cons for
>> >> automated trading. ?Some people use AQ for the trading engine but do algo
>> >> development in R and quantmod. ?Is this a recommended direction?
>> >>
>> >>
>> >> --
>> >> View this message in context:
>> >> http://n4.nabble.com/Live-Algo-Trading-tp978300p978300.html
>> >> Sent from the Rmetrics mailing list archive at Nabble.com.
>> >>
>> >> _______________________________________________
>> >> R-SIG-Finance at stat.math.ethz.ch mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >> -- Subscriber-posting only.
>> >> -- If you want to post, subscribe first.
>> >>
>> >
>> >
>> >
>> > --
>> > Jeffrey Ryan
>> > jeffrey.ryan at insightalgo.com
>> >
>> > ia: insight algorithmics
>> > www.insightalgo.com
>> >
>> > _______________________________________________
>> > R-SIG-Finance at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only.
>> > -- If you want to post, subscribe first.
>> >
>> >
>>
>> --
>> View this message in context: http://n4.nabble.com/Live-Algo-Trading-tp978300p978313.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From stock at ancientsaturn.com  Fri Dec 25 22:48:53 2009
From: stock at ancientsaturn.com (tradetree)
Date: Fri, 25 Dec 2009 13:48:53 -0800 (PST)
Subject: [R-SIG-Finance] Live Algo Trading
In-Reply-To: <BAY143-W291EEE47A41A8BA4206702FE7E0@phx.gbl>
References: <1261630548461-978300.post@n4.nabble.com>
	<e8e755250912232131ta894bacx268039f761817c4f@mail.gmail.com>
	<1261635931504-978313.post@n4.nabble.com>
	<BAY143-W291EEE47A41A8BA4206702FE7E0@phx.gbl>
Message-ID: <1261777733197-978909.post@n4.nabble.com>


To Nick and others looking for a working algo platform.  

I am looking to find a group of committed people who will work on a system
that can auto-trade.  It is hard to know where to post this question because
you need to know the answer before you ask it! ;-)  If R + quantmod work,
then the R list is the right one, but if you don't know that where do you
post?  So I'd recommend anyone with a committed interest in figuring out a
working system send me a private email.  I am in discussion with other
developers off-list.  Keep in mind that this is an incubation project
effort, so you need to be able to develop code either in R, R-quantmod, or
AQ.  I believe all three will be used, so the R and quantmod related
questions are appropriate to this list.  I think AQ may also be used, and if
that is the case we will use the AQ list on Nabble.  My hope is that a new
derivative database of a working algo trading system could emerge.

I wonder what the GPL license allows for integrating several GPL projects to
form another system?  I wonder what list is the right one to ask such a
question?


Nick Torenvliet wrote:
> 
> 
> Yeah, that was a good overview...  Does anyone here have experience with
> activequant?  I checked it out a while ago and was discrourage by the
> seeming lack of docs... but I'd be interested to know more. 
> 
> Happy Holidays all!
> 
>> Date: Wed, 23 Dec 2009 22:25:31 -0800
>> From: stock at ancientsaturn.com
>> To: r-sig-finance at stat.math.ethz.ch
>> Subject: Re: [R-SIG-Finance] Live Algo Trading
>> 
>> 
>> 
>> That was a great overview and exactly what I needed to find out.  I saw
>> very
>> quickly that R was powerful and could perform my tasks, but I also know
>> how
>> interpretive and scripted platforms perform when in production.  I will
>> stick to AQ and keep control of the internals implementation.  I am just
>> realizing how much work it will be!...
>> 
>> 
>> Jeff Ryan wrote:
>> > 
>> > Using R as a live trading platform is really on a case by case basis.
>> > 
>> > For 1 minute bar trading, with limited computational overhead, R is a
>> > perfectly workable solution.  Inside of that time-frame, things may
>> > get difficult.
>> > 
>> > A multitude of factors should be considered.  First and foremost would
>> > be R proficiency.  quantmod isn't up to the plug and play task of
>> > automated trading (yet?!).  So you'd need to do quite a bit of work to
>> > get things up to speed.  It is doable, but you'll either be writing a
>> > lot of code yourself to fill in some infrastructure bits, hiring
>> > someone to do it for you, or most likely a combination of the two.
>> > And it will take time.  All worthwhile things do.
>> > 
>> > The IBrokers package is a decent example of what you can do.  Run
>> > across multiple sessions on a multicore platform, you can manage to
>> > process as much data as IB will let you.  You'll not be able to take a
>> > raw feed from a real data source of course (think millions of messages
>> > a second).  Preprocessed (limited symbols, aggregation, many cores,
>> > capture-engine intermediary, etc), and you are getting closer to
>> > 'real-time' reality.
>> > 
>> > The advantage to myself and those I know who *do use* the above
>> > approach, is that you can think in "R".  If you are doing backtesting,
>> > post-analysis, etc in R, it is a quasi-natural fit to move the
>> > execution into R.
>> > 
>> > Another approach taken is to keep the execution stuff outside of R
>> > (C++ or Java for example), and simply make calls to R when needed.  Of
>> > course if your logic relies on the R code, you are still imposing the
>> > same potential limit on the total process.
>> > 
>> > Simple take away: it is possible, but not easy.  You gain an
>> > incredible amount of flexibility and speed of development (if R-versed
>> > already), but the trade-off is in raw processing capacity.  A strategy
>> > relying on ticks or orderbook data with only R would likely be
>> > suicide.  15s to end-of-day style, very doable.
>> > 
>> > Best,
>> > Jeff
>> > 
>> > 
>> > On Wed, Dec 23, 2009 at 10:55 PM, tradetree <stock at ancientsaturn.com>
>> > wrote:
>> >>
>> >> I wanted to see if there are people using R and quantmod to trade
>> live,
>> >> or
>> >> only as an off-line tool for algorithm development?  I am evaluating
>> >> ActiveQuant and R to decide what to use for a live trading platform. 
>> I
>> >> am
>> >> coming from Tradestation and right now considering AQ and the IB
>> >> interface.
>> >>
>> >> It is very hard to find an overview of approaches and pros/cons for
>> >> automated trading.  Some people use AQ for the trading engine but do
>> algo
>> >> development in R and quantmod.  Is this a recommended direction?
>> >>
>> >>
>> >> --
>> >> View this message in context:
>> >> http://n4.nabble.com/Live-Algo-Trading-tp978300p978300.html
>> >> Sent from the Rmetrics mailing list archive at Nabble.com.
>> >>
>> >> _______________________________________________
>> >> R-SIG-Finance at stat.math.ethz.ch mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >> -- Subscriber-posting only.
>> >> -- If you want to post, subscribe first.
>> >>
>> > 
>> > 
>> > 
>> > -- 
>> > Jeffrey Ryan
>> > jeffrey.ryan at insightalgo.com
>> > 
>> > ia: insight algorithmics
>> > www.insightalgo.com
>> > 
>> > _______________________________________________
>> > R-SIG-Finance at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only.
>> > -- If you want to post, subscribe first.
>> > 
>> > 
>> 
>> -- 
>> View this message in context:
>> http://n4.nabble.com/Live-Algo-Trading-tp978300p978313.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>> 
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>  		 	   		  
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
> 

-- 
View this message in context: http://n4.nabble.com/Live-Algo-Trading-tp978300p978909.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From ustaudinger at gmail.com  Sat Dec 26 04:22:29 2009
From: ustaudinger at gmail.com (ustaudinger at gmail.com)
Date: Sat, 26 Dec 2009 04:22:29 +0100
Subject: [R-SIG-Finance] Live Algo Trading
Message-ID: <phpYVBMz6LtS.HpZcQdVv@smtp.gmail.com>

Hi,

I am delighted to read these positive vibes about aq, as i found it in 2002 (under the name ccapi).

Mind the new and much easier to use aqp2 from us at http://aqp2.activequant.org .

The idea u describe is very much what we intend over at aq.org as well, for this reason we have migrated last year to something like r-forge, u can call it aq-forge, based on redmine. I offer the servives of aq.org to host all code, svn,wiki, bug tracker etc. Of course there r also the big places like sf.net and google code, but i appell on the smartness of people to not support these big ones, but rather stay close to us and work with aq.org. 
On the aq mailing lists we have many good and motivated people. i recommend to setup a project there and use all the discussion facilities from there. As we host everything ourselve, an automated backtesting is very easy to setup. Of course only the best of the best should join theae efforts, i fully agree that a thorough skillset is required.

Regarding licensing i don't see a problem as long as it stays gpl.

Let's stay in touch.

Sorry for "abusing" this list a bit, on friendly neighbourship,
Ulrich



-- Urspr. Mitt. --
Betreff: Re: [R-SIG-Finance] Live Algo Trading
Von: tradetree <stock at ancientsaturn.com>
Datum: 25.12.2009 22:50


To Nick and others looking for a working algo platform.  

I am looking to find a group of committed people who will work on a system
that can auto-trade.  It is hard to know where to post this question because
you need to know the answer before you ask it! ;-)  If R + quantmod work,
then the R list is the right one, but if you don't know that where do you
post?  So I'd recommend anyone with a committed interest in figuring out a
working system send me a private email.  I am in discussion with other
developers off-list.  Keep in mind that this is an incubation project
effort, so you need to be able to develop code either in R, R-quantmod, or
AQ.  I believe all three will be used, so the R and quantmod related
questions are appropriate to this list.  I think AQ may also be used, and if
that is the case we will use the AQ list on Nabble.  My hope is that a new
derivative database of a working algo trading system could emerge.

I wonder what the GPL license allows for integrating several GPL projects to
form another system?  I wonder what list is the right one to ask such a
question?


Nick Torenvliet wrote:
> 
> 
> Yeah, that was a good overview...  Does anyone here have experience with
> activequant?  I checked it out a while ago and was discrourage by the
> seeming lack of docs... but I'd be interested to know more. 
> 
> Happy Holidays all!
> 
>> Date: Wed, 23 Dec 2009 22:25:31 -0800
>> From: stock at ancientsaturn.com
>> To: r-sig-finance at stat.math.ethz.ch
>> Subject: Re: [R-SIG-Finance] Live Algo Trading
>> 
>> 
>> 
>> That was a great overview and exactly what I needed to find out.  I saw
>> very
>> quickly that R was powerful and could perform my tasks, but I also know
>> how
>> interpretive and scripted platforms perform when in production.  I will
>> stick to AQ and keep control of the internals implementation.  I am just
>> realizing how much work it will be!...
>> 
>> 
>> Jeff Ryan wrote:
>> > 
>> > Using R as a live trading platform is really on a case by case basis.
>> > 
>> > For 1 minute bar trading, with limited computational overhead, R is a
>> > perfectly workable solution.  Inside of that time-frame, things may
>> > get difficult.
>> > 
>> > A multitude of factors should be considered.  First and foremost would
>> > be R proficiency.  quantmod isn't up to the plug and play task of
>> > automated trading (yet?!).  So you'd need to do quite a bit of work to
>> > get things up to speed.  It is doable, but you'll either be writing a
>> > lot of code yourself to fill in some infrastructure bits, hiring
>> > someone to do it for you, or most likely a combination of the two.
>> > And it will take time.  All worthwhile things do.
>> > 
>> > The IBrokers package is a decent example of what you can do.  Run
>> > across multiple sessions on a multicore platform, you can manage to
>> > process as much data as IB will let you.  You'll not be able to take a
>> > raw feed from a real data source of course (think millions of messages
>> > a second).  Preprocessed (limited symbols, aggregation, many cores,
>> > capture-engine intermediary, etc), and you are getting closer to
>> > 'real-time' reality.
>> > 
>> > The advantage to myself and those I know who *do use* the above
>> > approach, is that you can think in "R".  If you are doing backtesting,
>> > post-analysis, etc in R, it is a quasi-natural fit to move the
>> > execution into R.
>> > 
>> > Another approach taken is to keep the execution stuff outside of R
>> > (C++ or Java for example), and simply make calls to R when needed.  Of
>> > course if your logic relies on the R code, you are still imposing the
>> > same potential limit on the total process.
>> > 
>> > Simple take away: it is possible, but not easy.  You gain an
>> > incredible amount of flexibility and speed of development (if R-versed
>> > already), but the trade-off is in raw processing capacity.  A strategy
>> > relying on ticks or orderbook data with only R would likely be
>> > suicide.  15s to end-of-day style, very doable.
>> > 
>> > Best,
>> > Jeff
>> > 
>> > 
>> > On Wed, Dec 23, 2009 at 10:55 PM, tradetree <stock at ancientsaturn.com>
>> > wrote:
>> >>
>> >> I wanted to see if there are people using R and quantmod to trade
>> live,
>> >> or
>> >> only as an off-line tool for algorithm development?  I am evaluating
>> >> ActiveQuant and R to decide what to use for a live trading platform. 
>> I
>> >> am
>> >> coming from Tradestation and right now considering AQ and the IB
>> >> interface.
>> >>
>> >> It is very hard to find an overview of approaches and pros/cons for
>> >> automated trading.  Some people use AQ for the trading engine but do
>> algo
>> >> development in R and quantmod.  Is this a recommended direction?
>> >>
>> >>
>> >> --
>> >> View this message in context:
>> >> http://n4.nabble.com/Live-Algo-Trading-tp978300p978300.html
>> >> Sent from the Rmetrics mailing list archive at Nabble.com.
>> >>
>> >> _______________________________________________
>> >> R-SIG-Finance at stat.math.ethz.ch mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >> -- Subscriber-posting only.
>> >> -- If you want to post, subscribe first.
>> >>
>> > 
>> > 
>> > 
>> > -- 
>> > Jeffrey Ryan
>> > jeffrey.ryan at insightalgo.com
>> > 
>> > ia: insight algorithmics
>> > www.insightalgo.com
>> > 
>> > _______________________________________________
>> > R-SIG-Finance at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only.
>> > -- If you want to post, subscribe first.
>> > 
>> > 
>> 
>> -- 
>> View this message in context:
>> http://n4.nabble.com/Live-Algo-Trading-tp978300p978313.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>> 
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>  		 	   		  
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
> 

-- 
View this message in context: http://n4.nabble.com/Live-Algo-Trading-tp978300p978909.html
Sent from the Rmetrics mailing list archive at Nabble.com.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From stock at ancientsaturn.com  Sat Dec 26 05:44:59 2009
From: stock at ancientsaturn.com (tradetree)
Date: Fri, 25 Dec 2009 20:44:59 -0800 (PST)
Subject: [R-SIG-Finance] Live Algo Trading
In-Reply-To: <phpYVBMz6LtS.HpZcQdVv@smtp.gmail.com>
References: <1261630548461-978300.post@n4.nabble.com>
	<phpYVBMz6LtS.HpZcQdVv@smtp.gmail.com>
Message-ID: <1261802699787-979014.post@n4.nabble.com>



Let's move this discussion over to the AQ forum on Nabble.  I want to point
out that aqp2 is not operational, so don't go there expecting a working
release.  But it is close, and I believe it can be the basis for good
progress with the right people.  This is the AQ forum:
http://old.nabble.com/ActiveQuant-f27807.html



Hi,

I am delighted to read these positive vibes about aq, as i found it in 2002
(under the name ccapi).

Mind the new and much easier to use aqp2 from us at
http://aqp2.activequant.org .

The idea u describe is very much what we intend over at aq.org as well, for
this reason we have migrated last year to something like r-forge, u can call
it aq-forge, based on redmine. I offer the servives of aq.org to host all
code, svn,wiki, bug tracker etc. Of course there r also the big places like
sf.net and google code, but i appell on the smartness of people to not
support these big ones, but rather stay close to us and work with aq.org. 
On the aq mailing lists we have many good and motivated people. i recommend
to setup a project there and use all the discussion facilities from there.
As we host everything ourselve, an automated backtesting is very easy to
setup. Of course only the best of the best should join theae efforts, i
fully agree that a thorough skillset is required.

Regarding licensing i don't see a problem as long as it stays gpl.

Let's stay in touch.

Sorry for "abusing" this list a bit, on friendly neighbourship,
Ulrich



-- 
View this message in context: http://n4.nabble.com/Live-Algo-Trading-tp978300p979014.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From edd at debian.org  Sat Dec 26 06:05:28 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 25 Dec 2009 23:05:28 -0600
Subject: [R-SIG-Finance] Live Algo Trading
In-Reply-To: <1261802699787-979014.post@n4.nabble.com>
References: <1261630548461-978300.post@n4.nabble.com>
	<phpYVBMz6LtS.HpZcQdVv@smtp.gmail.com>
	<1261802699787-979014.post@n4.nabble.com>
Message-ID: <19253.39320.476133.158267@ron.nulle.part>


On 25 December 2009 at 20:44, tradetree wrote:
| Let's move this discussion over to the AQ forum on Nabble.  

Please do, and I appreciate the preemptive move.

Dirk, wearning the listmaster hat

-- 
Three out of two people have difficulties with fractions.


From stock at ancientsaturn.com  Sat Dec 26 18:55:09 2009
From: stock at ancientsaturn.com (tradetree)
Date: Sat, 26 Dec 2009 09:55:09 -0800 (PST)
Subject: [R-SIG-Finance] Live Algo Trading
In-Reply-To: <19253.39320.476133.158267@ron.nulle.part>
References: <1261630548461-978300.post@n4.nabble.com>
	<phpYVBMz6LtS.HpZcQdVv@smtp.gmail.com>
	<1261802699787-979014.post@n4.nabble.com>
	<19253.39320.476133.158267@ron.nulle.part>
Message-ID: <1261850109101-979106.post@n4.nabble.com>


I started a thread "Algorithmic Trading using AQ?" here:
http://old.nabble.com/Algorithmic-Trading-using-AQ--td26928643.html


Dirk Eddelbuettel wrote:
> 
> 
> On 25 December 2009 at 20:44, tradetree wrote:
> | Let's move this discussion over to the AQ forum on Nabble.  
> 
> Please do, and I appreciate the preemptive move.
> 
> Dirk, wearning the listmaster hat
> 
> -- 
> Three out of two people have difficulties with fractions.
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
> 

-- 
View this message in context: http://n4.nabble.com/Live-Algo-Trading-tp978300p979106.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From aajd at xs4all.nl  Sun Dec 27 14:35:43 2009
From: aajd at xs4all.nl (Andre de Boer)
Date: Sun, 27 Dec 2009 14:35:43 +0100
Subject: [R-SIG-Finance] newbie
Message-ID: <21A6F529-2660-4D6D-91D3-0214EF1318B4@xs4all.nl>

Hello,

With quantmod (getSymbols(" ")) I imported some quotes from yahoo.
For instance ING.AS (see below) and AGN.AS.

How can I compute now the correlationcoefficient between ING.AS.Close and AGN.AS.Close?


Thanks for any answer,
Andr? de Boer




-------------- next part --------------
A non-text attachment was scrubbed...
Name: R Console.jpg
Type: image/jpg
Size: 50785 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091227/11a7dadb/attachment.jpg>

From r.rote12 at googlemail.com  Sun Dec 27 15:10:40 2009
From: r.rote12 at googlemail.com (Peter Rote)
Date: Sun, 27 Dec 2009 15:10:40 +0100
Subject: [R-SIG-Finance] Screeningn with IBrokers
Message-ID: <c68c5d80912270610w77f805b4j97978db31e91e61c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091227/31d24555/attachment.pl>

From brian at braverock.com  Sun Dec 27 16:36:33 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 27 Dec 2009 09:36:33 -0600
Subject: [R-SIG-Finance] newbie
In-Reply-To: <21A6F529-2660-4D6D-91D3-0214EF1318B4@xs4all.nl>
References: <21A6F529-2660-4D6D-91D3-0214EF1318B4@xs4all.nl>
Message-ID: <4B377F01.60207@braverock.com>

Andre de Boer wrote:
> Hello,
> 
> With quantmod (getSymbols(" ")) I imported some quotes from yahoo.
> For instance ING.AS (see below) and AGN.AS.
> 
> How can I compute now the correlation coefficient between ING.AS.Close and AGN.AS.Close?

You can access the columns by name:

ING.AS[,"Close"]
AGN.AS[,"Close"]
cor(ING.AS[,"Close"],AGN.AS[,"Close"])

You might also want to look at http://www.quantmod.com/ for a multitude of 
examples and documentation, and download one of the many R introductory 
tutorials you can find online.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From megh700004 at yahoo.com  Mon Dec 28 07:41:11 2009
From: megh700004 at yahoo.com (Megh)
Date: Sun, 27 Dec 2009 22:41:11 -0800 (PST)
Subject: [R-SIG-Finance]  Analysis of market impact
Message-ID: <1261982471803-989624.post@n4.nabble.com>


Hi all, Merry Christmas and happy new year

Here I am into some analysis on, maximum how many lots a market perticipant
can buy/sell in a particular day, on a particular futures contract without
altering the normal market dynamics and in what extend dynamics would be
influenced for some trade exceeding that stipulated amount.

Data I have is, contract-wise high, low, open, close quote as well as traded
volume on daily basis. Can experts here point out how should I do that. Any
references/published papers/books will be highly helpful to me.

Thanks and regards,
-- 
View this message in context: http://n4.nabble.com/Analysis-of-market-impact-tp989624p989624.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From breman.mark at gmail.com  Mon Dec 28 08:49:01 2009
From: breman.mark at gmail.com (Mark Breman)
Date: Mon, 28 Dec 2009 08:49:01 +0100
Subject: [R-SIG-Finance] Analysis of market impact
In-Reply-To: <1261982471803-989624.post@n4.nabble.com>
References: <1261982471803-989624.post@n4.nabble.com>
Message-ID: <5e6a2e670912272349r17bb343fv569148e3edbf6739@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091228/7e8694e5/attachment.pl>

From hkahra at gmail.com  Mon Dec 28 08:57:35 2009
From: hkahra at gmail.com (Hannu Kahra)
Date: Mon, 28 Dec 2009 09:57:35 +0200
Subject: [R-SIG-Finance] newbie
In-Reply-To: <21A6F529-2660-4D6D-91D3-0214EF1318B4@xs4all.nl>
References: <21A6F529-2660-4D6D-91D3-0214EF1318B4@xs4all.nl>
Message-ID: <3d35a2ca0912272357y195a3210xd77147440cdf4f48@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091228/9d6abb5b/attachment.pl>

From bjorn.hertzberg at gmail.com  Mon Dec 28 09:23:58 2009
From: bjorn.hertzberg at gmail.com (Bjorn Hertzberg)
Date: Mon, 28 Dec 2009 09:23:58 +0100
Subject: [R-SIG-Finance] Analysis of market impact
In-Reply-To: <1261982471803-989624.post@n4.nabble.com>
References: <1261982471803-989624.post@n4.nabble.com>
Message-ID: <7CDD89F3-DEA1-4638-BEC9-A65968893F5A@gmail.com>

The standard reference for market impact analyses is: http://www.courant.nyu.edu/~almgren/papers/optliq.pdf

/bjorn



28 dec 2009 kl. 07.41 skrev Megh <megh700004 at yahoo.com>:

>
> Hi all, Merry Christmas and happy new year
>
> Here I am into some analysis on, maximum how many lots a market  
> perticipant
> can buy/sell in a particular day, on a particular futures contract  
> without
> altering the normal market dynamics and in what extend dynamics  
> would be
> influenced for some trade exceeding that stipulated amount.
>
> Data I have is, contract-wise high, low, open, close quote as well  
> as traded
> volume on daily basis. Can experts here point out how should I do  
> that. Any
> references/published papers/books will be highly helpful to me.
>
> Thanks and regards,
> -- 
> View this message in context: http://n4.nabble.com/Analysis-of-market-impact-tp989624p989624.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R  
> questions should go.


From lisete.fernandes.noronha at caixaseguros.pt  Mon Dec 28 10:56:39 2009
From: lisete.fernandes.noronha at caixaseguros.pt (Lisete Fernandes de Noronha (DGR))
Date: Mon, 28 Dec 2009 09:56:39 +0000
Subject: [R-SIG-Finance] FW: Questions related to R- Credit Risk
Message-ID: <AE5E550698A603449F82135F81F0DA3418E15B2BF6@VPF6001EXC012.fidelidademundial.com>


I am a new user of R software, and at the moment I am interested in applying "R" to calculate Credit Risk measures.

I have already been in contact with Andreas Wittmann (responsible for CreditMetrics package). Nevertheless, there are some doubts that I have which Andreas could not help me. 

Is it possible to get the answers for my questions?

1. Which package calculates lgd (loss given default)?

 2. Besides CreditMetrics package, which packages are related with 
 Credit Risk in order to calculate credit risk measures, as:

 -          Loss Distribution;
 -          VAR;
 -          Unexpected Losses:
 -          Risk Contribution


Thank you
Best regards,
Lisete Noronha


-----Original Message-----
From: Andreas Wittmann [mailto:andreas_wittmann at gmx.de] 
Sent: sexta-feira, 25 de Dezembro de 2009 8:24
To: Lisete Fernandes de Noronha (DGR)
Subject: Re: Questions related to R- Credit Risk

Hi Lisete,

sorry, but spontaneously i have no answers for your questions. please 
search the following mailing lists and if your questions cannot be 
answered, ask the questions there again.

https://stat.ethz.ch/mailman/listinfo/r-help
https://stat.ethz.ch/mailman/listinfo/r-sig-finance

best regards and merry christmans

Andreas




Lisete Fernandes de Noronha (DGR) wrote:
>
> Thanks for your help.
>
> Sorry, but I have more questions for you.
>
> 1. Can you tell me which package calculates lgd?
>
> 2. Besides CreditMetrics package, which packages are related with 
> Credit Risk in order to calculate credit risk measures, as:
>
> -          Loss Distribution;

> -          VAR;

> -          Unexpected Losses:

> -          Risk Contribution
>
> Best Regards,
>
> Lisete
>
>  
>
>  
>
> ------------------------------------------------------------------------
>
> *From:* Andreas Wittmann [mailto:andreas_wittmann at gmx.de]
> *Sent:* segunda-feira, 21 de Dezembro de 2009 18:00
> *To:* Lisete Fernandes de Noronha (DGR)
> *Subject:* Re: Questions related to R- Credit Risk
>
>  
>
> Dear Lisete,
>
> thank you for using the CreditMetrics package.
>
>    1. the pd is the probability of default, as you can see in the
>       migration matrix this is the last column without the last row.
>    2. the lgd is not calculated in this package, it is only an input
>       parameter and actually it is only possibly to use the same lgd
>       for each rating.
>
>
> hope this helps.
>
> best regards
>
> Andreas
>
>
>


From hans.radtke at gutmark.net  Mon Dec 28 13:04:23 2009
From: hans.radtke at gutmark.net (Hans Radtke)
Date: Mon, 28 Dec 2009 13:04:23 +0100
Subject: [R-SIG-Finance] Questions related to R-Credit Risk
Message-ID: <6BC17AB6B99BC441ABC83269178375A327D307@grcserver.gutmark.de>

Dear Lisete,

I cannot claim to know all packages available, but I think that the CreditMetrics package is the only one specifically related to CreditVaR, and it does some other nice things, too - like estimating PDs out of spreads (or vice versa).

But to answer your questions: I don't think that there is anything related to LGD, as LGDs are normally estimated empirically or modelled intuitively by financial institutions. I've spent a fair amount of time on this issue and I have used R for data analysis only in this context.

With regard to loss distribution / unexpected losses / VaR (which are really the same topic, some might argue), again, CreditMetrics is probably the only dedicated package around. We have build an extremely simplistic and minimalist CreditVaR model myself, essentially implementing the Vasicek Model, which I am happy to share with you. And we are also working on an implementation of a model that's conceptually closer to the Credit Portfolio View Methodology proposed by Wilson.

Other than that, I have developed a simplistic stress-testing toolkit, applying stressed transition matrices to credit portfolios to estimate impact on Standardised and F-IRB RWAs.

You can contact me directly for further information.


Mit besten Gr??en / With kind regards
Hans Radtke
Vorstand
 
Gutmark, Radtke & Company AG
Lotzstrasse 36
65934 Frankfurt
 
Telefon  +49 69 35358-102
Telefax  +49 69 35358-100 (Office)
         +49 69 255-77374 (eFax)
Mobil    +49 162 7675407  (DE)
         +44 7798 812089  (UK)
 
 
 
Gutmark, Radtke & Company AG is incorporated under German law. Board of Directors (Vorstand): Benny Gutmark, Hans Radtke. Supervisory Board (Aufsichtsrat): Dr Jacob Gutmark, Chairman. Company Registration: HRB 53028, Amtsgericht Frankfurt. Value Added Tax Registration (USt-IdNr): DE218021594. This e-mail and any attachments are confidential and may be legally privileged. If you are not the intended recipient please notify the sender immediately and delete this email. Any dissemination, distribution, copying or other use is strictly prohibited. Any opinions expressed in this communication are personal and are not attributable to Gutmark, Radtke & Company. Any communication related to specific engagements is to be read in conjunction with the relevant engagement letter or proposal document as well as our terms and conditions.


----- Original Message -----
From: r-sig-finance-bounces at stat.math.ethz.ch <r-sig-finance-bounces at stat.math.ethz.ch>
To: r-sig-finance at stat.math.ethz.ch <r-sig-finance at stat.math.ethz.ch>
Sent: Mon Dec 28 12:00:01 2009
Subject: R-SIG-Finance Digest, Vol 67, Issue 24

Send R-SIG-Finance mailing list submissions to
	r-sig-finance at stat.math.ethz.ch

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-finance
or, via email, send a message with subject or body 'help' to
	r-sig-finance-request at stat.math.ethz.ch

You can reach the person managing the list at
	r-sig-finance-owner at stat.math.ethz.ch

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-SIG-Finance digest..."


Today's Topics:

   1. newbie (Andre de Boer)
   2. Screeningn with IBrokers (Peter Rote)
   3. Re: newbie (Brian G. Peterson)
   4.  Analysis of market impact (Megh)
   5. Re: Analysis of market impact (Mark Breman)
   6. Re: newbie (Hannu Kahra)
   7. Re: Analysis of market impact (Bjorn Hertzberg)
   8. FW: Questions related to R- Credit Risk
      (Lisete Fernandes de Noronha (DGR))


----------------------------------------------------------------------

Message: 1
Date: Sun, 27 Dec 2009 14:35:43 +0100
From: Andre de Boer <aajd at xs4all.nl>
Subject: [R-SIG-Finance] newbie
To: R-SIG-Finance at stat.math.ethz.ch
Message-ID: <21A6F529-2660-4D6D-91D3-0214EF1318B4 at xs4all.nl>
Content-Type: text/plain; charset="iso-8859-1"

Hello,

With quantmod (getSymbols(" ")) I imported some quotes from yahoo.
For instance ING.AS (see below) and AGN.AS.

How can I compute now the correlationcoefficient between ING.AS.Close and AGN.AS.Close?


Thanks for any answer,
Andr? de Boer




-------------- next part --------------
A non-text attachment was scrubbed...
Name: R Console.jpg
Type: image/jpg
Size: 50785 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091227/11a7dadb/attachment-0001.jpg>

------------------------------

Message: 2
Date: Sun, 27 Dec 2009 15:10:40 +0100
From: Peter Rote <r.rote12 at googlemail.com>
Subject: [R-SIG-Finance] Screeningn with IBrokers
To: r-sig-finance at stat.math.ethz.ch
Message-ID:
	<c68c5d80912270610w77f805b4j97978db31e91e61c at mail.gmail.com>
Content-Type: text/plain

Dear All,

I would like to check a large list of stocks Tickers (300) if the open
today is greater then yesterdays high (gap up).
As result i would like to have a variable with symbols which meet the
condition. My Ticker list is a csv file.

my start point is reqMktData(tws, list(twsSTK("AAPL"),twsSTK("SBUX")),
snapshot=TRUE)

1. but how do I put the Tickers in the reqMktData without having to
type all 300 tickers.
2. how do I get the Yesterday High and compare that too today open.

Does anyone have any ideas about that, please?

Thanks for any help,
Sincerely,
Peter

	[[alternative HTML version deleted]]



------------------------------

Message: 3
Date: Sun, 27 Dec 2009 09:36:33 -0600
From: "Brian G. Peterson" <brian at braverock.com>
Subject: Re: [R-SIG-Finance] newbie
To: Andre de Boer <aajd at xs4all.nl>
Cc: R-SIG-Finance at stat.math.ethz.ch
Message-ID: <4B377F01.60207 at braverock.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Andre de Boer wrote:
> Hello,
> 
> With quantmod (getSymbols(" ")) I imported some quotes from yahoo.
> For instance ING.AS (see below) and AGN.AS.
> 
> How can I compute now the correlation coefficient between ING.AS.Close and AGN.AS.Close?

You can access the columns by name:

ING.AS[,"Close"]
AGN.AS[,"Close"]
cor(ING.AS[,"Close"],AGN.AS[,"Close"])

You might also want to look at http://www.quantmod.com/ for a multitude of 
examples and documentation, and download one of the many R introductory 
tutorials you can find online.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock



------------------------------

Message: 4
Date: Sun, 27 Dec 2009 22:41:11 -0800 (PST)
From: Megh <megh700004 at yahoo.com>
Subject: [R-SIG-Finance]  Analysis of market impact
To: r-sig-finance at stat.math.ethz.ch
Message-ID: <1261982471803-989624.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii


Hi all, Merry Christmas and happy new year

Here I am into some analysis on, maximum how many lots a market perticipant
can buy/sell in a particular day, on a particular futures contract without
altering the normal market dynamics and in what extend dynamics would be
influenced for some trade exceeding that stipulated amount.

Data I have is, contract-wise high, low, open, close quote as well as traded
volume on daily basis. Can experts here point out how should I do that. Any
references/published papers/books will be highly helpful to me.

Thanks and regards,
-- 
View this message in context: http://n4.nabble.com/Analysis-of-market-impact-tp989624p989624.html
Sent from the Rmetrics mailing list archive at Nabble.com.



------------------------------

Message: 5
Date: Mon, 28 Dec 2009 08:49:01 +0100
From: Mark Breman <breman.mark at gmail.com>
Subject: Re: [R-SIG-Finance] Analysis of market impact
To: Megh <megh700004 at yahoo.com>
Cc: r-sig-finance at stat.math.ethz.ch
Message-ID:
	<5e6a2e670912272349r17bb343fv569148e3edbf6739 at mail.gmail.com>
Content-Type: text/plain

What are "normal market dynamics" in this context?

2009/12/28 Megh <megh700004 at yahoo.com>

>
> Hi all, Merry Christmas and happy new year
>
> Here I am into some analysis on, maximum how many lots a market perticipant
> can buy/sell in a particular day, on a particular futures contract without
> altering the normal market dynamics and in what extend dynamics would be
> influenced for some trade exceeding that stipulated amount.
>
> Data I have is, contract-wise high, low, open, close quote as well as
> traded
> volume on daily basis. Can experts here point out how should I do that. Any
> references/published papers/books will be highly helpful to me.
>
> Thanks and regards,
> --
> View this message in context:
> http://n4.nabble.com/Analysis-of-market-impact-tp989624p989624.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]



------------------------------

Message: 6
Date: Mon, 28 Dec 2009 09:57:35 +0200
From: Hannu Kahra <hkahra at gmail.com>
Subject: Re: [R-SIG-Finance] newbie
To: Andre de Boer <aajd at xs4all.nl>
Cc: R-SIG-Finance at stat.math.ethz.ch
Message-ID:
	<3d35a2ca0912272357y195a3210xd77147440cdf4f48 at mail.gmail.com>
Content-Type: text/plain

Andre,

if your variables are stock prices your correlation coefficient is close to
one. That is spurious, since prices are nonstationary. You should use
returns instead of prices.

-Hannu

On Sun, Dec 27, 2009 at 3:35 PM, Andre de Boer <aajd at xs4all.nl> wrote:

> Hello,
>
> With quantmod (getSymbols(" ")) I imported some quotes from yahoo.
> For instance ING.AS (see below) and AGN.AS.
>
> How can I compute now the correlationcoefficient between ING.AS.Close and
> AGN.AS.Close?
>
>
> Thanks for any answer,
> Andr? de Boer
>
>
>
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>

	[[alternative HTML version deleted]]



------------------------------

Message: 7
Date: Mon, 28 Dec 2009 09:23:58 +0100
From: Bjorn Hertzberg <bjorn.hertzberg at gmail.com>
Subject: Re: [R-SIG-Finance] Analysis of market impact
To: Megh <megh700004 at yahoo.com>
Cc: "r-sig-finance at stat.math.ethz.ch"
	<r-sig-finance at stat.math.ethz.ch>
Message-ID: <7CDD89F3-DEA1-4638-BEC9-A65968893F5A at gmail.com>
Content-Type: text/plain;	charset=us-ascii;	format=flowed;	delsp=yes

The standard reference for market impact analyses is: http://www.courant.nyu.edu/~almgren/papers/optliq.pdf

/bjorn



28 dec 2009 kl. 07.41 skrev Megh <megh700004 at yahoo.com>:

>
> Hi all, Merry Christmas and happy new year
>
> Here I am into some analysis on, maximum how many lots a market  
> perticipant
> can buy/sell in a particular day, on a particular futures contract  
> without
> altering the normal market dynamics and in what extend dynamics  
> would be
> influenced for some trade exceeding that stipulated amount.
>
> Data I have is, contract-wise high, low, open, close quote as well  
> as traded
> volume on daily basis. Can experts here point out how should I do  
> that. Any
> references/published papers/books will be highly helpful to me.
>
> Thanks and regards,
> -- 
> View this message in context: http://n4.nabble.com/Analysis-of-market-impact-tp989624p989624.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R  
> questions should go.



------------------------------

Message: 8
Date: Mon, 28 Dec 2009 09:56:39 +0000
From: "Lisete Fernandes de Noronha (DGR)"
	<lisete.fernandes.noronha at caixaseguros.pt>
Subject: [R-SIG-Finance] FW: Questions related to R- Credit Risk
To: "'r-sig-finance at stat.math.ethz.ch'"
	<r-sig-finance at stat.math.ethz.ch>
Message-ID:
	<AE5E550698A603449F82135F81F0DA3418E15B2BF6 at VPF6001EXC012.fidelidademundial.com>
	
Content-Type: text/plain; charset="us-ascii"


I am a new user of R software, and at the moment I am interested in applying "R" to calculate Credit Risk measures.

I have already been in contact with Andreas Wittmann (responsible for CreditMetrics package). Nevertheless, there are some doubts that I have which Andreas could not help me. 

Is it possible to get the answers for my questions?

1. Which package calculates lgd (loss given default)?

 2. Besides CreditMetrics package, which packages are related with 
 Credit Risk in order to calculate credit risk measures, as:

 -          Loss Distribution;
 -          VAR;
 -          Unexpected Losses:
 -          Risk Contribution


Thank you
Best regards,
Lisete Noronha


-----Original Message-----
From: Andreas Wittmann [mailto:andreas_wittmann at gmx.de] 
Sent: sexta-feira, 25 de Dezembro de 2009 8:24
To: Lisete Fernandes de Noronha (DGR)
Subject: Re: Questions related to R- Credit Risk

Hi Lisete,

sorry, but spontaneously i have no answers for your questions. please 
search the following mailing lists and if your questions cannot be 
answered, ask the questions there again.

https://stat.ethz.ch/mailman/listinfo/r-help
https://stat.ethz.ch/mailman/listinfo/r-sig-finance

best regards and merry christmans

Andreas




Lisete Fernandes de Noronha (DGR) wrote:
>
> Thanks for your help.
>
> Sorry, but I have more questions for you.
>
> 1. Can you tell me which package calculates lgd?
>
> 2. Besides CreditMetrics package, which packages are related with 
> Credit Risk in order to calculate credit risk measures, as:
>
> -          Loss Distribution;

> -          VAR;

> -          Unexpected Losses:

> -          Risk Contribution
>
> Best Regards,
>
> Lisete
>
>  
>
>  
>
> ------------------------------------------------------------------------
>
> *From:* Andreas Wittmann [mailto:andreas_wittmann at gmx.de]
> *Sent:* segunda-feira, 21 de Dezembro de 2009 18:00
> *To:* Lisete Fernandes de Noronha (DGR)
> *Subject:* Re: Questions related to R- Credit Risk
>
>  
>
> Dear Lisete,
>
> thank you for using the CreditMetrics package.
>
>    1. the pd is the probability of default, as you can see in the
>       migration matrix this is the last column without the last row.
>    2. the lgd is not calculated in this package, it is only an input
>       parameter and actually it is only possibly to use the same lgd
>       for each rating.
>
>
> hope this helps.
>
> best regards
>
> Andreas
>
>
>



------------------------------

_______________________________________________
R-SIG-Finance mailing list
R-SIG-Finance at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-finance


End of R-SIG-Finance Digest, Vol 67, Issue 24
*********************************************


From jeff.a.ryan at gmail.com  Mon Dec 28 17:19:07 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 28 Dec 2009 10:19:07 -0600
Subject: [R-SIG-Finance] Screeningn with IBrokers
In-Reply-To: <c68c5d80912270610w77f805b4j97978db31e91e61c@mail.gmail.com>
References: <c68c5d80912270610w77f805b4j97978db31e91e61c@mail.gmail.com>
Message-ID: <e8e755250912280819q39366a04sd0178aebad53ac87@mail.gmail.com>

Hi Peter,

Since you are passing in a list, use lapply to build it from a
character string (read from your file via scan/read.table/etc (R-help
question if you need to know how to do that ..)

> reqMktData(tws, lapply(c("AAPL","BBY","MSFT"),twsSTK), snapshot=TRUE)
        lastTimeStamp symbol bidSize bidPrice askPrice askSize lastPrice Volume
1 2009-12-28 10:00:26   AAPL       1   213.18   213.19       3    213.17  84944
2 2009-12-28 10:08:48    BBY       3    40.89    40.90       1     40.90      0
3 2009-12-28 10:07:12   MSFT    1452    30.99    31.00   12344     31.00      0
    Open   High    Low  Close
1 211.15 213.95 211.10 209.04
2  40.85  41.20  40.80  40.70
3  31.00  31.00  30.97  31.00

Note that snapshot=TRUE tends to be 1) slow and 2) delayed from
real-time.  You would be better off pulling chunks of data with some
sort of custom eWrapper object passed to reqMktData or
reqRealTimeBars.  A further limit is that IB imposes (on data calls) a
limit of 100 concurrent symbols (+/-, depending on account).

With respect to #2, IB can't provide that any better than Yahoo or a
local database.

See:

library(quantmod)
?getSymbols
?getQuote
?Cl

HTH
Jeff
On Sun, Dec 27, 2009 at 8:10 AM, Peter Rote <r.rote12 at googlemail.com> wrote:
> Dear All,
>
> I would like to check a large list of stocks Tickers (300) if the open
> today is greater then yesterdays high (gap up).
> As result i would like to have a variable with symbols which meet the
> condition. My Ticker list is a csv file.
>
> my start point is reqMktData(tws, list(twsSTK("AAPL"),twsSTK("SBUX")),
> snapshot=TRUE)
>
> 1. but how do I put the Tickers in the reqMktData without having to
> type all 300 tickers.
> 2. how do I get the Yesterday High and compare that too today open.
>
> Does anyone have any ideas about that, please?
>
> Thanks for any help,
> Sincerely,
> Peter
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From Reena.Bansal at moorecap.com  Mon Dec 28 20:21:17 2009
From: Reena.Bansal at moorecap.com (Reena Bansal)
Date: Mon, 28 Dec 2009 14:21:17 -0500
Subject: [R-SIG-Finance] Non parametric, unequal variance,
	equality of mean significance test
In-Reply-To: <9064522880125945B98983BBAECBA1CC0101BAED@exchsrv001.ebs.local>
Message-ID: <4AAD56F399C8564C9EB6817C17618CDD04E6721E@NYC-XCH3.win.moorecap.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091228/52abf7ec/attachment.pl>

From donahchoo at me.com  Wed Dec 30 03:09:58 2009
From: donahchoo at me.com (donahchoo at me.com)
Date: Tue, 29 Dec 2009 20:09:58 -0600
Subject: [R-SIG-Finance] histogram, sd and mean questions
Message-ID: <A237B6F2-FFCA-443F-B418-468F0F3429DB@me.com>

Hi,

I'm trying to plot the histogram, sd and mean of some range data I  
have collected and I have several questions.  First off, my statistics  
is ancient at best, so if I get things wrong forgive me.

What I'm trying to do is determine the range of the YM for 30 minute  
periods throughout the day.  I've got the code the determining range  
working, but my standard deviation plots appear to be off.

In the graph below the orange dotted line is the mean and the dotted  
red lines are +/- 1sd.  What I want to determine what ranges are  
within 1 sd of the mean and this graph looks off to me.

Can anyone confirm that I have (not) done this correctly?  Is there a  
way I can get a finer scale on the x axis? So far I haven't found a  
way to set tick marks on the charts...

Here's my R code:

 > hist(range_tmp, breaks=250, xlim=c(0,250))
 > abline(v=mean(range_tmp), col='orange', lty=2, lwd=2.5)
 > abline(v=mean(range_tmp) + sd(range_tmp), col='red', lty=2, lwd=2.5)
 > abline(v=mean(range_tmp) - sd(range_tmp), col='red', lty=2, lwd=2.5)

Thanks!







-------------- next part --------------
A non-text attachment was scrubbed...
Name: pastedGraphic.png
Type: image/png
Size: 30726 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091229/f0687b31/attachment.png>

From brian at braverock.com  Wed Dec 30 03:22:44 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 29 Dec 2009 20:22:44 -0600
Subject: [R-SIG-Finance] histogram, sd and mean questions
In-Reply-To: <A237B6F2-FFCA-443F-B418-468F0F3429DB@me.com>
References: <A237B6F2-FFCA-443F-B418-468F0F3429DB@me.com>
Message-ID: <4B3AB974.6020309@braverock.com>

donahchoo at me.com wrote:
> Hi,
> 
> I'm trying to plot the histogram, sd and mean of some range data I have 
> collected and I have several questions.  First off, my statistics is 
> ancient at best, so if I get things wrong forgive me.
> 
> What I'm trying to do is determine the range of the YM for 30 minute 
> periods throughout the day.  I've got the code the determining range 
> working, but my standard deviation plots appear to be off.
> 
> In the graph below the orange dotted line is the mean and the dotted red 
> lines are +/- 1sd.  What I want to determine what ranges are within 1 sd 
> of the mean and this graph looks off to me.
> 
> Can anyone confirm that I have (not) done this correctly?  Is there a 
> way I can get a finer scale on the x axis? So far I haven't found a way 
> to set tick marks on the charts...
> 
> Here's my R code:
> 
>  > hist(range_tmp, breaks=250, xlim=c(0,250))
>  > abline(v=mean(range_tmp), col='orange', lty=2, lwd=2.5)
>  > abline(v=mean(range_tmp) + sd(range_tmp), col='red', lty=2, lwd=2.5)
>  > abline(v=mean(range_tmp) - sd(range_tmp), col='red', lty=2, lwd=2.5)

I know better than to guess at whether a statistical calculation is correct by 
looking at the graph, and you didn't include your data.

Your code looks fine, without having access to the data to check it.

In the future, please send Stats 101 and R 101 questions to the general r-help 
list, as this has nothing at all to do with finance.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From donahchoo at me.com  Wed Dec 30 03:26:37 2009
From: donahchoo at me.com (donahchoo at me.com)
Date: Tue, 29 Dec 2009 20:26:37 -0600
Subject: [R-SIG-Finance] histogram, sd and mean questions
In-Reply-To: <4B3AB974.6020309@braverock.com>
References: <A237B6F2-FFCA-443F-B418-468F0F3429DB@me.com>
	<4B3AB974.6020309@braverock.com>
Message-ID: <163FCBA0-A586-42A5-9952-D183BEABD212@me.com>

Thanks, Brian.  I didn't include the data as I have over 500 data  
points and didn't think it would be much use.

I'll redirect my other questions to r-help.


On Dec 29, 2009, at 8:22 PM, Brian G. Peterson wrote:

> donahchoo at me.com wrote:
>> Hi,
>> I'm trying to plot the histogram, sd and mean of some range data I  
>> have collected and I have several questions.  First off, my  
>> statistics is ancient at best, so if I get things wrong forgive me.
>> What I'm trying to do is determine the range of the YM for 30  
>> minute periods throughout the day.  I've got the code the  
>> determining range working, but my standard deviation plots appear  
>> to be off.
>> In the graph below the orange dotted line is the mean and the  
>> dotted red lines are +/- 1sd.  What I want to determine what ranges  
>> are within 1 sd of the mean and this graph looks off to me.
>> Can anyone confirm that I have (not) done this correctly?  Is there  
>> a way I can get a finer scale on the x axis? So far I haven't found  
>> a way to set tick marks on the charts...
>> Here's my R code:
>> > hist(range_tmp, breaks=250, xlim=c(0,250))
>> > abline(v=mean(range_tmp), col='orange', lty=2, lwd=2.5)
>> > abline(v=mean(range_tmp) + sd(range_tmp), col='red', lty=2,  
>> lwd=2.5)
>> > abline(v=mean(range_tmp) - sd(range_tmp), col='red', lty=2,  
>> lwd=2.5)
>
> I know better than to guess at whether a statistical calculation is  
> correct by looking at the graph, and you didn't include your data.
>
> Your code looks fine, without having access to the data to check it.
>
> In the future, please send Stats 101 and R 101 questions to the  
> general r-help list, as this has nothing at all to do with finance.
>
> Regards,
>
>    - Brian
>
> -- 
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock


From swtzang at gmail.com  Wed Dec 30 16:24:05 2009
From: swtzang at gmail.com (ShyhWeir Tzang)
Date: Wed, 30 Dec 2009 23:24:05 +0800
Subject: [R-SIG-Finance] read data
Message-ID: <c17037a10912300724l36664115n7c79fd40c23a6823@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091230/e5078f15/attachment.pl>

From brian at braverock.com  Wed Dec 30 16:28:41 2009
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 30 Dec 2009 09:28:41 -0600
Subject: [R-SIG-Finance] read data
In-Reply-To: <c17037a10912300724l36664115n7c79fd40c23a6823@mail.gmail.com>
References: <c17037a10912300724l36664115n7c79fd40c23a6823@mail.gmail.com>
Message-ID: <4B3B71A9.1020905@braverock.com>

ShyhWeir Tzang wrote:
> Dear all:
>
> I need to read a data file in text type. However, the data is interspersed
> with headings in the following format:
>
> header1  header2 header3
> 1              2            3
> 4              5            6
> ....
> (space)
>  header1  header2 header3
> (space)
> 11                 22          33
> 44                 55          66
> ...
>  (space)
>  header1  header2 header3
> (space)
> 111             222          333
> 444             555          666
> ...
>
> Is there any way to read the data without importing the headers? Any
> suggestion is highly appreciated.
> Thanks for help.
1> RTFM
2> read the list archives. this question has been answered only a few 
days ago
3> direct these kinds of non-finance questions to r-help

  - Brian


From ibharadolfo at gmail.com  Wed Dec 30 19:28:46 2009
From: ibharadolfo at gmail.com (Ibhar)
Date: Wed, 30 Dec 2009 12:28:46 -0600
Subject: [R-SIG-Finance] EGARCH and R
Message-ID: <4467d39a0912301028jab210dcv5dc0e149526f3c76@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091230/ba39d5d1/attachment.pl>

From alexios at 4dscape.com  Wed Dec 30 19:39:15 2009
From: alexios at 4dscape.com (alexios)
Date: Wed, 30 Dec 2009 18:39:15 +0000
Subject: [R-SIG-Finance] EGARCH and R
In-Reply-To: <4467d39a0912301028jab210dcv5dc0e149526f3c76@mail.gmail.com>
References: <4467d39a0912301028jab210dcv5dc0e149526f3c76@mail.gmail.com>
Message-ID: <4B3B9E53.50901@4dscape.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091230/04e272db/attachment.pl>

From qqjwl at 163.com  Thu Dec 31 15:15:49 2009
From: qqjwl at 163.com (qqjwl)
Date: Thu, 31 Dec 2009 22:15:49 +0800 (CST)
Subject: [R-SIG-Finance] MSSV model with R?
Message-ID: <15703918.340631262268949558.JavaMail.coremail@bj163app119.163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20091231/1ad41ea4/attachment.pl>

