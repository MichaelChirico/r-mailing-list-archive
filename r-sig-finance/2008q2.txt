From binabina at bellsouth.net  Tue Apr  1 17:06:37 2008
From: binabina at bellsouth.net (binabina at bellsouth.net)
Date: Tue, 01 Apr 2008 15:06:37 +0000
Subject: [R-SIG-Finance] real time data feeds - commercial services
Message-ID: <040120081506.10520.47F24F7D0009361C0000291822230650629B0A02D2089B9A019C04040A0DBF0E02070D0E02070D@att.net>

Hello, anyone can recommend a few (inexpensive) 3rd party services that provide real time data for the markets with a Java API or some type of webservice to fetch the data?  Stock, bond, currency, option, and technical type indicators.   Like to begin creating some workflows using R to implement some algorithmic traded ,but need real time data! 

thanks in advance 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080401/4e5dde80/attachment.html 

From ryan.sheftel at malbecpartners.com  Tue Apr  1 17:11:52 2008
From: ryan.sheftel at malbecpartners.com (Ryan Sheftel)
Date: Tue, 1 Apr 2008 11:11:52 -0400
Subject: [R-SIG-Finance] real time data feeds - commercial services
In-Reply-To: <040120081506.10520.47F24F7D0009361C0000291822230650629B0A02D2089B9A019C04040A0DBF0E02070D0E02070D@att.net>
Message-ID: <OFC0E0F6D4.7400BF18-ON8525741E.00534C44-8525741E.00537BFF@fftw.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080401/36a1f14e/attachment.pl 

From adrian_d at eskimo.com  Tue Apr  1 17:12:32 2008
From: adrian_d at eskimo.com (Adrian Dragulescu)
Date: Tue, 1 Apr 2008 08:12:32 -0700 (PDT)
Subject: [R-SIG-Finance] real time data feeds - commercial services
In-Reply-To: <040120081506.10520.47F24F7D0009361C0000291822230650629B0A02D2089B9A019C04040A0DBF0E02070D0E02070D@att.net>
References: <040120081506.10520.47F24F7D0009361C0000291822230650629B0A02D2089B9A019C04040A0DBF0E02070D0E02070D@att.net>
Message-ID: <Pine.SUN.4.58.0804010811140.3741@eskimo.com>


Check out www.interactivebrokers.com.  It will require you open an
account, but the service is free.  It has a Java API.

Adrian Dragulescu

On Tue, 1 Apr 2008 binabina at bellsouth.net wrote:

> Hello, anyone can recommend a few (inexpensive) 3rd party services that provide real time data for the markets with a Java API or some type of webservice to fetch the data?  Stock, bond, currency, option, and technical type indicators.   Like to begin creating some workflows using R to implement some algorithmic traded ,but need real time data!
>
> thanks in advance


From jeff.a.ryan at gmail.com  Tue Apr  1 17:21:27 2008
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 1 Apr 2008 10:21:27 -0500
Subject: [R-SIG-Finance] real time data feeds - commercial services
In-Reply-To: <040120081506.10520.47F24F7D0009361C0000291822230650629B0A02D2089B9A019C04040A0DBF0E02070D0E02070D@att.net>
References: <040120081506.10520.47F24F7D0009361C0000291822230650629B0A02D2089B9A019C04040A0DBF0E02070D0E02070D@att.net>
Message-ID: <e8e755250804010821k79b9e475ib1840eb9142aa78b@mail.gmail.com>

A good choice for RT data (mostly free with an account) integrated
into a trading platform is Interactive Brokers - they have supported
APIs for Excel, Java, and C# - in addition there are many _unofficial_
APIs implementing some or all of the functionality.

www.interactivebrokers.com

More info here:

http://www.chuckcaplan.com/twsapi/

There is an R API in the works called IBrokers that is being sorted
out.  Current plans are for only historic data integration into R.
You can look at the code here: http://code.google.com/p/ibrokers/  It
is not very reliable at present - my time commitment to it has been
sidetracked recently - but it is being actively pursued.

For full API integration Java or Python via IbPy (
http://code.google.com/p/ibpy/ )would be the way to go

You might also want to look at www.opentick.com for data.  A lot of it
is free, though some exchange fees apply.  The biggest caveat to
opentick (besides questionable data) is the user agreement... read
carefully.

Jeff



On Tue, Apr 1, 2008 at 10:06 AM,  <binabina at bellsouth.net> wrote:
>
>  Hello, anyone can recommend a few (inexpensive) 3rd party services that
> provide real time data for the markets with a Java API or some type of
> webservice to fetch the data?  Stock, bond, currency, option, and technical
> type indicators.   Like to begin creating some workflows using R to
> implement some algorithmic traded ,but need real time data!
>
> thanks in advance
>
> _______________________________________________
>  R-SIG-Finance at stat.math.ethz.ch mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>  -- Subscriber-posting only.
>  -- If you want to post, subscribe first.
>



-- 
There's a way to do it better - find it.
Thomas A. Edison


From binabina at bellsouth.net  Tue Apr  1 17:45:29 2008
From: binabina at bellsouth.net (binabina at bellsouth.net)
Date: Tue, 01 Apr 2008 15:45:29 +0000
Subject: [R-SIG-Finance] real time data feeds - commercial services
In-Reply-To: <e8e755250804010821k79b9e475ib1840eb9142aa78b@mail.gmail.com>
References: <040120081506.10520.47F24F7D0009361C0000291822230650629B0A02D2089B9A019C04040A0DBF0E02070D0E02070D@att.net>
	<e8e755250804010821k79b9e475ib1840eb9142aa78b@mail.gmail.com>
Message-ID: <040120081545.7885.47F258990009257E00001ECD22230680329B0A02D2089B9A019C04040A0DBF0E02070D0E02070D@att.net>


 thanks - this is perfect.! 
  -------------- Original message from "Jeff Ryan" <jeff.a.ryan at gmail.com>: --------------


> A good choice for RT data (mostly free with an account) integrated
> into a trading platform is Interactive Brokers - they have supported
> APIs for Excel, Java, and C# - in addition there are many _unofficial_
> APIs implementing some or all of the functionality.
> 
> www.interactivebrokers.com
> 
> More info here:
> 
> http://www.chuckcaplan.com/twsapi/
> 
> There is an R API in the works called IBrokers that is being sorted
> out.  Current plans are for only historic data integration into R.
> You can look at the code here: http://code.google.com/p/ibrokers/  It
> is not very reliable at present - my time commitment to it has been
> sidetracked recently - but it is being actively pursued.
> 
> For full API integration Java or Python via IbPy (
> http://code.google.com/p/ibpy/ )would be the way to go
> 
> You might also want to look at www.opentick.com for data.  A lot of it
> is free, though some exchange fees apply.  The biggest caveat to
> opentick (besides questionable data) is the user agreement... read
> carefully.
> 
> Jeff
> 
> 
> 
> On Tue, Apr 1, 2008 at 10:06 AM,   wrote:
> >
> >  Hello, anyone can recommend a few (inexpensive) 3rd party services that
> > provide real time data for the markets with a Java API or some type of
> > webservice to fetch the data?  Stock, bond, currency, option, and technical
> > type indicators.   Like to begin creating some workflows using R to
> > implement some algorithmic traded ,but need real time data!
> >
> > thanks in advance
> >
> > _______________________________________________
> >  R-SIG-Finance at stat.math.ethz.ch mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >  -- Subscriber-posting only.
> >  -- If you want to post, subscribe first.
> >
> 
> 
> 
> -- 
> There's a way to do it better - find it.
> Thomas A. Edison  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080401/67170ad7/attachment.html 

From comtech.usa at gmail.com  Wed Apr  2 08:49:54 2008
From: comtech.usa at gmail.com (Michael)
Date: Tue, 1 Apr 2008 22:49:54 -0800
Subject: [R-SIG-Finance] Bayesian estimation of jump-diffusion processes and
	self-exciting counting processes
Message-ID: <b1f16d9d0804012349w3918521fy1bbb8adfa184d7fa@mail.gmail.com>

Hi all,

Could anybody give me some pointers to estimation of jump-diffusion
and self-exciting processes(or more generally, counting processes with
stochastic intensity, such as doubly stochastic processes, Cox
processes, Hawkes processes) using the Bayesian approach, esp. using
MCMC and BUGS, or more generally, how to estimate a state-space model
that contains both diffusion processes and jump or self-exciting
processes using Bayesian MCMC and BUGS(both in continuous time and in
discrete time). I've seen demonstration in BUGS for simple state-space
models, with diffusion processes. But I am having a lot of difficulty
finding literature and programs for using BUGS for state-space models
involving self-exciting counting processes with stochastic
intensities. Please give me some pointers! Thank you very much!

-M


From jtl at saxobank.com  Wed Apr  2 10:08:18 2008
From: jtl at saxobank.com (Jeffrey Todd Lins)
Date: Wed, 2 Apr 2008 10:08:18 +0200
Subject: [R-SIG-Finance] Bayesian estimation of jump-diffusion processes
 andself-exciting counting processes
Message-ID: <2FB6B34D94EC154F8C2BF381B928882B05A55277@malmb2-s3.mid.dom>



Sincerely,

Jeffrey Todd Lins
Executive Director
Quantitative Analysis
Saxo Bank A/S

(Sent from my BlackBerry)

----- Original Message -----
From: r-sig-finance-bounces at stat.math.ethz.ch <r-sig-finance-bounces at stat.math.ethz.ch>
To: r-help <R-help at stat.math.ethz.ch>; r-sig-finance at stat.math.ethz.ch <r-sig-finance at stat.math.ethz.ch>
Sent: Wed Apr 02 06:49:54 2008
Subject: [R-SIG-Finance] Bayesian estimation of jump-diffusion processes andself-exciting counting processes

Hi all,

Could anybody give me some pointers to estimation of jump-diffusion
and self-exciting processes(or more generally, counting processes with
stochastic intensity, such as doubly stochastic processes, Cox
processes, Hawkes processes) using the Bayesian approach, esp. using
MCMC and BUGS, or more generally, how to estimate a state-space model
that contains both diffusion processes and jump or self-exciting
processes using Bayesian MCMC and BUGS(both in continuous time and in
discrete time). I've seen demonstration in BUGS for simple state-space
models, with diffusion processes. But I am having a lot of difficulty
finding literature and programs for using BUGS for state-space models
involving self-exciting counting processes with stochastic
intensities. Please give me some pointers! Thank you very much!

-M

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. 
-- If you want to post, subscribe first.

This email may contain confidential and/or privileged information.
If you are not the intended recipient (or have received this email 
by mistake), please notify the sender immediately and destroy this 
email. Any unauthorised copying, disclosure or distribution of the
material in this email is strictly prohibited.

Email transmission security and error-free status cannot be guaranteed
as information could be intercepted, corrupted, destroyed, delayed,
incomplete, or contain viruses. The sender therefore does not accept
liability for any errors or omissions in the contents of this message 
which may arise as a result of email transmission.


From UriShimron at optiver.com  Wed Apr  2 13:31:34 2008
From: UriShimron at optiver.com (Uri Shimron)
Date: Wed, 2 Apr 2008 13:31:34 +0200
Subject: [R-SIG-Finance] R + NVIDIA CUDA
In-Reply-To: <C20EA84D76C94F4E999DC041E81C0D11058BD5DA@exchange2k3.ny.gghc.com>
Message-ID: <061264DF11708C44BAF02C0F3F4EA28F01D87543@opamms0002.comp.optiver.com>

All I know about R and GPUs is that there was a poster (which I haven't
seen) about it by Glaser et. al at User!2007
(http://user2007.org/program/). I've tried contacting Daniel Adler
through http://rgl.neoscientists.org/ but no luck so far. Sorry I can't
be more helpful, but please share your results with the list!

Uri
-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Joshua
Reich
Sent: Monday 31 March 2008 20:50
To: R-SIG-Finance
Subject: [R-SIG-Finance] R + NVIDIA CUDA

>From browsing the NVIDIA CUDA forum
(http://www.nvidia.com/object/cuda_home.html) it seems that quite a few
people are working on Monte Carlo option pricing libraries using GPU
technology for impressive speed-ups. Does anyone here know of any
attempts to use NVIDIA's BLAS library with R?

Thanks,

Josh Reich

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. 
-- If you want to post, subscribe first.

***************************************************************************
This email and any files transmitted with it are confide...{{dropped:11}}


From maechler at stat.math.ethz.ch  Wed Apr  2 13:56:01 2008
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 2 Apr 2008 13:56:01 +0200
Subject: [R-SIG-Finance] R + NVIDIA CUDA
In-Reply-To: <061264DF11708C44BAF02C0F3F4EA28F01D87543@opamms0002.comp.optiver.com>
References: <C20EA84D76C94F4E999DC041E81C0D11058BD5DA@exchange2k3.ny.gghc.com>
	<061264DF11708C44BAF02C0F3F4EA28F01D87543@opamms0002.comp.optiver.com>
Message-ID: <18419.29777.861376.802961@stat.math.ethz.ch>

>>>>> "US" == Uri Shimron <UriShimron at optiver.com>
>>>>>     on Wed, 2 Apr 2008 13:31:34 +0200 writes:

    US> All I know about R and GPUs is that there was a poster (which I haven't
    US> seen) about it by Glaser et. al at User!2007
    US> (http://user2007.org/program/). I've tried contacting Daniel Adler
    US> through http://rgl.neoscientists.org/ but no luck so far. Sorry I can't
    US> be more helpful, but please share your results with the list!

but "the list" for such a topic should really be  
"R-devel" rather than "R-SIG-Finance" ...

Martin

    US> Uri
    US> -----Original Message-----
    US> From: r-sig-finance-bounces at stat.math.ethz.ch
    US> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Joshua
    US> Reich
    US> Sent: Monday 31 March 2008 20:50
    US> To: R-SIG-Finance
    US> Subject: [R-SIG-Finance] R + NVIDIA CUDA

    >> From browsing the NVIDIA CUDA forum
    US> (http://www.nvidia.com/object/cuda_home.html) it seems that quite a few
    US> people are working on Monte Carlo option pricing libraries using GPU
    US> technology for impressive speed-ups. Does anyone here know of any
    US> attempts to use NVIDIA's BLAS library with R?

    US> Thanks,
    US> Josh Reich


From elise at predictionimpact.com  Fri Apr  4 11:36:33 2008
From: elise at predictionimpact.com (Elise Johnson)
Date: Fri, 4 Apr 2008 02:36:33 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Predictive Analytics for Business,
 Marketing and Web (May 8-9 and June 5-6)
Message-ID: <16490210.post@talk.nabble.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080404/27a9fe87/attachment.pl 

From yuri.volchik at gmail.com  Sun Apr  6 19:38:59 2008
From: yuri.volchik at gmail.com (Yuri Volchik)
Date: Sun, 6 Apr 2008 10:38:59 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] http://www.market-topology.com/
In-Reply-To: <47EC04EC.8060505@earthlink.net>
References: <15786834.post@talk.nabble.com> <47CAE8C3.90306@pdf.com>
	<16332263.post@talk.nabble.com> <47EC04EC.8060505@earthlink.net>
Message-ID: <16527497.post@talk.nabble.com>


I managed to create something similar to subj by using igraph package:

adjMat<-(1-abs(cov.rob(dMat,cor=TRUE)$cor))^2
g2 <- graph.adjacency(adjMat,mode='plus',weighted=T, diag=F)
V(g2)$name<-Names
V(g2)$label<-Names
mst <- minimum.spanning.tree(g2)
plot(mst,layout=layout.fruchterman.reingold,  vertex.color="grey", 
vertex.size=20)


So far i'm quite happy with results i got (for small datasets), seem to
align pretty well with a priori assumptions.
I'm also wondering about what Spencer said about full rank correlation
matrix, if there is another suitable metric to use for computing distances
instead of correlation matrix?

Thanks



-- 
View this message in context: http://www.nabble.com/http%3A--www.market-topology.com--tp15786834p16527497.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From ihernan at stat.Berkeley.EDU  Sun Apr  6 23:19:34 2008
From: ihernan at stat.Berkeley.EDU (ihernan at stat.Berkeley.EDU)
Date: Sun, 6 Apr 2008 14:19:34 -0700 (PDT)
Subject: [R-SIG-Finance] Seasonal GARCH
Message-ID: <2897.75.35.76.169.1207516774.squirrel@www.stat.berkeley.edu>

I am trying to use the library(fGarch) and fit a GARCH model but I am
interested in fitting a ARCH for the volatility.
If I use ~GARCH(5,0) then 5 autoregressive parameters are fitted but I am
just interested in the a_{t-5}^2 parameter. Is there any way I could
obtain this model using the function library(fGarch).

Thank you Irma


From spencer.graves at pdf.com  Mon Apr  7 03:38:58 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 06 Apr 2008 18:38:58 -0700
Subject: [R-SIG-Finance] Seasonal GARCH
In-Reply-To: <2897.75.35.76.169.1207516774.squirrel@www.stat.berkeley.edu>
References: <2897.75.35.76.169.1207516774.squirrel@www.stat.berkeley.edu>
Message-ID: <47F97B32.6000903@pdf.com>

      The last I checked, garchFit could not estimate a model with zero 
for either of the garch lag parameters. 

      The expert on current and planned garchFit capabilities is Yohan 
Chalabi, and I've copied him on this reply.  Unless you hear otherwise 
from him, I think it is best to assume that you can fit any garch(i, j) 
model you want as long as both i and j are strictly positive. 

      I'm sorry I couldn't be more helpful. 
      Spencer

ihernan at stat.berkeley.edu wrote:
> I am trying to use the library(fGarch) and fit a GARCH model but I am
> interested in fitting a ARCH for the volatility.
> If I use ~GARCH(5,0) then 5 autoregressive parameters are fitted but I am
> just interested in the a_{t-5}^2 parameter. Is there any way I could
> obtain this model using the function library(fGarch).
>
> Thank you Irma
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. 
> -- If you want to post, subscribe first.
>


From markleeds at verizon.net  Mon Apr  7 03:49:40 2008
From: markleeds at verizon.net (markleeds at verizon.net)
Date: Sun, 06 Apr 2008 20:49:40 -0500 (CDT)
Subject: [R-SIG-Finance] Seasonal GARCH
Message-ID: <8078573.1836281207532980812.JavaMail.root@vms069.mailsrvcs.net>

>From: Spencer Graves <spencer.graves at pdf.com>
>Date: 2008/04/06 Sun PM 08:38:58 CDT
>To: ihernan at stat.berkeley.edu
>Cc: r-sig-finance at stat.math.ethz.ch
>Subject: Re: [R-SIG-Finance] Seasonal GARCH

I've never used garchFit but one other possibility
is to use the fact that an ARCH model of the volatility
is the same as an AR whatever on sigma squared
, with some subtle, slight differences that I can't
recall. So, using that relation, you may be
able to use an AR ( so one of the arima functions ) 
but be careful because it doesn't imply EXACTLY 
the same model but it's close. 

I forget which text talks about the close but no cigar relation but my guess is that it's in Hamilton's or Zivot's text.





>      The last I checked, garchFit could not estimate a model with zero 
>for either of the garch lag parameters. 
>
>      The expert on current and planned garchFit capabilities is Yohan 
>Chalabi, and I've copied him on this reply.  Unless you hear otherwise 
>from him, I think it is best to assume that you can fit any garch(i, j) 
>model you want as long as both i and j are strictly positive. 
>
>      I'm sorry I couldn't be more helpful. 
>      Spencer
>
>ihernan at stat.berkeley.edu wrote:
>> I am trying to use the library(fGarch) and fit a GARCH model but I am
>> interested in fitting a ARCH for the volatility.
>> If I use ~GARCH(5,0) then 5 autoregressive parameters are fitted but I am
>> just interested in the a_{t-5}^2 parameter. Is there any way I could
>> obtain this model using the function library(fGarch).
>>
>> Thank you Irma
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. 
>> -- If you want to post, subscribe first.
>>
>
>_______________________________________________
>R-SIG-Finance at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>-- Subscriber-posting only. 
>-- If you want to post, subscribe first.


From ggrothendieck at gmail.com  Mon Apr  7 04:00:01 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 6 Apr 2008 22:00:01 -0400
Subject: [R-SIG-Finance] Seasonal GARCH
In-Reply-To: <8078573.1836281207532980812.JavaMail.root@vms069.mailsrvcs.net>
References: <8078573.1836281207532980812.JavaMail.root@vms069.mailsrvcs.net>
Message-ID: <971536df0804061900y5ba5d990h3eaaef0b7dce28d2@mail.gmail.com>

On Sun, Apr 6, 2008 at 9:49 PM,  <markleeds at verizon.net> wrote:
> >From: Spencer Graves <spencer.graves at pdf.com>
> >Date: 2008/04/06 Sun PM 08:38:58 CDT
> >To: ihernan at stat.berkeley.edu
> >Cc: r-sig-finance at stat.math.ethz.ch
> >Subject: Re: [R-SIG-Finance] Seasonal GARCH
>
> I've never used garchFit but one other possibility
> is to use the fact that an ARCH model of the volatility
> is the same as an AR whatever on sigma squared
> , with some subtle, slight differences that I can't
> recall. So, using that relation, you may be
> able to use an AR ( so one of the arima functions )
> but be careful because it doesn't imply EXACTLY
> the same model but it's close.
>
> I forget which text talks about the close but no cigar relation but my guess is that it's in Hamilton's or Zivot's text.
>

Its mentioned in Lutkepohl's book, New Intro to
Multiple Time Series Analysis.


From spencer.graves at pdf.com  Mon Apr  7 04:08:12 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 06 Apr 2008 19:08:12 -0700
Subject: [R-SIG-Finance] Seasonal GARCH
In-Reply-To: <47F97B32.6000903@pdf.com>
References: <2897.75.35.76.169.1207516774.squirrel@www.stat.berkeley.edu>
	<47F97B32.6000903@pdf.com>
Message-ID: <47F9820C.9000804@pdf.com>

      The 'garch' function in the 'tseries' package can estimate a 
garch(0, 5) or garch(5, 0) model. 

      Hope this helps. 
      Spencer

Spencer Graves wrote:
>       The last I checked, garchFit could not estimate a model with zero 
> for either of the garch lag parameters. 
>
>       The expert on current and planned garchFit capabilities is Yohan 
> Chalabi, and I've copied him on this reply.  Unless you hear otherwise 
> from him, I think it is best to assume that you can fit any garch(i, j) 
> model you want as long as both i and j are strictly positive. 
>
>       I'm sorry I couldn't be more helpful. 
>       Spencer
>
> ihernan at stat.berkeley.edu wrote:
>   
>> I am trying to use the library(fGarch) and fit a GARCH model but I am
>> interested in fitting a ARCH for the volatility.
>> If I use ~GARCH(5,0) then 5 autoregressive parameters are fitted but I am
>> just interested in the a_{t-5}^2 parameter. Is there any way I could
>> obtain this model using the function library(fGarch).
>>
>> Thank you Irma
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. 
>> -- If you want to post, subscribe first.
>>
>>     
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. 
> -- If you want to post, subscribe first.
>


From ezivot at u.washington.edu  Mon Apr  7 05:42:20 2008
From: ezivot at u.washington.edu (Eric Zivot)
Date: Sun, 6 Apr 2008 20:42:20 -0700 (PDT)
Subject: [R-SIG-Finance] Seasonal GARCH
In-Reply-To: <47F9820C.9000804@pdf.com>
Message-ID: <Pine.LNX.4.43.0804062042200.11100@hymn11.u.washington.edu>

You must be careful here. A garch(0,5) model is not identified. If all of the ARCH coefficients are zero then the model is not a conditional heteroskedastic model. Volatility is constant in this case.

****************************************************************
*  Eric Zivot                  			               *
*  Professor and Gary Waterman Distinguished Scholar           *
*  Department of Economics                                     *
*  Box 353330                  email:  ezivot at u.washington.edu *
*  University of Washington    phone:  206-543-6715            *
*  Seattle, WA 98195-3330                                      *                                                           *
*  www:  http://faculty.washington.edu/ezivot                  *
****************************************************************

On Sun, 6 Apr 2008, Spencer Graves wrote:

>      The 'garch' function in the 'tseries' package can estimate a
> garch(0, 5) or garch(5, 0) model.
>
>      Hope this helps.
>      Spencer
>
> Spencer Graves wrote:
>>       The last I checked, garchFit could not estimate a model with zero
>> for either of the garch lag parameters.
>>
>>       The expert on current and planned garchFit capabilities is Yohan
>> Chalabi, and I've copied him on this reply.  Unless you hear otherwise
>> from him, I think it is best to assume that you can fit any garch(i, j)
>> model you want as long as both i and j are strictly positive.
>>
>>       I'm sorry I couldn't be more helpful.
>>       Spencer
>>
>> ihernan at stat.berkeley.edu wrote:
>>
>>> I am trying to use the library(fGarch) and fit a GARCH model but I am
>>> interested in fitting a ARCH for the volatility.
>>> If I use ~GARCH(5,0) then 5 autoregressive parameters are fitted but I am
>>> just interested in the a_{t-5}^2 parameter. Is there any way I could
>>> obtain this model using the function library(fGarch).
>>>
>>> Thank you Irma
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
>>>
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From anass.mouhsine at sgcib.com  Mon Apr  7 13:26:34 2008
From: anass.mouhsine at sgcib.com (anass.mouhsine at sgcib.com)
Date: Mon, 7 Apr 2008 13:26:34 +0200
Subject: [R-SIG-Finance] [R-sig-finance] endpoints function in package xts
	[C1]
Message-ID: <OF8B7C3A2C.9766DF92-ONC1257424.003E06CB-C1257424.003EDB4A@fr.world.socgen>


Hi All,

I have an issue with endpoints in package xts.
Assume that I have a timeSeries of a tick by tick price and that I want to
get an hourly sum aggregation

> ep<-endpoints(temp,'hours',1)
>ans<-xts:::period.sum(temp[,1],ep)

this should do, but the problem is that in my set of data, I don't have any
data between 12h55 and 15h26.
so when it returns ans , ans equals:

2008-03-10 09:59:49 2004.37
2008-03-10 10:59:30 1441.56
2008-03-10 11:54:50 1445.40
2008-03-10 12:55:25  684.18
2008-03-10 15:50:41 1069.28
2008-03-10 16:56:49 3008.19
2008-03-10 17:30:00 1101.17

but I want something like

2008-03-10 09:59:49 2004.37
2008-03-10 10:59:30 1441.56
2008-03-10 11:54:50 1445.40
2008-03-10 12:55:25  684.18
2008-03-10 14:00:00 0
2008-03-10 15:00:00 0
2008-03-10 15:50:41 1069.28
2008-03-10 16:56:49 3008.19
2008-03-10 17:30:00 1101.17

Do you have any idea on how to perform this task?

Thanks in davance.

Anass

P.S: you will find below the timeSeries temp.

> temp
                                   V6
2008-03-10 09:00:00  0.00
2008-03-10 09:00:01 25.65
2008-03-10 09:00:01 25.65
2008-03-10 09:00:05 25.65
2008-03-10 09:03:03 25.65
2008-03-10 09:16:06 25.65
2008-03-10 09:16:18 25.65
2008-03-10 09:16:29 25.65
2008-03-10 09:16:29 25.65
2008-03-10 09:27:43 25.65
2008-03-10 09:27:43 25.65
2008-03-10 09:28:44 25.65
2008-03-10 09:28:44 25.65
2008-03-10 09:29:39 25.65
2008-03-10 09:29:39 25.65
2008-03-10 09:30:44 25.65
2008-03-10 09:36:36 25.65
2008-03-10 09:38:37 25.65
2008-03-10 09:38:37 25.65
2008-03-10 09:40:36 25.65
2008-03-10 09:44:47 25.50
2008-03-10 09:44:47 25.28
2008-03-10 09:44:47 25.28
2008-03-10 09:44:47 25.28
2008-03-10 09:44:47 25.28
2008-03-10 09:44:47 25.28
2008-03-10 09:44:48 25.28
2008-03-10 09:44:48 25.28
2008-03-10 09:44:48 25.28
2008-03-10 09:44:48 25.28
2008-03-10 09:44:48 25.28
2008-03-10 09:44:53 25.28
2008-03-10 09:45:44 25.28
2008-03-10 09:47:05 25.28
2008-03-10 09:47:05 25.28
2008-03-10 09:47:05 25.28
2008-03-10 09:47:52 25.28
2008-03-10 09:47:52 25.28
2008-03-10 09:50:44 25.28
2008-03-10 09:50:45 25.28
2008-03-10 09:50:45 25.28
2008-03-10 09:50:45 25.28
2008-03-10 09:51:42 25.28
2008-03-10 09:51:43 25.28
2008-03-10 09:51:43 25.28
2008-03-10 09:51:43 25.28
2008-03-10 09:51:43 25.28
2008-03-10 09:51:43 25.28
2008-03-10 09:51:44 25.28
2008-03-10 09:51:44 25.28
2008-03-10 09:51:44 25.28
2008-03-10 09:52:42 25.28
2008-03-10 09:52:42 25.28
2008-03-10 09:52:43 25.28
2008-03-10 09:52:43 25.28
2008-03-10 09:52:43 25.28
2008-03-10 09:52:43 25.28
2008-03-10 09:53:40 25.28
2008-03-10 09:53:40 25.28
2008-03-10 09:53:41 25.28
2008-03-10 09:53:41 25.28
2008-03-10 09:54:24 25.28
2008-03-10 09:54:24 25.28
2008-03-10 09:54:43 25.28
2008-03-10 09:54:43 25.28
2008-03-10 09:54:44 25.28
2008-03-10 09:54:44 25.28
2008-03-10 09:54:44 25.28
2008-03-10 09:54:44 25.28
2008-03-10 09:54:44 25.28
2008-03-10 09:54:44 25.28
2008-03-10 09:55:47 25.28
2008-03-10 09:55:47 25.28
2008-03-10 09:55:48 25.28
2008-03-10 09:55:48 25.28
2008-03-10 09:55:48 25.28
2008-03-10 09:59:04 25.28
2008-03-10 09:59:05 25.28
2008-03-10 09:59:49 25.28
2008-03-10 09:59:49 25.28
2008-03-10 10:00:45 25.28
2008-03-10 10:01:39 25.28
2008-03-10 10:01:39 25.28
2008-03-10 10:03:32 25.28
2008-03-10 10:05:31 25.28
2008-03-10 10:05:31 25.28
2008-03-10 10:07:32 25.28
2008-03-10 10:07:32 25.28
2008-03-10 10:07:32 25.28
2008-03-10 10:07:32 25.28
2008-03-10 10:07:32 25.28
2008-03-10 10:07:32 25.28
2008-03-10 10:08:34 25.28
2008-03-10 10:08:34 25.28
2008-03-10 10:08:34 25.28
2008-03-10 10:08:34 25.28
2008-03-10 10:09:30 25.28
2008-03-10 10:09:30 25.28
2008-03-10 10:10:25 25.28
2008-03-10 10:10:25 25.28
2008-03-10 10:11:25 25.28
2008-03-10 10:11:25 25.28
2008-03-10 10:12:24 25.28
2008-03-10 10:13:26 25.28
2008-03-10 10:14:31 25.28
2008-03-10 10:14:31 25.28
2008-03-10 10:15:35 25.28
2008-03-10 10:15:35 25.28
2008-03-10 10:16:38 25.28
2008-03-10 10:16:38 25.28
2008-03-10 10:16:53 25.28
2008-03-10 10:19:53 25.28
2008-03-10 10:19:54 25.28
2008-03-10 10:20:12 25.28
2008-03-10 10:20:48 25.28
2008-03-10 10:20:48 25.28
2008-03-10 10:24:52 25.28
2008-03-10 10:24:53 25.28
2008-03-10 10:24:53 25.28
2008-03-10 10:30:39 25.28
2008-03-10 10:30:39 25.28
2008-03-10 10:30:40 25.28
2008-03-10 10:47:27 25.32
2008-03-10 10:47:27 25.32
2008-03-10 10:47:28 25.32
2008-03-10 10:47:28 25.32
2008-03-10 10:47:29 25.32
2008-03-10 10:52:55 25.32
2008-03-10 10:55:51 25.32
2008-03-10 10:55:51 25.32
2008-03-10 10:55:51 25.32
2008-03-10 10:55:51 25.32
2008-03-10 10:55:51 25.32
2008-03-10 10:55:51 25.32
2008-03-10 10:59:29 25.32
2008-03-10 10:59:30 25.32
2008-03-10 10:59:30 25.32
2008-03-10 11:01:45 25.51
2008-03-10 11:01:45 25.51
2008-03-10 11:01:46 25.51
2008-03-10 11:01:46 25.51
2008-03-10 11:01:46 25.51
2008-03-10 11:13:50 25.51
2008-03-10 11:15:18 25.34
2008-03-10 11:15:18 25.34
2008-03-10 11:15:19 25.34
2008-03-10 11:15:19 25.34
2008-03-10 11:15:19 25.34
2008-03-10 11:22:53 25.34
2008-03-10 11:24:09 25.34
2008-03-10 11:32:15 25.34
2008-03-10 11:39:42 25.34
2008-03-10 11:39:55 25.34
2008-03-10 11:39:56 25.34
2008-03-10 11:39:56 25.34
2008-03-10 11:39:56 25.34
2008-03-10 11:39:56 25.34
2008-03-10 11:39:56 25.34
2008-03-10 11:40:56 25.34
2008-03-10 11:40:56 25.34
2008-03-10 11:40:57 25.34
2008-03-10 11:40:57 25.34
2008-03-10 11:40:57 25.34
2008-03-10 11:40:57 25.34
2008-03-10 11:43:22 25.34
2008-03-10 11:43:23 25.34
2008-03-10 11:43:59 25.34
2008-03-10 11:43:59 25.34
2008-03-10 11:47:54 25.34
2008-03-10 11:47:54 25.34
2008-03-10 11:48:51 25.34
2008-03-10 11:48:51 25.34
2008-03-10 11:49:46 25.34
2008-03-10 11:49:46 25.34
2008-03-10 11:50:17 25.34
2008-03-10 11:50:18 25.34
2008-03-10 11:50:18 25.34
2008-03-10 11:50:18 25.34
2008-03-10 11:50:19 25.34
2008-03-10 11:50:19 25.34
2008-03-10 11:50:48 25.34
2008-03-10 11:50:48 25.34
2008-03-10 11:51:49 25.34
2008-03-10 11:51:49 25.34
2008-03-10 11:52:20 25.34
2008-03-10 11:52:20 25.34
2008-03-10 11:52:49 25.34
2008-03-10 11:54:28 25.34
2008-03-10 11:54:28 25.34
2008-03-10 11:54:28 25.34
2008-03-10 11:54:28 25.34
2008-03-10 11:54:28 25.34
2008-03-10 11:54:28 25.34
2008-03-10 11:54:50 25.34
2008-03-10 12:31:29 25.34
2008-03-10 12:31:34 25.34
2008-03-10 12:31:35 25.34
2008-03-10 12:31:35 25.34
2008-03-10 12:31:35 25.34
2008-03-10 12:31:42 25.34
2008-03-10 12:31:42 25.34
2008-03-10 12:31:46 25.34
2008-03-10 12:31:47 25.34
2008-03-10 12:31:47 25.34
2008-03-10 12:31:47 25.34
2008-03-10 12:31:47 25.34
2008-03-10 12:31:52 25.34
2008-03-10 12:31:56 25.34
2008-03-10 12:31:57 25.34
2008-03-10 12:31:57 25.34
2008-03-10 12:31:57 25.34
2008-03-10 12:31:57 25.34
2008-03-10 12:31:58 25.34
2008-03-10 12:42:21 25.34
2008-03-10 12:55:24 25.34
2008-03-10 12:55:24 25.34
2008-03-10 12:55:25 25.34
2008-03-10 12:55:25 25.34
2008-03-10 12:55:25 25.34
2008-03-10 12:55:25 25.34
2008-03-10 12:55:25 25.34
2008-03-10 15:26:24 25.68
2008-03-10 15:26:24 25.68
2008-03-10 15:26:24 25.68
2008-03-10 15:26:24 25.68
2008-03-10 15:26:24 25.68
2008-03-10 15:26:25 25.68
2008-03-10 15:26:25 25.68
2008-03-10 15:31:24 25.68
2008-03-10 15:31:24 25.68
2008-03-10 15:46:56 25.68
2008-03-10 15:46:56 25.68
2008-03-10 15:46:56 25.68
2008-03-10 15:47:02 25.68
2008-03-10 15:48:12 25.42
2008-03-10 15:48:12 25.42
2008-03-10 15:48:13 25.42
2008-03-10 15:48:13 25.42
2008-03-10 15:48:13 25.42
2008-03-10 15:49:06 25.42
2008-03-10 15:49:06 25.42
2008-03-10 15:49:06 25.35
2008-03-10 15:49:06 25.35
2008-03-10 15:49:06 25.34
2008-03-10 15:49:06 25.34
2008-03-10 15:49:06 25.34
2008-03-10 15:49:06 25.34
2008-03-10 15:49:06 25.34
2008-03-10 15:49:06 25.34
2008-03-10 15:49:06 25.34
2008-03-10 15:49:17 25.34
2008-03-10 15:49:45 25.34
2008-03-10 15:49:45 25.34
2008-03-10 15:49:45 25.34
2008-03-10 15:49:45 25.34
2008-03-10 15:49:45 25.34
2008-03-10 15:49:45 25.34
2008-03-10 15:50:40 25.34
2008-03-10 15:50:40 25.34
2008-03-10 15:50:40 25.34
2008-03-10 15:50:40 25.34
2008-03-10 15:50:40 25.34
2008-03-10 15:50:41 25.34
2008-03-10 16:02:12 25.35
2008-03-10 16:02:12 25.35
2008-03-10 16:02:12 25.35
2008-03-10 16:02:13 25.35
2008-03-10 16:14:02 25.35
2008-03-10 16:14:02 25.35
2008-03-10 16:14:13 25.35
2008-03-10 16:14:16 25.34
2008-03-10 16:14:16 25.30
2008-03-10 16:14:16 25.30
2008-03-10 16:14:17 25.30
2008-03-10 16:14:17 25.30
2008-03-10 16:14:17 25.30
2008-03-10 16:14:17 25.30
2008-03-10 16:14:18 25.30
2008-03-10 16:14:18 25.30
2008-03-10 16:14:18 25.30
2008-03-10 16:14:20 25.30
2008-03-10 16:14:33 25.30
2008-03-10 16:14:33 25.30
2008-03-10 16:14:34 25.30
2008-03-10 16:14:34 25.30
2008-03-10 16:14:34 25.30
2008-03-10 16:14:34 25.30
2008-03-10 16:14:45 25.30
2008-03-10 16:15:15 25.30
2008-03-10 16:15:37 25.30
2008-03-10 16:15:37 25.30
2008-03-10 16:15:38 25.30
2008-03-10 16:15:38 25.30
2008-03-10 16:15:38 25.30
2008-03-10 16:15:38 25.30
2008-03-10 16:16:37 25.30
2008-03-10 16:16:37 25.30
2008-03-10 16:16:38 25.30
2008-03-10 16:16:38 25.30
2008-03-10 16:16:38 25.30
2008-03-10 16:16:38 25.30
2008-03-10 16:22:46 25.35
2008-03-10 16:22:46 25.35
2008-03-10 16:22:46 25.35
2008-03-10 16:22:47 25.35
2008-03-10 16:22:47 25.35
2008-03-10 16:22:47 25.35
2008-03-10 16:22:47 25.35
2008-03-10 16:22:47 25.35
2008-03-10 16:22:48 25.35
2008-03-10 16:23:46 25.35
2008-03-10 16:23:46 25.35
2008-03-10 16:23:47 25.35
2008-03-10 16:23:47 25.35
2008-03-10 16:23:47 25.35
2008-03-10 16:23:47 25.35
2008-03-10 16:24:43 25.35
2008-03-10 16:24:43 25.35
2008-03-10 16:24:44 25.35
2008-03-10 16:24:44 25.35
2008-03-10 16:24:44 25.35
2008-03-10 16:24:44 25.35
2008-03-10 16:25:07 25.35
2008-03-10 16:25:07 25.35
2008-03-10 16:25:41 25.35
2008-03-10 16:25:42 25.35
2008-03-10 16:25:42 25.35
2008-03-10 16:25:42 25.35
2008-03-10 16:25:42 25.35
2008-03-10 16:25:42 25.35
2008-03-10 16:25:42 25.35
2008-03-10 16:25:42 25.35
2008-03-10 16:25:43 25.35
2008-03-10 16:26:38 25.35
2008-03-10 16:26:38 25.35
2008-03-10 16:26:39 25.35
2008-03-10 16:32:49 25.35
2008-03-10 16:34:38 25.35
2008-03-10 16:35:09 25.35
2008-03-10 16:35:10 25.35
2008-03-10 16:35:10 25.35
2008-03-10 16:35:29 25.20
2008-03-10 16:35:29 25.20
2008-03-10 16:35:30 25.20
2008-03-10 16:35:30 25.20
2008-03-10 16:35:33 25.20
2008-03-10 16:35:33 25.20
2008-03-10 16:35:33 25.20
2008-03-10 16:35:34 25.20
2008-03-10 16:36:12 25.20
2008-03-10 16:36:12 25.20
2008-03-10 16:40:28 25.20
2008-03-10 16:43:42 25.20
2008-03-10 16:43:43 25.20
2008-03-10 16:44:24 25.20
2008-03-10 16:44:25 25.20
2008-03-10 16:44:25 25.20
2008-03-10 16:44:25 25.20
2008-03-10 16:50:31 25.20
2008-03-10 16:50:31 25.20
2008-03-10 16:51:31 25.20
2008-03-10 16:51:31 25.20
2008-03-10 16:52:29 25.20
2008-03-10 16:52:29 25.20
2008-03-10 16:53:00 25.20
2008-03-10 16:53:00 25.20
2008-03-10 16:53:23 25.20
2008-03-10 16:53:23 25.20
2008-03-10 16:54:27 25.20
2008-03-10 16:54:56 25.20
2008-03-10 16:55:30 25.20
2008-03-10 16:55:31 25.20
2008-03-10 16:55:31 25.20
2008-03-10 16:56:27 25.20
2008-03-10 16:56:27 25.10
2008-03-10 16:56:27 25.10
2008-03-10 16:56:28 25.10
2008-03-10 16:56:28 25.10
2008-03-10 16:56:28 25.10
2008-03-10 16:56:33 25.10
2008-03-10 16:56:43 25.10
2008-03-10 16:56:49 25.10
2008-03-10 17:02:16 25.10
2008-03-10 17:02:19 25.10
2008-03-10 17:03:56 25.10
2008-03-10 17:03:57 25.10
2008-03-10 17:05:59 25.06
2008-03-10 17:05:59 25.06
2008-03-10 17:06:00 25.06
2008-03-10 17:06:00 25.06
2008-03-10 17:06:00 25.06
2008-03-10 17:06:01 25.06
2008-03-10 17:06:12 25.05
2008-03-10 17:06:12 25.05
2008-03-10 17:06:12 25.05
2008-03-10 17:06:13 25.05
2008-03-10 17:06:13 25.05
2008-03-10 17:07:03 25.05
2008-03-10 17:07:16 25.05
2008-03-10 17:08:02 25.05
2008-03-10 17:08:02 25.01
2008-03-10 17:08:02 25.00
2008-03-10 17:08:02 25.00
2008-03-10 17:08:02 25.00
2008-03-10 17:08:02 25.00
2008-03-10 17:08:02 25.00
2008-03-10 17:08:02 25.00
2008-03-10 17:08:03 25.00
2008-03-10 17:08:03 25.00
2008-03-10 17:08:03 25.00
2008-03-10 17:08:10 25.00
2008-03-10 17:08:35 25.00
2008-03-10 17:08:43 25.00
2008-03-10 17:08:47 25.00
2008-03-10 17:24:18 25.00
2008-03-10 17:24:19 25.00
2008-03-10 17:24:19 25.00
2008-03-10 17:24:19 25.00
2008-03-10 17:24:19 25.00
2008-03-10 17:24:19 25.00
2008-03-10 17:24:20 25.00
2008-03-10 17:24:20 25.00
2008-03-10 17:29:05 25.00
2008-03-10 17:29:31 25.00
2008-03-10 17:29:31 25.00
2008-03-10 17:30:00 25.00



*************************************************************************
This message and any attachments (the "message") are con...{{dropped:10}}


From jeff.a.ryan at gmail.com  Mon Apr  7 15:16:28 2008
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 7 Apr 2008 08:16:28 -0500
Subject: [R-SIG-Finance] [R-sig-finance] endpoints function in package
	xts [C1]
In-Reply-To: <OF8B7C3A2C.9766DF92-ONC1257424.003E06CB-C1257424.003EDB4A@fr.world.socgen>
References: <OF8B7C3A2C.9766DF92-ONC1257424.003E06CB-C1257424.003EDB4A@fr.world.socgen>
Message-ID: <e8e755250804070616x6e5eedben5cf0873a2dedafdb@mail.gmail.com>

Hi Anass,

The question I have is -- what is the basis for the time stamps at 14
and 15, yet not at 13?  The problem from the endpoints function
perspective is just that - what would be the logic needed to get your
timestamps?  Would you like stamps that reflect the last obs. in the
time period (which is what endpoints does), or would you like
timestamps at the end/beginning of each hour from the start of the
series to the end?  Additionally the endpoints will pick the last
point within the hour - so 14:00 would be considered the _beginning_
of the 14th hour, 14:59:59 would be the end.

If you just want time stamps from each hour if not represented
already, that would certainly be doable - though not automatically at
present.  Possibly an addition to xts in the near future??

There are two soon to be exported functions from xts: lastof and
firstof, which essentially calculate the last_of an hour (or any
period), that may be of use:


> xts:::lastof(2008,3,10,14)
[1] "2008-03-10 14:59:59 GMT"

> xts:::firstof(2008,3,10,14)
[1] "2008-03-10 14:00:00 GMT"


You may be able to merge a series of all your required time stamps
with the series in question and get something approximately near what
you are seeking - but you'll most likely have to have stamps at each
hour, not just arbitrary ones.

Jeff

On Mon, Apr 7, 2008 at 6:26 AM,  <anass.mouhsine at sgcib.com> wrote:
>
>  Hi All,
>
>  I have an issue with endpoints in package xts.
>  Assume that I have a timeSeries of a tick by tick price and that I want to
>  get an hourly sum aggregation
>
>  > ep<-endpoints(temp,'hours',1)
>  >ans<-xts:::period.sum(temp[,1],ep)
>
>  this should do, but the problem is that in my set of data, I don't have any
>  data between 12h55 and 15h26.
>  so when it returns ans , ans equals:
>
>  2008-03-10 09:59:49 2004.37
>  2008-03-10 10:59:30 1441.56
>  2008-03-10 11:54:50 1445.40
>  2008-03-10 12:55:25  684.18
>  2008-03-10 15:50:41 1069.28
>  2008-03-10 16:56:49 3008.19
>  2008-03-10 17:30:00 1101.17
>
>  but I want something like
>
>  2008-03-10 09:59:49 2004.37
>  2008-03-10 10:59:30 1441.56
>  2008-03-10 11:54:50 1445.40
>  2008-03-10 12:55:25  684.18
>  2008-03-10 14:00:00 0
>  2008-03-10 15:00:00 0
>  2008-03-10 15:50:41 1069.28
>  2008-03-10 16:56:49 3008.19
>  2008-03-10 17:30:00 1101.17
>
>  Do you have any idea on how to perform this task?
>
>  Thanks in davance.
>
>  Anass
>
>  P.S: you will find below the timeSeries temp.
>
>  > temp
>                                    V6
>  2008-03-10 09:00:00  0.00
>  2008-03-10 09:00:01 25.65
>  2008-03-10 09:00:01 25.65
>  2008-03-10 09:00:05 25.65
>  2008-03-10 09:03:03 25.65
>  2008-03-10 09:16:06 25.65
>  2008-03-10 09:16:18 25.65
>  2008-03-10 09:16:29 25.65
>  2008-03-10 09:16:29 25.65
>  2008-03-10 09:27:43 25.65
>  2008-03-10 09:27:43 25.65
>  2008-03-10 09:28:44 25.65
>  2008-03-10 09:28:44 25.65
>  2008-03-10 09:29:39 25.65
>  2008-03-10 09:29:39 25.65
>  2008-03-10 09:30:44 25.65
>  2008-03-10 09:36:36 25.65
>  2008-03-10 09:38:37 25.65
>  2008-03-10 09:38:37 25.65
>  2008-03-10 09:40:36 25.65
>  2008-03-10 09:44:47 25.50
>  2008-03-10 09:44:47 25.28
>  2008-03-10 09:44:47 25.28
>  2008-03-10 09:44:47 25.28
>  2008-03-10 09:44:47 25.28
>  2008-03-10 09:44:47 25.28
>  2008-03-10 09:44:48 25.28
>  2008-03-10 09:44:48 25.28
>  2008-03-10 09:44:48 25.28
>  2008-03-10 09:44:48 25.28
>  2008-03-10 09:44:48 25.28
>  2008-03-10 09:44:53 25.28
>  2008-03-10 09:45:44 25.28
>  2008-03-10 09:47:05 25.28
>  2008-03-10 09:47:05 25.28
>  2008-03-10 09:47:05 25.28
>  2008-03-10 09:47:52 25.28
>  2008-03-10 09:47:52 25.28
>  2008-03-10 09:50:44 25.28
>  2008-03-10 09:50:45 25.28
>  2008-03-10 09:50:45 25.28
>  2008-03-10 09:50:45 25.28
>  2008-03-10 09:51:42 25.28
>  2008-03-10 09:51:43 25.28
>  2008-03-10 09:51:43 25.28
>  2008-03-10 09:51:43 25.28
>  2008-03-10 09:51:43 25.28
>  2008-03-10 09:51:43 25.28
>  2008-03-10 09:51:44 25.28
>  2008-03-10 09:51:44 25.28
>  2008-03-10 09:51:44 25.28
>  2008-03-10 09:52:42 25.28
>  2008-03-10 09:52:42 25.28
>  2008-03-10 09:52:43 25.28
>  2008-03-10 09:52:43 25.28
>  2008-03-10 09:52:43 25.28
>  2008-03-10 09:52:43 25.28
>  2008-03-10 09:53:40 25.28
>  2008-03-10 09:53:40 25.28
>  2008-03-10 09:53:41 25.28
>  2008-03-10 09:53:41 25.28
>  2008-03-10 09:54:24 25.28
>  2008-03-10 09:54:24 25.28
>  2008-03-10 09:54:43 25.28
>  2008-03-10 09:54:43 25.28
>  2008-03-10 09:54:44 25.28
>  2008-03-10 09:54:44 25.28
>  2008-03-10 09:54:44 25.28
>  2008-03-10 09:54:44 25.28
>  2008-03-10 09:54:44 25.28
>  2008-03-10 09:54:44 25.28
>  2008-03-10 09:55:47 25.28
>  2008-03-10 09:55:47 25.28
>  2008-03-10 09:55:48 25.28
>  2008-03-10 09:55:48 25.28
>  2008-03-10 09:55:48 25.28
>  2008-03-10 09:59:04 25.28
>  2008-03-10 09:59:05 25.28
>  2008-03-10 09:59:49 25.28
>  2008-03-10 09:59:49 25.28
>  2008-03-10 10:00:45 25.28
>  2008-03-10 10:01:39 25.28
>  2008-03-10 10:01:39 25.28
>  2008-03-10 10:03:32 25.28
>  2008-03-10 10:05:31 25.28
>  2008-03-10 10:05:31 25.28
>  2008-03-10 10:07:32 25.28
>  2008-03-10 10:07:32 25.28
>  2008-03-10 10:07:32 25.28
>  2008-03-10 10:07:32 25.28
>  2008-03-10 10:07:32 25.28
>  2008-03-10 10:07:32 25.28
>  2008-03-10 10:08:34 25.28
>  2008-03-10 10:08:34 25.28
>  2008-03-10 10:08:34 25.28
>  2008-03-10 10:08:34 25.28
>  2008-03-10 10:09:30 25.28
>  2008-03-10 10:09:30 25.28
>  2008-03-10 10:10:25 25.28
>  2008-03-10 10:10:25 25.28
>  2008-03-10 10:11:25 25.28
>  2008-03-10 10:11:25 25.28
>  2008-03-10 10:12:24 25.28
>  2008-03-10 10:13:26 25.28
>  2008-03-10 10:14:31 25.28
>  2008-03-10 10:14:31 25.28
>  2008-03-10 10:15:35 25.28
>  2008-03-10 10:15:35 25.28
>  2008-03-10 10:16:38 25.28
>  2008-03-10 10:16:38 25.28
>  2008-03-10 10:16:53 25.28
>  2008-03-10 10:19:53 25.28
>  2008-03-10 10:19:54 25.28
>  2008-03-10 10:20:12 25.28
>  2008-03-10 10:20:48 25.28
>  2008-03-10 10:20:48 25.28
>  2008-03-10 10:24:52 25.28
>  2008-03-10 10:24:53 25.28
>  2008-03-10 10:24:53 25.28
>  2008-03-10 10:30:39 25.28
>  2008-03-10 10:30:39 25.28
>  2008-03-10 10:30:40 25.28
>  2008-03-10 10:47:27 25.32
>  2008-03-10 10:47:27 25.32
>  2008-03-10 10:47:28 25.32
>  2008-03-10 10:47:28 25.32
>  2008-03-10 10:47:29 25.32
>  2008-03-10 10:52:55 25.32
>  2008-03-10 10:55:51 25.32
>  2008-03-10 10:55:51 25.32
>  2008-03-10 10:55:51 25.32
>  2008-03-10 10:55:51 25.32
>  2008-03-10 10:55:51 25.32
>  2008-03-10 10:55:51 25.32
>  2008-03-10 10:59:29 25.32
>  2008-03-10 10:59:30 25.32
>  2008-03-10 10:59:30 25.32
>  2008-03-10 11:01:45 25.51
>  2008-03-10 11:01:45 25.51
>  2008-03-10 11:01:46 25.51
>  2008-03-10 11:01:46 25.51
>  2008-03-10 11:01:46 25.51
>  2008-03-10 11:13:50 25.51
>  2008-03-10 11:15:18 25.34
>  2008-03-10 11:15:18 25.34
>  2008-03-10 11:15:19 25.34
>  2008-03-10 11:15:19 25.34
>  2008-03-10 11:15:19 25.34
>  2008-03-10 11:22:53 25.34
>  2008-03-10 11:24:09 25.34
>  2008-03-10 11:32:15 25.34
>  2008-03-10 11:39:42 25.34
>  2008-03-10 11:39:55 25.34
>  2008-03-10 11:39:56 25.34
>  2008-03-10 11:39:56 25.34
>  2008-03-10 11:39:56 25.34
>  2008-03-10 11:39:56 25.34
>  2008-03-10 11:39:56 25.34
>  2008-03-10 11:40:56 25.34
>  2008-03-10 11:40:56 25.34
>  2008-03-10 11:40:57 25.34
>  2008-03-10 11:40:57 25.34
>  2008-03-10 11:40:57 25.34
>  2008-03-10 11:40:57 25.34
>  2008-03-10 11:43:22 25.34
>  2008-03-10 11:43:23 25.34
>  2008-03-10 11:43:59 25.34
>  2008-03-10 11:43:59 25.34
>  2008-03-10 11:47:54 25.34
>  2008-03-10 11:47:54 25.34
>  2008-03-10 11:48:51 25.34
>  2008-03-10 11:48:51 25.34
>  2008-03-10 11:49:46 25.34
>  2008-03-10 11:49:46 25.34
>  2008-03-10 11:50:17 25.34
>  2008-03-10 11:50:18 25.34
>  2008-03-10 11:50:18 25.34
>  2008-03-10 11:50:18 25.34
>  2008-03-10 11:50:19 25.34
>  2008-03-10 11:50:19 25.34
>  2008-03-10 11:50:48 25.34
>  2008-03-10 11:50:48 25.34
>  2008-03-10 11:51:49 25.34
>  2008-03-10 11:51:49 25.34
>  2008-03-10 11:52:20 25.34
>  2008-03-10 11:52:20 25.34
>  2008-03-10 11:52:49 25.34
>  2008-03-10 11:54:28 25.34
>  2008-03-10 11:54:28 25.34
>  2008-03-10 11:54:28 25.34
>  2008-03-10 11:54:28 25.34
>  2008-03-10 11:54:28 25.34
>  2008-03-10 11:54:28 25.34
>  2008-03-10 11:54:50 25.34
>  2008-03-10 12:31:29 25.34
>  2008-03-10 12:31:34 25.34
>  2008-03-10 12:31:35 25.34
>  2008-03-10 12:31:35 25.34
>  2008-03-10 12:31:35 25.34
>  2008-03-10 12:31:42 25.34
>  2008-03-10 12:31:42 25.34
>  2008-03-10 12:31:46 25.34
>  2008-03-10 12:31:47 25.34
>  2008-03-10 12:31:47 25.34
>  2008-03-10 12:31:47 25.34
>  2008-03-10 12:31:47 25.34
>  2008-03-10 12:31:52 25.34
>  2008-03-10 12:31:56 25.34
>  2008-03-10 12:31:57 25.34
>  2008-03-10 12:31:57 25.34
>  2008-03-10 12:31:57 25.34
>  2008-03-10 12:31:57 25.34
>  2008-03-10 12:31:58 25.34
>  2008-03-10 12:42:21 25.34
>  2008-03-10 12:55:24 25.34
>  2008-03-10 12:55:24 25.34
>  2008-03-10 12:55:25 25.34
>  2008-03-10 12:55:25 25.34
>  2008-03-10 12:55:25 25.34
>  2008-03-10 12:55:25 25.34
>  2008-03-10 12:55:25 25.34
>  2008-03-10 15:26:24 25.68
>  2008-03-10 15:26:24 25.68
>  2008-03-10 15:26:24 25.68
>  2008-03-10 15:26:24 25.68
>  2008-03-10 15:26:24 25.68
>  2008-03-10 15:26:25 25.68
>  2008-03-10 15:26:25 25.68
>  2008-03-10 15:31:24 25.68
>  2008-03-10 15:31:24 25.68
>  2008-03-10 15:46:56 25.68
>  2008-03-10 15:46:56 25.68
>  2008-03-10 15:46:56 25.68
>  2008-03-10 15:47:02 25.68
>  2008-03-10 15:48:12 25.42
>  2008-03-10 15:48:12 25.42
>  2008-03-10 15:48:13 25.42
>  2008-03-10 15:48:13 25.42
>  2008-03-10 15:48:13 25.42
>  2008-03-10 15:49:06 25.42
>  2008-03-10 15:49:06 25.42
>  2008-03-10 15:49:06 25.35
>  2008-03-10 15:49:06 25.35
>  2008-03-10 15:49:06 25.34
>  2008-03-10 15:49:06 25.34
>  2008-03-10 15:49:06 25.34
>  2008-03-10 15:49:06 25.34
>  2008-03-10 15:49:06 25.34
>  2008-03-10 15:49:06 25.34
>  2008-03-10 15:49:06 25.34
>  2008-03-10 15:49:17 25.34
>  2008-03-10 15:49:45 25.34
>  2008-03-10 15:49:45 25.34
>  2008-03-10 15:49:45 25.34
>  2008-03-10 15:49:45 25.34
>  2008-03-10 15:49:45 25.34
>  2008-03-10 15:49:45 25.34
>  2008-03-10 15:50:40 25.34
>  2008-03-10 15:50:40 25.34
>  2008-03-10 15:50:40 25.34
>  2008-03-10 15:50:40 25.34
>  2008-03-10 15:50:40 25.34
>  2008-03-10 15:50:41 25.34
>  2008-03-10 16:02:12 25.35
>  2008-03-10 16:02:12 25.35
>  2008-03-10 16:02:12 25.35
>  2008-03-10 16:02:13 25.35
>  2008-03-10 16:14:02 25.35
>  2008-03-10 16:14:02 25.35
>  2008-03-10 16:14:13 25.35
>  2008-03-10 16:14:16 25.34
>  2008-03-10 16:14:16 25.30
>  2008-03-10 16:14:16 25.30
>  2008-03-10 16:14:17 25.30
>  2008-03-10 16:14:17 25.30
>  2008-03-10 16:14:17 25.30
>  2008-03-10 16:14:17 25.30
>  2008-03-10 16:14:18 25.30
>  2008-03-10 16:14:18 25.30
>  2008-03-10 16:14:18 25.30
>  2008-03-10 16:14:20 25.30
>  2008-03-10 16:14:33 25.30
>  2008-03-10 16:14:33 25.30
>  2008-03-10 16:14:34 25.30
>  2008-03-10 16:14:34 25.30
>  2008-03-10 16:14:34 25.30
>  2008-03-10 16:14:34 25.30
>  2008-03-10 16:14:45 25.30
>  2008-03-10 16:15:15 25.30
>  2008-03-10 16:15:37 25.30
>  2008-03-10 16:15:37 25.30
>  2008-03-10 16:15:38 25.30
>  2008-03-10 16:15:38 25.30
>  2008-03-10 16:15:38 25.30
>  2008-03-10 16:15:38 25.30
>  2008-03-10 16:16:37 25.30
>  2008-03-10 16:16:37 25.30
>  2008-03-10 16:16:38 25.30
>  2008-03-10 16:16:38 25.30
>  2008-03-10 16:16:38 25.30
>  2008-03-10 16:16:38 25.30
>  2008-03-10 16:22:46 25.35
>  2008-03-10 16:22:46 25.35
>  2008-03-10 16:22:46 25.35
>  2008-03-10 16:22:47 25.35
>  2008-03-10 16:22:47 25.35
>  2008-03-10 16:22:47 25.35
>  2008-03-10 16:22:47 25.35
>  2008-03-10 16:22:47 25.35
>  2008-03-10 16:22:48 25.35
>  2008-03-10 16:23:46 25.35
>  2008-03-10 16:23:46 25.35
>  2008-03-10 16:23:47 25.35
>  2008-03-10 16:23:47 25.35
>  2008-03-10 16:23:47 25.35
>  2008-03-10 16:23:47 25.35
>  2008-03-10 16:24:43 25.35
>  2008-03-10 16:24:43 25.35
>  2008-03-10 16:24:44 25.35
>  2008-03-10 16:24:44 25.35
>  2008-03-10 16:24:44 25.35
>  2008-03-10 16:24:44 25.35
>  2008-03-10 16:25:07 25.35
>  2008-03-10 16:25:07 25.35
>  2008-03-10 16:25:41 25.35
>  2008-03-10 16:25:42 25.35
>  2008-03-10 16:25:42 25.35
>  2008-03-10 16:25:42 25.35
>  2008-03-10 16:25:42 25.35
>  2008-03-10 16:25:42 25.35
>  2008-03-10 16:25:42 25.35
>  2008-03-10 16:25:42 25.35
>  2008-03-10 16:25:43 25.35
>  2008-03-10 16:26:38 25.35
>  2008-03-10 16:26:38 25.35
>  2008-03-10 16:26:39 25.35
>  2008-03-10 16:32:49 25.35
>  2008-03-10 16:34:38 25.35
>  2008-03-10 16:35:09 25.35
>  2008-03-10 16:35:10 25.35
>  2008-03-10 16:35:10 25.35
>  2008-03-10 16:35:29 25.20
>  2008-03-10 16:35:29 25.20
>  2008-03-10 16:35:30 25.20
>  2008-03-10 16:35:30 25.20
>  2008-03-10 16:35:33 25.20
>  2008-03-10 16:35:33 25.20
>  2008-03-10 16:35:33 25.20
>  2008-03-10 16:35:34 25.20
>  2008-03-10 16:36:12 25.20
>  2008-03-10 16:36:12 25.20
>  2008-03-10 16:40:28 25.20
>  2008-03-10 16:43:42 25.20
>  2008-03-10 16:43:43 25.20
>  2008-03-10 16:44:24 25.20
>  2008-03-10 16:44:25 25.20
>  2008-03-10 16:44:25 25.20
>  2008-03-10 16:44:25 25.20
>  2008-03-10 16:50:31 25.20
>  2008-03-10 16:50:31 25.20
>  2008-03-10 16:51:31 25.20
>  2008-03-10 16:51:31 25.20
>  2008-03-10 16:52:29 25.20
>  2008-03-10 16:52:29 25.20
>  2008-03-10 16:53:00 25.20
>  2008-03-10 16:53:00 25.20
>  2008-03-10 16:53:23 25.20
>  2008-03-10 16:53:23 25.20
>  2008-03-10 16:54:27 25.20
>  2008-03-10 16:54:56 25.20
>  2008-03-10 16:55:30 25.20
>  2008-03-10 16:55:31 25.20
>  2008-03-10 16:55:31 25.20
>  2008-03-10 16:56:27 25.20
>  2008-03-10 16:56:27 25.10
>  2008-03-10 16:56:27 25.10
>  2008-03-10 16:56:28 25.10
>  2008-03-10 16:56:28 25.10
>  2008-03-10 16:56:28 25.10
>  2008-03-10 16:56:33 25.10
>  2008-03-10 16:56:43 25.10
>  2008-03-10 16:56:49 25.10
>  2008-03-10 17:02:16 25.10
>  2008-03-10 17:02:19 25.10
>  2008-03-10 17:03:56 25.10
>  2008-03-10 17:03:57 25.10
>  2008-03-10 17:05:59 25.06
>  2008-03-10 17:05:59 25.06
>  2008-03-10 17:06:00 25.06
>  2008-03-10 17:06:00 25.06
>  2008-03-10 17:06:00 25.06
>  2008-03-10 17:06:01 25.06
>  2008-03-10 17:06:12 25.05
>  2008-03-10 17:06:12 25.05
>  2008-03-10 17:06:12 25.05
>  2008-03-10 17:06:13 25.05
>  2008-03-10 17:06:13 25.05
>  2008-03-10 17:07:03 25.05
>  2008-03-10 17:07:16 25.05
>  2008-03-10 17:08:02 25.05
>  2008-03-10 17:08:02 25.01
>  2008-03-10 17:08:02 25.00
>  2008-03-10 17:08:02 25.00
>  2008-03-10 17:08:02 25.00
>  2008-03-10 17:08:02 25.00
>  2008-03-10 17:08:02 25.00
>  2008-03-10 17:08:02 25.00
>  2008-03-10 17:08:03 25.00
>  2008-03-10 17:08:03 25.00
>  2008-03-10 17:08:03 25.00
>  2008-03-10 17:08:10 25.00
>  2008-03-10 17:08:35 25.00
>  2008-03-10 17:08:43 25.00
>  2008-03-10 17:08:47 25.00
>  2008-03-10 17:24:18 25.00
>  2008-03-10 17:24:19 25.00
>  2008-03-10 17:24:19 25.00
>  2008-03-10 17:24:19 25.00
>  2008-03-10 17:24:19 25.00
>  2008-03-10 17:24:19 25.00
>  2008-03-10 17:24:20 25.00
>  2008-03-10 17:24:20 25.00
>  2008-03-10 17:29:05 25.00
>  2008-03-10 17:29:31 25.00
>  2008-03-10 17:29:31 25.00
>  2008-03-10 17:30:00 25.00
>
>
>
>  *************************************************************************
>  This message and any attachments (the "message") are con...{{dropped:10}}
>
>  _______________________________________________
>  R-SIG-Finance at stat.math.ethz.ch mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>  -- Subscriber-posting only.
>  -- If you want to post, subscribe first.
>



-- 
There's a way to do it better - find it.
Thomas A. Edison


From ggrothendieck at gmail.com  Mon Apr  7 15:46:49 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 7 Apr 2008 09:46:49 -0400
Subject: [R-SIG-Finance] [R-sig-finance] endpoints function in package
	xts [C1]
In-Reply-To: <OF8B7C3A2C.9766DF92-ONC1257424.003E06CB-C1257424.003EDB4A@fr.world.socgen>
References: <OF8B7C3A2C.9766DF92-ONC1257424.003E06CB-C1257424.003EDB4A@fr.world.socgen>
Message-ID: <971536df0804070646q56fd28bckba4aaba66631ebb9@mail.gmail.com>

Here is an example using chron:



We will illustrate this using chron and zoo.

First we read in the data.  za is formed
by aggregating by hour, truncating and then
moving up to the next hour.  We convert to
zooreg since lag.zooreg moves by the delta of the
series whereas lag.zoo moves by data points. Then
we convert to ts and back which fills in the missing hours
with NAs and use aggregate to change it back
to chron. Where there is not an NA we put back
the original times and where there is an NA
we stick 0.

library(zoo)
library(chron)

Lines <- "2008-03-10 09:59:49,2004.37
2008-03-10 10:59:30,1441.56
2008-03-10 11:54:50,1445.40
2008-03-10 12:55:25,684.18
2008-03-10 15:50:41,1069.28
2008-03-10 16:56:49,3008.19
2008-03-10 17:30:00,1101.17
"
z <- read.zoo(textConnection(Lines), sep = ",", FUN = as.chron)

za <- lag(as.zooreg(aggregate(z, trunc(time(z), "hour"), sum)), -1)

zfill <- aggregate(as.zoo(as.ts(za)), chron, force)
time(zfill)[!is.na(zfill)] <- time(z)
zfill[is.na(zfill)] <- 0


Thus zfill looks like this:

> zfill
(03/10/08 09:59:49) (03/10/08 10:59:30) (03/10/08 11:54:50) (03/10/08 12:55:25)
            2004.37             1441.56             1445.40              684.18
(03/10/08 14:00:00) (03/10/08 15:00:00) (03/10/08 15:50:41) (03/10/08 16:56:49)
               0.00                0.00             1069.28             3008.19
(03/10/08 17:30:00)
            1101.17

On Mon, Apr 7, 2008 at 7:26 AM,  <anass.mouhsine at sgcib.com> wrote:
>
> Hi All,
>
> I have an issue with endpoints in package xts.
> Assume that I have a timeSeries of a tick by tick price and that I want to
> get an hourly sum aggregation
>
> > ep<-endpoints(temp,'hours',1)
> >ans<-xts:::period.sum(temp[,1],ep)
>
> this should do, but the problem is that in my set of data, I don't have any
> data between 12h55 and 15h26.
> so when it returns ans , ans equals:
>
> 2008-03-10 09:59:49 2004.37
> 2008-03-10 10:59:30 1441.56
> 2008-03-10 11:54:50 1445.40
> 2008-03-10 12:55:25  684.18
> 2008-03-10 15:50:41 1069.28
> 2008-03-10 16:56:49 3008.19
> 2008-03-10 17:30:00 1101.17
>
> but I want something like
>
> 2008-03-10 09:59:49 2004.37
> 2008-03-10 10:59:30 1441.56
> 2008-03-10 11:54:50 1445.40
> 2008-03-10 12:55:25  684.18
> 2008-03-10 14:00:00 0
> 2008-03-10 15:00:00 0
> 2008-03-10 15:50:41 1069.28
> 2008-03-10 16:56:49 3008.19
> 2008-03-10 17:30:00 1101.17
>
> Do you have any idea on how to perform this task?
>
> Thanks in davance.
>
> Anass
>
> P.S: you will find below the timeSeries temp.
>
> > temp
>                                   V6
> 2008-03-10 09:00:00  0.00
> 2008-03-10 09:00:01 25.65
> 2008-03-10 09:00:01 25.65
> 2008-03-10 09:00:05 25.65
> 2008-03-10 09:03:03 25.65
> 2008-03-10 09:16:06 25.65
> 2008-03-10 09:16:18 25.65
> 2008-03-10 09:16:29 25.65
> 2008-03-10 09:16:29 25.65
> 2008-03-10 09:27:43 25.65
> 2008-03-10 09:27:43 25.65
> 2008-03-10 09:28:44 25.65
> 2008-03-10 09:28:44 25.65
> 2008-03-10 09:29:39 25.65
> 2008-03-10 09:29:39 25.65
> 2008-03-10 09:30:44 25.65
> 2008-03-10 09:36:36 25.65
> 2008-03-10 09:38:37 25.65
> 2008-03-10 09:38:37 25.65
> 2008-03-10 09:40:36 25.65
> 2008-03-10 09:44:47 25.50
> 2008-03-10 09:44:47 25.28
> 2008-03-10 09:44:47 25.28
> 2008-03-10 09:44:47 25.28
> 2008-03-10 09:44:47 25.28
> 2008-03-10 09:44:47 25.28
> 2008-03-10 09:44:48 25.28
> 2008-03-10 09:44:48 25.28
> 2008-03-10 09:44:48 25.28
> 2008-03-10 09:44:48 25.28
> 2008-03-10 09:44:48 25.28
> 2008-03-10 09:44:53 25.28
> 2008-03-10 09:45:44 25.28
> 2008-03-10 09:47:05 25.28
> 2008-03-10 09:47:05 25.28
> 2008-03-10 09:47:05 25.28
> 2008-03-10 09:47:52 25.28
> 2008-03-10 09:47:52 25.28
> 2008-03-10 09:50:44 25.28
> 2008-03-10 09:50:45 25.28
> 2008-03-10 09:50:45 25.28
> 2008-03-10 09:50:45 25.28
> 2008-03-10 09:51:42 25.28
> 2008-03-10 09:51:43 25.28
> 2008-03-10 09:51:43 25.28
> 2008-03-10 09:51:43 25.28
> 2008-03-10 09:51:43 25.28
> 2008-03-10 09:51:43 25.28
> 2008-03-10 09:51:44 25.28
> 2008-03-10 09:51:44 25.28
> 2008-03-10 09:51:44 25.28
> 2008-03-10 09:52:42 25.28
> 2008-03-10 09:52:42 25.28
> 2008-03-10 09:52:43 25.28
> 2008-03-10 09:52:43 25.28
> 2008-03-10 09:52:43 25.28
> 2008-03-10 09:52:43 25.28
> 2008-03-10 09:53:40 25.28
> 2008-03-10 09:53:40 25.28
> 2008-03-10 09:53:41 25.28
> 2008-03-10 09:53:41 25.28
> 2008-03-10 09:54:24 25.28
> 2008-03-10 09:54:24 25.28
> 2008-03-10 09:54:43 25.28
> 2008-03-10 09:54:43 25.28
> 2008-03-10 09:54:44 25.28
> 2008-03-10 09:54:44 25.28
> 2008-03-10 09:54:44 25.28
> 2008-03-10 09:54:44 25.28
> 2008-03-10 09:54:44 25.28
> 2008-03-10 09:54:44 25.28
> 2008-03-10 09:55:47 25.28
> 2008-03-10 09:55:47 25.28
> 2008-03-10 09:55:48 25.28
> 2008-03-10 09:55:48 25.28
> 2008-03-10 09:55:48 25.28
> 2008-03-10 09:59:04 25.28
> 2008-03-10 09:59:05 25.28
> 2008-03-10 09:59:49 25.28
> 2008-03-10 09:59:49 25.28
> 2008-03-10 10:00:45 25.28
> 2008-03-10 10:01:39 25.28
> 2008-03-10 10:01:39 25.28
> 2008-03-10 10:03:32 25.28
> 2008-03-10 10:05:31 25.28
> 2008-03-10 10:05:31 25.28
> 2008-03-10 10:07:32 25.28
> 2008-03-10 10:07:32 25.28
> 2008-03-10 10:07:32 25.28
> 2008-03-10 10:07:32 25.28
> 2008-03-10 10:07:32 25.28
> 2008-03-10 10:07:32 25.28
> 2008-03-10 10:08:34 25.28
> 2008-03-10 10:08:34 25.28
> 2008-03-10 10:08:34 25.28
> 2008-03-10 10:08:34 25.28
> 2008-03-10 10:09:30 25.28
> 2008-03-10 10:09:30 25.28
> 2008-03-10 10:10:25 25.28
> 2008-03-10 10:10:25 25.28
> 2008-03-10 10:11:25 25.28
> 2008-03-10 10:11:25 25.28
> 2008-03-10 10:12:24 25.28
> 2008-03-10 10:13:26 25.28
> 2008-03-10 10:14:31 25.28
> 2008-03-10 10:14:31 25.28
> 2008-03-10 10:15:35 25.28
> 2008-03-10 10:15:35 25.28
> 2008-03-10 10:16:38 25.28
> 2008-03-10 10:16:38 25.28
> 2008-03-10 10:16:53 25.28
> 2008-03-10 10:19:53 25.28
> 2008-03-10 10:19:54 25.28
> 2008-03-10 10:20:12 25.28
> 2008-03-10 10:20:48 25.28
> 2008-03-10 10:20:48 25.28
> 2008-03-10 10:24:52 25.28
> 2008-03-10 10:24:53 25.28
> 2008-03-10 10:24:53 25.28
> 2008-03-10 10:30:39 25.28
> 2008-03-10 10:30:39 25.28
> 2008-03-10 10:30:40 25.28
> 2008-03-10 10:47:27 25.32
> 2008-03-10 10:47:27 25.32
> 2008-03-10 10:47:28 25.32
> 2008-03-10 10:47:28 25.32
> 2008-03-10 10:47:29 25.32
> 2008-03-10 10:52:55 25.32
> 2008-03-10 10:55:51 25.32
> 2008-03-10 10:55:51 25.32
> 2008-03-10 10:55:51 25.32
> 2008-03-10 10:55:51 25.32
> 2008-03-10 10:55:51 25.32
> 2008-03-10 10:55:51 25.32
> 2008-03-10 10:59:29 25.32
> 2008-03-10 10:59:30 25.32
> 2008-03-10 10:59:30 25.32
> 2008-03-10 11:01:45 25.51
> 2008-03-10 11:01:45 25.51
> 2008-03-10 11:01:46 25.51
> 2008-03-10 11:01:46 25.51
> 2008-03-10 11:01:46 25.51
> 2008-03-10 11:13:50 25.51
> 2008-03-10 11:15:18 25.34
> 2008-03-10 11:15:18 25.34
> 2008-03-10 11:15:19 25.34
> 2008-03-10 11:15:19 25.34
> 2008-03-10 11:15:19 25.34
> 2008-03-10 11:22:53 25.34
> 2008-03-10 11:24:09 25.34
> 2008-03-10 11:32:15 25.34
> 2008-03-10 11:39:42 25.34
> 2008-03-10 11:39:55 25.34
> 2008-03-10 11:39:56 25.34
> 2008-03-10 11:39:56 25.34
> 2008-03-10 11:39:56 25.34
> 2008-03-10 11:39:56 25.34
> 2008-03-10 11:39:56 25.34
> 2008-03-10 11:40:56 25.34
> 2008-03-10 11:40:56 25.34
> 2008-03-10 11:40:57 25.34
> 2008-03-10 11:40:57 25.34
> 2008-03-10 11:40:57 25.34
> 2008-03-10 11:40:57 25.34
> 2008-03-10 11:43:22 25.34
> 2008-03-10 11:43:23 25.34
> 2008-03-10 11:43:59 25.34
> 2008-03-10 11:43:59 25.34
> 2008-03-10 11:47:54 25.34
> 2008-03-10 11:47:54 25.34
> 2008-03-10 11:48:51 25.34
> 2008-03-10 11:48:51 25.34
> 2008-03-10 11:49:46 25.34
> 2008-03-10 11:49:46 25.34
> 2008-03-10 11:50:17 25.34
> 2008-03-10 11:50:18 25.34
> 2008-03-10 11:50:18 25.34
> 2008-03-10 11:50:18 25.34
> 2008-03-10 11:50:19 25.34
> 2008-03-10 11:50:19 25.34
> 2008-03-10 11:50:48 25.34
> 2008-03-10 11:50:48 25.34
> 2008-03-10 11:51:49 25.34
> 2008-03-10 11:51:49 25.34
> 2008-03-10 11:52:20 25.34
> 2008-03-10 11:52:20 25.34
> 2008-03-10 11:52:49 25.34
> 2008-03-10 11:54:28 25.34
> 2008-03-10 11:54:28 25.34
> 2008-03-10 11:54:28 25.34
> 2008-03-10 11:54:28 25.34
> 2008-03-10 11:54:28 25.34
> 2008-03-10 11:54:28 25.34
> 2008-03-10 11:54:50 25.34
> 2008-03-10 12:31:29 25.34
> 2008-03-10 12:31:34 25.34
> 2008-03-10 12:31:35 25.34
> 2008-03-10 12:31:35 25.34
> 2008-03-10 12:31:35 25.34
> 2008-03-10 12:31:42 25.34
> 2008-03-10 12:31:42 25.34
> 2008-03-10 12:31:46 25.34
> 2008-03-10 12:31:47 25.34
> 2008-03-10 12:31:47 25.34
> 2008-03-10 12:31:47 25.34
> 2008-03-10 12:31:47 25.34
> 2008-03-10 12:31:52 25.34
> 2008-03-10 12:31:56 25.34
> 2008-03-10 12:31:57 25.34
> 2008-03-10 12:31:57 25.34
> 2008-03-10 12:31:57 25.34
> 2008-03-10 12:31:57 25.34
> 2008-03-10 12:31:58 25.34
> 2008-03-10 12:42:21 25.34
> 2008-03-10 12:55:24 25.34
> 2008-03-10 12:55:24 25.34
> 2008-03-10 12:55:25 25.34
> 2008-03-10 12:55:25 25.34
> 2008-03-10 12:55:25 25.34
> 2008-03-10 12:55:25 25.34
> 2008-03-10 12:55:25 25.34
> 2008-03-10 15:26:24 25.68
> 2008-03-10 15:26:24 25.68
> 2008-03-10 15:26:24 25.68
> 2008-03-10 15:26:24 25.68
> 2008-03-10 15:26:24 25.68
> 2008-03-10 15:26:25 25.68
> 2008-03-10 15:26:25 25.68
> 2008-03-10 15:31:24 25.68
> 2008-03-10 15:31:24 25.68
> 2008-03-10 15:46:56 25.68
> 2008-03-10 15:46:56 25.68
> 2008-03-10 15:46:56 25.68
> 2008-03-10 15:47:02 25.68
> 2008-03-10 15:48:12 25.42
> 2008-03-10 15:48:12 25.42
> 2008-03-10 15:48:13 25.42
> 2008-03-10 15:48:13 25.42
> 2008-03-10 15:48:13 25.42
> 2008-03-10 15:49:06 25.42
> 2008-03-10 15:49:06 25.42
> 2008-03-10 15:49:06 25.35
> 2008-03-10 15:49:06 25.35
> 2008-03-10 15:49:06 25.34
> 2008-03-10 15:49:06 25.34
> 2008-03-10 15:49:06 25.34
> 2008-03-10 15:49:06 25.34
> 2008-03-10 15:49:06 25.34
> 2008-03-10 15:49:06 25.34
> 2008-03-10 15:49:06 25.34
> 2008-03-10 15:49:17 25.34
> 2008-03-10 15:49:45 25.34
> 2008-03-10 15:49:45 25.34
> 2008-03-10 15:49:45 25.34
> 2008-03-10 15:49:45 25.34
> 2008-03-10 15:49:45 25.34
> 2008-03-10 15:49:45 25.34
> 2008-03-10 15:50:40 25.34
> 2008-03-10 15:50:40 25.34
> 2008-03-10 15:50:40 25.34
> 2008-03-10 15:50:40 25.34
> 2008-03-10 15:50:40 25.34
> 2008-03-10 15:50:41 25.34
> 2008-03-10 16:02:12 25.35
> 2008-03-10 16:02:12 25.35
> 2008-03-10 16:02:12 25.35
> 2008-03-10 16:02:13 25.35
> 2008-03-10 16:14:02 25.35
> 2008-03-10 16:14:02 25.35
> 2008-03-10 16:14:13 25.35
> 2008-03-10 16:14:16 25.34
> 2008-03-10 16:14:16 25.30
> 2008-03-10 16:14:16 25.30
> 2008-03-10 16:14:17 25.30
> 2008-03-10 16:14:17 25.30
> 2008-03-10 16:14:17 25.30
> 2008-03-10 16:14:17 25.30
> 2008-03-10 16:14:18 25.30
> 2008-03-10 16:14:18 25.30
> 2008-03-10 16:14:18 25.30
> 2008-03-10 16:14:20 25.30
> 2008-03-10 16:14:33 25.30
> 2008-03-10 16:14:33 25.30
> 2008-03-10 16:14:34 25.30
> 2008-03-10 16:14:34 25.30
> 2008-03-10 16:14:34 25.30
> 2008-03-10 16:14:34 25.30
> 2008-03-10 16:14:45 25.30
> 2008-03-10 16:15:15 25.30
> 2008-03-10 16:15:37 25.30
> 2008-03-10 16:15:37 25.30
> 2008-03-10 16:15:38 25.30
> 2008-03-10 16:15:38 25.30
> 2008-03-10 16:15:38 25.30
> 2008-03-10 16:15:38 25.30
> 2008-03-10 16:16:37 25.30
> 2008-03-10 16:16:37 25.30
> 2008-03-10 16:16:38 25.30
> 2008-03-10 16:16:38 25.30
> 2008-03-10 16:16:38 25.30
> 2008-03-10 16:16:38 25.30
> 2008-03-10 16:22:46 25.35
> 2008-03-10 16:22:46 25.35
> 2008-03-10 16:22:46 25.35
> 2008-03-10 16:22:47 25.35
> 2008-03-10 16:22:47 25.35
> 2008-03-10 16:22:47 25.35
> 2008-03-10 16:22:47 25.35
> 2008-03-10 16:22:47 25.35
> 2008-03-10 16:22:48 25.35
> 2008-03-10 16:23:46 25.35
> 2008-03-10 16:23:46 25.35
> 2008-03-10 16:23:47 25.35
> 2008-03-10 16:23:47 25.35
> 2008-03-10 16:23:47 25.35
> 2008-03-10 16:23:47 25.35
> 2008-03-10 16:24:43 25.35
> 2008-03-10 16:24:43 25.35
> 2008-03-10 16:24:44 25.35
> 2008-03-10 16:24:44 25.35
> 2008-03-10 16:24:44 25.35
> 2008-03-10 16:24:44 25.35
> 2008-03-10 16:25:07 25.35
> 2008-03-10 16:25:07 25.35
> 2008-03-10 16:25:41 25.35
> 2008-03-10 16:25:42 25.35
> 2008-03-10 16:25:42 25.35
> 2008-03-10 16:25:42 25.35
> 2008-03-10 16:25:42 25.35
> 2008-03-10 16:25:42 25.35
> 2008-03-10 16:25:42 25.35
> 2008-03-10 16:25:42 25.35
> 2008-03-10 16:25:43 25.35
> 2008-03-10 16:26:38 25.35
> 2008-03-10 16:26:38 25.35
> 2008-03-10 16:26:39 25.35
> 2008-03-10 16:32:49 25.35
> 2008-03-10 16:34:38 25.35
> 2008-03-10 16:35:09 25.35
> 2008-03-10 16:35:10 25.35
> 2008-03-10 16:35:10 25.35
> 2008-03-10 16:35:29 25.20
> 2008-03-10 16:35:29 25.20
> 2008-03-10 16:35:30 25.20
> 2008-03-10 16:35:30 25.20
> 2008-03-10 16:35:33 25.20
> 2008-03-10 16:35:33 25.20
> 2008-03-10 16:35:33 25.20
> 2008-03-10 16:35:34 25.20
> 2008-03-10 16:36:12 25.20
> 2008-03-10 16:36:12 25.20
> 2008-03-10 16:40:28 25.20
> 2008-03-10 16:43:42 25.20
> 2008-03-10 16:43:43 25.20
> 2008-03-10 16:44:24 25.20
> 2008-03-10 16:44:25 25.20
> 2008-03-10 16:44:25 25.20
> 2008-03-10 16:44:25 25.20
> 2008-03-10 16:50:31 25.20
> 2008-03-10 16:50:31 25.20
> 2008-03-10 16:51:31 25.20
> 2008-03-10 16:51:31 25.20
> 2008-03-10 16:52:29 25.20
> 2008-03-10 16:52:29 25.20
> 2008-03-10 16:53:00 25.20
> 2008-03-10 16:53:00 25.20
> 2008-03-10 16:53:23 25.20
> 2008-03-10 16:53:23 25.20
> 2008-03-10 16:54:27 25.20
> 2008-03-10 16:54:56 25.20
> 2008-03-10 16:55:30 25.20
> 2008-03-10 16:55:31 25.20
> 2008-03-10 16:55:31 25.20
> 2008-03-10 16:56:27 25.20
> 2008-03-10 16:56:27 25.10
> 2008-03-10 16:56:27 25.10
> 2008-03-10 16:56:28 25.10
> 2008-03-10 16:56:28 25.10
> 2008-03-10 16:56:28 25.10
> 2008-03-10 16:56:33 25.10
> 2008-03-10 16:56:43 25.10
> 2008-03-10 16:56:49 25.10
> 2008-03-10 17:02:16 25.10
> 2008-03-10 17:02:19 25.10
> 2008-03-10 17:03:56 25.10
> 2008-03-10 17:03:57 25.10
> 2008-03-10 17:05:59 25.06
> 2008-03-10 17:05:59 25.06
> 2008-03-10 17:06:00 25.06
> 2008-03-10 17:06:00 25.06
> 2008-03-10 17:06:00 25.06
> 2008-03-10 17:06:01 25.06
> 2008-03-10 17:06:12 25.05
> 2008-03-10 17:06:12 25.05
> 2008-03-10 17:06:12 25.05
> 2008-03-10 17:06:13 25.05
> 2008-03-10 17:06:13 25.05
> 2008-03-10 17:07:03 25.05
> 2008-03-10 17:07:16 25.05
> 2008-03-10 17:08:02 25.05
> 2008-03-10 17:08:02 25.01
> 2008-03-10 17:08:02 25.00
> 2008-03-10 17:08:02 25.00
> 2008-03-10 17:08:02 25.00
> 2008-03-10 17:08:02 25.00
> 2008-03-10 17:08:02 25.00
> 2008-03-10 17:08:02 25.00
> 2008-03-10 17:08:03 25.00
> 2008-03-10 17:08:03 25.00
> 2008-03-10 17:08:03 25.00
> 2008-03-10 17:08:10 25.00
> 2008-03-10 17:08:35 25.00
> 2008-03-10 17:08:43 25.00
> 2008-03-10 17:08:47 25.00
> 2008-03-10 17:24:18 25.00
> 2008-03-10 17:24:19 25.00
> 2008-03-10 17:24:19 25.00
> 2008-03-10 17:24:19 25.00
> 2008-03-10 17:24:19 25.00
> 2008-03-10 17:24:19 25.00
> 2008-03-10 17:24:20 25.00
> 2008-03-10 17:24:20 25.00
> 2008-03-10 17:29:05 25.00
> 2008-03-10 17:29:31 25.00
> 2008-03-10 17:29:31 25.00
> 2008-03-10 17:30:00 25.00
>
>
>
> *************************************************************************
> This message and any attachments (the "message") are con...{{dropped:10}}
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From chalabi at phys.ethz.ch  Mon Apr  7 16:46:58 2008
From: chalabi at phys.ethz.ch (chalabi at phys.ethz.ch)
Date: Mon, 07 Apr 2008 16:46:58 +0200
Subject: [R-SIG-Finance] Seasonal GARCH
In-Reply-To: <47F97B32.6000903@pdf.com> (Spencer Graves's message of "Sun, 06
	Apr 2008 18:38:58 -0700")
References: <2897.75.35.76.169.1207516774.squirrel@www.stat.berkeley.edu>
	<47F97B32.6000903@pdf.com>
Message-ID: <87fxtx4t99.fsf@phys.ethz.ch>

Hi Irma,

After reading the previous post, I think there is some confusion about
what parameters you want to estimate. So I hope I will not add more
confusion out there.

As far as I understand your question, you want to estimate a GARCH(5,0)
and keep all alpha parameters fixed in the optimisation except
alpha_{t-5}.

Currently in garchFit you can only fix the parameters of the conditional
distribution (include.skew, include.shape), the mean equation
(include.mean) and the delta of an APARCH model (include.delta).

We plan to add the ability to fix any parameters in the optimisation for
a future release.

best regards,
Yohan

 
Currently it is not possible to fix parameters

Spencer Graves <spencer.graves at pdf.com> writes:

>      The last I checked, garchFit could not estimate a model with zero
> for either of the garch lag parameters. 
>
>      The expert on current and planned garchFit capabilities is Yohan
> Chalabi, and I've copied him on this reply.  Unless you hear otherwise
> from him, I think it is best to assume that you can fit any garch(i,
> j) model you want as long as both i and j are strictly positive. 
>
>      I'm sorry I couldn't be more helpful.    Spencer
>
> ihernan at stat.berkeley.edu wrote:
>> I am trying to use the library(fGarch) and fit a GARCH model but I am
>> interested in fitting a ARCH for the volatility.
>> If I use ~GARCH(5,0) then 5 autoregressive parameters are fitted but I am
>> just interested in the a_{t-5}^2 parameter. Is there any way I could
>> obtain this model using the function library(fGarch).
>>
>> Thank you Irma
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. -- If you want to post, subscribe first.
>>   

-- 


The 2nd International R/Rmetrics User and Developer Workshop ...
[http://www.rmetrics.org]


From chalabi at phys.ethz.ch  Mon Apr  7 16:53:35 2008
From: chalabi at phys.ethz.ch (chalabi at phys.ethz.ch)
Date: Mon, 07 Apr 2008 16:53:35 +0200
Subject: [R-SIG-Finance] Seasonal GARCH
In-Reply-To: <47F9820C.9000804@pdf.com> (Spencer Graves's message of "Sun, 06
	Apr 2008 19:08:12 -0700")
References: <2897.75.35.76.169.1207516774.squirrel@www.stat.berkeley.edu>
	<47F97B32.6000903@pdf.com> <47F9820C.9000804@pdf.com>
Message-ID: <877if94sy8.fsf@phys.ethz.ch>


>       The 'garch' function in the 'tseries' package can estimate a 
> garch(0, 5) or garch(5, 0) model. 

As far as fGarch is concerned, I refer you to my previous post on this
matter (https://stat.ethz.ch/pipermail/r-sig-finance/2008q1/002241.html).

regards,
Yohan

Spencer Graves <spencer.graves at pdf.com> writes:

>       The 'garch' function in the 'tseries' package can estimate a 
> garch(0, 5) or garch(5, 0) model. 
>
>       Hope this helps. 
>       Spencer
>
> Spencer Graves wrote:
>>       The last I checked, garchFit could not estimate a model with zero 
>> for either of the garch lag parameters. 
>>
>>       The expert on current and planned garchFit capabilities is Yohan 
>> Chalabi, and I've copied him on this reply.  Unless you hear otherwise 
>> from him, I think it is best to assume that you can fit any garch(i, j) 
>> model you want as long as both i and j are strictly positive. 
>>
>>       I'm sorry I couldn't be more helpful. 
>>       Spencer
>>
>> ihernan at stat.berkeley.edu wrote:
>>   
>>> I am trying to use the library(fGarch) and fit a GARCH model but I am
>>> interested in fitting a ARCH for the volatility.
>>> If I use ~GARCH(5,0) then 5 autoregressive parameters are fitted but I am
>>> just interested in the a_{t-5}^2 parameter. Is there any way I could
>>> obtain this model using the function library(fGarch).
>>>
>>> Thank you Irma
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. 
>>> -- If you want to post, subscribe first.
>>>
>>>     
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. 
>> -- If you want to post, subscribe first.
>>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. 
> -- If you want to post, subscribe first.

-- 


The 2nd International R/Rmetrics User and Developer Workshop ...
[http://www.rmetrics.org]


From sylvain.archenault at sgcib.com  Mon Apr  7 17:53:28 2008
From: sylvain.archenault at sgcib.com (sylvain.archenault at sgcib.com)
Date: Mon, 7 Apr 2008 17:53:28 +0200
Subject: [R-SIG-Finance] Problem with GarchFit [NC]
Message-ID: <OFB0BF0ABD.A1274ED7-ONC1257424.00573A72-C1257424.00574A48@fr.world.socgen>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080407/3f3a8139/attachment.pl 

From sylvain.archenault at sgcib.com  Mon Apr  7 18:14:48 2008
From: sylvain.archenault at sgcib.com (sylvain.archenault at sgcib.com)
Date: Mon, 7 Apr 2008 18:14:48 +0200
Subject: [R-SIG-Finance] Problem with GarchFit [NC]
In-Reply-To: <18153595.2985621207584100901.JavaMail.root@vms126.mailsrvcs.net>
Message-ID: <OF81E931A1.409B7342-ONC1257424.0058469B-C1257424.00593E56@fr.world.socgen>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080407/bc086b45/attachment.pl 

From sylvain.archenault at sgcib.com  Mon Apr  7 18:28:35 2008
From: sylvain.archenault at sgcib.com (sylvain.archenault at sgcib.com)
Date: Mon, 7 Apr 2008 18:28:35 +0200
Subject: [R-SIG-Finance] Problem with GarchFit [NC]
In-Reply-To: <11202455.2999951207585264641.JavaMail.root@vms126.mailsrvcs.net>
Message-ID: <OF21AA534F.50D73AC9-ONC1257424.005A18E5-C1257424.005A8125@fr.world.socgen>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080407/b1620a6e/attachment.pl 

From gplaxico at gmail.com  Mon Apr  7 19:57:00 2008
From: gplaxico at gmail.com (gabe plaxico)
Date: Mon, 7 Apr 2008 13:57:00 -0400
Subject: [R-SIG-Finance] Optimization Book with R. (Style Based Analysis,
	MV Portfolio)
Message-ID: <8c77486c0804071057g52cb2b76n703e48391d60317a@mail.gmail.com>

Anyone have any suggestion on a good book for optimization using R?
Specifically looking for material addressing linear/quadratic programming.
Mostly interested in mean-variance portfolio and MORE importantly
style based analysis.
Thanks in advance for the help. - Gabe


From markleeds at verizon.net  Mon Apr  7 20:06:32 2008
From: markleeds at verizon.net (markleeds at verizon.net)
Date: Mon, 07 Apr 2008 13:06:32 -0500 (CDT)
Subject: [R-SIG-Finance] Optimization Book with R. (Style Based Analysis,
	MV Portfoli
Message-ID: <6067365.7425071207591592220.JavaMail.root@vms226.mailsrvcs.net>

>From: gabe plaxico <gplaxico at gmail.com>
>Date: 2008/04/07 Mon PM 12:57:00 CDT
>To: r-sig-finance at stat.math.ethz.ch
>Subject: [R-SIG-Finance] Optimization Book with R. (Style Based Analysis,	MV Portfolio)

I know of 2 books but neither are R specific
and one is S+ specific.

1) introduction to modern portfolio optimization
with nuopt, s-plus and s+bayes.

2) portfolio construction and risk budgeting is
more of a theoretical ( also applied in
the sense of it gives examples )  book without
specific commands.

Both are by Bernd Scherer and the
first is Co-Auhored by Douglass Martin. 
They are both decent but I was looking for an example yesterday of the best way to include the notional in
a portfolio optimization ( i.e: the maximum
dollars one wants to spend on the long and short side
of a market neutral portfolio ) and I couldn't
find anything relevant in either. I'm not
saying the books aren't good but I was
hoping to find a simple example and I didn't.

2) gets pretty theoretical in terms of
handling various issues ( downside risk,
transaction cost error etc ).

for 1) you really need S+ in my opinion.



                               








>Anyone have any suggestion on a good book for optimization using R?
>Specifically looking for material addressing linear/quadratic programming.
>Mostly interested in mean-variance portfolio and MORE importantly
>style based analysis.
>Thanks in advance for the help. - Gabe
>
>_______________________________________________
>R-SIG-Finance at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>-- Subscriber-posting only. 
>-- If you want to post, subscribe first.


From ngottlieb at marinercapital.com  Mon Apr  7 22:08:39 2008
From: ngottlieb at marinercapital.com (ngottlieb at marinercapital.com)
Date: Mon, 7 Apr 2008 16:08:39 -0400
Subject: [R-SIG-Finance] Optimization Book with R. (Style Based Analysis,
	MV Portfolio)
In-Reply-To: <8c77486c0804071057g52cb2b76n703e48391d60317a@mail.gmail.com>
References: <8c77486c0804071057g52cb2b76n703e48391d60317a@mail.gmail.com>
Message-ID: <0946E293C7C22A45A0E33BA14FAA8D8801DBD0AD@500MAIL.goldbox.com>

Your best starting point if you want to do style based analysis is look
At W.F. Sharpe's 1992 paper on Style Analysis. A web search should 
On aforementioned should bring on the paper reference.

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of gabe
plaxico
Sent: Monday, April 07, 2008 1:57 PM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] Optimization Book with R. (Style Based
Analysis,MV Portfolio)

Anyone have any suggestion on a good book for optimization using R?
Specifically looking for material addressing linear/quadratic
programming.
Mostly interested in mean-variance portfolio and MORE importantly style
based analysis.
Thanks in advance for the help. - Gabe

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. 
-- If you want to post, subscribe first.
--------------------------------------------------------



This information is being sent at the recipient's reques...{{dropped:16}}


From peter at braverock.com  Mon Apr  7 22:26:06 2008
From: peter at braverock.com (Peter Carl)
Date: Mon, 07 Apr 2008 15:26:06 -0500
Subject: [R-SIG-Finance] Optimization Book with R. (Style Based	Analysis,
	MV Portfolio)
In-Reply-To: <8c77486c0804071057g52cb2b76n703e48391d60317a@mail.gmail.com>
References: <8c77486c0804071057g52cb2b76n703e48391d60317a@mail.gmail.com>
Message-ID: <1207599966.5008.1.camel@localhost>

On Mon, 2008-04-07 at 13:57 -0400, gabe plaxico wrote:
> Anyone have any suggestion on a good book for optimization using R?
> Specifically looking for material addressing linear/quadratic programming.
> Mostly interested in mean-variance portfolio and MORE importantly
> style based analysis.

Take a look at:

http://www.nabble.com/Implementing-Sharpe%
27s-style-analysis-with-solve.QP-td15681250.html#a15681250

... and let me know if it's helpful at all.

pcc

-- 
Peter Carl
145 Scottswood Rd
Riverside, IL 60546
312 307 6346
http://www.braverock.com/~peter


From max.berger at edhec.com  Mon Apr  7 22:26:18 2008
From: max.berger at edhec.com (Max BERGER)
Date: Mon, 7 Apr 2008 22:26:18 +0200
Subject: [R-SIG-Finance] Optimization Book with R. (Style Based Analysis,
	MV Portfolio)
Message-ID: <F46D8668785967429D15C48EA4E10DFE127DC8@edhec-mailback1.edhecmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080407/28b11559/attachment.pl 

From Christian.Prinoth at epsilonsgr.it  Tue Apr  8 09:15:36 2008
From: Christian.Prinoth at epsilonsgr.it (Christian Prinoth)
Date: Tue, 8 Apr 2008 09:15:36 +0200
Subject: [R-SIG-Finance] Optimization Book with R. (Style Based Analysis,
	MV Portfoli
In-Reply-To: <6067365.7425071207591592220.JavaMail.root@vms226.mailsrvcs.net >
References: <6067365.7425071207591592220.JavaMail.root@vms226.mailsrvcs.net>
Message-ID: <8D64D4652EB17048B874B0503309CFCA025E4516@epsilon2003.epsilonsgr.it>

This paper:

http://www.stanford.edu/~boyd/papers/portfolio.html

Contains some useful advice on doing what you want with standard tools
like solve.QP

-----Original Message-----
They are both decent but I was looking for an example yesterday of the
best way to include the notional in a portfolio optimization ( i.e: the
maximum dollars one wants to spend on the long and short side of a
market neutral portfolio ) and I couldn't find anything relevant in
either. I'm not saying the books aren't good but I was hoping to find a
simple example and I didn't.

DISCLAIMER:\ L'utilizzo non autorizzato del presente mes...{{dropped:16}}


From sylvain.archenault at sgcib.com  Tue Apr  8 09:25:57 2008
From: sylvain.archenault at sgcib.com (sylvain.archenault at sgcib.com)
Date: Tue, 8 Apr 2008 09:25:57 +0200
Subject: [R-SIG-Finance] Problem with GarchFit [NC]
In-Reply-To: <12492922.1550921207611224341.JavaMail.root@vms075.mailsrvcs.net>
Message-ID: <OFB86F4EB5.F3B033FB-ONC1257425.00255567-C1257425.0028D431@fr.world.socgen>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080408/c8e74d02/attachment.pl 

From berekket at gmail.com  Fri Apr 11 19:04:34 2008
From: berekket at gmail.com (bereket weldeslassie)
Date: Fri, 11 Apr 2008 11:04:34 -0600
Subject: [R-SIG-Finance] Fwd: time series regression
In-Reply-To: <4bc7c8760804101356o56e3c698q6fa5f6b7fb4d267@mail.gmail.com>
References: <4bc7c8760804101356o56e3c698q6fa5f6b7fb4d267@mail.gmail.com>
Message-ID: <4bc7c8760804111004s6f0e4e95g7bb38780f9b81b33@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080411/fdc7f201/attachment.pl 

From mrmelchi at grupobica.com.ar  Sat Apr 12 14:33:10 2008
From: mrmelchi at grupobica.com.ar (Mario Melchiori)
Date: Sat, 12 Apr 2008 09:33:10 -0300
Subject: [R-SIG-Finance]  CreditRisk+
Message-ID: <3bb54b1d0804120533q8bba1b8rcc0ae44acc936503@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080412/22ec2a1d/attachment.pl 

From stigler3 at etu.unige.ch  Sat Apr 12 15:22:10 2008
From: stigler3 at etu.unige.ch (stigler3 at etu.unige.ch)
Date: Sat, 12 Apr 2008 15:22:10 +0200
Subject: [R-SIG-Finance] Fwd: time series regression
In-Reply-To: <4bc7c8760804111004s6f0e4e95g7bb38780f9b81b33@mail.gmail.com>
References: <4bc7c8760804101356o56e3c698q6fa5f6b7fb4d267@mail.gmail.com>
	<4bc7c8760804111004s6f0e4e95g7bb38780f9b81b33@mail.gmail.com>
Message-ID: <20080412152210.gl1hkheyo0k80ogc@www.etu.unige.ch>

Hello

For the analysis of multivariate time series use package vars for VAR  
models and urca for VECM models, unit root and cointegration tests.  
The author of these package wrote also a  book "analysis of integrated  
and cointegrated time series with R" which can be usefull. See  
http://pfaffikus.de/

Matthieu



Quoting bereket weldeslassie <berekket at gmail.com>:

>  Hi Everyone,
> I am doing a time series regression (one dependent time series variable, 6
> independent time series variables and 32 annual observations). I have the
> problem of cointegration, autocorrelation and multicollinearity. I am
> considering an error correction model of the form:
> diff(lnY(t))=a+b1*lnY(t-1)+b2*lnX(t-1)+b3*diff(lnX(t))+error
> and not able to solve all problems.
> Any suggestion how to built a good model that solves these problems? I
> appreciate your help.
> Thanks,
> Bereket
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From mmiklovic at yahoo.com  Sun Apr 13 11:40:42 2008
From: mmiklovic at yahoo.com (michal miklovic)
Date: Sun, 13 Apr 2008 02:40:42 -0700 (PDT)
Subject: [R-SIG-Finance] Garch and multivariate garch
Message-ID: <396789.64227.qm@web50110.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080413/a1c29803/attachment.pl 

From binabina at bellsouth.net  Sun Apr 13 13:49:54 2008
From: binabina at bellsouth.net (zubin)
Date: Sun, 13 Apr 2008 07:49:54 -0400
Subject: [R-SIG-Finance] an obvious question
Message-ID: <4801F362.8090701@bellsouth.net>

Hello, this may be a question that cannot be answered.  But using 
advanced data mining algorithms that are in R and merging with real time 
data feeds - is anyone out there actually making any excess  returns 
(adjusted for risk) in the markets?


From ezivot at u.washington.edu  Sun Apr 13 18:23:26 2008
From: ezivot at u.washington.edu (Eric Zivot)
Date: Sun, 13 Apr 2008 09:23:26 -0700 (PDT)
Subject: [R-SIG-Finance] Garch and multivariate garch
In-Reply-To: <396789.64227.qm@web50110.mail.re2.yahoo.com>
Message-ID: <Pine.LNX.4.43.0804130923260.3430@hymn31.u.washington.edu>

The Bauwens survey paper in the Journal of Applied Econometrics is very good, but it lacks any practical examples of actually estimating multivariate garch models. In fact, I don't know of any survey paper that discusses the real life practical issues of estimating multivariate garch models. A good intuitive guide to forecasting correlation is in Carol alexander's book Market Models. Unfortunately, she spends a lot of time plugging her orthogonal garch model which is rather problematic in practice. A big problem in assessing the accuracy of estimating something like a conditional correlation is that the "true" time varying correlation is not observable so that the output of a multivariate garch model cannot be compared to an "actual" correlation to assess forecasting accuracy. One can try to follow Andersen and Bollerslev and try to compare a garch correlation forecast to a realized correlation 
computed from high frequency data. However, this is also fraught with problems as it is not clear how one is supposed to compute realized correlation. I have a paper under preparation that looks at evaluating multivariate garch models using realized correlation. Unfortunately, none of the typical multivariate garch models work very well - especially the dynamic conditional correlation model of Engle. This is often the worst model! I have a reference list of some empirical multivariate garch papers and I'll post some references later this week.


****************************************************************
*  Eric Zivot                  			               *
*  Professor and Gary Waterman Distinguished Scholar           *
*  Department of Economics                                     *
*  Box 353330                  email:  ezivot at u.washington.edu *
*  University of Washington    phone:  206-543-6715            *
*  Seattle, WA 98195-3330                                      *                                                           *
*  www:  http://faculty.washington.edu/ezivot                  *
****************************************************************

On Sun, 13 Apr 2008, michal miklovic wrote:

> Hi,
>
> I am quite familiar with univariate garch models but, unfortunately, not an expert on multivariate garch models. However, I would recommend that you have a look at this paper:
> Bauwens, Laurent, Rombouts (2006): Multivariate garch models: a survey, J. of applied econometrics 21, pp. 79 - 109.
> Chapter 3 in the following book provides a highly readable and not very technical description of the dynamic conditional correlation multivariate garch model of Engle (2002), which has been implemented in several statistical software packages but I am not not aware of an implementation in R.
> Christoffersen (2003): Elements of financial risk management, Academic Press
>
> The Engle reference is:
> Engle (2002): Dynamic conditional correlation - a simple class of multivariate garch models, J. of business and economic statistics 20, pp. 339 - 350.
>
> Hope this helps.
>
> Best regards,
>
> Michal
>
>
>
> ----- Original Message ----
> From: Matthieu Boyer <matthieudm.boyer at gmail.com>
> To: r-sig-finance at stat.math.ethz.ch
> Sent: Sunday, March 30, 2008 12:40:40 PM
> Subject: [R-SIG-Finance] Garch and multivariate garch
>
> Hello everybody,
> I know that there is a lot of messages regarding this topic but it starts
> becoming a wonderful mess!
> I just wanted to know if I can chat some day with somebody who knows garch
> models and more particularly multivariate garch model.
> I'm a student and I'm working with a big insurance company on volatility
> estimation and the next step is to work on correlation.
> I've already done some research on the web and I've found 2 methods:
> -first, use a little trick with an univariate garch (
> http://www.burns-stat.com/pages/Working/multgarchuni.pdf)
> -the second method consists in using mgarchbekk package.
> As the whole theory about garch is quite recent, I don't have any hindsight
> on it!
>
> I hope that someone will help me!
> Have a good day everybody!
> Matt
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
>
>
>
>
> __________________________________________________
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From manojsw at gmail.com  Mon Apr 14 14:30:06 2008
From: manojsw at gmail.com (Manoj)
Date: Mon, 14 Apr 2008 22:30:06 +1000
Subject: [R-SIG-Finance] question on zoo data manipulation
Message-ID: <829e6c8a0804140530o78977f2te561bf38c92ef974@mail.gmail.com>

Hi Zoo-experts,
      I am working on the data-set below.

Ticker	Date	BrokerName	Acc_Yr	Measure	lag
XXX	20080320	BRK1	200806	2.2	0
XXX	20080320	BRK1	200906	2.5	0
XXX	20080320	BRK2	200806	2.3	0
XXX	20080320	BRK2	200906	2.8	0
XXX	20080320	BRK3	200806	3.3	0
XXX	20080218	BRK1	200806	2.2	1
XXX	20080218	BRK1	200906	2.5	1
XXX	20080218	BRK2	200806	2.4	1
XXX	20080218	BRK2	200906	2.8	1



Using zoo object, Is there a quicker/efficient way of manipulating the
data as per following criteria?

1) For any given date/lag - compute mean of column "measure" grouped
by different broker & different accounting year?
          so the output data-set should look like:

Ticker 	Date	Mean Measure	Acc_Yr	Lag
XXX	20080320	2.6	200806	0

2) For any lag >= 1, calculate returns on  aggregate "measure"
constrained on "intersection" of broker-name across lag 0 & lag 1 (so
BRK3 should drop out) ?

i.e:  the intermediate data-set should look like

Ticker 	Date	Mean Measure	Acc_Yr	Lag
XXX	20080320	2.25	200806	0
XXX	20080318	2.3	200806	1


Note that for 200806, the mean changes from 2.6 as measured above to
2.25 (since BRK3 is dropped in calculation.  The final data-set should
then be:

Ticker 	Date	Pct_Change	Acc_Yr	Lag
XXX	20080218	0.02	200806	1

--------------------

I can accomplish the results using a combination of tapply &
subsetting the data-set for each lag but I thought this kind of
data-structure is ideal for zoo manipulation, hence the help request.

Thanks in Advance.

Manoj


From katchmalik at gmail.com  Mon Apr 14 20:04:55 2008
From: katchmalik at gmail.com (Shlomo Katchmalik)
Date: Mon, 14 Apr 2008 14:04:55 -0400
Subject: [R-SIG-Finance] 130/30 Portfolio Optimization
Message-ID: <38a7b0c80804141104t7f7f9bc1wde65242a795d3b5c@mail.gmail.com>

Hi All,

Does anybody have an idea as to how one would find an optimal 130/30
portfolio using R?

More specifically, for a given return covariance matrix Q, vector of
expected security returns mu, and risk tolerance tau, the problem is
to find the portfolio vector x that minimizes

x' * Q * x - tau * mu' * x

subject to the following constraints:
 A * x = b for given constraint matrix A and vector b,
 x >= L,
 x <= U,
 the sum of the positive elements of x is 1.3,
 the sum of the negative elements of x is -0.3,

If not for the last two nonlinear constraints, solve.QP in
library(quadprog) would be applicable.  Unfortunately, these two
constraints are central to the problem.

I'd appreciate any help.

Thanks,
Shlomo.


From guy.yollin at rotellacapital.com  Mon Apr 14 20:34:34 2008
From: guy.yollin at rotellacapital.com (Guy Yollin)
Date: Mon, 14 Apr 2008 14:34:34 -0400
Subject: [R-SIG-Finance] 130/30 Portfolio Optimization
In-Reply-To: <38a7b0c80804141104t7f7f9bc1wde65242a795d3b5c@mail.gmail.com>
References: <38a7b0c80804141104t7f7f9bc1wde65242a795d3b5c@mail.gmail.com>
Message-ID: <E634AF2410E42246A35865D8C0C784D9CD9AD8@MI8NYCMAIL09.Mi8.com>

Hi Shlomo,

On Feb 5th, David Basterfield gave a webcast on the differential
evolution algorithm (http://www.icsi.berkeley.edu/~storn/code.html) in
which he works through a few 115/15 portfolio optimization examples.
The webcast can be downloaded from the events area of the Insightful
website (www.insightful.com).

The DE algorithm is quite elegant and has been implemented in the
package DEoptim.

Best,

-- G



-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Shlomo
Katchmalik
Sent: Monday, April 14, 2008 11:05 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] 130/30 Portfolio Optimization

Hi All,

Does anybody have an idea as to how one would find an optimal 130/30
portfolio using R?

More specifically, for a given return covariance matrix Q, vector of
expected security returns mu, and risk tolerance tau, the problem is
to find the portfolio vector x that minimizes

x' * Q * x - tau * mu' * x

subject to the following constraints:
 A * x = b for given constraint matrix A and vector b,
 x >= L,
 x <= U,
 the sum of the positive elements of x is 1.3,
 the sum of the negative elements of x is -0.3,

If not for the last two nonlinear constraints, solve.QP in
library(quadprog) would be applicable.  Unfortunately, these two
constraints are central to the problem.

I'd appreciate any help.

Thanks,
Shlomo.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. 
-- If you want to post, subscribe first.


From berekket at gmail.com  Mon Apr 14 21:39:09 2008
From: berekket at gmail.com (bereket weldeslassie)
Date: Mon, 14 Apr 2008 13:39:09 -0600
Subject: [R-SIG-Finance] time series regression (demand for higher education)
Message-ID: <4bc7c8760804141239h62c68bc9i5b09c2883f9f1cd5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080414/1b53d155/attachment.pl 

From spencer.graves at pdf.com  Mon Apr 14 22:28:03 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 14 Apr 2008 13:28:03 -0700
Subject: [R-SIG-Finance] time series regression (demand for higher
	education)
In-Reply-To: <4bc7c8760804141239h62c68bc9i5b09c2883f9f1cd5@mail.gmail.com>
References: <4bc7c8760804141239h62c68bc9i5b09c2883f9f1cd5@mail.gmail.com>
Message-ID: <4803BE53.9050800@pdf.com>

      1.  Did you not receive a reply yesterday from Matthieu Stigler, 
reading as follows: 

For the analysis of multivariate time series use package vars for VAR 
models and urca for VECM models, unit root and cointegration tests. 
The author of these package wrote also a  book "analysis of integrated 
and cointegrated time series with R" which can be usefull. See 
http://pfaffikus.de/


      2.  Before posting the same question again, PLEASE do read the 
posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.  If 
you provide a self-contained example, you increase the pool of potential 
respondents by a factor of 10 or 100, because even people who don't know 
the answer can copy your pseudo-code from your email into R and take you 
to the next step. 


      Hope this helps. 
      Spencer

bereket weldeslassie wrote:
> Dear All,
> I am doing a time series regression with one dependent time series variable,
> 7 independent time series variables and 32 annual observations in an attempt
> to model the demand for higher education. The dependent variable is
> Enrollment and the independent variables are like tuition, income and so on.
> The main purpose of my analysis is to investigate the impact of economic
> factors (like tuition and income) on enrollment. I am considering an error
> correction model of the form:
> diff(lnY(t))=a+b1*lnY(t-1)+b2*lnX(t-1)+b3*diff(lnX(t))+error
> to model the demand and solve the problem of cointegration, autocorrelation
> and multicollinearity. But this is not been able to solve all these
> problems. Is that a right way to estimate the elacticities?
> Any suggestion how to built a good model that solves these problems? I
> appreciate your help.
> Thanks,
> Bereket
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. 
> -- If you want to post, subscribe first.
>


From Achim.Zeileis at wu-wien.ac.at  Mon Apr 14 23:39:31 2008
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 14 Apr 2008 23:39:31 +0200 (CEST)
Subject: [R-SIG-Finance] question on zoo data manipulation
In-Reply-To: <829e6c8a0804140530o78977f2te561bf38c92ef974@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0804142335020.1351-100000@disco.wu-wien.ac.at>

On Mon, 14 Apr 2008, Manoj wrote:

> Hi Zoo-experts,
>       I am working on the data-set below.
>
> Ticker	Date	BrokerName	Acc_Yr	Measure	lag
> XXX	20080320	BRK1	200806	2.2	0
> XXX	20080320	BRK1	200906	2.5	0
> XXX	20080320	BRK2	200806	2.3	0
> XXX	20080320	BRK2	200906	2.8	0
> XXX	20080320	BRK3	200806	3.3	0
> XXX	20080218	BRK1	200806	2.2	1
> XXX	20080218	BRK1	200906	2.5	1
> XXX	20080218	BRK2	200806	2.4	1
> XXX	20080218	BRK2	200906	2.8	1

The data is not really a straightforward time series but has more
structure, like a panel data set. Hence, I wouldn't try to represent it in
zoo in its un-aggregated form. Instead I would put it into a data.frame
using appropriate classes for the colums, e.g., "Date" for the Date and
"factor" for the BrokerName etc.

Then I would use the aggregate() method for data.frames to accomplish the
aggregation you look for. You can then collect various aggregations of
your data in a zoo object (if you've got unique Dates after aggregation).

hth,
Z

>
>
> Using zoo object, Is there a quicker/efficient way of manipulating the
> data as per following criteria?
>
> 1) For any given date/lag - compute mean of column "measure" grouped
> by different broker & different accounting year?
>           so the output data-set should look like:
>
> Ticker 	Date	Mean Measure	Acc_Yr	Lag
> XXX	20080320	2.6	200806	0
>
> 2) For any lag >= 1, calculate returns on  aggregate "measure"
> constrained on "intersection" of broker-name across lag 0 & lag 1 (so
> BRK3 should drop out) ?
>
> i.e:  the intermediate data-set should look like
>
> Ticker 	Date	Mean Measure	Acc_Yr	Lag
> XXX	20080320	2.25	200806	0
> XXX	20080318	2.3	200806	1
>
>
> Note that for 200806, the mean changes from 2.6 as measured above to
> 2.25 (since BRK3 is dropped in calculation.  The final data-set should
> then be:
>
> Ticker 	Date	Pct_Change	Acc_Yr	Lag
> XXX	20080218	0.02	200806	1
>
> --------------------
>
> I can accomplish the results using a combination of tapply &
> subsetting the data-set for each lag but I thought this kind of
> data-structure is ideal for zoo manipulation, hence the help request.
>
> Thanks in Advance.
>
> Manoj
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
>


From ggrothendieck at gmail.com  Tue Apr 15 01:51:39 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 14 Apr 2008 19:51:39 -0400
Subject: [R-SIG-Finance] question on zoo data manipulation
In-Reply-To: <829e6c8a0804140530o78977f2te561bf38c92ef974@mail.gmail.com>
References: <829e6c8a0804140530o78977f2te561bf38c92ef974@mail.gmail.com>
Message-ID: <971536df0804141651r5a9caa40l3c5660d65c81715b@mail.gmail.com>

Is lag always 0 or 1?

On Mon, Apr 14, 2008 at 8:30 AM, Manoj <manojsw at gmail.com> wrote:
> Hi Zoo-experts,
>      I am working on the data-set below.
>
> Ticker  Date    BrokerName      Acc_Yr  Measure lag
> XXX     20080320        BRK1    200806  2.2     0
> XXX     20080320        BRK1    200906  2.5     0
> XXX     20080320        BRK2    200806  2.3     0
> XXX     20080320        BRK2    200906  2.8     0
> XXX     20080320        BRK3    200806  3.3     0
> XXX     20080218        BRK1    200806  2.2     1
> XXX     20080218        BRK1    200906  2.5     1
> XXX     20080218        BRK2    200806  2.4     1
> XXX     20080218        BRK2    200906  2.8     1
>
>
>
> Using zoo object, Is there a quicker/efficient way of manipulating the
> data as per following criteria?
>
> 1) For any given date/lag - compute mean of column "measure" grouped
> by different broker & different accounting year?
>          so the output data-set should look like:
>
> Ticker  Date    Mean Measure    Acc_Yr  Lag
> XXX     20080320        2.6     200806  0
>
> 2) For any lag >= 1, calculate returns on  aggregate "measure"
> constrained on "intersection" of broker-name across lag 0 & lag 1 (so
> BRK3 should drop out) ?
>
> i.e:  the intermediate data-set should look like
>
> Ticker  Date    Mean Measure    Acc_Yr  Lag
> XXX     20080320        2.25    200806  0
> XXX     20080318        2.3     200806  1
>
>
> Note that for 200806, the mean changes from 2.6 as measured above to
> 2.25 (since BRK3 is dropped in calculation.  The final data-set should
> then be:
>
> Ticker  Date    Pct_Change      Acc_Yr  Lag
> XXX     20080218        0.02    200806  1
>
> --------------------
>
> I can accomplish the results using a combination of tapply &
> subsetting the data-set for each lag but I thought this kind of
> data-structure is ideal for zoo manipulation, hence the help request.
>
> Thanks in Advance.
>
> Manoj
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From manojsw at gmail.com  Tue Apr 15 02:39:34 2008
From: manojsw at gmail.com (Manoj)
Date: Tue, 15 Apr 2008 10:39:34 +1000
Subject: [R-SIG-Finance] question on zoo data manipulation
In-Reply-To: <971536df0804141651r5a9caa40l3c5660d65c81715b@mail.gmail.com>
References: <829e6c8a0804140530o78977f2te561bf38c92ef974@mail.gmail.com>
	<971536df0804141651r5a9caa40l3c5660d65c81715b@mail.gmail.com>
Message-ID: <829e6c8a0804141739t4c732033udea1958e80f371c0@mail.gmail.com>

Thanks for your suggestion Achim.

Gabor,
       No lag takes a value range of 0 ~ 12 - and is tied to date.
20080320 take 0, a one month lag take the value of 20080218 and so on.

       Please let me know if you need more info.

Many thanks.

Manoj


On 4/15/08, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Is lag always 0 or 1?
>
> On Mon, Apr 14, 2008 at 8:30 AM, Manoj <manojsw at gmail.com> wrote:
> > Hi Zoo-experts,
> >      I am working on the data-set below.
> >
> > Ticker  Date    BrokerName      Acc_Yr  Measure lag
> > XXX     20080320        BRK1    200806  2.2     0
> > XXX     20080320        BRK1    200906  2.5     0
> > XXX     20080320        BRK2    200806  2.3     0
> > XXX     20080320        BRK2    200906  2.8     0
> > XXX     20080320        BRK3    200806  3.3     0
> > XXX     20080218        BRK1    200806  2.2     1
> > XXX     20080218        BRK1    200906  2.5     1
> > XXX     20080218        BRK2    200806  2.4     1
> > XXX     20080218        BRK2    200906  2.8     1
> >
> >
> >
> > Using zoo object, Is there a quicker/efficient way of manipulating the
> > data as per following criteria?
> >
> > 1) For any given date/lag - compute mean of column "measure" grouped
> > by different broker & different accounting year?
> >          so the output data-set should look like:
> >
> > Ticker  Date    Mean Measure    Acc_Yr  Lag
> > XXX     20080320        2.6     200806  0
> >
> > 2) For any lag >= 1, calculate returns on  aggregate "measure"
> > constrained on "intersection" of broker-name across lag 0 & lag 1 (so
> > BRK3 should drop out) ?
> >
> > i.e:  the intermediate data-set should look like
> >
> > Ticker  Date    Mean Measure    Acc_Yr  Lag
> > XXX     20080320        2.25    200806  0
> > XXX     20080318        2.3     200806  1
> >
> >
> > Note that for 200806, the mean changes from 2.6 as measured above to
> > 2.25 (since BRK3 is dropped in calculation.  The final data-set should
> > then be:
> >
> > Ticker  Date    Pct_Change      Acc_Yr  Lag
> > XXX     20080218        0.02    200806  1
> >
> > --------------------
> >
> > I can accomplish the results using a combination of tapply &
> > subsetting the data-set for each lag but I thought this kind of
> > data-structure is ideal for zoo manipulation, hence the help request.
> >
> > Thanks in Advance.
> >
> > Manoj
> >
> > _______________________________________________
> > R-SIG-Finance at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only.
> > -- If you want to post, subscribe first.
> >
>


From tplate at acm.org  Tue Apr 15 08:59:02 2008
From: tplate at acm.org (Tony Plate)
Date: Tue, 15 Apr 2008 00:59:02 -0600
Subject: [R-SIG-Finance] an obvious question
In-Reply-To: <4801F362.8090701@bellsouth.net>
References: <4801F362.8090701@bellsouth.net>
Message-ID: <48045236.9070501@acm.org>

If you're not so concerned with the "that are in R" part of your question, the poster child for such success is Jim Simon's Medallion fund at Rennaissance: http://www.bloomberg.com/apps/news?pid=20601213&sid=aq33M3X795vQ&refer=home

-- Tony Plate

zubin wrote:
> Hello, this may be a question that cannot be answered.  But using 
> advanced data mining algorithms that are in R and merging with real time 
> data feeds - is anyone out there actually making any excess  returns 
> (adjusted for risk) in the markets?
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. 
> -- If you want to post, subscribe first.
>


From Mama_Attiglah at ssga.com  Tue Apr 15 10:45:43 2008
From: Mama_Attiglah at ssga.com (Attiglah, Mama)
Date: Tue, 15 Apr 2008 09:45:43 +0100
Subject: [R-SIG-Finance] 130/30 Portfolio Optimization
In-Reply-To: <E634AF2410E42246A35865D8C0C784D9CD9AD8@MI8NYCMAIL09.Mi8.com>
Message-ID: <D84557769CE9ED47AC31686731990DCB0F996199@INCLCW03A.corp.statestr.com>

This is a simple non-linear optimisation with linear constraints in a
convex set. Go to www.r-project.org, download the package Rdonlp2, and
use the optimiser donlp2. 
I would advise you to start with initial values being half way through
the feasible set of each of the control variables( the weights), then
reuse the optimal weights as the initial values in order to secure st
stability of the optimum. 
Hope this will help.


-----
Mama Attiglah, PhD
Quantitative Research analyst
Advanced Research Center
State Street Bank
+44(0)20 7698 6290 (Direct Line)
+44 (0)207 004 2968 (Direct Fax)
Please visit our Web site at 
www.ssga.com

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Guy Yollin
Sent: 14 April 2008 19:35
To: Shlomo Katchmalik; r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] 130/30 Portfolio Optimization

Hi Shlomo,

On Feb 5th, David Basterfield gave a webcast on the differential
evolution algorithm (http://www.icsi.berkeley.edu/~storn/code.html) in
which he works through a few 115/15 portfolio optimization examples.
The webcast can be downloaded from the events area of the Insightful
website (www.insightful.com).

The DE algorithm is quite elegant and has been implemented in the
package DEoptim.

Best,

-- G



-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Shlomo
Katchmalik
Sent: Monday, April 14, 2008 11:05 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] 130/30 Portfolio Optimization

Hi All,

Does anybody have an idea as to how one would find an optimal 130/30
portfolio using R?

More specifically, for a given return covariance matrix Q, vector of
expected security returns mu, and risk tolerance tau, the problem is
to find the portfolio vector x that minimizes

x' * Q * x - tau * mu' * x

subject to the following constraints:
 A * x = b for given constraint matrix A and vector b,
 x >= L,
 x <= U,
 the sum of the positive elements of x is 1.3,
 the sum of the negative elements of x is -0.3,

If not for the last two nonlinear constraints, solve.QP in
library(quadprog) would be applicable.  Unfortunately, these two
constraints are central to the problem.

I'd appreciate any help.

Thanks,
Shlomo.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. 
-- If you want to post, subscribe first.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. 
-- If you want to post, subscribe first.


From Christian.Prinoth at epsilonsgr.it  Tue Apr 15 11:03:40 2008
From: Christian.Prinoth at epsilonsgr.it (Christian Prinoth)
Date: Tue, 15 Apr 2008 11:03:40 +0200
Subject: [R-SIG-Finance] 130/30 Portfolio Optimization
In-Reply-To: <38a7b0c80804141104t7f7f9bc1wde65242a795d3b5c@mail.gmail.com>
References: <38a7b0c80804141104t7f7f9bc1wde65242a795d3b5c@mail.gmail.com>
Message-ID: <8D64D4652EB17048B874B0503309CFCA025E45F8@epsilon2003.epsilonsgr.it>

A few days ago I have posted a link to a paper describing techniques to
do what you want with solve.QP. Please search in the archive, I do not
have the link handy right now.

Chris

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Shlomo
Katchmalik
Sent: Monday, April 14, 2008 20:05
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] 130/30 Portfolio Optimization

Hi All,

Does anybody have an idea as to how one would find an optimal 130/30
portfolio using R?

More specifically, for a given return covariance matrix Q, vector of
expected security returns mu, and risk tolerance tau, the problem is to
find the portfolio vector x that minimizes

x' * Q * x - tau * mu' * x

subject to the following constraints:
 A * x = b for given constraint matrix A and vector b,  x >= L,  x <= U,
the sum of the positive elements of x is 1.3,  the sum of the negative
elements of x is -0.3,

If not for the last two nonlinear constraints, solve.QP in
library(quadprog) would be applicable.  Unfortunately, these two
constraints are central to the problem.

I'd appreciate any help.

Thanks,
Shlomo.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.

DISCLAIMER:\ L'utilizzo non autorizzato del presente mes...{{dropped:16}}


From ggrothendieck at gmail.com  Tue Apr 15 14:56:46 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 15 Apr 2008 08:56:46 -0400
Subject: [R-SIG-Finance] question on zoo data manipulation
In-Reply-To: <829e6c8a0804140530o78977f2te561bf38c92ef974@mail.gmail.com>
References: <829e6c8a0804140530o78977f2te561bf38c92ef974@mail.gmail.com>
Message-ID: <971536df0804150556h5a71312aof0889cf7698eebab@mail.gmail.com>

This does not really use zoo in any significant way since it
does not become a time series until the last line of f but
here is a solution that does use zoo in that one last line.

We use by to split up the data frame with a function f.
In f, br intersects the lag0 and lag1 brokers and then we
subset x according to those lines having a broker in br.
We then take the means, convert the series to zoo and
perform diff.zoo on it.

There are some aspects of the problem that were not defined
such as whether to use lag 1 to compare lag 3 if there is no
lag 2 and we did that here but that could be changed by using
the lag as the time index.

We have also dumped out the data frame, DF, using dput to make
it easier to reproduce the solution.

DF <- structure(list(Ticker = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L), .Label = "XXX", class = "factor"), Date = c(20080320L,
20080320L, 20080320L, 20080320L, 20080320L, 20080218L, 20080218L,
20080218L, 20080218L), BrokerName = structure(c(1L, 1L, 2L, 2L,
3L, 1L, 1L, 2L, 2L), .Label = c("BRK1", "BRK2", "BRK3"), class = "factor"),
    Acc_Yr = c(200806L, 200906L, 200806L, 200906L, 200806L, 200806L,
    200906L, 200806L, 200906L), Measure = c(2.2, 2.5, 2.3, 2.8,
    3.3, 2.2, 2.5, 2.4, 2.8), lag = c(0L, 0L, 0L, 0L, 0L, 1L,
    1L, 1L, 1L)), .Names = c("Ticker", "Date", "BrokerName",
"Acc_Yr", "Measure", "lag"), class = "data.frame", row.names = c(NA,
-9L))

library(zoo)

f <- function(x) {
    br <- intersect(x[x$lag == 0, "BrokerName"], x[x$lag == 1, "BrokerName"])
    sb <- subset(x, BrokerName %in% br)
    ag <- aggregate(sb["Measure"], sb[c(1, 2, 4, 6)], mean)
    transform(tail(ag, -1), Measure =
        coredata(diff(zoo(ag$Measure), arithmetic = FALSE) - 1))
}
do.call("rbind", by(DF, DF[c(1, 4)], f))


On Mon, Apr 14, 2008 at 8:30 AM, Manoj <manojsw at gmail.com> wrote:
> Hi Zoo-experts,
>      I am working on the data-set below.
>
> Ticker  Date    BrokerName      Acc_Yr  Measure lag
> XXX     20080320        BRK1    200806  2.2     0
> XXX     20080320        BRK1    200906  2.5     0
> XXX     20080320        BRK2    200806  2.3     0
> XXX     20080320        BRK2    200906  2.8     0
> XXX     20080320        BRK3    200806  3.3     0
> XXX     20080218        BRK1    200806  2.2     1
> XXX     20080218        BRK1    200906  2.5     1
> XXX     20080218        BRK2    200806  2.4     1
> XXX     20080218        BRK2    200906  2.8     1
>
>
>
> Using zoo object, Is there a quicker/efficient way of manipulating the
> data as per following criteria?
>
> 1) For any given date/lag - compute mean of column "measure" grouped
> by different broker & different accounting year?
>          so the output data-set should look like:
>
> Ticker  Date    Mean Measure    Acc_Yr  Lag
> XXX     20080320        2.6     200806  0
>
> 2) For any lag >= 1, calculate returns on  aggregate "measure"
> constrained on "intersection" of broker-name across lag 0 & lag 1 (so
> BRK3 should drop out) ?
>
> i.e:  the intermediate data-set should look like
>
> Ticker  Date    Mean Measure    Acc_Yr  Lag
> XXX     20080320        2.25    200806  0
> XXX     20080318        2.3     200806  1
>
>
> Note that for 200806, the mean changes from 2.6 as measured above to
> 2.25 (since BRK3 is dropped in calculation.  The final data-set should
> then be:
>
> Ticker  Date    Pct_Change      Acc_Yr  Lag
> XXX     20080218        0.02    200806  1
>
> --------------------
>
> I can accomplish the results using a combination of tapply &
> subsetting the data-set for each lag but I thought this kind of
> data-structure is ideal for zoo manipulation, hence the help request.
>
> Thanks in Advance.
>
> Manoj
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From futur.dorko at gmail.com  Tue Apr 15 21:27:39 2008
From: futur.dorko at gmail.com (Stefano Balietti)
Date: Tue, 15 Apr 2008 21:27:39 +0200
Subject: [R-SIG-Finance] Garch fitting with mean regressors
Message-ID: <1c7d4a100804151227m3eab4ec0vd73dd2c7b3a04860@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080415/3a56daa5/attachment.pl 

From kennylin at nthu.us  Wed Apr 16 07:16:43 2008
From: kennylin at nthu.us (kennylin nthu)
Date: Wed, 16 Apr 2008 13:16:43 +0800
Subject: [R-SIG-Finance] Test statistics for mean reverting property
Message-ID: <1f360deb0804152216l11a99899h3401011da9568c05@mail.gmail.com>

Dear all:
   Does anybody know the function in R with which we can
test the mean reverting property of a time series?
Thanks.


Best,
Kenny Lin


From chalabi at phys.ethz.ch  Wed Apr 16 08:21:12 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Wed, 16 Apr 2008 08:21:12 +0200
Subject: [R-SIG-Finance] Garch fitting with mean regressors
In-Reply-To: <1c7d4a100804151227m3eab4ec0vd73dd2c7b3a04860@mail.gmail.com>
References: <1c7d4a100804151227m3eab4ec0vd73dd2c7b3a04860@mail.gmail.com>
Message-ID: <20080416082112.326ff4cc@mimi>

>>>> "SB" == "Stefano Balietti" <futur.dorko at gmail.com>
>>>> on Tue, 15 Apr 2008 21:27:39 +0200

   SB> Hi,
   SB> I'm looking for R packages able to perform GARCH-like fitting
   SB> (estimates),
   SB> such as fGarch, tseries and FinTS, but that allow me to
   SB> specify extra
   SB> regressors for the mean equation. It doesn't seem to me
   SB> that the
   SB> above-mentioned packages permit that, but maybe I'm
   SB> wrong. However,  does
   SB> anyone have any suggestion?
   SB> 
   SB> Cheers,
   SB> 
   SB> Stefano Balietti
   SB> 
  
As far as fGarch is concerned, you can only specify the arma regressors
for the mean equation. However, the functions in fGarch are quite
modular and it should not be too much of work to add new regressor to
the mean equation. 

regards,
Yohan


-- 


The 2nd International R/Rmetrics User and Developer Workshop ...
[http://www.rmetrics.org]


From stigler3 at etu.unige.ch  Wed Apr 16 08:43:06 2008
From: stigler3 at etu.unige.ch (Matthieu Stigler)
Date: Wed, 16 Apr 2008 08:43:06 +0200
Subject: [R-SIG-Finance] Test statistics for mean reverting property
In-Reply-To: <1f360deb0804152216l11a99899h3401011da9568c05@mail.gmail.com>
References: <1f360deb0804152216l11a99899h3401011da9568c05@mail.gmail.com>
Message-ID: <48059FFA.2040208@etu.unige.ch>

Hello

I don't know any direct procedure to test if a time series is mean 
reverting but if you rely on the fact that a stationnary time series has 
the property to be mean reverting, then just test for stationnarity. R 
has many unit root and stationnarity tests for this in packages urca, 
uroot and tseries.

Matthieu

kennylin nthu a ?crit :
> Dear all:
>    Does anybody know the function in R with which we can
> test the mean reverting property of a time series?
> Thanks.
>
>
> Best,
> Kenny Lin
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. 
> -- If you want to post, subscribe first.
>


From frainj at tcd.ie  Wed Apr 16 10:51:30 2008
From: frainj at tcd.ie (John Frain)
Date: Wed, 16 Apr 2008 09:51:30 +0100
Subject: [R-SIG-Finance] Test statistics for mean reverting property
In-Reply-To: <1f360deb0804152216l11a99899h3401011da9568c05@mail.gmail.com>
References: <1f360deb0804152216l11a99899h3401011da9568c05@mail.gmail.com>
Message-ID: <cfdde1650804160151t1763ad09m6392a9534dca581b@mail.gmail.com>

If your H0 is mean reverting have a look at the KPSS test which is
also implemented in urca.  For most of the unit root tests H0 is that
there is a unit root and the series is non-stationary.  If you are
using urca have a look at the book 'Analysis of integrated and
cointegrated time series with R', Springer by Bernhard Pfaff who is
responsible for the urca package

Best Regards

John

On 16/04/2008, kennylin nthu <kennylin at nthu.us> wrote:
> Dear all:
>   Does anybody know the function in R with which we can
> test the mean reverting property of a time series?
> Thanks.
>
>
> Best,
> Kenny Lin
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
>


-- 
John C Frain
Trinity College Dublin
Dublin 2
Ireland
www.tcd.ie/Economics/staff/frainj/home.htm
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


From patrick at burns-stat.com  Wed Apr 16 11:11:27 2008
From: patrick at burns-stat.com (Patrick Burns)
Date: Wed, 16 Apr 2008 10:11:27 +0100
Subject: [R-SIG-Finance] Garch fitting with mean regressors
In-Reply-To: <1c7d4a100804151227m3eab4ec0vd73dd2c7b3a04860@mail.gmail.com>
References: <1c7d4a100804151227m3eab4ec0vd73dd2c7b3a04860@mail.gmail.com>
Message-ID: <4805C2BF.3010604@burns-stat.com>

You can do the regression on the returns and
then fit the garch model on the residuals.  That
will most probably be very close to the result
if you did it "right".


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Stefano Balietti wrote:
> Hi,
> I'm looking for R packages able to perform GARCH-like fitting (estimates),
> such as fGarch, tseries and FinTS, but that allow me to specify extra
> regressors for the mean equation. It doesn't seem to me that the
> above-mentioned packages permit that, but maybe I'm wrong. However,  does
> anyone have any suggestion?
>
> Cheers,
>
> Stefano Balietti
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. 
> -- If you want to post, subscribe first.
>
>
>


From ajayshah at mayin.org  Wed Apr 16 14:47:17 2008
From: ajayshah at mayin.org (Ajay Shah)
Date: Wed, 16 Apr 2008 18:17:17 +0530
Subject: [R-SIG-Finance] Test statistics for mean reverting property
In-Reply-To: <48059FFA.2040208@etu.unige.ch>
References: <1f360deb0804152216l11a99899h3401011da9568c05@mail.gmail.com>
	<48059FFA.2040208@etu.unige.ch>
Message-ID: <dfa07a9d0804160547k3b33ddd4kbd34b8f957f093a7@mail.gmail.com>

>  >    Does anybody know the function in R with which we can
>  > test the mean reverting property of a time series?

A package called "vrtest".

-- 
Ajay Shah
ajayshah at mayin.org
http://www.mayin.org/ajayshah
http://ajayshahblog.blogspot.com


From zeno.adams at vwl.uni-freiburg.de  Wed Apr 16 15:37:25 2008
From: zeno.adams at vwl.uni-freiburg.de (Zeno Adams)
Date: Wed, 16 Apr 2008 15:37:25 +0200
Subject: [R-SIG-Finance] Garch fitting with mean regressors
In-Reply-To: <4805C2BF.3010604@burns-stat.com>
References: <1c7d4a100804151227m3eab4ec0vd73dd2c7b3a04860@mail.gmail.com>
	<4805C2BF.3010604@burns-stat.com>
Message-ID: <web-100295074@uni-freiburg.de>

On Wed, 16 Apr 2008 10:11:27 +0100
 Patrick Burns <patrick at burns-stat.com> wrote:
> You can do the regression on the returns and
> then fit the garch model on the residuals.  That
> will most probably be very close to the result
> if you did it "right".
> 
> 


I wonder if you could really do that. After all you would do an
estimation ignoring heteroscedasticity in the returns which biases the
parameter estimates. If you include the exogenous in the mean equation
of a garch model then you take conditional heteroscedasticity into
account. This is easy to do in most commercial software (e.g. EViews,
RATS etc.)

Zeno


From futur.dorko at gmail.com  Wed Apr 16 15:40:23 2008
From: futur.dorko at gmail.com (Stefano Balietti)
Date: Wed, 16 Apr 2008 15:40:23 +0200
Subject: [R-SIG-Finance] Garch fitting with mean regressors
In-Reply-To: <4805F2E0.4030000@itp.phys.ethz.ch>
References: <1c7d4a100804151227m3eab4ec0vd73dd2c7b3a04860@mail.gmail.com>
	<20080416082112.326ff4cc@mimi> <4805F2E0.4030000@itp.phys.ethz.ch>
Message-ID: <1c7d4a100804160640k4a1853cbicbf646bd52d0fb7b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080416/a37999cd/attachment.pl 

From patrick at burns-stat.com  Wed Apr 16 17:47:50 2008
From: patrick at burns-stat.com (Patrick Burns)
Date: Wed, 16 Apr 2008 16:47:50 +0100
Subject: [R-SIG-Finance] Garch fitting with mean regressors
In-Reply-To: <web-100295074@uni-freiburg.de>
References: <1c7d4a100804151227m3eab4ec0vd73dd2c7b3a04860@mail.gmail.com>
	<4805C2BF.3010604@burns-stat.com> <web-100295074@uni-freiburg.de>
Message-ID: <48061FA6.9000207@burns-stat.com>

Zeno Adams wrote:
> On Wed, 16 Apr 2008 10:11:27 +0100
>  Patrick Burns <patrick at burns-stat.com> wrote:
>   
>> You can do the regression on the returns and
>> then fit the garch model on the residuals.  That
>> will most probably be very close to the result
>> if you did it "right".
>>
>>
>>     
>
>
> I wonder if you could really do that. After all you would do an
> estimation ignoring heteroscedasticity in the returns which biases the
> parameter estimates. If you include the exogenous in the mean equation
> of a garch model then you take conditional heteroscedasticity into
> account. This is easy to do in most commercial software (e.g. EViews,
> RATS etc.)
>
> Zeno
>   

Of course we can really do that.  The question is
whether or not it is a good idea to do it.

Yes, we are ignoring heteroscedasticity in the regression.
This makes it inefficient, but bias should be minimal.  There
is also the option to iterate the two stages which, under
suitable conditions, will converge to the maximum likelihood
solution.

If we are worried about violating assumptions, then the two
stage estimation is likely to be one of our lesser sins in the
exercise.

Pat

>
>


From ezivot at u.washington.edu  Wed Apr 16 23:35:26 2008
From: ezivot at u.washington.edu (Eric Zivot)
Date: Wed, 16 Apr 2008 14:35:26 -0700
Subject: [R-SIG-Finance] Garch fitting with mean regressors
In-Reply-To: <web-100295074@uni-freiburg.de>
Message-ID: <200804162135.m3GLZQPI027334@smtp.washington.edu>

Yes, you can do this. Heteroskedasticity does not generally bias the
coefficients from the regression - just invalidates the usual standard
errors. For basic garch models you can estimate them in a two-step fashion.
Engle showed this in his orignal ARCH paper in 1982  

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Zeno Adams
Sent: Wednesday, April 16, 2008 6:37 AM
To: Patrick Burns; Stefano Balietti
Cc: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Garch fitting with mean regressors

On Wed, 16 Apr 2008 10:11:27 +0100
 Patrick Burns <patrick at burns-stat.com> wrote:
> You can do the regression on the returns and then fit the garch model 
> on the residuals.  That will most probably be very close to the result 
> if you did it "right".
> 
> 


I wonder if you could really do that. After all you would do an estimation
ignoring heteroscedasticity in the returns which biases the parameter
estimates. If you include the exogenous in the mean equation of a garch
model then you take conditional heteroscedasticity into account. This is
easy to do in most commercial software (e.g. EViews, RATS etc.)

Zeno

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. 
-- If you want to post, subscribe first.


From ggrothendieck at gmail.com  Thu Apr 17 03:17:43 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 16 Apr 2008 21:17:43 -0400
Subject: [R-SIG-Finance] question on zoo data manipulation
In-Reply-To: <971536df0804150556h5a71312aof0889cf7698eebab@mail.gmail.com>
References: <829e6c8a0804140530o78977f2te561bf38c92ef974@mail.gmail.com>
	<971536df0804150556h5a71312aof0889cf7698eebab@mail.gmail.com>
Message-ID: <971536df0804161817k77efcd1eh4d6e1daa2d973e01@mail.gmail.com>

I thought about this one a bit more and have two
additional solutions.  One uses zoo more intensively
by forming the "time" index out of the merge keys.
This relies on the fact that zoo can use any class
with certain methods, not just the usual time/date
classes.  However, I think that the best wayof thinking
about this problem is from an SQL viewpoint since its
basically just a three way self merge followed by
an aggregation and the entire thing can be done
in a single SQL statement (although it spans several
lines).  Solution 1 is our prior minimally zoo solution,
solution 2 is the much more zoo-ish solution and
solution 3 uses sqldf to implement it in SQL.

DF <- structure(list(Ticker = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L), .Label = "XXX", class = "factor"), Date = c(20080320L,
20080320L, 20080320L, 20080320L, 20080320L, 20080218L, 20080218L,
20080218L, 20080218L), BrokerName = structure(c(1L, 1L, 2L, 2L,
3L, 1L, 1L, 2L, 2L), .Label = c("BRK1", "BRK2", "BRK3"), class = "factor"),
    Acc_Yr = c(200806L, 200906L, 200806L, 200906L, 200806L, 200806L,
    200906L, 200806L, 200906L), Measure = c(2.2, 2.5, 2.3, 2.8,
    3.3, 2.2, 2.5, 2.4, 2.8), lag = c(0L, 0L, 0L, 0L, 0L, 1L,
    1L, 1L, 1L)), .Names = c("Ticker", "Date", "BrokerName",
"Acc_Yr", "Measure", "lag"), class = "data.frame", row.names = c(NA,
-9L))


# zoo solution 1

library(zoo)

f <- function(x) {
    br <- intersect(x[x$lag == 0, "BrokerName"], x[x$lag == 1, "BrokerName"])
    sb <- subset(x, BrokerName %in% br)
    ag <- aggregate(sb["Measure"], sb[c(1, 2, 4, 6)], mean)
    transform(tail(ag, -1), Measure =
        coredata(diff(zoo(ag$Measure), arithmetic = FALSE) - 1))
}
do.call("rbind", by(DF, DF[c(1, 4)], f))

# zoo solution 2

library(zoo)

z <- zoo(DF$Measure, apply(DF[c(1, 3, 4, 6)], 1, paste, collapse = ":"))

zl <- zoo(DF$Measure,
    apply(transform(DF[c(1, 3, 4, 6)], lag = lag+1), 1, paste, collapse = ":"))

zm <- merge(z, zl, all = FALSE)

z01 <- zm[sub(":[0-9]*$", ":1", time(zm)) %in% time(zm)]

transform(aggregate(z01, sub(":[^:]*", "", time(z01)), mean), Change = z/zl-1)

# solution 3 - sqldf

library(sqldf)
sqldf("select Ticker, Date__1, Acc_Yr, lag, avg(Measure)/avg(Mprev)-1 Change
    from (select y.*, x.Measure Mprev from DF x, DF y, DF z
    where x.Ticker = y.Ticker and x.Acc_Yr = y.Acc_Yr
        and x.BrokerName = y.BrokerName and x.lag = y.lag - 1
        and x.Ticker = z.Ticker and x.Acc_Yr = z.Acc_Yr
        and x.BrokerName = z.BrokerName and z.lag = 1)
    group by Ticker, Acc_Yr, lag")



On Tue, Apr 15, 2008 at 8:56 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> This does not really use zoo in any significant way since it
> does not become a time series until the last line of f but
> here is a solution that does use zoo in that one last line.
>
> We use by to split up the data frame with a function f.
> In f, br intersects the lag0 and lag1 brokers and then we
> subset x according to those lines having a broker in br.
> We then take the means, convert the series to zoo and
> perform diff.zoo on it.
>
> There are some aspects of the problem that were not defined
> such as whether to use lag 1 to compare lag 3 if there is no
> lag 2 and we did that here but that could be changed by using
> the lag as the time index.
>
> We have also dumped out the data frame, DF, using dput to make
> it easier to reproduce the solution.
>
> DF <- structure(list(Ticker = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L), .Label = "XXX", class = "factor"), Date = c(20080320L,
> 20080320L, 20080320L, 20080320L, 20080320L, 20080218L, 20080218L,
> 20080218L, 20080218L), BrokerName = structure(c(1L, 1L, 2L, 2L,
> 3L, 1L, 1L, 2L, 2L), .Label = c("BRK1", "BRK2", "BRK3"), class = "factor"),
>    Acc_Yr = c(200806L, 200906L, 200806L, 200906L, 200806L, 200806L,
>    200906L, 200806L, 200906L), Measure = c(2.2, 2.5, 2.3, 2.8,
>    3.3, 2.2, 2.5, 2.4, 2.8), lag = c(0L, 0L, 0L, 0L, 0L, 1L,
>    1L, 1L, 1L)), .Names = c("Ticker", "Date", "BrokerName",
> "Acc_Yr", "Measure", "lag"), class = "data.frame", row.names = c(NA,
> -9L))
>
> library(zoo)
>
> f <- function(x) {
>    br <- intersect(x[x$lag == 0, "BrokerName"], x[x$lag == 1, "BrokerName"])
>    sb <- subset(x, BrokerName %in% br)
>    ag <- aggregate(sb["Measure"], sb[c(1, 2, 4, 6)], mean)
>    transform(tail(ag, -1), Measure =
>        coredata(diff(zoo(ag$Measure), arithmetic = FALSE) - 1))
> }
> do.call("rbind", by(DF, DF[c(1, 4)], f))
>
>
> On Mon, Apr 14, 2008 at 8:30 AM, Manoj <manojsw at gmail.com> wrote:
>
> > Hi Zoo-experts,
> >      I am working on the data-set below.
> >
> > Ticker  Date    BrokerName      Acc_Yr  Measure lag
> > XXX     20080320        BRK1    200806  2.2     0
> > XXX     20080320        BRK1    200906  2.5     0
> > XXX     20080320        BRK2    200806  2.3     0
> > XXX     20080320        BRK2    200906  2.8     0
> > XXX     20080320        BRK3    200806  3.3     0
> > XXX     20080218        BRK1    200806  2.2     1
> > XXX     20080218        BRK1    200906  2.5     1
> > XXX     20080218        BRK2    200806  2.4     1
> > XXX     20080218        BRK2    200906  2.8     1
> >
> >
> >
> > Using zoo object, Is there a quicker/efficient way of manipulating the
> > data as per following criteria?
> >
> > 1) For any given date/lag - compute mean of column "measure" grouped
> > by different broker & different accounting year?
> >          so the output data-set should look like:
> >
> > Ticker  Date    Mean Measure    Acc_Yr  Lag
> > XXX     20080320        2.6     200806  0
> >
> > 2) For any lag >= 1, calculate returns on  aggregate "measure"
> > constrained on "intersection" of broker-name across lag 0 & lag 1 (so
> > BRK3 should drop out) ?
> >
> > i.e:  the intermediate data-set should look like
> >
> > Ticker  Date    Mean Measure    Acc_Yr  Lag
> > XXX     20080320        2.25    200806  0
> > XXX     20080318        2.3     200806  1
> >
> >
> > Note that for 200806, the mean changes from 2.6 as measured above to
> > 2.25 (since BRK3 is dropped in calculation.  The final data-set should
> > then be:
> >
> > Ticker  Date    Pct_Change      Acc_Yr  Lag
> > XXX     20080218        0.02    200806  1
> >
> > --------------------
> >
> > I can accomplish the results using a combination of tapply &
> > subsetting the data-set for each lag but I thought this kind of
> > data-structure is ideal for zoo manipulation, hence the help request.
> >
> > Thanks in Advance.
> >
> > Manoj
> >
> > _______________________________________________
> > R-SIG-Finance at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only.
> > -- If you want to post, subscribe first.
> >
>


From mail at xesoftware.com.au  Thu Apr 17 03:41:40 2008
From: mail at xesoftware.com.au (stephen)
Date: Thu, 17 Apr 2008 11:41:40 +1000
Subject: [R-SIG-Finance] economagic Import - error message
Message-ID: <000001c8a02c$32b929e0$7201a8c0@tablet>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080417/6c25bb71/attachment.pl 

From manojsw at gmail.com  Thu Apr 17 06:41:08 2008
From: manojsw at gmail.com (Manoj)
Date: Thu, 17 Apr 2008 14:41:08 +1000
Subject: [R-SIG-Finance] question on zoo data manipulation
In-Reply-To: <971536df0804161817k77efcd1eh4d6e1daa2d973e01@mail.gmail.com>
References: <829e6c8a0804140530o78977f2te561bf38c92ef974@mail.gmail.com>
	<971536df0804150556h5a71312aof0889cf7698eebab@mail.gmail.com>
	<971536df0804161817k77efcd1eh4d6e1daa2d973e01@mail.gmail.com>
Message-ID: <829e6c8a0804162141sdc7fa1g2ab81f159ea35066@mail.gmail.com>

Thanks a lot Gabor!

I was playing around with sqldf yesterday and thought of the same only
to find a solution on those lines - much apppreciated!

Cheers

Manoj

On 4/17/08, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> I thought about this one a bit more and have two
> additional solutions.  One uses zoo more intensively
> by forming the "time" index out of the merge keys.
> This relies on the fact that zoo can use any class
> with certain methods, not just the usual time/date
> classes.  However, I think that the best wayof thinking
> about this problem is from an SQL viewpoint since its
> basically just a three way self merge followed by
> an aggregation and the entire thing can be done
> in a single SQL statement (although it spans several
> lines).  Solution 1 is our prior minimally zoo solution,
> solution 2 is the much more zoo-ish solution and
> solution 3 uses sqldf to implement it in SQL.
>
> DF <- structure(list(Ticker = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L), .Label = "XXX", class = "factor"), Date = c(20080320L,
> 20080320L, 20080320L, 20080320L, 20080320L, 20080218L, 20080218L,
> 20080218L, 20080218L), BrokerName = structure(c(1L, 1L, 2L, 2L,
> 3L, 1L, 1L, 2L, 2L), .Label = c("BRK1", "BRK2", "BRK3"), class = "factor"),
>    Acc_Yr = c(200806L, 200906L, 200806L, 200906L, 200806L, 200806L,
>    200906L, 200806L, 200906L), Measure = c(2.2, 2.5, 2.3, 2.8,
>    3.3, 2.2, 2.5, 2.4, 2.8), lag = c(0L, 0L, 0L, 0L, 0L, 1L,
>    1L, 1L, 1L)), .Names = c("Ticker", "Date", "BrokerName",
> "Acc_Yr", "Measure", "lag"), class = "data.frame", row.names = c(NA,
> -9L))
>
>
> # zoo solution 1
>
> library(zoo)
>
> f <- function(x) {
>    br <- intersect(x[x$lag == 0, "BrokerName"], x[x$lag == 1, "BrokerName"])
>    sb <- subset(x, BrokerName %in% br)
>    ag <- aggregate(sb["Measure"], sb[c(1, 2, 4, 6)], mean)
>    transform(tail(ag, -1), Measure =
>        coredata(diff(zoo(ag$Measure), arithmetic = FALSE) - 1))
> }
> do.call("rbind", by(DF, DF[c(1, 4)], f))
>
> # zoo solution 2
>
> library(zoo)
>
> z <- zoo(DF$Measure, apply(DF[c(1, 3, 4, 6)], 1, paste, collapse = ":"))
>
> zl <- zoo(DF$Measure,
>    apply(transform(DF[c(1, 3, 4, 6)], lag = lag+1), 1, paste, collapse = ":"))
>
> zm <- merge(z, zl, all = FALSE)
>
> z01 <- zm[sub(":[0-9]*$", ":1", time(zm)) %in% time(zm)]
>
> transform(aggregate(z01, sub(":[^:]*", "", time(z01)), mean), Change = z/zl-1)
>
> # solution 3 - sqldf
>
> library(sqldf)
> sqldf("select Ticker, Date__1, Acc_Yr, lag, avg(Measure)/avg(Mprev)-1 Change
>    from (select y.*, x.Measure Mprev from DF x, DF y, DF z
>    where x.Ticker = y.Ticker and x.Acc_Yr = y.Acc_Yr
>        and x.BrokerName = y.BrokerName and x.lag = y.lag - 1
>        and x.Ticker = z.Ticker and x.Acc_Yr = z.Acc_Yr
>        and x.BrokerName = z.BrokerName and z.lag = 1)
>    group by Ticker, Acc_Yr, lag")
>
>
>
> On Tue, Apr 15, 2008 at 8:56 AM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
> > This does not really use zoo in any significant way since it
> > does not become a time series until the last line of f but
> > here is a solution that does use zoo in that one last line.
> >
> > We use by to split up the data frame with a function f.
> > In f, br intersects the lag0 and lag1 brokers and then we
> > subset x according to those lines having a broker in br.
> > We then take the means, convert the series to zoo and
> > perform diff.zoo on it.
> >
> > There are some aspects of the problem that were not defined
> > such as whether to use lag 1 to compare lag 3 if there is no
> > lag 2 and we did that here but that could be changed by using
> > the lag as the time index.
> >
> > We have also dumped out the data frame, DF, using dput to make
> > it easier to reproduce the solution.
> >
> > DF <- structure(list(Ticker = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L), .Label = "XXX", class = "factor"), Date = c(20080320L,
> > 20080320L, 20080320L, 20080320L, 20080320L, 20080218L, 20080218L,
> > 20080218L, 20080218L), BrokerName = structure(c(1L, 1L, 2L, 2L,
> > 3L, 1L, 1L, 2L, 2L), .Label = c("BRK1", "BRK2", "BRK3"), class = "factor"),
> >    Acc_Yr = c(200806L, 200906L, 200806L, 200906L, 200806L, 200806L,
> >    200906L, 200806L, 200906L), Measure = c(2.2, 2.5, 2.3, 2.8,
> >    3.3, 2.2, 2.5, 2.4, 2.8), lag = c(0L, 0L, 0L, 0L, 0L, 1L,
> >    1L, 1L, 1L)), .Names = c("Ticker", "Date", "BrokerName",
> > "Acc_Yr", "Measure", "lag"), class = "data.frame", row.names = c(NA,
> > -9L))
> >
> > library(zoo)
> >
> > f <- function(x) {
> >    br <- intersect(x[x$lag == 0, "BrokerName"], x[x$lag == 1, "BrokerName"])
> >    sb <- subset(x, BrokerName %in% br)
> >    ag <- aggregate(sb["Measure"], sb[c(1, 2, 4, 6)], mean)
> >    transform(tail(ag, -1), Measure =
> >        coredata(diff(zoo(ag$Measure), arithmetic = FALSE) - 1))
> > }
> > do.call("rbind", by(DF, DF[c(1, 4)], f))
> >
> >
> > On Mon, Apr 14, 2008 at 8:30 AM, Manoj <manojsw at gmail.com> wrote:
> >
> > > Hi Zoo-experts,
> > >      I am working on the data-set below.
> > >
> > > Ticker  Date    BrokerName      Acc_Yr  Measure lag
> > > XXX     20080320        BRK1    200806  2.2     0
> > > XXX     20080320        BRK1    200906  2.5     0
> > > XXX     20080320        BRK2    200806  2.3     0
> > > XXX     20080320        BRK2    200906  2.8     0
> > > XXX     20080320        BRK3    200806  3.3     0
> > > XXX     20080218        BRK1    200806  2.2     1
> > > XXX     20080218        BRK1    200906  2.5     1
> > > XXX     20080218        BRK2    200806  2.4     1
> > > XXX     20080218        BRK2    200906  2.8     1
> > >
> > >
> > >
> > > Using zoo object, Is there a quicker/efficient way of manipulating the
> > > data as per following criteria?
> > >
> > > 1) For any given date/lag - compute mean of column "measure" grouped
> > > by different broker & different accounting year?
> > >          so the output data-set should look like:
> > >
> > > Ticker  Date    Mean Measure    Acc_Yr  Lag
> > > XXX     20080320        2.6     200806  0
> > >
> > > 2) For any lag >= 1, calculate returns on  aggregate "measure"
> > > constrained on "intersection" of broker-name across lag 0 & lag 1 (so
> > > BRK3 should drop out) ?
> > >
> > > i.e:  the intermediate data-set should look like
> > >
> > > Ticker  Date    Mean Measure    Acc_Yr  Lag
> > > XXX     20080320        2.25    200806  0
> > > XXX     20080318        2.3     200806  1
> > >
> > >
> > > Note that for 200806, the mean changes from 2.6 as measured above to
> > > 2.25 (since BRK3 is dropped in calculation.  The final data-set should
> > > then be:
> > >
> > > Ticker  Date    Pct_Change      Acc_Yr  Lag
> > > XXX     20080218        0.02    200806  1
> > >
> > > --------------------
> > >
> > > I can accomplish the results using a combination of tapply &
> > > subsetting the data-set for each lag but I thought this kind of
> > > data-structure is ideal for zoo manipulation, hence the help request.
> > >
> > > Thanks in Advance.
> > >
> > > Manoj
> > >
> > > _______________________________________________
> > > R-SIG-Finance at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > > -- Subscriber-posting only.
> > > -- If you want to post, subscribe first.
> > >
> >
>


From chalabi at phys.ethz.ch  Thu Apr 17 08:33:15 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Thu, 17 Apr 2008 08:33:15 +0200
Subject: [R-SIG-Finance] economagic Import - error message
In-Reply-To: <000001c8a02c$32b929e0$7201a8c0@tablet>
References: <000001c8a02c$32b929e0$7201a8c0@tablet>
Message-ID: <20080417083315.5040fd21@mimi>

>>>> "S" == "stephen" <mail at xesoftware.com.au>
>>>> on Thu, 17 Apr 2008 11:41:40 +1000

   S> > # save a download to a data file
   S> > file = 'fedfunds.csv'
   S> > source = 'http://www.economagic.com/em-cgi/data.exe/'
   S> > query = 'fedst1/fedfunds+2'
   S> > # download
   S> > economagicImport(file, source, query)
   S> Error in download.file(url = url, destfile = file, method =
   S> method) :
   S> unsupported URL scheme
   S> [1] "No Internet Access"

there is a typo in your query. It should be
query = 'fedstl/fedfunds+2'

and your arguemnts in economagicImport are not in the correct order...
?economagicImport

regards,
Yohan 

-- 


The 2nd International R/Rmetrics User and Developer Workshop ...
[http://www.rmetrics.org]


From wuertz at itp.phys.ethz.ch  Thu Apr 17 10:03:50 2008
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Thu, 17 Apr 2008 10:03:50 +0200
Subject: [R-SIG-Finance] economagic Import - error message
In-Reply-To: <20080417083315.5040fd21@mimi>
References: <000001c8a02c$32b929e0$7201a8c0@tablet>
	<20080417083315.5040fd21@mimi>
Message-ID: <48070466.3090304@itp.phys.ethz.ch>

Yohan Chalabi wrote:


Some additional information

Note, that economagicImport() requires also the input of the frequency
of the data. The default is "quarterly", alternatively you can use "monthly"
and "daily" frequency formats.

FED FUNDS data are available as monthly and weekly (in daily format)
data sets from economagic.com. Therefore you should specify
explicitely the frequency data in the argument list. Here the examples:

# I used R 2.6.2 with latest package updates
require(fImport)

# For weekly data (with daily date formats) use:
x = economagicImport(query = "fedstl/day-ff", frequency = "daily")
head(x at data) # gives you the series as a data.frame
head(as.timeSeries(x at data)) # converts it in a timeSeries object

# For monthly data use:
y = economagicImport(query = "fedstl/fedfunds+2", frequency = "monthly")
head(y at data) # gives you the series as a data.frame
head(as.timeSeries(y at data)) # converts it in a timeSeries object


Some more note: FED FUND data are also available from the St.
Louis FED data base, from where economagic.com has copied his
data. Since the FED uses ISO 8601 date records, and data are
earlier available I would recommend to download the data with
the function fredImport().


Diethelm Wuertz





>>>>> "S" == "stephen" <mail at xesoftware.com.au>
>>>>> on Thu, 17 Apr 2008 11:41:40 +1000
>>>>>           
>
>    S> > # save a download to a data file
>    S> > file = 'fedfunds.csv'
>    S> > source = 'http://www.economagic.com/em-cgi/data.exe/'
>    S> > query = 'fedst1/fedfunds+2'
>    S> > # download
>    S> > economagicImport(file, source, query)
>    S> Error in download.file(url = url, destfile = file, method =
>    S> method) :
>    S> unsupported URL scheme
>    S> [1] "No Internet Access"
>
> there is a typo in your query. It should be
> query = 'fedstl/fedfunds+2'
>
> and your arguemnts in economagicImport are not in the correct order...
> ?economagicImport
>
> regards,
> Yohan 
>
>   


-- 

PD Dr. Diethelm Wuertz
Institute for Theoretical Physics
Swiss Federal Institute of Technology

www.itp.phys.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From sylvain.archenault at sgcib.com  Thu Apr 17 11:33:03 2008
From: sylvain.archenault at sgcib.com (sylvain.archenault at sgcib.com)
Date: Thu, 17 Apr 2008 11:33:03 +0200
Subject: [R-SIG-Finance] garchFit - Strange behaviour of trace argument [C1]
Message-ID: <OF4AB4C3CB.56E2AFB8-ONC125742E.0031728D-C125742E.0034772D@fr.world.socgen>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080417/20c130d5/attachment.pl 

From chalabi at phys.ethz.ch  Thu Apr 17 15:21:40 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Thu, 17 Apr 2008 15:21:40 +0200
Subject: [R-SIG-Finance] garchFit - Strange behaviour of trace argument
 [C1]
In-Reply-To: <OF4AB4C3CB.56E2AFB8-ONC125742E.0031728D-C125742E.0034772D@fr.world.socgen>
References: <OF4AB4C3CB.56E2AFB8-ONC125742E.0031728D-C125742E.0034772D@fr.world.socgen>
Message-ID: <20080417152140.5f8e28fb@mimi>

>>>> "SAC" == sylvain.archenault at sgcib.com
>>>> on Thu, 17 Apr 2008 11:33:03 +0200

   SAC> This morning, I found a strange behaviour in the garchFit
   SAC> method. Fitting
   SAC> with trace=T doesn't give the same fitted value for h.t
   SAC> (or sigma.t) :

This problem is already fixed in the dev-version of fGarch.

Not dev-version of Rmetrics packages are available at R-Forge.

regards,
Yohan
-- 


The 2nd International R/Rmetrics User and Developer Workshop ...
[http://www.rmetrics.org]


From jeff.a.ryan at gmail.com  Thu Apr 17 16:18:40 2008
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Thu, 17 Apr 2008 09:18:40 -0500
Subject: [R-SIG-Finance] economagic Import - error message
In-Reply-To: <48070466.3090304@itp.phys.ethz.ch>
References: <000001c8a02c$32b929e0$7201a8c0@tablet>
	<20080417083315.5040fd21@mimi> <48070466.3090304@itp.phys.ethz.ch>
Message-ID: <e8e755250804170718v4cd4d0e5yb94f0f077141dde6@mail.gmail.com>

As Diethelm pointed out - the St. Louis Fed has most of the economagic series.

In addition to the Rmetrics interface there is one in quantmod.  A
list of all FRED series (19000+) is accessible from here:

http://research.stlouisfed.org/fred2/

library(quantmod)
> getSymbols("FEDFUNDS",src='FRED') # monthly
[1] "FEDFUNDS"
> head(FEDFUNDS)
           FEDFUNDS
1954-07-01     0.80
1954-08-01     1.22
1954-09-01     1.06
1954-10-01     0.85
1954-11-01     0.83
1954-12-01     1.28
> getSymbols("FF",src='FRED') #  weekly
[1] "FF"
> head(FF)
             FF
1954-07-07 1.00
1954-07-14 1.21
1954-07-21 0.57
1954-07-28 0.63
1954-08-04 0.27
1954-08-11 1.30


On Thu, Apr 17, 2008 at 3:03 AM, Diethelm Wuertz
<wuertz at itp.phys.ethz.ch> wrote:
> Yohan Chalabi wrote:
>
>
>  Some additional information
>
>  Note, that economagicImport() requires also the input of the frequency
>  of the data. The default is "quarterly", alternatively you can use "monthly"
>  and "daily" frequency formats.
>
>  FED FUNDS data are available as monthly and weekly (in daily format)
>  data sets from economagic.com. Therefore you should specify
>  explicitely the frequency data in the argument list. Here the examples:
>
>  # I used R 2.6.2 with latest package updates
>  require(fImport)
>
>  # For weekly data (with daily date formats) use:
>  x = economagicImport(query = "fedstl/day-ff", frequency = "daily")
>  head(x at data) # gives you the series as a data.frame
>  head(as.timeSeries(x at data)) # converts it in a timeSeries object
>
>  # For monthly data use:
>  y = economagicImport(query = "fedstl/fedfunds+2", frequency = "monthly")
>  head(y at data) # gives you the series as a data.frame
>  head(as.timeSeries(y at data)) # converts it in a timeSeries object
>
>
>  Some more note: FED FUND data are also available from the St.
>  Louis FED data base, from where economagic.com has copied his
>  data. Since the FED uses ISO 8601 date records, and data are
>  earlier available I would recommend to download the data with
>  the function fredImport().
>
>
>  Diethelm Wuertz
>
>
>
>
>
>
>  >>>>> "S" == "stephen" <mail at xesoftware.com.au>
>  >>>>> on Thu, 17 Apr 2008 11:41:40 +1000
>  >>>>>
>  >
>  >    S> > # save a download to a data file
>  >    S> > file = 'fedfunds.csv'
>  >    S> > source = 'http://www.economagic.com/em-cgi/data.exe/'
>  >    S> > query = 'fedst1/fedfunds+2'
>  >    S> > # download
>  >    S> > economagicImport(file, source, query)
>  >    S> Error in download.file(url = url, destfile = file, method =
>  >    S> method) :
>  >    S> unsupported URL scheme
>  >    S> [1] "No Internet Access"
>  >
>  > there is a typo in your query. It should be
>  > query = 'fedstl/fedfunds+2'
>  >
>  > and your arguemnts in economagicImport are not in the correct order...
>  > ?economagicImport
>  >
>  > regards,
>  > Yohan
>  >
>  >
>
>
>  --
>
>  PD Dr. Diethelm Wuertz
>  Institute for Theoretical Physics
>  Swiss Federal Institute of Technology
>
>  www.itp.phys.ethz.ch
>  www.rmetrics.org
>
>  NOTE:
>  Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
>  June 29th - July 3rd Meielisalp, Lake Thune, Switzerland
>
>
>
>  _______________________________________________
>  R-SIG-Finance at stat.math.ethz.ch mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>  -- Subscriber-posting only.
>  -- If you want to post, subscribe first.
>



-- 
There's a way to do it better - find it.
Thomas A. Edison


From Xiaochen.Sun at brunel.ac.uk  Thu Apr 17 17:52:40 2008
From: Xiaochen.Sun at brunel.ac.uk (Xiaochen Sun)
Date: Thu, 17 Apr 2008 16:52:40 +0100
Subject: [R-SIG-Finance] Risk Control Strategies for Hedge Funds and Program
	Trading - 4th Annual CARISMA conference
Message-ID: <E386E504246A9249A9176B5BEEC13B6F7B8F01@UXEXMBU116.academic.windsor>

We are pleased to announce the 4th Annual CARISMA conference, which takes place in London at 7City Learning on 1-2 July 2008.

The theme of the conference is "Risk Control Strategies for Hedge Funds and Program Trading".  There are also four pre- and post-conference workshops.  For further details see
 http://www.optirisk-systems.com/events/carisma2008.asp

The conference provides a platform to discuss the applications and advances, and to explore future research directions.  The focus is on the emerging requirements of the finance industry, from the perspective of performance monitoring, regulation and compliance.  It brings together practitioners and academics working in the area of financial planning, optimisation and risk modelling. The satellite workshops provide an in-depth view of related topics in investment and risk modelling.  

Speakers include:

* Carlo Acerbi, Abaxbank
* Art Asriev, Bear Stearns
* Les Balzer, The University of New South Wales
* Dan Bienstock, Columbia University
* Nicos Christofides, Imperial College
* Robert Clarkson, Cass Business School, City University.
* M A H Dempster, Centre for Financial Research, Judge Business School, University of Cambridge & Cambridge Systems Associates Limited
* Dan diBartolomeo, Northfield Information Services Inc 
* Chanaka Edirisinghe, University of Tennessee
* Philip Gagner, RavenPack Int'l
* Gerd Infanger, Stanford University
* Dilip Madan, University of Maryland, Consultant to Morgan Stanley & Visiting Professor, CARISMA (Risk Awards Quant of the Year 2008)
* Gautam Mitra, CARISMA, Brunel University
* Andrew Robinson, SunGard-APT
* Bernd Scherer, Morgan Stanley
* Rob Stubbs, Axioma
* Stefan Thurner, red.stars.com
* Xunyu Zhou, University of Oxford 

Topics:

* Risk Management for Hedge Funds
* Long-Short Portfolios with Downside Risk Control
* Credit Crunch, Liquidity, and Equity Market Neutral Strategies: Managing Risk in High Volatility Markets
* Dynamic Asset Allocation
* Automated Risk Management for Global Macro Strategies
* Actuarial Insights into Hedge Fund Management
* Optimal Trade Execution
* Risk Management for Equity Trading: Fat Tails and Liquidity Gaps
* Optimal Technical Trading Rules and Risk Control in Managing Stock Portfolios
* Portfolio Implementation Shortfall Trading Strategies
* Dynamic Behavioural Portfolio Choice
* Coherent Measures of Risk
* Automated Statistical Arbitrage Funds
* Efficiencies in Multi-Account Optimisation


Pre/Post Conference Workshops:

30 June 2008: Two Half-Day WORKSHOPS:

Morning: Robust Portfolio Optimisation
Afternoon: LDI/ALM 


3 July 2008: Two Half-Day WORKSHOPS:

Morning:  New Developments: Performance Measures and Structured Products; Coherent Risk Measures and Liquidity Risk

Afternoon: RavenPack workshop: News Analytics and Financial Modelling

###############################
# Apologise for any cross sending ##
###############################



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
Michael(Xiaochen) Sun, BA(BTBU), MSc(Hull), PhD Student,
CARISMA, www.carisma.brunel.ac.uk <http://www.carisma.brunel.ac.uk/>  
The Centre for the Analysis of Risk and OptimISation Modelling Applications
School of Information Systems, Computing and Mathematics
Brunel University, Uxbridge, UB8 3PH, Middlesex, United Kingdom
Telephone: +44 1895 265625 [M503], Fax: +44 1895 269732
Webpage:http://people.brunel.ac.uk/~mapgxcs <http://people.brunel.ac.uk/~mapgxcs>  
http://optirisk.googlepages.com <http://optirisk.googlepages.com/>  
Blog: http://mam3xs.blogspot.com <http://mam3xs.blogspot.com/> 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
<http://mam3xs.blogspot.com/>   


From berekket at gmail.com  Thu Apr 17 23:02:45 2008
From: berekket at gmail.com (bereket weldeslassie)
Date: Thu, 17 Apr 2008 15:02:45 -0600
Subject: [R-SIG-Finance] Causality test
Message-ID: <4bc7c8760804171402p221ac44n6bd55bc2f5885b57@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080417/7ecb08a4/attachment.pl 

From markleeds at verizon.net  Thu Apr 17 23:10:38 2008
From: markleeds at verizon.net (markleeds at verizon.net)
Date: Thu, 17 Apr 2008 16:10:38 -0500 (CDT)
Subject: [R-SIG-Finance] Causality test
Message-ID: <15566380.194111208466638691.JavaMail.root@vms075.mailsrvcs.net>

>From: bereket weldeslassie <berekket at gmail.com>
>Date: 2008/04/17 Thu PM 04:02:45 CDT
>To: r-sig-finance at stat.math.ethz.ch
>Subject: [R-SIG-Finance] Causality test

I don't know what the Sims Causality test
is but I'm almost positive that Bernhard's VARS package
has the Granger Causality test and maybe they're related ?



>Dear All,
>I am doing Casuality test among several time series variables.
>I am using the granger.test() function in the MSBVAR package. I am also
>trying to do the Sims Causality test (which tests the relationship between
>present values of one variable and the leading values of an other variable).
>Is there a function in R that does the Sims Causality test? I appreciate
>your help.
>Thanks,
>Bereket
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-SIG-Finance at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>-- Subscriber-posting only. 
>-- If you want to post, subscribe first.


From patrick.t.brandt at gmail.com  Fri Apr 18 00:22:08 2008
From: patrick.t.brandt at gmail.com (Patrick Brandt)
Date: Thu, 17 Apr 2008 17:22:08 -0500
Subject: [R-SIG-Finance] Causality test
In-Reply-To: <15566380.194111208466638691.JavaMail.root@vms075.mailsrvcs.net>
References: <15566380.194111208466638691.JavaMail.root@vms075.mailsrvcs.net>
Message-ID: <232e3f240804171522y58e66556j7e23a336f6bf31b0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080417/852cc489/attachment.pl 

From christian.kleiber at unibas.ch  Fri Apr 18 14:38:06 2008
From: christian.kleiber at unibas.ch (Christian Kleiber)
Date: Fri, 18 Apr 2008 14:38:06 +0200
Subject: [R-SIG-Finance] CFE'08 - Final call for papers
Message-ID: <4808962E.6040300@unibas.ch>

Dear useRs,

*Final call for papers*

Just a reminder that the abstract submission deadline

   2008-04-30

for the workshop

   Computational and Financial Econometrics (CFE'08)
   June 19-21, 2008,
   Neuchatel, Switzerland
   http://www.dcs.bbk.ac.uk/cfe08/

is approaching rapidly.

In this workshop, Achim Zeileis and myself are organizing a session on

   Computational Econometrics and Finance in R.

If you are interested in presenting in this session, please let me know
asap in an informal mail.

Best regards,
Christian Kleiber


-- 
Christian Kleiber
Professor of Econometrics and Statistics
WWZ, Universitaet Basel
Petersgraben 51
CH-4003 Basel
Switzerland

t +41 61 267 3367
f +41 61 267 3351
e christian.kleiber at unibas.ch


From markus at insightfromdata.com  Mon Apr 21 16:09:55 2008
From: markus at insightfromdata.com (Markus Loecher)
Date: Mon, 21 Apr 2008 10:09:55 -0400
Subject: [R-SIG-Finance] Estimating hour-of-day effects for count timeseries
Message-ID: <C4321873.B2A%markus@insightfromdata.com>

Dear all,
I am trying to model the hour-of-day effect of an overdispersed timeseries
of count data with a negative binomial distribution.
A toy example would be the following code sniplet, where x represents the
hour of day (1-24).

  x <- rep(1:24,50);
  x.df <- 
cbind.data.frame(y=rnbinom(length(x),mu=10*abs(sin(2*pi*x/24)+1.5),size =
2),x=x);
  x.glm <- glm(y~factor(x)-1,data = x.df, family=quasipoisson);

While this works fine to model overall overdispersion, I would also like to
set up a model with a different estimated overdispersion parameter for each
level of x. 
And when that is all done, I would like to conduct some ANOVA type model
comparison between this saturated model and the sparse model.
Do I need to switch to mixed effects models, such as lmer() ?

Thanks !

Markus


From rfiser at gmail.com  Mon Apr 21 21:00:15 2008
From: rfiser at gmail.com (=?WINDOWS-1252?Q?Radovan_Fi=9Aer?=)
Date: Mon, 21 Apr 2008 21:00:15 +0200
Subject: [R-SIG-Finance] External regressors in GARCH variance eq.
Message-ID: <195947bc0804211200v17d59185g7f0b4596333d1f19@mail.gmail.com>

Hello to all R users,

up to my knowledge, neither garch(tseries) nor garchFit(fGarch)
support including external regressors in variance equation regression
(not mean), which, for  example, arima(stats) can do by setting xreg.
Is there a package or any other way that can do this?

 To be precise, I want to estimate a variance equation that goes like this:
 h_t = arch_t + garch_t + dummy1_t + dummy2_t + v_t.

 Any advise appreciated!

 Radovan Fiser

--
 Institute of Economic Studies
 Prague
 http://ies.fsv.cuni.cz/
 radekf.net
 bikeri.cz - kostelnibriza.cz - fiserovi.cz - hcsgang.com


From jaromir.baxa at centrum.cz  Tue Apr 22 08:53:41 2008
From: jaromir.baxa at centrum.cz (Jaromir Baxa)
Date: Tue, 22 Apr 2008 08:53:41 +0200
Subject: [R-SIG-Finance] External regressors in GARCH variance eq.
In-Reply-To: <195947bc0804211200v17d59185g7f0b4596333d1f19@mail.gmail.com>
References: <195947bc0804211200v17d59185g7f0b4596333d1f19@mail.gmail.com>
Message-ID: <op.t9z2rrtnqapn36@los>

Don't know whether R knows that, but gretl does in its 1.7 version for  
sure. It has also direct link for export and import with R.
Best,
Jaromir Baxa

Dne Mon, 21 Apr 2008 21:00:15 +0200 Radovan Fi?er <rfiser at gmail.com>  
napsal/-a:

> Hello to all R users,
>
> up to my knowledge, neither garch(tseries) nor garchFit(fGarch)
> support including external regressors in variance equation regression
> (not mean), which, for  example, arima(stats) can do by setting xreg.
> Is there a package or any other way that can do this?
>
>  To be precise, I want to estimate a variance equation that goes like  
> this:
>  h_t = arch_t + garch_t + dummy1_t + dummy2_t + v_t.
>
>  Any advise appreciated!
>
>  Radovan Fiser
>
> --
>  Institute of Economic Studies
>  Prague
>  http://ies.fsv.cuni.cz/
>  radekf.net
>  bikeri.cz - kostelnibriza.cz - fiserovi.cz - hcsgang.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
>
>


From learningaddict83 at yahoo.com  Wed Apr 23 13:15:16 2008
From: learningaddict83 at yahoo.com (Aditya)
Date: Wed, 23 Apr 2008 04:15:16 -0700 (PDT)
Subject: [R-SIG-Finance] Conditional Variance in GARCH Model?
Message-ID: <126890.50459.qm@web45107.mail.sp1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080423/348adfd6/attachment.pl 

From mmiklovic at yahoo.com  Wed Apr 23 17:01:24 2008
From: mmiklovic at yahoo.com (michal miklovic)
Date: Wed, 23 Apr 2008 08:01:24 -0700 (PDT)
Subject: [R-SIG-Finance] Conditional Variance in GARCH Model?
Message-ID: <739621.1306.qm@web50111.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080423/cd72e8d0/attachment.pl 

From Timothy.Roberts at sigmacapny.com  Thu Apr 24 15:35:28 2008
From: Timothy.Roberts at sigmacapny.com (Roberts, Timothy)
Date: Thu, 24 Apr 2008 09:35:28 -0400
Subject: [R-SIG-Finance] Rbloomberg Crash Fixed
Message-ID: <89A0D10DBCB6DB4B9582994875D66E4201CDD48B@MAILNYIS03.saccap.int>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080424/ab237d32/attachment.pl 

From Dennis.D.Tuerk at wirtschaft.uni-giessen.de  Thu Apr 24 16:07:03 2008
From: Dennis.D.Tuerk at wirtschaft.uni-giessen.de (=?iso-8859-1?Q?Dennis_T=FCrk?=)
Date: Thu, 24 Apr 2008 16:07:03 +0200
Subject: [R-SIG-Finance] Inequality Constraints for GARCH using Matlab
Message-ID: <001d01c8a614$79005200$5852b086@fb02statw01>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080424/0945c085/attachment.pl 

From bastian2507hk at yahoo.co.uk  Thu Apr 24 15:47:05 2008
From: bastian2507hk at yahoo.co.uk (Bastian Offermann)
Date: Thu, 24 Apr 2008 15:47:05 +0200
Subject: [R-SIG-Finance] arma model fitting
Message-ID: <23263.82399.bm@omp211.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080424/2779c1fc/attachment.pl 

From finbref.2006 at gmail.com  Thu Apr 24 19:37:03 2008
From: finbref.2006 at gmail.com (Thomas Steiner)
Date: Thu, 24 Apr 2008 19:37:03 +0200
Subject: [R-SIG-Finance] Rbloomberg Crash Fixed
In-Reply-To: <89A0D10DBCB6DB4B9582994875D66E4201CDD48B@MAILNYIS03.saccap.int>
References: <89A0D10DBCB6DB4B9582994875D66E4201CDD48B@MAILNYIS03.saccap.int>
Message-ID: <d0f55a670804241037l2ab0ca9cqab91b433b7add51c@mail.gmail.com>

You are talking about this problem:
https://stat.ethz.ch/pipermail/r-sig-finance/2006q3/001029.html ?

Sounds great, this is really helpful, but I cannot "apply" this
workaround at work, they will never give me admin rights for anything.
And I guess I am not alone with this problem. If you can locate the
problem, perhaps the RDCOMClient people could then fix it?

Thomas


From brian at braverock.com  Thu Apr 24 19:47:55 2008
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 24 Apr 2008 12:47:55 -0500
Subject: [R-SIG-Finance] Rbloomberg Crash Fixed
In-Reply-To: <d0f55a670804241037l2ab0ca9cqab91b433b7add51c@mail.gmail.com>
References: <89A0D10DBCB6DB4B9582994875D66E4201CDD48B@MAILNYIS03.saccap.int>
	<d0f55a670804241037l2ab0ca9cqab91b433b7add51c@mail.gmail.com>
Message-ID: <4810C7CB.8020602@braverock.com>

Thomas Steiner wrote:
> You are talking about this problem:
> https://stat.ethz.ch/pipermail/r-sig-finance/2006q3/001029.html ?
> 
> Sounds great, this is really helpful, but I cannot "apply" this
> workaround at work, they will never give me admin rights for anything.
> And I guess I am not alone with this problem. If you can locate the
> problem, perhaps the RDCOMClient people could then fix it?

If the problem is Windows security permissions, then the answer will 
probably be in the Windows security settings.  No,w, it is possible that 
some set of permissions less than "admin rights" would still suffice.  I 
suggest talking to your information security folks, and having them work 
with you to make the applications work together.

Regards,

   - Brian


From mmiklovic at yahoo.com  Fri Apr 25 11:51:20 2008
From: mmiklovic at yahoo.com (michal miklovic)
Date: Fri, 25 Apr 2008 02:51:20 -0700 (PDT)
Subject: [R-SIG-Finance] arma model fitting
Message-ID: <42145.88416.qm@web50103.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080425/cc0a5d7c/attachment.pl 

From david.jessop at ubs.com  Fri Apr 25 12:34:13 2008
From: david.jessop at ubs.com (david.jessop at ubs.com)
Date: Fri, 25 Apr 2008 11:34:13 +0100
Subject: [R-SIG-Finance] Rbloomberg Crash Fixed
Message-ID: <25492B412B325B4FB1FED95013D3E5CE03BC7B87@NLDNC105PEX1.ubsw.net>

Hi,

Given that most problems with security under Windows come from running as admin and that most security experts suggest that you don't then surely fixing the problem with the code is the right solution; not getting "enough" admin rights to make it work.

David Jessop
--------------------------
David Jessop
Global Head of Quantitative Research
UBS Investment Research

+44 20 7567 9882
-------------- next part --------------
Issued by UBS AG or affiliates to professional investors for 
information only and its accuracy/completeness is not guaranteed. 
All opinions may change without notice and may differ to 
opinions/recommendations expressed by other business areas of UBS. 
UBS may maintain long/short positions and trade in instruments 
referred to. Unless stated otherwise, this is not a personal 
recommendation, offer or solicitation to buy/sell and any 
prices/quotations are indicative only. UBS may provide investment 
banking and other services to, and/or its employees may be directors 
of, companies referred to. To the extent permitted by law, UBS does 
not accept any liability arising from the use of this communication.

 ? UBS 2008.  All rights reserved. Intended for recipient only
and not for further distribution without the consent of UBS.

UBS Limited is a company registered in England & Wales under company
number 2035362, whose registered office is at 1 Finsbury Avenue,
London, EC2M 2PP, United Kingdom.

UBS AG (London Branch) is registered as a branch of a foreign company
under number BR004507, whose registered office is at
1 Finsbury Avenue, London, EC2M 2PP, United Kingdom.

UBS Clearing and Execution Services Limited is a company registered
in England & Wales under company number 03123037, whose registered
office is at 1 Finsbury Avenue, London, EC2M 2PP, United Kingdom.








From nelson.ana at gmail.com  Fri Apr 25 13:50:28 2008
From: nelson.ana at gmail.com (Ana Nelson)
Date: Fri, 25 Apr 2008 12:50:28 +0100
Subject: [R-SIG-Finance] Rbloomberg Crash Fixed
In-Reply-To: <25492B412B325B4FB1FED95013D3E5CE03BC7B87@NLDNC105PEX1.ubsw.net>
References: <25492B412B325B4FB1FED95013D3E5CE03BC7B87@NLDNC105PEX1.ubsw.net>
Message-ID: <a7d6d2740804250450u4e42f21bx484d5abb069e894f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080425/92739add/attachment.pl 

From adnen.chockri at gmail.com  Fri Apr 25 15:30:34 2008
From: adnen.chockri at gmail.com (chockri adnen)
Date: Fri, 25 Apr 2008 15:30:34 +0200
Subject: [R-SIG-Finance] Database : High frequency data
Message-ID: <33c60e200804250630t5e2b906j5799310803629bcd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080425/5f50d441/attachment.pl 

From armstrong.whit at gmail.com  Fri Apr 25 15:34:16 2008
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Fri, 25 Apr 2008 09:34:16 -0400
Subject: [R-SIG-Finance] Database : High frequency data
In-Reply-To: <33c60e200804250630t5e2b906j5799310803629bcd@mail.gmail.com>
References: <33c60e200804250630t5e2b906j5799310803629bcd@mail.gmail.com>
Message-ID: <8ec76080804250634n29552ac2wefa77645896ec9ee@mail.gmail.com>

CQG has very good data.
https://www.cqgdatafactory.com/

and LIM or BBG is probably your best bet for economic releases.
http://lim.com/

-Whit


On Fri, Apr 25, 2008 at 9:30 AM, chockri adnen <adnen.chockri at gmail.com> wrote:
> Hello,
>
>  I'm searching a database covering the entire calendar years  2002-2004 about
>  exchange rate returns for dollar versus euro frequency 5 minute or 10 minute
>  or 20 minute and the macroeconomic announcements (US, Euro area).
>
>  Please if anyone have an idea to help me.
>
>
>  Thanks,
>
>
>  Best Regards,
>
>
>  Adnen CHOCKRI
>
>         [[alternative HTML version deleted]]
>
>  _______________________________________________
>  R-SIG-Finance at stat.math.ethz.ch mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>  -- Subscriber-posting only.
>  -- If you want to post, subscribe first.
>


From josh.m.ulrich at gmail.com  Fri Apr 25 15:42:24 2008
From: josh.m.ulrich at gmail.com (Josh Ulrich)
Date: Fri, 25 Apr 2008 08:42:24 -0500
Subject: [R-SIG-Finance] Database : High frequency data
In-Reply-To: <8ec76080804250634n29552ac2wefa77645896ec9ee@mail.gmail.com>
References: <33c60e200804250630t5e2b906j5799310803629bcd@mail.gmail.com>
	<8ec76080804250634n29552ac2wefa77645896ec9ee@mail.gmail.com>
Message-ID: <8cca69990804250642l196dc8d9rbca48c50e14337f9@mail.gmail.com>

I've had good experience with Olson Financial Technologies foreign
exchange data.
http://www.olsendata.com/

Best,
Josh

-- 
http://quantemplation.blogspot.com


On Fri, Apr 25, 2008 at 8:34 AM, Whit Armstrong
<armstrong.whit at gmail.com> wrote:
> CQG has very good data.
>  https://www.cqgdatafactory.com/
>
>  and LIM or BBG is probably your best bet for economic releases.
>  http://lim.com/
>
>  -Whit
>
>
>  On Fri, Apr 25, 2008 at 9:30 AM, chockri adnen <adnen.chockri at gmail.com> wrote:
>  > Hello,
>  >
>  >  I'm searching a database covering the entire calendar years  2002-2004 about
>  >  exchange rate returns for dollar versus euro frequency 5 minute or 10 minute
>  >  or 20 minute and the macroeconomic announcements (US, Euro area).
>  >
>  >  Please if anyone have an idea to help me.
>  >
>  >
>  >  Thanks,
>  >
>  >
>  >  Best Regards,
>  >
>  >
>  >  Adnen CHOCKRI
>  >
>  >         [[alternative HTML version deleted]]
>  >
>  >  _______________________________________________
>  >  R-SIG-Finance at stat.math.ethz.ch mailing list
>  >  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>  >  -- Subscriber-posting only.
>  >  -- If you want to post, subscribe first.
>  >
>
>  _______________________________________________
>  R-SIG-Finance at stat.math.ethz.ch mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>  -- Subscriber-posting only.
>  -- If you want to post, subscribe first.
>


From adnen.chockri at gmail.com  Fri Apr 25 15:56:54 2008
From: adnen.chockri at gmail.com (chockri adnen)
Date: Fri, 25 Apr 2008 15:56:54 +0200
Subject: [R-SIG-Finance] Database : High frequency data
In-Reply-To: <8cca69990804250642l196dc8d9rbca48c50e14337f9@mail.gmail.com>
References: <33c60e200804250630t5e2b906j5799310803629bcd@mail.gmail.com>
	<8ec76080804250634n29552ac2wefa77645896ec9ee@mail.gmail.com>
	<8cca69990804250642l196dc8d9rbca48c50e14337f9@mail.gmail.com>
Message-ID: <33c60e200804250656o35d5f2f4l630831f1f9520223@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080425/60abcfd2/attachment.pl 

From drodriguez007 at gmail.com  Fri Apr 25 15:59:20 2008
From: drodriguez007 at gmail.com (David Rodriguez)
Date: Fri, 25 Apr 2008 09:59:20 -0400
Subject: [R-SIG-Finance] Database : High frequency data
In-Reply-To: <8dab790b0804250658g73793320sb09e08bc793be730@mail.gmail.com>
References: <33c60e200804250630t5e2b906j5799310803629bcd@mail.gmail.com>
	<8ec76080804250634n29552ac2wefa77645896ec9ee@mail.gmail.com>
	<8dab790b0804250658g73793320sb09e08bc793be730@mail.gmail.com>
Message-ID: <8dab790b0804250659u1540df64i533617d3d0cf0fa4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080425/b5012918/attachment.pl 

From ryan.sheftel at malbecpartners.com  Fri Apr 25 16:22:19 2008
From: ryan.sheftel at malbecpartners.com (Ryan Sheftel)
Date: Fri, 25 Apr 2008 10:22:19 -0400
Subject: [R-SIG-Finance] Database : High frequency data
In-Reply-To: <8ec76080804250634n29552ac2wefa77645896ec9ee@mail.gmail.com>
Message-ID: <OF3B58C6F2.E833C008-ON85257436.004B1FC9-85257436.004EF256@fftw.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080425/38b0f8e0/attachment.pl 

From adnen.chockri at gmail.com  Fri Apr 25 19:21:17 2008
From: adnen.chockri at gmail.com (chockri adnen)
Date: Fri, 25 Apr 2008 19:21:17 +0200
Subject: [R-SIG-Finance] Database : High frequency data
In-Reply-To: <OF3B58C6F2.E833C008-ON85257436.004B1FC9-85257436.004EF256@fftw.com>
References: <8ec76080804250634n29552ac2wefa77645896ec9ee@mail.gmail.com>
	<OF3B58C6F2.E833C008-ON85257436.004B1FC9-85257436.004EF256@fftw.com>
Message-ID: <33c60e200804251021t3102ebbre8f01ad6c1cc6405@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080425/86fa30a4/attachment.pl 

From brian at braverock.com  Fri Apr 25 19:26:04 2008
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 25 Apr 2008 12:26:04 -0500
Subject: [R-SIG-Finance] Database : High frequency data
In-Reply-To: <33c60e200804251021t3102ebbre8f01ad6c1cc6405@mail.gmail.com>
References: <8ec76080804250634n29552ac2wefa77645896ec9ee@mail.gmail.com>	<OF3B58C6F2.E833C008-ON85257436.004B1FC9-85257436.004EF256@fftw.com>
	<33c60e200804251021t3102ebbre8f01ad6c1cc6405@mail.gmail.com>
Message-ID: <4812142C.4010503@braverock.com>

chockri adnen wrote:
> Hello,
> Thanks for all answer but the problem :
> when I 'm reading the most article about the impact of macroeconomic news on
> exchange rate volatility, I note the data are from Olsen Financial
> Technologies Foreign. But the problem the price of data is expensive for me
> ( i'm from Tunisia). So i'm searching who have this database.
> 
> 
> Thanks for your help and understanding


Adnen,

I believe in one of your earlier posts that you said that you were an 
academic.  I believe that your best next step might be to contact Olsen 
and the other data providers mentioned here directly and ask them about 
their policy for sharing data with academics for research purposes. 
Many organizations have academic waivers for their licensing fees, and 
may be willing to provide you the information that you seek free of 
charge for your research.

Regards,

   - Brian


From Gaurav_Jasoria at ml.com  Mon Apr 28 17:12:58 2008
From: Gaurav_Jasoria at ml.com (Jasoria,
	Gaurav (GMI - Global Product Development))
Date: Mon, 28 Apr 2008 11:12:58 -0400
Subject: [R-SIG-Finance] Handling multiple files to generate Charts
Message-ID: <CF2F11E8C2C78E499ECBF3C5F22A7E5794A1A6@MLNYC20MB058.amrs.win.ml.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080428/cc89922d/attachment.pl>

From berekket at gmail.com  Tue Apr 29 00:29:48 2008
From: berekket at gmail.com (bereket weldeslassie)
Date: Mon, 28 Apr 2008 16:29:48 -0600
Subject: [R-SIG-Finance] cointegration and causality test
Message-ID: <4bc7c8760804281529y4f7316d7p42cf2d7c79d1b1aa@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080428/dabd5257/attachment.pl>

From Bernhard_Pfaff at fra.invesco.com  Tue Apr 29 10:08:08 2008
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Tue, 29 Apr 2008 09:08:08 +0100
Subject: [R-SIG-Finance] cointegration and causality test
In-Reply-To: <4bc7c8760804281529y4f7316d7p42cf2d7c79d1b1aa@mail.gmail.com>
References: <4bc7c8760804281529y4f7316d7p42cf2d7c79d1b1aa@mail.gmail.com>
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C3103D4496@GBHENXMB02.corp.amvescap.net>

Hello Bereket,

you might find this article of interest:
http://edoc.hu-berlin.de/series/sfb-373-papers/1999-4/PDF/4.pdf

The section on causality adresses your problem. You might find the
function cajorls() helpful in this context. Furthermore, if you want to
analyse your cointegration vector in more detail, have a look at the
functions: alrtest(), ablrtest() and blrtest().

Best,
Bernhard 

>Dear All,
>I am doing cointegration and causality test among four variables. I
>performed the cointegration test using ca.jo() function and 
>the result of
>trace test is:
>          test 10pct  5pct  1pct
>r <= 3 |  2.76  7.52  9.24 12.97
>r <= 2 |  9.56 17.85 19.96 24.60
>r <= 1 | 29.03 32.00 34.91 41.07
>r = 0  | 62.64 49.65 53.12 60.16
>which indicates that there is one cointegrating vector.
>Then estimated the OLS regressions of the VECM to identify the 
>significant
>vector (variables) and the result looks like:
>Response E.d :
>Coefficients:
>            Estimate Std. Error t value Pr(>|t|)
>E.dl1       0.035197   0.243545   0.145   0.8865
>PUTEP1.dl1  0.006782   0.274279   0.025   0.9805
>PEPCC.dl1  -0.281715   0.273295  -1.031   0.3144
>Exr.dl1     0.005339   0.146832   0.036   0.9713
>E.l1       -0.709115   0.309944  -2.288   0.0326 *
>PUTEP1.l1  -0.185750   0.172672  -1.076   0.2942
>PEPCC.l1    0.583796   0.381307   1.531   0.1407
>Exr.l1     -0.157639   0.186751  -0.844   0.4081
>constant    5.922444   2.997794   1.976   0.0615 .
>---
>Multiple R-Squared:  0.32,      Adjusted R-squared: 0.02863
>F-statistic: 1.098 on 9 and 21 DF,  p-value: 0.4051
>
>Response PUTEP1.d :
>Coefficients:
>           Estimate Std. Error t value Pr(>|t|)
>E.dl1       -0.2689     0.2637  -1.020    0.319
>PUTEP1.dl1   0.1924     0.2970   0.648    0.524
>PEPCC.dl1    0.1488     0.2959   0.503    0.620
>Exr.dl1     -0.1387     0.1590  -0.872    0.393
>E.l1         0.3942     0.3356   1.175    0.253
>PUTEP1.l1    0.2514     0.1870   1.345    0.193
>PEPCC.l1    -0.5425     0.4128  -1.314    0.203
>Exr.l1       0.2921     0.2022   1.445    0.163
>constant    -4.2368     3.2457  -1.305    0.206
>Residual standard error: 0.1083 on 21 degrees of freedom
>Multiple R-Squared: 0.4095,     Adjusted R-squared: 0.1564
>F-statistic: 1.618 on 9 and 21 DF,  p-value: 0.1740
>
>Response PEPCC.d :
>Coefficients:
>           Estimate Std. Error t value Pr(>|t|)
>E.dl1       0.04139    0.21105   0.196   0.8464
>PUTEP1.dl1  0.36818    0.23768   1.549   0.1363
>PEPCC.dl1  -0.03719    0.23683  -0.157   0.8767
>Exr.dl1     0.11927    0.12724   0.937   0.3592
>E.l1        0.18207    0.26859   0.678   0.5053
>PUTEP1.l1   0.36989    0.14963   2.472   0.0221 *
>PEPCC.l1   -0.80442    0.33043  -2.435   0.0239 *
>Exr.l1     -0.01621    0.16183  -0.100   0.9212
>constant   -1.19117    2.59777  -0.459   0.6513
>---
>Residual standard error: 0.08666 on 21 degrees of freedom
>Multiple R-Squared: 0.581,      Adjusted R-squared: 0.4014
>F-statistic: 3.235 on 9 and 21 DF,  p-value: 0.01275
>
>Response Exr.d :
>Coefficients:
>           Estimate Std. Error t value Pr(>|t|)
>E.dl1       0.22674    0.25078   0.904  0.37617
>PUTEP1.dl1  0.70895    0.28243   2.510  0.02032 *
>PEPCC.dl1  -0.03344    0.28141  -0.119  0.90653
>Exr.dl1     0.27850    0.15119   1.842  0.07964 .
>E.l1       -0.70257    0.31915  -2.201  0.03903 *
>PUTEP1.l1  -0.40521    0.17780  -2.279  0.03323 *
>PEPCC.l1    0.74434    0.39263   1.896  0.07184 .
>Exr.l1     -0.93802    0.19230  -4.878    8e-05 ***
>constant    9.64131    3.08684   3.123  0.00514 **
>---
>Residual standard error: 0.103 on 21 degrees of freedom
>Multiple R-Squared: 0.6468,     Adjusted R-squared: 0.4955
>F-statistic: 4.274 on 9 and 21 DF,  p-value: 0.002914
>I also performed the Granger causality test using 
>granger.test() function
>and the result looks like:
>                 F-statistic      p-value
>dPUTEP1 -> dE       0.2652173 0.6107489208
>dPEPCC -> dE        0.3099271 0.5823104521
>dExr -> dE          0.0756436 0.7853839986
>dE -> dPUTEP1       0.2927093 0.5929257035
>dPEPCC -> dPUTEP1   0.9240658 0.3449401105
>dExr -> dPUTEP1     0.5893134 0.4493465819
>dE -> dPEPCC        1.2787679 0.2680733692
>dPUTEP1 -> dPEPCC  16.4966125 0.0003759451
>dExr -> dPEPCC      0.0877026 0.7693843210
>dE -> dExr          0.7935924 0.3808859838
>dPUTEP1 -> dExr     1.8548683 0.1844741419
>dPEPCC -> dExr      2.5682890 0.1206617216
>The granger causality test shows that dPUTEP1 causes dPEPCC 
>but in addition
>to that the OLS of the VECM shows that PUTEP1 and E.l1 also 
>causes dExr.
>Given that there is only one cointegrating vector, which way 
>is the right
>way to identify that cointegrating vector? Do I have to use 
>the OLS of the
>VECM? If so, the OLS is showing more than one cointegrating 
>vector. that was
>my confusion. Any help is highly appreciated.
>Thanks,
>Bereket
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-SIG-Finance at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>-- Subscriber-posting only.
>-- If you want to post, subscribe first.
>
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:10}}


From weihanliu2002 at yahoo.com  Wed Apr 30 05:25:25 2008
From: weihanliu2002 at yahoo.com (Wei-han Liu)
Date: Tue, 29 Apr 2008 20:25:25 -0700 (PDT)
Subject: [R-SIG-Finance] rare event simulation
Message-ID: <394354.44294.qm@web53502.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080429/d267596b/attachment.pl>

From Bernhard_Pfaff at fra.invesco.com  Wed Apr 30 10:57:00 2008
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Wed, 30 Apr 2008 09:57:00 +0100
Subject: [R-SIG-Finance] rare event simulation
In-Reply-To: <394354.44294.qm@web53502.mail.re2.yahoo.com>
References: <394354.44294.qm@web53502.mail.re2.yahoo.com>
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C310571BE7@GBHENXMB02.corp.amvescap.net>

>Hello R users:
>I wonder if somebody can be kind enough to share some 
>information about rare event simulation, e.g. referecne, 
>coding, packages.


Hello Wei-han,

do you mean by rare event simulation extreme value theory (EVT) and risk
measures like VaR and ES? If so, the following CRAN-packages might be of
interest to you:

evd, fExtremes, ismev, POT, QRMlib and VaR

Have a look at the "Finance" task view (bullet point "Risk management")
on CRAN.

Best,
Bernhard

>Many thanks to your attention.
>Wei-han Liu
>
>
>      
>_______________________________________________________________
>_____________________
>
>[[elided Yahoo spam]]
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-SIG-Finance at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>-- Subscriber-posting only.
>-- If you want to post, subscribe first.
>
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:10}}


From frainj at tcd.ie  Thu May  1 23:23:47 2008
From: frainj at tcd.ie (John Frain)
Date: Thu, 1 May 2008 22:23:47 +0100
Subject: [R-SIG-Finance] Estimating the T-S Garch model
Message-ID: <cfdde1650805011423y30bc38d5lb092dd9e3dbb9c8b@mail.gmail.com>

I am trying to estimate a T-S Garch model with the following code -

library(fGarch)
myFinCenter =  "GMT"
dframe=read.csv(file="loss.csv")
dframe[1:5,]
loss=as.timeSeries(dframe)
head(loss)
tail(loss)
fit = garchFit(formula = ~ aparch(1,1), data=loss at Data, delta=1.0,
include.delta=FALSE,trace=FALSE)
summary(fit)
fit2 = garchFit(formula = ~ aparch(1,1), data=loss at Data, delta=1.0,
include.delta=FALSE,leverage=FALSE)

Output is at the end of the email.  I can estimate a model with
nonzero leverage (gamma1 non-zero) but I have problems when I try to
force gamma1 to be zero.  (See message at end of output.  Is there a
problem or have I not understood something.
I am using Windows XP,  R 2.7.0 and fGarch 260.72.  The data-set
loss.csv is attached.


-- 
John C Frain
Trinity College Dublin
Dublin 2
Ireland
www.tcd.ie/Economics/staff/frainj/home.htm
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


############## OUTPUT ##############################

> library(fGarch)
> myFinCenter =  "GMT"
> dframe=read.csv(file="loss.csv")
> dframe[1:5,]
           X       loss
1 1988-01-05 -3.2854337
2 1988-01-06 -2.6706190
3 1988-01-07  0.3662351
4 1988-01-08 -1.8030495
5 1988-01-11  1.1893279
> loss=as.timeSeries(dframe)
> head(loss)
                 TS.1
1988-01-05 -3.2854337
1988-01-06 -2.6706190
1988-01-07  0.3662351
1988-01-08 -1.8030495
1988-01-11  1.1893279
1988-01-12 -0.1981119
> tail(loss)
                 TS.1
2008-01-24 -4.8668943
2008-01-25  0.7808780
2008-01-28  1.7767990
2008-01-29 -1.1739951
2008-01-30 -0.5321964
2008-01-31  1.3622478
> fit = garchFit(formula = ~ aparch(1,1), data=loss at Data, delta=1.0, include.delta=FALSE,trace=FALSE)
> summary(fit)

Title:
 GARCH Modelling

Call:
 garchFit(formula = ~aparch(1, 1), data = loss at Data, delta = 1,
    include.delta = FALSE, trace = FALSE)

Mean and Variance Equation:
 ~arma(0, 0) + ~aparch(1, 1)

Conditional Distribution:
 dnorm

Coefficient(s):
        mu       omega      alpha1      gamma1       beta1
-0.0624601   0.0274496   0.0816745  -0.3396468   0.9100114

Error Analysis:
        Estimate  Std. Error  t value Pr(>|t|)
mu     -0.062460    0.011934   -5.234 1.66e-07 ***
omega   0.027450    0.005269    5.210 1.89e-07 ***
alpha1  0.081675    0.009555    8.548  < 2e-16 ***
gamma1 -0.339647    0.047851   -7.098 1.27e-12 ***
beta1   0.910011    0.011797   77.139  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Log Likelihood:
 6630.546    normalized:  1.316368

Standadized Residuals Tests:
                                Statistic p-Value
 Jarque-Bera Test   R    Chi^2  5720.432  0
 Shapiro-Wilk Test  R    W      NA        NA
 Ljung-Box Test     R    Q(10)  102.3393  0
 Ljung-Box Test     R    Q(15)  108.0036  4.440892e-16
 Ljung-Box Test     R    Q(20)  118.3874  5.551115e-16
 Ljung-Box Test     R^2  Q(10)  80.30754  4.369838e-13
 Ljung-Box Test     R^2  Q(15)  86.34728  4.738099e-12
 Ljung-Box Test     R^2  Q(20)  88.63123  1.28495e-10
 LM Arch Test       R    TR^2   66.55288  1.405827e-09

Information Criterion Statistics:
      AIC       BIC       SIC      HQIC
-2.630751 -2.624274 -2.630753 -2.628482

Description:
 Thu May 01 20:58:17 2008 by user: John C Frain

> fit = garchFit(formula = ~ aparch(1,1), data=loss at Data, delta=1.0, include.delta=FALSE,leverage=FALSE)

Series Initialization:
 ARMA model:                arma
 Formula mean:              ~ arma(0, 0)
 GARCH model:               aparch
 Formula var:               ~ aparch(1, 1)
 ARMA Order:                0 0
 Max ARMA Order:            0
 GARCH Order:               1 1
 Max GARCH Order:           1
 Maximum Order:             1
 h.start:                   2
 llh.start:                 1
 Length of Series:          5037
 Recursion Init:            mci
 Series Scale:              1.000351

Parameter Initialization:
 Initial Parameters:          $params
 Limits of Transformations:   $U, $V
 Which Parameters are Fixed?  $includes
 Parameter Matrix:
                       U           V      params includes
    mu     -4.830854e-01   0.4830854 -0.04830854     TRUE
    omega   1.000703e-06 100.0703024  0.10007030     TRUE
    alpha1  1.000000e-08   1.0000000  0.10000000     TRUE
    gamma1 -1.000000e+00   1.0000000  0.10000000    FALSE
    beta1   1.000000e-08   1.0000000  0.80000000     TRUE
    delta   0.000000e+00   2.0000000  1.00000000    FALSE
    skew    1.000000e-01  10.0000000  1.00000000    FALSE
    shape   1.000000e+00  20.0000000  4.00000000    FALSE
 Index List of Parameters to be Optimized:
    mu  omega alpha1  beta1
     1      2      3      5
 Persistence:                  0.8797885

Iteration Path:



Now NLMINB


Error in gamma[i] : object is not subsettable
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: loss.csv
Type: application/vnd.ms-excel
Size: 153809 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080501/da9c539e/attachment.xlb>

From mmiklovic at yahoo.com  Thu May  1 23:58:29 2008
From: mmiklovic at yahoo.com (michal miklovic)
Date: Thu, 1 May 2008 14:58:29 -0700 (PDT)
Subject: [R-SIG-Finance] Estimating the T-S Garch model
Message-ID: <620148.39708.qm@web50108.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080501/ef8c91e9/attachment.pl>

From frainj at tcd.ie  Fri May  2 12:01:13 2008
From: frainj at tcd.ie (John Frain)
Date: Fri, 2 May 2008 11:01:13 +0100
Subject: [R-SIG-Finance] Estimating the T-S Garch model
In-Reply-To: <620148.39708.qm@web50108.mail.re2.yahoo.com>
References: <620148.39708.qm@web50108.mail.re2.yahoo.com>
Message-ID: <cfdde1650805020301j370fc6f4td5ed15dc0b65cfec@mail.gmail.com>

Thanks.  The TS-Garch is now working as expected.

I had updated all the packages in the order specified except
fUnitroots.  When I load fGarch I get a warning message (output below)
which not be important (it is only a warning message).  The downloaded
fUnitroots.zip is only  9KB.  I have tried several times  but can not
download the full file.If I try

install.packages("fUnitRoots",repos="http://R-Forge.R-project.org")

I get a warning message

package  fUnitRoots is not available.

Best Regards

John

> library(fGarch)
Loading required package: fBasics
Loading required package: MASS
Loading required package: fImport
Loading required package: fSeries
Loading required package: robustbase
Loading required package: fCalendar
Loading required package: fEcofin
Loading required package: fUtilities
Rmetrics Package fUtilities (270.73) loaded.
Rmetrics Package fEcofin (270.73) loaded.
Rmetrics Package fCalendar (270.74) loaded.
Rmetrics Package fSeries (270.73) loaded.
Rmetrics Package fImport (270.73) loaded.
Rmetrics Package fBasics (270.73) loaded.
Loading required package: fArma
Rmetrics Package fArma (270.73) loaded.
Rmetrics Package fGarch (270.73) loaded.
Warning message:
In .recacheSubclasses(def at className, def, doSubclasses) :
  Undefined subclass, "double", of class "index_timeSeries";
definition not updated


2008/5/1 michal miklovic <mmiklovic at yahoo.com>:
>
> Hi,
>
> it is a bug and it has already been solved in the development version of
> fGarch. Rmetrics development web is at:
> http://r-forge.r-project.org/projects/rmetrics
> where you can find the latest versions of all packages. Download the zipped
> Windows binaries and install them in the following order:
> fUtilities, fEcofin, fCalendar, fSeries, fImport, fBasics, fBonds, fArma,
> fGarch, fTrading, fExtremes, fNonlinear, fOptions, fAsianOptions,
> fExoticOptions, fUnitRoots, fMultivar, fCopulae, fRegression, fAssets,
> fPortfolio, Rmetrics
> and the estimation should work fine.
>
> Best regards,
>
> Michal
>
>
>
>
> ----- Original Message ----
> From: John Frain <frainj at tcd.ie>
> To: R-SIG-Finance mailing list <r-sig-finance at stat.math.ethz.ch>
> Sent: Thursday, May 1, 2008 11:23:47 PM
> Subject: [R-SIG-Finance] Estimating the T-S Garch model
>
>  I am trying to estimate a T-S Garch model with the following code -
>
> library(fGarch)
> myFinCenter =  "GMT"
> dframe=read.csv(file="loss.csv")
> dframe[1:5,]
> loss=as.timeSeries(dframe)
> head(loss)
> tail(loss)
> fit = garchFit(formula = ~ aparch(1,1), data=loss at Data, delta=1.0,
> include.delta=FALSE,trace=FALSE)
> summary(fit)
> fit2 = garchFit(formula = ~ aparch(1,1), data=loss at Data, delta=1.0,
> include.delta=FALSE,leverage=FALSE)
>
> Output is at the end of the email.  I can estimate a model with
> nonzero leverage (gamma1 non-zero) but I have problems when I try to
> force gamma1 to be zero.  (See message at end of output.  Is there a
> problem or have I not understood something.
> I am using Windows XP,  R 2.7.0 and fGarch 260.72.  The data-set
> loss.csv is attached.
>
>
> --
> John C Frain
> Trinity College Dublin
> Dublin 2
> Ireland
> www.tcd.ie/Economics/staff/frainj/home.htm
> mailto:frainj at tcd.ie
> mailto:frainj at gmail.com
>
>
> ############## OUTPUT ##############################
>
> > library(fGarch)
> > myFinCenter =  "GMT"
> > dframe=read.csv(file="loss.csv")
> > dframe[1:5,]
>           X      loss
> 1 1988-01-05 -3.2854337
> 2 1988-01-06 -2.6706190
> 3 1988-01-07  0.3662351
> 4 1988-01-08 -1.8030495
> 5 1988-01-11  1.1893279
> > loss=as.timeSeries(dframe)
> > head(loss)
>                 TS.1
> 1988-01-05 -3.2854337
> 1988-01-06 -2.6706190
> 1988-01-07  0.3662351
> 1988-01-08 -1.8030495
> 1988-01-11  1.1893279
> 1988-01-12 -0.1981119
> > tail(loss)
>                 TS.1
> 2008-01-24 -4.8668943
> 2008-01-25  0.7808780
> 2008-01-28  1.7767990
> 2008-01-29 -1.1739951
> 2008-01-30 -0.5321964
> 2008-01-31  1.3622478
> > fit = garchFit(formula = ~ aparch(1,1), data=loss at Data, delta=1.0,
> include.delta=FALSE,trace=FALSE)
> > summary(fit)
>
> Title:
>  GARCH Modelling
>
> Call:
>  garchFit(formula = ~aparch(1, 1), data = loss at Data, delta = 1,
>     include.delta = FALSE, trace = FALSE)
>
> Mean and Variance Equation:
>  ~arma(0, 0) + ~aparch(1, 1)
>
> Conditional Distribution:
>  dnorm
>
> Coefficient(s):
>         mu      omega      alpha1      gamma1      beta1
> -0.0624601  0.0274496  0.0816745  -0.3396468  0.9100114
>
> Error Analysis:
>         Estimate  Std. Error  t value Pr(>|t|)
> mu    -0.062460    0.011934  -5.234 1.66e-07 ***
> omega  0.027450    0.005269    5.210 1.89e-07 ***
> alpha1  0.081675    0.009555    8.548  < 2e-16 ***
> gamma1 -0.339647    0.047851  -7.098 1.27e-12 ***
> beta1  0.910011    0.011797  77.139  < 2e-16 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Log Likelihood:
>  6630.546    normalized:  1.316368
>
> Standadized Residuals Tests:
>                                 Statistic p-Value
>  Jarque-Bera Test  R    Chi^2  5720.432  0
>  Shapiro-Wilk Test  R    W      NA        NA
>  Ljung-Box Test    R    Q(10)  102.3393  0
>  Ljung-Box Test    R    Q(15)  108.0036  4.440892e-16
>  Ljung-Box Test    R    Q(20)  118.3874  5.551115e-16
>  Ljung-Box Test    R^2  Q(10)  80.30754  4.369838e-13
>  Ljung-Box Test    R^2  Q(15)  86.34728  4.738099e-12
>  Ljung-Box Test    R^2  Q(20)  88.63123  1.28495e-10
>  LM Arch Test      R    TR^2  66.55288  1.405827e-09
>
> Information Criterion Statistics:
>       AIC      BIC      SIC      HQIC
> -2.630751 -2.624274 -2.630753 -2.628482
>
> Description:
>  Thu May 01 20:58:17 2008 by user: John C Frain
>
> > fit = garchFit(formula = ~ aparch(1,1), data=loss at Data, delta=1.0,
> include.delta=FALSE,leverage=FALSE)
>
> Series Initialization:
>  ARMA model:                arma
>  Formula mean:              ~ arma(0, 0)
>  GARCH model:              aparch
>  Formula var:              ~ aparch(1, 1)
>  ARMA Order:                0 0
>  Max ARMA Order:            0
>  GARCH Order:              1 1
>  Max GARCH Order:          1
>  Maximum Order:            1
>  h.start:                  2
>  llh.start:                1
>  Length of Series:          5037
>  Recursion Init:            mci
>  Series Scale:              1.000351
>
> Parameter Initialization:
>  Initial Parameters:          $params
>  Limits of Transformations:  $U, $V
>  Which Parameters are Fixed?  $includes
>  Parameter Matrix:
>                       U          V      params includes
>     mu    -4.830854e-01  0.4830854 -0.04830854    TRUE
>     omega  1.000703e-06 100.0703024  0.10007030    TRUE
>     alpha1  1.000000e-08  1.0000000  0.10000000    TRUE
>     gamma1 -1.000000e+00  1.0000000  0.10000000    FALSE
>     beta1  1.000000e-08  1.0000000  0.80000000    TRUE
>     delta  0.000000e+00  2.0000000  1.00000000    FALSE
>     skew    1.000000e-01  10.0000000  1.00000000    FALSE
>     shape  1.000000e+00  20.0000000  4.00000000    FALSE
>  Index List of Parameters to be Optimized:
>     mu  omega alpha1  beta1
>     1      2      3      5
>  Persistence:                  0.8797885
>
> Iteration Path:
>
>
>
> Now NLMINB
>
>
> Error in gamma[i] : object is not subsettable
> >
>
>
>  ________________________________
> Be a better friend, newshound, and know-it-all with Yahoo! Mobile. Try it
> now.



-- 
John C Frain
Trinity College Dublin
Dublin 2
Ireland
www.tcd.ie/Economics/staff/frainj/home.htm
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


From elise at predictionimpact.com  Sat May  3 13:42:39 2008
From: elise at predictionimpact.com (Elise Johnson)
Date: Sat, 3 May 2008 04:42:39 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Predictive Analytics Online
 Training, Half-Price thru 5/21
Message-ID: <17034339.post@talk.nabble.com>


Hi, we're kicking off a new predictive analytics online training program and
allowing people to sign up at half price until May 21st. The online training
starts July 7th and is on demand and self-paced.  It covers about 1/3 of our
in-person training seminar, and is targeted to managers and marketers who
need to make sense of customer data to predict buying behavior, profit, etc. 

You can find more info at 
http://www.predictionimpact.com/predictive-analytics-online-training.html,
e-mail training at predictionimpact.com, or call (415) 683-1146.

thanks much --Elise Johnson, Prediction Impact

-- 
View this message in context: http://www.nabble.com/Predictive-Analytics-Online-Training%2C-Half-Price-thru-5-21-tp17034339p17034339.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From burkett at uri.edu  Sat May  3 22:22:27 2008
From: burkett at uri.edu (John P. Burkett)
Date: Sat, 03 May 2008 16:22:27 -0400
Subject: [R-SIG-Finance] fPortfolio and efficient frontier
Message-ID: <481CC983.3090207@uri.edu>

Using R version 2.6.1 with package fPortfolio (260.72) running under 
Gentoo Linux, I am trying to calculate and plot an efficient frontier, 
following the example in "The fPortfolio Package" (February 16, 2008), 
p. 10.
My input code is the following:
Data = as.timeSeries(data(smallcap.ts))
Data = Data[, c("BKE", "GG", "GYMB", "KRON")]
Data
# Set Default Specifications:
Spec = portfolioSpec()
Spec
## portfolioFrontier -
# Modify Constraints - Now Long Only Constraints:
Constraint = c("minW[1:nAssets]=0")
# Calculation of the Efficient Frontier
frontier = portfolioFrontier(Data, Spec, Constraint)
print(frontier)
## plot -
# Plot Efficient Frontier with Minimum Variance Portfolio
plot(frontier, which = c(1, 3))
frontierSlider(frontier)

The output is not the hyperbola I had expected.  The command 
frontierSlider(frontier) produces an asymmetric curve whose upper branch 
is flatter than its lower branch.  At first I suspected this was just a 
graphical distortion.  However, inspecting the numerical output of 
print(frontier), I see the same asymmetry: Risk is minimized at the 
point (.09307886, 02653167) but the curve is not symmetrical around a 
horizontal line through this point. (Comparing the points 13, 31, and 49 
makes this clear. The differences in return between points 13 and 31 and 
between points 31 and 49 are virtually the same, but the difference in 
risk between points 13 and 31 is far less than between points 31 and 49.)

Is the asymmetry a bug or does it accurately represent an efficiency 
frontier of a kind different from the textbook hyperbolas?

Best regards,
John

-- 
John P. Burkett
Department of Environmental and Natural Resource Economics
and Department of Economics
University of Rhode Island
Kingston, RI 02881-0808
USA

phone (401) 874-9195


From burkett at uri.edu  Sun May  4 19:20:00 2008
From: burkett at uri.edu (John P. Burkett)
Date: Sun, 04 May 2008 13:20:00 -0400
Subject: [R-SIG-Finance] tseries and efficient frontier
Message-ID: <481DF040.5070102@uri.edu>

Yesterday I reported that my effort to compute and plot an efficient 
frontier using the fPortfolio package had produced an asymmetric curve 
rather than the anticipated hyperbola. Using the same data, I have now 
tried computing and plotting an efficient frontier using the tseries 
package. The result is again an asymmetric curve.

My code is as follows:
library(fPortfolio)
Data = as.timeSeries(data(smallcap.ts))
Data = Data[, c("BKE", "GG", "GYMB", "KRON")]
Data
x <- as.matrix(Data)
vcvd <- cov(Data)
pmv <- rep(0,100)
psv <- rep(0,100)
minr <- min(mean(Data))
maxr <- max(mean(Data))
vcv <- cov(x)
iv <- 0:99
mrv <- minr*(1-iv/99) + maxr*(iv/99)
pmv[1] <- min(mean(Data))
pmv[100] <-max(mean(Data))
psv[1] <- 0.2226543
psv[100] <- 0.1674082
for (i in 2:99) {
pmv[i] <- portfolio.optim(x, pm = mrv[i], covmat = vcv)$pm
psv[i] <- portfolio.optim(x, pm = mrv[i], covmat = vcv)$ps
}
plot(psv,pmv)

On the resulting curve, risk is minimized at point 62. But the curve is 
not symmetric around this point. (Moving 37 points in either direction 
from this point raises risk by the same amount. In contrast moving 37 
points back lowers the mean return far less than moving 37 points 
forward raises the mean return.)  I wonder whether this asymmetry is a 
bug or an accurate portrayal of a type of efficiency frontier different 
from the hyperbolas that appear in textbooks. I would be most grateful 
for suggestions about how to resolve this puzzle.

Best regards,
John


-- 
John P. Burkett
Department of Environmental and Natural Resource Economics
and Department of Economics
University of Rhode Island
Kingston, RI 02881-0808
USA

phone (401) 874-9195


From hwangzhuo2 at gmail.com  Sun May  4 22:51:22 2008
From: hwangzhuo2 at gmail.com (Albert)
Date: Sun, 4 May 2008 13:51:22 -0700
Subject: [R-SIG-Finance] For fCalendar timeDate object, howto get year, month,
	day, dayofweek, dayofmonth, dayofyear, hour, minutes, second?
In-Reply-To: <e6d785640805041349o5a4fd641g377e31e005cb1dea@mail.gmail.com>
References: <e6d785640805041349o5a4fd641g377e31e005cb1dea@mail.gmail.com>
Message-ID: <e6d785640805041351w77b34a4dr23ac0cf894aabc6d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080504/d65b1232/attachment.pl>

From cwrward at gmail.com  Sun May  4 23:44:49 2008
From: cwrward at gmail.com (Charles Ward)
Date: Sun, 4 May 2008 22:44:49 +0100
Subject: [R-SIG-Finance] tseries and efficient frontier
In-Reply-To: <481DF040.5070102@uri.edu>
References: <481DF040.5070102@uri.edu>
Message-ID: <bd9aa36b0805041444r63ad3bd4y188a0efb6311ee44@mail.gmail.com>

I think the reason is that the function "portfolio.optim"  has the
default option, short=FALSE. If you use the option short=TRUE you
should achieve the symmetrical shape of the efficient frontier.
When you constain the portfolio only to accept positive weights of
each asset, there will generally be bumps and asymmetries in the
efficient frontier.
The textbook examples usually assume short selling is allowed.
Charles Ward

2008/5/4 John P. Burkett <burkett at uri.edu>:
> Yesterday I reported that my effort to compute and plot an efficient
> frontier using the fPortfolio package had produced an asymmetric curve
> rather than the anticipated hyperbola. Using the same data, I have now tried
> computing and plotting an efficient frontier using the tseries package. The
> result is again an asymmetric curve.
>
>  My code is as follows:
>  library(fPortfolio)
>  Data = as.timeSeries(data(smallcap.ts))
>  Data = Data[, c("BKE", "GG", "GYMB", "KRON")]
>  Data
>  x <- as.matrix(Data)
>  vcvd <- cov(Data)
>  pmv <- rep(0,100)
>  psv <- rep(0,100)
>  minr <- min(mean(Data))
>  maxr <- max(mean(Data))
>  vcv <- cov(x)
>  iv <- 0:99
>  mrv <- minr*(1-iv/99) + maxr*(iv/99)
>  pmv[1] <- min(mean(Data))
>  pmv[100] <-max(mean(Data))
>  psv[1] <- 0.2226543
>  psv[100] <- 0.1674082
>  for (i in 2:99) {
>  pmv[i] <- portfolio.optim(x, pm = mrv[i], covmat = vcv)$pm
>  psv[i] <- portfolio.optim(x, pm = mrv[i], covmat = vcv)$ps
>  }
>  plot(psv,pmv)
>
>  On the resulting curve, risk is minimized at point 62. But the curve is not
> symmetric around this point. (Moving 37 points in either direction from this
> point raises risk by the same amount. In contrast moving 37 points back
> lowers the mean return far less than moving 37 points forward raises the
> mean return.)  I wonder whether this asymmetry is a bug or an accurate
> portrayal of a type of efficiency frontier different from the hyperbolas
> that appear in textbooks. I would be most grateful for suggestions about how
> to resolve this puzzle.
>
>  Best regards,
>  John
>
>
>  --
>  John P. Burkett
>  Department of Environmental and Natural Resource Economics
>  and Department of Economics
>  University of Rhode Island
>  Kingston, RI 02881-0808
>  USA
>
>  phone (401) 874-9195
>
>  _______________________________________________
>  R-SIG-Finance at stat.math.ethz.ch mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>  -- Subscriber-posting only.
>  -- If you want to post, subscribe first.
>


From burkett at uri.edu  Mon May  5 04:04:36 2008
From: burkett at uri.edu (John P. Burkett)
Date: Sun, 04 May 2008 22:04:36 -0400
Subject: [R-SIG-Finance] tseries and efficient frontier
In-Reply-To: <bd9aa36b0805041444r63ad3bd4y188a0efb6311ee44@mail.gmail.com>
References: <481DF040.5070102@uri.edu>
	<bd9aa36b0805041444r63ad3bd4y188a0efb6311ee44@mail.gmail.com>
Message-ID: <481E6B34.3000202@uri.edu>

Thanks, Charles!  You are absolutely correct.  Inserting the option 
shorts=TRUE produces a symmetrical curve. I'm very grateful to you for 
calling this to my attention.
Best regards,
John

Charles Ward wrote:
> I think the reason is that the function "portfolio.optim"  has the
> default option, short=FALSE. If you use the option short=TRUE you
> should achieve the symmetrical shape of the efficient frontier.
> When you constain the portfolio only to accept positive weights of
> each asset, there will generally be bumps and asymmetries in the
> efficient frontier.
> The textbook examples usually assume short selling is allowed.
> Charles Ward
> 
> 2008/5/4 John P. Burkett <burkett at uri.edu>:
>> Yesterday I reported that my effort to compute and plot an efficient
>> frontier using the fPortfolio package had produced an asymmetric curve
>> rather than the anticipated hyperbola. Using the same data, I have now tried
>> computing and plotting an efficient frontier using the tseries package. The
>> result is again an asymmetric curve.
>>
>>  My code is as follows:
>>  library(fPortfolio)
>>  Data = as.timeSeries(data(smallcap.ts))
>>  Data = Data[, c("BKE", "GG", "GYMB", "KRON")]
>>  Data
>>  x <- as.matrix(Data)
>>  vcvd <- cov(Data)
>>  pmv <- rep(0,100)
>>  psv <- rep(0,100)
>>  minr <- min(mean(Data))
>>  maxr <- max(mean(Data))
>>  vcv <- cov(x)
>>  iv <- 0:99
>>  mrv <- minr*(1-iv/99) + maxr*(iv/99)
>>  pmv[1] <- min(mean(Data))
>>  pmv[100] <-max(mean(Data))
>>  psv[1] <- 0.2226543
>>  psv[100] <- 0.1674082
>>  for (i in 2:99) {
>>  pmv[i] <- portfolio.optim(x, pm = mrv[i], covmat = vcv)$pm
>>  psv[i] <- portfolio.optim(x, pm = mrv[i], covmat = vcv)$ps
>>  }
>>  plot(psv,pmv)
>>
>>  On the resulting curve, risk is minimized at point 62. But the curve is not
>> symmetric around this point. (Moving 37 points in either direction from this
>> point raises risk by the same amount. In contrast moving 37 points back
>> lowers the mean return far less than moving 37 points forward raises the
>> mean return.)  I wonder whether this asymmetry is a bug or an accurate
>> portrayal of a type of efficiency frontier different from the hyperbolas
>> that appear in textbooks. I would be most grateful for suggestions about how
>> to resolve this puzzle.
>>
>>  Best regards,
>>  John
>>
>>
>>  --
>>  John P. Burkett
>>  Department of Environmental and Natural Resource Economics
>>  and Department of Economics
>>  University of Rhode Island
>>  Kingston, RI 02881-0808
>>  USA
>>
>>  phone (401) 874-9195
>>
>>  _______________________________________________
>>  R-SIG-Finance at stat.math.ethz.ch mailing list
>>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>  -- Subscriber-posting only.
>>  -- If you want to post, subscribe first.
>>
> 


-- 
John P. Burkett
Department of Environmental and Natural Resource Economics
and Department of Economics
University of Rhode Island
Kingston, RI 02881-0808
USA

phone (401) 874-9195


From chalabi at phys.ethz.ch  Tue May  6 10:15:03 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Tue, 6 May 2008 10:15:03 +0200
Subject: [R-SIG-Finance] Estimating the T-S Garch model
In-Reply-To: <620148.39708.qm@web50108.mail.re2.yahoo.com>
References: <620148.39708.qm@web50108.mail.re2.yahoo.com>
Message-ID: <20080506101503.3617e890@mimi>

>>>> "MM" == michal miklovic <mmiklovic at yahoo.com>
>>>> on Thu, 1 May 2008 14:58:29 -0700 (PDT)


   MM> it is a bug and it has already been solved in the
   MM> development version of fGarch. Rmetrics development web is
   MM> at: http://r-forge.r-project.org/projects/rmetrics
   MM> where you can find the latest versions of all
   MM> packages. Download the zipped Windows binaries and install
   MM> them in the following order:
   MM> fUtilities, fEcofin, fCalendar, fSeries, fImport, fBasics,
   MM> fBonds, fArma, fGarch, fTrading, fExtremes, fNonlinear,
   MM> fOptions, fAsianOptions, fExoticOptions, fUnitRoots,
   MM> fMultivar, fCopulae, fRegression, fAssets, fPortfolio,
   MM> Rmetrics
   MM> and the estimation should work fine.

Note you can use the script installRmetrics to install "fGarch"
development package with

source("http://rmetrics.R-Forge.R-project.org/installRmetrics.R")
installRmetrics("fGarch", repos="http://R-Forge.R-project.org")

Or any other Rmetrics development package...

regards,
Yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From vlanschot at yahoo.com  Tue May  6 17:17:20 2008
From: vlanschot at yahoo.com (R@Nabble)
Date: Tue, 6 May 2008 08:17:20 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Date from csv as date for ts
Message-ID: <17085476.post@talk.nabble.com>


Apologies if this has been answered elsewhere, but I couldn't find it.

Basically, I dump securities' return- data in a csv-file with 3 columns:
Name, Date, and Returns. In other words, the Date column contains multiple
entries for each date, namely one for each security. I figured out how to
extract these dates in one vector with strings from "31/01/2000" to
31/03/2008", which I then transformed via the as.Date function. I
subsequently created a return-matrix via cbind for each security.

My question/problem is, I have been unable to use the date-vector as
date-input for my ts-object. Looking at the smallcap.ts-example on page 14
of the fPortfolio Package pdf, I'd like to somehow combine my Date-vector
with my return-matrix into one large matrix for input in fPortfolio. Using
cbind, etc. leads to errors.

Clearly I'm on a steep learning curve, so any help appreciated.

Thx,

R at N
-- 
View this message in context: http://www.nabble.com/Date-from-csv-as-date-for-ts-tp17085476p17085476.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From jeff.a.ryan at gmail.com  Tue May  6 17:36:30 2008
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 6 May 2008 10:36:30 -0500
Subject: [R-SIG-Finance] [R-sig-finance] Date from csv as date for ts
In-Reply-To: <17085476.post@talk.nabble.com>
References: <17085476.post@talk.nabble.com>
Message-ID: <e8e755250805060836p54c59ebj7cfde8c37467e0a7@mail.gmail.com>

Take a look at the 'zoo' or 'xts' packages:

xts(smallcap.ts[,-1],as.Date(smallcap.ts[,1]))

zoo(smallcap.ts[,-1],as.Date(smallcap.ts[,1]))

'xts' extends zoo - so you get all the goodness of zoo, and it adds some
time-specific functionality.

Either would be a good choice/start.

A working sample might let me provide a more direct answer.

Jeff

On Tue, May 6, 2008 at 10:17 AM, R at Nabble <vlanschot at yahoo.com> wrote:
>
>  Apologies if this has been answered elsewhere, but I couldn't find it.
>
>  Basically, I dump securities' return- data in a csv-file with 3 columns:
>  Name, Date, and Returns. In other words, the Date column contains multiple
>  entries for each date, namely one for each security. I figured out how to
>  extract these dates in one vector with strings from "31/01/2000" to
>  31/03/2008", which I then transformed via the as.Date function. I
>  subsequently created a return-matrix via cbind for each security.
>
>  My question/problem is, I have been unable to use the date-vector as
>  date-input for my ts-object. Looking at the smallcap.ts-example on page 14
>  of the fPortfolio Package pdf, I'd like to somehow combine my Date-vector
>  with my return-matrix into one large matrix for input in fPortfolio. Using
>  cbind, etc. leads to errors.
>
>  Clearly I'm on a steep learning curve, so any help appreciated.
>
>  Thx,
>
>  R at N
>  --
>  View this message in context: http://www.nabble.com/Date-from-csv-as-date-for-ts-tp17085476p17085476.html
>  Sent from the Rmetrics mailing list archive at Nabble.com.
>
>  _______________________________________________
>  R-SIG-Finance at stat.math.ethz.ch mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>  -- Subscriber-posting only.
>  -- If you want to post, subscribe first.
>



-- 
There's a way to do it better - find it.
Thomas A. Edison


From ggrothendieck at gmail.com  Tue May  6 17:55:14 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 6 May 2008 11:55:14 -0400
Subject: [R-SIG-Finance] [R-sig-finance] Date from csv as date for ts
In-Reply-To: <17085476.post@talk.nabble.com>
References: <17085476.post@talk.nabble.com>
Message-ID: <971536df0805060855j616b587v73267fae2f271bc6@mail.gmail.com>

Try this where textConnection(Lines) would be replaced by "myfile.csv"
or whatever your file name.  Also you can replace each of the two occurrences
of the word zoo below with xts and it will give xts objects instead.
Read the three
vignettes that come with zoo for more info.

library(zoo)
Lines <- "Name,Date,Returns
A,31/01/2000,1
A,01/02/2000,2
B,31/01/2000,1
B,01/02/2000,2
B,01/03/2000,3
"
DF <- read.csv(textConnection(Lines))
f <- function(x) zoo(x$Returns, as.Date(x$Date, "%d/%m/%Y"))
do.call(merge, by(DF, DF$Name, f))


On Tue, May 6, 2008 at 11:17 AM, R at Nabble <vlanschot at yahoo.com> wrote:
>
> Apologies if this has been answered elsewhere, but I couldn't find it.
>
> Basically, I dump securities' return- data in a csv-file with 3 columns:
> Name, Date, and Returns. In other words, the Date column contains multiple
> entries for each date, namely one for each security. I figured out how to
> extract these dates in one vector with strings from "31/01/2000" to
> 31/03/2008", which I then transformed via the as.Date function. I
> subsequently created a return-matrix via cbind for each security.
>
> My question/problem is, I have been unable to use the date-vector as
> date-input for my ts-object. Looking at the smallcap.ts-example on page 14
> of the fPortfolio Package pdf, I'd like to somehow combine my Date-vector
> with my return-matrix into one large matrix for input in fPortfolio. Using
> cbind, etc. leads to errors.
>
> Clearly I'm on a steep learning curve, so any help appreciated.
>
> Thx,
>
> R at N
> --
> View this message in context: http://www.nabble.com/Date-from-csv-as-date-for-ts-tp17085476p17085476.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From frainj at tcd.ie  Tue May  6 23:28:30 2008
From: frainj at tcd.ie (John Frain)
Date: Tue, 6 May 2008 22:28:30 +0100
Subject: [R-SIG-Finance] Estimating the T-S Garch model
In-Reply-To: <20080506101503.3617e890@mimi>
References: <620148.39708.qm@web50108.mail.re2.yahoo.com>
	<20080506101503.3617e890@mimi>
Message-ID: <cfdde1650805061428h73400db5ja310c612742065f9@mail.gmail.com>

This script does not appear to work for me.  I have already loaded
fGarch 270.73 and when I try to run the script followed by the call to
the 'iinstall' program i get the error message below. (I have ran the
script from the internet and also downloaded it to my PC and the
result is the same).  |Packages|Update packages| works in the windows
GUI.  My version of fUnitRoots is 260.72 and it will not update.  I
had previously tried to download the zipped file for fUnitRoots and
failed.  I tried again this evening and failed again.  (I have
downloaded all the remaining Rmetrics files at this stage).

Best regards

John


R version 2.7.0 (2008-04-22)
Copyright (C) 2008 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> source("H:\\Archives\\software_econometric\\R\\R-2.7.0\\Rmetrics\\installRmetrics.R")
> installRmetrics("fGarch", repos="http://R-Forge.R-project.org")
Error in FUN("fGarch"[[1L]], ...) : subscript out of bounds
>


2008/5/6 Yohan Chalabi <chalabi at phys.ethz.ch>:
> >>>> "MM" == michal miklovic <mmiklovic at yahoo.com>
>  >>>> on Thu, 1 May 2008 14:58:29 -0700 (PDT)
>
>
>    MM> it is a bug and it has already been solved in the
>    MM> development version of fGarch. Rmetrics development web is
>    MM> at: http://r-forge.r-project.org/projects/rmetrics
>    MM> where you can find the latest versions of all
>    MM> packages. Download the zipped Windows binaries and install
>    MM> them in the following order:
>    MM> fUtilities, fEcofin, fCalendar, fSeries, fImport, fBasics,
>    MM> fBonds, fArma, fGarch, fTrading, fExtremes, fNonlinear,
>    MM> fOptions, fAsianOptions, fExoticOptions, fUnitRoots,
>    MM> fMultivar, fCopulae, fRegression, fAssets, fPortfolio,
>    MM> Rmetrics
>    MM> and the estimation should work fine.
>
>  Note you can use the script installRmetrics to install "fGarch"
>  development package with
>
>  source("http://rmetrics.R-Forge.R-project.org/installRmetrics.R")
>  installRmetrics("fGarch", repos="http://R-Forge.R-project.org")
>
>  Or any other Rmetrics development package...
>
>  regards,
>  Yohan
>
>  --
>  PhD student
>  Swiss Federal Institute of Technology
>  Zurich
>
>  www.ethz.ch
>  www.rmetrics.org
>
>  NOTE:
>  Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
>  June 29th - July 3rd Meielisalp, Lake Thune, Switzerland
>
>



-- 
John C Frain
Trinity College Dublin
Dublin 2
Ireland
www.tcd.ie/Economics/staff/frainj/home.htm
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


From brian at braverock.com  Tue May  6 23:53:50 2008
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 06 May 2008 16:53:50 -0500
Subject: [R-SIG-Finance] Estimating the T-S Garch model
In-Reply-To: <cfdde1650805061428h73400db5ja310c612742065f9@mail.gmail.com>
References: <620148.39708.qm@web50108.mail.re2.yahoo.com>	<20080506101503.3617e890@mimi>
	<cfdde1650805061428h73400db5ja310c612742065f9@mail.gmail.com>
Message-ID: <4820D36E.8030106@braverock.com>

John Frain wrote:
> This script does not appear to work for me.  I have already loaded
> fGarch 270.73 and when I try to run the script followed by the call to
> the 'iinstall' program i get the error message below. (I have ran the
> script from the internet and also downloaded it to my PC and the
> result is the same).  |Packages|Update packages| works in the windows
> GUI.  My version of fUnitRoots is 260.72 and it will not update.  I
> had previously tried to download the zipped file for fUnitRoots and
> failed.  I tried again this evening and failed again.  (I have
> downloaded all the remaining Rmetrics files at this stage).

>> Yohan wrote:
<snip>
>>  Note you can use the script installRmetrics to install "fGarch"
>>  development package with
>>
>>  source("http://rmetrics.R-Forge.R-project.org/installRmetrics.R")
>>  installRmetrics("fGarch", repos="http://R-Forge.R-project.org")
>>
>>  Or any other Rmetrics development package...


The likely cause here is that the .ZIP files have failed to build on 
R-forge for whatever reason.  Since John is using Windows, he won't 
likely be compiling them from source.  Perhaps somebody can take a look 
at the R-forge Windows build logs for these two packages and figure out 
what the build issue on Windows is.

Regards,

    - Brian


From jeff.a.ryan at gmail.com  Wed May  7 01:18:24 2008
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 6 May 2008 18:18:24 -0500
Subject: [R-SIG-Finance] Estimating the T-S Garch model
In-Reply-To: <4820D36E.8030106@braverock.com>
References: <620148.39708.qm@web50108.mail.re2.yahoo.com>
	<20080506101503.3617e890@mimi>
	<cfdde1650805061428h73400db5ja310c612742065f9@mail.gmail.com>
	<4820D36E.8030106@braverock.com>
Message-ID: <e8e755250805061618v42ab103cg161578cb1ee6c197@mail.gmail.com>

No solution from me, but I think this may have something to do with
the build issue:

http://www.nabble.com/R-Forge-SVN-repositories%3A-R-CMD-build-check-error-on-Windows-machines-to16942927.html

Jeff

On Tue, May 6, 2008 at 4:53 PM, Brian G. Peterson <brian at braverock.com> wrote:
> John Frain wrote:
>
> > This script does not appear to work for me.  I have already loaded
> > fGarch 270.73 and when I try to run the script followed by the call to
> > the 'iinstall' program i get the error message below. (I have ran the
> > script from the internet and also downloaded it to my PC and the
> > result is the same).  |Packages|Update packages| works in the windows
> > GUI.  My version of fUnitRoots is 260.72 and it will not update.  I
> > had previously tried to download the zipped file for fUnitRoots and
> > failed.  I tried again this evening and failed again.  (I have
> > downloaded all the remaining Rmetrics files at this stage).
> >
>
>
> >
> > > Yohan wrote:
> > >
> >
>  <snip>
>
>
> >
> > >  Note you can use the script installRmetrics to install "fGarch"
> > >  development package with
> > >
> > >  source("http://rmetrics.R-Forge.R-project.org/installRmetrics.R")
> > >  installRmetrics("fGarch", repos="http://R-Forge.R-project.org")
> > >
> > >  Or any other Rmetrics development package...
> > >
> >
>
>
>  The likely cause here is that the .ZIP files have failed to build on
> R-forge for whatever reason.  Since John is using Windows, he won't likely
> be compiling them from source.  Perhaps somebody can take a look at the
> R-forge Windows build logs for these two packages and figure out what the
> build issue on Windows is.
>
>  Regards,
>
>    - Brian
>
>
>
>  _______________________________________________
>  R-SIG-Finance at stat.math.ethz.ch mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>  -- Subscriber-posting only.
>  -- If you want to post, subscribe first.
>



-- 
There's a way to do it better - find it.
Thomas A. Edison


From chalabi at phys.ethz.ch  Wed May  7 09:41:02 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Wed, 7 May 2008 09:41:02 +0200
Subject: [R-SIG-Finance] Estimating the T-S Garch model
In-Reply-To: <cfdde1650805061428h73400db5ja310c612742065f9@mail.gmail.com>
References: <620148.39708.qm@web50108.mail.re2.yahoo.com>
	<20080506101503.3617e890@mimi>
	<cfdde1650805061428h73400db5ja310c612742065f9@mail.gmail.com>
Message-ID: <20080507094102.273b7e37@mimi>

>>>> "JF" == "John Frain" <frainj at tcd.ie>
>>>> on Tue, 6 May 2008 22:28:30 +0100


   JF> his script does not appear to work for me.  I have already
   JF> loaded
   JF> fGarch 270.73 and when I try to run the script followed by
   JF> the call to
   JF> the 'iinstall' program i get the error message below. (I
   JF> have ran the
   JF> script from the internet and also downloaded it to my PC
   JF> and the
   JF> result is the same).  |Packages|Update packages| works in
   JF> the windows
   JF> GUI.  My version of fUnitRoots is 260.72 and it will not
   JF> update.  I
   JF> had previously tried to download the zipped file for
   JF> fUnitRoots and
   JF> failed.  I tried again this evening and failed again.  (I have
   JF> downloaded all the remaining Rmetrics files at this stage).

There is an issue on R-Forge server with Windows binary packages.
According to the log files, there is no gfortran compiler and all
packages with Fortran source can cannot be build.

But you can compile the packages from source as long as you have the
required tools installed.

in Rterm type:

source("http://rmetrics.R-Forge.R-project.org/installRmetrics.R")
installRmetrics("fGarch", repos="http://R-Forge.R-project.org", type =
"source", suggests = FALSE)

Note with 'suggests = FALSE' suggested packages will not be installed.

regards,
Yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From frainj at tcd.ie  Wed May  7 19:08:47 2008
From: frainj at tcd.ie (John Frain)
Date: Wed, 7 May 2008 18:08:47 +0100
Subject: [R-SIG-Finance] Fwd:  Estimating the T-S Garch model
In-Reply-To: <cfdde1650805071007n58b2d7a2v3e2be298d470a870@mail.gmail.com>
References: <620148.39708.qm@web50108.mail.re2.yahoo.com>
	<20080506101503.3617e890@mimi>
	<cfdde1650805061428h73400db5ja310c612742065f9@mail.gmail.com>
	<20080507094102.273b7e37@mimi>
	<cfdde1650805071007n58b2d7a2v3e2be298d470a870@mail.gmail.com>
Message-ID: <cfdde1650805071008s4b7a7316j2bd14d959ddb34a4@mail.gmail.com>

---------- Forwarded message ----------
From: John Frain <frainj at tcd.ie>
Date: 2008/5/7
Subject: Re: [R-SIG-Finance] Estimating the T-S Garch model
To: Yohan Chalabi <chalabi at phys.ethz.ch>


Yohan

 This worked well.  I followed the instructions in Appendix E of the R
 Installation and Administration manual to download the Windows toolset
 and the MS HTML help workshop.  (I used the second url for the help
 workshop as the first may have moved to another address).  I have
 Latex already installed.  I did not install the Inno setup installer
 as I presume that this is not need for packages.  I created a batch
 file with one line

 set path=c:\Rtools\bin;c:\Rtools\perl\bin;c:\Rtools\mingw\bin;c:\progra~1\htmlhe~1;C:\Progra~1\R\R-2.7.0\bin;%path%

 to allow access to the tools. When I reboot my old path is then
 restored (I think).  I did not change anything in
 R_HOME/src/gnuwin32/MkRules.  The process appeared to work and was
 easier to implement than I had expected.

 Again Thanks to all

 John

 2008/5/7 Yohan Chalabi <chalabi at phys.ethz.ch>:


> >>>> "JF" == "John Frain" <frainj at tcd.ie>
 >  >>>> on Tue, 6 May 2008 22:28:30 +0100
 >
 >
 >    JF> his script does not appear to work for me.  I have already
 >    JF> loaded
 >    JF> fGarch 270.73 and when I try to run the script followed by
 >    JF> the call to
 >    JF> the 'iinstall' program i get the error message below. (I
 >    JF> have ran the
 >    JF> script from the internet and also downloaded it to my PC
 >    JF> and the
 >    JF> result is the same).  |Packages|Update packages| works in
 >    JF> the windows
 >    JF> GUI.  My version of fUnitRoots is 260.72 and it will not
 >    JF> update.  I
 >    JF> had previously tried to download the zipped file for
 >    JF> fUnitRoots and
 >    JF> failed.  I tried again this evening and failed again.  (I have
 >    JF> downloaded all the remaining Rmetrics files at this stage).
 >
 >  There is an issue on R-Forge server with Windows binary packages.
 >  According to the log files, there is no gfortran compiler and all
 >  packages with Fortran source can cannot be build.
 >
 >  But you can compile the packages from source as long as you have the
 >  required tools installed.
 >
 >  in Rterm type:
 >
 >
 >  source("http://rmetrics.R-Forge.R-project.org/installRmetrics.R")
 >  installRmetrics("fGarch", repos="http://R-Forge.R-project.org", type =
 >  "source", suggests = FALSE)
 >
 >  Note with 'suggests = FALSE' suggested packages will not be installed.
 >
 >
 >
 >  regards,
 >  Yohan
 >
 >  --
 >  PhD student
 >  Swiss Federal Institute of Technology
 >  Zurich
 >
 >  www.ethz.ch
 >  www.rmetrics.org
 >
 >  NOTE:
 >  Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
 >  June 29th - July 3rd Meielisalp, Lake Thune, Switzerland
 >
 >





--
 John C Frain
 Trinity College Dublin
 Dublin 2
 Ireland
 www.tcd.ie/Economics/staff/frainj/home.htm
 mailto:frainj at tcd.ie
 mailto:frainj at gmail.com



-- 
John C Frain
Trinity College Dublin
Dublin 2
Ireland
www.tcd.ie/Economics/staff/frainj/home.htm
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


From jorge.nieves at moorecap.com  Thu May  8 16:22:15 2008
From: jorge.nieves at moorecap.com (Jorge Nieves)
Date: Thu, 8 May 2008 10:22:15 -0400
Subject: [R-SIG-Finance] Rbloomberg problem
Message-ID: <1492B584537DA24ABBCC3EF56A464B8C105CDE8B@NYC-XCH1.nyc.win.moorecap.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080508/d2661f39/attachment.pl>

From nelson.ana at gmail.com  Thu May  8 17:39:46 2008
From: nelson.ana at gmail.com (Ana Nelson)
Date: Thu, 8 May 2008 16:39:46 +0100
Subject: [R-SIG-Finance] Rbloomberg problem
In-Reply-To: <1492B584537DA24ABBCC3EF56A464B8C105CDE8B@NYC-XCH1.nyc.win.moorecap.com>
References: <1492B584537DA24ABBCC3EF56A464B8C105CDE8B@NYC-XCH1.nyc.win.moorecap.com>
Message-ID: <a7d6d2740805080839w6df7d2e6tdd1207c07aacd8f8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080508/02757bfa/attachment.pl>

From jorge.nieves at moorecap.com  Thu May  8 17:44:23 2008
From: jorge.nieves at moorecap.com (Jorge Nieves)
Date: Thu, 8 May 2008 11:44:23 -0400
Subject: [R-SIG-Finance] Rbloomberg problem
In-Reply-To: <a7d6d2740805080839w6df7d2e6tdd1207c07aacd8f8@mail.gmail.com>
Message-ID: <1492B584537DA24ABBCC3EF56A464B8C105CDE8F@NYC-XCH1.nyc.win.moorecap.com>

 Thank you...

I just re-run them now and obtained the same results.. What version of R
are you using?

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Ana Nelson
Sent: Thursday, May 08, 2008 11:40 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Rbloomberg problem

Hi, Jorge,

Was the market actually open for the time period you requested? I've
just run those queries and they are working fine for me.

Will you try this again making sure the market you are querying is open
and let me know if it works for you?

Regards,
Ana



2008/5/8 Jorge Nieves <jorge.nieves at moorecap.com>:

> Hi,
>
> I am new R user and have been trying to properly configure an R 
> working environment.  I  have it up and ruining except for the
Rbloomberg.
>
> I tried running the examples in the documentation. And encountered  
> into several issues:  First, R2.5.1 was crashing and I could never 
> understand why. I installed the latest release R 2.7.0 and was 
> eventually able to run only tow of the examples from  
> blpGetData(RBloomberg)
>
> The intraday "Intraday bars" and the "Tick-by-tick" examples do not
run.
> I am wondering if (1) made a mistake in the set up? Or (2) there is a 
> problem here with R 2.7.0 too.
>
> Currently using
> Package:       RBloomberg
> Version:       0.1-10
> Date:          2006-05-04
> Built:         R 2.5.1; ; 2007-07-22 18:19:52; windows
>
> Usinga lso 'RDCOMClient' version 0.92-0
>
> Any recommendatiosn?
>
> blpGetData(RBloomberg) examples.
>
> library(RBloomberg)
>
> .bbfields <- blpReadFields("C:/Program Files/blp/API")
>
> ## Not run:
> conn <- blpConnect()
>
> ## Snapshot
> eda <- blpGetData(conn, c("ED5 Comdty","ED6 Comdty","ED7 Comdty",
> "ED8 Comdty"), "BID")
> eda
>
> ## Historical (last 30 days)
> edb <- blpGetData(conn, "ED1 Comdty", "PX_LAST",
> start=as.chron(Sys.time() - 86400 * 30)) edb
>
> ## Intraday bars (last hour in 2 min bars) edc <- blpGetData(conn, 
> "ED1 Comdty", c("BID","ASK"),
> start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2) edc
>
> ## Tick-by-tick (3 minutes starting an hour ago) edd <- 
> blpGetData(conn, "ED1 Comdty", c("BID"),
> start=as.chron(Sys.time() - 3600),
> end=as.chron(Sys.time() - 3420), barsize=0) edd
>
> blpDisconnect(conn)
> ## End(Not run)
>
>
> Output
>
>
>
> > .bbfields <- blpReadFields("C:/Program Files/blp/API")
> >
> > ## Not run:
> > conn <- blpConnect()
> >
> > ## Snapshot
> > eda <- blpGetData(conn, c("ED5 Comdty","ED6 Comdty","ED7 Comdty",
> + "ED8 Comdty"), "BID")
> > eda
>              BID
> ED5 COMDTY 96.860
> ED6 COMDTY 96.680
> ED7 COMDTY 96.475
> ED8 COMDTY 96.330
> >
> > ## Historical (last 30 days)
> > edb <- blpGetData(conn, "ED1 Comdty", "PX_LAST",
> + start=as.chron(Sys.time() - 86400 * 30))
> > edb
>         PX_LAST
> 04/08/08  97.530
> 04/09/08  97.545
> 04/10/08  97.500
> 04/11/08  97.540
> 04/14/08  97.495
> 04/15/08  97.440
> 04/16/08  97.290
> 04/17/08  97.120
> 04/18/08  97.090
> 04/21/08  97.125
> 04/22/08  97.125
> 04/23/08  97.135
> 04/24/08  97.145
> 04/25/08  97.135
> 04/28/08  97.195
> 04/29/08  97.245
> 04/30/08  97.325
> 05/01/08  97.330
> 05/02/08  97.365
> 05/05/08  97.350
> 05/06/08  97.365
> 05/07/08  97.365
> 05/08/08  97.395
> >
> > ## Intraday bars (last hour in 2 min bars) edc <- blpGetData(conn, 
> > "ED1 Comdty", c("BID","ASK"),
> + start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2)
> > edc
>                    BID.OPEN ASK.OPEN
> (05/08/08 09:26:21)       NA       NA
> >
> > ## Tick-by-tick (3 minutes starting an hour ago) edd <- 
> > blpGetData(conn, "ED1 Comdty", c("BID"),
> + start=as.chron(Sys.time() - 3600),
> + end=as.chron(Sys.time() - 3420), barsize=0)
> > edd
> Error in substr(text, first, last) : invalid substring argument(s)
> >
> > blpDisconnect(conn)
>         used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 291899  7.8     531268 14.2   408779 11.0
> Vcells 610228  4.7    1151091  8.8  1151024  8.8
> > ## End(Not run)
> >
> > help(blpDisconnect)
> >
>
>
> Jorge Nieves
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From nelson.ana at gmail.com  Thu May  8 18:09:26 2008
From: nelson.ana at gmail.com (Ana Nelson)
Date: Thu, 8 May 2008 17:09:26 +0100
Subject: [R-SIG-Finance] Rbloomberg problem
In-Reply-To: <1492B584537DA24ABBCC3EF56A464B8C105CDE8F@NYC-XCH1.nyc.win.moorecap.com>
References: <a7d6d2740805080839w6df7d2e6tdd1207c07aacd8f8@mail.gmail.com>
	<1492B584537DA24ABBCC3EF56A464B8C105CDE8F@NYC-XCH1.nyc.win.moorecap.com>
Message-ID: <a7d6d2740805080909q494481d8xb44181e62066985@mail.gmail.com>

I'm using R 2.7

There is a newer version of RBloomberg which you can try, 0.1-11. It's not
on CRAN yet, but you can get it from r-forge:
http://r-forge.r-project.org/projects/rbloomberg/

To install the package directly within R type:
install.packages("RBloomberg",repos="http://R-Forge.R-project.org")

I have attached a script of what I am running. Will you run this and send me
your console transcript as a text file attachment? (you can send it directly
to me, not the list)



2008/5/8 Jorge Nieves <jorge.nieves at moorecap.com>:

>  Thank you...
>
> I just re-run them now and obtained the same results.. What version of R
> are you using?
>
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Ana Nelson
> Sent: Thursday, May 08, 2008 11:40 AM
> To: r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] Rbloomberg problem
>
> Hi, Jorge,
>
> Was the market actually open for the time period you requested? I've
> just run those queries and they are working fine for me.
>
> Will you try this again making sure the market you are querying is open
> and let me know if it works for you?
>
> Regards,
> Ana
>
>
>
> 2008/5/8 Jorge Nieves <jorge.nieves at moorecap.com>:
>
> > Hi,
> >
> > I am new R user and have been trying to properly configure an R
> > working environment.  I  have it up and ruining except for the
> Rbloomberg.
> >
> > I tried running the examples in the documentation. And encountered
> > into several issues:  First, R2.5.1 was crashing and I could never
> > understand why. I installed the latest release R 2.7.0 and was
> > eventually able to run only tow of the examples from
> > blpGetData(RBloomberg)
> >
> > The intraday "Intraday bars" and the "Tick-by-tick" examples do not
> run.
> > I am wondering if (1) made a mistake in the set up? Or (2) there is a
> > problem here with R 2.7.0 too.
> >
> > Currently using
> > Package:       RBloomberg
> > Version:       0.1-10
> > Date:          2006-05-04
> > Built:         R 2.5.1; ; 2007-07-22 18:19:52; windows
> >
> > Usinga lso 'RDCOMClient' version 0.92-0
> >
> > Any recommendatiosn?
> >
> > blpGetData(RBloomberg) examples.
> >
> > library(RBloomberg)
> >
> > .bbfields <- blpReadFields("C:/Program Files/blp/API")
> >
> > ## Not run:
> > conn <- blpConnect()
> >
> > ## Snapshot
> > eda <- blpGetData(conn, c("ED5 Comdty","ED6 Comdty","ED7 Comdty",
> > "ED8 Comdty"), "BID")
> > eda
> >
> > ## Historical (last 30 days)
> > edb <- blpGetData(conn, "ED1 Comdty", "PX_LAST",
> > start=as.chron(Sys.time() - 86400 * 30)) edb
> >
> > ## Intraday bars (last hour in 2 min bars) edc <- blpGetData(conn,
> > "ED1 Comdty", c("BID","ASK"),
> > start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2) edc
> >
> > ## Tick-by-tick (3 minutes starting an hour ago) edd <-
> > blpGetData(conn, "ED1 Comdty", c("BID"),
> > start=as.chron(Sys.time() - 3600),
> > end=as.chron(Sys.time() - 3420), barsize=0) edd
> >
> > blpDisconnect(conn)
> > ## End(Not run)
> >
> >
> > Output
> >
> >
> >
> > > .bbfields <- blpReadFields("C:/Program Files/blp/API")
> > >
> > > ## Not run:
> > > conn <- blpConnect()
> > >
> > > ## Snapshot
> > > eda <- blpGetData(conn, c("ED5 Comdty","ED6 Comdty","ED7 Comdty",
> > + "ED8 Comdty"), "BID")
> > > eda
> >              BID
> > ED5 COMDTY 96.860
> > ED6 COMDTY 96.680
> > ED7 COMDTY 96.475
> > ED8 COMDTY 96.330
> > >
> > > ## Historical (last 30 days)
> > > edb <- blpGetData(conn, "ED1 Comdty", "PX_LAST",
> > + start=as.chron(Sys.time() - 86400 * 30))
> > > edb
> >         PX_LAST
> > 04/08/08  97.530
> > 04/09/08  97.545
> > 04/10/08  97.500
> > 04/11/08  97.540
> > 04/14/08  97.495
> > 04/15/08  97.440
> > 04/16/08  97.290
> > 04/17/08  97.120
> > 04/18/08  97.090
> > 04/21/08  97.125
> > 04/22/08  97.125
> > 04/23/08  97.135
> > 04/24/08  97.145
> > 04/25/08  97.135
> > 04/28/08  97.195
> > 04/29/08  97.245
> > 04/30/08  97.325
> > 05/01/08  97.330
> > 05/02/08  97.365
> > 05/05/08  97.350
> > 05/06/08  97.365
> > 05/07/08  97.365
> > 05/08/08  97.395
> > >
> > > ## Intraday bars (last hour in 2 min bars) edc <- blpGetData(conn,
> > > "ED1 Comdty", c("BID","ASK"),
> > + start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2)
> > > edc
> >                    BID.OPEN ASK.OPEN
> > (05/08/08 09:26:21)       NA       NA
> > >
> > > ## Tick-by-tick (3 minutes starting an hour ago) edd <-
> > > blpGetData(conn, "ED1 Comdty", c("BID"),
> > + start=as.chron(Sys.time() - 3600),
> > + end=as.chron(Sys.time() - 3420), barsize=0)
> > > edd
> > Error in substr(text, first, last) : invalid substring argument(s)
> > >
> > > blpDisconnect(conn)
> >         used (Mb) gc trigger (Mb) max used (Mb)
> > Ncells 291899  7.8     531268 14.2   408779 11.0
> > Vcells 610228  4.7    1151091  8.8  1151024  8.8
> > > ## End(Not run)
> > >
> > > help(blpDisconnect)
> > >
> >
> >
> > Jorge Nieves
> >
> >
> >
> >        [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only.
> > -- If you want to post, subscribe first.
> >
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080508/e1188be6/attachment.html>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: example.R
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080508/e1188be6/attachment.pl>

From davidr at rhotrading.com  Thu May  8 20:40:55 2008
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Thu, 8 May 2008 13:40:55 -0500
Subject: [R-SIG-Finance] Rbloomberg problem
In-Reply-To: <a7d6d2740805080909q494481d8xb44181e62066985@mail.gmail.com>
References: <a7d6d2740805080839w6df7d2e6tdd1207c07aacd8f8@mail.gmail.com><1492B584537DA24ABBCC3EF56A464B8C105CDE8F@NYC-XCH1.nyc.win.moorecap.com>
	<a7d6d2740805080909q494481d8xb44181e62066985@mail.gmail.com>
Message-ID: <F9F2A641C593D7408925574C05A7BE77DABD29@rhopost.rhotrading.com>


I installed the new RBloomberg from r-forge into a new R 2.7.0 patched, and I am getting the same results as Jorge.

> sessionInfo()
R version 2.7.0 Patched (2008-05-06 r45624) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] RBloomberg_0.1-11  chron_2.3-22       zoo_1.4-2          RDCOMClient_0.92-0

loaded via a namespace (and not attached):
[1] grid_2.7.0     lattice_0.17-7 tools_2.7.0   

> ls(all=TRUE)
character(0)
> library(RBloomberg)
> conn <- blpConnect()
> ex1 <- blpGetData(conn, "ED1 Comdty", c("BID","ASK"), start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2)
> ex2 <- blpGetData(conn, "ED1 Comdty", c("BID"), start=as.chron(Sys.time() - 3600), end=as.chron(Sys.time() - 3420), barsize=0)
> ex1
                    BID.OPEN ASK.OPEN
(05/08/08 13:14:41)       NA       NA
> ex2
Error in substr(text, first, last) : invalid substring argument(s)

(I was also got the same results in R 2.6.1 patched with the RBloomberg_0.1-10,
and R 2.7.0 with RBloomberg_0.1-10)
(Is it possible that Bloomberg is confused? Does BDP work in Excel? BDH?)

----------------------------
David L. Reiner, PhD
Head Quant
Rho Trading Securities, LLC
----------------------------

From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Ana Nelson
Sent: Thursday, May 08, 2008 11:09 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Rbloomberg problem

I'm using R 2.7

There is a newer version of RBloomberg which you can try, 0.1-11. It's not on CRAN yet, but you can get it from r-forge:
http://r-forge.r-project.org/projects/rbloomberg/

To install the package directly within R type: install.packages("RBloomberg",repos="http://R-Forge.R-project.org")

I have attached a script of what I am running. Will you run this and send me your console transcript as a text file attachment? (you can send it directly to me, not the list)


2008/5/8 Jorge Nieves <jorge.nieves at moorecap.com>:
?Thank you...

I just re-run them now and obtained the same results.. What version of R
are you using?

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Ana Nelson
Sent: Thursday, May 08, 2008 11:40 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Rbloomberg problem

Hi, Jorge,

Was the market actually open for the time period you requested? I've
just run those queries and they are working fine for me.

Will you try this again making sure the market you are querying is open
and let me know if it works for you?

Regards,
Ana



2008/5/8 Jorge Nieves <jorge.nieves at moorecap.com>:

> Hi,
>
> I am new R user and have been trying to properly configure an R
> working environment. ?I ?have it up and ruining except for the
Rbloomberg.
>
> I tried running the examples in the documentation. And encountered
> into several issues: ?First, R2.5.1 was crashing and I could never
> understand why. I installed the latest release R 2.7.0 and was
> eventually able to run only tow of the examples from
> blpGetData(RBloomberg)
>
> The intraday "Intraday bars" and the "Tick-by-tick" examples do not
run.
> I am wondering if (1) made a mistake in the set up? Or (2) there is a
> problem here with R 2.7.0 too.
>
> Currently using
> Package: ? ? ? RBloomberg
> Version: ? ? ? 0.1-10
> Date: ? ? ? ? ?2006-05-04
> Built: ? ? ? ? R 2.5.1; ; 2007-07-22 18:19:52; windows
>
> Usinga lso 'RDCOMClient' version 0.92-0
>
> Any recommendatiosn?
>
> blpGetData(RBloomberg) examples.
>
> library(RBloomberg)
>
> .bbfields <- blpReadFields("C:/Program Files/blp/API")
>
> ## Not run:
> conn <- blpConnect()
>
> ## Snapshot
> eda <- blpGetData(conn, c("ED5 Comdty","ED6 Comdty","ED7 Comdty",
> "ED8 Comdty"), "BID")
> eda
>
> ## Historical (last 30 days)
> edb <- blpGetData(conn, "ED1 Comdty", "PX_LAST",
> start=as.chron(Sys.time() - 86400 * 30)) edb
>
> ## Intraday bars (last hour in 2 min bars) edc <- blpGetData(conn,
> "ED1 Comdty", c("BID","ASK"),
> start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2) edc
>
> ## Tick-by-tick (3 minutes starting an hour ago) edd <-
> blpGetData(conn, "ED1 Comdty", c("BID"),
> start=as.chron(Sys.time() - 3600),
> end=as.chron(Sys.time() - 3420), barsize=0) edd
>
> blpDisconnect(conn)
> ## End(Not run)
>
>
> Output
>
>
>
> > .bbfields <- blpReadFields("C:/Program Files/blp/API")
> >
> > ## Not run:
> > conn <- blpConnect()
> >
> > ## Snapshot
> > eda <- blpGetData(conn, c("ED5 Comdty","ED6 Comdty","ED7 Comdty",
> + "ED8 Comdty"), "BID")
> > eda
> ? ? ? ? ? ? ?BID
> ED5 COMDTY 96.860
> ED6 COMDTY 96.680
> ED7 COMDTY 96.475
> ED8 COMDTY 96.330
> >
> > ## Historical (last 30 days)
> > edb <- blpGetData(conn, "ED1 Comdty", "PX_LAST",
> + start=as.chron(Sys.time() - 86400 * 30))
> > edb
> ? ? ? ? PX_LAST
> 04/08/08 ?97.530
> 04/09/08 ?97.545
> 04/10/08 ?97.500
> 04/11/08 ?97.540
> 04/14/08 ?97.495
> 04/15/08 ?97.440
> 04/16/08 ?97.290
> 04/17/08 ?97.120
> 04/18/08 ?97.090
> 04/21/08 ?97.125
> 04/22/08 ?97.125
> 04/23/08 ?97.135
> 04/24/08 ?97.145
> 04/25/08 ?97.135
> 04/28/08 ?97.195
> 04/29/08 ?97.245
> 04/30/08 ?97.325
> 05/01/08 ?97.330
> 05/02/08 ?97.365
> 05/05/08 ?97.350
> 05/06/08 ?97.365
> 05/07/08 ?97.365
> 05/08/08 ?97.395
> >
> > ## Intraday bars (last hour in 2 min bars) edc <- blpGetData(conn,
> > "ED1 Comdty", c("BID","ASK"),
> + start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2)
> > edc
> ? ? ? ? ? ? ? ? ? ?BID.OPEN ASK.OPEN
> (05/08/08 09:26:21) ? ? ? NA ? ? ? NA
> >
> > ## Tick-by-tick (3 minutes starting an hour ago) edd <-
> > blpGetData(conn, "ED1 Comdty", c("BID"),
> + start=as.chron(Sys.time() - 3600),
> + end=as.chron(Sys.time() - 3420), barsize=0)
> > edd
> Error in substr(text, first, last) : invalid substring argument(s)
> >
> > blpDisconnect(conn)
> ? ? ? ? used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 291899 ?7.8 ? ? 531268 14.2 ? 408779 11.0
> Vcells 610228 ?4.7 ? ?1151091 ?8.8 ?1151024 ?8.8
> > ## End(Not run)
> >
> > help(blpDisconnect)
> >
>
>
> Jorge Nieves
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>

? ? ? ?[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From josh.m.ulrich at gmail.com  Thu May  8 21:07:57 2008
From: josh.m.ulrich at gmail.com (Josh Ulrich)
Date: Thu, 8 May 2008 14:07:57 -0500
Subject: [R-SIG-Finance] portfolioFrontier/Spec: targetReturn
Message-ID: <8cca69990805081207k2516b681q99f42b5f3754fbdc@mail.gmail.com>

List,

I am trying to help a colleague with a question, but I am - by no
means - an expert in this area.  The output of the portfolioFrontier
function in the code below doesn't change for different values of
targetReturn and riskFreeRate (in portfolioSpec).  I would appreciate
if someone could point me to information on why this should be
expected or not.

Best,
Josh

require(TTR)
require(zoo)
suppressMessages(require(fPortfolio))

syms <- c('ABNDX','CAIBX','CWBFX','CWGIX','RYEOX','RYMTX','DBV')
X <- getYahooData(syms[1], start=20070601, quiet=TRUE)
X <- zoo( X$Close, X$Date )
for(i in 2:NROW(syms)) {
 print(syms[i])
 x <- getYahooData(syms[i], start=20070601, quiet=TRUE)
 X <- cbind( X, zoo( x$Close, x$Date ) )
}
colnames(X) <- syms
R <- as.timeSeries(returns(X, percentage = TRUE))

Spec = portfolioSpec(model = list(type = c("MV", "CVaR"),
  estimator = c("mean", "cov"), tailRisk = list(), params = list()),
  portfolio = list(weights = NULL, targetReturn = NULL,
    targetRisk = 4, targetAlpha = 0.05, riskFreeRate = NULL,
    nFrontierPoints = 50),
  solver = list(solver = c("quadprog", "Rdonlp2", "lpSolve"), trace = FALSE))
Spec
frontier <- portfolioFrontier( R, Spec, c("minW[1:nAssets]=0"))
weightsSlider(frontier)


> sessionInfo()
R version 2.7.0 (2008-04-22)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] tcltk     stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
 [1] fPortfolio_260.72  fAssets_260.72     fRegression_260.72 fMultivar_260.72
 [5] sn_0.4-4           mnormt_1.2-1       fTrading_260.72    polspline_1.0.15
 [9] nnet_7.2-42        mgcv_1.3-31        fBasics_260.72     fImport_260.72
[13] fSeries_260.72     fCalendar_262.73   fEcofin_260.72     fUtilities_260.72
[17] spatial_7.2-42     RUnit_0.4.17       robustbase_0.2-8   MASS_7.2-42
[21] lpSolve_5.6.2      quadprog_1.4-11    zoo_1.5-3          TTR_0.14-0

loaded via a namespace (and not attached):
Error in x[["Version"]] : subscript out of bounds
In addition: Warning message:
In FUN(c("grid", "lattice")[[2L]], ...) :
  DESCRIPTION file of package 'lattice' is missing or broken


-- 
http://quantemplation.blogspot.com


From davidr at rhotrading.com  Thu May  8 23:27:14 2008
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Thu, 8 May 2008 16:27:14 -0500
Subject: [R-SIG-Finance] Rbloomberg problem SOLVED
In-Reply-To: <1492B584537DA24ABBCC3EF56A464B8C105CDE96@NYC-XCH1.nyc.win.moorecap.com>
References: <F9F2A641C593D7408925574C05A7BE77DABD29@rhopost.rhotrading.com>
	<1492B584537DA24ABBCC3EF56A464B8C105CDE96@NYC-XCH1.nyc.win.moorecap.com>
Message-ID: <F9F2A641C593D7408925574C05A7BE77DABD92@rhopost.rhotrading.com>

It's the as.chron(Sys.time()-xxx).
Look at the value:

> library(chron)
> as.chron(Sys.time())
[1] (05/08/08 20:53:44)
> Sys.time()
[1] "2008-05-08 15:53:52 CDT"

The start time given to Bloomberg is in the future!
Maybe Ana is in a different time zone.

All works if you use explicit dates and times in the as.chron calls.


-- David


-----Original Message-----
From: Jorge Nieves [mailto:jorge.nieves at moorecap.com] 
Sent: Thursday, May 08, 2008 3:33 PM
To: David Reiner <davidr at rhotrading.com>
Subject: RE: [R-SIG-Finance] Rbloomberg problem

David,

Please let me know if you figure out a way to fix this thing. I will make sure to let you know if do on my side.


Thanks,

Jorge 

-----Original Message-----
From: davidr at rhotrading.com [mailto:davidr at rhotrading.com] 
Sent: Thursday, May 08, 2008 02:41 PM
To: Ana Nelson; r-sig-finance at stat.math.ethz.ch; Jorge Nieves
Subject: RE: [R-SIG-Finance] Rbloomberg problem


I installed the new RBloomberg from r-forge into a new R 2.7.0 patched, and I am getting the same results as Jorge.

> sessionInfo()
R version 2.7.0 Patched (2008-05-06 r45624)
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] RBloomberg_0.1-11  chron_2.3-22       zoo_1.4-2          RDCOMClient_0.92-0

loaded via a namespace (and not attached):
[1] grid_2.7.0     lattice_0.17-7 tools_2.7.0   

> ls(all=TRUE)
character(0)
> library(RBloomberg)
> conn <- blpConnect()
> ex1 <- blpGetData(conn, "ED1 Comdty", c("BID","ASK"), 
> start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2)
> ex2 <- blpGetData(conn, "ED1 Comdty", c("BID"), 
> start=as.chron(Sys.time() - 3600), end=as.chron(Sys.time() - 3420), 
> barsize=0)
> ex1
                    BID.OPEN ASK.OPEN
(05/08/08 13:14:41)       NA       NA
> ex2
Error in substr(text, first, last) : invalid substring argument(s)

(I was also got the same results in R 2.6.1 patched with the RBloomberg_0.1-10, and R 2.7.0 with RBloomberg_0.1-10) (Is it possible that Bloomberg is confused? Does BDP work in Excel? BDH?)

----------------------------
David L. Reiner, PhD
Head Quant
Rho Trading Securities, LLC
----------------------------

From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Ana Nelson
Sent: Thursday, May 08, 2008 11:09 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Rbloomberg problem

I'm using R 2.7

There is a newer version of RBloomberg which you can try, 0.1-11. It's not on CRAN yet, but you can get it from r-forge:
http://r-forge.r-project.org/projects/rbloomberg/

To install the package directly within R type: install.packages("RBloomberg",repos="http://R-Forge.R-project.org")

I have attached a script of what I am running. Will you run this and send me your console transcript as a text file attachment? (you can send it directly to me, not the list)


2008/5/8 Jorge Nieves <jorge.nieves at moorecap.com>:
?Thank you...

I just re-run them now and obtained the same results.. What version of R are you using?

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Ana Nelson
Sent: Thursday, May 08, 2008 11:40 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Rbloomberg problem

Hi, Jorge,

Was the market actually open for the time period you requested? I've just run those queries and they are working fine for me.

Will you try this again making sure the market you are querying is open and let me know if it works for you?

Regards,
Ana



2008/5/8 Jorge Nieves <jorge.nieves at moorecap.com>:

> Hi,
>
> I am new R user and have been trying to properly configure an R 
> working environment. ?I ?have it up and ruining except for the
Rbloomberg.
>
> I tried running the examples in the documentation. And encountered 
> into several issues: ?First, R2.5.1 was crashing and I could never 
> understand why. I installed the latest release R 2.7.0 and was 
> eventually able to run only tow of the examples from
> blpGetData(RBloomberg)
>
> The intraday "Intraday bars" and the "Tick-by-tick" examples do not
run.
> I am wondering if (1) made a mistake in the set up? Or (2) there is a 
> problem here with R 2.7.0 too.
>
> Currently using
> Package: ? ? ? RBloomberg
> Version: ? ? ? 0.1-10
> Date: ? ? ? ? ?2006-05-04
> Built: ? ? ? ? R 2.5.1; ; 2007-07-22 18:19:52; windows
>
> Usinga lso 'RDCOMClient' version 0.92-0
>
> Any recommendatiosn?
>
> blpGetData(RBloomberg) examples.
>
> library(RBloomberg)
>
> .bbfields <- blpReadFields("C:/Program Files/blp/API")
>
> ## Not run:
> conn <- blpConnect()
>
> ## Snapshot
> eda <- blpGetData(conn, c("ED5 Comdty","ED6 Comdty","ED7 Comdty",
> "ED8 Comdty"), "BID")
> eda
>
> ## Historical (last 30 days)
> edb <- blpGetData(conn, "ED1 Comdty", "PX_LAST",
> start=as.chron(Sys.time() - 86400 * 30)) edb
>
> ## Intraday bars (last hour in 2 min bars) edc <- blpGetData(conn,
> "ED1 Comdty", c("BID","ASK"),
> start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2) edc
>
> ## Tick-by-tick (3 minutes starting an hour ago) edd <- 
> blpGetData(conn, "ED1 Comdty", c("BID"),
> start=as.chron(Sys.time() - 3600),
> end=as.chron(Sys.time() - 3420), barsize=0) edd
>
> blpDisconnect(conn)
> ## End(Not run)
>
>
> Output
>
>
>
> > .bbfields <- blpReadFields("C:/Program Files/blp/API")
> >
> > ## Not run:
> > conn <- blpConnect()
> >
> > ## Snapshot
> > eda <- blpGetData(conn, c("ED5 Comdty","ED6 Comdty","ED7 Comdty",
> + "ED8 Comdty"), "BID")
> > eda
> ? ? ? ? ? ? ?BID
> ED5 COMDTY 96.860
> ED6 COMDTY 96.680
> ED7 COMDTY 96.475
> ED8 COMDTY 96.330
> >
> > ## Historical (last 30 days)
> > edb <- blpGetData(conn, "ED1 Comdty", "PX_LAST",
> + start=as.chron(Sys.time() - 86400 * 30))
> > edb
> ? ? ? ? PX_LAST
> 04/08/08 ?97.530
> 04/09/08 ?97.545
> 04/10/08 ?97.500
> 04/11/08 ?97.540
> 04/14/08 ?97.495
> 04/15/08 ?97.440
> 04/16/08 ?97.290
> 04/17/08 ?97.120
> 04/18/08 ?97.090
> 04/21/08 ?97.125
> 04/22/08 ?97.125
> 04/23/08 ?97.135
> 04/24/08 ?97.145
> 04/25/08 ?97.135
> 04/28/08 ?97.195
> 04/29/08 ?97.245
> 04/30/08 ?97.325
> 05/01/08 ?97.330
> 05/02/08 ?97.365
> 05/05/08 ?97.350
> 05/06/08 ?97.365
> 05/07/08 ?97.365
> 05/08/08 ?97.395
> >
> > ## Intraday bars (last hour in 2 min bars) edc <- blpGetData(conn,
> > "ED1 Comdty", c("BID","ASK"),
> + start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2)
> > edc
> ? ? ? ? ? ? ? ? ? ?BID.OPEN ASK.OPEN
> (05/08/08 09:26:21) ? ? ? NA ? ? ? NA
> >
> > ## Tick-by-tick (3 minutes starting an hour ago) edd <- 
> > blpGetData(conn, "ED1 Comdty", c("BID"),
> + start=as.chron(Sys.time() - 3600),
> + end=as.chron(Sys.time() - 3420), barsize=0)
> > edd
> Error in substr(text, first, last) : invalid substring argument(s)
> >
> > blpDisconnect(conn)
> ? ? ? ? used (Mb) gc trigger (Mb) max used (Mb) Ncells 291899 ?7.8 ? ? 
> 531268 14.2 ? 408779 11.0 Vcells 610228 ?4.7 ? ?1151091 ?8.8 ?1151024 ?
> 8.8
> > ## End(Not run)
> >
> > help(blpDisconnect)
> >
>
>
> Jorge Nieves
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>

? ? ? ?[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From mmiklovic at yahoo.com  Fri May  9 10:18:33 2008
From: mmiklovic at yahoo.com (michal miklovic)
Date: Fri, 9 May 2008 01:18:33 -0700 (PDT)
Subject: [R-SIG-Finance] two zoo questions
Message-ID: <947970.42462.qm@web50104.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080509/11724466/attachment.pl>

From robert at sanctumfi.com  Fri May  9 11:22:43 2008
From: robert at sanctumfi.com (Robert Sams)
Date: Fri, 9 May 2008 10:22:43 +0100
Subject: [R-SIG-Finance] Rbloomberg problem
References: <a7d6d2740805080839w6df7d2e6tdd1207c07aacd8f8@mail.gmail.com><1492B584537DA24ABBCC3EF56A464B8C105CDE8F@NYC-XCH1.nyc.win.moorecap.com><a7d6d2740805080909q494481d8xb44181e62066985@mail.gmail.com>
	<SANCTUMFISERVERMezI00003bf5@sanctumfi.com>
Message-ID: <SANCTUMFISERVER2uzq00003d30@sanctumfi.com>

Running David's example on my machine:

> library(RBloomberg)
Loading required package: RDCOMClient
Loading required package: zoo

Attaching package: 'zoo'


        The following object(s) are masked from package:base :

         as.Date.numeric 

Loading required package: chron
Contents of bbfields have been stored in .bbfields in the current workspace
> sessionInfo()
R version 2.7.0 (2008-04-22) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] RBloomberg_0.1-10  chron_2.3-22       zoo_1.5-3          RDCOMClient_0.92-0

loaded via a namespace (and not attached):
[1] grid_2.7.0     lattice_0.17-7 tools_2.7.0   
> conn <- blpConnect()
> ex1 <- blpGetData(conn, "ED1 Comdty", c("BID","ASK"), start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2)
> ex1
                    BID.OPEN ASK.OPEN
(05/09/08 08:03:00)   97.420   97.425
(05/09/08 08:05:00)   97.420   97.430
(05/09/08 08:07:00)   97.420   97.425
(05/09/08 08:09:00)   97.420   97.425
(05/09/08 08:11:00)   97.420   97.425
(05/09/08 08:13:00)   97.420   97.425
(05/09/08 08:15:00)   97.420   97.425
(05/09/08 08:17:00)   97.420   97.425
(05/09/08 08:19:00)   97.420   97.425
(05/09/08 08:21:00)   97.420   97.425
(05/09/08 08:23:00)   97.425   97.430
(05/09/08 08:25:00)   97.425   97.430
(05/09/08 08:27:00)   97.430   97.440

** CUT **

I can't seem to replicate this. Perhaps the issue is one between the patched R 2.7.0 and RDCOMClient 0.92-0. More likely, I think, is that something has caused the bbcom to crash. THAT has happened to me many times and of course RBloomberg, blp in Excel, etc. will not work. The solution is to restart the server. 

Can you verify that this is NOT the cause of your problem? Can you make the intraday calls in Excel but not R? Do no blpGetData calls work, or is it just the intraday? for some but not other tickers? etc etc.. 

Not much one can do with a problem one cannot replicate and a paucity of relavant information.

Robert

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of davidr at rhotrading.com
Sent: 08 May 2008 19:41
To: Ana Nelson; r-sig-finance at stat.math.ethz.ch; Jorge Nieves
Subject: Re: [R-SIG-Finance] Rbloomberg problem


I installed the new RBloomberg from r-forge into a new R 2.7.0 patched, and I am getting the same results as Jorge.

> sessionInfo()
R version 2.7.0 Patched (2008-05-06 r45624)
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] RBloomberg_0.1-11  chron_2.3-22       zoo_1.4-2          RDCOMClient_0.92-0

loaded via a namespace (and not attached):
[1] grid_2.7.0     lattice_0.17-7 tools_2.7.0   

> ls(all=TRUE)
character(0)
> library(RBloomberg)
> conn <- blpConnect()
> ex1 <- blpGetData(conn, "ED1 Comdty", c("BID","ASK"), 
> start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2)
> ex2 <- blpGetData(conn, "ED1 Comdty", c("BID"), 
> start=as.chron(Sys.time() - 3600), end=as.chron(Sys.time() - 3420), 
> barsize=0)
> ex1
                    BID.OPEN ASK.OPEN
(05/08/08 13:14:41)       NA       NA
> ex2
Error in substr(text, first, last) : invalid substring argument(s)

(I was also got the same results in R 2.6.1 patched with the RBloomberg_0.1-10, and R 2.7.0 with RBloomberg_0.1-10) (Is it possible that Bloomberg is confused? Does BDP work in Excel? BDH?)

----------------------------
David L. Reiner, PhD
Head Quant
Rho Trading Securities, LLC
----------------------------

From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Ana Nelson
Sent: Thursday, May 08, 2008 11:09 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Rbloomberg problem

I'm using R 2.7

There is a newer version of RBloomberg which you can try, 0.1-11. It's not on CRAN yet, but you can get it from r-forge:
http://r-forge.r-project.org/projects/rbloomberg/

To install the package directly within R type: install.packages("RBloomberg",repos="http://R-Forge.R-project.org")

I have attached a script of what I am running. Will you run this and send me your console transcript as a text file attachment? (you can send it directly to me, not the list)


2008/5/8 Jorge Nieves <jorge.nieves at moorecap.com>:
?Thank you...

I just re-run them now and obtained the same results.. What version of R are you using?

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Ana Nelson
Sent: Thursday, May 08, 2008 11:40 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Rbloomberg problem

Hi, Jorge,

Was the market actually open for the time period you requested? I've just run those queries and they are working fine for me.

Will you try this again making sure the market you are querying is open and let me know if it works for you?

Regards,
Ana



2008/5/8 Jorge Nieves <jorge.nieves at moorecap.com>:

> Hi,
>
> I am new R user and have been trying to properly configure an R 
> working environment. ?I ?have it up and ruining except for the
Rbloomberg.
>
> I tried running the examples in the documentation. And encountered 
> into several issues: ?First, R2.5.1 was crashing and I could never 
> understand why. I installed the latest release R 2.7.0 and was 
> eventually able to run only tow of the examples from
> blpGetData(RBloomberg)
>
> The intraday "Intraday bars" and the "Tick-by-tick" examples do not
run.
> I am wondering if (1) made a mistake in the set up? Or (2) there is a 
> problem here with R 2.7.0 too.
>
> Currently using
> Package: ? ? ? RBloomberg
> Version: ? ? ? 0.1-10
> Date: ? ? ? ? ?2006-05-04
> Built: ? ? ? ? R 2.5.1; ; 2007-07-22 18:19:52; windows
>
> Usinga lso 'RDCOMClient' version 0.92-0
>
> Any recommendatiosn?
>
> blpGetData(RBloomberg) examples.
>
> library(RBloomberg)
>
> .bbfields <- blpReadFields("C:/Program Files/blp/API")
>
> ## Not run:
> conn <- blpConnect()
>
> ## Snapshot
> eda <- blpGetData(conn, c("ED5 Comdty","ED6 Comdty","ED7 Comdty",
> "ED8 Comdty"), "BID")
> eda
>
> ## Historical (last 30 days)
> edb <- blpGetData(conn, "ED1 Comdty", "PX_LAST",
> start=as.chron(Sys.time() - 86400 * 30)) edb
>
> ## Intraday bars (last hour in 2 min bars) edc <- blpGetData(conn,
> "ED1 Comdty", c("BID","ASK"),
> start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2) edc
>
> ## Tick-by-tick (3 minutes starting an hour ago) edd <- 
> blpGetData(conn, "ED1 Comdty", c("BID"),
> start=as.chron(Sys.time() - 3600),
> end=as.chron(Sys.time() - 3420), barsize=0) edd
>
> blpDisconnect(conn)
> ## End(Not run)
>
>
> Output
>
>
>
> > .bbfields <- blpReadFields("C:/Program Files/blp/API")
> >
> > ## Not run:
> > conn <- blpConnect()
> >
> > ## Snapshot
> > eda <- blpGetData(conn, c("ED5 Comdty","ED6 Comdty","ED7 Comdty",
> + "ED8 Comdty"), "BID")
> > eda
> ? ? ? ? ? ? ?BID
> ED5 COMDTY 96.860
> ED6 COMDTY 96.680
> ED7 COMDTY 96.475
> ED8 COMDTY 96.330
> >
> > ## Historical (last 30 days)
> > edb <- blpGetData(conn, "ED1 Comdty", "PX_LAST",
> + start=as.chron(Sys.time() - 86400 * 30))
> > edb
> ? ? ? ? PX_LAST
> 04/08/08 ?97.530
> 04/09/08 ?97.545
> 04/10/08 ?97.500
> 04/11/08 ?97.540
> 04/14/08 ?97.495
> 04/15/08 ?97.440
> 04/16/08 ?97.290
> 04/17/08 ?97.120
> 04/18/08 ?97.090
> 04/21/08 ?97.125
> 04/22/08 ?97.125
> 04/23/08 ?97.135
> 04/24/08 ?97.145
> 04/25/08 ?97.135
> 04/28/08 ?97.195
> 04/29/08 ?97.245
> 04/30/08 ?97.325
> 05/01/08 ?97.330
> 05/02/08 ?97.365
> 05/05/08 ?97.350
> 05/06/08 ?97.365
> 05/07/08 ?97.365
> 05/08/08 ?97.395
> >
> > ## Intraday bars (last hour in 2 min bars) edc <- blpGetData(conn,
> > "ED1 Comdty", c("BID","ASK"),
> + start=as.chron(Sys.time() - 3600), barfields="OPEN", barsize=2)
> > edc
> ? ? ? ? ? ? ? ? ? ?BID.OPEN ASK.OPEN
> (05/08/08 09:26:21) ? ? ? NA ? ? ? NA
> >
> > ## Tick-by-tick (3 minutes starting an hour ago) edd <- 
> > blpGetData(conn, "ED1 Comdty", c("BID"),
> + start=as.chron(Sys.time() - 3600),
> + end=as.chron(Sys.time() - 3420), barsize=0)
> > edd
> Error in substr(text, first, last) : invalid substring argument(s)
> >
> > blpDisconnect(conn)
> ? ? ? ? used (Mb) gc trigger (Mb) max used (Mb) Ncells 291899 ?7.8 ? ? 
> 531268 14.2 ? 408779 11.0 Vcells 610228 ?4.7 ? ?1151091 ?8.8 ?1151024 ?
> 8.8
> > ## End(Not run)
> >
> > help(blpDisconnect)
> >
>
>
> Jorge Nieves
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>

? ? ? ?[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From enricoschumann at yahoo.de  Fri May  9 11:28:15 2008
From: enricoschumann at yahoo.de (Enrico Schumann)
Date: Fri, 9 May 2008 11:28:15 +0200
Subject: [R-SIG-Finance] portfolioFrontier/Spec: targetReturn
In-Reply-To: <8cca69990805081207k2516b681q99f42b5f3754fbdc@mail.gmail.com>
Message-ID: <120748.91265.bm@omp208.mail.ukl.yahoo.com>


dear josh

as portfolioFrontier seems to trace out the whole frontier of efficient
portfolios, i would not expect that changing the targetReturn and the
riskFreeRate makes a difference.

targetReturn should only be relevant if you look for one specific portfolio,
namely the one that minimises some `risk' measure (say, variance) while at
the same time satisfying your targetReturn constraint. when you plot the
whole frontier, you will get the portfolios for _all_ feasible
targetReturns.

the riskFreeRate should also not have an impact on the shape of the equity
portfolio frontier. all it allows is that you can build linear combinations
between the riskless asset and equity portfolios. (the riskless asset will
have zero risk and is thus a point on the y-axis which you can connect by a
line with any equity portfolio)

regards,
enrico


-----Urspr?ngliche Nachricht-----
Von: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] Im Auftrag von Josh Ulrich
Gesendet: Donnerstag, 8. Mai 2008 21:08
An: R-sig-finance
Betreff: [R-SIG-Finance] portfolioFrontier/Spec: targetReturn

List,

I am trying to help a colleague with a question, but I am - by no means - an
expert in this area.  The output of the portfolioFrontier function in the
code below doesn't change for different values of targetReturn and
riskFreeRate (in portfolioSpec).  I would appreciate if someone could point
me to information on why this should be expected or not.

Best,
Josh

require(TTR)
require(zoo)
suppressMessages(require(fPortfolio))

syms <- c('ABNDX','CAIBX','CWBFX','CWGIX','RYEOX','RYMTX','DBV')
X <- getYahooData(syms[1], start=20070601, quiet=TRUE) X <- zoo( X$Close,
X$Date ) for(i in 2:NROW(syms)) {
 print(syms[i])
 x <- getYahooData(syms[i], start=20070601, quiet=TRUE)  X <- cbind( X, zoo(
x$Close, x$Date ) ) }
colnames(X) <- syms
R <- as.timeSeries(returns(X, percentage = TRUE))

Spec = portfolioSpec(model = list(type = c("MV", "CVaR"),
  estimator = c("mean", "cov"), tailRisk = list(), params = list()),
  portfolio = list(weights = NULL, targetReturn = NULL,
    targetRisk = 4, targetAlpha = 0.05, riskFreeRate = NULL,
    nFrontierPoints = 50),
  solver = list(solver = c("quadprog", "Rdonlp2", "lpSolve"), trace =
FALSE)) Spec frontier <- portfolioFrontier( R, Spec, c("minW[1:nAssets]=0"))
weightsSlider(frontier)


> sessionInfo()
R version 2.7.0 (2008-04-22)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] tcltk     stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
 [1] fPortfolio_260.72  fAssets_260.72     fRegression_260.72
fMultivar_260.72
 [5] sn_0.4-4           mnormt_1.2-1       fTrading_260.72
polspline_1.0.15
 [9] nnet_7.2-42        mgcv_1.3-31        fBasics_260.72     fImport_260.72
[13] fSeries_260.72     fCalendar_262.73   fEcofin_260.72
fUtilities_260.72
[17] spatial_7.2-42     RUnit_0.4.17       robustbase_0.2-8   MASS_7.2-42
[21] lpSolve_5.6.2      quadprog_1.4-11    zoo_1.5-3          TTR_0.14-0

loaded via a namespace (and not attached):
Error in x[["Version"]] : subscript out of bounds In addition: Warning
message:
In FUN(c("grid", "lattice")[[2L]], ...) :
  DESCRIPTION file of package 'lattice' is missing or broken


--
http://quantemplation.blogspot.com

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.

No virus found in this incoming message.
Checked by AVG. 

07.05.2008
17:23



Checked by AVG. 

08.05.2008
17:24


From Achim.Zeileis at wu-wien.ac.at  Fri May  9 12:38:48 2008
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri, 9 May 2008 12:38:48 +0200 (CEST)
Subject: [R-SIG-Finance] two zoo questions
In-Reply-To: <947970.42462.qm@web50104.mail.re2.yahoo.com>
References: <947970.42462.qm@web50104.mail.re2.yahoo.com>
Message-ID: <Pine.LNX.4.64.0805091231120.6074@paninaro.stat-math.wu-wien.ac.at>

On Fri, 9 May 2008, michal miklovic wrote:

> I have a zoo object with three time series and the corresponding dates. 
> When I plot it, the x-axis contains dates which are not in the object 
> and, naturally, no data points are displayed for these dates. For 
> example, the date "2006-05-20" is not in the object, but it appears in 
> the x-axis of the plot. As a result, I get a plot with 'empty' segments.

I cannot reproduce that problem. For me 2006-05-22 is the first label 
displayed. In any case, 2006-05-20 is within the range of 
time(ShorterSpan) so I wouldn't be too surprised if it would appear. If 
you want fine control over the axis, you can
   plot(ShorterSpan, ..., axes = FALSE)
   axis(2)
   axis.Date(1, time(ShorterSpan), ...)
and pass all desired arguments to axis.Date() including "at" and "format".

> My second question concerns the way of displaying the dates on the 
> x-axis. Currently, the dates are displayed as "V 22", which stands for 
> "2006-05-22". I would like them to be displayed as "22 05 2006" or "22 
> May 2006". How can I do this?

Either suppress axes and add them by hand afterwards as outlined above, or
simply set format = "%d %b %Y" in your plot() call.

Both will lead to a couple of warnings but produce the desired result.

Best,
Z


From ggrothendieck at gmail.com  Fri May  9 13:12:19 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 May 2008 07:12:19 -0400
Subject: [R-SIG-Finance] two zoo questions
In-Reply-To: <947970.42462.qm@web50104.mail.re2.yahoo.com>
References: <947970.42462.qm@web50104.mail.re2.yahoo.com>
Message-ID: <971536df0805090412h5f1be691kfb93f84580f4855f@mail.gmail.com>

1. I can't reproduce your description either. When
I run the following using zoo 1.5-3 and  "R version 2.7.0 RC
(2008-04-17 r45367)"
the labelling on the X axis is May 22, May 27, Jun 01, Jun 06, Jun 11 and Jun 16
and when in the second plot statement (###) we plot the first series
using ordinary,
not zoo, graphics we get the exact same X axis (as expected) so there is nothing
specific to zoo here -- that is how automatic labelling in R works.

Maybe your ShorterSpan object is not what you think.  Try posting
dput(ShorterSpan) or perhaps inspection will make it immediately clear.
(Continued after code.)

library(zoo)
Lines <- " PXreturns VaRWHSe099 VaRWHSe095
2006-05-19 -0.6479279   1.878092   1.515232
2006-05-22 -6.1249511   1.878092   1.515232
2006-05-23  2.3501118   1.878092   1.515232
2006-05-24 -4.2859466   2.350112   2.350112
2006-05-25  2.6466856   2.350112   2.350112
2006-05-26  2.5496719   2.646686   2.646686
2006-05-29 -0.7580990   2.646686   2.646686
2006-05-30 -1.9170851   2.646686   2.646686
2006-05-31 -1.8566689   2.646686   2.646686
2006-06-01  1.4198415   2.646686   2.646686
2006-06-02  1.6703232   2.646686   2.646686
2006-06-05 -0.4974407   2.646686   2.646686
2006-06-06 -1.6936396   2.646686   2.646686
2006-06-07 -3.0212406   2.646686   2.646686
2006-06-08 -4.0235989   2.646686   2.646686
2006-06-09 -1.3131054   2.646686   2.646686
2006-06-12 -2.4710858   2.646686   2.646686
2006-06-13 -3.0808024   2.646686   2.646686
2006-06-14  1.9859772   2.646686   2.646686
2006-06-15  7.0481958   2.646686   2.646686
2006-06-16  0.1095805   7.048196   7.048196
2006-06-19  2.4037947   3.583430   7.048196
"
ShorterSpan <- read.zoo(textConnection(Lines), skip = 1, FUN = as.Date)
colnames(ShorterSpan) <- read.table(textConnection(Lines), nrow = 1)

plot(ShorterSpan, plot.type = "single", type = "p", xlab = "Date", ylab = "",
   col = list("black", "red", "orange"), pch = c(19,22,23), las = 1)

# gives same X axis labelling -- does not use plot.zoo
plot(time(ShorterSpan), coredata(ShorterSpan)[,1]) ###


2. Regarding your second question, you can change the format as in the
previously posted response or by issuing a custom axis command:

plot(ShorterSpan, type = "p", screen = 1, xaxt = "n")
ax <- as.Date(axTicks(1))
axis(1, ax, format(ax, "%Y-%m-%d"), cex.axis = 0.7)



On Fri, May 9, 2008 at 4:18 AM, michal miklovic <mmiklovic at yahoo.com> wrote:
> Hi,
>
> I have a zoo object with three time series and the corresponding dates. When I plot it, the x-axis contains dates which are not in the object and, naturally, no data points are displayed for these dates. For example, the date "2006-05-20" is not in the object, but it appears in the x-axis of the plot. As a result, I get a plot with 'empty' segments. The object, my code and sessionInfo are copied below.
> I would like to ask if it is possible to plot only the relevant dates, i.e. to produce a plot without, e.g., the date "2006-05-20". If yes, how could I do it?
>
> My second question concerns the way of displaying the dates on the x-axis. Currently, the dates are displayed as "V 22", which stands for "2006-05-22". I would like them to be displayed as "22 05 2006" or "22 May 2006". How can I do this?
>
> Thanks for your help!
>
> Michal
>
>
> The zoo object, ShorterSpan:
>            PXreturns VaRWHSe099 VaRWHSe095
> 2006-05-19 -0.6479279   1.878092   1.515232
> 2006-05-22 -6.1249511   1.878092   1.515232
> 2006-05-23  2.3501118   1.878092   1.515232
> 2006-05-24 -4.2859466   2.350112   2.350112
> 2006-05-25  2.6466856   2.350112   2.350112
> 2006-05-26  2.5496719   2.646686   2.646686
> 2006-05-29 -0.7580990   2.646686   2.646686
> 2006-05-30 -1.9170851   2.646686   2.646686
> 2006-05-31 -1.8566689   2.646686   2.646686
> 2006-06-01  1.4198415   2.646686   2.646686
> 2006-06-02  1.6703232   2.646686   2.646686
> 2006-06-05 -0.4974407   2.646686   2.646686
> 2006-06-06 -1.6936396   2.646686   2.646686
> 2006-06-07 -3.0212406   2.646686   2.646686
> 2006-06-08 -4.0235989   2.646686   2.646686
> 2006-06-09 -1.3131054   2.646686   2.646686
> 2006-06-12 -2.4710858   2.646686   2.646686
> 2006-06-13 -3.0808024   2.646686   2.646686
> 2006-06-14  1.9859772   2.646686   2.646686
> 2006-06-15  7.0481958   2.646686   2.646686
> 2006-06-16  0.1095805   7.048196   7.048196
> 2006-06-19  2.4037947   3.583430   7.048196
>
> My code:
>
> plot(ShorterSpan, plot.type = "single", type = "p", xlab = "Date", ylab = "",
>    col = list("black", "red", "orange"), pch = c(19,22,23), las = 1)
> legend.text <- expression(paste("% log returns on PX"),
>    paste("VaR WHS, ", eta, " = 0.99"), paste("VaR WHS, ", eta, " = 0.95"))
> legend("topleft", legend.text, col=c("black", "red","orange"), pch = c(19,22,23),
>    bty="n", y.intersp = 1.5)
>
>
> sessionInfo()
>
> R version 2.6.2 (2008-02-08)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Slovak_Slovakia.1250;LC_CTYPE=Slovak_Slovakia.1250;LC_MONETARY=Slovak_Slovakia.1250;
> LC_NUMERIC=C;LC_TIME=Slovak_Slovakia.1250
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] zoo_1.5-2
>
> loaded via a namespace (and not attached):
> [1] grid_2.6.2     lattice_0.17-6
>
>
>
>      ____________________________________________________________________________________
>
> [[elided Yahoo spam]]
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From mmiklovic at yahoo.com  Fri May  9 14:21:49 2008
From: mmiklovic at yahoo.com (michal miklovic)
Date: Fri, 9 May 2008 05:21:49 -0700 (PDT)
Subject: [R-SIG-Finance] two zoo questions
Message-ID: <696493.8510.qm@web50103.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080509/4b6e55e7/attachment.pl>

From Achim.Zeileis at wu-wien.ac.at  Fri May  9 15:14:31 2008
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri, 9 May 2008 15:14:31 +0200 (CEST)
Subject: [R-SIG-Finance] two zoo questions
In-Reply-To: <696493.8510.qm@web50103.mail.re2.yahoo.com>
Message-ID: <Pine.LNX.4.44.0805091511210.31902-100000@disco.wu-wien.ac.at>

On Fri, 9 May 2008, michal miklovic wrote:

> Hi,
>
> thanks for your prompt responses.
> I am sorry for not being clear in my first question. The date
> "2006-05-20" was not displayed in my plot but the x-axis contained a
> corresponding 'slot' although the date is not in the zoo object.
> Similarly, the date "Jun 11" is displayed but there are no observation
> for this date.

Gabor explained why this happens. When you do a scatter plot of
  plot(c(1, 2, 4), rnorm(3))
There is also 3 in the range of the x-axis although there are no
observations for this.

> I would like my x-axis to contain only the dates that are in the object.
> In other words, I do not want my plot to have empty segments, which arise
> from adding dates without observations to the x-axis. Is this possible?

I still don't understand what empty segments really means. But I have the
suspsicion you want something like:
  plot(1:nrow(ShorterSpan), ShorterSpan[,1], xaxt = "n")
  axis(1, at = 1:nrow(ShorterSpan),
    labels = format(time(ShorterSpan), "%d %b %Y"))
which is not really a time series plot...

hth,
Z

> Concerning my second question, your suggestions worked fine.
>
> Thanks again for your help.
>
> Best regards,
>
> Michal
>
>
> 'dput' output:
>
> structure(c(-0.647927859775788, -6.12495112247933, 2.35011183030576,
> -4.28594659156438, 2.64668558870609, 2.54967191535274, -0.758099006348889,
> -1.91708512600499, -1.85666892546967, 1.41984151778516, 1.67032322347964,
> -0.49744067461619, -1.69363956562325, -3.02124058139697, -4.02359885185390,
> -1.31310542630114, -2.47108579725168, -3.08080237199411, 1.98597717860372,
> 7.04819583250611, 0.10958047433407, 2.40379468330145, 1.87809239730186,
> 1.87809239730186, 1.87809239730186, 2.35011183030576, 2.35011183030576,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 7.04819583250611,
> 3.58343037136928, 1.51523152190878, 1.51523152190878, 1.51523152190878,
> 2.35011183030576, 2.35011183030576, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 7.04819583250611, 7.04819583250611), .Dim = c(22L,
> 3L), .Dimnames = list(NULL, c("PXreturns", "VaRWHSe099", "VaRWHSe095"
> )), index = structure(c(13287, 13290, 13291, 13292, 13293, 13294,
> 13297, 13298, 13299, 13300, 13301, 13304, 13305, 13306, 13307,
> 13308, 13311, 13312, 13313, 13314, 13315, 13318), class = "Date"), class = "zoo")
>
>
>
>
> ----- Original Message ----
> From: Gabor Grothendieck <ggrothendieck at gmail.com>
> To: michal miklovic <mmiklovic at yahoo.com>
> Cc: r-sig-finance at stat.math.ethz.ch
> Sent: Friday, May 9, 2008 1:12:19 PM
> Subject: Re: [R-SIG-Finance] two zoo questions
>
> 1. I can't reproduce your description either. When
> I run the following using zoo 1.5-3 and  "R version 2.7.0 RC
> (2008-04-17 r45367)"
> the labelling on the X axis is May 22, May 27, Jun 01, Jun 06, Jun 11 and Jun 16
> and when in the second plot statement (###) we plot the first series
> using ordinary,
> not zoo, graphics we get the exact same X axis (as expected) so there is nothing
> specific to zoo here -- that is how automatic labelling in R works.
>
> Maybe your ShorterSpan object is not what you think.  Try posting
> dput(ShorterSpan) or perhaps inspection will make it immediately clear.
> (Continued after code.)
>
> library(zoo)
> Lines <- " PXreturns VaRWHSe099 VaRWHSe095
> 2006-05-19 -0.6479279   1.878092   1.515232
> 2006-05-22 -6.1249511   1.878092   1.515232
> 2006-05-23  2.3501118   1.878092   1.515232
> 2006-05-24 -4.2859466   2.350112   2.350112
> 2006-05-25  2.6466856   2.350112   2.350112
> 2006-05-26  2.5496719   2.646686   2.646686
> 2006-05-29 -0.7580990   2.646686   2.646686
> 2006-05-30 -1.9170851   2.646686   2.646686
> 2006-05-31 -1.8566689   2.646686   2.646686
> 2006-06-01  1.4198415   2.646686   2.646686
> 2006-06-02  1.6703232   2.646686   2.646686
> 2006-06-05 -0.4974407   2.646686   2.646686
> 2006-06-06 -1.6936396   2.646686   2.646686
> 2006-06-07 -3.0212406   2.646686   2.646686
> 2006-06-08 -4.0235989   2.646686   2.646686
> 2006-06-09 -1.3131054   2.646686   2.646686
> 2006-06-12 -2.4710858   2.646686   2.646686
> 2006-06-13 -3.0808024   2.646686   2.646686
> 2006-06-14  1.9859772   2.646686   2.646686
> 2006-06-15  7.0481958   2.646686   2.646686
> 2006-06-16  0.1095805   7.048196   7.048196
> 2006-06-19  2.4037947   3.583430   7.048196
> "
> ShorterSpan <- read.zoo(textConnection(Lines), skip = 1, FUN = as.Date)
> colnames(ShorterSpan) <- read.table(textConnection(Lines), nrow = 1)
>
> plot(ShorterSpan, plot.type = "single", type = "p", xlab = "Date", ylab = "",
>    col = list("black", "red", "orange"), pch = c(19,22,23), las = 1)
>
> # gives same X axis labelling -- does not use plot.zoo
> plot(time(ShorterSpan), coredata(ShorterSpan)[,1]) ###
>
>
> 2. Regarding your second question, you can change the format as in the
> previously posted response or by issuing a custom axis command:
>
> plot(ShorterSpan, type = "p", screen = 1, xaxt = "n")
> ax <- as.Date(axTicks(1))
> axis(1, ax, format(ax, "%Y-%m-%d"), cex.axis = 0.7)
>
>
>
> On Fri, May 9, 2008 at 4:18 AM, michal miklovic <mmiklovic at yahoo.com> wrote:
> > Hi,
> >
> > I have a zoo object with three time series and the corresponding dates. When I plot it, the x-axis contains dates which are not in the object and, naturally, no data points are displayed for these dates. For example, the date "2006-05-20" is not in the object, but it appears in the x-axis of the plot. As a result, I get a plot with 'empty' segments. The object, my code and sessionInfo are copied below.
> > I would like to ask if it is possible to plot only the relevant dates, i.e. to produce a plot without, e.g., the date "2006-05-20". If yes, how could I do it?
> >
> > My second question concerns the way of displaying the dates on the x-axis. Currently, the dates are displayed as "V 22", which stands for "2006-05-22". I would like them to be displayed as "22 05 2006" or "22 May 2006". How can I do this?
> >
> > Thanks for your help!
> >
> > Michal
> >
> >
> > The zoo object, ShorterSpan:
> >            PXreturns VaRWHSe099 VaRWHSe095
> > 2006-05-19 -0.6479279   1.878092   1.515232
> > 2006-05-22 -6.1249511   1.878092   1.515232
> > 2006-05-23  2.3501118   1.878092   1.515232
> > 2006-05-24 -4.2859466   2.350112   2.350112
> > 2006-05-25  2.6466856   2.350112   2.350112
> > 2006-05-26  2.5496719   2.646686   2.646686
> > 2006-05-29 -0.7580990   2.646686   2.646686
> > 2006-05-30 -1.9170851   2.646686   2.646686
> > 2006-05-31 -1.8566689   2.646686   2.646686
> > 2006-06-01  1.4198415   2.646686   2.646686
> > 2006-06-02  1.6703232   2.646686   2.646686
> > 2006-06-05 -0.4974407   2.646686   2.646686
> > 2006-06-06 -1.6936396   2.646686   2.646686
> > 2006-06-07 -3.0212406   2.646686   2.646686
> > 2006-06-08 -4.0235989   2.646686   2.646686
> > 2006-06-09 -1.3131054   2.646686   2.646686
> > 2006-06-12 -2.4710858   2.646686   2.646686
> > 2006-06-13 -3.0808024   2.646686   2.646686
> > 2006-06-14  1.9859772   2.646686   2.646686
> > 2006-06-15  7.0481958   2.646686   2.646686
> > 2006-06-16  0.1095805   7.048196   7.048196
> > 2006-06-19  2.4037947   3.583430   7.048196
> >
> > My code:
> >
> > plot(ShorterSpan, plot.type = "single", type = "p", xlab = "Date", ylab = "",
> >    col = list("black", "red", "orange"), pch = c(19,22,23), las = 1)
> > legend.text <- expression(paste("% log returns on PX"),
> >    paste("VaR WHS, ", eta, " = 0.99"), paste("VaR WHS, ", eta, " = 0.95"))
> > legend("topleft", legend.text, col=c("black", "red","orange"), pch = c(19,22,23),
> >    bty="n", y.intersp = 1.5)
> >
> >
> > sessionInfo()
> >
> > R version 2.6.2 (2008-02-08)
> > i386-pc-mingw32
> >
> > locale:
> > LC_COLLATE=Slovak_Slovakia.1250;LC_CTYPE=Slovak_Slovakia.1250;LC_MONETARY=Slovak_Slovakia.1250;
> > LC_NUMERIC=C;LC_TIME=Slovak_Slovakia.1250
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] zoo_1.5-2
> >
> > loaded via a namespace (and not attached):
> > [1] grid_2.6.2     lattice_0.17-6
> >
> >
> >
> >      ____________________________________________________________________________________
> >
> > [[elided Yahoo spam]]
> >        [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only.
> > -- If you want to post, subscribe first.
> >
>
>
>
>       ____________________________________________________________________________________
> Be a better friend, newshound, and
> know-it-all with Yahoo! Mobile.  Try it now.  http://mobile.yahoo.com/;_ylt=Ahu06i62sR8HDtDypao8Wcj9tAcJ


From ggrothendieck at gmail.com  Fri May  9 15:14:28 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 May 2008 09:14:28 -0400
Subject: [R-SIG-Finance] two zoo questions
In-Reply-To: <696493.8510.qm@web50103.mail.re2.yahoo.com>
References: <696493.8510.qm@web50103.mail.re2.yahoo.com>
Message-ID: <971536df0805090614m24af4e2axb649b9928bec54d6@mail.gmail.com>

On Fri, May 9, 2008 at 8:21 AM, michal miklovic <mmiklovic at yahoo.com> wrote:
> Hi,
>
> thanks for your prompt responses.
> I am sorry for not being clear in my first question. The date "2006-05-20"
> was not displayed in my plot but the x-axis contained a corresponding 'slot'
> although the date is not in the zoo object. Similarly, the date "Jun 11" is
> displayed but there are no observation for this date.
> I would like my x-axis to contain only the dates that are in the object. In
> other words, I do not want my plot to have empty segments, which arise from
> adding dates without observations to the x-axis. Is this possible?

By "empty segments" do you mean you just want to plot the data
against 1, 2, 3, ... and then label successive times as
format(time(ShorterSpan), "...") on the X axis?

If that is it then try this:

s <- zoo(coredata(ShorterSpan))
plot(s, screens = 1, type = "p", col = 1:3, xaxt = "n")
axis(1, time(s), format(time(ShorterSpan), "%m-%d"), cex.axis = 0.5)

>
> Concerning my second question, your suggestions worked fine.
>
> Thanks again for your help.
>
> Best regards,
>
> Michal
>
>
> 'dput' output:
>
> structure(c(-0.647927859775788, -6.12495112247933, 2.35011183030576,
> -4.28594659156438, 2.64668558870609, 2.54967191535274, -0.758099006348889,
> -1.91708512600499, -1.85666892546967, 1.41984151778516, 1.67032322347964,
> -0.49744067461619, -1.69363956562325, -3.02124058139697, -4.02359885185390,
> -1.31310542630114, -2.47108579725168, -3.08080237199411, 1.98597717860372,
> 7.04819583250611, 0.10958047433407, 2.40379468330145, 1.87809239730186,
> 1.87809239730186, 1.87809239730186, 2.35011183030576, 2.35011183030576,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 7.04819583250611,
> 3.58343037136928, 1.51523152190878, 1.51523152190878, 1.51523152190878,
> 2.35011183030576, 2.35011183030576, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 2.64668558870609, 2.64668558870609, 2.64668558870609,
> 2.64668558870609, 7.04819583250611, 7.04819583250611), .Dim = c(22L,
> 3L), .Dimnames = list(NULL, c("PXreturns", "VaRWHSe099", "VaRWHSe095"
> )), index = structure(c(13287, 13290, 13291, 13292, 13293, 13294,
> 13297, 13298, 13299, 13300, 13301, 13304, 13305, 13306, 13307,
> 13308, 13311, 13312, 13313, 13314, 13315, 13318), class = "Date"), class =
> "zoo")
>
>
>
> ----- Original Message ----
> From: Gabor Grothendieck <ggrothendieck at gmail.com>
> To: michal miklovic <mmiklovic at yahoo.com>
> Cc: r-sig-finance at stat.math.ethz.ch
> Sent: Friday, May 9, 2008 1:12:19 PM
> Subject: Re: [R-SIG-Finance] two zoo questions
>
> 1. I can't reproduce your description either. When
> I run the following using zoo 1.5-3 and  "R version 2.7.0 RC
> (2008-04-17 r45367)"
> the labelling on the X axis is May 22, May 27, Jun 01, Jun 06, Jun 11 and
> Jun 16
> and when in the second plot statement (###) we plot the first series
> using ordinary,
> not zoo, graphics we get the exact same X axis (as expected) so there is
> nothing
> specific to zoo here -- that is how automatic labelling in R works.
>
> Maybe your ShorterSpan object is not what you think.  Try posting
> dput(ShorterSpan) or perhaps inspection will make it immediately clear.
> (Continued after code.)
>
> library(zoo)
> Lines <- " PXreturns VaRWHSe099 VaRWHSe095
> 2006-05-19 -0.6479279  1.878092  1.515232
> 2006-05-22 -6.1249511  1.878092  1.515232
> 2006-05-23  2.3501118  1.878092  1.515232
> 2006-05-24 -4.2859466  2.350112  2.350112
> 2006-05-25  2.6466856  2.350112  2.350112
> 2006-05-26  2.5496719  2.646686  2.646686
> 2006-05-29 -0.7580990  2.646686  2.646686
> 2006-05-30 -1.9170851  2.646686  2.646686
> 2006-05-31 -1.8566689  2.646686  2.646686
> 2006-06-01  1.4198415  2.646686  2.646686
> 2006-06-02  1.6703232  2.646686  2.646686
> 2006-06-05 -0.4974407  2.646686  2.646686
> 2006-06-06 -1.6936396  2.646686  2.646686
> 2006-06-07 -3.0212406  2.646686  2.646686
> 2006-06-08 -4.0235989  2.646686  2.646686
> 2006-06-09 -1.3131054  2.646686  2.646686
> 2006-06-12 -2.4710858  2.646686  2.646686
> 2006-06-13 -3.0808024  2.646686  2.646686
> 2006-06-14  1.9859772  2.646686  2.646686
> 2006-06-15  7.0481958  2.646686  2.646686
> 2006-06-16  0.1095805  7.048196  7.048196
> 2006-06-19  2.4037947  3.583430  7.048196
> "
> ShorterSpan <- read.zoo(textConnection(Lines), skip = 1, FUN = as.Date)
> colnames(ShorterSpan) <- read.table(textConnection(Lines), nrow = 1)
>
> plot(ShorterSpan, plot.type = "single", type = "p", xlab = "Date", ylab =
> "",
>   col = list("black", "red", "orange"), pch = c(19,22,23), las = 1)
>
> # gives same X axis labelling -- does not use plot.zoo
> plot(time(ShorterSpan), coredata(ShorterSpan)[,1]) ###
>
>
> 2. Regarding your second question, you can change the format as in the
> previously posted response or by issuing a custom axis command:
>
> plot(ShorterSpan, type = "p", screen = 1, xaxt = "n")
> ax <- as.Date(axTicks(1))
> axis(1, ax, format(ax, "%Y-%m-%d"), cex.axis = 0.7)
>
>
>
> On Fri, May 9, 2008 at 4:18 AM, michal miklovic <mmiklovic at yahoo.com> wrote:
>> Hi,
>>
>> I have a zoo object with three time series and the corresponding dates.
>> When I plot it, the x-axis contains dates which are not in the object and,
>> naturally, no data points are displayed for these dates. For example, the
>> date "2006-05-20" is not in the object, but it appears in the x-axis of the
>> plot. As a result, I get a plot with 'empty' segments. The object, my code
>> and sessionInfo are copied below.
>> I would like to ask if it is possible to plot only the relevant dates,
>> i.e. to produce a plot without, e.g., the date "2006-05-20". If yes, how
>> could I do it?
>>
>> My second question concerns the way of displaying the dates on the x-axis.
>> Currently, the dates are displayed as "V 22", which stands for "2006-05-22".
>> I would like them to be displayed as "22 05 2006" or "22 May 2006". How can
>> I do this?
>>
>> Thanks for your help!
>>
>> Michal
>>
>>
>> The zoo object, ShorterSpan:
>>            PXreturns VaRWHSe099 VaRWHSe095
>> 2006-05-19 -0.6479279  1.878092  1.515232
>> 2006-05-22 -6.1249511  1.878092  1.515232
>> 2006-05-23  2.3501118  1.878092  1.515232
>> 2006-05-24 -4.2859466  2.350112  2.350112
>> 2006-05-25  2.6466856  2.350112  2.350112
>> 2006-05-26  2.5496719  2.646686  2.646686
>> 2006-05-29 -0.7580990  2.646686  2.646686
>> 2006-05-30 -1.9170851  2.646686  2.646686
>> 2006-05-31 -1.8566689  2.646686  2.646686
>> 2006-06-01  1.4198415  2.646686  2.646686
>> 2006-06-02  1.6703232  2.646686  2.646686
>> 2006-06-05 -0.4974407  2.646686  2.646686
>> 2006-06-06 -1.6936396  2.646686  2.646686
>> 2006-06-07 -3.0212406  2.646686  2.646686
>> 2006-06-08 -4.0235989  2.646686  2.646686
>> 2006-06-09 -1.3131054  2.646686  2.646686
>> 2006-06-12 -2.4710858  2.646686  2.646686
>> 2006-06-13 -3.0808024  2.646686  2.646686
>> 2006-06-14  1.9859772  2.646686  2.646686
>> 2006-06-15  7.0481958  2.646686  2.646686
>> 2006-06-16  0.1095805  7.048196  7.048196
>> 2006-06-19  2.4037947  3.583430  7.048196
>>
>> My code:
>>
>> plot(ShorterSpan, plot.type = "single", type = "p", xlab = "Date", ylab =
>> "",
>>    col = list("black", "red", "orange"), pch = c(19,22,23), las = 1)
>> legend.text <- expression(paste("% log returns on PX"),
>>    paste("VaR WHS, ", eta, " = 0.99"), paste("VaR WHS, ", eta, " = 0.95"))
>> legend("topleft", legend.text, col=c("black", "red","orange"), pch =
>> c(19,22,23),
>>    bty="n", y.intersp = 1.5)
>>
>>
>> sessionInfo()
>>
>> R version 2.6.2 (2008-02-08)
>> i386-pc-mingw32
>>
>> locale:
>>
>> LC_COLLATE=Slovak_Slovakia.1250;LC_CTYPE=Slovak_Slovakia.1250;LC_MONETARY=Slovak_Slovakia.1250;
>> LC_NUMERIC=C;LC_TIME=Slovak_Slovakia.1250
>>
>> attached base packages:
>> [1] stats    graphics  grDevices utils    datasets  methods  base
>>
>> other attached packages:
>> [1] zoo_1.5-2
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.6.2    lattice_0.17-6
>>
>>
>>
>>
>> ____________________________________________________________________________________
>>
>> [[elided Yahoo spam]]
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>
> ________________________________
> Be a better friend, newshound, and know-it-all with Yahoo! Mobile. Try it
> now.


From vlanschot at yahoo.com  Thu May 15 11:59:46 2008
From: vlanschot at yahoo.com (R@Nabble)
Date: Thu, 15 May 2008 02:59:46 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Example codes fPortfolio Package ?
Message-ID: <17249802.post@talk.nabble.com>


Hello,

I was wondering whether there are more code-examples available for the above
package. In particular, I'm interested in applications whereby:

1) One can define per asset the minW, maxW constraints. 
(I tried ConstrLO = c("minW[1]=10","minW[2]=10","maxW[3]=15"), but I guess
my interpretation of "vector of character strings" as described in the
manual for the input here is wrong).
2) In addition to 1, add sector constraints (i.e. does one simply add it,
like ConstrLO = c("minW[1]=10","minW[2]=10","maxW[3]=15", "minsumW[1:2]=50")
???)
3) One can add the benchmark portfolio within the analysis, in particular as
a "dot" within the efficient frontier graph.
4) Assuming leverage, how to show a move along the cap.mkt line?

Any help/suggestions much appreciated.

Thx,

R at N
-- 
View this message in context: http://www.nabble.com/Example-codes-fPortfolio-Package---tp17249802p17249802.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From wuertz at itp.phys.ethz.ch  Thu May 15 14:05:55 2008
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Thu, 15 May 2008 14:05:55 +0200
Subject: [R-SIG-Finance] [R-sig-finance] Example codes fPortfolio
 Package ?
In-Reply-To: <17249802.post@talk.nabble.com>
References: <17249802.post@talk.nabble.com>
Message-ID: <482C2723.80804@itp.phys.ethz.ch>

R at Nabble wrote:
> Hello,
>
> I was wondering whether there are more code-examples available for the above
> package. In particular, I'm interested in applications whereby:
>
> 1) One can define per asset the minW, maxW constraints. 
> (I tried ConstrLO = c("minW[1]=10","minW[2]=10","maxW[3]=15"), but I guess
> my interpretation of "vector of character strings" as described in the
> manual for the input here is wrong).
> 2) In addition to 1, add sector constraints (i.e. does one simply add it,
> like ConstrLO = c("minW[1]=10","minW[2]=10","maxW[3]=15", "minsumW[1:2]=50")
> ???)
>   
Try just

c("minW[1]=0.10","minW[2]=0.10","maxW[3]=0.15") instead of 


c("minW[1]=10","minW[2]=10","maxW[3]=15")


I think this should be made more explicit in the help file.

Have you looked in the unit test directory where you find douzans of
unit testing examples.

Diethelm


> 3) One can add the benchmark portfolio within the analysis, in particular as
> a "dot" within the efficient frontier graph.
> 4) Assuming leverage, how to show a move along the cap.mkt line?
>
> Any help/suggestions much appreciated.
>
> Thx,
>
> R at N
>   


-- 

PD Dr. Diethelm Wuertz
Institute for Theoretical Physics
Swiss Federal Institute of Technology

www.itp.phys.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From alexandra.nitescoux at sgcib.com  Thu May 15 14:50:03 2008
From: alexandra.nitescoux at sgcib.com (A.N.)
Date: Thu, 15 May 2008 05:50:03 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] fPortfolio  min CVaR
Message-ID: <17252498.post@talk.nabble.com>


I am testing the fPortfolio package by comparing in the optimization type
between mean variance and CVaR minimization and I don't find where the CVaR
works in the solver code. 
By the way how the constraints in VaR and CVaR in the specifications are
computed in the optimization problem ? 



-- 
View this message in context: http://www.nabble.com/fPortfolio--min-CVaR-tp17252498p17252498.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From vlanschot at yahoo.com  Thu May 15 15:10:53 2008
From: vlanschot at yahoo.com (R@Nabble)
Date: Thu, 15 May 2008 06:10:53 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Example codes fPortfolio
	Package ?
In-Reply-To: <482C2723.80804@itp.phys.ethz.ch>
References: <17249802.post@talk.nabble.com> <482C2723.80804@itp.phys.ethz.ch>
Message-ID: <17252922.post@talk.nabble.com>


Thank you Diethelm. That did the trick (and kind of obvious, should have
tried myself), and I will have a look at those example files. Thanks for
creating this library which I'm currently learning and intend to use a lot.

R at N

Diethelm Wuertz wrote:
> 
> R at Nabble wrote:
>> Hello,
>>
>> I was wondering whether there are more code-examples available for the
>> above
>> package. In particular, I'm interested in applications whereby:
>>
>> 1) One can define per asset the minW, maxW constraints. 
>> (I tried ConstrLO = c("minW[1]=10","minW[2]=10","maxW[3]=15"), but I
>> guess
>> my interpretation of "vector of character strings" as described in the
>> manual for the input here is wrong).
>> 2) In addition to 1, add sector constraints (i.e. does one simply add it,
>> like ConstrLO = c("minW[1]=10","minW[2]=10","maxW[3]=15",
>> "minsumW[1:2]=50")
>> ???)
>>   
> Try just
> 
> c("minW[1]=0.10","minW[2]=0.10","maxW[3]=0.15") instead of 
> 
> 
> c("minW[1]=10","minW[2]=10","maxW[3]=15")
> 
> 
> I think this should be made more explicit in the help file.
> 
> Have you looked in the unit test directory where you find douzans of
> unit testing examples.
> 
> Diethelm
> 
> 
>> 3) One can add the benchmark portfolio within the analysis, in particular
>> as
>> a "dot" within the efficient frontier graph.
>> 4) Assuming leverage, how to show a move along the cap.mkt line?
>>
>> Any help/suggestions much appreciated.
>>
>> Thx,
>>
>> R at N
>>   
> 
> 
> -- 
> 
> PD Dr. Diethelm Wuertz
> Institute for Theoretical Physics
> Swiss Federal Institute of Technology
> 
> www.itp.phys.ethz.ch
> www.rmetrics.org
> 
> NOTE:
> Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
> June 29th - July 3rd Meielisalp, Lake Thune, Switzerland
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
> 

-- 
View this message in context: http://www.nabble.com/Example-codes-fPortfolio-Package---tp17249802p17252922.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From wuertz at itp.phys.ethz.ch  Fri May 16 09:19:40 2008
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Fri, 16 May 2008 09:19:40 +0200
Subject: [R-SIG-Finance] [R-sig-finance] fPortfolio  min CVaR
In-Reply-To: <17252498.post@talk.nabble.com>
References: <17252498.post@talk.nabble.com>
Message-ID: <482D358C.6020104@itp.phys.ethz.ch>

A.N. wrote:
> I am testing the fPortfolio package by comparing in the optimization type
> between mean variance and CVaR minimization and I don't find where the CVaR
> works in the solver code. 
> By the way how the constraints in VaR and CVaR in the specifications are
> computed in the optimization problem ? 
>
>
>   
What answer do you expect ?

Alexandra I think a little bit more information should be given to us
so that we can help you ...

Which version do you use?
What is your sample code which reproduces your results?

regards
Diethelm



-- 

PD Dr. Diethelm Wuertz
Institute for Theoretical Physics
Swiss Federal Institute of Technology

www.itp.phys.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From cdome at bk.ru  Fri May 16 15:35:17 2008
From: cdome at bk.ru (Andrey Riabushenko)
Date: Fri, 16 May 2008 16:35:17 +0300
Subject: [R-SIG-Finance] garchFit and garchSim
Message-ID: <200805161635.18555.cdome@bk.ru>

Hi !

I am trying to fit garch(1,1) model to stock returns using fGarch.

m = garchFit(~garch(1,1), data = returns)


But next I need to do 100 simulations of future returns. I am trying to use 
garchSim for that
I have extracted estimated alpha, beta and omega 
	params = model at fit$matcoef[,1]
	mu = params[1]
	omega = params[2]
	alpha = params[3]
	beta = params[4]

and i trying to do future simulation of returns 
	sim = mu + garchSim(list(alpha = alpha, beta = beta, omega = omega), 
resample=???)
	
I see that there is a resample parameter in garchSim function, but can't 
figure out how to use it, docs do not help.

Please help me, I am writing my MA theses and only one week is left till 
submission and my supervisor can't help with that.


P.S.
Also I have done similar thing, but using arima model. Please, check it if I 
am  doing everything right, because I  not sure about it.

forecast_arima = function (returns, n.ahead) {
    model = armaFit(~arma(10, 5), data=returns)
    c = coef(model)
    arma_mean = c["intercept"]
    arma_ar = c[1:10]
    arma_ma = c[11:15]

    m = matrix(NA, n.ahead, MAX_SIM)
						
    for(i in 1:MAX_SIM) {
	m[,i] = arma_mean + armaSim(list(ar = arma_ar, ma = arma_ma, d=0), n = 
n.ahead, start.innov = as.vector(returns))
    }
    return(m)
}


Thank you for you expertise.


From alexandra.nitescoux at sgcib.com  Fri May 16 15:40:41 2008
From: alexandra.nitescoux at sgcib.com (A.N.)
Date: Fri, 16 May 2008 06:40:41 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] fPortfolio  min CVaR
In-Reply-To: <482D358C.6020104@itp.phys.ethz.ch>
References: <17252498.post@talk.nabble.com> <482D358C.6020104@itp.phys.ethz.ch>
Message-ID: <17274998.post@talk.nabble.com>


I checked some papers on CVaR optimization from Professor Uryasev, and i was
wondering if his simple method of implementation was in the solver used in
fPortfolio. 
I'm using the version (270.73) of this package. 



Diethelm Wuertz wrote:
> 
> A.N. wrote:
>> I am testing the fPortfolio package by comparing in the optimization type
>> between mean variance and CVaR minimization and I don't find where the
>> CVaR
>> works in the solver code. 
>> By the way how the constraints in VaR and CVaR in the specifications are
>> computed in the optimization problem ? 
>>
>>
>>   
> What answer do you expect ?
> 
> Alexandra I think a little bit more information should be given to us
> so that we can help you ...
> 
> Which version do you use?
> What is your sample code which reproduces your results?
> 
> regards
> Diethelm
> 
> 
> 
> -- 
> 
> PD Dr. Diethelm Wuertz
> Institute for Theoretical Physics
> Swiss Federal Institute of Technology
> 
> www.itp.phys.ethz.ch
> www.rmetrics.org
> 
> NOTE:
> Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
> June 29th - July 3rd Meielisalp, Lake Thune, Switzerland
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
> 

-- 
View this message in context: http://www.nabble.com/fPortfolio--min-CVaR-tp17252498p17274998.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From mmiklovic at yahoo.com  Fri May 16 17:29:03 2008
From: mmiklovic at yahoo.com (michal miklovic)
Date: Fri, 16 May 2008 08:29:03 -0700 (PDT)
Subject: [R-SIG-Finance] garchFit and garchSim
Message-ID: <15237.25327.qm@web50108.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080516/90ef5004/attachment.pl>

From vlanschot at yahoo.com  Fri May 16 17:39:21 2008
From: vlanschot at yahoo.com (R@Nabble)
Date: Fri, 16 May 2008 08:39:21 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Example codes fPortfolio
	Package ?
In-Reply-To: <17249802.post@talk.nabble.com>
References: <17249802.post@talk.nabble.com>
Message-ID: <17277813.post@talk.nabble.com>


My previous questions below have been answered/are now clear. Still, a new
one has occurred: how can I make sure that 2 or more assets get the same
weights in the optimization?

Again, thx for any insights.

R at N

R at Nabble wrote:
> 
> Hello,
> 
> I was wondering whether there are more code-examples available for the
> above package. In particular, I'm interested in applications whereby:
> 
> 1) One can define per asset the minW, maxW constraints. 
> (I tried ConstrLO = c("minW[1]=10","minW[2]=10","maxW[3]=15"), but I guess
> my interpretation of "vector of character strings" as described in the
> manual for the input here is wrong).
> 2) In addition to 1, add sector constraints (i.e. does one simply add it,
> like ConstrLO = c("minW[1]=10","minW[2]=10","maxW[3]=15",
> "minsumW[1:2]=50") ???)
> 3) One can add the benchmark portfolio within the analysis, in particular
> as a "dot" within the efficient frontier graph.
> 4) Assuming leverage, how to show a move along the cap.mkt line?
> 
> Any help/suggestions much appreciated.
> 
> Thx,
> 
> R at N
> 

-- 
View this message in context: http://www.nabble.com/Example-codes-fPortfolio-Package---tp17249802p17277813.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From cdome at bk.ru  Sat May 17 09:26:40 2008
From: cdome at bk.ru (Andrey Riabushenko)
Date: Sat, 17 May 2008 10:26:40 +0300
Subject: [R-SIG-Finance] garchFit and garchSim
In-Reply-To: <15237.25327.qm@web50108.mail.re2.yahoo.com>
References: <15237.25327.qm@web50108.mail.re2.yahoo.com>
Message-ID: <200805171026.41575.cdome@bk.ru>

Yes, I meant presample indeed.

I see that it needs to be a thee column matrix, but I don't understand how to 
get this columns from the times series of the returns that I have.

> Hi,
>
> I guess you meant 'presample'. It is a matrix of starting values for the
> modeled series, h.t and innovations (with zero mean and unit variance).
> Have a look at the help page for garchSpec. I think the arma simulation is
> OK if n.ahead = 1. I would say it is possible to simulate an arma process
> with garchSim when you set the parameters of the conditional distribution
> to zero but I have never done it myself.
>
> Regards,
>
> Michal
>
>
>
>
> ----- Original Message ----
> From: Andrey Riabushenko <cdome at bk.ru>
> To: r-sig-finance at stat.math.ethz.ch
> Sent: Friday, May 16, 2008 3:35:17 PM
> Subject: [R-SIG-Finance] garchFit and garchSim
>
> Hi !
>
> I am trying to fit garch(1,1) model to stock returns using fGarch.
>
> m = garchFit(~garch(1,1), data = returns)
>
>
> But next I need to do 100 simulations of future returns. I am trying to use
> garchSim for that
> I have extracted estimated alpha, beta and omega
>     params = model at fit$matcoef[,1]
>     mu = params[1]
>     omega = params[2]
>     alpha = params[3]
>     beta = params[4]
>
> and i trying to do future simulation of returns
>     sim = mu + garchSim(list(alpha = alpha, beta = beta, omega = omega),
> resample=???)
>
> I see that there is a resample parameter in garchSim function, but can't
> figure out how to use it, docs do not help.
>
> Please help me, I am writing my MA theses and only one week is left till
> submission and my supervisor can't help with that.
>
>
> P.S.
> Also I have done similar thing, but using arima model. Please, check it if
> I am  doing everything right, because I  not sure about it.
>
> forecast_arima = function (returns, n.ahead) {
>     model = armaFit(~arma(10, 5), data=returns)
>     c = coef(model)
>     arma_mean = c["intercept"]
>     arma_ar = c[1:10]
>     arma_ma = c[11:15]
>
>     m = matrix(NA, n.ahead, MAX_SIM)
>
>     for(i in 1:MAX_SIM) {
>     m[,i] = arma_mean + armaSim(list(ar = arma_ar, ma = arma_ma, d=0), n =
> n.ahead, start.innov = as.vector(returns))
>     }
>     return(m)
> }
>
>
> Thank you for you expertise.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From cdome at bk.ru  Sat May 17 11:33:16 2008
From: cdome at bk.ru (Andrey Riabushenko)
Date: Sat, 17 May 2008 12:33:16 +0300
Subject: [R-SIG-Finance] garchFit and garchSim
In-Reply-To: <388892.42978.qm@web50109.mail.re2.yahoo.com>
References: <388892.42978.qm@web50109.mail.re2.yahoo.com>
Message-ID: <200805171233.18125.cdome@bk.ru>

Thanks a lot. I am making progress, but still some problems left
I am running

returns = as.vector(returns)
model = garchFit(~garch(1,1), data=returns)

params = model at fit$matcoef[,1]
mu = params[1]
omega = params[2]
alpha = params[3]
beta = params[4]

presample = cbind(returns, residuals(model, standardize =TRUE), model at h.t)

sim = mu + garchSim(list(alpha = alpha, beta = beta, omega = omega), 
n=n.ahead, n.start = length(returns), presample=presample)

But what I get is
head(sim) 
NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 

What it is wrong?


Also it is not clear why arima simulation is wrong  if n.ahead > 1, I need 
more than 1 for my study?

> The modeled series is readily available - in your case it is 'returns'. h.t
> can be obtained by m at h.t and starting values for the innovations, i.e. the
> standardised residuals, can be obtained by residuals(m, standardize =
> TRUE).
>
> Hope this helps.
>
> Michal
>
>
>
>


From mmiklovic at yahoo.com  Sat May 17 12:42:49 2008
From: mmiklovic at yahoo.com (michal miklovic)
Date: Sat, 17 May 2008 03:42:49 -0700 (PDT)
Subject: [R-SIG-Finance] garchFit and garchSim
Message-ID: <67493.1801.qm@web50101.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080517/22fdb919/attachment.pl>

From cdome at bk.ru  Sat May 17 14:32:10 2008
From: cdome at bk.ru (Andrey Riabushenko)
Date: Sat, 17 May 2008 15:32:10 +0300
Subject: [R-SIG-Finance] garchFit and garchSim
In-Reply-To: <67493.1801.qm@web50101.mail.re2.yahoo.com>
References: <67493.1801.qm@web50101.mail.re2.yahoo.com>
Message-ID: <200805171532.12186.cdome@bk.ru>

Thank you Michal Miklovic, it is working now

Here is a working code

forecast_garch = function(returns, n.ahead) {
	returns = as.vector(returns)

	model = garchFit(~garch(1,1), data=returns)
	params = model at fit$matcoef[,1]
	mu = params[1]
	omega = params[2]
	alpha = params[3]
	beta = params[4]

	presample = cbind(residuals(model, standardize =TRUE), model at h.t, returns)
	spec = garchSpec(list(mu = mu, alpha = alpha, beta = beta, omega = omega), 
presample=presample)

	m = matrix(NA, n.ahead, MAX_SIM)

	for(i in 1:MAX_SIM) {
		m[,i] = as.vector(garchSim(spec, n=n.ahead+1, n.start = 0))
	}
    return(m)
}


The small little thing is left. if n if equal to 10 the garchSim returns 
series of length 9. That is way I have placed n = a.ahead + 1. Is this a bug?


I am using R-2.6.1 built from sources with ATLAS on FreeBSD 7.0, the version 
of fGarch is 260.72 (also built from source)


Thank you once again.



? ????????? ?? Saturday 17 May 2008 13:42:49 ?? ????????:
> Hi,
>
> the correct order in presample is: innovations, h.t and returns. Next, I
> think it is necessary to first define a model by garchSpec and then use the
> definition to simulate it, have a look at the documentation. Btw, you can
> put 'mu' into the definition instead of adding it to the simulated series.
> I would set n.start = 0 in case of 'extending' an analysed series by
> simulation. n.start should be used when you simulate a series that is not
> 'appended' to another series. Concerning the arma simulation, I had another
> look at it and now I understand what you are doing and I think it is OK.
> Sorry for the confusion. Next time you post a question to mailing list,
> please indicate the version of R and packages you are using. It could be
> helpful because some packages get updated quite frequently.
>
> Regards,
>
> Michal
>
>
>
>
> ----- Original Message ----
> From: Andrey Riabushenko <cdome at bk.ru>
> To: michal miklovic <mmiklovic at yahoo.com>; r-sig-finance at stat.math.ethz.ch
> Sent: Saturday, May 17, 2008 11:33:16 AM
> Subject: Re: [R-SIG-Finance] garchFit and garchSim
>
> Thanks a lot. I am making progress, but still some problems left
> I am running
>
> returns = as.vector(returns)
> model = garchFit(~garch(1,1), data=returns)
>
> params = model at fit$matcoef[,1]
> mu = params[1]
> omega = params[2]
> alpha = params[3]
> beta = params[4]
>
> presample = cbind(returns, residuals(model, standardize =TRUE), model at h.t)
>
> sim = mu + garchSim(list(alpha = alpha, beta = beta, omega = omega),
> n=n.ahead, n.start = length(returns), presample=presample)
>
> But what I get is
> head(sim)
> NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
>
> What it is wrong?
>
>
> Also it is not clear why arima simulation is wrong  if n.ahead > 1, I need
> more than 1 for my study?
>
> > The modeled series is readily available - in your case it is 'returns'.
> > h.t can be obtained by m at h.t and starting values for the innovations,
> > i.e. the standardised residuals, can be obtained by residuals(m,
> > standardize = TRUE).
> >
> > Hope this helps.
> >
> > Michal


From mmiklovic at yahoo.com  Sat May 17 15:52:10 2008
From: mmiklovic at yahoo.com (michal miklovic)
Date: Sat, 17 May 2008 06:52:10 -0700 (PDT)
Subject: [R-SIG-Finance] garchFit and garchSim
Message-ID: <274489.86221.qm@web50112.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080517/37713b98/attachment.pl>

From brian at braverock.com  Wed May 21 12:41:59 2008
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 21 May 2008 05:41:59 -0500
Subject: [R-SIG-Finance] Thinking about Risk Budgeting and Portfolio
	Construction
Message-ID: <4833FC77.6040000@braverock.com>

We're getting ready to start a journal article/paper on risk budgeting 
and portfolio construction utilizing component risk metrics.  I'd like 
some input from the r-sig-finance community on what types of questions 
in this space you feel are under-served in the literature.

Specifically, we plan to examine how utilizing the sub-additive risks of 
each component of the portfolio (and optimizing the portfolio based on 
these) differs in out-of-sample performance from traditional risk 
budgeting methods which simply pick the target variance portfolio on the 
efficient frontier.

So, I'd like *your* input.  What questions do you have about risk 
budgeting portfolio construction methods?  What areas are poorly covered 
in the literature?  Are there any papers or references that you think we 
should read before starting out?

Thanks!

Regards,

    - Brian


From burkett at uri.edu  Fri May 23 04:32:01 2008
From: burkett at uri.edu (John P. Burkett)
Date: Thu, 22 May 2008 22:32:01 -0400
Subject: [R-SIG-Finance] fImport, yahooSeries, aggregation
Message-ID: <48362CA1.5070902@uri.edu>

In R version 2.6.1 running under Gentoo Linux, the commands
library(fImport)
yahooSeries("^FTSE", from = "2006-01-01", "2007-12-31", quote = "Close", 
aggregation = "m")
select the first business day of each month.  I would prefer to select 
the last business day of each month.  Suggestions about how to do so 
would be much appreciated.

-- 
John P. Burkett
Department of Environmental and Natural Resource Economics
and Department of Economics
University of Rhode Island
Kingston, RI 02881-0808
USA

phone (401) 874-9195


From jeff.a.ryan at gmail.com  Fri May 23 04:54:30 2008
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Thu, 22 May 2008 21:54:30 -0500
Subject: [R-SIG-Finance] fImport, yahooSeries, aggregation
In-Reply-To: <48362CA1.5070902@uri.edu>
References: <48362CA1.5070902@uri.edu>
Message-ID: <e8e755250805221954k78f367f6wb8e41ca9b7fb2513@mail.gmail.com>

Not using Rmetrics, but quantmod (and xts):

library(quantmod)
getSymbols("^FTSE",from="2006-01-01", to="2007-12-31")
to.monthly(FTSE, indexAt='lastof')
           FTSE.Open FTSE.High FTSE.Low FTSE.Close FTSE.Volume FTSE.Adjusted
2006-01-31    5618.8    5796.1   5618.8     5760.3 39158470800        5760.3
2006-02-28    5760.3    5893.3   5681.9     5791.5 37360441800        5791.5
2006-03-31    5791.5    6047.0   5783.9     5964.6 44156358400        5964.6
2006-04-30    5964.6    6137.1   5964.6     6023.1 30775737400        6023.1
2006-05-31    6023.1    6133.5   5510.5     5723.8 40051488800        5723.8
2006-06-30    5723.8    5865.7   5467.4     5833.4 36016490600        5833.4
2006-07-31    5833.4    5982.5   5654.6     5928.3 28208522700        5928.3
2006-08-31    5928.3    5949.8   5752.6     5906.1 29781298600        5906.1
2006-09-30    5906.1    6002.9   5774.5     5960.8 31844286400        5960.8
2006-10-31    5960.8    6244.6   5897.3     6129.2 34756902700        6129.2
2006-11-30    6129.2    6256.8   6011.8     6048.8 35409311600        6048.8
2006-12-31    6048.8    6271.4   5985.2     6220.8 25404342600        6220.8
2007-01-31    6220.8    6335.1   6130.2     6203.1 36903881300        6203.1
2007-02-28    6203.1    6451.4   6166.2     6171.5 33113524500        6171.5
2007-03-31    6171.5    6355.3   5989.6     6308.0 40662588400        6308.0
2007-04-30    6308.0    6516.2   6293.9     6449.2 31552434700        6449.2
2007-05-31    6449.2    6675.0   6395.5     6621.4 40045491500        6621.4
2007-06-30    6621.4    6751.3   6451.4     6607.9 39617754000        6607.9
2007-07-31    6607.9    6754.1   6186.2     6360.1 38493756200        6360.1
2007-08-31    6360.1    6406.3   5821.7     6303.3 38476546500        6303.3
2007-09-30    6303.3    6512.4   6123.1     6466.8 35732251000        6466.8
2007-10-31    6466.8    6751.7   6413.4     6721.6 41485100800        6721.6
2007-11-30    6721.6    6723.7   6026.9     6432.5 32531965100        6432.5
2007-12-31    6432.5    6610.9   6251.8     6456.9 19632325600        6456.9

getSymbols by default will load the data into a symbol FTSE
(automatically stripping the ^ from the Yahoo name)

to.monthly will by default index the series by 'yearmon'.  The indexAt
arg will align the series to
the 'lastof' the calendar period, the 'firstof' the period, the
'startof' the data in the period (the first tie seen) or the 'endof'
the data...

To get just the Close, you can wrap the whole thing in 'Cl'

Cl(to.monthly(FTSE,indexAt='lastof'))

           FTSE.Close
2006-01-31     5760.3
2006-02-28     5791.5
2006-03-31     5964.6
2006-04-30     6023.1
2006-05-31     5723.8
2006-06-30     5833.4
2006-07-31     5928.3
2006-08-31     5906.1
2006-09-30     5960.8
2006-10-31     6129.2
2006-11-30     6048.8
2006-12-31     6220.8
2007-01-31     6203.1
2007-02-28     6171.5
2007-03-31     6308.0
2007-04-30     6449.2
2007-05-31     6621.4
2007-06-30     6607.9
2007-07-31     6360.1
2007-08-31     6303.3
2007-09-30     6466.8
2007-10-31     6721.6
2007-11-30     6432.5
2007-12-31     6456.9

More info about quantmod can be found at http://www.quantmod.com ...
which is expecting an update any day now :)

Jeff
Jeff

On Thu, May 22, 2008 at 9:32 PM, John P. Burkett <burkett at uri.edu> wrote:
> In R version 2.6.1 running under Gentoo Linux, the commands
> library(fImport)
> yahooSeries("^FTSE", from = "2006-01-01", "2007-12-31", quote = "Close",
> aggregation = "m")
> select the first business day of each month.  I would prefer to select the
> last business day of each month.  Suggestions about how to do so would be
> much appreciated.
>
> --
> John P. Burkett
> Department of Environmental and Natural Resource Economics
> and Department of Economics
> University of Rhode Island
> Kingston, RI 02881-0808
> USA
>
> phone (401) 874-9195
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
There's a way to do it better - find it.
Thomas A. Edison


From noldo22 at gmail.com  Fri May 23 19:52:23 2008
From: noldo22 at gmail.com (Renato Costa)
Date: Fri, 23 May 2008 14:52:23 -0300
Subject: [R-SIG-Finance] GARCH-like models
Message-ID: <53d3e3c70805231052r60ab3a31s615c485adb6548bd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080523/d3249725/attachment.pl>

From mmiklovic at yahoo.com  Sat May 24 11:12:35 2008
From: mmiklovic at yahoo.com (michal miklovic)
Date: Sat, 24 May 2008 02:12:35 -0700 (PDT)
Subject: [R-SIG-Finance] GARCH-like models
Message-ID: <704049.83147.qm@web50104.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080524/d84fa45f/attachment.pl>

From vlanschot at yahoo.com  Tue May 27 13:15:15 2008
From: vlanschot at yahoo.com (R@Nabble)
Date: Tue, 27 May 2008 04:15:15 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Flexible inputs fPortfolio possible?
Message-ID: <17488047.post@talk.nabble.com>


Hi,

Is it possible yet to allow pre-specified mean-return and/or covar-matrices
in fPortfolio? If so, where can I find instructions to achieve this? I
remember reading somewhere that this would eventually become available.

Thx,

R at N
-- 
View this message in context: http://www.nabble.com/Flexible-inputs-fPortfolio-possible--tp17488047p17488047.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From chalabi at phys.ethz.ch  Tue May 27 18:01:43 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Tue, 27 May 2008 18:01:43 +0200
Subject: [R-SIG-Finance] [R-sig-finance] Flexible inputs fPortfolio
 possible?
In-Reply-To: <17488047.post@talk.nabble.com>
References: <17488047.post@talk.nabble.com>
Message-ID: <20080527180143.3ba18b70@mimi>

>>>> "R" == "R at Nabble" <vlanschot at yahoo.com>
>>>> on Tue, 27 May 2008 04:15:15 -0700 (PDT)


   R> Hi,
   R> 
   R> Is it possible yet to allow pre-specified mean-return and/or
   R> covar-matrices
   R> in fPortfolio? If so, where can I find instructions to
   R> achieve this? I
   R> remember reading somewhere that this would eventually become
   R> available.
   R> 
   R> Thx,
   R> 
   R> R at N

Do you want to define your own estimators of the covariance matrix?

You can do it with the dev-version of fPortfolio available at r-forge.

a quick example :

##################
library(fPortfolio)
# only with development version of fPortfolio available on R-Forge

# now you can define your own estimator which must returns a list with a
# named list, with at least the following two entries '\$mu' and
# '\$Sigma', which represent estimators for the mean and covariance,
# respectively.
myEstimator <- 
    function(x, spec = NULL, ...) list(mu = colMeans(x), Sigma = cov(x))

Spec <- portfolioSpec() # default portfolio specification  
setEstimator(Spec) <- "myEstimator" # new estimator
Spec

# Load Data and Convert to timeSeries Object:
Data = as.timeSeries(data(smallcap.ts))
Data = Data[, c("BKE", "GG", "GYMB", "KRON")]
Data

## Compute properties of Efficient Portfolio
frontier <- portfolioFrontier(Data, Spec, "LongOnly")
plot(frontier)

####################

hope this helps,
Yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From linuxpower at hotmail.fr  Wed May 28 19:06:14 2008
From: linuxpower at hotmail.fr (Linuxpower Ludo)
Date: Wed, 28 May 2008 19:06:14 +0200
Subject: [R-SIG-Finance] R-project can help me ? Building a portfolio..
In-Reply-To: <mailman.3.1211968801.31354.r-sig-finance@stat.math.ethz.ch>
References: <mailman.3.1211968801.31354.r-sig-finance@stat.math.ethz.ch>
Message-ID: <BAY116-W47BEA6C62D13EA2CDF8984A3BC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080528/86313cb1/attachment.pl>

From vlanschot at yahoo.com  Thu May 29 09:20:18 2008
From: vlanschot at yahoo.com (R@Nabble)
Date: Thu, 29 May 2008 00:20:18 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] Flexible inputs fPortfolio
	possible?
In-Reply-To: <20080527180143.3ba18b70@mimi>
References: <17488047.post@talk.nabble.com> <20080527180143.3ba18b70@mimi>
Message-ID: <17529091.post@talk.nabble.com>


Following your advice,  I did the following:
 
PropEstimates<-function(x,Estmu=colMeans(x),Covar=cov(x)) list(mu=Estmu,
Sigma=Covar)
####### Efficient Frontier
Data <- as.timeSeries(MatR)
NAss=ncol(Data)
NAss
SpecDef <- portfolioSpec()
Rfree = 0.04/12 
setRiskFreeRate(SpecDef)<- Rfree
TotUni<-PropEstimates(Data,colMeans(Data),cov(Data))
TotUni 
This code results in the following (what looks like correct) results:
 
> TotUni
$mu
      . . . . 
$Sigma
      . . . .
 
However, if I then input this as follows:
 
setEstimator(SpecDef)<-TotUni
ConstrLO = "LongOnly"
frontierLO = portfolioFrontier(Data, SpecDef, ConstrLO)
 
I get the following error:
 
ERROR:  
  c("'structure(list(mu = structure(c(0.0025, 0.00369565217391304, ' is not
a function, character or symbol", "'0.00271739130434783,
0.00347826086956522, 0.00858695652173913, ' is not a function, character or
symbol", "'0.00119565217391304, 0.00141304347826087, -0.00282608695652174, '
is not a function, character or symbol", "'0.0101086956521739,
0.00315217391304348, 0.0197826086956522, ' is not a function, character or
symbol", "'0.0141304347826087), .Names = c(\"FTSE.All.Share\",
\"FTSE.All.Stock.Gilts\", ' is not a function, character or symbol", 

Trying to correct it by literally applying your code, and using:

PropEstimates<-function(x, spec = NULL, ...) list(mu = colMeans(x), Sigma =
cov(x))
TotUni<-PropEstimates(Data,colMeans(Data),cov(Data))
setEstimator(SpecDef)<-"TotUni" 

I get this error:
 
ERROR:  
  variable "TotUni" of mode "function" was not found

In fact, even the "old" way of doing things, for example by leaving out any
setEstimator, results in:
 
ERROR:  
  variable "covEstimator" of mode "function" was not found
 
Is this because I'm still using 2.6.2 ???

Thx for any further insights/guidance,
 
R at N




Yohan Chalabi wrote:
> 
>>>>> "R" == "R at Nabble" <vlanschot at yahoo.com>
>>>>> on Tue, 27 May 2008 04:15:15 -0700 (PDT)
> 
> 
>    R> Hi,
>    R> 
>    R> Is it possible yet to allow pre-specified mean-return and/or
>    R> covar-matrices
>    R> in fPortfolio? If so, where can I find instructions to
>    R> achieve this? I
>    R> remember reading somewhere that this would eventually become
>    R> available.
>    R> 
>    R> Thx,
>    R> 
>    R> R at N
> 
> Do you want to define your own estimators of the covariance matrix?
> 
> You can do it with the dev-version of fPortfolio available at r-forge.
> 
> a quick example :
> 
> ##################
> library(fPortfolio)
> # only with development version of fPortfolio available on R-Forge
> 
> # now you can define your own estimator which must returns a list with a
> # named list, with at least the following two entries '\$mu' and
> # '\$Sigma', which represent estimators for the mean and covariance,
> # respectively.
> myEstimator <- 
>     function(x, spec = NULL, ...) list(mu = colMeans(x), Sigma = cov(x))
> 
> Spec <- portfolioSpec() # default portfolio specification  
> setEstimator(Spec) <- "myEstimator" # new estimator
> Spec
> 
> # Load Data and Convert to timeSeries Object:
> Data = as.timeSeries(data(smallcap.ts))
> Data = Data[, c("BKE", "GG", "GYMB", "KRON")]
> Data
> 
> ## Compute properties of Efficient Portfolio
> frontier <- portfolioFrontier(Data, Spec, "LongOnly")
> plot(frontier)
> 
> ####################
> 
> hope this helps,
> Yohan
> 
> -- 
> PhD student
> Swiss Federal Institute of Technology
> Zurich
> 
> www.ethz.ch
> www.rmetrics.org
> 
> NOTE:
> Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
> June 29th - July 3rd Meielisalp, Lake Thune, Switzerland
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
> 

-- 
View this message in context: http://www.nabble.com/Flexible-inputs-fPortfolio-possible--tp17488047p17529091.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From chalabi at phys.ethz.ch  Thu May 29 09:20:43 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Thu, 29 May 2008 09:20:43 +0200
Subject: [R-SIG-Finance] R-project can help me ? Building a portfolio..
In-Reply-To: <BAY116-W47BEA6C62D13EA2CDF8984A3BC0@phx.gbl>
References: <mailman.3.1211968801.31354.r-sig-finance@stat.math.ethz.ch>
	<BAY116-W47BEA6C62D13EA2CDF8984A3BC0@phx.gbl>
Message-ID: <20080529092043.25666a23@mimi>

>>>> "LL" == Linuxpower Ludo <linuxpower at hotmail.fr>
>>>> on Wed, 28 May 2008 19:06:14 +0200


   LL> Hi all,I am beginner and i need advices :)I expose you my
   LL> problematic.I want use R-project software for my selection
   LL> and weight of my systems.That is to say that I have several
   LL> systems trading on the Forex with UT and various symbols. My
   LL> pool of system is about >> 60 << systems available.My goal in
   LL> r-project is to build over these 60 systems, a Long & short
   LL> portfolio of 30 systems "only" and refresh or reoptimize
   LL> weekly or monthly period.I do not really know how to go
   LL> about it to find the 30 best systems for my portfolio.I
   LL> intend to recover the daily return as a percentage of each
   LL> system and store the result in a mysql database. (That works
   LL> correctly)The problem that I am a little lost now..At  the
   LL> moment i read a lot of stuff on the subject .. Efficient
   LL> frontier, MV portfolio etc etc but for putting into practice
   LL> is another thing :(
   LL> Can you help me to put into practice with examples of script
   LL> that you can use in selecting your portfolio ?
   LL> I think used fportfolio package. This package can do that?
   LL> 
   LL> Best Regads.


You can find many examples in fPortfolio package in its directory
unitTests.

regards,
Yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From chalabi at phys.ethz.ch  Thu May 29 11:02:58 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Thu, 29 May 2008 11:02:58 +0200
Subject: [R-SIG-Finance] [R-sig-finance] Flexible inputs fPortfolio
 possible?
In-Reply-To: <17529091.post@talk.nabble.com>
References: <17488047.post@talk.nabble.com> <20080527180143.3ba18b70@mimi>
	<17529091.post@talk.nabble.com>
Message-ID: <20080529110258.14da56b6@mimi>

>>>> "R" == "R at Nabble" <vlanschot at yahoo.com>
>>>> on Thu, 29 May 2008 00:20:18 -0700 (PDT)


   R> Following your advice,  I did the following:
   R> 
   R> PropEstimates<-function(x,Estmu=colMeans(x),Covar=cov(x))
   R> list(mu=Estmu,
   R> Sigma=Covar)
   R> ####### Efficient Frontier
   R> Data <- as.timeSeries(MatR)
   R> NAss=ncol(Data)
   R> NAss
   R> SpecDef <- portfolioSpec()
   R> Rfree = 0.04/12
   R> setRiskFreeRate(SpecDef)<- Rfree
   R> TotUni<-PropEstimates(Data,colMeans(Data),cov(Data))
   R> TotUni
   R> This code results in the following (what looks like correct)
   R> results:

how do you expect this code to work?? I did not recommend you to do
that!

you should specify the name of your estimator function with
"setEstimator<-".

this means, 

setEstimator(SpecDef) <- "PropEstimates" 

in your example.

Please use the code I already posted with the
*dev-version* of fPortfolio available at *R-forge*.

Yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From apsc.martins at gmail.com  Thu May 29 21:36:25 2008
From: apsc.martins at gmail.com (Ana Patricia Martins)
Date: Thu, 29 May 2008 20:36:25 +0100
Subject: [R-SIG-Finance] HJM model (Interest rate)
Message-ID: <4f37d3da0805291236x12cd4523qe16bd56ab6fd84e8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080529/890baeda/attachment.pl>

From markleeds at verizon.net  Thu May 29 21:47:21 2008
From: markleeds at verizon.net (markleeds at verizon.net)
Date: Thu, 29 May 2008 14:47:21 -0500 (CDT)
Subject: [R-SIG-Finance] HJM model (Interest rate)
Message-ID: <20718124.5884961212090442023.JavaMail.javamailuser@localhost>

I don't own the book so I can't say anything about it's quality but it ( 
see link below ) must point to packages involving such things ?
also, there is a package listing at www.r-project.org that may describe 
such a package ? or even do an R archive search for Stefan Iacus,
the author of the book.

 
http://www.amazon.com/Simulation-Inference-Stochastic-Differential-Equations/dp/0387758380/ref=sr_1_3?ie=UTF8&s=books&qid=1212090213&sr=8-3


On Thu, May 29, 2008 at  3:36 PM, Ana Patricia Martins wrote:

> **
>
> Dears users,
>
> Although my basic training is in statistics, I've little knowledge 
> about
> interest rates models, and it was suggested Cox-Ingersoll-Ross 
> process,
> Ornstein-Uhlenbeck or Vasicek process or Heath-Jarrow-Morton methods.
>
> Does anyone know if exist HJM model in R? I can't find?
>
> The CIR model was considered, however based on the observed data 
> (1998-2007)
> doesn't works.
> Does anyone can suggest a package or other models?
>
> Thanks in advance your help.
> Best regards
> Ana Patr?cia
>
> 	[[alternative HTML version deleted]]
>
>
>
>      ------------------------------
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From dsmith at viciscapital.com  Thu May 29 22:24:49 2008
From: dsmith at viciscapital.com (Dale Smith)
Date: Thu, 29 May 2008 16:24:49 -0400
Subject: [R-SIG-Finance] HJM model (Interest rate)
In-Reply-To: <20718124.5884961212090442023.JavaMail.javamailuser@localhost>
References: <20718124.5884961212090442023.JavaMail.javamailuser@localhost>
Message-ID: <0E4F0C7EEAAB274F8DC6B1543949F05B01DC9C30@vicsrv4.viciscapital.com>

I would say look at the Hull-White model. They even wrote a paper outlining how to implement their model, a rarity for academics. Just go to John Hull or Alan White's web page and look for the paper, or Google for it.

Christopher Finger's group at Riskmetrics recommended using this model in the MBS space. Register at the Riskmetrics web site & look for the article in 2004 or 2005.

HJM can be difficult to calibrate.

Dale Smith, Ph.D.
Vicis Capital LLC
Voice: 212-909-4635
Email: dsmith at viciscapital.com
AIM: dsmith11701

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of markleeds at verizon.net
Sent: Thursday, May 29, 2008 3:47 PM
To: Ana Patricia Martins
Cc: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] HJM model (Interest rate)

I don't own the book so I can't say anything about it's quality but it ( 
see link below ) must point to packages involving such things ?
also, there is a package listing at www.r-project.org that may describe 
such a package ? or even do an R archive search for Stefan Iacus,
the author of the book.

 
http://www.amazon.com/Simulation-Inference-Stochastic-Differential-Equations/dp/0387758380/ref=sr_1_3?ie=UTF8&s=books&qid=1212090213&sr=8-3


On Thu, May 29, 2008 at  3:36 PM, Ana Patricia Martins wrote:

> **
>
> Dears users,
>
> Although my basic training is in statistics, I've little knowledge 
> about
> interest rates models, and it was suggested Cox-Ingersoll-Ross 
> process,
> Ornstein-Uhlenbeck or Vasicek process or Heath-Jarrow-Morton methods.
>
> Does anyone know if exist HJM model in R? I can't find?
>
> The CIR model was considered, however based on the observed data 
> (1998-2007)
> doesn't works.
> Does anyone can suggest a package or other models?
>
> Thanks in advance your help.
> Best regards
> Ana Patr?cia
>
> 	[[alternative HTML version deleted]]
>
>
>
>      ------------------------------
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.

All e-mail sent to or from this address will be received or otherwise recorded by Vicis Capital, LLC and is subject to archival, monitoring and/or review, by and/or disclosure to, someone other than the recipient.  This message is intended only for the use of the person(s) ("intended recipient") to whom it is addressed.  It may contain information that is privileged and confidential.  If you are not the intended recipient, please contact the sender as soon as possible and delete the message without reading it or making a copy.  Any dissemination, distribution, copying, or other use of this message or any of its content by any person other than the intended recipient is strictly prohibited.  Vicis Capital, LLC only transacts business in states where it is properly registered or notice filed, or excluded or exempted from registration or notice filing requirements.

From daniel.wolff at gmail.com  Sun Jun  1 16:16:50 2008
From: daniel.wolff at gmail.com (Daniel Wolff)
Date: Sun, 1 Jun 2008 22:16:50 +0800
Subject: [R-SIG-Finance] fCalendar's time seems incorrect for some FinCenters
Message-ID: <4842af5c.0fba720a.4d33.fffff6cb@mx.google.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080601/dbf2bcbf/attachment.pl>

From handel at iinet.net.au  Mon Jun  2 07:18:15 2008
From: handel at iinet.net.au (Ross Bowden)
Date: Mon, 02 Jun 2008 13:18:15 +0800
Subject: [R-SIG-Finance] Fitting jump diffusion processes with Normal errors
Message-ID: <48438297.2020105@iinet.net.au>

Hello everyone. Apologies for cross posting with R-help and for a possible relationship with the thread "Bayesian estimation of jump-diffusion processes and self-exciting counting processes".

I have an interest in fitting jump diffusion AR(p) processes (which will likely form part of a Garch model with Normal errors). Does anyone know of some R code that will allow this please, hopefully using max likelihood (or similar) methods?

I'm currently using WinBUGS and RWinBUGS to utilise a Bayesian approach but my dataset is quite large (n=17,000 being half-hourly electricity prices for a year) and, not surprisingly, the routines have issues with execution time and program stability.

Many thanks,
Ross Bowden,
Synergy Energy,
Perth, Western Australia.


From enricoschumann at yahoo.de  Mon Jun  2 09:43:29 2008
From: enricoschumann at yahoo.de (Enrico Schumann)
Date: Mon, 2 Jun 2008 09:43:29 +0200
Subject: [R-SIG-Finance] fCalendar's time seems incorrect for some
	FinCenters
In-Reply-To: <4842af5c.0fba720a.4d33.fffff6cb@mx.google.com>
Message-ID: <129060.53339.bm@omp105.mail.mud.yahoo.com>

i am not an expert in time/date issues, but reading your post and looking a
bit on the web got me interested. the offsets (in seconds) seem to be
defined in the respective financial centre function, eg 

require(fCalendar)
Singapore

where the latest offset should be 27000 sec = 7.5 hours. 

according to http://www.math.nus.edu.sg/aslaksen/teaching/timezone.html the
offset is now 8 hours (28800sec) which seems not to have been in the
tzdata-base used for fCalendar. but again, i am not an expert, maybe there
is a reason for that...


best,enrico 

-----Urspr?ngliche Nachricht-----
Von: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] Im Auftrag von Daniel Wolff
Gesendet: Sonntag, 1. Juni 2008 16:17
An: R-SIG-Finance at stat.math.ethz.ch
Betreff: [R-SIG-Finance] fCalendar's time seems incorrect for some
FinCenters

Hello, 

having some trouble getting Sys.timeDate(x) to return the correct time for
some FinCenters. 

Here is a demonstration:

 

> require(fCalendar)

> x <- 
> c("HongKong","Singapore","Seoul","Tokyo","Sydney","London","NewYork")

> lapply(x,Sys.timeDate)

[[1]]

HongKong

[1] [2008-06-01 23:12:08]

 

[[2]]

Singapore

[1] [2008-06-01 21:42:08]

 

[[3]]

Seoul

[1] [2008-06-02 00:12:08]

 

[[4]]

Tokyo

[1] [2008-06-02 00:12:08]

 

[[5]]

Sydney

[1] [2008-06-02 00:12:08]

 

[[6]]

London

[1] [2008-06-01 15:12:08]

 

[[7]]

NewYork

[1] [2008-06-01 10:12:08]

 

> 

New York is correct

London is correct

Sydney is correct

but

Tokyo off by +1hr

Singapore is off by -0.5hr

Hong Kong is off by +1hr

Seoul is off by +1hr

 

Any tips on how to correct? 

 

Thank you


	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.
No virus found in this incoming message.
Checked by AVG. 

31.05.2008
12:25


From chalabi at phys.ethz.ch  Mon Jun  2 10:27:49 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Mon, 2 Jun 2008 10:27:49 +0200
Subject: [R-SIG-Finance] fCalendar's time seems incorrect for some
 FinCenters
In-Reply-To: <4842af5c.0fba720a.4d33.fffff6cb@mx.google.com>
References: <4842af5c.0fba720a.4d33.fffff6cb@mx.google.com>
Message-ID: <20080602102749.459082e4@mimi>

>>>> "DW" == "Daniel Wolff" <daniel.wolff at gmail.com>
>>>> on Sun, 1 Jun 2008 22:16:50 +0800


   DW> Hello,
   DW> 
   DW> having some trouble getting Sys.timeDate(x) to return the
   DW> correct time for
   DW> some FinCenters.
   DW> 
   DW> Here is a demonstration:


Hi Daniel,

Thanks for the report. 

There was a problem in the function which generates the DST rules. The
last entry ways dropped. 

I fixed it and I will upload to CRAN a new version ASAP.

regards,
Yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From feanor0 at hotmail.com  Mon Jun  2 13:57:03 2008
From: feanor0 at hotmail.com (Murali Menon)
Date: Mon, 2 Jun 2008 11:57:03 +0000
Subject: [R-SIG-Finance] apply.fromstart() warnings
Message-ID: <BLU105-W249C4E4EC70E6042ECA709EEBB0@phx.gbl>



Folks,

When I attempt to find the growing window columnwise mean of a two-dimensional array, I get a bunch of warnings. Any idea why? Here's my code:

> library(PerformanceAnalytics)

> d <- zoo(matrix(rnorm(50), ncol=2), order.by=as.Date(1:25))

> apply.fromstart(d, gap=20, FUN="mean")
1970-01-02          NA          NA
1970-01-03          NA          NA
1970-01-04          NA          NA
1970-01-05          NA          NA
1970-01-06          NA          NA
1970-01-07          NA          NA
1970-01-08          NA          NA
1970-01-09          NA          NA
1970-01-10          NA          NA
1970-01-11          NA          NA
1970-01-12          NA          NA
1970-01-13          NA          NA
1970-01-14          NA          NA
1970-01-15          NA          NA
1970-01-16          NA          NA
1970-01-17          NA          NA
1970-01-18          NA          NA
1970-01-19          NA          NA
1970-01-20          NA          NA
1970-01-21 -0.05899970 -0.05899970
1970-01-22 -0.05882669 -0.05882669
1970-01-23 -0.08635806 -0.08635806
1970-01-24 -0.15848480 -0.15848480
1970-01-25 -0.13168358 -0.13168358
1970-01-26 -0.17101046 -0.17101046
There were 12 warnings (use warnings() to see them)


When I check the warnings(), here's the first string I get:

1: In column.Return.calc[i] = apply(as.matrix(data.zoo[,  ... :
  number of items to replace is not a multiple of replacement length

I'm not sure why this should be the case?


I'm using:

> packageDescription("zoo")$Version
[1] "1.4-2"
> packageDescription("PerformanceAnalytics")$Version
[1] "0.9.6"


And R 2.6.1 on Windows XP.


Thanks,


Murali

_________________________________________________________________
Give to a good cause with every e-mail. Join the i?m Initiative from Microsoft.


From ggrothendieck at gmail.com  Mon Jun  2 14:27:56 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 2 Jun 2008 08:27:56 -0400
Subject: [R-SIG-Finance] apply.fromstart() warnings
In-Reply-To: <BLU105-W249C4E4EC70E6042ECA709EEBB0@phx.gbl>
References: <BLU105-W249C4E4EC70E6042ECA709EEBB0@phx.gbl>
Message-ID: <971536df0806020527s6028918bh3bf04ebf774eadba@mail.gmail.com>

To do it in zoo alone try this:

library(zoo)
d <- zoo(matrix(1:50, 25), as.Date(1:25))

dd <- NA * d
for(i in 21:nrow(dd)) dd[i, ] <- colMeans(d[1:i, ])

You also might try updating the to latest version of all packages and R
although that does not appear to be the source of the problem here.

On Mon, Jun 2, 2008 at 7:57 AM, Murali Menon <feanor0 at hotmail.com> wrote:
>
>
> Folks,
>
> When I attempt to find the growing window columnwise mean of a two-dimensional array, I get a bunch of warnings. Any idea why? Here's my code:
>
>> library(PerformanceAnalytics)
>
>> d <- zoo(matrix(rnorm(50), ncol=2), order.by=as.Date(1:25))
>
>> apply.fromstart(d, gap=20, FUN="mean")
> 1970-01-02          NA          NA
> 1970-01-03          NA          NA
> 1970-01-04          NA          NA
> 1970-01-05          NA          NA
> 1970-01-06          NA          NA
> 1970-01-07          NA          NA
> 1970-01-08          NA          NA
> 1970-01-09          NA          NA
> 1970-01-10          NA          NA
> 1970-01-11          NA          NA
> 1970-01-12          NA          NA
> 1970-01-13          NA          NA
> 1970-01-14          NA          NA
> 1970-01-15          NA          NA
> 1970-01-16          NA          NA
> 1970-01-17          NA          NA
> 1970-01-18          NA          NA
> 1970-01-19          NA          NA
> 1970-01-20          NA          NA
> 1970-01-21 -0.05899970 -0.05899970
> 1970-01-22 -0.05882669 -0.05882669
> 1970-01-23 -0.08635806 -0.08635806
> 1970-01-24 -0.15848480 -0.15848480
> 1970-01-25 -0.13168358 -0.13168358
> 1970-01-26 -0.17101046 -0.17101046
> There were 12 warnings (use warnings() to see them)
>
>
> When I check the warnings(), here's the first string I get:
>
> 1: In column.Return.calc[i] = apply(as.matrix(data.zoo[,  ... :
>  number of items to replace is not a multiple of replacement length
>
> I'm not sure why this should be the case?
>
>
> I'm using:
>
>> packageDescription("zoo")$Version
> [1] "1.4-2"
>> packageDescription("PerformanceAnalytics")$Version
> [1] "0.9.6"
>
>
> And R 2.6.1 on Windows XP.
>
>
> Thanks,
>
>
> Murali
>
> _________________________________________________________________
> Give to a good cause with every e-mail. Join the i'm Initiative from Microsoft.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From eowiesny at allstontrading.com  Mon Jun  2 14:51:06 2008
From: eowiesny at allstontrading.com (Eric Owiesny)
Date: Mon, 02 Jun 2008 07:51:06 -0500
Subject: [R-SIG-Finance] RBloomberg
Message-ID: <4843ECBA.6090506@allstontrading.com>

Hi,

I've been having some trouble with having the connection to Bloomberg 
fail after a while.  I've been using RBloomberg and wrote a simple 
function that downloads intraday data to write it to a file.  This works 
fine for a while, but will periodically give me an error saying:

Error in substr(text, first, last) : invalid Substring argument(s)

If I restart the function, it will work again.  I was wondering if 
anyone else had this problem or knew what was going on.

Thanks,
Eric Owiesny

------------------------------------------------------------------------------------------
This message is for the named person(s) use only. It may contain confidential proprietary or legally privileged information. No confidentiality or privilege is waived or lost by any mistransmission. If you receive this message in error, please immediately delete it and all copies of it from your system, destroy any hard copies of it and notify the sender. You must not, directly or indirectly use, disclose, distribute, print, or copy any part of this message if you are not the intended recipient. Allston Trading LLC and its subsidiaries and affiliates each reserve the right to monitor all e-mail communications through its networks. Any views expressed in this message are those of the individual sender, except where the message states otherwise and the sender is authorized to state them to be the views of any such entity.


From feanor0 at hotmail.com  Mon Jun  2 15:26:39 2008
From: feanor0 at hotmail.com (Murali Menon)
Date: Mon, 2 Jun 2008 13:26:39 +0000
Subject: [R-SIG-Finance] apply.fromstart() warnings
In-Reply-To: <971536df0806020527s6028918bh3bf04ebf774eadba@mail.gmail.com>
References: <BLU105-W249C4E4EC70E6042ECA709EEBB0@phx.gbl>
	<971536df0806020527s6028918bh3bf04ebf774eadba@mail.gmail.com>
Message-ID: <BLU105-W230B74166CA0FF70FED3D7EEBB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080602/c716e33f/attachment.pl>

From ggrothendieck at gmail.com  Mon Jun  2 15:40:53 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 2 Jun 2008 09:40:53 -0400
Subject: [R-SIG-Finance] apply.fromstart() warnings
In-Reply-To: <BLU105-W230B74166CA0FF70FED3D7EEBB0@phx.gbl>
References: <BLU105-W249C4E4EC70E6042ECA709EEBB0@phx.gbl>
	<971536df0806020527s6028918bh3bf04ebf774eadba@mail.gmail.com>
	<BLU105-W230B74166CA0FF70FED3D7EEBB0@phx.gbl>
Message-ID: <971536df0806020640v7b626ccao56b2faff1efb76cd@mail.gmail.com>

The problem goes beyond some warnings -- the answers from
apply.fromstart are wrong.  You could report the problem to the
author and just use a suitably modified version of the loop I posted
as a workaround.

On Mon, Jun 2, 2008 at 9:26 AM, Murali Menon <feanor0 at hotmail.com> wrote:
>
> Hi Gabor,
>
> Thanks for the suggestion. Actually, I just simplified the problem to a small bit of code that replicates the issue; in actuality, it's not the mean I am interested in calculating (but all sorts of other metrics), and the data are not randomly generated, but are financial time-series.
>
> The warning's probably coming from the apply.fromstart() function, but am not quite able to determine why. The initial 20 NAs are expected as there are no 'mean' computed for these (viz. the argument gap = 20).
>
> Cheers,
> Murali> Date: Mon, 2 Jun 2008 08:27:56 -0400> From: ggrothendieck at gmail.com> To: feanor0 at hotmail.com> Subject: Re: [R-SIG-Finance] apply.fromstart() warnings> CC: r-sig-finance at stat.math.ethz.ch> > To do it in zoo alone try this:> > library(zoo)> d <- zoo(matrix(1:50, 25), as.Date(1:25))> > dd <- NA * d> for(i in 21:nrow(dd)) dd[i, ] <- colMeans(d[1:i, ])> > You also might try updating the to latest version of all packages and R> although that does not appear to be the source of the problem here.> > On Mon, Jun 2, 2008 at 7:57 AM, Murali Menon <feanor0 at hotmail.com> wrote:> >> >> > Folks,> >> > When I attempt to find the growing window columnwise mean of a two-dimensional array, I get a bunch of warnings. Any idea why? Here's my code:> >> >> library(PerformanceAnalytics)> >> >> d <- zoo(matrix(rnorm(50), ncol=2), order.by=as.Date(1:25))> >> >> apply.fromstart(d, gap=20, FUN="mean")> > 1970-01-02 NA NA> > 1970-01-03 NA NA> > 1970-01-04 NA NA> > 1970-01-05 NA NA> > 1970-01-06 NA NA> > 1970-01-07 NA NA> > 1970-01-08 NA NA> > 1970-01-09 NA NA> > 1970-01-10 NA NA> > 1970-01-11 NA NA> > 1970-01-12 NA NA> > 1970-01-13 NA NA> > 1970-01-14 NA NA> > 1970-01-15 NA NA> > 1970-01-16 NA NA> > 1970-01-17 NA NA> > 1970-01-18 NA NA> > 1970-01-19 NA NA> > 1970-01-20 NA NA> > 1970-01-21 -0.05899970 -0.05899970> > 1970-01-22 -0.05882669 -0.05882669> > 1970-01-23 -0.08635806 -0.08635806> > 1970-01-24 -0.15848480 -0.15848480> > 1970-01-25 -0.13168358 -0.13168358> > 1970-01-26 -0.17101046 -0.17101046> > There were 12 warnings (use warnings() to see them)> >> >> > When I check the warnings(), here's the first string I get:> >> > 1: In column.Return.calc[i] = apply(as.matrix(data.zoo[, ... :> > number of items to replace is not a multiple of replacement length> >> > I'm not sure why this should be the case?> >> >> > I'm using:> >> >> packageDescription("zoo")$Version> > [1] "1.4-2"> >> packageDescription("PerformanceAnalytics")$Version> > [1] "0.9.6"> >> >> > And R 2.6.1 on Windows XP.> >> >> > Thanks,> >> >> > Murali> >> > _________________________________________________________________> > Give to a good cause with every e-mail. Join the i'm Initiative from Microsoft.> >> > _______________________________________________> > R-SIG-Finance at stat.math.ethz.ch mailing list> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance> > -- Subscriber-posting only.> > -- If you want to post, subscribe first.> >
> _________________________________________________________________
> Give to a good cause with every e-mail. Join the i'm Initiative from Microsoft.
>
>        [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From feanor0 at hotmail.com  Mon Jun  2 16:07:20 2008
From: feanor0 at hotmail.com (Murali Menon)
Date: Mon, 2 Jun 2008 14:07:20 +0000
Subject: [R-SIG-Finance] apply.fromstart() warnings
In-Reply-To: <971536df0806020640v7b626ccao56b2faff1efb76cd@mail.gmail.com>
References: <BLU105-W249C4E4EC70E6042ECA709EEBB0@phx.gbl>
	<971536df0806020527s6028918bh3bf04ebf774eadba@mail.gmail.com>
	<BLU105-W230B74166CA0FF70FED3D7EEBB0@phx.gbl> 
	<971536df0806020640v7b626ccao56b2faff1efb76cd@mail.gmail.com>
Message-ID: <BLU105-W310E34D5691BAAC7BB7B7EEEBB0@phx.gbl>



Hi,


Did you see where the answers are wrong? I tried the following, and it appears correct  (except for the warnings):


> apply.fromstart(cbind(1:20, 1:20), gap=10, FUN=mean)

           Column.1 Column.2
1970-01-02       NA       NA
1970-01-03       NA       NA
1970-01-04       NA       NA
1970-01-05       NA       NA
1970-01-06       NA       NA
1970-01-07       NA       NA
1970-01-08       NA       NA
1970-01-09       NA       NA
1970-01-10       NA       NA
1970-01-11      5.5      5.5
1970-01-12      6.0      6.0
1970-01-13      6.5      6.5
1970-01-14      7.0      7.0
1970-01-15      7.5      7.5
1970-01-16      8.0      8.0
1970-01-17      8.5      8.5
1970-01-18      9.0      9.0
1970-01-19      9.5      9.5
1970-01-20     10.0     10.0
1970-01-21     10.5     10.5
There were 22 warnings (use warnings() to see them)

That's correct, no? The mean of the first 10 entries go into the 10th row, the mean of the first 11 entries go into the 11th row, etc.

Funnily enough, there are no warnings if I run the function on a vector, say:

apply.fromstart(1:20, gap=10, FUN=mean)

Cheers,
Murali

> Date: Mon, 2 Jun 2008 09:40:53 -0400
> From: ggrothendieck at gmail.com
> To: r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] apply.fromstart() warnings
>
> The problem goes beyond some warnings -- the answers from
> apply.fromstart are wrong. You could report the problem to the
> author and just use a suitably modified version of the loop I posted
> as a workaround.
>
> On Mon, Jun 2, 2008 at 9:26 AM, Murali Menon  wrote:
>>
>> Hi Gabor,
>>
>> Thanks for the suggestion. Actually, I just simplified the problem to a small bit of code that replicates the issue; in actuality, it's not the mean I am interested in calculating (but all sorts of other metrics), and the data are not randomly generated, but are financial time-series.
>>
>> The warning's probably coming from the apply.fromstart() function, but am not quite able to determine why. The initial 20 NAs are expected as there are no 'mean' computed for these (viz. the argument gap = 20).
>>
>> Cheers,
>> Murali> Date: Mon, 2 Jun 2008 08:27:56 -0400> From: ggrothendieck at gmail.com> To: feanor0 at hotmail.com> Subject: Re: [R-SIG-Finance] apply.fromstart() warnings> CC: r-sig-finance at stat.math.ethz.ch>> To do it in zoo alone try this:>> library(zoo)> d <- zoo(matrix(1:50, 25), as.Date(1:25))>> dd <- NA * d> for(i in 21:nrow(dd)) dd[i, ] <- colMeans(d[1:i, ])>> You also might try updating the to latest version of all packages and R> although that does not appear to be the source of the problem here.>> On Mon, Jun 2, 2008 at 7:57 AM, Murali Menon  wrote:>>>>>> Folks,>>>> When I attempt to find the growing window columnwise mean of a two-dimensional array, I get a bunch of warnings. Any idea why? Here's my code:>>>>> library(PerformanceAnalytics)>>>>> d <- zoo(matrix(rnorm(50), ncol=2), order.by=as.Date(1:25))>>>>> apply.fromstart(d, gap=20, FUN="mean")>> 1970-01-02 NA NA>> 1970-01-03 NA NA>> 1970-01-04 NA NA>> 1970-01-05 NA NA>> 1970-01-06!
> NA NA>> 1970-01-07 NA NA>> 1970-01-08 NA NA>> 1970-01-09 NA NA>> 1970-01-10 NA NA>> 1970-01-11 NA NA>> 1970-01-12 NA NA>> 1970-01-13 NA NA>> 1970-01-14 NA NA>> 1970-01-15 NA NA>> 1970-01-16 NA NA>> 1970-01-17 NA NA>> 1970-01-18 NA NA>> 1970-01-19 NA NA>> 1970-01-20 NA NA>> 1970-01-21 -0.05899970 -0.05899970>> 1970-01-22 -0.05882669 -0.05882669>> 1970-01-23 -0.08635806 -0.08635806>> 1970-01-24 -0.15848480 -0.15848480>> 1970-01-25 -0.13168358 -0.13168358>> 1970-01-26 -0.17101046 -0.17101046>> There were 12 warnings (use warnings() to see them)>>>>>> When I check the warnings(), here's the first string I get:>>>> 1: In column.Return.calc[i] = apply(as.matrix(data.zoo[, ... :>> number of items to replace is not a multiple of replacement length>>>> I'm not sure why this should be the case?>>>>>> I'm using:>>>>> packageDescription("zoo")$Version>> [1] "1.4-2">>> packageDescription("PerformanceAnalytics")$Version>> [1] "0.9.6">>>>>> And R 2!
> .6.1 on Windows XP.>>>>>> Thanks,>>>>>> Murali>>>> ___________
> ______________________________________________________>> Give to a good cause with every e-mail. Join the i'm Initiative from Microsoft.>>>> _______________________________________________>> R-SIG-Finance at stat.math.ethz.ch mailing list>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance>> -- Subscriber-posting only.>> -- If you want to post, subscribe first.>>
>> _________________________________________________________________
>> Give to a good cause with every e-mail. Join the i'm Initiative from Microsoft.
>>
>> [[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.

_________________________________________________________________
Give to a good cause with every e-mail. Join the i?m Initiative from Microsoft.


From ggrothendieck at gmail.com  Mon Jun  2 16:10:44 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 2 Jun 2008 10:10:44 -0400
Subject: [R-SIG-Finance] apply.fromstart() warnings
In-Reply-To: <BLU105-W310E34D5691BAAC7BB7B7EEEBB0@phx.gbl>
References: <BLU105-W249C4E4EC70E6042ECA709EEBB0@phx.gbl>
	<971536df0806020527s6028918bh3bf04ebf774eadba@mail.gmail.com>
	<BLU105-W230B74166CA0FF70FED3D7EEBB0@phx.gbl>
	<971536df0806020640v7b626ccao56b2faff1efb76cd@mail.gmail.com>
	<BLU105-W310E34D5691BAAC7BB7B7EEEBB0@phx.gbl>
Message-ID: <971536df0806020710k4886af1es7cbff2c2f08b5571@mail.gmail.com>

Try the example in my post.

On Mon, Jun 2, 2008 at 10:07 AM, Murali Menon <feanor0 at hotmail.com> wrote:
>
>
> Hi,
>
>
> Did you see where the answers are wrong? I tried the following, and it appears correct  (except for the warnings):
>
>
>> apply.fromstart(cbind(1:20, 1:20), gap=10, FUN=mean)
>
>           Column.1 Column.2
> 1970-01-02       NA       NA
> 1970-01-03       NA       NA
> 1970-01-04       NA       NA
> 1970-01-05       NA       NA
> 1970-01-06       NA       NA
> 1970-01-07       NA       NA
> 1970-01-08       NA       NA
> 1970-01-09       NA       NA
> 1970-01-10       NA       NA
> 1970-01-11      5.5      5.5
> 1970-01-12      6.0      6.0
> 1970-01-13      6.5      6.5
> 1970-01-14      7.0      7.0
> 1970-01-15      7.5      7.5
> 1970-01-16      8.0      8.0
> 1970-01-17      8.5      8.5
> 1970-01-18      9.0      9.0
> 1970-01-19      9.5      9.5
> 1970-01-20     10.0     10.0
> 1970-01-21     10.5     10.5
> There were 22 warnings (use warnings() to see them)
>
> That's correct, no? The mean of the first 10 entries go into the 10th row, the mean of the first 11 entries go into the 11th row, etc.
>
> Funnily enough, there are no warnings if I run the function on a vector, say:
>
> apply.fromstart(1:20, gap=10, FUN=mean)
>
> Cheers,
> Murali
>
>> Date: Mon, 2 Jun 2008 09:40:53 -0400
>> From: ggrothendieck at gmail.com
>> To: r-sig-finance at stat.math.ethz.ch
>> Subject: Re: [R-SIG-Finance] apply.fromstart() warnings
>>
>> The problem goes beyond some warnings -- the answers from
>> apply.fromstart are wrong. You could report the problem to the
>> author and just use a suitably modified version of the loop I posted
>> as a workaround.
>>
>> On Mon, Jun 2, 2008 at 9:26 AM, Murali Menon  wrote:
>>>
>>> Hi Gabor,
>>>
>>> Thanks for the suggestion. Actually, I just simplified the problem to a small bit of code that replicates the issue; in actuality, it's not the mean I am interested in calculating (but all sorts of other metrics), and the data are not randomly generated, but are financial time-series.
>>>
>>> The warning's probably coming from the apply.fromstart() function, but am not quite able to determine why. The initial 20 NAs are expected as there are no 'mean' computed for these (viz. the argument gap = 20).
>>>
>>> Cheers,
>>> Murali> Date: Mon, 2 Jun 2008 08:27:56 -0400> From: ggrothendieck at gmail.com> To: feanor0 at hotmail.com> Subject: Re: [R-SIG-Finance] apply.fromstart() warnings> CC: r-sig-finance at stat.math.ethz.ch>> To do it in zoo alone try this:>> library(zoo)> d <- zoo(matrix(1:50, 25), as.Date(1:25))>> dd <- NA * d> for(i in 21:nrow(dd)) dd[i, ] <- colMeans(d[1:i, ])>> You also might try updating the to latest version of all packages and R> although that does not appear to be the source of the problem here.>> On Mon, Jun 2, 2008 at 7:57 AM, Murali Menon  wrote:>>>>>> Folks,>>>> When I attempt to find the growing window columnwise mean of a two-dimensional array, I get a bunch of warnings. Any idea why? Here's my code:>>>>> library(PerformanceAnalytics)>>>>> d <- zoo(matrix(rnorm(50), ncol=2), order.by=as.Date(1:25))>>>>> apply.fromstart(d, gap=20, FUN="mean")>> 1970-01-02 NA NA>> 1970-01-03 NA NA>> 1970-01-04 NA NA>> 1970-01-05 NA NA>> 1970-01-06!
>> NA NA>> 1970-01-07 NA NA>> 1970-01-08 NA NA>> 1970-01-09 NA NA>> 1970-01-10 NA NA>> 1970-01-11 NA NA>> 1970-01-12 NA NA>> 1970-01-13 NA NA>> 1970-01-14 NA NA>> 1970-01-15 NA NA>> 1970-01-16 NA NA>> 1970-01-17 NA NA>> 1970-01-18 NA NA>> 1970-01-19 NA NA>> 1970-01-20 NA NA>> 1970-01-21 -0.05899970 -0.05899970>> 1970-01-22 -0.05882669 -0.05882669>> 1970-01-23 -0.08635806 -0.08635806>> 1970-01-24 -0.15848480 -0.15848480>> 1970-01-25 -0.13168358 -0.13168358>> 1970-01-26 -0.17101046 -0.17101046>> There were 12 warnings (use warnings() to see them)>>>>>> When I check the warnings(), here's the first string I get:>>>> 1: In column.Return.calc[i] = apply(as.matrix(data.zoo[, ... :>> number of items to replace is not a multiple of replacement length>>>> I'm not sure why this should be the case?>>>>>> I'm using:>>>>> packageDescription("zoo")$Version>> [1] "1.4-2">>> packageDescription("PerformanceAnalytics")$Version>> [1] "0.9.6">>>>>> And R 2!
>> .6.1 on Windows XP.>>>>>> Thanks,>>>>>> Murali>>>> ___________
>> ______________________________________________________>> Give to a good cause with every e-mail. Join the i'm Initiative from Microsoft.>>>> _______________________________________________>> R-SIG-Finance at stat.math.ethz.ch mailing list>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance>> -- Subscriber-posting only.>> -- If you want to post, subscribe first.>>
>>> _________________________________________________________________
>>> Give to a good cause with every e-mail. Join the i'm Initiative from Microsoft.
>>>
>>> [[alternative HTML version deleted]]
>>>
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>
> _________________________________________________________________
> Give to a good cause with every e-mail. Join the i'm Initiative from Microsoft.
> http://im.live.com/Messenger/IM/Join/Default.aspx?souce=EML_WL_ GoodCause


From feanor0 at hotmail.com  Mon Jun  2 16:30:33 2008
From: feanor0 at hotmail.com (Murali Menon)
Date: Mon, 2 Jun 2008 14:30:33 +0000
Subject: [R-SIG-Finance] apply.fromstart() warnings
In-Reply-To: <971536df0806020710k4886af1es7cbff2c2f08b5571@mail.gmail.com>
References: <BLU105-W249C4E4EC70E6042ECA709EEBB0@phx.gbl>
	<971536df0806020527s6028918bh3bf04ebf774eadba@mail.gmail.com>
	<BLU105-W230B74166CA0FF70FED3D7EEBB0@phx.gbl>
	<971536df0806020640v7b626ccao56b2faff1efb76cd@mail.gmail.com>
	<BLU105-W310E34D5691BAAC7BB7B7EEEBB0@phx.gbl> 
	<971536df0806020710k4886af1es7cbff2c2f08b5571@mail.gmail.com>
Message-ID: <BLU105-W9403CBDB14B43DC0BBCC4EEBB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080602/a182f3ad/attachment.pl>

From ggrothendieck at gmail.com  Mon Jun  2 16:43:40 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 2 Jun 2008 10:43:40 -0400
Subject: [R-SIG-Finance] apply.fromstart() warnings
In-Reply-To: <BLU105-W9403CBDB14B43DC0BBCC4EEBB0@phx.gbl>
References: <BLU105-W249C4E4EC70E6042ECA709EEBB0@phx.gbl>
	<971536df0806020527s6028918bh3bf04ebf774eadba@mail.gmail.com>
	<BLU105-W230B74166CA0FF70FED3D7EEBB0@phx.gbl>
	<971536df0806020640v7b626ccao56b2faff1efb76cd@mail.gmail.com>
	<BLU105-W310E34D5691BAAC7BB7B7EEEBB0@phx.gbl>
	<971536df0806020710k4886af1es7cbff2c2f08b5571@mail.gmail.com>
	<BLU105-W9403CBDB14B43DC0BBCC4EEBB0@phx.gbl>
Message-ID: <971536df0806020743o2338fed9v7aad5165e6e5990e@mail.gmail.com>

Although the gap in my post was defined as one off from theirs that
is not the relevant point.  Look at the answers from apply.fromstart
The last number in the last column should be 38 (mean of 26:50),
not 13.

> d <- zoo(matrix(1:50, 25), as.Date(1:25))
> apply.fromstart(d, gap = 20, FUN = "mean")

1970-01-02   NA   NA
1970-01-03   NA   NA
1970-01-04   NA   NA
1970-01-05   NA   NA
1970-01-06   NA   NA
1970-01-07   NA   NA
1970-01-08   NA   NA
1970-01-09   NA   NA
1970-01-10   NA   NA
1970-01-11   NA   NA
1970-01-12   NA   NA
1970-01-13   NA   NA
1970-01-14   NA   NA
1970-01-15   NA   NA
1970-01-16   NA   NA
1970-01-17   NA   NA
1970-01-18   NA   NA
1970-01-19   NA   NA
1970-01-20   NA   NA
1970-01-21 10.5 10.5
1970-01-22 11.0 11.0
1970-01-23 11.5 11.5
1970-01-24 12.0 12.0
1970-01-25 12.5 12.5
1970-01-26 13.0 13.0
There were 12 warnings (use warnings() to see them)


On Mon, Jun 2, 2008 at 10:30 AM, Murali Menon <feanor0 at hotmail.com> wrote:
> Gabor,
>
> I think in your code, the loop should be (to replicate apply.fromstart())
>
> for(i in 20:nrow(dd)) dd[i, ] <- colMeans(d[1:i, ])
>
> not 21:nrow(dd)
>
> I think that's where the difference you refer to comes from. IF you make it
> 20:nrow(dd), then the answers match apply.fromstart()
>
> My understanding of the gap parameter:
>
> If it is 20, then the mean of the first 20 entries of d are computed, and
> stored in the 20th entry of dd, not the 21st.
>
> What do you think?
>
> Cheers,
> Murali
>
>> Date: Mon, 2 Jun 2008 10:10:44 -0400
>> From: ggrothendieck at gmail.com
>> To: feanor0 at hotmail.com
>> Subject: Re: [R-SIG-Finance] apply.fromstart() warnings
>> CC: r-sig-finance at stat.math.ethz.ch
>>
>> Try the example in my post.
>>
>> On Mon, Jun 2, 2008 at 10:07 AM, Murali Menon <feanor0 at hotmail.com> wrote:
>> >
>> >
>> > Hi,
>> >
>> >
>> > Did you see where the answers are wrong? I tried the following, and it
>> > appears correct (except for the warnings):
>> >
>> >
>> >> apply.fromstart(cbind(1:20, 1:20), gap=10, FUN=mean)
>> >
>> > Column.1 Column.2
>> > 1970-01-02 NA NA
>> > 1970-01-03 NA NA
>> > 1970-01-04 NA NA
>> > 1970-01-05 NA NA
>> > 1970-01-06 NA NA
>> > 1970-01-07 NA NA
>> > 1970-01-08 NA NA
>> > 1970-01-09 NA NA
>> > 1970-01-10 NA NA
>> > 1970-01-11 5.5 5.5
>> > 1970-01-12 6.0 6.0
>> > 1970-01-13 6.5 6.5
>> > 1970-01-14 7.0 7.0
>> > 1970-01-15 7.5 7.5
>> > 1970-01-16 8.0 8.0
>> > 1970-01-17 8.5 8.5
>> > 1970-01-18 9.0 9.0
>> > 1970-01-19 9.5 9.5
>> > 1970-01-20 10.0 10.0
>> > 1970-01-21 10.5 10.5
>> > There were 22 warnings (use warnings() to see them)
>> >
>> > That's correct, no? The mean of the first 10 entries go into the 10th
>> > row, the mean of the first 11 entries go into the 11th row, etc.
>> >
>> > Funnily enough, there are no warnings if I run the function on a vector,
>> > say:
>> >
>> > apply.fromstart(1:20, gap=10, FUN=mean)
>> >
>> > Cheers,
>> > Murali
>> >
>> >> Date: Mon, 2 Jun 2008 09:40:53 -0400
>> >> From: ggrothendieck at gmail.com
>> >> To: r-sig-finance at stat.math.ethz.ch
>> >> Subject: Re: [R-SIG-Finance] apply.fromstart() warnings
>> >>
>> >> The problem goes beyond some warnings -- the answers from
>> >> apply.fromstart are wrong. You could report the problem to the
>> >> author and just use a suitably modified version of the loop I posted
>> >> as a workaround.
>> >>
>> >> On Mon, Jun 2, 2008 at 9:26 AM, Murali Menon wrote:
>> >>>
>> >>> Hi Gabor,
>> >>>
>> >>> Thanks for the suggestion. Actually, I just simplified the problem to
>> >>> a small bit of code that replicates the issue; in actuality, it's not the
>> >>> mean I am interested in calculating (but all sorts of other metrics), and
>> >>> the data are not randomly generated, but are financial time-series.
>> >>>
>> >>> The warning's probably coming from the apply.fromstart() function, but
>> >>> am not quite able to determine why. The initial 20 NAs are expected as there
>> >>> are no 'mean' computed for these (viz. the argument gap = 20).
>> >>>
>> >>> Cheers,
>> >>> Murali> Date: Mon, 2 Jun 2008 08:27:56 -0400> From:
>> >>> ggrothendieck at gmail.com> To: feanor0 at hotmail.com> Subject: Re:
>> >>> [R-SIG-Finance] apply.fromstart() warnings> CC:
>> >>> r-sig-finance at stat.math.ethz.ch>> To do it in zoo alone try this:>>
>> >>> library(zoo)> d <- zoo(matrix(1:50, 25), as.Date(1:25))>> dd <- NA * d>
>> >>> for(i in 21:nrow(dd)) dd[i, ] <- colMeans(d[1:i, ])>> You also might try
>> >>> updating the to latest version of all packages and R> although that does not
>> >>> appear to be the source of the problem here.>> On Mon, Jun 2, 2008 at 7:57
>> >>> AM, Murali Menon wrote:>>>>>> Folks,>>>> When I attempt to find the growing
>> >>> window columnwise mean of a two-dimensional array, I get a bunch of
>> >>> warnings. Any idea why? Here's my code:>>>>>
>> >>> library(PerformanceAnalytics)>>>>> d <- zoo(matrix(rnorm(50), ncol=2),
>> >>> order.by=as.Date(1:25))>>>>> apply.fromstart(d, gap=20, FUN="mean")>>
>> >>> 1970-01-02 NA NA>> 1970-01-03 NA NA>> 1970-01-04 NA NA>> 1970-01-05 NA NA>>
>> >>> 1970-01-06!
>> >> NA NA>> 1970-01-07 NA NA>> 1970-01-08 NA NA>> 1970-01-09 NA NA>>
>> >> 1970-01-10 NA NA>> 1970-01-11 NA NA>> 1970-01-12 NA NA>> 1970-01-13 NA NA>>
>> >> 1970-01-14 NA NA>> 1970-01-15 NA NA>> 1970-01-16 NA NA>> 1970-01-17 NA NA>>
>> >> 1970-01-18 NA NA>> 1970-01-19 NA NA>> 1970-01-20 NA NA>> 1970-01-21
>> >> -0.05899970 -0.05899970>> 1970-01-22 -0.05882669 -0.05882669>> 1970-01-23
>> >> -0.08635806 -0.08635806>> 1970-01-24 -0.15848480 -0.15848480>> 1970-01-25
>> >> -0.13168358 -0.13168358>> 1970-01-26 -0.17101046 -0.17101046>> There were 12
>> >> warnings (use warnings() to see them)>>>>>> When I check the warnings(),
>> >> here's the first string I get:>>>> 1: In column.Return.calc[i] =
>> >> apply(as.matrix(data.zoo[, ... :>> number of items to replace is not a
>> >> multiple of replacement length>>>> I'm not sure why this should be the
>> >> case?>>>>>> I'm using:>>>>> packageDescription("zoo")$Version>> [1]
>> >> "1.4-2">>> packageDescription("PerformanceAnalytics")$Version>> [1]
>> >> "0.9.6">>>>>> And R 2!
>> >> .6.1 on Windows XP.>>>>>> Thanks,>>>>>> Murali>>>> ___________
>> >> ______________________________________________________>> Give to a good
>> >> cause with every e-mail. Join the i'm Initiative from Microsoft.>>>>
>> >> _______________________________________________>>
>> >> R-SIG-Finance at stat.math.ethz.ch mailing list>>
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance>> -- Subscriber-posting
>> >> only.>> -- If you want to post, subscribe first.>>
>> >>> _________________________________________________________________
>> >>> Give to a good cause with every e-mail. Join the i'm Initiative from
>> >>> Microsoft.
>> >>>
>> >>> [[alternative HTML version deleted]]
>> >>>
>> >>>
>> >>> _______________________________________________
>> >>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >>> -- Subscriber-posting only.
>> >>> -- If you want to post, subscribe first.
>> >>>
>> >>
>> >> _______________________________________________
>> >> R-SIG-Finance at stat.math.ethz.ch mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >> -- Subscriber-posting only.
>> >> -- If you want to post, subscribe first.
>> >
>> > _________________________________________________________________
>> > Give to a good cause with every e-mail. Join the i'm Initiative from
>> > Microsoft.
>> > http://im.live.com/Messenger/IM/Join/Default.aspx?souce=EML_WL_
>> > GoodCause
>
>
> ________________________________
> Change the world with e-mail. Join the i'm Initiative from Microsoft.


From feanor0 at hotmail.com  Mon Jun  2 16:59:09 2008
From: feanor0 at hotmail.com (Murali Menon)
Date: Mon, 2 Jun 2008 14:59:09 +0000
Subject: [R-SIG-Finance] apply.fromstart() warnings
In-Reply-To: <971536df0806020743o2338fed9v7aad5165e6e5990e@mail.gmail.com>
References: <BLU105-W249C4E4EC70E6042ECA709EEBB0@phx.gbl>
	<971536df0806020527s6028918bh3bf04ebf774eadba@mail.gmail.com>
	<BLU105-W230B74166CA0FF70FED3D7EEBB0@phx.gbl>
	<971536df0806020640v7b626ccao56b2faff1efb76cd@mail.gmail.com>
	<BLU105-W310E34D5691BAAC7BB7B7EEEBB0@phx.gbl>
	<971536df0806020710k4886af1es7cbff2c2f08b5571@mail.gmail.com>
	<BLU105-W9403CBDB14B43DC0BBCC4EEBB0@phx.gbl> 
	<971536df0806020743o2338fed9v7aad5165e6e5990e@mail.gmail.com>
Message-ID: <BLU105-W39B29F7A8E5CA3DBD5B412EEBB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080602/4e141953/attachment.pl>

From brian at braverock.com  Mon Jun  2 17:15:59 2008
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 02 Jun 2008 10:15:59 -0500
Subject: [R-SIG-Finance] apply.fromstart() warnings
In-Reply-To: <BLU105-W230B74166CA0FF70FED3D7EEBB0@phx.gbl>
References: <BLU105-W249C4E4EC70E6042ECA709EEBB0@phx.gbl>	<971536df0806020527s6028918bh3bf04ebf774eadba@mail.gmail.com>
	<BLU105-W230B74166CA0FF70FED3D7EEBB0@phx.gbl>
Message-ID: <48440EAF.4030705@braverock.com>

It looks like you may have found a bug in apply.fromstart()

We'll get a fit worked out and posted here soon.

Regards,

   - Brian


Murali Menon wrote:
> Hi Gabor,
>  
> Thanks for the suggestion. Actually, I just simplified the problem to a small bit of code that replicates the issue; in actuality, it's not the mean I am interested in calculating (but all sorts of other metrics), and the data are not randomly generated, but are financial time-series.
>  
> The warning's probably coming from the apply.fromstart() function, but am not quite able to determine why. The initial 20 NAs are expected as there are no 'mean' computed for these (viz. the argument gap = 20).
>  
> Cheers,
> Murali


From davidr at rhotrading.com  Mon Jun  2 20:28:47 2008
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Mon, 2 Jun 2008 13:28:47 -0500
Subject: [R-SIG-Finance] RBloomberg
In-Reply-To: <4843ECBA.6090506@allstontrading.com>
References: <4843ECBA.6090506@allstontrading.com>
Message-ID: <F9F2A641C593D7408925574C05A7BE77F7A723@rhopost.rhotrading.com>

Eric,

As no-one's jumped on this, I will give it a go.
Bloomberg's bbcomm.exe is notoriously flakey, sometimes returning
nothing but pretending to have answered your request.
About all I can suggest is to wrap your calls in try-catch and retry
once.
Either bbcomm.exe was at fault, in which case the second call should
succeed, or
there is no data for the ticker and time range you are requesting, in
which case,
you just go to the next ticker or time range.

I'm pretty sure this is not RBloomberg's fault.

HTH,
David L. Reiner, PhD
Head Quant
Rho Trading Securities, LLC

p.s. I'm just guessing, because you really haven't given us much
information.

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Eric
Owiesny
Sent: Monday, June 02, 2008 7:51 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] RBloomberg

Hi,

I've been having some trouble with having the connection to Bloomberg 
fail after a while.  I've been using RBloomberg and wrote a simple 
function that downloads intraday data to write it to a file.  This works

fine for a while, but will periodically give me an error saying:

Error in substr(text, first, last) : invalid Substring argument(s)

If I restart the function, it will work again.  I was wondering if 
anyone else had this problem or knew what was going on.

Thanks,
Eric Owiesny

------------------------------------------------------------------------
------------------
This message is for the named person(s) use only. It may contain
confidential proprietary or legally privileged information. No
confidentiality or privilege is waived or lost by any mistransmission.
If you receive this message in error, please immediately delete it and
all copies of it from your system, destroy any hard copies of it and
notify the sender. You must not, directly or indirectly use, disclose,
distribute, print, or copy any part of this message if you are not the
intended recipient. Allston Trading LLC and its subsidiaries and
affiliates each reserve the right to monitor all e-mail communications
through its networks. Any views expressed in this message are those of
the individual sender, except where the message states otherwise and the
sender is authorized to state them to be the views of any such entity.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From eowiesny at allstontrading.com  Mon Jun  2 20:52:32 2008
From: eowiesny at allstontrading.com (Eric Owiesny)
Date: Mon, 02 Jun 2008 13:52:32 -0500
Subject: [R-SIG-Finance] RBloomberg
In-Reply-To: <F9F2A641C593D7408925574C05A7BE77F7A723@rhopost.rhotrading.com>
References: <4843ECBA.6090506@allstontrading.com>
	<F9F2A641C593D7408925574C05A7BE77F7A723@rhopost.rhotrading.com>
Message-ID: <48444170.2080500@allstontrading.com>

David,

Thank you for the help.  It seemed likely to me that it's on Bloomberg's 
end as well.  I've made a wrapper to retry if it fails.  Sorry, I should 
have been more specific before.  Essentially it seems that the 
connection object ceases to work after some point.  It's an intermittent 
problem and occurs when there is data for the ticker and the time 
range.  If I reinitialize the connection object then it will usually 
work again.  It also seems to be worse during the day so it may be a 
load issue on their end.  Sorry for the lack of complete information, 
but I'm not entirely sure what the error is.    The wrapper should be 
fine, but I wanted to check to see if it was just me misusing something.

Thanks,
Eric Owiesny

davidr at rhotrading.com wrote:
> Eric,
>
> As no-one's jumped on this, I will give it a go.
> Bloomberg's bbcomm.exe is notoriously flakey, sometimes returning
> nothing but pretending to have answered your request.
> About all I can suggest is to wrap your calls in try-catch and retry
> once.
> Either bbcomm.exe was at fault, in which case the second call should
> succeed, or
> there is no data for the ticker and time range you are requesting, in
> which case,
> you just go to the next ticker or time range.
>
> I'm pretty sure this is not RBloomberg's fault.
>
> HTH,
> David L. Reiner, PhD
> Head Quant
> Rho Trading Securities, LLC
>
> p.s. I'm just guessing, because you really haven't given us much
> information.
>
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Eric
> Owiesny
> Sent: Monday, June 02, 2008 7:51 AM
> To: r-sig-finance at stat.math.ethz.ch
> Subject: [R-SIG-Finance] RBloomberg
>
> Hi,
>
> I've been having some trouble with having the connection to Bloomberg 
> fail after a while.  I've been using RBloomberg and wrote a simple 
> function that downloads intraday data to write it to a file.  This works
>
> fine for a while, but will periodically give me an error saying:
>
> Error in substr(text, first, last) : invalid Substring argument(s)
>
> If I restart the function, it will work again.  I was wondering if 
> anyone else had this problem or knew what was going on.
>
> Thanks,
> Eric Owiesny
>
> ------------------------------------------------------------------------
> ------------------
> This message is for the named person(s) use only. It may contain
> confidential proprietary or legally privileged information. No
> confidentiality or privilege is waived or lost by any mistransmission.
> If you receive this message in error, please immediately delete it and
> all copies of it from your system, destroy any hard copies of it and
> notify the sender. You must not, directly or indirectly use, disclose,
> distribute, print, or copy any part of this message if you are not the
> intended recipient. Allston Trading LLC and its subsidiaries and
> affiliates each reserve the right to monitor all e-mail communications
> through its networks. Any views expressed in this message are those of
> the individual sender, except where the message states otherwise and the
> sender is authorized to state them to be the views of any such entity.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>   


------------------------------------------------------------------------------------------
This message is for the named person(s) use only. It may contain confidential proprietary or legally privileged information. No confidentiality or privilege is waived or lost by any mistransmission. If you receive this message in error, please immediately delete it and all copies of it from your system, destroy any hard copies of it and notify the sender. You must not, directly or indirectly use, disclose, distribute, print, or copy any part of this message if you are not the intended recipient. Allston Trading LLC and its subsidiaries and affiliates each reserve the right to monitor all e-mail communications through its networks. Any views expressed in this message are those of the individual sender, except where the message states otherwise and the sender is authorized to state them to be the views of any such entity.


From Xiaochen.Sun at brunel.ac.uk  Wed Jun  4 13:18:40 2008
From: Xiaochen.Sun at brunel.ac.uk (Xiao Sun)
Date: Wed, 4 Jun 2008 12:18:40 +0100
Subject: [R-SIG-Finance] Conference and workshops: RISK CONTROL
	STRATEGIES FOR HEDGE FUNDS AND PROGRAM TRADING
References: <4843ECBA.6090506@allstontrading.com>
	<F9F2A641C593D7408925574C05A7BE77F7A723@rhopost.rhotrading.com>
Message-ID: <E386E504246A9249A9176B5BEEC13B6F7B8F9F@UXEXMBU116.academic.windsor>

Conference and workshops: RISK CONTROL STRATEGIES FOR HEDGE FUNDS AND PROGRAM TRADING 

1-2 July 2008, London

http://www.optirisk-systems.com/events/carisma2008.asp <http://www.optirisk-systems.com/events/carisma2008.asp> 

We are pleased to announce that places are still available for the above conference and related workshops. 

All the conference delegates are invited to attend the Drinks Receptions and Networking Evening sponsored by Dow Jones & Company <http://www.djnewswires.com/eu/>  for FREE on the evening of 1 July. 

NEW PRESENTATIONS UPDATED 

Trading off the News: Applications of News Algorithms

Alan Slomowitz, Director of  Algorithmic and Quantitative Trading Products 

Dow Jones & Company, Enterprise Media Group

News Analytics: Models that Quantify News

Philip A. Gagner, RavenPack International

? Syntax and News

? Quantified "Hard" News

? Semantics & News: News Sentiment

? Perturbing The Quantitative Equity Valuation Models

? Building an Impulse Response Model for News Stories

Efficiencies in Multi-Account Optimization

Pamela Vance, Axioma

? Efficiencies of rebalancing multiple accounts together

? Underestimation of market-impact with individual optimizations

? Accurate incorporation of interdependencies of multiple accounts

? Fairness issues in multi-account optimization

HOW TO REGISTER

For full programme details and registration, including fees, see http://www.optirisk-systems.com/events/carisma2008.asp <http://www.optirisk-systems.com/events/carisma2008.asp> 

WHAT THE SERIES COMPRISES:

1) A two-day conference: 

RISK CONTROL STRATEGIES FOR HEDGE FUNDS AND PROGRAM TRADING 

1-2 July 2008, London, plus:

2) Four pre- and post- conference half-day workshops on 30 June and 3 July, on:

a. Robust Portfolio Optimisation, 30 June Morning, London

b. LDI/ALM, 30 June Afternoon, London

c. New Developments: Performance Measures and Structured Products; Coherent . Risk Measures and Liquidity Risk, 3 July Morning, London

d. News Analytics and Financial Modelling, 3 July Afternoon, London

For full details see http://www.optirisk-systems.com/events/carisma2008.asp <http://www.optirisk-systems.com/events/carisma2008.asp> 

Please don't hesitate to contact me if you would like to reserve places or to discuss any aspect of this series in more details.

Kind regards,

Michael

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From brian at braverock.com  Wed Jun  4 14:58:53 2008
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 04 Jun 2008 07:58:53 -0500
Subject: [R-SIG-Finance] HJM model (Interest rate)
In-Reply-To: <4f37d3da0805291236x12cd4523qe16bd56ab6fd84e8@mail.gmail.com>
References: <4f37d3da0805291236x12cd4523qe16bd56ab6fd84e8@mail.gmail.com>
Message-ID: <4846918D.3000503@braverock.com>

Ana Patricia Martins wrote:
> Although my basic training is in statistics, I've little knowledge about
> interest rates models, and it was suggested Cox-Ingersoll-Ross process,
> Ornstein-Uhlenbeck or Vasicek process or Heath-Jarrow-Morton methods.
> 
> Does anyone know if exist HJM model in R? I can't find?
> 
> The CIR model was considered, however based on the observed data (1998-2007)
> doesn't works.
> Does anyone can suggest a package or other models?
> 
> Thanks in advance your help.
> Best regards
> Ana Patr?cia


Sorry for my late reply here, but here are some packages or sources you 
should consider:


The package 'termstrc' contains functions for computing bond prices of 
many different types of bonds, as well as parametric, spline, and 
Nelson-Siegel term structure models

The package 'fBonds' from RMetrics contains functions for Nelson-Siegel 
and Nelson-Siegel-Svensson term structure models

The package 'sde' implements the Ornstein-Uhlenbeck or Vasicek model

The package 'pomp' uses Markov processes to simulate univariate and 
bivariate Ornstein-Uhlenbeck or Vasicek processes.

The package 'SemiPar' implements semiparametric spline models, including 
the Jarrow-Ruppert-Yu term structure model.

Chapter 9 of David Ruppert's "Statistics in Finance" covers fixed income 
models, and his examples have all been re-worked in R and are available 
on the internet.

I'm sure that there are more, but these are the ones that come 
immediately to mind.  I am *not* aware of an R implementation of a 
Heath-Jarrow-Morton method, but that doesn't mean that one doesn't exist 
or couldn't be readily created.

Regards,

   - Brian


From finbref.2006 at gmail.com  Wed Jun  4 18:12:30 2008
From: finbref.2006 at gmail.com (Thomas Steiner)
Date: Wed, 4 Jun 2008 18:12:30 +0200
Subject: [R-SIG-Finance] HJM model (Interest rate)
In-Reply-To: <4846918D.3000503@braverock.com>
References: <4f37d3da0805291236x12cd4523qe16bd56ab6fd84e8@mail.gmail.com>
	<4846918D.3000503@braverock.com>
Message-ID: <d0f55a670806040912u271b527bs105ce690dfee9244@mail.gmail.com>

I agree, very good directions to go.

Just as personal code, I craeted this and some other pictures for
wikipedia: http://commons.wikimedia.org/wiki/Image:Zins-Vasicek.png
where you find the R code as well. let me know if you need eg CIR or
others (jumps?) as well. (see Svensson at
http://commons.wikimedia.org/wiki/Image:Zinsstruktur.png, CIR at
http://commons.wikimedia.org/wiki/Image:SQRTDiffusion.png)

And HJM is a framework, not a model. You will decide something on the
shape of the forward rate curve (eg Svensson, but then the is just one
(!) source of randomness possible if you want to be consistent (too
complicated for me...).

Thomas


2008/6/4, Brian G. Peterson <brian at braverock.com>:
> Ana Patricia Martins wrote:
> > Although my basic training is in statistics, I've little knowledge about
> > interest rates models, and it was suggested Cox-Ingersoll-Ross process,
> > Ornstein-Uhlenbeck or Vasicek process or Heath-Jarrow-Morton methods.
> >
> > Does anyone know if exist HJM model in R? I can't find?
> >
> > The CIR model was considered, however based on the observed data
> (1998-2007)
> > doesn't works.
> > Does anyone can suggest a package or other models?
> >
> > Thanks in advance your help.
> > Best regards
> > Ana Patr?cia
> >
>
>
> Sorry for my late reply here, but here are some packages or sources you
> should consider:
>
>
> The package 'termstrc' contains functions for computing bond prices of many
> different types of bonds, as well as parametric, spline, and Nelson-Siegel
> term structure models
>
> The package 'fBonds' from RMetrics contains functions for Nelson-Siegel and
> Nelson-Siegel-Svensson term structure models
>
> The package 'sde' implements the Ornstein-Uhlenbeck or Vasicek model
>
> The package 'pomp' uses Markov processes to simulate univariate and
> bivariate Ornstein-Uhlenbeck or Vasicek processes.
>
> The package 'SemiPar' implements semiparametric spline models, including the
> Jarrow-Ruppert-Yu term structure model.
>
> Chapter 9 of David Ruppert's "Statistics in Finance" covers fixed income
> models, and his examples have all been re-worked in R and are available on
> the internet.
>
> I'm sure that there are more, but these are the ones that come immediately
> to mind.  I am *not* aware of an R implementation of a Heath-Jarrow-Morton
> method, but that doesn't mean that one doesn't exist or couldn't be readily
> created.
>
> Regards,
>
>  - Brian
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From chalabi at phys.ethz.ch  Thu Jun  5 10:19:57 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Thu, 5 Jun 2008 10:19:57 +0200
Subject: [R-SIG-Finance] Demystification of GARCH modeling with fGarch
Message-ID: <20080605101957.5b91deaa@mimi>

Dear all,

I am working on a tutorial which would focus on the  common issues in GARCH/APARCH modeling. The idea is to give hints how to choose the optimization parameters,  the starting values, the distribution and how to properly scale the data.

This tutorial is meant to be very practical and I would like to have some input from the r-sig-finance community. If you have examples where garchFit badly failed for you, it would be great if you could send me your dataset with the R code you used. If you have any other comments or questions about fGarch, feel free to write me. 

Thanks!

Regards,
Yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From markleeds at verizon.net  Thu Jun  5 10:30:03 2008
From: markleeds at verizon.net (Mark Leeds)
Date: Thu, 05 Jun 2008 04:30:03 -0400
Subject: [R-SIG-Finance] Demystification of GARCH modeling with fGarch
In-Reply-To: <20080605101957.5b91deaa@mimi>
Message-ID: <000601c8c6e6$5a9633f0$2f01a8c0@coresystem>

Just to let you know, Eric Zivot has a fairly recent and interesting paper
on arch/garch modeling at his website. I haven't read it carefully yet ( I
more just glanced through it )  but maybe you'd want to look at that paper
before you make your tutorial. Thanks for all your work.


                                             Mark

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Yohan Chalabi
Sent: Thursday, June 05, 2008 4:20 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] Demystification of GARCH modeling with fGarch

Dear all,

I am working on a tutorial which would focus on the  common issues in
GARCH/APARCH modeling. The idea is to give hints how to choose the
optimization parameters,  the starting values, the distribution and how to
properly scale the data.

This tutorial is meant to be very practical and I would like to have some
input from the r-sig-finance community. If you have examples where garchFit
badly failed for you, it would be great if you could send me your dataset
with the R code you used. If you have any other comments or questions about
fGarch, feel free to write me. 

Thanks!

Regards,
Yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From feanor0 at hotmail.com  Thu Jun  5 11:39:11 2008
From: feanor0 at hotmail.com (Murali Menon)
Date: Thu, 5 Jun 2008 09:39:11 +0000
Subject: [R-SIG-Finance] Datastream interface
Message-ID: <BLU105-W22F80E4329E6A49BD31B9AEEB40@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080605/08424ab4/attachment.pl>

From feanor0 at hotmail.com  Mon Jun  9 18:19:55 2008
From: feanor0 at hotmail.com (Murali Menon)
Date: Mon, 9 Jun 2008 16:19:55 +0000
Subject: [R-SIG-Finance] Applying quarterly weights on daily returns
Message-ID: <BLU105-W420652C6A30919CD4C2758EEB00@phx.gbl>



Folks, 

I have quarterly weights (4 quarters) and 300 days of daily trading signals and returns for 3 assets. 

library(zoo) 
set.seed(123) 

wts <- abs(zoo(matrix(rnorm(36), ncol = 3), yearqtr(1970 + (0 : 3) / 4)) )

rets <- zoo(matrix(rnorm(900), ncol = 3) / 100, order.by = as.Date(1 : 300)) 

tsig <- zoo(rbinom(300, 2, 0.5) - 1, order.by = as.Date(1 : 300)) 

In each quarter, the return would be like: 

rowSums(head(tsig, -1) * tail(rets, -1) * wts(of that quarter)) 

Where the trading signal is applied today, but its return is observed tomorrow. 

How to apply quarterly series on a daily series, though?

Please advise. 

Thanks, 

Murali
_________________________________________________________________
Instantly invite friends from Facebook and other social networks to join yo
https://www.invite2messenger.net/im/?source=TXT_EML_WLH_InviteFriends

From ggrothendieck at gmail.com  Mon Jun  9 18:55:54 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 9 Jun 2008 12:55:54 -0400
Subject: [R-SIG-Finance] Applying quarterly weights on daily returns
In-Reply-To: <BLU105-W420652C6A30919CD4C2758EEB00@phx.gbl>
References: <BLU105-W420652C6A30919CD4C2758EEB00@phx.gbl>
Message-ID: <971536df0806090955s4d7e0d31g172f4c4553922a3d@mail.gmail.com>

If I understand it then you want to lag rets by one day, mulitply that
by tsig and then sum over the quarter and mulitply that by wts:

z <- tsig * lag(rets)
rowsum(z, as.yearqtr(time(z))) * wts

The rowsum output is a matrix and wts is zoo so
this depends on them having the same shapes.

On Mon, Jun 9, 2008 at 12:19 PM, Murali Menon <feanor0 at hotmail.com> wrote:
>
>
> Folks,
>
> I have quarterly weights (4 quarters) and 300 days of daily trading signals and returns for 3 assets.
>
> library(zoo)
> set.seed(123)
>
> wts <- abs(zoo(matrix(rnorm(36), ncol = 3), yearqtr(1970 + (0 : 3) / 4)) )
>
> rets <- zoo(matrix(rnorm(900), ncol = 3) / 100, order.by = as.Date(1 : 300))
>
> tsig <- zoo(rbinom(300, 2, 0.5) - 1, order.by = as.Date(1 : 300))
>
> In each quarter, the return would be like:
>
> rowSums(head(tsig, -1) * tail(rets, -1) * wts(of that quarter))
>
> Where the trading signal is applied today, but its return is observed tomorrow.
>
> How to apply quarterly series on a daily series, though?
>
> Please advise.
>
> Thanks,
>
> Murali
> _________________________________________________________________
> Instantly invite friends from Facebook and other social networks to join yo
> https://www.invite2messenger.net/im/?source=TXT_EML_WLH_InviteFriends
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From feanor0 at hotmail.com  Tue Jun 10 11:08:16 2008
From: feanor0 at hotmail.com (Murali Menon)
Date: Tue, 10 Jun 2008 09:08:16 +0000
Subject: [R-SIG-Finance] Applying quarterly weights on daily returns
In-Reply-To: <971536df0806090955s4d7e0d31g172f4c4553922a3d@mail.gmail.com>
References: <BLU105-W420652C6A30919CD4C2758EEB00@phx.gbl>
	<971536df0806090955s4d7e0d31g172f4c4553922a3d@mail.gmail.com>
Message-ID: <BLU105-W26DBA7FD395B90C162F9C1EEB30@phx.gbl>


Hi,

Thanks, that does the trick. Didn't know about the rowsum() magic.

Not sure I understand how tsig * lag(rets) works. tsig is a bigger matrix
(one extra row) than lag(rets), right? So should not there by some recycling
of column elements of lag(rets)?

Cheers,
Murali


> Date: Mon, 9 Jun 2008 12:55:54 -0400
> From: ggrothendieck at gmail.com
> To: feanor0 at hotmail.com
> Subject: Re: [R-SIG-Finance] Applying quarterly weights on daily returns
> CC: r-sig-finance at stat.math.ethz.ch
>
> If I understand it then you want to lag rets by one day, mulitply that
> by tsig and then sum over the quarter and mulitply that by wts:
>
> z <- tsig * lag(rets)
> rowsum(z, as.yearqtr(time(z))) * wts
>
> The rowsum output is a matrix and wts is zoo so
> this depends on them having the same shapes.
>
> On Mon, Jun 9, 2008 at 12:19 PM, Murali Menon  wrote:
>>
>>
>> Folks,
>>
>> I have quarterly weights (4 quarters) and 300 days of daily trading signals and returns for 3 assets.
>>
>> library(zoo)
>> set.seed(123)
>>
>> wts <- abs(zoo(matrix(rnorm(36), ncol = 3), yearqtr(1970 + (0 : 3) / 4)) )
>>
>> rets <- zoo(matrix(rnorm(900), ncol = 3) / 100, order.by = as.Date(1 : 300))
>>
>> tsig <- zoo(rbinom(300, 2, 0.5) - 1, order.by = as.Date(1 : 300))
>>
>> In each quarter, the return would be like:
>>
>> rowSums(head(tsig, -1) * tail(rets, -1) * wts(of that quarter))
>>
>> Where the trading signal is applied today, but its return is observed tomorrow.
>>
>> How to apply quarterly series on a daily series, though?
>>
>> Please advise.
>>
>> Thanks,
>>
>> Murali
>> _________________________________________________________________
>> Instantly invite friends from Facebook and other social networks to join yo
>> https://www.invite2messenger.net/im/?source=TXT_EML_WLH_InviteFriends
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>

_________________________________________________________________
Now you can invite friends from Facebook and other groups to join you on Wi
https://www.invite2messenger.net/im/?source=TXT_EML_WLH_AddNow_Now

From benverschuere at hotmail.com  Wed Jun 11 21:08:48 2008
From: benverschuere at hotmail.com (Verschuere Benjamin)
Date: Wed, 11 Jun 2008 21:08:48 +0200
Subject: [R-SIG-Finance] Granger-Gonzalo decomposition
Message-ID: <BLU109-W49D466255B96D9A3727066B8B20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080611/aaffea25/attachment.pl>

From wuertz at itp.phys.ethz.ch  Wed Jun 11 23:12:21 2008
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Wed, 11 Jun 2008 23:12:21 +0200
Subject: [R-SIG-Finance] ETH Internship - Dynamic Portfolio Asset Allocation
Message-ID: <48503FB5.4000909@itp.phys.ethz.ch>



Summer Internship at ETH Zurich
"Dynamic Portfolio Asset Allocation"


We offer a 3-months internship starting
midth July 2008. The topic addresses
"Dynamic Portfolio Asset Allocation"
including alternative instruments and
hedge funds. The goal will be to compare
the robust mean-variance, the lower partial
moment and the conditional value-at-risk
approaches for portfolio construction and
optimization using the Rmetrics package
"fPortfolio". Moreover, we will investigate
the influence of quadratic covariance and
copulae related tail risk budget constraints
as an option to limit and control the risk
attributed by individual assets.

We offer a generous compensation for traveling,
accomodation, and living costs in the beautiful
city of Zurich.

The candidate should have a strong quantitative
background and have experience in data
modelling with the R language.

The application should include a letter of
motivation (highlighting your interest and prior
knowledge in the internship topic) and an
up-to-date CV. Please send your application to
wuertz at phys.ethz.ch.

If you need further information, please contact us.

PD Dr. Diethelm Wuertz
Econophysics Group at the
Institute of Theoretical Physics
ETH Zurich

www.ethz.ch
www.phys.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From bveeraraghavan at yahoo.com  Fri Jun 13 14:18:32 2008
From: bveeraraghavan at yahoo.com (Balaji Veeraraghavan)
Date: Fri, 13 Jun 2008 05:18:32 -0700 (PDT)
Subject: [R-SIG-Finance] Financial workload in R
Message-ID: <735616.55774.qm@web82006.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080613/deb9731d/attachment.pl>

From pierre8r-list at yahoo.fr  Tue Jun 17 11:55:47 2008
From: pierre8r-list at yahoo.fr (pierre8r-list at yahoo.fr)
Date: Tue, 17 Jun 2008 09:55:47 +0000 (GMT)
Subject: [R-SIG-Finance] Are there somewhere the examples
	http://www.quantmod.com/examples/ ready to run ?
Message-ID: <595446.36061.qm@web28102.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080617/5ba4c79d/attachment.pl>

From jeff.a.ryan at gmail.com  Tue Jun 17 15:02:13 2008
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 17 Jun 2008 08:02:13 -0500
Subject: [R-SIG-Finance] Are there somewhere the examples
	http://www.quantmod.com/examples/ ready to run ?
In-Reply-To: <595446.36061.qm@web28102.mail.ukl.yahoo.com>
References: <595446.36061.qm@web28102.mail.ukl.yahoo.com>
Message-ID: <e8e755250806170602x70bc6c27ja94b6aeac9313767@mail.gmail.com>

Are you looking for a specific example - or more examples than:

http://www.quantmod.com/examples/intro/
http://www.quantmod.com/examples/data/
http://www.quantmod.com/examples/charting/

All should run by simply starting an R session and typing them in. If
you are looking for a script file, I am not sure that all examples
have those available, but none are too cumbersome to type --- and I
will at some point add script file(s) to facilitate.


Hope that answers your question,
Jeff

On Tue, Jun 17, 2008 at 4:55 AM,  <pierre8r-list at yahoo.fr> wrote:
> Hello,
>
>
>
> Are there somewhere the examples http://www.quantmod.com/examples/
>
> ready to run ?
>
>
>
> Thanks,
>
>
>
> Pierre8r
>
>
>      _____________________________________________________________________________
>
> o.fr
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From pierre8r-list at yahoo.fr  Tue Jun 17 18:47:59 2008
From: pierre8r-list at yahoo.fr (pierre8r-list at yahoo.fr)
Date: Tue, 17 Jun 2008 16:47:59 +0000 (GMT)
Subject: [R-SIG-Finance] How to merge Date and Time in a single value ?
Message-ID: <671639.34086.qm@web28106.mail.ukl.yahoo.com>

Hello,

I am a newbie with R. 
I try to import stock quotes in R. 

Samples stock quotes :

date ,time ,open ,high ,low ,close ,volume
12/29/2006,00:00,1.963,1.963,1.96195,1.96195,-1
12/29/2006,00:30,1.96195,1.9624,1.96195,1.962,-1
12/29/2006,01:00,1.962,1.9622,1.9608,1.961,-1
12/29/2006,01:30,1.961,1.9619,1.96095,1.96105,-1
12/29/2006,02:00,1.96105,1.96185,1.96105,1.9617,-1
12/29/2006,02:30,1.9617,1.9624,1.9616,1.9621,-1
12/29/2006,03:00,1.9621,1.96215,1.96155,1.96175,-1
12/29/2006,03:30,1.96175,1.96205,1.9615,1.96205,-1
12/29/2006,04:00,1.96205,1.9626,1.962,1.96235,-1
12/29/2006,04:30,1.96235,1.96305,1.96215,1.96275,-1
12/29/2006,05:00,1.96275,1.96345,1.96245,1.96325,-1
12/29/2006,05:30,1.96325,1.9639,1.96325,1.96375,-1
12/29/2006,06:00,1.96375,1.9647,1.9637,1.9646,-1
12/29/2006,06:30,1.9646,1.9657,1.964,1.964,-1
12/29/2006,07:00,1.964,1.96535,1.96385,1.9651,-1


I wrote a few lines of R. 

Code:

quotes <- read.csv2("GBPUSD-30mn.txt", header = TRUE, sep = ",", dec=".")
quotes
names(quotes)


The result does not agree me.
I would like to have the date and time data in a single value. 
The goal is then to display these stock prices as a graph.

Regards,

Pierre8r


      ____________________________________________________
intelligente http://mail.yahoo.fr


From ggrothendieck at gmail.com  Tue Jun 17 19:11:20 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 17 Jun 2008 13:11:20 -0400
Subject: [R-SIG-Finance] How to merge Date and Time in a single value ?
In-Reply-To: <671639.34086.qm@web28106.mail.ukl.yahoo.com>
References: <671639.34086.qm@web28106.mail.ukl.yahoo.com>
Message-ID: <971536df0806171011w60cacb23s87807c793ef30d9@mail.gmail.com>

Try:

quotes <- read.csv("GBPUSD-30mn.txt", as.is = TRUE)
library(chron)
dt <- chron(DF$date, paste(DF$time, "00", sep = ":"))

Check out R News 4/1 for article on dates.


On Tue, Jun 17, 2008 at 12:47 PM,  <pierre8r-list at yahoo.fr> wrote:
> Hello,
>
> I am a newbie with R.
> I try to import stock quotes in R.
>
> Samples stock quotes :
>
> date ,time ,open ,high ,low ,close ,volume
> 12/29/2006,00:00,1.963,1.963,1.96195,1.96195,-1
> 12/29/2006,00:30,1.96195,1.9624,1.96195,1.962,-1
> 12/29/2006,01:00,1.962,1.9622,1.9608,1.961,-1
> 12/29/2006,01:30,1.961,1.9619,1.96095,1.96105,-1
> 12/29/2006,02:00,1.96105,1.96185,1.96105,1.9617,-1
> 12/29/2006,02:30,1.9617,1.9624,1.9616,1.9621,-1
> 12/29/2006,03:00,1.9621,1.96215,1.96155,1.96175,-1
> 12/29/2006,03:30,1.96175,1.96205,1.9615,1.96205,-1
> 12/29/2006,04:00,1.96205,1.9626,1.962,1.96235,-1
> 12/29/2006,04:30,1.96235,1.96305,1.96215,1.96275,-1
> 12/29/2006,05:00,1.96275,1.96345,1.96245,1.96325,-1
> 12/29/2006,05:30,1.96325,1.9639,1.96325,1.96375,-1
> 12/29/2006,06:00,1.96375,1.9647,1.9637,1.9646,-1
> 12/29/2006,06:30,1.9646,1.9657,1.964,1.964,-1
> 12/29/2006,07:00,1.964,1.96535,1.96385,1.9651,-1
>
>
> I wrote a few lines of R.
>
> Code:
>
> quotes <- read.csv2("GBPUSD-30mn.txt", header = TRUE, sep = ",", dec=".")
> quotes
> names(quotes)
>
>
> The result does not agree me.
> I would like to have the date and time data in a single value.
> The goal is then to display these stock prices as a graph.
>
> Regards,
>
> Pierre8r
>
>
>      ____________________________________________________
> intelligente http://mail.yahoo.fr
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From jeff.a.ryan at gmail.com  Tue Jun 17 19:19:30 2008
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 17 Jun 2008 12:19:30 -0500
Subject: [R-SIG-Finance] How to merge Date and Time in a single value ?
In-Reply-To: <671639.34086.qm@web28106.mail.ukl.yahoo.com>
References: <671639.34086.qm@web28106.mail.ukl.yahoo.com>
Message-ID: <e8e755250806171019k4af9994pf0f3ee881be05262@mail.gmail.com>

Or you can use zoo/xts (substitute zoo() for xts()):


library(xts)
library(quantmod)

quotes <- read.csv2("GBPUSD-30mn.txt", header = TRUE, sep = ",", dec=".")

x <- xts(as.matrix(quotes[,-(1:2)]),as.POSIXct(paste(quotes[,1],quotes[,2]),format='%m/%d/%Y
%H:%M'))

colnames(x) <- c('Open','High','Low','Close','Volume')

barChart(x,TA=NULL)

Jeff

On Tue, Jun 17, 2008 at 11:47 AM,  <pierre8r-list at yahoo.fr> wrote:
> Hello,
>
> I am a newbie with R.
> I try to import stock quotes in R.
>
> Samples stock quotes :
>
> date ,time ,open ,high ,low ,close ,volume
> 12/29/2006,00:00,1.963,1.963,1.96195,1.96195,-1
> 12/29/2006,00:30,1.96195,1.9624,1.96195,1.962,-1
> 12/29/2006,01:00,1.962,1.9622,1.9608,1.961,-1
> 12/29/2006,01:30,1.961,1.9619,1.96095,1.96105,-1
> 12/29/2006,02:00,1.96105,1.96185,1.96105,1.9617,-1
> 12/29/2006,02:30,1.9617,1.9624,1.9616,1.9621,-1
> 12/29/2006,03:00,1.9621,1.96215,1.96155,1.96175,-1
> 12/29/2006,03:30,1.96175,1.96205,1.9615,1.96205,-1
> 12/29/2006,04:00,1.96205,1.9626,1.962,1.96235,-1
> 12/29/2006,04:30,1.96235,1.96305,1.96215,1.96275,-1
> 12/29/2006,05:00,1.96275,1.96345,1.96245,1.96325,-1
> 12/29/2006,05:30,1.96325,1.9639,1.96325,1.96375,-1
> 12/29/2006,06:00,1.96375,1.9647,1.9637,1.9646,-1
> 12/29/2006,06:30,1.9646,1.9657,1.964,1.964,-1
> 12/29/2006,07:00,1.964,1.96535,1.96385,1.9651,-1
>
>
> I wrote a few lines of R.
>
> Code:
>
> quotes <- read.csv2("GBPUSD-30mn.txt", header = TRUE, sep = ",", dec=".")
> quotes
> names(quotes)
>
>
> The result does not agree me.
> I would like to have the date and time data in a single value.
> The goal is then to display these stock prices as a graph.
>
> Regards,
>
> Pierre8r
>
>
>      ____________________________________________________
> intelligente http://mail.yahoo.fr
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From pierre8r-list at yahoo.fr  Tue Jun 17 19:20:55 2008
From: pierre8r-list at yahoo.fr (pierre8r-list at yahoo.fr)
Date: Tue, 17 Jun 2008 17:20:55 +0000 (GMT)
Subject: [R-SIG-Finance] Are there somewhere the examples
	http://www.quantmod.com/examples/ ready to run ?
Message-ID: <86384.35323.qm@web28101.mail.ukl.yahoo.com>


After some try, the samples are not so hard to type.

Thanks Jeff.

Pierre8r




      ____________________________________________________________
ente http://mail.yahoo.fr


From pierre8r-list at yahoo.fr  Tue Jun 17 19:31:42 2008
From: pierre8r-list at yahoo.fr (pierre8r-list at yahoo.fr)
Date: Tue, 17 Jun 2008 17:31:42 +0000 (GMT)
Subject: [R-SIG-Finance] How to merge Date and Time in a single value ?
In-Reply-To: <e8e755250806171019k4af9994pf0f3ee881be05262@mail.gmail.com>
Message-ID: <734957.43381.qm@web28101.mail.ukl.yahoo.com>

Thanks to Jeff Ryan and Gabor Grothendieck.

I only try the R code from Jeff Ryan and it dispays a nice graphics.

Pierre8r


      ____________________________________________________
intelligente http://mail.yahoo.fr


From katchmalik at gmail.com  Tue Jun 17 19:59:25 2008
From: katchmalik at gmail.com (Shlomo Katchmalik)
Date: Tue, 17 Jun 2008 13:59:25 -0400
Subject: [R-SIG-Finance] quantmod data from FRED and Yahoo
Message-ID: <38a7b0c80806171059t34cb81d5pdd80ff5417f317c5@mail.gmail.com>

Hi All,

I'm having trouble using quantmod (one of my favorite packages) to
download forex data from FRED and stock data from Yahoo.

First, using the following commands:

library(quantmod)
getSymbols("DEXUSJP",src="FRED")

I get the following error message:

Error in download.file(paste(FRED.URL, "/", Symbols[[i]], "/",
"downloaddata/",  :
  cannot open URL
'http://research.stlouisfed.org/fred2/series/DEXUSJP/downloaddata/DEXUSJP.csv'
In addition: Warning message:
In download.file(paste(FRED.URL, "/", Symbols[[i]], "/", "downloaddata/",  :
  cannot open: HTTP status was '404 Not Found'

It looks like FRED's url has changed.  Is anyone else having this problem?

Second, using the commands:

library(quantmod)
getSymbols("GOOG")

I get a number of error messages essentially repeating the following:

 In structure(.Internal(as.POSIXct(x, tz)), class = c("POSIXt", "POSIXct"),  :
  unknwon timezone 'XXXST'

where "XXX" is some weird character.

Am I doing something wrong?

Thanks,
Shlomo.
(Using R2.7.0 in Windows).


From jeff.a.ryan at gmail.com  Tue Jun 17 20:09:52 2008
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 17 Jun 2008 13:09:52 -0500
Subject: [R-SIG-Finance] quantmod data from FRED and Yahoo
In-Reply-To: <38a7b0c80806171059t34cb81d5pdd80ff5417f317c5@mail.gmail.com>
References: <38a7b0c80806171059t34cb81d5pdd80ff5417f317c5@mail.gmail.com>
Message-ID: <e8e755250806171109s7621a2caq162900544da93cb7@mail.gmail.com>

Hi Shlomo,

The FRED data is only available as DEXJPUS, see
http://research.stlouisfed.org/fred2/categories/94

Try:

getSymbols("DEXJPUS",src="FRED")

you could also fetch from oanda, though that is a slightly different
data periodicity.

getFX("USD/JPY")
 --or--
getFX("JPY/USD")


As far as the second issue, I am not too sure myself.  Try updating
quantmod, or attaching your sessionInfo() output.  It isn't likely to
be quantmod per se, I would guess it has something to do with your
locale...

Please post as much information about your install as possible (and
requested in the posting guide).

Jeff

On Tue, Jun 17, 2008 at 12:59 PM, Shlomo Katchmalik
<katchmalik at gmail.com> wrote:
> Hi All,
>
> I'm having trouble using quantmod (one of my favorite packages) to
> download forex data from FRED and stock data from Yahoo.
>
> First, using the following commands:
>
> library(quantmod)
> getSymbols("DEXUSJP",src="FRED")
>
> I get the following error message:
>
> Error in download.file(paste(FRED.URL, "/", Symbols[[i]], "/",
> "downloaddata/",  :
>  cannot open URL
> 'http://research.stlouisfed.org/fred2/series/DEXUSJP/downloaddata/DEXUSJP.csv'
> In addition: Warning message:
> In download.file(paste(FRED.URL, "/", Symbols[[i]], "/", "downloaddata/",  :
>  cannot open: HTTP status was '404 Not Found'
>
> It looks like FRED's url has changed.  Is anyone else having this problem?
>
> Second, using the commands:
>
> library(quantmod)
> getSymbols("GOOG")
>
> I get a number of error messages essentially repeating the following:
>
>  In structure(.Internal(as.POSIXct(x, tz)), class = c("POSIXt", "POSIXct"),  :
>  unknwon timezone ' XXXST'
>
> where "XXX" is some weird character.
>
> Am I doing something wrong?
>
> Thanks,
> Shlomo.
> (Using R2.7.0 in Windows).
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From alexander.f.moreno at gmail.com  Wed Jun 18 02:57:54 2008
From: alexander.f.moreno at gmail.com (Alexander Moreno)
Date: Tue, 17 Jun 2008 19:57:54 -0500
Subject: [R-SIG-Finance] portfolio optimization questions
Message-ID: <3303a4570806171757o62aa6781h473b9f4251f4ba77@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080617/ed2d0663/attachment.pl>

From brian at braverock.com  Wed Jun 18 04:30:35 2008
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 17 Jun 2008 21:30:35 -0500 (CDT)
Subject: [R-SIG-Finance] portfolio optimization questions
In-Reply-To: <3303a4570806171757o62aa6781h473b9f4251f4ba77@mail.gmail.com>
References: <3303a4570806171757o62aa6781h473b9f4251f4ba77@mail.gmail.com>
Message-ID: <58233.69.17.21.8.1213756235.squirrel@mail.braverock.com>

Alexander Moreno wrote:
> Hi,
>
> I have a general finance question, rather than an R-specific question.  In
> trading currencies, should the weights always add up to 1, or 0, or can
> they add up to anything?  What determines this?

If you have no leverage (long-only), and are fully invested, then your
weighting vector will add to 1.  If you are 1:1 long/short, then your
weighting vector would add to 0, if you are 50% levered long-only, then
you would have a weighting vector total of 1.5, and so on. Make sense?

> Also, I have an Splus nuopt
> question.  If anyone knows a better place to post this, it would be
> appreciated, but in the meantime I'll ask it here.  In NuOPT, when I set
> mu.target for solveQP to be very low (used as in page 9 of introduction to
> modern portfolio optimization with NuOPT, S-PLUS, and S+Bayes), I see poor
> portfolio returns, but if I set it to be high, I get an error message
> <<SIMPLE 193>> Error in solve():
>        <<NUOPT 2>> infeasible(linear constraints and variable bounds)

This most likely means that there is no portfolio with the target mu.

Regards,

  - Brian


From worik.stanton at gmail.com  Wed Jun 18 04:31:29 2008
From: worik.stanton at gmail.com (Worik)
Date: Wed, 18 Jun 2008 14:31:29 +1200
Subject: [R-SIG-Finance] Are there somewhere the
	examples	http://www.quantmod.com/examples/ ready to run ?
In-Reply-To: <595446.36061.qm@web28102.mail.ukl.yahoo.com>
References: <595446.36061.qm@web28102.mail.ukl.yahoo.com>
Message-ID: <1213756289.7709.34.camel@kupe>

I cannot install the quantmod package.

A required package 'Defaults' could not be found.

I am running ubuntu Hardy Heron.

I had no problems installing the xts package in the same way.

cheers
Worik

worik at alby:~/src/Finance$ sudo R CMD INSTALL quantmod_0.3-6.tar.gz
* Installing to library '/usr/local/lib/R/site-library'
* Installing *source* package 'quantmod' ...
** R
** preparing package for lazy loading
Loading required package: xts
Loading required package: zoo
Loading required package: Defaults
Warning in library(pkg, character.only = TRUE, logical.return = TRUE,
lib.loc = lib.loc) :
  there is no package called 'Defaults'
Error: package 'Defaults' could not be loaded
Execution halted
ERROR: lazy loading failed for package 'quantmod'
** Removing '/usr/local/lib/R/site-library/quantmod'


On Tue, 2008-06-17 at 09:55 +0000, pierre8r-list at yahoo.fr wrote:
> Hello,
> 
> 
> 
> Are there somewhere the examples http://www.quantmod.com/examples/
> 
> ready to run ?
> 
> 
> 
> Thanks,
> 
> 
> 
> Pierre8r
> 
> 
>       _____________________________________________________________________________ 
> 
> o.fr
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.


From jeff.a.ryan at gmail.com  Wed Jun 18 04:40:27 2008
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 17 Jun 2008 21:40:27 -0500
Subject: [R-SIG-Finance] Are there somewhere the examples
	http://www.quantmod.com/examples/ ready to run ?
In-Reply-To: <1213756289.7709.34.camel@kupe>
References: <595446.36061.qm@web28102.mail.ukl.yahoo.com>
	<1213756289.7709.34.camel@kupe>
Message-ID: <e8e755250806171940q7744dbbfg42e4bcf6e9d0cbde@mail.gmail.com>

There is a dependency on Defaults, which is available on CRAN.

http://cran.r-project.org/web/packages/Defaults/index.html

Also mentioned here: http://www.quantmod.com/download/

HTH
Jeff

On Tue, Jun 17, 2008 at 9:31 PM, Worik <worik.stanton at gmail.com> wrote:
> I cannot install the quantmod package.
>
> A required package 'Defaults' could not be found.
>
> I am running ubuntu Hardy Heron.
>
> I had no problems installing the xts package in the same way.
>
> cheers
> Worik
>
> worik at alby:~/src/Finance$ sudo R CMD INSTALL quantmod_0.3-6.tar.gz
> * Installing to library '/usr/local/lib/R/site-library'
> * Installing *source* package 'quantmod' ...
> ** R
> ** preparing package for lazy loading
> Loading required package: xts
> Loading required package: zoo
> Loading required package: Defaults
> Warning in library(pkg, character.only = TRUE, logical.return = TRUE,
> lib.loc = lib.loc) :
>  there is no package called 'Defaults'
> Error: package 'Defaults' could not be loaded
> Execution halted
> ERROR: lazy loading failed for package 'quantmod'
> ** Removing '/usr/local/lib/R/site-library/quantmod'
>
>
> On Tue, 2008-06-17 at 09:55 +0000, pierre8r-list at yahoo.fr wrote:
>> Hello,
>>
>>
>>
>> Are there somewhere the examples http://www.quantmod.com/examples/
>>
>> ready to run ?
>>
>>
>>
>> Thanks,
>>
>>
>>
>> Pierre8r
>>
>>
>>       _____________________________________________________________________________
>>
>> o.fr
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From weihanliu2002 at yahoo.com  Wed Jun 18 05:19:16 2008
From: weihanliu2002 at yahoo.com (Wei-han Liu)
Date: Tue, 17 Jun 2008 20:19:16 -0700 (PDT)
Subject: [R-SIG-Finance] Resampling Methods for Dependent Data
Message-ID: <472972.94523.qm@web53507.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080617/fed2d044/attachment.pl>

From jeff.a.ryan at gmail.com  Wed Jun 18 05:24:50 2008
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 17 Jun 2008 22:24:50 -0500
Subject: [R-SIG-Finance] Resampling Methods for Dependent Data
In-Reply-To: <472972.94523.qm@web53507.mail.re2.yahoo.com>
References: <472972.94523.qm@web53507.mail.re2.yahoo.com>
Message-ID: <e8e755250806172024i32d96d02hb5b56f0c9adf36da@mail.gmail.com>

I would suspect this might be a place to start:

http://finzi.psych.upenn.edu/R/library/boot/html/tsboot.html

RSiteSearch('block bootstrap')

Jeff

On Tue, Jun 17, 2008 at 10:19 PM, Wei-han Liu <weihanliu2002 at yahoo.com> wrote:
> Hi there:
> I am reading a book by Lahiri (2003): Resampling Methods for Dependent Data.  I am trying to implement some of the techniques that book has introduced, e.g. model-based bootstrap, block bootstrap method, and bootstrapping heavy-tailed data and extremes.
> Could somebody share any information helpful in this regard?
>
> Thanks a lot.
> Wei-han Liu
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From markleeds at verizon.net  Wed Jun 18 05:40:22 2008
From: markleeds at verizon.net (Mark Leeds)
Date: Tue, 17 Jun 2008 23:40:22 -0400
Subject: [R-SIG-Finance] portfolio optimization questions
In-Reply-To: <3303a4570806171757o62aa6781h473b9f4251f4ba77@mail.gmail.com>
Message-ID: <000801c8d0f5$09aac2d0$2f01a8c0@coresystem>

Hi: If you want to be market ( I should really say capitalization ) neutral
then the portfolio weights should sum to zero. If you have a fixed target
allocation in dollars that you need to spend and you only are going long, 
( rsther than wanting to be market neutral ) then your portfolio weights
should sum to 1.

I have that book you referred to but not in front of me so I don't
understand your second question .



-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Alexander
Moreno
Sent: Tuesday, June 17, 2008 8:58 PM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] portfolio optimization questions

Hi,

I have a general finance question, rather than an R-specific question.  In
trading currencies, should the weights always add up to 1, or 0, or can they
add up to anything?  What determines this?  Also, I have an Splus nuopt
question.  If anyone knows a better place to post this, it would be
appreciated, but in the meantime I'll ask it here.  In NuOPT, when I set
mu.target for solveQP to be very low (used as in page 9 of introduction to
modern portfolio optimization with NuOPT, S-PLUS, and S+Bayes), I see poor
portfolio returns, but if I set it to be high, I get an error message
<<SIMPLE 193>> Error in solve():
       <<NUOPT 2>> infeasible(linear constraints and variable bounds)

Any help would be much appreciated.

Regards,
Alexander Moreno

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From brian at braverock.com  Wed Jun 18 12:05:03 2008
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 18 Jun 2008 05:05:03 -0500 (CDT)
Subject: [R-SIG-Finance] Resampling Methods for Dependent Data
In-Reply-To: <472972.94523.qm@web53507.mail.re2.yahoo.com>
References: <472972.94523.qm@web53507.mail.re2.yahoo.com>
Message-ID: <47218.69.17.21.8.1213783503.squirrel@mail.braverock.com>

Wei-han Liu wrote:
> I am reading a book by Lahiri (2003): Resampling Methods for Dependent
> Data.  I am trying to implement some of the techniques that book has
> introduced, e.g. model-based bootstrap, block bootstrap method, and
> bootstrapping heavy-tailed data and extremes.
> Could somebody share any information helpful in this regard?

There has been a ton of information posted on this list on bootstrapping
techniques.  I suggest searching the list archive. Jrff has already
suggested the 'tsboot' package, which has been previously discussed here
in some depth.

When you have more specific questions, successes, or failures in your
investigation of these techniques, please share them with the list so
others can benefit from your experience.  Bootstrap techniques are so
important in modern financial analytics that just about anything you
discover (good or bad) will likely be useful to someone else on this list.

Regards,

   - Brian


From weihanliu2002 at yahoo.com  Wed Jun 18 15:19:07 2008
From: weihanliu2002 at yahoo.com (Wei-han Liu)
Date: Wed, 18 Jun 2008 06:19:07 -0700 (PDT)
Subject: [R-SIG-Finance] Resampling Methods for Dependent Data
Message-ID: <540758.91229.qm@web53504.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080618/a250baa0/attachment.pl>

From brian at braverock.com  Wed Jun 18 16:19:48 2008
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 18 Jun 2008 09:19:48 -0500
Subject: [R-SIG-Finance] Resampling Methods for Dependent Data
In-Reply-To: <540758.91229.qm@web53504.mail.re2.yahoo.com>
References: <540758.91229.qm@web53504.mail.re2.yahoo.com>
Message-ID: <48591984.7030107@braverock.com>

Wei-han Liu wrote:
> Hi:
> Yes, I know 'tsboot' package and it is designed to generate resample 
> using fixed or random block lengths. However, I am curious if it can be 
> used to bootstrap heavy-tailed data and extremes.
> Wei-han

Resampling, by definition, only works from the sample available.  If the 
sample has extremes, then the distribution generated by resampling with 
replacement will have heavy tails.  This is a natural result of the rule 
of large numbers...  With a sufficient number of samples, the tails will 
fill out with resampling.

One of the theoretical problems with small initial sample sizes is that 
the tails may not be representative in a resampling context.  If you've 
never seen large loss events, then the distribution resulting from 
resampling may not have heavy tails.  This is why other types of 
analysis are generally employed along with a simple bootstrap such as 
copula or skew-t fitting, or a Monte Carlo simulation with a fat-tailed 
assumption.

Regards,

   - Brian

> ----- Original Message ----
> From: Brian G. Peterson <brian at braverock.com>
> To: Wei-han Liu <weihanliu2002 at yahoo.com>
> Cc: r-sig-finance at stat.math.ethz.ch
> Sent: Wednesday, June 18, 2008 6:05:03 PM
> Subject: Re: [R-SIG-Finance] Resampling Methods for Dependent Data
> 
> Wei-han Liu wrote:
>  > I am reading a book by Lahiri (2003): Resampling Methods for Dependent
>  > Data.  I am trying to implement some of the techniques that book has
>  > introduced, e.g. model-based bootstrap, block bootstrap method, and
>  > bootstrapping heavy-tailed data and extremes.
>  > Could somebody share any information helpful in this regard?
> 
> There has been a ton of information posted on this list on bootstrapping
> techniques.  I suggest searching the list archive. Jrff has already
> suggested the 'tsboot' package, which has been previously discussed here
> in some depth.
> 
> When you have more specific questions, successes, or failures in your
> investigation of these techniques, please share them with the list so
> others can benefit from your experience.  Bootstrap techniques are so
> important in modern financial analytics that just about anything you
> discover (good or bad) will likely be useful to someone else on this list.
> 
> Regards,
> 
>   - Brian
> 
>


From markleeds at verizon.net  Wed Jun 18 19:38:28 2008
From: markleeds at verizon.net (markleeds at verizon.net)
Date: Wed, 18 Jun 2008 12:38:28 -0500 (CDT)
Subject: [R-SIG-Finance] currency weights question
Message-ID: <12928899.11818551213810708356.JavaMail.javamailuser@localhost>

To the person who asked the currency weights question last night. I lost 
your email but I just looked at that book you referred to. It looks
like a  very nice book  but, at a glance, the use of the  word "intro" 
in the title could be deceiving. if you want a somewhat gentler 
introduction
into the ideas behind portfolio optimization/theory you can look at

A) "Active Portfolio Management" by Grinold and Kahn.

B) Any investment text such as  "Investments" by William Sharpe.

C) Jacobs and Levy have a website with some decent intro papers on 
portfolio optimization.


From jh8080 at hotmail.com  Thu Jun 19 00:01:57 2008
From: jh8080 at hotmail.com (Jae Kim)
Date: Wed, 18 Jun 2008 22:01:57 +0000
Subject: [R-SIG-Finance] Resampling Methods for Dependent Data
In-Reply-To: <540758.91229.qm@web53504.mail.re2.yahoo.com>
References: <540758.91229.qm@web53504.mail.re2.yahoo.com>
Message-ID: <BAY108-W44FE737B25598373CDB840CDAB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080618/47a2bc83/attachment.pl>

From max.berger at edhec.com  Thu Jun 19 00:16:44 2008
From: max.berger at edhec.com (berg)
Date: Wed, 18 Jun 2008 15:16:44 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] fPortfolio Constraints Question
Message-ID: <17993195.post@talk.nabble.com>


Hi,

using  fPortfolio (270.74) i did the following optimization, which worked
well:
 
myEstimator <-
    function(x, Spec = NULL, ...) list(
    mu = c(asset1 = 0.1, asset2 = 0.08, asset3 = 0.08, asset4 = 0.045),
    Sigma = cov(y))

Spec <- portfolioSpec() 
setEstimator(Spec) <- "myEstimator"

Constraints = ("LongOnly")
frontier <- portfolioFrontier(y, Spec, Constraints)

Then I changed the Constraints to the following:

Constraints = c("minW[1]=0.1",
                "minW[2]=0.1",
                "minW[3]=0.1",
                "minW[4]=0.1"
                )

With these constraints I received the following error message:

Title:
 MV Portfolio Frontier 
 Estimator: myEstimator 
 Solver:    solveRquadprog 

Portfolio Weights:
Error in round(getWeights(object), digits = 4) : 
  Non-numeric argument to mathematical function

I'd appreciate any help!
Thanks,
max
-- 
View this message in context: http://www.nabble.com/fPortfolio-Constraints-Question-tp17993195p17993195.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From pierre8r-list at yahoo.fr  Mon Jun 23 23:38:06 2008
From: pierre8r-list at yahoo.fr (pierre8r-list at yahoo.fr)
Date: Mon, 23 Jun 2008 21:38:06 +0000 (GMT)
Subject: [R-SIG-Finance] How to remove the error : Error in dimnames(x) <-
	dn : length of 'dimnames' [2] not equal to array extent
Message-ID: <41147.61026.qm@web28102.mail.ukl.yahoo.com>

Hello,


The errors from the console :

> colnames(x) <- c('Open','High','Low','Close','Volume')
Error in dimnames(x) <- dn : 
  length of 'dimnames' [2] not equal to array extent



The complete script :

library(xts)
library(quantmod)
quotes <- read.csv2("K:\\00001-Compare\\Output\\OutputJBacktesting\\Quotes1HOUR.txt", header = FALSE, sep = ",", dec=".")
x <- xts(as.matrix(quotes[,-(1:2)]),as.POSIXct(paste(quotes[,1],quotes[,2]),format='%m/%d/%Y
%H:%M'))

colnames(x) <- c('Open','High','Low','Close','Volume')

barChart(x,TA=NULL)


Thanks,

Pierre8r

Some datas :

01/08/2007 00:59:00,1.930250,1.930350,1.929300,1.929600,-60
01/08/2007 01:59:00,1.929600,1.930100,1.926250,1.928050,-60
01/08/2007 02:59:00,1.928050,1.929700,1.927700,1.927800,-60
01/08/2007 03:59:00,1.927800,1.928350,1.927200,1.928250,-60
01/08/2007 04:59:00,1.928250,1.929600,1.928250,1.929000,-60
01/08/2007 05:59:00,1.929000,1.929250,1.928650,1.929250,-60
01/08/2007 06:59:00,1.929250,1.930850,1.928700,1.930650,-60
01/08/2007 07:59:00,1.930650,1.933100,1.930250,1.933000,-60
01/08/2007 08:59:00,1.933000,1.934350,1.931050,1.931100,-60
01/08/2007 09:59:00,1.931100,1.934750,1.930350,1.934000,-60
01/08/2007 10:59:00,1.934000,1.934650,1.932300,1.932400,-60
01/08/2007 11:59:00,1.932400,1.933500,1.931200,1.933050,-60
01/08/2007 12:59:00,1.933050,1.933850,1.932100,1.933600,-60
01/08/2007 13:59:00,1.933600,1.933750,1.932400,1.933450,-60
01/08/2007 14:59:00,1.933450,1.933600,1.928650,1.929050,-60
01/08/2007 15:59:00,1.929050,1.934600,1.928250,1.934100,-60
01/08/2007 16:59:00,1.934100,1.937350,1.934000,1.934650,-60
01/08/2007 17:59:00,1.934650,1.938650,1.934050,1.938400,-60
01/08/2007 18:59:00,1.938400,1.940500,1.937150,1.937750,-60
01/08/2007 19:59:00,1.937750,1.939350,1.937300,1.937300,-60
01/08/2007 20:59:00,1.937300,1.938700,1.936150,1.937800,-60
01/08/2007 21:59:00,1.937800,1.938400,1.937700,1.937800,-60
01/08/2007 22:59:00,1.937800,1.938150,1.937400,1.937800,-60
01/08/2007 23:58:00,1.938150,1.939250,1.938150,1.939050,-44 





      ____________________________________________________________
ente http://mail.yahoo.fr


From jeff.a.ryan at gmail.com  Tue Jun 24 00:09:34 2008
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 23 Jun 2008 17:09:34 -0500
Subject: [R-SIG-Finance] How to remove the error : Error in dimnames(x)
	<- dn : length of 'dimnames' [2] not equal to array extent
In-Reply-To: <41147.61026.qm@web28102.mail.ukl.yahoo.com>
References: <41147.61026.qm@web28102.mail.ukl.yahoo.com>
Message-ID: <e8e755250806231509t72ba17cdv3812adb18e3f0265@mail.gmail.com>

The issue lies in the data format, this time your time column has both
date _AND_ time in it.  So you need to adjust the xts conversion as
well:

> x <- xts(as.matrix(quotes[,-1]),as.POSIXct(paste(quotes[,1]),format='%m/%d/%Y %H:%M'))

> colnames(x) <- c('Open','High','Low','Close','Volume')

> x
                       Open    High     Low   Close Volume
2007-01-08 00:59:00 1.93025 1.93035 1.92930 1.92960    -60
2007-01-08 01:59:00 1.92960 1.93010 1.92625 1.92805    -60
2007-01-08 02:59:00 1.92805 1.92970 1.92770 1.92780    -60
2007-01-08 03:59:00 1.92780 1.92835 1.92720 1.92825    -60
2007-01-08 04:59:00 1.92825 1.92960 1.92825 1.92900    -60
2007-01-08 05:59:00 1.92900 1.92925 1.92865 1.92925    -60
2007-01-08 06:59:00 1.92925 1.93085 1.92870 1.93065    -60
2007-01-08 07:59:00 1.93065 1.93310 1.93025 1.93300    -60
2007-01-08 08:59:00 1.93300 1.93435 1.93105 1.93110    -60
2007-01-08 09:59:00 1.93110 1.93475 1.93035 1.93400    -60
2007-01-08 10:59:00 1.93400 1.93465 1.93230 1.93240    -60
2007-01-08 11:59:00 1.93240 1.93350 1.93120 1.93305    -60
2007-01-08 12:59:00 1.93305 1.93385 1.93210 1.93360    -60
2007-01-08 13:59:00 1.93360 1.93375 1.93240 1.93345    -60
2007-01-08 14:59:00 1.93345 1.93360 1.92865 1.92905    -60
2007-01-08 15:59:00 1.92905 1.93460 1.92825 1.93410    -60
2007-01-08 16:59:00 1.93410 1.93735 1.93400 1.93465    -60
2007-01-08 17:59:00 1.93465 1.93865 1.93405 1.93840    -60
2007-01-08 18:59:00 1.93840 1.94050 1.93715 1.93775    -60
2007-01-08 19:59:00 1.93775 1.93935 1.93730 1.93730    -60
2007-01-08 20:59:00 1.93730 1.93870 1.93615 1.93780    -60
2007-01-08 21:59:00 1.93780 1.93840 1.93770 1.93780    -60
2007-01-08 22:59:00 1.93780 1.93815 1.93740 1.93780    -60
2007-01-08 23:58:00 1.93815 1.93925 1.93815 1.93905    -44

> barChart(x,TA=NULL)

Jeff


On Mon, Jun 23, 2008 at 4:38 PM,  <pierre8r-list at yahoo.fr> wrote:
> Hello,
>
>
> The errors from the console :
>
>> colnames(x) <- c('Open','High','Low','Close','Volume')
> Error in dimnames(x) <- dn :
>  length of 'dimnames' [2] not equal to array extent
>
>
>
> The complete script :
>
> library(xts)
> library(quantmod)
> quotes <- read.csv2("K:\\00001-Compare\\Output\\OutputJBacktesting\\Quotes1HOUR.txt", header = FALSE, sep = ",", dec=".")
> x <- xts(as.matrix(quotes[,-(1:2)]),as.POSIXct(paste(quotes[,1],quotes[,2]),format='%m/%d/%Y
> %H:%M'))
>
> colnames(x) <- c('Open','High','Low','Close','Volume')
>
> barChart(x,TA=NULL)
>
>
> Thanks,
>
> Pierre8r
>
> Some datas :
>
> 01/08/2007 00:59:00,1.930250,1.930350,1.929300,1.929600,-60
> 01/08/2007 01:59:00,1.929600,1.930100,1.926250,1.928050,-60
> 01/08/2007 02:59:00,1.928050,1.929700,1.927700,1.927800,-60
> 01/08/2007 03:59:00,1.927800,1.928350,1.927200,1.928250,-60
> 01/08/2007 04:59:00,1.928250,1.929600,1.928250,1.929000,-60
> 01/08/2007 05:59:00,1.929000,1.929250,1.928650,1.929250,-60
> 01/08/2007 06:59:00,1.929250,1.930850,1.928700,1.930650,-60
> 01/08/2007 07:59:00,1.930650,1.933100,1.930250,1.933000,-60
> 01/08/2007 08:59:00,1.933000,1.934350,1.931050,1.931100,-60
> 01/08/2007 09:59:00,1.931100,1.934750,1.930350,1.934000,-60
> 01/08/2007 10:59:00,1.934000,1.934650,1.932300,1.932400,-60
> 01/08/2007 11:59:00,1.932400,1.933500,1.931200,1.933050,-60
> 01/08/2007 12:59:00,1.933050,1.933850,1.932100,1.933600,-60
> 01/08/2007 13:59:00,1.933600,1.933750,1.932400,1.933450,-60
> 01/08/2007 14:59:00,1.933450,1.933600,1.928650,1.929050,-60
> 01/08/2007 15:59:00,1.929050,1.934600,1.928250,1.934100,-60
> 01/08/2007 16:59:00,1.934100,1.937350,1.934000,1.934650,-60
> 01/08/2007 17:59:00,1.934650,1.938650,1.934050,1.938400,-60
> 01/08/2007 18:59:00,1.938400,1.940500,1.937150,1.937750,-60
> 01/08/2007 19:59:00,1.937750,1.939350,1.937300,1.937300,-60
> 01/08/2007 20:59:00,1.937300,1.938700,1.936150,1.937800,-60
> 01/08/2007 21:59:00,1.937800,1.938400,1.937700,1.937800,-60
> 01/08/2007 22:59:00,1.937800,1.938150,1.937400,1.937800,-60
> 01/08/2007 23:58:00,1.938150,1.939250,1.938150,1.939050,-44
>
>
>
>
>
>      ____________________________________________________________
> ente http://mail.yahoo.fr
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From ggrothendieck at gmail.com  Tue Jun 24 00:14:08 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 23 Jun 2008 18:14:08 -0400
Subject: [R-SIG-Finance] How to remove the error : Error in dimnames(x)
	<- dn : length of 'dimnames' [2] not equal to array extent
In-Reply-To: <41147.61026.qm@web28102.mail.ukl.yahoo.com>
References: <41147.61026.qm@web28102.mail.ukl.yahoo.com>
Message-ID: <971536df0806231514q274b07c8t93444d4cf570b4d4@mail.gmail.com>

Try this and look at ?read.zoo in the zoo package for more info

Lines <- "01/08/2007 00:59:00,1.930250,1.930350,1.929300,1.929600,-60
01/08/2007 01:59:00,1.929600,1.930100,1.926250,1.928050,-60
01/08/2007 02:59:00,1.928050,1.929700,1.927700,1.927800,-60
01/08/2007 03:59:00,1.927800,1.928350,1.927200,1.928250,-60
01/08/2007 04:59:00,1.928250,1.929600,1.928250,1.929000,-60
01/08/2007 05:59:00,1.929000,1.929250,1.928650,1.929250,-60
01/08/2007 06:59:00,1.929250,1.930850,1.928700,1.930650,-60
01/08/2007 07:59:00,1.930650,1.933100,1.930250,1.933000,-60
01/08/2007 08:59:00,1.933000,1.934350,1.931050,1.931100,-60
01/08/2007 09:59:00,1.931100,1.934750,1.930350,1.934000,-60
01/08/2007 10:59:00,1.934000,1.934650,1.932300,1.932400,-60
01/08/2007 11:59:00,1.932400,1.933500,1.931200,1.933050,-60
01/08/2007 12:59:00,1.933050,1.933850,1.932100,1.933600,-60
01/08/2007 13:59:00,1.933600,1.933750,1.932400,1.933450,-60
01/08/2007 14:59:00,1.933450,1.933600,1.928650,1.929050,-60
01/08/2007 15:59:00,1.929050,1.934600,1.928250,1.934100,-60
01/08/2007 16:59:00,1.934100,1.937350,1.934000,1.934650,-60
01/08/2007 17:59:00,1.934650,1.938650,1.934050,1.938400,-60
01/08/2007 18:59:00,1.938400,1.940500,1.937150,1.937750,-60
01/08/2007 19:59:00,1.937750,1.939350,1.937300,1.937300,-60
01/08/2007 20:59:00,1.937300,1.938700,1.936150,1.937800,-60
01/08/2007 21:59:00,1.937800,1.938400,1.937700,1.937800,-60
01/08/2007 22:59:00,1.937800,1.938150,1.937400,1.937800,-60
01/08/2007 23:58:00,1.938150,1.939250,1.938150,1.939050,-44
"

library(quantmod)
# replace first arg with "myfile.csv"
z <- read.zoo(textConnection(Lines), sep = ",",
 tz = "", format = "%m/%d/%Y %H:%M:%S",
 col.names = c('Datetime', 'Open', 'High', 'Low', 'Close', 'Volume'))

x <- as.xts(z)
barChart(x, TA = NULL)




On Mon, Jun 23, 2008 at 5:38 PM,  <pierre8r-list at yahoo.fr> wrote:
> Hello,
>
>
> The errors from the console :
>
>> colnames(x) <- c('Open','High','Low','Close','Volume')
> Error in dimnames(x) <- dn :
>  length of 'dimnames' [2] not equal to array extent
>
>
>
> The complete script :
>
> library(xts)
> library(quantmod)
> quotes <- read.csv2("K:\\00001-Compare\\Output\\OutputJBacktesting\\Quotes1HOUR.txt", header = FALSE, sep = ",", dec=".")
> x <- xts(as.matrix(quotes[,-(1:2)]),as.POSIXct(paste(quotes[,1],quotes[,2]),format='%m/%d/%Y
> %H:%M'))
>
> colnames(x) <- c('Open','High','Low','Close','Volume')
>
> barChart(x,TA=NULL)
>
>
> Thanks,
>
> Pierre8r
>
> Some datas :
>
> 01/08/2007 00:59:00,1.930250,1.930350,1.929300,1.929600,-60
> 01/08/2007 01:59:00,1.929600,1.930100,1.926250,1.928050,-60
> 01/08/2007 02:59:00,1.928050,1.929700,1.927700,1.927800,-60
> 01/08/2007 03:59:00,1.927800,1.928350,1.927200,1.928250,-60
> 01/08/2007 04:59:00,1.928250,1.929600,1.928250,1.929000,-60
> 01/08/2007 05:59:00,1.929000,1.929250,1.928650,1.929250,-60
> 01/08/2007 06:59:00,1.929250,1.930850,1.928700,1.930650,-60
> 01/08/2007 07:59:00,1.930650,1.933100,1.930250,1.933000,-60
> 01/08/2007 08:59:00,1.933000,1.934350,1.931050,1.931100,-60
> 01/08/2007 09:59:00,1.931100,1.934750,1.930350,1.934000,-60
> 01/08/2007 10:59:00,1.934000,1.934650,1.932300,1.932400,-60
> 01/08/2007 11:59:00,1.932400,1.933500,1.931200,1.933050,-60
> 01/08/2007 12:59:00,1.933050,1.933850,1.932100,1.933600,-60
> 01/08/2007 13:59:00,1.933600,1.933750,1.932400,1.933450,-60
> 01/08/2007 14:59:00,1.933450,1.933600,1.928650,1.929050,-60
> 01/08/2007 15:59:00,1.929050,1.934600,1.928250,1.934100,-60
> 01/08/2007 16:59:00,1.934100,1.937350,1.934000,1.934650,-60
> 01/08/2007 17:59:00,1.934650,1.938650,1.934050,1.938400,-60
> 01/08/2007 18:59:00,1.938400,1.940500,1.937150,1.937750,-60
> 01/08/2007 19:59:00,1.937750,1.939350,1.937300,1.937300,-60
> 01/08/2007 20:59:00,1.937300,1.938700,1.936150,1.937800,-60
> 01/08/2007 21:59:00,1.937800,1.938400,1.937700,1.937800,-60
> 01/08/2007 22:59:00,1.937800,1.938150,1.937400,1.937800,-60
> 01/08/2007 23:58:00,1.938150,1.939250,1.938150,1.939050,-44
>
>
>
>
>
>      ____________________________________________________________
> ente http://mail.yahoo.fr
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From swtzang at gmail.com  Tue Jun 24 09:46:16 2008
From: swtzang at gmail.com (ShyhWeir Tzang)
Date: Tue, 24 Jun 2008 15:46:16 +0800
Subject: [R-SIG-Finance] Multiplicative error model ?
Message-ID: <c17037a10806240046r105f80e0g6a7ac5f772717412@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080624/1725d06d/attachment.pl>

From chalabi at phys.ethz.ch  Tue Jun 24 20:04:10 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Tue, 24 Jun 2008 20:04:10 +0200
Subject: [R-SIG-Finance] [R-sig-finance] fPortfolio Constraints Question
In-Reply-To: <17993195.post@talk.nabble.com>
References: <17993195.post@talk.nabble.com>
Message-ID: <20080624200410.5121b335@mimi>

>>>> "B" == berg <max.berger at edhec.com>
>>>> on Wed, 18 Jun 2008 15:16:44 -0700 (PDT)

   B> myEstimator <-
   B>     function(x, Spec = NULL, ...) list(
   B>     mu = c(asset1 = 0.1, asset2 = 0.08, asset3 = 0.08, asset4 = 0.045),
   B>     Sigma = cov(y))

I would say that your mu is not a good idea and that the optimization does
not converge to a solution.

try with mu = colMeans(x) and see if it works.

note you can use the R function "traceback()" and then play around in
debug() mode to find out where the problem is.

regards,
Yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From hongchux at gmail.com  Thu Jun 26 13:23:07 2008
From: hongchux at gmail.com (Hongchuan Xia)
Date: Thu, 26 Jun 2008 13:23:07 +0200
Subject: [R-SIG-Finance] Error in QRMlib
Message-ID: <2f7adeb90806260423t761d2425ve16239b3ffb20a86@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080626/cf8e4a23/attachment.pl>

From chalabi at phys.ethz.ch  Thu Jun 26 13:46:24 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Thu, 26 Jun 2008 13:46:24 +0200
Subject: [R-SIG-Finance] Error in QRMlib
In-Reply-To: <2f7adeb90806260423t761d2425ve16239b3ffb20a86@mail.gmail.com>
References: <2f7adeb90806260423t761d2425ve16239b3ffb20a86@mail.gmail.com>
Message-ID: <20080626134624.45760bf3@mimi>

>>>> "HX" == "Hongchuan Xia" <hongchux at gmail.com>
>>>> on Thu, 26 Jun 2008 13:23:07 +0200

   HX> Hi,
   HX> 
   HX> I can not get the desired result if I running the example code from QRMlib
   HX> user manual:
   HX> 
   HX> -------------------------------------------
   HX> 
   HX> data(nasdaq);
   HX> > nreturns <- -mk.returns(nasdaq);
   HX> > monthly.maxima <- aggregateMonthlySeries(nreturns,FUN=max);  
   HX> Error in aggregateMonthlySeries(nreturns, FUN = max) :
   HX>   no slot of name "Dim" for this object of class "timeDate"
   HX> > monthly.maxima <- seriesData(monthly.maxima)  
   HX> Error in seriesData(monthly.maxima) : object "monthly.maxima" not found
   HX> > mod1 <- fit.GEV(monthly.maxima);  
   HX> Error in var(maxima) : object "monthly.maxima" not found
   HX> 
   HX> --------------------------------------------
   HX> 
   HX> The following content is the prompt message after I running debug
   HX> (ggregateMonthlySeries)
   HX> 
   HX> ----------------------------------------------
   HX> > monthly.maxima <- aggregateMonthlySeries(nreturns,FUN=max);  
   HX> debugging in: aggregateMonthlySeries(nreturns, FUN = max)
   HX> debug: {
   HX>   if (!is.timeSeries(timeseries))
   HX>   stop("timeseries must be of the timeSeries class from fCalendar package")
   HX>   charvecStartDate <- timeseries at positions[1]
   HX>   charvecLastDate <- timeseries at positions[length(timeseries at positions)]
   HX>   dateFormat = "%Y-%m-%d"
   HX>   test1 <- as.character(timeFirstDayInMonth(charvecStartDate))
   HX>   test2 <- as.character(timeFirstDayInMonth(charvecLastDate))
   HX>   from3 = timeSequence(from = test1, to = test2, by = "month",
   HX>   format = dateFormat)
   HX>   test3 <- as.character(timeLastDayInMonth(charvecStartDate))
   HX>   test4 <- as.character(timeLastDayInMonth(charvecLastDate))
   HX>   to3 = timeSequence(from = test3, to = test4, by = "month",
   HX>   format = dateFormat)
   HX>   monthsLength <- to3 at Dim
   HX>   repetitions <- as.integer(monthsLength/12)
   HX>   remainder <- monthsLength - 12 * repetitions
   HX>   firstDayInMonthYr <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
   HX>   monthNumbers <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11)
   HX>   lastMonthDayStdYr <- c(31, 28, 31, 30, 31, 30, 31, 31, 30,
   HX>   31, 30, 31)
   HX>   lastDayVector <- rep(lastMonthDayStdYr, time = repetitions)
   HX>   if (remainder > 0)
   HX>   lastDayVector <- c(lastDayVector, lastMonthDayStdYr[1:remainder])
   HX>   monthVector <- rep(monthNumbers, times = repetitions)
   HX>   if (remainder > 0)
   HX>   monthVector <- c(monthVector, monthNumbers[1:remainder])
   HX>   ltest <- strptime(to3 at Data, "%Y-%m-%d")
   HX>   ltest$mday <- lastDayVector
   HX>   ltest$mon <- monthVector
   HX>   for (iter in 1:monthsLength) {
   HX>   if (leap.year(ltest$year[iter] + 1900) && (ltest$mon[iter] ==
   HX>   1))
   HX>   ltest$mday[iter] <- 29
   HX>   }
   HX>   to3 at Data[] <- ltest
   HX>   applySeries(timeseries, from3, to3, by = "monthly", FUN = FUNC)
   HX> }
   HX> Browse[1]> monthly.maxima <- seriesData(monthly.maxima)  
   HX> Error in seriesData(monthly.maxima) : object "monthly.maxima" not found
   HX> Browse[1]> mod1 <- fit.GEV(monthly.maxima);  
   HX> ------------------------------------------------------
   HX> 
   HX> How can we get the desired result?
   HX> 
   HX> Appreciate a lot!
   HX> 
   HX> Best,
   HX> 
   HX> Hong


This is due to a change in timeDate class where the slot @Dim was
removed. One should use length("timeDate") instead of accessing directly
the slot.

I CC the maintainer of QRMlib.

regards,
Yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From hongchux at gmail.com  Fri Jun 27 15:08:47 2008
From: hongchux at gmail.com (Hongchuan Xia)
Date: Fri, 27 Jun 2008 15:08:47 +0200
Subject: [R-SIG-Finance] Bond valuation
Message-ID: <2f7adeb90806270608h6d162ec6x6b3296d611208b3d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080627/574b1a92/attachment.pl>

From brian at braverock.com  Fri Jun 27 15:48:37 2008
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 27 Jun 2008 08:48:37 -0500
Subject: [R-SIG-Finance] Bond valuation
In-Reply-To: <2f7adeb90806270608h6d162ec6x6b3296d611208b3d@mail.gmail.com>
References: <2f7adeb90806270608h6d162ec6x6b3296d611208b3d@mail.gmail.com>
Message-ID: <4864EFB5.9050507@braverock.com>

Hongchuan Xia wrote:
> Does R offer any package can calculate the duration of bond?

The duration of a bond is specified in the bond issue, it is not 
calculated.  So perhaps your question is not as clear as you might like?

So, I'll guess:

The R package 'termstrc' contains a number of functions for calculating 
metrics related to bonds such as the term structure of interest rates. 
It also contains some functionality which can be used to calculate the 
effective duration of a portfolio of bonds.

Regards,

   - Brian


From pdebruic at gmail.com  Fri Jun 27 16:12:52 2008
From: pdebruic at gmail.com (Paul DeBruicker)
Date: Fri, 27 Jun 2008 10:12:52 -0400
Subject: [R-SIG-Finance] Bond valuation
In-Reply-To: <4864EFB5.9050507@braverock.com>
References: <2f7adeb90806270608h6d162ec6x6b3296d611208b3d@mail.gmail.com>
	<4864EFB5.9050507@braverock.com>
Message-ID: <f2e3401f0806270712s796b965x1495a198f199dba@mail.gmail.com>

I thought duration varied with market interest rates, time to
maturity, coupon rate and the affect of any embedded options in the
bond as in the formulas cited on this page:

http://en.wikipedia.org/wiki/Bond_duration

Specifically the section on Macaulay duration & effective duration


To the question, I know of no R packages that provide a function to
calculate duration.  Maybe fBonds will when released.

Paul


On Fri, Jun 27, 2008 at 9:48 AM, Brian G. Peterson <brian at braverock.com> wrote:
> Hongchuan Xia wrote:
>>
>> Does R offer any package can calculate the duration of bond?
>
> The duration of a bond is specified in the bond issue, it is not calculated.
>  So perhaps your question is not as clear as you might like?
>
> So, I'll guess:
>
> The R package 'termstrc' contains a number of functions for calculating
> metrics related to bonds such as the term structure of interest rates. It
> also contains some functionality which can be used to calculate the
> effective duration of a portfolio of bonds.
>
> Regards,
>
>  - Brian
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From cwrward at gmail.com  Fri Jun 27 16:31:40 2008
From: cwrward at gmail.com (Charles Ward)
Date: Fri, 27 Jun 2008 15:31:40 +0100
Subject: [R-SIG-Finance] Bond valuation
In-Reply-To: <f2e3401f0806270712s796b965x1495a198f199dba@mail.gmail.com>
References: <2f7adeb90806270608h6d162ec6x6b3296d611208b3d@mail.gmail.com>	<4864EFB5.9050507@braverock.com>
	<f2e3401f0806270712s796b965x1495a198f199dba@mail.gmail.com>
Message-ID: <4864F9CC.8020600@gmail.com>

Duration calculation is indeed contained in termstrc

The entry is given as...

duration {termstrc}

The function calculates the Macauly duration, modified duration and 
duration based weights.
Usage
duration(cf_p, m_p, y)

Arguments
cf_p     cashflows matrix including the prices of the bonds.
m_p     maturity matrix, the first row is filled with zeros.
y     yields of the bonds.


Charles Ward


Paul DeBruicker wrote:
> I thought duration varied with market interest rates, time to
> maturity, coupon rate and the affect of any embedded options in the
> bond as in the formulas cited on this page:
>
> http://en.wikipedia.org/wiki/Bond_duration
>
> Specifically the section on Macaulay duration & effective duration
>
>
> To the question, I know of no R packages that provide a function to
> calculate duration.  Maybe fBonds will when released.
>
> Paul
>
>
> On Fri, Jun 27, 2008 at 9:48 AM, Brian G. Peterson <brian at braverock.com> wrote:
>   
>> Hongchuan Xia wrote:
>>     
>>> Does R offer any package can calculate the duration of bond?
>>>       
>> The duration of a bond is specified in the bond issue, it is not calculated.
>>  So perhaps your question is not as clear as you might like?
>>
>> So, I'll guess:
>>
>> The R package 'termstrc' contains a number of functions for calculating
>> metrics related to bonds such as the term structure of interest rates. It
>> also contains some functionality which can be used to calculate the
>> effective duration of a portfolio of bonds.
>>
>> Regards,
>>
>>  - Brian
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>>     
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From rory.winston at gmail.com  Sat Jun 28 18:15:03 2008
From: rory.winston at gmail.com (Rory Winston)
Date: Sat, 28 Jun 2008 17:15:03 +0100
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 49, Issue 13
In-Reply-To: <mailman.1.1214647202.4943.r-sig-finance@stat.math.ethz.ch>
References: <mailman.1.1214647202.4943.r-sig-finance@stat.math.ethz.ch>
Message-ID: <48666387.4090008@gmail.com>

No, it was a valid question. I think you are confusing bond "duration" 
with bond "maturity".

Rory.
> The duration of a bond is specified in the bond issue, it is not 
> calculated.  So perhaps your question is not as clear as you might like?
>
>


From alberthz at stanford.edu  Sun May  4 22:49:39 2008
From: alberthz at stanford.edu (Albert Zhuo Huang)
Date: Sun, 04 May 2008 20:49:39 -0000
Subject: [R-SIG-Finance] For fCalendar timeDate object, howto get year, month,
	day, dayofweek, dayofmonth, dayofyear, hour, minutes, second?
Message-ID: <e6d785640805041349o5a4fd641g377e31e005cb1dea@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080504/9c75d966/attachment.pl>

From ana.cunha.martins at caixaseguros.pt  Fri May  9 16:54:17 2008
From: ana.cunha.martins at caixaseguros.pt (Ana Patricia Silva Cunha Martins (DGR))
Date: Fri, 09 May 2008 14:54:17 -0000
Subject: [R-SIG-Finance]   HJM models (Forward Rates)
Message-ID: <8A3C325D0840894BA8F5C532F9553D24046309FB@GCXJXXIEXMS303.fidelidademundial.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080509/16515fd8/attachment.pl>

From vfulco1 at gmail.com  Mon May 19 02:02:44 2008
From: vfulco1 at gmail.com (Vince Fulco)
Date: Mon, 19 May 2008 00:02:44 -0000
Subject: [R-SIG-Finance] Quantmod: Managing lists of instruments...
Message-ID: <34f2770f0805181702u65fb89d8x76613f7191b11725@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080519/eaab6a5d/attachment.pl>

From k.umair at lancaster.ac.uk  Fri May 30 13:28:47 2008
From: k.umair at lancaster.ac.uk (k.umair at lancaster.ac.uk)
Date: Fri, 30 May 2008 11:28:47 -0000
Subject: [R-SIG-Finance] arfimaoxfit.ox and arfimaoxpredict.ox file needed
Message-ID: <15257.89.242.175.106.1212146905.squirrel@webmail01.lancs.ac.uk>

Hello dear All
hope you all will be fine and ok
i want to inquire about one thing if you can guied me through this if
possibel.
i have installed the fArma package in R but its has a cmmand to use which
is arfimaOxFit. for which we need to install the Ox package and do afew
thing which all i have done using the help from the fArma package Pdf help
guied from the R cran home page but there is a problem. they says to copy
ArfimaOxFit.ox and ArfimaOxPredict.ox from the directory "fSeries/data/"
but i am unable to find these two files any where in any package and even
on onternet, what can i do with it .


i hope i can get a valuable advice from you
if it is possible that you can send me these two files in attachement that
will be very nice

thanking in anticipation

Regards
Umair


From s_a_i_l at hotmail.com  Wed Jun 18 01:53:34 2008
From: s_a_i_l at hotmail.com (Bill_Jones)
Date: Tue, 17 Jun 2008 16:53:34 -0700 (PDT)
Subject: [R-SIG-Finance] [R-sig-finance] economagicImport problem
Message-ID: <17957076.post@talk.nabble.com>


I am trying to import a medical CPI index using fImport.  The command I tried
is:  
MED <- economagicImport(query = "blscu/CUUR0000SAM", source =
'http://www.economagic.com/em-cgi/data.exe/', frequency = "monthly", colname
= "CPI").  It sort of works but it seems to have a problem reading the data
because it only returns data through 2007-11-01 when there is data all the
way to 2008-05-01.  If I go directly to the series at
http://www.economagic.com/em-cgi/data.exe/blscu/CUUR0000SAM, the entire
series is there.  

I am able to read the general CPI data from FRED using the quantmod library
getSymbols command but FRED only has a couple of CPI indicies.  Any ideas?  
Thanks!
Bill

-- 
View this message in context: http://www.nabble.com/economagicImport-problem-tp17957076p17957076.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From Shinya.Watanuki at jp.kantargroup.com  Mon May 26 06:21:41 2008
From: Shinya.Watanuki at jp.kantargroup.com (Shinya.Watanuki at jp.kantargroup.com)
Date: Mon, 26 May 2008 04:21:41 -0000
Subject: [R-SIG-Finance] Duan GARCH model
Message-ID: <5988F51F73C039419EF7D713FC89FC090D19FF@KTTKYXCH001A.kt.group.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080526/635b635c/attachment.pl>

From mail at financedevelopmentcentre.com  Thu May 29 09:27:50 2008
From: mail at financedevelopmentcentre.com (mail at financedevelopmentcentre.com)
Date: Thu, 29 May 2008 07:27:50 -0000
Subject: [R-SIG-Finance] [SPAM] Re: R-project can help me ? Building a
	portfolio..
In-Reply-To: <20080529092043.25666a23@mimi>
References: <mailman.3.1211968801.31354.r-sig-finance@stat.math.ethz.ch>
	<BAY116-W47BEA6C62D13EA2CDF8984A3BC0@phx.gbl>
	<20080529092043.25666a23@mimi>
Message-ID: <9f792cf3241d8423be2647e56cbd6453@financedevelopmentcentre.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080529/1a86c57f/attachment.pl>

From jessen at econinfo.de  Wed May 21 18:42:35 2008
From: jessen at econinfo.de (Owe Jessen)
Date: Wed, 21 May 2008 16:42:35 -0000
Subject: [R-SIG-Finance] Thinking about Risk Budgeting and
	Portfolio	Construction
In-Reply-To: <4833FC77.6040000@braverock.com>
References: <4833FC77.6040000@braverock.com>
Message-ID: <483451A9.8050302@econinfo.de>

Brian G. Peterson schrieb:
> We're getting ready to start a journal article/paper on risk budgeting 
> and portfolio construction utilizing component risk metrics.  I'd like 
> some input from the r-sig-finance community on what types of questions 
> in this space you feel are under-served in the literature.
>
> Specifically, we plan to examine how utilizing the sub-additive risks 
> of each component of the portfolio (and optimizing the portfolio based 
> on these) differs in out-of-sample performance from traditional risk 
> budgeting methods which simply pick the target variance portfolio on 
> the efficient frontier.
>
> So, I'd like *your* input.  What questions do you have about risk 
> budgeting portfolio construction methods?  What areas are poorly 
> covered in the literature?  Are there any papers or references that 
> you think we should read before starting out?
>
> Thanks!
>
> Regards,
>
>    - Brian
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>
Just kidding: I'd be curious in which way one had to twist the 
portfolios of CDOs that portfolios consisting of subrime-market-loans 
could end up getting AAA-ratings.

Or maybe only halfway kidding, I just suppose this is not what you have 
in mind with your paper.

Regards,
Owe

-- 
Owe Jessen
Diplom-Volkswirt
Von-der-Horst-Str. 9 
24118 Kiel

jessen at econinfo.de
http://www.econinfo.de


From david.merritt at bris.ac.uk  Wed Jun 11 13:40:22 2008
From: david.merritt at bris.ac.uk (DavidM.UK)
Date: Wed, 11 Jun 2008 11:40:22 -0000
Subject: [R-SIG-Finance] [R-sig-finance] Demystification of GARCH
	modeling with fGarch
In-Reply-To: <20080605101957.5b91deaa@mimi>
References: <20080605101957.5b91deaa@mimi>
Message-ID: <17775532.post@talk.nabble.com>


The choice of distribution is relatively straight forward I'd say, in the
Econometric literature it tends to be either a standardized Student's-t
distribution [Bollerslev did a paper on it if I recall] or the standard
normal distribution. As a practical measure, I don't think you could do much
better than using qq.plot() from the "car" library for diagnostics, of
course you might just look at the histrogram plot of the returns to see if
their are heavy tails though (hist(x, br="FD") is my usual approach there).

For initial parameter estimates, I'm not sure it's a real issue, doesn't
fGarch take care of that for you. I think MATLAB's GARCH Toolbox and
RMetrics set \alpha_{i=1}^{p} = \frac{0.05}{p} and \beta_{j=1}^{q} =
\frac{0.85}{q} . I tend to use those setting with my own GARCH models and
they're generally "okay".

You might want to cover how to assess the fit of your estimated GARCH model,
paying attention to the kurtosis and skewness statistics (routines to
calculate both are in the e1071 package). As I'm sure you know, a strong
negative skew probably means you'll have more sucess with something like
GJR-GARCH. If the kurtosis is massively high (which you'll get if you
looking at intraday data) there's not that much you can do about it (well
it's what I work on) but I guess depending on your objective you might try
and remove some of the extremes/outliers before estimating your model, I
think fExtremes might have some useful stuff in that area.

Scaling the data is an interesting one, and a common cause of failure during
the opitmization stage in my view. I tend to scale raw logged returns by 10,
and intraday data by 100, but that's a rather random approach by me :) I'd
definitely suggest you get a range of data, and not just use the
EuStockMarkets series, for me I'd present GARCH modeling for intraday, daily
and indice data, and they are quite different.

Unfortunately the data I'm using can't be shared, but I'm sure there are
others out their that see fGarch fail with 
>my.garch <- garchFit(data=x, forumla=~garch(1,1)) 
where x are logged returns and the garchFit seems to get stuck in a loop,
with the only solution to quit R (on Linux this is). 

It might be worth giving a few examples of the different types of
optimization routines you can use, I don't tend to use RMetrics code - but
the way my code works is pretty much the same, and I generally get faster
convergence with nlminb() over optim(), and fGarch is generally quicker than
my code anyhow. Does it have some sort of SQP routine?

Cheers

David


Yohan Chalabi wrote:
> 
> Dear all,
> 
> I am working on a tutorial which would focus on the  common issues in
> GARCH/APARCH modeling. The idea is to give hints how to choose the
> optimization parameters,  the starting values, the distribution and how to
> properly scale the data.
> 
> This tutorial is meant to be very practical and I would like to have some
> input from the r-sig-finance community. If you have examples where
> garchFit badly failed for you, it would be great if you could send me your
> dataset with the R code you used. If you have any other comments or
> questions about fGarch, feel free to write me. 
> 
> 
> 
> 
> Thanks!
> 
> Regards,
> Yohan
> 
> -- 
> PhD student
> Swiss Federal Institute of Technology
> Zurich
> 
> www.ethz.ch
> www.rmetrics.org
> 
> NOTE:
> Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
> June 29th - July 3rd Meielisalp, Lake Thune, Switzerland
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
> 
> 

-- 
View this message in context: http://www.nabble.com/Demystification-of-GARCH-modeling-with-fGarch-tp17664671p17775532.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From fmarangoni at libero.it  Sun Jun 15 14:25:44 2008
From: fmarangoni at libero.it (Francesco Marangoni)
Date: Sun, 15 Jun 2008 14:25:44 +0200
Subject: [R-SIG-Finance]  Cox, Ingersoll,
 Ross/Vasicek parameter  estimation via Kalman-Filter (SSPIR)
Message-ID: <484D2FE800DC9B0B@> (added by postmaster@cp-out10.libero.it)

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080615/98f0f38d/attachment.pl>

From ctb at stern.nyu.edu  Tue Jun 24 16:12:07 2008
From: ctb at stern.nyu.edu (Christian Brownlees)
Date: Tue, 24 Jun 2008 10:12:07 -0400 (EDT)
Subject: [R-SIG-Finance] Multiplicative error model ?
Message-ID: <9587318.167231214316727716.JavaMail.root@calliope.stern.nyu.edu>


I'm actually working on package for R called dynamo which allows to
estimate univaraite MEMs. 

The package is on CRAN but on windows there are some CRAN dependent linking
problems which have to be solved.

However, I have a version of the package for windows that runs.

The packages is still under development but estimation, inference, prediction, simulation of the model
are already there more or less.

Best,
Christian

> Dear all:
> 
> Does anyone know whether the multiplicative error mode (MEM) is implemented
> in R or other languages? I tried to write the program but got non-converging
> problems. I checked the paper in :
> www.core.ucl.ac.be/archives/CORE.ETRICSfiles/2005-06/gallo.pdf
> But I found that the stuff there seems too complicated for me to handle.
> Can anyone give a hint here? Thanks for help of any kind.
> 
> ShyhWeir
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From NadiaT at investec.co.za  Fri May  9 16:37:43 2008
From: NadiaT at investec.co.za (Nadia Theron)
Date: Fri, 09 May 2008 14:37:43 -0000
Subject: [R-SIG-Finance] (no subject)
Message-ID: <CFC96762674FB94AA7EB3A67CA772DE7657C9D@mbzajhb06.za.corp.investec.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080509/87811725/attachment.pl>

From yyamada1 at uoregon.edu  Thu Apr 10 19:14:48 2008
From: yyamada1 at uoregon.edu (Yukihiro yamada)
Date: Thu, 10 Apr 2008 17:14:48 -0000
Subject: [R-SIG-Finance] Question: ACD?
Message-ID: <1207847673.384893.alphamail@mailapps1.uoregon.edu>

Hello everyone, 

Is it possible to perform "Autoregressive Conditional Duration" (ACD) in R? 
I'm a graduate student at U of Oregon and want to use ACD in my research project. 
Please advise. 

Best, 

Yuki


From edd at debian.org  Sat Jun 28 19:34:36 2008
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 28 Jun 2008 12:34:36 -0500
Subject: [R-SIG-Finance] Administrivia
Message-ID: <18534.30252.826785.765352@ron.nulle.part>


I just flushed the list of pending messages, getting rid of the spam and
accepting messages from non-subscribers that had been held for appropval.

So, no, the list is not broken, I just don't flush the queue all that often.

Dirk, wearing his list-admin hat

-- 
Three out of two people have difficulties with fractions.


From ggrothendieck at gmail.com  Sat Jun 28 19:51:29 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 28 Jun 2008 13:51:29 -0400
Subject: [R-SIG-Finance] Solicitation of opinions on which Timeseries
	object(s) to utilize.
In-Reply-To: <4796BE50.7040707@aol.com>
References: <fmvquf$9hm$1@ger.gmane.org> <20080121183539.GB12556@piskorski.com>
	<4796BE50.7040707@aol.com>
Message-ID: <971536df0806281051i3001bab8k88f7ae803d5cafbd@mail.gmail.com>

On Wed, Jan 23, 2008 at 12:10 AM, Joe W. Byers <ecjbosu at aim.com> wrote:
> The certain problems with timeDate objects of Rmetrics is one of the
> reasons I posted this question.  I have found that even though you can
> give the timeSeries a financial center and a zone, the underlying
> timeDate object still defaults to GMT.  I have to pass or set the
> tz='EST5EDT' or something like that to get the correct numerical time
> integers.  I have not quite figured this one out yet.  This may also be
> an underlying problem with other timeseries packages but I thought
> determining the "best" timeseries package before progressing further was
> a better course .
>

Actually this only is about the time index and that may be unrelated to the
time series package.  For example, zoo uses just about any time index
as long as the class supports certain methods so whether or not a particular
time index class is any good may be an orthogonal question.  Its only for
time series classes that have hard coded which time indexes can be used
with them that that might be a consideration.

e.g.

library(zoo)

dts <- c("1989-09-28", "2001-01-15", "2004-08-30", "1990-02-09")

# zoo object with "timeDate" class index
library(fSeries)
zoo(11:14, timeDate(dts))

# zoo object with "Date" class index
zoo(11:14, as.Date(dts))

# zoo object with "POSIXct" class index
zoo(11:14, as.POSIXct(dts))

# zoo object with chron "dates" class index
library(chron)
zoo(11:14, chron(dts, format = "y-m-d"))

# zoo object with "numeric" index
# using number of days since Epoch
zoo(11:14, as.numeric(as.Date(dts)))

# zoo object with "character" class as index
zoo(11:14, dts)


From seancarmody at gmail.com  Sat Jun 28 23:55:50 2008
From: seancarmody at gmail.com (Sean Carmody)
Date: Sun, 29 Jun 2008 07:55:50 +1000
Subject: [R-SIG-Finance] [R-sig-finance] [R] Bloomberg Data Import to R
In-Reply-To: <47A2B9DE.4010101@soundinvest.net>
References: <47A2B9DE.4010101@soundinvest.net>
Message-ID: <ce6bbb9d0806281455j30cb1594s5306a8235e3df229@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080629/cb581231/attachment.pl>

From armstrong.whit at gmail.com  Sun Jun 29 01:33:21 2008
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Sat, 28 Jun 2008 19:33:21 -0400
Subject: [R-SIG-Finance] [R-sig-finance] timeDate conversion [C1]
In-Reply-To: <16176711.post@talk.nabble.com>
References: <OF33BEE4EA.17F1467C-ONC12573E0.005006CB-C12573E0.0052689B@fr.world.socgen>
	<16176711.post@talk.nabble.com>
Message-ID: <8ec76080806281633s61ff8a8ke3b06b94672dd676@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080628/deefaeb0/attachment.pl>

From armstrong.whit at gmail.com  Sun Jun 29 01:38:45 2008
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Sat, 28 Jun 2008 19:38:45 -0400
Subject: [R-SIG-Finance] Quantmod: Managing lists of instruments...
In-Reply-To: <34f2770f0805181702u65fb89d8x76613f7191b11725@mail.gmail.com>
References: <34f2770f0805181702u65fb89d8x76613f7191b11725@mail.gmail.com>
Message-ID: <8ec76080806281638x28f4e7f0re2f749859bb66870@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080628/5753fa05/attachment.pl>

From finbref.2006 at gmail.com  Sun Jun 29 13:20:10 2008
From: finbref.2006 at gmail.com (Thomas Steiner)
Date: Sun, 29 Jun 2008 13:20:10 +0200
Subject: [R-SIG-Finance] HJM models (Forward Rates)
In-Reply-To: <8A3C325D0840894BA8F5C532F9553D24046309FB@GCXJXXIEXMS303.fidelidademundial.com>
References: <8A3C325D0840894BA8F5C532F9553D24046309FB@GCXJXXIEXMS303.fidelidademundial.com>
Message-ID: <d0f55a670806290420j588863x9e86c3fcee0d6e37@mail.gmail.com>

You asked this question already on may 28, right?
http://www.nabble.com/HJM-model-(Interest-rate)-td17544218.html
thomas



2008/5/9 Ana Patricia Silva Cunha Martins (DGR)
<ana.cunha.martins at caixaseguros.pt>:
> All users,
>
>
>
> Although my basic training is in statistics, I've little knowledge about interest rates models, and it was suggested Cox-Ingersoll-Ross process, Ornstein-Uhlenbeck or Vasicek process or Heath-Jarrow-Morton methods.
>
>
>
> Does anyone know if exist HJM model in R? I can't find....
>
> The CIR model was considered, however based on the observed data (1998-2007) doesn't works.
>
>
>
> Does anyone can suggest a package or other models?
>
> Thanks in advance your help.
>
> Best regards
>
> Ana Patr?cia
>
>
>        [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>


From ryan.sheftel at malbecpartners.com  Sun Jun 29 19:00:04 2008
From: ryan.sheftel at malbecpartners.com (ryan.sheftel at malbecpartners.com)
Date: Sun, 29 Jun 2008 13:00:04 -0400
Subject: [R-SIG-Finance] Experience of large scale use of R in
	financial	services
In-Reply-To: <59C6D502E2521141B9F6C3D857FB24BA0DBB19@becxoex03.corp.kpmgconsulting.com>
Message-ID: <OF72F45E12.A57A7080-ON85257477.005D3E67-85257477.005D6613@malbecpartners.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080629/c3f1a4e4/attachment.pl>

From dutt.debashis at gmail.com  Sun Jun 29 19:16:40 2008
From: dutt.debashis at gmail.com (Debashis Dutta)
Date: Sun, 29 Jun 2008 20:16:40 +0300
Subject: [R-SIG-Finance] Experience of large scale use of R in financial
	services
In-Reply-To: <OF72F45E12.A57A7080-ON85257477.005D3E67-85257477.005D6613@malbecpartners.com>
References: <59C6D502E2521141B9F6C3D857FB24BA0DBB19@becxoex03.corp.kpmgconsulting.com>
	<OF72F45E12.A57A7080-ON85257477.005D3E67-85257477.005D6613@malbecpartners.com>
Message-ID: <37673c2d0806291016n2985cd82v9a784b466e8590a3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080629/a73589fa/attachment.pl>

From ryan.sheftel at malbecpartners.com  Sun Jun 29 19:23:48 2008
From: ryan.sheftel at malbecpartners.com (ryan.sheftel at malbecpartners.com)
Date: Sun, 29 Jun 2008 13:23:48 -0400
Subject: [R-SIG-Finance] Experience of large scale use of R in financial
 services
In-Reply-To: <37673c2d0806291016n2985cd82v9a784b466e8590a3@mail.gmail.com>
Message-ID: <OF395CEEBB.6098762E-ON85257477.005F44C4-85257477.005F9246@malbecpartners.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080629/6ddb9624/attachment.pl>

From jp at anet.com  Sun Jun 29 22:43:20 2008
From: jp at anet.com (John Pederson)
Date: Sun, 29 Jun 2008 15:43:20 -0500
Subject: [R-SIG-Finance] Dummy / Indicator Variable
Message-ID: <000001c8da28$c4b432f0$0b6c010a@John>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20080629/161e8ab0/attachment.pl>

From peter at braverock.com  Mon Jun 30 05:32:14 2008
From: peter at braverock.com (Peter Carl)
Date: Sun, 29 Jun 2008 22:32:14 -0500
Subject: [R-SIG-Finance] [R-sig-finance] chart.Histogram differences
	between PerformanceAnalytics 9.5 and 9.6
In-Reply-To: <15655891.post@talk.nabble.com>
References: <15655891.post@talk.nabble.com>
Message-ID: <200806292232.14305.peter@braverock.com>

On Saturday 23 February 2008 1:10:12 pm EdNel wrote:
> I've encountered two differences between versions 9.5 and 9.6 in the
> results I get for of the chart.Histogram function :
>
> i) The y axis (density) limits are fixed at 0,10 but they used to follow
> the default behaviour of the plot function and adjust to accomodate the
> maximum value
>
> ii) I get lots of warnings like this :
> "In VaR.CornishFisher(x, p = p) :
>   Cornish-Fisher Expansion produces unreliable result (risk over 100%) for
> column: 1 : 6.21173467258483"
> I assume the function is calculating VaRs though (methods =
> c("add.density","add.centered")), I'm not actually using them.
>
> Are these bugs or are there parameters I can change to get the 9.5
> behaviour back?
>
> Thanks.

Despite the fact that this message got plugged in the pipe for a while, it's 
still worth pointing out a couple of things.  First, if you have a question 
on the PerformanceAnalytics package, please feel free to send it to Brian 
(who is listed as the maintainer in the package documentation).  We value 
your feedback and will always try to respond in a timely fashion.

Second, the warnings you got were likely because you were representing the 
return data as percentages (6.01%) rather than decimals (.0601).

The y-axis behavior in 0.9.6 isn't ideal, and I've had a fix for it waiting 
for release 0.9.7 (which should be released in the next couple of weeks).  
I've attached the function below.  The behavior of the y-axis should be 
better now, but let either of us know if you feel otherwise.

pcc

-- 
Peter Carl
145 Scottswood Rd
Riverside, IL 60546
312 307 6346
http://www.braverock.com/~peter
-------------- next part --------------
`chart.Histogram` <-
function(R, breaks="FD", main = NULL, xlab = "Returns", ylab = "Frequency", methods = c("none","add.density", "add.normal", "add.centered", "add.cauchy", "add.sst", "add.rug", "add.risk", "add.qqplot"), show.outliers = TRUE, colorset = c("lightgray", "#00008F", "#005AFF", "#23FFDC", "#ECFF13", "#FF4A00", "#800000"), border.col = "white", lwd = 2, xlim = NULL, ylim = NULL, elementcolor="gray", note.lines = NULL, note.labels = NULL, note.cex = 0.7, note.color = "darkgray", probability = FALSE, p=0.99, ...)
{ # @author Peter Carl

    # DESCRIPTION:

    # Create a histogram of returns, with optional curve fits for density
    # and normal

    # Inputs:
    # R = usually a set of monthly return

    # Code inspired by a chart on:
    # http://zoonek2.free.fr/UNIX/48_R/03.html

    y = checkData(R)
    x = checkData(na.omit(y[,1]), method="vector")

    columns = ncol(y)
    rows = nrow(y)
    columnnames = colnames(y)
    n=length(x)
    rangedata = 0

    if(is.null(main)){
        main = columnnames[1]
    }

    if(is.null(methods) || methods[1]=="none"){
        methods = NULL
    }

#     xlim = range(qnorm(0.001, mean(x), stdev(x)), qnorm(0.999, mean(x), stdev(x)), note.lines, b)
    if(show.outliers)
        rangedata = c(min(x),max(x))
    else
        rangedata =  c(qnorm(0.001, mean(x), sd(x)), qnorm(0.999, mean(x), sd(x)))
    if(!is.null(note.lines)) {
        rangedata = c(rangedata,note.lines)
    }

    if("add.risk" %in% method){
        b = c(-VaR.CornishFisher(x,p=p),-VaR.traditional(x,p=p))
        b.labels = c(paste(p*100,"% ModVaR",sep=" "),paste(p*100,"% VaR",sep=""))
        rangedata = c(rangedata,b)
    }

    yrange = 0

    if(is.null(xlim))
        xlim = range(rangedata)

     s = seq(xlim[1], xlim[2], length = 500)
#     s = seq(min(x, na.rm=TRUE), max(x, na.rm=TRUE), length = 500)

    # Things to do before the plot is drawn
    for (method in methods) {
        switch(method,
            add.density = {
                # Show density estimate
                den = density(x, n=length(x))
                yrange=c(yrange,max(den$y))
                 probability = TRUE
            },
            add.stable = {
                stopifnot("package:fBasics" %in% search() || require("fBasics",quietly=TRUE))
                fit.stable = stableFit(x,doplot = FALSE)
                fitted.stable = dstable(s,alpha = fit.stable at fit$estimate[[1]], beta = fit.stable at fit$estimate[[2]], gamma = fit.stable at fit$estimate[[3]], delta = fit.stable at fit$estimate[[4]], pm = 0)
                # look at documentation for pm
                yrange=c(yrange,max(fitted.stable))
                probability = TRUE
            },
            add.cauchy = {
                # requires library(MASS)
                stopifnot("package:MASS" %in% search() || require("MASS",quietly=TRUE))

                # This uses a Maximum Likelihood method as shown on:
                # Wessa P., (2006), Maximum-likelihood Cauchy Distribution Fitting (v1.0.0) in
                # Free Statistics Software (v1.1.21-r4), Office for Research Development and
                # Education, URL http://www.wessa.net/rwasp_fitdistrcauchy.wasp/
                fit = fitdistr(x, 'cauchy')
                xlab = paste("Cauchy (location = ",round(fit$estimate[[1]],2),", scale = ",round(fit$estimate[[2]],2),")", sep="")
                fitted.cauchy = dcauchy(s,location = fit$estimate[[1]], scale = fit$estimate[[2]], log = FALSE)
                yrange=c(yrange,max(fitted.cauchy))
                probability = TRUE
            },
            add.sst = {
#               requires library(sn)
                stopifnot("package:sn" %in% search() || require("sn",quietly=TRUE))

                fit = st.mle(y=x)
                fitted.sst = dst(s, location = fit$dp[[1]], scale = fit$dp[[2]], shape = fit$dp[[3]], df=fit$dp[[4]], log = FALSE)
                yrange=c(yrange,max(fitted.sst))
                probability = TRUE
            },
            add.lnorm = {
                fit = fitdistr(1+x,'log-normal')
                fitted.lnorm = dlnorm(1+s, meanlog = fit$estimate[[1]], sdlog = fit$estimate[[2]], log = FALSE)
                yrange=c(yrange,max(fitted.lnorm))
                probability = TRUE
            },
            add.normal = {
                fitted.normal = dnorm(s, mean(x), sd(x))
                yrange=c(yrange,max(fitted.normal))
                probability = TRUE
            },
            add.centered = {
                fitted.centered = dnorm(s, 0, sd(x))
                yrange=c(yrange,max(fitted.centered))
                probability = TRUE
            },
            add.risk = {
                #
            }
        )
    }

    # Draw the plot
    if(probability == TRUE) maxyhist = max(hist(x, breaks = breaks, plot = FALSE)$density)
    else maxyhist = max(hist(x, breaks = breaks, plot = FALSE)$count)
    yrange = c(yrange, maxyhist*1.1)
    ylim = c(0,ceiling(max(yrange)))

    hist(x = x, probability = probability, xlim = xlim, ylim = ylim, col = colorset[1], border = border.col, xlab = xlab, main = main, breaks = breaks, axes = FALSE, ...)
    axis(1, col = elementcolor)
    axis(2, col = elementcolor)

    box(col=elementcolor)

    # Things to do after the plot is drawn
    for (method in methods) {
        switch(method,
            add.density = {
                # Show density estimate
                lines(den, col = colorset[2], lwd = lwd)
            },
            add.normal = {
                # Show normal distribution around the mean
                lines(s, fitted.normal, col = colorset[3], lwd = lwd)
            },
            add.centered = {
                # Show normal distribution around 0
                lines(s, fitted.centered, col = colorset[3], lwd = lwd)
            },
            add.lnorm = {
                # Show normal distribution around the mean
                lines(s, fitted.lnorm, col = colorset[4], lwd = lwd)
            },
            add.cauchy = {
                lines(s, fitted.cauchy, col = colorset[4], lwd=lwd)
            },
            add.stable = {
                lines(s, fitted.stable, col = colorset[4], lwd=lwd)
            },
            add.sst = { #requires package sn
                lines(s, fitted.sst, col = colorset[4], lwd=lwd)
            },
            add.rug = {
                rug(x, col = elementcolor)
            },
            add.risk = {
                h = rep(.2*par("usr")[3] + 1*par("usr")[4], length(b))
#                points(b, h, type='h', col='red',lwd=3)
#                points(b, h, col='red', lwd=3)
                abline(v = b, col = "darkgray", lty=2)
                text(b, h, b.labels, offset = .2, pos = 2, cex = 0.8, srt=90)
            },
             add.qqplot = {
                op <- par(no.readonly=TRUE)
                op1 <- par(fig=c(.02,.5,.5,.98), new=TRUE)
                qqnorm(x, xlab="", ylab="", main="", axes=FALSE, pch=".",col=colorset[2])
                qqline(x, col=colorset[3])
                box(col=elementcolor)
                par(op)
             }
        ) # end switch
    } # end for

    # Draw and label arbitrary lines
    if(!is.null(note.lines)) {
        #number.note.labels = ((length(note.labels)-length(note.ind) + 1):length(note.labels))

        abline(v = note.lines, col = note.color, lty = 2)
        if(!is.null(note.labels)) {
            h = rep(.2*par("usr")[3] + 0.99*par("usr")[4], length(b))
            text(note.lines, h, note.labels, offset = .2, pos = 2, cex = note.cex, srt = 90, col = note.color)

        }
    }
#                 abline(v = b, col = "darkgray", lty=2)
#                 text(b, h, b.labels, offset = .2, pos = 2, cex = 0.8, srt=90)

}

###############################################################################
# R (http://r-project.org/) Econometrics for Performance and Risk Analysis
#
# Copyright (c) 2004-2008 Peter Carl and Brian G. Peterson
#
# This library is distributed under the terms of the GNU Public License (GPL)
# for full details see the file COPYING
#
# $Id: chart.Histogram.R,v 1.35 2008-06-30 03:10:57 peter Exp $
#
###############################################################################
# $Log: chart.Histogram.R,v $
# Revision 1.35  2008-06-30 03:10:57  peter
# - VaR not calculated without 'add.risk' method
# - x-axis correctly adjusted with 'add.risk' method
# - chart reset correctly after 'qq.plot' method
#
# Revision 1.34  2008-06-26 02:00:01  peter
# - changed 'stdev' to 'sd'
#
# Revision 1.32  2008-06-23 02:35:10  peter
# - added note line text size attribute
# - added check for 'sn' library
#
# Revision 1.31  2008-06-02 16:05:19  brian
# - update copyright to 2004-2008
#
# Revision 1.30  2008/01/15 21:06:13  peter
# - fixed ylim for probability T or F
#
# Revision 1.28  2007/12/29 19:25:09  brian
# - minor changes to pass R CMD check
#
# Revision 1.27  2007/12/27 20:11:19  peter
# - fixed F for FALSE in function call
#
# Revision 1.24  2007/11/23 04:28:01  peter
# - added margin to histogram bars for ylim
#
# Revision 1.17  2007/11/19 03:40:46  peter
# - smoothed out the density line for smaller data sets
# - added parameter for showing all data points rather than center
#
# Revision 1.16  2007/09/26 03:33:12  peter
# - no longer clobbers xlim when passed in from function
#
# Revision 1.14  2007/09/18 03:24:07  peter
# - default for methods is now NULL
#
# Revision 1.13  2007/09/14 02:04:56  peter
# - commented need for adding MASS as a dependency
#
# Revision 1.12  2007/08/24 04:02:51  peter
# - labels now work for note.lines
#
# Revision 1.11  2007/08/24 03:54:54  peter
# - added arbitrary lines and labels
# - labeling doesn't work yet
#
# Revision 1.10  2007/08/24 03:18:08  peter
# - added cauchy fit
#
# Revision 1.9  2007/08/24 01:43:04  peter
# - beautified format of vertical lines for add.risk
#
# Revision 1.8  2007/06/17 21:42:34  brian
# - update /usage and /items to pass check
#
# Revision 1.7  2007/06/07 23:42:00  brian
# - add comments
#
# Revision 1.6  2007/04/30 12:51:38  peter
# - fixed F instead of FALSE error
#
# Revision 1.5  2007/04/27 03:25:00  peter
# - added risk lines
#
# Revision 1.4  2007/04/27 03:08:22  peter
# - added switch
# - added qqchart
# - added rug
#
# Revision 1.3  2007/04/15 12:56:04  brian
# - add breaks as an explicit parameter
#
# Revision 1.2  2007/02/07 13:24:49  brian
# - fix pervasive comment typo
#
# Revision 1.1  2007/02/02 19:06:15  brian
# - Initial Revision of packaged files to version control
# Bug 890
#
###############################################################################

From guillaume.nicoulaud at halbis.com  Mon Jun 30 09:37:14 2008
From: guillaume.nicoulaud at halbis.com (guillaume.nicoulaud at halbis.com)
Date: Mon, 30 Jun 2008 09:37:14 +0200
Subject: [R-SIG-Finance] Bloomberg / rcom
Message-ID: <OFC06F19B7.778439B3-ONC1257478.0028E9CC-C1257478.0029DC6E@hsbc.fr>


Dear all,

I've been using RBloomberg for a while and it used to work fairly well but since a few months the Gui crashes with blpConnect()... I gave a look to the code to see what happened: it creates the COM object but reading or setting any of its
properties causes the Gui to crash.
Did anyone met the same issue? If yes, have you found a way to fix it ?

Many thanks,
G


Les informations contenues dans ce message sont confidentielles et peuvent constituer des informations privilegiees. Si vous n etes pas le destinataire de ce message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d en utiliser tout ou partie. Si vous avez recu ce message par erreur, merci de le supprimer de votre systeme, ainsi que toutes ses copies, et d en avertir immediatement l expediteur par message de retour.
Il est impossible de garantir que les communications par messagerie electronique arrivent en temps utile, sont securisees ou denuees de toute erreur ou virus. En consequence, l expediteur n accepte aucune responsabilite du fait des erreurs ou omissions qui pourraient en resulter.
--- ----------------------------------------------------- ---
The information contained in this e-mail is confidential...{{dropped:3}}


From robert at sanctumfi.com  Mon Jun 30 12:34:42 2008
From: robert at sanctumfi.com (Robert Sams)
Date: Mon, 30 Jun 2008 11:34:42 +0100
Subject: [R-SIG-Finance] [R-sig-finance] [R] Bloomberg Data Import to R
References: <47A2B9DE.4010101@soundinvest.net>
	<SANCTUMFISERVER8i0B0000231a@sanctumfi.com>
Message-ID: <SANCTUMFISERVERuQuN00002455@sanctumfi.com>

Hi Marcin,

I've never run across this problem but then I never throw hundreds of tickers into a single API request. I have heard many times that the API does seem to choke unpredictably when large calls are made, so I suspect it's a bloomberg problem, despite what they tell you. Can you successfully perform your 900 ticker request using the Excel interface? If you can't, go back to bloomberg. If you can, send me your R code (that chokes) and your .xls file (that works) and I'll look into it.

But Sean's suggestion is the most sensible approach; break your big call up into smaller calls. This will not only improve reliability on the RBloomberg side of things, it is also the approach that the R community recommends for dealing with large datasets. 

Robert

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Sean Carmody
Sent: 28 June 2008 22:56
To: marcin.kopaczynski at soundinvest.net
Cc: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] [R-sig-finance] [R] Bloomberg Data Import to R

Marcin,

While I have not seen this problem with the R Bloomberg package, I have certainly seen something similar with large calls to the Bloomberg API from Excel. For some reason, the API seemed to choke if it received "too many"
data requests. I never had any luck getting clarification from Bloomberg as to the limits of the API and only got around the problem by breaking my problem into smaller requests. In your case, you might need to loop through say 100 stocks or so at a time. In any event, it is certainly worth testing whether your code works with a smaller number than 900.

Regards,
Sean.

On Fri, Feb 1, 2008 at 4:19 PM, Marcin Kopaczynski < marcin.kopaczynski at soundinvest.net> wrote:

> hi robert,
>
> i?ve got a problem with the bloomberg data import. usually all works 
> well, but sometimes it seems that nothing is downloaded at all from bloomberg.
>
> example: i wanted to download px_last for 900 us-stocks beginning with
> 19900101 (giving him the appropriate chron-date format). the download 
> starts, the downloaded data is stored and written out to a file. new 
> data is being concatenated with the old data (column by column) until 
> all 900 stocks are downloaded. during this process the download breaks 
> down, and the strange thing is, that it does happen SOMETIMES and not 
> at the same place (i.e. not at stock number 390, but at number 401 at 
> one time and 789 at other time). sometimes it does not happen at all. 
> also, when i resume the download, i.e. tell him to download the data 
> from where he stopped, it then works.
>
> so i checked the functions in your package and the problem really 
> seems to be with the download itself. what happens is: in the function 
> <blpGetHistoricalData> the object <lst> is NULL. this makes the 
> command "attr(lst, "num.of.date.cols")  <- 1" to throw an error, 
> because he is not able to assign an attribute to a NULL object:
> "attr(lst, "num.of.date.cols") <- 1 : attempt to set an attribute on NULL".
> the object <lst> becomes then a data.frame of the dimension 
> [0:number.of.tickers], which obviously is not what one would expect to get.
>
> my question is: have you ever experienced such a problem? the problem 
> seems to become more probable, the more data one downloads from bloomberg.
>
> here are some infos on my environment:
>
> R 2.5.1
> windows xp on the bloomberg terminal
> chron 2.3.16
> RBloomberg 0.1-10
> RDCOMClient 0.91-0
> zoo 1.4-2
>
> i?ve been talking to bloomberg about this problem, as well. they 
> assured me that it is not about the amount of data i was downloading. 
> so there must be something else.
>
> thx in advance for your help,
>
> marcin
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>

	[[alternative HTML version deleted]]


From chalabi at phys.ethz.ch  Mon Jun 30 14:38:00 2008
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Mon, 30 Jun 2008 14:38:00 +0200
Subject: [R-SIG-Finance] arfimaoxfit.ox and arfimaoxpredict.ox file
 needed
In-Reply-To: <15257.89.242.175.106.1212146905.squirrel@webmail01.lancs.ac.uk>
References: <15257.89.242.175.106.1212146905.squirrel@webmail01.lancs.ac.uk>
Message-ID: <20080630143800.263e3822@mimi>

>>>> "KUAU" == k.umair at lancaster.ac.uk
>>>> on Fri, 30 May 2008 12:28:25 +0100 (BST)

   KUAU> Hello dear All
   KUAU> hope you all will be fine and ok
   KUAU> i want to inquire about one thing if you can guied me through this if
   KUAU> possibel.
   KUAU> i have installed the fArma package in R but its has a cmmand to use which
   KUAU> is arfimaOxFit. for which we need to install the Ox package and do afew
   KUAU> thing which all i have done using the help from the fArma package Pdf help
   KUAU> guied from the R cran home page but there is a problem. they says to copy
   KUAU> ArfimaOxFit.ox and ArfimaOxPredict.ox from the directory "fSeries/data/"
   KUAU> but i am unable to find these two files any where in any package and even
   KUAU> on onternet, what can i do with it .


the Ox interface is old code and will be deprecated in the next release.

But if you are interested to use it, you are very welcome to update it. 
And we will be glad to give you advices to do so.

The manual page you referred to is outdated and will be corrected in the
next release. 


regards,
yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch
www.rmetrics.org

NOTE:
Rmetrics Workshop: http://www.rmetrics.org/meielisalp.htm
June 29th - July 3rd Meielisalp, Lake Thune, Switzerland


From davidr at rhotrading.com  Mon Jun 30 15:31:30 2008
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Mon, 30 Jun 2008 08:31:30 -0500
Subject: [R-SIG-Finance] [R-sig-finance] [R] Bloomberg Data Import to R
In-Reply-To: <SANCTUMFISERVERuQuN00002455@sanctumfi.com>
References: <47A2B9DE.4010101@soundinvest.net><SANCTUMFISERVER8i0B0000231a@sanctumfi.com>
	<SANCTUMFISERVERuQuN00002455@sanctumfi.com>
Message-ID: <F9F2A641C593D7408925574C05A7BE77010C69EF@rhopost.rhotrading.com>

I'll have to throw in my two cents' worth here, too, while agreeing with Sean and Robert.
I have seen the bbcomm.exe act flakey for larger calls. If you can reproduce it in VBA,
you might have a shot with Bloomberg help, emphasizing the VBA aspect to get it to the right
people. However, it seems much less work to break the call into several calls that have
a better chance of working.

David L. Reiner, PhD
Head Quant
Rho Trading Securities, LLC


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Robert Sams
Sent: Monday, June 30, 2008 5:35 AM
To: Sean Carmody; marcin.kopaczynski at soundinvest.net
Cc: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] [R-sig-finance] [R] Bloomberg Data Import to R

Hi Marcin,

I've never run across this problem but then I never throw hundreds of tickers into a single API request. I have heard many times that the API does seem to choke unpredictably when large calls are made, so I suspect it's a bloomberg problem, despite what they tell you. Can you successfully perform your 900 ticker request using the Excel interface? If you can't, go back to bloomberg. If you can, send me your R code (that chokes) and your .xls file (that works) and I'll look into it.

But Sean's suggestion is the most sensible approach; break your big call up into smaller calls. This will not only improve reliability on the RBloomberg side of things, it is also the approach that the R community recommends for dealing with large datasets. 

Robert

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Sean Carmody
Sent: 28 June 2008 22:56
To: marcin.kopaczynski at soundinvest.net
Cc: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] [R-sig-finance] [R] Bloomberg Data Import to R

Marcin,

While I have not seen this problem with the R Bloomberg package, I have certainly seen something similar with large calls to the Bloomberg API from Excel. For some reason, the API seemed to choke if it received "too many"
data requests. I never had any luck getting clarification from Bloomberg as to the limits of the API and only got around the problem by breaking my problem into smaller requests. In your case, you might need to loop through say 100 stocks or so at a time. In any event, it is certainly worth testing whether your code works with a smaller number than 900.

Regards,
Sean.

On Fri, Feb 1, 2008 at 4:19 PM, Marcin Kopaczynski < marcin.kopaczynski at soundinvest.net> wrote:

> hi robert,
>
> i?ve got a problem with the bloomberg data import. usually all works 
> well, but sometimes it seems that nothing is downloaded at all from bloomberg.
>
> example: i wanted to download px_last for 900 us-stocks beginning with
> 19900101 (giving him the appropriate chron-date format). the download 
> starts, the downloaded data is stored and written out to a file. new 
> data is being concatenated with the old data (column by column) until 
> all 900 stocks are downloaded. during this process the download breaks 
> down, and the strange thing is, that it does happen SOMETIMES and not 
> at the same place (i.e. not at stock number 390, but at number 401 at 
> one time and 789 at other time). sometimes it does not happen at all. 
> also, when i resume the download, i.e. tell him to download the data 
> from where he stopped, it then works.
>
> so i checked the functions in your package and the problem really 
> seems to be with the download itself. what happens is: in the function 
> <blpGetHistoricalData> the object <lst> is NULL. this makes the 
> command "attr(lst, "num.of.date.cols")  <- 1" to throw an error, 
> because he is not able to assign an attribute to a NULL object:
> "attr(lst, "num.of.date.cols") <- 1 : attempt to set an attribute on NULL".
> the object <lst> becomes then a data.frame of the dimension 
> [0:number.of.tickers], which obviously is not what one would expect to get.
>
> my question is: have you ever experienced such a problem? the problem 
> seems to become more probable, the more data one downloads from bloomberg.
>
> here are some infos on my environment:
>
> R 2.5.1
> windows xp on the bloomberg terminal
> chron 2.3.16
> RBloomberg 0.1-10
> RDCOMClient 0.91-0
> zoo 1.4-2
>
> i?ve been talking to bloomberg about this problem, as well. they 
> assured me that it is not about the amount of data i was downloading. 
> so there must be something else.
>
> thx in advance for your help,
>
> marcin
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only.
> -- If you want to post, subscribe first.
>

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only.
-- If you want to post, subscribe first.


From pierre8r-list at yahoo.fr  Mon Jun 30 22:12:17 2008
From: pierre8r-list at yahoo.fr (pierre8r-list at yahoo.fr)
Date: Mon, 30 Jun 2008 20:12:17 +0000 (GMT)
Subject: [R-SIG-Finance] Hourly quotations from 1 minutes quotations.
Message-ID: <453388.71856.qm@web28103.mail.ukl.yahoo.com>

Hello,

I am trying to do 5 minutes quotations and to hourly quotations.
>From 1 minute quotations.
I wrote a script that does not work.

Thank you in advance,

Pierre8r

Here's my script that does not work:

library(xts)
library(quantmod)

quotes <- read.csv2("E:\\00001-Compare\\Import\\ImportIB\\TestGBPUSD-1mn.txt",
header = TRUE, sep = ",", dec=".")

q1mn <- xts(as.matrix(quotes[,-(1:2)]),as.POSIXct(paste(quotes[,1],quotes[,2]),
format='%m/%d/%Y%H:%M'))

colnames(q1mn) <- c('Open','High','Low','Close','Volume')

q5mns <- q1mn
to.minutes5(q5mns)

qHourly <- q1mn
to.hourly(qHourly)

barChart(q1mn,TA=NULL)
barChart(q5mns,TA=NULL)
barChart(qHourly,TA=NULL)


Some datas :

01/08/2007,00:00,1.93025,1.93025,1.93015,1.9302,-1
01/08/2007,00:01,1.9302,1.9302,1.93015,1.9302,-1
01/08/2007,00:02,1.9302,1.93025,1.9302,1.9302,-1
01/08/2007,00:03,1.9302,1.93025,1.9302,1.9302,-1
01/08/2007,00:04,1.9302,1.93025,1.9302,1.9302,-1
01/08/2007,00:05,1.9302,1.93025,1.9302,1.9302,-1
01/08/2007,00:06,1.9302,1.93025,1.93015,1.93015,-1
01/08/2007,00:07,1.93015,1.93025,1.93015,1.9302,-1
01/08/2007,00:08,1.9302,1.93035,1.9302,1.9303,-1
01/08/2007,00:09,1.9303,1.9303,1.9303,1.9303,-1
01/08/2007,00:10,1.9303,1.9303,1.9303,1.9303,-1
01/08/2007,00:11,1.9303,1.9303,1.9303,1.9303,-1
01/08/2007,00:12,1.9303,1.9303,1.9302,1.9302,-1
01/08/2007,00:13,1.9302,1.9302,1.9302,1.9302,-1
01/08/2007,00:14,1.9302,1.9302,1.9302,1.9302,-1
01/08/2007,00:15,1.9302,1.9302,1.9302,1.9302,-1
01/08/2007,00:16,1.9302,1.9302,1.9302,1.9302,-1
01/08/2007,00:17,1.9302,1.9302,1.9302,1.9302,-1
01/08/2007,00:18,1.9302,1.9302,1.9302,1.9302,-1
01/08/2007,00:19,1.9302,1.9302,1.9302,1.9302,-1
01/08/2007,00:20,1.9302,1.9302,1.9302,1.9302,-1
01/08/2007,00:21,1.9302,1.9302,1.9302,1.9302,-1
01/08/2007,00:22,1.9302,1.9302,1.9302,1.9302,-1
01/08/2007,00:23,1.9302,1.9302,1.9302,1.9302,-1
01/08/2007,00:24,1.9302,1.9302,1.93015,1.93015,-1
01/08/2007,00:25,1.93015,1.93015,1.93015,1.93015,-1
01/08/2007,00:26,1.93015,1.93015,1.93015,1.93015,-1
01/08/2007,00:27,1.93015,1.93015,1.93015,1.93015,-1
01/08/2007,00:28,1.93015,1.93015,1.93015,1.93015,-1
01/08/2007,00:29,1.93015,1.93015,1.93005,1.93005,-1
01/08/2007,00:30,1.93005,1.93005,1.93005,1.93005,-1
01/08/2007,00:31,1.93005,1.93005,1.93005,1.93005,-1
01/08/2007,00:32,1.93005,1.93005,1.93005,1.93005,-1
01/08/2007,00:33,1.93005,1.93005,1.93005,1.93005,-1
01/08/2007,00:34,1.93005,1.93005,1.93005,1.93005,-1
01/08/2007,00:35,1.93005,1.93005,1.93005,1.93005,-1
01/08/2007,00:36,1.93005,1.93015,1.93005,1.93005,-1
01/08/2007,00:37,1.93005,1.9301,1.93005,1.93005,-1
01/08/2007,00:38,1.93005,1.93015,1.93005,1.93015,-1
01/08/2007,00:39,1.93015,1.93015,1.93015,1.93015,-1
01/08/2007,00:40,1.93015,1.93015,1.9301,1.9301,-1
01/08/2007,00:41,1.9301,1.9302,1.9301,1.9302,-1
01/08/2007,00:42,1.9302,1.9302,1.9301,1.9301,-1
01/08/2007,00:43,1.9301,1.9301,1.9301,1.9301,-1
01/08/2007,00:44,1.9301,1.9301,1.9301,1.9301,-1
01/08/2007,00:45,1.9301,1.9301,1.93005,1.9301,-1
01/08/2007,00:46,1.9301,1.9301,1.9301,1.9301,-1
01/08/2007,00:47,1.9301,1.9301,1.93005,1.9301,-1
01/08/2007,00:48,1.9301,1.9301,1.9301,1.9301,-1
01/08/2007,00:49,1.9301,1.9301,1.9301,1.9301,-1
01/08/2007,00:50,1.9301,1.9301,1.9301,1.9301,-1
01/08/2007,00:51,1.9301,1.9301,1.92995,1.93,-1
01/08/2007,00:52,1.93,1.93015,1.93,1.93005,-1
01/08/2007,00:53,1.93005,1.93005,1.92995,1.93,-1
01/08/2007,00:54,1.93,1.93,1.92995,1.93,-1
01/08/2007,00:55,1.93,1.93,1.92995,1.93,-1




      ____________________________________________________________
ente http://mail.yahoo.fr


