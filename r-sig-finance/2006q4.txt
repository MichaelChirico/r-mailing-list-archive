From roger at ysidro.econ.uiuc.edu  Sun Oct  1 00:19:57 2006
From: roger at ysidro.econ.uiuc.edu (roger koenker)
Date: Sat, 30 Sep 2006 17:19:57 -0500
Subject: [R-SIG-Finance] [R] counting a sequence of charactors or numbers
In-Reply-To: <efmq51$gpi$1@sea.gmane.org>
References: <efmq51$gpi$1@sea.gmane.org>
Message-ID: <15895752-068E-40E2-BCBE-6C0E941513C1@ysidro.econ.uiuc.edu>

?rle

url:    www.econ.uiuc.edu/~roger                Roger Koenker
email   rkoenker at uiuc.edu                       Department of Economics
vox:    217-333-4558                            University of Illinois
fax:    217-244-6678                            Champaign, IL 61820


On Sep 30, 2006, at 5:13 PM, Joe Byers wrote:

> I have the following sequence of characters.  These could be  
> integers as
> well.  For this problem, only two values are valid.
>
> S S S S S S W W W W W W W W S S S S S S S S W W W W W W W W S S S S  
> S S
> S S S S S S S W W W W W W W W W
>
> I need to determine the count of the classes/groups in sequence. as
> 6,8,8,8,13,9 where the sum of these equal my total observations.
>
> Any help is greatly appreciated.
>
> Thank you
> Joe
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From joe-byers at utulsa.edu  Thu Oct  5 20:19:23 2006
From: joe-byers at utulsa.edu (Joe Byers)
Date: Thu, 05 Oct 2006 13:19:23 -0500
Subject: [R-SIG-Finance] isBizday question
Message-ID: <eg3ia6$9cb$1@sea.gmane.org>

I have the following code to create a calendar time sequence to perform 
a simulation
MTMDate<-'2006-09-25';
lastDay<-'2007-03-31';
traj<-500;
##############end input section
dt<-1/365;

#build calendar
calday<-timeSequence(from = MTMDate, to = lastDay,by = 
"day",FinCenter='America/Eastern')
#get rid of holidays and weekends
calday<-calday[isBizday(calday,holidays=holiday.NYSE())];

The problem is that the holidays are only eliminated for the current 
year, 2006, not the next year 2007.

Does anyone have a suggestion that I can use to get the isBizday method 
to also see the multiple years for the holidays?

Thank you
Joe


From wuertz at itp.phys.ethz.ch  Thu Oct  5 20:48:21 2006
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Thu, 05 Oct 2006 20:48:21 +0200
Subject: [R-SIG-Finance] isBizday question
In-Reply-To: <eg3ia6$9cb$1@sea.gmane.org>
References: <eg3ia6$9cb$1@sea.gmane.org>
Message-ID: <45255375.3060202@itp.phys.ethz.ch>

Joe Byers wrote:

>I have the following code to create a calendar time sequence to perform 
>a simulation
>MTMDate<-'2006-09-25';
>lastDay<-'2007-03-31';
>traj<-500;
>##############end input section
>dt<-1/365;
>
>#build calendar
>calday<-timeSequence(from = MTMDate, to = lastDay,by = 
>"day",FinCenter='America/Eastern')
>#get rid of holidays and weekends
>calday<-calday[isBizday(calday,holidays=holiday.NYSE())];
>  
>
You have to set the year,  e.g.

 > holiday.NYSE()
[1] "America/New_York"
[1] [2006-01-02] [2006-01-16] [2006-02-20] [2006-04-14] [2006-05-29] 
[2006-07-04]
[7] [2006-09-04] [2006-11-23] [2006-12-25]
 > holiday.NYSE(2005:2006)
[1] "America/New_York"
 [1] [2005-01-17] [2005-02-21] [2005-03-25] [2005-05-30] [2005-07-04] 
[2005-09-05]
 [7] [2005-11-24] [2005-12-26] [2006-01-02] [2006-01-16] [2006-02-20] 
[2006-04-14]
[13] [2006-05-29] [2006-07-04] [2006-09-04] [2006-11-23] [2006-12-25]
 > help(holiday.NYSE)


regards DW

>The problem is that the holidays are only eliminated for the current 
>year, 2006, not the next year 2007.
>  
>
that's not true read the help page.

>Does anyone have a suggestion that I can use to get the isBizday method 
>to also see the multiple years for the holidays?
>
>Thank you
>Joe
>
>_______________________________________________
>R-SIG-Finance at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>
>  
>


From joe-byers at utulsa.edu  Thu Oct  5 22:30:57 2006
From: joe-byers at utulsa.edu (Joe Byers)
Date: Thu, 05 Oct 2006 15:30:57 -0500
Subject: [R-SIG-Finance] isBizday question
In-Reply-To: <45255375.3060202@itp.phys.ethz.ch>
References: <eg3ia6$9cb$1@sea.gmane.org> <45255375.3060202@itp.phys.ethz.ch>
Message-ID: <45256B81.80608@utulsa.edu>

Diethelm,

thank you for your reply.

In reference to your comment below,
as I specified the holidays=holidays.NYSE(), it only calculates for the 
default function parameters.  I read that in the document pages, just 
did not understand it until I reviewed the results and the code for the 
two functions.

I figured out something that works, I just wonder if there is a simpler 
method.  I used the atoms and factor methods to get the factor levels of 
my years.  I replaced the line of code that contains isBizday with
#as.numeric(factor(atoms(calday)$Y)@levels)
calday<-calday[isBizday(calday,  
holidays=holiday.NYSE(as.numeric(factor(atoms(calday)$Y)@levels)))]

Thank you
Joe



Diethelm Wuertz wrote:
> Joe Byers wrote:
>
>> I have the following code to create a calendar time sequence to 
>> perform a simulation
>> MTMDate<-'2006-09-25';
>> lastDay<-'2007-03-31';
>> traj<-500;
>> ##############end input section
>> dt<-1/365;
>>
>> #build calendar
>> calday<-timeSequence(from = MTMDate, to = lastDay,by = 
>> "day",FinCenter='America/Eastern')
>> #get rid of holidays and weekends
>> calday<-calday[isBizday(calday,holidays=holiday.NYSE())];
>>  
>>
> You have to set the year,  e.g.
>
> > holiday.NYSE()
> [1] "America/New_York"
> [1] [2006-01-02] [2006-01-16] [2006-02-20] [2006-04-14] [2006-05-29] 
> [2006-07-04]
> [7] [2006-09-04] [2006-11-23] [2006-12-25]
> > holiday.NYSE(2005:2006)
> [1] "America/New_York"
> [1] [2005-01-17] [2005-02-21] [2005-03-25] [2005-05-30] [2005-07-04] 
> [2005-09-05]
> [7] [2005-11-24] [2005-12-26] [2006-01-02] [2006-01-16] [2006-02-20] 
> [2006-04-14]
> [13] [2006-05-29] [2006-07-04] [2006-09-04] [2006-11-23] [2006-12-25]
> > help(holiday.NYSE)
>
>
> regards DW
>
>> The problem is that the holidays are only eliminated for the current 
>> year, 2006, not the next year 2007.
>>  
>>
>
>
>> Does anyone have a suggestion that I can use to get the isBizday 
>> method to also see the multiple years for the holidays?
>>
>> Thank you
>> Joe
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>
>>  
>>
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: joe-byers.vcf
Type: text/x-vcard
Size: 295 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061005/83d5a5ef/attachment.vcf 

From schmis at gmx.ch  Fri Oct  6 15:59:12 2006
From: schmis at gmx.ch (-)
Date: Fri, 06 Oct 2006 15:59:12 +0200
Subject: [R-SIG-Finance] error message when loading package fSeries
Message-ID: <45266130.6080406@gmx.ch>

When I try to load the package fSeries I get the following error message 
in a window (in German):

"Der Prozedureinsprungpunkt 'signal' wurde in der DLL 'R.dll' nicht 
gefunden."

In the R-Interface it says:

"Fehler in dyn.load(x, as.logical(local), as.logical(now)) :
         kann shared library 
'C:/Programme/R/R-2.4.0/library/fBasics/libs/fBasics.dll' nicht laden:
  LoadLibrary failure:  Die angegebene Prozedur wurde nicht gefunden.

Fehler: Paket 'fBasics' konnte nicht geladen werden"

I have no clue what this means.

Any help is greatly appreciated.



Thank you, MD.


From schmis at gmx.ch  Fri Oct  6 16:38:34 2006
From: schmis at gmx.ch (-)
Date: Fri, 06 Oct 2006 16:38:34 +0200
Subject: [R-SIG-Finance]  error message when loading package fSeries
Message-ID: <45266A6A.2070705@gmx.ch>

I forgot to write that I use R version 2.4.0 for Windows and that other 
Rmetrics packages like fBasics or fCalender produce the same error messages.

Thanks.

Marius


From wuertz at itp.phys.ethz.ch  Sat Oct  7 00:12:03 2006
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Sat, 07 Oct 2006 00:12:03 +0200
Subject: [R-SIG-Finance] error message when loading package fSeries
In-Reply-To: <45266130.6080406@gmx.ch>
References: <45266130.6080406@gmx.ch>
Message-ID: <4526D4B3.3010608@itp.phys.ethz.ch>

- wrote:

Sorry, the Rmetrics Packages are not yet ready for 2.4.0. They will become
updated during the next week. Many Thanks
Diethelm Wuertz

>When I try to load the package fSeries I get the following error message 
>in a window (in German):
>
>"Der Prozedureinsprungpunkt 'signal' wurde in der DLL 'R.dll' nicht 
>gefunden."
>
>In the R-Interface it says:
>
>"Fehler in dyn.load(x, as.logical(local), as.logical(now)) :
>         kann shared library 
>'C:/Programme/R/R-2.4.0/library/fBasics/libs/fBasics.dll' nicht laden:
>  LoadLibrary failure:  Die angegebene Prozedur wurde nicht gefunden.
>
>Fehler: Paket 'fBasics' konnte nicht geladen werden"
>
>I have no clue what this means.
>
>Any help is greatly appreciated.
>
>
>
>Thank you, MD.
>
>_______________________________________________
>R-SIG-Finance at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>
>  
>


From edd at debian.org  Sat Oct  7 01:24:03 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 6 Oct 2006 18:24:03 -0500
Subject: [R-SIG-Finance] error message when loading package fSeries
In-Reply-To: <4526D4B3.3010608@itp.phys.ethz.ch>
References: <45266130.6080406@gmx.ch>
	<4526D4B3.3010608@itp.phys.ethz.ch>
Message-ID: <17702.58771.406827.609438@basebud.nulle.part>


On 7 October 2006 at 00:12, Diethelm Wuertz wrote:
| - wrote:
| 
| Sorry, the Rmetrics Packages are not yet ready for 2.4.0. They will become
| updated during the next week. Many Thanks

FWIW they continue to work under Linux.

edd at basebud:~> R

R version 2.4.0 (2006-10-03)
Copyright (C) 2006 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> library(fSeries)
Loading required package: fBasics

Rmetrics, (C) 1999-2005, Diethelm Wuertz, GPL
fBasics: Markets and Basic Statistics
Loading required package: fCalendar

Rmetrics, (C) 1999-2005, Diethelm Wuertz, GPL
fCalendar: Time, Date and Calendar Tools

Rmetrics, (C) 1999-2005, Diethelm Wuertz, GPL
fSeries: The Dynamical Process Behind Financial Markets
>                                                                           

Dirk


| Diethelm Wuertz
| 
| >When I try to load the package fSeries I get the following error message 
| >in a window (in German):
| >
| >"Der Prozedureinsprungpunkt 'signal' wurde in der DLL 'R.dll' nicht 
| >gefunden."
| >
| >In the R-Interface it says:
| >
| >"Fehler in dyn.load(x, as.logical(local), as.logical(now)) :
| >         kann shared library 
| >'C:/Programme/R/R-2.4.0/library/fBasics/libs/fBasics.dll' nicht laden:
| >  LoadLibrary failure:  Die angegebene Prozedur wurde nicht gefunden.
| >
| >Fehler: Paket 'fBasics' konnte nicht geladen werden"
| >
| >I have no clue what this means.
| >
| >Any help is greatly appreciated.
| >
| >
| >
| >Thank you, MD.
| >
| >_______________________________________________
| >R-SIG-Finance at stat.math.ethz.ch mailing list
| >https://stat.ethz.ch/mailman/listinfo/r-sig-finance
| >
| >  
| >
| 
| _______________________________________________
| R-SIG-Finance at stat.math.ethz.ch mailing list
| https://stat.ethz.ch/mailman/listinfo/r-sig-finance

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From vitorteixeira at mail.telepac.pt  Sun Oct  8 16:28:08 2006
From: vitorteixeira at mail.telepac.pt (VitorTeixeira)
Date: Sun, 8 Oct 2006 15:28:08 +0100
Subject: [R-SIG-Finance] Error in if (Y > 0) { : missing value where
	TRUE/FALSE needed
Message-ID: <000001c6eae5$fa5172d0$0100a8c0@ESCRITORIO>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061008/962b295e/attachment.pl 

From gyadav at ccilindia.co.in  Mon Oct  9 14:11:23 2006
From: gyadav at ccilindia.co.in (gyadav at ccilindia.co.in)
Date: Mon, 9 Oct 2006 17:41:23 +0530
Subject: [R-SIG-Finance] regarding bootstrapping
Message-ID: <OF26745E0E.2E0FC7BF-ON65257202.0042DC33-652571FF.00431358@ccilindia.co.in>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061009/e2e6626f/attachment.pl 

From brian at braverock.com  Mon Oct  9 15:29:42 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 9 Oct 2006 08:29:42 -0500
Subject: [R-SIG-Finance] regarding bootstrapping
In-Reply-To: <OF26745E0E.2E0FC7BF-ON65257202.0042DC33-652571FF.00431358@ccilindia.co.in>
References: <OF26745E0E.2E0FC7BF-ON65257202.0042DC33-652571FF.00431358@ccilindia.co.in>
Message-ID: <200610090829.43003.brian@braverock.com>

On Monday 09 October 2006 07:11, gyadav at ccilindia.co.in wrote:
> I just want to know how to make yield curve by bootstrapping using R.
> Please give me some subject-matter links and code links.
> Especially the Spot Yield Curve and YTM Curve.

Could you be a little more specific about what you're trying to do?  If 
you're trying to get current yield curves, there are simpler fitting 
methods than bootstrapping (or just take it off Bloomberg).  Any 
introductory R/S statistics text will give you several fitting options. 
If you're trying to forecast yield curve, what are you using as forecast 
rates?  If, for example, you're using futures prices, then again you have 
many simpler fitting mechanisms than bootstapping.  If you've got a more 
complicated forecast range, then bootstrapping may be appropriate.

Inside R, try 

help.search ("bootstrap")

and look at the examples most appropriate to your problem.

Regards,

 - Brian


From davidr at rhotrading.com  Mon Oct  9 17:25:32 2006
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Mon, 9 Oct 2006 10:25:32 -0500
Subject: [R-SIG-Finance] regarding bootstrapping
Message-ID: <F9F2A641C593D7408925574C05A7BE77131645@rhopost.rhotrading.com>

Yield curve bootstrapping and statistical bootstrapping are not really
related.
Yield curve bootstrapping is constructing a yield curve from market
instruments' prices (deposit rates or [L]ibors, Eurocurrency prices,
swaps.)
There are so many ways of doing it, that I suspect you will have to do
it yourself to get something suitable for your particular situation.
You could start with one of the 'big' finance texts that covers it in
some detail, such as Hull.

Good luck!

David L. Reiner
Rho Trading Securities, LLC
Chicago  IL  60605
312-362-4963
-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Brian G.
Peterson
Sent: Monday, October 09, 2006 8:30 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] regarding bootstrapping

On Monday 09 October 2006 07:11, gyadav at ccilindia.co.in wrote:
> I just want to know how to make yield curve by bootstrapping using R.
> Please give me some subject-matter links and code links.
> Especially the Spot Yield Curve and YTM Curve.

Could you be a little more specific about what you're trying to do?  If 
you're trying to get current yield curves, there are simpler fitting 
methods than bootstrapping (or just take it off Bloomberg).  Any 
introductory R/S statistics text will give you several fitting options. 
If you're trying to forecast yield curve, what are you using as forecast

rates?  If, for example, you're using futures prices, then again you
have 
many simpler fitting mechanisms than bootstapping.  If you've got a more

complicated forecast range, then bootstrapping may be appropriate.

Inside R, try 

help.search ("bootstrap")

and look at the examples most appropriate to your problem.

Regards,

 - Brian

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance


From finbref.2006 at gmail.com  Mon Oct  9 17:48:35 2006
From: finbref.2006 at gmail.com (Thomas Steiner)
Date: Mon, 9 Oct 2006 17:48:35 +0200
Subject: [R-SIG-Finance] regarding bootstrapping
In-Reply-To: <OF26745E0E.2E0FC7BF-ON65257202.0042DC33-652571FF.00431358@ccilindia.co.in>
References: <OF26745E0E.2E0FC7BF-ON65257202.0042DC33-652571FF.00431358@ccilindia.co.in>
Message-ID: <d0f55a670610090848gd8ddd19w2985b7ec0c908a26@mail.gmail.com>

Gaurav,

some time ago I asked a very similar question. I got some very helpful
answers and some lines of code. Perhaps you want to read this (after
consulting Hull and the others):
https://stat.ethz.ch/pipermail/r-sig-finance/2006q1/000682.html

If you want to see some of my "present" code, just let me know.

Yours,
Thomas


From gyadav at ccilindia.co.in  Tue Oct 10 07:34:21 2006
From: gyadav at ccilindia.co.in (gyadav at ccilindia.co.in)
Date: Tue, 10 Oct 2006 11:04:21 +0530
Subject: [R-SIG-Finance] regarding bootstrapping
In-Reply-To: <F9F2A641C593D7408925574C05A7BE77131645@rhopost.rhotrading.com>
Message-ID: <OFCBC74165.F3DF81E6-ON65257203.001E2E76-65257203.001EB9C1@ccilindia.co.in>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061010/015fd941/attachment.pl 

From gyadav at ccilindia.co.in  Tue Oct 10 08:44:59 2006
From: gyadav at ccilindia.co.in (gyadav at ccilindia.co.in)
Date: Tue, 10 Oct 2006 12:14:59 +0530
Subject: [R-SIG-Finance]  regarding bootstrapping... REVISITED
In-Reply-To: <d0f55a670610090848gd8ddd19w2985b7ec0c908a26@mail.gmail.com>
Message-ID: <OFC80A015F.B5FE411D-ON65257203.001F22F0-65257203.0025310A@ccilindia.co.in>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061010/077a8b39/attachment.pl 

From gyadav at ccilindia.co.in  Tue Oct 10 09:02:44 2006
From: gyadav at ccilindia.co.in (gyadav at ccilindia.co.in)
Date: Tue, 10 Oct 2006 12:32:44 +0530
Subject: [R-SIG-Finance] ERRATA: Re: [R] regarding bootstrapping... REVISITED
In-Reply-To: <OFC80A015F.B5FE411D-ON65257203.001F22F0-65257203.0025310A@ccil
	india.co.in>
Message-ID: <OFD15F7096.EE168F43-ON65257203.00269C3C-65257203.0026D111@ccilindia.co.in>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061010/78aceab9/attachment.pl 

From brian at braverock.com  Tue Oct 10 13:18:12 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 10 Oct 2006 06:18:12 -0500
Subject: [R-SIG-Finance] regarding bootstrapping... REVISITED
In-Reply-To: <OFC80A015F.B5FE411D-ON65257203.001F22F0-65257203.0025310A@ccilindia.co.in>
References: <OFC80A015F.B5FE411D-ON65257203.001F22F0-65257203.0025310A@ccilindia.co.in>
Message-ID: <200610100618.12185.brian@braverock.com>

On Tuesday 10 October 2006 00:25, gyadav at ccilindia.co.in wrote:
> i am trying to build a spot yield curve for fixed income market
> specifically bonds. i was told by my contacts that this can be done
> best by bootstrapping.


On Tuesday 10 October 2006 01:44, gyadav at ccilindia.co.in wrote:
> I went through the thread(
> https://stat.ethz.ch/pipermail/r-sig-finance/2006q1/000682.html which
> concerns with swaps). Yeah it is correct that i would like to quote
> both David and Krishna that the curve interpolation may vary
> considerably (for e.g. any polynomial/parametric fit is very different
> from and curve fitting whether it is free hand or by NURBS ( complex
> version of Basis Splines ZZZzzz). My problem is that i want to know how
> can i generate spot curve using bootstrap method in R.Further, even if
> you do not have fixed maturity bonds i.e. when you need to create
> fictitious or virtual paper of varied fixed maturities like 1 month, 6
> month, 1 year, 5 year, 10 year ..... so that you can create a spot
> curve from the traded points which may be like as follows.... for e.g.

Gaurav,

I believe we're all saying the same thing.  

David has correctly pointed out that to simply discuss "bootstrapping a 
yield curve" does not necessarily imply the use of a statistical 
"bootstrap" method to build your curve, although it does not necessarily 
rule it out either.  Kris in the earlier thread provided code for an 
interpolation/fit method using the discount rate. Thomas used a different 
method.  Kris also provided reference to several papers that could be 
used to construct other methods, and pointed out that the choice of 
method will change your estimates, possibly significantly. My point was 
that you will need to test any fitting method against the specific 
problem that you have, and that a statistical bootstrap may or may not be 
appropriate to your problem. The input data you have available will help 
you determine the best fitting method to use.

Both Thomas' code and Kris' code look like they will do a credible job of 
fitting a yield curve.  Perhaps you should consider testing those methods 
against your problem, so that you could identify deficiencies that those 
methods may have in your specific implementation.  Then we could discuss 
approaches here that might address the specific deficiencies that you 
identify.

Regards,

   - Brian


From davidr at rhotrading.com  Tue Oct 10 16:23:15 2006
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Tue, 10 Oct 2006 09:23:15 -0500
Subject: [R-SIG-Finance] regarding bootstrapping... REVISITED
Message-ID: <F9F2A641C593D7408925574C05A7BE7713166A@rhopost.rhotrading.com>

It is possible that the constant maturity treasury curve constructed
daily by the NY Fed will serve your needs. (You didn't say what you were
trying to accomplish AFAICS.) 
You can get history at
http://www.federalreserve.gov/releases/h15/data.htm . Look for 'Treasury
constant maturities'. They used to hand-fit a curve, but now they use an
algorithm (which is documented somewhere I don't remember.)

HTH

David L. Reiner
Rho Trading Securities, LLC
Chicago  IL  60605
312-362-4963

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Brian G.
Peterson
Sent: Tuesday, October 10, 2006 6:18 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] regarding bootstrapping... REVISITED

On Tuesday 10 October 2006 00:25, gyadav at ccilindia.co.in wrote:
> i am trying to build a spot yield curve for fixed income market
> specifically bonds. i was told by my contacts that this can be done
> best by bootstrapping.


On Tuesday 10 October 2006 01:44, gyadav at ccilindia.co.in wrote:
> I went through the thread(
> https://stat.ethz.ch/pipermail/r-sig-finance/2006q1/000682.html which
> concerns with swaps). Yeah it is correct that i would like to quote
> both David and Krishna that the curve interpolation may vary
> considerably (for e.g. any polynomial/parametric fit is very different
> from and curve fitting whether it is free hand or by NURBS ( complex
> version of Basis Splines ZZZzzz). My problem is that i want to know
how
> can i generate spot curve using bootstrap method in R.Further, even if
> you do not have fixed maturity bonds i.e. when you need to create
> fictitious or virtual paper of varied fixed maturities like 1 month, 6
> month, 1 year, 5 year, 10 year ..... so that you can create a spot
> curve from the traded points which may be like as follows.... for e.g.

Gaurav,

I believe we're all saying the same thing.  

David has correctly pointed out that to simply discuss "bootstrapping a 
yield curve" does not necessarily imply the use of a statistical 
"bootstrap" method to build your curve, although it does not necessarily

rule it out either.  Kris in the earlier thread provided code for an 
interpolation/fit method using the discount rate. Thomas used a
different 
method.  Kris also provided reference to several papers that could be 
used to construct other methods, and pointed out that the choice of 
method will change your estimates, possibly significantly. My point was 
that you will need to test any fitting method against the specific 
problem that you have, and that a statistical bootstrap may or may not
be 
appropriate to your problem. The input data you have available will help

you determine the best fitting method to use.

Both Thomas' code and Kris' code look like they will do a credible job
of 
fitting a yield curve.  Perhaps you should consider testing those
methods 
against your problem, so that you could identify deficiencies that those

methods may have in your specific implementation.  Then we could discuss

approaches here that might address the specific deficiencies that you 
identify.

Regards,

   - Brian

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance


From vitorteixeira at mail.telepac.pt  Tue Oct 10 16:25:50 2006
From: vitorteixeira at mail.telepac.pt (VitorTeixeira)
Date: Tue, 10 Oct 2006 15:25:50 +0100
Subject: [R-SIG-Finance] Error message
Message-ID: <000e01c6ec77$fe0631c0$0100a8c0@ESCRITORIO>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061010/5a290e82/attachment.pl 

From edd at debian.org  Tue Oct 10 16:32:30 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 10 Oct 2006 09:32:30 -0500
Subject: [R-SIG-Finance] Error message
In-Reply-To: <000e01c6ec77$fe0631c0$0100a8c0@ESCRITORIO>
References: <000e01c6ec77$fe0631c0$0100a8c0@ESCRITORIO>
Message-ID: <17707.44798.20178.525561@basebud.nulle.part>


On 10 October 2006 at 15:25, VitorTeixeira wrote:
| Hi.
|  
| I have this error message:
|  
| Error in if (Y > 0) { : missing value where TRUE/FALSE needed
|  
| when I?m trying to run this code.

We know as you already told us two days ago.  

I'd start by examining my data and remove __missing values__ as the code you
are using apparently does not digests data containing missing values.  The
summary(), is.finite() and which() functions may all be of help here.

I am not familiar with the function itself so this may be of limited actual
help to you. 

Good luck, Dirk


-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From gyadav at ccilindia.co.in  Wed Oct 11 09:49:35 2006
From: gyadav at ccilindia.co.in (gyadav at ccilindia.co.in)
Date: Wed, 11 Oct 2006 13:19:35 +0530
Subject: [R-SIG-Finance] Some bond basics... please help
In-Reply-To: <200610100618.12185.brian@braverock.com>
Message-ID: <OFA37CA706.84AC2939-ON65257204.002A2B7E-65257203.002B1AAD@ccilindia.co.in>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061011/8f351444/attachment.pl 

From janpaulr at yahoo.com  Wed Oct 11 12:33:22 2006
From: janpaulr at yahoo.com (Jan-Paul Roodbol)
Date: Wed, 11 Oct 2006 11:33:22 +0100 (BST)
Subject: [R-SIG-Finance] Some ANOVA and data matrix basics... please help
In-Reply-To: <OFA37CA706.84AC2939-ON65257204.002A2B7E-65257203.002B1AAD@ccilindia.co.in>
Message-ID: <20061011103322.64590.qmail@web34202.mail.mud.yahoo.com>

Friendly greetings

I have been told about the power and flexibility of R.
 However, I'm not good at programming, and a mediocre
statistician at best.  I think I'm best at asking
relevant questions and interpreting replies.
I hope you can help me with my data analysis.

I have 65 months of data
20 different variables
159 companies
Nine different classification systems (call them A, B,
C
 I) of the 159 companies, so each of the 159
companies has 9 different classifcations.

I want to test which classification system is the
'best'
To do this, I apply ANOVA to a specific classication
system, one at a time (A, B,  
 I)
In this way I see if the groupings in a specific
classification system are significantly better (I want
the variance in each group to be low, and 
the variance between groups high.)

I want to do the ANOVA test for all 20 variables
For each month individually, as well as for the
average
For 9 classification systems

So the question is: 
Using R
How do I code this so that it automatically reads a
different column, and uses a different classification
system.
Also, how do I store the output in a matrix

Thank you in advance for your help

Kind regards

Jan-Paul


From brian at braverock.com  Wed Oct 11 12:59:22 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 11 Oct 2006 05:59:22 -0500
Subject: [R-SIG-Finance] Some ANOVA and data matrix basics... please help
In-Reply-To: <20061011103322.64590.qmail@web34202.mail.mud.yahoo.com>
References: <20061011103322.64590.qmail@web34202.mail.mud.yahoo.com>
Message-ID: <200610110559.22313.brian@braverock.com>

On Wednesday 11 October 2006 05:33, Jan-Paul Roodbol wrote:
> I want to do the ANOVA test for all 20 variables
> For each month individually, as well as for the
> average For 9 classification systems

One online reference that looks particularly relevant to your query is:
"Practical Regression and Anova in R" by Julian J. Faraway, available 
here:
http://www.stat.lsa.umich.edu/~faraway/book/pra.pdf
Or, his updated book
"Linear Models with R"
http://www.stat.lsa.umich.edu/~faraway/LMR/
which I use regularly as a reference.

Your questions also contain elements of "how do I do simple things in R" 
that would be covered by any of the introductory R/S texts.

> How do I code this so that it automatically reads a
> different column, and uses a different classification
> system.

I assume with a set of nested loops that vary the indices.

> Also, how do I store the output in a matrix

probably by using c(), cbind(), and rbind() in some combination to collect 
your results.

Regards,

   - Brian


From finbref.2006 at gmail.com  Thu Oct 12 14:13:26 2006
From: finbref.2006 at gmail.com (Thomas Steiner)
Date: Thu, 12 Oct 2006 14:13:26 +0200
Subject: [R-SIG-Finance] regarding bootstrapping... REVISITED
In-Reply-To: <F9F2A641C593D7408925574C05A7BE7713166A@rhopost.rhotrading.com>
References: <F9F2A641C593D7408925574C05A7BE7713166A@rhopost.rhotrading.com>
Message-ID: <d0f55a670610120513u726b0e42g37c05ad613e1cb9a@mail.gmail.com>

> You can get history at
> http://www.federalreserve.gov/releases/h15/data.htm . Look for 'Treasury
> constant maturities'. They used to hand-fit a curve, but now they use an
> algorithm (which is documented somewhere I don't remember.)

find it (briefly) here (cubic splines):
http://www.treas.gov/offices/domestic-finance/debt-management/interest-rate/yieldmethod.html
Thomas


From raggadbechir at yahoo.fr  Mon Oct 16 13:36:33 2006
From: raggadbechir at yahoo.fr (bechir raggad)
Date: Mon, 16 Oct 2006 13:36:33 +0200 (CEST)
Subject: [R-SIG-Finance] DCC-MGARCH
Message-ID: <20061016113633.82480.qmail@web26612.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061016/a4e842a4/attachment.pl 

From felipehsantos at gmail.com  Thu Oct 19 16:52:23 2006
From: felipehsantos at gmail.com (Felipe Santos)
Date: Thu, 19 Oct 2006 11:52:23 -0300
Subject: [R-SIG-Finance] predict.Arima question
Message-ID: <b4d88c800610190752r46f4a224kd8dd05fbc25f4aaf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061019/749bd6a8/attachment.pl 

From pdebruic at gmail.com  Thu Oct 19 17:50:41 2006
From: pdebruic at gmail.com (Paul DeBruicker)
Date: Thu, 19 Oct 2006 11:50:41 -0400
Subject: [R-SIG-Finance] No fMultivar Windows Binary on CRAN,
	installation alternatives?
Message-ID: <f2e3401f0610190850q577b1e12x8274cef7c7002b39@mail.gmail.com>

Without a Windows binary on CRAN, is there a way to install fMultivar
on an XP box running R 2.4?

I can unzip and untar the package source, but don't yet have a
compiler to build the appropriate files.  Is that my only option or am
I missing another viable alternative?

Is it expected that there will be a Windows binary for fMultivar at
some point in the future?


Thanks for what clarification you can provide.


Paul


From tjohnson at covad.net  Thu Oct 19 06:23:57 2006
From: tjohnson at covad.net (Tom Johnson)
Date: Wed, 18 Oct 2006 21:23:57 -0700
Subject: [R-SIG-Finance]  R Implementation of FIX
Message-ID: <GPEPLHOKJEHOCLMBOODGKEBDGNAA.tjohnson@covad.net>

Does anyone please know of an example of R (or S-Plus) code being used to
implement the FIX ("Financial Information eXchange") protocol for
communicating securities transactions between two parties?  I only know of
implementations in C++, Visual Basic, Delphi, Java, etc.  Thanking you for
any leads,  Tom


From rob.hyndman at buseco.monash.edu.au  Fri Oct 20 00:17:44 2006
From: rob.hyndman at buseco.monash.edu.au (Rob Hyndman)
Date: Fri, 20 Oct 2006 08:17:44 +1000
Subject: [R-SIG-Finance] predict.Arima question
In-Reply-To: <b4d88c800610190752r46f4a224kd8dd05fbc25f4aaf@mail.gmail.com>
References: <b4d88c800610190752r46f4a224kd8dd05fbc25f4aaf@mail.gmail.com>
Message-ID: <4537F988.5050206@buseco.monash.edu.au>

Unfortunately you can't do this using the arima() or predict() functions 
in the stats package. However, you can do what you want using the 
arima() function in the forecast package (available on CRAN). There is 
also a function best.arima() which selects the best model according to 
AIC, BIC or AICc.

Best wishes,
Rob

Felipe Santos wrote:
> Hi,
> 
> I am trying to forecast a model using predict.Arima
> 
> I found arima model for a data set: x={x1,x2,x3,...,x(t)}
> 
> arima_model = arima(x,order=c(1,0,1))
> 
> I am forecasting the next N lags using predict:
> 
> arima_pred = predict(arima_model,n.ahead = N, se.fit=T)
> 
> If I have one more point in my series, let's say x(t+1). I do not want to
> recalibrate themodel, I just want to forecast the next N-1 lags  using the
> same model for x={x1,x2,...x(t)} but without recalibrate arima.
> 
> How to do it using arima + predict.Arima ?
> 
> My problem is that I am trying to fit arima models by brute force ( trying
> lots of combinations for p and q and chosing the best model by AIC and BIC )
> I have a big time series and I am running calibration for some sub-sequence
> and I trying to forecast some points. I repeat this process for the next
> contiguous subsequence and try to forecast again, until the big series end.
> 
> Thanks
> Felipe
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance

-- 
__________________________________________________
Professor Rob J Hyndman
Department of Econometrics & Business Statistics,
Monash University, VIC 3800, Australia
http://www.robhyndman.info/


From rob.hyndman at buseco.monash.edu.au  Fri Oct 20 00:45:13 2006
From: rob.hyndman at buseco.monash.edu.au (Rob Hyndman)
Date: Fri, 20 Oct 2006 08:45:13 +1000
Subject: [R-SIG-Finance] No fMultivar Windows Binary on CRAN,
 installation alternatives?
In-Reply-To: <f2e3401f0610190850q577b1e12x8274cef7c7002b39@mail.gmail.com>
References: <f2e3401f0610190850q577b1e12x8274cef7c7002b39@mail.gmail.com>
Message-ID: <4537FFF9.5060205@buseco.monash.edu.au>

Download the 2.3 version at
http://cran.r-project.org/bin/windows/contrib/2.3/fMultivar_221.10065.zip

Paul DeBruicker wrote:
> Without a Windows binary on CRAN, is there a way to install fMultivar
> on an XP box running R 2.4?
> 
> I can unzip and untar the package source, but don't yet have a
> compiler to build the appropriate files.  Is that my only option or am
> I missing another viable alternative?
> 
> Is it expected that there will be a Windows binary for fMultivar at
> some point in the future?
> 
> 
> Thanks for what clarification you can provide.
> 
> 
> Paul
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance

-- 
__________________________________________________
Professor Rob J Hyndman
Department of Econometrics & Business Statistics,
Monash University, VIC 3800, Australia
http://www.robhyndman.info/


From Joe-Byers at utulsa.edu  Fri Oct 20 18:04:08 2006
From: Joe-Byers at utulsa.edu (Joe W. Byers)
Date: Fri, 20 Oct 2006 11:04:08 -0500
Subject: [R-SIG-Finance] Help with date arithmetic
Message-ID: <ehas1p$kbn$1@sea.gmane.org>

I have the following day
dts<-('02/08/2002');
I want to return a vector of character dates by adding 1 to the current 
day and adding the number of non business days for a weekend and/or 
holiday if they occur to get the following results

should.be.results<-('02/09/2002','02/12/2002');

I can handle the first calculation but I can not find how to increment 
the date for non business days.

results<-c(format.Date(as.date(dts,order='mdy')+1,'%m/%d/%Y'),
	I need help  here);

I have review the fCalendar docs and others.  I have also created a time 
sequence for this project where I removed the non-business days using 
the isBizday method.  Any help is greatly appreciated.
Thank you
Joe


From Joe-Byers at utulsa.edu  Fri Oct 20 19:22:09 2006
From: Joe-Byers at utulsa.edu (Joe W. Byers)
Date: Fri, 20 Oct 2006 12:22:09 -0500
Subject: [R-SIG-Finance] Adding NYMEX to holidays calendar
Message-ID: <ehb0k2$8d0$1@sea.gmane.org>

Rmetrics

Can anyone help me create a new holidays calendar method like 
holidaysNYSE() for NYMEX holidays.  The only difference is the holidays 
for Independence day and thanks giving.
Independence Day
	Monday, July 3*
	Tuesday, July 4
	(Electronic trading closed Sunday and Monday, July 2 and 3; reopens 
6:00 PM, July 4)
Thanksgiving
	Thursday, November 23
	Friday, November 24
	(NYMEX ClearPort? and CME Globex? open both days)

NYMEX is closed on Monday July 3rd this year since the 4th is on a 
Tuesday and Friday the day following Thanksgiving.  This will end in 
2007 according to NYMEX.  The Independence day holiday I think will 
observe Friday as a holiday when the 4th is on a Thurs but, according to 
NYMEX they are not sure for 2007.  Also the webpage 
http://www.nymex.com/holida_schedu.aspx notes that Christmas eve will 
become a holiday in 2007 but expirations will not change.  I am sending 
their customer service a request to post a document with the holiday 
rules as well as these tables for those of us who worry about a 
derivatives calendar.

Thank you
Joe


From spencer.graves at pdf.com  Fri Oct 20 23:38:11 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 21 Oct 2006 06:38:11 +0900
Subject: [R-SIG-Finance] Some bond basics... please help
In-Reply-To: <OFA37CA706.84AC2939-ON65257204.002A2B7E-65257203.002B1AAD@ccilindia.co.in>
References: <OFA37CA706.84AC2939-ON65257204.002A2B7E-65257203.002B1AAD@ccilindia.co.in>
Message-ID: <453941C3.4@pdf.com>

       RSiteSearch("bond") produced 135 hits for me just now, and  
RSiteSearch("bond", "function") produced 22.  If you'd like further help 
from this listserve, please provide commented, minimal, self-contained, 
reproducible code describing something you've tried and why it did not 
meet your needs (as suggested in the posting guide 
"www.R-project.org/posting-guide.html").

      Hope this helps. 
      Spencer Graves

gyadav at ccilindia.co.in wrote:
> hi All,
>
> Can I do something like this, really wondering 
>
> I have a securities details like this :
>
> Security Name : Xa
> Coupon : 6.322%  = Xb
> Yield : 5.6% = Xc
> Maturity : 12-Aug-2010 = Xd
> Settlement Date : 10-Oct-2006 = Xe
>
> Can I find the zero coupon price like this P1 = price(Xe, Xd, Xc, 0%) 
> where all details are same as the abov security except the coupon which is 
> zero. Further, then I find the Yield with This Price P1 which i get as Y1 
> (Y1 = yield(Xe, Xd, P1, 0%). 
>
> Is Y1 a zero coupon bond equivalent yield ???
>
>
> Thanks in advance,
> -Gaurav
>
>
>
>    Sayonara With Smile & With Warm Regards :-)
>
>   G a u r a v   Y a d a v
>   Senior Executive Officer,
>   Economic Research & Surveillance Department,
>   Clearing Corporation Of India Limited.
>
>   Address: 5th, 6th, 7th Floor, Trade Wing 'C',  Kamala City, S.B. Marg, 
> Mumbai - 400 013
>   Telephone(Office): - +91 022 6663 9398 ,  Mobile(Personal) (0)9821286118
>   Email(Office) :- gyadav at ccilindia.co.in ,  Email(Personal) :- 
> emailtogauravyadav at gmail.com
>
>
> ============================================================================================
> DISCLAIMER AND CONFIDENTIALITY CAUTION:\ \ This message and ...{{dropped}}
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From brian at braverock.com  Sat Oct 21 01:03:11 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 20 Oct 2006 18:03:11 -0500
Subject: [R-SIG-Finance] Some bond basics... please help
In-Reply-To: <453941C3.4@pdf.com>
References: <OFA37CA706.84AC2939-ON65257204.002A2B7E-65257203.002B1AAD@ccilindia.co.in>
	<453941C3.4@pdf.com>
Message-ID: <200610201803.11520.brian@braverock.com>

On Friday 20 October 2006 16:38, Spencer Graves wrote:
> If you'd like further help
> from this listserve, please provide commented, minimal, self-contained,
> reproducible code describing something you've tried and why it did not
> meet your needs (as suggested in the posting guide

I believe that the original poster solved his problem via simple 
interpolation in one case and spline fitting in a more complicated case.  
I believe that he was really looking for a pointer on how one might fit a 
yield curve, which several people provided, and as I understand it, he 
solved his problem already.

Nevertheless, there are no widely available functions that I am aware of 
that have been published in R specifically for calculating a yield curve 
on a group of bonds.  The eagerly awaited fBonds package has not yet been 
released.  So, the interested analyst must resort to generic fitting 
methods already available in R, as several of us indicated to the OP.

Regards,

  - Brian


From spencer.graves at pdf.com  Sat Oct 21 01:25:15 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 21 Oct 2006 08:25:15 +0900
Subject: [R-SIG-Finance] Some bond basics... please help
In-Reply-To: <200610201803.11520.brian@braverock.com>
References: <OFA37CA706.84AC2939-ON65257204.002A2B7E-65257203.002B1AAD@ccilindia.co.in>	<453941C3.4@pdf.com>
	<200610201803.11520.brian@braverock.com>
Message-ID: <45395ADB.9030300@pdf.com>

Hi, Brian:  Thanks.  I missed the replies;  I should have looked more 
carefully.  Thanks again.  Spencer Graves

Brian G. Peterson wrote:
> On Friday 20 October 2006 16:38, Spencer Graves wrote:
>   
>> If you'd like further help
>> from this listserve, please provide commented, minimal, self-contained,
>> reproducible code describing something you've tried and why it did not
>> meet your needs (as suggested in the posting guide
>>     
>
> I believe that the original poster solved his problem via simple 
> interpolation in one case and spline fitting in a more complicated case.  
> I believe that he was really looking for a pointer on how one might fit a 
> yield curve, which several people provided, and as I understand it, he 
> solved his problem already.
>
> Nevertheless, there are no widely available functions that I am aware of 
> that have been published in R specifically for calculating a yield curve 
> on a group of bonds.  The eagerly awaited fBonds package has not yet been 
> released.  So, the interested analyst must resort to generic fitting 
> methods already available in R, as several of us indicated to the OP.
>
> Regards,
>
>   - Brian
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From frednovo at pipeline.com  Sat Oct 21 19:23:25 2006
From: frednovo at pipeline.com (Frederick Novomestky)
Date: Sat, 21 Oct 2006 13:23:25 -0400
Subject: [R-SIG-Finance] Some bond basics... please help
In-Reply-To: <200610201803.11520.brian@braverock.com>
References: <OFA37CA706.84AC2939-ON65257204.002A2B7E-65257203.002B1AAD@ccilindia.co.in>
	<453941C3.4@pdf.com> <200610201803.11520.brian@braverock.com>
Message-ID: <6.2.1.2.2.20061021132005.023aec18@pop.pipeline.com>

To all:

This semester I am teaching a course on Term Structure modeling and 
advanced interest rate derivatives.  To support the empirical work, I am 
developing a package fTermStructure that am building as we go along.  It's 
not fully ready for submission to R, but can do so.

Regards

Fred Novomestky
Industry Professor
Department of Financial Engineering
Polytechnic University
6 Metrotech Center
Brooklyn, NY 11201 USA
Vox: 1.718.260.3436
Fax: 1.718.260.3874
University email: fnovomes at poly.edu

The package includes the valuation of pure discount and fixed rate coupon 
paying bonds, bootstrap construction of spot curves, yield to maturity 
calculation, forward rate curve construction from spot rates and, by this 
week, Nelson Siegel function estimation.

At 07:03 PM 10/20/2006, Brian G. Peterson wrote:
>On Friday 20 October 2006 16:38, Spencer Graves wrote:
> > If you'd like further help
> > from this listserve, please provide commented, minimal, self-contained,
> > reproducible code describing something you've tried and why it did not
> > meet your needs (as suggested in the posting guide
>
>I believe that the original poster solved his problem via simple
>interpolation in one case and spline fitting in a more complicated case.
>I believe that he was really looking for a pointer on how one might fit a
>yield curve, which several people provided, and as I understand it, he
>solved his problem already.
>
>Nevertheless, there are no widely available functions that I am aware of
>that have been published in R specifically for calculating a yield curve
>on a group of bonds.  The eagerly awaited fBonds package has not yet been
>released.  So, the interested analyst must resort to generic fitting
>methods already available in R, as several of us indicated to the OP.
>
>Regards,
>
>   - Brian
>
>_______________________________________________
>R-SIG-Finance at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance

Frederick Novomestky, Ph.D.
Novomestky Associates
41 Eastover Drive
East Northport, NY 11731-4330
Vox: 1.631.368.0701
Fax: 1.631.368.1696

Confidentiality Notice: This electronic mail transmission, i...{{dropped}}


From Joe-Byers at utulsa.edu  Sat Oct 21 21:30:43 2006
From: Joe-Byers at utulsa.edu (Joe W. Byers)
Date: Sat, 21 Oct 2006 14:30:43 -0500
Subject: [R-SIG-Finance] Help with date arithmetic
In-Reply-To: <ehas1p$kbn$1@sea.gmane.org>
References: <ehas1p$kbn$1@sea.gmane.org>
Message-ID: <ehdsh4$gt2$1@sea.gmane.org>

All here is what I came up with to increment over non-business days and 
NYSE holidays.  I would appreciate any help in refining this code to be 
more generic for use with vectors, more date formats, and other 
holidays.  It is extremely slow to run this function over a large time 
sequence.  I think I could change the code from using fCalendar 
timesequence() to using the date.mdy()$year for part of the code, but I 
am still learning these things in R.

#function call
Bizday.increment('09/25/04',1)

# Created by: Joe W. Byers
# Date: 10/20/06
#Method to increment a give date to the next business day given 
holidayNYSE() holidays
Bizday.increment<-function(data,inc=1,format='%m/%d/%Y'){
	#need to add date coersion if data numeric
	# need to add ability to perform over a vector and return all increments
	# need to add ability to perform with different holidays beside NYSE
	Loop=T; # set loop test
	ans<-format.Date(as.date(data,order='mdy')+inc,format)
	while(Loop==T){
		t1<-isBizday(timeSequence(from=ans,to=ans,format=format),
			holidays=holidayNYSE(as.numeric(
			factor(atoms(timeSequence(from=ans,to=ans,format=format)
			)$Y)@levels)))
		if (t1==T) {Loop=F}
		else {ans<-format.Date(as.date(ans,order='mdy')+inc,format)}
	}
	ans
}
Thank you
Joe

Joe W. Byers wrote:
> I have the following day
> dts<-('02/08/2002');
> I want to return a vector of character dates by adding 1 to the current 
> day and adding the number of non business days for a weekend and/or 
> holiday if they occur to get the following results
> 
> should.be.results<-('02/09/2002','02/12/2002');
> 
> I can handle the first calculation but I can not find how to increment 
> the date for non business days.
> 
> results<-c(format.Date(as.date(dts,order='mdy')+1,'%m/%d/%Y'),
> 	I need help  here);
> 
> I have review the fCalendar docs and others.  I have also created a time 
> sequence for this project where I removed the non-business days using 
> the isBizday method.  Any help is greatly appreciated.
> Thank you
> Joe
>


From kb2qzv at poczta.wp.pl  Sat Oct 21 23:08:47 2006
From: kb2qzv at poczta.wp.pl (Andy (Lists))
Date: Sat, 21 Oct 2006 16:08:47 -0500
Subject: [R-SIG-Finance] How to try technical indicators, fMultivar
Message-ID: <200610211608.47615.kb2qzv@poczta.wp.pl>

Hi,
Please bear with me while I try to figure out how R and RMetrics work.
I would like to try out the fMultivar package to see how well it can display 
different technical indicators.  I have no experience in R.

The data file named WIG20.mst looks like this:
<Ticker>,<Date>,<Open>,<High>,<Low>,<Close>,<Volume>
[...]
WIG20,20051021,2324.18,2338.45,2312.07,2323.23,890642.379
WIG20,20051024,2322.77,2357.95,2322.77,2339.41,763810.167
WIG20,20051025,2353.27,2372.36,2344.46,2360.77,654536.990
WIG20,20051026,2373.50,2380.10,2310.39,2340.24,807947.585
WIG20,20051027,2291.66,2307.86,2285.16,2302.53,711165.288
WIG20,20051028,2283.72,2320.37,2273.49,2316.55,538880.205
[...]
It contains data from the year 1994 to-date. The obove is just an exerpt.

So in R I used read.csv() function to create the object "wig20".
wig20 = read.csv("WIG20.mst")

So far so good but when I check the object "wig20" I can see that it looks a 
little different than what the original file:
wig20
2851     WIG20      20051024 2322.77 2357.95 2322.77  2339.41  763810.17
2852     WIG20      20051025 2353.27 2372.36 2344.46  2360.77  654536.99
2853     WIG20      20051026 2373.50 2380.10 2310.39  2340.24  807947.58
2854     WIG20      20051027 2291.66 2307.86 2285.16  2302.53  711165.29
2855     WIG20      20051028 2283.72 2320.37 2273.49  2316.55  538880.20

What are those numbers before the ticker value WIG20? I hope this is something 
that I can just ignore. But it would be good to know what they are.

Next I would like to display both the price plot and below the price one of 
the technical indicators plot in a manner similar to what other stock market 
analysis software does.  For example price plot with MACD below it?

I know that there exists a function called plotOHLC or ohlcPlot but have no 
clue how to start plotting. I can imagine I need to tell the software the 
date range and then the cells of data to be plotted. Could I see some 
examples of that based on the data file I provided?

Thanks a lot for any clues.

Andy


From dave at kanecap.com  Sat Oct 21 23:14:50 2006
From: dave at kanecap.com (David Kane)
Date: Sat, 21 Oct 2006 17:14:50 -0400
Subject: [R-SIG-Finance] How to try technical indicators, fMultivar
In-Reply-To: <200610211608.47615.kb2qzv@poczta.wp.pl>
References: <200610211608.47615.kb2qzv@poczta.wp.pl>
Message-ID: <17722.36298.863123.337929@gargle.gargle.HOWL>

Andy (Lists) writes:
 > So far so good but when I check the object "wig20" I can see that it looks a 
 > little different than what the original file:
 > wig20
 > 2851     WIG20      20051024 2322.77 2357.95 2322.77  2339.41  763810.17
 > 2852     WIG20      20051025 2353.27 2372.36 2344.46  2360.77  654536.99
 > 2853     WIG20      20051026 2373.50 2380.10 2310.39  2340.24  807947.58
 > 2854     WIG20      20051027 2291.66 2307.86 2285.16  2302.53  711165.29
 > 2855     WIG20      20051028 2283.72 2320.37 2273.49  2316.55  538880.20
 > 
 > What are those numbers before the ticker value WIG20? I hope this is something 
 > that I can just ignore. But it would be good to know what they are.

They look like row numbers to me. I think that you need to go through
An Introduction to R before you proceed any further. Once you have
that basic understanding of the software, you can ask more questions.

Good luck and welcome to R!

Dave Kane


From tom.soyer at gmail.com  Sun Oct 22 16:45:11 2006
From: tom.soyer at gmail.com (tom soyer)
Date: Sun, 22 Oct 2006 09:45:11 -0500
Subject: [R-SIG-Finance] Where is the R Finance website?
Message-ID: <65cc7bdf0610220745y2506191fgd0d1fa95884c1e45@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061022/99f61518/attachment.pl 

From ggrothendieck at gmail.com  Sun Oct 22 17:01:48 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 22 Oct 2006 11:01:48 -0400
Subject: [R-SIG-Finance] Where is the R Finance website?
In-Reply-To: <65cc7bdf0610220745y2506191fgd0d1fa95884c1e45@mail.gmail.com>
References: <65cc7bdf0610220745y2506191fgd0d1fa95884c1e45@mail.gmail.com>
Message-ID: <971536df0610220801s7cf922bod13e61501f1dcc7@mail.gmail.com>

The Task Views summarize which packages might be
relevant and some packages have their own web sites.
   http://cran.r-project.org/src/contrib/Views/
Within the task view click on each package and
if there is a URL entry on its page then that will
generally be its home page.

On 10/22/06, tom soyer <tom.soyer at gmail.com> wrote:
> Hi,
>
> Does R SIG Finance have its own website? If not, then are there
> websites that focus on using R for financial analysis?
>
> Thanks,
>
> Tom
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From tom.soyer at gmail.com  Sun Oct 22 18:11:17 2006
From: tom.soyer at gmail.com (tom soyer)
Date: Sun, 22 Oct 2006 11:11:17 -0500
Subject: [R-SIG-Finance] Where is the R Finance website?
In-Reply-To: <971536df0610220801s7cf922bod13e61501f1dcc7@mail.gmail.com>
References: <65cc7bdf0610220745y2506191fgd0d1fa95884c1e45@mail.gmail.com>
	<971536df0610220801s7cf922bod13e61501f1dcc7@mail.gmail.com>
Message-ID: <65cc7bdf0610220911u3ea155baye688e0a567749d92@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061022/1d580774/attachment.pl 

From edd at debian.org  Sun Oct 22 23:06:19 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 22 Oct 2006 16:06:19 -0500
Subject: [R-SIG-Finance] Where is the R Finance website?
In-Reply-To: <971536df0610220801s7cf922bod13e61501f1dcc7@mail.gmail.com>
References: <65cc7bdf0610220745y2506191fgd0d1fa95884c1e45@mail.gmail.com>
	<971536df0610220801s7cf922bod13e61501f1dcc7@mail.gmail.com>
Message-ID: <17723.56651.325204.866791@basebud.nulle.part>


On 22 October 2006 at 11:01, Gabor Grothendieck wrote:
| The Task Views summarize which packages might be
| relevant and some packages have their own web sites.
|    http://cran.r-project.org/src/contrib/Views/
| Within the task view click on each package and
| if there is a URL entry on its page then that will
| generally be its home page.

Yes, thanks for mentioning the task view. Also, at the bottom is a
'catch-all' list of relevant R/Finance website.  If anybody has further
suggestions, please send them along to me so that I can add them to the
taskview page.

Dirk  
 
-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From Joe-Byers at utulsa.edu  Mon Oct 23 01:35:40 2006
From: Joe-Byers at utulsa.edu (Joe W. Byers)
Date: Sun, 22 Oct 2006 18:35:40 -0500
Subject: [R-SIG-Finance] Help with date arithmetic
Message-ID: <453C004C.7040908@utulsa.edu>

Mark,

Not off base.  I do have a calendar that is only business days created 
to set up a simulation.

I am working on a simulation of Natural gas prices that has spot, 
balance of the month, and forward prices for each business day.  The 
problem I am addressing is that NG spot and balmo trade on a business 
day, but the commodity transfers title on the flow days, or one day 
after the trade date for the spot.  The balmo contract is interesting 
because it starts flowing on the next day after spot gas flows. 
Business days are easy, spot flows one business day after the 
transaction, and balmo flows 2 business days after the transaction.  But 
on the last business day of a week, spot gas is traded for the next 
three days, two non business and one business day (Sat-Mon).  So, balmo 
does not start flowing till the following Tues or four days.  If there 
is a holiday anywhere in here, it has to be handled to get balmo 
correct.  Because spot and balmo have different flow start dates each 
trading day, I have to calculate them instead of using the specified 
contract month as with the NYMEX futures contracts.  The flow date for 
spot and balmo is basically the same as a futures contract month here. 
Another thing to remember with NYMEX NG 1 contract for next Jan is 
10000MMBTU and it flow or in delivered in 1/31 of a contract increments 
starting on Jan 1st.

Equities, fixed income, and others are easy.  Transaction days, 
expiration days, settlement days all line up nice and neatly for 
analysis.  Commodities not so, and carry charges can be significant 
sometimes.  Commodities violate our wonderful Black-scholes world we 
assume exists.

I maybe can use the calendar that I have created and select the first 
business day greater than the trade date I have for the spot and also 
the second for the balmo.  Still a loop, but I may be able to prebuild a 
matrix for these contracts easier than the function I have.

So you are not off base.  You gave me another idea to try.

Thank you very much
Joe

Leeds, Mark (IED) wrote:
 > Joe : I'm just jumping in so excuse me if I'm totally off base. It seems
 > like youa re writing code to jump form one date to the next business
 > day.
 > I'm sure youa re clever and close tog etting it working but whren I do (
 > or did ) in the past to dela with this problem
 > Is just have a series out there that represents only business days. For
 > example, if you pull ibm's data from
 > Yahoo or wherever, it is only
 > Going to come back with business dzy dates.
 >
 > If you need to do the same thing for japan, pull "toyota" from somewhere
 > ( maybe yahoo also ? ) and it will only come back with
 > business day dates for japan.  Anyway, this was always my easy solution
 > but you may have some reason why you can't do it hat way.
 > Your code is way beyond my level of knowledge of R so I can't help you
 > with it.
 >
 >
 >
 > -----Original Message-----
 > From: r-sig-finance-bounces at stat.math.ethz.ch
 > [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Joe W.
 > Byers
 > Sent: Saturday, October 21, 2006 3:31 PM
 > To: r-sig-finance at stat.math.ethz.ch
 > Subject: Re: [R-SIG-Finance] Help with date arithmetic
 >
 > All here is what I came up with to increment over non-business days and
 > NYSE holidays.  I would appreciate any help in refining this code to be
 > more generic for use with vectors, more date formats, and other
 > holidays.  It is extremely slow to run this function over a large time
 > sequence.  I think I could change the code from using fCalendar
 > timesequence() to using the date.mdy()$year for part of the code, but I
 > am still learning these things in R.
 >
 > #function call
 > Bizday.increment('09/25/04',1)
 >
 > # Created by: Joe W. Byers
 > # Date: 10/20/06
 > #Method to increment a give date to the next business day given
 > holidayNYSE() holidays
 > Bizday.increment<-function(data,inc=1,format='%m/%d/%Y'){
 > 	#need to add date coersion if data numeric
 > 	# need to add ability to perform over a vector and return all
 > increments
 > 	# need to add ability to perform with different holidays beside
 > NYSE
 > 	Loop=T; # set loop test
 > 	ans<-format.Date(as.date(data,order='mdy')+inc,format)
 > 	while(Loop==T){
 > 	
 > t1<-isBizday(timeSequence(from=ans,to=ans,format=format),
 > 			holidays=holidayNYSE(as.numeric(
 > 	
 > factor(atoms(timeSequence(from=ans,to=ans,format=format)
 > 			)$Y)@levels)))
 > 		if (t1==T) {Loop=F}
 > 		else
 > {ans<-format.Date(as.date(ans,order='mdy')+inc,format)}
 > 	}
 > 	ans
 > }
 > Thank you
 > Joe
 >
 > Joe W. Byers wrote:
 >> I have the following day
 >> dts<-('02/08/2002');
 >> I want to return a vector of character dates by adding 1 to the
 >> current day and adding the number of non business days for a weekend
 >> and/or holiday if they occur to get the following results
 >>
 >> should.be.results<-('02/09/2002','02/12/2002');
 >>
 >> I can handle the first calculation but I can not find how to increment
 >
 >> the date for non business days.
 >>
 >> results<-c(format.Date(as.date(dts,order='mdy')+1,'%m/%d/%Y'),
 >> 	I need help  here);
 >>
 >> I have review the fCalendar docs and others.  I have also created a
 >> time sequence for this project where I removed the non-business days
 >> using the isBizday method.  Any help is greatly appreciated.
 >> Thank you
 >> Joe
 >>
 >
 > _______________________________________________
 > R-SIG-Finance at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
 > --------------------------------------------------------
 >
 > This is not an offer (or solicitation of an offer) to buy/sell the 
securities/instruments mentioned or an official confirmation.  Morgan 
Stanley may deal as principal in or own or act as market maker for 
securities/instruments mentioned or may advise the issuers.  This is not 
research and is not from MS Research but it may refer to a research 
analyst/research report.  Unless indicated, these views are the author's 
and may differ from those of Morgan Stanley research or others in the 
Firm.  We do not represent this is accurate or complete and we may not 
update this.  Past performance is not indicative of future returns.  For 
additional information, research reports and important disclosures, 
contact me or see https://secure.ms.com/servlet/cls.  You should not use 
e-mail to request, authorize or effect the purchase or sale of any 
security or instrument, to send transfer instructions, or to effect any 
other transactions.  We cannot guarantee that any such requests received 
via e-mail will be processed in a timely manner.  This communication is 
solely for the addressee(s) and may contain confidential information. 
We do not waive confidentiality by mistransmission.  Contact me if you 
do not wish to receive these communications.  In the UK, this 
communication is directed in the UK to those persons who are market 
counterparties or intermediate customers (as defined in the UK Financial 
Services Authority's rules).


From spencer.graves at pdf.com  Tue Oct 24 06:50:54 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 23 Oct 2006 21:50:54 -0700
Subject: [R-SIG-Finance] DCC-MGARCH
In-Reply-To: <20061016113633.82480.qmail@web26612.mail.ukl.yahoo.com>
References: <20061016113633.82480.qmail@web26612.mail.ukl.yahoo.com>
Message-ID: <453D9BAE.4010100@pdf.com>

  RSiteSearch("MGARCH") returned 10 hits. Have you reviewed these to see 
if any can handle "dynamic conditional correlation"? If not, I would 
think that some of what is available could be modified or extended 
without excessive difficulty to do what you want. Similarly, Google 
returned 43 hits for "DCC-MGARCH". Have you reviewed those to see what 
software they used? Depending on the language in which these other 
algorithms have been programmed, it might not be too difficult to either 
link from R to it, if it is written in a standard compiled language, or 
to translate the code into R, if it is something like Matlab.

If you'd like further help from this listserve, please provide 
commented, minimal, self-contained, reproducible code, as suggested in 
the posting guide "www.R-project.org/posting-guide.html".

Hope this helps.
Spencer Graves

bechir raggad wrote:
> Hi,
>     I?m interested in application of DCC-MGARCH (DCC Engle(2002), Tse and Tsui (2002)) for some financial and economic data. 
>   Would you tell me if  there any existing codes on Splus, R or Gauss?
>
>     Thank you
>
>
>  		
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From fcitta at inwind.it  Thu Oct 26 15:39:11 2006
From: fcitta at inwind.it (Citta Francesco)
Date: Thu, 26 Oct 2006 15:39:11 +0200
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 29, Issue 9
References: <mailman.17.1161079206.11307.r-sig-finance@stat.math.ethz.ch>
Message-ID: <000301c6f904$3025b200$5f5c1997@y6c3m0>

I have your same problem... I hope to help you at least with the DCC-MGARCH.
First, if you have Matlab in the Sheppard's homepage you can find a very
interesting package about DCC, it covers only the simmetric and simpler DCC
model.
For Gauss you can read the paper "International Stock Markets Interactions
and Conditional Correlations" wrote by Savva, send him an email and ask the
most recent version and the GAUSS code (christos.savva at manchester.ac.uk).
In R I find the estimation very hard. You can start visting the Patrick
Burn's homepage: http://www.burns-stat.com/ and download the paper called
"Multivariate GARCH with Only Univariate Estimation". Alternatively or in
addition, you can visit the Vehbi Sinan's homepage:
http://www.vsthost.com/old/vstDocs/projects/R/mgarchBEKK/
It is usefull for the BEKK estimation but reading the documentation it seems
that it is possible to extend this estimation to the DCC model but I am not
able...
If you find something about DCC tell me...
Good luck
----- Original Message -----
From: <r-sig-finance-request at stat.math.ethz.ch>
To: <r-sig-finance at stat.math.ethz.ch>
Sent: Tuesday, October 17, 2006 12:00 PM
Subject: R-SIG-Finance Digest, Vol 29, Issue 9


> Send R-SIG-Finance mailing list submissions to
> r-sig-finance at stat.math.ethz.ch
>
> To subscribe or unsubscribe via the World Wide Web, visit
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> or, via email, send a message with subject or body 'help' to
> r-sig-finance-request at stat.math.ethz.ch
>
> You can reach the person managing the list at
> r-sig-finance-owner at stat.math.ethz.ch
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-SIG-Finance digest..."
>
>
> Today's Topics:
>
>   1. DCC-MGARCH (bechir raggad)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 16 Oct 2006 13:36:33 +0200 (CEST)
> From: bechir raggad <raggadbechir at yahoo.fr>
> Subject: [R-SIG-Finance] DCC-MGARCH
> To: r-sig-finance at stat.math.ethz.ch
> Message-ID: <20061016113633.82480.qmail at web26612.mail.ukl.yahoo.com>
> Content-Type: text/plain
>
> Hi,
>    I'm interested in application of DCC-MGARCH (DCC Engle(2002), Tse and
> Tsui (2002)) for some financial and economic data.
>  Would you tell me if  there any existing codes on Splus, R or Gauss?
>
>    Thank you
>
>
>
> ---------------------------------
>
> [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> _______________________________________________
> R-SIG-Finance mailing list
> R-SIG-Finance at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>
>
> End of R-SIG-Finance Digest, Vol 29, Issue 9
> ********************************************


From spencer.graves at pdf.com  Thu Oct 26 19:44:51 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 26 Oct 2006 10:44:51 -0700
Subject: [R-SIG-Finance] R Implementation of FIX
In-Reply-To: <GPEPLHOKJEHOCLMBOODGKEBDGNAA.tjohnson@covad.net>
References: <GPEPLHOKJEHOCLMBOODGKEBDGNAA.tjohnson@covad.net>
Message-ID: <4540F413.7080908@pdf.com>

      I'm not familiar with the "Financial Information eXchange" 
protocol, but RSiteSearch("financial information exchange") produced 5 
hits for me just now.  Two of these referenced HighFrequencyDataTools 
{fCalendar} and MarketStatistics {fBasics}.  RSiteSearch("download", 
"functions") produced 75 hits, and h("download financial data", 
"functions") returned only 4 hits. 

      If you'd like further help from this list, please submit another 
post.  When you do, please outline very briefly what you've tried and 
include a simple, self-contained example of something that seemed the 
closest to what you want, explaining its deficiencies. 

      Hope this helps. 
      Spencer Graves

Tom Johnson wrote:
> Does anyone please know of an example of R (or S-Plus) code being used to
> implement the FIX ("Financial Information eXchange") protocol for
> communicating securities transactions between two parties?  I only know of
> implementations in C++, Visual Basic, Delphi, Java, etc.  Thanking you for
> any leads,  Tom
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From edd at debian.org  Thu Oct 26 20:02:17 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 26 Oct 2006 13:02:17 -0500
Subject: [R-SIG-Finance] R Implementation of FIX
In-Reply-To: <GPEPLHOKJEHOCLMBOODGKEBDGNAA.tjohnson@covad.net>
References: <GPEPLHOKJEHOCLMBOODGKEBDGNAA.tjohnson@covad.net>
Message-ID: <17728.63529.790498.336394@basebud.nulle.part>


On 18 October 2006 at 21:23, Tom Johnson wrote:
| Does anyone please know of an example of R (or S-Plus) code being used to
| implement the FIX ("Financial Information eXchange") protocol for
| communicating securities transactions between two parties?  I only know of
| implementations in C++, Visual Basic, Delphi, Java, etc.  Thanking you for
| any leads,  Tom

Your best best, IMHO, is to take one of those C++ libraries and to write some
R glue code.  Or to higher someone who can do it for you.

There are numerous example packages on CRAN which do exactly that: provide R
access to and from external libraries, often written in C, C++ or Fortran.

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From brian at braverock.com  Thu Oct 26 20:17:08 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 26 Oct 2006 13:17:08 -0500
Subject: [R-SIG-Finance] R Implementation of FIX
In-Reply-To: <4540F413.7080908@pdf.com>
References: <GPEPLHOKJEHOCLMBOODGKEBDGNAA.tjohnson@covad.net>
	<4540F413.7080908@pdf.com>
Message-ID: <200610261317.08962.brian@braverock.com>

On Thursday 26 October 2006 12:44, Spencer Graves wrote:
> I'm not familiar with the "Financial Information eXchange"
> protocol, but RSiteSearch("financial information exchange") produced 5
> hits for me just now. ?Two of these referenced HighFrequencyDataTools
> {fCalendar} and MarketStatistics {fBasics}. ?RSiteSearch("download",
> "functions") produced 75 hits, and h("download financial data",
> "functions") returned only 4 hits.

FIX is a protocol used most often for data feeds from exchanges or 
clearing brokers.  Generally, it is used for high-frequency order and 
confirmation data on transactions, although the protocol also contains 
data types for a number of other types of records, including tick data.  
I am not aware of and could not locate an R implementation of FIX.

I think Dirk's suggestion to use one of the C/C++ FIX libraries and glue 
it to R is probably the correct one.  You may wish to consider an open 
FIX implementation like QuickFIX, which is probably the most widely used 
and best tested open source implementation of FIX.

http://www.quickfixengine.org/

Hopefully, if you manage to implement an R wrapper around a FIX library, 
you will consider sharing it with the community so that no one else will 
have your problem in the future.

Regards,

   - Brian


From spencer.graves at pdf.com  Sun Oct 29 03:36:15 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 28 Oct 2006 19:36:15 -0700
Subject: [R-SIG-Finance] Adding NYMEX to holidays calendar
In-Reply-To: <ehb0k2$8d0$1@sea.gmane.org>
References: <ehb0k2$8d0$1@sea.gmane.org>
Message-ID: <4544139F.8000502@pdf.com>

      What level of help do you need?  Have you tried listing the 
function 'holidayNYSE', making a local copy, then editing it do what you 
want?  After you've tried that, please send the results to Diethelm 
Wuertz and me.  If you can't make it work, please explain the problem. 

      Hope this helps. 
      Spencer Graves

Joe W. Byers wrote:
> Rmetrics
>
> Can anyone help me create a new holidays calendar method like 
> holidaysNYSE() for NYMEX holidays.  The only difference is the holidays 
> for Independence day and thanks giving.
> Independence Day
> 	Monday, July 3*
> 	Tuesday, July 4
> 	(Electronic trading closed Sunday and Monday, July 2 and 3; reopens 
> 6:00 PM, July 4)
> Thanksgiving
> 	Thursday, November 23
> 	Friday, November 24
> 	(NYMEX ClearPort? and CME Globex? open both days)
>
> NYMEX is closed on Monday July 3rd this year since the 4th is on a 
> Tuesday and Friday the day following Thanksgiving.  This will end in 
> 2007 according to NYMEX.  The Independence day holiday I think will 
> observe Friday as a holiday when the 4th is on a Thurs but, according to 
> NYMEX they are not sure for 2007.  Also the webpage 
> http://www.nymex.com/holida_schedu.aspx notes that Christmas eve will 
> become a holiday in 2007 but expirations will not change.  I am sending 
> their customer service a request to post a document with the holiday 
> rules as well as these tables for those of us who worry about a 
> derivatives calendar.
>
> Thank you
> Joe
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From joe-byers at utulsa.edu  Sun Oct 29 04:19:38 2006
From: joe-byers at utulsa.edu (Joe Byers)
Date: Sat, 28 Oct 2006 22:19:38 -0500
Subject: [R-SIG-Finance] Adding NYMEX to holidays calendar
In-Reply-To: <4544139F.8000502@pdf.com>
References: <ehb0k2$8d0$1@sea.gmane.org> <4544139F.8000502@pdf.com>
Message-ID: <45441DCA.6090808@utulsa.edu>

Spencer,

I will look at the code for holidayNYSE.  I had several conversations 
with NYMEX right after I posted my message so I wanted to make sure I 
had a handle on their upcoming changes for 2007.  These changes will 
require several test within the holiday method.  I also need to get the 
a couple of years from NYMEX and compare to NYSE to see how much they 
will differ for the current holidays and the proposed changes.  I have 
given NYMEX rmetrics links and quantlib links to the calendar libraries 
of these two software packages along with links to other calendar rules 
posted for NYSE, NERC,... in hopes that NYMEX will post the actual rules 
they use for their holiday calendars.  This would alleviate me from 
implying the rules.  Even if NYMEX would say we follow the "Federal 
holidays" and any others would help minimize assumptions on my part.

I will see what I can come up with and send to you both.

Thank you for your reply.

Joe


Spencer Graves wrote:
>      What level of help do you need?  Have you tried listing the 
> function 'holidayNYSE', making a local copy, then editing it do what 
> you want?  After you've tried that, please send the results to 
> Diethelm Wuertz and me.  If you can't make it work, please explain the 
> problem.
>      Hope this helps.      Spencer Graves
>
> Joe W. Byers wrote:
>> Rmetrics
>>
>> Can anyone help me create a new holidays calendar method like 
>> holidaysNYSE() for NYMEX holidays.  The only difference is the 
>> holidays for Independence day and thanks giving.
>> Independence Day
>>     Monday, July 3*
>>     Tuesday, July 4
>>     (Electronic trading closed Sunday and Monday, July 2 and 3; 
>> reopens 6:00 PM, July 4)
>> Thanksgiving
>>     Thursday, November 23
>>     Friday, November 24
>>     (NYMEX ClearPort? and CME Globex? open both days)
>>
>> NYMEX is closed on Monday July 3rd this year since the 4th is on a 
>> Tuesday and Friday the day following Thanksgiving.  This will end in 
>> 2007 according to NYMEX.  The Independence day holiday I think will 
>> observe Friday as a holiday when the 4th is on a Thurs but, according 
>> to NYMEX they are not sure for 2007.  Also the webpage 
>> http://www.nymex.com/holida_schedu.aspx notes that Christmas eve will 
>> become a holiday in 2007 but expirations will not change.  I am 
>> sending their customer service a request to post a document with the 
>> holiday rules as well as these tables for those of us who worry about 
>> a derivatives calendar.
>>
>> Thank you
>> Joe
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>   
-------------- next part --------------
A non-text attachment was scrubbed...
Name: joe-byers.vcf
Type: text/x-vcard
Size: 104 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061028/5137a564/attachment.vcf 

From tjohnson at covad.net  Mon Oct 30 21:05:21 2006
From: tjohnson at covad.net (Tom Johnson)
Date: Mon, 30 Oct 2006 12:05:21 -0800
Subject: [R-SIG-Finance] R Implementation of FIX
In-Reply-To: <mailman.17.1161943206.32467.r-sig-finance@stat.math.ethz.ch>
Message-ID: <GPEPLHOKJEHOCLMBOODGKEKMGNAA.tjohnson@covad.net>

After review, the R wrapper with FIX would appear best, but a gui interface
will do instead.  Thank you, Tom

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch]On Behalf Of
r-sig-finance-request at stat.math.ethz.ch
Sent: Friday, October 27, 2006 03:00
To: r-sig-finance at stat.math.ethz.ch
Subject: R-SIG-Finance Digest, Vol 29, Issue 15


Send R-SIG-Finance mailing list submissions to
	r-sig-finance at stat.math.ethz.ch

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-finance
or, via email, send a message with subject or body 'help' to
	r-sig-finance-request at stat.math.ethz.ch

You can reach the person managing the list at
	r-sig-finance-owner at stat.math.ethz.ch

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-SIG-Finance digest..."


Today's Topics:

   1. Re: R-SIG-Finance Digest, Vol 29, Issue 9 (Citta Francesco)
   2. Re: R Implementation of FIX (Spencer Graves)
   3. Re: R Implementation of FIX (Dirk Eddelbuettel)
   4. Re: R Implementation of FIX (Brian G. Peterson)


----------------------------------------------------------------------

Message: 1
Date: Thu, 26 Oct 2006 15:39:11 +0200
From: "Citta Francesco" <fcitta at inwind.it>
Subject: Re: [R-SIG-Finance] R-SIG-Finance Digest, Vol 29, Issue 9
To: <r-sig-finance at stat.math.ethz.ch>
Message-ID: <000301c6f904$3025b200$5f5c1997 at y6c3m0>
Content-Type: text/plain;	charset="iso-8859-1"

I have your same problem... I hope to help you at least with the DCC-MGARCH.
First, if you have Matlab in the Sheppard's homepage you can find a very
interesting package about DCC, it covers only the simmetric and simpler DCC
model.
For Gauss you can read the paper "International Stock Markets Interactions
and Conditional Correlations" wrote by Savva, send him an email and ask the
most recent version and the GAUSS code (christos.savva at manchester.ac.uk).
In R I find the estimation very hard. You can start visting the Patrick
Burn's homepage: http://www.burns-stat.com/ and download the paper called
"Multivariate GARCH with Only Univariate Estimation". Alternatively or in
addition, you can visit the Vehbi Sinan's homepage:
http://www.vsthost.com/old/vstDocs/projects/R/mgarchBEKK/
It is usefull for the BEKK estimation but reading the documentation it seems
that it is possible to extend this estimation to the DCC model but I am not
able...
If you find something about DCC tell me...
Good luck
----- Original Message -----
From: <r-sig-finance-request at stat.math.ethz.ch>
To: <r-sig-finance at stat.math.ethz.ch>
Sent: Tuesday, October 17, 2006 12:00 PM
Subject: R-SIG-Finance Digest, Vol 29, Issue 9


> Send R-SIG-Finance mailing list submissions to
> r-sig-finance at stat.math.ethz.ch
>
> To subscribe or unsubscribe via the World Wide Web, visit
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> or, via email, send a message with subject or body 'help' to
> r-sig-finance-request at stat.math.ethz.ch
>
> You can reach the person managing the list at
> r-sig-finance-owner at stat.math.ethz.ch
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-SIG-Finance digest..."
>
>
> Today's Topics:
>
>   1. DCC-MGARCH (bechir raggad)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 16 Oct 2006 13:36:33 +0200 (CEST)
> From: bechir raggad <raggadbechir at yahoo.fr>
> Subject: [R-SIG-Finance] DCC-MGARCH
> To: r-sig-finance at stat.math.ethz.ch
> Message-ID: <20061016113633.82480.qmail at web26612.mail.ukl.yahoo.com>
> Content-Type: text/plain
>
> Hi,
>    I'm interested in application of DCC-MGARCH (DCC Engle(2002), Tse and
> Tsui (2002)) for some financial and economic data.
>  Would you tell me if  there any existing codes on Splus, R or Gauss?
>
>    Thank you
>
>
>
> ---------------------------------
>
> [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> _______________________________________________
> R-SIG-Finance mailing list
> R-SIG-Finance at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>
>
> End of R-SIG-Finance Digest, Vol 29, Issue 9
> ********************************************



------------------------------

Message: 2
Date: Thu, 26 Oct 2006 10:44:51 -0700
From: Spencer Graves <spencer.graves at pdf.com>
Subject: Re: [R-SIG-Finance] R Implementation of FIX
To: Tom Johnson <tjohnson at covad.net>
Cc: r-sig-finance at stat.math.ethz.ch
Message-ID: <4540F413.7080908 at pdf.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

      I'm not familiar with the "Financial Information eXchange"
protocol, but RSiteSearch("financial information exchange") produced 5
hits for me just now.  Two of these referenced HighFrequencyDataTools
{fCalendar} and MarketStatistics {fBasics}.  RSiteSearch("download",
"functions") produced 75 hits, and h("download financial data",
"functions") returned only 4 hits.

      If you'd like further help from this list, please submit another
post.  When you do, please outline very briefly what you've tried and
include a simple, self-contained example of something that seemed the
closest to what you want, explaining its deficiencies.

      Hope this helps.
      Spencer Graves

Tom Johnson wrote:
> Does anyone please know of an example of R (or S-Plus) code being used to
> implement the FIX ("Financial Information eXchange") protocol for
> communicating securities transactions between two parties?  I only know of
> implementations in C++, Visual Basic, Delphi, Java, etc.  Thanking you for
> any leads,  Tom
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>



------------------------------

Message: 3
Date: Thu, 26 Oct 2006 13:02:17 -0500
From: Dirk Eddelbuettel <edd at debian.org>
Subject: Re: [R-SIG-Finance] R Implementation of FIX
To: "Tom Johnson" <tjohnson at covad.net>
Cc: r-sig-finance at stat.math.ethz.ch
Message-ID: <17728.63529.790498.336394 at basebud.nulle.part>
Content-Type: text/plain; charset=us-ascii


On 18 October 2006 at 21:23, Tom Johnson wrote:
| Does anyone please know of an example of R (or S-Plus) code being used to
| implement the FIX ("Financial Information eXchange") protocol for
| communicating securities transactions between two parties?  I only know of
| implementations in C++, Visual Basic, Delphi, Java, etc.  Thanking you for
| any leads,  Tom

Your best best, IMHO, is to take one of those C++ libraries and to write
some
R glue code.  Or to higher someone who can do it for you.

There are numerous example packages on CRAN which do exactly that: provide R
access to and from external libraries, often written in C, C++ or Fortran.

Dirk

--
Hell, there are no rules here - we're trying to accomplish something.
                                                  -- Thomas A. Edison



------------------------------

Message: 4
Date: Thu, 26 Oct 2006 13:17:08 -0500
From: "Brian G. Peterson" <brian at braverock.com>
Subject: Re: [R-SIG-Finance] R Implementation of FIX
To: r-sig-finance at stat.math.ethz.ch
Cc: Tom Johnson <tjohnson at covad.net>
Message-ID: <200610261317.08962.brian at braverock.com>
Content-Type: text/plain;  charset="iso-8859-1"

On Thursday 26 October 2006 12:44, Spencer Graves wrote:
> I'm not familiar with the "Financial Information eXchange"
> protocol, but RSiteSearch("financial information exchange") produced 5
> hits for me just now. ?Two of these referenced HighFrequencyDataTools
> {fCalendar} and MarketStatistics {fBasics}. ?RSiteSearch("download",
> "functions") produced 75 hits, and h("download financial data",
> "functions") returned only 4 hits.

FIX is a protocol used most often for data feeds from exchanges or
clearing brokers.  Generally, it is used for high-frequency order and
confirmation data on transactions, although the protocol also contains
data types for a number of other types of records, including tick data.
I am not aware of and could not locate an R implementation of FIX.

I think Dirk's suggestion to use one of the C/C++ FIX libraries and glue
it to R is probably the correct one.  You may wish to consider an open
FIX implementation like QuickFIX, which is probably the most widely used
and best tested open source implementation of FIX.

http://www.quickfixengine.org/

Hopefully, if you manage to implement an R wrapper around a FIX library,
you will consider sharing it with the community so that no one else will
have your problem in the future.

Regards,

   - Brian



------------------------------

_______________________________________________
R-SIG-Finance mailing list
R-SIG-Finance at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-finance


End of R-SIG-Finance Digest, Vol 29, Issue 15


From Xiaochen.Sun at brunel.ac.uk  Tue Oct 31 00:33:31 2006
From: Xiaochen.Sun at brunel.ac.uk (Xiaochen Sun)
Date: Mon, 30 Oct 2006 23:33:31 -0000
Subject: [R-SIG-Finance] 3-D graphing in quantile curve
Message-ID: <4053699F3E4AD04BA536A5F6BB81A2CFF91FCA@UXEXMBU116.academic.windsor>

Dear list, 

I have a problem on my research project. I have three time series data, u1, u2 and v, I get the conditional distribution F1(u2|u1)and F2(v|u1) first, then produce the quantile curve by using formula: y = qgev(pnorm(rho*qnormF1(u2|u1)+sqrt(1-rho^2)*qnorm(P))),xi,mu,sigma)
P,here is the different quantile: 0.05,0.1,0.5,0.9,0.95.

I wonder how could I produce 3-dimentional graph?

I have tried scatterplot3d(u1,u2,y), any other method?

Appreciate for any reply.

Thanks
Mc


From Rob.Hyndman at buseco.monash.edu.au  Tue Oct 31 05:44:23 2006
From: Rob.Hyndman at buseco.monash.edu.au (Rob Hyndman)
Date: Tue, 31 Oct 2006 15:44:23 +1100
Subject: [R-SIG-Finance] 3-D graphing in quantile curve
In-Reply-To: <4053699F3E4AD04BA536A5F6BB81A2CFF91FCA@UXEXMBU116.academic.windsor>
References: <4053699F3E4AD04BA536A5F6BB81A2CFF91FCA@UXEXMBU116.academic.windsor>
Message-ID: <4546D4A7.7040600@buseco.monash.edu.au>

One solution is to use coplot() which is a wonderful, but underused, function in 
R/S+.

Another possibility is try the function plot.cde() in the hdrcde package. This 
is designed for plotting conditional density estimates. But it could probably be 
fooled into plotting conditional quantile estimates without too much difficulty. 
It will handle one or two conditioning variables. The plots are either stacked 
densities or highest density region strips.

Or you could try persp(), image(), contour(), etc.

Best wishes,
Rob



Xiaochen Sun wrote:
> Dear list, 
> 
> I have a problem on my research project. I have three time series data, u1, u2 and v, I get the conditional distribution F1(u2|u1)and F2(v|u1) first, then produce the quantile curve by using formula: y = qgev(pnorm(rho*qnormF1(u2|u1)+sqrt(1-rho^2)*qnorm(P))),xi,mu,sigma)
> P,here is the different quantile: 0.05,0.1,0.5,0.9,0.95.
> 
> I wonder how could I produce 3-dimentional graph?
> 
> I have tried scatterplot3d(u1,u2,y), any other method?
> 
> Appreciate for any reply.
> 
> Thanks
> Mc
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance

-- 
__________________________________________________
Professor Rob J Hyndman
Department of Econometrics & Business Statistics,
Monash University, VIC 3800, Australia
http://www.robhyndman.info/


From alte at comcast.net  Tue Oct 31 06:01:46 2006
From: alte at comcast.net (jk)
Date: Tue, 31 Oct 2006 00:01:46 -0500
Subject: [R-SIG-Finance] beginner asks:
Message-ID: <4546D8BA.9080806@comcast.net>

below is from an available online textbook.  as an experienced user can 
see, the below text is "how" to determine %s of winning come-out rolls 
(7 or 11) in a 1000 games of craps.  I cannot figure out how to stick 
this query into R correctly.  at the first prompt i make the vector of 
length 1000 filled with 0s called "wins"
i hit enter.
get a fresh prompt, so far so good. But the rest of the example in the 
book does not seem to paste so simply.
What is frustrating is the first example in this book shows the prompt 
at each line. So it's clear what to type and where. But in this one, 
only the second example, i've tried a dozen variations always with the 
correct text sequentially to no avail.  syntax errors.  I'd sure be 
grateful for some guidance.  thanks, john kuhn


Now we have to figure out how to simulate the Come-out roll and decide 
whether
the shooter wins. Clearly, we begin by simulating the roll of two dice. 
So our snippet
expands to
# make a vector of length 1000, filled with 0?s
wins <- rep ( 0, 1000 )
for ( i in 1:1000 ) {
d <- sample ( 1:6, 2, replace=T )
if ( sum(d) == 7 || sum(d) == 11 ) wins[i] <- 1
}sum ( wins ) # print the number of wins


From jeff.a.ryan at gmail.com  Tue Oct 31 06:50:29 2006
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 30 Oct 2006 23:50:29 -0600
Subject: [R-SIG-Finance] beginner asks:
In-Reply-To: <4546D8BA.9080806@comcast.net>
References: <4546D8BA.9080806@comcast.net>
Message-ID: <e8e755250610302150u4092fffap8e56c4b3681fe581@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061030/52aca4bf/attachment.pl 

From Xiaochen.Sun at brunel.ac.uk  Tue Nov  7 11:16:47 2006
From: Xiaochen.Sun at brunel.ac.uk (Xiaochen Sun)
Date: Tue, 7 Nov 2006 10:16:47 -0000
Subject: [R-SIG-Finance] CONTINUOUS TIME FINANCE with S-Plus
Message-ID: <4053699F3E4AD04BA536A5F6BB81A2CFF91FE8@UXEXMBU116.academic.windsor>

Dear list, we are pleased to announce the following workshop with S-Plus:
 

CONTINUOUS TIME FINANCE with S-Plus

CONTINUOUS TIME FINANCE with S-Plus
27-29 November 2006, Brunel University, West London, UK
(www.unicom.co.uk/finance)

Background
Three-day workshop presented by Dr Paresh Date and Mr Luka Jalen,
CARISMA: The Centre for the Analysis of Risk and Optimisation Modelling
Applications, Brunel University

Whether it is mergers and acquisitions, derivative asset pricing, optimal portfolio choice or risk management, success in modern finance is unthinkable without a solid grasp of mathematics. Continuous time models now play a central role in pricing of financial assets under more challenging circumstances than can be handled with discrete time models. This course introduces models in continuous time and the advanced mathematics required for their analysis such as stochastic analysis (Brownian motion), partial differential equations and martingale measures, and shows how these can be used for asset and derivative valuation in continuous time.
Given the fast pace of development of finance theory and product innovation in recent times, the course will be of great value to banking professionals who want to learn basic modelling and pricing methods in investment banking as well as to graduate students starting their doctoral studies in finance.

Course Outline
* Day 1
o Introduction to stochastic calculus
Wiener processes
Linear stochastic differential equations: asset price dynamics
Ito's lemma
o Introduction to Splus for mathematical finance
Writing functions
Random number generation and generating sample paths

*Day 2
o Introduction to pricing and hedging of derivatives
Pricing of futures contracts
Hedging using futures
European Option payoffs and hedging using options
Black-Scholes formula
Delta hedging
o Pricing European options using Monte Carlo in Splus


* Day 3
o Stochastic interest rate models
Spot rates, forward rates and arbitrage
Bond prices and yield curve
Short rate models, Vasicek model
o Calibration of Vasicek model from real yield data using Splus

Each day will include hands-on demonstrations of Splus

Benefits of Attending
You will learn about the latest developments in the field from acknowledged research leaders, gathered together in London. By networking and listening to the presentations, you will gain valuable knowledge and practical techniques to apply your own area of practice or research. You will gain first hand experience of the innovative thinking and best practices currently being developed in some of the world's leading educational institutions.


The target audience
*Graduate students who are starting their doctoral studies in finance
*PhD Research Students
*Academics
*Banking professionals who want to learn basic modelling and pricing methods in investment banking.

This workshop is organized by The Centre for the Analysis of Risk and Optimisation Modelling Applications (CARISMA) at Brunel University and managed by UNICOM Seminars. It takes place at Brunel University campus, West London.

For further details please go to www.unicom.co.uk/finance  or email info at unicom.co.uk  for a PDF flier.

Alternatively you may telephone UNICOM on +44 1895 256 484 for further information.

We look forward to welcoming you to the CONTINUOUS TIME FINANCE, 27-29 November 2006; please also make your colleagues aware of it.

With regards,

Michael

 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
Michael(Xiaochen) Sun
CARISMA, www.carisma.brunel.ac.uk <http://www.carisma.brunel.ac.uk/>  
Centre for the Analysis of Risk and Optimisation Modelling Application; 
School of Computing, Information Systems and Mathematics 
Brunel University 
Uxbridge, UB8 3PH 
United Kingdom 
Email: xiaochen.sun (at) brunel.ac.uk
http://optirisk.googlepages.com/ <http://optirisk.googlepages.com/>  
http://people.brunel.ac.uk/~mapgxcs <http://people.brunel.ac.uk/~mapgxcs>  
Blog: http://mam3xs.blogspot.com <http://mam3xs.blogspot.com/> 
Tel: (+44) (0)1895 265625
Mobile: (+44) (0)7841873292
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


From comtech.usa at gmail.com  Mon Nov 13 05:41:22 2006
From: comtech.usa at gmail.com (Michael)
Date: Sun, 12 Nov 2006 20:41:22 -0800
Subject: [R-SIG-Finance] looking for functions that can test/estimate CAMPM,
	APT, Fama's factor model, etc.
In-Reply-To: <b1f16d9d0611121353qe2676faye41fdd0140f395b0@mail.gmail.com>
References: <b1f16d9d0611121353qe2676faye41fdd0140f395b0@mail.gmail.com>
Message-ID: <b1f16d9d0611122041p51a192d3hfb57f2d0c135dcdf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061112/ae333c16/attachment.pl 

From brian at braverock.com  Mon Nov 13 14:27:34 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 13 Nov 2006 07:27:34 -0600
Subject: [R-SIG-Finance] looking for functions that can test/estimate
	CAPM, APT, Fama's factor model, etc.
In-Reply-To: <b1f16d9d0611122041p51a192d3hfb57f2d0c135dcdf@mail.gmail.com>
References: <b1f16d9d0611121353qe2676faye41fdd0140f395b0@mail.gmail.com>
	<b1f16d9d0611122041p51a192d3hfb57f2d0c135dcdf@mail.gmail.com>
Message-ID: <200611130727.35021.brian@braverock.com>

On Sunday 12 November 2006 22:41, Michael wrote:
> > I am also looking for interesting statistical experiments about
> > testing and estimating CAPM, APT, Fama models, etc. 
> > using R using financial series data... 
> > please give me some pointers... I have been searching 
> > the R archives for the past a few hours and I vaguely got to know
> > that there are programs do these interesting statistical things, but
> > I just could not find where are they...

Look at at the 'portfolio' and 'RMetrics' packages.  RMetrics is actually 
a group of packages, not just a single module.  These should give you 
CAPM and more.

I can also recommend this excellent introductory book:
http://www.amazon.com/Statistics-Finance-Introduction-David-Ruppert/dp/0387202706
Statistics and Finance: An Introduction by David Ruppert

with R examples available here:
http://www.stat.tamu.edu/~ljin/Finance/stat689-R.htm

Once you've worked on this for a while, if you need pointers on a specific 
problem, this list may be able to be of greater assistance.

Regards,

   - Brian


From comtech.usa at gmail.com  Mon Nov 13 19:13:20 2006
From: comtech.usa at gmail.com (Michael)
Date: Mon, 13 Nov 2006 10:13:20 -0800
Subject: [R-SIG-Finance] looking for functions that can test/estimate
	CAPM, APT, Fama's factor model, etc.
In-Reply-To: <200611130727.35021.brian@braverock.com>
References: <b1f16d9d0611121353qe2676faye41fdd0140f395b0@mail.gmail.com>
	<b1f16d9d0611122041p51a192d3hfb57f2d0c135dcdf@mail.gmail.com>
	<200611130727.35021.brian@braverock.com>
Message-ID: <b1f16d9d0611131013l41b725efn44bd18425552e70d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061113/ff03ac1e/attachment.pl 

From comtech.usa at gmail.com  Mon Nov 13 19:35:07 2006
From: comtech.usa at gmail.com (Michael)
Date: Mon, 13 Nov 2006 10:35:07 -0800
Subject: [R-SIG-Finance] use log return or quotient return?
Message-ID: <b1f16d9d0611131035u689278d0oc0c7301175870607@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061113/d76b9af4/attachment.pl 

From Mark.Leeds at morganstanley.com  Mon Nov 13 19:49:36 2006
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Mon, 13 Nov 2006 13:49:36 -0500
Subject: [R-SIG-Finance] use log return or quotient return?
In-Reply-To: <b1f16d9d0611131035u689278d0oc0c7301175870607@mail.gmail.com>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344B64210@NYWEXMB23.msad.ms.com>

Probably log because it's closer to continuous compounding and
continuous compounding is often more realistic.
It sort of depends on the application though.



-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Michael
Sent: Monday, November 13, 2006 1:35 PM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] use log return or quotient return?

Hi all,

Does anybody know which is more commonly used in financial time series
-- log return or quotient return?

Thanks a lot,

M

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From brian at braverock.com  Mon Nov 13 19:56:05 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 13 Nov 2006 12:56:05 -0600
Subject: [R-SIG-Finance] looking for functions that can test/estimate
	CAPM, APT, Fama's factor model, etc.
In-Reply-To: <b1f16d9d0611131013l41b725efn44bd18425552e70d@mail.gmail.com>
References: <b1f16d9d0611121353qe2676faye41fdd0140f395b0@mail.gmail.com>
	<200611130727.35021.brian@braverock.com>
	<b1f16d9d0611131013l41b725efn44bd18425552e70d@mail.gmail.com>
Message-ID: <200611131256.06064.brian@braverock.com>

On Monday 13 November 2006 12:13, Michael wrote:
> thanks a lot for your pointers! I've taken a look at the book and the R
> example website. That's super! Some of the examples there are very
> good.
>
> Yet I am still looking for Fama 3 factor model and Ross' APT
> implementation. The concept is not hard per se, however I am not sure
> how to classify some companies as H, and some companies as L and others
> as Value companies, and the others as Growth companies. There are a lot
> of implementation details that I am not sure of. Thus I guess learning
> from other people's implementation is a better approach for me as a
> green-hand.


Here's a great thread from this list last year about the Fama three-factor 
model:
http://blog.gmane.org/gmane.comp.lang.r.r-metrics/month=20050901

There is a ton of functionality in R for factor modeling, spread through 
lots of different packages.  I'd suggest that you do some searching on 
Primary Factor Analysis or Primary Component Analysis.

The best bet is to use the Value/Growth categorizations done by an 
external body, such as Reuters, Bloomberg, or S&P.  There doesn't seem to 
be much reason for you to independently categorize companies, especially 
in your learning stages.

For Arbitrage Pricing Theory, you've got to decide on a pricing model.  
There are many implementations of many pricing models in R.

> (The Rmetrics are not very complete I guess.)

RMetrics is very complete for what it does, with some notable exceptions 
(fixed income instruments).  I've generally had a lot of luck using 
functions from RMetrics as building blocks for more complex analysis.

Regards,

  - Brian


From ggrothendieck at gmail.com  Mon Nov 13 19:59:17 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 13 Nov 2006 13:59:17 -0500
Subject: [R-SIG-Finance] use log return or quotient return?
In-Reply-To: <b1f16d9d0611131035u689278d0oc0c7301175870607@mail.gmail.com>
References: <b1f16d9d0611131035u689278d0oc0c7301175870607@mail.gmail.com>
Message-ID: <971536df0611131059q3d6fce8cj746b95104f08dceb@mail.gmail.com>

It depends on how good the approximation log(1+r) = r is and that
depends on whether r is sufficiently small or not.

On 11/13/06, Michael <comtech.usa at gmail.com> wrote:
> Hi all,
>
> Does anybody know which is more commonly used in financial time series --
> log return or quotient return?
>
> Thanks a lot,


From jgalt70 at yahoo.com  Mon Nov 13 21:35:54 2006
From: jgalt70 at yahoo.com (Andrew West)
Date: Mon, 13 Nov 2006 12:35:54 -0800 (PST)
Subject: [R-SIG-Finance] looking for functions that can test/estimate
	CAPM, APT, Fama's factor model, etc.
Message-ID: <20061113203554.83462.qmail@web60322.mail.yahoo.com>

This thread reminded me to post a somewhat improved and updated version of the code I was working on last year, re Fama French.
Most notably, I worked up something that would let me visualize how coefficients to value and growth factors change over time. The basic code could be modified to accomplish different goals, e.g. (getting significance test scores on the factors for the company you're looking at, doing the same for a longer list of companies). I once even created a version that treated a list of companies as longitudinal data, and used the lme package to do a mixed effects model for the FF-3 factor model for a list of companies within an industry. The interesting thing is that these coefficients are often not very stationary over time.

 I'm dropping the long, ugly, inadequately commented code below, and attatching it as a text file (I'm not an R-programmer, just someone who was willing to do a lot of trial and error and patch stuff together till I got the output I wanted. In the past some e-mail programs will mess up the code a little, by converting quotes or urls, so watch out for that. I did test it and it works as of R2.4 this afternoon on my Windows XP machine. Good luck.

getrffBeta= function(tool,span) {
require(MASS);
require(tseries);
require(wle)
require(zoo)
stock= (get.hist.quote(instrument = tool, quote =c("Ad"),compression="m",origin= as.Date(0)));
spx=(get.hist.quote(instrument = "^gspc", quote =c("Ad"),compression="m",origin= as.Date(0)));
today=Sys.Date();
seqmo=length(seq(as.Date("1926-07-01"),today,by="month"))-2;
url="http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_Factors.zip";
destfile=tempfile();
dataff=download.file(url, destfile, mode='wb');
unzip=unz(destfile,"F-F_Research_Data_Factors.txt");
ff4 <- read.table(unzip, header=FALSE, sep="",na.strings="NA", dec=".", strip.white=TRUE, skip=4,nrows=seqmo)
ffdata <- ff4
attach(ffdata);
ffdata=ffdata/100
#find out starting year month for ffdata;
ffdatats=ts(ffdata, start=c(1926,7), frequency=12);
stock=ts(na.omit(coredata(stock)), start= as.numeric(as.yearmon(as.Date(start(stock)[1]))),
frequency=12);
spx=ts(na.remove(spx), start=
as.numeric(as.yearmon(as.Date(start(spx)[1]))),
frequency=12);
combined= na.remove(ts.union(stock,spx));
combreturn= na.remove(diff(log(combined)));
combined=na.remove(ts.intersect(combreturn,ffdatats), names=list("stockret", "spxret", "dates","ffmktret","smb","hml","rf"));
combined[,1]=combined[,1]-combined[,7]
combined[,2]=combined[,2]-combined[,7]
simplereg=lm(combined[,1]~combined[,4]);
stockbeta=simplereg$coef[2];
textout=paste("CAPM beta=", stockbeta);
robustreg=wle.lm(combined[,1]~combined[,4]);
robstockbeta=robustreg$coef[2];
textout2=paste("robust stock beta=", robstockbeta);
plot(as.numeric(combined[,1])~as.numeric(combined[,2]),xlab="Market",
ylab=tool)
title(main=textout, sub=list(textout2, col="red"))
abline(coef(simplereg));
abline(coef(robustreg),col="red")
print(textout);
print(textout2);
ffreg=wle.lm(combined[,1]~combined[,4]+combined[,5]+combined[,6]);
ffalpha=ffreg$coef[1]
ffbeta=ffreg$coef[2];
ffsmb=ffreg$coef[3];
ffhml=ffreg$coef[4] ;
textout3a= paste('robust ff alpha=',ffalpha) ;
textout3=paste('robust ff beta=',ffbeta) ;
textout4=paste('robust ff smb=',ffsmb) ;
textout5=paste('robust ff hml=',ffhml) ;
print(textout3a)
print(textout3) ;
print(textout4) ;
print(textout5) ;
rf=5
smb=1
hml=2
rm=5
ffcoe=rf+ffbeta*rm+ffsmb*smb+ffhml*hml
robcoe=rf+robstockbeta*rm
regcoe=rf+stockbeta*rm
textout6=paste('regular coe=',regcoe,' robustcoe=',
robcoe)
textout7=paste('Fama-French coe=',ffcoe)
print(textout6)
print(textout7) ;
ffreg2=lm(combined[,1]~combined[,4]+combined[,5]+combined[,6]);
a1=as.vector(combined[,1])
b1=as.vector(ffreg2$fitted)
c1=as.vector(simplereg$fitted)
plot3= (data.frame(a1,b1,c1))
win.graph()
panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y))
txt <- format(c(r, 0.123456789), digits=digits)[1]
txt <- paste(prefix, txt, sep="")
if(missing(cex.cor)) cex <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex * r)
}
pairs(plot3, upper.panel=panel.cor,labels=c("stock returns","FF fits","CAPM fits"))
ffreg2=lm(combined[,1]~combined[,4]+combined[,5]+combined[,6]);
zcombined=zoo(combined);

zoocoefcapmbeta=function(x) {
zoo.wle=wle.lm(x[,1]~x[,4]);
coef (zoo.wle)
}
rollcoefcapm=rollapply(zcombined,span,zoocoefcapmbeta,by.column=FALSE,align="right");
dfrollcoefcapm=as.data.frame(rollcoefcapm)
names(dfrollcoefcapm)[1]="alpha"
names(dfrollcoefcapm)[2]="mkt beta"
RollingCoefficientsCAPM=zoo(dfrollcoefcapm, order.by=index(rollcoefcapm))
win.graph()
plot(RollingCoefficientsCAPM)
zoocoefsa=function(x) {
zoo.wle=wle.lm(x[,1]~x[,4]+ x[,5]+ x[,6]);
coef (zoo.wle)
}
rollcoef=rollapply(zcombined,span,zoocoefsa,by.column=FALSE,align="right");
dfrollcoef=as.data.frame(rollcoef)
names(dfrollcoef)[1]="alpha"
names(dfrollcoef)[2]="mkt beta"
names(dfrollcoef)[3]="smb"
names(dfrollcoef)[4]="hml"
RollingCoefficients=zoo(dfrollcoef, order.by=index(rollcoef))
win.graph()
plot(RollingCoefficients)
compositecoef=merge(RollingCoefficients, RollingCoefficientsCAPM, zcombined[,7])
rollcapmcoe=function(x){
CAPMCOE=x[6]*rm+rf
}
rollffcoe=function(x){
FFCOE=x[2]*rm+x[3]*smb+x[4]*hml+rf
}
rollffbetacoe=function(x){
FFCOE=x[2]*rm +rf
}

rollffCOE=rollapply(compositecoef,1,rollffcoe,by.column=FALSE,align="right")
rollcapmCOE=rollapply(compositecoef,1,rollcapmcoe,by.column=FALSE,align="right")
rollffbetaCOE=rollapply(compositecoef,1,rollffbetacoe,by.column=FALSE,align="right")
dfrollcoe=as.data.frame(merge(rollffCOE,rollcapmCOE,rollffbetaCOE))
names(dfrollcoe)[1]="FFCOE"
names(dfrollcoe)[2]="CAPMCOE"
names(dfrollcoe)[3]="FF(beta)COE"
RollingCOE=zoo(dfrollcoe,order.by=index(rollcapmCOE))
win.graph()
plot(RollingCOE,plot.type="multiple")
if((AIC(simplereg))<(AIC(ffreg2))) "CAPM superior to FF" else "FF superior to CAPM";
}



----- Original Message ----
From: Brian G. Peterson <brian at braverock.com>
To: r-sig-finance at stat.math.ethz.ch
Sent: Monday, November 13, 2006 1:56:05 PM
Subject: Re: [R-SIG-Finance] looking for functions that can test/estimate CAPM, APT, Fama's factor model, etc.


On Monday 13 November 2006 12:13, Michael wrote:
> thanks a lot for your pointers! I've taken a look at the book and the R
> example website. That's super! Some of the examples there are very
> good.
>
> Yet I am still looking for Fama 3 factor model and Ross' APT
> implementation. The concept is not hard per se, however I am not sure
> how to classify some companies as H, and some companies as L and others
> as Value companies, and the others as Growth companies. There are a lot
> of implementation details that I am not sure of. Thus I guess learning
> from other people's implementation is a better approach for me as a
> green-hand.


Here's a great thread from this list last year about the Fama three-factor 
model:
http://blog.gmane.org/gmane.comp.lang.r.r-metrics/month=20050901

There is a ton of functionality in R for factor modeling, spread through 
lots of different packages.  I'd suggest that you do some searching on 
Primary Factor Analysis or Primary Component Analysis.

The best bet is to use the Value/Growth categorizations done by an 
external body, such as Reuters, Bloomberg, or S&P.  There doesn't seem to 
be much reason for you to independently categorize companies, especially 
in your learning stages.

For Arbitrage Pricing Theory, you've got to decide on a pricing model.  
There are many implementations of many pricing models in R.

> (The Rmetrics are not very complete I guess.)

RMetrics is very complete for what it does, with some notable exceptions 
(fixed income instruments).  I've generally had a lot of luck using 
functions from RMetrics as building blocks for more complex analysis.

Regards,

  - Brian

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance


 
___________________________________________________________________________________

http://voice.yahoo.com
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: getrffBeta.txt
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061113/d443ce24/attachment.txt 

From patrick at burns-stat.com  Tue Nov 14 11:20:16 2006
From: patrick at burns-stat.com (Patrick Burns)
Date: Tue, 14 Nov 2006 10:20:16 +0000
Subject: [R-SIG-Finance] use log return or quotient return?
In-Reply-To: <b1f16d9d0611131035u689278d0oc0c7301175870607@mail.gmail.com>
References: <b1f16d9d0611131035u689278d0oc0c7301175870607@mail.gmail.com>
Message-ID: <45599860.3040502@burns-stat.com>

I think you have the wrong question.  The right
question is: Given what I'm doing, should I use
log returns or simple returns?

Since log returns are additive in time, it doesn't
stretch credibility too much to assume that the
distribution of log returns is Gaussian as the time
period gets large.  With shorter periods the distribution
will be long-tailed, but is often not far from symmetric. 
Hence for many modeling problems it makes sense to
use log returns.

Since simple returns are additive across assets,
it makes sense to use simple returns when going
from individual assets to a portfolio.  Simple returns
are also better understood by investors.

Writing R functions to switch between the two is an
easy exercise left to the reader.  Such functions should
be used as appropriate throughout a project.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Michael wrote:

>Hi all,
>
>Does anybody know which is more commonly used in financial time series --
>log return or quotient return?
>
>Thanks a lot,
>
>M
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-SIG-Finance at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>
>
>  
>


From debmidya at yahoo.com  Tue Nov 14 13:14:03 2006
From: debmidya at yahoo.com (Deb Midya)
Date: Tue, 14 Nov 2006 04:14:03 -0800 (PST)
Subject: [R-SIG-Finance] Fwd: Re: looking for functions that can
	test/estimate CAPM, APT, Fama's factor model, etc.
Message-ID: <20061114121403.61221.qmail@web50405.mail.yahoo.com>

Andrew,
   
  Thanks in advance.
   
  I have run your code and it works well. Will you please clarify the error below:
   
  Error in getrffBeta("BNI", span = 60) : could not find function "rollapply".

  It is required to put appropriate package using require(?) to incorporate the function "rollapply".
   
  May I request you to provide some literature on above topics.
   
  Thanks,
   
  Deb
  
Note: forwarded message attached.

 	
---------------------------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061114/c7971b9b/attachment.html 
-------------- next part --------------
An embedded message was scrubbed...
From: unknown sender
Subject: no subject
Date: no date
Size: 18537
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061114/c7971b9b/attachment.mht 

From jgalt70 at yahoo.com  Tue Nov 14 13:54:43 2006
From: jgalt70 at yahoo.com (Andrew West)
Date: Tue, 14 Nov 2006 04:54:43 -0800 (PST)
Subject: [R-SIG-Finance] Fwd: Re: looking for functions that can
	test/estimate CAPM, APT, Fama's factor model, etc.
Message-ID: <20061114125443.74056.qmail@web60321.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061114/00696b2a/attachment.pl 

From ggrothendieck at gmail.com  Tue Nov 14 14:02:24 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 14 Nov 2006 08:02:24 -0500
Subject: [R-SIG-Finance] Fwd: Re: looking for functions that can
	test/estimate CAPM, APT, Fama's factor model, etc.
In-Reply-To: <20061114125443.74056.qmail@web60321.mail.yahoo.com>
References: <20061114125443.74056.qmail@web60321.mail.yahoo.com>
Message-ID: <971536df0611140502n2677894bh80d1b5c522ae600c@mail.gmail.com>

Note that the reason that rapply was changed to rollapply was that
R base recently introduced a rapply function (but its a recursive lapply
whereas the one in zoo is a rolling one) so the name was changed to avoid
conflicts.

On 11/14/06, Andrew West <jgalt70 at yahoo.com> wrote:
> Deb,
> that sounds like a problem related to the rollapply function in the zoo package. I originally wrote it for an older version of zoo, using the function rapply, but zoo then changed the name of that function from rapply to rollapply. Maybe you haven't updated to the latest version of zoo? If you can't update, change the term "rollapply" to "rapply" and it will work with older zoo packages, but not the most recent.
> Hope this helps,
> Andrew
>
>
> ----- Original Message ----
> From: Deb Midya <debmidya at yahoo.com>
> To: r-sig-finance at stat.math.ethz.ch
> Sent: Tuesday, November 14, 2006 7:14:03 AM
> Subject: [R-SIG-Finance] Fwd: Re: looking for functions that can test/estimate CAPM, APT, Fama's factor model, etc.
>
>
> Andrew,
>
> Thanks in advance.
>
> I have run your code and it works well. Will you please clarify the error below:
>
> Error in getrffBeta("BNI", span = 60) : could not find function "rollapply".
>
> It is required to put appropriate package using require(?) to incorporate the function "rollapply".
>
> May I request you to provide some literature on above topics.
>
> Thanks,
>
> Deb
>
> Note: forwarded message attached.
> X-Originating-IP: [129.132.145.15]
> Authentication-Results: mta356.mail.mud.yahoo.com  from=stat.math.ethz.ch; domainkeys=neutral (no sig)
> Received: from 129.132.145.15  (EHLO hypatia.math.ethz.ch) (129.132.145.15)
>  by mta356.mail.mud.yahoo.com with SMTP; Mon, 13 Nov 2006 12:41:23 -0800
> Received: from hypatia.math.ethz.ch (hypatia [129.132.145.15])
>    by hypatia.math.ethz.ch (8.13.6/8.13.6) with ESMTP id kADKeYpt010461;
>    Mon, 13 Nov 2006 21:40:41 +0100
> X-Spam-Checker-Version: SpamAssassin 3.1.7 (2006-10-05) on hypatia.math.ethz.ch
> X-Spam-Level:
> X-Spam-Status: No, score=0.5 required=5.0 tests=AWL,
>    BAYES_50 autolearn=no version=3.1.7
> Received: from web60322.mail.yahoo.com (web60322.mail.yahoo.com
>    [209.73.178.130])
>    by hypatia.math.ethz.ch (8.13.6/8.13.6) with SMTP id kADKZtp5008571
>    for <r-sig-finance at stat.math.ethz.ch>; Mon, 13 Nov 2006 21:35:56 +0100
> Received: (qmail 83464 invoked by uid 60001); 13 Nov 2006 20:35:54 -0000
> Received: from [71.250.242.218] by web60322.mail.yahoo.com via HTTP;
>    Mon, 13 Nov 2006 12:35:54 PST
> Date: Mon, 13 Nov 2006 12:35:54 -0800 (PST)
>
> To: r-sig-finance at stat.math.ethz.ch
> MIME-Version: 1.0
> Content-Type: multipart/mixed; boundary="0-1294175594-1163450154=:83460"
> X-Virus-Scanned: by amavisd-new at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] looking for functions that can test/estimate
>    CAPM, APT, Fama's factor model, etc.
> X-BeenThere: r-sig-finance at stat.math.ethz.ch
> X-Mailman-Version: 2.1.9
> Precedence: list
> List-Id: Special Interest Group for 'R in Finance'
>    <r-sig-finance.stat.math.ethz.ch>
> List-Unsubscribe: <https://stat.ethz.ch/mailman/listinfo/r-sig-finance>,
>    <mailto:r-sig-finance-request at stat.math.ethz.ch?subject=unsubscribe>
> List-Archive: <https://stat.ethz.ch/pipermail/r-sig-finance>
> List-Post: <mailto:r-sig-finance at stat.math.ethz.ch>
> List-Help: <mailto:r-sig-finance-request at stat.math.ethz.ch?subject=help>
> List-Subscribe: <https://stat.ethz.ch/mailman/listinfo/r-sig-finance>,
>    <mailto:r-sig-finance-request at stat.math.ethz.ch?subject=subscribe>
> Sender: r-sig-finance-bounces at stat.math.ethz.ch
> Errors-To: r-sig-finance-bounces at stat.math.ethz.ch
> Content-Length: 7811
>
> --0-1294175594-1163450154=:83460
> Content-Type: text/plain; charset=ascii
> Content-Transfer-Encoding: quoted-printable
>
> This thread reminded me to post a somewhat improved and updated version of =
> the code I was working on last year, re Fama French.=0AMost notably, I work=
> ed up something that would let me visualize how coefficients to value and g=
> rowth factors change over time. The basic code could be modified to accompl=
> ish different goals, e.g. (getting significance test scores on the factors =
> for the company you're looking at, doing the same for a longer list of comp=
> anies). I once even created a version that treated a list of companies as l=
> ongitudinal data, and used the lme package to do a mixed effects model for =
> the FF-3 factor model for a list of companies within an industry. The inter=
> esting thing is that these coefficients are often not very stationary over =
> time.=0A=0A I'm dropping the long, ugly, inadequately commented code below,=
> and attatching it as a text file (I'm not an R-programmer, just someone wh=
> o was willing to do a lot of trial and error and patch stuff together till =
> I got the output I wanted. In the past some e-mail programs will mess up th=
> e code a little, by converting quotes or urls, so watch out for that. I did=
> test it and it works as of R2.4 this afternoon on my Windows XP machine. G=
> ood luck.=0A=0AgetrffBeta=3D function(tool,span) {=0Arequire(MASS);=0Arequi=
> re(tseries);=0Arequire(wle)=0Arequire(zoo)=0Astock=3D (get.hist.quote(instr=
> ument =3D tool, quote =3Dc("Ad"),compression=3D"m",origin=3D as.Date(0)));=
> =0Aspx=3D(get.hist.quote(instrument =3D "^gspc", quote =3Dc("Ad"),compressi=
> on=3D"m",origin=3D as.Date(0)));=0Atoday=3DSys.Date();=0Aseqmo=3Dlength(seq=
> (as.Date("1926-07-01"),today,by=3D"month"))-2;=0Aurl=3D"http://mba.tuck.dar=
> tmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_Factors.zip";=0Ad=
> estfile=3Dtempfile();=0Adataff=3Ddownload.file(url, destfile, mode=3D'wb');=
> =0Aunzip=3Dunz(destfile,"F-F_Research_Data_Factors.txt");=0Aff4 <- read.tab=
> le(unzip, header=3DFALSE, sep=3D"",na.strings=3D"NA", dec=3D".", strip.whit=
> e=3DTRUE, skip=3D4,nrows=3Dseqmo)=0Affdata <- ff4=0Aattach(ffdata);=0Affdat=
> a=3Dffdata/100=0A#find out starting year month for ffdata;=0Affdatats=3Dts(=
> ffdata, start=3Dc(1926,7), frequency=3D12);=0Astock=3Dts(na.omit(coredata(s=
> tock)), start=3D as.numeric(as.yearmon(as.Date(start(stock)[1]))),=0Afreque=
> ncy=3D12);=0Aspx=3Dts(na.remove(spx), start=3D=0Aas.numeric(as.yearmon(as.D=
> ate(start(spx)[1]))),=0Afrequency=3D12);=0Acombined=3D na.remove(ts.union(s=
> tock,spx));=0Acombreturn=3D na.remove(diff(log(combined)));=0Acombined=3Dna=
> .remove(ts.intersect(combreturn,ffdatats), names=3Dlist("stockret", "spxret=
> ", "dates","ffmktret","smb","hml","rf"));=0Acombined[,1]=3Dcombined[,1]-com=
> bined[,7]=0Acombined[,2]=3Dcombined[,2]-combined[,7]=0Asimplereg=3Dlm(combi=
> ned[,1]~combined[,4]);=0Astockbeta=3Dsimplereg$coef[2];=0Atextout=3Dpaste("=
> CAPM beta=3D", stockbeta);=0Arobustreg=3Dwle.lm(combined[,1]~combined[,4]);=
> =0Arobstockbeta=3Drobustreg$coef[2];=0Atextout2=3Dpaste("robust stock beta=
> =3D", robstockbeta);=0Aplot(as.numeric(combined[,1])~as.numeric(combined[,2=
> ]),xlab=3D"Market",=0Aylab=3Dtool)=0Atitle(main=3Dtextout, sub=3Dlist(texto=
> ut2, col=3D"red"))=0Aabline(coef(simplereg));=0Aabline(coef(robustreg),col=
> =3D"red")=0Aprint(textout);=0Aprint(textout2);=0Affreg=3Dwle.lm(combined[,1=
> ]~combined[,4]+combined[,5]+combined[,6]);=0Affalpha=3Dffreg$coef[1]=0Affbe=
> ta=3Dffreg$coef[2];=0Affsmb=3Dffreg$coef[3];=0Affhml=3Dffreg$coef[4] ;=0Ate=
> xtout3a=3D paste('robust ff alpha=3D',ffalpha) ;=0Atextout3=3Dpaste('robust=
> ff beta=3D',ffbeta) ;=0Atextout4=3Dpaste('robust ff smb=3D',ffsmb) ;=0Atex=
> tout5=3Dpaste('robust ff hml=3D',ffhml) ;=0Aprint(textout3a)=0Aprint(textou=
> t3) ;=0Aprint(textout4) ;=0Aprint(textout5) ;=0Arf=3D5=0Asmb=3D1=0Ahml=3D2=
> =0Arm=3D5=0Affcoe=3Drf+ffbeta*rm+ffsmb*smb+ffhml*hml=0Arobcoe=3Drf+robstock=
> beta*rm=0Aregcoe=3Drf+stockbeta*rm=0Atextout6=3Dpaste('regular coe=3D',regc=
> oe,' robustcoe=3D',=0Arobcoe)=0Atextout7=3Dpaste('Fama-French coe=3D',ffcoe=
> )=0Aprint(textout6)=0Aprint(textout7) ;=0Affreg2=3Dlm(combined[,1]~combined=
> [,4]+combined[,5]+combined[,6]);=0Aa1=3Das.vector(combined[,1])=0Ab1=3Das.v=
> ector(ffreg2$fitted)=0Ac1=3Das.vector(simplereg$fitted)=0Aplot3=3D (data.fr=
> ame(a1,b1,c1))=0Awin.graph()=0Apanel.cor <- function(x, y, digits=3D2, pref=
> ix=3D"", cex.cor)=0A{=0Ausr <- par("usr"); on.exit(par(usr))=0Apar(usr =3D =
> c(0, 1, 0, 1))=0Ar <- abs(cor(x, y))=0Atxt <- format(c(r, 0.123456789), dig=
> its=3Ddigits)[1]=0Atxt <- paste(prefix, txt, sep=3D"")=0Aif(missing(cex.cor=
> )) cex <- 0.8/strwidth(txt)=0Atext(0.5, 0.5, txt, cex =3D cex * r)=0A}=0Apa=
> irs(plot3, upper.panel=3Dpanel.cor,labels=3Dc("stock returns","FF fits","CA=
> PM fits"))=0Affreg2=3Dlm(combined[,1]~combined[,4]+combined[,5]+combined[,6=
> ]);=0Azcombined=3Dzoo(combined);=0A=0Azoocoefcapmbeta=3Dfunction(x) {=0Azoo=
> .wle=3Dwle.lm(x[,1]~x[,4]);=0Acoef (zoo.wle)=0A}=0Arollcoefcapm=3Drollapply=
> (zcombined,span,zoocoefcapmbeta,by.column=3DFALSE,align=3D"right");=0Adfrol=
> lcoefcapm=3Das.data.frame(rollcoefcapm)=0Anames(dfrollcoefcapm)[1]=3D"alpha=
> "=0Anames(dfrollcoefcapm)[2]=3D"mkt beta"=0ARollingCoefficientsCAPM=3Dzoo(d=
> frollcoefcapm, order.by=3Dindex(rollcoefcapm))=0Awin.graph()=0Aplot(Rolling=
> CoefficientsCAPM)=0Azoocoefsa=3Dfunction(x) {=0Azoo.wle=3Dwle.lm(x[,1]~x[,4=
> ]+ x[,5]+ x[,6]);=0Acoef (zoo.wle)=0A}=0Arollcoef=3Drollapply(zcombined,spa=
> n,zoocoefsa,by.column=3DFALSE,align=3D"right");=0Adfrollcoef=3Das.data.fram=
> e(rollcoef)=0Anames(dfrollcoef)[1]=3D"alpha"=0Anames(dfrollcoef)[2]=3D"mkt =
> beta"=0Anames(dfrollcoef)[3]=3D"smb"=0Anames(dfrollcoef)[4]=3D"hml"=0ARolli=
> ngCoefficients=3Dzoo(dfrollcoef, order.by=3Dindex(rollcoef))=0Awin.graph()=
> =0Aplot(RollingCoefficients)=0Acompositecoef=3Dmerge(RollingCoefficients, R=
> ollingCoefficientsCAPM, zcombined[,7])=0Arollcapmcoe=3Dfunction(x){=0ACAPMC=
> OE=3Dx[6]*rm+rf=0A}=0Arollffcoe=3Dfunction(x){=0AFFCOE=3Dx[2]*rm+x[3]*smb+x=
> [4]*hml+rf=0A}=0Arollffbetacoe=3Dfunction(x){=0AFFCOE=3Dx[2]*rm +rf=0A}=0A=
> =0ArollffCOE=3Drollapply(compositecoef,1,rollffcoe,by.column=3DFALSE,align=
> =3D"right")=0ArollcapmCOE=3Drollapply(compositecoef,1,rollcapmcoe,by.column=
> =3DFALSE,align=3D"right")=0ArollffbetaCOE=3Drollapply(compositecoef,1,rollf=
> fbetacoe,by.column=3DFALSE,align=3D"right")=0Adfrollcoe=3Das.data.frame(mer=
> ge(rollffCOE,rollcapmCOE,rollffbetaCOE))=0Anames(dfrollcoe)[1]=3D"FFCOE"=0A=
> names(dfrollcoe)[2]=3D"CAPMCOE"=0Anames(dfrollcoe)[3]=3D"FF(beta)COE"=0ARol=
> lingCOE=3Dzoo(dfrollcoe,order.by=3Dindex(rollcapmCOE))=0Awin.graph()=0Aplot=
> (RollingCOE,plot.type=3D"multiple")=0Aif((AIC(simplereg))<(AIC(ffreg2))) "C=
> APM superior to FF" else "FF superior to CAPM";=0A}=0A=0A=0A=0A----- Origin=
> al Message ----=0AFrom: Brian G. Peterson <brian at braverock.com>=0ATo: r-sig=
> -finance at stat.math.ethz.ch=0ASent: Monday, November 13, 2006 1:56:05 PM=0AS=
> ubject: Re: [R-SIG-Finance] looking for functions that can test/estimate CA=
> PM, APT, Fama's factor model, etc.=0A=0A=0AOn Monday 13 November 2006 12:13=
> , Michael wrote:=0A> thanks a lot for your pointers! I've taken a look at t=
> he book and the R=0A> example website. That's super! Some of the examples t=
> here are very=0A> good.=0A>=0A> Yet I am still looking for Fama 3 factor mo=
> del and Ross' APT=0A> implementation. The concept is not hard per se, howev=
> er I am not sure=0A> how to classify some companies as H, and some companie=
> s as L and others=0A> as Value companies, and the others as Growth companie=
> s. There are a lot=0A> of implementation details that I am not sure of. Thu=
> s I guess learning=0A> from other people's implementation is a better appro=
> ach for me as a=0A> green-hand.=0A=0A=0AHere's a great thread from this lis=
> t last year about the Fama three-factor =0Amodel:=0Ahttp://blog.gmane.org/g=
> mane.comp.lang.r.r-metrics/month=3D20050901=0A=0AThere is a ton of function=
> ality in R for factor modeling, spread through =0Alots of different package=
> s.  I'd suggest that you do some searching on =0APrimary Factor Analysis or=
> Primary Component Analysis.=0A=0AThe best bet is to use the Value/Growth c=
> ategorizations done by an =0Aexternal body, such as Reuters, Bloomberg, or =
> S&P.  There doesn't seem to =0Abe much reason for you to independently cate=
> gorize companies, especially =0Ain your learning stages.=0A=0AFor Arbitrage=
> Pricing Theory, you've got to decide on a pricing model.  =0AThere are man=
> y implementations of many pricing models in R.=0A=0A> (The Rmetrics are not=
> very complete I guess.)=0A=0ARMetrics is very complete for what it does, w=
> ith some notable exceptions =0A(fixed income instruments).  I've generally =
> had a lot of luck using =0Afunctions from RMetrics as building blocks for m=
> ore complex analysis.=0A=0ARegards,=0A=0A  - Brian=0A=0A___________________=
> ____________________________=0AR-SIG-Finance at stat.math.ethz.ch mailing list=
> =0Ahttps://stat.ethz.ch/mailman/listinfo/r-sig-finance=0A=0A=0A =0A________=
> ___________________________________________________________________________=
>
>
> --0-1294175594-1163450154=:83460
> Content-Type: text/plain; name="=?utf-8?q?getrffBeta.txt?="
> Content-Transfer-Encoding: base64
> Content-Disposition: attachment; filename="=?utf-8?q?getrffBeta.txt?="
>
> Z2V0cmZmQmV0YT0gZnVuY3Rpb24odG9vbCxzcGFuKSB7DQpyZXF1aXJlKE1B
> U1MpOw0KcmVxdWlyZSh0c2VyaWVzKTsNCnJlcXVpcmUod2xlKQ0KcmVxdWly
> ZSh6b28pDQpzdG9jaz0gKGdldC5oaXN0LnF1b3RlKGluc3RydW1lbnQgPSB0
> b29sLCBxdW90ZSA9YygiQWQiKSxjb21wcmVzc2lvbj0ibSIsb3JpZ2luPSBh
> cy5EYXRlKDApKSk7DQpzcHg9KGdldC5oaXN0LnF1b3RlKGluc3RydW1lbnQg
> PSAiXmdzcGMiLCBxdW90ZSA9YygiQWQiKSxjb21wcmVzc2lvbj0ibSIsb3Jp
> Z2luPSBhcy5EYXRlKDApKSk7DQp0b2RheT1TeXMuRGF0ZSgpOw0Kc2VxbW89
> bGVuZ3RoKHNlcShhcy5EYXRlKCIxOTI2LTA3LTAxIiksdG9kYXksYnk9Im1v
> bnRoIikpLTI7DQp1cmw9Imh0dHA6Ly9tYmEudHVjay5kYXJ0bW91dGguZWR1
> L3BhZ2VzL2ZhY3VsdHkva2VuLmZyZW5jaC9mdHAvRi1GX1Jlc2VhcmNoX0Rh
> dGFfRmFjdG9ycy56aXAiOw0KZGVzdGZpbGU9dGVtcGZpbGUoKTsNCmRhdGFm
> Zj1kb3dubG9hZC5maWxlKHVybCwgZGVzdGZpbGUsIG1vZGU9J3diJyk7DQp1
> bnppcD11bnooZGVzdGZpbGUsIkYtRl9SZXNlYXJjaF9EYXRhX0ZhY3RvcnMu
> dHh0Iik7DQpmZjQgPC0gcmVhZC50YWJsZSh1bnppcCwgaGVhZGVyPUZBTFNF
> LCBzZXA9IiIsbmEuc3RyaW5ncz0iTkEiLCBkZWM9Ii4iLCBzdHJpcC53aGl0
> ZT1UUlVFLCBza2lwPTQsbnJvd3M9c2VxbW8pDQpmZmRhdGEgPC0gZmY0DQph
> dHRhY2goZmZkYXRhKTsNCmZmZGF0YT1mZmRhdGEvMTAwDQojZmluZCBvdXQg
> c3RhcnRpbmcgeWVhciBtb250aCBmb3IgZmZkYXRhOw0KZmZkYXRhdHM9dHMo
> ZmZkYXRhLCBzdGFydD1jKDE5MjYsNyksIGZyZXF1ZW5jeT0xMik7DQpzdG9j
> az10cyhuYS5vbWl0KGNvcmVkYXRhKHN0b2NrKSksIHN0YXJ0PSBhcy5udW1l
> cmljKGFzLnllYXJtb24oYXMuRGF0ZShzdGFydChzdG9jaylbMV0pKSksDQpm
> cmVxdWVuY3k9MTIpOw0Kc3B4PXRzKG5hLnJlbW92ZShzcHgpLCBzdGFydD0N
> CmFzLm51bWVyaWMoYXMueWVhcm1vbihhcy5EYXRlKHN0YXJ0KHNweClbMV0p
> KSksDQpmcmVxdWVuY3k9MTIpOw0KY29tYmluZWQ9IG5hLnJlbW92ZSh0cy51
> bmlvbihzdG9jayxzcHgpKTsNCmNvbWJyZXR1cm49IG5hLnJlbW92ZShkaWZm
> KGxvZyhjb21iaW5lZCkpKTsNCmNvbWJpbmVkPW5hLnJlbW92ZSh0cy5pbnRl
> cnNlY3QoY29tYnJldHVybixmZmRhdGF0cyksIG5hbWVzPWxpc3QoInN0b2Nr
> cmV0IiwgInNweHJldCIsICJkYXRlcyIsImZmbWt0cmV0Iiwic21iIiwiaG1s
> IiwicmYiKSk7DQpjb21iaW5lZFssMV09Y29tYmluZWRbLDFdLWNvbWJpbmVk
> Wyw3XQ0KY29tYmluZWRbLDJdPWNvbWJpbmVkWywyXS1jb21iaW5lZFssN10N
> CnNpbXBsZXJlZz1sbShjb21iaW5lZFssMV1+Y29tYmluZWRbLDRdKTsNCnN0
> b2NrYmV0YT1zaW1wbGVyZWckY29lZlsyXTsNCnRleHRvdXQ9cGFzdGUoIkNB
> UE0gYmV0YT0iLCBzdG9ja2JldGEpOw0Kcm9idXN0cmVnPXdsZS5sbShjb21i
> aW5lZFssMV1+Y29tYmluZWRbLDRdKTsNCnJvYnN0b2NrYmV0YT1yb2J1c3Ry
> ZWckY29lZlsyXTsNCnRleHRvdXQyPXBhc3RlKCJyb2J1c3Qgc3RvY2sgYmV0
> YT0iLCByb2JzdG9ja2JldGEpOw0KcGxvdChhcy5udW1lcmljKGNvbWJpbmVk
> WywxXSl+YXMubnVtZXJpYyhjb21iaW5lZFssMl0pLHhsYWI9Ik1hcmtldCIs
> DQp5bGFiPXRvb2wpDQp0aXRsZShtYWluPXRleHRvdXQsIHN1Yj1saXN0KHRl
> eHRvdXQyLCBjb2w9InJlZCIpKQ0KYWJsaW5lKGNvZWYoc2ltcGxlcmVnKSk7
> DQphYmxpbmUoY29lZihyb2J1c3RyZWcpLGNvbD0icmVkIikNCnByaW50KHRl
> eHRvdXQpOw0KcHJpbnQodGV4dG91dDIpOw0KZmZyZWc9d2xlLmxtKGNvbWJp
> bmVkWywxXX5jb21iaW5lZFssNF0rY29tYmluZWRbLDVdK2NvbWJpbmVkWyw2
> XSk7DQpmZmFscGhhPWZmcmVnJGNvZWZbMV0NCmZmYmV0YT1mZnJlZyRjb2Vm
> WzJdOw0KZmZzbWI9ZmZyZWckY29lZlszXTsNCmZmaG1sPWZmcmVnJGNvZWZb
> NF0gOw0KdGV4dG91dDNhPSBwYXN0ZSgncm9idXN0IGZmIGFscGhhPScsZmZh
> bHBoYSkgOw0KdGV4dG91dDM9cGFzdGUoJ3JvYnVzdCBmZiBiZXRhPScsZmZi
> ZXRhKSA7DQp0ZXh0b3V0ND1wYXN0ZSgncm9idXN0IGZmIHNtYj0nLGZmc21i
> KSA7DQp0ZXh0b3V0NT1wYXN0ZSgncm9idXN0IGZmIGhtbD0nLGZmaG1sKSA7
> DQpwcmludCh0ZXh0b3V0M2EpDQpwcmludCh0ZXh0b3V0MykgOw0KcHJpbnQo
> dGV4dG91dDQpIDsNCnByaW50KHRleHRvdXQ1KSA7DQpyZj01DQpzbWI9MQ0K
> aG1sPTINCnJtPTUNCmZmY29lPXJmK2ZmYmV0YSpybStmZnNtYipzbWIrZmZo
> bWwqaG1sDQpyb2Jjb2U9cmYrcm9ic3RvY2tiZXRhKnJtDQpyZWdjb2U9cmYr
> c3RvY2tiZXRhKnJtDQp0ZXh0b3V0Nj1wYXN0ZSgncmVndWxhciBjb2U9Jyxy
> ZWdjb2UsJyByb2J1c3Rjb2U9JywNCnJvYmNvZSkNCnRleHRvdXQ3PXBhc3Rl
> KCdGYW1hLUZyZW5jaCBjb2U9JyxmZmNvZSkNCnByaW50KHRleHRvdXQ2KQ0K
> cHJpbnQodGV4dG91dDcpIDsNCmZmcmVnMj1sbShjb21iaW5lZFssMV1+Y29t
> YmluZWRbLDRdK2NvbWJpbmVkWyw1XStjb21iaW5lZFssNl0pOw0KYTE9YXMu
> dmVjdG9yKGNvbWJpbmVkWywxXSkNCmIxPWFzLnZlY3RvcihmZnJlZzIkZml0
> dGVkKQ0KYzE9YXMudmVjdG9yKHNpbXBsZXJlZyRmaXR0ZWQpDQpwbG90Mz0g
> KGRhdGEuZnJhbWUoYTEsYjEsYzEpKQ0Kd2luLmdyYXBoKCkNCnBhbmVsLmNv
> ciA8LSBmdW5jdGlvbih4LCB5LCBkaWdpdHM9MiwgcHJlZml4PSIiLCBjZXgu
> Y29yKQ0Kew0KdXNyIDwtIHBhcigidXNyIik7IG9uLmV4aXQocGFyKHVzcikp
> DQpwYXIodXNyID0gYygwLCAxLCAwLCAxKSkNCnIgPC0gYWJzKGNvcih4LCB5
> KSkNCnR4dCA8LSBmb3JtYXQoYyhyLCAwLjEyMzQ1Njc4OSksIGRpZ2l0cz1k
> aWdpdHMpWzFdDQp0eHQgPC0gcGFzdGUocHJlZml4LCB0eHQsIHNlcD0iIikN
> CmlmKG1pc3NpbmcoY2V4LmNvcikpIGNleCA8LSAwLjgvc3Ryd2lkdGgodHh0
> KQ0KdGV4dCgwLjUsIDAuNSwgdHh0LCBjZXggPSBjZXggKiByKQ0KfQ0KcGFp
> cnMocGxvdDMsIHVwcGVyLnBhbmVsPXBhbmVsLmNvcixsYWJlbHM9Yygic3Rv
> Y2sgcmV0dXJucyIsIkZGIGZpdHMiLCJDQVBNIGZpdHMiKSkNCmZmcmVnMj1s
> bShjb21iaW5lZFssMV1+Y29tYmluZWRbLDRdK2NvbWJpbmVkWyw1XStjb21i
> aW5lZFssNl0pOw0KemNvbWJpbmVkPXpvbyhjb21iaW5lZCk7DQoNCg0Kem9v
> Y29lZmNhcG1iZXRhPWZ1bmN0aW9uKHgpIHsNCnpvby53bGU9d2xlLmxtKHhb
> LDFdfnhbLDRdKTsNCmNvZWYgKHpvby53bGUpDQp9DQoNCnJvbGxjb2VmY2Fw
> bT1yb2xsYXBwbHkoemNvbWJpbmVkLHNwYW4sem9vY29lZmNhcG1iZXRhLGJ5
> LmNvbHVtbj1GQUxTRSxhbGlnbj0icmlnaHQiKTsNCmRmcm9sbGNvZWZjYXBt
> PWFzLmRhdGEuZnJhbWUocm9sbGNvZWZjYXBtKQ0KbmFtZXMoZGZyb2xsY29l
> ZmNhcG0pWzFdPSJhbHBoYSINCm5hbWVzKGRmcm9sbGNvZWZjYXBtKVsyXT0i
> bWt0IGJldGEiDQpSb2xsaW5nQ29lZmZpY2llbnRzQ0FQTT16b28oZGZyb2xs
> Y29lZmNhcG0sIG9yZGVyLmJ5PWluZGV4KHJvbGxjb2VmY2FwbSkpDQp3aW4u
> Z3JhcGgoKQ0KcGxvdChSb2xsaW5nQ29lZmZpY2llbnRzQ0FQTSkNCg0Kem9v
> Y29lZnNhPWZ1bmN0aW9uKHgpIHsNCnpvby53bGU9d2xlLmxtKHhbLDFdfnhb
> LDRdKyB4Wyw1XSsgeFssNl0pOw0KY29lZiAoem9vLndsZSkNCn0NCg0Kcm9s
> bGNvZWY9cm9sbGFwcGx5KHpjb21iaW5lZCxzcGFuLHpvb2NvZWZzYSxieS5j
> b2x1bW49RkFMU0UsYWxpZ249InJpZ2h0Iik7DQpkZnJvbGxjb2VmPWFzLmRh
> dGEuZnJhbWUocm9sbGNvZWYpDQpuYW1lcyhkZnJvbGxjb2VmKVsxXT0iYWxw
> aGEiDQpuYW1lcyhkZnJvbGxjb2VmKVsyXT0ibWt0IGJldGEiDQpuYW1lcyhk
> ZnJvbGxjb2VmKVszXT0ic21iIg0KbmFtZXMoZGZyb2xsY29lZilbNF09Imht
> bCINClJvbGxpbmdDb2VmZmljaWVudHM9em9vKGRmcm9sbGNvZWYsIG9yZGVy
> LmJ5PWluZGV4KHJvbGxjb2VmKSkNCndpbi5ncmFwaCgpDQpwbG90KFJvbGxp
> bmdDb2VmZmljaWVudHMpDQoNCmNvbXBvc2l0ZWNvZWY9bWVyZ2UoUm9sbGlu
> Z0NvZWZmaWNpZW50cywgUm9sbGluZ0NvZWZmaWNpZW50c0NBUE0sIHpjb21i
> aW5lZFssN10pDQpyb2xsY2FwbWNvZT1mdW5jdGlvbih4KXsNCkNBUE1DT0U9
> eFs2XSpybStyZg0KfQ0Kcm9sbGZmY29lPWZ1bmN0aW9uKHgpew0KRkZDT0U9
> eFsyXSpybSt4WzNdKnNtYit4WzRdKmhtbCtyZg0KfQ0Kcm9sbGZmYmV0YWNv
> ZT1mdW5jdGlvbih4KXsNCkZGQ09FPXhbMl0qcm0gK3JmDQp9DQoNCg0Kcm9s
> bGZmQ09FPXJvbGxhcHBseShjb21wb3NpdGVjb2VmLDEscm9sbGZmY29lLGJ5
> LmNvbHVtbj1GQUxTRSxhbGlnbj0icmlnaHQiKQ0Kcm9sbGNhcG1DT0U9cm9s
> bGFwcGx5KGNvbXBvc2l0ZWNvZWYsMSxyb2xsY2FwbWNvZSxieS5jb2x1bW49
> RkFMU0UsYWxpZ249InJpZ2h0IikNCnJvbGxmZmJldGFDT0U9cm9sbGFwcGx5
> KGNvbXBvc2l0ZWNvZWYsMSxyb2xsZmZiZXRhY29lLGJ5LmNvbHVtbj1GQUxT
> RSxhbGlnbj0icmlnaHQiKQ0KZGZyb2xsY29lPWFzLmRhdGEuZnJhbWUobWVy
> Z2Uocm9sbGZmQ09FLHJvbGxjYXBtQ09FLHJvbGxmZmJldGFDT0UpKQ0KbmFt
> ZXMoZGZyb2xsY29lKVsxXT0iRkZDT0UiDQpuYW1lcyhkZnJvbGxjb2UpWzJd
> PSJDQVBNQ09FIg0KbmFtZXMoZGZyb2xsY29lKVszXT0iRkYoYmV0YSlDT0Ui
> DQoNClJvbGxpbmdDT0U9em9vKGRmcm9sbGNvZSxvcmRlci5ieT1pbmRleChy
> b2xsY2FwbUNPRSkpDQp3aW4uZ3JhcGgoKQ0KcGxvdChSb2xsaW5nQ09FLHBs
> b3QudHlwZT0ibXVsdGlwbGUiKQ0KaWYoKEFJQyhzaW1wbGVyZWcpKTwoQUlD
> KGZmcmVnMikpKSAiQ0FQTSBzdXBlcmlvciB0byBGRiIgZWxzZSAiRkYgc3Vw
> ZXJpb3IgdG8gQ0FQTSI7DQp9DQoNCg0KVXNlIGJ5IHR5cGluZyBzb21ldGhp
> bmcgbGlrZSANCmdldHJmZkJldGEok0JOSZQsc3Bhbj02MCkNCg==
>
> --0-1294175594-1163450154=:83460
> Content-Type: text/plain; charset="us-ascii"
> MIME-Version: 1.0
> Content-Transfer-Encoding: 7bit
> Content-Disposition: inline
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>
> --0-1294175594-1163450154=:83460--
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>
>
>
> ____________________________________________________________________________________
>
> Access over 1 million songs.
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From jacinthe at gmx.de  Fri Nov 10 18:06:50 2006
From: jacinthe at gmx.de (jacinthe at gmx.de)
Date: Fri, 10 Nov 2006 18:06:50 +0100
Subject: [R-SIG-Finance] tsPlot and timeSeries
Message-ID: <20061110170650.258070@gmx.net>

Hi,

where do I find the functions "tsPlot" and "timeSeries". I have searched in all RMetrics packages, but didn?t find them any more. Are they detached?

Regards,

Jaci
--


From brian at braverock.com  Tue Nov 14 15:34:17 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 14 Nov 2006 08:34:17 -0600
Subject: [R-SIG-Finance] tsPlot and timeSeries
In-Reply-To: <20061110170650.258070@gmx.net>
References: <20061110170650.258070@gmx.net>
Message-ID: <200611140834.17717.brian@braverock.com>

On Friday 10 November 2006 11:06, jacinthe at gmx.de wrote:
> Hi,
>
> where do I find the functions "tsPlot" and "timeSeries". I have
> searched in all RMetrics packages, but didn?t find them any more. Are
> they detached?
>
> Regards,

ts.plot(stats)          Plot Multiple Time Series

TimeSeries is a data class, implemented by the main R package, extended by 
fBasics and many other R packages (zoo, irts, several others)

try 
> help.search("timeseries")

Regards,

  - Brian


From ggrothendieck at gmail.com  Tue Nov 14 15:41:18 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 14 Nov 2006 09:41:18 -0500
Subject: [R-SIG-Finance] tsPlot and timeSeries
In-Reply-To: <20061110170650.258070@gmx.net>
References: <20061110170650.258070@gmx.net>
Message-ID: <971536df0611140641s148358ebi8ada84237c756c4e@mail.gmail.com>

I think tsPlot is now plot.timeSeries and both that and timeSeries
are in fCalendar.


On 11/10/06, jacinthe at gmx.de <jacinthe at gmx.de> wrote:
> Hi,
>
> where do I find the functions "tsPlot" and "timeSeries". I have searched in all RMetrics packages, but didn?t find them any more. Are they detached?
>
> Regards,
>
> Jaci
> --
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From comtech.usa at gmail.com  Wed Nov 15 03:11:54 2006
From: comtech.usa at gmail.com (Michael)
Date: Tue, 14 Nov 2006 18:11:54 -0800
Subject: [R-SIG-Finance] where to obtain T-bill 3 month rate?
Message-ID: <b1f16d9d0611141811r1f378b42n80746883368b2e10@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061114/f04b4a27/attachment.pl 

From ezivot at u.washington.edu  Wed Nov 15 04:27:51 2006
From: ezivot at u.washington.edu (Eric Zivot)
Date: Tue, 14 Nov 2006 19:27:51 -0800
Subject: [R-SIG-Finance] where to obtain T-bill 3 month rate?
In-Reply-To: <b1f16d9d0611141811r1f378b42n80746883368b2e10@mail.gmail.com>
Message-ID: <000901c70866$0883f2e0$6401a8c0@zivotd800>

2 good sources of info are

1. FRED database at the Federal Reserve bank of Kansas City. 
2. www.economagic.com. They have a nice collection of free financial and
economic data.

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Michael
Sent: Tuesday, November 14, 2006 6:12 PM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] where to obtain T-bill 3 month rate?

Hi all,

In playing with the empirical finance models, we need the risk-free rate. I
am thinking of T-bill 3 month rate.

I've looked at a few webpages, e.g.

http://mortgage-x.com/general/indexes/t-bill_index_faq.asp

But they look complicated... is there a popular place that I can simply
download the T-bill 3 month historical data?

Is there a program in R that can automatically/streamingly pull stock and
T-bill rate data from popular website?

Thanks a lot!

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance


From edd at debian.org  Wed Nov 15 05:10:23 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 14 Nov 2006 22:10:23 -0600
Subject: [R-SIG-Finance] where to obtain T-bill 3 month rate?
In-Reply-To: <000901c70866$0883f2e0$6401a8c0@zivotd800>
References: <b1f16d9d0611141811r1f378b42n80746883368b2e10@mail.gmail.com>
	<000901c70866$0883f2e0$6401a8c0@zivotd800>
Message-ID: <17754.37679.104643.749177@basebud.nulle.part>


On 14 November 2006 at 19:27, Eric Zivot wrote:
| 2 good sources of info are
| 
| 1. FRED database at the Federal Reserve bank of Kansas City. 
| 2. www.economagic.com. They have a nice collection of free financial and
| economic data.

And IIRC Rmetrics has a function to access both:

TimeSeriesImport          package:fCalendar          R Documentation

Import Market Data from the Internet

Description:

     A collection and description of functions to import  financial and
     economic market data from the Internet. Download functions are
     available for economic and financial market data from
     Economagic's, from  Yahoo's, from the Federal Reserve's, and from
     the the forecasts.org Internet sites. 

     The functions are:

       'economagicImport'  Economic series from Economagic's Web site,
       'yahooImport'       daily stock market data from Yahoo's Web site,
       'yahooSeries'       easy to use download from Yahoo,
       'keystatsImport'    key statistics from Yahoo's Web site,
       'fredImport'        time series from St. Louis FRED Web site,
       'forecastsImport'   monthly data from the Financial Forecast Center.


Hth, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From finbref.2006 at gmail.com  Wed Nov 15 11:11:48 2006
From: finbref.2006 at gmail.com (Thomas Steiner)
Date: Wed, 15 Nov 2006 11:11:48 +0100
Subject: [R-SIG-Finance] where to obtain T-bill 3 month rate?
In-Reply-To: <b1f16d9d0611141811r1f378b42n80746883368b2e10@mail.gmail.com>
References: <b1f16d9d0611141811r1f378b42n80746883368b2e10@mail.gmail.com>
Message-ID: <d0f55a670611150211p67e0d25g2b96198d92580a73@mail.gmail.com>

Michael,

> Is there a program in R that can automatically/streamingly pull stock and
> T-bill rate data from popular website?

I use the US-fed site to get US-data from there:

library(zoo)

usfedyields<-function(mat) {
  ##from: http://www.federalreserve.gov/releases/h15/data.htm
  url<-paste("http://www.federalreserve.gov/releases/h15/data/Business_day/H15_TCMNOM_",mat,".txt",sep="")
  raw<-read.csv(file=url,skip=7,colClasses=c("character","character"))
  date<-as.Date(raw[,1],format="%m/%d/%Y")
  yield<-as.numeric(raw[,2])
  return(zoo(yield,date))
}

y3 <-usfedyields("M3")

A more theoretical question:
Do you use the 3-month rate as the short rate? I don't know what model
you use, but if you use vasicek, CIR, some parametric model (Svensson,
...) the 3 month rate will differ from the short rate by a well
defined quantity. How do you deal with this? What do others use as
short rate?
Just tell me more! I am curious on literature as well; I just now
http://ideas.repec.org/p/wpa/wuwpfi/9808004.html

Best,
Thomas


From me4kata2003 at yahoo.co.uk  Wed Nov 15 12:11:27 2006
From: me4kata2003 at yahoo.co.uk (Valentin Popov)
Date: Wed, 15 Nov 2006 11:11:27 +0000 (GMT)
Subject: [R-SIG-Finance] Zeros of a hairy function
Message-ID: <20061115111128.85539.qmail@web27802.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061115/0d59f5a4/attachment.pl 

From ggrothendieck at gmail.com  Wed Nov 15 13:30:22 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 15 Nov 2006 07:30:22 -0500
Subject: [R-SIG-Finance] where to obtain T-bill 3 month rate?
In-Reply-To: <d0f55a670611150211p67e0d25g2b96198d92580a73@mail.gmail.com>
References: <b1f16d9d0611141811r1f378b42n80746883368b2e10@mail.gmail.com>
	<d0f55a670611150211p67e0d25g2b96198d92580a73@mail.gmail.com>
Message-ID: <971536df0611150430y5cc481a8r63c054bcc8ba1291@mail.gmail.com>

You could also use read.zoo.   With the same url as in the function below:

   read.zoo(url, skip = 7, header = TRUE, sep = ",", format = "%m/%d/%Y")


On 11/15/06, Thomas Steiner <finbref.2006 at gmail.com> wrote:
> Michael,
>
> > Is there a program in R that can automatically/streamingly pull stock and
> > T-bill rate data from popular website?
>
> I use the US-fed site to get US-data from there:
>
> library(zoo)
>
> usfedyields<-function(mat) {
>  ##from: http://www.federalreserve.gov/releases/h15/data.htm
>  url<-paste("http://www.federalreserve.gov/releases/h15/data/Business_day/H15_TCMNOM_",mat,".txt",sep="")
>  raw<-read.csv(file=url,skip=7,colClasses=c("character","character"))
>  date<-as.Date(raw[,1],format="%m/%d/%Y")
>  yield<-as.numeric(raw[,2])
>  return(zoo(yield,date))
> }
>
> y3 <-usfedyields("M3")
>
> A more theoretical question:
> Do you use the 3-month rate as the short rate? I don't know what model
> you use, but if you use vasicek, CIR, some parametric model (Svensson,
> ...) the 3 month rate will differ from the short rate by a well
> defined quantity. How do you deal with this? What do others use as
> short rate?
> Just tell me more! I am curious on literature as well; I just now
> http://ideas.repec.org/p/wpa/wuwpfi/9808004.html
>
> Best,
> Thomas
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From david.ardia at unifr.ch  Wed Nov 15 13:34:55 2006
From: david.ardia at unifr.ch (ARDIA David)
Date: Wed, 15 Nov 2006 13:34:55 +0100
Subject: [R-SIG-Finance] Zeros of a hairy function
Message-ID: <2AA9A291D7760C40B00A75A149DB5D37043D65@EXCHANGE4.unifr.ch>

If your function is f(x), then you could apply optim to g(x) := f(x)^2. 

You can also consider the DEoptim package to perform robust optimization
based on a genetic algorithm.

Hope it helps,

David

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Valentin
Popov
Sent: mercredi, 15. novembre 2006 12:11
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] Zeros of a hairy function


Hi all,

In order to get an estimator for the correlation between two asstes I
need the zeros of a quite "hairy" nonlinear function. Could you give me
a tip which function in R could supply a solution? I thought of  'optim'
but it will only minimize the function but not get its zeros.

Thanks a lot!

Valentin



Send instant messages to your online friends
http://uk.messenger.yahoo.com 
	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance


From kevinramoutar at yahoo.co.uk  Fri Nov 17 12:49:31 2006
From: kevinramoutar at yahoo.co.uk (Kevin Ramoutar)
Date: Fri, 17 Nov 2006 11:49:31 +0000 (GMT)
Subject: [R-SIG-Finance] R-SIG-Finance Digest - Yield Curve Modeling
Message-ID: <20061117114931.67352.qmail@web25513.mail.ukl.yahoo.com>

Hello All,
 
Advance apologies for this not being specifically an R technical question.
 
I am attempting to construct the yield curve in a market characterised by the following:
 
1. There isn't an organised market for bond secondary market bond trading most corporate of issues are privately placed but the bond information is available via the local SEC;
2. Bond issues (govt) are few and far between lets say about 2-3 each quarter.
3. Most bonds issues are not rated by any agency so the extraction of the credit spread is made even more difficult.
 
The short end of the curve is no problem as there are Government issues that can cover up to the 1 year maturity.
 
Does anyone know of a case study or other literature that can provide guidance? Your help would be greatly appreciated.

Regards
Kevin

Send instant messages to your online friends http://uk.messenger.yahoo.com


From kriskumar at earthlink.net  Fri Nov 17 13:20:17 2006
From: kriskumar at earthlink.net (Krishna Kumar)
Date: Fri, 17 Nov 2006 07:20:17 -0500
Subject: [R-SIG-Finance] use log return or quotient return?
In-Reply-To: <971536df0611131059q3d6fce8cj746b95104f08dceb@mail.gmail.com>
References: <b1f16d9d0611131035u689278d0oc0c7301175870607@mail.gmail.com>
	<971536df0611131059q3d6fce8cj746b95104f08dceb@mail.gmail.com>
Message-ID: <455DA901.8060605@earthlink.net>

There are atleast three ways to compute returns take first differences , 
take first differences and scale, take first differences of the log returns
One of the nice aspect of  first differences of log is that they include 
scaling and all the three are approximately the same(as Gabor points 
out) at high-freq over a short period of time. But if you had a lower 
freq data over a much longer period of time then it is useful to 
investigate the statistical properties of the returns before going one 
way or the other.

Best,
Krishna


Gabor Grothendieck wrote:
> It depends on how good the approximation log(1+r) = r is and that
> depends on whether r is sufficiently small or not.
>
> On 11/13/06, Michael <comtech.usa at gmail.com> wrote:
>   
>> Hi all,
>>
>> Does anybody know which is more commonly used in financial time series --
>> log return or quotient return?
>>
>> Thanks a lot,
>>     
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>
>


From frainj at tcd.ie  Fri Nov 17 14:32:15 2006
From: frainj at tcd.ie (John C. Frain)
Date: Fri, 17 Nov 2006 13:32:15 +0000
Subject: [R-SIG-Finance] use log return or quotient return?
In-Reply-To: <455DA901.8060605@earthlink.net>
References: <b1f16d9d0611131035u689278d0oc0c7301175870607@mail.gmail.com>
	<971536df0611131059q3d6fce8cj746b95104f08dceb@mail.gmail.com>
	<455DA901.8060605@earthlink.net>
Message-ID: <1163770335.455db9df3836c@mymail.tcd.ie>

Many markets use quotient returns or discounts.  Returns expressed in this way
are not consistent between markets.  Also aggregating over time is only
approximate.  For this reason empirical work would be better served if the
institutional rates were converted to log difference returns before analysis.

Even for macroeconometric analysis of various growth rates log differences are
more aligned with theory and are likely to give better results.  I would
recommend that, regardless of market practices, all serious empirical work on
returns be done in terms of log differences



John C. Frain.
Economics Department
Trinity College Dublin
Dublin 2

www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie


Quoting Krishna Kumar <kriskumar at earthlink.net>:

> There are atleast three ways to compute returns take first differences ,
> take first differences and scale, take first differences of the log returns
> One of the nice aspect of  first differences of log is that they include
> scaling and all the three are approximately the same(as Gabor points
> out) at high-freq over a short period of time. But if you had a lower
> freq data over a much longer period of time then it is useful to
> investigate the statistical properties of the returns before going one
> way or the other.
>
> Best,
> Krishna
>
>
> Gabor Grothendieck wrote:
> > It depends on how good the approximation log(1+r) = r is and that
> > depends on whether r is sufficiently small or not.
> >
> > On 11/13/06, Michael <comtech.usa at gmail.com> wrote:
> >
> >> Hi all,
> >>
> >> Does anybody know which is more commonly used in financial time series --
> >> log return or quotient return?
> >>
> >> Thanks a lot,
> >>
> >
> > _______________________________________________
> > R-SIG-Finance at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >
> >
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From rsheftel at gmail.com  Fri Nov 17 18:56:41 2006
From: rsheftel at gmail.com (Ryan Sheftel)
Date: Fri, 17 Nov 2006 11:56:41 -0600
Subject: [R-SIG-Finance] R-SIG-Finance Digest - Yield Curve Modeling
In-Reply-To: <20061117114931.67352.qmail@web25513.mail.ukl.yahoo.com>
Message-ID: <002201c70a71$bcf00fe0$6a01a8c0@LAPTOP>

I have never replied to a message on this group before, so apologies in
advance if I am not doing it the right way.

To construct a yield curve the best choice is to use a combination of the
LIBOR market for short rates, and the Swap markets for all maturities beyond
1 year. The LIBOR and swap market are derivative markets that are completely
free from the nuances and technicalities of a specific bond market (either
government or corporate). The standard practice is to use the LIBOR/Swap
markets to construct a yield (discount) curve. Then any other bond is quoted
and discounted at a spread to that curve.

The LIBOR and Swap market yield are available from a daily poll by the BBA
(British Bankers Association), and is available on their web site, via
Bloomberg, and the US Fed also re-publishes. The great part of the
LIBOR/Swap markets is that they publish rates for almost every maturity, so
there are no gaps in the yield curve. The Fed only publishes a sub-set, but
it should be enough to get you going.

BBA LIBOR http://www.bba.org.uk/bba/jsp/polopoly.jsp?d=141&a=627
 
Federal Reserve H15 release
http://www.federalreserve.gov/releases/h15/update/

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Kevin Ramoutar
Sent: Friday, November 17, 2006 5:50 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] R-SIG-Finance Digest - Yield Curve Modeling

Hello All,
 
Advance apologies for this not being specifically an R technical question.
 
I am attempting to construct the yield curve in a market characterised by
the following:
 
1. There isn't an organised market for bond secondary market bond trading
most corporate of issues are privately placed but the bond information is
available via the local SEC; 2. Bond issues (govt) are few and far between
lets say about 2-3 each quarter.
3. Most bonds issues are not rated by any agency so the extraction of the
credit spread is made even more difficult.
 
The short end of the curve is no problem as there are Government issues that
can cover up to the 1 year maturity.
 
Does anyone know of a case study or other literature that can provide
guidance? Your help would be greatly appreciated.

Regards
Kevin

Send instant messages to your online friends http://uk.messenger.yahoo.com

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance

--
No virus found in this incoming message.


3:51 PM
 

-- 



3:51 PM


From fcitta at inwind.it  Sun Nov 19 15:10:18 2006
From: fcitta at inwind.it (Citta Francesco)
Date: Sun, 19 Nov 2006 15:10:18 +0100
Subject: [R-SIG-Finance] ARMA(m,n)-APARCH(p,q)
References: <mailman.17.1162292407.30427.r-sig-finance@stat.math.ethz.ch>
Message-ID: <000301c70be4$81c26c00$5a611997@y6c3m0>

Dear Listers,
I am working with cac40 time series data (from 03-01-2000 to 08-11-2006). I
estimated, with successful, a simple ARMA(6,0)-GARCH(1,1) but I think tha it
is better an ARMA(6,0)-TGARCH(1,1).
For this I used the garchFit() function , setting:

garchFit(formula.var=~arma(6,0),formula.var=~aparch(1,1),series=cac,delta=2,
cond.dist="dnorm",include.delta=FALSE)

I obtain a strange value of gamma1 (1) ,I think that it wrong, the expected
value would be near 0.12, and the ARCH sign is positive instead of negative.
How can solve this problem?
Are you able to say me where I mistaked?
Best regards.


From kriskumar at earthlink.net  Sun Nov 19 17:03:14 2006
From: kriskumar at earthlink.net (kriskumar at earthlink.net)
Date: Sun, 19 Nov 2006 16:03:14 +0000
Subject: [R-SIG-Finance] ARMA(m,n)-APARCH(p,q)
In-Reply-To: <000301c70be4$81c26c00$5a611997@y6c3m0>
References: <mailman.17.1162292407.30427.r-sig-finance@stat.math.ethz.ch>
	<000301c70be4$81c26c00$5a611997@y6c3m0>
Message-ID: <1548161647-1163952269-cardhu_blackberry.rim.net-888528073-@bwe044-cell00.bisx.prod.on.blackberry>

The estimation is by MLE and so completely depends on the optimizer you specify. 

I would take the loglikelihood function and try with a global optimizer like SA or diff evolution. The DE works with a population of solns and so you can get a distibution of the parameters and get a sense if there are multiple local minima.

HTH

Best
Krishna




Sent from my BlackBerry? wireless handheld  

-----Original Message-----
From: "Citta Francesco" <fcitta at inwind.it>
Date: Sun, 19 Nov 2006 15:10:18 
To:<r-sig-finance at stat.math.ethz.ch>
Subject: [R-SIG-Finance] ARMA(m,n)-APARCH(p,q)

Dear Listers,
I am working with cac40 time series data (from 03-01-2000 to 08-11-2006). I
estimated, with successful, a simple ARMA(6,0)-GARCH(1,1) but I think tha it
is better an ARMA(6,0)-TGARCH(1,1).
For this I used the garchFit() function , setting:

garchFit(formula.var=~arma(6,0),formula.var=~aparch(1,1),series=cac,delta=2,
cond.dist="dnorm",include.delta=FALSE)

I obtain a strange value of gamma1 (1) ,I think that it wrong, the expected
value would be near 0.12, and the ARCH sign is positive instead of negative.
How can solve this problem?
Are you able to say me where I mistaked?
Best regards.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance


From Xiaochen.Sun at brunel.ac.uk  Sun Nov 19 18:44:42 2006
From: Xiaochen.Sun at brunel.ac.uk (Xiaochen Sun)
Date: Sun, 19 Nov 2006 17:44:42 -0000
Subject: [R-SIG-Finance] 1.data sorting and matching/2.quantile function of
	empirical marginal distribution
Message-ID: <4053699F3E4AD04BA536A5F6BB81A2CF48F6A0@UXEXMBU116.academic.windsor>

Dear list, 

Can any R user leave some hints on the following problems:

We had a data frame with 4 coloums and 676 numbers(rows), now I want to sort Phi first; secondly, find our which F(v1) is equaly Phi(or at least quite close), then tick out that v value....

	u1	v1	F(v1)	Phi	
1		v1	3	2	
2		v2	4	3	
3		v3	2	8	
4		v4	5	4	
5		v5	8	5	
.		.	.		
.		.	.		
.		.	.		
.		.	.		
		.			
676					

Also, did anyone know some package or function on quantile function of empirical marginal distribution?

Thank you very much.

With regards
MC


From kevinramoutar at yahoo.co.uk  Mon Nov 20 14:12:19 2006
From: kevinramoutar at yahoo.co.uk (Kevin Ramoutar)
Date: Mon, 20 Nov 2006 13:12:19 +0000 (GMT)
Subject: [R-SIG-Finance] R-SIG-Finance Digest - Yield Curve Modeling
Message-ID: <20061120131219.44227.qmail@web25506.mail.ukl.yahoo.com>

Hello Ryan,

Thanks for the help. But there is one problem. We do not have a swap market or derivatives market here in Trinidad. What then do I do?

Kevin

----- Original Message ----
From: Ryan Sheftel <rsheftel at gmail.com>
To: Kevin Ramoutar <kevinramoutar at yahoo.co.uk>; r-sig-finance at stat.math.ethz.ch
Sent: Friday, 17 November, 2006 1:56:41 PM
Subject: RE: [R-SIG-Finance] R-SIG-Finance Digest - Yield Curve Modeling


I have never replied to a message on this group before, so apologies in
advance if I am not doing it the right way.

To construct a yield curve the best choice is to use a combination of the
LIBOR market for short rates, and the Swap markets for all maturities beyond
1 year. The LIBOR and swap market are derivative markets that are completely
free from the nuances and technicalities of a specific bond market (either
government or corporate). The standard practice is to use the LIBOR/Swap
markets to construct a yield (discount) curve. Then any other bond is quoted
and discounted at a spread to that curve.

The LIBOR and Swap market yield are available from a daily poll by the BBA
(British Bankers Association), and is available on their web site, via
Bloomberg, and the US Fed also re-publishes. The great part of the
LIBOR/Swap markets is that they publish rates for almost every maturity, so
there are no gaps in the yield curve. The Fed only publishes a sub-set, but
it should be enough to get you going.

BBA LIBOR http://www.bba.org.uk/bba/jsp/polopoly.jsp?d=141&a=627

Federal Reserve H15 release
http://www.federalreserve.gov/releases/h15/update/

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Kevin Ramoutar
Sent: Friday, November 17, 2006 5:50 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] R-SIG-Finance Digest - Yield Curve Modeling

Hello All,

Advance apologies for this not being specifically an R technical question.

I am attempting to construct the yield curve in a market characterised by
the following:

1. There isn't an organised market for bond secondary market bond trading
most corporate of issues are privately placed but the bond information is
available via the local SEC; 2. Bond issues (govt) are few and far between
lets say about 2-3 each quarter.
3. Most bonds issues are not rated by any agency so the extraction of the
credit spread is made even more difficult.

The short end of the curve is no problem as there are Government issues that
can cover up to the 1 year maturity.

Does anyone know of a case study or other literature that can provide
guidance? Your help would be greatly appreciated.

Regards
Kevin

Send instant messages to your online friends http://uk.messenger.yahoo.com

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance

--
No virus found in this incoming message.


3:51 PM


-- 



3:51 PM


From micha.keijzers at gmail.com  Mon Nov 20 14:37:10 2006
From: micha.keijzers at gmail.com (Micha Keijzers)
Date: Mon, 20 Nov 2006 14:37:10 +0100
Subject: [R-SIG-Finance] R-SIG-Finance Digest - Yield Curve Modeling
In-Reply-To: <20061120131219.44227.qmail@web25506.mail.ukl.yahoo.com>
References: <20061120131219.44227.qmail@web25506.mail.ukl.yahoo.com>
Message-ID: <13eac1860611200537t575569b7qd7cb0fa8158c3e99@mail.gmail.com>

2006/11/20, Kevin Ramoutar <kevinramoutar at yahoo.co.uk>:
> Hello Ryan,
>
> Thanks for the help. But there is one problem. We do not have a swap market
> or derivatives market here in Trinidad. What then do I do?
>
> Kevin

Hi Kevin,

[I don't know if it is correct in this group to not top-post. And
also, this topic is not R-specific anymore. But anyway, here (as well
as Ryan) goes also my first post to this list...]

What you might do is look for another swap market that closely
resembles a virtual swap rate in Trinidad. Do "Trinidad swap rates" in
some way follow neighbouring country's swap rates? Is there a global
swap rate that governs Trinidad's? Anyway, look for a rate that
determines Trinidad's market fundamentals *as if there was a swap
market* and use that rate. Not sure if you can do much better than
that.

Basically, the idea of the above is probably what was already
mentioned below by Ryan. It could be that a Trinidad swap rate would
be governed by LIBOR-rates. In that case, use LIBOR-rates.

And by the way, for the short end of the curve, as you mentioned that
this is not a problem, there is a way to combine the short end of the
curve with the longer end of some other curve. This would inherently
give a discontinuity at the pasting point, but there's a way to get
around this. If you simply have a grid of collected swap rates (from
two different closely resembling sources) one could use a spline-based
method (cubic spline) or a Nelson-Siegel curve fit to obtain the total
yield curve.

Hope this helps, and if others have better ideas...

Kind regards,
Micha Keijzers

>
> ----- Original Message ----
> From: Ryan Sheftel <rsheftel at gmail.com>
> To: Kevin Ramoutar <kevinramoutar at yahoo.co.uk>;
> r-sig-finance at stat.math.ethz.ch
> Sent: Friday, 17 November, 2006 1:56:41 PM
> Subject: RE: [R-SIG-Finance] R-SIG-Finance Digest - Yield Curve Modeling
>
>
> I have never replied to a message on this group before, so apologies in
> advance if I am not doing it the right way.
>
> To construct a yield curve the best choice is to use a combination of the
> LIBOR market for short rates, and the Swap markets for all maturities beyond
> 1 year. The LIBOR and swap market are derivative markets that are completely
> free from the nuances and technicalities of a specific bond market (either
> government or corporate). The standard practice is to use the LIBOR/Swap
> markets to construct a yield (discount) curve. Then any other bond is quoted
> and discounted at a spread to that curve.
>
> The LIBOR and Swap market yield are available from a daily poll by the BBA
> (British Bankers Association), and is available on their web site, via
> Bloomberg, and the US Fed also re-publishes. The great part of the
> LIBOR/Swap markets is that they publish rates for almost every maturity, so
> there are no gaps in the yield curve. The Fed only publishes a sub-set, but
> it should be enough to get you going.
>
> BBA LIBOR http://www.bba.org.uk/bba/jsp/polopoly.jsp?d=141&a=627
>
> Federal Reserve H15 release
> http://www.federalreserve.gov/releases/h15/update/
>
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Kevin Ramoutar
> Sent: Friday, November 17, 2006 5:50 AM
> To: r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] R-SIG-Finance Digest - Yield Curve Modeling
>
> Hello All,
>
> Advance apologies for this not being specifically an R technical question.
>
> I am attempting to construct the yield curve in a market characterised by
> the following:
>
> 1. There isn't an organised market for bond secondary market bond trading
> most corporate of issues are privately placed but the bond information is
> available via the local SEC; 2. Bond issues (govt) are few and far between
> lets say about 2-3 each quarter.
> 3. Most bonds issues are not rated by any agency so the extraction of the
> credit spread is made even more difficult.
>
> The short end of the curve is no problem as there are Government issues that
> can cover up to the 1 year maturity.
>
> Does anyone know of a case study or other literature that can provide
> guidance? Your help would be greatly appreciated.
>
> Regards
> Kevin
>
> Send instant messages to your online friends http://uk.messenger.yahoo.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>
> --
> No virus found in this incoming message.
>
>
> 3:51 PM
>
>
> --
>
>
>
> 3:51 PM
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From kevinramoutar at yahoo.co.uk  Mon Nov 20 15:37:37 2006
From: kevinramoutar at yahoo.co.uk (Kevin Ramoutar)
Date: Mon, 20 Nov 2006 14:37:37 +0000 (GMT)
Subject: [R-SIG-Finance] R-SIG-Finance Digest - Yield Curve Modeling
Message-ID: <20061120143737.96134.qmail@web25513.mail.ukl.yahoo.com>

Thanks Micha + Ryan for your assistance.

Kevin

----- Original Message ----
From: Micha Keijzers <micha.keijzers at gmail.com>
To: Kevin Ramoutar <kevinramoutar at yahoo.co.uk>
Cc: Ryan Sheftel <rsheftel at gmail.com>; r-sig-finance at stat.math.ethz.ch
Sent: Monday, 20 November, 2006 9:37:10 AM
Subject: Re: R-SIG-Finance Digest - Yield Curve Modeling


2006/11/20, Kevin Ramoutar <kevinramoutar at yahoo.co.uk>:
> Hello Ryan,
>
> Thanks for the help. But there is one problem. We do not have a swap market
> or derivatives market here in Trinidad. What then do I do?
>
> Kevin

Hi Kevin,

[I don't know if it is correct in this group to not top-post. And
also, this topic is not R-specific anymore. But anyway, here (as well
as Ryan) goes also my first post to this list...]

What you might do is look for another swap market that closely
resembles a virtual swap rate in Trinidad. Do "Trinidad swap rates" in
some way follow neighbouring country's swap rates? Is there a global
swap rate that governs Trinidad's? Anyway, look for a rate that
determines Trinidad's market fundamentals *as if there was a swap
market* and use that rate. Not sure if you can do much better than
that.

Basically, the idea of the above is probably what was already
mentioned below by Ryan. It could be that a Trinidad swap rate would
be governed by LIBOR-rates. In that case, use LIBOR-rates.

And by the way, for the short end of the curve, as you mentioned that
this is not a problem, there is a way to combine the short end of the
curve with the longer end of some other curve. This would inherently
give a discontinuity at the pasting point, but there's a way to get
around this. If you simply have a grid of collected swap rates (from
two different closely resembling sources) one could use a spline-based
method (cubic spline) or a Nelson-Siegel curve fit to obtain the total
yield curve.

Hope this helps, and if others have better ideas...

Kind regards,
Micha Keijzers

>
> ----- Original Message ----
> From: Ryan Sheftel <rsheftel at gmail.com>
> To: Kevin Ramoutar <kevinramoutar at yahoo.co.uk>;
> r-sig-finance at stat.math.ethz.ch
> Sent: Friday, 17 November, 2006 1:56:41 PM
> Subject: RE: [R-SIG-Finance] R-SIG-Finance Digest - Yield Curve Modeling
>
>
> I have never replied to a message on this group before, so apologies in
> advance if I am not doing it the right way.
>
> To construct a yield curve the best choice is to use a combination of the
> LIBOR market for short rates, and the Swap markets for all maturities beyond
> 1 year. The LIBOR and swap market are derivative markets that are completely
> free from the nuances and technicalities of a specific bond market (either
> government or corporate). The standard practice is to use the LIBOR/Swap
> markets to construct a yield (discount) curve. Then any other bond is quoted
> and discounted at a spread to that curve.
>
> The LIBOR and Swap market yield are available from a daily poll by the BBA
> (British Bankers Association), and is available on their web site, via
> Bloomberg, and the US Fed also re-publishes. The great part of the
> LIBOR/Swap markets is that they publish rates for almost every maturity, so
> there are no gaps in the yield curve. The Fed only publishes a sub-set, but
> it should be enough to get you going.
>
> BBA LIBOR http://www.bba.org.uk/bba/jsp/polopoly.jsp?d=141&a=627
>
> Federal Reserve H15 release
> http://www.federalreserve.gov/releases/h15/update/
>
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Kevin Ramoutar
> Sent: Friday, November 17, 2006 5:50 AM
> To: r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] R-SIG-Finance Digest - Yield Curve Modeling
>
> Hello All,
>
> Advance apologies for this not being specifically an R technical question.
>
> I am attempting to construct the yield curve in a market characterised by
> the following:
>
> 1. There isn't an organised market for bond secondary market bond trading
> most corporate of issues are privately placed but the bond information is
> available via the local SEC; 2. Bond issues (govt) are few and far between
> lets say about 2-3 each quarter.
> 3. Most bonds issues are not rated by any agency so the extraction of the
> credit spread is made even more difficult.
>
> The short end of the curve is no problem as there are Government issues that
> can cover up to the 1 year maturity.
>
> Does anyone know of a case study or other literature that can provide
> guidance? Your help would be greatly appreciated.
>
> Regards
> Kevin
>
> Send instant messages to your online friends http://uk.messenger.yahoo.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>
> --
> No virus found in this incoming message.
>
>
> 3:51 PM
>
>
> --
>
>
>
> 3:51 PM
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From dickgiesser at gmail.com  Tue Nov 21 12:34:22 2006
From: dickgiesser at gmail.com (Benjamin Dickgiesser)
Date: Tue, 21 Nov 2006 11:34:22 +0000
Subject: [R-SIG-Finance] Garch, beginner questions
In-Reply-To: <b75d67340611210113v7059eaa0h39ac03c019c70026@mail.gmail.com>
References: <b75d67340611210113v7059eaa0h39ac03c019c70026@mail.gmail.com>
Message-ID: <b75d67340611210334r5c134043i340a78246d72df9c@mail.gmail.com>

I now wrote this function, but am sure it can be done much better somehow..

library(fSeries)
library(tseries)

VaR.Garch <- function(data,stockId=1,p=0.01,dt=1)
{
	r <- diff(log(data))
	
	#fit Garch(1,1), Ar(2) modell
	fit = garchFit(~arma(2,0), ~garch(1,1), series = r)
	
	#init vars
	rhat[1:3] <- 0
	a[1:3] <- 0
	sigma[1:3] <- 0
	VaR[1:3] <- 0
	
	for (t in 3:length(r))
	{	
		#Calculate r suggested by AR	
		rhat[t] <- fit at fit$matcoef[1,1] + fit at fit$matcoef[2,1] * r[t-1] +
fit at fit$matcoef[3,1]*  r[t-2]
		#calculate error from fitted AR
		a[t] 		<- r[t] - rhat[t]
		#estimate sigma
		sigma[t] 	<- sqrt(fit at fit$matcoef[4,1] + fit at fit$matcoef[5,1] *
sigma[t-1]^2 + fit at fit$matcoef[6,1] * a[t - 1]^2)
		# calculate the value at risk
		VaR[t] <- (1 - exp(rhat[t] * dt + sqrt(dt) * qnorm(p) * sigma[t])) * data[t]
	}
	list(VaR=VaR,r=rhat,std=sigma)
}



On 11/21/06, Benjamin Dickgiesser <dickgiesser at gmail.com> wrote:
> Hi all,
>
> if I use
> fit = garchFit(~arma(2,0), ~garch(1,1), series = rt)
>
> does fit at fitted.values hold the fitted standard deviations? The manual
> only says
> @fitted.values  a numeric vector with the fitted values.
> I'm not sure if this means the fitted values from the arma or the variance..
>
> Is there also a function to estimate a AR-Garch model with t
> distributed innovations? I'm trying to calculate the Value at Risk
> using the models outlined above.
>
> I really appreciate your help,
> Benjamin
>


From muster at gmail.com  Wed Nov 22 02:34:34 2006
From: muster at gmail.com (T Mu)
Date: Tue, 21 Nov 2006 20:34:34 -0500
Subject: [R-SIG-Finance] questions about garchFit
Message-ID: <b68812e70611211734u4cb42852v696864974888e89f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061121/48644a64/attachment.pl 

From muster at gmail.com  Wed Nov 22 17:06:28 2006
From: muster at gmail.com (T Mu)
Date: Wed, 22 Nov 2006 11:06:28 -0500
Subject: [R-SIG-Finance] problems with garchFit
Message-ID: <b68812e70611220806v43f1a178rae85a5a62f8198d1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061122/cc4b5ca1/attachment.pl 

From muster at gmail.com  Wed Nov 22 18:59:54 2006
From: muster at gmail.com (T Mu)
Date: Wed, 22 Nov 2006 12:59:54 -0500
Subject: [R-SIG-Finance] problems with garchFit
In-Reply-To: <b68812e70611220806v43f1a178rae85a5a62f8198d1@mail.gmail.com>
References: <b68812e70611220806v43f1a178rae85a5a62f8198d1@mail.gmail.com>
Message-ID: <b68812e70611220959r6029a8adw13bb1ff8abe83cc3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061122/4f023401/attachment.pl 

From debmidya at yahoo.com  Thu Nov 23 12:31:08 2006
From: debmidya at yahoo.com (Deb Midya)
Date: Thu, 23 Nov 2006 03:31:08 -0800 (PST)
Subject: [R-SIG-Finance] portfolioMarkowitz function
Message-ID: <20061123113108.78362.qmail@web50409.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061123/1605f5da/attachment.pl 

From dickgiesser at gmail.com  Tue Nov 21 10:13:49 2006
From: dickgiesser at gmail.com (Benjamin Dickgiesser)
Date: Tue, 21 Nov 2006 09:13:49 +0000
Subject: [R-SIG-Finance] Garch, beginner questions
Message-ID: <b75d67340611210113v7059eaa0h39ac03c019c70026@mail.gmail.com>

Hi all,

if I use
fit = garchFit(~arma(2,0), ~garch(1,1), series = rt)

does fit at fitted.values hold the fitted standard deviations? The manual
only says
@fitted.values 	a numeric vector with the fitted values.
I'm not sure if this means the fitted values from the arma or the variance..

Is there also a function to estimate a AR-Garch model with t
distributed innovations? I'm trying to calculate the Value at Risk
using the models outlined above.

I really appreciate your help,
Benjamin


From wuertz at itp.phys.ethz.ch  Thu Nov 23 16:56:28 2006
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Thu, 23 Nov 2006 16:56:28 +0100
Subject: [R-SIG-Finance] portfolioMarkowitz function
In-Reply-To: <20061123113108.78362.qmail@web50409.mail.yahoo.com>
References: <20061123113108.78362.qmail@web50409.mail.yahoo.com>
Message-ID: <4565C4AC.4050705@itp.phys.ethz.ch>

Deb Midya wrote:

>Hi!,
>   
>  Thanks in advance.
>   
>  I am using the example function provided in the library fPortfolio.
>   
>  The example is:
>   
>  library(fPortfolio)
>   
>  ## SOURCE("fPortfolio.B2-MarkowitzPortfolio")
>  ## Not run: 
>  ## berndtInvest -
>  data(berndtInvest)
>  # Exclude Date, Market and Interest Rate columns from data frame,
>  # then multiply by 100 for percentual returns ...
>  berndtAssets = berndtInvest[, -c(1, 11, 18)]
>  rownames(berndtAssets) = berndtInvest[, 1]
>  head(berndtAssets)
>  
>  ## portfolioMarkowitz - 
>  myPortfolio = portfolioMarkowitz(x = berndtAssets, targetReturn = 20/100/12)
>   
>  I need to clarify the followings:
>   
>  1. targetReturn = 20/100/12
>  
>
targetReturn = 0.0167
20 devided by 100 devided by 12

>   
>  I could not follow the format used for targetReturn. How can I explain the values 20, 100 and 12?
>   
>  2. What is the objective function? 
>
Mean-variance Portfolio Problem ...

>and
>   
>  3. What are the constraints?
>  
>
no short selling bigger than 0 smaller than 1 for each asset ....

>   
>  I am looking forward for your response.
>   
>  Regards,
>   
>  Debabrata (Deb)
>  
>
The result:

Title:
 Mean-Variance Portfolio Optimization

Call:
 portfolioMarkowitz(x = berndtAssets, targetReturn = 20/100/12)

Portfolio Weights:
    2    5    7    9   10   13   14
0.53 0.03 0.15 0.08 0.08 0.02 0.12

Sum of Weights:
 [1] 1

Target Return(s):
 [1] 0.0167

Target Risk(s):
       [,1]
[1,] 0.037

Description:
 [1] "Thu Nov 23 16:49:18 2006"

The solution is for the Mean-Variance Portfolio optimization problem 
according
to Markowitz, short selling forbidden. The target return is just 
20/100/12 = 0.0167.
The investment in asset No 2 is 53%, in asset no 7 15% and so on.

Diethelm Wuertz

>   
>
> 
>---------------------------------
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-SIG-Finance at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>
>  
>


From emmanuel.leclercq at epfl.ch  Fri Dec  1 17:05:34 2006
From: emmanuel.leclercq at epfl.ch (EMMANUEL LECLERCQ)
Date: Fri, 01 Dec 2006 17:05:34 +0100
Subject: [R-SIG-Finance] fBasics: error with stableFit, cannot find PhiStable
Message-ID: <2f0163072c.3072c2f016@imap.epfl.ch>

Hi,

I begin with R and and I would like to use the stableFit function of 
the fBasics package. But when I compute this function, I have the 
following error message :

Erreur dans .qStableFit(x, doplot, title, description) : 
        objet ".PhiStable" non trouv?
De plus : Warning message:
data set 'PhiStable' not found in: data(PhiStable)

Any solutions or advice are welcome.
Thanks

Emmanuel Leclercq


From volchik2000 at list.ru  Tue Dec  5 15:58:27 2006
From: volchik2000 at list.ru (=?koi8-r?Q?=D2=CF=D7=C5=CE_=E1=CB=D8=C1=D4=CF=C9?=)
Date: Tue, 05 Dec 2006 17:58:27 +0300
Subject: [R-SIG-Finance] Converting factors back to numbers in R
In-Reply-To: =?koi8-r?Q?<mailman.13.1165057204.16307.r-sig-finance=40stat.math.ethz.ch>?=
Message-ID: <E1GrbkZ-0009Kj-00.volchik2000-list-ru@f65.mail.ru>

Hi everybody,

i've spent a lot of time trying to fix the following problem:

i'm trying to load into R several dataframes with stocks data through:

dat<-lapply(1:Number.of.contracts,function(x) {
   print(Names[x])
   read.csv(paste(WorkingDirectory,Names[x], '_',TimeFrame,'.csv',sep=''),as.is=T,header=T,row.names=1,na.strings=c("#NA",""))
   })


Because the header are times in the format "HH:MM" R converts them to strings, changing in the way. It's now a problem, i can fix it using sub (gsub) functions.
Problem is that R converts prices to factors as well even though i have option as.is=T set, and then it almost impossible to convert them back to double preserving the row.names (these are dates) and column names (times), probably because of the structure i store them in (list of dataframes).
I suspect there is an easy way to solve this problem, but couldn't figure it out :(

Thanks


From frainj at tcd.ie  Tue Dec  5 16:15:27 2006
From: frainj at tcd.ie (John C. Frain)
Date: Tue,  5 Dec 2006 15:15:27 +0000
Subject: [R-SIG-Finance] Converting factors back to numbers in R
Message-ID: <1165331727.45758d0fd3f80@mymail.tcd.ie>

The html help file for factors gives

To ?revert? a factor f to its original numeric values, as.numeric(levels(f))[f]
is recommended and slightly more efficient than as.numeric(as.character(f)).


John C. Frain.
Economics Department
Trinity College Dublin
Dublin 2

www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie


Quoting ????? ??????? <volchik2000 at list.ru>:

> Hi everybody,
>
> i've spent a lot of time trying to fix the following problem:
>
> i'm trying to load into R several dataframes with stocks data through:
>
> dat<-lapply(1:Number.of.contracts,function(x) {
>    print(Names[x])
>    read.csv(paste(WorkingDirectory,Names[x],
>
'_',TimeFrame,'.csv',sep=''),as.is=T,header=T,row.names=1,na.strings=c("#NA",""))
>    })
>
>
> Because the header are times in the format "HH:MM" R converts them to
> strings, changing in the way. It's now a problem, i can fix it using sub
> (gsub) functions.
> Problem is that R converts prices to factors as well even though i have
> option as.is=T set, and then it almost impossible to convert them back to
> double preserving the row.names (these are dates) and column names (times),
> probably because of the structure i store them in (list of dataframes).
> I suspect there is an easy way to solve this problem, but couldn't figure it
> out :(
>
> Thanks
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>


From brian at braverock.com  Tue Dec  5 23:35:19 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 5 Dec 2006 16:35:19 -0600
Subject: [R-SIG-Finance] Incremental and Component VaR
Message-ID: <200612051635.19757.brian@braverock.com>

I have previously posted several functions for analysis of the higher 
moments of a returns distribution here:

http://braverock.com/brian/R/extra_moments.R

including a function to calculate modified Cornish-Fisher VaR.

I've intermittently tried to implement Incremental (or Component) VaR.

I could really use some help debugging this function.  In Incremental VaR, 
the Incremental VaR of each component of the portfolio should all add up 
to the total VaR of the portfolio.  Several papers suggest that this 
should work with either traditional (RiskMetrics) VaR or with modified 
Cornish-Fisher VaR.

Unfortunately, I can't get it to work with either VaR calculation, so I 
must have an error in my logic somewhere.

Help would be greatly appreciated in fixing this function.  My 
IncrementalVaR function begins on line 610 of the referenced 
extra_moments.R file

Thanks in advance for any assistance.

Regards,

  - Brian


Ref:

Incremental and Component VaR is described many places in the literature, 
including:
Beyond the VaR Horizon, Gaussel, et. al.
http://www.mathfin.com/nicolas/Q37.pdf

Incremental, Marginal, and Component VaR, 2004, Denton and Jayaraman
http://www.sungard.com/products_and_services/energy/variantsofvar1.pdf

extra_moments.R
http://braverock.com/brian/R/extra_moments.R


From Joe-Byers at utulsa.edu  Wed Dec  6 16:55:16 2006
From: Joe-Byers at utulsa.edu (Joe W. Byers)
Date: Wed, 06 Dec 2006 09:55:16 -0600
Subject: [R-SIG-Finance] Incremental and Component VaR
In-Reply-To: <200612051635.19757.brian@braverock.com>
References: <200612051635.19757.brian@braverock.com>
Message-ID: <4576E7E4.9000701@utulsa.edu>

Brian,

It looks like you are trying to calculate Marginal VAR (using 
riskmetrics' definition of marginal VAR) You should checkout riskmetrics 
web site www.riskmetrics.com.  Pages 69-70 of their document Return to 
riskmetrics - the evolution of a standard has IVAR calculations there. 
They specify IVAR = weights * the gradiant of the VAR with respect to 
the weights or
w(i) * partial (VAR/w(i))  This is equation 6.10.  Their equation 6.14 
give the calculation of the gradient as
-z{ Covariance Matrix * weights vector) / sqrt(t(weights) * covariance 
matrix * weights)} where z is the VAR alpha level.  Mutiply this term by 
the weights vector and you get a vector of IVAR's where the sum of the 
vector is equal to VAR.  Their documentation seems to imply that you 
have to calculate IVAR as a separate function meaning you do not call a 
VAR calc on the sub portfolio as you do in your code.

I should also point out that VAR definitions are not consistent in the 
literature.  Jorion's VAR book and the riskmetrics documentation differ 
in incremental VAR and mariginal VAR definitions.  IVAR in Jorion is 
Marginal VAR in riskmetrics and IVAR in riskmetrics is component VAR in 
Jorion for example.

Please let me know how it is going.

Good Luck
Joe W. Byers
Professor of Finance
The University of Tulsa


Brian G. Peterson wrote:
> I have previously posted several functions for analysis of the higher 
> moments of a returns distribution here:
> 
> http://braverock.com/brian/R/extra_moments.R
> 
> including a function to calculate modified Cornish-Fisher VaR.
> 
> I've intermittently tried to implement Incremental (or Component) VaR.
> 
> I could really use some help debugging this function.  In Incremental VaR, 
> the Incremental VaR of each component of the portfolio should all add up 
> to the total VaR of the portfolio.  Several papers suggest that this 
> should work with either traditional (RiskMetrics) VaR or with modified 
> Cornish-Fisher VaR.
> 
> Unfortunately, I can't get it to work with either VaR calculation, so I 
> must have an error in my logic somewhere.
> 
> Help would be greatly appreciated in fixing this function.  My 
> IncrementalVaR function begins on line 610 of the referenced 
> extra_moments.R file
> 
> Thanks in advance for any assistance.
> 
> Regards,
> 
>   - Brian
> 
> 
> Ref:
> 
> Incremental and Component VaR is described many places in the literature, 
> including:
> Beyond the VaR Horizon, Gaussel, et. al.
> http://www.mathfin.com/nicolas/Q37.pdf
> 
> Incremental, Marginal, and Component VaR, 2004, Denton and Jayaraman
> http://www.sungard.com/products_and_services/energy/variantsofvar1.pdf
> 
> extra_moments.R
> http://braverock.com/brian/R/extra_moments.R
>


From Joe-Byers at utulsa.edu  Wed Dec  6 17:03:26 2006
From: Joe-Byers at utulsa.edu (Joe W. Byers)
Date: Wed, 06 Dec 2006 10:03:26 -0600
Subject: [R-SIG-Finance] Incremental and Component VaR
In-Reply-To: <200612051635.19757.brian@braverock.com>
References: <200612051635.19757.brian@braverock.com>
Message-ID: <4576E9CE.50803@utulsa.edu>

Brian,

After reading your documented links.  The two source your are using 
confuse the definitions of IVAR and Marginal VAR as describe in the risk 
metrics documents.  IVAR in your first source is the riskmetrics 
definition. Marginal VAR in the second (sungard) is IVAR in the 
riskmetrics definitions and IVAR in this source in Marginal VAR in the 
riskmetrics definition.

This means you are not calculating the IVAR correctly.

Confusing isn't.

Joe


Brian G. Peterson wrote:
> I have previously posted several functions for analysis of the higher 
> moments of a returns distribution here:
> 
> http://braverock.com/brian/R/extra_moments.R
> 
> including a function to calculate modified Cornish-Fisher VaR.
> 
> I've intermittently tried to implement Incremental (or Component) VaR.
> 
> I could really use some help debugging this function.  In Incremental VaR, 
> the Incremental VaR of each component of the portfolio should all add up 
> to the total VaR of the portfolio.  Several papers suggest that this 
> should work with either traditional (RiskMetrics) VaR or with modified 
> Cornish-Fisher VaR.
> 
> Unfortunately, I can't get it to work with either VaR calculation, so I 
> must have an error in my logic somewhere.
> 
> Help would be greatly appreciated in fixing this function.  My 
> IncrementalVaR function begins on line 610 of the referenced 
> extra_moments.R file
> 
> Thanks in advance for any assistance.
> 
> Regards,
> 
>   - Brian
> 
> 
> Ref:
> 
> Incremental and Component VaR is described many places in the literature, 
> including:
> Beyond the VaR Horizon, Gaussel, et. al.
> http://www.mathfin.com/nicolas/Q37.pdf
> 
> Incremental, Marginal, and Component VaR, 2004, Denton and Jayaraman
> http://www.sungard.com/products_and_services/energy/variantsofvar1.pdf
> 
> extra_moments.R
> http://braverock.com/brian/R/extra_moments.R
>


From brian at braverock.com  Wed Dec  6 18:16:54 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 6 Dec 2006 11:16:54 -0600
Subject: [R-SIG-Finance] Incremental and Component VaR
In-Reply-To: <4576E9CE.50803@utulsa.edu>
References: <200612051635.19757.brian@braverock.com>
	<4576E9CE.50803@utulsa.edu>
Message-ID: <200612061116.54795.brian@braverock.com>

On Wednesday 06 December 2006 10:03, Joe W. Byers wrote:
> Brian,
>
> After reading your documented links.  The two source you are using
> confuse the definitions of IVAR and Marginal VAR as describe in the
> risk metrics documents.  IVAR in your first source is the riskmetrics
> definition. Marginal VAR in the second (sungard) is IVAR in the
> riskmetrics definitions and IVAR in this source in Marginal VAR in the
> riskmetrics definition.
>
> This means you are not calculating the IVAR correctly.
>
> Confusing isn't.

Prof. Byers,

Thank you for your comments on this matter.  I had previously noticed the 
definitional confusion on this, and thought (apparently erroneously) that 
I had sorted it out.  I'll re-review the references at my disposal and 
try again to unravel it.

I'm most interested in using a modified Cornish-Fisher VaR in these 
calculations, as I find that modified VaR is significantly more useful 
for assets that are not normally distributed than Riskmetrics style 
variance/covariance delta-normal VaR, but their descriptions are complete 
and coherent.  A number of authors have suggested that you can use 
modified VaR for Incremental/Component/Marginal VaR, so hopefully I'll be 
able to make it work with either traditional or modified VaR.

Thanks again for the review and pointers.  I'll post updates to this 
thread as I have them worked out.

Regards,

   - Brian

> Brian G. Peterson wrote:
<...>
>> Ref:
>>
>> Incremental and Component VaR is described many places in the
>> literature, including:
>> Beyond the VaR Horizon, Gaussel, et. al.
>> http://www.mathfin.com/nicolas/Q37.pdf
>>
>> Incremental, Marginal, and Component VaR, 2004, Denton and Jayaraman
>> http://www.sungard.com/products_and_services/energy/variantsofvar1.pdf
>>
>> extra_moments.R
>> http://braverock.com/brian/R/extra_moments.R

Return to Riskmetrics: the Evolution of a Standard
http://www.riskmetrics.com/r2rovv.html
http://www.riskmetrics.com/pdf/rrmfinal.pdf (pp.69-72)


From Efferz at gmx.de  Fri Dec  8 10:56:39 2006
From: Efferz at gmx.de (Efferz at gmx.de)
Date: Fri, 08 Dec 2006 10:56:39 +0100
Subject: [R-SIG-Finance] GARCH/APARCH with fSeries
Message-ID: <20061208095639.75940@gmx.net>

Hi,

I try to make VaR predictions with different GARCH setups, and have some questions about the implementation with fSeries.

1) Is the following setup correct to predict the one-step ahead VaR with skewed t GARCH(1,1)?
  
  (retdata contains the daily returns)

   st.fit<-sstdFit(retdata)
   g.fit<-garchFit(formula=~garch(1,1),
                   data=retdata,
                   cond.dist="dsstd",
                   skew=st.fit$est['xi']
                   shape=st.fit$est['nu']
                   include.shape=T,
                   include.skew=T,
                   include.mean=T)	
   param<-predict(g.fit,1)
   g.os.pred<-qsstd(0.05,mean=as.numeric(param['meanForecast']),
                    sd=as.numeric(param['standardDeviation']),
                    nu=as.numeric(g.fit at fit$params$params['shape']),
                    xi=as.numeric(g.fit at fit$params$params['skew']))

2) How to predict the 5day VaR within that setup? (not the daily VaR in 5   
   days!) Are the predicted values in predict(g.fit,5)[5,] those for the  
   daily mean and sd in 5 days?

3) When using the same setup as in 1) but now for skewed t APARCH(1,1) 
   (formula=~APARCH(1,1)) I get extremly large predicted standard  
   deviations of 0.3 and larger (in contrast to 0.02 of the skewed t  
   GARCH(1,1) setup). I think that isn?t reasonable and therefore I have
   doubts if my implementation in 1) is correct. 

Kind regards,

Martin
--


From junkmanu at free.fr  Sat Dec  9 11:26:49 2006
From: junkmanu at free.fr (manu)
Date: Sat, 9 Dec 2006 11:26:49 +0100
Subject: [R-SIG-Finance] troubles with the weights in the VaR function
Message-ID: <455B2F290064F967@> (added by postmaster@aliceadsl.fr)

hi there

i have some troubles with VaR ( value at risk function)
to be more specific, with the weights in the VaR function


when i run the example:
equalWeights = rep(1/4, 4)
alpha = 0.10
# Value at Risk:
VaR(myAssets, equalWeights, alpha)

everything is ok



BUT 

when i read my own data set, and try to have my own weights, i have the following message :

Erreur dans `names<-.default`(`*tmp*`, value = "VaR") : 
        attribut 'names' [1] doit ?tre de m?me longueur que le vecteur [0]

which can be translated as:

error in `names<-.default`(`*tmp*`, value = "VaR") : 
	attribute 'names' [1] must have the same length as vector [0]



i have no idea of what it means
:-(


i printed the names of my data, and it was exactely the same as the names in the VaR example



when returning this message, R returns at the same time the computation of the VaR, but using the default (equal weights); in my case it is not possible to have different weights :-(




did anyone face the same problem?
if yes, how to solve it


thx in advance


regards


manu


From brian at braverock.com  Sat Dec  9 16:48:43 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 9 Dec 2006 09:48:43 -0600
Subject: [R-SIG-Finance] performance analytics functions missing from other
	libraries (implemented)
In-Reply-To: <200608100705.43884.brian@braverock.com>
References: <200608100705.43884.brian@braverock.com>
Message-ID: <200612090948.44201.brian@braverock.com>

We previously released our functions for dealing with higher moments of 
the return distribution, including coskewness, cokurtosis, and Modified 
Cornish-Fisher VaR.  That release post may be found here:

https://stat.ethz.ch/pipermail/r-sig-finance/2006q3/000977.html

We would now like to release a collection of assorted performance 
analytics functions, filling in gaps that we found when working with the 
excellent and extremely useful RMetrics, 'portfolio', and other 
finance-focused R packages.  

The following functions are useful for calculating performance metrics for 
trading strategies, fund performance, or other post-trade (even 
post-balance- sheet) performance assessment.  In general, we're working 
with monthly scaled returns data (although these functions should be 
useful for daily or weekly scales as well), and in returns rather than 
prices.

There are books and books full of these calculations.  Some are even 
useful. Notation terminology in the papers and texts is often sloppy, so 
the user should be aware of how the specific calculations are 
implemented.

Functions:
  checkDataMatrix
  checkDataVector
  annualizedReturn
  annualizedStdDev
  sharpeRatio
  annualizedSharpeRatio
  modSharpe
  semiDeviation
  downsideDeviation
  sortinoRatio
  maxDrawdown
  beta
  alpha
  omega
  trackingError
  activePremium
  informationRatio
  rollingFunction
  rollingStat
  cumulativeReturns
  colCumprods
  colCumMax
  rollingCorrelation
  statsTable
  @todo Herfindahl Index
  @todo Geltner method risk-adjusted returns
  @todo longest run up/down
  @todo improve the way statsTable() uses apply() to make it more generic

Default input values assume regular monthly returns.  Scale arguements can 
be used to specify the number of observations during a year (e.g., 12 = 
monthly returns).

The risk free rate (rf) MUST be in the same periodicity as the data going 
in.

checkDataMatrix
checkDataVector
      Description:
      These functions were created to make the different kinds of data
      at least _seem_ more fungible.  It allows the user to pass in a data
      object without being concerned that the function requires a matrix,
      data.frame, or timeSeries object.  
      By using this, the function "knows"
      what data format it has to work with.

annualizedReturn
      Description:
      An average annualized return is convenient for comparing returns.

annualizedStdDev
      To annualize standard deviation, we multiply by the square root 
      of the number of observations per year.

sharpeRatio
      Description:
      The Sharpe ratio is simply the return per unit of risk 
      (represented by variability).  
      This function uses returns rather than prices as is 
      done in other R libraries.

annualizedSharpeRatio
      Description:
      Using an annualized Sharpe Ratio is useful for comparison.  
      The annualized Sharpe ratio is computed by dividing the 
      annualized mean monthly excess return by the 
      annualized monthly standard deviation of excess return.

modSharpe
      Description:
      The Sharpe ratio is simply the return per unit of risk 
      (represented by variance).  
      The higher the Sharpe ratio, the better the combined
      performance of "risk" and return.

      The Sharpe Ratio is a risk-adjusted measure of return that uses
      standard deviation to represent risk.

      A number of papers now recommend using a "modified Sharpe" ratio
      using a Modified Cornish-Fisher VaR as the measure of Risk.

semiDeviation
      Description:
      This function should just be a wrapper of downsideDeviation with
      MAR = mean(x)
      see below

downsideDeviation
      Description:
      Downside deviation, similar to semi deviation, eliminates 
      positive returns when calculating risk.  
      To calculate it, we take the returns that are less
      than the target (or Minimum Acceptable Returns (MAR)) 
      returns and take the differences of those to the target.  
      We sum the squares and divide by the total number 
      of returns to get a below-target semi-variance.

sortinoRatio
      Description:
      Sortino proposed to better account for skill and excess performance
      by using only downside semivariance as the measure of risk.
      modified by permission from function by Sankalp Upadhyay

maxDrawdown = function (R)
      Description:
      To find the maximum drawdown in a return series, we need to first
      calculate the cumulative returns and the maximum cumulative return
      to that point.  
      Any time the cumulative returns dips below the maximum
      cumulative returns, it's a drawdown.  Drawdowns are measured as a
      percentage of that maximum cumulative return, in effect, 
      measured from peak equity.

alpha
      This is a wrapper for calculating a CAPM alpha.

beta
      Description:
      This is a wrapper for calculating a CAPM beta.

omega
      Description
      Keating and Shadwick (2002) proposed Omega 
      (referred to as Gamma in their original paper) 
      as a way to capture all of the higher moments of the
      returns distribution.  Mathematically, Omega is:
        integral[L to b](1 - F(r))dr / integral[a to L](F(r))dr
      where the cumulative distribution F is defined 
      on the interval (a,b).
      L is the loss threshold that can be specified as zero, return from a
      benchmark index, or 
         an absolute rate of return - any specified level.
      When comparing alternatives using Omega, L should be common.  
      Input data can be transformed prior to calculation, 
      which may be useful for introducing risk aversion.

trackingError
      Description
      trackingError = sqrt(sum(assetReturns.vec - indexReturns.vec)^2 /
                        (length(assetReturns.vec) - 1)) * sqrt(scale)

activePremium
      Description
      activePremium = (annualizedReturn(assetReturns.vec, scale = scale) -
                       annualizedReturn(indexReturns.vec, scale = scale) )

informationRatio
      Description
      informationRatio = activePremium/trackingError

rollingStat
      function for calculating any function over a rolling period,
      say the last three months.  Pass in the function name as FUN,
      e.g., FUN = "mean".  Useful for passing in several periods and 
functions
      for comparing different series.

cumulativeReturn
      Simple function for calculating cumulative return over a period
      of time, say a calendar year.  
      Can produce simple or geometric return.

colCumprods
      apply cumulative product to the return strem, wrapped using apply()

colCummax
      to get to drawdown calculations, we need colCummax

statsTable
      Description:
      This function creates a table of statistics from vectors 
      of functions and labels passed in. 
      The resulting table is formatted such that metrics
      are calculated separately for each column of returns 
      in the data object.


rollingCorrelation
      Description:
      This is a wrapper for providing n-period trailing correlations 
      for the data provided.  
      Inspired by rollFun() written by Diethelm Wurtz.

      Specifically, we're wrapping the basic function cor(), which has:
      function (x, y = NULL, use = "all.obs", method = c("pearson",
          "kendall", "spearman"))


rollingFunction
      Description:
      This is a wrapper for providing n-period trailing calculations 
      for the data and functions provided.

rollingRegression
      Description:
      This code was posted to the R-help mailing list in response to a 
question
      posted by Ajay Shah.  For the full discussion, see:
      http://www.mail-archive.com/r-help at stat.math.ethz.ch/msg19544.html


This library is free software; you can redistribute it and/or
modify it under the terms of the GNU General Public License (which 
includes attribution for the original creator)

The GNU General Public License is available here:
http://www.gnu.org/licenses/gpl.html

The current and all future versions of the attached file 
may be found here:
http://braverock.com/brian/R/performance-analytics.R

We hope you find it useful.  Any comments, criticisms, or suggestions
for improvement are gladly accepted.

Regards,

    - Brian

-------------- next part --------------
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either
# version 2 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Library General Public License for more details.
#
# You should have received a copy of the GNU General
# Public License along with this library; if not,
# go here: http://www.gnu.org/licenses/gpl.html
# or write to the
# Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston,
# MA  02111-1307  USA

# Copyright 2006 Peter Carl, Brian G. Peterson
# $Id: performance-analytics.R,v 1.36 2006/12/09 15:26:08 brian Exp $

################################################################################
# FUNCTIONS:
#
#   checkDataMatrix
#   checkDataVector
#   annualizedReturn
#   annualizedStdDev
#   sharpeRatio
#   annualizedSharpeRatio
#   modSharpe
#   semiDeviation
#   downsideDeviation
#   sortinoRatio
#   maxDrawdown
#   beta
#   alpha
#   omega
#   trackingError
#   activePremium
#   informationRatio
#   rollingFunction
#   rollingStat
#   cumulativeReturns
#   colCumprods
#   colCumMax
#   rollingCorrelation
#   statsTable
#
#   @todo Herfindahl Index
#   @todo Geltner method risk-adjusted returns
#   @todo longest run up/down
#   @todo improve the way statsTable() fn uses apply() to make it more generic
#
################################################################################

################################################################################
# The following functions are useful for calculating performance metrics for
# trading strategies, fund performance, or other post-trade (even post-balance-
# sheet) performance assessment.  In general, we're working with monthly scaled
# data (although these functions should be useful for daily or weekly scales as
# well), and in returns rather than prices.

# There are books and books full of these calculations.  Some are even useful.
# Notation is sloppy, however, so the user should be aware of how the specific
# calculations are implemented.

# Default input values assume regular monthly returns.  Scale arguements can be
# used to specify the number of observations during a year (e.g., 12 = monthly
# returns).

# The risk free rate (rf) MUST be in the same periodicity as the data going in.

# ------------------------------------------------------------------------------

# Load any required libraries.

if(!require("fCalendar", quietly=TRUE)) {
    stop("package", sQuote("fOptions"), "is needed.  Stopping")
}
if(!require("fOptions", quietly=TRUE)) {
    stop("package", sQuote("fOptions"), "is needed.  Stopping")
}
if(!require("tseries", quietly=TRUE)) {
    stop("package", sQuote("tseries"), "is needed.  Stopping")
}
if(!require("Hmisc", quietly=TRUE)) {
    stop("package", sQuote("Hmisc"), "is needed.  Stopping")
}
# also requires Brian's extra_moments.R file, should we always include it?

# ------------------------------------------------------------------------------

checkDataMatrix = function (x, na.rm = FALSE, ...)
{ # @author Peter Carl

    # Description:

    # This function was created to make the different kinds of data classes
    # at least _seem_ more fungible.  It allows the user to pass in a data
    # object without being concerned that the function requires a matrix,
    # data.frame, or timeSeries object.  By using this, the function "knows"
    # what data format it has to work with.

    # Inputs:
    # x: a matrix, data.frame or timeSeries object of data to be checked and
    # transformed if necessary.
    # na.rm: removes rows of data with NA's in any column.  This is useful
    # for calculating correlations, etc., that require complete data.  Note
    # that this passes back only the first contiguous set of data, to retain
    # the regular timeseries nature of the data.

    # Outputs:
    # Produces a matrix object with named rows and columns.

    # FUNCTION:
    if (class(x) == "numeric") {
        # Note that column and row labels will be blank.
        y = as.matrix(x)
    }

    if (class(x) == "matrix") {
        y = x
    }

    if (class(x) == "data.frame") {
        y = as.matrix(x)
    }

    if (class(x) == "timeSeries") {
        # timeSeries objects keep the data in a matrix and append a set of
        # meta-data.  We just need the information stored in the 'Data' slot.
        #y = x at Data
        y = seriesData(x)
    }

    if (na.rm) {
        #y = na.contiguous(y)
        y = na.omit(y)
    }
    return(y)

}

# ------------------------------------------------------------------------------

checkDataVector = function (R, na.rm = TRUE, quiet = TRUE, ...)
{ # @author Peter Carl

    # Description:

    # This function was created to make the different kinds of data classes
    # at least _seem_ more fungible.  It allows the user to pass in a data
    # object without being concerned that the function requires a matrix,
    # data.frame, or timeSeries object.  By using this, the function "knows"
    # what data format it has to work with.

    # Inputs:
    # x: the data provided.
    # na.rm: default behavior is to remove NA's
    # quiet: if true, it will throw warnings when errors are noticed

    # Outputs:
    # Produces a numeric vector or an NA and any associated warnings.

    # FUNCTION:

    x = as.vector(R)

    # First, we'll check to see if we have more than one column.
    if (NCOL(x) > 1) {
        if(!quiet)
            warning("The data provided is not a vector or univariate time series.  Used only the first column")
        x = x[,1]
    }

    # Second, we'll hunt for NA's and remove them if required
    if (any(is.na(x))) {
        if(na.rm) {
            # Try to remove any NA's
            x = x[!is.na(x)]
            if(!quiet){
                warning("The following slots have NAs.")
                warning(paste(x at na.removed," "))
            }
        }
        else {
            if(!quiet)
                warning("Data contains NA's.")
        }
    }

    # Third, we'll check to see if we have any character data
    if (!is.numeric(x)){
        if(!quiet)
            warning("The data is not numeric.")
        # Try to coerce the data
        x = as.numeric(x)
    }

    # Fourth, we'll see if we have more than one data point.
    if (NROW(x) <= 1) {
        if(!quiet)
            warning("Only one row provided.  Returning NA.")
        return(NA)
    }

    # @todo: Add check for stopifnot(is.atomic(y))???

    return(as.vector(x))

}

# ------------------------------------------------------------------------------

annualizedReturn = function (R, geometric = TRUE, scale = 12)
{ # @author Peter Carl

    # Description:

    # An average annualized return is convenient for comparing returns.
    # @todo: This function could be used for calculating geometric or simple
    # returns

    # n = periods under analysis
    # f = number of periods in a year (daily f = 252, monthly f = 12,
    # quarterly f = 4)

    # arithmetic average: ra = (f/n) * sum(ri)
    # geometric average: rg = product(1 + ri)^(f/n) - 1

    # @todo: don't calculate for returns less than 1 year

    # FUNCTION:

    x = checkDataVector(R)
    y = x[!is.na(x)]
    n = length(y)
    # currently only uses geometric return to annualize returns
    #return(prod(1 + x)^(scale/length(x)) - 1)
    return(prod(1 + x, na.rm = TRUE)^(scale/n) - 1)
}

# ------------------------------------------------------------------------------

annualizedStdDev = function (R, rf = 0, scale = 12)
{ # @author Peter Carl

    # To annualize standard deviation, we multiply by the square root of the
    # number of observations per year.

    x = checkDataVector(R)

    # return(sqrt(scale)*sqrt(var(x - rf)))
    return(sqrt(scale)*sqrt(var(x, na.rm = TRUE)))
}

# ------------------------------------------------------------------------------

sharpeRatio = function (R, rf = 0)
{ # @author Peter Carl

    # DESCRIPTION:
    # The Sharpe ratio is simply the return per unit of risk (represented by
    # variability).  The higher the Sharpe ratio, the better the combined
    # performance of "risk" and return.

    # The Sharpe Ratio is a risk-adjusted measure of return that uses
    # standard deviation to represent risk.

    # Inputs:
    # R: in this case, the function anticipates having a return stream as input,
    #    rather than prices.
    # rf: the risk free rate MUST be in the same periodicity as the data going in.

    # Outputs:
    # This function returns a Sharpe ratio for the same periodicity of the
    # data being input (e.g., monthly data -> monthly SR)

    # FUNCTION:

    x = checkDataVector(R)
    return((mean(x, na.rm = TRUE) - rf)/sd(x, na.rm = TRUE))
    #return((mean(x) - rf)/sd(x))
}

# ------------------------------------------------------------------------------

annualizedSharpeRatio = function (R, rf = 0, scale = 12)
{ # @author Peter Carl

    # DESCRIPTION:

    # Using an annualized Sharpe Ratio is useful for comparison.  The annualized
    # Sharpe ratio is computed by dividing the annualized mean monthly excess
    # return by the annualized monthly standard deviation of excess return.

    # @todo: monthly standard deviation of ***excess*** return

    # Inputs:
    # R: in this case, the function anticipates having a return stream as input,
    #     rather than prices.
    # rf: the risk free rate MUST be in the same periodicity as the data going in.

    # FUNCTION:

    x = checkDataVector(R)

    return((annualizedReturn(x, scale = scale) - (rf * scale))/annualizedStdDev(x, rf = rf, scale = scale))

}

# ------------------------------------------------------------------------------

modSharpe = function (R, rf = 0, p=0.95, scale=1)
{ # @author Brian G. Peterson

    # DESCRIPTION:
    # The Sharpe ratio is simply the return per unit of risk (represented by
    # variability).  The higher the Sharpe ratio, the better the combined
    # performance of "risk" and return.

    # The Sharpe Ratio is a risk-adjusted measure of return that uses
    # standard deviation to represent risk.

    # A number of papers now recommend using a "modified Sharpe" ratio
    # using a Modified Cornish-Fisher VaR as the measure of Risk.

    # Inputs:
    # R: in this case, the function anticipates having a return stream as input,
    #    rather than prices.
    #
    # rf: the risk free rate MUST be in the same periodicity as the data going in.
    #
    # p: probability at which to calculate the modified VaR (defaults to 95%)

    # Outputs:
    # This function returns a modified Sharpe ratio for the same periodicity of the
    # data being input (e.g., monthly data -> monthly SR)

    # FUNCTION:

    x = checkDataVector(R)
    return( (mean(x, na.rm = TRUE) - rf)*scale/(modifiedVaR(x, p)*sqrt(scale)) )
    #return((mean(x) - rf)/sd(x))
}

# ------------------------------------------------------------------------------

semiDeviation = function (R)
{ # @author Peter Carl

    # DESCRIPTION:
    # This function should just be a wrapper of downsideDeviation with
    # MAR = mean(x)
    # see below

    # FUNCTION:

    x = checkDataVector(R)

    y = subset(x,x < mean(x))
    return(sqrt(sum((y - mean(x))^2)/(length(y)-1)))

}

# ------------------------------------------------------------------------------

downsideDeviation = function (R, MAR = 0)
{ # @author Peter Carl

    # DESCRIPTION:
    # Downside deviation, similar to semi deviation, eliminates positive returns
    # when calculating risk.  To calculate it, we take the returns that are less
    # than the target (or Minimum Acceptable Returns (MAR)) returns and take the
    # differences of those to the target.  We sum the squares and divide by the
    # total number of returns to get a below-target semi-variance.

    # This is also useful for calculating semi-deviation by setting
    # MAR = mean(x)

    # FUNCTION:

    x = checkDataVector(R)

    y = subset(x,x < MAR)
    # return(sqrt(sum((y - MAR)^2)/(length(y)-1)))
    return(sqrt(sum((y - MAR)^2)/(length(y))))
    # @todo verify which calculation is correct

}

# ------------------------------------------------------------------------------

sortinoRatio = function (R, MAR = 0)
{ # @author Brian G. Peterson
  # modified from function by Sankalp Upadhyay <sankalp.upadhyay [at] gmail [dot] com> with permission

    # Description:
    # Sortino proposed to better account for skill and excess performance
    # by using only downside semivariance as the measure of risk.

    # R     return vector
    # MAR   minimum acceptable return
    # Function:

    x = checkDataVector(R)

    result = mean (R - MAR) / downsideDeviation(R, MAR)

    #Return:
    result
}

# ------------------------------------------------------------------------------

maxDrawdown = function (R)
{ # @author Peter Carl

    # DESCRIPTION:
    # To find the maximum drawdown in a return series, we need to first
    # calculate the cumulative returns and the maximum cumulative return to
    # that point.  Any time the cumulative returns dips below the maximum
    # cumulative returns, it's a drawdown.  Drawdowns are measured as a
    # percentage of that maximum cumulative return, in effect, measured from
    # peak equity.

    # FUNCTION:

    x = checkDataVector(R)

    cumulativeReturn = cumprod(1+x)
    maxCumulativeReturn = cummax(cumulativeReturn)
    drawdown = cumulativeReturn/maxCumulativeReturn - 1
    # if you want to see the drawdown series, plot(drawdown,type="l")
    return(min(drawdown))

}

# ------------------------------------------------------------------------------

alpha = function (x, y, rf = 0)
{ # @author Peter Carl

    # DESCRIPTION:
    # This is a wrapper for calculating a CAPM alpha.

    # Inputs:
    # x: vector of returns for the asset being tested
    # y: vector of returns for the benchmark the asset is being gauged against
    # x and y are assumed to be matching periods
    # rf: risk free rate in the same periodicity as the returns.  May be a vector
    #     of the same length as x and y.

    # Output:
    #

    # FUNCTION:

    assetReturns.vec = checkDataVector(x)
    indexReturns.vec = checkDataVector(y)

    if (length(assetReturns.vec) != length(indexReturns.vec))
        stop("Returns to be assessed have unequal time periods. Are there NA's in the data?")

    # Make these excess returns
    assetExcessRet.vec = assetReturns.vec - rf
    indexExcessRet.vec = indexReturns.vec - rf

    # regress
    model.lm = lm(assetExcessRet.vec ~ indexExcessRet.vec)

    alpha = coef(model.lm)[[1]]
#    beta = coef(model.lm)[[2]]
    alpha
}

# ------------------------------------------------------------------------------

beta = function (x, y, rf = 0, digits = 4)
{ # @author Peter Carl

    # DESCRIPTION:
    # This is a wrapper for calculating a CAPM beta.

    # Inputs:
    # x: vector of returns for the asset being tested
    # y: vector of returns for the benchmark the asset is being gauged against
    # x and y are assumed to be matching periods and NO TEST IS MADE TO CHECK
    # rf: risk free rate in the same periodicity as the returns.  May be a vector
    #     of the same length as x and y.

    # Output:
    #

    # FUNCTION:

    assetReturns.vec = checkDataVector(x)
    indexReturns.vec = checkDataVector(y)

    if (length(assetReturns.vec) != length(indexReturns.vec))
        stop("Returns to be assessed have unequal time periods. Are there NA's in the data?")

    # Make these excess returns
    assetExcessRet.vec = assetReturns.vec - rf
    indexExcessRet.vec = indexReturns.vec - rf

    # regress
    model.lm = lm(assetExcessRet.vec ~ indexExcessRet.vec)

#    alpha = coef(model.lm)[[1]]
    beta = coef(model.lm)[[2]]
    beta
}

# ------------------------------------------------------------------------------

omega = function (R, L = 0, method = c("simple", "interp", "binomial", "blackscholes"), output = c("point", "full"), rf = 0)
{ # @author Peter Carl

    # DESCRIPTION
    # Keating and Shadwick (2002) proposed Omega (referred to as Gamma in their
    # original paper) as a way to capture all of the higher moments of the
    # returns distribution.  Mathematically, Omega is:
    #   integral[L to b](1 - F(r))dr / integral[a to L](F(r))dr
    # where the cumulative distribution F is defined on the interval (a,b).
    # L is the loss threshold that can be specified as zero, return from a
    # benchmark index, or an absolute rate of return - any specified level.
    # When comparing alternatives using Omega, L should be common.  Input data
    # can be transformed prior to calculation, which may be useful for
    # introducing risk aversion.

    # This function returns a vector of Omega, useful for plotting.  The
    # steeper, the less risky.  Above it's mean, a steeply sloped Omega also
    # implies a very limited potential for further gain.

    # Omega has a value of 1 at the mean of the distribution.

    # Omega is sub-additive.  The ratio is dimensionless.

    # Kazemi, Schneeweis, and Gupta (2003), in "Omega as a Performance Measure"
    # shows that Omega can be written as:
    #   Omega(L) = C(L)/P(L)
    # where C(L) is essentially the price of a European call option written
    # on the investment and P(L) is essentially the price of a European put
    # option written on the investment.  The maturity for both options is
    # one period (e.g., one month) and L is the strike price of both options.

    # The numerator and the denominator can be expressed as:
    #   exp(-rf) * E[max(x - L, 0)]
    #   exp(-rf) * E[max(L - x, 0)]
    # with exp(-rf) calculating the present values of the two, where rf is
    # the per-period riskless rate.

    # The first three methods implemented here focus on that observation.
    # The first method takes the simplification described above.  The second
    # uses the Black-Scholes option pricing as implemented in fOptions.  The
    # third uses the binomial pricing model from fOptions.  The second and
    # third methods are not implemented here.

    # The fourth method, "interp", creates a linear interpolation of the cdf of
    # returns, calculates Omega as a vector, and finally interpolates a function
    # for Omega as a function of L.

    # FUNCTION

    x = checkDataVector(R)

    if(method == "simple") {
        numerator = exp(-rf) * mean(max(x - L, 0))
        denominator = exp(-rf) * mean(max(L - x, 0))
        omega = numerator/denominator
    }

    if(method == "interp") {
    #

        a = min(x)
        b = max(x)

        xcdf = ecdf(x)
        f <- approxfun(xcdf$x,xcdf$y,method="linear",ties="ordered")

        if(output == "full") {
            omega = cumsum(1-f(xcdf$x))/cumsum(f(xcdf$x))
        }
        else {
        # returns only the point value for L
            # to get a point measure for omega, have to interpolate
            omegafull = cumsum(1-f(xcdf$x))/cumsum(f(xcdf$x)) # ????????
            g <- approxfun(xcdf$x,omegafull,method="linear",ties="ordered")
            omega = g(L)
        }
    }
    result = omega
    result

}

# ------------------------------------------------------------------------------

trackingError = function (R, Ri, scale = 12)
{ # @author Peter Carl

    # DESCRIPTION
    # trackingError = sqrt(sum(assetReturns.vec - indexReturns.vec)^2 /
    #                   (length(assetReturns.vec) - 1)) * sqrt(scale)

    # Inputs:
    # Outputs:

    # FUNCTION
    assetReturns.vec = checkDataVector(R)
    indexReturns.vec = checkDataVector(Ri)

    trackingError = sqrt(sum(assetReturns.vec - indexReturns.vec)^2 / (length(assetReturns.vec) - 1)) * sqrt(scale)

    trackingError

}

# ------------------------------------------------------------------------------

activePremium = function (R, Ri, scale = 12)
{ # @author Peter Carl

    # DESCRIPTION
    # activePremium = (annualizedReturn(assetReturns.vec, scale = scale) -
    #                  annualizedReturn(indexReturns.vec, scale = scale) )

    # Inputs:
    # Outputs:

    # FUNCTION
    assetReturns.vec = checkDataVector(R)
    indexReturns.vec = checkDataVector(Ri)

    activePremium = (annualizedReturn(assetReturns.vec, scale = scale) - annualizedReturn(indexReturns.vec, scale = scale))

    activePremium

}

# ------------------------------------------------------------------------------

informationRatio = function (R, Ri, scale = 12)
{ # @author Peter Carl

    # DESCRIPTION
    # informationRatio = activePremium/trackingError

    # Inputs:
    # Outputs:

    # FUNCTION
    assetReturns.vec = checkDataVector(R)
    indexReturns.vec = checkDataVector(Ri)

    activePremium = activePremium(assetReturns.vec,indexReturns.vec, scale = scale)
    trackingError = trackingError(assetReturns.vec,indexReturns.vec, scale = scale)

    informationRatio = activePremium/trackingError

    informationRatio
}

# ------------------------------------------------------------------------------
rollingStat = function (R, period = 3, trim = TRUE, FUN, ...)
{ # @author Peter Carl

    # DESCRIPTION
    # Function to apply any time series function over a rolling period,
    # say the last three months.  Pass in the function name as FUN,
    # e.g., FUN = "mean".  Useful for passing in several periods and functions
    # for comparing different series.

    # Inputs:
    # period  the number of periods over which to calculate the statistic.
    #         Setting the period to 0 calculates the statistic "from inception" or
    #         using all of the data passed in.
    # FUN     function to apply over e.g., FUN = "mean" or FUN = "cumulativeReturns"

    # Output:

    # FUNCTION

    x = checkDataVector(R)

    if (length(x) < period){
    # @todo: instead of stopping, should this warn and return NAs for length(x)?
        stop("Data set is not long enough. Reduce the evaluation period or provide a longer time period of data. Also, check the data for NA's.")
    }
    if (period == 0) {
        y = as.matrix(x[1:length(x)])
    }
    else
        y = as.matrix(x[(length(x)- period + 1):length(x)])
    answer=apply(y, MARGIN = 2, FUN = FUN, ...)
    return(answer)
    # Example includes how to pass in arguements to the function - must be in order:
    # > rollingStat(gg.ts at Data[,1],period=12,FUN="annualizedSharpeRatio",rf=.03/12)
    # [1] 1.476426
    # > rollingStat(gg.ts at Data[,1],period=3,FUN="annualizedSharpeRatio",rf=.03/12)
    # [1] 6.804358
    # > rollingStat(gg.ts at Data[,1],period=3,FUN="annualizedSharpeRatio",rf=0)
    # [1] 8.253612

}

# ------------------------------------------------------------------------------

cumulativeReturn = function (R, geometric = TRUE)
{ # @author Peter Carl

    # This is a useful function for calculating cumulative return over a period
    # of time, say a calendar year.  Can produce simple or geometric return.

    x = checkDataVector(R)

    if (!geometric)
        return(sum(x, na.rm = TRUE))
    else {
        return(prod(1+x, na.rm = TRUE)-1)
    }
}

# ------------------------------------------------------------------------------

colCumprods = function (R, na.rm = TRUE, ...)
{ # @author Peter Carl

    # if we do this, then cumulating a set of monthly returns is easy
    x = checkDataMatrix(R)

    if (na.rm) {
        result = apply(na.omit(x), MARGIN = 2, FUN = cumprod,
            ...)
    }
    else {
        result = apply(x, MARGIN = 2, FUN = cumprod, ...)
    }
    result
}

# ------------------------------------------------------------------------------

colCummax = function (R, na.rm = TRUE, ...)
{ # @author Peter Carl

    # to get to drawdown calculations, we need colCummax
    x = checkDataMatrix(R)

    if (na.rm) {
        result = apply(na.omit(x), MARGIN = 2, FUN = cummax,
            ...)
    }
    else {
        result = apply(x, MARGIN = 2, FUN = cummax, ...)
    }
    result
}

# ------------------------------------------------------------------------------

statsTable = function (R, metrics=c("mean","sd"), metricsNames=c("Average Return","Standard Deviation"), ...)
{ # @author Peter Carl

    # DESCRIPTION:
    # This function creates a table of statistics from vectors of functions and
    # labels passed in.  The resulting table is formatted such that metrics
    # are calculated separately for each column of returns in the data object.

    # Inputs:
    # Assumes an input of period returns.  Scale arguements can be used to
    # specify the number of observations during a year (e.g., 12 = monthly
    # returns).

    # Outputs:
    # A table with calculated metrics for each column

    # The idea here is to be able to pass in sets of metrics and values, like:

    # metrics = c(downsideDeviation(x,MAR=mean(x)), sd(subset(x,x>0)),
    # sd(subset(x,x<0)), downsideDeviation(x,MAR=MAR),
    # downsideDeviation(x,MAR=rf), downsideDeviation(x,MAR=0),maxDrawdown(x))

    # metricsNames = c("Semi Deviation", "Gain Deviation", "Loss Deviation",
    # paste("Downside Deviation (MAR=",MAR*scale*100,"%)", sep=""),
    # paste("Downside Deviation (rf=",rf*scale*100,"%)", sep=""),
    # paste("Downside Deviation (0%)", sep=""), "Maximum Drawdown" )

    # Here's how it's working right now:
    # > statsTable(monthlyReturns.ts,metrics=c("modifiedVaR","mean"),
    # metricsNames=c("modVaR","mean"),p=.95)
    #            Actual   S&P500TR
    # modVaR 0.04186461 0.06261451
    # mean   0.00945000 0.01013684

    # Passing in attributes doesn't quite work.  The issue is apparent in:
    # > statsTable(monthlyReturns.ts,metrics=c("modifiedVaR", "modifiedVaR"),
    #   metricsNames=c("Modified VaR","Traditional VaR"), modified=c(TRUE,FALSE))
    #                     Actual   S&P500TR
    # Modified VaR    0.06340849 0.09334976
    # Traditional VaR 0.06340849 0.09334976
    # Warning messages:
    # 1: the condition has length > 1 and only the first element will be used in: if (modified) {
    # 2: the condition has length > 1 and only the first element will be used in: if (modified) {
    # 3: the condition has length > 1 and only the first element will be used in: if (modified) {
    # 4: the condition has length > 1 and only the first element will be used in: if (modified) {

    # FUNCTION:

    y = checkDataMatrix(R)

    # for each column, do the following:
    for(column in 1:columns) {
#     x = as.vector(y[,column])
    x = as.matrix(y[,column])
    x.length = length(x)
    x = x[!is.na(x)]
    x.na = x.length - length(x)

        # apply the calculations
        values = vector('numeric', 0)
    for(metric in metrics) {
#        values = c(values,metric)
            # I'm not quite sure why this requires the as.matrix() coersion
            newvalue = apply(as.matrix(x), MARGIN = 2, FUN = metric, ...)
            values = c(values,newvalue)
        }

        if(column == 1) {
            resultingtable = data.frame(Value = values, row.names = metricsNames)
        }
        else {
            nextcolumn = data.frame(Value = values, row.names = metricsNames)
            resultingtable = cbind(resultingtable, nextcolumn)
        }
    }
    colnames(resultingtable) = columnnames
    resultingtable

}

# ------------------------------------------------------------------------------

rollingCorrelation = function (x, y, n, trim = TRUE, na.rm = FALSE, ...)
{# @author Peter Carl

    # DESCRIPTION:
    # This is a wrapper for providing n-period trailing correlations for the
    # data provided.  Inspired by rollFun() written by Diethelm Wurtz.

    # Specifically, we're wrapping the basic function cor(), which has:
    # function (x, y = NULL, use = "all.obs", method = c("pearson",
    #     "kendall", "spearman"))

    # Inputs:
    # Assumes an input of regular period returns.
    #    x: a numeric vector, matrix, data frame, or timeSeries.
    #       The resulting data frame will contain columns of cor(x,y)
    #       for each period.
    #
    #    y: 'NULL' (default) or a vector, matrix, data frame or timeSeries
    #       with compatible dimensions to 'x'.
    #
    #    Currently assumes that BOTH x and y are provided
    #    @todo: Make it so we can _either_ give a matrix or data frame
    #    for 'x' _or_ give both 'x' and 'y' (as in cov())
    #
    # Assumes that x and y are sequenced exactly the same and are regular.

    # Outputs:
    # A data.table of n-period trailing correlations for each column in y.

    # FUNCTION:

    # target.vec is the vector of data we want correlations for; we'll get it
    # from x
    target.vec = checkDataVector(x)
    xrows = nrow(x)
    rownames = rownames(x)

    # data.matrix is a vector or matrix of data we want correlations against;
    # we'll take it from y
    data.matrix = checkDataMatrix(y)
    columns=ncol(y)
    columnnames = colnames(y)

    if (!trim) {
        result.df = as.data.frame(matrix(data = NA, nrow = (n-1), ncol = columns, byrow = FALSE, dimnames = NULL))
        colnames(result.df) = columnnames
    }
    #  For each period (or row):
    for(row in n:xrows) {
        values = vector('numeric', 0)
        # Get the subset of returns on which to calulate correlation
        trailing.data = data.matrix[(row-n+1):row,]
        trailing.vec = target.vec[(row-n+1):row]

        # Calculate correlation
        values = cor(trailing.vec,trailing.data,...)

        if(row == n && trim) {
            result.df = data.frame(Value = values, row.names = rownames[n])
        }

        else {
            nextrow = data.frame(Value = values, row.names = rownames[row])
            colnames(nextrow) = columnnames
            result.df = rbind(result.df, nextrow)
        }
    }

    if (!trim) {
        rownames(result.df) = rownames
    }
    else
        rownames(result.df) = rownames(n:xrows)

    colnames(result.df) = columnnames

    result.df

    # Example:
    # > head(rollingCorrelation(manager.ts at Data[,1],edhec.ts at Data,n=12))
    #            Convertible Arbitrage CTA Global Distressed Securities
    # 2003-11-28             0.2591101  0.2762218             0.7516556
    # 2003-12-31             0.2162078  0.2477113             0.7452179
    # 2004-01-30             0.3918575  0.3489062             0.7562063
    # 2004-02-27             0.5331404  0.3905645             0.7088004
    # 2004-03-31             0.5730389  0.3010877             0.5694478
    # 2004-04-30             0.5146946  0.3762283             0.4374524
    #            Emerging Markets Equity Market Neutral Event Driven
    # 2003-11-28        0.6678183             0.4133534    0.6872263
    # 2003-12-31        0.7739188             0.3758590    0.8494740
    # 2004-01-30        0.7805586             0.4148372    0.8338275
    # 2004-02-27        0.7353874             0.3444552    0.8181069
    # 2004-03-31        0.7072259             0.2740104    0.6270411
    # 2004-04-30        0.4430823             0.3918143    0.4966760
    #            Fixed Income Arbitrage Funds of Funds Global Macro Long/Short Equity
    # 2003-11-28              0.6681346      0.7413791    0.5698372         0.4429661
    # 2003-12-31              0.6583804      0.7705968    0.5647109         0.6949394
    # 2004-01-30              0.7116529      0.7427369    0.5972492         0.6849833
    # 2004-02-27              0.7580839      0.6831231    0.6555057         0.6300653
    # 2004-03-31              0.7057303      0.6172516    0.6253257         0.5233462
    # 2004-04-30              0.7583853      0.5305704    0.6740996         0.3518156
    #            Merger Arbitrage Relative Value Short Selling
    # 2003-11-28        0.6890493      0.6858798   -0.23238159
    # 2003-12-31        0.7397387      0.8062422   -0.41123820
    # 2004-01-30        0.7219990      0.7883262   -0.36321115
    # 2004-02-27        0.6862517      0.7605837   -0.28807086
    # 2004-03-31        0.5921739      0.6766063   -0.24154960
    # 2004-04-30        0.5073817      0.5257858   -0.04663322

}

# ------------------------------------------------------------------------------

rollingFunction = function (R, n, trim = TRUE, na.rm = TRUE, firstcolumn = 1, digits = 4, rf = 0, FUN = "mean", ...)
{# @author Peter Carl

    # DESCRIPTION:
    # This is a wrapper for providing n-period trailing calculations for the
    # data and functions provided.

    # Inputs:
    # R: a matrix, data frame, or timeSeries of regular period returns.
    # n: the number of periods over which a function is to be calculated. Use
    #     the value zero (0) to roll the statistic from inception
    # FUN: the function to apply to the data
    # trim:
    # na.rm:
    # firstcolumn:
    # digits: number of decimal places to round the display to.

    # Outputs:
    # A data.table of n-period trailing calculations for each column
    # in x.

    # Inspired by rollFun() written by Diethelm Wurtz.  We've extended the idea
    # to all the columns provided.

    # FUNCTION:

    data.mat = checkDataMatrix(R)
    columns=ncol(data.mat)
    # @todo: remove NA's before setting column names
    columnnames = colnames(data.mat)
    # @todo: handle empty column names
    if(is.null(columnnames))
        stop("Column names are empty.  If you are trying to pass in a timeSeries, use seriesData() rather than the explicit @Data slot.")
    rows = nrow(data.mat)
    rownames = rownames(data.mat)

    if(rows < n)
        stop("Data set is too short. Select a shorter evaluation period or provide a longer time period.  Also, check the data for NA's.")

    # for each column, do the following:
    for(column in firstcolumn:columns) {
        valueNames = vector('character', 0)
        values = vector('numeric', 0)
    x = checkDataVector(data.mat[,column])

        if(n == 0) {
            period = 0
            n = 12
        }
        else
            period = n

        for(row in n:rows) {
            subperiod = x[1:row]
            values = c(values,rollingStat(subperiod, period = period, FUN = FUN, ...))
            valueNames = c(valueNames,rownames[row])
        }
        if (!trim) {
            values = c(rep(NA, (n - 1)), values)
            valueNames = c(rownames[1:n-1],valueNames)
        }
        if(column == 1) {
            resultingtable = data.frame(Value = values, row.names = valueNames)
        }

        else {
            nextcolumn = data.frame(Value = values, row.names = valueNames)
            resultingtable = cbind(resultingtable, nextcolumn)
        }
    }
    colnames(resultingtable) = columnnames
    result = round(resultingtable, digits)
    result

    # Examples:
    # > rollingFunction(gg.ts[,1],n=3,FUN="annualizedReturn")
    #                     Manager
    # 2002-02-28           0.0306
    # 2002-03-31           0.0521
    # 2002-04-30           0.0387
    # ...
    # > rollingFunction(gg.ts[,1],n=3,trim=FALSE,FUN="annualizedReturn")
    #                     Manager
    # 2001-12-31               NA
    # 2002-01-31               NA
    # 2002-02-28           0.0306
    # 2002-03-31           0.0521
    # 2002-04-30           0.0387
    # ...
    # > rollingFunction(gg.ts[,1],n=3,trim=FALSE,FUN="annualizedSharpeRatio")
    #                     Manager
    # 2001-12-31               NA
    # 2002-01-31               NA
    # 2002-02-28           1.5302
    # 2002-03-31           4.3768
    # 2002-04-30           6.9640
    # ...
    # > rollingFunction(gg.ts[,1],n=3,trim=FALSE,FUN="annualizedSharpeRatio",rf=.03/12)
    #                     Manager
    # 2001-12-31               NA
    # 2002-01-31               NA
    # 2002-02-28           0.0298
    # 2002-03-31           1.8587
    # 2002-04-30           1.5598
    # ...
}

# ------------------------------------------------------------------------------


rollingRegression <- function(formula, data, width, ...)
{# @author Douglas Bates
 # @author modified by Peter Carl

    # DESCRIPTION:
    # This code was posted to the R-help mailing list in response to a question
    # posted by Ajay Shah.  For the full discussion, see:
    # http://www.mail-archive.com/r-help at stat.math.ethz.ch/msg19544.html

    # @todo: make inputs consistant with other functions

    mCall = match.call()
    mCall$width = NULL
    mCall[[1]] = as.name("lm")
    mCall$x = mCall$y = TRUE # now mCall contains lm(y = TRUE, x = TRUE)
    bigfit = eval(mCall, parent.frame())
    ncoef = length(coef(bigfit))
    nr = nrow(data)
    width = as.integer(width)[1]
    stopifnot(width >= ncoef, width <= nr)
    y = bigfit$y
    x = bigfit$x
    terms = bigfit$terms
    inds = embed(seq(nr), width)[, rev(seq(width))]
    sumrys <- lapply(seq(nrow(inds)),
        function(st) {
            ind = inds[st,]
            fit = lm.fit(x[ind, , drop = FALSE], y[ind])
            fit$terms = terms
            class(fit) = "lm"
            summary(fit)
        })
    list(coefficients = sapply(sumrys, function(sm) coef(sm)[,"Estimate"]),
        Std.Error = sapply(sumrys, function(sm) coef(sm)[,"Std. Error"]),
        sigma = sapply(sumrys, "[[", "sigma"),
        r.squared = sapply(sumrys, "[[", "r.squared"))
}

# ------------------------------------------------------------------------------

################################################################################
# $Log: performance-analytics.R,v $
# Revision 1.36  2006/12/09 15:26:08  brian
# - clean up function comments some more in advance of public release
# Bug 128
#
# Revision 1.35  2006/12/06 15:07:41  brian
# - add todo items for Herfindahl, Geltner, and runs
# - remove stub notation on Sortino
# Bug 128
#
# Revision 1.34  2006/12/06 03:39:08  brian
# - add Sortino function modified from  Sankalp Upadhyay
#
# Revision 1.33  2006/12/05 21:52:32  brian
# - add modSharpe fn
# - update function list to show all functions in file
# - update copyright
# - fix indentation
# Bug 128
#
# Revision 1.32  2006/11/17 21:18:18  peter
# - added rf option to rollingFunction
#
# Revision 1.31  2006/11/07 03:36:12  peter
# - added informationRatio, trackingError, and activePremium function
#
# Revision 1.30  2006/10/31 03:58:11  peter
# - added function for rollingRegression
#
# Revision 1.29  2006/10/19 14:58:13  peter
# - fixed an issue with single-point calculation in rollingFunction when using n=0
#
# Revision 1.28  2006/10/19 13:45:53  peter
# - added "trim" option to rollingCorrelation
#
# Revision 1.27  2006/10/19 02:00:21  peter
# - rollingFunction with n=0 will trim first 12 observations
#
# Revision 1.26  2006/10/19 01:36:41  peter
# - rollingFunction now calculates statistics "from inception"
#
# Revision 1.25  2006/10/17 04:36:35  peter
# - minor modifications to rollingCorrelations function
#
# Revision 1.24  2006/10/10 04:39:48  peter
# - reverted back from na.contiguous to na.omit; not working for single column in matrix
#
# Revision 1.23  2006/10/09 13:59:37  peter
# - replaced na.omit with na.contiguous to retain time series nature of data in
# checkDataMatrix when na.rm = T
#
# Revision 1.22  2006/10/09 13:53:56  peter
# - added na.omit to dataCheckMatrix to ensure complete data sets for particular
# calculations
#
# Revision 1.21  2006/10/07 03:24:42  peter
# - improved NA handling in checkDataVector
# - added NA removal to some calculations, no longer needed
#
# Revision 1.20  2006/10/05 01:13:25  peter
# - rollingStat now passes arguements to functions with parameters
# - added a trim option to rollingFunction for lining up data in charts
#
# Revision 1.19  2006/10/04 14:13:55  peter
# - minor cleanup on RollingFunction
#
# Revision 1.18  2006/10/03 19:19:45  peter
# - fixed checkDataMatrix for the timeSeries case with missing column names
#
# Revision 1.17  2006/09/30 03:46:44  peter
# - fixed typo in annualizedSharpeRatio()
#
# Revision 1.16  2006/09/30 03:42:51  peter
# - finished applying data checks
# - fixed rollingFunction
#
# Revision 1.15  2006/09/30 00:54:21  peter
# - added checkDataVector() and applied to most calculations
#
# Revision 1.14  2006/09/29 14:19:19  peter
# - added fCalendar as an explicit required library
#
# Revision 1.13  2006/09/29 14:18:04  peter
# - fixed matrix case for checkDataMatrix
#
# Revision 1.12  2006/09/29 14:13:38  peter
# - added checkDataMatrix() to make data objects appear more fungible
#
# Revision 1.11  2006/09/28 14:53:40  peter
# - debugging rollingCorrelations(); x currently needs to be a matrix
#
# Revision 1.10  2006/09/26 21:56:55  brian
# - replace loud require directives with quiet requires
#
# Revision 1.9  2006/09/20 19:13:16  peter
# - repaired AnnualizedReturn call
#
# Revision 1.8  2006/09/20 19:08:54  peter
# - fixed annualizedSharpeRatio() calculation
#
# Revision 1.7  2006/09/20 17:08:44  peter
# Added rollingFunction() to calculate single-input metrics on a rolling period basis.
# Currently not working.
#
# Revision 1.6  2006/09/12 13:37:53  peter
# - snapshot 2006-09-11
#
# Revision 1.4  2006/09/12 13:09:50  brian
# - added omega function
# - snapshot 2006-08-26 v2
#
# Revision 1.3  2006/09/12 13:06:32  peter
# - snapshot 2006-08-23
#
# Revision 1.2  2006/09/12 12:56:39  peter
# - second revision snapshot 2006-08-17
#
# Revision 1.1 2006-09-12 07:46:18 peter
# - initial revision snapshot 2006-08-16
# Bug 128
################################################################################

From birdandfish99 at gmail.com  Thu Dec 14 11:09:58 2006
From: birdandfish99 at gmail.com (Bird Fish)
Date: Thu, 14 Dec 2006 02:09:58 -0800
Subject: [R-SIG-Finance] implied volatility of American Put
Message-ID: <3f6db1e70612140209l1110441fm746d665725820b57@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061214/a14c5320/attachment.pl 

From michaelbarber at gmail.com  Fri Dec 15 07:09:27 2006
From: michaelbarber at gmail.com (Michael Barber)
Date: Fri, 15 Dec 2006 08:09:27 +0200
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 31, Issue 7
In-Reply-To: <mailman.16.1166094006.5402.r-sig-finance@stat.math.ethz.ch>
References: <mailman.16.1166094006.5402.r-sig-finance@stat.math.ethz.ch>
Message-ID: <98afbab40612142209k33663d68k5138cf23d4c5c554@mail.gmail.com>

On 12/14/06, r-sig-finance-request at stat.math.ethz.ch
<r-sig-finance-request at stat.math.ethz.ch> wrote:
> Send R-SIG-Finance mailing list submissions to
> 	r-sig-finance at stat.math.ethz.ch
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> or, via email, send a message with subject or body 'help' to
> 	r-sig-finance-request at stat.math.ethz.ch
>
> You can reach the person managing the list at
> 	r-sig-finance-owner at stat.math.ethz.ch
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-SIG-Finance digest..."
>
>


From emmanuel.leclercq at epfl.ch  Tue Dec 12 16:01:43 2006
From: emmanuel.leclercq at epfl.ch (EMMANUEL LECLERCQ)
Date: Tue, 12 Dec 2006 16:01:43 +0100
Subject: [R-SIG-Finance] Anderson-Darling test for stable law
Message-ID: <5554c53685.536855554c@imap.epfl.ch>

Hello everybody,

I would like to apply the anderson-darling test in order to determine 
if my data follows a stable law.
I cannot find table of critical values for the stable distribution. 
Does anyone know if it's possible to do it with R ?

Thanks
Emmanuel


From Achim.Zeileis at R-project.org  Thu Dec 21 21:03:21 2006
From: Achim.Zeileis at R-project.org (Achim Zeileis)
Date: Thu, 21 Dec 2006 21:03:21 +0100
Subject: [R-SIG-Finance] Workshop: Computational and Financial Econometrics
Message-ID: <20061221210321.eded137c.Achim.Zeileis@R-project.org>

Dear useRs,

CSDA and ERCIM jointly organize the workshop

  Computational and Financial Econometrics
  April 20-22, 2007
  University of Geneva, Switzerland
  http://www.csdassn.org/europe/CFE07/

In this workshop, I'm organizing a session on 
  Computational Econometrics and Finance in R
which should also reflect the activities on this mailing list and I
would be happy if many of you would consider attending the workshop or
(even better) giving a presentation. If you are interested in
presenting in this session, please let me know in an informal mail. The
official call for papers along with further details on the organization
can be found at the above URL.

Best wishes,
Z


From bbands at gmail.com  Wed Dec 27 20:45:48 2006
From: bbands at gmail.com (BBands)
Date: Wed, 27 Dec 2006 11:45:48 -0800
Subject: [R-SIG-Finance] semi variance
Message-ID: <6e8360ad0612271145v38db0034nd332fefeecd096da@mail.gmail.com>

Has anyone here had any experience with semi variance and its kin
outside of VaR?

    jab
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.


From brian at braverock.com  Thu Dec 28 00:58:54 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 27 Dec 2006 17:58:54 -0600
Subject: [R-SIG-Finance] semi variance
In-Reply-To: <6e8360ad0612271145v38db0034nd332fefeecd096da@mail.gmail.com>
References: <6e8360ad0612271145v38db0034nd332fefeecd096da@mail.gmail.com>
Message-ID: <200612271758.54373.brian@braverock.com>

On Wednesday 27 December 2006 13:45, BBands wrote:
> Has anyone here had any experience with semi variance and its kin
> outside of VaR?

We implemented semideviation and downside deviation here:

https://stat.ethz.ch/pipermail/r-sig-finance/2006q4/001170.html

But perhaps you could be a bit more specific about what you're looking 
for?

Regards,

   - Brian


From kriskumar at earthlink.net  Thu Dec 28 03:09:47 2006
From: kriskumar at earthlink.net (Krishna Kumar)
Date: Wed, 27 Dec 2006 21:09:47 -0500
Subject: [R-SIG-Finance] semi variance
In-Reply-To: <6e8360ad0612271145v38db0034nd332fefeecd096da@mail.gmail.com>
References: <6e8360ad0612271145v38db0034nd332fefeecd096da@mail.gmail.com>
Message-ID: <4593276B.8040004@earthlink.net>

BBands wrote:
> Has anyone here had any experience with semi variance and its kin
> outside of VaR?
>
>     jab
>   
Well this gets used in optimization. There is also another performance 
measure the ratio of
upside variance to downside variance which is popular as well.

Best,
Kris


From brian at braverock.com  Thu Dec 28 04:15:21 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 27 Dec 2006 21:15:21 -0600
Subject: [R-SIG-Finance] semi variance
In-Reply-To: <4593276B.8040004@earthlink.net>
References: <6e8360ad0612271145v38db0034nd332fefeecd096da@mail.gmail.com>
	<4593276B.8040004@earthlink.net>
Message-ID: <200612272115.21765.brian@braverock.com>

On Wednesday 27 December 2006 20:09, Krishna Kumar wrote:
> BBands wrote:
> > Has anyone here had any experience with semi variance and its kin
> > outside of VaR?
> >
> >     jab
>
> Well this gets used in optimization. There is also another performance
> measure the ratio of
> upside variance to downside variance which is popular as well.

I've seen implementations of mean-semivariance optimization using the same 
quadratic methods as Markowitz mean-variance optimization?  I seem to 
recall reading a paper that used a semivariance/semicovariance matrix as 
well.
There's also a generalized semivariance optimization method discussed in 
Chapter 5 of 
Bernd Scherer, R. Douglas Martin
Introduction To Modern Portfolio Optimization With NUOPT And S-PLUS 

Regards,

   - Brian


From jtl at saxobank.com  Thu Dec 28 14:46:38 2006
From: jtl at saxobank.com (Jeffrey Todd Lins)
Date: Thu, 28 Dec 2006 14:46:38 +0100
Subject: [R-SIG-Finance] semi variance
In-Reply-To: <4593276B.8040004@earthlink.net>
Message-ID: <F9E56E6FA5761145BE9CCF5EE386D5F002AA5FB3@malmb2-s3.mid.dom>

Just on a related tangent, here is an interesting paper, "On the Maximum
Drawdown of a Brownian Motion",
http://alumnus.caltech.edu/~amir/drawdown-jrnl.pdf .

There was also an interesting article by the same authors in Risk,
w.r.t. intertemporal scaling and use in optimization:

 http://alumnus.caltech.edu/~amir/mdd-risk.pdf

Jeffrey Lins 

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Krishna
Kumar
Sent: Thursday, December 28, 2006 3:10 AM
To: BBands
Cc: R-sig-finance
Subject: Re: [R-SIG-Finance] semi variance

BBands wrote:
> Has anyone here had any experience with semi variance and its kin 
> outside of VaR?
>
>     jab
>   
Well this gets used in optimization. There is also another performance
measure the ratio of upside variance to downside variance which is
popular as well.

Best,
Kris

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance

This email may contain confidential and/or privileged inform...{{dropped}}


From bbands at gmail.com  Thu Dec 28 16:36:27 2006
From: bbands at gmail.com (BBands)
Date: Thu, 28 Dec 2006 07:36:27 -0800
Subject: [R-SIG-Finance] semi variance
In-Reply-To: <200612271758.54373.brian@braverock.com>
References: <6e8360ad0612271145v38db0034nd332fefeecd096da@mail.gmail.com>
	<200612271758.54373.brian@braverock.com>
Message-ID: <6e8360ad0612280736va7fa2f3w1e731f3e26d5da61@mail.gmail.com>

On 12/27/06, Brian G. Peterson <brian at braverock.com> wrote:
> We implemented semideviation and downside deviation here:
>
> https://stat.ethz.ch/pipermail/r-sig-finance/2006q4/001170.html

Yes, I saw that package. Very useful. Thank you.

> But perhaps you could be a bit more specific
> about what you're looking for?

OK. I first tackled this general area 10 years ago when I created
www.EquityTrader.com, which presents positive and negative alphas and
betas, a very popular feature. While doing some recent portfolio work
I revisited my "semi" alpha and betas and considered some related
ideas. The "semis" seem to have become popular, so I thought I'd ask
this august group if anybody was doing anything "interesting" with
them.

    jab
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.


From brian at braverock.com  Thu Dec 28 17:20:00 2006
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 28 Dec 2006 10:20:00 -0600
Subject: [R-SIG-Finance] semi variance
In-Reply-To: <6e8360ad0612280736va7fa2f3w1e731f3e26d5da61@mail.gmail.com>
References: <6e8360ad0612271145v38db0034nd332fefeecd096da@mail.gmail.com>
	<200612271758.54373.brian@braverock.com>
	<6e8360ad0612280736va7fa2f3w1e731f3e26d5da61@mail.gmail.com>
Message-ID: <200612281020.00304.brian@braverock.com>

On Thursday 28 December 2006 09:36, BBands wrote:
> On 12/27/06, Brian G. Peterson <brian at braverock.com> wrote:
> > We implemented semideviation and downside deviation here:
> >
> > https://stat.ethz.ch/pipermail/r-sig-finance/2006q4/001170.html
>
> Yes, I saw that package. Very useful. Thank you.
>
> > But perhaps you could be a bit more specific
> > about what you're looking for?
>
> OK. I first tackled this general area 10 years ago when I created
> www.EquityTrader.com, which presents positive and negative alphas and
> betas, a very popular feature. While doing some recent portfolio work
> I revisited my "semi" alpha and betas and considered some related
> ideas. The "semis" seem to have become popular, so I thought I'd ask
> this august group if anybody was doing anything "interesting" with
> them.

Kris an I both discussed use of semi-variance in optimization in other 
replies to your query.  I've found these approaches to be somewhat useful 
as part of the portfolio optimization problem.

In general, I've gotten more "signal" from higher moments (skew, kurtosis) 
than from the broader area of lower partial moments.  That said, depth 
and length of drawdowns (and upside runs) does seem to have some 
information content for some instruments.

Regards,

   - Brian


From jtl at saxobank.com  Fri Dec 29 12:00:56 2006
From: jtl at saxobank.com (Jeffrey Todd Lins)
Date: Fri, 29 Dec 2006 12:00:56 +0100
Subject: [R-SIG-Finance]  Incremental and Component VaR
Message-ID: <F9E56E6FA5761145BE9CCF5EE386D5F002AA5FC5@malmb2-s3.mid.dom>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20061229/afc01fd1/attachment.pl 

From kriskumar at earthlink.net  Fri Dec 29 13:16:34 2006
From: kriskumar at earthlink.net (Krishna Kumar)
Date: Fri, 29 Dec 2006 07:16:34 -0500
Subject: [R-SIG-Finance] semi variance
In-Reply-To: <F9E56E6FA5761145BE9CCF5EE386D5F002AA5FB3@malmb2-s3.mid.dom>
References: <F9E56E6FA5761145BE9CCF5EE386D5F002AA5FB3@malmb2-s3.mid.dom>
Message-ID: <45950722.1070004@earthlink.net>

Jeffrey Todd Lins wrote:
> Just on a related tangent, here is an interesting paper, "On the Maximum
> Drawdown of a Brownian Motion",
> http://alumnus.caltech.edu/~amir/drawdown-jrnl.pdf .
>
> There was also an interesting article by the same authors in Risk,
> w.r.t. intertemporal scaling and use in optimization:
>
>  http://alumnus.caltech.edu/~amir/mdd-risk.pdf
>
> Jeffrey Lins 
>   
By the way the package fOptions has a set of utils to do cdf, density, 
rng etc from the drawdown distribution with no drift.
And the original Amir Atiya paper actually seems to give a series 
solution for the drawdown distribution for the
general case of a GBM with drift.


