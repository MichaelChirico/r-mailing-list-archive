From kabonline07 at yahoo.com  Fri Jan  1 09:56:10 2010
From: kabonline07 at yahoo.com (KAUSHIK BHATTACHARJEE)
Date: Fri, 1 Jan 2010 00:56:10 -0800 (PST)
Subject: [R-SIG-Finance] Which one is better?
Message-ID: <32849.66090.qm@web110013.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100101/ddb2ba9e/attachment.pl>

From matthieu.stigler at gmail.com  Fri Jan  1 11:50:28 2010
From: matthieu.stigler at gmail.com (mat)
Date: Fri, 01 Jan 2010 11:50:28 +0100
Subject: [R-SIG-Finance] Which one is better?
In-Reply-To: <32849.66090.qm@web110013.mail.gq1.yahoo.com>
References: <32849.66090.qm@web110013.mail.gq1.yahoo.com>
Message-ID: <4B3DD374.7000707@gmail.com>

KAUSHIK BHATTACHARJEE a ?crit :
> I have some time series .more than 1000 observations each ..I want to test if  they contain unit roots...
> I am performing ADF as well as  KPSS tests...I am getting contraditory results in 7 out of 10 series....KPSS test is rejecting stationarity where as ADF test is not....
> Which one is more reliable test...any idea/reference?
>  
>   
any reference? Yes, the paper of KPSS! It is not too technical and in 
the empirical part they discuss this issue of contradictory results with 
unit roots tests (if I remember well there are five cases from the 
Nelson Plosser data were KPSS is different than ADF, so that's a known 
issue:-).

I would rather base on a unit root test (btw rather ERS than ADF) as the 
KPSS test is rather considered as a "confirmatory test". Base on unit 
root tests especially when both tests are rejected, as unit root tests 
are known to have low power and rejection is then a pretty "big sign". 
But note that their size is not so good neither, while KPSS can have 
really big size distortions, try yourself:

library(urca)

simul.cval<-function(ar, n=100){
  series<-arima.sim(model=list(ar=ar), n=n)
  summary(ur.kpss(series, use.lag=1))@teststat
}

mc<-replicate(500, simul.cval(ar=0.2))
mean(mc>  0.463)

mc<-replicate(500, simul.cval(ar=0.9))
mean(mc>  0.463)

Hope this helps

Mat
> Kaushik Bhattacharjee
>
>
>
>       
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From patrick at burns-stat.com  Fri Jan  1 12:53:18 2010
From: patrick at burns-stat.com (Patrick Burns)
Date: Fri, 01 Jan 2010 11:53:18 +0000
Subject: [R-SIG-Finance] Which one is better?
In-Reply-To: <4B3DD374.7000707@gmail.com>
References: <32849.66090.qm@web110013.mail.gq1.yahoo.com>
	<4B3DD374.7000707@gmail.com>
Message-ID: <4B3DE22E.6050309@burns-stat.com>

I suspect this is asking the wrong question
of the data.  I don't know what the right
questions are, but they should be in the
direction of where ever you want to go.

mat wrote:
> KAUSHIK BHATTACHARJEE a ?crit :
>> I have some time series .more than 1000 observations each ..I want to 
>> test if  they contain unit roots...
>> I am performing ADF as well as  KPSS tests...I am getting contraditory 
>> results in 7 out of 10 series....KPSS test is rejecting stationarity 
>> where as ADF test is not....
>> Which one is more reliable test...any idea/reference?
>>  
>>   
> any reference? Yes, the paper of KPSS! It is not too technical and in 
> the empirical part they discuss this issue of contradictory results with 
> unit roots tests (if I remember well there are five cases from the 
> Nelson Plosser data were KPSS is different than ADF, so that's a known 
> issue:-).
> 
> I would rather base on a unit root test (btw rather ERS than ADF) as the 
> KPSS test is rather considered as a "confirmatory test". Base on unit 
> root tests especially when both tests are rejected, as unit root tests 
> are known to have low power and rejection is then a pretty "big sign". 
> But note that their size is not so good neither, while KPSS can have 
> really big size distortions, try yourself:
> 
> library(urca)
> 
> simul.cval<-function(ar, n=100){
>  series<-arima.sim(model=list(ar=ar), n=n)
>  summary(ur.kpss(series, use.lag=1))@teststat
> }
> 
> mc<-replicate(500, simul.cval(ar=0.2))
> mean(mc>  0.463)
> 
> mc<-replicate(500, simul.cval(ar=0.9))
> mean(mc>  0.463)
> 
> Hope this helps
> 
> Mat
>> Kaushik Bhattacharjee
>>
>>
>>
>>           [[alternative HTML version deleted]]
>>
>>   
>> ------------------------------------------------------------------------
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R 
>> questions should go.
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions 
> should go.
> 
>


From frainj at tcd.ie  Fri Jan  1 13:42:55 2010
From: frainj at tcd.ie (John Frain)
Date: Fri, 1 Jan 2010 12:42:55 +0000
Subject: [R-SIG-Finance] Which one is better?
In-Reply-To: <32849.66090.qm@web110013.mail.gq1.yahoo.com>
References: <32849.66090.qm@web110013.mail.gq1.yahoo.com>
Message-ID: <cfdde1651001010442l463e40ffwfb576bfa9dea4a3e@mail.gmail.com>

Without knowing something about the nature of your data and the
purpose of your analysis this is a hard question to answer.  Do you
have an underlying theory agout the behaviour of your series?   If
that theory implies a unit root then and ADF type test (probably an
ERS test, as recommended by Mat)  is an appropriate choice.  If theory
says that the series is stationary then the KPSS test is an
appropriate test of the null of stationarity.  There are, of course,
non-stationary series that do not have a unit root.  It is nice if ADF
and KPSS tests lead to the same conclusion but there is no
contradiction if this does not happen.

Maddala and Kim (1998), Unit Roots Cointegration and Structural
Change, Cambridge University Press, is a good suvey of the theory of
unit roots etc.

Leybourne and McCabe (1989) shows how certain revisions to the KPSS
test can make the results of the ADF and KPSS test more consistent.

John




2010/1/1 KAUSHIK BHATTACHARJEE <kabonline07 at yahoo.com>:
> I have some time series .more than 1000 observations each ..I want to test if ?they contain unit roots...
> I am performing ADF as well?as ?KPSS tests...I am getting contraditory results in 7 out of 10 series....KPSS test is rejecting stationarity where as ADF test is not....
> Which one is more reliable test...any idea/reference?
>
> Kaushik Bhattacharjee
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
John C Frain, Ph.D.
Trinity College Dublin
Dublin 2
Ireland
www.tcd.ie/Economics/staff/frainj/home.htm
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


From rvince99 at earthlink.net  Sat Jan  2 15:49:31 2010
From: rvince99 at earthlink.net (R. Vince)
Date: Sat, 2 Jan 2010 09:49:31 -0500
Subject: [R-SIG-Finance] Brazilian Equities
Message-ID: <15058A262EEB497A8B772C88F4BB70FC@XP1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100102/26e9eb2a/attachment.pl>

From josh.m.ulrich at gmail.com  Sat Jan  2 17:36:24 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 2 Jan 2010 10:36:24 -0600
Subject: [R-SIG-Finance] Brazilian Equities
In-Reply-To: <15058A262EEB497A8B772C88F4BB70FC@XP1>
References: <15058A262EEB497A8B772C88F4BB70FC@XP1>
Message-ID: <8cca69991001020836u54ebd511jdfb637ae8d9d26f9@mail.gmail.com>

Ralph,

I found 25 of the 30 symbols on Yahoo Finance by appending ".SA" to
the end of each ticker.  You can find the Yahoo exchange suffixes
here: http://finance.yahoo.com/exchanges.  The remaining 5 do not seem
to have historical data on Yahoo, but I didn't check all of them.

To get 25, I had to change the "yahoo.URL" object in
quantmod::getSymbols.yahoo.  You can do this via the
fixInNamespace(getSymbols.yahoo,"quantmod") command.

I changed it from
yahoo.URL <- "http://chart.yahoo.com/table.csv?"
to
yahoo.URL <- "http://ichart.yahoo.com/table.csv?"

HTH,
Josh
--
http://blog.fosstrading.com



On Sat, Jan 2, 2010 at 8:49 AM, R. Vince <rvince99 at earthlink.net> wrote:
> If I have quantmod loaded, is there a source I can go to for Brazilian
> equities prices, as traded in Sao Paulo? In particular, I am looking for the
> following equities, and their corresponding symbols (as I have them) :
>
> (stock ?: symbol)
> FOSF?RTIL : FFTL4
> ABC BANCO ?: ABCB4
> BMF BOVESPA ?: ?BVMF3
> PORTO SEGURO ?: ?PSSA3
> ROSSI ?: ?RSID3
> CYRELA ?: ?CYRE3
> DURATEX ?: ?DTEX3
> MRV ?: ?MRVE3
> PDG REALTY ?: ?PDRG3
> GAFISA ?: ?GFSA3
> CONFAB ?: ?CFNB4
> LUPATECH ?: ?LUPA3
> PLASCAR ?: ?PLAS3
> MARCOPOLO ?: ?POMO4
> WEGE ?: ?WEGE3
> AM?RICA LATINA LOG?STICA ?: ?ALLL11
> VALE ?: ?VALE5
> MMX ? : ?MMXM3
> OGX PETR?LEO ?: ?OGXP3
> PETROBRAS ? PETR4
> DASA ? DASA3
> SIDERURGICA NACIONAL ?: ?CSNA3
> GERDAU ? : ?GGBR4
> USIMINAS ? USIM5
> TOTS ?: ?TOTS3
> B 2 W ?: ?BTOW3
> HYPERMARCAS ?: ?HYPE3
> LOJAS AMERICANAS ? : ?LAME4
> LOJAS RENNER ?: ?LREN3
> LOCALIZA ? : ?RENT3
>
> Thanks, R. Vince
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From edd at debian.org  Sat Jan  2 18:58:04 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 2 Jan 2010 11:58:04 -0600
Subject: [R-SIG-Finance] Brazilian Equities
In-Reply-To: <8cca69991001020836u54ebd511jdfb637ae8d9d26f9@mail.gmail.com>
References: <15058A262EEB497A8B772C88F4BB70FC@XP1>
	<8cca69991001020836u54ebd511jdfb637ae8d9d26f9@mail.gmail.com>
Message-ID: <19263.35116.624020.401212@ron.nulle.part>


On 2 January 2010 at 10:36, Joshua Ulrich wrote:
| To get 25, I had to change the "yahoo.URL" object in
| quantmod::getSymbols.yahoo.  You can do this via the
| fixInNamespace(getSymbols.yahoo,"quantmod") command.
| 
| I changed it from
| yahoo.URL <- "http://chart.yahoo.com/table.csv?"
| to
| yahoo.URL <- "http://ichart.yahoo.com/table.csv?"

That is interesting topic. A bit over a decade ago, I became CPAN maintainer
of Finance::YahooQuote as two of my (then current, now almost stale :) Perl
projects use it to acquire current data.  Over the years, but more so in the
beginning, I had to make a number of adjustments to the URL that Yahoo uses,
often with explicit if/else or switches based on ticker extension
("country").  But as I said, that is for _current_ data.

For historical data, I never got around to releasing the accessor as a
standalone module and the functionality is hidden within the Beancounter
code. There I use "http://table.finance.yahoo.com/table.csv?" as the base URL
and that has worked fairly reliably for all historical equity data I (or
other users) have tried to retrieve.  FX is a different story, and so are
other asset classes they don't even cover.  But that interface has been much
stabler

If you're into Perl, the function is 

sub GetHistoricalData {         # get a batch of historical quotes from Yahoo!
  my ($symbol,$from,$to) = @_;
  my $ua = RequestAgent->new;
  $ua->env_proxy;               # proxy settings from *_proxy env. variables.
  $ua->proxy('http', $Config{proxy}) if $Config{proxy};  # or config vars
  my ($a,$b,$c,$d,$e,$f);       # we need the date as yyyy, mm and dd
  ($c,$a,$b) = ($from =~ m/(\d\d\d\d)(\d\d)(\d\d)/);
  ($f,$d,$e) = ($to =~ m/(\d\d\d\d)(\d\d)(\d\d)/);
  --$a; --$d; # month is zero-based
  my $req = new HTTP::Request GET => "http://table.finance.yahoo.com/" .
    "table.csv?a=$a&b=$b&c=$c&d=$d&e=$e&f=$f&s=$symbol&y=0&g=d&ignore=.csv";
  my $res = $ua->request($req);  # Pass request to user agent and get response
  if ($res->is_success) {       # Check the outcome of the response
    return split(/\n/, $res->content);
  } else {
    warn "No luck with symbol $symbol\n";
  }
}

One of these days I sit down and rewrite all of Beancounter in R....  But
I've been saying that for a few years and haven't done it yet so don't hold
your breath.

Anyway, to prove Josh's point, you can 'hand-translate' this into a R request
for, say, Petrobas:

R> X <- read.csv("http://table.finance.yahoo.com/table.csv?a=2009&b=01&c=01&d=2009&e=01e&f=01&s=PETR4.SA&y=0&g=d&ignore=.csv", header=TRUE)
R> head(X)
        Date  Open  High   Low Close   Volume Adj.Close
1 2009-12-30 36.57 36.69 36.35 36.69 13901400     36.69
2 2009-12-29 36.89 36.94 36.65 36.80  5198500     36.80
3 2009-12-28 36.91 37.00 36.63 36.75  9099900     36.75
4 2009-12-23 36.50 36.76 36.15 36.70 11004500     36.70
5 2009-12-22 35.73 36.34 35.60 36.34 15008900     36.34
6 2009-12-21 36.80 36.85 35.20 35.20 20905000     35.20
R>

It's too bad that Yahoo! doesn't simply declare this a public interface and
document it so that we have to poke in the dark for the best URL...

Dirk

PS Beancounter lives at http://dirk.eddelbuettel.com/code/beancounter.html

-- 
Three out of two people have difficulties with fractions.


From gero.schwenk at web.de  Sun Jan  3 14:01:06 2010
From: gero.schwenk at web.de (Gero Schwenk)
Date: Sun, 03 Jan 2010 14:01:06 +0100
Subject: [R-SIG-Finance] Stability of trading models
Message-ID: <4B409512.2030109@web.de>

Hello together!
I've got a question regarding the assessment of stability of trading 
models. Here's a short intro to the background:

I have fitted regression models with lagged independent variables to 
data of daily stock returns. (The model methodology was MARS, allowing 
for  second order interaction terms.) The independent variables had been 
selected on basis of explorative clustering and correlation studies and 
showed face validity. I used both logit and gaussian link functions and 
generated out-of-sample predictions for a test window of two months (40+ 
observations, following the training window in time), which were of 
reasonable to really satisfying quality, depending on the exact model.

In order to assess the stability of out-of-sample fit of a given model, 
I would normally draw cross-validation samples and partition them into 
training- and test subsets. Grounds for this would be the assumption of 
independent observations contained in the model and forced onto the data 
by backshifting them.

However, I'm reluctant to believe that the data-generating process 
doesn't change over time, which is implied by my procedures. If this was 
true and time was not an issue, it should not be necessary to 
recalibrate the model, even after a long period of out-of-sample 
prediction. This seems overly optimistic to me.

Returning to the question of stability assessment and cross-validation, 
I would like to know if there is some pragmatic solution. Is simple 
cross-validation viable? Do I need to go far into the past using some 
possibly sliding training- and test-windows? Or has anybody a different 
suggestion how to deal with this problem in the realm of regression models?


Kind regards,
Gero


From brian at braverock.com  Sun Jan  3 14:16:44 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 03 Jan 2010 07:16:44 -0600
Subject: [R-SIG-Finance] Stability of trading models
In-Reply-To: <4B409512.2030109@web.de>
References: <4B409512.2030109@web.de>
Message-ID: <4B4098BC.8070808@braverock.com>

Gero Schwenk wrote:
> <... snip ...>
> In order to assess the stability of out-of-sample fit of a given 
> model, I would normally draw cross-validation samples and partition 
> them into training- and test subsets. Grounds for this would be the 
> assumption of independent observations contained in the model and 
> forced onto the data by backshifting them.
>
> However, I'm reluctant to believe that the data-generating process 
> doesn't change over time, which is implied by my procedures. If this 
> was true and time was not an issue, it should not be necessary to 
> recalibrate the model, even after a long period of out-of-sample 
> prediction. This seems overly optimistic to me.
>
> Returning to the question of stability assessment and 
> cross-validation, I would like to know if there is some pragmatic 
> solution. Is simple cross-validation viable? Do I need to go far into 
> the past using some possibly sliding training- and test-windows? Or 
> has anybody a different suggestion how to deal with this problem in 
> the realm of regression models?
While we would all like a perfectly stable model, the reality is usually different.

Since you've said that your model is regression-based, take a look at chart.RollingRegression.  This will let you see the stability of your regression model over different rolling windows.  I suggest checking longer, shorter, and from-inception windows.

>From there, you'll have a lot of information to refine your modeling/tuning approach.

I generally am dubious that financial time series or trading models are completely stable over long periods of time.

Cheers,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From rvince99 at earthlink.net  Sun Jan  3 20:01:02 2010
From: rvince99 at earthlink.net (R. Vince)
Date: Sun, 3 Jan 2010 14:01:02 -0500
Subject: [R-SIG-Finance] Simple Date Formatting
References: <15058A262EEB497A8B772C88F4BB70FC@XP1><8cca69991001020836u54ebd511jdfb637ae8d9d26f9@mail.gmail.com>
	<19263.35116.624020.401212@ron.nulle.part>
Message-ID: <33CB8C9636BB49CA949FB832BD5C5BEC@XP1>

Suppose I have a matrix, X, whose leftmost column is a date in the format:

2009-07-10

how do I alter it such that it is formatted as:

20090710

without using string manipulations? Surely there mist be a common means for 
doing this? Also, how can I remove the rightmost column of a matrix prior to 
doing a write.table() ? Thanks so much -RVince


From edd at debian.org  Sun Jan  3 20:36:03 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 3 Jan 2010 13:36:03 -0600
Subject: [R-SIG-Finance] Simple Date Formatting
In-Reply-To: <33CB8C9636BB49CA949FB832BD5C5BEC@XP1>
References: <15058A262EEB497A8B772C88F4BB70FC@XP1>
	<8cca69991001020836u54ebd511jdfb637ae8d9d26f9@mail.gmail.com>
	<19263.35116.624020.401212@ron.nulle.part>
	<33CB8C9636BB49CA949FB832BD5C5BEC@XP1>
Message-ID: <19264.61859.31102.90915@ron.nulle.part>


Ralph,

On 3 January 2010 at 14:01, R. Vince wrote:
| Suppose I have a matrix, X, whose leftmost column is a date in the format:
| 
| 2009-07-10
| 
| how do I alter it such that it is formatted as:
| 
| 20090710
| 
| without using string manipulations? Surely there mist be a common means for 
| doing this? Also, how can I remove the rightmost column of a matrix prior to 
| doing a write.table() ? Thanks so much -RVince

See 
    help(Date)
    help(strptime)
    help(DateTimeClasses)

In a nutshell, parse it as a Date, then tell the Date to format as you want
it.  

But you will get told the same as everybody else here: Non-Finance questions
belong to r-help. Thanks for adhering to the spirit of the list.

Regards,  Dirk

-- 
Three out of two people have difficulties with fractions.


From ggrothendieck at gmail.com  Sun Jan  3 21:08:20 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 3 Jan 2010 15:08:20 -0500
Subject: [R-SIG-Finance] Simple Date Formatting
In-Reply-To: <33CB8C9636BB49CA949FB832BD5C5BEC@XP1>
References: <15058A262EEB497A8B772C88F4BB70FC@XP1>
	<8cca69991001020836u54ebd511jdfb637ae8d9d26f9@mail.gmail.com> 
	<19263.35116.624020.401212@ron.nulle.part>
	<33CB8C9636BB49CA949FB832BD5C5BEC@XP1>
Message-ID: <971536df1001031208x7919dc9ax7498f6d90b3e7a34@mail.gmail.com>

If you truly have a matrix with one column being a date you are
starting off with the wrong class of object in the first place.  See
?read.zoo in the zoo package and the three vignettes (pdf documents)
that come with it.  You might also want to look at the xts package as
well.

On Sun, Jan 3, 2010 at 2:01 PM, R. Vince <rvince99 at earthlink.net> wrote:
> Suppose I have a matrix, X, whose leftmost column is a date in the format:
>
> 2009-07-10
>
> how do I alter it such that it is formatted as:
>
> 20090710
>
> without using string manipulations? Surely there mist be a common means for
> doing this? Also, how can I remove the rightmost column of a matrix prior to
> doing a write.table() ? Thanks so much -RVince


From mdelvaux at gmail.com  Tue Jan  5 05:38:53 2010
From: mdelvaux at gmail.com (Marc Delvaux)
Date: Mon, 4 Jan 2010 20:38:53 -0800
Subject: [R-SIG-Finance] NoVaS transformation
Message-ID: <a010cefd1001042038w20116e5fsd32a45b861fef367@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100104/37d74f11/attachment.pl>

From BChiquoine at tiff.org  Tue Jan  5 20:50:48 2010
From: BChiquoine at tiff.org (Chiquoine, Ben)
Date: Tue, 5 Jan 2010 14:50:48 -0500
Subject: [R-SIG-Finance] Portfolio Optimization Subject to Tracking Error
	Constraint
Message-ID: <E71E6D5B2274B341B26B6DF3D34D8028025D43CD@vsw3exch2.tiff.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100105/b009e9db/attachment.pl>

From robert at sanctumfi.com  Thu Jan  7 12:57:49 2010
From: robert at sanctumfi.com (Robert Sams)
Date: Thu, 7 Jan 2010 11:57:49 -0000
Subject: [R-SIG-Finance] Simple Date Formatting
References: <15058A262EEB497A8B772C88F4BB70FC@XP1><8cca69991001020836u54ebd511jdfb637ae8d9d26f9@mail.gmail.com><19263.35116.624020.401212@ron.nulle.part>
	<SANCTUMFISERVERqhvy00004545@sanctumfi.com>
Message-ID: <SANCTUMFISERVERotRZ000055ee@sanctumfi.com>

Ralph, as you want to store a "date" in a column of a matrix object, you
can't format a Date class as it will be coerced to class numeric. 

How about this solution?

> intDate <- function(x){
+   y <- as.POSIXlt(as.Date(x))
+   ((y$year + 1900) * 10000) + ((y$mon + 1) * 100) + y$mday
+ }
> 
> as.Date.intDate <- function(x, ...){
+   year <- trunc(x / 10000)
+   month <- trunc(x / 100) - year * 100
+   day <- x - trunc(x / 100) * 100
+   as.Date(ISOdate(year, month, day))
+ }
> 
> (x <- intDate("2009-07-10"))
[1] 20090710
> as.Date.intDate(x)
[1] "2009-07-10"
>

Robert
-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of R. Vince
Sent: 03 January 2010 19:01
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] Simple Date Formatting

Suppose I have a matrix, X, whose leftmost column is a date in the
format:

2009-07-10

how do I alter it such that it is formatted as:

20090710

without using string manipulations? Surely there mist be a common means
for 
doing this? Also, how can I remove the rightmost column of a matrix
prior to 
doing a write.table() ? Thanks so much -RVince

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From risk2009 at ath.forthnet.gr  Fri Jan  8 12:29:33 2010
From: risk2009 at ath.forthnet.gr (Research)
Date: Fri, 08 Jan 2010 13:29:33 +0200
Subject: [R-SIG-Finance] Downloading Real Time Data from FRED
	(fImport/fredSeries)
Message-ID: <4B47171D.5050908@ath.forthnet.gr>

Hi,

I was looking at the API for ALFRED:

    http://api.stlouisfed.org/docs/fred/realtime_period.html
    http://api.stlouisfed.org/docs/fred/series_release.html

ALFRED is like FRED but provides us with real-time data, i.e., data for 
macroeconomic variables as they were originaly announced (released) and 
not the revised (finalised) data which FRED contains. These are useful 
for real-time econometric applications.

I was wondering, how can one use the existing routines/packages that 
access FRED, to access ALFRED.

 From what I have checked so far,  the mnemonics appear to be the same 
on FRED and ALFRED for the same series (say PAYMES for non-farm payrolls).

Thanks in advance,
Costas_//_


From brian at braverock.com  Fri Jan  8 13:42:19 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 08 Jan 2010 06:42:19 -0600
Subject: [R-SIG-Finance] Downloading Real Time Data from
	FRED	(fImport/fredSeries)
In-Reply-To: <4B47171D.5050908@ath.forthnet.gr>
References: <4B47171D.5050908@ath.forthnet.gr>
Message-ID: <4B47282B.3090203@braverock.com>

Research wrote:
> Hi,
>
> I was looking at the API for ALFRED:
>
>    http://api.stlouisfed.org/docs/fred/realtime_period.html
>    http://api.stlouisfed.org/docs/fred/series_release.html
>
> ALFRED is like FRED but provides us with real-time data, i.e., data 
> for macroeconomic variables as they were originaly announced 
> (released) and not the revised (finalised) data which FRED contains. 
> These are useful for real-time econometric applications.
>
> I was wondering, how can one use the existing routines/packages that 
> access FRED, to access ALFRED.
>
> From what I have checked so far,  the mnemonics appear to be the same 
> on FRED and ALFRED for the same series (say PAYMES for non-farm 
> payrolls).

I haven't used the fImport function, but quantmod has a similar 
function, so I'll use that in my examople on modifying, the details 
should be quite similar.

look at function:

getSymbols.FRED

copy this to function getSymbols.ALFRED

modify it to include a parameter for the api key, or better yet register 
one for the project. 

then modify the line starting with download.file to reflect the new 
required URL. While the Symbol may be the same, the url is clearly different

test and share with the community

Regards,
 
  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From brian at braverock.com  Fri Jan  8 14:14:41 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 08 Jan 2010 07:14:41 -0600
Subject: [R-SIG-Finance] Downloading Real Time Data from FRED
	(fImport/fredSeries)
In-Reply-To: <c5c9755b1001080459g3bb94633sfc1d46908b33b12b@mail.gmail.com>
References: <4B47171D.5050908@ath.forthnet.gr> <4B47282B.3090203@braverock.com>
	<c5c9755b1001080459g3bb94633sfc1d46908b33b12b@mail.gmail.com>
Message-ID: <4B472FC1.7010409@braverock.com>

Costas Vorlow wrote:
> Dear Brian,
>
> Thanks. I tried to download data from FRED via quantmod (BTW excellent 
> package) but I can't. It returns empty time series (unlike the GS 
> Yahoo example). Is there something wrong? (using 2.9.2 R).
>
I have no idea, as you didn't provide a reproducible example (see 
posting guide or http://catb.org/~esr/faqs/smart-questions.html)

Also, please keep replies on-list, so everyone can benefit from what you 
discover or create.

Regards,

    - Brian

> 2010/1/8 Brian G. Peterson <brian at braverock.com 
> <mailto:brian at braverock.com>>
>
>     Research wrote:
>
>         Hi,
>
>         I was looking at the API for ALFRED:
>
>           http://api.stlouisfed.org/docs/fred/realtime_period.html
>           http://api.stlouisfed.org/docs/fred/series_release.html
>
>         ALFRED is like FRED but provides us with real-time data, i.e.,
>         data for macroeconomic variables as they were originaly
>         announced (released) and not the revised (finalised) data
>         which FRED contains. These are useful for real-time
>         econometric applications.
>
>         I was wondering, how can one use the existing
>         routines/packages that access FRED, to access ALFRED.
>
>         >From what I have checked so far,  the mnemonics appear to be
>         the same on FRED and ALFRED for the same series (say PAYMES
>         for non-farm payrolls).
>
>
>     I haven't used the fImport function, but quantmod has a similar
>     function, so I'll use that in my examople on modifying, the
>     details should be quite similar.
>
>     look at function:
>
>     getSymbols.FRED
>
>     copy this to function getSymbols.ALFRED
>
>     modify it to include a parameter for the api key, or better yet
>     register one for the project.
>     then modify the line starting with download.file to reflect the
>     new required URL. While the Symbol may be the same, the url is
>     clearly different
>
>     test and share with the community
>
>     Regards,
>
>      - Brian
>
>     -- 
>     Brian G. Peterson
>     http://braverock.com/brian/
>     Ph: 773-459-4973
>     IM: bgpbraverock
>
>
>


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From veepsirtt at gmail.com  Sat Jan  9 16:23:48 2010
From: veepsirtt at gmail.com (Velappan Periasamy)
Date: Sat, 9 Jan 2010 20:53:48 +0530
Subject: [R-SIG-Finance] getting nseindia time series values
Message-ID: <c224dc731001090723l76bd4de4sbf5567700bf08a19@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100109/970c57e3/attachment.pl>

From edd at debian.org  Sat Jan  9 16:50:37 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 9 Jan 2010 09:50:37 -0600
Subject: [R-SIG-Finance] getting nseindia time series values
In-Reply-To: <c224dc731001090723l76bd4de4sbf5567700bf08a19@mail.gmail.com>
References: <c224dc731001090723l76bd4de4sbf5567700bf08a19@mail.gmail.com>
Message-ID: <19272.42445.841850.681218@ron.nulle.part>


On 9 January 2010 at 20:53, Velappan Periasamy wrote:
| How to get the closing price of RCOM  directly into R.
| Archives at
| http://nseindia.com/content/equities/scripvol/datafiles/08-01-2010-TO-08-01-2010RCOMEQN.csv


R> IcantBelieveYouDidNotTryThis <- read.csv("http://nseindia.com/content/equities/scripvol/datafiles/08-01-2010-TO-08-01-2010RCOMEQN.csv")
R> head(IcantBelieveYouDidNotTryThis) Symbol Series Date Prev.Close
  Open.Price High.Price Low.Price Last.Price Close.Price Average.Price
  Total.Traded.Quantity Turnover.in.Lacs X 1 RCOM EQ 08-Jan-2010 183.9
  184.5 185.2 180.2 181.1 180.8 182.1 3775898 6878 NA
R>

Dirk

-- 
Three out of two people have difficulties with fractions.


From sarswat at gmail.com  Sat Jan  9 17:56:32 2010
From: sarswat at gmail.com (sunil)
Date: Sat, 9 Jan 2010 22:26:32 +0530
Subject: [R-SIG-Finance] getting nseindia time series values
In-Reply-To: <c224dc731001090723l76bd4de4sbf5567700bf08a19@mail.gmail.com>
References: <c224dc731001090723l76bd4de4sbf5567700bf08a19@mail.gmail.com>
Message-ID: <28fa0bac1001090856s3d2e2a3h8d5e7af26b40b6fe@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100109/d105ffea/attachment.pl>

From n_torenvliet at hotmail.com  Sun Jan 10 02:03:55 2010
From: n_torenvliet at hotmail.com (Nick Torenvliet)
Date: Sat, 9 Jan 2010 20:03:55 -0500
Subject: [R-SIG-Finance] getting nseindia time series values
In-Reply-To: <28fa0bac1001090856s3d2e2a3h8d5e7af26b40b6fe@mail.gmail.com>
References: <c224dc731001090723l76bd4de4sbf5567700bf08a19@mail.gmail.com>,
	<28fa0bac1001090856s3d2e2a3h8d5e7af26b40b6fe@mail.gmail.com>
Message-ID: <BAY143-W83CDDEC87CD82D25046D7FE6E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100109/b572aca4/attachment.pl>

From veepsirtt at gmail.com  Sun Jan 10 07:27:23 2010
From: veepsirtt at gmail.com (Velappan Periasamy)
Date: Sat, 9 Jan 2010 22:27:23 -0800
Subject: [R-SIG-Finance] Reading nsedata price series
Message-ID: <c224dc731001092227l24869db8s7ebf1f81b3b5ed12@mail.gmail.com>

 I am getting this error.----------
while downloading data

IcantBelieveYouDidNotTryThis <-
read.csv("http://nseindia.com/content/equities/scripvol/datafiles/08-01-2010-TO-08-01-2010RCOMEQN.csv")

Error in file(file, "r") : cannot open the connection
In addition: Warning message:
In file(file, "r") : cannot open: HTTP status was '404 Not Found'


From veepsirtt at gmail.com  Sun Jan 10 08:35:44 2010
From: veepsirtt at gmail.com (Velappan Periasamy)
Date: Sat, 9 Jan 2010 23:35:44 -0800
Subject: [R-SIG-Finance] Reading nsedata price series
In-Reply-To: <8ed68eed1001092242w2e3a8a93o4607daae52579a01@mail.gmail.com>
References: <c224dc731001092227l24869db8s7ebf1f81b3b5ed12@mail.gmail.com>
	<8ed68eed1001092242w2e3a8a93o4607daae52579a01@mail.gmail.com>
Message-ID: <c224dc731001092335we822fc8wc0346cdcabb0059c@mail.gmail.com>

How  did Mr Dirk got this result ?.

to me, r-sig-finance
show details
 7:50 am (15 hours ago) 	
- Show quoted text -
R> IcantBelieveYouDidNotTryThis <-
read.csv("http://nseindia.com/content/equities/scripvol/datafiles/08-01-2010-TO-08-01-2010RCOMEQN.csv")

R> head(IcantBelieveYouDidNotTryThis) Symbol Series Date Prev.Close
 Open.Price High.Price Low.Price Last.Price Close.Price Average.Price
 Total.Traded.Quantity Turnover.in.Lacs X 1 RCOM EQ 08-Jan-2010 183.9
 184.5 185.2 180.2 181.1 180.8 182.1 3775898 6878 NA
R>

Dirk




On 1/9/10, Sean O'Riordain <sean.oriordain at gmail.com> wrote:
> Good morning,
>  I got the same error - but then I opened it in firefox... then again
>  in R and it worked... I'd be surprised if it's an R problem - more
>  likely nseindia.com doesn't want scraping of its webside.
>
>  Try using wireshark (.org) to debug the network packets going back and forth.
>  cheers,
>  Sean
>
>
>  On Sun, Jan 10, 2010 at 6:27 AM, Velappan Periasamy <veepsirtt at gmail.com> wrote:
>  >  I am getting this error.----------
>  > while downloading data
>  >
>  > IcantBelieveYouDidNotTryThis <-
>  > read.csv("http://nseindia.com/content/equities/scripvol/datafiles/08-01-2010-TO-08-01-2010RCOMEQN.csv")
>  >
>  > Error in file(file, "r") : cannot open the connection
>  > In addition: Warning message:
>  > In file(file, "r") : cannot open: HTTP status was '404 Not Found'
>  >
>
> > _______________________________________________
>  > R-SIG-Finance at stat.math.ethz.ch mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>  > -- Subscriber-posting only. If you want to post, subscribe first.
>  > -- Also note that this is not the r-help list where general R questions should go.
>  >
>


From sankalp.upadhyay at gmail.com  Sun Jan 10 10:13:17 2010
From: sankalp.upadhyay at gmail.com (Sankalp Upadhyay)
Date: Sun, 10 Jan 2010 17:13:17 +0800
Subject: [R-SIG-Finance] Reading nsedata price series
In-Reply-To: <c224dc731001092335we822fc8wc0346cdcabb0059c@mail.gmail.com>
References: <c224dc731001092227l24869db8s7ebf1f81b3b5ed12@mail.gmail.com>
	<8ed68eed1001092242w2e3a8a93o4607daae52579a01@mail.gmail.com>
	<c224dc731001092335we822fc8wc0346cdcabb0059c@mail.gmail.com>
Message-ID: <ff91746c1001100113i3676becp7793e893cb5819bf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100110/97a78775/attachment.pl>

From konradhoppe at hotmail.de  Sun Jan 10 12:31:35 2010
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Sun, 10 Jan 2010 12:31:35 +0100
Subject: [R-SIG-Finance] MACD Histogram
Message-ID: <SNT114-DS2351FC0D98FC7E26118E21D06E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100110/7c1a0f1f/attachment.pl>

From veepsirtt at gmail.com  Sun Jan 10 12:43:26 2010
From: veepsirtt at gmail.com (Velappan Periasamy)
Date: Sun, 10 Jan 2010 17:13:26 +0530
Subject: [R-SIG-Finance] getting nseindia time series values
Message-ID: <c224dc731001100343sb7db7f0if4cd208a7e190e6b@mail.gmail.com>

Dear Dirk Eddelbuettel ,

Try this command posted by you.
You got the result, but I couldn't.
any library to be installed?

IcantBelieveYouDidNotTryThis <-
read.csv("http://nseindia.com/content/equities/scripvol/datafiles/08-01-2010-TO-08-01-2010RCOMEQN.csv")
with regards.


From sean.oriordain at gmail.com  Sun Jan 10 15:03:05 2010
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Sun, 10 Jan 2010 14:03:05 +0000
Subject: [R-SIG-Finance] getting nseindia time series values
In-Reply-To: <c224dc731001100343sb7db7f0if4cd208a7e190e6b@mail.gmail.com>
References: <c224dc731001100343sb7db7f0if4cd208a7e190e6b@mail.gmail.com>
Message-ID: <8ed68eed1001100603l618eb58bh3470e18bf02bd465@mail.gmail.com>

if you read
?read.csv
you'll see that it is part of the utils library which is one of the
core libraries installed with R.  As I and others have said already -
this is an issue with the URL that you are passing, NOT with R.

To demonstrate this,

TryRunningThisAlternativeURL <-
read.csv('http://www.nwoods.com/act/trials/Export%20Sales%20Info-demo.csv')

then say
head(TryRunningThisAlternativeURL)

The CSV file on nseindia.com is dynamically generated - you need to
figure out what triggers this dynamic generation and what prevents it
- hint... it's not R... R has done *exactly* as you asked it

Sean





On Sun, Jan 10, 2010 at 11:43 AM, Velappan Periasamy
<veepsirtt at gmail.com> wrote:
> Dear Dirk Eddelbuettel ,
>
> Try this command posted by you.
> You got the result, but I couldn't.
> any library to be installed?
>
> IcantBelieveYouDidNotTryThis <-
> read.csv("http://nseindia.com/content/equities/scripvol/datafiles/08-01-2010-TO-08-01-2010RCOMEQN.csv")
> with regards.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From jeff.a.ryan at gmail.com  Sun Jan 10 15:45:38 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sun, 10 Jan 2010 08:45:38 -0600
Subject: [R-SIG-Finance] MACD Histogram
In-Reply-To: <SNT114-DS2351FC0D98FC7E26118E21D06E0@phx.gbl>
References: <SNT114-DS2351FC0D98FC7E26118E21D06E0@phx.gbl>
Message-ID: <e8e755251001100645w4e72c0f2jf7b615a914374103@mail.gmail.com>

Konrad,

Your error is in how you are calling MACD.  See the examples in ?MACD.
 You need to pass it the Close column if you want it to be what you
are expecting.

macd <- MACD(Cl(arl))
macdHist <- macd$macd - macd$signal
addTA(macdHist,type='h')

HTH,
Jeff

On Sun, Jan 10, 2010 at 5:31 AM, Konrad Hoppe <konradhoppe at hotmail.de> wrote:
> Hi Mailinglist members,
>
>
>
> I?ve got a question concerning the histogram which is plotted in the
> addMACD() method. I expect that this represents the difference between the
> macd and the signal line, but when I implement it by myself, I get a clearly
> other result. Please check the following code snippet. I add the MACD
> histogram via the addMACD() method and in addition a second TA, which
> represents the difference between the signal and the macd.
>
> Could you tell me whether I?m mistaking respectively what is plotted in the
> histogram?
>
>
>
> library(quantmod)
>
>
>
> from.dat <- as.Date("01/01/03", format="%m/%d/%y")
>
> to.dat <- as.Date(Sys.Date(), format="%m/%d/%y")
>
> getSymbols("ARL.DE", src="yahoo", from = from.dat, to = to.dat)
>
> arl <- last(ARL.DE , "100 days")
>
>
>
> chartSeries(arl, theme="white", TA=NULL)
>
> addMACD()
>
> macd <- MACD(arl)
>
> macdHist <- macd$macd - macd$signal
>
> addTA(macdHist, type="h")
>
>
>
>
>
> Thanks in advance.
>
> --
>
> Konrad Hoppe
>
> ?<http://www.konrad-hoppe.com/> http://www.konrad-hoppe.com/
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From mjenko at yahoo.com  Sun Jan 10 20:53:50 2010
From: mjenko at yahoo.com (Martin Jenkins)
Date: Sun, 10 Jan 2010 11:53:50 -0800 (PST)
Subject: [R-SIG-Finance] Retrieving latest day's data
In-Reply-To: <e8e755250911171438q5ca2db79n3e070ba33cc898db@mail.gmail.com>
References: <4B020FFF.6040803@cedrickjohnson.com>
	<879120.69033.qm@web113206.mail.gq1.yahoo.com>
	<e8e755250911171438q5ca2db79n3e070ba33cc898db@mail.gmail.com>
Message-ID: <485151.59927.qm@web113216.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100110/310f6a9d/attachment.pl>

From ggrothendieck at gmail.com  Sun Jan 10 22:57:16 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 10 Jan 2010 16:57:16 -0500
Subject: [R-SIG-Finance] Retrieving latest day's data
In-Reply-To: <485151.59927.qm@web113216.mail.gq1.yahoo.com>
References: <4B020FFF.6040803@cedrickjohnson.com>
	<879120.69033.qm@web113206.mail.gq1.yahoo.com> 
	<e8e755250911171438q5ca2db79n3e070ba33cc898db@mail.gmail.com> 
	<485151.59927.qm@web113216.mail.gq1.yahoo.com>
Message-ID: <971536df1001101357k63a0b0br404a069451b97453@mail.gmail.com>

Try this:

> library(zoo)
> # create some test data from built-in BOD
> z <- with(BOD, zoo(demand, Time))
>
> # create data frame from z with time reversed
> DFrev <- cbind(Time = time(z), as.data.frame(z))[length(time(z)):1,]
> write.table(DFrev, row.names = FALSE)
"Time" "z"
7 19.8
5 15.6
4 16
3 19
2 10.3
1 8.3

On Sun, Jan 10, 2010 at 2:53 PM, Martin Jenkins <mjenko at yahoo.com> wrote:
> Thanks for the help. ?For write.zoo() is there a way of ordering by date descending? ?Or tore-phrase, an easy way? ?In my output file I would like today's date, or the most recent date at the top and the oldest date at the bottom.
>
> I've attempted using the order() but it doesn't like it as it's a date field, no unary. ?No progressing using ORDER(zoo), although I suspect I'm not using it correctly. ?Any help would be appreciated, cheers, Martin.
>
>
>
>
> ________________________________
> From: Jeff Ryan <jeff.a.ryan at gmail.com>
>
> Cc: R-SIG-Finance <r-sig-finance at stat.math.ethz.ch>; Cedrick W. Johnson <cedrick at cedrickjohnson.com>
> Sent: Tue, November 17, 2009 10:38:07 PM
> Subject: Re: [R-SIG-Finance] Retrieving latest day's data
>
> Hi Martin,
>
> The 'time' in an xts or zoo object isn't part of the data per se.
>
> index() or time() will extract for you.
>
> write.zoo() will also output what you expect to disk
>
>> getSymbols("AAPL")
> [1] "AAPL"
>> head(index(AAPL))
> [1] "2007-01-03" "2007-01-04" "2007-01-05" "2007-01-08" "2007-01-09"
> [6] "2007-01-10"
>> head(time(AAPL))
> [1] "2007-01-03" "2007-01-04" "2007-01-05" "2007-01-08" "2007-01-09"
> [6] "2007-01-10"
>> write.zoo(tail(AAPL))
> "Index" "AAPL.Open" "AAPL.High" "AAPL.Low" "AAPL.Close" "AAPL.Volume"
> "AAPL.Adjusted"
> 2009-11-09 196.94 201.9 196.26 201.46 18854500 201.46
> 2009-11-10 201.02 204.98 201.01 202.98 14315400 202.98
> 2009-11-11 204.56 205 201.83 203.25 15852500 203.25
> 2009-11-12 203.14 204.87 201.43 201.99 12990400 201.99
> 2009-11-13 202.87 204.83 202.07 204.45 12220200 204.45
> 2009-11-16 205.48 208 205.01 206.63 17216900 206.63
>
>
> Best,
> Jeff
>
>
>> Hi,
>>
>> Thanks for the suggestions, just what I need, however just one more thing...
>>
>> When I use:
>>
>> getSymbols("AML.L", src="google")
>> x <- tail(AML.L,1)
>>
>> I get back:
>>
>> ? ? ? ? ? ?AML.L.Open AML.L.High AML.L.Low AML.L.Close AML.L.Volume
>> 2009-11-17 ? ? ?385.5 ? ? ?388.9 ? ? 381.6 ? ? ? 382.6 ? ? ?1176883
>>
>> All the variables above are named, apart from the date. ?What I would like to do is have an if x$AML.L.Date = Sys.Date() then update my text file. ?This means that I can update the historical data that I download from Yahoo in the evening, run my model and look for any buys, so I can save a day and do my research in the evening before the next morning. ?Unfortunately for some reason I can't access the date, high low close open and volume are there but not date.
>>
>> Any help please?
>>
>> Thanks again,
>> Martin.
>>
>>
>>
>> --- On Tue, 11/17/09, Cedrick W. Johnson <cedrick at cedrickjohnson.com> wrote:
>>
>> From: Cedrick W. Johnson <cedrick at cedrickjohnson.com>
>> Subject: Re: [R-SIG-Finance] ?Retrieving latest day's data
>
>> Date: Tuesday, November 17, 2009, 2:52 AM
>>
>> I have found that typically after the evening extended sessions finish (~8PM ET) I can get today's closing prices. I just ran this now @ 9:45P et and got my closing prices for today:
>>
>> ? ? ? ? ? GSPC.Open GSPC.High GSPC.Low GSPC.Close GSPC.Volume GSPC.Adjusted
>> 2009-11-13 ? 1087.59 ? 1097.79 ?1085.33 ? ?1093.48 ?3792610000 ? ? ? 1093.48
>> 2009-11-16 ? 1094.13 ? 1113.69 ?1094.13 ? ?1109.30 ?4565850000 ? ? ? 1109.30
>>
>> I see you're getting UK tickers (this is what Joshua suggested, the getQuote function in quantmod):
>>> getQuote("AML.L")
>> ? ? ? ? ? ? ? Trade Time ?Last Change % Change Open ?High ? Low ?Volume
>> AML.L 2009-11-16 11:35:00 387.4 ? 10.8 ? +2.87% ?385 395.1 375.6 3375783
>>
>> *edit*
>>
>> While composing, I thought to check using Google:
>>
>>> getSymbols("AML.L", src="google")
>>
>>> tail(AML.L,2)
>> ? ? ? ? ? AML.L.Open AML.L.High AML.L.Low AML.L.Close AML.L.Volume
>> 2009-11-13 ? ? ?372.9 ? ? ?376.9 ? ? 368.1 ? ? ? 376.6 ? ? ?1403827
>> 2009-11-16 ? ? ?385.0 ? ? ?395.1 ? ? 375.6 ? ? ? 387.4 ? ? ?3375783
>>
>> Try that on the rest of your symbols to see what you get. Again, the time(s) that they update the closing price may be different. The same query I just did using Yahoo as a source yielded the 13th's closing price, while google is getting you what you want.
>>
>> HTH,
>> Cedrick
>>
>>
>> Martin Jenkins wrote:
>>> Hi,
>>>
>>> I realise that this isn't a 100% R-SIG question and is probably a more general R question, but I think it is related, and when I sort it it is leading to an R-SIG question, so if I could ask you to bear with me.
>>>
>>> I'm trying to build my own trading model, to test out some strategies. ?Part of this involves downloading the stcok market data and then processing it, i.e. running my model on it, using R-SIG to build graphs etc. ?However using Yahoo the historical data is always one day behind. ?To get around this I'm attempting to use a screen scraper utility, called PageScrape. ?It's command line based, however I'm trying to use system() to call the screen scraper from within R. ?The problem is that the screen scraper use regex and this causes unexpected symbol errors when I try to run it inside the system function.
>>>
>>> So, I can run the below inside a batch file, so can you if you download PageScraper:
>>> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Day's Range:[0-9]+\.[0-9]+ - ([0-9]+\.[0-9]+)"
>>> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Day's Range:</td><td class=.yfnc_tabledata1.>([0-9]+\.[0-9]+) - [0-9]+\.[0-9]+</td></tr>"
>>> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e">Last Trade:</td><td class=.yfnc_tabledata1.><big><b>([0-9]+\.[0-9]+) p"
>>> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Open:</td><td class=.yfnc_tabledata1.>([0-9]+\.[0-9]+)</td></tr>"
>>> pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Volume:</td><td class=.yfnc_tabledata1.>([0-9]+,[0-9]+,[0-9]+)</td></tr>"
>>> pause
>>>
>>> This is actually 4 lines, which will bring back the open, high, low and volume from the URL after -u. ?The bit inside the () is what's returned.
>>>
>>> What I'm after is to convert this to:
>>>
>>> system('cmd /c "pscrape -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c=" -e"Day's Range:</td><td class=.yfnc_tabledata1.>[0-9]+\.[0-9]+ - ([0-9]+\.[0-9]+)</td></tr>""')
>>>
>>> I've tried several attempts to get it working without any success. ?If anyone here can help that would be terrific, and hopefully some of you may find it useful.
>>>
>>> Many thanks,
>>> Martin.
>>>
>>>
>>>
>>> ? ? ? ? ? [[alternative HTML version deleted]]
>>>
>>> ? ------------------------------------------------------------------------
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>
>>
>>
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>>
>
>
>
> --
> Jeffrey Ryan
> jeffrey.ryan at insightalgo.com
>
> ia: insight algorithmics
> www.insightalgo.com
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From mjenko at yahoo.com  Mon Jan 11 00:43:53 2010
From: mjenko at yahoo.com (Martin Jenkins)
Date: Sun, 10 Jan 2010 15:43:53 -0800 (PST)
Subject: [R-SIG-Finance] Retrieving latest day's data
In-Reply-To: <971536df1001101357k63a0b0br404a069451b97453@mail.gmail.com>
References: <4B020FFF.6040803@cedrickjohnson.com>
	<879120.69033.qm@web113206.mail.gq1.yahoo.com>
	<e8e755250911171438q5ca2db79n3e070ba33cc898db@mail.gmail.com>
	<485151.59927.qm@web113216.mail.gq1.yahoo.com>
	<971536df1001101357k63a0b0br404a069451b97453@mail.gmail.com>
Message-ID: <692863.11996.qm@web113208.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100110/ab4bfcc8/attachment.pl>

From ggrothendieck at gmail.com  Mon Jan 11 00:55:48 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 10 Jan 2010 18:55:48 -0500
Subject: [R-SIG-Finance] Retrieving latest day's data
In-Reply-To: <692863.11996.qm@web113208.mail.gq1.yahoo.com>
References: <4B020FFF.6040803@cedrickjohnson.com>
	<879120.69033.qm@web113206.mail.gq1.yahoo.com> 
	<e8e755250911171438q5ca2db79n3e070ba33cc898db@mail.gmail.com> 
	<485151.59927.qm@web113216.mail.gq1.yahoo.com>
	<971536df1001101357k63a0b0br404a069451b97453@mail.gmail.com> 
	<692863.11996.qm@web113208.mail.gq1.yahoo.com>
Message-ID: <971536df1001101555p2897437u4be4c989acfdd64e@mail.gmail.com>

There was nothing specific to the class of the time index in my sample code.

On Sun, Jan 10, 2010 at 6:43 PM, Martin Jenkins <mjenko at yahoo.com> wrote:
> Thanks, apologies if I'm being a bit dim, but will that work the same with
> dates, most code looks something like below:
>
> csD <- tail(getSymbols("VOD.L", src="google", auto.assign=FALSE),800)
> macd<-tail(MACD(csD),800)
> names(macd)[2] <- "macd_signal"
> csDoutput<-merge(csD, macd)
> outputfile ="C:/Users/Admin/Documents/VOD.L_MACD.csv"
> write.zoo(csDoutput, file = outputfile, append = TRUE, sep = ",")
>
> ________________________________
> From: Gabor Grothendieck <ggrothendieck at gmail.com>
> To: Martin Jenkins <mjenko at yahoo.com>
> Cc: R-SIG-Finance <r-sig-finance at stat.math.ethz.ch>
> Sent: Sun, January 10, 2010 9:57:16 PM
> Subject: Re: [R-SIG-Finance] Retrieving latest day's data
>
> Try this:
>
>> library(zoo)
>> # create some test data from built-in BOD
>> z <- with(BOD, zoo(demand, Time))
>>
>> # create data frame from z with time reversed
>> DFrev <- cbind(Time = time(z), as.data.frame(z))[length(time(z)):1,]
>> write.table(DFrev, row.names = FALSE)
> "Time" "z"
> 7 19.8
> 5 15.6
> 4 16
> 3 19
> 2 10.3
> 1 8.3
>
> On Sun, Jan 10, 2010 at 2:53 PM, Martin Jenkins <mjenko at yahoo.com> wrote:
>> Thanks for the help. ?For write.zoo() is there a way of ordering by date
>> descending? ?Or tore-phrase, an easy way? ?In my output file I would like
>> today's date, or the most recent date at the top and the oldest date at the
>> bottom.
>>
>> I've attempted using the order() but it doesn't like it as it's a date
>> field, no unary. ?No progressing using ORDER(zoo), although I suspect I'm
>> not using it correctly. ?Any help would be appreciated, cheers, Martin.
>>
>>
>>
>>
>> ________________________________
>> From: Jeff Ryan <jeff.a.ryan at gmail.com>
>>
>> Cc: R-SIG-Finance <r-sig-finance at stat.math.ethz.ch>; Cedrick W. Johnson
>> <cedrick at cedrickjohnson.com>
>> Sent: Tue, November 17, 2009 10:38:07 PM
>> Subject: Re: [R-SIG-Finance] Retrieving latest day's data
>>
>> Hi Martin,
>>
>> The 'time' in an xts or zoo object isn't part of the data per se.
>>
>> index() or time() will extract for you.
>>
>> write.zoo() will also output what you expect to disk
>>
>>> getSymbols("AAPL")
>> [1] "AAPL"
>>> head(index(AAPL))
>> [1] "2007-01-03" "2007-01-04" "2007-01-05" "2007-01-08" "2007-01-09"
>> [6] "2007-01-10"
>>> head(time(AAPL))
>> [1] "2007-01-03" "2007-01-04" "2007-01-05" "2007-01-08" "2007-01-09"
>> [6] "2007-01-10"
>>> write.zoo(tail(AAPL))
>> "Index" "AAPL.Open" "AAPL.High" "AAPL.Low" "AAPL.Close" "AAPL.Volume"
>> "AAPL.Adjusted"
>> 2009-11-09 196.94 201.9 196.26 201.46 18854500 201.46
>> 2009-11-10 201.02 204.98 201.01 202.98 14315400 202.98
>> 2009-11-11 204.56 205 201.83 203.25 15852500 203.25
>> 2009-11-12 203.14 204.87 201.43 201.99 12990400 201.99
>> 2009-11-13 202.87 204.83 202.07 204.45 12220200 204.45
>> 2009-11-16 205.48 208 205.01 206.63 17216900 206.63
>>
>>
>> Best,
>> Jeff
>>
>>
>>> Hi,
>>>
>>> Thanks for the suggestions, just what I need, however just one more
>>> thing...
>>>
>>> When I use:
>>>
>>> getSymbols("AML.L", src="google")
>>> x <- tail(AML.L,1)
>>>
>>> I get back:
>>>
>>> ? ? ? ? ? ?AML.L.Open AML.L.High AML.L.Low AML.L.Close AML.L.Volume
>>> 2009-11-17 ? ? ?385.5 ? ? ?388.9 ? ? 381.6 ? ? ? 382.6 ? ? ?1176883
>>>
>>> All the variables above are named, apart from the date. ?What I would
>>> like to do is have an if x$AML.L.Date = Sys.Date() then update my text file.
>>> ?This means that I can update the historical data that I download from Yahoo
>>> in the evening, run my model and look for any buys, so I can save a day and
>>> do my research in the evening before the next morning. ?Unfortunately for
>>> some reason I can't access the date, high low close open and volume are
>>> there but not date.
>>>
>>> Any help please?
>>>
>>> Thanks again,
>>> Martin.
>>>
>>>
>>>
>>> --- On Tue, 11/17/09, Cedrick W. Johnson <cedrick at cedrickjohnson.com>
>>> wrote:
>>>
>>> From: Cedrick W. Johnson <cedrick at cedrickjohnson.com>
>>> Subject: Re: [R-SIG-Finance] ?Retrieving latest day's data
>>
>>> Date: Tuesday, November 17, 2009, 2:52 AM
>>>
>>> I have found that typically after the evening extended sessions finish
>>> (~8PM ET) I can get today's closing prices. I just ran this now @ 9:45P et
>>> and got my closing prices for today:
>>>
>>> ? ? ? ? ? GSPC.Open GSPC.High GSPC.Low GSPC.Close GSPC.Volume
>>> GSPC.Adjusted
>>> 2009-11-13 ? 1087.59 ? 1097.79 ?1085.33 ? ?1093.48 ?3792610000
>>> 1093.48
>>> 2009-11-16 ? 1094.13 ? 1113.69 ?1094.13 ? ?1109.30 ?4565850000
>>> 1109.30
>>>
>>> I see you're getting UK tickers (this is what Joshua suggested, the
>>> getQuote function in quantmod):
>>>> getQuote("AML.L")
>>> ? ? ? ? ? ? ? Trade Time ?Last Change % Change Open ?High ? Low ?Volume
>>> AML.L 2009-11-16 11:35:00 387.4 ? 10.8 ? +2.87% ?385 395.1 375.6 3375783
>>>
>>> *edit*
>>>
>>> While composing, I thought to check using Google:
>>>
>>>> getSymbols("AML.L", src="google")
>>>
>>>> tail(AML.L,2)
>>> ? ? ? ? ? AML.L.Open AML.L.High AML.L.Low AML.L.Close AML.L.Volume
>>> 2009-11-13 ? ? ?372.9 ? ? ?376.9 ? ? 368.1 ? ? ? 376.6 ? ? ?1403827
>>> 2009-11-16 ? ? ?385.0 ? ? ?395.1 ? ? 375.6 ? ? ? 387.4 ? ? ?3375783
>>>
>>> Try that on the rest of your symbols to see what you get. Again, the
>>> time(s) that they update the closing price may be different. The same query
>>> I just did using Yahoo as a source yielded the 13th's closing price, while
>>> google is getting you what you want.
>>>
>>> HTH,
>>> Cedrick
>>>
>>>
>>> Martin Jenkins wrote:
>>>> Hi,
>>>>
>>>> I realise that this isn't a 100% R-SIG question and is probably a more
>>>> general R question, but I think it is related, and when I sort it it is
>>>> leading to an R-SIG question, so if I could ask you to bear with me.
>>>>
>>>> I'm trying to build my own trading model, to test out some strategies.
>>>> ?Part of this involves downloading the stcok market data and then processing
>>>> it, i.e. running my model on it, using R-SIG to build graphs etc. ?However
>>>> using Yahoo the historical data is always one day behind. ?To get around
>>>> this I'm attempting to use a screen scraper utility, called PageScrape.
>>>> ?It's command line based, however I'm trying to use system() to call the
>>>> screen scraper from within R. ?The problem is that the screen scraper use
>>>> regex and this causes unexpected symbol errors when I try to run it inside
>>>> the system function.
>>>>
>>>> So, I can run the below inside a batch file, so can you if you download
>>>> PageScraper:
>>>> pscrape
>>>> -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c="
>>>> -e"Day's Range:[0-9]+\.[0-9]+ - ([0-9]+\.[0-9]+)"
>>>> pscrape
>>>> -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c="
>>>> -e"Day's Range:</td><td class=.yfnc_tabledata1.>([0-9]+\.[0-9]+) -
>>>> [0-9]+\.[0-9]+</td></tr>"
>>>> pscrape
>>>> -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c="
>>>> -e">Last Trade:</td><td class=.yfnc_tabledata1.><big><b>([0-9]+\.[0-9]+) p"
>>>> pscrape
>>>> -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c="
>>>> -e"Open:</td><td class=.yfnc_tabledata1.>([0-9]+\.[0-9]+)</td></tr>"
>>>> pscrape
>>>> -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c="
>>>> -e"Volume:</td><td class=.yfnc_tabledata1.>([0-9]+,[0-9]+,[0-9]+)</td></tr>"
>>>> pause
>>>>
>>>> This is actually 4 lines, which will bring back the open, high, low and
>>>> volume from the URL after -u. ?The bit inside the () is what's returned.
>>>>
>>>> What I'm after is to convert this to:
>>>>
>>>> system('cmd /c "pscrape
>>>> -u"http://uk.finance.yahoo.com/q/ta?s=AML.L&t=1y&l=off&z=l&q=b&p=&a=&c="
>>>> -e"Day's Range:</td><td class=.yfnc_tabledata1.>[0-9]+\.[0-9]+ -
>>>> ([0-9]+\.[0-9]+)</td></tr>""')
>>>>
>>>> I've tried several attempts to get it working without any success. ?If
>>>> anyone here can help that would be terrific, and hopefully some of you may
>>>> find it useful.
>>>>
>>>> Many thanks,
>>>> Martin.
>>>>
>>>>
>>>>
>>>> ? ? ? ? ? [[alternative HTML version deleted]]
>>>>
>>>>
>>>> ------------------------------------------------------------------------
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only.
>>>> -- If you want to post, subscribe first.
>>>
>>>
>>>
>>>
>>>
>>> ? ? ? ?[[alternative HTML version deleted]]
>>>
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only.
>>> -- If you want to post, subscribe first.
>>>
>>
>>
>>
>> --
>> Jeffrey Ryan
>> jeffrey.ryan at insightalgo.com
>>
>> ia: insight algorithmics
>> www.insightalgo.com
>>
>>
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>


From liuweiw_cuhk at hotmail.com  Mon Jan 11 04:12:54 2010
From: liuweiw_cuhk at hotmail.com (weiwei liu)
Date: Mon, 11 Jan 2010 11:12:54 +0800
Subject: [R-SIG-Finance] (no subject)
Message-ID: <SNT127-W249649CDE923BAF4A39259F96D0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100111/8395f2a8/attachment.pl>

From michael at optirisk-systems.com  Mon Jan 11 18:21:25 2010
From: michael at optirisk-systems.com (Michael Sun)
Date: Mon, 11 Jan 2010 17:21:25 -0000
Subject: [R-SIG-Finance] News Analytics Applied to Trading,
	Fund Management and Risk Control
Message-ID: <61F86A9166CACB40A35D88D0DCE52E4F0194F4E3@exch-be21.exchange.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100111/d8bd5ba8/attachment.pl>

From gps at asu.edu  Tue Jan 12 00:35:53 2010
From: gps at asu.edu (Geoffrey Smith)
Date: Mon, 11 Jan 2010 16:35:53 -0700
Subject: [R-SIG-Finance] taq high-frequency data
Message-ID: <4b5c27441001111535i279f15b0wa4c8595914aa985@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100111/920a5f5e/attachment.pl>

From scott.p.macdonald at gmail.com  Tue Jan 12 00:54:29 2010
From: scott.p.macdonald at gmail.com (Scott MacDonald)
Date: Tue, 12 Jan 2010 10:54:29 +1100
Subject: [R-SIG-Finance] taq high-frequency data
In-Reply-To: <4b5c27441001111535i279f15b0wa4c8595914aa985@mail.gmail.com>
References: <4b5c27441001111535i279f15b0wa4c8595914aa985@mail.gmail.com>
Message-ID: <c4adf6e91001111554n202e6519p234ebdbdbe0f963b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100112/7efeeb2e/attachment.pl>

From brian at braverock.com  Tue Jan 12 02:31:28 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 11 Jan 2010 19:31:28 -0600
Subject: [R-SIG-Finance] taq high-frequency data
In-Reply-To: <4b5c27441001111535i279f15b0wa4c8595914aa985@mail.gmail.com>
References: <4b5c27441001111535i279f15b0wa4c8595914aa985@mail.gmail.com>
Message-ID: <4B4BD0F0.5020609@braverock.com>

Geoffrey Smith wrote:
> Hello, may I please ask if anyone is aware of any R package that could help
> with cleaning up and processing the high-frequency trade and quote data from
> the NYSE TAQ database?  Thank you.  Geoff

I see that Scott has posted pointers to several resources that talk about high 
frequency data analysis and cleaning.

Kris Boudt and one of his students have created an R package called RTAQ that 
does parses, imports, and does analysis on TAQ data.

I've copied Kris, and we'll try to get the code up onto R-Forge or somewhere 
else accessible.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From nicolas.chapados at gmail.com  Tue Jan 12 02:36:35 2010
From: nicolas.chapados at gmail.com (Nicolas Chapados)
Date: Mon, 11 Jan 2010 20:36:35 -0500
Subject: [R-SIG-Finance] quantmod: adding many TAs in a function without
	constant replotting
Message-ID: <6fdf6d431001111736y44c0850cpe5e4600c8f0b4442@mail.gmail.com>

Dear list,

I'm using quantmod to create some good-looking charts (many thanks to
the Jeff Ryan for this great package!), and I would like to wrap some
recipes within a function, as opposed to updating the chart
interactively.  In particular, I want to add a bunch (a few dozen) of
TAs (using addTA) to a chart.  However, since this is performed within
a function and not interactively, it is necessary, as per previous
posts to this list, to wrap each addTA call within a plot:

myplot <- function()
{
    candleChart(prices)
    plot(addTA(...))
    plot(addTA(...))
    ...
}

However, since there is a lot of addTA in my code, this is EXTREMELY
slow.  Is there a way to simply "accumulate" all the chobTA objects
returned by addTA into the chob returned by candleChart WITHOUT
replotting each time, and to simply do a final plot at the end?  I
looked long and hard for previous posts on this topic, and tried
inspecting some of quantmod code as well, to no avail...

Any help greatly appreciated!

    Best regards,
    + Nicolas Chapados


From rbali at ufmg.br  Tue Jan 12 03:28:36 2010
From: rbali at ufmg.br (Robert Iquiapaza)
Date: Tue, 12 Jan 2010 00:28:36 -0200
Subject: [R-SIG-Finance] (no subject)
In-Reply-To: <SNT127-W249649CDE923BAF4A39259F96D0@phx.gbl>
References: <SNT127-W249649CDE923BAF4A39259F96D0@phx.gbl>
Message-ID: <0FD6918CFA654BDBA21FD7E9D530E32D@DellPC>

For mgarch: An R Package for MGARCH Processes
try at
http://mgarch.sourceforge.net/
and
http://www.agrocampus-ouest.fr/math/useR-2009/slides/Schmidbauer+Tunalioglu+Roesch.pdf

Robert
--------------------------------------------------
From: "weiwei liu" <liuweiw_cuhk at hotmail.com>
Sent: Monday, January 11, 2010 1:12 AM
To: <r-sig-finance at stat.math.ethz.ch>
Subject: [R-SIG-Finance] (no subject)

>
> Hi, every one!
>
> I am looking for an package for multivariate garch mode. I know there were 
> two package named "mgarch" and "garchBEKK", however I cann't find them 
> anywhere.
>
> Could you tell me where I can find them OR there is any other package for 
> multivariate garch model.
>
> Thanks very much.
>
> m Hotmail?.
>
> cial-network-basics.aspx?ocid=PID23461::T:WLMTAGL:ON:WL:en-xm:SI_SB_4:092
> [[alternative HTML version deleted]]


From jeff.a.ryan at gmail.com  Tue Jan 12 05:38:45 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 11 Jan 2010 22:38:45 -0600
Subject: [R-SIG-Finance] (no subject)
In-Reply-To: <SNT127-W249649CDE923BAF4A39259F96D0@phx.gbl>
References: <SNT127-W249649CDE923BAF4A39259F96D0@phx.gbl>
Message-ID: <e8e755251001112038k4bb63a6dgdca049d79d79ea93@mail.gmail.com>

The old package mgarchBEKK is available one the quantmod site:

http://www.quantmod.com/download/mgarchBEKK/

It may or may not run, as I only hosted a copy for the sake of the
community (I never use it).

HTH
Jeff

On Sun, Jan 10, 2010 at 9:12 PM, weiwei liu <liuweiw_cuhk at hotmail.com> wrote:
>
> Hi, every one!
>
>
>
> I am looking for an package for multivariate garch mode. I know there were two package named "mgarch" and "garchBEKK", however I cann't find them anywhere.
>
>
>
> Could you tell me where I can find them OR there is any other package for multivariate garch model.
>
>
>
> Thanks very much.
>
> _________________________________________________________________
>
> m Hotmail?.
>
> cial-network-basics.aspx?ocid=PID23461::T:WLMTAGL:ON:WL:en-xm:SI_SB_4:092
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From Bernhard_Pfaff at fra.invesco.com  Tue Jan 12 09:28:00 2010
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Tue, 12 Jan 2010 08:28:00 -0000
Subject: [R-SIG-Finance] (no subject)
In-Reply-To: <e8e755251001112038k4bb63a6dgdca049d79d79ea93@mail.gmail.com>
References: <SNT127-W249649CDE923BAF4A39259F96D0@phx.gbl>
	<e8e755251001112038k4bb63a6dgdca049d79d79ea93@mail.gmail.com>
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C320FEE600@GBHENXMB02.corp.amvescap.net>

For the sake of completeness, there is also the package 'gogarch' available on CRAN and R-Forge.

Best,
Bernhard 

 |>  -----Original Message-----
 |>  From: r-sig-finance-bounces at stat.math.ethz.ch 
 |>  [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf 
 |>  Of Jeff Ryan
 |>  Sent: Tuesday, January 12, 2010 5:39 AM
 |>  To: weiwei liu
 |>  Cc: r-sig-finance at stat.math.ethz.ch
 |>  Subject: Re: [R-SIG-Finance] (no subject)
 |>  
 |>  The old package mgarchBEKK is available one the quantmod site:
 |>  
 |>  http://www.quantmod.com/download/mgarchBEKK/
 |>  
 |>  It may or may not run, as I only hosted a copy for the sake of the
 |>  community (I never use it).
 |>  
 |>  HTH
 |>  Jeff
 |>  
 |>  On Sun, Jan 10, 2010 at 9:12 PM, weiwei liu 
 |>  <liuweiw_cuhk at hotmail.com> wrote:
 |>  >
 |>  > Hi, every one!
 |>  >
 |>  >
 |>  >
 |>  > I am looking for an package for multivariate garch mode. 
 |>  I know there were two package named "mgarch" and 
 |>  "garchBEKK", however I cann't find them anywhere.
 |>  >
 |>  >
 |>  >
 |>  > Could you tell me where I can find them OR there is any 
 |>  other package for multivariate garch model.
 |>  >
 |>  >
 |>  >
 |>  > Thanks very much.
 |>  >
 |>  > _________________________________________________________________
 |>  >
 |>  > m Hotmail?.
 |>  >
 |>  > 
 |>  cial-network-basics.aspx?ocid=PID23461::T:WLMTAGL:ON:WL:en-
 |>  xm:SI_SB_4:092
 |>  > ? ? ? ?[[alternative HTML version deleted]]
 |>  >
 |>  >
 |>  > _______________________________________________
 |>  > R-SIG-Finance at stat.math.ethz.ch mailing list
 |>  > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
 |>  > -- Subscriber-posting only. If you want to post, subscribe first.
 |>  > -- Also note that this is not the r-help list where 
 |>  general R questions should go.
 |>  >
 |>  
 |>  
 |>  
 |>  -- 
 |>  Jeffrey Ryan
 |>  jeffrey.ryan at insightalgo.com
 |>  
 |>  ia: insight algorithmics
 |>  www.insightalgo.com
 |>  
 |>  _______________________________________________
 |>  R-SIG-Finance at stat.math.ethz.ch mailing list
 |>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
 |>  -- Subscriber-posting only. If you want to post, subscribe first.
 |>  -- Also note that this is not the r-help list where 
 |>  general R questions should go.
 |>  
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:10}}


From john.kerpel at gmail.com  Tue Jan 12 09:33:51 2010
From: john.kerpel at gmail.com (John Kerpel)
Date: Tue, 12 Jan 2010 02:33:51 -0600
Subject: [R-SIG-Finance] (no subject)
In-Reply-To: <e8e755251001112038k4bb63a6dgdca049d79d79ea93@mail.gmail.com>
References: <SNT127-W249649CDE923BAF4A39259F96D0@phx.gbl>
	<e8e755251001112038k4bb63a6dgdca049d79d79ea93@mail.gmail.com>
Message-ID: <6555fd731001120033n742b6e2ake0fa207fc23621da@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100112/305664ea/attachment.pl>

From Samuel.Meichtry at bkw-fmb.ch  Tue Jan 12 10:03:40 2010
From: Samuel.Meichtry at bkw-fmb.ch (Samuel.Meichtry at bkw-fmb.ch)
Date: Tue, 12 Jan 2010 10:03:40 +0100
Subject: [R-SIG-Finance] Sorting Data.Frames after merge?
Message-ID: <201001120903.o0C93r3V022636@hypatia.math.ethz.ch>

Hi Mailinglist members,

I've got a question concerning the sorting a data.frame in Gnu R by a specific column. I have calculated deviations and means of a electricity consumption timeserie and would like to roll it out for the next 4 years.

After merging two data.frames by weeknumber (week) and weekday over several years, I get a unsorted data.frame, meaning that it is not in the correct date order. Therefore I would like to sort it by TimeStamp again.

Thanks in advance.


#DataFrame No.1
rf <- data.frame(
        Week=tmWeek[s:e],
        Weekday=tmWeekday[s:e],
        Mean=smMean[s:e],    
        Quantile05=smQuant05[s:e],
        Quantile95=smQuant95[s:e]
)

#DataFrame No.2
md <- data.frame(
    TimeStamp = tmp.d, 
    Week = tmp.week,
    Weekday = tmp.weekday  
)

#Merging of the two DataFrames
kdf <- merge(md,rf,by=intersect(names(md),names(rf)))

____________________________________________
BKW FMB Energie AG
Energy Trading
Samuel Meichtry
Analyst Energy Trading
Tel +41 31 330 53 99
Fax +41 31 330 56 16
e-mail samuel.meichtry at bkw-fmb.ch


From konradhoppe at hotmail.de  Tue Jan 12 10:46:53 2010
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Tue, 12 Jan 2010 10:46:53 +0100
Subject: [R-SIG-Finance] Sorting Data.Frames after merge?
In-Reply-To: <201001120903.o0C93r3V022636@hypatia.math.ethz.ch>
Message-ID: <SNT114-DS7E6819A685C03232203FCD06C0@phx.gbl>

Hi,

maybe this is what you're looking for:

dates <- c(as.Date("08/30/03", format="%m/%d/%y"),
		as.Date("01/01/03", format="%m/%d/%y"),
		as.Date("01/01/02", format="%m/%d/%y"),
		as.Date("02/01/03", format="%m/%d/%y"))
entries <- c(1,2,3,4)
dat <- data.frame(dates,entries)
dat[order(dat$dates),]


regards
--
Konrad Hoppe
http://www.konrad-hoppe.com/

-----Urspr?ngliche Nachricht-----
Von: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] Im Auftrag von
Samuel.Meichtry at bkw-fmb.ch
Gesendet: Dienstag, 12. Januar 2010 10:04
An: r-sig-finance at stat.math.ethz.ch
Betreff: [R-SIG-Finance] Sorting Data.Frames after merge?

Hi Mailinglist members,

I've got a question concerning the sorting a data.frame in Gnu R by a
specific column. I have calculated deviations and means of a electricity
consumption timeserie and would like to roll it out for the next 4 years.

After merging two data.frames by weeknumber (week) and weekday over several
years, I get a unsorted data.frame, meaning that it is not in the correct
date order. Therefore I would like to sort it by TimeStamp again.

Thanks in advance.


#DataFrame No.1
rf <- data.frame(
        Week=tmWeek[s:e],
        Weekday=tmWeekday[s:e],
        Mean=smMean[s:e],    
        Quantile05=smQuant05[s:e],
        Quantile95=smQuant95[s:e]
)

#DataFrame No.2
md <- data.frame(
    TimeStamp = tmp.d, 
    Week = tmp.week,
    Weekday = tmp.weekday  
)

#Merging of the two DataFrames
kdf <- merge(md,rf,by=intersect(names(md),names(rf)))

____________________________________________
BKW FMB Energie AG
Energy Trading
Samuel Meichtry
Analyst Energy Trading
Tel +41 31 330 53 99
Fax +41 31 330 56 16
e-mail samuel.meichtry at bkw-fmb.ch

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list

-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From ggrothendieck at gmail.com  Tue Jan 12 13:40:21 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 12 Jan 2010 07:40:21 -0500
Subject: [R-SIG-Finance] Sorting Data.Frames after merge?
In-Reply-To: <201001120903.o0C93r3V022636@hypatia.math.ethz.ch>
References: <AcqTZiIUzUztf2vcRRKGAWJIh7rzKw==>
	<201001120903.o0C93r3V022636@hypatia.math.ethz.ch>
Message-ID: <971536df1001120440r389dc82qa42fa4cbc86f831f@mail.gmail.com>

This code is not reproducible since there are variables used that are
not supplied.  See last line to every message on r-help.

The zoo package can store time series with arbitrary index class
provided it supports certain methods and merge such series while
keeping them sorted automatically.  See the three vignettes that come
with the package and ?merge.zoo


On Tue, Jan 12, 2010 at 4:03 AM,  <Samuel.Meichtry at bkw-fmb.ch> wrote:
> Hi Mailinglist members,
>
> I've got a question concerning the sorting a data.frame in Gnu R by a specific column. I have calculated deviations and means of a electricity consumption timeserie and would like to roll it out for the next 4 years.
>
> After merging two data.frames by weeknumber (week) and weekday over several years, I get a unsorted data.frame, meaning that it is not in the correct date order. Therefore I would like to sort it by TimeStamp again.
>
> Thanks in advance.
>
>
> #DataFrame No.1
> rf <- data.frame(
> ? ? ? ?Week=tmWeek[s:e],
> ? ? ? ?Weekday=tmWeekday[s:e],
> ? ? ? ?Mean=smMean[s:e],
> ? ? ? ?Quantile05=smQuant05[s:e],
> ? ? ? ?Quantile95=smQuant95[s:e]
> )
>
> #DataFrame No.2
> md <- data.frame(
> ? ?TimeStamp = tmp.d,
> ? ?Week = tmp.week,
> ? ?Weekday = tmp.weekday
> )
>
> #Merging of the two DataFrames
> kdf <- merge(md,rf,by=intersect(names(md),names(rf)))
>
> ____________________________________________
> BKW FMB Energie AG
> Energy Trading
> Samuel Meichtry
> Analyst Energy Trading
> Tel +41 31 330 53 99
> Fax +41 31 330 56 16
> e-mail samuel.meichtry at bkw-fmb.ch
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From rgs.stat at gmail.com  Tue Jan 12 15:41:27 2010
From: rgs.stat at gmail.com (=?iso-8859-1?Q?Ricardo_Gin=E7alves_Silva?=)
Date: Tue, 12 Jan 2010 12:41:27 -0200
Subject: [R-SIG-Finance] Credit Migration Matrix
Message-ID: <A40406BAD2AF4775AAA32944055A9164@RicardoPC>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100112/f2408ca7/attachment.pl>

From konradhoppe at hotmail.de  Tue Jan 12 16:53:30 2010
From: konradhoppe at hotmail.de (Konrad Hoppe)
Date: Tue, 12 Jan 2010 16:53:30 +0100
Subject: [R-SIG-Finance] Credit Migration Matrix
In-Reply-To: <A40406BAD2AF4775AAA32944055A9164@RicardoPC>
Message-ID: <SNT114-DS13A355F3088C6C5215FACED06C0@phx.gbl>

Hi Rick,

I wrote a small code snippet for you. It calculates the credit migration for
one institute. You can pack it in a function and apply it to every institute
you want to. But be careful with the relative proportions, I'm not deep in
this topic and unsure about the exact definition.


# credit migration:

#sampling the data:
dat <- sample(c("A","AA","AAA"), 100, replace=T)

# give numerical names for the ratings:
dat[which(dat=="A")] <- 1
dat[which(dat=="AA")] <- 2
dat[which(dat=="AAA")] <- 3
dat <- as.numeric(dat)

migrationMat <- matrix(0,nrow=3,ncol=3)

for(i in 1:(length(dat)-1)){
	origin <- dat[i]
	target <- dat[i+1]
	migrationMat[origin,target] <- migrationMat[origin,target]+1
}
rownames(migrationMat) <- c("A","AA","AAA")
colnames(migrationMat) <- c("A","AA","AAA")

#relative proportions:
migrationMatRel <- matrix(0, nrow=3,ncol=3)

for(i in 1:nrow(migrationMat)){
	for(j in 1:ncol(migrationMat)){
		migrationMatRel[i,j] <-
migrationMat[i,j]/sum(migrationMat[,j])
	}
}
rownames(migrationMatRel) <- c("A","AA","AAA")
colnames(migrationMatRel) <- c("A","AA","AAA")
migrationMatRel


All the best,
--
Konrad Hoppe
http://www.konrad-hoppe.com/

-----Urspr?ngliche Nachricht-----
Von: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] Im Auftrag von Ricardo
Gin?alves Silva
Gesendet: Dienstag, 12. Januar 2010 15:41
An: R-Finance
Betreff: [R-SIG-Finance] Credit Migration Matrix

Dear Users,

I  would like to know how can I compute credit rating migration matrix using
R.
I have 10 years data (monthly rates for each firm) and I would like 
to compute 12 (and more) months ahead migrations.
Any hints? Or a general purpose code to do it?

Best 

Rick
	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list

-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From etheber at gmx.de  Tue Jan 12 19:39:12 2010
From: etheber at gmx.de (Thomas Etheber)
Date: Tue, 12 Jan 2010 19:39:12 +0100
Subject: [R-SIG-Finance] Bry/Boschan routine for timing Business Cycle
	turning points
Message-ID: <4B4CC1D0.8010506@gmx.de>

Dear Users,

may I ask the same question as Pierre in the r-help 
(http://tolstoy.newcastle.edu.au/R/help/05/05/4753.html) group a few 
years later...


 >>>
Does anyone of you know if someone has programmed the Bry & Boschan 
routines in R? It's also known as the NBER method for identifying 
economic cycles peaks and troughs. Or do you know any method in R for 
indentifying peaks and troughs for times series. 

<<<

I already asked google without success.

Regards,
Thomas


From brian at braverock.com  Tue Jan 12 19:57:44 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 12 Jan 2010 12:57:44 -0600
Subject: [R-SIG-Finance] Bry/Boschan routine for timing Business Cycle
 turning points
In-Reply-To: <4B4CC1D0.8010506@gmx.de>
References: <4B4CC1D0.8010506@gmx.de>
Message-ID: <4B4CC628.7000909@braverock.com>

Thomas Etheber wrote:
> Dear Users,
>
> may I ask the same question as Pierre in the r-help 
> (http://tolstoy.newcastle.edu.au/R/help/05/05/4753.html) group a few 
> years later...
>
>
> >>>
> Does anyone of you know if someone has programmed the Bry & Boschan 
> routines in R? It's also known as the NBER method for identifying 
> economic cycles peaks and troughs. Or do you know any method in R for 
> indentifying peaks and troughs for times series.
> <<<
>
> I already asked google without success.

Take a look at Marc Wildi's work on Recessions and his 'dfa' package.

Cheers,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From otis at zhaw.ch  Tue Jan 12 22:47:23 2010
From: otis at zhaw.ch (Otziger Simon (otis))
Date: Tue, 12 Jan 2010 22:47:23 +0100
Subject: [R-SIG-Finance] Bry/Boschan routine for timing Business Cycle
	turning points
In-Reply-To: <4B4CC1D0.8010506@gmx.de>
References: <4B4CC1D0.8010506@gmx.de>
Message-ID: <3D71D281-3F5B-471B-95ED-2946446236BA@zhaw.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100112/946dbb68/attachment.pl>

From matthieu.stigler at gmail.com  Wed Jan 13 10:18:28 2010
From: matthieu.stigler at gmail.com (mat)
Date: Wed, 13 Jan 2010 10:18:28 +0100
Subject: [R-SIG-Finance] Bry/Boschan routine for timing Business Cycle
 turning points
In-Reply-To: <3D71D281-3F5B-471B-95ED-2946446236BA@zhaw.ch>
References: <4B4CC1D0.8010506@gmx.de>
	<3D71D281-3F5B-471B-95ED-2946446236BA@zhaw.ch>
Message-ID: <4B4D8FE4.9040500@gmail.com>

Dear Thomas

A collegue of mine had used the Bry/Boschan procedure implemented in 
GROCER and used a small wrapper to call it within R. The code is quite 
crude and might need some modifications but we can send it to you if you 
want.

Best

Matthieu Stigler


Otziger Simon (otis) a ?crit :
> Dear Thomas,
>
> Brian is referring to the "signalextraction" package. This package features the univariate case of Marc's Direct Filter Approach (DFA). The multivariate DFA is the core of a fast and reliable real-time recession indicator for the USA named USRI: http://cancun.zhaw.ch/cirano/
>
> Marc compares the USRI to various other competitors, e.g. ADS, CFNAI, Markov switching, OECD, conference board, ... The latest comparison is available at his Blog: http://blog.zhaw.ch/idp/sefblog/index.php?/archives/42-USRI-September-2009-Data-up-to-end-September.html
>
> Further, for financial application using this indicator please have a look at http://blog.zhaw.ch/idp/sefblog/index.php?/archives/45-Fast-Real-Time-Recession-Indicator-USRI-and-Fundamental-Financial-Trading.html and http://blog.zhaw.ch/idp/sefblog/index.php?/archives/46-On-the-Importance-of-Fast-but-not-too-Fast-Real-Time-Recession-Indicators-in-the-Context-of-Financial-Trading.html
>
>
> HTH,
> Simon
>
> On Jan 12, 2010, at 7:39 PM, Thomas Etheber wrote:
>
>   
>> Dear Users,
>>
>> may I ask the same question as Pierre in the r-help (http://tolstoy.newcastle.edu.au/R/help/05/05/4753.html) group a few years later...
>>
>>
>>     
>> Does anyone of you know if someone has programmed the Bry & Boschan routines in R? It's also known as the NBER method for identifying economic cycles peaks and troughs. Or do you know any method in R for indentifying peaks and troughs for times series. 
>> <<<
>>
>> I already asked google without success.
>>
>> Regards,
>> Thomas
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>>     
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From cmdr_rogue at hotmail.com  Wed Jan 13 11:14:18 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Wed, 13 Jan 2010 05:14:18 -0500
Subject: [R-SIG-Finance] Credit Migration Matrix
In-Reply-To: <A40406BAD2AF4775AAA32944055A9164@RicardoPC>
References: <A40406BAD2AF4775AAA32944055A9164@RicardoPC>
Message-ID: <BLU0-SMTP100609B6CF90750F0C27FF9E26B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100113/651fceb3/attachment.pl>

From etheber at gmx.de  Wed Jan 13 12:44:03 2010
From: etheber at gmx.de (Thomas Etheber)
Date: Wed, 13 Jan 2010 12:44:03 +0100
Subject: [R-SIG-Finance] Bry/Boschan routine for timing Business Cycle
 turning points
In-Reply-To: <4B4D8FE4.9040500@gmail.com>
References: <4B4CC1D0.8010506@gmx.de>
	<3D71D281-3F5B-471B-95ED-2946446236BA@zhaw.ch>
	<4B4D8FE4.9040500@gmail.com>
Message-ID: <4B4DB203.7020003@gmx.de>

Dear Matthieu,

I do not know GROCER, but if you (or the code) can guide me through the 
connection to the R interface/wrapper, I would highly appreciate to 
receive your code.
It might be usefull at least as a benchmark for own implementations.

Btw, thank you all for the helpful comments.

Best
Thomas


mat schrieb:
> Dear Thomas
>
> A collegue of mine had used the Bry/Boschan procedure implemented in 
> GROCER and used a small wrapper to call it within R. The code is quite 
> crude and might need some modifications but we can send it to you if 
> you want.
>
> Best
>
> Matthieu Stigler
>
>
> Otziger Simon (otis) a ?crit :
>> Dear Thomas,
>>
>> Brian is referring to the "signalextraction" package. This package 
>> features the univariate case of Marc's Direct Filter Approach (DFA). 
>> The multivariate DFA is the core of a fast and reliable real-time 
>> recession indicator for the USA named USRI: 
>> http://cancun.zhaw.ch/cirano/
>>
>> Marc compares the USRI to various other competitors, e.g. ADS, CFNAI, 
>> Markov switching, OECD, conference board, ... The latest comparison 
>> is available at his Blog: 
>> http://blog.zhaw.ch/idp/sefblog/index.php?/archives/42-USRI-September-2009-Data-up-to-end-September.html 
>>
>>
>> Further, for financial application using this indicator please have a 
>> look at 
>> http://blog.zhaw.ch/idp/sefblog/index.php?/archives/45-Fast-Real-Time-Recession-Indicator-USRI-and-Fundamental-Financial-Trading.html 
>> and 
>> http://blog.zhaw.ch/idp/sefblog/index.php?/archives/46-On-the-Importance-of-Fast-but-not-too-Fast-Real-Time-Recession-Indicators-in-the-Context-of-Financial-Trading.html 
>>
>>
>>
>> HTH,
>> Simon
>>
>> On Jan 12, 2010, at 7:39 PM, Thomas Etheber wrote:
>>
>>  
>>> Dear Users,
>>>
>>> may I ask the same question as Pierre in the r-help 
>>> (http://tolstoy.newcastle.edu.au/R/help/05/05/4753.html) group a few 
>>> years later...
>>>
>>>
>>>     Does anyone of you know if someone has programmed the Bry & 
>>> Boschan routines in R? It's also known as the NBER method for 
>>> identifying economic cycles peaks and troughs. Or do you know any 
>>> method in R for indentifying peaks and troughs for times series. <<<
>>>
>>> I already asked google without success.
>>>
>>> Regards,
>>> Thomas
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R 
>>> questions should go.
>>>     
>>
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R 
>> questions should go.
>>   
>


From minkymorgan at gmail.com  Wed Jan 13 16:55:12 2010
From: minkymorgan at gmail.com (andrew morgan)
Date: Wed, 13 Jan 2010 15:55:12 +0000
Subject: [R-SIG-Finance] Quantmod vertical gridlines?
Message-ID: <317ffdf51001130755o7030fa6bnbe70eff1488717f4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100113/9a6aee67/attachment.pl>

From diego.jara at quantil.com.co  Wed Jan 13 16:56:53 2010
From: diego.jara at quantil.com.co (Diego Jara)
Date: Wed, 13 Jan 2010 10:56:53 -0500
Subject: [R-SIG-Finance] Add business days
Message-ID: <1730e1951001130756u7df04496ube497351668625d0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100113/a7c76745/attachment.pl>

From ezivot at u.washington.edu  Wed Jan 13 23:48:17 2010
From: ezivot at u.washington.edu (Eric Zivot)
Date: Wed, 13 Jan 2010 14:48:17 -0800 (PST)
Subject: [R-SIG-Finance] Packages/functions for finance day count conventions
Message-ID: <Pine.LNX.4.43.1001131448170.10842@hymn11.u.washington.edu>

I'm looking for any R packages that have functions for SIA day count conventions (e.g. actual/actual, 30/360, actual/360 etc). It looks like RQuantMod handles some of these details internally in C code but they are not exposed at the R level. Any suggestions would be appreciated. Thanks,
ez

****************************************************************
*  Eric Zivot                  			               *
*  Professor and Gary Waterman Distinguished Scholar           *
*  Department of Economics                                     *
*  Adjunct Professor of Finance                                *
*  Adjunct Professor of Statistics
*  Box 353330                  email:  ezivot at u.washington.edu *
*  University of Washington    phone:  206-543-6715            *
*  Seattle, WA 98195-3330                                      *                                                           *
*  www:  http://faculty.washington.edu/ezivot                  *


From edd at debian.org  Thu Jan 14 03:55:40 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 13 Jan 2010 20:55:40 -0600
Subject: [R-SIG-Finance] Packages/functions for finance day count
	conventions
In-Reply-To: <Pine.LNX.4.43.1001131448170.10842@hymn11.u.washington.edu>
References: <Pine.LNX.4.43.1001131448170.10842@hymn11.u.washington.edu>
Message-ID: <19278.34732.863130.864518@ron.nulle.part>


On 13 January 2010 at 14:48, Eric Zivot wrote:
| I'm looking for any R packages that have functions for SIA day count
| conventions (e.g. actual/actual, 30/360, actual/360 etc). It looks like
| RQuantMod handles some of these details internally in C code but they are not
| exposed at the R level. Any suggestions would be appreciated. Thanks, 

There is no RQuantMod we know of but yes, Khanh just yesterday committed a
few more date functions to the SVN for RQuantLib so maybe this may be of
help.  [1] 

These date conventions do exist in QuantLib --- and AFAIK are already used
for some curve-building code --- so maybe we just need to sit down and
expose them.

Hth, Dirk

[1] https://r-forge.r-project.org/plugins/scmsvn/viewcvs.php?root=rquantlib&view=rev&rev=135

-- 
Three out of two people have difficulties with fractions.


From knguyen at cs.umb.edu  Thu Jan 14 05:09:43 2010
From: knguyen at cs.umb.edu (Khanh Nguyen)
Date: Wed, 13 Jan 2010 23:09:43 -0500
Subject: [R-SIG-Finance] Packages/functions for finance day count
	conventions
In-Reply-To: <19278.34732.863130.864518@ron.nulle.part>
References: <Pine.LNX.4.43.1001131448170.10842@hymn11.u.washington.edu>
	<19278.34732.863130.864518@ron.nulle.part>
Message-ID: <2871c9e11001132009s2dc081e5kcb3e9fbe10ba2e8e@mail.gmail.com>

The codes I committed yesterday port the QuantLib's calendar interface
here http://quantlib.org/reference/class_quant_lib_1_1_calendar.html
to RQuantLib.

However, I guess Dr. Zivot need the day counter here
http://quantlib.org/reference/class_quant_lib_1_1_day_counter.html . I
ported this to R, but for my little toolbox and not in Rquantlib yet.
I will do it later tonight...It should be available in RQuantLib
tomorrow.

-k



On Wed, Jan 13, 2010 at 9:55 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 13 January 2010 at 14:48, Eric Zivot wrote:
> | I'm looking for any R packages that have functions for SIA day count
> | conventions (e.g. actual/actual, 30/360, actual/360 etc). It looks like
> | RQuantMod handles some of these details internally in C code but they are not
> | exposed at the R level. Any suggestions would be appreciated. Thanks,
>
> There is no RQuantMod we know of but yes, Khanh just yesterday committed a
> few more date functions to the SVN for RQuantLib so maybe this may be of
> help. ?[1]
>
> These date conventions do exist in QuantLib --- and AFAIK are already used
> for some curve-building code --- so maybe we just need to sit down and
> expose them.
>
> Hth, Dirk
>
> [1] https://r-forge.r-project.org/plugins/scmsvn/viewcvs.php?root=rquantlib&view=rev&rev=135
>
> --
> Three out of two people have difficulties with fractions.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From knguyen at cs.umb.edu  Thu Jan 14 06:40:45 2010
From: knguyen at cs.umb.edu (Khanh Nguyen)
Date: Thu, 14 Jan 2010 00:40:45 -0500
Subject: [R-SIG-Finance] Packages/functions for finance day count
	conventions
In-Reply-To: <2871c9e11001132009s2dc081e5kcb3e9fbe10ba2e8e@mail.gmail.com>
References: <Pine.LNX.4.43.1001131448170.10842@hymn11.u.washington.edu>
	<19278.34732.863130.864518@ron.nulle.part>
	<2871c9e11001132009s2dc081e5kcb3e9fbe10ba2e8e@mail.gmail.com>
Message-ID: <2871c9e11001132140g6013c2fep98ce66f2668eea39@mail.gmail.com>

Hello again,

The QuantLib's DayCounter functions are available in RQuantLib now. It
supports the
following calendars:

Actual360
Actual360FixEd
ActualActual
ActualBusiness252
OneDayCounter
SimpleDayCounter
Thirty360

Please take a look and let me know if you have any problem. Thanks

-k

On Wed, Jan 13, 2010 at 11:09 PM, Khanh Nguyen <knguyen at cs.umb.edu> wrote:
> The codes I committed yesterday port the QuantLib's calendar interface
> here http://quantlib.org/reference/class_quant_lib_1_1_calendar.html
> to RQuantLib.
>
> However, I guess Dr. Zivot need the day counter here
> http://quantlib.org/reference/class_quant_lib_1_1_day_counter.html . I
> ported this to R, but for my little toolbox and not in Rquantlib yet.
> I will do it later tonight...It should be available in RQuantLib
> tomorrow.
>
> -k
>
>
>
> On Wed, Jan 13, 2010 at 9:55 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>>
>> On 13 January 2010 at 14:48, Eric Zivot wrote:
>> | I'm looking for any R packages that have functions for SIA day count
>> | conventions (e.g. actual/actual, 30/360, actual/360 etc). It looks like
>> | RQuantMod handles some of these details internally in C code but they are not
>> | exposed at the R level. Any suggestions would be appreciated. Thanks,
>>
>> There is no RQuantMod we know of but yes, Khanh just yesterday committed a
>> few more date functions to the SVN for RQuantLib so maybe this may be of
>> help. ?[1]
>>
>> These date conventions do exist in QuantLib --- and AFAIK are already used
>> for some curve-building code --- so maybe we just need to sit down and
>> expose them.
>>
>> Hth, Dirk
>>
>> [1] https://r-forge.r-project.org/plugins/scmsvn/viewcvs.php?root=rquantlib&view=rev&rev=135
>>
>> --
>> Three out of two people have difficulties with fractions.
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>>
>


From ctchadwick at hotmail.com  Thu Jan 14 07:41:07 2010
From: ctchadwick at hotmail.com (Todd Chadwick)
Date: Thu, 14 Jan 2010 01:41:07 -0500
Subject: [R-SIG-Finance] fPortfolioSolver Issues
Message-ID: <SNT133-ds3DF28D00D1618B72E2A40C06A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100114/d592bb92/attachment.ksh>

From brian at braverock.com  Thu Jan 14 13:29:38 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 14 Jan 2010 06:29:38 -0600
Subject: [R-SIG-Finance] fPortfolioSolver Issues
In-Reply-To: <SNT133-ds3DF28D00D1618B72E2A40C06A0@phx.gbl>
References: <SNT133-ds3DF28D00D1618B72E2A40C06A0@phx.gbl>
Message-ID: <4B4F0E32.4030502@braverock.com>

Todd Chadwick wrote:
> I'm wondering if any of you are using any of the solvers in the
> fPortfolioSolver by the RMetrics chaps?  I've been trying to install the
> package via RCMD from the source on my Windows XP machine (running R 2.10.1)
> and it gets hung up during the process.  I am really interested in using the
> second-order cone programming optimizer wrapper they provide (working on
> getting a max return optimized portfolio for given target risk).
>   
The fPortfolioSolver examples for

solveRsocp

and

solveRqpqc


works for me on linux.  I don't have time to test on Windows, as I don't 
use that environment for R.

I am wondering why you are trying to install from source on Windows, 
rather than using the binary zip from R-Forge available here:

http://r-forge.r-project.org/R/?group_id=156

> I feel sure there are several ways to do things.  My apologies for burdening
> the list with my rusty operations research skills.   Any help is certainly
> appreciated, and let me know if more info is needed about my install issues.
> If Dr. Wuertz or any of the RMetrics team can chime in, even better.  
>   
If the optimization problem you are hoping to solve is amenable to a 
conical solver, then fPortfolioSolver will be the fastest at finding a 
solution. 

If, however, you have complex constraints that are not amenable to the 
quadratic, linear, and conical constraint and objective structure in the 
RMetrics packages, the PortfolioAnalytics package may be able to let you 
construct a more arbitrary set of constraints and objectives. 

When I get some time, I hope to make the specifications interoperable, 
as well.

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From djsamperi at gmail.com  Fri Jan 15 00:01:55 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 14 Jan 2010 18:01:55 -0500
Subject: [R-SIG-Finance] RcppTemplate user alert
Message-ID: <d4cf43b61001141501j5342b3a1o6c30daca6d109cc3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100114/77ba9323/attachment.pl>

From arnaudb25 at gmail.com  Fri Jan 15 02:16:05 2010
From: arnaudb25 at gmail.com (Arnaud Battistella)
Date: Fri, 15 Jan 2010 02:16:05 +0100
Subject: [R-SIG-Finance] IBrokers
Message-ID: <3f1cfd831001141716u57a564f4h343be522c99f849e@mail.gmail.com>

Hi all,

I recently started using IBrokers and it really is a great package.
But I have some questions about its use:

1. placeOrder seems to work as expected but I was wondering how to
make the command exit by itself and prevent it from returning any
output (unless asked for it).
As it doesn't exit I don't know how to include it in a script as R
hangs on this command waiting for a user interrupt...

2. Is there a way to submit several orders with one placeOrder call?
the usual c() or list() don't work...

3. I was wondering how to extract tick prices from reqMktData.
As of now I simply  obtain them from the csv output as follow:
myWrapper <- eWrapper.MktData.CSV(1)
reqMktData(tws, twsEquity("QQQQ"), eventWrapper=myWrapper, file="data.csv")
and then selecting the right column of data.
Still if I understood correctly tick prices are also stored in .Data
but I could not figure out how to access them...
myWrapper$get.Data("data") only gives the last tick prices

4. Where can I find the column names for the csv output of
eWrapper.MktData.CSV()?

Thanks!

A.


From wuertz at itp.phys.ethz.ch  Fri Jan 15 02:20:15 2010
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Fri, 15 Jan 2010 02:20:15 +0100
Subject: [R-SIG-Finance] R/Rmetrics Conference Singapore, February 19/20
Message-ID: <4B4FC2CF.9020300@itp.phys.ethz.ch>


2nd Announcement


-----------------------------------------------------------------------
R/Rmetrics "Computational Topics in Finance" Conference
National University of Singapore, February 19/20, 2009.
-----------------------------------------------------------------------
www.rmetrics.org


Sponsored by: ETH Zurich, Finance Online Zurich, REvolution Computing 
New Haven, RMI National University of Singapore.

The Rmetrics Organization from the Swiss Federal Institute of Technology 
(ETHZ) and the National University of Singapore invite you to the first 
R Conference in Asia.

R was definitely the shooting star in the financial software world 2009. 
Even the New York Times recently reported about R in an enthusiastic 
article. One can say that R has established itself as the open source 
"rapid model prototyping system" for financial applications in business, 
research and education.

The conference will cover the topics: Econometric Modeling, Financial 
Time Series Analysis, Volatility Forecasting, Trading and Decision 
Making Systems, Portfolio Selection and Optimization, Financial 
Stability Analysis, Stress Testing, Performance Analysis, Benchmarking, 
Risk Analysis and Measurement, Valuation of Financial Derivatives, 
Extreme Value Theory and Copulae, FX High Frequency Data Analysis, Time 
& Sales Data, Monte Carlo Simulation and Pricing, Robust Statistics in 
Finance, Using R/Rmetrics in Finance and Insurance.

Keynote Speakers of the conference include:

 Karim Chine, Cloud Era Ltd Cambridge UK
 Sun Defeng, National University of Singapore
 Juri Hinz, National University of Singapore
 Stefano Iacus, University of Milano
 Marc Paolella, Swiss Banking Institute Zurich
 Vikram Kuriyan, K3 Advisors New York
 David Scott, University of Auckland
 Pradap Sondhi, GF Management Hongkong
 Diethelm Wuertz, ETH Zurich
 Eric Zivot, University of Washington
 ...

We have a limited number of slots for contributed presentations; if you 
are interested in giving a presentation, please contact the organizers: 
submissions at rmetrics.org. Submission will be considered on a rolling 
admission basis.

The conference is recommended to fund and/or risk managers from banks 
andinsurance firms, to researchers from industry and academia, and to 
decision makers. Come, discuss, and get new ideas for your own business 
and research. The topics will be by no means confined to applications 
from R/Rmetrics or related rapid model prototyping systems, the 
conference is also open to theoretical concepts and ideas, behind the 
applications and software solutions.

Preceding the conference, the Rmetrics team is giving a two-day "Basic R 
for Finance" course. For more information, see: 
www.rmetrics.org/basicRsingapore. There is a limited number of free 
scholarships for students, for more information please contact the 
organizers: submissions at rmetrics.org.

We wish you a happy new year and we are looking forward to meet you in 
February at RMI/NUS in Singapore.


For the organizing committee
Diethelm Wuertz ETH Zurich, Juri Hinz NUS Singapore,
Mahendra Mehta NTS Mumbai, David Scott University of Auckland
www.rmetrics.org



///


From cmdr_rogue at hotmail.com  Fri Jan 15 02:35:39 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Thu, 14 Jan 2010 20:35:39 -0500
Subject: [R-SIG-Finance] fPortfolioSolver Issues
In-Reply-To: <4B4F0E32.4030502@braverock.com>
References: <SNT133-ds3DF28D00D1618B72E2A40C06A0@phx.gbl>
	<4B4F0E32.4030502@braverock.com>
Message-ID: <BLU0-SMTP939C658EE5422C9B578CF0E2690@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100114/7534355d/attachment.pl>

From brian at braverock.com  Fri Jan 15 12:05:49 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 15 Jan 2010 05:05:49 -0600
Subject: [R-SIG-Finance] [Fwd: RE:  fPortfolioSolver Issues]
Message-ID: <4B504C0D.2080805@braverock.com>

To the list, in case any one else has insight for Todd.

You would probably need to produce a list of what you're doing, the actual 
shell commands, and the output of 'R CMD build'

If I were you, I'd probably CC whoever is listed as the maintainer for the 
package as well, as not everyone monitors this list every day.

Cheers,

   - Brian

-------- Original Message --------
Subject: RE: [R-SIG-Finance] fPortfolioSolver Issues
Date: Fri, 15 Jan 2010 00:46:37 -0500
From: Todd Chadwick <ctchadwick at hotmail.com>
To: 'Brian G. Peterson' <brian at braverock.com>
References: <SNT133-ds3DF28D00D1618B72E2A40C06A0 at phx.gbl> 
<4B4F0E32.4030502 at braverock.com>

Thanks for the response Brian,

I haven't thought to test it out on Linux which I can do, but it will limit
me when it comes to handing some things off to a client I am putting things
together for.  Currently there isn't a Windows binary on the Rforge site for
the fPortfolioSolver, so that's why I'm installing it from the sources.  I
haven't had any problems with doing this for other packages without
binaries, but for some reason that's not clear it gets hung up when doing
this package.  I was thinking it has something to do with some problems with
some of the dependencies, but it's usually good telling you something is
missing.  With this one, it just stops in mid process.  I wouldn't be
surprised if it was all a Windows thing.

If you have any insights, pass them along.  Thank man,

todd



-----Original Message-----
From: Brian G. Peterson [mailto:brian at braverock.com]
Sent: Thursday, January 14, 2010 7:30 AM
To: Todd Chadwick; R-SIG-Finance mailing list
Subject: Re: [R-SIG-Finance] fPortfolioSolver Issues

Todd Chadwick wrote:
> I'm wondering if any of you are using any of the solvers in the
> fPortfolioSolver by the RMetrics chaps?  I've been trying to install the
> package via RCMD from the source on my Windows XP machine (running R
2.10.1)
> and it gets hung up during the process.  I am really interested in using
the
> second-order cone programming optimizer wrapper they provide (working on
> getting a max return optimized portfolio for given target risk).
>   
The fPortfolioSolver examples for

solveRsocp

and

solveRqpqc


works for me on linux.  I don't have time to test on Windows, as I don't
use that environment for R.

I am wondering why you are trying to install from source on Windows,
rather than using the binary zip from R-Forge available here:

http://r-forge.r-project.org/R/?group_id=156

> I feel sure there are several ways to do things.  My apologies for
burdening
> the list with my rusty operations research skills.   Any help is certainly
> appreciated, and let me know if more info is needed about my install
issues.
> If Dr. Wuertz or any of the RMetrics team can chime in, even better.  
>   
If the optimization problem you are hoping to solve is amenable to a
conical solver, then fPortfolioSolver will be the fastest at finding a
solution.

If, however, you have complex constraints that are not amenable to the
quadratic, linear, and conical constraint and objective structure in the
RMetrics packages, the PortfolioAnalytics package may be able to let you
construct a more arbitrary set of constraints and objectives.

When I get some time, I hope to make the specifications interoperable,
as well.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock



-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From fjpcaballero at gmail.com  Sat Jan 16 18:44:26 2010
From: fjpcaballero at gmail.com (Francisco Javier Perez Caballero)
Date: Sat, 16 Jan 2010 12:44:26 -0500
Subject: [R-SIG-Finance] IBrokers - twsConnect error
Message-ID: <86319cea1001160944p77f953f0mea644ef5369a647a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100116/822cf2f8/attachment.pl>

From jeff.a.ryan at gmail.com  Sat Jan 16 19:00:18 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sat, 16 Jan 2010 12:00:18 -0600
Subject: [R-SIG-Finance] IBrokers - twsConnect error
In-Reply-To: <86319cea1001160944p77f953f0mea644ef5369a647a@mail.gmail.com>
References: <86319cea1001160944p77f953f0mea644ef5369a647a@mail.gmail.com>
Message-ID: <e8e755251001161000q1a2799ceo18a6051606fe31ab@mail.gmail.com>

The version if IBrokers is more important that the version of Java, at
least as far as debugging an IBrokers issue.  The version IBrokers
corresponds to is 9.62 of the API.  The TWS shouldn't be that
important.

sessionInfo() as described in the posting guide.

Best bet is to install from the googlecode repos:

  http://code.google.com/p/ibrokers/source/checkout

Most likely this will solve the issue.  I'll get a new one to CRAN
just in case CRAN isn't up to date.

Best,
Jeff

On Sat, Jan 16, 2010 at 11:44 AM, Francisco Javier Perez Caballero
<fjpcaballero at gmail.com> wrote:
> I'm getting the following error:
>
>> tws <- twsConnect()
> Error in structure(list(s, clientId = clientId, port = port, server.version
> = SERVER_VERSION, ?:
> ?object 'SERVER_VERSION' not found
>
> I see in the mailing list that this error already appeared in late 2008 and
> had been patched (
> https://stat.ethz.ch/pipermail/r-sig-finance/2008q4/003252.html), so I
> wondering what's going on. I'm running R 2.10.1 on Linux 64 2.6.31-16
> (Ubuntu), TraderWorkstation Build 901.7, Java Version: 1.6.0_15.
>
> Thanks
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From fjpcaballero at gmail.com  Sat Jan 16 23:37:42 2010
From: fjpcaballero at gmail.com (Francisco Javier Perez Caballero)
Date: Sat, 16 Jan 2010 17:37:42 -0500
Subject: [R-SIG-Finance] IBrokers - twsConnect error
In-Reply-To: <e8e755251001161000q1a2799ceo18a6051606fe31ab@mail.gmail.com>
References: <86319cea1001160944p77f953f0mea644ef5369a647a@mail.gmail.com>
	<e8e755251001161000q1a2799ceo18a6051606fe31ab@mail.gmail.com>
Message-ID: <86319cea1001161437m6db01037t9928d2cc7e13472b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100116/f11ebf22/attachment.pl>

From zhucai4 at gmail.com  Mon Jan 18 05:43:13 2010
From: zhucai4 at gmail.com (zhucai4)
Date: Sun, 17 Jan 2010 20:43:13 -0800
Subject: [R-SIG-Finance] A question about the package "ccgarch"
Message-ID: <201001172043116565180@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100117/4351d140/attachment.pl>

From brian at braverock.com  Sun Jan 17 13:50:50 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 17 Jan 2010 06:50:50 -0600
Subject: [R-SIG-Finance] A question about the package "ccgarch"
In-Reply-To: <201001172043116565180@gmail.com>
References: <201001172043116565180@gmail.com>
Message-ID: <4B5307AA.2090309@braverock.com>

The .Call is calling some other compiled code. See the R package 
development documentation.

zhucai4 wrote:
> Hello everyone:
>
> I am a new user to the package "ccgarch". I have a question about one function "dcc.estimation" in the package. In this function , a subfunction "vector.garch" is used to calculate conditional variances. However, when I type: 
>   
>> library(ccgarch)
>> vector.garch
>>     
> the code of "vector.garch" is as follows:
> function (dvar, a, A, B) 
> {
>     dvar <- dvar^2
>     .Call("vector_garch", dvar, a, A, B)
> }
> <environment: namespace:ccgarch>
>
> And I find the "vector_garch" in the source code zip, the code is as follows:
> #computing vector GARCH volatilities: valid for CCC, ECCC, DCC, EDCC models
> vector.garch <- function(dvar, a, A, B){
>       dvar <- dvar^2           # dvar = eps
>      .Call("vector_garch", dvar, a, A, B)
> }
>
> My question is : how can these lines of code be able to calculate conditional variances in the package? I feel confused.
>
> Thank you very much for any help about my problem.
>                                                                            ZHU Cai
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>   


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From robert.nicholson at gmail.com  Sun Jan 17 19:55:07 2010
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Sun, 17 Jan 2010 12:55:07 -0600
Subject: [R-SIG-Finance] Which tool to analyze past trade history?
Message-ID: <4FC624F5-B4C2-4687-A033-4EE1D0454730@gmail.com>

Fidelity gives you trade history where each trade is a separate line in a CSV file.

Which tool does the best job of letting you enter and exit positions ie. knows when it's closing an existing position and entering a new one and then provide a report on each position taken etc?


From otis at zhaw.ch  Sun Jan 17 20:11:07 2010
From: otis at zhaw.ch (Otziger Simon (otis))
Date: Sun, 17 Jan 2010 20:11:07 +0100
Subject: [R-SIG-Finance] Which tool to analyze past trade history?
In-Reply-To: <4FC624F5-B4C2-4687-A033-4EE1D0454730@gmail.com>
References: <4FC624F5-B4C2-4687-A033-4EE1D0454730@gmail.com>
Message-ID: <6CD66F8F-B148-4C41-AD39-A64E03A9AB54@zhaw.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100117/f71d2596/attachment.pl>

From veepsirtt at gmail.com  Mon Jan 18 00:04:15 2010
From: veepsirtt at gmail.com (Velappan Periasamy)
Date: Mon, 18 Jan 2010 04:34:15 +0530
Subject: [R-SIG-Finance] Reading nsedata price series
In-Reply-To: <ff91746c1001100113i3676becp7793e893cb5819bf@mail.gmail.com>
References: <c224dc731001092227l24869db8s7ebf1f81b3b5ed12@mail.gmail.com>
	<8ed68eed1001092242w2e3a8a93o4607daae52579a01@mail.gmail.com>
	<c224dc731001092335we822fc8wc0346cdcabb0059c@mail.gmail.com>
	<ff91746c1001100113i3676becp7793e893cb5819bf@mail.gmail.com>
Message-ID: <c224dc731001171504x496e0b7bhd08ef7685f0a415d@mail.gmail.com>

this link gives me corrupted data.how to unzip it?.
mydata <- read.csv("http://nseindia.com/content/historical/EQUITIES/2010/JAN/cm15JAN2010bhav.csv.zip")
thanks
v.periasamy


From brian at braverock.com  Mon Jan 18 00:27:24 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 17 Jan 2010 17:27:24 -0600
Subject: [R-SIG-Finance] Reading nsedata price series
In-Reply-To: <c224dc731001171504x496e0b7bhd08ef7685f0a415d@mail.gmail.com>
References: <c224dc731001092227l24869db8s7ebf1f81b3b5ed12@mail.gmail.com>	<8ed68eed1001092242w2e3a8a93o4607daae52579a01@mail.gmail.com>	<c224dc731001092335we822fc8wc0346cdcabb0059c@mail.gmail.com>	<ff91746c1001100113i3676becp7793e893cb5819bf@mail.gmail.com>
	<c224dc731001171504x496e0b7bhd08ef7685f0a415d@mail.gmail.com>
Message-ID: <4B539CDC.40901@braverock.com>

Velappan Periasamy wrote:
> this link gives me corrupted data.how to unzip it?.
> mydata <- read.csv("http://nseindia.com/content/historical/EQUITIES/2010/JAN/cm15JAN2010bhav.csv.zip")

??zip

This has nothing to do with finance, has been amply covered in the list 
archives of the R lists and data import/export documentation, and if you really 
couldn't find the answer on your own, should have gone to R-help.


From minkymorgan at gmail.com  Mon Jan 18 00:55:44 2010
From: minkymorgan at gmail.com (andrew morgan)
Date: Sun, 17 Jan 2010 23:55:44 +0000
Subject: [R-SIG-Finance] addTA error message with text()
Message-ID: <317ffdf51001171555uce8d0bdu403f1c7d423b8120@mail.gmail.com>

Hi list,

I'm trying to use text() with addTA + chartSeries to label points.
In testing this idea out, I'm getting an error message I don't know
how to interpret.
Can anyone explain what it means, or what I'm doing wrong here?

Contrived example, and error message below.

BARC <- get.hist.quote(instrument = "BARC.L", start = "2000-01-01",
end = "2010-04-04")
chartSeries(BARC)
addTA(text(index(BARC), BARC$Close, as.character(BARC$Close)))

# error is:
Error in addTA(text(index(BARC), BARC$Close, as.character(BARC$Close))) :
  non-xtsible data must match the length of the underlying series

In what way is the data not the same length?
Is there a simple way to label points?

many thanks

Andrew


From jeff.a.ryan at gmail.com  Mon Jan 18 01:47:27 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sun, 17 Jan 2010 18:47:27 -0600
Subject: [R-SIG-Finance] addTA error message with text()
In-Reply-To: <317ffdf51001171555uce8d0bdu403f1c7d423b8120@mail.gmail.com>
References: <317ffdf51001171555uce8d0bdu403f1c7d423b8120@mail.gmail.com>
Message-ID: <e8e755251001171647m11c69550g4a8124075664ca84@mail.gmail.com>

There are two problems:

?addTA
Both 'addTA' and 'newTA' can be used to dynamically add custom
     content to a displayed chart.

     'addTA' takes a series of values, either in a form coercible to
     'xts' or of the same length as the charted series has rows, and
     displays the results in either a new TA sub-window, or

So text() isn't "a series of values".  Clearly not the same length, or
anything remotely like the requirements.

The second is the chart from chartSeries doesn't use "index" for an
x-axis, it is closer to:

x.pos <- 1 + x at spacing * (1:x at length - 1)

Though as the docs mention chartSeries isn't really compatible with
base graphics anyway.

So what you want is _possible_, but is probably not going to be what
you really want:

Try:

> chartSeries(BARC,TA=NULL)
> text(1:NROW(BARC), Cl(BARC), labels=Cl(BARC), col='white')

You'll see that it is a visual disaster.  If you tell us what you want
to accomplish, it may be easier to redirect you.

One final comment, chartSeries in quantmod is about 2 weeks away from
the introduction of an updated set of charting tools.  These will
allow for much more mixing with traditional graphics in R.  I'll keep
the list posted when this is available.

Best,
Jeff




On Sun, Jan 17, 2010 at 5:55 PM, andrew morgan <minkymorgan at gmail.com> wrote:
> Hi list,
>
> I'm trying to use text() with addTA + chartSeries to label points.
> In testing this idea out, I'm getting an error message I don't know
> how to interpret.
> Can anyone explain what it means, or what I'm doing wrong here?
>
> Contrived example, and error message below.
>
> BARC <- get.hist.quote(instrument = "BARC.L", start = "2000-01-01",
> end = "2010-04-04")
> chartSeries(BARC)
> addTA(text(index(BARC), BARC$Close, as.character(BARC$Close)))
>
> # error is:
> Error in addTA(text(index(BARC), BARC$Close, as.character(BARC$Close))) :
> ?non-xtsible data must match the length of the underlying series
>
> In what way is the data not the same length?
> Is there a simple way to label points?
>
> many thanks
>
> Andrew
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From risk2009 at ath.forthnet.gr  Mon Jan 18 15:54:23 2010
From: risk2009 at ath.forthnet.gr (Research)
Date: Mon, 18 Jan 2010 16:54:23 +0200
Subject: [R-SIG-Finance] 5th of month working day
Message-ID: <4B54761F.6020606@ath.forthnet.gr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100118/1919a574/attachment.pl>

From ggrothendieck at gmail.com  Mon Jan 18 16:16:56 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 18 Jan 2010 10:16:56 -0500
Subject: [R-SIG-Finance] 5th of month working day
In-Reply-To: <4B54761F.6020606@ath.forthnet.gr>
References: <4B54761F.6020606@ath.forthnet.gr>
Message-ID: <971536df1001180716s5eea5424vbf1dc105e94881fd@mail.gmail.com>

On Mon, Jan 18, 2010 at 9:54 AM, Research <risk2009 at ath.forthnet.gr> wrote:
> Hello,
>
> I have a daily data zoo object with ?prices such as:
>
> 05/04/2006 ? ? ?1311.56
> 06/04/2006 ? ? ?1309.04
> 07/04/2006 ? ? ?1295.5
> 10/04/2006 ? ? ?1296.6
> 11/04/2006 ? ? ?1286.57
> 12/04/2006 ? ? ?1288.12
> 13/04/2006 ? ? ?1289.12
> 14/04/2006 ? ? ?1289.12
> 17/04/2006 ? ? ?1285.33
> 18/04/2006 ? ? ?1307.65
> 19/04/2006 ? ? ?1309.93
> 20/04/2006 ? ? ?1311.46
> 21/04/2006 ? ? ?1311.28
> 24/04/2006 ? ? ?1308.11
> 25/04/2006 ? ? ?1301.74
> 26/04/2006 ? ? ?1305.41
> 27/04/2006 ? ? ?1309.72
> 28/04/2006 ? ? ?1310.61
> 01/05/2006 ? ? ?1305.19
> 02/05/2006 ? ? ?1313.21
> 03/05/2006 ? ? ?1307.85
> 04/05/2006 ? ? ?1312.25
> 05/05/2006 ? ? ?1325.76
>
>
>
> How can I isolate the 5th day of each month (if this was a
> working/trading day) otherwise the most recent (before the 5th) working
> day for each month?
>

Your sample data always has the 5th of the month filled in but
assuming that that is not the case for the real data, merge your
series with a zero width series having every date and use na.locf to
move values up into subsequent NAs.  Then just pick off the 5th of
each month.

Lines <- "05/04/2006      1311.56
06/04/2006      1309.04
07/04/2006      1295.5
10/04/2006      1296.6
11/04/2006      1286.57
12/04/2006      1288.12
13/04/2006      1289.12
14/04/2006      1289.12
17/04/2006      1285.33
18/04/2006      1307.65
19/04/2006      1309.93
20/04/2006      1311.46
21/04/2006      1311.28
24/04/2006      1308.11
25/04/2006      1301.74
26/04/2006      1305.41
27/04/2006      1309.72
28/04/2006      1310.61
01/05/2006      1305.19
02/05/2006      1313.21
03/05/2006      1307.85
04/05/2006      1312.25
05/05/2006      1325.76"
library(zoo)
z <- read.zoo(textConnection(Lines), format = "%d/%m/%Y")
rng <- range(time(z))
zz <- na.locf(merge(z, zoo(, seq(rng[1], rng[2], by = "day"))))
zz[format(time(zz), "%d") == "05"]


From comtech.usa at gmail.com  Mon Jan 18 16:57:31 2010
From: comtech.usa at gmail.com (Michael)
Date: Mon, 18 Jan 2010 10:57:31 -0500
Subject: [R-SIG-Finance] Any quant trading conference in 2010?
Message-ID: <b1f16d9d1001180757l7c175701u1a8ce9e2d206f0d8@mail.gmail.com>

Happy new year folks!

Anybody has a list of quant trading conference/seminars in 2010?

Thanks!


From brian at braverock.com  Mon Jan 18 17:09:56 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 18 Jan 2010 10:09:56 -0600
Subject: [R-SIG-Finance] Any quant trading conference in 2010?
In-Reply-To: <b1f16d9d1001180757l7c175701u1a8ce9e2d206f0d8@mail.gmail.com>
References: <b1f16d9d1001180757l7c175701u1a8ce9e2d206f0d8@mail.gmail.com>
Message-ID: <4B5487D4.3070809@braverock.com>

Michael wrote:
> Happy new year folks!
>
> Anybody has a list of quant trading conference/seminars in 2010?
>   
Well, there's clearly: http://www.rinfinance.com/

Other than that, all the other 'quant' ones I've seen have been very 
vendor-focused (but I'm biased).

However, for more general 'finance' conferences, JoF maintains a list, 
AFA maintains a list, EFA maintains a list...  Google is your friend.

Cheers,

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From daniel.cegielka at gmail.com  Mon Jan 18 17:18:38 2010
From: daniel.cegielka at gmail.com (Daniel Cegielka)
Date: Mon, 18 Jan 2010 17:18:38 +0100
Subject: [R-SIG-Finance] Any quant trading conference in 2010?
In-Reply-To: <b1f16d9d1001180757l7c175701u1a8ce9e2d206f0d8@mail.gmail.com>
References: <b1f16d9d1001180757l7c175701u1a8ce9e2d206f0d8@mail.gmail.com>
Message-ID: <4B5489DE.8040409@gmail.com>

http://www.rinfinance.com/

http://www.rmetrics.org/

best
daniel


W dniu 18.01.2010 16:57, Michael pisze:
> Happy new year folks!
>
> Anybody has a list of quant trading conference/seminars in 2010?
>
> Thanks!
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From edd at debian.org  Mon Jan 18 17:34:50 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 18 Jan 2010 10:34:50 -0600
Subject: [R-SIG-Finance] Any quant trading conference in 2010?
In-Reply-To: <b1f16d9d1001180757l7c175701u1a8ce9e2d206f0d8@mail.gmail.com>
References: <b1f16d9d1001180757l7c175701u1a8ce9e2d206f0d8@mail.gmail.com>
Message-ID: <19284.36266.688962.640430@ron.nulle.part>


http://lmgtfy.com/?q=quant+finance+conference+2010

Thanks to Brian and Dan for helpful and timely answers that even provided R
context, but I suggest we stop the thread here as the QUESTION had nothing to
do with either R or Finance.

Moroever, the question showed an astounding unwillingness of doing any
personal research whatsoever.  Let's not support that any further.

Dirk

-- 
Three out of two people have difficulties with fractions.


From edd at debian.org  Mon Jan 18 17:51:14 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 18 Jan 2010 10:51:14 -0600
Subject: [R-SIG-Finance] Any quant trading conference in 2010?
In-Reply-To: <19284.36266.688962.640430@ron.nulle.part>
References: <b1f16d9d1001180757l7c175701u1a8ce9e2d206f0d8@mail.gmail.com>
	<19284.36266.688962.640430@ron.nulle.part>
Message-ID: <19284.37250.799994.333959@ron.nulle.part>


On 18 January 2010 at 10:34, Dirk Eddelbuettel wrote:
| http://lmgtfy.com/?q=quant+finance+conference+2010
| 
| Thanks to Brian and Dan for helpful and timely answers that even provided R
| context, but I suggest we stop the thread here as the QUESTION had nothing to
| do with either R or Finance.

s/either R or Finance/with R-SIG-Finance/

Dirk
 
| Moroever, the question showed an astounding unwillingness of doing any
| personal research whatsoever.  Let's not support that any further.
| 
| Dirk
| 
| -- 
| Three out of two people have difficulties with fractions.
| 
| _______________________________________________
| R-SIG-Finance at stat.math.ethz.ch mailing list
| https://stat.ethz.ch/mailman/listinfo/r-sig-finance
| -- Subscriber-posting only. If you want to post, subscribe first.
| -- Also note that this is not the r-help list where general R questions should go.

-- 
Three out of two people have difficulties with fractions.


From wuertz at itp.phys.ethz.ch  Mon Jan 18 18:31:42 2010
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Mon, 18 Jan 2010 18:31:42 +0100
Subject: [R-SIG-Finance] 5th of month working day
In-Reply-To: <971536df1001180716s5eea5424vbf1dc105e94881fd@mail.gmail.com>
References: <4B54761F.6020606@ath.forthnet.gr>
	<971536df1001180716s5eea5424vbf1dc105e94881fd@mail.gmail.com>
Message-ID: <4B549AFE.4090008@itp.phys.ethz.ch>

Since I do not understand Gabor's solution I add my suggestion to
solve the problem ...

 > require(timeSeries)
 >
 > # Compose for 2006 a calendar with the first 5 days in each month:
 > years = rep(2006, times = 60)
 > months = rep(1:12, each = 5)
 > days = rep(1:5, times = 12)
 > tD = timeCalendar(years, months, days)
 > tD
GMT
 [1] [2006-01-01] [2006-01-02] [2006-01-03] [2006-01-04] [2006-01-05]
 [6] [2006-02-01] [2006-02-02] [2006-02-03] [2006-02-04] [2006-02-05]
[11] [2006-03-01] [2006-03-02] [2006-03-03] [2006-03-04] [2006-03-05]
[16] [2006-04-01] [2006-04-02] [2006-04-03] [2006-04-04] [2006-04-05]
[21] [2006-05-01] [2006-05-02] [2006-05-03] [2006-05-04] [2006-05-05]
[26] [2006-06-01] [2006-06-02] [2006-06-03] [2006-06-04] [2006-06-05]
[31] [2006-07-01] [2006-07-02] [2006-07-03] [2006-07-04] [2006-07-05]
[36] [2006-08-01] [2006-08-02] [2006-08-03] [2006-08-04] [2006-08-05]
[41] [2006-09-01] [2006-09-02] [2006-09-03] [2006-09-04] [2006-09-05]
[46] [2006-10-01] [2006-10-02] [2006-10-03] [2006-10-04] [2006-10-05]
[51] [2006-11-01] [2006-11-02] [2006-11-03] [2006-11-04] [2006-11-05]
[56] [2006-12-01] [2006-12-02] [2006-12-03] [2006-12-04] [2006-12-05]
 >
 > # Then extract the Business days (not weekdays!) according
 > #   to a given holiday Calendar, here I used the NYSE holiday 
calendar for 2006
 > #   Note with Rmetrics you can create your own business calendars!
 > tM = matrix(as.integer(isBizday(tD, holidayNYSE(2006))), byrow = 
TRUE, ncol = 5)
 > rownames(tM) = paste(200600+1:12)
 > colnames(tM) = paste(1:5)
 > tM
       1 2 3 4 5
200601 0 0 1 1 1
200602 1 1 1 0 0
200603 1 1 1 0 0
200604 0 0 1 1 1
200605 1 1 1 1 1
200606 1 1 0 0 1
200607 0 0 1 0 1
200608 1 1 1 1 0
200609 1 0 0 0 1
200610 0 1 1 1 1
200611 1 1 1 0 0
200612 1 0 0 1 1
 >
 > # Then isolate the 5th day of each month if this was a business day
 > #     otherwise the most recent business day before the 5th working
 > #     day for each month - this is what you want, or?
 > # Take care, there may be again holidays in between previous working
 > #     days!! Here they are handled properly.
 > tW = t(apply(tM, 1, cumsum))[,5:1]
 > tW
       5 4 3 2 1
200601 3 2 1 0 0
200602 3 3 3 2 1
200603 3 3 3 2 1
200604 3 2 1 0 0
200605 5 4 3 2 1
200606 3 2 2 2 1
200607 2 1 1 0 0
200608 4 4 3 2 1
200609 2 1 1 1 1
200610 4 3 2 1 0
200611 3 3 3 2 1
200612 3 2 1 1 1
 > tIndex = which(t(tW) == 1)
 >
 >
 > # After having the Index, you can get the timeDate objects for 2006
 > tD[tIndex]
GMT
 [1] [2006-01-03] [2006-02-05] [2006-03-05] [2006-04-03] [2006-05-05]
 [6] [2006-06-05] [2006-07-02] [2006-07-03] [2006-08-05] [2006-09-02]
[11] [2006-09-03] [2006-09-04] [2006-09-05] [2006-10-04] [2006-11-05]
[16] [2006-12-03] [2006-12-04] [2006-12-05]
 >
 > # and finally index your time series with the timeDate objects.
 > # Isn't it powerful to use timeDate and timeSeries objects?

Exercise: write a small function to extract the n-th business day for
each month of a timeDate calendar object given a specific holiday Calendar

enjoy Rmetrics!

Diethelm 

PS: I found this example really nice to show what timeDate and timeSeries
methods can do for you, I will add this example to the FAQ's in the next
edition of our timeSeries FAQ e-book: http://www.rmetrics.org/node/8


-----------------------




Gabor Grothendieck wrote:
> On Mon, Jan 18, 2010 at 9:54 AM, Research <risk2009 at ath.forthnet.gr> wrote:
>> Hello,
>>
>> I have a daily data zoo object with  prices such as:
>>
>> 05/04/2006      1311.56
>> 06/04/2006      1309.04
>> 07/04/2006      1295.5
>> 10/04/2006      1296.6
>> 11/04/2006      1286.57
>> 12/04/2006      1288.12
>> 13/04/2006      1289.12
>> 14/04/2006      1289.12
>> 17/04/2006      1285.33
>> 18/04/2006      1307.65
>> 19/04/2006      1309.93
>> 20/04/2006      1311.46
>> 21/04/2006      1311.28
>> 24/04/2006      1308.11
>> 25/04/2006      1301.74
>> 26/04/2006      1305.41
>> 27/04/2006      1309.72
>> 28/04/2006      1310.61
>> 01/05/2006      1305.19
>> 02/05/2006      1313.21
>> 03/05/2006      1307.85
>> 04/05/2006      1312.25
>> 05/05/2006      1325.76
>>
>>
>>
>> How can I isolate the 5th day of each month (if this was a
>> working/trading day) otherwise the most recent (before the 5th) working
>> day for each month?
>>
>
> Your sample data always has the 5th of the month filled in but
> assuming that that is not the case for the real data, merge your
> series with a zero width series having every date and use na.locf to
> move values up into subsequent NAs.  Then just pick off the 5th of
> each month.
>
> Lines <- "05/04/2006      1311.56
> 06/04/2006      1309.04
> 07/04/2006      1295.5
> 10/04/2006      1296.6
> 11/04/2006      1286.57
> 12/04/2006      1288.12
> 13/04/2006      1289.12
> 14/04/2006      1289.12
> 17/04/2006      1285.33
> 18/04/2006      1307.65
> 19/04/2006      1309.93
> 20/04/2006      1311.46
> 21/04/2006      1311.28
> 24/04/2006      1308.11
> 25/04/2006      1301.74
> 26/04/2006      1305.41
> 27/04/2006      1309.72
> 28/04/2006      1310.61
> 01/05/2006      1305.19
> 02/05/2006      1313.21
> 03/05/2006      1307.85
> 04/05/2006      1312.25
> 05/05/2006      1325.76"
> library(zoo)
> z <- read.zoo(textConnection(Lines), format = "%d/%m/%Y")
> rng <- range(time(z))
> zz <- na.locf(merge(z, zoo(, seq(rng[1], rng[2], by = "day"))))
> zz[format(time(zz), "%d") == "05"]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>
>


From wuertz at itp.phys.ethz.ch  Mon Jan 18 19:12:41 2010
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Mon, 18 Jan 2010 19:12:41 +0100
Subject: [R-SIG-Finance] R/Rmetrics Internships a t ETH Zurich
Message-ID: <4B54A499.3020508@itp.phys.ethz.ch>


We are offering R/Rmetrics Student Internships at ETH Zurich, for a two 
to three months stay in Zurich (www.ethz.ch) working in research 
projects and software development projects on volatility forecasting, 
risk management, portfolio optimization, and financial stability. The 
Internships will be offered under the 2010 ThinkSwiss Research 
Scholarship Program.

Diethelm Wuertz


--------------------------


ThinkSwiss offers 15 scholarships for a research stay in Switzerland. 
This scholarship program supports highly motivated and qualified U.S. 
undergraduate and graduate students to do research at a public Swiss 
university or research institute for 2 to 3 months. The scholarship is 
open to students of all fields.

To apply for a ThinkSwiss Research Scholarship, you must:
- Be currently enrolled at an accredited U.S. university/college
- Be a graduate student or an undergraduate student who will have 
completed your sophomore year by the time the research stay in 
Switzerland begins
- Provide a written confirmation from a professor at a Swiss university 
that he/she will accept you for a research stay in his/her group

This program does not provide health, accident or liability insurance. 
Applicants must make sure that they have
insurance coverage applicable for their stay in Switzerland. While 
German, French or Italian language skills are not required for the 
research stay in Switzerland, knowledge of any of these languages would 
be helpful in daily life. The working language will generally be English.

The ThinkSwiss Research Scholarship program provides a monthly 
scholarship of CHF 1,050 (approx. USD 1,000) for a period of 2 to 3 
months (CHF 3,150 maximum), which covers two thirds of the average 
student?s living costs. By accepting this scholarship, you agree to 
participate in a blog to share your experiences during your research 
stay in Switzerland. After your return to the U.S. you also agree to 
carry out at least one activity as student ?ambassador? to promote Swiss 
research. Half of the scholarship will be paid at the beginning and half 
at the end of your research stay, after your final report has been 
received. ? To get a better idea, please visit:
http://thinkswiss-research.blogspot.com/

Application (deadline: March 31, 2010)

If you are interested in the ThinkSwiss Research Scholarship program, 
please send the following documents by e-mail to the contact address below:
- Cover letter, including information about your educational and 
professional background, goals for your research stay in Switzerland, 
why you have chosen that particular Swiss university, give one reason 
why you would make an excellent student ?ambassador? and suggest an 
activity with which you could promote Swiss research at your U.S. university
- Letter of acceptance by a professor at a Swiss university into his/her 
research group
- A current official university/college transcript
- A letter of reference from a senior academic in your field of study

Embassy of Switzerland, Office of Science, Technology and Higher 
Education (OSTHE),
2900 Cathedral Ave., N.W., Washington, D.C. 20008

E-mail: was.science at eda.admin.ch, Phone: (202) 745-7958
Website: www.eda.admin.ch/washington/Studying_in_Switzerland
www.sbf.admin.ch/campus-switzerland


From ggrothendieck at gmail.com  Tue Jan 19 15:20:05 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 19 Jan 2010 09:20:05 -0500
Subject: [R-SIG-Finance] 5th of month working day
In-Reply-To: <971536df1001180716s5eea5424vbf1dc105e94881fd@mail.gmail.com>
References: <4B54761F.6020606@ath.forthnet.gr>
	<971536df1001180716s5eea5424vbf1dc105e94881fd@mail.gmail.com>
Message-ID: <971536df1001190620l54f2b904w10ac87ea22eaec94@mail.gmail.com>

Here is a second example that does the same thing except (that is it
returns the last value on or prior to the 5th); however, in the prior
solution the date was shown as the 5th and in this one it is shown as
the date of the last filled in value.  Not sure which you would
prefer.  See ?na.locf for more info on moving values forward into NAs
and also read the three vignettes that come with zoo.

# same as your example except I have removed the 5ths of the month and
added 4/4/2006.

Lines <- "
04/04/2006      1311.56
06/04/2006      1309.04
07/04/2006      1295.5
10/04/2006      1296.6
11/04/2006      1286.57
12/04/2006      1288.12
13/04/2006      1289.12
14/04/2006      1289.12
17/04/2006      1285.33
18/04/2006      1307.65
19/04/2006      1309.93
20/04/2006      1311.46
21/04/2006      1311.28
24/04/2006      1308.11
25/04/2006      1301.74
26/04/2006      1305.41
27/04/2006      1309.72
28/04/2006      1310.61
01/05/2006      1305.19
02/05/2006      1313.21
03/05/2006      1307.85
04/05/2006      1312.25
06/05/2006      1325.76"

        library(zoo)
	z <- read.zoo(textConnection(Lines), format = "%d/%m/%Y")

# z.na is same as z but with missing days added using NAs
# Its formed by merging z with a zoo-width series containing all days.

	rng <- range(time(z))
	z.na <- merge(z, zoo(, seq(rng[1], rng[2], by = "day")))

# form a series that has NAs wherever z.na does but has 1, 2, 3, ...
# instead of z.na's data values and then use na.locf to fill in NAs

	idx <- na.locf(seq_along(z.na) + (0 * z.na))

# pick off elements of z.na corresponding to 5th of month

	z.na[idx[format(time(z.na), "%d") == "05"]]


Here is the final result:

2006-04-04 2006-05-04
   1311.56    1312.25


On Mon, Jan 18, 2010 at 10:16 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> On Mon, Jan 18, 2010 at 9:54 AM, Research <risk2009 at ath.forthnet.gr> wrote:
>> Hello,
>>
>> I have a daily data zoo object with ?prices such as:
>>
>> 05/04/2006 ? ? ?1311.56
>> 06/04/2006 ? ? ?1309.04
>> 07/04/2006 ? ? ?1295.5
>> 10/04/2006 ? ? ?1296.6
>> 11/04/2006 ? ? ?1286.57
>> 12/04/2006 ? ? ?1288.12
>> 13/04/2006 ? ? ?1289.12
>> 14/04/2006 ? ? ?1289.12
>> 17/04/2006 ? ? ?1285.33
>> 18/04/2006 ? ? ?1307.65
>> 19/04/2006 ? ? ?1309.93
>> 20/04/2006 ? ? ?1311.46
>> 21/04/2006 ? ? ?1311.28
>> 24/04/2006 ? ? ?1308.11
>> 25/04/2006 ? ? ?1301.74
>> 26/04/2006 ? ? ?1305.41
>> 27/04/2006 ? ? ?1309.72
>> 28/04/2006 ? ? ?1310.61
>> 01/05/2006 ? ? ?1305.19
>> 02/05/2006 ? ? ?1313.21
>> 03/05/2006 ? ? ?1307.85
>> 04/05/2006 ? ? ?1312.25
>> 05/05/2006 ? ? ?1325.76
>>
>>
>>
>> How can I isolate the 5th day of each month (if this was a
>> working/trading day) otherwise the most recent (before the 5th) working
>> day for each month?
>>
>
> Your sample data always has the 5th of the month filled in but
> assuming that that is not the case for the real data, merge your
> series with a zero width series having every date and use na.locf to
> move values up into subsequent NAs. ?Then just pick off the 5th of
> each month.
>
> Lines <- "05/04/2006 ? ? ?1311.56
> 06/04/2006 ? ? ?1309.04
> 07/04/2006 ? ? ?1295.5
> 10/04/2006 ? ? ?1296.6
> 11/04/2006 ? ? ?1286.57
> 12/04/2006 ? ? ?1288.12
> 13/04/2006 ? ? ?1289.12
> 14/04/2006 ? ? ?1289.12
> 17/04/2006 ? ? ?1285.33
> 18/04/2006 ? ? ?1307.65
> 19/04/2006 ? ? ?1309.93
> 20/04/2006 ? ? ?1311.46
> 21/04/2006 ? ? ?1311.28
> 24/04/2006 ? ? ?1308.11
> 25/04/2006 ? ? ?1301.74
> 26/04/2006 ? ? ?1305.41
> 27/04/2006 ? ? ?1309.72
> 28/04/2006 ? ? ?1310.61
> 01/05/2006 ? ? ?1305.19
> 02/05/2006 ? ? ?1313.21
> 03/05/2006 ? ? ?1307.85
> 04/05/2006 ? ? ?1312.25
> 05/05/2006 ? ? ?1325.76"
> library(zoo)
> z <- read.zoo(textConnection(Lines), format = "%d/%m/%Y")
> rng <- range(time(z))
> zz <- na.locf(merge(z, zoo(, seq(rng[1], rng[2], by = "day"))))
> zz[format(time(zz), "%d") == "05"]
>


From ggrothendieck at gmail.com  Tue Jan 19 15:21:28 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 19 Jan 2010 09:21:28 -0500
Subject: [R-SIG-Finance] 5th of month working day
In-Reply-To: <971536df1001190620l54f2b904w10ac87ea22eaec94@mail.gmail.com>
References: <4B54761F.6020606@ath.forthnet.gr>
	<971536df1001180716s5eea5424vbf1dc105e94881fd@mail.gmail.com> 
	<971536df1001190620l54f2b904w10ac87ea22eaec94@mail.gmail.com>
Message-ID: <971536df1001190621s1bb9d117j87396955080bd56a@mail.gmail.com>

The first line should have read

Here is a second example that does the same thing (that is it

On Tue, Jan 19, 2010 at 9:20 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> Here is a second example that does the same thing except (that is it
> returns the last value on or prior to the 5th); however, in the prior
> solution the date was shown as the 5th and in this one it is shown as
> the date of the last filled in value. ?Not sure which you would
> prefer. ?See ?na.locf for more info on moving values forward into NAs
> and also read the three vignettes that come with zoo.
>
> # same as your example except I have removed the 5ths of the month and
> added 4/4/2006.
>
> Lines <- "
> 04/04/2006 ? ? ?1311.56
> 06/04/2006 ? ? ?1309.04
> 07/04/2006 ? ? ?1295.5
> 10/04/2006 ? ? ?1296.6
> 11/04/2006 ? ? ?1286.57
> 12/04/2006 ? ? ?1288.12
> 13/04/2006 ? ? ?1289.12
> 14/04/2006 ? ? ?1289.12
> 17/04/2006 ? ? ?1285.33
> 18/04/2006 ? ? ?1307.65
> 19/04/2006 ? ? ?1309.93
> 20/04/2006 ? ? ?1311.46
> 21/04/2006 ? ? ?1311.28
> 24/04/2006 ? ? ?1308.11
> 25/04/2006 ? ? ?1301.74
> 26/04/2006 ? ? ?1305.41
> 27/04/2006 ? ? ?1309.72
> 28/04/2006 ? ? ?1310.61
> 01/05/2006 ? ? ?1305.19
> 02/05/2006 ? ? ?1313.21
> 03/05/2006 ? ? ?1307.85
> 04/05/2006 ? ? ?1312.25
> 06/05/2006 ? ? ?1325.76"
>
> ? ? ? ?library(zoo)
> ? ? ? ?z <- read.zoo(textConnection(Lines), format = "%d/%m/%Y")
>
> # z.na is same as z but with missing days added using NAs
> # Its formed by merging z with a zoo-width series containing all days.
>
> ? ? ? ?rng <- range(time(z))
> ? ? ? ?z.na <- merge(z, zoo(, seq(rng[1], rng[2], by = "day")))
>
> # form a series that has NAs wherever z.na does but has 1, 2, 3, ...
> # instead of z.na's data values and then use na.locf to fill in NAs
>
> ? ? ? ?idx <- na.locf(seq_along(z.na) + (0 * z.na))
>
> # pick off elements of z.na corresponding to 5th of month
>
> ? ? ? ?z.na[idx[format(time(z.na), "%d") == "05"]]
>
>
> Here is the final result:
>
> 2006-04-04 2006-05-04
> ? 1311.56 ? ?1312.25
>
>
> On Mon, Jan 18, 2010 at 10:16 AM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>> On Mon, Jan 18, 2010 at 9:54 AM, Research <risk2009 at ath.forthnet.gr> wrote:
>>> Hello,
>>>
>>> I have a daily data zoo object with ?prices such as:
>>>
>>> 05/04/2006 ? ? ?1311.56
>>> 06/04/2006 ? ? ?1309.04
>>> 07/04/2006 ? ? ?1295.5
>>> 10/04/2006 ? ? ?1296.6
>>> 11/04/2006 ? ? ?1286.57
>>> 12/04/2006 ? ? ?1288.12
>>> 13/04/2006 ? ? ?1289.12
>>> 14/04/2006 ? ? ?1289.12
>>> 17/04/2006 ? ? ?1285.33
>>> 18/04/2006 ? ? ?1307.65
>>> 19/04/2006 ? ? ?1309.93
>>> 20/04/2006 ? ? ?1311.46
>>> 21/04/2006 ? ? ?1311.28
>>> 24/04/2006 ? ? ?1308.11
>>> 25/04/2006 ? ? ?1301.74
>>> 26/04/2006 ? ? ?1305.41
>>> 27/04/2006 ? ? ?1309.72
>>> 28/04/2006 ? ? ?1310.61
>>> 01/05/2006 ? ? ?1305.19
>>> 02/05/2006 ? ? ?1313.21
>>> 03/05/2006 ? ? ?1307.85
>>> 04/05/2006 ? ? ?1312.25
>>> 05/05/2006 ? ? ?1325.76
>>>
>>>
>>>
>>> How can I isolate the 5th day of each month (if this was a
>>> working/trading day) otherwise the most recent (before the 5th) working
>>> day for each month?
>>>
>>
>> Your sample data always has the 5th of the month filled in but
>> assuming that that is not the case for the real data, merge your
>> series with a zero width series having every date and use na.locf to
>> move values up into subsequent NAs. ?Then just pick off the 5th of
>> each month.
>>
>> Lines <- "05/04/2006 ? ? ?1311.56
>> 06/04/2006 ? ? ?1309.04
>> 07/04/2006 ? ? ?1295.5
>> 10/04/2006 ? ? ?1296.6
>> 11/04/2006 ? ? ?1286.57
>> 12/04/2006 ? ? ?1288.12
>> 13/04/2006 ? ? ?1289.12
>> 14/04/2006 ? ? ?1289.12
>> 17/04/2006 ? ? ?1285.33
>> 18/04/2006 ? ? ?1307.65
>> 19/04/2006 ? ? ?1309.93
>> 20/04/2006 ? ? ?1311.46
>> 21/04/2006 ? ? ?1311.28
>> 24/04/2006 ? ? ?1308.11
>> 25/04/2006 ? ? ?1301.74
>> 26/04/2006 ? ? ?1305.41
>> 27/04/2006 ? ? ?1309.72
>> 28/04/2006 ? ? ?1310.61
>> 01/05/2006 ? ? ?1305.19
>> 02/05/2006 ? ? ?1313.21
>> 03/05/2006 ? ? ?1307.85
>> 04/05/2006 ? ? ?1312.25
>> 05/05/2006 ? ? ?1325.76"
>> library(zoo)
>> z <- read.zoo(textConnection(Lines), format = "%d/%m/%Y")
>> rng <- range(time(z))
>> zz <- na.locf(merge(z, zoo(, seq(rng[1], rng[2], by = "day"))))
>> zz[format(time(zz), "%d") == "05"]
>>
>


From wuertz at itp.phys.ethz.ch  Tue Jan 19 21:12:52 2010
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Tue, 19 Jan 2010 21:12:52 +0100
Subject: [R-SIG-Finance] Add business days
In-Reply-To: <1730e1951001130756u7df04496ube497351668625d0@mail.gmail.com>
References: <1730e1951001130756u7df04496ube497351668625d0@mail.gmail.com>
Message-ID: <4B561244.6090003@itp.phys.ethz.ch>

Diego Jara wrote:


use the function isBizday() and holidayNYSE()

load package timeSeries

Diethelm
> Hi. Given a date for fixing LIBOR, I am trying to generate the Value date
> and the Maturity date in R, for a NY locality. This involves calculating the
> date which is two LDN business days after the Value Date (as long as it
> falls on a NY business day), for the Value Date, and then calculating the
> next LDN and NY business day after the date which is 1 month (or 3 months,
> or the appropriate term) after the Value Date.
> I'm a beginner in R, but haven't been able to mix concepts of holidays (for
> NY and LDN), adding days or months to a date, and calculating business days.
>
> Any help that can get me jump-started is appreciated.
>
> DJ
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>
>
>


From diego.jara at quantil.com.co  Tue Jan 19 22:46:59 2010
From: diego.jara at quantil.com.co (Diego Jara)
Date: Tue, 19 Jan 2010 16:46:59 -0500
Subject: [R-SIG-Finance] Add business days
In-Reply-To: <4B561244.6090003@itp.phys.ethz.ch>
References: <1730e1951001130756u7df04496ube497351668625d0@mail.gmail.com>
	<4B561244.6090003@itp.phys.ethz.ch>
Message-ID: <1730e1951001191346t6cfdd55dk34032b2fd33578a4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100119/2f205c93/attachment.pl>

From donahchoo at me.com  Wed Jan 20 02:34:17 2010
From: donahchoo at me.com (donahchoo at me.com)
Date: Tue, 19 Jan 2010 19:34:17 -0600
Subject: [R-SIG-Finance] Detecting a range through time for a security?
Message-ID: <E7ED988C-ACBF-4CF6-BEB1-8500DD884EEB@me.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100119/98073647/attachment.pl>

From brenda.quismorio at gmail.com  Wed Jan 20 05:49:54 2010
From: brenda.quismorio at gmail.com (Brenda Quismorio)
Date: Tue, 19 Jan 2010 20:49:54 -0800
Subject: [R-SIG-Finance] Tail dependence coefficient using fCopulae
Message-ID: <b3288fe11001192049n4837da77ndfe44786e46feea5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100119/e44c8b1b/attachment.pl>

From brian at braverock.com  Wed Jan 20 11:33:12 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 20 Jan 2010 04:33:12 -0600
Subject: [R-SIG-Finance] Detecting a range through time for a security?
In-Reply-To: <E7ED988C-ACBF-4CF6-BEB1-8500DD884EEB@me.com>
References: <E7ED988C-ACBF-4CF6-BEB1-8500DD884EEB@me.com>
Message-ID: <4B56DBE8.8080700@braverock.com>

donahchoo at me.com wrote:
> Hello,
> 
> I'd like to run a study that detects a range for a security and  
> determines how long the security stays within this range.
> 
> Is there a package that will do this already?
> 
> If not, does anyone have suggestions on how to implement this?

require(zoo)
rollapply(pricedatadata,width,FUN=range)

'detection' should be trivial once you know the ranges.

Also, see the copious documentation for package 'TTR'

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From zhucai4 at gmail.com  Thu Jan 21 08:32:45 2010
From: zhucai4 at gmail.com (zhucai4)
Date: Wed, 20 Jan 2010 23:32:45 -0800
Subject: [R-SIG-Finance] A problem about download stock data from yahoo
Message-ID: <201001202332442657094@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100120/c829610d/attachment.pl>

From josh.m.ulrich at gmail.com  Wed Jan 20 17:21:04 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 20 Jan 2010 10:21:04 -0600
Subject: [R-SIG-Finance] A problem about download stock data from yahoo
In-Reply-To: <201001202332442657094@gmail.com>
References: <201001202332442657094@gmail.com>
Message-ID: <8cca69991001200821i7791da27w7ffc16daf5999427@mail.gmail.com>

I've never heard of the "yahoo.get.hist.quote" function, though its
documentation says it's in tseries (which it isn't).  Though
tseries::get.hist.quote does exist.

I would recommend using quantmod's getSymbols function:
library(quantmod)
x <- getSymbols("0012.HK",auto.assign=FALSE)

Please note that you must turn off auto assignment because "0012.HK"
is an illegal object name because it starts with a number.

HTH,
Josh
--
http://www.fosstrading.com



On Thu, Jan 21, 2010 at 1:32 AM, zhucai4 <zhucai4 at gmail.com> wrote:
> Hello, everyone:
>
> I try to download the history data for a hongkong stock:0012.HK, using "yahoo.get.hist.quote", when I type the code:
>> library("UsingR")
>> instrument<-"0012.HK"
>> destfile<-"Henderson.csv"
>> yahoo.get.hist.quote(instrument,destfile,start=2008-1-1,end=2010-1-1,
> + quote="Close",download=TRUE,adjusted=TRUE,origin="1970-01-01", compression="d")
>
> there is an error message:
> Error in as.POSIXct.numeric(start, tz = "GMT") : 'origin' must be supplied
>
> I also try origin="1899-12-30", but the error message is still there.
>
> Did anyone encounter with this problem before ? Thank you very much for the help!
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From nordicgnome at gmail.com  Wed Jan 20 19:29:55 2010
From: nordicgnome at gmail.com (Jan Vandermeer)
Date: Wed, 20 Jan 2010 13:29:55 -0500
Subject: [R-SIG-Finance] Blotter package - problem with example.
Message-ID: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100120/8b7286bd/attachment.pl>

From brian at braverock.com  Wed Jan 20 19:49:29 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 20 Jan 2010 12:49:29 -0600
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>
Message-ID: <4B575039.7090103@braverock.com>

Jan,

I believe that Josh has updated his example on the FOSStrading site.

demo('longtrend') should work as expected.
demo('turtles') is broken, I haven't gotten around to updating it yet
demo('amzn') is working

'blotter' is currently under very heavy development to integrate more 
complex instrument types and multiple currencies.

Last week, the interfaces of several of the core functions changed with 
the introduction of an environment to store trade, position, and P&L data.

As such, old examples will be broken until updated.

addTxn(), for example, no longer returns a portfolio object, but instead 
assigns the updated portfolio back into the environment.

Take a look at the two working examples (above) and then I'd be happy to 
help make your example work on the new code if you're still having trouble.

The good news is that much of the major surgury is completed, and the 
code is much faster than it was a couple weeks ago, and more flexible.

Regards,

    - Brian

Jan Vandermeer wrote:
> Hi Folks;
>
> Seems that dissimilar but related problems happen with blotter for me. See <
> https://stat.ethz.ch/pipermail/r-sig-finance/2009q4/005014.html>
>
> I was playing with the FOSS Trading blog example Tactical Asset Allocation
> Using Blotter <
> http://blog.fosstrading.com/2009/11/tactical-asset-allocation-using-blotter.html>
> and initially it ran faultlessly. I then updated my R packages, this this:
>
> update.packages() using a local mirror (University of Waterloo) and example
> no longer worked.
>
> When I reran the tactical example R spat out:
>
> "source("tactical.R") -  (This is a verbatim copy of Josh's code in the
> article)
> Loading required package: xts
> Loading required package: zoo
> Loading required package: Defaults
> Loading required package: TTR
> Loading required package: FinancialInstrument
>
> Package PerformanceAnalytics (1.0.0) loaded.
> Econometric tools for performance and risk analysis.
> (c) 2004-2009 Peter Carl, Brian G. Peterson. License: GPL
> http://braverock.com/R/
>
>
> Attaching package: 'PerformanceAnalytics'
>
>
>         The following object(s) are masked from package:graphics :
>
>          legend
>
> [1] "Loading data"
> [1] "Setting up indicators"
> [1] "Initializing portfolio and account structure"
> Error in vector("list", length = length(symbols)) : element 1 is empty;
>    the part of the args list of 'length' being evaluated was:
>    (symbols)
>
>
> I then went and tried the example in the blotter package. It did not work
> either and I then tried Jeff Ryan's suggestion and updated
> blotter, xts & quantmod and reran the example:
>
> # Construct a portfolio object and add some transactions
> library(blotter)
> # Download price data
> symbols = c("IBM","F","MMM")
> require(quantmod)
> getSymbols(symbols, from='2007-01-01', to='2007-01-31',
> index.class="POSIXct")
>
> # Initialize a portfolio object 'p'
> print('Creating portfolio \"p\"...')
> p = initPortf(symbols=symbols)
>
> ## Trades must be made in date order.
> print('Adding trades to \"p\"...')
> # Make a couple of trades in IBM
> p = addTxn(p, "IBM", '2007-01-03', 50, 96.5, -0.05*50)
> p = addTxn(p, "IBM", '2007-01-04', 50, 97.1, -0.05*50)
>
> # ...a few in F...
> p = addTxn(p, "F", '2007-01-03', -100, 7.60, -0.05*100)
> p = addTxn(p, "F", '2007-01-04', 50, 7.70, -0.05*50)
> p = addTxn(p, "F", '2007-01-10', 50, 7.78, -0.05*50)
>
> # ...and some in MMM
> p = addTxn(p, "MMM", '2007-01-05', -50, 77.9, -0.05*50)
> p = addTxn(p, "MMM", '2007-01-08', 50, 77.6, -0.05*50)
> p = addTxn(p, "MMM", '2007-01-09', 50, 77.6, -0.05*50)
>
> print('Updating portfolio \"p\"...')
> p = updatePortf(p,'2007-01')
> calcPortfSummary(p)
> getBySymbol(p,'Pos.Qty')
>
> print('Creating account \"a\" for portfolio \"p\"...')
> a = initAcct(portfolios="p")
> print('Updating account \"a\"...')
> a = updateAcct(a,'2007-01') # Check out the sweet date scoping. Thanks, xts.
> a = updateEndEq(a,'2007-01')
> print(a)
>
> which gave me:
>
> source("Blotter_ex.R")
> Loading required package: xts
> Loading required package: zoo
> Loading required package: quantmod
> Loading required package: Defaults
> Loading required package: TTR
> Loading required package: FinancialInstrument
> [1] "Creating portfolio \"p\"..."
> [1] "Adding trades to \"p\"..."
> [1] "2007-01-03 IBM 50 @ 96.5"
> Error in get(paste("portfolio", pname, sep = "."), envir = .blotter) :
>   object 'portfolio.list(txn = c(0, 50, 0, 96.5, 0, 0, 0, 4825, 0, 96.5, 0,
> 50, 0, 96.5, 0, 0, 0, 1), posPL = c(0, 1, 1, 0, 0, 0, 0, 0, 0))' not found
> In addition: Warning message:
> In addTxn(p, "IBM", "2007-01-03", 50, 96.5, -0.05 * 50) :
>   Instrument IBM  not found, using contract multiplier of 1
>
> I've tried to puzzle my way through this. I seems that there are updates
> that introduce these different errors. Are they related ?
>
> Any assistance would be appreciated.
>
> Jan Vandermeer
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>   


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From josh.m.ulrich at gmail.com  Wed Jan 20 20:31:46 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 20 Jan 2010 13:31:46 -0600
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <4B575039.7090103@braverock.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com> 
	<4B575039.7090103@braverock.com>
Message-ID: <8cca69991001201131w311d124bq26fa627c25560740@mail.gmail.com>

Brian / Jan,

It's not updated yet, but I know what needs to be done and plan to
update the post this evening.

Best,
Josh
--
http://www.fosstrading.com



On Wed, Jan 20, 2010 at 12:49 PM, Brian G. Peterson <brian at braverock.com> wrote:
> Jan,
>
> I believe that Josh has updated his example on the FOSStrading site.
>
> demo('longtrend') should work as expected.
> demo('turtles') is broken, I haven't gotten around to updating it yet
> demo('amzn') is working
>
> 'blotter' is currently under very heavy development to integrate more
> complex instrument types and multiple currencies.
>
> Last week, the interfaces of several of the core functions changed with the
> introduction of an environment to store trade, position, and P&L data.
>
> As such, old examples will be broken until updated.
>
> addTxn(), for example, no longer returns a portfolio object, but instead
> assigns the updated portfolio back into the environment.
>
> Take a look at the two working examples (above) and then I'd be happy to
> help make your example work on the new code if you're still having trouble.
>
> The good news is that much of the major surgury is completed, and the code
> is much faster than it was a couple weeks ago, and more flexible.
>
> Regards,
>
> ? - Brian
>
> Jan Vandermeer wrote:
>>
>> Hi Folks;
>>
>> Seems that dissimilar but related problems happen with blotter for me. See
>> <
>> https://stat.ethz.ch/pipermail/r-sig-finance/2009q4/005014.html>
>>
>> I was playing with the FOSS Trading blog example Tactical Asset Allocation
>> Using Blotter <
>>
>> http://blog.fosstrading.com/2009/11/tactical-asset-allocation-using-blotter.html>
>> and initially it ran faultlessly. I then updated my R packages, this this:
>>
>> update.packages() using a local mirror (University of Waterloo) and
>> example
>> no longer worked.
>>
>> When I reran the tactical example R spat out:
>>
>> "source("tactical.R") - ?(This is a verbatim copy of Josh's code in the
>> article)
>> Loading required package: xts
>> Loading required package: zoo
>> Loading required package: Defaults
>> Loading required package: TTR
>> Loading required package: FinancialInstrument
>>
>> Package PerformanceAnalytics (1.0.0) loaded.
>> Econometric tools for performance and risk analysis.
>> (c) 2004-2009 Peter Carl, Brian G. Peterson. License: GPL
>> http://braverock.com/R/
>>
>>
>> Attaching package: 'PerformanceAnalytics'
>>
>>
>> ? ? ? ?The following object(s) are masked from package:graphics :
>>
>> ? ? ? ? legend
>>
>> [1] "Loading data"
>> [1] "Setting up indicators"
>> [1] "Initializing portfolio and account structure"
>> Error in vector("list", length = length(symbols)) : element 1 is empty;
>> ? the part of the args list of 'length' being evaluated was:
>> ? (symbols)
>>
>>
>> I then went and tried the example in the blotter package. It did not work
>> either and I then tried Jeff Ryan's suggestion and updated
>> blotter, xts & quantmod and reran the example:
>>
>> # Construct a portfolio object and add some transactions
>> library(blotter)
>> # Download price data
>> symbols = c("IBM","F","MMM")
>> require(quantmod)
>> getSymbols(symbols, from='2007-01-01', to='2007-01-31',
>> index.class="POSIXct")
>>
>> # Initialize a portfolio object 'p'
>> print('Creating portfolio \"p\"...')
>> p = initPortf(symbols=symbols)
>>
>> ## Trades must be made in date order.
>> print('Adding trades to \"p\"...')
>> # Make a couple of trades in IBM
>> p = addTxn(p, "IBM", '2007-01-03', 50, 96.5, -0.05*50)
>> p = addTxn(p, "IBM", '2007-01-04', 50, 97.1, -0.05*50)
>>
>> # ...a few in F...
>> p = addTxn(p, "F", '2007-01-03', -100, 7.60, -0.05*100)
>> p = addTxn(p, "F", '2007-01-04', 50, 7.70, -0.05*50)
>> p = addTxn(p, "F", '2007-01-10', 50, 7.78, -0.05*50)
>>
>> # ...and some in MMM
>> p = addTxn(p, "MMM", '2007-01-05', -50, 77.9, -0.05*50)
>> p = addTxn(p, "MMM", '2007-01-08', 50, 77.6, -0.05*50)
>> p = addTxn(p, "MMM", '2007-01-09', 50, 77.6, -0.05*50)
>>
>> print('Updating portfolio \"p\"...')
>> p = updatePortf(p,'2007-01')
>> calcPortfSummary(p)
>> getBySymbol(p,'Pos.Qty')
>>
>> print('Creating account \"a\" for portfolio \"p\"...')
>> a = initAcct(portfolios="p")
>> print('Updating account \"a\"...')
>> a = updateAcct(a,'2007-01') # Check out the sweet date scoping. Thanks,
>> xts.
>> a = updateEndEq(a,'2007-01')
>> print(a)
>>
>> which gave me:
>>
>> source("Blotter_ex.R")
>> Loading required package: xts
>> Loading required package: zoo
>> Loading required package: quantmod
>> Loading required package: Defaults
>> Loading required package: TTR
>> Loading required package: FinancialInstrument
>> [1] "Creating portfolio \"p\"..."
>> [1] "Adding trades to \"p\"..."
>> [1] "2007-01-03 IBM 50 @ 96.5"
>> Error in get(paste("portfolio", pname, sep = "."), envir = .blotter) :
>> ?object 'portfolio.list(txn = c(0, 50, 0, 96.5, 0, 0, 0, 4825, 0, 96.5, 0,
>> 50, 0, 96.5, 0, 0, 0, 1), posPL = c(0, 1, 1, 0, 0, 0, 0, 0, 0))' not found
>> In addition: Warning message:
>> In addTxn(p, "IBM", "2007-01-03", 50, 96.5, -0.05 * 50) :
>> ?Instrument IBM ?not found, using contract multiplier of 1
>>
>> I've tried to puzzle my way through this. I seems that there are updates
>> that introduce these different errors. Are they related ?
>>
>> Any assistance would be appreciated.
>>
>> Jan Vandermeer
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>


From zhucai4 at gmail.com  Thu Jan 21 22:38:46 2010
From: zhucai4 at gmail.com (=?utf-8?B?emh1Y2FpNA==?=)
Date: Thu, 21 Jan 2010 13:38:46 -0800
Subject: [R-SIG-Finance]
	=?utf-8?q?A_problem_about_download_stock_data_fro?=
	=?utf-8?q?m_yahoo?=
References: <201001202332442657094@gmail.com>
Message-ID: <201001211338442656172@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100121/8eb49bf2/attachment.pl>

From weihanliu2002 at yahoo.com  Thu Jan 21 08:35:28 2010
From: weihanliu2002 at yahoo.com (Wei-han Liu)
Date: Wed, 20 Jan 2010 23:35:28 -0800 (PST)
Subject: [R-SIG-Finance] to run R in Amazon Elastic Compute Cloud
Message-ID: <312051.5700.qm@web53501.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100120/946806d4/attachment.pl>

From brian at braverock.com  Thu Jan 21 13:56:37 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 21 Jan 2010 06:56:37 -0600
Subject: [R-SIG-Finance] to run R in Amazon Elastic Compute Cloud
In-Reply-To: <312051.5700.qm@web53501.mail.re2.yahoo.com>
References: <312051.5700.qm@web53501.mail.re2.yahoo.com>
Message-ID: <4B584F05.1080000@braverock.com>

Wei-han Liu wrote:
> Hi R users:
>
> I am a newbie to parallel computing. I am curious how to run R in Amazon Elastic Compute Cloud (Amazon EC2) for a huge computation-intensive task.
>
>
> I know there are some R packages, e.g. snow and snowfall, to coordinate multi-core and multi-unit. So far, I have only worked out to use all the CPUs in my single computer. I assume that some commercial service are available for such demand and I do not to have work on the details for setting up the computing cloud.
>
> Please be kind to share some information.
>   
I will share the information of where to look, which is often the most 
important.

There is a separate R-SIG-HPC list and resources.  They have had many 
discussions on EC2 over there.

Check out the list archives or google 'r-sig-hpc ec2'

Regards,
 
     - Brian
   

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From lippelanna24 at hotmail.com  Thu Jan 21 18:57:09 2010
From: lippelanna24 at hotmail.com (lippel anna)
Date: Thu, 21 Jan 2010 18:57:09 +0100
Subject: [R-SIG-Finance] Problem on blpGetData function from RBloomberg
 package, is there a maximum return value size?
Message-ID: <COL108-W255E70BBD5AB0D93523AB9C5630@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100121/948ea4d7/attachment.pl>

From brian at braverock.com  Thu Jan 21 19:03:42 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 21 Jan 2010 12:03:42 -0600
Subject: [R-SIG-Finance] Problem on blpGetData function from RBloomberg
 package, is there a maximum return value size?
In-Reply-To: <COL108-W255E70BBD5AB0D93523AB9C5630@phx.gbl>
References: <COL108-W255E70BBD5AB0D93523AB9C5630@phx.gbl>
Message-ID: <4B5896FE.2010108@braverock.com>

lippel anna wrote:
> Hello, this is the statement I am writing to get the closing prices of 80 stocks:
>
>  
>
> donnees<-blp(conn,mblist,"PX_LAST",startDate,endDate)
>
> where mblist represents a list of 80 stocks
>
> I set the endDate to yesterday
>
> When I set startDate to beginning of september it returns me the right value but when I want to set it at january 2005 it returns me the following error:
>
> "Error in blpGetHistoricalData(conn, securities, fields, start, end, barsize,  : 
>  Call to BLPSubscribe did not return any data!"
>
> As it is working for one smaller case I am wondering if it's not a size limitation problem. If that is the case what is the limit. It would slow down my code a lot if If I have to call it for each stock, do you another way to do it?thank you!
>   
Bloomberg limits how much data you can get in a single query. 

Experiment on breaking it up. 

Schedule getting the data from Bloomberg and store it somewhere else.

Good Luck,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From lippelanna24 at hotmail.com  Thu Jan 21 19:07:27 2010
From: lippelanna24 at hotmail.com (lippel anna)
Date: Thu, 21 Jan 2010 19:07:27 +0100
Subject: [R-SIG-Finance] Problem on blpGetData function from RBloomberg
 package, is there a maximum return value size?
In-Reply-To: <4B5896FE.2010108@braverock.com>
References: <COL108-W255E70BBD5AB0D93523AB9C5630@phx.gbl>,
	<4B5896FE.2010108@braverock.com>
Message-ID: <COL108-W228E72A4D0B246C77A1B83C5630@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100121/7045ae55/attachment.pl>

From brian at braverock.com  Thu Jan 21 19:19:48 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 21 Jan 2010 12:19:48 -0600
Subject: [R-SIG-Finance] Problem on blpGetData function from RBloomberg
 package, is there a maximum return value size?
In-Reply-To: <COL108-W228E72A4D0B246C77A1B83C5630@phx.gbl>
References: <COL108-W255E70BBD5AB0D93523AB9C5630@phx.gbl>,
	<4B5896FE.2010108@braverock.com>
	<COL108-W228E72A4D0B246C77A1B83C5630@phx.gbl>
Message-ID: <4B589AC4.4010602@braverock.com>

lippel anna wrote:
> Hi Brian, thank you for your answer. I wanted to avoid breaking the 
> retrieved datas but it's not a big deal. I need 3 years and I got to 
> extract 1 year for 80 stocks but not 2...so I guess I will have to 
> make 3 queries, one for each year!
Note that it is also possible that not all of the symbols you're looking 
for have daily data back three years.  Eventually, the data changes to 
monthly.

Good Luck.

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From lippelanna24 at hotmail.com  Thu Jan 21 19:44:34 2010
From: lippelanna24 at hotmail.com (lippel anna)
Date: Thu, 21 Jan 2010 19:44:34 +0100
Subject: [R-SIG-Finance] Problem on blpGetData function from RBloomberg
 package, is there a maximum return value size?
In-Reply-To: <4B589AC4.4010602@braverock.com>
References: <COL108-W255E70BBD5AB0D93523AB9C5630@phx.gbl>,
	<4B5896FE.2010108@braverock.com>
	<COL108-W228E72A4D0B246C77A1B83C5630@phx.gbl>,
	<4B589AC4.4010602@braverock.com>
Message-ID: <COL108-W3180AD59001DC406985926C5630@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100121/abcfa388/attachment.pl>

From jorge.nieves at moorecap.com  Thu Jan 21 20:58:10 2010
From: jorge.nieves at moorecap.com (Jorge Nieves)
Date: Thu, 21 Jan 2010 14:58:10 -0500
Subject: [R-SIG-Finance] Return.annualized(PerformanceAnalytics)
Message-ID: <D595C0E05185614C90515F1E8A2D4CBF060B4084@NYC-XCH3.win.moorecap.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100121/beab67f5/attachment.pl>

From brian at braverock.com  Thu Jan 21 21:13:53 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 21 Jan 2010 14:13:53 -0600
Subject: [R-SIG-Finance] Return.annualized(PerformanceAnalytics)
In-Reply-To: <D595C0E05185614C90515F1E8A2D4CBF060B4084@NYC-XCH3.win.moorecap.com>
References: <D595C0E05185614C90515F1E8A2D4CBF060B4084@NYC-XCH3.win.moorecap.com>
Message-ID: <4B58B581.1070509@braverock.com>

Jorge Nieves wrote:
> Hi,
>
> I have a dataSet of returns with 15 columns. I would like to compute the
> geometric annualized returns.  I can do that easily with a loop, but I
> was wondering it can be done with the apply function. If so, does anyone
> knows the syntax?
>
>   This is the specification I would like to use.
>
> Return.annualized(x, scale = 252, geometric = TRUE)
>   
Return.annualized has had multi-column support since September of last 
year.  It will apply over your columns for you.

Regards,

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From cgb at datanalytics.com  Thu Jan 21 23:10:18 2010
From: cgb at datanalytics.com (Carlos J. Gil Bellosta)
Date: Thu, 21 Jan 2010 23:10:18 +0100
Subject: [R-SIG-Finance] to run R in Amazon Elastic Compute Cloud
In-Reply-To: <312051.5700.qm@web53501.mail.re2.yahoo.com>
References: <312051.5700.qm@web53501.mail.re2.yahoo.com>
Message-ID: <4B58D0CA.7090302@datanalytics.com>

You can perhaps have a look at

http://tolstoy.newcastle.edu.au/R/e8/help/09/12/9382.html

and

http://tolstoy.newcastle.edu.au/R/e8/help/09/12/9486.html

Best regards,

Carlos J. Gil Bellosta
http://www.datanalytics.com

Wei-han Liu wrote:
> Hi R users:
> 
> I am a newbie to parallel computing. I am curious how to run R in Amazon Elastic Compute Cloud (Amazon EC2) for a huge computation-intensive task.
> 
> 
> I know there are some R packages, e.g. snow and snowfall, to coordinate multi-core and multi-unit. So far, I have only worked out to use all the CPUs in my single computer. I assume that some commercial service are available for such demand and I do not to have work on the details for setting up the computing cloud.
> 
> Please be kind to share some information.
> 
> Thanks a lot.
> 
> Wei-han
> 
> 
>       
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From kagba2006 at yahoo.com  Fri Jan 22 19:09:44 2010
From: kagba2006 at yahoo.com (FMH)
Date: Fri, 22 Jan 2010 10:09:44 -0800 (PST)
Subject: [R-SIG-Finance] How to seperate date and time into different
	columns?
Message-ID: <820257.41041.qm@web38308.mail.mud.yahoo.com>

Dear All,

I have a series of data in which the first column consist of a combination of date and time, for instance 17 April 2008 at 4.01pm, such data is recorded as:

4/17/2008 16:01 

I'd like to seperate it into four different columns which consist of Day, Month,Year and Time, respectively.

Could someone please advice me on this mater?

Thank you,
Fir


From brian at braverock.com  Fri Jan 22 19:18:15 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 22 Jan 2010 12:18:15 -0600
Subject: [R-SIG-Finance] How to separate date and time into different
 columns?
In-Reply-To: <820257.41041.qm@web38308.mail.mud.yahoo.com>
References: <820257.41041.qm@web38308.mail.mud.yahoo.com>
Message-ID: <4B59EBE7.4000506@braverock.com>

FMH wrote:
> Dear All,
>
> I have a series of data in which the first column consist of a combination of date and time, for instance 17 April 2008 at 4.01pm, such data is recorded as:
>
> 4/17/2008 16:01 
>
> I'd like to seperate it into four different columns which consist of Day, Month,Year and Time, respectively.
>
> Could someone please advice me on this mater?
>   
Use xts.

Specify a POSIXlt index

All of the properties will be available in POSIXlt.

However, you didn't state what you wish to accomplish.  It is likely 
that xts will be able to subset anything you need without splitting 
things up.

Realize that using a real time series class will always perform better 
than using a data frame.

Cross-posting is considered rude. If you need more help than the above, 
please make your query specific to some problem in finance, to keep the 
list focused on its topic (finance), or only reply to r-help.

It would be polite to sign your name too...

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From ggrothendieck at gmail.com  Fri Jan 22 19:43:10 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 22 Jan 2010 13:43:10 -0500
Subject: [R-SIG-Finance] [R] How to seperate date and time into
	different columns?
In-Reply-To: <820257.41041.qm@web38308.mail.mud.yahoo.com>
References: <820257.41041.qm@web38308.mail.mud.yahoo.com>
Message-ID: <971536df1001221043n3d99a19ex9725c195b77dec40@mail.gmail.com>

Normally one wants to store time indexes as a single column so its
likely that this is not what you really want to do.  You may wish to
explain what your final objective is and why you want to do this.

However, if you must there are many ways and here is one  The first
two lines load chron and set up some input data.  Now that we have
some input the first line of the solution creates a chron object by
passing to chron the portion prior to the space and the portion after
the space and appending :00 to the latter.  The second line uses
month.day.year to get the date components and subtraction of the date
to get the times.

> library(chron)
> x <- c("4/17/2008 16:01", "4/18/2008 20:01")

> xc <- chron(sub(" .*", "", x), sub(".* (.*)", "\\1:00", x))
> with(month.day.year(xc), data.frame(year, month, day, time = xc - dates(xc)))
  year month day     time
1 2008     4  17 16:01:00
2 2008     4  18 20:01:00

R News 4/1 has an relevant article.

On Fri, Jan 22, 2010 at 1:09 PM, FMH <kagba2006 at yahoo.com> wrote:
> Dear All,
>
> I have a series of data in which the first column consist of a combination of date and time, for instance 17 April 2008 at 4.01pm, such data is recorded as:
>
> 4/17/2008 16:01
>
> I'd like to seperate it into four different columns which consist of Day, Month,Year and Time, respectively.
>
> Could someone please advice me on this mater?
>
> Thank you,
> Fir
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jeff.a.ryan at gmail.com  Fri Jan 22 20:13:35 2010
From: jeff.a.ryan at gmail.com (J Ryan)
Date: Fri, 22 Jan 2010 13:13:35 -0600
Subject: [R-SIG-Finance] How to separate date and time into different
	columns?
In-Reply-To: <4B59EBE7.4000506@braverock.com>
References: <820257.41041.qm@web38308.mail.mud.yahoo.com>
	<4B59EBE7.4000506@braverock.com>
Message-ID: <1827DFA3-E4D9-4918-A912-8379CA276AFB@gmail.com>

A note about xts:

The time class layer is abstracted from the implementation. This  
allows for some very time specific manipulation without having to  
manage the underlying details.

Take a look at the xts docs and vignette.

Also, the functions .indexmon .indexyear etc correspond to the POSIXlt  
components. The xts object doesn't use this as a class, but this  
allows you access as if it did.

HTH
Jeff

Jeffrey A. Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com

On Jan 22, 2010, at 12:18 PM, "Brian G. Peterson"  
<brian at braverock.com> wrote:

> FMH wrote:
>> Dear All,
>>
>> I have a series of data in which the first column consist of a  
>> combination of date and time, for instance 17 April 2008 at 4.01pm,  
>> such data is recorded as:
>>
>> 4/17/2008 16:01
>> I'd like to seperate it into four different columns which consist  
>> of Day, Month,Year and Time, respectively.
>>
>> Could someone please advice me on this mater?
>>
> Use xts.
>
> Specify a POSIXlt index
>
> All of the properties will be available in POSIXlt.
>
> However, you didn't state what you wish to accomplish.  It is likely  
> that xts will be able to subset anything you need without splitting  
> things up.
>
> Realize that using a real time series class will always perform  
> better than using a data frame.
>
> Cross-posting is considered rude. If you need more help than the  
> above, please make your query specific to some problem in finance,  
> to keep the list focused on its topic (finance), or only reply to r- 
> help.
>
> It would be polite to sign your name too...
>
> Regards,
>
>   - Brian
>
> -- 
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R  
> questions should go.


From dengyishuo at 163.com  Sat Jan 23 05:54:42 2010
From: dengyishuo at 163.com (=?UTF-8?B?6YKT5LiA56GV?=)
Date: Fri, 22 Jan 2010 20:54:42 -0800 (PST)
Subject: [R-SIG-Finance] How to get SSE Composite Index from yahoo or google?
Message-ID: <1264222482598-1204402.post@n4.nabble.com>



Hi,all! 

Anybody know how can I get SSE Composite Index (Shanghai Composite Index)
from yahoo or google using R?

Thanks!



-----
?????????????????
-- 
View this message in context: http://n4.nabble.com/How-to-get-SSE-Composite-Index-from-yahoo-or-google-tp1204402p1204402.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From jeff.a.ryan at gmail.com  Sat Jan 23 05:58:56 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 22 Jan 2010 22:58:56 -0600
Subject: [R-SIG-Finance] How to get SSE Composite Index from yahoo or
	google?
In-Reply-To: <1264222482598-1204402.post@n4.nabble.com>
References: <1264222482598-1204402.post@n4.nabble.com>
Message-ID: <e8e755251001222058t65c3f3n639136de09856f8d@mail.gmail.com>

Couple of options using quantmod:

library(quantmod)

> SSE <- getSymbols("000001.SS",auto.assign=FALSE)
> head(SSE)
           000001.SS.Open 000001.SS.High 000001.SS.Low 000001.SS.Close
2007-01-01        2675.47        2675.47       2675.47         2675.47
2007-01-02        2675.47        2675.47       2675.47         2675.47
2007-01-03        2675.47        2675.47       2675.47         2675.47
2007-01-04        2728.19        2847.61       2684.82         2715.72
2007-01-05        2668.58        2685.80       2617.02         2641.33
2007-01-08        2621.07        2708.44       2620.62         2707.20
           000001.SS.Volume 000001.SS.Adjusted
2007-01-01                0            2675.47
2007-01-02                0            2675.47
2007-01-03                0            2675.47
2007-01-04       4294967200            2715.72
2007-01-05       4294967200            2641.33
2007-01-08       4294967200            2707.20
> setSymbolLookup(SSE=list(name="000001.SS", src="yahoo"))
> getSymbols("SSE")
[1] "SSE"
> head(SSE)
           000001.SS.Open 000001.SS.High 000001.SS.Low 000001.SS.Close
2007-01-01        2675.47        2675.47       2675.47         2675.47
2007-01-02        2675.47        2675.47       2675.47         2675.47
2007-01-03        2675.47        2675.47       2675.47         2675.47
2007-01-04        2728.19        2847.61       2684.82         2715.72
2007-01-05        2668.58        2685.80       2617.02         2641.33
2007-01-08        2621.07        2708.44       2620.62         2707.20
           000001.SS.Volume 000001.SS.Adjusted
2007-01-01                0            2675.47
2007-01-02                0            2675.47
2007-01-03                0            2675.47
2007-01-04       4294967200            2715.72
2007-01-05       4294967200            2641.33
2007-01-08       4294967200            2707.20

HTH
Jeff

2010/1/22 ??? <dengyishuo at 163.com>:
>
>
> Hi,all!
>
> Anybody know how can I get SSE Composite Index (Shanghai Composite Index)
> from yahoo or google using R?
>
> Thanks!
>
>
>
> -----
> ?????????????????
> --
> View this message in context: http://n4.nabble.com/How-to-get-SSE-Composite-Index-from-yahoo-or-google-tp1204402p1204402.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From josh.m.ulrich at gmail.com  Sat Jan 23 06:01:30 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 22 Jan 2010 23:01:30 -0600
Subject: [R-SIG-Finance] How to get SSE Composite Index from yahoo or
	google?
In-Reply-To: <e8e755251001222058t65c3f3n639136de09856f8d@mail.gmail.com>
References: <1264222482598-1204402.post@n4.nabble.com>
	<e8e755251001222058t65c3f3n639136de09856f8d@mail.gmail.com>
Message-ID: <8cca69991001222101m32f823d7pe7597b9e7b1d3e5d@mail.gmail.com>

And perhaps even more obvious:

> getSymbols("^SSEC")
[1] "SSEC"
> head(SSEC)
           SSEC.Open SSEC.High SSEC.Low SSEC.Close SSEC.Volume SSEC.Adjusted
2007-01-04   2728.19   2847.61  2684.82    2715.72      120200       2715.72
2007-01-05   2668.58   2685.80  2617.02    2641.33      106200       2641.33
2007-01-08   2621.07   2708.44  2620.62    2707.20      106800       2707.20
2007-01-09   2711.05   2809.39  2691.36    2807.80      110800       2807.80
2007-01-10   2838.11   2841.74  2770.99    2825.58      111800       2825.58
2007-01-11   2819.37   2841.18  2763.89    2770.11      121600       2770.11

Best,
Josh
--
http://www.fosstrading.com



2010/1/22 Jeff Ryan <jeff.a.ryan at gmail.com>:
> Couple of options using quantmod:
>
> library(quantmod)
>
>> SSE <- getSymbols("000001.SS",auto.assign=FALSE)
>> head(SSE)
>           000001.SS.Open 000001.SS.High 000001.SS.Low 000001.SS.Close
> 2007-01-01        2675.47        2675.47       2675.47         2675.47
> 2007-01-02        2675.47        2675.47       2675.47         2675.47
> 2007-01-03        2675.47        2675.47       2675.47         2675.47
> 2007-01-04        2728.19        2847.61       2684.82         2715.72
> 2007-01-05        2668.58        2685.80       2617.02         2641.33
> 2007-01-08        2621.07        2708.44       2620.62         2707.20
>           000001.SS.Volume 000001.SS.Adjusted
> 2007-01-01                0            2675.47
> 2007-01-02                0            2675.47
> 2007-01-03                0            2675.47
> 2007-01-04       4294967200            2715.72
> 2007-01-05       4294967200            2641.33
> 2007-01-08       4294967200            2707.20
>> setSymbolLookup(SSE=list(name="000001.SS", src="yahoo"))
>> getSymbols("SSE")
> [1] "SSE"
>> head(SSE)
>           000001.SS.Open 000001.SS.High 000001.SS.Low 000001.SS.Close
> 2007-01-01        2675.47        2675.47       2675.47         2675.47
> 2007-01-02        2675.47        2675.47       2675.47         2675.47
> 2007-01-03        2675.47        2675.47       2675.47         2675.47
> 2007-01-04        2728.19        2847.61       2684.82         2715.72
> 2007-01-05        2668.58        2685.80       2617.02         2641.33
> 2007-01-08        2621.07        2708.44       2620.62         2707.20
>           000001.SS.Volume 000001.SS.Adjusted
> 2007-01-01                0            2675.47
> 2007-01-02                0            2675.47
> 2007-01-03                0            2675.47
> 2007-01-04       4294967200            2715.72
> 2007-01-05       4294967200            2641.33
> 2007-01-08       4294967200            2707.20
>
> HTH
> Jeff
>
> 2010/1/22 ??? <dengyishuo at 163.com>:
>>
>>
>> Hi,all!
>>
>> Anybody know how can I get SSE Composite Index (Shanghai Composite Index)
>> from yahoo or google using R?
>>
>> Thanks!
>>
>>
>>
>> -----
>> ?????????????????
>> --
>> View this message in context: http://n4.nabble.com/How-to-get-SSE-Composite-Index-from-yahoo-or-google-tp1204402p1204402.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>
>
>
> --
> Jeffrey Ryan
> jeffrey.ryan at insightalgo.com
>
> ia: insight algorithmics
> www.insightalgo.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From jeff.a.ryan at gmail.com  Sat Jan 23 06:13:36 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 22 Jan 2010 23:13:36 -0600
Subject: [R-SIG-Finance] Quantmod: getFin; getFinancials
In-Reply-To: <2BA8E482-361F-446B-8FBC-D8A8F4642EC8@gmail.com>
References: <fc85ab5b0911301825r2ee22c2ar4fd41050d080cd1b@mail.gmail.com>
	<2BA8E482-361F-446B-8FBC-D8A8F4642EC8@gmail.com>
Message-ID: <e8e755251001222113n5c2c94eck4316de211b3027c@mail.gmail.com>

Just an FYI.

getFin has been fixed in the R-forge quantmod repository.  There
should be a new CRAN version in a few days.

Thanks,
Jeff

On Mon, Nov 30, 2009 at 9:16 PM, J Ryan <jeff.a.ryan at gmail.com> wrote:
> Hi Krish,
>
> I noticed this last week. It is due to an internal change in the google
> results that quantmod uses.
>
> I should have a fix soon, just haven't had a chance since discovering it.
>
> Thanks for the report.
>
> Jeff
>
> Jeffrey A. Ryan
> jeffrey.ryan at insightalgo.com
>
> ia: insight algorithmics
> www.insightalgo.com
>
> On Nov 30, 2009, at 8:25 PM, Krishnan Maheswaran
> <krish.maheswaran at gmail.com> wrote:
>
>> HiHi ?All:
>>
>> Apologies for re-posting. I did not properly subscribe to the Rmetrics
>> group.
>>
>>
>> I get the following error when I issue the getFin command:
>>
>>> getFin('AAPL')
>>
>> Error in getFin("AAPL") : subscript out of bounds
>>
>> I would appreciate any help.
>>
>> Thanks in advance,
>> Krish
>>
>> ? [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only.
>> -- If you want to post, subscribe first.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From dengyishuo at 163.com  Sat Jan 23 15:01:43 2010
From: dengyishuo at 163.com (deng yishuo)
Date: Sat, 23 Jan 2010 06:01:43 -0800 (PST)
Subject: [R-SIG-Finance] How to extract all VaR values?
Message-ID: <1264255303705-1288195.post@n4.nabble.com>



Hello,everyone!
I'm using "rgarch"(a very powerful package) now. 
And there is a problem for me.That is I don't  know how to  extract the VaR
values after 
I have caculated them using function ugarchroll().
Please help me!
Thank you so much! 

-----
?????????????????
-- 
View this message in context: http://n4.nabble.com/How-to-extract-all-VaR-values-tp1288195p1288195.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Sat Jan 23 15:18:55 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 23 Jan 2010 08:18:55 -0600
Subject: [R-SIG-Finance] How to extract all VaR values?
In-Reply-To: <1264255303705-1288195.post@n4.nabble.com>
References: <1264255303705-1288195.post@n4.nabble.com>
Message-ID: <4B5B054F.5090207@braverock.com>

deng yishuo wrote:
> Hello,everyone!
> I'm using "rgarch"(a very powerful package) now. 
> And there is a problem for me.That is I don't  know how to  extract the VaR
> values after 
> I have caculated them using function ugarchroll().
> Please help me!
> Thank you so much! 
>   
It would be easier for people to help you if you construct some sample 
data and the commands you use to get to where you're at right now.

Then, anyone on the list can replicate the commands you use to get where 
you are, and it is much easier to help you than to have to start from 
scratch to replicate.

Perhaps, for example, start from examples in the rgarch documentation, 
and get the list to the same point you're at now.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From brian at braverock.com  Sat Jan 23 15:43:22 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 23 Jan 2010 08:43:22 -0600
Subject: [R-SIG-Finance] How to extract all VaR values?
Message-ID: <4B5B0B0A.3010303@braverock.com>

On list. Thanks. I'll take a look at it in a bit if no one beats me to it.

- Brian

-------- Original Message --------
Subject: 	Re:Re: [R-SIG-Finance] How to extract all VaR values?
Date: 	Sat, 23 Jan 2010 22:35:51 +0800 (CST)
From: 	??? <dengyishuo at 163.com>
To: 	Brian G. Peterson <brian at braverock.com>
References: 	<4B5B054F.5090207 at braverock.com> 
<1264255303705-1288195.post at n4.nabble.com>



library(rgarch)
data(sp500ret)
ctrl = list(RHO = 1,DELTA = 1e-9, MAJIT = 100,MINIT = 650,TOL = 1e-7)

spec = ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1,1)), 
		mean.model = list(armaOrder = c(0,0), include.mean = TRUE), 
		distribution.model = "std")

sp500.bktest = ugarchroll(spec, data = sp500ret, n.ahead = 1, forecast.length = 100, 
		refit.every = 1, refit.window = "recursive", use.mclapply = FALSE, 
		solver = "solnp", fit.control = list(), solver.control = ctrl,
		calculate.VaR = TRUE, VaR.alpha = c(0.01, 0.025, 0.05))

#Is there anyway for me to extract everyday's VaR values?




--
???
----------
Regards,
YiShuo
--
YiShuo Deng
Phone: +86-(0)10-62264532
Mobile: +86-13651352627

School of Statistics,
Central University of Finance and Economics, Haidian District ,Beijing, 
100081, China


?2010-01-23 22:18:55?"Brian G. Peterson" <brian at braverock.com> ???
>deng yishuo wrote:
>> Hello,everyone!
>> I'm using "rgarch"(a very powerful package) now. 
>> And there is a problem for me.That is I don't  know how to  extract the VaR
>> values after 
>> I have caculated them using function ugarchroll().
>> Please help me!
>> Thank you so much! 
>>   
>It would be easier for people to help you if you construct some sample 
>data and the commands you use to get to where you're at right now.
>
>Then, anyone on the list can replicate the commands you use to get where 
>you are, and it is much easier to help you than to have to start from 
>scratch to replicate.
>
>Perhaps, for example, start from examples in the rgarch documentation, 
>and get the list to the same point you're at now.
>
>Regards,
>
>   - Brian
>
>-- 
>Brian G. Peterson
>http://braverock.com/brian/
>Ph: 773-459-4973
>IM: bgpbraverock
>
>




-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From alexios at 4dscape.com  Sat Jan 23 16:39:19 2010
From: alexios at 4dscape.com (alexios)
Date: Sat, 23 Jan 2010 15:39:19 +0000
Subject: [R-SIG-Finance] How to extract all VaR values?
In-Reply-To: <4B5B0B0A.3010303@braverock.com>
References: <4B5B0B0A.3010303@braverock.com>
Message-ID: <4B5B1827.2060200@4dscape.com>

There is a data.frame extractor function which is documented (type 
?ugarchroll and look at the
returned class which lists methods for it).

Briefly, you type as.data.frame(x, which = "VaR", n.ahead = ...), where 
"x" is an object of class
uGARCHroll returned from running the ugarchroll function, and n.ahead is 
the n-ahead forecast horizon you
want to have a value returned for and was supplied in the call to the 
ugarchroll function.

Note that the VaR is based on the analytical evaluation of the forecast 
density returned from the GARCH
model rolling forecast.

Regards,
Alexios Ghalanos

On 1/23/2010 2:43 PM, Brian G. Peterson wrote
> On list. Thanks. I'll take a look at it in a bit if no one beats me to 
> it.
>
> - Brian
>
> -------- Original Message --------
> Subject: Re:Re: [R-SIG-Finance] How to extract all VaR values?
> Date: Sat, 23 Jan 2010 22:35:51 +0800 (CST)
> From: ?????? <dengyishuo at 163.com>
> To: Brian G. Peterson <brian at braverock.com>
> References: <4B5B054F.5090207 at braverock.com> 
> <1264255303705-1288195.post at n4.nabble.com>
>
>
>
> library(rgarch)
> data(sp500ret)
> ctrl = list(RHO = 1,DELTA = 1e-9, MAJIT = 100,MINIT = 650,TOL = 1e-7)
>
> spec = ugarchspec(variance.model = list(model = "sGARCH", garchOrder = 
> c(1,1)), mean.model = list(armaOrder = c(0,0), include.mean = TRUE), 
> distribution.model = "std")
>
> sp500.bktest = ugarchroll(spec, data = sp500ret, n.ahead = 1, 
> forecast.length = 100, refit.every = 1, refit.window = "recursive", 
> use.mclapply = FALSE, solver = "solnp", fit.control = list(), 
> solver.control = ctrl,
> calculate.VaR = TRUE, VaR.alpha = c(0.01, 0.025, 0.05))
>
> #Is there anyway for me to extract everyday's VaR values?
>
>
>
>
> -- 
> ??????
> ----------
> Regards,
> YiShuo
> -- 
> YiShuo Deng
> Phone: +86-(0)10-62264532
> Mobile: +86-13651352627
>
> School of Statistics,
> Central University of Finance and Economics, Haidian District 
> ,Beijing, 100081, China
>
>
> ??2010-01-23 22:18:55??"Brian G. Peterson" <brian at braverock.com> ??????
>> deng yishuo wrote:
>>> Hello,everyone!
>>> I'm using "rgarch"(a very powerful package) now. And there is a 
>>> problem for me.That is I don't know how to extract the VaR
>>> values after I have caculated them using function ugarchroll().
>>> Please help me!
>>> Thank you so much! 
>> It would be easier for people to help you if you construct some 
>> sample data and the commands you use to get to where you're at right 
>> now.
>>
>> Then, anyone on the list can replicate the commands you use to get 
>> where you are, and it is much easier to help you than to have to 
>> start from scratch to replicate.
>>
>> Perhaps, for example, start from examples in the rgarch 
>> documentation, and get the list to the same point you're at now.
>>
>> Regards,
>>
>> - Brian
>>
>> -- 
>> Brian G. Peterson
>> http://braverock.com/brian/
>> Ph: 773-459-4973
>> IM: bgpbraverock
>>
>>
>
>
>
>


From veepsirtt at gmail.com  Sun Jan 24 02:38:32 2010
From: veepsirtt at gmail.com (Velappan Periasamy)
Date: Sun, 24 Jan 2010 07:08:32 +0530
Subject: [R-SIG-Finance] Statistically how to find overbought and oversold
	condition of stocks?.
Message-ID: <c224dc731001231738s7e03a502y664fd3487fb975e2@mail.gmail.com>

Statistically how to find overbought and oversold condition of stocks.
Name some prediction methods available in R?.


From edd at debian.org  Sun Jan 24 03:04:07 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 23 Jan 2010 20:04:07 -0600
Subject: [R-SIG-Finance] Statistically how to find overbought and
	oversold	condition of stocks?.
In-Reply-To: <c224dc731001231738s7e03a502y664fd3487fb975e2@mail.gmail.com>
References: <c224dc731001231738s7e03a502y664fd3487fb975e2@mail.gmail.com>
Message-ID: <19291.43671.195703.185713@ron.nulle.part>


On 24 January 2010 at 07:08, Velappan Periasamy wrote:
| Statistically how to find overbought and oversold condition of stocks.

People have been trying to do that for as long as markets existed. Luckily,
the ideas, opinions, methods, implementationds, data sets, ... all differ so
that folks end up with different views.  

Which is what you need for a functioning market: a buyer for every seller.

| Name some prediction methods available in R?.

That's a little broad.  Why don't you do a little homework first and come
back with real questions, preferably with some R content? 

One starting point is e.g. http://cran.r-project.org/web/views/ and you can
pick your favourite area: Machine Learning, Clustering, Robust,
Econnometrics, Bayesian, ...

Dirk

-- 
Three out of two people have difficulties with fractions.


From markknecht at gmail.com  Sun Jan 24 03:21:31 2010
From: markknecht at gmail.com (Mark Knecht)
Date: Sat, 23 Jan 2010 18:21:31 -0800
Subject: [R-SIG-Finance] Statistically how to find overbought and
	oversold condition of stocks?.
In-Reply-To: <c224dc731001231738s7e03a502y664fd3487fb975e2@mail.gmail.com>
References: <c224dc731001231738s7e03a502y664fd3487fb975e2@mail.gmail.com>
Message-ID: <5bdc1c8b1001231821u2a85ac1ck4e5f3250d6ba8fd3@mail.gmail.com>

On Sat, Jan 23, 2010 at 5:38 PM, Velappan Periasamy <veepsirtt at gmail.com> wrote:
> Statistically how to find overbought and oversold condition of stocks.
> Name some prediction methods available in R?.
>

Welcome to the world of R email lists - a different animal than any
other on the web...

Anyway, Investopedia has some fairly straight forward answers to your
question. Using this description you could use anything like RSI,
stochastics, etc.

http://www.investopedia.com/terms/o/overbought.asp

Hope this helps,
Mark


From guillaume.yziquel at citycable.ch  Sun Jan 24 15:39:59 2010
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Sun, 24 Jan 2010 15:39:59 +0100
Subject: [R-SIG-Finance] How to extract all VaR values?
In-Reply-To: <4B5B0B0A.3010303@braverock.com>
References: <4B5B0B0A.3010303@braverock.com>
Message-ID: <4B5C5BBF.2080208@citycable.ch>

Brian G. Peterson a ?crit :
> On list. Thanks. I'll take a look at it in a bit if no one beats me to it.
> 
> - Brian
> 
> -------- Original Message --------
> Subject:     Re:Re: [R-SIG-Finance] How to extract all VaR values?
> Date:     Sat, 23 Jan 2010 22:35:51 +0800 (CST)
> From:     ??? <dengyishuo at 163.com>
> To:     Brian G. Peterson <brian at braverock.com>
> References:     <4B5B054F.5090207 at braverock.com> 
> <1264255303705-1288195.post at n4.nabble.com>
> 
> 
> 
> library(rgarch)
> data(sp500ret)
> ctrl = list(RHO = 1,DELTA = 1e-9, MAJIT = 100,MINIT = 650,TOL = 1e-7)
> 
> spec = ugarchspec(variance.model = list(model = "sGARCH", garchOrder = 
> c(1,1)),         mean.model = list(armaOrder = c(0,0), include.mean = 
> TRUE),         distribution.model = "std")

Hi.

I've just tried using rgarch, and it seems to me that there are a few 
issues with the package. I'm installing the package from R-forge:

>> install.packages("rgarch",repos="http://R-Forge.R-project.org")
> Avis dans install.packages("rgarch", repos = "http://R-Forge.R-project.org") :
>   l'argument 'lib' manque : '/home/yziquel/R/x86_64-pc-linux-gnu-library/2.10' est utilis?
> also installing the dependency ?Rsolnp?
> 
> essai de l'URL 'http://R-Forge.R-project.org/src/contrib/Rsolnp2_0.3.tar.gz'
> Content type 'application/x-gzip' length 120837 bytes (118 Kb)
> URL ouverte
> ==================================================
> downloaded 118 Kb
> 
> essai de l'URL 'http://R-Forge.R-project.org/src/contrib/regr0_1.0.tar.gz'
> Content type 'application/x-gzip' length 114317 bytes (111 Kb)
> URL ouverte
> ==================================================
> downloaded 111 Kb
> 
> * installing *source* package ?Rsolnp2? ...
> ** R
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices ...
> * DONE (Rsolnp2)
> * installing *source* package ?regr0? ...
> ** R
> ** data
> ** preparing package for lazy loading
> ** help
> Avis : ./man/drop1.regr.Rd:30: unknown macro '\lind'
> *** installing help indices
> ** building package indices ...
> * DONE (regr0)
> 
> Les packages t?l?charg?s sont dans
> 	?/tmp/Rtmp0M6Zuj/downloaded_packages?
>> library(rgarch)
> Erreur dans library(rgarch) : aucun package nomm? 'rgarch' n'est trouv?

So I tried to check the availability of the dependencies:

>> library(stats)
>> library(graphics)
>> library(methods)
>> library(Matrix)
> Le chargement a n?cessit? le package : lattice
>> library(chron)
>> library(Rsolnp)
> Erreur dans library(Rsolnp) : aucun package nomm? 'Rsolnp' n'est trouv?
>> library(Rsolnp2)
>> library(sandwich)
> Le chargement a n?cessit? le package : zoo

In the rgarch repository, I see that rgarch depends on Rsolnp:

http://r-forge.r-project.org/plugins/scmsvn/viewcvs.php/pkg/DESCRIPTION?rev=143&root=rgarch&view=markup

But somehow, on the Net, I only see things concerning Rsolnp2, which is 
available in the Rmetrics package. Moreover, in the Rmetrics repository, 
you have:

http://r-forge.r-project.org/plugins/scmsvn/viewcvs.php/pkg/Rsolnp2/IMPORTANT?rev=4479&root=rmetrics&view=markup

> new package Rsonlp2 from Alexios and Stefan added
> 
> This solver will be withdrawn from Rmetrics as soon as the solver package
> Rsonlp written by Alexios Ghalanos and Stefan Theussl will be released to
> CRAN.
> 
> Diethelm Wuertz

But Rsolnp is nowhere to be seen.

So am I hitting a real issue getting rgarch to work on my Debian R 
system? Or, plainly, how do you get rgarch working?

All the best,

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From alexios at 4dscape.com  Sun Jan 24 16:48:27 2010
From: alexios at 4dscape.com (alexios)
Date: Sun, 24 Jan 2010 15:48:27 +0000
Subject: [R-SIG-Finance] How to extract all VaR values?
In-Reply-To: <4B5C5BBF.2080208@citycable.ch>
References: <4B5B0B0A.3010303@braverock.com> <4B5C5BBF.2080208@citycable.ch>
Message-ID: <4B5C6BCB.80804@4dscape.com>

The 'official' Rsolnp package is part of the Rino package on r-forge, 
which a search in R or google reveals(http://lmgtfy.com/?q=Rsolnp).

http://r-forge.r-project.org/projects/rino/

Regards,
-Alexios Ghalanos

On 1/24/2010 2:39 PM, Guillaume Yziquel wrote:
> Brian G. Peterson a ?crit :
>> On list. Thanks. I'll take a look at it in a bit if no one beats me to
>> it.
>>
>> - Brian
>>
>> -------- Original Message --------
>> Subject: Re:Re: [R-SIG-Finance] How to extract all VaR values?
>> Date: Sat, 23 Jan 2010 22:35:51 +0800 (CST)
>> From: ??? <dengyishuo at 163.com>
>> To: Brian G. Peterson <brian at braverock.com>
>> References: <4B5B054F.5090207 at braverock.com>
>> <1264255303705-1288195.post at n4.nabble.com>
>>
>>
>>
>> library(rgarch)
>> data(sp500ret)
>> ctrl = list(RHO = 1,DELTA = 1e-9, MAJIT = 100,MINIT = 650,TOL = 1e-7)
>>
>> spec = ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>> c(1,1)), mean.model = list(armaOrder = c(0,0), include.mean = TRUE),
>> distribution.model = "std")
>
> Hi.
>
> I've just tried using rgarch, and it seems to me that there are a few
> issues with the package. I'm installing the package from R-forge:
>
>>> install.packages("rgarch",repos="http://R-Forge.R-project.org")
>> Avis dans install.packages("rgarch", repos =
>> "http://R-Forge.R-project.org") :
>> l'argument 'lib' manque :
>> '/home/yziquel/R/x86_64-pc-linux-gnu-library/2.10' est utilis?
>> also installing the dependency ?Rsolnp?
>>
>> essai de l'URL
>> 'http://R-Forge.R-project.org/src/contrib/Rsolnp2_0.3.tar.gz'
>> Content type 'application/x-gzip' length 120837 bytes (118 Kb)
>> URL ouverte
>> ==================================================
>> downloaded 118 Kb
>>
>> essai de l'URL
>> 'http://R-Forge.R-project.org/src/contrib/regr0_1.0.tar.gz'
>> Content type 'application/x-gzip' length 114317 bytes (111 Kb)
>> URL ouverte
>> ==================================================
>> downloaded 111 Kb
>>
>> * installing *source* package ?Rsolnp2? ...
>> ** R
>> ** inst
>> ** preparing package for lazy loading
>> ** help
>> *** installing help indices
>> ** building package indices ...
>> * DONE (Rsolnp2)
>> * installing *source* package ?regr0? ...
>> ** R
>> ** data
>> ** preparing package for lazy loading
>> ** help
>> Avis : ./man/drop1.regr.Rd:30: unknown macro '\lind'
>> *** installing help indices
>> ** building package indices ...
>> * DONE (regr0)
>>
>> Les packages t?l?charg?s sont dans
>> ?/tmp/Rtmp0M6Zuj/downloaded_packages?
>>> library(rgarch)
>> Erreur dans library(rgarch) : aucun package nomm? 'rgarch' n'est trouv?
>
> So I tried to check the availability of the dependencies:
>
>>> library(stats)
>>> library(graphics)
>>> library(methods)
>>> library(Matrix)
>> Le chargement a n?cessit? le package : lattice
>>> library(chron)
>>> library(Rsolnp)
>> Erreur dans library(Rsolnp) : aucun package nomm? 'Rsolnp' n'est trouv?
>>> library(Rsolnp2)
>>> library(sandwich)
>> Le chargement a n?cessit? le package : zoo
>
> In the rgarch repository, I see that rgarch depends on Rsolnp:
>
> http://r-forge.r-project.org/plugins/scmsvn/viewcvs.php/pkg/DESCRIPTION?rev=143&root=rgarch&view=markup
>
>
> But somehow, on the Net, I only see things concerning Rsolnp2, which is
> available in the Rmetrics package. Moreover, in the Rmetrics repository,
> you have:
>
> http://r-forge.r-project.org/plugins/scmsvn/viewcvs.php/pkg/Rsolnp2/IMPORTANT?rev=4479&root=rmetrics&view=markup
>
>
>> new package Rsonlp2 from Alexios and Stefan added
>>
>> This solver will be withdrawn from Rmetrics as soon as the solver package
>> Rsonlp written by Alexios Ghalanos and Stefan Theussl will be released to
>> CRAN.
>>
>> Diethelm Wuertz
>
> But Rsolnp is nowhere to be seen.
>
> So am I hitting a real issue getting rgarch to work on my Debian R
> system? Or, plainly, how do you get rgarch working?
>
> All the best,
>


From edd at debian.org  Sun Jan 24 17:04:15 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 24 Jan 2010 10:04:15 -0600
Subject: [R-SIG-Finance] How to extract all VaR values?
In-Reply-To: <4B5C5BBF.2080208@citycable.ch>
References: <4B5B0B0A.3010303@braverock.com>
	<4B5C5BBF.2080208@citycable.ch>
Message-ID: <19292.28543.897154.136288@ron.nulle.part>


On 24 January 2010 at 15:39, Guillaume Yziquel wrote:
| I've just tried using rgarch, and it seems to me that there are a few 
| issues with the package. I'm installing the package from R-forge:
| 
| >> install.packages("rgarch",repos="http://R-Forge.R-project.org")
| > Avis dans install.packages("rgarch", repos = "http://R-Forge.R-project.org") :
| >   l'argument 'lib' manque : '/home/yziquel/R/x86_64-pc-linux-gnu-library/2.10' est utilis?
| > also installing the dependency ?Rsolnp?
| > 
| > essai de l'URL 'http://R-Forge.R-project.org/src/contrib/Rsolnp2_0.3.tar.gz'
| > Content type 'application/x-gzip' length 120837 bytes (118 Kb)
| > URL ouverte
| > ==================================================
| > downloaded 118 Kb
| > 
| > essai de l'URL 'http://R-Forge.R-project.org/src/contrib/regr0_1.0.tar.gz'
| > Content type 'application/x-gzip' length 114317 bytes (111 Kb)
| > URL ouverte
| > ==================================================
| > downloaded 111 Kb
| > 
| > * installing *source* package ?Rsolnp2? ...
| > ** R
| > ** inst
| > ** preparing package for lazy loading
| > ** help
| > *** installing help indices
| > ** building package indices ...
| > * DONE (Rsolnp2)
| > * installing *source* package ?regr0? ...
| > ** R
| > ** data
| > ** preparing package for lazy loading
| > ** help
| > Avis : ./man/drop1.regr.Rd:30: unknown macro '\lind'
| > *** installing help indices
| > ** building package indices ...
| > * DONE (regr0)
| > 
| > Les packages t?l?charg?s sont dans
| > 	?/tmp/Rtmp0M6Zuj/downloaded_packages?
| >> library(rgarch)
| > Erreur dans library(rgarch) : aucun package nomm? 'rgarch' n'est trouv?
| 
| So I tried to check the availability of the dependencies:
| 
| >> library(stats)
| >> library(graphics)
| >> library(methods)
| >> library(Matrix)
| > Le chargement a n?cessit? le package : lattice
| >> library(chron)
| >> library(Rsolnp)
| > Erreur dans library(Rsolnp) : aucun package nomm? 'Rsolnp' n'est trouv?
| >> library(Rsolnp2)
| >> library(sandwich)
| > Le chargement a n?cessit? le package : zoo
| 
| In the rgarch repository, I see that rgarch depends on Rsolnp:
| 
| http://r-forge.r-project.org/plugins/scmsvn/viewcvs.php/pkg/DESCRIPTION?rev=143&root=rgarch&view=markup
| 
| But somehow, on the Net, I only see things concerning Rsolnp2, which is 
| available in the Rmetrics package. Moreover, in the Rmetrics repository, 
| you have:
| 
| http://r-forge.r-project.org/plugins/scmsvn/viewcvs.php/pkg/Rsolnp2/IMPORTANT?rev=4479&root=rmetrics&view=markup
| 
| > new package Rsonlp2 from Alexios and Stefan added
| > 
| > This solver will be withdrawn from Rmetrics as soon as the solver package
| > Rsonlp written by Alexios Ghalanos and Stefan Theussl will be released to
| > CRAN.
| > 
| > Diethelm Wuertz
| 
| But Rsolnp is nowhere to be seen.
| 
| So am I hitting a real issue getting rgarch to work on my Debian R 
| system? Or, plainly, how do you get rgarch working?

This may or may not be related:

  Date: Sun, 24 Jan 2010 10:09:43 +0000
  From: Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
  To: r-help at r-project.org
  Subject: [R] R-forge getting the wrong package

  After accusing someone of typing 'install.packages("weather")' instead
  of 'install.packages("webmaps")', I discovered that R-forge really is
  currently returning the wrong source tarball for packages after
  'Repitools' in the alphabet.

  The data returned from available.package in install.packages goes out
  of sync at 'Repitools':

  RemoteREngine                      "RemoteREngine_0.0-8.tar.gz"
  RemoteSensing                      "RemoteSensing_0.2-5.tar.gz"
  Repitools                          "RepitoolsExamples_1.01.tar.gz"
  Rglpk                              "Repitools_0.0.107.tar.gz"
  Ripop                              "Rglpk_0.3-2.tar.gz"
  Rllvm                              "Ripop_0.1.tar.gz"
  RlpSolveAPI                        "Rllvm_0.1.tar.gz"
 
  [...]

Can you please download the .tar.gz in question by hand, run R CMD INSTALL on
it and see if that works?  You may have to do that recursively for its
dependencies.  

Dirk

-- 
Three out of two people have difficulties with fractions.


From jonathan.shore at gmail.com  Sun Jan 24 18:57:32 2010
From: jonathan.shore at gmail.com (Jonathan Shore)
Date: Sun, 24 Jan 2010 09:57:32 -0800 (PST)
Subject: [R-SIG-Finance] IBrokers - twsConnect error
In-Reply-To: <e8e755251001161000q1a2799ceo18a6051606fe31ab@mail.gmail.com>
References: <86319cea1001160944p77f953f0mea644ef5369a647a@mail.gmail.com>
	<e8e755251001161000q1a2799ceo18a6051606fe31ab@mail.gmail.com>
Message-ID: <1264355852835-1288760.post@n4.nabble.com>


Hi,

Well it looks like IB did it again (more transparent updates).  The
CLIENT_VERSION is now 46 rather than 45, so twsConnect() fails.   I looked
at what is currently in the google code project and still references 45.   I
tried locally adjusting CLIENT_VERSION to "46".   twsConnect() got further,
but then faulted at:

if (curMsg == .twsIncomingMSG$ERR_MSG) {
    if (!errorHandler(s, verbose)) ...
}

My TWS client is Build 901.8, Jan 20, 2010 1:17:05 PM.

Not sure if there is something other than the version number that needs to
be updated.  Hopefully there are no protocol changes.

Jonathan
--
http://tr8dr.wordpress.com/

-- 
View this message in context: http://n4.nabble.com/IBrokers-twsConnect-error-tp1015713p1288760.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From jeff.a.ryan at gmail.com  Sun Jan 24 19:09:39 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sun, 24 Jan 2010 12:09:39 -0600
Subject: [R-SIG-Finance] IBrokers - twsConnect error
In-Reply-To: <1264355852835-1288760.post@n4.nabble.com>
References: <86319cea1001160944p77f953f0mea644ef5369a647a@mail.gmail.com>
	<e8e755251001161000q1a2799ceo18a6051606fe31ab@mail.gmail.com>
	<1264355852835-1288760.post@n4.nabble.com>
Message-ID: <e8e755251001241009h7695e61bq5653562aabc3b653@mail.gmail.com>

Hi Jonathan,

There is a new version of IBrokers on the way to CRAN.  This should
address the issue.

The CLIENT_VERSION needn't keep up btw.  The failure was coming from
the internal check for a match to the sent CLIENT_VERSION.  This was
never needed, and the connection has been refactored to have
connections be more robust.

Check CRAN in the next day or two.

Best,
Jeff

On Sun, Jan 24, 2010 at 11:57 AM, Jonathan Shore
<jonathan.shore at gmail.com> wrote:
>
> Hi,
>
> Well it looks like IB did it again (more transparent updates). ?The
> CLIENT_VERSION is now 46 rather than 45, so twsConnect() fails. ? I looked
> at what is currently in the google code project and still references 45. ? I
> tried locally adjusting CLIENT_VERSION to "46". ? twsConnect() got further,
> but then faulted at:
>
> if (curMsg == .twsIncomingMSG$ERR_MSG) {
> ? ?if (!errorHandler(s, verbose)) ...
> }
>
> My TWS client is Build 901.8, Jan 20, 2010 1:17:05 PM.
>
> Not sure if there is something other than the version number that needs to
> be updated. ?Hopefully there are no protocol changes.
>
> Jonathan
> --
> http://tr8dr.wordpress.com/
>
> --
> View this message in context: http://n4.nabble.com/IBrokers-twsConnect-error-tp1015713p1288760.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From i.siddharth at gmail.com  Mon Jan 25 07:29:38 2010
From: i.siddharth at gmail.com (Siddharth Agarwal)
Date: Mon, 25 Jan 2010 14:29:38 +0800
Subject: [R-SIG-Finance] Getting Index Members
Message-ID: <6ba9f3631001242229j2b6b8b98ufe25e42734a6329c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100125/8773d3b9/attachment.asc>

From sankalp.upadhyay at gmail.com  Mon Jan 25 18:14:13 2010
From: sankalp.upadhyay at gmail.com (Sankalp Upadhyay)
Date: Tue, 26 Jan 2010 01:14:13 +0800
Subject: [R-SIG-Finance] Getting Index Members
In-Reply-To: <6ba9f3631001242229j2b6b8b98ufe25e42734a6329c@mail.gmail.com>
References: <6ba9f3631001242229j2b6b8b98ufe25e42734a6329c@mail.gmail.com>
Message-ID: <1264439653.19590.35.camel@linux-desktop>

Hi,

AFAIK, RBloomberg does not support bulk fields. Index members is a bulk
field.
However, the code below works. The returned data structure is not very
pretty but the data seems correct:

blCon <<- try(blCon <- COMCreate("Bloomberg.Data.1"), silent=TRUE)
bulkData <- blpSubscribe(blCon, "TPELMH Index", "INDX_MEMBERS");
blpDisconnect(blCon)

The code is from
https://stat.ethz.ch/pipermail/r-sig-finance/2005q1/000281.html


Regards


On Mon, 2010-01-25 at 14:29 +0800, Siddharth Agarwal wrote:
> Hi Everyone,
> 
> 
> 
>  I just started using Rbloomberg and am facing a small problem.
> 
>  I went through previous queries but couldnt find a solution.
> 
> 
> 
> While trying to get the list of index members for a given index
> 
> 
> 
> index.memb<-blp(conn,"TPELMH Index","INDX_MEMBERS")
> 
> 
> 
> I get the following error
> 
> 
> 
> Error in blpSubscribe(conn, securities, fields, override_fields, overrides)
> :
> 
>   Call to BLPSubscribe did not return any data!
> 
> 
> 
> Can someone please suggest a way to get the members list ?
> 
> 
> 
> Many Thanks,
> 
> Siddharth
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From karlavhv142 at hotmail.com  Mon Jan 25 19:55:35 2010
From: karlavhv142 at hotmail.com (karla hernandez villafuerte)
Date: Mon, 25 Jan 2010 12:55:35 -0600
Subject: [R-SIG-Finance] Cointegration, more than one structural break
Message-ID: <COL124-W622B2B85C6C07B6DB781CFE55F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100125/523f3ba5/attachment.pl>

From guillaume.yziquel at citycable.ch  Tue Jan 26 02:40:32 2010
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Tue, 26 Jan 2010 02:40:32 +0100
Subject: [R-SIG-Finance] How to extract all VaR values?
In-Reply-To: <19292.28543.897154.136288@ron.nulle.part>
References: <4B5B0B0A.3010303@braverock.com>	<4B5C5BBF.2080208@citycable.ch>
	<19292.28543.897154.136288@ron.nulle.part>
Message-ID: <4B5E4810.6060504@citycable.ch>

Dirk Eddelbuettel a ?crit :
> 
> This may or may not be related:
> 
>   Date: Sun, 24 Jan 2010 10:09:43 +0000
>   From: Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
>   To: r-help at r-project.org
>   Subject: [R] R-forge getting the wrong package
> 
>   After accusing someone of typing 'install.packages("weather")' instead
>   of 'install.packages("webmaps")', I discovered that R-forge really is
>   currently returning the wrong source tarball for packages after
>   'Repitools' in the alphabet.
> 
>   The data returned from available.package in install.packages goes out
>   of sync at 'Repitools':

Yes. That definitely was the issue. Sorry for the bother.

All the best,

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From Samuel.Meichtry at bkw-fmb.ch  Tue Jan 26 07:51:41 2010
From: Samuel.Meichtry at bkw-fmb.ch (Samuel.Meichtry at bkw-fmb.ch)
Date: Tue, 26 Jan 2010 07:51:41 +0100
Subject: [R-SIG-Finance] Estimation of growth in electricity consumption
	timeserie [hourly]
Message-ID: <201001260651.o0Q6prER021915@hypatia.math.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100126/49ebb6ff/attachment.pl>

From bogaso.christofer at gmail.com  Tue Jan 26 09:25:16 2010
From: bogaso.christofer at gmail.com (Bogaso)
Date: Tue, 26 Jan 2010 00:25:16 -0800 (PST)
Subject: [R-SIG-Finance] Need help please
Message-ID: <1264494316707-1290132.post@n4.nabble.com>


Dear folks,

I got a very notorious weekly price series where price seldom changes like :

6-Jan-92	4.38
13-Jan-92	4.38
20-Jan-92	4.38
27-Jan-92	4.38
3-Feb-92	4.38
10-Feb-92	4.38
17-Feb-92	4.38
24-Feb-92	4.38
2-Mar-92	4.38
9-Mar-92	4.38
16-Mar-92	4.38
23-Mar-92	4.38
30-Mar-92	4.38
6-Apr-92	4.38
13-Apr-92	4.38
20-Apr-92	6.56
27-Apr-92	6.56
4-May-92	6.56
11-May-92	6.56
18-May-92	6.56
25-May-92	6.56
1-Jun-92	6.56
8-Jun-92	6.63
15-Jun-92	6.63
22-Jun-92	6.63
29-Jun-92	6.63
6-Jul-92	6.63
13-Jul-92	6.63
20-Jul-92	6.99
27-Jul-92	6.99
3-Aug-92	6.99
10-Aug-92	6.99
17-Aug-92	6.99
24-Aug-92	6.99
31-Aug-92	6.99
7-Sep-92	6.99
14-Sep-92	6.99
21-Sep-92	6.99
28-Sep-92	6.99
5-Oct-92	6.99
12-Oct-92	6.99
19-Oct-92	6.99
26-Oct-92	6.99
2-Nov-92	6.99
9-Nov-92	6.99
16-Nov-92	6.99
23-Nov-92	6.99
30-Nov-92	6.99
7-Dec-92	6.99
14-Dec-92	6.99
21-Dec-92	6.99
28-Dec-92	6.99
4-Jan-93	6.99
11-Jan-93	6.99
18-Jan-93	6.99
25-Jan-93	6.99
1-Feb-93	6.99
8-Feb-93	6.99
15-Feb-93	6.99
22-Feb-93	6.99
1-Mar-93	6.99
8-Mar-93	6.99
15-Mar-93	6.99
22-Mar-93	6.56
29-Mar-93	6.56
5-Apr-93	6.56
12-Apr-93	6.56
19-Apr-93	6.56
26-Apr-93	6.56
3-May-93	6.56
10-May-93	6.63
17-May-93	6.63
24-May-93	6.63
31-May-93	6.63
7-Jun-93	6.63
14-Jun-93	6.63
21-Jun-93	6.99
28-Jun-93	6.99
5-Jul-93	6.99
12-Jul-93	6.99
19-Jul-93	6.99
26-Jul-93	6.99
2-Aug-93	6.99
9-Aug-93	6.99
16-Aug-93	6.99
23-Aug-93	6.99

I have a mandate to calculate VaR on that price data, probably in Parametric
way. My question is can I apply standard way which we generally use like
log-normally distributed price, to calculate VaR here? Or some other
modeling approach needs to be taken care? Can anyone please provide me any
references over net, how to handle this type of scenario?

Your help will be highly appreciated.

Thanks,
-- 
View this message in context: http://n4.nabble.com/Need-help-please-tp1290132p1290132.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From patrick at burns-stat.com  Tue Jan 26 13:01:52 2010
From: patrick at burns-stat.com (Patrick Burns)
Date: Tue, 26 Jan 2010 12:01:52 +0000
Subject: [R-SIG-Finance] BurStFin package
Message-ID: <4B5ED9B0.3090802@burns-stat.com>

The (public domain) package BurStFin is now
available at repository:
http://www.burns-stat.com/R

This largely consists of functions that have
been split off from the commercial software.

The functionality includes:

* estimation of a variance matrix as a statistical
factor model (missing values are allowed -- even
all missing for some assets).

* estimation of a variance matrix by shrinking to
the equal correlation matrix (Ledoit-Wolf).  This
also allows missing values.

* Add a benchmark to a variance matrix

* Transform a variance matrix to be relative to a
benchmark.


The 'tawny' package also has a function to estimate
the shrinkage variance.  There is a slight difference
in the estimated shrinkage.  I have circumstantial
evidence that the BurStFin function is what Ledoit-Wolf
does, but it would be nice if someone spent the time
to sort that out.

For those looking for research topics, the help files
for the two variance estimation functions have some
questions that we don't seem to know the answers to.

BurStFin will eventually, at the appropriate juncture,
in due course, in the fullness of time, at the end of
the day appear on CRAN.


Caution: if you have R version 2.10.0, you
need to update to 2.10.1 in order to have
the repository work.

Windows binary and source are available, but MacOS is
not.  However, all the code is R code -- there is no
C or Fortran.

More details at:
http://www.burns-stat.com/pages/public.html

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com


From rdapamoga at gmail.com  Wed Jan 27 13:53:32 2010
From: rdapamoga at gmail.com (Trafim Vanishek)
Date: Wed, 27 Jan 2010 13:53:32 +0100
Subject: [R-SIG-Finance] GARCH (1,1) negative volatility???
In-Reply-To: <7dc3eb8d1001270304n17799166x7a4e904657f32df@mail.gmail.com>
References: <7dc3eb8d1001270304n17799166x7a4e904657f32df@mail.gmail.com>
Message-ID: <7dc3eb8d1001270453j25f973d2if69fc91295f82227@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100127/979c4e5e/attachment.pl>

From rdapamoga at gmail.com  Wed Jan 27 14:28:07 2010
From: rdapamoga at gmail.com (Trafim Vanishek)
Date: Wed, 27 Jan 2010 14:28:07 +0100
Subject: [R-SIG-Finance] GARCH (1,1) negative volatility???
In-Reply-To: <OFEDAB7469.5DFC5523-ONC12576B8.0048BBF1-C12576B8.00492986@hsbctrinkaus.de>
References: <7dc3eb8d1001270304n17799166x7a4e904657f32df@mail.gmail.com>
	<7dc3eb8d1001270453j25f973d2if69fc91295f82227@mail.gmail.com>
	<OFEDAB7469.5DFC5523-ONC12576B8.0048BBF1-C12576B8.00492986@hsbctrinkaus.de>
Message-ID: <7dc3eb8d1001270528x661f3083g2d28d0ef12e9a62a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100127/1a33066c/attachment.pl>

From martin.becker at mx.uni-saarland.de  Wed Jan 27 14:48:50 2010
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Wed, 27 Jan 2010 14:48:50 +0100
Subject: [R-SIG-Finance] GARCH (1,1) negative volatility???
In-Reply-To: <7dc3eb8d1001270453j25f973d2if69fc91295f82227@mail.gmail.com>
References: <7dc3eb8d1001270304n17799166x7a4e904657f32df@mail.gmail.com>
	<7dc3eb8d1001270453j25f973d2if69fc91295f82227@mail.gmail.com>
Message-ID: <4B604442.9050904@mx.uni-saarland.de>

Dear Trafim,

your code simulates a GARCH(1,1) - process, which is (of course) *not* 
restricted to be nonnegative; the volatility equation of a GARCH(1,1) 
process (which indeed should not produce negative values) is only one of 
the ingredients of the process. If you want to access the conditional 
volatilities (and not the GARCH process path itself), you have to use 
the "extended" argument as in
  gat <- garchSim(spec, n = 10, extended = TRUE)
and extract the conditional volatilities via
  gat$sigma

Best,
  Martin



Trafim Vanishek wrote:
> Dear all,
>
> I am using GARCH (1,1) model to simulate volatility.
> But seems that I am missing something about how it works in R.
>
> The following code produces negative results, though vola cannot be.
> What is wrong here?
>
> library("fSeries")
> library("fGarch")
>
> spec = garchSpec(model = list(omega = 0.01, alpha = 0.13, beta = 0.86))
> gat <- garchSim(spec, n = 10)
>
> Thanks a lot!
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>   


-- 
Dr. Martin Becker
Statistics and Econometrics
Saarland University
Campus C3 1, Room 206
66123 Saarbruecken
Germany


From matthieu.stigler at gmail.com  Wed Jan 27 15:08:05 2010
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Wed, 27 Jan 2010 15:08:05 +0100
Subject: [R-SIG-Finance] Cointegration, more than one structural break
In-Reply-To: <COL124-W622B2B85C6C07B6DB781CFE55F0@phx.gbl>
References: <COL124-W622B2B85C6C07B6DB781CFE55F0@phx.gbl>
Message-ID: <111060c21001270608i6c2e773dwe15e47f07a076dcd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100127/003394bd/attachment.pl>

From ivan.zhang at bankofamerica.com  Wed Jan 27 17:44:37 2010
From: ivan.zhang at bankofamerica.com (Zhang, Ivan)
Date: Wed, 27 Jan 2010 11:44:37 -0500
Subject: [R-SIG-Finance] Need help please
In-Reply-To: <1264494316707-1290132.post@n4.nabble.com>
References: <1264494316707-1290132.post@n4.nabble.com>
Message-ID: <338D58262CB96E438AD6AFEEE6D9482DDDB712@ex2k.bankofamerica.com>

Hi Bogaso,

This may not necessarily help you get an answer, but perhaps would steer
you in another direction:

If the series doesn't look continuous you may potentially be able to
pick a quantile that would make this measure not "coherent" which
basically invalidates the use of VaR as a measure of risk in this case.

For more information on Coherent risk measures, see below link or Google
"coherent risk measure"

http://www.math.ethz.ch/~delbaen/ftp/preprints/CoherentMF.pdf


Hope this helps,


-Ivan Zhang

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Bogaso
Sent: Tuesday, January 26, 2010 3:25 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] Need help please


Dear folks,

I got a very notorious weekly price series where price seldom changes
like :

6-Jan-92	4.38
13-Jan-92	4.38
20-Jan-92	4.38
27-Jan-92	4.38
3-Feb-92	4.38
10-Feb-92	4.38
17-Feb-92	4.38
24-Feb-92	4.38
2-Mar-92	4.38
9-Mar-92	4.38
16-Mar-92	4.38
23-Mar-92	4.38
30-Mar-92	4.38
6-Apr-92	4.38
13-Apr-92	4.38
20-Apr-92	6.56
27-Apr-92	6.56
4-May-92	6.56
11-May-92	6.56
18-May-92	6.56
25-May-92	6.56
1-Jun-92	6.56
8-Jun-92	6.63
15-Jun-92	6.63
22-Jun-92	6.63
29-Jun-92	6.63
6-Jul-92	6.63
13-Jul-92	6.63
20-Jul-92	6.99
27-Jul-92	6.99
3-Aug-92	6.99
10-Aug-92	6.99
17-Aug-92	6.99
24-Aug-92	6.99
31-Aug-92	6.99
7-Sep-92	6.99
14-Sep-92	6.99
21-Sep-92	6.99
28-Sep-92	6.99
5-Oct-92	6.99
12-Oct-92	6.99
19-Oct-92	6.99
26-Oct-92	6.99
2-Nov-92	6.99
9-Nov-92	6.99
16-Nov-92	6.99
23-Nov-92	6.99
30-Nov-92	6.99
7-Dec-92	6.99
14-Dec-92	6.99
21-Dec-92	6.99
28-Dec-92	6.99
4-Jan-93	6.99
11-Jan-93	6.99
18-Jan-93	6.99
25-Jan-93	6.99
1-Feb-93	6.99
8-Feb-93	6.99
15-Feb-93	6.99
22-Feb-93	6.99
1-Mar-93	6.99
8-Mar-93	6.99
15-Mar-93	6.99
22-Mar-93	6.56
29-Mar-93	6.56
5-Apr-93	6.56
12-Apr-93	6.56
19-Apr-93	6.56
26-Apr-93	6.56
3-May-93	6.56
10-May-93	6.63
17-May-93	6.63
24-May-93	6.63
31-May-93	6.63
7-Jun-93	6.63
14-Jun-93	6.63
21-Jun-93	6.99
28-Jun-93	6.99
5-Jul-93	6.99
12-Jul-93	6.99
19-Jul-93	6.99
26-Jul-93	6.99
2-Aug-93	6.99
9-Aug-93	6.99
16-Aug-93	6.99
23-Aug-93	6.99

I have a mandate to calculate VaR on that price data, probably in
Parametric
way. My question is can I apply standard way which we generally use like
log-normally distributed price, to calculate VaR here? Or some other
modeling approach needs to be taken care? Can anyone please provide me
any
references over net, how to handle this type of scenario?

Your help will be highly appreciated.

Thanks,
-- 
View this message in context:
http://n4.nabble.com/Need-help-please-tp1290132p1290132.html
Sent from the Rmetrics mailing list archive at Nabble.com.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From john.seppanen99 at gmail.com  Wed Jan 27 18:16:09 2010
From: john.seppanen99 at gmail.com (=?ISO-8859-1?Q?John_Sepp=E4nen?=)
Date: Wed, 27 Jan 2010 19:16:09 +0200
Subject: [R-SIG-Finance] CVaR portfolio-optimization vs. utility
	maximization..
Message-ID: <f5dfae7c1001270916s691e749dxa8ccb0a72c9a8e8d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100127/461ae74a/attachment.pl>

From brian at braverock.com  Wed Jan 27 18:36:33 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 27 Jan 2010 11:36:33 -0600
Subject: [R-SIG-Finance] CVaR portfolio-optimization vs.
	utility	maximization..
In-Reply-To: <f5dfae7c1001270916s691e749dxa8ccb0a72c9a8e8d@mail.gmail.com>
References: <f5dfae7c1001270916s691e749dxa8ccb0a72c9a8e8d@mail.gmail.com>
Message-ID: <4B6079A1.4050704@braverock.com>

John Sepp?nen wrote:
> Hi all!
>
> My question itself is not related to R so my apologies for that. I ran
> scenario optimizations in S-Plus with respect to variance and CVaR as a risk
> measures (based on Scherer & Martin's (2005) book). My assets where
> mostly negatively skewed and fat-tailed and I expected the resulting
> portfolio from CVaR-optimization to have less tail-risk than the the
> portfolio from variance-optimization. However, I noticed the opposite which
> is surpirising because the markowitz optimization is often accused of
> being tail-risk maximization when assets are negatively skewed (e.g. hedge
> funds).
>
> In many sources CVaR is said to be "the measure" for downside risk
> measurement. However, I am not able to find a discussion about how well CVaR
> relates with the utility maximization framework.. who should optimize with
> respect to CVaR if it increases the tail-risk? Computational easiness is not
> a good reason..   Any references or thoughts about the subject would be
> appreciated..
>   
Use modified CVaR instead.  It handles non-normal distributions.

And, being an *R* finance list, all that functionality is already 
available in R, including optimizing using modified CVaR as one of your 
objectives.

Cheers,

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From J_Cuisinier at hotmail.com  Wed Jan 27 18:36:52 2010
From: J_Cuisinier at hotmail.com (julien cuisinier)
Date: Wed, 27 Jan 2010 18:36:52 +0100
Subject: [R-SIG-Finance] Need help please
In-Reply-To: <338D58262CB96E438AD6AFEEE6D9482DDDB712@ex2k.bankofamerica.com>
References: <1264494316707-1290132.post@n4.nabble.com>
	<338D58262CB96E438AD6AFEEE6D9482DDDB712@ex2k.bankofamerica.com>
Message-ID: <BLU0-SMTP5399479842760FE032184C8F5D0@phx.gbl>

Hi Bogaso,


I am not a VaR expert at all, but I would say this:
1. Not enough data to compute anything with any sensible level of  
statistical significance (probably already very weak for volatility,  
but most probably very very very weak for VaR estimation)
2. I do not know this "very notorious" time series personally  
(probably my own limitation), but it looks pretty odd to me, basically  
you have 7 different prices repeated many times giving you 6 returns -  
one of which is almost 50% - and many nil returns...
3. VaR using the simple log-normal model of asset prices (I guess you  
mean VaR(99%)=average - 2.33*stdev) is vastly documented to be  
insufficient for financial assets like equity, so most probably not  
for whatever this thing is.

So I would personally simply say that it is not possible with the data  
at hand. Better to accept you cannot than use inappropriate "models"  
just to get some number out. But that's a personal opinion. Or there  
is another complex way (probably with a set of strong assumptions on  
the variable) which is beyond my knowledge

& as Ivan pointed out, this does not even enter the debate whether VaR  
is a sensible risk measure (coherence, best outcome in a bad day,  
etc...). I may be wrong of course, but I would be interested to have  
other list member opinion on this.


Sorry, this is most probably not the hoped/expected feedback.


Rgds,
Julen






On Jan 27, 2010, at 5:44 PM, Zhang, Ivan wrote:

> Hi Bogaso,
>
> This may not necessarily help you get an answer, but perhaps would  
> steer
> you in another direction:
>
> If the series doesn't look continuous you may potentially be able to
> pick a quantile that would make this measure not "coherent" which
> basically invalidates the use of VaR as a measure of risk in this  
> case.
>
> For more information on Coherent risk measures, see below link or  
> Google
> "coherent risk measure"
>
> http://www.math.ethz.ch/~delbaen/ftp/preprints/CoherentMF.pdf
>
>
> Hope this helps,
>
>
> -Ivan Zhang
>
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Bogaso
> Sent: Tuesday, January 26, 2010 3:25 AM
> To: r-sig-finance at stat.math.ethz.ch
> Subject: [R-SIG-Finance] Need help please
>
>
> Dear folks,
>
> I got a very notorious weekly price series where price seldom changes
> like :
>
> 6-Jan-92	4.38
> 13-Jan-92	4.38
> 20-Jan-92	4.38
> 27-Jan-92	4.38
> 3-Feb-92	4.38
> 10-Feb-92	4.38
> 17-Feb-92	4.38
> 24-Feb-92	4.38
> 2-Mar-92	4.38
> 9-Mar-92	4.38
> 16-Mar-92	4.38
> 23-Mar-92	4.38
> 30-Mar-92	4.38
> 6-Apr-92	4.38
> 13-Apr-92	4.38
> 20-Apr-92	6.56
> 27-Apr-92	6.56
> 4-May-92	6.56
> 11-May-92	6.56
> 18-May-92	6.56
> 25-May-92	6.56
> 1-Jun-92	6.56
> 8-Jun-92	6.63
> 15-Jun-92	6.63
> 22-Jun-92	6.63
> 29-Jun-92	6.63
> 6-Jul-92	6.63
> 13-Jul-92	6.63
> 20-Jul-92	6.99
> 27-Jul-92	6.99
> 3-Aug-92	6.99
> 10-Aug-92	6.99
> 17-Aug-92	6.99
> 24-Aug-92	6.99
> 31-Aug-92	6.99
> 7-Sep-92	6.99
> 14-Sep-92	6.99
> 21-Sep-92	6.99
> 28-Sep-92	6.99
> 5-Oct-92	6.99
> 12-Oct-92	6.99
> 19-Oct-92	6.99
> 26-Oct-92	6.99
> 2-Nov-92	6.99
> 9-Nov-92	6.99
> 16-Nov-92	6.99
> 23-Nov-92	6.99
> 30-Nov-92	6.99
> 7-Dec-92	6.99
> 14-Dec-92	6.99
> 21-Dec-92	6.99
> 28-Dec-92	6.99
> 4-Jan-93	6.99
> 11-Jan-93	6.99
> 18-Jan-93	6.99
> 25-Jan-93	6.99
> 1-Feb-93	6.99
> 8-Feb-93	6.99
> 15-Feb-93	6.99
> 22-Feb-93	6.99
> 1-Mar-93	6.99
> 8-Mar-93	6.99
> 15-Mar-93	6.99
> 22-Mar-93	6.56
> 29-Mar-93	6.56
> 5-Apr-93	6.56
> 12-Apr-93	6.56
> 19-Apr-93	6.56
> 26-Apr-93	6.56
> 3-May-93	6.56
> 10-May-93	6.63
> 17-May-93	6.63
> 24-May-93	6.63
> 31-May-93	6.63
> 7-Jun-93	6.63
> 14-Jun-93	6.63
> 21-Jun-93	6.99
> 28-Jun-93	6.99
> 5-Jul-93	6.99
> 12-Jul-93	6.99
> 19-Jul-93	6.99
> 26-Jul-93	6.99
> 2-Aug-93	6.99
> 9-Aug-93	6.99
> 16-Aug-93	6.99
> 23-Aug-93	6.99
>
> I have a mandate to calculate VaR on that price data, probably in
> Parametric
> way. My question is can I apply standard way which we generally use  
> like
> log-normally distributed price, to calculate VaR here? Or some other
> modeling approach needs to be taken care? Can anyone please provide me
> any
> references over net, how to handle this type of scenario?
>
> Your help will be highly appreciated.
>
> Thanks,
> -- 
> View this message in context:
> http://n4.nabble.com/Need-help-please-tp1290132p1290132.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R  
> questions
> should go.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R  
> questions should go.
>


From john.seppanen99 at gmail.com  Wed Jan 27 19:15:26 2010
From: john.seppanen99 at gmail.com (=?ISO-8859-1?Q?John_Sepp=E4nen?=)
Date: Wed, 27 Jan 2010 20:15:26 +0200
Subject: [R-SIG-Finance] CVaR portfolio-optimization vs. utility
	maximization..
In-Reply-To: <4B6079A1.4050704@braverock.com>
References: <f5dfae7c1001270916s691e749dxa8ccb0a72c9a8e8d@mail.gmail.com>
	<4B6079A1.4050704@braverock.com>
Message-ID: <f5dfae7c1001271015i5c9c491fj3c36678efc4c6073@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100127/a16e5398/attachment.pl>

From brian at braverock.com  Wed Jan 27 19:47:00 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 27 Jan 2010 12:47:00 -0600
Subject: [R-SIG-Finance] CVaR portfolio-optimization vs. utility
	maximization..
In-Reply-To: <f5dfae7c1001271015i5c9c491fj3c36678efc4c6073@mail.gmail.com>
References: <f5dfae7c1001270916s691e749dxa8ccb0a72c9a8e8d@mail.gmail.com>	
	<4B6079A1.4050704@braverock.com>
	<f5dfae7c1001271015i5c9c491fj3c36678efc4c6073@mail.gmail.com>
Message-ID: <4B608A24.4050903@braverock.com>

Well, there are a couple things likely going on here....

Your choice of confidence threshold is really important.  The highly 
risk averse investor might be better off using VaR with a high threshold 
than CVaR, despite its nonlinearity.

Whether you have enough data to fit a copula is important.

If you're doing this in a portfolio context, I'd argue that flattening 
from a multivariate distribution to a univariate CVaR number, even with 
a copula, misses the component contribution to risk.  See "Component 
Expected Shortfall" or "Component CVaR"

Regards,

    - Brian

John Sepp?nen wrote:
> Brian,
>  
> Thanks for your answer. I am using scenarios in optimization. 
> Scenarios are drawn from a multivariate distribution that is built by 
> fitting univariate return distributions and then gluing the 
> distibutions with a copula. Thus the non-normality of assets should be 
> taken into account.. I am assuming the reason for my "findings" are 
> that the CVaR puts "only" a linear penalty for returns below the 
> quantile and I am wondering how optimal this is for a (highly) risk 
> averse investor... 
>  
> -John
>
> 2010/1/27 Brian G. Peterson <brian at braverock.com 
> <mailto:brian at braverock.com>>
>
>     John Sepp?nen wrote:
>
>         Hi all!
>
>         My question itself is not related to R so my apologies for
>         that. I ran
>         scenario optimizations in S-Plus with respect to variance and
>         CVaR as a risk
>         measures (based on Scherer & Martin's (2005) book). My assets
>         where
>         mostly negatively skewed and fat-tailed and I expected the
>         resulting
>         portfolio from CVaR-optimization to have less tail-risk than
>         the the
>         portfolio from variance-optimization. However, I noticed the
>         opposite which
>         is surpirising because the markowitz optimization is often
>         accused of
>         being tail-risk maximization when assets are negatively skewed
>         (e.g. hedge
>         funds).
>
>         In many sources CVaR is said to be "the measure" for downside risk
>         measurement. However, I am not able to find a discussion about
>         how well CVaR
>         relates with the utility maximization framework.. who should
>         optimize with
>         respect to CVaR if it increases the tail-risk? Computational
>         easiness is not
>         a good reason..   Any references or thoughts about the subject
>         would be
>         appreciated..
>          
>
>     Use modified CVaR instead.  It handles non-normal distributions.
>
>     And, being an *R* finance list, all that functionality is already
>     available in R, including optimizing using modified CVaR as one of
>     your objectives.
>
>     Cheers,
>
>      - Brian
>
>     -- 
>     Brian G. Peterson
>     http://braverock.com/brian/
>     Ph: 773-459-4973
>     IM: bgpbraverock
>
>
>


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From vsg.nyc at gmail.com  Wed Jan 27 19:48:53 2010
From: vsg.nyc at gmail.com (Rich Ghazarian)
Date: Wed, 27 Jan 2010 10:48:53 -0800
Subject: [R-SIG-Finance] RBloomberg xts quantmod Coercion
Message-ID: <ace0be451001271048i6a03f74bxab8b09161b33ffac@mail.gmail.com>

I pull the data using RBbloomberg and then I transform to xts using the as.xts

zooxts<-as.xts(eda, dateFormat="Date")


then I run a summary

> summary(zooxts)
     Index                       CL1 COMDTY       CL2 COMDTY       CL3
COMDTY       CJ4 COMDTY
 Min.   :(11/28/90 08:00:00)   Min.   : 10.72   Min.   : 11.02   Min.
 : 11.33   Min.   :  NA
 1st Qu.:(03/10/95 08:00:00)   1st Qu.: 19.49   1st Qu.: 19.42   1st
Qu.: 19.31   1st Qu.:  NA
 Median :(01/19/00 08:00:00)   Median : 25.80   Median : 25.46
Median : 24.98   Median :  NA
 Mean   :(02/17/00 08:43:43)   Mean   : 36.19   Mean   : 36.25   Mean
 : 36.25   Mean   : NaN
 3rd Qu.:(12/06/04 08:00:00)   3rd Qu.: 48.79   3rd Qu.: 49.15   3rd
Qu.: 49.73   3rd Qu.:  NA
 Max.   :(01/27/10 08:00:00)   Max.   :145.29   Max.   :145.86   Max.
 :146.13   Max.   :  NA
 NA's   :2798                  NA's   :  3.00                    NA's
 :  2.00   NA's   :4807
Warning message:
In data.row.names(row.names, rowsi, i) :
  some row.names duplicated:
91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,11

Q1) What is the warning sign for?


Q2) What is the following error for?

chartSeries(naeda[,2])
Error in periodicity(x) : can not calculate periodicity of 1 observation


Thank you


From jeff.a.ryan at gmail.com  Wed Jan 27 20:16:19 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Wed, 27 Jan 2010 13:16:19 -0600
Subject: [R-SIG-Finance] RBloomberg xts quantmod Coercion
In-Reply-To: <ace0be451001271048i6a03f74bxab8b09161b33ffac@mail.gmail.com>
References: <ace0be451001271048i6a03f74bxab8b09161b33ffac@mail.gmail.com>
Message-ID: <e8e755251001271116i5851e556vf2dfca7c4e9d5b9d@mail.gmail.com>

Rich,

Can you provide a str(eda) or better yet dput(eda).

I suspect you just have a format that as.xts isn't able to handle
automatically, but without the data I can't be of much help.

Jeff

On Wed, Jan 27, 2010 at 12:48 PM, Rich Ghazarian <vsg.nyc at gmail.com> wrote:
> I pull the data using RBbloomberg and then I transform to xts using the as.xts
>
> zooxts<-as.xts(eda, dateFormat="Date")
>
>
> then I run a summary
>
>> summary(zooxts)
> ? ? Index ? ? ? ? ? ? ? ? ? ? ? CL1 COMDTY ? ? ? CL2 COMDTY ? ? ? CL3
> COMDTY ? ? ? CJ4 COMDTY
> ?Min. ? :(11/28/90 08:00:00) ? Min. ? : 10.72 ? Min. ? : 11.02 ? Min.
> ?: 11.33 ? Min. ? : ?NA
> ?1st Qu.:(03/10/95 08:00:00) ? 1st Qu.: 19.49 ? 1st Qu.: 19.42 ? 1st
> Qu.: 19.31 ? 1st Qu.: ?NA
> ?Median :(01/19/00 08:00:00) ? Median : 25.80 ? Median : 25.46
> Median : 24.98 ? Median : ?NA
> ?Mean ? :(02/17/00 08:43:43) ? Mean ? : 36.19 ? Mean ? : 36.25 ? Mean
> ?: 36.25 ? Mean ? : NaN
> ?3rd Qu.:(12/06/04 08:00:00) ? 3rd Qu.: 48.79 ? 3rd Qu.: 49.15 ? 3rd
> Qu.: 49.73 ? 3rd Qu.: ?NA
> ?Max. ? :(01/27/10 08:00:00) ? Max. ? :145.29 ? Max. ? :145.86 ? Max.
> ?:146.13 ? Max. ? : ?NA
> ?NA's ? :2798 ? ? ? ? ? ? ? ? ?NA's ? : ?3.00 ? ? ? ? ? ? ? ? ? ?NA's
> ?: ?2.00 ? NA's ? :4807
> Warning message:
> In data.row.names(row.names, rowsi, i) :
> ?some row.names duplicated:
> 91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,11
>
> Q1) What is the warning sign for?
>
>
> Q2) What is the following error for?
>
> chartSeries(naeda[,2])
> Error in periodicity(x) : can not calculate periodicity of 1 observation
>
>
> Thank you
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From taplate at gmail.com  Wed Jan 27 21:20:29 2010
From: taplate at gmail.com (Tony Plate)
Date: Wed, 27 Jan 2010 13:20:29 -0700
Subject: [R-SIG-Finance] Need help please
In-Reply-To: <1264494316707-1290132.post@n4.nabble.com>
References: <1264494316707-1290132.post@n4.nabble.com>
Message-ID: <f262cf7a1001271220p72fd60f5u2f81302d6bd77a64@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100127/74f800a4/attachment.pl>

From cmdr_rogue at hotmail.com  Thu Jan 28 02:38:38 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Wed, 27 Jan 2010 20:38:38 -0500
Subject: [R-SIG-Finance] GARCH (1,1) negative volatility???
In-Reply-To: <7dc3eb8d1001270528x661f3083g2d28d0ef12e9a62a@mail.gmail.com>
References: <7dc3eb8d1001270304n17799166x7a4e904657f32df@mail.gmail.com>
	<7dc3eb8d1001270453j25f973d2if69fc91295f82227@mail.gmail.com>
	<OFEDAB7469.5DFC5523-ONC12576B8.0048BBF1-C12576B8.00492986@hsbctrinkaus.de>
	<7dc3eb8d1001270528x661f3083g2d28d0ef12e9a62a@mail.gmail.com>
Message-ID: <BLU0-SMTP586D5866B8909F216B6AD6E25C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100127/c16e3ea5/attachment.pl>

From dengyishuo at 163.com  Thu Jan 28 08:31:59 2010
From: dengyishuo at 163.com (deng yishuo)
Date: Wed, 27 Jan 2010 23:31:59 -0800 (PST)
Subject: [R-SIG-Finance] how to get next trading day's VaR
Message-ID: <1264663919518-1329244.post@n4.nabble.com>



Dear folks!

data(sp500ret)
ctrl = list(RHO = 1,DELTA = 1e-9, MAJIT = 100,MINIT = 650,TOL = 1e-7)
spec = ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
c(1,1)), 
		mean.model = list(armaOrder = c(0,0), include.mean = TRUE), 
		distribution.model = "std")

sp500.bktest = ugarchroll(spec, data = sp500ret, n.ahead = 1,
forecast.length = 100, 
		refit.every = 25, refit.window = "recursive", use.mclapply = FALSE, 
		solver = "solnp", fit.control = list(), solver.control = ctrl,
		calculate.VaR = TRUE, VaR.alpha = c(0.01, 0.025, 0.05))

In this example,as you can see we have already known the return rate from
1987-03-10 to 2009-01-30
I wonder how can we kown the next trading day's VaR after  2009-01-30.

Thanks!



-----
?????????????????
-- 
View this message in context: http://n4.nabble.com/how-to-get-next-trading-day-s-VaR-tp1329244p1329244.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From megh700004 at yahoo.com  Thu Jan 28 09:53:38 2010
From: megh700004 at yahoo.com (Megh)
Date: Thu, 28 Jan 2010 00:53:38 -0800 (PST)
Subject: [R-SIG-Finance] ICE commodity swap
Message-ID: <1264668818852-1341811.post@n4.nabble.com>


Dear all, here I was studying the commodity swap contracts traded at ICE, one
of them is "Singapore 0.5% Gasoil Swap", contract specification is here :
https://www.theice.com/productguide/ProductDetails.shtml?specId=1206

Here in daily settlement process, it is written as "Floating Price will be
determined by ICE using price data from a number of sources including spot,
forward, and derivative markets for both physical and financial products"

Can anyone please provide me any details what is the formula they are using
to determine that and exactly what spot, forward quotes they are using? Is
there any data-sources to find the historical daily quotes as well?

Thanks and regards,
-- 
View this message in context: http://n4.nabble.com/ICE-commodity-swap-tp1341811p1341811.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Thu Jan 28 11:14:36 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 28 Jan 2010 04:14:36 -0600
Subject: [R-SIG-Finance] ICE commodity swap
In-Reply-To: <1264668818852-1341811.post@n4.nabble.com>
References: <1264668818852-1341811.post@n4.nabble.com>
Message-ID: <4B61638C.3050808@braverock.com>

Megh wrote:
> Dear all, here I was studying the commodity swap contracts traded at ICE, one
> of them is "Singapore 0.5% Gasoil Swap", contract specification is here :
> https://www.theice.com/productguide/ProductDetails.shtml?specId=1206
> 
> Here in daily settlement process, it is written as "Floating Price will be
> determined by ICE using price data from a number of sources including spot,
> forward, and derivative markets for both physical and financial products"
> 
> Can anyone please provide me any details what is the formula they are using
> to determine that and exactly what spot, forward quotes they are using? Is
> there any data-sources to find the historical daily quotes as well?
> 
> Thanks and regards,

The point is, they don't tell you.

I've dealt with ICE before, and it can be maddening trying to get details out 
of them.

So, maybe if you call the exchange support folks and ask them, you *might* get 
an answer, but probably not.

Or, you can guess.  There are only so many markets where natural gas and 
heating oil are traded.  Clearly, for this one, I'd start with Singapore 
prices.  See how close you can get using observable market factors.  That might 
let you know whether you want ICE as a counterparty.

And what did this have to do with R anyway?

Cheers,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From patrick at burns-stat.com  Thu Jan 28 11:24:29 2010
From: patrick at burns-stat.com (Patrick Burns)
Date: Thu, 28 Jan 2010 10:24:29 +0000
Subject: [R-SIG-Finance] alternative lists (was : ICE commodity swap)
In-Reply-To: <4B61638C.3050808@braverock.com>
References: <1264668818852-1341811.post@n4.nabble.com>
	<4B61638C.3050808@braverock.com>
Message-ID: <4B6165DD.9000404@burns-stat.com>

On 28/01/2010 10:14, Brian G. Peterson wrote:

  ...

>
> And what did this have to do with R anyway?

I also inferred a minimal R content.  But it is
hard for me to blame people too much for posting
off-topic questions if we don't offer them any
alternatives.

For basic R questions we obviously have R-help.
Can we suggest any finance-related lists as suitable
alternatives?


>
> Cheers,
>
> - Brian
>

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com


From cmdr_rogue at hotmail.com  Thu Jan 28 11:28:39 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Thu, 28 Jan 2010 05:28:39 -0500
Subject: [R-SIG-Finance] how to get next trading day's VaR
In-Reply-To: <1264663919518-1329244.post@n4.nabble.com>
References: <1264663919518-1329244.post@n4.nabble.com>
Message-ID: <BLU0-SMTP880E64D2295CEB888FAAFAE25C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100128/93a1729f/attachment.pl>

From arun.kumar.saha at gmail.com  Thu Jan 28 11:40:22 2010
From: arun.kumar.saha at gmail.com (Arun.stat)
Date: Thu, 28 Jan 2010 02:40:22 -0800 (PST)
Subject: [R-SIG-Finance] Need help please
In-Reply-To: <1264494316707-1290132.post@n4.nabble.com>
References: <1264494316707-1290132.post@n4.nabble.com>
Message-ID: <1264675222403-1352675.post@n4.nabble.com>


hmmm..........interesting no doubt............what about this sort of
modeling?

1. 1st define a r.v. to represent the number of days/weeks price is being
kept fixed, you could try some exponential dist.
2. 2nd define another r.v. to represent the magnitude of change in prices.

Then you need to combine those two r.v., perhaps you could use "convolution"
concept (i am not sure exactly) and then simulate different price scenario
and choose the worst 5th. By this way can calculate VaR under MCS framework,
not really parametric as you wished.

However I would really be happy if someone throws points on following "

1. How to incorporate correlation (if any, if not you need to quantify still
to justify that) between above those 2 r.v.s
2. How to calculate VaR from a portfolio perspective.

I would really be happy if someone would point out the feasibility of above
approach.

Thanks,


-- 
View this message in context: http://n4.nabble.com/Need-help-please-tp1290132p1352675.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From Matthias.Koberstein at hsbctrinkaus.de  Thu Jan 28 11:45:18 2010
From: Matthias.Koberstein at hsbctrinkaus.de (Matthias Koberstein)
Date: Thu, 28 Jan 2010 11:45:18 +0100
Subject: [R-SIG-Finance] Packages/functions for finance day count conventions
In-Reply-To: <19278.34732.863130.864518@ron.nulle.part>
References: <Pine.LNX.4.43.1001131448170.10842@hymn11.u.washington.edu>
	<19278.34732.863130.864518@ron.nulle.part>
Message-ID: <OFF02170DD.17EC6D07-ONC12576B9.003A84A0-C12576B9.003B143A@hsbctrinkaus.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100128/9dd52e5b/attachment.pl>

From brian at braverock.com  Thu Jan 28 11:57:14 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 28 Jan 2010 04:57:14 -0600
Subject: [R-SIG-Finance] alternative lists (was : ICE commodity swap)
In-Reply-To: <4B6165DD.9000404@burns-stat.com>
References: <1264668818852-1341811.post@n4.nabble.com>	<4B61638C.3050808@braverock.com>
	<4B6165DD.9000404@burns-stat.com>
Message-ID: <4B616D8A.3080909@braverock.com>

Patrick Burns wrote:
> On 28/01/2010 10:14, Brian G. Peterson wrote:
> 
>  ...
> 
>>
>> And what did this have to do with R anyway?
> 
> I also inferred a minimal R content.  But it is
> hard for me to blame people too much for posting
> off-topic questions if we don't offer them any
> alternatives.
> 
> For basic R questions we obviously have R-help.
> Can we suggest any finance-related lists as suitable
> alternatives?

Well, clearly anything googled as 'trading forum' have discussions like this 
all the time. YMMV as to the quality of information to be found on these forums.

Of course, every research question is different, and forums (or lists such as 
this one) do not always have credible information.  What process would the 
interested researcher follow to get reliable (tradable) information?

Specific to the inquiry about ICE, or any other exchange traded product, the 
first resource *should* be to call the exchange.  They have support numbers for 
a reason, this is one of them.  So the exchange should be the *first* avenue of 
inquiry for product details on products traded on that exchange.

Next, try calling your data vendors.  One of the reasons you pay a bunch of 
money to Reuters, Bloomberg, QAI, etc. is so that you can call them and ask 
them questions.

In doing product research on derivative products, I usually find it useful to 
work your way back up the chain closer to the underlying instrument.

So, for this example.

Singapore 0.5% GasOil Swap

The contract spec says that:
"In respect of final settlement, the Floating Price will be a price in USD and 
cents per barrel based on the average of the mean of the relevant high and low 
quotations appearing in the 'Platts Asian-Pacific MarketScan' under the heading 
`FOB Singapore of Gasoil Reg 0.5% sulfur' for the contract month."

The Platts reports are subscription products.  The interested user would call 
their clearing broker and custody broker and ask them to send you copies.  Most 
brokers have access to more research reports than one would ever want to 
actually read. An old copy of the Platts report may be seen for reference here: 
www.platts.com/IM.Platts.Content/ProductsServices/Products/apagscan.pdf

This raises another interesting research opportunity.  Call your brokers.  They 
want you to trade more things in higher volume.  They'll be happy to trot out a 
'asset class expert' or some-such to talk to you.  They might even know 
something about the products in question.

Let's assume none of that works out.  One might continue working back towards 
the underlying products.

The Department of Energy posts helpful daily close prices on energy products.

http://tonto.eia.doe.gov/dnav/pet/PET_PRI_SPT_S1_D.htm

Our tax dollars even provide copious amounts of historical data.  Singapore Gas 
and Singapore Heating Oil are both listed, as is Singapore GasOil (I assume the 
spread, but maybe the original exchange even sells a swap, and ICE is just 
freeloading with a US$ product).  If one spoke Chinese, I'm sure even more 
market quotations would be available.

Research is a process (as Patrick clearly knows).  Hopefully my spending a 
little time to elucidate that process has been useful for our readers.

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From alexios at 4dscape.com  Thu Jan 28 17:18:23 2010
From: alexios at 4dscape.com (alexios)
Date: Thu, 28 Jan 2010 16:18:23 +0000
Subject: [R-SIG-Finance] how to get next trading day's VaR
In-Reply-To: <BLU0-SMTP880E64D2295CEB888FAAFAE25C0@phx.gbl>
References: <1264663919518-1329244.post@n4.nabble.com>
	<BLU0-SMTP880E64D2295CEB888FAAFAE25C0@phx.gbl>
Message-ID: <4B61B8CF.7040703@4dscape.com>

The "ugarchroll" function is for backtesting the model against existing 
data (split into in- and out-of sample for estimation/forecasting and 
rolled via a window which is either recursive or moving). As such, you 
will not get the "next trading day's VaR after  2009-01-30".
If you want to do forecasting with GARCH, use the "ugarchforecast" 
function.
For 1-ahead forecasts you can use the forecasted mean and variance to 
rescale the conditional density from (0,1) to that of the underlying 
returns and use that as the "predictive" density from which you can find 
analytically the VaR (see for example the function "qdist" for the 
quantile and the relevant notes).
For n-ahead density forecasts you need to simulate since we do not know 
the predictive density, but you can also use the "ugarchboot" function
which implements both a "full" and "conditional" bootstrap procedure 
based on the method of Pascual, Romo and Ruiz (2006), where both 
parameter and predictive distribution uncertainty are take into 
consideration. Do read the documentation.

Regards,
-Alexios Ghalanos

On 1/28/2010 10:28 AM, Sarbo wrote:
> Use a "historical simulation" approach. See Hull, Options, Futures&
> Other Derivatives, Ch.17, for details. It's a very easy technique to
> implement- the fPortfolio package in R should be able to do it with one
> command.
>
> On Wed, 2010-01-27 at 23:31 -0800, deng yishuo wrote:
>
>>
>> Dear folks!
>>
>> data(sp500ret)
>> ctrl = list(RHO = 1,DELTA = 1e-9, MAJIT = 100,MINIT = 650,TOL = 1e-7)
>> spec = ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>> c(1,1)),
>> 		mean.model = list(armaOrder = c(0,0), include.mean = TRUE),
>> 		distribution.model = "std")
>>
>> sp500.bktest = ugarchroll(spec, data = sp500ret, n.ahead = 1,
>> forecast.length = 100,
>> 		refit.every = 25, refit.window = "recursive", use.mclapply = FALSE,
>> 		solver = "solnp", fit.control = list(), solver.control = ctrl,
>> 		calculate.VaR = TRUE, VaR.alpha = c(0.01, 0.025, 0.05))
>>
>> In this example,as you can see we have already known the return rate from
>> 1987-03-10 to 2009-01-30
>> I wonder how can we kown the next trading day's VaR after  2009-01-30.
>>
>> Thanks!
>>
>>
>>
>> -----
>> ???????????????????????????????????????????????????
>> --
>> View this message in context: http://n4.nabble.com/how-to-get-next-trading-day-s-VaR-tp1329244p1329244.html
>> Sent from the Rmetrics mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From bogaso.christofer at gmail.com  Sun Jan 31 12:52:02 2010
From: bogaso.christofer at gmail.com (Bogaso)
Date: Sun, 31 Jan 2010 03:52:02 -0800 (PST)
Subject: [R-SIG-Finance] Option greeks
Message-ID: <1264938722487-1457972.post@n4.nabble.com>


Hi folks, is there any function available in R to calculate the different
option greeks at least for European type?

Thanks
-- 
View this message in context: http://n4.nabble.com/Option-greeks-tp1457972p1457972.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Sun Jan 31 13:18:48 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 31 Jan 2010 06:18:48 -0600
Subject: [R-SIG-Finance] Option greeks
In-Reply-To: <1264938722487-1457972.post@n4.nabble.com>
References: <1264938722487-1457972.post@n4.nabble.com>
Message-ID: <4B657528.2080903@braverock.com>

Bogaso wrote:
> Hi folks, is there any function available in R to calculate the different
> option greeks at least for European type?
>   
Christofer,

http://lmgtfy.com/?q=r-project+european+options


From cmdr_rogue at hotmail.com  Sun Jan 31 13:22:28 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Sun, 31 Jan 2010 07:22:28 -0500
Subject: [R-SIG-Finance] Option greeks
In-Reply-To: <1264938722487-1457972.post@n4.nabble.com>
References: <1264938722487-1457972.post@n4.nabble.com>
Message-ID: <BLU0-SMTP5197FC23D5DD1332BA5E95E2590@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100131/f9270cee/attachment.pl>

From bogaso.christofer at gmail.com  Sun Jan 31 13:42:46 2010
From: bogaso.christofer at gmail.com (Bogaso)
Date: Sun, 31 Jan 2010 04:42:46 -0800 (PST)
Subject: [R-SIG-Finance] Option greeks
In-Reply-To: <4B657528.2080903@braverock.com>
References: <1264938722487-1457972.post@n4.nabble.com>
	<4B657528.2080903@braverock.com>
Message-ID: <1264941766629-1457996.post@n4.nabble.com>


Thanks for this mail. I was not aware of that package, obviously it is
terribly good. However I found significant differences while comparing the
numbers with online option calculators available over net. For example

> GBSGreeks(Selection = "theta", TypeFlag = "c", S = 105, X = 100, Time =
> 1/2, r = 0.10, b = 0, sigma = 0.36)
[1] -8.396841

However this site
http://www.intrepid.com/robertl/option-pricer1/option-pricer.cgi gives
completely different figure as "-0.0965 "

am I missing something?

-- 
View this message in context: http://n4.nabble.com/Option-greeks-tp1457972p1457996.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From cmdr_rogue at hotmail.com  Sun Jan 31 15:42:41 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Sun, 31 Jan 2010 09:42:41 -0500
Subject: [R-SIG-Finance] Option greeks
In-Reply-To: <1264941766629-1457996.post@n4.nabble.com>
References: <1264938722487-1457972.post@n4.nabble.com>
	<4B657528.2080903@braverock.com>
	<1264941766629-1457996.post@n4.nabble.com>
Message-ID: <BLU0-SMTP787AC6CF350A1E1820767EE2590@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100131/19514d38/attachment.pl>

From davidr at rhotrading.com  Mon Feb  1 17:31:13 2010
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Mon, 1 Feb 2010 10:31:13 -0600
Subject: [R-SIG-Finance] Option greeks
In-Reply-To: <1264941766629-1457996.post@n4.nabble.com>
References: <1264938722487-1457972.post@n4.nabble.com><4B657528.2080903@braverock.com>
	<1264941766629-1457996.post@n4.nabble.com>
Message-ID: <F9F2A641C593D7408925574C05A7BE7704F1C65E@rhopost.rhotrading.com>

Theta seems to be one of the most widely varied in how people calculate
and scale it,
but all the Greeks and even the theoretical values vary from package to
package.
This variation is usually explained by the various ways of scaling the
answers and the inputs.
For example, are the input rats supposed to be continuous rates or
Act/360 or Act/365, etc.
Should the time between dates be scaled to years by dividing 365 or
365.25 days? 
Should the volatility time be scaled the same way or by some other
number of days, say 252?
Is the theta for one year, one day, one business day; does it include
carry or not?
And so on and so on. If you have access to the source (in R, you do),
you can see exactly what
the programmers did, whereas for commercial or on-line models, you have
to rely on good documentation.

A few years ago, Dr Risk (William Margrabe http://www.margrabe.com/)
wrote about testing his calculator 
against eight commercial packages, and documented how difficult it can
be.

Good luck!

David L. Reiner, PhD
Head Quant
XR Trading, LLC

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Bogaso
Sent: Sunday, January 31, 2010 6:43 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Option greeks


Thanks for this mail. I was not aware of that package, obviously it is
terribly good. However I found significant differences while comparing
the
numbers with online option calculators available over net. For example

> GBSGreeks(Selection = "theta", TypeFlag = "c", S = 105, X = 100, Time
=
> 1/2, r = 0.10, b = 0, sigma = 0.36)
[1] -8.396841

However this site
http://www.intrepid.com/robertl/option-pricer1/option-pricer.cgi gives
completely different figure as "-0.0965 "

am I missing something?

-- 
View this message in context:
http://n4.nabble.com/Option-greeks-tp1457972p1457996.html
Sent from the Rmetrics mailing list archive at Nabble.com.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.

THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON'S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.


From jorgy.porgee at gmail.com  Thu Feb  4 13:45:21 2010
From: jorgy.porgee at gmail.com (Jorgy Porgee)
Date: Thu, 4 Feb 2010 14:45:21 +0200
Subject: [R-SIG-Finance] fPortfolio question: is it possible to optimize a
	portfolio when you've got missing (returns) data for a subset
	of your total assets?
Message-ID: <28c145941002040445s32b13f57hfc83271e0fc2b7e1@mail.gmail.com>

Good day all,

I'm trying to create a MV portfolio using a bunch of stock returns.
However, the length of the historic data is not uniform (some stocks
have 12 month historics say while the bulk have 24 which is what I'm
interested in).

Is there a way of creating a portfolio (so far I've tried a
feasiblePortfolio()) without dropping the subset with short histories?

So far I get this error:

> setWeights(ewSpec)<-rep(1/nAssets,times=nAssets)
> ewPortfolio<-feasiblePortfolio(
	data = asset.returns,
	spec = ewSpec,
	constraints = "LongOnly"
	)

Error in quantile.default(returns, alpha, type = 1) :
  missing values and NaN's not allowed if 'na.rm' is FALSE

Thanking you in advance,

Jorgy.


From brian at braverock.com  Thu Feb  4 13:55:35 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 04 Feb 2010 06:55:35 -0600
Subject: [R-SIG-Finance] fPortfolio question: is it possible to optimize
 a	portfolio when you've got missing (returns) data for a subset	of your
 total assets?
In-Reply-To: <28c145941002040445s32b13f57hfc83271e0fc2b7e1@mail.gmail.com>
References: <28c145941002040445s32b13f57hfc83271e0fc2b7e1@mail.gmail.com>
Message-ID: <4B6AC3C7.80100@braverock.com>

Jorgy Porgee wrote:
> Good day all,
>
> I'm trying to create a MV portfolio using a bunch of stock returns.
> However, the length of the historic data is not uniform (some stocks
> have 12 month historics say while the bulk have 24 which is what I'm
> interested in).
>
> Is there a way of creating a portfolio (so far I've tried a
> feasiblePortfolio()) without dropping the subset with short histories?
>
> So far I get this error:
>
>   
>> setWeights(ewSpec)<-rep(1/nAssets,times=nAssets)
>> ewPortfolio<-feasiblePortfolio(
>>     
> 	data = asset.returns,
> 	spec = ewSpec,
> 	constraints = "LongOnly"
> 	)
>
> Error in quantile.default(returns, alpha, type = 1) :
>   missing values and NaN's not allowed if 'na.rm' is FALSE
>
> Thanking you in advance,
>   
The typical answer to this is to create a series of portfolios.  One 
portfolio contains only the stocks that have 24 months, which you then 
use for the first six months.  Then you insert stocks for which you have 
18 months of history, and use this for the next six months, then you 
insert the stocks that have only 12 months of history, and use that.

Unfortunately, this won't work for the classic mean-variance portfolio 
unless you construct your portfolio moments by hand.  You're going to 
have to make a business decision about how to do this, and then apply 
the correct statistical technique to get what you want.  If you want to 
force-fit this, then you need to truncate your data to the length of the 
shortest series (na.rm=TRUE in your example), backfill the shortest 
series using factor correlations (Sharpe and Sortino both wrote some 
papers on this), or use a more esoteric method to provide the moments 
and comoments for your quadratic optimization algorithm.

Of course, this kind of real-world problem in data length is one reason 
that the classic Markowitz optimization approach seldom works in 
practice the way it does in your average textbook stock/bond example.

Regards,

   - Brian
 

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From David.King at schroders.com  Thu Feb  4 14:09:44 2010
From: David.King at schroders.com (King, David)
Date: Thu, 4 Feb 2010 13:09:44 -0000
Subject: [R-SIG-Finance] fPortfolio question: is it possible to optimize
	aportfolio when you've got missing (returns) data for a
	subsetof your total assets?
In-Reply-To: <28c145941002040445s32b13f57hfc83271e0fc2b7e1@mail.gmail.com>
References: <28c145941002040445s32b13f57hfc83271e0fc2b7e1@mail.gmail.com>
Message-ID: <E863B8D444B2464B949B92708C3BA384018A8CAA@LON0826.London.Schroders.com>


See 'Covariance Misspecification in Asset Allocation' by Peterson and
Grier (FAJ 2006, Vol 62 No.4) and the references given in the paper
especially the work by Stambaugh.

Bernd Scherer's book 'Portfolio Construction and Risk Budgeting' also
contains useful information on this topic.

David


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Jorgy
Porgee
Sent: 04 February 2010 12:45
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] fPortfolio question: is it possible to optimize
aportfolio when you've got missing (returns) data for a subsetof your
total assets?

Good day all,

I'm trying to create a MV portfolio using a bunch of stock returns.
However, the length of the historic data is not uniform (some stocks
have 12 month historics say while the bulk have 24 which is what I'm
interested in).

Is there a way of creating a portfolio (so far I've tried a
feasiblePortfolio()) without dropping the subset with short histories?

So far I get this error:

> setWeights(ewSpec)<-rep(1/nAssets,times=nAssets)
> ewPortfolio<-feasiblePortfolio(
	data = asset.returns,
	spec = ewSpec,
	constraints = "LongOnly"
	)

Error in quantile.default(returns, alpha, type = 1) :
  missing values and NaN's not allowed if 'na.rm' is FALSE

Thanking you in advance,

Jorgy.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.
* Please Note : This message was received from the Internet *
_____________________________________________________________

__________________________________________________________________


Visit Schroders Talking Point for market news and expert views http://www.schroders.com/talkingpoint

This message might contain confidential information. If it has been sent to you in error please do not forward it or copy it or act upon its contents, but report it to postmaster at schroders.com

Schroders has the right lawfully to record, monitor and inspect messages between its employees and any third party. Your messages shall be subject to such lawful supervision as Schroders deems to be necessary in order to protect its information, its interests and its reputation.

Schroders prohibits and takes steps to prevent its information systems from being used to view, store or forward offensive or discriminatory material. If this message contains such material please report it to abuse at schroders.com

Schroders does not normally accept or offer business instructions via email unless prior agreements are in place. Any action that you might take upon this message might be at your own risk.


Schroder Investment Management Limited
31 Gresham Street
London EC2V 7QA

Authorised and regulated by the Financial Services Authority. Schroder Investment Management Limited is entered on the FSA register under the following register number: 119348

Registered Office
31 Gresham Street
London EC2V 7QA

Registered number 1893220
VAT registration number 243 8687 30


From ariascos at gmail.com  Thu Feb  4 16:35:35 2010
From: ariascos at gmail.com (Alvaro Riascos)
Date: Thu, 4 Feb 2010 10:35:35 -0500
Subject: [R-SIG-Finance] ts class to timeSeries class
Message-ID: <012001caa5af$b3026960$19073c20$@com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100204/b866686b/attachment.pl>

From david.jessop at ubs.com  Thu Feb  4 16:46:16 2010
From: david.jessop at ubs.com (david.jessop at ubs.com)
Date: Thu, 4 Feb 2010 15:46:16 -0000
Subject: [R-SIG-Finance] fPortfolio question: is it possible to
	optimizeaportfolio when you've got missing (returns) data for
	asubsetof your total assets?
In-Reply-To: <E863B8D444B2464B949B92708C3BA384018A8CAA@LON0826.London.Schroders.com>
References: <28c145941002040445s32b13f57hfc83271e0fc2b7e1@mail.gmail.com>
	<E863B8D444B2464B949B92708C3BA384018A8CAA@LON0826.London.Schroders.com>
Message-ID: <25492B412B325B4FB1FED95013D3E5CE0A109695@NLDNC105PEX1.ubsw.net>

Hi

Also, look for papers by Gramacy [Gramacy, R. B., Lee, J. H., and Silva,
R. (2008). "On estimating covariances between
many assets with histories of highly variable length." Tech. Rep.
0710.5837, arXiv. Url:http://arxiv.org/abs/0710.5837. ] who has extended
the Stambaugh approach.  And he's even been nice enough to produce an R
library to do what he talks about. 

Regards

David 

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of King,
David
Sent: 04 February 2010 13:10
To: Jorgy Porgee; r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] fPortfolio question: is it possible to
optimizeaportfolio when you've got missing (returns) data for asubsetof
your total assets?


See 'Covariance Misspecification in Asset Allocation' by Peterson and
Grier (FAJ 2006, Vol 62 No.4) and the references given in the paper
especially the work by Stambaugh.

Bernd Scherer's book 'Portfolio Construction and Risk Budgeting' also
contains useful information on this topic.

David


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Jorgy
Porgee
Sent: 04 February 2010 12:45
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] fPortfolio question: is it possible to optimize
aportfolio when you've got missing (returns) data for a subsetof your
total assets?

Good day all,

I'm trying to create a MV portfolio using a bunch of stock returns.
However, the length of the historic data is not uniform (some stocks
have 12 month historics say while the bulk have 24 which is what I'm
interested in).

Is there a way of creating a portfolio (so far I've tried a
feasiblePortfolio()) without dropping the subset with short histories?

So far I get this error:

> setWeights(ewSpec)<-rep(1/nAssets,times=nAssets)
> ewPortfolio<-feasiblePortfolio(
	data = asset.returns,
	spec = ewSpec,
	constraints = "LongOnly"
	)

Error in quantile.default(returns, alpha, type = 1) :
  missing values and NaN's not allowed if 'na.rm' is FALSE

Thanking you in advance,

Jorgy.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.
* Please Note : This message was received from the Internet *
_____________________________________________________________

__________________________________________________________________


Visit Schroders Talking Point for market news and expert views
http://www.schroders.com/talkingpoint

This message might contain confidential information. If it has been sent
to you in error please do not forward it or copy it or act upon its
contents, but report it to postmaster at schroders.com

Schroders has the right lawfully to record, monitor and inspect messages
between its employees and any third party. Your messages shall be
subject to such lawful supervision as Schroders deems to be necessary in
order to protect its information, its interests and its reputation.

Schroders prohibits and takes steps to prevent its information systems
from being used to view, store or forward offensive or discriminatory
material. If this message contains such material please report it to
abuse at schroders.com

Schroders does not normally accept or offer business instructions via
email unless prior agreements are in place. Any action that you might
take upon this message might be at your own risk.


Schroder Investment Management Limited
31 Gresham Street
London EC2V 7QA

Authorised and regulated by the Financial Services Authority. Schroder
Investment Management Limited is entered on the FSA register under the
following register number: 119348

Registered Office
31 Gresham Street
London EC2V 7QA

Registered number 1893220
VAT registration number 243 8687 30

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.

Issued by UBS AG or affiliates to professional investors...{{dropped:30}}


From ezivot at u.washington.edu  Thu Feb  4 19:38:33 2010
From: ezivot at u.washington.edu (Eric Zivot)
Date: Thu, 4 Feb 2010 10:38:33 -0800
Subject: [R-SIG-Finance] fPortfolio question: is it possible
	to	optimizeaportfolio when you've got missing (returns) data
	for	asubsetof your total assets?
In-Reply-To: <25492B412B325B4FB1FED95013D3E5CE0A109695@NLDNC105PEX1.ubsw.net>
References: <28c145941002040445s32b13f57hfc83271e0fc2b7e1@mail.gmail.com>	<E863B8D444B2464B949B92708C3BA384018A8CAA@LON0826.London.Schroders.com>
	<25492B412B325B4FB1FED95013D3E5CE0A109695@NLDNC105PEX1.ubsw.net>
Message-ID: <001d01caa5c9$4140b650$c3c222f0$@washington.edu>

Well, an even easier approach would be to use a simple factor model, like
Sharpe's single index model, to construct the return covariance matrix for
the assets. You can estimate the factor model on the available histories for
each stock and then construct the covariance matrix from the factor model
estimates (e.g. betas, factor covariances and residual variances). While
this doesn't use the "in-fill" approach of Stambaugh, it is certainly easier
to implement and would provide a good starting point.


Eric Zivot                  			               
Professor and Gary Waterman Distinguished Scholar       
Department of Economics                                 
Adjunct Professor of Finance                            
Adjunct Professor of Statistics
Box 353330                  email:  ezivot at u.washington.edu 
University of Washington    phone:  206-543-6715            
Seattle, WA 98195-3330
www:  http://faculty.washington.edu/ezivot                  


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of
david.jessop at ubs.com
Sent: Thursday, February 04, 2010 7:46 AM
To: David.King at schroders.com; jorgy.porgee at gmail.com;
r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] fPortfolio question: is it possible to
optimizeaportfolio when you've got missing (returns) data for asubsetof your
total assets?

Hi

Also, look for papers by Gramacy [Gramacy, R. B., Lee, J. H., and Silva,
R. (2008). "On estimating covariances between
many assets with histories of highly variable length." Tech. Rep.
0710.5837, arXiv. Url:http://arxiv.org/abs/0710.5837. ] who has extended
the Stambaugh approach.  And he's even been nice enough to produce an R
library to do what he talks about. 

Regards

David 

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of King,
David
Sent: 04 February 2010 13:10
To: Jorgy Porgee; r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] fPortfolio question: is it possible to
optimizeaportfolio when you've got missing (returns) data for asubsetof
your total assets?


See 'Covariance Misspecification in Asset Allocation' by Peterson and
Grier (FAJ 2006, Vol 62 No.4) and the references given in the paper
especially the work by Stambaugh.

Bernd Scherer's book 'Portfolio Construction and Risk Budgeting' also
contains useful information on this topic.

David


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Jorgy
Porgee
Sent: 04 February 2010 12:45
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] fPortfolio question: is it possible to optimize
aportfolio when you've got missing (returns) data for a subsetof your
total assets?

Good day all,

I'm trying to create a MV portfolio using a bunch of stock returns.
However, the length of the historic data is not uniform (some stocks
have 12 month historics say while the bulk have 24 which is what I'm
interested in).

Is there a way of creating a portfolio (so far I've tried a
feasiblePortfolio()) without dropping the subset with short histories?

So far I get this error:

> setWeights(ewSpec)<-rep(1/nAssets,times=nAssets)
> ewPortfolio<-feasiblePortfolio(
	data = asset.returns,
	spec = ewSpec,
	constraints = "LongOnly"
	)

Error in quantile.default(returns, alpha, type = 1) :
  missing values and NaN's not allowed if 'na.rm' is FALSE

Thanking you in advance,

Jorgy.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.
* Please Note : This message was received from the Internet *
_____________________________________________________________

__________________________________________________________________


Visit Schroders Talking Point for market news and expert views
http://www.schroders.com/talkingpoint

This message might contain confidential information. If it has been sent
to you in error please do not forward it or copy it or act upon its
contents, but report it to postmaster at schroders.com

Schroders has the right lawfully to record, monitor and inspect messages
between its employees and any third party. Your messages shall be
subject to such lawful supervision as Schroders deems to be necessary in
order to protect its information, its interests and its reputation.

Schroders prohibits and takes steps to prevent its information systems
from being used to view, store or forward offensive or discriminatory
material. If this message contains such material please report it to
abuse at schroders.com

Schroders does not normally accept or offer business instructions via
email unless prior agreements are in place. Any action that you might
take upon this message might be at your own risk.


Schroder Investment Management Limited
31 Gresham Street
London EC2V 7QA

Authorised and regulated by the Financial Services Authority. Schroder
Investment Management Limited is entered on the FSA register under the
following register number: 119348

Registered Office
31 Gresham Street
London EC2V 7QA

Registered number 1893220
VAT registration number 243 8687 30

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.

Issued by UBS AG or affiliates to professional investors...{{dropped:9}}


From patrick at burns-stat.com  Thu Feb  4 21:47:59 2010
From: patrick at burns-stat.com (Patrick Burns)
Date: Thu, 04 Feb 2010 20:47:59 +0000
Subject: [R-SIG-Finance] Fwd: Re: fPortfolio question: is it possible
 to	optimizeaportfolio when you've got missing (returns) data for	asubsetof
 your total assets?
Message-ID: <4B6B327F.6040102@burns-stat.com>

(missed the list on this one)

-------- Original Message --------
Subject: Re: [R-SIG-Finance] fPortfolio question: is it possible to 
optimizeaportfolio when you've got missing (returns) data for	asubsetof 
your total assets?
Date: Thu, 04 Feb 2010 16:37:48 +0000
From: Patrick Burns <patrick at burns-stat.com>
To: david.jessop at ubs.com

Thanks for pointing out 'monomvn', I'd previously
missed it.

 From a quick perusal of the paper I didn't see an
answer to the following question.  When there are
missing values, the covariance estimates are going
to be shrunk towards something (at least at the
moment I can't see how that can't be the case).
How you want the shrinkage to happen will depend on
what you are doing.  Optimizing long-short may be
different than optimizing long-only.  Optimizing
long-only relative to a benchmark can be different
from long-only independent of the benchmark.  I've
seen significant differences in the case of estimating
the variance with a statistical factor model.

Has there been any study of this estimator with missing
values for different types of portfolios?


On 04/02/2010 15:46, david.jessop at ubs.com wrote:
> Hi
>
> Also, look for papers by Gramacy [Gramacy, R. B., Lee, J. H., and Silva,
> R. (2008). "On estimating covariances between
> many assets with histories of highly variable length." Tech. Rep.
> 0710.5837, arXiv. Url:http://arxiv.org/abs/0710.5837. ] who has extended
> the Stambaugh approach.  And he's even been nice enough to produce an R
> library to do what he talks about.
>
> Regards
>
> David
>
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of King,
> David
> Sent: 04 February 2010 13:10
> To: Jorgy Porgee; r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] fPortfolio question: is it possible to
> optimizeaportfolio when you've got missing (returns) data for asubsetof
> your total assets?
>
>
> See 'Covariance Misspecification in Asset Allocation' by Peterson and
> Grier (FAJ 2006, Vol 62 No.4) and the references given in the paper
> especially the work by Stambaugh.
>
> Bernd Scherer's book 'Portfolio Construction and Risk Budgeting' also
> contains useful information on this topic.
>
> David
>
>
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Jorgy
> Porgee
> Sent: 04 February 2010 12:45
> To: r-sig-finance at stat.math.ethz.ch
> Subject: [R-SIG-Finance] fPortfolio question: is it possible to optimize
> aportfolio when you've got missing (returns) data for a subsetof your
> total assets?
>
> Good day all,
>
> I'm trying to create a MV portfolio using a bunch of stock returns.
> However, the length of the historic data is not uniform (some stocks
> have 12 month historics say while the bulk have 24 which is what I'm
> interested in).
>
> Is there a way of creating a portfolio (so far I've tried a
> feasiblePortfolio()) without dropping the subset with short histories?
>
> So far I get this error:
>
>> setWeights(ewSpec)<-rep(1/nAssets,times=nAssets)
>> ewPortfolio<-feasiblePortfolio(
> 	data = asset.returns,
> 	spec = ewSpec,
> 	constraints = "LongOnly"
> 	)
>
> Error in quantile.default(returns, alpha, type = 1) :
>    missing values and NaN's not allowed if 'na.rm' is FALSE
>
> Thanking you in advance,
>
> Jorgy.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
> * Please Note : This message was received from the Internet *
> _____________________________________________________________
>
> __________________________________________________________________
>
>
> Visit Schroders Talking Point for market news and expert views
> http://www.schroders.com/talkingpoint
>
> This message might contain confidential information. If it has been sent
> to you in error please do not forward it or copy it or act upon its
> contents, but report it to postmaster at schroders.com
>
> Schroders has the right lawfully to record, monitor and inspect messages
> between its employees and any third party. Your messages shall be
> subject to such lawful supervision as Schroders deems to be necessary in
> order to protect its information, its interests and its reputation.
>
> Schroders prohibits and takes steps to prevent its information systems
> from being used to view, store or forward offensive or discriminatory
> material. If this message contains such material please report it to
> abuse at schroders.com
>
> Schroders does not normally accept or offer business instructions via
> email unless prior agreements are in place. Any action that you might
> take upon this message might be at your own risk.
>
>
> Schroder Investment Management Limited
> 31 Gresham Street
> London EC2V 7QA
>
> Authorised and regulated by the Financial Services Authority. Schroder
> Investment Management Limited is entered on the FSA register under the
> following register number: 119348
>
> Registered Office
> 31 Gresham Street
> London EC2V 7QA
>
> Registered number 1893220
> VAT registration number 243 8687 30
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
> Issued by UBS AG or affiliates to professional investors...{{dropped:30}}
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com


From patrick at burns-stat.com  Thu Feb  4 21:56:02 2010
From: patrick at burns-stat.com (Patrick Burns)
Date: Thu, 04 Feb 2010 20:56:02 +0000
Subject: [R-SIG-Finance] fPortfolio question: is it
 possible	to	optimizeaportfolio when you've got missing (returns)
 data	for	asubsetof your total assets?
In-Reply-To: <001d01caa5c9$4140b650$c3c222f0$@washington.edu>
References: <28c145941002040445s32b13f57hfc83271e0fc2b7e1@mail.gmail.com>	<E863B8D444B2464B949B92708C3BA384018A8CAA@LON0826.London.Schroders.com>	<25492B412B325B4FB1FED95013D3E5CE0A109695@NLDNC105PEX1.ubsw.net>
	<001d01caa5c9$4140b650$c3c222f0$@washington.edu>
Message-ID: <4B6B3462.9010400@burns-stat.com>

On 04/02/2010 18:38, Eric Zivot wrote:
> Well, an even easier approach would be to use a simple factor model, like
> Sharpe's single index model, to construct the return covariance matrix for
> the assets. You can estimate the factor model on the available histories for
> each stock and then construct the covariance matrix from the factor model
> estimates (e.g. betas, factor covariances and residual variances). While
> this doesn't use the "in-fill" approach of Stambaugh, it is certainly easier
> to implement and would provide a good starting point.
>

That is essentially what the function in BurStFin
does (which by the way is still confined to
burns-stat.com -- it hasn't yet escaped to CRAN),
except it uses principal components.

But I think all this discussion might just be teasing
the original poster.  Am I wrong that the optimizer
demands you input a return matrix rather than a variance
matrix and expected return vector?

I tried to check, but I'm getting an error loading the
Rglpk package.

Pat


>
> Eric Zivot                  			
> Professor and Gary Waterman Distinguished Scholar
> Department of Economics
> Adjunct Professor of Finance
> Adjunct Professor of Statistics
> Box 353330                  email:  ezivot at u.washington.edu
> University of Washington    phone:  206-543-6715
> Seattle, WA 98195-3330
> www:  http://faculty.washington.edu/ezivot
>
>
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of
> david.jessop at ubs.com
> Sent: Thursday, February 04, 2010 7:46 AM
> To: David.King at schroders.com; jorgy.porgee at gmail.com;
> r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] fPortfolio question: is it possible to
> optimizeaportfolio when you've got missing (returns) data for asubsetof your
> total assets?
>
> Hi
>
> Also, look for papers by Gramacy [Gramacy, R. B., Lee, J. H., and Silva,
> R. (2008). "On estimating covariances between
> many assets with histories of highly variable length." Tech. Rep.
> 0710.5837, arXiv. Url:http://arxiv.org/abs/0710.5837. ] who has extended
> the Stambaugh approach.  And he's even been nice enough to produce an R
> library to do what he talks about.
>
> Regards
>
> David
>
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of King,
> David
> Sent: 04 February 2010 13:10
> To: Jorgy Porgee; r-sig-finance at stat.math.ethz.ch
> Subject: Re: [R-SIG-Finance] fPortfolio question: is it possible to
> optimizeaportfolio when you've got missing (returns) data for asubsetof
> your total assets?
>
>
> See 'Covariance Misspecification in Asset Allocation' by Peterson and
> Grier (FAJ 2006, Vol 62 No.4) and the references given in the paper
> especially the work by Stambaugh.
>
> Bernd Scherer's book 'Portfolio Construction and Risk Budgeting' also
> contains useful information on this topic.
>
> David
>
>
> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Jorgy
> Porgee
> Sent: 04 February 2010 12:45
> To: r-sig-finance at stat.math.ethz.ch
> Subject: [R-SIG-Finance] fPortfolio question: is it possible to optimize
> aportfolio when you've got missing (returns) data for a subsetof your
> total assets?
>
> Good day all,
>
> I'm trying to create a MV portfolio using a bunch of stock returns.
> However, the length of the historic data is not uniform (some stocks
> have 12 month historics say while the bulk have 24 which is what I'm
> interested in).
>
> Is there a way of creating a portfolio (so far I've tried a
> feasiblePortfolio()) without dropping the subset with short histories?
>
> So far I get this error:
>
>> setWeights(ewSpec)<-rep(1/nAssets,times=nAssets)
>> ewPortfolio<-feasiblePortfolio(
> 	data = asset.returns,
> 	spec = ewSpec,
> 	constraints = "LongOnly"
> 	)
>
> Error in quantile.default(returns, alpha, type = 1) :
>    missing values and NaN's not allowed if 'na.rm' is FALSE
>
> Thanking you in advance,
>
> Jorgy.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
> * Please Note : This message was received from the Internet *
> _____________________________________________________________
>
> __________________________________________________________________
>
>
> Visit Schroders Talking Point for market news and expert views
> http://www.schroders.com/talkingpoint
>
> This message might contain confidential information. If it has been sent
> to you in error please do not forward it or copy it or act upon its
> contents, but report it to postmaster at schroders.com
>
> Schroders has the right lawfully to record, monitor and inspect messages
> between its employees and any third party. Your messages shall be
> subject to such lawful supervision as Schroders deems to be necessary in
> order to protect its information, its interests and its reputation.
>
> Schroders prohibits and takes steps to prevent its information systems
> from being used to view, store or forward offensive or discriminatory
> material. If this message contains such material please report it to
> abuse at schroders.com
>
> Schroders does not normally accept or offer business instructions via
> email unless prior agreements are in place. Any action that you might
> take upon this message might be at your own risk.
>
>
> Schroder Investment Management Limited
> 31 Gresham Street
> London EC2V 7QA
>
> Authorised and regulated by the Financial Services Authority. Schroder
> Investment Management Limited is entered on the FSA register under the
> following register number: 119348
>
> Registered Office
> 31 Gresham Street
> London EC2V 7QA
>
> Registered number 1893220
> VAT registration number 243 8687 30
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
> Issued by UBS AG or affiliates to professional investors...{{dropped:9}}
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com


From nick.torenvliet at gmail.com  Fri Feb  5 04:23:13 2010
From: nick.torenvliet at gmail.com (Nick Torenvliet)
Date: Thu, 4 Feb 2010 22:23:13 -0500
Subject: [R-SIG-Finance] quantmod model functions
Message-ID: <8531d53e1002041923p5d3aac8axaaca6dcff9ef6f68@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100204/2ae96189/attachment.pl>

From josh.m.ulrich at gmail.com  Fri Feb  5 04:36:28 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 4 Feb 2010 21:36:28 -0600
Subject: [R-SIG-Finance] quantmod model functions
In-Reply-To: <8531d53e1002041923p5d3aac8axaaca6dcff9ef6f68@mail.gmail.com>
References: <8531d53e1002041923p5d3aac8axaaca6dcff9ef6f68@mail.gmail.com>
Message-ID: <8cca69991002041936h3955922yab85a5b003743238@mail.gmail.com>

Nick,

See:
https://stat.ethz.ch/pipermail/r-sig-finance/2009q3/004580.html

Best,
Josh
--
http://www.fosstrading.com



On Thu, Feb 4, 2010 at 9:23 PM, Nick Torenvliet
<nick.torenvliet at gmail.com> wrote:
> Hey all,
>
> Been going through the quantmod docs and I'm interested in getting to know
> the "model" related functions/functionality much better.
>
> I was wondering if any of you might be so inclined as to send me some
> working quantmod model code. ?History, scripts, whatever
> would be appreciated. ?Just something so I can cycle through some working
> models to get a hang of writing them myself.
>
> Thanks in advance,
>
> Nick
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From nick.torenvliet at gmail.com  Fri Feb  5 15:24:11 2010
From: nick.torenvliet at gmail.com (Nick Torenvliet)
Date: Fri, 5 Feb 2010 09:24:11 -0500
Subject: [R-SIG-Finance] IRC
Message-ID: <8531d53e1002050624l1bb574aahdb7ecd8f563b4545@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100205/b2252993/attachment.pl>

From josh.m.ulrich at gmail.com  Fri Feb  5 15:38:06 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 5 Feb 2010 08:38:06 -0600
Subject: [R-SIG-Finance] IRC
In-Reply-To: <8531d53e1002050624l1bb574aahdb7ecd8f563b4545@mail.gmail.com>
References: <8531d53e1002050624l1bb574aahdb7ecd8f563b4545@mail.gmail.com>
Message-ID: <8cca69991002050638l241b2b54w89625fe076a08c5f@mail.gmail.com>

On Fri, Feb 5, 2010 at 8:24 AM, Nick Torenvliet
<nick.torenvliet at gmail.com> wrote:
> Just hooked up a couple of econometric IRC chat rooms. ?Where do open source
> quant tools users hang out on IRC?
>
I'm not sure, but R finance users tend to hang out on the
R-SIG-Finance mailing list... and they appreciate the low
signal-to-noise ratio.

Best,
Josh
--
http://www.fosstrading.com

> Nick
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From josh.m.ulrich at gmail.com  Fri Feb  5 15:47:10 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 5 Feb 2010 08:47:10 -0600
Subject: [R-SIG-Finance] IRC
In-Reply-To: <8cca69991002050638l241b2b54w89625fe076a08c5f@mail.gmail.com>
References: <8531d53e1002050624l1bb574aahdb7ecd8f563b4545@mail.gmail.com> 
	<8cca69991002050638l241b2b54w89625fe076a08c5f@mail.gmail.com>
Message-ID: <8cca69991002050647x517e92f8od63ac5d9e481a247@mail.gmail.com>

On Fri, Feb 5, 2010 at 8:38 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> On Fri, Feb 5, 2010 at 8:24 AM, Nick Torenvliet
> <nick.torenvliet at gmail.com> wrote:
>> Just hooked up a couple of econometric IRC chat rooms. ?Where do open source
>> quant tools users hang out on IRC?
>>
> I'm not sure, but R finance users tend to hang out on the
> R-SIG-Finance mailing list... and they appreciate the low
> signal-to-noise ratio.
>
That should be *high* signal-to-noise ratio... and I need more coffee.

> Best,
> Josh
> --
> http://www.fosstrading.com
>
>> Nick
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>>
>


From nick.torenvliet at gmail.com  Fri Feb  5 16:10:37 2010
From: nick.torenvliet at gmail.com (Nick Torenvliet)
Date: Fri, 5 Feb 2010 10:10:37 -0500
Subject: [R-SIG-Finance] Academic Papers
Message-ID: <8531d53e1002050710g44182315v2ce7c2eafb0fb9c6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100205/5d48aff0/attachment.pl>

From edd at debian.org  Fri Feb  5 18:24:21 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 5 Feb 2010 11:24:21 -0600
Subject: [R-SIG-Finance] Academic Papers
In-Reply-To: <8531d53e1002050710g44182315v2ce7c2eafb0fb9c6@mail.gmail.com>
References: <8531d53e1002050710g44182315v2ce7c2eafb0fb9c6@mail.gmail.com>
Message-ID: <19308.21573.907588.124619@ron.nulle.part>


On 5 February 2010 at 10:10, Nick Torenvliet wrote:
| Sorry Josh, for possibly adding to the signal to noise ratio here :-)
| 
| I'm heading to the University of Waterloo library tomorrow to get some
| journal articles on quantitative finance, particularly an article in
| Quantitative Finance on Natural Gas inventories that just came out.
| 
| If anyone is looking for any articles in particular, let me know the
| reference and I'll see if I can grab you a pdf or two.

That is a kind thought---but also mostl likely in violation of copyright
terms and hence not something we condone.

Dirk

-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From edd at debian.org  Fri Feb  5 22:18:35 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 5 Feb 2010 15:18:35 -0600
Subject: [R-SIG-Finance] R / Finance 2010: Applied Finance with R --
	Registration now open
Message-ID: <19308.35627.230064.182439@ron.nulle.part>


   R / Finance 2010: Applied Finance with R
   April 16 & 17, Chicago, IL, US
  
   The second annual R / Finance conference for applied finance using R, 
   the premier free software system for statistical computation and graphics,
   will be held this spring in Chicago, IL, USA on Friday April 16 and
   Saturday April 17.

   Building on the success of the inaugural R / Finance 2009 event, this
   two-day conference will cover topics as diverse as portfolio theory,
   time-series analysis, as well as advanced risk tools, high-performance
   computing, and econometrics. All will be discussed within the context of
   using R as a primary tool for financial risk management and trading.

   Invited keynote presentations by Bernhard Pfaff, Ralph Vince, Mark Wildi
   and Achim Zeileis are complemented by over twenty talks (both full-length
   and 'lightning') selected from the submissions.  Four optional tutorials
   are also offered on Friday April 16.

   R / Finance 2010 is organized by a local group of R package authors and
   community contributors, and hosted by the International Center for Futures
   and Derivatives [ICFD] at the University of Illinois at Chicago.

   Conference registration is now open. Special advanced registration pricing is
   available, as well as discounted pricing for academic and student
   registrations. 

   More details and registration information can be found at the website at  

        	       http://www.RinFinance.com

   For the program committee:

        Gib Bassett, Peter Carl, Dirk Eddelbuettel, John Miller,
        Brian Peterson, Dale Rosenthal, Jeffrey Ryan

-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From kaninski2000 at yahoo.com  Sun Feb  7 01:14:02 2010
From: kaninski2000 at yahoo.com (Kanin Kaninski)
Date: Sat, 6 Feb 2010 16:14:02 -0800 (PST)
Subject: [R-SIG-Finance] Retrieving Historical Intraday Data with RBloomberg
Message-ID: <189175.46620.qm@web52805.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100206/efb5c44a/attachment.pl>

From cmdr_rogue at hotmail.com  Mon Feb  8 02:18:51 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Sun, 07 Feb 2010 20:18:51 -0500
Subject: [R-SIG-Finance] Retrieving Historical Intraday Data with
 RBloomberg
In-Reply-To: <189175.46620.qm@web52805.mail.re2.yahoo.com>
References: <189175.46620.qm@web52805.mail.re2.yahoo.com>
Message-ID: <BLU0-SMTP655644B588BCE941793504E2510@phx.gbl>

1) You don't really need to include "LAST_PRICE" as the argument for
"barfields". Actually, you don't really need to specify anything there
at all.

2) It's probably because there was no data available for 2009-12-15
00:00. You're looking at 5-minute intervals of data. My guess is that
either Bloomberg's servers didn't record the data between 2009-12-14
23:00 and 2009-12-15 00:00. It's not that big a deal unless you're
actually planning to trade using that data.

You'd probably be better off using the blpGetData function instead. It's
a wrapper function and more generic to boot.

On Sat, 2010-02-06 at 16:14 -0800, Kanin Kaninski wrote:
> As a total newbie in
> R, I am struggling to make a few things work. I am wondering if anyone
> has experience using RBloomberg to download intraday data.
> 
> I am using the following lines and get funky output:
> 
> ======================================
> library(RBloomberg)
> conn <- blpConnect()
> 
> # Loading currencies
> AUD
> <- blp(conn, "AUD Curncy", fields = "LAST_PRICE", start ="2009-12-15
> 00:00", end = "2010-01-18 23:59", barsize=5, barfields= " LAST_PRICE",
> retval="zoo")
> 
> ========================================
> 
> > head(AUD)
>                      LAST_PRICE. LAST_PRICE
> 2009-12-14 23:00:00                0.915447
> 2009-12-15 00:05:00                0.916005
> 2009-12-15 00:10:00                0.916167
> 2009-12-15 00:15:00                0.916200
> 2009-12-15 00:20:00                0.916188
> 2009-12-15 00:25:00                0.916265
> 
> (1) First question is why I need a space before  LAST 
> 
> in barfields= " LAST_PRICE"
> 
> Took me an hour to debug and still don't understand why this is the solution
> 
> (2)
> more
> worrisome, why doesn't it start at 2009-12-15 00:00:00 as
> instructed but at 2009-12-14 23:00:00. I am not sure the value returned
> there belong to this time stamp (i.e I think the value might belong to
> 2009-12-15 00:00:00 even though the timestamp says 2009-12-14 23:00:00).
> 
> Anyone had similar experience? What am I doing wrong here?
> 
> Thank you very much in advance.
> 
> (This request was also posted on NP)
> 
> 
>       
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From davidr at rhotrading.com  Mon Feb  8 16:55:03 2010
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Mon, 8 Feb 2010 09:55:03 -0600
Subject: [R-SIG-Finance] Retrieving Historical Intraday Data with
	RBloomberg
In-Reply-To: <189175.46620.qm@web52805.mail.re2.yahoo.com>
References: <189175.46620.qm@web52805.mail.re2.yahoo.com>
Message-ID: <F9F2A641C593D7408925574C05A7BE770508D228@rhopost.rhotrading.com>

I agree with Sarbo that you should use the higher level function.

But there was data at that time, and I can get it through Excel
and the Bloomberg History Tool.

I'm confused by your seeming necessity to insert a space in the
barfield.

(In the documentation for bar data from Bloomberg in the data wizard,
it looks as if the field should be what they call "Market events"
(Trade, Bid, Ask) and the barfield should be what they call Interval
fields (Open, High, Low, Close, Tick count, Volume).
However the RBloomberg code may wrap these for you.)
You may also want to specify the fill action and value for intervals
with no activity.
(I cannot run RBloomberg to check at this moment.)

David L. Reiner, PhD
Head Quant
XR Trading, LLC


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Kanin
Kaninski
Sent: Saturday, February 06, 2010 6:14 PM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] Retrieving Historical Intraday Data with
RBloomberg

As a total newbie in
R, I am struggling to make a few things work. I am wondering if anyone
has experience using RBloomberg to download intraday data.

I am using the following lines and get funky output:

======================================
library(RBloomberg)
conn <- blpConnect()

# Loading currencies
AUD
<- blp(conn, "AUD Curncy", fields = "LAST_PRICE", start ="2009-12-15
00:00", end = "2010-01-18 23:59", barsize=5, barfields= " LAST_PRICE",
retval="zoo")

========================================

> head(AUD)
                     LAST_PRICE. LAST_PRICE
2009-12-14 23:00:00                0.915447
2009-12-15 00:05:00                0.916005
2009-12-15 00:10:00                0.916167
2009-12-15 00:15:00                0.916200
2009-12-15 00:20:00                0.916188
2009-12-15 00:25:00                0.916265

(1) First question is why I need a space before  LAST 

in barfields= " LAST_PRICE"

Took me an hour to debug and still don't understand why this is the
solution

(2)
more
worrisome, why doesn't it start at 2009-12-15 00:00:00 as
instructed but at 2009-12-14 23:00:00. I am not sure the value returned
there belong to this time stamp (i.e I think the value might belong to
2009-12-15 00:00:00 even though the timestamp says 2009-12-14 23:00:00).

Anyone had similar experience? What am I doing wrong here?

Thank you very much in advance.

(This request was also posted on NP)


      
	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.

THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON'S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.


From kaninski2000 at yahoo.com  Tue Feb  9 00:21:47 2010
From: kaninski2000 at yahoo.com (Kanin Kaninski)
Date: Mon, 8 Feb 2010 15:21:47 -0800 (PST)
Subject: [R-SIG-Finance] Retrieving Historical Intraday Data with
	RBloomberg
Message-ID: <634778.37833.qm@web52807.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100208/3c284615/attachment.pl>

From davidr at rhotrading.com  Tue Feb  9 15:54:23 2010
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Tue, 9 Feb 2010 08:54:23 -0600
Subject: [R-SIG-Finance] Retrieving Historical Intraday Data
	withRBloomberg
In-Reply-To: <634778.37833.qm@web52807.mail.re2.yahoo.com>
References: <634778.37833.qm@web52807.mail.re2.yahoo.com>
Message-ID: <F9F2A641C593D7408925574C05A7BE770508D442@rhopost.rhotrading.com>

OK, I got the new version from R-forge and it does say to use blp() now.
Still needs a little work since ?blp gives me no help.
I ran your AUD example and got the same answer AND ALSO A WARNING about my time zone:
Warning message:
In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'CST'

That may explain why my result is a little funky. If you got this warning, too,
you might try setting your timezone.
(Unfortunately, the last time I changed my environment to make this work,
it broke some production stuff so I better not mess with it right now.)

-- David


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Kanin Kaninski
Sent: Monday, February 08, 2010 5:22 PM
To: r-sig-finance at stat.math.ethz.ch
Subject: Re: [R-SIG-Finance] Retrieving Historical Intraday Data withRBloomberg

Sarbo, thank you for your answer. 

1) You don't really need to include "LAST_PRICE" as the argument for "barfields". Actually, you don't really need to specify anything there at all.

If I don't specify anything, i.e. if I just write:

> AUD2 <- blp(conn, "AUD Curncy", fields = "LAST_PRICE", start ="2009-12-15 00:00", end = "2010-01-18 23:59", barsize=5, retval="zoo")
> head(AUD2)

I will receive the following, which contains more information than I wanted, but actually not the "close bar" (the close bar column contains N/A - another strange thing...):

                    LAST_PRICE.OPEN LAST_PRICE.HIGH LAST_PRICE.LOW LAST_PRICE.LAST_TRADE LAST_PRICE.NUMBER_TICKS LAST_PRICE.VOLUME
2009-12-14 23:00:00        0.915705        0.915705       0.915400                    NA                    1127                 0
2009-12-15 00:05:00        0.915450        0.916075       0.915450                    NA                    1183                 0
2009-12-15 00:10:00        0.916005        0.916185       0.915998                    NA                     746                 0
2009-12-15 00:15:00        0.916160        0.916530       0.916000                    NA                    1230                 0
2009-12-15 00:20:00        0.916200        0.916307       0.916135                    NA                    1021                 0
2009-12-15 00:25:00        0.916188        0.916350       0.916095                 NA                    1271                 0

2) It's probably because there was no data available for 2009-12-15
00:00. You're looking at 5-minute intervals of data. My guess is that
either Bloomberg's servers didn't record the data between 2009-12-14
23:00 and 2009-12-15 00:00. It's not that big a deal unless you're actually planning to trade using that data.
No there is data there, and I am pretty sure the data is correct but the time stamp received is displaced by one hour for some reason:

> head(AUD)
                        LAST
2009-12-14 23:00:00 0.915447
2009-12-15 00:05:00 0.916005
2009-12-15 00:10:00 0.916167
2009-12-15 00:15:00 0.916200
2009-12-15 00:20:00 0.916188
2009-12-15 00:25:00 0.916265

>
AUD_lag <- blp(conn, "AUD Curncy", fields = "LAST_PRICE", start
="2009-12-14 00:00", end = "2010-01-18 23:59", barsize=5, barfields= "
LAST_PRICE", retval="zoo")
> AUD_lag <- as.xts(AUD_lag)

> AUD_lag["2009-12-15 00:00:00"]
           LAST_PRICE. LAST_PRICE
2009-12-15               0.915447

> AUD_lag["2009-12-14 23:00:00"]
                    LAST_PRICE. LAST_PRICE
2009-12-14 23:00:00               0.915585

So I could probably force the change of time stamp to 2009-12-15 00:00:00 but that would be the same as assuming that there is a bug in RBloomberg. Given that this should be such a basic function, I would be surprised if this was a bug. It is more probable this is a config issue. But as a total newbie I struggle to see from where this comes.

You'd probably be better off using the blpGetData function instead. It's
a wrapper function and more generic to boot.
Running blpGetData() I receive the following:
> blpGetData is deprecated, please update your code to call blp() instead. blpGetData will be removed in an upcoming version of RBloomberg.
So my understanding is the blp() is what shoudl be used. The package used is 'http://R-forge.R-project.org/bin/windows/contrib/2.10/RBloomberg_0.2-2.zip'

===============
David, I agree the space is a strange error. Look at the two outputs belows:

# This is with space:

> AUD <- blp(conn, "AUD Curncy", fields = "LAST_PRICE", start ="2009-12-15 00:00", end = "2010-01-18 23:59", barsize=5, barfields= " LAST_PRICE", retval="zoo")
> head(AUD)
                    LAST_PRICE. LAST_PRICE
2009-12-14 23:00:00               0.915447
2009-12-15 00:05:00               0.916005
2009-12-15 00:10:00               0.916167
2009-12-15 00:15:00               0.916200
2009-12-15 00:20:00               0.916188
2009-12-15 00:25:00               0.916265

# Now if I try without the space:

> AUD <- blp(conn, "AUD Curncy", fields = "LAST_PRICE", start ="2009-12-15 00:00", end = "2010-01-18 23:59", barsize=5, barfields= "LAST_PRICE", retval="zoo")
Error in blp(conn, "AUD Curncy", fields = "LAST_PRICE", start = "2009-12-15 00:00",  : 
  barfields must be one or more of  OPEN, HIGH, LOW, LAST_PRICE, VOLUME, NUMBER_TICKS


=======================
Any help appreciated! Thanks in advance.










      
	[[alternative HTML version deleted]]



This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.
 
THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON'S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.


From kaninski2000 at yahoo.com  Tue Feb  9 23:29:44 2010
From: kaninski2000 at yahoo.com (Kanin Kaninski)
Date: Tue, 9 Feb 2010 14:29:44 -0800 (PST)
Subject: [R-SIG-Finance] Retrieving Historical Intraday Data
	withRBloomberg
In-Reply-To: <F9F2A641C593D7408925574C05A7BE770508D442@rhopost.rhotrading.com>
Message-ID: <220567.87840.qm@web52805.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100209/bfb6de44/attachment.pl>

From nelson.ana at gmail.com  Thu Feb 11 14:43:11 2010
From: nelson.ana at gmail.com (Ana Nelson)
Date: Thu, 11 Feb 2010 13:43:11 +0000
Subject: [R-SIG-Finance] RBloomberg 0.2-98
Message-ID: <a7d6d2741002110543x924ed7eg8d4e801f08f2d9d8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100211/cbe8b444/attachment.pl>

From davidr at rhotrading.com  Thu Feb 11 15:25:28 2010
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Thu, 11 Feb 2010 08:25:28 -0600
Subject: [R-SIG-Finance] RBloomberg 0.2-98
In-Reply-To: <a7d6d2741002110543x924ed7eg8d4e801f08f2d9d8@mail.gmail.com>
References: <a7d6d2741002110543x924ed7eg8d4e801f08f2d9d8@mail.gmail.com>
Message-ID: <F9F2A641C593D7408925574C05A7BE77051F3D30@rhopost.rhotrading.com>

Ana,
What is the relation between this version and the one at
http://R-forge.R-project.org/bin/windows/contrib/2.10/RBloomberg_0.2-2.z
ip ?
I successfully installed the latter in R 2.10.1 and it seems to work
(mostly) correctly.
Of course that one depends on rcom, zoo, bitops, and RUnit and uses
statconn.
Thanks,
David L. Reiner, PhD
Head Quant
XR Trading, LLC


-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Ana Nelson
Sent: Thursday, February 11, 2010 7:43 AM
To: R-Finance
Subject: [R-SIG-Finance] RBloomberg 0.2-98

A new minor version of RBloomberg is available via:

install.packages("RBloomberg",repos="http://r.bloombergapi.com/")

Note that this is only available for R 2.9 (or 2.8) as there is no
RDCOMClient for R 2.10 yet.

There is now support for returning bar data in zoo format, other minor
bug
fixes.

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.

THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON'S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.


From kaninski2000 at yahoo.com  Fri Feb 12 00:36:28 2010
From: kaninski2000 at yahoo.com (Kanin Kaninski)
Date: Thu, 11 Feb 2010 15:36:28 -0800 (PST)
Subject: [R-SIG-Finance] Retrieving Historical Intraday Data
	withRBloomberg
In-Reply-To: <F9F2A641C593D7408925574C05A7BE770508D442@rhopost.rhotrading.com>
Message-ID: <279821.78900.qm@web52807.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100211/d93c8df0/attachment.pl>

From vsg.nyc at gmail.com  Fri Feb 12 21:02:06 2010
From: vsg.nyc at gmail.com (Rich Ghazarian)
Date: Fri, 12 Feb 2010 12:02:06 -0800
Subject: [R-SIG-Finance] Plot GARCH data using Quantmod
Message-ID: <ace0be451002121202n57636be9xb03117bad4d8f5f0@mail.gmail.com>

I'm trying to plot a garch fit using quantmod by doing something like this
 mm <- specifyModel(garchFit(formula = ~ garch(1, 1), data = ngrt1))

and obviously it's not working

My question is what is: What is the quickest way to fit and plot a
GARCH series that preserves its date and time structure.  If I just do
something like
test<-(fitted(garch(ngrt1, order = c(1,1),fitted.values=TRUE)))
then I lose the date index.

Thank you


From brian at braverock.com  Fri Feb 12 21:37:50 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 12 Feb 2010 14:37:50 -0600
Subject: [R-SIG-Finance] Plot GARCH data using Quantmod
In-Reply-To: <ace0be451002121202n57636be9xb03117bad4d8f5f0@mail.gmail.com>
References: <ace0be451002121202n57636be9xb03117bad4d8f5f0@mail.gmail.com>
Message-ID: <4B75BC1E.1020506@braverock.com>

Rich Ghazarian wrote:
> I'm trying to plot a garch fit using quantmod by doing something like this
>  mm <- specifyModel(garchFit(formula = ~ garch(1, 1), data = ngrt1))
>
> and obviously it's not working
>
> My question is what is: What is the quickest way to fit and plot a
> GARCH series that preserves its date and time structure.  If I just do
> something like
> test<-(fitted(garch(ngrt1, order = c(1,1),fitted.values=TRUE)))
> then I lose the date index.
>   
You've specified GARCH functions from two different packages, fGarch and 
tseries.

the ones from tseries are years old at this point, and there are many 
newer GARCH implementations in R, including fGarch.

fGarch has many plotting methods.  Are those not working for you? 

help("plot-methods",package='fGarch')

there are also numerous examples in the garchFit documentation

help("garchFit",package='fGarch')

garchFit will give you timeSeries results, you can plot those using 
chartSeries.  I do it all the time.

specifyModel in quantmod doesn't work the way you seem to think it 
does.  It's not magic.  See the quantmod documentation, quantmod 
website, and the list archives of this thread foor how to use 
specifyModel (you won't use the way your example seems to propose)

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From cmdr_rogue at hotmail.com  Sat Feb 13 03:58:06 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Fri, 12 Feb 2010 21:58:06 -0500
Subject: [R-SIG-Finance] Plot GARCH data using Quantmod
In-Reply-To: <ace0be451002121202n57636be9xb03117bad4d8f5f0@mail.gmail.com>
References: <ace0be451002121202n57636be9xb03117bad4d8f5f0@mail.gmail.com>
Message-ID: <BLU0-SMTP58AE81102309EB35404047E24C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100212/08d3316d/attachment.pl>

From tallent_e at lycos.com  Sat Feb 13 21:50:55 2010
From: tallent_e at lycos.com (Edouard Tallent)
Date: Sat, 13 Feb 2010 15:50:55 -0500 (EST)
Subject: [R-SIG-Finance] commodities futures
Message-ID: <20100213155055.HM.000000000000AH3@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100213/4bcd1ad3/attachment.html>

From cmdr_rogue at hotmail.com  Sat Feb 13 22:54:35 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Sat, 13 Feb 2010 16:54:35 -0500
Subject: [R-SIG-Finance] commodities futures
In-Reply-To: <20100213155055.HM.000000000000AH3@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
References: <20100213155055.HM.000000000000AH3@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
Message-ID: <BLU0-SMTP7571CB1FCA3FC05EA72CC9E24C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100213/d93fe214/attachment.pl>

From kaninski2000 at yahoo.com  Sun Feb 14 04:07:18 2010
From: kaninski2000 at yahoo.com (Kanin Kaninski)
Date: Sat, 13 Feb 2010 19:07:18 -0800 (PST)
Subject: [R-SIG-Finance] Rounding time series to nearest 5mn
Message-ID: <495005.95159.qm@web52805.mail.re2.yahoo.com>

Continuing on the learning path... I have the followig xts time series:

                    LAST      
2009-12-15 00:00:00 "0.915447"
2009-12-15 00:04:59 "0.916005"
2009-12-15 00:09:59 "0.916167"
2009-12-15 00:15:00 "0.9162"  
2009-12-15 00:20:00 "0.916188"
2009-12-15 00:24:59 "0.916265"

I would like to quantize the time stamps so that 00:04:59 becomes 00:05:00, i.e. rounding the time series to the nearest (in this case) 5 minutes.

What I could find on the net was the align function in the xts package. Unfortunately it doesnt really perform as expected: it has transformed a 5mn multiple timestamp (e.g. 00:00:00) into the next multiple (00:05:00). Moreover I understand that it always "round up" the time, rather than rounding to closest.

> tSerie_align<-align.time(tSerie, n=300)
> head(tSerie_align)
                    LAST      
2009-12-15 00:05:00 "0.915447"
2009-12-15 00:05:00 "0.916005"
2009-12-15 00:10:00 "0.916167"
2009-12-15 00:20:00 "0.9162"  
2009-12-15 00:25:00 "0.916188"
2009-12-15 00:25:00 "0.916265"

Any ideas how I could transform this time series to look as follows:

                    LAST      
2009-12-15 00:00:00 "0.915447"
2009-12-15 00:05:00 "0.916005"
2009-12-15 00:10:00 "0.916167"
2009-12-15 00:15:00 "0.9162"  
2009-12-15 00:20:00 "0.916188"
2009-12-15 00:25:00 "0.916265"

Thank you in advance.

/K


From josh.m.ulrich at gmail.com  Sun Feb 14 04:44:17 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 13 Feb 2010 21:44:17 -0600
Subject: [R-SIG-Finance] Rounding time series to nearest 5mn
In-Reply-To: <495005.95159.qm@web52805.mail.re2.yahoo.com>
References: <495005.95159.qm@web52805.mail.re2.yahoo.com>
Message-ID: <8cca69991002131944u73071901r9d1b64c2b7a9ca11@mail.gmail.com>

On Sat, Feb 13, 2010 at 9:07 PM, Kanin Kaninski <kaninski2000 at yahoo.com> wrote:
> Continuing on the learning path... I have the followig xts time series:
>
> ? ? ? ? ? ? ? ? ? ?LAST
> 2009-12-15 00:00:00 "0.915447"
> 2009-12-15 00:04:59 "0.916005"
> 2009-12-15 00:09:59 "0.916167"
> 2009-12-15 00:15:00 "0.9162"
> 2009-12-15 00:20:00 "0.916188"
> 2009-12-15 00:24:59 "0.916265"
>
> I would like to quantize the time stamps so that 00:04:59 becomes 00:05:00, i.e. rounding the time series to the nearest (in this case) 5 minutes.
>
> What I could find on the net was the align function in the xts package. Unfortunately it doesnt really perform as expected: it has transformed a 5mn multiple timestamp (e.g. 00:00:00) into the next multiple (00:05:00). Moreover I understand that it always "round up" the time, rather than rounding to closest.
>
It performs exactly as documented.  Is that really unfortunate or unexpected?

"Description:

     Change timestamps to the start of the next period, specified in
     multiples of seconds."
[snip]
"Details:

     This function is an S3 generic.  The result is to round up to the
     next period determined by ?n modulo x?."


>> tSerie_align<-align.time(tSerie, n=300)
>> head(tSerie_align)
> ? ? ? ? ? ? ? ? ? ?LAST
> 2009-12-15 00:05:00 "0.915447"
> 2009-12-15 00:05:00 "0.916005"
> 2009-12-15 00:10:00 "0.916167"
> 2009-12-15 00:20:00 "0.9162"
> 2009-12-15 00:25:00 "0.916188"
> 2009-12-15 00:25:00 "0.916265"
>
> Any ideas how I could transform this time series to look as follows:
>
> ? ? ? ? ? ? ? ? ? ?LAST
> 2009-12-15 00:00:00 "0.915447"
> 2009-12-15 00:05:00 "0.916005"
> 2009-12-15 00:10:00 "0.916167"
> 2009-12-15 00:15:00 "0.9162"
> 2009-12-15 00:20:00 "0.916188"
> 2009-12-15 00:25:00 "0.916265"
>
Make a new xts object:

new.tSerie <- xts(coredata(tSerie),index(tSerie)-1)
align.time(new.tSerie)
                        [,1]
2009-12-15 00:00:00 0.915447
2009-12-15 00:05:00 0.916005
2009-12-15 00:10:00 0.916167
2009-12-15 00:15:00 0.916200
2009-12-15 00:20:00 0.916188
2009-12-15 00:25:00 0.916265

Best,
Josh
--
http://www.fosstrading.com


> Thank you in advance.
>
> /K
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From jeff.a.ryan at gmail.com  Sun Feb 14 04:59:01 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sat, 13 Feb 2010 21:59:01 -0600
Subject: [R-SIG-Finance] Rounding time series to nearest 5mn
In-Reply-To: <495005.95159.qm@web52805.mail.re2.yahoo.com>
References: <495005.95159.qm@web52805.mail.re2.yahoo.com>
Message-ID: <e8e755251002131959o17f7e7ccy971519208cd7a415@mail.gmail.com>

> I would like to quantize the time stamps so that 00:04:59 becomes 00:05:00, i.e. rounding the time series to the nearest (in this case) 5 minutes.
>

I general that is a bad idea, as you now have timestamps that refer to
data that occurs in the future.  Might look nice, but will likely cost
you money...

> What I could find on the net was the align function in the xts package. Unfortunately it doesnt really perform as expected: it has transformed a 5mn multiple timestamp (e.g. 00:00:00) into the next multiple (00:05:00). Moreover I understand that it always "round up" the time, rather than rounding to closest.

See above comment.  And per docs, it is as expected.

To clarify why 00:00:00 isn't set to 00:00:00, it is because the
function aggregates all values within the time block (5 min here) and
sets the time stamp to the beginning of the next block.  1:00:00 is
the start of the hour, and everything from that point onward to 1:05
(but not including) is pegged to 1:05.

Josh's reply should do what you want, but rounding down is a recipe
for disaster.

HTH
Jeff

>
>> tSerie_align<-align.time(tSerie, n=300)
>> head(tSerie_align)
> ? ? ? ? ? ? ? ? ? ?LAST
> 2009-12-15 00:05:00 "0.915447"
> 2009-12-15 00:05:00 "0.916005"
> 2009-12-15 00:10:00 "0.916167"
> 2009-12-15 00:20:00 "0.9162"
> 2009-12-15 00:25:00 "0.916188"
> 2009-12-15 00:25:00 "0.916265"
>
> Any ideas how I could transform this time series to look as follows:
>
> ? ? ? ? ? ? ? ? ? ?LAST
> 2009-12-15 00:00:00 "0.915447"
> 2009-12-15 00:05:00 "0.916005"
> 2009-12-15 00:10:00 "0.916167"
> 2009-12-15 00:15:00 "0.9162"
> 2009-12-15 00:20:00 "0.916188"
> 2009-12-15 00:25:00 "0.916265"
>
> Thank you in advance.
>
> /K
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From dstjohn at math.uic.edu  Sun Feb 14 16:57:51 2010
From: dstjohn at math.uic.edu (David St John)
Date: Sun, 14 Feb 2010 09:57:51 -0600
Subject: [R-SIG-Finance] Rounding time series to nearest 5mn
Message-ID: <998c123e1002140757y5c64cdebr928e093513e2f246@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100214/ae74d1ae/attachment.pl>

From dstjohn at math.uic.edu  Sun Feb 14 17:01:25 2010
From: dstjohn at math.uic.edu (David St John)
Date: Sun, 14 Feb 2010 10:01:25 -0600
Subject: [R-SIG-Finance] Rounding time series to nearest 5mn
Message-ID: <998c123e1002140801l48ebd9cbk4041ca3a5d5bac31@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100214/50266cee/attachment.pl>

From kaninski2000 at yahoo.com  Sun Feb 14 18:00:59 2010
From: kaninski2000 at yahoo.com (Kanin Kaninski)
Date: Sun, 14 Feb 2010 09:00:59 -0800 (PST)
Subject: [R-SIG-Finance] Rounding time series to nearest 5mn
In-Reply-To: <e8e755251002131959o17f7e7ccy971519208cd7a415@mail.gmail.com>
Message-ID: <51962.52957.qm@web52805.mail.re2.yahoo.com>

Josh, Jeff, thank you for your answers. 

Jeff, I totally agree with you re: dangers of changing time stamps on observations. 

The issue here is that the data is pulled from BBG and should be in 5mn increments, so even though the time stamp shows 04:59, I'm 99% sure it really means 05:00. 

I guess you would argue that its more correct to keep it as 04:59 given that xts can handle this but my "quick and dirty" testing at this stage will suffer some intial productivity if I do this. Not super clean, but will get me through until I find out why the data from Bloomberg is not retrieved in multiples of 5mn...

Thank you again for your quick replies. Much appreciated.

/K


--- On Sun, 2/14/10, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:

> From: Jeff Ryan <jeff.a.ryan at gmail.com>
> Subject: Re: [R-SIG-Finance] Rounding time series to nearest 5mn
> To: "Kanin Kaninski" <kaninski2000 at yahoo.com>
> Cc: r-sig-finance at stat.math.ethz.ch
> Date: Sunday, February 14, 2010, 4:59 AM
> > I would like to quantize the
> time stamps so that 00:04:59 becomes 00:05:00, i.e. rounding
> the time series to the nearest (in this case) 5 minutes.
> >
> 
> I general that is a bad idea, as you now have timestamps
> that refer to
> data that occurs in the future.? Might look nice, but
> will likely cost
> you money...
> 
> > What I could find on the net was the align function in
> the xts package. Unfortunately it doesnt really perform as
> expected: it has transformed a 5mn multiple timestamp (e.g.
> 00:00:00) into the next multiple (00:05:00). Moreover I
> understand that it always "round up" the time, rather than
> rounding to closest.
> 
> See above comment.? And per docs, it is as expected.
> 
> To clarify why 00:00:00 isn't set to 00:00:00, it is
> because the
> function aggregates all values within the time block (5 min
> here) and
> sets the time stamp to the beginning of the next
> block.? 1:00:00 is
> the start of the hour, and everything from that point
> onward to 1:05
> (but not including) is pegged to 1:05.
> 
> Josh's reply should do what you want, but rounding down is
> a recipe
> for disaster.
> 
> HTH
> Jeff
> 
> >
> >> tSerie_align<-align.time(tSerie, n=300)
> >> head(tSerie_align)
> > ? ? ? ? ? ? ? ? ? ?LAST
> > 2009-12-15 00:05:00 "0.915447"
> > 2009-12-15 00:05:00 "0.916005"
> > 2009-12-15 00:10:00 "0.916167"
> > 2009-12-15 00:20:00 "0.9162"
> > 2009-12-15 00:25:00 "0.916188"
> > 2009-12-15 00:25:00 "0.916265"
> >
> > Any ideas how I could transform this time series to
> look as follows:
> >
> > ? ? ? ? ? ? ? ? ? ?LAST
> > 2009-12-15 00:00:00 "0.915447"
> > 2009-12-15 00:05:00 "0.916005"
> > 2009-12-15 00:10:00 "0.916167"
> > 2009-12-15 00:15:00 "0.9162"
> > 2009-12-15 00:20:00 "0.916188"
> > 2009-12-15 00:25:00 "0.916265"
> >
> > Thank you in advance.
> >
> > /K
> >
> > _______________________________________________
> > R-SIG-Finance at stat.math.ethz.ch
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post,
> subscribe first.
> > -- Also note that this is not the r-help list where
> general R questions should go.
> >
> 
> 
> 
> -- 
> Jeffrey Ryan
> jeffrey.ryan at insightalgo.com
> 
> ia: insight algorithmics
> www.insightalgo.com
> 





From luethid at gmail.com  Sun Feb 14 18:13:33 2010
From: luethid at gmail.com (=?ISO-8859-1?Q?David_L=FCthi?=)
Date: Sun, 14 Feb 2010 18:13:33 +0100
Subject: [R-SIG-Finance] commodities futures
In-Reply-To: <20100213155055.HM.000000000000AH3@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
References: <20100213155055.HM.000000000000AH3@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
Message-ID: <4B782F3D.7060608@gmail.com>

Hi Edouard

There is an R package which deals with commodity futures. It's name is
schwartz97 and can be found on R-forge under the Rmetrics project (it
will be on CRAN soon). As revealed by its name, this package
implements the 2 factor model of Eduardo Schwartz.

In general commodity modelling is not straight-forward at all and a
commodity model per se does not exist. The characteristics of
different commodities can be completely different.  Gold, e.g.,
behaves as a financial asset and therefore standard term-structure
models can be used. Flow commodities as electricity can exhibit very
wild behavior as zero prices and very steep forward curves in both
directions. The spot market (if it exists) is likely to be illiquid
but futures are traded in high volumes. Hence, the dynamics of the
forward curve is the object of interest and the plain spot price
dynamics is least relevant.  But a flexible forward curve implies the
modelling of several factors. The likelihood to run into serious
overfitting when several factors and their interdependence is modelled
is high...

To sum up, the model or heuristic of choice depends heavily on the
commodity and the goal of the modelling. The 2-factor model of
Schwartz is quite appropriate for base metals and some agriculturals
as soybeans and corn if it is about risk management.

Cheers, david


Edouard Tallent wrote:
> hi everyone.
> 
> is there any special R package to deal with commodities futures ?
> 
> anyone interested in sharing knowledge, experience on the implementation of 
> trading strategies on commodities futures markets (energy, softs) with R ?
> 
> cheers,
> edouard.
> 
> "spreads for life"
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From brian at braverock.com  Mon Feb 15 01:20:28 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 14 Feb 2010 18:20:28 -0600
Subject: [R-SIG-Finance] Rounding time series to nearest 5mn
In-Reply-To: <51962.52957.qm@web52805.mail.re2.yahoo.com>
References: <51962.52957.qm@web52805.mail.re2.yahoo.com>
Message-ID: <4B78934C.3080604@braverock.com>

Kanin Kaninski wrote:
> Josh, Jeff, thank you for your answers. 
> 
> Jeff, I totally agree with you re: dangers of changing time stamps on observations. 
> 
> The issue here is that the data is pulled from BBG and should be in 5mn increments, so even though the time stamp shows 04:59, I'm 99% sure it really means 05:00. 
> 
> I guess you would argue that its more correct to keep it as 04:59 given that xts can handle this but my "quick and dirty" testing at this stage will suffer some intial productivity if I do this. Not super clean, but will get me through until I find out why the data from Bloomberg is not retrieved in multiples of 5mn...
> 
> Thank you again for your quick replies. Much appreciated.

What is likely happening with the BBG data is the same thing that happens with 
to.period in xts.  The last observation in the bar is returned, and it will 
likely not fall exactly on the bar.

You may also want to look at digits.secs, because 00:00:00.0001 is not the same 
as 00:00:00

align.time will work 'better' (more like you expect) in xts if you get higher 
frequency data from your data provider, apply to.period, and then align.time. 
This is the application it was written for, to take high frequency data and 
align it nicely in lower frequency bars.  In these cases, you should not see 
some of the odd things that you seem to be getting from trying to align your 
Bloomberg bars.

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From j_cuisinier at hotmail.com  Tue Feb 16 12:07:38 2010
From: j_cuisinier at hotmail.com (julien cuisinier)
Date: Tue, 16 Feb 2010 12:07:38 +0100
Subject: [R-SIG-Finance] quantmod getSymbols data extraction issue - (1)
 symbol starting with number & (2) accessing data from multiple symbols
 lookup (through simple loop?)
Message-ID: <COL102-W257D47F45AACB810AED0B78F490@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100216/576501b0/attachment.pl>

From scott.p.macdonald at gmail.com  Tue Feb 16 12:12:11 2010
From: scott.p.macdonald at gmail.com (Scott MacDonald)
Date: Tue, 16 Feb 2010 22:12:11 +1100
Subject: [R-SIG-Finance] quantmod getSymbols data extraction issue - (1)
	symbol starting with number & (2) accessing data from
	multiple symbols lookup (through simple loop?)
In-Reply-To: <COL102-W257D47F45AACB810AED0B78F490@phx.gbl>
References: <COL102-W257D47F45AACB810AED0B78F490@phx.gbl>
Message-ID: <c4adf6e91002160312m146183bau6a9fcfd2d5bfdc4b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100216/2cb183db/attachment.pl>

From j_cuisinier at hotmail.com  Tue Feb 16 12:40:04 2010
From: j_cuisinier at hotmail.com (julien cuisinier)
Date: Tue, 16 Feb 2010 12:40:04 +0100
Subject: [R-SIG-Finance] quantmod getSymbols data extraction issue -
 (1)symbol starting with number & (2) accessing data from multiple
 symbolslookup (through simple loop?)
In-Reply-To: <577394828-1266318892-cardhu_decombobulator_blackberry.rim.net-1790139533-@bda147.bisx.prod.on.blackberry>
References: <COL102-W257D47F45AACB810AED0B78F490@phx.gbl>,
	<577394828-1266318892-cardhu_decombobulator_blackberry.rim.net-1790139533-@bda147.bisx.prod.on.blackberry>
Message-ID: <COL102-W58CF013521635355111F9A8F490@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100216/8b381bd6/attachment.pl>

From benjifamel at gmail.com  Wed Feb 17 00:34:38 2010
From: benjifamel at gmail.com (Benji Famel)
Date: Tue, 16 Feb 2010 18:34:38 -0500
Subject: [R-SIG-Finance] PCA in Risk Control with R
Message-ID: <b50d8da01002161534v3f87af73t2dfdef9dc048e765@mail.gmail.com>

Hello,

my apologies if I do something wrong - first posting for me.

I am trying to apply PCA on the daily history of a bunch of forward
curves and run into my depths of ignorance.  I would appreciate some
help...

My aim is to use PCA for risk control.  I.e. estimate the
eigenverctors and eigenvalues and build the principal components at
some confidence level, e.g. 95%.  If, for example, we were looking at
the first 3 components only, I would
- estimate PC1up, PC1dn, PC2up, PC2dn, PC3up and PC3dn.

Let's assume that
- PC1up is worse for my position than PC1dn,
- PC2up is worse than PC2dn and
- PC3dn is worse than PC3up
I would then 'add' these worse for me components (PC1up, PC2up and
PC3dn) and run my position through them to get a measure of risk at
that confidence level.

To do the PCA, I first foundthe log returns, let's call them Returns.
I then do:
pcdat <-princomp(Returns, cor=TRUE)
and calculate the principal components like this (this is where I am
very foggy...):

PC <- exp(someQuantile*t(pcdat[[2]])*sqrt(pcdat[[1]])*sd(Returns))   #
somQuantile = 1.64 for a 95% CL


As much as I looked around, people discuss the benefits of PC but not
how to recombine the principal components at some confidence interval
to get a shocked curve.

Could anyone help?

Thank you,
Benji


From brian at braverock.com  Wed Feb 17 00:54:10 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 16 Feb 2010 17:54:10 -0600
Subject: [R-SIG-Finance] PCA in Risk Control with R
In-Reply-To: <b50d8da01002161534v3f87af73t2dfdef9dc048e765@mail.gmail.com>
References: <b50d8da01002161534v3f87af73t2dfdef9dc048e765@mail.gmail.com>
Message-ID: <4B7B3022.4060907@braverock.com>

Why don't you disguise a subset of your data and provide a working example?

Both you and the list will get more out of it if we can all work on something 
that is actually executable in R, per the posting guide.

Your problem is interesting and relevant, so put a little more effort into it, 
and I'm sure you'll get collaborators in working through it.

Regards,

   - Brian

Benji Famel wrote:
> Hello,
> 
> my apologies if I do something wrong - first posting for me.
> 
> I am trying to apply PCA on the daily history of a bunch of forward
> curves and run into my depths of ignorance.  I would appreciate some
> help...
> 
> My aim is to use PCA for risk control.  I.e. estimate the
> eigenverctors and eigenvalues and build the principal components at
> some confidence level, e.g. 95%.  If, for example, we were looking at
> the first 3 components only, I would
> - estimate PC1up, PC1dn, PC2up, PC2dn, PC3up and PC3dn.
> 
> Let's assume that
> - PC1up is worse for my position than PC1dn,
> - PC2up is worse than PC2dn and
> - PC3dn is worse than PC3up
> I would then 'add' these worse for me components (PC1up, PC2up and
> PC3dn) and run my position through them to get a measure of risk at
> that confidence level.
> 
> To do the PCA, I first foundthe log returns, let's call them Returns.
> I then do:
> pcdat <-princomp(Returns, cor=TRUE)
> and calculate the principal components like this (this is where I am
> very foggy...):
> 
> PC <- exp(someQuantile*t(pcdat[[2]])*sqrt(pcdat[[1]])*sd(Returns))   #
> somQuantile = 1.64 for a 95% CL
> 
> 
> As much as I looked around, people discuss the benefits of PC but not
> how to recombine the principal components at some confidence interval
> to get a shocked curve.
> 
> Could anyone help?
> 
> Thank you,
> Benji
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From benjifamel at gmail.com  Wed Feb 17 01:15:27 2010
From: benjifamel at gmail.com (Benji Famel)
Date: Tue, 16 Feb 2010 19:15:27 -0500
Subject: [R-SIG-Finance] PCA in Risk Control with R
In-Reply-To: <4B7B3022.4060907@braverock.com>
References: <b50d8da01002161534v3f87af73t2dfdef9dc048e765@mail.gmail.com>
	<4B7B3022.4060907@braverock.com>
Message-ID: <b50d8da01002161615q7ec3065bu8e308bf6c5883276@mail.gmail.com>

I like the idea, and I have attached a sample of data.  I think this
should work as the file is not a binary one.  The data represents
daily NYMEX data for Natural gas.
The columns are flat prices (not returns) and represent:
1. Date
2. Prompt contract
3. Back contract (2nd month out)
4. Far contract (3d month out)
5. etc.
After transferring the data to R through RExcel as MktData,  I execute
the following code:

MktReturns.d <- MktData

# ----------- Data Preparation  ------------------
for (i in 1:ncol(MktData) ) {
  MktReturns.d[,i] <- Fin.Calcs.logreturns(x=MktData[,i],  deltaT= 1, pad=T)
 }
MktReturns.d <- na.omit(MktReturns.d)

#PERFORM PCA ON DAILIES    (good for 1 day risk... if I wanted the
weekly risk, I would work with weekly returns)
pcdat.d <- princomp(MktReturns.d, cor=TRUE) 	# - It will use
correlation matrix so NO need to scale
the.summary.d <- summary(pcdat.d) 	# - It will print standard
deviation and proportion of variances for each component
the.loadings.d <- loadings(pcdat.d) 	# - it will give information how
much each variable contribute to each component.
the.scores.d <- pcdat.d$scores 		# - It will plot scores of each
observation for each variable
whichQuantile <- quantile(rnorm(1000000),probs=c(0.95))

PC <- exp(whichQuantile*t(pcdat.d[[2]])*sqrt(pcdat.d[[1]])*sd(MktReturns.d))
# note that if I wanted to work with daily returns but calculate the 1
week risk, I woudl be multiplying above with sqrt(5)

Hope this helps.

Benji

On Tue, Feb 16, 2010 at 6:54 PM, Brian G. Peterson <brian at braverock.com> wrote:
> Why don't you disguise a subset of your data and provide a working example?
>
> Both you and the list will get more out of it if we can all work on
> something that is actually executable in R, per the posting guide.
>
> Your problem is interesting and relevant, so put a little more effort into
> it, and I'm sure you'll get collaborators in working through it.
>
> Regards,
>
> ?- Brian
>
> Benji Famel wrote:
>>
>> Hello,
>>
>> my apologies if I do something wrong - first posting for me.
>>
>> I am trying to apply PCA on the daily history of a bunch of forward
>> curves and run into my depths of ignorance. ?I would appreciate some
>> help...
>>
>> My aim is to use PCA for risk control. ?I.e. estimate the
>> eigenverctors and eigenvalues and build the principal components at
>> some confidence level, e.g. 95%. ?If, for example, we were looking at
>> the first 3 components only, I would
>> - estimate PC1up, PC1dn, PC2up, PC2dn, PC3up and PC3dn.
>>
>> Let's assume that
>> - PC1up is worse for my position than PC1dn,
>> - PC2up is worse than PC2dn and
>> - PC3dn is worse than PC3up
>> I would then 'add' these worse for me components (PC1up, PC2up and
>> PC3dn) and run my position through them to get a measure of risk at
>> that confidence level.
>>
>> To do the PCA, I first foundthe log returns, let's call them Returns.
>> I then do:
>> pcdat <-princomp(Returns, cor=TRUE)
>> and calculate the principal components like this (this is where I am
>> very foggy...):
>>
>> PC <- exp(someQuantile*t(pcdat[[2]])*sqrt(pcdat[[1]])*sd(Returns)) ? #
>> somQuantile = 1.64 for a 95% CL
>>
>>
>> As much as I looked around, people discuss the benefits of PC but not
>> how to recombine the principal components at some confidence interval
>> to get a shocked curve.
>>
>> Could anyone help?
>>
>> Thank you,
>> Benji
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: NYMEX curves.csv
Type: application/octet-stream
Size: 376188 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100216/33a4c680/attachment.obj>

From cmdr_rogue at hotmail.com  Wed Feb 17 02:02:12 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Tue, 16 Feb 2010 20:02:12 -0500
Subject: [R-SIG-Finance] PCA in Risk Control with R
In-Reply-To: <b50d8da01002161615q7ec3065bu8e308bf6c5883276@mail.gmail.com>
References: <b50d8da01002161534v3f87af73t2dfdef9dc048e765@mail.gmail.com>
	<4B7B3022.4060907@braverock.com>
	<b50d8da01002161615q7ec3065bu8e308bf6c5883276@mail.gmail.com>
Message-ID: <BLU0-SMTP808896487582BFBBE0DE2CE2480@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100216/438e7214/attachment.pl>

From benjifamel at gmail.com  Wed Feb 17 02:26:47 2010
From: benjifamel at gmail.com (Benji Famel)
Date: Tue, 16 Feb 2010 20:26:47 -0500
Subject: [R-SIG-Finance] PCA in Risk Control with R
In-Reply-To: <BLU0-SMTP808896487582BFBBE0DE2CE2480@phx.gbl>
References: <b50d8da01002161534v3f87af73t2dfdef9dc048e765@mail.gmail.com>
	<4B7B3022.4060907@braverock.com>
	<b50d8da01002161615q7ec3065bu8e308bf6c5883276@mail.gmail.com>
	<BLU0-SMTP808896487582BFBBE0DE2CE2480@phx.gbl>
Message-ID: <808CF421-6C9D-4C7A-B06D-DC362495FA6D@gmail.com>


Sarbo,

Thank you. This answers how you rebuild the curve.

Now this may be a silly question but how do you shock the resulting  
curve to a given conf level?

Thanks again,

Benji.
Sent from my mobile device.

On Feb 16, 2010, at 8:02 PM, Sarbo <cmdr_rogue at hotmail.com> wrote:

> Hi Benji- you're in luck. I've done exactly this sort of thing in the
> past. Here is the code that I wrote to do the job:
>
> BuildPCACurves <- function(data, ncomps = 3){
>  if (class(data) != 'matrix'){A <- as.matrix(data)} else A <- data
>  M <- t(A) %*% A
>  eigens <- eigen(M)$vectors
>  eigens[,1] <- -eigens[,1]
>  selectors <- matrix(0, nrow = ncol(A), ncol = ncol(A))
>  diagentries <- c(rep(1, ncomps), rep(0, ncol(A) - ncomps))
>  diag(selectors) <- diagentries
>  coefficients <- A %*% eigens
>  newcurves <- coefficients %*% selectors %*% t(eigens)
>  coef2 <- apply(coefficients, 2, diff)
>  means <- apply(coef2, 2, mean)
>  stdevs <- apply(coef2, 2, sd)
>  RMSE <- sqrt(sum((apply(newcurves - A, 2, sum)) ^ 2))
>  output = list(original = A, rebuilt = newcurves, means =
> means[1:ncomps], stds = stdevs[1:ncomps], RMSE = RMSE)
>  return(output)
> }
>
> This doesn't use the actual "princomp" function in R, but it does
> exactly the same thing; it just uses the underlying matrix theory  
> behind
> PCA itself.
>
> On Tue, 2010-02-16 at 19:15 -0500, Benji Famel wrote:
>
>> I like the idea, and I have attached a sample of data.  I think this
>> should work as the file is not a binary one.  The data represents
>> daily NYMEX data for Natural gas.
>> The columns are flat prices (not returns) and represent:
>> 1. Date
>> 2. Prompt contract
>> 3. Back contract (2nd month out)
>> 4. Far contract (3d month out)
>> 5. etc.
>> After transferring the data to R through RExcel as MktData,  I  
>> execute
>> the following code:
>>
>> MktReturns.d <- MktData
>>
>> # ----------- Data Preparation  ------------------
>> for (i in 1:ncol(MktData) ) {
>>  MktReturns.d[,i] <- Fin.Calcs.logreturns(x=MktData[,i],  deltaT=  
>> 1, pad=T)
>> }
>> MktReturns.d <- na.omit(MktReturns.d)
>>
>> #PERFORM PCA ON DAILIES    (good for 1 day risk... if I wanted the
>> weekly risk, I would work with weekly returns)
>> pcdat.d <- princomp(MktReturns.d, cor=TRUE)    # - It will use
>> correlation matrix so NO need to scale
>> the.summary.d <- summary(pcdat.d)    # - It will print standard
>> deviation and proportion of variances for each component
>> the.loadings.d <- loadings(pcdat.d)    # - it will give information  
>> how
>> much each variable contribute to each component.
>> the.scores.d <- pcdat.d$scores        # - It will plot scores of each
>> observation for each variable
>> whichQuantile <- quantile(rnorm(1000000),probs=c(0.95))
>>
>> PC <- exp(whichQuantile*t(pcdat.d[[2]])*sqrt(pcdat.d[[1]])*sd 
>> (MktReturns.d))
>> # note that if I wanted to work with daily returns but calculate  
>> the 1
>> week risk, I woudl be multiplying above with sqrt(5)
>>
>> Hope this helps.
>>
>> Benji
>>
>> On Tue, Feb 16, 2010 at 6:54 PM, Brian G. Peterson <brian at braverock.com 
>> > wrote:
>>> Why don't you disguise a subset of your data and provide a working  
>>> example?
>>>
>>> Both you and the list will get more out of it if we can all work on
>>> something that is actually executable in R, per the posting guide.
>>>
>>> Your problem is interesting and relevant, so put a little more  
>>> effort into
>>> it, and I'm sure you'll get collaborators in working through it.
>>>
>>> Regards,
>>>
>>> - Brian
>>>
>>> Benji Famel wrote:
>>>>
>>>> Hello,
>>>>
>>>> my apologies if I do something wrong - first posting for me.
>>>>
>>>> I am trying to apply PCA on the daily history of a bunch of forward
>>>> curves and run into my depths of ignorance.  I would appreciate  
>>>> some
>>>> help...
>>>>
>>>> My aim is to use PCA for risk control.  I.e. estimate the
>>>> eigenverctors and eigenvalues and build the principal components at
>>>> some confidence level, e.g. 95%.  If, for example, we were  
>>>> looking at
>>>> the first 3 components only, I would
>>>> - estimate PC1up, PC1dn, PC2up, PC2dn, PC3up and PC3dn.
>>>>
>>>> Let's assume that
>>>> - PC1up is worse for my position than PC1dn,
>>>> - PC2up is worse than PC2dn and
>>>> - PC3dn is worse than PC3up
>>>> I would then 'add' these worse for me components (PC1up, PC2up and
>>>> PC3dn) and run my position through them to get a measure of risk at
>>>> that confidence level.
>>>>
>>>> To do the PCA, I first foundthe log returns, let's call them  
>>>> Returns.
>>>> I then do:
>>>> pcdat <-princomp(Returns, cor=TRUE)
>>>> and calculate the principal components like this (this is where I  
>>>> am
>>>> very foggy...):
>>>>
>>>> PC <- exp(someQuantile*t(pcdat[[2]])*sqrt(pcdat[[1]])*sd 
>>>> (Returns))   #
>>>> somQuantile = 1.64 for a 95% CL
>>>>
>>>>
>>>> As much as I looked around, people discuss the benefits of PC but  
>>>> not
>>>> how to recombine the principal components at some confidence  
>>>> interval
>>>> to get a shocked curve.
>>>>
>>>> Could anyone help?
>>>>
>>>> Thank you,
>>>> Benji
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R  
>>>> questions
>>>> should go.
>>>
>>>
>>> --
>>> Brian G. Peterson
>>> http://braverock.com/brian/
>>> Ph: 773-459-4973
>>> IM: bgpbraverock
>>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R  
>> questions should go.
>
>
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R  
> questions should go.


From j_cuisinier at hotmail.com  Wed Feb 17 09:38:25 2010
From: j_cuisinier at hotmail.com (julien cuisinier)
Date: Wed, 17 Feb 2010 09:38:25 +0100
Subject: [R-SIG-Finance] PCA in Risk Control with R
In-Reply-To: <808CF421-6C9D-4C7A-B06D-DC362495FA6D@gmail.com>
References: <b50d8da01002161534v3f87af73t2dfdef9dc048e765@mail.gmail.com>,
	<4B7B3022.4060907@braverock.com>,
	<b50d8da01002161615q7ec3065bu8e308bf6c5883276@mail.gmail.com>,
	<BLU0-SMTP808896487582BFBBE0DE2CE2480@phx.gbl>,
	<808CF421-6C9D-4C7A-B06D-DC362495FA6D@gmail.com>
Message-ID: <COL102-W58C19D322EC070F58ACFA28F480@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100217/6601eb3c/attachment.pl>

From christopher.masters at gmail.com  Wed Feb 17 10:38:35 2010
From: christopher.masters at gmail.com (Chris Masters)
Date: Wed, 17 Feb 2010 09:38:35 +0000
Subject: [R-SIG-Finance] rnorm.sobol problems (from fOptions)
Message-ID: <c1f3afcb1002170138q1650e41ek4112f34d78cde621@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100217/e6659389/attachment.pl>

From martin.becker at mx.uni-saarland.de  Wed Feb 17 10:54:05 2010
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Wed, 17 Feb 2010 10:54:05 +0100
Subject: [R-SIG-Finance] rnorm.sobol problems (from fOptions)
In-Reply-To: <c1f3afcb1002170138q1650e41ek4112f34d78cde621@mail.gmail.com>
References: <c1f3afcb1002170138q1650e41ek4112f34d78cde621@mail.gmail.com>
Message-ID: <4B7BBCBD.7010805@mx.uni-saarland.de>

Chris,

although rnorm.sobol should not cause a segfault, you should not expect 
it to work for dimensions greater than 1111, as 1111 is the (documented, 
see ?rnorm.sobol) maximal dimension for rnorm.sobol.
Regards,
  Martin


Chris Masters wrote:
> Hi
>
> I'm having issues calling rnorm.sobol in the fOptions package. Is this a
> known issue? (with a lower dimension it works fine)
>
> ---
>
> R version 2.10.1 (2009-12-14)
> Copyright (C) 2009 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>   Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>   
>> library(fOptions)
>>     
> Loading required package: timeDate
> Loading required package: timeSeries
> Loading required package: fBasics
> Loading required package: MASS
> Rmetrics Package fOptions (2100.76) loaded.
>   
>> rnorm.sobol(30,1500)
>>     
>
>  *** caught segfault ***
> address 0x7f3867c487a8, cause 'invalid permissions'
>
> Traceback:
>  1: .Fortran("sobol", as.double(qn), as.integer(n),
> as.integer(dimension),
> as.double(.getfOptionsEnv(".rnorm.sobol.seed")$quasi),
> as.integer(.getfOptionsEnv(".rnorm.sobol.seed")$ll),
> as.integer(.getfOptionsEnv(".rnorm.sobol.seed")$count),
> as.integer(.getfOptionsEnv(".rnorm.sobol.seed")$sv),
> as.integer(scrambling),
> as.integer(.getfOptionsEnv(".rnorm.sobol.seed")$seed),     as.integer(init),
> as.integer(1), PACKAGE = "fOptions")
>  2: rnorm.sobol(30, 1500)
>
>
> ---
>
>
> Thanks
>
> Chris
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>   


-- 
Dr. Martin Becker
Statistics and Econometrics
Saarland University
Campus C3 1, Room 206
66123 Saarbruecken
Germany


From benjifamel at gmail.com  Wed Feb 17 13:34:22 2010
From: benjifamel at gmail.com (Benji Famel)
Date: Wed, 17 Feb 2010 07:34:22 -0500
Subject: [R-SIG-Finance] PCA in Risk Control with R
In-Reply-To: <COL102-W58C19D322EC070F58ACFA28F480@phx.gbl>
References: <b50d8da01002161534v3f87af73t2dfdef9dc048e765@mail.gmail.com>
	<4B7B3022.4060907@braverock.com>
	<b50d8da01002161615q7ec3065bu8e308bf6c5883276@mail.gmail.com>
	<BLU0-SMTP808896487582BFBBE0DE2CE2480@phx.gbl>
	<808CF421-6C9D-4C7A-B06D-DC362495FA6D@gmail.com>
	<COL102-W58C19D322EC070F58ACFA28F480@phx.gbl>
Message-ID: <b50d8da01002170434l9f34432r942f8c6481fb4420@mail.gmail.com>

hello Julien,

Thank you for your response.  I get Point 1.

On point 2, stating your comment in another way (to make sure I
understand it): since we do not have a distribution of the normal
modes, no scale factor exists by which to shock them.

Here is my thinking:
1. Work with returns
2 .Calculate the sigma of these returns (assuming a normal for ease)
3. Scale by sigma (which explains why it appears as a mult factor in step 5)
4. Calculate the normal modes
5. Return to original coordinate system by  (this might be somewhat
incorrect but, if not, then it provides a way to stress at a given
confidence level):
 PCA| i,m = exp( FI(0.995) * N|i,m * S|m * SQRT(L|i) )

i = i-th Principal component
m = forward month
FI = inv normal at a CL
N|i,m = eigenvectors
S|mm = std dev
L|i = eigenvalue

So my way of stressing is scaling up that S by the "2.57" (the
FI(0.995)).  Is this wrong?  Am I missing something?

Benji


On Wed, Feb 17, 2010 at 3:38 AM, julien cuisinier
<j_cuisinier at hotmail.com> wrote:
> Hi Benji,
>
>
> Welcome to the list & good luck with the posting guide ;-)
>
> I am not a PCA expert, but in my opinion there are 2 items in your question:
>
> 1. run PCA on original data set, choose relevant factors/components, do
> something with these factors, back to "original" data set. check
> http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf
> there is a small description of getting back to old axis system
>
> 2. Do something to the factors (risk focus): it seems you do factor push
> stress testing (i.e. each pushing factor right/left by an arbitrary amount,
> pick the side hurting the port the most, repeat this for each factors and
> apply each factor "worst" move to the portfolio. I therefore do not see
> where/why the last computation comes in (trying to get a risk measure at a
> certain confidence level). The components moves are arbitrary and the risk
> measure resulting on the portfolio level will also be, no probabilities
> associated hence no confidence level.
>
> One can decide to model each component with a parametric distribution then
> derive what risk measure is relevant - the big advatages of PCA being that
> you do not have to care about components comovement, as long as the
> assumption of linearity is acceptable. But this is simply another approach,
> not something on top of the factor push you are trying
>
>
> Hope this helps
>
>
> Rgds,
> Julien
>
> PS: the "parametric approach" used in your first post on top of the factor
> push stuff seems to use simple normal distrib VaR, if you go that route I
> would probably start by trying to model volatility clustering (GARCH)
> instead of relying on simple historical estimates...hope I understood your
> post well, I do not mean to lecture you of course...
>
>> From: benjifamel at gmail.com
>> To: cmdr_rogue at hotmail.com
>> Date: Tue, 16 Feb 2010 20:26:47 -0500
>> CC: r-sig-finance at stat.math.ethz.ch
>> Subject: Re: [R-SIG-Finance] PCA in Risk Control with R
>>
>>
>> Sarbo,
>>
>> Thank you. This answers how you rebuild the curve.
>>
>> Now this may be a silly question but how do you shock the resulting
>> curve to a given conf level?
>>
>> Thanks again,
>>
>> Benji.
>> Sent from my mobile device.
>>
>> On Feb 16, 2010, at 8:02 PM, Sarbo <cmdr_rogue at hotmail.com> wrote:
>>
>> > Hi Benji- you're in luck. I've done exactly this sort of thing in the
>> > past. Here is the code that I wrote to do the job:
>> >
>> > BuildPCACurves <- function(data, ncomps = 3){
>> > if (class(data) != 'matrix'){A <- as.matrix(data)} else A <- data
>> > M <- t(A) %*% A
>> > eigens <- eigen(M)$vectors
>> > eigens[,1] <- -eigens[,1]
>> > selectors <- matrix(0, nrow = ncol(A), ncol = ncol(A))
>> > diagentries <- c(rep(1, ncomps), rep(0, ncol(A) - ncomps))
>> > diag(selectors) <- diagentries
>> > coefficients <- A %*% eigens
>> > newcurves <- coefficients %*% selectors %*% t(eigens)
>> > coef2 <- apply(coefficients, 2, diff)
>> > means <- apply(coef2, 2, mean)
>> > stdevs <- apply(coef2, 2, sd)
>> > RMSE <- sqrt(sum((apply(newcurves - A, 2, sum)) ^ 2))
>> > output = list(original = A, rebuilt = newcurves, means =
>> > means[1:ncomps], stds = stdevs[1:ncomps], RMSE = RMSE)
>> > return(output)
>> > }
>> >
>> > This doesn't use the actual "princomp" function in R, but it does
>> > exactly the same thing; it just uses the underlying matrix theory
>> > behind
>> > PCA itself.
>> >
>> > On Tue, 2010-02-16 at 19:15 -0500, Benji Famel wrote:
>> >
>> >> I like the idea, and I have attached a sample of data. I think this
>> >> should work as the file is not a binary one. The data represents
>> >> daily NYMEX data for Natural gas.
>> >> The columns are flat prices (not returns) and represent:
>> >> 1. Date
>> >> 2. Prompt contract
>> >> 3. Back contract (2nd month out)
>> >> 4. Far contract (3d month out)
>> >> 5. etc.
>> >> After transferring the data to R through RExcel as MktData, I
>> >> execute
>> >> the following code:
>> >>
>> >> MktReturns.d <- MktData
>> >>
>> >> # ----------- Data Preparation ------------------
>> >> for (i in 1:ncol(MktData) ) {
>> >> MktReturns.d[,i] <- Fin.Calcs.logreturns(x=MktData[,i], deltaT=
>> >> 1, pad=T)
>> >> }
>> >> MktReturns.d <- na.omit(MktReturns.d)
>> >>
>> >> #PERFORM PCA ON DAILIES (good for 1 day risk... if I wanted the
>> >> weekly risk, I would work with weekly returns)
>> >> pcdat.d <- princomp(MktReturns.d, cor=TRUE) # - It will use
>> >> correlation matrix so NO need to scale
>> >> the.summary.d <- summary(pcdat.d) # - It will print standard
>> >> deviation and proportion of variances for each component
>> >> the.loadings.d <- loadings(pcdat.d) # - it will give information
>> >> how
>> >> much each variable contribute to each component.
>> >> the.scores.d <- pcdat.d$scores # - It will plot scores of each
>> >> observation for each variable
>> >> whichQuantile <- quantile(rnorm(1000000),probs=c(0.95))
>> >>
>> >> PC <- exp(whichQuantile*t(pcdat.d[[2]])*sqrt(pcdat.d[[1]])*sd
>> >> (MktReturns.d))
>> >> # note that if I wanted to work with daily returns but calculate
>> >> the 1
>> >> week risk, I woudl be multiplying above with sqrt(5)
>> >>
>> >> Hope this helps.
>> >>
>> >> Benji
>> >>
>> >> On Tue, Feb 16, 2010 at 6:54 PM, Brian G. Peterson <brian at braverock.com
>> >> > wrote:
>> >>> Why don't you disguise a subset of your data and provide a working
>> >>> example?
>> >>>
>> >>> Both you and the list will get more out of it if we can all work on
>> >>> something that is actually executable in R, per the posting guide.
>> >>>
>> >>> Your problem is interesting and relevant, so put a little more
>> >>> effort into
>> >>> it, and I'm sure you'll get collaborators in working through it.
>> >>>
>> >>> Regards,
>> >>>
>> >>> - Brian
>> >>>
>> >>> Benji Famel wrote:
>> >>>>
>> >>>> Hello,
>> >>>>
>> >>>> my apologies if I do something wrong - first posting for me.
>> >>>>
>> >>>> I am trying to apply PCA on the daily history of a bunch of forward
>> >>>> curves and run into my depths of ignorance. I would appreciate
>> >>>> some
>> >>>> help...
>> >>>>
>> >>>> My aim is to use PCA for risk control. I.e. estimate the
>> >>>> eigenverctors and eigenvalues and build the principal components at
>> >>>> some confidence level, e.g. 95%. If, for example, we were
>> >>>> looking at
>> >>>> the first 3 components only, I would
>> >>>> - estimate PC1up, PC1dn, PC2up, PC2dn, PC3up and PC3dn.
>> >>>>
>> >>>> Let's assume that
>> >>>> - PC1up is worse for my position than PC1dn,
>> >>>> - PC2up is worse than PC2dn and
>> >>>> - PC3dn is worse than PC3up
>> >>>> I would then 'add' these worse for me components (PC1up, PC2up and
>> >>>> PC3dn) and run my position through them to get a measure of risk at
>> >>>> that confidence level.
>> >>>>
>> >>>> To do the PCA, I first foundthe log returns, let's call them
>> >>>> Returns.
>> >>>> I then do:
>> >>>> pcdat <-princomp(Returns, cor=TRUE)
>> >>>> and calculate the principal components like this (this is where I
>> >>>> am
>> >>>> very foggy...):
>> >>>>
>> >>>> PC <- exp(someQuantile*t(pcdat[[2]])*sqrt(pcdat[[1]])*sd
>> >>>> (Returns)) #
>> >>>> somQuantile = 1.64 for a 95% CL
>> >>>>
>> >>>>
>> >>>> As much as I looked around, people discuss the benefits of PC but
>> >>>> not
>> >>>> how to recombine the principal components at some confidence
>> >>>> interval
>> >>>> to get a shocked curve.
>> >>>>
>> >>>> Could anyone help?
>> >>>>
>> >>>> Thank you,
>> >>>> Benji
>> >>>>
>> >>>> _______________________________________________
>> >>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >>>> -- Subscriber-posting only. If you want to post, subscribe first.
>> >>>> -- Also note that this is not the r-help list where general R
>> >>>> questions
>> >>>> should go.
>> >>>
>> >>>
>> >>> --
>> >>> Brian G. Peterson
>> >>> http://braverock.com/brian/
>> >>> Ph: 773-459-4973
>> >>> IM: bgpbraverock
>> >>>
>> >> _______________________________________________
>> >> R-SIG-Finance at stat.math.ethz.ch mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >> -- Subscriber-posting only. If you want to post, subscribe first.
>> >> -- Also note that this is not the r-help list where general R
>> >> questions should go.
>> >
>> >
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only. If you want to post, subscribe first.
>> > -- Also note that this is not the r-help list where general R
>> > questions should go.
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
> ________________________________
> Hotmail: Leistungsstarke kostenlose E-Mails mit Sicherheit von Microsoft.
> Jetzt herunterladen.


From arnaudb25 at gmail.com  Wed Feb 17 18:36:42 2010
From: arnaudb25 at gmail.com (Arnaud Battistella)
Date: Wed, 17 Feb 2010 18:36:42 +0100
Subject: [R-SIG-Finance] adf.test.help
Message-ID: <3f1cfd831002170936j70769e51y9d3264a2af7af0f0@mail.gmail.com>

Hi,

I am trying to test whether a return series is stationary, but before
proceeding I wanted to make sure I understand correctly how to use the
adf.test function and interpret its output... Could you please let me
know whether I am correct in my interpretations?

ex: I take x such as I know it doesn't have a unit root, and is
therefore stationary

1/
> x <- rnorm(1000)
> adf.test(x, "stationary", k=0)

Augmented Dickey-Fuller Test

data: x
Dickey-Fuller = -31.8629, Lag order = 0, p-value = 0.01
alternative hypothesis: stationary

Warning message:
In adf.test(x, "stationary", k = 0) : p-value smaller than printed p-value

If I understand correctly, I am told that the probability of x having
a unit root and therefore being non-stationary is 0.01, so the test
tells me that there is a very high probability that x is stationary.
Then I can conclude that x is mean-reverting. Am I correct?

2/ I would like to see critical values also, so I tried with ur.df

> summary(ur.df(x, "trend", lag=0))

<snip>

Value of test-statistic is: -31.8629 338.4156 507.6231

Critical values for test statistics:
1pct 5pct 10pct
tau3 -3.96 -3.41 -3.12
phi2 6.09 4.68 4.03
phi3 8.27 6.25 5.34

Here if I understand correctly, as my first critical value is
significantly less than the 1% critical value I reject the null
hypothesis that x has a unit root, so x is stationary and then mean
reverting.

Thanks,

-Arnaud


From matthieu.stigler at gmail.com  Wed Feb 17 19:10:19 2010
From: matthieu.stigler at gmail.com (mat)
Date: Wed, 17 Feb 2010 19:10:19 +0100
Subject: [R-SIG-Finance] adf.test.help
In-Reply-To: <3f1cfd831002170936j70769e51y9d3264a2af7af0f0@mail.gmail.com>
References: <3f1cfd831002170936j70769e51y9d3264a2af7af0f0@mail.gmail.com>
Message-ID: <4B7C310B.8030301@gmail.com>

Arnaud Battistella a ?crit :
> Hi,
>
> I am trying to test whether a return series is stationary, but before
> proceeding I wanted to make sure I understand correctly how to use the
> adf.test function and interpret its output... Could you please let me
> know whether I am correct in my interpretations?
>
> ex: I take x such as I know it doesn't have a unit root, and is
> therefore stationary
>
> 1/
>   
>> x <- rnorm(1000)
>> adf.test(x, "stationary", k=0)
>>     
>
> Augmented Dickey-Fuller Test
>
> data: x
> Dickey-Fuller = -31.8629, Lag order = 0, p-value = 0.01
> alternative hypothesis: stationary
>
> Warning message:
> In adf.test(x, "stationary", k = 0) : p-value smaller than printed p-value
>
> If I understand correctly, I am told that the probability of x having
> a unit root and therefore being non-stationary is 0.01, so the test
> tells me that there is a very high probability that x is stationary.
> Then I can conclude that x is mean-reverting. Am I correct?
>
>   
yes
> 2/ I would like to see critical values also, so I tried with ur.df
>
>   
>> summary(ur.df(x, "trend", lag=0))
>>     
>
> <snip>
>
> Value of test-statistic is: -31.8629 338.4156 507.6231
>
> Critical values for test statistics:
> 1pct 5pct 10pct
> tau3 -3.96 -3.41 -3.12
> phi2 6.09 4.68 4.03
> phi3 8.27 6.25 5.34
>
> Here if I understand correctly, as my first critical value is
> significantly less than the 1% critical value I reject the null
> hypothesis that x has a unit root, so x is stationary and then mean
> reverting.
>
>   
yes


> Thanks,
>
> -Arnaud
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From arnaudb25 at gmail.com  Wed Feb 17 19:16:40 2010
From: arnaudb25 at gmail.com (Arnaud Battistella)
Date: Wed, 17 Feb 2010 19:16:40 +0100
Subject: [R-SIG-Finance] adf.test.help
In-Reply-To: <4B7C310B.8030301@gmail.com>
References: <3f1cfd831002170936j70769e51y9d3264a2af7af0f0@mail.gmail.com>
	<4B7C310B.8030301@gmail.com>
Message-ID: <3f1cfd831002171016k72242db1je3c7696fb0df1048@mail.gmail.com>

Thanks, so do you confirm that a stationary series is *always* mean-reverting?

-Arnaud


On Wed, Feb 17, 2010 at 7:10 PM, mat <matthieu.stigler at gmail.com> wrote:
> Arnaud Battistella a ?crit :
>>
>> Hi,
>>
>> I am trying to test whether a return series is stationary, but before
>> proceeding I wanted to make sure I understand correctly how to use the
>> adf.test function and interpret its output... Could you please let me
>> know whether I am correct in my interpretations?
>>
>> ex: I take x such as I know it doesn't have a unit root, and is
>> therefore stationary
>>
>> 1/
>>
>>>
>>> x <- rnorm(1000)
>>> adf.test(x, "stationary", k=0)
>>>
>>
>> Augmented Dickey-Fuller Test
>>
>> data: x
>> Dickey-Fuller = -31.8629, Lag order = 0, p-value = 0.01
>> alternative hypothesis: stationary
>>
>> Warning message:
>> In adf.test(x, "stationary", k = 0) : p-value smaller than printed p-value
>>
>> If I understand correctly, I am told that the probability of x having
>> a unit root and therefore being non-stationary is 0.01, so the test
>> tells me that there is a very high probability that x is stationary.
>> Then I can conclude that x is mean-reverting. Am I correct?
>>
>>
>
> yes
>>
>> 2/ I would like to see critical values also, so I tried with ur.df
>>
>>
>>>
>>> summary(ur.df(x, "trend", lag=0))
>>>
>>
>> <snip>
>>
>> Value of test-statistic is: -31.8629 338.4156 507.6231
>>
>> Critical values for test statistics:
>> 1pct 5pct 10pct
>> tau3 -3.96 -3.41 -3.12
>> phi2 6.09 4.68 4.03
>> phi3 8.27 6.25 5.34
>>
>> Here if I understand correctly, as my first critical value is
>> significantly less than the 1% critical value I reject the null
>> hypothesis that x has a unit root, so x is stationary and then mean
>> reverting.
>>
>>
>
> yes
>
>
>> Thanks,
>>
>> -Arnaud
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>


From matthieu.stigler at gmail.com  Wed Feb 17 19:45:16 2010
From: matthieu.stigler at gmail.com (mat)
Date: Wed, 17 Feb 2010 19:45:16 +0100
Subject: [R-SIG-Finance] adf.test.help
In-Reply-To: <3f1cfd831002171016k72242db1je3c7696fb0df1048@mail.gmail.com>
References: <3f1cfd831002170936j70769e51y9d3264a2af7af0f0@mail.gmail.com>	
	<4B7C310B.8030301@gmail.com>
	<3f1cfd831002171016k72242db1je3c7696fb0df1048@mail.gmail.com>
Message-ID: <4B7C393C.5090805@gmail.com>

Well I would say yes, but I'm sure you can find some paper where the 
authour finds a process that is stationary but not mean-reverting....

Weak stationarity is defined as the existence of (asymptotically) 
time-invariant expectation and auto-covariance, so this will generally 
mean your process will be mean reverting.

At least an AR(q) process that has roots lying outside the unit circle 
is mean reverting, and this is what you are estimating.

Hope this helps, and hope I'm not too wrong...

Mat
Arnaud Battistella a ?crit :
> Thanks, so do you confirm that a stationary series is *always* mean-reverting?
>
> -Arnaud
>
>
> On Wed, Feb 17, 2010 at 7:10 PM, mat <matthieu.stigler at gmail.com> wrote:
>   
>> Arnaud Battistella a ?crit :
>>     
>>> Hi,
>>>
>>> I am trying to test whether a return series is stationary, but before
>>> proceeding I wanted to make sure I understand correctly how to use the
>>> adf.test function and interpret its output... Could you please let me
>>> know whether I am correct in my interpretations?
>>>
>>> ex: I take x such as I know it doesn't have a unit root, and is
>>> therefore stationary
>>>
>>> 1/
>>>
>>>       
>>>> x <- rnorm(1000)
>>>> adf.test(x, "stationary", k=0)
>>>>
>>>>         
>>> Augmented Dickey-Fuller Test
>>>
>>> data: x
>>> Dickey-Fuller = -31.8629, Lag order = 0, p-value = 0.01
>>> alternative hypothesis: stationary
>>>
>>> Warning message:
>>> In adf.test(x, "stationary", k = 0) : p-value smaller than printed p-value
>>>
>>> If I understand correctly, I am told that the probability of x having
>>> a unit root and therefore being non-stationary is 0.01, so the test
>>> tells me that there is a very high probability that x is stationary.
>>> Then I can conclude that x is mean-reverting. Am I correct?
>>>
>>>
>>>       
>> yes
>>     
>>> 2/ I would like to see critical values also, so I tried with ur.df
>>>
>>>
>>>       
>>>> summary(ur.df(x, "trend", lag=0))
>>>>
>>>>         
>>> <snip>
>>>
>>> Value of test-statistic is: -31.8629 338.4156 507.6231
>>>
>>> Critical values for test statistics:
>>> 1pct 5pct 10pct
>>> tau3 -3.96 -3.41 -3.12
>>> phi2 6.09 4.68 4.03
>>> phi3 8.27 6.25 5.34
>>>
>>> Here if I understand correctly, as my first critical value is
>>> significantly less than the 1% critical value I reject the null
>>> hypothesis that x has a unit root, so x is stationary and then mean
>>> reverting.
>>>
>>>
>>>       
>> yes
>>
>>
>>     
>>> Thanks,
>>>
>>> -Arnaud
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>>
>>>       
>>


From arnaudb25 at gmail.com  Wed Feb 17 20:11:25 2010
From: arnaudb25 at gmail.com (Arnaud Battistella)
Date: Wed, 17 Feb 2010 20:11:25 +0100
Subject: [R-SIG-Finance] adf.test.help
In-Reply-To: <1612949140.289277.1266432935503.JavaMail.root@vms231.mailsrvcs.net>
References: <1612949140.289277.1266432935503.JavaMail.root@vms231.mailsrvcs.net>
Message-ID: <3f1cfd831002171111w7d920100tc8140d8da2d02563@mail.gmail.com>

Mark, indeed, the series you gave me doesn't have a unit root
(adf.test confirms this) but is clearly not mean reverting. I assume
we cannot say that this series is stationary, or maybe on restricted
segments... How would you test such series?
Matthieu, thanks a lot for this explanation, that makes things clearer
to me, I just wanted to make sure I was not overlooking something that
could pose me problems later on.

Arnaud


On Wed, Feb 17, 2010 at 7:55 PM,  <markleeds at verizon.net> wrote:
> Thanks Matthieu: I agree with you but his series is actually normal with
> E(X) = 0 and rho_i = 0 for all i so it is mean reverting but
> not even reverting.in the sense of being dependent on itdself.? It's just
> there at zero all the time.
>
> I think the series I asked him to construct is a dumb example but it is one
> of those series that doesn't have a unit root and is not mean reverting. So,
> I think it's just an issue of terminology because usually when these terms
> are being used, they are used in the context? series is dependent on
> previous values of itself. In Arnaud's case, this wasn't the case. Thanks
> for your explanation.
>
> Arnaud: If you want to say that a series that doesn't have a unit root? is
> stationary, I guess it's okay because the use of the terms
> can be tricky. I'm sorry if I was being too picky.
>
>
>
>
>
>
> On Feb 17, 2010, mat <matthieu.stigler at gmail.com> wrote:
>
> Well I would say yes, but I'm sure you can find some paper where the
> authour finds a process that is stationary but not mean-reverting....
>
> Weak stationarity is defined as the existence of (asymptotically)
> time-invariant expectation and auto-covariance, so this will generally
> mean your process will be mean reverting.
>
> At least an AR(q) process that has roots lying outside the unit circle
> is mean reverting, and this is what you are estimating.
>
> Hope this helps, and hope I'm not too wrong...
>
> Mat
> Arnaud Battistella a ?crit :
>> Thanks, so do you confirm that a stationary series is *always*
>> mean-reverting?
>>
>> -Arnaud
>>
>>
>> On Wed, Feb 17, 2010 at 7:10 PM, mat <matthieu.stigler at gmail.com> wrote:
>>
>>> Arnaud Battistella a ?crit :
>>>
>>>> Hi,
>>>>
>>>> I am trying to test whether a return series is stationary, but before
>>>> proceeding I wanted to make sure I understand correctly how to use the
>>>> adf.test function and interpret its output... Could you please let me
>>>> know whether I am correct in my interpretations?
>>>>
>>>> ex: I take x such as I know it doesn't have a unit root, and is
>>>> therefore stationary
>>>>
>>>> 1/
>>>>
>>>>
>>>>> x <- rnorm(1000)
>>>>> adf.test(x, "stationary", k=0)
>>>>>
>>>>>
>>>> Augmented Dickey-Fuller Test
>>>>
>>>> data: x
>>>> Dickey-Fuller = -31.8629, Lag order = 0, p-value = 0.01
>>>> alternative hypothesis: stationary
>>>>
>>>> Warning message:
>>>> In adf.test(x, "stationary", k = 0) : p-value smaller than printed
>>>> p-value
>>>>
>>>> If I understand correctly, I am told that the probability of x having
>>>> a unit root and therefore being non-stationary is 0.01, so the test
>>>> tells me that there is a very high probability that x is stationary.
>>>> Then I can conclude that x is mean-reverting. Am I correct?
>>>>
>>>>
>>>>
>>> yes
>>>
>>>> 2/ I would like to see critical values also, so I tried with ur.df
>>>>
>>>>
>>>>
>>>>> summary(ur.df(x, "trend", lag=0))
>>>>>
>>>>>
>>>> <snip>
>>>>
>>>> Value of test-statistic is: -31.8629 338.4156 507.6231
>>>>
>>>> Critical values for test statistics:
>>>> 1pct 5pct 10pct
>>>> tau3 -3.96 -3.41 -3.12
>>>> phi2 6.09 4.68 4.03
>>>> phi3 8.27 6.25 5.34
>>>>
>>>> Here if I understand correctly, as my first critical value is
>>>> significantly less than the 1% critical value I reject the null
>>>> hypothesis that x has a unit root, so x is stationary and then mean
>>>> reverting.
>>>>
>>>>
>>>>
>>> yes
>>>
>>>
>>>
>>>> Thanks,
>>>>
>>>> -Arnaud
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions
>>>> should go.
>>>>
>>>>
>>>
>
>


From dutangc at gmail.com  Wed Feb 17 20:43:58 2010
From: dutangc at gmail.com (Christophe Dutang)
Date: Wed, 17 Feb 2010 20:43:58 +0100
Subject: [R-SIG-Finance] rnorm.sobol problems (from fOptions)
In-Reply-To: <4B7BBCBD.7010805@mx.uni-saarland.de>
References: <c1f3afcb1002170138q1650e41ek4112f34d78cde621@mail.gmail.com>
	<4B7BBCBD.7010805@mx.uni-saarland.de>
Message-ID: <45A4897D-3D5C-4726-84EB-155CE8159D34@gmail.com>

Chris, 

By the way, sobol and halton sequences have been transfered from fBasics to the randtoolbox package. You can download it on CRAN: http://cran.r-project.org/web/packages/randtoolbox/ .

Christophe

Le 17 f?vr. 2010 ? 10:54, Martin Becker a ?crit :

> Chris,
> 
> although rnorm.sobol should not cause a segfault, you should not expect it to work for dimensions greater than 1111, as 1111 is the (documented, see ?rnorm.sobol) maximal dimension for rnorm.sobol.
> Regards,
> Martin
> 
> 
> Chris Masters wrote:
>> Hi
>> 
>> I'm having issues calling rnorm.sobol in the fOptions package. Is this a
>> known issue? (with a lower dimension it works fine)
>> 
>> ---
>> 
>> R version 2.10.1 (2009-12-14)
>> Copyright (C) 2009 The R Foundation for Statistical Computing
>> ISBN 3-900051-07-0
>> 
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>> 
>>  Natural language support but running in an English locale
>> 
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>> 
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>> 
>>  
>>> library(fOptions)
>>>    
>> Loading required package: timeDate
>> Loading required package: timeSeries
>> Loading required package: fBasics
>> Loading required package: MASS
>> Rmetrics Package fOptions (2100.76) loaded.
>>  
>>> rnorm.sobol(30,1500)
>>>    
>> 
>> *** caught segfault ***
>> address 0x7f3867c487a8, cause 'invalid permissions'
>> 
>> Traceback:
>> 1: .Fortran("sobol", as.double(qn), as.integer(n),
>> as.integer(dimension),
>> as.double(.getfOptionsEnv(".rnorm.sobol.seed")$quasi),
>> as.integer(.getfOptionsEnv(".rnorm.sobol.seed")$ll),
>> as.integer(.getfOptionsEnv(".rnorm.sobol.seed")$count),
>> as.integer(.getfOptionsEnv(".rnorm.sobol.seed")$sv),
>> as.integer(scrambling),
>> as.integer(.getfOptionsEnv(".rnorm.sobol.seed")$seed),     as.integer(init),
>> as.integer(1), PACKAGE = "fOptions")
>> 2: rnorm.sobol(30, 1500)
>> 
>> 
>> ---
>> 
>> 
>> Thanks
>> 
>> Chris
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>>  
> 
> 
> -- 
> Dr. Martin Becker
> Statistics and Econometrics
> Saarland University
> Campus C3 1, Room 206
> 66123 Saarbruecken
> Germany
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

--
Christophe Dutang
Ph.D. student at ISFA, Lyon, France
website: http://dutangc.free.fr


From bogaso.christofer at gmail.com  Thu Feb 18 11:32:07 2010
From: bogaso.christofer at gmail.com (Bogaso)
Date: Thu, 18 Feb 2010 02:32:07 -0800 (PST)
Subject: [R-SIG-Finance] [R-sig-finance] Commodity swap?
In-Reply-To: <EDC8FC938727462DABDB7DC53E8CBC16@HPR>
References: <1266489127279-929176.post@n4.nabble.com>
	<1266489127280-929177.post@n4.nabble.com>
	<EDC8FC938727462DABDB7DC53E8CBC16@HPR>
Message-ID: <1266489127278-1559917.post@n4.nabble.com>


unlike most interest rate swaps explained in common risk management book, I
found that in most of the exchanges like IPE etc, cash flow is generally
happen daily (where for interest rate case it is mostly monthly or quarterly
etc) and all of the case underlying is some futures contracts. 

In ordinary ineterst rate case future expectation is generally replaced by
the futures quote. Therefore my question is, if swap is based on futures
itself then how can I get unbaised expected value as proxy?

Or should I treat this kind of swap contract just like a Basis wherein Basis
= (tomorrow's future quote - fixed) and try to understand the tomorrow's
possible distribution that future quote and hence the VaR just the same way
as Delta-normal approach?

What I mean is that :

VaR in this approach :

5th worst of (Basis[t+1] - Basis[t]) = (Futures[t+1] - Futures[t]), as other
leg is fixed and therefore no risk is there.

Is it the currect? Then how should I incorporate term structure which is
generally the case for interest rate swap?

If somebody can give some view, it would be great. 

Thanks,
-- 
View this message in context: http://n4.nabble.com/Commodity-swap-tp929176p1559917.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Thu Feb 18 12:13:11 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 18 Feb 2010 05:13:11 -0600
Subject: [R-SIG-Finance] [R-sig-finance] Commodity swap?
In-Reply-To: <1266489127278-1559917.post@n4.nabble.com>
References: <1266489127279-929176.post@n4.nabble.com>	<1266489127280-929177.post@n4.nabble.com>	<EDC8FC938727462DABDB7DC53E8CBC16@HPR>
	<1266489127278-1559917.post@n4.nabble.com>
Message-ID: <4B7D20C7.3040001@braverock.com>

Bogaso wrote:
> unlike most interest rate swaps explained in common risk management book, I
> found that in most of the exchanges like IPE etc, cash flow is generally
> happen daily (where for interest rate case it is mostly monthly or quarterly
> etc) and all of the case underlying is some futures contracts. 
> 
> In ordinary interest rate case future expectation is generally replaced by
> the futures quote. Therefore my question is, if swap is based on futures
> itself then how can I get unbiased expected value as proxy?
> 
> Or should I treat this kind of swap contract just like a Basis wherein Basis
> = (tomorrow's future quote - fixed) and try to understand the tomorrow's
> possible distribution that future quote and hence the VaR just the same way
> as Delta-normal approach?
> 
> What I mean is that :
> 
> VaR in this approach :
> 
> 5th worst of (Basis[t+1] - Basis[t]) = (Futures[t+1] - Futures[t]), as other
> leg is fixed and therefore no risk is there.
> 
> Is it the correct? Then how should I incorporate term structure which is
> generally the case for interest rate swap?
> 
> If somebody can give some view, it would be great. 

Christofer,

Every swap contract is different, and you didn't actually tell us what contract 
you're looking at.  So replies will of necessity be somewhat more general than 
your general questions...

Considering a futures contract to be an 'unbiased expected value as proxy' is a 
bit of a stretch in any event.  Futures, like any other financial instrument, 
exhibit all sorts of biases and market forces. All that aside, you're on the 
right track.

The risk of *any* swap is the risk of the underlying basket portfolio.

Given that you can model a swap as a basket portfolio, you are correct that you 
would model the risk of the underlying futures contract.  However, I don't 
understand why you are thinking about one-day risk as opposed to some longer 
time horizon.  In some frameworks (e.g. Basel II, or a day trading firm) daily 
risk is required, but in many investment frameworks, you're most concerned with 
longer time horizons, even if the contract is valued daily.  It is of course 
straightforward to aggregate prices or returns to a longer horizon.  (using 
to.period in xts for price series or PerformanceAnalytics' portfolio return 
functions for return series in R)

You would model the term structure using any of the many tools available in R 
to do so (termstruct comes immediately to mind, though there are many other 
models represented in other packages). This would enable you to add interest 
rate basis risk to your market risk estimates.

Any complex synthetic instrument may be modeled as though it were a portfolio 
of the underlying or representative assets.  What you choose as your risk 
measure (Expected Shortfall, Delta-VaR, Conditional expectation of Drawdown, 
etc.) is, as always, a business decision based on your investment style and 
time horizon.

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From michael.in.the.jungle at gmail.com  Fri Feb 19 00:07:40 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Thu, 18 Feb 2010 15:07:40 -0800 (PST)
Subject: [R-SIG-Finance] Any time series visualization tool and backtest
 platform in R? Any good software outside R
Message-ID: <1266534460789-1560967.post@n4.nabble.com>


I don't have those trading software such as TradeStation at this moment.

But I have Matlab, R and Bloomberg.

I would like to find a way that I can easily visualize a bunch of time
series curves and cross-compare them. For example, the price curve vs.
trading signal curve. vs. SP500, etc.

The display doesn't have to be live or dynamic. 

The curve data are currently in Matlab, which can be the simplest column
data. These are backtest data.

But what's the best/convenient/effective way to rapidly visualize and
manipulate these time series data? Any good software?

I want to create these type of plots, overlayed with my own buy/sell
signals.

http://stockcharts.com/h-sc/ui?s=GE

And the plot needs to be interactive, ie. you can drag, zoom, explore, etc.

You think Matlab plot can do this?

I guess I am looking for more of a back-test platform...



-- 
View this message in context: http://n4.nabble.com/Any-time-series-visualization-tool-and-backtest-platform-in-R-Any-good-software-outside-R-tp1560967p1560967.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From josh.m.ulrich at gmail.com  Fri Feb 19 00:15:56 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 18 Feb 2010 17:15:56 -0600
Subject: [R-SIG-Finance] Any time series visualization tool and backtest
	platform in R? Any good software outside R
In-Reply-To: <1266534460789-1560967.post@n4.nabble.com>
References: <1266534460789-1560967.post@n4.nabble.com>
Message-ID: <8cca69991002181515o5ddcab6cgda88b688b80c515a@mail.gmail.com>

On Thu, Feb 18, 2010 at 5:07 PM, Michael Jungle
<michael.in.the.jungle at gmail.com> wrote:
>
> I don't have those trading software such as TradeStation at this moment.
>
> But I have Matlab, R and Bloomberg.
>
> I would like to find a way that I can easily visualize a bunch of time
> series curves and cross-compare them. For example, the price curve vs.
> trading signal curve. vs. SP500, etc.
>
> The display doesn't have to be live or dynamic.
>
> The curve data are currently in Matlab, which can be the simplest column
> data. These are backtest data.
>
> But what's the best/convenient/effective way to rapidly visualize and
> manipulate these time series data? Any good software?
>
Check out www.quantmod.com.  Specifically,
http://www.quantmod.com/examples/charting/

> I want to create these type of plots, overlayed with my own buy/sell
> signals.
>
> http://stockcharts.com/h-sc/ui?s=GE
>
> And the plot needs to be interactive, ie. you can drag, zoom, explore, etc.
>
quantmod allows you to zoom (and might have some other interactive features).

> You think Matlab plot can do this?
>
Not a good question for a R mailing list...

> I guess I am looking for more of a back-test platform...
See the tools under TradeAnalytics on R-forge:
http://r-forge.r-project.org/projects/blotter/

Best,
Josh
--
http://www.fosstrading.com


>
> --
> View this message in context: http://n4.nabble.com/Any-time-series-visualization-tool-and-backtest-platform-in-R-Any-good-software-outside-R-tp1560967p1560967.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From ggrothendieck at gmail.com  Fri Feb 19 02:48:49 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 18 Feb 2010 20:48:49 -0500
Subject: [R-SIG-Finance] Any time series visualization tool and backtest
	platform in R? Any good software outside R
In-Reply-To: <1266534460789-1560967.post@n4.nabble.com>
References: <1266534460789-1560967.post@n4.nabble.com>
Message-ID: <971536df1002181748j24802238h93357df18f30b65@mail.gmail.com>

This may not be exactly what you are looking for but you can use zoo
series with the playwith package to do zoom, pan, do annotation and a
few other things as shown in the examples near the end in ?xyplot.zoo
in the zoo package.   It also can be used in conjunction with the
TeachingDemos package as shown in one of the ?plot.zoo examples near
the end

On Thu, Feb 18, 2010 at 6:07 PM, Michael Jungle
<michael.in.the.jungle at gmail.com> wrote:
>
> I don't have those trading software such as TradeStation at this moment.
>
> But I have Matlab, R and Bloomberg.
>
> I would like to find a way that I can easily visualize a bunch of time
> series curves and cross-compare them. For example, the price curve vs.
> trading signal curve. vs. SP500, etc.
>
> The display doesn't have to be live or dynamic.
>
> The curve data are currently in Matlab, which can be the simplest column
> data. These are backtest data.
>
> But what's the best/convenient/effective way to rapidly visualize and
> manipulate these time series data? Any good software?
>
> I want to create these type of plots, overlayed with my own buy/sell
> signals.
>
> http://stockcharts.com/h-sc/ui?s=GE
>
> And the plot needs to be interactive, ie. you can drag, zoom, explore, etc.
>
> You think Matlab plot can do this?
>
> I guess I am looking for more of a back-test platform...
>
>
>
> --
> View this message in context: http://n4.nabble.com/Any-time-series-visualization-tool-and-backtest-platform-in-R-Any-good-software-outside-R-tp1560967p1560967.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From breman.mark at gmail.com  Fri Feb 19 19:34:32 2010
From: breman.mark at gmail.com (Mark Breman)
Date: Fri, 19 Feb 2010 19:34:32 +0100
Subject: [R-SIG-Finance] Howto cancel reqMktData() from IBrokers package?
Message-ID: <5e6a2e671002191034m38733cf2xf011cca8fc51f81a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100219/0162333d/attachment.pl>

From jeff.a.ryan at gmail.com  Fri Feb 19 23:45:53 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 19 Feb 2010 16:45:53 -0600
Subject: [R-SIG-Finance] Howto cancel reqMktData() from IBrokers package?
In-Reply-To: <5e6a2e671002191034m38733cf2xf011cca8fc51f81a@mail.gmail.com>
References: <5e6a2e671002191034m38733cf2xf011cca8fc51f81a@mail.gmail.com>
Message-ID: <e8e755251002191445w5294039ctf370975fd0958500@mail.gmail.com>

Hi Mark,

The basic premise is that the eWrapper is just the collection of
callbacks that manage each incoming message.  Either doing nothing
with it, yet still processing correctly [eWrapper(NULL)], or handling
each message type with some particular logic.

It seems like you have extended that perfectly.

What you need to customize is the CALLBACK that is passed in.  By
default this is twsCALLBACK.

In a nutshell, this is the main 'loop' that waits on the connection or
connections you have established to the TWS or external data source,
and it cycles though each new incoming message.  The messages
themselves are handled by the eWrapper object's callback(s) you
write/use.

What you want to do is add a few lines of code in a new CALLBACK that
test for the condition of the data you are storing (some n number of
bars, or all values are now non-NA, etc), and when it evaluates to
TRUE, simply return() from the call.  Easiest is just make a copy of
the twsCALLBACK and modify.

The function itself (reqMktData) should cancel the outstanding data
subscription you made, but to be sure you can also call cancelMktData
yourself.

I'll be giving a tutorial on trading with IBrokers (and event
processing in general with R) at the upcoming R/Finance 2010
conference in Chicago this coming April 16 and 17.

http://www.RinFinance.com

If you can't make the conference or the workshop, the slides will
eventually make their way to the website.

Hope that helps,
Jeff


On Fri, Feb 19, 2010 at 12:34 PM, Mark Breman <breman.mark at gmail.com> wrote:
> Hi everyone,
>
> I'm using the IBrokers package to get the implied volatility for options
> from Interactive Brokers.
>
> To seperate the implied volatility field from the data stream you get after
> calling reqMktData(), I had to write a specific EventWrapper:
>
> library(IBrokers)
>
> implVWrapper <-
> function(n=1) {
> eW <- eWrapper(NULL)
> #eW$assign.Data("data", vector(mode = "numeric", length = 2))
>
> eW$tickOptionComputation <- function(curMsg, msg, timestamp, file, ...) {
> ? ? ? ?tickType = msg[3]
> ? ? ? ?msg <- as.numeric(msg)
> ? ? ? ? id <- as.numeric(msg[2])
> value <- msg[4]
> #file <- file[[id]]
> ? ? ? ? #data <- eW$get.Data("data")
>
> if(tickType == 13 & value != -1) { ? ? # 14 is MODEL_OPTION, -1 is ???
> print(paste("id:", id, "implVol:", msg[4]))
> v[id] <<- value
> #cancelMktData(tws, id)
> }
>
> #eW$assign.Data("data", data)
> ? ? ? ?c(curMsg, msg)
> }
>
> return(eW)
> }
>
> Now I call the reqMktData() function with my special eventwrapper:
>
> options = list(twsOption("AA ? ?100320P00012000"), twsOption("AA
> ?100320C00014000")) # specify the options
> v = vector(mode = "numeric", length = length(options)) ? ?# v will hold the
> implied volatilities for the options
> tws = twsConnect(clientId=1)
> reqMktData(tws, options, eventWrapper=implVWrapper())
>
> This all works as expected except that reqMktData() keeps on running until
> it is stopped by the user (with the Esc key). What I would like is some way
> to stop the function when both implied volatilities are "filled". How do I
> do that?
>
> Kind regards,
>
> -Mark-
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From michael.in.the.jungle at gmail.com  Fri Feb 19 23:46:44 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Fri, 19 Feb 2010 14:46:44 -0800 (PST)
Subject: [R-SIG-Finance] How to find lead-lag relation in two time series?
Message-ID: <1266619604439-1562347.post@n4.nabble.com>


Any systematic way in R of doing this?

Thanks a lot!
-- 
View this message in context: http://n4.nabble.com/How-to-find-lead-lag-relation-in-two-time-series-tp1562347p1562347.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Fri Feb 19 23:50:03 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 19 Feb 2010 16:50:03 -0600
Subject: [R-SIG-Finance] How to find lead-lag relation in two time
	series?
In-Reply-To: <1266619604439-1562347.post@n4.nabble.com>
References: <1266619604439-1562347.post@n4.nabble.com>
Message-ID: <4B7F159B.7050206@braverock.com>

Michael Jungle wrote:
> Any systematic way in R of doing this? [find lead-lag relation in two time series?]
>   
Lots of them.

What theory of lead-lag relationships are you trying to replicate?  On 
what type of data? 
(those are important inputs to answering what tools are available))

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From michael.in.the.jungle at gmail.com  Sat Feb 20 00:15:05 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Fri, 19 Feb 2010 15:15:05 -0800 (PST)
Subject: [R-SIG-Finance] How to find lead-lag relation in two time
	series?
In-Reply-To: <1266619604439-1562347.post@n4.nabble.com>
References: <1266619604439-1562347.post@n4.nabble.com>
Message-ID: <1266621305368-1562383.post@n4.nabble.com>


One possibility is to do the cross-correlation. 

What series shall I apply cross-correlation to? Price or return series?

If I do cross-correlation on two price series, and found some large
correlation numbers,

and then do cross-correlation on two return series, and found no significant
numbers(almost zero), 

What does that mean?
-- 
View this message in context: http://n4.nabble.com/How-to-find-lead-lag-relation-in-two-time-series-tp1562347p1562383.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From ezivot at u.washington.edu  Sat Feb 20 00:21:36 2010
From: ezivot at u.washington.edu (Eric Zivot)
Date: Fri, 19 Feb 2010 15:21:36 -0800
Subject: [R-SIG-Finance] How to find lead-lag relation in two time
	series?
In-Reply-To: <1266619604439-1562347.post@n4.nabble.com>
References: <1266619604439-1562347.post@n4.nabble.com>
Message-ID: <022301cab1ba$481a5880$d84f0980$@washington.edu>

The standard approach is to estimate a vector autoregression involving your
variables of interest and then test for Granger non-causality. See the vars
package and in particular the causality() function.


Eric Zivot                  			               
Professor and Gary Waterman Distinguished Scholar       
Department of Economics                                 
Adjunct Professor of Finance                            
Adjunct Professor of Statistics
Box 353330                  email:  ezivot at u.washington.edu 
University of Washington    phone:  206-543-6715            
Seattle, WA 98195-3330
www:  http://faculty.washington.edu/ezivot                  



-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Michael Jungle
Sent: Friday, February 19, 2010 2:47 PM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] How to find lead-lag relation in two time series?


Any systematic way in R of doing this?

Thanks a lot!
-- 
View this message in context:
http://n4.nabble.com/How-to-find-lead-lag-relation-in-two-time-series-tp1562
347p1562347.html
Sent from the Rmetrics mailing list archive at Nabble.com.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From hhummel at post.harvard.edu  Sat Feb 20 01:23:15 2010
From: hhummel at post.harvard.edu (Harry Hummel)
Date: Fri, 19 Feb 2010 19:23:15 -0500
Subject: [R-SIG-Finance] Extracting regression coefficient standard errors
	from VAR
Message-ID: <30A3EA1218BA44BDA0FDB74D07D5C507@Venus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100219/840bfe12/attachment.pl>

From matthieu.stigler at gmail.com  Sat Feb 20 09:46:23 2010
From: matthieu.stigler at gmail.com (mat)
Date: Sat, 20 Feb 2010 09:46:23 +0100
Subject: [R-SIG-Finance] Extracting regression coefficient standard
 errors from VAR
In-Reply-To: <30A3EA1218BA44BDA0FDB74D07D5C507@Venus>
References: <30A3EA1218BA44BDA0FDB74D07D5C507@Venus>
Message-ID: <4B7FA15F.4030604@gmail.com>

Dear Harry

Please when asking a question do provide also a minimal code to 
illustrate your point.

library(vars)
data(Canada)
V<-VAR(Canada, p=2)
lapply(V$varresult, function(x) coefficients(summary(x)))

#more precisely:
lapply(V$varresult, function(x) coefficients(summary(x))[,2])


Harry Hummel a ?crit :
> How could one extract the standard errors from the results of VAR from the
> vars package?  The regression coefficients look pretty straight-forward, but
> I don?t see how to access the SE?s.
>
>  
>
> Sorry if this is a na?ve, newbie question.
>
>  
>
> Harry
>
>
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From patrick at burns-stat.com  Sat Feb 20 09:36:11 2010
From: patrick at burns-stat.com (Patrick Burns)
Date: Sat, 20 Feb 2010 08:36:11 +0000
Subject: [R-SIG-Finance] How to find lead-lag relation in two
	time	series?
In-Reply-To: <1266621305368-1562383.post@n4.nabble.com>
References: <1266619604439-1562347.post@n4.nabble.com>
	<1266621305368-1562383.post@n4.nabble.com>
Message-ID: <4B7F9EFB.6090802@burns-stat.com>

You want to use returns, not prices.
Correlations with prices are spurious.
(The extreme example is to think of
a long set of series with inflation --
all the price series will be positively
correlated.)


On 19/02/2010 23:15, Michael Jungle wrote:
>
> One possibility is to do the cross-correlation.
>
> What series shall I apply cross-correlation to? Price or return series?
>
> If I do cross-correlation on two price series, and found some large
> correlation numbers,
>
> and then do cross-correlation on two return series, and found no significant
> numbers(almost zero),
>
> What does that mean?

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com


From matthieu.stigler at gmail.com  Sat Feb 20 09:54:00 2010
From: matthieu.stigler at gmail.com (mat)
Date: Sat, 20 Feb 2010 09:54:00 +0100
Subject: [R-SIG-Finance] How to find lead-lag relation in two
	time	series?
In-Reply-To: <4B7F9EFB.6090802@burns-stat.com>
References: <1266619604439-1562347.post@n4.nabble.com>	<1266621305368-1562383.post@n4.nabble.com>
	<4B7F9EFB.6090802@burns-stat.com>
Message-ID: <4B7FA328.3000506@gmail.com>

For lead and lags cross-correlation:

cc<-ccf(mdeaths, fdeaths,lag.max=4, plot=F)
cc
#but this function is rather ugly...

Patrick Burns a ?crit :
> You want to use returns, not prices.
> Correlations with prices are spurious.
> (The extreme example is to think of
> a long set of series with inflation --
> all the price series will be positively
> correlated.)
>
>
> On 19/02/2010 23:15, Michael Jungle wrote:
>>
>> One possibility is to do the cross-correlation.
>>
>> What series shall I apply cross-correlation to? Price or return series?
>>
>> If I do cross-correlation on two price series, and found some large
>> correlation numbers,
>>
>> and then do cross-correlation on two return series, and found no 
>> significant
>> numbers(almost zero),
>>
>> What does that mean?
>


From breman.mark at gmail.com  Sat Feb 20 10:56:12 2010
From: breman.mark at gmail.com (Mark Breman)
Date: Sat, 20 Feb 2010 10:56:12 +0100
Subject: [R-SIG-Finance] Howto cancel reqMktData() from IBrokers package?
In-Reply-To: <e8e755251002191445w5294039ctf370975fd0958500@mail.gmail.com>
References: <5e6a2e671002191034m38733cf2xf011cca8fc51f81a@mail.gmail.com>
	<e8e755251002191445w5294039ctf370975fd0958500@mail.gmail.com>
Message-ID: <5e6a2e671002200156n2f215ac6sf4dd78f25e301a1f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100220/2b0acea8/attachment.pl>

From michael.in.the.jungle at gmail.com  Sat Feb 20 17:50:11 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Sat, 20 Feb 2010 08:50:11 -0800 (PST)
Subject: [R-SIG-Finance] How to find lead-lag relation in two time
 series?
In-Reply-To: <4B7F9EFB.6090802@burns-stat.com>
References: <1266619604439-1562347.post@n4.nabble.com>
	<1266621305368-1562383.post@n4.nabble.com>
	<4B7F9EFB.6090802@burns-stat.com>
Message-ID: <bbdd14ad1002200849t767dffe5vdcc088d85cc8aceb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100220/c0512235/attachment.pl>

From etheber at gmx.de  Sat Feb 20 18:30:39 2010
From: etheber at gmx.de (Thomas Etheber)
Date: Sat, 20 Feb 2010 18:30:39 +0100
Subject: [R-SIG-Finance] How to find lead-lag relation in two time
	series?
In-Reply-To: <bbdd14ad1002200849t767dffe5vdcc088d85cc8aceb@mail.gmail.com>
References: <1266619604439-1562347.post@n4.nabble.com>	<1266621305368-1562383.post@n4.nabble.com>	<4B7F9EFB.6090802@burns-stat.com>
	<bbdd14ad1002200849t767dffe5vdcc088d85cc8aceb@mail.gmail.com>
Message-ID: <4B801C3F.2090009@gmx.de>

Price time series will usually have a positive drift and thus are 
non-stationary.
As far as I know most methods of time series analysis deal with 
stationary series and if you want to analyze a non-stationary series, 
you should transform  the series and obtain a stationary version of the 
raw data first.
Return time series are usually (or at least assumed to be) stationary 
and thus your focus should lie on returns rather than prices..

Hth
Thomas



Michael Jungle schrieb:
> Thx but why? I want buy/short based on price correlations right? Not returns...
>
> On Saturday, February 20, 2010, Patrick Burns-2 [via R]
> <ml-node+1562668-773442928-108803 at n4.nabble.com> wrote:
>   
>> You want to use returns, not prices.
>>
>> Correlations with prices are spurious.
>>
>> (The extreme example is to think of
>>
>> a long set of series with inflation --
>>
>> all the price series will be positively
>>
>> correlated.)
>>
>>
>>
>> On 19/02/2010 23:15, Michael Jungle wrote:
>>
>>     
>>> One possibility is to do the cross-correlation.
>>>       
>>> What series shall I apply cross-correlation to? Price or return series?
>>>       
>>> If I do cross-correlation on two price series, and found some large
>>>       
>>> correlation numbers,
>>>       
>>> and then do cross-correlation on two return series, and found no significant
>>>       
>>> numbers(almost zero),
>>>       
>>> What does that mean?
>>>       
>> --
>>
>> Patrick Burns
>>
>> [hidden email]? <http://n4.nabble.com/user/SendEmail.jtp?type=node&node=1562668&i=0>
>>
>> http://www.burns-stat.com
>>
>> _______________________________________________
>>
>> [hidden email]? <http://n4.nabble.com/user/SendEmail.jtp?type=node&node=1562668&i=1> mailing list
>>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>>
>> -- Also note that this is not the r-help list where general R questions should go.
>>
>>
>>
>>
>> View message @ http://n4.nabble.com/How-to-find-lead-lag-relation-in-two-time-series-tp1562347p1562668.html
>>
>>
>> To unsubscribe from Re: How to find lead-lag relation in two time series?, click here? < (link removed) =>.
>>
>>
>>
>>     
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From cmdr_rogue at hotmail.com  Sat Feb 20 19:14:37 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Sat, 20 Feb 2010 13:14:37 -0500
Subject: [R-SIG-Finance] How to find lead-lag relation in two time
 series?
In-Reply-To: <4B801C3F.2090009@gmx.de>
References: <1266619604439-1562347.post@n4.nabble.com>
	<1266621305368-1562383.post@n4.nabble.com>
	<4B7F9EFB.6090802@burns-stat.com>
	<bbdd14ad1002200849t767dffe5vdcc088d85cc8aceb@mail.gmail.com>
	<4B801C3F.2090009@gmx.de>
Message-ID: <BLU0-SMTP6867E96527C1D1426C11CE2450@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100220/96a50981/attachment.pl>

From thomas_schwander at web.de  Sun Feb 21 12:59:03 2010
From: thomas_schwander at web.de (Thomas Schwander)
Date: Sun, 21 Feb 2010 12:59:03 +0100
Subject: [R-SIG-Finance] Downloading data from Reuters - second trial
Message-ID: <4B812007.8040000@web.de>

Dear lists (I was not sure which list would be the better-one),

I'm trying to download data from Reuters (3000 Xtra) into R with the 
extension written by Rory Winston (http://www.theresearchkitchen.com). I 
first stored the dlls into the bin directory of R, tried to load it into 
R with dyn.load but the extension cannot be loaded.

So I hoped to find an answer in the R list and got the topic. It seems 
like I have the same problem as Shubha, because also on his PC 
dyn.load("reuters_ts.dll") fails to load. Unfortunately the topics ends 
with "I'll email you off-list and we can work through it."

Maybe anyone's also tried to download data from Reuters (even via 
another way than Rorys) and got it to work?

Thanks for your help and have a nice weekend,
Thomas

Configuration: Windows 7, R 2.10.0, Reuters 3000 Xtra


From edd at debian.org  Sun Feb 21 21:56:34 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 21 Feb 2010 14:56:34 -0600
Subject: [R-SIG-Finance] One week remaining: useR! 2010 Abstract submission
	deadline
Message-ID: <19329.40450.469920.43527@ron.nulle.part>


Below is a final reminder for abstract submission for useR! 2010. It would be
nice to have a few finance-related talks to please consider submitting.

Dirk Eddelbuettel, on behalf of the program committee


  The abstract submission deadline for the R Users Conference, useR! 2010, 
  is just one week away.

       Submission deadline: 2010-03-01

  Early registration will also close on 2010-03-01.

  Now is the perfect time to prepare an abstract presenting innovations or 
  exciting applications of R. The call for abstracts along with the link for 
  submission is available at:
       http://www.R-project.org/useR-2010/#Call

  This meeting of the R user community will take place at the Gaithersburg,
  Maryland, USA campus of the National Institute of Standards and Technology
  (NIST), July 21-23, 2010.

  The conference schedule is comprised of invited lectures and 
  user-contributed sessions as well as half-day tutorials presented by R 
  experts on July 20, 2010, prior to the conference.

  Invited speakers will include
       Mark Handcock, Frank Harrell Jr, Friedrich Leisch, Michael Meyer,
       Richard Stallman, Luke Tierney, and Diethelm Wuertz.

  The full spectrum of conference information is available from the webpage:
       http://www.R-project.org/useR-2010/

  We hope to meet you in Gaithersburg!

  Kate Mullen, for the organizing committee


-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From ctchadwick at hotmail.com  Mon Feb 22 05:31:08 2010
From: ctchadwick at hotmail.com (Todd Chadwick)
Date: Sun, 21 Feb 2010 23:31:08 -0500
Subject: [R-SIG-Finance] Optimization Constraint Violations
Message-ID: <SNT133-ds6815AAE90093934F0BA5FC0430@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100221/bfeba60b/attachment.pl>

From cmdr_rogue at hotmail.com  Mon Feb 22 11:09:01 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Mon, 22 Feb 2010 05:09:01 -0500
Subject: [R-SIG-Finance] Optimization Constraint Violations
In-Reply-To: <SNT133-ds6815AAE90093934F0BA5FC0430@phx.gbl>
References: <SNT133-ds6815AAE90093934F0BA5FC0430@phx.gbl>
Message-ID: <BLU0-SMTP48E4ADEB5A5326FEB99913E2430@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100222/02097fac/attachment.pl>

From matthias.kornexl at raiffeisenbank.at  Mon Feb 22 11:18:28 2010
From: matthias.kornexl at raiffeisenbank.at (matthias.kornexl at raiffeisenbank.at)
Date: Mon, 22 Feb 2010 11:18:28 +0100
Subject: [R-SIG-Finance]  Optimization Constraint Violations
In-Reply-To: <SNT133-ds6815AAE90093934F0BA5FC0430@phx.gbl>
References: <SNT133-ds6815AAE90093934F0BA5FC0430@phx.gbl>
Message-ID: <OF5DFE7FCA.2EB483EA-ONC12576D2.00381173-C12576D2.00389F67@mdcs.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100222/6c9ab692/attachment.pl>

From j_cuisinier at hotmail.com  Mon Feb 22 11:26:12 2010
From: j_cuisinier at hotmail.com (julien cuisinier)
Date: Mon, 22 Feb 2010 11:26:12 +0100
Subject: [R-SIG-Finance] Optimization Constraint Violations
In-Reply-To: <BLU0-SMTP48E4ADEB5A5326FEB99913E2430@phx.gbl>
References: <SNT133-ds6815AAE90093934F0BA5FC0430@phx.gbl>,
	<BLU0-SMTP48E4ADEB5A5326FEB99913E2430@phx.gbl>
Message-ID: <COL102-W388C1F7766FF77B26F5E5F8F430@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100222/7b676a95/attachment.pl>

From brian at braverock.com  Mon Feb 22 12:00:25 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 22 Feb 2010 05:00:25 -0600
Subject: [R-SIG-Finance] Optimization Constraint Violations
In-Reply-To: <COL102-W388C1F7766FF77B26F5E5F8F430@phx.gbl>
References: <SNT133-ds6815AAE90093934F0BA5FC0430@phx.gbl>,
	<BLU0-SMTP48E4ADEB5A5326FEB99913E2430@phx.gbl>
	<COL102-W388C1F7766FF77B26F5E5F8F430@phx.gbl>
Message-ID: <4B8263C9.5020908@braverock.com>

fPortfolio uses quadprog underneath, so I don't know that using quadprog 
directly does anything other than lose the portability of the portfolio 
specification in fPortfolio.

Mattias raises the correct point, that fPortfolio will 'fall back' on 
unconstrained optimization when optimization is not possible with a given 
constraint set.  I believe that the unconstrained optimization is always 
performed, such that the efficient frontier is known and may be plotted against 
the constrained efficient frontier.

It is possible in any portfolio optimization problem, Markowitz MV or not, to 
specify constraints and objectives that are unreasonable.  Pat Burns has 
correctly suggested in his many writings that random portfolios can help to 
define the shape of the available space.  A portfolio manager also rapidly 
wants to specify constraints or objectives that are not amenable to a quadratic 
solution, and then other optimization engines are required.  Linear and Conical 
solvers are available in fPortfolio for some more robust approaches. Fully 
non-linear approaches such as random portfolios, simulated annealing, and 
differential evolution are available in other R packages.

However, none of this will matter if the combination of objectives and 
constraints are unreasonable.

And, to echo the other posters, please do take the time to construct a minimal 
example that shows what you're seeing.  It is really not to hard to either use 
publicly available data, or to disguise your data, such that we can see what's 
causing the problem.

Regards,

     - Brian

julien cuisinier wrote:
> I agree on the use of quadprog package, I do not know fPortfolio package and its MV optimization function but I can only guess it is done to provide an output in any case, i.e. whether an optimal solution fit within the constraints or not (so considering the constraints as soft by default)...but that only a guess.
> Indeed providing a reproducible code would make much easier to investigate what's going on.
> 
>> Sarbo writes:
>>
>> Would you mind including the code that you're using? It will be (much)
>> easier to figure out what's going on once we know precisely what the
>> constraints and the objective function are.
>>
>> One other thing- if you're looking to find the standard Markowitz
>> optimal portfolio with multiple assets and weightings, I recommend using
>> the "quadprog" package. I've used it before to solve such problems and
>> it does the job pretty nicely.
>>
>> On Sun, 2010-02-21 at 23:31 -0500, Todd Chadwick wrote:
>>
>>> Hi all,
>>>
>>> I'm stumped with a portfolio optimization issue.  I'm utilizing the
>>> fPortfolio package (although I know this issue is more general) and I am
>>> trying to perform a vanilla MV optimization using both a weighting
>>> constraint (box constrained and sum to unity) and target return
>>> specification (specifically using the "efficientPortfolio()" wrapper
>>> function).  My puzzle is that sometimes the box constraints are violated and
>>> I am curious as to either what else I need to consider (I suspect the issue
>>> involves the target return spec) or how to force the constraints to be
>>> honored.  
>>>
>>> Sorry no data examples to provide, but I hope that the experience of the
>>> collective can shed some light for a rookie.
>>>
>>> Todd


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From minkymorgan at gmail.com  Mon Feb 22 14:07:08 2010
From: minkymorgan at gmail.com (andrew morgan)
Date: Mon, 22 Feb 2010 13:07:08 +0000
Subject: [R-SIG-Finance] Downloading data from Reuters - second trial
	(Andrew)
Message-ID: <317ffdf51002220507t7ff3aecfm29e7809407548602@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100222/3f612cd5/attachment.pl>

From christophe00 at gmx.ch  Mon Feb 22 14:38:44 2010
From: christophe00 at gmx.ch (christophe00 at gmx.ch)
Date: Mon, 22 Feb 2010 14:38:44 +0100
Subject: [R-SIG-Finance] adjustOHLC does not consider setSymbolLookup
	settings [quantmod]
Message-ID: <20100222133844.54830@gmx.net>

Hi,

am I right, that even though getSymbols() does consider mapped ticker names, which were defined using setSymbolLookup(), adjustOHLC does not?

example:
> setSymbolLookup(ASSA.B.ST = list(name = 'ASSA-B.ST', src = 'yahoo'))
> getSymbols('ASSA.B.ST')
[1] "ASSA.B.ST"
> adjustOHLC('ASSA.B.ST', adjust = "split")
Error in download.file(paste(yahoo.URL, Symbol.name, "&a=", from.m, "&b=",  : 
  cannot open URL 'http://ichart.finance.yahoo.com/table.csv?s="ASSA.B.ST"&a=0&b=01&c=1970&d=1&e=22&f=2010&g=v&ignore=.csv'
In addition: Warning message:
In download.file(paste(yahoo.URL, Symbol.name, "&a=", from.m, "&b=",  :
  cannot open: HTTP status was '404 Not Found'

is there any work around?

Thanks and best regards,

Chris
-- 
Sicherer, schneller und einfacher. Die aktuellen Internet-Browser -
jetzt kostenlos herunterladen! http://portal.gmx.net/de/go/chbrowser


From michael.in.the.jungle at gmail.com  Mon Feb 22 21:47:52 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Mon, 22 Feb 2010 12:47:52 -0800 (PST)
Subject: [R-SIG-Finance] How to find lead-lag relation in two time
	series?
In-Reply-To: <BLU0-SMTP6867E96527C1D1426C11CE2450@phx.gbl>
References: <1266619604439-1562347.post@n4.nabble.com>
	<1266621305368-1562383.post@n4.nabble.com>
	<4B7F9EFB.6090802@burns-stat.com>
	<bbdd14ad1002200849t767dffe5vdcc088d85cc8aceb@mail.gmail.com>
	<4B801C3F.2090009@gmx.de>
	<BLU0-SMTP6867E96527C1D1426C11CE2450@phx.gbl>
Message-ID: <1266871672223-1565114.post@n4.nabble.com>


But we trade on prices, right? How do you trade on returns? 

My preliminary understanding is "whatever we trade on, we should find
correlation, etc. there...". 

If you find lead-lag relations on returns, how do you trade them?
-- 
View this message in context: http://n4.nabble.com/How-to-find-lead-lag-relation-in-two-time-series-tp1562347p1565114.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From ivan.kalafatic at gmail.com  Mon Feb 22 21:52:08 2010
From: ivan.kalafatic at gmail.com (Ivan Kalafatic)
Date: Mon, 22 Feb 2010 21:52:08 +0100
Subject: [R-SIG-Finance] Creating regularly spaced time series from
	irregular one
Message-ID: <6dbf89a51002221252tfd48465o12c43a2a2004c1d0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100222/29bda350/attachment.pl>

From jeff.a.ryan at gmail.com  Mon Feb 22 22:09:02 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 22 Feb 2010 15:09:02 -0600
Subject: [R-SIG-Finance] Creating regularly spaced time series from
	irregular one
In-Reply-To: <6dbf89a51002221252tfd48465o12c43a2a2004c1d0@mail.gmail.com>
References: <6dbf89a51002221252tfd48465o12c43a2a2004c1d0@mail.gmail.com>
Message-ID: <e8e755251002221309hc6e4ab2g8f830f412192bba0@mail.gmail.com>

Firstly, don't cross-post.

Second, take a look at the archives on both these lists for answers to
your questions.

'its' is rather old, and not where you want to be looking.

Take a look at xts for fast time-series manipulation like you need,
specifically to.period, endpoints, and align.time.  There is a wealth
of documentation in the package, in the vignette, and even online in
more than a few places, but you can start here:

http://cran.r-project.org/web/packages/xts/vignettes/xts.pdf
http://www.quantmod.com/examples/data/

Also zoo for na.locf etc.

Additional options include the fts package and timeSeries.

HTH
Jeff

On Mon, Feb 22, 2010 at 2:52 PM, Ivan Kalafatic
<ivan.kalafatic at gmail.com> wrote:
> Hello,
> I have a series of intraday (high-frequency) price data in the form of POSIX
> timestamp followed by the value.
> I sucesfuly loaded that into "its" package object. I would like to create
> from it a regularly spaced time series of prices (for example 1min, 5min,
> etc apart) so i could calcualte returns.
> There is an interpolation function locf() that for timestamp with value NA
> uses last known observation.
> I guess the idea would be to start from the begining of my series and, for
> example, if there is no timestamp for t+5min add that time with value NA.
> Than I could use locf() function to fill those NAs. Finaly I should extract
> from that series, series with 5min spaced timestamps with prices.
> Appart from applying locf() function, I have no idea how to add NAs into
> original series or extract the regular series after.
> Can someone help me with this?
> Thank you.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From brian at braverock.com  Mon Feb 22 22:13:58 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 22 Feb 2010 15:13:58 -0600
Subject: [R-SIG-Finance] How to find lead-lag relation in two
	time	series?
In-Reply-To: <1266871672223-1565114.post@n4.nabble.com>
References: <1266619604439-1562347.post@n4.nabble.com>	<1266621305368-1562383.post@n4.nabble.com>	<4B7F9EFB.6090802@burns-stat.com>	<bbdd14ad1002200849t767dffe5vdcc088d85cc8aceb@mail.gmail.com>	<4B801C3F.2090009@gmx.de>	<BLU0-SMTP6867E96527C1D1426C11CE2450@phx.gbl>
	<1266871672223-1565114.post@n4.nabble.com>
Message-ID: <4B82F396.6060108@braverock.com>

Michael Jungle wrote:
> But we trade on prices, right? How do you trade on returns? 
>
> My preliminary understanding is "whatever we trade on, we should find
> correlation, etc. there...". 
>
> If you find lead-lag relations on returns, how do you trade them?
>   
You've already been given the answer. 

Correlations on prices produce spurious results. 

Go do some research.  The literature will agree with what you've been 
told here.

Returns may be turned back into prices (or more appropriately, a wealth 
index)

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From ggrothendieck at gmail.com  Tue Feb 23 01:17:51 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 22 Feb 2010 19:17:51 -0500
Subject: [R-SIG-Finance] Creating regularly spaced time series from
	irregular one
In-Reply-To: <6dbf89a51002221252tfd48465o12c43a2a2004c1d0@mail.gmail.com>
References: <6dbf89a51002221252tfd48465o12c43a2a2004c1d0@mail.gmail.com>
Message-ID: <971536df1002221617n7c94dd21o1b67164d92d6acfa@mail.gmail.com>

You probably want to ask the author of the its package directly about that.

Note that as.zoo has an its method and as.its has a zoo method and
they will allow you to convert back and forth between its and zoo so
you can effectively use the functionality of both packages:

# converting back and forth
library(zoo)
library(its)
ii <- its(1:3, seq(Sys.time(), length = 3, by = "day"))
z <- as.zoo(ii)
ii2 <- as.its(z)

In zoo, see the discussion of the intraday.discretize function which
is defined in the following vignette:

library(zoo)
vignette("zoo-quickref")

# also see
vignette("zoo")
vignette("zoo-faq")

The discretizing discussion mentioned may apply in concept if not
literally to its as well.

Also note that zoo has an its method for the lattice xyplot function.

The xts package is defined as a layer on top of zoo and shares some
functions and methods with zoo and is particularly geared to finance
along with the quantmod package by the same author so see them too.
Also there is a list of R packages in the zoo-faq vignette mentioned
above that may be of interest.

On Mon, Feb 22, 2010 at 3:52 PM, Ivan Kalafatic
<ivan.kalafatic at gmail.com> wrote:
> Hello,
> I have a series of intraday (high-frequency) price data in the form of POSIX
> timestamp followed by the value.
> I sucesfuly loaded that into "its" package object. I would like to create
> from it a regularly spaced time series of prices (for example 1min, 5min,
> etc apart) so i could calcualte returns.
> There is an interpolation function locf() that for timestamp with value NA
> uses last known observation.
> I guess the idea would be to start from the begining of my series and, for
> example, if there is no timestamp for t+5min add that time with value NA.
> Than I could use locf() function to fill those NAs. Finaly I should extract
> from that series, series with 5min spaced timestamps with prices.
> Appart from applying locf() function, I have no idea how to add NAs into
> original series or extract the regular series after.
> Can someone help me with this?
> Thank you.


From cmdr_rogue at hotmail.com  Tue Feb 23 02:30:38 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Mon, 22 Feb 2010 20:30:38 -0500
Subject: [R-SIG-Finance] How to find lead-lag relation in two time
 series?
In-Reply-To: <4B82F396.6060108@braverock.com>
References: <1266619604439-1562347.post@n4.nabble.com>
	<1266621305368-1562383.post@n4.nabble.com>
	<4B7F9EFB.6090802@burns-stat.com>
	<bbdd14ad1002200849t767dffe5vdcc088d85cc8aceb@mail.gmail.com>
	<4B801C3F.2090009@gmx.de>	<BLU0-SMTP6867E96527C1D1426C11CE2450@phx.gbl>
	<1266871672223-1565114.post@n4.nabble.com>
	<4B82F396.6060108@braverock.com>
Message-ID: <BLU0-SMTP93937DAF199B699349239CE2420@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100222/a5b21d15/attachment.pl>

From chrysanthemum at gmail.com  Tue Feb 23 03:31:32 2010
From: chrysanthemum at gmail.com (Brian Giarrocco)
Date: Mon, 22 Feb 2010 21:31:32 -0500
Subject: [R-SIG-Finance] Pairs trading & cointegration
Message-ID: <fb3919991002221831j21f9dbc0l2cca6cbaf63eb090@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100222/67b92d76/attachment.pl>

From markknecht at gmail.com  Tue Feb 23 03:38:48 2010
From: markknecht at gmail.com (Mark Knecht)
Date: Mon, 22 Feb 2010 18:38:48 -0800
Subject: [R-SIG-Finance] Pairs trading & cointegration
In-Reply-To: <fb3919991002221831j21f9dbc0l2cca6cbaf63eb090@mail.gmail.com>
References: <fb3919991002221831j21f9dbc0l2cca6cbaf63eb090@mail.gmail.com>
Message-ID: <5bdc1c8b1002221838x75a86830n6684ee7538d2af35@mail.gmail.com>

On Mon, Feb 22, 2010 at 6:31 PM, Brian Giarrocco
<chrysanthemum at gmail.com> wrote:
> First time posting here so I hope I get it right!
>
> I'm an undergraduate in an American University, and am Computer
> Science/Math/Finance focused. I'm attempting to create a basic Pairs Trading
> portfolio as a project and have found many good resources online that have
> pointed me in the right direction.
>
> I have a symbol list of 50 Utility stocks w/ 500k+ ADV. I then compare each
> symbol to every other symbol using the Dickey-Fuller test, and then accept a
> pair if it passes with 95% confidence. Pretty simple idea.
>
> I created a python script to back-test different entry and exit points, but
> the problem, as most of you may have already found -- is that the
> co-integration does not significantly hold. The profitability seems to be
> around 1-2% over a year period. (Profitable, but not good)
>
> I'm looking to expand this out, does anyone have any suggestions on what I
> can add to tighten up the confidence of the cointegration. Is it possible to
> add in fundamentals? Are there any good papers that deal with cointegration
> between equities (Specifically in the US Equities Market)?
>
> I've posted all my code to: http://g-rock.dreamhosters.com/pairs/
> With the hope that it may help someone in the future.
>
>
> Thanks for any tips,
> Brian Giarrocco
> bvgiarro at edisto.cofc.edu

A fairly typical answer I suspect but have you investigated using some
overall gate to tell you to favor long or short, such as ETF for the
utility sector or overall market direction using the SPX or something
else like that?

pairs.r did not resolve for me.

Cheers,
Mark


From sankalp.upadhyay at gmail.com  Tue Feb 23 04:29:57 2010
From: sankalp.upadhyay at gmail.com (Sankalp Upadhyay)
Date: Tue, 23 Feb 2010 08:59:57 +0530
Subject: [R-SIG-Finance] Pairs trading & cointegration
In-Reply-To: <5bdc1c8b1002221838x75a86830n6684ee7538d2af35@mail.gmail.com>
References: <fb3919991002221831j21f9dbc0l2cca6cbaf63eb090@mail.gmail.com>
	<5bdc1c8b1002221838x75a86830n6684ee7538d2af35@mail.gmail.com>
Message-ID: <ff91746c1002221929x68fe0874ya4a88e95fc471d41@mail.gmail.com>

You should be able to get information sufficient for a good project in:

EP Chan's blog: http://epchan.blogspot.com/
He also wrote a book but that is quite basic and pairs are a very
small part of it. The comments on his blog should be useful. There are
discussions on cointegration between equities and between ETFs and use
of R.

A book on pairs trading:
http://www.amazon.com/Pairs-Trading-Quantitative-Methods-Analysis/dp/0471460672
While the book is missing some important steps, it does provide a good
discussion on what can be used to select or filter pairs.

An article or discussion that uses correlation to identify pairs may
also be good for you - because as I understand you need criteria to
select good pairs out of all pairs or to filter out the bad ones.

Regards
Sankalp



On Tue, Feb 23, 2010 at 8:08 AM, Mark Knecht <markknecht at gmail.com> wrote:
>
> On Mon, Feb 22, 2010 at 6:31 PM, Brian Giarrocco
> <chrysanthemum at gmail.com> wrote:
> > First time posting here so I hope I get it right!
> >
> > I'm an undergraduate in an American University, and am Computer
> > Science/Math/Finance focused. I'm attempting to create a basic Pairs Trading
> > portfolio as a project and have found many good resources online that have
> > pointed me in the right direction.
> >
> > I have a symbol list of 50 Utility stocks w/ 500k+ ADV. I then compare each
> > symbol to every other symbol using the Dickey-Fuller test, and then accept a
> > pair if it passes with 95% confidence. Pretty simple idea.
> >
> > I created a python script to back-test different entry and exit points, but
> > the problem, as most of you may have already found -- is that the
> > co-integration does not significantly hold. The profitability seems to be
> > around 1-2% over a year period. (Profitable, but not good)
> >
> > I'm looking to expand this out, does anyone have any suggestions on what I
> > can add to tighten up the confidence of the cointegration. Is it possible to
> > add in fundamentals? Are there any good papers that deal with cointegration
> > between equities (Specifically in the US Equities Market)?
> >
> > I've posted all my code to: http://g-rock.dreamhosters.com/pairs/
> > With the hope that it may help someone in the future.
> >
> >
> > Thanks for any tips,
> > Brian Giarrocco
> > bvgiarro at edisto.cofc.edu
>
> A fairly typical answer I suspect but have you investigated using some
> overall gate to tell you to favor long or short, such as ETF for the
> utility sector or overall market direction using the SPX or something
> else like that?
>
> pairs.r did not resolve for me.
>
> Cheers,
> Mark
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



--
--
Sankalp Upadhyay


From P.Pasching at investmentfonds.at  Tue Feb 23 08:13:10 2010
From: P.Pasching at investmentfonds.at (Pasching Petra)
Date: Tue, 23 Feb 2010 08:13:10 +0100
Subject: [R-SIG-Finance] close value
Message-ID: <ACD1AE4C4561DC43A545F3CDBB561824046A966D@SRVEX2.cquadrat.loc>

	 

	

Hi!

I recently started working with RBloomberg and I mainly need historical time series. Nevertheless, I want to make sure, that the last value (close price, etc.)  is already published and not some actual intraday value for the last observation.

If I set 

 

conn<-blpConnect(iface="COM", timeout=12000, show.days="week",na.action="na", periodicity="daily");

data<-blpGetData(conn, "VG1 Index", "PX_LAST",start= as.chron(Sys.Date()-150),end= as.chron(Sys.Date()),barsize=NULL)

 

I get NAs for the bank holidays but not for the close if it has not been published yet.

Can someone help me with this?

Thanks and best regards,

 

Petra

 


Mit freundlichen Gr??en 

DI Petra Pasching
Senior Financial Mathematician
Structured Solutions & ETFs 

Tel.:

 

+43(1)51566472

Fax:

 

+43(1)5156688119

eMail:

 

P.Pasching at investmentfonds.at <mailto:P.Pasching at investmentfonds.at> 

Web:

 

http://www.c-quadrat.at <http://www.c-quadrat.at> 

			

 

________________________________

C-QUADRAT Kapitalanlage AG
A-1010 Wien, Stubenring 2
FN 200444 x - UID: ATU50406109 

________________________________



Die Information in dieser E-Mail einschlie?lich allf?lliger Anh?nge ist vertraulich und ausschlie?lich f?r den Adressaten bestimmt. Der Empf?nger dieser Nachricht, der nicht Adressat, einer seiner Mitarbeiter oder sein Empfangsbevollm?chtigter ist, wird hiermit davon in Kenntnis gesetzt, dass er deren Inhalt nicht verwenden, weitergeben oder reproduzieren darf. Sollten Sie nicht der beabsichtigte Empf?nger sein, verst?ndigen Sie bitte unverz?glich den Absender und l?schen Sie anschlie?end dieses E-Mail einschlie?lich allf?lliger Kopien. Der Absender haftet weder f?r die richtige und vollst?ndige ?bermittlung dieser E-Mail einschlie?lich allf?lliger Anh?nge noch f?r eine allf?llige Verz?gerung bei der ?bermittlung. 

This email and any attachments thereto are confidential and for the attention of the intended addressee only. The person, who receives this message but is not the addressee, one of his employees or his receiving agent, is hereby informed that he may not use, transmit or reproduce its content. If you are not the intended recipient, please immediately notify the sender and delete the message as well as any copies thereof. The sender is not liable for, inter alia, the proper and complete transmission of the e-mail and its attachments or for any delay in its transmission. 

________________________________

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100223/2377837d/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 2786 bytes
Desc: image001.gif
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100223/2377837d/attachment.gif>

From xie.jinghua at uit.no  Tue Feb 23 09:24:29 2010
From: xie.jinghua at uit.no (Xie Jinghua)
Date: Tue, 23 Feb 2010 00:24:29 -0800 (PST)
Subject: [R-SIG-Finance] Systemfit package/Autocorrelation
In-Reply-To: <454722.10417.qm@web28006.mail.ukl.yahoo.com>
References: <454722.10417.qm@web28006.mail.ukl.yahoo.com>
Message-ID: <1266913469486-1565607.post@n4.nabble.com>


Dear Axel

I am using SUR for demand system estimation and have the same problem as you
when I use "systemfit" package. Could you please post or send the codes to
me if you have solved the problem?

 I also want to know if I want to impose the same (or common) Rho across the
equation, how can I manage it? 

By the way, how to get dubin-watson test result for each equations in the
system package?

Thanks, 

Jinghua Xie
-- 
View this message in context: http://n4.nabble.com/Systemfit-package-Autocorrelation-tp930381p1565607.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From Christian.Prinoth at epsilonsgr.it  Tue Feb 23 09:40:16 2010
From: Christian.Prinoth at epsilonsgr.it (Christian Prinoth)
Date: Tue, 23 Feb 2010 09:40:16 +0100
Subject: [R-SIG-Finance] Pairs trading & cointegration
In-Reply-To: <fb3919991002221831j21f9dbc0l2cca6cbaf63eb090@mail.gmail.com>
References: <fb3919991002221831j21f9dbc0l2cca6cbaf63eb090@mail.gmail.com>
Message-ID: <8D64D4652EB17048B874B0503309CFCA03BBF818@epsilon2003.epsilonsgr.it>


I would try to find cointegrated portfolios, instead of pairs of single
stocks. That might give you more stable cointegration relationships.
There used to be some papers on the topic by Carol Alexander on the net.

Christian Prinoth


> -----Original Message-----
> From: r-sig-finance-bounces at stat.math.ethz.ch
> [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of
> Brian Giarrocco
> Sent: 23 February, 2010 03:32
> To: r-sig-finance at stat.math.ethz.ch
> Subject: [R-SIG-Finance] Pairs trading & cointegration
>
> First time posting here so I hope I get it right!
>
> I'm an undergraduate in an American University, and am Computer
> Science/Math/Finance focused. I'm attempting to create a
> basic Pairs Trading
> portfolio as a project and have found many good resources
> online that have
> pointed me in the right direction.
>
> I have a symbol list of 50 Utility stocks w/ 500k+ ADV. I
> then compare each
> symbol to every other symbol using the Dickey-Fuller test,
> and then accept a
> pair if it passes with 95% confidence. Pretty simple idea.
>
> I created a python script to back-test different entry and
> exit points, but
> the problem, as most of you may have already found -- is that the
> co-integration does not significantly hold. The profitability
> seems to be
> around 1-2% over a year period. (Profitable, but not good)
>
> I'm looking to expand this out, does anyone have any
> suggestions on what I
> can add to tighten up the confidence of the cointegration. Is
> it possible to
> add in fundamentals? Are there any good papers that deal with
> cointegration
> between equities (Specifically in the US Equities Market)?
>
> I've posted all my code to: http://g-rock.dreamhosters.com/pairs/
> With the hope that it may help someone in the future.
>
>
> Thanks for any tips,
> Brian Giarrocco
> bvgiarro at edisto.cofc.edu
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R
> questions should go.
>

EPSILON SGR S.P.A.
Sede Legale: Piazzale Cadorna,3 20123 Milano, Italia - Tel.+39 02.8810.2070, Fax +39 02.7005.7447
Capitale Sociale euro 5.200.000 i.v. - Codice Fiscale, Partita IVA e n. Iscrizione Registro Imprese di Milano 11048700154 - Albo S.G.R. n. 91 - Societ? soggetta all'attivit? di direzione e coordinamento di Intesa Sanpaolo S.p.A. e appartenente al Gruppo Bancario Intesa Sanpaolo, iscritto all'Albo dei Gruppi Bancari - Socio Unico: Eurizon Capital SGR S.p.A.



DISCLAIMER:\ L'utilizzo non autorizzato del presente mes...{{dropped:16}}


From david.luethi at claridenleu.com  Tue Feb 23 10:04:42 2010
From: david.luethi at claridenleu.com (=?iso-8859-1?Q?L=FCthi_David_=28XICD_1=29?=)
Date: Tue, 23 Feb 2010 10:04:42 +0100
Subject: [R-SIG-Finance] RBloomberg: Switch 'periodicity' without disconnect
	and reconnect
Message-ID: <939D0071146E1941A5ABEB7F23C388C103987C30@chsa1556.share.beluni.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100223/b0a6e107/attachment.pl>

From arne.henningsen at googlemail.com  Tue Feb 23 10:07:11 2010
From: arne.henningsen at googlemail.com (Arne Henningsen)
Date: Tue, 23 Feb 2010 10:07:11 +0100
Subject: [R-SIG-Finance] Systemfit package/Autocorrelation
In-Reply-To: <1266913469486-1565607.post@n4.nabble.com>
References: <454722.10417.qm@web28006.mail.ukl.yahoo.com>
	<1266913469486-1565607.post@n4.nabble.com>
Message-ID: <ee2a35a61002230107u4109192dqfafdbea98425f014@mail.gmail.com>

Hi,

Currently, systemfit cannot account for auto-correlation and a
Durbin-Watson test has not been implemented yet, because I usually
have cross-sectional data, where autocorrelation is not an issue.
However, you are welcome to register at R-Forge and implement these
(or other) features in the systemfit package.

Best wishes,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name


From michael.in.the.jungle at gmail.com  Tue Feb 23 16:41:11 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Tue, 23 Feb 2010 07:41:11 -0800 (PST)
Subject: [R-SIG-Finance] How to cluster time series sequences?
Message-ID: <1266939671921-1566061.post@n4.nabble.com>


Are there toolboxes in R that can do time series sequencce clustering?

Thanks
-- 
View this message in context: http://n4.nabble.com/How-to-cluster-time-series-sequences-tp1566061p1566061.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Tue Feb 23 17:04:15 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 23 Feb 2010 10:04:15 -0600
Subject: [R-SIG-Finance] How to cluster time series sequences?
In-Reply-To: <1266939671921-1566061.post@n4.nabble.com>
References: <1266939671921-1566061.post@n4.nabble.com>
Message-ID: <4B83FC7F.3060101@braverock.com>

Michael Jungle wrote:
> Are there toolboxes in R that can do time series sequencce clustering?
>   
Michael,

It is always best to cite a reference that you're trying to understand 
and replicate in R when posting to the list. 
This will make sure everybody understands your terminology, and at the 
same time provides food for thought to the list contributors who you are 
asking for assistance.

'clustering' and 'cluster' can mean a lot of different things in 
finance, and R has tools for all the ones I can think of.  Please be 
more specific.

Also, if you're not already familiar with it, please get familiar with 
the tool 'RSiteSearch'

?RSiteSearch
RSiteSearch('cluster')

Though I suspect that you might not mean this at all, which is why I 
suggest that you always cite a reference to anchor your terminology when 
posting.

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From thomas_schwander at web.de  Tue Feb 23 18:03:54 2010
From: thomas_schwander at web.de (Thomas Schwander)
Date: Tue, 23 Feb 2010 18:03:54 +0100
Subject: [R-SIG-Finance] Downloading data from Reuters - second trial
 (Andrew)
In-Reply-To: <317ffdf51002220507t7ff3aecfm29e7809407548602@mail.gmail.com>
References: <317ffdf51002220507t7ff3aecfm29e7809407548602@mail.gmail.com>
Message-ID: <4B840A7A.8020708@web.de>

Hi Andrew,

thanks for your answer. I will try to work it through, but it would also 
be very very appreciated if you could send (parts?) of this code if 
you've still got it.

Thanks and regards,
Thomas

andrew morgan schrieb:
> On reuters data in R.
>
> I also had problems with those libraries, so hacked up something using three
> tools:
>
> I installed RExcel which allows you to pass data quickly between R and
> Excel.
> I installed RMySQL too, again allowing easy data passing between the R and
> Mysql.
> I used PowerPlusPro, the excel add in for 3000 Xtra, to set up a download of
> reuters TS1 data to a spreadsheet just using the wizards, nothing fancy.
>
> Using these tools, I set up a refreshing dataframe in R of the reuters data.
>
> The basic flow was something like this:
>
> 1) I used PowerPlusPro (aka PowerLink) to fetch Reuters data to excel into
> an excel named range.
> 2) an RExcel "rexec" call was made to run R code held in cells in the
> spreadsheet.
> 2.a) remeber the rexcel function was run on each data refresh event
> automatically, so powerplus pro was effectively synchronising the runs to
> happen on update.
> 2.b) that R code put the named range of data into a tmp data frame in R, and
> ran more R code to open a db connection, and move the block of new data to a
> temp table in mysql using overwrite=T
> 2.c) it also executed a second RMySql call to start a MySQL stored procedure
> that derived a delta from the tmp table, format it properly, and to insert
> new rows data into my main instrument history table. That table had cols
> named for working with R, things like row_names holding dates etc, turning
> reuters "Last" into "Close" etc.
> 3) it lastly called R code to repopulate my main moving window of dataframe
> data in R from MySql, which it then replotted before closing my connection
> to the db
>
> All this ran fast enough to work on min bars as they updated and was fun to
> play with.
>
> But to be clear - it was a terrible hack, and not a great way to work - if
> there's a better way, I also need it.
>
> Andrew
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>
>


From neil.gup at gmail.com  Tue Feb 23 21:38:34 2010
From: neil.gup at gmail.com (Neil Gupta)
Date: Tue, 23 Feb 2010 14:38:34 -0600
Subject: [R-SIG-Finance] Lagging Correlations
Message-ID: <a51fe2df1002231238q407b3304mf006ea1f6761baf2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100223/ad0582e4/attachment.pl>

From michael.in.the.jungle at gmail.com  Tue Feb 23 21:53:29 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Tue, 23 Feb 2010 12:53:29 -0800 (PST)
Subject: [R-SIG-Finance] How to cluster time series sequences?
In-Reply-To: <4B83FC7F.3060101@braverock.com>
References: <1266939671921-1566061.post@n4.nabble.com>
	<4B83FC7F.3060101@braverock.com>
Message-ID: <1266958409772-1566519.post@n4.nabble.com>


Sorry. I meant the clustering analysis of time series data (i.e. treating a
whole series as one data point), 
and then do the clustering on top of these data-points,

such as this:

http://www.google.com/url?sa=t&source=web&ct=res&cd=2&ved=0CAsQFjAB&url=http%3A%2F%2Fwww.cs.ucr.edu%2F~jessica%2FKeogh_ICDM_expanded.pdf&ei=4TaES4GpNc_ElAfEm-T4AQ&usg=AFQjCNGBenCWOqL6r_SeaiLIob5czJNErA&sig2=jzTONPtWjY3CBtGHOFO5Bw

I cannot conveniently access some Intenet websites, can anybody point me
directly to suitable R packages?

Thanks!


-- 
View this message in context: http://n4.nabble.com/How-to-cluster-time-series-sequences-tp1566061p1566519.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From michael.in.the.jungle at gmail.com  Tue Feb 23 21:57:30 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Tue, 23 Feb 2010 12:57:30 -0800 (PST)
Subject: [R-SIG-Finance] Is there a way to automate Bloomberg?
Message-ID: <1266958650043-1566526.post@n4.nabble.com>


Is there a way to automate Bloomberg?
Typing all those same buttons daily is really boring.
Anybody know if I could automate BB?
For example:
Currently I do the following manually:
I use Matlab to generate some of my own price data (write into an Excel
sheet),
and then I use BB's Customized Index Uploader to upload my own price Excel
sheet into BB,
And need to fill a few blanks, click a few buttons, assign a new name, etc.
so I could plot it with other data.
What's the best way to automate the above process?
I don't think BB's own macro can handle ALL of these things, am I right?
I mean, it can do a small portion, by creating a customized button, 
but I want to automate the whole process, including the "Matlab generate
Excel file" part, 
(btw, this also applies to using R to interface with BB, which is the reason
why I post here...)
Thanks!

-- 
View this message in context: http://n4.nabble.com/Is-there-a-way-to-automate-Bloomberg-tp1566526p1566526.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From michael.in.the.jungle at gmail.com  Tue Feb 23 21:59:22 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Tue, 23 Feb 2010 12:59:22 -0800 (PST)
Subject: [R-SIG-Finance] Is there a way to automate Bloomberg?
In-Reply-To: <1266958650043-1566526.post@n4.nabble.com>
References: <1266958650043-1566526.post@n4.nabble.com>
Message-ID: <1266958762804-1566528.post@n4.nabble.com>


I am probably asking for what's the best way to automate the whole process,
including BB+Matlab, (can also be R), etc. on a Windows environment?
-- 
View this message in context: http://n4.nabble.com/Is-there-a-way-to-automate-Bloomberg-tp1566526p1566528.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Tue Feb 23 22:06:09 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 23 Feb 2010 15:06:09 -0600
Subject: [R-SIG-Finance] Is there a way to automate Bloomberg?
In-Reply-To: <1266958650043-1566526.post@n4.nabble.com>
References: <1266958650043-1566526.post@n4.nabble.com>
Message-ID: <4B844341.5040803@braverock.com>

Michael Jungle wrote:
> Is there a way to automate Bloomberg?

Please Please PLEASE search before posting.

You have R, with

help.search()

and you have

RSiteSearch()

I assure you that

RSiteSearch('Bloomberg')

would have solved your problem.

and I assume you have Google.

If you can't access Google or RSiteSearch from work, it's not my problem 
or the problem of the people you are leaching time from.  This list has 
a relatively high signal to noise ratio.  I'd like to keep it that way.  
Please do just a little tiny bit of homework before posting.

  - Brian


From chrysanthemum at gmail.com  Wed Feb 24 01:50:28 2010
From: chrysanthemum at gmail.com (Brian Giarrocco)
Date: Tue, 23 Feb 2010 19:50:28 -0500
Subject: [R-SIG-Finance] Pairs trading & cointegration
In-Reply-To: <8D64D4652EB17048B874B0503309CFCA03BBF818@epsilon2003.epsilonsgr.it>
References: <fb3919991002221831j21f9dbc0l2cca6cbaf63eb090@mail.gmail.com>
	<8D64D4652EB17048B874B0503309CFCA03BBF818@epsilon2003.epsilonsgr.it>
Message-ID: <fb3919991002231650u3a2ad72doaaa1c888c7872bab@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100223/31a02a6f/attachment.pl>

From michael.in.the.jungle at gmail.com  Wed Feb 24 16:44:40 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Wed, 24 Feb 2010 07:44:40 -0800 (PST)
Subject: [R-SIG-Finance] Is there a way to automate Bloomberg?
In-Reply-To: <4B844341.5040803@braverock.com>
References: <1266958650043-1566526.post@n4.nabble.com>
	<4B844341.5040803@braverock.com>
Message-ID: <1267026280796-1567628.post@n4.nabble.com>


PLEASE, PLEASE DON'T ASSUME PEOPLE DON'T GOOGLE. 
And please keep your volume down if you don't add value to the discussion.
-- 
View this message in context: http://n4.nabble.com/Is-there-a-way-to-automate-Bloomberg-tp1566526p1567628.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From tallent_e at lycos.com  Wed Feb 24 23:05:23 2010
From: tallent_e at lycos.com (Edouard Tallent)
Date: Wed, 24 Feb 2010 17:05:23 -0500 (EST)
Subject: [R-SIG-Finance] [RE] Lagging Correlations
Message-ID: <20100224170523.HM.000000000000AMU@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100224/3920083f/attachment.html>

From luke.gower at cba.com.au  Wed Feb 24 23:23:20 2010
From: luke.gower at cba.com.au (Gower, Luke)
Date: Thu, 25 Feb 2010 09:23:20 +1100
Subject: [R-SIG-Finance] [RE] Lagging Correlations
In-Reply-To: <20100224170523.HM.000000000000AMU@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
References: <20100224170523.HM.000000000000AMU@tallent_e.mail-wwl7.bo3.lycos.com.lycos.com>
Message-ID: <A3B7C29F9599CC4BBF25F9830FA0138D5557236FA6@VAUNSW137.au.cbainet.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100225/181a2f72/attachment.pl>

From J_Cuisinier at hotmail.com  Thu Feb 25 08:30:32 2010
From: J_Cuisinier at hotmail.com (julien cuisinier)
Date: Thu, 25 Feb 2010 08:30:32 +0100
Subject: [R-SIG-Finance] Is there a way to automate Bloomberg?
In-Reply-To: <1267026280796-1567628.post@n4.nabble.com>
References: <1266958650043-1566526.post@n4.nabble.com>
	<4B844341.5040803@braverock.com>
	<1267026280796-1567628.post@n4.nabble.com>
Message-ID: <BLU0-SMTP7567A55222D68E5332819C8F400@phx.gbl>

Michael,



I really do not think this is a way you'll get anyone sympathy or help  
on this list.

Several points on your recent messages posted here:

1. you're sending to a R list a message of how to automate a process  
involving BB & Matlab....not a good idea, if you have Matlab you are  
paying the hefty fees that comes with it...hence you have access to  
their customer services which would be much better placed than this  
list to help you.

2. Bear in mind that R is free & that any help you may receive through  
this list is also free & provided by people who have their own job/ 
agenda (i.e. unlike Matlab's support, they are not sitting & paid to  
solve your problems). Hence any question asked should be as concise  
and focused as possible and you should have clearly searched  
beforehand, which was far from obvious from your recent posts...

3. Everyone on this list has a limited time capital to spend asking  
questions and not posting properly (I will not pretend it never  
happened to me...), you've been clearly dilapidating this capital of  
late. People are not there to solve your prbls and spare you some  
time, rather to try helping you on a voluntary basis if you're facing  
a blocking point in your research / development. Asking people to  
solve your Bloomberg process for uploading from Excel is none of this  
list problem. Again if you have bloomberg station you have access to  
their customer support which should be the people to answer your  
question.

4. Reacting the way you did below will definitely alienate you most of  
this list participants. You would have made some research into the   
previous posts, you would have seen Brian is quite an intensive  
contributor and often provides helpful guidance when it is properly  
asked. Again this is a free help, so you have to adapt to it no the  
other way around.

5. "if you don't add value to the discussion" >> which discussion?


Sorry for this direct tone, but as Brian said this list has a quite  
interesting high signal to noise ratio which makes all its value.
Thank you for your collaboration in keeping it this way.


Rgds,
Julien


On Feb 24, 2010, at 4:44 PM, Michael Jungle wrote:

>
> PLEASE, PLEASE DON'T ASSUME PEOPLE DON'T GOOGLE.
> And please keep your volume down if you don't add value to the  
> discussion.
> -- 
> View this message in context: http://n4.nabble.com/Is-there-a-way-to-automate-Bloomberg-tp1566526p1567628.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R  
> questions should go.
>


From ustaudinger at gmail.com  Thu Feb 25 09:19:39 2010
From: ustaudinger at gmail.com (Ulrich Staudinger)
Date: Thu, 25 Feb 2010 09:19:39 +0100
Subject: [R-SIG-Finance] Is there a way to automate Bloomberg?
In-Reply-To: <BLU0-SMTP7567A55222D68E5332819C8F400@phx.gbl>
References: <1266958650043-1566526.post@n4.nabble.com>
	<4B844341.5040803@braverock.com>
	<1267026280796-1567628.post@n4.nabble.com>
	<BLU0-SMTP7567A55222D68E5332819C8F400@phx.gbl>
Message-ID: <65daf6a61002250019s2b8b8edev305a7fc355021fdf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100225/b78f1966/attachment.pl>

From groups.robert at gmail.com  Thu Feb 25 09:41:00 2010
From: groups.robert at gmail.com (Robert for Groups)
Date: Thu, 25 Feb 2010 00:41:00 -0800 (PST)
Subject: [R-SIG-Finance] Is there a way to automate Bloomberg?
In-Reply-To: <1266958762804-1566528.post@n4.nabble.com>
References: <1266958650043-1566526.post@n4.nabble.com>
	<1266958762804-1566528.post@n4.nabble.com>
Message-ID: <1267087260667-1568669.post@n4.nabble.com>


Michael,

you should have asked for a tool automating not bloomberg or R but windows?

I would suggest you look at http://www.autohotkey.com/

It's a little tricky at the beginning - but it can really automate
everything: Cross applications, mouseinput, keyinput, variables,
systemcalls, etc ...

Cheers,

Robert
-- 
View this message in context: http://n4.nabble.com/Is-there-a-way-to-automate-Bloomberg-tp1566526p1568669.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From david.luethi at claridenleu.com  Thu Feb 25 11:33:51 2010
From: david.luethi at claridenleu.com (=?iso-8859-1?Q?L=FCthi_David_=28XICD_1=29?=)
Date: Thu, 25 Feb 2010 11:33:51 +0100
Subject: [R-SIG-Finance] RBloomberg: Switch 'periodicity' without
	disconnect and reconnect
In-Reply-To: <939D0071146E1941A5ABEB7F23C388C103987C30@chsa1556.share.beluni.net>
References: <939D0071146E1941A5ABEB7F23C388C103987C30@chsa1556.share.beluni.net>
Message-ID: <939D0071146E1941A5ABEB7F23C388C103987C43@chsa1556.share.beluni.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100225/192cbb5e/attachment.pl>

From matthieu.stigler at gmail.com  Fri Feb 26 16:05:00 2010
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Fri, 26 Feb 2010 16:05:00 +0100
Subject: [R-SIG-Finance] How people do get information about the list?
Message-ID: <111060c21002260705r22f9e032l5748dbce240b2a0a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100226/6b5bdf4b/attachment.pl>

From breman.mark at gmail.com  Fri Feb 26 16:19:18 2010
From: breman.mark at gmail.com (Mark Breman)
Date: Fri, 26 Feb 2010 16:19:18 +0100
Subject: [R-SIG-Finance] How people do get information about the list?
In-Reply-To: <111060c21002260705r22f9e032l5748dbce240b2a0a@mail.gmail.com>
References: <111060c21002260705r22f9e032l5748dbce240b2a0a@mail.gmail.com>
Message-ID: <5e6a2e671002260719p6853bcd8n7bcb17d2e6cb577f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100226/6b6bc80c/attachment.pl>

From rbali at ufmg.br  Fri Feb 26 16:25:55 2010
From: rbali at ufmg.br (Robert Iquiapaza)
Date: Fri, 26 Feb 2010 12:25:55 -0300
Subject: [R-SIG-Finance] How people do get information about the list?
In-Reply-To: <111060c21002260705r22f9e032l5748dbce240b2a0a@mail.gmail.com>
References: <111060c21002260705r22f9e032l5748dbce240b2a0a@mail.gmail.com>
Message-ID: <0696C90CD7454A82B49DB1578F8FAE9E@DellPC>

Good idea to create something for beginners.

Also, in Nabble
http://n4.nabble.com/R-f789695.html
it is possible to search many past post to R lists

Robert

--------------------------------------------------
From: "Matthieu Stigler" <matthieu.stigler at gmail.com>
Sent: Friday, February 26, 2010 12:05 PM
To: "R-Finance" <r-sig-finance at stat.math.ethz.ch>
Subject: [R-SIG-Finance] How people do get information about the list?

> Hi guys
>
> I was just wondering after those repeted scenes where people ask and get
> answered "search on the list", "this has been answered", "give 
> reproducible
> example" how actually soemone totally new to the list might know about its
> functionning...
>
> Assume the guy discovers the list through R page/ mailing lists/ r
> -sig-finance. How can he serach into the archive? Obviously, just looking 
> at
> that page:
> "To see the collection of prior postings to the list, visit the 
> R-SIG-Finance
> Archives <https://stat.ethz.ch/pipermail/r-sig-finance/>.
>
> won't help him so much (unless there is a way to search from that 
> archive?).
> After some search (assume the guy wants something more precise than just
> google), the guy will maybe find that there is a searchable archive here
> (are there others?):
> http://marc.info/?l=r-sig-finance&r=1&b=200902&w=2
>
> Finally, say the guy searched and did an answer for his topic. She wants 
> to
> ask, how should she formulate her question? No particular instructions 
> (show
> code, give self repro example), are given...
>
> So I don't know... but there would maybe be another way to give a few
> informations on the list that could help people asking questions, and 
> avoid
> people from the list to repeat always the same? Maybe kind of web page 
> just
> metionning a few "advices" on how to ask, with links to searchable 
> archives?
> Or any other idea?
>
> Best
>
> Matthieu
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions 
> should go.
>


From josh.m.ulrich at gmail.com  Fri Feb 26 16:26:13 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 26 Feb 2010 09:26:13 -0600
Subject: [R-SIG-Finance] How people do get information about the list?
In-Reply-To: <111060c21002260705r22f9e032l5748dbce240b2a0a@mail.gmail.com>
References: <111060c21002260705r22f9e032l5748dbce240b2a0a@mail.gmail.com>
Message-ID: <8cca69991002260726n939419ao88ef78968827dac3@mail.gmail.com>

On Fri, Feb 26, 2010 at 9:05 AM, Matthieu Stigler
<matthieu.stigler at gmail.com> wrote:
> Hi guys
>
> I was just wondering after those repeted scenes where people ask and get
> answered "search on the list", "this has been answered", "give reproducible
> example" how actually soemone totally new to the list might know about its
> functionning...
>
The "Search" link on the R homepage and the _first sentence_ on the
mailing list page, "Please read the instructions below and the posting
guide before sending anything to any mailing list!"

> Assume the guy discovers the list through R page/ mailing lists/ r
> -sig-finance. How can he serach into the archive? Obviously, just looking at
> that page:
> "To see the collection of prior postings to the list, visit the R-SIG-Finance
> Archives <https://stat.ethz.ch/pipermail/r-sig-finance/>.
>
> won't help him so much (unless there is a way to search from that archive?).
> After some search (assume the guy wants something more precise than just
> google), the guy will maybe find that there is a searchable archive here
> (are there others?):
> http://marc.info/?l=r-sig-finance&r=1&b=200902&w=2
>
There are several others, found by clicking the "Search" link on the R homepage:
http://www.r-project.org/search.html

> Finally, say the guy searched and did an answer for his topic. She wants to
> ask, how should she formulate her question? No particular instructions (show
> code, give self repro example), are given...
>
Not true.  The posting guide says small, self-reproducible examples
are helpful.  It also provides guidance on how to formulate a post to
the list.
Additionally, the "Final Words" section of the posting guide has this
very useful link:
http://www.catb.org/~esr/faqs/smart-questions.html

> So I don't know... but there would maybe be another way to give a few
> informations on the list that could help people asking questions, and avoid
> people from the list to repeat always the same? Maybe kind of web page just
> metionning a few "advices" on how to ask, with links to searchable archives?
> Or any other idea?
>
Providing information isn't the problem.  The problem is getting
people to actually use it.

Best,
Josh
--
http://www.fosstrading.com



> Best
>
> Matthieu
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From michael.in.the.jungle at gmail.com  Fri Feb 26 16:31:04 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Fri, 26 Feb 2010 07:31:04 -0800 (PST)
Subject: [R-SIG-Finance] Is there a way to automate Bloomberg?
In-Reply-To: <65daf6a61002250019s2b8b8edev305a7fc355021fdf@mail.gmail.com>
References: <1266958650043-1566526.post@n4.nabble.com>
	<4B844341.5040803@braverock.com>
	<1267026280796-1567628.post@n4.nabble.com>
	<BLU0-SMTP7567A55222D68E5332819C8F400@phx.gbl>
	<65daf6a61002250019s2b8b8edev305a7fc355021fdf@mail.gmail.com>
Message-ID: <1267198264351-1570773.post@n4.nabble.com>


Thanks. But did you notice I am not asking for "data-importing" using R for
BB, instead, I was asking for automating? 

Do you assume ONLY you know GOOGLE on the earth? 
-- 
View this message in context: http://n4.nabble.com/Is-there-a-way-to-automate-Bloomberg-tp1566526p1570773.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Fri Feb 26 16:28:16 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 26 Feb 2010 09:28:16 -0600
Subject: [R-SIG-Finance] How people do get information about the list?
In-Reply-To: <111060c21002260705r22f9e032l5748dbce240b2a0a@mail.gmail.com>
References: <111060c21002260705r22f9e032l5748dbce240b2a0a@mail.gmail.com>
Message-ID: <4B87E890.9040604@braverock.com>

Matthieu Stigler wrote:
> Hi guys
>
> I was just wondering after those repeted scenes where people ask and get
> answered "search on the list", "this has been answered", "give reproducible
> example" how actually soemone totally new to the list might know about its
> functionning...
>   
> Assume the guy discovers the list through R page/ mailing lists/ r
> -sig-finance. How can he serach into the archive? Obviously, just looking at
> that page:
> "To see the collection of prior postings to the list, visit the R-SIG-Finance
> Archives <https://stat.ethz.ch/pipermail/r-sig-finance/>.
>
> won't help him so much (unless there is a way to search from that archive?).
> After some search (assume the guy wants something more precise than just
> google), the guy will maybe find that there is a searchable archive here
> (are there others?):
> http://marc.info/?l=r-sig-finance&r=1&b=200902&w=2
>
>   

Here is the Nabble archive, which offers reasonable searchability via a 
custom Google search:

http://n4.nabble.com/Rmetrics-f925806.html

And of course searching for anything R related should follow the 
standard guidelines for searching

- try help.search() and RSiteSearch() first
- use RSeek.org to search
- Google search by adding '+R' or 'r-project' to your search

> Finally, say the guy searched and did an answer for his topic. She wants to
> ask, how should she formulate her question? No particular instructions (show
> code, give self repro example), are given...
>
>   
Well, I'd probably start with the posting guide:

http://www.r-project.org/posting-guide.html

Maybe this should get added (again?) to the footer of all list emails.

The classic treatise on the topic of how to get support for free 
software is Eric Raymond's 'How to Ask Questions the Smart Way'

http://catb.org/~esr/faqs/smart-questions.html

> So I don't know... but there would maybe be another way to give a few
> informations on the list that could help people asking questions, and avoid
> people from the list to repeat always the same? Maybe kind of web page just
> metionning a few "advices" on how to ask, with links to searchable archives?
> Or any other idea?
>
> Best
>
> Matthieu
>   
Cheers,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From michael.in.the.jungle at gmail.com  Fri Feb 26 16:33:23 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Fri, 26 Feb 2010 07:33:23 -0800 (PST)
Subject: [R-SIG-Finance] Is there a way to automate Bloomberg?
In-Reply-To: <BLU0-SMTP7567A55222D68E5332819C8F400@phx.gbl>
References: <1266958650043-1566526.post@n4.nabble.com>
	<4B844341.5040803@braverock.com>
	<1267026280796-1567628.post@n4.nabble.com>
	<BLU0-SMTP7567A55222D68E5332819C8F400@phx.gbl>
Message-ID: <1267198403250-1570778.post@n4.nabble.com>


My goodness - you spent such a great deal of energy bashing me on a public
forum?
How much bandwidth/time you are wasting of all other people?
------------
I asked a question - how to automate BB from R/Matlab. Notice, it's not
about "importing data".
I am sure this is of interest to many other fellow R users. 
But you came back with an extremely length bashing? 

-- 
View this message in context: http://n4.nabble.com/Is-there-a-way-to-automate-Bloomberg-tp1566526p1570778.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From michael.in.the.jungle at gmail.com  Fri Feb 26 16:34:17 2010
From: michael.in.the.jungle at gmail.com (Michael Jungle)
Date: Fri, 26 Feb 2010 07:34:17 -0800 (PST)
Subject: [R-SIG-Finance] Is there a way to automate Bloomberg?
In-Reply-To: <1267087260667-1568669.post@n4.nabble.com>
References: <1266958650043-1566526.post@n4.nabble.com>
	<1266958762804-1566528.post@n4.nabble.com>
	<1267087260667-1568669.post@n4.nabble.com>
Message-ID: <1267198457783-1570779.post@n4.nabble.com>


Thanks so much Bob. Really appreciate this kind of informative and helpful
pointers! 

Have a great weekend Bob and everyone!
-- 
View this message in context: http://n4.nabble.com/Is-there-a-way-to-automate-Bloomberg-tp1566526p1570779.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From edd at debian.org  Fri Feb 26 17:03:12 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 26 Feb 2010 10:03:12 -0600
Subject: [R-SIG-Finance] List etiquette
Message-ID: <19335.61632.652376.970624@ron.nulle.part>


i)     The list works well. I would like to thank all of you for helping to keep
       the signal level up, and noise level down. 

ii)    We can do better still.  Let's (once more) follow Brian Ripley's lead
       and apply some pressure so that people actually post using their real 
       names instead of handles like hotshot at awesome.com.  We have nothing
       against GMail accounts, but we do have something against people hiding
       behind them.

iii)   As a draconian measure, I just unsubscribed the 'Michael Jungle' monkey.
       I do not like to do this, but he worked hard to deserve it. He will
       undoubtedly come back with a new handle, so let us all try to remember
       point ii) above above.

iv)    FYI, we currently have over 1900 direct subscribers, and several of
       these are other mailing list gateways for in-house lists, gmane, ...

v)     While I am on the soap box:
       
	   R / Finance 2010 registration is open, see www.RinFinance.com
	   
	   useR! 2010 early registration and abstract submission deadline is
	   _this weekend_, see www.useR2010.org

Thanks, Dirk
 



-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From markknecht at gmail.com  Fri Feb 26 20:00:42 2010
From: markknecht at gmail.com (Mark Knecht)
Date: Fri, 26 Feb 2010 11:00:42 -0800
Subject: [R-SIG-Finance] List etiquette
In-Reply-To: <19335.61632.652376.970624@ron.nulle.part>
References: <19335.61632.652376.970624@ron.nulle.part>
Message-ID: <5bdc1c8b1002261100l1f5f2b7bva1c4a12fda1bab0@mail.gmail.com>

On Fri, Feb 26, 2010 at 8:03 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
<SNP>
>
> ii) ? ?We can do better still. ?Let's (once more) follow Brian Ripley's lead
> ? ? ? and apply some pressure so that people actually post using their real
> ? ? ? names instead of handles like hotshot at awesome.com. ?We have nothing
> ? ? ? against GMail accounts, but we do have something against people hiding
> ? ? ? behind them.

This seems quite arbitrary to me as I can subscribe to GMail using any
real _looking_ name which still isn't actually _my_ real name.

While I don't do it I think there are real world privacy concerns some
people have about using their real names on lists like this and I
would vote not to require something that looks real if you're not
interested in ensuring that it actually is real.

Just my 2 cents. It's you're list so you're free to do what you want.

Cheers,
Mark


From jeff.a.ryan at gmail.com  Fri Feb 26 20:26:20 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 26 Feb 2010 13:26:20 -0600
Subject: [R-SIG-Finance] List etiquette
In-Reply-To: <5bdc1c8b1002261100l1f5f2b7bva1c4a12fda1bab0@mail.gmail.com>
References: <19335.61632.652376.970624@ron.nulle.part>
	<5bdc1c8b1002261100l1f5f2b7bva1c4a12fda1bab0@mail.gmail.com>
Message-ID: <e8e755251002261126h4b8fef35tccfd35607988b843@mail.gmail.com>

>
> This seems quite arbitrary to me as I can subscribe to GMail using any
> real _looking_ name which still isn't actually _my_ real name.

Of course you can -- one can also provide disinformation (deception?).
 Just because you can doesn't mean it is good.

Certainly it may be important for some to remove firm affiliations,
for legal or personal reasons.  Your name/signature serves as a
measure of trust.  If you are willing to attach your real name, that
says something important to me about your integrity and honesty.  It
says even more when you don't.

It is a fairly simple expectation that I have.  If you want
assistance, or to engage in discussion, it strikes me as rude that you
wouldn't share with the audience your name.  If we were in a physical
forum, it would be akin to making me stand behind a curtain so I
didn't get to see who you were.

While this game sometimes boils down to egos, I think this list is
stellar because it does not.

Jeff
>
> While I don't do it I think there are real world privacy concerns some
> people have about using their real names on lists like this and I
> would vote not to require something that looks real if you're not
> interested in ensuring that it actually is real.
>
> Just my 2 cents. It's you're list so you're free to do what you want.
>
> Cheers,
> Mark
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From breman.mark at gmail.com  Sun Feb 28 14:36:55 2010
From: breman.mark at gmail.com (Mark Breman)
Date: Sun, 28 Feb 2010 14:36:55 +0100
Subject: [R-SIG-Finance] blotter and dividends
Message-ID: <5e6a2e671002280536r447c6c5do3a10b30a8f5c2fa4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100228/74eb9ad4/attachment.pl>

From brian at braverock.com  Sun Feb 28 15:20:51 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 28 Feb 2010 08:20:51 -0600
Subject: [R-SIG-Finance] blotter and dividends
In-Reply-To: <5e6a2e671002280536r447c6c5do3a10b30a8f5c2fa4@mail.gmail.com>
References: <5e6a2e671002280536r447c6c5do3a10b30a8f5c2fa4@mail.gmail.com>
Message-ID: <4B8A7BC3.2090604@braverock.com>

Mark Breman wrote:
> I want to add a dividend payment from a stock to blotter. How do I do that?
>
> According to the blotter documentation it should be done as a transaction:
> "In the most common use, 'transactions' are trades in an instrument.
> Instruments are bought or sold in a transaction. Other transaction types
> include splits, dividends, expirations, assignments, etc."
>
> but it looks like addTxn() does not support dividends.
>   
You're right, addTxn doesn't yet support dividends. 

It hasn't been important enough to the 'blotter' authors, including 
myself, to get around to adding it.

If it is important to you, we'd love some collaboration to make the 
toolkit better for everyone.

I'm going to state some obvious stuff before launching into design 
details, please bear with me.

Dividends are cash payments from the company to its  equity (stock) 
holders.  Interest, in a similar vein, is cash payments to an issuers 
debt (bond) holders.  There are exceptions to this, but generally 
speaking that definition should be enough to work from.

In blotter, this would need to be evidenced as a cash (in some currency) 
payment into the Account object (where cash/capital/acct equity value of 
the portfolios are held)

We could model this as a cash payment 'on' a Stock/Bond instrument into 
the Portfolio object.  This would make tracking things easier, I think.  
It would add the complication that you might need to add a currency 
position in the portfolio to hold that money.  Another approach would be 
to add a 'adjustments' table to the portfolio object in the list for 
each asset.  The second approach is more work, but might be beneficial 
from a speed perspective, as the adjustments could be stored as a text 
matrix or data.frame, allowing more freedom to add human-readable 
information (the $txn and $posPL slots are all numeric xts objects, for 
increased ease of handling the numeric and time series portions)

I think this is probably best implemented with a new function, not in 
addTxn (which is part of why it hasn't been done yet).  The other types 
of special transactions that you mentioned above (splits, expiration, 
assignment, exercise, etc.) are also different in their effects from 
buying or selling a specific instrument.  All of these, except for 
splits, similarly act on a cash balance.

An addDividend function would be trivial to write (probably fewer than 
20 lines of code), assuming that it adds cash to a portfolio. 

I'm not set on the design details, by any means, but this is my reaction 
to knowing that someone is actually ready to use blotter with 
dividends.  So if anyone has a better implementation proposal, feel free 
to chime in.

If you want to collaborate on this, we'd love your help.  Otherwise, 
I'll bump it up a little in priority on my (long) list of things to do.

In other 'blotter' news, I know that Jeff is starting to look at more 
options-specific handling, which might get some of the other special 
transaction types worked through as well.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From kafka at centras.lt  Sun Feb 28 20:11:05 2010
From: kafka at centras.lt (kafkaz)
Date: Sun, 28 Feb 2010 11:11:05 -0800 (PST)
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <4B575039.7090103@braverock.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>
	<4B575039.7090103@braverock.com>
Message-ID: <1267384265779-1572896.post@n4.nabble.com>


Brian,
I tried demo('longtrend') and the result is:

# Load data with quantmod
> print("Loading data")
[1] "Loading data"

> currency("USD")
Error in eval.with.vis(expr, envir, enclos) : 
  could not find function "currency"
In addition: There were 11 warnings (use warnings() to see them)

My problems started, then I tried to add a new transaction:

addTxn(portfolio, "SPY", '2007-01-03', 50, 96.5, -0.05*50) 
[1] "2007-01-03 SPY 50 @ 96.5"
Warning messages:
1: In getInstrument(Symbol) :
  Instrument SPY  not found, please create it first.


I debugged a bit and I found, that getInstrument function fails on this
line:
if (inherits(tmp_instr, "try-error") | !is.instrument(tmp_instr)) {

I suspect, that FinancialInstrument package isn't committed properly.
Currency, stock methods
do not exist in my environment. The version of FI is 0.02, blotter v.0.4

As well, I have noticed, that environment variables are used very heavily.
What is the reason of using
environment variables instead of local variables? For example, in initPortf
method:
if (exists(paste("portfolio", name, sep = "."), envir = .blotter, 
        inherits = TRUE))
I found it frustrating, when I tried to recreate a portfolio and an account,
but I couldn't.

Thanks,
kafka
-- 
View this message in context: http://n4.nabble.com/Blotter-package-problem-with-example-tp1018634p1572896.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Sun Feb 28 20:25:47 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 28 Feb 2010 13:25:47 -0600
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <1267384265779-1572896.post@n4.nabble.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>	<4B575039.7090103@braverock.com>
	<1267384265779-1572896.post@n4.nabble.com>
Message-ID: <4B8AC33B.40903@braverock.com>

kafkaz wrote:
> currency("USD")
>   
> Error in eval.with.vis(expr, envir, enclos) : 
>   could not find function "currency"
> In addition: There were 11 warnings (use warnings() to see them)
>
> My problems started, then I tried to add a new transaction:
>
>   
<...>

> I suspect, that FinancialInstrument package isn't committed properly.
> Currency, stock methods
> do not exist in my environment. The version of FI is 0.02, blotter v.0.4
>
>   
Yes, I tried using @alias tags (getting fancy) in the documentation, and 
it messed up the NAMESPACE file.  Sorry.

This was fixed in revision 270 a couple of days ago, which looks like 
it's available as prebuilt packages on R-Forge now.

updating FinancialInstrument should fix this.

> As well, I have noticed, that environment variables are used very heavily.
> What is the reason of using
> environment variables instead of local variables? For example, in initPortf
> method:
> if (exists(paste("portfolio", name, sep = "."), envir = .blotter, 
>         inherits = TRUE))
> I found it frustrating, when I tried to recreate a portfolio and an account,
> but I couldn't.
>   
getPortfolio() and getAccount()

will let you examine the Portfolio and Account objects by providing 
local copies in the global environment.

The primary reason for using the environment is performance.  By using 
get() and assign() we can minimize unnecessary copying as things are called.

The secondary (but important) reason for using environment variables 
instead of local (passed) variables is that we need to maintain control 
over the objects.  By putting them in an environment, they don't clutter 
the global environment, and we have a reasonable belief that only expert 
users will 'touch' the objects themselves.

The tertiary reason is that we expect that these objects and/or their 
methods will probably get reimplemented in C/C++ at some point, and will 
not necessarily remain as pure R code for performance.  We've (mostly) 
stabilized the API and function calls, so those should (mostly) remain 
the same (I'm relying on this code on real portfolios at this point) but 
the 'internals' may change as we optimize the execution.

Regards,

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From kafka at centras.lt  Sun Feb 28 21:29:41 2010
From: kafka at centras.lt (kafkaz)
Date: Sun, 28 Feb 2010 12:29:41 -0800 (PST)
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <4B8AC33B.40903@braverock.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>
	<4B575039.7090103@braverock.com>
	<1267384265779-1572896.post@n4.nabble.com>
	<4B8AC33B.40903@braverock.com>
Message-ID: <1267388981726-1572940.post@n4.nabble.com>


I tried to run this:
install.packages("FinancialInstrument",
repos="http://R-Forge.R-project.org")
result is the same.

Concerning variable's question I'm convinced. But how do I clean up after
using blotter? 
-- 
View this message in context: http://n4.nabble.com/Blotter-package-problem-with-example-tp1018634p1572940.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Sun Feb 28 21:35:37 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 28 Feb 2010 14:35:37 -0600
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <1267388981726-1572940.post@n4.nabble.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>	<4B575039.7090103@braverock.com>	<1267384265779-1572896.post@n4.nabble.com>	<4B8AC33B.40903@braverock.com>
	<1267388981726-1572940.post@n4.nabble.com>
Message-ID: <4B8AD399.8080802@braverock.com>

kafkaz wrote:
> I tried to run this:
> install.packages("FinancialInstrument",
> repos="http://R-Forge.R-project.org")
> result is the same.
>
>   
restart R after doing this.  I was just able to update one machine here 
using the metohd you describe, and got the current revision of 
FinancialInstrument from R-Forge, so you should too.
> Concerning variable's question I'm convinced. But how do I clean up after
> using blotter? 
>   
The demo's clean up at the start so that you can run them multiple times.

Look at how the demos remove objects in the environment namespace.

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From kafka at centras.lt  Sun Feb 28 23:11:55 2010
From: kafka at centras.lt (kafkaz)
Date: Sun, 28 Feb 2010 14:11:55 -0800 (PST)
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <4B8AD399.8080802@braverock.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>
	<4B575039.7090103@braverock.com>
	<1267384265779-1572896.post@n4.nabble.com>
	<4B8AC33B.40903@braverock.com>
	<1267388981726-1572940.post@n4.nabble.com>
	<4B8AD399.8080802@braverock.com>
Message-ID: <1267395115970-1573015.post@n4.nabble.com>


Got another error:

updateAcct("aaa", Dates = as.Date(index(SPY.monthly[length(SPY.monthly)])))
Error: object 'CurrentSpan' not found
In addition: Warning message:
In max(i) : no non-missing arguments to max; returning -Inf

My proposal would be to implement the methods like
removeAccount/removePortfolio. 
My dirty solution:
rm(list=ls(envir=.blotter),envir=.blotter)
try(rm("ltaccount","ltportfolio","ClosePrice","CurrentDate","equity","GSPC","i","initDate","initEq","Posn","UnitSize","verbose"),silent=TRUE)


-- 
View this message in context: http://n4.nabble.com/Blotter-package-problem-with-example-tp1018634p1573015.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From mvyver at gmail.com  Mon Mar  1 02:54:05 2010
From: mvyver at gmail.com (Mark V)
Date: Mon, 1 Mar 2010 12:54:05 +1100
Subject: [R-SIG-Finance] List etiquette
In-Reply-To: <e8e755251002261126h4b8fef35tccfd35607988b843@mail.gmail.com>
References: <19335.61632.652376.970624@ron.nulle.part>
	<5bdc1c8b1002261100l1f5f2b7bva1c4a12fda1bab0@mail.gmail.com>
	<e8e755251002261126h4b8fef35tccfd35607988b843@mail.gmail.com>
Message-ID: <389c43e41002281754m7e673b04j3aae2a45344121d6@mail.gmail.com>

On Sat, Feb 27, 2010 at 6:26 AM, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:
>>
>> This seems quite arbitrary to me as I can subscribe to GMail using any
>> real _looking_ name which still isn't actually _my_ real name.
>
> Of course you can -- one can also provide disinformation (deception?).
> ?Just because you can doesn't mean it is good.
>
> Certainly it may be important for some to remove firm affiliations,
> for legal or personal reasons. ?Your name/signature serves as a
> measure of trust. ?If you are willing to attach your real name, that
> says something important to me about your integrity and honesty. ?It
> says even more when you don't.
>

E.g We don't want a modern day Mr Student's contributions?
Now, jokes aside.
I do understand the attaction of superficial rules of thumb for making
quick judgements about both people's motives, and the likely quality
of their contributions.  It's an age old solution to the same problem
and it seems not easily escaped, even today.

IMO, it would be useful if the list was open, if not welcoming, to
productive contributions from any 'Keyboard Monkey' alias, where the
true identity is unknown.  Equally, it is useful if the list was open
to rejecting noise from "John K. Smith, Phd (MIT)" where the name and
qualifation have been vetted.
Overall, I think an approach favoring substance over style is best.

I do appreciate that validating genuine email addresses is not
trivial, nor is it simple to establish that a human is always driving
the keyboard.  However there are resaonable tools and services to help
make those administration tasks less onerous.

My 2c
Mark
> It is a fairly simple expectation that I have. ?If you want
> assistance, or to engage in discussion, it strikes me as rude that you
> wouldn't share with the audience your name. ?If we were in a physical
> forum, it would be akin to making me stand behind a curtain so I
> didn't get to see who you were.
>
> While this game sometimes boils down to egos, I think this list is
> stellar because it does not.
>
> Jeff
>>
>> While I don't do it I think there are real world privacy concerns some
>> people have about using their real names on lists like this and I
>> would vote not to require something that looks real if you're not
>> interested in ensuring that it actually is real.
>>
>> Just my 2 cents. It's you're list so you're free to do what you want.
>>
>> Cheers,
>> Mark
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>
>
>
> --
> Jeffrey Ryan
> jeffrey.ryan at insightalgo.com
>
> ia: insight algorithmics
> www.insightalgo.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From cwrward at gmail.com  Mon Mar  1 09:21:21 2010
From: cwrward at gmail.com (Charles Ward)
Date: Mon, 1 Mar 2010 08:21:21 +0000
Subject: [R-SIG-Finance] fPortfolio plotting of efficient frontiers
Message-ID: <bd9aa36b1003010021v273fb70m8ebf5b27f1ad3138@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100301/f6139023/attachment.pl>

From brian at braverock.com  Mon Mar  1 12:11:05 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 01 Mar 2010 05:11:05 -0600
Subject: [R-SIG-Finance] fPortfolio plotting of efficient frontiers
In-Reply-To: <bd9aa36b1003010021v273fb70m8ebf5b27f1ad3138@mail.gmail.com>
References: <bd9aa36b1003010021v273fb70m8ebf5b27f1ad3138@mail.gmail.com>
Message-ID: <4B8BA0C9.6010609@braverock.com>

Charles Ward wrote:
> But if I calculate the frontier using the Kendall method (stored in f9) and
> plot two frontiers using frontierPlot,
> they appear on the same horizontal risk-scale. Shouldn't the two scales be
> different?

Charles,

The two efficient frontiers would not be comparable if plotted on different 
axes on the same chart.

The (typical) reason for plotting multiple efficient frontiers is to see how 
the unconstrained (or long only) Markowitz mean-variance frontier 'shrinks' 
with different constraints or risk measures.  By definition, the area under 
these more-restricted efficient frontiers will be smaller than the 
unconstrained or long-only case.

A modification to this approach that we use often it to set the 'risk' axis to 
the risk measure you really care about, such as CVaR, and then plot the 
unconstrained or long-only efficient frontier on/against *that* axis.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From cwrward at gmail.com  Mon Mar  1 12:32:35 2010
From: cwrward at gmail.com (Charles Ward)
Date: Mon, 1 Mar 2010 11:32:35 +0000
Subject: [R-SIG-Finance] fPortfolio plotting of efficient frontiers
In-Reply-To: <4B8BA0C9.6010609@braverock.com>
References: <bd9aa36b1003010021v273fb70m8ebf5b27f1ad3138@mail.gmail.com>
	<4B8BA0C9.6010609@braverock.com>
Message-ID: <bd9aa36b1003010332t605e1a08v18ae20c74becac97@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100301/cffbc6af/attachment.pl>

From brian at braverock.com  Mon Mar  1 12:41:14 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 01 Mar 2010 05:41:14 -0600
Subject: [R-SIG-Finance] fPortfolio plotting of efficient frontiers
In-Reply-To: <bd9aa36b1003010332t605e1a08v18ae20c74becac97@mail.gmail.com>
References: <bd9aa36b1003010021v273fb70m8ebf5b27f1ad3138@mail.gmail.com>	
	<4B8BA0C9.6010609@braverock.com>
	<bd9aa36b1003010332t605e1a08v18ae20c74becac97@mail.gmail.com>
Message-ID: <4B8BA7DA.7070507@braverock.com>

No worries.  Unfortunately now I can't really be of much assistance.

I suspect that you may have changed the portfolioSpec, and changing the option 
again doesn't change it back, but I don't really know without  code to examine.

I'd suggest using one of the standard data sets, like 'edhec' or anything from 
fEcoFin, and building a little test script.  The list software will allow you 
to attach PDF's of the output, and your test script will let Diethelm or others 
more knowledgeable in fPortfolio replicate the problem.

Regards,

     - Brian

Charles Ward wrote:
> I am sorry Brian - my query was unclear.
> I plotted the frontier on two different graphs. In both cases, it was 
> the same calculation - only the options in the frontierPlot were changed.
> I am not quite clear what the units are in the default plot of the 
> Kendall estimator but the x-axis shows units of 150, 200 and 250 with 
> the settings                            risk=c("Sig") 
> If I then repeat the function with the option set to         risk= 
> c("Cov")  
> I would have expected the horizontal scale to show the standard 
> deviation where the units would be in the region of 0.008 to 0.011. In 
> fact, the graph appears unchanged with the same units of 150, 200 and 250.
> So my question really was about the option    risk = ... in the 
> frontierPlot function.
> What does it do?
> Charles
> 
> 
> On Mon, Mar 1, 2010 at 11:11 AM, Brian G. Peterson <brian at braverock.com 
> <mailto:brian at braverock.com>> wrote:
> 
>     Charles Ward wrote:
> 
>         But if I calculate the frontier using the Kendall method (stored
>         in f9) and
>         plot two frontiers using frontierPlot,
>         they appear on the same horizontal risk-scale. Shouldn't the two
>         scales be
>         different?
> 
> 
>     Charles,
> 
>     The two efficient frontiers would not be comparable if plotted on
>     different axes on the same chart.
> 
>     The (typical) reason for plotting multiple efficient frontiers is to
>     see how the unconstrained (or long only) Markowitz mean-variance
>     frontier 'shrinks' with different constraints or risk measures.  By
>     definition, the area under these more-restricted efficient frontiers
>     will be smaller than the unconstrained or long-only case.
> 
>     A modification to this approach that we use often it to set the
>     'risk' axis to the risk measure you really care about, such as CVaR,
>     and then plot the unconstrained or long-only efficient frontier
>     on/against *that* axis.
> 
>     Regards,
> 
>        - Brian
> 
>     -- 
>     Brian G. Peterson
>     http://braverock.com/brian/
>     Ph: 773-459-4973
>     IM: bgpbraverock
> 
> 


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From cwrward at gmail.com  Mon Mar  1 13:32:55 2010
From: cwrward at gmail.com (Charles Ward)
Date: Mon, 1 Mar 2010 12:32:55 +0000
Subject: [R-SIG-Finance] fPortfolio plotting of efficient frontiers
In-Reply-To: <4B8BA7DA.7070507@braverock.com>
References: <bd9aa36b1003010021v273fb70m8ebf5b27f1ad3138@mail.gmail.com>
	<4B8BA0C9.6010609@braverock.com>
	<bd9aa36b1003010332t605e1a08v18ae20c74becac97@mail.gmail.com>
	<4B8BA7DA.7070507@braverock.com>
Message-ID: <bd9aa36b1003010432h3639e75bi6cab4219ac098836@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100301/8384d627/attachment.pl>

From kafka at centras.lt  Mon Mar  1 14:03:16 2010
From: kafka at centras.lt (kafkaz)
Date: Mon, 1 Mar 2010 05:03:16 -0800 (PST)
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <1267395115970-1573015.post@n4.nabble.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>
	<4B575039.7090103@braverock.com>
	<1267384265779-1572896.post@n4.nabble.com>
	<4B8AC33B.40903@braverock.com>
	<1267388981726-1572940.post@n4.nabble.com>
	<4B8AD399.8080802@braverock.com>
	<1267395115970-1573015.post@n4.nabble.com>
Message-ID: <1267448596709-1573514.post@n4.nabble.com>


Could you explain, why equity goes down calling these functions:
equity=getEndEq('acc',as.character(currentDate))
print(paste('equity ',equity, ' date ',currentDate,' Spy ', SPY.monthly[i]))
updatePortf(Portfolio = "prtf", Dates = as.character(currentDate))
updateAcct("acc", Dates = as.character(currentDate))
updateEndEq("acc", as.character(currentDate))

[1] "equity  10000  date  1995-01-31  Spy  37.02"
[1] "upAcc 1995-01-31"
[1] "upEnd 1995-01-31"
[1] "equity  10000  date  1995-02-28  Spy  38.54"
[1] "upAcc 1995-02-28"
[1] "upEnd 1995-02-28"
[1] "equity  0  date  1995-03-31  Spy  39.64"
[1] "upAcc 1995-03-31"
[1] "upEnd 1995-03-31"
[1] "equity  0  date  1995-04-28  Spy  40.81"
[1] "upAcc 1995-04-28"
[1] "upEnd 1995-04-28"
[1] "equity  0  date  1995-05-31  Spy  42.43"
[1] "upAcc 1995-05-31"
[1] "upEnd 1995-05-31"
[1] "equity  0  date  1995-06-30  Spy  43.29"
[1] "upAcc 1995-06-30"
[1] "upEnd 1995-06-30"
[1] "equity  0  date  1995-07-31  Spy  44.68"
[1] "upAcc 1995-07-31"
[1] "upEnd 1995-07-31"
[1] "equity  0  date  1995-08-31  Spy  44.88"
[1] "upAcc 1995-08-31"
[1] "upEnd 1995-08-31"
[1] "equity  0  date  1995-09-29  Spy  46.77"
[1] "upAcc 1995-09-29"
[1] "upEnd 1995-09-29"
[1] "equity  0  date  1995-10-31  Spy  46.64"
[1] "buy"
[1] "1995-10-31 SPY 0 @ 46.64"
[1] "upAcc 1995-10-31"
[1] "upEnd 1995-10-31"

Latter on, it fails on updateEndEq("acc", as.character(currentDate))

Error in if (length(c(year, month, day, hour, min, sec)) == 6 && c(year,  : 
  missing value where TRUE/FALSE needed
In addition: Warning messages:
1: In as_numeric(YYYY) : NAs introduced by coercion
2: In as_numeric(YYYY) : NAs introduced by coercion

Thank you.

-- 
View this message in context: http://n4.nabble.com/Blotter-package-problem-with-example-tp1018634p1573514.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Mon Mar  1 14:48:00 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 01 Mar 2010 07:48:00 -0600
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <1267448596709-1573514.post@n4.nabble.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>	<4B575039.7090103@braverock.com>	<1267384265779-1572896.post@n4.nabble.com>	<4B8AC33B.40903@braverock.com>	<1267388981726-1572940.post@n4.nabble.com>	<4B8AD399.8080802@braverock.com>	<1267395115970-1573015.post@n4.nabble.com>
	<1267448596709-1573514.post@n4.nabble.com>
Message-ID: <4B8BC590.8080507@braverock.com>

You did not provide a reproducible example, only a slice from some other 
code. 

I do not see the problem you describe in the 'blotter' demos or in any 
of my code. 

Please provide more information, and your name would be nice too.

Regards,

   - Brian

kafkaz wrote:
> Could you explain, why equity goes down calling these functions:
> equity=getEndEq('acc',as.character(currentDate))
> print(paste('equity ',equity, ' date ',currentDate,' Spy ', SPY.monthly[i]))
> updatePortf(Portfolio = "prtf", Dates = as.character(currentDate))
> updateAcct("acc", Dates = as.character(currentDate))
> updateEndEq("acc", as.character(currentDate))
>
> [1] "equity  10000  date  1995-01-31  Spy  37.02"
> [1] "upAcc 1995-01-31"
> [1] "upEnd 1995-01-31"
> [1] "equity  10000  date  1995-02-28  Spy  38.54"
> [1] "upAcc 1995-02-28"
> [1] "upEnd 1995-02-28"
> [1] "equity  0  date  1995-03-31  Spy  39.64"
> [1] "upAcc 1995-03-31"
> [1] "upEnd 1995-03-31"
> [1] "equity  0  date  1995-04-28  Spy  40.81"
> [1] "upAcc 1995-04-28"
> [1] "upEnd 1995-04-28"
> [1] "equity  0  date  1995-05-31  Spy  42.43"
> [1] "upAcc 1995-05-31"
> [1] "upEnd 1995-05-31"
> [1] "equity  0  date  1995-06-30  Spy  43.29"
> [1] "upAcc 1995-06-30"
> [1] "upEnd 1995-06-30"
> [1] "equity  0  date  1995-07-31  Spy  44.68"
> [1] "upAcc 1995-07-31"
> [1] "upEnd 1995-07-31"
> [1] "equity  0  date  1995-08-31  Spy  44.88"
> [1] "upAcc 1995-08-31"
> [1] "upEnd 1995-08-31"
> [1] "equity  0  date  1995-09-29  Spy  46.77"
> [1] "upAcc 1995-09-29"
> [1] "upEnd 1995-09-29"
> [1] "equity  0  date  1995-10-31  Spy  46.64"
> [1] "buy"
> [1] "1995-10-31 SPY 0 @ 46.64"
> [1] "upAcc 1995-10-31"
> [1] "upEnd 1995-10-31"
>
> Latter on, it fails on updateEndEq("acc", as.character(currentDate))
>
> Error in if (length(c(year, month, day, hour, min, sec)) == 6 && c(year,  : 
>   missing value where TRUE/FALSE needed
> In addition: Warning messages:
> 1: In as_numeric(YYYY) : NAs introduced by coercion
> 2: In as_numeric(YYYY) : NAs introduced by coercion
>
> Thank you.
>
>   


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From kafka at centras.lt  Mon Mar  1 15:31:27 2010
From: kafka at centras.lt (kafkaz)
Date: Mon, 1 Mar 2010 06:31:27 -0800 (PST)
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <4B8BC590.8080507@braverock.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>
	<4B575039.7090103@braverock.com>
	<1267384265779-1572896.post@n4.nabble.com>
	<4B8AC33B.40903@braverock.com>
	<1267388981726-1572940.post@n4.nabble.com>
	<4B8AD399.8080802@braverock.com>
	<1267395115970-1573015.post@n4.nabble.com>
	<1267448596709-1573514.post@n4.nabble.com>
	<4B8BC590.8080507@braverock.com>
Message-ID: <1267453887141-1573601.post@n4.nabble.com>


demo('longtrend')

[1] "1998-10-30 GSPC 0 @ 1098.67"
.
[1] "1998-11-30 GSPC 0 @ 1163.63"
.
[1] "1998-12-31 GSPC 0 @ 1229.23"
.
[1] "1999-01-29 GSPC 0 @ 1279.64"
.
[1] "1999-02-26 GSPC 0 @ 1238.33"
.
[1] "1999-03-31 GSPC 0 @ 1286.37"
.
[1] "1999-04-30 GSPC 0 @ 1335.18"
.
[1] "1999-05-28 GSPC 0 @ 1301.84"
.
[1] "1999-06-30 GSPC 0 @ 1372.71"
.
[1] "1999-07-30 GSPC 0 @ 1328.72"
.
[1] "1999-08-31 GSPC 0 @ 1320.41"
..
[1] "1999-10-29 GSPC 0 @ 1362.93"
.
[1] "1999-11-30 GSPC 0 @ 1388.91"
.
[1] "1999-12-31 GSPC 0 @ 1469.25"
.
[1] "2000-01-31 GSPC 0 @ 1394.46"
.
[1] "2000-02-29 GSPC 0 @ 1366.42"
.
[1] "2000-03-31 GSPC 0 @ 1498.58"
.
[1] "2000-04-28 GSPC 0 @ 1452.43"
.
[1] "2000-05-31 GSPC 0 @ 1420.6"
.
[1] "2000-06-30 GSPC 0 @ 1454.6"
.
[1] "2000-07-31 GSPC 0 @ 1430.83"
.
[1] "2000-08-31 GSPC 0 @ 1517.68"
...................
[1] "2002-03-28 GSPC 0 @ 1147.39"
.............
[1] "2003-04-30 GSPC 0 @ 916.92"
.
[1] "2003-05-30 GSPC 0 @ 963.59"
.
[1] "2003-06-30 GSPC 0 @ 974.5"
.
[1] "2003-07-31 GSPC 0 @ 990.31"
.
[1] "2003-08-29 GSPC 0 @ 1008.01"
.
[1] "2003-09-30 GSPC 0 @ 995.97"
.
[1] "2003-10-31 GSPC 0 @ 1050.71"
.
[1] "2003-11-28 GSPC 0 @ 1058.2"
.
[1] "2003-12-31 GSPC 0 @ 1111.92"
.
[1] "2004-01-30 GSPC 0 @ 1131.13"
.
[1] "2004-02-27 GSPC 0 @ 1144.94"
.
[1] "2004-03-31 GSPC 0 @ 1126.21"
.
[1] "2004-04-30 GSPC 0 @ 1107.3"
.
[1] "2004-05-28 GSPC 0 @ 1120.68"
.
[1] "2004-06-30 GSPC 0 @ 1140.84"
....
[1] "2004-10-29 GSPC 0 @ 1130.2"
.
[1] "2004-11-30 GSPC 0 @ 1173.82"
.
[1] "2004-12-31 GSPC 0 @ 1211.92"
.
[1] "2005-01-31 GSPC 0 @ 1181.27"
.
[1] "2005-02-28 GSPC 0 @ 1203.6"
.
[1] "2005-03-31 GSPC 0 @ 1180.59"
.
[1] "2005-04-29 GSPC 0 @ 1156.85"
.
[1] "2005-05-31 GSPC 0 @ 1191.5"
.
[1] "2005-06-30 GSPC 0 @ 1191.33"
.
[1] "2005-07-29 GSPC 0 @ 1234.18"
.
[1] "2005-08-31 GSPC 0 @ 1220.33"
.
[1] "2005-09-30 GSPC 0 @ 1228.81"
.
[1] "2005-10-31 GSPC 0 @ 1207.01"
.
[1] "2005-11-30 GSPC 0 @ 1249.48"
.
[1] "2005-12-30 GSPC 0 @ 1248.29"
.
[1] "2006-01-31 GSPC 0 @ 1280.08"
.
[1] "2006-02-28 GSPC 0 @ 1280.66"
.
[1] "2006-03-31 GSPC 0 @ 1294.87"
.
[1] "2006-04-28 GSPC 0 @ 1310.61"
.
[1] "2006-05-31 GSPC 0 @ 1270.09"
.
[1] "2006-06-30 GSPC 0 @ 1270.2"
.
[1] "2006-07-31 GSPC 0 @ 1276.66"
.
[1] "2006-08-31 GSPC 0 @ 1303.82"
.
[1] "2006-09-29 GSPC 0 @ 1335.85"
.
[1] "2006-10-31 GSPC 0 @ 1377.94"
.
[1] "2006-11-30 GSPC 0 @ 1400.63"
.
[1] "2006-12-29 GSPC 0 @ 1418.3"
.
[1] "2007-01-31 GSPC 0 @ 1438.24"
.
[1] "2007-02-28 GSPC 0 @ 1406.82"
.
[1] "2007-03-30 GSPC 0 @ 1420.86"
.
[1] "2007-04-30 GSPC 0 @ 1482.37"
.
[1] "2007-05-31 GSPC 0 @ 1530.62"
.
[1] "2007-06-29 GSPC 0 @ 1503.35"
.
[1] "2007-07-31 GSPC 0 @ 1455.27"
.
[1] "2007-08-31 GSPC 0 @ 1473.99"
.
[1] "2007-09-28 GSPC 0 @ 1526.75"
.
[1] "2007-10-31 GSPC 0 @ 1549.38"
....................
[1] "2009-06-30 GSPC 0 @ 919.32"
.
[1] "2009-07-31 GSPC 0 @ 987.48"
.
[1] "2009-08-31 GSPC 0 @ 1020.62"
.
[1] "2009-09-30 GSPC 0 @ 1057.08"
.
[1] "2009-10-30 GSPC 0 @ 1036.19"
.
[1] "2009-11-30 GSPC 0 @ 1095.63"
.
[1] "2009-12-31 GSPC 0 @ 1115.1"
.
[1] "2010-01-29 GSPC 0 @ 1073.87"
.
[1] "2010-02-26 GSPC 0 @ 1104.49"

> cat('\n')


> # Chart results with quantmod
> chart.Posn(ltportfolio, Symbol = 'GSPC', Dates =
> '1998::',theme=chartTheme('white', up.col='lightgreen', dn.col='pink'),
> type='bar')
Hit <Return> to see next plot: 
Hit <Return> to see next plot: 
Hit <Return> to see next plot: 

> plot(addSMA(n=10,col='darkgreen', on=1))
Hit <Return> to see next plot: 

> getTxns(Portfolio="longtrend", Symbol="GSPC", Date="2000::2004")
           Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost
2000-01-31       0   1394.46        0         0          NaN
2000-02-29       0   1366.42        0         0          NaN
2000-03-31       0   1498.58        0         0          NaN
2000-04-28       0   1452.43        0         0          NaN
2000-05-31       0   1420.60        0         0          NaN
2000-06-30       0   1454.60        0         0          NaN
2000-07-31       0   1430.83        0         0          NaN
2000-08-31       0   1517.68        0         0          NaN
2002-03-28       0   1147.39        0         0          NaN
2003-04-30       0    916.92        0         0          NaN
2003-05-30       0    963.59        0         0          NaN
2003-06-30       0    974.50        0         0          NaN
2003-07-31       0    990.31        0         0          NaN
2003-08-29       0   1008.01        0         0          NaN
2003-09-30       0    995.97        0         0          NaN
2003-10-31       0   1050.71        0         0          NaN
2003-11-28       0   1058.20        0         0          NaN
2003-12-31       0   1111.92        0         0          NaN
2004-01-30       0   1131.13        0         0          NaN
2004-02-27       0   1144.94        0         0          NaN
2004-03-31       0   1126.21        0         0          NaN
2004-04-30       0   1107.30        0         0          NaN
2004-05-28       0   1120.68        0         0          NaN
2004-06-30       0   1140.84        0         0          NaN
2004-10-29       0   1130.20        0         0          NaN
2004-11-30       0   1173.82        0         0          NaN
2004-12-31       0   1211.92        0         0          NaN

> # Copy the results into the local environment
> print("Retrieving resulting portfolio and account")
[1] "Retrieving resulting portfolio and account"

> ltportfolio = getPortfolio("longtrend")

> ltaccount = getAccount("longtrend")
Warning messages:
1: In max(i) : no non-missing arguments to max; returning -Inf
2: In max(i) : no non-missing arguments to max; returning -Inf
3: In max(i) : no non-missing arguments to max; returning -Inf
4: In max(i) : no non-missing arguments to max; returning -Inf

I had the same warnings in my code. 
Is it normal, what quantity/position size is 0? 

-- 
View this message in context: http://n4.nabble.com/Blotter-package-problem-with-example-tp1018634p1573601.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Mon Mar  1 15:52:47 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 01 Mar 2010 08:52:47 -0600
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <1267453887141-1573601.post@n4.nabble.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>	<4B575039.7090103@braverock.com>	<1267384265779-1572896.post@n4.nabble.com>	<4B8AC33B.40903@braverock.com>	<1267388981726-1572940.post@n4.nabble.com>	<4B8AD399.8080802@braverock.com>	<1267395115970-1573015.post@n4.nabble.com>	<1267448596709-1573514.post@n4.nabble.com>	<4B8BC590.8080507@braverock.com>
	<1267453887141-1573601.post@n4.nabble.com>
Message-ID: <4B8BD4BF.7050004@braverock.com>

kafkaz wrote:
> <.. snip example ...>
> I had the same warnings in my code. 
> Is it normal, what quantity/position size is 0?
No, it's not normal.  Something is still not right in your environment.


I suspect that you are probably using old code that blotter depends on.


Try updating xts and quantmod to the current R-Forge versions. 
blotter has prompted many improvements and bugfixes in these packages, 
and the CRAN versions are lagging a bit.


For your reference, I've posted the output from the longtrend demo here:


http://www.braverock.com/brian/longtrend/


including a PDF of the chart.Posn output and the output of 
getPortfolio() and getAccount()

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From kafka at centras.lt  Mon Mar  1 16:23:36 2010
From: kafka at centras.lt (kafkaz)
Date: Mon, 1 Mar 2010 07:23:36 -0800 (PST)
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <4B8BD4BF.7050004@braverock.com>
References: <4B575039.7090103@braverock.com>
	<1267384265779-1572896.post@n4.nabble.com>
	<4B8AC33B.40903@braverock.com>
	<1267388981726-1572940.post@n4.nabble.com>
	<4B8AD399.8080802@braverock.com>
	<1267395115970-1573015.post@n4.nabble.com>
	<1267448596709-1573514.post@n4.nabble.com>
	<4B8BC590.8080507@braverock.com>
	<1267453887141-1573601.post@n4.nabble.com>
	<4B8BD4BF.7050004@braverock.com>
Message-ID: <1267457016526-1573671.post@n4.nabble.com>


install.packages("TTR", repos="http://R-Forge.R-project.org") 
install.packages("xts", repos="http://R-Forge.R-project.org") 
install.packages("quantmod", repos="http://R-Forge.R-project.org") 
install.packages("FinancialInstrument",
repos="http://R-Forge.R-project.org") 
q() #reboot

Unfortunately, it didn't solve the problem. 
-- 
View this message in context: http://n4.nabble.com/Blotter-package-problem-with-example-tp1018634p1573671.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From cedrick at cedrickjohnson.com  Mon Mar  1 16:31:49 2010
From: cedrick at cedrickjohnson.com (Cedrick Johnson)
Date: Mon, 1 Mar 2010 10:31:49 -0500
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <1267448596709-1573514.post@n4.nabble.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>
	<4B575039.7090103@braverock.com>
	<1267384265779-1572896.post@n4.nabble.com>
	<4B8AC33B.40903@braverock.com>
	<1267388981726-1572940.post@n4.nabble.com>
	<4B8AD399.8080802@braverock.com>
	<1267395115970-1573015.post@n4.nabble.com>
	<1267448596709-1573514.post@n4.nabble.com>
Message-ID: <3ad7fd721003010731u124abe98k6257385eb650ecc6@mail.gmail.com>

I would try update.packages instead of install....

Regards,
CJ

On 3/1/10, kafkaz <kafka at centras.lt> wrote:
>
> Could you explain, why equity goes down calling these functions:
> equity=getEndEq('acc',as.character(currentDate))
> print(paste('equity ',equity, ' date ',currentDate,' Spy ', SPY.monthly[i]))
> updatePortf(Portfolio = "prtf", Dates = as.character(currentDate))
> updateAcct("acc", Dates = as.character(currentDate))
> updateEndEq("acc", as.character(currentDate))
>
> [1] "equity  10000  date  1995-01-31  Spy  37.02"
> [1] "upAcc 1995-01-31"
> [1] "upEnd 1995-01-31"
> [1] "equity  10000  date  1995-02-28  Spy  38.54"
> [1] "upAcc 1995-02-28"
> [1] "upEnd 1995-02-28"
> [1] "equity  0  date  1995-03-31  Spy  39.64"
> [1] "upAcc 1995-03-31"
> [1] "upEnd 1995-03-31"
> [1] "equity  0  date  1995-04-28  Spy  40.81"
> [1] "upAcc 1995-04-28"
> [1] "upEnd 1995-04-28"
> [1] "equity  0  date  1995-05-31  Spy  42.43"
> [1] "upAcc 1995-05-31"
> [1] "upEnd 1995-05-31"
> [1] "equity  0  date  1995-06-30  Spy  43.29"
> [1] "upAcc 1995-06-30"
> [1] "upEnd 1995-06-30"
> [1] "equity  0  date  1995-07-31  Spy  44.68"
> [1] "upAcc 1995-07-31"
> [1] "upEnd 1995-07-31"
> [1] "equity  0  date  1995-08-31  Spy  44.88"
> [1] "upAcc 1995-08-31"
> [1] "upEnd 1995-08-31"
> [1] "equity  0  date  1995-09-29  Spy  46.77"
> [1] "upAcc 1995-09-29"
> [1] "upEnd 1995-09-29"
> [1] "equity  0  date  1995-10-31  Spy  46.64"
> [1] "buy"
> [1] "1995-10-31 SPY 0 @ 46.64"
> [1] "upAcc 1995-10-31"
> [1] "upEnd 1995-10-31"
>
> Latter on, it fails on updateEndEq("acc", as.character(currentDate))
>
> Error in if (length(c(year, month, day, hour, min, sec)) == 6 && c(year,  :
>   missing value where TRUE/FALSE needed
> In addition: Warning messages:
> 1: In as_numeric(YYYY) : NAs introduced by coercion
> 2: In as_numeric(YYYY) : NAs introduced by coercion
>
> Thank you.
>
> --
> View this message in context:
> http://n4.nabble.com/Blotter-package-problem-with-example-tp1018634p1573514.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

-- 
Sent from my mobile device


From kafka at centras.lt  Mon Mar  1 16:36:48 2010
From: kafka at centras.lt (kafkaz)
Date: Mon, 1 Mar 2010 07:36:48 -0800 (PST)
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <1267457016526-1573671.post@n4.nabble.com>
References: <1267384265779-1572896.post@n4.nabble.com>
	<4B8AC33B.40903@braverock.com>
	<1267388981726-1572940.post@n4.nabble.com>
	<4B8AD399.8080802@braverock.com>
	<1267395115970-1573015.post@n4.nabble.com>
	<1267448596709-1573514.post@n4.nabble.com>
	<4B8BC590.8080507@braverock.com>
	<1267453887141-1573601.post@n4.nabble.com>
	<4B8BD4BF.7050004@braverock.com>
	<1267457016526-1573671.post@n4.nabble.com>
Message-ID: <1267457808210-1573705.post@n4.nabble.com>


So, I tried on fresh Windows machine. I installed R 2.10 and all required
packages from http://R-Forge.R-project.org. Got the same, nasty behavior
with demo(longtrend). Something is wrong...
-- 
View this message in context: http://n4.nabble.com/Blotter-package-problem-with-example-tp1018634p1573705.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Mon Mar  1 16:42:54 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 01 Mar 2010 09:42:54 -0600
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <1267457016526-1573671.post@n4.nabble.com>
References: <4B575039.7090103@braverock.com>	<1267384265779-1572896.post@n4.nabble.com>	<4B8AC33B.40903@braverock.com>	<1267388981726-1572940.post@n4.nabble.com>	<4B8AD399.8080802@braverock.com>	<1267395115970-1573015.post@n4.nabble.com>	<1267448596709-1573514.post@n4.nabble.com>	<4B8BC590.8080507@braverock.com>	<1267453887141-1573601.post@n4.nabble.com>	<4B8BD4BF.7050004@braverock.com>
	<1267457016526-1573671.post@n4.nabble.com>
Message-ID: <4B8BE07E.9010600@braverock.com>

kafkaz wrote:
> install.packages("TTR", repos="http://R-Forge.R-project.org") 
> install.packages("xts", repos="http://R-Forge.R-project.org") 
> install.packages("quantmod", repos="http://R-Forge.R-project.org") 
> install.packages("FinancialInstrument",
> repos="http://R-Forge.R-project.org") 
> q() #reboot
>
> Unfortunately, it didn't solve the problem. 
>   

I've added another file:


http://ethos.braverock.com/brian/longtrend/sessioninfo.txt


that shows my sessionInfo() for a session that works as advertised.


You should probably examine your environment and see what's different.


And really, you could at least sign you messages with your first name, 
even if you've got some other reason to protect your identity.

Regards,

    - Brian



-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From breman.mark at gmail.com  Mon Mar  1 16:51:07 2010
From: breman.mark at gmail.com (Mark Breman)
Date: Mon, 1 Mar 2010 16:51:07 +0100
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <1267453887141-1573601.post@n4.nabble.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>
	<4B575039.7090103@braverock.com>
	<1267384265779-1572896.post@n4.nabble.com>
	<4B8AC33B.40903@braverock.com>
	<1267388981726-1572940.post@n4.nabble.com>
	<4B8AD399.8080802@braverock.com>
	<1267395115970-1573015.post@n4.nabble.com>
	<1267448596709-1573514.post@n4.nabble.com>
	<4B8BC590.8080507@braverock.com>
	<1267453887141-1573601.post@n4.nabble.com>
Message-ID: <5e6a2e671003010751p7052fe39p109dac5efe72ef89@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100301/3ea87cff/attachment.pl>

From daniel.cegielka at gmail.com  Mon Mar  1 16:52:26 2010
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Mon, 1 Mar 2010 16:52:26 +0100
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <4B8BE07E.9010600@braverock.com>
References: <4B575039.7090103@braverock.com>
	<1267388981726-1572940.post@n4.nabble.com>
	<4B8AD399.8080802@braverock.com>
	<1267395115970-1573015.post@n4.nabble.com>
	<1267448596709-1573514.post@n4.nabble.com>
	<4B8BC590.8080507@braverock.com>
	<1267453887141-1573601.post@n4.nabble.com>
	<4B8BD4BF.7050004@braverock.com>
	<1267457016526-1573671.post@n4.nabble.com>
	<4B8BE07E.9010600@braverock.com>
Message-ID: <5ddf2c611003010752p1bfd939fvcac3820b279cdb3d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100301/5b618123/attachment.pl>

From daniel.cegielka at gmail.com  Mon Mar  1 16:56:36 2010
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Mon, 1 Mar 2010 16:56:36 +0100
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <5e6a2e671003010751p7052fe39p109dac5efe72ef89@mail.gmail.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>
	<1267384265779-1572896.post@n4.nabble.com>
	<4B8AC33B.40903@braverock.com>
	<1267388981726-1572940.post@n4.nabble.com>
	<4B8AD399.8080802@braverock.com>
	<1267395115970-1573015.post@n4.nabble.com>
	<1267448596709-1573514.post@n4.nabble.com>
	<4B8BC590.8080507@braverock.com>
	<1267453887141-1573601.post@n4.nabble.com>
	<5e6a2e671003010751p7052fe39p109dac5efe72ef89@mail.gmail.com>
Message-ID: <5ddf2c611003010756t64900affif63601264dc1e42c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100301/3a35877f/attachment.pl>

From kafka at centras.lt  Mon Mar  1 17:02:37 2010
From: kafka at centras.lt (kafkaz)
Date: Mon, 1 Mar 2010 08:02:37 -0800 (PST)
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <5e6a2e671003010751p7052fe39p109dac5efe72ef89@mail.gmail.com>
References: <4B575039.7090103@braverock.com>
	<1267384265779-1572896.post@n4.nabble.com>
	<4B8AC33B.40903@braverock.com>
	<1267388981726-1572940.post@n4.nabble.com>
	<4B8AD399.8080802@braverock.com>
	<1267395115970-1573015.post@n4.nabble.com>
	<1267448596709-1573514.post@n4.nabble.com>
	<4B8BC590.8080507@braverock.com>
	<1267453887141-1573601.post@n4.nabble.com>
	<5e6a2e671003010751p7052fe39p109dac5efe72ef89@mail.gmail.com>
Message-ID: <1267459357343-1573759.post@n4.nabble.com>


Mark,
respect! That fixed demo() problem.

Thank you,
kafka
-- 
View this message in context: http://n4.nabble.com/Blotter-package-problem-with-example-tp1018634p1573759.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Mon Mar  1 17:14:02 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 01 Mar 2010 10:14:02 -0600
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <5e6a2e671003010751p7052fe39p109dac5efe72ef89@mail.gmail.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>	<4B575039.7090103@braverock.com>	<1267384265779-1572896.post@n4.nabble.com>	<4B8AC33B.40903@braverock.com>	<1267388981726-1572940.post@n4.nabble.com>	<4B8AD399.8080802@braverock.com>	<1267395115970-1573015.post@n4.nabble.com>	<1267448596709-1573514.post@n4.nabble.com>	<4B8BC590.8080507@braverock.com>	<1267453887141-1573601.post@n4.nabble.com>
	<5e6a2e671003010751p7052fe39p109dac5efe72ef89@mail.gmail.com>
Message-ID: <4B8BE7CA.50406@braverock.com>

Mark Breman wrote:
> Hi kafkaz,
>
> I also have this problem with the 0 size transactions if I run the
> demo(longtrend).
>
> It looks like there is a small bug in the longtrend.R script in the demo
> directory. The account is not initialized with a beginning equity.
>
> replace the line:
> initAcct(ltaccount,portfolios='longtrend', initDate=initDate)
>
> with:
> initAcct(ltaccount,portfolios='longtrend', initDate=initDate, initEq=initEq)
>
> Save the modification and run "demo(longtrend) again. This solved it for me.
>   

Thanks Mark (and Daniel and kafkaz for the confirmation).  I've updated 
the demo code and committed the changes to svn on R-Forge.

Regards,

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From rbali at ufmg.br  Mon Mar  1 20:24:04 2010
From: rbali at ufmg.br (Robert Iquiapaza)
Date: Mon, 1 Mar 2010 16:24:04 -0300
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <4B8BE7CA.50406@braverock.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>	<4B575039.7090103@braverock.com>	<1267384265779-1572896.post@n4.nabble.com>	<4B8AC33B.40903@braverock.com>	<1267388981726-1572940.post@n4.nabble.com>	<4B8AD399.8080802@braverock.com>	<1267395115970-1573015.post@n4.nabble.com>	<1267448596709-1573514.post@n4.nabble.com>	<4B8BC590.8080507@braverock.com>	<1267453887141-1573601.post@n4.nabble.com><5e6a2e671003010751p7052fe39p109dac5efe72ef89@mail.gmail.com>
	<4B8BE7CA.50406@braverock.com>
Message-ID: <59A2E329CD9D496BAEEC632A100FEA9D@DellPC>


Another problem:

It appears to be with index in quantmod

#In my case the result after running
getSymbols('^GSPC', src='yahoo', 
index.class=c("POSIXt","POSIXct"),from='1998-01-01')
GSPC

#is problematic, the last observation has <NA> index!

....
2010-02-22   1110.00   1112.29  1105.38    1108.01  3814440000       1108.01
2010-02-23   1107.49   1108.58  1092.18    1094.60  4521050000       1094.60
2010-02-24   1095.89   1106.42  1095.50    1105.24  4168360000       1105.24
2010-02-25   1101.24   1103.50  1086.02    1102.94  4521130000       1102.94
2010-02-26   1103.10   1107.24  1097.56    1104.49  3945190000       1104.49
<NA>         1130.51   1140.48  1128.12    1130.56  1659000000       1130.56

GSPC=to.monthly(GSPC, indexAt='endof')
GSPC
...
2010-01-29   1116.56   1150.45  1071.59    1073.87  90947579600 
1073.87
2010-02-26   1073.89   1112.42  1044.50    1104.49  84561340000 
1104.49
<NA>         1130.51   1140.48  1128.12    1130.56   1659000000 
1130.56

#So, the next sentence gives an error

> print("Setting up indicators")
[1] "Setting up indicators"
> GSPC$SMA10m <- SMA(GSPC[,grep('Adj',colnames(GSPC))], 10)
nan, nan
Error in merge.xts(..., all = all, fill = fill, suffixes = suffixes) :
  'NA' not allowed in 'index'

#If I drop the last observation, inserting the following code after 
to.monthly,

GSPC <- GSPC[1:(length(GSPC[,1])-1),]

#Then, everything goes well with the example.

Any ideas what could be wrong?

I have already reinstall some packages and the problem continues:
install.packages("TTR", repos="http://R-Forge.R-project.org")
install.packages("xts", repos="http://R-Forge.R-project.org")
install.packages("quantmod", repos="http://R-Forge.R-project.org")
install.packages("FinancialInstrument", 
repos="http://R-Forge.R-project.org")


Here is my system information:

> R.version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          10.1
year           2009
month          12
day            14
svn rev        50720
language       R
version.string R version 2.10.1 (2009-12-14)
> sessionInfo()
R version 2.10.1 (2009-12-14)
i386-pc-mingw32

locale:
[1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
[3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C
[5] LC_TIME=Portuguese_Brazil.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] blotter_0.4               FinancialInstrument_0.0.2 quantmod_0.3-14
[4] TTR_0.20-1                Defaults_1.1-1            xts_0.7-1
[7] zoo_1.6-2

loaded via a namespace (and not attached):
[1] grid_2.10.1    lattice_0.18-3

Regards,
Robert

--------------------------------------------------
From: "Brian G. Peterson" <brian at braverock.com>
Sent: Monday, March 01, 2010 1:14 PM
To: "Mark Breman" <breman.mark at gmail.com>
Cc: <r-sig-finance at stat.math.ethz.ch>; "kafkaz" <kafka at centras.lt>
Subject: Re: [R-SIG-Finance] Blotter package - problem with example.

> Mark Breman wrote:
>> Hi kafkaz,
>>
>> I also have this problem with the 0 size transactions if I run the
>> demo(longtrend).
>>
>> It looks like there is a small bug in the longtrend.R script in the demo
>> directory. The account is not initialized with a beginning equity.
>>
>> replace the line:
>> initAcct(ltaccount,portfolios='longtrend', initDate=initDate)
>>
>> with:
>> initAcct(ltaccount,portfolios='longtrend', initDate=initDate, 
>> initEq=initEq)
>>
>> Save the modification and run "demo(longtrend) again. This solved it for 
>> me.
>>
>
> Thanks Mark (and Daniel and kafkaz for the confirmation).  I've updated 
> the demo code and committed the changes to svn on R-Forge.
>
> Regards,
>
>  - Brian
>
> -- 
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions 
> should go.
>


From breman.mark at gmail.com  Mon Mar  1 20:37:20 2010
From: breman.mark at gmail.com (Mark Breman)
Date: Mon, 1 Mar 2010 20:37:20 +0100
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <59A2E329CD9D496BAEEC632A100FEA9D@DellPC>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>
	<1267388981726-1572940.post@n4.nabble.com>
	<4B8AD399.8080802@braverock.com>
	<1267395115970-1573015.post@n4.nabble.com>
	<1267448596709-1573514.post@n4.nabble.com>
	<4B8BC590.8080507@braverock.com>
	<1267453887141-1573601.post@n4.nabble.com>
	<5e6a2e671003010751p7052fe39p109dac5efe72ef89@mail.gmail.com>
	<4B8BE7CA.50406@braverock.com>
	<59A2E329CD9D496BAEEC632A100FEA9D@DellPC>
Message-ID: <5e6a2e671003011137vb7c3de7m3fe4b568c4e40529@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100301/2df776e7/attachment.pl>

From jeff.a.ryan at gmail.com  Mon Mar  1 20:41:26 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 1 Mar 2010 13:41:26 -0600
Subject: [R-SIG-Finance] Blotter package - problem with example.
In-Reply-To: <5e6a2e671003011137vb7c3de7m3fe4b568c4e40529@mail.gmail.com>
References: <e64efa441001201029k65b7f5cfx214030e524c7e110@mail.gmail.com>
	<4B8AD399.8080802@braverock.com>
	<1267395115970-1573015.post@n4.nabble.com>
	<1267448596709-1573514.post@n4.nabble.com>
	<4B8BC590.8080507@braverock.com>
	<1267453887141-1573601.post@n4.nabble.com>
	<5e6a2e671003010751p7052fe39p109dac5efe72ef89@mail.gmail.com>
	<4B8BE7CA.50406@braverock.com>
	<59A2E329CD9D496BAEEC632A100FEA9D@DellPC>
	<5e6a2e671003011137vb7c3de7m3fe4b568c4e40529@mail.gmail.com>
Message-ID: <e8e755251003011141n32ec7e66l4fb33454f5daf4e8@mail.gmail.com>

One item of note, Sys.timezone on Windows is tricky at best, and wrong
at worst.

Check and use Sys.setenv('TZ') or Sys.setenv(TZ="America/Chicago") instead.

You need to make sure that TZ is a legal variable, or else R (the OS)
will just ignore (no error) and carry on..

Bad things ensue...

Jeff

On Mon, Mar 1, 2010 at 1:37 PM, Mark Breman <breman.mark at gmail.com> wrote:
> Hi Robert,
>
> What is your timezone setting?
>
> type: Sys.timezone()
>
> If it's not ?"GMT" could you try:
> Sys.setenv(TZ="GMT")
> getSymbols('^GSPC', src='yahoo',
> index.class=c("POSIXt","POSIXct"),from='1998-01-01')
>
> and see if GSPC still has a NA in the last record?
>
> Regards,
>
> -Mark-
>
> 2010/3/1 Robert Iquiapaza <rbali at ufmg.br>
>
>>
>> Another problem:
>>
>> It appears to be with index in quantmod
>>
>> #In my case the result after running
>> getSymbols('^GSPC', src='yahoo',
>> index.class=c("POSIXt","POSIXct"),from='1998-01-01')
>> GSPC
>>
>> #is problematic, the last observation has <NA> index!
>>
>> ....
>> 2010-02-22 ? 1110.00 ? 1112.29 ?1105.38 ? ?1108.01 ?3814440000
>> 1108.01
>> 2010-02-23 ? 1107.49 ? 1108.58 ?1092.18 ? ?1094.60 ?4521050000
>> 1094.60
>> 2010-02-24 ? 1095.89 ? 1106.42 ?1095.50 ? ?1105.24 ?4168360000
>> 1105.24
>> 2010-02-25 ? 1101.24 ? 1103.50 ?1086.02 ? ?1102.94 ?4521130000
>> 1102.94
>> 2010-02-26 ? 1103.10 ? 1107.24 ?1097.56 ? ?1104.49 ?3945190000
>> 1104.49
>> <NA> ? ? ? ? 1130.51 ? 1140.48 ?1128.12 ? ?1130.56 ?1659000000
>> 1130.56
>>
>> GSPC=to.monthly(GSPC, indexAt='endof')
>> GSPC
>> ...
>> 2010-01-29 ? 1116.56 ? 1150.45 ?1071.59 ? ?1073.87 ?90947579600 1073.87
>> 2010-02-26 ? 1073.89 ? 1112.42 ?1044.50 ? ?1104.49 ?84561340000 1104.49
>> <NA> ? ? ? ? 1130.51 ? 1140.48 ?1128.12 ? ?1130.56 ? 1659000000 1130.56
>>
>> #So, the next sentence gives an error
>>
>> ?print("Setting up indicators")
>>>
>> [1] "Setting up indicators"
>>
>>> GSPC$SMA10m <- SMA(GSPC[,grep('Adj',colnames(GSPC))], 10)
>>>
>> nan, nan
>> Error in merge.xts(..., all = all, fill = fill, suffixes = suffixes) :
>> ?'NA' not allowed in 'index'
>>
>> #If I drop the last observation, inserting the following code after
>> to.monthly,
>>
>> GSPC <- GSPC[1:(length(GSPC[,1])-1),]
>>
>> #Then, everything goes well with the example.
>>
>> Any ideas what could be wrong?
>>
>> I have already reinstall some packages and the problem continues:
>> install.packages("TTR", repos="http://R-Forge.R-project.org")
>> install.packages("xts", repos="http://R-Forge.R-project.org")
>> install.packages("quantmod", repos="http://R-Forge.R-project.org")
>>
>> install.packages("FinancialInstrument", repos="
>> http://R-Forge.R-project.org")
>>
>>
>> Here is my system information:
>>
>> ?R.version
>>>
>> ? ? ? ? ? ? ?_
>> platform ? ? ? i386-pc-mingw32
>> arch ? ? ? ? ? i386
>> os ? ? ? ? ? ? mingw32
>> system ? ? ? ? i386, mingw32
>> status
>> major ? ? ? ? ?2
>> minor ? ? ? ? ?10.1
>> year ? ? ? ? ? 2009
>> month ? ? ? ? ?12
>> day ? ? ? ? ? ?14
>> svn rev ? ? ? ?50720
>> language ? ? ? R
>> version.string R version 2.10.1 (2009-12-14)
>>
>>> sessionInfo()
>>>
>> R version 2.10.1 (2009-12-14)
>> i386-pc-mingw32
>>
>> locale:
>> [1] LC_COLLATE=Portuguese_Brazil.1252 ?LC_CTYPE=Portuguese_Brazil.1252
>> [3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C
>> [5] LC_TIME=Portuguese_Brazil.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] blotter_0.4 ? ? ? ? ? ? ? FinancialInstrument_0.0.2 quantmod_0.3-14
>> [4] TTR_0.20-1 ? ? ? ? ? ? ? ?Defaults_1.1-1 ? ? ? ? ? ?xts_0.7-1
>> [7] zoo_1.6-2
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.10.1 ? ?lattice_0.18-3
>>
>> Regards,
>> Robert
>>
>> --------------------------------------------------
>> From: "Brian G. Peterson" <brian at braverock.com>
>> Sent: Monday, March 01, 2010 1:14 PM
>> To: "Mark Breman" <breman.mark at gmail.com>
>> Cc: <r-sig-finance at stat.math.ethz.ch>; "kafkaz" <kafka at centras.lt>
>> Subject: Re: [R-SIG-Finance] Blotter package - problem with example.
>>
>> ?Mark Breman wrote:
>>>
>>>> Hi kafkaz,
>>>>
>>>> I also have this problem with the 0 size transactions if I run the
>>>> demo(longtrend).
>>>>
>>>> It looks like there is a small bug in the longtrend.R script in the demo
>>>> directory. The account is not initialized with a beginning equity.
>>>>
>>>> replace the line:
>>>> initAcct(ltaccount,portfolios='longtrend', initDate=initDate)
>>>>
>>>> with:
>>>> initAcct(ltaccount,portfolios='longtrend', initDate=initDate,
>>>> initEq=initEq)
>>>>
>>>> Save the modification and run "demo(longtrend) again. This solved it for
>>>> me.
>>>>
>>>>
>>> Thanks Mark (and Daniel and kafkaz for the confirmation). ?I've updated
>>> the demo code and committed the changes to svn on R-Forge.
>>>
>>> Regards,
>>>
>>> ?- Brian
>>>
>>> --
>>> Brian G. Peterson
>>> http://braverock.com/brian/
>>> Ph: 773-459-4973
>>> IM: bgpbraverock
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>>
>>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From rbali at ufmg.br  Tue Mar  2 02:17:43 2010
From: rbali at ufmg.br (Robert Iquiapaza)
Date: Mon, 1 Mar 2010 22:17:43 -0300
Subject: [R-SIG-Finance] Blotter package - problem with example.
Message-ID: <3B1D6A4D23E348E7948D571D8573AE97@DellPC>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100301/d8bd552b/attachment.pl>

From matthieu.stigler at gmail.com  Tue Mar  2 10:08:29 2010
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Tue, 02 Mar 2010 10:08:29 +0100
Subject: [R-SIG-Finance] version 1.4.7 of vars: HC estimation
Message-ID: <4B8CD58D.9040305@gmail.com>

Hi

As also announced on r-pkgs, the package vars has been updated to 
version 1.4.7

The main change concerns the compatibility with the sandwich/lmtest 
package, thanks to the nice help of Achim Zeileis and Bernhard Pfaff.

One can hence now use heteroskedasticity-consistent covariance matrix 
for inference in VAR models. This is available through function 
coeftest() from lmtest package:

library(vars)
data(Canada)
va<-VAR(Canada, p=2)
coeftest(va, vcov.=vcovHC)


The second change is an implementation of this procedure for the granger 
causality() test, leading to a heteroskedasticity-robust version of the 
test:

causality(va, vcov.=vcovHC)

As the distribution of the test is different whether there is really 
heteroskedasticity or not, a wild bootstrap procedure has been implemented:

causality(va, vcov.=vcovHC, boot=TRUE)


Those procedures above are especially interesting when one is modelling 
a VAR and finds  heteroskedasicity but is reluctant to model a 
multivariate GARCH if the focus is only on the conditional mean 
parameters, as advocated by Hafner and Herwartz (2009).

Matthieu Stigler

Hafner, C. M. and Herwartz, H. (2009) Testing for linear vector
     autoregressive  dynamics under multivariate generalized
     autoregressive heteroskedasticity,  _Statistica Neerlandica_,
     *63*: 294-323


From joshchien at yahoo.com  Wed Mar  3 01:25:40 2010
From: joshchien at yahoo.com (JOSH CHIEN)
Date: Tue, 2 Mar 2010 16:25:40 -0800 (PST)
Subject: [R-SIG-Finance] RBloomberg Package Problem
Message-ID: <748115.25531.qm@web113107.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100302/5ccb7fae/attachment.pl>

From cedrick at cedrickjohnson.com  Wed Mar  3 01:32:07 2010
From: cedrick at cedrickjohnson.com (Cedrick Johnson)
Date: Tue, 2 Mar 2010 19:32:07 -0500
Subject: [R-SIG-Finance] RBloomberg Package Problem
In-Reply-To: <748115.25531.qm@web113107.mail.gq1.yahoo.com>
References: <748115.25531.qm@web113107.mail.gq1.yahoo.com>
Message-ID: <3ad7fd721003021632n1dbcb8c2idc303febc04701e5@mail.gmail.com>

Try a google search for the package, I ran into the same issue
installing on my new workstation yesterday.

-c

On 3/2/10, JOSH CHIEN <joshchien at yahoo.com> wrote:
> Hi R
> users,
> I?m using
> R on company?s computer, Bloomberg terminal.
> Here
> below is warning message as I have installed Rbloomberg and then to call
> Rbloomberg library.
> But, it
> seems not to work. How to solve for this problem ?
> thanks a lot.
>
>
> library(RBloomberg)
> Loading required
> package: RDCOMClient
> : package
> 'RDCOMClient' could not be loaded
> : Warning
> message:
> In library(pkg,
> character.only = TRUE, logical.return = TRUE, lib.loc = lib.loc)
> :
>   there is no package
> called 'RDCOMClient'
> 	[[alternative HTML version deleted]]
>
>

-- 
Sent from my mobile device


From hvollmeier at mac.com  Wed Mar  3 09:15:57 2010
From: hvollmeier at mac.com (hvollmeier)
Date: Wed, 3 Mar 2010 00:15:57 -0800 (PST)
Subject: [R-SIG-Finance] PerformanceAnalytics - show.symetric
Message-ID: <1267604157188-1576210.post@n4.nabble.com>


Setting the "show.symetric" argument to TRUE seems to be ignored when using
the "chart.BarVaR" or "charts.PerformanceSummary" function. ( i.e. to plot
the positive as well as negative values for method "StdDev" ). Anyone having
the same problem ?

I am using R 2.10.1 and PerformanceAnalytics package V. 1.0 on a MacBook Pro
with OS X 10.6.2 installed.

Regards
Helmuth
-- 
View this message in context: http://n4.nabble.com/PerformanceAnalytics-show-symetric-tp1576210p1576210.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Wed Mar  3 13:50:22 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 03 Mar 2010 06:50:22 -0600
Subject: [R-SIG-Finance] PerformanceAnalytics - show.symmetric
In-Reply-To: <1267604157188-1576210.post@n4.nabble.com>
References: <1267604157188-1576210.post@n4.nabble.com>
Message-ID: <4B8E5B0E.3060509@braverock.com>

Helmuth Vollmeier wrote:
> Setting the "show.symmetric" argument to TRUE seems to be ignored when using
> the "chart.BarVaR" or "charts.PerformanceSummary" function. ( i.e. to plot
> the positive as well as negative values for method "StdDev" ). Anyone having
> the same problem ?
>
> I am using R 2.10.1 and PerformanceAnalytics package V. 1.0 on a MacBook Pro
> with OS X 10.6.2 installed.
>   
Helmuth,

It's a bug.  Fixed in SVN on R-Forge.

Thanks!

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From hvollmeier at mac.com  Wed Mar  3 15:34:14 2010
From: hvollmeier at mac.com (hvollmeier)
Date: Wed, 3 Mar 2010 06:34:14 -0800 (PST)
Subject: [R-SIG-Finance] PerformanceAnalytics - show.symmetric
In-Reply-To: <4B8E5B0E.3060509@braverock.com>
References: <1267604157188-1576210.post@n4.nabble.com>
	<4B8E5B0E.3060509@braverock.com>
Message-ID: <1267626854229-1576617.post@n4.nabble.com>


Brian,

thank you for your prompt reply and the great package.

Regards
Helmuth


braverock wrote:
> 
> 
> It's a bug.  Fixed in SVN on R-Forge.
> 
> Thanks!
> 
>   - Brian
> 
> -- 
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
> 
> 
> Helmuth Vollmeier wrote:
>> Setting the "show.symmetric" argument to TRUE seems to be ignored when
>> using
>> the "chart.BarVaR" or "charts.PerformanceSummary" function. ( i.e. to
>> plot
>> the positive as well as negative values for method "StdDev" ). Anyone
>> having
>> the same problem ?
>>
>> I am using R 2.10.1 and PerformanceAnalytics package V. 1.0 on a MacBook
>> Pro
>> with OS X 10.6.2 installed.
>>   
> Helmuth,
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
> 
> 


-- 
View this message in context: http://n4.nabble.com/PerformanceAnalytics-show-symetric-tp1576210p1576617.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From lippelanna24 at hotmail.com  Thu Mar  4 21:51:23 2010
From: lippelanna24 at hotmail.com (lippel anna)
Date: Thu, 4 Mar 2010 21:51:23 +0100
Subject: [R-SIG-Finance] Problems using blp function
Message-ID: <COL108-W21801A44136B45945FD787C5390@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100304/0a2d8195/attachment.pl>

From robert.nicholson at gmail.com  Fri Mar  5 03:15:07 2010
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Fri, 5 Mar 2010 09:15:07 +0700
Subject: [R-SIG-Finance] Standard Deviations using Sliding window?
Message-ID: <880CFF9B-A79F-4866-8345-0D08217140EA@gmail.com>

Here was a naive attempt to do standard deviation with sliding window
>require(quantmod)
>getSymbols("AAPL")
> AAPL$STDDEV = sd(Cl(AAPL), 20)
> AAPL$SMA = SMA(Cl(AAPL), 10)
> AAPL

apparently sd doesn't work with a sliding window where was SMA does so it seems I need to look at SMA to see how the sliding window code is handled and write my own sd that uses a sliding window?

the SD columns up the same for all rows which isn't what I want.


From josh.m.ulrich at gmail.com  Fri Mar  5 03:23:57 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 4 Mar 2010 20:23:57 -0600
Subject: [R-SIG-Finance] Standard Deviations using Sliding window?
In-Reply-To: <880CFF9B-A79F-4866-8345-0D08217140EA@gmail.com>
References: <880CFF9B-A79F-4866-8345-0D08217140EA@gmail.com>
Message-ID: <8cca69991003041823i39f3993bu63e2a01188685db2@mail.gmail.com>

On Thu, Mar 4, 2010 at 8:15 PM, Robert Nicholson
<robert.nicholson at gmail.com> wrote:
> Here was a naive attempt to do standard deviation with sliding window
>>require(quantmod)
>>getSymbols("AAPL")
>> AAPL$STDDEV = sd(Cl(AAPL), 20)
>> AAPL$SMA = SMA(Cl(AAPL), 10)
>> AAPL
>
> apparently sd doesn't work with a sliding window where was SMA does so it seems

No, sd doesn't work with a sliding window, but there's nothing in ?sd
to indicate that it would.

> I need to look at SMA to see how the sliding window code is handled and write my
> own sd that uses a sliding window?
>
Yes, or you can just use the runSD function in TTR. ;-)

> the SD columns up the same for all rows which isn't what I want.
>
but that's exactly what it's documented to do...

Best,
Josh
--
Joshua Ulrich
FOSS Trading: www.fosstrading.com

> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From judsonm123 at yahoo.com  Fri Mar  5 15:17:49 2010
From: judsonm123 at yahoo.com (Judson m)
Date: Fri, 5 Mar 2010 06:17:49 -0800 (PST)
Subject: [R-SIG-Finance] Subject: Re: Standard Deviations using Sliding
	window?
Message-ID: <291701.34639.qm@web33008.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100305/23d191b1/attachment.pl>

From robert.nicholson at gmail.com  Fri Mar  5 17:15:08 2010
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Fri, 5 Mar 2010 23:15:08 +0700
Subject: [R-SIG-Finance] Subject: Re: Standard Deviations using Sliding
	window?
In-Reply-To: <291701.34639.qm@web33008.mail.mud.yahoo.com>
References: <291701.34639.qm@web33008.mail.mud.yahoo.com>
Message-ID: <6F7C22A3-AC2E-4D24-AA6F-89CFF0F2BD1C@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100305/e6c4419c/attachment.pl>

From maechler at stat.math.ethz.ch  Fri Mar  5 17:16:36 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 5 Mar 2010 17:16:36 +0100
Subject: [R-SIG-Finance] "Package", please ...
In-Reply-To: <291701.34639.qm@web33008.mail.mud.yahoo.com>
References: <291701.34639.qm@web33008.mail.mud.yahoo.com>
Message-ID: <19345.11876.62695.329457@lynne.math.ethz.ch>

>>>>> "Jm" == Judson m <judsonm123 at yahoo.com>
>>>>>     on Fri, 5 Mar 2010 06:17:49 -0800 (PST) writes:

    >> Here was a naive attempt to do standard deviation with
    >> sliding window
    >>> require(quantmod) getSymbols("AAPL") AAPL$STDDEV =
    >>> sd(Cl(AAPL), 20) AAPL$SMA = SMA(Cl(AAPL), 10) AAPL

    Jm> I am pretty sure that rollapply in the ZOO library would
    Jm> work for you.

There's neither "ZOO" nor would that be "library".

It is   "zoo"   and it  is a *package*.

Martin Maechler, ETH Zurich


From brian at braverock.com  Fri Mar  5 17:22:21 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 05 Mar 2010 10:22:21 -0600
Subject: [R-SIG-Finance] Subject: Re: Standard Deviations using Sliding
 window?
In-Reply-To: <6F7C22A3-AC2E-4D24-AA6F-89CFF0F2BD1C@gmail.com>
References: <291701.34639.qm@web33008.mail.mud.yahoo.com>
	<6F7C22A3-AC2E-4D24-AA6F-89CFF0F2BD1C@gmail.com>
Message-ID: <4B912FBD.3080302@braverock.com>

I think Josh's earlier suggestion of runSD is more along the lines of 
what you want.

While you can certainly do what you want via rollapply, your original 
example will work via

getSymbols('AAPL')
AAPL$STDDEV = runSD(Cl(AAPL), 20)
AAPL$SMA = SMA(Cl(AAPL), 10)

Regards,

    - Brian

Robert Nicholson wrote:
> Yep that's where I am now
>
> When I try
>
> getSymbols('AAPL')
> closes = Cl(AAPL)
> change = rollapply(closes['2010-02-25::'],width=2, function(x) { log(x[2]/x[1])}, by=1, align = "right", na.pad = TRUE)
>
> I end up with
>
> Error in switch(deparse(substitute(FUN)), mean = return(rollmean(data,  : 
>   switch: EXPR must return a length 1 vector
>
> this was what I expected
>
> rollapply(zoo(1:10), 2, sum, na.pad = TRUE, by = 1, align="right")
>  1  2  3  4  5  6  7  8  9 10 
> NA  3  5  7  9 11 13 15 17 19
>
> On Mar 5, 2010, at 9:17 PM, Judson m wrote:
>
>   
>>> Here was a naive attempt to do standard deviation with sliding window
>>>       
>>>> require(quantmod)
>>>> getSymbols("AAPL")
>>>> AAPL$STDDEV = sd(Cl(AAPL), 20)
>>>> AAPL$SMA = SMA(Cl(AAPL), 10)
>>>> AAPL
>>>>         
>> I am pretty sure that rollapply in the ZOO library would work for you. 
>>
>>
>>     
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>   


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From ggrothendieck at gmail.com  Fri Mar  5 17:30:53 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 5 Mar 2010 11:30:53 -0500
Subject: [R-SIG-Finance] Subject: Re: Standard Deviations using Sliding
	window?
In-Reply-To: <6F7C22A3-AC2E-4D24-AA6F-89CFF0F2BD1C@gmail.com>
References: <291701.34639.qm@web33008.mail.mud.yahoo.com>
	<6F7C22A3-AC2E-4D24-AA6F-89CFF0F2BD1C@gmail.com>
Message-ID: <971536df1003050830w1907a3c6tf6eda44e072a585e@mail.gmail.com>

You likely want just this:

diff(log(closes['2010-02-05::']))

or this:

   rollapply(as.zoo(whatever), ...)

(Actually I would have thought your command would have worked since
your object inherits from zoo and will check it out.)

On Fri, Mar 5, 2010 at 11:15 AM, Robert Nicholson
<robert.nicholson at gmail.com> wrote:
> Yep that's where I am now
>
> When I try
>
> getSymbols('AAPL')
> closes = Cl(AAPL)
> change = rollapply(closes['2010-02-25::'],width=2, function(x) { log(x[2]/x[1])}, by=1, align = "right", na.pad = TRUE)
>
> I end up with
>
> Error in switch(deparse(substitute(FUN)), mean = return(rollmean(data, ?:
> ?switch: EXPR must return a length 1 vector
>
> this was what I expected
>
> rollapply(zoo(1:10), 2, sum, na.pad = TRUE, by = 1, align="right")
> ?1 ?2 ?3 ?4 ?5 ?6 ?7 ?8 ?9 10
> NA ?3 ?5 ?7 ?9 11 13 15 17 19
>
> On Mar 5, 2010, at 9:17 PM, Judson m wrote:
>
>> > Here was a naive attempt to do standard deviation with sliding window
>> >>require(quantmod)
>> >>getSymbols("AAPL")
>> >> AAPL$STDDEV = sd(Cl(AAPL), 20)
>> >> AAPL$SMA = SMA(Cl(AAPL), 10)
>> >> AAPL
>>
>> I am pretty sure that rollapply in the ZOO library would work for you.
>>
>>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From ggrothendieck at gmail.com  Fri Mar  5 19:39:30 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 5 Mar 2010 13:39:30 -0500
Subject: [R-SIG-Finance] Subject: Re: Standard Deviations using Sliding
	window?
In-Reply-To: <971536df1003050830w1907a3c6tf6eda44e072a585e@mail.gmail.com>
References: <291701.34639.qm@web33008.mail.mud.yahoo.com>
	<6F7C22A3-AC2E-4D24-AA6F-89CFF0F2BD1C@gmail.com> 
	<971536df1003050830w1907a3c6tf6eda44e072a585e@mail.gmail.com>
Message-ID: <971536df1003051039k53bcc208ie95ed07f0ab8e32@mail.gmail.com>

On Fri, Mar 5, 2010 at 11:30 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> You likely want just this:
>
> diff(log(closes['2010-02-05::']))
>
> or this:
>
> ? rollapply(as.zoo(whatever), ...)
>
> (Actually I would have thought your command would have worked since
> your object inherits from zoo and will check it out.)

The problem seems to occur in deparsing the function.  The problem has
been fixed in the devel version of zoo but in the meantime an easy
workaround is to define the function in a separate line like this:

# workaround
f <- function(x) { log(x[2]/x[1]) }
change <- rollapply(closes['2010-02-25::'], width=2, FUN = f, align =
"right", na.pad = TRUE)


From nelson.ana at gmail.com  Fri Mar  5 23:37:51 2010
From: nelson.ana at gmail.com (Ana Nelson)
Date: Fri, 5 Mar 2010 22:37:51 +0000 (GMT)
Subject: [R-SIG-Finance] Problems using blp function
In-Reply-To: <COL108-W21801A44136B45945FD787C5390@phx.gbl>
Message-ID: <467758.01267828668758.JavaMail.ana@Ana-Nelsons-MacBook.local>

Hi, Anna,

Can you check if the equivalent query works in Excel using the Bloomberg Excel add-in?

Also can you try it with the DVD_HIST field instead of DVD_HIST_WITH_AMT_STATUS?

Regards,
Ana



----- Original Message -----
From: "lippel anna" <lippelanna24 at hotmail.com>
To: r-sig-finance at stat.math.ethz.ch
Sent: Thursday, 4 March, 2010 20:51:23 GMT +00:00 GMT Britain, Ireland, Portugal
Subject: [R-SIG-Finance] Problems using blp function


Hello, I want to retrieve the historical amount of the dividends plus their declaration date using the following code:
library(RBloomberg)
conn<-blpConnect(na.action="na")
divs<-blp(conn,"ABT UN Equity","DVD_HIST_WITH_AMT_STATUS") but it returns me the following error:
 and I get that error:
Error in blpSubscribe(conn, securities, fields, override_fields, overrides) : 
  Call to BLPSubscribe did not return any data!
anu idea
 		 	   		  
_________________________________________________________________
Navegue sem medo com o Internet Explorer 8. Clique aqui para instalar gratuitamente.

	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


From nelson.ana at gmail.com  Fri Mar  5 23:41:28 2010
From: nelson.ana at gmail.com (Ana Nelson)
Date: Fri, 5 Mar 2010 22:41:28 +0000 (GMT)
Subject: [R-SIG-Finance] RBloomberg Package Problem
In-Reply-To: <3ad7fd721003021632n1dbcb8c2idc303febc04701e5@mail.gmail.com>
Message-ID: <16816594.41267828886795.JavaMail.ana@Ana-Nelsons-MacBook.local>

There is currently no version of RDCOMClient for R 2.10, and RBloomberg depends on this package.

You can install RBloomberg on R 2.9 with:
install.packages("RBloomberg",repos="http://r.bloombergapi.com/")

This issue will be resolved very soon by switching to the new Java API which will remove the RDCOMClient dependency altogether. Will be announced on this list when available.




----- Original Message -----
From: "Cedrick Johnson" <cedrick at cedrickjohnson.com>
To: "JOSH CHIEN" <joshchien at yahoo.com>, "R-Finance" <r-sig-finance at stat.math.ethz.ch>
Sent: Wednesday, 3 March, 2010 00:32:07 GMT +00:00 GMT Britain, Ireland, Portugal
Subject: Re: [R-SIG-Finance] RBloomberg Package Problem

Try a google search for the package, I ran into the same issue
installing on my new workstation yesterday.

-c

On 3/2/10, JOSH CHIEN <joshchien at yahoo.com> wrote:
> Hi R
> users,
> I?m using
> R on company?s computer, Bloomberg terminal.
> Here
> below is warning message as I have installed Rbloomberg and then to call
> Rbloomberg library.
> But, it
> seems not to work. How to solve for this problem ?
> thanks a lot.
>
>
> library(RBloomberg)
> Loading required
> package: RDCOMClient
> : package
> 'RDCOMClient' could not be loaded
> : Warning
> message:
> In library(pkg,
> character.only = TRUE, logical.return = TRUE, lib.loc = lib.loc)
> :
>   there is no package
> called 'RDCOMClient'
> 	[[alternative HTML version deleted]]
>
>

-- 
Sent from my mobile device

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


From fly1985 at gmail.com  Sat Mar  6 14:23:09 2010
From: fly1985 at gmail.com (Yin ZHANG)
Date: Sat, 6 Mar 2010 21:23:09 +0800
Subject: [R-SIG-Finance] about Nelson-Siegel model fitting
Message-ID: <57f92e091003060523yd051b5u4b1d724b30cc6b0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100306/e8108809/attachment.pl>

From brian at braverock.com  Sat Mar  6 14:46:23 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 06 Mar 2010 07:46:23 -0600
Subject: [R-SIG-Finance] about Nelson-Siegel model fitting
In-Reply-To: <57f92e091003060523yd051b5u4b1d724b30cc6b0@mail.gmail.com>
References: <57f92e091003060523yd051b5u4b1d724b30cc6b0@mail.gmail.com>
Message-ID: <4B925CAF.8000604@braverock.com>

Yin ZHANG wrote:
> I am trying to fit the bond market data to the Nelson-Siegel term structure
> model. I have a series of bond price data, most of them are coupon bonds.
> According to the original Nelson-Siegel model setting, my objective is
> trying to get the paremeters that minimize the weighted/unweighted  sum of
> price errors squared.
>
> So, is there any simple way in R or any package that can do this job? I do
> not know any about non-linear optimization, so what I need is an easy to use
> package/code that can do the job.
>   
As is often the case, a simple search would have yielded the answer to 
this question:

RSiteSearch("Nelson-Siegel")

http://finzi.psych.upenn.edu/R/library/YieldCurve/html/Nelson.Siegel.html

Please search before posting.

   - Brian


From cmdr_rogue at hotmail.com  Sat Mar  6 15:10:14 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Sat, 06 Mar 2010 09:10:14 -0500
Subject: [R-SIG-Finance] about Nelson-Siegel model fitting
In-Reply-To: <57f92e091003060523yd051b5u4b1d724b30cc6b0@mail.gmail.com>
References: <57f92e091003060523yd051b5u4b1d724b30cc6b0@mail.gmail.com>
Message-ID: <BLU0-SMTP8F42AA7D7B4DE0AA5D0BCE2370@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100306/2cd25bbe/attachment.pl>

From brian at braverock.com  Sat Mar  6 15:14:47 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 06 Mar 2010 08:14:47 -0600
Subject: [R-SIG-Finance] about Nelson-Siegel model fitting
In-Reply-To: <57f92e091003060552x735970d1vc75cdce259bbb8@mail.gmail.com>
References: <57f92e091003060523yd051b5u4b1d724b30cc6b0@mail.gmail.com>	
	<4B925CAF.8000604@braverock.com>
	<57f92e091003060552x735970d1vc75cdce259bbb8@mail.gmail.com>
Message-ID: <4B926357.5020106@braverock.com>

Yin,

Please direct replies to the list.  More people looking at your problem 
means you're more likely to get an answer and we are (slightly) less 
likely to have to answer the same questions again for someone else.

Per the posting guide, it helps us to help you if you tell us what 
you've already tried, and be as specific as possible about what you need.

If you have the prices and coupon specifications you can calculate the 
spot yield quite easily.
For a non-technical introduction, see for example:
http://www.investopedia.com/articles/bonds/07/price_yield.asp

Then you can use Nelson-Siegel to calculate the term structure.

So, what's the problem? 

Please be specific so that people can help you.  Code examples help us 
help you.

Regards,

  - Brian



Yin ZHANG wrote:
> thanks for your note. I have tried that package before I post. But 
> that one only works when you already got a series of spot yields with 
> different maturities. My problem is my data set is just bond prices 
> together with their coupon specifications, which is qutie different 
> from the YieldCurve package.
>  
> Kindest
>  
> Yin
>
>
>  
> On Sat, Mar 6, 2010 at 9:46 PM, Brian G. Peterson <brian at braverock.com 
> <mailto:brian at braverock.com>> wrote:
>
>     Yin ZHANG wrote:
>
>         I am trying to fit the bond market data to the Nelson-Siegel
>         term structure
>         model. I have a series of bond price data, most of them are
>         coupon bonds.
>         According to the original Nelson-Siegel model setting, my
>         objective is
>         trying to get the paremeters that minimize the
>         weighted/unweighted  sum of
>         price errors squared.
>
>         So, is there any simple way in R or any package that can do
>         this job? I do
>         not know any about non-linear optimization, so what I need is
>         an easy to use
>         package/code that can do the job.
>          
>
>     As is often the case, a simple search would have yielded the
>     answer to this question:
>
>     RSiteSearch("Nelson-Siegel")
>
>     http://finzi.psych.upenn.edu/R/library/YieldCurve/html/Nelson.Siegel.html
>
>     Please search before posting.
>
>      - Brian
>
>


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From robert.nicholson at gmail.com  Sun Mar  7 02:06:05 2010
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Sun, 7 Mar 2010 08:06:05 +0700
Subject: [R-SIG-Finance] Adding columns to an XTS
Message-ID: <4A8BC6CC-7873-4A20-978E-CFBE56122F60@gmail.com>

If you're using rollapply with an existing XTS object from getSymbols what's the most appropriate way to add new columns to the object?

say you have

getSymbols('AAPL')
change = rollapply(Cl(AAPL),width=2, function(x) log(x[2]/x[1]), by=1, align = "right", na.pad = TRUE)
colnames(change) <- c('AAPL.change')

how can you get change into the original AAPL xts object whereby everything is lined up correctly?

From jeff.a.ryan at gmail.com  Sun Mar  7 02:29:37 2010
From: jeff.a.ryan at gmail.com (jeff.a.ryan at gmail.com)
Date: Sun, 7 Mar 2010 01:29:37 +0000
Subject: [R-SIG-Finance] Fw:  Adding columns to an XTS
Message-ID: <931246385-1267925378-cardhu_decombobulator_blackberry.rim.net-1966721364-@bda325.bisx.prod.on.blackberry>


Sent via BlackBerry from T-Mobile

-----Original Message-----
From: jeff.a.ryan at gmail.com
Date: Sun, 7 Mar 2010 01:28:57 
To: Robert Nicholson<robert.nicholson at gmail.com>
Subject: Re: [R-SIG-Finance] Adding columns to an XTS

Hi Robert,

Try ?merge.xts

That will do what you want. 

Best,
Jeff
------Original Message------
From: Robert Nicholson
Sender: r-sig-finance-bounces at stat.math.ethz.ch
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] Adding columns to an XTS
Sent: Mar 6, 2010 7:06 PM

If you're using rollapply with an existing XTS object from getSymbols what's the most appropriate way to add new columns to the object?

say you have

getSymbols('AAPL')
change = rollapply(Cl(AAPL),width=2, function(x) log(x[2]/x[1]), by=1, align = "right", na.pad = TRUE)
colnames(change) <- c('AAPL.change')

how can you get change into the original AAPL xts object whereby everything is lined up correctly?
_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


Sent via BlackBerry from T-Mobile

From robert.nicholson at gmail.com  Sun Mar  7 03:15:49 2010
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Sun, 7 Mar 2010 09:15:49 +0700
Subject: [R-SIG-Finance] Standard Deviations using Sliding window?
In-Reply-To: <8cca69991003041823i39f3993bu63e2a01188685db2@mail.gmail.com>
References: <880CFF9B-A79F-4866-8345-0D08217140EA@gmail.com>
	<8cca69991003041823i39f3993bu63e2a01188685db2@mail.gmail.com>
Message-ID: <2E943418-F6DB-49E0-ADF7-F96B3DAAD481@gmail.com>

currently using rollapply with sd so I assume that will do the same as runSD

On Mar 5, 2010, at 9:23 AM, Joshua Ulrich wrote:

> On Thu, Mar 4, 2010 at 8:15 PM, Robert Nicholson
> <robert.nicholson at gmail.com> wrote:
>> Here was a naive attempt to do standard deviation with sliding window
>>> require(quantmod)
>>> getSymbols("AAPL")
>>> AAPL$STDDEV = sd(Cl(AAPL), 20)
>>> AAPL$SMA = SMA(Cl(AAPL), 10)
>>> AAPL
>> 
>> apparently sd doesn't work with a sliding window where was SMA does so it seems
> 
> No, sd doesn't work with a sliding window, but there's nothing in ?sd
> to indicate that it would.
> 
>> I need to look at SMA to see how the sliding window code is handled and write my
>> own sd that uses a sliding window?
>> 
> Yes, or you can just use the runSD function in TTR. ;-)
> 
>> the SD columns up the same for all rows which isn't what I want.
>> 
> but that's exactly what it's documented to do...
> 
> Best,
> Josh
> --
> Joshua Ulrich
> FOSS Trading: www.fosstrading.com
> 
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>> 


From ggrothendieck at gmail.com  Sun Mar  7 03:27:19 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 6 Mar 2010 21:27:19 -0500
Subject: [R-SIG-Finance] Standard Deviations using Sliding window?
In-Reply-To: <2E943418-F6DB-49E0-ADF7-F96B3DAAD481@gmail.com>
References: <880CFF9B-A79F-4866-8345-0D08217140EA@gmail.com> 
	<8cca69991003041823i39f3993bu63e2a01188685db2@mail.gmail.com> 
	<2E943418-F6DB-49E0-ADF7-F96B3DAAD481@gmail.com>
Message-ID: <971536df1003061827l60193f9dx2d0fccfcdd28e7bf@mail.gmail.com>

Yes, try this:

> library(TTR)
> set.seed(1)
> x <- xts(rnorm(10), Sys.Date() - 1:10)
> runSD(x, 3)
                [,1]
2010-02-24        NA
2010-02-25        NA
2010-02-26 0.5615778
2010-02-27 0.1272629
2010-02-28 0.8369966
2010-03-01 0.7139071
2010-03-02 1.2083371
2010-03-03 1.2158018
2010-03-04 1.2207208
2010-03-05 0.5383504
> rollapply(x, 3, sd, align = "right", na.pad = TRUE)

2010-02-24        NA
2010-02-25        NA
2010-02-26 0.5615778
2010-02-27 0.1272629
2010-02-28 0.8369966
2010-03-01 0.7139071
2010-03-02 1.2083371
2010-03-03 1.2158018
2010-03-04 1.2207208
2010-03-05 0.5383504


On Sat, Mar 6, 2010 at 9:15 PM, Robert Nicholson
<robert.nicholson at gmail.com> wrote:
> currently using rollapply with sd so I assume that will do the same as runSD
>
> On Mar 5, 2010, at 9:23 AM, Joshua Ulrich wrote:
>
>> On Thu, Mar 4, 2010 at 8:15 PM, Robert Nicholson
>> <robert.nicholson at gmail.com> wrote:
>>> Here was a naive attempt to do standard deviation with sliding window
>>>> require(quantmod)
>>>> getSymbols("AAPL")
>>>> AAPL$STDDEV = sd(Cl(AAPL), 20)
>>>> AAPL$SMA = SMA(Cl(AAPL), 10)
>>>> AAPL
>>>
>>> apparently sd doesn't work with a sliding window where was SMA does so it seems
>>
>> No, sd doesn't work with a sliding window, but there's nothing in ?sd
>> to indicate that it would.
>>
>>> I need to look at SMA to see how the sliding window code is handled and write my
>>> own sd that uses a sliding window?
>>>
>> Yes, or you can just use the runSD function in TTR. ;-)
>>
>>> the SD columns up the same for all rows which isn't what I want.
>>>
>> but that's exactly what it's documented to do...
>>
>> Best,
>> Josh
>> --
>> Joshua Ulrich
>> FOSS Trading: www.fosstrading.com
>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions should go.
>>>
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From rex at nosyntax.net  Sun Mar  7 04:24:33 2010
From: rex at nosyntax.net (rex)
Date: Sat, 6 Mar 2010 19:24:33 -0800
Subject: [R-SIG-Finance] getOptionChain returns NULL data
Message-ID: <20100307032433.GI4232@nosyntax.net>

After Yahoo changed to the new option symbols this code returns:

> library(quantmod)
> amznOpts <- getOptionChain('AMZN', Exp = "2010-05")
> amznOpts
$calls
NULL

$puts
NULL

$symbol
[1] "AMZN"

It used to return:

$calls                                   
     Strike  Last   Chg   Bid   Ask   Vol    OI
[...]

$puts
     Strike  Last    Chg   Bid   Ask  Vol    OI
[...]

Is there a fix for this? 

If not, is there another convenient method to get option chain data using R?

I've searched w/o finding an answer.

Thanks,

-rex
-- 
While Linux is larger than Emacs, at least Linux has the excuse that it
needs to be. -- Linus Torvalds


From jeff.a.ryan at gmail.com  Sun Mar  7 05:18:53 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sat, 6 Mar 2010 22:18:53 -0600
Subject: [R-SIG-Finance] getOptionChain returns NULL data
In-Reply-To: <20100307032433.GI4232@nosyntax.net>
References: <20100307032433.GI4232@nosyntax.net>
Message-ID: <e8e755251003062018h3c583760p38d4ac027717cbd9@mail.gmail.com>

The quantmod on R-forge solves this issue (the OCC's new OSI key
initiative + yahoo = havoc).

Your other issue is that there is no 2010-05 exp...  There is 04 and
07 though...

You're sessionInfo or packageDescription output would typically be
useful in future emails.

HTH,
Jeff

> getOptionChain("AMZN",Exp="2010-04")
$calls
                   Strike  Last   Chg   Bid   Ask  Vol   OI
ZQN100417C00050000     50 68.20  0.00 78.65 79.10    3  178
ZQN100417C00055000     55 72.70  0.00 73.65 74.15    0  104
ZQN100417C00060000     60 68.15 -0.55 68.65 68.90    1   90
ZQN100417C00065000     65 51.50  0.00 63.65 64.15    0   89
ZQN100417C00070000     70 58.85  3.26 58.70 58.95   10  235
ZQN100417C00075000     75 53.85 11.52 53.70 53.95    5  414
QZN100417C00080000     80 48.85  3.35 48.75 48.95   10  607
QZN100417C00085000     85 43.40  9.75 43.80 44.00    1  553
QZN100417C00090000     90 37.90  0.10 38.85 39.05    8 1307
QZN100417C00095000     95 31.83  0.00 33.95 34.15    5  940
QZN100417C00100000    100 29.20  0.10 29.10 29.20   20 1841
QZN100417C00105000    105 24.40  0.20 24.25 24.40   32  641
QZN100417C00110000    110 19.60  0.20 19.65 19.75   93 1249
QZN100417C00115000    115 15.35  0.20 15.15 15.25  132 2383
QZN100417C00120000    120 11.11  0.01 11.10 11.15  455 7083
QZN100417C00125000    125  7.55 -0.15  7.55  7.60 1957 6470
QZN100417C00130000    130  4.71 -0.14  4.70  4.75 3479 6522
QZN100417C00135000    135  2.71 -0.16  2.70  2.73 1754 5704
QZN100417C00140000    140  1.50 -0.05  1.44  1.48 1799 7647
QZN100417C00145000    145  0.74 -0.09  0.73  0.77  348 4537
QZN100417C00150000    150  0.38 -0.02  0.38  0.40  100 4177
QZN100417C00155000    155  0.21  0.03  0.19  0.21   23 2161
QZN100417C00160000    160  0.11  0.00  0.10  0.13   85 2773
QZN100417C00165000    165  0.04  0.00  0.06  0.08    0 1600
QZN100417C00170000    170  0.01  0.00  0.04  0.07   10  829
QZN100417C00175000    175  0.05  0.00  0.01  0.07    0  988
QZN100417C00180000    180  0.03  0.00    NA  0.06   20 1135
QZN100417C00185000    185  0.03  0.00    NA  0.03    0  651
QZN100417C00190000    190  0.03  0.00    NA  0.05    0 1212
QZN100417C00195000    195  0.04  0.00    NA  0.04    0 2115
QZN100417C00200000    200  0.09  0.00    NA  0.04    0  262
QZN100417C00210000    210  0.03  0.00    NA  0.03    0 3415

$puts
                   Strike  Last   Chg   Bid   Ask  Vol    OI
ZQN100417P00050000     50  0.03  0.00    NA  0.04  190   953
ZQN100417P00055000     55  0.03  0.00    NA  0.04   81   524
ZQN100417P00060000     60  0.04  0.00    NA  0.05   35   244
ZQN100417P00065000     65  0.05  0.00  0.01  0.06    4  1079
ZQN100417P00070000     70  0.05  0.00  0.03  0.06    8   758
ZQN100417P00075000     75  0.05 -0.05  0.05  0.08   15   979
QZN100417P00080000     80  0.08 -0.03  0.07  0.10   32  2059
QZN100417P00085000     85  0.13  0.00  0.11  0.13   38  3703
QZN100417P00090000     90  0.18  0.00  0.17  0.18   17  2487
QZN100417P00095000     95  0.25 -0.01  0.23  0.25   32  6528
QZN100417P00100000    100  0.37 -0.02  0.35  0.36   75  8171
QZN100417P00105000    105  0.55 -0.04  0.53  0.56  161  4555
QZN100417P00110000    110  0.86 -0.11  0.85  0.88  644  5384
QZN100417P00115000    115  1.40 -0.13  1.39  1.43  569 12351
QZN100417P00120000    120  2.33 -0.17  2.29  2.32 1601  7001
QZN100417P00125000    125  3.75 -0.30  3.70  3.80 3144  4510
QZN100417P00130000    130  5.95 -0.30  5.90  6.00 1155  4691
QZN100417P00135000    135  8.90 -0.20  8.90  8.95  329  1415
QZN100417P00140000    140 12.65 -0.45 12.60 12.70   70  1675
QZN100417P00145000    145 16.99 -1.06 16.90 17.00   36  1208
QZN100417P00150000    150 22.05  0.14 21.50 21.65   52   535
QZN100417P00155000    155 26.85 -1.45 26.35 26.50    5   584
QZN100417P00160000    160 31.50 -3.18 31.25 31.40   12   298
QZN100417P00165000    165 36.45 -2.00 36.20 36.30   41   160
QZN100417P00170000    170 41.60  0.00 41.10 41.40   25   144
QZN100417P00175000    175 55.75  0.00 45.90 46.40    0    54
QZN100417P00180000    180 61.45  0.00 50.90 51.40    0    16
QZN100417P00185000    185 54.55  0.00 55.85 56.60    0    16
QZN100417P00195000    195 73.15  0.00 65.85 66.60    0    10
QZN100417P00200000    200 84.00  0.00 70.85 71.60    0    14

$symbol
[1] "AMZN"


On Sat, Mar 6, 2010 at 9:24 PM, rex <rex at nosyntax.net> wrote:
> After Yahoo changed to the new option symbols this code returns:
>
>> library(quantmod)
>> amznOpts <- getOptionChain('AMZN', Exp = "2010-05")
>> amznOpts
>
> $calls
> NULL
>
> $puts
> NULL
>
> $symbol
> [1] "AMZN"
>
> It used to return:
>
> $calls ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Strike ?Last ? Chg ? Bid ? Ask
> ? Vol ? ?OI
> [...]
>
> $puts
> ? ?Strike ?Last ? ?Chg ? Bid ? Ask ?Vol ? ?OI
> [...]
>
> Is there a fix for this?
> If not, is there another convenient method to get option chain data using R?
>
> I've searched w/o finding an answer.
>
> Thanks,
>
> -rex
> --
> While Linux is larger than Emacs, at least Linux has the excuse that it
> needs to be. -- Linus Torvalds
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From rex at nosyntax.net  Sun Mar  7 07:39:33 2010
From: rex at nosyntax.net (rex)
Date: Sat, 6 Mar 2010 22:39:33 -0800
Subject: [R-SIG-Finance] getOptionChain returns NULL data
In-Reply-To: <e8e755251003062018h3c583760p38d4ac027717cbd9@mail.gmail.com>
References: <20100307032433.GI4232@nosyntax.net>
	<e8e755251003062018h3c583760p38d4ac027717cbd9@mail.gmail.com>
Message-ID: <20100307063933.GJ4232@nosyntax.net>

Jeff Ryan <jeff.a.ryan at gmail.com> [2010-03-06 20:19]:
>The quantmod on R-forge solves this issue (the OCC's new OSI key
>initiative + yahoo = havoc).

Hello Jeff,

First, thanks very much for providing a very useful library.

>You're sessionInfo or packageDescription output would typically be
>useful in future emails.

Wasn't aware of them, thanks.

When getOptionChain() quit working (no thanks to OCC+Yahoo), the first
thing I did was go to:

http://www.quantmod.com/download/

and use the command:

> install.packages(c('xts','Defaults','quantmod'))

That didn't help, and the suggestion on the above page:

========================================================================
For the latest version of quantmod (and TTR) - download the source here:

    xts package source:     xts_0.0-15.tar.gz
    quantmod package source:     quantmod_0.3-6.tar.gz
    TTR package source:     TTR_0.14-0.tar.gz 
========================================================================

didn't seem likely to improve the situation, since
quantmod_0.3-6.tar.gz is quite old.

Thanks to your mention of R-forge, I used:

> install.packages("quantmod", repos="http://R-Forge.R-project.org")

and that upgraded from the 0.3-13 I was using to 0.3-14, which
fixed the problem.

Thank you very much for the help. 

For reference:

> sessionInfo()
R version 2.10.0 (2009-10-26)
i486-pc-linux-gnu

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] quantmod_0.3-14 TTR_0.20-1      Defaults_1.1-1  xts_0.7-0
[5] zoo_1.6-2

loaded via a namespace (and not attached):
[1] grid_2.10.0     lattice_0.17-26

-rex
-- 
"If a man is talking in the forest and no woman is there to hear him,
is he still wrong?"


From matthieu.stigler at gmail.com  Sun Mar  7 13:46:21 2010
From: matthieu.stigler at gmail.com (mat)
Date: Sun, 07 Mar 2010 13:46:21 +0100
Subject: [R-SIG-Finance] what's wrong with diff.zoo
Message-ID: <4B93A01D.60900@gmail.com>

Hi all

I have a strange output using diff.zoo, where diff reduces the dim 
object by more than 1:

See:
 >class(PPP)
[1] "zooreg" "zoo"  
 > frequency(PPP)
[1] 12
 > dim(PPP)
[1] 202   3
 > dim(diff(PPP))
[1] 67  3

#What is happening? Dim is not 201 3 as I would expect, like I get with ts:
 >dim(diff(as.ts(PPP)))
[1] 201   3

#Differentiation seems to be done only for selected months...
 > head(PPP)
          PriceIT   PriceUS ExRateUSIT
1973(1) 0.0000000 0.0000000  0.0000000
1973(2) 0.5089089 0.7017644  1.9819006
1973(3) 2.0202688 1.6298400  3.0273857
1973(4) 3.0153056 2.3202898 -0.6350275
1973(5) 4.4895300 3.0060137 -0.6944147
1973(6) 4.9761509 3.6870589 -1.6951727
 > head(diff(PPP))
           PriceIT   PriceUS ExRateUSIT
1973(4)  0.9950369 0.6904498 -3.6624133
1973(7)  0.4842643 0.2259853  2.3995976
1973(10) 0.9478780 0.8810579 -0.1979420
1974(1)  1.3730158 0.8620694 -6.4295795
1974(4)  1.2959112 0.4175387  0.2104218
1974(7)  2.4591418 0.8130157  0.9254661

#Series is from:
library(zoo)
source("priceLev.R") #see below

Thanks a lot for your help, I'm really stuck...

Mat

I had problems copy/paste this directly into R console, but saving it as 
priceLev.R and sourcing it was ok:


PPP<-structure(c(19.60000038147, 19.70000076294, 20, 20.20000076294,
20.5, 20.60000038147, 20.70000076294, 20.70000076294, 21, 21.20000076294,
21.29999923706, 21.70000076294, 22, 22.39999961853, 23, 23.29999923706,
23.70000076294, 24.10000038147, 24.70000076294, 25.20000076294,
26, 26.5, 27, 27.10000038147, 27.5, 27.89999961853, 27.89999961853,
28.20000076294, 28.5, 28.79999923706, 28.89999961853, 29.10000038147,
29.29999923706, 29.70000076294, 30, 30.29999923706, 30.5, 31,
31.70000076294, 32.70000076294, 33.20000076294, 33.29999923706,
33.5, 33.79999923706, 34.40000152588, 35.59999847412, 36.29999923706,
36.79999923706, 37.29999923706, 38.09999847412, 38.79999923706,
39.20000076294, 39.70000076294, 40, 40.29999923706, 40.70000076294,
41.09999847412, 41.40000152588, 42.09999847412, 42.29999923706,
42.79999923706, 43.20000076294, 43.59999847412, 44.09999847412,
44.59999847412, 44.90000152588, 45.29999923706, 45.40000152588,
46.09999847412, 46.59999847412, 47, 47.40000152588, 48.29999923706,
48.90000152588, 49.70000076294, 50.40000152588, 51.09999847412,
51.59999847412, 52, 52.59999847412, 53.79999923706, 55.09999847412,
55.70000076294, 56.70000076294, 58.5, 59.59999847412, 60.20000076294,
61, 61.59999847412, 62.09999847412, 63.20000076294, 63.90000152588,
65.30000305176, 66.40000152588, 67.80000305176, 68.69999694824,
69.90000152588, 71.19999694824, 72.19999694824, 73.30000305176,
74.19999694824, 75, 75.69999694824, 76.19999694824, 77.30000305176,
78.69999694824, 80.09999847412, 80.90000152588, 82, 83.09999847412,
83.80000305176, 84.5, 85.5, 86.40000152588, 87.69999694824, 89.30000305176,
90.5, 92.30000305176, 93.5, 94.09999847412, 95.40000152588, 96.80000305176,
97.59999847412, 98.59999847412, 99.59999847412, 100.19999694824,
101.09999847412, 101.5, 102.80000305176, 104.5, 105.59999847412,
106.09999847412, 107.40000152588, 108.5, 109.19999694824, 110.09999847412,
110.69999694824, 111.30000305176, 111.69999694824, 112, 112.90000152588,
114, 114.69999694824, 115.40000152588, 116.59999847412, 117.80000305176,
118.69999694824, 119.69999694824, 120.40000152588, 121, 121.5,
121.69999694824, 122.19999694824, 123.69999694824, 124.5, 125.30000305176,
126, 126.80000305176, 127.30000305176, 127.59999847412, 128.10000610352,
128.60000610352, 128.60000610352, 128.89999389648, 129.19999694824,
130, 130.39999389648, 130.80000305176, 131.60000610352, 132.10000610352,
132.60000610352, 133, 133.5, 133.89999389648, 134.30000305176,
134.69999694824, 135.60000610352, 136.89999389648, 137.19999694824,
137.5, 138.19999694824, 138.5, 139.19999694824, 139.60000610352,
140, 140.5, 140.89999389648, 141.5, 142.19999694824, 143.30000305176,
144.5, 145, 146.10000610352, 147.30000305176, 148, 149, 149.60000610352,
150.30000305176, 150.69999694824, 150.89999389648, 151.60000610352,
153.10000610352, 42.5999984741, 42.9000015259, 43.2999992371,
43.5999984741, 43.9000015259, 44.2000007629, 44.2999992371, 45.0999984741,
45.2000007629, 45.5999984741, 45.9000015259, 46.2000007629, 46.5999984741,
47.2000007629, 47.7999992371, 48, 48.5999984741, 49, 49.4000015259,
50, 50.5999984741, 51.0999984741, 51.5, 51.9000015259, 52.0999984741,
52.5, 52.7000007629, 52.9000015259, 53.2000007629, 53.5999984741,
54.2000007629, 54.2999992371, 54.5999984741, 54.9000015259, 55.2999992371,
55.5, 55.5999984741, 55.7999992371, 55.9000015259, 56.0999984741,
56.5, 56.7999992371, 57.0999984741, 57.4000015259, 57.5999984741,
57.9000015259, 58, 58.2000007629, 58.5, 59.0999984741, 59.5,
60, 60.2999992371, 60.7000007629, 61, 61.2000007629, 61.4000015259,
61.5999984741, 61.9000015259, 62.0999984741, 62.5, 62.9000015259,
63.4000015259, 63.9000015259, 64.5, 65.1999969482, 65.6999969482,
66, 66.5, 67.0999984741, 67.4000015259, 67.6999969482, 68.3000030518,
69.0999984741, 69.8000030518, 70.5999984741, 71.5, 72.3000030518,
73.0999984741, 73.8000030518, 74.5999984741, 75.1999969482, 75.9000015259,
76.6999969482, 77.8000030518, 78.9000015259, 80.0999984741, 81,
81.8000030518, 82.6999969482, 82.6999969482, 83.3000030518, 84,
84.8000030518, 85.5, 86.3000030518, 87, 87.9000015259, 88.5,
89.0999984741, 89.8000030518, 90.5999984741, 91.5999984741, 92.3000030518,
93.1999969482, 93.4000015259, 93.6999969482, 94, 94.3000030518,
94.5999984741, 94.5, 94.9000015259, 95.8000030518, 97, 97.5,
97.6999969482, 97.9000015259, 98.1999969482, 98, 97.5999984741,
97.8000030518, 97.9000015259, 97.9000015259, 98.5999984741, 99.1999969482,
99.5, 99.9000015259, 100.1999969482, 100.6999969482, 101, 101.1999969482,
101.3000030518, 101.9000015259, 102.4000015259, 102.5999984741,
103.0999984741, 103.4000015259, 103.6999969482, 104.0999984741,
104.5, 105, 105.3000030518, 105.3000030518, 105.3000030518, 105.5,
106, 106.4000015259, 106.9000015259, 107.3000030518, 107.5999984741,
107.8000030518, 108, 108.3000030518, 108.6999969482, 109, 109.3000030518,
109.5999984741, 109.3000030518, 108.8000030518, 108.5999984741,
108.9000015259, 109.5, 109.5, 109.6999969482, 110.1999969482,
110.3000030518, 110.4000015259, 110.5, 111.1999969482, 111.5999984741,
112.0999984741, 112.6999969482, 113.0999984741, 113.5, 113.8000030518,
114.4000015259, 115, 115.3000030518, 115.4000015259, 115.4000015259,
115.6999969482, 116, 116.5, 117.0999984741, 117.5, 118, 118.5,
119, 119.8000030518, 120.1999969482, 120.3000030518, 120.5, 121.0999984741,
121.5999984741, 122.3000030518, 123.0999984741, 123.8000030518,
124.0999984741, 124.4000015259, 124.5999984741, 125, 125.5999984741,
0.00170791273132914, 0.00174209951913706, 0.00176040845258218,
0.00169710137902025, 0.00169609381850337, 0.0016792046735684,
0.00171998616788486, 0.00174231201103162, 0.00176909737593850,
0.00176559905254172, 0.00169038840243291, 0.00164579257106955,
0.00154330508995765, 0.00152751052610713, 0.00156870134431149,
0.00157200571003395, 0.00158080266451816, 0.00153789372388514,
0.00155219247186651, 0.00152690408919378, 0.00151030025882740,
0.0014992053772286, 0.00149961004098130, 0.00151791138210253,
0.00155041165776418, 0.00156779122961396, 0.00158420865760686,
0.00157669023618497, 0.00159370176532851, 0.00159820997361459,
0.00153869820346857, 0.00149628918637955, 0.00147399143728242,
0.00147449127396179, 0.00147210366254964, 0.001464493321869,
0.00142450142450142, 0.00130210030432208, 0.00121129900062598,
0.00113710017662363, 0.00116759682220348, 0.00117799501854215,
0.00119430080008036, 0.00119360230910755, 0.00118369811305430,
0.00116840174992149, 0.00115540150202195, 0.00115210030473245,
0.00113720364788047, 0.00113269527966656, 0.00112759908181671,
0.00112640515330342, 0.00112790438476952, 0.00112949684031799,
0.00113300327052292, 0.00113319581068863, 0.0011317978765388,
0.00113530572839516, 0.00113879652617039, 0.00114160461084470,
0.00114689423295764, 0.00116189904399275, 0.00116919410456185,
0.00116440190827110, 0.00114880470740695, 0.00116339946972441,
0.00118040065178541, 0.00119520008695516, 0.00120499348594498,
0.00123169392646559, 0.00118570513198108, 0.00118629587872915,
0.00119550017935439, 0.00118989544621630, 0.00118880621116386,
0.00118580356321465, 0.00117439812096301, 0.00118280204099774,
0.00121919992832387, 0.00122189634673585, 0.00123260489724270,
0.00121119629142077, 0.00121119629142077, 0.00123289363839214,
0.00124269912368631, 0.00123459841491511, 0.00116349423223834,
0.00114169585595958, 0.00118600047471892, 0.00119730364063127,
0.00120260238929126, 0.00118009415111576, 0.00117420504297619,
0.00114409932379843, 0.00110000106750649, 0.00107040024502102,
0.00104718620797518, 0.000980613256761468, 0.000969649910456641,
0.000927867583147656, 0.000876370465502322, 0.000843525938422606,
0.000823295979829121, 0.000803735801681492, 0.000842027275228413,
0.000837303506576214, 0.00083921485467683, 0.000828939961655155,
0.000814186402967888, 0.000791652779081, 0.000773221759850004,
0.000756658609619449, 0.00077919851937074, 0.000736143901754949,
0.000723452890870574, 0.000718081299390519, 0.00070862183088102,
0.000694473409094806, 0.000680809361993181, 0.000714929155512817,
0.00072742616872993, 0.000714397961872782, 0.000699437666460164,
0.00068853453006531, 0.000681310291427974, 0.00066182213723944,
0.000652141291441826, 0.000629033682327389, 0.000623978237540331,
0.000631787746464218, 0.000615085574381394, 0.000599923208071712,
0.000585950087094921, 0.000600099611261314, 0.000619513417282865,
0.000610321768907887, 0.000589511431606801, 0.000590040105729007,
0.000571043507422813, 0.000561649461352701, 0.000534533528145891,
0.000526598495131594, 0.000536754233000383, 0.000522870343728599,
0.000513146818997007, 0.000489715964740451, 0.000481116189559779,
0.000506101044383357, 0.000503917974554817, 0.000511791668803899,
0.000526224404774398, 0.000533757489838498, 0.000525370111122406,
0.000560089149346125, 0.000570216463691828, 0.000583600817041144,
0.000601272286874565, 0.000629639672710148, 0.000645815416462228,
0.000641251743442265, 0.000654236179260713, 0.000652273182391623,
0.000676448079471965, 0.000704061753916339, 0.000709104198499191,
0.000720632404196826, 0.000713735141009144, 0.000724931887198181,
0.000759203418417369, 0.0007705703819913, 0.000765755403403666,
0.000773419154661628, 0.000774713326752632, 0.000759589821496392,
0.000747406521267597, 0.000743947953430204, 0.000762857979627377,
0.00076770719167874, 0.000807174154425746, 0.000830744187376882,
0.000821773713091906, 0.000800243277082303, 0.000806016075652368,
0.00080580827232252, 0.000794401024342725, 0.000765954804926349,
0.00073138978164888, 0.000715343373114671, 0.00071779778378185,
0.000738901704515748, 0.000769100631071927, 0.000771837212823204,
0.000743428098333353, 0.000737854892260688, 0.000728597449908925,
0.000728969211551167, 0.000706299507030033, 0.000697155593265228,
0.000731320244617571, 0.000722418082886736, 0.00071215938252162,
0.000730332160273162), .Dim = c(202L, 3L), .Dimnames = list(NULL,
    c("PriceIT", "PriceUS", "ExRateUSIT")), index = c(1973,
1973.08333333333, 1973.16666666667, 1973.25, 1973.33333333333,
1973.41666666667, 1973.5, 1973.58333333333, 1973.66666666667,
1973.75, 1973.83333333333, 1973.91666666667, 1974, 1974.08333333333,
1974.16666666667, 1974.25, 1974.33333333333, 1974.41666666667,
1974.5, 1974.58333333333, 1974.66666666667, 1974.75, 1974.83333333333,
1974.91666666667, 1975, 1975.08333333333, 1975.16666666667, 1975.25,
1975.33333333333, 1975.41666666667, 1975.5, 1975.58333333333,
1975.66666666667, 1975.75, 1975.83333333333, 1975.91666666667,
1976, 1976.08333333333, 1976.16666666667, 1976.25, 1976.33333333333,
1976.41666666667, 1976.5, 1976.58333333333, 1976.66666666667,
1976.75, 1976.83333333333, 1976.91666666667, 1977, 1977.08333333333,
1977.16666666667, 1977.25, 1977.33333333333, 1977.41666666667,
1977.5, 1977.58333333333, 1977.66666666667, 1977.75, 1977.83333333333,
1977.91666666667, 1978, 1978.08333333333, 1978.16666666667, 1978.25,
1978.33333333333, 1978.41666666667, 1978.5, 1978.58333333333,
1978.66666666667, 1978.75, 1978.83333333333, 1978.91666666667,
1979, 1979.08333333333, 1979.16666666667, 1979.25, 1979.33333333333,
1979.41666666667, 1979.5, 1979.58333333333, 1979.66666666667,
1979.75, 1979.83333333333, 1979.91666666667, 1980, 1980.08333333333,
1980.16666666667, 1980.25, 1980.33333333333, 1980.41666666667,
1980.5, 1980.58333333333, 1980.66666666667, 1980.75, 1980.83333333333,
1980.91666666667, 1981, 1981.08333333333, 1981.16666666667, 1981.25,
1981.33333333333, 1981.41666666667, 1981.5, 1981.58333333333,
1981.66666666667, 1981.75, 1981.83333333333, 1981.91666666667,
1982, 1982.08333333333, 1982.16666666667, 1982.25, 1982.33333333333,
1982.41666666667, 1982.5, 1982.58333333333, 1982.66666666667,
1982.75, 1982.83333333333, 1982.91666666667, 1983, 1983.08333333333,
1983.16666666667, 1983.25, 1983.33333333333, 1983.41666666667,
1983.5, 1983.58333333333, 1983.66666666667, 1983.75, 1983.83333333333,
1983.91666666667, 1984, 1984.08333333333, 1984.16666666667, 1984.25,
1984.33333333333, 1984.41666666667, 1984.5, 1984.58333333333,
1984.66666666667, 1984.75, 1984.83333333333, 1984.91666666667,
1985, 1985.08333333333, 1985.16666666667, 1985.25, 1985.33333333333,
1985.41666666667, 1985.5, 1985.58333333333, 1985.66666666667,
1985.75, 1985.83333333333, 1985.91666666667, 1986, 1986.08333333333,
1986.16666666667, 1986.25, 1986.33333333333, 1986.41666666667,
1986.5, 1986.58333333333, 1986.66666666667, 1986.75, 1986.83333333333,
1986.91666666667, 1987, 1987.08333333333, 1987.16666666667, 1987.25,
1987.33333333333, 1987.41666666667, 1987.5, 1987.58333333333,
1987.66666666667, 1987.75, 1987.83333333333, 1987.91666666667,
1988, 1988.08333333333, 1988.16666666667, 1988.25, 1988.33333333333,
1988.41666666667, 1988.5, 1988.58333333333, 1988.66666666667,
1988.75, 1988.83333333333, 1988.91666666667, 1989, 1989.08333333333,
1989.16666666667, 1989.25, 1989.33333333333, 1989.41666666667,
1989.5, 1989.58333333333, 1989.66666666667, 1989.75), class = c("zooreg",
"zoo"), frequency = 12)


sessionInfo()
R version 2.9.2 (2009-08-24)
x86_64-pc-linux-gnu

locale:
LC_CTYPE=fr_CH.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CH.UTF-8;LC_COLLATE=fr_CH.UTF-8;LC_MONETARY=fr_CH.UTF-8;LC_MESSAGES=fr_CH.UTF-8;LC_PAPER=fr_CH.UTF-8;LC_NAME=fr_CH.UTF-8;LC_ADDRESS=fr_CH.UTF-8;LC_TELEPHONE=fr_CH.UTF-8;LC_MEASUREMENT=fr_CH.UTF-8;LC_IDENTIFICATION=fr_CH.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base    

other attached packages:
[1] zoo_1.6-2    rkward_0.5.1

loaded via a namespace (and not attached):
[1] grid_2.9.2      lattice_0.17-26 tools_2.9.2


From ggrothendieck at gmail.com  Sun Mar  7 14:14:12 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 7 Mar 2010 08:14:12 -0500
Subject: [R-SIG-Finance] what's wrong with diff.zoo
In-Reply-To: <4B93A01D.60900@gmail.com>
References: <4B93A01D.60900@gmail.com>
Message-ID: <971536df1003070514m62909b82jbd7cafe49c67390c@mail.gmail.com>

Its best to cut down your data as much as possible when posting.
Using the first 10 rows of PPP seems sufficient to illustrate this:

> P <- head(PPP, 10)
> diff(P)
           PriceIT    PriceUS    ExRateUSIT
1973(4)  0.2000008 0.29999924 -6.330707e-05
1973(7)  0.1000004 0.09999847  4.078149e-05
1973(10) 0.2000008 0.39999771 -3.498323e-06

Here is the dput output for just those 10 rows in case there are follow ups:

P <- structure(c(19.60000038147, 19.70000076294, 20, 20.20000076294,
20.5, 20.60000038147, 20.70000076294, 20.70000076294, 21, 21.20000076294,
42.5999984741, 42.9000015259, 43.2999992371, 43.5999984741, 43.9000015259,
44.2000007629, 44.2999992371, 45.0999984741, 45.2000007629, 45.5999984741,
0.00170791273132914, 0.00174209951913706, 0.00176040845258218,
0.00169710137902025, 0.00169609381850337, 0.0016792046735684,
0.00171998616788486, 0.00174231201103162, 0.0017690973759385,
0.00176559905254172), .Dim = c(10L, 3L), .Dimnames = list(NULL,
    c("PriceIT", "PriceUS", "ExRateUSIT")), index = c(1973, 1973.08333333333,
1973.16666666667, 1973.25, 1973.33333333333, 1973.41666666667,
1973.5, 1973.58333333333, 1973.66666666667, 1973.75), class = c("zooreg",
"zoo"), frequency = 12)

The problem appears to be small differences between P and lag(P, -1).
Note sure if this is a problem with this specific object (how was it
created?) or if its a general problem.  We can see the problem by
merging P with lag(P, -1) :

> merge(P, lag(P, -1))
                   PriceIT.P PriceUS.P ExRateUSIT.P PriceIT.lag(P, -1)
PriceUS.lag(P, -1) ExRateUSIT.lag(P, -1)
1973(1)                 19.6      42.6  0.001707913                 NA
                NA                    NA
1973(26178848280)       19.7      42.9  0.001742100                 NA
                NA                    NA
1973(26178848281)         NA        NA           NA               19.6
              42.6           0.001707913
1973(52357696562)         NA        NA           NA               19.7
              42.9           0.001742100
1973(52357696563)       20.0      43.3  0.001760408                 NA
                NA                    NA
1973(78536544842)       20.2      43.6  0.001697101               20.0
              43.3           0.001760408
1973(104715393122)      20.5      43.9  0.001696094                 NA
                NA                    NA
1973(104715393123)        NA        NA           NA               20.2
              43.6           0.001697101
1973(130894241403)        NA        NA           NA               20.5
              43.9           0.001696094
1973(130894241404)      20.6      44.2  0.001679205                 NA
                NA                    NA
1973(157073089683)      20.7      44.3  0.001719986               20.6
              44.2           0.001679205
1973(183251937963)      20.7      45.1  0.001742312                 NA
                NA                    NA
1973(183251937964)        NA        NA           NA               20.7
              44.3           0.001719986
1973(209430786244)        NA        NA           NA               20.7
              45.1           0.001742312
1973(209430786245)      21.0      45.2  0.001769097                 NA
                NA                    NA
1973(235609634525)      21.2      45.6  0.001765599               21.0
              45.2           0.001769097
1973(261788482805)        NA        NA           NA               21.2
              45.6           0.001765599

Will look at the problem but in the meantime here are three workarounds:

> # 1. fix up the time scale as it seems slightly off a 12 point cycle
> P0 <- aggregate(P, round(12 * time(P))/12, identity)
> diff(P0)
           PriceIT    PriceUS    ExRateUSIT
1973(2)  0.1000004 0.30000305  3.418679e-05
1973(3)  0.2999992 0.39999771  1.830893e-05
1973(4)  0.2000008 0.29999924 -6.330707e-05
1973(5)  0.2999992 0.30000305 -1.007561e-06
1973(6)  0.1000004 0.29999924 -1.688914e-05
1973(7)  0.1000004 0.09999847  4.078149e-05
1973(8)  0.0000000 0.79999924  2.232584e-05
1973(9)  0.2999992 0.10000229  2.678536e-05
1973(10) 0.2000008 0.39999771 -3.498323e-06

> # 2. use zoo instead of zooreg
> diff(as.zoo(P))
            PriceIT    PriceUS    ExRateUSIT
1973.0833 0.1000004 0.30000305  3.418679e-05
1973.1667 0.2999992 0.39999771  1.830893e-05
1973.25   0.2000008 0.29999924 -6.330707e-05
1973.3333 0.2999992 0.30000305 -1.007561e-06
1973.4167 0.1000004 0.29999924 -1.688914e-05
1973.5    0.1000004 0.09999847  4.078149e-05
1973.5833 0.0000000 0.79999924  2.232584e-05
1973.6667 0.2999992 0.10000229  2.678536e-05
1973.75   0.2000008 0.39999771 -3.498323e-06

> # 3. assuming this is monthly data use yearmon class
> Pym <- aggregate(P, as.yearmon, identity)
> diff(Pym)
           PriceIT    PriceUS    ExRateUSIT
Feb 1973 0.1000004 0.30000305  3.418679e-05
Mar 1973 0.2999992 0.39999771  1.830893e-05
Apr 1973 0.2000008 0.29999924 -6.330707e-05
May 1973 0.2999992 0.30000305 -1.007561e-06
Jun 1973 0.1000004 0.29999924 -1.688914e-05
Jul 1973 0.1000004 0.09999847  4.078149e-05
Aug 1973 0.0000000 0.79999924  2.232584e-05
Sep 1973 0.2999992 0.10000229  2.678536e-05
Oct 1973 0.2000008 0.39999771 -3.498323e-06


On Sun, Mar 7, 2010 at 7:46 AM, mat <matthieu.stigler at gmail.com> wrote:
> Hi all
>
> I have a strange output using diff.zoo, where diff reduces the dim object by
> more than 1:
>
> See:




>>class(PPP)
> [1] "zooreg" "zoo" ?> frequency(PPP)
> [1] 12
>> dim(PPP)
> [1] 202 ? 3
>> dim(diff(PPP))
> [1] 67 ?3
>
> #What is happening? Dim is not 201 3 as I would expect, like I get with ts:
>>dim(diff(as.ts(PPP)))
> [1] 201 ? 3
>
> #Differentiation seems to be done only for selected months...
>> head(PPP)
> ? ? ? ? PriceIT ? PriceUS ExRateUSIT
> 1973(1) 0.0000000 0.0000000 ?0.0000000
> 1973(2) 0.5089089 0.7017644 ?1.9819006
> 1973(3) 2.0202688 1.6298400 ?3.0273857
> 1973(4) 3.0153056 2.3202898 -0.6350275
> 1973(5) 4.4895300 3.0060137 -0.6944147
> 1973(6) 4.9761509 3.6870589 -1.6951727
>> head(diff(PPP))
> ? ? ? ? ?PriceIT ? PriceUS ExRateUSIT
> 1973(4) ?0.9950369 0.6904498 -3.6624133
> 1973(7) ?0.4842643 0.2259853 ?2.3995976
> 1973(10) 0.9478780 0.8810579 -0.1979420
> 1974(1) ?1.3730158 0.8620694 -6.4295795
> 1974(4) ?1.2959112 0.4175387 ?0.2104218
> 1974(7) ?2.4591418 0.8130157 ?0.9254661
>
> #Series is from:
> library(zoo)
> source("priceLev.R") #see below
>
> Thanks a lot for your help, I'm really stuck...
>
> Mat
>
> I had problems copy/paste this directly into R console, but saving it as
> priceLev.R and sourcing it was ok:
>
>
> PPP<-structure(c(19.60000038147, 19.70000076294, 20, 20.20000076294,
> 20.5, 20.60000038147, 20.70000076294, 20.70000076294, 21, 21.20000076294,
> 21.29999923706, 21.70000076294, 22, 22.39999961853, 23, 23.29999923706,
> 23.70000076294, 24.10000038147, 24.70000076294, 25.20000076294,
> 26, 26.5, 27, 27.10000038147, 27.5, 27.89999961853, 27.89999961853,
> 28.20000076294, 28.5, 28.79999923706, 28.89999961853, 29.10000038147,
> 29.29999923706, 29.70000076294, 30, 30.29999923706, 30.5, 31,
> 31.70000076294, 32.70000076294, 33.20000076294, 33.29999923706,
> 33.5, 33.79999923706, 34.40000152588, 35.59999847412, 36.29999923706,
> 36.79999923706, 37.29999923706, 38.09999847412, 38.79999923706,
> 39.20000076294, 39.70000076294, 40, 40.29999923706, 40.70000076294,
> 41.09999847412, 41.40000152588, 42.09999847412, 42.29999923706,
> 42.79999923706, 43.20000076294, 43.59999847412, 44.09999847412,
> 44.59999847412, 44.90000152588, 45.29999923706, 45.40000152588,
> 46.09999847412, 46.59999847412, 47, 47.40000152588, 48.29999923706,
> 48.90000152588, 49.70000076294, 50.40000152588, 51.09999847412,
> 51.59999847412, 52, 52.59999847412, 53.79999923706, 55.09999847412,
> 55.70000076294, 56.70000076294, 58.5, 59.59999847412, 60.20000076294,
> 61, 61.59999847412, 62.09999847412, 63.20000076294, 63.90000152588,
> 65.30000305176, 66.40000152588, 67.80000305176, 68.69999694824,
> 69.90000152588, 71.19999694824, 72.19999694824, 73.30000305176,
> 74.19999694824, 75, 75.69999694824, 76.19999694824, 77.30000305176,
> 78.69999694824, 80.09999847412, 80.90000152588, 82, 83.09999847412,
> 83.80000305176, 84.5, 85.5, 86.40000152588, 87.69999694824, 89.30000305176,
> 90.5, 92.30000305176, 93.5, 94.09999847412, 95.40000152588, 96.80000305176,
> 97.59999847412, 98.59999847412, 99.59999847412, 100.19999694824,
> 101.09999847412, 101.5, 102.80000305176, 104.5, 105.59999847412,
> 106.09999847412, 107.40000152588, 108.5, 109.19999694824, 110.09999847412,
> 110.69999694824, 111.30000305176, 111.69999694824, 112, 112.90000152588,
> 114, 114.69999694824, 115.40000152588, 116.59999847412, 117.80000305176,
> 118.69999694824, 119.69999694824, 120.40000152588, 121, 121.5,
> 121.69999694824, 122.19999694824, 123.69999694824, 124.5, 125.30000305176,
> 126, 126.80000305176, 127.30000305176, 127.59999847412, 128.10000610352,
> 128.60000610352, 128.60000610352, 128.89999389648, 129.19999694824,
> 130, 130.39999389648, 130.80000305176, 131.60000610352, 132.10000610352,
> 132.60000610352, 133, 133.5, 133.89999389648, 134.30000305176,
> 134.69999694824, 135.60000610352, 136.89999389648, 137.19999694824,
> 137.5, 138.19999694824, 138.5, 139.19999694824, 139.60000610352,
> 140, 140.5, 140.89999389648, 141.5, 142.19999694824, 143.30000305176,
> 144.5, 145, 146.10000610352, 147.30000305176, 148, 149, 149.60000610352,
> 150.30000305176, 150.69999694824, 150.89999389648, 151.60000610352,
> 153.10000610352, 42.5999984741, 42.9000015259, 43.2999992371,
> 43.5999984741, 43.9000015259, 44.2000007629, 44.2999992371, 45.0999984741,
> 45.2000007629, 45.5999984741, 45.9000015259, 46.2000007629, 46.5999984741,
> 47.2000007629, 47.7999992371, 48, 48.5999984741, 49, 49.4000015259,
> 50, 50.5999984741, 51.0999984741, 51.5, 51.9000015259, 52.0999984741,
> 52.5, 52.7000007629, 52.9000015259, 53.2000007629, 53.5999984741,
> 54.2000007629, 54.2999992371, 54.5999984741, 54.9000015259, 55.2999992371,
> 55.5, 55.5999984741, 55.7999992371, 55.9000015259, 56.0999984741,
> 56.5, 56.7999992371, 57.0999984741, 57.4000015259, 57.5999984741,
> 57.9000015259, 58, 58.2000007629, 58.5, 59.0999984741, 59.5,
> 60, 60.2999992371, 60.7000007629, 61, 61.2000007629, 61.4000015259,
> 61.5999984741, 61.9000015259, 62.0999984741, 62.5, 62.9000015259,
> 63.4000015259, 63.9000015259, 64.5, 65.1999969482, 65.6999969482,
> 66, 66.5, 67.0999984741, 67.4000015259, 67.6999969482, 68.3000030518,
> 69.0999984741, 69.8000030518, 70.5999984741, 71.5, 72.3000030518,
> 73.0999984741, 73.8000030518, 74.5999984741, 75.1999969482, 75.9000015259,
> 76.6999969482, 77.8000030518, 78.9000015259, 80.0999984741, 81,
> 81.8000030518, 82.6999969482, 82.6999969482, 83.3000030518, 84,
> 84.8000030518, 85.5, 86.3000030518, 87, 87.9000015259, 88.5,
> 89.0999984741, 89.8000030518, 90.5999984741, 91.5999984741, 92.3000030518,
> 93.1999969482, 93.4000015259, 93.6999969482, 94, 94.3000030518,
> 94.5999984741, 94.5, 94.9000015259, 95.8000030518, 97, 97.5,
> 97.6999969482, 97.9000015259, 98.1999969482, 98, 97.5999984741,
> 97.8000030518, 97.9000015259, 97.9000015259, 98.5999984741, 99.1999969482,
> 99.5, 99.9000015259, 100.1999969482, 100.6999969482, 101, 101.1999969482,
> 101.3000030518, 101.9000015259, 102.4000015259, 102.5999984741,
> 103.0999984741, 103.4000015259, 103.6999969482, 104.0999984741,
> 104.5, 105, 105.3000030518, 105.3000030518, 105.3000030518, 105.5,
> 106, 106.4000015259, 106.9000015259, 107.3000030518, 107.5999984741,
> 107.8000030518, 108, 108.3000030518, 108.6999969482, 109, 109.3000030518,
> 109.5999984741, 109.3000030518, 108.8000030518, 108.5999984741,
> 108.9000015259, 109.5, 109.5, 109.6999969482, 110.1999969482,
> 110.3000030518, 110.4000015259, 110.5, 111.1999969482, 111.5999984741,
> 112.0999984741, 112.6999969482, 113.0999984741, 113.5, 113.8000030518,
> 114.4000015259, 115, 115.3000030518, 115.4000015259, 115.4000015259,
> 115.6999969482, 116, 116.5, 117.0999984741, 117.5, 118, 118.5,
> 119, 119.8000030518, 120.1999969482, 120.3000030518, 120.5, 121.0999984741,
> 121.5999984741, 122.3000030518, 123.0999984741, 123.8000030518,
> 124.0999984741, 124.4000015259, 124.5999984741, 125, 125.5999984741,
> 0.00170791273132914, 0.00174209951913706, 0.00176040845258218,
> 0.00169710137902025, 0.00169609381850337, 0.0016792046735684,
> 0.00171998616788486, 0.00174231201103162, 0.00176909737593850,
> 0.00176559905254172, 0.00169038840243291, 0.00164579257106955,
> 0.00154330508995765, 0.00152751052610713, 0.00156870134431149,
> 0.00157200571003395, 0.00158080266451816, 0.00153789372388514,
> 0.00155219247186651, 0.00152690408919378, 0.00151030025882740,
> 0.0014992053772286, 0.00149961004098130, 0.00151791138210253,
> 0.00155041165776418, 0.00156779122961396, 0.00158420865760686,
> 0.00157669023618497, 0.00159370176532851, 0.00159820997361459,
> 0.00153869820346857, 0.00149628918637955, 0.00147399143728242,
> 0.00147449127396179, 0.00147210366254964, 0.001464493321869,
> 0.00142450142450142, 0.00130210030432208, 0.00121129900062598,
> 0.00113710017662363, 0.00116759682220348, 0.00117799501854215,
> 0.00119430080008036, 0.00119360230910755, 0.00118369811305430,
> 0.00116840174992149, 0.00115540150202195, 0.00115210030473245,
> 0.00113720364788047, 0.00113269527966656, 0.00112759908181671,
> 0.00112640515330342, 0.00112790438476952, 0.00112949684031799,
> 0.00113300327052292, 0.00113319581068863, 0.0011317978765388,
> 0.00113530572839516, 0.00113879652617039, 0.00114160461084470,
> 0.00114689423295764, 0.00116189904399275, 0.00116919410456185,
> 0.00116440190827110, 0.00114880470740695, 0.00116339946972441,
> 0.00118040065178541, 0.00119520008695516, 0.00120499348594498,
> 0.00123169392646559, 0.00118570513198108, 0.00118629587872915,
> 0.00119550017935439, 0.00118989544621630, 0.00118880621116386,
> 0.00118580356321465, 0.00117439812096301, 0.00118280204099774,
> 0.00121919992832387, 0.00122189634673585, 0.00123260489724270,
> 0.00121119629142077, 0.00121119629142077, 0.00123289363839214,
> 0.00124269912368631, 0.00123459841491511, 0.00116349423223834,
> 0.00114169585595958, 0.00118600047471892, 0.00119730364063127,
> 0.00120260238929126, 0.00118009415111576, 0.00117420504297619,
> 0.00114409932379843, 0.00110000106750649, 0.00107040024502102,
> 0.00104718620797518, 0.000980613256761468, 0.000969649910456641,
> 0.000927867583147656, 0.000876370465502322, 0.000843525938422606,
> 0.000823295979829121, 0.000803735801681492, 0.000842027275228413,
> 0.000837303506576214, 0.00083921485467683, 0.000828939961655155,
> 0.000814186402967888, 0.000791652779081, 0.000773221759850004,
> 0.000756658609619449, 0.00077919851937074, 0.000736143901754949,
> 0.000723452890870574, 0.000718081299390519, 0.00070862183088102,
> 0.000694473409094806, 0.000680809361993181, 0.000714929155512817,
> 0.00072742616872993, 0.000714397961872782, 0.000699437666460164,
> 0.00068853453006531, 0.000681310291427974, 0.00066182213723944,
> 0.000652141291441826, 0.000629033682327389, 0.000623978237540331,
> 0.000631787746464218, 0.000615085574381394, 0.000599923208071712,
> 0.000585950087094921, 0.000600099611261314, 0.000619513417282865,
> 0.000610321768907887, 0.000589511431606801, 0.000590040105729007,
> 0.000571043507422813, 0.000561649461352701, 0.000534533528145891,
> 0.000526598495131594, 0.000536754233000383, 0.000522870343728599,
> 0.000513146818997007, 0.000489715964740451, 0.000481116189559779,
> 0.000506101044383357, 0.000503917974554817, 0.000511791668803899,
> 0.000526224404774398, 0.000533757489838498, 0.000525370111122406,
> 0.000560089149346125, 0.000570216463691828, 0.000583600817041144,
> 0.000601272286874565, 0.000629639672710148, 0.000645815416462228,
> 0.000641251743442265, 0.000654236179260713, 0.000652273182391623,
> 0.000676448079471965, 0.000704061753916339, 0.000709104198499191,
> 0.000720632404196826, 0.000713735141009144, 0.000724931887198181,
> 0.000759203418417369, 0.0007705703819913, 0.000765755403403666,
> 0.000773419154661628, 0.000774713326752632, 0.000759589821496392,
> 0.000747406521267597, 0.000743947953430204, 0.000762857979627377,
> 0.00076770719167874, 0.000807174154425746, 0.000830744187376882,
> 0.000821773713091906, 0.000800243277082303, 0.000806016075652368,
> 0.00080580827232252, 0.000794401024342725, 0.000765954804926349,
> 0.00073138978164888, 0.000715343373114671, 0.00071779778378185,
> 0.000738901704515748, 0.000769100631071927, 0.000771837212823204,
> 0.000743428098333353, 0.000737854892260688, 0.000728597449908925,
> 0.000728969211551167, 0.000706299507030033, 0.000697155593265228,
> 0.000731320244617571, 0.000722418082886736, 0.00071215938252162,
> 0.000730332160273162), .Dim = c(202L, 3L), .Dimnames = list(NULL,
> ? c("PriceIT", "PriceUS", "ExRateUSIT")), index = c(1973,
> 1973.08333333333, 1973.16666666667, 1973.25, 1973.33333333333,
> 1973.41666666667, 1973.5, 1973.58333333333, 1973.66666666667,
> 1973.75, 1973.83333333333, 1973.91666666667, 1974, 1974.08333333333,
> 1974.16666666667, 1974.25, 1974.33333333333, 1974.41666666667,
> 1974.5, 1974.58333333333, 1974.66666666667, 1974.75, 1974.83333333333,
> 1974.91666666667, 1975, 1975.08333333333, 1975.16666666667, 1975.25,
> 1975.33333333333, 1975.41666666667, 1975.5, 1975.58333333333,
> 1975.66666666667, 1975.75, 1975.83333333333, 1975.91666666667,
> 1976, 1976.08333333333, 1976.16666666667, 1976.25, 1976.33333333333,
> 1976.41666666667, 1976.5, 1976.58333333333, 1976.66666666667,
> 1976.75, 1976.83333333333, 1976.91666666667, 1977, 1977.08333333333,
> 1977.16666666667, 1977.25, 1977.33333333333, 1977.41666666667,
> 1977.5, 1977.58333333333, 1977.66666666667, 1977.75, 1977.83333333333,
> 1977.91666666667, 1978, 1978.08333333333, 1978.16666666667, 1978.25,
> 1978.33333333333, 1978.41666666667, 1978.5, 1978.58333333333,
> 1978.66666666667, 1978.75, 1978.83333333333, 1978.91666666667,
> 1979, 1979.08333333333, 1979.16666666667, 1979.25, 1979.33333333333,
> 1979.41666666667, 1979.5, 1979.58333333333, 1979.66666666667,
> 1979.75, 1979.83333333333, 1979.91666666667, 1980, 1980.08333333333,
> 1980.16666666667, 1980.25, 1980.33333333333, 1980.41666666667,
> 1980.5, 1980.58333333333, 1980.66666666667, 1980.75, 1980.83333333333,
> 1980.91666666667, 1981, 1981.08333333333, 1981.16666666667, 1981.25,
> 1981.33333333333, 1981.41666666667, 1981.5, 1981.58333333333,
> 1981.66666666667, 1981.75, 1981.83333333333, 1981.91666666667,
> 1982, 1982.08333333333, 1982.16666666667, 1982.25, 1982.33333333333,
> 1982.41666666667, 1982.5, 1982.58333333333, 1982.66666666667,
> 1982.75, 1982.83333333333, 1982.91666666667, 1983, 1983.08333333333,
> 1983.16666666667, 1983.25, 1983.33333333333, 1983.41666666667,
> 1983.5, 1983.58333333333, 1983.66666666667, 1983.75, 1983.83333333333,
> 1983.91666666667, 1984, 1984.08333333333, 1984.16666666667, 1984.25,
> 1984.33333333333, 1984.41666666667, 1984.5, 1984.58333333333,
> 1984.66666666667, 1984.75, 1984.83333333333, 1984.91666666667,
> 1985, 1985.08333333333, 1985.16666666667, 1985.25, 1985.33333333333,
> 1985.41666666667, 1985.5, 1985.58333333333, 1985.66666666667,
> 1985.75, 1985.83333333333, 1985.91666666667, 1986, 1986.08333333333,
> 1986.16666666667, 1986.25, 1986.33333333333, 1986.41666666667,
> 1986.5, 1986.58333333333, 1986.66666666667, 1986.75, 1986.83333333333,
> 1986.91666666667, 1987, 1987.08333333333, 1987.16666666667, 1987.25,
> 1987.33333333333, 1987.41666666667, 1987.5, 1987.58333333333,
> 1987.66666666667, 1987.75, 1987.83333333333, 1987.91666666667,
> 1988, 1988.08333333333, 1988.16666666667, 1988.25, 1988.33333333333,
> 1988.41666666667, 1988.5, 1988.58333333333, 1988.66666666667,
> 1988.75, 1988.83333333333, 1988.91666666667, 1989, 1989.08333333333,
> 1989.16666666667, 1989.25, 1989.33333333333, 1989.41666666667,
> 1989.5, 1989.58333333333, 1989.66666666667, 1989.75), class = c("zooreg",
> "zoo"), frequency = 12)
>
>
> sessionInfo()
> R version 2.9.2 (2009-08-24)
> x86_64-pc-linux-gnu
>
> locale:
> LC_CTYPE=fr_CH.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CH.UTF-8;LC_COLLATE=fr_CH.UTF-8;LC_MONETARY=fr_CH.UTF-8;LC_MESSAGES=fr_CH.UTF-8;LC_PAPER=fr_CH.UTF-8;LC_NAME=fr_CH.UTF-8;LC_ADDRESS=fr_CH.UTF-8;LC_TELEPHONE=fr_CH.UTF-8;LC_MEASUREMENT=fr_CH.UTF-8;LC_IDENTIFICATION=fr_CH.UTF-8
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
> other attached packages:
> [1] zoo_1.6-2 ? ?rkward_0.5.1
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.2 ? ? ?lattice_0.17-26 tools_2.9.2
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>


From matthieu.stigler at gmail.com  Sun Mar  7 14:43:46 2010
From: matthieu.stigler at gmail.com (mat)
Date: Sun, 07 Mar 2010 14:43:46 +0100
Subject: [R-SIG-Finance] what's wrong with diff.zoo
In-Reply-To: <971536df1003070514m62909b82jbd7cafe49c67390c@mail.gmail.com>
References: <4B93A01D.60900@gmail.com>
	<971536df1003070514m62909b82jbd7cafe49c67390c@mail.gmail.com>
Message-ID: <4B93AD92.5020107@gmail.com>

Thanks Gabor for your fast answer! And thanks for "reducing" the data 
file, true it is much easier to read!

I think the problem must be specific to this data. I had created it from 
a .csv file, putting ts attributes with ts(), converting to zoo and then 
finally dput(). So maybe through this complicated and indirect process 
something went wrong?

I'm using your second workaround, which solves the problem!

Thanks again!

Gabor Grothendieck a ?crit :
> Its best to cut down your data as much as possible when posting.
> Using the first 10 rows of PPP seems sufficient to illustrate this:
>
>   
>> P <- head(PPP, 10)
>> diff(P)
>>     
>            PriceIT    PriceUS    ExRateUSIT
> 1973(4)  0.2000008 0.29999924 -6.330707e-05
> 1973(7)  0.1000004 0.09999847  4.078149e-05
> 1973(10) 0.2000008 0.39999771 -3.498323e-06
>
> Here is the dput output for just those 10 rows in case there are follow ups:
>
> P <- structure(c(19.60000038147, 19.70000076294, 20, 20.20000076294,
> 20.5, 20.60000038147, 20.70000076294, 20.70000076294, 21, 21.20000076294,
> 42.5999984741, 42.9000015259, 43.2999992371, 43.5999984741, 43.9000015259,
> 44.2000007629, 44.2999992371, 45.0999984741, 45.2000007629, 45.5999984741,
> 0.00170791273132914, 0.00174209951913706, 0.00176040845258218,
> 0.00169710137902025, 0.00169609381850337, 0.0016792046735684,
> 0.00171998616788486, 0.00174231201103162, 0.0017690973759385,
> 0.00176559905254172), .Dim = c(10L, 3L), .Dimnames = list(NULL,
>     c("PriceIT", "PriceUS", "ExRateUSIT")), index = c(1973, 1973.08333333333,
> 1973.16666666667, 1973.25, 1973.33333333333, 1973.41666666667,
> 1973.5, 1973.58333333333, 1973.66666666667, 1973.75), class = c("zooreg",
> "zoo"), frequency = 12)
>
> The problem appears to be small differences between P and lag(P, -1).
> Note sure if this is a problem with this specific object (how was it
> created?) or if its a general problem.  We can see the problem by
> merging P with lag(P, -1) :
>
>   
>> merge(P, lag(P, -1))
>>     
>                    PriceIT.P PriceUS.P ExRateUSIT.P PriceIT.lag(P, -1)
> PriceUS.lag(P, -1) ExRateUSIT.lag(P, -1)
> 1973(1)                 19.6      42.6  0.001707913                 NA
>                 NA                    NA
> 1973(26178848280)       19.7      42.9  0.001742100                 NA
>                 NA                    NA
> 1973(26178848281)         NA        NA           NA               19.6
>               42.6           0.001707913
> 1973(52357696562)         NA        NA           NA               19.7
>               42.9           0.001742100
> 1973(52357696563)       20.0      43.3  0.001760408                 NA
>                 NA                    NA
> 1973(78536544842)       20.2      43.6  0.001697101               20.0
>               43.3           0.001760408
> 1973(104715393122)      20.5      43.9  0.001696094                 NA
>                 NA                    NA
> 1973(104715393123)        NA        NA           NA               20.2
>               43.6           0.001697101
> 1973(130894241403)        NA        NA           NA               20.5
>               43.9           0.001696094
> 1973(130894241404)      20.6      44.2  0.001679205                 NA
>                 NA                    NA
> 1973(157073089683)      20.7      44.3  0.001719986               20.6
>               44.2           0.001679205
> 1973(183251937963)      20.7      45.1  0.001742312                 NA
>                 NA                    NA
> 1973(183251937964)        NA        NA           NA               20.7
>               44.3           0.001719986
> 1973(209430786244)        NA        NA           NA               20.7
>               45.1           0.001742312
> 1973(209430786245)      21.0      45.2  0.001769097                 NA
>                 NA                    NA
> 1973(235609634525)      21.2      45.6  0.001765599               21.0
>               45.2           0.001769097
> 1973(261788482805)        NA        NA           NA               21.2
>               45.6           0.001765599
>
> Will look at the problem but in the meantime here are three workarounds:
>
>   
>> # 1. fix up the time scale as it seems slightly off a 12 point cycle
>> P0 <- aggregate(P, round(12 * time(P))/12, identity)
>> diff(P0)
>>     
>            PriceIT    PriceUS    ExRateUSIT
> 1973(2)  0.1000004 0.30000305  3.418679e-05
> 1973(3)  0.2999992 0.39999771  1.830893e-05
> 1973(4)  0.2000008 0.29999924 -6.330707e-05
> 1973(5)  0.2999992 0.30000305 -1.007561e-06
> 1973(6)  0.1000004 0.29999924 -1.688914e-05
> 1973(7)  0.1000004 0.09999847  4.078149e-05
> 1973(8)  0.0000000 0.79999924  2.232584e-05
> 1973(9)  0.2999992 0.10000229  2.678536e-05
> 1973(10) 0.2000008 0.39999771 -3.498323e-06
>
>   
>> # 2. use zoo instead of zooreg
>> diff(as.zoo(P))
>>     
>             PriceIT    PriceUS    ExRateUSIT
> 1973.0833 0.1000004 0.30000305  3.418679e-05
> 1973.1667 0.2999992 0.39999771  1.830893e-05
> 1973.25   0.2000008 0.29999924 -6.330707e-05
> 1973.3333 0.2999992 0.30000305 -1.007561e-06
> 1973.4167 0.1000004 0.29999924 -1.688914e-05
> 1973.5    0.1000004 0.09999847  4.078149e-05
> 1973.5833 0.0000000 0.79999924  2.232584e-05
> 1973.6667 0.2999992 0.10000229  2.678536e-05
> 1973.75   0.2000008 0.39999771 -3.498323e-06
>
>   
>> # 3. assuming this is monthly data use yearmon class
>> Pym <- aggregate(P, as.yearmon, identity)
>> diff(Pym)
>>     
>            PriceIT    PriceUS    ExRateUSIT
> Feb 1973 0.1000004 0.30000305  3.418679e-05
> Mar 1973 0.2999992 0.39999771  1.830893e-05
> Apr 1973 0.2000008 0.29999924 -6.330707e-05
> May 1973 0.2999992 0.30000305 -1.007561e-06
> Jun 1973 0.1000004 0.29999924 -1.688914e-05
> Jul 1973 0.1000004 0.09999847  4.078149e-05
> Aug 1973 0.0000000 0.79999924  2.232584e-05
> Sep 1973 0.2999992 0.10000229  2.678536e-05
> Oct 1973 0.2000008 0.39999771 -3.498323e-06
>
>
> On Sun, Mar 7, 2010 at 7:46 AM, mat <matthieu.stigler at gmail.com> wrote:
>   
>> Hi all
>>
>> I have a strange output using diff.zoo, where diff reduces the dim object by
>> more than 1:
>>
>> See:
>>     
>
>
>
>
>   
>>> class(PPP)
>>>       
>> [1] "zooreg" "zoo"  > frequency(PPP)
>> [1] 12
>>     
>>> dim(PPP)
>>>       
>> [1] 202   3
>>     
>>> dim(diff(PPP))
>>>       
>> [1] 67  3
>>
>> #What is happening? Dim is not 201 3 as I would expect, like I get with ts:
>>     
>>> dim(diff(as.ts(PPP)))
>>>       
>> [1] 201   3
>>
>> #Differentiation seems to be done only for selected months...
>>     
>>> head(PPP)
>>>       
>>         PriceIT   PriceUS ExRateUSIT
>> 1973(1) 0.0000000 0.0000000  0.0000000
>> 1973(2) 0.5089089 0.7017644  1.9819006
>> 1973(3) 2.0202688 1.6298400  3.0273857
>> 1973(4) 3.0153056 2.3202898 -0.6350275
>> 1973(5) 4.4895300 3.0060137 -0.6944147
>> 1973(6) 4.9761509 3.6870589 -1.6951727
>>     
>>> head(diff(PPP))
>>>       
>>          PriceIT   PriceUS ExRateUSIT
>> 1973(4)  0.9950369 0.6904498 -3.6624133
>> 1973(7)  0.4842643 0.2259853  2.3995976
>> 1973(10) 0.9478780 0.8810579 -0.1979420
>> 1974(1)  1.3730158 0.8620694 -6.4295795
>> 1974(4)  1.2959112 0.4175387  0.2104218
>> 1974(7)  2.4591418 0.8130157  0.9254661
>>
>> #Series is from:
>> library(zoo)
>> source("priceLev.R") #see below
>>
>> Thanks a lot for your help, I'm really stuck...
>>
>> Mat
>>
>> I had problems copy/paste this directly into R console, but saving it as
>> priceLev.R and sourcing it was ok:
>>
>>
>> PPP<-structure(c(19.60000038147, 19.70000076294, 20, 20.20000076294,
>> 20.5, 20.60000038147, 20.70000076294, 20.70000076294, 21, 21.20000076294,
>> 21.29999923706, 21.70000076294, 22, 22.39999961853, 23, 23.29999923706,
>> 23.70000076294, 24.10000038147, 24.70000076294, 25.20000076294,
>> 26, 26.5, 27, 27.10000038147, 27.5, 27.89999961853, 27.89999961853,
>> 28.20000076294, 28.5, 28.79999923706, 28.89999961853, 29.10000038147,
>> 29.29999923706, 29.70000076294, 30, 30.29999923706, 30.5, 31,
>> 31.70000076294, 32.70000076294, 33.20000076294, 33.29999923706,
>> 33.5, 33.79999923706, 34.40000152588, 35.59999847412, 36.29999923706,
>> 36.79999923706, 37.29999923706, 38.09999847412, 38.79999923706,
>> 39.20000076294, 39.70000076294, 40, 40.29999923706, 40.70000076294,
>> 41.09999847412, 41.40000152588, 42.09999847412, 42.29999923706,
>> 42.79999923706, 43.20000076294, 43.59999847412, 44.09999847412,
>> 44.59999847412, 44.90000152588, 45.29999923706, 45.40000152588,
>> 46.09999847412, 46.59999847412, 47, 47.40000152588, 48.29999923706,
>> 48.90000152588, 49.70000076294, 50.40000152588, 51.09999847412,
>> 51.59999847412, 52, 52.59999847412, 53.79999923706, 55.09999847412,
>> 55.70000076294, 56.70000076294, 58.5, 59.59999847412, 60.20000076294,
>> 61, 61.59999847412, 62.09999847412, 63.20000076294, 63.90000152588,
>> 65.30000305176, 66.40000152588, 67.80000305176, 68.69999694824,
>> 69.90000152588, 71.19999694824, 72.19999694824, 73.30000305176,
>> 74.19999694824, 75, 75.69999694824, 76.19999694824, 77.30000305176,
>> 78.69999694824, 80.09999847412, 80.90000152588, 82, 83.09999847412,
>> 83.80000305176, 84.5, 85.5, 86.40000152588, 87.69999694824, 89.30000305176,
>> 90.5, 92.30000305176, 93.5, 94.09999847412, 95.40000152588, 96.80000305176,
>> 97.59999847412, 98.59999847412, 99.59999847412, 100.19999694824,
>> 101.09999847412, 101.5, 102.80000305176, 104.5, 105.59999847412,
>> 106.09999847412, 107.40000152588, 108.5, 109.19999694824, 110.09999847412,
>> 110.69999694824, 111.30000305176, 111.69999694824, 112, 112.90000152588,
>> 114, 114.69999694824, 115.40000152588, 116.59999847412, 117.80000305176,
>> 118.69999694824, 119.69999694824, 120.40000152588, 121, 121.5,
>> 121.69999694824, 122.19999694824, 123.69999694824, 124.5, 125.30000305176,
>> 126, 126.80000305176, 127.30000305176, 127.59999847412, 128.10000610352,
>> 128.60000610352, 128.60000610352, 128.89999389648, 129.19999694824,
>> 130, 130.39999389648, 130.80000305176, 131.60000610352, 132.10000610352,
>> 132.60000610352, 133, 133.5, 133.89999389648, 134.30000305176,
>> 134.69999694824, 135.60000610352, 136.89999389648, 137.19999694824,
>> 137.5, 138.19999694824, 138.5, 139.19999694824, 139.60000610352,
>> 140, 140.5, 140.89999389648, 141.5, 142.19999694824, 143.30000305176,
>> 144.5, 145, 146.10000610352, 147.30000305176, 148, 149, 149.60000610352,
>> 150.30000305176, 150.69999694824, 150.89999389648, 151.60000610352,
>> 153.10000610352, 42.5999984741, 42.9000015259, 43.2999992371,
>> 43.5999984741, 43.9000015259, 44.2000007629, 44.2999992371, 45.0999984741,
>> 45.2000007629, 45.5999984741, 45.9000015259, 46.2000007629, 46.5999984741,
>> 47.2000007629, 47.7999992371, 48, 48.5999984741, 49, 49.4000015259,
>> 50, 50.5999984741, 51.0999984741, 51.5, 51.9000015259, 52.0999984741,
>> 52.5, 52.7000007629, 52.9000015259, 53.2000007629, 53.5999984741,
>> 54.2000007629, 54.2999992371, 54.5999984741, 54.9000015259, 55.2999992371,
>> 55.5, 55.5999984741, 55.7999992371, 55.9000015259, 56.0999984741,
>> 56.5, 56.7999992371, 57.0999984741, 57.4000015259, 57.5999984741,
>> 57.9000015259, 58, 58.2000007629, 58.5, 59.0999984741, 59.5,
>> 60, 60.2999992371, 60.7000007629, 61, 61.2000007629, 61.4000015259,
>> 61.5999984741, 61.9000015259, 62.0999984741, 62.5, 62.9000015259,
>> 63.4000015259, 63.9000015259, 64.5, 65.1999969482, 65.6999969482,
>> 66, 66.5, 67.0999984741, 67.4000015259, 67.6999969482, 68.3000030518,
>> 69.0999984741, 69.8000030518, 70.5999984741, 71.5, 72.3000030518,
>> 73.0999984741, 73.8000030518, 74.5999984741, 75.1999969482, 75.9000015259,
>> 76.6999969482, 77.8000030518, 78.9000015259, 80.0999984741, 81,
>> 81.8000030518, 82.6999969482, 82.6999969482, 83.3000030518, 84,
>> 84.8000030518, 85.5, 86.3000030518, 87, 87.9000015259, 88.5,
>> 89.0999984741, 89.8000030518, 90.5999984741, 91.5999984741, 92.3000030518,
>> 93.1999969482, 93.4000015259, 93.6999969482, 94, 94.3000030518,
>> 94.5999984741, 94.5, 94.9000015259, 95.8000030518, 97, 97.5,
>> 97.6999969482, 97.9000015259, 98.1999969482, 98, 97.5999984741,
>> 97.8000030518, 97.9000015259, 97.9000015259, 98.5999984741, 99.1999969482,
>> 99.5, 99.9000015259, 100.1999969482, 100.6999969482, 101, 101.1999969482,
>> 101.3000030518, 101.9000015259, 102.4000015259, 102.5999984741,
>> 103.0999984741, 103.4000015259, 103.6999969482, 104.0999984741,
>> 104.5, 105, 105.3000030518, 105.3000030518, 105.3000030518, 105.5,
>> 106, 106.4000015259, 106.9000015259, 107.3000030518, 107.5999984741,
>> 107.8000030518, 108, 108.3000030518, 108.6999969482, 109, 109.3000030518,
>> 109.5999984741, 109.3000030518, 108.8000030518, 108.5999984741,
>> 108.9000015259, 109.5, 109.5, 109.6999969482, 110.1999969482,
>> 110.3000030518, 110.4000015259, 110.5, 111.1999969482, 111.5999984741,
>> 112.0999984741, 112.6999969482, 113.0999984741, 113.5, 113.8000030518,
>> 114.4000015259, 115, 115.3000030518, 115.4000015259, 115.4000015259,
>> 115.6999969482, 116, 116.5, 117.0999984741, 117.5, 118, 118.5,
>> 119, 119.8000030518, 120.1999969482, 120.3000030518, 120.5, 121.0999984741,
>> 121.5999984741, 122.3000030518, 123.0999984741, 123.8000030518,
>> 124.0999984741, 124.4000015259, 124.5999984741, 125, 125.5999984741,
>> 0.00170791273132914, 0.00174209951913706, 0.00176040845258218,
>> 0.00169710137902025, 0.00169609381850337, 0.0016792046735684,
>> 0.00171998616788486, 0.00174231201103162, 0.00176909737593850,
>> 0.00176559905254172, 0.00169038840243291, 0.00164579257106955,
>> 0.00154330508995765, 0.00152751052610713, 0.00156870134431149,
>> 0.00157200571003395, 0.00158080266451816, 0.00153789372388514,
>> 0.00155219247186651, 0.00152690408919378, 0.00151030025882740,
>> 0.0014992053772286, 0.00149961004098130, 0.00151791138210253,
>> 0.00155041165776418, 0.00156779122961396, 0.00158420865760686,
>> 0.00157669023618497, 0.00159370176532851, 0.00159820997361459,
>> 0.00153869820346857, 0.00149628918637955, 0.00147399143728242,
>> 0.00147449127396179, 0.00147210366254964, 0.001464493321869,
>> 0.00142450142450142, 0.00130210030432208, 0.00121129900062598,
>> 0.00113710017662363, 0.00116759682220348, 0.00117799501854215,
>> 0.00119430080008036, 0.00119360230910755, 0.00118369811305430,
>> 0.00116840174992149, 0.00115540150202195, 0.00115210030473245,
>> 0.00113720364788047, 0.00113269527966656, 0.00112759908181671,
>> 0.00112640515330342, 0.00112790438476952, 0.00112949684031799,
>> 0.00113300327052292, 0.00113319581068863, 0.0011317978765388,
>> 0.00113530572839516, 0.00113879652617039, 0.00114160461084470,
>> 0.00114689423295764, 0.00116189904399275, 0.00116919410456185,
>> 0.00116440190827110, 0.00114880470740695, 0.00116339946972441,
>> 0.00118040065178541, 0.00119520008695516, 0.00120499348594498,
>> 0.00123169392646559, 0.00118570513198108, 0.00118629587872915,
>> 0.00119550017935439, 0.00118989544621630, 0.00118880621116386,
>> 0.00118580356321465, 0.00117439812096301, 0.00118280204099774,
>> 0.00121919992832387, 0.00122189634673585, 0.00123260489724270,
>> 0.00121119629142077, 0.00121119629142077, 0.00123289363839214,
>> 0.00124269912368631, 0.00123459841491511, 0.00116349423223834,
>> 0.00114169585595958, 0.00118600047471892, 0.00119730364063127,
>> 0.00120260238929126, 0.00118009415111576, 0.00117420504297619,
>> 0.00114409932379843, 0.00110000106750649, 0.00107040024502102,
>> 0.00104718620797518, 0.000980613256761468, 0.000969649910456641,
>> 0.000927867583147656, 0.000876370465502322, 0.000843525938422606,
>> 0.000823295979829121, 0.000803735801681492, 0.000842027275228413,
>> 0.000837303506576214, 0.00083921485467683, 0.000828939961655155,
>> 0.000814186402967888, 0.000791652779081, 0.000773221759850004,
>> 0.000756658609619449, 0.00077919851937074, 0.000736143901754949,
>> 0.000723452890870574, 0.000718081299390519, 0.00070862183088102,
>> 0.000694473409094806, 0.000680809361993181, 0.000714929155512817,
>> 0.00072742616872993, 0.000714397961872782, 0.000699437666460164,
>> 0.00068853453006531, 0.000681310291427974, 0.00066182213723944,
>> 0.000652141291441826, 0.000629033682327389, 0.000623978237540331,
>> 0.000631787746464218, 0.000615085574381394, 0.000599923208071712,
>> 0.000585950087094921, 0.000600099611261314, 0.000619513417282865,
>> 0.000610321768907887, 0.000589511431606801, 0.000590040105729007,
>> 0.000571043507422813, 0.000561649461352701, 0.000534533528145891,
>> 0.000526598495131594, 0.000536754233000383, 0.000522870343728599,
>> 0.000513146818997007, 0.000489715964740451, 0.000481116189559779,
>> 0.000506101044383357, 0.000503917974554817, 0.000511791668803899,
>> 0.000526224404774398, 0.000533757489838498, 0.000525370111122406,
>> 0.000560089149346125, 0.000570216463691828, 0.000583600817041144,
>> 0.000601272286874565, 0.000629639672710148, 0.000645815416462228,
>> 0.000641251743442265, 0.000654236179260713, 0.000652273182391623,
>> 0.000676448079471965, 0.000704061753916339, 0.000709104198499191,
>> 0.000720632404196826, 0.000713735141009144, 0.000724931887198181,
>> 0.000759203418417369, 0.0007705703819913, 0.000765755403403666,
>> 0.000773419154661628, 0.000774713326752632, 0.000759589821496392,
>> 0.000747406521267597, 0.000743947953430204, 0.000762857979627377,
>> 0.00076770719167874, 0.000807174154425746, 0.000830744187376882,
>> 0.000821773713091906, 0.000800243277082303, 0.000806016075652368,
>> 0.00080580827232252, 0.000794401024342725, 0.000765954804926349,
>> 0.00073138978164888, 0.000715343373114671, 0.00071779778378185,
>> 0.000738901704515748, 0.000769100631071927, 0.000771837212823204,
>> 0.000743428098333353, 0.000737854892260688, 0.000728597449908925,
>> 0.000728969211551167, 0.000706299507030033, 0.000697155593265228,
>> 0.000731320244617571, 0.000722418082886736, 0.00071215938252162,
>> 0.000730332160273162), .Dim = c(202L, 3L), .Dimnames = list(NULL,
>>   c("PriceIT", "PriceUS", "ExRateUSIT")), index = c(1973,
>> 1973.08333333333, 1973.16666666667, 1973.25, 1973.33333333333,
>> 1973.41666666667, 1973.5, 1973.58333333333, 1973.66666666667,
>> 1973.75, 1973.83333333333, 1973.91666666667, 1974, 1974.08333333333,
>> 1974.16666666667, 1974.25, 1974.33333333333, 1974.41666666667,
>> 1974.5, 1974.58333333333, 1974.66666666667, 1974.75, 1974.83333333333,
>> 1974.91666666667, 1975, 1975.08333333333, 1975.16666666667, 1975.25,
>> 1975.33333333333, 1975.41666666667, 1975.5, 1975.58333333333,
>> 1975.66666666667, 1975.75, 1975.83333333333, 1975.91666666667,
>> 1976, 1976.08333333333, 1976.16666666667, 1976.25, 1976.33333333333,
>> 1976.41666666667, 1976.5, 1976.58333333333, 1976.66666666667,
>> 1976.75, 1976.83333333333, 1976.91666666667, 1977, 1977.08333333333,
>> 1977.16666666667, 1977.25, 1977.33333333333, 1977.41666666667,
>> 1977.5, 1977.58333333333, 1977.66666666667, 1977.75, 1977.83333333333,
>> 1977.91666666667, 1978, 1978.08333333333, 1978.16666666667, 1978.25,
>> 1978.33333333333, 1978.41666666667, 1978.5, 1978.58333333333,
>> 1978.66666666667, 1978.75, 1978.83333333333, 1978.91666666667,
>> 1979, 1979.08333333333, 1979.16666666667, 1979.25, 1979.33333333333,
>> 1979.41666666667, 1979.5, 1979.58333333333, 1979.66666666667,
>> 1979.75, 1979.83333333333, 1979.91666666667, 1980, 1980.08333333333,
>> 1980.16666666667, 1980.25, 1980.33333333333, 1980.41666666667,
>> 1980.5, 1980.58333333333, 1980.66666666667, 1980.75, 1980.83333333333,
>> 1980.91666666667, 1981, 1981.08333333333, 1981.16666666667, 1981.25,
>> 1981.33333333333, 1981.41666666667, 1981.5, 1981.58333333333,
>> 1981.66666666667, 1981.75, 1981.83333333333, 1981.91666666667,
>> 1982, 1982.08333333333, 1982.16666666667, 1982.25, 1982.33333333333,
>> 1982.41666666667, 1982.5, 1982.58333333333, 1982.66666666667,
>> 1982.75, 1982.83333333333, 1982.91666666667, 1983, 1983.08333333333,
>> 1983.16666666667, 1983.25, 1983.33333333333, 1983.41666666667,
>> 1983.5, 1983.58333333333, 1983.66666666667, 1983.75, 1983.83333333333,
>> 1983.91666666667, 1984, 1984.08333333333, 1984.16666666667, 1984.25,
>> 1984.33333333333, 1984.41666666667, 1984.5, 1984.58333333333,
>> 1984.66666666667, 1984.75, 1984.83333333333, 1984.91666666667,
>> 1985, 1985.08333333333, 1985.16666666667, 1985.25, 1985.33333333333,
>> 1985.41666666667, 1985.5, 1985.58333333333, 1985.66666666667,
>> 1985.75, 1985.83333333333, 1985.91666666667, 1986, 1986.08333333333,
>> 1986.16666666667, 1986.25, 1986.33333333333, 1986.41666666667,
>> 1986.5, 1986.58333333333, 1986.66666666667, 1986.75, 1986.83333333333,
>> 1986.91666666667, 1987, 1987.08333333333, 1987.16666666667, 1987.25,
>> 1987.33333333333, 1987.41666666667, 1987.5, 1987.58333333333,
>> 1987.66666666667, 1987.75, 1987.83333333333, 1987.91666666667,
>> 1988, 1988.08333333333, 1988.16666666667, 1988.25, 1988.33333333333,
>> 1988.41666666667, 1988.5, 1988.58333333333, 1988.66666666667,
>> 1988.75, 1988.83333333333, 1988.91666666667, 1989, 1989.08333333333,
>> 1989.16666666667, 1989.25, 1989.33333333333, 1989.41666666667,
>> 1989.5, 1989.58333333333, 1989.66666666667, 1989.75), class = c("zooreg",
>> "zoo"), frequency = 12)
>>
>>
>> sessionInfo()
>> R version 2.9.2 (2009-08-24)
>> x86_64-pc-linux-gnu
>>
>> locale:
>> LC_CTYPE=fr_CH.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CH.UTF-8;LC_COLLATE=fr_CH.UTF-8;LC_MONETARY=fr_CH.UTF-8;LC_MESSAGES=fr_CH.UTF-8;LC_PAPER=fr_CH.UTF-8;LC_NAME=fr_CH.UTF-8;LC_ADDRESS=fr_CH.UTF-8;LC_TELEPHONE=fr_CH.UTF-8;LC_MEASUREMENT=fr_CH.UTF-8;LC_IDENTIFICATION=fr_CH.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> other attached packages:
>> [1] zoo_1.6-2    rkward_0.5.1
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.9.2      lattice_0.17-26 tools_2.9.2
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>>


From knguyen at cs.umb.edu  Sun Mar  7 21:56:56 2010
From: knguyen at cs.umb.edu (Khanh Nguyen)
Date: Sun, 7 Mar 2010 15:56:56 -0500
Subject: [R-SIG-Finance] about Nelson-Siegel model fitting
In-Reply-To: <57f92e091003070339t47452afbt66abe380036ba693@mail.gmail.com>
References: <57f92e091003060523yd051b5u4b1d724b30cc6b0@mail.gmail.com>
	<2871c9e11003060558u7c922c7ag15106d1d203003c9@mail.gmail.com>
	<57f92e091003070339t47452afbt66abe380036ba693@mail.gmail.com>
Message-ID: <2871c9e11003071256k2c292d8fx3b51483d5270f750@mail.gmail.com>

FittedBondCurve only returns curve data, you can not get the
parameters of the model.

-k

> I am wondering whether I can get the parameters of the Nelson-Siegel model
> directly from this FittedBondCurve method.
>
> Also, if possible, could you kindly provide a specific example for the
> following bonds price dataset that I have attached with this mail?
>
> My primary aim is to get the Nelson-Siegel model parameters. Also, I want
> pricing errors of the fitted curve, such as sum of price errors squared.
>
> Thanks a lot in advance.
>
> Kindest
>
> Yin
>
>
>
>
>
>
>
> On Sat, Mar 6, 2010 at 9:58 PM, Khanh Nguyen <knguyen at cs.umb.edu> wrote:
>>
>> You can look into RQuantLib
>>
>> -k
>>
>> On Sat, Mar 6, 2010 at 8:23 AM, Yin ZHANG <fly1985 at gmail.com> wrote:
>> > I am trying to fit the bond market data to the Nelson-Siegel term
>> > structure
>> > model. I have a series of bond price data, most of them are coupon
>> > bonds.
>> > According to the original Nelson-Siegel model setting, my objective is
>> > trying to get the paremeters that minimize the weighted/unweighted ?sum
>> > of
>> > price errors squared.
>> >
>> > So, is there any simple way in R or any package that can do this job? I
>> > do
>> > not know any about non-linear optimization, so what I need is an easy to
>> > use
>> > package/code that can do the job.
>> >
>> >
>> > thanks a lot in advance.
>> >
>> >
>> > Yin
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only. If you want to post, subscribe first.
>> > -- Also note that this is not the r-help list where general R questions
>> > should go.
>> >
>
>


From wobwu22 at yahoo.de  Tue Mar  9 15:12:09 2010
From: wobwu22 at yahoo.de (Wob Wu)
Date: Tue, 9 Mar 2010 14:12:09 +0000 (GMT)
Subject: [R-SIG-Finance] Xts,
	Zoo Error: "number of items to replace not multiple of replacement
	length"
Message-ID: <519655.96749.qm@web23405.mail.ird.yahoo.com>

Hello,

I am trying to construct a continous price series of future contracts. This is all working well apart from one bit in my code. After spending hours of debugging I still can't find the source of the problem. So any help is highly appreciated!!!

Ok, so basically I am trying to replace the log returns on specific days. This works for nearly all contracts that I am converting, apart from a
few. And I really can't see what the difference between it is as the
code is exactly the same.

So the specific code is:

returnNorm[expiryDates,] <- returnRoll[expiryDates,];

This however fails with the error:
"Error in NextMethod(.Generic) :   number of items to replace is not a multiple of replacement length"

where 

class(returnNorm) and class(returnRoll) is "xts" "zoo"
class(expiryDates) is "Date"

and

 dim(returnRoll[expiryDates,])
[1] 242   1
> dim(returnNorm[expiryDates,])
[1] 242   1

The data basically looks like this:

 returnNorm[expiryDates,]
               1.Close
1990-01-23 -0.04304175
1990-02-21 -0.02048786
1990-03-21  0.03466198
1990-04-23  0.06052630
1990-05-23  0.02568539
...

 returnRoll[expiryDates,]
                1.Close
1990-01-23 -0.007839561
1990-02-21 -0.018232046
1990-03-21  0.009564634
1990-04-23  0.013196285
1990-05-23 -0.042100119
...

 expiryDates
  [1] "1990-01-23" "1990-02-21" "1990-03-21" "1990-04-23" "1990-05-23" ...

______________________________
f?gt ?ber einen herausragenden Schutz gegen Massenmails. 
http://mail.yahoo.com


From brian at braverock.com  Tue Mar  9 15:27:55 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 09 Mar 2010 08:27:55 -0600
Subject: [R-SIG-Finance] Xts,
 Zoo Error: "number of items to replace not multiple of
 replacement	length"
In-Reply-To: <519655.96749.qm@web23405.mail.ird.yahoo.com>
References: <519655.96749.qm@web23405.mail.ird.yahoo.com>
Message-ID: <4B965AEB.2010207@braverock.com>

You haven't provided a reproducible example, per the posting guide.  
This makes it difficult to help you.

This error usually results from NA's or a function failing to return.  
Look at your data, and see if the replaced series has problems.

Also, given that this question really has nothing to do with finance 
(though it does purport to use xts and zoo) it probably belonged on 
R-Help, where you would likely have also been told to do your homework 
and provide a reproducible example.

   - Brian

Wob Wu wrote:
> Hello,
>
> I am trying to construct a continous price series of future contracts. This is all working well apart from one bit in my code. After spending hours of debugging I still can't find the source of the problem. So any help is highly appreciated!!!
>
> Ok, so basically I am trying to replace the log returns on specific days. This works for nearly all contracts that I am converting, apart from a
> few. And I really can't see what the difference between it is as the
> code is exactly the same.
>
> So the specific code is:
>
> returnNorm[expiryDates,] <- returnRoll[expiryDates,];
>
> This however fails with the error:
> "Error in NextMethod(.Generic) :   number of items to replace is not a multiple of replacement length"
>
> where 
>
> class(returnNorm) and class(returnRoll) is "xts" "zoo"
> class(expiryDates) is "Date"
>
> and
>
>  dim(returnRoll[expiryDates,])
> [1] 242   1
>   
>> dim(returnNorm[expiryDates,])
>>     
> [1] 242   1
>
> The data basically looks like this:
>
>  returnNorm[expiryDates,]
>                1.Close
> 1990-01-23 -0.04304175
> 1990-02-21 -0.02048786
> 1990-03-21  0.03466198
> 1990-04-23  0.06052630
> 1990-05-23  0.02568539
> ...
>
>  returnRoll[expiryDates,]
>                 1.Close
> 1990-01-23 -0.007839561
> 1990-02-21 -0.018232046
> 1990-03-21  0.009564634
> 1990-04-23  0.013196285
> 1990-05-23 -0.042100119
> ...
>
>  expiryDates
>   [1] "1990-01-23" "1990-02-21" "1990-03-21" "1990-04-23" "1990-05-23" ...
>
> ______________________________
> f?gt ?ber einen herausragenden Schutz gegen Massenmails. 
> http://mail.yahoo.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>   


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From wobwu22 at yahoo.de  Tue Mar  9 15:52:27 2010
From: wobwu22 at yahoo.de (Wob Wu)
Date: Tue, 9 Mar 2010 14:52:27 +0000 (GMT)
Subject: [R-SIG-Finance] Xts,
	Zoo Error: "number of items to replace not multiple of replacement
	length"
In-Reply-To: <4B965AEB.2010207@braverock.com>
References: <519655.96749.qm@web23405.mail.ird.yahoo.com>
	<4B965AEB.2010207@braverock.com>
Message-ID: <668795.31815.qm@web23402.mail.ird.yahoo.com>

Brian, 
thanks for your email. Sorry for not providing an reproducible example. But your guess was already spot on. The error was caused by NA's in the data. Once I've taken them out it works fine.

Thanks again!!

Wolfgang Wu



----- Urspr?ngliche Mail ----
Von: Brian G. Peterson <brian at braverock.com>
An: Wob Wu <wobwu22 at yahoo.de>
CC: R-SIG-Finance at stat.math.ethz.ch
Gesendet: Dienstag, den 9. M?rz 2010, 14:27:55 Uhr
Betreff: Re: [R-SIG-Finance] Xts, Zoo Error: "number of items to replace not multiple of replacement length"

You haven't provided a reproducible example, per the posting guide.  
This makes it difficult to help you.

This error usually results from NA's or a function failing to return.  
Look at your data, and see if the replaced series has problems.

Also, given that this question really has nothing to do with finance 
(though it does purport to use xts and zoo) it probably belonged on 
R-Help, where you would likely have also been told to do your homework 
and provide a reproducible example.

   - Brian

Wob Wu wrote:
> Hello,
>
> I am trying to construct a continous price series of future contracts. This is all working well apart from one bit in my code. After spending hours of debugging I still can't find the source of the problem. So any help is highly appreciated!!!
>
> Ok, so basically I am trying to replace the log returns on specific days. This works for nearly all contracts that I am converting, apart from a
> few. And I really can't see what the difference between it is as the
> code is exactly the same.
>
> So the specific code is:
>
> returnNorm[expiryDates,] <- returnRoll[expiryDates,];
>
> This however fails with the error:
> "Error in NextMethod(.Generic) :   number of items to replace is not a multiple of replacement length"
>
> where 
>
> class(returnNorm) and class(returnRoll) is "xts" "zoo"
> class(expiryDates) is "Date"
>
> and
>
>  dim(returnRoll[expiryDates,])
> [1] 242   1
>  
>> dim(returnNorm[expiryDates,])
>>    
> [1] 242   1
>
> The data basically looks like this:
>
>  returnNorm[expiryDates,]
>                1.Close
> 1990-01-23 -0.04304175
> 1990-02-21 -0.02048786
> 1990-03-21  0.03466198
> 1990-04-23  0.06052630
> 1990-05-23  0.02568539
> ...
>
>  returnRoll[expiryDates,]
>                 1.Close
> 1990-01-23 -0.007839561
> 1990-02-21 -0.018232046
> 1990-03-21  0.009564634
> 1990-04-23  0.013196285
> 1990-05-23 -0.042100119
> ...
>
>  expiryDates
>   [1] "1990-01-23" "1990-02-21" "1990-03-21" "1990-04-23" "1990-05-23" ...
>
> ______________________________
> f?gt ?ber einen herausragenden Schutz gegen Massenmails. 
> http://mail.yahoo.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>  


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

__________________________________________________
Do You
enden Schutz gegen Massenmails. 
http://mail.yahoo.com


From Heiko-Mayer at gmx.de  Tue Mar  9 21:35:36 2010
From: Heiko-Mayer at gmx.de (Heiko Mayer)
Date: Tue, 09 Mar 2010 21:35:36 +0100
Subject: [R-SIG-Finance] Portfolio Optimization
Message-ID: <20100309203536.222780@gmx.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100309/39e1c48e/attachment.pl>

From armstrong.whit at gmail.com  Tue Mar  9 22:19:20 2010
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Tue, 9 Mar 2010 16:19:20 -0500
Subject: [R-SIG-Finance] Portfolio Optimization
In-Reply-To: <20100309203536.222780@gmx.net>
References: <20100309203536.222780@gmx.net>
Message-ID: <8ec76081003091319t3e9a84a3kc32b7f80fe02211@mail.gmail.com>

You can do this w/ solve.QP.

use something like this:

solve.QP(lambda*2*vcv,fcst,Amat,bvec)

and set up Amat and bvec to be the appropriate duration constraints.

-Whit


On Tue, Mar 9, 2010 at 3:35 PM, Heiko Mayer <Heiko-Mayer at gmx.de> wrote:
> Dear all,
>
> I am looking for a smart way of portfolio optimization. Currently, I am
> using solve.QP from quadprog package which is quite useful for MV
> optimization. However, I would like to create a bond portfolio with
> duration constraints. It would be possible to use solve.QP as well, but
> instead of setting a target return and getting the optimal MV portfolio
> given the duration constraints, I would like to set a target risk, expected
> returns and the covariance matrix to maximize the portfolio return.
> So far, I was unlucky finding something the SIG archive and I am afraid
> solve.QP is not applicable for this task.
> Any ideas are highly appreciated.
>
> Thanks,
> Heiko
> --
>
> http://portal.gmx.net/de/go/dsl02
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From john.kerpel at gmail.com  Wed Mar 10 00:00:35 2010
From: john.kerpel at gmail.com (John Kerpel)
Date: Tue, 9 Mar 2010 17:00:35 -0600
Subject: [R-SIG-Finance] Timedate problems in Rmetrics
Message-ID: <6555fd731003091500h2116a811i50160dd541e5ee48@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100309/8b28c528/attachment.pl>

From chalabi at phys.ethz.ch  Wed Mar 10 09:48:54 2010
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Wed, 10 Mar 2010 09:48:54 +0100
Subject: [R-SIG-Finance] Timedate problems in Rmetrics
In-Reply-To: <6555fd731003091500h2116a811i50160dd541e5ee48@mail.gmail.com>
References: <6555fd731003091500h2116a811i50160dd541e5ee48@mail.gmail.com>
Message-ID: <20100310094854.48bba57c@mimi>

>>>> "JK" == John Kerpel <john.kerpel at gmail.com>
>>>> on Tue, 9 Mar 2010 17:00:35 -0600

   JK> Hi folks!
   JK>
   JK> Shouldn't the following code cut out New Year's Day (2008-01-01)
   JK> and MLK day
   JK> (2008-01-21) ?
   JK>
   JK> I need a sequence without holidays as well as weekends.  Thx!
   JK>
   JK> John
   JK>
   JK> tS<-timeSequence(from = "2008-01-01", to = "2008-01-31", by =
   JK> "day")
   JK>
   JK> tS[isBizday(tS, holidayNYSE())]

Hi John,

You need to specify the year in holidayNYSE otherwise it uses the
current one.

try with

tS[isBizday(tS, holidayNYSE(2008))]


HTH,
Yohan


   JK>
   JK> GMT
   JK> [1] [2008-01-01] [2008-01-02] [2008-01-03] [2008-01-04]
   JK> [2008-01-07]
   JK> [2008-01-08] [2008-01-09]
   JK> [8] [2008-01-10] [2008-01-11] [2008-01-14] [2008-01-15]
   JK> [2008-01-16]
   JK> [2008-01-17] [2008-01-18]
   JK> [15] [2008-01-21] [2008-01-22] [2008-01-23] [2008-01-24]
   JK> [2008-01-25]
   JK> [2008-01-28] [2008-01-29]
   JK> [22] [2008-01-30] [2008-01-31]
   JK>
   JK> holidayNYSE(2008)
   JK> NewYork
   JK> [1] [2008-01-01] [2008-01-21] [2008-02-18] [2008-03-21]
   JK> [2008-05-26]
   JK> [2008-07-04] [2008-09-01]
   JK> [8] [2008-11-27] [2008-12-25]

-- 
PhD candidate
Swiss Federal Institute of Technology
Zurich

www.ethz.ch


From robert.nicholson at gmail.com  Wed Mar 10 14:52:29 2010
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Wed, 10 Mar 2010 07:52:29 -0600
Subject: [R-SIG-Finance] Most common way to add derived columns to an XTS
	object?
Message-ID: <3EE0936A-4BEB-493C-86B7-B9F474B482C4@gmail.com>

So you have data in your XTS object and all I'm trying to do is add columns (attributes) that are derived values.

does anybody have an example of this?

I'm trying to perform a simply transformation on an existing attribute in my XTS object and store the value as a new attribute.


From jeff.a.ryan at gmail.com  Wed Mar 10 15:08:51 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Wed, 10 Mar 2010 08:08:51 -0600
Subject: [R-SIG-Finance] Most common way to add derived columns to an
	XTS object?
In-Reply-To: <3EE0936A-4BEB-493C-86B7-B9F474B482C4@gmail.com>
References: <3EE0936A-4BEB-493C-86B7-B9F474B482C4@gmail.com>
Message-ID: <e8e755251003100608y489216darebd40240911cbf46@mail.gmail.com>

Hi Robert,

New columns aren't attributes, they are columns.  For that:

> x <- xts(1:10, Sys.Date()+1:10)
> y <- x*2
> merge(x,y)
            x  y
2010-03-11  1  2
2010-03-12  2  4
2010-03-13  3  6
2010-03-14  4  8
2010-03-15  5 10
2010-03-16  6 12
2010-03-17  7 14
2010-03-18  8 16
2010-03-19  9 18
2010-03-20 10 20


HTH,
Jeff

On Wed, Mar 10, 2010 at 7:52 AM, Robert Nicholson
<robert.nicholson at gmail.com> wrote:
> So you have data in your XTS object and all I'm trying to do is add columns (attributes) that are derived values.
>
> does anybody have an example of this?
>
> I'm trying to perform a simply transformation on an existing attribute in my XTS object and store the value as a new attribute.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From josh.m.ulrich at gmail.com  Wed Mar 10 15:12:26 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 10 Mar 2010 08:12:26 -0600
Subject: [R-SIG-Finance] Most common way to add derived columns to an
	XTS object?
In-Reply-To: <3EE0936A-4BEB-493C-86B7-B9F474B482C4@gmail.com>
References: <3EE0936A-4BEB-493C-86B7-B9F474B482C4@gmail.com>
Message-ID: <8cca69991003100612h6c1fd7c9yf8e3205abf885b03@mail.gmail.com>

You already asked and received an answer for this question.  I also
answered you when you asked me this question off-list.  Please don't
post duplicate questions, especially when they were answered only days
ago!

As Jeff Ryan said, use merge.xts.  See ?merge.xts.

x <- .xts(1:10,1:10)
y <- merge(x,d=diff(x))

As I said, use "$<-".  See ?"$".
y$r <- rnorm(NROW(y))

Do some work.  No one is going to spoon feed you.

--
Joshua Ulrich
FOSS Trading: www.fosstrading.com



On Wed, Mar 10, 2010 at 7:52 AM, Robert Nicholson
<robert.nicholson at gmail.com> wrote:
> So you have data in your XTS object and all I'm trying to do is add columns (attributes) that are derived values.
>
> does anybody have an example of this?
>
> I'm trying to perform a simply transformation on an existing attribute in my XTS object and store the value as a new attribute.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From robert.nicholson at gmail.com  Wed Mar 10 15:28:04 2010
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Wed, 10 Mar 2010 08:28:04 -0600
Subject: [R-SIG-Finance] Most common way to add derived columns to an
	XTS object?
In-Reply-To: <8cca69991003100612h6c1fd7c9yf8e3205abf885b03@mail.gmail.com>
References: <3EE0936A-4BEB-493C-86B7-B9F474B482C4@gmail.com>
	<8cca69991003100612h6c1fd7c9yf8e3205abf885b03@mail.gmail.com>
Message-ID: <5D303CBD-6234-4FF6-80C1-F5E977A85D94@gmail.com>

The previous post was when I had something given to me already as in

library('quantmod')
getSymbols('AAPL')
CHANGE = rollapply(Cl(AAPL),width=2, function(x) log(x[2]/x[1]), by=1, align = "right", na.pad = TRUE)
merge.zoo(AAPL, CHANGE)

and this worked fine

however

I'm not using rollapply and simply want to iterate over my existing XTS object and create a new column
with a derived value.

I was trying

SD = rollapply(CHANGE, width=20, function(x) sd(x) * sqrt(252), by=1, align = "right", na.pad = TRUE)
colnames(SD) = "StdDev Log Change"
for (i in 1:NROW(SD)) {
SD[i, "STDEV"] = SD[i, "StdDev Log Change"] * Cl(AAPL)[i];
}

but it wasn't working

I'm sorry if you thought it was a duplicate question. In my mind the context where I was trying to perform
the change was different because in the original case some other function built me a series that I then
merged with my original. My question was how to I go about modifying the original without generating
a new series and merging.

In this case I'm iterating because I'm trying to perform a transformation where I map to another series
using the same index.

On Mar 10, 2010, at 8:12 AM, Joshua Ulrich wrote:

> You already asked and received an answer for this question.  I also
> answered you when you asked me this question off-list.  Please don't
> post duplicate questions, especially when they were answered only days
> ago!
> 
> As Jeff Ryan said, use merge.xts.  See ?merge.xts.
> 
> x <- .xts(1:10,1:10)
> y <- merge(x,d=diff(x))
> 
> As I said, use "$<-".  See ?"$".
> y$r <- rnorm(NROW(y))
> 
> Do some work.  No one is going to spoon feed you.
> 
> --
> Joshua Ulrich
> FOSS Trading: www.fosstrading.com
> 
> 
> 
> On Wed, Mar 10, 2010 at 7:52 AM, Robert Nicholson
> <robert.nicholson at gmail.com> wrote:
>> So you have data in your XTS object and all I'm trying to do is add columns (attributes) that are derived values.
>> 
>> does anybody have an example of this?
>> 
>> I'm trying to perform a simply transformation on an existing attribute in my XTS object and store the value as a new attribute.
>> 
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>> 


From robert.nicholson at gmail.com  Wed Mar 10 15:32:28 2010
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Wed, 10 Mar 2010 08:32:28 -0600
Subject: [R-SIG-Finance] Most common way to add derived columns to an
	XTS object?
In-Reply-To: <8cca69991003100612h6c1fd7c9yf8e3205abf885b03@mail.gmail.com>
References: <3EE0936A-4BEB-493C-86B7-B9F474B482C4@gmail.com>
	<8cca69991003100612h6c1fd7c9yf8e3205abf885b03@mail.gmail.com>
Message-ID: <E42ECA1C-CCA4-43ED-8712-FB2AA4125C3F@gmail.com>

It seems the missing piece in the puzzle was to define the column first with

SD$STDDEV = rep(0, NROW(SD))
for (i in 1:NROW(SD)) {
SD[i, "STDDEV"] = SD[i, "StdDev Log Change"] * Cl(AAPL)[i];
}

then I can expect to assign values to it.

On Mar 10, 2010, at 8:12 AM, Joshua Ulrich wrote:

> You already asked and received an answer for this question.  I also
> answered you when you asked me this question off-list.  Please don't
> post duplicate questions, especially when they were answered only days
> ago!
> 
> As Jeff Ryan said, use merge.xts.  See ?merge.xts.
> 
> x <- .xts(1:10,1:10)
> y <- merge(x,d=diff(x))
> 
> As I said, use "$<-".  See ?"$".
> y$r <- rnorm(NROW(y))
> 
> Do some work.  No one is going to spoon feed you.
> 
> --
> Joshua Ulrich
> FOSS Trading: www.fosstrading.com
> 
> 
> 
> On Wed, Mar 10, 2010 at 7:52 AM, Robert Nicholson
> <robert.nicholson at gmail.com> wrote:
>> So you have data in your XTS object and all I'm trying to do is add columns (attributes) that are derived values.
>> 
>> does anybody have an example of this?
>> 
>> I'm trying to perform a simply transformation on an existing attribute in my XTS object and store the value as a new attribute.
>> 
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>> 


From robert.nicholson at gmail.com  Thu Mar 11 03:23:00 2010
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Wed, 10 Mar 2010 20:23:00 -0600
Subject: [R-SIG-Finance] Perhaps somebody would like to critique my code?
Message-ID: <39A57FC1-B27D-49E9-B111-A845A5D1D62A@gmail.com>

This piece of code is giving me the answers I expect it to but to me it looks ugly and that's usually a sign that there are better more elegant ways to accomplish the same task.

I would welcome any criticism of the following as I'm only just getting started in R

library('quantmod')
getSymbols('RIMM')
TICKER=RIMM
#TICKER = as.xts(read.table("/Users/robert/Programming/R/close.txt"))
PriceChange = rollapply(Cl(TICKER), width=2, function(x) x[2] - x[1], by=1, align = "right", na.pad = TRUE)
colnames(PriceChange) = c("Price.Change")
TICKER = merge.xts(TICKER, PriceChange)
LogOfChange = rollapply(Cl(TICKER),width=2, function(x) round(log(x[2]/x[1]),4), by=1, align = "right", na.pad = TRUE)
colnames(LogOfChange) = c("Log.Change")
TICKER = merge.xts(TICKER, LogOfChange)
Sd = rollapply(LogOfChange, width=20, function(x) round(sd(x), 4), by=1, align = "right", na.pad = TRUE)
colnames(Sd) = c("StdDev.Log.Change")
TICKER = merge.xts(TICKER, Sd)
Sd$StdDev = rep(NA, NROW(Sd))
colnames(Sd) = c("StdDev.Log.Change", "StdDev")
for (i in 1:NROW(Sd)) {
Sd[i, "StdDev"] = round(TICKER[i, "StdDev.Log.Change"] * Cl(TICKER)[i],3);
}
TICKER = merge.xts(TICKER, Sd$StdDev)
Sd$Spike = rep(NA, NROW(Sd))
colnames(Sd) = c("StdDev.Log.Change", "StdDev", "Spike")
for (j in 1:NROW(Sd)) {
if (!is.na(Sd[j, "StdDev"])) {
	Sd[j, "Spike"] = round(as.numeric(TICKER[j, 'Price.Change']) / as.numeric(Sd[j-1,"StdDev"]),2)
}
}
TICKER = merge.xts(TICKER, Sd$Spike)
lineChart(Sd$Spike, line.type = 'h')
addTA(Cl(TICKER))


From scott.p.macdonald at gmail.com  Thu Mar 11 04:50:08 2010
From: scott.p.macdonald at gmail.com (Scott MacDonald)
Date: Thu, 11 Mar 2010 14:50:08 +1100
Subject: [R-SIG-Finance] The 'realized' package user manual
Message-ID: <c4adf6e91003101950n8b6340fj2a5f12f207d7f09a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100311/0ceb240b/attachment.pl>

From brian at braverock.com  Thu Mar 11 11:31:34 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 11 Mar 2010 04:31:34 -0600
Subject: [R-SIG-Finance] The 'realized' package user manual
In-Reply-To: <c4adf6e91003101950n8b6340fj2a5f12f207d7f09a@mail.gmail.com>
References: <c4adf6e91003101950n8b6340fj2a5f12f207d7f09a@mail.gmail.com>
Message-ID: <4B98C686.4030405@braverock.com>

Scott MacDonald wrote:
> Hi,
> 
> A while back I remember skimming the user manual to Scott Payseur's
> 'realized' package, but when I try to retrieve it from his home page:
> http://students.washington.edu/spayseur/realized I get a Not Found error.
> Does anyone have an alternative link?

'realized' (and its manual) is available on CRAN.

   - Brian


From rforler at uchicago.edu  Thu Mar 11 14:48:59 2010
From: rforler at uchicago.edu (Rob Forler)
Date: Thu, 11 Mar 2010 07:48:59 -0600
Subject: [R-SIG-Finance] Perhaps somebody would like to critique my code?
In-Reply-To: <39A57FC1-B27D-49E9-B111-A845A5D1D62A@gmail.com>
References: <39A57FC1-B27D-49E9-B111-A845A5D1D62A@gmail.com>
Message-ID: <eb472fec1003110548q71f6ada3vf6fb8cdbabdf8a27@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100311/ee50ab73/attachment.pl>

From Heiko-Mayer at gmx.de  Thu Mar 11 20:48:15 2010
From: Heiko-Mayer at gmx.de (Heiko Mayer)
Date: Thu, 11 Mar 2010 20:48:15 +0100
Subject: [R-SIG-Finance] Portfolio Optimization
In-Reply-To: <8ec76081003091319t3e9a84a3kc32b7f80fe02211@mail.gmail.com>
References: <20100309203536.222780@gmx.net>
	<8ec76081003091319t3e9a84a3kc32b7f80fe02211@mail.gmail.com>
Message-ID: <20100311194815.173450@gmx.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100311/b03424fe/attachment.pl>

From armstrong.whit at gmail.com  Thu Mar 11 21:10:53 2010
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Thu, 11 Mar 2010 15:10:53 -0500
Subject: [R-SIG-Finance] Portfolio Optimization
In-Reply-To: <20100311194815.173450@gmx.net>
References: <20100309203536.222780@gmx.net>
	<8ec76081003091319t3e9a84a3kc32b7f80fe02211@mail.gmail.com>
	<20100311194815.173450@gmx.net>
Message-ID: <8ec76081003111210wae8d65bu46443a058b9ee673@mail.gmail.com>

well, solve.QP is going to do this optim:

max[   x'E(R) - lambda * x' VCV x ]

Where x is your wgts vector.

You need to set lambda to reflect the amt of risk you want to take.

you can use Grinold and Kahn to decide what lambda should be:

target.lambda <- function(residual.risk, expected.IR, freq) {
    ## Grinold & Kahn page 122
    expected.IR/(2 * residual.risk * sqrt(freq))
}


On Thu, Mar 11, 2010 at 2:48 PM, Heiko Mayer <Heiko-Mayer at gmx.de> wrote:
> Whit,
>
> Thank your for your comment. I have attached the current code that uses a
> target return. As mentioned before, I would like to set a target risk
> instead and solve for the maximum return. Could you please give me a sample
> according to your suggestion below?
>
> library(quadprog)
> # Input
> eReturn=c(0.04,0.05,0.045,0.055) #expected return
> Duration=c(6,7,6.5,7.5) #current duration
> Treturn=0.01 #Target return
> TDuration=2 #Target duration
> # Solver data
> CovMat=cov(matrix(rnorm(400,mean=0,sd=0.05),nrow=100,ncol=4))
> VM=c(rep(0,4))
> A1=cbind(eReturn,Duration)
> CV=c(Treturn,TDuration)
> meq=2
> # Solver
> Res=solve.QP(Dmat=CovMat,dvec=VM,Amat=A1,bvec=CV,meq=meq)
> # Solution summary
> print(Res)
> cat("Duration in years: ",sum(as.matrix(Res$solution) *
> as.matrix(Duration)),"\n")
> cat("Volatility: ",sqrt(Res$value*2),"\n")
> cat("exp. return: ",sum(Res$solution*eReturn),"\n")
> cat("Sum of weights: ",round(sum(Res$solution),digits=2),"\n")
>
> Thank you,
> Heiko
>
> -------- Original-Nachricht --------
> Datum: Tue, 9 Mar 2010 16:19:20 -0500
> Von: Whit Armstrong <armstrong.whit at gmail.com>
> An: Heiko Mayer <Heiko-Mayer at gmx.de>
> CC: r-sig-finance at stat.math.ethz.ch
> Betreff: Re: [R-SIG-Finance] Portfolio Optimization
>
> You can do this w/ solve.QP.
>
> use something like this:
>
> solve.QP(lambda*2*vcv,fcst,Amat,bvec)
>
> and set up Amat and bvec to be the appropriate duration constraints.
>
> -Whit
>
>
> On Tue, Mar 9, 2010 at 3:35 PM, Heiko Mayer <Heiko-Mayer at gmx.de> wrote:
>> Dear all,
>>
>> I am looking for a smart way of portfolio optimization. Currently, I am
>> using solve.QP from quadprog package which is quite useful for MV
>> optimization. However, I would like to create a bond portfolio with
>> duration constraints. It would be possible to use solve.QP as well, but
>> instead of setting a target return and getting the optimal MV portfolio
>> given the duration constraints, I would like to set a target risk,
>> expected
>> returns and the covariance matrix to maximize the portfolio return.
>> So far, I was unlucky finding something the SIG archive and I am afraid
>> solve.QP is not applicable for this task.
>> Any ideas are highly appreciated.
>>
>> Thanks,
>> Heiko
>> --
>>
>> http://portal.gmx.net/de/go/dsl02
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>
>
> --
> GMX DSL: Internet, Telefon und Entertainment f?r nur 19,99 EUR/mtl.!
> http://portal.gmx.net/de/go/dsl02


From lippelanna24 at hotmail.com  Thu Mar 11 22:49:18 2010
From: lippelanna24 at hotmail.com (anna)
Date: Thu, 11 Mar 2010 13:49:18 -0800 (PST)
Subject: [R-SIG-Finance] Problems using blp function
In-Reply-To: <467758.01267828668758.JavaMail.ana@Ana-Nelsons-MacBook.local>
References: <COL108-W21801A44136B45945FD787C5390@phx.gbl>
	<467758.01267828668758.JavaMail.ana@Ana-Nelsons-MacBook.local>
Message-ID: <1268344158670-1589797.post@n4.nabble.com>


Hi Ana, I tried it with the DIV_HIST field and got the same problem. It would
work properly on Excel.

-----
Anna Lippel
-- 
View this message in context: http://n4.nabble.com/Problems-using-blp-function-tp1578730p1589797.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From lippelanna24 at hotmail.com  Thu Mar 11 23:00:28 2010
From: lippelanna24 at hotmail.com (anna)
Date: Thu, 11 Mar 2010 14:00:28 -0800 (PST)
Subject: [R-SIG-Finance] blp() function making R crash
Message-ID: <1268344828463-1589818.post@n4.nabble.com>


Hello everyone, I use blp() function in R to retrieve prices. It has always
been working and now, from out of nowhere it crashes. It gives me the option
to shut R, send the error report or debug. So when I debug this is the error
I get: 
Unhandled exception at 0x77124ca5 in Rgui.exe: 0xC0000005: Access violation
reading location 0x7e4a1000
Bloomberg help have no idea of what it could be and neither do I. Has
someone already encountered that problem?
Thanks

-----
Anna Lippel
-- 
View this message in context: http://n4.nabble.com/blp-function-making-R-crash-tp1589818p1589818.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From robert.nicholson at gmail.com  Fri Mar 12 06:42:10 2010
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Thu, 11 Mar 2010 23:42:10 -0600
Subject: [R-SIG-Finance] "Package", please ...
In-Reply-To: <19345.11876.62695.329457@lynne.math.ethz.ch>
References: <291701.34639.qm@web33008.mail.mud.yahoo.com>
	<19345.11876.62695.329457@lynne.math.ethz.ch>
Message-ID: <B78C2AB1-0BE8-476F-B51D-F21513242BBC@gmail.com>

Why isn't zoo rollapply written to take the return type? Why do you have to wrap the return value?

if I start with an xts and rollapply I get a zoo and I'm required to wrap in an as.xts so why couldn't rollapply
be written to accept the return value or derive the return value from the type of data?

On Mar 5, 2010, at 10:16 AM, Martin Maechler wrote:

>>>>>> "Jm" == Judson m <judsonm123 at yahoo.com>
>>>>>>    on Fri, 5 Mar 2010 06:17:49 -0800 (PST) writes:
> 
>>> Here was a naive attempt to do standard deviation with
>>> sliding window
>>>> require(quantmod) getSymbols("AAPL") AAPL$STDDEV =
>>>> sd(Cl(AAPL), 20) AAPL$SMA = SMA(Cl(AAPL), 10) AAPL
> 
>    Jm> I am pretty sure that rollapply in the ZOO library would
>    Jm> work for you.
> 
> There's neither "ZOO" nor would that be "library".
> 
> It is   "zoo"   and it  is a *package*.
> 
> Martin Maechler, ETH Zurich


From ggrothendieck at gmail.com  Fri Mar 12 15:14:09 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 12 Mar 2010 09:14:09 -0500
Subject: [R-SIG-Finance] "Package", please ...
In-Reply-To: <B78C2AB1-0BE8-476F-B51D-F21513242BBC@gmail.com>
References: <291701.34639.qm@web33008.mail.mud.yahoo.com>
	<19345.11876.62695.329457@lynne.math.ethz.ch> 
	<B78C2AB1-0BE8-476F-B51D-F21513242BBC@gmail.com>
Message-ID: <971536df1003120614nedc235cicdd29564a67134bf@mail.gmail.com>

rollapply is part of the zoo package and it is intended to both input
and output a zoo object.  There are zoo and zooreg methods.  If you
use rollapply then the usual S3 method search applies.

Thus if the first arg is an xts object then such an object has a class
vector of c("xts", "zoo") so rollapply.zoo gets used.

On Fri, Mar 12, 2010 at 12:42 AM, Robert Nicholson
<robert.nicholson at gmail.com> wrote:
> Why isn't zoo rollapply written to take the return type? Why do you have to wrap the return value?
>
> if I start with an xts and rollapply I get a zoo and I'm required to wrap in an as.xts so why couldn't rollapply
> be written to accept the return value or derive the return value from the type of data?
>
> On Mar 5, 2010, at 10:16 AM, Martin Maechler wrote:
>
>>>>>>> "Jm" == Judson m <judsonm123 at yahoo.com>
>>>>>>> ? ?on Fri, 5 Mar 2010 06:17:49 -0800 (PST) writes:
>>
>>>> Here was a naive attempt to do standard deviation with
>>>> sliding window
>>>>> require(quantmod) getSymbols("AAPL") AAPL$STDDEV =
>>>>> sd(Cl(AAPL), 20) AAPL$SMA = SMA(Cl(AAPL), 10) AAPL
>>
>> ? ?Jm> I am pretty sure that rollapply in the ZOO library would
>> ? ?Jm> work for you.
>>
>> There's neither "ZOO" nor would that be "library".
>>
>> It is ? "zoo" ? and it ?is a *package*.
>>
>> Martin Maechler, ETH Zurich
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From lippelanna24 at hotmail.com  Fri Mar 12 19:51:22 2010
From: lippelanna24 at hotmail.com (anna)
Date: Fri, 12 Mar 2010 10:51:22 -0800 (PST)
Subject: [R-SIG-Finance] blp() function making R crash
In-Reply-To: <1268344828463-1589818.post@n4.nabble.com>
References: <1268344828463-1589818.post@n4.nabble.com>
Message-ID: <1268419882657-1590942.post@n4.nabble.com>


No one never had any crash retrieving bloomberg data? 

-----
Anna Lippel
-- 
View this message in context: http://n4.nabble.com/blp-function-making-R-crash-tp1589818p1590942.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From diego.jara at quantil.com.co  Sat Mar 13 00:49:19 2010
From: diego.jara at quantil.com.co (Diego Jara)
Date: Fri, 12 Mar 2010 18:49:19 -0500
Subject: [R-SIG-Finance] Asian Options Inputs
Message-ID: <1730e1951003121549k452eb412hd49e0e4e032c0fc3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100312/0f7f9b8c/attachment.pl>

From scott.p.macdonald at gmail.com  Sat Mar 13 05:37:48 2010
From: scott.p.macdonald at gmail.com (Scott MacDonald)
Date: Sat, 13 Mar 2010 15:37:48 +1100
Subject: [R-SIG-Finance] The 'realized' package user manual
In-Reply-To: <4B98C686.4030405@braverock.com>
References: <c4adf6e91003101950n8b6340fj2a5f12f207d7f09a@mail.gmail.com>
	<4B98C686.4030405@braverock.com>
Message-ID: <c4adf6e91003122037w51704258xd05808718a9db145@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100313/c4e448e1/attachment.pl>

From brian at braverock.com  Sat Mar 13 11:55:26 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 13 Mar 2010 04:55:26 -0600
Subject: [R-SIG-Finance] The 'realized' package user manual
In-Reply-To: <c4adf6e91003122037w51704258xd05808718a9db145@mail.gmail.com>
References: <c4adf6e91003101950n8b6340fj2a5f12f207d7f09a@mail.gmail.com>	
	<4B98C686.4030405@braverock.com>
	<c4adf6e91003122037w51704258xd05808718a9db145@mail.gmail.com>
Message-ID: <4B9B6F1E.80300@braverock.com>

Scott,

According to the list archives, from Scott Payseur, the link was:

students.washington.edu/spayseur/realized/users.manual.08.pdf

But it is a dead link anyway, so it is included here only to help future searchers.

There is a users.manual.script.q file included in the package, which I presume 
is the code from the missing manual.

I looked in my older copies of the package, and found the docs you're looking 
for.

I've posted mirror copies here:
http://www.braverock.com/brian/realized/

As these docs are not included in the current archives on CRAN.

Regards,

     - Brian



Scott MacDonald wrote:
> Sorry, I should have been more specific.
> 
> The reference manual, realized.pdf is indeed on CRAN. I was referring to 
> a document that was more like a vignette.
> 
> I believe it was located at, 
> http://students.washington.edu/spayseur/realized/splus.supplement.08.pdf 
> <http://students.washington.edu/spayseur/realized/splus.supplement.08.pdf>
> 
> Apologies for the confusion.
> Scott/
> /
> On Thu, Mar 11, 2010 at 9:31 PM, Brian G. Peterson <brian at braverock.com 
> <mailto:brian at braverock.com>> wrote:
> 
>     Scott MacDonald wrote:
> 
>         Hi,
> 
>         A while back I remember skimming the user manual to Scott Payseur's
>         'realized' package, but when I try to retrieve it from his home
>         page:
>         http://students.washington.edu/spayseur/realized I get a Not
>         Found error.
>         Does anyone have an alternative link?
> 
> 
>     'realized' (and its manual) is available on CRAN.
> 
>      - Brian
> 
> 


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From fly1985 at gmail.com  Sat Mar 13 12:38:46 2010
From: fly1985 at gmail.com (Yin ZHANG)
Date: Sat, 13 Mar 2010 19:38:46 +0800
Subject: [R-SIG-Finance] about Nelson-Siegel model fitting
In-Reply-To: <2871c9e11003071256k2c292d8fx3b51483d5270f750@mail.gmail.com>
References: <57f92e091003060523yd051b5u4b1d724b30cc6b0@mail.gmail.com>
	<2871c9e11003060558u7c922c7ag15106d1d203003c9@mail.gmail.com>
	<57f92e091003070339t47452afbt66abe380036ba693@mail.gmail.com>
	<2871c9e11003071256k2c292d8fx3b51483d5270f750@mail.gmail.com>
Message-ID: <57f92e091003130338h1fb0ce0dxcece4d7d75b7f776@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100313/0613a489/attachment.pl>

From brian at braverock.com  Sat Mar 13 13:33:31 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 13 Mar 2010 06:33:31 -0600
Subject: [R-SIG-Finance] about Nelson-Siegel model fitting
In-Reply-To: <57f92e091003130338h1fb0ce0dxcece4d7d75b7f776@mail.gmail.com>
References: <57f92e091003060523yd051b5u4b1d724b30cc6b0@mail.gmail.com>	<2871c9e11003060558u7c922c7ag15106d1d203003c9@mail.gmail.com>	<57f92e091003070339t47452afbt66abe380036ba693@mail.gmail.com>	<2871c9e11003071256k2c292d8fx3b51483d5270f750@mail.gmail.com>
	<57f92e091003130338h1fb0ce0dxcece4d7d75b7f776@mail.gmail.com>
Message-ID: <4B9B861B.7090806@braverock.com>

Yin ZHANG wrote:
> What I have: traded bond prices, along with their coupon/maturity
> sprcifications
 >
> What I want to do: get the NelsonSiegel parameters for the fitted yield
> curve
> 
> What I am doing:
> 
> 1. I use the fixed income toolbox within Matlab 2008b to get the fitted
> curve data( it only provides the curve, but no NelsonSiegel parameters).
> i.e., Matlab only outputs the spot/forward yield you want in certain
> maturities.

As I told you before, the spot yield on a bond, given it's observed price and 
known maturity, is simple algebra.  R can do this easily, with or without the 
aid of a package.  You don't need a 'toolbox' to calculate these things, or to 
graph the resulting yield curve, fitted or not.  There are tools for doing this 
(see below) if you want them.

(there's absolutely no point in fitting a yield curve at this stage if the 
output of the fitted model isn't what you want)

You aren't going to get past the step of converting spot prices to yields on 
each series.  You have to do it to get what you want.  Write a function, make 
it easily repeatable, or use one of the packages.

> 2.Then I use the fBonds package function NelsonSiegel function to get the
> parameters of the Nelson Siegel Model.

The input to every Nelson Siegel method that I'm aware of is a set of spot 
yields and maturities. The output is a fitted yield curve and the parameters of 
the stochastic term structure model.


The packages I'm aware of for doing all this in R are

'YieldCurve', which I mentioned in my previous email.

'fBonds' which you are already familiar with.

'RQuantLib' which as discussed only returns the fitted curve, and

'termstrc' which contains a setting for using *prices* to calculate the yield 
and then fit the model.
http://cran.r-project.org/web/packages/termstrc/index.html
http://r-forge.r-project.org/projects/termstrc/

The only thing I can think of is that you haven't tried termstrc, otherwise I'm 
not sure what you've done here except to re-ask the same question.

In the interests of exposition and to aid future searches, all of these 
packages are mentioned in the CRAN Finance Task View:

http://cran.r-project.org/web/views/Finance.html

Regards,

   - Brian

> On Mon, Mar 8, 2010 at 4:56 AM, Khanh Nguyen <knguyen at cs.umb.edu> wrote:
> 
>> FittedBondCurve only returns curve data, you can not get the
>> parameters of the model.
>>
>> -k
>>
>>> I am wondering whether I can get the parameters of the Nelson-Siegel
>> model
>>> directly from this FittedBondCurve method.
>>>
>>> Also, if possible, could you kindly provide a specific example for the
>>> following bonds price dataset that I have attached with this mail?
>>>
>>> My primary aim is to get the Nelson-Siegel model parameters. Also, I want
>>> pricing errors of the fitted curve, such as sum of price errors squared.
>>>
>>> Thanks a lot in advance.
>>>
>>> Kindest
>>>
>>> Yin
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> On Sat, Mar 6, 2010 at 9:58 PM, Khanh Nguyen <knguyen at cs.umb.edu> wrote:
>>>> You can look into RQuantLib
>>>>
>>>> -k
>>>>
>>>> On Sat, Mar 6, 2010 at 8:23 AM, Yin ZHANG <fly1985 at gmail.com> wrote:
>>>>> I am trying to fit the bond market data to the Nelson-Siegel term
>>>>> structure
>>>>> model. I have a series of bond price data, most of them are coupon
>>>>> bonds.
>>>>> According to the original Nelson-Siegel model setting, my objective is
>>>>> trying to get the paremeters that minimize the weighted/unweighted
>>  sum
>>>>> of
>>>>> price errors squared.
>>>>>
>>>>> So, is there any simple way in R or any package that can do this job?
>> I
>>>>> do
>>>>> not know any about non-linear optimization, so what I need is an easy
>> to
>>>>> use
>>>>> package/code that can do the job.
>>>>>
>>>>>
>>>>> thanks a lot in advance.
>>>>>
>>>>>
>>>>> Yin
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>> -- Also note that this is not the r-help list where general R
>> questions
>>>>> should go.
>>>>>
>>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From fly1985 at gmail.com  Sat Mar 13 13:50:13 2010
From: fly1985 at gmail.com (Yin ZHANG)
Date: Sat, 13 Mar 2010 20:50:13 +0800
Subject: [R-SIG-Finance] about Nelson-Siegel model fitting
In-Reply-To: <4B9B861B.7090806@braverock.com>
References: <57f92e091003060523yd051b5u4b1d724b30cc6b0@mail.gmail.com>
	<2871c9e11003060558u7c922c7ag15106d1d203003c9@mail.gmail.com>
	<57f92e091003070339t47452afbt66abe380036ba693@mail.gmail.com>
	<2871c9e11003071256k2c292d8fx3b51483d5270f750@mail.gmail.com>
	<57f92e091003130338h1fb0ce0dxcece4d7d75b7f776@mail.gmail.com>
	<4B9B861B.7090806@braverock.com>
Message-ID: <57f92e091003130450g4e67cc0bp30e429cd4bbb1021@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100313/f3ce6bb4/attachment.pl>

From list at econinfo.de  Sat Mar 13 15:00:01 2010
From: list at econinfo.de (Owe Jessen)
Date: Sat, 13 Mar 2010 15:00:01 +0100
Subject: [R-SIG-Finance] Problem with ugarchroll
Message-ID: <4B9B9A61.6080108@econinfo.de>

Hi,

i've got a problem with ugarchroll from rgarch - can anybody help me 
explain what the following error message means and how i might 
circumvent the problem?

Done!...all converged.
Fehler in ans$z : $ operator is invalid for atomic vectors
Zus?tzlich: Warnmeldung:
In arima(data, order = c(armap, 0, armaq), include.mean = include.mean,  :
   possible convergence problem: optim gave code=1

Here's some code:
require(rgarch)
require(quantmod)
getSymbols("^GDAXI", src="yahoo", from=1991-01-02)
r <- dailyReturn(GDAXI)
r.out <- window(r, start="2007-07-01")
n.out <- length(r.out)
gjr.spec = ugarchspec(variance.model = list(model = "fGARCH", garchOrder 
= c(2,2),submodel="GJRGARCH"),mean.model = 
list(armaOrder=c(1,1)),distribution.model= dist)
gjr.roll <- ugarchroll(gjr.spec, 
r,n.ahead=10,forecast.length=n.out,refit.window="moving")

Thanks in advance.

Owe

-- 
Owe Jessen
Nettelbeckstr. 5
24105 Kiel
post at owejessen.de
http://privat.owejessen.de


From cmdr_rogue at hotmail.com  Sat Mar 13 16:28:09 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Sat, 13 Mar 2010 10:28:09 -0500
Subject: [R-SIG-Finance] Asian Options Inputs
In-Reply-To: <1730e1951003121549k452eb412hd49e0e4e032c0fc3@mail.gmail.com>
References: <1730e1951003121549k452eb412hd49e0e4e032c0fc3@mail.gmail.com>
Message-ID: <BLU0-SMTP51950F4B8C693CB9DD2862E2300@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100313/493f84bb/attachment.pl>

From alexios at 4dscape.com  Sat Mar 13 21:55:58 2010
From: alexios at 4dscape.com (alexios)
Date: Sat, 13 Mar 2010 20:55:58 +0000
Subject: [R-SIG-Finance] Problem with ugarchroll
In-Reply-To: <4B9B9A61.6080108@econinfo.de>
References: <4B9B9A61.6080108@econinfo.de>
Message-ID: <4B9BFBDE.9020807@4dscape.com>

Hi Owe,

I have tracked down the bug, which only affects the fGARCH model, and 
will upload to r-forge soon (should be available to download in the next 
cycle of checks/builds on r-forge). In the meantime, you can should use 
this equivalent specification:

gjr.spec = ugarchspec(variance.model = list(model = "gjrGARCH", 
garchOrder = c(2,2)),mean.model list(armaOrder=c(1,1)))

There is no reason to use the fGARCH spec for models which are
already implemented seperately (i.e. the gjr and aparch models)
since it is more highly parametrized (being an omnibus model) and
there will be a little more overhead in estimation.

Hope that helps.

Regards,
Alexios Ghalanos



On 3/13/2010 2:00 PM, Owe Jessen wrote:
> Hi,
>
> i've got a problem with ugarchroll from rgarch - can anybody help me
> explain what the following error message means and how i might
> circumvent the problem?
>
> Done!...all converged.
> Fehler in ans$z : $ operator is invalid for atomic vectors
> Zus?tzlich: Warnmeldung:
> In arima(data, order = c(armap, 0, armaq), include.mean = include.mean, :
> possible convergence problem: optim gave code=1
>
> Here's some code:
> require(rgarch)
> require(quantmod)
> getSymbols("^GDAXI", src="yahoo", from=1991-01-02)
> r <- dailyReturn(GDAXI)
> r.out <- window(r, start="2007-07-01")
> n.out <- length(r.out)
> gjr.spec = ugarchspec(variance.model = list(model = "fGARCH", garchOrder
> = c(2,2),submodel="GJRGARCH"),mean.model =
> list(armaOrder=c(1,1)),distribution.model= dist)
> gjr.roll <- ugarchroll(gjr.spec,
> r,n.ahead=10,forecast.length=n.out,refit.window="moving")
>
> Thanks in advance.
>
> Owe
>


From scott.p.macdonald at gmail.com  Sun Mar 14 02:29:56 2010
From: scott.p.macdonald at gmail.com (Scott MacDonald)
Date: Sun, 14 Mar 2010 12:29:56 +1100
Subject: [R-SIG-Finance] The 'realized' package user manual
In-Reply-To: <4B9B6F1E.80300@braverock.com>
References: <c4adf6e91003101950n8b6340fj2a5f12f207d7f09a@mail.gmail.com>
	<4B98C686.4030405@braverock.com>
	<c4adf6e91003122037w51704258xd05808718a9db145@mail.gmail.com>
	<4B9B6F1E.80300@braverock.com>
Message-ID: <c4adf6e91003131729q6207857bk86e461ab16e6f399@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100314/e18ba961/attachment.pl>

From wuertz at itp.phys.ethz.ch  Mon Mar 15 08:48:33 2010
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Mon, 15 Mar 2010 08:48:33 +0100
Subject: [R-SIG-Finance] Asian Options Inputs
In-Reply-To: <1730e1951003121549k452eb412hd49e0e4e032c0fc3@mail.gmail.com>
References: <1730e1951003121549k452eb412hd49e0e4e032c0fc3@mail.gmail.com>
Message-ID: <4B9DE651.7020800@itp.phys.ethz.ch>

Diego Jara wrote:
> Hi. Can someone help me understand better the inputs to the function
> TurnbullWakemanAsianApprox?
> In particular, it's not clear from the manual which is the difference
> between S and SA, and between Time and time.
>
> Thank you.
>
>   
Have a look in Espen Haugs book, the notation follows his book.

Kind Regards
Diethelm


From edd at debian.org  Mon Mar 15 12:25:20 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 15 Mar 2010 06:25:20 -0500
Subject: [R-SIG-Finance] R/Finance 2010 agenda and registration reminder
Message-ID: <19358.6432.352183.79853@ron.nulle.part>


R/Finance 2010: Applied Finance with R
April 16 & 17, Chicago, IL, US
www.RinFinance.com <http://www.RinFinance.com>
 
The second annual R/Finance conference for applied finance using R, the
premier free software system for statistical computation and graphics, will
be held this spring in Chicago, IL, USA on Friday April 16 and Saturday April
17, 2010.

Registration is still open and early bird pricing ends April 1, 2010.  Given
the current registration, we anticipate that some of the tutorials will be
closed before that date.  Register at http://www.RinFinance.com to secure a
tutorial spot and avoid a price increase.

The conference includes keynote and regular presentations as well as short
lightning talks to present a diverse range of ideas.  The planned list of
tutorials and conference presentations (which is also available at
http://www.RinFinance.com) follows:


Friday, April 16th, 2010
------------------------
Optional pre-conference tutorials:
  Dirk Eddelbuettel: Rcpp/RInside and How to Extend R with C++
  Jeff Ryan Trading with R
  Peter Carl/Brian Peterson: Complex Portfolio Optimization with General Business Objectives
  Josh Buckner/Mark Seligman: GPU Programming with R

*Achim Zeileis: Testing, Monitoring and Dating Structural Change in FX Regimes
David Smith: Analysing Large-Scale Financial Data Sets in R
Tony Plate: Mean-variance Portfolio Optimization: Do Historical 
Correlations Help or Hinder Risk Control in a Crisis?
*Ralph Vince/Soren MacBeth: Leverage Space Portfolio Model
Kris Boudt: Portfolio Optimization with Conditional Value-at-Risk Budgets
Steve Kane/Jeff Lewis: The esperr package and the Esper API
Lightning talks:
  Peter Carl: The blotter / instrument / strategy toolchain
  Wei-han Liu: Improved Generalized Gram-Charlier Expansions based on 
Multivariate Skew Distributions
  Wendy Wang: Strategic Asset Allocation using Markov Switching
  James "JD" Long: Zen and the Art of Stochastic Dart Throwing (How I 
Build Insurance / Reinsurance Models with R)
 
Saturday, April 17th, 2010
------
Josh Buckner/Mark Seligman: GPU computing with the gputools package
Saptarshi Guha: R and Hadoop Integrated Processing Environment
Stefan Theussl: Distributed Text Mining with tm 
*Bernhard Pfaff: Risk Modeling with R
Lightning talks:
  Jonathan Cornelissen: RTAQ: Tools for Analysis of Trades and Quotes
  Robert Grossman: Computing in the Cloud
  Nicolas Christou/David Diez: Statistical Finance for Investors Unfamiliar with Quantitative Methods
Maria Belianina: Data Management Challenges for Quantitative Research
*Marc Wildi: Adapting the MDFA to 'Financial Trading'
Eric Zivot: Simulation-based Estimation of Continuous Time Models
Dirk Eddelbuettel/Khanh Nguyen: RQuantLib: Interfacing QuantLib from R
Lightning talks:
  Jeff Ryan: Databasing without the Database: The indexing package
  Josh Ulrich: Fast and Flexible Technical Analysis with TTR
  Ruud Koning: Thick Tails, Thin Tails, or Dependence?
  Michael North: R and Repast Simphony


R/Finance 2010 is organized by a local group of R package authors and 
community contributors, hosted by the International Center for Futures 
and Derivatives (ICFD) at the University of Illinois at Chicago and made 
possible via sponsorship support from ICFD, REvolution Computing, 
OneMarketData and Insight Algorithmics.


For the program committee:
Gib Bassett, Peter Carl, Dirk Eddelbuettel, John Miller, Brian Peterson, 
Dale Rosenthal, Jeffrey Ryan

-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From rene.naarmann at mnet-online.de  Tue Mar 16 00:04:39 2010
From: rene.naarmann at mnet-online.de (=?ISO-8859-15?Q?Ren=E9_Naarmann?=)
Date: Tue, 16 Mar 2010 00:04:39 +0100
Subject: [R-SIG-Finance] style.fit by month
Message-ID: <4B9EBD07.2020900@mnet-online.de>

Hi R-users,

it is the first time for me writing to this group. I would be grateful 
if somebody could help me to find
a solution to my problem.

I am working on my final thesis and I would like to analyse the impact 
of return frequency
using return-based style analysis. Specifically I would like to 
calculate attributable returns. An attributalbe return
is the difference between the realised return of a fund and the forecast 
from using the estimated style coefficients
multiplied by the respective indexseries.

I am using the implemented functions for style analysis in the 
PerformanceAnalytics Package.
I would like to use the quadratic programming algorithm just for each 
day in a specific month, i.e.
use the daily returns from january to calculate the style weigths. This 
should be done month by month.
In the next step the calculation should include two months of data and 
calculate the style weigths month by month.

So far I tried to usw apply.month in combination with style.fit. This 
returns the same results for each month.
In the next step I tried to use some code out of chart.RollingStyle. I 
change it for my purpose and
receive the style weights in a rolling calculation and could enable the 
by option. So I get styleweights
over a specific width and could shift the calculation by a specified 
block, i.e. calculate styleweigths
for 20 days shifting this calculation by the next 20 days. What I would 
like to have is a shifting by month
to use the last month realised daily returns to forecast the style 
weigths for the next month.

Has somebody an idea how to handle this problem?
Thank you in advance

Ren? Naarmann

-- 
E-Mail: rene.naarmann at mnet-online.de


From J_Cuisinier at hotmail.com  Tue Mar 16 07:27:31 2010
From: J_Cuisinier at hotmail.com (julien cuisinier)
Date: Tue, 16 Mar 2010 07:27:31 +0100
Subject: [R-SIG-Finance] style.fit by month
In-Reply-To: <4B9EBD07.2020900@mnet-online.de>
References: <4B9EBD07.2020900@mnet-online.de>
Message-ID: <BLU0-SMTP148BB1216F8827226EBC6C8F2D0@phx.gbl>

Hi Ren?,



For quad prog algo, look for solve.QP from quadprog package in R. It  
should allow you to do what you want (if I understood well). Please  
note I am not too familiar with the PerformanceAnalytics package & its  
capabilities (but suspect its style analysis function is a wrapper for  
solve.QP). Building a rolling window analysis is quite trivial from  
there.

On another note, using 1 month data is probably too small to have  
stable results (depending on how many factors in your style analysis -  
personal rule of thumb is 10 times the number of factors gives you a  
benchmark of nbr of data points needed) , I would look to include more  
returns in your linear regression. One could look into applying some  
sort of weighting to your regression to improve forecasting power  
(e.g. exponential weighting). I guess you are also looking into the  
residuals for autocorrelation & heteroskedasticity which will impact  
the hypothesis testing of your betas/coefficients.

& Finally, always best to make a question as concise as possible,  
include a piece of reproducible code of what you are trying to do &  
some system information (what R version, what OS) ... that often makes  
easier for list member to help & follow (more or less) the posting  
guide.



HTH
Julien


On Mar 16, 2010, at 12:04 AM, Ren? Naarmann wrote:

> Hi R-users,
>
> it is the first time for me writing to this group. I would be  
> grateful if somebody could help me to find
> a solution to my problem.
>
> I am working on my final thesis and I would like to analyse the  
> impact of return frequency
> using return-based style analysis. Specifically I would like to  
> calculate attributable returns. An attributalbe return
> is the difference between the realised return of a fund and the  
> forecast from using the estimated style coefficients
> multiplied by the respective indexseries.
>
> I am using the implemented functions for style analysis in the  
> PerformanceAnalytics Package.
> I would like to use the quadratic programming algorithm just for  
> each day in a specific month, i.e.
> use the daily returns from january to calculate the style weigths.  
> This should be done month by month.
> In the next step the calculation should include two months of data  
> and calculate the style weigths month by month.
>
> So far I tried to usw apply.month in combination with style.fit.  
> This returns the same results for each month.
> In the next step I tried to use some code out of chart.RollingStyle.  
> I change it for my purpose and
> receive the style weights in a rolling calculation and could enable  
> the by option. So I get styleweights
> over a specific width and could shift the calculation by a specified  
> block, i.e. calculate styleweigths
> for 20 days shifting this calculation by the next 20 days. What I  
> would like to have is a shifting by month
> to use the last month realised daily returns to forecast the style  
> weigths for the next month.
>
> Has somebody an idea how to handle this problem?
> Thank you in advance
>
> Ren? Naarmann
>
> -- 
> E-Mail: rene.naarmann at mnet-online.de
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R  
> questions should go.
>


From rene.naarmann at mnet-online.de  Tue Mar 16 16:06:34 2010
From: rene.naarmann at mnet-online.de (=?ISO-8859-1?Q?Ren=E9_Naarmann?=)
Date: Tue, 16 Mar 2010 16:06:34 +0100
Subject: [R-SIG-Finance] style.fit by month
In-Reply-To: <BLU0-SMTP148BB1216F8827226EBC6C8F2D0@phx.gbl>
References: <4B9EBD07.2020900@mnet-online.de>
	<BLU0-SMTP148BB1216F8827226EBC6C8F2D0@phx.gbl>
Message-ID: <4B9F9E7A.9070707@mnet-online.de>

Hi all,

thank you Julien for your thougts. I working with R 2.10.0 on Windows XP.
I remembered the function applySeries and fapply respectively. I tried 
to calculate
a variance covariance matrix over different periods. When this works I 
could go on with solve.QP which needs the Dmat.

Here is an example:
require(timeSeries)
btime <- timeSequence(from="1999-01-01", to="1999-03-31", by = "month")
etime <- timeLastDayInMonth(btime[-1])
btime <- btime[-length(btime)]
data1 <- rnorm(1:90)
data2 <- matrix(rnorm(270), ncol = 3)
colnames(data2) <- LETTERS[1:3]
datats <- timeSequence(from="1999-01-01", to="1999-03-31", by = "day")
S <- timeSeries(data2, datats)
applySeries(S, btime, etime, FUN = function(x) cov(x, 
use="pairwise.complete.obs"))
cov(window(S, start="1999-01-01", end="1999-02-28"))

The result is a matrix which contains the varcov matrices for 2 
subperiods which is fine,
but when I am using my real Data I receive this Message:
Fehler in midnightStandard2(charvec, format) :  'charvec' has non-NA 
entries of different number of characters
I don't understand this error message, can anyone help?


I read my datafile from a spreadsheet via readSeries(), the head looks 
like this:
                    R2G          R2V           R1G           R1V    
MSCIWexUS
1999-01-04 -0.006477506  0.004066846 -0.0026417776 -0.0009521722  
0.018939565
1999-01-05  0.001725935  0.002339151  0.0128278433  0.0116685255  
0.006108505
1999-01-06  0.018860732  0.007514636  0.0211913231  0.0215123444  
0.019311270
1999-01-07  0.005040827 -0.004752986 -0.0028397673  0.0013254882 
-0.005757679
1999-01-08  0.011525972  0.003911511 -0.0006109632  0.0101291838  
0.001059926
1999-01-11  0.013880501 -0.005775207 -0.0039712968 -0.0108176871 
-0.011788948

Thanks in advance
Ren?


julien cuisinier schrieb:
> Hi Ren?,
>
>
>
> For quad prog algo, look for solve.QP from quadprog package in R. It 
> should allow you to do what you want (if I understood well). Please 
> note I am not too familiar with the PerformanceAnalytics package & its 
> capabilities (but suspect its style analysis function is a wrapper for 
> solve.QP). Building a rolling window analysis is quite trivial from 
> there.
>
> On another note, using 1 month data is probably too small to have 
> stable results (depending on how many factors in your style analysis - 
> personal rule of thumb is 10 times the number of factors gives you a 
> benchmark of nbr of data points needed) , I would look to include more 
> returns in your linear regression. One could look into applying some 
> sort of weighting to your regression to improve forecasting power 
> (e.g. exponential weighting). I guess you are also looking into the 
> residuals for autocorrelation & heteroskedasticity which will impact 
> the hypothesis testing of your betas/coefficients.
>
> & Finally, always best to make a question as concise as possible, 
> include a piece of reproducible code of what you are trying to do & 
> some system information (what R version, what OS) ... that often makes 
> easier for list member to help & follow (more or less) the posting guide.
>
>
>
> HTH
> Julien
>
>
> On Mar 16, 2010, at 12:04 AM, Ren? Naarmann wrote:
>
>> Hi R-users,
>>
>> it is the first time for me writing to this group. I would be 
>> grateful if somebody could help me to find
>> a solution to my problem.
>>
>> I am working on my final thesis and I would like to analyse the 
>> impact of return frequency
>> using return-based style analysis. Specifically I would like to 
>> calculate attributable returns. An attributalbe return
>> is the difference between the realised return of a fund and the 
>> forecast from using the estimated style coefficients
>> multiplied by the respective indexseries.
>>
>> I am using the implemented functions for style analysis in the 
>> PerformanceAnalytics Package.
>> I would like to use the quadratic programming algorithm just for each 
>> day in a specific month, i.e.
>> use the daily returns from january to calculate the style weigths. 
>> This should be done month by month.
>> In the next step the calculation should include two months of data 
>> and calculate the style weigths month by month.
>>
>> So far I tried to usw apply.month in combination with style.fit. This 
>> returns the same results for each month.
>> In the next step I tried to use some code out of chart.RollingStyle. 
>> I change it for my purpose and
>> receive the style weights in a rolling calculation and could enable 
>> the by option. So I get styleweights
>> over a specific width and could shift the calculation by a specified 
>> block, i.e. calculate styleweigths
>> for 20 days shifting this calculation by the next 20 days. What I 
>> would like to have is a shifting by month
>> to use the last month realised daily returns to forecast the style 
>> weigths for the next month.
>>
>> Has somebody an idea how to handle this problem?
>> Thank you in advance
>>
>> Ren? Naarmann
>>
>> -- 
>> E-Mail: rene.naarmann at mnet-online.de
>>
>> _______________________________________________
>> R-SIG-Finance at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R 
>> questions should go.
>>
>
>
>

-- 
Ren? Naarmann
Eckentaler Str. 16
90542 Eckental
---
Tel.: 	(09126)-294069
Mobil: 	(0170)-8100941
E-Mail: rene.naarmann at mnet-online.de


From lippelanna24 at hotmail.com  Wed Mar 17 20:48:20 2010
From: lippelanna24 at hotmail.com (anna)
Date: Wed, 17 Mar 2010 11:48:20 -0800 (PST)
Subject: [R-SIG-Finance] Rownames on blp() return matrix
Message-ID: <1268855300702-1597041.post@n4.nabble.com>


Hello, I am using the blp() function from RBloomberg package to retrieve a
matrix of prices. I had to reinstall the package and since I can't retrieve
the dates with rownames() as I used to before. When I display the matrix on
the console I can see the row names (dates) on the left but when i do
rownames() it returns me a NULL value...Any idea? Has some changes been done
on this package? Thank you

-----
Anna Lippel
-- 
View this message in context: http://n4.nabble.com/Rownames-on-blp-return-matrix-tp1597041p1597041.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Wed Mar 17 20:52:53 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 17 Mar 2010 14:52:53 -0500
Subject: [R-SIG-Finance] Rownames on blp() return matrix
In-Reply-To: <1268855300702-1597041.post@n4.nabble.com>
References: <1268855300702-1597041.post@n4.nabble.com>
Message-ID: <4BA13315.1050303@braverock.com>

anna wrote:
> Hello, I am using the blp() function from RBloomberg package to retrieve a
> matrix of prices. I had to reinstall the package and since I can't retrieve
> the dates with rownames() as I used to before. When I display the matrix on
> the console I can see the row names (dates) on the left but when i do
> rownames() it returns me a NULL value...Any idea? Has some changes been done
> on this package? Thank you
>   
I don't recall, and I'm not at a Bloomberg/R machine right now, but 
isn't the returned time series class zoo or xts?

in that case, you would use 'index', not 'rownames'.

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From lippelanna24 at hotmail.com  Wed Mar 17 21:00:30 2010
From: lippelanna24 at hotmail.com (anna)
Date: Wed, 17 Mar 2010 12:00:30 -0800 (PST)
Subject: [R-SIG-Finance] Rownames on blp() return matrix
In-Reply-To: <4BA13315.1050303@braverock.com>
References: <1268855300702-1597041.post@n4.nabble.com>
	<4BA13315.1050303@braverock.com>
Message-ID: <1268856030386-1597063.post@n4.nabble.com>


Hi Brian! well yes, i tested if it was a zoo and a matrix object and it
returned true in both cases that's why i got a bit confused. So now I used
index() and it worked but it's funny because rownames() would work before.
I'm wondering if the package hasn't changes  a bit, specially that I had to
reinstall it. Anyway, thank you!!

-----
Anna Lippel
-- 
View this message in context: http://n4.nabble.com/Rownames-on-blp-return-matrix-tp1597041p1597063.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From ajayshah at mayin.org  Thu Mar 18 06:30:03 2010
From: ajayshah at mayin.org (Ajay Shah)
Date: Thu, 18 Mar 2010 11:00:03 +0530
Subject: [R-SIG-Finance] A bug report on quantmod::getSymbols (or a bug in
	FRED)
Message-ID: <20100318053003.GA88026@ajay-shahs-macbook-pro.local>

Folks,

Here's a blemish:

  library(quantmod)
  getSymbols("PPIACO", src="FRED")
  PPIACO[342:347,]

which gives me:

           PPIACO
1941-06-01   15.0
1941-07-01   15.3
1941-08-01   15.6
1941-09-01   15.8
<NA>         15.9
1941-11-01   15.9

where, as you see, the date for October 1941 is missing. This could be
a mistake in the underlying FRED data or it could be a flaw in
getSymbols.FRED.

Hope this helps,

-- 
Ajay Shah                                      http://www.mayin.org/ajayshah  
ajayshah at mayin.org                             http://ajayshahblog.blogspot.com
<*(:-? - wizard who doesn't know the answer.


From breman.mark at gmail.com  Thu Mar 18 08:13:58 2010
From: breman.mark at gmail.com (Mark Breman)
Date: Thu, 18 Mar 2010 08:13:58 +0100
Subject: [R-SIG-Finance] A bug report on quantmod::getSymbols (or a bug
	in FRED)
In-Reply-To: <20100318053003.GA88026@ajay-shahs-macbook-pro.local>
References: <20100318053003.GA88026@ajay-shahs-macbook-pro.local>
Message-ID: <5e6a2e671003180013t40eea160tc48c1689bd321018@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100318/ec43483d/attachment.pl>

From jeff.a.ryan at gmail.com  Thu Mar 18 13:57:14 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Thu, 18 Mar 2010 07:57:14 -0500
Subject: [R-SIG-Finance] A bug report on quantmod::getSymbols (or a bug
	in FRED)
In-Reply-To: <20100318053003.GA88026@ajay-shahs-macbook-pro.local>
References: <20100318053003.GA88026@ajay-shahs-macbook-pro.local>
Message-ID: <e8e755251003180557q4396e982u48dda142558e4763@mail.gmail.com>

Try the newest version (from R-forge) of xts.  There was a strange R
bug in POSIXct times that combined with xts caused some odd behavior.
Not too sure if that is the reason, but mine seems to work:

> getSymbols("PPIACO", src="FRED")
[1] "PPIACO"
> PPIACO['1941']
           PPIACO
1941-01-01   13.9
1941-02-01   13.9
1941-03-01   14.0
1941-04-01   14.4
1941-05-01   14.6
1941-06-01   15.0
1941-07-01   15.3
1941-08-01   15.6
1941-09-01   15.8
1941-10-01   15.9
1941-11-01   15.9
1941-12-01   16.2
>

sessionInfo() is also helpful when it comes to diagnosing.
> sessionInfo()
R version 2.10.1 (2009-12-14)
i386-apple-darwin10.0.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] quantmod_0.3-14 TTR_0.20-1      Defaults_1.1-1  xts_0.7-1
[5] zoo_1.6-2

loaded via a namespace (and not attached):
[1] grid_2.10.1     lattice_0.17-26


Best,
Jeff

On Thu, Mar 18, 2010 at 12:30 AM, Ajay Shah <ajayshah at mayin.org> wrote:
> Folks,
>
> Here's a blemish:
>
> ?library(quantmod)
> ?getSymbols("PPIACO", src="FRED")
> ?PPIACO[342:347,]
>
> which gives me:
>
> ? ? ? ? ? PPIACO
> 1941-06-01 ? 15.0
> 1941-07-01 ? 15.3
> 1941-08-01 ? 15.6
> 1941-09-01 ? 15.8
> <NA> ? ? ? ? 15.9
> 1941-11-01 ? 15.9
>
> where, as you see, the date for October 1941 is missing. This could be
> a mistake in the underlying FRED data or it could be a flaw in
> getSymbols.FRED.
>
> Hope this helps,
>
> --
> Ajay Shah ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?http://www.mayin.org/ajayshah
> ajayshah at mayin.org ? ? ? ? ? ? ? ? ? ? ? ? ? ? http://ajayshahblog.blogspot.com
> <*(:-? - wizard who doesn't know the answer.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From robert.nicholson at gmail.com  Fri Mar 19 13:33:10 2010
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Fri, 19 Mar 2010 07:33:10 -0500
Subject: [R-SIG-Finance] addTA on an existing subchart
Message-ID: <143DC90F-98A9-4950-A98D-533B79E255DD@gmail.com>

Is this supported yet?

docs say

The on is used to identify which subchart to add the graphic to. By default, on=NA will draw the series in a new subchart below the last indicator. Setting this to either a positive or negative value will allow for the series to be super-imposed on, or under, the (sub)chart specified, respectively. A value of 1 refers to the main chart, and at present is the only location supported.


From brian at braverock.com  Fri Mar 19 13:42:02 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 19 Mar 2010 07:42:02 -0500
Subject: [R-SIG-Finance] addTA on an existing subchart
In-Reply-To: <143DC90F-98A9-4950-A98D-533B79E255DD@gmail.com>
References: <143DC90F-98A9-4950-A98D-533B79E255DD@gmail.com>
Message-ID: <4BA3711A.8020709@braverock.com>

Robert Nicholson wrote:
> Is this supported yet?
>
> docs say
>
> The on is used to identify which subchart to add the graphic to. By default, on=NA will draw the series in a new subchart below the last indicator. Setting this to either a positive or negative value will allow for the series to be super-imposed on, or under, the (sub)chart specified, respectively. A value of 1 refers to the main chart, and at present is the only location supported.
>   
Only in development code.


From megh700004 at yahoo.com  Sun Mar 21 06:44:59 2010
From: megh700004 at yahoo.com (Megh)
Date: Sat, 20 Mar 2010 21:44:59 -0800 (PST)
Subject: [R-SIG-Finance] Ratio collar option
Message-ID: <1269150299502-1676491.post@n4.nabble.com>


My query is not directly R related rather on finance. Hopefully folks here
would give some solution. I would like to ask what is the "Ratio collar
option". I know about the Collar option and if I search over net on Ratio
collar option all the time it refers to Collar option only. Are they both
same? Why the term "Ratio" there?

Any view will be highly appreciated.

Thanks,
-- 
View this message in context: http://n4.nabble.com/Ratio-collar-option-tp1676491p1676491.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From sunder_1600 at yahoo.com  Sun Mar 21 11:09:25 2010
From: sunder_1600 at yahoo.com (Zany Z)
Date: Sun, 21 Mar 2010 03:09:25 -0700 (PDT)
Subject: [R-SIG-Finance] fArma
Message-ID: <850274.98769.qm@web113216.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100321/b372456b/attachment.pl>

From brian at braverock.com  Sun Mar 21 11:23:57 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 21 Mar 2010 05:23:57 -0500
Subject: [R-SIG-Finance] fArma
In-Reply-To: <850274.98769.qm@web113216.mail.gq1.yahoo.com>
References: <850274.98769.qm@web113216.mail.gq1.yahoo.com>
Message-ID: <4BA5F3BD.3060103@braverock.com>

You haven't provided your data series, and you haven't said *where* the 
script fails.  That makes it difficult to help you.

Do the examples for fArma work? 
Are all the files in the correct location?
Your script requires fSeries, but not fArma.
what is the output of traceback() after the error?


Zany Z wrote:
> Hi,
>
> I don't know where else to seek help, if not applicable, I would be grateful if you could direct me to a relevant reference.
>
> I tried running (this code was gotten from TAMU.edu) but I kept getting this error "Error in eval(expr, envir, enclos) : object 'package' not found". I looked into fArma, but to no avail. What should I do? What is object 'package'?:
> #Examples 
> #Fit GE data using AR(1),AR(6), MA(2), ARMA(2,1), ARIMA(2,1,0) Models
> # Yt = a * Y(t-1) + et
>
> Price<-scan("C:\\R\\IXIC.txt")
> N<-length(Price)  
> Return<-Price[2:N]/Price[1:(N-1)]-1
> LogReturn<-log(1+Return)
> LogPrice<-log(Price)
>
> library("fSeries")
>
> #Fit GE Daily log return
> fit_ar<-armaFit(formula = LogReturn ~ arima(1,0,0))     #AR (1)
> fit_ar6<-armaFit(formula = LogReturn ~ arima(6,0,0))     #AR (6)
> fit_ma<-armaFit(formula = LogReturn ~ arima(0,0,2))     #ma (2)
> fit_arma<-armaFit(formula = LogReturn ~ arima(2,0,1))   #arma (2,1)    
>
> #arima model fit GE daily log prices
> fit_arima<-armaFit(formula = LogPrice ~ arima(2,1,0))  #arima (2,1,0)           
>        
>
> sink("C:\\R\\ar.txt")
> pdf("C:\\R\\ar.pdf")
> summary(fit_ar)
> dev.off()
> sink()
>
> sink("C:\\R\\ar6.txt")
> pdf("C:\\R\\ar6.pdf")
> summary(fit_ar6)
> dev.off()
> sink()
>
> sink("C:\\R\\ma.txt")
> pdf("C:\\R\\ma.pdf")
> summary(fit_ma)
> dev.off()
> sink()
>
> sink("C:\\R\\arma.txt")
> pdf("C:\\R\\arma.pdf")
> summary(fit_arma)
> dev.off()
> sink()
>
> sink("C:\\R\\arima.txt")
> pdf("C:\\R\\arima.pdf")
> summary(fit_arima)
> dev.off()
> sink()
>
>   
-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From cmdr_rogue at hotmail.com  Sun Mar 21 14:57:59 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Sun, 21 Mar 2010 09:57:59 -0400
Subject: [R-SIG-Finance] Ratio collar option
In-Reply-To: <1269150299502-1676491.post@n4.nabble.com>
References: <1269150299502-1676491.post@n4.nabble.com>
Message-ID: <BLU0-SMTP832969D16A3204FD172A60E2280@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100321/2e6a5694/attachment.pl>

From bogaso.christofer at gmail.com  Sun Mar 21 18:00:32 2010
From: bogaso.christofer at gmail.com (Bogaso)
Date: Sun, 21 Mar 2010 09:00:32 -0800 (PST)
Subject: [R-SIG-Finance] VaR for path-dependent option portfolio
Message-ID: <1269190832111-1676787.post@n4.nabble.com>


Hi all,

Here I am mandated to find the VaR for an Asian type option say call option,
wherein pay-off for that option will be simple average of daily prices (20
trading days) for next month. For example today it is 21st-march and pay-off
will be daily average for all trading days for the month of april, which is
going to expire on the last trading day of april. 

I am clear on calculating VaR, at least daily, for European type option
wherein distribution of option price for next day is determined using BS
formula and hence the distribution of P/L for the option premium. However in
current case as option is path-dependent possibly there is no closed form
solution available to determine the fair price of the option. Therefore I am
seeking help on how to deal with my present case. If experts here give some
clue as well as some published documents or books on the regard I would be
truly grateful. Whatever I am aware of is calculation of VaR for plain
vanilla option.

Thanks,
-- 
View this message in context: http://n4.nabble.com/VaR-for-path-dependent-option-portfolio-tp1676787p1676787.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From cmdr_rogue at hotmail.com  Sun Mar 21 20:17:03 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Sun, 21 Mar 2010 15:17:03 -0400
Subject: [R-SIG-Finance] VaR for path-dependent option portfolio
In-Reply-To: <1269190832111-1676787.post@n4.nabble.com>
References: <1269190832111-1676787.post@n4.nabble.com>
Message-ID: <BLU0-SMTP15ADEFBE3CB934FD30C5ADE2280@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100321/2737e0f2/attachment.pl>

From robert.nicholson at gmail.com  Mon Mar 22 01:12:34 2010
From: robert.nicholson at gmail.com (Robert Nicholson)
Date: Sun, 21 Mar 2010 19:12:34 -0500
Subject: [R-SIG-Finance] Any examples of addTA legend?
Message-ID: <36E6FBE6-1147-4D04-AAC8-7B1CAB14112D@gmail.com>

Looking for examples on how addTA legend functions should be defined.

Looking to add Low and High of the series to the existing legend.


From dengyishuo at 163.com  Mon Mar 22 07:56:36 2010
From: dengyishuo at 163.com (=?UTF-8?B?6YKT5LiA56GV?=)
Date: Sun, 21 Mar 2010 22:56:36 -0800 (PST)
Subject: [R-SIG-Finance] How to get Time-sharing data with package
	"quantmod"?
Message-ID: <1269240996233-1677249.post@n4.nabble.com>



Hi all!

Is there any way for me to get Time-sharing data with packages "quantmod"?

Thank you!


-----
?????????????????
-- 
View this message in context: http://n4.nabble.com/How-to-get-Time-sharing-data-with-package-quantmod-tp1677249p1677249.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From breman.mark at gmail.com  Mon Mar 22 14:00:44 2010
From: breman.mark at gmail.com (Mark Breman)
Date: Mon, 22 Mar 2010 14:00:44 +0100
Subject: [R-SIG-Finance] Strange side effect on setting not existing column
	to NULL in xts
Message-ID: <5e6a2e671003220600w3ee8fbdbya4c8de648be9d1db@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100322/fdf55ccb/attachment.pl>

From f.pollastri at inrim.it  Mon Mar 22 15:32:47 2010
From: f.pollastri at inrim.it (Fabrizio Pollastri)
Date: Mon, 22 Mar 2010 15:32:47 +0100
Subject: [R-SIG-Finance] efficient yearly return on a monthly basis
Message-ID: <4BA77F8F.80800@inrim.it>

The following code computes yearly returns every month on the xts seqence s.

s=xts(1:1000,as.Date(0:999))
yret_by_month = diff(s,lag=365)/lag(s,k=365)[endpoints(s,on="months")]

There is a more efficient way to avoid diff and lag to perform 
computations over the whole sequence? Thanks in advance for any help.


Regards,
F. Pollastri


From brian at braverock.com  Mon Mar 22 15:41:27 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 22 Mar 2010 09:41:27 -0500
Subject: [R-SIG-Finance] efficient yearly return on a monthly basis
In-Reply-To: <4BA77F8F.80800@inrim.it>
References: <4BA77F8F.80800@inrim.it>
Message-ID: <4BA78197.4080607@braverock.com>

Fabrizio Pollastri wrote:
> The following code computes yearly returns every month on the xts 
> seqence s.
>
> s=xts(1:1000,as.Date(0:999))
> yret_by_month = diff(s,lag=365)/lag(s,k=365)[endpoints(s,on="months")]
>
> There is a more efficient way to avoid diff and lag to perform 
> computations over the whole sequence? Thanks in advance for any help.
It is of course unlikely that you have daily returns for 365 days of the 
year, but thanks for providing a reproducible example.

The first issue I see with your code is that you are calculating for 
every day, but only care about "extracting" the monthly endpoints.  So 
you're doing (in this example) ~30x more calculation than required (and 
~22x more than required on likely real data).
 
diff and Lag are pretty efficient, but I suspect that you can calculate 
log (or simple) returns on the daily or monthly series, then use runSum 
on a x-days or 12-month window to get your rolling annual return.

  - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From jeff.a.ryan at gmail.com  Mon Mar 22 15:45:17 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 22 Mar 2010 09:45:17 -0500
Subject: [R-SIG-Finance] efficient yearly return on a monthly basis
In-Reply-To: <4BA78197.4080607@braverock.com>
References: <4BA77F8F.80800@inrim.it> <4BA78197.4080607@braverock.com>
Message-ID: <e8e755251003220745l280f1aa4g59abd3c078484b87@mail.gmail.com>

Forgetting 'coding' efficiency, I don't see how this is slow:

> s=xts(1:15000,as.Date(0:14999))                                               > system.time(yret_by_month <- diff(s,lag=365)/lag(s,k=365)[endpoints(s,on="months")])
   user  system elapsed
  0.008   0.000   0.007
> str(yret_by_month)
An ?xts? object from 1970-01-31 to 2011-01-25 containing:
  Data: num [1:493, 1] NA NA NA NA NA NA NA NA NA NA ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr "e1"
  Indexed by objects of class: [Date] TZ: America/Chicago
  xts Attributes:
 NULL

That is 40 years of daily data, in 7 MILLISECONDS on a laptop.

Where is the problem?

Additionally lag/diff in xts are memcpy at the C level, so you won't
really be able to beat this in many languages (any!... maybe someone
can post a Kx comparison for kicks ;-) ) without some assembly in the
mix.

HTH
Jeff

On Mon, Mar 22, 2010 at 9:41 AM, Brian G. Peterson <brian at braverock.com> wrote:
> Fabrizio Pollastri wrote:
>>
>> The following code computes yearly returns every month on the xts seqence
>> s.
>>
>> s=xts(1:1000,as.Date(0:999))
>> yret_by_month = diff(s,lag=365)/lag(s,k=365)[endpoints(s,on="months")]
>>
>> There is a more efficient way to avoid diff and lag to perform
>> computations over the whole sequence? Thanks in advance for any help.
>
> It is of course unlikely that you have daily returns for 365 days of the
> year, but thanks for providing a reproducible example.
>
> The first issue I see with your code is that you are calculating for every
> day, but only care about "extracting" the monthly endpoints. ?So you're
> doing (in this example) ~30x more calculation than required (and ~22x more
> than required on likely real data).
>
> diff and Lag are pretty efficient, but I suspect that you can calculate log
> (or simple) returns on the daily or monthly series, then use runSum on a
> x-days or 12-month window to get your rolling annual return.
>
> ?- Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From sunder_1600 at yahoo.com  Mon Mar 22 16:30:34 2010
From: sunder_1600 at yahoo.com (Zany Z)
Date: Mon, 22 Mar 2010 08:30:34 -0700 (PDT)
Subject: [R-SIG-Finance] BHHH vs LBFGS
Message-ID: <959921.27420.qm@web113213.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100322/bc14946c/attachment.pl>

From ezivot at u.washington.edu  Mon Mar 22 18:01:13 2010
From: ezivot at u.washington.edu (Eric Zivot)
Date: Mon, 22 Mar 2010 10:01:13 -0700
Subject: [R-SIG-Finance] BHHH vs LBFGS
In-Reply-To: <959921.27420.qm@web113213.mail.gq1.yahoo.com>
References: <959921.27420.qm@web113213.mail.gq1.yahoo.com>
Message-ID: <003201cac9e1$472ff3f0$d58fdbd0$@washington.edu>

This is not an R finance question. A simple google search brought up the
following helpful paper

http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6V8V-3SX829Y-G&_us
er=582538&_coverDate=03%2F06%2F1998&_rdoc=1&_fmt=high&_orig=search&_sort=d&_
docanchor=&view=c&_searchStrId=1261826491&_rerunOrigin=google&_acct=C0000297
18&_version=1&_urlVersion=0&_userid=582538&md5=6de6878bc6c66e54110a2005b6370
63d



-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Zany Z
Sent: Monday, March 22, 2010 8:31 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] BHHH vs LBFGS

Hi,

What is the difference between BHHH and LBFGS? Which is the better algorithm
for Garch(q,p)? I noticed in garchFit, there are algorithms 'nlminb',
'lbfgsb', 'nlminb+nm' & 'lbfgsb+nm'. Which one enables the BHHH algo or is
there another function for BHHH? 


Thanks in advance.


      
	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From sunder_1600 at yahoo.com  Mon Mar 22 18:10:55 2010
From: sunder_1600 at yahoo.com (Zany Z)
Date: Mon, 22 Mar 2010 10:10:55 -0700 (PDT)
Subject: [R-SIG-Finance] BHHH vs LBFGS
In-Reply-To: <003201cac9e1$472ff3f0$d58fdbd0$@washington.edu>
References: <959921.27420.qm@web113213.mail.gq1.yahoo.com>
	<003201cac9e1$472ff3f0$d58fdbd0$@washington.edu>
Message-ID: <722352.43778.qm@web113203.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100322/38dac7d5/attachment.pl>

From mikeocon333 at gmail.com  Mon Mar 22 18:57:43 2010
From: mikeocon333 at gmail.com (Mike O'Connel)
Date: Mon, 22 Mar 2010 13:57:43 -0400
Subject: [R-SIG-Finance] Neural Networks and R
Message-ID: <8a0ad2fb1003221057s8ece2d4m8612a87a60a386f6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100322/32f0442a/attachment.pl>

From wuertz at itp.phys.ethz.ch  Tue Mar 23 01:03:11 2010
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Tue, 23 Mar 2010 01:03:11 +0100
Subject: [R-SIG-Finance] 4th R/Rmetrics Summer School and User/Developer
	Meeting
Message-ID: <4BA8053F.7080903@itp.phys.ethz.ch>


Second Announcement
www.rmetrics.org


                        *** Rmetrics 2010 ***  


4th R/Rmetrics Summer School and User/Developer Meeting on 
"Computational Finance and Financial Engineering", Meielisalp, Lake 
Thune Switzerland, June 27 - July 1, 2010

The Summer School and User/Developer Meeting focuse on topics from 
"Computational Finance and Financial Engineering" and on the use of 
R/Rmetrics in finance, insurance and related fields.

The Summer School morning sessions have four tutorials given by key note 
speakers covering topics from time series analysis, stochastic 
differential equations, and risk management. The tutorials are together 
with practical exercises.

Summer School Lecturers:

    * Alexander McNeil, Actuarial Mathematics and Statistics, 
Heriot-Watt University Edinburgh
    * Eckhard Platen, Quantitative Finance Research Centre, University 
of Technology Sydney
    * Nakahiro Yoshida, Graduate School of Mathematical Sciences, 
University of Tokyo
    * Eric Zivot, Economics Department, University of Washington, Seattle

The afternoon User/Developer Meetings are dedicated to contributed talks 
and presentations reflecting the wide range of fields in which R and 
Rmetrics are used in finance and insurance to analyze and model data. 
The goal is to bring together students, researchers, developers, 
practitioners, and users from finance and insurance providing a platform 
for common discussions and exchange of ideas.

The Summer School together with the User/Developer meeting is limited to 
50 participants, therefore early registration is highly recommended.



Call for Papers - Topics:

We invite to submit abstracts presenting innovations or exciting 
applications covering the whole spectrum of computational topics in 
finance, insurance and related fields. To submit an abstract email your 
pdf file to submissions [at] rmetrics.org. Please keep abstracts to one 
page. The abstracts will become available in an online abstract booklet. 
Submission will be considered on a rolling admission basis.

Scholarship for Students:
A limited number of scholarships are available for full-time Bachelor 
and Master students which include a reduction on the accommodation fees 
(total accommodation fees would be 90.00 CHF). Please send a letter of 
motivation and a recommendation letter from your supervisor to 
submissions [at] rmetrics.org. Note that only applications send from an 
email address affiliated to an university will be accepted. Deadline to 
apply for scholarship is June 1.

Organization:
    Rmetrics Association, co-organized by
    Swiss Federal Institute of Technology, Zurich.

Conference Chairs:
    Diethelm Wuertz, Swiss Federal Institute of Technology, Zurich CH
    Stefano Iacus, University of Milano, Milano, IT
    Mahendra Mehta, Neural Tech Technologies, Mumbai, IN
    David Scott, University of Auckland, Auckland, NZ

Conference Office:
    Yohan Chalabi, Swiss Federal Institute of Technology, Zurich CH
    Andrew Ellis, Swiss Federal Institute of Technology, Zurich CH

Supported by:
    Rmetrics Association Zurich
    ETH Zurich
    REvolution Computing
    ...

Visit:
    http://www.rmetrics.org/meielisalp2010
    http://www.rmetrics.org/meielisalp2010-registration


From etheber at gmx.de  Tue Mar 23 11:42:48 2010
From: etheber at gmx.de (Thomas Etheber)
Date: Tue, 23 Mar 2010 11:42:48 +0100
Subject: [R-SIG-Finance] style.fit by month
In-Reply-To: <4B9F9E7A.9070707@mnet-online.de>
References: <4B9EBD07.2020900@mnet-online.de>	<BLU0-SMTP148BB1216F8827226EBC6C8F2D0@phx.gbl>
	<4B9F9E7A.9070707@mnet-online.de>
Message-ID: <4BA89B28.30109@gmx.de>

Dear Rene,

why are you trying to circumvent the already implemented wrapper in 
style.QPfit?
If I got your problem right, you could just slice your data to rolling 
estimation windows and then forward it to style.QPfit. Did you already 
have a look at rollapply, I didn't test it but I think this should work 
for your purpose. In this case you will have to store the coefficients 
in each run, so that you are able to calculate the unsystematic returns, 
e.g. in a loop.

Hth
Thomas


Ren? Naarmann schrieb:
> Hi all,
>
> thank you Julien for your thougts. I working with R 2.10.0 on Windows XP.
> I remembered the function applySeries and fapply respectively. I tried 
> to calculate
> a variance covariance matrix over different periods. When this works I 
> could go on with solve.QP which needs the Dmat.
>
> Here is an example:
> require(timeSeries)
> btime <- timeSequence(from="1999-01-01", to="1999-03-31", by = "month")
> etime <- timeLastDayInMonth(btime[-1])
> btime <- btime[-length(btime)]
> data1 <- rnorm(1:90)
> data2 <- matrix(rnorm(270), ncol = 3)
> colnames(data2) <- LETTERS[1:3]
> datats <- timeSequence(from="1999-01-01", to="1999-03-31", by = "day")
> S <- timeSeries(data2, datats)
> applySeries(S, btime, etime, FUN = function(x) cov(x, 
> use="pairwise.complete.obs"))
> cov(window(S, start="1999-01-01", end="1999-02-28"))
>
> The result is a matrix which contains the varcov matrices for 2 
> subperiods which is fine,
> but when I am using my real Data I receive this Message:
> Fehler in midnightStandard2(charvec, format) :  'charvec' has non-NA 
> entries of different number of characters
> I don't understand this error message, can anyone help?
>
>
> I read my datafile from a spreadsheet via readSeries(), the head looks 
> like this:
>                    R2G          R2V           R1G           R1V    
> MSCIWexUS
> 1999-01-04 -0.006477506  0.004066846 -0.0026417776 -0.0009521722  
> 0.018939565
> 1999-01-05  0.001725935  0.002339151  0.0128278433  0.0116685255  
> 0.006108505
> 1999-01-06  0.018860732  0.007514636  0.0211913231  0.0215123444  
> 0.019311270
> 1999-01-07  0.005040827 -0.004752986 -0.0028397673  0.0013254882 
> -0.005757679
> 1999-01-08  0.011525972  0.003911511 -0.0006109632  0.0101291838  
> 0.001059926
> 1999-01-11  0.013880501 -0.005775207 -0.0039712968 -0.0108176871 
> -0.011788948
>
> Thanks in advance
> Ren?
>
>
> julien cuisinier schrieb:
>> Hi Ren?,
>>
>>
>>
>> For quad prog algo, look for solve.QP from quadprog package in R. It 
>> should allow you to do what you want (if I understood well). Please 
>> note I am not too familiar with the PerformanceAnalytics package & 
>> its capabilities (but suspect its style analysis function is a 
>> wrapper for solve.QP). Building a rolling window analysis is quite 
>> trivial from there.
>>
>> On another note, using 1 month data is probably too small to have 
>> stable results (depending on how many factors in your style analysis 
>> - personal rule of thumb is 10 times the number of factors gives you 
>> a benchmark of nbr of data points needed) , I would look to include 
>> more returns in your linear regression. One could look into applying 
>> some sort of weighting to your regression to improve forecasting 
>> power (e.g. exponential weighting). I guess you are also looking into 
>> the residuals for autocorrelation & heteroskedasticity which will 
>> impact the hypothesis testing of your betas/coefficients.
>>
>> & Finally, always best to make a question as concise as possible, 
>> include a piece of reproducible code of what you are trying to do & 
>> some system information (what R version, what OS) ... that often 
>> makes easier for list member to help & follow (more or less) the 
>> posting guide.
>>
>>
>>
>> HTH
>> Julien
>>
>>
>> On Mar 16, 2010, at 12:04 AM, Ren? Naarmann wrote:
>>
>>> Hi R-users,
>>>
>>> it is the first time for me writing to this group. I would be 
>>> grateful if somebody could help me to find
>>> a solution to my problem.
>>>
>>> I am working on my final thesis and I would like to analyse the 
>>> impact of return frequency
>>> using return-based style analysis. Specifically I would like to 
>>> calculate attributable returns. An attributalbe return
>>> is the difference between the realised return of a fund and the 
>>> forecast from using the estimated style coefficients
>>> multiplied by the respective indexseries.
>>>
>>> I am using the implemented functions for style analysis in the 
>>> PerformanceAnalytics Package.
>>> I would like to use the quadratic programming algorithm just for 
>>> each day in a specific month, i.e.
>>> use the daily returns from january to calculate the style weigths. 
>>> This should be done month by month.
>>> In the next step the calculation should include two months of data 
>>> and calculate the style weigths month by month.
>>>
>>> So far I tried to usw apply.month in combination with style.fit. 
>>> This returns the same results for each month.
>>> In the next step I tried to use some code out of chart.RollingStyle. 
>>> I change it for my purpose and
>>> receive the style weights in a rolling calculation and could enable 
>>> the by option. So I get styleweights
>>> over a specific width and could shift the calculation by a specified 
>>> block, i.e. calculate styleweigths
>>> for 20 days shifting this calculation by the next 20 days. What I 
>>> would like to have is a shifting by month
>>> to use the last month realised daily returns to forecast the style 
>>> weigths for the next month.
>>>
>>> Has somebody an idea how to handle this problem?
>>> Thank you in advance
>>>
>>> Ren? Naarmann
>>>
>>> -- 
>>> E-Mail: rene.naarmann at mnet-online.de
>>>
>>> _______________________________________________
>>> R-SIG-Finance at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R 
>>> questions should go.
>>>
>>
>>
>>
>


From etheber at gmx.de  Tue Mar 23 12:03:27 2010
From: etheber at gmx.de (Thomas Etheber)
Date: Tue, 23 Mar 2010 12:03:27 +0100
Subject: [R-SIG-Finance] PerformanceAnalytics - Style Analysis
Message-ID: <4BA89FFF.3060000@gmx.de>

Dear List,

I had a look at the code of the PerformanceAnalytics package and I use 
this package on a regular basis.

The style.fit function for Style Analysis provides thrree supported 
methods, which can be chosen via a parameter. I am talking of the 
normalized method here. This method requires the regression coefficients 
to sum to 1.
Indeed the code in Version 1.0.0 says something like this:

[... Default implementation ...]
column.weights = as.data.frame(coef(column.lm))
[...]
 if (method == "normalized") {
                column.weights = column.weights/sum(column.weights)
 }

I suppose here we are just scaling the coefficients to sum to 1, in my 
view the regression should a priori deal with this restriction (some 
sort of constrained regression or the like).
At least if you look at Tabel 2 of Sharpe (1992) the coefficients do not 
support the actual implementation and I think somebody might want to 
have a look at this code fragment.
Unfortunately I do not know how to implement this kind of restricted 
regression in R, but I believe there are already ways of doing this. 
Perhaps somebody from the list can guide us to the right direction.

Anyway great thx to the authors of this packkage!
Thomas

PS: In Stata the right command seems to be cnsreg.


From breman.mark at gmail.com  Tue Mar 23 13:15:52 2010
From: breman.mark at gmail.com (Mark Breman)
Date: Tue, 23 Mar 2010 13:15:52 +0100
Subject: [R-SIG-Finance] Price velocity and price acceleration
Message-ID: <5e6a2e671003230515h23178104v880e8280a3021ae@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100323/f884d357/attachment.pl>

From jorge.nieves at moorecap.com  Tue Mar 23 18:09:43 2010
From: jorge.nieves at moorecap.com (Jorge Nieves)
Date: Tue, 23 Mar 2010 13:09:43 -0400
Subject: [R-SIG-Finance] Looking for a fast convergence methodology
Message-ID: <D595C0E05185614C90515F1E8A2D4CBF060B449A@NYC-XCH3.win.moorecap.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100323/9b8a55d1/attachment.pl>

From jeff.a.ryan at gmail.com  Tue Mar 23 18:58:30 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 23 Mar 2010 12:58:30 -0500
Subject: [R-SIG-Finance] Looking for a fast convergence methodology
In-Reply-To: <D595C0E05185614C90515F1E8A2D4CBF060B449A@NYC-XCH3.win.moorecap.com>
References: <D595C0E05185614C90515F1E8A2D4CBF060B449A@NYC-XCH3.win.moorecap.com>
Message-ID: <e8e755251003231058g13fc793cl4b166ad580ac5d29@mail.gmail.com>

Yes,

Nothing at all to do with finance. The reason we emphasize "finance"
on the finance list is two-fold:

1) to remove noise that is not *unique* to finance and
2) to encourage general questions to go to a general audience that
will likely be better able to assist in possibly more creative ways.

To highlight the latter:

?optim

I am sure you will get a better reply to your general optimization
question than that on R-help.

HTH
Jeff

On Tue, Mar 23, 2010 at 12:09 PM, Jorge Nieves
<jorge.nieves at moorecap.com> wrote:
>
> Hi all,
>
> First I would like to apologize if my question seems to be out of the
> scope of this list. It is part of a Finacial model that I am working on.
>
> I have a model in a ?functional format:
>
> Result ?= mymodel(x,y)
>
> I would like to run the model for a range of values for both variables
> "x" and "y". The number of possible combination of x and y spans several
> thousand possible scenarios. My goal is to find the best possible
> outcome out of all the different possibilities. I am able to setup ?and
> run this exhaustively, ?but it takes too long to cover the
> possibilities. I even have a parallel process set up, but it still takes
> too long.
>
> I know my description might be ?a bit too general, but I was wondering
> if anyone might have suggestions as what approaches I could experiment.
> I am looking ?for some technique that might help to find fast
> convergence without the need to having to exhaust each of the
> possibilities.
>
> Thanks,
>
> Jorge Nieves
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From ezivot at u.washington.edu  Tue Mar 23 18:59:46 2010
From: ezivot at u.washington.edu (Eric Zivot)
Date: Tue, 23 Mar 2010 10:59:46 -0700
Subject: [R-SIG-Finance] PerformanceAnalytics - Style Analysis
In-Reply-To: <4BA89FFF.3060000@gmx.de>
References: <4BA89FFF.3060000@gmx.de>
Message-ID: <007b01cacab2$9fdde7b0$df99b710$@washington.edu>

You are right. The correct way to enforce that the regression coefficients
sum to unity is to impose this in the regression instead of just normalizing
the coefficients to sum to unity. It is not difficult to do this because it
is a linear restriction and the restriction can be substituted into the
linear regression to create another linear regression. I was supposed to add
this fix to the style.fit() function last year. I'll do it now and send the
fix off to Brian so he can put it in the PerformanceAnalytics package.
Briefly, consider the simple linear regression

Y = x1*b1 + x2*b2 + e

The restriction to impose is b1 + b2 = 1. Equivalently, b1 = 1 - b2.
Substituting into the regression gives

Y = x1*(1 - b2) + x2*b2 + e = x1 + b2*(x2 - x1) + e => Y - x1 = b2*(x2 - x1)
+ e

Therefore, the linear regression to run to impose the restriction b1+b2 = 1
is

(Y - x1) = b2*(x2 - x1) + e

Once you have b2.hat, then just solve for b1 using the constraint: b1.hat =
1 - b2.hat. (Note that it doesn't matter if you define the restriction in
terms of b1 = 1 - b2 or b2 = 1 - b1.)  Of course, to get the right R2 you
have to base it on Y as the dependent variable and not Y - x1. That is,
compute the R2 from the fitted values

Y.hat = b1.hat*x1 + b2.hat*x2 

Where b1.hat and b2.hat are the restricted least squares coefficients. 

Eric Zivot                  			               
Professor and Gary Waterman Distinguished Scholar       
Department of Economics                                 
Adjunct Professor of Finance                            
Adjunct Professor of Statistics
Box 353330                  email:  ezivot at u.washington.edu 
University of Washington    phone:  206-543-6715            
Seattle, WA 98195-3330
www:  http://faculty.washington.edu/ezivot                  




-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Thomas Etheber
Sent: Tuesday, March 23, 2010 4:03 AM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] PerformanceAnalytics - Style Analysis

Dear List,

I had a look at the code of the PerformanceAnalytics package and I use 
this package on a regular basis.

The style.fit function for Style Analysis provides thrree supported 
methods, which can be chosen via a parameter. I am talking of the 
normalized method here. This method requires the regression coefficients 
to sum to 1.
Indeed the code in Version 1.0.0 says something like this:

[... Default implementation ...]
column.weights = as.data.frame(coef(column.lm))
[...]
 if (method == "normalized") {
                column.weights = column.weights/sum(column.weights)
 }

I suppose here we are just scaling the coefficients to sum to 1, in my 
view the regression should a priori deal with this restriction (some 
sort of constrained regression or the like).
At least if you look at Tabel 2 of Sharpe (1992) the coefficients do not 
support the actual implementation and I think somebody might want to 
have a look at this code fragment.
Unfortunately I do not know how to implement this kind of restricted 
regression in R, but I believe there are already ways of doing this. 
Perhaps somebody from the list can guide us to the right direction.

Anyway great thx to the authors of this packkage!
Thomas

PS: In Stata the right command seems to be cnsreg.

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.


From armstrong.whit at gmail.com  Tue Mar 23 19:01:09 2010
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Tue, 23 Mar 2010 14:01:09 -0400
Subject: [R-SIG-Finance] Looking for a fast convergence methodology
In-Reply-To: <D595C0E05185614C90515F1E8A2D4CBF060B449A@NYC-XCH3.win.moorecap.com>
References: <D595C0E05185614C90515F1E8A2D4CBF060B449A@NYC-XCH3.win.moorecap.com>
Message-ID: <8ec76081003231101v42d991fcq420be4b03008544b@mail.gmail.com>

there is very small amount of literature on this subject.

have a look here:
http://www.coin-or.org/projects/

or here:
http://en.wikipedia.org/wiki/Optimization_(mathematics)

-Whit


On Tue, Mar 23, 2010 at 1:09 PM, Jorge Nieves <jorge.nieves at moorecap.com> wrote:
>
> Hi all,
>
> First I would like to apologize if my question seems to be out of the
> scope of this list. It is part of a Finacial model that I am working on.
>
> I have a model in a ?functional format:
>
> Result ?= mymodel(x,y)
>
> I would like to run the model for a range of values for both variables
> "x" and "y". The number of possible combination of x and y spans several
> thousand possible scenarios. My goal is to find the best possible
> outcome out of all the different possibilities. I am able to setup ?and
> run this exhaustively, ?but it takes too long to cover the
> possibilities. I even have a parallel process set up, but it still takes
> too long.
>
> I know my description might be ?a bit too general, but I was wondering
> if anyone might have suggestions as what approaches I could experiment.
> I am looking ?for some technique that might help to find fast
> convergence without the need to having to exhaust each of the
> possibilities.
>
> Thanks,
>
> Jorge Nieves
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From cmdr_rogue at hotmail.com  Tue Mar 23 23:40:20 2010
From: cmdr_rogue at hotmail.com (Sarbo)
Date: Tue, 23 Mar 2010 18:40:20 -0400
Subject: [R-SIG-Finance] Looking for a fast convergence methodology
In-Reply-To: <D595C0E05185614C90515F1E8A2D4CBF060B449A@NYC-XCH3.win.moorecap.com>
References: <D595C0E05185614C90515F1E8A2D4CBF060B449A@NYC-XCH3.win.moorecap.com>
Message-ID: <BLU0-SMTP973F100EACE63C87D706B0E2260@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100323/90b50cf5/attachment.pl>

From gero.schwenk at web.de  Tue Mar 23 23:59:12 2010
From: gero.schwenk at web.de (Gero Schwenk)
Date: Tue, 23 Mar 2010 23:59:12 +0100
Subject: [R-SIG-Finance] Neural Networks and R
Message-ID: <4BA947C0.4000706@web.de>

Hi Mike!
I don't have experience with neural networks, but with other machine 
learning techniques. Whatever your approach will be, there are some 
important things to know in order to use machine learning in a time 
series context.

1) You need to check the model's potential for generalization by 
calculating out-of-sample error measures. A test sample following the 
training sample in time is usually a harder test than cross-validation. 
That's general machine learning business.

2) You need to calculate your models on the returns (differences) of the 
series rather than on the series itself. The latter is usually 
integrated, has increasing error variance and is therefore not iid 
distributed. My experience is that failing to difference the data series 
will usually result in extremely good in-sample fit and inexistent 
out-of-sample generalization. The literature on ARIMA covers this topic 
and associated tests extensively.

3) Assume that the data-generating process (and therefore model error) 
is not stable over time. You can check this by doing rolling analyses of 
correlations between criterion and predictors, respectively rolling 
model application and error assessment. (Have a look at the 
"rollapply"-function for doing this.) A way to check for this more 
formally is to draw bootstrap samples of your focus quantities for two 
time intervals and test for differences - rolling may be overly time 
consuming here.

Hope this helps!
Regards, Gero


From worik.stanton at gmail.com  Thu Mar 25 02:06:40 2010
From: worik.stanton at gmail.com (Worik Stanton)
Date: Thu, 25 Mar 2010 14:06:40 +1300
Subject: [R-SIG-Finance] Selecting once a month from a xts series
Message-ID: <5fae31c41003241806o783e3cfanead46f564c1fdf9a@mail.gmail.com>

With a xts series of daily prices I want to select samples from once a month.

Given that p.xts is the xts series

> p.xts[1,]
           Adj.Close
2003-01-01       4.3

> p.xts[length(p.xts[,1]),]
           Adj.Close
2010-03-05      2.25



What I would like to do is...

> i <- seq(from=index(p.xts[1,]), to=index(p.xts[length(p.xts[,1]),]), by="month")
> m.xts <- p.xts[i,]
Error in `[.xts`(p.xts, i, ) : i is out of range

Of course some of the dates in 'i' are not in index(p  .xts)

Is there a simple solution?

cheers
Worik

-- 
Dig it out of the ground
Melt it down
Bury it
Guard it


From brian at braverock.com  Thu Mar 25 02:18:49 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 24 Mar 2010 20:18:49 -0500
Subject: [R-SIG-Finance] Selecting once a month from a xts series
In-Reply-To: <5fae31c41003241806o783e3cfanead46f564c1fdf9a@mail.gmail.com>
References: <5fae31c41003241806o783e3cfanead46f564c1fdf9a@mail.gmail.com>
Message-ID: <4BAAB9F9.5080400@braverock.com>

Worik Stanton wrote:
> With a xts series of daily prices I want to select samples from once a month.
> 
> Given that p.xts is the xts series
> 
>> p.xts[1,]
>            Adj.Close
> 2003-01-01       4.3
> 
>> p.xts[length(p.xts[,1]),]
>            Adj.Close
> 2010-03-05      2.25
> 
> 
> 
> What I would like to do is...
> 
>> i <- seq(from=index(p.xts[1,]), to=index(p.xts[length(p.xts[,1]),]), by="month")
>> m.xts <- p.xts[i,]
> Error in `[.xts`(p.xts, i, ) : i is out of range
> 
> Of course some of the dates in 'i' are not in index(p  .xts)
> 
> Is there a simple solution?

?endpoints


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From jeff.a.ryan at gmail.com  Thu Mar 25 02:24:39 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Wed, 24 Mar 2010 20:24:39 -0500
Subject: [R-SIG-Finance] Selecting once a month from a xts series
In-Reply-To: <4BAAB9F9.5080400@braverock.com>
References: <5fae31c41003241806o783e3cfanead46f564c1fdf9a@mail.gmail.com>
	<4BAAB9F9.5080400@braverock.com>
Message-ID: <e8e755251003241824t17c7a413kc767cc06acaa4dcb@mail.gmail.com>

If you want something like a random date, with a max of one per month,
you can try:

library(quantmod) #for getSymbols
getSymbols("AAPL")

do.call(rbind,
          lapply(sample(split(AAPL,"months"), 10),
                   function(x) x[sample(1:NROW(x),1)]
                   )
          )

           AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted
2007-07-11    132.07    133.70   131.31     132.39    29349000        132.39
2007-09-14    136.57    138.98   136.20     138.81    21690000        138.81
2007-11-19    166.10    168.20   162.10     163.95    41196800        163.95
2008-01-22    148.06    159.98   146.00     155.64    86955500        155.64
2008-04-10    151.13    155.42   150.60     154.55    34134400        154.55
2008-06-20    179.35    181.00   175.00     175.27    31727400        175.27
2008-07-16    170.20    172.93   168.60     172.81    26706800        172.81
2009-05-11    127.37    130.96   127.12     129.57    14452100        129.57
2009-10-09    188.97    190.70   188.62     190.47    10474000        190.47
2009-11-17    206.08    207.44   205.00     207.00    14161200        207.00
>

split.xts is the key, the rest is just regular R code; which means
there's more than one way to do it.

If you want to assure one per month, just make sure you set the "10"
to the nmonths of the data.

> do.call(rbind,lapply(sample(split(AAPL,"months"), nmonths(AAPL)), function(x) x[sample(1:NROW(x),1)]))
           AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted
2007-01-04     84.05     85.95    83.82      85.66    30259300         85.66
2007-02-02     84.12     85.25    83.70      84.75    22197500         84.75
2007-03-13     89.41     90.60    88.40      88.40    30996100         88.40
2007-04-04     94.94     95.14    94.13      94.27    17028000         94.27
2007-05-04    100.80    101.60   100.50     100.81    13642400        100.81
2007-06-28    122.36    122.49   120.00     120.56    29933700        120.56
2007-07-24    138.88    141.00   134.15     134.89    64117600        134.89
2007-08-10    123.12    127.75   120.30     125.00    50383900        125.00
2007-09-12    135.99    139.40   135.75     136.85    36527500        136.85
2007-10-16    165.54    170.18   165.15     169.58    38136800        169.58
2007-11-28    176.82    180.60   175.35     180.22    41104000        180.22
2007-12-13    190.19    192.12   187.82     191.83    30879200        191.83
2008-01-22    148.06    159.98   146.00     155.64    86955500        155.64
2008-02-19    125.99    126.75   121.44     122.18    35894500        122.18
2008-03-19    133.12    134.29   129.67     129.67    36090600        129.67
2008-04-15    149.40    149.72   145.72     148.38    24929900        148.38
2008-05-08    183.77    186.50   183.07     185.06    32110200        185.06
2008-06-26    174.07    174.84   168.01     168.26    31057500        168.26
2008-07-16    170.20    172.93   168.60     172.81    26706800        172.81
2008-08-04    156.60    157.90   152.91     153.23    21161700        153.23
2008-09-03    166.84    168.68   164.00     166.96    26244100        166.96
2008-10-06     91.96     98.78    87.54      98.14    75264900         98.14
2008-11-24     85.21     94.79    84.84      92.95    51509200         92.95
2008-12-10     97.87     99.49    96.50      98.21    33501700         98.21
2009-01-23     86.82     89.87    86.50      88.36    27277500         88.36
2009-02-25     89.86     92.92    89.25      91.16    29751900         91.16
2009-03-25    107.58    108.36   103.86     106.49    23093500        106.49
2009-04-06    114.94    118.75   113.28     118.45    23502300        118.45
2009-05-06    133.33    133.50   130.22     132.50    16912100        132.50
2009-06-05    145.31    146.40   143.21     144.67    22597000        144.67
2009-07-30    161.70    164.72   161.50     162.79    16771600        162.79
2009-08-10    165.66    166.60   163.66     164.72    10724800        164.72
2009-09-02    164.62    167.61   164.11     165.18    13008900        165.18
2009-10-22    204.70    207.85   202.51     205.20    28264000        205.20
2009-11-30    201.11    201.68   198.77     199.91    15173500        199.91
2009-12-23    201.20    202.38   200.81     202.10    12315900        202.10
2010-01-26    205.95    213.71   202.58     205.94    66605200        205.94
2010-02-11    194.88    199.75   194.06     198.67    19643400        198.67
2010-03-02    209.93    210.83   207.74     208.85    20220200        208.85



HTH
Jeff

On Wed, Mar 24, 2010 at 8:18 PM, Brian G. Peterson <brian at braverock.com> wrote:
> Worik Stanton wrote:
>>
>> With a xts series of daily prices I want to select samples from once a
>> month.
>>
>> Given that p.xts is the xts series
>>
>>> p.xts[1,]
>>
>> ? ? ? ? ? Adj.Close
>> 2003-01-01 ? ? ? 4.3
>>
>>> p.xts[length(p.xts[,1]),]
>>
>> ? ? ? ? ? Adj.Close
>> 2010-03-05 ? ? ?2.25
>>
>>
>>
>> What I would like to do is...
>>
>>> i <- seq(from=index(p.xts[1,]), to=index(p.xts[length(p.xts[,1]),]),
>>> by="month")
>>> m.xts <- p.xts[i,]
>>
>> Error in `[.xts`(p.xts, i, ) : i is out of range
>>
>> Of course some of the dates in 'i' are not in index(p ?.xts)
>>
>> Is there a simple solution?
>
> ?endpoints
>
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From worik.stanton at gmail.com  Thu Mar 25 02:26:37 2010
From: worik.stanton at gmail.com (Worik Stanton)
Date: Thu, 25 Mar 2010 14:26:37 +1300
Subject: [R-SIG-Finance] Selecting once a month from a xts series
In-Reply-To: <4BAAB9F9.5080400@braverock.com>
References: <5fae31c41003241806o783e3cfanead46f564c1fdf9a@mail.gmail.com>
	<4BAAB9F9.5080400@braverock.com>
Message-ID: <5fae31c41003241826t64afccfft943f51b259a7d6b4@mail.gmail.com>

>> Is there a simple solution?
>
> ?endpoints

Bingo!  Thank you

Worik

-- 
Dig it out of the ground
Melt it down
Bury it
Guard it


From wobwu22 at yahoo.de  Thu Mar 25 09:37:31 2010
From: wobwu22 at yahoo.de (Wob Wu)
Date: Thu, 25 Mar 2010 01:37:31 -0700 (PDT)
Subject: [R-SIG-Finance] Error in Blotter's Longtrend Demo
Message-ID: <188648.2427.qm@web23404.mail.ird.yahoo.com>

I am trying to reproduce the longtrend example in the current blotter package.

> require('blotter')
Loading required package: blotter
Loading required package: FinancialInstrument
> demo('longtrend')

The demo breaks after the for loop with the error: object 'ConMult' not found. 
Is this a known issue or am I doing something wrong?

I have compared my R settings with Brian's examples in http://ethos.braverock.com/brian/longtrend/sessioninfo.txt
My xts and zoo package seem to be newer than the ones in the example settings. Is this causing the problem? 

Maybe someone can point me to the right direction.

My current setup is the following:

> R.version
               _                            
platform       i386-pc-mingw32              
arch           i386                         
os             mingw32                      
system         i386, mingw32                
status                                      
major          2                            
minor          10.1                         
year           2009                         
month          12                           
day            14                           
svn rev        50720                        
language       R                            
version.string R version 2.10.1 (2009-12-14)
> sessionInfo()
R version 2.10.1 (2009-12-14) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                            LC_TIME=English_United Kingdom.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] PerformanceAnalytics_1.0.2 blotter_0.4                FinancialInstrument_0.0.2  quantmod_0.3-14            TTR_0.20-1                
[6] Defaults_1.1-1             xts_0.7-1                  zoo_1.6-3                 

loaded via a namespace (and not attached):
[1] grid_2.10.1    lattice_0.18-3 tools_2.10.1  



And here is the code snippet of the demo('longtrend') that is breaking:

> # Create trades
> for( i in 10:NROW(GSPC) ) { 
+     # browser()
+     CurrentDate=time(GSPC)[i]
+     cat(".")
+     equity = getEndEq(ltaccount, CurrentDate)
+ 
+     ClosePrice = as.numeric(Ad(GSPC[i,]))
+     Posn = getPosQty(ltportfolio, Symbol='GSPC', Date=CurrentDate)
+     UnitSize = as.numeric(trunc(equity/ClosePrice))
+ 
+     # Position Entry (assume fill at close)
+     if( Posn == 0 ) { 
+     # No position, so test to initiate Long position
+         if( as.numeric(Ad(GSPC[i,])) > as.numeric(GSPC[i,'SMA10m']) ) { 
+             cat('\n')
+             # Store trade with blotter
+             addTxn(ltportfolio, Symbol='GSPC', TxnDate=CurrentDate, TxnPrice=ClosePrice, TxnQty = UnitSize , TxnFees=0, verbose=verbose)
+         } 
+     } else {
+     # Have a position, so check exit
+         if( as.numeric(Ad(GSPC[i,]))  <  as.numeric(GSPC[i,'SMA10m'])) { 
+             cat('\n')
+             # Store trade with blotter
+             addTxn(ltportfolio, Symbol='GSPC', TxnDate=CurrentDate, TxnPrice=ClosePrice, TxnQty = -Posn , TxnFees=0, verbose=verbose)
+         } 
+     }
+ 
+     # Calculate P&L and resulting equity with blotter
+     updatePortf(ltportfolio, Dates = CurrentDate)
+     updateAcct(ltaccount, Dates = CurrentDate)
+     updateEndEq(ltaccount, Dates = CurrentDate)
+ } # End dates loop
.
[1] "1998-10-30 GSPC 91 @ 1098.67"
Error: object 'ConMult' not found
In addition: There were 15 warnings (use warnings() to see them)

Thanks for your help!

Regards,

 Wolfgang Wu


_______________________________
?gt ?ber einen herausragenden Schutz gegen Massenmails. 
http://mail.yahoo.com


From wobwu22 at yahoo.de  Thu Mar 25 11:42:49 2010
From: wobwu22 at yahoo.de (Wolfgang Wu)
Date: Thu, 25 Mar 2010 10:42:49 +0000 (GMT)
Subject: [R-SIG-Finance] Error in Blotter's Longtrend Demo
In-Reply-To: <188648.2427.qm@web23404.mail.ird.yahoo.com>
References: <188648.2427.qm@web23404.mail.ird.yahoo.com>
Message-ID: <173860.75855.qm@web23401.mail.ird.yahoo.com>

It seems like the error happens in the first iteration of the loop with i=10 on the following statement:

> updatePortf(ltportfolio, Dates = CurrentDate)
Error: object 'ConMult' not found

> CurrentDate
[1] "1998-10-30 GMT"
> Port <- getPortfolio(ltportfolio)
> Port
$GSPC
$GSPC$txn
           Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty Pos.Avg.Cost Realized.PL Con.Mult
1997-12-31       0      0.00        0      0.00         0.00       0         0.00           0        0
1998-10-30      91   1098.67        0  99978.97      1098.67      91      1098.67           0        1

$GSPC$posPL
           Pos.Qty Con.Mult Ccy.Mult Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL Trading.PL
1997-12-31       0        1        1         0         0        0           0             0          0


attr(,"class")
[1] "blotter_portfolio" "portfolio"        


Thanks.

Regards,

 Wolfgang Wu





----- Urspr?ngliche Mail ----
Von: Wob Wu <wobwu22 at yahoo.de>
An: r-sig-finance at stat.math.ethz.ch
Gesendet: Donnerstag, den 25. M?rz 2010, 8:37:31 Uhr
Betreff: [R-SIG-Finance] Error in Blotter's Longtrend Demo

I am trying to reproduce the longtrend example in the current blotter package.

> require('blotter')
Loading required package: blotter
Loading required package: FinancialInstrument
> demo('longtrend')

The demo breaks after the for loop with the error: object 'ConMult' not found. 
Is this a known issue or am I doing something wrong?

I have compared my R settings with Brian's examples in http://ethos.braverock.com/brian/longtrend/sessioninfo.txt
My xts and zoo package seem to be newer than the ones in the example settings. Is this causing the problem? 

Maybe someone can point me to the right direction.

My current setup is the following:

> R.version
               _                            
platform       i386-pc-mingw32              
arch           i386                        
os             mingw32                      
system         i386, mingw32                
status                                      
major          2                            
minor          10.1                        
year           2009                        
month          12                          
day            14                          
svn rev        50720                        
language       R                            
version.string R version 2.10.1 (2009-12-14)
> sessionInfo()
R version 2.10.1 (2009-12-14) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                            LC_TIME=English_United Kingdom.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base    

other attached packages:
[1] PerformanceAnalytics_1.0.2 blotter_0.4                FinancialInstrument_0.0.2  quantmod_0.3-14            TTR_0.20-1                
[6] Defaults_1.1-1             xts_0.7-1                  zoo_1.6-3                

loaded via a namespace (and not attached):
[1] grid_2.10.1    lattice_0.18-3 tools_2.10.1  



And here is the code snippet of the demo('longtrend') that is breaking:

> # Create trades
> for( i in 10:NROW(GSPC) ) { 
+     # browser()
+     CurrentDate=time(GSPC)[i]
+     cat(".")
+     equity = getEndEq(ltaccount, CurrentDate)
+ 
+     ClosePrice = as.numeric(Ad(GSPC[i,]))
+     Posn = getPosQty(ltportfolio, Symbol='GSPC', Date=CurrentDate)
+     UnitSize = as.numeric(trunc(equity/ClosePrice))
+ 
+     # Position Entry (assume fill at close)
+     if( Posn == 0 ) { 
+     # No position, so test to initiate Long position
+         if( as.numeric(Ad(GSPC[i,])) > as.numeric(GSPC[i,'SMA10m']) ) { 
+             cat('\n')
+             # Store trade with blotter
+             addTxn(ltportfolio, Symbol='GSPC', TxnDate=CurrentDate, TxnPrice=ClosePrice, TxnQty = UnitSize , TxnFees=0, verbose=verbose)
+         } 
+     } else {
+     # Have a position, so check exit
+         if( as.numeric(Ad(GSPC[i,]))  <  as.numeric(GSPC[i,'SMA10m'])) { 
+             cat('\n')
+             # Store trade with blotter
+             addTxn(ltportfolio, Symbol='GSPC', TxnDate=CurrentDate, TxnPrice=ClosePrice, TxnQty = -Posn , TxnFees=0, verbose=verbose)
+         } 
+     }
+ 
+     # Calculate P&L and resulting equity with blotter
+     updatePortf(ltportfolio, Dates = CurrentDate)
+     updateAcct(ltaccount, Dates = CurrentDate)
+     updateEndEq(ltaccount, Dates = CurrentDate)
+ } # End dates loop
.
[1] "1998-10-30 GSPC 91 @ 1098.67"
Error: object 'ConMult' not found
In addition: There were 15 warnings (use warnings() to see them)

Thanks for your help!

Regards,

Wolfgang Wu


_______________________________
?gt ?ber einen herausragenden Schutz gegen Massenmails. 
http://mail.yahoo.com

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


___________________________________
t ?ber einen herausragenden Schutz gegen Massenmails. 
http://mail.yahoo.com


From brian at braverock.com  Thu Mar 25 12:11:46 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 25 Mar 2010 06:11:46 -0500
Subject: [R-SIG-Finance] Error in Blotter's Longtrend Demo
In-Reply-To: <188648.2427.qm@web23404.mail.ird.yahoo.com>
References: <188648.2427.qm@web23404.mail.ird.yahoo.com>
Message-ID: <4BAB44F2.7080801@braverock.com>

I am unable to reproduce your error.  Current SVN works fine for me on 
two different machines, one of them only updated after your email.

If it is failing, I'm guessing it is happening earlier in the script.  
Are there any warnings?  The one I would expect is related to the 
instrument definition.

If there is no instrument defined, blotter attempts to proceed forward 
with a contract multiplier of 1.

It is possible that we have not made this assumption everywhere, 
expectially in updatePosn or updateAcct.  If there is a warning earlier 
in the demo, that would confirm that this is where I need to look.

Regards,

     - Brian

On 03/25/2010 03:37 AM, Wob Wu wrote:
> I am trying to reproduce the longtrend example in the current blotter package.
>
>    
>> require('blotter')
>>      
> Loading required package: blotter
> Loading required package: FinancialInstrument
>    
>> demo('longtrend')
>>      
> The demo breaks after the for loop with the error: object 'ConMult' not found.
> Is this a known issue or am I doing something wrong?
>
> I have compared my R settings with Brian's examples in http://ethos.braverock.com/brian/longtrend/sessioninfo.txt
> My xts and zoo package seem to be newer than the ones in the example settings. Is this causing the problem?
>
> Maybe someone can point me to the right direction.
>
> My current setup is the following:
>
>    
>> R.version
>>      
>                 _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          10.1
> year           2009
> month          12
> day            14
> svn rev        50720
> language       R
> version.string R version 2.10.1 (2009-12-14)
>    
>> sessionInfo()
>>      
> R version 2.10.1 (2009-12-14)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C                            LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] PerformanceAnalytics_1.0.2 blotter_0.4                FinancialInstrument_0.0.2  quantmod_0.3-14            TTR_0.20-1
> [6] Defaults_1.1-1             xts_0.7-1                  zoo_1.6-3
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.1    lattice_0.18-3 tools_2.10.1
>
>
>
> And here is the code snippet of the demo('longtrend') that is breaking:
>
>    
>> # Create trades
>> for( i in 10:NROW(GSPC) ) {
>>      
> +     # browser()
> +     CurrentDate=time(GSPC)[i]
> +     cat(".")
> +     equity = getEndEq(ltaccount, CurrentDate)
> +
> +     ClosePrice = as.numeric(Ad(GSPC[i,]))
> +     Posn = getPosQty(ltportfolio, Symbol='GSPC', Date=CurrentDate)
> +     UnitSize = as.numeric(trunc(equity/ClosePrice))
> +
> +     # Position Entry (assume fill at close)
> +     if( Posn == 0 ) {
> +     # No position, so test to initiate Long position
> +         if( as.numeric(Ad(GSPC[i,]))>  as.numeric(GSPC[i,'SMA10m']) ) {
> +             cat('\n')
> +             # Store trade with blotter
> +             addTxn(ltportfolio, Symbol='GSPC', TxnDate=CurrentDate, TxnPrice=ClosePrice, TxnQty = UnitSize , TxnFees=0, verbose=verbose)
> +         }
> +     } else {
> +     # Have a position, so check exit
> +         if( as.numeric(Ad(GSPC[i,]))<   as.numeric(GSPC[i,'SMA10m'])) {
> +             cat('\n')
> +             # Store trade with blotter
> +             addTxn(ltportfolio, Symbol='GSPC', TxnDate=CurrentDate, TxnPrice=ClosePrice, TxnQty = -Posn , TxnFees=0, verbose=verbose)
> +         }
> +     }
> +
> +     # Calculate P&L and resulting equity with blotter
> +     updatePortf(ltportfolio, Dates = CurrentDate)
> +     updateAcct(ltaccount, Dates = CurrentDate)
> +     updateEndEq(ltaccount, Dates = CurrentDate)
> + } # End dates loop
> .
> [1] "1998-10-30 GSPC 91 @ 1098.67"
> Error: object 'ConMult' not found
> In addition: There were 15 warnings (use warnings() to see them)
>
> Thanks for your help!
>
> Regards,
>
>   Wolfgang Wu
>
>
> _______________________________
> ?gt ?ber einen herausragenden Schutz gegen Massenmails.
> http://mail.yahoo.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>    


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From wobwu22 at yahoo.de  Thu Mar 25 12:25:58 2010
From: wobwu22 at yahoo.de (Wolfgang Wu)
Date: Thu, 25 Mar 2010 11:25:58 +0000 (GMT)
Subject: [R-SIG-Finance] Error in Blotter's Longtrend Demo
In-Reply-To: <4BAB44F2.7080801@braverock.com>
References: <188648.2427.qm@web23404.mail.ird.yahoo.com>
	<4BAB44F2.7080801@braverock.com>
Message-ID: <917864.1112.qm@web23402.mail.ird.yahoo.com>

Thanks Brian,

I do get the following warnings but my knowledge of R is unfortunately reaching its limit to evaluate if they are relevant or not.

[1] "1998-10-30 GSPC 91 @ 1098.67"
Error: object 'ConMult' not found
In addition: There were 15 warnings (use warnings() to see them)
> warnings()
Warning messages:
1: In rm("account.longtrend", "portfolio.longtrend", pos = .blotter) :
  object 'account.longtrend' not found
2: In rm("account.longtrend", "portfolio.longtrend", pos = .blotter) :
  object 'portfolio.longtrend' not found
3: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'ltaccount' not found
4: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'ltportfolio' not found
5: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'ClosePrice' not found
6: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'CurrentDate' not found
7: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'equity' not found
8: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'GSPC' not found
9: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'i' not found
10: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'initDate' not found
11: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'initEq' not found
12: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'Posn' not found
13: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'UnitSize' not found
14: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'verbose' not found
15: In download.file(paste(yahoo.URL, "s=", Symbols.name,  ... :
  downloaded length 187356 != reported length 200



It seems like the error happens in the first iteration of the loop with 
i=10. 
When I run the following statement I get the same error:

> updatePortf(ltportfolio, 
Dates = CurrentDate)
Error: object 'ConMult' not found
> i
[1] 10
> 
CurrentDate
[1] "1998-10-30 GMT"
> Port <- 
getPortfolio(ltportfolio)
> Port
$GSPC
$GSPC$txn
          Txn.Qty Txn.Price Txn.Fees Txn.Value Txn.Avg.Cost Pos.Qty Pos.Avg.Cost Realized.PL Con.Mult
1997-12-31       0      0.00        0      
0.00         0.00       0         0.00           0        0
1998-10-30      91   1098.67        0  99978.97      1098.67      91      1098.67           0        1

$GSPC$posPL
           Pos.Qty Con.Mult 
Ccy.Mult Pos.Value Txn.Value Txn.Fees Realized.PL Unrealized.PL 
Trading.PL
1997-12-31       0        1        1         0         0        0           0             0          0


attr(,"class")
[1] "blotter_portfolio" "portfolio"        


Thanks.

Regards,


 Wolfgang Wu





----- Urspr?ngliche Mail ----
Von: Brian G. Peterson <brian at braverock.com>
An: r-sig-finance at stat.math.ethz.ch
Gesendet: Donnerstag, den 25. M?rz 2010, 11:11:46 Uhr
Betreff: Re: [R-SIG-Finance] Error in Blotter's Longtrend Demo

I am unable to reproduce your error.  Current SVN works fine for me on 
two different machines, one of them only updated after your email.

If it is failing, I'm guessing it is happening earlier in the script.  
Are there any warnings?  The one I would expect is related to the 
instrument definition.

If there is no instrument defined, blotter attempts to proceed forward 
with a contract multiplier of 1.

It is possible that we have not made this assumption everywhere, 
expectially in updatePosn or updateAcct.  If there is a warning earlier 
in the demo, that would confirm that this is where I need to look.

Regards,

     - Brian

On 03/25/2010 03:37 AM, Wob Wu wrote:
> I am trying to reproduce the longtrend example in the current blotter package.
>
>    
>> require('blotter')
>>      
> Loading required package: blotter
> Loading required package: FinancialInstrument
>    
>> demo('longtrend')
>>      
> The demo breaks after the for loop with the error: object 'ConMult' not found.
> Is this a known issue or am I doing something wrong?
>
> I have compared my R settings with Brian's examples in http://ethos.braverock.com/brian/longtrend/sessioninfo.txt
> My xts and zoo package seem to be newer than the ones in the example settings. Is this causing the problem?
>
> Maybe someone can point me to the right direction.
>
> My current setup is the following:
>
>    
>> R.version
>>      
>                 _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          10.1
> year           2009
> month          12
> day            14
> svn rev        50720
> language       R
> version.string R version 2.10.1 (2009-12-14)
>    
>> sessionInfo()
>>      
> R version 2.10.1 (2009-12-14)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C                            LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] PerformanceAnalytics_1.0.2 blotter_0.4                FinancialInstrument_0.0.2  quantmod_0.3-14            TTR_0.20-1
> [6] Defaults_1.1-1             xts_0.7-1                  zoo_1.6-3
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.1    lattice_0.18-3 tools_2.10.1
>
>
>
> And here is the code snippet of the demo('longtrend') that is breaking:
>
>    
>> # Create trades
>> for( i in 10:NROW(GSPC) ) {
>>      
> +     # browser()
> +     CurrentDate=time(GSPC)[i]
> +     cat(".")
> +     equity = getEndEq(ltaccount, CurrentDate)
> +
> +     ClosePrice = as.numeric(Ad(GSPC[i,]))
> +     Posn = getPosQty(ltportfolio, Symbol='GSPC', Date=CurrentDate)
> +     UnitSize = as.numeric(trunc(equity/ClosePrice))
> +
> +     # Position Entry (assume fill at close)
> +     if( Posn == 0 ) {
> +     # No position, so test to initiate Long position
> +         if( as.numeric(Ad(GSPC[i,]))>  as.numeric(GSPC[i,'SMA10m']) ) {
> +             cat('\n')
> +             # Store trade with blotter
> +             addTxn(ltportfolio, Symbol='GSPC', TxnDate=CurrentDate, TxnPrice=ClosePrice, TxnQty = UnitSize , TxnFees=0, verbose=verbose)
> +         }
> +     } else {
> +     # Have a position, so check exit
> +         if( as.numeric(Ad(GSPC[i,]))<   as.numeric(GSPC[i,'SMA10m'])) {
> +             cat('\n')
> +             # Store trade with blotter
> +             addTxn(ltportfolio, Symbol='GSPC', TxnDate=CurrentDate, TxnPrice=ClosePrice, TxnQty = -Posn , TxnFees=0, verbose=verbose)
> +         }
> +     }
> +
> +     # Calculate P&L and resulting equity with blotter
> +     updatePortf(ltportfolio, Dates = CurrentDate)
> +     updateAcct(ltaccount, Dates = CurrentDate)
> +     updateEndEq(ltaccount, Dates = CurrentDate)
> + } # End dates loop
> .
> [1] "1998-10-30 GSPC 91 @ 1098.67"
> Error: object 'ConMult' not found
> In addition: There were 15 warnings (use warnings() to see them)
>
> Thanks for your help!
>
> Regards,
>
>   Wolfgang Wu
>
>
> _______________________________
> ?gt ?ber einen herausragenden Schutz gegen Massenmails.
> http://mail.yahoo.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>    


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


__________________________________________________
Do You Yahoo!?
Sie sind Spam leid? Yahoo! Mail verf?gt ?ber einen herausragenden Schutz gegen Massenmails. 
http://mail.yahoo.com


From brian at braverock.com  Thu Mar 25 13:09:05 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 25 Mar 2010 07:09:05 -0500
Subject: [R-SIG-Finance] Error in Blotter's Longtrend Demo
In-Reply-To: <917864.1112.qm@web23402.mail.ird.yahoo.com>
References: <188648.2427.qm@web23404.mail.ird.yahoo.com>
	<4BAB44F2.7080801@braverock.com>
	<917864.1112.qm@web23402.mail.ird.yahoo.com>
Message-ID: <4BAB5261.6050605@braverock.com>

On 03/25/2010 06:25 AM, Wolfgang Wu wrote:
> Thanks Brian,
>
> I do get the following warnings but my knowledge of R is unfortunately reaching its limit to evaluate if they are relevant or not.
>    
Try rerunning the demo in the same R session as your first, failed/error 
attempt.  The 'rm' errors are there to clean out the side effects from 
previous demo runs.  Rerunning will get rid of those, and may give us 
the warning I expect that would point towards where your problem is.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From wobwu22 at yahoo.de  Thu Mar 25 13:14:25 2010
From: wobwu22 at yahoo.de (Wolfgang Wu)
Date: Thu, 25 Mar 2010 12:14:25 +0000 (GMT)
Subject: [R-SIG-Finance] Error in Blotter's Longtrend Demo
In-Reply-To: <4BAB44F2.7080801@braverock.com>
References: <188648.2427.qm@web23404.mail.ird.yahoo.com>
	<4BAB44F2.7080801@braverock.com>
Message-ID: <761623.23956.qm@web23402.mail.ird.yahoo.com>

Ok. Here is another log of me trying to get through the demo. It seems like the first warnings are just there because the rm function can't find the objects. I then get another warning when trying to do a getsymbol. Does this help at all?

> require(TTR)
> require(blotter)
> try(rm("account.longtrend","portfolio.longtrend",pos=.blotter),silent=TRUE)
Warning messages:
1: In rm("account.longtrend", "portfolio.longtrend", pos = .blotter) :
  object 'account.longtrend' not found
2: In rm("account.longtrend", "portfolio.longtrend", pos = .blotter) :
  object 'portfolio.longtrend' not found
> try(rm("ltaccount","ltportfolio","ClosePrice","CurrentDate","equity","GSPC","i","initDate","initEq","Posn","UnitSize","verbose"),silent=TRUE)
There were 12 warnings (use warnings() to see them)
> warnings()
Warning messages:
1: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'ltaccount' not found
2: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'ltportfolio' not found
3: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'ClosePrice' not found
4: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'CurrentDate' not found
5: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'equity' not found
6: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'GSPC' not found
7: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'i' not found
8: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'initDate' not found
9: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'initEq' not found
10: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'Posn' not found
11: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'UnitSize' not found
12: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate",  ... :
  object 'verbose' not found
> # Set initial values
> initDate='1997-12-31'
> initEq=100000
> print("Loading data")
[1] "Loading data"
> currency("USD")
> stock("GSPC",currency="USD",multiplier=1)
> getSymbols('^GSPC', src='yahoo', index.class=c("POSIXt","POSIXct"),from='1998-01-01')
[1] "GSPC"
Warning message:
In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
  downloaded length 187356 != reported length 200
> GSPC=to.monthly(GSPC, indexAt='endof')
> print("Setting up indicators")
[1] "Setting up indicators"
> GSPC$SMA10m <- SMA(GSPC[,grep('Adj',colnames(GSPC))], 10)
> print("Initializing portfolio and account structure")
[1] "Initializing portfolio and account structure"
> ltportfolio='longtrend'
> ltaccount='longtrend'
> initPortf(ltportfolio,'GSPC', initDate=initDate)
[1] "longtrend"
> initAcct(ltaccount,portfolios='longtrend', initDate=initDate)
[1] "longtrend"
> verbose=TRUE
> i <- 10
> CurrentDate=time(GSPC)[i]
> cat(".")
.> equity = getEndEq(ltaccount, CurrentDate)
> ClosePrice = as.numeric(Ad(GSPC[i,]))
> Posn = getPosQty(ltportfolio, Symbol='GSPC', Date=CurrentDate)
> UnitSize = as.numeric(trunc(equity/ClosePrice))
> Posn
[1] 0
> as.numeric(Ad(GSPC[i,])) > as.numeric(GSPC[i,'SMA10m'])
[1] TRUE
> cat('\n')

> addTxn(ltportfolio, Symbol='GSPC', TxnDate=CurrentDate, TxnPrice=ClosePrice, TxnQty = UnitSize , TxnFees=0, verbose=verbose)
[1] "1998-10-30 GSPC 0 @ 1098.67"
> updatePortf(ltportfolio, Dates = CurrentDate)
Error: object 'ConMult' not found

 

Regards,


Wolfgang Wu



----- Urspr?ngliche Mail ----
Von: Brian G. Peterson <brian at braverock.com>
An: r-sig-finance at stat.math.ethz.ch
Gesendet: Donnerstag, den 25. M?rz 2010, 11:11:46 Uhr
Betreff: Re: [R-SIG-Finance] Error in Blotter's Longtrend Demo

I am unable to reproduce your error.  Current SVN works fine for me on 
two different machines, one of them only updated after your email.

If it is failing, I'm guessing it is happening earlier in the script.  
Are there any warnings?  The one I would expect is related to the 
instrument definition.

If there is no instrument defined, blotter attempts to proceed forward 
with a contract multiplier of 1.

It is possible that we have not made this assumption everywhere, 
expectially in updatePosn or updateAcct.  If there is a warning earlier 
in the demo, that would confirm that this is where I need to look.

Regards,

     - Brian

On 03/25/2010 03:37 AM, Wob Wu wrote:
> I am trying to reproduce the longtrend example in the current blotter package.
>
>    
>> require('blotter')
>>      
> Loading required package: blotter
> Loading required package: FinancialInstrument
>    
>> demo('longtrend')
>>      
> The demo breaks after the for loop with the error: object 'ConMult' not found.
> Is this a known issue or am I doing something wrong?
>
> I have compared my R settings with Brian's examples in http://ethos.braverock.com/brian/longtrend/sessioninfo.txt
> My xts and zoo package seem to be newer than the ones in the example settings. Is this causing the problem?
>
> Maybe someone can point me to the right direction.
>
> My current setup is the following:
>
>    
>> R.version
>>      
>                 _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          10.1
> year           2009
> month          12
> day            14
> svn rev        50720
> language       R
> version.string R version 2.10.1 (2009-12-14)
>    
>> sessionInfo()
>>      
> R version 2.10.1 (2009-12-14)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C                            LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] PerformanceAnalytics_1.0.2 blotter_0.4                FinancialInstrument_0.0.2  quantmod_0.3-14            TTR_0.20-1
> [6] Defaults_1.1-1             xts_0.7-1                  zoo_1.6-3
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.1    lattice_0.18-3 tools_2.10.1
>
>
>
> And here is the code snippet of the demo('longtrend') that is breaking:
>
>    
>> # Create trades
>> for( i in 10:NROW(GSPC) ) {
>>      
> +     # browser()
> +     CurrentDate=time(GSPC)[i]
> +     cat(".")
> +     equity = getEndEq(ltaccount, CurrentDate)
> +
> +     ClosePrice = as.numeric(Ad(GSPC[i,]))
> +     Posn = getPosQty(ltportfolio, Symbol='GSPC', Date=CurrentDate)
> +     UnitSize = as.numeric(trunc(equity/ClosePrice))
> +
> +     # Position Entry (assume fill at close)
> +     if( Posn == 0 ) {
> +     # No position, so test to initiate Long position
> +         if( as.numeric(Ad(GSPC[i,]))>  as.numeric(GSPC[i,'SMA10m']) ) {
> +             cat('\n')
> +             # Store trade with blotter
> +             addTxn(ltportfolio, Symbol='GSPC', TxnDate=CurrentDate, TxnPrice=ClosePrice, TxnQty = UnitSize , TxnFees=0, verbose=verbose)
> +         }
> +     } else {
> +     # Have a position, so check exit
> +         if( as.numeric(Ad(GSPC[i,]))<   as.numeric(GSPC[i,'SMA10m'])) {
> +             cat('\n')
> +             # Store trade with blotter
> +             addTxn(ltportfolio, Symbol='GSPC', TxnDate=CurrentDate, TxnPrice=ClosePrice, TxnQty = -Posn , TxnFees=0, verbose=verbose)
> +         }
> +     }
> +
> +     # Calculate P&L and resulting equity with blotter
> +     updatePortf(ltportfolio, Dates = CurrentDate)
> +     updateAcct(ltaccount, Dates = CurrentDate)
> +     updateEndEq(ltaccount, Dates = CurrentDate)
> + } # End dates loop
> .
> [1] "1998-10-30 GSPC 91 @ 1098.67"
> Error: object 'ConMult' not found
> In addition: There were 15 warnings (use warnings() to see them)
>
> Thanks for your help!
>
> Regards,
>
>   Wolfgang Wu
>
>
> _______________________________
> ?gt ?ber einen herausragenden Schutz gegen Massenmails.
> http://mail.yahoo.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>    


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


__________________________________________________
Do 
ragenden Schutz gegen Massenmails. 
http://mail.yahoo.com


From wobwu22 at yahoo.de  Thu Mar 25 13:29:00 2010
From: wobwu22 at yahoo.de (Wolfgang Wu)
Date: Thu, 25 Mar 2010 12:29:00 +0000 (GMT)
Subject: [R-SIG-Finance] Error in Blotter's Longtrend Demo
In-Reply-To: <4BAB5261.6050605@braverock.com>
References: <188648.2427.qm@web23404.mail.ird.yahoo.com>
	<4BAB44F2.7080801@braverock.com>
	<917864.1112.qm@web23402.mail.ird.yahoo.com>
	<4BAB5261.6050605@braverock.com>
Message-ID: <298467.23288.qm@web23401.mail.ird.yahoo.com>

Ok. I understand. So when I run it the second time the warnings regarding the rm functions are gone. I still get a warning for getSymbols.
> getSymbols('^GSPC', src='yahoo', index.class=c("POSIXt","POSIXct"),from='1998-01-01')
[1] "GSPC"
Warning message:
In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
  downloaded length 187356 != reported length 200

My GSPC time series looks like this:

          GSPC.Open GSPC.High GSPC.Low GSPC.Close  GSPC.Volume GSPC.Adjusted   SMA10m
1998-01-30    970.43    992.65   912.83     980.28  12733830000        980.28       NA
1998-02-27    980.28   1051.66   980.28    1049.34  11656550000       1049.34       NA
1998-03-31   1049.34   1113.07  1030.87    1101.75  13719590000       1101.75       NA
1998-04-30   1101.75   1132.98  1076.70    1111.75  13656060000       1111.75       NA
1998-05-29   1111.75   1130.52  1074.39    1090.82  11477140000       1090.82       NA
1998-06-30   1090.82   1145.15  1074.67    1133.84  13551970000       1133.84       NA
1998-07-31   1133.84   1190.58  1114.30    1120.67  14194800000       1120.67       NA
1998-08-31   1120.67   1121.79   957.28     957.28  15071550000        957.28       NA
1998-09-30    957.28   1066.11   939.98    1017.01  16714080000       1017.01       NA
1998-10-30   1017.01   1103.78   923.32    1098.67  18001650000       1098.67 1066.141
1998-11-30   1098.67   1192.97  1098.67    1163.63  13451280000       1163.63 1084.476

There are no other warnings. And I still get

> updatePortf(ltportfolio, Dates = CurrentDate)
Error: object 'ConMult' not found

Any other ideas? 


Regards,

Wolfgang Wu



----- Urspr?ngliche Mail ----
Von: Brian G. Peterson <brian at braverock.com>
An: Wolfgang Wu <wobwu22 at yahoo.de>
CC: r-sig-finance at stat.math.ethz.ch
Gesendet: Donnerstag, den 25. M?rz 2010, 12:09:05 Uhr
Betreff: Re: AW: [R-SIG-Finance] Error in Blotter's Longtrend Demo

On 03/25/2010 06:25 AM, Wolfgang Wu wrote:
> Thanks Brian,
> 
> I do get the following warnings but my knowledge of R is unfortunately reaching its limit to evaluate if they are relevant or not.
>    
Try rerunning the demo in the same R session as your first, failed/error attempt.  The 'rm' errors are there to clean out the side effects from previous demo runs.  Rerunning will get rid of those, and may give us the warning I expect that would point towards where your problem is.

Regards,

    - Brian

-- Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

__________________________________________________
Do You Yahoo!?
hutz gegen Massenmails. 
http://mail.yahoo.com


From wobwu22 at yahoo.de  Thu Mar 25 17:15:04 2010
From: wobwu22 at yahoo.de (Wolfgang Wu)
Date: Thu, 25 Mar 2010 16:15:04 +0000 (GMT)
Subject: [R-SIG-Finance] Error in Blotter's Longtrend Demo
In-Reply-To: <4BAB894C.7080606@braverock.com>
References: <188648.2427.qm@web23404.mail.ird.yahoo.com>
	<4BAB44F2.7080801@braverock.com>
	<917864.1112.qm@web23402.mail.ird.yahoo.com>
	<4BAB5261.6050605@braverock.com>
	<298467.23288.qm@web23401.mail.ird.yahoo.com>
	<4BAB894C.7080606@braverock.com>
Message-ID: <843411.61849.qm@web23405.mail.ird.yahoo.com>

Sorry for being unclear. The time series does go until the current date, so this is probably not the source of the error:

           GSPC.Open GSPC.High GSPC.Low GSPC.Close  GSPC.Volume GSPC.Adjusted   SMA10m
1998-01-30    970.43    992.65   912.83     980.28  12733830000        980.28       NA
1998-02-27    980.28   1051.66   980.28    1049.34  11656550000       1049.34       NA
1998-03-31   1049.34   1113.07  1030.87    1101.75  13719590000       1101.75       NA
1998-04-30   1101.75   1132.98  1076.70    1111.75  13656060000       1111.75       NA
1998-05-29   1111.75   1130.52  1074.39    1090.82  11477140000       1090.82       NA
1998-06-30   1090.82   1145.15  1074.67    1133.84  13551970000       1133.84       NA
1998-07-31   1133.84   1190.58  1114.30    1120.67  14194800000       1120.67       NA
1998-08-31   1120.67   1121.79   957.28     957.28  15071550000        957.28       NA
1998-09-30    957.28   1066.11   939.98    1017.01  16714080000       1017.01       NA
1998-10-30   1017.01   1103.78   923.32    1098.67  18001650000       1098.67 1066.141
1998-11-30   1098.67   1192.97  1098.67    1163.63  13451280000       1163.63 1084.476
...
2010-02-26   1073.89   1112.42  1044.50    1104.49  84561340000       1104.49 1032.892
2010-03-24   1105.36   1174.72  1105.36    1167.72  80361310000       1167.72 1057.750

I understand that this is a hard problem to find when you can't reproduce the error. I will try to debug the function itself once I have a bit more time.

Thanks for your help so far!!!

Regards,

 Wolfgang Wu



----- Urspr?ngliche Mail ----
Von: Brian G. Peterson <brian at braverock.com>
An: Wolfgang Wu <wobwu22 at yahoo.de>
Gesendet: Donnerstag, den 25. M?rz 2010, 16:03:24 Uhr
Betreff: Re: [R-SIG-Finance] Error in Blotter's Longtrend Demo

On 03/25/2010 07:29 AM, Wolfgang Wu wrote:
> Ok. I understand. So when I run it the second time the warnings regarding the rm functions are gone. I still get a warning for getSymbols.
>    
>> getSymbols('^GSPC', src='yahoo', index.class=c("POSIXt","POSIXct"),from='1998-01-01')
>>      
> [1] "GSPC"
> Warning message:
> In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
>    downloaded length 187356 != reported length 200
>
>    
That series should run up to the current day.  This may be the source of 
your problem.  See if you can change the source to google, or try again 
later.

> My GSPC time series looks like this:
>
>            GSPC.Open GSPC.High GSPC.Low GSPC.Close  GSPC.Volume GSPC.Adjusted   SMA10m
> 1998-01-30    970.43    992.65   912.83     980.28  12733830000        980.28       NA
> 1998-02-27    980.28   1051.66   980.28    1049.34  11656550000       1049.34       NA
> 1998-03-31   1049.34   1113.07  1030.87    1101.75  13719590000       1101.75       NA
> 1998-04-30   1101.75   1132.98  1076.70    1111.75  13656060000       1111.75       NA
> 1998-05-29   1111.75   1130.52  1074.39    1090.82  11477140000       1090.82       NA
> 1998-06-30   1090.82   1145.15  1074.67    1133.84  13551970000       1133.84       NA
> 1998-07-31   1133.84   1190.58  1114.30    1120.67  14194800000       1120.67       NA
> 1998-08-31   1120.67   1121.79   957.28     957.28  15071550000        957.28       NA
> 1998-09-30    957.28   1066.11   939.98    1017.01  16714080000       1017.01       NA
> 1998-10-30   1017.01   1103.78   923.32    1098.67  18001650000       1098.67 1066.141
> 1998-11-30   1098.67   1192.97  1098.67    1163.63  13451280000       1163.63 1084.476
>
> There are no other warnings. And I still get
>
>    
>> updatePortf(ltportfolio, Dates = CurrentDate)
>>      
> Error: object 'ConMult' not found
>
> Any other ideas?
>
>
> Regards,
>
> Wolfgang Wu
>
>
>
> ----- Urspr?ngliche Mail ----
> Von: Brian G. Peterson<brian at braverock.com>
> An: Wolfgang Wu<wobwu22 at yahoo.de>
> CC: r-sig-finance at stat.math.ethz.ch
> Gesendet: Donnerstag, den 25. M?rz 2010, 12:09:05 Uhr
> Betreff: Re: AW: [R-SIG-Finance] Error in Blotter's Longtrend Demo
>
> On 03/25/2010 06:25 AM, Wolfgang Wu wrote:
>    
>> Thanks Brian,
>>
>> I do get the following warnings but my knowledge of R is unfortunately reaching its limit to evaluate if they are relevant or not.
>>
>>      
> Try rerunning the demo in the same R session as your first, failed/error attempt.  The 'rm' errors are there to clean out the side effects from previous demo runs.  Rerunning will get rid of those, and may give us the warning I expect that would point towards where your problem is.
>
> Regards,
>
>      - Brian
>
> -- Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> __________________________________________________
> Do You Yahoo!?
> Sie sind Spam lei
ls.
> http://mail.yahoo.com
>    


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

__________________________________________________
Do You Yahoo!?
Sie sind Spa
enmails. 
http://mail.yahoo.com


From worik.stanton at gmail.com  Thu Mar 25 21:41:48 2010
From: worik.stanton at gmail.com (Worik)
Date: Fri, 26 Mar 2010 09:41:48 +1300
Subject: [R-SIG-Finance] Tests for TTR, and similar, packages
Message-ID: <201003260941.48494.worik.stanton@gmail.com>

Are there any test sets that can be used with the TTR packages to verify they 
work as they should?

I will be using them soon in some academic projects and the issue of 
reliability is weighing heavily on my mind.

cheers
Worik


From jeff.a.ryan at gmail.com  Thu Mar 25 21:53:46 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Thu, 25 Mar 2010 15:53:46 -0500
Subject: [R-SIG-Finance] Tests for TTR, and similar, packages
In-Reply-To: <201003260941.48494.worik.stanton@gmail.com>
References: <201003260941.48494.worik.stanton@gmail.com>
Message-ID: <e8e755251003251353r2295e1ddg88f2586e4c326928@mail.gmail.com>

Worik,

One of the chief advantages of open source is the ability to
scrutinize the code yourself.  This is miles ahead of anything a
closed solution could allow.  So you are ahead of the game already.
Of course you have to read the code...

Second advantage is that widely used packages (FREE makes many users)
get lots of eyeballs.  That isn't a guarantee of anything of course,
but it should add to your confidence.

The above said, OSS is OSS, without warranty expressed or implied OF ANY KIND.

Of course trust in anything is subject to doubt.  Compiler?  R?  OS?
Do you have ECC RAM? How's your data?

In a perfect world we of course would have perfect regression suites
that test all unknowns.
Clearly life isn't perfect.

What WOULD be valuable is the addition of YOUR tests.  So write some,
instead of asking, and contribute the second half of the puzzle to the
community.

Thanks in advance!!
Jeff

On Thu, Mar 25, 2010 at 3:41 PM, Worik <worik.stanton at gmail.com> wrote:
> Are there any test sets that can be used with the TTR packages to verify they
> work as they should?
>
> I will be using them soon in some academic projects and the issue of
> reliability is weighing heavily on my mind.
>
> cheers
> Worik
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From brian at braverock.com  Thu Mar 25 23:07:57 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 25 Mar 2010 17:07:57 -0500
Subject: [R-SIG-Finance] Tests for TTR, and similar, packages
In-Reply-To: <201003260941.48494.worik.stanton@gmail.com>
References: <201003260941.48494.worik.stanton@gmail.com>
Message-ID: <4BABDEBD.3070806@braverock.com>

On 03/25/2010 03:41 PM, Worik wrote:
> Are there any test sets that can be used with the TTR packages to verify they
> work as they should?
>
>    
There is documentation, which is quite extensive, and the references 
therein, and the code, and the examples.

Basically, the examples provide something of a regression suite, though 
I don't think they're set up with expected outputs in TTR as *formal* 
tests, as that was quite a pain in R package-land up until the 2.10.x 
series.  And TTR does indeed have several unit tests, which you can run, 
and examine, in the tests/ directory.

> I will be using them soon in some academic projects and the issue of
> reliability is weighing heavily on my mind.
>    

Well, the functions in TTR are used every day by hundreds, if not 
thousands of people and firms around the world.  That's not a guarantee, 
of course, but it is meaningful.  In such a widely used package, an 
awful lot of smart folks are thinking about the output of those 
functions.  Some of the lesser used stuff in the corners would 
undoubtedly benefit from more looking at (ALL code has bugs, even if 
only at the edges or with 'bad' inputs), but the main, popular, stuff is 
used a LOT.

Please share any tests you write, even (especially) simple ones or edge 
cases.  I'm sure Josh would be happy to include them for others to 
benefit from.

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From wobwu22 at yahoo.de  Fri Mar 26 11:44:04 2010
From: wobwu22 at yahoo.de (Wolfgang Wu)
Date: Fri, 26 Mar 2010 10:44:04 +0000 (GMT)
Subject: [R-SIG-Finance] Error in Blotter's Longtrend Demo
In-Reply-To: <843411.61849.qm@web23405.mail.ird.yahoo.com>
References: <188648.2427.qm@web23404.mail.ird.yahoo.com>
	<4BAB44F2.7080801@braverock.com>
	<917864.1112.qm@web23402.mail.ird.yahoo.com>
	<4BAB5261.6050605@braverock.com>
	<298467.23288.qm@web23401.mail.ird.yahoo.com>
	<4BAB894C.7080606@braverock.com>
	<843411.61849.qm@web23405.mail.ird.yahoo.com>
Message-ID: <80447.16554.qm@web23403.mail.ird.yahoo.com>

Just for your info. I have done another checkout from the repository using now Version: 0.4 |  Last change: 2010-03-17 23:53:21+01 |  Rev.: 295 and it seems to work fine. Thanks for all  your help.

 Regards,

Wolfgang Wu



----- Urspr?ngliche Mail ----
Von: Wolfgang Wu <wobwu22 at yahoo.de>
An: Brian G. Peterson <brian at braverock.com>
CC: r-sig-finance at stat.math.ethz.ch
Gesendet: Donnerstag, den 25. M?rz 2010, 16:15:04 Uhr
Betreff: Re: [R-SIG-Finance] Error in Blotter's Longtrend Demo

Sorry for being unclear. The time series does go until the current date, so this is probably not the source of the error:

           GSPC.Open GSPC.High GSPC.Low GSPC.Close  GSPC.Volume GSPC.Adjusted   SMA10m
1998-01-30    970.43    992.65   912.83     980.28  12733830000        980.28       NA
1998-02-27    980.28   1051.66   980.28    1049.34  11656550000       1049.34       NA
1998-03-31   1049.34   1113.07  1030.87    1101.75  13719590000       1101.75       NA
1998-04-30   1101.75   1132.98  1076.70    1111.75  13656060000       1111.75       NA
1998-05-29   1111.75   1130.52  1074.39    1090.82  11477140000       1090.82       NA
1998-06-30   1090.82   1145.15  1074.67    1133.84  13551970000       1133.84       NA
1998-07-31   1133.84   1190.58  1114.30    1120.67  14194800000       1120.67       NA
1998-08-31   1120.67   1121.79   957.28     957.28  15071550000        957.28       NA
1998-09-30    957.28   1066.11   939.98    1017.01  16714080000       1017.01       NA
1998-10-30   1017.01   1103.78   923.32    1098.67  18001650000       1098.67 1066.141
1998-11-30   1098.67   1192.97  1098.67    1163.63  13451280000       1163.63 1084.476
...
2010-02-26   1073.89   1112.42  1044.50    1104.49  84561340000       1104.49 1032.892
2010-03-24   1105.36   1174.72  1105.36    1167.72  80361310000       1167.72 1057.750

I understand that this is a hard problem to find when you can't reproduce the error. I will try to debug the function itself once I have a bit more time.

Thanks for your help so far!!!

Regards,

Wolfgang Wu



----- Urspr?ngliche Mail ----
Von: Brian G. Peterson <brian at braverock.com>
An: Wolfgang Wu <wobwu22 at yahoo.de>
Gesendet: Donnerstag, den 25. M?rz 2010, 16:03:24 Uhr
Betreff: Re: [R-SIG-Finance] Error in Blotter's Longtrend Demo

On 03/25/2010 07:29 AM, Wolfgang Wu wrote:
> Ok. I understand. So when I run it the second time the warnings regarding the rm functions are gone. I still get a warning for getSymbols.
>    
>> getSymbols('^GSPC', src='yahoo', index.class=c("POSIXt","POSIXct"),from='1998-01-01')
>>      
> [1] "GSPC"
> Warning message:
> In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
>    downloaded length 187356 != reported length 200
>
>    
That series should run up to the current day.  This may be the source of 
your problem.  See if you can change the source to google, or try again 
later.

> My GSPC time series looks like this:
>
>            GSPC.Open GSPC.High GSPC.Low GSPC.Close  GSPC.Volume GSPC.Adjusted   SMA10m
> 1998-01-30    970.43    992.65   912.83     980.28  12733830000        980.28       NA
> 1998-02-27    980.28   1051.66   980.28    1049.34  11656550000       1049.34       NA
> 1998-03-31   1049.34   1113.07  1030.87    1101.75  13719590000       1101.75       NA
> 1998-04-30   1101.75   1132.98  1076.70    1111.75  13656060000       1111.75       NA
> 1998-05-29   1111.75   1130.52  1074.39    1090.82  11477140000       1090.82       NA
> 1998-06-30   1090.82   1145.15  1074.67    1133.84  13551970000       1133.84       NA
> 1998-07-31   1133.84   1190.58  1114.30    1120.67  14194800000       1120.67       NA
> 1998-08-31   1120.67   1121.79   957.28     957.28  15071550000        957.28       NA
> 1998-09-30    957.28   1066.11   939.98    1017.01  16714080000       1017.01       NA
> 1998-10-30   1017.01   1103.78   923.32    1098.67  18001650000       1098.67 1066.141
> 1998-11-30   1098.67   1192.97  1098.67    1163.63  13451280000       1163.63 1084.476
>
> There are no other warnings. And I still get
>
>    
>> updatePortf(ltportfolio, Dates = CurrentDate)
>>      
> Error: object 'ConMult' not found
>
> Any other ideas?
>
>
> Regards,
>
> Wolfgang Wu
>
>
>
> ----- Urspr?ngliche Mail ----
> Von: Brian G. Peterson<brian at braverock.com>
> An: Wolfgang Wu<wobwu22 at yahoo.de>
> CC: r-sig-finance at stat.math.ethz.ch
> Gesendet: Donnerstag, den 25. M?rz 2010, 12:09:05 Uhr
> Betreff: Re: AW: [R-SIG-Finance] Error in Blotter's Longtrend Demo
>
> On 03/25/2010 06:25 AM, Wolfgang Wu wrote:
>    
>> Thanks Brian,
>>
>> I do get the following warnings but my knowledge of R is unfortunately reaching its limit to evaluate if they are relevant or not.
>>
>>      
> Try rerunning the demo in the same R session as your first, failed/error attempt.  The 'rm' errors are there to clean out the side effects from previous demo runs.  Rerunning will get rid of those, and may give us the warning I expect that would point towards where your problem is.
>
> Regards,
>
>      - Brian
>
> -- Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> __________________________________________________
> Do You Yahoo!?
> Sie sind Spam lei
ls.
> http://mail.yahoo.com
>    


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

__________________________________________________
Do You Yahoo!?
Sie sind Spa
enmails. 
http://mail.yahoo.com

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


__________________________________________________
Do You Yahoo!?
Sie sind Spam leid? Yahoo! Mail verf?gt ?ber einen herausragenden Schutz gegen Massenmails. 
http://mail.yahoo.com


From wobwu22 at yahoo.de  Fri Mar 26 14:03:19 2010
From: wobwu22 at yahoo.de (Wolfgang Wu)
Date: Fri, 26 Mar 2010 13:03:19 +0000 (GMT)
Subject: [R-SIG-Finance] Multi-currency example for blotter
Message-ID: <494000.9554.qm@web23406.mail.ird.yahoo.com>

Is there an example of how to use blotter for multiple currencies. Imagine a portfolio of two stocks. One is denominated in USD the other in EUR. I buy them both at time t. At time t+1 I want to evaluate the value of the portfolio in USD. 

Would I do something like this?

require(blotter)
initDate='1997-12-31'
initEq=100000

currency("USD")
currency("EUR")

stock("A",currency="USD",multiplier=1)
stock("B", currency="EUR", multiplier=1)

getSymbols('A', src='yahoo', index.class=c("POSIXt","POSIXct"),from='1998-01-01')
getSymbols('B', src='yahoo', 
index.class=c("POSIXt","POSIXct"),from='1998-01-01')

initPortf('MultCurPort',symbols=c('A','B'), initDate=initDate)
initAcct('MultCurAcc',portfolios='MultCurPort', initDate=initDate, initEq=initEq)

CurrentDate = '1997-01-30'
addTxn('MultCurPort', Symbol='A', TxnDate=CurrentDate, TxnPrice=100, TxnQty = 1, TxnFees=0)
addTxn('MultCurPort', Symbol='A', TxnDate=CurrentDate, 
TxnPrice=50, TxnQty = 1, TxnFees=0)
updatePortf('MultCurPort', Dates = CurrentDate)
updateAcct('MultCurAcc', Dates = CurrentDate)
updateEndEq('MultCurAcc', Dates = CurrentDate)

CurrentDate = '1998-01-30'
updatePortf('MultCurPort', Dates = CurrentDate)
updateAcct('MultCurAcc', Dates = CurrentDate)
updateEndEq('MultCurAcc', Dates = CurrentDate)


a) What I don't understand is how the USDEUR currency rate is used. Do I need the time series for the currency as well? Something like
getSymbols('EUR', src='yahoo', 
index.class=c("POSIXt","POSIXct"),from='1998-01-01')? 

b) How do I get the value of the portfolio? Via getEndEq(Account, Date)? In what currency will the account be evaluated? 

Thanks for the help.

Regards,

 Wolfgang Wu


_______________________________
?gt ?ber einen herausragenden Schutz gegen Massenmails. 
http://mail.yahoo.com


From wobwu22 at yahoo.de  Fri Mar 26 14:10:45 2010
From: wobwu22 at yahoo.de (Wolfgang Wu)
Date: Fri, 26 Mar 2010 13:10:45 +0000 (GMT)
Subject: [R-SIG-Finance] Multi-currency example for blotter
In-Reply-To: <494000.9554.qm@web23406.mail.ird.yahoo.com>
References: <494000.9554.qm@web23406.mail.ird.yahoo.com>
Message-ID: <862522.78777.qm@web23402.mail.ird.yahoo.com>

Sorry, that should have said:

CurrentDate = '1998-01-01'
addTxn('MultCurPort', Symbol='A', TxnDate=CurrentDate, TxnPrice=100, 
TxnQty = 1, TxnFees=0)
addTxn('MultCurPort', Symbol='B', 
TxnDate=CurrentDate, TxnPrice=50, TxnQty = 1, TxnFees=0)

Thanks

 Wolfgang Wu



----- Urspr?ngliche Mail ----
Von: Wolfgang Wu <wobwu22 at yahoo.de>
An: R SIG Finance <R-SIG-Finance at stat.math.ethz.ch>
Gesendet: Freitag, den 26. M?rz 2010, 13:03:19 Uhr
Betreff: [R-SIG-Finance] Multi-currency example for blotter

Is there an example of how to use blotter for multiple currencies. Imagine a portfolio of two stocks. One is denominated in USD the other in EUR. I buy them both at time t. At time t+1 I want to evaluate the value of the portfolio in USD. 

Would I do something like this?

require(blotter)
initDate='1997-12-31'
initEq=100000

currency("USD")
currency("EUR")

stock("A",currency="USD",multiplier=1)
stock("B", currency="EUR", multiplier=1)

getSymbols('A', src='yahoo', index.class=c("POSIXt","POSIXct"),from='1998-01-01')
getSymbols('B', src='yahoo', 
index.class=c("POSIXt","POSIXct"),from='1998-01-01')

initPortf('MultCurPort',symbols=c('A','B'), initDate=initDate)
initAcct('MultCurAcc',portfolios='MultCurPort', initDate=initDate, initEq=initEq)

CurrentDate = '1997-01-30'
addTxn('MultCurPort', Symbol='A', TxnDate=CurrentDate, TxnPrice=100, TxnQty = 1, TxnFees=0)
addTxn('MultCurPort', Symbol='A', TxnDate=CurrentDate, 
TxnPrice=50, TxnQty = 1, TxnFees=0)
updatePortf('MultCurPort', Dates = CurrentDate)
updateAcct('MultCurAcc', Dates = CurrentDate)
updateEndEq('MultCurAcc', Dates = CurrentDate)

CurrentDate = '1998-01-30'
updatePortf('MultCurPort', Dates = CurrentDate)
updateAcct('MultCurAcc', Dates = CurrentDate)
updateEndEq('MultCurAcc', Dates = CurrentDate)


a) What I don't understand is how the USDEUR currency rate is used. Do I need the time series for the currency as well? Something like
getSymbols('EUR', src='yahoo', 
index.class=c("POSIXt","POSIXct"),from='1998-01-01')? 

b) How do I get the value of the portfolio? Via getEndEq(Account, Date)? In what currency will the account be evaluated? 

Thanks for the help.

Regards,

Wolfgang Wu


_______________________________
?gt ?ber einen herausragenden Schutz gegen Massenmails. 
http://mail.yahoo.com

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


__________________________________________________
Do You Yahoo!?
Sie sind Spam 
mails. 
http://mail.yahoo.com


From brian at braverock.com  Fri Mar 26 14:12:26 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 26 Mar 2010 08:12:26 -0500
Subject: [R-SIG-Finance] Multi-currency example for blotter
In-Reply-To: <494000.9554.qm@web23406.mail.ird.yahoo.com>
References: <494000.9554.qm@web23406.mail.ird.yahoo.com>
Message-ID: <4BACB2BA.1050405@braverock.com>

We have done minimal testing on multi-currency portfolios.  Some issues 
remain.

I will work on this over the weekend, and will expand your code example.

To answer your specific questions,

a) exchange rates may be static or a time series.  A time series is 
obviously 'more correct', but many organizations change the exchange 
rate they use to mark their trading books only infrequently, and at 
arbitrary times.

b) Accounts, like portfolios, have a currency they are evaluated in.  
Transactions always and only happen in the currency of the instrument 
being traded, but portfolios and accounts have a currency that they are 
marked to.  We have discussed having multiple markings available, but 
have not implemented this yet.

Please let me know if you want to actively work on this functionality, 
we certainly welcome contributions and collaboration.

Regards,

     - Brian

On 03/26/2010 08:03 AM, Wolfgang Wu wrote:
> Is there an example of how to use blotter for multiple currencies. Imagine a portfolio of two stocks. One is denominated in USD the other in EUR. I buy them both at time t. At time t+1 I want to evaluate the value of the portfolio in USD.
>
> Would I do something like this?
>
> require(blotter)
> initDate='1997-12-31'
> initEq=100000
>
> currency("USD")
> currency("EUR")
>
> stock("A",currency="USD",multiplier=1)
> stock("B", currency="EUR", multiplier=1)
>
> getSymbols('A', src='yahoo', index.class=c("POSIXt","POSIXct"),from='1998-01-01')
> getSymbols('B', src='yahoo',
> index.class=c("POSIXt","POSIXct"),from='1998-01-01')
>
> initPortf('MultCurPort',symbols=c('A','B'), initDate=initDate)
> initAcct('MultCurAcc',portfolios='MultCurPort', initDate=initDate, initEq=initEq)
>
> CurrentDate = '1997-01-30'
> addTxn('MultCurPort', Symbol='A', TxnDate=CurrentDate, TxnPrice=100, TxnQty = 1, TxnFees=0)
> addTxn('MultCurPort', Symbol='A', TxnDate=CurrentDate,
> TxnPrice=50, TxnQty = 1, TxnFees=0)
> updatePortf('MultCurPort', Dates = CurrentDate)
> updateAcct('MultCurAcc', Dates = CurrentDate)
> updateEndEq('MultCurAcc', Dates = CurrentDate)
>
> CurrentDate = '1998-01-30'
> updatePortf('MultCurPort', Dates = CurrentDate)
> updateAcct('MultCurAcc', Dates = CurrentDate)
> updateEndEq('MultCurAcc', Dates = CurrentDate)
>
>
> a) What I don't understand is how the USDEUR currency rate is used. Do I need the time series for the currency as well? Something like
> getSymbols('EUR', src='yahoo',
> index.class=c("POSIXt","POSIXct"),from='1998-01-01')?
>
> b) How do I get the value of the portfolio? Via getEndEq(Account, Date)? In what currency will the account be evaluated?
>
> Thanks for the help.
>
> Regards,
>
>   Wolfgang Wu
>
>
> _______________________________
> ?gt ?ber einen herausragenden Schutz gegen Massenmails.
> http://mail.yahoo.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>    


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From wobwu22 at yahoo.de  Fri Mar 26 14:52:43 2010
From: wobwu22 at yahoo.de (Wolfgang Wu)
Date: Fri, 26 Mar 2010 06:52:43 -0700 (PDT)
Subject: [R-SIG-Finance] Multi-currency example for blotter
In-Reply-To: <4BACB2BA.1050405@braverock.com>
References: <494000.9554.qm@web23406.mail.ird.yahoo.com>
	<4BACB2BA.1050405@braverock.com>
Message-ID: <457073.5587.qm@web23408.mail.ird.yahoo.com>

I would want to actively work on the multi currency functionality. It will take some time to get my R programming skills up to standard but I would be willing to put in the effort. 
I also would also want to work on functionality to include futures/forward contracts as instruments. (If this is already implemented then please ignore the comment)

 

Regards, 

Wolfgang Wu



----- Urspr?ngliche Mail ----
Von: Brian G. Peterson <brian at braverock.com>
An: Wolfgang Wu <wobwu22 at yahoo.de>
CC: R SIG Finance <R-SIG-Finance at stat.math.ethz.ch>
Gesendet: Freitag, den 26. M?rz 2010, 13:12:26 Uhr
Betreff: Re: [R-SIG-Finance] Multi-currency example for blotter

We have done minimal testing on multi-currency portfolios.  Some issues 
remain.

I will work on this over the weekend, and will expand your code example.

To answer your specific questions,

a) exchange rates may be static or a time series.  A time series is 
obviously 'more correct', but many organizations change the exchange 
rate they use to mark their trading books only infrequently, and at 
arbitrary times.

b) Accounts, like portfolios, have a currency they are evaluated in.  
Transactions always and only happen in the currency of the instrument 
being traded, but portfolios and accounts have a currency that they are 
marked to.  We have discussed having multiple markings available, but 
have not implemented this yet.

Please let me know if you want to actively work on this functionality, 
we certainly welcome contributions and collaboration.

Regards,

     - Brian

On 03/26/2010 08:03 AM, Wolfgang Wu wrote:
> Is there an example of how to use blotter for multiple currencies. Imagine a portfolio of two stocks. One is denominated in USD the other in EUR. I buy them both at time t. At time t+1 I want to evaluate the value of the portfolio in USD.
>
> Would I do something like this?
>
> require(blotter)
> initDate='1997-12-31'
> initEq=100000
>
> currency("USD")
> currency("EUR")
>
> stock("A",currency="USD",multiplier=1)
> stock("B", currency="EUR", multiplier=1)
>
> getSymbols('A', src='yahoo', index.class=c("POSIXt","POSIXct"),from='1998-01-01')
> getSymbols('B', src='yahoo',
> index.class=c("POSIXt","POSIXct"),from='1998-01-01')
>
> initPortf('MultCurPort',symbols=c('A','B'), initDate=initDate)
> initAcct('MultCurAcc',portfolios='MultCurPort', initDate=initDate, initEq=initEq)
>
> CurrentDate = '1997-01-30'
> addTxn('MultCurPort', Symbol='A', TxnDate=CurrentDate, TxnPrice=100, TxnQty = 1, TxnFees=0)
> addTxn('MultCurPort', Symbol='A', TxnDate=CurrentDate,
> TxnPrice=50, TxnQty = 1, TxnFees=0)
> updatePortf('MultCurPort', Dates = CurrentDate)
> updateAcct('MultCurAcc', Dates = CurrentDate)
> updateEndEq('MultCurAcc', Dates = CurrentDate)
>
> CurrentDate = '1998-01-30'
> updatePortf('MultCurPort', Dates = CurrentDate)
> updateAcct('MultCurAcc', Dates = CurrentDate)
> updateEndEq('MultCurAcc', Dates = CurrentDate)
>
>
> a) What I don't understand is how the USDEUR currency rate is used. Do I need the time series for the currency as well? Something like
> getSymbols('EUR', src='yahoo',
> index.class=c("POSIXt","POSIXct"),from='1998-01-01')?
>
> b) How do I get the value of the portfolio? Via getEndEq(Account, Date)? In what currency will the account be evaluated?
>
> Thanks for the help.
>
> Regards,
>
>   Wolfgang Wu
>
>
> _______________________________
> ?gt ?ber einen herausragenden Schutz gegen Massenmails.
> http://mail.yahoo.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>    


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock

____________________________________
 ?ber einen herausragenden Schutz gegen Massenmails. 
http://mail.yahoo.com


From ngottlieb at marinercapital.com  Fri Mar 26 20:44:37 2010
From: ngottlieb at marinercapital.com (Gottlieb, Neil)
Date: Fri, 26 Mar 2010 15:44:37 -0400
Subject: [R-SIG-Finance] Anyone Know How to Calculate Ex Ante Standard
	Deviation
Message-ID: <5AB6B736E9303149B6928CB914961831633054F645@500MAILBOX.goldbox.com>

Does anyone know what the Barra Ex Ante Standard Deviation is and how to Calculate it?

Thanks,
Neil

This information is being sent at the recipient's reques...{{dropped:15}}


From brian at braverock.com  Fri Mar 26 20:53:08 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 26 Mar 2010 14:53:08 -0500
Subject: [R-SIG-Finance] Anyone Know How to Calculate Ex Ante Standard
 Deviation
In-Reply-To: <5AB6B736E9303149B6928CB914961831633054F645@500MAILBOX.goldbox.com>
References: <5AB6B736E9303149B6928CB914961831633054F645@500MAILBOX.goldbox.com>
Message-ID: <4BAD10A4.2070403@braverock.com>

Gottlieb, Neil wrote:
> Does anyone know what the Barra Ex Ante Standard Deviation is and how to Calculate it?
> 
> Thanks,
> Neil

Not an R finance question, but this publication (and several other BARRA 
publications):

http://www.barra.com/newsletter/nl169/estimationeuro169.asp

says:
"The standard BARRA technology is to scale these forecasts to make them 
specific risk forecasts by multiplying them by the empirical ratio of mean 
absolute specific return to standard deviation of specific return. We found 
that this ratio differs by capitalization class."

Of course, any Barra subscriber (and if you're not a Barra subscriber, why 
would you try to replicate their analysis?) may just call them up and talk to 
one of their analysts.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From arnaud.amsellem at gmail.com  Sat Mar 27 08:55:16 2010
From: arnaud.amsellem at gmail.com (yoda55)
Date: Fri, 26 Mar 2010 23:55:16 -0800 (PST)
Subject: [R-SIG-Finance] R and Metatrader
Message-ID: <1269676516179-1693168.post@n4.nabble.com>


Hi,

Has anyone ever tried to connect R to MetaTrader (MT4 or MT5)?
I mean by this: get a feed from MT into R, generates the signals in R, send
the orders back into MT and get some feedback MT.
I haven't tried it yet and I just want to see if someone  has any experience
with this before embarking myself into it.

Any help appreciated.
-- 
View this message in context: http://n4.nabble.com/R-and-Metatrader-tp1693168p1693168.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From dengyishuo at 163.com  Sat Mar 27 16:38:07 2010
From: dengyishuo at 163.com (=?UTF-8?B?6YKT5LiA56GV?=)
Date: Sat, 27 Mar 2010 07:38:07 -0800 (PST)
Subject: [R-SIG-Finance] A problem with RBloomberg
Message-ID: <1269704287488-1693477.post@n4.nabble.com>


Hi,all!
RBloomberg seems not work well with computer?
Here is the Problem:
>library(RBloomberg)
Loading required package: RDCOMClient
Loading required package: zoo
Loading required package: chron
Warning messages:
1: In file(file, "rt") :
  cannot open file 'C:/blp/API/bbfields.tbl': No such file or directory
2: In f(libname, pkgname) :
  I can't find your bbfields file.. see ?blpReadFields

Is there anyone who can help me?
Thanks!

-----
?????????????????
-- 
View this message in context: http://n4.nabble.com/A-problem-with-RBloomberg-tp1693477p1693477.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From dengyishuo at 163.com  Sat Mar 27 16:38:27 2010
From: dengyishuo at 163.com (=?UTF-8?B?6YKT5LiA56GV?=)
Date: Sat, 27 Mar 2010 07:38:27 -0800 (PST)
Subject: [R-SIG-Finance] A problem with RBloomberg
Message-ID: <1269704307732-1693479.post@n4.nabble.com>


Hi,all!
Here is the Problem:
>library(RBloomberg)
Loading required package: RDCOMClient
Loading required package: zoo
Loading required package: chron
Warning messages:
1: In file(file, "rt") :
  cannot open file 'C:/blp/API/bbfields.tbl': No such file or directory
2: In f(libname, pkgname) :
  I can't find your bbfields file.. see ?blpReadFields

Is there anyone who can help me?
Thanks!

-----
?????????????????
-- 
View this message in context: http://n4.nabble.com/A-problem-with-RBloomberg-tp1693479p1693479.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From cedrick at cedrickjohnson.com  Sun Mar 28 00:53:04 2010
From: cedrick at cedrickjohnson.com (Cedrick Johnson)
Date: Sat, 27 Mar 2010 19:53:04 -0400
Subject: [R-SIG-Finance] A problem with RBloomberg
In-Reply-To: <1269704287488-1693477.post@n4.nabble.com>
References: <1269704287488-1693477.post@n4.nabble.com>
Message-ID: <3ad7fd721003271653u595f59d5u53713bd266c14190@mail.gmail.com>

Try installing the Bloomberg API I believe.. The error is quite clear
that you are missing that particular file in the bbg installation.

Hth
C

On 3/27/10, ??? <dengyishuo at 163.com> wrote:
>
> Hi,all!
> RBloomberg seems not work well with computer?
> Here is the Problem:
>>library(RBloomberg)
> Loading required package: RDCOMClient
> Loading required package: zoo
> Loading required package: chron
> Warning messages:
> 1: In file(file, "rt") :
>   cannot open file 'C:/blp/API/bbfields.tbl': No such file or directory
> 2: In f(libname, pkgname) :
>   I can't find your bbfields file.. see ?blpReadFields
>
> Is there anyone who can help me?
> Thanks!
>
> -----
> ?????????????????
> --
> View this message in context:
> http://n4.nabble.com/A-problem-with-RBloomberg-tp1693477p1693477.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.

-- 
Sent from my mobile device


From worik.stanton at gmail.com  Sun Mar 28 07:15:29 2010
From: worik.stanton at gmail.com (Worik)
Date: Sun, 28 Mar 2010 18:15:29 +1300
Subject: [R-SIG-Finance] specifyModel/buildModel/tradeModel
Message-ID: <201003281815.29493.worik.stanton@gmail.com>

I am trying to work out what these functions do.

How is the model in specifyModel used?

What are the restrictions on the sorts of models that can be used?

Here are some of my experiments.  I do not know why only Next(OpCl(AIA.NZ)) ~ 
Lag(OpHi(AIA.NZ)) works for all stages.

> f1
Op(AIA.NZ) ~ EMA(Op(AIA.NZ))
> f2
Op(AIA.NZ) ~ Lag(AIA.NZ)
> f3
Op(AIA.NZ) ~ EMA(Op(AIA.NZ))
> f4
Next(OpCl(AIA.NZ)) ~ Lag(OpHi(AIA.NZ))
> m1 <- specifyModel(f1)
> m2 <- specifyModel(f2)
Error in dimnames(x) <- dn : 
  length of 'dimnames' [1] not equal to array extent
> m3 <- specifyModel(f3)
> m4 <- specifyModel(f4)
> b1 <- buildModel(m1, method='rpart', 
training.per=c('2007-01-01','2007-04-01'))
> b3 <- buildModel(m3, method='rpart', 
training.per=c('2007-01-01','2007-04-01'))
> b4 <- buildModel(m4, method='rpart', 
training.per=c('2007-01-01','2007-04-01'))
> tradeModel(b1)
Error in `[.zoo`(neg.days, , 1) : subscript out of bounds
In addition: Warning message:
In modelReturn(quantmodResults, trade.dates = trade.dates, leverage = 
leverage,  :
  Model results are all one direction.
> tradeModel(b3)
Error in `[.zoo`(neg.days, , 1) : subscript out of bounds
In addition: Warning message:
In modelReturn(quantmodResults, trade.dates = trade.dates, leverage = 
leverage,  :
  Model results are all one direction.
> tradeModel(b4)

  Model:  rpart1269752986.98017 

  C.A.G.R.:  -9.62% 	H.P.R.:  -35.37% 

  Returns by period summary:

             weekly monthly quarterly  yearly
    Max.      7.99%  12.57%    25.20%  58.18%
    3rd Qu.   1.80%   3.76%    11.03%   9.80%
    Mean     -0.23%  -0.94%    -2.39%  -2.64%
    Median   -0.20%  -0.59%    -3.56%  -8.70%
    2rd Qu.  -2.12%  -4.93%   -13.31% -21.14%
    Min.    -12.76% -26.11%   -33.25% -51.34%

  Period to date returns:

             weekly monthly quarterly yearly
             -0.52%   0.89%    -6.33% -6.33%
> 

I have version 0.3-8 of quantmod
R version 2.9.2

cheers
Worik


From brian at braverock.com  Sun Mar 28 11:27:42 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 28 Mar 2010 04:27:42 -0500
Subject: [R-SIG-Finance] specifyModel/buildModel/tradeModel
In-Reply-To: <201003281815.29493.worik.stanton@gmail.com>
References: <201003281815.29493.worik.stanton@gmail.com>
Message-ID: <4BAF210E.8010807@braverock.com>

Worik wrote:
> I am trying to work out what these functions do.
> 
> How is the model in specifyModel used?
> 
> What are the restrictions on the sorts of models that can be used?
<snip>
First, thank you for  providing your code example.
I don't have time right now  to dissect it, but perhaps someone else will.

Basically, quantmod model specification will work with R functions like lm() or 
glm() that take a specification of class "formula".  If you have a problem of 
this type, specifyModel, buildModel, etc. will likely work quite well.

See
?formula
in R for the documentation on 'formula' objects and how they are specified.

Look at the quantmod website for some quantmod-specific examples.

Look at the list archives for this list for more that has been written over the 
years.

If that still doesn't answer your question, add to your prior code example, 
with comments, etc, and I expect someone will do what they can to help.

Regards,

    - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From konrad.banachewicz at gmail.com  Sun Mar 28 12:26:36 2010
From: konrad.banachewicz at gmail.com (Konrad Banachewicz)
Date: Sun, 28 Mar 2010 12:26:36 +0200
Subject: [R-SIG-Finance] A problem with RBloomberg
Message-ID: <204e4c51003280326t55bb1318jfd219d211eb07750@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100328/192ce29c/attachment.pl>

From kriskumar at earthlink.net  Sun Mar 28 13:44:47 2010
From: kriskumar at earthlink.net (Krishna)
Date: Sun, 28 Mar 2010 07:44:47 -0400
Subject: [R-SIG-Finance] A problem with RBloomberg
In-Reply-To: <204e4c51003280326t55bb1318jfd219d211eb07750@mail.gmail.com>
References: <204e4c51003280326t55bb1318jfd219d211eb07750@mail.gmail.com>
Message-ID: <B9FD32BC-0C69-4CA5-9903-4204DF11C903@earthlink.net>

If you look at the docs for RBloomberg there is a functiion to specify  
where bbg is installed on your machine.

On Mar 28, 2010, at 6:26 AM, Konrad Banachewicz <konrad.banachewicz at gmail.com 
 > wrote:

> simple restart might do. Bloomberg consoles with R installed on them  
> - under
> Windows - tend to exhibit somewhat erratic behavior. I've had a  
> similar
> problem, with R "complaining" about lack of file / dir, and after  
> restarting
> it worked fine.
>
>
> rg,
> K
>
> *Hi,all!**
> **Here is the Problem:**
> **>library(RBloomberg)**
> **Loading required package: RDCOMClient**
> **Loading required package: zoo**
> **Loading required package: chron**
> **Warning messages:**
> **1: In file(file, "rt") :**
> ** cannot open file 'C:/blp/API/bbfields.tbl': No such file or  
> directory**
> **2: In f(libname, pkgname) :**
> ** I can't find your bbfields file.. see ?blpReadFields**
> **
> **Is there anyone who can help me?**
> **Thanks!**
> **
> **-----**
> **?????????????????**
> **--**
> **View this message in context:
> http://n4.nabble.com/A-problem-with-RBloomberg- 
> tp1693479p1693479.html**
> **Sent from the Rmetrics mailing list archive at Nabble.com.**
> *
> *
> *
>
> ---
> A gentleman is one who never hurts anyone's feelings unintentionally.
>
> Oscar Wilde
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R  
> questions should go.


From dlvanbrunt at gmail.com  Sun Mar 28 17:12:01 2010
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Sun, 28 Mar 2010 11:12:01 -0400
Subject: [R-SIG-Finance] Coding for a trailing stop (% or fixed $)
Message-ID: <d332d3e11003280812q4edd001at8e604090b2c5aecb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100328/e21722ab/attachment.pl>

From brian at braverock.com  Sun Mar 28 17:44:48 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 28 Mar 2010 10:44:48 -0500
Subject: [R-SIG-Finance] Coding for a trailing stop (% or fixed $)
In-Reply-To: <d332d3e11003280812q4edd001at8e604090b2c5aecb@mail.gmail.com>
References: <d332d3e11003280812q4edd001at8e604090b2c5aecb@mail.gmail.com>
Message-ID: <4BAF7970.3060407@braverock.com>

On 03/28/2010 10:12 AM, David L. Van Brunt, Ph.D. wrote:
> For the life of me, I don't know why this is eluding me...
>
> I'm trying to add a variable into a time series (have quote data added via
> quantmod).  I've added technical indicators, but now want a column that will
> reflect the trailing stop value for that day, given a starting date and
> trade value, and a given trailing stop.
>
> Is there a more sensible way than using a FOR loop to march through the
> rows, lagging to compare prior highs/lows to current stop value?  I don't
> want the canned Parabolic SAR, but a custom user-specifiable trailing stop
> (for example, 5% below the high since position entry for long, 5% above low
> since short entry)
>    

If I understand you correctly, what you want is path dependent, based on 
your current position and entry price.

You *may* be able to do it with an ifelse statement, suitably crafted, 
but otherwise, loop away.

A wise mentor of mine once said:
"First make it work, then make it work right, then make it fast; in that 
order, do not deviate."

Still true almost two decades later.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From hesen.peng at gmail.com  Sun Mar 28 20:22:06 2010
From: hesen.peng at gmail.com (Hesen Peng)
Date: Sun, 28 Mar 2010 14:22:06 -0400
Subject: [R-SIG-Finance] Coding for a trailing stop (% or fixed $)
In-Reply-To: <d332d3e11003280812q4edd001at8e604090b2c5aecb@mail.gmail.com>
References: <d332d3e11003280812q4edd001at8e604090b2c5aecb@mail.gmail.com>
Message-ID: <4ae8ae6e1003281122h5eb40921x8a07a82dd053a0d2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100328/7ccf15b4/attachment.pl>

From daniel.cegielka at gmail.com  Sun Mar 28 20:59:17 2010
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Sun, 28 Mar 2010 19:59:17 +0100
Subject: [R-SIG-Finance] Coding for a trailing stop (% or fixed $)
In-Reply-To: <d332d3e11003280812q4edd001at8e604090b2c5aecb@mail.gmail.com>
References: <d332d3e11003280812q4edd001at8e604090b2c5aecb@mail.gmail.com>
Message-ID: <5ddf2c611003281159v67eadc87i7da0d7136b5a0c93@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100328/78155402/attachment.pl>

From pgrahl at gmail.com  Mon Mar 29 23:00:09 2010
From: pgrahl at gmail.com (Paulo Grahl)
Date: Mon, 29 Mar 2010 18:00:09 -0300
Subject: [R-SIG-Finance] Wild bootstrap
Message-ID: <755f575b1003291400m2bb6cfa3gb5646380c0623ff@mail.gmail.com>

Dear list members,

I am wondering whether it is possible to use 'boot' package (or any
other) in order to use the wild bootstrap method.
Any help, examples, would be appreciated.
Thanks,
Paulo


From brian at braverock.com  Mon Mar 29 23:08:33 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 29 Mar 2010 16:08:33 -0500
Subject: [R-SIG-Finance] Wild bootstrap
In-Reply-To: <755f575b1003291400m2bb6cfa3gb5646380c0623ff@mail.gmail.com>
References: <755f575b1003291400m2bb6cfa3gb5646380c0623ff@mail.gmail.com>
Message-ID: <4BB116D1.70302@braverock.com>

On 03/29/2010 04:00 PM, Paulo Grahl wrote:
> I am wondering whether it is possible to use 'boot' package (or any
> other) in order to use the wild bootstrap method.
> Any help, examples, would be appreciated.
>    

There are many implementations of the wild bootstap in R.

Perhaps you should do a little searching, try a few things, and refine 
your question with a code example.

Regards,

     - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From BChiquoine at tiff.org  Mon Mar 29 23:06:48 2010
From: BChiquoine at tiff.org (Chiquoine, Ben)
Date: Mon, 29 Mar 2010 17:06:48 -0400
Subject: [R-SIG-Finance] Wild bootstrap
In-Reply-To: <755f575b1003291400m2bb6cfa3gb5646380c0623ff@mail.gmail.com>
References: <755f575b1003291400m2bb6cfa3gb5646380c0623ff@mail.gmail.com>
Message-ID: <E71E6D5B2274B341B26B6DF3D34D802802EBF4BC@vsw3exch2.tiff.local>

I was doing some bootstrapping with R a while back and found the
following document helpful. Maybe you will as well. 
http://www.statoo.com/en/publications/bootstrap_scgn_v131.pdf

Ben

-----Original Message-----
From: r-sig-finance-bounces at stat.math.ethz.ch
[mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf Of Paulo
Grahl
Sent: Monday, March 29, 2010 5:00 PM
To: r-sig-finance at stat.math.ethz.ch
Subject: [R-SIG-Finance] Wild bootstrap

Dear list members,

I am wondering whether it is possible to use 'boot' package (or any
other) in order to use the wild bootstrap method.
Any help, examples, would be appreciated.
Thanks,
Paulo

_______________________________________________
R-SIG-Finance at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions
should go.
___________________________________________
This message and any attached documents contain
information which may be confidential, subject to 
privilege or exempt from disclosure under applicable
law. These materials are solely for the use of the 
intended recipient. If you are not the intended 
recipient of this transmission, you are hereby 
notified that any distribution, disclosure, printing, 
copying, storage, modification or the taking of any
action in reliance upon this transmission is strictly
prohibited. Delivery of this message to any person
other than the intended recipient shall not
compromise or waive such confidentiality, privilege
or exemption from disclosure as to this 
communication. 

If you have received this communication in error, 
please notify the sender immediately and delete
this message from your system. 



From patrick at burns-stat.com  Tue Mar 30 10:14:58 2010
From: patrick at burns-stat.com (Patrick Burns)
Date: Tue, 30 Mar 2010 09:14:58 +0100
Subject: [R-SIG-Finance] Wild bootstrap
In-Reply-To: <4BB116D1.70302@braverock.com>
References: <755f575b1003291400m2bb6cfa3gb5646380c0623ff@mail.gmail.com>
	<4BB116D1.70302@braverock.com>
Message-ID: <4BB1B302.5010001@burns-stat.com>

It is good if the original poster explains what
a term means that they are searching for.  That
has at least two benefits:

* it avoids misunderstandings if the same or a
similar term has a different meaning.

* it educates subscribers (like me) who don't
know the term.

If not the original poster, then it's nice if a
response contains it.  So here goes:

The wild bootstrap is bootstrapping residuals and
then randomly multiplying by 1 or -1.  Hence ensuring
the distribution is symmetric around zero.

I've done it -- I just didn't know it had a name.

The bootstrapping tutorial on www.burns-stat.com
would tell you how to do it yourself (minus the last
step of multiplying by -1 or 1).


On 29/03/2010 22:08, Brian G. Peterson wrote:
> On 03/29/2010 04:00 PM, Paulo Grahl wrote:
>> I am wondering whether it is possible to use 'boot' package (or any
>> other) in order to use the wild bootstrap method.
>> Any help, examples, would be appreciated.
>
> There are many implementations of the wild bootstap in R.
>
> Perhaps you should do a little searching, try a few things, and refine
> your question with a code example.
>
> Regards,
>
> - Brian
>

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com


From jh8080 at hotmail.com  Tue Mar 30 10:32:40 2010
From: jh8080 at hotmail.com (Jae Kim)
Date: Tue, 30 Mar 2010 19:32:40 +1100
Subject: [R-SIG-Finance] Wild bootstrap
In-Reply-To: <4BB1B302.5010001@burns-stat.com>
References: <755f575b1003291400m2bb6cfa3gb5646380c0623ff@mail.gmail.com><4BB116D1.70302@braverock.com>
	<4BB1B302.5010001@burns-stat.com>
Message-ID: <SNT124-DS2719F23AAA3CC6FFE1B99CD1F0@phx.gbl>

The wild bootstrap is bootstrapping for heteroskedastic data.

The package vrtest has wild bootstrap implementations of the variance ratio 
tests and you will find some references in the manual.

A well-known reference is

Davidson, Russell & Flachaire, Emmanuel, 2008. "The wild bootstrap, tamed at 
last," Journal of Econometrics, Elsevier, vol. 146(1), pages 162-169, 
September

It is not intended for symmetry, but for replicating heteroskdastic 
structure.

It also has wide applications to financial data.

Hope this helps. Jae Kim




--------------------------------------------------
From: "Patrick Burns" <patrick at burns-stat.com>
Sent: Tuesday, March 30, 2010 7:14 PM
To: <r-sig-finance at stat.math.ethz.ch>
Subject: Re: [R-SIG-Finance] Wild bootstrap

> It is good if the original poster explains what
> a term means that they are searching for.  That
> has at least two benefits:
>
> * it avoids misunderstandings if the same or a
> similar term has a different meaning.
>
> * it educates subscribers (like me) who don't
> know the term.
>
> If not the original poster, then it's nice if a
> response contains it.  So here goes:
>
> The wild bootstrap is bootstrapping residuals and
> then randomly multiplying by 1 or -1.  Hence ensuring
> the distribution is symmetric around zero.
>
> I've done it -- I just didn't know it had a name.
>
> The bootstrapping tutorial on www.burns-stat.com
> would tell you how to do it yourself (minus the last
> step of multiplying by -1 or 1).
>
>
> On 29/03/2010 22:08, Brian G. Peterson wrote:
>> On 03/29/2010 04:00 PM, Paulo Grahl wrote:
>>> I am wondering whether it is possible to use 'boot' package (or any
>>> other) in order to use the wild bootstrap method.
>>> Any help, examples, would be appreciated.
>>
>> There are many implementations of the wild bootstap in R.
>>
>> Perhaps you should do a little searching, try a few things, and refine
>> your question with a code example.
>>
>> Regards,
>>
>> - Brian
>>
>
> -- 
> Patrick Burns
> patrick at burns-stat.com
> http://www.burns-stat.com
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions 
> should go.
>


From matthieu.stigler at gmail.com  Tue Mar 30 10:39:41 2010
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Tue, 30 Mar 2010 10:39:41 +0200
Subject: [R-SIG-Finance] Wild bootstrap
In-Reply-To: <4BB1B302.5010001@burns-stat.com>
References: <755f575b1003291400m2bb6cfa3gb5646380c0623ff@mail.gmail.com>	<4BB116D1.70302@braverock.com>
	<4BB1B302.5010001@burns-stat.com>
Message-ID: <4BB1B8CD.80208@gmail.com>


Actually the wild bootstrap just samples the residuals, following 
different schemes:
- 1 and -1 ("rademacher" bootstrap)
-normal distribution
-other schemes... see 
http://www.econ.queensu.ca/working_papers/papers/qed_wp_1028.pdf

I have implemented such a bootstrap for VAR models (allowing to include 
HC estimators from pkg sandwich), see:
library(vars)
?causality

Note that as only the residuals are bootstraped, and not the regressors, 
a lot of computation can be saved as you don't need to compute every 
time the (X'X)-1 matrix. Because you want to do it many times, it can be 
useful not to reuse lm() at each step

I explored:
update(lm)
and finally used something like:
Ynew<-pred+res*rnorm(n=obs, mean=0, sd=x)
PI.boot<-solve(cross, crossprod(Zmlm,Ynew))

But this sure could be more efficient...

Matthieu



Patrick Burns a ?crit :
> It is good if the original poster explains what
> a term means that they are searching for.  That
> has at least two benefits:
>
> * it avoids misunderstandings if the same or a
> similar term has a different meaning.
>
> * it educates subscribers (like me) who don't
> know the term.
>
> If not the original poster, then it's nice if a
> response contains it.  So here goes:
>
> The wild bootstrap is bootstrapping residuals and
> then randomly multiplying by 1 or -1.  Hence ensuring
> the distribution is symmetric around zero.
>
> I've done it -- I just didn't know it had a name.
>
> The bootstrapping tutorial on www.burns-stat.com
> would tell you how to do it yourself (minus the last
> step of multiplying by -1 or 1).
>
>
> On 29/03/2010 22:08, Brian G. Peterson wrote:
>> On 03/29/2010 04:00 PM, Paulo Grahl wrote:
>>> I am wondering whether it is possible to use 'boot' package (or any
>>> other) in order to use the wild bootstrap method.
>>> Any help, examples, would be appreciated.
>>
>> There are many implementations of the wild bootstap in R.
>>
>> Perhaps you should do a little searching, try a few things, and refine
>> your question with a code example.
>>
>> Regards,
>>
>> - Brian
>>
>


From christopher.masters at gmail.com  Tue Mar 30 13:07:14 2010
From: christopher.masters at gmail.com (Chris Masters)
Date: Tue, 30 Mar 2010 12:07:14 +0100
Subject: [R-SIG-Finance] Plotting intraday time series with ggplot2
Message-ID: <c1f3afcb1003300407t7a4a7e4dx85cdf3107bf3b280@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100330/1128e8ff/attachment.pl>

From ggrothendieck at gmail.com  Tue Mar 30 13:13:25 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 30 Mar 2010 07:13:25 -0400
Subject: [R-SIG-Finance] Plotting intraday time series with ggplot2
In-Reply-To: <c1f3afcb1003300407t7a4a7e4dx85cdf3107bf3b280@mail.gmail.com>
References: <c1f3afcb1003300407t7a4a7e4dx85cdf3107bf3b280@mail.gmail.com>
Message-ID: <971536df1003300413x19b2f25bh4f290847a8b81e11@mail.gmail.com>

Its not ggplot2 but gap.plot in the plotrix package will put gaps on
an axis in classic graphics.

On Tue, Mar 30, 2010 at 7:07 AM, Chris Masters
<christopher.masters at gmail.com> wrote:
> Hi
>
> I have a time series over n days of data observed at fixed intervals (m
> seconds) between 8:30am and 4:30pm and would like to plot this with ggplot2
> without the overnight gaps between 4:30pm and 8:30am. I have googled around
> quite a bit trying to see if I can have a disjoint x-axis but can't seem to
> come up with much. I also tried using scale_x_continuous for each day in the
> hope you could apply it multiple times to achieve this. I'd also like to
> label the x-axis with the dates of the days.
>
> Does anyone have any ideas? It seems like it should be a relatively simple
> to do but I'm afraid my ggplot2 knowledge is a bit thin
>
> Thanks
>
> Chris
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From jeff.a.ryan at gmail.com  Tue Mar 30 16:00:50 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 30 Mar 2010 09:00:50 -0500
Subject: [R-SIG-Finance] Plotting intraday time series with ggplot2
In-Reply-To: <c1f3afcb1003300407t7a4a7e4dx85cdf3107bf3b280@mail.gmail.com>
References: <c1f3afcb1003300407t7a4a7e4dx85cdf3107bf3b280@mail.gmail.com>
Message-ID: <e8e755251003300700l6f3999d3u6af483d5c756ef7@mail.gmail.com>

Not really a finance question, so that would explain the lack of
helpful replies.

Ask again on R-help.

For time-series plots, take a look at both plot.zoo and to a lesser
extent (less function, but different design) plot.xts.  You can coerce
most time-series with as.zoo or as.xts.

These two will utilize the underlying time index 'gaps'.

For something closer to financial charting software in R, take a look
at quantmod's chartSeries and unexported (so far) chart_Series.

http://www.quantmod.com/examples/

The site is getting a little dated, but the functionality is the same.
 These plots will not leave spaces (i.e. the ignore the time for all
but the axis labeling, and internal data alignment)

HTH
Jeff
On Tue, Mar 30, 2010 at 6:07 AM, Chris Masters
<christopher.masters at gmail.com> wrote:
> Hi
>
> I have a time series over n days of data observed at fixed intervals (m
> seconds) between 8:30am and 4:30pm and would like to plot this with ggplot2
> without the overnight gaps between 4:30pm and 8:30am. I have googled around
> quite a bit trying to see if I can have a disjoint x-axis but can't seem to
> come up with much. I also tried using scale_x_continuous for each day in the
> hope you could apply it multiple times to achieve this. I'd also like to
> label the x-axis with the dates of the days.
>
> Does anyone have any ideas? It seems like it should be a relatively simple
> to do but I'm afraid my ggplot2 knowledge is a bit thin
>
> Thanks
>
> Chris
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From kagba2006 at yahoo.com  Tue Mar 30 21:31:29 2010
From: kagba2006 at yahoo.com (FMH)
Date: Tue, 30 Mar 2010 12:31:29 -0700 (PDT)
Subject: [R-SIG-Finance] Inflection point on a curve
Message-ID: <193106.19220.qm@web38303.mail.mud.yahoo.com>

Dear All,

I have been trying to find an inflection point from?a nonparametric model, for instance on? a series of Economics, Financial, Environmental data, which was fitted via sm.regression package, but have difficulty to find the derivative of the model. The following are the data and the codes to fit such a nonparametric model.

#######################################################
library(sm)
x?<- c(6.3,? 6.6,? 7.0,? 8.0,? 8.8,? 9.8, 12.0, 14.2, 15.5, 15.7, 15.8) 
y?<- rev(seq(1,51,by=5))
sm.regression(x,y,method = "cv", col = "red")
#######################################################


Could someone please advice me?an appropriate?way to determine such an inflection point from?the nonparametric model?

Thank you
Fir?






From pgrahl at gmail.com  Wed Mar 31 04:09:18 2010
From: pgrahl at gmail.com (Paulo Grahl)
Date: Tue, 30 Mar 2010 23:09:18 -0300
Subject: [R-SIG-Finance] Wild bootstrap
In-Reply-To: <4BB1B8CD.80208@gmail.com>
References: <755f575b1003291400m2bb6cfa3gb5646380c0623ff@mail.gmail.com>
	<4BB116D1.70302@braverock.com> <4BB1B302.5010001@burns-stat.com>
	<4BB1B8CD.80208@gmail.com>
Message-ID: <s2t755f575b1003301909z37e9e1aeycb03793bfb46a595@mail.gmail.com>

Thank you all for the help.  And sorry for not being precise on the
question, but you got it right:
my question was regarding the wild bootstrap for bootstrapping
heteroskedastic data, using Rademacher random variables. Even though
it is simple to implement it, I was wondering whether or not that
could be done
in a straightforward way using the 'boot' package.
Thanks
Paulo

On Tue, Mar 30, 2010 at 5:39 AM, Matthieu Stigler
<matthieu.stigler at gmail.com> wrote:
>
> Actually the wild bootstrap just samples the residuals, following different
> schemes:
> - 1 and -1 ("rademacher" bootstrap)
> -normal distribution
> -other schemes... see
> http://www.econ.queensu.ca/working_papers/papers/qed_wp_1028.pdf
>
> I have implemented such a bootstrap for VAR models (allowing to include HC
> estimators from pkg sandwich), see:
> library(vars)
> ?causality
>
> Note that as only the residuals are bootstraped, and not the regressors, a
> lot of computation can be saved as you don't need to compute every time the
> (X'X)-1 matrix. Because you want to do it many times, it can be useful not
> to reuse lm() at each step
>
> I explored:
> update(lm)
> and finally used something like:
> Ynew<-pred+res*rnorm(n=obs, mean=0, sd=x)
> PI.boot<-solve(cross, crossprod(Zmlm,Ynew))
>
> But this sure could be more efficient...
>
> Matthieu
>
>
>
> Patrick Burns a ?crit :
>>
>> It is good if the original poster explains what
>> a term means that they are searching for. ?That
>> has at least two benefits:
>>
>> * it avoids misunderstandings if the same or a
>> similar term has a different meaning.
>>
>> * it educates subscribers (like me) who don't
>> know the term.
>>
>> If not the original poster, then it's nice if a
>> response contains it. ?So here goes:
>>
>> The wild bootstrap is bootstrapping residuals and
>> then randomly multiplying by 1 or -1. ?Hence ensuring
>> the distribution is symmetric around zero.
>>
>> I've done it -- I just didn't know it had a name.
>>
>> The bootstrapping tutorial on www.burns-stat.com
>> would tell you how to do it yourself (minus the last
>> step of multiplying by -1 or 1).
>>
>>
>> On 29/03/2010 22:08, Brian G. Peterson wrote:
>>>
>>> On 03/29/2010 04:00 PM, Paulo Grahl wrote:
>>>>
>>>> I am wondering whether it is possible to use 'boot' package (or any
>>>> other) in order to use the wild bootstrap method.
>>>> Any help, examples, would be appreciated.
>>>
>>> There are many implementations of the wild bootstap in R.
>>>
>>> Perhaps you should do a little searching, try a few things, and refine
>>> your question with a code example.
>>>
>>> Regards,
>>>
>>> - Brian
>>>
>>
>
>



-- 
Paulo Gustavo Grahl, CFA
------------------------------------------
pgrahl at gmail.com
pgrahl at fgvmail.br
www.linkedin.com/in/pgrahl


From ron_michael70 at yahoo.com  Wed Mar 31 05:34:52 2010
From: ron_michael70 at yahoo.com (Ron_M)
Date: Tue, 30 Mar 2010 19:34:52 -0800 (PST)
Subject: [R-SIG-Finance] Simulating VAR model (re-post)
Message-ID: <1270006492076-1746259.post@n4.nabble.com>


Dear all,

I have posted a query on simulating a VAR (Vector Auto-regression) model on
R-help, however still unable to get some satisfactory reply. That post can
be found here
"http://n4.nabble.com/Simulation-of-VAR-td1693295.html#a1693295". Therefore
I am re-posting the same here as well. Hopefully this query will be able to
fetch some educated attention from the experts here, who are presumably more
into time series analysis/finance.

This is my post :

I want to simulate a VAR model on some estimated coefficients. And employed
two approaches, one is my native approach completely based on the my
understanding on VAR and second based "simulate" function from "dse"
package. Surprisingly those two are giving quite different results, although
they are based on same set of random numbers. Here is that :

library(dse) 
A1 <- matrix(rnorm(16),4) 
A2 <- matrix(rnorm(16),4) 
mu <- rnorm(4) 
sigma <- matrix(c(0.006594712, 
0.006467731, 
-0.000254914, 
0.005939934, 
0.006467731, 
0.006654184, 
-0.000384097, 
0.005658247, 
-0.000254914, 
-0.000384097, 
0.000310294, 
4.34141E-05, 
0.005939934, 
0.005658247, 
4.34141E-05, 
0.00574024), 4) 
initial.val <- matrix(c(-0.2347096, 
-0.1803612, 
-0.2780356, 
-0.2154427 , 
3.740364, 
3.757908, 
3.50216 , 
3.57783), 2) 

##### My approach
res <- matrix(NA, 4,4); res[c(1,2),] <- initial.val 
library(mnormt); shocks <- rmnorm(2, rep(0,4), sigma) 
for (i in 1:2) { 
      res[i+2,] <- mu + A1%*%res[i+2-1,] + A2%*%res[i+2-2,] + shocks[i,] } 
res 
##### dse approach
temp1 <- matrix(t(cbind(diag(4), A1, A2)), ncol = 4, byrow = TRUE) 
model <- ARMA(A=array(temp1, c(3,4,4)), B=diag(4), TREND=mu) 
simulate(model, y0=initial.val, sampleT=2, noise=shocks) 


So I guess something terribly going wrong in any of the approaches in terms
of my understanding. Can someone here point out what is that, if any? Your
help will be highly appreciated.

Thanks,
-- 
View this message in context: http://n4.nabble.com/Simulating-VAR-model-re-post-tp1746259p1746259.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From matthieu.stigler at gmail.com  Wed Mar 31 09:20:25 2010
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Wed, 31 Mar 2010 09:20:25 +0200
Subject: [R-SIG-Finance] Simulating VAR model (re-post)
In-Reply-To: <1270006492076-1746259.post@n4.nabble.com>
References: <1270006492076-1746259.post@n4.nabble.com>
Message-ID: <4BB2F7B9.10308@gmail.com>

I don't think this will solve the problem but it looks like you are once 
specifying mu as a constant (your model) once as a trend (dse), right?

Mat

Ron_M a ?crit :
> Dear all,
>
> I have posted a query on simulating a VAR (Vector Auto-regression) model on
> R-help, however still unable to get some satisfactory reply. That post can
> be found here
> "http://n4.nabble.com/Simulation-of-VAR-td1693295.html#a1693295". Therefore
> I am re-posting the same here as well. Hopefully this query will be able to
> fetch some educated attention from the experts here, who are presumably more
> into time series analysis/finance.
>
> This is my post :
>
> I want to simulate a VAR model on some estimated coefficients. And employed
> two approaches, one is my native approach completely based on the my
> understanding on VAR and second based "simulate" function from "dse"
> package. Surprisingly those two are giving quite different results, although
> they are based on same set of random numbers. Here is that :
>
> library(dse) 
> A1 <- matrix(rnorm(16),4) 
> A2 <- matrix(rnorm(16),4) 
> mu <- rnorm(4) 
> sigma <- matrix(c(0.006594712, 
> 0.006467731, 
> -0.000254914, 
> 0.005939934, 
> 0.006467731, 
> 0.006654184, 
> -0.000384097, 
> 0.005658247, 
> -0.000254914, 
> -0.000384097, 
> 0.000310294, 
> 4.34141E-05, 
> 0.005939934, 
> 0.005658247, 
> 4.34141E-05, 
> 0.00574024), 4) 
> initial.val <- matrix(c(-0.2347096, 
> -0.1803612, 
> -0.2780356, 
> -0.2154427 , 
> 3.740364, 
> 3.757908, 
> 3.50216 , 
> 3.57783), 2) 
>
> ##### My approach
> res <- matrix(NA, 4,4); res[c(1,2),] <- initial.val 
> library(mnormt); shocks <- rmnorm(2, rep(0,4), sigma) 
> for (i in 1:2) { 
>       res[i+2,] <- mu + A1%*%res[i+2-1,] + A2%*%res[i+2-2,] + shocks[i,] } 
> res 
> ##### dse approach
> temp1 <- matrix(t(cbind(diag(4), A1, A2)), ncol = 4, byrow = TRUE) 
> model <- ARMA(A=array(temp1, c(3,4,4)), B=diag(4), TREND=mu) 
> simulate(model, y0=initial.val, sampleT=2, noise=shocks) 
>
>
> So I guess something terribly going wrong in any of the approaches in terms
> of my understanding. Can someone here point out what is that, if any? Your
> help will be highly appreciated.
>
> Thanks,
>


From ron_michael70 at yahoo.com  Wed Mar 31 10:28:06 2010
From: ron_michael70 at yahoo.com (Ron_M)
Date: Wed, 31 Mar 2010 00:28:06 -0800 (PST)
Subject: [R-SIG-Finance] Simulating VAR model (re-post)
In-Reply-To: <4BB2F7B9.10308@gmail.com>
References: <1270006492076-1746259.post@n4.nabble.com>
	<4BB2F7B9.10308@gmail.com>
Message-ID: <1270024086107-1746451.post@n4.nabble.com>


Thanks for this mail. In the documentation of ?ARMA following definition for
"TREND" is given :

"The name of last term, ?TREND?, is misleading. If it is NULL
     it is treated as zero. If it is a p-vector, then this constant
     vector is added to the the p-vector ?y(t)? at each period. For
     a stable model this would give the none zero mean, and might more
     appropriately be called the constant or intercept rather than
     trend. If the model is for differenced data, then this mean is the
     trend of the undifferenced model. The more general case is when
     ?TREND? is a time series matrix of the same dimension as
     ?y?. In this case it is added to ?y?. This allows for a
     very general deterministic component, which may or may not be a
     traditional trend."

>From this write-up what I understood is I can treat the constant_term as
trend. Or I messed-up?

Thanks,
-- 
View this message in context: http://n4.nabble.com/Simulating-VAR-model-re-post-tp1746259p1746451.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From renault.gautier at gmail.com  Wed Mar 31 10:57:50 2010
From: renault.gautier at gmail.com (Gautier RENAULT)
Date: Wed, 31 Mar 2010 10:57:50 +0200
Subject: [R-SIG-Finance] VECM problem with exogenous components
Message-ID: <s2z5bfb4a971003310157w3a97613co41a155078eedb938@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100331/6af0a600/attachment.pl>

From Bernhard_Pfaff at fra.invesco.com  Wed Mar 31 11:33:02 2010
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Wed, 31 Mar 2010 10:33:02 +0100
Subject: [R-SIG-Finance] FW:  VECM problem with exogenous components
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C3235BEB24@GBHENXMB02.corp.amvescap.net>

Dear Gautier,
 
standard errors, t-values and marginal signficnance levels 
are not implmenented for a VECM in the package urca. 
However, you can transform your VECM into its level-VAR 
form (see vec2var() in package vars) and can obtain the 
desired numbers by applying the summary method.
  
Best,
Bernhard  


 |>  
 |>   |>  -----Original Message-----
 |>   |>  From: r-sig-finance-bounces at stat.math.ethz.ch 
 |>   |>  [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf 
 |>   |>  Of Gautier RENAULT
 |>   |>  Sent: Wednesday, March 31, 2010 10:58 AM
 |>   |>  To: r-sig-finance at stat.math.ethz.ch
 |>   |>  Subject: [R-SIG-Finance] VECM problem with exogenous 
 |>  components
 |>   |>  
 |>   |>  Dear all,
 |>   |>  
 |>   |>  I deal with a econometrics problem in R.
 |>   |>  
 |>   |>  My final goal is to estimate a vecm (three components) 
 |>   |>  imposing combined
 |>   |>  restrictions on two components in alpha matrix.
 |>   |>  
 |>   |>  I have no problem to :
 |>   |>  solve the problem using ca.jo() and cajorls() when I treat 
 |>   |>  all components as
 |>   |>  endogenous
 |>   |>  test exogeneity of one or more components
 |>   |>  
 |>   |>  but how can I get standard errors, t values, 
 |>  associated probs for :
 |>   |>  the cointegration equation ?
 |>   |>  the estimated value of the error correction term ?
 |>   |>  the lagged differences ?
 |>   |>  
 |>   |>  This is my R code :
 |>   |>  
 |>   |>  y.mat<-data.frame(y1,y2,y3)
 |>   |>  vecm<-ca.jo(y.mat, type="trace", ecdet= "const", K=2, 
 |>   |>  spec="transitory")
 |>   |>  vecm.result<-cajorls(vecm, r=1)
 |>   |>  summary(vecm.result$rlm)
 |>   |>  
 |>   |>  # testing weak exogeneity
 |>   |>  
 |>   |>  A<-matrix(c(1,0,0), nrow=3, ncol=1)       # restriction 
 |>   |>  matrix (y2, y3
 |>   |>  :treated as exogenous)
 |>   |>  vecm.restriction<-alrtest(vecm, A, r=1)
 |>   |>  summary(vecm.restriction)
 |>   |>  
 |>   |>  Could someone help ?
 |>   |>  
 |>   |>  Gautier
 |>   |>  
 |>   |>  	[[alternative HTML version deleted]]
 |>   |>  
 |>   |>  _______________________________________________
 |>   |>  R-SIG-Finance at stat.math.ethz.ch mailing list
 |>   |>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
 |>   |>  -- Subscriber-posting only. If you want to post, 
 |>  subscribe first.
 |>   |>  -- Also note that this is not the r-help list where 
 |>   |>  general R questions should go.
 |>   |>  
 |>  
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:10}}


From matthieu.stigler at gmail.com  Wed Mar 31 11:46:25 2010
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Wed, 31 Mar 2010 11:46:25 +0200
Subject: [R-SIG-Finance] FW:  VECM problem with exogenous components
In-Reply-To: <B89F0CE41D45644A97CCC93DF548C1C3235BEB24@GBHENXMB02.corp.amvescap.net>
References: <B89F0CE41D45644A97CCC93DF548C1C3235BEB24@GBHENXMB02.corp.amvescap.net>
Message-ID: <4BB319F1.2080904@gmail.com>

Hi

but how can I get standard errors, t values, 
 |>  associated probs for :
 |>   |>  the cointegration equation ?
 |>   |>  the estimated value of the error correction term ?
 |>   |>  the lagged differences ?

Ok 1 is not available, but I thought 2 and 3 would be available through 
cajorls(), unless one estimates a restricted  model, right?

Thanks for clarifying this point!

Matthieu

Pfaff, Bernhard Dr. a ?crit :
> Dear Gautier,
>  
> standard errors, t-values and marginal signficnance levels 
> are not implmenented for a VECM in the package urca. 
> However, you can transform your VECM into its level-VAR 
> form (see vec2var() in package vars) and can obtain the 
> desired numbers by applying the summary method.
>   
> Best,
> Bernhard  
>
>
>  |>  
>  |>   |>  -----Original Message-----
>  |>   |>  From: r-sig-finance-bounces at stat.math.ethz.ch 
>  |>   |>  [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf 
>  |>   |>  Of Gautier RENAULT
>  |>   |>  Sent: Wednesday, March 31, 2010 10:58 AM
>  |>   |>  To: r-sig-finance at stat.math.ethz.ch
>  |>   |>  Subject: [R-SIG-Finance] VECM problem with exogenous 
>  |>  components
>  |>   |>  
>  |>   |>  Dear all,
>  |>   |>  
>  |>   |>  I deal with a econometrics problem in R.
>  |>   |>  
>  |>   |>  My final goal is to estimate a vecm (three components) 
>  |>   |>  imposing combined
>  |>   |>  restrictions on two components in alpha matrix.
>  |>   |>  
>  |>   |>  I have no problem to :
>  |>   |>  solve the problem using ca.jo() and cajorls() when I treat 
>  |>   |>  all components as
>  |>   |>  endogenous
>  |>   |>  test exogeneity of one or more components
>  |>   |>  
>  |>   |>  but how can I get standard errors, t values, 
>  |>  associated probs for :
>  |>   |>  the cointegration equation ?
>  |>   |>  the estimated value of the error correction term ?
>  |>   |>  the lagged differences ?
>  |>   |>  
>  |>   |>  This is my R code :
>  |>   |>  
>  |>   |>  y.mat<-data.frame(y1,y2,y3)
>  |>   |>  vecm<-ca.jo(y.mat, type="trace", ecdet= "const", K=2, 
>  |>   |>  spec="transitory")
>  |>   |>  vecm.result<-cajorls(vecm, r=1)
>  |>   |>  summary(vecm.result$rlm)
>  |>   |>  
>  |>   |>  # testing weak exogeneity
>  |>   |>  
>  |>   |>  A<-matrix(c(1,0,0), nrow=3, ncol=1)       # restriction 
>  |>   |>  matrix (y2, y3
>  |>   |>  :treated as exogenous)
>  |>   |>  vecm.restriction<-alrtest(vecm, A, r=1)
>  |>   |>  summary(vecm.restriction)
>  |>   |>  
>  |>   |>  Could someone help ?
>  |>   |>  
>  |>   |>  Gautier
>  |>   |>  
>  |>   |>  	[[alternative HTML version deleted]]
>  |>   |>  
>  |>   |>  _______________________________________________
>  |>   |>  R-SIG-Finance at stat.math.ethz.ch mailing list
>  |>   |>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>  |>   |>  -- Subscriber-posting only. If you want to post, 
>  |>  subscribe first.
>  |>   |>  -- Also note that this is not the r-help list where 
>  |>   |>  general R questions should go.
>  |>   |>  
>  |>  
> *****************************************************************
> Confidentiality Note: The information contained in this ...{{dropped:10}}
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From Bernhard_Pfaff at fra.invesco.com  Wed Mar 31 11:53:16 2010
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Wed, 31 Mar 2010 10:53:16 +0100
Subject: [R-SIG-Finance] FW:  VECM problem with exogenous components
In-Reply-To: <4BB319F1.2080904@gmail.com>
References: <B89F0CE41D45644A97CCC93DF548C1C3235BEB24@GBHENXMB02.corp.amvescap.net>
	<4BB319F1.2080904@gmail.com>
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C3235BEB54@GBHENXMB02.corp.amvescap.net>

Hello Mat,

your are right about your asertion. cajorls() suffices for non-restricted models and hence a transformation to level-VAR is not necessary. 

Best,
Bernhard 

 |>  -----Original Message-----
 |>  From: Matthieu Stigler [mailto:matthieu.stigler at gmail.com] 
 |>  Sent: Wednesday, March 31, 2010 11:46 AM
 |>  To: r-sig-finance at stat.math.ethz.ch
 |>  Cc: Pfaff, Bernhard Dr.; renault.gautier at gmail.com
 |>  Subject: Re: [R-SIG-Finance] FW: VECM problem with 
 |>  exogenous components
 |>  
 |>  Hi
 |>  
 |>  but how can I get standard errors, t values, 
 |>   |>  associated probs for :
 |>   |>   |>  the cointegration equation ?
 |>   |>   |>  the estimated value of the error correction term ?
 |>   |>   |>  the lagged differences ?
 |>  
 |>  Ok 1 is not available, but I thought 2 and 3 would be 
 |>  available through 
 |>  cajorls(), unless one estimates a restricted  model, right?
 |>  
 |>  Thanks for clarifying this point!
 |>  
 |>  Matthieu
 |>  
 |>  Pfaff, Bernhard Dr. a ?crit :
 |>  > Dear Gautier,
 |>  >  
 |>  > standard errors, t-values and marginal signficnance levels 
 |>  > are not implmenented for a VECM in the package urca. 
 |>  > However, you can transform your VECM into its level-VAR 
 |>  > form (see vec2var() in package vars) and can obtain the 
 |>  > desired numbers by applying the summary method.
 |>  >   
 |>  > Best,
 |>  > Bernhard  
 |>  >
 |>  >
 |>  >  |>  
 |>  >  |>   |>  -----Original Message-----
 |>  >  |>   |>  From: r-sig-finance-bounces at stat.math.ethz.ch 
 |>  >  |>   |>  
 |>  [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf 
 |>  >  |>   |>  Of Gautier RENAULT
 |>  >  |>   |>  Sent: Wednesday, March 31, 2010 10:58 AM
 |>  >  |>   |>  To: r-sig-finance at stat.math.ethz.ch
 |>  >  |>   |>  Subject: [R-SIG-Finance] VECM problem with exogenous 
 |>  >  |>  components
 |>  >  |>   |>  
 |>  >  |>   |>  Dear all,
 |>  >  |>   |>  
 |>  >  |>   |>  I deal with a econometrics problem in R.
 |>  >  |>   |>  
 |>  >  |>   |>  My final goal is to estimate a vecm (three components) 
 |>  >  |>   |>  imposing combined
 |>  >  |>   |>  restrictions on two components in alpha matrix.
 |>  >  |>   |>  
 |>  >  |>   |>  I have no problem to :
 |>  >  |>   |>  solve the problem using ca.jo() and cajorls() 
 |>  when I treat 
 |>  >  |>   |>  all components as
 |>  >  |>   |>  endogenous
 |>  >  |>   |>  test exogeneity of one or more components
 |>  >  |>   |>  
 |>  >  |>   |>  but how can I get standard errors, t values, 
 |>  >  |>  associated probs for :
 |>  >  |>   |>  the cointegration equation ?
 |>  >  |>   |>  the estimated value of the error correction term ?
 |>  >  |>   |>  the lagged differences ?
 |>  >  |>   |>  
 |>  >  |>   |>  This is my R code :
 |>  >  |>   |>  
 |>  >  |>   |>  y.mat<-data.frame(y1,y2,y3)
 |>  >  |>   |>  vecm<-ca.jo(y.mat, type="trace", ecdet= "const", K=2, 
 |>  >  |>   |>  spec="transitory")
 |>  >  |>   |>  vecm.result<-cajorls(vecm, r=1)
 |>  >  |>   |>  summary(vecm.result$rlm)
 |>  >  |>   |>  
 |>  >  |>   |>  # testing weak exogeneity
 |>  >  |>   |>  
 |>  >  |>   |>  A<-matrix(c(1,0,0), nrow=3, ncol=1)       # 
 |>  restriction 
 |>  >  |>   |>  matrix (y2, y3
 |>  >  |>   |>  :treated as exogenous)
 |>  >  |>   |>  vecm.restriction<-alrtest(vecm, A, r=1)
 |>  >  |>   |>  summary(vecm.restriction)
 |>  >  |>   |>  
 |>  >  |>   |>  Could someone help ?
 |>  >  |>   |>  
 |>  >  |>   |>  Gautier
 |>  >  |>   |>  
 |>  >  |>   |>  	[[alternative HTML version deleted]]
 |>  >  |>   |>  
 |>  >  |>   |>  _______________________________________________
 |>  >  |>   |>  R-SIG-Finance at stat.math.ethz.ch mailing list
 |>  >  |>   |>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
 |>  >  |>   |>  -- Subscriber-posting only. If you want to post, 
 |>  >  |>  subscribe first.
 |>  >  |>   |>  -- Also note that this is not the r-help list where 
 |>  >  |>   |>  general R questions should go.
 |>  >  |>   |>  
 |>  >  |>  
 |>  > *****************************************************************
 |>  > Confidentiality Note: The information contained in this 
 |>  ...{{dropped:10}}
 |>  >
 |>  > _______________________________________________
 |>  > R-SIG-Finance at stat.math.ethz.ch mailing list
 |>  > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
 |>  > -- Subscriber-posting only. If you want to post, subscribe first.
 |>  > -- Also note that this is not the r-help list where 
 |>  general R questions should go.
 |>  >   
 |>  
 |>  


From renault.gautier at gmail.com  Wed Mar 31 12:33:51 2010
From: renault.gautier at gmail.com (renault gautier)
Date: Wed, 31 Mar 2010 12:33:51 +0200
Subject: [R-SIG-Finance] FW:  VECM problem with exogenous components
In-Reply-To: <B89F0CE41D45644A97CCC93DF548C1C3235BEB54@GBHENXMB02.corp.amvescap.net>
References: <B89F0CE41D45644A97CCC93DF548C1C3235BEB24@GBHENXMB02.corp.amvescap.net>
	<4BB319F1.2080904@gmail.com>
	<B89F0CE41D45644A97CCC93DF548C1C3235BEB54@GBHENXMB02.corp.amvescap.net>
Message-ID: <4BB3250F.2010308@gmail.com>

Hello Bernhard,

I bought and red your book few month ago. I really appreciated it. It is 
useful to cope with econometrics in R.

Since alrtest()  returns a cajo.test object, can I take the result of 
this function as an argument in cajorls function to solve my problem 
with urca package? According to R documentation, cajorls() can take 
ca.jo or cajo.test.

I dit it to try and obtain all values (estimators, t stats, associated 
probs, standard errors) except for the cointegration equation by 
applying summary method :
these values seems to be right for lagged differences (I compare with 
results with E-view)
but the values associated to error correction terms seems to be false...

How is it possible ?

Gautier



Le 31/03/2010 11:53, Pfaff, Bernhard Dr. a ?crit :
> Hello Mat,
>
> your are right about your asertion. cajorls() suffices for non-restricted models and hence a transformation to level-VAR is not necessary.
>
> Best,
> Bernhard
>
>   |>   -----Original Message-----
>   |>   From: Matthieu Stigler [mailto:matthieu.stigler at gmail.com]
>   |>   Sent: Wednesday, March 31, 2010 11:46 AM
>   |>   To: r-sig-finance at stat.math.ethz.ch
>   |>   Cc: Pfaff, Bernhard Dr.; renault.gautier at gmail.com
>   |>   Subject: Re: [R-SIG-Finance] FW: VECM problem with
>   |>   exogenous components
>   |>
>   |>   Hi
>   |>
>   |>   but how can I get standard errors, t values,
>   |>    |>   associated probs for :
>   |>    |>    |>   the cointegration equation ?
>   |>    |>    |>   the estimated value of the error correction term ?
>   |>    |>    |>   the lagged differences ?
>   |>
>   |>   Ok 1 is not available, but I thought 2 and 3 would be
>   |>   available through
>   |>   cajorls(), unless one estimates a restricted  model, right?
>   |>
>   |>   Thanks for clarifying this point!
>   |>
>   |>   Matthieu
>   |>
>   |>   Pfaff, Bernhard Dr. a ?crit :
>   |>   >  Dear Gautier,
>   |>   >
>   |>   >  standard errors, t-values and marginal signficnance levels
>   |>   >  are not implmenented for a VECM in the package urca.
>   |>   >  However, you can transform your VECM into its level-VAR
>   |>   >  form (see vec2var() in package vars) and can obtain the
>   |>   >  desired numbers by applying the summary method.
>   |>   >
>   |>   >  Best,
>   |>   >  Bernhard
>   |>   >
>   |>   >
>   |>   >   |>
>   |>   >   |>    |>   -----Original Message-----
>   |>   >   |>    |>   From: r-sig-finance-bounces at stat.math.ethz.ch
>   |>   >   |>    |>
>   |>   [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf
>   |>   >   |>    |>   Of Gautier RENAULT
>   |>   >   |>    |>   Sent: Wednesday, March 31, 2010 10:58 AM
>   |>   >   |>    |>   To: r-sig-finance at stat.math.ethz.ch
>   |>   >   |>    |>   Subject: [R-SIG-Finance] VECM problem with exogenous
>   |>   >   |>   components
>   |>   >   |>    |>
>   |>   >   |>    |>   Dear all,
>   |>   >   |>    |>
>   |>   >   |>    |>   I deal with a econometrics problem in R.
>   |>   >   |>    |>
>   |>   >   |>    |>   My final goal is to estimate a vecm (three components)
>   |>   >   |>    |>   imposing combined
>   |>   >   |>    |>   restrictions on two components in alpha matrix.
>   |>   >   |>    |>
>   |>   >   |>    |>   I have no problem to :
>   |>   >   |>    |>   solve the problem using ca.jo() and cajorls()
>   |>   when I treat
>   |>   >   |>    |>   all components as
>   |>   >   |>    |>   endogenous
>   |>   >   |>    |>   test exogeneity of one or more components
>   |>   >   |>    |>
>   |>   >   |>    |>   but how can I get standard errors, t values,
>   |>   >   |>   associated probs for :
>   |>   >   |>    |>   the cointegration equation ?
>   |>   >   |>    |>   the estimated value of the error correction term ?
>   |>   >   |>    |>   the lagged differences ?
>   |>   >   |>    |>
>   |>   >   |>    |>   This is my R code :
>   |>   >   |>    |>
>   |>   >   |>    |>   y.mat<-data.frame(y1,y2,y3)
>   |>   >   |>    |>   vecm<-ca.jo(y.mat, type="trace", ecdet= "const", K=2,
>   |>   >   |>    |>   spec="transitory")
>   |>   >   |>    |>   vecm.result<-cajorls(vecm, r=1)
>   |>   >   |>    |>   summary(vecm.result$rlm)
>   |>   >   |>    |>
>   |>   >   |>    |>   # testing weak exogeneity
>   |>   >   |>    |>
>   |>   >   |>    |>   A<-matrix(c(1,0,0), nrow=3, ncol=1)       #
>   |>   restriction
>   |>   >   |>    |>   matrix (y2, y3
>   |>   >   |>    |>   :treated as exogenous)
>   |>   >   |>    |>   vecm.restriction<-alrtest(vecm, A, r=1)
>   |>   >   |>    |>   summary(vecm.restriction)
>   |>   >   |>    |>
>   |>   >   |>    |>   Could someone help ?
>   |>   >   |>    |>
>   |>   >   |>    |>   Gautier
>   |>   >   |>    |>
>   |>   >   |>    |>   	[[alternative HTML version deleted]]
>   |>   >   |>    |>
>   |>   >   |>    |>   _______________________________________________
>   |>   >   |>    |>   R-SIG-Finance at stat.math.ethz.ch mailing list
>   |>   >   |>    |>   https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>   |>   >   |>    |>   -- Subscriber-posting only. If you want to post,
>   |>   >   |>   subscribe first.
>   |>   >   |>    |>   -- Also note that this is not the r-help list where
>   |>   >   |>    |>   general R questions should go.
>   |>   >   |>    |>
>   |>   >   |>
>   |>   >  *****************************************************************
>   |>   >  Confidentiality Note: The information contained in this
>   |>   ...{{dropped:10}}
>   |>   >
>   |>   >  _______________________________________________
>   |>   >  R-SIG-Finance at stat.math.ethz.ch mailing list
>   |>   >  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>   |>   >  -- Subscriber-posting only. If you want to post, subscribe first.
>   |>   >  -- Also note that this is not the r-help list where
>   |>   general R questions should go.
>   |>   >
>   |>
>   |>
>


From Bernhard_Pfaff at fra.invesco.com  Wed Mar 31 14:08:05 2010
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Wed, 31 Mar 2010 13:08:05 +0100
Subject: [R-SIG-Finance] FW:  VECM problem with exogenous components
In-Reply-To: <4BB3250F.2010308@gmail.com>
References: <B89F0CE41D45644A97CCC93DF548C1C3235BEB24@GBHENXMB02.corp.amvescap.net>
	<4BB319F1.2080904@gmail.com>
	<B89F0CE41D45644A97CCC93DF548C1C3235BEB54@GBHENXMB02.corp.amvescap.net>
	<4BB3250F.2010308@gmail.com>
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C3235BEC3F@GBHENXMB02.corp.amvescap.net>

Hello Gautier,

I am not familiar with the EViews implementation and hence cannot comment on why the results differ. Is the \beta matrix the same, i.e. the normalization?

Best,
Bernhard

 |>  -----Original Message-----
 |>  From: renault gautier [mailto:renault.gautier at gmail.com] 
 |>  Sent: Wednesday, March 31, 2010 12:34 PM
 |>  To: Pfaff, Bernhard Dr.
 |>  Cc: Matthieu Stigler; r-sig-finance at stat.math.ethz.ch
 |>  Subject: Re: [R-SIG-Finance] FW: VECM problem with 
 |>  exogenous components
 |>  
 |>  Hello Bernhard,
 |>  
 |>  I bought and red your book few month ago. I really 
 |>  appreciated it. It is 
 |>  useful to cope with econometrics in R.
 |>  
 |>  Since alrtest()  returns a cajo.test object, can I take 
 |>  the result of 
 |>  this function as an argument in cajorls function to solve 
 |>  my problem 
 |>  with urca package? According to R documentation, cajorls() 
 |>  can take 
 |>  ca.jo or cajo.test.
 |>  
 |>  I dit it to try and obtain all values (estimators, t 
 |>  stats, associated 
 |>  probs, standard errors) except for the cointegration equation by 
 |>  applying summary method :
 |>  these values seems to be right for lagged differences (I 
 |>  compare with 
 |>  results with E-view)
 |>  but the values associated to error correction terms seems 
 |>  to be false...
 |>  
 |>  How is it possible ?
 |>  
 |>  Gautier
 |>  
 |>  
 |>  
 |>  Le 31/03/2010 11:53, Pfaff, Bernhard Dr. a ?crit :
 |>  > Hello Mat,
 |>  >
 |>  > your are right about your asertion. cajorls() suffices 
 |>  for non-restricted models and hence a transformation to 
 |>  level-VAR is not necessary.
 |>  >
 |>  > Best,
 |>  > Bernhard
 |>  >
 |>  >   |>   -----Original Message-----
 |>  >   |>   From: Matthieu Stigler [mailto:matthieu.stigler at gmail.com]
 |>  >   |>   Sent: Wednesday, March 31, 2010 11:46 AM
 |>  >   |>   To: r-sig-finance at stat.math.ethz.ch
 |>  >   |>   Cc: Pfaff, Bernhard Dr.; renault.gautier at gmail.com
 |>  >   |>   Subject: Re: [R-SIG-Finance] FW: VECM problem with
 |>  >   |>   exogenous components
 |>  >   |>
 |>  >   |>   Hi
 |>  >   |>
 |>  >   |>   but how can I get standard errors, t values,
 |>  >   |>    |>   associated probs for :
 |>  >   |>    |>    |>   the cointegration equation ?
 |>  >   |>    |>    |>   the estimated value of the error 
 |>  correction term ?
 |>  >   |>    |>    |>   the lagged differences ?
 |>  >   |>
 |>  >   |>   Ok 1 is not available, but I thought 2 and 3 would be
 |>  >   |>   available through
 |>  >   |>   cajorls(), unless one estimates a restricted  
 |>  model, right?
 |>  >   |>
 |>  >   |>   Thanks for clarifying this point!
 |>  >   |>
 |>  >   |>   Matthieu
 |>  >   |>
 |>  >   |>   Pfaff, Bernhard Dr. a ?crit :
 |>  >   |>   >  Dear Gautier,
 |>  >   |>   >
 |>  >   |>   >  standard errors, t-values and marginal 
 |>  signficnance levels
 |>  >   |>   >  are not implmenented for a VECM in the package urca.
 |>  >   |>   >  However, you can transform your VECM into its level-VAR
 |>  >   |>   >  form (see vec2var() in package vars) and can obtain the
 |>  >   |>   >  desired numbers by applying the summary method.
 |>  >   |>   >
 |>  >   |>   >  Best,
 |>  >   |>   >  Bernhard
 |>  >   |>   >
 |>  >   |>   >
 |>  >   |>   >   |>
 |>  >   |>   >   |>    |>   -----Original Message-----
 |>  >   |>   >   |>    |>   From: 
 |>  r-sig-finance-bounces at stat.math.ethz.ch
 |>  >   |>   >   |>    |>
 |>  >   |>   [mailto:r-sig-finance-bounces at stat.math.ethz.ch] On Behalf
 |>  >   |>   >   |>    |>   Of Gautier RENAULT
 |>  >   |>   >   |>    |>   Sent: Wednesday, March 31, 2010 10:58 AM
 |>  >   |>   >   |>    |>   To: r-sig-finance at stat.math.ethz.ch
 |>  >   |>   >   |>    |>   Subject: [R-SIG-Finance] VECM 
 |>  problem with exogenous
 |>  >   |>   >   |>   components
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   Dear all,
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   I deal with a econometrics problem in R.
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   My final goal is to estimate a 
 |>  vecm (three components)
 |>  >   |>   >   |>    |>   imposing combined
 |>  >   |>   >   |>    |>   restrictions on two components in 
 |>  alpha matrix.
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   I have no problem to :
 |>  >   |>   >   |>    |>   solve the problem using ca.jo() 
 |>  and cajorls()
 |>  >   |>   when I treat
 |>  >   |>   >   |>    |>   all components as
 |>  >   |>   >   |>    |>   endogenous
 |>  >   |>   >   |>    |>   test exogeneity of one or more components
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   but how can I get standard errors, 
 |>  t values,
 |>  >   |>   >   |>   associated probs for :
 |>  >   |>   >   |>    |>   the cointegration equation ?
 |>  >   |>   >   |>    |>   the estimated value of the error 
 |>  correction term ?
 |>  >   |>   >   |>    |>   the lagged differences ?
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   This is my R code :
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   y.mat<-data.frame(y1,y2,y3)
 |>  >   |>   >   |>    |>   vecm<-ca.jo(y.mat, type="trace", 
 |>  ecdet= "const", K=2,
 |>  >   |>   >   |>    |>   spec="transitory")
 |>  >   |>   >   |>    |>   vecm.result<-cajorls(vecm, r=1)
 |>  >   |>   >   |>    |>   summary(vecm.result$rlm)
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   # testing weak exogeneity
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   A<-matrix(c(1,0,0), nrow=3, ncol=1)       #
 |>  >   |>   restriction
 |>  >   |>   >   |>    |>   matrix (y2, y3
 |>  >   |>   >   |>    |>   :treated as exogenous)
 |>  >   |>   >   |>    |>   vecm.restriction<-alrtest(vecm, A, r=1)
 |>  >   |>   >   |>    |>   summary(vecm.restriction)
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   Could someone help ?
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   Gautier
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   	[[alternative HTML version deleted]]
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>    |>   
 |>  _______________________________________________
 |>  >   |>   >   |>    |>   R-SIG-Finance at stat.math.ethz.ch 
 |>  mailing list
 |>  >   |>   >   |>    |>   
 |>  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
 |>  >   |>   >   |>    |>   -- Subscriber-posting only. If you 
 |>  want to post,
 |>  >   |>   >   |>   subscribe first.
 |>  >   |>   >   |>    |>   -- Also note that this is not the 
 |>  r-help list where
 |>  >   |>   >   |>    |>   general R questions should go.
 |>  >   |>   >   |>    |>
 |>  >   |>   >   |>
 |>  >   |>   >  
 |>  *****************************************************************
 |>  >   |>   >  Confidentiality Note: The information contained in this
 |>  >   |>   ...{{dropped:10}}
 |>  >   |>   >
 |>  >   |>   >  _______________________________________________
 |>  >   |>   >  R-SIG-Finance at stat.math.ethz.ch mailing list
 |>  >   |>   >  https://stat.ethz.ch/mailman/listinfo/r-sig-finance
 |>  >   |>   >  -- Subscriber-posting only. If you want to 
 |>  post, subscribe first.
 |>  >   |>   >  -- Also note that this is not the r-help list where
 |>  >   |>   general R questions should go.
 |>  >   |>   >
 |>  >   |>
 |>  >   |>
 |>  >    
 |>  
 |>  


From julia_cains at yahoo.com  Wed Mar 31 14:55:58 2010
From: julia_cains at yahoo.com (Julia Cains)
Date: Wed, 31 Mar 2010 05:55:58 -0700 (PDT)
Subject: [R-SIG-Finance] Truncated Distributions - for OpVaR
Message-ID: <798928.13501.qm@web111603.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100331/114772c1/attachment.pl>

From cgb at datanalytics.com  Wed Mar 31 15:00:59 2010
From: cgb at datanalytics.com (Carlos J. Gil Bellosta )
Date: Wed, 31 Mar 2010 15:00:59 +0200
Subject: [R-SIG-Finance] Truncated Distributions - for OpVaR
In-Reply-To: <798928.13501.qm@web111603.mail.gq1.yahoo.com>
References: <798928.13501.qm@web111603.mail.gq1.yahoo.com>
Message-ID: <m2kb028350f1003310600yae8df236w9b795e49e69d2e1@mail.gmail.com>

Hello,

Package truncgof coudl be a good starting point.

http://cran.stat.auckland.ac.nz/web/packages/truncgof/index.html

I found something funny with it some time ago as you can read at

http://www.mail-archive.com/r-help at r-project.org/msg57500.html

The paper(s) mentioned in the package will provide you with ideas an
tools for extending the usual GoF tests for those cases where stress
should fall on tail behaviour.

Best regards,

Carlos J. Gil Bellosta
http://www.datanalytics.com




2010/3/31 Julia Cains <julia_cains at yahoo.com>:
> Dear R users,
>
> I am working on the Value at Risk (VaR) for the
> Operational risk. For a given loss data, we try to fit some statistical
> distributions using Kolmogorov-Smirnov (KS) test and A-D test and then
> for fitted distribution using the estimated parameters, the losses are
> simulated and the VaR is arrived at.
>
> The typical problem faced
> by the banks is the paucity of Internal loss data and thus banks depend
> on the external loss data obtained from external sources. This external
> data is normally of higher magnitude than the internal loss data of the
> bank. Thus using regression technique, this external data is scaled and
> then the internal data and the scaled external data is combined. Then we
> ?try to fit some statistical distribution to this combined data.
> However, at times it becomes very difficult to fit any distribution to
> this particular combined data as the data becomes Bimodal.
>
> The
> paper by G. Dionne and Hela Dahen " What about underevaluating
> Operational Value at Risk in the Banking sector?" suggests that we fit
> two distributions
>
> (1) to the internal data (called body part)
> with Upper cap or upper bound to the loss data and
>
> (2) to the
> external data with Lower bound (called Tail part).
>
> Thus, now I
> am dealing with two truncated distributions (i) having a lower loss
> bound (say 5000$ i.e. bank records only those losses exceeding 5,000$)
> and having an Upper bound of say 500,000$; and (ii) having lower loss
> bound of say 500,000$ and no upper limit.
>
> My question is
>
> (1)
> ?Is there any R package which helps to estimate the parameters of
> "various" Truncated distributions?
>
> (2) How to fit the truncated
> distributions to loss data in the sense how do we use KS and AD tests?
>
> Extremely
> ?sorry for writing such a long mail.
>
> Regards
>
> Julia
>
> ************************************************
>
>
>
> Only a man of Worth sees Worth in other men
>
>
>
> ************************************************
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From pierrelap at gmail.com  Wed Mar 31 21:40:22 2010
From: pierrelap at gmail.com (Pierre Lapointe)
Date: Wed, 31 Mar 2010 15:40:22 -0400
Subject: [R-SIG-Finance] plot log scale on y axis using zoo object (with
	plot.zoo)
Message-ID: <w2m676b0d531003311240lb6c31eacz650eb10986901aae@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100331/6b156122/attachment.pl>

From Anil.Vijendran.wg08 at wharton.upenn.edu  Wed Mar 31 21:47:54 2010
From: Anil.Vijendran.wg08 at wharton.upenn.edu (Anil Vijendran)
Date: Wed, 31 Mar 2010 12:47:54 -0700
Subject: [R-SIG-Finance] RBloomberg: blpReadFields
Message-ID: <u2uf6ac578e1003311247p99013532l4f4198e15bed7f4d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100331/4c759ed4/attachment.pl>

From renault.gautier at gmail.com  Wed Mar 31 21:57:27 2010
From: renault.gautier at gmail.com (Gautier RENAULT)
Date: Wed, 31 Mar 2010 21:57:27 +0200
Subject: [R-SIG-Finance] FW: VECM problem with exogenous components
In-Reply-To: <B89F0CE41D45644A97CCC93DF548C1C3235BEC3F@GBHENXMB02.corp.amvescap.net>
References: <B89F0CE41D45644A97CCC93DF548C1C3235BEB24@GBHENXMB02.corp.amvescap.net>
	<4BB319F1.2080904@gmail.com>
	<B89F0CE41D45644A97CCC93DF548C1C3235BEB54@GBHENXMB02.corp.amvescap.net>
	<4BB3250F.2010308@gmail.com>
	<B89F0CE41D45644A97CCC93DF548C1C3235BEC3F@GBHENXMB02.corp.amvescap.net>
Message-ID: <j2k5bfb4a971003311257je1641d38rec5bd7a6e0b9ee64@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100331/5da8c62c/attachment.pl>

From brian at braverock.com  Wed Mar 31 21:58:54 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 31 Mar 2010 14:58:54 -0500
Subject: [R-SIG-Finance] plot log scale on y axis using zoo object (with
 plot.zoo)
In-Reply-To: <w2m676b0d531003311240lb6c31eacz650eb10986901aae@mail.gmail.com>
References: <w2m676b0d531003311240lb6c31eacz650eb10986901aae@mail.gmail.com>
Message-ID: <4BB3A97E.5020108@braverock.com>

try chartSeries with log.scale=TRUE

On 03/31/2010 02:40 PM, Pierre Lapointe wrote:
> Hi,
>
> I'd like to plot a times series with a log on the y-axis. I'm plotting a zoo
> object as it is easier to format the dates on the x-axis. Unfortunately,
> log="y" does not work with plot.zoo. Any idea?
>
> Here's a reproducible example
>
> x<-seq(1,10000,length.out=10)
> plot(x,log="y",type="l")  #works
>
> z<- zoo(seq(1,10000,length.out=10),
>       as.Date(c("1992-01-10", "1992-01-17", "1992-01-24", "1992-01-31",
>         "1992-02-07", "1992-02-14", "1992-02-21", "1992-02-28", "1992-03-06",
>         "1992-03-13")))
> plot(z,log="y")          #gives error
>
> #Warning message:
> #In plot.xy(xy.coords(x, y), type = type, ...) :
> #  "log" is not a graphical parameter
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>    


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From pierrelap at gmail.com  Wed Mar 31 22:14:48 2010
From: pierrelap at gmail.com (Pierre Lapointe)
Date: Wed, 31 Mar 2010 16:14:48 -0400
Subject: [R-SIG-Finance] plot log scale on y axis using zoo object (with
	plot.zoo)
In-Reply-To: <4BB3A97E.5020108@braverock.com>
References: <w2m676b0d531003311240lb6c31eacz650eb10986901aae@mail.gmail.com>
	<4BB3A97E.5020108@braverock.com>
Message-ID: <i2y676b0d531003311314n33a86ccanfd6e595034f3c8b6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20100331/4c13f39b/attachment.pl>

From jeff.a.ryan at gmail.com  Wed Mar 31 22:19:06 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Wed, 31 Mar 2010 15:19:06 -0500
Subject: [R-SIG-Finance] plot log scale on y axis using zoo object (with
	plot.zoo)
In-Reply-To: <w2m676b0d531003311240lb6c31eacz650eb10986901aae@mail.gmail.com>
References: <w2m676b0d531003311240lb6c31eacz650eb10986901aae@mail.gmail.com>
Message-ID: <i2ne8e755251003311319ye88dd180w79a3c0f8f4389bd5@mail.gmail.com>

A warning isn't an error.

As far as I can tell my output works using:

> plot(zoo(1:10,1:10))
> plot(zoo(1:10,1:10),log='y')
Warning message:
In plot.xy(xy.coords(x, y), type = type, ...) :
  "log" is not a graphical parameter

Jeff

On Wed, Mar 31, 2010 at 2:40 PM, Pierre Lapointe <pierrelap at gmail.com> wrote:
> Hi,
>
> I'd like to plot a times series with a log on the y-axis. I'm plotting a zoo
> object as it is easier to format the dates on the x-axis. Unfortunately,
> log="y" does not work with plot.zoo. Any idea?
>
> Here's a reproducible example
>
> x <-seq(1,10000,length.out=10)
> plot(x,log="y",type="l") ?#works
>
> z <- zoo(seq(1,10000,length.out=10),
> ? ? as.Date(c("1992-01-10", "1992-01-17", "1992-01-24", "1992-01-31",
> ? ? ? "1992-02-07", "1992-02-14", "1992-02-21", "1992-02-28", "1992-03-06",
> ? ? ? "1992-03-13")))
> plot(z,log="y") ? ? ? ? ?#gives error
>
> #Warning message:
> #In plot.xy(xy.coords(x, y), type = type, ...) :
> # ?"log" is not a graphical parameter
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


