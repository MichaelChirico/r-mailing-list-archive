From roschm at ymail.com  Mon Apr  1 19:17:22 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Mon, 1 Apr 2013 10:17:22 -0700 (PDT)
Subject: [R-SIG-Finance] Problems with data
In-Reply-To: <1364806514419-4662948.post@n4.nabble.com>
References: <1364801726234-4662947.post@n4.nabble.com>
	<1364806514419-4662948.post@n4.nabble.com>
Message-ID: <1364836642848-4662978.post@n4.nabble.com>

Hi starter123,

I posted some getting started code that includes the option of reading a csv
file from disk.  You can compare that to what you are doing.

http://r.789695.n4.nabble.com/quantstrat-newbie-sigFormula-example-tp4661594.html

Best regards,

Rob



--
View this message in context: http://r.789695.n4.nabble.com/Problems-with-data-tp4662947p4662978.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From roschm at ymail.com  Tue Apr  2 03:16:58 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Mon, 1 Apr 2013 18:16:58 -0700 (PDT)
Subject: [R-SIG-Finance] Updated Pair Trade Demo
Message-ID: <1364865418280-4663023.post@n4.nabble.com>

Hello All,

Since the old version is making an error, here is an updated version of
Garrett See's great pair trade demo.  

First, there is some boilerplate at the top for timezone and an RStudio
flag. If true, an x11() window is called instead of dev.new() which RStudio
built-in graphics doesn't support but this file uses.

The calcRatio indicator received a label="Ratio" argument to match the label
in the sigComparison lines.  Those lines also had "dn", "mavg", and "up"
which were changed to "BB.1", "BB.2", "BB.3", and label=='BB" was added to
the BBands indicator arguments.  That's all.

Best regards,

Rob




--
View this message in context: http://r.789695.n4.nabble.com/Updated-Pair-Trade-Demo-tp4663023.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From roschm at ymail.com  Tue Apr  2 03:18:31 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Mon, 1 Apr 2013 18:18:31 -0700 (PDT)
Subject: [R-SIG-Finance] Updated Pair Trade Demo
In-Reply-To: <1364865418280-4663023.post@n4.nabble.com>
References: <1364865418280-4663023.post@n4.nabble.com>
Message-ID: <1364865511207-4663024.post@n4.nabble.com>

pair_trade_edited.R
<http://r.789695.n4.nabble.com/file/n4663024/pair_trade_edited.R>  



--
View this message in context: http://r.789695.n4.nabble.com/Updated-Pair-Trade-Demo-tp4663023p4663024.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From roschm at ymail.com  Tue Apr  2 16:28:59 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Tue, 2 Apr 2013 07:28:59 -0700 (PDT)
Subject: [R-SIG-Finance] Updated Pair Trade Demo
In-Reply-To: <1364865511207-4663024.post@n4.nabble.com>
References: <1364865418280-4663023.post@n4.nabble.com>
	<1364865511207-4663024.post@n4.nabble.com>
Message-ID: <1364912939764-4663089.post@n4.nabble.com>

I received an e-mail that the original file wasn't generating an error for
some.  (Newbie panic ensues!)  It can be reproduced (for me) via R --vanilla
at a terminal.  Then require(quantstrat) and demo(pair_trade).  So, I have
submitted a bug report to R-Forge as was suggested.  I had thought I was
pretty up to date, but I'm going to revisit installing from source. 

Best regards,

Rob

> sessionInfo()
R version 2.15.3 (2013-03-01)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8   
LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] quantstrat_0.7.7        foreach_1.4.0           blotter_0.8.13         
[4] FinancialInstrument_1.1 quantmod_0.4-0          Defaults_1.1-1         
[7] TTR_0.22-0              xts_0.9-3               zoo_1.7-9              

loaded via a namespace (and not attached):
[1] codetools_0.2-8 grid_2.15.3     iterators_1.0.6 lattice_0.20-13
tools_2.15.3   




--
View this message in context: http://r.789695.n4.nabble.com/Updated-Pair-Trade-Demo-tp4663023p4663089.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From thais.azevedo at aluno.puc-rio.br  Wed Apr  3 15:29:58 2013
From: thais.azevedo at aluno.puc-rio.br (THAIS CRISTINA CHAGAS S AZEVEDO)
Date: Wed, 3 Apr 2013 10:29:58 -0300 (BRT)
Subject: [R-SIG-Finance] problems with rugarch
Message-ID: <1452.164.85.6.1.1364995798.squirrel@webmail.aluno.puc-rio.br>

Hi,

I?m trying to use the ugarchfit function and an error is being reported.
This is the script:

spec1=ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
c(1,1),submodel = NULL),mean.model = list(armaOrder = c(1, 1),include.mean
= TRUE),distribution.model = "std")

fit1 = ugarchfit(spec=spec1,data=x,out.sample=0)

The "x" object it's a xts object with more than 4000 data.

The following message is exhibit:

Error in .hessian2sidedcpp(f, ipars[estidx, 1], arglist = arglist) :
  SET_VECTOR_ELT() can only be applied to a 'list', not a 'symbol'

Where is the mistake in the function?

I?m using the most updated version of the package (1.0-16).

Tks the help.


From roschm at ymail.com  Thu Apr  4 19:23:47 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Thu, 4 Apr 2013 10:23:47 -0700 (PDT)
Subject: [R-SIG-Finance] Cross correlation problems
In-Reply-To: <1364978358960-4663151.post@n4.nabble.com>
References: <1364978358960-4663151.post@n4.nabble.com>
Message-ID: <1365096227859-4663338.post@n4.nabble.com>

Hi starter123,

I don't have any good suggestions but here's a little code snippet that
might give you some ideas.  ( Thanks to rosy2 from elitetrader)

Best Regards,

Rob

library(quantmod)
getSymbols("YHOO",src="google")
getSymbols("GOOG",src="google")
getSymbols("MSFT",src="google")
df = data.frame( dailyReturn(YHOO), dailyReturn(GOOG), dailyReturn(MSFT) )
names(df)<- c("YHOO","GOOG","MSFT")
round(cor(df),2)




--
View this message in context: http://r.789695.n4.nabble.com/Cross-correlation-problems-tp4663151p4663338.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From bill at easterngrain.com  Fri Apr  5 11:51:10 2013
From: bill at easterngrain.com (wlblount)
Date: Fri, 5 Apr 2013 02:51:10 -0700 (PDT)
Subject: [R-SIG-Finance] Cross correlation problems
In-Reply-To: <1365096227859-4663338.post@n4.nabble.com>
References: <1364978358960-4663151.post@n4.nabble.com>
	<1365096227859-4663338.post@n4.nabble.com>
Message-ID: <1365155470147-4663403.post@n4.nabble.com>

just curious why this would not work

library(quantmod) 
getSymbols("SPY",src="google") 
getSymbols("ILF",src="google") 
getSymbols("EWZ",src="google") 
df = data.frame( dailyReturn(SPY), dailyReturn(ILF), dailyReturn(EWZ) ) 
names(df)<- c("SPY","ILF","EWZ") 
round(cor(df),2)

i assume it has to do with the "names" function.

can some one point me in the direction of... 

1 - using variables as to only have to input symbol once  

2 - how about expanding to 4 symbols (or any amount of 
symbols)

Thanks,
Bill




--
View this message in context: http://r.789695.n4.nabble.com/Cross-correlation-problems-tp4663151p4663403.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From roschm at ymail.com  Fri Apr  5 14:03:13 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Fri, 5 Apr 2013 05:03:13 -0700 (PDT)
Subject: [R-SIG-Finance] Cross correlation problems
In-Reply-To: <1365155470147-4663403.post@n4.nabble.com>
References: <1364978358960-4663151.post@n4.nabble.com>
	<1365096227859-4663338.post@n4.nabble.com>
	<1365155470147-4663403.post@n4.nabble.com>
Message-ID: <1365163393415-4663410.post@n4.nabble.com>

I think of setting the initDate as a cheesy way to induce the rows to match
better without having to actually deal with it.  Here's a more mangled
version:

library(quantmod)

sym1 <- "SPY"
sym2 <- "ILF"
sym3 <- "EWZ"
sym4 <- "IBM"
initDate <- "2010-01-01"
getSymbols(sym1,from=initDate)
getSymbols(sym2,from=initDate)
getSymbols(sym3,from=initDate)
getSymbols(sym4,from=initDate)
df <- data.frame( dailyReturn(get(sym1)), dailyReturn(get(sym2)), 
                 dailyReturn(get(sym3)), dailyReturn(get(sym4)) )
names(df) <- c(sym1,sym2,sym3,sym4)
print(round(cor(df),2))

Best regards,

Rob




--
View this message in context: http://r.789695.n4.nabble.com/Cross-correlation-problems-tp4663151p4663410.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From roschm at ymail.com  Fri Apr  5 15:30:06 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Fri, 5 Apr 2013 06:30:06 -0700 (PDT)
Subject: [R-SIG-Finance] Cross correlation problems
In-Reply-To: <1365163393415-4663410.post@n4.nabble.com>
References: <1364978358960-4663151.post@n4.nabble.com>
	<1365096227859-4663338.post@n4.nabble.com>
	<1365155470147-4663403.post@n4.nabble.com>
	<1365163393415-4663410.post@n4.nabble.com>
Message-ID: <1365168606481-4663425.post@n4.nabble.com>

And here is the way that a non-newbie would approach the problem.  (Thanks to
Brian who must be taking pity on us, LOL)

library(quantmod)
symbols <- c("SPY","ILF","EWZ","IBM")
initDate <- "2010-01-01"
getSymbols(symbols,from=initDate)
rets <- xts(do.call(cbind.xts,
                    lapply(symbols,function(sym)
                        dailyReturn(get(sym)))),
            order.by=as.Date(index(get(symbols[1]))))
colnames(rets) <- symbols
print(round(cor(df),2))




--
View this message in context: http://r.789695.n4.nabble.com/Cross-correlation-problems-tp4663151p4663425.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From roschm at ymail.com  Fri Apr  5 15:53:16 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Fri, 5 Apr 2013 06:53:16 -0700 (PDT)
Subject: [R-SIG-Finance] Cross correlation problems
In-Reply-To: <1365168606481-4663425.post@n4.nabble.com>
References: <1364978358960-4663151.post@n4.nabble.com>
	<1365096227859-4663338.post@n4.nabble.com>
	<1365155470147-4663403.post@n4.nabble.com>
	<1365163393415-4663410.post@n4.nabble.com>
	<1365168606481-4663425.post@n4.nabble.com>
Message-ID: <1365169996913-4663428.post@n4.nabble.com>

Doh!  Might as well fix my typo at the bottom.

library(quantmod)
symbols <- c("SPY","ILF","EWZ","IBM")
initDate <- "2010-01-01"
getSymbols(symbols,from=initDate)
rets <- xts(do.call(cbind.xts,
                    lapply(symbols,function(sym)
                        dailyReturn(get(sym)))),
            order.by=as.Date(index(get(symbols[1]))))
colnames(rets) <- symbols
print(round(cor(rets),2))    




--
View this message in context: http://r.789695.n4.nabble.com/Cross-correlation-problems-tp4663151p4663428.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From bill at easterngrain.com  Fri Apr  5 19:16:45 2013
From: bill at easterngrain.com (wlblount)
Date: Fri, 5 Apr 2013 10:16:45 -0700 (PDT)
Subject: [R-SIG-Finance] Cross correlation problems
In-Reply-To: <1365169996913-4663428.post@n4.nabble.com>
References: <1364978358960-4663151.post@n4.nabble.com>
	<1365096227859-4663338.post@n4.nabble.com>
	<1365155470147-4663403.post@n4.nabble.com>
	<1365163393415-4663410.post@n4.nabble.com>
	<1365168606481-4663425.post@n4.nabble.com>
	<1365169996913-4663428.post@n4.nabble.com>
Message-ID: <1365182205320-4663457.post@n4.nabble.com>

so then the above with 4 symbols works fine, but when you add a symbol

library(quantmod) 

sym1 <- "SPY" 
sym2 <- "ILF" 
sym3 <- "EWZ" 
sym4 <- "DIA"  
sym5 <- "EPP"
initDate <- "2010-01-01" 
getSymbols(sym1,from=initDate) 
getSymbols(sym2,from=initDate) 
getSymbols(sym3,from=initDate) 
getSymbols(sym4,from=initDate) 
getSymbols(sym5,from=initDate) 

df <- data.frame( dailyReturn(get(sym1)), dailyReturn(get(sym2)), 
                  dailyReturn(get(sym3)), dailyReturn(get(sym4)),
			dailyReturn(get(sym5))) 
names(df) <- c(sym1,sym2,sym3,sym4,sym5) 
print(round(cor(df),2))





you get an error message.  what am i missing?



--
View this message in context: http://r.789695.n4.nabble.com/Cross-correlation-problems-tp4663151p4663457.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Fri Apr  5 19:21:10 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 05 Apr 2013 12:21:10 -0500
Subject: [R-SIG-Finance] Cross correlation problems
In-Reply-To: <1365182205320-4663457.post@n4.nabble.com>
References: <1364978358960-4663151.post@n4.nabble.com>
	<1365096227859-4663338.post@n4.nabble.com>
	<1365155470147-4663403.post@n4.nabble.com>
	<1365163393415-4663410.post@n4.nabble.com>
	<1365168606481-4663425.post@n4.nabble.com>
	<1365169996913-4663428.post@n4.nabble.com>
	<1365182205320-4663457.post@n4.nabble.com>
Message-ID: <515F0806.7090202@braverock.com>

On 04/05/2013 12:16 PM, wlblount wrote:
> so then the above with 4 symbols works fine, but when you add a symbol
<... broken code deleted>
> you get an error message.  what am i missing?

The code that Rob forwarded later, below, is elastic to basically any 
number of symbols.

library(quantmod)
symbols <- c("SPY","ILF","EWZ","IBM","AAPL","GOOG")
initDate <- "2010-01-01"
getSymbols(symbols,from=initDate)
rets <- xts(do.call(cbind.xts,
                     lapply(symbols,function(sym)
                         dailyReturn(get(sym)))),
             order.by=as.Date(index(get(symbols[1]))))
colnames(rets) <- symbols
print(round(cor(rets),2))


From bill at easterngrain.com  Fri Apr  5 21:10:36 2013
From: bill at easterngrain.com (wlblount)
Date: Fri, 5 Apr 2013 12:10:36 -0700 (PDT)
Subject: [R-SIG-Finance] Cross correlation problems
In-Reply-To: <515F0806.7090202@braverock.com>
References: <1364978358960-4663151.post@n4.nabble.com>
	<1365096227859-4663338.post@n4.nabble.com>
	<1365155470147-4663403.post@n4.nabble.com>
	<1365163393415-4663410.post@n4.nabble.com>
	<1365168606481-4663425.post@n4.nabble.com>
	<1365169996913-4663428.post@n4.nabble.com>
	<1365182205320-4663457.post@n4.nabble.com>
	<515F0806.7090202@braverock.com>
Message-ID: <1365189036342-4663470.post@n4.nabble.com>

so just for my own info.  why isnt the first one elastic?  is there some
function behind the scenes that is not obvious to the binarily challenged
eye?



--
View this message in context: http://r.789695.n4.nabble.com/Cross-correlation-problems-tp4663151p4663470.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From roschm at ymail.com  Fri Apr  5 23:28:36 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Fri, 5 Apr 2013 14:28:36 -0700 (PDT)
Subject: [R-SIG-Finance] Cross correlation problems
In-Reply-To: <1365189036342-4663470.post@n4.nabble.com>
References: <1364978358960-4663151.post@n4.nabble.com>
	<1365096227859-4663338.post@n4.nabble.com>
	<1365155470147-4663403.post@n4.nabble.com>
	<1365163393415-4663410.post@n4.nabble.com>
	<1365168606481-4663425.post@n4.nabble.com>
	<1365169996913-4663428.post@n4.nabble.com>
	<1365182205320-4663457.post@n4.nabble.com>
	<515F0806.7090202@braverock.com>
	<1365189036342-4663470.post@n4.nabble.com>
Message-ID: <1365197316252-4663484.post@n4.nabble.com>

Hi wlblount,

The snippet I found was just barely functional.  You could "fix" the frame
buffer on the five sized version by changing the initDate to 2011.  It is
sensitive to the length of the data.  But the right way is by using the xts
object.   And you get lots of nice hidden features that way.  For example,
put 2003 for the year in the xts version.  You will find that some
correlations are missing but the calculation still doesn't give any errors.

Best regards,

Rob



--
View this message in context: http://r.789695.n4.nabble.com/Cross-correlation-problems-tp4663151p4663484.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From bill at easterngrain.com  Sat Apr  6 04:00:57 2013
From: bill at easterngrain.com (wlblount)
Date: Fri, 5 Apr 2013 19:00:57 -0700 (PDT)
Subject: [R-SIG-Finance] Cross correlation problems
In-Reply-To: <1365197316252-4663484.post@n4.nabble.com>
References: <1364978358960-4663151.post@n4.nabble.com>
	<1365096227859-4663338.post@n4.nabble.com>
	<1365155470147-4663403.post@n4.nabble.com>
	<1365163393415-4663410.post@n4.nabble.com>
	<1365168606481-4663425.post@n4.nabble.com>
	<1365169996913-4663428.post@n4.nabble.com>
	<1365182205320-4663457.post@n4.nabble.com>
	<515F0806.7090202@braverock.com>
	<1365189036342-4663470.post@n4.nabble.com>
	<1365197316252-4663484.post@n4.nabble.com>
Message-ID: <1365213657627-4663495.post@n4.nabble.com>

i see.  so the data ran out and therefore was not complete for all five
symbols... thus the error?  thank you.



--
View this message in context: http://r.789695.n4.nabble.com/Cross-correlation-problems-tp4663151p4663495.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From statisticiangermany at gmail.com  Sat Apr  6 11:56:52 2013
From: statisticiangermany at gmail.com (Stat Tistician)
Date: Sat, 6 Apr 2013 11:56:52 +0200
Subject: [R-SIG-Finance] EM algorithm with R manually implemented?
Message-ID: <CAC=XAU1xb=dGfA6kww2_Rc1KQB6G7-DG0NJirLKEfG7cxg8nRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130406/67e9823d/attachment.pl>

From roschm at ymail.com  Sat Apr  6 14:24:54 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Sat, 6 Apr 2013 05:24:54 -0700 (PDT)
Subject: [R-SIG-Finance] Cross correlation problems
In-Reply-To: <1365213657627-4663495.post@n4.nabble.com>
References: <1365096227859-4663338.post@n4.nabble.com>
	<1365155470147-4663403.post@n4.nabble.com>
	<1365163393415-4663410.post@n4.nabble.com>
	<1365168606481-4663425.post@n4.nabble.com>
	<1365169996913-4663428.post@n4.nabble.com>
	<1365182205320-4663457.post@n4.nabble.com>
	<515F0806.7090202@braverock.com>
	<1365189036342-4663470.post@n4.nabble.com>
	<1365197316252-4663484.post@n4.nabble.com>
	<1365213657627-4663495.post@n4.nabble.com>
Message-ID: <1365251094602-4663512.post@n4.nabble.com>

Hi wlblount,

I'm sorry, I think my poor explanation might be  misleading you.  I'm good
at that.   I don't think it is the total data length, rather that each
column has to match the others in the data frame.  (That's another thing
that using the xts object solves for us.)  My cheesy solution of shortening
the columns was to attempt to just make the columns match by getting rid of
missing data, etc.  Here is the five sized example showing the column
lengths not matching.

Best regards,

Rob

library(quantmod)

sym1 <- "SPY"
sym2 <- "ILF"
sym3 <- "EWZ"
sym4 <- "DIA"  
sym5 <- "EPP"
initDate <- "2010-01-01"
getSymbols(sym1,from=initDate)
getSymbols(sym2,from=initDate)
getSymbols(sym3,from=initDate)
getSymbols(sym4,from=initDate)
getSymbols(sym5,from=initDate)
print(length(get(sym1)))
print(length(get(sym2)))
print(length(get(sym3)))
print(length(get(sym4)))
print(length(get(sym5)))

df <- data.frame( dailyReturn(get(sym1)), dailyReturn(get(sym2)),
                  dailyReturn(get(sym3)), dailyReturn(get(sym4)),
                        dailyReturn(get(sym5)))
names(df) <- c(sym1,sym2,sym3,sym4,sym5)
print(round(cor(df),2))




--
View this message in context: http://r.789695.n4.nabble.com/Cross-correlation-problems-tp4663151p4663512.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From statisticiangermany at gmail.com  Sat Apr  6 22:42:41 2013
From: statisticiangermany at gmail.com (Stat Tistician)
Date: Sat, 6 Apr 2013 22:42:41 +0200
Subject: [R-SIG-Finance] error message sending question to the list
Message-ID: <CAC=XAU39E=o9cOB=EK3ShtiTVk1KVN4Mz=4CQ4s3GkJPfSqgQw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130406/eb847342/attachment.pl>

From michael.weylandt at gmail.com  Sat Apr  6 22:47:53 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Sat, 6 Apr 2013 15:47:53 -0500
Subject: [R-SIG-Finance] error message sending question to the list
In-Reply-To: <CAC=XAU39E=o9cOB=EK3ShtiTVk1KVN4Mz=4CQ4s3GkJPfSqgQw@mail.gmail.com>
References: <CAC=XAU39E=o9cOB=EK3ShtiTVk1KVN4Mz=4CQ4s3GkJPfSqgQw@mail.gmail.com>
Message-ID: <575C9478-6FEA-4FAF-BF4C-DDCCBAC1553E@gmail.com>

Post in plain text (not HTML) which is a choice within your email client.  

And please (!!) don't post the same question to multiple lists. If your question is off-topic, the list membership will redirect as needed. 
Double posting simply wasted the community's energies by duplicating responses. 

Michael

On Apr 6, 2013, at 3:42 PM, Stat Tistician <statisticiangermany at gmail.com> wrote:

> Hi,
> I tried to send several questions to the lists (both normal R and
> R-Sig-Finance), but everytime I look them up in the archives my messages
> end up with the following
> 
> "An embedded and charset-unspecified text was scrubbed...
> 
> for example see my post here:
> 
> https://stat.ethz.ch/pipermail/r-sig-finance/2013q2/011496.html
> 
> 
> This one was a real important for me. Can subscribers still read it? Shall
> I repost, how can I post correctly?
> 
> Thanks
> 
>    [[alternative HTML version deleted]]
> 

See -- HTML!


> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From bill at easterngrain.com  Tue Apr  9 03:12:32 2013
From: bill at easterngrain.com (wlblount)
Date: Mon, 8 Apr 2013 18:12:32 -0700 (PDT)
Subject: [R-SIG-Finance] Help with iBrokers data
Message-ID: <1365469952068-4663719.post@n4.nabble.com>

about 30 days ago i posted here looking for historical, intraday data.  since
then i have figured out how to use the ibrokers package to download approx 4
days of 3 minute data (650 bars x 8 variables = 5200 which is the ibrokers
limit for 1 request).

library(IBrokers)

tws <- twsConnect()

symbol <- "uvxy"

contract<- twsEquity(symbol)

pricedata<-reqHistoricalData(tws,contract,barSize="3 mins", duration = "1
W")

save(pricedata,file=symbol)

twsDisconnect(tws)


my next step is to figure out how to 1- loop this request to get older  data
(i would like to get 2 years) and append the saved file.  and 2 -eventually
move up to periodically updating 50 or so symbols and saving and appending
all the symbol data to individual files.


does anyone have any code or could anyone point me in the right direction? 
my coding skills are only slightly above control c and control v .  any help
would be greatly appreciated and i will be happy to share data, code, or
whatever i end up with.  thanks.  Bill




--
View this message in context: http://r.789695.n4.nabble.com/Help-with-iBrokers-data-tp4663719.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From gsee000 at gmail.com  Tue Apr  9 03:36:08 2013
From: gsee000 at gmail.com (G See)
Date: Mon, 8 Apr 2013 20:36:08 -0500
Subject: [R-SIG-Finance] Help with iBrokers data
In-Reply-To: <1365469952068-4663719.post@n4.nabble.com>
References: <1365469952068-4663719.post@n4.nabble.com>
Message-ID: <CA+xi=qbvVsqQaiVvnTFBQ_-Ziv3THKxXr1tyLRZrtDhNNwvLBA@mail.gmail.com>

For the first part, see ?reqHistory.  You can't get 2 years of data
though, IB only provides 1 year.

For the second part, maybe reqTBBOhistory from my twsInstrument
package is useful (https://r-forge.r-project.org/R/?group_id=1113).
See also the unexported wrapper twsInstrument:::update.data()

Garrett

On Mon, Apr 8, 2013 at 8:12 PM, wlblount <bill at easterngrain.com> wrote:
> about 30 days ago i posted here looking for historical, intraday data.  since
> then i have figured out how to use the ibrokers package to download approx 4
> days of 3 minute data (650 bars x 8 variables = 5200 which is the ibrokers
> limit for 1 request).
>
> library(IBrokers)
>
> tws <- twsConnect()
>
> symbol <- "uvxy"
>
> contract<- twsEquity(symbol)
>
> pricedata<-reqHistoricalData(tws,contract,barSize="3 mins", duration = "1
> W")
>
> save(pricedata,file=symbol)
>
> twsDisconnect(tws)
>
>
> my next step is to figure out how to 1- loop this request to get older  data
> (i would like to get 2 years) and append the saved file.  and 2 -eventually
> move up to periodically updating 50 or so symbols and saving and appending
> all the symbol data to individual files.
>
>
> does anyone have any code or could anyone point me in the right direction?
> my coding skills are only slightly above control c and control v .  any help
> would be greatly appreciated and i will be happy to share data, code, or
> whatever i end up with.  thanks.  Bill
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Help-with-iBrokers-data-tp4663719.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From bill at easterngrain.com  Tue Apr  9 13:07:19 2013
From: bill at easterngrain.com (wlblount)
Date: Tue, 9 Apr 2013 04:07:19 -0700 (PDT)
Subject: [R-SIG-Finance] Help with iBrokers data
In-Reply-To: <1365469952068-4663719.post@n4.nabble.com>
References: <1365469952068-4663719.post@n4.nabble.com>
Message-ID: <1365505639091-4663744.post@n4.nabble.com>

control v not working for me today...

running this for the default 1 minute, 1 year works


tws <- twsConnect()
symbol<-"UVXY"
contract <- twsEquity(symbol)


Sys.sleep(10) # mandatory 10s between request to avoid IB pacing violation
pricedata<-reqHistory(tws, Contract=contract)
save(pricedata,file=symbol)


changing the reqHistory arguments to 3 min. and 1 month of data causes an
error....


> pricedata<-reqHistory(tws, Contract=contract, barSize="3 mins", duration =
> "1 M")

gets this error...

Error in reqHistoricalData(conn, Contract, barSize = barSize, duration =
duration,  : 
  formal argument "duration" matched by multiple actual arguments



--
View this message in context: http://r.789695.n4.nabble.com/Help-with-iBrokers-data-tp4663719p4663744.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From michael.weylandt at gmail.com  Wed Apr 10 01:05:54 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Wed, 10 Apr 2013 00:05:54 +0100
Subject: [R-SIG-Finance] [R] Maximum likelihood estimation of ARMA(1,
	1)-GARCH(1, 1)
In-Reply-To: <CACByDzqJc2bMCVNH2QJFQWspNyNfakqZYBUVp19d6rRt6tDwVw@mail.gmail.com>
References: <CACByDzqJc2bMCVNH2QJFQWspNyNfakqZYBUVp19d6rRt6tDwVw@mail.gmail.com>
Message-ID: <CAAmySGN48vy+bthcuuHW3oQ-L-AvjDFFDRZcHeDYmYYZm7TRgw@mail.gmail.com>

Forwarding to r-sig-finance where you might get a better response.

MW

On Mon, Apr 8, 2013 at 5:30 AM, Andy Yeh <rochefort2010 at gmail.com> wrote:
> Hello
>
> Following some standard textbooks on ARMA(1,1)-GARCH(1,1) (e.g. Ruey
> Tsay's Analysis of Financial Time Series), I try to write an R program
> to estimate the key parameters of an ARMA(1,1)-GARCH(1,1) model for
> Intel's stock returns. For some random reason, I cannot decipher what
> is wrong with my R program. The R package fGarch already gives me the
> answer, but my customized function does not seem to produce the same
> result.
>
> I would like to build an R program that helps estimate the baseline
> ARMA(1,1)-GARCH(1,1) model. Then I would like to adapt this baseline
> script to fit different GARCH variants (e.g. EGARCH, NGARCH, and
> TGARCH). It would be much appreciated if you could provide some
> guidance in this case. The code below is the R script for estimating
> the 6 parameters of an ARMA(1,1)-GARCH(1,1) model for Intel's stock
> returns. At any rate, I would be glad to know your thoughts and
> insights. If you have a similar example, please feel free to share
> your extant code in R. Many thanks in advance.
>
> Emily
>
>
>
> # This R script offers a suite of functions for estimating  the
> volatility dynamics based on the standard ARMA(1,1)-GARCH(1,1) model
> and its variants.
> # The baseline ARMA(1,1) model characterizes the dynamic evolution of
> the return generating process.
> # The baseline GARCH(1,1) model depicts the the return volatility
> dynamics over time.
> # We can extend the GARCH(1,1) volatility model to a variety of
> alternative specifications to capture the potential asymmetry for a
> better comparison:
> # GARCH(1,1), EGARCH(1,1),  NGARCH(1,1), and TGARCH(1,1).
>
> options(scipen=10)
>
> intel= read.csv(file="intel.csv")
> summary(intel)
>
> raw_data= as.matrix(intel$logret)
>
> library(fGarch)
> garchFit(~arma(1,1)+garch(1,1), data=raw_data, trace=FALSE)
>
>
> negative_log_likelihood_arma11_garch11=
> function(theta, data)
> {mean =theta[1]
>  delta=theta[2]
>  gamma=theta[3]
>  omega=theta[4]
>  alpha=theta[5]
>  beta= theta[6]
>
>  r= ts(data)
>  n= length(r)
>
>  u= vector(length=n)
>  u= ts(u)
>  u[1]= r[1]- mean
>
>  for (t in 2:n)
>  {u[t]= r[t]- mean- delta*r[t-1]- gamma*u[t-1]}
>
>  h= vector(length=n)
>  h= ts(h)
>  h[1]= omega/(1-alpha-beta)
>
>  for (t in 2:n)
>  {h[t]= omega+ alpha*(u[t-1]^2)+ beta*h[t-1]}
>
>  #return(-sum(dnorm(u[2:n], mean=mean, sd=sqrt(h[2:n]), log=TRUE)))
>  pi=3.141592653589793238462643383279502884197169399375105820974944592
>  return(-sum(-0.5*log(2*pi) -0.5*log(h[2:n]) -0.5*(u[2:n]^2)/h[2:n]))
> }
>
>
> #theta0=c(0, +0.78, -0.79, +0.0000018, +0.06, +0.93, 0.01)
> theta0=rep(0.01,6)
> negative_log_likelihood_arma11_garch11(theta=theta0, data=raw_data)
>
>
> alpha= proc.time()
> maximum_likelihood_fit_arma11_garch11=
> nlm(negative_log_likelihood_arma11_garch11,
>     p=theta0,
>     data=raw_data,
>     hessian=TRUE,
>     iterlim=500)
> #optim(theta0,
> #      negative_log_likelihood_arma11_garch11,
> #      data=raw_data,
> #      method="L-BFGS-B",
> #      upper=c(+0.999999999999,+0.999999999999,+0.999999999999,0.999999999999,0.999999999999,0.999999999999),
> #      lower=c(-0.999999999999,-0.999999999999,-0.999999999999,0.000000000001,0.000000000001,0.000000000001),
> #      hessian=TRUE)
>
> # We record the end time and calculate the total runtime for the above work.
> omega= proc.time()
> runtime= omega-alpha
> zhours = floor(runtime/60/60)
> zminutes=floor(runtime/60- zhours*60)
> zseconds=floor(runtime- zhours*60*60- zminutes*60)
> print(paste("It takes ",zhours,"hour(s)", zminutes," minute(s) ","and
> ", zseconds,"second(s) to finish running this R program",sep=""))
>
>
> maximum_likelihood_fit_arma11_garch11
>
> sqrt(diag(solve(maximum_likelihood_fit_arma11_garch11$hessian)))
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michael.weylandt at gmail.com  Wed Apr 10 01:28:04 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Wed, 10 Apr 2013 00:28:04 +0100
Subject: [R-SIG-Finance] [R] Fitting distributions to financial data
 using volatility model to estimate VaR
In-Reply-To: <CAC=XAU2wOGH2+40hQtvD6fTi9eGc5=sVWpOLXH3MMnMQC9U6ug@mail.gmail.com>
References: <CAC=XAU2wOGH2+40hQtvD6fTi9eGc5=sVWpOLXH3MMnMQC9U6ug@mail.gmail.com>
Message-ID: <CAAmySGPpJ=BqO3O615+v07pBA-3oYwNTv3dDrq83f2JTA7Q-oA@mail.gmail.com>

Moving to R-SIG-Finance which seems to be the correct mailing list.

On Sun, Apr 7, 2013 at 8:41 AM, Stat Tistician
<statisticiangermany at gmail.com> wrote:
> Ok,
> I try it again with plain text, with a simple R code example and just
> sending it to the r list and you move it to sig finance if it is
> necessary.
>
> I try to be as detailed as possible.
>
> I want to fit a distribution to my financial data using a volatility
> model to estimate the VaR. So in case of a normal distribution, this
> would be very easy, I assume the returns to follow a normal
> distribution and calculate a volatility forecast for each day, so I
> have sigma_1,sigma_2,...,sigma_n,. I can calculate the VaR via (mu
> constant, z_alpha quantile of standard normal):
> VaR_(alpha,t)=mu+sigma_t * z_alpha. This is in case, I have losses, so
> I look at the right tail. So for each day I have a normal density with
> a constant mu but a different sigma corrensponding to the volatility
> model. Let's assume a very simple volatility model, e.g. (empirical)
> standard deviation of the last 10 days and the mu is set to zero. The
> R code could look like (data):
>
> volatility<-0
> quantile<-0
> for(i in 11:length(dat)){
> volatility[i]<-sd(dat[(i-10):(i-1)])
> }
>

Let's clean this up:

library(xts)
# Load data into an xts object called "dat" here.

library(TTR)
vola <- runSD(dat, 10) # volatility is a ttr function name, so not using that

> for(i in 1:length(dat)){
> quantile[i]<-qnorm(0.975,mean=0,sd=volatility[i])
> }

# Similarly, quantile is a function name and not a good idea to override

quan <- qnorm(0.975, mean = 0, sd = vola)

> # the first quantile value is the VaR for the 11th date
>
> #plot the volatility
> plot(c(1:length(volatility)),volatility,type="l")

Can just do
plot(vola) # if vola is an xts object. Also, the c() is superfluous
(and arguably dangerous) there

>
> #add VaR
> lines(quantile,type="l",col="red")

library(PerformanceAnalytics)
chart.BarVaR(dat) # is probably easier.


>
> Now, I want to change the volatility model to a more advanced model
> (EWMA, ARCH, GARCH) and the distribution to a more sophisticated
> distribution (student, generalized hyperbolic distribution). My main
> question is now, how can I combine the volatility model and the
> distribution, since in case e.g. of a Student's-t distribution with
> parameters mu (location), v (df), beta (scale) I cannot just plug the
> sigma in, because the distribution has no sigma?

Be careful here -- it certainly has a standard deviation, just not a
parameter called sigma. Keeping those two ideas distinct is important
here. They only coincide for the normal distribution. (Among the major
ones)

You're also using something other than the classical t-distribution
(as defined by the all-hallowed Wikipedia) if it's a three parameter
distribution.

>
> One solution I already know is, that I take the variance formula of
> the corresponding distribution - in case of a Student's-t distribution
> this would be sigma=beta v/(v-2). I have an estimate for sigma. So for
> each day I do the ML estimation with a modified log-likelihood where I
> insert for the scale parameter: beta=sigma * (v-2)/v and do the
> estimation.
>
> First of all, is this correct?

No -- I believe that the t-distribution has sigma^2 = v / (v-2).

But even with that correction, it's not what I would do.

I would first fit beta, nu, and mu by ML and then estimate sigma from there.

Without checking, I'm not positive that sample standard deviation
gives a particularly good estimator for the df of a t-distribution. It
wouldn't surprise me if it did though.

In that same vein, I'm not sure this process gives an estimate that's
much superior to the rolling empirical standard deviation. Though it
might be useful for forward looking predictions...

Bigger question -- have you looked at TTR::volatility or
PerformanceAnalytics::VaR. There's a lot of useful stuff in there.

I'll try to read through the rest of this later -- about to have
dinner with the family,
Michael

>
> I looked at several papers, but I did not understand, how they did
> this? No matter what volatility model they use, I cannot understand
> the connection of distribution and volatility model. For example,
> consider this paper:
> http://www.math.chalmers.se/~palbin/mattiasviktor.pdf
>
> On page 50 they are showing the hyperbolical distribution with
> different volatility models, how did they do this?
>
> Also, I do not understand table 6.2 on page 49: If they have estimated
> several distributions over the time, they have lots of estimates, but
> they just show one distribution? I mean, where does it come from? The
> 3d picture clearly differnt distributions over time, so they have
> estimated the distribution after 5 days (page 48), but in the table is
> just one specific distribution with specific parameters? And they give
> the volatility models in the rows?
>
> A second famous paper is the Technial Document by JPMorgan:
> RiskMetrics Technical Document - Fourth Edition 1996, December:
>
> http://www.google.de/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CDUQFjAA&url=http%3A%2F%2Fzhiqiang.org%2Fblog%2Fdownload%2FRiskMetrics%2520-%2520Technical%2520Document.pdf&ei=RSJhUd7YJIbktQaQ-YCAAw&usg=AFQjCNGpCXUdLSVHQtYJMl7MccLGQtdkDw&sig2=HBxWDrRTMN7rVqWu-Yp1zQ&bvm=bv.44770516,d.Yms
>
>
> Especially page 238 is interesting: "According to this model, returns
> are generated as follows"
>
> r_t=sigma_t xi_t
>
> sigma^2_t is calculated by EWMA
>
>
> xi is distributed according to the generalized error distribution. So
> they do not assume the returns to follow a certain distribution, but
> they assume the returns condition on the volatility to follow a
> certain distribution, right?
>
> Now my question is, how can one calculate the VaR in this case? On
> page 242 they give a short summary, describing the steps. The third
> step in the most intersting: "Third, we use [...] volatility estimated
> and the [...] probability distributions ([...] generalized error
> distribution) evaluated at the parameter estimates to construct VaR
> forecasts at the 1st and the 99th percentile."
>
> My question is now, how do they do it?
>
> They describe their fitting steps in the steps before, but I am not
> getting the following point:
>
> Do they fit the distribution to the original return series, calculate
> the volatility (?t) and then just calculate the VaR with
> VaR_t=sigma_t*q_alpha where q_alpha is the quantile of the fitted
> distribution
>
> or
>
> do they fit the distribution to the standardized returns
> (xi_t=r_t/sigma_t), calculate the volatility and then just calucate
> the VaR with VaR_t=sigma_t*q_alpha where q_alpha is now the quantile
> of the fitted distribution which was fitted using the standardized
> residuals?
>
> Another question is: Did they set the mean of the return to zero?
>
> My main point is, how to fit a sophisticated distribution to financial
> data using a volatility forecast for each day, which was generated by
> EWMA, ARCH or GARCH and how to calculate the VaR for each day over a
> time horizon and how to implement this. The paper is doing this, but I
> am simply not getting it. I worked on this for days now and I am
> really stuck here.
>
> And one other question: If I am doing the way with the modified
> log-likelihood: This is really challenging in case of a hyperbolic
> distribution, since the variance is not calculated easily anymore? See
> wikipedia.
>
> Thanks a lot for your help.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alexios at 4dscape.com  Wed Apr 10 02:40:10 2013
From: alexios at 4dscape.com (Alexios Ghalanos)
Date: Wed, 10 Apr 2013 01:40:10 +0100
Subject: [R-SIG-Finance] [R] Fitting distributions to financial data
	using volatility model to estimate VaR
In-Reply-To: <CAAmySGPpJ=BqO3O615+v07pBA-3oYwNTv3dDrq83f2JTA7Q-oA@mail.gmail.com>
References: <CAC=XAU2wOGH2+40hQtvD6fTi9eGc5=sVWpOLXH3MMnMQC9U6ug@mail.gmail.com>
	<CAAmySGPpJ=BqO3O615+v07pBA-3oYwNTv3dDrq83f2JTA7Q-oA@mail.gmail.com>
Message-ID: <9AB5C795-8570-4564-971A-2F4B4976CADA@4dscape.com>



Sent from my iPhone

On Apr 10, 2013, at 0:28, "R. Michael Weylandt" <michael.weylandt at gmail.com> wrote:

> Moving to R-SIG-Finance which seems to be the correct mailing list.
> 
> On Sun, Apr 7, 2013 at 8:41 AM, Stat Tistician
> <statisticiangermany at gmail.com> wrote:
>> Ok,
>> I try it again with plain text, with a simple R code example and just
>> sending it to the r list and you move it to sig finance if it is
>> necessary.
>> 
>> I try to be as detailed as possible.
>> 
>> I want to fit a distribution to my financial data using a volatility
>> model to estimate the VaR. So in case of a normal distribution, this
>> would be very easy, I assume the returns to follow a normal
>> distribution and calculate a volatility forecast for each day, so I
>> have sigma_1,sigma_2,...,sigma_n,. I can calculate the VaR via (mu
>> constant, z_alpha quantile of standard normal):
>> VaR_(alpha,t)=mu+sigma_t * z_alpha. This is in case, I have losses, so
>> I look at the right tail. So for each day I have a normal density with
>> a constant mu but a different sigma corrensponding to the volatility
>> model. Let's assume a very simple volatility model, e.g. (empirical)
>> standard deviation of the last 10 days and the mu is set to zero. The
>> R code could look like (data):
>> 
>> volatility<-0
>> quantile<-0
>> for(i in 11:length(dat)){
>> volatility[i]<-sd(dat[(i-10):(i-1)])
>> }
> 
> Let's clean this up:
> 
> library(xts)
> # Load data into an xts object called "dat" here.
> 
> library(TTR)
> vola <- runSD(dat, 10) # volatility is a ttr function name, so not using that
> 
>> for(i in 1:length(dat)){
>> quantile[i]<-qnorm(0.975,mean=0,sd=volatility[i])
>> }
> 
> # Similarly, quantile is a function name and not a good idea to override
> 
> quan <- qnorm(0.975, mean = 0, sd = vola)
> 
>> # the first quantile value is the VaR for the 11th date
>> 
>> #plot the volatility
>> plot(c(1:length(volatility)),volatility,type="l")
> 
> Can just do
> plot(vola) # if vola is an xts object. Also, the c() is superfluous
> (and arguably dangerous) there
> 
>> 
>> #add VaR
>> lines(quantile,type="l",col="red")
> 
> library(PerformanceAnalytics)
> chart.BarVaR(dat) # is probably easier.
> 
> 
>> 
>> Now, I want to change the volatility model to a more advanced model
>> (EWMA, ARCH, GARCH) and the distribution to a more sophisticated
>> distribution (student, generalized hyperbolic distribution). My main
>> question is now, how can I combine the volatility model and the
>> distribution, since in case e.g. of a Student's-t distribution with
>> parameters mu (location), v (df), beta (scale) I cannot just plug the
>> sigma in, because the distribution has no sigma?
> 
> Be careful here -- it certainly has a standard deviation, just not a
> parameter called sigma. Keeping those two ideas distinct is important
> here. They only coincide for the normal distribution. (Among the major
> ones)
> 
> You're also using something other than the classical t-distribution
> (as defined by the all-hallowed Wikipedia) if it's a three parameter
> distribution.
> 
>> 
>> One solution I already know is, that I take the variance formula of
>> the corresponding distribution - in case of a Student's-t distribution
>> this would be sigma=beta v/(v-2). I have an estimate for sigma. So for
>> each day I do the ML estimation with a modified log-likelihood where I
>> insert for the scale parameter: beta=sigma * (v-2)/v and do the
>> estimation.
>> 
>> First of all, is this correct?
> 
> No -- I believe that the t-distribution has sigma^2 = v / (v-2).
> 
> But even with that correction, it's not what I would do.
> 
> I would first fit beta, nu, and mu by ML and then estimate sigma from there.
> 
> Without checking, I'm not positive that sample standard deviation
> gives a particularly good estimator for the df of a t-distribution. It
> wouldn't surprise me if it did though.
> 
> In that same vein, I'm not sure this process gives an estimate that's
> much superior to the rolling empirical standard deviation. Though it
> might be useful for forward looking predictions...
> 
> Bigger question -- have you looked at TTR::volatility or
> PerformanceAnalytics::VaR. There's a lot of useful stuff in there.
> 
> I'll try to read through the rest of this later -- about to have
> dinner with the family,
> Michael
> 
>> 
>> I looked at several papers, but I did not understand, how they did
>> this? No matter what volatility model they use, I cannot understand
>> the connection of distribution and volatility model. For example,
>> consider this paper:
>> http://www.math.chalmers.se/~palbin/mattiasviktor.pdf
>> 
>> On page 50 they are showing the hyperbolical distribution with
>> different volatility models, how did they do this?
>> 
>> Also, I do not understand table 6.2 on page 49: If they have estimated
>> several distributions over the time, they have lots of estimates, but
>> they just show one distribution? I mean, where does it come from? The
>> 3d picture clearly differnt distributions over time, so they have
>> estimated the distribution after 5 days (page 48), but in the table is
>> just one specific distribution with specific parameters? And they give
>> the volatility models in the rows?
>> 
>> A second famous paper is the Technial Document by JPMorgan:
>> RiskMetrics Technical Document - Fourth Edition 1996, December:
>> 
>> http://www.google.de/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CDUQFjAA&url=http%3A%2F%2Fzhiqiang.org%2Fblog%2Fdownload%2FRiskMetrics%2520-%2520Technical%2520Document.pdf&ei=RSJhUd7YJIbktQaQ-YCAAw&usg=AFQjCNGpCXUdLSVHQtYJMl7MccLGQtdkDw&sig2=HBxWDrRTMN7rVqWu-Yp1zQ&bvm=bv.44770516,d.Yms
>> 
>> 
>> Especially page 238 is interesting: "According to this model, returns
>> are generated as follows"
>> 
>> r_t=sigma_t xi_t
>> 
>> sigma^2_t is calculated by EWMA
>> 
>> 
>> xi is distributed according to the generalized error distribution. So
>> they do not assume the returns to follow a certain distribution, but
>> they assume the returns condition on the volatility to follow a
>> certain distribution, right?
>> 
>> Now my question is, how can one calculate the VaR in this case? On
>> page 242 they give a short summary, describing the steps. The third
>> step in the most intersting: "Third, we use [...] volatility estimated
>> and the [...] probability distributions ([...] generalized error
>> distribution) evaluated at the parameter estimates to construct VaR
>> forecasts at the 1st and the 99th percentile."
>> 
>> My question is now, how do they do it?
>> 
>> They describe their fitting steps in the steps before, but I am not
>> getting the following point:
>> 
>> Do they fit the distribution to the original return series, calculate
>> the volatility (?t) and then just calculate the VaR with
>> VaR_t=sigma_t*q_alpha where q_alpha is the quantile of the fitted
>> distribution
>> 
>> or
>> 
>> do they fit the distribution to the standardized returns
>> (xi_t=r_t/sigma_t), calculate the volatility and then just calucate
>> the VaR with VaR_t=sigma_t*q_alpha where q_alpha is now the quantile
>> of the fitted distribution which was fitted using the standardized
>> residuals?
>> 
>> Another question is: Did they set the mean of the return to zero?
>> 
>> My main point is, how to fit a sophisticated distribution to financial
>> data using a volatility forecast for each day, which was generated by
>> EWMA, ARCH or GARCH and how to calculate the VaR for each day over a
>> time horizon and how to implement this. The paper is doing this, but I
>> am simply not getting it. I worked on this for days now and I am
>> really stuck here.
>> 
>> And one other question: If I am doing the way with the modified
>> log-likelihood: This is really challenging in case of a hyperbolic
>> distribution, since the variance is not calculated easily anymore? See
>> wikipedia.
>> 
>> Thanks a lot for your help.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From alexios at 4dscape.com  Wed Apr 10 02:44:53 2013
From: alexios at 4dscape.com (Alexios Ghalanos)
Date: Wed, 10 Apr 2013 01:44:53 +0100
Subject: [R-SIG-Finance] [R] Fitting distributions to financial data
	using volatility model to estimate VaR
In-Reply-To: <CAAmySGPpJ=BqO3O615+v07pBA-3oYwNTv3dDrq83f2JTA7Q-oA@mail.gmail.com>
References: <CAC=XAU2wOGH2+40hQtvD6fTi9eGc5=sVWpOLXH3MMnMQC9U6ug@mail.gmail.com>
	<CAAmySGPpJ=BqO3O615+v07pBA-3oYwNTv3dDrq83f2JTA7Q-oA@mail.gmail.com>
Message-ID: <444ED0E3-4C6B-4FAD-8590-F75369B161DA@4dscape.com>

The rugarch vignette has details on the standardization of these and other distributions. It also has a method called quantile (i.e. VaR) which you can call from any GARCH object (estimated, forecast , simulated).

-Alexios

On Apr 10, 2013, at 0:28, "R. Michael Weylandt" <michael.weylandt at gmail.com> wrote:

> Moving to R-SIG-Finance which seems to be the correct mailing list.
> 
> On Sun, Apr 7, 2013 at 8:41 AM, Stat Tistician
> <statisticiangermany at gmail.com> wrote:
>> Ok,
>> I try it again with plain text, with a simple R code example and just
>> sending it to the r list and you move it to sig finance if it is
>> necessary.
>> 
>> I try to be as detailed as possible.
>> 
>> I want to fit a distribution to my financial data using a volatility
>> model to estimate the VaR. So in case of a normal distribution, this
>> would be very easy, I assume the returns to follow a normal
>> distribution and calculate a volatility forecast for each day, so I
>> have sigma_1,sigma_2,...,sigma_n,. I can calculate the VaR via (mu
>> constant, z_alpha quantile of standard normal):
>> VaR_(alpha,t)=mu+sigma_t * z_alpha. This is in case, I have losses, so
>> I look at the right tail. So for each day I have a normal density with
>> a constant mu but a different sigma corrensponding to the volatility
>> model. Let's assume a very simple volatility model, e.g. (empirical)
>> standard deviation of the last 10 days and the mu is set to zero. The
>> R code could look like (data):
>> 
>> volatility<-0
>> quantile<-0
>> for(i in 11:length(dat)){
>> volatility[i]<-sd(dat[(i-10):(i-1)])
>> }
> 
> Let's clean this up:
> 
> library(xts)
> # Load data into an xts object called "dat" here.
> 
> library(TTR)
> vola <- runSD(dat, 10) # volatility is a ttr function name, so not using that
> 
>> for(i in 1:length(dat)){
>> quantile[i]<-qnorm(0.975,mean=0,sd=volatility[i])
>> }
> 
> # Similarly, quantile is a function name and not a good idea to override
> 
> quan <- qnorm(0.975, mean = 0, sd = vola)
> 
>> # the first quantile value is the VaR for the 11th date
>> 
>> #plot the volatility
>> plot(c(1:length(volatility)),volatility,type="l")
> 
> Can just do
> plot(vola) # if vola is an xts object. Also, the c() is superfluous
> (and arguably dangerous) there
> 
>> 
>> #add VaR
>> lines(quantile,type="l",col="red")
> 
> library(PerformanceAnalytics)
> chart.BarVaR(dat) # is probably easier.
> 
> 
>> 
>> Now, I want to change the volatility model to a more advanced model
>> (EWMA, ARCH, GARCH) and the distribution to a more sophisticated
>> distribution (student, generalized hyperbolic distribution). My main
>> question is now, how can I combine the volatility model and the
>> distribution, since in case e.g. of a Student's-t distribution with
>> parameters mu (location), v (df), beta (scale) I cannot just plug the
>> sigma in, because the distribution has no sigma?
> 
> Be careful here -- it certainly has a standard deviation, just not a
> parameter called sigma. Keeping those two ideas distinct is important
> here. They only coincide for the normal distribution. (Among the major
> ones)
> 
> You're also using something other than the classical t-distribution
> (as defined by the all-hallowed Wikipedia) if it's a three parameter
> distribution.
> 
>> 
>> One solution I already know is, that I take the variance formula of
>> the corresponding distribution - in case of a Student's-t distribution
>> this would be sigma=beta v/(v-2). I have an estimate for sigma. So for
>> each day I do the ML estimation with a modified log-likelihood where I
>> insert for the scale parameter: beta=sigma * (v-2)/v and do the
>> estimation.
>> 
>> First of all, is this correct?
> 
> No -- I believe that the t-distribution has sigma^2 = v / (v-2).
> 
> But even with that correction, it's not what I would do.
> 
> I would first fit beta, nu, and mu by ML and then estimate sigma from there.
> 
> Without checking, I'm not positive that sample standard deviation
> gives a particularly good estimator for the df of a t-distribution. It
> wouldn't surprise me if it did though.
> 
> In that same vein, I'm not sure this process gives an estimate that's
> much superior to the rolling empirical standard deviation. Though it
> might be useful for forward looking predictions...
> 
> Bigger question -- have you looked at TTR::volatility or
> PerformanceAnalytics::VaR. There's a lot of useful stuff in there.
> 
> I'll try to read through the rest of this later -- about to have
> dinner with the family,
> Michael
> 
>> 
>> I looked at several papers, but I did not understand, how they did
>> this? No matter what volatility model they use, I cannot understand
>> the connection of distribution and volatility model. For example,
>> consider this paper:
>> http://www.math.chalmers.se/~palbin/mattiasviktor.pdf
>> 
>> On page 50 they are showing the hyperbolical distribution with
>> different volatility models, how did they do this?
>> 
>> Also, I do not understand table 6.2 on page 49: If they have estimated
>> several distributions over the time, they have lots of estimates, but
>> they just show one distribution? I mean, where does it come from? The
>> 3d picture clearly differnt distributions over time, so they have
>> estimated the distribution after 5 days (page 48), but in the table is
>> just one specific distribution with specific parameters? And they give
>> the volatility models in the rows?
>> 
>> A second famous paper is the Technial Document by JPMorgan:
>> RiskMetrics Technical Document - Fourth Edition 1996, December:
>> 
>> http://www.google.de/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CDUQFjAA&url=http%3A%2F%2Fzhiqiang.org%2Fblog%2Fdownload%2FRiskMetrics%2520-%2520Technical%2520Document.pdf&ei=RSJhUd7YJIbktQaQ-YCAAw&usg=AFQjCNGpCXUdLSVHQtYJMl7MccLGQtdkDw&sig2=HBxWDrRTMN7rVqWu-Yp1zQ&bvm=bv.44770516,d.Yms
>> 
>> 
>> Especially page 238 is interesting: "According to this model, returns
>> are generated as follows"
>> 
>> r_t=sigma_t xi_t
>> 
>> sigma^2_t is calculated by EWMA
>> 
>> 
>> xi is distributed according to the generalized error distribution. So
>> they do not assume the returns to follow a certain distribution, but
>> they assume the returns condition on the volatility to follow a
>> certain distribution, right?
>> 
>> Now my question is, how can one calculate the VaR in this case? On
>> page 242 they give a short summary, describing the steps. The third
>> step in the most intersting: "Third, we use [...] volatility estimated
>> and the [...] probability distributions ([...] generalized error
>> distribution) evaluated at the parameter estimates to construct VaR
>> forecasts at the 1st and the 99th percentile."
>> 
>> My question is now, how do they do it?
>> 
>> They describe their fitting steps in the steps before, but I am not
>> getting the following point:
>> 
>> Do they fit the distribution to the original return series, calculate
>> the volatility (?t) and then just calculate the VaR with
>> VaR_t=sigma_t*q_alpha where q_alpha is the quantile of the fitted
>> distribution
>> 
>> or
>> 
>> do they fit the distribution to the standardized returns
>> (xi_t=r_t/sigma_t), calculate the volatility and then just calucate
>> the VaR with VaR_t=sigma_t*q_alpha where q_alpha is now the quantile
>> of the fitted distribution which was fitted using the standardized
>> residuals?
>> 
>> Another question is: Did they set the mean of the return to zero?
>> 
>> My main point is, how to fit a sophisticated distribution to financial
>> data using a volatility forecast for each day, which was generated by
>> EWMA, ARCH or GARCH and how to calculate the VaR for each day over a
>> time horizon and how to implement this. The paper is doing this, but I
>> am simply not getting it. I worked on this for days now and I am
>> really stuck here.
>> 
>> And one other question: If I am doing the way with the modified
>> log-likelihood: This is really challenging in case of a hyperbolic
>> distribution, since the variance is not calculated easily anymore? See
>> wikipedia.
>> 
>> Thanks a lot for your help.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From bill at easterngrain.com  Wed Apr 10 11:45:45 2013
From: bill at easterngrain.com (wlblount)
Date: Wed, 10 Apr 2013 02:45:45 -0700 (PDT)
Subject: [R-SIG-Finance] Base R question on XTS object
Message-ID: <1365587145641-4663858.post@n4.nabble.com>

before the days of all these great packages, how would one with base R access
only find the following assuming i have an XTS object with normal OHLC price
data for 100 periods.


1 - change in price from yesterday to today.  close[today] -
close[yesterday]

2 -rolling or moving simple ave. of close[last 30 periods]

3 - rolling or moving sd of close[last 30 periods]

i understand that this would all be done with quantmod /ttr etc today but
would just like to stay within the bounds of base R for educational
purposes.  

thanks for your help.  Bill






--
View this message in context: http://r.789695.n4.nabble.com/Base-R-question-on-XTS-object-tp4663858.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From josh.m.ulrich at gmail.com  Wed Apr 10 12:15:57 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 10 Apr 2013 05:15:57 -0500
Subject: [R-SIG-Finance] Base R question on XTS object
In-Reply-To: <1365587145641-4663858.post@n4.nabble.com>
References: <1365587145641-4663858.post@n4.nabble.com>
Message-ID: <CAPPM_gR2Ga-w0qNVSdQdvwk49eR2rpv86q7NAh_Mb7yWP2TrFQ@mail.gmail.com>

On Wed, Apr 10, 2013 at 4:45 AM, wlblount <bill at easterngrain.com> wrote:
> before the days of all these great packages, how would one with base R access
> only find the following assuming i have an XTS object with normal OHLC price
> data for 100 periods.
>
>
> 1 - change in price from yesterday to today.  close[today] -
> close[yesterday]
>
x <- .xts(1:10,1:10)
diff(x)

> 2 -rolling or moving simple ave. of close[last 30 periods]
>
If you have an xts object, that means you have the zoo package loaded,
so you could use rollmean.
rollmean(x,5)

Or you could use cumsum with lag:
(cumsum(x)-lag(cumsum(x),5))/5

Or you could completely roll your own:
(cumsum(x)-c(rep(NA,5-1),0,cumsum(x)[1:(nrow(x)-5)]))/5

> 3 - rolling or moving sd of close[last 30 periods]
>
If I had to use base, I would use the embed function:
ex <- embed(x,5)
sqrt(1/(5-1)*rowSums((ex-rowMeans(ex))^2))

> i understand that this would all be done with quantmod /ttr etc today but
> would just like to stay within the bounds of base R for educational
> purposes.
>
> thanks for your help.  Bill
>

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com

R/Finance 2013: Applied Finance with R  | www.RinFinance.com


From brian at braverock.com  Wed Apr 10 12:17:51 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 10 Apr 2013 05:17:51 -0500
Subject: [R-SIG-Finance] Base R question on XTS object
In-Reply-To: <1365587145641-4663858.post@n4.nabble.com>
References: <1365587145641-4663858.post@n4.nabble.com>
Message-ID: <51653C4F.4030403@braverock.com>

On 04/10/2013 04:45 AM, wlblount wrote:
> before the days of all these great packages, how would one with base R access
> only find the following assuming i have an XTS object with normal OHLC price
> data for 100 periods.
>
>
> 1 - change in price from yesterday to today.  close[today] -
> close[yesterday]

?diff
(part of base)

> 2 -rolling or moving simple ave. of close[last 30 periods]
>
> 3 - rolling or moving sd of close[last 30 periods]

?apply
(in base)

?rollapply
(today)
Rollapply is basically a loop that constructs the windowed index.

> i understand that this would all be done with quantmod /ttr etc today but
> would just like to stay within the bounds of base R for educational
> purposes.

Then read an old book on S.

?ts

the 'ts' class has been part of the S language basically since inception.

Alternatively, all this code is open source.  Look at the code.

Cheers,

Brian


From michael.weylandt at gmail.com  Wed Apr 10 15:56:52 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Wed, 10 Apr 2013 08:56:52 -0500
Subject: [R-SIG-Finance] Base R question on XTS object
In-Reply-To: <51653C4F.4030403@braverock.com>
References: <1365587145641-4663858.post@n4.nabble.com>
	<51653C4F.4030403@braverock.com>
Message-ID: <CAAmySGPahfLA_sKdB33nNDTgYOb+ckwbGn97-ZVo0pHTdpD9ig@mail.gmail.com>

On Wed, Apr 10, 2013 at 5:17 AM, Brian G. Peterson <brian at braverock.com> wrote:
> On 04/10/2013 04:45 AM, wlblount wrote:
>>
>> before the days of all these great packages, how would one with base R
>> access
>> only find the following assuming i have an XTS object with normal OHLC
>> price
>> data for 100 periods.
>>
>>
>> 1 - change in price from yesterday to today.  close[today] -
>> close[yesterday]
>
>
> ?diff
> (part of base)
>
>
>> 2 -rolling or moving simple ave. of close[last 30 periods]
>>
>> 3 - rolling or moving sd of close[last 30 periods]
>
>
> ?apply
> (in base)
>
> ?rollapply
> (today)
> Rollapply is basically a loop that constructs the windowed index.
>
>
>> i understand that this would all be done with quantmod /ttr etc today but
>> would just like to stay within the bounds of base R for educational
>> purposes.
>

'xts' is not part of base R, so if your students can get 'xts' they
should be able to get 'quantmod'. In fact, if you simply have them
install.packages("quantmod") that will get them zoo, TTR, and xts
automatically.

>
> Then read an old book on S.
>
> ?ts
>
> the 'ts' class has been part of the S language basically since inception.
>
> Alternatively, all this code is open source.  Look at the code.
>
> Cheers,
>
> Brian
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.


From oleg.mubarakshin at gmail.com  Thu Apr 11 15:29:34 2013
From: oleg.mubarakshin at gmail.com (Oleg Mubarakshin)
Date: Thu, 11 Apr 2013 17:29:34 +0400
Subject: [R-SIG-Finance] GARCH option valuation
Message-ID: <00ae01ce36b8$9bf9e110$d3eda330$@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130411/1a903741/attachment.pl>

From dominykasgrigonis at gmail.com  Sat Apr 13 08:42:23 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sat, 13 Apr 2013 07:42:23 +0100
Subject: [R-SIG-Finance] euro call by integration
Message-ID: <31AE529DE9C041BEB5DEEC9B6837B355@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130413/a8922bee/attachment.pl>

From es at enricoschumann.net  Sat Apr 13 13:42:30 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Sat, 13 Apr 2013 13:42:30 +0200
Subject: [R-SIG-Finance] euro call by integration
In-Reply-To: <31AE529DE9C041BEB5DEEC9B6837B355@gmail.com> (Dominykas
	Grigonis's message of "Sat, 13 Apr 2013 07:42:23 +0100")
References: <31AE529DE9C041BEB5DEEC9B6837B355@gmail.com>
Message-ID: <87hajaodw9.fsf@enricoschumann.net>

On Sat, 13 Apr 2013, Dominykas Grigonis <dominykasgrigonis at gmail.com> writes:

> Valuing european call option by taking expectation and integrating:
>
> gmb <- function(x,s0=100,r=0.05,vol=0.1){
> s0*exp( (r - vol^2/2) + vol * x)}
>
> fun <- function(x, K=100){
> (gbm(x) - 100) * dnorm(x)}
>
> min = -(log(1) + (0.05-0.1^2/2)) / 0.1
> integrate(fun,min,Inf)
>
> could someone tell me what am I doing wrong? I do not even know if this is R related question or not... 
>
> returns 7.153855, while actual risk neutral price is 6.804958
>
> Thank you in advance.
>
> Kind regards,-- 
> Dominykas Grigonis
>

I did not run your code, but shouldn't you discount the result?



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From kk2250 at optonline.net  Sat Apr 13 18:49:29 2013
From: kk2250 at optonline.net (Kris)
Date: Sat, 13 Apr 2013 12:49:29 -0400
Subject: [R-SIG-Finance] euro call by integration
In-Reply-To: <87hajaodw9.fsf@enricoschumann.net>
References: <31AE529DE9C041BEB5DEEC9B6837B355@gmail.com>
	<87hajaodw9.fsf@enricoschumann.net>
Message-ID: <4DCD6BA0-DF11-4ECC-B266-014359412A16@optonline.net>

You need to integrate payoff x density

[disc factor x pmax(s-k,0) x density ]
below

Also  the std error of the integration unlikely it is going to be that big but worth keeping in mind.



On Apr 13, 2013, at 7:42 AM, Enrico Schumann <es at enricoschumann.net> wrote:

> On Sat, 13 Apr 2013, Dominykas Grigonis <dominykasgrigonis at gmail.com> writes:
> 
>> Valuing european call option by taking expectation and integrating:
>> 
>> gmb <- function(x,s0=100,r=0.05,vol=0.1){
>> s0*exp( (r - vol^2/2) + vol * x)}
>> 
>> fun <- function(x, K=100){
>> (gbm(x) - 100) * dnorm(x)}
>> 
>> min = -(log(1) + (0.05-0.1^2/2)) / 0.1
>> integrate(fun,min,Inf)
>> 
>> could someone tell me what am I doing wrong? I do not even know if this is R related question or not... 
>> 
>> returns 7.153855, while actual risk neutral price is 6.804958
>> 
>> Thank you in advance.
>> 
>> Kind regards,-- 
>> Dominykas Grigonis
> 
> I did not run your code, but shouldn't you discount the result?
> 
> 
> 
> -- 
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From dominykasgrigonis at gmail.com  Sat Apr 13 19:44:06 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sat, 13 Apr 2013 18:44:06 +0100
Subject: [R-SIG-Finance] euro call by integration
In-Reply-To: <87hajaodw9.fsf@enricoschumann.net>
References: <31AE529DE9C041BEB5DEEC9B6837B355@gmail.com>
	<87hajaodw9.fsf@enricoschumann.net>
Message-ID: <0AD8389F876748C5900680298067A0AB@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130413/e494e403/attachment.pl>

From nikos.rachmanis at gmail.com  Sat Apr 13 20:34:52 2013
From: nikos.rachmanis at gmail.com (Nikos Rachmanis)
Date: Sat, 13 Apr 2013 14:34:52 -0400
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 107, Issue 11
In-Reply-To: <mailman.1.1365847201.23041.r-sig-finance@r-project.org>
References: <mailman.1.1365847201.23041.r-sig-finance@r-project.org>
Message-ID: <5169A54C.7020106@gmail.com>

Assuming t=1, you forgot to discount

updating the function

fun <- function(x, K=100)
   {
     (gbm(x) - 100) * dnorm(x) * exp(-0.05)
   }

should give you the result you want.

Nikos

On 4/13/2013 6:00 AM, r-sig-finance-request at r-project.org wrote:
> Today's Topics:
>
>     1. euro call by integration (Dominykas Grigonis)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 13 Apr 2013 07:42:23 +0100
> From: Dominykas Grigonis <dominykasgrigonis at gmail.com>
> To: r-sig-finance <r-sig-finance at r-project.org>
> Subject: [R-SIG-Finance] euro call by integration
> Message-ID: <31AE529DE9C041BEB5DEEC9B6837B355 at gmail.com>
> Content-Type: text/plain
>
> Valuing european call option by taking expectation and integrating:
>
> gmb <- function(x,s0=100,r=0.05,vol=0.1){
> s0*exp( (r - vol^2/2) + vol * x)}
>
> fun <- function(x, K=100){
> (gbm(x) - 100) * dnorm(x)}
>
> min = -(log(1) + (0.05-0.1^2/2)) / 0.1
> integrate(fun,min,Inf)
>
> could someone tell me what am I doing wrong? I do not even know if this is R related question or not...
>
> returns 7.153855, while actual risk neutral price is 6.804958
>
> Thank you in advance.
>
> Kind regards,--
> Dominykas Grigonis
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> _______________________________________________
> R-SIG-Finance mailing list
> R-SIG-Finance at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>
>
> End of R-SIG-Finance Digest, Vol 107, Issue 11
> **********************************************


From dominykasgrigonis at gmail.com  Sat Apr 13 20:47:40 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sat, 13 Apr 2013 19:47:40 +0100
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 107, Issue 11
In-Reply-To: <5169A54C.7020106@gmail.com>
References: <mailman.1.1365847201.23041.r-sig-finance@r-project.org>
	<5169A54C.7020106@gmail.com>
Message-ID: <305278AB142F4E49866AFFBA9C9C1488@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130413/0fe4fd15/attachment.pl>

From roschm at ymail.com  Sat Apr 13 22:51:06 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Sat, 13 Apr 2013 13:51:06 -0700 (PDT)
Subject: [R-SIG-Finance] quantstrat add.indicator change (mktdata) to
	(mktdata)[, 1]
Message-ID: <1365886266943-4664153.post@n4.nabble.com>

Hi All,

As the world marches forward, my newbie quantstrat examples have become
broken.  (How dare they change anything!)  I was unaware, so thanks to Scott
Schmidt for pointing out that functions of mktdata in the add.indicator
command now have a column specified.  For example Cl(mktdata) becomes
Cl(mktdata)[,1].  Also we should update to the latest versions like I
finally did.

Best regards,

Rob




--
View this message in context: http://r.789695.n4.nabble.com/quantstrat-add-indicator-change-mktdata-to-mktdata-1-tp4664153.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Sat Apr 13 23:20:03 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 13 Apr 2013 16:20:03 -0500
Subject: [R-SIG-Finance] quantstrat add.indicator change (mktdata) to
 (mktdata)[, 1]
In-Reply-To: <1365886266943-4664153.post@n4.nabble.com>
References: <1365886266943-4664153.post@n4.nabble.com>
Message-ID: <5169CC03.8060901@braverock.com>

On 04/13/2013 03:51 PM, Rob Schmidt wrote:
> As the world marches forward, my newbie quantstrat examples have become
> broken.  (How dare they change anything!)  I was unaware, so thanks to Scott
> Schmidt for pointing out that functions of mktdata in the add.indicator
> command now have a column specified.  For example Cl(mktdata) becomes
> Cl(mktdata)[,1].  Also we should update to the latest versions like I
> finally did.

It would be more accurate to say that moving average functions in TTR 
now paste the MA type and periodicity onto the name of the data they are 
passed.

So, if you have and xts OHLC object called x, with standard 
getSymbols-style naming, it would have a column called x.Close.

If you extract that column with Cl(x) as input to SMA(Cl(x),20), you'll 
get back a column called x.Close.SMA.20.  The quantstrat indicators code 
will cbind that to mktdata

If you now call Cl(mktdata), you'll get two columns back: x.Close and 
x.Close.SMA.20.

So now you need to specify which one you want in later operations.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From michael.weylandt at gmail.com  Sun Apr 14 03:20:23 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Sat, 13 Apr 2013 21:20:23 -0400
Subject: [R-SIG-Finance] [R] help on smoothing volatility surface..
In-Reply-To: <CAE8ybh8eJPakVg-Y-XUYR4Wprzr+ZcVFuq+nyoXOhBb_12nZtQ@mail.gmail.com>
References: <CAE8ybh8eJPakVg-Y-XUYR4Wprzr+ZcVFuq+nyoXOhBb_12nZtQ@mail.gmail.com>
Message-ID: <E7489B89-324D-4EC9-8712-0FAF2A66D509@gmail.com>

Moving to the relevant list. 

MW

On Apr 13, 2013, at 6:14 PM, C <cdcaveman at gmail.com> wrote:

> This script below pulls yahoo data via a function in quantmod, then
> massages the data around to forumalate a 3D graph with RGL library,
> attached is a ggplot to show the data i'm trying to create a surface with
> in separate line geoms . the issue is that the 3D graph looks very ugly and
> cut up because of the limited quantities of points on the front month
> expirations.. can anyone tell me whats going on here , what i can do to fix
> this.. do i need to smooth each expiration's line then interpolate.... ??
> 
> 
> 
> 
> library(RQuantLib)
> library(quantmod)
> library(rgl)
> library(akima)
> library(ggplot2)
> library(plyr)
> 
> GetIV <- function(type, value,
>                  underlying, strike,dividendYield, riskFreeRate, maturity,
> volatility,
>                  timeSteps=150, gridPoints=151) {
> 
>    AmericanOptionImpliedVolatility(type, value,
>                                    underlying, strike,dividendYield,
> riskFreeRate, maturity, volatility,
>                                    timeSteps=150,
> gridPoints=151)$impliedVol
> }
> 
> 
> GetDelta <- function(type, underlying, strike,
>                     dividendYield, riskFreeRate, maturity, volatility,
>                     timeSteps=150, gridPoints=149, engine="CrankNicolson")
> {
> 
>    AmericanOption(type,underlying, strike, dividendYield, riskFreeRate,
> maturity, volatility,
>                   timeSteps=150, gridPoints=149,
> engine="CrankNicolson")$delta
> }
> # set what symbol you want vol surface for
> underlying <- 'GOOG'
> # set what your volatility forcast or assumption is
> volforcast <- .25
> # Get symbols current price
> underlying.price <- getQuote(underlying,what=yahooQF("Last Trade (Price
> Only)"))$Last
> 
> OC <- getOptionChain(underlying, NULL)
> #check data
> head(OC)
> lputs <- lapply(OC, FUN = function(x) x$puts[grep("[A-Z]\\d{6}[CP]\\d{8}$",
> rownames(x$puts)), ])
> head(lputs) #check for NA values, yahoo returns all NA values sometimes
> puts <- do.call('rbind', lputs )
> #check data
> head(puts,5)
> 
> symbols <- as.vector(unlist(lapply(lputs, rownames)))
> expiries <- unlist(lapply(symbols, FUN = function(x) regmatches(x=x,
> regexpr('[0-9]{6}', x) )))
> puts$maturity <- as.numeric((as.Date(expiries, "%y%m%d") - Sys.Date())/365)
> 
> puts$IV <- mapply(GetIV, value = puts$Ask, strike = puts$Strike, maturity =
> puts$maturity,
>                  MoreArgs= list(type='put', underlying= underlying.price,
>                                 dividendYield=0, riskFreeRate = 0.01,
>                                 volatility = volforcast), SIMPLIFY=TRUE)
> 
> puts$delta <- mapply(GetDelta, strike =  puts$Strike, volatility = puts$IV,
>                     maturity = puts$maturity, MoreArgs= list(type='put',
> 
> underlying=underlying.price, dividendYield=0,
>                                                              riskFreeRate
> = 0.01 ), SIMPLIFY=TRUE)
> 
> # subset out itm puts
> puts <- subset(puts, delta < -.09 & delta > -.5 )
> 
> expiries.formated <- format(as.Date(levels(factor(expiries)), format =
> '%y%m%d'), "%B %d, %Y")
> 
> fractionofyear.levels <- levels(factor(puts$maturity))
> 
> xyz <- with(puts, interp(x=maturity, y=delta*100, z=IV*100,
>                         xo=sort(unique(maturity)), extrap=FALSE ))
> 
> with(xyz, persp3d(x,y,z, col=heat.colors(length(z))[rank(z)],
> xlab='maturity',
>                  ylab='delta', zlab='IV', main='IV Surface'))
> 
> putsplot <- ggplot(puts, aes(delta, IV, group = factor(maturity), color =
> factor(maturity))) +
>    labs(x = "Delta", y = "Implied Volatilty", title="Volatility Smile",
> color = "GooG \nExpiration") +
>    scale_colour_discrete( breaks=c(fractionofyear.levels),
>                           labels=c(expiries.formated)) +
>    geom_line() +
>    geom_point()
> 
> putsplot
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ivan.popivanov at gmail.com  Sun Apr 14 06:33:54 2013
From: ivan.popivanov at gmail.com (Ivan Popivanov)
Date: Sun, 14 Apr 2013 00:33:54 -0400
Subject: [R-SIG-Finance] quantstrat: A bug in rules.R for stoplimits?
Message-ID: <CAK7-yAi6LiSuL0cJi+6uAk84MMDeMwFUqTyfavXNbhWU5eOFFw@mail.gmail.com>

The code which decides the next index for stoplimit orders looks like:

cross<-sigThreshold(label='tmpstop',column=col,threshold=tmpprice,relationship=relationship)
if(any(cross[timespan])){
                        # find first index that would cross after this index
                        newidx <- curIndex + which(cross[timespan])[1] - 1
                        # insert that into dindex
                        assign.dindex(c(get.dindex(),newidx))
                    }

To me, what the above says is: if we have a cross, set the new index to the
first cross. However, the first cross could be the timestamp corresponding
to the current index (easiest to repro by hacking the Low price for a long
stoplimit). If that's the case, newidx is set to the current index, in
other words, the stoplimit is not respected until the next date we decide
to stop (from the vectorization of the math) for another reason.

In the attached file, I have provided a possible fix and the original file,
for easy diff.

Regards,
Ivan

My fix:


cross<-sigThreshold(label='tmpstop',column=col,threshold=tmpprice,relationship=relationship)
                    if(any(cross[timespan])) {
                        # find first index that would cross after this index
                        crosses = which(cross[timespan])
                        if(crosses[1] != 1) {
                           # The first cross is not on the current index
                           newidx <- curIndex + crosses[1] - 1
                        } else if(length(crosses) > 1) {
                           # The first cross is on the current index, but
there is another index
                           newidx <- curIndex + crosses[2] - 1
                        } else {
                           # Only one cross and it's on the current index
                           newidx <- NA
                        }
                        if(!is.na(newidx)) {
                           # insert that into dindex
                           assign.dindex(c(get.dindex(),newidx))
                        }
                    }
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130414/1902a195/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fix.tar.gz
Type: application/x-gzip
Size: 20164 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130414/1902a195/attachment.gz>

From josh.m.ulrich at gmail.com  Sun Apr 14 11:47:34 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 14 Apr 2013 04:47:34 -0500
Subject: [R-SIG-Finance] quantstrat: A bug in rules.R for stoplimits?
In-Reply-To: <CAK7-yAi6LiSuL0cJi+6uAk84MMDeMwFUqTyfavXNbhWU5eOFFw@mail.gmail.com>
References: <CAK7-yAi6LiSuL0cJi+6uAk84MMDeMwFUqTyfavXNbhWU5eOFFw@mail.gmail.com>
Message-ID: <CAPPM_gTuqq3YvNgna7DK1GaYcWG2h=h3yiW87Sx4VninQ6HT7Q@mail.gmail.com>

Hi Ivan,

This was fixed in r1430 a few days ago.

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com

R/Finance 2013: Applied Finance with R  | www.RinFinance.com


On Sat, Apr 13, 2013 at 11:33 PM, Ivan Popivanov
<ivan.popivanov at gmail.com> wrote:
> The code which decides the next index for stoplimit orders looks like:
>
> cross<-sigThreshold(label='tmpstop',column=col,threshold=tmpprice,relationship=relationship)
> if(any(cross[timespan])){
>                         # find first index that would cross after this index
>                         newidx <- curIndex + which(cross[timespan])[1] - 1
>                         # insert that into dindex
>                         assign.dindex(c(get.dindex(),newidx))
>                     }
>
> To me, what the above says is: if we have a cross, set the new index to the
> first cross. However, the first cross could be the timestamp corresponding
> to the current index (easiest to repro by hacking the Low price for a long
> stoplimit). If that's the case, newidx is set to the current index, in other
> words, the stoplimit is not respected until the next date we decide to stop
> (from the vectorization of the math) for another reason.
>
> In the attached file, I have provided a possible fix and the original file,
> for easy diff.
>
> Regards,
> Ivan
>
> My fix:
>
>
> cross<-sigThreshold(label='tmpstop',column=col,threshold=tmpprice,relationship=relationship)
>                     if(any(cross[timespan])) {
>                         # find first index that would cross after this index
>                         crosses = which(cross[timespan])
>                         if(crosses[1] != 1) {
>                            # The first cross is not on the current index
>                            newidx <- curIndex + crosses[1] - 1
>                         } else if(length(crosses) > 1) {
>                            # The first cross is on the current index, but
> there is another index
>                            newidx <- curIndex + crosses[2] - 1
>                         } else {
>                            # Only one cross and it's on the current index
>                            newidx <- NA
>                         }
>                         if(!is.na(newidx)) {
>                            # insert that into dindex
>                            assign.dindex(c(get.dindex(),newidx))
>                         }
>                     }
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.


From ivan.popivanov at gmail.com  Sun Apr 14 19:13:23 2013
From: ivan.popivanov at gmail.com (Ivan Popivanov)
Date: Sun, 14 Apr 2013 13:13:23 -0400
Subject: [R-SIG-Finance] quantstrat: NA for "Order.Prefer" for a
	stoptrailing order
Message-ID: <CAK7-yAh80mcbAgSmq+yARcKXCi3a7az3myQ4hmcgEG70u4WE_w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130414/65a87c3d/attachment.pl>

From josh.m.ulrich at gmail.com  Sun Apr 14 21:53:16 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 14 Apr 2013 14:53:16 -0500
Subject: [R-SIG-Finance] quantstrat: NA for "Order.Prefer" for a
 stoptrailing order
In-Reply-To: <CAK7-yAh80mcbAgSmq+yARcKXCi3a7az3myQ4hmcgEG70u4WE_w@mail.gmail.com>
References: <CAK7-yAh80mcbAgSmq+yARcKXCi3a7az3myQ4hmcgEG70u4WE_w@mail.gmail.com>
Message-ID: <CAPPM_gSYuSA8DRu1twtZSZNn2Eh_kXzWEv7tkCdOopDPoM9pjA@mail.gmail.com>

Ivan,

I've been working on a similar issue for the past few days.  Can you
please provide a reproducible example that causes problems for you?

Thanks,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com

R/Finance 2013: Applied Finance with R  | www.RinFinance.com


On Sun, Apr 14, 2013 at 12:13 PM, Ivan Popivanov
<ivan.popivanov at gmail.com> wrote:
> Not 100% sure about the root cause (could be also some bad logic in my
> script), but I managed to track it as far as addOrder - to me the following
> code seems very dubious at least:
>
>     for (i in 1:length(price)) {
>         if(is.null(prefer[i])) prefer[i] = ''
>
> Notice that the function has a parameter *prefer* with a default value of
> NULL. The first time this loop is entered, is.null(prefer[1]) is TRUE,
> thus, prefer[i] is set to ''. However, subsequent values will be NA, thus,
> the if is not entered and prefer[2] will be left as NA.
>
> Probably better to initialize prefer prior to the loop?
>
> if(is.null(prefer)) prefer = rep(NULL, length(price))
>
> Thanks,
> Ivan
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From ivan.popivanov at gmail.com  Sun Apr 14 23:54:59 2013
From: ivan.popivanov at gmail.com (Ivan Popivanov)
Date: Sun, 14 Apr 2013 17:54:59 -0400
Subject: [R-SIG-Finance] quantstrat: NA for "Order.Prefer" for a
 stoptrailing order
In-Reply-To: <CAPPM_gSYuSA8DRu1twtZSZNn2Eh_kXzWEv7tkCdOopDPoM9pjA@mail.gmail.com>
References: <CAK7-yAh80mcbAgSmq+yARcKXCi3a7az3myQ4hmcgEG70u4WE_w@mail.gmail.com>
	<CAPPM_gSYuSA8DRu1twtZSZNn2Eh_kXzWEv7tkCdOopDPoM9pjA@mail.gmail.com>
Message-ID: <CAK7-yAgBmU9-GoHgo+Q6oLjx2zL0m=qGN2bw99R46w7h6tzQtw@mail.gmail.com>

See the attachment. The script needs to be sourced from the directory, the
SPY.bin is the data file. Seems to happen only for short orders.

Regards,
Ivan


On Sun, Apr 14, 2013 at 3:53 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>wrote:

> Ivan,
>
> I've been working on a similar issue for the past few days.  Can you
> please provide a reproducible example that causes problems for you?
>
> Thanks,
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
>
> R/Finance 2013: Applied Finance with R  | www.RinFinance.com
>
>
> On Sun, Apr 14, 2013 at 12:13 PM, Ivan Popivanov
> <ivan.popivanov at gmail.com> wrote:
> > Not 100% sure about the root cause (could be also some bad logic in my
> > script), but I managed to track it as far as addOrder - to me the
> following
> > code seems very dubious at least:
> >
> >     for (i in 1:length(price)) {
> >         if(is.null(prefer[i])) prefer[i] = ''
> >
> > Notice that the function has a parameter *prefer* with a default value of
> > NULL. The first time this loop is entered, is.null(prefer[1]) is TRUE,
> > thus, prefer[i] is set to ''. However, subsequent values will be NA,
> thus,
> > the if is not entered and prefer[2] will be left as NA.
> >
> > Probably better to initialize prefer prior to the loop?
> >
> > if(is.null(prefer)) prefer = rep(NULL, length(price))
> >
> > Thanks,
> > Ivan
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130414/c1fc16d5/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: repro.tar.gz
Type: application/x-gzip
Size: 106491 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130414/c1fc16d5/attachment.gz>

From ngm at uni.edu  Mon Apr 15 01:05:30 2013
From: ngm at uni.edu (ngm)
Date: Sun, 14 Apr 2013 16:05:30 -0700 (PDT)
Subject: [R-SIG-Finance] Stock Return (Fitting a Copula)
Message-ID: <1365980730267-4664209.post@n4.nabble.com>

Hi ,

I need help figuring out how to fit a copula to my stock return data. I
can't seem to determine a single copula that would fit my data even though I
have proved that my data are not independent. I think my problem is trying
to figure out the param I need to set for my copula to fit the data. Anybody
has any idea how to do so? Is there a function I need to run before to my
data before I run the gofCopula? returns.csv
<http://r.789695.n4.nabble.com/file/n4664209/returns.csv>   Thank you!

system.time(srGof.t.mult <- gofCopula(claytonCopula(param=*????*, dim = 3),
test1, method = "mpl",simulation="mult"))

I have uploaded my data to this post. Any help would be appreciated.



--
View this message in context: http://r.789695.n4.nabble.com/Stock-Return-Fitting-a-Copula-tp4664209.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From ngm at uni.edu  Mon Apr 15 02:03:16 2013
From: ngm at uni.edu (ngm)
Date: Sun, 14 Apr 2013 17:03:16 -0700 (PDT)
Subject: [R-SIG-Finance] Fitting and testing copula-functions
In-Reply-To: <f5dfae7c0907260154o5ac75121hf0b2a1dc04336093@mail.gmail.com>
References: <f5dfae7c0907260154o5ac75121hf0b2a1dc04336093@mail.gmail.com>
Message-ID: <1365984196810-4664210.post@n4.nabble.com>

Hi 

Have you managed to figure out how to fit a copula to the data? I am having
the same problem and wondering if you managed to figure out anything. Thank
you!

Lester.



--
View this message in context: http://r.789695.n4.nabble.com/Fitting-and-testing-copula-functions-tp929814p4664210.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brad.saterfiel at gmail.com  Mon Apr 15 11:22:42 2013
From: brad.saterfiel at gmail.com (JohnnyPaper)
Date: Mon, 15 Apr 2013 02:22:42 -0700 (PDT)
Subject: [R-SIG-Finance] Fitting and testing copula-functions
In-Reply-To: <1365984196810-4664210.post@n4.nabble.com>
References: <f5dfae7c0907260154o5ac75121hf0b2a1dc04336093@mail.gmail.com>
	<1365984196810-4664210.post@n4.nabble.com>
Message-ID: <1366017762896-4664233.post@n4.nabble.com>

Hi,

There are some rather quick workarounds to answer your problems I can assure
you. Here are a couple of steps, but I warn you...you had better know what
type of game you are playing with copulas and their limitations. By the way
if step 1 or 2 sounds strange to you, stop then and go back to learning more
before you mess with this stuff. 

1) Pick a time frame and distribution...a la GEV family or maybe Laplace or
Cauchy or whatever floats your boat. 

2) Normalize that on [0,1] for the unit hypercube. (Some data I just looked
at from someone was returns only for SP, Goog and BRKb or something. Those
were definitely not CDFs.)  

3) Use the package CDVine for hours weeks and months of enjoyment. (Save
yourself a ton of time and read the documentation about 10 times so you are
thoroughly aware of what is available to you in the package.) It should
contain everything you fellas are looking for...including some very high
level stuff, hence the "Vine", should you really wanna mash it up. 

4) Don't forget to take the inverse of the CDF later. (Quantile Function)
And voila.

If you are just looking to fit a copula though, steps 1-3 should do you
fine.  You just need to think about storing the parameters for your fitted
distributions dynamically if you wanna run a very large universe through a
backtest or say get some hypothetical pairs or a full portfolio to trade the
next day. Possibly need to look at packages doParallel and doSNOW for use of
%dopar% if you plan on running super granular data. Ok ok ok...that's enough
and if you're truly ready for this stuff (Copulas) in my opinion, then that
should have been all the help you needed. Good luck fellas. 

*It is also very late so I hope there aren't any dumb mistakes in that
explanation off the top of my head. I haven't messed with copulas & R in
several months. 

Best,

Brad




--
View this message in context: http://r.789695.n4.nabble.com/Fitting-and-testing-copula-functions-tp929814p4664233.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From markknecht at gmail.com  Mon Apr 15 20:43:43 2013
From: markknecht at gmail.com (Mark Knecht)
Date: Mon, 15 Apr 2013 11:43:43 -0700
Subject: [R-SIG-Finance] email a data.frame as part of a small example?
Message-ID: <CAK2H+edtnQDk=wXMqoG7rbpG8Zb7JQUAG_BHrf_QV_0gvtOBqA@mail.gmail.com>

Hi,
   Sorry but I've drawn a blank. What's the proper way to preprocess a
small data.frame into a structure to use as data in example code sent
to this list when I ask a question? I'm looking at the two R books I
have and haven't found it but I know I've done it in the past.

Thanks in advance.
Mark


From zach.mayer at gmail.com  Mon Apr 15 20:55:40 2013
From: zach.mayer at gmail.com (Zachary Mayer)
Date: Mon, 15 Apr 2013 14:55:40 -0400
Subject: [R-SIG-Finance] email a data.frame as part of a small example?
In-Reply-To: <CAK2H+edtnQDk=wXMqoG7rbpG8Zb7JQUAG_BHrf_QV_0gvtOBqA@mail.gmail.com>
References: <CAK2H+edtnQDk=wXMqoG7rbpG8Zb7JQUAG_BHrf_QV_0gvtOBqA@mail.gmail.com>
Message-ID: <-779079550114827300@unknownmsgid>

Try dput()

Sent from my iPhone

On Apr 15, 2013, at 2:45 PM, Mark Knecht <markknecht at gmail.com> wrote:

> Hi,
>   Sorry but I've drawn a blank. What's the proper way to preprocess a
> small data.frame into a structure to use as data in example code sent
> to this list when I ask a question? I'm looking at the two R books I
> have and haven't found it but I know I've done it in the past.
>
> Thanks in advance.
> Mark
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From markknecht at gmail.com  Mon Apr 15 20:56:24 2013
From: markknecht at gmail.com (Mark Knecht)
Date: Mon, 15 Apr 2013 11:56:24 -0700
Subject: [R-SIG-Finance] email a data.frame as part of a small example?
In-Reply-To: <-779079550114827300@unknownmsgid>
References: <CAK2H+edtnQDk=wXMqoG7rbpG8Zb7JQUAG_BHrf_QV_0gvtOBqA@mail.gmail.com>
	<-779079550114827300@unknownmsgid>
Message-ID: <CAK2H+efy2eOTxVf_Wb+1J56QzQHVoLukGL29Z5i-j0CEG_cuYg@mail.gmail.com>

Darn, that's it. Thanks Zachary!

Cheers,
Mark

On Mon, Apr 15, 2013 at 11:55 AM, Zachary Mayer <zach.mayer at gmail.com> wrote:
> Try dput()
>
> Sent from my iPhone
>
> On Apr 15, 2013, at 2:45 PM, Mark Knecht <markknecht at gmail.com> wrote:
>
>> Hi,
>>   Sorry but I've drawn a blank. What's the proper way to preprocess a
>> small data.frame into a structure to use as data in example code sent
>> to this list when I ask a question? I'm looking at the two R books I
>> have and haven't found it but I know I've done it in the past.
>>
>> Thanks in advance.
>> Mark
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.


From David.Reiner at xrtrading.com  Mon Apr 15 22:58:39 2013
From: David.Reiner at xrtrading.com (David Reiner)
Date: Mon, 15 Apr 2013 15:58:39 -0500
Subject: [R-SIG-Finance] Rbbg in R 3.0.0
Message-ID: <9DE405308A6AA24AA794B76282C6C00F4A3AAC12F9@HQ-POST1>

I tried Rbbg in R 3.0.0, but I'm getting a Java-related error I think.
Hints?

> install.packages("Rbbg", repos="http://r.findata.org/", dependencies = TRUE)
trying URL 'http://r.findata.org/bin/windows/contrib/3.0/Rbbg_0.4-155.zip'
Content type 'application/zip' length 41069 bytes (40 Kb)
opened URL
downloaded 40 Kb

package 'Rbbg' successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\davidr\AppData\Local\Temp\RtmpAvhuq1\downloaded_packages
> require(Rbbg)
Loading required package: Rbbg
Loading required package: rJava
> conn <- blpConnect()
R version 3.0.0 (2013-04-03)
rJava Version 0.9-4
Rbbg Version 0.4-155
Java environment initialized successfully.
Looking for most recent blpapi3.jar file...
Adding C:\blp\API\APIv3\JavaAPI\v3.4.3.2\lib\blpapi3.jar to Java classpath
Bloomberg API Version 3.4.3.2
> ticker <- "GOOG US Equity"
> start <- "2013-04-15 13:30:00" # These are UTC, right?
> end <- "2013-04-15 14:00:00"
> interval <- "1"
> bar(conn, ticker, "BID", start, end, interval)
Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
  java.lang.ArrayIndexOutOfBoundsException: 6
> sessionInfo()
R version 3.0.0 (2013-04-03)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] Rbbg_0.4-155 rJava_0.9-4

loaded via a namespace (and not attached):
[1] tools_3.0.0

Any help is much appreciated!
David L. Reiner
XR Trading LLC



This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.

THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON'S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.


From markknecht at gmail.com  Tue Apr 16 00:42:32 2013
From: markknecht at gmail.com (Mark Knecht)
Date: Mon, 15 Apr 2013 15:42:32 -0700
Subject: [R-SIG-Finance] Trying to get earth models to (better) match those
	from other tools
Message-ID: <CAK2H+ecO9QVa-piPwp3LPhL7t0q5RAAfPaawT_+6Wm_DTdWWeQ@mail.gmail.com>

Hi,
   Does anyone have experience comparing the MARS models created in R
using the earth package to those created in commercially available
tools? I'm wondering about settings I might need to tweak to more
closely match between the two.

   I'm currently attempting to build a model of a signal used to trade
GS using a neural network program. The target (last column in the
data) is an 'ideal' signal for the neural network that produces
excellent returns. It's mathematically generated after the fact and
cannot be used for real trading. The inputs are standard indicators.
My models in both R & Salford are using the same data set, 100%
in-sample for now, and while the models are sometimes similar they
don't ever match. There's code below that you can run yourself if
you'd like to duplicate at the R side of what I'm posting here. Here
are two very simple models exhibiting a typical difference:

>From R:
TargetData =
  1.4277855
  +  2.7607779 * pmax(0,      ATR.30. -        5.003)
  -  1.5817456 * pmax(0,        5.003 -      ATR.30.)
  + 0.47233563 * pmax(0, SDev..C..10. -     4.536255)
  -  1.0922087 * pmax(0, SDev..C..30. -     6.659525)

>From Salford SPM:
 BF1 = max(0, SDEV__C__30_ - 7.7014);
 BF3 = max(0, PDIFFEMA__C__100_ + 0.124316);
 BF5 = max(0, 4.97535 - SDEV__C__20_);
 BF7 = max(0, 0.005878 - PDIFFEMA__C__2_);

 Y = 0.0886771 - 1.13545 * BF1 + 10.4891 * BF3 + 0.677875 * BF5
               + 16.2416 * BF7

   As you can see the two environments chose very different indicators
and came up with very different results. So far in most (approx. 75%)
of the cases I've run I find the Salford model has lower residuals at
least compared with my rather simple code of the type below, but I bet
there's better settings for the earth package than what I'm doing
here.

   In the end I don't think it's critically important that R exactly
equals what Salford's tool puts out, but I'd like to better understand
at what's driving the differences if I can. I hope someone with more
experience in this area might share some pointers.

Thanks in advance,
Mark



library(earth)

Test_Data = structure(list(ATR.200. = c(5.3593, 5.38645, 5.38465, 5.39745,
5.4037, 5.41655, 5.3925, 5.40095, 5.4075, 5.41, 5.43405, 5.4421,
5.4421, 5.4615, 5.47085, 5.4571, 5.4549, 5.4062, 5.4084, 5.4446,
5.45275, 5.459, 5.41465, 5.3884, 5.3553, 5.3612, 5.35245, 5.3256,
5.30565, 5.2844), ATR.30. = c(4.728667, 4.709667, 4.666333, 4.635,
4.672667, 4.620333, 4.497667, 4.570667, 4.566333, 4.654, 4.808,
4.853667, 4.957667, 5.057667, 5.071667, 4.973667, 5.003, 4.899,
5.063667, 5.453, 5.463333, 5.525667, 5.536333, 5.624, 5.765667,
5.794667, 5.773667, 5.742333, 5.805, 5.807), ATR.50. = c(5.5326,
5.5312, 5.4926, 5.465, 5.4488, 5.4586, 5.4524, 5.496, 5.4372,
5.3484, 5.4258, 5.4182, 5.3544, 5.2906, 5.2404, 5.148, 5.1268,
4.977, 5.037, 5.2382, 5.2758, 5.2658, 5.2636, 5.225, 5.2814,
5.2574, 5.155, 5.1488, 5.1864, 5.194), PDiffEMA..C..10. = c(0.054091,
0.034275, 0.009988, 0.064954, 0.090363, 0.040484, 0.047534, -0.021532,
-0.024618, -0.02721, 0.009576, 0.013524, 0.045701, 0.08149, 0.091634,
0.074339, 0.103592, 0.081728, 0.011472, 0.131327, 0.08382, 0.030076,
0.012852, -0.002183, 0.027274, 0.037493, 0.017167, 0.023488,
0.019136, -0.003297), PDiffEMA..C..100. = c(-0.099275, -0.10749,
-0.124316, -0.061964, -0.019515, -0.054829, -0.037535, -0.103405,
-0.109136, -0.114795, -0.077913, -0.0702, -0.030246, 0.021007,
0.050924, 0.050572, 0.102323, 0.098286, 0.028976, 0.181165, 0.149558,
0.097734, 0.080706, 0.062797, 0.09865, 0.116274, 0.096454, 0.106667,
0.104335, 0.077546), PDiffEMA..C..15. = c(0.040617, 0.025189,
0.002923, 0.063291, 0.09577, 0.047913, 0.057517, -0.014829, -0.020429,
-0.025383, 0.011905, 0.01652, 0.051724, 0.093053, 0.108744, 0.094524,
0.129525, 0.10992, 0.035246, 0.164669, 0.117805, 0.060309, 0.039645,
0.020689, 0.04972, 0.059919, 0.037539, 0.043015, 0.037437, 0.012106
), PDiffEMA..C..150. = c(-0.093172, -0.10216, -0.11988, -0.057662,
-0.015205, -0.051074, -0.034004, -0.100777, -0.107207, -0.113581,
-0.077145, -0.069872, -0.030105, 0.021298, 0.051577, 0.051572,
0.104112, 0.100766, 0.031468, 0.185417, 0.154788, 0.103376, 0.086768,
0.069123, 0.105824, 0.124328, 0.104963, 0.115925, 0.114214, 0.08761
), PDiffEMA..C..2. = c(0.026596, 0.00496, -0.005546, 0.020439,
0.021133, -0.005641, 0.003898, -0.023289, -0.010783, -0.006531,
0.010838, 0.00588, 0.015649, 0.022227, 0.017145, 0.005878, 0.018494,
0.005532, -0.019885, 0.039654, 0.004918, -0.013167, -0.009126,
-0.008236, 0.008927, 0.00901, -0.002334, 0.003026, 0.001007,
-0.007354), PDiffEMA..C..20. = c(0.023494, 0.01081, -0.009719,
0.053501, 0.09028, 0.044888, 0.056839, -0.015898, -0.022072,
-0.027705, 0.010135, 0.015484, 0.052611, 0.097353, 0.116772,
0.105168, 0.144353, 0.127141, 0.050961, 0.186998, 0.14148, 0.082672,
0.060787, 0.040121, 0.069478, 0.080018, 0.056583, 0.061777, 0.055567,
0.028484), PDiffEMA..C..200. = c(-0.068742, -0.078508, -0.097264,
-0.033866, 0.009361, -0.027797, -0.010654, -0.079549, -0.08665,
-0.093699, -0.056883, -0.049865, -0.009547, 0.042795, 0.07366,
0.073603, 0.127377, 0.124079, 0.053195, 0.210835, 0.179869, 0.127461,
0.110549, 0.092516, 0.130148, 0.149253, 0.129579, 0.140945, 0.139347,
0.112197), SDev..C..10. = c(2.45958, 2.926513, 2.845093, 3.756374,
5.10219, 5.081868, 5.265783, 4.826626, 4.291157, 3.6295, 3.616951,
3.548322, 3.416113, 4.265086, 5.237565, 6.098094, 7.574411, 8.106913,
7.438958, 8.134102, 7.922738, 6.598096, 5.383846, 4.80761, 4.536255,
4.222188, 4.213449, 4.221269, 3.064969, 2.264761), SDev..C..100. = c(13.805593,
13.920931, 14.058221, 14.112652, 14.14233, 14.192877, 14.235045,
14.342703, 14.456662, 14.576194, 14.652769, 14.716173, 14.741869,
14.741427, 14.739052, 14.739403, 14.741696, 14.72701, 14.69742,
14.715059, 14.70022, 14.683246, 14.596897, 14.496483, 14.430424,
14.416019, 14.345137, 14.295151, 14.236519, 14.14409), SDev..C..15. =
c(3.810122,
3.727714, 3.420287, 3.488475, 4.557784, 4.940561, 5.411468, 5.152154,
4.963443, 4.826029, 4.495605, 4.327133, 4.217027, 4.473102, 4.804435,
5.44519, 6.496722, 6.980111, 7.051635, 8.743879, 9.554652, 9.794502,
9.39961, 8.65292, 7.64887, 6.855349, 5.630696, 4.653948, 4.153742,
3.841768), SDev..C..150. = c(14.809111, 14.831458, 14.871543,
14.875049, 14.86221, 14.85398, 14.839834, 14.839124, 14.83275,
14.800584, 14.744953, 14.70903, 14.680755, 14.634937, 14.583621,
14.535156, 14.49157, 14.425511, 14.354034, 14.308416, 14.160925,
13.939813, 13.738813, 13.549968, 13.402108, 13.345101, 13.266162,
13.220572, 13.159213, 13.071028), SDev..C..20. = c(4.490554,
4.136249, 3.827253, 3.827253, 4.433983, 4.677989, 4.975351, 4.906121,
4.751858, 4.726276, 4.738339, 4.787789, 4.796663, 5.260255, 5.922471,
6.230072, 7.061402, 7.532933, 7.293521, 8.285976, 9.020732, 9.136875,
8.933207, 8.906268, 9.121289, 9.26624, 9.309381, 8.905484, 8.244527,
7.159201), SDev..C..200. = c(13.937699, 13.932049, 13.915857,
13.87102, 13.808371, 13.757481, 13.744457, 13.752084, 13.758076,
13.783514, 13.798682, 13.813838, 13.81888, 13.816158, 13.812102,
13.812203, 13.812013, 13.792836, 13.771866, 13.812937, 13.841213,
13.850953, 13.807815, 13.777951, 13.728936, 13.694142, 13.64009,
13.572522, 13.563963, 13.540619), SDev..C..30. = c(6.659525,
6.312348, 6.205628, 6.185313, 6.276642, 6.153, 5.885621, 5.692941,
5.318038, 4.77963, 4.515988, 4.380862, 4.444435, 4.856535, 5.515185,
6.06977, 6.968752, 7.701403, 7.940274, 9.207252, 9.917679, 10.233194,
10.249308, 10.195807, 10.272199, 10.266021, 10.206979, 10.081089,
9.856419, 9.433817), SDev..C..300. = c(16.797963, 16.701622,
16.613187, 16.517589, 16.42642, 16.327529, 16.224822, 16.110968,
16.013515, 15.919686, 15.832194, 15.738236, 15.647027, 15.556436,
15.464073, 15.356872, 15.267237, 15.158701, 15.029432, 14.953765,
14.873406, 14.774429, 14.694815, 14.599113, 14.495635, 14.415466,
14.375168, 14.332271, 14.278468, 14.21763), SDev..C..5. = c(2.964954,
3.467655, 3.229029, 3.743404, 3.972414, 4.012618, 3.804355, 3.185228,
4.097424, 3.676871, 3.257195, 1.740488, 3.116317, 4.908958, 5.445399,
5.221577, 4.870424, 3.613789, 3.198867, 5.955117, 5.904707, 5.869594,
5.915874, 4.5131, 3.000012, 2.17424, 2.235985, 2.256934, 0.873212,
1.219631), SDev..C..50. = c(10.343699, 10.196541, 10.16258, 9.852793,
9.464534, 8.984178, 8.524337, 8.265461, 7.711857, 7.41325, 7.18623,
7.024682, 6.807552, 6.873778, 6.882958, 6.825507, 7.090114, 7.357327,
7.350076, 7.864016, 8.263432, 8.462081, 8.672223, 8.837325, 9.106306,
9.417383, 9.621208, 9.885152, 10.115859, 10.252854), Target8 = c(0.1998,
0.81849, 1.41144, 1.41144, 1.41144, 1.41144, 1.028738, 1.028738,
0.435787, 0.435787, 0.435787, 0.896595, 1.799078, 1.799078, 2.083291,
2.11517, 2.11517, 2.036645, 2.036645, 1.720176, 0.389911, -0.337575,
-0.726615, -0.726615, -0.337575, -0.068188, -0.068188, 0.034502,
0.144095, 0.1998)), .Names = c("ATR.200.", "ATR.30.", "ATR.50.",
"PDiffEMA..C..10.", "PDiffEMA..C..100.", "PDiffEMA..C..15.",
"PDiffEMA..C..150.", "PDiffEMA..C..2.", "PDiffEMA..C..20.", "PDiffEMA..C..200.",
"SDev..C..10.", "SDev..C..100.", "SDev..C..15.", "SDev..C..150.",
"SDev..C..20.", "SDev..C..200.", "SDev..C..30.", "SDev..C..300.",
"SDev..C..5.", "SDev..C..50.", "Target8"), class = "data.frame",
row.names = c(NA,
-30L))

IndData    = data.frame(Test_Data[,1:ncol(Test_Data)-1])
TargetData = data.frame(Test_Data[,ncol(Test_Data)])

model_earth = earth(IndData, TargetData, nprune=5)
summary(model_earth, digits = 8, style = "pmax")


From graizada at gmail.com  Tue Apr 16 07:41:58 2013
From: graizada at gmail.com (Gaurav Raizada)
Date: Tue, 16 Apr 2013 11:11:58 +0530
Subject: [R-SIG-Finance] Error in highfrequency package
Message-ID: <CANazbfVCWm5TLt0PC35qqiJi2Lsfyfjea3gUG9yyG4cbgLNgog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130416/3e9f32cb/attachment.pl>

From grandtiger at gmail.com  Tue Apr 16 12:18:56 2013
From: grandtiger at gmail.com (George Wang)
Date: Tue, 16 Apr 2013 06:18:56 -0400
Subject: [R-SIG-Finance] Rbbg in R 3.0.0
In-Reply-To: <9DE405308A6AA24AA794B76282C6C00F4A3AAC12F9@HQ-POST1>
References: <9DE405308A6AA24AA794B76282C6C00F4A3AAC12F9@HQ-POST1>
Message-ID: <5A5A9E7B-CD1A-460E-85C5-3F3461D9070B@gmail.com>

You need to install the Bloomberg desktop API by WAPI<go>.

But there seems to be an issue with the windows api download on Bloomberg side recently. Hope it's resolved now.

Sent from my iPad

On Apr 15, 2013, at 4:58 PM, David Reiner <David.Reiner at xrtrading.com> wrote:

> I tried Rbbg in R 3.0.0, but I'm getting a Java-related error I think.
> Hints?
> 
>> install.packages("Rbbg", repos="http://r.findata.org/", dependencies = TRUE)
> trying URL 'http://r.findata.org/bin/windows/contrib/3.0/Rbbg_0.4-155.zip'
> Content type 'application/zip' length 41069 bytes (40 Kb)
> opened URL
> downloaded 40 Kb
> 
> package 'Rbbg' successfully unpacked and MD5 sums checked
> 
> The downloaded binary packages are in
>        C:\Users\davidr\AppData\Local\Temp\RtmpAvhuq1\downloaded_packages
>> require(Rbbg)
> Loading required package: Rbbg
> Loading required package: rJava
>> conn <- blpConnect()
> R version 3.0.0 (2013-04-03)
> rJava Version 0.9-4
> Rbbg Version 0.4-155
> Java environment initialized successfully.
> Looking for most recent blpapi3.jar file...
> Adding C:\blp\API\APIv3\JavaAPI\v3.4.3.2\lib\blpapi3.jar to Java classpath
> Bloomberg API Version 3.4.3.2
>> ticker <- "GOOG US Equity"
>> start <- "2013-04-15 13:30:00" # These are UTC, right?
>> end <- "2013-04-15 14:00:00"
>> interval <- "1"
>> bar(conn, ticker, "BID", start, end, interval)
> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
>  java.lang.ArrayIndexOutOfBoundsException: 6
>> sessionInfo()
> R version 3.0.0 (2013-04-03)
> Platform: i386-w64-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] Rbbg_0.4-155 rJava_0.9-4
> 
> loaded via a namespace (and not attached):
> [1] tools_3.0.0
> 
> Any help is much appreciated!
> David L. Reiner
> XR Trading LLC
> 
> 
> 
> This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.
> 
> THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON'S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From john.laing at gmail.com  Tue Apr 16 13:16:17 2013
From: john.laing at gmail.com (John Laing)
Date: Tue, 16 Apr 2013 07:16:17 -0400
Subject: [R-SIG-Finance] Rbbg in R 3.0.0
In-Reply-To: <5A5A9E7B-CD1A-460E-85C5-3F3461D9070B@gmail.com>
References: <9DE405308A6AA24AA794B76282C6C00F4A3AAC12F9@HQ-POST1>
	<5A5A9E7B-CD1A-460E-85C5-3F3461D9070B@gmail.com>
Message-ID: <CAA3Wa=tvcUOn9w6DQESv7ipFqsYY2Q+G-_-w3kgKaJejrn_1_Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130416/b90ee0f7/attachment.pl>

From David.Reiner at xrtrading.com  Tue Apr 16 16:22:56 2013
From: David.Reiner at xrtrading.com (David Reiner)
Date: Tue, 16 Apr 2013 09:22:56 -0500
Subject: [R-SIG-Finance] Rbbg in R 3.0.0
In-Reply-To: <CAA3Wa=tvcUOn9w6DQESv7ipFqsYY2Q+G-_-w3kgKaJejrn_1_Q@mail.gmail.com>
References: <9DE405308A6AA24AA794B76282C6C00F4A3AAC12F9@HQ-POST1>
	<5A5A9E7B-CD1A-460E-85C5-3F3461D9070B@gmail.com>
	<CAA3Wa=tvcUOn9w6DQESv7ipFqsYY2Q+G-_-w3kgKaJejrn_1_Q@mail.gmail.com>
Message-ID: <9DE405308A6AA24AA794B76282C6C00F4A3AAC131C@HQ-POST1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130416/4abe5c19/attachment.pl>

From ArvanitisCh at piraeusbank.gr  Wed Apr 17 16:44:41 2013
From: ArvanitisCh at piraeusbank.gr (ArvanitisCh at piraeusbank.gr)
Date: Wed, 17 Apr 2013 14:44:41 +0000
Subject: [R-SIG-Finance] RBBG with R 2.15.2
Message-ID: <1D0553B3A773464E9C862F25286DD1CB6EAC798D@msexc10mb2.central.piraeusgroup.gr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130417/e455d411/attachment.pl>

From john.laing at gmail.com  Wed Apr 17 17:31:17 2013
From: john.laing at gmail.com (John Laing)
Date: Wed, 17 Apr 2013 11:31:17 -0400
Subject: [R-SIG-Finance] RBBG with R 2.15.2
In-Reply-To: <1D0553B3A773464E9C862F25286DD1CB6EAC798D@msexc10mb2.central.piraeusgroup.gr>
References: <1D0553B3A773464E9C862F25286DD1CB6EAC798D@msexc10mb2.central.piraeusgroup.gr>
Message-ID: <CAA3Wa=sM1itqTKMGCBTH9GqFCBQHShtO0qDuU5crq65RLQ_a9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130417/4ac5df96/attachment.pl>

From pgilbert902 at gmail.com  Wed Apr 17 17:51:39 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 17 Apr 2013 11:51:39 -0400
Subject: [R-SIG-Finance] RBBG with R 2.15.2
In-Reply-To: <CAA3Wa=sM1itqTKMGCBTH9GqFCBQHShtO0qDuU5crq65RLQ_a9Q@mail.gmail.com>
References: <1D0553B3A773464E9C862F25286DD1CB6EAC798D@msexc10mb2.central.piraeusgroup.gr>
	<CAA3Wa=sM1itqTKMGCBTH9GqFCBQHShtO0qDuU5crq65RLQ_a9Q@mail.gmail.com>
Message-ID: <516EC50B.2010702@gmail.com>

This regarding setInternet2 and .jinit is probably related. It is 
summarized from a personal correspondence forwarded to me by Geoff Wright:

(by memory so details may not be exactly correct)

-the issue was related to a change in stack size introduced with R 
2.15.2 (using a stack size of 64m; even on Windows 32-bit systems).

- RStudio introduced a fix to use a smaller stack size on Windows 32-bit.

-With R 3.0 the stack size was changed back to 16m for the Win32 builds.

-Therefore, do not use R 2.15.2 or R 2.15.3 on Windows 32-bit (except 
for using it with a recent RStudio release where they force smaller 
stack sizes).

Paul

On 13-04-17 11:31 AM, John Laing wrote:
> The Java OOM error has crept up occasionally over many versions of R. There
> is nothing specific to 2.15.2, as many of us have used the package
> successfully in that version.
>
> If you're happy to use R 3.0, then great, nothing to be done here.
> Otherwise you should compare your JVM settings across the different R
> versions to see what's different.
>
> -John
>
>
> On Wed, Apr 17, 2013 at 10:44 AM, <ArvanitisCh at piraeusbank.gr> wrote:
>
>> Hello to everyone,
>>
>> Recently I have tried to use the package RBBG and I have remarked the
>> following issue:
>>
>> I have used r version R-2.15.2 and got
>>
>> require(Rbbg)
>> Loading required package: Rbbg
>> Loading required package: rJava
>> Warning message:
>> package 'rJava' was built under R version 2.15.3
>>
>> when I fired in R
>> blpConnect() I got the following (by now well known) error
>>
>> R version 2.15.2 (2012-10-26)
>> rJava Version 0.9-4
>> Rbbg Version 0.4-155
>> Java environment initialized successfully.
>> Looking for most recent blpapi3.jar file...
>> Adding C:\blp\API\APIv3\JavaAPI\v3.6.1.0\lib\blpapi3.jar to Java classpath
>> Error in .jnew("org/findata/blpwrapper/Connection", java.log.level) :
>>    java.lang.OutOfMemoryError: unable to create new native thread
>>
>> This seemed to me a memory issue of the JVM and I have started to google
>> around for a solution of the issue
>>
>> All of the JVM fine tunes I found around gave me no solution to the JVM
>> memory issue
>>
>> I have then decided to work with R version 3.0.0
>>
>> Automatically the above issue has resolved
>>
>> So is there is an issue inherent to the R version 2.15.2?
>>
>> Thank you in advance for your help
>>
>> Christos arvanitis
>>
>> sessionInfo()
>> R version 2.15.2 (2012-10-26)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices datasets  utils     methods   base
>>
>> other attached packages:
>> [1] Rbbg_0.4-155   rJava_0.9-4    rcom_3.1-2     rscproxy_2.0-5
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.15.2
>>
>>
>>
>> MESSAGE CONFIDENTIALITY AND SECURITY NOTICE
>>
>> =========================================
>>
>> This message and/or its attachments may contain confidential and
>> privileged information and is intended for the named person or entity to
>> which it is addressed. Any use, copying or distribution of this information
>> by anyone other than the intended recipient(s) is prohibited by law. If you
>> receive this in error, please immediately delete it from your system and
>> notify the sender.
>>
>> The contents of this message contain personal opinions of the sender,
>> which are not the official views of Piraeus Bank nor do they consist a
>> provision of financial or advisory services unless expressly stated
>> otherwise. This message is not a solicitation and/or an offer or acceptance
>> of any proposal in relation to any contract or transaction unless expressly
>> otherwise indicated in the message itself.
>>
>> The Internet is not a secure or error-free environment, and Piraeus Bank
>> does not accept liability for any loss or damage arising from the use of
>> this message or from delayed, intercepted, corrupted or virus-infected
>> e-mail transmission.
>>
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From thais.azevedo at aluno.puc-rio.br  Wed Apr 17 19:01:23 2013
From: thais.azevedo at aluno.puc-rio.br (Thais Azevedo)
Date: Wed, 17 Apr 2013 10:01:23 -0700 (PDT)
Subject: [R-SIG-Finance] Using garchFit to fit a model ARMA(2, 2) + GARCH(3,
	1)
Message-ID: <1366218083733-4664530.post@n4.nabble.com>

Hi,

I'm using the function garchFit from fGarch package to fit models to my
serie.
I need to fit an ARMA(2,2) + GARCH(3,1), but i want just one parcel of ARCH 
lagged 3 steps
I tried to use:
garchFit(~arma(2,2)+garch(3,1), data=ret2, trace=FALSE, include.mean=FALSE,
cond.dist="ged", control = list(alpha1=0, alpha2=0))
But it doesn't work.

Can somebody help me?

If it's not possible to do that with garchFit, please someone let me know.

Thanks the help.



--
View this message in context: http://r.789695.n4.nabble.com/Using-garchFit-to-fit-a-model-ARMA-2-2-GARCH-3-1-tp4664530.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From savio.debian at gmail.com  Thu Apr 18 02:29:16 2013
From: savio.debian at gmail.com (=?ISO-8859-1?Q?S=E1vio_Ramos?=)
Date: Wed, 17 Apr 2013 21:29:16 -0300
Subject: [R-SIG-Finance] saveChart don't work in Quantmod package
Message-ID: <CADYnR6Pp0rXtRSkVhL2Muxs9s6msq6=-tmPCFmhRDFME5au4-g@mail.gmail.com>

Hi,

After upgraded R to realese 3.o saveChart don't work more, error is:

>   saveChart('pdf',width=25,height=13)
Erro em assign(".chob", x, env) :
  n?o ? poss?vel mudar o valor de vinculo bloqueado para '.chob'

Is there any workaround?

Thanks.
-- 
S?vio M Ramos
Arquiteto, Rio, RJ
S? uso Linux desde 2000
www.debian.org


From josh.m.ulrich at gmail.com  Thu Apr 18 02:43:22 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 17 Apr 2013 19:43:22 -0500
Subject: [R-SIG-Finance] saveChart don't work in Quantmod package
In-Reply-To: <CADYnR6Pp0rXtRSkVhL2Muxs9s6msq6=-tmPCFmhRDFME5au4-g@mail.gmail.com>
References: <CADYnR6Pp0rXtRSkVhL2Muxs9s6msq6=-tmPCFmhRDFME5au4-g@mail.gmail.com>
Message-ID: <CAPPM_gQnU82PqMB15zkPKQVR6iC5KMSU2UCgfZ6JpHm_xoVd_g@mail.gmail.com>

You need to update quantmod too.  You don't say which version of
quantmod you're using, but R-3.0.0 requires you to use quantmod_0.4-0.
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com

R/Finance 2013: Applied Finance with R  | www.RinFinance.com


On Wed, Apr 17, 2013 at 7:29 PM, S?vio Ramos <savio.debian at gmail.com> wrote:
> Hi,
>
> After upgraded R to realese 3.o saveChart don't work more, error is:
>
>>   saveChart('pdf',width=25,height=13)
> Erro em assign(".chob", x, env) :
>   n?o ? poss?vel mudar o valor de vinculo bloqueado para '.chob'
>
> Is there any workaround?
>
> Thanks.
> --
> S?vio M Ramos
> Arquiteto, Rio, RJ
> S? uso Linux desde 2000
> www.debian.org
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From josh.m.ulrich at gmail.com  Thu Apr 18 17:43:59 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 18 Apr 2013 10:43:59 -0500
Subject: [R-SIG-Finance] saveChart don't work in Quantmod package
In-Reply-To: <CAPPM_gQnU82PqMB15zkPKQVR6iC5KMSU2UCgfZ6JpHm_xoVd_g@mail.gmail.com>
References: <CADYnR6Pp0rXtRSkVhL2Muxs9s6msq6=-tmPCFmhRDFME5au4-g@mail.gmail.com>
	<CAPPM_gQnU82PqMB15zkPKQVR6iC5KMSU2UCgfZ6JpHm_xoVd_g@mail.gmail.com>
Message-ID: <CAPPM_gTWg0tAGBgxP=Yv3qExpx6PzQHpJpczmwWmOnjzgAOdUg@mail.gmail.com>

On Wed, Apr 17, 2013 at 7:43 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> You need to update quantmod too.  You don't say which version of
> quantmod you're using, but R-3.0.0 requires you to use quantmod_0.4-0.

After further investigation, it looks like this is a bug.  I can
reproduce it with quantmod_0.4-0 and R-2.15.2 on Windows.

library(quantmod)
getSymbols("SPY")
chartSeries(SPY)
saveChart()
Error in assign(".chob", x, env) :
  cannot change value of locked binding for '.chob'

sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] quantmod_0.4-0 TTR_0.21-1     xts_0.9-3      zoo_1.7-10     Defaults_1.1-1

loaded via a namespace (and not attached):
[1] grid_2.15.2     lattice_0.20-10


> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
>
> R/Finance 2013: Applied Finance with R  | www.RinFinance.com
>
>
> On Wed, Apr 17, 2013 at 7:29 PM, S?vio Ramos <savio.debian at gmail.com> wrote:
>> Hi,
>>
>> After upgraded R to realese 3.o saveChart don't work more, error is:
>>
>>>   saveChart('pdf',width=25,height=13)
>> Erro em assign(".chob", x, env) :
>>   n?o ? poss?vel mudar o valor de vinculo bloqueado para '.chob'
>>
>> Is there any workaround?
>>
>> Thanks.
>> --
>> S?vio M Ramos
>> Arquiteto, Rio, RJ
>> S? uso Linux desde 2000
>> www.debian.org
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.


From jeff.a.ryan at gmail.com  Thu Apr 18 18:02:37 2013
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Thu, 18 Apr 2013 11:02:37 -0500
Subject: [R-SIG-Finance] saveChart don't work in Quantmod package
In-Reply-To: <CAPPM_gTWg0tAGBgxP=Yv3qExpx6PzQHpJpczmwWmOnjzgAOdUg@mail.gmail.com>
References: <CADYnR6Pp0rXtRSkVhL2Muxs9s6msq6=-tmPCFmhRDFME5au4-g@mail.gmail.com>
	<CAPPM_gQnU82PqMB15zkPKQVR6iC5KMSU2UCgfZ6JpHm_xoVd_g@mail.gmail.com>
	<CAPPM_gTWg0tAGBgxP=Yv3qExpx6PzQHpJpczmwWmOnjzgAOdUg@mail.gmail.com>
Message-ID: <A8CB4A75-63DD-47BC-B10F-5088FDD7C1E4@gmail.com>

Yes. This is a bug. Newest R and quantmod use a different mechanism to store the data that needs to be replayed for saving

You can use dev.copy2pdf directly of course as well. 

HTH
Jeff

Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com

www.lemnica.com

On Apr 18, 2013, at 10:43 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:

> On Wed, Apr 17, 2013 at 7:43 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>> You need to update quantmod too.  You don't say which version of
>> quantmod you're using, but R-3.0.0 requires you to use quantmod_0.4-0.
> 
> After further investigation, it looks like this is a bug.  I can
> reproduce it with quantmod_0.4-0 and R-2.15.2 on Windows.
> 
> library(quantmod)
> getSymbols("SPY")
> chartSeries(SPY)
> saveChart()
> Error in assign(".chob", x, env) :
>  cannot change value of locked binding for '.chob'
> 
> sessionInfo()
> R version 2.15.2 (2012-10-26)
> Platform: i386-w64-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] quantmod_0.4-0 TTR_0.21-1     xts_0.9-3      zoo_1.7-10     Defaults_1.1-1
> 
> loaded via a namespace (and not attached):
> [1] grid_2.15.2     lattice_0.20-10
> 
> 
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com
>> 
>> R/Finance 2013: Applied Finance with R  | www.RinFinance.com
>> 
>> 
>> On Wed, Apr 17, 2013 at 7:29 PM, S?vio Ramos <savio.debian at gmail.com> wrote:
>>> Hi,
>>> 
>>> After upgraded R to realese 3.o saveChart don't work more, error is:
>>> 
>>>>  saveChart('pdf',width=25,height=13)
>>> Erro em assign(".chob", x, env) :
>>>  n?o ? poss?vel mudar o valor de vinculo bloqueado para '.chob'
>>> 
>>> Is there any workaround?
>>> 
>>> Thanks.
>>> --
>>> S?vio M Ramos
>>> Arquiteto, Rio, RJ
>>> S? uso Linux desde 2000
>>> www.debian.org
>>> 
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions should go.
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From ivan.popivanov at gmail.com  Thu Apr 18 19:32:52 2013
From: ivan.popivanov at gmail.com (Ivan Popivanov)
Date: Thu, 18 Apr 2013 13:32:52 -0400
Subject: [R-SIG-Finance] Is this the place for reporting quantmod (and other
	packages) bugs?
Message-ID: <CAK7-yAiDXw5Amii2A6L+iEOuDB9rn8uZw9hGmZu+nJQmLFyUug@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130418/58e92c29/attachment.pl>

From aidan.corcoran11 at gmail.com  Fri Apr 19 09:52:06 2013
From: aidan.corcoran11 at gmail.com (Aidan Corcoran)
Date: Fri, 19 Apr 2013 08:52:06 +0100
Subject: [R-SIG-Finance] precision of data download in rbbg/rbloomberg
Message-ID: <CADv5Py6kxg-TxFuEKSa_tGjG0GaSP6QVNz09nyrY9LqDKVJmgg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130419/1161e691/attachment.pl>

From john.laing at gmail.com  Fri Apr 19 13:04:34 2013
From: john.laing at gmail.com (John Laing)
Date: Fri, 19 Apr 2013 07:04:34 -0400
Subject: [R-SIG-Finance] precision of data download in rbbg/rbloomberg
In-Reply-To: <CADv5Py6kxg-TxFuEKSa_tGjG0GaSP6QVNz09nyrY9LqDKVJmgg@mail.gmail.com>
References: <CADv5Py6kxg-TxFuEKSa_tGjG0GaSP6QVNz09nyrY9LqDKVJmgg@mail.gmail.com>
Message-ID: <CAA3Wa=vSsygfWC1REu0-nQUGLkX9RDRdFFe2B06DKEW7eSkuEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130419/bbedb6be/attachment.pl>

From aidan.corcoran11 at gmail.com  Fri Apr 19 14:34:40 2013
From: aidan.corcoran11 at gmail.com (Aidan Corcoran)
Date: Fri, 19 Apr 2013 13:34:40 +0100
Subject: [R-SIG-Finance] precision of data download in rbbg/rbloomberg
In-Reply-To: <CAA3Wa=vSsygfWC1REu0-nQUGLkX9RDRdFFe2B06DKEW7eSkuEw@mail.gmail.com>
References: <CADv5Py6kxg-TxFuEKSa_tGjG0GaSP6QVNz09nyrY9LqDKVJmgg@mail.gmail.com>
	<CAA3Wa=vSsygfWC1REu0-nQUGLkX9RDRdFFe2B06DKEW7eSkuEw@mail.gmail.com>
Message-ID: <CADv5Py57FpzB+cxHri7tqS89uXBgOS=BjUDy7+-4mRXpR-mpKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130419/f696c49c/attachment.pl>

From jeff.a.ryan at gmail.com  Fri Apr 19 14:52:54 2013
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 19 Apr 2013 07:52:54 -0500
Subject: [R-SIG-Finance] precision of data download in rbbg/rbloomberg
In-Reply-To: <CADv5Py57FpzB+cxHri7tqS89uXBgOS=BjUDy7+-4mRXpR-mpKw@mail.gmail.com>
References: <CADv5Py6kxg-TxFuEKSa_tGjG0GaSP6QVNz09nyrY9LqDKVJmgg@mail.gmail.com>
	<CAA3Wa=vSsygfWC1REu0-nQUGLkX9RDRdFFe2B06DKEW7eSkuEw@mail.gmail.com>
	<CADv5Py57FpzB+cxHri7tqS89uXBgOS=BjUDy7+-4mRXpR-mpKw@mail.gmail.com>
Message-ID: <CABDUZc9GoxwdOycpcVoSaJ_Cvg1GF-+8O0DMSXRtozPbE2KNug@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130419/80ac7356/attachment.pl>

From john.laing at gmail.com  Fri Apr 19 15:05:26 2013
From: john.laing at gmail.com (John Laing)
Date: Fri, 19 Apr 2013 09:05:26 -0400
Subject: [R-SIG-Finance] precision of data download in rbbg/rbloomberg
In-Reply-To: <CABDUZc9GoxwdOycpcVoSaJ_Cvg1GF-+8O0DMSXRtozPbE2KNug@mail.gmail.com>
References: <CADv5Py6kxg-TxFuEKSa_tGjG0GaSP6QVNz09nyrY9LqDKVJmgg@mail.gmail.com>
	<CAA3Wa=vSsygfWC1REu0-nQUGLkX9RDRdFFe2B06DKEW7eSkuEw@mail.gmail.com>
	<CADv5Py57FpzB+cxHri7tqS89uXBgOS=BjUDy7+-4mRXpR-mpKw@mail.gmail.com>
	<CABDUZc9GoxwdOycpcVoSaJ_Cvg1GF-+8O0DMSXRtozPbE2KNug@mail.gmail.com>
Message-ID: <CAA3Wa=vRxzq+tnt-20CH5GVdRzWQRyPvPoTThxeLzCUB-YGf5Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130419/6221f50e/attachment.pl>

From armstrong.whit at gmail.com  Fri Apr 19 15:35:10 2013
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Fri, 19 Apr 2013 09:35:10 -0400
Subject: [R-SIG-Finance] precision of data download in rbbg/rbloomberg
In-Reply-To: <CAA3Wa=vRxzq+tnt-20CH5GVdRzWQRyPvPoTThxeLzCUB-YGf5Q@mail.gmail.com>
References: <CADv5Py6kxg-TxFuEKSa_tGjG0GaSP6QVNz09nyrY9LqDKVJmgg@mail.gmail.com>
	<CAA3Wa=vSsygfWC1REu0-nQUGLkX9RDRdFFe2B06DKEW7eSkuEw@mail.gmail.com>
	<CADv5Py57FpzB+cxHri7tqS89uXBgOS=BjUDy7+-4mRXpR-mpKw@mail.gmail.com>
	<CABDUZc9GoxwdOycpcVoSaJ_Cvg1GF-+8O0DMSXRtozPbE2KNug@mail.gmail.com>
	<CAA3Wa=vRxzq+tnt-20CH5GVdRzWQRyPvPoTThxeLzCUB-YGf5Q@mail.gmail.com>
Message-ID: <CAMi=pg7UTVD1LXiyoKaa8TXd=iYVgs45S3pfRXh3z4baYsF33Q@mail.gmail.com>

So, as JL was saying, in this case, implementation speed isn't the issue.

Before someone makes a fuss about re-inventing the wheel...

The thinking behind the c++ version is that as much as I love Java (ha
ha), we need to use this in ruby, so the c++ bit will eventually be
generalized into something independent from this R package.

One of the bigger issues to deal with is a c++ implementation of
DataFrames.  It's a bit of a pain in the ass.

Anyway, the link is here if anyone wants to experiment.  I've set this
up to compile on linux, but I haven't done anything about Windows, so
you're on your own if you want that to work.

https://github.com/armstrtw/Rblpapi

-Whit

On Fri, Apr 19, 2013 at 9:05 AM, John Laing <john.laing at gmail.com> wrote:
> Jeff is right, Rbbg's result processing is not, shall we say, optimized.
> Whit Armstrong has been working on a more lightweight C++-based interface
> to Bloomberg that is also more graceful with its data type handling. I
> don't think he's released it publicly yet.
>
> But in this case his version is roughly the same speed as Rbbg. I think the
> slowness is on Bloomberg's side.
>
> -John
>
>
> On Fri, Apr 19, 2013 at 8:52 AM, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:
>
>> Aidan,
>>
>> There is an awful lot of additional processing happening inside of bdh in
>> terms of data extraction/manipulation. In the past I've extracted out the
>> important .java type calls and return types to get substantial speed-ups,
>> especially when dealing with a common/more constrained search (e.g. one
>> name at a time)
>>
>> Of course, YMMV
>>
>> Best,
>> Jeff
>>
>>
>> On Fri, Apr 19, 2013 at 7:34 AM, Aidan Corcoran
>> <aidan.corcoran11 at gmail.com>wrote:
>>
>> > hi John,
>> >
>> > thanks for your reply. my results were:
>> >  user  system elapsed
>> >    1.00    0.06    6.43
>> >
>> > This is using win7 64bit, 12gb of RAM. I get roughly 6mbps download speed
>> > from the internet where I am in case that has any bearing.
>> >
>> > The speed is probably not bad, I just wanted to make sure I wasn't
>> missing
>> > an easy option to get a bit more speed.
>> >
>> > Thanks for your help!
>> >
>> >
>> > On Fri, Apr 19, 2013 at 12:04 PM, John Laing <john.laing at gmail.com>
>> wrote:
>> >
>> > > Aidan,
>> > >
>> > > I don't think the Bloomberg API offers such an option. However, I also
>> > > don't think that precision is a big cause of slowness. Can you send a
>> > > sample query to demonstrate your issue? E.g.:
>> > >
>> > > > system.time(ty1 <- bdh(conn, "TY1 Comdty", "PX_LAST",
>> > > start_date=as.Date("1900-01-01"), end_date=Sys.Date()))
>> > >    user  system elapsed
>> > >   0.428   0.024   2.772
>> > > > dim(ty1)
>> > > [1] 7795    2
>> > >
>> > >
>> > > -John
>> > >
>> > >
>> > > On Fri, Apr 19, 2013 at 3:52 AM, Aidan Corcoran <
>> > > aidan.corcoran11 at gmail.com> wrote:
>> > >
>> > >> hi folks,
>> > >>
>> > >> I was wondering if it is possible to limit the precision of the data
>> > being
>> > >> downloaded via the bdh function in rbbg, in the interest of speed. I
>> > >> haven't seen any mention of such an option but thought I would ask
>> just
>> > in
>> > >> case I missed something.
>> > >>
>> > >> thanks in advance
>> > >> Aidan
>> > >>
>> > >>         [[alternative HTML version deleted]]
>> > >>
>> > >> _______________________________________________
>> > >> R-SIG-Finance at r-project.org mailing list
>> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > >> -- Subscriber-posting only. If you want to post, subscribe first.
>> > >> -- Also note that this is not the r-help list where general R
>> questions
>> > >> should go.
>> > >>
>> > >
>> > >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only. If you want to post, subscribe first.
>> > -- Also note that this is not the r-help list where general R questions
>> > should go.
>> >
>>
>>
>>
>> --
>> Jeffrey Ryan
>> jeffrey.ryan at lemnica.com
>>
>> www.lemnica.com
>>
>> R/Finance 2013: Applied R in Finance
>> May 17, 18 Chicago, IL
>> www.RinFinance.com
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From aidan.corcoran11 at gmail.com  Fri Apr 19 16:40:50 2013
From: aidan.corcoran11 at gmail.com (Aidan Corcoran)
Date: Fri, 19 Apr 2013 15:40:50 +0100
Subject: [R-SIG-Finance] precision of data download in rbbg/rbloomberg
In-Reply-To: <CAMi=pg7UTVD1LXiyoKaa8TXd=iYVgs45S3pfRXh3z4baYsF33Q@mail.gmail.com>
References: <CADv5Py6kxg-TxFuEKSa_tGjG0GaSP6QVNz09nyrY9LqDKVJmgg@mail.gmail.com>
	<CAA3Wa=vSsygfWC1REu0-nQUGLkX9RDRdFFe2B06DKEW7eSkuEw@mail.gmail.com>
	<CADv5Py57FpzB+cxHri7tqS89uXBgOS=BjUDy7+-4mRXpR-mpKw@mail.gmail.com>
	<CABDUZc9GoxwdOycpcVoSaJ_Cvg1GF-+8O0DMSXRtozPbE2KNug@mail.gmail.com>
	<CAA3Wa=vRxzq+tnt-20CH5GVdRzWQRyPvPoTThxeLzCUB-YGf5Q@mail.gmail.com>
	<CAMi=pg7UTVD1LXiyoKaa8TXd=iYVgs45S3pfRXh3z4baYsF33Q@mail.gmail.com>
Message-ID: <CADv5Py4gCnwyRkHTQj6JemrR5rs=AeW8Ug9uww5-QVhMaQ0SYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130419/053d221a/attachment.pl>

From jesperhybel at hotmail.com  Fri Apr 19 20:09:15 2013
From: jesperhybel at hotmail.com (Jesper Hybel Pedersen)
Date: Fri, 19 Apr 2013 20:09:15 +0200
Subject: [R-SIG-Finance] FIGARCH estimation and simulation
Message-ID: <DUB119-DS18C6527660FC78CB008366AEC80@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130419/5705b0c1/attachment.pl>

From yitaoz at stanford.edu  Sat Apr 20 00:32:07 2013
From: yitaoz at stanford.edu (Yitao Zhang)
Date: Fri, 19 Apr 2013 15:32:07 -0700
Subject: [R-SIG-Finance] Using getSymbol in a R function
Message-ID: <AABA18F5-C768-43DB-93A2-0D5789B7D72E@stanford.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130419/f54b2222/attachment.pl>

From roschm at ymail.com  Sat Apr 20 04:23:15 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Fri, 19 Apr 2013 19:23:15 -0700 (PDT)
Subject: [R-SIG-Finance] quantmod newbie xts example
Message-ID: <1366424595571-4664796.post@n4.nabble.com>

Hello all,

Here is a newbie example of using an xts object.  It calculates a 
random walk simulation of prices and plots the data in a moving window.
Weekends have been removed from the dates and also a moving average 
has been added to the plot.

Thank you in advance for all corrections, improvements, comments, 
modifications, etc. which help us newbies learn.  

Best regards,

Rob
random_walk4.R <http://r.789695.n4.nabble.com/file/n4664796/random_walk4.R>  



--
View this message in context: http://r.789695.n4.nabble.com/quantmod-newbie-xts-example-tp4664796.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From ivan.popivanov at gmail.com  Sat Apr 20 06:09:55 2013
From: ivan.popivanov at gmail.com (Ivan Popivanov)
Date: Sat, 20 Apr 2013 00:09:55 -0400
Subject: [R-SIG-Finance] Using getSymbol in a R function
In-Reply-To: <AABA18F5-C768-43DB-93A2-0D5789B7D72E@stanford.edu>
References: <AABA18F5-C768-43DB-93A2-0D5789B7D72E@stanford.edu>
Message-ID: <CAK7-yAhgJ_Kt26_RxEYbzr8dPLY0hXfvuGfHoPttfS5_NhqG+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130420/35999a5e/attachment.pl>

From nk at fennoturvapalvelut.com  Sat Apr 20 09:51:00 2013
From: nk at fennoturvapalvelut.com (Niklas K)
Date: Sat, 20 Apr 2013 10:51:00 +0300
Subject: [R-SIG-Finance] reqHistoricalData for comboLeg
Message-ID: <517248E4.4010209@fennoturvapalvelut.com>

Hi,

I am trying to get historical data for a comboLeg with the following code:



  tws <- twsConnect(1)
  bag <- twsBAG(    list(
    twsComboLeg( conId = "43635367", ratio = "1", action = "BUY", 
exchange = "SMART"
      )
      ,
      twsComboLeg(  conId = "47207284", ratio = "1", action = "SELL", 
exchange = "SMART"
      )
    )
  )
  reqHistoricalData(tws, Contract=bag, barSize='1 min', duration='2 D')




For some reason it gets stuck at:
"waiting for TWS reply on USD ..."

If someone has been successfully getting data for comboLegs from IB tws 
I would be thankful for any tips.

-niklas


From jeff.a.ryan at gmail.com  Sat Apr 20 15:13:23 2013
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sat, 20 Apr 2013 08:13:23 -0500
Subject: [R-SIG-Finance] reqHistoricalData for comboLeg
In-Reply-To: <517248E4.4010209@fennoturvapalvelut.com>
References: <517248E4.4010209@fennoturvapalvelut.com>
Message-ID: <CABDUZc88yjhPr-pTHC5inZJZW8mTMVq_Ge6K_LCxJqRGskW7ZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130420/803ee5e2/attachment.pl>

From nk at fennoturvapalvelut.com  Sat Apr 20 15:19:34 2013
From: nk at fennoturvapalvelut.com (Niklas K)
Date: Sat, 20 Apr 2013 16:19:34 +0300
Subject: [R-SIG-Finance] reqHistoricalData for comboLeg
In-Reply-To: <CABDUZc88yjhPr-pTHC5inZJZW8mTMVq_Ge6K_LCxJqRGskW7ZQ@mail.gmail.com>
References: <517248E4.4010209@fennoturvapalvelut.com>
	<CABDUZc88yjhPr-pTHC5inZJZW8mTMVq_Ge6K_LCxJqRGskW7ZQ@mail.gmail.com>
Message-ID: <517295E6.10208@fennoturvapalvelut.com>

Hi,

Thanks, thats right can probably not use "SMART" there.

It appears possible to get comboLeg data from the IB API: 
https://stat.ethz.ch/pipermail/r-sig-finance/2012q3/010588.html


-n



On 20.4.2013 16:13, Jeff Ryan wrote:
> Hi Niklas,
>
> I haven't been able to check, but I don't think you can use
> exhange="SMART", rather it must be explicit, i.e. "CBOE".
>
> I also don't think you can get the combo price, rather you need to
> request the historical data for each leg.  Would of course love to be
> proved wrong...
>
>
> HTH
> Jeff
>
>
> On Sat, Apr 20, 2013 at 2:51 AM, Niklas K <nk at fennoturvapalvelut.com
> <mailto:nk at fennoturvapalvelut.com>> wrote:
>
>     Hi,
>
>     I am trying to get historical data for a comboLeg with the following
>     code:
>
>
>
>       tws <- twsConnect(1)
>       bag <- twsBAG(    list(
>         twsComboLeg( conId = "43635367", ratio = "1", action = "BUY",
>     exchange = "SMART"
>           )
>           ,
>           twsComboLeg(  conId = "47207284", ratio = "1", action =
>     "SELL", exchange = "SMART"
>           )
>         )
>       )
>       reqHistoricalData(tws, Contract=bag, barSize='1 min', duration='2 D')
>
>
>
>
>     For some reason it gets stuck at:
>     "waiting for TWS reply on USD ..."
>
>     If someone has been successfully getting data for comboLegs from IB
>     tws I would be thankful for any tips.
>
>     -niklas
>
>     _________________________________________________
>     R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org>
>     mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-sig-finance
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-finance>
>     -- Subscriber-posting only. If you want to post, subscribe first.
>     -- Also note that this is not the r-help list where general R
>     questions should go.
>
>
>
>
> --
> Jeffrey Ryan
> jeffrey.ryan at lemnica.com <mailto:jeffrey.ryan at lemnica.com>
>
> www.lemnica.com <http://www.lemnica.com>
>
> R/Finance 2013: Applied R in Finance
> May 17, 18 Chicago, IL
> www.RinFinance.com <http://www.RinFinance.com>
>


From roschm at ymail.com  Sat Apr 20 16:29:19 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Sat, 20 Apr 2013 07:29:19 -0700 (PDT)
Subject: [R-SIG-Finance] quantstrat spread parameter sweep problem
Message-ID: <1366468159886-4664819.post@n4.nabble.com>

Hello all,

I am stuck on making a parameter sweep of a spread and have attached 
the version that gets the farthest before failing.  This has driven me 
to extreme measures like reading the documentation and trying to upgrade 
my debugging skills.  

The code gets through the basic calculations and makes a chart so the 
spread definitions seem ok.  But it fails in applyParameter.  The variable 
values are reasonable as far as I can tell until %dopar% in the foreach() 
command in parameters.R.  Then the debugger takes the rest of the 
command in {} as a big chunk and my modest debug skills fail.  This 
sweep code works when I use a single contract rather than a spread.  
Here is the error.  The traceback points to the chunk of code after 
%dopar% so I won't repeat that.

Thanks to the authors for this great effort. Thanks for all help.

Best regards,

Rob

> source('~/work/R/quantstrat/spread-sweep05.R')
[1] "2011-03-01 00:00:00 SPY.DIA -100 @ 10.9387968680294"
[1] "2011-03-07 00:00:00 SPY.DIA 100 @ 10.8600842370335"
[1] "2011-03-10 00:00:00 SPY.DIA -100 @ 9.82580786782957"
[1] "2011-03-11 00:00:00 SPY.DIA 100 @ 10.0274530275673"
[1] "2011-03-15 00:00:00 SPY.DIA -100 @ 9.2739827055253"
[1] "2011-04-06 00:00:00 SPY.DIA 100 @ 9.78335984354628"
[1] "2011-04-13 00:00:00 SPY.DIA -100 @ 9.02241069100391"
Realized PL: -63.23097 
[1] "Object for parameter distribution initialized..."
[1] "Parameter constraint object initialized..."
[1] "ParamTable generated"
numValues: 5, numResults: 0, stopped: TRUE
got results for task 1
accumulate got an error result
numValues: 5, numResults: 1, stopped: TRUE
returning status FALSE
got results for task 2
numValues: 5, numResults: 2, stopped: TRUE
returning status FALSE
got results for task 3
numValues: 5, numResults: 3, stopped: TRUE
returning status FALSE
got results for task 4
numValues: 5, numResults: 4, stopped: TRUE
returning status FALSE
got results for task 5
numValues: 5, numResults: 5, stopped: TRUE
not calling combine function due to errors
returning status TRUE
Error in { (from spread-sweep05.R#193) : task 1 failed - "argument is of
length zero"
> sessionInfo()
R version 2.15.3 (2013-03-01)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
 [1] doMC_1.3.0                 iterators_1.0.6           
 [3] quantstrat_0.7.7           foreach_1.4.0             
 [5] blotter_0.8.14             PerformanceAnalytics_1.1.0
 [7] FinancialInstrument_1.1.7  quantmod_0.4-0            
 [9] Defaults_1.1-1             TTR_0.22-0                
[11] xts_0.9-3                  zoo_1.7-9                 
[13] vimcom_0.9-8               setwidth_1.0-3            

loaded via a namespace (and not attached):
[1] codetools_0.2-8 compiler_2.15.3 grid_2.15.3     lattice_0.20-13
[5] tools_2.15.3

spread-sweep05.R
<http://r.789695.n4.nabble.com/file/n4664819/spread-sweep05.R>  



--
View this message in context: http://r.789695.n4.nabble.com/quantstrat-spread-parameter-sweep-problem-tp4664819.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From brian at braverock.com  Sat Apr 20 16:53:50 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 20 Apr 2013 09:53:50 -0500
Subject: [R-SIG-Finance] quantstrat spread parameter sweep problem
In-Reply-To: <1366468159886-4664819.post@n4.nabble.com>
References: <1366468159886-4664819.post@n4.nabble.com>
Message-ID: <5172ABFE.4030809@braverock.com>

On 04/20/2013 09:29 AM, Rob Schmidt wrote:
> I am stuck on making a parameter sweep of a spread and have attached
> the version that gets the farthest before failing.  This has driven me
> to extreme measures like reading the documentation and trying to upgrade
> my debugging skills.
>
> The code gets through the basic calculations and makes a chart so the
> spread definitions seem ok.  But it fails in applyParameter.  The variable
> values are reasonable as far as I can tell until %dopar% in the foreach()
> command in parameters.R.  Then the debugger takes the rest of the
> command in {} as a big chunk and my modest debug skills fail.  This
> sweep code works when I use a single contract rather than a spread.
> Here is the error.  The traceback points to the chunk of code after
> %dopar% so I won't repeat that.

%dopar% is running in parallel.  Obviously you can't get a debugger down 
into the child processes (debugging for parallel computing is an even 
darker art than R coding).

You may be able to debug into your problem by calling registerDoSEQ() 
before running your script, to force foreach into single threaded mode 
so that you can debug into the foreach loop.

> Error in { (from spread-sweep05.R#193) : task 1 failed - "argument is of

This is saying the error is on line 193 of your script, but I suspect 
that you're going to come back and say that is the applyParameters line.

Now that I've said all that, we've moved all our development attention 
on parameter code to apply.paramsets instead of applyParameters.  The 
old code wasn't extensible enough, and we've basically abandoned it in 
favor of a more flexible apporoach, and a refactored code base.

You can see all the documentation, and you should be able to find the 
code in the paramsets.R file in the source.  One of the luxor demos uses 
the paramsets code, so you shjould be able to find example code to start 
from as well in modifying your parameter specification.

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From yitaoz at stanford.edu  Mon Apr 22 01:28:31 2013
From: yitaoz at stanford.edu (Yitao Zhang)
Date: Sun, 21 Apr 2013 16:28:31 -0700
Subject: [R-SIG-Finance] Using adf.test to test time series stationarity of
	stock price
Message-ID: <D04F7CC1-3F00-4499-9AC0-239C73AEDA15@stanford.edu>

Hey guys,

I'm trying to do a augmented Dickey-Fuller test to test the stationarity of a stock price.

library(quantmod)
library(tseries)
stock2=getSymbols("PEP", src="yahoo", from= '2005-6-01', to ='2012-6-21', auto.assign=FALSE)
adf.test(stock2[,1])


Results:

	Augmented Dickey-Fuller Test

data:  stock2[, 1]
Dickey-Fuller = 2.7174, Lag order = 12, p-value = 0.99
alternative hypothesis: stationary

Warning message:
In adf.test(stock2[, 1]) : p-value greater than printed p-value

My results has a warning of p value greater than printed p value. Is this normal? Also I've tried various stocks but it doesn't ever go below 0.99. Would love to know what you guys think.



--
Yitao Zhang
Stanford University '14
B.A. in Economics
(650)-391-6966 | yitaoz at stanford.edu


From brian at braverock.com  Mon Apr 22 02:16:11 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 21 Apr 2013 19:16:11 -0500
Subject: [R-SIG-Finance] Using adf.test to test time series stationarity
 of stock price
In-Reply-To: <D04F7CC1-3F00-4499-9AC0-239C73AEDA15@stanford.edu>
References: <D04F7CC1-3F00-4499-9AC0-239C73AEDA15@stanford.edu>
Message-ID: <5174814B.9050409@braverock.com>

On 04/21/2013 06:28 PM, Yitao Zhang wrote:
> Hey guys,
>
> I'm trying to do a augmented Dickey-Fuller test to test the stationarity of a stock price.

With your stated economics background, one would assume that you'd 
realize that price is almost never stationary.

Perhaps try on returns?

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From roschm at ymail.com  Mon Apr 22 04:09:15 2013
From: roschm at ymail.com (Rob Schmidt)
Date: Sun, 21 Apr 2013 19:09:15 -0700 (PDT)
Subject: [R-SIG-Finance] quantstrat spread parameter sweep problem
In-Reply-To: <5172ABFE.4030809@braverock.com>
References: <1366468159886-4664819.post@n4.nabble.com>
	<5172ABFE.4030809@braverock.com>
Message-ID: <1366596555345-4664943.post@n4.nabble.com>

Hi Brian,

Thank you for your helpful suggestions.  The paramset method is working much
better.  For completeness, I'm attaching a minimum parameter sweep example
using apply.paramset() based on a simple moving average crossover.  It is a
mangle of a small piece of the luxor demo.  It does make a warning about
GBPUSD being the name of a currency about which I have no clue.

Best regards,

Rob

spread-sweep08.R
<http://r.789695.n4.nabble.com/file/n4664943/spread-sweep08.R>  



--
View this message in context: http://r.789695.n4.nabble.com/quantstrat-spread-parameter-sweep-problem-tp4664819p4664943.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From katherine_gobin at yahoo.com  Mon Apr 22 08:32:08 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Mon, 22 Apr 2013 14:32:08 +0800 (SGT)
Subject: [R-SIG-Finance] Gini Coefficient and Coefficient of Concordance
Message-ID: <1366612328.91343.YahooMailClassic@web193203.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130422/c184f1ac/attachment.pl>

From amit.varshney at credit-suisse.com  Mon Apr 22 13:32:30 2013
From: amit.varshney at credit-suisse.com (Varshney, Amit)
Date: Mon, 22 Apr 2013 07:32:30 -0400
Subject: [R-SIG-Finance] (no subject)
Message-ID: <73C6A3E13FB1DF4590E8CDCE8325130C1112AD41@EPRI17P32011A.csfb.cs-group.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130422/fb1f8cab/attachment.pl>

From arturo.didonna at gmail.com  Mon Apr 22 16:24:32 2013
From: arturo.didonna at gmail.com (Arturo DiDonna)
Date: Mon, 22 Apr 2013 16:24:32 +0200
Subject: [R-SIG-Finance] Stocks outperforming their index
Message-ID: <CACov-j-iNpXiUq_5LL2LAxJ8xFPbZH=nRF2g9hStaFFQ5_grmA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130422/989a8454/attachment.pl>

From michael.weylandt at gmail.com  Mon Apr 22 16:55:45 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Mon, 22 Apr 2013 15:55:45 +0100
Subject: [R-SIG-Finance] Stocks outperforming their index
In-Reply-To: <CACov-j-iNpXiUq_5LL2LAxJ8xFPbZH=nRF2g9hStaFFQ5_grmA@mail.gmail.com>
References: <CACov-j-iNpXiUq_5LL2LAxJ8xFPbZH=nRF2g9hStaFFQ5_grmA@mail.gmail.com>
Message-ID: <CAAmySGNz9WbWKYo1t86PGjBpQam7w8vLRwF=zr2L3GXcEMNGZQ@mail.gmail.com>

On Mon, Apr 22, 2013 at 3:24 PM, Arturo DiDonna
<arturo.didonna at gmail.com> wrote:
> I am sorry if this is a FAQ, but I am looking for a resource allowing to
> determine which stocks have out(under)performed their index by a given
> parameter over a certain period of time. Ideally, the r package should
> provide also some facility for data retrieval.
> Thanks in advance.

It's fairly canned, but I think

library(quantmod)
? getSymbols # Data retreival
? ROC # Convert Prices to returns
? runMean # running returns

get you there. Of course, you'll need to use > / < operators yourself,
but it's quite easily programmed.

Cheers,
MW


>
> Arturo.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From fabien.azoulay at gmail.com  Mon Apr 22 23:53:17 2013
From: fabien.azoulay at gmail.com (fabien azoulay)
Date: Mon, 22 Apr 2013 17:53:17 -0400
Subject: [R-SIG-Finance] RBBG bdp function with override
Message-ID: <CAJsDZUfyjPmaw8_bX2PuAzG+kiJVdzuBQL8cS5tT+-f-4Yxe7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130422/69053f23/attachment.pl>

From john.laing at gmail.com  Tue Apr 23 00:54:04 2013
From: john.laing at gmail.com (John Laing)
Date: Mon, 22 Apr 2013 18:54:04 -0400
Subject: [R-SIG-Finance] RBBG bdp function with override
In-Reply-To: <CAJsDZUfyjPmaw8_bX2PuAzG+kiJVdzuBQL8cS5tT+-f-4Yxe7Q@mail.gmail.com>
References: <CAJsDZUfyjPmaw8_bX2PuAzG+kiJVdzuBQL8cS5tT+-f-4Yxe7Q@mail.gmail.com>
Message-ID: <CAA3Wa=vwsBXUG6Sk22Q4J5q39GyAny0LCLwCBTZq7psxMtNFjw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130422/58d3dbbb/attachment.pl>

From fabien.azoulay at gmail.com  Tue Apr 23 01:31:39 2013
From: fabien.azoulay at gmail.com (fabien azoulay)
Date: Mon, 22 Apr 2013 19:31:39 -0400
Subject: [R-SIG-Finance] RBBG bdp function with override
In-Reply-To: <CAA3Wa=vwsBXUG6Sk22Q4J5q39GyAny0LCLwCBTZq7psxMtNFjw@mail.gmail.com>
References: <CAJsDZUfyjPmaw8_bX2PuAzG+kiJVdzuBQL8cS5tT+-f-4Yxe7Q@mail.gmail.com>
	<CAA3Wa=vwsBXUG6Sk22Q4J5q39GyAny0LCLwCBTZq7psxMtNFjw@mail.gmail.com>
Message-ID: <CAJsDZUfZgd4atJ2dVfPAdPOc36koBW9qKM_9dNGCMHnbZDzAnA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130422/c30f31a2/attachment.pl>

From pereira_rock at hotmail.com  Tue Apr 23 01:44:43 2013
From: pereira_rock at hotmail.com (Rock Pereira)
Date: Mon, 22 Apr 2013 19:44:43 -0400
Subject: [R-SIG-Finance] Error in quantmod getOptionChain()
Message-ID: <BAY160-W58A4568E3F5A51C107D4F0FDCB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130422/d6b46710/attachment.pl>

From jeff.a.ryan at gmail.com  Tue Apr 23 14:19:25 2013
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 23 Apr 2013 07:19:25 -0500
Subject: [R-SIG-Finance] Error in quantmod getOptionChain()
In-Reply-To: <BAY160-W58A4568E3F5A51C107D4F0FDCB0@phx.gbl>
References: <BAY160-W58A4568E3F5A51C107D4F0FDCB0@phx.gbl>
Message-ID: <CABDUZc_wduLmxMQKCBFneV4wXsFXs=j8RjKf3sxs=YivK55kig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130423/5a826cd8/attachment.pl>

From bill at easterngrain.com  Wed Apr 24 13:26:21 2013
From: bill at easterngrain.com (wlblount)
Date: Wed, 24 Apr 2013 04:26:21 -0700 (PDT)
Subject: [R-SIG-Finance] Length of a curve?
Message-ID: <1366802781461-4665208.post@n4.nabble.com>

how would i calculate the length of this plot for a trading day?  i am using
ibrokers data for stocks in 3 min. bars

library(quantmod)
load("~/R/UVXY")          #3 min xts  stock data

reg10 <- rollSFM(Cl(pricedata),seq(nrow(pricedata)),10)
rma10 <- reg10$alpha + reg10$beta*seq(nrow(pricedata))



i am looking for the length of the rma10 plot for one trading day (ie. if it
were a piece of string, the measurement once straightened out) .  i would
like to compare this measurement to the same measurement for previous days
(regular trading hours 9:30am-4:00pm).

sorry for the non-technical language.  Bill






--
View this message in context: http://r.789695.n4.nabble.com/Length-of-a-curve-tp4665208.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From michael.weylandt at gmail.com  Wed Apr 24 17:32:35 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Wed, 24 Apr 2013 16:32:35 +0100
Subject: [R-SIG-Finance] Length of a curve?
In-Reply-To: <1366802781461-4665208.post@n4.nabble.com>
References: <1366802781461-4665208.post@n4.nabble.com>
Message-ID: <CAAmySGMkZyWxs0kUrSaXTKFxQ_yvPrpGV_TbHi5KV8dZ0wAAXQ@mail.gmail.com>

On Wed, Apr 24, 2013 at 12:26 PM, wlblount <bill at easterngrain.com> wrote:
> how would i calculate the length of this plot for a trading day?  i am using
> ibrokers data for stocks in 3 min. bars
>
> library(quantmod)
> load("~/R/UVXY")          #3 min xts  stock data
>
> reg10 <- rollSFM(Cl(pricedata),seq(nrow(pricedata)),10)
> rma10 <- reg10$alpha + reg10$beta*seq(nrow(pricedata))
>
>
>
> i am looking for the length of the rma10 plot for one trading day (ie. if it
> were a piece of string, the measurement once straightened out) .  i would
> like to compare this measurement to the same measurement for previous days
> (regular trading hours 9:30am-4:00pm).
>
> sorry for the non-technical language.  Bill
>
>

I'd assume that, for regular data, you'd just add up the absolute
values of the differences between observations.

MW


From michael.weylandt at gmail.com  Wed Apr 24 17:35:19 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Wed, 24 Apr 2013 16:35:19 +0100
Subject: [R-SIG-Finance] Length of a curve?
In-Reply-To: <CAAmySGMkZyWxs0kUrSaXTKFxQ_yvPrpGV_TbHi5KV8dZ0wAAXQ@mail.gmail.com>
References: <1366802781461-4665208.post@n4.nabble.com>
	<CAAmySGMkZyWxs0kUrSaXTKFxQ_yvPrpGV_TbHi5KV8dZ0wAAXQ@mail.gmail.com>
Message-ID: <CAAmySGOVQHjSWbxz6__n1DN1vRcjTg0KnYrNxVHxK9TpUh-ykg@mail.gmail.com>

On Wed, Apr 24, 2013 at 4:32 PM, R. Michael Weylandt
<michael.weylandt at gmail.com> wrote:
> On Wed, Apr 24, 2013 at 12:26 PM, wlblount <bill at easterngrain.com> wrote:
>> how would i calculate the length of this plot for a trading day?  i am using
>> ibrokers data for stocks in 3 min. bars
>>
>> library(quantmod)
>> load("~/R/UVXY")          #3 min xts  stock data
>>
>> reg10 <- rollSFM(Cl(pricedata),seq(nrow(pricedata)),10)
>> rma10 <- reg10$alpha + reg10$beta*seq(nrow(pricedata))
>>
>>
>>
>> i am looking for the length of the rma10 plot for one trading day (ie. if it
>> were a piece of string, the measurement once straightened out) .  i would
>> like to compare this measurement to the same measurement for previous days
>> (regular trading hours 9:30am-4:00pm).
>>
>> sorry for the non-technical language.  Bill
>>
>>
>
> I'd assume that, for regular data, you'd just add up the absolute
> values of the differences between observations.
>

Sorry -- that's not quite correct. But the idea's right: to be the
length of a curve, you just want to do

sum(sqrt((dx)^2 + (dy)^2))

If your dx is constant, it's an easy enough calculation but you'll
need to define a 'conversion' from 3 minutes to distance and from
price differences to distance.

> MW


From howard.libby at gmail.com  Thu Apr 25 10:05:37 2013
From: howard.libby at gmail.com (Elizabeth Howard)
Date: Thu, 25 Apr 2013 10:05:37 +0200
Subject: [R-SIG-Finance] rmgarch package
In-Reply-To: <51486F8B.8080104@4dscape.com>
References: <CALBLFAXqBpnUb0x_TbB8h_w7jVCvJNGFvCr+XWRWHZ-yoaKjpA@mail.gmail.com>
	<51486F8B.8080104@4dscape.com>
Message-ID: <CALRcJNNgQZrD74XcPj+-ZYPxgcPiEdctXJ6J07UMh--dGjruOw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130425/b29c6217/attachment.pl>

From alexios at 4dscape.com  Thu Apr 25 10:11:34 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Thu, 25 Apr 2013 09:11:34 +0100
Subject: [R-SIG-Finance] rmgarch package
In-Reply-To: <CALRcJNNgQZrD74XcPj+-ZYPxgcPiEdctXJ6J07UMh--dGjruOw@mail.gmail.com>
References: <CALBLFAXqBpnUb0x_TbB8h_w7jVCvJNGFvCr+XWRWHZ-yoaKjpA@mail.gmail.com>
	<51486F8B.8080104@4dscape.com>
	<CALRcJNNgQZrD74XcPj+-ZYPxgcPiEdctXJ6J07UMh--dGjruOw@mail.gmail.com>
Message-ID: <5178E536.5050506@4dscape.com>

Hi Elizabeth,

rmgarch requires that you have R>= 3.0.0.

Regards,

Alexios

On 25/04/2013 09:05, Elizabeth Howard wrote:
> Hi Alexios,
>
> I trust you're well. I've recently tried installing the rmgarch (1.2-0)
> package from CRAN, but have the same problem as with the Google download
> (Warning message: package ?rmgarch? is not available (for R version
> 2.15.3)) despite doing the usual troubleshooting.
> Just checking if you have any further advice on this?
>
> Thanks a lot once again,
>
> Elizabeth
>
>
>
>
> On 19 March 2013 15:00, alexios ghalanos <alexios at 4dscape.com
> <mailto:alexios at 4dscape.com>> wrote:
>
>     rugarch and rmgarch are no longer hosted on r-forge (they have not
>     been for a few months now).
>     Download and install from:
>     code.google.com/p/rmgarch/ <http://code.google.com/p/rmgarch/>
>     code.google.com/p/rugarch/ <http://code.google.com/p/rugarch/>
>
>     -Alexios
>
>
>     On 19/03/2013 13:50, Iaa Maa wrote:
>
>         Hi all,
>
>         Any reason why rmgarch doesn't install?
>
>             *
>             install*<http://r.789695.n4.__nabble.com/quot-Multivariate-__Garch-quot-Package-in-r-__td4644495.html#
>             <http://r.789695.n4.nabble.com/quot-Multivariate-Garch-quot-Package-in-r-td4644495.html#>>
>
>         *.packages("rmgarch", repos="http://R-Forge.R-__project.org
>         <http://R-Forge.R-project.org>") *
>
>         *Installing package(s) into
>         ?C:/Users/Isaac/Documents/R/__win-library/2.15?
>         (as ?lib? is unspecified)
>         Warning message: package ?rmgarch? is not available (for R
>         version 2.15.3) *
>
>
>         I've tried with 2.15.1 and 2.15.2 as well.
>
>
>
>         Isaac
>
>                  [[alternative HTML version deleted]]
>
>
>
>         _________________________________________________
>         R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org>
>         mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-sig-finance
>         <https://stat.ethz.ch/mailman/listinfo/r-sig-finance>
>         -- Subscriber-posting only. If you want to post, subscribe first.
>         -- Also note that this is not the r-help list where general R
>         questions should go.
>
>
>     _________________________________________________
>     R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org>
>     mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-sig-finance
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-finance>
>     -- Subscriber-posting only. If you want to post, subscribe first.
>     -- Also note that this is not the r-help list where general R
>     questions should go.
>
>


From markknecht at gmail.com  Thu Apr 25 21:00:54 2013
From: markknecht at gmail.com (Mark Knecht)
Date: Thu, 25 Apr 2013 12:00:54 -0700
Subject: [R-SIG-Finance] quantStrat/blotter for R-3.0.0?
Message-ID: <CAK2H+ecK9_mYhJDq9pgQChMGzyDKPjVfJLEQfrib=PVpkx8PPw@mail.gmail.com>

Hi,
   Is there a good home page or Wiki for how folks are approaching
trading within R using quantStrat, TradeAnalytics, or something else?

   I'm working in RStudio/R-3.0-64-bit and am pretty much a putz when
it comes to R programming. However I've started developing something
that would never be tradable in TradeStation but might well work in R
one of these days so I thought maybe I should start learning a bit
more. Unfortunately when I attempt to install quantstrat & blotter
using the RStudio GUI from CRAN I get messages that they're not
available for R-3.0. Trade Analytics doesn't seem to show up at all.

   Am I pointed at the wrong place to get the packages, do I need to
downgrade R/R-Studio, or am I attempting to install the wrong thing? I
see quantStrat pages. I've also found Trade Analytics pages so I'm
thinking I need a pointer to the right place to start my education.

Thanks,
Mark


From michael.weylandt at gmail.com  Fri Apr 26 01:07:46 2013
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Fri, 26 Apr 2013 00:07:46 +0100
Subject: [R-SIG-Finance] quantStrat/blotter for R-3.0.0?
In-Reply-To: <CAK2H+ecK9_mYhJDq9pgQChMGzyDKPjVfJLEQfrib=PVpkx8PPw@mail.gmail.com>
References: <CAK2H+ecK9_mYhJDq9pgQChMGzyDKPjVfJLEQfrib=PVpkx8PPw@mail.gmail.com>
Message-ID: <490F9DA8-58B9-4C67-A0D0-B35AEC7959CB@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130426/3a46e851/attachment.pl>

From chinmay.patil at gmail.com  Fri Apr 26 02:38:14 2013
From: chinmay.patil at gmail.com (Chinmay Patil)
Date: Fri, 26 Apr 2013 08:38:14 +0800
Subject: [R-SIG-Finance] quantStrat/blotter for R-3.0.0?
In-Reply-To: <490F9DA8-58B9-4C67-A0D0-B35AEC7959CB@gmail.com>
References: <CAK2H+ecK9_mYhJDq9pgQChMGzyDKPjVfJLEQfrib=PVpkx8PPw@mail.gmail.com>
	<490F9DA8-58B9-4C67-A0D0-B35AEC7959CB@gmail.com>
Message-ID: <BE132774-A94C-436F-BE41-DA29AC09D343@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130426/e0e7365e/attachment.pl>

From ahmed_9473 at yahoo.com  Sun Apr 28 13:40:43 2013
From: ahmed_9473 at yahoo.com (ahmed sedky)
Date: Sun, 28 Apr 2013 04:40:43 -0700 (PDT)
Subject: [R-SIG-Finance] robust  estimation of DCC GARCH model
Message-ID: <1367149243.57833.YahooMailNeo@web121002.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130428/77237493/attachment.pl>

From john.xiaohan at gmail.com  Sun Apr 28 15:54:51 2013
From: john.xiaohan at gmail.com (John Han)
Date: Sun, 28 Apr 2013 09:54:51 -0400
Subject: [R-SIG-Finance] Issues about "maCross" demo in Quantstrat
Message-ID: <CAHwi5XhEdUU3-LTEws7yqz2FonRUyZRD-JQQrF0-_sFzAhyYCg@mail.gmail.com>

Hi,

I ran the demo "maCross" successfully in R. When I enable the commented
code, it works also OK and I suppose to get both long and short position
happening in the backtesting result.
[image: Inline image 1]

However, I can only see either long or short and never happen at the same
time. It seems like that the "exit" and new "entry" can not be at the same
day.
Any insights? The code in the graph is the only part I changed.

Thanks a lot.
-- 

Sincerely,
John Han
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130428/229887fc/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 20399 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130428/229887fc/attachment.png>

From markknecht at gmail.com  Sun Apr 28 20:22:16 2013
From: markknecht at gmail.com (Mark Knecht)
Date: Sun, 28 Apr 2013 11:22:16 -0700
Subject: [R-SIG-Finance] Issues about "maCross" demo in Quantstrat
In-Reply-To: <CAHwi5XhEdUU3-LTEws7yqz2FonRUyZRD-JQQrF0-_sFzAhyYCg@mail.gmail.com>
References: <CAHwi5XhEdUU3-LTEws7yqz2FonRUyZRD-JQQrF0-_sFzAhyYCg@mail.gmail.com>
Message-ID: <CAK2H+edtFsRbQVtPC=T79M1t_vtcC8q2f55CE7P1usJCHnVm1Q@mail.gmail.com>

On Sun, Apr 28, 2013 at 6:54 AM, John Han <john.xiaohan at gmail.com> wrote:
>
> Hi,
>
> I ran the demo "maCross" successfully in R. When I enable the commented code, it works also OK and I suppose to get both long and short position happening in the backtesting result.
>
>
> However, I can only see either long or short and never happen at the same time. It seems like that the "exit" and new "entry" can not be at the same day.
> Any insights? The code in the graph is the only part I changed.
>
> Thanks a lot.
> --
>
> Sincerely,
> John Han
>


Hi John,
   I don't know but that demo doesn't seem to generate shorts for me
either. However there seem to be a number of small inconsistencies in
the code and the current documentation isn't easy to understand. (For
me anyway) The following is based on me running R ver 2.15.3

1) I get some errors starting the run in the first few lines which may
be caused by some package not being explicitly loaded?

> initPortf(portfolio.st,symbols=stock.str, initDate=initDate)
Error in exists(paste("portfolio", name, sep = "."), envir = .blotter,  :
  object '.blotter' not found
> initAcct(account.st,portfolios=portfolio.st, initDate=initDate)
Error in exists(paste("account", name, sep = "."), envir = .blotter,
inherits = TRUE) :
  object '.blotter' not found
> initOrders(portfolio=portfolio.st,initDate=initDate)
Error in getPortfolio(portfolio) :
  Portfolio macross  not found, use initPortf() to create a new portfolio

2) The crossover rules use 'columns' and 'column'. Not sure if that
affects the underlying stratMACROSS structure.

3) The long entry/exit uses 100/all, which the short uses -100/100.
Why the inconsistency?

4) Really it's an initialization issue but in the rules greater
than/less than isn't the same as crosses above/crosses below. I'm
unclear if that's somehow handled in the code setup. Maybe this is
handled by name="sigCrossover", but the relationship="gte"/"lt"
implies (to me) just a logical check. (Would like to find the right
docs to better understand that.

5) In RStudio I don't know how to make sense of the stratMACROSS
structure. It's fairly unreadable to my old eyes.

6) It seems that chart.Posn command doesn't actually draw anything
until I run at least one of the add.SMA commands.

   Overall I'm actually pretty excited about all the capabilities
these geniuses are trying to give us. However right now it's a
learning experience.

HTH,
Mark


From darkoowusu at yahoo.com  Mon Apr 29 08:34:15 2013
From: darkoowusu at yahoo.com (Owusu Darko)
Date: Sun, 28 Apr 2013 23:34:15 -0700 (PDT)
Subject: [R-SIG-Finance] fitting AR-GARCH model to data with seasonal
	variation in FGARCH.
Message-ID: <1367217255.30865.YahooMailNeo@web125704.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130428/a513f105/attachment.pl>

From deo.jaiswal at gmail.com  Tue Apr 30 11:48:49 2013
From: deo.jaiswal at gmail.com (Deo Jaiswal)
Date: Tue, 30 Apr 2013 05:48:49 -0400
Subject: [R-SIG-Finance] Question on QuantStrat
Message-ID: <CAPMHGQw_Hrs=K1qA_FX4qdboVhFMdvtS8ckSJoh40Wd4YE4T4g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130430/5cf77af5/attachment.pl>

From alok1511 at gmail.com  Tue Apr 30 12:26:02 2013
From: alok1511 at gmail.com (Alok Shah)
Date: Tue, 30 Apr 2013 15:56:02 +0530
Subject: [R-SIG-Finance] maximizing the returns to a portfolio given a
	target risk
Message-ID: <CAP1e-visAS4LOEh6NVf7r1QDYVGUxEdEsDt+LUQq=Tez3V3E2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130430/1a2b6290/attachment.pl>

From katherine_gobin at yahoo.com  Tue Apr 30 18:50:25 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Wed, 1 May 2013 00:50:25 +0800 (SGT)
Subject: [R-SIG-Finance] CLEAN price of Bond in r
Message-ID: <1367340625.47572.YahooMailClassic@web193203.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130501/c188e527/attachment.pl>

From paulteetor at yahoo.com  Tue Apr 30 20:54:35 2013
From: paulteetor at yahoo.com (Paul Teetor)
Date: Tue, 30 Apr 2013 11:54:35 -0700 (PDT)
Subject: [R-SIG-Finance] CLEAN price of Bond in r
In-Reply-To: <1367340625.47572.YahooMailClassic@web193203.mail.sg3.yahoo.com>
References: <1367340625.47572.YahooMailClassic@web193203.mail.sg3.yahoo.com>
Message-ID: <1367348075.15888.YahooMailNeo@web160903.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130430/5907d32e/attachment.pl>

From darkoowusu at yahoo.com  Tue Apr 30 21:58:53 2013
From: darkoowusu at yahoo.com (Owusu Darko)
Date: Tue, 30 Apr 2013 12:58:53 -0700 (PDT)
Subject: [R-SIG-Finance] FITTING AR-GARCH model to data with specified AR
	terms.
In-Reply-To: <1367217255.30865.YahooMailNeo@web125704.mail.ne1.yahoo.com>
References: <1367217255.30865.YahooMailNeo@web125704.mail.ne1.yahoo.com>
Message-ID: <1367351933.91284.YahooMailNeo@web125701.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130430/a0285bd6/attachment.pl>

From matthieu.stigler at gmail.com  Fri May  3 10:25:31 2013
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Fri, 3 May 2013 10:25:31 +0200
Subject: [R-SIG-Finance] Using adf.test to test time series stationarity
 of stock price
In-Reply-To: <5174814B.9050409@braverock.com>
References: <D04F7CC1-3F00-4499-9AC0-239C73AEDA15@stanford.edu>
	<5174814B.9050409@braverock.com>
Message-ID: <CAEYvig+hrDqKGXaetr=H=vy1FYsXiuB60hSkZoDt6L3L31od8Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130503/df19fc60/attachment.pl>

From jonpsparks at gmail.com  Fri May  3 15:48:20 2013
From: jonpsparks at gmail.com (Jonathan Sparks)
Date: Fri, 3 May 2013 14:48:20 +0100
Subject: [R-SIG-Finance] Z
Message-ID: <F533E7A1-6A2D-42CD-A510-E0C04F9F3A14@gmail.com>



Sent from my iPhone


From leijin56 at hotmail.com  Fri May  3 20:19:45 2013
From: leijin56 at hotmail.com (Lei Jin)
Date: Fri, 3 May 2013 11:19:45 -0700
Subject: [R-SIG-Finance] error in updatePortf()
In-Reply-To: <BAY403-EAS135A1A6C53DD963B293098C1BD0@phx.gbl>
References: <BAY403-EAS135A1A6C53DD963B293098C1BD0@phx.gbl>
Message-ID: <BAY150-W3804F4681D5C6051B6DC81C1BE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130503/ae5eab92/attachment.pl>

From adrian at trapletti.org  Sat May  4 16:41:54 2013
From: adrian at trapletti.org (Adrian Trapletti)
Date: Sat, 4 May 2013 16:41:54 +0200
Subject: [R-SIG-Finance] Using adf.test to test time series stationarity
 of stock price
Message-ID: <51851E32.2060101@trapletti.org>

Hi Matthieu

For me it looks like adf.test does not correctly handle xts and/or zoo 
inputs due to the subsetting code:

 > adf.test(stock2[,1])

         Augmented Dickey-Fuller Test

data:  stock2[, 1]
Dickey-Fuller = 2.7174, Lag order = 12, p-value = 0.99
alternative hypothesis: stationary

Warning message:
In adf.test(stock2[, 1]) : p-value greater than printed p-value
 > adf.test(unclass(stock2[,1]))

         Augmented Dickey-Fuller Test

data:  unclass(stock2[, 1])
Dickey-Fuller = -2.4579, Lag order = 12, p-value = 0.3845
alternative hypothesis: stationary

At the time when adf.test was written neither xts nor zoo existed. A 
quick fix is to revise the documentation of adf.test: "x: a numeric 
vector."

Best regards
Adrian

> Date: Fri, 3 May 2013 10:25:31 +0200
> From: Matthieu Stigler<matthieu.stigler at gmail.com>
> To: "Brian G. Peterson"<brian at braverock.com>,yitaoz at stanford.edu,
> 	Kurt.Hornik at r-project.org
> Cc:"r-sig-finance at r-project.org"  <r-sig-finance at r-project.org>
> Subject: Re: [R-SIG-Finance] Using adf.test to test time series
> 	stationarity of stock price
> Message-ID:
> 	<CAEYvig+hrDqKGXaetr=H=vy1FYsXiuB60hSkZoDt6L3L31od8Q at mail.gmail.com>
> Content-Type: text/plain
>
> Hi
>
> With our stated background in stats, we should have realised that the
> result you obtain is indeed surprising, since your t-stat is large, but
> positive! A positive t-stat implies actually that your rho is bigger than
> 1... So in this case, you will not reject the alternative of stationarity,
> but that of explosivity, try:
>
> adf.test(stock2[,1], alternative="explosive")
>
> That said, we should have also realised that results in adf.test seem to be
> incorrect,  since they do not correspond to the ones in:
> library(urca)
> ur.df(stock2[,1], lags=12, type="trend")
> # or the corresponding "ADF" regression from tsDyn:
> library(tsDyn)
> ar_ts <- linear(stock2[,1], m=12, include="both", type="ADF")
> summary(ar_ts)$coef["phi.1",]
>
> Both urca and tsDyn agree closely on the t-stat, at -2.4578550 for urca,
> and -2.466884912 for tsDyn (differences come from the way of counting
> degrees of freedom, urca discards the initial values, while tsDyn does not,
> as in ar()). Looking closer at the code of adf.test(), it looks like the
> regression is \Delta y_t = const + trend + y_t while I would have expected
> a y_{t-1}. I guess code should be corrected as:
>      xt1 <- x[(k-1):(n-1)]
> instead of
>      xt1 <- x[k:n]
>
> once this done, adf.test does correspond to the others. And now Brian's
> point that prices are usually non-stationary holds.
>
> I am ccing the maintainer of tseries on this.
>
> Best
>
> Matthieu
>
>
>
>
> 2013/4/22 Brian G. Peterson<brian at braverock.com>
>
>> On 04/21/2013 06:28 PM, Yitao Zhang wrote:
>>
>>> Hey guys,
>>>
>>> I'm trying to do a augmented Dickey-Fuller test to test the stationarity
>>> of a stock price.
>>>
>> With your stated economics background, one would assume that you'd realize
>> that price is almost never stationary.
>>
>> Perhaps try on returns?
>>
>> --
>> Brian G. Peterson
>> http://braverock.com/brian/
>> Ph: 773-459-4973
>> IM: bgpbraverock
>>
>>
>> ______________________________**_________________
>> R-SIG-Finance at r-project.org  mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-sig-finance<https://stat.ethz.ch/mailman/listinfo/r-sig-finance>
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>

-- 
Dr. Adrian Trapletti
Steinstrasse 9b
CH-8610 Uster
Switzerland

Phone : +41 (0) 44 9945630
Mobile : +41 (0) 79 1037131

Email : adrian at trapletti.org
WWW : www.trapletti.org


From matthieu.stigler at gmail.com  Sat May  4 17:38:58 2013
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Sat, 4 May 2013 17:38:58 +0200
Subject: [R-SIG-Finance] Using adf.test to test time series stationarity
 of stock price
In-Reply-To: <51851E32.2060101@trapletti.org>
References: <51851E32.2060101@trapletti.org>
Message-ID: <CAEYvigLXbqFZAW73ULYBrdsSrn7x4eWVJgGzhAdn_XbdQ-2+fg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130504/a0616361/attachment.pl>

From nikos.rachmanis at gmail.com  Mon May  6 09:12:44 2013
From: nikos.rachmanis at gmail.com (Nikos Rachmanis)
Date: Mon, 06 May 2013 03:12:44 -0400
Subject: [R-SIG-Finance] Cumulative return
Message-ID: <518757EC.8020508@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130506/793b8fad/attachment.pl>

From chinmay.patil at gmail.com  Mon May  6 09:17:33 2013
From: chinmay.patil at gmail.com (Chinmay Patil)
Date: Mon, 6 May 2013 15:17:33 +0800
Subject: [R-SIG-Finance] Cumulative return
In-Reply-To: <518757EC.8020508@gmail.com>
References: <518757EC.8020508@gmail.com>
Message-ID: <CA+kDFFXj3YFUGi30id0RpJBSk0jRTH3EqrqveeKUrNF3OOdVPg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130506/b90b71e3/attachment.pl>

From chinmay.patil at gmail.com  Mon May  6 09:18:47 2013
From: chinmay.patil at gmail.com (Chinmay Patil)
Date: Mon, 6 May 2013 15:18:47 +0800
Subject: [R-SIG-Finance] Cumulative return
In-Reply-To: <CA+kDFFXj3YFUGi30id0RpJBSk0jRTH3EqrqveeKUrNF3OOdVPg@mail.gmail.com>
References: <518757EC.8020508@gmail.com>
	<CA+kDFFXj3YFUGi30id0RpJBSk0jRTH3EqrqveeKUrNF3OOdVPg@mail.gmail.com>
Message-ID: <CA+kDFFWynzQnXp3pdNVeuWoWVLy-RjEqHJZRMoOh+zWvN9vs4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130506/8321c268/attachment.pl>

From adrian at trapletti.org  Mon May  6 14:50:41 2013
From: adrian at trapletti.org (Adrian Trapletti)
Date: Mon, 6 May 2013 14:50:41 +0200
Subject: [R-SIG-Finance] Using adf.test to test time series stationarity
 of stock price
In-Reply-To: <CAEYvigLXbqFZAW73ULYBrdsSrn7x4eWVJgGzhAdn_XbdQ-2+fg@mail.gmail.com>
References: <51851E32.2060101@trapletti.org>
	<CAEYvigLXbqFZAW73ULYBrdsSrn7x4eWVJgGzhAdn_XbdQ-2+fg@mail.gmail.com>
Message-ID: <5187A721.1010109@trapletti.org>

Matthieu,

Thank you for the suggestion.We are going to revise the code.

Best regards
Adrian

On 05/04/2013 05:38 PM, Matthieu Stigler wrote:
> Hi Adrian!
>
> Well spotted! Indeed, the issue comes from the fact that diff.xts 
> keeps the first NA (as has na.pad=TRUE), while diff.zoo does not 
> (na.pad=FALSE), as well as na.ts ...
>
> A simple solution seems to be to add then:
> diff(y, na.pad=FALSE)
> or simply:
> y<- y[!is.na <http://is.na>(y)]
>
> which seems to lead to correct results in both cases, but I haven't 
> tested thoroughly...
>
> Best
>
>
> 2013/5/4 Adrian Trapletti <adrian at trapletti.org 
> <mailto:adrian at trapletti.org>>
>
>     Hi Matthieu
>
>     For me it looks like adf.test does not correctly handle xts and/or
>     zoo inputs due to the subsetting code:
>
>     > adf.test(stock2[,1])
>
>             Augmented Dickey-Fuller Test
>
>     data:  stock2[, 1]
>     Dickey-Fuller = 2.7174, Lag order = 12, p-value = 0.99
>     alternative hypothesis: stationary
>
>     Warning message:
>     In adf.test(stock2[, 1]) : p-value greater than printed p-value
>     > adf.test(unclass(stock2[,1]))
>
>             Augmented Dickey-Fuller Test
>
>     data:  unclass(stock2[, 1])
>     Dickey-Fuller = -2.4579, Lag order = 12, p-value = 0.3845
>     alternative hypothesis: stationary
>
>     At the time when adf.test was written neither xts nor zoo existed.
>     A quick fix is to revise the documentation of adf.test: "x: a
>     numeric vector."
>
>     Best regards
>     Adrian
>
>         Date: Fri, 3 May 2013 10:25:31 +0200
>         From: Matthieu Stigler<matthieu.stigler at gmail.com
>         <mailto:matthieu.stigler at gmail.com>>
>         To: "Brian G. Peterson"<brian at braverock.com
>         <mailto:brian at braverock.com>>,yitaoz at stanford.edu
>         <mailto:yitaoz at stanford.edu>,
>         Kurt.Hornik at r-project.org <mailto:Kurt.Hornik at r-project.org>
>         Cc:"r-sig-finance at r-project.org
>         <mailto:r-sig-finance at r-project.org>"
>          <r-sig-finance at r-project.org
>         <mailto:r-sig-finance at r-project.org>>
>         Subject: Re: [R-SIG-Finance] Using adf.test to test time series
>                 stationarity of stock price
>         Message-ID:
>                
>         <CAEYvig+hrDqKGXaetr=H=vy1FYsXiuB60hSkZoDt6L3L31od8Q at mail.gmail.com
>         <mailto:vy1FYsXiuB60hSkZoDt6L3L31od8Q at mail.gmail.com>>
>         Content-Type: text/plain
>
>         Hi
>
>         With our stated background in stats, we should have realised
>         that the
>         result you obtain is indeed surprising, since your t-stat is
>         large, but
>         positive! A positive t-stat implies actually that your rho is
>         bigger than
>         1... So in this case, you will not reject the alternative of
>         stationarity,
>         but that of explosivity, try:
>
>         adf.test(stock2[,1], alternative="explosive")
>
>         That said, we should have also realised that results in
>         adf.test seem to be
>         incorrect,  since they do not correspond to the ones in:
>         library(urca)
>         ur.df(stock2[,1], lags=12, type="trend")
>         # or the corresponding "ADF" regression from tsDyn:
>         library(tsDyn)
>         ar_ts <- linear(stock2[,1], m=12, include="both", type="ADF")
>         summary(ar_ts)$coef["phi.1",]
>
>         Both urca and tsDyn agree closely on the t-stat, at -2.4578550
>         for urca,
>         and -2.466884912 <tel:2.466884912> for tsDyn (differences come
>         from the way of counting
>         degrees of freedom, urca discards the initial values, while
>         tsDyn does not,
>         as in ar()). Looking closer at the code of adf.test(), it
>         looks like the
>         regression is \Delta y_t = const + trend + y_t while I would
>         have expected
>         a y_{t-1}. I guess code should be corrected as:
>              xt1 <- x[(k-1):(n-1)]
>         instead of
>              xt1 <- x[k:n]
>
>         once this done, adf.test does correspond to the others. And
>         now Brian's
>         point that prices are usually non-stationary holds.
>
>         I am ccing the maintainer of tseries on this.
>
>         Best
>
>         Matthieu
>
>
>
>
>         2013/4/22 Brian G. Peterson<brian at braverock.com
>         <mailto:brian at braverock.com>>
>
>             On 04/21/2013 06:28 PM, Yitao Zhang wrote:
>
>                 Hey guys,
>
>                 I'm trying to do a augmented Dickey-Fuller test to
>                 test the stationarity
>                 of a stock price.
>
>             With your stated economics background, one would assume
>             that you'd realize
>             that price is almost never stationary.
>
>             Perhaps try on returns?
>
>             --
>             Brian G. Peterson
>             http://braverock.com/brian/
>             Ph: 773-459-4973 <tel:773-459-4973>
>             IM: bgpbraverock
>
>
>             ______________________________**_________________
>             R-SIG-Finance at r-project.org
>             <mailto:R-SIG-Finance at r-project.org>  mailing list
>             https://stat.ethz.ch/mailman/**listinfo/r-sig-finance<https://stat.ethz.ch/mailman/listinfo/r-sig-finance>
>             -- Subscriber-posting only. If you want to post, subscribe
>             first.
>             -- Also note that this is not the r-help list where
>             general R questions
>             should go.
>
>
>     -- 
>     Dr. Adrian Trapletti
>     Steinstrasse 9b
>     CH-8610 Uster
>     Switzerland
>
>     Phone : +41 (0) 44 9945630 <tel:%2B41%20%280%29%2044%209945630>
>     Mobile : +41 (0) 79 1037131 <tel:%2B41%20%280%29%2079%201037131>
>
>     Email : adrian at trapletti.org <mailto:adrian at trapletti.org>
>     WWW : www.trapletti.org <http://www.trapletti.org>
>
>     _______________________________________________
>     R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org>
>     mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>     -- Subscriber-posting only. If you want to post, subscribe first.
>     -- Also note that this is not the r-help list where general R
>     questions should go.
>
>

-- 
Dr. Adrian Trapletti
Steinstrasse 9b
CH-8610 Uster
Switzerland

Phone : +41 (0) 44 9945630
Mobile : +41 (0) 79 1037131

Email : adrian at trapletti.org
WWW : www.trapletti.org


From nikos.rachmanis at gmail.com  Mon May  6 17:53:50 2013
From: nikos.rachmanis at gmail.com (Nikos Rachmanis)
Date: Mon, 6 May 2013 11:53:50 -0400
Subject: [R-SIG-Finance] Cumulative return
In-Reply-To: <CA+kDFFWynzQnXp3pdNVeuWoWVLy-RjEqHJZRMoOh+zWvN9vs4w@mail.gmail.com>
References: <518757EC.8020508@gmail.com>
	<CA+kDFFXj3YFUGi30id0RpJBSk0jRTH3EqrqveeKUrNF3OOdVPg@mail.gmail.com>
	<CA+kDFFWynzQnXp3pdNVeuWoWVLy-RjEqHJZRMoOh+zWvN9vs4w@mail.gmail.com>
Message-ID: <CAC=5KeKZkZJ-+JtOs5pLZc9WKet4K2HaqYfnCW_1kdoEz83hFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130506/76753141/attachment.pl>

From neumancohu at gmail.com  Tue May  7 13:15:18 2013
From: neumancohu at gmail.com (Neuman Co)
Date: Tue, 7 May 2013 13:15:18 +0200
Subject: [R-SIG-Finance] rugarch VaR calculation "manually"
Message-ID: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>

I am using the rugarch package in R and I have some questions:

I want to use the rugarch package to calculate the VaR.

I used the following code to to fit a certain model:

spec2<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
c(1, 1)),
mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
distribution.model =
"norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))

model2<-ugarchfit(spec=spec2,data=mydata)

Now I can look at the 2.5 % VaR with the following command:
plot(model)

and choosing the second plot.

Now my first question is: How can I get the 1.0% VaR VALUES, so not
the plot, but
the values/numbers?

In case of the normal distribution, one can easily do the calculation of
the VaR with using the forecasted conditional volatility and the forecasted
conditional mean:

I use the ugarchforecast command and with that I can get the cond. volatility
and cond. mean (my mean equation is an modified ARMA(5,5), see above in the spec
command):

forecast = ugarchforecast(spec, data, n.roll = , n.ahead = , out.sample=)

# conditional mean
cmu = as.numeric(as.data.frame(forecast, which = "series",
rollframe="all", aligned = FALSE))
# conditional sigma
csigma = as.numeric(as.data.frame(forecast, which = "sigma",
rollframe="all", aligned = FALSE))

I can calculate the VaR by using the property, that the normal distribution
is part of the location-scale distribution families

# use location+scaling transformation property of normal distribution:
VaR = qnorm(0.01)*csigma + cmu

My second question belongs to the n.roll and out.sample command. I had
a look at the
description http://www.inside-r.org/packages/cran/rugarch/docs/ugarchforecast
but I did not understand the n.roll and out.sample command. I want to
calculate the
daily VaR, so I need one step ahead predicitons and I do not want to reestimate
the model every time step. So what does it mean "to roll the forecast
1 step " and
what is out.sample?

My third question(s) is (are): How to calculate the VaR in case of a
standardized
hyperbolic distribution? Can I still calculate it like in the normal case
or does it not work anymore (I am not sure, if the sdhyp belongs to the
location-scale family).

Even if it does work (so if the sdhyp belongs to the family of
location-scale distributions) how do I calculate it in case of a
distribution, which does not belong to the location-scale family?
(I mean, if I cannot calculate it via VaR = uncmean + sigma* z_alpha how
do I have to calculate it). Which distribution implemented in the rugarch
package does not belong to the location-scale family?

Thanks a lot for your help!


From alexios at 4dscape.com  Tue May  7 13:35:27 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Tue, 07 May 2013 12:35:27 +0100
Subject: [R-SIG-Finance] rugarch VaR calculation "manually"
In-Reply-To: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>
References: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>
Message-ID: <5188E6FF.7040304@4dscape.com>

Hello,

On 07/05/2013 12:15, Neuman Co wrote:
> I am using the rugarch package in R and I have some questions:
>
> I want to use the rugarch package to calculate the VaR.
>
> I used the following code to to fit a certain model:
>
> spec2<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
> c(1, 1)),
> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
> distribution.model =
> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>
> model2<-ugarchfit(spec=spec2,data=mydata)
>
> Now I can look at the 2.5 % VaR with the following command:
> plot(model)
>
> and choosing the second plot.
>
> Now my first question is: How can I get the 1.0% VaR VALUES, so not
> the plot, but
> the values/numbers?
Use the 'quantile' method i.e. 'quantile(model2, 0.01)'...also applies 
to uGARCHforecast, uGARCHsim etc It IS documented.
>
> In case of the normal distribution, one can easily do the calculation of
> the VaR with using the forecasted conditional volatility and the forecasted
> conditional mean:
>
> I use the ugarchforecast command and with that I can get the cond. volatility
> and cond. mean (my mean equation is an modified ARMA(5,5), see above in the spec
> command):
>
> forecast = ugarchforecast(spec, data, n.roll = , n.ahead = , out.sample=)
>
> # conditional mean
> cmu = as.numeric(as.data.frame(forecast, which = "series",
> rollframe="all", aligned = FALSE))
> # conditional sigma
> csigma = as.numeric(as.data.frame(forecast, which = "sigma",
> rollframe="all", aligned = FALSE))
>
NO. 'as.data.frame' has long been deprecated. Use the 'sigma' and 
'fitted' methods (and make sure you upgrade to latest version of rugarch).

> I can calculate the VaR by using the property, that the normal distribution
> is part of the location-scale distribution families
>
> # use location+scaling transformation property of normal distribution:
> VaR = qnorm(0.01)*csigma + cmu
>
> My second question belongs to the n.roll and out.sample command. I had
> a look at the
> description http://www.inside-r.org/packages/cran/rugarch/docs/ugarchforecast
> but I did not understand the n.roll and out.sample command. I want to
> calculate the
> daily VaR, so I need one step ahead predicitons and I do not want to reestimate
> the model every time step. So what does it mean "to roll the forecast
> 1 step " and
> what is out.sample?
out.sample, which is used in the estimation stage retains 'out.sample' 
data (i.e. they are not used in the estimation) so that a rolling 
forecast can then be performed using this data. 'Rolling' means using 
data at time T-p (p=lag) to create a conditional 1-ahead forecast at 
time T. For the ugarchforecast method, this means using only estimates 
of the parameters from length(data)-out.sample. There is no 
re-estimation taking place (this is only done in the ugarchroll method).
For n.ahead>1, this becomes an unconditional forecast. Equivalently, you 
can append new data to your old dataset and use the ugarchfilter method.
>
> My third question(s) is (are): How to calculate the VaR in case of a
> standardized
> hyperbolic distribution? Can I still calculate it like in the normal case
> or does it not work anymore (I am not sure, if the sdhyp belongs to the
> location-scale family).
>
> Even if it does work (so if the sdhyp belongs to the family of
> location-scale distributions) how do I calculate it in case of a
> distribution, which does not belong to the location-scale family?
> (I mean, if I cannot calculate it via VaR = uncmean + sigma* z_alpha how
> do I have to calculate it). Which distribution implemented in the rugarch
> package does not belong to the location-scale family?
>
ALL distributions in the rugarch package are represented in a location- 
and scale- invariant parameterization since this is a key property 
required in working with the standardized residuals in the density 
function (i.e. the subtraction of the mean and scaling by the volatility).
The standardized Generalized Hyperbolic distribution does indeed have 
this property, and details are available in the vignette. See also paper 
by Blaesild (http://biomet.oxfordjournals.org/content/68/1/251.short) 
for the linear transformation (aX+b) property.

If working with the standard (NOT standardized) version of the GH 
distribution (\lambda, \alpha, \beta, \delta, \mu) you need to apply the 
location/scaling transformation as the example below shows which is 
equivalent to just using the location/scaling transformation in the 
standardized version:
#################################################
library(rugarch)
# zeta = shape
zeta = 0.4
# rho = skew
rho = 0.9
# lambda = GIG mixing distribution shape parameter
lambda=-1
# POSITIVE scaling factor (sigma is in any always positive)
# mean
scaling = 0.02
# sigma
location = 0.001

# standardized transformation based on (0,1,\rho,\zeta)
# parameterization:
x1 = scaling*qdist("ghyp", seq(0.001, 0.5, length.out=100), shape = 
zeta, skew = rho, lambda = lambda)+location
# Equivalent to standard transformation:
# First obtain the standard parameters (which have a mean of zero
# and sigma of 1).
parms = rugarch:::.paramGH(zeta, rho, lambda)
x2 = rugarch:::.qgh( seq(0.001, 0.5, length.out=100), alpha = 
parms[1]/abs(scaling), beta = parms[2]/abs(scaling), 
delta=abs(scaling)*parms[3], mu = (scaling)*parms[4]+location, lambda = 
lambda)
all.equal(x1, x2)
# Notice the approximation error in the calculation of the quantile for 
# which there is no closed form solution (and rugarch uses a tolerance
# value of .Machine$double.eps^0.25)
# Load the GeneralizedHyperbolic package of Scott to adjust the
# tolerance:
library(GeneralizedHyperbolic)

x1 = location+scaling*qghyp(seq(0.001, 0.5, length.out=100), mu = 
parms[4], delta = parms[3], alpha =  parms[1], beta = parms[2], lambda = 
lambda, lower.tail = TRUE, method = c("spline", "integrate")[2], 
nInterpol = 501, subdivisions = 500, uniTol = 2e-12)
# equivalent to:
x2 = qghyp(seq(0.001, 0.5, length.out=100), mu = 
(scaling)*parms[4]+location, delta = abs(scaling)*parms[3], alpha = 
parms[1]/abs(scaling), beta = parms[2]/abs(scaling), lambda = lambda, 
lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 
501, subdivisions = 500, uniTol = 2e-12)

all.equal(x1, x2)
#################################################


> Thanks a lot for your help!
>

Regards,

Alexios
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From neumancohu at gmail.com  Tue May  7 13:51:56 2013
From: neumancohu at gmail.com (Neuman Co)
Date: Tue, 7 May 2013 13:51:56 +0200
Subject: [R-SIG-Finance] rugarch VaR calculation "manually"
In-Reply-To: <5188E6FF.7040304@4dscape.com>
References: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>
	<5188E6FF.7040304@4dscape.com>
Message-ID: <CADih64RY4XoytMMpmPpO6sEW245oW=3SpWUKDmiupDKcbD6jEA@mail.gmail.com>

thanks a lot for your help, but
"Use the 'sigma' and 'fitted' methods"

But these are the fitted values for the volatility and the final
fitted values. But to calculate the VaR I need the 1 step ahead
forecast of the cond. sigmas and the 1 step ahead forecast of the
cond. mean. The cond.mean is not equivalent to the fitted values? And
the fitted values are not one step ahead forecasts?

2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
> Hello,
>
>
> On 07/05/2013 12:15, Neuman Co wrote:
>>
>> I am using the rugarch package in R and I have some questions:
>>
>> I want to use the rugarch package to calculate the VaR.
>>
>> I used the following code to to fit a certain model:
>>
>> spec2<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>> c(1, 1)),
>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>> distribution.model =
>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>
>> model2<-ugarchfit(spec=spec2,data=mydata)
>>
>> Now I can look at the 2.5 % VaR with the following command:
>> plot(model)
>>
>> and choosing the second plot.
>>
>> Now my first question is: How can I get the 1.0% VaR VALUES, so not
>> the plot, but
>> the values/numbers?
>
> Use the 'quantile' method i.e. 'quantile(model2, 0.01)'...also applies to
> uGARCHforecast, uGARCHsim etc It IS documented.
>
>>
>> In case of the normal distribution, one can easily do the calculation of
>> the VaR with using the forecasted conditional volatility and the
>> forecasted
>> conditional mean:
>>
>> I use the ugarchforecast command and with that I can get the cond.
>> volatility
>> and cond. mean (my mean equation is an modified ARMA(5,5), see above in
>> the spec
>> command):
>>
>> forecast = ugarchforecast(spec, data, n.roll = , n.ahead = , out.sample=)
>>
>> # conditional mean
>> cmu = as.numeric(as.data.frame(forecast, which = "series",
>> rollframe="all", aligned = FALSE))
>> # conditional sigma
>> csigma = as.numeric(as.data.frame(forecast, which = "sigma",
>> rollframe="all", aligned = FALSE))
>>
> NO. 'as.data.frame' has long been deprecated. Use the 'sigma' and 'fitted'
> methods (and make sure you upgrade to latest version of rugarch).
>
>
>> I can calculate the VaR by using the property, that the normal
>> distribution
>> is part of the location-scale distribution families
>>
>> # use location+scaling transformation property of normal distribution:
>> VaR = qnorm(0.01)*csigma + cmu
>>
>> My second question belongs to the n.roll and out.sample command. I had
>> a look at the
>> description
>> http://www.inside-r.org/packages/cran/rugarch/docs/ugarchforecast
>> but I did not understand the n.roll and out.sample command. I want to
>> calculate the
>> daily VaR, so I need one step ahead predicitons and I do not want to
>> reestimate
>> the model every time step. So what does it mean "to roll the forecast
>> 1 step " and
>> what is out.sample?
>
> out.sample, which is used in the estimation stage retains 'out.sample' data
> (i.e. they are not used in the estimation) so that a rolling forecast can
> then be performed using this data. 'Rolling' means using data at time T-p
> (p=lag) to create a conditional 1-ahead forecast at time T. For the
> ugarchforecast method, this means using only estimates of the parameters
> from length(data)-out.sample. There is no re-estimation taking place (this
> is only done in the ugarchroll method).
> For n.ahead>1, this becomes an unconditional forecast. Equivalently, you can
> append new data to your old dataset and use the ugarchfilter method.
>
>>
>> My third question(s) is (are): How to calculate the VaR in case of a
>> standardized
>> hyperbolic distribution? Can I still calculate it like in the normal case
>> or does it not work anymore (I am not sure, if the sdhyp belongs to the
>> location-scale family).
>>
>> Even if it does work (so if the sdhyp belongs to the family of
>> location-scale distributions) how do I calculate it in case of a
>> distribution, which does not belong to the location-scale family?
>> (I mean, if I cannot calculate it via VaR = uncmean + sigma* z_alpha how
>> do I have to calculate it). Which distribution implemented in the rugarch
>> package does not belong to the location-scale family?
>>
> ALL distributions in the rugarch package are represented in a location- and
> scale- invariant parameterization since this is a key property required in
> working with the standardized residuals in the density function (i.e. the
> subtraction of the mean and scaling by the volatility).
> The standardized Generalized Hyperbolic distribution does indeed have this
> property, and details are available in the vignette. See also paper by
> Blaesild (http://biomet.oxfordjournals.org/content/68/1/251.short) for the
> linear transformation (aX+b) property.
>
> If working with the standard (NOT standardized) version of the GH
> distribution (\lambda, \alpha, \beta, \delta, \mu) you need to apply the
> location/scaling transformation as the example below shows which is
> equivalent to just using the location/scaling transformation in the
> standardized version:
> #################################################
> library(rugarch)
> # zeta = shape
> zeta = 0.4
> # rho = skew
> rho = 0.9
> # lambda = GIG mixing distribution shape parameter
> lambda=-1
> # POSITIVE scaling factor (sigma is in any always positive)
> # mean
> scaling = 0.02
> # sigma
> location = 0.001
>
> # standardized transformation based on (0,1,\rho,\zeta)
> # parameterization:
> x1 = scaling*qdist("ghyp", seq(0.001, 0.5, length.out=100), shape = zeta,
> skew = rho, lambda = lambda)+location
> # Equivalent to standard transformation:
> # First obtain the standard parameters (which have a mean of zero
> # and sigma of 1).
> parms = rugarch:::.paramGH(zeta, rho, lambda)
> x2 = rugarch:::.qgh( seq(0.001, 0.5, length.out=100), alpha =
> parms[1]/abs(scaling), beta = parms[2]/abs(scaling),
> delta=abs(scaling)*parms[3], mu = (scaling)*parms[4]+location, lambda =
> lambda)
> all.equal(x1, x2)
> # Notice the approximation error in the calculation of the quantile for #
> which there is no closed form solution (and rugarch uses a tolerance
> # value of .Machine$double.eps^0.25)
> # Load the GeneralizedHyperbolic package of Scott to adjust the
> # tolerance:
> library(GeneralizedHyperbolic)
>
> x1 = location+scaling*qghyp(seq(0.001, 0.5, length.out=100), mu = parms[4],
> delta = parms[3], alpha =  parms[1], beta = parms[2], lambda = lambda,
> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 501,
> subdivisions = 500, uniTol = 2e-12)
> # equivalent to:
> x2 = qghyp(seq(0.001, 0.5, length.out=100), mu =
> (scaling)*parms[4]+location, delta = abs(scaling)*parms[3], alpha =
> parms[1]/abs(scaling), beta = parms[2]/abs(scaling), lambda = lambda,
> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 501,
> subdivisions = 500, uniTol = 2e-12)
>
> all.equal(x1, x2)
> #################################################
>
>
>
>> Thanks a lot for your help!
>>
>
> Regards,
>
> Alexios
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>


From alexios at 4dscape.com  Tue May  7 13:58:49 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Tue, 07 May 2013 12:58:49 +0100
Subject: [R-SIG-Finance] rugarch VaR calculation "manually"
In-Reply-To: <CADih64RY4XoytMMpmPpO6sEW245oW=3SpWUKDmiupDKcbD6jEA@mail.gmail.com>
References: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>
	<5188E6FF.7040304@4dscape.com>
	<CADih64RY4XoytMMpmPpO6sEW245oW=3SpWUKDmiupDKcbD6jEA@mail.gmail.com>
Message-ID: <5188EC79.7060604@4dscape.com>

Applying 'sigma' (conditional volatility) and 'fitted' (conditional 
mean) METHODS on a uGARCHforecast object will return the forecast values 
of those quantities with appropriately labelled dates (the T+0 time). 
This too is documented in the help files, and there was also a blog post 
about this ('Whats new in rugarch (ver 1.01-5)').

For VaR, as I already mentioned, you can use the 'quantile' method on
any of the returned S4 class objects.

-Alexios

On 07/05/2013 12:51, Neuman Co wrote:
> thanks a lot for your help, but
> "Use the 'sigma' and 'fitted' methods"
>
> But these are the fitted values for the volatility and the final
> fitted values. But to calculate the VaR I need the 1 step ahead
> forecast of the cond. sigmas and the 1 step ahead forecast of the
> cond. mean. The cond.mean is not equivalent to the fitted values? And
> the fitted values are not one step ahead forecasts?
>
> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>> Hello,
>>
>>
>> On 07/05/2013 12:15, Neuman Co wrote:
>>>
>>> I am using the rugarch package in R and I have some questions:
>>>
>>> I want to use the rugarch package to calculate the VaR.
>>>
>>> I used the following code to to fit a certain model:
>>>
>>> spec2<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>>> c(1, 1)),
>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>> distribution.model =
>>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>>
>>> model2<-ugarchfit(spec=spec2,data=mydata)
>>>
>>> Now I can look at the 2.5 % VaR with the following command:
>>> plot(model)
>>>
>>> and choosing the second plot.
>>>
>>> Now my first question is: How can I get the 1.0% VaR VALUES, so not
>>> the plot, but
>>> the values/numbers?
>>
>> Use the 'quantile' method i.e. 'quantile(model2, 0.01)'...also applies to
>> uGARCHforecast, uGARCHsim etc It IS documented.
>>
>>>
>>> In case of the normal distribution, one can easily do the calculation of
>>> the VaR with using the forecasted conditional volatility and the
>>> forecasted
>>> conditional mean:
>>>
>>> I use the ugarchforecast command and with that I can get the cond.
>>> volatility
>>> and cond. mean (my mean equation is an modified ARMA(5,5), see above in
>>> the spec
>>> command):
>>>
>>> forecast = ugarchforecast(spec, data, n.roll = , n.ahead = , out.sample=)
>>>
>>> # conditional mean
>>> cmu = as.numeric(as.data.frame(forecast, which = "series",
>>> rollframe="all", aligned = FALSE))
>>> # conditional sigma
>>> csigma = as.numeric(as.data.frame(forecast, which = "sigma",
>>> rollframe="all", aligned = FALSE))
>>>
>> NO. 'as.data.frame' has long been deprecated. Use the 'sigma' and 'fitted'
>> methods (and make sure you upgrade to latest version of rugarch).
>>
>>
>>> I can calculate the VaR by using the property, that the normal
>>> distribution
>>> is part of the location-scale distribution families
>>>
>>> # use location+scaling transformation property of normal distribution:
>>> VaR = qnorm(0.01)*csigma + cmu
>>>
>>> My second question belongs to the n.roll and out.sample command. I had
>>> a look at the
>>> description
>>> http://www.inside-r.org/packages/cran/rugarch/docs/ugarchforecast
>>> but I did not understand the n.roll and out.sample command. I want to
>>> calculate the
>>> daily VaR, so I need one step ahead predicitons and I do not want to
>>> reestimate
>>> the model every time step. So what does it mean "to roll the forecast
>>> 1 step " and
>>> what is out.sample?
>>
>> out.sample, which is used in the estimation stage retains 'out.sample' data
>> (i.e. they are not used in the estimation) so that a rolling forecast can
>> then be performed using this data. 'Rolling' means using data at time T-p
>> (p=lag) to create a conditional 1-ahead forecast at time T. For the
>> ugarchforecast method, this means using only estimates of the parameters
>> from length(data)-out.sample. There is no re-estimation taking place (this
>> is only done in the ugarchroll method).
>> For n.ahead>1, this becomes an unconditional forecast. Equivalently, you can
>> append new data to your old dataset and use the ugarchfilter method.
>>
>>>
>>> My third question(s) is (are): How to calculate the VaR in case of a
>>> standardized
>>> hyperbolic distribution? Can I still calculate it like in the normal case
>>> or does it not work anymore (I am not sure, if the sdhyp belongs to the
>>> location-scale family).
>>>
>>> Even if it does work (so if the sdhyp belongs to the family of
>>> location-scale distributions) how do I calculate it in case of a
>>> distribution, which does not belong to the location-scale family?
>>> (I mean, if I cannot calculate it via VaR = uncmean + sigma* z_alpha how
>>> do I have to calculate it). Which distribution implemented in the rugarch
>>> package does not belong to the location-scale family?
>>>
>> ALL distributions in the rugarch package are represented in a location- and
>> scale- invariant parameterization since this is a key property required in
>> working with the standardized residuals in the density function (i.e. the
>> subtraction of the mean and scaling by the volatility).
>> The standardized Generalized Hyperbolic distribution does indeed have this
>> property, and details are available in the vignette. See also paper by
>> Blaesild (http://biomet.oxfordjournals.org/content/68/1/251.short) for the
>> linear transformation (aX+b) property.
>>
>> If working with the standard (NOT standardized) version of the GH
>> distribution (\lambda, \alpha, \beta, \delta, \mu) you need to apply the
>> location/scaling transformation as the example below shows which is
>> equivalent to just using the location/scaling transformation in the
>> standardized version:
>> #################################################
>> library(rugarch)
>> # zeta = shape
>> zeta = 0.4
>> # rho = skew
>> rho = 0.9
>> # lambda = GIG mixing distribution shape parameter
>> lambda=-1
>> # POSITIVE scaling factor (sigma is in any always positive)
>> # mean
>> scaling = 0.02
>> # sigma
>> location = 0.001
>>
>> # standardized transformation based on (0,1,\rho,\zeta)
>> # parameterization:
>> x1 = scaling*qdist("ghyp", seq(0.001, 0.5, length.out=100), shape = zeta,
>> skew = rho, lambda = lambda)+location
>> # Equivalent to standard transformation:
>> # First obtain the standard parameters (which have a mean of zero
>> # and sigma of 1).
>> parms = rugarch:::.paramGH(zeta, rho, lambda)
>> x2 = rugarch:::.qgh( seq(0.001, 0.5, length.out=100), alpha =
>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling),
>> delta=abs(scaling)*parms[3], mu = (scaling)*parms[4]+location, lambda =
>> lambda)
>> all.equal(x1, x2)
>> # Notice the approximation error in the calculation of the quantile for #
>> which there is no closed form solution (and rugarch uses a tolerance
>> # value of .Machine$double.eps^0.25)
>> # Load the GeneralizedHyperbolic package of Scott to adjust the
>> # tolerance:
>> library(GeneralizedHyperbolic)
>>
>> x1 = location+scaling*qghyp(seq(0.001, 0.5, length.out=100), mu = parms[4],
>> delta = parms[3], alpha =  parms[1], beta = parms[2], lambda = lambda,
>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 501,
>> subdivisions = 500, uniTol = 2e-12)
>> # equivalent to:
>> x2 = qghyp(seq(0.001, 0.5, length.out=100), mu =
>> (scaling)*parms[4]+location, delta = abs(scaling)*parms[3], alpha =
>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling), lambda = lambda,
>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 501,
>> subdivisions = 500, uniTol = 2e-12)
>>
>> all.equal(x1, x2)
>> #################################################
>>
>>
>>
>>> Thanks a lot for your help!
>>>
>>
>> Regards,
>>
>> Alexios
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>>
>>
>


From edd at debian.org  Tue May  7 18:06:45 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 7 May 2013 11:06:45 -0500
Subject: [R-SIG-Finance] Ten days remaining for R/Finance 2013 registrations
In-Reply-To: <20822.828.474518.884561@max.nulle.part>
References: <20821.65063.213827.443150@max.nulle.part>
	<20822.828.474518.884561@max.nulle.part>
Message-ID: <20873.9877.398548.243023@max.nulle.part>


R/Finance 2013 is coming up in ten days on May 17 and 18.  Registration is
going strong at (currently) just under 200 registrants with about 100 spots
remaining. 

The earlier announcement is below for your convenience. 

We look forward to seeing you in Chicago in ten days.

Dirk

| Now open for registrations --- and more details as always at http://www.RinFinance.com :
| 
|   R / Finance 2013: Applied Finance with R
|   May 17 and 18, 2013 
|   Chicago, IL, USA
| 
|   The registration for R/Finance 2013 -- which will take place May 17 and 18
|   in Chicago -- is NOW OPEN!
| 
|   Building on the success of the previous conferences in 2009, 2010, 2011 and
|   2012, we expect more than 250 attendees from around the world. R users from
|   industry, academia, and government will joining 30+ presenters covering all
|   areas of finance with R.
| 
|   We are very excited about the four keynotes by Sanjiv Das, Attilio Meucci,
|   Ryan Sheftel and Ruey Tsay.  The main agenda (currently) includes seventeen
|   full presentations and fifteen shorter "lightning talks". We are also
|   excited to offer five optional pre-conference seminars on Friday morning.
| 
|   To celebrate the fifth year of the conference in style, the dinner will be
|   held at The Terrace of the Trump Hotel. Overlooking the Chicago River and
|   skyline, it is a perfect venue to continue conversations while dining and
|   drinking.
|                                                                                                           
|   More details of the agenda are available at:
|                                                                                                           
|     http://www.RinFinance.com/agenda/
|                                                                                                           
|   Registration information is available at
|                                                                                                           
|     http://www.RinFinance.com/register/
|                                                                                                           
|   and can also be directly accessed by going to
|                                                                                                           
|     http://www.regonline.com/RFinance2013
|                                                                                                           
|   We would to thank our 2013 Sponsors for the continued support enabling us
|   to host such an exciting conference:
|                                                                                                           
|     International Center for Futures and Derivatives at UIC
|                                                                                                           
|     Revolution Analytics
|     MS-Computational Finance at University of Washington
|                                                                                                           
|     Google
|     lemnica
|     OpenGamma
|     OneMarketData
|     RStudio
|                                                                                                           
|   On behalf of the committee and sponsors, we look forward to seeing you in
|   Chicago!
| 
|     Gib Bassett, Peter Carl, Dirk Eddelbuettel, Brian Peterson, 
|     Dale Rosenthal, Jeffrey Ryan, Joshua Ulrich
| 
| See you in Chicago in May!!
| 
| Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From neumancohu at gmail.com  Wed May  8 10:42:21 2013
From: neumancohu at gmail.com (Neuman Co)
Date: Wed, 8 May 2013 10:42:21 +0200
Subject: [R-SIG-Finance] rugarch VaR calculation "manually"
In-Reply-To: <5188EC79.7060604@4dscape.com>
References: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>
	<5188E6FF.7040304@4dscape.com>
	<CADih64RY4XoytMMpmPpO6sEW245oW=3SpWUKDmiupDKcbD6jEA@mail.gmail.com>
	<5188EC79.7060604@4dscape.com>
Message-ID: <CADih64TsACXe=4iPcBVoaehHshOiyC5YTHVRd2Jdo3vFrNW_9g@mail.gmail.com>

The data I am working with can be found here:
http://uploadeasy.net/upload/2fvhy.rar

I fitted the following model:
alvnomodel<-ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
distribution.model = "norm")

alvnomodelgarch<-ugarchfit(spec=alvnomodel,data=alvlloss)

Now I want to get the one-day ahead forecasts of the cond. volatility
and the cond. mean. I try to applay ugrachforecast:

ugarchforecast(alvnomodelgarch, n.ahead = 1,out.sample=50,n.roll=10)

But I get the error message:
ugarchforecast-->error: n.roll must not be greater than out.sample!

What is wrong?

Also I don't know what values I should take for out.sample and n.roll?
I just want to get 1 day ahead forecasts. What values do I need to
insert?

2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
> Applying 'sigma' (conditional volatility) and 'fitted' (conditional mean)
> METHODS on a uGARCHforecast object will return the forecast values of those
> quantities with appropriately labelled dates (the T+0 time). This too is
> documented in the help files, and there was also a blog post about this
> ('Whats new in rugarch (ver 1.01-5)').
>
> For VaR, as I already mentioned, you can use the 'quantile' method on
> any of the returned S4 class objects.
>
> -Alexios
>
>
> On 07/05/2013 12:51, Neuman Co wrote:
>>
>> thanks a lot for your help, but
>> "Use the 'sigma' and 'fitted' methods"
>>
>> But these are the fitted values for the volatility and the final
>> fitted values. But to calculate the VaR I need the 1 step ahead
>> forecast of the cond. sigmas and the 1 step ahead forecast of the
>> cond. mean. The cond.mean is not equivalent to the fitted values? And
>> the fitted values are not one step ahead forecasts?
>>
>> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>>>
>>> Hello,
>>>
>>>
>>> On 07/05/2013 12:15, Neuman Co wrote:
>>>>
>>>>
>>>> I am using the rugarch package in R and I have some questions:
>>>>
>>>> I want to use the rugarch package to calculate the VaR.
>>>>
>>>> I used the following code to to fit a certain model:
>>>>
>>>> spec2<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>>>> c(1, 1)),
>>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>>> distribution.model =
>>>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>>>
>>>> model2<-ugarchfit(spec=spec2,data=mydata)
>>>>
>>>> Now I can look at the 2.5 % VaR with the following command:
>>>> plot(model)
>>>>
>>>> and choosing the second plot.
>>>>
>>>> Now my first question is: How can I get the 1.0% VaR VALUES, so not
>>>> the plot, but
>>>> the values/numbers?
>>>
>>>
>>> Use the 'quantile' method i.e. 'quantile(model2, 0.01)'...also applies to
>>> uGARCHforecast, uGARCHsim etc It IS documented.
>>>
>>>>
>>>> In case of the normal distribution, one can easily do the calculation of
>>>> the VaR with using the forecasted conditional volatility and the
>>>> forecasted
>>>> conditional mean:
>>>>
>>>> I use the ugarchforecast command and with that I can get the cond.
>>>> volatility
>>>> and cond. mean (my mean equation is an modified ARMA(5,5), see above in
>>>> the spec
>>>> command):
>>>>
>>>> forecast = ugarchforecast(spec, data, n.roll = , n.ahead = ,
>>>> out.sample=)
>>>>
>>>> # conditional mean
>>>> cmu = as.numeric(as.data.frame(forecast, which = "series",
>>>> rollframe="all", aligned = FALSE))
>>>> # conditional sigma
>>>> csigma = as.numeric(as.data.frame(forecast, which = "sigma",
>>>> rollframe="all", aligned = FALSE))
>>>>
>>> NO. 'as.data.frame' has long been deprecated. Use the 'sigma' and
>>> 'fitted'
>>> methods (and make sure you upgrade to latest version of rugarch).
>>>
>>>
>>>> I can calculate the VaR by using the property, that the normal
>>>> distribution
>>>> is part of the location-scale distribution families
>>>>
>>>> # use location+scaling transformation property of normal distribution:
>>>> VaR = qnorm(0.01)*csigma + cmu
>>>>
>>>> My second question belongs to the n.roll and out.sample command. I had
>>>> a look at the
>>>> description
>>>> http://www.inside-r.org/packages/cran/rugarch/docs/ugarchforecast
>>>> but I did not understand the n.roll and out.sample command. I want to
>>>> calculate the
>>>> daily VaR, so I need one step ahead predicitons and I do not want to
>>>> reestimate
>>>> the model every time step. So what does it mean "to roll the forecast
>>>> 1 step " and
>>>> what is out.sample?
>>>
>>>
>>> out.sample, which is used in the estimation stage retains 'out.sample'
>>> data
>>> (i.e. they are not used in the estimation) so that a rolling forecast can
>>> then be performed using this data. 'Rolling' means using data at time T-p
>>> (p=lag) to create a conditional 1-ahead forecast at time T. For the
>>> ugarchforecast method, this means using only estimates of the parameters
>>> from length(data)-out.sample. There is no re-estimation taking place
>>> (this
>>> is only done in the ugarchroll method).
>>> For n.ahead>1, this becomes an unconditional forecast. Equivalently, you
>>> can
>>> append new data to your old dataset and use the ugarchfilter method.
>>>
>>>>
>>>> My third question(s) is (are): How to calculate the VaR in case of a
>>>> standardized
>>>> hyperbolic distribution? Can I still calculate it like in the normal
>>>> case
>>>> or does it not work anymore (I am not sure, if the sdhyp belongs to the
>>>> location-scale family).
>>>>
>>>> Even if it does work (so if the sdhyp belongs to the family of
>>>> location-scale distributions) how do I calculate it in case of a
>>>> distribution, which does not belong to the location-scale family?
>>>> (I mean, if I cannot calculate it via VaR = uncmean + sigma* z_alpha how
>>>> do I have to calculate it). Which distribution implemented in the
>>>> rugarch
>>>> package does not belong to the location-scale family?
>>>>
>>> ALL distributions in the rugarch package are represented in a location-
>>> and
>>> scale- invariant parameterization since this is a key property required
>>> in
>>> working with the standardized residuals in the density function (i.e. the
>>> subtraction of the mean and scaling by the volatility).
>>> The standardized Generalized Hyperbolic distribution does indeed have
>>> this
>>> property, and details are available in the vignette. See also paper by
>>> Blaesild (http://biomet.oxfordjournals.org/content/68/1/251.short) for
>>> the
>>> linear transformation (aX+b) property.
>>>
>>> If working with the standard (NOT standardized) version of the GH
>>> distribution (\lambda, \alpha, \beta, \delta, \mu) you need to apply the
>>> location/scaling transformation as the example below shows which is
>>> equivalent to just using the location/scaling transformation in the
>>> standardized version:
>>> #################################################
>>> library(rugarch)
>>> # zeta = shape
>>> zeta = 0.4
>>> # rho = skew
>>> rho = 0.9
>>> # lambda = GIG mixing distribution shape parameter
>>> lambda=-1
>>> # POSITIVE scaling factor (sigma is in any always positive)
>>> # mean
>>> scaling = 0.02
>>> # sigma
>>> location = 0.001
>>>
>>> # standardized transformation based on (0,1,\rho,\zeta)
>>> # parameterization:
>>> x1 = scaling*qdist("ghyp", seq(0.001, 0.5, length.out=100), shape = zeta,
>>> skew = rho, lambda = lambda)+location
>>> # Equivalent to standard transformation:
>>> # First obtain the standard parameters (which have a mean of zero
>>> # and sigma of 1).
>>> parms = rugarch:::.paramGH(zeta, rho, lambda)
>>> x2 = rugarch:::.qgh( seq(0.001, 0.5, length.out=100), alpha =
>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling),
>>> delta=abs(scaling)*parms[3], mu = (scaling)*parms[4]+location, lambda =
>>> lambda)
>>> all.equal(x1, x2)
>>> # Notice the approximation error in the calculation of the quantile for #
>>> which there is no closed form solution (and rugarch uses a tolerance
>>> # value of .Machine$double.eps^0.25)
>>> # Load the GeneralizedHyperbolic package of Scott to adjust the
>>> # tolerance:
>>> library(GeneralizedHyperbolic)
>>>
>>> x1 = location+scaling*qghyp(seq(0.001, 0.5, length.out=100), mu =
>>> parms[4],
>>> delta = parms[3], alpha =  parms[1], beta = parms[2], lambda = lambda,
>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 501,
>>> subdivisions = 500, uniTol = 2e-12)
>>> # equivalent to:
>>> x2 = qghyp(seq(0.001, 0.5, length.out=100), mu =
>>> (scaling)*parms[4]+location, delta = abs(scaling)*parms[3], alpha =
>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling), lambda = lambda,
>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 501,
>>> subdivisions = 500, uniTol = 2e-12)
>>>
>>> all.equal(x1, x2)
>>> #################################################
>>>
>>>
>>>
>>>> Thanks a lot for your help!
>>>>
>>>
>>> Regards,
>>>
>>> Alexios
>>>>
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions
>>>> should go.
>>>>
>>>
>>
>


From neumancohu at gmail.com  Wed May  8 11:45:16 2013
From: neumancohu at gmail.com (Neuman Co)
Date: Wed, 8 May 2013 11:45:16 +0200
Subject: [R-SIG-Finance] rugarch VaR calculation "manually"
In-Reply-To: <CADih64TsACXe=4iPcBVoaehHshOiyC5YTHVRd2Jdo3vFrNW_9g@mail.gmail.com>
References: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>
	<5188E6FF.7040304@4dscape.com>
	<CADih64RY4XoytMMpmPpO6sEW245oW=3SpWUKDmiupDKcbD6jEA@mail.gmail.com>
	<5188EC79.7060604@4dscape.com>
	<CADih64TsACXe=4iPcBVoaehHshOiyC5YTHVRd2Jdo3vFrNW_9g@mail.gmail.com>
Message-ID: <CADih64QrM7bwy0f=N-fCfT9dZLbzi1qoiKnnL5-+5W=b0N+=Qg@mail.gmail.com>

Also http://www.unstarched.net/2013/02/27/whats-new-in-rugarch-ver-1-01-5/
does not work if I try it.
If I do
c(is(sigma((fit))), is(fitted(fit)), is(residuals(fit)))
I do not get xts xts xts but numeric vector and so on?

If I try
plot(xts(fit at model$modeldata$data, fit at model$modeldata$index),
auto.grid = FALSE,
    minor.ticks = FALSE, main = 'S&P500 Conditional Mean')
lines(fitted(fit), col = 2)
grid()

I get the error messages
Fehler in plot(xts(fit at model$modeldata$data, fit at model$modeldata$index),  :
  Fehler bei der Auswertung des Argumentes 'x' bei der Methodenauswahl
f?r Funktion 'plot': Fehler in xts(fit at model$modeldata$data,
fit at model$modeldata$index) :
  order.by requires an appropriate time-based object

and sigma(f) is also not working?
Fehler in UseMethod("sigma") :
  nicht anwendbare Methode f?r 'sigma' auf Objekt der Klasse
"c('uGARCHforecast', 'GARCHforecast', 'rGARCH')" angewendet
>


I just tried to understand the examples, but they do not work?

2013/5/8 Neuman Co <neumancohu at gmail.com>:
> The data I am working with can be found here:
> http://uploadeasy.net/upload/2fvhy.rar
>
> I fitted the following model:
> alvnomodel<-ugarchspec(variance.model = list(model = "sGARCH",
> garchOrder = c(1, 1)),
> mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
> distribution.model = "norm")
>
> alvnomodelgarch<-ugarchfit(spec=alvnomodel,data=alvlloss)
>
> Now I want to get the one-day ahead forecasts of the cond. volatility
> and the cond. mean. I try to applay ugrachforecast:
>
> ugarchforecast(alvnomodelgarch, n.ahead = 1,out.sample=50,n.roll=10)
>
> But I get the error message:
> ugarchforecast-->error: n.roll must not be greater than out.sample!
>
> What is wrong?
>
> Also I don't know what values I should take for out.sample and n.roll?
> I just want to get 1 day ahead forecasts. What values do I need to
> insert?
>
> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>> Applying 'sigma' (conditional volatility) and 'fitted' (conditional mean)
>> METHODS on a uGARCHforecast object will return the forecast values of those
>> quantities with appropriately labelled dates (the T+0 time). This too is
>> documented in the help files, and there was also a blog post about this
>> ('Whats new in rugarch (ver 1.01-5)').
>>
>> For VaR, as I already mentioned, you can use the 'quantile' method on
>> any of the returned S4 class objects.
>>
>> -Alexios
>>
>>
>> On 07/05/2013 12:51, Neuman Co wrote:
>>>
>>> thanks a lot for your help, but
>>> "Use the 'sigma' and 'fitted' methods"
>>>
>>> But these are the fitted values for the volatility and the final
>>> fitted values. But to calculate the VaR I need the 1 step ahead
>>> forecast of the cond. sigmas and the 1 step ahead forecast of the
>>> cond. mean. The cond.mean is not equivalent to the fitted values? And
>>> the fitted values are not one step ahead forecasts?
>>>
>>> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>>>>
>>>> Hello,
>>>>
>>>>
>>>> On 07/05/2013 12:15, Neuman Co wrote:
>>>>>
>>>>>
>>>>> I am using the rugarch package in R and I have some questions:
>>>>>
>>>>> I want to use the rugarch package to calculate the VaR.
>>>>>
>>>>> I used the following code to to fit a certain model:
>>>>>
>>>>> spec2<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>>>>> c(1, 1)),
>>>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>>>> distribution.model =
>>>>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>>>>
>>>>> model2<-ugarchfit(spec=spec2,data=mydata)
>>>>>
>>>>> Now I can look at the 2.5 % VaR with the following command:
>>>>> plot(model)
>>>>>
>>>>> and choosing the second plot.
>>>>>
>>>>> Now my first question is: How can I get the 1.0% VaR VALUES, so not
>>>>> the plot, but
>>>>> the values/numbers?
>>>>
>>>>
>>>> Use the 'quantile' method i.e. 'quantile(model2, 0.01)'...also applies to
>>>> uGARCHforecast, uGARCHsim etc It IS documented.
>>>>
>>>>>
>>>>> In case of the normal distribution, one can easily do the calculation of
>>>>> the VaR with using the forecasted conditional volatility and the
>>>>> forecasted
>>>>> conditional mean:
>>>>>
>>>>> I use the ugarchforecast command and with that I can get the cond.
>>>>> volatility
>>>>> and cond. mean (my mean equation is an modified ARMA(5,5), see above in
>>>>> the spec
>>>>> command):
>>>>>
>>>>> forecast = ugarchforecast(spec, data, n.roll = , n.ahead = ,
>>>>> out.sample=)
>>>>>
>>>>> # conditional mean
>>>>> cmu = as.numeric(as.data.frame(forecast, which = "series",
>>>>> rollframe="all", aligned = FALSE))
>>>>> # conditional sigma
>>>>> csigma = as.numeric(as.data.frame(forecast, which = "sigma",
>>>>> rollframe="all", aligned = FALSE))
>>>>>
>>>> NO. 'as.data.frame' has long been deprecated. Use the 'sigma' and
>>>> 'fitted'
>>>> methods (and make sure you upgrade to latest version of rugarch).
>>>>
>>>>
>>>>> I can calculate the VaR by using the property, that the normal
>>>>> distribution
>>>>> is part of the location-scale distribution families
>>>>>
>>>>> # use location+scaling transformation property of normal distribution:
>>>>> VaR = qnorm(0.01)*csigma + cmu
>>>>>
>>>>> My second question belongs to the n.roll and out.sample command. I had
>>>>> a look at the
>>>>> description
>>>>> http://www.inside-r.org/packages/cran/rugarch/docs/ugarchforecast
>>>>> but I did not understand the n.roll and out.sample command. I want to
>>>>> calculate the
>>>>> daily VaR, so I need one step ahead predicitons and I do not want to
>>>>> reestimate
>>>>> the model every time step. So what does it mean "to roll the forecast
>>>>> 1 step " and
>>>>> what is out.sample?
>>>>
>>>>
>>>> out.sample, which is used in the estimation stage retains 'out.sample'
>>>> data
>>>> (i.e. they are not used in the estimation) so that a rolling forecast can
>>>> then be performed using this data. 'Rolling' means using data at time T-p
>>>> (p=lag) to create a conditional 1-ahead forecast at time T. For the
>>>> ugarchforecast method, this means using only estimates of the parameters
>>>> from length(data)-out.sample. There is no re-estimation taking place
>>>> (this
>>>> is only done in the ugarchroll method).
>>>> For n.ahead>1, this becomes an unconditional forecast. Equivalently, you
>>>> can
>>>> append new data to your old dataset and use the ugarchfilter method.
>>>>
>>>>>
>>>>> My third question(s) is (are): How to calculate the VaR in case of a
>>>>> standardized
>>>>> hyperbolic distribution? Can I still calculate it like in the normal
>>>>> case
>>>>> or does it not work anymore (I am not sure, if the sdhyp belongs to the
>>>>> location-scale family).
>>>>>
>>>>> Even if it does work (so if the sdhyp belongs to the family of
>>>>> location-scale distributions) how do I calculate it in case of a
>>>>> distribution, which does not belong to the location-scale family?
>>>>> (I mean, if I cannot calculate it via VaR = uncmean + sigma* z_alpha how
>>>>> do I have to calculate it). Which distribution implemented in the
>>>>> rugarch
>>>>> package does not belong to the location-scale family?
>>>>>
>>>> ALL distributions in the rugarch package are represented in a location-
>>>> and
>>>> scale- invariant parameterization since this is a key property required
>>>> in
>>>> working with the standardized residuals in the density function (i.e. the
>>>> subtraction of the mean and scaling by the volatility).
>>>> The standardized Generalized Hyperbolic distribution does indeed have
>>>> this
>>>> property, and details are available in the vignette. See also paper by
>>>> Blaesild (http://biomet.oxfordjournals.org/content/68/1/251.short) for
>>>> the
>>>> linear transformation (aX+b) property.
>>>>
>>>> If working with the standard (NOT standardized) version of the GH
>>>> distribution (\lambda, \alpha, \beta, \delta, \mu) you need to apply the
>>>> location/scaling transformation as the example below shows which is
>>>> equivalent to just using the location/scaling transformation in the
>>>> standardized version:
>>>> #################################################
>>>> library(rugarch)
>>>> # zeta = shape
>>>> zeta = 0.4
>>>> # rho = skew
>>>> rho = 0.9
>>>> # lambda = GIG mixing distribution shape parameter
>>>> lambda=-1
>>>> # POSITIVE scaling factor (sigma is in any always positive)
>>>> # mean
>>>> scaling = 0.02
>>>> # sigma
>>>> location = 0.001
>>>>
>>>> # standardized transformation based on (0,1,\rho,\zeta)
>>>> # parameterization:
>>>> x1 = scaling*qdist("ghyp", seq(0.001, 0.5, length.out=100), shape = zeta,
>>>> skew = rho, lambda = lambda)+location
>>>> # Equivalent to standard transformation:
>>>> # First obtain the standard parameters (which have a mean of zero
>>>> # and sigma of 1).
>>>> parms = rugarch:::.paramGH(zeta, rho, lambda)
>>>> x2 = rugarch:::.qgh( seq(0.001, 0.5, length.out=100), alpha =
>>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling),
>>>> delta=abs(scaling)*parms[3], mu = (scaling)*parms[4]+location, lambda =
>>>> lambda)
>>>> all.equal(x1, x2)
>>>> # Notice the approximation error in the calculation of the quantile for #
>>>> which there is no closed form solution (and rugarch uses a tolerance
>>>> # value of .Machine$double.eps^0.25)
>>>> # Load the GeneralizedHyperbolic package of Scott to adjust the
>>>> # tolerance:
>>>> library(GeneralizedHyperbolic)
>>>>
>>>> x1 = location+scaling*qghyp(seq(0.001, 0.5, length.out=100), mu =
>>>> parms[4],
>>>> delta = parms[3], alpha =  parms[1], beta = parms[2], lambda = lambda,
>>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 501,
>>>> subdivisions = 500, uniTol = 2e-12)
>>>> # equivalent to:
>>>> x2 = qghyp(seq(0.001, 0.5, length.out=100), mu =
>>>> (scaling)*parms[4]+location, delta = abs(scaling)*parms[3], alpha =
>>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling), lambda = lambda,
>>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 501,
>>>> subdivisions = 500, uniTol = 2e-12)
>>>>
>>>> all.equal(x1, x2)
>>>> #################################################
>>>>
>>>>
>>>>
>>>>> Thanks a lot for your help!
>>>>>
>>>>
>>>> Regards,
>>>>
>>>> Alexios
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> R-SIG-Finance at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>> -- Also note that this is not the r-help list where general R questions
>>>>> should go.
>>>>>
>>>>
>>>
>>


From neumancohu at gmail.com  Wed May  8 12:28:54 2013
From: neumancohu at gmail.com (Neuman Co)
Date: Wed, 8 May 2013 12:28:54 +0200
Subject: [R-SIG-Finance] rugarch VaR calculation "manually"
In-Reply-To: <CADih64QrM7bwy0f=N-fCfT9dZLbzi1qoiKnnL5-+5W=b0N+=Qg@mail.gmail.com>
References: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>
	<5188E6FF.7040304@4dscape.com>
	<CADih64RY4XoytMMpmPpO6sEW245oW=3SpWUKDmiupDKcbD6jEA@mail.gmail.com>
	<5188EC79.7060604@4dscape.com>
	<CADih64TsACXe=4iPcBVoaehHshOiyC5YTHVRd2Jdo3vFrNW_9g@mail.gmail.com>
	<CADih64QrM7bwy0f=N-fCfT9dZLbzi1qoiKnnL5-+5W=b0N+=Qg@mail.gmail.com>
Message-ID: <CADih64SdsZWrpDRyoihSzZuiBR_qaa1tZJxpvvKOsKA0oLvhnA@mail.gmail.com>

I mean, I only try to get the one-step ahead in-sample predictions. So
I do NOT want to leave out any observations in the estimation stage? I
want to use all observations, estimate the GARCH and use the estimated
parameters and data to get one step ahead in sample predictions so I
can use these one-step-ahead-in-sample predictions of my cond.
volatility and cond. mean to calculate the VaR.

2013/5/8 Neuman Co <neumancohu at gmail.com>:
> Also http://www.unstarched.net/2013/02/27/whats-new-in-rugarch-ver-1-01-5/
> does not work if I try it.
> If I do
> c(is(sigma((fit))), is(fitted(fit)), is(residuals(fit)))
> I do not get xts xts xts but numeric vector and so on?
>
> If I try
> plot(xts(fit at model$modeldata$data, fit at model$modeldata$index),
> auto.grid = FALSE,
>     minor.ticks = FALSE, main = 'S&P500 Conditional Mean')
> lines(fitted(fit), col = 2)
> grid()
>
> I get the error messages
> Fehler in plot(xts(fit at model$modeldata$data, fit at model$modeldata$index),  :
>   Fehler bei der Auswertung des Argumentes 'x' bei der Methodenauswahl
> f?r Funktion 'plot': Fehler in xts(fit at model$modeldata$data,
> fit at model$modeldata$index) :
>   order.by requires an appropriate time-based object
>
> and sigma(f) is also not working?
> Fehler in UseMethod("sigma") :
>   nicht anwendbare Methode f?r 'sigma' auf Objekt der Klasse
> "c('uGARCHforecast', 'GARCHforecast', 'rGARCH')" angewendet
>>
>
>
> I just tried to understand the examples, but they do not work?
>
> 2013/5/8 Neuman Co <neumancohu at gmail.com>:
>> The data I am working with can be found here:
>> http://uploadeasy.net/upload/2fvhy.rar
>>
>> I fitted the following model:
>> alvnomodel<-ugarchspec(variance.model = list(model = "sGARCH",
>> garchOrder = c(1, 1)),
>> mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
>> distribution.model = "norm")
>>
>> alvnomodelgarch<-ugarchfit(spec=alvnomodel,data=alvlloss)
>>
>> Now I want to get the one-day ahead forecasts of the cond. volatility
>> and the cond. mean. I try to applay ugrachforecast:
>>
>> ugarchforecast(alvnomodelgarch, n.ahead = 1,out.sample=50,n.roll=10)
>>
>> But I get the error message:
>> ugarchforecast-->error: n.roll must not be greater than out.sample!
>>
>> What is wrong?
>>
>> Also I don't know what values I should take for out.sample and n.roll?
>> I just want to get 1 day ahead forecasts. What values do I need to
>> insert?
>>
>> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>>> Applying 'sigma' (conditional volatility) and 'fitted' (conditional mean)
>>> METHODS on a uGARCHforecast object will return the forecast values of those
>>> quantities with appropriately labelled dates (the T+0 time). This too is
>>> documented in the help files, and there was also a blog post about this
>>> ('Whats new in rugarch (ver 1.01-5)').
>>>
>>> For VaR, as I already mentioned, you can use the 'quantile' method on
>>> any of the returned S4 class objects.
>>>
>>> -Alexios
>>>
>>>
>>> On 07/05/2013 12:51, Neuman Co wrote:
>>>>
>>>> thanks a lot for your help, but
>>>> "Use the 'sigma' and 'fitted' methods"
>>>>
>>>> But these are the fitted values for the volatility and the final
>>>> fitted values. But to calculate the VaR I need the 1 step ahead
>>>> forecast of the cond. sigmas and the 1 step ahead forecast of the
>>>> cond. mean. The cond.mean is not equivalent to the fitted values? And
>>>> the fitted values are not one step ahead forecasts?
>>>>
>>>> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>>>>>
>>>>> Hello,
>>>>>
>>>>>
>>>>> On 07/05/2013 12:15, Neuman Co wrote:
>>>>>>
>>>>>>
>>>>>> I am using the rugarch package in R and I have some questions:
>>>>>>
>>>>>> I want to use the rugarch package to calculate the VaR.
>>>>>>
>>>>>> I used the following code to to fit a certain model:
>>>>>>
>>>>>> spec2<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>>>>>> c(1, 1)),
>>>>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>>>>> distribution.model =
>>>>>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>>>>>
>>>>>> model2<-ugarchfit(spec=spec2,data=mydata)
>>>>>>
>>>>>> Now I can look at the 2.5 % VaR with the following command:
>>>>>> plot(model)
>>>>>>
>>>>>> and choosing the second plot.
>>>>>>
>>>>>> Now my first question is: How can I get the 1.0% VaR VALUES, so not
>>>>>> the plot, but
>>>>>> the values/numbers?
>>>>>
>>>>>
>>>>> Use the 'quantile' method i.e. 'quantile(model2, 0.01)'...also applies to
>>>>> uGARCHforecast, uGARCHsim etc It IS documented.
>>>>>
>>>>>>
>>>>>> In case of the normal distribution, one can easily do the calculation of
>>>>>> the VaR with using the forecasted conditional volatility and the
>>>>>> forecasted
>>>>>> conditional mean:
>>>>>>
>>>>>> I use the ugarchforecast command and with that I can get the cond.
>>>>>> volatility
>>>>>> and cond. mean (my mean equation is an modified ARMA(5,5), see above in
>>>>>> the spec
>>>>>> command):
>>>>>>
>>>>>> forecast = ugarchforecast(spec, data, n.roll = , n.ahead = ,
>>>>>> out.sample=)
>>>>>>
>>>>>> # conditional mean
>>>>>> cmu = as.numeric(as.data.frame(forecast, which = "series",
>>>>>> rollframe="all", aligned = FALSE))
>>>>>> # conditional sigma
>>>>>> csigma = as.numeric(as.data.frame(forecast, which = "sigma",
>>>>>> rollframe="all", aligned = FALSE))
>>>>>>
>>>>> NO. 'as.data.frame' has long been deprecated. Use the 'sigma' and
>>>>> 'fitted'
>>>>> methods (and make sure you upgrade to latest version of rugarch).
>>>>>
>>>>>
>>>>>> I can calculate the VaR by using the property, that the normal
>>>>>> distribution
>>>>>> is part of the location-scale distribution families
>>>>>>
>>>>>> # use location+scaling transformation property of normal distribution:
>>>>>> VaR = qnorm(0.01)*csigma + cmu
>>>>>>
>>>>>> My second question belongs to the n.roll and out.sample command. I had
>>>>>> a look at the
>>>>>> description
>>>>>> http://www.inside-r.org/packages/cran/rugarch/docs/ugarchforecast
>>>>>> but I did not understand the n.roll and out.sample command. I want to
>>>>>> calculate the
>>>>>> daily VaR, so I need one step ahead predicitons and I do not want to
>>>>>> reestimate
>>>>>> the model every time step. So what does it mean "to roll the forecast
>>>>>> 1 step " and
>>>>>> what is out.sample?
>>>>>
>>>>>
>>>>> out.sample, which is used in the estimation stage retains 'out.sample'
>>>>> data
>>>>> (i.e. they are not used in the estimation) so that a rolling forecast can
>>>>> then be performed using this data. 'Rolling' means using data at time T-p
>>>>> (p=lag) to create a conditional 1-ahead forecast at time T. For the
>>>>> ugarchforecast method, this means using only estimates of the parameters
>>>>> from length(data)-out.sample. There is no re-estimation taking place
>>>>> (this
>>>>> is only done in the ugarchroll method).
>>>>> For n.ahead>1, this becomes an unconditional forecast. Equivalently, you
>>>>> can
>>>>> append new data to your old dataset and use the ugarchfilter method.
>>>>>
>>>>>>
>>>>>> My third question(s) is (are): How to calculate the VaR in case of a
>>>>>> standardized
>>>>>> hyperbolic distribution? Can I still calculate it like in the normal
>>>>>> case
>>>>>> or does it not work anymore (I am not sure, if the sdhyp belongs to the
>>>>>> location-scale family).
>>>>>>
>>>>>> Even if it does work (so if the sdhyp belongs to the family of
>>>>>> location-scale distributions) how do I calculate it in case of a
>>>>>> distribution, which does not belong to the location-scale family?
>>>>>> (I mean, if I cannot calculate it via VaR = uncmean + sigma* z_alpha how
>>>>>> do I have to calculate it). Which distribution implemented in the
>>>>>> rugarch
>>>>>> package does not belong to the location-scale family?
>>>>>>
>>>>> ALL distributions in the rugarch package are represented in a location-
>>>>> and
>>>>> scale- invariant parameterization since this is a key property required
>>>>> in
>>>>> working with the standardized residuals in the density function (i.e. the
>>>>> subtraction of the mean and scaling by the volatility).
>>>>> The standardized Generalized Hyperbolic distribution does indeed have
>>>>> this
>>>>> property, and details are available in the vignette. See also paper by
>>>>> Blaesild (http://biomet.oxfordjournals.org/content/68/1/251.short) for
>>>>> the
>>>>> linear transformation (aX+b) property.
>>>>>
>>>>> If working with the standard (NOT standardized) version of the GH
>>>>> distribution (\lambda, \alpha, \beta, \delta, \mu) you need to apply the
>>>>> location/scaling transformation as the example below shows which is
>>>>> equivalent to just using the location/scaling transformation in the
>>>>> standardized version:
>>>>> #################################################
>>>>> library(rugarch)
>>>>> # zeta = shape
>>>>> zeta = 0.4
>>>>> # rho = skew
>>>>> rho = 0.9
>>>>> # lambda = GIG mixing distribution shape parameter
>>>>> lambda=-1
>>>>> # POSITIVE scaling factor (sigma is in any always positive)
>>>>> # mean
>>>>> scaling = 0.02
>>>>> # sigma
>>>>> location = 0.001
>>>>>
>>>>> # standardized transformation based on (0,1,\rho,\zeta)
>>>>> # parameterization:
>>>>> x1 = scaling*qdist("ghyp", seq(0.001, 0.5, length.out=100), shape = zeta,
>>>>> skew = rho, lambda = lambda)+location
>>>>> # Equivalent to standard transformation:
>>>>> # First obtain the standard parameters (which have a mean of zero
>>>>> # and sigma of 1).
>>>>> parms = rugarch:::.paramGH(zeta, rho, lambda)
>>>>> x2 = rugarch:::.qgh( seq(0.001, 0.5, length.out=100), alpha =
>>>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling),
>>>>> delta=abs(scaling)*parms[3], mu = (scaling)*parms[4]+location, lambda =
>>>>> lambda)
>>>>> all.equal(x1, x2)
>>>>> # Notice the approximation error in the calculation of the quantile for #
>>>>> which there is no closed form solution (and rugarch uses a tolerance
>>>>> # value of .Machine$double.eps^0.25)
>>>>> # Load the GeneralizedHyperbolic package of Scott to adjust the
>>>>> # tolerance:
>>>>> library(GeneralizedHyperbolic)
>>>>>
>>>>> x1 = location+scaling*qghyp(seq(0.001, 0.5, length.out=100), mu =
>>>>> parms[4],
>>>>> delta = parms[3], alpha =  parms[1], beta = parms[2], lambda = lambda,
>>>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 501,
>>>>> subdivisions = 500, uniTol = 2e-12)
>>>>> # equivalent to:
>>>>> x2 = qghyp(seq(0.001, 0.5, length.out=100), mu =
>>>>> (scaling)*parms[4]+location, delta = abs(scaling)*parms[3], alpha =
>>>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling), lambda = lambda,
>>>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 501,
>>>>> subdivisions = 500, uniTol = 2e-12)
>>>>>
>>>>> all.equal(x1, x2)
>>>>> #################################################
>>>>>
>>>>>
>>>>>
>>>>>> Thanks a lot for your help!
>>>>>>
>>>>>
>>>>> Regards,
>>>>>
>>>>> Alexios
>>>>>>
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-SIG-Finance at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>>> -- Also note that this is not the r-help list where general R questions
>>>>>> should go.
>>>>>>
>>>>>
>>>>
>>>


From alexios at 4dscape.com  Wed May  8 12:55:14 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 08 May 2013 11:55:14 +0100
Subject: [R-SIG-Finance] rugarch VaR calculation "manually"
In-Reply-To: <CADih64SdsZWrpDRyoihSzZuiBR_qaa1tZJxpvvKOsKA0oLvhnA@mail.gmail.com>
References: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>
	<5188E6FF.7040304@4dscape.com>
	<CADih64RY4XoytMMpmPpO6sEW245oW=3SpWUKDmiupDKcbD6jEA@mail.gmail.com>
	<5188EC79.7060604@4dscape.com>
	<CADih64TsACXe=4iPcBVoaehHshOiyC5YTHVRd2Jdo3vFrNW_9g@mail.gmail.com>
	<CADih64QrM7bwy0f=N-fCfT9dZLbzi1qoiKnnL5-+5W=b0N+=Qg@mail.gmail.com>
	<CADih64SdsZWrpDRyoihSzZuiBR_qaa1tZJxpvvKOsKA0oLvhnA@mail.gmail.com>
Message-ID: <518A2F12.7030503@4dscape.com>

Please TRY to send one question, wait for a reply and then ask another 
rather than sending 3 emails in a row.

1. The only reason that you would not get an xts returned object in the 
example below is that you are using an old version of rugarch. Make sure 
you download the latest version (which requires R>=3.0.0) and update 
your packages. It is also good practice to send the output of
sessionInfo() in such cases.

2. I'm not sure what you mean by "one step ahead in sample predictions".
- If you want the 1-ahead forecast use ugarchforecast(alvnomodelgarch, 
n.ahead = 1)
- If you want the in-sample estimated values use 'fitted' and 'sigma'
(in which case the terminology you used in not 'standard').

3. There are enough examples in 'rugarch.tests' folder in the source 
distribution, online blog examples, previous mailing list posts, other 
online resources, for you to be able to do what you need.

Finally, I am more likely to respond to future requests for help if you 
provide minimally reproducible examples without sending zip files of 
your data (this is rarely needed), showed that you made an effort to 
read the documentation, and have signed your emails with your real name.

Regards,
Alexios

On 08/05/2013 11:28, Neuman Co wrote:
> I mean, I only try to get the one-step ahead in-sample predictions. So
> I do NOT want to leave out any observations in the estimation stage? I
> want to use all observations, estimate the GARCH and use the estimated
> parameters and data to get one step ahead in sample predictions so I
> can use these one-step-ahead-in-sample predictions of my cond.
> volatility and cond. mean to calculate the VaR.
>
> 2013/5/8 Neuman Co <neumancohu at gmail.com>:
>> Also http://www.unstarched.net/2013/02/27/whats-new-in-rugarch-ver-1-01-5/
>> does not work if I try it.
>> If I do
>> c(is(sigma((fit))), is(fitted(fit)), is(residuals(fit)))
>> I do not get xts xts xts but numeric vector and so on?
>>
>> If I try
>> plot(xts(fit at model$modeldata$data, fit at model$modeldata$index),
>> auto.grid = FALSE,
>>      minor.ticks = FALSE, main = 'S&P500 Conditional Mean')
>> lines(fitted(fit), col = 2)
>> grid()
>>
>> I get the error messages
>> Fehler in plot(xts(fit at model$modeldata$data, fit at model$modeldata$index),  :
>>    Fehler bei der Auswertung des Argumentes 'x' bei der Methodenauswahl
>> f?r Funktion 'plot': Fehler in xts(fit at model$modeldata$data,
>> fit at model$modeldata$index) :
>>    order.by requires an appropriate time-based object
>>
>> and sigma(f) is also not working?
>> Fehler in UseMethod("sigma") :
>>    nicht anwendbare Methode f?r 'sigma' auf Objekt der Klasse
>> "c('uGARCHforecast', 'GARCHforecast', 'rGARCH')" angewendet
>>>
>>
>>
>> I just tried to understand the examples, but they do not work?
>>
>> 2013/5/8 Neuman Co <neumancohu at gmail.com>:
>>> The data I am working with can be found here:
>>> http://uploadeasy.net/upload/2fvhy.rar
>>>
>>> I fitted the following model:
>>> alvnomodel<-ugarchspec(variance.model = list(model = "sGARCH",
>>> garchOrder = c(1, 1)),
>>> mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
>>> distribution.model = "norm")
>>>
>>> alvnomodelgarch<-ugarchfit(spec=alvnomodel,data=alvlloss)
>>>
>>> Now I want to get the one-day ahead forecasts of the cond. volatility
>>> and the cond. mean. I try to applay ugrachforecast:
>>>
>>> ugarchforecast(alvnomodelgarch, n.ahead = 1,out.sample=50,n.roll=10)
>>>
>>> But I get the error message:
>>> ugarchforecast-->error: n.roll must not be greater than out.sample!
>>>
>>> What is wrong?
>>>
>>> Also I don't know what values I should take for out.sample and n.roll?
>>> I just want to get 1 day ahead forecasts. What values do I need to
>>> insert?
>>>
>>> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>>>> Applying 'sigma' (conditional volatility) and 'fitted' (conditional mean)
>>>> METHODS on a uGARCHforecast object will return the forecast values of those
>>>> quantities with appropriately labelled dates (the T+0 time). This too is
>>>> documented in the help files, and there was also a blog post about this
>>>> ('Whats new in rugarch (ver 1.01-5)').
>>>>
>>>> For VaR, as I already mentioned, you can use the 'quantile' method on
>>>> any of the returned S4 class objects.
>>>>
>>>> -Alexios
>>>>
>>>>
>>>> On 07/05/2013 12:51, Neuman Co wrote:
>>>>>
>>>>> thanks a lot for your help, but
>>>>> "Use the 'sigma' and 'fitted' methods"
>>>>>
>>>>> But these are the fitted values for the volatility and the final
>>>>> fitted values. But to calculate the VaR I need the 1 step ahead
>>>>> forecast of the cond. sigmas and the 1 step ahead forecast of the
>>>>> cond. mean. The cond.mean is not equivalent to the fitted values? And
>>>>> the fitted values are not one step ahead forecasts?
>>>>>
>>>>> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>>>>>>
>>>>>> Hello,
>>>>>>
>>>>>>
>>>>>> On 07/05/2013 12:15, Neuman Co wrote:
>>>>>>>
>>>>>>>
>>>>>>> I am using the rugarch package in R and I have some questions:
>>>>>>>
>>>>>>> I want to use the rugarch package to calculate the VaR.
>>>>>>>
>>>>>>> I used the following code to to fit a certain model:
>>>>>>>
>>>>>>> spec2<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>>>>>>> c(1, 1)),
>>>>>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>>>>>> distribution.model =
>>>>>>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>>>>>>
>>>>>>> model2<-ugarchfit(spec=spec2,data=mydata)
>>>>>>>
>>>>>>> Now I can look at the 2.5 % VaR with the following command:
>>>>>>> plot(model)
>>>>>>>
>>>>>>> and choosing the second plot.
>>>>>>>
>>>>>>> Now my first question is: How can I get the 1.0% VaR VALUES, so not
>>>>>>> the plot, but
>>>>>>> the values/numbers?
>>>>>>
>>>>>>
>>>>>> Use the 'quantile' method i.e. 'quantile(model2, 0.01)'...also applies to
>>>>>> uGARCHforecast, uGARCHsim etc It IS documented.
>>>>>>
>>>>>>>
>>>>>>> In case of the normal distribution, one can easily do the calculation of
>>>>>>> the VaR with using the forecasted conditional volatility and the
>>>>>>> forecasted
>>>>>>> conditional mean:
>>>>>>>
>>>>>>> I use the ugarchforecast command and with that I can get the cond.
>>>>>>> volatility
>>>>>>> and cond. mean (my mean equation is an modified ARMA(5,5), see above in
>>>>>>> the spec
>>>>>>> command):
>>>>>>>
>>>>>>> forecast = ugarchforecast(spec, data, n.roll = , n.ahead = ,
>>>>>>> out.sample=)
>>>>>>>
>>>>>>> # conditional mean
>>>>>>> cmu = as.numeric(as.data.frame(forecast, which = "series",
>>>>>>> rollframe="all", aligned = FALSE))
>>>>>>> # conditional sigma
>>>>>>> csigma = as.numeric(as.data.frame(forecast, which = "sigma",
>>>>>>> rollframe="all", aligned = FALSE))
>>>>>>>
>>>>>> NO. 'as.data.frame' has long been deprecated. Use the 'sigma' and
>>>>>> 'fitted'
>>>>>> methods (and make sure you upgrade to latest version of rugarch).
>>>>>>
>>>>>>
>>>>>>> I can calculate the VaR by using the property, that the normal
>>>>>>> distribution
>>>>>>> is part of the location-scale distribution families
>>>>>>>
>>>>>>> # use location+scaling transformation property of normal distribution:
>>>>>>> VaR = qnorm(0.01)*csigma + cmu
>>>>>>>
>>>>>>> My second question belongs to the n.roll and out.sample command. I had
>>>>>>> a look at the
>>>>>>> description
>>>>>>> http://www.inside-r.org/packages/cran/rugarch/docs/ugarchforecast
>>>>>>> but I did not understand the n.roll and out.sample command. I want to
>>>>>>> calculate the
>>>>>>> daily VaR, so I need one step ahead predicitons and I do not want to
>>>>>>> reestimate
>>>>>>> the model every time step. So what does it mean "to roll the forecast
>>>>>>> 1 step " and
>>>>>>> what is out.sample?
>>>>>>
>>>>>>
>>>>>> out.sample, which is used in the estimation stage retains 'out.sample'
>>>>>> data
>>>>>> (i.e. they are not used in the estimation) so that a rolling forecast can
>>>>>> then be performed using this data. 'Rolling' means using data at time T-p
>>>>>> (p=lag) to create a conditional 1-ahead forecast at time T. For the
>>>>>> ugarchforecast method, this means using only estimates of the parameters
>>>>>> from length(data)-out.sample. There is no re-estimation taking place
>>>>>> (this
>>>>>> is only done in the ugarchroll method).
>>>>>> For n.ahead>1, this becomes an unconditional forecast. Equivalently, you
>>>>>> can
>>>>>> append new data to your old dataset and use the ugarchfilter method.
>>>>>>
>>>>>>>
>>>>>>> My third question(s) is (are): How to calculate the VaR in case of a
>>>>>>> standardized
>>>>>>> hyperbolic distribution? Can I still calculate it like in the normal
>>>>>>> case
>>>>>>> or does it not work anymore (I am not sure, if the sdhyp belongs to the
>>>>>>> location-scale family).
>>>>>>>
>>>>>>> Even if it does work (so if the sdhyp belongs to the family of
>>>>>>> location-scale distributions) how do I calculate it in case of a
>>>>>>> distribution, which does not belong to the location-scale family?
>>>>>>> (I mean, if I cannot calculate it via VaR = uncmean + sigma* z_alpha how
>>>>>>> do I have to calculate it). Which distribution implemented in the
>>>>>>> rugarch
>>>>>>> package does not belong to the location-scale family?
>>>>>>>
>>>>>> ALL distributions in the rugarch package are represented in a location-
>>>>>> and
>>>>>> scale- invariant parameterization since this is a key property required
>>>>>> in
>>>>>> working with the standardized residuals in the density function (i.e. the
>>>>>> subtraction of the mean and scaling by the volatility).
>>>>>> The standardized Generalized Hyperbolic distribution does indeed have
>>>>>> this
>>>>>> property, and details are available in the vignette. See also paper by
>>>>>> Blaesild (http://biomet.oxfordjournals.org/content/68/1/251.short) for
>>>>>> the
>>>>>> linear transformation (aX+b) property.
>>>>>>
>>>>>> If working with the standard (NOT standardized) version of the GH
>>>>>> distribution (\lambda, \alpha, \beta, \delta, \mu) you need to apply the
>>>>>> location/scaling transformation as the example below shows which is
>>>>>> equivalent to just using the location/scaling transformation in the
>>>>>> standardized version:
>>>>>> #################################################
>>>>>> library(rugarch)
>>>>>> # zeta = shape
>>>>>> zeta = 0.4
>>>>>> # rho = skew
>>>>>> rho = 0.9
>>>>>> # lambda = GIG mixing distribution shape parameter
>>>>>> lambda=-1
>>>>>> # POSITIVE scaling factor (sigma is in any always positive)
>>>>>> # mean
>>>>>> scaling = 0.02
>>>>>> # sigma
>>>>>> location = 0.001
>>>>>>
>>>>>> # standardized transformation based on (0,1,\rho,\zeta)
>>>>>> # parameterization:
>>>>>> x1 = scaling*qdist("ghyp", seq(0.001, 0.5, length.out=100), shape = zeta,
>>>>>> skew = rho, lambda = lambda)+location
>>>>>> # Equivalent to standard transformation:
>>>>>> # First obtain the standard parameters (which have a mean of zero
>>>>>> # and sigma of 1).
>>>>>> parms = rugarch:::.paramGH(zeta, rho, lambda)
>>>>>> x2 = rugarch:::.qgh( seq(0.001, 0.5, length.out=100), alpha =
>>>>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling),
>>>>>> delta=abs(scaling)*parms[3], mu = (scaling)*parms[4]+location, lambda =
>>>>>> lambda)
>>>>>> all.equal(x1, x2)
>>>>>> # Notice the approximation error in the calculation of the quantile for #
>>>>>> which there is no closed form solution (and rugarch uses a tolerance
>>>>>> # value of .Machine$double.eps^0.25)
>>>>>> # Load the GeneralizedHyperbolic package of Scott to adjust the
>>>>>> # tolerance:
>>>>>> library(GeneralizedHyperbolic)
>>>>>>
>>>>>> x1 = location+scaling*qghyp(seq(0.001, 0.5, length.out=100), mu =
>>>>>> parms[4],
>>>>>> delta = parms[3], alpha =  parms[1], beta = parms[2], lambda = lambda,
>>>>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 501,
>>>>>> subdivisions = 500, uniTol = 2e-12)
>>>>>> # equivalent to:
>>>>>> x2 = qghyp(seq(0.001, 0.5, length.out=100), mu =
>>>>>> (scaling)*parms[4]+location, delta = abs(scaling)*parms[3], alpha =
>>>>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling), lambda = lambda,
>>>>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol = 501,
>>>>>> subdivisions = 500, uniTol = 2e-12)
>>>>>>
>>>>>> all.equal(x1, x2)
>>>>>> #################################################
>>>>>>
>>>>>>
>>>>>>
>>>>>>> Thanks a lot for your help!
>>>>>>>
>>>>>>
>>>>>> Regards,
>>>>>>
>>>>>> Alexios
>>>>>>>
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-SIG-Finance at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>>>> -- Also note that this is not the r-help list where general R questions
>>>>>>> should go.
>>>>>>>
>>>>>>
>>>>>
>>>>
>


From neumancohu at gmail.com  Wed May  8 13:06:04 2013
From: neumancohu at gmail.com (Neuman Co)
Date: Wed, 8 May 2013 13:06:04 +0200
Subject: [R-SIG-Finance] rugarch VaR calculation "manually"
In-Reply-To: <518A2F12.7030503@4dscape.com>
References: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>
	<5188E6FF.7040304@4dscape.com>
	<CADih64RY4XoytMMpmPpO6sEW245oW=3SpWUKDmiupDKcbD6jEA@mail.gmail.com>
	<5188EC79.7060604@4dscape.com>
	<CADih64TsACXe=4iPcBVoaehHshOiyC5YTHVRd2Jdo3vFrNW_9g@mail.gmail.com>
	<CADih64QrM7bwy0f=N-fCfT9dZLbzi1qoiKnnL5-+5W=b0N+=Qg@mail.gmail.com>
	<CADih64SdsZWrpDRyoihSzZuiBR_qaa1tZJxpvvKOsKA0oLvhnA@mail.gmail.com>
	<518A2F12.7030503@4dscape.com>
Message-ID: <CADih64QudPg=Ur2kz9TsUcMQBD1jqfNCzLqPfv_Gc1A-r6RTug@mail.gmail.com>

well but this is exactly the point, that

ugarchforecast(alvnomodelgarch, n.ahead = 1)

just gives me one forecast, but I want to have this from my beginning
of the time series up to the end. So I do not want to exclude these
observations in my fitting. I want to use all observations for my
fitting and then do one step ahead in sample predictions. So e.g. I
have a time series of 1000 observations. I to the fitting with the
1000 observations and then I want to predict the one step ahead
in-sample forecasts of the cond. mean and the cond. volatility?

I do not understand the thing with the fitted and the sigma. Correct
me if I am wrong, but these are the fitted values, these are not
1-step-ahead forecasts?

I try to give a more simpler example to make the understanding easier:
consider a simple linear regression:
The fitted values of y at time point t use the realization of x at
time point t. The one step ahead forecast uses the realization of
timepoint minus 1.

So I do NOT want to have the fitted values of the cond. volatility and
the cond. mean (in my case the cond. mean is zero, because I have
specified no model for it), but the one step ahead forecasts of it. So
R should do the n.ahead=1 not only for the last value, but from the
beginning up to the end?

I mean I only get the forecast of the next day, the 2013-03-04, but I
want to have it from the beginning up to the end?






2013/5/8 alexios ghalanos <alexios at 4dscape.com>:
> Please TRY to send one question, wait for a reply and then ask another
> rather than sending 3 emails in a row.
>
> 1. The only reason that you would not get an xts returned object in the
> example below is that you are using an old version of rugarch. Make sure you
> download the latest version (which requires R>=3.0.0) and update your
> packages. It is also good practice to send the output of
> sessionInfo() in such cases.
>
> 2. I'm not sure what you mean by "one step ahead in sample predictions".
> - If you want the 1-ahead forecast use ugarchforecast(alvnomodelgarch,
> n.ahead = 1)
> - If you want the in-sample estimated values use 'fitted' and 'sigma'
> (in which case the terminology you used in not 'standard').
>
> 3. There are enough examples in 'rugarch.tests' folder in the source
> distribution, online blog examples, previous mailing list posts, other
> online resources, for you to be able to do what you need.
>
> Finally, I am more likely to respond to future requests for help if you
> provide minimally reproducible examples without sending zip files of your
> data (this is rarely needed), showed that you made an effort to read the
> documentation, and have signed your emails with your real name.
>
> Regards,
> Alexios
>
>
> On 08/05/2013 11:28, Neuman Co wrote:
>>
>> I mean, I only try to get the one-step ahead in-sample predictions. So
>> I do NOT want to leave out any observations in the estimation stage? I
>> want to use all observations, estimate the GARCH and use the estimated
>> parameters and data to get one step ahead in sample predictions so I
>> can use these one-step-ahead-in-sample predictions of my cond.
>> volatility and cond. mean to calculate the VaR.
>>
>> 2013/5/8 Neuman Co <neumancohu at gmail.com>:
>>>
>>> Also
>>> http://www.unstarched.net/2013/02/27/whats-new-in-rugarch-ver-1-01-5/
>>> does not work if I try it.
>>> If I do
>>> c(is(sigma((fit))), is(fitted(fit)), is(residuals(fit)))
>>> I do not get xts xts xts but numeric vector and so on?
>>>
>>> If I try
>>> plot(xts(fit at model$modeldata$data, fit at model$modeldata$index),
>>> auto.grid = FALSE,
>>>      minor.ticks = FALSE, main = 'S&P500 Conditional Mean')
>>> lines(fitted(fit), col = 2)
>>> grid()
>>>
>>> I get the error messages
>>> Fehler in plot(xts(fit at model$modeldata$data, fit at model$modeldata$index),
>>> :
>>>    Fehler bei der Auswertung des Argumentes 'x' bei der Methodenauswahl
>>> f?r Funktion 'plot': Fehler in xts(fit at model$modeldata$data,
>>> fit at model$modeldata$index) :
>>>    order.by requires an appropriate time-based object
>>>
>>> and sigma(f) is also not working?
>>> Fehler in UseMethod("sigma") :
>>>    nicht anwendbare Methode f?r 'sigma' auf Objekt der Klasse
>>> "c('uGARCHforecast', 'GARCHforecast', 'rGARCH')" angewendet
>>>>
>>>>
>>>
>>>
>>> I just tried to understand the examples, but they do not work?
>>>
>>> 2013/5/8 Neuman Co <neumancohu at gmail.com>:
>>>>
>>>> The data I am working with can be found here:
>>>> http://uploadeasy.net/upload/2fvhy.rar
>>>>
>>>> I fitted the following model:
>>>> alvnomodel<-ugarchspec(variance.model = list(model = "sGARCH",
>>>> garchOrder = c(1, 1)),
>>>> mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
>>>> distribution.model = "norm")
>>>>
>>>> alvnomodelgarch<-ugarchfit(spec=alvnomodel,data=alvlloss)
>>>>
>>>> Now I want to get the one-day ahead forecasts of the cond. volatility
>>>> and the cond. mean. I try to applay ugrachforecast:
>>>>
>>>> ugarchforecast(alvnomodelgarch, n.ahead = 1,out.sample=50,n.roll=10)
>>>>
>>>> But I get the error message:
>>>> ugarchforecast-->error: n.roll must not be greater than out.sample!
>>>>
>>>> What is wrong?
>>>>
>>>> Also I don't know what values I should take for out.sample and n.roll?
>>>> I just want to get 1 day ahead forecasts. What values do I need to
>>>> insert?
>>>>
>>>> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>>>>>
>>>>> Applying 'sigma' (conditional volatility) and 'fitted' (conditional
>>>>> mean)
>>>>> METHODS on a uGARCHforecast object will return the forecast values of
>>>>> those
>>>>> quantities with appropriately labelled dates (the T+0 time). This too
>>>>> is
>>>>> documented in the help files, and there was also a blog post about this
>>>>> ('Whats new in rugarch (ver 1.01-5)').
>>>>>
>>>>> For VaR, as I already mentioned, you can use the 'quantile' method on
>>>>> any of the returned S4 class objects.
>>>>>
>>>>> -Alexios
>>>>>
>>>>>
>>>>> On 07/05/2013 12:51, Neuman Co wrote:
>>>>>>
>>>>>>
>>>>>> thanks a lot for your help, but
>>>>>> "Use the 'sigma' and 'fitted' methods"
>>>>>>
>>>>>> But these are the fitted values for the volatility and the final
>>>>>> fitted values. But to calculate the VaR I need the 1 step ahead
>>>>>> forecast of the cond. sigmas and the 1 step ahead forecast of the
>>>>>> cond. mean. The cond.mean is not equivalent to the fitted values? And
>>>>>> the fitted values are not one step ahead forecasts?
>>>>>>
>>>>>> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>>>>>>>
>>>>>>>
>>>>>>> Hello,
>>>>>>>
>>>>>>>
>>>>>>> On 07/05/2013 12:15, Neuman Co wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> I am using the rugarch package in R and I have some questions:
>>>>>>>>
>>>>>>>> I want to use the rugarch package to calculate the VaR.
>>>>>>>>
>>>>>>>> I used the following code to to fit a certain model:
>>>>>>>>
>>>>>>>> spec2<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder
>>>>>>>> =
>>>>>>>> c(1, 1)),
>>>>>>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>>>>>>> distribution.model =
>>>>>>>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>>>>>>>
>>>>>>>> model2<-ugarchfit(spec=spec2,data=mydata)
>>>>>>>>
>>>>>>>> Now I can look at the 2.5 % VaR with the following command:
>>>>>>>> plot(model)
>>>>>>>>
>>>>>>>> and choosing the second plot.
>>>>>>>>
>>>>>>>> Now my first question is: How can I get the 1.0% VaR VALUES, so not
>>>>>>>> the plot, but
>>>>>>>> the values/numbers?
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Use the 'quantile' method i.e. 'quantile(model2, 0.01)'...also
>>>>>>> applies to
>>>>>>> uGARCHforecast, uGARCHsim etc It IS documented.
>>>>>>>
>>>>>>>>
>>>>>>>> In case of the normal distribution, one can easily do the
>>>>>>>> calculation of
>>>>>>>> the VaR with using the forecasted conditional volatility and the
>>>>>>>> forecasted
>>>>>>>> conditional mean:
>>>>>>>>
>>>>>>>> I use the ugarchforecast command and with that I can get the cond.
>>>>>>>> volatility
>>>>>>>> and cond. mean (my mean equation is an modified ARMA(5,5), see above
>>>>>>>> in
>>>>>>>> the spec
>>>>>>>> command):
>>>>>>>>
>>>>>>>> forecast = ugarchforecast(spec, data, n.roll = , n.ahead = ,
>>>>>>>> out.sample=)
>>>>>>>>
>>>>>>>> # conditional mean
>>>>>>>> cmu = as.numeric(as.data.frame(forecast, which = "series",
>>>>>>>> rollframe="all", aligned = FALSE))
>>>>>>>> # conditional sigma
>>>>>>>> csigma = as.numeric(as.data.frame(forecast, which = "sigma",
>>>>>>>> rollframe="all", aligned = FALSE))
>>>>>>>>
>>>>>>> NO. 'as.data.frame' has long been deprecated. Use the 'sigma' and
>>>>>>> 'fitted'
>>>>>>> methods (and make sure you upgrade to latest version of rugarch).
>>>>>>>
>>>>>>>
>>>>>>>> I can calculate the VaR by using the property, that the normal
>>>>>>>> distribution
>>>>>>>> is part of the location-scale distribution families
>>>>>>>>
>>>>>>>> # use location+scaling transformation property of normal
>>>>>>>> distribution:
>>>>>>>> VaR = qnorm(0.01)*csigma + cmu
>>>>>>>>
>>>>>>>> My second question belongs to the n.roll and out.sample command. I
>>>>>>>> had
>>>>>>>> a look at the
>>>>>>>> description
>>>>>>>> http://www.inside-r.org/packages/cran/rugarch/docs/ugarchforecast
>>>>>>>> but I did not understand the n.roll and out.sample command. I want
>>>>>>>> to
>>>>>>>> calculate the
>>>>>>>> daily VaR, so I need one step ahead predicitons and I do not want to
>>>>>>>> reestimate
>>>>>>>> the model every time step. So what does it mean "to roll the
>>>>>>>> forecast
>>>>>>>> 1 step " and
>>>>>>>> what is out.sample?
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> out.sample, which is used in the estimation stage retains
>>>>>>> 'out.sample'
>>>>>>> data
>>>>>>> (i.e. they are not used in the estimation) so that a rolling forecast
>>>>>>> can
>>>>>>> then be performed using this data. 'Rolling' means using data at time
>>>>>>> T-p
>>>>>>> (p=lag) to create a conditional 1-ahead forecast at time T. For the
>>>>>>> ugarchforecast method, this means using only estimates of the
>>>>>>> parameters
>>>>>>> from length(data)-out.sample. There is no re-estimation taking place
>>>>>>> (this
>>>>>>> is only done in the ugarchroll method).
>>>>>>> For n.ahead>1, this becomes an unconditional forecast. Equivalently,
>>>>>>> you
>>>>>>> can
>>>>>>> append new data to your old dataset and use the ugarchfilter method.
>>>>>>>
>>>>>>>>
>>>>>>>> My third question(s) is (are): How to calculate the VaR in case of a
>>>>>>>> standardized
>>>>>>>> hyperbolic distribution? Can I still calculate it like in the normal
>>>>>>>> case
>>>>>>>> or does it not work anymore (I am not sure, if the sdhyp belongs to
>>>>>>>> the
>>>>>>>> location-scale family).
>>>>>>>>
>>>>>>>> Even if it does work (so if the sdhyp belongs to the family of
>>>>>>>> location-scale distributions) how do I calculate it in case of a
>>>>>>>> distribution, which does not belong to the location-scale family?
>>>>>>>> (I mean, if I cannot calculate it via VaR = uncmean + sigma* z_alpha
>>>>>>>> how
>>>>>>>> do I have to calculate it). Which distribution implemented in the
>>>>>>>> rugarch
>>>>>>>> package does not belong to the location-scale family?
>>>>>>>>
>>>>>>> ALL distributions in the rugarch package are represented in a
>>>>>>> location-
>>>>>>> and
>>>>>>> scale- invariant parameterization since this is a key property
>>>>>>> required
>>>>>>> in
>>>>>>> working with the standardized residuals in the density function (i.e.
>>>>>>> the
>>>>>>> subtraction of the mean and scaling by the volatility).
>>>>>>> The standardized Generalized Hyperbolic distribution does indeed have
>>>>>>> this
>>>>>>> property, and details are available in the vignette. See also paper
>>>>>>> by
>>>>>>> Blaesild (http://biomet.oxfordjournals.org/content/68/1/251.short)
>>>>>>> for
>>>>>>> the
>>>>>>> linear transformation (aX+b) property.
>>>>>>>
>>>>>>> If working with the standard (NOT standardized) version of the GH
>>>>>>> distribution (\lambda, \alpha, \beta, \delta, \mu) you need to apply
>>>>>>> the
>>>>>>> location/scaling transformation as the example below shows which is
>>>>>>> equivalent to just using the location/scaling transformation in the
>>>>>>> standardized version:
>>>>>>> #################################################
>>>>>>> library(rugarch)
>>>>>>> # zeta = shape
>>>>>>> zeta = 0.4
>>>>>>> # rho = skew
>>>>>>> rho = 0.9
>>>>>>> # lambda = GIG mixing distribution shape parameter
>>>>>>> lambda=-1
>>>>>>> # POSITIVE scaling factor (sigma is in any always positive)
>>>>>>> # mean
>>>>>>> scaling = 0.02
>>>>>>> # sigma
>>>>>>> location = 0.001
>>>>>>>
>>>>>>> # standardized transformation based on (0,1,\rho,\zeta)
>>>>>>> # parameterization:
>>>>>>> x1 = scaling*qdist("ghyp", seq(0.001, 0.5, length.out=100), shape =
>>>>>>> zeta,
>>>>>>> skew = rho, lambda = lambda)+location
>>>>>>> # Equivalent to standard transformation:
>>>>>>> # First obtain the standard parameters (which have a mean of zero
>>>>>>> # and sigma of 1).
>>>>>>> parms = rugarch:::.paramGH(zeta, rho, lambda)
>>>>>>> x2 = rugarch:::.qgh( seq(0.001, 0.5, length.out=100), alpha =
>>>>>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling),
>>>>>>> delta=abs(scaling)*parms[3], mu = (scaling)*parms[4]+location, lambda
>>>>>>> =
>>>>>>> lambda)
>>>>>>> all.equal(x1, x2)
>>>>>>> # Notice the approximation error in the calculation of the quantile
>>>>>>> for #
>>>>>>> which there is no closed form solution (and rugarch uses a tolerance
>>>>>>> # value of .Machine$double.eps^0.25)
>>>>>>> # Load the GeneralizedHyperbolic package of Scott to adjust the
>>>>>>> # tolerance:
>>>>>>> library(GeneralizedHyperbolic)
>>>>>>>
>>>>>>> x1 = location+scaling*qghyp(seq(0.001, 0.5, length.out=100), mu =
>>>>>>> parms[4],
>>>>>>> delta = parms[3], alpha =  parms[1], beta = parms[2], lambda =
>>>>>>> lambda,
>>>>>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol =
>>>>>>> 501,
>>>>>>> subdivisions = 500, uniTol = 2e-12)
>>>>>>> # equivalent to:
>>>>>>> x2 = qghyp(seq(0.001, 0.5, length.out=100), mu =
>>>>>>> (scaling)*parms[4]+location, delta = abs(scaling)*parms[3], alpha =
>>>>>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling), lambda = lambda,
>>>>>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol =
>>>>>>> 501,
>>>>>>> subdivisions = 500, uniTol = 2e-12)
>>>>>>>
>>>>>>> all.equal(x1, x2)
>>>>>>> #################################################
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> Thanks a lot for your help!
>>>>>>>>
>>>>>>>
>>>>>>> Regards,
>>>>>>>
>>>>>>> Alexios
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-SIG-Finance at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>>>>> -- Also note that this is not the r-help list where general R
>>>>>>>> questions
>>>>>>>> should go.
>>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>
>


From brian at braverock.com  Wed May  8 13:15:31 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 08 May 2013 06:15:31 -0500
Subject: [R-SIG-Finance] rugarch VaR calculation "manually"
In-Reply-To: <CADih64QudPg=Ur2kz9TsUcMQBD1jqfNCzLqPfv_Gc1A-r6RTug@mail.gmail.com>
References: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>
	<5188E6FF.7040304@4dscape.com>
	<CADih64RY4XoytMMpmPpO6sEW245oW=3SpWUKDmiupDKcbD6jEA@mail.gmail.com>
	<5188EC79.7060604@4dscape.com>
	<CADih64TsACXe=4iPcBVoaehHshOiyC5YTHVRd2Jdo3vFrNW_9g@mail.gmail.com>
	<CADih64QrM7bwy0f=N-fCfT9dZLbzi1qoiKnnL5-+5W=b0N+=Qg@mail.gmail.com>
	<CADih64SdsZWrpDRyoihSzZuiBR_qaa1tZJxpvvKOsKA0oLvhnA@mail.gmail.com>
	<518A2F12.7030503@4dscape.com>
	<CADih64QudPg=Ur2kz9TsUcMQBD1jqfNCzLqPfv_Gc1A-r6RTug@mail.gmail.com>
Message-ID: <518A33D3.1050601@braverock.com>

On 05/08/2013 06:06 AM, Neuman Co wrote:
> I want to use all observations for my
> fitting and then do one step ahead in sample predictions.

There is no such thing as a one step ahead in-sample  *prediction*.

Please stop and think a moment about how absurd that is before you waste 
more of everyone's time.

At each time t, I may make a prediction for time t+1

ugarchroll will give you a set of rolling one or n step ahead 
*predictions*, as Alexios has also already told you.

If you want the in-sample *estimate* from the fitted model values (it is 
not a prediction), then you want the 'fitted' and 'sigma' values, as 
Alexios has told you at least twice now.

...and I still don't see you signing your name.

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From alexios at 4dscape.com  Wed May  8 13:20:46 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 08 May 2013 12:20:46 +0100
Subject: [R-SIG-Finance] rugarch VaR calculation "manually"
In-Reply-To: <CADih64QudPg=Ur2kz9TsUcMQBD1jqfNCzLqPfv_Gc1A-r6RTug@mail.gmail.com>
References: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>
	<5188E6FF.7040304@4dscape.com>
	<CADih64RY4XoytMMpmPpO6sEW245oW=3SpWUKDmiupDKcbD6jEA@mail.gmail.com>
	<5188EC79.7060604@4dscape.com>
	<CADih64TsACXe=4iPcBVoaehHshOiyC5YTHVRd2Jdo3vFrNW_9g@mail.gmail.com>
	<CADih64QrM7bwy0f=N-fCfT9dZLbzi1qoiKnnL5-+5W=b0N+=Qg@mail.gmail.com>
	<CADih64SdsZWrpDRyoihSzZuiBR_qaa1tZJxpvvKOsKA0oLvhnA@mail.gmail.com>
	<518A2F12.7030503@4dscape.com>
	<CADih64QudPg=Ur2kz9TsUcMQBD1jqfNCzLqPfv_Gc1A-r6RTug@mail.gmail.com>
Message-ID: <518A350E.9090706@4dscape.com>

That may be the case for your linear regression example, but certainly 
NOT the case in the ARMA-GARCH models. Everything is based on 
information upto time T-1. There is no "contemporaneous" data, as a 
reading of the vignette (where the models are clearly explained and 
formulated) shows. Therefore, and as pointed out before, USE the fitted, 
sigma, and quantile methods.

-Alexios

On 08/05/2013 12:06, Neuman Co wrote:
> well but this is exactly the point, that
>
> ugarchforecast(alvnomodelgarch, n.ahead = 1)
>
> just gives me one forecast, but I want to have this from my beginning
> of the time series up to the end. So I do not want to exclude these
> observations in my fitting. I want to use all observations for my
> fitting and then do one step ahead in sample predictions. So e.g. I
> have a time series of 1000 observations. I to the fitting with the
> 1000 observations and then I want to predict the one step ahead
> in-sample forecasts of the cond. mean and the cond. volatility?
>
> I do not understand the thing with the fitted and the sigma. Correct
> me if I am wrong, but these are the fitted values, these are not
> 1-step-ahead forecasts?
>
> I try to give a more simpler example to make the understanding easier:
> consider a simple linear regression:
> The fitted values of y at time point t use the realization of x at
> time point t. The one step ahead forecast uses the realization of
> timepoint minus 1.
>
> So I do NOT want to have the fitted values of the cond. volatility and
> the cond. mean (in my case the cond. mean is zero, because I have
> specified no model for it), but the one step ahead forecasts of it. So
> R should do the n.ahead=1 not only for the last value, but from the
> beginning up to the end?
>
> I mean I only get the forecast of the next day, the 2013-03-04, but I
> want to have it from the beginning up to the end?
>
>
>
>
>
>
> 2013/5/8 alexios ghalanos <alexios at 4dscape.com>:
>> Please TRY to send one question, wait for a reply and then ask another
>> rather than sending 3 emails in a row.
>>
>> 1. The only reason that you would not get an xts returned object in the
>> example below is that you are using an old version of rugarch. Make sure you
>> download the latest version (which requires R>=3.0.0) and update your
>> packages. It is also good practice to send the output of
>> sessionInfo() in such cases.
>>
>> 2. I'm not sure what you mean by "one step ahead in sample predictions".
>> - If you want the 1-ahead forecast use ugarchforecast(alvnomodelgarch,
>> n.ahead = 1)
>> - If you want the in-sample estimated values use 'fitted' and 'sigma'
>> (in which case the terminology you used in not 'standard').
>>
>> 3. There are enough examples in 'rugarch.tests' folder in the source
>> distribution, online blog examples, previous mailing list posts, other
>> online resources, for you to be able to do what you need.
>>
>> Finally, I am more likely to respond to future requests for help if you
>> provide minimally reproducible examples without sending zip files of your
>> data (this is rarely needed), showed that you made an effort to read the
>> documentation, and have signed your emails with your real name.
>>
>> Regards,
>> Alexios
>>
>>
>> On 08/05/2013 11:28, Neuman Co wrote:
>>>
>>> I mean, I only try to get the one-step ahead in-sample predictions. So
>>> I do NOT want to leave out any observations in the estimation stage? I
>>> want to use all observations, estimate the GARCH and use the estimated
>>> parameters and data to get one step ahead in sample predictions so I
>>> can use these one-step-ahead-in-sample predictions of my cond.
>>> volatility and cond. mean to calculate the VaR.
>>>
>>> 2013/5/8 Neuman Co <neumancohu at gmail.com>:
>>>>
>>>> Also
>>>> http://www.unstarched.net/2013/02/27/whats-new-in-rugarch-ver-1-01-5/
>>>> does not work if I try it.
>>>> If I do
>>>> c(is(sigma((fit))), is(fitted(fit)), is(residuals(fit)))
>>>> I do not get xts xts xts but numeric vector and so on?
>>>>
>>>> If I try
>>>> plot(xts(fit at model$modeldata$data, fit at model$modeldata$index),
>>>> auto.grid = FALSE,
>>>>       minor.ticks = FALSE, main = 'S&P500 Conditional Mean')
>>>> lines(fitted(fit), col = 2)
>>>> grid()
>>>>
>>>> I get the error messages
>>>> Fehler in plot(xts(fit at model$modeldata$data, fit at model$modeldata$index),
>>>> :
>>>>     Fehler bei der Auswertung des Argumentes 'x' bei der Methodenauswahl
>>>> f?r Funktion 'plot': Fehler in xts(fit at model$modeldata$data,
>>>> fit at model$modeldata$index) :
>>>>     order.by requires an appropriate time-based object
>>>>
>>>> and sigma(f) is also not working?
>>>> Fehler in UseMethod("sigma") :
>>>>     nicht anwendbare Methode f?r 'sigma' auf Objekt der Klasse
>>>> "c('uGARCHforecast', 'GARCHforecast', 'rGARCH')" angewendet
>>>>>
>>>>>
>>>>
>>>>
>>>> I just tried to understand the examples, but they do not work?
>>>>
>>>> 2013/5/8 Neuman Co <neumancohu at gmail.com>:
>>>>>
>>>>> The data I am working with can be found here:
>>>>> http://uploadeasy.net/upload/2fvhy.rar
>>>>>
>>>>> I fitted the following model:
>>>>> alvnomodel<-ugarchspec(variance.model = list(model = "sGARCH",
>>>>> garchOrder = c(1, 1)),
>>>>> mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
>>>>> distribution.model = "norm")
>>>>>
>>>>> alvnomodelgarch<-ugarchfit(spec=alvnomodel,data=alvlloss)
>>>>>
>>>>> Now I want to get the one-day ahead forecasts of the cond. volatility
>>>>> and the cond. mean. I try to applay ugrachforecast:
>>>>>
>>>>> ugarchforecast(alvnomodelgarch, n.ahead = 1,out.sample=50,n.roll=10)
>>>>>
>>>>> But I get the error message:
>>>>> ugarchforecast-->error: n.roll must not be greater than out.sample!
>>>>>
>>>>> What is wrong?
>>>>>
>>>>> Also I don't know what values I should take for out.sample and n.roll?
>>>>> I just want to get 1 day ahead forecasts. What values do I need to
>>>>> insert?
>>>>>
>>>>> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>>>>>>
>>>>>> Applying 'sigma' (conditional volatility) and 'fitted' (conditional
>>>>>> mean)
>>>>>> METHODS on a uGARCHforecast object will return the forecast values of
>>>>>> those
>>>>>> quantities with appropriately labelled dates (the T+0 time). This too
>>>>>> is
>>>>>> documented in the help files, and there was also a blog post about this
>>>>>> ('Whats new in rugarch (ver 1.01-5)').
>>>>>>
>>>>>> For VaR, as I already mentioned, you can use the 'quantile' method on
>>>>>> any of the returned S4 class objects.
>>>>>>
>>>>>> -Alexios
>>>>>>
>>>>>>
>>>>>> On 07/05/2013 12:51, Neuman Co wrote:
>>>>>>>
>>>>>>>
>>>>>>> thanks a lot for your help, but
>>>>>>> "Use the 'sigma' and 'fitted' methods"
>>>>>>>
>>>>>>> But these are the fitted values for the volatility and the final
>>>>>>> fitted values. But to calculate the VaR I need the 1 step ahead
>>>>>>> forecast of the cond. sigmas and the 1 step ahead forecast of the
>>>>>>> cond. mean. The cond.mean is not equivalent to the fitted values? And
>>>>>>> the fitted values are not one step ahead forecasts?
>>>>>>>
>>>>>>> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>>>>>>>>
>>>>>>>>
>>>>>>>> Hello,
>>>>>>>>
>>>>>>>>
>>>>>>>> On 07/05/2013 12:15, Neuman Co wrote:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> I am using the rugarch package in R and I have some questions:
>>>>>>>>>
>>>>>>>>> I want to use the rugarch package to calculate the VaR.
>>>>>>>>>
>>>>>>>>> I used the following code to to fit a certain model:
>>>>>>>>>
>>>>>>>>> spec2<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder
>>>>>>>>> =
>>>>>>>>> c(1, 1)),
>>>>>>>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>>>>>>>> distribution.model =
>>>>>>>>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>>>>>>>>
>>>>>>>>> model2<-ugarchfit(spec=spec2,data=mydata)
>>>>>>>>>
>>>>>>>>> Now I can look at the 2.5 % VaR with the following command:
>>>>>>>>> plot(model)
>>>>>>>>>
>>>>>>>>> and choosing the second plot.
>>>>>>>>>
>>>>>>>>> Now my first question is: How can I get the 1.0% VaR VALUES, so not
>>>>>>>>> the plot, but
>>>>>>>>> the values/numbers?
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> Use the 'quantile' method i.e. 'quantile(model2, 0.01)'...also
>>>>>>>> applies to
>>>>>>>> uGARCHforecast, uGARCHsim etc It IS documented.
>>>>>>>>
>>>>>>>>>
>>>>>>>>> In case of the normal distribution, one can easily do the
>>>>>>>>> calculation of
>>>>>>>>> the VaR with using the forecasted conditional volatility and the
>>>>>>>>> forecasted
>>>>>>>>> conditional mean:
>>>>>>>>>
>>>>>>>>> I use the ugarchforecast command and with that I can get the cond.
>>>>>>>>> volatility
>>>>>>>>> and cond. mean (my mean equation is an modified ARMA(5,5), see above
>>>>>>>>> in
>>>>>>>>> the spec
>>>>>>>>> command):
>>>>>>>>>
>>>>>>>>> forecast = ugarchforecast(spec, data, n.roll = , n.ahead = ,
>>>>>>>>> out.sample=)
>>>>>>>>>
>>>>>>>>> # conditional mean
>>>>>>>>> cmu = as.numeric(as.data.frame(forecast, which = "series",
>>>>>>>>> rollframe="all", aligned = FALSE))
>>>>>>>>> # conditional sigma
>>>>>>>>> csigma = as.numeric(as.data.frame(forecast, which = "sigma",
>>>>>>>>> rollframe="all", aligned = FALSE))
>>>>>>>>>
>>>>>>>> NO. 'as.data.frame' has long been deprecated. Use the 'sigma' and
>>>>>>>> 'fitted'
>>>>>>>> methods (and make sure you upgrade to latest version of rugarch).
>>>>>>>>
>>>>>>>>
>>>>>>>>> I can calculate the VaR by using the property, that the normal
>>>>>>>>> distribution
>>>>>>>>> is part of the location-scale distribution families
>>>>>>>>>
>>>>>>>>> # use location+scaling transformation property of normal
>>>>>>>>> distribution:
>>>>>>>>> VaR = qnorm(0.01)*csigma + cmu
>>>>>>>>>
>>>>>>>>> My second question belongs to the n.roll and out.sample command. I
>>>>>>>>> had
>>>>>>>>> a look at the
>>>>>>>>> description
>>>>>>>>> http://www.inside-r.org/packages/cran/rugarch/docs/ugarchforecast
>>>>>>>>> but I did not understand the n.roll and out.sample command. I want
>>>>>>>>> to
>>>>>>>>> calculate the
>>>>>>>>> daily VaR, so I need one step ahead predicitons and I do not want to
>>>>>>>>> reestimate
>>>>>>>>> the model every time step. So what does it mean "to roll the
>>>>>>>>> forecast
>>>>>>>>> 1 step " and
>>>>>>>>> what is out.sample?
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> out.sample, which is used in the estimation stage retains
>>>>>>>> 'out.sample'
>>>>>>>> data
>>>>>>>> (i.e. they are not used in the estimation) so that a rolling forecast
>>>>>>>> can
>>>>>>>> then be performed using this data. 'Rolling' means using data at time
>>>>>>>> T-p
>>>>>>>> (p=lag) to create a conditional 1-ahead forecast at time T. For the
>>>>>>>> ugarchforecast method, this means using only estimates of the
>>>>>>>> parameters
>>>>>>>> from length(data)-out.sample. There is no re-estimation taking place
>>>>>>>> (this
>>>>>>>> is only done in the ugarchroll method).
>>>>>>>> For n.ahead>1, this becomes an unconditional forecast. Equivalently,
>>>>>>>> you
>>>>>>>> can
>>>>>>>> append new data to your old dataset and use the ugarchfilter method.
>>>>>>>>
>>>>>>>>>
>>>>>>>>> My third question(s) is (are): How to calculate the VaR in case of a
>>>>>>>>> standardized
>>>>>>>>> hyperbolic distribution? Can I still calculate it like in the normal
>>>>>>>>> case
>>>>>>>>> or does it not work anymore (I am not sure, if the sdhyp belongs to
>>>>>>>>> the
>>>>>>>>> location-scale family).
>>>>>>>>>
>>>>>>>>> Even if it does work (so if the sdhyp belongs to the family of
>>>>>>>>> location-scale distributions) how do I calculate it in case of a
>>>>>>>>> distribution, which does not belong to the location-scale family?
>>>>>>>>> (I mean, if I cannot calculate it via VaR = uncmean + sigma* z_alpha
>>>>>>>>> how
>>>>>>>>> do I have to calculate it). Which distribution implemented in the
>>>>>>>>> rugarch
>>>>>>>>> package does not belong to the location-scale family?
>>>>>>>>>
>>>>>>>> ALL distributions in the rugarch package are represented in a
>>>>>>>> location-
>>>>>>>> and
>>>>>>>> scale- invariant parameterization since this is a key property
>>>>>>>> required
>>>>>>>> in
>>>>>>>> working with the standardized residuals in the density function (i.e.
>>>>>>>> the
>>>>>>>> subtraction of the mean and scaling by the volatility).
>>>>>>>> The standardized Generalized Hyperbolic distribution does indeed have
>>>>>>>> this
>>>>>>>> property, and details are available in the vignette. See also paper
>>>>>>>> by
>>>>>>>> Blaesild (http://biomet.oxfordjournals.org/content/68/1/251.short)
>>>>>>>> for
>>>>>>>> the
>>>>>>>> linear transformation (aX+b) property.
>>>>>>>>
>>>>>>>> If working with the standard (NOT standardized) version of the GH
>>>>>>>> distribution (\lambda, \alpha, \beta, \delta, \mu) you need to apply
>>>>>>>> the
>>>>>>>> location/scaling transformation as the example below shows which is
>>>>>>>> equivalent to just using the location/scaling transformation in the
>>>>>>>> standardized version:
>>>>>>>> #################################################
>>>>>>>> library(rugarch)
>>>>>>>> # zeta = shape
>>>>>>>> zeta = 0.4
>>>>>>>> # rho = skew
>>>>>>>> rho = 0.9
>>>>>>>> # lambda = GIG mixing distribution shape parameter
>>>>>>>> lambda=-1
>>>>>>>> # POSITIVE scaling factor (sigma is in any always positive)
>>>>>>>> # mean
>>>>>>>> scaling = 0.02
>>>>>>>> # sigma
>>>>>>>> location = 0.001
>>>>>>>>
>>>>>>>> # standardized transformation based on (0,1,\rho,\zeta)
>>>>>>>> # parameterization:
>>>>>>>> x1 = scaling*qdist("ghyp", seq(0.001, 0.5, length.out=100), shape =
>>>>>>>> zeta,
>>>>>>>> skew = rho, lambda = lambda)+location
>>>>>>>> # Equivalent to standard transformation:
>>>>>>>> # First obtain the standard parameters (which have a mean of zero
>>>>>>>> # and sigma of 1).
>>>>>>>> parms = rugarch:::.paramGH(zeta, rho, lambda)
>>>>>>>> x2 = rugarch:::.qgh( seq(0.001, 0.5, length.out=100), alpha =
>>>>>>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling),
>>>>>>>> delta=abs(scaling)*parms[3], mu = (scaling)*parms[4]+location, lambda
>>>>>>>> =
>>>>>>>> lambda)
>>>>>>>> all.equal(x1, x2)
>>>>>>>> # Notice the approximation error in the calculation of the quantile
>>>>>>>> for #
>>>>>>>> which there is no closed form solution (and rugarch uses a tolerance
>>>>>>>> # value of .Machine$double.eps^0.25)
>>>>>>>> # Load the GeneralizedHyperbolic package of Scott to adjust the
>>>>>>>> # tolerance:
>>>>>>>> library(GeneralizedHyperbolic)
>>>>>>>>
>>>>>>>> x1 = location+scaling*qghyp(seq(0.001, 0.5, length.out=100), mu =
>>>>>>>> parms[4],
>>>>>>>> delta = parms[3], alpha =  parms[1], beta = parms[2], lambda =
>>>>>>>> lambda,
>>>>>>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol =
>>>>>>>> 501,
>>>>>>>> subdivisions = 500, uniTol = 2e-12)
>>>>>>>> # equivalent to:
>>>>>>>> x2 = qghyp(seq(0.001, 0.5, length.out=100), mu =
>>>>>>>> (scaling)*parms[4]+location, delta = abs(scaling)*parms[3], alpha =
>>>>>>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling), lambda = lambda,
>>>>>>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol =
>>>>>>>> 501,
>>>>>>>> subdivisions = 500, uniTol = 2e-12)
>>>>>>>>
>>>>>>>> all.equal(x1, x2)
>>>>>>>> #################################################
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>> Thanks a lot for your help!
>>>>>>>>>
>>>>>>>>
>>>>>>>> Regards,
>>>>>>>>
>>>>>>>> Alexios
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> _______________________________________________
>>>>>>>>> R-SIG-Finance at r-project.org mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>>>>>> -- Also note that this is not the r-help list where general R
>>>>>>>>> questions
>>>>>>>>> should go.
>>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>
>>>
>>
>


From neumancohu at gmail.com  Thu May  9 09:31:33 2013
From: neumancohu at gmail.com (Neuman Co)
Date: Thu, 9 May 2013 09:31:33 +0200
Subject: [R-SIG-Finance] rugarch VaR calculation "manually"
In-Reply-To: <518A350E.9090706@4dscape.com>
References: <CADih64Rm7eSOw9oUj-ji2ok5p43+hb1q_ADX5N-Hg9MNJiRfwQ@mail.gmail.com>
	<5188E6FF.7040304@4dscape.com>
	<CADih64RY4XoytMMpmPpO6sEW245oW=3SpWUKDmiupDKcbD6jEA@mail.gmail.com>
	<5188EC79.7060604@4dscape.com>
	<CADih64TsACXe=4iPcBVoaehHshOiyC5YTHVRd2Jdo3vFrNW_9g@mail.gmail.com>
	<CADih64QrM7bwy0f=N-fCfT9dZLbzi1qoiKnnL5-+5W=b0N+=Qg@mail.gmail.com>
	<CADih64SdsZWrpDRyoihSzZuiBR_qaa1tZJxpvvKOsKA0oLvhnA@mail.gmail.com>
	<518A2F12.7030503@4dscape.com>
	<CADih64QudPg=Ur2kz9TsUcMQBD1jqfNCzLqPfv_Gc1A-r6RTug@mail.gmail.com>
	<518A350E.9090706@4dscape.com>
Message-ID: <CADih64SQ9ALvcNP9mcWiuuQvDR0BQGVqqBHsM8zT22URFcLtyQ@mail.gmail.com>

Thanks a lot for your help, ok, I added the signature in my mail and
the r sig list accout.

But to be honest neither I am not really understanding you nor are
your hints helping me. From someone other, I was told to use the
following code to get what I want:

(I add my model here specification again, so you do not have to search
in my posts before)

-----------------------------------------------------------------------------------
library(rugarch)
alvdatemod<-alvdate[-1]
alvgarchdata<-data.frame(alvlloss,row.names=alvdatemod)

alvnomodel<-ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
distribution.model = "norm")

alvnomodelgarch<-ugarchfit(spec=alvnomodel,data=alvgarchdata)
#plot(alvnomodelgarch)
-------------------------------------------------------------------------------------


and here comes the relevant part:


spec = getspec(alvnomodelgarch);
setfixed(spec) <- as.list(coef(alvnomodelgarch));
forecast = ugarchforecast(spec, n.ahead = 1, n.roll = 2579, data =
alvgarchdata[1:2580, ,drop=FALSE], out.sample = 2579);
sigma(forecast);
fitted(forecast)


I get the (german) error message after the sigma command:
Fehler in UseMethod("sigma") :
  nicht anwendbare Methode f?r 'sigma' auf Objekt der Klasse
"c('uGARCHforecast', 'GARCHforecast', 'rGARCH')" angewendet

And the forecast specification is also not what I want, if you just
look at forecast, you will see, that again I just got one value, this
is NOT what I want!

Also, I am not understanding why I have to use this n.roll number and
this out.sample number. Also, why can't I just use my dataset, but
instead use [1:2580, ,drop=FALSE] ? But these are just some smaller
unimportant questions.



Later on, I want to calculate the VaR and compare it to the quantile
method, therefore I would continue with the following idea, first,
calculate VaR:

VaR=fitted(forecast)+sigma(forecast)*qnorm(0.99)

and then compare it to the quantile method:

quantile(forecast,probs=0.99)

but it seemed, that I also did a syntax error here.


2013/5/8 alexios ghalanos <alexios at 4dscape.com>:
> That may be the case for your linear regression example, but certainly NOT
> the case in the ARMA-GARCH models. Everything is based on information upto
> time T-1. There is no "contemporaneous" data, as a reading of the vignette
> (where the models are clearly explained and formulated) shows. Therefore,
> and as pointed out before, USE the fitted, sigma, and quantile methods.
>
> -Alexios
>
>
> On 08/05/2013 12:06, Neuman Co wrote:
>>
>> well but this is exactly the point, that
>>
>> ugarchforecast(alvnomodelgarch, n.ahead = 1)
>>
>> just gives me one forecast, but I want to have this from my beginning
>> of the time series up to the end. So I do not want to exclude these
>> observations in my fitting. I want to use all observations for my
>> fitting and then do one step ahead in sample predictions. So e.g. I
>> have a time series of 1000 observations. I to the fitting with the
>> 1000 observations and then I want to predict the one step ahead
>> in-sample forecasts of the cond. mean and the cond. volatility?
>>
>> I do not understand the thing with the fitted and the sigma. Correct
>> me if I am wrong, but these are the fitted values, these are not
>> 1-step-ahead forecasts?
>>
>> I try to give a more simpler example to make the understanding easier:
>> consider a simple linear regression:
>> The fitted values of y at time point t use the realization of x at
>> time point t. The one step ahead forecast uses the realization of
>> timepoint minus 1.
>>
>> So I do NOT want to have the fitted values of the cond. volatility and
>> the cond. mean (in my case the cond. mean is zero, because I have
>> specified no model for it), but the one step ahead forecasts of it. So
>> R should do the n.ahead=1 not only for the last value, but from the
>> beginning up to the end?
>>
>> I mean I only get the forecast of the next day, the 2013-03-04, but I
>> want to have it from the beginning up to the end?
>>
>>
>>
>>
>>
>>
>> 2013/5/8 alexios ghalanos <alexios at 4dscape.com>:
>>>
>>> Please TRY to send one question, wait for a reply and then ask another
>>> rather than sending 3 emails in a row.
>>>
>>> 1. The only reason that you would not get an xts returned object in the
>>> example below is that you are using an old version of rugarch. Make sure
>>> you
>>> download the latest version (which requires R>=3.0.0) and update your
>>> packages. It is also good practice to send the output of
>>> sessionInfo() in such cases.
>>>
>>> 2. I'm not sure what you mean by "one step ahead in sample predictions".
>>> - If you want the 1-ahead forecast use ugarchforecast(alvnomodelgarch,
>>> n.ahead = 1)
>>> - If you want the in-sample estimated values use 'fitted' and 'sigma'
>>> (in which case the terminology you used in not 'standard').
>>>
>>> 3. There are enough examples in 'rugarch.tests' folder in the source
>>> distribution, online blog examples, previous mailing list posts, other
>>> online resources, for you to be able to do what you need.
>>>
>>> Finally, I am more likely to respond to future requests for help if you
>>> provide minimally reproducible examples without sending zip files of your
>>> data (this is rarely needed), showed that you made an effort to read the
>>> documentation, and have signed your emails with your real name.
>>>
>>> Regards,
>>> Alexios
>>>
>>>
>>> On 08/05/2013 11:28, Neuman Co wrote:
>>>>
>>>>
>>>> I mean, I only try to get the one-step ahead in-sample predictions. So
>>>> I do NOT want to leave out any observations in the estimation stage? I
>>>> want to use all observations, estimate the GARCH and use the estimated
>>>> parameters and data to get one step ahead in sample predictions so I
>>>> can use these one-step-ahead-in-sample predictions of my cond.
>>>> volatility and cond. mean to calculate the VaR.
>>>>
>>>> 2013/5/8 Neuman Co <neumancohu at gmail.com>:
>>>>>
>>>>>
>>>>> Also
>>>>> http://www.unstarched.net/2013/02/27/whats-new-in-rugarch-ver-1-01-5/
>>>>> does not work if I try it.
>>>>> If I do
>>>>> c(is(sigma((fit))), is(fitted(fit)), is(residuals(fit)))
>>>>> I do not get xts xts xts but numeric vector and so on?
>>>>>
>>>>> If I try
>>>>> plot(xts(fit at model$modeldata$data, fit at model$modeldata$index),
>>>>> auto.grid = FALSE,
>>>>>       minor.ticks = FALSE, main = 'S&P500 Conditional Mean')
>>>>> lines(fitted(fit), col = 2)
>>>>> grid()
>>>>>
>>>>> I get the error messages
>>>>> Fehler in plot(xts(fit at model$modeldata$data,
>>>>> fit at model$modeldata$index),
>>>>> :
>>>>>     Fehler bei der Auswertung des Argumentes 'x' bei der
>>>>> Methodenauswahl
>>>>> f?r Funktion 'plot': Fehler in xts(fit at model$modeldata$data,
>>>>> fit at model$modeldata$index) :
>>>>>     order.by requires an appropriate time-based object
>>>>>
>>>>> and sigma(f) is also not working?
>>>>> Fehler in UseMethod("sigma") :
>>>>>     nicht anwendbare Methode f?r 'sigma' auf Objekt der Klasse
>>>>> "c('uGARCHforecast', 'GARCHforecast', 'rGARCH')" angewendet
>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>> I just tried to understand the examples, but they do not work?
>>>>>
>>>>> 2013/5/8 Neuman Co <neumancohu at gmail.com>:
>>>>>>
>>>>>>
>>>>>> The data I am working with can be found here:
>>>>>> http://uploadeasy.net/upload/2fvhy.rar
>>>>>>
>>>>>> I fitted the following model:
>>>>>> alvnomodel<-ugarchspec(variance.model = list(model = "sGARCH",
>>>>>> garchOrder = c(1, 1)),
>>>>>> mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
>>>>>> distribution.model = "norm")
>>>>>>
>>>>>> alvnomodelgarch<-ugarchfit(spec=alvnomodel,data=alvlloss)
>>>>>>
>>>>>> Now I want to get the one-day ahead forecasts of the cond. volatility
>>>>>> and the cond. mean. I try to applay ugrachforecast:
>>>>>>
>>>>>> ugarchforecast(alvnomodelgarch, n.ahead = 1,out.sample=50,n.roll=10)
>>>>>>
>>>>>> But I get the error message:
>>>>>> ugarchforecast-->error: n.roll must not be greater than out.sample!
>>>>>>
>>>>>> What is wrong?
>>>>>>
>>>>>> Also I don't know what values I should take for out.sample and n.roll?
>>>>>> I just want to get 1 day ahead forecasts. What values do I need to
>>>>>> insert?
>>>>>>
>>>>>> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>>>>>>>
>>>>>>>
>>>>>>> Applying 'sigma' (conditional volatility) and 'fitted' (conditional
>>>>>>> mean)
>>>>>>> METHODS on a uGARCHforecast object will return the forecast values of
>>>>>>> those
>>>>>>> quantities with appropriately labelled dates (the T+0 time). This too
>>>>>>> is
>>>>>>> documented in the help files, and there was also a blog post about
>>>>>>> this
>>>>>>> ('Whats new in rugarch (ver 1.01-5)').
>>>>>>>
>>>>>>> For VaR, as I already mentioned, you can use the 'quantile' method on
>>>>>>> any of the returned S4 class objects.
>>>>>>>
>>>>>>> -Alexios
>>>>>>>
>>>>>>>
>>>>>>> On 07/05/2013 12:51, Neuman Co wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> thanks a lot for your help, but
>>>>>>>> "Use the 'sigma' and 'fitted' methods"
>>>>>>>>
>>>>>>>> But these are the fitted values for the volatility and the final
>>>>>>>> fitted values. But to calculate the VaR I need the 1 step ahead
>>>>>>>> forecast of the cond. sigmas and the 1 step ahead forecast of the
>>>>>>>> cond. mean. The cond.mean is not equivalent to the fitted values?
>>>>>>>> And
>>>>>>>> the fitted values are not one step ahead forecasts?
>>>>>>>>
>>>>>>>> 2013/5/7 alexios ghalanos <alexios at 4dscape.com>:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Hello,
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On 07/05/2013 12:15, Neuman Co wrote:
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> I am using the rugarch package in R and I have some questions:
>>>>>>>>>>
>>>>>>>>>> I want to use the rugarch package to calculate the VaR.
>>>>>>>>>>
>>>>>>>>>> I used the following code to to fit a certain model:
>>>>>>>>>>
>>>>>>>>>> spec2<-ugarchspec(variance.model = list(model = "sGARCH",
>>>>>>>>>> garchOrder
>>>>>>>>>> =
>>>>>>>>>> c(1, 1)),
>>>>>>>>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>>>>>>>>> distribution.model =
>>>>>>>>>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>>>>>>>>>
>>>>>>>>>> model2<-ugarchfit(spec=spec2,data=mydata)
>>>>>>>>>>
>>>>>>>>>> Now I can look at the 2.5 % VaR with the following command:
>>>>>>>>>> plot(model)
>>>>>>>>>>
>>>>>>>>>> and choosing the second plot.
>>>>>>>>>>
>>>>>>>>>> Now my first question is: How can I get the 1.0% VaR VALUES, so
>>>>>>>>>> not
>>>>>>>>>> the plot, but
>>>>>>>>>> the values/numbers?
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Use the 'quantile' method i.e. 'quantile(model2, 0.01)'...also
>>>>>>>>> applies to
>>>>>>>>> uGARCHforecast, uGARCHsim etc It IS documented.
>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> In case of the normal distribution, one can easily do the
>>>>>>>>>> calculation of
>>>>>>>>>> the VaR with using the forecasted conditional volatility and the
>>>>>>>>>> forecasted
>>>>>>>>>> conditional mean:
>>>>>>>>>>
>>>>>>>>>> I use the ugarchforecast command and with that I can get the cond.
>>>>>>>>>> volatility
>>>>>>>>>> and cond. mean (my mean equation is an modified ARMA(5,5), see
>>>>>>>>>> above
>>>>>>>>>> in
>>>>>>>>>> the spec
>>>>>>>>>> command):
>>>>>>>>>>
>>>>>>>>>> forecast = ugarchforecast(spec, data, n.roll = , n.ahead = ,
>>>>>>>>>> out.sample=)
>>>>>>>>>>
>>>>>>>>>> # conditional mean
>>>>>>>>>> cmu = as.numeric(as.data.frame(forecast, which = "series",
>>>>>>>>>> rollframe="all", aligned = FALSE))
>>>>>>>>>> # conditional sigma
>>>>>>>>>> csigma = as.numeric(as.data.frame(forecast, which = "sigma",
>>>>>>>>>> rollframe="all", aligned = FALSE))
>>>>>>>>>>
>>>>>>>>> NO. 'as.data.frame' has long been deprecated. Use the 'sigma' and
>>>>>>>>> 'fitted'
>>>>>>>>> methods (and make sure you upgrade to latest version of rugarch).
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> I can calculate the VaR by using the property, that the normal
>>>>>>>>>> distribution
>>>>>>>>>> is part of the location-scale distribution families
>>>>>>>>>>
>>>>>>>>>> # use location+scaling transformation property of normal
>>>>>>>>>> distribution:
>>>>>>>>>> VaR = qnorm(0.01)*csigma + cmu
>>>>>>>>>>
>>>>>>>>>> My second question belongs to the n.roll and out.sample command. I
>>>>>>>>>> had
>>>>>>>>>> a look at the
>>>>>>>>>> description
>>>>>>>>>> http://www.inside-r.org/packages/cran/rugarch/docs/ugarchforecast
>>>>>>>>>> but I did not understand the n.roll and out.sample command. I want
>>>>>>>>>> to
>>>>>>>>>> calculate the
>>>>>>>>>> daily VaR, so I need one step ahead predicitons and I do not want
>>>>>>>>>> to
>>>>>>>>>> reestimate
>>>>>>>>>> the model every time step. So what does it mean "to roll the
>>>>>>>>>> forecast
>>>>>>>>>> 1 step " and
>>>>>>>>>> what is out.sample?
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> out.sample, which is used in the estimation stage retains
>>>>>>>>> 'out.sample'
>>>>>>>>> data
>>>>>>>>> (i.e. they are not used in the estimation) so that a rolling
>>>>>>>>> forecast
>>>>>>>>> can
>>>>>>>>> then be performed using this data. 'Rolling' means using data at
>>>>>>>>> time
>>>>>>>>> T-p
>>>>>>>>> (p=lag) to create a conditional 1-ahead forecast at time T. For the
>>>>>>>>> ugarchforecast method, this means using only estimates of the
>>>>>>>>> parameters
>>>>>>>>> from length(data)-out.sample. There is no re-estimation taking
>>>>>>>>> place
>>>>>>>>> (this
>>>>>>>>> is only done in the ugarchroll method).
>>>>>>>>> For n.ahead>1, this becomes an unconditional forecast.
>>>>>>>>> Equivalently,
>>>>>>>>> you
>>>>>>>>> can
>>>>>>>>> append new data to your old dataset and use the ugarchfilter
>>>>>>>>> method.
>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> My third question(s) is (are): How to calculate the VaR in case of
>>>>>>>>>> a
>>>>>>>>>> standardized
>>>>>>>>>> hyperbolic distribution? Can I still calculate it like in the
>>>>>>>>>> normal
>>>>>>>>>> case
>>>>>>>>>> or does it not work anymore (I am not sure, if the sdhyp belongs
>>>>>>>>>> to
>>>>>>>>>> the
>>>>>>>>>> location-scale family).
>>>>>>>>>>
>>>>>>>>>> Even if it does work (so if the sdhyp belongs to the family of
>>>>>>>>>> location-scale distributions) how do I calculate it in case of a
>>>>>>>>>> distribution, which does not belong to the location-scale family?
>>>>>>>>>> (I mean, if I cannot calculate it via VaR = uncmean + sigma*
>>>>>>>>>> z_alpha
>>>>>>>>>> how
>>>>>>>>>> do I have to calculate it). Which distribution implemented in the
>>>>>>>>>> rugarch
>>>>>>>>>> package does not belong to the location-scale family?
>>>>>>>>>>
>>>>>>>>> ALL distributions in the rugarch package are represented in a
>>>>>>>>> location-
>>>>>>>>> and
>>>>>>>>> scale- invariant parameterization since this is a key property
>>>>>>>>> required
>>>>>>>>> in
>>>>>>>>> working with the standardized residuals in the density function
>>>>>>>>> (i.e.
>>>>>>>>> the
>>>>>>>>> subtraction of the mean and scaling by the volatility).
>>>>>>>>> The standardized Generalized Hyperbolic distribution does indeed
>>>>>>>>> have
>>>>>>>>> this
>>>>>>>>> property, and details are available in the vignette. See also paper
>>>>>>>>> by
>>>>>>>>> Blaesild (http://biomet.oxfordjournals.org/content/68/1/251.short)
>>>>>>>>> for
>>>>>>>>> the
>>>>>>>>> linear transformation (aX+b) property.
>>>>>>>>>
>>>>>>>>> If working with the standard (NOT standardized) version of the GH
>>>>>>>>> distribution (\lambda, \alpha, \beta, \delta, \mu) you need to
>>>>>>>>> apply
>>>>>>>>> the
>>>>>>>>> location/scaling transformation as the example below shows which is
>>>>>>>>> equivalent to just using the location/scaling transformation in the
>>>>>>>>> standardized version:
>>>>>>>>> #################################################
>>>>>>>>> library(rugarch)
>>>>>>>>> # zeta = shape
>>>>>>>>> zeta = 0.4
>>>>>>>>> # rho = skew
>>>>>>>>> rho = 0.9
>>>>>>>>> # lambda = GIG mixing distribution shape parameter
>>>>>>>>> lambda=-1
>>>>>>>>> # POSITIVE scaling factor (sigma is in any always positive)
>>>>>>>>> # mean
>>>>>>>>> scaling = 0.02
>>>>>>>>> # sigma
>>>>>>>>> location = 0.001
>>>>>>>>>
>>>>>>>>> # standardized transformation based on (0,1,\rho,\zeta)
>>>>>>>>> # parameterization:
>>>>>>>>> x1 = scaling*qdist("ghyp", seq(0.001, 0.5, length.out=100), shape =
>>>>>>>>> zeta,
>>>>>>>>> skew = rho, lambda = lambda)+location
>>>>>>>>> # Equivalent to standard transformation:
>>>>>>>>> # First obtain the standard parameters (which have a mean of zero
>>>>>>>>> # and sigma of 1).
>>>>>>>>> parms = rugarch:::.paramGH(zeta, rho, lambda)
>>>>>>>>> x2 = rugarch:::.qgh( seq(0.001, 0.5, length.out=100), alpha =
>>>>>>>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling),
>>>>>>>>> delta=abs(scaling)*parms[3], mu = (scaling)*parms[4]+location,
>>>>>>>>> lambda
>>>>>>>>> =
>>>>>>>>> lambda)
>>>>>>>>> all.equal(x1, x2)
>>>>>>>>> # Notice the approximation error in the calculation of the quantile
>>>>>>>>> for #
>>>>>>>>> which there is no closed form solution (and rugarch uses a
>>>>>>>>> tolerance
>>>>>>>>> # value of .Machine$double.eps^0.25)
>>>>>>>>> # Load the GeneralizedHyperbolic package of Scott to adjust the
>>>>>>>>> # tolerance:
>>>>>>>>> library(GeneralizedHyperbolic)
>>>>>>>>>
>>>>>>>>> x1 = location+scaling*qghyp(seq(0.001, 0.5, length.out=100), mu =
>>>>>>>>> parms[4],
>>>>>>>>> delta = parms[3], alpha =  parms[1], beta = parms[2], lambda =
>>>>>>>>> lambda,
>>>>>>>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol
>>>>>>>>> =
>>>>>>>>> 501,
>>>>>>>>> subdivisions = 500, uniTol = 2e-12)
>>>>>>>>> # equivalent to:
>>>>>>>>> x2 = qghyp(seq(0.001, 0.5, length.out=100), mu =
>>>>>>>>> (scaling)*parms[4]+location, delta = abs(scaling)*parms[3], alpha =
>>>>>>>>> parms[1]/abs(scaling), beta = parms[2]/abs(scaling), lambda =
>>>>>>>>> lambda,
>>>>>>>>> lower.tail = TRUE, method = c("spline", "integrate")[2], nInterpol
>>>>>>>>> =
>>>>>>>>> 501,
>>>>>>>>> subdivisions = 500, uniTol = 2e-12)
>>>>>>>>>
>>>>>>>>> all.equal(x1, x2)
>>>>>>>>> #################################################
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> Thanks a lot for your help!
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Regards,
>>>>>>>>>
>>>>>>>>> Alexios
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> _______________________________________________
>>>>>>>>>> R-SIG-Finance at r-project.org mailing list
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>>>>>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>>>>>>>> -- Also note that this is not the r-help list where general R
>>>>>>>>>> questions
>>>>>>>>>> should go.
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>
>>>
>>
>



--
Neumann, Conrad


From weihanliu2002 at yahoo.com  Thu May  9 11:18:28 2013
From: weihanliu2002 at yahoo.com (Wei-han Liu)
Date: Thu, 9 May 2013 02:18:28 -0700 (PDT)
Subject: [R-SIG-Finance] PLM package - pggls
Message-ID: <1368091108.68297.YahooMailNeo@web163804.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130509/f89d469f/attachment.pl>

From dougedmunds at gmail.com  Thu May  9 23:00:09 2013
From: dougedmunds at gmail.com (dae)
Date: Thu, 9 May 2013 14:00:09 -0700 (PDT)
Subject: [R-SIG-Finance] convert ordered but non-unique csv to unique xts
Message-ID: <1368133209437-4666712.post@n4.nabble.com>

The csv file has ordered data but does not provide microseconds. 
There are entries with the same datetime  (to the seconds level) which
are in the proper sequential order.

I want to convert the file into an xts object with unique time values 
(by adding microseconds), if that can be done.
I am stuck for what steps to take, starting from the csv file.

Example data from csv file (note that four entries all have same datetime):

Time,High,Low,Open,Close,Vol
2013/05/08 08:02:04,6.35,6.345,6.35,6.345,172
2013/05/08 08:02:07,6.345,6.3425,6.345,6.3425,69
2013/05/08 08:02:07,6.3425,6.34,6.3425,6.34,74
2013/05/08 08:02:07,6.3425,6.34,6.34,6.3425,80
2013/05/08 08:02:07,6.345,6.3425,6.3425,6.345,87
2013/05/08 08:02:13,6.345,6.3425,6.345,6.3425,110

Goal; an xts object something like this 
(however the microseconds may appear):

                                          High,Low,Open,Close,Vol
2013-05-08 08:02:04.000,6.35,6.345,6.35,6.345,172
2013-05-08 08:02:07.001,6.345,6.3425,6.345,6.3425,69
2013-05-08 08:02:07.002,6.3425,6.34,6.3425,6.34,74
2013-05-08 08:02:07.003,6.3425,6.34,6.34,6.3425,80
2013-05-08 08:02:07.004,6.345,6.3425,6.3425,6.345,87
2013-05-08 08:02:13.000,6.345,6.3425,6.345,6.3425,110

Any help greatly appreciated. Thanks.



--
View this message in context: http://r.789695.n4.nabble.com/convert-ordered-but-non-unique-csv-to-unique-xts-tp4666712.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From josh.m.ulrich at gmail.com  Thu May  9 23:07:35 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 9 May 2013 16:07:35 -0500
Subject: [R-SIG-Finance] convert ordered but non-unique csv to unique xts
In-Reply-To: <1368133209437-4666712.post@n4.nabble.com>
References: <1368133209437-4666712.post@n4.nabble.com>
Message-ID: <CAPPM_gTXb7O5niAUjOg9vc1HALganj85BR4XwW+u0yQ+LFLosg@mail.gmail.com>

Use make.index.unique after you've created an xts object from the data
in the CSV.
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com

R/Finance 2013: Applied Finance with R  | www.RinFinance.com


On Thu, May 9, 2013 at 4:00 PM, dae <dougedmunds at gmail.com> wrote:
> The csv file has ordered data but does not provide microseconds.
> There are entries with the same datetime  (to the seconds level) which
> are in the proper sequential order.
>
> I want to convert the file into an xts object with unique time values
> (by adding microseconds), if that can be done.
> I am stuck for what steps to take, starting from the csv file.
>
> Example data from csv file (note that four entries all have same datetime):
>
> Time,High,Low,Open,Close,Vol
> 2013/05/08 08:02:04,6.35,6.345,6.35,6.345,172
> 2013/05/08 08:02:07,6.345,6.3425,6.345,6.3425,69
> 2013/05/08 08:02:07,6.3425,6.34,6.3425,6.34,74
> 2013/05/08 08:02:07,6.3425,6.34,6.34,6.3425,80
> 2013/05/08 08:02:07,6.345,6.3425,6.3425,6.345,87
> 2013/05/08 08:02:13,6.345,6.3425,6.345,6.3425,110
>
> Goal; an xts object something like this
> (however the microseconds may appear):
>
>                                           High,Low,Open,Close,Vol
> 2013-05-08 08:02:04.000,6.35,6.345,6.35,6.345,172
> 2013-05-08 08:02:07.001,6.345,6.3425,6.345,6.3425,69
> 2013-05-08 08:02:07.002,6.3425,6.34,6.3425,6.34,74
> 2013-05-08 08:02:07.003,6.3425,6.34,6.34,6.3425,80
> 2013-05-08 08:02:07.004,6.345,6.3425,6.3425,6.345,87
> 2013-05-08 08:02:13.000,6.345,6.3425,6.345,6.3425,110
>
> Any help greatly appreciated. Thanks.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/convert-ordered-but-non-unique-csv-to-unique-xts-tp4666712.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From dougedmunds at gmail.com  Fri May 10 06:48:18 2013
From: dougedmunds at gmail.com (dae)
Date: Thu, 9 May 2013 21:48:18 -0700 (PDT)
Subject: [R-SIG-Finance] convert ordered but non-unique csv to unique xts
In-Reply-To: <CAPPM_gTXb7O5niAUjOg9vc1HALganj85BR4XwW+u0yQ+LFLosg@mail.gmail.com>
References: <1368133209437-4666712.post@n4.nabble.com>
	<CAPPM_gTXb7O5niAUjOg9vc1HALganj85BR4XwW+u0yQ+LFLosg@mail.gmail.com>
Message-ID: <1368161298103-4666735.post@n4.nabble.com>

I placed the example code in a file named "zc.csv"

 Time,High,Low,Open,Close,Vol 
 2013/05/08 08:02:04,6.35,6.345,6.35,6.345,172 
 2013/05/08 08:02:07,6.345,6.3425,6.345,6.3425,69 
 2013/05/08 08:02:07,6.3425,6.34,6.3425,6.34,74 
 2013/05/08 08:02:07,6.3425,6.34,6.34,6.3425,80 
 2013/05/08 08:02:07,6.345,6.3425,6.3425,6.345,87 
 2013/05/08 08:02:13,6.345,6.3425,6.345,6.3425,110 

I  ran these steps to convert to xts and make the index unique:
-------
library("quantmod")
ds = options(digits.secs=6)
x = "zc.csv"
zc.xts =  as.xts(read.zoo(x, header = T, sep = ",", format = "%Y/%m/%d
%H:%M:%S", tz=""))
# that code works, but generates a warning:
#Warning message:
#  In zoo(rval3, ix) :
#  some methods for ?zoo? objects do not work if the index entries in
?order.by? are not unique

zc2.xts = make.index.unique (zc.xts)
isOrdered( .index(zc2.xts) )  #evaluates to TRUE
zc2.xts

---------------
This is how zc2.xts appears: 

                                                      High    Low     Open  
Close   Vol
2013-05-08 08:02:04.000000 6.3500 6.3450 6.3500 6.3450 172
2013-05-08 08:02:07.000000 6.3450 6.3425 6.3450 6.3425  69
2013-05-08 08:02:07.000000 6.3425 6.3400 6.3425 6.3400  74
2013-05-08 08:02:07.000001 6.3425 6.3400 6.3400 6.3425  80
2013-05-08 08:02:07.000002 6.3450 6.3425 6.3425 6.3450  87
2013-05-08 08:02:13.000000 6.3450 6.3425 6.3450 6.3425 110

Look at the index of the second and third records.  
Although apparently the indexes are unique, the indexes look the same.
Is there some way to make them look different?


I am running this code on a 32 bit WinXP SP3 box.
I am looking at it through RStudio 0.97.449




--
View this message in context: http://r.789695.n4.nabble.com/convert-ordered-but-non-unique-csv-to-unique-xts-tp4666712p4666735.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From jeff.a.ryan at gmail.com  Fri May 10 07:22:11 2013
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 10 May 2013 00:22:11 -0500
Subject: [R-SIG-Finance] convert ordered but non-unique csv to unique xts
In-Reply-To: <1368161298103-4666735.post@n4.nabble.com>
References: <1368133209437-4666712.post@n4.nabble.com>
	<CAPPM_gTXb7O5niAUjOg9vc1HALganj85BR4XwW+u0yQ+LFLosg@mail.gmail.com>
	<1368161298103-4666735.post@n4.nabble.com>
Message-ID: <CABDUZc8Rn+MjU_2wBNBcBUtFQwm8BfUWQ2K9Jv1A1yrChudPqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130510/12f29df0/attachment.pl>

From markknecht at gmail.com  Fri May 10 23:47:56 2013
From: markknecht at gmail.com (Mark Knecht)
Date: Fri, 10 May 2013 14:47:56 -0700
Subject: [R-SIG-Finance] Do the blotter demos work?
Message-ID: <CAK2H+edB11jpTVG7xNPsJ6cYX3DB5pPGx5OJ4kU2hKvbYwAM=w@mail.gmail.com>

Hi,
   I'm struggling to get any of the demos in the blotter package to
work. Using a command such as:

demo(longtrend, package="blotter")

it runs along for a second and then fails with this message:

+     # Calculate P&L and resulting equity with blotter
+     updatePortf(ltportfolio, Dates = CurrentDate)
+     updateAcct(ltaccount, Dates = CurrentDate)
+     updateEndEq(ltaccount, Dates = CurrentDate)
+ } # End dates loop
.
[1] "1998-10-30 00:00:00 GSPC 91 @ 1098.67"
Error in lag.xts(TmpPeriods$Pos.Value, 1) :
  abs(k) must be less than nrow(x)
In addition: Warning messages:
1: In rm("account.longtrend", "portfolio.longtrend", pos = .blotter) :
  object 'account.longtrend' not found
2: In rm("account.longtrend", "portfolio.longtrend", pos = .blotter) :
  object 'portfolio.longtrend' not found
3: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate", "equity",  :
  object 'ltaccount' not found
4: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate", "equity",  :
  object 'ltportfolio' not found
5: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate", "equity",  :
  object 'GSPC' not found
6: In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
  downloaded length 236151 != reported length 200

   I suspect I'm just not running it correctly but don't know what I'm
doing wrong.

   I've generally had trouble with all demos having to do with
blotter. Are they still working or are they no longer maintained?

   The quantstrat demos, at least the couple I've tried, do seem to work.

   This is R-2.15.3 running in RStudio=0.97.336/

Thanks,
Mark


From josh.m.ulrich at gmail.com  Sat May 11 14:04:50 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 11 May 2013 07:04:50 -0500
Subject: [R-SIG-Finance] Do the blotter demos work?
In-Reply-To: <CAK2H+edB11jpTVG7xNPsJ6cYX3DB5pPGx5OJ4kU2hKvbYwAM=w@mail.gmail.com>
References: <CAK2H+edB11jpTVG7xNPsJ6cYX3DB5pPGx5OJ4kU2hKvbYwAM=w@mail.gmail.com>
Message-ID: <CAPPM_gSGPws-ivyAW0s=W6NG3j8HhmbGyD5RmXnKK7s=D=KUfg@mail.gmail.com>

The "longtrend" and "turtles" demos appear to be broken by recent
changes to xts and quantmod (regarding timezone issues with
Date-classed indexes).  I don't have time to work on a fix at the
moment, but wanted to answer in case others might investigate and work
on a patch.

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com

R/Finance 2013: Applied Finance with R  | www.RinFinance.com


On Fri, May 10, 2013 at 4:47 PM, Mark Knecht <markknecht at gmail.com> wrote:
> Hi,
>    I'm struggling to get any of the demos in the blotter package to
> work. Using a command such as:
>
> demo(longtrend, package="blotter")
>
> it runs along for a second and then fails with this message:
>
> +     # Calculate P&L and resulting equity with blotter
> +     updatePortf(ltportfolio, Dates = CurrentDate)
> +     updateAcct(ltaccount, Dates = CurrentDate)
> +     updateEndEq(ltaccount, Dates = CurrentDate)
> + } # End dates loop
> .
> [1] "1998-10-30 00:00:00 GSPC 91 @ 1098.67"
> Error in lag.xts(TmpPeriods$Pos.Value, 1) :
>   abs(k) must be less than nrow(x)
> In addition: Warning messages:
> 1: In rm("account.longtrend", "portfolio.longtrend", pos = .blotter) :
>   object 'account.longtrend' not found
> 2: In rm("account.longtrend", "portfolio.longtrend", pos = .blotter) :
>   object 'portfolio.longtrend' not found
> 3: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate", "equity",  :
>   object 'ltaccount' not found
> 4: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate", "equity",  :
>   object 'ltportfolio' not found
> 5: In rm("ltaccount", "ltportfolio", "ClosePrice", "CurrentDate", "equity",  :
>   object 'GSPC' not found
> 6: In download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
>   downloaded length 236151 != reported length 200
>
>    I suspect I'm just not running it correctly but don't know what I'm
> doing wrong.
>
>    I've generally had trouble with all demos having to do with
> blotter. Are they still working or are they no longer maintained?
>
>    The quantstrat demos, at least the couple I've tried, do seem to work.
>
>    This is R-2.15.3 running in RStudio=0.97.336/
>
> Thanks,
> Mark
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From alexandra.rautoiu at yahoo.com  Mon May 13 00:20:34 2013
From: alexandra.rautoiu at yahoo.com (Alexandra Allexa)
Date: Sun, 12 May 2013 15:20:34 -0700 (PDT)
Subject: [R-SIG-Finance] CVaR with NIG- GARCH(1,1)
Message-ID: <1368397234.30486.YahooMailNeo@web122406.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130512/9d699eae/attachment.pl>

From brian at braverock.com  Mon May 13 00:43:23 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 12 May 2013 17:43:23 -0500
Subject: [R-SIG-Finance] CVaR with NIG- GARCH(1,1)
In-Reply-To: <1368397234.30486.YahooMailNeo@web122406.mail.ne1.yahoo.com>
References: <1368397234.30486.YahooMailNeo@web122406.mail.ne1.yahoo.com>
Message-ID: <51901B0B.5010200@braverock.com>

On 05/12/2013 05:20 PM, Alexandra Allexa wrote:
> My problem is how to define the NIG distribution for such a model?
> How I set the parameters/ vectors: y,p,q and n?
>
> In this situation, it is possible to use the function CVaR or ETL
> provided by the package {PerformanceAnalytics}? How?
>
> I can applied the same principle used in computing CVaR for
> CDD/CDaR?
>
> Thank you in advance,
>
> Alexandra Rautoiu

CVaR/ETL in PerformanceAnalytics don't have NIG distribution options.

I'm not sure if the NIG distribution has p,d,q,r functions as is common 
in R for discrete distributions.

If you have the q(uantile) function, you should be able to adapt the 
code from PerformanceAnalytics with relative ease, since it is only 
required to know the quantile, and then integrate over the tail, to 
compute the CVaR for a continuous distribution.

Regards,

Brian


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From alexios at 4dscape.com  Mon May 13 00:46:01 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sun, 12 May 2013 23:46:01 +0100
Subject: [R-SIG-Finance] CVaR with NIG- GARCH(1,1)
In-Reply-To: <1368397234.30486.YahooMailNeo@web122406.mail.ne1.yahoo.com>
References: <1368397234.30486.YahooMailNeo@web122406.mail.ne1.yahoo.com>
Message-ID: <51901BA9.2000005@4dscape.com>

Hi Alexandra,

The conditional Expected Shortfall for the NIG (or any other 
standardized rugarch distribution) using the rolling estimation/forecast 
method is given below.

# using your example:
mu=fitlist1[, 'Mu']
sigma=fitlist1[, 'Sigma']
shape=fitlist1[, 'Shape']
skew=fitlist1[, 'Skew']

# for the 5% quantile (adjust 0.05 as appropriate)
f = function(x, mu, sigma, skew, shape) mu + qdist("nig", p=x, mu=0, 
sigma=1, skew=skew, shape=shape)*sigma
for(i in 1:N)
{
ES[i] = integrate(f, 0, 0.05, mu = mu[i], sigma=sigma[i], shape = 
shape[i], skew=skew[i])$value/0.05
}
# Also see the ESTest.

You do not need to load ALL those packages (you only need rugarch for 
this example).

Regards,

Alexios

PS
# its "nig" NOT "snig" (you are confusing the name with that used in
# the fGarch package)...and yes, it is the same standardized
# distribution.
distplot(distribution = "nig", skewbounds = NULL, shapebounds = NULL,
          n.points = NULL)


On 12/05/2013 23:20, Alexandra Allexa wrote:
>
>
> Hello,
>
> My name is Alexandra and I have a very tight deadline for my MSc dissertation. My intention is to do a CVaR/ES using a NIG_GARCH model for estimating the volatility.
>
> With the Alexios's help I did a part of the following code (Thank you very much for your help, Alexios Ghalanos!):
>
> library(timeSeries)
> library(timeDate)
> library(Rcpp)
> library(RcppArmadillo)
> library(parallel)
> library(chron)
> library(Rsolnp)
> library(truncnorm)
> library(rugarch)
> library(fGarch)
> library(timeDate)
> library(PerformanceAnalytics)
> library(AER)
> library(fGarch)
>
> eur_all=timeSeries(eur_2001)
> r_eur1=getReturns(eur_all)
> rand_eur1=r_eur1*100
>
> #-NIG_GARCH
>
> #I. Specification Model and Fitting
>
> spec1 = ugarchspec(variance.model = list(model = 'sGARCH',
>                                           garchOrder = c(1,1)), mean.model =
>                       list(armaOrder = c(1,1), include.mean = TRUE),
>                     distribution.model = "nig")
>
>
>
> #Fit the model
>
>
> tmp = ugarchroll(spec1, rand_eur1, forecast.length = 1500, refit.every = 50,
>                   refit.window = 'moving', windows.size = 1500, solver ='hybrid',
>                   calculate.VaR = TRUE,VaR.alpha = c(0.01, 0.025, 0.05), keep.coef = TRUE)
>
> if (!is.null(tmp at model$noncidx)) {
>
>    tmp = resume(tmp, solver = "solnp", fit.control = list(scale = 1), solver.control = list(tol = 1e-07,
>                                                                                             delta = 1e-06))
>
>    if (!is.null(tmp at model$noncidx))
>
>      fitlist1 = NA
> } else {
>
>    fitlist1 = as.data.frame(tmp, which = 'density')
>
>
> }
>
>
> # Defining NIG distribution
>
> mu=fitlist1[, 'Mu']
> sigma=fitlist1[, 'Sigma']
> shape=fitlist1[, 'Shape']
> skew=fitlist1[, 'Skew']
> lambda =fitlist1[, 'Shape.GIG']
>
> dist=ddist(distribution = "nig", y, mu = mu, sigma = sigma, lambda = lambda, skew = skew,
>             shape = shape)
> pd=pdist(distribution = "nig", q, mu = mu, sigma = sigma, lambda = lambda, skew = skew,
>           shape = shape)
> qst=qdist(distribution = "nig", p, mu = mu, sigma = sigma, lambda = lambda, skew = skew,
>            shape = shape)
> r=rdist(distribution = "nig", n, mu = mu, sigma = sigma, lambda = lambda, skew = skew,
>          shape = shape)
> fitdist(distribution = "nig", fitlist1, control=list())
>
> distplot(distribution = "snig", skewbounds = NULL, shapebounds = NULL,
>           n.points = NULL)
>
> #CVaR/ES
>
> EURLOSS <- timeSeries(-1.0*rand_eur1,
>                        char.vec = time(eur_all))
>
> ESgarch <- function(rand_eur1, p = 0.99){
>    sigma <-fitlist1[, 'Sigma']
>    df <- fitlist1[,"Shape"]
>    ES <- sigma * (dist(qst(p, df), df)/(1 - p)) *
>      ((df + (qst(p, df))^2)/(df - 1))
>    return(ES)
> }
>
>
> from <- time(EURLOSS)[-c((nrow(EURLOSS) - 999) : nrow(EURLOSS))]
> to <- time(EURLOSS)[-c(1:1000)]
> EURSEES <- fapply(EURLOSS, from = from, to = to, FUN = ESgarch)
> EURSEESL1 <- lag(EURSEES, k = 1)
> res <- na.omit(cbind(EURSELOSS, EURSEESL1))
> colnames(res) <- c("EURSELOSS", "ES99")
> plot(res[, 2], col = "red", ylim = range(res),
>       main = "EUR: NIG-GARCH(1,1) ES 99%",
>       ylab = "percentages", xlab = "")
> points(res[, 1], type = "p", cex = 0.2, pch = 19, col = "blue")
> legend("topleft", legend = c("Loss", "ES"),
>         col = c("blue", "pink"), lty = c(NA, 1), pch = c(19, NA))
>
>
>
> My problem is how to define the NIG distribution for such a model?
> How I set the parameters/ vectors: y,p,q and n?
>
> In this situation, it is possible to use the function CVaR or ETL provided by the package {PerformanceAnalytics}? How?
>
> I can applied the same principle used in computing CVaR for CDD/CDaR?
>
> Thank you in advance,
>
> Alexandra Rautoiu
> 	[[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From alexios at 4dscape.com  Mon May 13 00:49:44 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sun, 12 May 2013 23:49:44 +0100
Subject: [R-SIG-Finance] CVaR with NIG- GARCH(1,1)
In-Reply-To: <51901B0B.5010200@braverock.com>
References: <1368397234.30486.YahooMailNeo@web122406.mail.ne1.yahoo.com>
	<51901B0B.5010200@braverock.com>
Message-ID: <51901C88.8050600@4dscape.com>

Hi Brian,

All distributions in rugarch have p*,d*,q*,r* functions, but I have 
unified the functions into the following functions:

pdist, ddist, qdist, rdist

They simply take as first argument the distribution (e.g. "nig", 
"std","sstd", "norm", "snorm", "ghyp", "ged","sged","ghst"), and then 
the standard inputs where mu is the mean, and sigma the standard 
deviation (since the distributions in rugarch are standardized this way).

Best,

Alexios

On 12/05/2013 23:43, Brian G. Peterson wrote:
> On 05/12/2013 05:20 PM, Alexandra Allexa wrote:
>> My problem is how to define the NIG distribution for such a model?
>> How I set the parameters/ vectors: y,p,q and n?
>>
>> In this situation, it is possible to use the function CVaR or ETL
>> provided by the package {PerformanceAnalytics}? How?
>>
>> I can applied the same principle used in computing CVaR for
>> CDD/CDaR?
>>
>> Thank you in advance,
>>
>> Alexandra Rautoiu
>
> CVaR/ETL in PerformanceAnalytics don't have NIG distribution options.
>
> I'm not sure if the NIG distribution has p,d,q,r functions as is common
> in R for discrete distributions.
>
> If you have the q(uantile) function, you should be able to adapt the
> code from PerformanceAnalytics with relative ease, since it is only
> required to know the quantile, and then integrate over the tail, to
> compute the CVaR for a continuous distribution.
>
> Regards,
>
> Brian
>
>


From alexandra.rautoiu at yahoo.com  Mon May 13 20:10:29 2013
From: alexandra.rautoiu at yahoo.com (Alexandra Allexa)
Date: Mon, 13 May 2013 11:10:29 -0700 (PDT)
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 108, Issue 12
In-Reply-To: <mailman.3.1368439201.30547.r-sig-finance@r-project.org>
References: <mailman.3.1368439201.30547.r-sig-finance@r-project.org>
Message-ID: <1368468629.47583.YahooMailNeo@web122403.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130513/17d01798/attachment.pl>

From wuertz at phys.ethz.ch  Tue May 14 08:50:59 2013
From: wuertz at phys.ethz.ch (Diethelm Wuertz)
Date: Tue, 14 May 2013 08:50:59 +0200
Subject: [R-SIG-Finance] 7th R/Rmetrics Meielisalp Workshop and Summer
	School 2013
Message-ID: <986DA9FC-43F1-41EA-99E6-887A69871005@phys.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130514/deb9d6f5/attachment.pl>

From samir.purple at gmail.com  Tue May 14 18:46:45 2013
From: samir.purple at gmail.com (samshky)
Date: Tue, 14 May 2013 09:46:45 -0700 (PDT)
Subject: [R-SIG-Finance] Portfolio Optimization Combination problem
Message-ID: <1368550005944-4667054.post@n4.nabble.com>

I load the following library
library("fPortfolio")

then i use the avaialable data of the library fportfolio

data = SPISECTOR.RET
names(data)
 [1] "SPI"  "BASI" "INDU" "CONG" "HLTH" "CONS" "TELE" "UTIL" "FINA" "TECH"

SPISECTOR.RET consists the retunrs of above 10 sectors.

When investors wants to invest in these 10 sector using following code i
find the tangency and minimum variance portfolio with  
tangencyPortfolio(data, spec = portfolioSpec(), constraints = "LongOnly")
minvariancePortfolio(data, spec = portfolioSpec(), constraints = "LongOnly")

But, Say an investor wants to know the Global Minimum Variance Portfolio and
tangencyPortfolio among the various portfoilo consist of these 10 sectors.
THis is my question and what can be the code for such problem?

My rough ideam be:
We may need a dataframe or matrix say "MATALL" which consist the the various
combinations portfolios of these sectors like
portfolio1 = SPI
portfolio2 = BASI
.......
.......
portfolio9 = TECH
portfolio10 = c(SPI, BASI)
portfolio11 = c(SPI, INDU)
portfolio12 = c(SPI, CONG)
.......
.......
Portfolio511 = c(SPI,  BASI, INDU, CONG, HLTH, CONS, TELE, UTIL, FINA, TECH)

Then we need another matrix or dataframe say "MAT" which exclude portfolio1
to portfolio9 because of the portfolio optimization problem ie  
MAT consist from portfolio10 to portfolio 511.

Now we need  mean     mu    Cov  Sigma   CVaR    VaR of tangencyPortfolio of
each of the portfolios in MAT and export it to Excel file
Similarly 
we need  mean     mu    Cov  Sigma   CVaR    VaR of minvariancePortfolio of
each of the portfolio in MAT and export it to Excel file


Thanks Samir




--
View this message in context: http://r.789695.n4.nabble.com/Portfolio-Optimization-Combination-problem-tp4667054.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From alexandra.rautoiu at yahoo.com  Tue May 14 18:53:55 2013
From: alexandra.rautoiu at yahoo.com (Alexandra Allexa)
Date: Tue, 14 May 2013 09:53:55 -0700 (PDT)
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 108, Issue 12
In-Reply-To: <mailman.3.1368439201.30547.r-sig-finance@r-project.org>
References: <mailman.3.1368439201.30547.r-sig-finance@r-project.org>
Message-ID: <1368550435.84950.YahooMailNeo@web122405.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130514/22c8712c/attachment.pl>

From alexios at 4dscape.com  Tue May 14 19:35:01 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Tue, 14 May 2013 18:35:01 +0100
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 108, Issue 12
In-Reply-To: <1368550435.84950.YahooMailNeo@web122405.mail.ne1.yahoo.com>
References: <mailman.3.1368439201.30547.r-sig-finance@r-project.org>
	<1368550435.84950.YahooMailNeo@web122405.mail.ne1.yahoo.com>
Message-ID: <519275C5.2030701@4dscape.com>

1. You may have encountered an error in the intergation (you should use 
"try-catch", and option stop.on.error in integrate set to FALSE..after 
which you would check for any NA's etc)...but send the code so that we 
may see. Did you set the length (N) of "ES" to the same length as your 
conditional forecasts?

2. NO. ONE SIDED test. When uncertain about something, either read up on 
the original reference or try for yourself:

e.g.
t.test(rnorm(1000, mean=0.1, sd=0.02), alternative="greater")
t.test(rnorm(1000), alternative="greater")


Regards,
-Alexios

On 14/05/2013 17:53, Alexandra Allexa wrote:
> Hi again,
>
>
>
> I run the code wrote by Alexios and I have this error messege:
> 'Error in integrate(f, 0, 0.05, mu = mu[i], sigma = sigma[i], shape = shape[i],  :
>    evaluation of function gave a result of wrong length"
>
> I tried to figure out but I didn't find any solution. May you help me with this?
>
> Also, I tried the ESTest for 2 different series. One series proposed in the vignette of the test and my series and I got 2 antagonist results.
>
> For dji30ret i have the following output:
> $expected.exceed
> [1] 75
>
> $actual.exceed
> [1] 74
>
> $H1
> [1] "Mean of Excess Violations of VaR is greater than zero"
>
> $boot.p.value
> [1] 0.9663557
>
> $p.value
> [1] 0.9655261
>
> $Decision
> [1] "Fail to Reject H0"
>
>
> For my series I have:
> $expected.exceed
> [1] 80
>
> $actual.exceed
> [1] 87
>
> $H1
> [1] "Mean of Excess Violations of VaR is greater than zero"
>
> $boot.p.value
> [1] 0.06042038
>
> $p.value
> [1] 0.05122453
>
> $Decision
> [1] "Fail to Reject H0"
>
> What seems to me bizarre is the fact that for my series the $p.value and $boot.p.value are under 10% and for dji30ret I have this propabilites are approx. 95% and for the both cases I got the same Decision.
>
> In the vignette is mentioned that ESTet is  sided t-test, since I remember (I'm not sure) for this types of tests, Ho is accepted for a p value lower or equal to the  threshold of 1%/5%/10%. Why I have this extrange results?
>
> Thank you!
>
> Alexandra
>
>
>
>
>
>
> From: "r-sig-finance-request at r-project.org" <r-sig-finance-request at r-project.org>
> To: r-sig-finance at r-project.org
> Sent: Monday, May 13, 2013 1:00 PM
> Subject: R-SIG-Finance Digest, Vol 108, Issue 12
>
>
> Send R-SIG-Finance mailing list submissions to
>      r-sig-finance at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>      https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> or, via email, send a message with subject or body 'help' to
>      r-sig-finance-request at r-project.org
>
> You can reach the person managing the list at
>      r-sig-finance-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-SIG-Finance digest..."
>
>
> Today's Topics:
>
>     1. CVaR with NIG- GARCH(1,1) (Alexandra Allexa)
>     2. Re: CVaR with NIG- GARCH(1,1) (Brian G. Peterson)
>     3. Re: CVaR with NIG- GARCH(1,1) (alexios ghalanos)
>     4. Re: CVaR with NIG- GARCH(1,1) (alexios ghalanos)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sun, 12 May 2013 15:20:34 -0700 (PDT)
>
> To: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
> Subject: [R-SIG-Finance] CVaR with NIG- GARCH(1,1)
> Message-ID:
>      <1368397234.30486.YahooMailNeo at web122406.mail.ne1.yahoo.com>
> Content-Type: text/plain
>
>
>
> Hello,
>
> My name is Alexandra and I have a very tight deadline for my MSc dissertation. My intention is to do a CVaR/ES using a NIG_GARCH model for estimating the volatility.
>
> With the Alexios's help I did a part of the following code (Thank you very much for your help, Alexios Ghalanos!):
>
> library(timeSeries)
> library(timeDate)
> library(Rcpp)
> library(RcppArmadillo)
> library(parallel)
> library(chron)
> library(Rsolnp)
> library(truncnorm)
> library(rugarch)
> library(fGarch)
> library(timeDate)
> library(PerformanceAnalytics)
> library(AER)
> library(fGarch)
>
> eur_all=timeSeries(eur_2001)
> r_eur1=getReturns(eur_all)
> rand_eur1=r_eur1*100
>
> #-NIG_GARCH
>
> #I. Specification Model and Fitting
>
> spec1 = ugarchspec(variance.model = list(model = 'sGARCH',
>                                           garchOrder = c(1,1)), mean.model =
>                       list(armaOrder = c(1,1), include.mean = TRUE),
>                     distribution.model = "nig")
>
>
>
> #Fit the model
>
>
> tmp = ugarchroll(spec1, rand_eur1, forecast.length = 1500, refit.every = 50,
>                   refit.window = 'moving', windows.size = 1500, solver ='hybrid',
>                   calculate.VaR = TRUE,VaR.alpha = c(0.01, 0.025, 0.05), keep.coef = TRUE)
>
> if (!is.null(tmp at model$noncidx)) {
>
>    tmp = resume(tmp, solver = "solnp", fit.control = list(scale = 1), solver.control = list(tol = 1e-07,
>                                                                                             delta = 1e-06))
>
>    if (!is.null(tmp at model$noncidx))
>
>      fitlist1 = NA
> } else {
>
>    fitlist1 = as.data.frame(tmp, which = 'density')
>
>
> }
>
>
> # Defining NIG distribution
>
> mu=fitlist1[, 'Mu']
> sigma=fitlist1[, 'Sigma']
> shape=fitlist1[, 'Shape']
> skew=fitlist1[, 'Skew']
> lambda =fitlist1[, 'Shape.GIG']
>
> dist=ddist(distribution = "nig", y, mu = mu, sigma = sigma, lambda = lambda, skew = skew,
>             shape = shape)
> pd=pdist(distribution = "nig", q, mu = mu, sigma = sigma, lambda = lambda, skew = skew,
>           shape = shape)
> qst=qdist(distribution = "nig", p, mu = mu, sigma = sigma, lambda = lambda, skew = skew,
>            shape = shape)
> r=rdist(distribution = "nig", n, mu = mu, sigma = sigma, lambda = lambda, skew = skew,
>          shape = shape)
> fitdist(distribution = "nig", fitlist1, control=list())
>
> distplot(distribution = "snig", skewbounds = NULL, shapebounds = NULL,
>           n.points = NULL)
>
> #CVaR/ES
>
> EURLOSS <- timeSeries(-1.0*rand_eur1,
>                        char.vec = time(eur_all))
>
> ESgarch <- function(rand_eur1, p = 0.99){
>    sigma <-fitlist1[, 'Sigma']
>    df <- fitlist1[,"Shape"]
>    ES <- sigma * (dist(qst(p, df), df)/(1 - p)) *
>      ((df + (qst(p, df))^2)/(df - 1))
>    return(ES)
> }
>
>
> from <- time(EURLOSS)[-c((nrow(EURLOSS) - 999) : nrow(EURLOSS))]
> to <- time(EURLOSS)[-c(1:1000)]
> EURSEES <- fapply(EURLOSS, from = from, to = to, FUN = ESgarch)
> EURSEESL1 <- lag(EURSEES, k = 1)
> res <- na.omit(cbind(EURSELOSS, EURSEESL1))
> colnames(res) <- c("EURSELOSS", "ES99")
> plot(res[, 2], col = "red", ylim = range(res),
>       main = "EUR: NIG-GARCH(1,1) ES 99%",
>       ylab = "percentages", xlab = "")
> points(res[, 1], type = "p", cex = 0.2, pch = 19, col = "blue")
> legend("topleft", legend = c("Loss", "ES"),
>         col = c("blue", "pink"), lty = c(NA, 1), pch = c(19, NA))
>
>
>
> My problem is how to define the NIG distribution for such a model?
> How I set the parameters/ vectors: y,p,q and n?
>
> In this situation, it is possible to use the function CVaR or ETL provided by the package {PerformanceAnalytics}? How?
>
> I can applied the same principle used in computing CVaR for CDD/CDaR?
>
> Thank you in advance,
>
> Alexandra Rautoiu
>      [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sun, 12 May 2013 17:43:23 -0500
> From: "Brian G. Peterson" <brian at braverock.com>
> To: r-sig-finance at r-project.org
> Subject: Re: [R-SIG-Finance] CVaR with NIG- GARCH(1,1)
> Message-ID: <51901B0B.5010200 at braverock.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> On 05/12/2013 05:20 PM, Alexandra Allexa wrote:
>> My problem is how to define the NIG distribution for such a model?
>> How I set the parameters/ vectors: y,p,q and n?
>>
>> In this situation, it is possible to use the function CVaR or ETL
>> provided by the package {PerformanceAnalytics}? How?
>>
>> I can applied the same principle used in computing CVaR for
>> CDD/CDaR?
>>
>> Thank you in advance,
>>
>> Alexandra Rautoiu
>
> CVaR/ETL in PerformanceAnalytics don't have NIG distribution options.
>
> I'm not sure if the NIG distribution has p,d,q,r functions as is common
> in R for discrete distributions.
>
> If you have the q(uantile) function, you should be able to adapt the
> code from PerformanceAnalytics with relative ease, since it is only
> required to know the quantile, and then integrate over the tail, to
> compute the CVaR for a continuous distribution.
>
> Regards,
>
> Brian
>
>
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From alexios at 4dscape.com  Tue May 14 22:29:36 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Tue, 14 May 2013 21:29:36 +0100
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 108, Issue 12
In-Reply-To: <1368561303.61201.YahooMailNeo@web122401.mail.ne1.yahoo.com>
References: <mailman.3.1368439201.30547.r-sig-finance@r-project.org>
	<1368550435.84950.YahooMailNeo@web122405.mail.ne1.yahoo.com>
	<519275C5.2030701@4dscape.com>
	<1368561303.61201.YahooMailNeo@web122401.mail.ne1.yahoo.com>
Message-ID: <51929EB0.3050108@4dscape.com>

The reason you have an error is that you have not followed my instructions.

Your code:
##################
f = function(x, mu, sigma, skew, shape) mu + qdist("nig", p=0.05, mu=0, 
sigma=1, skew=skew, shape=shape)*sigma
##################
But I this is not what I sent you, and makes absolutely no sense (you 
want to integrate this quantile over the range 0-alpha).

Instead you should have used:
##################
f = function(x, mu, sigma, skew, shape) mu + qdist("nig", p=x, mu=0, 
sigma=1, skew=skew, shape=shape)*sigma
##################

Regards,
Alexios


On 14/05/2013 20:55, Alexandra Allexa wrote:
>
> Yes, I set N to the same length as my conditional forecasts.
>
> Here is the code and my data base is attached to the mail:
>


From henry.bee at gmail.com  Wed May 15 03:35:47 2013
From: henry.bee at gmail.com (Henry Bee)
Date: Tue, 14 May 2013 18:35:47 -0700
Subject: [R-SIG-Finance] getSymbols: unable to connect to 'chart.yahoo.com'
	on port 80
Message-ID: <CAJQFRkob=aTAS8YAjDx8G9MXTaXqrM4rYd0B=hS6iMn6+8tRbg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130514/84e1e863/attachment.pl>

From thomas.chan.sf at boci-pru.com.hk  Wed May 15 11:25:56 2013
From: thomas.chan.sf at boci-pru.com.hk (thomas.chan.sf at boci-pru.com.hk)
Date: Wed, 15 May 2013 17:25:56 +0800
Subject: [R-SIG-Finance] gbm.step run out of memory?
Message-ID: <OF31F636A1.D3C2BFE4-ON48257B6C.002D93C0-48257B6C.0033D01C@boci-pru.com.hk>


Hi

I used the gbm.step function to perform boosted regression tree analysis
using a PC, which has an Intel i5 CPU (650 @3.20 GHz 3.33 GHz) and 8 GB
RAM.

When I ran it on Rx64 2.15.0, it runs slow but fine. In fact, I can
simultaneously run almost identical scripts in 4 R programs at the same
time without causing any problem other than that it is slow. When I changed
it to Rx3.0.0, even with only one R scripts and nothing else running in the
PC, it soon got stuck and gave this message:

            Microsoft Visual C++ Runtime Library
            This application has required the Runtime to terminate it in an
unusual way. Please contact the application's support team for more
information.

I looked into it and suspect that in Rx64 2.15.0, the R script uses only
one core to run, whereas in Rx3.0.0 it uses all cores and soon runs out of
memory altogether. Could somebody please shed light on this? Is there
anyway to get around it? Thanks.

TC

---------------------------------------------------------------------------------------

Important : The information contained in this e-mail and any attachment thereof is intended only for use of the addressee and is confidential and may be privileged and/or otherwise protected from disclosure. If you are not the intended recipient, you are hereby notified that any use, copying, dissemination or any other action taken or omitted to be taken in reliance upon this information is strictly prohibited. If you have received this communication in error, please notify the sender immediately by reply and delete this message from your system. Any views expressed in this e-mail are those of the individual sender except where the e-mail states otherwise and the sender is authorized to state them to be the views of BOCI-Prudential Asset Management Limited. Unless otherwise stated, any information given in this e-mail shall not be regarded as an offer, solicitation, invitation, advice or recommendation to buy or sell any investment or securities within or outside Hong Kong SAR. Any reference to the terms of executed transactions should be treated as preliminary only and subject to our formal written confirmation.


______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com


From statquery at webmail.co.za  Wed May 15 12:30:50 2013
From: statquery at webmail.co.za (Private Private)
Date: Wed, 15 May 2013 12:30:50 +0200
Subject: [R-SIG-Finance] Question rugarch VaR plot
Message-ID: <04a06d91fbdc6db715a153b58fa49033@www.webmail.co.za>

Dear All/Alexios Ghalanos

I have a question concerning the plot method of the ugarchroll class in the
package rugarch:

1.) When I plot the VaR of a ugarchroll class, I would like to change the
x-axis values to the dates corresponding to the log returns I feed ugarchroll
- how would I do that? I have tried adding additional arguments like: xaxt="n"
 - but to no avail. Right now the x-axis has values from 1978????

2.) Much along the same lines, How would I be able to change the default title
of the plot? 

Using the title() function just pastes over the default title and trying to
use the 'main' property of plot does not work. 

My goal is to have the dates on the x-axis reflect the returns that are being
graphed and also to have a heading which states with GARCH model is being
used. 

I would like have a VaR plot for each GARCH model I fit (ie. iGarch, EGarch)
and would like the title of the graph to reflect that and perhaps the
distribution I chose (ie. normal, t, skewed t).


Thank you very much for any help you can provide and I am a very grateful user
of the rugarch package.





Code follows and an example of the plot is attached:

library(rugrch)
data(sp500ret)

spec<-ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1)),distribution.model = "norm")

roll<-ugarchroll(spec,data=data[,3],n.ahead = 1, 
	forecast.length = 100,refit.every=60,refit.window="moving",
	solver = "hybrid", calculate.VaR = TRUE, 
	VaR.alpha =0.01)

plot(roll,which=4,VaR.alpha=0.01)



____________________________________________________________
South Africas premier free email service - www.webmail.co.za 

For super low premiums, click here.
http://www.dialdirect.co.za/smart-can-get-a-parrot-hands-free-kit?vdn=15752


From alexios at 4dscape.com  Wed May 15 13:24:39 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 15 May 2013 12:24:39 +0100
Subject: [R-SIG-Finance] Question rugarch VaR plot
In-Reply-To: <04a06d91fbdc6db715a153b58fa49033@www.webmail.co.za>
References: <04a06d91fbdc6db715a153b58fa49033@www.webmail.co.za>
Message-ID: <51937077.6090509@4dscape.com>

Hi,

1. If you provide a proper xts based data object as an input, then you 
will get a nice chart.
2. If you provide instead a numeric or undated series, then this is 
coerced to xts and assigned an artificial date sequence using :
as.POSIXct(as.Date(seq_along(data), origin="1970-01-01"))
which is probably why you get 1978 in your x-axis.

If you want to customize a VaR plot, you can use/edit the VaRplot 
function which takes as inputs xts based objects. If you do not want to 
use xts, then you are left to code your own plot. rugarch 
documentation/examples provide enough details to show how to extract the 
forecast VaR from the rolling estimation object, and has been discussed 
on this forum numerous times in the past.

Finally, I urge you to follow mailing list etiquette and sign your 
emails with your real name rather than "Private Private". It is only 
polite given that you are asking for help on this forum.

Regards,

Alexios

On 15/05/2013 11:30, Private Private wrote:
> Dear All/Alexios Ghalanos
>
> I have a question concerning the plot method of the ugarchroll class in the
> package rugarch:
>
> 1.) When I plot the VaR of a ugarchroll class, I would like to change the
> x-axis values to the dates corresponding to the log returns I feed ugarchroll
> - how would I do that? I have tried adding additional arguments like: xaxt="n"
>   - but to no avail. Right now the x-axis has values from 1978????
>
> 2.) Much along the same lines, How would I be able to change the default title
> of the plot?
>
> Using the title() function just pastes over the default title and trying to
> use the 'main' property of plot does not work.
>
> My goal is to have the dates on the x-axis reflect the returns that are being
> graphed and also to have a heading which states with GARCH model is being
> used.
>
> I would like have a VaR plot for each GARCH model I fit (ie. iGarch, EGarch)
> and would like the title of the graph to reflect that and perhaps the
> distribution I chose (ie. normal, t, skewed t).
>
>
> Thank you very much for any help you can provide and I am a very grateful user
> of the rugarch package.
>
>
>
>
>
> Code follows and an example of the plot is attached:
>
> library(rugrch)
> data(sp500ret)
>
> spec<-ugarchspec(variance.model = list(model = "sGARCH",
> garchOrder = c(1, 1)),distribution.model = "norm")
>
> roll<-ugarchroll(spec,data=data[,3],n.ahead = 1,
> 	forecast.length = 100,refit.every=60,refit.window="moving",
> 	solver = "hybrid", calculate.VaR = TRUE,
> 	VaR.alpha =0.01)
>
> plot(roll,which=4,VaR.alpha=0.01)
>
>
>
> ____________________________________________________________
> South Africas premier free email service - www.webmail.co.za
>
> For super low premiums, click here.
> http://www.dialdirect.co.za/smart-can-get-a-parrot-hands-free-kit?vdn=15752
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From bpilgrimmeister at gmail.com  Wed May 15 22:31:21 2013
From: bpilgrimmeister at gmail.com (Billy Pilgrim)
Date: Wed, 15 May 2013 16:31:21 -0400
Subject: [R-SIG-Finance] Analyzing Real Portfolios and Transactions from
	Interactive Brokers
Message-ID: <5193F099.3090806@gmail.com>

Hi

I am trading with Interactive Brokers and I am trying to determine how I 
would go about easily loading my IB transactions into blotter for later 
analysis with the PerformanceAnalytics package.  I have searched 
r-sig-finance and blogs for any discussions on this subject but have not 
found any info so far .... just managed to give myself a headache 
scanning all the posts.

If anyone can point me in the right direction it would be very helpful.  
Although IB's reporting system is fairly adequate on real money accounts 
it is not available for the paper trading and it does not have the 
ability to isolate performance of trading individual instruments.

Regards ... Billy


From matthieu.stigler at gmail.com  Thu May 16 20:00:47 2013
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Thu, 16 May 2013 20:00:47 +0200
Subject: [R-SIG-Finance] PLM package - pggls
In-Reply-To: <1368091108.68297.YahooMailNeo@web163804.mail.gq1.yahoo.com>
References: <1368091108.68297.YahooMailNeo@web163804.mail.gq1.yahoo.com>
Message-ID: <CAEYvigJfH6rHTR6vz8PbcbJ++TAshqrnz_uyJDFkzXF5TpdJ_Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130516/f5464f23/attachment.pl>

From faiube at gmail.com  Sat May 18 13:55:15 2013
From: faiube at gmail.com (fernando)
Date: Sat, 18 May 2013 04:55:15 -0700 (PDT)
Subject: [R-SIG-Finance] function "spectrum"
Message-ID: <1368878115730-4667405.post@n4.nabble.com>

Hi, I am interested in the use of spectrum function and I want to set a
different number of frequencies. Does anyone know how to manage this issue.
For example I want to set m=T^0.5, what should I do? Or else is  there any
other alternative functions to do this?
Thanks in advance,
Fernando



--
View this message in context: http://r.789695.n4.nabble.com/function-spectrum-tp4667405.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From faiube at gmail.com  Sat May 18 13:57:28 2013
From: faiube at gmail.com (fernando)
Date: Sat, 18 May 2013 04:57:28 -0700 (PDT)
Subject: [R-SIG-Finance] function "spectrum"
Message-ID: <1368878248658-4667406.post@n4.nabble.com>

Hi, I am interested in the use of spectrum function and I want to set a
different number of frequencies. Does anyone know how to manage this issue.
For example I want to set m=T^0.5, what should I do? Or else is  there any
other alternative functions to do this?
Thanks in advance,
Fernando



--
View this message in context: http://r.789695.n4.nabble.com/function-spectrum-tp4667406.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From kw1958 at gmail.com  Sat May 18 14:35:19 2013
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Sat, 18 May 2013 08:35:19 -0400
Subject: [R-SIG-Finance] CVA functionality in R?
Message-ID: <E8CEC800-BF8F-45FE-B1B6-4276F1024F22@gmail.com>

Folks,
  I am sorry if this (short) note makes it to the list twice. I mistakenly posted with a wrong email address. It doesn't seem to have made it into the archive (which is good!).

We are working to build a CVA (Credit Valuation Adjustment) system in R.

Pointers or links to R resources that are specific to this project would be greatly appreciated.

Note that I have looked at the CRAN Finance Task view.

Thanks for your help,
KW


--


From junluke at gmail.com  Sat May 18 16:41:01 2013
From: junluke at gmail.com (jun wang)
Date: Sat, 18 May 2013 10:41:01 -0400
Subject: [R-SIG-Finance] Error message of rmgarch package
Message-ID: <CAPD4hGAbYfF2mLsH0GAUQMreshTgY0JhxHZm9v01FJQcOHqxsA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130518/93688d76/attachment.pl>

From jenbohold at yahoo.de  Sat May 18 16:53:24 2013
From: jenbohold at yahoo.de (Jen Bohold)
Date: Sat, 18 May 2013 15:53:24 +0100 (BST)
Subject: [R-SIG-Finance] Different results between Box-Ljung test and ARCHLM
	test?
Message-ID: <1368888804.2183.YahooMailNeo@web171402.mail.ir2.yahoo.com>



Hi,
using r and the rugarch package, I fitted a garch model u. The output (extracted) is as follows:

GARCH Model??? : sGARCH(1,1)
Mean Model??? : ARFIMA(0,0,0)
Distribution??? : norm 


Q-Statistics on Standardized Residuals
------------------------------------
???????????? ? ? ? ? ?? statistic? p-value
Lag[1]????? ? ?? ???? 7.939??? 0.004839
Lag[p+q+1][1]???? 7.939??? 0.004839
Lag[p+q+5][5]??? 15.939 ? 0.007021
d.o.f=0
H0 : No serial correlation

Q-Statistics on Standardized Squared Residuals
------------------------------------
?????????? ? ? ? ? ?? ? statistic? p-value
Lag[1]????????? ? ? ? 1.390??? 0.238324
Lag[p+q+1][3]???? 9.242 ?? 0.002365
Lag[p+q+5][7]??? 11.963 ? 0.035303
d.o.f=2

ARCH LM Tests
------------------------------------
????????? ? ? ? ? ? ?? ? Statistic DoF P-Value
ARCH Lag[2]????? 5.474?? 2?????? 0.06478
ARCH Lag[5]????? 8.973?? 5?????? 0.11014
ARCH Lag[10]??? 12.090? 10 ? ? 0.27910

Now I have trouble interpreting the results of Q-Statistics?
First of all to test the mean equation, we look at the standardized 
residuals. These standardized residuals should behave iid(0,1). Since 
the p-values is very small, we can conclude, that they are not 
independent, since there exist serial correlation. Is this right?
To test the volatility equation we look at the standardized squared 
residuals, they should also behave iid(0,1). Since the p-values for lag 
order higher than one are small, we can conclude, that they are not 
independent. So there still exist arch effects, Right?
Now my problem is, that the ARCHLM test also looks at the 
standardized squared residuals and comes to a different result: The 
p-value is not very small, so H0 cannot be rejected. That means, there 
are no ARCH effects left?

So the ARCHLM tests shows a different result than the Q-Statistics? What should I conclude in this case?

I attached the plots of the standardized residuals and the squared standardized residuals.
Thanks a lot for your help, Jen
-------------- next part --------------
A non-text attachment was scrubbed...
Name: test1.PNG
Type: image/png
Size: 80288 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130518/e41dff4d/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: test2.PNG
Type: image/png
Size: 82893 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130518/e41dff4d/attachment-0001.png>

From alexios at 4dscape.com  Sat May 18 16:59:31 2013
From: alexios at 4dscape.com (Alexios Ghalanos)
Date: Sat, 18 May 2013 09:59:31 -0500
Subject: [R-SIG-Finance] Error message of rmgarch package
In-Reply-To: <CAPD4hGAbYfF2mLsH0GAUQMreshTgY0JhxHZm9v01FJQcOHqxsA@mail.gmail.com>
References: <CAPD4hGAbYfF2mLsH0GAUQMreshTgY0JhxHZm9v01FJQcOHqxsA@mail.gmail.com>
Message-ID: <BF1B7AF1-8506-419D-8E13-F7EFA208B63E@4dscape.com>

Hi,

Try solver='gosolnp' (NOT 'slover'...at best rlover), and report back if you continue to have problems. Also, the cgarchspec you provide has errors (fixed.pars should be outside the distribution.model list and I am assuming that you WANT to fix the shape parameter since cgarchfit CAN estimate it)...and make sure you are using the latest version from google code.

Regards,

Alexios

On 18 May 2013, at 09:41, jun wang <junluke at gmail.com> wrote:

> Hi,Alexios,
> 
> I am doing a project using Rmgarch package and i kept getting the following
> error messages when using 'cgarchfit'. I was wondering if you could give
> any advice. Many thanks!!!
> 
> 
> Non-Converged:
> [1] 2
> 
> dccfit-->error: convergence problem in univariate fit...
> ...returning uGARCHmultifit object instead...check and resubmit...Error in
> UseMethod("rcor") :
>  no applicable method for 'rcor' applied to an object of class
> "uGARCHmultifit"
> In addition: Warning message:
> In .sgarchfit(spec = spec, data = data, out.sample = out.sample,  :
> ugarchfit-->warning: solver failer to converge.
> 
> 
> Here is my code:
> 
> uspec = ugarchspec(mean.model = list(armaOrder = c(1,0),include.mean=TRUE),
>                   variance.model = list(garchOrder = c(1,1), model =
> "sGARCH"),
>                   distribution.model = "norm")
> 
> spec1 = cgarchspec(uspec = multispec( replicate(2, uspec) ), asymmetric =
> TRUE, distribution.model = list(copula = "mvt", method = "Kendall",
> time.varying = TRUE, transformation = "empirical",fixed.pars = list(mshape
> = v)))
> fit1 = cgarchfit(spec1, data =return,
> solver.control=list(trace=0),slover=c("gosolnp","lbfgs"))
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From sduve at hotmail.com  Sat May 18 19:18:35 2013
From: sduve at hotmail.com (sven duve)
Date: Sat, 18 May 2013 19:18:35 +0200
Subject: [R-SIG-Finance] CVA functionality in R?
In-Reply-To: <E8CEC800-BF8F-45FE-B1B6-4276F1024F22@gmail.com>
References: <E8CEC800-BF8F-45FE-B1B6-4276F1024F22@gmail.com>
Message-ID: <DUB405-EAS178511B2453A17519462CDABEAD0@phx.gbl>

Hello,

what exactly are you looking for? Existing packages which you could build on? 

I think a package like this could be good.

Best Regards


Sven Duve

Am 18 May 2013 um 14:36 schrieb "Keith S Weintraub" <kw1958 at gmail.com>:

> Folks,
>  I am sorry if this (short) note makes it to the list twice. I mistakenly posted with a wrong email address. It doesn't seem to have made it into the archive (which is good!).
> 
> We are working to build a CVA (Credit Valuation Adjustment) system in R.
> 
> Pointers or links to R resources that are specific to this project would be greatly appreciated.
> 
> Note that I have looked at the CRAN Finance Task view.
> 
> Thanks for your help,
> KW
> 
> 
> --
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From yana.roth at yahoo.com  Mon May 20 09:37:15 2013
From: yana.roth at yahoo.com (Yana Roth)
Date: Mon, 20 May 2013 00:37:15 -0700 (PDT)
Subject: [R-SIG-Finance] nested matrices
Message-ID: <1369035435.77128.YahooMailClassic@web160502.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130520/ed1e9030/attachment.pl>

From michael.weylandt at gmail.com  Mon May 20 09:49:31 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Mon, 20 May 2013 08:49:31 +0100
Subject: [R-SIG-Finance] nested matrices
In-Reply-To: <1369035435.77128.YahooMailClassic@web160502.mail.bf1.yahoo.com>
References: <1369035435.77128.YahooMailClassic@web160502.mail.bf1.yahoo.com>
Message-ID: <CAAmySGP72+UZTBOCFJxPeoyPpSvmK8eQEOHv8RV47KYh3icWGA@mail.gmail.com>

As best as I know the Matlab 'cell array', you might want to consider
adding dimensionality to a list object:

x <- list(1:4, "cow", lm, 0.25)
dim(x) <- c(2,2)

Then you can do:

x[[2,2]] + 1

x[[1,2]](rnorm(25) ~ rexp(25))

None too financey

etc.

MW

On Mon, May 20, 2013 at 8:37 AM, Yana Roth <yana.roth at yahoo.com> wrote:
> Hello,I was reading the tread about R equivalent of cell array in Matlab and still couldn't understand how can you systematically  organize large set of data as cell arrays in R.
> would appreciate your help
>
> Yana
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From dominykasgrigonis at gmail.com  Mon May 20 14:15:29 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Mon, 20 May 2013 13:15:29 +0100
Subject: [R-SIG-Finance] Passing variables...
Message-ID: <A0EAAE2C922646A183E29D1AA6C99249@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130520/db6a5d44/attachment.pl>

From deo.jaiswal at gmail.com  Mon May 20 14:26:17 2013
From: deo.jaiswal at gmail.com (Deo Jaiswal)
Date: Mon, 20 May 2013 08:26:17 -0400
Subject: [R-SIG-Finance] Passing variables...
In-Reply-To: <A0EAAE2C922646A183E29D1AA6C99249@gmail.com>
References: <A0EAAE2C922646A183E29D1AA6C99249@gmail.com>
Message-ID: <CAPMHGQw80tYf7vBenpVYTMCPRaXcPPOKP_7LJsRN7DuFsFHJxg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130520/d29bc9ee/attachment.pl>

From dominykasgrigonis at gmail.com  Mon May 20 14:50:21 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Mon, 20 May 2013 13:50:21 +0100
Subject: [R-SIG-Finance] Passing variables...
In-Reply-To: <CAPMHGQw80tYf7vBenpVYTMCPRaXcPPOKP_7LJsRN7DuFsFHJxg@mail.gmail.com>
References: <A0EAAE2C922646A183E29D1AA6C99249@gmail.com>
	<CAPMHGQw80tYf7vBenpVYTMCPRaXcPPOKP_7LJsRN7DuFsFHJxg@mail.gmail.com>
Message-ID: <BE9271F2C6904410ADA83C4B11E4D971@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130520/0f774230/attachment.pl>

From jenbohold at yahoo.de  Mon May 20 15:17:57 2013
From: jenbohold at yahoo.de (Jen Bohold)
Date: Mon, 20 May 2013 14:17:57 +0100 (BST)
Subject: [R-SIG-Finance] Interpretation of sign bias test in rugarch output?
Message-ID: <1369055877.9321.YahooMailNeo@web171405.mail.ir2.yahoo.com>

I fitted a standard GARCH(1,1) model to my data using r and the rugarch package. In the model checking, I looked at the sign bias test output:

Sign Bias Test
------------------------------------
???????????????? ? ? ? ? ?? t-value????? prob sig
Sign Bias??????? ? ? ?? 2.020???? 4.344e-02? **
Negative Sign Bias? 1.014 ? ? 3.105e-01??? 
Positive Sign Bias?? 1.579 ? ? 1.145e-01??? 
Joint Effect????? ? ? ?? 21.632 ?? 7.779e-05 ***


I am not sure about the interpretation of this?

I said the following:

The test for sign bias tests if positive and negative shocks have different impacts on the volatility. 
The positive size bias test tests, if the size of positive shocks affects the volatility differently. So if large and small shocks have different impacts on the volatility, which are not predicted by the volatility model (the negative size bias test is for negative shocks).
Since I used a standard GARCH model, I already assumed, that larger shocks have a larger influcence on the volatility (since the epsilon term is squared in the volatility equation). The output shows, that the main problem here is the sign bias. So my sGARCH models the impact of the size of the shocks on the volatility correctly, but positive and negative shocks have different impacts on the volatility and not a symmetric impact.

Is this correct, can anyone give further hings/comments?

Thanks a lot for your wisdom!
Jen


From es at enricoschumann.net  Mon May 20 15:38:07 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Mon, 20 May 2013 15:38:07 +0200
Subject: [R-SIG-Finance] Passing variables...
In-Reply-To: <A0EAAE2C922646A183E29D1AA6C99249@gmail.com> (Dominykas
	Grigonis's message of "Mon, 20 May 2013 13:15:29 +0100")
References: <A0EAAE2C922646A183E29D1AA6C99249@gmail.com>
Message-ID: <87sj1h4vr4.fsf@enricoschumann.net>

On Mon, 20 May 2013, Dominykas Grigonis <dominykasgrigonis at gmail.com> writes:

> Hello, I am writing a scenario analysis for option strategies. I am
> trying to build a framework, such that new pricing functions can be
> added as well as volatility surface, interest rate term structure,
> etc? But for now I am sticking to ear vanilla case. Anyways, the
> problem is not actually related to finance, but I could not find any
> answer so far.
>
> fun1 <- function(a,b){fun2(a)}
> fun2 <- function(c){fun3(c)}
> fun3 <- function(d){d+b}
>
>
> fun1(2,2) #Error in fun3(c) : object 'b' not found
>
> I have always thought that if functions can not find a variable it
> gradually goes back up through each single environment looking for
> that variable. However, now it is apparent, that it only looks for it
> in .GlobalEnv.

If a variable is not found during function evaluation, R will indeed
move through the environments that enclose the function's environment.
But the function's environment is the one in which the function was
*created*, not where it was *called*.

Example:

  fun1 <- function()
      a + 1

  fun2 <- function(f){
      a <- 5
      f()
  }
  fun2(fun1)  

  ## Error in f() (from #1) : object 'a' not found

This is an error because 'a' was not defined in environment of 'fun1'.
But the following would work, even though 'a' does not exist in the
global environment.

  makefun <- function() {
      a <- 5
      function()
          a + 1
  }
  fun3 <- makefun()
  fun2(fun3)


[...]

> anyways, you got the idea of my issue. I do not want to pass all of
> these via arguments through 2 functions. The main reason is that it
> becomes messy and complicates the code significantly. I was thinking

My suggestion would still be: pass everything.  If you don't like to
have too many arguments, collect all information in one list, 'Data',
say.  Then you only have to pass one object.  In my experience, the
increased 'complication' of adding more arguments to your functions is
nothing compared with the trouble you will have when you need to debug
your code.

>
> Do you have any ideas how to overcome this issue?
> I could share the code, but there is quite a lot of it. I hope you
> understand my problem and I will appreciate any help. Thank you in
> advance.

You could of course assign all variables in the global environment.  But
if you really want to use environments, I would suggest to make this
dependence explicit:

  Data <- new.env()
  Data$a <- 5
  environment(fun1) <- Data
  ls()  

  ## [1] "Data" "fun1" "fun2"

  ls(environment(fun1))
  
  ## [1] "a"

  fun2(fun1)

  ## [1] 6

It is easier then to keep track of what you add to or remove from 'Data'.

Regards,
Enrico

>
> Kind regards,--  
> Dominykas Grigonis
>
>
> 	[[alternative HTML version deleted]]

Please send plain-text messages to this mailing list.

>

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From jenbohold at yahoo.de  Mon May 20 17:15:03 2013
From: jenbohold at yahoo.de (Jen Bohold)
Date: Mon, 20 May 2013 16:15:03 +0100 (BST)
Subject: [R-SIG-Finance] Q-Statistics lag order and connection to plot
Message-ID: <1369062903.33463.YahooMailNeo@web171406.mail.ir2.yahoo.com>



Hi,
I am sorry to bother you and the list again, but I have again a problem which I cannot explain to myself:

I fitted a ARMA-GARCH model with the rugarch package of r. The arma is modified, since some parameters are fixed to zero. The relevant output for the explanation of my problem of the model is:


*---------------------------------*
*????????? GARCH Model Fit*
*---------------------------------*

Conditional Variance Dynamics ??? 
-----------------------------------
GARCH Model??? : sGARCH(1,1)
Mean Model??? : ARFIMA(5,0,5)
Distribution??? : norm 

Optimal Parameters
------------------------------------
??????? Estimate? Std. Error? t value Pr(>|t|)
ar1???? 0.000000????????? NA?????? NA?????? NA
ar2???? 0.000000????????? NA?????? NA?????? NA
ar3???? 0.000000????????? NA?????? NA?????? NA
ar4??? -0.292207??? 0.019550 -14.9467? 0.0e+00
ar5??? -0.745887??? 0.018488 -40.3436? 0.0e+00
ma1???? 0.000000????????? NA?????? NA?????? NA
ma2???? 0.000000????????? NA?????? NA?????? NA
ma3???? 0.000000????????? NA?????? NA?????? NA
ma4???? 0.309446??? 0.026659? 11.6073? 0.0e+00
ma5???? 0.718856??? 0.021208? 33.8952? 0.0e+00
omega?? 0.000006??? 0.000001?? 4.2106? 2.5e-05
alpha1? 0.093397??? 0.011308?? 8.2591? 0.0e+00
beta1?? 0.892404??? 0.012437? 71.7563? 0.0e+00


Q-Statistics on Standardized Residuals
------------------------------------
???????????????????????? statistic? ? p-value
Lag[1]????????? ? ?? ? 7.898???? ? 4.949e-03
Lag[p+q+1][11]??? 21.627???? 3.312e-06
Lag[p+q+5][15]??? 27.133???? 5.374e-05
d.o.f=10
H0 : No serial correlation

Q-Statistics on Standardized Squared Residuals
------------------------------------
???????????? ? ? ? ? ?? statistic? p-value
Lag[1]??????? ? ? ?? 1.274???? 0.258961
Lag[p+q+1][3]???? 9.351??? 0.002229
Lag[p+q+5][7]??? 12.135 ?? 0.032980
d.o.f=2

My first question belongs to the used lag order in case of the Q-Statistics on Standardized Squared Residuals:
Why is this 3 and 7? As in the case of standardized residuals I would have expect it to be equal to 11 and 15?

Also, if I look at the acf of the standardized squared residuals of the plot method (I attached the plot) you can see, that there is no significant spike. So why is the p-value of lag order 3 and 7 so small? This would mean, that there is serial correlation, which is highly significant, but as the plot shows, all spikes are not significant?

I also attached my data, and my r code is:


library(rugarch)


modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)), 
mean.model = list(armaOrder = c(5, 5), include.mean = FALSE), 
distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))

modgarch<-ugarchfit(spec=modsp,data=mydata)
plot(modgarch)



Thanks a lot for your help,
Jen
-------------- next part --------------
A non-text attachment was scrubbed...
Name: acfstandalvsquared.PNG
Type: image/png
Size: 16874 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130520/aca25a5d/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mydatagarch.RData
Type: application/octet-stream
Size: 27552 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130520/aca25a5d/attachment.obj>

From sashinali79 at hotmail.com  Mon May 20 18:36:12 2013
From: sashinali79 at hotmail.com (Sash Ali)
Date: Mon, 20 May 2013 16:36:12 +0000
Subject: [R-SIG-Finance]  Is R good for Finance ?
In-Reply-To: <DUB103-W502FD25491036547D1137FAB7F0@phx.gbl>
References: <DUB103-W28EE932F42A34567C2CE6EAB7F0@phx.gbl>,
	<20120213180934.0c9cb49c@desktop1>,
	<DUB103-W502FD25491036547D1137FAB7F0@phx.gbl>
Message-ID: <DUB103-W7EF2211EC299A2AEFEE4DABAF0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130520/b5b43781/attachment.pl>

From dominykasgrigonis at gmail.com  Tue May 21 03:46:18 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Tue, 21 May 2013 02:46:18 +0100
Subject: [R-SIG-Finance] Passing variables...
In-Reply-To: <87sj1h4vr4.fsf@enricoschumann.net>
References: <A0EAAE2C922646A183E29D1AA6C99249@gmail.com>
	<87sj1h4vr4.fsf@enricoschumann.net>
Message-ID: <D13BBAD186A04E768997C657B5BD53CE@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130521/3375dcfa/attachment.pl>

From nikos.rachmanis at gmail.com  Tue May 21 07:33:47 2013
From: nikos.rachmanis at gmail.com (Nikos Rachmanis)
Date: Tue, 21 May 2013 01:33:47 -0400
Subject: [R-SIG-Finance] Rbbg(Bloomberg) time zone problem and xts
	constructor
Message-ID: <519B073B.1000307@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130521/80f8d872/attachment.pl>

From David.Reiner at xrtrading.com  Tue May 21 18:09:05 2013
From: David.Reiner at xrtrading.com (David Reiner)
Date: Tue, 21 May 2013 11:09:05 -0500
Subject: [R-SIG-Finance] [SPAM] - Rbbg(Bloomberg) time zone problem and
 xtsconstructor - Email found in subject
In-Reply-To: <bc0ce9e0-fccf-49ed-ac0a-a784e3788a51@r-project.org>
References: <bc0ce9e0-fccf-49ed-ac0a-a784e3788a51@r-project.org>
Message-ID: <9DE405308A6AA24AA794B76282C6C00F4A4231CA5D@HQ-POST1>

new<-xts(bid[,3:4],order.by=strptime(x=bid$time,format="%Y-%m-%dT%H:%M:%OS")-4*3600)

should work for you (until DST  ends.)
Note that bid$time was already character. Always look to see what you are getting back.
Also, it's considered polite to give the commands you used to get your results so helpers are encouraged to help.

-- David

-----Original Message-----
From: r-sig-finance-bounces at r-project.org [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Nikos Rachmanis
Sent: Tuesday, May 21, 2013 12:34 AM
To: r-sig-finance at r-project.org
Subject: [SPAM] - [R-SIG-Finance] Rbbg(Bloomberg) time zone problem and xtsconstructor - Email found in subject

Hi all,

I have come across the following time zone problem and I would
appreciate your input.

I am trying to download tick data using the Rbloomberg and I have found
out that the query should be done in "UTC" time zone. My current zone is
"EST" so i have written the code below to transform it from "EST" to
"UTC" and works fine however the output i get is indicated in "UTC" as
listed below for my query (instead of 10:00:00.000).


        time    type    value   size
1       2013-05-13T14:00:00.000         ASK_BEST        454.87  1
2       2013-05-13T14:00:00.000         TRADE   454.58  100
3       2013-05-13T14:00:00.000         ASK_BEST        454.78  10
4       2013-05-13T14:00:00.000         ASK_BEST        454.7   1
5       2013-05-13T14:00:00.000         TRADE   454.58  100
6       2013-05-13T14:00:00.000         ASK_BEST        454.7   1
7       2013-05-13T14:00:01.000         ASK_BEST        454.69  1


My questions are the the following:
1) Is there a way I could write the timezone transformation and get the
correct timing or would I have to change after I download?
2) I have tried to use the xts constructor with the following command
but was not successful. Any idea how to separate the "T" in the time?
new<-xts(bid[,3:4],order.by=strptime(x=as.character(bid$time),format="%Y-%m-%d
%H:%M:%OS",tz="EST"))

Thank you all,

Nikos



#Rbloomberg Code
# Special options
options(warn=-1)
options(digits.secs = 3)
options(java.parameters = "-Xmx1000m")

# Import libraries
library(RODBC)
library(Rbbg)

#set time interval (transforms from 10:00:00.001 to 14:00:00.001)
start_time<-toString(format(as.POSIXct("2013-05-13 10:00:00.001",
tz="EST5EDT"), tz="UTC"))
end_time<-toString(format(as.POSIXct("2013-05-13 10:15:00.001",
tz="EST5EDT"), tz="UTC"))

# Connect to Bloomberg API
conn <-  blpConnect(log.level = "finest")

#Download command
data <- tick(conn, "AAPL US Equity",
              c("TRADE","BID_BEST","ASK_BEST"),
              start_date_time=start_time,
              end_date_time=end_time)

        [[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.

THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON'S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.


From brendan_dornan at hotmail.com  Tue May 21 18:09:43 2013
From: brendan_dornan at hotmail.com (dornan)
Date: Tue, 21 May 2013 09:09:43 -0700 (PDT)
Subject: [R-SIG-Finance] qmao installation failure
In-Reply-To: <CA+xi=qbOcVxy9hOnWKTrCer=LeS=djvE9VvkG_XRW1RXQstu0w@mail.gmail.com>
References: <20130316004307.GD10052@ninja.nosyntax.net>
	<CA+xi=qbOcVxy9hOnWKTrCer=LeS=djvE9VvkG_XRW1RXQstu0w@mail.gmail.com>
Message-ID: <1369152583384-4667618.post@n4.nabble.com>

great package, thanks for putting it together.  Getting some errors and
wondering if someone could help. Sorry in advance if posting format 

#only a few lines with this command
> getEPS("Goog")
           Goog.Q.EPS
2012-03-31       8.75
2012-06-30       8.56
2012-09-30       6.47
2012-12-31       9.40
2013-03-31      10.00
Warning message:
In readLines(tmp) :
  incomplete final line found on
'C:\Users\BAM\AppData\Local\Temp\RtmpC0laFg\file111060ec69e2'

#xts, gdata, pander, all installed, but getting this error
> getEarnings("GOOG")
Error in `[.data.frame`(df, , "TIME") : undefined columns selected
In addition: Warning messages:
1: NAs introduced by coercion 
2: NAs introduced by coercion 
3: NAs introduced by coercion 

Thanks for any help!



--
View this message in context: http://r.789695.n4.nabble.com/qmao-installation-failure-tp4661552p4667618.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From gsee000 at gmail.com  Tue May 21 18:14:37 2013
From: gsee000 at gmail.com (G See)
Date: Tue, 21 May 2013 11:14:37 -0500
Subject: [R-SIG-Finance] qmao installation failure
In-Reply-To: <1369152583384-4667618.post@n4.nabble.com>
References: <20130316004307.GD10052@ninja.nosyntax.net>
	<CA+xi=qbOcVxy9hOnWKTrCer=LeS=djvE9VvkG_XRW1RXQstu0w@mail.gmail.com>
	<1369152583384-4667618.post@n4.nabble.com>
Message-ID: <CA+xi=qbV-Q8t5RjSFuPkCUam9UtoqTGR5zeF7t1kcLda_9tBtQ@mail.gmail.com>

Please provide the output of sessionInfo()

For me, with this sessionInfo()
> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] qmao_1.6.5.2              XML_3.96-1.1
[3] gdata_2.12.0.2            FinancialInstrument_1.1.7
[5] quantmod_0.4-0            TTR_0.22-0.1
[7] Defaults_1.1-1            xts_0.9-3.2
[9] zoo_1.7-10

loaded via a namespace (and not attached):
 [1] bitops_1.0-5    caTools_1.14    digest_0.6.3    grid_3.0.1
 [5] gtools_2.7.1    httpuv_1.0.5    lattice_0.20-15 pander_0.3.5
 [9] RCurl_1.95-4.1  RJSONIO_1.0-3   shiny_0.5.0.99  xtable_1.7-1

I get this

> getEarnings("GOOG")
                    EPS.ESTIMATE EPS.ACTUAL PREV.YEAR.ACTUAL
2004-10-21 15:15:00           NA         NA               NA
2005-02-01 15:15:00           NA         NA               NA
2005-04-21 15:15:00           NA         NA               NA
2005-07-21 15:15:00           NA         NA               NA
2005-10-20 15:15:00           NA         NA               NA
2006-01-31 15:15:00           NA         NA               NA
2006-04-20 15:15:00         1.98       2.29               NA
2006-07-20 15:15:00         2.22       2.49               NA
2006-10-19 15:15:00         2.42       2.62               NA
2007-01-31 15:15:00         2.92       3.18               NA
2007-04-19 15:15:00         3.31       3.68             2.29
2007-07-19 15:15:00         3.59       3.56             2.49
2007-10-18 15:15:00         3.78       3.91             2.62
2008-01-31 15:15:00         4.44       4.43             3.18
2008-04-17 15:15:00         4.52       4.84             3.68
2008-07-17 15:15:00         4.74       4.63             3.56
2008-10-16 15:15:00         4.75       4.92             3.91
2009-01-22 15:15:00         4.95       5.10             4.43
2009-04-16 15:15:00         4.93       5.16             4.84
2009-07-16 15:15:00         5.09       5.36             4.63
2009-10-15 15:15:00         5.42       5.89             4.92
2010-01-21 15:15:00         6.48       6.79             5.10
2010-04-15 15:15:00         6.60       6.76             5.16
2010-07-15 15:15:00         6.52       6.45             5.36
2010-10-14 15:15:00         6.69       7.64             5.89
2011-01-20 15:15:00         8.10       8.75             6.79
2011-04-14 15:15:00         8.10       8.08             6.76
2011-07-14 15:15:00         7.85       8.74             6.45
2011-10-13 15:15:00         8.74       9.72             7.64
2012-01-19 15:15:00        10.50       9.50             8.75
2012-04-12 15:15:00         9.65      10.08             8.08
2012-07-19 15:15:00        10.04      10.12             8.74
2012-10-18 15:15:00        10.65       9.03             9.72
2013-01-22 15:15:00        10.42      10.59             9.50
2013-04-18 15:15:00        10.66      11.58            10.08
2013-07-15 15:15:00        10.80         NA            10.12
Warning message:
In FUN(c("15-Jul-13 - 19-Jul-13", "18-Apr-13 AMC", "22-Jan-13 AMC",  :
  Using 1st date of earnings date range

Garrett

On Tue, May 21, 2013 at 11:09 AM, dornan <brendan_dornan at hotmail.com> wrote:
> great package, thanks for putting it together.  Getting some errors and
> wondering if someone could help. Sorry in advance if posting format
>
> #only a few lines with this command
>> getEPS("Goog")
>            Goog.Q.EPS
> 2012-03-31       8.75
> 2012-06-30       8.56
> 2012-09-30       6.47
> 2012-12-31       9.40
> 2013-03-31      10.00
> Warning message:
> In readLines(tmp) :
>   incomplete final line found on
> 'C:\Users\BAM\AppData\Local\Temp\RtmpC0laFg\file111060ec69e2'
>
> #xts, gdata, pander, all installed, but getting this error
>> getEarnings("GOOG")
> Error in `[.data.frame`(df, , "TIME") : undefined columns selected
> In addition: Warning messages:
> 1: NAs introduced by coercion
> 2: NAs introduced by coercion
> 3: NAs introduced by coercion
>
> Thanks for any help!
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/qmao-installation-failure-tp4661552p4667618.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From brendan_dornan at hotmail.com  Tue May 21 21:10:26 2013
From: brendan_dornan at hotmail.com (tbam)
Date: Tue, 21 May 2013 12:10:26 -0700 (PDT)
Subject: [R-SIG-Finance] qmao installation failure
In-Reply-To: <CA+xi=qbV-Q8t5RjSFuPkCUam9UtoqTGR5zeF7t1kcLda_9tBtQ@mail.gmail.com>
References: <20130316004307.GD10052@ninja.nosyntax.net>
	<CA+xi=qbOcVxy9hOnWKTrCer=LeS=djvE9VvkG_XRW1RXQstu0w@mail.gmail.com>
	<1369152583384-4667618.post@n4.nabble.com>
	<CA+xi=qbV-Q8t5RjSFuPkCUam9UtoqTGR5zeF7t1kcLda_9tBtQ@mail.gmail.com>
Message-ID: <1369163426513-4667635.post@n4.nabble.com>

> sessionInfo()
R version 2.15.3 (2013-03-01)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] pander_0.3.6              qmao_1.6                  ggplot2_0.9.3.1          
 [4] devtools_1.1              XML_3.96-1.1              gdata_2.12.0.2           
 [7] FinancialInstrument_1.1.7 quantmod_0.4-0            TTR_0.22-0               
[10] Defaults_1.1-1            xts_0.9-3                 zoo_1.7-9    

Thanks!



--
View this message in context: http://r.789695.n4.nabble.com/qmao-installation-failure-tp4661552p4667635.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From gsee000 at gmail.com  Tue May 21 22:14:36 2013
From: gsee000 at gmail.com (G See)
Date: Tue, 21 May 2013 15:14:36 -0500
Subject: [R-SIG-Finance] qmao installation failure
In-Reply-To: <1369163426513-4667635.post@n4.nabble.com>
References: <20130316004307.GD10052@ninja.nosyntax.net>
	<CA+xi=qbOcVxy9hOnWKTrCer=LeS=djvE9VvkG_XRW1RXQstu0w@mail.gmail.com>
	<1369152583384-4667618.post@n4.nabble.com>
	<CA+xi=qbV-Q8t5RjSFuPkCUam9UtoqTGR5zeF7t1kcLda_9tBtQ@mail.gmail.com>
	<1369163426513-4667635.post@n4.nabble.com>
Message-ID: <CA+xi=qZnJgpr0_y=UFHwVryd+XW_G6f5g4Dx+g-pyy7_NppPYA@mail.gmail.com>

Please update qmao.

With the earnings.com webpage, XML:::readHTMLTable() used to return a
data.frame where the first row was the headers, so getEarnings() and
other functions worked around that by setting the names() to be the
first row, then removing that row. In the current release of XML,
readHTMLTable() gets the names() right, so my previous work-around is
no longer necessary.

The current version of qmao is 1.6.5.2.  Let me know if you still have
issues after upgrading.

Garrett

On Tue, May 21, 2013 at 2:10 PM, tbam <brendan_dornan at hotmail.com> wrote:
>> sessionInfo()
> R version 2.15.3 (2013-03-01)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>  [1] pander_0.3.6              qmao_1.6                  ggplot2_0.9.3.1
>  [4] devtools_1.1              XML_3.96-1.1              gdata_2.12.0.2
>  [7] FinancialInstrument_1.1.7 quantmod_0.4-0            TTR_0.22-0
> [10] Defaults_1.1-1            xts_0.9-3                 zoo_1.7-9
>
> Thanks!
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/qmao-installation-failure-tp4661552p4667635.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From gsee000 at gmail.com  Tue May 21 22:24:51 2013
From: gsee000 at gmail.com (G See)
Date: Tue, 21 May 2013 15:24:51 -0500
Subject: [R-SIG-Finance] qmao installation failure
In-Reply-To: <CA+xi=qZnJgpr0_y=UFHwVryd+XW_G6f5g4Dx+g-pyy7_NppPYA@mail.gmail.com>
References: <20130316004307.GD10052@ninja.nosyntax.net>
	<CA+xi=qbOcVxy9hOnWKTrCer=LeS=djvE9VvkG_XRW1RXQstu0w@mail.gmail.com>
	<1369152583384-4667618.post@n4.nabble.com>
	<CA+xi=qbV-Q8t5RjSFuPkCUam9UtoqTGR5zeF7t1kcLda_9tBtQ@mail.gmail.com>
	<1369163426513-4667635.post@n4.nabble.com>
	<CA+xi=qZnJgpr0_y=UFHwVryd+XW_G6f5g4Dx+g-pyy7_NppPYA@mail.gmail.com>
Message-ID: <CA+xi=qaRYgCDUJo8Gf2TOd4_xLnNHNV4UzeT+PQut2cnU95AjQ@mail.gmail.com>

BTW, this Warning (as opposed to error) in getEPS()

Warning message:
In readLines(tmp) :
  incomplete final line found on
'C:\Users\BAM\AppData\Local\Temp\RtmpC0laFg\file111060ec69e2'

actually comes from getFinancials().  It's harmless, but could be
avoided if getFinancials() were patched to use warn=FALSE in the
readLines() call.


Josh, Jeff,

Line 13 of getFinancials.R could be changed from

    Symbol <- readLines(tmp)

to

    Symbols <- readLines(tmp, warn=FALSE)


Garrett


From nikos.rachmanis at gmail.com  Wed May 22 08:08:03 2013
From: nikos.rachmanis at gmail.com (Nikos Rachmanis)
Date: Wed, 22 May 2013 02:08:03 -0400
Subject: [R-SIG-Finance] Rbbg(Bloomberg) time zone problem and xts
	constructor
In-Reply-To: <CAA3Wa=v5bsDazyptH76+6k-CbqeRccSTcx2fR2n_0bDzhjsBAQ@mail.gmail.com>
References: <519B073B.1000307@gmail.com>
	<CAA3Wa=v5bsDazyptH76+6k-CbqeRccSTcx2fR2n_0bDzhjsBAQ@mail.gmail.com>
Message-ID: <519C60C3.1010004@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130522/96f33ed2/attachment.pl>

From jenbohold at yahoo.de  Wed May 22 09:10:39 2013
From: jenbohold at yahoo.de (Jen Bohold)
Date: Wed, 22 May 2013 08:10:39 +0100 (BST)
Subject: [R-SIG-Finance] Error in rugarch ACF squared standardized residuals
	plot
Message-ID: <1369206639.91126.YahooMailNeo@web171401.mail.ir2.yahoo.com>

Although it seems that there is no feedback and you do not want to comment on me, I thought I should share this to the list, maybe someone else is some time wondering about this (maybe I did a mistake, but no one of the list or you told me in the previous mail). Also, I do not want to offend you, I like your package it's great! Especially I liked the acf plots, they have a better design, although 
you will see in the following text, that the "ACF of Squared Standadrized Residuals" plot are not useable anymore. 


The plot of the ACF of the squared standardized residuals in rugarch output (you get it via plot(yourmodel) and choosing number 11) is wrong.
However, the corresponding Q-Statistics of the rugarch output are correct!

Consider the following (I attached my data and the plots). I fitted the following model (output extracted to the relevant parts):

*---------------------------------*
*????????? GARCH Model Fit*
*---------------------------------*

Conditional Variance Dynamics ??? 
-----------------------------------
GARCH Model??? : sGARCH(1,1)
Mean Model??? : ARFIMA(5,0,5)
Distribution??? : norm 

Optimal Parameters
------------------------------------
??????? Estimate? Std. Error? t value Pr(>|t|)
ar1???? 0.000000????????? NA?????? NA?????? NA
ar2???? 0.000000????????? NA?????? NA?????? NA
ar3???? 0.000000????????? NA?????? NA?????? NA
ar4??? -0.292207??? 0.019550 -14.9467? 0.0e+00
ar5??? -0.745887??? 0.018488 -40.3436? 0.0e+00
ma1???? 0.000000????????? NA?????? NA?????? NA
ma2???? 0.000000????????? NA?????? NA?????? NA
ma3???? 0.000000????????? NA?????? NA?????? NA
ma4???? 0.309446??? 0.026659? 11.6073? 0.0e+00
ma5???? 0.718856??? 0.021208? 33.8952? 0.0e+00
omega?? 0.000006??? 0.000001?? 4.2106? 2.5e-05
alpha1? 0.093397??? 0.011308?? 8.2591? 0.0e+00
beta1?? 0.892404??? 0.012437? 71.7563? 0.0e+00


Q-Statistics on Standardized Residuals
------------------------------------
???????????????????????? statistic? ? p-value
Lag[1]????????? ? ?? ? 7.898???? ? 4.949e-03
Lag[p+q+1][11]??? 21.627???? 3.312e-06
Lag[p+q+5][15]??? 27.133???? 5.374e-05
d.o.f=10
H0 : No serial correlation

Q-Statistics on Standardized Squared Residuals
------------------------------------
???????????? ? ? ? ? ?? statistic? p-value
Lag[1]??????? ? ? ?? 1.274???? 0.258961
Lag[p+q+1][3]???? 9.351??? 0.002229
Lag[p+q+5][7]??? 12.135 ?? 0.032980
d.o.f=2
As you can see in the "Q-Statistics on Standardized Squared Residuals" there is clearly correlation in the standardized squared residuals. BUT if you look at the plot with the plot method and choosing number 11 you can see, that NO spike is significant.

This plot is not correct, I controlled it via the Acf plot of the forecast package and clearly, the spikes are larger! So the second spike is now significant. I control the calculations via the Box.test method using d.o.f.=2 and choosing the lag 3 and 7 and the calculations in the rugarch package are correct! So the p-values are indeed 0.002229 and 0.032980. So why is the plot of the rugarch package wrong?

One further notice: In a previous mail, I asked, why the lags in the Q-Statistics on Standardized Squared Residuals are different to the lags used in Q-Statistics on Standardized Residuals. Of course, I have now seen, that the second uses the GARCH parameters, so it is clear, that this has to be equal to two (1+1). I also have to say, that I think, that the ACF of observations plot e.g. is indeed correct (number 4), so it seems, that the plot number 11 uses different scaled residuals? Maybe it uses the non-standardized squared residuals? Could that be the reason?

Thanks a lot for your notice.
My code:

library(rugarch)
modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)), 
mean.model = list(armaOrder = c(5, 5), include.mean = FALSE), 
distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))

modgarch<-ugarchfit(spec=modsp,data=mydata)
plot(modgarch)


residuals(mydata,standardize=TRUE)
resdi<-as.numeric(residuals(mydata,standardize=TRUE))

library(forecast)
Acf(resdi^2)

Box.test(resdi^2, lag = 3, type = "Ljung-Box", fitdf = 2)
Box.test(resdi^2, lag = 7, type = "Ljung-Box", fitdf = 2)
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mydatagarch.RData
Type: application/octet-stream
Size: 27552 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130522/78795877/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rugarchoutput.PNG
Type: image/png
Size: 17372 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130522/78795877/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: forecastoutput.PNG
Type: image/png
Size: 10868 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130522/78795877/attachment-0001.png>

From alexios at 4dscape.com  Wed May 22 11:43:30 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 22 May 2013 10:43:30 +0100
Subject: [R-SIG-Finance] Error in rugarch ACF squared standardized
	residuals plot
In-Reply-To: <1369206639.91126.YahooMailNeo@web171401.mail.ir2.yahoo.com>
References: <1369206639.91126.YahooMailNeo@web171401.mail.ir2.yahoo.com>
Message-ID: <519C9342.2030904@4dscape.com>

Dear Jen,

The reason I have not answered is that you post one question, then 
instead of patiently waiting for an answer, you very shortly post more 
and more followups. As I said in a previous email, the likelihood of 
answering, at least on my part, will depend on the effort shown to at 
least try to do your own research and the framing of the question. You 
also seem to be cross-posting to stackexchange.

With regards to your specific question, you are wrong and this is seen 
by your own code:

resdi<-as.numeric(residuals(mydata,standardize=TRUE))

This is NOT the standardized residuals of the model but the 
observations, so that when you compare to the Acf plot you are comparing 
the observations (before the estimation) to the standardized residuals 
(after the ARMA filtration).

You probably wanted to write:

resdi<-as.numeric(residuals(modgarch,standardize=TRUE))

The plots of the results from rugarch are the same with what you get 
with the Forecast package (which is actually a wrapper for the stats 
package 'plot.acf').

I'm going to politely ask you to please take some more care when posting 
and making such grand statement as "plot are not useable anymore". You 
are quickly burning through any remaining goodwill left on the part of 
this developer. Finally, I would suggest an excellent reference such as 
Zivot and Wang ("Modeling Financial Time Series with S-PLUS") or Tsay 
("Analysis of Financial Time Series") which may help you answer some of 
your many questions.

Regards,

Alexios



On 22/05/2013 08:10, Jen Bohold wrote:
> Although it seems that there is no feedback and you do not want to comment on me, I thought I should share this to the list, maybe someone else is some time wondering about this (maybe I did a mistake, but no one of the list or you told me in the previous mail). Also, I do not want to offend you, I like your package it's great! Especially I liked the acf plots, they have a better design, although
> you will see in the following text, that the "ACF of Squared Standadrized Residuals" plot are not useable anymore.
>
>
> The plot of the ACF of the squared standardized residuals in rugarch output (you get it via plot(yourmodel) and choosing number 11) is wrong.
> However, the corresponding Q-Statistics of the rugarch output are correct!
>
> Consider the following (I attached my data and the plots). I fitted the following model (output extracted to the relevant parts):
>
> *---------------------------------*
> *          GARCH Model Fit*
> *---------------------------------*
>
> Conditional Variance Dynamics
> -----------------------------------
> GARCH Model    : sGARCH(1,1)
> Mean Model    : ARFIMA(5,0,5)
> Distribution    : norm
>
> Optimal Parameters
> ------------------------------------
>          Estimate  Std. Error  t value Pr(>|t|)
> ar1     0.000000          NA       NA       NA
> ar2     0.000000          NA       NA       NA
> ar3     0.000000          NA       NA       NA
> ar4    -0.292207    0.019550 -14.9467  0.0e+00
> ar5    -0.745887    0.018488 -40.3436  0.0e+00
> ma1     0.000000          NA       NA       NA
> ma2     0.000000          NA       NA       NA
> ma3     0.000000          NA       NA       NA
> ma4     0.309446    0.026659  11.6073  0.0e+00
> ma5     0.718856    0.021208  33.8952  0.0e+00
> omega   0.000006    0.000001   4.2106  2.5e-05
> alpha1  0.093397    0.011308   8.2591  0.0e+00
> beta1   0.892404    0.012437  71.7563  0.0e+00
>
>
> Q-Statistics on Standardized Residuals
> ------------------------------------
>                           statistic    p-value
> Lag[1]                 7.898       4.949e-03
> Lag[p+q+1][11]    21.627     3.312e-06
> Lag[p+q+5][15]    27.133     5.374e-05
> d.o.f=10
> H0 : No serial correlation
>
> Q-Statistics on Standardized Squared Residuals
> ------------------------------------
>                          statistic  p-value
> Lag[1]               1.274     0.258961
> Lag[p+q+1][3]     9.351    0.002229
> Lag[p+q+5][7]    12.135    0.032980
> d.o.f=2
> As you can see in the "Q-Statistics on Standardized Squared Residuals" there is clearly correlation in the standardized squared residuals. BUT if you look at the plot with the plot method and choosing number 11 you can see, that NO spike is significant.
>
> This plot is not correct, I controlled it via the Acf plot of the forecast package and clearly, the spikes are larger! So the second spike is now significant. I control the calculations via the Box.test method using d.o.f.=2 and choosing the lag 3 and 7 and the calculations in the rugarch package are correct! So the p-values are indeed 0.002229 and 0.032980. So why is the plot of the rugarch package wrong?
>
> One further notice: In a previous mail, I asked, why the lags in the Q-Statistics on Standardized Squared Residuals are different to the lags used in Q-Statistics on Standardized Residuals. Of course, I have now seen, that the second uses the GARCH parameters, so it is clear, that this has to be equal to two (1+1). I also have to say, that I think, that the ACF of observations plot e.g. is indeed correct (number 4), so it seems, that the plot number 11 uses different scaled residuals? Maybe it uses the non-standardized squared residuals? Could that be the reason?
>
> Thanks a lot for your notice.
> My code:
>
> library(rugarch)
> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
> distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>
> modgarch<-ugarchfit(spec=modsp,data=mydata)
> plot(modgarch)
>
>
> residuals(mydata,standardize=TRUE)
> resdi<-as.numeric(residuals(mydata,standardize=TRUE))
>
> library(forecast)
> Acf(resdi^2)
>
> Box.test(resdi^2, lag = 3, type = "Ljung-Box", fitdf = 2)
> Box.test(resdi^2, lag = 7, type = "Ljung-Box", fitdf = 2)
>


From jenbohold at yahoo.de  Wed May 22 12:49:30 2013
From: jenbohold at yahoo.de (Jen Bohold)
Date: Wed, 22 May 2013 11:49:30 +0100 (BST)
Subject: [R-SIG-Finance] Error in rugarch ACF squared standardized
	residuals plot
In-Reply-To: <519C9342.2030904@4dscape.com>
References: <1369206639.91126.YahooMailNeo@web171401.mail.ir2.yahoo.com>
	<519C9342.2030904@4dscape.com>
Message-ID: <1369219770.43709.YahooMailNeo@web171401.mail.ir2.yahoo.com>

Dear Alexios,
thanks a lot for your response!
Yes, this was a typo, so I meant to write

resdi<-as.numeric(residuals(modgarch,standardize=TRUE))

and then plot it with


Acf(resdi^2)

this gives a DIFFERENT plot! It is NOT the same!

Again, I attach both plots.



----- Urspr?ngliche Message -----
Von: alexios ghalanos <alexios at 4dscape.com>
An: Jen Bohold <jenbohold at yahoo.de>
CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
Gesendet: 11:43 Mittwoch, 22.Mai 2013
Betreff: Re: Error in rugarch ACF squared standardized residuals plot

Dear Jen,

The reason I have not answered is that you post one question, then 
instead of patiently waiting for an answer, you very shortly post more 
and more followups. As I said in a previous email, the likelihood of 
answering, at least on my part, will depend on the effort shown to at 
least try to do your own research and the framing of the question. You 
also seem to be cross-posting to stackexchange.

With regards to your specific question, you are wrong and this is seen 
by your own code:

resdi<-as.numeric(residuals(mydata,standardize=TRUE))

This is NOT the standardized residuals of the model but the 
observations, so that when you compare to the Acf plot you are comparing 
the observations (before the estimation) to the standardized residuals 
(after the ARMA filtration).

You probably wanted to write:

resdi<-as.numeric(residuals(modgarch,standardize=TRUE))

The plots of the results from rugarch are the same with what you get 
with the Forecast package (which is actually a wrapper for the stats 
package 'plot.acf').

I'm going to politely ask you to please take some more care when posting 
and making such grand statement as "plot are not useable anymore". You 
are quickly burning through any remaining goodwill left on the part of 
this developer. Finally, I would suggest an excellent reference such as 
Zivot and Wang ("Modeling Financial Time Series with S-PLUS") or Tsay 
("Analysis of Financial Time Series") which may help you answer some of 
your many questions.

Regards,

Alexios



On 22/05/2013 08:10, Jen Bohold wrote:
> Although it seems that there is no feedback and you do not want to comment on me, I thought I should share this to the list, maybe someone else is some time wondering about this (maybe I did a mistake, but no one of the list or you told me in the previous mail). Also, I do not want to offend you, I like your package it's great! Especially I liked the acf plots, they have a better design, although
> you will see in the following text, that the "ACF of Squared Standadrized Residuals" plot are not useable anymore.
>
>
> The plot of the ACF of the squared standardized residuals in rugarch output (you get it via plot(yourmodel) and choosing number 11) is wrong.
> However, the corresponding Q-Statistics of the rugarch output are correct!
>
> Consider the following (I attached my data and the plots). I fitted the following model (output extracted to the relevant parts):
>
> *---------------------------------*
> *? ? ? ? ? GARCH Model Fit*
> *---------------------------------*
>
> Conditional Variance Dynamics
> -----------------------------------
> GARCH Model? ? : sGARCH(1,1)
> Mean Model? ? : ARFIMA(5,0,5)
> Distribution? ? : norm
>
> Optimal Parameters
> ------------------------------------
>? ? ? ? ? Estimate? Std. Error? t value Pr(>|t|)
> ar1? ?  0.000000? ? ? ? ? NA? ? ?  NA? ? ?  NA
> ar2? ?  0.000000? ? ? ? ? NA? ? ?  NA? ? ?  NA
> ar3? ?  0.000000? ? ? ? ? NA? ? ?  NA? ? ?  NA
> ar4? ? -0.292207? ? 0.019550 -14.9467? 0.0e+00
> ar5? ? -0.745887? ? 0.018488 -40.3436? 0.0e+00
> ma1? ?  0.000000? ? ? ? ? NA? ? ?  NA? ? ?  NA
> ma2? ?  0.000000? ? ? ? ? NA? ? ?  NA? ? ?  NA
> ma3? ?  0.000000? ? ? ? ? NA? ? ?  NA? ? ?  NA
> ma4? ?  0.309446? ? 0.026659? 11.6073? 0.0e+00
> ma5? ?  0.718856? ? 0.021208? 33.8952? 0.0e+00
> omega?  0.000006? ? 0.000001?  4.2106? 2.5e-05
> alpha1? 0.093397? ? 0.011308?  8.2591? 0.0e+00
> beta1?  0.892404? ? 0.012437? 71.7563? 0.0e+00
>
>
> Q-Statistics on Standardized Residuals
> ------------------------------------
>? ? ? ? ? ? ? ? ? ? ? ? ?  statistic? ? p-value
> Lag[1]? ? ? ? ? ? ? ?  7.898? ? ?  4.949e-03
> Lag[p+q+1][11]? ? 21.627? ?  3.312e-06
> Lag[p+q+5][15]? ? 27.133? ?  5.374e-05
> d.o.f=10
> H0 : No serial correlation
>
> Q-Statistics on Standardized Squared Residuals
> ------------------------------------
>? ? ? ? ? ? ? ? ? ? ? ? ? statistic? p-value
> Lag[1]? ? ? ? ? ? ?  1.274? ?  0.258961
> Lag[p+q+1][3]? ?  9.351? ? 0.002229
> Lag[p+q+5][7]? ? 12.135? ? 0.032980
> d.o.f=2
> As you can see in the "Q-Statistics on Standardized Squared Residuals" there is clearly correlation in the standardized squared residuals. BUT if you look at the plot with the plot method and choosing number 11 you can see, that NO spike is significant.
>
> This plot is not correct, I controlled it via the Acf plot of the forecast package and clearly, the spikes are larger! So the second spike is now significant. I control the calculations via the Box.test method using d.o.f.=2 and choosing the lag 3 and 7 and the calculations in the rugarch package are correct! So the p-values are indeed 0.002229 and 0.032980. So why is the plot of the rugarch package wrong?
>
> One further notice: In a previous mail, I asked, why the lags in the Q-Statistics on Standardized Squared Residuals are different to the lags used in Q-Statistics on Standardized Residuals. Of course, I have now seen, that the second uses the GARCH parameters, so it is clear, that this has to be equal to two (1+1). I also have to say, that I think, that the ACF of observations plot e.g. is indeed correct (number 4), so it seems, that the plot number 11 uses different scaled residuals? Maybe it uses the non-standardized squared residuals? Could that be the reason?
>
> Thanks a lot for your notice.
> My code:
>
> library(rugarch)
> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
> distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>
> modgarch<-ugarchfit(spec=modsp,data=mydata)
> plot(modgarch)
>
>
> residuals(mydata,standardize=TRUE)
> resdi<-as.numeric(residuals(mydata,standardize=TRUE))
>
> library(forecast)
> Acf(resdi^2)
>
> Box.test(resdi^2, lag = 3, type = "Ljung-Box", fitdf = 2)
> Box.test(resdi^2, lag = 7, type = "Ljung-Box", fitdf = 2)
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rugarchoutput.PNG
Type: image/png
Size: 17314 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130522/87b81ea1/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: forecastoutput.PNG
Type: image/png
Size: 11031 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130522/87b81ea1/attachment-0001.png>

From alexios at 4dscape.com  Wed May 22 13:30:14 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 22 May 2013 12:30:14 +0100
Subject: [R-SIG-Finance] Error in rugarch ACF squared standardized
	residuals plot
In-Reply-To: <1369219770.43709.YahooMailNeo@web171401.mail.ir2.yahoo.com>
References: <1369206639.91126.YahooMailNeo@web171401.mail.ir2.yahoo.com>
	<519C9342.2030904@4dscape.com>
	<1369219770.43709.YahooMailNeo@web171401.mail.ir2.yahoo.com>
Message-ID: <519CAC46.3060801@4dscape.com>

I can't replicate your PNG chart differences and here is an example of 
how you can check:
##########################################
library(rugarch)
# you specification with YOUR estimated parameters:
modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = 
c(1, 1)),
mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,
ar4 = -0.292207, ar5 = -0.745887, ma1=0,ma2=0,ma3=0,
ma4 = 0.309446, ma5 = 0.718856, omega = 6e-6, alpha1=0.093397,
beta1 = 0.892404))
# Simulate a path
sim=ugarchpath(modsp, n.sim=5000)
# extract the simulated data
mydata = as.numeric(fitted(sim))
# restate the specification:
modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = 
c(1, 1)), mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
distribution.model = 
"norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
# estimate the model:
modgarch<-ugarchfit(spec=modsp,data=mydata )
# extract the standardized residuals:
resdi<-as.numeric(residuals(modgarch,standardize=TRUE))

# plot:
library(forecast)
par(mfrow=c(2,2))
Acf(resdi^2)
plot(modgarch, which=11)
###############################################

I don't see ANY differences. You are however welcome to look at the 
underlying code in the rugarch-plots.R file in the source. If you find a 
bug you are welcome to submit a patch to the google code repository of 
the package rather than continuously sending this list PNG attachments 
and non reproducible code/examples.

Regards,

Alexios


On 22/05/2013 11:49, Jen Bohold wrote:
> Dear Alexios,
> thanks a lot for your response!
> Yes, this was a typo, so I meant to write
>
> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>
> and then plot it with
>
>
> Acf(resdi^2)
>
> this gives a DIFFERENT plot! It is NOT the same!
>
> Again, I attach both plots.
>
>
>
> ----- Urspr?ngliche Message -----
> Von: alexios ghalanos <alexios at 4dscape.com>
> An: Jen Bohold <jenbohold at yahoo.de>
> CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
> Gesendet: 11:43 Mittwoch, 22.Mai 2013
> Betreff: Re: Error in rugarch ACF squared standardized residuals plot
>
> Dear Jen,
>
> The reason I have not answered is that you post one question, then
> instead of patiently waiting for an answer, you very shortly post more
> and more followups. As I said in a previous email, the likelihood of
> answering, at least on my part, will depend on the effort shown to at
> least try to do your own research and the framing of the question. You
> also seem to be cross-posting to stackexchange.
>
> With regards to your specific question, you are wrong and this is seen
> by your own code:
>
> resdi<-as.numeric(residuals(mydata,standardize=TRUE))
>
> This is NOT the standardized residuals of the model but the
> observations, so that when you compare to the Acf plot you are comparing
> the observations (before the estimation) to the standardized residuals
> (after the ARMA filtration).
>
> You probably wanted to write:
>
> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>
> The plots of the results from rugarch are the same with what you get
> with the Forecast package (which is actually a wrapper for the stats
> package 'plot.acf').
>
> I'm going to politely ask you to please take some more care when posting
> and making such grand statement as "plot are not useable anymore". You
> are quickly burning through any remaining goodwill left on the part of
> this developer. Finally, I would suggest an excellent reference such as
> Zivot and Wang ("Modeling Financial Time Series with S-PLUS") or Tsay
> ("Analysis of Financial Time Series") which may help you answer some of
> your many questions.
>
> Regards,
>
> Alexios
>
>
>
> On 22/05/2013 08:10, Jen Bohold wrote:
>> Although it seems that there is no feedback and you do not want to comment on me, I thought I should share this to the list, maybe someone else is some time wondering about this (maybe I did a mistake, but no one of the list or you told me in the previous mail). Also, I do not want to offend you, I like your package it's great! Especially I liked the acf plots, they have a better design, although
>> you will see in the following text, that the "ACF of Squared Standadrized Residuals" plot are not useable anymore.
>>
>>
>> The plot of the ACF of the squared standardized residuals in rugarch output (you get it via plot(yourmodel) and choosing number 11) is wrong.
>> However, the corresponding Q-Statistics of the rugarch output are correct!
>>
>> Consider the following (I attached my data and the plots). I fitted the following model (output extracted to the relevant parts):
>>
>> *---------------------------------*
>> *          GARCH Model Fit*
>> *---------------------------------*
>>
>> Conditional Variance Dynamics
>> -----------------------------------
>> GARCH Model    : sGARCH(1,1)
>> Mean Model    : ARFIMA(5,0,5)
>> Distribution    : norm
>>
>> Optimal Parameters
>> ------------------------------------
>>            Estimate  Std. Error  t value Pr(>|t|)
>> ar1     0.000000          NA       NA       NA
>> ar2     0.000000          NA       NA       NA
>> ar3     0.000000          NA       NA       NA
>> ar4    -0.292207    0.019550 -14.9467  0.0e+00
>> ar5    -0.745887    0.018488 -40.3436  0.0e+00
>> ma1     0.000000          NA       NA       NA
>> ma2     0.000000          NA       NA       NA
>> ma3     0.000000          NA       NA       NA
>> ma4     0.309446    0.026659  11.6073  0.0e+00
>> ma5     0.718856    0.021208  33.8952  0.0e+00
>> omega   0.000006    0.000001   4.2106  2.5e-05
>> alpha1  0.093397    0.011308   8.2591  0.0e+00
>> beta1   0.892404    0.012437  71.7563  0.0e+00
>>
>>
>> Q-Statistics on Standardized Residuals
>> ------------------------------------
>>                             statistic    p-value
>> Lag[1]                 7.898       4.949e-03
>> Lag[p+q+1][11]    21.627     3.312e-06
>> Lag[p+q+5][15]    27.133     5.374e-05
>> d.o.f=10
>> H0 : No serial correlation
>>
>> Q-Statistics on Standardized Squared Residuals
>> ------------------------------------
>>                            statistic  p-value
>> Lag[1]               1.274     0.258961
>> Lag[p+q+1][3]     9.351    0.002229
>> Lag[p+q+5][7]    12.135    0.032980
>> d.o.f=2
>> As you can see in the "Q-Statistics on Standardized Squared Residuals" there is clearly correlation in the standardized squared residuals. BUT if you look at the plot with the plot method and choosing number 11 you can see, that NO spike is significant.
>>
>> This plot is not correct, I controlled it via the Acf plot of the forecast package and clearly, the spikes are larger! So the second spike is now significant. I control the calculations via the Box.test method using d.o.f.=2 and choosing the lag 3 and 7 and the calculations in the rugarch package are correct! So the p-values are indeed 0.002229 and 0.032980. So why is the plot of the rugarch package wrong?
>>
>> One further notice: In a previous mail, I asked, why the lags in the Q-Statistics on Standardized Squared Residuals are different to the lags used in Q-Statistics on Standardized Residuals. Of course, I have now seen, that the second uses the GARCH parameters, so it is clear, that this has to be equal to two (1+1). I also have to say, that I think, that the ACF of observations plot e.g. is indeed correct (number 4), so it seems, that the plot number 11 uses different scaled residuals? Maybe it uses the non-standardized squared residuals? Could that be the reason?
>>
>> Thanks a lot for your notice.
>> My code:
>>
>> library(rugarch)
>> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>> distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>
>> modgarch<-ugarchfit(spec=modsp,data=mydata)
>> plot(modgarch)
>>
>>
>> residuals(mydata,standardize=TRUE)
>> resdi<-as.numeric(residuals(mydata,standardize=TRUE))
>>
>> library(forecast)
>> Acf(resdi^2)
>>
>> Box.test(resdi^2, lag = 3, type = "Ljung-Box", fitdf = 2)
>> Box.test(resdi^2, lag = 7, type = "Ljung-Box", fitdf = 2)
>>
>


From jenbohold at yahoo.de  Wed May 22 14:40:06 2013
From: jenbohold at yahoo.de (Jen Bohold)
Date: Wed, 22 May 2013 13:40:06 +0100 (BST)
Subject: [R-SIG-Finance] Error in rugarch ACF squared standardized
	residuals plot
In-Reply-To: <519CAC46.3060801@4dscape.com>
References: <1369206639.91126.YahooMailNeo@web171401.mail.ir2.yahoo.com>
	<519C9342.2030904@4dscape.com>
	<1369219770.43709.YahooMailNeo@web171401.mail.ir2.yahoo.com>
	<519CAC46.3060801@4dscape.com>
Message-ID: <1369226406.24329.YahooMailNeo@web171402.mail.ir2.yahoo.com>

It is not true, that I sent non-reproducible code/examples. I can give you the complete code again and I attach my data. You just have to run the code and you will see, that indeed both plots do differ. So this is replicatable.



library(rugarch)
myspecification<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)), 
mean.model = list(armaOrder = c(5, 5), include.mean = FALSE), 
distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))

modelgarch<-ugarchfit(spec=myspecification,data=mydata)
plot(modelgarch,which=11)


library(forecast)
resdi<-as.numeric(residuals(modelgarch,standardize=TRUE))^2


Acf(resdi)

You can see, that the plots are NOT the same. I do not know, what is wrong with your code and I do not want to offend you, but there is clearly an error in it.


----- Urspr?ngliche Message -----
Von: alexios ghalanos <alexios at 4dscape.com>
An: Jen Bohold <jenbohold at yahoo.de>
CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
Gesendet: 13:30 Mittwoch, 22.Mai 2013
Betreff: Re: Error in rugarch ACF squared standardized residuals plot

I can't replicate your PNG chart differences and here is an example of 
how you can check:
##########################################
library(rugarch)
# you specification with YOUR estimated parameters:
modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = 
c(1, 1)),
mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,
ar4 = -0.292207, ar5 = -0.745887, ma1=0,ma2=0,ma3=0,
ma4 = 0.309446, ma5 = 0.718856, omega = 6e-6, alpha1=0.093397,
beta1 = 0.892404))
# Simulate a path
sim=ugarchpath(modsp, n.sim=5000)
# extract the simulated data
mydata = as.numeric(fitted(sim))
# restate the specification:
modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = 
c(1, 1)), mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
distribution.model = 
"norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
# estimate the model:
modgarch<-ugarchfit(spec=modsp,data=mydata )
# extract the standardized residuals:
resdi<-as.numeric(residuals(modgarch,standardize=TRUE))

# plot:
library(forecast)
par(mfrow=c(2,2))
Acf(resdi^2)
plot(modgarch, which=11)
###############################################

I don't see ANY differences. You are however welcome to look at the 
underlying code in the rugarch-plots.R file in the source. If you find a 
bug you are welcome to submit a patch to the google code repository of 
the package rather than continuously sending this list PNG attachments 
and non reproducible code/examples.

Regards,

Alexios


On 22/05/2013 11:49, Jen Bohold wrote:
> Dear Alexios,
> thanks a lot for your response!
> Yes, this was a typo, so I meant to write
>
> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>
> and then plot it with
>
>
> Acf(resdi^2)
>
> this gives a DIFFERENT plot! It is NOT the same!
>
> Again, I attach both plots.
>
>
>
> ----- Urspr?ngliche Message -----
> Von: alexios ghalanos <alexios at 4dscape.com>
> An: Jen Bohold <jenbohold at yahoo.de>
> CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
> Gesendet: 11:43 Mittwoch, 22.Mai 2013
> Betreff: Re: Error in rugarch ACF squared standardized residuals plot
>
> Dear Jen,
>
> The reason I have not answered is that you post one question, then
> instead of patiently waiting for an answer, you very shortly post more
> and more followups. As I said in a previous email, the likelihood of
> answering, at least on my part, will depend on the effort shown to at
> least try to do your own research and the framing of the question. You
> also seem to be cross-posting to stackexchange.
>
> With regards to your specific question, you are wrong and this is seen
> by your own code:
>
> resdi<-as.numeric(residuals(mydata,standardize=TRUE))
>
> This is NOT the standardized residuals of the model but the
> observations, so that when you compare to the Acf plot you are comparing
> the observations (before the estimation) to the standardized residuals
> (after the ARMA filtration).
>
> You probably wanted to write:
>
> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>
> The plots of the results from rugarch are the same with what you get
> with the Forecast package (which is actually a wrapper for the stats
> package 'plot.acf').
>
> I'm going to politely ask you to please take some more care when posting
> and making such grand statement as "plot are not useable anymore". You
> are quickly burning through any remaining goodwill left on the part of
> this developer. Finally, I would suggest an excellent reference such as
> Zivot and Wang ("Modeling Financial Time Series with S-PLUS") or Tsay
> ("Analysis of Financial Time Series") which may help you answer some of
> your many questions.
>
> Regards,
>
> Alexios
>
>
>
> On 22/05/2013 08:10, Jen Bohold wrote:
>> Although it seems that there is no feedback and you do not want to comment on me, I thought I should share this to the list, maybe someone else is some time wondering about this (maybe I did a mistake, but no one of the list or you told me in the previous mail). Also, I do not want to offend you, I like your package it's great! Especially I liked the acf plots, they have a better design, although
>> you will see in the following text, that the "ACF of Squared Standadrized Residuals" plot are not useable anymore.
>>
>>
>> The plot of the ACF of the squared standardized residuals in rugarch output (you get it via plot(yourmodel) and choosing number 11) is wrong.
>> However, the corresponding Q-Statistics of the rugarch output are correct!
>>
>> Consider the following (I attached my data and the plots). I fitted the following model (output extracted to the relevant parts):
>>
>> *---------------------------------*
>> *? ? ? ? ? GARCH Model Fit*
>> *---------------------------------*
>>
>> Conditional Variance Dynamics
>> -----------------------------------
>> GARCH Model? ? : sGARCH(1,1)
>> Mean Model? ? : ARFIMA(5,0,5)
>> Distribution? ? : norm
>>
>> Optimal Parameters
>> ------------------------------------
>>? ? ? ? ? ? Estimate? Std. Error? t value Pr(>|t|)
>> ar1? ?  0.000000? ? ? ? ? NA? ? ?  NA? ? ?  NA
>> ar2? ?  0.000000? ? ? ? ? NA? ? ?  NA? ? ?  NA
>> ar3? ?  0.000000? ? ? ? ? NA? ? ?  NA? ? ?  NA
>> ar4? ? -0.292207? ? 0.019550 -14.9467? 0.0e+00
>> ar5? ? -0.745887? ? 0.018488 -40.3436? 0.0e+00
>> ma1? ?  0.000000? ? ? ? ? NA? ? ?  NA? ? ?  NA
>> ma2? ?  0.000000? ? ? ? ? NA? ? ?  NA? ? ?  NA
>> ma3? ?  0.000000? ? ? ? ? NA? ? ?  NA? ? ?  NA
>> ma4? ?  0.309446? ? 0.026659? 11.6073? 0.0e+00
>> ma5? ?  0.718856? ? 0.021208? 33.8952? 0.0e+00
>> omega?  0.000006? ? 0.000001?  4.2106? 2.5e-05
>> alpha1? 0.093397? ? 0.011308?  8.2591? 0.0e+00
>> beta1?  0.892404? ? 0.012437? 71.7563? 0.0e+00
>>
>>
>> Q-Statistics on Standardized Residuals
>> ------------------------------------
>>? ? ? ? ? ? ? ? ? ? ? ? ? ?  statistic? ? p-value
>> Lag[1]? ? ? ? ? ? ? ?  7.898? ? ?  4.949e-03
>> Lag[p+q+1][11]? ? 21.627? ?  3.312e-06
>> Lag[p+q+5][15]? ? 27.133? ?  5.374e-05
>> d.o.f=10
>> H0 : No serial correlation
>>
>> Q-Statistics on Standardized Squared Residuals
>> ------------------------------------
>>? ? ? ? ? ? ? ? ? ? ? ? ? ? statistic? p-value
>> Lag[1]? ? ? ? ? ? ?  1.274? ?  0.258961
>> Lag[p+q+1][3]? ?  9.351? ? 0.002229
>> Lag[p+q+5][7]? ? 12.135? ? 0.032980
>> d.o.f=2
>> As you can see in the "Q-Statistics on Standardized Squared Residuals" there is clearly correlation in the standardized squared residuals. BUT if you look at the plot with the plot method and choosing number 11 you can see, that NO spike is significant.
>>
>> This plot is not correct, I controlled it via the Acf plot of the forecast package and clearly, the spikes are larger! So the second spike is now significant. I control the calculations via the Box.test method using d.o.f.=2 and choosing the lag 3 and 7 and the calculations in the rugarch package are correct! So the p-values are indeed 0.002229 and 0.032980. So why is the plot of the rugarch package wrong?
>>
>> One further notice: In a previous mail, I asked, why the lags in the Q-Statistics on Standardized Squared Residuals are different to the lags used in Q-Statistics on Standardized Residuals. Of course, I have now seen, that the second uses the GARCH parameters, so it is clear, that this has to be equal to two (1+1). I also have to say, that I think, that the ACF of observations plot e.g. is indeed correct (number 4), so it seems, that the plot number 11 uses different scaled residuals? Maybe it uses the non-standardized squared residuals? Could that be the reason?
>>
>> Thanks a lot for your notice.
>> My code:
>>
>> library(rugarch)
>> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>> distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>
>> modgarch<-ugarchfit(spec=modsp,data=mydata)
>> plot(modgarch)
>>
>>
>> residuals(mydata,standardize=TRUE)
>> resdi<-as.numeric(residuals(mydata,standardize=TRUE))
>>
>> library(forecast)
>> Acf(resdi^2)
>>
>> Box.test(resdi^2, lag = 3, type = "Ljung-Box", fitdf = 2)
>> Box.test(resdi^2, lag = 7, type = "Ljung-Box", fitdf = 2)
>>
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mydatagarch.RData
Type: application/octet-stream
Size: 27552 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130522/6a12563e/attachment.obj>

From alexios at 4dscape.com  Wed May 22 15:16:35 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 22 May 2013 14:16:35 +0100
Subject: [R-SIG-Finance] Error in rugarch ACF squared standardized
	residuals plot
In-Reply-To: <1369226406.24329.YahooMailNeo@web171402.mail.ir2.yahoo.com>
References: <1369206639.91126.YahooMailNeo@web171401.mail.ir2.yahoo.com>
	<519C9342.2030904@4dscape.com>
	<1369219770.43709.YahooMailNeo@web171401.mail.ir2.yahoo.com>
	<519CAC46.3060801@4dscape.com>
	<1369226406.24329.YahooMailNeo@web171402.mail.ir2.yahoo.com>
Message-ID: <519CC533.8080704@4dscape.com>

I've traced the difference to the way the residuals method deals with 
the startup values (5 lags) versus the plot which extracts directly the 
standardized residuals used in the likelihood routine.

This gives the same answer:

par(mfrow=c(2,2))
plot(modelgarch,which=11)
resdi<-as.numeric(residuals(modelgarch,standardize=TRUE))^2
Acf(resdi[-c(1:5)])

In most cases this is not likely be significantly different. It is 
related to a problem of how to initialize the ARMA recursion and what to 
return to the user. In THIS case, the first 5 values had an effect which 
changed the visual result marginally. For consistency I guess that the 
plot should return the result one would expect by using the residuals 
method on the model.

Feel free to submit a patch.

Regards,
Alexios

On 22/05/2013 13:40, Jen Bohold wrote:
> It is not true, that I sent non-reproducible code/examples. I can give you the complete code again and I attach my data. You just have to run the code and you will see, that indeed both plots do differ. So this is replicatable.
>
>
>
> library(rugarch)
> myspecification<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
> distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>
> modelgarch<-ugarchfit(spec=myspecification,data=mydata)
> plot(modelgarch,which=11)
>
>
> library(forecast)
> resdi<-as.numeric(residuals(modelgarch,standardize=TRUE))^2
>
>
> Acf(resdi)
>
> You can see, that the plots are NOT the same. I do not know, what is wrong with your code and I do not want to offend you, but there is clearly an error in it.
>
>
> ----- Urspr?ngliche Message -----
> Von: alexios ghalanos <alexios at 4dscape.com>
> An: Jen Bohold <jenbohold at yahoo.de>
> CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
> Gesendet: 13:30 Mittwoch, 22.Mai 2013
> Betreff: Re: Error in rugarch ACF squared standardized residuals plot
>
> I can't replicate your PNG chart differences and here is an example of
> how you can check:
> ##########################################
> library(rugarch)
> # you specification with YOUR estimated parameters:
> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
> c(1, 1)),
> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
> distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,
> ar4 = -0.292207, ar5 = -0.745887, ma1=0,ma2=0,ma3=0,
> ma4 = 0.309446, ma5 = 0.718856, omega = 6e-6, alpha1=0.093397,
> beta1 = 0.892404))
> # Simulate a path
> sim=ugarchpath(modsp, n.sim=5000)
> # extract the simulated data
> mydata = as.numeric(fitted(sim))
> # restate the specification:
> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
> c(1, 1)), mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
> distribution.model =
> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
> # estimate the model:
> modgarch<-ugarchfit(spec=modsp,data=mydata )
> # extract the standardized residuals:
> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>
> # plot:
> library(forecast)
> par(mfrow=c(2,2))
> Acf(resdi^2)
> plot(modgarch, which=11)
> ###############################################
>
> I don't see ANY differences. You are however welcome to look at the
> underlying code in the rugarch-plots.R file in the source. If you find a
> bug you are welcome to submit a patch to the google code repository of
> the package rather than continuously sending this list PNG attachments
> and non reproducible code/examples.
>
> Regards,
>
> Alexios
>
>
> On 22/05/2013 11:49, Jen Bohold wrote:
>> Dear Alexios,
>> thanks a lot for your response!
>> Yes, this was a typo, so I meant to write
>>
>> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>>
>> and then plot it with
>>
>>
>> Acf(resdi^2)
>>
>> this gives a DIFFERENT plot! It is NOT the same!
>>
>> Again, I attach both plots.
>>
>>
>>
>> ----- Urspr?ngliche Message -----
>> Von: alexios ghalanos <alexios at 4dscape.com>
>> An: Jen Bohold <jenbohold at yahoo.de>
>> CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
>> Gesendet: 11:43 Mittwoch, 22.Mai 2013
>> Betreff: Re: Error in rugarch ACF squared standardized residuals plot
>>
>> Dear Jen,
>>
>> The reason I have not answered is that you post one question, then
>> instead of patiently waiting for an answer, you very shortly post more
>> and more followups. As I said in a previous email, the likelihood of
>> answering, at least on my part, will depend on the effort shown to at
>> least try to do your own research and the framing of the question. You
>> also seem to be cross-posting to stackexchange.
>>
>> With regards to your specific question, you are wrong and this is seen
>> by your own code:
>>
>> resdi<-as.numeric(residuals(mydata,standardize=TRUE))
>>
>> This is NOT the standardized residuals of the model but the
>> observations, so that when you compare to the Acf plot you are comparing
>> the observations (before the estimation) to the standardized residuals
>> (after the ARMA filtration).
>>
>> You probably wanted to write:
>>
>> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>>
>> The plots of the results from rugarch are the same with what you get
>> with the Forecast package (which is actually a wrapper for the stats
>> package 'plot.acf').
>>
>> I'm going to politely ask you to please take some more care when posting
>> and making such grand statement as "plot are not useable anymore". You
>> are quickly burning through any remaining goodwill left on the part of
>> this developer. Finally, I would suggest an excellent reference such as
>> Zivot and Wang ("Modeling Financial Time Series with S-PLUS") or Tsay
>> ("Analysis of Financial Time Series") which may help you answer some of
>> your many questions.
>>
>> Regards,
>>
>> Alexios
>>
>>
>>
>> On 22/05/2013 08:10, Jen Bohold wrote:
>>> Although it seems that there is no feedback and you do not want to comment on me, I thought I should share this to the list, maybe someone else is some time wondering about this (maybe I did a mistake, but no one of the list or you told me in the previous mail). Also, I do not want to offend you, I like your package it's great! Especially I liked the acf plots, they have a better design, although
>>> you will see in the following text, that the "ACF of Squared Standadrized Residuals" plot are not useable anymore.
>>>
>>>
>>> The plot of the ACF of the squared standardized residuals in rugarch output (you get it via plot(yourmodel) and choosing number 11) is wrong.
>>> However, the corresponding Q-Statistics of the rugarch output are correct!
>>>
>>> Consider the following (I attached my data and the plots). I fitted the following model (output extracted to the relevant parts):
>>>
>>> *---------------------------------*
>>> *          GARCH Model Fit*
>>> *---------------------------------*
>>>
>>> Conditional Variance Dynamics
>>> -----------------------------------
>>> GARCH Model    : sGARCH(1,1)
>>> Mean Model    : ARFIMA(5,0,5)
>>> Distribution    : norm
>>>
>>> Optimal Parameters
>>> ------------------------------------
>>>              Estimate  Std. Error  t value Pr(>|t|)
>>> ar1     0.000000          NA       NA       NA
>>> ar2     0.000000          NA       NA       NA
>>> ar3     0.000000          NA       NA       NA
>>> ar4    -0.292207    0.019550 -14.9467  0.0e+00
>>> ar5    -0.745887    0.018488 -40.3436  0.0e+00
>>> ma1     0.000000          NA       NA       NA
>>> ma2     0.000000          NA       NA       NA
>>> ma3     0.000000          NA       NA       NA
>>> ma4     0.309446    0.026659  11.6073  0.0e+00
>>> ma5     0.718856    0.021208  33.8952  0.0e+00
>>> omega   0.000006    0.000001   4.2106  2.5e-05
>>> alpha1  0.093397    0.011308   8.2591  0.0e+00
>>> beta1   0.892404    0.012437  71.7563  0.0e+00
>>>
>>>
>>> Q-Statistics on Standardized Residuals
>>> ------------------------------------
>>>                               statistic    p-value
>>> Lag[1]                 7.898       4.949e-03
>>> Lag[p+q+1][11]    21.627     3.312e-06
>>> Lag[p+q+5][15]    27.133     5.374e-05
>>> d.o.f=10
>>> H0 : No serial correlation
>>>
>>> Q-Statistics on Standardized Squared Residuals
>>> ------------------------------------
>>>                              statistic  p-value
>>> Lag[1]               1.274     0.258961
>>> Lag[p+q+1][3]     9.351    0.002229
>>> Lag[p+q+5][7]    12.135    0.032980
>>> d.o.f=2
>>> As you can see in the "Q-Statistics on Standardized Squared Residuals" there is clearly correlation in the standardized squared residuals. BUT if you look at the plot with the plot method and choosing number 11 you can see, that NO spike is significant.
>>>
>>> This plot is not correct, I controlled it via the Acf plot of the forecast package and clearly, the spikes are larger! So the second spike is now significant. I control the calculations via the Box.test method using d.o.f.=2 and choosing the lag 3 and 7 and the calculations in the rugarch package are correct! So the p-values are indeed 0.002229 and 0.032980. So why is the plot of the rugarch package wrong?
>>>
>>> One further notice: In a previous mail, I asked, why the lags in the Q-Statistics on Standardized Squared Residuals are different to the lags used in Q-Statistics on Standardized Residuals. Of course, I have now seen, that the second uses the GARCH parameters, so it is clear, that this has to be equal to two (1+1). I also have to say, that I think, that the ACF of observations plot e.g. is indeed correct (number 4), so it seems, that the plot number 11 uses different scaled residuals? Maybe it uses the non-standardized squared residuals? Could that be the reason?
>>>
>>> Thanks a lot for your notice.
>>> My code:
>>>
>>> library(rugarch)
>>> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>> distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>>
>>> modgarch<-ugarchfit(spec=modsp,data=mydata)
>>> plot(modgarch)
>>>
>>>
>>> residuals(mydata,standardize=TRUE)
>>> resdi<-as.numeric(residuals(mydata,standardize=TRUE))
>>>
>>> library(forecast)
>>> Acf(resdi^2)
>>>
>>> Box.test(resdi^2, lag = 3, type = "Ljung-Box", fitdf = 2)
>>> Box.test(resdi^2, lag = 7, type = "Ljung-Box", fitdf = 2)
>>>
>>
>


From peterallington03 at gmail.com  Wed May 22 15:58:32 2013
From: peterallington03 at gmail.com (Peter Allington)
Date: Wed, 22 May 2013 15:58:32 +0200
Subject: [R-SIG-Finance] Error in rugarch ACF squared standardized
 residuals plot
In-Reply-To: <519CC533.8080704@4dscape.com>
References: <1369206639.91126.YahooMailNeo@web171401.mail.ir2.yahoo.com>
	<519C9342.2030904@4dscape.com>
	<1369219770.43709.YahooMailNeo@web171401.mail.ir2.yahoo.com>
	<519CAC46.3060801@4dscape.com>
	<1369226406.24329.YahooMailNeo@web171402.mail.ir2.yahoo.com>
	<519CC533.8080704@4dscape.com>
Message-ID: <CAJjpXgz8wgio9FW6CaF3PrfVGsb29dm3JnJbOcE6rAzWfx24Qw@mail.gmail.com>

Thanks a lot for not giving me up!

I have one last question:
I wondered about, because in my example the Q-Statistics was really
"strong". So the p-values for the lag 3 and 7 were really small
(0.002229 and 0.032980). So this indicates, that there is jointly
autocorrelation, but the plot showes, that there is just one spike
which is slightly significant. Why does this has such a strong impact
on the Q-Statistics? The spike is slightly different (it crosses the
dashed line) and the p-value of the Q-Statistics is already so small?
Why? The other spikes of lag 4 and 5 and so one are not significant?
Why is the p-value of the joint test so small? I would have expect
that there are lots of significant spikes?

Thanks a lot for your wisdom!

2013/5/22 alexios ghalanos <alexios at 4dscape.com>:
> I've traced the difference to the way the residuals method deals with the
> startup values (5 lags) versus the plot which extracts directly the
> standardized residuals used in the likelihood routine.
>
> This gives the same answer:
>
> par(mfrow=c(2,2))
> plot(modelgarch,which=11)
> resdi<-as.numeric(residuals(modelgarch,standardize=TRUE))^2
> Acf(resdi[-c(1:5)])
>
> In most cases this is not likely be significantly different. It is related
> to a problem of how to initialize the ARMA recursion and what to return to
> the user. In THIS case, the first 5 values had an effect which changed the
> visual result marginally. For consistency I guess that the plot should
> return the result one would expect by using the residuals method on the
> model.
>
> Feel free to submit a patch.
>
> Regards,
> Alexios
>
>
> On 22/05/2013 13:40, Jen Bohold wrote:
>>
>> It is not true, that I sent non-reproducible code/examples. I can give you
>> the complete code again and I attach my data. You just have to run the code
>> and you will see, that indeed both plots do differ. So this is replicatable.
>>
>>
>>
>> library(rugarch)
>> myspecification<-ugarchspec(variance.model = list(model = "sGARCH",
>> garchOrder = c(1, 1)),
>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>> distribution.model =
>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>
>> modelgarch<-ugarchfit(spec=myspecification,data=mydata)
>> plot(modelgarch,which=11)
>>
>>
>> library(forecast)
>> resdi<-as.numeric(residuals(modelgarch,standardize=TRUE))^2
>>
>>
>> Acf(resdi)
>>
>> You can see, that the plots are NOT the same. I do not know, what is wrong
>> with your code and I do not want to offend you, but there is clearly an
>> error in it.
>>
>>
>> ----- Urspr?ngliche Message -----
>> Von: alexios ghalanos <alexios at 4dscape.com>
>> An: Jen Bohold <jenbohold at yahoo.de>
>> CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
>> Gesendet: 13:30 Mittwoch, 22.Mai 2013
>> Betreff: Re: Error in rugarch ACF squared standardized residuals plot
>>
>> I can't replicate your PNG chart differences and here is an example of
>> how you can check:
>> ##########################################
>> library(rugarch)
>> # you specification with YOUR estimated parameters:
>> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>> c(1, 1)),
>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>> distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,
>> ar4 = -0.292207, ar5 = -0.745887, ma1=0,ma2=0,ma3=0,
>> ma4 = 0.309446, ma5 = 0.718856, omega = 6e-6, alpha1=0.093397,
>> beta1 = 0.892404))
>> # Simulate a path
>> sim=ugarchpath(modsp, n.sim=5000)
>> # extract the simulated data
>> mydata = as.numeric(fitted(sim))
>> # restate the specification:
>> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>> c(1, 1)), mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>> distribution.model =
>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>> # estimate the model:
>> modgarch<-ugarchfit(spec=modsp,data=mydata )
>> # extract the standardized residuals:
>> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>>
>> # plot:
>> library(forecast)
>> par(mfrow=c(2,2))
>> Acf(resdi^2)
>> plot(modgarch, which=11)
>> ###############################################
>>
>> I don't see ANY differences. You are however welcome to look at the
>> underlying code in the rugarch-plots.R file in the source. If you find a
>> bug you are welcome to submit a patch to the google code repository of
>> the package rather than continuously sending this list PNG attachments
>> and non reproducible code/examples.
>>
>> Regards,
>>
>> Alexios
>>
>>
>> On 22/05/2013 11:49, Jen Bohold wrote:
>>>
>>> Dear Alexios,
>>> thanks a lot for your response!
>>> Yes, this was a typo, so I meant to write
>>>
>>> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>>>
>>> and then plot it with
>>>
>>>
>>> Acf(resdi^2)
>>>
>>> this gives a DIFFERENT plot! It is NOT the same!
>>>
>>> Again, I attach both plots.
>>>
>>>
>>>
>>> ----- Urspr?ngliche Message -----
>>> Von: alexios ghalanos <alexios at 4dscape.com>
>>> An: Jen Bohold <jenbohold at yahoo.de>
>>> CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
>>> Gesendet: 11:43 Mittwoch, 22.Mai 2013
>>> Betreff: Re: Error in rugarch ACF squared standardized residuals plot
>>>
>>> Dear Jen,
>>>
>>> The reason I have not answered is that you post one question, then
>>> instead of patiently waiting for an answer, you very shortly post more
>>> and more followups. As I said in a previous email, the likelihood of
>>> answering, at least on my part, will depend on the effort shown to at
>>> least try to do your own research and the framing of the question. You
>>> also seem to be cross-posting to stackexchange.
>>>
>>> With regards to your specific question, you are wrong and this is seen
>>> by your own code:
>>>
>>> resdi<-as.numeric(residuals(mydata,standardize=TRUE))
>>>
>>> This is NOT the standardized residuals of the model but the
>>> observations, so that when you compare to the Acf plot you are comparing
>>> the observations (before the estimation) to the standardized residuals
>>> (after the ARMA filtration).
>>>
>>> You probably wanted to write:
>>>
>>> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>>>
>>> The plots of the results from rugarch are the same with what you get
>>> with the Forecast package (which is actually a wrapper for the stats
>>> package 'plot.acf').
>>>
>>> I'm going to politely ask you to please take some more care when posting
>>> and making such grand statement as "plot are not useable anymore". You
>>> are quickly burning through any remaining goodwill left on the part of
>>> this developer. Finally, I would suggest an excellent reference such as
>>> Zivot and Wang ("Modeling Financial Time Series with S-PLUS") or Tsay
>>> ("Analysis of Financial Time Series") which may help you answer some of
>>> your many questions.
>>>
>>> Regards,
>>>
>>> Alexios
>>>
>>>
>>>
>>> On 22/05/2013 08:10, Jen Bohold wrote:
>>>>
>>>> Although it seems that there is no feedback and you do not want to
>>>> comment on me, I thought I should share this to the list, maybe someone else
>>>> is some time wondering about this (maybe I did a mistake, but no one of the
>>>> list or you told me in the previous mail). Also, I do not want to offend
>>>> you, I like your package it's great! Especially I liked the acf plots, they
>>>> have a better design, although
>>>> you will see in the following text, that the "ACF of Squared
>>>> Standadrized Residuals" plot are not useable anymore.
>>>>
>>>>
>>>> The plot of the ACF of the squared standardized residuals in rugarch
>>>> output (you get it via plot(yourmodel) and choosing number 11) is wrong.
>>>> However, the corresponding Q-Statistics of the rugarch output are
>>>> correct!
>>>>
>>>> Consider the following (I attached my data and the plots). I fitted the
>>>> following model (output extracted to the relevant parts):
>>>>
>>>> *---------------------------------*
>>>> *          GARCH Model Fit*
>>>> *---------------------------------*
>>>>
>>>> Conditional Variance Dynamics
>>>> -----------------------------------
>>>> GARCH Model    : sGARCH(1,1)
>>>> Mean Model    : ARFIMA(5,0,5)
>>>> Distribution    : norm
>>>>
>>>> Optimal Parameters
>>>> ------------------------------------
>>>>              Estimate  Std. Error  t value Pr(>|t|)
>>>> ar1     0.000000          NA       NA       NA
>>>> ar2     0.000000          NA       NA       NA
>>>> ar3     0.000000          NA       NA       NA
>>>> ar4    -0.292207    0.019550 -14.9467  0.0e+00
>>>> ar5    -0.745887    0.018488 -40.3436  0.0e+00
>>>> ma1     0.000000          NA       NA       NA
>>>> ma2     0.000000          NA       NA       NA
>>>> ma3     0.000000          NA       NA       NA
>>>> ma4     0.309446    0.026659  11.6073  0.0e+00
>>>> ma5     0.718856    0.021208  33.8952  0.0e+00
>>>> omega   0.000006    0.000001   4.2106  2.5e-05
>>>> alpha1  0.093397    0.011308   8.2591  0.0e+00
>>>> beta1   0.892404    0.012437  71.7563  0.0e+00
>>>>
>>>>
>>>> Q-Statistics on Standardized Residuals
>>>> ------------------------------------
>>>>                               statistic    p-value
>>>> Lag[1]                 7.898       4.949e-03
>>>> Lag[p+q+1][11]    21.627     3.312e-06
>>>> Lag[p+q+5][15]    27.133     5.374e-05
>>>> d.o.f=10
>>>> H0 : No serial correlation
>>>>
>>>> Q-Statistics on Standardized Squared Residuals
>>>> ------------------------------------
>>>>                              statistic  p-value
>>>> Lag[1]               1.274     0.258961
>>>> Lag[p+q+1][3]     9.351    0.002229
>>>> Lag[p+q+5][7]    12.135    0.032980
>>>> d.o.f=2
>>>> As you can see in the "Q-Statistics on Standardized Squared Residuals"
>>>> there is clearly correlation in the standardized squared residuals. BUT if
>>>> you look at the plot with the plot method and choosing number 11 you can
>>>> see, that NO spike is significant.
>>>>
>>>> This plot is not correct, I controlled it via the Acf plot of the
>>>> forecast package and clearly, the spikes are larger! So the second spike is
>>>> now significant. I control the calculations via the Box.test method using
>>>> d.o.f.=2 and choosing the lag 3 and 7 and the calculations in the rugarch
>>>> package are correct! So the p-values are indeed 0.002229 and 0.032980. So
>>>> why is the plot of the rugarch package wrong?
>>>>
>>>> One further notice: In a previous mail, I asked, why the lags in the
>>>> Q-Statistics on Standardized Squared Residuals are different to the lags
>>>> used in Q-Statistics on Standardized Residuals. Of course, I have now seen,
>>>> that the second uses the GARCH parameters, so it is clear, that this has to
>>>> be equal to two (1+1). I also have to say, that I think, that the ACF of
>>>> observations plot e.g. is indeed correct (number 4), so it seems, that the
>>>> plot number 11 uses different scaled residuals? Maybe it uses the
>>>> non-standardized squared residuals? Could that be the reason?
>>>>
>>>> Thanks a lot for your notice.
>>>> My code:
>>>>
>>>> library(rugarch)
>>>> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>>>> c(1, 1)),
>>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>>> distribution.model =
>>>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>>>
>>>> modgarch<-ugarchfit(spec=modsp,data=mydata)
>>>> plot(modgarch)
>>>>
>>>>
>>>> residuals(mydata,standardize=TRUE)
>>>> resdi<-as.numeric(residuals(mydata,standardize=TRUE))
>>>>
>>>> library(forecast)
>>>> Acf(resdi^2)
>>>>
>>>> Box.test(resdi^2, lag = 3, type = "Ljung-Box", fitdf = 2)
>>>> Box.test(resdi^2, lag = 7, type = "Ljung-Box", fitdf = 2)
>>>>
>>>
>>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.



-- 
Peter Allington, M. Sc. CF&RM University of Washington


From peterallington03 at gmail.com  Wed May 22 15:59:23 2013
From: peterallington03 at gmail.com (Peter Allington)
Date: Wed, 22 May 2013 15:59:23 +0200
Subject: [R-SIG-Finance] Error in rugarch ACF squared standardized
 residuals plot
In-Reply-To: <CAJjpXgz8wgio9FW6CaF3PrfVGsb29dm3JnJbOcE6rAzWfx24Qw@mail.gmail.com>
References: <1369206639.91126.YahooMailNeo@web171401.mail.ir2.yahoo.com>
	<519C9342.2030904@4dscape.com>
	<1369219770.43709.YahooMailNeo@web171401.mail.ir2.yahoo.com>
	<519CAC46.3060801@4dscape.com>
	<1369226406.24329.YahooMailNeo@web171402.mail.ir2.yahoo.com>
	<519CC533.8080704@4dscape.com>
	<CAJjpXgz8wgio9FW6CaF3PrfVGsb29dm3JnJbOcE6rAzWfx24Qw@mail.gmail.com>
Message-ID: <CAJjpXgyZEqHP_fk3BMPYXx4dVMTWQOLfsGmV1trk1KixQgv+yg@mail.gmail.com>

do not get confused: I answered with my friends account.

2013/5/22 Peter Allington <peterallington03 at gmail.com>:
> Thanks a lot for not giving me up!
>
> I have one last question:
> I wondered about, because in my example the Q-Statistics was really
> "strong". So the p-values for the lag 3 and 7 were really small
> (0.002229 and 0.032980). So this indicates, that there is jointly
> autocorrelation, but the plot showes, that there is just one spike
> which is slightly significant. Why does this has such a strong impact
> on the Q-Statistics? The spike is slightly different (it crosses the
> dashed line) and the p-value of the Q-Statistics is already so small?
> Why? The other spikes of lag 4 and 5 and so one are not significant?
> Why is the p-value of the joint test so small? I would have expect
> that there are lots of significant spikes?
>
> Thanks a lot for your wisdom!
>
> 2013/5/22 alexios ghalanos <alexios at 4dscape.com>:
>> I've traced the difference to the way the residuals method deals with the
>> startup values (5 lags) versus the plot which extracts directly the
>> standardized residuals used in the likelihood routine.
>>
>> This gives the same answer:
>>
>> par(mfrow=c(2,2))
>> plot(modelgarch,which=11)
>> resdi<-as.numeric(residuals(modelgarch,standardize=TRUE))^2
>> Acf(resdi[-c(1:5)])
>>
>> In most cases this is not likely be significantly different. It is related
>> to a problem of how to initialize the ARMA recursion and what to return to
>> the user. In THIS case, the first 5 values had an effect which changed the
>> visual result marginally. For consistency I guess that the plot should
>> return the result one would expect by using the residuals method on the
>> model.
>>
>> Feel free to submit a patch.
>>
>> Regards,
>> Alexios
>>
>>
>> On 22/05/2013 13:40, Jen Bohold wrote:
>>>
>>> It is not true, that I sent non-reproducible code/examples. I can give you
>>> the complete code again and I attach my data. You just have to run the code
>>> and you will see, that indeed both plots do differ. So this is replicatable.
>>>
>>>
>>>
>>> library(rugarch)
>>> myspecification<-ugarchspec(variance.model = list(model = "sGARCH",
>>> garchOrder = c(1, 1)),
>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>> distribution.model =
>>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>>
>>> modelgarch<-ugarchfit(spec=myspecification,data=mydata)
>>> plot(modelgarch,which=11)
>>>
>>>
>>> library(forecast)
>>> resdi<-as.numeric(residuals(modelgarch,standardize=TRUE))^2
>>>
>>>
>>> Acf(resdi)
>>>
>>> You can see, that the plots are NOT the same. I do not know, what is wrong
>>> with your code and I do not want to offend you, but there is clearly an
>>> error in it.
>>>
>>>
>>> ----- Urspr?ngliche Message -----
>>> Von: alexios ghalanos <alexios at 4dscape.com>
>>> An: Jen Bohold <jenbohold at yahoo.de>
>>> CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
>>> Gesendet: 13:30 Mittwoch, 22.Mai 2013
>>> Betreff: Re: Error in rugarch ACF squared standardized residuals plot
>>>
>>> I can't replicate your PNG chart differences and here is an example of
>>> how you can check:
>>> ##########################################
>>> library(rugarch)
>>> # you specification with YOUR estimated parameters:
>>> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>>> c(1, 1)),
>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>> distribution.model = "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,
>>> ar4 = -0.292207, ar5 = -0.745887, ma1=0,ma2=0,ma3=0,
>>> ma4 = 0.309446, ma5 = 0.718856, omega = 6e-6, alpha1=0.093397,
>>> beta1 = 0.892404))
>>> # Simulate a path
>>> sim=ugarchpath(modsp, n.sim=5000)
>>> # extract the simulated data
>>> mydata = as.numeric(fitted(sim))
>>> # restate the specification:
>>> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>>> c(1, 1)), mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>> distribution.model =
>>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>> # estimate the model:
>>> modgarch<-ugarchfit(spec=modsp,data=mydata )
>>> # extract the standardized residuals:
>>> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>>>
>>> # plot:
>>> library(forecast)
>>> par(mfrow=c(2,2))
>>> Acf(resdi^2)
>>> plot(modgarch, which=11)
>>> ###############################################
>>>
>>> I don't see ANY differences. You are however welcome to look at the
>>> underlying code in the rugarch-plots.R file in the source. If you find a
>>> bug you are welcome to submit a patch to the google code repository of
>>> the package rather than continuously sending this list PNG attachments
>>> and non reproducible code/examples.
>>>
>>> Regards,
>>>
>>> Alexios
>>>
>>>
>>> On 22/05/2013 11:49, Jen Bohold wrote:
>>>>
>>>> Dear Alexios,
>>>> thanks a lot for your response!
>>>> Yes, this was a typo, so I meant to write
>>>>
>>>> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>>>>
>>>> and then plot it with
>>>>
>>>>
>>>> Acf(resdi^2)
>>>>
>>>> this gives a DIFFERENT plot! It is NOT the same!
>>>>
>>>> Again, I attach both plots.
>>>>
>>>>
>>>>
>>>> ----- Urspr?ngliche Message -----
>>>> Von: alexios ghalanos <alexios at 4dscape.com>
>>>> An: Jen Bohold <jenbohold at yahoo.de>
>>>> CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
>>>> Gesendet: 11:43 Mittwoch, 22.Mai 2013
>>>> Betreff: Re: Error in rugarch ACF squared standardized residuals plot
>>>>
>>>> Dear Jen,
>>>>
>>>> The reason I have not answered is that you post one question, then
>>>> instead of patiently waiting for an answer, you very shortly post more
>>>> and more followups. As I said in a previous email, the likelihood of
>>>> answering, at least on my part, will depend on the effort shown to at
>>>> least try to do your own research and the framing of the question. You
>>>> also seem to be cross-posting to stackexchange.
>>>>
>>>> With regards to your specific question, you are wrong and this is seen
>>>> by your own code:
>>>>
>>>> resdi<-as.numeric(residuals(mydata,standardize=TRUE))
>>>>
>>>> This is NOT the standardized residuals of the model but the
>>>> observations, so that when you compare to the Acf plot you are comparing
>>>> the observations (before the estimation) to the standardized residuals
>>>> (after the ARMA filtration).
>>>>
>>>> You probably wanted to write:
>>>>
>>>> resdi<-as.numeric(residuals(modgarch,standardize=TRUE))
>>>>
>>>> The plots of the results from rugarch are the same with what you get
>>>> with the Forecast package (which is actually a wrapper for the stats
>>>> package 'plot.acf').
>>>>
>>>> I'm going to politely ask you to please take some more care when posting
>>>> and making such grand statement as "plot are not useable anymore". You
>>>> are quickly burning through any remaining goodwill left on the part of
>>>> this developer. Finally, I would suggest an excellent reference such as
>>>> Zivot and Wang ("Modeling Financial Time Series with S-PLUS") or Tsay
>>>> ("Analysis of Financial Time Series") which may help you answer some of
>>>> your many questions.
>>>>
>>>> Regards,
>>>>
>>>> Alexios
>>>>
>>>>
>>>>
>>>> On 22/05/2013 08:10, Jen Bohold wrote:
>>>>>
>>>>> Although it seems that there is no feedback and you do not want to
>>>>> comment on me, I thought I should share this to the list, maybe someone else
>>>>> is some time wondering about this (maybe I did a mistake, but no one of the
>>>>> list or you told me in the previous mail). Also, I do not want to offend
>>>>> you, I like your package it's great! Especially I liked the acf plots, they
>>>>> have a better design, although
>>>>> you will see in the following text, that the "ACF of Squared
>>>>> Standadrized Residuals" plot are not useable anymore.
>>>>>
>>>>>
>>>>> The plot of the ACF of the squared standardized residuals in rugarch
>>>>> output (you get it via plot(yourmodel) and choosing number 11) is wrong.
>>>>> However, the corresponding Q-Statistics of the rugarch output are
>>>>> correct!
>>>>>
>>>>> Consider the following (I attached my data and the plots). I fitted the
>>>>> following model (output extracted to the relevant parts):
>>>>>
>>>>> *---------------------------------*
>>>>> *          GARCH Model Fit*
>>>>> *---------------------------------*
>>>>>
>>>>> Conditional Variance Dynamics
>>>>> -----------------------------------
>>>>> GARCH Model    : sGARCH(1,1)
>>>>> Mean Model    : ARFIMA(5,0,5)
>>>>> Distribution    : norm
>>>>>
>>>>> Optimal Parameters
>>>>> ------------------------------------
>>>>>              Estimate  Std. Error  t value Pr(>|t|)
>>>>> ar1     0.000000          NA       NA       NA
>>>>> ar2     0.000000          NA       NA       NA
>>>>> ar3     0.000000          NA       NA       NA
>>>>> ar4    -0.292207    0.019550 -14.9467  0.0e+00
>>>>> ar5    -0.745887    0.018488 -40.3436  0.0e+00
>>>>> ma1     0.000000          NA       NA       NA
>>>>> ma2     0.000000          NA       NA       NA
>>>>> ma3     0.000000          NA       NA       NA
>>>>> ma4     0.309446    0.026659  11.6073  0.0e+00
>>>>> ma5     0.718856    0.021208  33.8952  0.0e+00
>>>>> omega   0.000006    0.000001   4.2106  2.5e-05
>>>>> alpha1  0.093397    0.011308   8.2591  0.0e+00
>>>>> beta1   0.892404    0.012437  71.7563  0.0e+00
>>>>>
>>>>>
>>>>> Q-Statistics on Standardized Residuals
>>>>> ------------------------------------
>>>>>                               statistic    p-value
>>>>> Lag[1]                 7.898       4.949e-03
>>>>> Lag[p+q+1][11]    21.627     3.312e-06
>>>>> Lag[p+q+5][15]    27.133     5.374e-05
>>>>> d.o.f=10
>>>>> H0 : No serial correlation
>>>>>
>>>>> Q-Statistics on Standardized Squared Residuals
>>>>> ------------------------------------
>>>>>                              statistic  p-value
>>>>> Lag[1]               1.274     0.258961
>>>>> Lag[p+q+1][3]     9.351    0.002229
>>>>> Lag[p+q+5][7]    12.135    0.032980
>>>>> d.o.f=2
>>>>> As you can see in the "Q-Statistics on Standardized Squared Residuals"
>>>>> there is clearly correlation in the standardized squared residuals. BUT if
>>>>> you look at the plot with the plot method and choosing number 11 you can
>>>>> see, that NO spike is significant.
>>>>>
>>>>> This plot is not correct, I controlled it via the Acf plot of the
>>>>> forecast package and clearly, the spikes are larger! So the second spike is
>>>>> now significant. I control the calculations via the Box.test method using
>>>>> d.o.f.=2 and choosing the lag 3 and 7 and the calculations in the rugarch
>>>>> package are correct! So the p-values are indeed 0.002229 and 0.032980. So
>>>>> why is the plot of the rugarch package wrong?
>>>>>
>>>>> One further notice: In a previous mail, I asked, why the lags in the
>>>>> Q-Statistics on Standardized Squared Residuals are different to the lags
>>>>> used in Q-Statistics on Standardized Residuals. Of course, I have now seen,
>>>>> that the second uses the GARCH parameters, so it is clear, that this has to
>>>>> be equal to two (1+1). I also have to say, that I think, that the ACF of
>>>>> observations plot e.g. is indeed correct (number 4), so it seems, that the
>>>>> plot number 11 uses different scaled residuals? Maybe it uses the
>>>>> non-standardized squared residuals? Could that be the reason?
>>>>>
>>>>> Thanks a lot for your notice.
>>>>> My code:
>>>>>
>>>>> library(rugarch)
>>>>> modsp<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>>>>> c(1, 1)),
>>>>> mean.model = list(armaOrder = c(5, 5), include.mean = FALSE),
>>>>> distribution.model =
>>>>> "norm",fixed.pars=list(ar1=0,ar2=0,ar3=0,ma1=0,ma2=0,ma3=0))
>>>>>
>>>>> modgarch<-ugarchfit(spec=modsp,data=mydata)
>>>>> plot(modgarch)
>>>>>
>>>>>
>>>>> residuals(mydata,standardize=TRUE)
>>>>> resdi<-as.numeric(residuals(mydata,standardize=TRUE))
>>>>>
>>>>> library(forecast)
>>>>> Acf(resdi^2)
>>>>>
>>>>> Box.test(resdi^2, lag = 3, type = "Ljung-Box", fitdf = 2)
>>>>> Box.test(resdi^2, lag = 7, type = "Ljung-Box", fitdf = 2)
>>>>>
>>>>
>>>
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>
>
> --
> Peter Allington, M. Sc. CF&RM University of Washington



-- 
Peter Allington, M. Sc. CF&RM University of Washington


From edd at debian.org  Thu May 23 17:21:31 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 23 May 2013 10:21:31 -0500
Subject: [R-SIG-Finance] List behavour on R-SIG-Finance
In-Reply-To: <CAJjpXgyZEqHP_fk3BMPYXx4dVMTWQOLfsGmV1trk1KixQgv+yg@mail.gmail.com>
References: <1369206639.91126.YahooMailNeo@web171401.mail.ir2.yahoo.com>
	<519C9342.2030904@4dscape.com>
	<1369219770.43709.YahooMailNeo@web171401.mail.ir2.yahoo.com>
	<519CAC46.3060801@4dscape.com>
	<1369226406.24329.YahooMailNeo@web171402.mail.ir2.yahoo.com>
	<519CC533.8080704@4dscape.com>
	<CAJjpXgz8wgio9FW6CaF3PrfVGsb29dm3JnJbOcE6rAzWfx24Qw@mail.gmail.com>
	<CAJjpXgyZEqHP_fk3BMPYXx4dVMTWQOLfsGmV1trk1KixQgv+yg@mail.gmail.com>
Message-ID: <20894.13307.347446.198647@max.nulle.part>


On 22 May 2013 at 15:59, Peter Allington wrote:
| do not get confused: I answered with my friends account.

That is not tolerated here. We, just like the main R lists, strongly prefer that you

     a) post under your real name and 
     b) preferably use a signature block providing additional identification.

Moreover, I happened to have been informed today that you have just been
thrown off two related, popular, non-email "Q and A" sites (I won't say more)
for exhibiting this type of behaviour (and then some).

We will not tolerate it either.  

You have been in an excessive exchange with Alexios, who patiently took time
from actually working on his packages, to tell to a) slow down and not post
excessively and b) do some research yourself.  You have not done either.

Please change your behaviour, or risk being ignored and/or expelled.

Dirk 
(acting as listmaster)

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From bogaso.christofer at gmail.com  Thu May 23 21:08:31 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Fri, 24 May 2013 00:53:31 +0545
Subject: [R-SIG-Finance] Garch model
Message-ID: <CA+dpOJncNmi0G7fdzyTRKgaPsgSxdbDS=Wb0qWg6SddALNODCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130524/6868dd7b/attachment.pl>

From alexios at 4dscape.com  Thu May 23 23:09:18 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Thu, 23 May 2013 22:09:18 +0100
Subject: [R-SIG-Finance] Garch model
In-Reply-To: <CA+dpOJncNmi0G7fdzyTRKgaPsgSxdbDS=Wb0qWg6SddALNODCA@mail.gmail.com>
References: <CA+dpOJncNmi0G7fdzyTRKgaPsgSxdbDS=Wb0qWg6SddALNODCA@mail.gmail.com>
Message-ID: <519E857E.8040600@4dscape.com>

Looks like a jump GARCH model. Haven't seen anything in R.
Have been considering its implementation for some time based on the Chan 
and Maheu (2002) paper 
(www.ecn.ulaval.ca/~sgor/cours/ecn66054/articles/ChanMaheu.pdf?)

There is some RATS code for this here:
http://www.estima.com/forum/viewtopic.php?f=8&t=1578

Regards,
Alexios


On 23/05/2013 20:08, Christofer Bogaso wrote:
> Hello again, I am trying to estimate the parameters of following Garch
> model:
>
> r[t] = Mu + K * Sigma[t] + Z[t] * Sigma[t] + sum( on j from 1 to st)Nu[j]
>
> Z[t] ~ N(0, 1)
>
> st ~ Poisson[Lambda]
>
> Nu[j] ~ N(0, v)
>
> Sigma[t] ~ Garch(1,1)
>
> I have the time series for r[t] for 500 days.
>
> Can someone point me if there is any R function to achieve the estimation
> of those parameters?
>
> Some research paper on the estimation of same, also be really beneficial.
>
> Thanks for your help.
>
> Thanks and regards,
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From alexandra.rautoiu at yahoo.com  Fri May 24 14:18:48 2013
From: alexandra.rautoiu at yahoo.com (Alexandra Allexa)
Date: Fri, 24 May 2013 05:18:48 -0700 (PDT)
Subject: [R-SIG-Finance] plots with hystorical data
Message-ID: <1369397928.76824.YahooMailNeo@web122405.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130524/35893a9b/attachment.pl>

From brian at braverock.com  Fri May 24 14:22:31 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 24 May 2013 07:22:31 -0500
Subject: [R-SIG-Finance] plots with hystorical data
In-Reply-To: <1369397928.76824.YahooMailNeo@web122405.mail.ne1.yahoo.com>
References: <1369397928.76824.YahooMailNeo@web122405.mail.ne1.yahoo.com>
Message-ID: <519F5B87.6030508@braverock.com>

On 05/24/2013 07:18 AM, Alexandra Allexa wrote:
> I feel ashamed to ask this, but I tried a lot and I do not know where
> I have to search an answer for my problem.
>
> I have to plot some hystorical data, nothing special ar difficult,
> but I don't know haw to do to appear on the x axis the dates of my
> data.
>
> For example my database has records starting with 03th January 2001
> but on x axis apear as label dates starting with 2nd January 1970.
> What is the function for corrige my plots? I have been trying
> funtions from the packages xts and zoo.

You didn't provide a reproducible example, so anyone who answers is just 
guessing, but it seems likely that your
source data is not a time series.

You probably have a data.frame or matrix or similar, and when you use 
plot, you're getting a forced index.

check the class of your input data to make sure that it is xts.

then plot (from zoo, xts, or xtsExtra) or chart_Series or chartSeries 
(from quantmod) will work just fine.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From deo.jaiswal at gmail.com  Fri May 24 14:24:12 2013
From: deo.jaiswal at gmail.com (Deo Jaiswal)
Date: Fri, 24 May 2013 08:24:12 -0400
Subject: [R-SIG-Finance] plots with hystorical data
In-Reply-To: <1369397928.76824.YahooMailNeo@web122405.mail.ne1.yahoo.com>
References: <1369397928.76824.YahooMailNeo@web122405.mail.ne1.yahoo.com>
Message-ID: <CAPMHGQyznGmugCxkLpeFB0fO1m1aiyGBaf9b1FQpdYPu_FgCgg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130524/64f0a2fa/attachment.pl>

From dougedmunds at gmail.com  Sun May 26 23:53:49 2013
From: dougedmunds at gmail.com (dae)
Date: Sun, 26 May 2013 14:53:49 -0700 (PDT)
Subject: [R-SIG-Finance] Extracting numeric data from a mixed data .csv file
Message-ID: <1369605229575-4668030.post@n4.nabble.com>

I have a .csv file that contains 191 columns, some of which are numeric
and others are character data. 

I want to create an xts object, preserving the numerical data.
I am not concerned about saving the character data. 

The date field is a character field in the 3rd column of the the .csv file,
in the format %Y-%m-%d.  

These are the steps I took.  I used some different variable names so
I could back up if I didn't get the result I was expecting:

I am curious to know of other approaches, other than combining some of the
lines, or if there
are problems with this approach.

---code---

library("quantmod")
x = "mixed_data.csv"
x1.csv = read.csv(x, sep=',', as.is=TRUE)  
x.dates = as.POSIXct(x1.csv[,3], format="%Y-%m-%d")
x2.csv = lapply(x1.csv,as.numeric)  #generates a list with NAs for all chr
fields
x3.csv = data.frame(x2.csv)
x.zoo = zoo(x3.csv, order.by=x.dates)
x.xts = xts(x.zoo)

---end code---



--
View this message in context: http://r.789695.n4.nabble.com/Extracting-numeric-data-from-a-mixed-data-csv-file-tp4668030.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From edd at debian.org  Mon May 27 17:37:26 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 27 May 2013 10:37:26 -0500
Subject: [R-SIG-Finance] R/Finance 2013 presentations posted
Message-ID: <20899.32182.995806.927973@max.nulle.part>


Presentation slides from R/Finance 2013 have now been posted; I wrote up a
short blog post at

    http://dirk.eddelbuettel.com/blog/2013/05/27#r_finance_2013_recap

with links and the following short text:

   R / Finance 2013 Recap -- and Presentation Slides 

   The fifth internation R/Finance conference was held last weekend. As one
   of the founding co-organizers, I may well be accussed of a little bias,
   but we think we once again pulled off a very nice and successful
   weekend-long event. Participants had kind words to say during the
   conference, and a few first posts have appeared such as Joe Rickert's post
   over at the REvo blog. 

   Some participants, myself included, had already posted on their personal
   websites (though had forgotten to mention it here). In any event, I just
   updated the website with links to the pdf (or ppt) slides of all
   presenters who shared their material with us. Supplemental material may be
   made available too at a later date. 

   We hope you find these slides useful. Please do spread the word about the
   R/Finance conference as we expect to have a sixth edition in May
   2014---and we do look forward to receiving even more outstanding
   submissions. Dates, details, call for papers, etc will be forthcoming over
   the next few months. 

So please do spread the word, and do plan submit to submit something once we
open the call for papers for the 2014 edition.

On behalf of everybody behind the R/Finance conferences,   
Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From towanda.sagitario at gmail.com  Mon May 27 20:18:37 2013
From: towanda.sagitario at gmail.com (towanda.sagitario)
Date: Mon, 27 May 2013 20:18:37 +0200
Subject: [R-SIG-Finance] Data frame
Message-ID: <CAGhYrgkW2TP2yCZ3Ky7CYdhFV-MiPd+4K39T8kCAnOn=h4e4NA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130527/dee2c8ec/attachment.pl>

From brian at braverock.com  Mon May 27 21:53:17 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 27 May 2013 14:53:17 -0500
Subject: [R-SIG-Finance] Data frame
In-Reply-To: <CAGhYrgkW2TP2yCZ3Ky7CYdhFV-MiPd+4K39T8kCAnOn=h4e4NA@mail.gmail.com>
References: <CAGhYrgkW2TP2yCZ3Ky7CYdhFV-MiPd+4K39T8kCAnOn=h4e4NA@mail.gmail.com>
Message-ID: <51A3B9AD.3020901@braverock.com>

On 05/27/2013 01:18 PM, towanda.sagitario wrote:
> Tengo datos de activos financieros en xls que exporto convenientemente a r
> . En cada columna tengo una series de datos numericos (precios de cierres)
> de los activos financieros. Como podria tipificar cada uno de esos valores
> numericos segun media y desviacion tipica segun la muestra tomada? Gracias

This list is usually in English.

It's a little difficult for me to understand what you're asking for.

If you have a time series of prices, you should probably use a time 
series class such as xts rather than a data.frame.

If you want the mean and sd for the entire series, then mean() and sd() 
will work.  If you want a running estimate over some time window or 
sample, then you probably want runMean() and runSD()


require(quantmod)
getSymbols('IBM')
IBM$runMean<-runMean(Cl(IBM),20)
IBM$runSD<-runSD(Cl(IBM),20)
mean(Cl(IBM))
sd(Cl(IBM))

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From cdcaveman at gmail.com  Mon May 27 22:08:23 2013
From: cdcaveman at gmail.com (C)
Date: Mon, 27 May 2013 16:08:23 -0400
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 108, Issue 24
In-Reply-To: <mailman.3.1369648801.23950.r-sig-finance@r-project.org>
References: <mailman.3.1369648801.23950.r-sig-finance@r-project.org>
Message-ID: <CAE8ybh_YTTO0N2h8cL3z_ryEQEW114hu2CnkoSOzYdrtz=Nt1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130527/62e06d1a/attachment.pl>

From cdcaveman at gmail.com  Mon May 27 22:11:18 2013
From: cdcaveman at gmail.com (cdcaveman)
Date: Mon, 27 May 2013 13:11:18 -0700 (PDT)
Subject: [R-SIG-Finance] Extracting numeric data from a mixed data .csv
	file
In-Reply-To: <1369605229575-4668030.post@n4.nabble.com>
References: <1369605229575-4668030.post@n4.nabble.com>
Message-ID: <1369685478453-4668085.post@n4.nabble.com>

where could i get that data to look at it?  reproducible? 



--
View this message in context: http://r.789695.n4.nabble.com/Extracting-numeric-data-from-a-mixed-data-csv-file-tp4668030p4668085.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From Bauermartin at gmx.at  Tue May 28 09:28:38 2013
From: Bauermartin at gmx.at (Martin Bauer)
Date: Tue, 28 May 2013 09:28:38 +0200 (CEST)
Subject: [R-SIG-Finance] row sum in XTS object
Message-ID: <trinity-a46a50ee-cdca-4a61-8190-e781cb63f25c-1369726117677@3capp-gmx-bs60>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130528/47d356d4/attachment.html>

From vaughn at phxlaw.com  Tue May 28 13:01:46 2013
From: vaughn at phxlaw.com (Kenneth B Vaughn)
Date: Tue, 28 May 2013 13:01:46
Subject: [R-SIG-Finance] row sum in XTS object
In-Reply-To: <trinity-a46a50ee-cdca-4a61-8190-e781cb63f25c-1369726117677@3capp-gmx-bs60>
Message-ID: <1369746134_391506@gwa8>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130528/295e849d/attachment.html>

From breman.mark at gmail.com  Tue May 28 19:37:02 2013
From: breman.mark at gmail.com (Mark Breman)
Date: Tue, 28 May 2013 19:37:02 +0200
Subject: [R-SIG-Finance] row sum in XTS object
In-Reply-To: <1369746134_391506@gwa8>
References: <trinity-a46a50ee-cdca-4a61-8190-e781cb63f25c-1369726117677@3capp-gmx-bs60>
	<1369746134_391506@gwa8>
Message-ID: <CAEaVHoKb5O42Ayq8v76entU3xSJVjLKTvg45k-NkQFoAT7B11A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130528/07cbf646/attachment.pl>

From oleg.mubarakshin at gmail.com  Thu May 30 15:17:22 2013
From: oleg.mubarakshin at gmail.com (Oleg Mubarakshin)
Date: Thu, 30 May 2013 17:17:22 +0400
Subject: [R-SIG-Finance] ts object
Message-ID: <4F62F45F10B74B44B9035CE62D77466E@OLEHP>

Dear colleagues,

How can I create time series (ts) object with specified dates?
E.g.
data = c(100,101,99)
dates = c(?2013-05-20?,?2013-05-21?,?2013-05-30?)

and plot it with specified time range? In case I have several ts and want to plot them on one chart
E.g.
ts1, ts2, ts3
date >= ?2013-05-20? & date <= ?2013-05-25?

Thank you!

Sincerely,
Oleg Mubarakshin

om at quant-lab.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130530/c8fe5864/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 4432 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130530/c8fe5864/attachment.jpe>

From deo.jaiswal at gmail.com  Thu May 30 15:34:56 2013
From: deo.jaiswal at gmail.com (Deo Jaiswal)
Date: Thu, 30 May 2013 09:34:56 -0400
Subject: [R-SIG-Finance] ts object
In-Reply-To: <4F62F45F10B74B44B9035CE62D77466E@OLEHP>
References: <4F62F45F10B74B44B9035CE62D77466E@OLEHP>
Message-ID: <CAPMHGQxP6kn8cKFEdBu3UjrWNRNnFxLobNhNywKa=adUHTh=NA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130530/f9e6c8be/attachment.pl>

From michael.weylandt at gmail.com  Thu May 30 23:05:04 2013
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Thu, 30 May 2013 23:05:04 +0200
Subject: [R-SIG-Finance] ts object
In-Reply-To: <CAPMHGQxP6kn8cKFEdBu3UjrWNRNnFxLobNhNywKa=adUHTh=NA@mail.gmail.com>
References: <4F62F45F10B74B44B9035CE62D77466E@OLEHP>
	<CAPMHGQxP6kn8cKFEdBu3UjrWNRNnFxLobNhNywKa=adUHTh=NA@mail.gmail.com>
Message-ID: <7EC890F3-C56F-49AF-B36F-96D36C5E7886@gmail.com>

To echo what Deo is saying, if the question is 'how to do X with ts objects' the answer is almost always going to be 'Use xts instead'. It's not quite a drop in for one or two things, but its basically always going to be better for whatever you may wish. 

M

On May 30, 2013, at 15:34, Deo Jaiswal <deo.jaiswal at gmail.com> wrote:

> require(xts)
> data <- c(100,101,99)
> dates <-
> c(as.POSIXlt('2013-05-20'),as.POSIXlt('2013-05-21'),as.POSIXlt('2013-05-30'))
> xts(c,order.by=dates)
> 
> Deo Jaiswal
> Student of R
> 
> On Thu, May 30, 2013 at 9:17 AM, Oleg Mubarakshin <
> oleg.mubarakshin at gmail.com> wrote:
> 
>>  Dear colleagues,
>> 
>> How can I create time series (ts) object with specified dates?
>> E.g.
>> data = c(100,101,99)
>> dates = c(?2013-05-20?,?2013-05-21?,?2013-05-30?)
>> 
>> and plot it with specified time range? In case I have several ts and want
>> to plot them on one chart
>> E.g.
>> ts1, ts2, ts3
>> date >= ?2013-05-20? & date <= ?2013-05-25?
>> 
>> Thank you!
>> 
>>  Sincerely,
>> Oleg Mubarakshin
>> 
>> om at quant-lab.com
>> [image: logo_ql_email] <http://quant-lab.com/>
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From dominykasgrigonis at gmail.com  Thu May 30 23:26:55 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Thu, 30 May 2013 22:26:55 +0100
Subject: [R-SIG-Finance] ts object
In-Reply-To: <7EC890F3-C56F-49AF-B36F-96D36C5E7886@gmail.com>
References: <4F62F45F10B74B44B9035CE62D77466E@OLEHP>
	<CAPMHGQxP6kn8cKFEdBu3UjrWNRNnFxLobNhNywKa=adUHTh=NA@mail.gmail.com>
	<7EC890F3-C56F-49AF-B36F-96D36C5E7886@gmail.com>
Message-ID: <379645E49FBE4FD1A709C8F3383BE7B4@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130530/7048f396/attachment.pl>

From oleg.mubarakshin at gmail.com  Fri May 31 20:04:25 2013
From: oleg.mubarakshin at gmail.com (Oleg Mubarakshin)
Date: Fri, 31 May 2013 22:04:25 +0400
Subject: [R-SIG-Finance] options data
Message-ID: <C99F70ED3CAE49AEA789E0016F604F26@OLEHP>

Dear colleagues,

Where can I download free historical options data (market premiums or implied volatilities of options of futures contracts or stocks)?



Kind regards,
Oleg Mubarakshin

om at quant-lab.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130531/252ab046/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 4432 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130531/252ab046/attachment.jpe>

From dominykasgrigonis at gmail.com  Fri May 31 20:12:25 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Fri, 31 May 2013 19:12:25 +0100
Subject: [R-SIG-Finance] options data
In-Reply-To: <C99F70ED3CAE49AEA789E0016F604F26@OLEHP>
References: <C99F70ED3CAE49AEA789E0016F604F26@OLEHP>
Message-ID: <0D10166EF5F24F0B954747394A5D0683@gmail.com>

The only option I know via R is yahoo finance.
there is a function, that does it for you.
getOptionChain("AAPL", Exp="2013-10")

as for implied vols? Have to write your own functions. Use bloomberg otherwise. R has a nice interface to it via package RBloomberg or sty  


Kind regards,--  
Dominykas Grigonis


On Friday, 31 May 2013 at 19:04, Oleg Mubarakshin wrote:

> Dear colleagues,
>   
> Where can I download free historical options data (market premiums or implied volatilities of options of futures contracts or stocks)?
>   
>   
>   
> Kind regards,
> Oleg Mubarakshin  
>   
> om at quant-lab.com (mailto:om at quant-lab.com)
>  
>  
>  
>  
>  
>  
>  
> _______________________________________________
> R-SIG-Finance at r-project.org (mailto:R-SIG-Finance at r-project.org) mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>  
>  


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130531/2412329b/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: logo_ql_email[1].jpg
Type: image/jpeg
Size: 4432 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130531/2412329b/attachment.jpg>

From dominykasgrigonis at gmail.com  Fri May 31 20:12:54 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Fri, 31 May 2013 19:12:54 +0100
Subject: [R-SIG-Finance] options data
In-Reply-To: <0D10166EF5F24F0B954747394A5D0683@gmail.com>
References: <C99F70ED3CAE49AEA789E0016F604F26@OLEHP>
	<0D10166EF5F24F0B954747394A5D0683@gmail.com>
Message-ID: <DDFD4788C75D477791B876FD1BB7E912@gmail.com>

its from:
require(quantmod)



Kind regards,--  
Dominykas Grigonis


On Friday, 31 May 2013 at 19:12, Dominykas Grigonis wrote:

> The only option I know via R is yahoo finance.
> there is a function, that does it for you.
> getOptionChain("AAPL", Exp="2013-10")
>  
> as for implied vols? Have to write your own functions. Use bloomberg otherwise. R has a nice interface to it via package RBloomberg or sty  
>  
>  
> Kind regards,--  
> Dominykas Grigonis
>  
>  
> On Friday, 31 May 2013 at 19:04, Oleg Mubarakshin wrote:
>  
> > Dear colleagues,
> >   
> > Where can I download free historical options data (market premiums or implied volatilities of options of futures contracts or stocks)?
> >   
> >   
> >   
> > Kind regards,
> > Oleg Mubarakshin  
> >   
> > om at quant-lab.com (mailto:om at quant-lab.com)
> >  
> >  
> >  
> >  
> >  
> >  
> >  
> > _______________________________________________
> > R-SIG-Finance at r-project.org (mailto:R-SIG-Finance at r-project.org) mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions should go.
> >  
> >  
> >  
>  
>  

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130531/573b0396/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: logo_ql_email[1].jpg
Type: image/jpeg
Size: 4432 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130531/573b0396/attachment.jpg>

From frankm60606 at gmail.com  Fri May 31 20:51:38 2013
From: frankm60606 at gmail.com (Frank)
Date: Fri, 31 May 2013 13:51:38 -0500
Subject: [R-SIG-Finance] options data
In-Reply-To: <C99F70ED3CAE49AEA789E0016F604F26@OLEHP>
References: <C99F70ED3CAE49AEA789E0016F604F26@OLEHP>
Message-ID: <F60E37FAF4254C62899D9337D64EACC3@Franki7>

http://www.cmegroup.com/market-data/settlements/

Includes futures and option settlements from the various CME futures
exchanges which are available:

?  The most recent trading day available free of charge in text format.
?  Seven days of reports available free of charge in text or XML format on
our?Settlement History?page.
?  For historical settlement data (more than one week old), learn more about
CME?s?DataMine Service.

Frank
Chicago, IL

________________________________________
From: r-sig-finance-bounces at r-project.org
[mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Oleg Mubarakshin
Sent: Friday, May 31, 2013 1:04 PM
To: r-sig-finance
Subject: [R-SIG-Finance] options data

Dear colleagues,
?
Where can I download free historical options data (market premiums or
implied volatilities of options of futures contracts or stocks)?
?
?
?
Kind regards,
Oleg Mubarakshin
?
om at quant-lab.com


From flynn.step at gmail.com  Fri May 31 23:30:03 2013
From: flynn.step at gmail.com (Stephen Flynn)
Date: Fri, 31 May 2013 17:30:03 -0400
Subject: [R-SIG-Finance] MSCI Barra Indicie's
Message-ID: <51A9165B.7070707@gmail.com>

  Hello,

Is there anyway to obtain these for free, such as GEM2L/S?

Thanks,
Steve


From matt at considine.net  Sun Jun  2 00:17:14 2013
From: matt at considine.net (Matt Considine)
Date: Sat, 01 Jun 2013 18:17:14 -0400
Subject: [R-SIG-Finance] MSCI Barra Indicie's
Message-ID: <51AA72EA.4040105@considine.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130601/a1b12ce4/attachment.pl>

From gunjan_narulkar at yahoo.com  Mon Jun  3 17:36:18 2013
From: gunjan_narulkar at yahoo.com (gunjan narulkar)
Date: Mon, 3 Jun 2013 08:36:18 -0700 (PDT)
Subject: [R-SIG-Finance] Regarding significance of "Season" parameter
Message-ID: <1370273778.7668.YahooMailNeo@web162402.mail.bf1.yahoo.com>

Hi,

I'm trying to learn about cointegration, specifically about how to use "ca.jo" for finding the cointegration basis. The data is that of FX rates and M1 supply difference. I need help understanding the below two points:

1. Seasonal variables:?

-> What is the importance of season parameter apart from seemingly obvious explanation in the documentation; in other words, should it be understood as equivalent of Seasonal ARIMA vs ARIMA where we take care of the seasonal unit roots??

-> Should the parameter be set to the value at which the Y_t under question is sampled? Or should it be based on some common frequency derived from individual Y_t component series's periodicity as found from their periodogram (spectrum command in R)?

-> Should the season paramater must be greater then 2? As by spectrum of M1 and FX rate series, I was getting the prominent frequencies for both variables as 2 and its multiples, but got below error, which got resolved as soon as I used anything >2:

"Error in while (nrow(dums) < N) { : argument is of length zero"

Background: I tried checking for cointegration between two monthly series, taking the "season" parameter as 12 (as I had monthly data) first time and without having any season parameter the second. The order of cointegration in both the cases was 1. But further, when I tried fitting VECM and using vec2var created 6 months ahead forecasts and calculated MAPE (Mean Absolute Percentage Error), the MAPE for ca.jo output without season parm specified was better then with season parameter - which lead me to the above confusions.


2. ecdet paramter:?
The awesome book as well as documentation describe this parameter nicely. But when I use it, the message that comes in the output is a bit confusing:

> cv1.m1.bop = ca.jo(cor2,type="trace",ecdet="const",K=2,season=12,dumvar=bop)
> summary(cv1.m1.bop)?


######################?
# Johansen-Procedure #?
######################?

Test type: trace statistic , without linear trend and constant in cointegration?
.
.
.

The confusion is that I'm interested in finding out presence of "restricted constant", so I used "ecdet='const'". Am I correct in doing so?

Apologies if this is not the right forum for asking these questions and also for the long mail.

Thanks & Regards,

Gunjan Narulkar,
Ist Year M. Mgmt., DOMS,
Indian Institute of Science
Contact: +91-99007-40404
LinkedIn: in.linkedin.com/pub/gunjan-narulkar/19/a3b/521


From alexandbridges at gmail.com  Tue Jun  4 15:25:10 2013
From: alexandbridges at gmail.com (Alexandra Bridges)
Date: Tue, 4 Jun 2013 15:25:10 +0200
Subject: [R-SIG-Finance] Are my VaR forecasts correct (using rugarch)?
Message-ID: <CAJ5rLA8rdzq8DnLxFvDOMzYP=cEMvrbr_Af6mmSRhL6bGyN7EQ@mail.gmail.com>

Hi,
I am using the rugarch package and especially the command ugarchroll
to do a rolling forecasting to calculate the VaR.

I am using the sp500ret of the rugarch package:

library(rugarch)
data(sp500ret)


This is daily data. I now want to fit a GARCH model every 100th day.
The window size should be 255 observations. So my GARCH model should
take the last recent 255 observations. Therefore the first VaR
forecast belongs to the 256th day (this is in this dataset the
11.03.1988).

My code is:

# model specification
spmodel<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder
= c(1, 1)),
mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
distribution.model = "norm")

# model fit
spgarchmodel<-ugarchfit(spec=spmodel,data=sp500ret)


# now rolling forecasts with ugarchroll

# observations available in total:
length(sp500ret[,1])

roll = ugarchroll(spmodel, sp500ret, n.start=255,
 refit.every = 100, refit.window = 'moving', window.size = 255,
  calculate.VaR = TRUE, keep.coef = TRUE)

show(roll)
# or the following alternatively also works:

roll = ugarchroll(spmodel, sp500ret, forecast.length=(length(sp500ret[,1]))-255,
 refit.every = 100, refit.window = 'moving', window.size = 255,
  calculate.VaR = TRUE, keep.coef = TRUE)

show(roll,which=4)


First: Is this right what I am doing? Since both methods lead to the
same result I think I am correct, right?

Second:
The backtest shows the following:

report(roll,type="VaR",VaR.alpha=0.01,conf.level=0.99)

That means, I have far more exceedances than expected. So my model is
not good, why? What am I doing wrong? Is this due to a bad model
specification or due to an error in my code?

--
Alexa Bridges


From ryan.lanham at bluecrestcapital.com  Tue Jun  4 16:56:52 2013
From: ryan.lanham at bluecrestcapital.com (Ryan Lanham)
Date: Tue, 4 Jun 2013 14:56:52 +0000
Subject: [R-SIG-Finance] SABR or 5 point models
Message-ID: <89C0ED3F689318428038605A447F10293EB25FD5@G40WIEXMBP02.BlueCrest.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130604/3084ba08/attachment.pl>

From alexios at 4dscape.com  Wed Jun  5 00:28:22 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Tue, 04 Jun 2013 23:28:22 +0100
Subject: [R-SIG-Finance] Are my VaR forecasts correct (using rugarch)?
In-Reply-To: <CAJ5rLA8rdzq8DnLxFvDOMzYP=cEMvrbr_Af6mmSRhL6bGyN7EQ@mail.gmail.com>
References: <CAJ5rLA8rdzq8DnLxFvDOMzYP=cEMvrbr_Af6mmSRhL6bGyN7EQ@mail.gmail.com>
Message-ID: <51AE6A06.4080009@4dscape.com>

Hi,

1. You can easily check whether you are getting the forecast at the date 
you want by inspecting the returned forecast density data.frame:
as.data.frame(roll, which = "density")
OR VaR:
as.data.frame(roll, which = "VaR")
If you provided an xts object, then the dates in the data.frame rownames 
will provide you with the answer.

Have you tried help('uGARCHroll-class') ?

2. "show(roll,which=4)". There is no documented method 'show' which
takes on additional arguments 'which'.

3. 'report(roll,type="VaR",VaR.alpha=0.01,conf.level=0.99)'
This is a formal test of the conditional coverage. You ask WHY your 
model does not pass the test. ONLY YOU can answer that question given 
you knowledge of YOUR data.
However, it is usually unlikely that the normal distribution provides 
for a good fit to the observed security return dynamics in financial 
markets (try distribution.model='jsu').
Also, if you search previous postings you may see that a data length of 
255 may not be adequate for modelling the volatility process 
persistence. There is a blog post on this question you may find useful 
(http://www.unstarched.net/2012/12/26/garch-parameter-uncertainty-and-data-size/).


Regards,

Alexios



On 04/06/2013 14:25, Alexandra Bridges wrote:
> Hi,
> I am using the rugarch package and especially the command ugarchroll
> to do a rolling forecasting to calculate the VaR.
>
> I am using the sp500ret of the rugarch package:
>
> library(rugarch)
> data(sp500ret)
>
>
> This is daily data. I now want to fit a GARCH model every 100th day.
> The window size should be 255 observations. So my GARCH model should
> take the last recent 255 observations. Therefore the first VaR
> forecast belongs to the 256th day (this is in this dataset the
> 11.03.1988).
>
> My code is:
>
> # model specification
> spmodel<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder
> = c(1, 1)),
> mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
> distribution.model = "norm")
>
> # model fit
> spgarchmodel<-ugarchfit(spec=spmodel,data=sp500ret)
>
>
> # now rolling forecasts with ugarchroll
>
> # observations available in total:
> length(sp500ret[,1])
>
> roll = ugarchroll(spmodel, sp500ret, n.start=255,
>   refit.every = 100, refit.window = 'moving', window.size = 255,
>    calculate.VaR = TRUE, keep.coef = TRUE)
>
> show(roll)
> # or the following alternatively also works:
>
> roll = ugarchroll(spmodel, sp500ret, forecast.length=(length(sp500ret[,1]))-255,
>   refit.every = 100, refit.window = 'moving', window.size = 255,
>    calculate.VaR = TRUE, keep.coef = TRUE)
>
> show(roll,which=4)
>
>
> First: Is this right what I am doing? Since both methods lead to the
> same result I think I am correct, right?
>
> Second:
> The backtest shows the following:
>
> report(roll,type="VaR",VaR.alpha=0.01,conf.level=0.99)
>
> That means, I have far more exceedances than expected. So my model is
> not good, why? What am I doing wrong? Is this due to a bad model
> specification or due to an error in my code?
>
> --
> Alexa Bridges
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From matthieu.stigler at gmail.com  Wed Jun  5 09:52:08 2013
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Wed, 5 Jun 2013 09:52:08 +0200
Subject: [R-SIG-Finance] Regarding significance of "Season" parameter
In-Reply-To: <1370273778.7668.YahooMailNeo@web162402.mail.bf1.yahoo.com>
References: <1370273778.7668.YahooMailNeo@web162402.mail.bf1.yahoo.com>
Message-ID: <CAEYvig+ZnBW6gMTKu02Q9dZRHP4JL1T9SZyq8jLbqkZFOo7Z2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130605/83ed2b96/attachment.pl>

From gunjan_narulkar at yahoo.com  Wed Jun  5 12:48:19 2013
From: gunjan_narulkar at yahoo.com (gunjan narulkar)
Date: Wed, 5 Jun 2013 03:48:19 -0700 (PDT)
Subject: [R-SIG-Finance] Regarding significance of "Season" parameter
In-Reply-To: <CAEYvig+ZnBW6gMTKu02Q9dZRHP4JL1T9SZyq8jLbqkZFOo7Z2A@mail.gmail.com>
References: <1370273778.7668.YahooMailNeo@web162402.mail.bf1.yahoo.com>
	<CAEYvig+ZnBW6gMTKu02Q9dZRHP4JL1T9SZyq8jLbqkZFOo7Z2A@mail.gmail.com>
Message-ID: <1370429299.27096.YahooMailNeo@web162402.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130605/90f89990/attachment.pl>

From roger.bos at rothschild.com  Wed Jun  5 22:17:17 2013
From: roger.bos at rothschild.com (Bos, Roger)
Date: Wed, 5 Jun 2013 20:17:17 +0000
Subject: [R-SIG-Finance] performance attribution output
Message-ID: <0765308CD028654885F30322557308D80DFDDD5B@NYCSM0208.rth.ad.rothschild.com>

I have been trying out the performance attribution package and find it very interesting, but I can't figure out how to get the output into a data.frame or other object that would make it easy for me to store it.  Here is some example code:

library(pa)
data(jan)
br.single <- brinson(x = jan, date.var = "date", cat.var = "sector", bench.weight = "benchmark", portfolio.weight = "portfolio", ret.var = "return")
summary(br.single)

Running this example will produce the following output (which looks better in R than it does here)

Period:                              2010-01-01
Methodology:                         Brinson
Securities in the portfolio:         200
Securities in the benchmark:         1000

Exposures 
            Portfolio Benchmark     Diff
Energy          0.085    0.2782 -0.19319
Materials       0.070    0.0277  0.04230
Industrials     0.045    0.0330  0.01201
ConDiscre       0.050    0.0188  0.03124
ConStaples      0.030    0.0148  0.01518
HealthCare      0.015    0.0608 -0.04576
Financials      0.370    0.2979  0.07215
InfoTech        0.005    0.0129 -0.00787
TeleSvcs        0.300    0.1921  0.10792
Utilities       0.030    0.0640 -0.03399

Returns 
$`Attribution by category in bps`
            Allocation Selection Interaction
Energy         110.934    -37.52      26.059
Materials      -41.534      0.48       0.734
Industrials      0.361      1.30       0.473
ConDiscre      -28.688     -4.23      -7.044
ConStaples       5.467     -3.59      -3.673
HealthCare      -6.692     -4.07       3.063
Financials     -43.998     70.13      16.988
InfoTech        -3.255     -5.32       3.255
TeleSvcs       -23.106     41.55      23.348
Utilities       16.544     83.03     -44.108
Total          -13.966    141.77      19.095

$Aggregate
                   2010-01-01
Allocation Effect    -0.00140
Selection Effect      0.01418
Interaction Effect    0.00191
Active Return         0.01469

My question is, how can I, say, save the $Aggregate output into a data.frame?  I have been trying to read about S4 objects, but I am still not able to figure this out.  As long as I am asking, could anyone tell me how to see the code behind the "summary" function being used here?  The following is not very enlightening:

> showMethods("summary", classes="brinson")
Function: summary (package base)
object="brinson"

Thanks in advance for any help!


From Yang.Lu at williams.edu  Thu Jun  6 04:41:45 2013
From: Yang.Lu at williams.edu (Yang Lu)
Date: Wed,  5 Jun 2013 22:41:45 -0400 (EDT)
Subject: [R-SIG-Finance] performance attribution output
In-Reply-To: <0765308CD028654885F30322557308D80DFDDD5B@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D80DFDDD5B@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <201306060241.000059@miram7700b.williams.edu>

Hi Roger, 

The last part of the summary output '$Aggregate' comes from the returns method in the package. There are two parts (in a list) in the returns output. The '$Aggregate' is the second part. To save it as a data.frame, you can do the following:

> df = as.data.frame(returns(br.single)[[2]])

To see the source code from R, 

> getMethods("summary")
> getMethods("returns")

Hope this helps. Please let me know if you have any other questions,

Best,
Yang

Yang Lu '14
SU 2896  Paresky Center
Williams College, MA
(413)884-4847


---- Original message ----
>Date: Wed, 5 Jun 2013 20:17:17 +0000
>From: r-sig-finance-bounces at r-project.org (on behalf of "Bos, Roger" <roger.bos at rothschild.com>)
>Subject: [R-SIG-Finance] performance attribution output  
>To: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
>
>I have been trying out the performance attribution package and find it very interesting, but I can't figure out how to get the output into a data.frame or other object that would make it easy for me to store it.  Here is some example code:
>
>library(pa)
>data(jan)
>br.single <- brinson(x = jan, date.var = "date", cat.var = "sector", bench.weight = "benchmark", portfolio.weight = "portfolio", ret.var = "return")
>summary(br.single)
>
>Running this example will produce the following output (which looks better in R than it does here)
>
>Period:                              2010-01-01
>Methodology:                         Brinson
>Securities in the portfolio:         200
>Securities in the benchmark:         1000
>
>Exposures 
>            Portfolio Benchmark     Diff
>Energy          0.085    0.2782 -0.19319
>Materials       0.070    0.0277  0.04230
>Industrials     0.045    0.0330  0.01201
>ConDiscre       0.050    0.0188  0.03124
>ConStaples      0.030    0.0148  0.01518
>HealthCare      0.015    0.0608 -0.04576
>Financials      0.370    0.2979  0.07215
>InfoTech        0.005    0.0129 -0.00787
>TeleSvcs        0.300    0.1921  0.10792
>Utilities       0.030    0.0640 -0.03399
>
>Returns 
>$`Attribution by category in bps`
>            Allocation Selection Interaction
>Energy         110.934    -37.52      26.059
>Materials      -41.534      0.48       0.734
>Industrials      0.361      1.30       0.473
>ConDiscre      -28.688     -4.23      -7.044
>ConStaples       5.467     -3.59      -3.673
>HealthCare      -6.692     -4.07       3.063
>Financials     -43.998     70.13      16.988
>InfoTech        -3.255     -5.32       3.255
>TeleSvcs       -23.106     41.55      23.348
>Utilities       16.544     83.03     -44.108
>Total          -13.966    141.77      19.095
>
>$Aggregate
>                   2010-01-01
>Allocation Effect    -0.00140
>Selection Effect      0.01418
>Interaction Effect    0.00191
>Active Return         0.01469
>
>My question is, how can I, say, save the $Aggregate output into a data.frame?  I have been trying to read about S4 objects, but I am still not able to figure this out.  As long as I am asking, could anyone tell me how to see the code behind the "summary" function being used here?  The following is not very enlightening:
>
>> showMethods("summary", classes="brinson")
>Function: summary (package base)
>object="brinson"
>
>Thanks in advance for any help!
>
>_______________________________________________
>R-SIG-Finance at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>-- Subscriber-posting only. If you want to post, subscribe first.
>-- Also note that this is not the r-help list where general R questions should go.


From bastian2507hk at yahoo.co.uk  Thu Jun  6 08:55:28 2013
From: bastian2507hk at yahoo.co.uk (Bastian Offermann)
Date: Thu, 06 Jun 2013 02:55:28 -0400
Subject: [R-SIG-Finance] Best optimizer for large scale problems
Message-ID: <51B03260.60904@yahoo.co.uk>

Hi all,
I am working on a large scale portfolio optimization problem with up to 
500 assets. My objective function is simple

w*returns - 1/2 * 1/constant * w * Matrix * w

subject to sum(w) == 1 and w is a vector of weights with 0 <= w[i] <= 1 
for all i = 1, ..., n.

I have tried quadprog, alabama and DEoptim. What are your experiences 
with those and possibly other options?
Thanks in advance!


From dominykasgrigonis at gmail.com  Thu Jun  6 09:58:11 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Thu, 6 Jun 2013 08:58:11 +0100
Subject: [R-SIG-Finance] Best optimizer for large scale problems
In-Reply-To: <51B03260.60904@yahoo.co.uk>
References: <51B03260.60904@yahoo.co.uk>
Message-ID: <39324418247A4AD393948D30A360BDD0@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130606/e7debc4d/attachment.pl>

From alexios at 4dscape.com  Thu Jun  6 10:09:15 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Thu, 06 Jun 2013 09:09:15 +0100
Subject: [R-SIG-Finance] Best optimizer for large scale problems
In-Reply-To: <39324418247A4AD393948D30A360BDD0@gmail.com>
References: <51B03260.60904@yahoo.co.uk>
	<39324418247A4AD393948D30A360BDD0@gmail.com>
Message-ID: <51B043AB.8090505@4dscape.com>

For quadratic problems you really should use quadprog.

You can also try the 'parma' package which provides a nice interface to 
frame your problem and constraints and then solve it using either an LP, 
QP, NLP (with analytic derivatives) or GNLP formulation (depending on 
the intersection of problem and constraint type).

Regards,

Alexios

On 06/06/2013 08:58, Dominykas Grigonis wrote:
> ROI::ROI_solve( problem, solver, control, ... )
> DEoptim::DEoptim() # differential evolution!
>
> Rsolnp # general non-linear optimisation
>
> This is from my R conspects. Can try to take a look at those.
> For your problem quadprog might be the best option regarding speed. I like DEoptim a lot, but I use it for more complicated problems when I can not find simpler solution. Try adjusting parameters of it, it has 5 or 6 different approaches to the problem. Adding jitter helps in some cases(might slow process a bit, but not sure). I used it when I was optimising with respect to non-linear functions of portfolio evolution as drawdown.
>
>
>
> Kind regards,--
> Dominykas Grigonis
>
>
> On Thursday, 6 June 2013 at 07:55, Bastian Offermann wrote:
>
>> Hi all,
>> I am working on a large scale portfolio optimization problem with up to
>> 500 assets. My objective function is simple
>>
>> w*returns - 1/2 * 1/constant * w * Matrix * w
>>
>> subject to sum(w) == 1 and w is a vector of weights with 0 <= w[i] <= 1
>> for all i = 1, ..., n.
>>
>> I have tried quadprog, alabama and DEoptim. What are your experiences
>> with those and possibly other options?
>> Thanks in advance!
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org (mailto:R-SIG-Finance at r-project.org) mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>>
>>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From es at enricoschumann.net  Thu Jun  6 11:51:20 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Thu, 06 Jun 2013 11:51:20 +0200
Subject: [R-SIG-Finance] Best optimizer for large scale problems
In-Reply-To: <51B03260.60904@yahoo.co.uk> (Bastian Offermann's message of
	"Thu, 06 Jun 2013 02:55:28 -0400")
References: <51B03260.60904@yahoo.co.uk>
Message-ID: <87ehcf5zzb.fsf@enricoschumann.net>

On Thu, 06 Jun 2013, Bastian Offermann <bastian2507hk at yahoo.co.uk> writes:

> Hi all,
> I am working on a large scale portfolio optimization problem with up
> to 500 assets. My objective function is simple
>
> w*returns - 1/2 * 1/constant * w * Matrix * w
>
> subject to sum(w) == 1 and w is a vector of weights with 0 <= w[i] <=
> 1 for all i = 1, ..., n.
>
> I have tried quadprog, alabama and DEoptim. What are your experiences
> with those and possibly other options?
> Thanks in advance!
>

You say you "have tried" these packages, so did you encounter any
specific problems?  If yes, you should post some examples that
demonstrate these problems.

quadprog sounds reasonable, but if your covariance matrix is not
full-rank, quadprog's solve.QP will not work.  (Which is actually more
an empirical than a computational problem.  For example, there might be
no unique solution.)  Other methods, such as Differential Evolution, do
not have such a constraint.

Regards,
        Enrico

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From armstrong.whit at gmail.com  Thu Jun  6 13:52:58 2013
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Thu, 6 Jun 2013 07:52:58 -0400
Subject: [R-SIG-Finance] Best optimizer for large scale problems
In-Reply-To: <87ehcf5zzb.fsf@enricoschumann.net>
References: <51B03260.60904@yahoo.co.uk>
	<87ehcf5zzb.fsf@enricoschumann.net>
Message-ID: <CAMi=pg43UNEc0_ivG4wObYEZvW=6E7xhDony-oUmRep7Tn+EeA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130606/779009c9/attachment.pl>

From alexandbridges at gmail.com  Sat Jun  8 09:56:26 2013
From: alexandbridges at gmail.com (Alexandra Bridges)
Date: Sat, 8 Jun 2013 09:56:26 +0200
Subject: [R-SIG-Finance] Are my VaR forecasts correct (using rugarch)?
In-Reply-To: <51AE6A06.4080009@4dscape.com>
References: <CAJ5rLA8rdzq8DnLxFvDOMzYP=cEMvrbr_Af6mmSRhL6bGyN7EQ@mail.gmail.com>
	<51AE6A06.4080009@4dscape.com>
Message-ID: <CAJ5rLA-r9yJHQUBmg-SXii0HpBgUOTLBNc3a6Qt6oXjnZLNQdg@mail.gmail.com>

Thanks a lot for your answer!

One question for me remains:
I use a simple model fit like this (so no rolling estimation):

spgarchmodel<-ugarchfit(spec=
spmodel,data=sp500ret)


now I can get the sigma values with

sigma(spgarchmodel)

I know how to calculate them recursively, but what about
sigma(spgarchmodel)[1] ?
How is this value calculated?

I tried the following:
The initial sigma_0 is set to the unconditional variance. So in case
of a GARCH(1,1) this would be:
omega/(1-alpha1-beta1)

This is inserted into the GARCH(1,1) formula, the "residual value"
epsilon_0 is set to the return of the first date, so:
sqrt(omega+alpha1*return_ofthefirstdate^2 + beta1*unconditional_variance)

But this gives a sligthly different value?

Thanks a lot for your answer!


2013/6/5 alexios ghalanos <alexios at 4dscape.com>:
> Hi,
>
> 1. You can easily check whether you are getting the forecast at the date you
> want by inspecting the returned forecast density data.frame:
> as.data.frame(roll, which = "density")
> OR VaR:
> as.data.frame(roll, which = "VaR")
> If you provided an xts object, then the dates in the data.frame rownames
> will provide you with the answer.
>
> Have you tried help('uGARCHroll-class') ?
>
> 2. "show(roll,which=4)". There is no documented method 'show' which
> takes on additional arguments 'which'.
>
> 3. 'report(roll,type="VaR",VaR.alpha=0.01,conf.level=0.99)'
> This is a formal test of the conditional coverage. You ask WHY your model
> does not pass the test. ONLY YOU can answer that question given you
> knowledge of YOUR data.
> However, it is usually unlikely that the normal distribution provides for a
> good fit to the observed security return dynamics in financial markets (try
> distribution.model='jsu').
> Also, if you search previous postings you may see that a data length of 255
> may not be adequate for modelling the volatility process persistence. There
> is a blog post on this question you may find useful
> (http://www.unstarched.net/2012/12/26/garch-parameter-uncertainty-and-data-size/).
>
>
> Regards,
>
> Alexios
>
>
>
>
> On 04/06/2013 14:25, Alexandra Bridges wrote:
>>
>> Hi,
>> I am using the rugarch package and especially the command ugarchroll
>> to do a rolling forecasting to calculate the VaR.
>>
>> I am using the sp500ret of the rugarch package:
>>
>> library(rugarch)
>> data(sp500ret)
>>
>>
>> This is daily data. I now want to fit a GARCH model every 100th day.
>> The window size should be 255 observations. So my GARCH model should
>> take the last recent 255 observations. Therefore the first VaR
>> forecast belongs to the 256th day (this is in this dataset the
>> 11.03.1988).
>>
>> My code is:
>>
>> # model specification
>> spmodel<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder
>> = c(1, 1)),
>> mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
>> distribution.model = "norm")
>>
>> # model fit
>> spgarchmodel<-ugarchfit(spec=spmodel,data=sp500ret)
>>
>>
>> # now rolling forecasts with ugarchroll
>>
>> # observations available in total:
>> length(sp500ret[,1])
>>
>> roll = ugarchroll(spmodel, sp500ret, n.start=255,
>>   refit.every = 100, refit.window = 'moving', window.size = 255,
>>    calculate.VaR = TRUE, keep.coef = TRUE)
>>
>> show(roll)
>> # or the following alternatively also works:
>>
>> roll = ugarchroll(spmodel, sp500ret,
>> forecast.length=(length(sp500ret[,1]))-255,
>>   refit.every = 100, refit.window = 'moving', window.size = 255,
>>    calculate.VaR = TRUE, keep.coef = TRUE)
>>
>> show(roll,which=4)
>>
>>
>> First: Is this right what I am doing? Since both methods lead to the
>> same result I think I am correct, right?
>>
>> Second:
>> The backtest shows the following:
>>
>> report(roll,type="VaR",VaR.alpha=0.01,conf.level=0.99)
>>
>> That means, I have far more exceedances than expected. So my model is
>> not good, why? What am I doing wrong? Is this due to a bad model
>> specification or due to an error in my code?
>>
>> --
>> Alexa Bridges
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>



-- 
Alexa Bridges


From jesperhybel at hotmail.com  Sat Jun  8 22:45:03 2013
From: jesperhybel at hotmail.com (Jesper Hybel Pedersen)
Date: Sat, 8 Jun 2013 22:45:03 +0200
Subject: [R-SIG-Finance] rugarch
Message-ID: <DUB119-DS9CE00AA3B9C43EFC81771AE9A0@phx.gbl>

I recently used the rugarch package for a Bachelor project and spent a lot of time
browsing the net, various helpfiles and reading the reference manual and vignette. So I thought
I might do a small example on some estimation and forecasting which perhaps could be of help to others at my own level. 
I do not really have any place to publish the example and anyway the vignette says ?drop me a note? and although I realize this
is probably intended for publishing fellow researcher here is a note and a thank you for a great package which I had a lot of fun getting to
know.

Best regards Jesper Hybel
Student of Economics Copenhagen University
Sorry if I am somehow misusing the mailing list.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130608/91b6cb9d/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: an example in rugarch.pdf
Type: application/pdf
Size: 266710 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130608/91b6cb9d/attachment.pdf>

From jeff.a.ryan at gmail.com  Sat Jun  8 23:36:35 2013
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sat, 8 Jun 2013 16:36:35 -0500
Subject: [R-SIG-Finance] rugarch
In-Reply-To: <DUB119-DS9CE00AA3B9C43EFC81771AE9A0@phx.gbl>
References: <DUB119-DS9CE00AA3B9C43EFC81771AE9A0@phx.gbl>
Message-ID: <9F390BE3-3CFB-479D-B623-E8E6C7100467@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130608/ad800536/attachment.pl>

From alexios at 4dscape.com  Sun Jun  9 00:50:28 2013
From: alexios at 4dscape.com (Alexios Ghalanos)
Date: Sun, 9 Jun 2013 01:50:28 +0300
Subject: [R-SIG-Finance] rugarch
In-Reply-To: <9F390BE3-3CFB-479D-B623-E8E6C7100467@gmail.com>
References: <DUB119-DS9CE00AA3B9C43EFC81771AE9A0@phx.gbl>
	<9F390BE3-3CFB-479D-B623-E8E6C7100467@gmail.com>
Message-ID: <A95F8FAE-3351-440E-A154-FABE85D39976@4dscape.com>

Brilliant piece of work Jesper. Thanks for sharing and giving back to the community.

Best,
Alexios

On Jun 9, 2013, at 0:36, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:

> Quite the contrary, this is an outstanding use of the list. 
> 
> Thanks for contributing to the community!
> 
> Jeff
> 
> Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com
> 
> www.lemnica.com
> 
> On Jun 8, 2013, at 3:45 PM, "Jesper Hybel Pedersen" <jesperhybel at hotmail.com> wrote:
> 
>> I recently used the rugarch package for a Bachelor project and spent a lot of time
>> browsing the net, various helpfiles and reading the reference manual and vignette. So I thought
>> I might do a small example on some estimation and forecasting which perhaps could be of help to others at my own level.
>> I do not really have any place to publish the example and anyway the vignette says ?drop me a note? and although I realize this
>> is probably intended for publishing fellow researcher here is a note and a thank you for a great package which I had a lot of fun getting to
>> know.
>> 
>> Best regards Jesper Hybel
>> Student of Economics Copenhagen University
>> Sorry if I am somehow misusing the mailing list.
>> <an example in rugarch.pdf>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From alexios at 4dscape.com  Sun Jun  9 01:17:01 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sun, 09 Jun 2013 02:17:01 +0300
Subject: [R-SIG-Finance] Are my VaR forecasts correct (using rugarch)?
In-Reply-To: <CAJ5rLA-r9yJHQUBmg-SXii0HpBgUOTLBNc3a6Qt6oXjnZLNQdg@mail.gmail.com>
References: <CAJ5rLA8rdzq8DnLxFvDOMzYP=cEMvrbr_Af6mmSRhL6bGyN7EQ@mail.gmail.com>
	<51AE6A06.4080009@4dscape.com>
	<CAJ5rLA-r9yJHQUBmg-SXii0HpBgUOTLBNc3a6Qt6oXjnZLNQdg@mail.gmail.com>
Message-ID: <51B3BB6D.6050403@4dscape.com>

Initialization of the GARCH recursion is mentioned in the vignette in 
the first paragraph of P.21.
The default option is to use the mean of the squared residuals from the 
conditional mean filtration
process. This is the standard approach. However, if you read the 
'ugarchfit' documentation (or vignette),
there is also mention of the 'rec.init' option:

"the rec.init option determines the type of initialization for the 
variance recursion. Valid options
are ?all? which uses all the values for the unconditional variance 
calculation, an integer greater
than or equal to 1 denoting the number of data points to use for the 
calculation, or a positive
numeric value less than one which determines the weighting for use in an 
exponential
smoothing backcast."

Regards,

Alexios

On 06/08/2013 10:56 AM, Alexandra Bridges wrote:
> Thanks a lot for your answer!
>
> One question for me remains:
> I use a simple model fit like this (so no rolling estimation):
>
> spgarchmodel<-ugarchfit(spec=
> spmodel,data=sp500ret)
>
>
> now I can get the sigma values with
>
> sigma(spgarchmodel)
>
> I know how to calculate them recursively, but what about
> sigma(spgarchmodel)[1] ?
> How is this value calculated?
>
> I tried the following:
> The initial sigma_0 is set to the unconditional variance. So in case
> of a GARCH(1,1) this would be:
> omega/(1-alpha1-beta1)
>
> This is inserted into the GARCH(1,1) formula, the "residual value"
> epsilon_0 is set to the return of the first date, so:
> sqrt(omega+alpha1*return_ofthefirstdate^2 + beta1*unconditional_variance)
>
> But this gives a sligthly different value?
>
> Thanks a lot for your answer!
>
>
> 2013/6/5 alexios ghalanos <alexios at 4dscape.com>:
>> Hi,
>>
>> 1. You can easily check whether you are getting the forecast at the date you
>> want by inspecting the returned forecast density data.frame:
>> as.data.frame(roll, which = "density")
>> OR VaR:
>> as.data.frame(roll, which = "VaR")
>> If you provided an xts object, then the dates in the data.frame rownames
>> will provide you with the answer.
>>
>> Have you tried help('uGARCHroll-class') ?
>>
>> 2. "show(roll,which=4)". There is no documented method 'show' which
>> takes on additional arguments 'which'.
>>
>> 3. 'report(roll,type="VaR",VaR.alpha=0.01,conf.level=0.99)'
>> This is a formal test of the conditional coverage. You ask WHY your model
>> does not pass the test. ONLY YOU can answer that question given you
>> knowledge of YOUR data.
>> However, it is usually unlikely that the normal distribution provides for a
>> good fit to the observed security return dynamics in financial markets (try
>> distribution.model='jsu').
>> Also, if you search previous postings you may see that a data length of 255
>> may not be adequate for modelling the volatility process persistence. There
>> is a blog post on this question you may find useful
>> (http://www.unstarched.net/2012/12/26/garch-parameter-uncertainty-and-data-size/).
>>
>>
>> Regards,
>>
>> Alexios
>>
>>
>>
>>
>> On 04/06/2013 14:25, Alexandra Bridges wrote:
>>> Hi,
>>> I am using the rugarch package and especially the command ugarchroll
>>> to do a rolling forecasting to calculate the VaR.
>>>
>>> I am using the sp500ret of the rugarch package:
>>>
>>> library(rugarch)
>>> data(sp500ret)
>>>
>>>
>>> This is daily data. I now want to fit a GARCH model every 100th day.
>>> The window size should be 255 observations. So my GARCH model should
>>> take the last recent 255 observations. Therefore the first VaR
>>> forecast belongs to the 256th day (this is in this dataset the
>>> 11.03.1988).
>>>
>>> My code is:
>>>
>>> # model specification
>>> spmodel<-ugarchspec(variance.model = list(model = "sGARCH", garchOrder
>>> = c(1, 1)),
>>> mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
>>> distribution.model = "norm")
>>>
>>> # model fit
>>> spgarchmodel<-ugarchfit(spec=spmodel,data=sp500ret)
>>>
>>>
>>> # now rolling forecasts with ugarchroll
>>>
>>> # observations available in total:
>>> length(sp500ret[,1])
>>>
>>> roll = ugarchroll(spmodel, sp500ret, n.start=255,
>>>    refit.every = 100, refit.window = 'moving', window.size = 255,
>>>     calculate.VaR = TRUE, keep.coef = TRUE)
>>>
>>> show(roll)
>>> # or the following alternatively also works:
>>>
>>> roll = ugarchroll(spmodel, sp500ret,
>>> forecast.length=(length(sp500ret[,1]))-255,
>>>    refit.every = 100, refit.window = 'moving', window.size = 255,
>>>     calculate.VaR = TRUE, keep.coef = TRUE)
>>>
>>> show(roll,which=4)
>>>
>>>
>>> First: Is this right what I am doing? Since both methods lead to the
>>> same result I think I am correct, right?
>>>
>>> Second:
>>> The backtest shows the following:
>>>
>>> report(roll,type="VaR",VaR.alpha=0.01,conf.level=0.99)
>>>
>>> That means, I have far more exceedances than expected. So my model is
>>> not good, why? What am I doing wrong? Is this due to a bad model
>>> specification or due to an error in my code?
>>>
>>> --
>>> Alexa Bridges
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>>
>
>


From ivanovruporvrich at yahoo.com  Mon Jun 10 07:44:50 2013
From: ivanovruporvrich at yahoo.com (Ivanov Ruporvrich)
Date: Mon, 10 Jun 2013 06:44:50 +0100 (BST)
Subject: [R-SIG-Finance] Computational Time using rugarch package
Message-ID: <1370843090.10209.YahooMailNeo@web171506.mail.ir2.yahoo.com>



Hi,
I am using the rugarch package in R and I have a certain model, which I want to reestimate on a daily basis using ugarchroll.

I am aware of the fact, that my problem is caused by the reason, that I do the reestimation daily, but since I really need the daily reestimation I cannot change this parameter (change to an higher number). My problem is, that reestimation on a daily basis takes a lot of time. I ran my pc for 7 hours but I did not get a result, when I pressed ESC I got 4 or 5 warning messages that the hessian could not be inverted.

So my main question is: Is there any chance to get this estimation running? Maybe change the solver or something like that?

I do not have a problem with running R for like 6 hours or so, at least if I get a result afterwards.

My R code is: (I use 262 observations for each window, I am aware of the fact, that 
more observations would be better in order to get more consistent 
estimates.)

library(rugarch)

garchspecification<-ugarchspec(variance.model = list(model="fGARCH",submodel="NAGARCH", garchOrder = c(1, 1)), 
mean.model = list(armaOrder = c(1, 0), include.mean = FALSE), 
distribution.model = "ged")

rollmodel = ugarchroll(garchspecification, mydata, n.start=262,
?refit.every = 1, refit.window = 'moving', window.size = 262,
? calculate.VaR = TRUE, keep.coef = TRUE)



I attached the data.


Thanks a lot for your help,
Ivanov
-------------- next part --------------
A non-text attachment was scrubbed...
Name: GARCHdata.RData
Type: application/octet-stream
Size: 27552 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130610/d2227659/attachment.obj>

From alexios at 4dscape.com  Mon Jun 10 09:12:03 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Mon, 10 Jun 2013 10:12:03 +0300
Subject: [R-SIG-Finance] Computational Time using rugarch package
In-Reply-To: <1370843090.10209.YahooMailNeo@web171506.mail.ir2.yahoo.com>
References: <1370843090.10209.YahooMailNeo@web171506.mail.ir2.yahoo.com>
Message-ID: <51B57C43.4000807@4dscape.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130610/0dd74f74/attachment.pl>

From optionsraghu at gmail.com  Mon Jun 10 10:37:36 2013
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Mon, 10 Jun 2013 09:37:36 +0100
Subject: [R-SIG-Finance] Monte Carlo simulations for barrier options?
Message-ID: <CADgEnD=dYmqgCKiYvU-_vy2Fotm44vMrv187-4mQ-RT5+zR=Bw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130610/5bb50399/attachment.pl>

From ivanovruporvrich at yahoo.com  Mon Jun 10 18:18:30 2013
From: ivanovruporvrich at yahoo.com (Ivanov Ruporvrich)
Date: Mon, 10 Jun 2013 17:18:30 +0100 (BST)
Subject: [R-SIG-Finance] Computational Time using rugarch package
In-Reply-To: <51B57C43.4000807@4dscape.com>
References: <1370843090.10209.YahooMailNeo@web171506.mail.ir2.yahoo.com>
	<51B57C43.4000807@4dscape.com>
Message-ID: <1370881110.47120.YahooMailNeo@web171504.mail.ir2.yahoo.com>



Thanks a lot for your answer,
I tried your code and run it for 7 hours, but it did not completely suceed:

First of all, I got different warning messages which say:


27: In .makefitmodel(garchmodel = "fGARCH", f = .fgarchLLH,? ... : 
rugarch-->warning: failed to invert hessian


Two warning messages say:
28: In nlminb(start = pars, objective = fun, gradient = gr,? ... :
? unrecognized control elements named ?tol? ignored

One further message says:
30: In .rollfdensity(spec = spec, data = data, n.ahead = n.ahead,? ... : 
non-converged estimation windows present...resubsmit object with different solver parameters...


If I want to look at the output via the show() command, I get the message:
Object contains non-converged estimation windows. Use resume method to re-estimate.


So my question now is: How can I reestimate just the windows which did not converge? So how do I have to apply the resume method in this case?

From your excellent short "a-short-introduction-to-the-rugarch-package" of the unstarched homepage it says:


"A key feature of this method is the existence of a rescue method called resume which allows the resumption of the estimation when there are 
non-converged windows, by submitting the resulting object into resume 
with the option of using a different solver, control parameters etc. 
This process can be continued until all windows converge, thus not 
wasting time and resources by having to resubmit the whole problem from 
scratch."

But I don't know how to code this in my case? So what options do I have to take and what code should I run?


Thanks a lot again for your help,
Ivanov




________________________________
Von: alexios ghalanos <alexios at 4dscape.com>
An: Ivanov Ruporvrich <ivanovruporvrich at yahoo.com> 
CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>; alexios at 4dscape.com 
Gesendet: 9:12 Montag, 10.Juni 2013
Betreff: Re: [R-SIG-Finance] Computational Time using rugarch package



You say that you are aware that more observations would be better to get more consistent estimates, yet you
use a moving window of size 262 on a highly non-linear variant of
??????GARCH (NAGARCH) with a non-normal distribution, 
and you wonder WHY you have difficulty in estimating the model? 

This issue of dataset size has been extensively covered in this
??????forum in the past (and very recently in fact), and in the 
FAQ of the vignette where suggestions are also made about the use
??????of the scaling option, setting
solver parameters or using alternative solvers.

-Alexios

Try:
rollmodel = ugarchroll(garchspecification, mydata, n.start=262,
?????????????????????? refit.every = 1, refit.window = 'moving',
??????window.size = 262,
?????????????????????? calculate.VaR = TRUE, keep.coef = TRUE,
??????solver.control=list(tol=1e-6, trace=1), fit.control=list(scale=1))

On 06/10/2013 08:44 AM, Ivanov Ruporvrich wrote:

Hi,
I am using the rugarch package in R and I have a certain model, which I want to reestimate on a daily basis using ugarchroll. I am aware of the fact, that my problem is caused by the reason, that I do the reestimation daily, but since I really need the daily reestimation I cannot change this parameter (change to an higher number). My problem is, that reestimation on a daily basis takes a lot of time. I ran my pc for 7 hours but I did not get a result, when I pressed ESC I got 4 or 5 warning messages that the hessian could not be inverted. So my main question is: Is there any chance to get this estimation running? Maybe change the solver or something like that? I do not have a problem with running R for like 6 hours or so, at least if I get a result afterwards. My R code is: (I use 262 observations for each window, I am aware of the fact, that 
more observations would be better in order to get more consistent 
estimates.) library(rugarch) garchspecification<-ugarchspec(variance.model = list(model="fGARCH",submodel="NAGARCH", garchOrder = c(1, 1)), 
mean.model = list(armaOrder = c(1, 0), include.mean = FALSE), 
distribution.model = "ged") rollmodel = ugarchroll(garchspecification, mydata, n.start=262,
?refit.every = 1, refit.window = 'moving', window.size = 262,
? calculate.VaR = TRUE, keep.coef = TRUE) I attached the data. Thanks a lot for your help,
Ivanov 
>
>
>_______________________________________________ R-SIG-Finance at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance -- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


From alexios at 4dscape.com  Mon Jun 10 18:27:15 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Mon, 10 Jun 2013 19:27:15 +0300
Subject: [R-SIG-Finance] Computational Time using rugarch package
In-Reply-To: <1370881110.47120.YahooMailNeo@web171504.mail.ir2.yahoo.com>
References: <1370843090.10209.YahooMailNeo@web171506.mail.ir2.yahoo.com>
	<51B57C43.4000807@4dscape.com>
	<1370881110.47120.YahooMailNeo@web171504.mail.ir2.yahoo.com>
Message-ID: <51B5FE63.5000808@4dscape.com>

Assume the object you tried to estimate is called 'roll'.

Then do the following:

roll = resume(roll, solver="gosolnp")

The 'resume' method takes a uGARCHroll object which contains 
non-converged 'windows' and re-estimates
them subject to additional options (e.g. different solver, control 
options, starting parameters in a revised
uGARCHspec etc).

You might also like to read the post on rolling GARCH forecasts which 
explains how to 'roll your own' rolling forecast:
http://www.unstarched.net/2012/12/26/rolling-garch-forecasts/

-Alexios

On 06/10/2013 07:18 PM, Ivanov Ruporvrich wrote:
>
> Thanks a lot for your answer,
> I tried your code and run it for 7 hours, but it did not completely suceed:
>
> First of all, I got different warning messages which say:
>
>
> 27: In .makefitmodel(garchmodel = "fGARCH", f = .fgarchLLH,  ... :
> rugarch-->warning: failed to invert hessian
>
>
> Two warning messages say:
> 28: In nlminb(start = pars, objective = fun, gradient = gr,  ... :
>    unrecognized control elements named ?tol? ignored
>
> One further message says:
> 30: In .rollfdensity(spec = spec, data = data, n.ahead = n.ahead,  ... :
> non-converged estimation windows present...resubsmit object with different solver parameters...
>
>
> If I want to look at the output via the show() command, I get the message:
> Object contains non-converged estimation windows. Use resume method to re-estimate.
>
>
> So my question now is: How can I reestimate just the windows which did not converge? So how do I have to apply the resume method in this case?
>
>  From your excellent short "a-short-introduction-to-the-rugarch-package" of the unstarched homepage it says:
>
>
> "A key feature of this method is the existence of a rescue method called resume which allows the resumption of the estimation when there are
> non-converged windows, by submitting the resulting object into resume
> with the option of using a different solver, control parameters etc.
> This process can be continued until all windows converge, thus not
> wasting time and resources by having to resubmit the whole problem from
> scratch."
>
> But I don't know how to code this in my case? So what options do I have to take and what code should I run?
>
>
> Thanks a lot again for your help,
> Ivanov
>
>
>
>
> ________________________________
> Von: alexios ghalanos <alexios at 4dscape.com>
> An: Ivanov Ruporvrich <ivanovruporvrich at yahoo.com>
> CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>; alexios at 4dscape.com
> Gesendet: 9:12 Montag, 10.Juni 2013
> Betreff: Re: [R-SIG-Finance] Computational Time using rugarch package
>
>
>
> You say that you are aware that more observations would be better to get more consistent estimates, yet you
> use a moving window of size 262 on a highly non-linear variant of
>        GARCH (NAGARCH) with a non-normal distribution,
> and you wonder WHY you have difficulty in estimating the model?
>
> This issue of dataset size has been extensively covered in this
>        forum in the past (and very recently in fact), and in the
> FAQ of the vignette where suggestions are also made about the use
>        of the scaling option, setting
> solver parameters or using alternative solvers.
>
> -Alexios
>
> Try:
> rollmodel = ugarchroll(garchspecification, mydata, n.start=262,
>                         refit.every = 1, refit.window = 'moving',
>        window.size = 262,
>                         calculate.VaR = TRUE, keep.coef = TRUE,
>        solver.control=list(tol=1e-6, trace=1), fit.control=list(scale=1))
>
> On 06/10/2013 08:44 AM, Ivanov Ruporvrich wrote:
>
> Hi,
> I am using the rugarch package in R and I have a certain model, which I want to reestimate on a daily basis using ugarchroll. I am aware of the fact, that my problem is caused by the reason, that I do the reestimation daily, but since I really need the daily reestimation I cannot change this parameter (change to an higher number). My problem is, that reestimation on a daily basis takes a lot of time. I ran my pc for 7 hours but I did not get a result, when I pressed ESC I got 4 or 5 warning messages that the hessian could not be inverted. So my main question is: Is there any chance to get this estimation running? Maybe change the solver or something like that? I do not have a problem with running R for like 6 hours or so, at least if I get a result afterwards. My R code is: (I use 262 observations for each window, I am aware of the fact, that
> more observations would be better in order to get more consistent
> estimates.) library(rugarch) garchspecification<-ugarchspec(variance.model = list(model="fGARCH",submodel="NAGARCH", garchOrder = c(1, 1)),
> mean.model = list(armaOrder = c(1, 0), include.mean = FALSE),
> distribution.model = "ged") rollmodel = ugarchroll(garchspecification, mydata, n.start=262,
>   refit.every = 1, refit.window = 'moving', window.size = 262,
>    calculate.VaR = TRUE, keep.coef = TRUE) I attached the data. Thanks a lot for your help,
> Ivanov
>>
>> _______________________________________________ R-SIG-Finance at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From alexios at 4dscape.com  Mon Jun 10 18:33:15 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Mon, 10 Jun 2013 19:33:15 +0300
Subject: [R-SIG-Finance] Computational Time using rugarch package
In-Reply-To: <51B5FE63.5000808@4dscape.com>
References: <1370843090.10209.YahooMailNeo@web171506.mail.ir2.yahoo.com>
	<51B57C43.4000807@4dscape.com>
	<1370881110.47120.YahooMailNeo@web171504.mail.ir2.yahoo.com>
	<51B5FE63.5000808@4dscape.com>
Message-ID: <51B5FFCB.9040407@4dscape.com>

I forgot to mention that you can also use a cluster object (if you have 
the computational resources) to speed things up so that
you don't wait '7 hours' for the 2308 re-estimations of the model.

-Alexios

On 06/10/2013 07:27 PM, alexios ghalanos wrote:
> Assume the object you tried to estimate is called 'roll'.
>
> Then do the following:
>
> roll = resume(roll, solver="gosolnp")
>
> The 'resume' method takes a uGARCHroll object which contains 
> non-converged 'windows' and re-estimates
> them subject to additional options (e.g. different solver, control 
> options, starting parameters in a revised
> uGARCHspec etc).
>
> You might also like to read the post on rolling GARCH forecasts which 
> explains how to 'roll your own' rolling forecast:
> http://www.unstarched.net/2012/12/26/rolling-garch-forecasts/
>
> -Alexios
>
> On 06/10/2013 07:18 PM, Ivanov Ruporvrich wrote:
>>
>> Thanks a lot for your answer,
>> I tried your code and run it for 7 hours, but it did not completely 
>> suceed:
>>
>> First of all, I got different warning messages which say:
>>
>>
>> 27: In .makefitmodel(garchmodel = "fGARCH", f = .fgarchLLH,  ... :
>> rugarch-->warning: failed to invert hessian
>>
>>
>> Two warning messages say:
>> 28: In nlminb(start = pars, objective = fun, gradient = gr,  ... :
>>    unrecognized control elements named ?tol? ignored
>>
>> One further message says:
>> 30: In .rollfdensity(spec = spec, data = data, n.ahead = n.ahead,  ... :
>> non-converged estimation windows present...resubsmit object with 
>> different solver parameters...
>>
>>
>> If I want to look at the output via the show() command, I get the 
>> message:
>> Object contains non-converged estimation windows. Use resume method 
>> to re-estimate.
>>
>>
>> So my question now is: How can I reestimate just the windows which 
>> did not converge? So how do I have to apply the resume method in this 
>> case?
>>
>>  From your excellent short 
>> "a-short-introduction-to-the-rugarch-package" of the unstarched 
>> homepage it says:
>>
>>
>> "A key feature of this method is the existence of a rescue method 
>> called resume which allows the resumption of the estimation when 
>> there are
>> non-converged windows, by submitting the resulting object into resume
>> with the option of using a different solver, control parameters etc.
>> This process can be continued until all windows converge, thus not
>> wasting time and resources by having to resubmit the whole problem from
>> scratch."
>>
>> But I don't know how to code this in my case? So what options do I 
>> have to take and what code should I run?
>>
>>
>> Thanks a lot again for your help,
>> Ivanov
>>
>>
>>
>>
>> ________________________________
>> Von: alexios ghalanos <alexios at 4dscape.com>
>> An: Ivanov Ruporvrich <ivanovruporvrich at yahoo.com>
>> CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>; 
>> alexios at 4dscape.com
>> Gesendet: 9:12 Montag, 10.Juni 2013
>> Betreff: Re: [R-SIG-Finance] Computational Time using rugarch package
>>
>>
>>
>> You say that you are aware that more observations would be better to 
>> get more consistent estimates, yet you
>> use a moving window of size 262 on a highly non-linear variant of
>>        GARCH (NAGARCH) with a non-normal distribution,
>> and you wonder WHY you have difficulty in estimating the model?
>>
>> This issue of dataset size has been extensively covered in this
>>        forum in the past (and very recently in fact), and in the
>> FAQ of the vignette where suggestions are also made about the use
>>        of the scaling option, setting
>> solver parameters or using alternative solvers.
>>
>> -Alexios
>>
>> Try:
>> rollmodel = ugarchroll(garchspecification, mydata, n.start=262,
>>                         refit.every = 1, refit.window = 'moving',
>>        window.size = 262,
>>                         calculate.VaR = TRUE, keep.coef = TRUE,
>>        solver.control=list(tol=1e-6, trace=1), 
>> fit.control=list(scale=1))
>>
>> On 06/10/2013 08:44 AM, Ivanov Ruporvrich wrote:
>>
>> Hi,
>> I am using the rugarch package in R and I have a certain model, which 
>> I want to reestimate on a daily basis using ugarchroll. I am aware of 
>> the fact, that my problem is caused by the reason, that I do the 
>> reestimation daily, but since I really need the daily reestimation I 
>> cannot change this parameter (change to an higher number). My problem 
>> is, that reestimation on a daily basis takes a lot of time. I ran my 
>> pc for 7 hours but I did not get a result, when I pressed ESC I got 4 
>> or 5 warning messages that the hessian could not be inverted. So my 
>> main question is: Is there any chance to get this estimation running? 
>> Maybe change the solver or something like that? I do not have a 
>> problem with running R for like 6 hours or so, at least if I get a 
>> result afterwards. My R code is: (I use 262 observations for each 
>> window, I am aware of the fact, that
>> more observations would be better in order to get more consistent
>> estimates.) library(rugarch) 
>> garchspecification<-ugarchspec(variance.model = 
>> list(model="fGARCH",submodel="NAGARCH", garchOrder = c(1, 1)),
>> mean.model = list(armaOrder = c(1, 0), include.mean = FALSE),
>> distribution.model = "ged") rollmodel = 
>> ugarchroll(garchspecification, mydata, n.start=262,
>>   refit.every = 1, refit.window = 'moving', window.size = 262,
>>    calculate.VaR = TRUE, keep.coef = TRUE) I attached the data. 
>> Thanks a lot for your help,
>> Ivanov
>>>
>>> _______________________________________________ 
>>> R-SIG-Finance at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance -- 
>>> Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R 
>> questions should go.
>


From ivanovruporvrich at yahoo.com  Mon Jun 10 19:10:53 2013
From: ivanovruporvrich at yahoo.com (Ivanov Ruporvrich)
Date: Mon, 10 Jun 2013 18:10:53 +0100 (BST)
Subject: [R-SIG-Finance] Computational Time using rugarch package
In-Reply-To: <51B5FE63.5000808@4dscape.com>
References: <1370843090.10209.YahooMailNeo@web171506.mail.ir2.yahoo.com>
	<51B57C43.4000807@4dscape.com>
	<1370881110.47120.YahooMailNeo@web171504.mail.ir2.yahoo.com>
	<51B5FE63.5000808@4dscape.com>
Message-ID: <1370884253.71465.YahooMailNeo@web171506.mail.ir2.yahoo.com>

Thanks a lot for your help again,
I did it and I got the message:
"Object contains non-converged estimation windows. Use resume method to re-estimate.
Warning:
In .resumeroll1(object, ...) : 
non-converged estimation windows present...resubsmit object with different solver parameters...
"

If I do show(roll) I still get


Object contains non-converged estimation windows. Use resume method to re-estimate.

What should I do? I guess do it again with different solver parameters but which one?



----- Urspr?ngliche Message -----
Von: alexios ghalanos <alexios at 4dscape.com>
An: Ivanov Ruporvrich <ivanovruporvrich at yahoo.com>
CC: alexios ghalanos <alexios at 4dscape.com>; "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
Gesendet: 18:27 Montag, 10.Juni 2013
Betreff: Re: [R-SIG-Finance] Computational Time using rugarch package

Assume the object you tried to estimate is called 'roll'.

Then do the following:

roll = resume(roll, solver="gosolnp")

The 'resume' method takes a uGARCHroll object which contains 
non-converged 'windows' and re-estimates
them subject to additional options (e.g. different solver, control 
options, starting parameters in a revised
uGARCHspec etc).

You might also like to read the post on rolling GARCH forecasts which 
explains how to 'roll your own' rolling forecast:
http://www.unstarched.net/2012/12/26/rolling-garch-forecasts/

-Alexios

On 06/10/2013 07:18 PM, Ivanov Ruporvrich wrote:
>
> Thanks a lot for your answer,
> I tried your code and run it for 7 hours, but it did not completely suceed:
>
> First of all, I got different warning messages which say:
>
>
> 27: In .makefitmodel(garchmodel = "fGARCH", f = .fgarchLLH,? ... :
> rugarch-->warning: failed to invert hessian
>
>
> Two warning messages say:
> 28: In nlminb(start = pars, objective = fun, gradient = gr,? ... :
>? ? unrecognized control elements named ?tol? ignored
>
> One further message says:
> 30: In .rollfdensity(spec = spec, data = data, n.ahead = n.ahead,? ... :
> non-converged estimation windows present...resubsmit object with different solver parameters...
>
>
> If I want to look at the output via the show() command, I get the message:
> Object contains non-converged estimation windows. Use resume method to re-estimate.
>
>
> So my question now is: How can I reestimate just the windows which did not converge? So how do I have to apply the resume method in this case?
>
>? From your excellent short "a-short-introduction-to-the-rugarch-package" of the unstarched homepage it says:
>
>
> "A key feature of this method is the existence of a rescue method called resume which allows the resumption of the estimation when there are
> non-converged windows, by submitting the resulting object into resume
> with the option of using a different solver, control parameters etc.
> This process can be continued until all windows converge, thus not
> wasting time and resources by having to resubmit the whole problem from
> scratch."
>
> But I don't know how to code this in my case? So what options do I have to take and what code should I run?
>
>
> Thanks a lot again for your help,
> Ivanov
>
>
>
>
> ________________________________
> Von: alexios ghalanos <alexios at 4dscape.com>
> An: Ivanov Ruporvrich <ivanovruporvrich at yahoo.com>
> CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>; alexios at 4dscape.com
> Gesendet: 9:12 Montag, 10.Juni 2013
> Betreff: Re: [R-SIG-Finance] Computational Time using rugarch package
>
>
>
> You say that you are aware that more observations would be better to get more consistent estimates, yet you
> use a moving window of size 262 on a highly non-linear variant of
>? ? ? ? GARCH (NAGARCH) with a non-normal distribution,
> and you wonder WHY you have difficulty in estimating the model?
>
> This issue of dataset size has been extensively covered in this
>? ? ? ? forum in the past (and very recently in fact), and in the
> FAQ of the vignette where suggestions are also made about the use
>? ? ? ? of the scaling option, setting
> solver parameters or using alternative solvers.
>
> -Alexios
>
> Try:
> rollmodel = ugarchroll(garchspecification, mydata, n.start=262,
>? ? ? ? ? ? ? ? ? ? ? ?  refit.every = 1, refit.window = 'moving',
>? ? ? ? window.size = 262,
>? ? ? ? ? ? ? ? ? ? ? ?  calculate.VaR = TRUE, keep.coef = TRUE,
>? ? ? ? solver.control=list(tol=1e-6, trace=1), fit.control=list(scale=1))
>
> On 06/10/2013 08:44 AM, Ivanov Ruporvrich wrote:
>
> Hi,
> I am using the rugarch package in R and I have a certain model, which I want to reestimate on a daily basis using ugarchroll. I am aware of the fact, that my problem is caused by the reason, that I do the reestimation daily, but since I really need the daily reestimation I cannot change this parameter (change to an higher number). My problem is, that reestimation on a daily basis takes a lot of time. I ran my pc for 7 hours but I did not get a result, when I pressed ESC I got 4 or 5 warning messages that the hessian could not be inverted. So my main question is: Is there any chance to get this estimation running? Maybe change the solver or something like that? I do not have a problem with running R for like 6 hours or so, at least if I get a result afterwards. My R code is: (I use 262 observations for each window, I am aware of the fact, that
> more observations would be better in order to get more consistent
> estimates.) library(rugarch) garchspecification<-ugarchspec(variance.model = list(model="fGARCH",submodel="NAGARCH", garchOrder = c(1, 1)),
> mean.model = list(armaOrder = c(1, 0), include.mean = FALSE),
> distribution.model = "ged") rollmodel = ugarchroll(garchspecification, mydata, n.start=262,
>?  refit.every = 1, refit.window = 'moving', window.size = 262,
>? ? calculate.VaR = TRUE, keep.coef = TRUE) I attached the data. Thanks a lot for your help,
> Ivanov
>>
>> _______________________________________________ R-SIG-Finance at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From ivanovruporvrich at yahoo.com  Mon Jun 10 19:56:00 2013
From: ivanovruporvrich at yahoo.com (Ivanov Ruporvrich)
Date: Mon, 10 Jun 2013 18:56:00 +0100 (BST)
Subject: [R-SIG-Finance] Computational Time using rugarch package
In-Reply-To: <51B5FE63.5000808@4dscape.com>
References: <1370843090.10209.YahooMailNeo@web171506.mail.ir2.yahoo.com>
	<51B57C43.4000807@4dscape.com>
	<1370881110.47120.YahooMailNeo@web171504.mail.ir2.yahoo.com>
	<51B5FE63.5000808@4dscape.com>
Message-ID: <1370886960.20022.YahooMailNeo@web171506.mail.ir2.yahoo.com>

Sorry for bothering you again, but I now also tried

resume(rollalv,solver="hybrid")

,because in the manual it says this one tries different solvers, but still I get two error messages in which cases it says:

"failed to invert hessian"



----- Urspr?ngliche Message -----
Von: alexios ghalanos <alexios at 4dscape.com>
An: Ivanov Ruporvrich <ivanovruporvrich at yahoo.com>
CC: alexios ghalanos <alexios at 4dscape.com>; "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
Gesendet: 18:27 Montag, 10.Juni 2013
Betreff: Re: [R-SIG-Finance] Computational Time using rugarch package

Assume the object you tried to estimate is called 'roll'.

Then do the following:

roll = resume(roll, solver="gosolnp")

The 'resume' method takes a uGARCHroll object which contains 
non-converged 'windows' and re-estimates
them subject to additional options (e.g. different solver, control 
options, starting parameters in a revised
uGARCHspec etc).

You might also like to read the post on rolling GARCH forecasts which 
explains how to 'roll your own' rolling forecast:
http://www.unstarched.net/2012/12/26/rolling-garch-forecasts/

-Alexios

On 06/10/2013 07:18 PM, Ivanov Ruporvrich wrote:
>
> Thanks a lot for your answer,
> I tried your code and run it for 7 hours, but it did not completely suceed:
>
> First of all, I got different warning messages which say:
>
>
> 27: In .makefitmodel(garchmodel = "fGARCH", f = .fgarchLLH,? ... :
> rugarch-->warning: failed to invert hessian
>
>
> Two warning messages say:
> 28: In nlminb(start = pars, objective = fun, gradient = gr,? ... :
>? ? unrecognized control elements named ?tol? ignored
>
> One further message says:
> 30: In .rollfdensity(spec = spec, data = data, n.ahead = n.ahead,? ... :
> non-converged estimation windows present...resubsmit object with different solver parameters...
>
>
> If I want to look at the output via the show() command, I get the message:
> Object contains non-converged estimation windows. Use resume method to re-estimate.
>
>
> So my question now is: How can I reestimate just the windows which did not converge? So how do I have to apply the resume method in this case?
>
>? From your excellent short "a-short-introduction-to-the-rugarch-package" of the unstarched homepage it says:
>
>
> "A key feature of this method is the existence of a rescue method called resume which allows the resumption of the estimation when there are
> non-converged windows, by submitting the resulting object into resume
> with the option of using a different solver, control parameters etc.
> This process can be continued until all windows converge, thus not
> wasting time and resources by having to resubmit the whole problem from
> scratch."
>
> But I don't know how to code this in my case? So what options do I have to take and what code should I run?
>
>
> Thanks a lot again for your help,
> Ivanov
>
>
>
>
> ________________________________
> Von: alexios ghalanos <alexios at 4dscape.com>
> An: Ivanov Ruporvrich <ivanovruporvrich at yahoo.com>
> CC: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>; alexios at 4dscape.com
> Gesendet: 9:12 Montag, 10.Juni 2013
> Betreff: Re: [R-SIG-Finance] Computational Time using rugarch package
>
>
>
> You say that you are aware that more observations would be better to get more consistent estimates, yet you
> use a moving window of size 262 on a highly non-linear variant of
>? ? ? ? GARCH (NAGARCH) with a non-normal distribution,
> and you wonder WHY you have difficulty in estimating the model?
>
> This issue of dataset size has been extensively covered in this
>? ? ? ? forum in the past (and very recently in fact), and in the
> FAQ of the vignette where suggestions are also made about the use
>? ? ? ? of the scaling option, setting
> solver parameters or using alternative solvers.
>
> -Alexios
>
> Try:
> rollmodel = ugarchroll(garchspecification, mydata, n.start=262,
>? ? ? ? ? ? ? ? ? ? ? ?  refit.every = 1, refit.window = 'moving',
>? ? ? ? window.size = 262,
>? ? ? ? ? ? ? ? ? ? ? ?  calculate.VaR = TRUE, keep.coef = TRUE,
>? ? ? ? solver.control=list(tol=1e-6, trace=1), fit.control=list(scale=1))
>
> On 06/10/2013 08:44 AM, Ivanov Ruporvrich wrote:
>
> Hi,
> I am using the rugarch package in R and I have a certain model, which I want to reestimate on a daily basis using ugarchroll. I am aware of the fact, that my problem is caused by the reason, that I do the reestimation daily, but since I really need the daily reestimation I cannot change this parameter (change to an higher number). My problem is, that reestimation on a daily basis takes a lot of time. I ran my pc for 7 hours but I did not get a result, when I pressed ESC I got 4 or 5 warning messages that the hessian could not be inverted. So my main question is: Is there any chance to get this estimation running? Maybe change the solver or something like that? I do not have a problem with running R for like 6 hours or so, at least if I get a result afterwards. My R code is: (I use 262 observations for each window, I am aware of the fact, that
> more observations would be better in order to get more consistent
> estimates.) library(rugarch) garchspecification<-ugarchspec(variance.model = list(model="fGARCH",submodel="NAGARCH", garchOrder = c(1, 1)),
> mean.model = list(armaOrder = c(1, 0), include.mean = FALSE),
> distribution.model = "ged") rollmodel = ugarchroll(garchspecification, mydata, n.start=262,
>?  refit.every = 1, refit.window = 'moving', window.size = 262,
>? ? calculate.VaR = TRUE, keep.coef = TRUE) I attached the data. Thanks a lot for your help,
> Ivanov
>>
>> _______________________________________________ R-SIG-Finance at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From kk2250 at optonline.net  Wed Jun 12 15:05:06 2013
From: kk2250 at optonline.net (Kris)
Date: Wed, 12 Jun 2013 09:05:06 -0400
Subject: [R-SIG-Finance] Monte Carlo simulations for barrier options?
In-Reply-To: <CADgEnD=dYmqgCKiYvU-_vy2Fotm44vMrv187-4mQ-RT5+zR=Bw@mail.gmail.com>
References: <CADgEnD=dYmqgCKiYvU-_vy2Fotm44vMrv187-4mQ-RT5+zR=Bw@mail.gmail.com>
Message-ID: <4F2EABA5-B589-47E7-B31B-9A082792E231@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130612/8473c6a5/attachment.pl>

From alexandbridges at gmail.com  Wed Jun 12 17:31:11 2013
From: alexandbridges at gmail.com (Alexandra Bridges)
Date: Wed, 12 Jun 2013 17:31:11 +0200
Subject: [R-SIG-Finance] Window size in ugarchroll of rugarch package?
Message-ID: <CAJ5rLA9o9HdUOwSFRCF0oVCcfrm9pZ9oukx+F=HYaJNF_nHgqw@mail.gmail.com>

Hi,
I did already a post to the list about another problem and you helped
me out, but this time, I have problems with understanding the
ugarchroll command:

I want to use a reestimation every day, which uses 400 observations.
The first window should use the first 400 observations. Therefore, I
set n.start to 400 and window.size to 400, my code (the rolling
estimation takes about 2.1 minutes):

library(rugarch)
data(sp500ret)

datamodified<-  subset(sp500ret, row(sp500ret) < 1001)

myspecification<-ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
distribution.model = "norm")

rolling = ugarchroll(myspecification, datamodified, n.start=400,
 refit.every = 1, refit.window = 'moving', window.size = 400,
  calculate.VaR = FALSE, keep.coef = TRUE)

show(rolling)

So the first forecast is for the 401th day, the 1988-10-06.

I now want to verify the results by reestimation one certain window, I
have choosen the third window:

coef(rolling)[[3]]

This window shows, that it uses observations until 1988-10-07 (the
date is the "ending date of each estimation window."). The estimates
output of this window is:

           Estimate   Std. Error  t value     Pr(>|t|)
omega  0.0000148153 1.133298e-05 1.307272 1.911203e-01
alpha1 0.2977622797 1.801401e-01 1.652948 9.834147e-02
beta1  0.6972828253 1.328726e-01 5.247754 1.539647e-07

I now want to reproduce them with one single ugarchfit-command:

thirdwindow<-datamodified[2:402,1]
fitverify<-ugarchfit(spec=myspecification,data=thirdwindow)
coef(fitverify)

This gives the same estimates. BUT this uses 401 observations?
length(2:402) is 401 and not just 400? So why is not 3:402 correct? If
I do it with 3:402 it leads to different estimates?

Thanks a lot for your help!

--
Alexa Bridges


From ilya.kipnis at gmail.com  Wed Jun 12 21:15:12 2013
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Wed, 12 Jun 2013 12:15:12 -0700
Subject: [R-SIG-Finance] Warning: timeLastNdayInMonth gets Fridays one week
	off
Message-ID: <CA+oJuEGK5FhtTmJDZ1hUtxeH9_8L9Yzd1jo2vi0hjAqZZc6MCg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130612/6409111c/attachment.pl>

From es at enricoschumann.net  Thu Jun 13 07:54:21 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Thu, 13 Jun 2013 07:54:21 +0200
Subject: [R-SIG-Finance] Warning: timeLastNdayInMonth gets Fridays one
	week off
In-Reply-To: <CA+oJuEGK5FhtTmJDZ1hUtxeH9_8L9Yzd1jo2vi0hjAqZZc6MCg@mail.gmail.com>
	(Ilya Kipnis's message of "Wed, 12 Jun 2013 12:15:12 -0700")
References: <CA+oJuEGK5FhtTmJDZ1hUtxeH9_8L9Yzd1jo2vi0hjAqZZc6MCg@mail.gmail.com>
Message-ID: <874nd28sj6.fsf@enricoschumann.net>

On Wed, 12 Jun 2013, Ilya Kipnis <ilya.kipnis at gmail.com> writes:

> For those of you looking to find the last Fridays in a month (quarter,
> etc.), I just wanted to issue a warning about using the timeLastNdayInMonth
> function.  For instance, run these lines:
>
>  #dates<-seq(as.Date("2010-01-01"),as.Date("2013-04-02"),by="day") test case
>   friDates<-dates[which(weekdays(dates)=="Friday")]
>   buggedLastMonthlyFridays<-unique(timeLastNdayInMonth(friDates,5)) #gives
> one week after the last friday of the month
>
> and one will notice that the dates are often at the beginning of the next
> month.  This is my fix:
>
> buggedLastMonthlyFridays[which(as.numeric(substr(buggedLastMonthlyFridays,9,10))<20)]<-
>
> as.Date(buggedLastMonthlyFridays[which(as.numeric(substr(buggedLastMonthlyFridays,9,10))<20)])-7
>
> It's not exactly pretty, but I hope this helps someone out there.
>
> -Ilya Kipnis
>

I suppose the 'timeLastNdayInMonth' function is from a package?  Then you
should also contact directly the package's maintainer.



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From alexandre.piche at mail.mcgill.ca  Thu Jun 13 11:42:53 2013
From: alexandre.piche at mail.mcgill.ca (AlexPiche)
Date: Thu, 13 Jun 2013 02:42:53 -0700 (PDT)
Subject: [R-SIG-Finance] RQuantLib setCalendarContext
Message-ID: <1371116573787-4669436.post@n4.nabble.com>

Hello Folks,

I have problem with setting a calendar in RQuantLib, since I want to use the
french calendar which is not recognized by the package. I find a calendar
that I convert to string, but entering the following command :

>setCalendarContext(FR)

I have the following error message

Error: Calendar 1980-01-01, 1980-04-07, 1980-05-01, 1980-05-08, 1980-05-15,
1980-05-26, 1980-07-14, 1980-08-15, 1980-11-11, 1980-12-25, 1981-01-01,
1981-04-20, 1981-05-01, 1981-05-08, 1981-05-28, 1981-06-08, 1981-07-14,
1981-11-11, 1981-12-25, 1982-01-01, 1982-04-12, 1982-05-20, 1982-05-31,
1982-07-14, 1982-11-01, 1982-11-11, 1983-04-04, 1983-05-12, 1983-05-23,
1983-07-14, 1983-08-15, 1983-11-01, 1983-11-11, 1984-04-23, 1984-05-01,
1984-05-08, 1984-05-31, 1984-06-11, 1984-08-15, 1984-11-01, 1984-12-25,
1985-01-01, 1985-04-08, 1985-05-01, 1985-05-08, 1985-05-16, 1985-05-27,
1985-08-15, 1985-11-01, 1985-11-11, 1985-12-25, 1986-01-01, 1986-03-31,
1986-05-01, 1986-05-08, 1986-05-19, 1986-07-14, 1986-08-15, 1986-11-11,
1986-12-25, 1987-01-01, 1987-04-20, 1987-05-01, 1987-05-08, 1987-05-28,
1987-06-08, 1987-07-14, 1987-11-11, 1987-12-25, 1988-01-01, 1988-04-04,
1988-05-12, 1988-05-23, 1988-07-14, 1988-08-15, 1988-11-01, 1988-11-11,
1989-03-27, 1989-05-01, 1989-05-04, 1989-05-08, 1989-05-15,

Anyone can give me a hand on that?

Regards,

Alex



--
View this message in context: http://r.789695.n4.nabble.com/RQuantLib-setCalendarContext-tp4669436.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From ganesha0701 at gmail.com  Fri Jun 14 11:07:47 2013
From: ganesha0701 at gmail.com (ganesha0701)
Date: Fri, 14 Jun 2013 04:07:47 -0500
Subject: [R-SIG-Finance] Questions on stationarity and johansen test.
Message-ID: <CA+j8qo26XWGyVL11etHiauuVkDKFMxigMi0LLx5GwdEpdcRXpA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130614/57be279b/attachment.pl>

From optionsraghu at gmail.com  Fri Jun 14 17:27:21 2013
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Fri, 14 Jun 2013 16:27:21 +0100
Subject: [R-SIG-Finance] Monte Carlo simulations for barrier options?
In-Reply-To: <4F2EABA5-B589-47E7-B31B-9A082792E231@optonline.net>
References: <CADgEnD=dYmqgCKiYvU-_vy2Fotm44vMrv187-4mQ-RT5+zR=Bw@mail.gmail.com>
	<4F2EABA5-B589-47E7-B31B-9A082792E231@optonline.net>
Message-ID: <CADgEnDnvKWS_oFchac7wK0eX9rcRd-73M6JjmVPGA-1k1tNyMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130614/39ff953c/attachment.pl>

From ganesha0701 at gmail.com  Fri Jun 14 18:09:25 2013
From: ganesha0701 at gmail.com (ganesha0701)
Date: Fri, 14 Jun 2013 11:09:25 -0500
Subject: [R-SIG-Finance] Cointegration question.
Message-ID: <CA+j8qo1q59LMEm_xK22oXu_xQZcDccDrs4DZAj3x+ZXi8P0BNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130614/704c14e8/attachment.pl>

From brian at braverock.com  Fri Jun 14 18:14:12 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 14 Jun 2013 11:14:12 -0500
Subject: [R-SIG-Finance] Cointegration question.
In-Reply-To: <CA+j8qo1q59LMEm_xK22oXu_xQZcDccDrs4DZAj3x+ZXi8P0BNw@mail.gmail.com>
References: <CA+j8qo1q59LMEm_xK22oXu_xQZcDccDrs4DZAj3x+ZXi8P0BNw@mail.gmail.com>
Message-ID: <51BB4154.3030701@braverock.com>

Please don't repost.  If someone has the answer to your question and 
feels like helping, they will.

The most common problem we see in the list archives when questions like 
this arise is that people are trying to test stationarity and 
cointegration on prices rather than on returns.

However, you haven't actually provided reproducible data with your 
partial code, so without that I'm just guessing.

  - Brian

On 06/14/2013 11:09 AM, ganesha0701 wrote:
> I have two time series that I am investigating, acc and amb, the time
> frequency is daily data. They are both non stationary, as evidenced by the
> follows.
>
>
>
> adf.test(df$acc)
>
>          Augmented Dickey-Fuller Test
>
> data:  df$acc
> Dickey-Fuller = -2.7741, Lag order = 5, p-value = 0.2519
> alternative hypothesis: stationary
>
>> adf.test(df$amb)
>
>          Augmented Dickey-Fuller Test
>
> data:  df$amb
> Dickey-Fuller = -1.9339, Lag order = 5, p-value = 0.6038
> alternative hypothesis: stationary
>
> I am looking to test for cointegration between the two time series but the
> problem I am running into is that the cointegrating vector seems to change
> in time.
>
>
> 1)* First 200 points*
>
> ######################
> # Johansen-Procedure #
> ######################
>
> Test type: maximal eigenvalue statistic (lambda max) , with linear trend
>
> Eigenvalues (lambda):
> [1] 0.0501585398 0.0003129906
>
> Values of teststatistic and critical values of test:
>
>            test 10pct  5pct  1pct
> r <= 1 |  0.06  6.50  8.18 11.65
> r = 0  | 10.19 12.91 14.90 19.19
>
> Eigenvectors, normalised to first column:
> (These are the cointegration relations)
>
>             acc.l2    amb.l2
> acc.l2  1.0000000  1.000000
> amb.l2 -0.9610573 -2.237141
>
> Weights W:
> (This is the loading matrix)
>
>             acc.l2       amb.l2
> acc.d -0.03332428 -0.002576070
> amb.d  0.03986111 -0.001591227
>
>
> 2) *First 1000 points*
>
> ######################
> # Johansen-Procedure #
> ######################
>
> Test type: maximal eigenvalue statistic (lambda max) , with linear trend
>
> Eigenvalues (lambda):
> [1] 0.019211132 0.001959403
>
> Values of teststatistic and critical values of test:
>
>            test 10pct  5pct  1pct
> r <= 1 |  1.96  6.50  8.18 11.65
> r = 0  | 19.36 12.91 14.90 19.19
>
> Eigenvectors, normalised to first column:
> (These are the cointegration relations)
>
>             acc.l2   amb.l2
> acc.l2  1.0000000  1.00000
> amb.l2 -0.8611314 15.76683
>
> Weights W:
> (This is the loading matrix)
>
>              acc.l2        amb.l2
> acc.d -0.008993595 -0.0002419353
> amb.d  0.027935684 -0.0002067523
>
>
> 3)* Whole History*
>
> ######################
> # Johansen-Procedure #
> ######################
>
> Test type: maximal eigenvalue statistic (lambda max) , with linear trend
>
> Eigenvalues (lambda):
> [1] 0.0144066813 0.0008146258
>
> Values of teststatistic and critical values of test:
>
>            test 10pct  5pct  1pct
> r <= 1 |  1.16  6.50  8.18 11.65
> r = 0  | 20.64 12.91 14.90 19.19
>
> Eigenvectors, normalised to first column:
> (These are the cointegration relations)
>
>             acc.l2    amb.l2
> acc.l2  1.0000000   1.00000
> amb.l2 -0.8051537 -25.42806
>
> Weights W:
> (This is the loading matrix)
>
>             acc.l2       amb.l2
> acc.d -0.01003068 7.009487e-05
> amb.d  0.02128464 6.980209e-05
>
> You can see the marginal change the coefficient values, from -0.96 to -0.86
> to -0.80.
>
> My question is how to interpret this, what is the optimal look back period,
> what is the true relationship I should use for future prediction?
>


From wlmr at zhaw.ch  Sat Jun 15 08:54:52 2013
From: wlmr at zhaw.ch (Wildi Marc (wlmr))
Date: Sat, 15 Jun 2013 06:54:52 +0000
Subject: [R-SIG-Finance] Cointegration question.
In-Reply-To: <51BB4154.3030701@braverock.com>
References: <CA+j8qo1q59LMEm_xK22oXu_xQZcDccDrs4DZAj3x+ZXi8P0BNw@mail.gmail.com>,
	<51BB4154.3030701@braverock.com>
Message-ID: <E2339A3600811248AB525B8FAB3A1BCE98789ACD@srv-mail-101.zhaw.ch>

Ganesha, Brian, All

The log-return transformation typically eliminates trends of `prices' (the latter should behave not too far away from a random-walk although we all know that's not entirely true because otherwise this Mailing list wouldn't exist).  Therefore the empirical significance Level of the ADF-test should be markedly below 5% for log-Returns (except if there is/are shift(s) in the transformed data!). The posted results (25%) strongly suggest Prices (not log-Returns).

Cointegration: this is an econometrician tool developped for `stable' (difference-stationary Gaussian) series which `behave well' over longer time spans: Forget about application of this very sensitive stuff to non-stationary financial data. Prices are not difference-stationary! Econometrician are interested in the DGP (data generating process), not in generating trading performances: therefore typical optimization criteria are misleading: all statistics address one-step ahead mean-square performances; who in the world (besides econometrician) is interested in such a criterion?

My advice: skip this unreliable Topic and save some time for leisure!

Marc 

________________________________________
Von: r-sig-finance-bounces at r-project.org [r-sig-finance-bounces at r-project.org]&quot; im Auftrag von &quot;Brian G. Peterson [brian at braverock.com]
Gesendet: Freitag, 14. Juni 2013 18:14
An: r-sig-finance at r-project.org
Betreff: Re: [R-SIG-Finance] Cointegration question.

Please don't repost.  If someone has the answer to your question and
feels like helping, they will.

The most common problem we see in the list archives when questions like
this arise is that people are trying to test stationarity and
cointegration on prices rather than on returns.

However, you haven't actually provided reproducible data with your
partial code, so without that I'm just guessing.

  - Brian

On 06/14/2013 11:09 AM, ganesha0701 wrote:
> I have two time series that I am investigating, acc and amb, the time
> frequency is daily data. They are both non stationary, as evidenced by the
> follows.
>
>
>
> adf.test(df$acc)
>
>          Augmented Dickey-Fuller Test
>
> data:  df$acc
> Dickey-Fuller = -2.7741, Lag order = 5, p-value = 0.2519
> alternative hypothesis: stationary
>
>> adf.test(df$amb)
>
>          Augmented Dickey-Fuller Test
>
> data:  df$amb
> Dickey-Fuller = -1.9339, Lag order = 5, p-value = 0.6038
> alternative hypothesis: stationary
>
> I am looking to test for cointegration between the two time series but the
> problem I am running into is that the cointegrating vector seems to change
> in time.
>
>
> 1)* First 200 points*
>
> ######################
> # Johansen-Procedure #
> ######################
>
> Test type: maximal eigenvalue statistic (lambda max) , with linear trend
>
> Eigenvalues (lambda):
> [1] 0.0501585398 0.0003129906
>
> Values of teststatistic and critical values of test:
>
>            test 10pct  5pct  1pct
> r <= 1 |  0.06  6.50  8.18 11.65
> r = 0  | 10.19 12.91 14.90 19.19
>
> Eigenvectors, normalised to first column:
> (These are the cointegration relations)
>
>             acc.l2    amb.l2
> acc.l2  1.0000000  1.000000
> amb.l2 -0.9610573 -2.237141
>
> Weights W:
> (This is the loading matrix)
>
>             acc.l2       amb.l2
> acc.d -0.03332428 -0.002576070
> amb.d  0.03986111 -0.001591227
>
>
> 2) *First 1000 points*
>
> ######################
> # Johansen-Procedure #
> ######################
>
> Test type: maximal eigenvalue statistic (lambda max) , with linear trend
>
> Eigenvalues (lambda):
> [1] 0.019211132 0.001959403
>
> Values of teststatistic and critical values of test:
>
>            test 10pct  5pct  1pct
> r <= 1 |  1.96  6.50  8.18 11.65
> r = 0  | 19.36 12.91 14.90 19.19
>
> Eigenvectors, normalised to first column:
> (These are the cointegration relations)
>
>             acc.l2   amb.l2
> acc.l2  1.0000000  1.00000
> amb.l2 -0.8611314 15.76683
>
> Weights W:
> (This is the loading matrix)
>
>              acc.l2        amb.l2
> acc.d -0.008993595 -0.0002419353
> amb.d  0.027935684 -0.0002067523
>
>
> 3)* Whole History*
>
> ######################
> # Johansen-Procedure #
> ######################
>
> Test type: maximal eigenvalue statistic (lambda max) , with linear trend
>
> Eigenvalues (lambda):
> [1] 0.0144066813 0.0008146258
>
> Values of teststatistic and critical values of test:
>
>            test 10pct  5pct  1pct
> r <= 1 |  1.16  6.50  8.18 11.65
> r = 0  | 20.64 12.91 14.90 19.19
>
> Eigenvectors, normalised to first column:
> (These are the cointegration relations)
>
>             acc.l2    amb.l2
> acc.l2  1.0000000   1.00000
> amb.l2 -0.8051537 -25.42806
>
> Weights W:
> (This is the loading matrix)
>
>             acc.l2       amb.l2
> acc.d -0.01003068 7.009487e-05
> amb.d  0.02128464 6.980209e-05
>
> You can see the marginal change the coefficient values, from -0.96 to -0.86
> to -0.80.
>
> My question is how to interpret this, what is the optimal look back period,
> what is the true relationship I should use for future prediction?
>

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.

From alexios at 4dscape.com  Sat Jun 15 09:15:05 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sat, 15 Jun 2013 08:15:05 +0100
Subject: [R-SIG-Finance] Window size in ugarchroll of rugarch package?
In-Reply-To: <CAJ5rLA9o9HdUOwSFRCF0oVCcfrm9pZ9oukx+F=HYaJNF_nHgqw@mail.gmail.com>
References: <CAJ5rLA9o9HdUOwSFRCF0oVCcfrm9pZ9oukx+F=HYaJNF_nHgqw@mail.gmail.com>
Message-ID: <51BC1479.3050005@4dscape.com>

The shortest way to understand how it works and feel confident that it 
DOES what it is supposed to do, is to look at the ugarchroll function, 
which as stated on numerous occasions is a wrapper for ugarchfit and 
ugarchforecast. The code can be obtained by looking in the R directory 
(file: 'rugarch-rolling.R') of the package source or by typing:

rugarch:::.rollfdensity

Regards,
Alexios


On 12/06/2013 16:31, Alexandra Bridges wrote:
> Hi,
> I did already a post to the list about another problem and you helped
> me out, but this time, I have problems with understanding the
> ugarchroll command:
>
> I want to use a reestimation every day, which uses 400 observations.
> The first window should use the first 400 observations. Therefore, I
> set n.start to 400 and window.size to 400, my code (the rolling
> estimation takes about 2.1 minutes):
>
> library(rugarch)
> data(sp500ret)
>
> datamodified<-  subset(sp500ret, row(sp500ret) < 1001)
>
> myspecification<-ugarchspec(variance.model = list(model = "sGARCH",
> garchOrder = c(1, 1)),
> mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
> distribution.model = "norm")
>
> rolling = ugarchroll(myspecification, datamodified, n.start=400,
>   refit.every = 1, refit.window = 'moving', window.size = 400,
>    calculate.VaR = FALSE, keep.coef = TRUE)
>
> show(rolling)
>
> So the first forecast is for the 401th day, the 1988-10-06.
>
> I now want to verify the results by reestimation one certain window, I
> have choosen the third window:
>
> coef(rolling)[[3]]
>
> This window shows, that it uses observations until 1988-10-07 (the
> date is the "ending date of each estimation window."). The estimates
> output of this window is:
>
>             Estimate   Std. Error  t value     Pr(>|t|)
> omega  0.0000148153 1.133298e-05 1.307272 1.911203e-01
> alpha1 0.2977622797 1.801401e-01 1.652948 9.834147e-02
> beta1  0.6972828253 1.328726e-01 5.247754 1.539647e-07
>
> I now want to reproduce them with one single ugarchfit-command:
>
> thirdwindow<-datamodified[2:402,1]
> fitverify<-ugarchfit(spec=myspecification,data=thirdwindow)
> coef(fitverify)
>
> This gives the same estimates. BUT this uses 401 observations?
> length(2:402) is 401 and not just 400? So why is not 3:402 correct? If
> I do it with 3:402 it leads to different estimates?
>
> Thanks a lot for your help!
>
> --
> Alexa Bridges
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From ganesha0701 at gmail.com  Sat Jun 15 14:30:41 2013
From: ganesha0701 at gmail.com (ganesha0701)
Date: Sat, 15 Jun 2013 07:30:41 -0500
Subject: [R-SIG-Finance] Cointegration question.
In-Reply-To: <E2339A3600811248AB525B8FAB3A1BCE98789ACD@srv-mail-101.zhaw.ch>
References: <CA+j8qo1q59LMEm_xK22oXu_xQZcDccDrs4DZAj3x+ZXi8P0BNw@mail.gmail.com>
	<51BB4154.3030701@braverock.com>
	<E2339A3600811248AB525B8FAB3A1BCE98789ACD@srv-mail-101.zhaw.ch>
Message-ID: <CA+j8qo2RS3+BX5arMxXVQ-=fZUmCm5QN-vQpnRuS3DaqD5Ko4g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130615/0d76bf8a/attachment.pl>

From ganesha0701 at gmail.com  Sat Jun 15 15:12:22 2013
From: ganesha0701 at gmail.com (ganesha0701)
Date: Sat, 15 Jun 2013 08:12:22 -0500
Subject: [R-SIG-Finance] Continuous time series in futures.
Message-ID: <CA+j8qo0VALV+=cCPQd80-zRrxzVr9wcu+JJaq=_iFBfWbx-pPA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130615/fb919d6d/attachment.pl>

From bogaso.christofer at gmail.com  Sat Jun 15 16:00:51 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sat, 15 Jun 2013 19:45:51 +0545
Subject: [R-SIG-Finance] Garch Model
Message-ID: <CA+dpOJ=wvFneXrnhKoJ2LnXgLdz_u7MPcV2LHUrcrt7rEmZJwA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130615/b2187ac3/attachment.pl>

From khoxsey at gmail.com  Sat Jun 15 16:15:42 2013
From: khoxsey at gmail.com (Kent Hoxsey)
Date: Sat, 15 Jun 2013 07:15:42 -0700
Subject: [R-SIG-Finance] Cointegration question.
In-Reply-To: <CA+j8qo2RS3+BX5arMxXVQ-=fZUmCm5QN-vQpnRuS3DaqD5Ko4g@mail.gmail.com>
References: <CA+j8qo1q59LMEm_xK22oXu_xQZcDccDrs4DZAj3x+ZXi8P0BNw@mail.gmail.com>
	<51BB4154.3030701@braverock.com>
	<E2339A3600811248AB525B8FAB3A1BCE98789ACD@srv-mail-101.zhaw.ch>
	<CA+j8qo2RS3+BX5arMxXVQ-=fZUmCm5QN-vQpnRuS3DaqD5Ko4g@mail.gmail.com>
Message-ID: <BC8A3F7A-C8CF-4394-806C-DCB8D13364CA@gmail.com>

If you are looking for tools to identify trading pairs, you might start with Bryan Lewis' presentation from R-Finance 2012:

	http://www.rinfinance.com/agenda/2012/talk/BryanLewis.pdf

GL!

On Jun 15, 2013, at 5:30 AM, ganesha0701 wrote:

> Thanks for the inputs Marc. You provide some interesting insights. Yes,
> they are all prices. In my case the prices are very close to difference
> stationary actually. But none the less, any particular tool that you will
> recommend when it comes to testing for pairs trading. That is the ultimate
> application of interest, which is why I was interested in cointegration in
> the first place.
> 
> 
> On Sat, Jun 15, 2013 at 1:54 AM, Wildi Marc (wlmr) <wlmr at zhaw.ch> wrote:
> 
>> Ganesha, Brian, All
>> 
>> The log-return transformation typically eliminates trends of `prices' (the
>> latter should behave not too far away from a random-walk although we all
>> know that's not entirely true because otherwise this Mailing list wouldn't
>> exist).  Therefore the empirical significance Level of the ADF-test should
>> be markedly below 5% for log-Returns (except if there is/are shift(s) in
>> the transformed data!). The posted results (25%) strongly suggest Prices
>> (not log-Returns).
>> 
>> Cointegration: this is an econometrician tool developped for `stable'
>> (difference-stationary Gaussian) series which `behave well' over longer
>> time spans: Forget about application of this very sensitive stuff to
>> non-stationary financial data. Prices are not difference-stationary!
>> Econometrician are interested in the DGP (data generating process), not in
>> generating trading performances: therefore typical optimization criteria
>> are misleading: all statistics address one-step ahead mean-square
>> performances; who in the world (besides econometrician) is interested in
>> such a criterion?
>> 
>> My advice: skip this unreliable Topic and save some time for leisure!
>> 
>> Marc
>> 
>> ________________________________________
>> Von: r-sig-finance-bounces at r-project.org [
>> r-sig-finance-bounces at r-project.org]&quot; im Auftrag von &quot;Brian G.
>> Peterson [brian at braverock.com]
>> Gesendet: Freitag, 14. Juni 2013 18:14
>> An: r-sig-finance at r-project.org
>> Betreff: Re: [R-SIG-Finance] Cointegration question.
>> 
>> Please don't repost.  If someone has the answer to your question and
>> feels like helping, they will.
>> 
>> The most common problem we see in the list archives when questions like
>> this arise is that people are trying to test stationarity and
>> cointegration on prices rather than on returns.
>> 
>> However, you haven't actually provided reproducible data with your
>> partial code, so without that I'm just guessing.
>> 
>>  - Brian
>> 
>> On 06/14/2013 11:09 AM, ganesha0701 wrote:
>>> I have two time series that I am investigating, acc and amb, the time
>>> frequency is daily data. They are both non stationary, as evidenced by
>> the
>>> follows.
>>> 
>>> 
>>> 
>>> adf.test(df$acc)
>>> 
>>>         Augmented Dickey-Fuller Test
>>> 
>>> data:  df$acc
>>> Dickey-Fuller = -2.7741, Lag order = 5, p-value = 0.2519
>>> alternative hypothesis: stationary
>>> 
>>>> adf.test(df$amb)
>>> 
>>>         Augmented Dickey-Fuller Test
>>> 
>>> data:  df$amb
>>> Dickey-Fuller = -1.9339, Lag order = 5, p-value = 0.6038
>>> alternative hypothesis: stationary
>>> 
>>> I am looking to test for cointegration between the two time series but
>> the
>>> problem I am running into is that the cointegrating vector seems to
>> change
>>> in time.
>>> 
>>> 
>>> 1)* First 200 points*
>>> 
>>> ######################
>>> # Johansen-Procedure #
>>> ######################
>>> 
>>> Test type: maximal eigenvalue statistic (lambda max) , with linear trend
>>> 
>>> Eigenvalues (lambda):
>>> [1] 0.0501585398 0.0003129906
>>> 
>>> Values of teststatistic and critical values of test:
>>> 
>>>           test 10pct  5pct  1pct
>>> r <= 1 |  0.06  6.50  8.18 11.65
>>> r = 0  | 10.19 12.91 14.90 19.19
>>> 
>>> Eigenvectors, normalised to first column:
>>> (These are the cointegration relations)
>>> 
>>>            acc.l2    amb.l2
>>> acc.l2  1.0000000  1.000000
>>> amb.l2 -0.9610573 -2.237141
>>> 
>>> Weights W:
>>> (This is the loading matrix)
>>> 
>>>            acc.l2       amb.l2
>>> acc.d -0.03332428 -0.002576070
>>> amb.d  0.03986111 -0.001591227
>>> 
>>> 
>>> 2) *First 1000 points*
>>> 
>>> ######################
>>> # Johansen-Procedure #
>>> ######################
>>> 
>>> Test type: maximal eigenvalue statistic (lambda max) , with linear trend
>>> 
>>> Eigenvalues (lambda):
>>> [1] 0.019211132 0.001959403
>>> 
>>> Values of teststatistic and critical values of test:
>>> 
>>>           test 10pct  5pct  1pct
>>> r <= 1 |  1.96  6.50  8.18 11.65
>>> r = 0  | 19.36 12.91 14.90 19.19
>>> 
>>> Eigenvectors, normalised to first column:
>>> (These are the cointegration relations)
>>> 
>>>            acc.l2   amb.l2
>>> acc.l2  1.0000000  1.00000
>>> amb.l2 -0.8611314 15.76683
>>> 
>>> Weights W:
>>> (This is the loading matrix)
>>> 
>>>             acc.l2        amb.l2
>>> acc.d -0.008993595 -0.0002419353
>>> amb.d  0.027935684 -0.0002067523
>>> 
>>> 
>>> 3)* Whole History*
>>> 
>>> ######################
>>> # Johansen-Procedure #
>>> ######################
>>> 
>>> Test type: maximal eigenvalue statistic (lambda max) , with linear trend
>>> 
>>> Eigenvalues (lambda):
>>> [1] 0.0144066813 0.0008146258
>>> 
>>> Values of teststatistic and critical values of test:
>>> 
>>>           test 10pct  5pct  1pct
>>> r <= 1 |  1.16  6.50  8.18 11.65
>>> r = 0  | 20.64 12.91 14.90 19.19
>>> 
>>> Eigenvectors, normalised to first column:
>>> (These are the cointegration relations)
>>> 
>>>            acc.l2    amb.l2
>>> acc.l2  1.0000000   1.00000
>>> amb.l2 -0.8051537 -25.42806
>>> 
>>> Weights W:
>>> (This is the loading matrix)
>>> 
>>>            acc.l2       amb.l2
>>> acc.d -0.01003068 7.009487e-05
>>> amb.d  0.02128464 6.980209e-05
>>> 
>>> You can see the marginal change the coefficient values, from -0.96 to
>> -0.86
>>> to -0.80.
>>> 
>>> My question is how to interpret this, what is the optimal look back
>> period,
>>> what is the true relationship I should use for future prediction?
>>> 
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From simon.fnb at gmail.com  Sat Jun 15 18:24:00 2013
From: simon.fnb at gmail.com (ousbens)
Date: Sat, 15 Jun 2013 09:24:00 -0700 (PDT)
Subject: [R-SIG-Finance] How to calculate AIC and BIC for GBM and OU
	processes in R
Message-ID: <1371313440031-4669607.post@n4.nabble.com>

I would like to find out if a GBM (Geometric Brownian motion) process or a
mean reverting Ornstein-Uhlenbeck (OU) process fits better to a time series.

To determine this I would like to calculate the AIC, BIC and Log Likelihood
values for the GBM and OU processes (and also for a simple Jump diffusion
process).

How can this be done in R?

Many thanks. 



--
View this message in context: http://r.789695.n4.nabble.com/How-to-calculate-AIC-and-BIC-for-GBM-and-OU-processes-in-R-tp4669607.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From dominykasgrigonis at gmail.com  Sat Jun 15 18:31:54 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sat, 15 Jun 2013 17:31:54 +0100
Subject: [R-SIG-Finance] How to calculate AIC and BIC for GBM and OU
 processes in R
In-Reply-To: <1371313440031-4669607.post@n4.nabble.com>
References: <1371313440031-4669607.post@n4.nabble.com>
Message-ID: <A5D4A2B0DBCF48FFB772E87AEEB7B557@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130615/9f8db82d/attachment.pl>

From rimmer.matt at gmail.com  Sat Jun 15 22:19:11 2013
From: rimmer.matt at gmail.com (Matt Rimmer)
Date: Sat, 15 Jun 2013 21:19:11 +0100
Subject: [R-SIG-Finance] Cointegration question.
In-Reply-To: <BC8A3F7A-C8CF-4394-806C-DCB8D13364CA@gmail.com>
References: <CA+j8qo1q59LMEm_xK22oXu_xQZcDccDrs4DZAj3x+ZXi8P0BNw@mail.gmail.com>
	<51BB4154.3030701@braverock.com>
	<E2339A3600811248AB525B8FAB3A1BCE98789ACD@srv-mail-101.zhaw.ch>
	<CA+j8qo2RS3+BX5arMxXVQ-=fZUmCm5QN-vQpnRuS3DaqD5Ko4g@mail.gmail.com>
	<BC8A3F7A-C8CF-4394-806C-DCB8D13364CA@gmail.com>
Message-ID: <6D51B040-F6C2-45DA-B7E8-70FFAFB4D522@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130615/f69ea301/attachment.pl>

From markleeds2 at gmail.com  Sun Jun 16 03:48:17 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Sat, 15 Jun 2013 21:48:17 -0400
Subject: [R-SIG-Finance] How to calculate AIC and BIC for GBM and OU
 processes in R
In-Reply-To: <A5D4A2B0DBCF48FFB772E87AEEB7B557@gmail.com>
References: <1371313440031-4669607.post@n4.nabble.com>
	<A5D4A2B0DBCF48FFB772E87AEEB7B557@gmail.com>
Message-ID: <CAHz+bWbQRYe-+x0Dej2R8fDL8q0jb29tRRjssXCJvWPH2HDQjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130615/b8ca405f/attachment.pl>

From octubre21_2 at hotmail.com  Sun Jun 16 22:56:16 2013
From: octubre21_2 at hotmail.com (=?ISO-8859-1?Q?Eduardo_Romero_L=F3pez?=)
Date: Sun, 16 Jun 2013 22:56:16 +0200
Subject: [R-SIG-Finance] Error when I run the strategy.
Message-ID: <BLU0-SMTP350955C167D0A63DC65148D9820@phx.gbl>

Hi all,

I am trying to run a strategy very simple.

if Cl() > DonchianChannel(Cl(x), n = xx)[,"mid"]
     Open "long"

Close Trailing Stop

but I do not get to do that strategy works. I get this error:

 > correr.estrategia <- applyStrategy(
+   strategy=objeto.estrategia,
+   portfolios=mi.estrategia
+ )
Error en function (x, xx)  : el argumento(s) no fue utilizado(s) (n = 30)
Adem?s: Mensajes de aviso perdidos
In applyIndicators(strategy = strategy, mktdata = mktdata, parameters = 
parameters,  :
   some arguments stored for f.dc.mid do not match

I am using that code:

mi = as.xts(read.zoo("mini.ibex.csv",
                      sep="\t", format="%d/%m/%y", header=TRUE))
colnames(mi) <- c("Open", "High", "Low", "Close", "Volume")
tail(mi)

currency("USD")
stock("mi", currency='USD',multiplier=1)

mi.estrategia <- "nombre.estrategia"

initPortf(
   mi.estrategia,
   'mi',
   initDate='1997-12-31'
)

initAcct(
   mi.estrategia,
   portfolios=mi.estrategia,
   initDate='1997-12-31',
   initEq=1000
)

initOrders(
   portfolio = mi.estrategia,
   initDate='1997-12-31'
)

objeto.estrategia <- strategy(mi.estrategia, store=TRUE)

mid= 30
threshold=30
txnfees = -6
orderqty = 1000

summary(objeto.estrategia)

f.dc.mid <- function(x,xx){
   a<-DonchianChannel(Cl(x), n = xx)[,"mid"]
   return(a)
}

objeto.estrategia <- add.indicator(
   strategy = objeto.estrategia,
   name = "f.dc.mid",
   arguments = list(x = quote(Cl(mktdata)[,1]), n = mid),
   label="nmid"
)

summary(objeto.estrategia)

objeto.estrategia <- add.signal(
   objeto.estrategia,
   name='sigCrossover',
   arguments = list(columns=c("Close","nmid"),relationship="gt"),
   label='long'
)

summary(objeto.estrategia)

objeto.estrategia <- add.rule(
   objeto.estrategia,
   name='ruleSignal',
   arguments=list(
     sigcol='long',
     sigval=TRUE,
     orderside='long',
     ordertype='market',
     #prefer='High',
     threshold=NULL,
     orderqty= orderqty,
     replace=FALSE
   ),
   type='enter',
   label='EntradaLargo'
)
summary(objeto.estrategia)

objeto.estrategia <- add.rule(
   objeto.estrategia,
   name='ruleSignal',
   arguments = list(
     sigcol="long",
     sigval=TRUE,
     orderqty='all',
     ordertype='stoptrailing',
     orderside='short',
     threshold=-threshold,
     tmult=FALSE,
     orderset='exitTS'
   ),
   type='chain',
   parent='enter',
   label='trailingexit')

summary(objeto.estrategia)

correr.estrategia <- applyStrategy(
   strategy=objeto.estrategia,
   portfolios=mi.estrategia
)

if anyone can help me, thank very much.

Eduardo,


From atp at piskorski.com  Sun Jun 16 23:07:51 2013
From: atp at piskorski.com (Andrew Piskorski)
Date: Sun, 16 Jun 2013 17:07:51 -0400
Subject: [R-SIG-Finance] Continuous time series in futures.
In-Reply-To: <CA+j8qo0VALV+=3DcCPQd80-zRrxzVr9wcu+JJaq=3D_iFBfWbx-pPA@mail.gmail.com>
References: <CA+j8qo0VALV+=3DcCPQd80-zRrxzVr9wcu+JJaq=3D_iFBfWbx-pPA@mail.gmail.com>
Message-ID: <20130616210751.GA78553@piskorski.com>

On Sat, Jun 15, 2013 at 08:12:22AM -0500, ganesha0701 wrote:
> Hi I did go through the previous posts on this topic but still confused. I
> am basically researching on some ideas and need continuous time futures
> data. At any point in time I basically have three futures, F1, F2 F3. They
> basically have monthly, 2 month and 3 month expiries. I have daily OHLC
> data for all of the, but need to create continuous time series.
> 
> I am basically researching on convergence-divergence ideas in price space.
> What is wrong with just the following procedure
> 
> 1) Just grab the F1 price and at the roll data switch to F2 or the new
> front month?

What "roll date"?  You have to pick your roll dates.  In many markets
there are common conventions when everyone rolls, thus all the traders
will know when the roll date is coming up, it's not secret.  But, I
have never seen that knowledge encoded anywhere, and certainly not in
computer readable form.  You typically have to figure it out on your own.

For backtesting strategies that are intended to be continually
invested in whatever the single "live" or "primary" futures contract
is at any given time, I've used a shortest path algorithm to
retrospectively pick the roll path through the highest volume contract
on each day.  (Some markets trade similar volume in a wide range of
contracts, others mostly only trade one contract at a time.  Here I
only wanted to trade one contract at a time.)

That should give you reasonable choices for rolls dates, and is a big
convenience vs. having to manually decide what all those ancient roll
dates should have been.  Of course that only works after the fact
looking backwards, but as long as your strategy isn't trying to profit
from the roll yield it probably won't introduce cheating into your
backtest.

But that probably isn't useful if your strategy is primarily
interested in the price spreads between contracts expiring at
different times (the term structure of one futures market).

> When I went through the papers and discussion on creating continuous
> contract, please correct me if I am wrong but it seemed that the procedure
> is the follows, to get the front month contract.

There are multiple ways to do it.  The usual approach is to "link
prices" using either an additive or multiplicative price adjustment.
The adjustment is simply to remove the price jump due to switching
from the old to the new contract.  And of course you can either adjust
all the old prices to match the current true market price, or the
current prices to match some point in the past, whichever is
operationally more convenient for you.

Morningstar gives a clear and detailed description of the particular
linking procedure they adopted for their commodity indexes, which
seems like as good a place to start as any:

  http://corporate.morningstar.com/US/documents/Indexes/ConstructionRulesCommodityIndex.pdf 
  "Construction Rules for Morningstar Commodity Indexes" 
  Morningstar Methodology Paper Version 3.2, May 31, 2008 

Instead of linking that way, you could also create a synthetic
"perpetual" contract which is always a constant distance from
expiration.  Various textbooks talk about that stuff.  Since you are
interested in the term structure, that may be more what you want.

Or you may be interested solely in the spread between adjacent
contracts, and model that directly.  Some spreads are even traded for
real with their own contracts, so you may want to get direct price
data on those.

They key thing is to think about which information your price linking
process retains and which it discards.  E.g., is the roll yield
included, or assumed to be zero?  You need to pick a linking process
that's appropriate for modeling your particular strategy, calculate
returns correctly, etc.

-- 
Andrew Piskorski <atp at piskorski.com>


From deo.jaiswal at gmail.com  Tue Jun 18 00:08:29 2013
From: deo.jaiswal at gmail.com (Deo Jaiswal)
Date: Mon, 17 Jun 2013 18:08:29 -0400
Subject: [R-SIG-Finance] Error when I run the strategy.
In-Reply-To: <BLU0-SMTP350955C167D0A63DC65148D9820@phx.gbl>
References: <BLU0-SMTP350955C167D0A63DC65148D9820@phx.gbl>
Message-ID: <CAPMHGQyUezKD8unS-y756mtOKCY5sHkmpkeaXHs-p_ecAF+sMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130617/1e19e3e9/attachment.pl>

From iza.ch1 at op.pl  Tue Jun 18 13:07:57 2013
From: iza.ch1 at op.pl (iza.ch1)
Date: Tue, 18 Jun 2013 13:07:57 +0200
Subject: [R-SIG-Finance] Package "eventstudies" and column names
Message-ID: <42362180-d7fc22ee91ff5518202c13b2db8e31ef@pmq5.m5r2.onet>

Hi!

I have a question to you. I am conducting event studies by using the package "eventstudies". I have the problem with transforming the list of results "es". I receive as column names only the numbers 1 2 3 4 etc. Instead I need to have as the column name the company name for which this returns were presented in "es". Does someone know the way to achieve it?

Thank you in advance.

Iza


From economics.vikram at gmail.com  Tue Jun 18 13:45:07 2013
From: economics.vikram at gmail.com (Vikram Bahure)
Date: Tue, 18 Jun 2013 17:15:07 +0530
Subject: [R-SIG-Finance] Package "eventstudies" and column names
In-Reply-To: <42362180-d7fc22ee91ff5518202c13b2db8e31ef@pmq5.m5r2.onet>
References: <42362180-d7fc22ee91ff5518202c13b2db8e31ef@pmq5.m5r2.onet>
Message-ID: <CAEfYxiU4dTLWd4hf2NC-2KV0+ZOk-w-zsev7SEqF2aS=AqyCkQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130618/ebb587e4/attachment.pl>

From zadig_1 at excite.com  Tue Jun 18 22:18:18 2013
From: zadig_1 at excite.com (ce)
Date: Tue, 18 Jun 2013 16:18:18 -0400
Subject: [R-SIG-Finance] can't find setstart setbound setfixed in rugarch
	package
Message-ID: <20130618161818.27720@web001.roc2.bluetie.com>


Hi

I installed R 3.01 , and rugarch. I use opensuse 12.3 .
I can't find setstart setbound and setfixed methods :

> R

R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library("rugarch")
Loading required package: Rcpp
Loading required package: RcppArmadillo
Package Rsolnp (1.14) loaded.  To cite, see citation("Rsolnp")

KernSmooth 2.23 loaded
Copyright M. P. Wand 1997-2009
> spec = ugarchspec(variance.model = list(model = 'eGARCH', garchOrder = c(2, 1)), distribution = 'std')
> setstart(spec) < - list(shape = 5)
Error: could not find function "setstart"
> setbounds(spec)
Error: could not find function "setbounds"


From alexios at 4dscape.com  Tue Jun 18 22:31:27 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Tue, 18 Jun 2013 21:31:27 +0100
Subject: [R-SIG-Finance] can't find setstart setbound setfixed in
 rugarch package
In-Reply-To: <20130618161818.27720@web001.roc2.bluetie.com>
References: <20130618161818.27720@web001.roc2.bluetie.com>
Message-ID: <51C0C39F.2080404@4dscape.com>

That's because you use "< -" which is completely invalid syntax in this 
setting. There is no space in the assignment function between "<" and 
"-". (i.e. it should be "<-")

-Alexios

On 18/06/2013 21:18, ce wrote:
>
> Hi
>
> I installed R 3.01 , and rugarch. I use opensuse 12.3 .
> I can't find setstart setbound and setfixed methods :
>
>> R
>
> R version 3.0.1 (2013-05-16) -- "Good Sport"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>    Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>> library("rugarch")
> Loading required package: Rcpp
> Loading required package: RcppArmadillo
> Package Rsolnp (1.14) loaded.  To cite, see citation("Rsolnp")
>
> KernSmooth 2.23 loaded
> Copyright M. P. Wand 1997-2009
>> spec = ugarchspec(variance.model = list(model = 'eGARCH', garchOrder = c(2, 1)), distribution = 'std')
>> setstart(spec) < - list(shape = 5)
> Error: could not find function "setstart"
>> setbounds(spec)
> Error: could not find function "setbounds"
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From liebert.daniel at googlemail.com  Wed Jun 19 10:47:04 2013
From: liebert.daniel at googlemail.com (Daniel Liebert)
Date: Wed, 19 Jun 2013 10:47:04 +0200
Subject: [R-SIG-Finance] Expected Shortfall from GARCH Models with sged
	Innovation
Message-ID: <CANFB4-Yxqeamb6=m1jMNmWJWZJd-e9mJ5z6uF8Zkod_W93Nm9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130619/1df5381e/attachment.pl>

From alexios at 4dscape.com  Wed Jun 19 11:23:16 2013
From: alexios at 4dscape.com (Alexios Ghalanos)
Date: Wed, 19 Jun 2013 10:23:16 +0100
Subject: [R-SIG-Finance] Expected Shortfall from GARCH Models with sged
	Innovation
In-Reply-To: <CANFB4-Yxqeamb6=m1jMNmWJWZJd-e9mJ5z6uF8Zkod_W93Nm9w@mail.gmail.com>
References: <CANFB4-Yxqeamb6=m1jMNmWJWZJd-e9mJ5z6uF8Zkod_W93Nm9w@mail.gmail.com>
Message-ID: <F57CD0D9-9892-41AF-9D34-7FC7AAFA75ED@4dscape.com>

From a quick look at your code (am not at my computer), you have forgotten to divide the integration result by the coverage rate (see rugarch::ESTest for an example of the calculation).

Regards,
Alexios

Sent from my iPad

On 19 Jun 2013, at 09:47, Daniel Liebert <liebert.daniel at googlemail.com> wrote:

> Hi all,
> Iam trying to compute the Expected Shortfall from a GARCH(1,1) with sged
> innovations created via the great rugarch package. The problem is that the
> range of values compared to the VaR(99) is totally different and I dont
> know where I have made the mistake.
> Here is my code:
> 
> library(quantmod)
> library(rugarch)
> library(parallel)
> library(PerformanceAnalytics)
> 
> # get Data
> mmm <- getSymbols("MMM", from = "2005-01-01", to = "2013-05-31")
> mmm <- Ad(get(mmm))
> ldr_mmm <- Return.calculate(mmm, method = "log"
> # remove NA observations
> ldr_mmm <- na.omit(ldr_mmm)
> 
> ctrl = list(rho = 1, delta = 1e-9, outer.iter = 1000, tol = 1e-7) # options
> for solver
> cl = makePSOCKcluster(10) # Create a Parallel Socket Cluster
> 
> # Choosing estimation and test window
> n_all_mmm = nrow(mmm)
> n_test_mmm <- nrow(as.xts(ldr_mmm)["2007-01-04/2013-05-31"]) # testing
> window
> n_est_mmm <- n_all_mmm - n_test_mmm # estimation window
> 
> # Fitting a GARCH(1,1) Model with skewed generalized error distribution
> innovations
> fit_MMM_def = ugarchspec(variance.model = list(model = "sGARCH", garchOrder
> = c(1,1)),
>                                         mean.model = list(armaOrder =
> c(0,0), include.mean = TRUE),
>                                         distribution.model = "sged")
> 
> # Calcualte Backtest
> MMM.backtest = ugarchroll(fit_MMM_def, data = ldr_mmm, n.ahead = 1,
>                                                forecast.length =
> n_test_mmm, refit.every = 20, refit.window = "moving",
>                                                solver = "hybrid",
> fit.control = list(), solver.control = ctrl,
>                                                calculate.VaR = TRUE,
> VaR.alpha = c(0.01), # Compute VaR = TRUE
>                                                cluster = cl)
> 
> # Calculate the VaR(99) by your own if calculate.VaR = FALSE @ ugarchroll
> df1_var <- as.data.frame(MMM.backtest, which = "density")
> f = function(x, skew, shape) qdist("sged", p = x, mu = 0, sigma = 1, skew =
> skew, shape = shape)
> test_var = df1_var[, 'Mu'] + qdist("sged", 0.01, 0, 1, skew = df1_var[,
> 'Skew'],
>                                                                 shape =
> df1_var[, 'Shape']) * df1_var[, 'Sigma']
> 
> # Lets compare it with the results from the ugarchroll function
> MMM_GARCH <- MMM.backtest at forecast
> head(cbind(test_var, as.data.frame(MMM_GARCH[["VaR"]]))) # exactly the
> same, thats good!
> 
> # Calcualte the Expected Shortfall (99)
> test_es = apply(df1_var, 1, function(x) x['Mu'] + x['Sigma'] * integrate(f,
> 0, 0.01, skew = x['Skew'], shape = x['Shape'])$value)
> test_es <- as.zoo(as.xts(test_es))
> test_es <- aggregate(test_es, function(tt) as.Date(tt, tz = "")) #convert
> to date
> 
> # Lets compare the VaR(99) and the ES(99)
> layout(1:2)
> plot(test_es) # ES(99)
> plot(as.zoo(MMM.backtest at forecast$VaR[1])) # VaR(99)
> 
> The most of the ideas are from http://www.unstarched.net (rugarch). My clue
> is that the integration is wrong but Iam not sure...
> 
> Thanks in advance
> Daniel
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From liebert.daniel at googlemail.com  Wed Jun 19 12:31:24 2013
From: liebert.daniel at googlemail.com (Daniel Liebert)
Date: Wed, 19 Jun 2013 12:31:24 +0200
Subject: [R-SIG-Finance] Expected Shortfall from GARCH Models with sged
	Innovation
In-Reply-To: <F57CD0D9-9892-41AF-9D34-7FC7AAFA75ED@4dscape.com>
References: <CANFB4-Yxqeamb6=m1jMNmWJWZJd-e9mJ5z6uF8Zkod_W93Nm9w@mail.gmail.com>
	<F57CD0D9-9892-41AF-9D34-7FC7AAFA75ED@4dscape.com>
Message-ID: <CANFB4-bWqoMD3an=cHuZ4ZbdUw7ptmr+o3K0rN3FFK5hT4-PQQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130619/cbbbd9e4/attachment.pl>

From alexios at 4dscape.com  Wed Jun 19 12:42:49 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 19 Jun 2013 11:42:49 +0100
Subject: [R-SIG-Finance] Expected Shortfall from GARCH Models with sged
 Innovation
In-Reply-To: <CANFB4-bWqoMD3an=cHuZ4ZbdUw7ptmr+o3K0rN3FFK5hT4-PQQ@mail.gmail.com>
References: <CANFB4-Yxqeamb6=m1jMNmWJWZJd-e9mJ5z6uF8Zkod_W93Nm9w@mail.gmail.com>
	<F57CD0D9-9892-41AF-9D34-7FC7AAFA75ED@4dscape.com>
	<CANFB4-bWqoMD3an=cHuZ4ZbdUw7ptmr+o3K0rN3FFK5hT4-PQQ@mail.gmail.com>
Message-ID: <51C18B29.1010802@4dscape.com>

Use This:

test_es = df1_var['Mu'] + df1_var['Sigma']*apply(df1_var, 1, function(x) 
  integrate(f,0,0.01, skew = x['Skew'], shape = x['Shape'])$value/0.01)


Best,

Alexios

On 19/06/2013 11:31, Daniel Liebert wrote:
> Thanks for your quick reply!
> Then this should be the answer, isnt it?
>
> # Calcualte the Expected Shortfall (99)
> test_es = apply(df1_var, 1, function(x) x['Mu'] + x['Sigma'] *
>                                      ((integrate(f, 0, 0.01, skew =
> x['Skew'], shape = x['Shape'])$value) / (0.01)))
>
> Greetings
> Daniel
>
>
> 2013/6/19 Alexios Ghalanos <alexios at 4dscape.com
> <mailto:alexios at 4dscape.com>>
>
>      >From a quick look at your code (am not at my computer), you have
>     forgotten to divide the integration result by the coverage rate (see
>     rugarch::ESTest for an example of the calculation).
>
>     Regards,
>     Alexios
>
>     Sent from my iPad
>
>     On 19 Jun 2013, at 09:47, Daniel Liebert
>     <liebert.daniel at googlemail.com
>     <mailto:liebert.daniel at googlemail.com>> wrote:
>
>      > Hi all,
>      > Iam trying to compute the Expected Shortfall from a GARCH(1,1)
>     with sged
>      > innovations created via the great rugarch package. The problem is
>     that the
>      > range of values compared to the VaR(99) is totally different and
>     I dont
>      > know where I have made the mistake.
>      > Here is my code:
>      >
>      > library(quantmod)
>      > library(rugarch)
>      > library(parallel)
>      > library(PerformanceAnalytics)
>      >
>      > # get Data
>      > mmm <- getSymbols("MMM", from = "2005-01-01", to = "2013-05-31")
>      > mmm <- Ad(get(mmm))
>      > ldr_mmm <- Return.calculate(mmm, method = "log"
>      > # remove NA observations
>      > ldr_mmm <- na.omit(ldr_mmm)
>      >
>      > ctrl = list(rho = 1, delta = 1e-9, outer.iter = 1000, tol = 1e-7)
>     # options
>      > for solver
>      > cl = makePSOCKcluster(10) # Create a Parallel Socket Cluster
>      >
>      > # Choosing estimation and test window
>      > n_all_mmm = nrow(mmm)
>      > n_test_mmm <- nrow(as.xts(ldr_mmm)["2007-01-04/2013-05-31"]) #
>     testing
>      > window
>      > n_est_mmm <- n_all_mmm - n_test_mmm # estimation window
>      >
>      > # Fitting a GARCH(1,1) Model with skewed generalized error
>     distribution
>      > innovations
>      > fit_MMM_def = ugarchspec(variance.model = list(model = "sGARCH",
>     garchOrder
>      > = c(1,1)),
>      >                                         mean.model = list(armaOrder =
>      > c(0,0), include.mean = TRUE),
>      >                                         distribution.model = "sged")
>      >
>      > # Calcualte Backtest
>      > MMM.backtest = ugarchroll(fit_MMM_def, data = ldr_mmm, n.ahead = 1,
>      >                                                forecast.length =
>      > n_test_mmm, refit.every = 20, refit.window = "moving",
>      >                                                solver = "hybrid",
>      > fit.control = list(), solver.control = ctrl,
>      >                                                calculate.VaR = TRUE,
>      > VaR.alpha = c(0.01), # Compute VaR = TRUE
>      >                                                cluster = cl)
>      >
>      > # Calculate the VaR(99) by your own if calculate.VaR = FALSE @
>     ugarchroll
>      > df1_var <- as.data.frame(MMM.backtest, which = "density")
>      > f = function(x, skew, shape) qdist("sged", p = x, mu = 0, sigma =
>     1, skew =
>      > skew, shape = shape)
>      > test_var = df1_var[, 'Mu'] + qdist("sged", 0.01, 0, 1, skew =
>     df1_var[,
>      > 'Skew'],
>      >
>     shape =
>      > df1_var[, 'Shape']) * df1_var[, 'Sigma']
>      >
>      > # Lets compare it with the results from the ugarchroll function
>      > MMM_GARCH <- MMM.backtest at forecast
>      > head(cbind(test_var, as.data.frame(MMM_GARCH[["VaR"]]))) #
>     exactly the
>      > same, thats good!
>      >
>      > # Calcualte the Expected Shortfall (99)
>      > test_es = apply(df1_var, 1, function(x) x['Mu'] + x['Sigma'] *
>     integrate(f,
>      > 0, 0.01, skew = x['Skew'], shape = x['Shape'])$value)
>      > test_es <- as.zoo(as.xts(test_es))
>      > test_es <- aggregate(test_es, function(tt) as.Date(tt, tz = ""))
>     #convert
>      > to date
>      >
>      > # Lets compare the VaR(99) and the ES(99)
>      > layout(1:2)
>      > plot(test_es) # ES(99)
>      > plot(as.zoo(MMM.backtest at forecast$VaR[1])) # VaR(99)
>      >
>      > The most of the ideas are from http://www.unstarched.net
>     (rugarch). My clue
>      > is that the integration is wrong but Iam not sure...
>      >
>      > Thanks in advance
>      > Daniel
>      >
>      >    [[alternative HTML version deleted]]
>      >
>      > _______________________________________________
>      > R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org>
>     mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>      > -- Subscriber-posting only. If you want to post, subscribe first.
>      > -- Also note that this is not the r-help list where general R
>     questions should go.
>
>


From oleg.mubarakshin at gmail.com  Wed Jun 19 19:32:25 2013
From: oleg.mubarakshin at gmail.com (Oleg Mubarakshin)
Date: Wed, 19 Jun 2013 21:32:25 +0400
Subject: [R-SIG-Finance] FLEX options
Message-ID: <982F0E5C088D4C948EE2C007CDB60ECC@OLEHP>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130619/36babdf3/attachment.pl>

From zadig_1 at excite.com  Wed Jun 19 19:54:19 2013
From: zadig_1 at excite.com (ce)
Date: Wed, 19 Jun 2013 13:54:19 -0400
Subject: [R-SIG-Finance] can't find setstart setbound setfixed in
	rugarch package
Message-ID: <20130619135419.8825@web006.roc2.bluetie.com>

Hi Alexios,

Thanks for the answer. In fact I was reading your document http://www.unstarched.net/r-examples/rugarch/a-short-introduction-to-the-rugarch-package/
and I copied pasted the code. My old eyes didn't see the space . But still I can't find setbounds 

> require(rugarch)
Loading required package: rugarch
Loading required package: Rcpp
Loading required package: RcppArmadillo
Package Rsolnp (1.14) loaded.  To cite, see citation("Rsolnp")

KernSmooth 2.23 loaded
Copyright M. P. Wand 1997-2009
> data(sp500ret)
> # create a cluster object to be used as part of this demonstration
> cluster = makePSOCKcluster(15)
> spec = ugarchspec(variance.model = list(model = 'eGARCH', garchOrder = c(2, 1)), distribution = 'std')
> setstart(spec) <- list(shape = 5)
> setbounds(spec)
Error: could not find function "setbounds"



-----Original Message-----
From: "alexios ghalanos" [alexios at 4dscape.com]
Date: 06/18/2013 04:31 PM
To: "ce" <zadig_1 at excite.com>
CC: "" <r-sig-finance at r-project.org>
Subject: Re: [R-SIG-Finance] can't find setstart setbound setfixed in rugarch
 package

That's because you use "< -" which is completely invalid syntax in this 
setting. There is no space in the assignment function between "<" and 
"-". (i.e. it should be "<-")

-Alexios

On 18/06/2013 21:18, ce wrote:
>
> Hi
>
> I installed R 3.01 , and rugarch. I use opensuse 12.3 .
> I can't find setstart setbound and setfixed methods :
>
>> R
>
> R version 3.0.1 (2013-05-16) -- "Good Sport"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>    Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>> library("rugarch")
> Loading required package: Rcpp
> Loading required package: RcppArmadillo
> Package Rsolnp (1.14) loaded.  To cite, see citation("Rsolnp")
>
> KernSmooth 2.23 loaded
> Copyright M. P. Wand 1997-2009
>> spec = ugarchspec(variance.model = list(model = 'eGARCH', garchOrder = c(2, 1)), distribution = 'std')
>> setstart(spec) < - list(shape = 5)
> Error: could not find function "setstart"
>> setbounds(spec)
> Error: could not find function "setbounds"
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From alexios at 4dscape.com  Wed Jun 19 20:17:09 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 19 Jun 2013 19:17:09 +0100
Subject: [R-SIG-Finance] can't find setstart setbound setfixed in
 rugarch package
In-Reply-To: <20130619135419.8825@web006.roc2.bluetie.com>
References: <20130619135419.8825@web006.roc2.bluetie.com>
Message-ID: <51C1F5A5.6050506@4dscape.com>

Hi,

The method is "setbounds<-" not "setbounds".

e.g.
setbounds(spec)<-list(shape=c(4.1, 40), alpha1=c(0, 1))


Regards,

Alexios

On 19/06/2013 18:54, ce wrote:
> Hi Alexios,
>
> Thanks for the answer. In fact I was reading your document http://www.unstarched.net/r-examples/rugarch/a-short-introduction-to-the-rugarch-package/
> and I copied pasted the code. My old eyes didn't see the space . But still I can't find setbounds
>
>> require(rugarch)
> Loading required package: rugarch
> Loading required package: Rcpp
> Loading required package: RcppArmadillo
> Package Rsolnp (1.14) loaded.  To cite, see citation("Rsolnp")
>
> KernSmooth 2.23 loaded
> Copyright M. P. Wand 1997-2009
>> data(sp500ret)
>> # create a cluster object to be used as part of this demonstration
>> cluster = makePSOCKcluster(15)
>> spec = ugarchspec(variance.model = list(model = 'eGARCH', garchOrder = c(2, 1)), distribution = 'std')
>> setstart(spec) <- list(shape = 5)
>> setbounds(spec)
> Error: could not find function "setbounds"
>
>
>
> -----Original Message-----
> From: "alexios ghalanos" [alexios at 4dscape.com]
> Date: 06/18/2013 04:31 PM
> To: "ce" <zadig_1 at excite.com>
> CC: "" <r-sig-finance at r-project.org>
> Subject: Re: [R-SIG-Finance] can't find setstart setbound setfixed in rugarch
>   package
>
> That's because you use "< -" which is completely invalid syntax in this
> setting. There is no space in the assignment function between "<" and
> "-". (i.e. it should be "<-")
>
> -Alexios
>
> On 18/06/2013 21:18, ce wrote:
>>
>> Hi
>>
>> I installed R 3.01 , and rugarch. I use opensuse 12.3 .
>> I can't find setstart setbound and setfixed methods :
>>
>>> R
>>
>> R version 3.0.1 (2013-05-16) -- "Good Sport"
>> Copyright (C) 2013 The R Foundation for Statistical Computing
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>     Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>>> library("rugarch")
>> Loading required package: Rcpp
>> Loading required package: RcppArmadillo
>> Package Rsolnp (1.14) loaded.  To cite, see citation("Rsolnp")
>>
>> KernSmooth 2.23 loaded
>> Copyright M. P. Wand 1997-2009
>>> spec = ugarchspec(variance.model = list(model = 'eGARCH', garchOrder = c(2, 1)), distribution = 'std')
>>> setstart(spec) < - list(shape = 5)
>> Error: could not find function "setstart"
>>> setbounds(spec)
>> Error: could not find function "setbounds"
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
>>
>
>
>


From bbands at gmail.com  Sat Jun 22 16:19:38 2013
From: bbands at gmail.com (BBands)
Date: Sat, 22 Jun 2013 07:19:38 -0700
Subject: [R-SIG-Finance] Clustering
Message-ID: <CAGS5yBV677h=HitudOwLSgVGXZKkKhVzE-mmcq=40Z6GPEznVQ@mail.gmail.com>

Good morning,

I am interested in doing some work on clustering stocks and would like
to chat with anyone who has had some experience in the area. I am
primarily interested in creating industry groups from larger lists of
stocks. We already do this is a semi numerical manner, so I have a lot
of experience with the issues. R offers several approaches and I am
hoping not to have to explore them all. Off list is fine if you
prefer.

Thanks,

      John -- who is really sorry that he missed the conference, but
the daughter only graduates from college once

--
John Bollinger
www.BollingerBands.com


From me at censix.com  Sat Jun 22 18:48:18 2013
From: me at censix.com (me)
Date: Sat, 22 Jun 2013 18:48:18 +0200
Subject: [R-SIG-Finance] Clustering
In-Reply-To: <CAGS5yBV677h=HitudOwLSgVGXZKkKhVzE-mmcq=40Z6GPEznVQ@mail.gmail.com>
References: <CAGS5yBV677h=HitudOwLSgVGXZKkKhVzE-mmcq=40Z6GPEznVQ@mail.gmail.com>
Message-ID: <20130622184818.063bc336@desktop1>

On Sat, 22 Jun 2013 07:19:38 -0700
BBands <bbands at gmail.com> wrote:

> Good morning,
> 
> I am interested in doing some work on clustering stocks and would like
> to chat with anyone who has had some experience in the area. I am
> primarily interested in creating industry groups from larger lists of
> stocks. We already do this is a semi numerical manner, so I have a lot
> of experience with the issues. R offers several approaches and I am
> hoping not to have to explore them all. Off list is fine if you
> prefer.
> 
> Thanks,
> 
>       John -- who is really sorry that he missed the conference, but
> the daughter only graduates from college once
> 
> --
> John Bollinger
> www.BollingerBands.com
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R
> questions should go.



John

Not an expert, but here is one way to do it (This example was sitting
around on my drive). By using a sufficiently large stock universe and a
reasonably small number of clusters (kk) you should see sectors emerge
'naturally'. One could try and use weekly or monthly returns instead of
daily returns.

regards

Soren



require(quantmod)

symList <- c('MSN','GOOG','YHOO', 'BA', 'SI', 'BP', 'AMD','AMGN.MX')
getSymbols(symList)

# Matrix of daily returns. Or use weekly, monthly returns...
returns.mat <- NULL
for (sym in symList) returns.mat<- cbind( returns.mat,
dailyReturn( Ad(get(sym)) ) )

colnames(returns.mat) <- symList


# Use kmeans to group into kk clusters
kk <- 3
KM <- kmeans( x=t(returns.mat), centers=kk, nstart=20)   
# Important: nstart should be set to around 20, to 
# make sure the clustering result is stable

# Print the result 
for (ii in 1:kk) {
  print(paste('######### Cluster:',ii))
  print( colnames(returns.mat)[KM$cluster==ii])
  print(' ')
}





------------------------------------------------------------------
Soren Wilkening

http://censix.com


From dominykasgrigonis at gmail.com  Sun Jun 23 17:02:23 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sun, 23 Jun 2013 16:02:23 +0100
Subject: [R-SIG-Finance] cut range from time objects
Message-ID: <EE0A91AFB2CB446F8698DC206516A6E0@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130623/62918de4/attachment.pl>

From gsee000 at gmail.com  Sun Jun 23 17:45:27 2013
From: gsee000 at gmail.com (G See)
Date: Sun, 23 Jun 2013 10:45:27 -0500
Subject: [R-SIG-Finance] cut range from time objects
In-Reply-To: <EE0A91AFB2CB446F8698DC206516A6E0@gmail.com>
References: <EE0A91AFB2CB446F8698DC206516A6E0@gmail.com>
Message-ID: <CA+xi=qZiw8c0C6jRRbtSWE1ymoFWpkTVrxTLsBzHT2+gdGAFCg@mail.gmail.com>

Hi Dominykas

I would try the below as my first attempt.

library(xts)
library(timeSeries)
Sys.setenv(TZ="GMT")
temp <- xts(1:84, timeCalendar(m=1, d=rep(1:7,each=12),h = seq(0,23,2)))

# Monday through Thursday
mt <- temp[.indexwday(temp) %in% 1:4]

# Friday 00:00:00/20:00:00
f <- temp[.indexwday(temp) == 5L]["T00:00:00/T20:00:00"]

# Sunday 20:00:00/24:00:00
s <- temp[.indexwday(temp) == 0L]["T20:00:00.000/T23:59:59.999"]

out <- rbind(mt, f, s)

# check answer by adding a column with weekday (0-6 starting on Sunday)
colnames(out) <- "temp" # have to have a column name to do the next step
out$wday <- .indexwday(out)
# Now you can look at the output and see that the only times where wday is 0
# are 20:00 or later, and the only times where wday is 5 are 20:00 or earlier
out

Hope this helps,
Garrett



On Sun, Jun 23, 2013 at 10:02 AM, Dominykas Grigonis
<dominykasgrigonis at gmail.com> wrote:
> Dear all,
>
> I have come across the issue and I hope you will be able to help me.
>
> I have minute data and unfortunately it has weekends in it and unfortunately the values on weekend are not 0s and not NAs, but rather last trading price of friday. I want to cut the ranges out as it slows down strategy testing.
>
> Say we have xts object with timeDate index
> temp <- xts(1:84, timeCalendar(m=1, d=rep(1:7,each=12),h = seq(0,23,2)))
>
>
> I want to cut rows from friday 20:00 to sunday 20:00.
> I started writing function, but it just does not seem right?
>
> filtertime <- function(x, rwd <- "5/2", rt <- "0800/1400"){
>     is.within   <- function(x){
>         value   <- hour(x)*60+minute(x)
>         (value > range[1] && value < range[2])}
>     rwd     <- as.numeric(strsplit(rwd,"/")[[1]])
>     rt      <- as.numeric(strsplit(rt,"/")[[1]])
>     rt      <- (rt%/%100)*60+(rt%%100)
>     time    <- index(x)
>     if(rwd[1]>rwd[2]){ wsq <- c((rwd[1]:7), (1:rwd[2]))
>     }else{wsq <- rwd[1]:rwd[2]}
>     wweek   <- sapply(time, function(x){x[all(dayOfWeek(x) != wsq)]})
>     wweek   <- x[all(dayOfWeek(x) != wsq)]
>
> }
> I am not looking for help on this function, I hope someone could suggest some efficient way to solve my problem as I am working on 1 year 1minute data.
> Thank you in advance.
>
> Kind regards,--
> Dominykas Grigonis
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From dominykasgrigonis at gmail.com  Sun Jun 23 18:34:20 2013
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Sun, 23 Jun 2013 17:34:20 +0100
Subject: [R-SIG-Finance] create new columns xts
Message-ID: <32C562C5C1B345839BE32E29F7138D10@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130623/fa72e2f5/attachment.pl>

From junluke at gmail.com  Sun Jun 23 18:38:52 2013
From: junluke at gmail.com (jun wang)
Date: Sun, 23 Jun 2013 12:38:52 -0400
Subject: [R-SIG-Finance] rugarch package
Message-ID: <CAPD4hGAz8NC3xF2JVXCyX6ERFC4KC6Eqpg3YDzVwvBNPoQfhDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130623/29634111/attachment.pl>

From alexios at 4dscape.com  Sun Jun 23 18:55:42 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Sun, 23 Jun 2013 17:55:42 +0100
Subject: [R-SIG-Finance] rugarch package
In-Reply-To: <CAPD4hGAz8NC3xF2JVXCyX6ERFC4KC6Eqpg3YDzVwvBNPoQfhDg@mail.gmail.com>
References: <CAPD4hGAz8NC3xF2JVXCyX6ERFC4KC6Eqpg3YDzVwvBNPoQfhDg@mail.gmail.com>
Message-ID: <51C7288E.1020302@4dscape.com>

Hi Jun,

This is likely related to the time format of the data you are passing to 
the ugarchfit function ('data' argument). Ideally it should be an xts 
object, with a POSIXct (or Date) index, and you have also set your 
timezone (e.g. Sys.setenv(TZ="GMT") ).

You should really take some time to familiarize yourself with R's 
Date/Time functions and the xts package (it will payoff in the long run, 
IMHO).

Best,

Alexios

On 23/06/2013 17:38, jun wang wrote:
> Hi, Alexios,
>
> I am using the rugarch package to get the conditional variance of the
> uni variate garch model. But the result i got seems a little weird, see
> below:
>
> uspec = ugarchspec(mean.model = list(armaOrder = c(0,0),include.mean=TRUE),
>                     variance.model = list(garchOrder = c(1,1), model =
> "sGARCH"),
>                     distribution.model = "ghyp")
> fit1=ugarchfit(uspec,data=jpm)
> fit2=ugarchfit(uspec,data=sp500)
>
> a=sigma(fit1)
> b=sigma(fit2)
> H=cbind(1/a,1/b)
>
> In the matrix H, i had the following format:
> 1970-01-01 19:00:00 0.10648731 0.004840093
> 1970-01-02 19:00:00 0.13220160 0.003223305
>
> Any way to get rid of  1970-01-01 19:00:00?
>
> Many thanks!!!
>
> Jun
>


From gsee000 at gmail.com  Sun Jun 23 19:25:05 2013
From: gsee000 at gmail.com (G See)
Date: Sun, 23 Jun 2013 12:25:05 -0500
Subject: [R-SIG-Finance] create new columns xts
In-Reply-To: <32C562C5C1B345839BE32E29F7138D10@gmail.com>
References: <32C562C5C1B345839BE32E29F7138D10@gmail.com>
Message-ID: <CA+xi=qY7eKSu-pSsnZRaWYtKpEcE2OxTVDKTGZodfhEPwWGrAA@mail.gmail.com>

It might be nice if `[[<-` worked on zoo/xts objects like it does on a
data.frame.
For example,

    X <- as.data.frame(temp)
    n <- 1
    X[[paste0("sma.", n)]] <- SMA(X[[1]])
    tail(X)

But, with zoo/xts objects, temp[[1]] refers to the 1st row of the 1st column.

I _think_ the closest you can get is to pass dimnames= through a new
xts call like this:

    merge(temp, xts(SMA(temp), dimnames=list(NULL, paste0("sma.", n))))

It's a shame that the availability of dimnames= is so hidden (and that it has
to be specified as a list, which is a little weird.)

You probably also wanted your `temp` object to have colnames; otherwise,
temp$sma <- SMA(temp) wouldn't work.  Instead of doing that with
colnames(temp) <- "temp" you could do it when you create the object which can
sometimes be more convenient.

    temp <- xts(1:84, timeCalendar(m=1, d=rep(1:7,each=12),h = seq(0,23,2)),
                dimnames=list(NULL, "temp"))

Garrett

On Sun, Jun 23, 2013 at 11:34 AM, Dominykas Grigonis
<dominykasgrigonis at gmail.com> wrote:
> One more question, that will get me going.
>
> temp <- xts(1:84, timeCalendar(m=1, d=rep(1:7,each=12),h = seq(0,23,2)))
>
> I need to add named column, say SMA(temp)
>
> nice way to do this is temp$sma <- SMA(temp)
>
> however it is inside a function and it might have different SMAs, so I want to adda column named paste0("sma.",n)
>
> temp$paste0("sma.",n) <- SMA(temp)
> temp[,paste0("sma.",n)] <- SMA(temp)
>
> does not work
>
> it is an option to use merge
> merge(temp,SMA(temp))
> and then colnames
>
> However my question is whether it is possible to use temp$paste0("sma.",n) <- SMA(temp) in some way.
> I tried  temp$as.name(paste0("sma.",n)) and similar options...
>
> Thank you.
>
> Kind regards,--
> Dominykas Grigonis
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From efm at linsomniac.com  Sun Jun 23 19:50:31 2013
From: efm at linsomniac.com (Evelyn Mitchell)
Date: Sun, 23 Jun 2013 11:50:31 -0600
Subject: [R-SIG-Finance] fastCluster Clustering
Message-ID: <51C73567.3060600@linsomniac.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130623/773b01a8/attachment.pl>

From bbands at gmail.com  Sun Jun 23 21:25:46 2013
From: bbands at gmail.com (BBands)
Date: Sun, 23 Jun 2013 12:25:46 -0700
Subject: [R-SIG-Finance] Fwd: Turing's Cathedral
In-Reply-To: <CAGS5yBUNw5YosR0DpBh8jMDt0rVDuJa8Kw9-BNRJ-T+cb=Od4A@mail.gmail.com>
References: <CAGS5yBUNw5YosR0DpBh8jMDt0rVDuJa8Kw9-BNRJ-T+cb=Od4A@mail.gmail.com>
Message-ID: <CAGS5yBX0WSE_xxE5-qEWC=Y=GoZB-V9DyyCwm84Q0+8ZfhZAbw@mail.gmail.com>

I'm reading George Dyson's "Turing's Cathedral", ostensibly a history
of the Princeton computer project circa 1945-1955, but more than
anything else a biography of John von Neuman, the animating force
behind the project.

http://www.amazon.com/Turings-Cathedral-Origins-Digital-Universe/dp/1400075998

There are lots of bits in it that might be of interest here, perhaps
none more so than page 190 and the few pages following which sketch
out Stan Ulam's creation of Monte Carlo simulation. I won't give it
away as it is a good story.

Enjoy,

    John


From bogaso.christofer at gmail.com  Sat Jun 29 20:49:01 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 30 Jun 2013 00:34:01 +0545
Subject: [R-SIG-Finance] Risk return analysis
Message-ID: <CA+dpOJn6pzOG_XWrSsGELPyP8MmE5c=-HZF0U_ChC5RSksmtkA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130630/0d8218b3/attachment.pl>

From wlmr at zhaw.ch  Sat Jun 29 23:59:23 2013
From: wlmr at zhaw.ch (Wildi Marc (wlmr))
Date: Sat, 29 Jun 2013 21:59:23 +0000
Subject: [R-SIG-Finance] Risk return analysis
In-Reply-To: <CA+dpOJn6pzOG_XWrSsGELPyP8MmE5c=-HZF0U_ChC5RSksmtkA@mail.gmail.com>
References: <CA+dpOJn6pzOG_XWrSsGELPyP8MmE5c=-HZF0U_ChC5RSksmtkA@mail.gmail.com>
Message-ID: <E2339A3600811248AB525B8FAB3A1BCE9878FE6B@srv-mail-101.zhaw.ch>

This is a classic topic of/for confusion:

-Garch-in-Mean (as you use) is not related to Markowitz: the former (Garch-in-Mean) emphasizes longitudinal dynamics whereas Markowitz emphasizes cross-sectional `diversity'.

-Typically, the link between return and volatility in the Garch-in-mean is negative. This means: high-volatility is associated with draw-downs (negative returns): asymmetry of markets.

-In contrast, in a Markowitzian cross-sectional perspective the link between vola and return is positive: higher returns offset higher risk.

Do not stumble into this trap...

Marc




________________________________________
Von: r-sig-finance-bounces at r-project.org [r-sig-finance-bounces at r-project.org]&quot; im Auftrag von &quot;Christofer Bogaso [bogaso.christofer at gmail.com]
Gesendet: Samstag, 29. Juni 2013 20:49
An: r-sig-finance at r-project.org
Betreff: [R-SIG-Finance] Risk return analysis

Hello again,

I have estimated a garch model with following specification:

r[t] = mu + k * sigma[t] + epsilon[t]

sigma[t] ~ garch(1,1)

However I see that estimate of k is positive but insignificant.

My question what does it mean? Does it mean that, for that asset people are
not risk adverse? they do not demand higher return for higher risk?

Or it just some noise?

I am using daily log-return for 10 years.

Thanks for your help.

        [[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


From htrahdis at gmail.com  Sun Jun 30 05:40:11 2013
From: htrahdis at gmail.com (sidharth mallik)
Date: Sun, 30 Jun 2013 09:10:11 +0530
Subject: [R-SIG-Finance] Risk return analysis
In-Reply-To: <E2339A3600811248AB525B8FAB3A1BCE9878FE6B@srv-mail-101.zhaw.ch>
References: <CA+dpOJn6pzOG_XWrSsGELPyP8MmE5c=-HZF0U_ChC5RSksmtkA@mail.gmail.com>
	<E2339A3600811248AB525B8FAB3A1BCE9878FE6B@srv-mail-101.zhaw.ch>
Message-ID: <CAJXbfOJepfR6YGOZ9ecH2i6vBMm2Uj1FayUzB8yxLaJ7FWpfLw@mail.gmail.com>

also, the methods of estimation should be rigorously checked again.
please see this link : http://mahalanobis.twoday.net/stories/2684143/.
parameter estimation for these models may not be as easy as a simple
GARCH model.

On 6/30/13, Wildi Marc (wlmr) <wlmr at zhaw.ch> wrote:
> This is a classic topic of/for confusion:
>
> -Garch-in-Mean (as you use) is not related to Markowitz: the former
> (Garch-in-Mean) emphasizes longitudinal dynamics whereas Markowitz
> emphasizes cross-sectional `diversity'.
>
> -Typically, the link between return and volatility in the Garch-in-mean is
> negative. This means: high-volatility is associated with draw-downs
> (negative returns): asymmetry of markets.
>
> -In contrast, in a Markowitzian cross-sectional perspective the link between
> vola and return is positive: higher returns offset higher risk.
>
> Do not stumble into this trap...
>
> Marc
>
>
>
>
> ________________________________________
> Von: r-sig-finance-bounces at r-project.org
> [r-sig-finance-bounces at r-project.org]&quot; im Auftrag von &quot;Christofer
> Bogaso [bogaso.christofer at gmail.com]
> Gesendet: Samstag, 29. Juni 2013 20:49
> An: r-sig-finance at r-project.org
> Betreff: [R-SIG-Finance] Risk return analysis
>
> Hello again,
>
> I have estimated a garch model with following specification:
>
> r[t] = mu + k * sigma[t] + epsilon[t]
>
> sigma[t] ~ garch(1,1)
>
> However I see that estimate of k is positive but insignificant.
>
> My question what does it mean? Does it mean that, for that asset people are
> not risk adverse? they do not demand higher return for higher risk?
>
> Or it just some noise?
>
> I am using daily log-return for 10 years.
>
> Thanks for your help.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>


From frankm60606 at gmail.com  Sun Jun 30 19:29:56 2013
From: frankm60606 at gmail.com (Frank)
Date: Sun, 30 Jun 2013 12:29:56 -0500
Subject: [R-SIG-Finance] Delete bad dividend row
Message-ID: <D1005A76DEBE435BB0EBEC9F25A39287@Franki7PC>

Hi all,

I successfully get dividend data from Yahoo Finance, including a bad
dividend:

2012-12-20 0.039

How do I delete this one row from the data? This dividend shows up on the
Yahoo Finance site but is not reported by Philip Morris. 

Thanks,

Frank
Chicago, IL


R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

? Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> library(quantmod)
Loading required package: Defaults
Loading required package: xts
Loading required package: zoo

Attaching package: 'zoo'

The following object is masked from 'package:base':

??? as.Date, as.Date.numeric

Loading required package: TTR
Version 0.4-0 included new data defaults. See ?getSymbols.
> library(chron)
> 
> from_date="2010-1-1"
> {Divs<-getDividends("PM",from=from_date)}
> Divs
??????????? [,1]
2010-03-23 0.580
2010-06-22 0.580
2010-09-22 0.640
2010-12-21 0.640
2011-03-22 0.640
2011-06-21 0.640
2011-09-23 0.770
2011-12-20 0.770
2012-03-27 0.770
2012-06-25 0.770
2012-09-25 0.850
2012-12-20 0.039
2012-12-24 0.850
2013-03-26 0.850
2013-06-25 0.850
> 
> quit()
> proc.time()
?? user? system elapsed 
?? 0.92??? 0.04??? 1.04


From bogaso.christofer at gmail.com  Sun Jun 30 20:58:07 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 1 Jul 2013 00:43:07 +0545
Subject: [R-SIG-Finance] Risk return analysis
In-Reply-To: <CAJXbfOJepfR6YGOZ9ecH2i6vBMm2Uj1FayUzB8yxLaJ7FWpfLw@mail.gmail.com>
References: <CA+dpOJn6pzOG_XWrSsGELPyP8MmE5c=-HZF0U_ChC5RSksmtkA@mail.gmail.com>
	<E2339A3600811248AB525B8FAB3A1BCE9878FE6B@srv-mail-101.zhaw.ch>
	<CAJXbfOJepfR6YGOZ9ecH2i6vBMm2Uj1FayUzB8yxLaJ7FWpfLw@mail.gmail.com>
Message-ID: <CA+dpOJko=0sJRL=NA5FBDHuj3BaSd+s8RvBQiiQXpmA274x9_Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20130701/caafa8f2/attachment.pl>

