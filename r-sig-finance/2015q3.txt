From danielmelendez at alum.northwestern.edu  Wed Jul  1 19:28:20 2015
From: danielmelendez at alum.northwestern.edu (Daniel Melendez)
Date: Wed, 1 Jul 2015 12:28:20 -0500
Subject: [R-SIG-Finance] Question rmgarch
Message-ID: <CAEjpDDrETnNCFRr32vU_Qh0DFiw0Z_JQX9qLgoY7YPGsUQGSLw@mail.gmail.com>

Hello All -

Is there a sampling function already created within the package once the
density is formed by FFT?  Or is this something the analyst will have to
create?

-- 
Regards

Daniel Melendez

=========================================================================

	[[alternative HTML version deleted]]


From danielmelendez at alum.northwestern.edu  Wed Jul  1 19:51:43 2015
From: danielmelendez at alum.northwestern.edu (Daniel Melendez)
Date: Wed, 1 Jul 2015 12:51:43 -0500
Subject: [R-SIG-Finance] Question rmgarch
In-Reply-To: <559424A8.4050409@4dscape.com>
References: <CAEjpDDrETnNCFRr32vU_Qh0DFiw0Z_JQX9qLgoY7YPGsUQGSLw@mail.gmail.com>
	<559424A8.4050409@4dscape.com>
Message-ID: <CAEjpDDpEm3AcqZd5VswkJ2Z=8tfwsEJdMP-xvZdcUHZeUBx95Q@mail.gmail.com>

thx

On Wed, Jul 1, 2015 at 12:34 PM, alexios ghalanos <alexios at 4dscape.com>
wrote:

> Please READ the documentation/manual.
>
> -----------------
> qfft
>
> signature(object = "goGARCHfft") This takes additional argument ?index?
> to indicate the particular time point, and returns an interpolated
> quantile function which may be called like any other ?q? type quantile
> function. This may also be used to generate pseudo-random variables from
> the distribution by using random standard uniform numbers as inputs.
> ------------------
>
>
>
> -Alexios
>
> On 01/07/2015 18:28, Daniel Melendez wrote:
> > Hello All -
> >
> > Is there a sampling function already created within the package once the
> > density is formed by FFT?  Or is this something the analyst will have to
> > create?
> >
>



-- 
Regards

Daniel Melendez

=========================================================================

	[[alternative HTML version deleted]]


From alexios at 4dscape.com  Wed Jul  1 19:34:32 2015
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 1 Jul 2015 18:34:32 +0100
Subject: [R-SIG-Finance] Question rmgarch
In-Reply-To: <CAEjpDDrETnNCFRr32vU_Qh0DFiw0Z_JQX9qLgoY7YPGsUQGSLw@mail.gmail.com>
References: <CAEjpDDrETnNCFRr32vU_Qh0DFiw0Z_JQX9qLgoY7YPGsUQGSLw@mail.gmail.com>
Message-ID: <559424A8.4050409@4dscape.com>

Please READ the documentation/manual.

-----------------
qfft

signature(object = "goGARCHfft") This takes additional argument ?index?
to indicate the particular time point, and returns an interpolated
quantile function which may be called like any other ?q? type quantile
function. This may also be used to generate pseudo-random variables from
the distribution by using random standard uniform numbers as inputs.
------------------



-Alexios

On 01/07/2015 18:28, Daniel Melendez wrote:
> Hello All -
> 
> Is there a sampling function already created within the package once the
> density is formed by FFT?  Or is this something the analyst will have to
> create?
>


From junluke at gmail.com  Wed Jul  1 20:37:03 2015
From: junluke at gmail.com (jun wang)
Date: Wed, 1 Jul 2015 14:37:03 -0400
Subject: [R-SIG-Finance] Estimating Heston model
Message-ID: <CAPD4hGCLbFP=MNwTdj0JyYDxT06bf2uaVzxaGMKWn7p2LBo4wg@mail.gmail.com>

Dear all,

Can anybody provide some hints/examples to estimate Heston models in R?
The stochvol can only estimate the the level of log-variance ?, the
persistence of log-variance ?, and the volatility of log-variance. How can
i estimate the leverage effect parameter?

Any help would be appreciated.

Jun

	[[alternative HTML version deleted]]


From junluke at gmail.com  Wed Jul  1 22:03:48 2015
From: junluke at gmail.com (jun wang)
Date: Wed, 1 Jul 2015 16:03:48 -0400
Subject: [R-SIG-Finance] Estimating Heston model
In-Reply-To: <CAEjpDDqcaGz11ZJRf+TcxJzuHU1FFgOPnY2ba3GLRmM0NDvoXw@mail.gmail.com>
References: <CAPD4hGCLbFP=MNwTdj0JyYDxT06bf2uaVzxaGMKWn7p2LBo4wg@mail.gmail.com>
	<CAEjpDDp+z9kmVZx2t+W5TCS01LfqejJgv_uPPTQX=y4N++14bQ@mail.gmail.com>
	<CAPD4hGB6aFJ9i3s0X2vF455_OwT5gvcfN5VRh+9fX9MniYrmmg@mail.gmail.com>
	<CAEjpDDqcaGz11ZJRf+TcxJzuHU1FFgOPnY2ba3GLRmM0NDvoXw@mail.gmail.com>
Message-ID: <CAPD4hGCOauj4reoK_9ox+o81=DUn3pde4fnbTH3_SYM2WoKGxw@mail.gmail.com>

Thank you,Daniel!

On Wed, Jul 1, 2015 at 4:00 PM, Daniel Melendez <
danielmelendez at alum.northwestern.edu> wrote:

> I think this is what you might be looking for (attached).  The data set
> that is currently being used is monthly returns.  Also might want to send
> out a message to the group about our discussion.  I didnt want to reply all
> with an attachment.  Hope all of this helps you
>
> On Wed, Jul 1, 2015 at 2:52 PM, jun wang <junluke at gmail.com> wrote:
>
>> Thank you, Daniel! Is there a example using daily stock returns rather
>> than the option data to estimate the parameters? Like the MCMC algorithm?
>>
>> Jun
>>
>> On Wed, Jul 1, 2015 at 3:47 PM, Daniel Melendez <
>> danielmelendez at alum.northwestern.edu> wrote:
>>
>>> Hello Jun -
>>>
>>>
>>> Attached is an example I found a while back by Dr. Dale Roberts, I
>>> believe it provides for a great example and hopefully its a benefit to you.
>>>
>>
>>
>
>
> --
> Regards
>
> Daniel Melendez
>
> =========================================================================
>

	[[alternative HTML version deleted]]


From daneedwards1 at hotmail.com  Thu Jul  2 14:24:59 2015
From: daneedwards1 at hotmail.com (Dane Edwards)
Date: Thu, 2 Jul 2015 22:24:59 +1000
Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill
	Williams)
Message-ID: <DUB131-W541D03BA87DB585B94C82A82970@phx.gbl>

Hi, how do i create a custom indicator for quantmod / quantstrat. I'm trying to create a Fractal indicator (Bill Williams), the indicator needs to look back 5 days to calculate if a fractal has happened.
http://www.winnersedgetrading.com/how-to-trade-the-fractal-indicator/
This is in MQL language
 //----Fractals up      FractalFound=false;      dCurrent=High[i];      if(dCurrent>High[i+1] && dCurrent>High[i+2] && dCurrent>High[i-1] && dCurrent>High[i-2])        {         FractalFound=true;        }//i is the current day

I'm not sure how the indicators work in quantstrat, in most backtesting software it loops through each day and calculates the indicator (for each day you then look back 5 days), does quanstrat do the same or do i need to write my own looping function in the indicator?
Thanks!! 		 	   		  
	[[alternative HTML version deleted]]


From Ikipnis at grahamcapital.com  Thu Jul  2 14:42:43 2015
From: Ikipnis at grahamcapital.com (Ilya Kipnis)
Date: Thu, 2 Jul 2015 12:42:43 +0000
Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by
 Bill	Williams)
In-Reply-To: <DUB131-W541D03BA87DB585B94C82A82970@phx.gbl>
References: <DUB131-W541D03BA87DB585B94C82A82970@phx.gbl>
Message-ID: <B37698F4177E1D4A9D2750822083CBF0559216@GCM-EXMB-R1.grahamcapital.com>

Indicators are just functions like any other R function. EG the quantstrat demos use a lot of the TTR functions, but those TTR are functions are just R functions themselves.

-----Original Message-----
From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Dane Edwards
Sent: Thursday, July 02, 2015 8:25 AM
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill Williams)

Hi, how do i create a custom indicator for quantmod / quantstrat. I'm trying to create a Fractal indicator (Bill Williams), the indicator needs to look back 5 days to calculate if a fractal has happened.
http://www.winnersedgetrading.com/how-to-trade-the-fractal-indicator/
This is in MQL language
 //----Fractals up      FractalFound=false;      dCurrent=High[i];      if(dCurrent>High[i+1] && dCurrent>High[i+2] && dCurrent>High[i-1] && dCurrent>High[i-2])        {         FractalFound=true;        }//i is the current day

I'm not sure how the indicators work in quantstrat, in most backtesting software it loops through each day and calculates the indicator (for each day you then look back 5 days), does quanstrat do the same or do i need to write my own looping function in the indicator?
Thanks!! 		 	   		  
	[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


From Andy.Tang at morningstar.com  Thu Jul  2 21:29:17 2015
From: Andy.Tang at morningstar.com (Andy Tang)
Date: Thu, 2 Jul 2015 19:29:17 +0000
Subject: [R-SIG-Finance] rugarch NIG shape and skew parameters
Message-ID: <B02BF0AA835AD14DA16AB693135BAB590CD5B1E7@MSEXCHM83.morningstar.com>

Hi Alex,

In your rugarch package, the garch+nig model has coefficients of 'skew' and 'shape'. These two parameters map to alpha_bar/beta_bar, not alpha/beta in the NIG parameter set, right?

Thanks
Andy

________________________________
Andy Tang, CFA
Quantitative Analyst
Morningstar, Inc.

Morningstar. Illuminating investing worldwide.

+1 312-384-4839 voice
andy.tang at morningstar.com<mailto:andy.tang at morningstar.com>


This e-mail contains privileged and confidential information and is intended only for the use of the person(s) named above. Any dissemination, distribution, or duplication of this communication without prior written consent from Morningstar is strictly prohibited. If you have received this message in error, please contact the sender immediately and delete the materials from any computer.



	[[alternative HTML version deleted]]


From daneedwards1 at hotmail.com  Fri Jul  3 01:44:46 2015
From: daneedwards1 at hotmail.com (Dane Edwards)
Date: Fri, 3 Jul 2015 09:44:46 +1000
Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by
 Bill Williams)
In-Reply-To: <B37698F4177E1D4A9D2750822083CBF0559216@GCM-EXMB-R1.grahamcapital.com>
References: <DUB131-W541D03BA87DB585B94C82A82970@phx.gbl>,
	<B37698F4177E1D4A9D2750822083CBF0559216@GCM-EXMB-R1.grahamcapital.com>
Message-ID: <DUB131-W433B6664C2055613200ED582970@phx.gbl>

Thanks Ilya, does the indicator function get called for every row (like esignal, ninjatrader)  in the xts when the apply strategy function is called? or is the indicator function called once?
i'm thinking now that the indicator column is calculated before applystrategy is ran, is this correct?

 

> From: Ikipnis at grahamcapital.com
> To: daneedwards1 at hotmail.com; r-sig-finance at r-project.org
> Subject: RE: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill	Williams)
> Date: Thu, 2 Jul 2015 12:42:43 +0000
> 
> Indicators are just functions like any other R function. EG the quantstrat demos use a lot of the TTR functions, but those TTR are functions are just R functions themselves.
> 
> -----Original Message-----
> From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Dane Edwards
> Sent: Thursday, July 02, 2015 8:25 AM
> To: r-sig-finance at r-project.org
> Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill Williams)
> 
> Hi, how do i create a custom indicator for quantmod / quantstrat. I'm trying to create a Fractal indicator (Bill Williams), the indicator needs to look back 5 days to calculate if a fractal has happened.
> http://www.winnersedgetrading.com/how-to-trade-the-fractal-indicator/
> This is in MQL language
>  //----Fractals up      FractalFound=false;      dCurrent=High[i];      if(dCurrent>High[i+1] && dCurrent>High[i+2] && dCurrent>High[i-1] && dCurrent>High[i-2])        {         FractalFound=true;        }//i is the current day
> 
> I'm not sure how the indicators work in quantstrat, in most backtesting software it loops through each day and calculates the indicator (for each day you then look back 5 days), does quanstrat do the same or do i need to write my own looping function in the indicator?
> Thanks!! 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
 		 	   		  
	[[alternative HTML version deleted]]


From alexios at 4dscape.com  Fri Jul  3 03:03:04 2015
From: alexios at 4dscape.com (alexios)
Date: Fri, 3 Jul 2015 02:03:04 +0100
Subject: [R-SIG-Finance] rugarch NIG shape and skew parameters
In-Reply-To: <B02BF0AA835AD14DA16AB693135BAB590CD5B1E7@MSEXCHM83.morningstar.com>
References: <B02BF0AA835AD14DA16AB693135BAB590CD5B1E7@MSEXCHM83.morningstar.com>
Message-ID: <5595DF48.5000502@4dscape.com>

Andy,

(skew,shape) are the location-scale invariant parameters (\rho,\zeta) in 
one of the parametrizations of the GH distribution (the '2nd 
parametrization' in Prause 1999). They jointly map onto
(\alpha,\beta,\delta,\mu) - the standard parameters of the GH 
distribution as shown in equations 70-82 of Section 2.3.5 of the vignette.

The (\bar \alpha,\bar \beta) you are referring to is a different 
location-scale invariant parametrization (the '4th').

One of the nice features of the (\rho,\zeta) parametrization is that
you can immediately translate it to the (\xi,\chi) parametrization (the 
'3rd') which asymptotically describes the skewness and kurtosis, 
respectively, of the hyperbolic distribution (lambda=1). See 
Barndorff-Nielsen et al 1985 for details.

However, for the particular limiting case of the GH Skew Student 
(discussed seperately in Section 2.3.6), the \bar \beta
parametrization (skew) together with nu (shape) is used.

If you want to investigate the maximum domain of skewness-kurtosis of 
the various distributions, have a look at the skdomain function, an 
example of which is available on the 'Distributions Functions' section 
of this rather old post: 
http://unstarched.net/2013/02/27/whats-new-in-rugarch-ver-1-01-5/

Regards,

Alexios

On 02/07/2015 20:29, Andy Tang wrote:
> Hi Alex,
>
> In your rugarch package, the garch+nig model has coefficients of 'skew' and 'shape'. These two parameters map to alpha_bar/beta_bar, not alpha/beta in the NIG parameter set, right?
>
> Thanks
> Andy
>
> ________________________________
> Andy Tang, CFA
> Quantitative Analyst
> Morningstar, Inc.
>
> Morningstar. Illuminating investing worldwide.
>
> +1 312-384-4839 voice
> andy.tang at morningstar.com<mailto:andy.tang at morningstar.com>
>
>
> This e-mail contains privileged and confidential information and is intended only for the use of the person(s) named above. Any dissemination, distribution, or duplication of this communication without prior written consent from Morningstar is strictly prohibited. If you have received this message in error, please contact the sender immediately and delete the materials from any computer.
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>
>


From brian at braverock.com  Fri Jul  3 03:38:48 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 02 Jul 2015 20:38:48 -0500
Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by
 Bill Williams)
In-Reply-To: <DUB131-W433B6664C2055613200ED582970@phx.gbl>
References: <DUB131-W541D03BA87DB585B94C82A82970@phx.gbl>,
	<B37698F4177E1D4A9D2750822083CBF0559216@GCM-EXMB-R1.grahamcapital.com>
	<DUB131-W433B6664C2055613200ED582970@phx.gbl>
Message-ID: <5595E7A8.3060306@braverock.com>

On 07/02/2015 06:44 PM, Dane Edwards wrote:
> Thanks Ilya, does the indicator function get called for every row (like esignal, ninjatrader)  in the xts when the apply strategy function is called? or is the indicator function called once?
> i'm thinking now that the indicator column is calculated before applystrategy is ran, is this correct?


This is covered in the documentation.

You are certainly welcome to add a column or columns to your data before 
calling applyStrategy, but you don't need to do that.

You indicator and signal functions are presumed to be path-independent. 
  They should return an xts time series object of the same length as the 
input data.

It is most efficient to write vectorized indicators or signals, but you 
may write a loop if you like, it will just be slower.

Regards,

Brian

>> From: Ikipnis at grahamcapital.com
>> To: daneedwards1 at hotmail.com; r-sig-finance at r-project.org
>> Subject: RE: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill	Williams)
>> Date: Thu, 2 Jul 2015 12:42:43 +0000
>>
>> Indicators are just functions like any other R function. EG the quantstrat demos use a lot of the TTR functions, but those TTR are functions are just R functions themselves.
>>
>> -----Original Message-----
>> From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Dane Edwards
>> Sent: Thursday, July 02, 2015 8:25 AM
>> To: r-sig-finance at r-project.org
>> Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill Williams)
>>
>> Hi, how do i create a custom indicator for quantmod / quantstrat. I'm trying to create a Fractal indicator (Bill Williams), the indicator needs to look back 5 days to calculate if a fractal has happened.
>> http://www.winnersedgetrading.com/how-to-trade-the-fractal-indicator/
>> This is in MQL language
>>   //----Fractals up      FractalFound=false;      dCurrent=High[i];      if(dCurrent>High[i+1] && dCurrent>High[i+2] && dCurrent>High[i-1] && dCurrent>High[i-2])        {         FractalFound=true;        }//i is the current day
>>
>> I'm not sure how the indicators work in quantstrat, in most backtesting software it loops through each day and calculates the indicator (for each day you then look back 5 days), does quanstrat do the same or do i need to write my own looping function in the indicator?
>> Thanks!!


From daneedwards1 at hotmail.com  Fri Jul  3 05:03:19 2015
From: daneedwards1 at hotmail.com (daneedwards1)
Date: Fri, 3 Jul 2015 13:03:19 +1000
Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by
 Bill Williams)
Message-ID: <DUB402-EAS61C225538CE8E23E0675ED82960@phx.gbl>

Thanks both, you answered my question. I'll read your presentations again.
Quantstrat works different to what I've used before, but I like it. Modular which is good


Sent from Samsung MobileThanks both, you answered my question. I'll read your presentations again. again.
Quantstrat works different to what I've used before, but I like it. Modular which is good


Sent from Samsung Mobile

-------- Original message --------
From: "Brian G. Peterson" <brian at braverock.com>
Date: 07/03/2015  11:39  (GMT+10:00)
To: r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill Williams)

On 07/02/2015 06:44 PM, Dane Edwards wrote:
> Thanks Ilya, does the indicator function get called for every row (like esignal, ninjatrader)  in the xts when the apply strategy function is called? or is the indicator function called once?
> i'm thinking now that the indicator column is calculated before applystrategy is ran, is this correct?


This is covered in the documentation.

You are certainly welcome to add a column or columns to your data before
calling applyStrategy, but you don't need to do that.

You indicator and signal functions are presumed to be path-independent.
  They should return an xts time series object of the same length as the
input data.

It is most efficient to write vectorized indicators or signals, but you
may write a loop if you like, it will just be slower.

Regards,

Brian

>> From: Ikipnis at grahamcapital.com
>> To: daneedwards1 at hotmail.com; r-sig-finance at r-project.org
>> Subject: RE: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill       Williams)
>> Date: Thu, 2 Jul 2015 12:42:43 +0000
>>
>> Indicators are just functions like any other R function. EG the quantstrat demos use a lot of the TTR functions, but those TTR are functions are just R functions themselves.
>>
>> -----Original Message-----
>> From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Dane Edwards
>> Sent: Thursday, July 02, 2015 8:25 AM
>> To: r-sig-finance at r-project.org
>> Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill Williams)
>>
>> Hi, how do i create a custom indicator for quantmod / quantstrat. I'm trying to create a Fractal indicator (Bill Williams), the indicator needs to look back 5 days to calculate if a fractal has happened.
>> http://www.winnersedgetrading.com/how-to-trade-the-fractal-indicator/
>> This is in MQL language
>>   //----Fractals up      FractalFound=false;      dCurrent=High[i];      if(dCurrent>High[i+1] && dCurrent>High[i+2] && dCurrent>High[i-1] && dCurrent>High[i-2])        {         FractalFound=true;        }//i is the current day
>>
>> I'm not sure how the indicators work in quantstrat, in most backtesting software it loops through each day and calculates the indicator (for each day you then look back 5 days), does quanstrat do the same or do i need to write my own looping function in the indicator?
>> Thanks!!

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Fri Jul  3 05:51:44 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 2 Jul 2015 22:51:44 -0500
Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by
	Bill Williams)
In-Reply-To: <DUB402-EAS61C225538CE8E23E0675ED82960@phx.gbl>
References: <DUB402-EAS61C225538CE8E23E0675ED82960@phx.gbl>
Message-ID: <CAPPM_gQ9YCOAFPWw27fqw+2xLO2uAf7mR8XZzPAX+46QNj-DPw@mail.gmail.com>

Please don't cross-post: http://quant.stackexchange.com/q/18634/56

At minimum, tell people you're doing it so they don't possibly expend
their valuable effort trying to answer a question that was answered on
another forum they do not follow.


On Thu, Jul 2, 2015 at 10:03 PM, daneedwards1 <daneedwards1 at hotmail.com> wrote:
> Thanks both, you answered my question. I'll read your presentations again.
> Quantstrat works different to what I've used before, but I like it. Modular which is good
>
>
> Sent from Samsung MobileThanks both, you answered my question. I'll read your presentations again. again.
> Quantstrat works different to what I've used before, but I like it. Modular which is good
>
>
> Sent from Samsung Mobile
>
> -------- Original message --------
> From: "Brian G. Peterson" <brian at braverock.com>
> Date: 07/03/2015  11:39  (GMT+10:00)
> To: r-sig-finance at r-project.org
> Subject: Re: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill Williams)
>
> On 07/02/2015 06:44 PM, Dane Edwards wrote:
>> Thanks Ilya, does the indicator function get called for every row (like esignal, ninjatrader)  in the xts when the apply strategy function is called? or is the indicator function called once?
>> i'm thinking now that the indicator column is calculated before applystrategy is ran, is this correct?
>
>
> This is covered in the documentation.
>
> You are certainly welcome to add a column or columns to your data before
> calling applyStrategy, but you don't need to do that.
>
> You indicator and signal functions are presumed to be path-independent.
>   They should return an xts time series object of the same length as the
> input data.
>
> It is most efficient to write vectorized indicators or signals, but you
> may write a loop if you like, it will just be slower.
>
> Regards,
>
> Brian
>
>>> From: Ikipnis at grahamcapital.com
>>> To: daneedwards1 at hotmail.com; r-sig-finance at r-project.org
>>> Subject: RE: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill       Williams)
>>> Date: Thu, 2 Jul 2015 12:42:43 +0000
>>>
>>> Indicators are just functions like any other R function. EG the quantstrat demos use a lot of the TTR functions, but those TTR are functions are just R functions themselves.
>>>
>>> -----Original Message-----
>>> From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Dane Edwards
>>> Sent: Thursday, July 02, 2015 8:25 AM
>>> To: r-sig-finance at r-project.org
>>> Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill Williams)
>>>
>>> Hi, how do i create a custom indicator for quantmod / quantstrat. I'm trying to create a Fractal indicator (Bill Williams), the indicator needs to look back 5 days to calculate if a fractal has happened.
>>> http://www.winnersedgetrading.com/how-to-trade-the-fractal-indicator/
>>> This is in MQL language
>>>   //----Fractals up      FractalFound=false;      dCurrent=High[i];      if(dCurrent>High[i+1] && dCurrent>High[i+2] && dCurrent>High[i-1] && dCurrent>High[i-2])        {         FractalFound=true;        }//i is the current day
>>>
>>> I'm not sure how the indicators work in quantstrat, in most backtesting software it loops through each day and calculates the indicator (for each day you then look back 5 days), does quanstrat do the same or do i need to write my own looping function in the indicator?
>>> Thanks!!
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From daneedwards1 at hotmail.com  Fri Jul  3 06:01:21 2015
From: daneedwards1 at hotmail.com (Dane Edwards)
Date: Fri, 3 Jul 2015 14:01:21 +1000
Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by
 Bill Williams)
In-Reply-To: <CAPPM_gQ9YCOAFPWw27fqw+2xLO2uAf7mR8XZzPAX+46QNj-DPw@mail.gmail.com>
References: <DUB402-EAS61C225538CE8E23E0675ED82960@phx.gbl>,
	<CAPPM_gQ9YCOAFPWw27fqw+2xLO2uAf7mR8XZzPAX+46QNj-DPw@mail.gmail.com>
Message-ID: <DUB131-W364ED80978E32CF15A23F382960@phx.gbl>

Yes they are similar but really two different questions,  posted on this list was help in understanding how the indicators functions are processed, so i could try create the indicator myself. the stack exchange post was asking if anyone has seen that indicator before (as its not in the TTR package), so i would not have to code it myself. Note taken. 




> From: josh.m.ulrich at gmail.com
> Date: Thu, 2 Jul 2015 22:51:44 -0500
> Subject: Re: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill Williams)
> To: daneedwards1 at hotmail.com
> CC: brian at braverock.com; r-sig-finance at r-project.org
> 
> Please don't cross-post: http://quant.stackexchange.com/q/18634/56
> 
> At minimum, tell people you're doing it so they don't possibly expend
> their valuable effort trying to answer a question that was answered on
> another forum they do not follow.
> 
> 
> On Thu, Jul 2, 2015 at 10:03 PM, daneedwards1 <daneedwards1 at hotmail.com> wrote:
> > Thanks both, you answered my question. I'll read your presentations again.
> > Quantstrat works different to what I've used before, but I like it. Modular which is good
> >
> >
> > Sent from Samsung MobileThanks both, you answered my question. I'll read your presentations again. again.
> > Quantstrat works different to what I've used before, but I like it. Modular which is good
> >
> >
> > Sent from Samsung Mobile
> >
> > -------- Original message --------
> > From: "Brian G. Peterson" <brian at braverock.com>
> > Date: 07/03/2015  11:39  (GMT+10:00)
> > To: r-sig-finance at r-project.org
> > Subject: Re: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill Williams)
> >
> > On 07/02/2015 06:44 PM, Dane Edwards wrote:
> >> Thanks Ilya, does the indicator function get called for every row (like esignal, ninjatrader)  in the xts when the apply strategy function is called? or is the indicator function called once?
> >> i'm thinking now that the indicator column is calculated before applystrategy is ran, is this correct?
> >
> >
> > This is covered in the documentation.
> >
> > You are certainly welcome to add a column or columns to your data before
> > calling applyStrategy, but you don't need to do that.
> >
> > You indicator and signal functions are presumed to be path-independent.
> >   They should return an xts time series object of the same length as the
> > input data.
> >
> > It is most efficient to write vectorized indicators or signals, but you
> > may write a loop if you like, it will just be slower.
> >
> > Regards,
> >
> > Brian
> >
> >>> From: Ikipnis at grahamcapital.com
> >>> To: daneedwards1 at hotmail.com; r-sig-finance at r-project.org
> >>> Subject: RE: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill       Williams)
> >>> Date: Thu, 2 Jul 2015 12:42:43 +0000
> >>>
> >>> Indicators are just functions like any other R function. EG the quantstrat demos use a lot of the TTR functions, but those TTR are functions are just R functions themselves.
> >>>
> >>> -----Original Message-----
> >>> From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Dane Edwards
> >>> Sent: Thursday, July 02, 2015 8:25 AM
> >>> To: r-sig-finance at r-project.org
> >>> Subject: [R-SIG-Finance] Custom indicator for Quantstrat (Fractals by Bill Williams)
> >>>
> >>> Hi, how do i create a custom indicator for quantmod / quantstrat. I'm trying to create a Fractal indicator (Bill Williams), the indicator needs to look back 5 days to calculate if a fractal has happened.
> >>> http://www.winnersedgetrading.com/how-to-trade-the-fractal-indicator/
> >>> This is in MQL language
> >>>   //----Fractals up      FractalFound=false;      dCurrent=High[i];      if(dCurrent>High[i+1] && dCurrent>High[i+2] && dCurrent>High[i-1] && dCurrent>High[i-2])        {         FractalFound=true;        }//i is the current day
> >>>
> >>> I'm not sure how the indicators work in quantstrat, in most backtesting software it loops through each day and calculates the indicator (for each day you then look back 5 days), does quanstrat do the same or do i need to write my own looping function in the indicator?
> >>> Thanks!!
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions should go.
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions should go.
> 
> 
> 
> -- 
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
 		 	   		  
	[[alternative HTML version deleted]]


From agracian at yahoo.co.uk  Fri Jul  3 10:17:38 2015
From: agracian at yahoo.co.uk (Alexander Gracian)
Date: Fri, 3 Jul 2015 08:17:38 +0000 (UTC)
Subject: [R-SIG-Finance] getSymbols for FRED in quantmod has stopped
	working???
Message-ID: <247111061.2447960.1435911458955.JavaMail.yahoo@mail.yahoo.com>


Hi,
I have started getting an error when using getSymbols for FRED in quantmod. It was working fine a few weeks ago. I'm using R on a Mac:
getSymbols("CPIAUCSL", src="FRED")Error in download.file(paste(FRED.URL, "/", Symbols[[i]], "/", "downloaddata/", ?:?? cannot open URL 'http://research.stlouisfed.org/fred2/series/CPIAUCSL/downloaddata/CPIAUCSL.csv'
If I paste the URL in the error message into a browser it downloads the csv?fine, so I think the url is ok.It also works ok for other sources, such as yahoo etc.
Any insights would be appreciated.
Thanks,Alex
	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Fri Jul  3 17:30:48 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 3 Jul 2015 10:30:48 -0500
Subject: [R-SIG-Finance] getSymbols for FRED in quantmod has stopped
	working???
In-Reply-To: <247111061.2447960.1435911458955.JavaMail.yahoo@mail.yahoo.com>
References: <247111061.2447960.1435911458955.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAPPM_gTUnHogn7JUh0sz9hHi2tg+M4tVuJXhRCJZKjLoR7ZnBg@mail.gmail.com>

On Fri, Jul 3, 2015 at 3:17 AM, Alexander Gracian <agracian at yahoo.co.uk> wrote:
>
> Hi,
> I have started getting an error when using getSymbols for FRED in quantmod. It was working fine a few weeks ago. I'm using R on a Mac:
> getSymbols("CPIAUCSL", src="FRED")Error in download.file(paste(FRED.URL, "/", Symbols[[i]], "/", "downloaddata/",  :   cannot open URL 'http://research.stlouisfed.org/fred2/series/CPIAUCSL/downloaddata/CPIAUCSL.csv'
> If I paste the URL in the error message into a browser it downloads the csv fine, so I think the url is ok.It also works ok for other sources, such as yahoo etc.

The FRED http:// URLs now redirect to https://.  That causes issues
with the default method for download.file on some platforms.  I'm
aware of the issue and working on a fix.

See the conversation on R-package-devel if you're interested in the details:
https://stat.ethz.ch/pipermail/r-package-devel/2015q3/000193.html

> Any insights would be appreciated.
> Thanks,Alex
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From danielmelendez at alum.northwestern.edu  Fri Jul  3 18:05:35 2015
From: danielmelendez at alum.northwestern.edu (Daniel Melendez)
Date: Fri, 3 Jul 2015 11:05:35 -0500
Subject: [R-SIG-Finance] getSymbols for FRED in quantmod has stopped
	working???
In-Reply-To: <CAPPM_gTUnHogn7JUh0sz9hHi2tg+M4tVuJXhRCJZKjLoR7ZnBg@mail.gmail.com>
References: <247111061.2447960.1435911458955.JavaMail.yahoo@mail.yahoo.com>
	<CAPPM_gTUnHogn7JUh0sz9hHi2tg+M4tVuJXhRCJZKjLoR7ZnBg@mail.gmail.com>
Message-ID: <CAEjpDDqT0-OeVYmd+wA7arSWEWabYWR8hidJJQSOsdW=4+25qg@mail.gmail.com>

As a suggestion ( although not that efficient ) there is an excel macro
that can download the information.  I'm not sure if you're aware of it or
not but just thought I'd mention it just in case.

https://research.stlouisfed.org/fred-addin/

On Fri, Jul 3, 2015 at 10:30 AM, Joshua Ulrich <josh.m.ulrich at gmail.com>
wrote:

> On Fri, Jul 3, 2015 at 3:17 AM, Alexander Gracian <agracian at yahoo.co.uk>
> wrote:
> >
> > Hi,
> > I have started getting an error when using getSymbols for FRED in
> quantmod. It was working fine a few weeks ago. I'm using R on a Mac:
> > getSymbols("CPIAUCSL", src="FRED")Error in download.file(paste(FRED.URL,
> "/", Symbols[[i]], "/", "downloaddata/",  :   cannot open URL '
> http://research.stlouisfed.org/fred2/series/CPIAUCSL/downloaddata/CPIAUCSL.csv
> '
> > If I paste the URL in the error message into a browser it downloads the
> csv fine, so I think the url is ok.It also works ok for other sources, such
> as yahoo etc.
>
> The FRED http:// URLs now redirect to https://.  That causes issues
> with the default method for download.file on some platforms.  I'm
> aware of the issue and working on a fix.
>
> See the conversation on R-package-devel if you're interested in the
> details:
> https://stat.ethz.ch/pipermail/r-package-devel/2015q3/000193.html
>
> > Any insights would be appreciated.
> > Thanks,Alex
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>



-- 
Regards

Daniel Melendez

=========================================================================

	[[alternative HTML version deleted]]


From pgrahl at gmail.com  Fri Jul  3 19:30:56 2015
From: pgrahl at gmail.com (Paulo Grahl)
Date: Fri, 3 Jul 2015 14:30:56 -0300
Subject: [R-SIG-Finance] getSymbols for FRED in quantmod has stopped
	working???
In-Reply-To: <CAEjpDDqT0-OeVYmd+wA7arSWEWabYWR8hidJJQSOsdW=4+25qg@mail.gmail.com>
References: <247111061.2447960.1435911458955.JavaMail.yahoo@mail.yahoo.com>
	<CAPPM_gTUnHogn7JUh0sz9hHi2tg+M4tVuJXhRCJZKjLoR7ZnBg@mail.gmail.com>
	<CAEjpDDqT0-OeVYmd+wA7arSWEWabYWR8hidJJQSOsdW=4+25qg@mail.gmail.com>
Message-ID: <CAMPBK=tfVFofe0dyo8=c_5zVJ3Aekyp9qottJkRrYEVvaxJYAQ@mail.gmail.com>

There's also a package FredR. Last time I checked (few months ago) it was
working.

https://github.com/jcizel/FredR

On Fri, Jul 3, 2015 at 1:05 PM, Daniel Melendez <
danielmelendez at alum.northwestern.edu> wrote:

> As a suggestion ( although not that efficient ) there is an excel macro
> that can download the information.  I'm not sure if you're aware of it or
> not but just thought I'd mention it just in case.
>
> https://research.stlouisfed.org/fred-addin/
>
> On Fri, Jul 3, 2015 at 10:30 AM, Joshua Ulrich <josh.m.ulrich at gmail.com>
> wrote:
>
> > On Fri, Jul 3, 2015 at 3:17 AM, Alexander Gracian <agracian at yahoo.co.uk>
> > wrote:
> > >
> > > Hi,
> > > I have started getting an error when using getSymbols for FRED in
> > quantmod. It was working fine a few weeks ago. I'm using R on a Mac:
> > > getSymbols("CPIAUCSL", src="FRED")Error in
> download.file(paste(FRED.URL,
> > "/", Symbols[[i]], "/", "downloaddata/",  :   cannot open URL '
> >
> http://research.stlouisfed.org/fred2/series/CPIAUCSL/downloaddata/CPIAUCSL.csv
> > '
> > > If I paste the URL in the error message into a browser it downloads the
> > csv fine, so I think the url is ok.It also works ok for other sources,
> such
> > as yahoo etc.
> >
> > The FRED http:// URLs now redirect to https://.  That causes issues
> > with the default method for download.file on some platforms.  I'm
> > aware of the issue and working on a fix.
> >
> > See the conversation on R-package-devel if you're interested in the
> > details:
> > https://stat.ethz.ch/pipermail/r-package-devel/2015q3/000193.html
> >
> > > Any insights would be appreciated.
> > > Thanks,Alex
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-SIG-Finance at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > > -- Subscriber-posting only. If you want to post, subscribe first.
> > > -- Also note that this is not the r-help list where general R questions
> > should go.
> >
> >
> >
> > --
> > Joshua Ulrich  |  about.me/joshuaulrich
> > FOSS Trading  |  www.fosstrading.com
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> > should go.
> >
>
>
>
> --
> Regards
>
> Daniel Melendez
>
> =========================================================================
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From pgilbert902 at gmail.com  Sat Jul  4 01:11:14 2015
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 03 Jul 2015 19:11:14 -0400
Subject: [R-SIG-Finance] getSymbols for FRED in quantmod has stopped
	working???
In-Reply-To: <CAEjpDDqT0-OeVYmd+wA7arSWEWabYWR8hidJJQSOsdW=4+25qg@mail.gmail.com>
References: <247111061.2447960.1435911458955.JavaMail.yahoo@mail.yahoo.com>	<CAPPM_gTUnHogn7JUh0sz9hHi2tg+M4tVuJXhRCJZKjLoR7ZnBg@mail.gmail.com>
	<CAEjpDDqT0-OeVYmd+wA7arSWEWabYWR8hidJJQSOsdW=4+25qg@mail.gmail.com>
Message-ID: <55971692.9010806@gmail.com>

The discussion on R-pkg-devel has been about how to fix default 
download.file behaviour that has previously worked on all platforms, and 
is now broken by a very recent change at the St Louis Fed. A method 
working a few days ago would not be a guarantee that it still works. 
Before people go overboard changing their workflow, let me point out 
that this can likely be fixed by a user setting

    options(download.file.method="libcurl")
or
    options(download.file.method="wget")
or
    options(download.file.method="wininet")

See ?download.file  for more options, which will be platform specific 
(but maybe not as specific as using an excel macro).

The package developer problem is slightly different. That problem, the 
problem that Joshua is working on, is that the default method no longer 
works. So either the default method has to be fixed or users need to be 
directed to some solution that will depend on their platform.

Paul

On 07/03/2015 12:05 PM, Daniel Melendez wrote:
> As a suggestion ( although not that efficient ) there is an excel macro
> that can download the information.  I'm not sure if you're aware of it or
> not but just thought I'd mention it just in case.
>
> https://research.stlouisfed.org/fred-addin/
>
> On Fri, Jul 3, 2015 at 10:30 AM, Joshua Ulrich <josh.m.ulrich at gmail.com>
> wrote:
>
>> On Fri, Jul 3, 2015 at 3:17 AM, Alexander Gracian <agracian at yahoo.co.uk>
>> wrote:
>>>
>>> Hi,
>>> I have started getting an error when using getSymbols for FRED in
>> quantmod. It was working fine a few weeks ago. I'm using R on a Mac:
>>> getSymbols("CPIAUCSL", src="FRED")Error in download.file(paste(FRED.URL,
>> "/", Symbols[[i]], "/", "downloaddata/",  :   cannot open URL '
>> http://research.stlouisfed.org/fred2/series/CPIAUCSL/downloaddata/CPIAUCSL.csv
>> '
>>> If I paste the URL in the error message into a browser it downloads the
>> csv fine, so I think the url is ok.It also works ok for other sources, such
>> as yahoo etc.
>>
>> The FRED http:// URLs now redirect to https://.  That causes issues
>> with the default method for download.file on some platforms.  I'm
>> aware of the issue and working on a fix.
>>
>> See the conversation on R-package-devel if you're interested in the
>> details:
>> https://stat.ethz.ch/pipermail/r-package-devel/2015q3/000193.html
>>
>>> Any insights would be appreciated.
>>> Thanks,Alex
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>>
>>
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>
>


From kunalshah305 at gmail.com  Sun Jul  5 08:33:40 2015
From: kunalshah305 at gmail.com (Kunal Shah)
Date: Sun, 5 Jul 2015 12:03:40 +0530
Subject: [R-SIG-Finance] Web/Server Interface for R Files
Message-ID: <CAOPdpkZiS=WB8QGaZsGznM2xTqwE0OJ_k5TGW1w+qcB7iVgVJA@mail.gmail.com>

Hello,

I have the following code

#### From excel.link package

xl.workbook.activate("ADSnippetXLS.xlsx")
source('ActiveDeltaSnippet2.R')

#### "ActiveDeltaSnippet2.R" takes data from ADSnippetXLS, performs some
computations on the data and outputs the data back into "ADSnippetXLS.xlsx"


I dont want that the file "ActiveDeltaSnippet2.R" to be stored on the same
PC. In fact I want to call this R file which might be stored on any
server/Web

I tried to search Shiny and ROOK but got lost in the literature.
Any help will be appreciated

Regards

	[[alternative HTML version deleted]]


From brian at braverock.com  Sun Jul  5 13:27:06 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 05 Jul 2015 06:27:06 -0500
Subject: [R-SIG-Finance] Web/Server Interface for R Files
In-Reply-To: <CAOPdpkZiS=WB8QGaZsGznM2xTqwE0OJ_k5TGW1w+qcB7iVgVJA@mail.gmail.com>
References: <CAOPdpkZiS=WB8QGaZsGznM2xTqwE0OJ_k5TGW1w+qcB7iVgVJA@mail.gmail.com>
Message-ID: <5599148A.7090409@braverock.com>

This is not a finance question.

Please direct it to R-Help or StackOverflow, where such questions belong 
(and remember not to cross-post to r-help and SO)

Brian


On 07/05/2015 01:33 AM, Kunal Shah wrote:
> Hello,
>
> I have the following code
>
> #### From excel.link package
>
> xl.workbook.activate("ADSnippetXLS.xlsx")
> source('ActiveDeltaSnippet2.R')
>
> #### "ActiveDeltaSnippet2.R" takes data from ADSnippetXLS, performs some
> computations on the data and outputs the data back into "ADSnippetXLS.xlsx"
>
>
> I dont want that the file "ActiveDeltaSnippet2.R" to be stored on the same
> PC. In fact I want to call this R file which might be stored on any
> server/Web
>
> I tried to search Shiny and ROOK but got lost in the literature.
> Any help will be appreciated
>
> Regards
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From danfeng_bi at yahoo.com  Sun Jul  5 22:20:47 2015
From: danfeng_bi at yahoo.com (Dan Bi)
Date: Sun, 5 Jul 2015 13:20:47 -0700
Subject: [R-SIG-Finance] R-SIG-Finance Digest, Vol 134, Issue 4
In-Reply-To: <mailman.17.1436090403.17226.r-sig-finance@r-project.org>
References: <mailman.17.1436090403.17226.r-sig-finance@r-project.org>
Message-ID: <48479.82597.bm@smtp205.mail.bf1.yahoo.com>

As. U

-----Original Message-----
From: "r-sig-finance-request at r-project.org" <r-sig-finance-request at r-project.org>
Sent: ?7/?5/?2015 3:03 AM
To: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org>
Subject: R-SIG-Finance Digest, Vol 134, Issue 4

Send R-SIG-Finance mailing list submissions to
	r-sig-finance at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-finance
or, via email, send a message with subject or body 'help' to
	r-sig-finance-request at r-project.org

You can reach the person managing the list at
	r-sig-finance-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-SIG-Finance digest..."


Today's Topics:

   1. Web/Server Interface for R Files (Kunal Shah)


----------------------------------------------------------------------

Message: 1
Date: Sun, 5 Jul 2015 12:03:40 +0530
From: Kunal Shah <kunalshah305 at gmail.com>
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] Web/Server Interface for R Files
Message-ID:
	<CAOPdpkZiS=WB8QGaZsGznM2xTqwE0OJ_k5TGW1w+qcB7iVgVJA at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Hello,

I have the following code

#### From excel.link package

xl.workbook.activate("ADSnippetXLS.xlsx")
source('ActiveDeltaSnippet2.R')

#### "ActiveDeltaSnippet2.R" takes data from ADSnippetXLS, performs some
computations on the data and outputs the data back into "ADSnippetXLS.xlsx"


I dont want that the file "ActiveDeltaSnippet2.R" to be stored on the same
PC. In fact I want to call this R file which might be stored on any
server/Web

I tried to search Shiny and ROOK but got lost in the literature.
Any help will be appreciated

Regards

	[[alternative HTML version deleted]]



------------------------------

Subject: Digest Footer

_______________________________________________
R-SIG-Finance mailing list
R-SIG-Finance at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-finance

------------------------------

End of R-SIG-Finance Digest, Vol 134, Issue 4
*********************************************

	[[alternative HTML version deleted]]


From roger.bos at rothschild.com  Mon Jul  6 16:49:30 2015
From: roger.bos at rothschild.com (Bos, Roger)
Date: Mon, 6 Jul 2015 14:49:30 +0000
Subject: [R-SIG-Finance] getSymbols for FRED in quantmod has
	stopped	working???
In-Reply-To: <55971692.9010806@gmail.com>
References: <247111061.2447960.1435911458955.JavaMail.yahoo@mail.yahoo.com>
	<CAPPM_gTUnHogn7JUh0sz9hHi2tg+M4tVuJXhRCJZKjLoR7ZnBg@mail.gmail.com>
	<CAEjpDDqT0-OeVYmd+wA7arSWEWabYWR8hidJJQSOsdW=4+25qg@mail.gmail.com>
	<55971692.9010806@gmail.com>
Message-ID: <0765308CD028654885F30322557308D81EEE6218@NYCSM0208.rth.ad.rothschild.com>

I just about to post a question about this.  I ended up fixing it an easy way as well, by adding this line:

setInternet2(TRUE)

I just don't know why or what exactly it does.

Thanks,

Roger



***************************************************************
This message and any attachments are for the intended recipient's use only.
This message may contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message, any attachments and all
copies from your system and destroy any hard copies.  You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message or any attachments if you are not
the intended recipient.


-----Original Message-----
From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Paul Gilbert
Sent: Friday, July 03, 2015 7:11 PM
To: r-sig-finance at r-project.org
Subject: Re: [R-SIG-Finance] getSymbols for FRED in quantmod has stopped working???

The discussion on R-pkg-devel has been about how to fix default download.file behaviour that has previously worked on all platforms, and is now broken by a very recent change at the St Louis Fed. A method working a few days ago would not be a guarantee that it still works.
Before people go overboard changing their workflow, let me point out that this can likely be fixed by a user setting

    options(download.file.method="libcurl")
or
    options(download.file.method="wget")
or
    options(download.file.method="wininet")

See ?download.file  for more options, which will be platform specific (but maybe not as specific as using an excel macro).

The package developer problem is slightly different. That problem, the problem that Joshua is working on, is that the default method no longer works. So either the default method has to be fixed or users need to be directed to some solution that will depend on their platform.

Paul

On 07/03/2015 12:05 PM, Daniel Melendez wrote:
> As a suggestion ( although not that efficient ) there is an excel
> macro that can download the information.  I'm not sure if you're aware
> of it or not but just thought I'd mention it just in case.
>
> https://research.stlouisfed.org/fred-addin/
>
> On Fri, Jul 3, 2015 at 10:30 AM, Joshua Ulrich
> <josh.m.ulrich at gmail.com>
> wrote:
>
>> On Fri, Jul 3, 2015 at 3:17 AM, Alexander Gracian
>> <agracian at yahoo.co.uk>
>> wrote:
>>>
>>> Hi,
>>> I have started getting an error when using getSymbols for FRED in
>> quantmod. It was working fine a few weeks ago. I'm using R on a Mac:
>>> getSymbols("CPIAUCSL", src="FRED")Error in
>>> download.file(paste(FRED.URL,
>> "/", Symbols[[i]], "/", "downloaddata/",  :   cannot open URL '
>> http://research.stlouisfed.org/fred2/series/CPIAUCSL/downloaddata/CPI
>> AUCSL.csv
>> '
>>> If I paste the URL in the error message into a browser it downloads
>>> the
>> csv fine, so I think the url is ok.It also works ok for other
>> sources, such as yahoo etc.
>>
>> The FRED http:// URLs now redirect to https://.  That causes issues
>> with the default method for download.file on some platforms.  I'm
>> aware of the issue and working on a fix.
>>
>> See the conversation on R-package-devel if you're interested in the
>> details:
>> https://stat.ethz.ch/pipermail/r-package-devel/2015q3/000193.html
>>
>>> Any insights would be appreciated.
>>> Thanks,Alex
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R
>>> questions
>> should go.
>>
>>
>>
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich FOSS Trading  |
>> www.fosstrading.com
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R
>> questions should go.
>>
>
>
>

_______________________________________________
R-SIG-Finance at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.

From aaron at quantrisktrading.com  Mon Jul  6 21:27:57 2015
From: aaron at quantrisktrading.com (Aaron Goldenberg)
Date: Mon, 6 Jul 2015 15:27:57 -0400
Subject: [R-SIG-Finance] RBlpapi
Message-ID: <CAG7y0gpU+NYDp+AKDsTyo-ALsjds+vKKtidDZ=dTAe8_-_JAOA@mail.gmail.com>

I was excited to try out the RBlpapi package until I discovered that
Bloomberg professional does not have a Linux download. If RBlpapi runs on
Linux, how do you use it with Bloomberg?

	[[alternative HTML version deleted]]


From n-e-w at qtradr.net  Mon Jul  6 23:17:07 2015
From: n-e-w at qtradr.net (Nick White)
Date: Tue, 7 Jul 2015 07:17:07 +1000
Subject: [R-SIG-Finance] RBlpapi
In-Reply-To: <CAG7y0gpU+NYDp+AKDsTyo-ALsjds+vKKtidDZ=dTAe8_-_JAOA@mail.gmail.com>
References: <CAG7y0gpU+NYDp+AKDsTyo-ALsjds+vKKtidDZ=dTAe8_-_JAOA@mail.gmail.com>
Message-ID: <CAH+4RFsVGpT+asv+iBpVNdUwCEM5WPVe0zBUENimedOqtHQBuA@mail.gmail.com>

Server API or B-PIPE subscription.

Has anyone tried connecting their Rblpapi on a Linux VM to the necessary
terminal desktop ports?



On Tuesday, July 7, 2015, Aaron Goldenberg <aaron at quantrisktrading.com>
wrote:

> I was excited to try out the RBlpapi package until I discovered that
> Bloomberg professional does not have a Linux download. If RBlpapi runs on
> Linux, how do you use it with Bloomberg?
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From armstrong.whit at gmail.com  Tue Jul  7 00:22:05 2015
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Mon, 6 Jul 2015 18:22:05 -0400
Subject: [R-SIG-Finance] RBlpapi
In-Reply-To: <CAH+4RFsVGpT+asv+iBpVNdUwCEM5WPVe0zBUENimedOqtHQBuA@mail.gmail.com>
References: <CAG7y0gpU+NYDp+AKDsTyo-ALsjds+vKKtidDZ=dTAe8_-_JAOA@mail.gmail.com>
	<CAH+4RFsVGpT+asv+iBpVNdUwCEM5WPVe0zBUENimedOqtHQBuA@mail.gmail.com>
Message-ID: <CAMi=pg7LfMS71ARE-vcYR_dP0TFAEEWOXiBk=aLtCaTJLcYV4w@mail.gmail.com>

IANAL and all that, but...

My usual advice, if you happen to have two machines called W and L...

1) download socat.

2) run this as a batch file on machine "W":
start c:\blp\API\bbcomm.exe
socat TCP4-LISTEN:18194,fork TCP4:localhost:8194

3) connect like this from R on machine "L":

## set your options in your .Rprofile
options(
blpAutoConnect=TRUE,
blpHost="W",
blpPort=18194L)

library(Rblpapi) ## will establish the connection on startup if
blpAutoConnect=TRUE
is in your options

Like I mentioned, consult your in house council before running w/ this.

-Whit



On Mon, Jul 6, 2015 at 5:17 PM, Nick White <n-e-w at qtradr.net> wrote:

> Server API or B-PIPE subscription.
>
> Has anyone tried connecting their Rblpapi on a Linux VM to the necessary
> terminal desktop ports?
>
>
>
> On Tuesday, July 7, 2015, Aaron Goldenberg <aaron at quantrisktrading.com>
> wrote:
>
> > I was excited to try out the RBlpapi package until I discovered that
> > Bloomberg professional does not have a Linux download. If RBlpapi runs on
> > Linux, how do you use it with Bloomberg?
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org <javascript:;> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> > should go.
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From kw1958 at gmail.com  Tue Jul  7 18:35:13 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Tue, 7 Jul 2015 12:35:13 -0400
Subject: [R-SIG-Finance] Complex yields.
Message-ID: <BB7271B9-6A7C-40CF-B53E-D04CDE5D4023@gmail.com>

Folks,

Forgive me if I have asked this before in this forum.

I have been working on some bonds with odd cashflows and I need to be able to back out the yield from the price.

Sometimes the yield will turn out to be complex.

I have used the polyroot function in {base} R which works fine. Usually there are a number of non-complex roots that make sense.

The problem with using polyroot is that the exponents have to be integers (polyroot <?> polynomial). That leaves me with a bit of a problem when I want to find the yield of a bond with coupons on off-dates.

For example suppose I have an 11 day front stub and semi-annual coupon payments. With coupon payments at 11, 191, 376, ? I would then have to convert to days and have a problematic numerical calculation.

If you have any pointers to papers on this or code I would greatly appreciate it.

Thanks so much for your time,
Best,
KW


From chijerej at icloud.com  Tue Jul  7 22:43:05 2015
From: chijerej at icloud.com (Chijere Joseph)
Date: Tue, 07 Jul 2015 20:43:05 +0000 (GMT)
Subject: [R-SIG-Finance] TVAR Coefficient Intepretation
Message-ID: <3e374d56-5b53-4925-ad0b-899d79dd47f7@me.com>

Hello

I was trying to use the TVAR function to estimate exchange rate pass-through

i am getting the results in almost a matrix/list form

i was wondering on how one goes about interpreting TVAR coeffiecients
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20150707/286e4406/attachment.html>

From blinkychinky at yahoo.com  Wed Jul  8 22:47:29 2015
From: blinkychinky at yahoo.com (Kads Bennurkar)
Date: Wed, 8 Jul 2015 20:47:29 +0000 (UTC)
Subject: [R-SIG-Finance] Parma / MAxReward Portfolio
Message-ID: <1705887661.1492843.1436388449098.JavaMail.yahoo@mail.yahoo.com>

Hi,?
I'm trying to generate an efficient frontier for a MaxReward portfolio and get the weights of the portfolios lying on the efficient frontier.?
So far I have been able to get a maxReward portfolio using Parma package. However, I keep getting error while trying to generate ?an Efficient Frontier.?
codes:data(etfdata)R = ROC(etfdata, na.pad=FALSE)riskB = (15^2)/12spec ? <- parmaspec(S = as.matrix(cov(R1)), riskB=riskB,risk="EV",riskType="maxreward", LB = rep(0.05,15), ? ? ? ? ? ? ? ? ? ?UB = rep(0.35,15), budget=1, forecast=as.numeric(colMeans(R1)))port <- parmasolve(spec, solver="SOCP"); port ??

Issue:?parmafrontier(spec, n.points = 100, solver="SOCP")?


Thanks!

	[[alternative HTML version deleted]]


From alexios at 4dscape.com  Wed Jul  8 23:32:26 2015
From: alexios at 4dscape.com (alexios)
Date: Wed, 8 Jul 2015 22:32:26 +0100
Subject: [R-SIG-Finance] Parma / MAxReward Portfolio
In-Reply-To: <1705887661.1492843.1436388449098.JavaMail.yahoo@mail.yahoo.com>
References: <1705887661.1492843.1436388449098.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <559D96EA.4060304@4dscape.com>

Why don't you use riskType="minrisk"? They are equivalent!
And parma in any case only uses the minrisk.

...but, when in doubt:

library(xts)
data("etfdata")
R = etfdata/lag(etfdata)-1
R = na.omit(R)
S = cov(coredata(R))
LB = rep(0, 15)
UB = rep(1, 15)
fmu = colMeans(coredata(R))

spec = parmaspec(S = S, forecast = fmu, target = NULL, LB = LB, UB = UB,
risk = "EV", riskType = "minrisk", targetType = "equality",budget = 1)

frontqp = parmafrontier(spec, n.points = 100)
riskB = sqrt(frontqp[,"EV"])
rewardQP = frontqp[,"reward"]

rewardSOCP = rep(0, 100)
control=list(abs.tol = 1e-8, rel.tol = 1e-8, Nu=4, max.iter=1250,
BigM.K = 4, BigM.iter = 15)
for(i in 1:100){
spec = parmaspec(S = S, forecast = fmu, target = NULL, LB = LB, UB = UB, 
riskB = riskB[i], risk = "EV", riskType = "maxReward", targetType = 
"equality",budget = 1)
tmp<-parmasolve(spec, solver="SOCP",solver.control=control)
rewardSOCP[i]=parmareward(tmp)
}

par(mfrow=c(2,1))
plot(rewardQP)
lines(rewardSOCP, col=2)
plot(riskB, rewardQP)
lines(riskB, rewardSOCP, col=2)

-Alexios

On 08/07/2015 21:47, Kads Bennurkar via R-SIG-Finance wrote:
> Hi,
> I'm trying to generate an efficient frontier for a MaxReward portfolio and get the weights of the portfolios lying on the efficient frontier.
> So far I have been able to get a maxReward portfolio using Parma package. However, I keep getting error while trying to generate  an Efficient Frontier.
> codes:data(etfdata)R = ROC(etfdata, na.pad=FALSE)riskB = (15^2)/12spec   <- parmaspec(S = as.matrix(cov(R1)), riskB=riskB,risk="EV",riskType="maxreward", LB = rep(0.05,15),                    UB = rep(0.35,15), budget=1, forecast=as.numeric(colMeans(R1)))port <- parmasolve(spec, solver="SOCP"); port
>
> Issue: parmafrontier(spec, n.points = 100, solver="SOCP")
>
>
> Thanks!
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From blinkychinky at yahoo.com  Thu Jul  9 03:03:47 2015
From: blinkychinky at yahoo.com (Kads Bennurkar)
Date: Thu, 9 Jul 2015 01:03:47 +0000 (UTC)
Subject: [R-SIG-Finance] Parma / MAxReward Portfolio
In-Reply-To: <559D96EA.4060304@4dscape.com>
References: <559D96EA.4060304@4dscape.com>
Message-ID: <2027918420.1622662.1436403827807.JavaMail.yahoo@mail.yahoo.com>

That worked! Thank you so much Alexios.?
I had tried risktype="minrisk" and I had also tried?parmafrontier(spec, n.points = 100) but it kept giving me errors. But it ran this time.?
Thank you again for your prompt response! This is very helpful.?
Best,?Kads 


     On Wednesday, July 8, 2015 4:32 PM, alexios <alexios at 4dscape.com> wrote:
   

 Why don't you use riskType="minrisk"? They are equivalent!
And parma in any case only uses the minrisk.

...but, when in doubt:

library(xts)
data("etfdata")
R = etfdata/lag(etfdata)-1
R = na.omit(R)
S = cov(coredata(R))
LB = rep(0, 15)
UB = rep(1, 15)
fmu = colMeans(coredata(R))

spec = parmaspec(S = S, forecast = fmu, target = NULL, LB = LB, UB = UB,
risk = "EV", riskType = "minrisk", targetType = "equality",budget = 1)

frontqp = parmafrontier(spec, n.points = 100)
riskB = sqrt(frontqp[,"EV"])
rewardQP = frontqp[,"reward"]

rewardSOCP = rep(0, 100)
control=list(abs.tol = 1e-8, rel.tol = 1e-8, Nu=4, max.iter=1250,
BigM.K = 4, BigM.iter = 15)
for(i in 1:100){
spec = parmaspec(S = S, forecast = fmu, target = NULL, LB = LB, UB = UB, 
riskB = riskB[i], risk = "EV", riskType = "maxReward", targetType = 
"equality",budget = 1)
tmp<-parmasolve(spec, solver="SOCP",solver.control=control)
rewardSOCP[i]=parmareward(tmp)
}

par(mfrow=c(2,1))
plot(rewardQP)
lines(rewardSOCP, col=2)
plot(riskB, rewardQP)
lines(riskB, rewardSOCP, col=2)

-Alexios

On 08/07/2015 21:47, Kads Bennurkar via R-SIG-Finance wrote:
> Hi,
> I'm trying to generate an efficient frontier for a MaxReward portfolio and get the weights of the portfolios lying on the efficient frontier.
> So far I have been able to get a maxReward portfolio using Parma package. However, I keep getting error while trying to generate? an Efficient Frontier.
> codes:data(etfdata)R = ROC(etfdata, na.pad=FALSE)riskB = (15^2)/12spec? <- parmaspec(S = as.matrix(cov(R1)), riskB=riskB,risk="EV",riskType="maxreward", LB = rep(0.05,15),? ? ? ? ? ? ? ? ? ? UB = rep(0.35,15), budget=1, forecast=as.numeric(colMeans(R1)))port <- parmasolve(spec, solver="SOCP"); port
>
> Issue: parmafrontier(spec, n.points = 100, solver="SOCP")
>
>
> Thanks!
>
> ??? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>



  
	[[alternative HTML version deleted]]


From weihanliu2002 at yahoo.com  Thu Jul  9 08:40:13 2015
From: weihanliu2002 at yahoo.com (Wei-han Liu)
Date: Thu, 9 Jul 2015 06:40:13 +0000 (UTC)
Subject: [R-SIG-Finance] databases of carbon prices
Message-ID: <644033923.2011446.1436424013030.JavaMail.yahoo@mail.yahoo.com>

Dear R users:
Could some people share some information about where to download the time series of carbon prices over some countries? Commercial database or free online source will do.
Thanks for your kind attention.
Weihan

	[[alternative HTML version deleted]]


From danielmelendez at alum.northwestern.edu  Thu Jul  9 09:57:49 2015
From: danielmelendez at alum.northwestern.edu (Daniel Melendez)
Date: Thu, 9 Jul 2015 02:57:49 -0500
Subject: [R-SIG-Finance] databases of carbon prices
In-Reply-To: <644033923.2011446.1436424013030.JavaMail.yahoo@mail.yahoo.com>
References: <644033923.2011446.1436424013030.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAEjpDDoz7Jks3DyfB8vSg4f3GkXkGn+Py8kEJX5+=2NDwoukBw@mail.gmail.com>

Have you looked here?

http://www.oecd.org/env/tools-evaluation/carbon-prices.htm

On Thu, Jul 9, 2015 at 1:40 AM, Wei-han Liu via R-SIG-Finance <
r-sig-finance at r-project.org> wrote:

> Dear R users:
> Could some people share some information about where to download the time
> series of carbon prices over some countries? Commercial database or free
> online source will do.
> Thanks for your kind attention.
> Weihan
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>



-- 
Regards

Daniel Melendez

=========================================================================

	[[alternative HTML version deleted]]


From Ikipnis at grahamcapital.com  Wed Jul  8 19:37:13 2015
From: Ikipnis at grahamcapital.com (Ilya Kipnis)
Date: Wed, 8 Jul 2015 17:37:13 +0000
Subject: [R-SIG-Finance] What's the best package for SOCP in R?
Message-ID: <B37698F4177E1D4A9D2750822083CBF0559432@GCM-EXMB-R1.grahamcapital.com>

I was reading the following paper from Adam Butler:

http://www.bpgassociates.com/docs/Adaptive-Asset-Allocation-A-Primer.pdf

I saw the example on page 26, namely one with an 8% annualized volatility target.

I was wondering if there's a go-to package among the R/Finance community to solve problems of the type:

max w'r
s.t.
w'Sw = target
0 <= w_i <= 1 for all i
Sum(i=1...n)w_i = 1

I know that quadprog solves problems of the form of
min -w'r + lambda*w'Sw
s.t.
0 <= w_i <= 1 for all i
Sum(i=1...n)w_i = 1

I was wondering if there was a go-to package for SOCP so that I could solve the first type of problem without needing to call a global optimizer.

Thanks a lot.

-Ilya

	[[alternative HTML version deleted]]


From alexios at 4dscape.com  Thu Jul  9 15:17:03 2015
From: alexios at 4dscape.com (alexios)
Date: Thu, 9 Jul 2015 14:17:03 +0100
Subject: [R-SIG-Finance] What's the best package for SOCP in R?
In-Reply-To: <B37698F4177E1D4A9D2750822083CBF0559432@GCM-EXMB-R1.grahamcapital.com>
References: <B37698F4177E1D4A9D2750822083CBF0559432@GCM-EXMB-R1.grahamcapital.com>
Message-ID: <559E744F.1090800@4dscape.com>

Ilya, Bernhard's cccp package should be the definitive socp package in R 
now.
cran.r-project.org/package=cccp

-Alexios

On 08/07/2015 18:37, Ilya Kipnis wrote:
> I was reading the following paper from Adam Butler:
>
> http://www.bpgassociates.com/docs/Adaptive-Asset-Allocation-A-Primer.pdf
>
> I saw the example on page 26, namely one with an 8% annualized volatility target.
>
> I was wondering if there's a go-to package among the R/Finance community to solve problems of the type:
>
> max w'r
> s.t.
> w'Sw = target
> 0 <= w_i <= 1 for all i
> Sum(i=1...n)w_i = 1
>
> I know that quadprog solves problems of the form of
> min -w'r + lambda*w'Sw
> s.t.
> 0 <= w_i <= 1 for all i
> Sum(i=1...n)w_i = 1
>
> I was wondering if there was a go-to package for SOCP so that I could solve the first type of problem without needing to call a global optimizer.
>
> Thanks a lot.
>
> -Ilya
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>
>


From Bernhard_Pfaff at fra.invesco.com  Thu Jul  9 18:03:00 2015
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Thu, 9 Jul 2015 16:03:00 +0000
Subject: [R-SIG-Finance] What's the best package for SOCP in R?
In-Reply-To: <559E744F.1090800@4dscape.com>
References: <B37698F4177E1D4A9D2750822083CBF0559432@GCM-EXMB-R1.grahamcapital.com>
	<559E744F.1090800@4dscape.com>
Message-ID: <FCD9A33C859ACC469587CB09DD5C6C710EA8E207@GBLONXMB13.corp.amvescap.net>

Dear Ilya & Alexios,

given that the Alexios played the ball into my court, please find below a toy example to your problem:
(the parma package is loaded for the data set)

library(parma)
library(cccp)
data("etfdata")
R = etfdata/lag(etfdata)-1
R = na.omit(R * 100)
N <- ncol(R)
S = cov(coredata(R))
Se <- eigen(S)
Sr <- Se$vectors %*% diag(sqrt(Se$values)) %*% t(Se$vectors)
all.equal(Sr %*% Sr, S, check.attributes = FALSE)
mu <- colMeans(R)
q <- -mu
## Formulating constraints
## Non-negativity & SOC
nvec <- rep(0, N)
nno1 <- nnoc(G = -diag(N), h = nvec)
soc1 <- socc(F = Sr, g = nvec, d = nvec, f = 1.5)
## Budget constraint
A <- matrix(rep(1, N), nrow = 1, ncol = N)
b <- matrix(1, nrow = 1, ncol = 1)
## Solving problem
Popt <- cccp(q = q, A = A, b = b,
             cList = list(nno1, soc1))
w <- getx(Popt)
## checking
all(w > 0)
all.equal(sum(w), 1.0)
(retmax <- -getstate(Popt)["pobj"])
(sdrisk <- drop(sqrt(crossprod(w, S) %*% w)))

Best wishes,
Bernhard


-----Urspr?ngliche Nachricht-----
Von: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] Im Auftrag von alexios
Gesendet: Donnerstag, 9. Juli 2015 15:17
An: Ilya Kipnis; r-sig-finance at r-project.org
Betreff: Re: [R-SIG-Finance] What's the best package for SOCP in R?

Ilya, Bernhard's cccp package should be the definitive socp package in R now.
cran.r-project.org/package=cccp

-Alexios

On 08/07/2015 18:37, Ilya Kipnis wrote:
> I was reading the following paper from Adam Butler:
>
> http://www.bpgassociates.com/docs/Adaptive-Asset-Allocation-A-Primer.p
> df
>
> I saw the example on page 26, namely one with an 8% annualized volatility target.
>
> I was wondering if there's a go-to package among the R/Finance community to solve problems of the type:
>
> max w'r
> s.t.
> w'Sw = target
> 0 <= w_i <= 1 for all i
> Sum(i=1...n)w_i = 1
>
> I know that quadprog solves problems of the form of min -w'r + 
> lambda*w'Sw s.t.
> 0 <= w_i <= 1 for all i
> Sum(i=1...n)w_i = 1
>
> I was wondering if there was a go-to package for SOCP so that I could solve the first type of problem without needing to call a global optimizer.
>
> Thanks a lot.
>
> -Ilya
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>
>

_______________________________________________
R-SIG-Finance at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:10}}


From johannes.lips at gmail.com  Fri Jul 10 12:01:07 2015
From: johannes.lips at gmail.com (Johannes Lips)
Date: Fri, 10 Jul 2015 12:01:07 +0200
Subject: [R-SIG-Finance] Implementation of Lee Strazicich Unit Root Test for
	R - Optimization
Message-ID: <559F97E3.7050506@gmail.com>

Dear list,

I have implemented the test from Lee and Strazichich (2003, 2004) in R 
and uploaded it to github. [1]
The advantage of this test is, that it endogenously determines the dates 
of up to two possible structural breaks and
it includes these structural breaks under the null and also the 
alternative hypothesis.
I also implemented a General-to-Specific Approach to determine the 
number of lagged augmented terms to include in the test equation.
At the moment it's not very efficient in regard to computing time, so I 
would be glad if someone could point out improvements to make the code 
faster and more efficient.

Thanks in advance!

Best regards,
Johannes Lips


[1] https://github.com/hannes101/LeeStrazicichUnitRoot
Lee, Junsoo and Mark C. Strazicich (2003). ?Minimum Lagrange Multiplier 
Unit Root Test with Two Structural Breaks?. In: The Review of Economics 
and Statistics 85.4, pp. 1082?1089.
Lee, Junsoo and Mark C. Strazicich (2004). ?Minimum LM Unit Root Test 
with One Structural Break?. In: 04-17. url: 
https://ideas.repec.org/p/apl/wpaper/04-17.html (visited on 02/04/2015).


From ohpenot at gmail.com  Fri Jul 10 13:07:00 2015
From: ohpenot at gmail.com (Hamad Penot)
Date: Fri, 10 Jul 2015 13:07:00 +0200
Subject: [R-SIG-Finance] unsuscribe
Message-ID: <CAFs9OdXekQYobRGf3KgZqAqBzDK1RZQ3AD3ewNF4QEsvCS1Opg@mail.gmail.com>

dear sir,

i would like to unsuscribe to R-sig finance mailing list

*Hamad Penot*
*D?veloppeur .Net*

06 79 61 25 23
Merci de me contacter de pr?f?rence par mail ou message texte

	[[alternative HTML version deleted]]


From dragan.tevdovski at gmail.com  Fri Jul 10 13:40:14 2015
From: dragan.tevdovski at gmail.com (Dragan Tevdovski)
Date: Fri, 10 Jul 2015 13:40:14 +0200
Subject: [R-SIG-Finance] unsuscribe
In-Reply-To: <CAFs9OdXekQYobRGf3KgZqAqBzDK1RZQ3AD3ewNF4QEsvCS1Opg@mail.gmail.com>
References: <CAFs9OdXekQYobRGf3KgZqAqBzDK1RZQ3AD3ewNF4QEsvCS1Opg@mail.gmail.com>
Message-ID: <CAAHt723AAixAZ74Yoi9MmuRJ6te=TGcb8hpGamh2sgoK0=417A@mail.gmail.com>

I accept.

On Fri, Jul 10, 2015 at 1:07 PM, Hamad Penot <ohpenot at gmail.com> wrote:

> dear sir,
>
> i would like to unsuscribe to R-sig finance mailing list
>
> *Hamad Penot*
> *D?veloppeur .Net*
>
> 06 79 61 25 23
> Merci de me contacter de pr?f?rence par mail ou message texte
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.

	[[alternative HTML version deleted]]


From wouter at morannon.org  Fri Jul 10 14:04:08 2015
From: wouter at morannon.org (Wouter Thielen)
Date: Fri, 10 Jul 2015 12:04:08 +0000
Subject: [R-SIG-Finance] unsuscribe
In-Reply-To: <CAAHt723AAixAZ74Yoi9MmuRJ6te=TGcb8hpGamh2sgoK0=417A@mail.gmail.com>
References: <CAFs9OdXekQYobRGf3KgZqAqBzDK1RZQ3AD3ewNF4QEsvCS1Opg@mail.gmail.com>
	<CAAHt723AAixAZ74Yoi9MmuRJ6te=TGcb8hpGamh2sgoK0=417A@mail.gmail.com>
Message-ID: <CACySJQWyvfP+XtuUUousDgnoAp2njySDBz9M5D5VU4mYJ+ZzpQ@mail.gmail.com>

You can unsubscribe via this page:
https://stat.ethz.ch/mailman/listinfo/r-sig-finance

Look for: "To unsubscribe from R-SIG-Finance, get a password reminder, or
change your subscription options enter your subscription email address:"



On Fri, Jul 10, 2015 at 8:41 PM Dragan Tevdovski <dragan.tevdovski at gmail.com>
wrote:

> I accept.
>
> On Fri, Jul 10, 2015 at 1:07 PM, Hamad Penot <ohpenot at gmail.com> wrote:
>
> > dear sir,
> >
> > i would like to unsuscribe to R-sig finance mailing list
> >
> > *Hamad Penot*
> > *D?veloppeur .Net*
> >
> > 06 79 61 25 23
> > Merci de me contacter de pr?f?rence par mail ou message texte
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> > should go.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.

	[[alternative HTML version deleted]]


From robsch at robsch.eu  Fri Jul 10 15:20:09 2015
From: robsch at robsch.eu (Robert Schien)
Date: Fri, 10 Jul 2015 15:20:09 +0200
Subject: [R-SIG-Finance] IBrokers: placing a combo order
Message-ID: <20150710132009.GA1051@robsch.eu>

I want to place a combo order (futures calendar spread) and
tried this:

library(IBrokers)
tws <- ibgConnect()
contr1 <- twsFuture("ESTX50","DTB","201512",currency="EUR")
contr2 <- twsFuture("ESTX50","DTB","201509",currency="EUR")
cid1 <- reqContractDetails(tws,contr1)[[1]]$conId
cid2 <- reqContractDetails(tws,contr2)[[1]]$conId
leg1 <- twsComboLeg(conId=cid1,ratio="1",action="BUY",exchange="DTB")
leg2 <- twsComboLeg(conId=cid2,ratio="1",action="SELL",exchange="DTB")
bag <- twsBAG(list(leg1,leg2))
order <- twsOrder(1,"BUY",1,"MKT")
placeOrder(tws,bag,order)

reqOpenOrders(tws) delivered the error message that the details
of leg '0' were invalid. 
I don't know what leg '0' is but I assume that it is the
first leg in the combo.

Have I overlooked a detail?

I apologize for asking in this list but on the yahoolist twsapi
are only few R programmers and I received no answer there.

Thank you in advance.
Robert


From markknecht at gmail.com  Fri Jul 10 15:58:00 2015
From: markknecht at gmail.com (Mark Knecht)
Date: Fri, 10 Jul 2015 06:58:00 -0700
Subject: [R-SIG-Finance] What's the best package for SOCP in R?
In-Reply-To: <FCD9A33C859ACC469587CB09DD5C6C710EA8E207@GBLONXMB13.corp.amvescap.net>
References: <B37698F4177E1D4A9D2750822083CBF0559432@GCM-EXMB-R1.grahamcapital.com>
	<559E744F.1090800@4dscape.com>
	<FCD9A33C859ACC469587CB09DD5C6C710EA8E207@GBLONXMB13.corp.amvescap.net>
Message-ID: <CAK2H+edpGogOrPJE+wV1MbOH5r7KMnjifkouHNUsW5jj+icDZw@mail.gmail.com>

On Thu, Jul 9, 2015 at 9:03 AM, Pfaff, Bernhard Dr.
<Bernhard_Pfaff at fra.invesco.com> wrote:
> Dear Ilya & Alexios,
>
> given that the Alexios played the ball into my court, please find below a toy example to your problem:
> (the parma package is loaded for the data set)
>
> library(parma)
> library(cccp)


Sadly, library(parma) works its way down to Rglpk which doesn't build
coming from CRAN. Is there a better place to get that?

* installing *source* package ?Rglpk? ...
** package ?Rglpk? successfully unpacked and MD5 sums checked
** libs
/bin/sh: line 0: cd: GLPK: No such file or directory
Makevars:10: recipe for target 'GLPK.ts' failed
make: *** [GLPK.ts] Error 1
ERROR: compilation failed for package ?Rglpk?

Thanks,
Mark


From markknecht at gmail.com  Fri Jul 10 16:19:08 2015
From: markknecht at gmail.com (Mark Knecht)
Date: Fri, 10 Jul 2015 07:19:08 -0700
Subject: [R-SIG-Finance] What's the best package for SOCP in R?
In-Reply-To: <CAK2H+edpGogOrPJE+wV1MbOH5r7KMnjifkouHNUsW5jj+icDZw@mail.gmail.com>
References: <B37698F4177E1D4A9D2750822083CBF0559432@GCM-EXMB-R1.grahamcapital.com>
	<559E744F.1090800@4dscape.com>
	<FCD9A33C859ACC469587CB09DD5C6C710EA8E207@GBLONXMB13.corp.amvescap.net>
	<CAK2H+edpGogOrPJE+wV1MbOH5r7KMnjifkouHNUsW5jj+icDZw@mail.gmail.com>
Message-ID: <CAK2H+ecmdCEe4YOQVgMxPkkNbT+KHKwT12VK8mZruFjwByM0Qg@mail.gmail.com>

On Fri, Jul 10, 2015 at 6:58 AM, Mark Knecht <markknecht at gmail.com> wrote:
> On Thu, Jul 9, 2015 at 9:03 AM, Pfaff, Bernhard Dr.
> <Bernhard_Pfaff at fra.invesco.com> wrote:
>> Dear Ilya & Alexios,
>>
>> given that the Alexios played the ball into my court, please find below a toy example to your problem:
>> (the parma package is loaded for the data set)
>>
>> library(parma)
>> library(cccp)
>
>
> Sadly, library(parma) works its way down to Rglpk which doesn't build
> coming from CRAN. Is there a better place to get that?
>
> * installing *source* package ?Rglpk? ...
> ** package ?Rglpk? successfully unpacked and MD5 sums checked
> ** libs
> /bin/sh: line 0: cd: GLPK: No such file or directory
> Makevars:10: recipe for target 'GLPK.ts' failed
> make: *** [GLPK.ts] Error 1
> ERROR: compilation failed for package ?Rglpk?
>
> Thanks,
> Mark

Rglpk requires that I install glpk in Linux first. With that done the
example runs.

Thanks,
Mark


From josh.m.ulrich at gmail.com  Sat Jul 11 17:35:46 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 11 Jul 2015 10:35:46 -0500
Subject: [R-SIG-Finance] Implementation of Lee Strazicich Unit Root Test
 for R - Optimization
In-Reply-To: <559F97E3.7050506@gmail.com>
References: <559F97E3.7050506@gmail.com>
Message-ID: <CAPPM_gTSBj9-puEX5RZEVnYbPi+Q+614gySqLP5pKVKEJh+W0Q@mail.gmail.com>

On Fri, Jul 10, 2015 at 5:01 AM, Johannes Lips <johannes.lips at gmail.com> wrote:
> Dear list,
>
> I have implemented the test from Lee and Strazichich (2003, 2004) in R and
> uploaded it to github. [1]
> The advantage of this test is, that it endogenously determines the dates of
> up to two possible structural breaks and
> it includes these structural breaks under the null and also the alternative
> hypothesis.
> I also implemented a General-to-Specific Approach to determine the number of
> lagged augmented terms to include in the test equation.
> At the moment it's not very efficient in regard to computing time, so I
> would be glad if someone could point out improvements to make the code
> faster and more efficient.
>
If you provide an example I can run, I can profile it to look for
bottlenecks.  From a quick look at the code, one thing that should
help a fair amount is to avoid calls to lm() and call lm.fit()
directly.

> Thanks in advance!
>
> Best regards,
> Johannes Lips
>
>
> [1] https://github.com/hannes101/LeeStrazicichUnitRoot
> Lee, Junsoo and Mark C. Strazicich (2003). ?Minimum Lagrange Multiplier Unit
> Root Test with Two Structural Breaks?. In: The Review of Economics and
> Statistics 85.4, pp. 1082?1089.
> Lee, Junsoo and Mark C. Strazicich (2004). ?Minimum LM Unit Root Test with
> One Structural Break?. In: 04-17. url:
> https://ideas.repec.org/p/apl/wpaper/04-17.html (visited on 02/04/2015).
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From johannes.lips at gmail.com  Mon Jul 13 07:58:26 2015
From: johannes.lips at gmail.com (Johannes Lips)
Date: Mon, 13 Jul 2015 07:58:26 +0200
Subject: [R-SIG-Finance] Implementation of Lee Strazicich Unit Root Test
 for R - Optimization
In-Reply-To: <CAPPM_gTSBj9-puEX5RZEVnYbPi+Q+614gySqLP5pKVKEJh+W0Q@mail.gmail.com>
References: <559F97E3.7050506@gmail.com>
	<CAPPM_gTSBj9-puEX5RZEVnYbPi+Q+614gySqLP5pKVKEJh+W0Q@mail.gmail.com>
Message-ID: <55A35382.60203@gmail.com>



On 11.07.2015 17:35, Joshua Ulrich wrote:
> On Fri, Jul 10, 2015 at 5:01 AM, Johannes Lips <johannes.lips at gmail.com> wrote:
>> Dear list,
>>
>> I have implemented the test from Lee and Strazichich (2003, 2004) in R and
>> uploaded it to github. [1]
>> The advantage of this test is, that it endogenously determines the dates of
>> up to two possible structural breaks and
>> it includes these structural breaks under the null and also the alternative
>> hypothesis.
>> I also implemented a General-to-Specific Approach to determine the number of
>> lagged augmented terms to include in the test equation.
>> At the moment it's not very efficient in regard to computing time, so I
>> would be glad if someone could point out improvements to make the code
>> faster and more efficient.
>>
> If you provide an example I can run, I can profile it to look for
> bottlenecks.  From a quick look at the code, one thing that should
> help a fair amount is to avoid calls to lm() and call lm.fit()
> directly.
Thanks for your reply. For preliminary testing I often used a generated 
time series, which only has a break in the intercept at t=75.
After reading the csv file the test can be applied to the time series.
y <- read.csv("y.csv", col.names= c("t","y"))[,2]
ur.ls(y=y , model = "crash", breaks = 1, lags = NULL, method = "GTOS",pi 
= 0.1 )
The test call only looks for one break, but uses the general-to-specific 
approach, which is also quite time-consuming.
I will look into lm.fit() today and will try to implement it.

Thanks a lot for your suggestion!

-johannes
>
>> Thanks in advance!
>>
>> Best regards,
>> Johannes Lips
>>
>>
>> [1] https://github.com/hannes101/LeeStrazicichUnitRoot
>> Lee, Junsoo and Mark C. Strazicich (2003). ?Minimum Lagrange Multiplier Unit
>> Root Test with Two Structural Breaks?. In: The Review of Economics and
>> Statistics 85.4, pp. 1082?1089.
>> Lee, Junsoo and Mark C. Strazicich (2004). ?Minimum LM Unit Root Test with
>> One Structural Break?. In: 04-17. url:
>> https://ideas.repec.org/p/apl/wpaper/04-17.html (visited on 02/04/2015).
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: y.csv
Type: application/vnd.ms-excel
Size: 3483 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20150713/b00a6e2b/attachment.xlb>

From censix0 at gmail.com  Mon Jul 13 10:42:03 2015
From: censix0 at gmail.com (censix)
Date: Mon, 13 Jul 2015 10:42:03 +0200
Subject: [R-SIG-Finance] IBrokers: placing a combo order
In-Reply-To: <20150710132009.GA1051@robsch.eu>
References: <20150710132009.GA1051@robsch.eu>
Message-ID: <CAOGDGTb+jByoTJ4T1gs9Ps4YuGHeMck8ZdbfPUqY96Ohi32m3g@mail.gmail.com>

Hi Robert

I believe that the current IBrokers package implementation may not be well
suited for the use of ComboOrders.  I am saying this because when I was
implementing an update to some functions in the IBrokers package  a couple
of month ago because there had been changes IB had made to API messaging on
their side.

https://github.com/censix/INTRADAY-PartAB/blob/master/INTRADAY-PartA/__IBapi-clientVer63-v002.r

While doing this I ignored everything that had to do with Combo orders,
because I do not use them AND the current IBrokers package does, to my
knowledge NOT handle them correctly....

So at least from my side there is no easy answer to your question and it
may be very likely that you will not get this to work.

But then again, someone else may have fixed this ...

regards

Soren

On Fri, Jul 10, 2015 at 3:20 PM, Robert Schien <robsch at robsch.eu> wrote:

> I want to place a combo order (futures calendar spread) and
> tried this:
>
> library(IBrokers)
> tws <- ibgConnect()
> contr1 <- twsFuture("ESTX50","DTB","201512",currency="EUR")
> contr2 <- twsFuture("ESTX50","DTB","201509",currency="EUR")
> cid1 <- reqContractDetails(tws,contr1)[[1]]$conId
> cid2 <- reqContractDetails(tws,contr2)[[1]]$conId
> leg1 <- twsComboLeg(conId=cid1,ratio="1",action="BUY",exchange="DTB")
> leg2 <- twsComboLeg(conId=cid2,ratio="1",action="SELL",exchange="DTB")
> bag <- twsBAG(list(leg1,leg2))
> order <- twsOrder(1,"BUY",1,"MKT")
> placeOrder(tws,bag,order)
>
> reqOpenOrders(tws) delivered the error message that the details
> of leg '0' were invalid.
> I don't know what leg '0' is but I assume that it is the
> first leg in the combo.
>
> Have I overlooked a detail?
>
> I apologize for asking in this list but on the yahoolist twsapi
> are only few R programmers and I received no answer there.
>
> Thank you in advance.
> Robert
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From johannes.lips at gmail.com  Tue Jul 14 09:51:53 2015
From: johannes.lips at gmail.com (Johannes Lips)
Date: Tue, 14 Jul 2015 09:51:53 +0200
Subject: [R-SIG-Finance] Implementation of Lee Strazicich Unit Root Test
 for R - Optimization
In-Reply-To: <CAPPM_gTSBj9-puEX5RZEVnYbPi+Q+614gySqLP5pKVKEJh+W0Q@mail.gmail.com>
References: <559F97E3.7050506@gmail.com>
	<CAPPM_gTSBj9-puEX5RZEVnYbPi+Q+614gySqLP5pKVKEJh+W0Q@mail.gmail.com>
Message-ID: <55A4BF99.8060604@gmail.com>

On 11.07.2015 17:35, Joshua Ulrich wrote:
> On Fri, Jul 10, 2015 at 5:01 AM, Johannes Lips <johannes.lips at gmail.com> wrote:
>> Dear list,
>>
>> I have implemented the test from Lee and Strazichich (2003, 2004) in R and
>> uploaded it to github. [1]
>> The advantage of this test is, that it endogenously determines the dates of
>> up to two possible structural breaks and
>> it includes these structural breaks under the null and also the alternative
>> hypothesis.
>> I also implemented a General-to-Specific Approach to determine the number of
>> lagged augmented terms to include in the test equation.
>> At the moment it's not very efficient in regard to computing time, so I
>> would be glad if someone could point out improvements to make the code
>> faster and more efficient.
>>
> If you provide an example I can run, I can profile it to look for
> bottlenecks.  From a quick look at the code, one thing that should
> help a fair amount is to avoid calls to lm() and call lm.fit()
> directly.
I've implemented the use of lm.fit() instead of lm in a first function 
call, where I only need the residuals of the OLS.
In all other instances it is a bit harder to replace, because I need the 
t-statistics and those are not as easily accessible from lm.fit() as 
from lm.
I need to check if the lm.fit() call really is equivalent to the lm 
call, because I think the results slightly changed, but the time gain 
was already considerable. It went from 3.6h to 2h on nearly 3000 
observations, just by replacing the lm with lm.fit() in two places.
Thanks again,
johannes
>
>> Thanks in advance!
>>
>> Best regards,
>> Johannes Lips
>>
>>
>> [1] https://github.com/hannes101/LeeStrazicichUnitRoot
>> Lee, Junsoo and Mark C. Strazicich (2003). ?Minimum Lagrange Multiplier Unit
>> Root Test with Two Structural Breaks?. In: The Review of Economics and
>> Statistics 85.4, pp. 1082?1089.
>> Lee, Junsoo and Mark C. Strazicich (2004). ?Minimum LM Unit Root Test with
>> One Structural Break?. In: 04-17. url:
>> https://ideas.repec.org/p/apl/wpaper/04-17.html (visited on 02/04/2015).
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>


From johannes.lips at gmail.com  Thu Jul 16 10:23:24 2015
From: johannes.lips at gmail.com (Johannes Lips)
Date: Thu, 16 Jul 2015 10:23:24 +0200
Subject: [R-SIG-Finance] Implementation of Lee Strazicich Unit Root Test
 for R - Optimization
In-Reply-To: <55A4BF99.8060604@gmail.com>
References: <559F97E3.7050506@gmail.com>
	<CAPPM_gTSBj9-puEX5RZEVnYbPi+Q+614gySqLP5pKVKEJh+W0Q@mail.gmail.com>
	<55A4BF99.8060604@gmail.com>
Message-ID: <55A769FC.1060006@gmail.com>

On 14.07.2015 09:51, Johannes Lips wrote:
> On 11.07.2015 17:35, Joshua Ulrich wrote:
>> On Fri, Jul 10, 2015 at 5:01 AM, Johannes Lips 
>> <johannes.lips at gmail.com> wrote:
>>> Dear list,
>>>
>>> I have implemented the test from Lee and Strazichich (2003, 2004) in 
>>> R and
>>> uploaded it to github. [1]
>>> The advantage of this test is, that it endogenously determines the 
>>> dates of
>>> up to two possible structural breaks and
>>> it includes these structural breaks under the null and also the 
>>> alternative
>>> hypothesis.
>>> I also implemented a General-to-Specific Approach to determine the 
>>> number of
>>> lagged augmented terms to include in the test equation.
>>> At the moment it's not very efficient in regard to computing time, so I
>>> would be glad if someone could point out improvements to make the code
>>> faster and more efficient.
>>>
>> If you provide an example I can run, I can profile it to look for
>> bottlenecks.  From a quick look at the code, one thing that should
>> help a fair amount is to avoid calls to lm() and call lm.fit()
>> directly.
> I've implemented the use of lm.fit() instead of lm in a first function 
> call, where I only need the residuals of the OLS.
> In all other instances it is a bit harder to replace, because I need 
> the t-statistics and those are not as easily accessible from lm.fit() 
> as from lm.
> I need to check if the lm.fit() call really is equivalent to the lm 
> call, because I think the results slightly changed, but the time gain 
> was already considerable. It went from 3.6h to 2h on nearly 3000 
> observations, just by replacing the lm with lm.fit() in two places.
> Thanks again,
> johannes
Hi all,

so I've managed to replace lm() with lm.fit() in all instances and made 
the lm() call only available to get the results for the breakpoints. 
This results in a reduction of the runtime to roughly a third of the 
original runtime. So thanks a lot for this very valuable suggestion.
I yesterday uploaded the final code to my github repository. [1] So 
please, if you find obvious mistakes or problems, just let me know.

Best regards,
johannes

[1] https://github.com/hannes101/LeeStrazicichUnitRoot

>>
>>> Thanks in advance!
>>>
>>> Best regards,
>>> Johannes Lips
>>>
>>>
>>> [1] https://github.com/hannes101/LeeStrazicichUnitRoot
>>> Lee, Junsoo and Mark C. Strazicich (2003). ?Minimum Lagrange 
>>> Multiplier Unit
>>> Root Test with Two Structural Breaks?. In: The Review of Economics and
>>> Statistics 85.4, pp. 1082?1089.
>>> Lee, Junsoo and Mark C. Strazicich (2004). ?Minimum LM Unit Root 
>>> Test with
>>> One Structural Break?. In: 04-17. url:
>>> https://ideas.repec.org/p/apl/wpaper/04-17.html (visited on 
>>> 02/04/2015).
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>
>>
>


From uelihofstetter at gmail.com  Thu Jul 16 16:37:36 2015
From: uelihofstetter at gmail.com (Ueli Hofstetter)
Date: Thu, 16 Jul 2015 16:37:36 +0200
Subject: [R-SIG-Finance] factoranalytics vs factoranalyticsuw
Message-ID: <CA+fgw8Sq5A_G3VODFhCYHJPDUc=omBv6qvFr4dm4gUqXLDi47w@mail.gmail.com>

hello,

does anyone know why there are two branches of the factor analytics
package, i.e. the one which looks like the "original" version
(factoranalyticsuw)
https://r-forge.r-project.org/scm/viewvc.php/pkg/factorAnalyticsUW/?root=factoranalytics
and the one merged into the returnanalytics package
https://r-forge.r-project.org/R/?group_id=579 ?

while the package merged into the returnanalytics library has more recent
updates, it seems that some of the functionality presented in
http://www.rinfinance.com/agenda/2014/workshop/YiAnChen.pdf
is missing.

any hints are greatly appreciated

cheers

	[[alternative HTML version deleted]]


From brian at braverock.com  Thu Jul 16 16:49:03 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 16 Jul 2015 09:49:03 -0500
Subject: [R-SIG-Finance] factoranalytics vs factoranalyticsuw
In-Reply-To: <CA+fgw8Sq5A_G3VODFhCYHJPDUc=omBv6qvFr4dm4gUqXLDi47w@mail.gmail.com>
References: <CA+fgw8Sq5A_G3VODFhCYHJPDUc=omBv6qvFr4dm4gUqXLDi47w@mail.gmail.com>
Message-ID: <1437058143.26442.45.camel@brian-rcg>

Eric Zivot may comment as well, but the version in the returnanalytics
branch is the current and actively worked on version.

All the *functionality* the Yi-An worked on should be there.

Unfortunately, all the *interfaces* are not the same.  Extensions of the
functionality, and continued standardization of the model interfaces,
have resulted in changes that break backwards compatibility.  

Overall, I think the interface is cleaner and more consistent now, which
is good.  I am always unhappy to break backwards compatibility though.
We felt that the number of active users of the code was small enough
that new users would be better served by the cleaner, more consistent
interfaces.

The current plan is to release the package to CRAN after this summer's
GSoC.

Regards,

Brian


On Thu, 2015-07-16 at 16:37 +0200, Ueli Hofstetter wrote:
> hello,
> 
> does anyone know why there are two branches of the factor analytics
> package, i.e. the one which looks like the "original" version
> (factoranalyticsuw)
> https://r-forge.r-project.org/scm/viewvc.php/pkg/factorAnalyticsUW/?root=factoranalytics
> and the one merged into the returnanalytics package
> https://r-forge.r-project.org/R/?group_id=579 ?
> 
> while the package merged into the returnanalytics library has more recent
> updates, it seems that some of the functionality presented in
> http://www.rinfinance.com/agenda/2014/workshop/YiAnChen.pdf
> is missing.
> 
> any hints are greatly appreciated
> 
> cheers
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From uelihofstetter at gmail.com  Thu Jul 16 17:26:34 2015
From: uelihofstetter at gmail.com (Ueli Hofstetter)
Date: Thu, 16 Jul 2015 17:26:34 +0200
Subject: [R-SIG-Finance] factoranalytics vs factoranalyticsuw
In-Reply-To: <1437058143.26442.45.camel@brian-rcg>
References: <CA+fgw8Sq5A_G3VODFhCYHJPDUc=omBv6qvFr4dm4gUqXLDi47w@mail.gmail.com>
	<1437058143.26442.45.camel@brian-rcg>
Message-ID: <CA+fgw8TY09t-3c6Us+ZM0JEcFDFup398GO-rQ4R2m3vdK3220g@mail.gmail.com>

To clarify my original post:
It looks like the timeseries/macro factor model and the statistical factor
model are available (i.e. fitTsfm and fitSfm) but the fundamental factor
model is missing (although the function "fitFfm" is still mentioned in the
documentation).

So my question would be: Has the fundamental factor model been removed or
renamed (if so, what is the new name)?

Again, any hints greatly appreciated

2015-07-16 16:49 GMT+02:00 Brian G. Peterson <brian at braverock.com>:

> Eric Zivot may comment as well, but the version in the returnanalytics
> branch is the current and actively worked on version.
>
> All the *functionality* the Yi-An worked on should be there.
>
> Unfortunately, all the *interfaces* are not the same.  Extensions of the
> functionality, and continued standardization of the model interfaces,
> have resulted in changes that break backwards compatibility.
>
> Overall, I think the interface is cleaner and more consistent now, which
> is good.  I am always unhappy to break backwards compatibility though.
> We felt that the number of active users of the code was small enough
> that new users would be better served by the cleaner, more consistent
> interfaces.
>
> The current plan is to release the package to CRAN after this summer's
> GSoC.
>
> Regards,
>
> Brian
>
>
> On Thu, 2015-07-16 at 16:37 +0200, Ueli Hofstetter wrote:
> > hello,
> >
> > does anyone know why there are two branches of the factor analytics
> > package, i.e. the one which looks like the "original" version
> > (factoranalyticsuw)
> >
> https://r-forge.r-project.org/scm/viewvc.php/pkg/factorAnalyticsUW/?root=factoranalytics
> > and the one merged into the returnanalytics package
> > https://r-forge.r-project.org/R/?group_id=579 ?
> >
> > while the package merged into the returnanalytics library has more recent
> > updates, it seems that some of the functionality presented in
> > http://www.rinfinance.com/agenda/2014/workshop/YiAnChen.pdf
> > is missing.
> >
> > any hints are greatly appreciated
> >
> > cheers
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
>


-- 
Ueli Hofstetter

	[[alternative HTML version deleted]]


From rex at nosyntax.net  Sat Jul 18 07:19:08 2015
From: rex at nosyntax.net (rex)
Date: Fri, 17 Jul 2015 22:19:08 -0700
Subject: [R-SIG-Finance] Quantmod, qmao & option chains
Message-ID: <20150718051908.GB28480@nosyntax.net>

Today both packages are throwing errors:

> library(qmao)
> library(quantmod)

> intc.opt <- getOptionChain('INTC')
Error in data.frame(Strike, Last, Chg = Change, Bid, Ask, Vol = Volume,  : 
  object 'Strike' not found
> option_series.yahoo('SPY')
Error in data.frame(Strike, Last, Chg = Change, Bid, Ask, Vol = Volume,  : 
  object 'Strike' not found

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] qmao_1.6.10               XML_3.98-1.1             
[3] gdata_2.17.0              FinancialInstrument_1.2.0
[5] quantmod_0.4-4            TTR_0.22-0               
[7] xts_0.9-7                 zoo_1.7-12               

loaded via a namespace (and not attached):
 [1] digest_0.6.4    grid_3.1.1      gtools_3.5.0    htmltools_0.2.6
 [5] httpuv_1.3.2    lattice_0.20-29 mime_0.3        pander_0.5.2   
 [9] R6_2.1.0        Rcpp_0.11.6     RCurl_1.95-4.3  RJSONIO_1.3-0  
[13] shiny_0.12.1    tcltk_3.1.1     tools_3.1.1     xtable_1.7-4   


Option data is available in the browser.

http://finance.yahoo.com/q/op?s=INTC+Options

Any help much appreciated, thanks.

-rex
--
The government [is] extremely fond of amassing great quantities of
statistics. These are raised to the nth degree, the cube roots are
extracted, and the results are arranged into elaborate and impressive
displays. What must be kept ever in mind, however, is that in every case,
the figures are first put down by a village watchman, and he puts down
anything he damn well pleases. --Sir Josiah Stamp


From josh.m.ulrich at gmail.com  Sat Jul 18 13:34:33 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 18 Jul 2015 06:34:33 -0500
Subject: [R-SIG-Finance] Quantmod, qmao & option chains
In-Reply-To: <20150718051908.GB28480@nosyntax.net>
References: <20150718051908.GB28480@nosyntax.net>
Message-ID: <CAPPM_gRhkU0+9dG1UCLF14SVNz_vnij-Uc8H2buCRtOtOkPzKw@mail.gmail.com>

On Sat, Jul 18, 2015 at 12:19 AM, rex <rex at nosyntax.net> wrote:
> Today both packages are throwing errors:
>
>> library(qmao)
>> library(quantmod)
>
>> intc.opt <- getOptionChain('INTC')
> Error in data.frame(Strike, Last, Chg = Change, Bid, Ask, Vol = Volume,  :
>   object 'Strike' not found
>> option_series.yahoo('SPY')
> Error in data.frame(Strike, Last, Chg = Change, Bid, Ask, Vol = Volume,  :
>   object 'Strike' not found
>
This was reported and fixed ~3 hours before your email.  See:
https://github.com/joshuaulrich/quantmod/issues/62

>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] qmao_1.6.10               XML_3.98-1.1
> [3] gdata_2.17.0              FinancialInstrument_1.2.0
> [5] quantmod_0.4-4            TTR_0.22-0
> [7] xts_0.9-7                 zoo_1.7-12
>
> loaded via a namespace (and not attached):
>  [1] digest_0.6.4    grid_3.1.1      gtools_3.5.0    htmltools_0.2.6
>  [5] httpuv_1.3.2    lattice_0.20-29 mime_0.3        pander_0.5.2
>  [9] R6_2.1.0        Rcpp_0.11.6     RCurl_1.95-4.3  RJSONIO_1.3-0
> [13] shiny_0.12.1    tcltk_3.1.1     tools_3.1.1     xtable_1.7-4
>
>
> Option data is available in the browser.
>
> http://finance.yahoo.com/q/op?s=INTC+Options
>
> Any help much appreciated, thanks.
>
> -rex
> --
> The government [is] extremely fond of amassing great quantities of
> statistics. These are raised to the nth degree, the cube roots are
> extracted, and the results are arranged into elaborate and impressive
> displays. What must be kept ever in mind, however, is that in every case,
> the figures are first put down by a village watchman, and he puts down
> anything he damn well pleases. --Sir Josiah Stamp
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From huppertz.tom at gmail.com  Mon Jul 20 10:44:05 2015
From: huppertz.tom at gmail.com (Tom Huppertz)
Date: Mon, 20 Jul 2015 10:44:05 +0200
Subject: [R-SIG-Finance] Forecast of ARMA-GARCH model in R
Message-ID: <55ACB4D5.9090902@gmail.com>

I managed to forecast a GARCH model yesterday and run a Monte Carlo 
simulation on R. Nevertheless, I can't do the same with an ARMA-GARCH. I 
tested 4 different method but without achieving an ARMA-GARCH simulation 
with my data.

Thanks in advance !

Tom Huppertz

The packages and the data I used:

|library(quantmod)
library(tseries)
library(TSA)
library(betategarch)
library(mcsm)
library(PerformanceAnalytics)
library(forecast)
library(fGarch)
library(GEVStableGarch)

getSymbols("DEXB.BR",from="2005-07-01", to="2015-07-01")
STOCK = DEXB.BR
STOCK.rtn=diff(STOCK[,6] )
STOCK.diff = STOCK.rtn[2:length(STOCK.rtn)]
ARI_2_1=arima(STOCK[,6],order=c(2,1,1))
GA_1_1=garch(ARI_2_1$residuals, order = c(1,1))
|


    First tested method

|specifi = garchSpec(model = list(ar = c(0.49840, -0.0628), ma =c(-0.4551), omega = 8.393e-08, alpha = 1.356e-01, beta = 8.844e-01))

garchSim(spec = specifi, n = 500, n.start = 200, extended = FALSE)
|

This lead to a "NaN" forecast.

|garchSim(spec = specifi, n = 500)

n=1000
armagarch.sim_1 = rep(0,n)
armagarch.sim_50 = rep(0,n)
armagarch.sim_100 = rep(0,n)
for(i in 1:n)
{
     armagarch.sim=garchSim(spec = specifi, n = 500, n.start = 200, extended = FALSE)
     armagarch.sim_1[i] = armagarch.sim[1]
     armagarch.sim_50[i] = armagarch.sim[50]
     armagarch.sim_100[i] = armagarch.sim[100]

}
|


    Second tested method

|GSgarch.Sim(N = 500, mu = 0, a = c(0.49840, -0.0628), b = c(-0.4551),
omega = 8.393e-08, alpha = c(1.356e-01), gm = c(0), beta = c(8.844e-01),
  cond.dist = "norm")
|

This part works.

|n=10000

Garmagarch.sim_1 = rep(0,n)
Garmagarch.sim_50 = rep(0,n)
Garmagarch.sim_100 = rep(0,n)

for(i in 1:n)
{
     Garmagarch.sim= GSgarch.Sim(N = 500, mu = 0, a = c(0.49840, -0.0628), b = c(-0.4551),omega = 8.393e-08, alpha = c(1.356e-01), gm = c(0), beta c(8.844e-01), cond.dist = "norm")

     Garmagarch.sim_1[i] = Garmagarch.sim[1]
     Garmagarch.sim_50[i] = Garmagarch.sim[50]
     Garmagarch.sim_100[i] = Garmagarch.sim[100]

}
|

The simulation runs but

|> Garmagarch.sim[1]
$model
[1] "arma(2,1)-aparch(1,1) ## Intercept:FALSE"
|

and

|> Garmagarch.sim[50]
$<NA>
NULL
|


    Third tested method

|ga_arma = garch.sim(alpha=c(8.393e-08,1.356e-01),beta =8.844e-01 ,n=500, ntrans=200)
|

This lead to

|Error in garch.sim(alpha = c(8.393e-08, 0.1356), beta = 0.8844, n = 500,  :
   Check model: it does not have finite variance


arima.sim(ARI_2_1, 500, innov = ga_arma ,n.start = 200)
|

And this to

|Error in arima.sim(ARI_2_1, 500, innov = ga_arma, n.start = 200) :
   la partie 'ar' du mopd?le n'est pas stationaire
|

which mean that the 'ar' part of the model isn't stationnary.


    Fourth tested method

|forecast(ARI_2_1, h = 500, bootstrap = TRUE, npaths=200)
|

This one actually works but I don't know how to add the GARCH component.

|forecast(specifi, h = 500, bootstrap = TRUE, npaths=200)


  
|


	[[alternative HTML version deleted]]


From erol.biceroglu at alumni.utoronto.ca  Tue Jul 21 02:53:05 2015
From: erol.biceroglu at alumni.utoronto.ca (Erol Biceroglu)
Date: Mon, 20 Jul 2015 20:53:05 -0400
Subject: [R-SIG-Finance] checkBlotterUpdate fails on quantstrat
Message-ID: <CACjNfm=NzuaN31MqB7n9+H9x1aiwkpgCO_J=rtuWHXjPJM+5xQ@mail.gmail.com>

Hello,

I've been playing around with quanstrat and was looking forward to running
*apply.paramset()* to optimize the strategy's parameters, only to find an
empty set of results.

(Please note, my actual code follows after my message)

After investigating, I found that *checkBlotterUpdate* fails with the
message:

> checkBlotterUpdate(tradeStrategy,tradeStrategy)
[1] "portfolio P&L doesn't match sum of symbols P&L"
[1] "portfolio P&L doesn't match account P&L"
[1] FALSE

Upon further investigation, I'm unable to run the following:
> tradeStats(tradeStrategy)
NULL
Warning message:
In tradeStats(tradeStrategy) : TotalNetProfit NA forSPY

When I run this line (after executing everything), I find that the
"strategy date" (the first date before the beginning of the time series) is
duplicated, and in the 2nd instance, there are NAs in:
-Pos.Value
-Period.Unrealized.PL
-Gross.Trading.PL
-Net.Trading.PL

I've tried to play around with it and unfortunately I can't figure out what
would cause the duplicate, generate the NA.  Any thoughts or feedback would
be greatly appreciated.  Thanks for your help.

Here's the code:
---------
rm(list=ls())
library(quantstrat)
library(timeDate)
library(stringr)
library(IKTrading)


Sys.setenv(TZ="UTC")
startDate<-as.Date("1993-02-02", format="%Y-%m-%d")
endDate<-as.Date("2015-07-17", format="%Y-%m-%d")

getSymbols(Symbols = c("SPY", "^VIX")
           ,src="yahoo"
           , verbose=TRUE
           , warnings=TRUE
           , auto.assign=TRUE
           , return.class = "xts"
           , index.class = "Date"
           ,from = startDate
           , to = endDate
)

#set Financial instrument objects
currency("USD")
stock(primary_id = c("SPY", "VIX"),currency = "USD")


#name
tradeStrategy <-"SPYVIXStrategy"

#Date, one day before prices
strategyDate <- min(index(SPY)) - 1


#rm.strat(tradeStrategy)
#rm(mktdata)

NumSh<-3
VIXThreshold <- 20
PctThreshold <- 0.75

#init portfolio and account
initPortf(name = tradeStrategy
          , symbols = "SPY" #as defined in Financial instrument
          , initDate = strategyDate)

initAcct(name = tradeStrategy
         ,portfolios = tradeStrategy
         ,initDate = strategyDate
         ,initEq = 10e6 #as.vector(first(SPY$SPY.Close))*NumSh
)



#order book, and strategy
initOrders(portfolio = tradeStrategy
           , initDate = strategyDate
)

#position limits
addPosLimit(tradeStrategy, symbol = "SPY", strategyDate, maxpos = NumSh,
longlevels = NumSh)

strategy( tradeStrategy, store = TRUE)



#define indicator function
PctStrat <- function(x){
data<-merge(
  runPercentRank(x=ifelse(diff(x)<0,0,diff(x)),cumulative = FALSE
  )
  , ifelse(diff(x)<0,0,diff(x))
  , x
)
names(data) <- c("Percentile", "PositiveDiffs","VIX.Close")

data<-xts(x = sapply(data
                     ,function(x){ifelse(is.na(x),0,x)}
                    ), order.by = index(data)
          )

return(data)
}


#add indicator
add.indicator(strategy = tradeStrategy
  , name = "PctStrat"
, arguments = list( x = quote(VIX$VIX.Close))
  , label = "VIXPct"
)


# >=75th percentile move
add.signal(strategy = tradeStrategy
           , name = "sigThreshold"
           , arguments = list(column = c("Percentile.VIXPct")
                              , threshold = quote(PctThreshold) #0.75
                              , relationship = "gte"
                              , cross = FALSE
           )
           , label = "Pct.gte.3Qt"
)

#<75th percentile move
add.signal(strategy = tradeStrategy
           , name = "sigThreshold"
           , arguments = list(column = c("Percentile.VIXPct")
                              , threshold = quote(PctThreshold) #0.75
                              , relationship = "lt"
                              , cross = FALSE
           )
           , label = "Pct.lt.3Qt"
)

#>VIX 20
add.signal(strategy = tradeStrategy
           , name = "sigThreshold"
           , arguments = list(column = c("VIX.Close.VIXPct")
                              , threshold = quote(VIXThreshold) #20
                              , relationship = "gt"
                              , cross = FALSE
           )
           , label = "HighVolatility"
)


#<=VIX 20
add.signal(strategy = tradeStrategy
           , name = "sigThreshold"
           , arguments = list(column = c("VIX.Close.VIXPct")
                              , threshold = quote(VIXThreshold) #20
                              , relationship = "lte"
                              , cross = FALSE
           )
           , label = "LowVolatility"
)

#intersect signals
add.signal(strategy = tradeStrategy
           , name = "sigAND"
           , arguments = list(columns = c("Pct.lt.3Qt", "LowVolatility"),
cross = TRUE)
           , label = "Pct.lt.3qt.LowVol"
)

add.signal(strategy = tradeStrategy
           , name = "sigAND"
           , arguments = list(columns = c("Pct.lt.3Qt", "HighVolatility"),
cross = FALSE)
           , label = "Pct.lt.3qt.HighVol"
)

add.signal(strategy = tradeStrategy
           , name = "sigAND"
           , arguments = list(columns = c("Pct.gte.3Qt", "HighVolatility"),
cross = FALSE)
           , label = "Pct.gte.3qt.HighVol"
)

add.signal(strategy = tradeStrategy
           , name = "sigAND"
           , arguments = list(columns = c("Pct.gte.3Qt", "LowVolatility"),
cross = TRUE)
           , label = "Pct.gte.3qt.LowVol"
)

#rules
add.rule(strategy = tradeStrategy
         , name = "ruleSignal"
         , arguments = list(sigcol="Pct.lt.3qt.LowVol"
                            , sigval=TRUE
                            , orderqty=NumSh
                            , ordertype="market"
                            , orderside=NULL#"long"
                            , osFUN = "osMaxPos"
         )
         , type = "enter"
)

add.rule(strategy = tradeStrategy
         , name = "ruleSignal"
         , arguments = list(sigcol= "HighVolatility" #"Pct.lt.3qt.HighVol"
                            , sigval=TRUE
                            , orderqty="all"
                            , ordertype="market"
                            , orderside=NULL#"long"
                            , osFUN = "osMaxPos"
         )
         , type = "exit"
)

add.rule(strategy = tradeStrategy
         , name = "ruleSignal"
         , arguments = list(sigcol="Pct.gte.3qt.LowVol"
                            , sigval=TRUE
                            , orderqty=1
                            , ordertype="market"
                            , orderside=NULL#"long"
                            , osFUN = "osMaxPos"
         )
         , type = "exit"
)


applyStrategy(strategy = tradeStrategy
              , portfolios = tradeStrategy
)

updatePortf(tradeStrategy)
updateAcct(tradeStrategy)
updateEndEq(tradeStrategy)


###From Guy Yollin's Slides
checkBlotterUpdate <- function(port.st,account.st,verbose=TRUE)
{
  ok <- TRUE
  p <- getPortfolio(port.st)
  a <- getAccount(account.st)
  syms <- names(p$symbols)
  port.tot <- sum(sapply(syms,FUN = function(x) eval(parse(
    text=paste("sum(p$symbols",x,"posPL.USD$Net.Trading.PL)",sep="$")))))
  port.sum.tot <- sum(p$summary$Net.Trading.PL)
  if( !isTRUE(all.equal(port.tot,port.sum.tot)) ) {
    ok <- FALSE
    if( verbose )
      print("portfolio P&L doesn't match sum of symbols P&L")
  }
  initEq <- as.numeric(first(a$summary$End.Eq))
  endEq <- as.numeric(last(a$summary$End.Eq))
  if( !isTRUE(all.equal(port.tot,endEq-initEq)) ) {
    ok <- FALSE
    if( verbose )
      print("portfolio P&L doesn't match account P&L")
  }
  if( sum(duplicated(index(p$summary))) ) {
    ok <- FALSE
    if( verbose )
      print("duplicate timestamps in portfolio summary")
  }
  if( sum(duplicated(index(a$summary))) ) {
    ok <- FALSE
    if( verbose )
      print("duplicate timestamps in account summary")
  }
  return(ok)
}
###End Guy Yollin's code

#This fails
checkBlotterUpdate(tradeStrategy,tradeStrategy)

chart.Posn(tradeStrategy
         , Symbol = "SPY"
         #, Dates = "1994::"
         #, Dates = "2012::"
         ,TA = "add_TA(VIX$VIX.Close)"

)

#Here's an error
tradeStats(tradeStrategy)

#Here's the source of the error, an NA on the 2nd line
getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]

-------
End code


Erol Biceroglu


*erol.biceroglu at alumni.utoronto.ca <erol.biceroglu at alumni.utoronto.ca>*

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Tue Jul 21 05:47:59 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 20 Jul 2015 22:47:59 -0500
Subject: [R-SIG-Finance] checkBlotterUpdate fails on quantstrat
In-Reply-To: <CACjNfm=NzuaN31MqB7n9+H9x1aiwkpgCO_J=rtuWHXjPJM+5xQ@mail.gmail.com>
References: <CACjNfm=NzuaN31MqB7n9+H9x1aiwkpgCO_J=rtuWHXjPJM+5xQ@mail.gmail.com>
Message-ID: <CAPPM_gTe0zj7CXRxCEEXM0FhUvG2qfL7cXp=Hx=3bF9AWbzTtA@mail.gmail.com>

On Mon, Jul 20, 2015 at 7:53 PM, Erol Biceroglu
<erol.biceroglu at alumni.utoronto.ca> wrote:
> Hello,
>
> I've been playing around with quanstrat and was looking forward to running
> *apply.paramset()* to optimize the strategy's parameters, only to find an
> empty set of results.
>
Empty set of results from what?  There isn't a call to apply.paramset
in your code.  If you are actually running apply.paramset, please
provide the output from sessionInfo().

> (Please note, my actual code follows after my message)
>
> After investigating, I found that *checkBlotterUpdate* fails with the
> message:
>
>> checkBlotterUpdate(tradeStrategy,tradeStrategy)
> [1] "portfolio P&L doesn't match sum of symbols P&L"
> [1] "portfolio P&L doesn't match account P&L"
> [1] FALSE
>
> Upon further investigation, I'm unable to run the following:
>> tradeStats(tradeStrategy)
> NULL
> Warning message:
> In tradeStats(tradeStrategy) : TotalNetProfit NA forSPY
>
> When I run this line (after executing everything), I find that the
> "strategy date" (the first date before the beginning of the time series) is
> duplicated, and in the 2nd instance, there are NAs in:
> -Pos.Value
> -Period.Unrealized.PL
> -Gross.Trading.PL
> -Net.Trading.PL
>
> I've tried to play around with it and unfortunately I can't figure out what
> would cause the duplicate, generate the NA.  Any thoughts or feedback would
> be greatly appreciated.  Thanks for your help.
>
You will likely get more help if you provide a _minimal_ reproducible
example (yours didn't run for me because I don't have IKTrading
installed).  It would also help to provide more detail about what
you've tried in order to solve your problem--"tried to play around
with it" doesn't help people know what you did.

The general advice I can give you is to individually run
applyIndicators, applySignals, and applyRules; and to check the
mktdata object after you run each function.

> Here's the code:
> ---------
> rm(list=ls())
> library(quantstrat)
> library(timeDate)
> library(stringr)
> library(IKTrading)
>
>
> Sys.setenv(TZ="UTC")
> startDate<-as.Date("1993-02-02", format="%Y-%m-%d")
> endDate<-as.Date("2015-07-17", format="%Y-%m-%d")
>
> getSymbols(Symbols = c("SPY", "^VIX")
>            ,src="yahoo"
>            , verbose=TRUE
>            , warnings=TRUE
>            , auto.assign=TRUE
>            , return.class = "xts"
>            , index.class = "Date"
>            ,from = startDate
>            , to = endDate
> )
>
> #set Financial instrument objects
> currency("USD")
> stock(primary_id = c("SPY", "VIX"),currency = "USD")
>
>
> #name
> tradeStrategy <-"SPYVIXStrategy"
>
> #Date, one day before prices
> strategyDate <- min(index(SPY)) - 1
>
>
> #rm.strat(tradeStrategy)
> #rm(mktdata)
>
> NumSh<-3
> VIXThreshold <- 20
> PctThreshold <- 0.75
>
> #init portfolio and account
> initPortf(name = tradeStrategy
>           , symbols = "SPY" #as defined in Financial instrument
>           , initDate = strategyDate)
>
> initAcct(name = tradeStrategy
>          ,portfolios = tradeStrategy
>          ,initDate = strategyDate
>          ,initEq = 10e6 #as.vector(first(SPY$SPY.Close))*NumSh
> )
>
>
>
> #order book, and strategy
> initOrders(portfolio = tradeStrategy
>            , initDate = strategyDate
> )
>
> #position limits
> addPosLimit(tradeStrategy, symbol = "SPY", strategyDate, maxpos = NumSh,
> longlevels = NumSh)
>
> strategy( tradeStrategy, store = TRUE)
>
>
>
> #define indicator function
> PctStrat <- function(x){
> data<-merge(
>   runPercentRank(x=ifelse(diff(x)<0,0,diff(x)),cumulative = FALSE
>   )
>   , ifelse(diff(x)<0,0,diff(x))
>   , x
> )
> names(data) <- c("Percentile", "PositiveDiffs","VIX.Close")
>
> data<-xts(x = sapply(data
>                      ,function(x){ifelse(is.na(x),0,x)}
>                     ), order.by = index(data)
>           )
>
> return(data)
> }
>
>
> #add indicator
> add.indicator(strategy = tradeStrategy
>   , name = "PctStrat"
> , arguments = list( x = quote(VIX$VIX.Close))
>   , label = "VIXPct"
> )
>
>
> # >=75th percentile move
> add.signal(strategy = tradeStrategy
>            , name = "sigThreshold"
>            , arguments = list(column = c("Percentile.VIXPct")
>                               , threshold = quote(PctThreshold) #0.75
>                               , relationship = "gte"
>                               , cross = FALSE
>            )
>            , label = "Pct.gte.3Qt"
> )
>
> #<75th percentile move
> add.signal(strategy = tradeStrategy
>            , name = "sigThreshold"
>            , arguments = list(column = c("Percentile.VIXPct")
>                               , threshold = quote(PctThreshold) #0.75
>                               , relationship = "lt"
>                               , cross = FALSE
>            )
>            , label = "Pct.lt.3Qt"
> )
>
> #>VIX 20
> add.signal(strategy = tradeStrategy
>            , name = "sigThreshold"
>            , arguments = list(column = c("VIX.Close.VIXPct")
>                               , threshold = quote(VIXThreshold) #20
>                               , relationship = "gt"
>                               , cross = FALSE
>            )
>            , label = "HighVolatility"
> )
>
>
> #<=VIX 20
> add.signal(strategy = tradeStrategy
>            , name = "sigThreshold"
>            , arguments = list(column = c("VIX.Close.VIXPct")
>                               , threshold = quote(VIXThreshold) #20
>                               , relationship = "lte"
>                               , cross = FALSE
>            )
>            , label = "LowVolatility"
> )
>
> #intersect signals
> add.signal(strategy = tradeStrategy
>            , name = "sigAND"
>            , arguments = list(columns = c("Pct.lt.3Qt", "LowVolatility"),
> cross = TRUE)
>            , label = "Pct.lt.3qt.LowVol"
> )
>
> add.signal(strategy = tradeStrategy
>            , name = "sigAND"
>            , arguments = list(columns = c("Pct.lt.3Qt", "HighVolatility"),
> cross = FALSE)
>            , label = "Pct.lt.3qt.HighVol"
> )
>
> add.signal(strategy = tradeStrategy
>            , name = "sigAND"
>            , arguments = list(columns = c("Pct.gte.3Qt", "HighVolatility"),
> cross = FALSE)
>            , label = "Pct.gte.3qt.HighVol"
> )
>
> add.signal(strategy = tradeStrategy
>            , name = "sigAND"
>            , arguments = list(columns = c("Pct.gte.3Qt", "LowVolatility"),
> cross = TRUE)
>            , label = "Pct.gte.3qt.LowVol"
> )
>
> #rules
> add.rule(strategy = tradeStrategy
>          , name = "ruleSignal"
>          , arguments = list(sigcol="Pct.lt.3qt.LowVol"
>                             , sigval=TRUE
>                             , orderqty=NumSh
>                             , ordertype="market"
>                             , orderside=NULL#"long"
>                             , osFUN = "osMaxPos"
>          )
>          , type = "enter"
> )
>
> add.rule(strategy = tradeStrategy
>          , name = "ruleSignal"
>          , arguments = list(sigcol= "HighVolatility" #"Pct.lt.3qt.HighVol"
>                             , sigval=TRUE
>                             , orderqty="all"
>                             , ordertype="market"
>                             , orderside=NULL#"long"
>                             , osFUN = "osMaxPos"
>          )
>          , type = "exit"
> )
>
> add.rule(strategy = tradeStrategy
>          , name = "ruleSignal"
>          , arguments = list(sigcol="Pct.gte.3qt.LowVol"
>                             , sigval=TRUE
>                             , orderqty=1
>                             , ordertype="market"
>                             , orderside=NULL#"long"
>                             , osFUN = "osMaxPos"
>          )
>          , type = "exit"
> )
>
>
> applyStrategy(strategy = tradeStrategy
>               , portfolios = tradeStrategy
> )
>
> updatePortf(tradeStrategy)
> updateAcct(tradeStrategy)
> updateEndEq(tradeStrategy)
>
>
> ###From Guy Yollin's Slides
> checkBlotterUpdate <- function(port.st,account.st,verbose=TRUE)
> {
>   ok <- TRUE
>   p <- getPortfolio(port.st)
>   a <- getAccount(account.st)
>   syms <- names(p$symbols)
>   port.tot <- sum(sapply(syms,FUN = function(x) eval(parse(
>     text=paste("sum(p$symbols",x,"posPL.USD$Net.Trading.PL)",sep="$")))))
>   port.sum.tot <- sum(p$summary$Net.Trading.PL)
>   if( !isTRUE(all.equal(port.tot,port.sum.tot)) ) {
>     ok <- FALSE
>     if( verbose )
>       print("portfolio P&L doesn't match sum of symbols P&L")
>   }
>   initEq <- as.numeric(first(a$summary$End.Eq))
>   endEq <- as.numeric(last(a$summary$End.Eq))
>   if( !isTRUE(all.equal(port.tot,endEq-initEq)) ) {
>     ok <- FALSE
>     if( verbose )
>       print("portfolio P&L doesn't match account P&L")
>   }
>   if( sum(duplicated(index(p$summary))) ) {
>     ok <- FALSE
>     if( verbose )
>       print("duplicate timestamps in portfolio summary")
>   }
>   if( sum(duplicated(index(a$summary))) ) {
>     ok <- FALSE
>     if( verbose )
>       print("duplicate timestamps in account summary")
>   }
>   return(ok)
> }
> ###End Guy Yollin's code
>
> #This fails
> checkBlotterUpdate(tradeStrategy,tradeStrategy)
>
> chart.Posn(tradeStrategy
>          , Symbol = "SPY"
>          #, Dates = "1994::"
>          #, Dates = "2012::"
>          ,TA = "add_TA(VIX$VIX.Close)"
>
> )
>
> #Here's an error
> tradeStats(tradeStrategy)
>
> #Here's the source of the error, an NA on the 2nd line
> getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
>
> -------
> End code
>
>
> Erol Biceroglu
>
>
> *erol.biceroglu at alumni.utoronto.ca <erol.biceroglu at alumni.utoronto.ca>*
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From erol.biceroglu at alumni.utoronto.ca  Tue Jul 21 06:49:23 2015
From: erol.biceroglu at alumni.utoronto.ca (Erol Biceroglu)
Date: Tue, 21 Jul 2015 00:49:23 -0400
Subject: [R-SIG-Finance] checkBlotterUpdate fails on quantstrat
In-Reply-To: <CAPPM_gTe0zj7CXRxCEEXM0FhUvG2qfL7cXp=Hx=3bF9AWbzTtA@mail.gmail.com>
References: <CACjNfm=NzuaN31MqB7n9+H9x1aiwkpgCO_J=rtuWHXjPJM+5xQ@mail.gmail.com>
	<CAPPM_gTe0zj7CXRxCEEXM0FhUvG2qfL7cXp=Hx=3bF9AWbzTtA@mail.gmail.com>
Message-ID: <CACjNfmkByQ+tYemkrXbzEPaZykS6kUw=WVBG17-2Zu0WpxbAtA@mail.gmail.com>

Hi Joshua,

Thanks for the feedback, your comments are helpful.

My apologies for the confusion, perhaps I provided too much information at
first.  I am using apply.paramset, and although it runs, it doesn't work.
It will finish without an error, but the results are empty.  The NA is
throwing off the aggregation of the trade statistics, which occurs before I
get to apply.paramset, so it would have made my code much longer.

My intention, and what I was hoping I did, was identify what as causing the
error (the NAs in posPL):

getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]

I tried to trim the example down, however I wasn't sure what was causing
the error, so I also tried to preserve as much as I could.  However I
appreciate the advice, and I will keep that in mind in the future.

Anyway, based on your comments, it looks like its the following rules that
are causing the issue:

Pct.lt.3qt.LowVol

Pct.gte.3qt.LowVol


These generate NA on the first time stamp, so I have something to go
on to continue my investigation.


Lastly, here's sessionInfo() output in case it's helpful.


Thank you,


> sessionInfo()R version 3.2.1 (2015-06-18)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.2 LTS

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
 [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
LC_PAPER=en_CA.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
 [1] IKTrading_1.0                 roxygen2_4.1.1
digest_0.6.8                  Rcpp_0.11.6
 [5] stringr_1.0.0                 timeDate_3012.100
quantstrat_0.9.1687           foreach_1.4.2
 [9] blotter_0.9.1666              PerformanceAnalytics_1.4.3541
FinancialInstrument_1.2.0     quantmod_0.4-4
[13] TTR_0.23-0                    xts_0.9-7
zoo_1.7-12

loaded via a namespace (and not attached):
[1] lattice_0.20-31 codetools_0.2-8 grid_3.2.1      magrittr_1.5
stringi_0.5-5   iterators_1.0.7 tools_3.2.1





Erol Biceroglu


*erol.biceroglu at alumni.utoronto.ca <erol.biceroglu at alumni.utoronto.ca>*

On Mon, Jul 20, 2015 at 11:47 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>
wrote:

> On Mon, Jul 20, 2015 at 7:53 PM, Erol Biceroglu
> <erol.biceroglu at alumni.utoronto.ca> wrote:
> > Hello,
> >
> > I've been playing around with quanstrat and was looking forward to
> running
> > *apply.paramset()* to optimize the strategy's parameters, only to find an
> > empty set of results.
> >
> Empty set of results from what?  There isn't a call to apply.paramset
> in your code.  If you are actually running apply.paramset, please
> provide the output from sessionInfo().
>
> > (Please note, my actual code follows after my message)
> >
> > After investigating, I found that *checkBlotterUpdate* fails with the
> > message:
> >
> >> checkBlotterUpdate(tradeStrategy,tradeStrategy)
> > [1] "portfolio P&L doesn't match sum of symbols P&L"
> > [1] "portfolio P&L doesn't match account P&L"
> > [1] FALSE
> >
> > Upon further investigation, I'm unable to run the following:
> >> tradeStats(tradeStrategy)
> > NULL
> > Warning message:
> > In tradeStats(tradeStrategy) : TotalNetProfit NA forSPY
> >
> > When I run this line (after executing everything), I find that the
> > "strategy date" (the first date before the beginning of the time series)
> is
> > duplicated, and in the 2nd instance, there are NAs in:
> > -Pos.Value
> > -Period.Unrealized.PL
> > -Gross.Trading.PL
> > -Net.Trading.PL
> >
> > I've tried to play around with it and unfortunately I can't figure out
> what
> > would cause the duplicate, generate the NA.  Any thoughts or feedback
> would
> > be greatly appreciated.  Thanks for your help.
> >
> You will likely get more help if you provide a _minimal_ reproducible
> example (yours didn't run for me because I don't have IKTrading
> installed).  It would also help to provide more detail about what
> you've tried in order to solve your problem--"tried to play around
> with it" doesn't help people know what you did.
>
> The general advice I can give you is to individually run
> applyIndicators, applySignals, and applyRules; and to check the
> mktdata object after you run each function.
>
> > Here's the code:
> > ---------
> > rm(list=ls())
> > library(quantstrat)
> > library(timeDate)
> > library(stringr)
> > library(IKTrading)
> >
> >
> > Sys.setenv(TZ="UTC")
> > startDate<-as.Date("1993-02-02", format="%Y-%m-%d")
> > endDate<-as.Date("2015-07-17", format="%Y-%m-%d")
> >
> > getSymbols(Symbols = c("SPY", "^VIX")
> >            ,src="yahoo"
> >            , verbose=TRUE
> >            , warnings=TRUE
> >            , auto.assign=TRUE
> >            , return.class = "xts"
> >            , index.class = "Date"
> >            ,from = startDate
> >            , to = endDate
> > )
> >
> > #set Financial instrument objects
> > currency("USD")
> > stock(primary_id = c("SPY", "VIX"),currency = "USD")
> >
> >
> > #name
> > tradeStrategy <-"SPYVIXStrategy"
> >
> > #Date, one day before prices
> > strategyDate <- min(index(SPY)) - 1
> >
> >
> > #rm.strat(tradeStrategy)
> > #rm(mktdata)
> >
> > NumSh<-3
> > VIXThreshold <- 20
> > PctThreshold <- 0.75
> >
> > #init portfolio and account
> > initPortf(name = tradeStrategy
> >           , symbols = "SPY" #as defined in Financial instrument
> >           , initDate = strategyDate)
> >
> > initAcct(name = tradeStrategy
> >          ,portfolios = tradeStrategy
> >          ,initDate = strategyDate
> >          ,initEq = 10e6 #as.vector(first(SPY$SPY.Close))*NumSh
> > )
> >
> >
> >
> > #order book, and strategy
> > initOrders(portfolio = tradeStrategy
> >            , initDate = strategyDate
> > )
> >
> > #position limits
> > addPosLimit(tradeStrategy, symbol = "SPY", strategyDate, maxpos = NumSh,
> > longlevels = NumSh)
> >
> > strategy( tradeStrategy, store = TRUE)
> >
> >
> >
> > #define indicator function
> > PctStrat <- function(x){
> > data<-merge(
> >   runPercentRank(x=ifelse(diff(x)<0,0,diff(x)),cumulative = FALSE
> >   )
> >   , ifelse(diff(x)<0,0,diff(x))
> >   , x
> > )
> > names(data) <- c("Percentile", "PositiveDiffs","VIX.Close")
> >
> > data<-xts(x = sapply(data
> >                      ,function(x){ifelse(is.na(x),0,x)}
> >                     ), order.by = index(data)
> >           )
> >
> > return(data)
> > }
> >
> >
> > #add indicator
> > add.indicator(strategy = tradeStrategy
> >   , name = "PctStrat"
> > , arguments = list( x = quote(VIX$VIX.Close))
> >   , label = "VIXPct"
> > )
> >
> >
> > # >=75th percentile move
> > add.signal(strategy = tradeStrategy
> >            , name = "sigThreshold"
> >            , arguments = list(column = c("Percentile.VIXPct")
> >                               , threshold = quote(PctThreshold) #0.75
> >                               , relationship = "gte"
> >                               , cross = FALSE
> >            )
> >            , label = "Pct.gte.3Qt"
> > )
> >
> > #<75th percentile move
> > add.signal(strategy = tradeStrategy
> >            , name = "sigThreshold"
> >            , arguments = list(column = c("Percentile.VIXPct")
> >                               , threshold = quote(PctThreshold) #0.75
> >                               , relationship = "lt"
> >                               , cross = FALSE
> >            )
> >            , label = "Pct.lt.3Qt"
> > )
> >
> > #>VIX 20
> > add.signal(strategy = tradeStrategy
> >            , name = "sigThreshold"
> >            , arguments = list(column = c("VIX.Close.VIXPct")
> >                               , threshold = quote(VIXThreshold) #20
> >                               , relationship = "gt"
> >                               , cross = FALSE
> >            )
> >            , label = "HighVolatility"
> > )
> >
> >
> > #<=VIX 20
> > add.signal(strategy = tradeStrategy
> >            , name = "sigThreshold"
> >            , arguments = list(column = c("VIX.Close.VIXPct")
> >                               , threshold = quote(VIXThreshold) #20
> >                               , relationship = "lte"
> >                               , cross = FALSE
> >            )
> >            , label = "LowVolatility"
> > )
> >
> > #intersect signals
> > add.signal(strategy = tradeStrategy
> >            , name = "sigAND"
> >            , arguments = list(columns = c("Pct.lt.3Qt", "LowVolatility"),
> > cross = TRUE)
> >            , label = "Pct.lt.3qt.LowVol"
> > )
> >
> > add.signal(strategy = tradeStrategy
> >            , name = "sigAND"
> >            , arguments = list(columns = c("Pct.lt.3Qt",
> "HighVolatility"),
> > cross = FALSE)
> >            , label = "Pct.lt.3qt.HighVol"
> > )
> >
> > add.signal(strategy = tradeStrategy
> >            , name = "sigAND"
> >            , arguments = list(columns = c("Pct.gte.3Qt",
> "HighVolatility"),
> > cross = FALSE)
> >            , label = "Pct.gte.3qt.HighVol"
> > )
> >
> > add.signal(strategy = tradeStrategy
> >            , name = "sigAND"
> >            , arguments = list(columns = c("Pct.gte.3Qt",
> "LowVolatility"),
> > cross = TRUE)
> >            , label = "Pct.gte.3qt.LowVol"
> > )
> >
> > #rules
> > add.rule(strategy = tradeStrategy
> >          , name = "ruleSignal"
> >          , arguments = list(sigcol="Pct.lt.3qt.LowVol"
> >                             , sigval=TRUE
> >                             , orderqty=NumSh
> >                             , ordertype="market"
> >                             , orderside=NULL#"long"
> >                             , osFUN = "osMaxPos"
> >          )
> >          , type = "enter"
> > )
> >
> > add.rule(strategy = tradeStrategy
> >          , name = "ruleSignal"
> >          , arguments = list(sigcol= "HighVolatility"
> #"Pct.lt.3qt.HighVol"
> >                             , sigval=TRUE
> >                             , orderqty="all"
> >                             , ordertype="market"
> >                             , orderside=NULL#"long"
> >                             , osFUN = "osMaxPos"
> >          )
> >          , type = "exit"
> > )
> >
> > add.rule(strategy = tradeStrategy
> >          , name = "ruleSignal"
> >          , arguments = list(sigcol="Pct.gte.3qt.LowVol"
> >                             , sigval=TRUE
> >                             , orderqty=1
> >                             , ordertype="market"
> >                             , orderside=NULL#"long"
> >                             , osFUN = "osMaxPos"
> >          )
> >          , type = "exit"
> > )
> >
> >
> > applyStrategy(strategy = tradeStrategy
> >               , portfolios = tradeStrategy
> > )
> >
> > updatePortf(tradeStrategy)
> > updateAcct(tradeStrategy)
> > updateEndEq(tradeStrategy)
> >
> >
> > ###From Guy Yollin's Slides
> > checkBlotterUpdate <- function(port.st,account.st,verbose=TRUE)
> > {
> >   ok <- TRUE
> >   p <- getPortfolio(port.st)
> >   a <- getAccount(account.st)
> >   syms <- names(p$symbols)
> >   port.tot <- sum(sapply(syms,FUN = function(x) eval(parse(
> >     text=paste("sum(p$symbols",x,"posPL.USD$Net.Trading.PL
> )",sep="$")))))
> >   port.sum.tot <- sum(p$summary$Net.Trading.PL)
> >   if( !isTRUE(all.equal(port.tot,port.sum.tot)) ) {
> >     ok <- FALSE
> >     if( verbose )
> >       print("portfolio P&L doesn't match sum of symbols P&L")
> >   }
> >   initEq <- as.numeric(first(a$summary$End.Eq))
> >   endEq <- as.numeric(last(a$summary$End.Eq))
> >   if( !isTRUE(all.equal(port.tot,endEq-initEq)) ) {
> >     ok <- FALSE
> >     if( verbose )
> >       print("portfolio P&L doesn't match account P&L")
> >   }
> >   if( sum(duplicated(index(p$summary))) ) {
> >     ok <- FALSE
> >     if( verbose )
> >       print("duplicate timestamps in portfolio summary")
> >   }
> >   if( sum(duplicated(index(a$summary))) ) {
> >     ok <- FALSE
> >     if( verbose )
> >       print("duplicate timestamps in account summary")
> >   }
> >   return(ok)
> > }
> > ###End Guy Yollin's code
> >
> > #This fails
> > checkBlotterUpdate(tradeStrategy,tradeStrategy)
> >
> > chart.Posn(tradeStrategy
> >          , Symbol = "SPY"
> >          #, Dates = "1994::"
> >          #, Dates = "2012::"
> >          ,TA = "add_TA(VIX$VIX.Close)"
> >
> > )
> >
> > #Here's an error
> > tradeStats(tradeStrategy)
> >
> > #Here's the source of the error, an NA on the 2nd line
> > getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
> >
> > -------
> > End code
> >
> >
> > Erol Biceroglu
> >
> >
> > *erol.biceroglu at alumni.utoronto.ca <erol.biceroglu at alumni.utoronto.ca>*
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
>

	[[alternative HTML version deleted]]


From amelia_marsh08 at yahoo.com  Wed Jul 22 11:07:09 2015
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Wed, 22 Jul 2015 09:07:09 +0000 (UTC)
Subject: [R-SIG-Finance] Distribution fitting to loss data - Operational Risk
Message-ID: <943867839.260187.1437556029168.JavaMail.yahoo@mail.yahoo.com>

Hello!

I am into risk management and deal with Operatioanl risk. As a part of BASEL II guidelines, we need to arrive at the capital charge the banks must set aside to counter any operational risk, if it happens. As a part of Loss Distribution Approach (LDA), we need to collate past loss events and use these loss amounts. The usual process as being practised in the industry is as follows - 

Using these historical loss amounts and using the various statistical tests like KS test, AD test, PP plot, QQ plot etc, we try to identify best statistical (continuous) distribution fitting this historical loss data. Then using these estimated parameters w.r.t. the statistical distribution, we simulate say 1 miliion loss anounts and then taking appropriate percentile (say 99.9%), we arrive at the capital charge. 

However, many a times, loss data is such that fitting of distribution to loss data is not possible. May be loss data is multimodal or has significant variability, making the fitting of distribution impossible. Can someone guide me how to deal with such data and what can be done to simulate losses using this historical loss data in R. 

My data is as follows - 

mydat <- c(829.53,4000,6000,1000,1063904,102400,22000,4000,4200,2000,10000,400, 459006, 7276,4000,100,4000,10000,613803.36, 825,1000,5000,4000,3000,84500,200, 2000,68000,97400,6267.8, 49500,27000,2100,10489.92,2200,2000,2000,1000,1900, 6000,5600,100,4000,14300,100,94100,1200,7000,2000,3000,1100,6900,1000,18500,6000,2000,4000,8400,11200,1000,15100,23300,4000,13100,4500,200,2000,50000,3900,3200,2000,2000,67000,2000,500,2000,1000,1900,10400,1900,2000,3200,6500,10000,2900,1000,14300,1000,2700,1500,12000,40000,25000,2800,5000,15000,4000,1000,21000,15000,16000,54000,1500,19200,2000,2000,1000,39000,5000,1100,18000,10000,3500,1000,10000,5000,14000,1800,4000,1000,300,4000,1000,100,1000,4400,2000,2000,12000,200,100,1000,1000,2000,1600,2000,4000,14000,4000,13500,1000,200,200,1000,18000,23000,41400,60000,500,3000,21000,6900,14600,1900,4000,4500,1000,2000,2000,1000,4100,2000,1000,2000,8000,3000,1500,2000,2000,3500,2000,2000,1000,3800,30000,55000,500,1000,1000,2000,62400,2000,3000,200,2000,3500,2000,2000,500,3000,4500,1000,10000,2000,3000,3600,1000,2000,2000,5000,23000,2000,1900,2000,60000,2000,60000,20000,2000,2000,4600,1000,2000,1000,18000,6000,62000,68000,26800,50000,45900,16900,21500,2000,22700,2000,2000,32000,10000,5000,138000,159700,13000,2000,17619,2000,1000,4000,2000,1500,4000,20000,158900,74100,6000,24900,60000,500,1000,40000,10000,50000,800,4000,4900,6500,5000,400,500,3000,32300,24000,300,11500,2000,5000,1000,500,5000,5500,17450,56800,2000,1000,21400,22000,60000,3000,7500,3000,1000,1000,2000,1500,83700,2000,4000,170005,70000,6700,1500,3500,2000,10563.97,1500,25000,2000,2000,2267.57,1100,3100,2000,3500,10000,2000,6000,1500,200,20000,4000,46400,296900,150000,3700,7500,20000,48500,3500,12000,2500,4000,8500,1000,14500,1000,11000,2000,2000,120000,20000,7600,3000,2000,8000,1600,40000,2000,5000,34187.67,279100,9900,31300,814000,43500,5100,49500,4500,6262.38,100,10400,2400,1500,5000,2500,15000,40000,32500,41100,358600,109600,514300,258200,225900,402700,274300,75000,1000,56000,10000,4100,1000,15000,100,40000,7900,5000,105000,15100,2000,1100,2900,1500,600,500,1300,100,5000,5000,10000,10100,7000,40000,10500,5000,9500,1000,15200,2000,10000,10000,100,7800,3500,189900,58000,345000,151700,11000,6000,7000,15700,6000,3000,5000,10000,2000,1000,36000,1000,500,8000,9000,6000,2000,26500,6000,5000,97200,2000,5100,17000,2500,25500,24000,5400,90000,41500,6200,7500,5000,7000,41000,25000,1500,40000,5000,10000,21500,100,32000,32500,70000,500,66400,21000,5000,5000,12600,3000,6200,38900,10000,1000,60000,41100,1200,31300,2500,58000,4100,58000,42500) 

Sorry for the inconvenience. I do understand fitting of distribution to such data is not a full proof method, but this is what is the procedure that has been followed in the risk management risk industry. Please note that my question is not pertaining to operational risk. My question if if distributions are not fitting to a particular data, how do we proceed further to simualte data based on this data. 

Regards 

Amelia Marsh


From dmack10 at verizon.net  Thu Jul 23 01:54:36 2015
From: dmack10 at verizon.net (D Mack)
Date: Wed, 22 Jul 2015 16:54:36 -0700 (PDT)
Subject: [R-SIG-Finance] getSymbols for FRED in quantmod has stopped
	working???
In-Reply-To: <247111061.2447960.1435911458955.JavaMail.yahoo@mail.yahoo.com>
References: <247111061.2447960.1435911458955.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1437609276799-4710227.post@n4.nabble.com>

Alexander,  I have researched several post on this an am not clear on a work
around.     I am on a Mac using RStudio with R3.1.3

I have used a recommended workaround, but am still getting an error

options(download.file.method="libcurl")
getSymbols("DGS10", from = FromDate, to = ToDate, src="FRED")
US10Y <- data.frame(date=index(DGS10),coredata(DGS10))

I get the following error

Error in download.file(paste(FRED.URL, "/", Symbols[[i]], "/",
"downloaddata/",  : 
  object 'status' not found

Have you been able to get a work around for this issue?



--
View this message in context: http://r.789695.n4.nabble.com/getSymbols-for-FRED-in-quantmod-has-stopped-working-tp4709356p4710227.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From erol.biceroglu at alumni.utoronto.ca  Thu Jul 23 03:02:26 2015
From: erol.biceroglu at alumni.utoronto.ca (Erol Biceroglu)
Date: Wed, 22 Jul 2015 21:02:26 -0400
Subject: [R-SIG-Finance] checkBlotterUpdate fails on quantstrat
In-Reply-To: <CACjNfmkByQ+tYemkrXbzEPaZykS6kUw=WVBG17-2Zu0WpxbAtA@mail.gmail.com>
References: <CACjNfm=NzuaN31MqB7n9+H9x1aiwkpgCO_J=rtuWHXjPJM+5xQ@mail.gmail.com>
	<CAPPM_gTe0zj7CXRxCEEXM0FhUvG2qfL7cXp=Hx=3bF9AWbzTtA@mail.gmail.com>
	<CACjNfmkByQ+tYemkrXbzEPaZykS6kUw=WVBG17-2Zu0WpxbAtA@mail.gmail.com>
Message-ID: <CACjNfmkm8w+OSUPHpY1dpuHPwPX=xnZT6FYwzsHLnt8iUS+GwA@mail.gmail.com>

Hello,

So I've taken your advice Joshua, and ran applyIndicators, applySignals and
applyRules one by one.  What I've discovered is that my initial thoughts
that the NAs in the mktdata were being carried to updatePortf() were
incorrect, since I modified the signal and rules to ensure there were no
NAs, and still got the same error (checkBlotterUpdate fails).

Each function (applyIndicators, applySignals and applyRules) runs without
errors.  I can even run applyStrategy and chart.Posn successfully.

What (I believe) is ultimately throwing it off is a duplicate entry in the
portfolio object (after running updatePortf()), where in the 2nd instance
there are NAs in Windows, or NaNs in Ubuntu, in:
-Pos.Value
-Period.Unrealized.PL
-Gross.Trading.PL
-Net.Trading.PL

I *think* this is the case since I can run perTradeStats() without any
issues.

Running the following after executing the code (provided below) will
demonstrate what I'm referring to:
getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]

I've ran it in both Windows and Ubuntu OS's, under daily and weekly
frequencies.

In both OS's, daily frequencies cause checkBlotterUpdate to fail, whereas
under the weekly frequency, both OS's run checkBlotterUpdate successfully,
which allows me to generate tradeStats, and run additional functionality.

Here's my Windows sessionInfo():
> sessionInfo()
R version 3.2.0 (2015-04-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8 x64 (build 9200)

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
 LC_MONETARY=English_Canada.1252
[4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] quantstrat_0.9.1632           foreach_1.4.2
blotter_0.9.1637
[4] PerformanceAnalytics_1.4.3541 FinancialInstrument_1.2.0
quantmod_0.4-4
[7] TTR_0.22-0                    xts_0.9-7                     zoo_1.7-12


loaded via a namespace (and not attached):
[1] tools_3.2.0      codetools_0.2-11 grid_3.2.0       iterators_1.0.7
 lattice_0.20-31

and here's my Ubuntu sessionInfo():

> sessionInfo()R version 3.2.1 (2015-06-18)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.2 LTS

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
 [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
LC_PAPER=en_CA.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] quantstrat_0.9.1687           foreach_1.4.2
blotter_0.9.1666              PerformanceAnalytics_1.4.3541
[5] FinancialInstrument_1.2.0     quantmod_0.4-4
TTR_0.23-0                    xts_0.9-7
[9] zoo_1.7-12

loaded via a namespace (and not attached):
[1] tools_3.2.1     codetools_0.2-8 grid_3.2.1      iterators_1.0.7
lattice_0.20-31



Lastly, here's the updated code, which I've attempted to reduce as much as
possible.  Please let me know if there's any additional information that I
can provide.

Any thoughts and advice on how to proceed would be greatly appreciated.

Thank you for your help.

BEGIN CODE-----
library(quantstrat)

Sys.setenv(TZ="UTC")
startDate<-as.Date("1993-02-02", format="%Y-%m-%d")
endDate<-as.Date("2015-07-17", format="%Y-%m-%d")

getSymbols(Symbols = c("SPY", "^VIX")
           ,src="yahoo"
           , verbose=TRUE
           , warnings=TRUE
           , auto.assign=TRUE
           , return.class = "xts"
           , index.class = "Date"
           , from = startDate
           , to = endDate
)

#set Financial instrument objects
currency("USD")
stock(primary_id = c("SPY", "VIX"),currency = "USD")

#name
tradeStrategy <-"SPYVIXStrategy"

#Date, one day before prices
strategyDate <- min(index(SPY)) - 1

#Code to reset
#rm.strat(tradeStrategy)
#rm(mktdata)


VIXThreshold <- 20

#RUNNING THIS WORKS
# VIX <- to.weekly(VIX, drop.time = FALSE)
# SPY <- to.weekly(SPY, drop.time = FALSE)


#init portfolio and account
initPortf(name = tradeStrategy
          , symbols = "SPY" #as defined in Financial instrument
          , initDate = strategyDate)

initAcct(name = tradeStrategy
         ,portfolios = tradeStrategy
         ,initDate = strategyDate
         ,initEq = 10e6 #as.vector(first(SPY$SPY.Close))*NumSh
)

#order book, and strategy
initOrders(portfolio = tradeStrategy
           , initDate = strategyDate
)

#store strategy
strategy( tradeStrategy, store = TRUE)


#Pass VIX Close as an Indicator
PctStrat <- function(x){return(x)}


#add indicator
add.indicator(strategy = tradeStrategy
              , name = "PctStrat"
              , arguments = list( x = quote(VIX$VIX.Close))
              , label = "VIXPct"
)


#>VIX 20
add.signal(strategy = tradeStrategy
           , name = "sigThreshold"
           , arguments = list(column = c("VIX.Close.VIXPct")
                              , threshold = quote(VIXThreshold) #20
                              , relationship = "gt"
                              , cross = TRUE #FALSE
           )
           , label = "HighVolatility"
)


#<=VIX 20
add.signal(strategy = tradeStrategy
           , name = "sigThreshold"
           , arguments = list(column = c("VIX.Close.VIXPct")
                              , threshold = quote(VIXThreshold) #20
                              , relationship = "lte"
                              , cross = TRUE #FALSE
           )
           , label = "LowVolatility"
)

#rules
add.rule(strategy = tradeStrategy
         , name = "ruleSignal"
         , arguments = list(sigcol="LowVolatility"
                            , sigval=TRUE
                            , orderqty=1
                            , ordertype="market"
                            , orderside=NULL#"long"
                            #, osFUN = "osMaxPos"
         )
         , type = "enter"
)

add.rule(strategy = tradeStrategy
         , name = "ruleSignal"
         , arguments = list(sigcol= "HighVolatility"
                            , sigval=TRUE
                            , orderqty="all"
                            , ordertype="market"
                            , orderside=NULL#"long"
                            #, osFUN = "osMaxPos"
         )
         , type = "exit"
)


applyStrategy(strategy = tradeStrategy
              , portfolios = tradeStrategy
              , debug = TRUE
)


#update
updatePortf(tradeStrategy)
updateAcct(tradeStrategy)
updateEndEq(tradeStrategy)

##Verify Results

###From Guy Yollin's Slides
checkBlotterUpdate <- function(port.st,account.st,verbose=TRUE)
{
  ok <- TRUE
  p <- getPortfolio(port.st)
  a <- getAccount(account.st)
  syms <- names(p$symbols)
  port.tot <- sum(sapply(syms,FUN = function(x) eval(parse(
    text=paste("sum(p$symbols",x,"posPL.USD$Net.Trading.PL)",sep="$")))))
  port.sum.tot <- sum(p$summary$Net.Trading.PL)
  if( !isTRUE(all.equal(port.tot,port.sum.tot)) ) {
    ok <- FALSE
    if( verbose )
      print("portfolio P&L doesn't match sum of symbols P&L")
  }
  initEq <- as.numeric(first(a$summary$End.Eq))
  endEq <- as.numeric(last(a$summary$End.Eq))
  if( !isTRUE(all.equal(port.tot,endEq-initEq)) ) {
    ok <- FALSE
    if( verbose )
      print("portfolio P&L doesn't match account P&L")
  }
  if( sum(duplicated(index(p$summary))) ) {
    ok <- FALSE
    if( verbose )
      print("duplicate timestamps in portfolio summary")
  }
  if( sum(duplicated(index(a$summary))) ) {
    ok <- FALSE
    if( verbose )
      print("duplicate timestamps in account summary")
  }
  return(ok)
}
###End Guy Yollin's code

#This fails
checkBlotterUpdate(tradeStrategy,tradeStrategy)

#Here's what I suspect is causing checkBlotterUpdate() to fail (see NA's in
Windows, NaN's on Ubuntu, line 2)

getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]

#Chart strategy works

chart.Posn(tradeStrategy
           , Symbol = "SPY"
           #, Dates = "1994::"
           #, Dates = "2012::"
           ,TA = "add_TA(VIX$VIX.Close)"

)

#this doesn't work

tradeStats(tradeStrategy)

#but this does

head(perTradeStats(tradeStrategy, "SPY"))
END  CODE-------



Erol Biceroglu


*erol.biceroglu at alumni.utoronto.ca <erol.biceroglu at alumni.utoronto.ca>*

On Tue, Jul 21, 2015 at 12:49 AM, Erol Biceroglu <
erol.biceroglu at alumni.utoronto.ca> wrote:

> Hi Joshua,
>
> Thanks for the feedback, your comments are helpful.
>
> My apologies for the confusion, perhaps I provided too much information at
> first.  I am using apply.paramset, and although it runs, it doesn't work.
> It will finish without an error, but the results are empty.  The NA is
> throwing off the aggregation of the trade statistics, which occurs before I
> get to apply.paramset, so it would have made my code much longer.
>
> My intention, and what I was hoping I did, was identify what as causing
> the error (the NAs in posPL):
>
> getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
>
> I tried to trim the example down, however I wasn't sure what was causing
> the error, so I also tried to preserve as much as I could.  However I
> appreciate the advice, and I will keep that in mind in the future.
>
> Anyway, based on your comments, it looks like its the following rules that
> are causing the issue:
>
> Pct.lt.3qt.LowVol
>
> Pct.gte.3qt.LowVol
>
>
> These generate NA on the first time stamp, so I have something to go on to continue my investigation.
>
>
> Lastly, here's sessionInfo() output in case it's helpful.
>
>
> Thank you,
>
>
> > sessionInfo()R version 3.2.1 (2015-06-18)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.2 LTS
>
> locale:
>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8    LC_PAPER=en_CA.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>  [1] IKTrading_1.0                 roxygen2_4.1.1                digest_0.6.8                  Rcpp_0.11.6
>  [5] stringr_1.0.0                 timeDate_3012.100             quantstrat_0.9.1687           foreach_1.4.2
>  [9] blotter_0.9.1666              PerformanceAnalytics_1.4.3541 FinancialInstrument_1.2.0     quantmod_0.4-4
> [13] TTR_0.23-0                    xts_0.9-7                     zoo_1.7-12
>
> loaded via a namespace (and not attached):
> [1] lattice_0.20-31 codetools_0.2-8 grid_3.2.1      magrittr_1.5    stringi_0.5-5   iterators_1.0.7 tools_3.2.1
>
>
>
>
>
> Erol Biceroglu
>
>
> *erol.biceroglu at alumni.utoronto.ca <erol.biceroglu at alumni.utoronto.ca>*
>
> On Mon, Jul 20, 2015 at 11:47 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>
> wrote:
>
>> On Mon, Jul 20, 2015 at 7:53 PM, Erol Biceroglu
>> <erol.biceroglu at alumni.utoronto.ca> wrote:
>> > Hello,
>> >
>> > I've been playing around with quanstrat and was looking forward to
>> running
>> > *apply.paramset()* to optimize the strategy's parameters, only to find
>> an
>> > empty set of results.
>> >
>> Empty set of results from what?  There isn't a call to apply.paramset
>> in your code.  If you are actually running apply.paramset, please
>> provide the output from sessionInfo().
>>
>> > (Please note, my actual code follows after my message)
>> >
>> > After investigating, I found that *checkBlotterUpdate* fails with the
>> > message:
>> >
>> >> checkBlotterUpdate(tradeStrategy,tradeStrategy)
>> > [1] "portfolio P&L doesn't match sum of symbols P&L"
>> > [1] "portfolio P&L doesn't match account P&L"
>> > [1] FALSE
>> >
>> > Upon further investigation, I'm unable to run the following:
>> >> tradeStats(tradeStrategy)
>> > NULL
>> > Warning message:
>> > In tradeStats(tradeStrategy) : TotalNetProfit NA forSPY
>> >
>> > When I run this line (after executing everything), I find that the
>> > "strategy date" (the first date before the beginning of the time
>> series) is
>> > duplicated, and in the 2nd instance, there are NAs in:
>> > -Pos.Value
>> > -Period.Unrealized.PL
>> > -Gross.Trading.PL
>> > -Net.Trading.PL
>> >
>>
>> > I've tried to play around with it and unfortunately I can't figure out
>> what
>> > would cause the duplicate, generate the NA.  Any thoughts or feedback
>> would
>> > be greatly appreciated.  Thanks for your help.
>> >
>> You will likely get more help if you provide a _minimal_ reproducible
>> example (yours didn't run for me because I don't have IKTrading
>> installed).  It would also help to provide more detail about what
>> you've tried in order to solve your problem--"tried to play around
>> with it" doesn't help people know what you did.
>>
>> The general advice I can give you is to individually run
>> applyIndicators, applySignals, and applyRules; and to check the
>> mktdata object after you run each function.
>>
>> > Here's the code:
>> > ---------
>> > rm(list=ls())
>> > library(quantstrat)
>> > library(timeDate)
>> > library(stringr)
>> > library(IKTrading)
>> >
>> >
>> > Sys.setenv(TZ="UTC")
>> > startDate<-as.Date("1993-02-02", format="%Y-%m-%d")
>> > endDate<-as.Date("2015-07-17", format="%Y-%m-%d")
>> >
>> > getSymbols(Symbols = c("SPY", "^VIX")
>> >            ,src="yahoo"
>> >            , verbose=TRUE
>> >            , warnings=TRUE
>> >            , auto.assign=TRUE
>> >            , return.class = "xts"
>> >            , index.class = "Date"
>> >            ,from = startDate
>> >            , to = endDate
>> > )
>> >
>> > #set Financial instrument objects
>> > currency("USD")
>> > stock(primary_id = c("SPY", "VIX"),currency = "USD")
>> >
>> >
>> > #name
>> > tradeStrategy <-"SPYVIXStrategy"
>> >
>> > #Date, one day before prices
>> > strategyDate <- min(index(SPY)) - 1
>> >
>> >
>> > #rm.strat(tradeStrategy)
>> > #rm(mktdata)
>> >
>> > NumSh<-3
>> > VIXThreshold <- 20
>> > PctThreshold <- 0.75
>> >
>> > #init portfolio and account
>> > initPortf(name = tradeStrategy
>> >           , symbols = "SPY" #as defined in Financial instrument
>> >           , initDate = strategyDate)
>> >
>> > initAcct(name = tradeStrategy
>> >          ,portfolios = tradeStrategy
>> >          ,initDate = strategyDate
>> >          ,initEq = 10e6 #as.vector(first(SPY$SPY.Close))*NumSh
>> > )
>> >
>> >
>> >
>> > #order book, and strategy
>> > initOrders(portfolio = tradeStrategy
>> >            , initDate = strategyDate
>> > )
>> >
>> > #position limits
>> > addPosLimit(tradeStrategy, symbol = "SPY", strategyDate, maxpos = NumSh,
>> > longlevels = NumSh)
>> >
>> > strategy( tradeStrategy, store = TRUE)
>> >
>> >
>> >
>> > #define indicator function
>> > PctStrat <- function(x){
>> > data<-merge(
>> >   runPercentRank(x=ifelse(diff(x)<0,0,diff(x)),cumulative = FALSE
>> >   )
>> >   , ifelse(diff(x)<0,0,diff(x))
>> >   , x
>> > )
>> > names(data) <- c("Percentile", "PositiveDiffs","VIX.Close")
>> >
>> > data<-xts(x = sapply(data
>> >                      ,function(x){ifelse(is.na(x),0,x)}
>> >                     ), order.by = index(data)
>>
>> >           )
>> >
>> > return(data)
>> > }
>> >
>> >
>> > #add indicator
>> > add.indicator(strategy = tradeStrategy
>> >   , name = "PctStrat"
>> > , arguments = list( x = quote(VIX$VIX.Close))
>> >   , label = "VIXPct"
>> > )
>> >
>> >
>> > # >=75th percentile move
>> > add.signal(strategy = tradeStrategy
>> >            , name = "sigThreshold"
>> >            , arguments = list(column = c("Percentile.VIXPct")
>> >                               , threshold = quote(PctThreshold) #0.75
>> >                               , relationship = "gte"
>> >                               , cross = FALSE
>> >            )
>> >            , label = "Pct.gte.3Qt"
>> > )
>> >
>> > #<75th percentile move
>> > add.signal(strategy = tradeStrategy
>> >            , name = "sigThreshold"
>> >            , arguments = list(column = c("Percentile.VIXPct")
>> >                               , threshold = quote(PctThreshold) #0.75
>> >                               , relationship = "lt"
>> >                               , cross = FALSE
>> >            )
>> >            , label = "Pct.lt.3Qt"
>> > )
>> >
>> > #>VIX 20
>> > add.signal(strategy = tradeStrategy
>> >            , name = "sigThreshold"
>> >            , arguments = list(column = c("VIX.Close.VIXPct")
>> >                               , threshold = quote(VIXThreshold) #20
>> >                               , relationship = "gt"
>> >                               , cross = FALSE
>> >            )
>> >            , label = "HighVolatility"
>> > )
>> >
>> >
>> > #<=VIX 20
>> > add.signal(strategy = tradeStrategy
>> >            , name = "sigThreshold"
>> >            , arguments = list(column = c("VIX.Close.VIXPct")
>> >                               , threshold = quote(VIXThreshold) #20
>> >                               , relationship = "lte"
>> >                               , cross = FALSE
>> >            )
>> >            , label = "LowVolatility"
>> > )
>> >
>> > #intersect signals
>> > add.signal(strategy = tradeStrategy
>> >            , name = "sigAND"
>> >            , arguments = list(columns = c("Pct.lt.3Qt",
>> "LowVolatility"),
>> > cross = TRUE)
>> >            , label = "Pct.lt.3qt.LowVol"
>> > )
>> >
>> > add.signal(strategy = tradeStrategy
>> >            , name = "sigAND"
>> >            , arguments = list(columns = c("Pct.lt.3Qt",
>> "HighVolatility"),
>> > cross = FALSE)
>> >            , label = "Pct.lt.3qt.HighVol"
>> > )
>> >
>> > add.signal(strategy = tradeStrategy
>> >            , name = "sigAND"
>> >            , arguments = list(columns = c("Pct.gte.3Qt",
>> "HighVolatility"),
>> > cross = FALSE)
>> >            , label = "Pct.gte.3qt.HighVol"
>> > )
>> >
>> > add.signal(strategy = tradeStrategy
>> >            , name = "sigAND"
>> >            , arguments = list(columns = c("Pct.gte.3Qt",
>> "LowVolatility"),
>> > cross = TRUE)
>> >            , label = "Pct.gte.3qt.LowVol"
>> > )
>> >
>> > #rules
>> > add.rule(strategy = tradeStrategy
>> >          , name = "ruleSignal"
>> >          , arguments = list(sigcol="Pct.lt.3qt.LowVol"
>> >                             , sigval=TRUE
>> >                             , orderqty=NumSh
>> >                             , ordertype="market"
>> >                             , orderside=NULL#"long"
>> >                             , osFUN = "osMaxPos"
>> >          )
>> >          , type = "enter"
>> > )
>> >
>> > add.rule(strategy = tradeStrategy
>> >          , name = "ruleSignal"
>> >          , arguments = list(sigcol= "HighVolatility"
>> #"Pct.lt.3qt.HighVol"
>> >                             , sigval=TRUE
>> >                             , orderqty="all"
>> >                             , ordertype="market"
>> >                             , orderside=NULL#"long"
>> >                             , osFUN = "osMaxPos"
>> >          )
>> >          , type = "exit"
>> > )
>> >
>> > add.rule(strategy = tradeStrategy
>> >          , name = "ruleSignal"
>> >          , arguments = list(sigcol="Pct.gte.3qt.LowVol"
>> >                             , sigval=TRUE
>> >                             , orderqty=1
>> >                             , ordertype="market"
>> >                             , orderside=NULL#"long"
>> >                             , osFUN = "osMaxPos"
>> >          )
>> >          , type = "exit"
>> > )
>> >
>> >
>> > applyStrategy(strategy = tradeStrategy
>> >               , portfolios = tradeStrategy
>> > )
>> >
>> > updatePortf(tradeStrategy)
>> > updateAcct(tradeStrategy)
>> > updateEndEq(tradeStrategy)
>> >
>> >
>> > ###From Guy Yollin's Slides
>> > checkBlotterUpdate <- function(port.st,account.st,verbose=TRUE)
>> > {
>> >   ok <- TRUE
>> >   p <- getPortfolio(port.st)
>> >   a <- getAccount(account.st)
>> >   syms <- names(p$symbols)
>> >   port.tot <- sum(sapply(syms,FUN = function(x) eval(parse(
>> >     text=paste("sum(p$symbols",x,"posPL.USD$Net.Trading.PL
>> )",sep="$")))))
>> >   port.sum.tot <- sum(p$summary$Net.Trading.PL)
>>
>> >   if( !isTRUE(all.equal(port.tot,port.sum.tot)) ) {
>> >     ok <- FALSE
>> >     if( verbose )
>> >       print("portfolio P&L doesn't match sum of symbols P&L")
>> >   }
>> >   initEq <- as.numeric(first(a$summary$End.Eq))
>> >   endEq <- as.numeric(last(a$summary$End.Eq))
>> >   if( !isTRUE(all.equal(port.tot,endEq-initEq)) ) {
>> >     ok <- FALSE
>> >     if( verbose )
>> >       print("portfolio P&L doesn't match account P&L")
>> >   }
>> >   if( sum(duplicated(index(p$summary))) ) {
>> >     ok <- FALSE
>> >     if( verbose )
>> >       print("duplicate timestamps in portfolio summary")
>> >   }
>> >   if( sum(duplicated(index(a$summary))) ) {
>> >     ok <- FALSE
>> >     if( verbose )
>> >       print("duplicate timestamps in account summary")
>> >   }
>> >   return(ok)
>> > }
>> > ###End Guy Yollin's code
>> >
>> > #This fails
>> > checkBlotterUpdate(tradeStrategy,tradeStrategy)
>> >
>> > chart.Posn(tradeStrategy
>> >          , Symbol = "SPY"
>> >          #, Dates = "1994::"
>> >          #, Dates = "2012::"
>> >          ,TA = "add_TA(VIX$VIX.Close)"
>> >
>> > )
>> >
>> > #Here's an error
>> > tradeStats(tradeStrategy)
>> >
>> > #Here's the source of the error, an NA on the 2nd line
>> > getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
>> >
>> > -------
>> > End code
>> >
>> >
>> > Erol Biceroglu
>> >
>> >
>> > *erol.biceroglu at alumni.utoronto.ca <erol.biceroglu at alumni.utoronto.ca>*
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only. If you want to post, subscribe first.
>> > -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>>
>>
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com
>>
>
>

	[[alternative HTML version deleted]]


From 7141175 at gmail.com  Thu Jul 23 10:02:00 2015
From: 7141175 at gmail.com (Mauna)
Date: Thu, 23 Jul 2015 16:02:00 +0800
Subject: [R-SIG-Finance] quantmod - How to have addTA() not print legend
 when the indicator is overlaid on another chart?
Message-ID: <CADT=x93bWZofGZx60ypTqGubyNK=OVoq3Y1BWe_zZfpjZKyyLw@mail.gmail.com>

In this code:

library(quantmod)
getSymbols("YHOO")
candleChart(YHOO)
addTA(Cl(YHOO)/2, legend = "", on = NA )

the legend parameter of addTa() works as expected.

But the same value to that parameter does not work if I let on = 1:

library(quantmod)
getSymbols("YHOO")
candleChart(YHOO)
addTA(Cl(YHOO)/2, legend = "", on = 1 )

It shows Cl(YHOO)/2: followed by the last adjusted price as the legend. How
can I remove this legend? Also, is it possible to remove the last price of
shown on the chart? I couldn't find any mention of this in the chartSeries()
 documentation.

The following is the output of my sessionInfo():

R version 3.2.1 (2015-06-18)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8 x64 (build 9200)

locale:[1] LC_COLLATE=English_United States.1252
LC_CTYPE=English_United States.1252   [3] LC_MONETARY=English_United
States.1252 LC_NUMERIC=C                          [5]
LC_TIME=English_United States.1252

attached base packages:[1] parallel  stats     graphics  grDevices
utils     datasets  methods   base

other attached packages:[1] quantmod_0.4-4   TTR_0.22-0
doParallel_1.0.8 iterators_1.0.7  xts_0.9-7       [6] zoo_1.7-12
foreach_1.4.2    magrittr_1.5

loaded via a namespace (and not attached):
 [1] Rcpp_0.11.6      lubridate_1.3.3  lattice_0.20-31
codetools_0.2-11 digest_0.6.8
 [6] dplyr_0.4.2      assertthat_0.1   plyr_1.8.3       grid_3.2.1
  R6_2.1.0        [11] DBI_0.3.1        RSQLite_1.0.0    utilsSE_0.1
   stringi_0.5-5    lazyeval_0.1.10 [16] tools_3.2.1
stringr_1.0.0    compiler_3.2.1   memoise_0.2.1

	[[alternative HTML version deleted]]


From paulteetor at yahoo.com  Thu Jul 23 13:51:55 2015
From: paulteetor at yahoo.com (Paul Teetor)
Date: Thu, 23 Jul 2015 11:51:55 +0000 (UTC)
Subject: [R-SIG-Finance] Distribution fitting to loss data - Operational
 Risk
In-Reply-To: <943867839.260187.1437556029168.JavaMail.yahoo@mail.yahoo.com>
References: <943867839.260187.1437556029168.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <2110924890.1149420.1437652315269.JavaMail.yahoo@mail.yahoo.com>

Amelia:
You are following the correct procedure. Unfortunately, you are also experiencing a very common problem: the loss data for operational risk do not follow any simple distribution. Fitting that data to a particular distribution is usually difficult or meaningless from a statistician's point of view.
In operational risk, the loss events are from multiple sources (fraud, legal events, IT events, natural disaster, etc), and each source has it's own quirks. I suggest grouping the loss events according to source, then determining if each source follows a reasonable distribution. That could lead to a mixture model.
There are several excellent books on modeling loss data. Don't forget to review one or two for ideas on appropriate distributions.
You could try a statistical bootstrap. I'll warn you however, that the estimates desired by the regulators will be unstable, due to the extreme tail probability that they require.
The only good news is that regulators are aware of the problem. I suggest that you work with your Risk Management committee to determine which compromise will satisfy both them and the regulators. There is no good, simple solution here until the regulatory framework catches up with the reality.
Good luck.?Paul Teetor, Elgin, IL USAhttp://quantdevel.com/public
      From: Amelia Marsh via R-SIG-Finance <r-sig-finance at r-project.org>
 To: "r-sig-finance at r-project.org" <r-sig-finance at r-project.org> 
 Sent: Wednesday, July 22, 2015 4:07 AM
 Subject: [R-SIG-Finance] Distribution fitting to loss data - Operational Risk
   
Hello!

I am into risk management and deal with Operatioanl risk. As a part of BASEL II guidelines, we need to arrive at the capital charge the banks must set aside to counter any operational risk, if it happens. As a part of Loss Distribution Approach (LDA), we need to collate past loss events and use these loss amounts. The usual process as being practised in the industry is as follows - 

Using these historical loss amounts and using the various statistical tests like KS test, AD test, PP plot, QQ plot etc, we try to identify best statistical (continuous) distribution fitting this historical loss data. Then using these estimated parameters w.r.t. the statistical distribution, we simulate say 1 miliion loss anounts and then taking appropriate percentile (say 99.9%), we arrive at the capital charge. 

However, many a times, loss data is such that fitting of distribution to loss data is not possible. May be loss data is multimodal or has significant variability, making the fitting of distribution impossible. Can someone guide me how to deal with such data and what can be done to simulate losses using this historical loss data in R. 

My data is as follows - 

mydat <- c(829.53,4000,6000,1000,1063904,102400,22000,4000,4200,2000,10000,400, 459006, 7276,4000,100,4000,10000,613803.36, 825,1000,5000,4000,3000,84500,200, 2000,68000,97400,6267.8, 49500,27000,2100,10489.92,2200,2000,2000,1000,1900, 6000,5600,100,4000,14300,100,94100,1200,7000,2000,3000,1100,6900,1000,18500,6000,2000,4000,8400,11200,1000,15100,23300,4000,13100,4500,200,2000,50000,3900,3200,2000,2000,67000,2000,500,2000,1000,1900,10400,1900,2000,3200,6500,10000,2900,1000,14300,1000,2700,1500,12000,40000,25000,2800,5000,15000,4000,1000,21000,15000,16000,54000,1500,19200,2000,2000,1000,39000,5000,1100,18000,10000,3500,1000,10000,5000,14000,1800,4000,1000,300,4000,1000,100,1000,4400,2000,2000,12000,200,100,1000,1000,2000,1600,2000,4000,14000,4000,13500,1000,200,200,1000,18000,23000,41400,60000,500,3000,21000,6900,14600,1900,4000,4500,1000,2000,2000,1000,4100,2000,1000,2000,8000,3000,1500,2000,2000,3500,2000,2000,1000,3800,30000,55000,500,1000,1000,2000,62400,2000,3000,200,200!
 0,3500,2000,2000,500,3000,4500,1000,10000,2000,3000,3600,1000,2000,2000,5000,23000,2000,1900,2000,60000,2000,60000,20000,2000,2000,4600,1000,2000,1000,18000,6000,62000,68000,26800,50000,45900,16900,21500,2000,22700,2000,2000,32000,10000,5000,138000,159700,13000,2000,17619,2000,1000,4000,2000,1500,4000,20000,158900,74100,6000,24900,60000,500,1000,40000,10000,50000,800,4000,4900,6500,5000,400,500,3000,32300,24000,300,11500,2000,5000,1000,500,5000,5500,17450,56800,2000,1000,21400,22000,60000,3000,7500,3000,1000,1000,2000,1500,83700,2000,4000,170005,70000,6700,1500,3500,2000,10563.97,1500,25000,2000,2000,2267.57,1100,3100,2000,3500,10000,2000,6000,1500,200,20000,4000,46400,296900,150000,3700,7500,20000,48500,3500,12000,2500,4000,8500,1000,14500,1000,11000,2000,2000,120000,20000,7600,3000,2000,8000,1600,40000,2000,5000,34187.67,279100,9900,31300,814000,43500,5100,49500,4500,6262.38,100,10400,2400,1500,5000,2500,15000,40000,32500,41100,358600,109600,514300,258200,225900,402700,27!
 4300,75000,1000,56000,10000,4100,1000,15000,100,40000,7900,5000,105000
,15100,2000,1100,2900,1500,600,500,1300,100,5000,5000,10000,10100,7000,40000,10500,5000,9500,1000,15200,2000,10000,10000,100,7800,3500,189900,58000,345000,151700,11000,6000,7000,15700,6000,3000,5000,10000,2000,1000,36000,1000,500,8000,9000,6000,2000,26500,6000,5000,97200,2000,5100,17000,2500,25500,24000,5400,90000,41500,6200,7500,5000,7000,41000,25000,1500,40000,5000,10000,21500,100,32000,32500,70000,500,66400,21000,5000,5000,12600,3000,6200,38900,10000,1000,60000,41100,1200,31300,2500,58000,4100,58000,42500) 

Sorry for the inconvenience. I do understand fitting of distribution to such data is not a full proof method, but this is what is the procedure that has been followed in the risk management risk industry. Please note that my question is not pertaining to operational risk. My question if if distributions are not fitting to a particular data, how do we proceed further to simualte data based on this data. 

Regards 

Amelia Marsh

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.


  
	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Fri Jul 24 06:00:21 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 23 Jul 2015 23:00:21 -0500
Subject: [R-SIG-Finance] checkBlotterUpdate fails on quantstrat
In-Reply-To: <CACjNfmkm8w+OSUPHpY1dpuHPwPX=xnZT6FYwzsHLnt8iUS+GwA@mail.gmail.com>
References: <CACjNfm=NzuaN31MqB7n9+H9x1aiwkpgCO_J=rtuWHXjPJM+5xQ@mail.gmail.com>
	<CAPPM_gTe0zj7CXRxCEEXM0FhUvG2qfL7cXp=Hx=3bF9AWbzTtA@mail.gmail.com>
	<CACjNfmkByQ+tYemkrXbzEPaZykS6kUw=WVBG17-2Zu0WpxbAtA@mail.gmail.com>
	<CACjNfmkm8w+OSUPHpY1dpuHPwPX=xnZT6FYwzsHLnt8iUS+GwA@mail.gmail.com>
Message-ID: <CAPPM_gQERSVcKLRM4cDgSXPM8bbNwU9zf+yWk1jr2KHm9=TZSg@mail.gmail.com>

On Wed, Jul 22, 2015 at 8:02 PM, Erol Biceroglu
<erol.biceroglu at alumni.utoronto.ca> wrote:
> Hello,
>
> So I've taken your advice Joshua, and ran applyIndicators, applySignals and
> applyRules one by one.  What I've discovered is that my initial thoughts
> that the NAs in the mktdata were being carried to updatePortf() were
> incorrect, since I modified the signal and rules to ensure there were no
> NAs, and still got the same error (checkBlotterUpdate fails).
>
> Each function (applyIndicators, applySignals and applyRules) runs without
> errors.  I can even run applyStrategy and chart.Posn successfully.
>
> What (I believe) is ultimately throwing it off is a duplicate entry in the
> portfolio object (after running updatePortf()), where in the 2nd instance
> there are NAs in Windows, or NaNs in Ubuntu, in:
> -Pos.Value
> -Period.Unrealized.PL
> -Gross.Trading.PL
> -Net.Trading.PL
>
> I *think* this is the case since I can run perTradeStats() without any
> issues.
>
> Running the following after executing the code (provided below) will
> demonstrate what I'm referring to:
> getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
>
> I've ran it in both Windows and Ubuntu OS's, under daily and weekly
> frequencies.
>
> In both OS's, daily frequencies cause checkBlotterUpdate to fail, whereas
> under the weekly frequency, both OS's run checkBlotterUpdate successfully,
> which allows me to generate tradeStats, and run additional functionality.
>
> Here's my Windows sessionInfo():
<snip>
>
> and here's my Ubuntu sessionInfo():
<snip>
>
> Lastly, here's the updated code, which I've attempted to reduce as much as
> possible.  Please let me know if there's any additional information that I
> can provide.
>
Thank you very much for the more minimal example.  This looks like a
bug in blotter:::.updatePosPL.  If you don't supply the Dates argument
in the updatePortf call, the dates are extracted from the index of the
Prices argument (or the object containing data for the given Symbol).
In this case, they're extracted from the SPY object, which has an Date
class index.  The index of the posPL and txn tables are always
POSIXct.

In order to get a date range for which position P&L needs to be
updated, we subtract a very small value from the first observation in
Dates.  Since Dates is a 'Date' vector in this case and subtracting a
very small value causes the date to shift back an entire day.  This
causes the initializing transaction in the txn table to be included in
the P&L calculations.  For example:
R> as.Date("1993-02-02")-0.0001
[1] "1993-02-01"

Here's a patch that seems to fix this specific issue.  It needs more
testing before I'd be comfortable committing it to the repository.

Index: updatePosPL.R
===================================================================
--- updatePosPL.R (revision 1692)
+++ updatePosPL.R (working copy)
@@ -37,7 +37,7 @@

     # if no date is specified, get all available dates
     if(is.null(Dates)) {
-        Dates = index(prices)
+        Dates = as.POSIXct(index(prices))
     } else if(!is.timeBased(Dates)) {
         Dates<- if(is.na(.parseISO8601(Dates)$first.time) ||
             .parseISO8601(Dates)$first.time <
as.POSIXct(first(index(prices)))){


> Any thoughts and advice on how to proceed would be greatly appreciated.
>
> Thank you for your help.
>
> BEGIN CODE-----
<snip>
> END  CODE-------
>
>
>
> Erol Biceroglu
> erol.biceroglu at alumni.utoronto.ca
>
>
> On Tue, Jul 21, 2015 at 12:49 AM, Erol Biceroglu
> <erol.biceroglu at alumni.utoronto.ca> wrote:
>>
>> Hi Joshua,
>>
>> Thanks for the feedback, your comments are helpful.
>>
>> My apologies for the confusion, perhaps I provided too much information at
>> first.  I am using apply.paramset, and although it runs, it doesn't work.
>> It will finish without an error, but the results are empty.  The NA is
>> throwing off the aggregation of the trade statistics, which occurs before I
>> get to apply.paramset, so it would have made my code much longer.
>>
>> My intention, and what I was hoping I did, was identify what as causing
>> the error (the NAs in posPL):
>>
>> getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
>>
>> I tried to trim the example down, however I wasn't sure what was causing
>> the error, so I also tried to preserve as much as I could.  However I
>> appreciate the advice, and I will keep that in mind in the future.
>>
>> Anyway, based on your comments, it looks like its the following rules that
>> are causing the issue:
>>
>> Pct.lt.3qt.LowVol
>>
>> Pct.gte.3qt.LowVol
>>
>>
>> These generate NA on the first time stamp, so I have something to go on to
>> continue my investigation.
>>
>>
>> Lastly, here's sessionInfo() output in case it's helpful.
>>
>>
>> Thank you,
>>
>>
>> > sessionInfo()
>> R version 3.2.1 (2015-06-18)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.2 LTS
>>
>> locale:
>>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>> LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>> LC_PAPER=en_CA.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>>  [1] IKTrading_1.0                 roxygen2_4.1.1
>> digest_0.6.8                  Rcpp_0.11.6
>>  [5] stringr_1.0.0                 timeDate_3012.100
>> quantstrat_0.9.1687           foreach_1.4.2
>>  [9] blotter_0.9.1666              PerformanceAnalytics_1.4.3541
>> FinancialInstrument_1.2.0     quantmod_0.4-4
>> [13] TTR_0.23-0                    xts_0.9-7
>> zoo_1.7-12
>>
>> loaded via a namespace (and not attached):
>> [1] lattice_0.20-31 codetools_0.2-8 grid_3.2.1      magrittr_1.5
>> stringi_0.5-5   iterators_1.0.7 tools_3.2.1
>>
>>
>>
>>
>>
>> Erol Biceroglu
>> erol.biceroglu at alumni.utoronto.ca
>>
>>
>> On Mon, Jul 20, 2015 at 11:47 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>
>> wrote:
>>>
>>> On Mon, Jul 20, 2015 at 7:53 PM, Erol Biceroglu
>>> <erol.biceroglu at alumni.utoronto.ca> wrote:
>>> > Hello,
>>> >
>>> > I've been playing around with quanstrat and was looking forward to
>>> > running
>>> > *apply.paramset()* to optimize the strategy's parameters, only to find
>>> > an
>>> > empty set of results.
>>> >
>>> Empty set of results from what?  There isn't a call to apply.paramset
>>> in your code.  If you are actually running apply.paramset, please
>>> provide the output from sessionInfo().
>>>
>>> > (Please note, my actual code follows after my message)
>>> >
>>> > After investigating, I found that *checkBlotterUpdate* fails with the
>>> > message:
>>> >
>>> >> checkBlotterUpdate(tradeStrategy,tradeStrategy)
>>> > [1] "portfolio P&L doesn't match sum of symbols P&L"
>>> > [1] "portfolio P&L doesn't match account P&L"
>>> > [1] FALSE
>>> >
>>> > Upon further investigation, I'm unable to run the following:
>>> >> tradeStats(tradeStrategy)
>>> > NULL
>>> > Warning message:
>>> > In tradeStats(tradeStrategy) : TotalNetProfit NA forSPY
>>> >
>>> > When I run this line (after executing everything), I find that the
>>> > "strategy date" (the first date before the beginning of the time
>>> > series) is
>>> > duplicated, and in the 2nd instance, there are NAs in:
>>> > -Pos.Value
>>> > -Period.Unrealized.PL
>>> > -Gross.Trading.PL
>>> > -Net.Trading.PL
>>> >
>>>
>>> > I've tried to play around with it and unfortunately I can't figure out
>>> > what
>>> > would cause the duplicate, generate the NA.  Any thoughts or feedback
>>> > would
>>> > be greatly appreciated.  Thanks for your help.
>>> >
>>> You will likely get more help if you provide a _minimal_ reproducible
>>> example (yours didn't run for me because I don't have IKTrading
>>> installed).  It would also help to provide more detail about what
>>> you've tried in order to solve your problem--"tried to play around
>>> with it" doesn't help people know what you did.
>>>
>>> The general advice I can give you is to individually run
>>> applyIndicators, applySignals, and applyRules; and to check the
>>> mktdata object after you run each function.
>>>
>>> > Here's the code:
>>> > ---------
>>> > rm(list=ls())
>>> > library(quantstrat)
>>> > library(timeDate)
>>> > library(stringr)
>>> > library(IKTrading)
>>> >
>>> >
>>> > Sys.setenv(TZ="UTC")
>>> > startDate<-as.Date("1993-02-02", format="%Y-%m-%d")
>>> > endDate<-as.Date("2015-07-17", format="%Y-%m-%d")
>>> >
>>> > getSymbols(Symbols = c("SPY", "^VIX")
>>> >            ,src="yahoo"
>>> >            , verbose=TRUE
>>> >            , warnings=TRUE
>>> >            , auto.assign=TRUE
>>> >            , return.class = "xts"
>>> >            , index.class = "Date"
>>> >            ,from = startDate
>>> >            , to = endDate
>>> > )
>>> >
>>> > #set Financial instrument objects
>>> > currency("USD")
>>> > stock(primary_id = c("SPY", "VIX"),currency = "USD")
>>> >
>>> >
>>> > #name
>>> > tradeStrategy <-"SPYVIXStrategy"
>>> >
>>> > #Date, one day before prices
>>> > strategyDate <- min(index(SPY)) - 1
>>> >
>>> >
>>> > #rm.strat(tradeStrategy)
>>> > #rm(mktdata)
>>> >
>>> > NumSh<-3
>>> > VIXThreshold <- 20
>>> > PctThreshold <- 0.75
>>> >
>>> > #init portfolio and account
>>> > initPortf(name = tradeStrategy
>>> >           , symbols = "SPY" #as defined in Financial instrument
>>> >           , initDate = strategyDate)
>>> >
>>> > initAcct(name = tradeStrategy
>>> >          ,portfolios = tradeStrategy
>>> >          ,initDate = strategyDate
>>> >          ,initEq = 10e6 #as.vector(first(SPY$SPY.Close))*NumSh
>>> > )
>>> >
>>> >
>>> >
>>> > #order book, and strategy
>>> > initOrders(portfolio = tradeStrategy
>>> >            , initDate = strategyDate
>>> > )
>>> >
>>> > #position limits
>>> > addPosLimit(tradeStrategy, symbol = "SPY", strategyDate, maxpos =
>>> > NumSh,
>>> > longlevels = NumSh)
>>> >
>>> > strategy( tradeStrategy, store = TRUE)
>>> >
>>> >
>>> >
>>> > #define indicator function
>>> > PctStrat <- function(x){
>>> > data<-merge(
>>> >   runPercentRank(x=ifelse(diff(x)<0,0,diff(x)),cumulative = FALSE
>>> >   )
>>> >   , ifelse(diff(x)<0,0,diff(x))
>>> >   , x
>>> > )
>>> > names(data) <- c("Percentile", "PositiveDiffs","VIX.Close")
>>> >
>>> > data<-xts(x = sapply(data
>>> >                      ,function(x){ifelse(is.na(x),0,x)}
>>> >                     ), order.by = index(data)
>>>
>>> >           )
>>> >
>>> > return(data)
>>> > }
>>> >
>>> >
>>> > #add indicator
>>> > add.indicator(strategy = tradeStrategy
>>> >   , name = "PctStrat"
>>> > , arguments = list( x = quote(VIX$VIX.Close))
>>> >   , label = "VIXPct"
>>> > )
>>> >
>>> >
>>> > # >=75th percentile move
>>> > add.signal(strategy = tradeStrategy
>>> >            , name = "sigThreshold"
>>> >            , arguments = list(column = c("Percentile.VIXPct")
>>> >                               , threshold = quote(PctThreshold) #0.75
>>> >                               , relationship = "gte"
>>> >                               , cross = FALSE
>>> >            )
>>> >            , label = "Pct.gte.3Qt"
>>> > )
>>> >
>>> > #<75th percentile move
>>> > add.signal(strategy = tradeStrategy
>>> >            , name = "sigThreshold"
>>> >            , arguments = list(column = c("Percentile.VIXPct")
>>> >                               , threshold = quote(PctThreshold) #0.75
>>> >                               , relationship = "lt"
>>> >                               , cross = FALSE
>>> >            )
>>> >            , label = "Pct.lt.3Qt"
>>> > )
>>> >
>>> > #>VIX 20
>>> > add.signal(strategy = tradeStrategy
>>> >            , name = "sigThreshold"
>>> >            , arguments = list(column = c("VIX.Close.VIXPct")
>>> >                               , threshold = quote(VIXThreshold) #20
>>> >                               , relationship = "gt"
>>> >                               , cross = FALSE
>>> >            )
>>> >            , label = "HighVolatility"
>>> > )
>>> >
>>> >
>>> > #<=VIX 20
>>> > add.signal(strategy = tradeStrategy
>>> >            , name = "sigThreshold"
>>> >            , arguments = list(column = c("VIX.Close.VIXPct")
>>> >                               , threshold = quote(VIXThreshold) #20
>>> >                               , relationship = "lte"
>>> >                               , cross = FALSE
>>> >            )
>>> >            , label = "LowVolatility"
>>> > )
>>> >
>>> > #intersect signals
>>> > add.signal(strategy = tradeStrategy
>>> >            , name = "sigAND"
>>> >            , arguments = list(columns = c("Pct.lt.3Qt",
>>> > "LowVolatility"),
>>> > cross = TRUE)
>>> >            , label = "Pct.lt.3qt.LowVol"
>>> > )
>>> >
>>> > add.signal(strategy = tradeStrategy
>>> >            , name = "sigAND"
>>> >            , arguments = list(columns = c("Pct.lt.3Qt",
>>> > "HighVolatility"),
>>> > cross = FALSE)
>>> >            , label = "Pct.lt.3qt.HighVol"
>>> > )
>>> >
>>> > add.signal(strategy = tradeStrategy
>>> >            , name = "sigAND"
>>> >            , arguments = list(columns = c("Pct.gte.3Qt",
>>> > "HighVolatility"),
>>> > cross = FALSE)
>>> >            , label = "Pct.gte.3qt.HighVol"
>>> > )
>>> >
>>> > add.signal(strategy = tradeStrategy
>>> >            , name = "sigAND"
>>> >            , arguments = list(columns = c("Pct.gte.3Qt",
>>> > "LowVolatility"),
>>> > cross = TRUE)
>>> >            , label = "Pct.gte.3qt.LowVol"
>>> > )
>>> >
>>> > #rules
>>> > add.rule(strategy = tradeStrategy
>>> >          , name = "ruleSignal"
>>> >          , arguments = list(sigcol="Pct.lt.3qt.LowVol"
>>> >                             , sigval=TRUE
>>> >                             , orderqty=NumSh
>>> >                             , ordertype="market"
>>> >                             , orderside=NULL#"long"
>>> >                             , osFUN = "osMaxPos"
>>> >          )
>>> >          , type = "enter"
>>> > )
>>> >
>>> > add.rule(strategy = tradeStrategy
>>> >          , name = "ruleSignal"
>>> >          , arguments = list(sigcol= "HighVolatility"
>>> > #"Pct.lt.3qt.HighVol"
>>> >                             , sigval=TRUE
>>> >                             , orderqty="all"
>>> >                             , ordertype="market"
>>> >                             , orderside=NULL#"long"
>>> >                             , osFUN = "osMaxPos"
>>> >          )
>>> >          , type = "exit"
>>> > )
>>> >
>>> > add.rule(strategy = tradeStrategy
>>> >          , name = "ruleSignal"
>>> >          , arguments = list(sigcol="Pct.gte.3qt.LowVol"
>>> >                             , sigval=TRUE
>>> >                             , orderqty=1
>>> >                             , ordertype="market"
>>> >                             , orderside=NULL#"long"
>>> >                             , osFUN = "osMaxPos"
>>> >          )
>>> >          , type = "exit"
>>> > )
>>> >
>>> >
>>> > applyStrategy(strategy = tradeStrategy
>>> >               , portfolios = tradeStrategy
>>> > )
>>> >
>>> > updatePortf(tradeStrategy)
>>> > updateAcct(tradeStrategy)
>>> > updateEndEq(tradeStrategy)
>>> >
>>> >
>>> > ###From Guy Yollin's Slides
>>> > checkBlotterUpdate <- function(port.st,account.st,verbose=TRUE)
>>> > {
>>> >   ok <- TRUE
>>> >   p <- getPortfolio(port.st)
>>> >   a <- getAccount(account.st)
>>> >   syms <- names(p$symbols)
>>> >   port.tot <- sum(sapply(syms,FUN = function(x) eval(parse(
>>> >
>>> > text=paste("sum(p$symbols",x,"posPL.USD$Net.Trading.PL)",sep="$")))))
>>> >   port.sum.tot <- sum(p$summary$Net.Trading.PL)
>>>
>>> >   if( !isTRUE(all.equal(port.tot,port.sum.tot)) ) {
>>> >     ok <- FALSE
>>> >     if( verbose )
>>> >       print("portfolio P&L doesn't match sum of symbols P&L")
>>> >   }
>>> >   initEq <- as.numeric(first(a$summary$End.Eq))
>>> >   endEq <- as.numeric(last(a$summary$End.Eq))
>>> >   if( !isTRUE(all.equal(port.tot,endEq-initEq)) ) {
>>> >     ok <- FALSE
>>> >     if( verbose )
>>> >       print("portfolio P&L doesn't match account P&L")
>>> >   }
>>> >   if( sum(duplicated(index(p$summary))) ) {
>>> >     ok <- FALSE
>>> >     if( verbose )
>>> >       print("duplicate timestamps in portfolio summary")
>>> >   }
>>> >   if( sum(duplicated(index(a$summary))) ) {
>>> >     ok <- FALSE
>>> >     if( verbose )
>>> >       print("duplicate timestamps in account summary")
>>> >   }
>>> >   return(ok)
>>> > }
>>> > ###End Guy Yollin's code
>>> >
>>> > #This fails
>>> > checkBlotterUpdate(tradeStrategy,tradeStrategy)
>>> >
>>> > chart.Posn(tradeStrategy
>>> >          , Symbol = "SPY"
>>> >          #, Dates = "1994::"
>>> >          #, Dates = "2012::"
>>> >          ,TA = "add_TA(VIX$VIX.Close)"
>>> >
>>> > )
>>> >
>>> > #Here's an error
>>> > tradeStats(tradeStrategy)
>>> >
>>> > #Here's the source of the error, an NA on the 2nd line
>>> > getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
>>> >
>>> > -------
>>> > End code
>>> >
>>> >
>>> > Erol Biceroglu
>>> >
>>> >
>>> > *erol.biceroglu at alumni.utoronto.ca <erol.biceroglu at alumni.utoronto.ca>*
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-SIG-Finance at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> > -- Subscriber-posting only. If you want to post, subscribe first.
>>> > -- Also note that this is not the r-help list where general R questions
>>> > should go.
>>>
>>>
>>>
>>> --
>>> Joshua Ulrich  |  about.me/joshuaulrich
>>> FOSS Trading  |  www.fosstrading.com
>>
>>
>



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From josh.m.ulrich at gmail.com  Fri Jul 24 15:41:23 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 24 Jul 2015 08:41:23 -0500
Subject: [R-SIG-Finance] checkBlotterUpdate fails on quantstrat
In-Reply-To: <CAPPM_gQERSVcKLRM4cDgSXPM8bbNwU9zf+yWk1jr2KHm9=TZSg@mail.gmail.com>
References: <CACjNfm=NzuaN31MqB7n9+H9x1aiwkpgCO_J=rtuWHXjPJM+5xQ@mail.gmail.com>
	<CAPPM_gTe0zj7CXRxCEEXM0FhUvG2qfL7cXp=Hx=3bF9AWbzTtA@mail.gmail.com>
	<CACjNfmkByQ+tYemkrXbzEPaZykS6kUw=WVBG17-2Zu0WpxbAtA@mail.gmail.com>
	<CACjNfmkm8w+OSUPHpY1dpuHPwPX=xnZT6FYwzsHLnt8iUS+GwA@mail.gmail.com>
	<CAPPM_gQERSVcKLRM4cDgSXPM8bbNwU9zf+yWk1jr2KHm9=TZSg@mail.gmail.com>
Message-ID: <CAPPM_gTETA-V4-U64K-pO-nPtMTz9yRTuMJZcVd03-sLByOjpw@mail.gmail.com>

On Thu, Jul 23, 2015 at 11:00 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> On Wed, Jul 22, 2015 at 8:02 PM, Erol Biceroglu
> <erol.biceroglu at alumni.utoronto.ca> wrote:
>> Hello,
>>
>> So I've taken your advice Joshua, and ran applyIndicators, applySignals and
>> applyRules one by one.  What I've discovered is that my initial thoughts
>> that the NAs in the mktdata were being carried to updatePortf() were
>> incorrect, since I modified the signal and rules to ensure there were no
>> NAs, and still got the same error (checkBlotterUpdate fails).
>>
>> Each function (applyIndicators, applySignals and applyRules) runs without
>> errors.  I can even run applyStrategy and chart.Posn successfully.
>>
>> What (I believe) is ultimately throwing it off is a duplicate entry in the
>> portfolio object (after running updatePortf()), where in the 2nd instance
>> there are NAs in Windows, or NaNs in Ubuntu, in:
>> -Pos.Value
>> -Period.Unrealized.PL
>> -Gross.Trading.PL
>> -Net.Trading.PL
>>
>> I *think* this is the case since I can run perTradeStats() without any
>> issues.
>>
>> Running the following after executing the code (provided below) will
>> demonstrate what I'm referring to:
>> getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
>>
>> I've ran it in both Windows and Ubuntu OS's, under daily and weekly
>> frequencies.
>>
>> In both OS's, daily frequencies cause checkBlotterUpdate to fail, whereas
>> under the weekly frequency, both OS's run checkBlotterUpdate successfully,
>> which allows me to generate tradeStats, and run additional functionality.
>>
>> Here's my Windows sessionInfo():
> <snip>
>>
>> and here's my Ubuntu sessionInfo():
> <snip>
>>
>> Lastly, here's the updated code, which I've attempted to reduce as much as
>> possible.  Please let me know if there's any additional information that I
>> can provide.
>>
> Thank you very much for the more minimal example.  This looks like a
> bug in blotter:::.updatePosPL.  If you don't supply the Dates argument
> in the updatePortf call, the dates are extracted from the index of the
> Prices argument (or the object containing data for the given Symbol).
> In this case, they're extracted from the SPY object, which has an Date
> class index.  The index of the posPL and txn tables are always
> POSIXct.
>
> In order to get a date range for which position P&L needs to be
> updated, we subtract a very small value from the first observation in
> Dates.  Since Dates is a 'Date' vector in this case and subtracting a
> very small value causes the date to shift back an entire day.  This
> causes the initializing transaction in the txn table to be included in
> the P&L calculations.  For example:
> R> as.Date("1993-02-02")-0.0001
> [1] "1993-02-01"
>
> Here's a patch that seems to fix this specific issue.  It needs more
> testing before I'd be comfortable committing it to the repository.
>
Brian Peterson suggested an easier/simpler fix: simply do not set the
initDate in your calls to initPortf and initAcct.  I've confirmed that
avoids this issue.

> Index: updatePosPL.R
> ===================================================================
> --- updatePosPL.R (revision 1692)
> +++ updatePosPL.R (working copy)
> @@ -37,7 +37,7 @@
>
>      # if no date is specified, get all available dates
>      if(is.null(Dates)) {
> -        Dates = index(prices)
> +        Dates = as.POSIXct(index(prices))
>      } else if(!is.timeBased(Dates)) {
>          Dates<- if(is.na(.parseISO8601(Dates)$first.time) ||
>              .parseISO8601(Dates)$first.time <
> as.POSIXct(first(index(prices)))){
>
>
>> Any thoughts and advice on how to proceed would be greatly appreciated.
>>
>> Thank you for your help.
>>
>> BEGIN CODE-----
> <snip>
>> END  CODE-------
>>
>>
>>
>> Erol Biceroglu
>> erol.biceroglu at alumni.utoronto.ca
>>
>>
>> On Tue, Jul 21, 2015 at 12:49 AM, Erol Biceroglu
>> <erol.biceroglu at alumni.utoronto.ca> wrote:
>>>
>>> Hi Joshua,
>>>
>>> Thanks for the feedback, your comments are helpful.
>>>
>>> My apologies for the confusion, perhaps I provided too much information at
>>> first.  I am using apply.paramset, and although it runs, it doesn't work.
>>> It will finish without an error, but the results are empty.  The NA is
>>> throwing off the aggregation of the trade statistics, which occurs before I
>>> get to apply.paramset, so it would have made my code much longer.
>>>
>>> My intention, and what I was hoping I did, was identify what as causing
>>> the error (the NAs in posPL):
>>>
>>> getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
>>>
>>> I tried to trim the example down, however I wasn't sure what was causing
>>> the error, so I also tried to preserve as much as I could.  However I
>>> appreciate the advice, and I will keep that in mind in the future.
>>>
>>> Anyway, based on your comments, it looks like its the following rules that
>>> are causing the issue:
>>>
>>> Pct.lt.3qt.LowVol
>>>
>>> Pct.gte.3qt.LowVol
>>>
>>>
>>> These generate NA on the first time stamp, so I have something to go on to
>>> continue my investigation.
>>>
>>>
>>> Lastly, here's sessionInfo() output in case it's helpful.
>>>
>>>
>>> Thank you,
>>>
>>>
>>> > sessionInfo()
>>> R version 3.2.1 (2015-06-18)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu 14.04.2 LTS
>>>
>>> locale:
>>>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>> LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>>  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>>> LC_PAPER=en_CA.UTF-8       LC_NAME=C
>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>>  [1] IKTrading_1.0                 roxygen2_4.1.1
>>> digest_0.6.8                  Rcpp_0.11.6
>>>  [5] stringr_1.0.0                 timeDate_3012.100
>>> quantstrat_0.9.1687           foreach_1.4.2
>>>  [9] blotter_0.9.1666              PerformanceAnalytics_1.4.3541
>>> FinancialInstrument_1.2.0     quantmod_0.4-4
>>> [13] TTR_0.23-0                    xts_0.9-7
>>> zoo_1.7-12
>>>
>>> loaded via a namespace (and not attached):
>>> [1] lattice_0.20-31 codetools_0.2-8 grid_3.2.1      magrittr_1.5
>>> stringi_0.5-5   iterators_1.0.7 tools_3.2.1
>>>
>>>
>>>
>>>
>>>
>>> Erol Biceroglu
>>> erol.biceroglu at alumni.utoronto.ca
>>>
>>>
>>> On Mon, Jul 20, 2015 at 11:47 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>
>>> wrote:
>>>>
>>>> On Mon, Jul 20, 2015 at 7:53 PM, Erol Biceroglu
>>>> <erol.biceroglu at alumni.utoronto.ca> wrote:
>>>> > Hello,
>>>> >
>>>> > I've been playing around with quanstrat and was looking forward to
>>>> > running
>>>> > *apply.paramset()* to optimize the strategy's parameters, only to find
>>>> > an
>>>> > empty set of results.
>>>> >
>>>> Empty set of results from what?  There isn't a call to apply.paramset
>>>> in your code.  If you are actually running apply.paramset, please
>>>> provide the output from sessionInfo().
>>>>
>>>> > (Please note, my actual code follows after my message)
>>>> >
>>>> > After investigating, I found that *checkBlotterUpdate* fails with the
>>>> > message:
>>>> >
>>>> >> checkBlotterUpdate(tradeStrategy,tradeStrategy)
>>>> > [1] "portfolio P&L doesn't match sum of symbols P&L"
>>>> > [1] "portfolio P&L doesn't match account P&L"
>>>> > [1] FALSE
>>>> >
>>>> > Upon further investigation, I'm unable to run the following:
>>>> >> tradeStats(tradeStrategy)
>>>> > NULL
>>>> > Warning message:
>>>> > In tradeStats(tradeStrategy) : TotalNetProfit NA forSPY
>>>> >
>>>> > When I run this line (after executing everything), I find that the
>>>> > "strategy date" (the first date before the beginning of the time
>>>> > series) is
>>>> > duplicated, and in the 2nd instance, there are NAs in:
>>>> > -Pos.Value
>>>> > -Period.Unrealized.PL
>>>> > -Gross.Trading.PL
>>>> > -Net.Trading.PL
>>>> >
>>>>
>>>> > I've tried to play around with it and unfortunately I can't figure out
>>>> > what
>>>> > would cause the duplicate, generate the NA.  Any thoughts or feedback
>>>> > would
>>>> > be greatly appreciated.  Thanks for your help.
>>>> >
>>>> You will likely get more help if you provide a _minimal_ reproducible
>>>> example (yours didn't run for me because I don't have IKTrading
>>>> installed).  It would also help to provide more detail about what
>>>> you've tried in order to solve your problem--"tried to play around
>>>> with it" doesn't help people know what you did.
>>>>
>>>> The general advice I can give you is to individually run
>>>> applyIndicators, applySignals, and applyRules; and to check the
>>>> mktdata object after you run each function.
>>>>
>>>> > Here's the code:
>>>> > ---------
>>>> > rm(list=ls())
>>>> > library(quantstrat)
>>>> > library(timeDate)
>>>> > library(stringr)
>>>> > library(IKTrading)
>>>> >
>>>> >
>>>> > Sys.setenv(TZ="UTC")
>>>> > startDate<-as.Date("1993-02-02", format="%Y-%m-%d")
>>>> > endDate<-as.Date("2015-07-17", format="%Y-%m-%d")
>>>> >
>>>> > getSymbols(Symbols = c("SPY", "^VIX")
>>>> >            ,src="yahoo"
>>>> >            , verbose=TRUE
>>>> >            , warnings=TRUE
>>>> >            , auto.assign=TRUE
>>>> >            , return.class = "xts"
>>>> >            , index.class = "Date"
>>>> >            ,from = startDate
>>>> >            , to = endDate
>>>> > )
>>>> >
>>>> > #set Financial instrument objects
>>>> > currency("USD")
>>>> > stock(primary_id = c("SPY", "VIX"),currency = "USD")
>>>> >
>>>> >
>>>> > #name
>>>> > tradeStrategy <-"SPYVIXStrategy"
>>>> >
>>>> > #Date, one day before prices
>>>> > strategyDate <- min(index(SPY)) - 1
>>>> >
>>>> >
>>>> > #rm.strat(tradeStrategy)
>>>> > #rm(mktdata)
>>>> >
>>>> > NumSh<-3
>>>> > VIXThreshold <- 20
>>>> > PctThreshold <- 0.75
>>>> >
>>>> > #init portfolio and account
>>>> > initPortf(name = tradeStrategy
>>>> >           , symbols = "SPY" #as defined in Financial instrument
>>>> >           , initDate = strategyDate)
>>>> >
>>>> > initAcct(name = tradeStrategy
>>>> >          ,portfolios = tradeStrategy
>>>> >          ,initDate = strategyDate
>>>> >          ,initEq = 10e6 #as.vector(first(SPY$SPY.Close))*NumSh
>>>> > )
>>>> >
>>>> >
>>>> >
>>>> > #order book, and strategy
>>>> > initOrders(portfolio = tradeStrategy
>>>> >            , initDate = strategyDate
>>>> > )
>>>> >
>>>> > #position limits
>>>> > addPosLimit(tradeStrategy, symbol = "SPY", strategyDate, maxpos =
>>>> > NumSh,
>>>> > longlevels = NumSh)
>>>> >
>>>> > strategy( tradeStrategy, store = TRUE)
>>>> >
>>>> >
>>>> >
>>>> > #define indicator function
>>>> > PctStrat <- function(x){
>>>> > data<-merge(
>>>> >   runPercentRank(x=ifelse(diff(x)<0,0,diff(x)),cumulative = FALSE
>>>> >   )
>>>> >   , ifelse(diff(x)<0,0,diff(x))
>>>> >   , x
>>>> > )
>>>> > names(data) <- c("Percentile", "PositiveDiffs","VIX.Close")
>>>> >
>>>> > data<-xts(x = sapply(data
>>>> >                      ,function(x){ifelse(is.na(x),0,x)}
>>>> >                     ), order.by = index(data)
>>>>
>>>> >           )
>>>> >
>>>> > return(data)
>>>> > }
>>>> >
>>>> >
>>>> > #add indicator
>>>> > add.indicator(strategy = tradeStrategy
>>>> >   , name = "PctStrat"
>>>> > , arguments = list( x = quote(VIX$VIX.Close))
>>>> >   , label = "VIXPct"
>>>> > )
>>>> >
>>>> >
>>>> > # >=75th percentile move
>>>> > add.signal(strategy = tradeStrategy
>>>> >            , name = "sigThreshold"
>>>> >            , arguments = list(column = c("Percentile.VIXPct")
>>>> >                               , threshold = quote(PctThreshold) #0.75
>>>> >                               , relationship = "gte"
>>>> >                               , cross = FALSE
>>>> >            )
>>>> >            , label = "Pct.gte.3Qt"
>>>> > )
>>>> >
>>>> > #<75th percentile move
>>>> > add.signal(strategy = tradeStrategy
>>>> >            , name = "sigThreshold"
>>>> >            , arguments = list(column = c("Percentile.VIXPct")
>>>> >                               , threshold = quote(PctThreshold) #0.75
>>>> >                               , relationship = "lt"
>>>> >                               , cross = FALSE
>>>> >            )
>>>> >            , label = "Pct.lt.3Qt"
>>>> > )
>>>> >
>>>> > #>VIX 20
>>>> > add.signal(strategy = tradeStrategy
>>>> >            , name = "sigThreshold"
>>>> >            , arguments = list(column = c("VIX.Close.VIXPct")
>>>> >                               , threshold = quote(VIXThreshold) #20
>>>> >                               , relationship = "gt"
>>>> >                               , cross = FALSE
>>>> >            )
>>>> >            , label = "HighVolatility"
>>>> > )
>>>> >
>>>> >
>>>> > #<=VIX 20
>>>> > add.signal(strategy = tradeStrategy
>>>> >            , name = "sigThreshold"
>>>> >            , arguments = list(column = c("VIX.Close.VIXPct")
>>>> >                               , threshold = quote(VIXThreshold) #20
>>>> >                               , relationship = "lte"
>>>> >                               , cross = FALSE
>>>> >            )
>>>> >            , label = "LowVolatility"
>>>> > )
>>>> >
>>>> > #intersect signals
>>>> > add.signal(strategy = tradeStrategy
>>>> >            , name = "sigAND"
>>>> >            , arguments = list(columns = c("Pct.lt.3Qt",
>>>> > "LowVolatility"),
>>>> > cross = TRUE)
>>>> >            , label = "Pct.lt.3qt.LowVol"
>>>> > )
>>>> >
>>>> > add.signal(strategy = tradeStrategy
>>>> >            , name = "sigAND"
>>>> >            , arguments = list(columns = c("Pct.lt.3Qt",
>>>> > "HighVolatility"),
>>>> > cross = FALSE)
>>>> >            , label = "Pct.lt.3qt.HighVol"
>>>> > )
>>>> >
>>>> > add.signal(strategy = tradeStrategy
>>>> >            , name = "sigAND"
>>>> >            , arguments = list(columns = c("Pct.gte.3Qt",
>>>> > "HighVolatility"),
>>>> > cross = FALSE)
>>>> >            , label = "Pct.gte.3qt.HighVol"
>>>> > )
>>>> >
>>>> > add.signal(strategy = tradeStrategy
>>>> >            , name = "sigAND"
>>>> >            , arguments = list(columns = c("Pct.gte.3Qt",
>>>> > "LowVolatility"),
>>>> > cross = TRUE)
>>>> >            , label = "Pct.gte.3qt.LowVol"
>>>> > )
>>>> >
>>>> > #rules
>>>> > add.rule(strategy = tradeStrategy
>>>> >          , name = "ruleSignal"
>>>> >          , arguments = list(sigcol="Pct.lt.3qt.LowVol"
>>>> >                             , sigval=TRUE
>>>> >                             , orderqty=NumSh
>>>> >                             , ordertype="market"
>>>> >                             , orderside=NULL#"long"
>>>> >                             , osFUN = "osMaxPos"
>>>> >          )
>>>> >          , type = "enter"
>>>> > )
>>>> >
>>>> > add.rule(strategy = tradeStrategy
>>>> >          , name = "ruleSignal"
>>>> >          , arguments = list(sigcol= "HighVolatility"
>>>> > #"Pct.lt.3qt.HighVol"
>>>> >                             , sigval=TRUE
>>>> >                             , orderqty="all"
>>>> >                             , ordertype="market"
>>>> >                             , orderside=NULL#"long"
>>>> >                             , osFUN = "osMaxPos"
>>>> >          )
>>>> >          , type = "exit"
>>>> > )
>>>> >
>>>> > add.rule(strategy = tradeStrategy
>>>> >          , name = "ruleSignal"
>>>> >          , arguments = list(sigcol="Pct.gte.3qt.LowVol"
>>>> >                             , sigval=TRUE
>>>> >                             , orderqty=1
>>>> >                             , ordertype="market"
>>>> >                             , orderside=NULL#"long"
>>>> >                             , osFUN = "osMaxPos"
>>>> >          )
>>>> >          , type = "exit"
>>>> > )
>>>> >
>>>> >
>>>> > applyStrategy(strategy = tradeStrategy
>>>> >               , portfolios = tradeStrategy
>>>> > )
>>>> >
>>>> > updatePortf(tradeStrategy)
>>>> > updateAcct(tradeStrategy)
>>>> > updateEndEq(tradeStrategy)
>>>> >
>>>> >
>>>> > ###From Guy Yollin's Slides
>>>> > checkBlotterUpdate <- function(port.st,account.st,verbose=TRUE)
>>>> > {
>>>> >   ok <- TRUE
>>>> >   p <- getPortfolio(port.st)
>>>> >   a <- getAccount(account.st)
>>>> >   syms <- names(p$symbols)
>>>> >   port.tot <- sum(sapply(syms,FUN = function(x) eval(parse(
>>>> >
>>>> > text=paste("sum(p$symbols",x,"posPL.USD$Net.Trading.PL)",sep="$")))))
>>>> >   port.sum.tot <- sum(p$summary$Net.Trading.PL)
>>>>
>>>> >   if( !isTRUE(all.equal(port.tot,port.sum.tot)) ) {
>>>> >     ok <- FALSE
>>>> >     if( verbose )
>>>> >       print("portfolio P&L doesn't match sum of symbols P&L")
>>>> >   }
>>>> >   initEq <- as.numeric(first(a$summary$End.Eq))
>>>> >   endEq <- as.numeric(last(a$summary$End.Eq))
>>>> >   if( !isTRUE(all.equal(port.tot,endEq-initEq)) ) {
>>>> >     ok <- FALSE
>>>> >     if( verbose )
>>>> >       print("portfolio P&L doesn't match account P&L")
>>>> >   }
>>>> >   if( sum(duplicated(index(p$summary))) ) {
>>>> >     ok <- FALSE
>>>> >     if( verbose )
>>>> >       print("duplicate timestamps in portfolio summary")
>>>> >   }
>>>> >   if( sum(duplicated(index(a$summary))) ) {
>>>> >     ok <- FALSE
>>>> >     if( verbose )
>>>> >       print("duplicate timestamps in account summary")
>>>> >   }
>>>> >   return(ok)
>>>> > }
>>>> > ###End Guy Yollin's code
>>>> >
>>>> > #This fails
>>>> > checkBlotterUpdate(tradeStrategy,tradeStrategy)
>>>> >
>>>> > chart.Posn(tradeStrategy
>>>> >          , Symbol = "SPY"
>>>> >          #, Dates = "1994::"
>>>> >          #, Dates = "2012::"
>>>> >          ,TA = "add_TA(VIX$VIX.Close)"
>>>> >
>>>> > )
>>>> >
>>>> > #Here's an error
>>>> > tradeStats(tradeStrategy)
>>>> >
>>>> > #Here's the source of the error, an NA on the 2nd line
>>>> > getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
>>>> >
>>>> > -------
>>>> > End code
>>>> >
>>>> >
>>>> > Erol Biceroglu
>>>> >
>>>> >
>>>> > *erol.biceroglu at alumni.utoronto.ca <erol.biceroglu at alumni.utoronto.ca>*
>>>> >
>>>> >         [[alternative HTML version deleted]]
>>>> >
>>>> > _______________________________________________
>>>> > R-SIG-Finance at r-project.org mailing list
>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> > -- Subscriber-posting only. If you want to post, subscribe first.
>>>> > -- Also note that this is not the r-help list where general R questions
>>>> > should go.
>>>>
>>>>
>>>>
>>>> --
>>>> Joshua Ulrich  |  about.me/joshuaulrich
>>>> FOSS Trading  |  www.fosstrading.com
>>>
>>>
>>
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From erol.biceroglu at alumni.utoronto.ca  Sat Jul 25 03:08:59 2015
From: erol.biceroglu at alumni.utoronto.ca (Erol Biceroglu)
Date: Fri, 24 Jul 2015 21:08:59 -0400
Subject: [R-SIG-Finance] checkBlotterUpdate fails on quantstrat
In-Reply-To: <CAPPM_gTETA-V4-U64K-pO-nPtMTz9yRTuMJZcVd03-sLByOjpw@mail.gmail.com>
References: <CACjNfm=NzuaN31MqB7n9+H9x1aiwkpgCO_J=rtuWHXjPJM+5xQ@mail.gmail.com>
	<CAPPM_gTe0zj7CXRxCEEXM0FhUvG2qfL7cXp=Hx=3bF9AWbzTtA@mail.gmail.com>
	<CACjNfmkByQ+tYemkrXbzEPaZykS6kUw=WVBG17-2Zu0WpxbAtA@mail.gmail.com>
	<CACjNfmkm8w+OSUPHpY1dpuHPwPX=xnZT6FYwzsHLnt8iUS+GwA@mail.gmail.com>
	<CAPPM_gQERSVcKLRM4cDgSXPM8bbNwU9zf+yWk1jr2KHm9=TZSg@mail.gmail.com>
	<CAPPM_gTETA-V4-U64K-pO-nPtMTz9yRTuMJZcVd03-sLByOjpw@mail.gmail.com>
Message-ID: <CACjNfmkCqcrE1ruFCf-0pv=m90MwVs8GzWdXXtYxh5WCUV_O_g@mail.gmail.com>

Hello Joshua,

I can also confirm that Brian's suggestion solves the issue (in both OSs).
Thank you both very much for your help and time with this, I very much
appreciate it.

Regards,

Erol Biceroglu


*erol.biceroglu at alumni.utoronto.ca <erol.biceroglu at alumni.utoronto.ca>*

On Fri, Jul 24, 2015 at 9:41 AM, Joshua Ulrich <josh.m.ulrich at gmail.com>
wrote:

> On Thu, Jul 23, 2015 at 11:00 PM, Joshua Ulrich <josh.m.ulrich at gmail.com>
> wrote:
> > On Wed, Jul 22, 2015 at 8:02 PM, Erol Biceroglu
> > <erol.biceroglu at alumni.utoronto.ca> wrote:
> >> Hello,
> >>
> >> So I've taken your advice Joshua, and ran applyIndicators, applySignals
> and
> >> applyRules one by one.  What I've discovered is that my initial thoughts
> >> that the NAs in the mktdata were being carried to updatePortf() were
> >> incorrect, since I modified the signal and rules to ensure there were no
> >> NAs, and still got the same error (checkBlotterUpdate fails).
> >>
> >> Each function (applyIndicators, applySignals and applyRules) runs
> without
> >> errors.  I can even run applyStrategy and chart.Posn successfully.
> >>
> >> What (I believe) is ultimately throwing it off is a duplicate entry in
> the
> >> portfolio object (after running updatePortf()), where in the 2nd
> instance
> >> there are NAs in Windows, or NaNs in Ubuntu, in:
> >> -Pos.Value
> >> -Period.Unrealized.PL
> >> -Gross.Trading.PL
> >> -Net.Trading.PL
> >>
> >> I *think* this is the case since I can run perTradeStats() without any
> >> issues.
> >>
> >> Running the following after executing the code (provided below) will
> >> demonstrate what I'm referring to:
> >> getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
> >>
> >> I've ran it in both Windows and Ubuntu OS's, under daily and weekly
> >> frequencies.
> >>
> >> In both OS's, daily frequencies cause checkBlotterUpdate to fail,
> whereas
> >> under the weekly frequency, both OS's run checkBlotterUpdate
> successfully,
> >> which allows me to generate tradeStats, and run additional
> functionality.
> >>
> >> Here's my Windows sessionInfo():
> > <snip>
> >>
> >> and here's my Ubuntu sessionInfo():
> > <snip>
> >>
> >> Lastly, here's the updated code, which I've attempted to reduce as much
> as
> >> possible.  Please let me know if there's any additional information
> that I
> >> can provide.
> >>
> > Thank you very much for the more minimal example.  This looks like a
> > bug in blotter:::.updatePosPL.  If you don't supply the Dates argument
> > in the updatePortf call, the dates are extracted from the index of the
> > Prices argument (or the object containing data for the given Symbol).
> > In this case, they're extracted from the SPY object, which has an Date
> > class index.  The index of the posPL and txn tables are always
> > POSIXct.
> >
> > In order to get a date range for which position P&L needs to be
> > updated, we subtract a very small value from the first observation in
> > Dates.  Since Dates is a 'Date' vector in this case and subtracting a
> > very small value causes the date to shift back an entire day.  This
> > causes the initializing transaction in the txn table to be included in
> > the P&L calculations.  For example:
> > R> as.Date("1993-02-02")-0.0001
> > [1] "1993-02-01"
> >
> > Here's a patch that seems to fix this specific issue.  It needs more
> > testing before I'd be comfortable committing it to the repository.
> >
> Brian Peterson suggested an easier/simpler fix: simply do not set the
> initDate in your calls to initPortf and initAcct.  I've confirmed that
> avoids this issue.
>
> > Index: updatePosPL.R
> > ===================================================================
> > --- updatePosPL.R (revision 1692)
> > +++ updatePosPL.R (working copy)
> > @@ -37,7 +37,7 @@
> >
> >      # if no date is specified, get all available dates
> >      if(is.null(Dates)) {
> > -        Dates = index(prices)
> > +        Dates = as.POSIXct(index(prices))
> >      } else if(!is.timeBased(Dates)) {
> >          Dates<- if(is.na(.parseISO8601(Dates)$first.time) ||
> >              .parseISO8601(Dates)$first.time <
> > as.POSIXct(first(index(prices)))){
> >
> >
> >> Any thoughts and advice on how to proceed would be greatly appreciated.
> >>
> >> Thank you for your help.
> >>
> >> BEGIN CODE-----
> > <snip>
> >> END  CODE-------
> >>
> >>
> >>
> >> Erol Biceroglu
> >> erol.biceroglu at alumni.utoronto.ca
> >>
> >>
> >> On Tue, Jul 21, 2015 at 12:49 AM, Erol Biceroglu
> >> <erol.biceroglu at alumni.utoronto.ca> wrote:
> >>>
> >>> Hi Joshua,
> >>>
> >>> Thanks for the feedback, your comments are helpful.
> >>>
> >>> My apologies for the confusion, perhaps I provided too much
> information at
> >>> first.  I am using apply.paramset, and although it runs, it doesn't
> work.
> >>> It will finish without an error, but the results are empty.  The NA is
> >>> throwing off the aggregation of the trade statistics, which occurs
> before I
> >>> get to apply.paramset, so it would have made my code much longer.
> >>>
> >>> My intention, and what I was hoping I did, was identify what as causing
> >>> the error (the NAs in posPL):
> >>>
> >>> getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
> >>>
> >>> I tried to trim the example down, however I wasn't sure what was
> causing
> >>> the error, so I also tried to preserve as much as I could.  However I
> >>> appreciate the advice, and I will keep that in mind in the future.
> >>>
> >>> Anyway, based on your comments, it looks like its the following rules
> that
> >>> are causing the issue:
> >>>
> >>> Pct.lt.3qt.LowVol
> >>>
> >>> Pct.gte.3qt.LowVol
> >>>
> >>>
> >>> These generate NA on the first time stamp, so I have something to go
> on to
> >>> continue my investigation.
> >>>
> >>>
> >>> Lastly, here's sessionInfo() output in case it's helpful.
> >>>
> >>>
> >>> Thank you,
> >>>
> >>>
> >>> > sessionInfo()
> >>> R version 3.2.1 (2015-06-18)
> >>> Platform: x86_64-pc-linux-gnu (64-bit)
> >>> Running under: Ubuntu 14.04.2 LTS
> >>>
> >>> locale:
> >>>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
> >>> LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
> >>>  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
> >>> LC_PAPER=en_CA.UTF-8       LC_NAME=C
> >>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> >>> LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
> >>>
> >>> attached base packages:
> >>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>
> >>> other attached packages:
> >>>  [1] IKTrading_1.0                 roxygen2_4.1.1
> >>> digest_0.6.8                  Rcpp_0.11.6
> >>>  [5] stringr_1.0.0                 timeDate_3012.100
> >>> quantstrat_0.9.1687           foreach_1.4.2
> >>>  [9] blotter_0.9.1666              PerformanceAnalytics_1.4.3541
> >>> FinancialInstrument_1.2.0     quantmod_0.4-4
> >>> [13] TTR_0.23-0                    xts_0.9-7
> >>> zoo_1.7-12
> >>>
> >>> loaded via a namespace (and not attached):
> >>> [1] lattice_0.20-31 codetools_0.2-8 grid_3.2.1      magrittr_1.5
> >>> stringi_0.5-5   iterators_1.0.7 tools_3.2.1
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> Erol Biceroglu
> >>> erol.biceroglu at alumni.utoronto.ca
> >>>
> >>>
> >>> On Mon, Jul 20, 2015 at 11:47 PM, Joshua Ulrich <
> josh.m.ulrich at gmail.com>
> >>> wrote:
> >>>>
> >>>> On Mon, Jul 20, 2015 at 7:53 PM, Erol Biceroglu
> >>>> <erol.biceroglu at alumni.utoronto.ca> wrote:
> >>>> > Hello,
> >>>> >
> >>>> > I've been playing around with quanstrat and was looking forward to
> >>>> > running
> >>>> > *apply.paramset()* to optimize the strategy's parameters, only to
> find
> >>>> > an
> >>>> > empty set of results.
> >>>> >
> >>>> Empty set of results from what?  There isn't a call to apply.paramset
> >>>> in your code.  If you are actually running apply.paramset, please
> >>>> provide the output from sessionInfo().
> >>>>
> >>>> > (Please note, my actual code follows after my message)
> >>>> >
> >>>> > After investigating, I found that *checkBlotterUpdate* fails with
> the
> >>>> > message:
> >>>> >
> >>>> >> checkBlotterUpdate(tradeStrategy,tradeStrategy)
> >>>> > [1] "portfolio P&L doesn't match sum of symbols P&L"
> >>>> > [1] "portfolio P&L doesn't match account P&L"
> >>>> > [1] FALSE
> >>>> >
> >>>> > Upon further investigation, I'm unable to run the following:
> >>>> >> tradeStats(tradeStrategy)
> >>>> > NULL
> >>>> > Warning message:
> >>>> > In tradeStats(tradeStrategy) : TotalNetProfit NA forSPY
> >>>> >
> >>>> > When I run this line (after executing everything), I find that the
> >>>> > "strategy date" (the first date before the beginning of the time
> >>>> > series) is
> >>>> > duplicated, and in the 2nd instance, there are NAs in:
> >>>> > -Pos.Value
> >>>> > -Period.Unrealized.PL
> >>>> > -Gross.Trading.PL
> >>>> > -Net.Trading.PL
> >>>> >
> >>>>
> >>>> > I've tried to play around with it and unfortunately I can't figure
> out
> >>>> > what
> >>>> > would cause the duplicate, generate the NA.  Any thoughts or
> feedback
> >>>> > would
> >>>> > be greatly appreciated.  Thanks for your help.
> >>>> >
> >>>> You will likely get more help if you provide a _minimal_ reproducible
> >>>> example (yours didn't run for me because I don't have IKTrading
> >>>> installed).  It would also help to provide more detail about what
> >>>> you've tried in order to solve your problem--"tried to play around
> >>>> with it" doesn't help people know what you did.
> >>>>
> >>>> The general advice I can give you is to individually run
> >>>> applyIndicators, applySignals, and applyRules; and to check the
> >>>> mktdata object after you run each function.
> >>>>
> >>>> > Here's the code:
> >>>> > ---------
> >>>> > rm(list=ls())
> >>>> > library(quantstrat)
> >>>> > library(timeDate)
> >>>> > library(stringr)
> >>>> > library(IKTrading)
> >>>> >
> >>>> >
> >>>> > Sys.setenv(TZ="UTC")
> >>>> > startDate<-as.Date("1993-02-02", format="%Y-%m-%d")
> >>>> > endDate<-as.Date("2015-07-17", format="%Y-%m-%d")
> >>>> >
> >>>> > getSymbols(Symbols = c("SPY", "^VIX")
> >>>> >            ,src="yahoo"
> >>>> >            , verbose=TRUE
> >>>> >            , warnings=TRUE
> >>>> >            , auto.assign=TRUE
> >>>> >            , return.class = "xts"
> >>>> >            , index.class = "Date"
> >>>> >            ,from = startDate
> >>>> >            , to = endDate
> >>>> > )
> >>>> >
> >>>> > #set Financial instrument objects
> >>>> > currency("USD")
> >>>> > stock(primary_id = c("SPY", "VIX"),currency = "USD")
> >>>> >
> >>>> >
> >>>> > #name
> >>>> > tradeStrategy <-"SPYVIXStrategy"
> >>>> >
> >>>> > #Date, one day before prices
> >>>> > strategyDate <- min(index(SPY)) - 1
> >>>> >
> >>>> >
> >>>> > #rm.strat(tradeStrategy)
> >>>> > #rm(mktdata)
> >>>> >
> >>>> > NumSh<-3
> >>>> > VIXThreshold <- 20
> >>>> > PctThreshold <- 0.75
> >>>> >
> >>>> > #init portfolio and account
> >>>> > initPortf(name = tradeStrategy
> >>>> >           , symbols = "SPY" #as defined in Financial instrument
> >>>> >           , initDate = strategyDate)
> >>>> >
> >>>> > initAcct(name = tradeStrategy
> >>>> >          ,portfolios = tradeStrategy
> >>>> >          ,initDate = strategyDate
> >>>> >          ,initEq = 10e6 #as.vector(first(SPY$SPY.Close))*NumSh
> >>>> > )
> >>>> >
> >>>> >
> >>>> >
> >>>> > #order book, and strategy
> >>>> > initOrders(portfolio = tradeStrategy
> >>>> >            , initDate = strategyDate
> >>>> > )
> >>>> >
> >>>> > #position limits
> >>>> > addPosLimit(tradeStrategy, symbol = "SPY", strategyDate, maxpos =
> >>>> > NumSh,
> >>>> > longlevels = NumSh)
> >>>> >
> >>>> > strategy( tradeStrategy, store = TRUE)
> >>>> >
> >>>> >
> >>>> >
> >>>> > #define indicator function
> >>>> > PctStrat <- function(x){
> >>>> > data<-merge(
> >>>> >   runPercentRank(x=ifelse(diff(x)<0,0,diff(x)),cumulative = FALSE
> >>>> >   )
> >>>> >   , ifelse(diff(x)<0,0,diff(x))
> >>>> >   , x
> >>>> > )
> >>>> > names(data) <- c("Percentile", "PositiveDiffs","VIX.Close")
> >>>> >
> >>>> > data<-xts(x = sapply(data
> >>>> >                      ,function(x){ifelse(is.na(x),0,x)}
> >>>> >                     ), order.by = index(data)
> >>>>
> >>>> >           )
> >>>> >
> >>>> > return(data)
> >>>> > }
> >>>> >
> >>>> >
> >>>> > #add indicator
> >>>> > add.indicator(strategy = tradeStrategy
> >>>> >   , name = "PctStrat"
> >>>> > , arguments = list( x = quote(VIX$VIX.Close))
> >>>> >   , label = "VIXPct"
> >>>> > )
> >>>> >
> >>>> >
> >>>> > # >=75th percentile move
> >>>> > add.signal(strategy = tradeStrategy
> >>>> >            , name = "sigThreshold"
> >>>> >            , arguments = list(column = c("Percentile.VIXPct")
> >>>> >                               , threshold = quote(PctThreshold)
> #0.75
> >>>> >                               , relationship = "gte"
> >>>> >                               , cross = FALSE
> >>>> >            )
> >>>> >            , label = "Pct.gte.3Qt"
> >>>> > )
> >>>> >
> >>>> > #<75th percentile move
> >>>> > add.signal(strategy = tradeStrategy
> >>>> >            , name = "sigThreshold"
> >>>> >            , arguments = list(column = c("Percentile.VIXPct")
> >>>> >                               , threshold = quote(PctThreshold)
> #0.75
> >>>> >                               , relationship = "lt"
> >>>> >                               , cross = FALSE
> >>>> >            )
> >>>> >            , label = "Pct.lt.3Qt"
> >>>> > )
> >>>> >
> >>>> > #>VIX 20
> >>>> > add.signal(strategy = tradeStrategy
> >>>> >            , name = "sigThreshold"
> >>>> >            , arguments = list(column = c("VIX.Close.VIXPct")
> >>>> >                               , threshold = quote(VIXThreshold) #20
> >>>> >                               , relationship = "gt"
> >>>> >                               , cross = FALSE
> >>>> >            )
> >>>> >            , label = "HighVolatility"
> >>>> > )
> >>>> >
> >>>> >
> >>>> > #<=VIX 20
> >>>> > add.signal(strategy = tradeStrategy
> >>>> >            , name = "sigThreshold"
> >>>> >            , arguments = list(column = c("VIX.Close.VIXPct")
> >>>> >                               , threshold = quote(VIXThreshold) #20
> >>>> >                               , relationship = "lte"
> >>>> >                               , cross = FALSE
> >>>> >            )
> >>>> >            , label = "LowVolatility"
> >>>> > )
> >>>> >
> >>>> > #intersect signals
> >>>> > add.signal(strategy = tradeStrategy
> >>>> >            , name = "sigAND"
> >>>> >            , arguments = list(columns = c("Pct.lt.3Qt",
> >>>> > "LowVolatility"),
> >>>> > cross = TRUE)
> >>>> >            , label = "Pct.lt.3qt.LowVol"
> >>>> > )
> >>>> >
> >>>> > add.signal(strategy = tradeStrategy
> >>>> >            , name = "sigAND"
> >>>> >            , arguments = list(columns = c("Pct.lt.3Qt",
> >>>> > "HighVolatility"),
> >>>> > cross = FALSE)
> >>>> >            , label = "Pct.lt.3qt.HighVol"
> >>>> > )
> >>>> >
> >>>> > add.signal(strategy = tradeStrategy
> >>>> >            , name = "sigAND"
> >>>> >            , arguments = list(columns = c("Pct.gte.3Qt",
> >>>> > "HighVolatility"),
> >>>> > cross = FALSE)
> >>>> >            , label = "Pct.gte.3qt.HighVol"
> >>>> > )
> >>>> >
> >>>> > add.signal(strategy = tradeStrategy
> >>>> >            , name = "sigAND"
> >>>> >            , arguments = list(columns = c("Pct.gte.3Qt",
> >>>> > "LowVolatility"),
> >>>> > cross = TRUE)
> >>>> >            , label = "Pct.gte.3qt.LowVol"
> >>>> > )
> >>>> >
> >>>> > #rules
> >>>> > add.rule(strategy = tradeStrategy
> >>>> >          , name = "ruleSignal"
> >>>> >          , arguments = list(sigcol="Pct.lt.3qt.LowVol"
> >>>> >                             , sigval=TRUE
> >>>> >                             , orderqty=NumSh
> >>>> >                             , ordertype="market"
> >>>> >                             , orderside=NULL#"long"
> >>>> >                             , osFUN = "osMaxPos"
> >>>> >          )
> >>>> >          , type = "enter"
> >>>> > )
> >>>> >
> >>>> > add.rule(strategy = tradeStrategy
> >>>> >          , name = "ruleSignal"
> >>>> >          , arguments = list(sigcol= "HighVolatility"
> >>>> > #"Pct.lt.3qt.HighVol"
> >>>> >                             , sigval=TRUE
> >>>> >                             , orderqty="all"
> >>>> >                             , ordertype="market"
> >>>> >                             , orderside=NULL#"long"
> >>>> >                             , osFUN = "osMaxPos"
> >>>> >          )
> >>>> >          , type = "exit"
> >>>> > )
> >>>> >
> >>>> > add.rule(strategy = tradeStrategy
> >>>> >          , name = "ruleSignal"
> >>>> >          , arguments = list(sigcol="Pct.gte.3qt.LowVol"
> >>>> >                             , sigval=TRUE
> >>>> >                             , orderqty=1
> >>>> >                             , ordertype="market"
> >>>> >                             , orderside=NULL#"long"
> >>>> >                             , osFUN = "osMaxPos"
> >>>> >          )
> >>>> >          , type = "exit"
> >>>> > )
> >>>> >
> >>>> >
> >>>> > applyStrategy(strategy = tradeStrategy
> >>>> >               , portfolios = tradeStrategy
> >>>> > )
> >>>> >
> >>>> > updatePortf(tradeStrategy)
> >>>> > updateAcct(tradeStrategy)
> >>>> > updateEndEq(tradeStrategy)
> >>>> >
> >>>> >
> >>>> > ###From Guy Yollin's Slides
> >>>> > checkBlotterUpdate <- function(port.st,account.st,verbose=TRUE)
> >>>> > {
> >>>> >   ok <- TRUE
> >>>> >   p <- getPortfolio(port.st)
> >>>> >   a <- getAccount(account.st)
> >>>> >   syms <- names(p$symbols)
> >>>> >   port.tot <- sum(sapply(syms,FUN = function(x) eval(parse(
> >>>> >
> >>>> > text=paste("sum(p$symbols",x,"posPL.USD$Net.Trading.PL
> )",sep="$")))))
> >>>> >   port.sum.tot <- sum(p$summary$Net.Trading.PL)
> >>>>
> >>>> >   if( !isTRUE(all.equal(port.tot,port.sum.tot)) ) {
> >>>> >     ok <- FALSE
> >>>> >     if( verbose )
> >>>> >       print("portfolio P&L doesn't match sum of symbols P&L")
> >>>> >   }
> >>>> >   initEq <- as.numeric(first(a$summary$End.Eq))
> >>>> >   endEq <- as.numeric(last(a$summary$End.Eq))
> >>>> >   if( !isTRUE(all.equal(port.tot,endEq-initEq)) ) {
> >>>> >     ok <- FALSE
> >>>> >     if( verbose )
> >>>> >       print("portfolio P&L doesn't match account P&L")
> >>>> >   }
> >>>> >   if( sum(duplicated(index(p$summary))) ) {
> >>>> >     ok <- FALSE
> >>>> >     if( verbose )
> >>>> >       print("duplicate timestamps in portfolio summary")
> >>>> >   }
> >>>> >   if( sum(duplicated(index(a$summary))) ) {
> >>>> >     ok <- FALSE
> >>>> >     if( verbose )
> >>>> >       print("duplicate timestamps in account summary")
> >>>> >   }
> >>>> >   return(ok)
> >>>> > }
> >>>> > ###End Guy Yollin's code
> >>>> >
> >>>> > #This fails
> >>>> > checkBlotterUpdate(tradeStrategy,tradeStrategy)
> >>>> >
> >>>> > chart.Posn(tradeStrategy
> >>>> >          , Symbol = "SPY"
> >>>> >          #, Dates = "1994::"
> >>>> >          #, Dates = "2012::"
> >>>> >          ,TA = "add_TA(VIX$VIX.Close)"
> >>>> >
> >>>> > )
> >>>> >
> >>>> > #Here's an error
> >>>> > tradeStats(tradeStrategy)
> >>>> >
> >>>> > #Here's the source of the error, an NA on the 2nd line
> >>>> > getPortfolio(tradeStrategy)$symbols$SPY$posPL[1:10]
> >>>> >
> >>>> > -------
> >>>> > End code
> >>>> >
> >>>> >
> >>>> > Erol Biceroglu
> >>>> >
> >>>> >
> >>>> > *erol.biceroglu at alumni.utoronto.ca <
> erol.biceroglu at alumni.utoronto.ca>*
> >>>> >
> >>>> >         [[alternative HTML version deleted]]
> >>>> >
> >>>> > _______________________________________________
> >>>> > R-SIG-Finance at r-project.org mailing list
> >>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >>>> > -- Subscriber-posting only. If you want to post, subscribe first.
> >>>> > -- Also note that this is not the r-help list where general R
> questions
> >>>> > should go.
> >>>>
> >>>>
> >>>>
> >>>> --
> >>>> Joshua Ulrich  |  about.me/joshuaulrich
> >>>> FOSS Trading  |  www.fosstrading.com
> >>>
> >>>
> >>
> >
> >
> >
> > --
> > Joshua Ulrich  |  about.me/joshuaulrich
> > FOSS Trading  |  www.fosstrading.com
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
>

	[[alternative HTML version deleted]]


From uchiharj at gmail.com  Sun Jul 26 23:58:44 2015
From: uchiharj at gmail.com (Rods)
Date: Mon, 27 Jul 2015 01:58:44 +0400
Subject: [R-SIG-Finance] Question about dccsim
Message-ID: <CAJLULw=8SMzautdXZkTqHGwLrawzUzsFjT2Py_vrx4ZTzkMYSw@mail.gmail.com>

Hi,

I'm wondering why dccsim is giving a different 1 step ahead H matrix from
dccforecast. Shouldn't these be the same? Running the code below, you can
see that only the diagonal matches. Also, if I remove the rseed argument
I'm getting an error, is it just me? Lastly, if you just run "sim1", you
get an empty summary.

Thanks in advance,
-------------------------------------------------------------------------------------

    data(dji30retw)
    Dat = dji30retw[, 1:3, drop = FALSE]


    cnames = colnames(Dat)
    uspec = ugarchspec(mean.model = list(armaOrder = c(2,1), include.mean =
FALSE), variance.model = list(garchOrder = c(1,1), model = "gjrGARCH"),
distribution.model = "norm")
    spec1 = dccspec(uspec = multispec( replicate(3, uspec) ), dccOrder =
c(1,1),
             distribution = "mvnorm")
    fit1 = dccfit(spec1, data = Dat, out.sample = 100, fit.control = list(
eval.se=FALSE))
    T = dim(Dat)[1]-100


    forc2 = dccforecast(fit1, n.ahead = 1, n.roll = 10)
    presigma = tail( sigma(fit1 ), 2 )
    preresiduals = tail( residuals(fit1), 2 )
    prereturns = tail( as.matrix(Dat[1:T,]), 2 )


    sim1 = dccsim(fitORspec = fit1, n.sim = 2, m.sim = 500, startMethod =
"unconditional",
            presigma = presigma, preresiduals = preresiduals, prereturns =
prereturns,
            preQ = last(rcor(fit1, type = "Q"))[,,1], Qbar = fit1 at mfit$Qbar,

            preZ = tail(fit1 at mfit$stdresid, 1), rseed=c(152))


    sim1 at msim$simH[[1]][,,1]
    forc2 at mforecast$H[[1]]

	[[alternative HTML version deleted]]


From dutangc at gmail.com  Mon Jul 27 10:40:55 2015
From: dutangc at gmail.com (Christophe Dutang)
Date: Mon, 27 Jul 2015 10:40:55 +0200
Subject: [R-SIG-Finance] Distribution fitting to loss data - Operational
	Risk
In-Reply-To: <943867839.260187.1437556029168.JavaMail.yahoo@mail.yahoo.com>
References: <943867839.260187.1437556029168.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <725FACCE-E814-4C65-8304-3F41E628A964@gmail.com>

Hi,

The Pareto II distribution does a great job for fitting your data. see below

plot(ecdf(mydat))
plot(ecdf(mydat), log="x", xlim=range(mydat)+1)

#identical values?
table(mydat)[table(mydat) > 10] 

mydat <- mydat + rnorm(mydat, sd=.1)

library(actuar)
library(fitdistrplus)

f1 <- fitdist(mydat, "burr", start=list(shape1=2, shape2=2, rate=0.0005), method="qme", lower=c(1, 1, 0.1), probs=c(1/4, 1/2, 3/4))
f2 <- fitdist(mydat, "pareto", start=list(shape=2, scale=1000), method="mle", lower=c(0.5, 0))

cdfcomp(list(f1, f2), do.points=FALSE, xlogscale=TRUE, legend=c("Burr", "Pareto 2"))

Regards, CD
---------------------------------------
Christophe Dutang
LMM, UdM, Le Mans, France
web: http://dutangc.free.fr

Le 22 juil. 2015 ? 11:07, Amelia Marsh via R-SIG-Finance <r-sig-finance at r-project.org> a ?crit :

> Hello!
> 
> I am into risk management and deal with Operatioanl risk. As a part of BASEL II guidelines, we need to arrive at the capital charge the banks must set aside to counter any operational risk, if it happens. As a part of Loss Distribution Approach (LDA), we need to collate past loss events and use these loss amounts. The usual process as being practised in the industry is as follows - 
> 
> Using these historical loss amounts and using the various statistical tests like KS test, AD test, PP plot, QQ plot etc, we try to identify best statistical (continuous) distribution fitting this historical loss data. Then using these estimated parameters w.r.t. the statistical distribution, we simulate say 1 miliion loss anounts and then taking appropriate percentile (say 99.9%), we arrive at the capital charge. 
> 
> However, many a times, loss data is such that fitting of distribution to loss data is not possible. May be loss data is multimodal or has significant variability, making the fitting of distribution impossible. Can someone guide me how to deal with such data and what can be done to simulate losses using this historical loss data in R. 
> 
> My data is as follows - 
> 
> mydat <- c(829.53,4000,6000,1000,1063904,102400,22000,4000,4200,2000,10000,400, 459006, 7276,4000,100,4000,10000,613803.36, 825,1000,5000,4000,3000,84500,200, 2000,68000,97400,6267.8, 49500,27000,2100,10489.92,2200,2000,2000,1000,1900, 6000,5600,100,4000,14300,100,94100,1200,7000,2000,3000,1100,6900,1000,18500,6000,2000,4000,8400,11200,1000,15100,23300,4000,13100,4500,200,2000,50000,3900,3200,2000,2000,67000,2000,500,2000,1000,1900,10400,1900,2000,3200,6500,10000,2900,1000,14300,1000,2700,1500,12000,40000,25000,2800,5000,15000,4000,1000,21000,15000,16000,54000,1500,19200,2000,2000,1000,39000,5000,1100,18000,10000,3500,1000,10000,5000,14000,1800,4000,1000,300,4000,1000,100,1000,4400,2000,2000,12000,200,100,1000,1000,2000,1600,2000,4000,14000,4000,13500,1000,200,200,1000,18000,23000,41400,60000,500,3000,21000,6900,14600,1900,4000,4500,1000,2000,2000,1000,4100,2000,1000,2000,8000,3000,1500,2000,2000,3500,2000,2000,1000,3800,30000,55000,500,1000,1000,2000,62400,2000,3000,200,200!
> 0,3500,2000,2000,500,3000,4500,1000,10000,2000,3000,3600,1000,2000,2000,5000,23000,2000,1900,2000,60000,2000,60000,20000,2000,2000,4600,1000,2000,1000,18000,6000,62000,68000,26800,50000,45900,16900,21500,2000,22700,2000,2000,32000,10000,5000,138000,159700,13000,2000,17619,2000,1000,4000,2000,1500,4000,20000,158900,74100,6000,24900,60000,500,1000,40000,10000,50000,800,4000,4900,6500,5000,400,500,3000,32300,24000,300,11500,2000,5000,1000,500,5000,5500,17450,56800,2000,1000,21400,22000,60000,3000,7500,3000,1000,1000,2000,1500,83700,2000,4000,170005,70000,6700,1500,3500,2000,10563.97,1500,25000,2000,2000,2267.57,1100,3100,2000,3500,10000,2000,6000,1500,200,20000,4000,46400,296900,150000,3700,7500,20000,48500,3500,12000,2500,4000,8500,1000,14500,1000,11000,2000,2000,120000,20000,7600,3000,2000,8000,1600,40000,2000,5000,34187.67,279100,9900,31300,814000,43500,5100,49500,4500,6262.38,100,10400,2400,1500,5000,2500,15000,40000,32500,41100,358600,109600,514300,258200,225900,402700,27!
> 4300,75000,1000,56000,10000,4100,1000,15000,100,40000,7900,5000,105000
> ,15100,2000,1100,2900,1500,600,500,1300,100,5000,5000,10000,10100,7000,40000,10500,5000,9500,1000,15200,2000,10000,10000,100,7800,3500,189900,58000,345000,151700,11000,6000,7000,15700,6000,3000,5000,10000,2000,1000,36000,1000,500,8000,9000,6000,2000,26500,6000,5000,97200,2000,5100,17000,2500,25500,24000,5400,90000,41500,6200,7500,5000,7000,41000,25000,1500,40000,5000,10000,21500,100,32000,32500,70000,500,66400,21000,5000,5000,12600,3000,6200,38900,10000,1000,60000,41100,1200,31300,2500,58000,4100,58000,42500) 
> 
> Sorry for the inconvenience. I do understand fitting of distribution to such data is not a full proof method, but this is what is the procedure that has been followed in the risk management risk industry. Please note that my question is not pertaining to operational risk. My question if if distributions are not fitting to a particular data, how do we proceed further to simualte data based on this data. 
> 
> Regards 
> 
> Amelia Marsh
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From alexios at 4dscape.com  Mon Jul 27 12:20:09 2015
From: alexios at 4dscape.com (alexios)
Date: Mon, 27 Jul 2015 11:20:09 +0100
Subject: [R-SIG-Finance] Question about dccsim
In-Reply-To: <CAJLULw=8SMzautdXZkTqHGwLrawzUzsFjT2Py_vrx4ZTzkMYSw@mail.gmail.com>
References: <CAJLULw=8SMzautdXZkTqHGwLrawzUzsFjT2Py_vrx4ZTzkMYSw@mail.gmail.com>
Message-ID: <55B605D9.10402@4dscape.com>

Hi,

It should.

For preZ use:
preZ = tail(residuals(fit1)/sigma(fit1),1)
NOT
preZ = tail(fit1 at mfit$stdresid, 1)

I'm guessing you looked at the code for startMethod="sample"
which used this (wrongly). This has been fixed now in
the version 1.3-0 on bitbucket.

As a test, we can perform the following in-sample check,
which also illustrates the use of dccsim using a specification
object:

######################################################
library(rmgarch)
data(dji30retw)
Dat = dji30retw[, 1:3, drop = FALSE]
cnames = colnames(Dat)
uspec = ugarchspec(mean.model = list(armaOrder = c(2,1), include.mean =
FALSE), variance.model = list(garchOrder = c(2,1), model = "gjrGARCH"),
distribution.model = "norm")
spec = dccspec(uspec = multispec( replicate(3, uspec) ), dccOrder = 
c(1,1), distribution = "mvnorm")
fit = dccfit(spec, data = Dat, fit.control = list(eval.se=FALSE))

uspec2 = ugarchspec(mean.model = list(armaOrder = c(2,1), include.mean =
FALSE), variance.model = list(garchOrder = c(2,1), model = "gjrGARCH"),
distribution.model = "norm")
vspec = vector(mode = "list", length = 3)
midx = fit at model$midx
mpars = fit at model$mpars
for(i in 1:3){
vspec[[i]] = uspec2
setfixed(vspec[[i]])<-as.list(mpars[midx[,i]==1, i])
}
dccfix = as.list(coef(fit, "dcc"))
spec2 = dccspec(uspec = multispec( vspec ),
dccOrder = c(1,1),  distribution = "mvnorm",
fixed.pars = dccfix)

presigma = sigma(fit)[1:2,]
preresiduals = residuals(fit)[1:2,]
prereturns = as.matrix(Dat[1:2,])

sim = dccsim(fitORspec = spec2, n.sim = 1, n.start = 0, m.sim = 1,
presigma = presigma, preresiduals = preresiduals, prereturns = 
prereturns, preQ = rcor(fit, type = "Q")[,,2], Qbar = fit at mfit$Qbar,
		preZ = (residuals(fit)/sigma(fit))[2,],rseed = c(100), mexsimdata = 
NULL, vexsimdata = NULL)

# the in-sample forecast for T+3 == simulated 1-ahead at T+2
all.equal(rcov(fit)[,,3], rcov(sim)[,,1],check.attributes=FALSE)
 >TRUE
###################################################################

As regards the rseed, yes there is an error if you don't explicitly 
provide it. I'll look into this when I have more time.

The summary for simulated DCC objects is indeed empty...feel free to 
contribute a patch which will show something more meaningful.

Regards,

Alexios

On 26/07/2015 22:58, Rods wrote:
> Hi,
>
> I'm wondering why dccsim is giving a different 1 step ahead H matrix from
> dccforecast. Shouldn't these be the same? Running the code below, you can
> see that only the diagonal matches. Also, if I remove the rseed argument
> I'm getting an error, is it just me? Lastly, if you just run "sim1", you
> get an empty summary.
>
> Thanks in advance,
> -------------------------------------------------------------------------------------
>
>      data(dji30retw)
>      Dat = dji30retw[, 1:3, drop = FALSE]
>
>
>      cnames = colnames(Dat)
>      uspec = ugarchspec(mean.model = list(armaOrder = c(2,1), include.mean =
> FALSE), variance.model = list(garchOrder = c(1,1), model = "gjrGARCH"),
> distribution.model = "norm")
>      spec1 = dccspec(uspec = multispec( replicate(3, uspec) ), dccOrder =
> c(1,1),
>               distribution = "mvnorm")
>      fit1 = dccfit(spec1, data = Dat, out.sample = 100, fit.control = list(
> eval.se=FALSE))
>      T = dim(Dat)[1]-100
>
>
>      forc2 = dccforecast(fit1, n.ahead = 1, n.roll = 10)
>      presigma = tail( sigma(fit1 ), 2 )
>      preresiduals = tail( residuals(fit1), 2 )
>      prereturns = tail( as.matrix(Dat[1:T,]), 2 )
>
>
>      sim1 = dccsim(fitORspec = fit1, n.sim = 2, m.sim = 500, startMethod =
> "unconditional",
>              presigma = presigma, preresiduals = preresiduals, prereturns =
> prereturns,
>              preQ = last(rcor(fit1, type = "Q"))[,,1], Qbar = fit1 at mfit$Qbar,
>
>              preZ = tail(fit1 at mfit$stdresid, 1), rseed=c(152))
>
>
>      sim1 at msim$simH[[1]][,,1]
>      forc2 at mforecast$H[[1]]
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>
>


From josh.m.ulrich at gmail.com  Mon Jul 27 16:53:15 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 27 Jul 2015 09:53:15 -0500
Subject: [R-SIG-Finance] getSymbols for FRED in quantmod has stopped
	working???
In-Reply-To: <55971692.9010806@gmail.com>
References: <247111061.2447960.1435911458955.JavaMail.yahoo@mail.yahoo.com>
	<CAPPM_gTUnHogn7JUh0sz9hHi2tg+M4tVuJXhRCJZKjLoR7ZnBg@mail.gmail.com>
	<CAEjpDDqT0-OeVYmd+wA7arSWEWabYWR8hidJJQSOsdW=4+25qg@mail.gmail.com>
	<55971692.9010806@gmail.com>
Message-ID: <CAPPM_gRsjN3B0KNz2rtNgsZFNPm7u2r-anJ809vjibfnFu-=+A@mail.gmail.com>

An updated version of quantmod that addresses this issue is on CRAN now.

On Fri, Jul 3, 2015 at 6:11 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> The discussion on R-pkg-devel has been about how to fix default
> download.file behaviour that has previously worked on all platforms, and is
> now broken by a very recent change at the St Louis Fed. A method working a
> few days ago would not be a guarantee that it still works. Before people go
> overboard changing their workflow, let me point out that this can likely be
> fixed by a user setting
>
>    options(download.file.method="libcurl")
> or
>    options(download.file.method="wget")
> or
>    options(download.file.method="wininet")
>
> See ?download.file  for more options, which will be platform specific (but
> maybe not as specific as using an excel macro).
>
> The package developer problem is slightly different. That problem, the
> problem that Joshua is working on, is that the default method no longer
> works. So either the default method has to be fixed or users need to be
> directed to some solution that will depend on their platform.
>
> Paul
>
>
> On 07/03/2015 12:05 PM, Daniel Melendez wrote:
>>
>> As a suggestion ( although not that efficient ) there is an excel macro
>> that can download the information.  I'm not sure if you're aware of it or
>> not but just thought I'd mention it just in case.
>>
>> https://research.stlouisfed.org/fred-addin/
>>
>> On Fri, Jul 3, 2015 at 10:30 AM, Joshua Ulrich <josh.m.ulrich at gmail.com>
>> wrote:
>>
>>> On Fri, Jul 3, 2015 at 3:17 AM, Alexander Gracian <agracian at yahoo.co.uk>
>>> wrote:
>>>>
>>>>
>>>> Hi,
>>>> I have started getting an error when using getSymbols for FRED in
>>>
>>> quantmod. It was working fine a few weeks ago. I'm using R on a Mac:
>>>>
>>>> getSymbols("CPIAUCSL", src="FRED")Error in download.file(paste(FRED.URL,
>>>
>>> "/", Symbols[[i]], "/", "downloaddata/",  :   cannot open URL '
>>>
>>> http://research.stlouisfed.org/fred2/series/CPIAUCSL/downloaddata/CPIAUCSL.csv
>>> '
>>>>
>>>> If I paste the URL in the error message into a browser it downloads the
>>>
>>> csv fine, so I think the url is ok.It also works ok for other sources,
>>> such
>>> as yahoo etc.
>>>
>>> The FRED http:// URLs now redirect to https://.  That causes issues
>>> with the default method for download.file on some platforms.  I'm
>>> aware of the issue and working on a fix.
>>>
>>> See the conversation on R-package-devel if you're interested in the
>>> details:
>>> https://stat.ethz.ch/pipermail/r-package-devel/2015q3/000193.html
>>>
>>>> Any insights would be appreciated.
>>>> Thanks,Alex
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions
>>>
>>> should go.
>>>
>>>
>>>
>>> --
>>> Joshua Ulrich  |  about.me/joshuaulrich
>>> FOSS Trading  |  www.fosstrading.com
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>>
>>
>>
>>
>



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From samuelcoltwilson at gmail.com  Mon Jul 27 18:23:56 2015
From: samuelcoltwilson at gmail.com (Samuel Wilson)
Date: Mon, 27 Jul 2015 09:23:56 -0700
Subject: [R-SIG-Finance] getquote function
Message-ID: <CACCk-cHi+pB57O9FtuQYjzUnMya5NtgJJZkv+rVqmMmHcPTHXA@mail.gmail.com>

Quick question,

Anyone else having trouble with getQuote function this morning (quantmod
library)?

Mine will not pull a current delayed quote, but is pulling last close.
Worked on Friday, but today not.  Before I spend time troubling shooting, I
want to figure out if anyone else is having this problem.

	[[alternative HTML version deleted]]


From gsee000 at gmail.com  Mon Jul 27 18:29:05 2015
From: gsee000 at gmail.com (G See)
Date: Mon, 27 Jul 2015 11:29:05 -0500
Subject: [R-SIG-Finance] getquote function
In-Reply-To: <CACCk-cHi+pB57O9FtuQYjzUnMya5NtgJJZkv+rVqmMmHcPTHXA@mail.gmail.com>
References: <CACCk-cHi+pB57O9FtuQYjzUnMya5NtgJJZkv+rVqmMmHcPTHXA@mail.gmail.com>
Message-ID: <CA+xi=qaKmMhH20UK8SHFv2uGc+C9mt3D7JCuq+37nbSAWba5og@mail.gmail.com>

Works for me, but it's not that unusual for different yahoo servers to
give different answers (which you don't have much control over).

getQuote("SPY", src="yahoo")
#             Trade Time   Last Change % Change   Open   High    Low   Volume
#SPY 2015-07-27 12:10:00 206.93  -1.07   -0.51% 206.94 207.55 206.26 54683280

#devtools::install_github("gsee/qmao")
suppressPackageStartupMessages(library(qmao))

getQuote("SPY", src="google")
#              TradeTime   Last Change PctChg Exchange GoogleID
#SPY 2015-07-27 12:27:00 207.01  -0.99  -0.48 NYSEARCA   700145

getQuote("SPY", src="bats", what="bbo")
#  TradeTime BidSize BidPrice AskPrice AskSize    Last LastSize row.names
#1  12:27:01    1965      207   207.01    3135 207.005       18       SPY

Garrett

On Mon, Jul 27, 2015 at 11:23 AM, Samuel Wilson
<samuelcoltwilson at gmail.com> wrote:
> Quick question,
>
> Anyone else having trouble with getQuote function this morning (quantmod
> library)?
>
> Mine will not pull a current delayed quote, but is pulling last close.
> Worked on Friday, but today not.  Before I spend time troubling shooting, I
> want to figure out if anyone else is having this problem.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From samuelcoltwilson at gmail.com  Mon Jul 27 18:56:59 2015
From: samuelcoltwilson at gmail.com (Samuel Wilson)
Date: Mon, 27 Jul 2015 09:56:59 -0700
Subject: [R-SIG-Finance] getquote function
In-Reply-To: <CA+xi=qaKmMhH20UK8SHFv2uGc+C9mt3D7JCuq+37nbSAWba5og@mail.gmail.com>
References: <CACCk-cHi+pB57O9FtuQYjzUnMya5NtgJJZkv+rVqmMmHcPTHXA@mail.gmail.com>
	<CA+xi=qaKmMhH20UK8SHFv2uGc+C9mt3D7JCuq+37nbSAWba5og@mail.gmail.com>
Message-ID: <CACCk-cGYqtHP5FiUcMagEKCOETgMvuEmkuXViE-d3Z6viWFw6g@mail.gmail.com>

Small follow up in-case anyone is interested, appears to be only on select
symbols (for example, XIV), I think the problem is at Yahoo's end....

> ticker<-c("IWM","XIV","SPY","TLT","EFA","^IXIC","ZIV")> getQuote(ticker)               Trade Time      Last   Change % Change    Open     High      Low   Volume
IWM   2015-07-27 12:41:00  120.7386  -0.8414 -0.6921%  121.13 121.3200
120.2700 17553725
XIV   2015-07-24 04:00:00   46.2000   0.0000   +0.00%   43.62      N/A
     N/A        0
SPY   2015-07-27 12:41:00  206.9500  -1.0500   -0.50%  206.94   207.55
  206.26 57283787
TLT   2015-07-27 12:41:00  121.6400   0.2500   +0.21%  122.19   122.29
  121.48  4531597
EFA   2015-07-27 12:41:00   63.5701  -0.3199 -0.5007%   63.74  63.7500
 63.5000  9169989
^IXIC 2015-07-27 12:55:00 5040.9500 -47.6800   -0.94% 5055.92  5072.88
 5033.31        0
ZIV   2015-07-24 04:00:00   48.7300   0.0000   +0.00%   47.85      N/A
     N/A        0



On Mon, Jul 27, 2015 at 9:29 AM, G See <gsee000 at gmail.com> wrote:

> Works for me, but it's not that unusual for different yahoo servers to
> give different answers (which you don't have much control over).
>
> getQuote("SPY", src="yahoo")
> #             Trade Time   Last Change % Change   Open   High    Low
>  Volume
> #SPY 2015-07-27 12:10:00 206.93  -1.07   -0.51% 206.94 207.55 206.26
> 54683280
>
> #devtools::install_github("gsee/qmao")
> suppressPackageStartupMessages(library(qmao))
>
> getQuote("SPY", src="google")
> #              TradeTime   Last Change PctChg Exchange GoogleID
> #SPY 2015-07-27 12:27:00 207.01  -0.99  -0.48 NYSEARCA   700145
>
> getQuote("SPY", src="bats", what="bbo")
> #  TradeTime BidSize BidPrice AskPrice AskSize    Last LastSize row.names
> #1  12:27:01    1965      207   207.01    3135 207.005       18       SPY
>
> Garrett
>
> On Mon, Jul 27, 2015 at 11:23 AM, Samuel Wilson
> <samuelcoltwilson at gmail.com> wrote:
> > Quick question,
> >
> > Anyone else having trouble with getQuote function this morning (quantmod
> > library)?
> >
> > Mine will not pull a current delayed quote, but is pulling last close.
> > Worked on Friday, but today not.  Before I spend time troubling
> shooting, I
> > want to figure out if anyone else is having this problem.
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From jerseyfanatic1 at gmail.com  Sat Aug  1 18:22:53 2015
From: jerseyfanatic1 at gmail.com (Jersey Fanatic)
Date: Sat, 1 Aug 2015 19:22:53 +0300
Subject: [R-SIG-Finance] Guy Yollin's apply.paramset() on Windows remark and
	related developments
Message-ID: <CAC_=oyO8qV-naDHNMxwWDriR0AB_Vh6oUhM5PQnqdPZ35oMrTA@mail.gmail.com>

Hi everyone,

Guy Yollin states in his Luxor slides the following:
"As of 2013-08-12, apply.paramset does not appear to run properly in
parallel on
Windows. To run on a Windows platform, load the doParallel package but do
not call
the registerDoParallel function; apply.paramset will then be able to run in
sequential
rather than parallel mode."

Is there any news on this topic, I cannot seem to find any info about
developments on this topic, is it fixed, or was another way found to do
parallel computing for apply.paramset()?

Note: I am running RStudio on Windows 7. apply.paramset() seems to work
when registerDoParallel() is not called, but the computing time is taking
too long for each combination of parameters.

Any help is appreciated. Thanks! :)

Koji Nakata

	[[alternative HTML version deleted]]


From erol.biceroglu at alumni.utoronto.ca  Sat Aug  1 21:11:54 2015
From: erol.biceroglu at alumni.utoronto.ca (Erol Biceroglu)
Date: Sat, 1 Aug 2015 15:11:54 -0400
Subject: [R-SIG-Finance] Guy Yollin's apply.paramset() on Windows remark
 and related developments
In-Reply-To: <CAC_=oyO8qV-naDHNMxwWDriR0AB_Vh6oUhM5PQnqdPZ35oMrTA@mail.gmail.com>
References: <CAC_=oyO8qV-naDHNMxwWDriR0AB_Vh6oUhM5PQnqdPZ35oMrTA@mail.gmail.com>
Message-ID: <CACjNfmkB_m-fOcC+JUJsQOYXt4VgWbB-RL57Ld8CQPUru1fMoQ@mail.gmail.com>

Hi,

To my knowledge, you (still) have to use a Unix based OS to run
apply.paramset in parallel.  It's possible to install Linux along side your
Windows OS without affecting anything.  I *suspect* the main issue is that
in an OS like Linux, you can "fork" (parallel processes share memory)
whereas in Windows you can't (each worker needs its own copy).

The bonus is, you'll have more RAM available to you if you were to run a
Linux OS, which can come in handy running apply.paramset.


Erol Biceroglu


*erol.biceroglu at alumni.utoronto.ca
<erol.biceroglu at alumni.utoronto.ca>416-275-7970*

On Sat, Aug 1, 2015 at 12:22 PM, Jersey Fanatic <jerseyfanatic1 at gmail.com>
wrote:

> Hi everyone,
>
> Guy Yollin states in his Luxor slides the following:
> "As of 2013-08-12, apply.paramset does not appear to run properly in
> parallel on
> Windows. To run on a Windows platform, load the doParallel package but do
> not call
> the registerDoParallel function; apply.paramset will then be able to run in
> sequential
> rather than parallel mode."
>
> Is there any news on this topic, I cannot seem to find any info about
> developments on this topic, is it fixed, or was another way found to do
> parallel computing for apply.paramset()?
>
> Note: I am running RStudio on Windows 7. apply.paramset() seems to work
> when registerDoParallel() is not called, but the computing time is taking
> too long for each combination of parameters.
>
> Any help is appreciated. Thanks! :)
>
> Koji Nakata
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Mon Aug  3 21:32:59 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 3 Aug 2015 14:32:59 -0500
Subject: [R-SIG-Finance] Guy Yollin's apply.paramset() on Windows remark
 and related developments
In-Reply-To: <CAC_=oyO8qV-naDHNMxwWDriR0AB_Vh6oUhM5PQnqdPZ35oMrTA@mail.gmail.com>
References: <CAC_=oyO8qV-naDHNMxwWDriR0AB_Vh6oUhM5PQnqdPZ35oMrTA@mail.gmail.com>
Message-ID: <CAPPM_gSA-d_q_ouoCTd6f8n3Sid1nq8KdUR5inTXicaAbH6T2A@mail.gmail.com>

On Sat, Aug 1, 2015 at 11:22 AM, Jersey Fanatic
<jerseyfanatic1 at gmail.com> wrote:
> Hi everyone,
>
> Guy Yollin states in his Luxor slides the following:
> "As of 2013-08-12, apply.paramset does not appear to run properly in
> parallel on
> Windows. To run on a Windows platform, load the doParallel package but do
> not call
> the registerDoParallel function; apply.paramset will then be able to run in
> sequential
> rather than parallel mode."
>
> Is there any news on this topic, I cannot seem to find any info about
> developments on this topic, is it fixed, or was another way found to do
> parallel computing for apply.paramset()?
>
No, it's not fixed, as the main package authors try to avoid using
Windows whenever possible.  Someone with interest and inclination
would need to submit patches to allow apply.paramset to work with
doParallel on Windows.

That said, others have had success running in parallel on Windows
using the doRedis backend.  For those interested/inclined, that may be
a good place to start the attempt to get apply.paramset working with
doParallel on Windows.

> Note: I am running RStudio on Windows 7. apply.paramset() seems to work
> when registerDoParallel() is not called, but the computing time is taking
> too long for each combination of parameters.
>
> Any help is appreciated. Thanks! :)
>
> Koji Nakata
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From aaron at quantrisktrading.com  Tue Aug  4 01:48:47 2015
From: aaron at quantrisktrading.com (Aaron Goldenberg)
Date: Mon, 3 Aug 2015 19:48:47 -0400
Subject: [R-SIG-Finance] aggregate an xts by factors
Message-ID: <CAG7y0grCoiXz1dzdtN0BupyB=uV5OLmNYEbYv=ta4JXOEcLKAg@mail.gmail.com>

This seems like a simple issue but I cannot get it to work for some reason.
I have a time series object that has daily returns of several stocks that I
would like to aggregate by qualitative factor.  In my toy example, for each
day, I would like to have two entries, one for the sum of the returns of my
two computer stocks and another for my financial stock. Then I would like
to calculate the cumulative sum of the returns for each factor. What am I
not doing correctly?

library(quantmod)
getSymbols("AAPL", src="yahoo", from="2015-07-01")
AAPL <- dailyReturn(AAPL$AAPL.Adjusted)
AAPL <- cbind(data.frame(AAPL), sector="Computer")
AAPL <- as.xts(AAPL)
getSymbols("GOOG", src="yahoo", from="2015-07-01")
GOOG <- dailyReturn(GOOG$GOOG.Adjusted)
GOOG <- cbind(data.frame(GOOG), sector="Computer")
GOOG <- as.xts(GOOG)
getSymbols("GS", src="yahoo", from="2015-07-01")
GS <- dailyReturn(GS$GS.Adjusted)
GS <- cbind(data.frame(GS), sector="Financial")
GS <- as.xts(GS)
combined <- rbind(AAPL, GOOG, GS)
#combined <- period.sum(combined$daily.returns, endpoints(combined,
on="days"))
combined <- aggregate(combined, by=combined$sector, sum)

	[[alternative HTML version deleted]]


From aaron at quantrisktrading.com  Tue Aug  4 01:51:08 2015
From: aaron at quantrisktrading.com (Aaron Goldenberg)
Date: Mon, 3 Aug 2015 19:51:08 -0400
Subject: [R-SIG-Finance] aggregate an xts by factors
In-Reply-To: <CAG7y0grCoiXz1dzdtN0BupyB=uV5OLmNYEbYv=ta4JXOEcLKAg@mail.gmail.com>
References: <CAG7y0grCoiXz1dzdtN0BupyB=uV5OLmNYEbYv=ta4JXOEcLKAg@mail.gmail.com>
Message-ID: <CAG7y0gonZfsPx-m+9m=dq37V=0X2axwjYiBa0iZ7vMaC_pPBYw@mail.gmail.com>

Alternatively, I could have two separate time series, one for each factor.

On Mon, Aug 3, 2015 at 7:48 PM, Aaron Goldenberg <aaron at quantrisktrading.com
> wrote:

> This seems like a simple issue but I cannot get it to work for some
> reason. I have a time series object that has daily returns of several
> stocks that I would like to aggregate by qualitative factor.  In my toy
> example, for each day, I would like to have two entries, one for the sum of
> the returns of my two computer stocks and another for my financial stock.
> Then I would like to calculate the cumulative sum of the returns for each
> factor. What am I not doing correctly?
>
> library(quantmod)
> getSymbols("AAPL", src="yahoo", from="2015-07-01")
> AAPL <- dailyReturn(AAPL$AAPL.Adjusted)
> AAPL <- cbind(data.frame(AAPL), sector="Computer")
> AAPL <- as.xts(AAPL)
> getSymbols("GOOG", src="yahoo", from="2015-07-01")
> GOOG <- dailyReturn(GOOG$GOOG.Adjusted)
> GOOG <- cbind(data.frame(GOOG), sector="Computer")
> GOOG <- as.xts(GOOG)
> getSymbols("GS", src="yahoo", from="2015-07-01")
> GS <- dailyReturn(GS$GS.Adjusted)
> GS <- cbind(data.frame(GS), sector="Financial")
> GS <- as.xts(GS)
> combined <- rbind(AAPL, GOOG, GS)
> #combined <- period.sum(combined$daily.returns, endpoints(combined,
> on="days"))
> combined <- aggregate(combined, by=combined$sector, sum)
>
>
>
>

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Tue Aug  4 19:06:51 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 4 Aug 2015 12:06:51 -0500
Subject: [R-SIG-Finance] aggregate an xts by factors
In-Reply-To: <CAG7y0gonZfsPx-m+9m=dq37V=0X2axwjYiBa0iZ7vMaC_pPBYw@mail.gmail.com>
References: <CAG7y0grCoiXz1dzdtN0BupyB=uV5OLmNYEbYv=ta4JXOEcLKAg@mail.gmail.com>
	<CAG7y0gonZfsPx-m+9m=dq37V=0X2axwjYiBa0iZ7vMaC_pPBYw@mail.gmail.com>
Message-ID: <CAPPM_gQrBxU_9wgZC8Fx+ysMLOb_HOvPO40e9qDbEq0Y+MX4_w@mail.gmail.com>

On Mon, Aug 3, 2015 at 6:51 PM, Aaron Goldenberg
<aaron at quantrisktrading.com> wrote:
> Alternatively, I could have two separate time series, one for each factor.
>
> On Mon, Aug 3, 2015 at 7:48 PM, Aaron Goldenberg <aaron at quantrisktrading.com
>> wrote:
>
>> This seems like a simple issue but I cannot get it to work for some
>> reason. I have a time series object that has daily returns of several
>> stocks that I would like to aggregate by qualitative factor.  In my toy
>> example, for each day, I would like to have two entries, one for the sum of
>> the returns of my two computer stocks and another for my financial stock.
>> Then I would like to calculate the cumulative sum of the returns for each
>> factor. What am I not doing correctly?
>>
>> library(quantmod)
>> getSymbols("AAPL", src="yahoo", from="2015-07-01")
>> AAPL <- dailyReturn(AAPL$AAPL.Adjusted)
>> AAPL <- cbind(data.frame(AAPL), sector="Computer")
>> AAPL <- as.xts(AAPL)
>> getSymbols("GOOG", src="yahoo", from="2015-07-01")
>> GOOG <- dailyReturn(GOOG$GOOG.Adjusted)
>> GOOG <- cbind(data.frame(GOOG), sector="Computer")
>> GOOG <- as.xts(GOOG)
>> getSymbols("GS", src="yahoo", from="2015-07-01")
>> GS <- dailyReturn(GS$GS.Adjusted)
>> GS <- cbind(data.frame(GS), sector="Financial")
>> GS <- as.xts(GS)
>> combined <- rbind(AAPL, GOOG, GS)
>> #combined <- period.sum(combined$daily.returns, endpoints(combined,
>> on="days"))
>> combined <- aggregate(combined, by=combined$sector, sum)
>>
The problem is that you're trying to mix types in the xts data.  xts
extends zoo, which is simply a matrix with an index attribute, and you
can't mix types in a matrix.

There are many different ways to do this.  Here's one way that should
be easily extensible to more sectors.

library(quantmod)
Computer <- new.env()
Financial <- new.env()
getSymbols("AAPL;GOOG", from="2015-07-01", env=Computer)
getSymbols("GS", from="2015-07-01", env=Financial)

sectorReturnSum <- function(env) {
  adj <- do.call(cbind, eapply(env, Ad))
  ret <- ROC(adj, type="discrete")
  xts(rowSums(ret, na.rm=TRUE), index(ret))
}
combined <- merge(Computer = sectorReturnSum(Computer),
  Financial = sectorReturnSum(Financial))

>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From ransomedbyfire at gmail.com  Tue Aug  4 19:50:27 2015
From: ransomedbyfire at gmail.com (Laura Rogers)
Date: Tue, 4 Aug 2015 13:50:27 -0400
Subject: [R-SIG-Finance] Fwd: RBloomberg EMA Calculation
In-Reply-To: <CAJJKKFB8t1ypnUbjnxu8qYD40=yN8cN8u98so7Bmafs2+Gn3rQ@mail.gmail.com>
References: <CAJJKKFB8t1ypnUbjnxu8qYD40=yN8cN8u98so7Bmafs2+Gn3rQ@mail.gmail.com>
Message-ID: <CAJJKKFCyp8wgB2=v6YvytObZpYjQeRpNN2FL8gO4+SoDhFOtHg@mail.gmail.com>

Hello.
I am trying to figure out what exactly the formula below does. It's
supposed to be an exponential moving average, but it does not equal any of
the other EMA values I've seen elsewhere, such as Yahoo! Finance or
anything I've ever seen manually calculated in a spreadsheet. Could someone
please help me figure out what exactly this is calculating? Thanks!

=BTH("QQQ","EMAVG","7/10/15","7/10/15","EMAVG","TAPeriod=30","DSClose=PX_LAST","Dir=V","Dts=H","Sort=A","QtTyp=P","Days=T","Per=cd","UseDPDF=N",
"CshAdjNormal=Y","CshAdjAbnormal=Y","CapChg=Y")

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Tue Aug  4 20:01:09 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 4 Aug 2015 13:01:09 -0500
Subject: [R-SIG-Finance] Fwd: RBloomberg EMA Calculation
In-Reply-To: <CAJJKKFCyp8wgB2=v6YvytObZpYjQeRpNN2FL8gO4+SoDhFOtHg@mail.gmail.com>
References: <CAJJKKFB8t1ypnUbjnxu8qYD40=yN8cN8u98so7Bmafs2+Gn3rQ@mail.gmail.com>
	<CAJJKKFCyp8wgB2=v6YvytObZpYjQeRpNN2FL8gO4+SoDhFOtHg@mail.gmail.com>
Message-ID: <CAPPM_gTm2F1Dx=nrG0F4mXMJPWp5EDnGHr9z=2=+KF7T2UHHaQ@mail.gmail.com>

On Tue, Aug 4, 2015 at 12:50 PM, Laura Rogers <ransomedbyfire at gmail.com> wrote:
> Hello.
> I am trying to figure out what exactly the formula below does. It's
> supposed to be an exponential moving average, but it does not equal any of
> the other EMA values I've seen elsewhere, such as Yahoo! Finance or
> anything I've ever seen manually calculated in a spreadsheet. Could someone
> please help me figure out what exactly this is calculating? Thanks!
>
This isn't the appropriate forum for your question, since this has
nothing to do with R.  Perhaps ask your Bloomberg representative for
some pointers?

It's also polite to mention that you've cross-posted elsewhere:
http://quant.stackexchange.com/q/18630/56

> =BTH("QQQ","EMAVG","7/10/15","7/10/15","EMAVG","TAPeriod=30","DSClose=PX_LAST","Dir=V","Dts=H","Sort=A","QtTyp=P","Days=T","Per=cd","UseDPDF=N",
> "CshAdjNormal=Y","CshAdjAbnormal=Y","CapChg=Y")
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From armstrong.whit at gmail.com  Tue Aug  4 20:01:07 2015
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Tue, 4 Aug 2015 14:01:07 -0400
Subject: [R-SIG-Finance] Fwd: RBloomberg EMA Calculation
In-Reply-To: <CAJJKKFCyp8wgB2=v6YvytObZpYjQeRpNN2FL8gO4+SoDhFOtHg@mail.gmail.com>
References: <CAJJKKFB8t1ypnUbjnxu8qYD40=yN8cN8u98so7Bmafs2+Gn3rQ@mail.gmail.com>
	<CAJJKKFCyp8wgB2=v6YvytObZpYjQeRpNN2FL8gO4+SoDhFOtHg@mail.gmail.com>
Message-ID: <CAMi=pg6zdTr5=5fvv+aMfLyRGHpaX3JHkAhKLJOXbBMTQ-MJcg@mail.gmail.com>

If you are a bbg subscriber, then why not ask the help desk?  They are
typically very responsive to requests like this...


On Tue, Aug 4, 2015 at 1:50 PM, Laura Rogers <ransomedbyfire at gmail.com>
wrote:

> Hello.
> I am trying to figure out what exactly the formula below does. It's
> supposed to be an exponential moving average, but it does not equal any of
> the other EMA values I've seen elsewhere, such as Yahoo! Finance or
> anything I've ever seen manually calculated in a spreadsheet. Could someone
> please help me figure out what exactly this is calculating? Thanks!
>
>
> =BTH("QQQ","EMAVG","7/10/15","7/10/15","EMAVG","TAPeriod=30","DSClose=PX_LAST","Dir=V","Dts=H","Sort=A","QtTyp=P","Days=T","Per=cd","UseDPDF=N",
> "CshAdjNormal=Y","CshAdjAbnormal=Y","CapChg=Y")
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From ntobiaskramer at gmail.com  Tue Aug  4 20:34:45 2015
From: ntobiaskramer at gmail.com (Nils Tobias Kramer)
Date: Tue, 4 Aug 2015 20:34:45 +0200
Subject: [R-SIG-Finance] Fwd: RBloomberg EMA Calculation
In-Reply-To: <CAMi=pg6zdTr5=5fvv+aMfLyRGHpaX3JHkAhKLJOXbBMTQ-MJcg@mail.gmail.com>
References: <CAJJKKFB8t1ypnUbjnxu8qYD40=yN8cN8u98so7Bmafs2+Gn3rQ@mail.gmail.com>
	<CAJJKKFCyp8wgB2=v6YvytObZpYjQeRpNN2FL8gO4+SoDhFOtHg@mail.gmail.com>
	<CAMi=pg6zdTr5=5fvv+aMfLyRGHpaX3JHkAhKLJOXbBMTQ-MJcg@mail.gmail.com>
Message-ID: <C89DB5B5-B224-4ECE-9483-36CE08A9B00C@gmail.com>

If you have the bloomberg api (the excel addin) running you can press this little fx symbol left of the formular. This will explain every single parameter and also all the options you got for those parameters.

I usually use BDH and BDP, haven't tried with BTH but pretty sure this should be the same.

Toby

> On 04.08.2015, at 20:01, Whit Armstrong <armstrong.whit at gmail.com> wrote:
> 
> If you are a bbg subscriber, then why not ask the help desk?  They are
> typically very responsive to requests like this...
> 
> 
> On Tue, Aug 4, 2015 at 1:50 PM, Laura Rogers <ransomedbyfire at gmail.com>
> wrote:
> 
>> Hello.
>> I am trying to figure out what exactly the formula below does. It's
>> supposed to be an exponential moving average, but it does not equal any of
>> the other EMA values I've seen elsewhere, such as Yahoo! Finance or
>> anything I've ever seen manually calculated in a spreadsheet. Could someone
>> please help me figure out what exactly this is calculating? Thanks!
>> 
>> 
>> =BTH("QQQ","EMAVG","7/10/15","7/10/15","EMAVG","TAPeriod=30","DSClose=PX_LAST","Dir=V","Dts=H","Sort=A","QtTyp=P","Days=T","Per=cd","UseDPDF=N",
>> "CshAdjNormal=Y","CshAdjAbnormal=Y","CapChg=Y")
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From gambulator at gmail.com  Wed Aug  5 03:26:28 2015
From: gambulator at gmail.com (Gambulator Gambulator)
Date: Tue, 4 Aug 2015 18:26:28 -0700
Subject: [R-SIG-Finance] how to use all the cumulative equities in the
	account to buy
Message-ID: <CAFSUCtsriNX4Drgh7E-KA1mQTFEaj2cVvymmo3u_hPE7MyaXeg@mail.gmail.com>

Say I am trading SPY and started with 100k. I would like to have my first
trade to buy whatever number of shares SPY I can buy. Then let's say I made
money and my account now has 200k, I want my next trade to use 200k and buy
whatever SPY I can buy and if I lose money then I would use whatever the
leftover is to do the next trade.

I see people talking about using the rebalance function to do that and then
I see people mentioning percentRisk function but I can't quite figure out
how to call these functions properly. Perhaps they are for portfolio with
more than 1 stock and requires asset allocation type of rebalancing.

Is there an out of the box function that would buy using my current equity
? If not, anyone has a custom one that I can use ? After doing some
googling, some people suggest that we can just add the P&L to the initial
capital and figure out the current equity. Is that the way to go ?

	[[alternative HTML version deleted]]


From gambulator at gmail.com  Wed Aug  5 07:34:12 2015
From: gambulator at gmail.com (Gambulator Gambulator)
Date: Tue, 4 Aug 2015 22:34:12 -0700
Subject: [R-SIG-Finance] how to use all the cumulative equities in the
	account to buy
In-Reply-To: <CAFSUCtsriNX4Drgh7E-KA1mQTFEaj2cVvymmo3u_hPE7MyaXeg@mail.gmail.com>
References: <CAFSUCtsriNX4Drgh7E-KA1mQTFEaj2cVvymmo3u_hPE7MyaXeg@mail.gmail.com>
Message-ID: <CAFSUCtvqzUaVsn9JSaW_riVR2aCav-Ek63wYuPcwKyt9xvcRRQ@mail.gmail.com>

I did this and it seems to work fine.

osMaxEquity <- function(timestamp, orderqty, portfolio, symbol, ruletype,
...)
{
  updatePortf(portfolio, symbol,
Dates=paste('::',as.Date(timestamp),sep=''))
  Posn = getPosQty(portfolio, symbol, timestamp)
  if (Posn!=0){
   orderqty=0
   return (orderqty)
  }
  cumPL <- sum(getPortfolio(portfolio)$symbols[[symbol]]$posPL$
Net.Trading.PL)
  totalEquity=initEq+cumPL
  closePrice <- as.numeric(Cl(mktdata[timestamp,]))
  orderqty=totalEquity/closePrice
  print(orderqty)
  return(orderqty)
}


I don't know why print does not print anything out though

On Tue, Aug 4, 2015 at 6:26 PM, Gambulator Gambulator <gambulator at gmail.com>
wrote:

> Say I am trading SPY and started with 100k. I would like to have my first
> trade to buy whatever number of shares SPY I can buy. Then let's say I made
> money and my account now has 200k, I want my next trade to use 200k and buy
> whatever SPY I can buy and if I lose money then I would use whatever the
> leftover is to do the next trade.
>
> I see people talking about using the rebalance function to do that and
> then I see people mentioning percentRisk function but I can't quite figure
> out how to call these functions properly. Perhaps they are for portfolio
> with more than 1 stock and requires asset allocation type of rebalancing.
>
> Is there an out of the box function that would buy using my current equity
> ? If not, anyone has a custom one that I can use ? After doing some
> googling, some people suggest that we can just add the P&L to the initial
> capital and figure out the current equity. Is that the way to go ?
>

	[[alternative HTML version deleted]]


From gambulator at gmail.com  Wed Aug  5 09:04:32 2015
From: gambulator at gmail.com (Gambulator Gambulator)
Date: Wed, 5 Aug 2015 00:04:32 -0700
Subject: [R-SIG-Finance] (DSTrading) and (IKTrading) are not available on R
	version 3.2.1
Message-ID: <CAFSUCtu-NnjYrA54BfnwL-AHqjVTA7Wxg7XA0_9wq1fmZpFsdg@mail.gmail.com>

 package ?https://github.com/IlyaKipnis/DSTrading.git? is not available
(for R version 3.2.1)

Do I need to just downgrade my R or there are easy way to get around this?

	[[alternative HTML version deleted]]


From brian at braverock.com  Wed Aug  5 11:39:30 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 05 Aug 2015 04:39:30 -0500
Subject: [R-SIG-Finance] (DSTrading) and (IKTrading) are not available
 on R version 3.2.1
In-Reply-To: <CAFSUCtu-NnjYrA54BfnwL-AHqjVTA7Wxg7XA0_9wq1fmZpFsdg@mail.gmail.com>
References: <CAFSUCtu-NnjYrA54BfnwL-AHqjVTA7Wxg7XA0_9wq1fmZpFsdg@mail.gmail.com>
Message-ID: <55C1D9D2.9020005@braverock.com>

On 08/05/2015 02:04 AM, Gambulator Gambulator wrote:
>   package ?https://github.com/IlyaKipnis/DSTrading.git? is not available
> (for R version 3.2.1)
>
> Do I need to just downgrade my R or there are easy way to get around this?

IKTrading and DSTrading are only available on github.  you need to have 
devtools (and probably Rtools as well if you're running Windows) and use 
install_github to install them

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From ntobiaskramer at gmail.com  Wed Aug  5 13:11:43 2015
From: ntobiaskramer at gmail.com (Nils Tobias Kramer)
Date: Wed, 5 Aug 2015 13:11:43 +0200
Subject: [R-SIG-Finance] Fwd: RBloomberg EMA Calculation
In-Reply-To: <CAJJKKFAe+11ZiuJk+2DaR-atnOkh0xx9iJu6RzpGvcpaNtD=Fw@mail.gmail.com>
References: <CAJJKKFB8t1ypnUbjnxu8qYD40=yN8cN8u98so7Bmafs2+Gn3rQ@mail.gmail.com>
	<CAJJKKFCyp8wgB2=v6YvytObZpYjQeRpNN2FL8gO4+SoDhFOtHg@mail.gmail.com>
	<CAMi=pg6zdTr5=5fvv+aMfLyRGHpaX3JHkAhKLJOXbBMTQ-MJcg@mail.gmail.com>
	<C89DB5B5-B224-4ECE-9483-36CE08A9B00C@gmail.com>
	<CAJJKKFAe+11ZiuJk+2DaR-atnOkh0xx9iJu6RzpGvcpaNtD=Fw@mail.gmail.com>
Message-ID: <AC01F7CD-9D33-43E3-A001-967623573011@gmail.com>

BTH: Bloomberg Technical Analysis Function
QQQ: Security 
EMAVG: Field and Study of your request, exponential moving average
"7/10/15": Startdate and Enddate
TAPeriod: number of days for average
DSClose: specifies intraday field, so you take the closing prices
Dir: direction data is returned to Excel
Dts: dates are hidden
Sort: ascending dates
Days: t for trading days
Per: periodicity, so cd for daily
UseDPDF: follows DPDF settings
CshAdjNormal: adjust historical pricing to refelect some normal items, e.g. regular cash
CshAdjAbnormal: adjust historical pricing to refelect some non normal items, e.g. capital gains
CapChg: adjust prices for corporate actions, like spin offs

Toby

> On 04.08.2015, at 20:44, Laura Rogers <ransomedbyfire at gmail.com> wrote:
> 
> Unfortunately, I don't have Bloomberg myself. But thanks for the info!
> 
>> On Tue, Aug 4, 2015 at 2:34 PM, Nils Tobias Kramer <ntobiaskramer at gmail.com> wrote:
>> If you have the bloomberg api (the excel addin) running you can press this little fx symbol left of the formular. This will explain every single parameter and also all the options you got for those parameters.
>> 
>> I usually use BDH and BDP, haven't tried with BTH but pretty sure this should be the same.
>> 
>> Toby
>> 
>> > On 04.08.2015, at 20:01, Whit Armstrong <armstrong.whit at gmail.com> wrote:
>> >
>> > If you are a bbg subscriber, then why not ask the help desk?  They are
>> > typically very responsive to requests like this...
>> >
>> >
>> > On Tue, Aug 4, 2015 at 1:50 PM, Laura Rogers <ransomedbyfire at gmail.com>
>> > wrote:
>> >
>> >> Hello.
>> >> I am trying to figure out what exactly the formula below does. It's
>> >> supposed to be an exponential moving average, but it does not equal any of
>> >> the other EMA values I've seen elsewhere, such as Yahoo! Finance or
>> >> anything I've ever seen manually calculated in a spreadsheet. Could someone
>> >> please help me figure out what exactly this is calculating? Thanks!
>> >>
>> >>
>> >> =BTH("QQQ","EMAVG","7/10/15","7/10/15","EMAVG","TAPeriod=30","DSClose=PX_LAST","Dir=V","Dts=H","Sort=A","QtTyp=P","Days=T","Per=cd","UseDPDF=N",
>> >> "CshAdjNormal=Y","CshAdjAbnormal=Y","CapChg=Y")
>> >>
>> >>        [[alternative HTML version deleted]]
>> >>
>> >> _______________________________________________
>> >> R-SIG-Finance at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> >> -- Subscriber-posting only. If you want to post, subscribe first.
>> >> -- Also note that this is not the r-help list where general R questions
>> >> should go.
>> >
>> >    [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only. If you want to post, subscribe first.
>> > -- Also note that this is not the r-help list where general R questions should go.
> 

	[[alternative HTML version deleted]]


From ntobiaskramer at gmail.com  Wed Aug  5 19:07:11 2015
From: ntobiaskramer at gmail.com (Nils Tobias Kramer)
Date: Wed, 5 Aug 2015 19:07:11 +0200
Subject: [R-SIG-Finance] Fwd: RBloomberg EMA Calculation
In-Reply-To: <CAJJKKFAczZ-a4=Do4iMpH-hjcp5up8_=c6sKk6oa4tjTHzQwEA@mail.gmail.com>
References: <CAJJKKFB8t1ypnUbjnxu8qYD40=yN8cN8u98so7Bmafs2+Gn3rQ@mail.gmail.com>
	<CAJJKKFCyp8wgB2=v6YvytObZpYjQeRpNN2FL8gO4+SoDhFOtHg@mail.gmail.com>
	<CAMi=pg6zdTr5=5fvv+aMfLyRGHpaX3JHkAhKLJOXbBMTQ-MJcg@mail.gmail.com>
	<C89DB5B5-B224-4ECE-9483-36CE08A9B00C@gmail.com>
	<CAJJKKFAe+11ZiuJk+2DaR-atnOkh0xx9iJu6RzpGvcpaNtD=Fw@mail.gmail.com>
	<AC01F7CD-9D33-43E3-A001-967623573011@gmail.com>
	<CAJJKKFAczZ-a4=Do4iMpH-hjcp5up8_=c6sKk6oa4tjTHzQwEA@mail.gmail.com>
Message-ID: <B3EEF4C6-ADA5-4FD9-89E1-488FA390E329@gmail.com>

I don't use this function sorry.

> On 05.08.2015, at 18:39, Laura Rogers <ransomedbyfire at gmail.com> wrote:
> 
> Thank you so much for this info! It sounds like this value should, in theory, match Yahoo Finance's historical adjusted prices (and just about everyone else's). But it doesn't. Do you suppose the discrepancy could be because the two sources aren't adjusting for exactly the same things? Or is there some other factor I'm not considering?
> 
> Thanks!
> 
>> On Wed, Aug 5, 2015 at 7:11 AM, Nils Tobias Kramer <ntobiaskramer at gmail.com> wrote:
>> BTH: Bloomberg Technical Analysis Function
>> QQQ: Security 
>> EMAVG: Field and Study of your request, exponential moving average
>> "7/10/15": Startdate and Enddate
>> TAPeriod: number of days for average
>> DSClose: specifies intraday field, so you take the closing prices
>> Dir: direction data is returned to Excel
>> Dts: dates are hidden
>> Sort: ascending dates
>> Days: t for trading days
>> Per: periodicity, so cd for daily
>> UseDPDF: follows DPDF settings
>> CshAdjNormal: adjust historical pricing to refelect some normal items, e.g. regular cash
>> CshAdjAbnormal: adjust historical pricing to refelect some non normal items, e.g. capital gains
>> CapChg: adjust prices for corporate actions, like spin offs
>> 
>> Toby
>> 
>>> On 04.08.2015, at 20:44, Laura Rogers <ransomedbyfire at gmail.com> wrote:
>>> 
>>> Unfortunately, I don't have Bloomberg myself. But thanks for the info!
>>> 
>>>> On Tue, Aug 4, 2015 at 2:34 PM, Nils Tobias Kramer <ntobiaskramer at gmail.com> wrote:
>>>> If you have the bloomberg api (the excel addin) running you can press this little fx symbol left of the formular. This will explain every single parameter and also all the options you got for those parameters.
>>>> 
>>>> I usually use BDH and BDP, haven't tried with BTH but pretty sure this should be the same.
>>>> 
>>>> Toby
>>>> 
>>>> > On 04.08.2015, at 20:01, Whit Armstrong <armstrong.whit at gmail.com> wrote:
>>>> >
>>>> > If you are a bbg subscriber, then why not ask the help desk?  They are
>>>> > typically very responsive to requests like this...
>>>> >
>>>> >
>>>> > On Tue, Aug 4, 2015 at 1:50 PM, Laura Rogers <ransomedbyfire at gmail.com>
>>>> > wrote:
>>>> >
>>>> >> Hello.
>>>> >> I am trying to figure out what exactly the formula below does. It's
>>>> >> supposed to be an exponential moving average, but it does not equal any of
>>>> >> the other EMA values I've seen elsewhere, such as Yahoo! Finance or
>>>> >> anything I've ever seen manually calculated in a spreadsheet. Could someone
>>>> >> please help me figure out what exactly this is calculating? Thanks!
>>>> >>
>>>> >>
>>>> >> =BTH("QQQ","EMAVG","7/10/15","7/10/15","EMAVG","TAPeriod=30","DSClose=PX_LAST","Dir=V","Dts=H","Sort=A","QtTyp=P","Days=T","Per=cd","UseDPDF=N",
>>>> >> "CshAdjNormal=Y","CshAdjAbnormal=Y","CapChg=Y")
>>>> >>
>>>> >>        [[alternative HTML version deleted]]
>>>> >>
>>>> >> _______________________________________________
>>>> >> R-SIG-Finance at r-project.org mailing list
>>>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> >> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> >> -- Also note that this is not the r-help list where general R questions
>>>> >> should go.
>>>> >
>>>> >    [[alternative HTML version deleted]]
>>>> >
>>>> > _______________________________________________
>>>> > R-SIG-Finance at r-project.org mailing list
>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> > -- Subscriber-posting only. If you want to post, subscribe first.
>>>> > -- Also note that this is not the r-help list where general R questions should go.
>>> 
> 

	[[alternative HTML version deleted]]


From shawkat.hammoudeh at yahoo.com  Mon Aug 10 03:56:43 2015
From: shawkat.hammoudeh at yahoo.com (Shawkat Hammoudeh)
Date: Mon, 10 Aug 2015 01:56:43 +0000 (UTC)
Subject: [R-SIG-Finance] (no subject)
Message-ID: <1631368273.968976.1439171803208.JavaMail.yahoo@mail.yahoo.com>

?Thanks.Shawkat Hammoudeh, Ph.D.Associate Editor, Energy Economics
Associate Editor, Global Review of Business and EconomicsAssociate Editor, Brazilian Journal of Business Economics
Associate Editor, Global Review of Business and Economics ResearchGuest-Editor, International Review of Economics and FinanceGuest-editor, North American Journal of Economics and FinanceProfessor of Economics and International Business
College of Business, 
Drexel University Philadelphia, PA 19104
Tel : 610-949-0133 Fax : 215-895-6975
http://www.lebow.drexel.edu/hammoudeh
http://blogs.zawya.com/shawkat.hammoudeh/
http://www.thereviewme.com/author/shawkat-hammoudeh/
http://ssrn.com/author=399139
http://authors.repec.org/menu!03d68dfe
View my research on my SSRN Author page: 
http://ssrn.com/author=399139
	[[alternative HTML version deleted]]


From mcewan.gareth at gmail.com  Tue Aug 11 11:33:03 2015
From: mcewan.gareth at gmail.com (Gareth McEwan)
Date: Tue, 11 Aug 2015 11:33:03 +0200
Subject: [R-SIG-Finance] Demean or not to demean
Message-ID: <CALGfFMadvasuLL7Y+JpkZRRyaaqe7g2RnUb8mWaXQnqXRGDXzw@mail.gmail.com>

Hi all

I was hoping someone could shed light or direct me to a resource (or two)
regarding a "demean" question.

As I understand, QMLEs estimated on "demeaned" log return data vs straight
"log return" data behave quite differently in finite samples (particularly
for nonlinear MA models where the MA parameter is of interest). Apparently,
for linear AR models, demeaning data does not seriously affect estimation
of non-intercept parameters (refer: Yong Bao "Should We Demean Data?").

For monthly financial log return data, I find ARMA specifications are not
significant, but some sample *means *ARE significant, while others are not.
In either case, I add the GARCH model specification with various error
distributions from the "rugarch" package.

Code example:
x.log.ret = diff(log(price.x) #i.e. not "demeaned"
spec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1),
            submodel=NULL,external.regressors=NULL,variance.targeting=F),
            mean.model=list(*armaOrder = c(0,0)*,* include.mean = T*,
external.regressors=NULL),
            distribution.model="std")
tempgarch <- ugarchfit(spec=spec,data=x.log.ret,solver="hybrid")

I work through the steps necessary to fitting a *t*Copula from which to
simulate and ultimately work my way back to simulated returns.

The goal here is to extract from the matrix of simulated returns those
groups of returns coinciding with certain pre-determined "scenarios". These
are then used for portfolio optimization.

In the "global respect" of the methodology, can anyone shed light on the
merits/demerits of not first demeaning the data? I haven't found any
glaring problems, but it bothers me that the "rugarch" package operates on
demeaned data.

Thank you very much for the help
Gareth

	[[alternative HTML version deleted]]


From alexios at 4dscape.com  Tue Aug 11 12:02:00 2015
From: alexios at 4dscape.com (alexios)
Date: Tue, 11 Aug 2015 11:02:00 +0100
Subject: [R-SIG-Finance] Demean or not to demean
In-Reply-To: <CALGfFMadvasuLL7Y+JpkZRRyaaqe7g2RnUb8mWaXQnqXRGDXzw@mail.gmail.com>
References: <CALGfFMadvasuLL7Y+JpkZRRyaaqe7g2RnUb8mWaXQnqXRGDXzw@mail.gmail.com>
Message-ID: <55C9C818.8020809@4dscape.com>

On 11/08/2015 10:33, Gareth McEwan wrote:
> Hi all
>
> I was hoping someone could shed light or direct me to a resource (or two)
> regarding a "demean" question.
>
> As I understand, QMLEs estimated on "demeaned" log return data vs straight
> "log return" data behave quite differently in finite samples (particularly
> for nonlinear MA models where the MA parameter is of interest). Apparently,
> for linear AR models, demeaning data does not seriously affect estimation
> of non-intercept parameters (refer: Yong Bao "Should We Demean Data?").
>
> For monthly financial log return data, I find ARMA specifications are not
> significant, but some sample *means *ARE significant, while others are not.
> In either case, I add the GARCH model specification with various error
> distributions from the "rugarch" package.
>
> Code example:
> x.log.ret = diff(log(price.x) #i.e. not "demeaned"
> spec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1),
>              submodel=NULL,external.regressors=NULL,variance.targeting=F),
>              mean.model=list(*armaOrder = c(0,0)*,* include.mean = T*,
> external.regressors=NULL),
>              distribution.model="std")
> tempgarch <- ugarchfit(spec=spec,data=x.log.ret,solver="hybrid")
>
> I work through the steps necessary to fitting a *t*Copula from which to
> simulate and ultimately work my way back to simulated returns.
>
> The goal here is to extract from the matrix of simulated returns those
> groups of returns coinciding with certain pre-determined "scenarios". These
> are then used for portfolio optimization.
>
> In the "global respect" of the methodology, can anyone shed light on the
> merits/demerits of not first demeaning the data? I haven't found any
> glaring problems, but it bothers me that the "rugarch" package operates on
> demeaned data.

The rugarch package does NOT operate on demeaned data. It offers the 
option (default=TRUE) through "include.mean" on whether to demean the 
data or not. In case you are not demeaning, then the data are passed 
straight to the GARCH routine and assumed as the zero-mean residuals.

>
> Thank you very much for the help
> Gareth
>

Alexios


From mcewan.gareth at gmail.com  Wed Aug 12 10:48:57 2015
From: mcewan.gareth at gmail.com (Gareth McEwan)
Date: Wed, 12 Aug 2015 10:48:57 +0200
Subject: [R-SIG-Finance] Demean or not to demean
In-Reply-To: <CALGfFMZ2wBEqb26hrCbsjneq5DOZ8oVh84vSi-9k1CygxC6Fbg@mail.gmail.com>
References: <CALGfFMadvasuLL7Y+JpkZRRyaaqe7g2RnUb8mWaXQnqXRGDXzw@mail.gmail.com>
	<55C9C818.8020809@4dscape.com>
	<CALGfFMaHpk9MNbB_SpeG1Wc73Evn9eYsnd5r2X6RwxKuraTnfQ@mail.gmail.com>
	<CALGfFMYafZfyvOLKcKKq9KB5+Rz5fe3M5mqzbb_DeirtRfophA@mail.gmail.com>
	<55CB04FF.1000301@4dscape.com>
	<CALGfFMZ2wBEqb26hrCbsjneq5DOZ8oVh84vSi-9k1CygxC6Fbg@mail.gmail.com>
Message-ID: <CALGfFMYtrtZ4QOtW8LMPFP6QnGfmiqPnKDWm2JkFHj-uFvhxVg@mail.gmail.com>

If one specifies "include.mean = TRUE" in "ugarchspec", does the
"ugarchfit" function then use that (conditional mean) estimate to
center/demean the innovations before subsequently fitting the GARCH portion
of the model?

Moreover, I'm trying to
(1) understand the consequences/disadvantages of not demeaning the data
prior to passing through to the GARCH routine, i.e.,

(2) what effects take place when setting "include.mean = FALSE" in the
"mean.model" specification

Many thanks
Gareth



Refer:
On 11/08/2015 10:33, Gareth McEwan wrote:

> Hi all
>
> I was hoping someone could shed light or direct me to a resource (or two)
> regarding a "demean" question.
>
> As I understand, QMLEs estimated on "demeaned" log return data vs straight
> "log return" data behave quite differently in finite samples (particularly
> for nonlinear MA models where the MA parameter is of interest). Apparently,
> for linear AR models, demeaning data does not seriously affect estimation
> of non-intercept parameters (refer: Yong Bao "Should We Demean Data?").
>
> For monthly financial log return data, I find ARMA specifications are not
> significant, but some sample *means *ARE significant, while others are not.
> In either case, I add the GARCH model specification with various error
> distributions from the "rugarch" package.
>
> Code example:
> x.log.ret = diff(log(price.x) #i.e. not "demeaned"
> spec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1),
>              submodel=NULL,external.regressors=NULL,variance.targeting=F),
>              mean.model=list(*armaOrder = c(0,0)*,* include.mean = T*,
> external.regressors=NULL),
>              distribution.model="std")
> tempgarch <- ugarchfit(spec=spec,data=x.log.ret,solver="hybrid")
>
> I work through the steps necessary to fitting a *t*Copula from which to
> simulate and ultimately work my way back to simulated returns.
>
> The goal here is to extract from the matrix of simulated returns those
> groups of returns coinciding with certain pre-determined "scenarios". These
> are then used for portfolio optimization.
>
> In the "global respect" of the methodology, can anyone shed light on the
> merits/demerits of not first demeaning the data? I haven't found any
> glaring problems, but it bothers me that the "rugarch" package operates on
> demeaned data.
>

The rugarch package does NOT operate on demeaned data. It offers the option
(default=TRUE) through "include.mean" on whether to demean the data or not.
In case you are not demeaning, then the data are passed straight to the
GARCH routine and assumed as the zero-mean residuals.

On Wed, Aug 12, 2015 at 10:37 AM, Gareth McEwan <mcewan.gareth at gmail.com>
wrote:

> Hmmm, I did, initially (to R-sig-finance email address).
>
> You then replied (which I thought would address the R-sig-finance group),
> and me to your reply (also thinking it would address the group).
>
> I'll double check..
>
> On Wed, Aug 12, 2015 at 10:34 AM, alexios ghalanos <alexios at 4dscape.com>
> wrote:
>
>> You should post your question to the mailing list.
>>
>> A.
>>
>> On 12/08/2015 09:30, Gareth McEwan wrote:
>> > Sorry to keep bothering you Alexios (I know you're busy).
>> >
>> > Referring to my most recent response: if one specifies "include.mean =
>> > TRUE" in "ugarchspec", does the "ugarchfit" function use that
>> > (unconditional mean?) estimate to center/demean the innovations?
>> >
>> > I'm trying to understand how the "include.mean = T" is used in fitting
>> > the model.
>> >
>> > Many thanks
>> > Gareth
>> >
>> >
>> > On Tue, Aug 11, 2015 at 1:22 PM, Gareth McEwan <mcewan.gareth at gmail.com
>> > <mailto:mcewan.gareth at gmail.com>> wrote:
>> >
>> >     Hi Alexios
>> >
>> >     Is it correct then to say that by specifying "include.mean = TRUE"
>> >     in "ugarchspec", the "ugarchfit" function uses that (unconditional
>> >     mean) estimate to demean the data before subsequently fitting the
>> >     GARCH portion of the model?
>> >
>> >     Many thanks
>> >     Gareth
>> >
>> >
>> >
>> >     On Tue, Aug 11, 2015 at 12:02 PM, alexios <alexios at 4dscape.com
>> >     <mailto:alexios at 4dscape.com>> wrote:
>> >
>> >         On 11/08/2015 10:33, Gareth McEwan wrote:
>> >
>> >             Hi all
>> >
>> >             I was hoping someone could shed light or direct me to a
>> >             resource (or two)
>> >             regarding a "demean" question.
>> >
>> >             As I understand, QMLEs estimated on "demeaned" log return
>> >             data vs straight
>> >             "log return" data behave quite differently in finite samples
>> >             (particularly
>> >             for nonlinear MA models where the MA parameter is of
>> >             interest). Apparently,
>> >             for linear AR models, demeaning data does not seriously
>> >             affect estimation
>> >             of non-intercept parameters (refer: Yong Bao "Should We
>> >             Demean Data?").
>> >
>> >             For monthly financial log return data, I find ARMA
>> >             specifications are not
>> >             significant, but some sample *means *ARE significant, while
>> >             others are not.
>> >             In either case, I add the GARCH model specification with
>> >             various error
>> >             distributions from the "rugarch" package.
>> >
>> >             Code example:
>> >             x.log.ret = diff(log(price.x) #i.e. not "demeaned"
>> >             spec <-
>> >
>>  ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1),
>> >
>> >
>> submodel=NULL,external.regressors=NULL,variance.targeting=F),
>> >                          mean.model=list(*armaOrder = c(0,0)*,*
>> >             include.mean = T*,
>> >             external.regressors=NULL),
>> >                          distribution.model="std")
>> >             tempgarch <-
>> ugarchfit(spec=spec,data=x.log.ret,solver="hybrid")
>> >
>> >             I work through the steps necessary to fitting a *t*Copula
>> >             from which to
>> >             simulate and ultimately work my way back to simulated
>> returns.
>> >
>> >             The goal here is to extract from the matrix of simulated
>> >             returns those
>> >             groups of returns coinciding with certain pre-determined
>> >             "scenarios". These
>> >             are then used for portfolio optimization.
>> >
>> >             In the "global respect" of the methodology, can anyone shed
>> >             light on the
>> >             merits/demerits of not first demeaning the data? I haven't
>> >             found any
>> >             glaring problems, but it bothers me that the "rugarch"
>> >             package operates on
>> >             demeaned data.
>> >
>> >
>> >         The rugarch package does NOT operate on demeaned data. It offers
>> >         the option (default=TRUE) through "include.mean" on whether to
>> >         demean the data or not. In case you are not demeaning, then the
>> >         data are passed straight to the GARCH routine and assumed as the
>> >         zero-mean residuals.
>> >
>> >
>> >
>> >             Thank you very much for the help
>> >             Gareth
>> >
>> >
>> >         Alexios
>> >
>> >
>> >
>>
>
>

	[[alternative HTML version deleted]]


From alexios at 4dscape.com  Wed Aug 12 10:54:45 2015
From: alexios at 4dscape.com (alexios ghalanos)
Date: Wed, 12 Aug 2015 09:54:45 +0100
Subject: [R-SIG-Finance] Demean or not to demean
In-Reply-To: <CALGfFMYtrtZ4QOtW8LMPFP6QnGfmiqPnKDWm2JkFHj-uFvhxVg@mail.gmail.com>
References: <CALGfFMadvasuLL7Y+JpkZRRyaaqe7g2RnUb8mWaXQnqXRGDXzw@mail.gmail.com>
	<55C9C818.8020809@4dscape.com>
	<CALGfFMaHpk9MNbB_SpeG1Wc73Evn9eYsnd5r2X6RwxKuraTnfQ@mail.gmail.com>
	<CALGfFMYafZfyvOLKcKKq9KB5+Rz5fe3M5mqzbb_DeirtRfophA@mail.gmail.com>
	<55CB04FF.1000301@4dscape.com>
	<CALGfFMZ2wBEqb26hrCbsjneq5DOZ8oVh84vSi-9k1CygxC6Fbg@mail.gmail.com>
	<CALGfFMYtrtZ4QOtW8LMPFP6QnGfmiqPnKDWm2JkFHj-uFvhxVg@mail.gmail.com>
Message-ID: <55CB09D5.1090406@4dscape.com>

The mean is estimated using maximum likelihood when include.mean=TRUE,
else it is zero (that should be clear from the vignette).

As to the assumptions on zero mean residuals, any
econometric/statistical reference should
answer that.

Alexios


On 12/08/2015 09:48, Gareth McEwan wrote:
> If one specifies "include.mean = TRUE" in "ugarchspec", does the
> "ugarchfit" function then use that (conditional mean) estimate to
> center/demean the innovations before subsequently fitting the GARCH
> portion of the model?
> 
> Moreover, I'm trying to 
> (1) understand the consequences/disadvantages of not demeaning the data
> prior to passing through to the GARCH routine, i.e., 
> 
> (2) what effects take place when setting "include.mean = FALSE" in the
> "mean.model" specification
> 
> Many thanks
> Gareth
> 
> 
> 
> Refer:
> On 11/08/2015 10:33, Gareth McEwan wrote:
> 
>     Hi all
> 
>     I was hoping someone could shed light or direct me to a resource (or
>     two)
>     regarding a "demean" question.
> 
>     As I understand, QMLEs estimated on "demeaned" log return data vs
>     straight
>     "log return" data behave quite differently in finite samples
>     (particularly
>     for nonlinear MA models where the MA parameter is of interest).
>     Apparently,
>     for linear AR models, demeaning data does not seriously affect
>     estimation
>     of non-intercept parameters (refer: Yong Bao "Should We Demean Data?").
> 
>     For monthly financial log return data, I find ARMA specifications
>     are not
>     significant, but some sample *means *ARE significant, while others
>     are not.
>     In either case, I add the GARCH model specification with various error
>     distributions from the "rugarch" package.
> 
>     Code example:
>     x.log.ret = diff(log(price.x) #i.e. not "demeaned"
>     spec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1),
>                
>      submodel=NULL,external.regressors=NULL,variance.targeting=F),
>                  mean.model=list(*armaOrder = c(0,0)*,* include.mean = T*,
>     external.regressors=NULL),
>                  distribution.model="std")
>     tempgarch <- ugarchfit(spec=spec,data=x.log.ret,solver="hybrid")
> 
>     I work through the steps necessary to fitting a *t*Copula from which to
>     simulate and ultimately work my way back to simulated returns.
> 
>     The goal here is to extract from the matrix of simulated returns those
>     groups of returns coinciding with certain pre-determined
>     "scenarios". These
>     are then used for portfolio optimization.
> 
>     In the "global respect" of the methodology, can anyone shed light on the
>     merits/demerits of not first demeaning the data? I haven't found any
>     glaring problems, but it bothers me that the "rugarch" package
>     operates on
>     demeaned data.
> 
> 
> The rugarch package does NOT operate on demeaned data. It offers the
> option (default=TRUE) through "include.mean" on whether to demean the
> data or not. In case you are not demeaning, then the data are passed
> straight to the GARCH routine and assumed as the zero-mean residuals.
> 
> On Wed, Aug 12, 2015 at 10:37 AM, Gareth McEwan <mcewan.gareth at gmail.com
> <mailto:mcewan.gareth at gmail.com>> wrote:
> 
>     Hmmm, I did, initially (to R-sig-finance email address).
> 
>     You then replied (which I thought would address the R-sig-finance
>     group), and me to your reply (also thinking it would address the group).
> 
>     I'll double check..
> 
>     On Wed, Aug 12, 2015 at 10:34 AM, alexios ghalanos
>     <alexios at 4dscape.com <mailto:alexios at 4dscape.com>> wrote:
> 
>         You should post your question to the mailing list.
> 
>         A.
> 
>         On 12/08/2015 09:30, Gareth McEwan wrote:
>         > Sorry to keep bothering you Alexios (I know you're busy).
>         >
>         > Referring to my most recent response: if one specifies "include.mean =
>         > TRUE" in "ugarchspec", does the "ugarchfit" function use that
>         > (unconditional mean?) estimate to center/demean the innovations?
>         >
>         > I'm trying to understand how the "include.mean = T" is used in fitting
>         > the model.
>         >
>         > Many thanks
>         > Gareth
>         >
>         >
>         > On Tue, Aug 11, 2015 at 1:22 PM, Gareth McEwan <mcewan.gareth at gmail.com <mailto:mcewan.gareth at gmail.com>
>         > <mailto:mcewan.gareth at gmail.com <mailto:mcewan.gareth at gmail.com>>> wrote:
>         >
>         >     Hi Alexios
>         >
>         >     Is it correct then to say that by specifying "include.mean = TRUE"
>         >     in "ugarchspec", the "ugarchfit" function uses that (unconditional
>         >     mean) estimate to demean the data before subsequently fitting the
>         >     GARCH portion of the model?
>         >
>         >     Many thanks
>         >     Gareth
>         >
>         >
>         >
>         >     On Tue, Aug 11, 2015 at 12:02 PM, alexios <alexios at 4dscape.com <mailto:alexios at 4dscape.com>
>         >     <mailto:alexios at 4dscape.com <mailto:alexios at 4dscape.com>>>
>         wrote:
>         >
>         >         On 11/08/2015 10:33, Gareth McEwan wrote:
>         >
>         >             Hi all
>         >
>         >             I was hoping someone could shed light or direct me
>         to a
>         >             resource (or two)
>         >             regarding a "demean" question.
>         >
>         >             As I understand, QMLEs estimated on "demeaned" log
>         return
>         >             data vs straight
>         >             "log return" data behave quite differently in
>         finite samples
>         >             (particularly
>         >             for nonlinear MA models where the MA parameter is of
>         >             interest). Apparently,
>         >             for linear AR models, demeaning data does not
>         seriously
>         >             affect estimation
>         >             of non-intercept parameters (refer: Yong Bao
>         "Should We
>         >             Demean Data?").
>         >
>         >             For monthly financial log return data, I find ARMA
>         >             specifications are not
>         >             significant, but some sample *means *ARE
>         significant, while
>         >             others are not.
>         >             In either case, I add the GARCH model
>         specification with
>         >             various error
>         >             distributions from the "rugarch" package.
>         >
>         >             Code example:
>         >             x.log.ret = diff(log(price.x) #i.e. not "demeaned"
>         >             spec <-
>         >           
>          ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1),
>         >
>         >             
>         submodel=NULL,external.regressors=NULL,variance.targeting=F),
>         >                          mean.model=list(*armaOrder = c(0,0)*,*
>         >             include.mean = T*,
>         >             external.regressors=NULL),
>         >                          distribution.model="std")
>         >             tempgarch <-
>         ugarchfit(spec=spec,data=x.log.ret,solver="hybrid")
>         >
>         >             I work through the steps necessary to fitting a
>         *t*Copula
>         >             from which to
>         >             simulate and ultimately work my way back to
>         simulated returns.
>         >
>         >             The goal here is to extract from the matrix of
>         simulated
>         >             returns those
>         >             groups of returns coinciding with certain
>         pre-determined
>         >             "scenarios". These
>         >             are then used for portfolio optimization.
>         >
>         >             In the "global respect" of the methodology, can
>         anyone shed
>         >             light on the
>         >             merits/demerits of not first demeaning the data? I
>         haven't
>         >             found any
>         >             glaring problems, but it bothers me that the "rugarch"
>         >             package operates on
>         >             demeaned data.
>         >
>         >
>         >         The rugarch package does NOT operate on demeaned data.
>         It offers
>         >         the option (default=TRUE) through "include.mean" on
>         whether to
>         >         demean the data or not. In case you are not demeaning,
>         then the
>         >         data are passed straight to the GARCH routine and
>         assumed as the
>         >         zero-mean residuals.
>         >
>         >
>         >
>         >             Thank you very much for the help
>         >             Gareth
>         >
>         >
>         >         Alexios
>         >
>         >
>         >
> 
> 
>


From pippenspips at uchicago.edu  Wed Aug 12 16:27:47 2015
From: pippenspips at uchicago.edu (Pippens Pips)
Date: Wed, 12 Aug 2015 14:27:47 +0000 (UTC)
Subject: [R-SIG-Finance] rolling forecasts with rugarch
Message-ID: <1626541376.3543704.1439389667257.JavaMail.yahoo@mail.yahoo.com>

Hi,This is my first time using this so sorry in advance if my post is not clear. I am trying to use the past 500 days to create a rolling forecast 1 day ahead. So for the 501th day I would use 1-500 and for the 502nd day I would use 2-501. I am using the ugarchroll command for the next 20 days. I understand that the code should be this:
library(quantmod)library(rugarch)library(PerformanceAnalytics)getSymbols("SPY")spyRets=na.omit(Return.calculate(Cl(SPY),method=c('log'))) #log returnsspec=ugarchspec(mean.model=list(armaOrder=c(3,3))) #arma(3,3) and garch(1,1)GARCH=ugarchfit(spec,head(spyRets,500),solver="hybrid") #run regressionspyRetssub=spyRets[1:520,]roll=ugarchroll(spec,data=spyRetssub,n.start=500,refit.every=1,window.size=500,refit.window=c('moving'),solver='hybrid')rollingforecasts=xts(roll at forecast$density$Mu,order.by=index(spyRets[501:520,])) #my forecasts for next 20 days with walk forward
I now check that by manually doing the same forecasts except now I will use the ugarchforecast function and then just change the data to the subset that I want.
setfixed(spec)=as.list(coef(GARCH))forecast501=ugarchforecast(spec,data=spyRets[1:500],n.ahead=1) #give me one step ahead forecastfitted(forecast501) #t+1 fitted value. This matchesforecast502=ugarchforecast(spec,data=spyRets[2:501],n.ahead=1) #give me one step ahead forecastfitted(forecast502) #t+2 fitted value. This does not match with rolling forecastforecast503=ugarchforecast(spec,data=spyRets[3:502],n.ahead=1) #give me one step ahead forecastfitted(forecast503) #t+3 fitted value. This does not match with rolling forecast
The issue is that the 1st forecast matches, however after that the forecasts break down. Is there something that I am doing wrong in my original rolling forecast code that gets the first t+1 day correct but not the rest?
Thanks in advancePippens
	[[alternative HTML version deleted]]


From alexios at 4dscape.com  Thu Aug 13 21:02:16 2015
From: alexios at 4dscape.com (alexios)
Date: Thu, 13 Aug 2015 20:02:16 +0100
Subject: [R-SIG-Finance] rolling forecasts with rugarch
In-Reply-To: <1626541376.3543704.1439389667257.JavaMail.yahoo@mail.yahoo.com>
References: <1626541376.3543704.1439389667257.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <55CCE9B8.9080804@4dscape.com>

You email has arrived very badly formatted making it difficult to 
read...in any case, I suggest you look at the underlying function in the 
source (rugarch-rolling.R) to see how the rolling estimation/forecasting 
is performed, which should allow you to reproduce the results exactly 
with ugarchforecast (ugarchroll is after all just a wrapper around this).

You should also search this mailing list's archives for similar/related 
questions.

Alexios

On 12/08/2015 15:27, Pippens Pips wrote:
> Hi,This is my first time using this so sorry in advance if my post is not clear. I am trying to use the past 500 days to create a rolling forecast 1 day ahead. So for the 501th day I would use 1-500 and for the 502nd day I would use 2-501. I am using the ugarchroll command for the next 20 days. I understand that the code should be this:
> library(quantmod)library(rugarch)library(PerformanceAnalytics)getSymbols("SPY")spyRets=na.omit(Return.calculate(Cl(SPY),method=c('log'))) #log returnsspec=ugarchspec(mean.model=list(armaOrder=c(3,3))) #arma(3,3) and garch(1,1)GARCH=ugarchfit(spec,head(spyRets,500),solver="hybrid") #run regressionspyRetssub=spyRets[1:520,]roll=ugarchroll(spec,data=spyRetssub,n.start=500,refit.every=1,window.size=500,refit.window=c('moving'),solver='hybrid')rollingforecasts=xts(roll at forecast$density$Mu,order.by=index(spyRets[501:520,])) #my forecasts for next 20 days with walk forward
> I now check that by manually doing the same forecasts except now I will use the ugarchforecast function and then just change the data to the subset that I want.
> setfixed(spec)=as.list(coef(GARCH))forecast501=ugarchforecast(spec,data=spyRets[1:500],n.ahead=1) #give me one step ahead forecastfitted(forecast501) #t+1 fitted value. This matchesforecast502=ugarchforecast(spec,data=spyRets[2:501],n.ahead=1) #give me one step ahead forecastfitted(forecast502) #t+2 fitted value. This does not match with rolling forecastforecast503=ugarchforecast(spec,data=spyRets[3:502],n.ahead=1) #give me one step ahead forecastfitted(forecast503) #t+3 fitted value. This does not match with rolling forecast
> The issue is that the 1st forecast matches, however after that the forecasts break down. Is there something that I am doing wrong in my original rolling forecast code that gets the first t+1 day correct but not the rest?
> Thanks in advancePippens
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>
>


From samuelcoltwilson at gmail.com  Thu Aug 13 21:54:24 2015
From: samuelcoltwilson at gmail.com (Samuel Wilson)
Date: Thu, 13 Aug 2015 12:54:24 -0700
Subject: [R-SIG-Finance] Constant maturity Futures
Message-ID: <CACCk-cHAS+yBjr9xuJqDiQLoQVt39sLMtdOe6+=LUjoCB08=hw@mail.gmail.com>

Before I write the code, I was wondering if anyone had already created a
function or code for calculating constant maturity for a futures contract
in R.

	[[alternative HTML version deleted]]


From ilya.kipnis at gmail.com  Thu Aug 13 22:02:35 2015
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Thu, 13 Aug 2015 16:02:35 -0400
Subject: [R-SIG-Finance] Constant maturity Futures
In-Reply-To: <CACCk-cHAS+yBjr9xuJqDiQLoQVt39sLMtdOe6+=LUjoCB08=hw@mail.gmail.com>
References: <CACCk-cHAS+yBjr9xuJqDiQLoQVt39sLMtdOe6+=LUjoCB08=hw@mail.gmail.com>
Message-ID: <CA+oJuEFzP6arc5earutGD9zypiby-Du70xavUn4eiyCV2+gHWg@mail.gmail.com>

Highly doubt it, simply due to lack of good free futures data. Is this for
volatility trading?
On Aug 13, 2015 3:54 PM, "Samuel Wilson" <samuelcoltwilson at gmail.com> wrote:

> Before I write the code, I was wondering if anyone had already created a
> function or code for calculating constant maturity for a futures contract
> in R.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From gsee000 at gmail.com  Thu Aug 13 23:56:15 2015
From: gsee000 at gmail.com (G See)
Date: Thu, 13 Aug 2015 16:56:15 -0500
Subject: [R-SIG-Finance] Constant maturity Futures
In-Reply-To: <CACCk-cHAS+yBjr9xuJqDiQLoQVt39sLMtdOe6+=LUjoCB08=hw@mail.gmail.com>
References: <CACCk-cHAS+yBjr9xuJqDiQLoQVt39sLMtdOe6+=LUjoCB08=hw@mail.gmail.com>
Message-ID: <CA+xi=qZ2ykXsWfGY5REEvC7Ru4cxCy-TXitELw5deiq7vwv6Yg@mail.gmail.com>

Hi Samuel,

Here's some code (also attached) that creates constant maturity
futures for VIX futures.  I wrote this code 4 years ago.  I'm not
particularly proud of it.  I don't know for sure that it works.  It
might not be elegant.  etc.  Take it for what it's worth.

You should be able to source this code and get a time series plot of
several different CMFs of varying maturities.  You'll need my qmao
package which you can install with
devtools::install_github("gsee/qmao")


#' @export
#' @rdname primary2expiry
suffix2expiry <- function(suffix, root='VX', ...) {
    if (exists(paste('suffix2expiry',root,sep="."))) {
        do.call(paste('suffix2expiry',root,sep='.'),list(suffix, ...))
    } else {
        warning(paste(root, 'is not and available suffix2expiry
method; using "VX" instead'))
        do.call('suffix2expiry.VX',list(suffix, ...))
    }
}

#' Get the expiration date of an instrument given it's primary_id
#'
#' \code{primary2expiry} is basically a wrapper for
\code{\link{suffix2expiry}}.  It uses
#' \code{\link[FinancialInstrument]{parse_id}} to split the
\code{primary_id} into rood_id and suffix_id.
#' then it calls the appropriate \code{\link{suffix2expiry}} method.
#'
#' \code{suffix2expiry} is a generic-like function.  There should be a
method defined
#' the "root_id".  Currently, written methods include "VX", "ES" (and
aliases "YM", "NQ").
#' There are links to methods help pages in the seealso section.
#'
#' @param primary_id character string.  Primary identifier of the instrument
#' @param root character string. root symbol like "ES" or "VX" (NULL)
#' @param silent silence warnings? (TRUE)
#' @param suffix character string that indicates expiration month and
year (and, for options, right and strike).
#' See \code{\link[FinancialInstrument]{parse_suffix}} for examples of
acceptable formats.
#' @param ... any arguments to be passed to the \code{suffix2expiry} method
#' @return expiration Date
#' @seealso \code{\link{suffix2expiry.VX}}, \code{\link{suffix2expiry.ES}}
#' @aliases primary2expiry, suffix2expiry
#' @author gsee
#' @examples
#' primary2expiry("ESU1")
#' suffix2expiry('V11', root='VX')
#' @export
#' @rdname primary2expiry
primary2expiry <- function(primary_id, root=NULL, silent=TRUE) {
  idlist <- parse_id(primary_id, silent=silent)
  if (is.null(root)) root <- idlist$root
  do.call(paste("suffix2expiry",root,sep='.'),
list(suffix=idlist$suffix, silent=silent))
}


#' VIX future contract expiration date
#'
#' Calculate the expiration date of a VIX future contract given a suffix_id
#'
#' Per the contract specs, expiration will occur on \dQuote{the Wednesday that
#' is thirty days prior to the third Friday of the calendar month
#' immediately following the month in which the contract expires
("Final Settlement Date").
#' If the third Friday of the month subsequent to expiration of the applicable
#' VIX futures contract is a CBOE holiday, the Final Settlement Date
for the contract
#' shall be thirty days prior to the CBOE business day immediately
preceding that Friday.}
#' @param suffix suffix_id that should be something like (\sQuote{U1},
\sQuote{U11}, or \sQuote{SEP11})
#' @param silent silence warnings? (TRUE)
#' @return an expiration Date
#' @author gsee
#' @references \url{http://cfe.cboe.com/products/spec_vix.aspx}
#' @examples
#' \dontrun{
#' suffix2expiry.VX('U11')
#' suffix2expiry.VX("JUN09")
#' }
#' @export
suffix2expiry.VX <- suffix2expiry.VIX <- function(suffix, silent=TRUE) {
    #require('timeDate')
    sl <- parse_suffix(suffix,silent=silent)
    DT <- as.Date(paste(15, sl$month, sl$year,sep='-'),format="%d-%b-%Y")
    Y <- format(DT,"%Y")
    M <- format((DT + 30),"%m")
    if (as.numeric(M) == 1) Y <- paste(as.numeric(Y) + 1)
    DS <- as.Date(paste(Y,M,01,sep='-'))+0:22
    DS <- DS[months(DS, abbreviate=TRUE) == C2M()[as.numeric(M)]]
    ds <- which(weekdays(DS) == "Friday")[3]
    if (DS[ds] %in% as.Date(holidayNYSE(as.numeric(Y))@Data)) {
        while (DS[ds] %in% as.Date(holidayNYSE(as.numeric(Y))@Data)
                || any(c('Saturday', 'Sunday') == weekdays(DS[ds])))
            ds <- ds-1
    }
    #try(detach(package:timeDate), silent=TRUE);
try(detach(package:timeSeries), silent=TRUE)
    DS[ds] - 30
}





.interp.fut.VX <- function(x1, x2, n=36, prefer='Close') {
    xs <- c(x1,x2) # names of 2 instruments
    x1 <- get(x1,pos=.GlobalEnv)
    x2 <- get(x2,pos=.GlobalEnv)

    x1$DTE <- primary2expiry(xs[1])-index(x1)#, index(x1)) #dlf(x1)
    x2$DTE <- primary2expiry(xs[2])-index(x2)#, index(x2)) #dlf(x2)
    df <- merge(x1$DTE,x2$DTE,all=FALSE)
    df <- na.omit(df)
    if (length(df[,1]) && length(df[,2])) {
        Pcmf <- xts()
        if(all(df[,1] < df[,2])) {
            col1 <- 1
            col2 <- 2
        } else if (all(df[,2] < df[,1])) {
            col1 <- 2
            col2 <- 1
        } else stop(paste("ambiguous nearby contract",xs))
        for (ns in n) {
            idx <- index(df[(df[,col1] <= ns) & (df[,col2] > ns)])
            if (length(idx) == 0) return(NULL)
            w <- 1/ns
            P1 <- try(getPrice(x1[idx],prefer=prefer))
            P2 <- try(getPrice(x2[idx],prefer=prefer))
            wP <- try((w*P1) + ((1-w)*P2))
            if (!any(sapply(list(P1,P2,wP), inherits, 'try-error')))
                Pcmf <- cbind(Pcmf,wP)
        }
    #indexClass(Pcmf) <- 'Date' ## xts kind of broke this.
    Pcmf
    }
}


term.structure <- function(Symbols, cdays=c(35,60,90,120)) {
    s <- Symbols
    cnames <- paste(strsplit(s[[1]],"_")[[1]][1], "cm", cdays, sep=".")
    a <- list()
    for (i in 2:length(s)) {
        tmp <- .interp.fut.VX(s[i-1],s[i],cdays)
        if (length(tmp)) {
            a[[i-1]] <- tmp
            colnames(a[[i-1]]) <- cnames
        }
    }
    #for (i in 1:length(a)) colnames(a[[i]]) <- paste("VX.CM", tdays, sep=".")
    cb <- NULL
    for (i in 1:length(cdays)) {
        rb <- na.omit(a[[1]][,i])
        for (j in 2:(length(s)-1)) {
            if (length(a) > j && length(a[[j]][,i]) &&
                length(na.omit(a[[j]][,i])))
              rb <- rbind(rb, na.omit(a[[j]][,i]))
        }
        cb <- as.xts(cbind(cb, rb), dateFormat="Date")
    }
    cb
}

library(qmao)
library(timeDate) # for holidayNYSE
setSymbolLookup(VX='cfe')
vx <- getSymbols('VX',Month=1:12,Year=2007:2011)

plot.zoo(term.structure(vx, seq(20, 200, 20)), screens=1, col=rainbow(10))

-----

HTH,
Garrett



On Thu, Aug 13, 2015 at 2:54 PM, Samuel Wilson
<samuelcoltwilson at gmail.com> wrote:
> Before I write the code, I was wondering if anyone had already created a
> function or code for calculating constant maturity for a futures contract
> in R.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: VXCurve.R
Type: application/octet-stream
Size: 5969 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20150813/1b0731ac/attachment.obj>

From weigel.eric1 at gmail.com  Sat Aug 15 21:00:51 2015
From: weigel.eric1 at gmail.com (Eric Weigel)
Date: Sat, 15 Aug 2015 15:00:51 -0400
Subject: [R-SIG-Finance] CONSTRAINED REGRESSIONS
Message-ID: <CAErBeddkDcrHRQF90SySs+i9RXF871hHbufLf_zJcCYG664FWg@mail.gmail.com>

?I wish to run a regression where the slope coefficients are bound between
0 and 1, the sum of the slope coefficients ?sums to 1 and there is an
intercept (no bounds). Specifically I wish to run a Heston/Rouwenhorst type
of regression using country and sector dummies.

Is there a procedure in R that can run such a constrained regression?

Thanks for your help.

-- 

*Eric J. Weigel*

	[[alternative HTML version deleted]]


From markleeds2 at gmail.com  Sat Aug 15 22:36:05 2015
From: markleeds2 at gmail.com (Mark Leeds)
Date: Sat, 15 Aug 2015 16:36:05 -0400
Subject: [R-SIG-Finance] CONSTRAINED REGRESSIONS
In-Reply-To: <CAErBeddkDcrHRQF90SySs+i9RXF871hHbufLf_zJcCYG664FWg@mail.gmail.com>
References: <CAErBeddkDcrHRQF90SySs+i9RXF871hHbufLf_zJcCYG664FWg@mail.gmail.com>
Message-ID: <CAHz+bWb61NfnOAKzy2rTdQ1ugxGUrMrwFQA9kedWhJGx1GXwpg@mail.gmail.com>

Hi: There probably is but I don't know of the package.

Another way is just to maximize the standard likelihood with the
constraints that all of the coefficients are between 0 and 1, except for
one of them which is then 1 minus the sum of the others. Note that,
whatever you use,  don't use L-BFGS-B. It's buggy and not due to anything
anyone associated with R did. It uses a Fortran algorithm and Nocedal
posted the bug a few years ago.

http://www.ece.northwestern.edu/~morales/PSfiles/acm-remark.pdf

As a recommendation, I've had very good experiences with Rvmmin ( use the
variable metric approach  just like BFGS )  so I'm biased towards that one.
But, if you want to use it, speak with John Nash because it's often in
active development-improvement so you should get the latest one.












On Sat, Aug 15, 2015 at 3:00 PM, Eric Weigel <weigel.eric1 at gmail.com> wrote:

> ?I wish to run a regression where the slope coefficients are bound between
> 0 and 1, the sum of the slope coefficients ?sums to 1 and there is an
> intercept (no bounds). Specifically I wish to run a Heston/Rouwenhorst type
> of regression using country and sector dummies.
>
> Is there a procedure in R that can run such a constrained regression?
>
> Thanks for your help.
>
> --
>
> *Eric J. Weigel*
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.

	[[alternative HTML version deleted]]


From jmtruppia at gmail.com  Sun Aug 16 14:14:22 2015
From: jmtruppia at gmail.com (Juan Manuel Truppia)
Date: Sun, 16 Aug 2015 12:14:22 +0000
Subject: [R-SIG-Finance] reikon : A package to retrieve data from Thomson
	Reuters Eikon platform
Message-ID: <CAO2XSvc9f4NMg_wdDV=rwK98MZpYKr5ZGrLbOvDOfCW9-1YGig@mail.gmail.com>

Hi, I'm developing a package to interact from R with Eikon, the Thomson
Reuters financial data platform (a la Rblpapi).
You can find the package in Bitbucket at
https <https://bitbucket.org/juancentro/reikon>://
<https://bitbucket.org/juancentro/reikon>bitbucket.org
<https://bitbucket.org/juancentro/reikon>/
<https://bitbucket.org/juancentro/reikon>juancentro
<https://bitbucket.org/juancentro/reikon>/reikon
<https://bitbucket.org/juancentro/reikon>.
The package is fully functional, but requires testing and usage in other
environments than mine.
It has documentation and a vignette.
Please report any bugs directly in Bitbucket, and I would gladly accept
help with the development.

Regards

Juan

	[[alternative HTML version deleted]]


From edd at debian.org  Sun Aug 16 18:48:10 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 16 Aug 2015 11:48:10 -0500
Subject: [R-SIG-Finance] [ANN] Rblpapi: Connecting R to Bloomberg
Message-ID: <21968.48842.98787.918780@max.nulle.part>


[ This is an ascii version of Friday's blog post at
     http://dirk.eddelbuettel.com/blog/2015/08/14#rblpapi_0.3.0
  which you should go to for the links and colour highlighting. The CRAN
  sites now carry Windows and OS X (Mavericks) binary packages.  -- Dirk ]


   Rblpapi: Connecting R to Bloomberg
   
   Whit, John and I are thrilled to announce Rblapi, a new CRAN package which
   connects R to the Bloomberg backends.
   
   Rebuilt from scratch using only the Bloomberg C++ API and the Rcpp and BH
   packages, it offers efficient and direct access from R to a truly vast
   number of financial data series, pricing tools and more. The package has
   been tested on Windows, OS X and Linux. As is standard for CRAN packages,
   binaries for Windows and OS X are provided (or will be once the builders
   caught up). Needless to say, a working Bloomberg installation is required
   to use the package.
   
   Please see the Rblapi package page for more details, including a large
   part of the introductory vignette document. As a teaser, here are just
   three of the core functions:
   
      ## Bloomberg Data Point Query
      bdp(c("ESA Index", "SPY US Equity"), c("PX_LAST", "VOLUME"))
   
      ## Bloomberg Data Set Query
      bds("GOOG US Equity", "TOP_20_HOLDERS_PUBLIC_FILINGS")
   
      ## Bloomberg Data History Query
      bdh("SPY US Equity", c("PX_LAST", "VOLUME"), start.date=Sys.Date()-31)
   
      ## Get OHLCV bars (by default hourly and just six of them)
      getBars("ES1 Index")
   
      ## Get Tick Data (by default last hour)
      getTicks("ES1 Index")
   
   Source code for the package is at the Rblpapi GitHub repo where issue
   tickets can be filed as well. The sibbling blp GitHub repo contains the
   Bloomberg code required to build and link the package (which is automated
   during the build of the CRAN package). Last but not least the Rblpapi
   package page has more details about the package.


See the blog post for links, and the package page at
   http://dirk.eddelbuettel.com/code/rblpapi.html
for more.  Please use the Github issue tracker at
   https://github.com/Rblp/Rblpapi/issues
for bug reports.

Regards,  Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From minger00 at gmx.de  Sun Aug 16 18:55:20 2015
From: minger00 at gmx.de (Mingersming)
Date: Sun, 16 Aug 2015 09:55:20 -0700 (PDT)
Subject: [R-SIG-Finance] VaR calculation warning with rugarch
Message-ID: <1439744120303-4711164.post@n4.nabble.com>

Hi all,

there is one issue I can?t go one myself. I try to fit a nig-distribution in
a rolling window method to a time-series with the fantastic rugarch package.
I use the option 'calculate.VaR' for several other distributions and it
works fine, but if I switch to the nig-distribution, I recieve the following
warning:

In ans[i] = mu[i] + sigma[i] * .qsnigC(p, rho = skew[i],  ... :number of
items to replace is not a multiple of replacement length

I tried to turn off the option and calculate the quantile on my own. I think
there is an misstake with the number of the parameters, but what can I
change to get over? 

For code, see below

Best regards 

library(quantmod)
library(rugarch)
library(PerformanceAnalytics)

bi <- getSymbols('^GDAXI', from = "2004-01-01", to = "2015-08-01")	
bi <- Ad(get(bi[1]))
bi_tlr <- Return.calculate(bi, method = "log")
bi_tlr <- na.omit(bi_tlr)

ctrl = list(rho = 1, delta = 1e-11, outer.iter = 1000, tol = 1e-12)
cl = makePSOCKcluster(10)

T = nrow(bi_tlr)
t_bt <- nrow(as.xts(bi_tlr)["2006-01-01/2015-08-01"]) 
t_est <- T - t_bt

spec_nig = ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
c(1,1)), 
mean.model = list(armaOrder = c(0,0), include.mean = FALSE),
distribution.model = "nig")

bi.backtest.nig = ugarchroll(spec_nig, data = bi_tlr, n.ahead = 1,
forecast.length = 10, refit.every = 1, refit.window = "moving", solver =
"hybrid", fit.control = list(), solver.control = ctrl, calculate.VaR = TRUE,
VaR.alpha = c(0.01,0.05), cluster = cl,keep.coef = TRUE)





--
View this message in context: http://r.789695.n4.nabble.com/VaR-calculation-warning-with-rugarch-tp4711164.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From alexios at 4dscape.com  Sun Aug 16 19:15:42 2015
From: alexios at 4dscape.com (alexios)
Date: Sun, 16 Aug 2015 18:15:42 +0100
Subject: [R-SIG-Finance] VaR calculation warning with rugarch
In-Reply-To: <1439744120303-4711164.post@n4.nabble.com>
References: <1439744120303-4711164.post@n4.nabble.com>
Message-ID: <55D0C53E.6010105@4dscape.com>

You can ignore the warning. You can calculate the values yourself and 
check that the results are the same:

df = as.data.frame(bi.backtest.nig)

q = quantile(bi.backtest.nig,0.01)
q10 = 
qdist("nig",0.01,mu=0,sigma=df[10,"Sigma"],skew=df[10,"Skew"],shape=df[10,"Shape"])
as.numeric(q[10])==q10
 > TRUE
q5 = 
qdist("nig",0.01,mu=0,sigma=df[5,"Sigma"],skew=df[5,"Skew"],shape=df[5,"Shape"])
as.numeric(q[5])==q5
 > TRUE

The warning will be fixed in the development version (...soon).

Alexios

On 16/08/2015 17:55, Mingersming wrote:
> Hi all,
>
> there is one issue I can?t go one myself. I try to fit a nig-distribution in
> a rolling window method to a time-series with the fantastic rugarch package.
> I use the option 'calculate.VaR' for several other distributions and it
> works fine, but if I switch to the nig-distribution, I recieve the following
> warning:
>
> In ans[i] = mu[i] + sigma[i] * .qsnigC(p, rho = skew[i],  ... :number of
> items to replace is not a multiple of replacement length
>
> I tried to turn off the option and calculate the quantile on my own. I think
> there is an misstake with the number of the parameters, but what can I
> change to get over?
>
> For code, see below
>
> Best regards
>
> library(quantmod)
> library(rugarch)
> library(PerformanceAnalytics)
>
> bi <- getSymbols('^GDAXI', from = "2004-01-01", to = "2015-08-01")	
> bi <- Ad(get(bi[1]))
> bi_tlr <- Return.calculate(bi, method = "log")
> bi_tlr <- na.omit(bi_tlr)
>
> ctrl = list(rho = 1, delta = 1e-11, outer.iter = 1000, tol = 1e-12)
> cl = makePSOCKcluster(10)
>
> T = nrow(bi_tlr)
> t_bt <- nrow(as.xts(bi_tlr)["2006-01-01/2015-08-01"])
> t_est <- T - t_bt
>
> spec_nig = ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
> c(1,1)),
> mean.model = list(armaOrder = c(0,0), include.mean = FALSE),
> distribution.model = "nig")
>
> bi.backtest.nig = ugarchroll(spec_nig, data = bi_tlr, n.ahead = 1,
> forecast.length = 10, refit.every = 1, refit.window = "moving", solver =
> "hybrid", fit.control = list(), solver.control = ctrl, calculate.VaR = TRUE,
> VaR.alpha = c(0.01,0.05), cluster = cl,keep.coef = TRUE)
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/VaR-calculation-warning-with-rugarch-tp4711164.html
> Sent from the Rmetrics mailing list archive at Nabble.com.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>


From akanefortuna at gmail.com  Sun Aug 16 19:19:34 2015
From: akanefortuna at gmail.com (Akane Fortuna)
Date: Sun, 16 Aug 2015 20:19:34 +0300
Subject: [R-SIG-Finance] Consolidating Backtests
Message-ID: <CACf9SCJ-3qcca6X8ar5yWoodopQ5wADRs5-iE0WbrHPvqWkOtg@mail.gmail.com>

Hi everyone,

I am trying to test a strategy with random parameters that change every
month as some kind of a benchmark to compare my other strategies against.
This strategy is applied to the same instrument every month.  I tried to
make a loop with applystrategy(), where in each iteration the different
random parameter values are passed, and the next month's data is used. The
first iteration is executed without problems but I cannot make the next
iterations work.

I want to be able to use chart.Posn(), tradeStats() (in consolidated form),
chart.ME(), getOrderBook(), getTxns() with the consolidated strategy
backtest.

How should I go about doing this? No code is necessary for an answer, but I
appreciate it if there is. Just outline/plan of the code is sufficient.
Thank you.

	[[alternative HTML version deleted]]


From brian at braverock.com  Sun Aug 16 21:02:27 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Sun, 16 Aug 2015 14:02:27 -0500
Subject: [R-SIG-Finance] Consolidating Backtests
In-Reply-To: <CACf9SCJ-3qcca6X8ar5yWoodopQ5wADRs5-iE0WbrHPvqWkOtg@mail.gmail.com>
References: <CACf9SCJ-3qcca6X8ar5yWoodopQ5wADRs5-iE0WbrHPvqWkOtg@mail.gmail.com>
Message-ID: <1439751747.3920.5.camel@brian-rcg>

On Sun, 2015-08-16 at 20:19 +0300, Akane Fortuna wrote:
> I am trying to test a strategy with random parameters that change every
> month as some kind of a benchmark to compare my other strategies against.
> This strategy is applied to the same instrument every month.  I tried to
> make a loop with applystrategy(), where in each iteration the different
> random parameter values are passed, and the next month's data is used. The
> first iteration is executed without problems but I cannot make the next
> iterations work.
> 
> I want to be able to use chart.Posn(), tradeStats() (in consolidated form),
> chart.ME(), getOrderBook(), getTxns() with the consolidated strategy
> backtest.
> 
> How should I go about doing this? No code is necessary for an answer, but I
> appreciate it if there is. Just outline/plan of the code is sufficient.
> Thank you.

The challenge with what you're trying to do is that the indicators and
signals are presumed to be vectorized functions.  So they are applied to
the entire dataset at once.

You're talking about subsetting the data by months, and applying
different parameter values.

If your indicators and signals don't have any lookback period, or are
constant over the entire test, then you should be able to use a
rebalance rule, which will subset the data and let you change things
around on your rebalance periods.

Assuming that's not the case, your options are somewhat more limited.

You have no problems using the same portfolio and account over
progressively increasing time periods.  You're basically just adding new
transactions over time.

The slightly challenging point will be in controlling the start and end
periods for everything else.  You'll need to make sure you don't have
signals before the start of the subset period, or after the end of the
subset period.

A minimal reproducible example would help others help you.

Regards,

Brian


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From ilya.kipnis at gmail.com  Sun Aug 16 21:06:35 2015
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Sun, 16 Aug 2015 15:06:35 -0400
Subject: [R-SIG-Finance] Consolidating Backtests
In-Reply-To: <1439751747.3920.5.camel@brian-rcg>
References: <CACf9SCJ-3qcca6X8ar5yWoodopQ5wADRs5-iE0WbrHPvqWkOtg@mail.gmail.com>
	<1439751747.3920.5.camel@brian-rcg>
Message-ID: <CA+oJuEHH47pBTOj2dkpjpaUsmnvqO8Je+nXM=ns3dspTheKCig@mail.gmail.com>

Set a seed.
Loop through months, using that seed to generate the integer value of your
lookback every month.
Loop through all unique integer lookback values.
Compute your indicator for those values.
Proceed as usual.

On Sun, Aug 16, 2015 at 3:02 PM, Brian G. Peterson <brian at braverock.com>
wrote:

> On Sun, 2015-08-16 at 20:19 +0300, Akane Fortuna wrote:
> > I am trying to test a strategy with random parameters that change every
> > month as some kind of a benchmark to compare my other strategies against.
> > This strategy is applied to the same instrument every month.  I tried to
> > make a loop with applystrategy(), where in each iteration the different
> > random parameter values are passed, and the next month's data is used.
> The
> > first iteration is executed without problems but I cannot make the next
> > iterations work.
> >
> > I want to be able to use chart.Posn(), tradeStats() (in consolidated
> form),
> > chart.ME(), getOrderBook(), getTxns() with the consolidated strategy
> > backtest.
> >
> > How should I go about doing this? No code is necessary for an answer,
> but I
> > appreciate it if there is. Just outline/plan of the code is sufficient.
> > Thank you.
>
> The challenge with what you're trying to do is that the indicators and
> signals are presumed to be vectorized functions.  So they are applied to
> the entire dataset at once.
>
> You're talking about subsetting the data by months, and applying
> different parameter values.
>
> If your indicators and signals don't have any lookback period, or are
> constant over the entire test, then you should be able to use a
> rebalance rule, which will subset the data and let you change things
> around on your rebalance periods.
>
> Assuming that's not the case, your options are somewhat more limited.
>
> You have no problems using the same portfolio and account over
> progressively increasing time periods.  You're basically just adding new
> transactions over time.
>
> The slightly challenging point will be in controlling the start and end
> periods for everything else.  You'll need to make sure you don't have
> signals before the start of the subset period, or after the end of the
> subset period.
>
> A minimal reproducible example would help others help you.
>
> Regards,
>
> Brian
>
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From markleeds2 at gmail.com  Mon Aug 17 19:25:10 2015
From: markleeds2 at gmail.com (Mark Leeds)
Date: Mon, 17 Aug 2015 13:25:10 -0400
Subject: [R-SIG-Finance] correction
Message-ID: <CAHz+bWb0=6A5weA9WZOA3C4GEGujpDPnwsinGG7H5X2HRK=o2g@mail.gmail.com>

Hi Eric: A friend of mine pointed out that my answer to your question about
constraining the regression is incorrect because the way I recommended
bounding the parameters won't guarantee feasibility.

Below is a small example that implements what I described but note that the
sum constraint won't necessarily hold if the other 2 parameters end up both
being greater than 0.5. ( it does in this example I created but that's just
fortunate ). So don't use my approach.

There are probably optimizers out there that handle sum constraints. One
that does but I have little experience with it is Ravi Varadhan's BB
package. Also, check out John Nash's book
if you have it because that gives nice coverage of a lot ( if not all ) of
all of the optimization packages available in R.

Or as you noted, there is probably an R package that estimates that type of
regression directly. Good luck and sorry for noise.

#====================================================================

set.seed(123)
x1 <- rnorm(1000)
x2 <- rnorm(1000)
x3 <- rnorm(1000)
y <- rnorm(1000, 2 + .5 * x1 + .3 * x2 + .2 * x3)

residsfunc <- function(par, x1,x2,x3,y) {
  Xmod <- cbind(par[1], par[2]*x1, par[3]*x2, (1-par[2]-par[3])*x3)
  sum((y - Xmod)^2)
}

mypar <- c(mean(y),0.9,0.9)

result <- optim(par = mypar, fn=residsfunc, method = "L-BFGS-B", lower =
c(0,0,0), upper = c(Inf,1,1),
      x1 = x1, x2 = x2, x3 = x3, y = y)

lastpar <- 1-result$par[2]-result$par[3]
print(c(result$par,lastpar))

	[[alternative HTML version deleted]]


From dominykasgrigonis at gmail.com  Mon Aug 17 20:12:14 2015
From: dominykasgrigonis at gmail.com (Dominykas Grigonis)
Date: Mon, 17 Aug 2015 19:12:14 +0100
Subject: [R-SIG-Finance] correction
In-Reply-To: <CAHz+bWb0=6A5weA9WZOA3C4GEGujpDPnwsinGG7H5X2HRK=o2g@mail.gmail.com>
References: <CAHz+bWb0=6A5weA9WZOA3C4GEGujpDPnwsinGG7H5X2HRK=o2g@mail.gmail.com>
Message-ID: <5DF2DA52-6163-4C54-8761-4063DBD36A9F@gmail.com>

One (very crude) approach would be to take DE or SA optimisers and introduce constraints like (a + b - 2)^1000 in your target SSE function

> On 17 Aug 2015, at 18:25, Mark Leeds <markleeds2 at gmail.com> wrote:
> 
> Hi Eric: A friend of mine pointed out that my answer to your question about
> constraining the regression is incorrect because the way I recommended
> bounding the parameters won't guarantee feasibility.
> 
> Below is a small example that implements what I described but note that the
> sum constraint won't necessarily hold if the other 2 parameters end up both
> being greater than 0.5. ( it does in this example I created but that's just
> fortunate ). So don't use my approach.
> 
> There are probably optimizers out there that handle sum constraints. One
> that does but I have little experience with it is Ravi Varadhan's BB
> package. Also, check out John Nash's book
> if you have it because that gives nice coverage of a lot ( if not all ) of
> all of the optimization packages available in R.
> 
> Or as you noted, there is probably an R package that estimates that type of
> regression directly. Good luck and sorry for noise.
> 
> #====================================================================
> 
> set.seed(123)
> x1 <- rnorm(1000)
> x2 <- rnorm(1000)
> x3 <- rnorm(1000)
> y <- rnorm(1000, 2 + .5 * x1 + .3 * x2 + .2 * x3)
> 
> residsfunc <- function(par, x1,x2,x3,y) {
>  Xmod <- cbind(par[1], par[2]*x1, par[3]*x2, (1-par[2]-par[3])*x3)
>  sum((y - Xmod)^2)
> }
> 
> mypar <- c(mean(y),0.9,0.9)
> 
> result <- optim(par = mypar, fn=residsfunc, method = "L-BFGS-B", lower =
> c(0,0,0), upper = c(Inf,1,1),
>      x1 = x1, x2 = x2, x3 = x3, y = y)
> 
> lastpar <- 1-result$par[2]-result$par[3]
> print(c(result$par,lastpar))
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From minger00 at gmx.de  Mon Aug 17 22:38:07 2015
From: minger00 at gmx.de (Mingersming)
Date: Mon, 17 Aug 2015 13:38:07 -0700 (PDT)
Subject: [R-SIG-Finance] VaR calculation warning with rugarch
In-Reply-To: <55D0C53E.6010105@4dscape.com>
References: <1439744120303-4711164.post@n4.nabble.com>
	<55D0C53E.6010105@4dscape.com>
Message-ID: <1439843887883-4711204.post@n4.nabble.com>

Okay, I thought there was a generally mistake by myself. Because I saw the
same warnings with my quantil approach. But now it?s clear, after I saw the
same warnings with your code. 
I was confused about the running time compared to the "easier"
distributions, and thought the calculation was stucked. I saw the CPU-usage
running down after a few minutes. So, i suggested the tasks run into a
overflow or something like that. 
For my clarity: the solver extract firstly the model parameters (with 100
percent CPU-usage) and calculate afterwards the quantile?

After some benchmarking I think the "nig" model takes 9x of the time it does
take to fit the "norm" model.

Thank you, for your quick response!

Best Re



--
View this message in context: http://r.789695.n4.nabble.com/VaR-calculation-warning-with-rugarch-tp4711164p4711204.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From aaron at quantrisktrading.com  Mon Aug 17 23:49:49 2015
From: aaron at quantrisktrading.com (Aaron Goldenberg)
Date: Mon, 17 Aug 2015 17:49:49 -0400
Subject: [R-SIG-Finance] [ANN] Rblpapi: Connecting R to Bloomberg
Message-ID: <CAG7y0grWfc3eKoxvJHmxod0Bb2VmLmmD1Zk2DXZ4iBCcVQiOcg@mail.gmail.com>

This is incredibly helpful! Thank you! Are there plans to include portfolio
calls in future releases? Is this something you would like help
implementing?

	[[alternative HTML version deleted]]


From edd at debian.org  Tue Aug 18 00:12:35 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 17 Aug 2015 17:12:35 -0500
Subject: [R-SIG-Finance] [ANN] Rblpapi: Connecting R to Bloomberg
In-Reply-To: <CAG7y0grWfc3eKoxvJHmxod0Bb2VmLmmD1Zk2DXZ4iBCcVQiOcg@mail.gmail.com>
References: <CAG7y0grWfc3eKoxvJHmxod0Bb2VmLmmD1Zk2DXZ4iBCcVQiOcg@mail.gmail.com>
Message-ID: <21970.23635.436248.361858@max.nulle.part>


On 17 August 2015 at 17:49, Aaron Goldenberg wrote:
| This is incredibly helpful! Thank you! Are there plans to include portfolio
| calls in future releases? Is this something you would like help
| implementing?

The documentation at 

   http://www.bloomberglabs.com/api/documentation/

is pretty good about what the API supports.

If there is something you would like to add, you could file an issue ticket
at our Github issue tracker

   https://github.com/Rblp/Rblpapi/issues

to start a discussion.  I don;t think we'll say No to useful additions.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From carlos.ungil at gmail.com  Tue Aug 18 23:15:26 2015
From: carlos.ungil at gmail.com (Carlos Ungil)
Date: Tue, 18 Aug 2015 23:15:26 +0200
Subject: [R-SIG-Finance] [ANN] Rblpapi: Connecting R to Bloomberg
In-Reply-To: <CAG7y0grWfc3eKoxvJHmxod0Bb2VmLmmD1Zk2DXZ4iBCcVQiOcg@mail.gmail.com>
References: <CAG7y0grWfc3eKoxvJHmxod0Bb2VmLmmD1Zk2DXZ4iBCcVQiOcg@mail.gmail.com>
Message-ID: <759D086C-7BE1-4C6A-9F9F-E2297557B972@gmail.com>

Hi Aaron,

You might find the files below useful as a starting point if you want to add this functionality (you?ll also have to add beqs and bport to NAMESPACE). This unfinished implementation can retrieve data from Bloomberg, but it still has to be converted properly to R data frames (or whatever structure makes sense depending on the type of response).

Best regards,

Carlos

> bport("U1234567-1 Client")
PortfolioDataResponse = {
    securityData[] = {
        securityData = {
            security = "U1234567-1 Client"
            eidData[] = {
            }
            fieldExceptions[] = {
            }
            sequenceNumber = 0
            fieldData = {
                PORTFOLIO_MEMBERS[] = {
                    PORTFOLIO_MEMBERS = {
                        Security = "..... Equity"
                    }
 ...... ...... ...... ...... ...... ...... ......

Error: Unsupported datatype: BLPAPI_DATATYPE_SEQUENCE.

> beqs("Insider Buyers","GLOBAL","Popular")
BeqsResponse = {
    data = {
        fieldDisplayUnits = {
            Ticker = ""
            Short Name = ""
            Market Cap = ""
            GICS Sector = ""
            Cntry = ""
        }
        securityData[] = {
            securityData = {
                security = "AAPL US"
                fieldExceptions[] = {
                }
                fieldData = {
                    Ticker = "AAPL US"
                    Short Name = "APPLE INC"
                    Market Cap = 667446607872.000000
                    GICS Sector = "Information Technology"
                    Cntry = "United States"
                }
            }
 ...... ...... ...... ...... ...... ...... ......

[1] Cntry       GICS Sector Market Cap  Short Name  Ticker     
<0 rows> (or 0-length row.names)


========
R/bport.R
========

bport <- function(portid, fields="MEMBERS", date=NULL, identity=NULL, con=.pkgenv$con) {
    if (!(fields %in% c("MEMBERS","MPOSITION","MWEIGHT","DATA"))) stop("Fields should be one of MEMBERS, MPOSITION, MWEIGHT, DATA.", call.=FALSE)
    bport_Impl(con, portid, paste("PORTFOLIO_",fields,sep=""), date, identity)
}

========
R/beqs.R
========

beqs <- function(name, type="PRIVATE", group=NULL, languageId=NULL, identity=NULL, con=.pkgenv$con) {
    if (!(type %in% c("PRIVATE","GLOBAL"))) stop("Type should be PRIVATE or GLOBAL.", call.=FALSE)
    beqs_Impl(con, name, type, group, languageId, identity)
}

========
src/bport.cpp
========

#include <iostream>
#include <vector>
#include <string>
#include <blpapi_session.h>
#include <blpapi_service.h>
#include <blpapi_request.h>
#include <blpapi_event.h>
#include <blpapi_message.h>
#include <blpapi_element.h>
#include <Rcpp.h>
#include <blpapi_utils.h>

using BloombergLP::blpapi::Session;
using BloombergLP::blpapi::Service;
using BloombergLP::blpapi::Request;
using BloombergLP::blpapi::Event;
using BloombergLP::blpapi::Element;
using BloombergLP::blpapi::Message;
using BloombergLP::blpapi::MessageIterator;

void getPortfolioDataResult(Event& event, LazyFrameT& lazy_frame) {
  Rcpp::List ans;
    MessageIterator msgIter(event);
    if (!msgIter.next()) {
        throw std::logic_error("Not a valid MessageIterator.");
    }
    Message msg = msgIter.message();
    msg.print(Rcpp::Rcerr);
    Element response = msg.asElement();
    if (std::strcmp(response.name().string(),"PortfolioDataResponse")) {
        throw std::logic_error("Not a valid PortfolioDataResponse.");
    }
    Element securityData = response.getElement("securityData");
    for (size_t i = 0; i < securityData.numValues(); ++i) {
        Element this_security = securityData.getValueAsElement(i);
        Element fieldData = this_security.getElement("fieldData");
        for(size_t j = 0; j < fieldData.numElements(); ++j) {
            Element e = fieldData.getElement(j);
            LazyFrameIteratorT iter = assertColumnDefined(lazy_frame,e,securityData.numValues());
            populateDfRow(iter->second,i,e);
        }
    }
}

// Simpler interface with std::vector<std::string> thanks to Rcpp::Attributes
//
// [[Rcpp::export]]
SEXP bport_Impl(SEXP con_, std::vector<std::string> securities, std::vector<std::string> fields, 
              SEXP date_, SEXP identity_) {

    // via Rcpp Attributes we get a try/catch block with error propagation to R "for free"
    Session* session = 
        reinterpret_cast<Session*>(checkExternalPointer(con_, "blpapi::Session*"));

    const std::string rdsrv = "//blp/refdata";
    if (!session->openService(rdsrv.c_str())) {
        Rcpp::stop("Failed to open " + rdsrv);
    }
    
    Service refDataService = session->getService(rdsrv.c_str());
    Request request = refDataService.createRequest("PortfolioDataRequest");
    request.getElement("securities").appendValue(securities[0].c_str());
    request.getElement("fields").appendValue(fields[0].c_str());
    if (date_ != R_NilValue) {
        Element overrides = request.getElement("overrides");
        Element override = overrides.appendElement();
        override.setElement("fieldId","REFERENCE_DATE");
        override.setElement("value", Rcpp::as<std::string>(date_).c_str());
    }
    sendRequestWithIdentity(session, request, identity_);

    LazyFrameT lazy_frame;

    while (true) {
        Event event = session->nextEvent();
        //REprintf("%d\n",event.eventType());
        switch (event.eventType()) {
        case Event::RESPONSE:
        case Event::PARTIAL_RESPONSE:
  	    getPortfolioDataResult(event, lazy_frame);
            break;
        default:
            MessageIterator msgIter(event);
            while (msgIter.next()) {
                Message msg = msgIter.message();
                //FIXME:: capture messages here for debugging
            }
        }
        if (event.eventType() == Event::RESPONSE) { break; }
    }
    return buildDataFrame(lazy_frame, false, false);
}

========
src/beqs.cpp
========

#include <iostream>
#include <vector>
#include <string>
#include <blpapi_session.h>
#include <blpapi_service.h>
#include <blpapi_request.h>
#include <blpapi_event.h>
#include <blpapi_message.h>
#include <blpapi_element.h>
#include <Rcpp.h>
#include <blpapi_utils.h>

using BloombergLP::blpapi::Session;
using BloombergLP::blpapi::Service;
using BloombergLP::blpapi::Request;
using BloombergLP::blpapi::Event;
using BloombergLP::blpapi::Element;
using BloombergLP::blpapi::Message;
using BloombergLP::blpapi::MessageIterator;

void getBeqsResult(Event& event, LazyFrameT& lazy_frame) {
    MessageIterator msgIter(event);
    if (!msgIter.next()) {
        throw std::logic_error("Not a valid MessageIterator.");
    }
    Message msg = msgIter.message();
    msg.print(Rcpp::Rcerr);
    Element response = msg.asElement();
    if (std::strcmp(response.name().string(),"BeqsResponse")) {
        throw std::logic_error("Not a valid BeqsResponse.");
    }
    if (msg.hasElement("responseError")){
      msg.print(Rcpp::Rcerr);
    }
    Element securityData = response.getElement("data").getElement("securityData");
    for (size_t i = 0; i < securityData.numValues(); ++i) {
        Element this_security = securityData.getValueAsElement(i);
        Element fieldData = this_security.getElement("fieldData");
        for(size_t j = 0; j < fieldData.numElements(); ++j) {
            Element e = fieldData.getElement(j);
            LazyFrameIteratorT iter = assertColumnDefined(lazy_frame,e,securityData.numValues());
            populateDfRow(iter->second,i,e);
        }
    }
}

// Simpler interface with std::vector<std::string> thanks to Rcpp::Attributes
//
// [[Rcpp::export]]
SEXP beqs_Impl(SEXP con_, std::string name, std::string type, 
              SEXP group_, SEXP languageId_, SEXP identity_) {

    // via Rcpp Attributes we get a try/catch block with error propagation to R "for free"
    Session* session = 
        reinterpret_cast<Session*>(checkExternalPointer(con_, "blpapi::Session*"));

    const std::string rdsrv = "//blp/refdata";
    if (!session->openService(rdsrv.c_str())) {
        Rcpp::stop("Failed to open " + rdsrv);
    }
    
    Service refDataService = session->getService(rdsrv.c_str());
    Request request = refDataService.createRequest("BeqsRequest");
    request.set ("screenName", name.c_str());
    request.set ("screenType", type.c_str());
    if (group_ != R_NilValue) {
        request.set ("Group", Rcpp::as<std::string>(group_).c_str());
    }
    if (languageId_ != R_NilValue) {
        request.set ("languageId", Rcpp::as<std::string>(languageId_).c_str());
    }
    sendRequestWithIdentity(session, request, identity_);

    LazyFrameT lazy_frame;

    while (true) {
        Event event = session->nextEvent();
        //REprintf("%d\n",event.eventType());
        switch (event.eventType()) {
        case Event::RESPONSE:
        case Event::PARTIAL_RESPONSE:
	    getBeqsResult(event, lazy_frame);
            break;
        default:
            MessageIterator msgIter(event);
            while (msgIter.next()) {
                Message msg = msgIter.message();
                //FIXME:: capture messages here for debugging
            }
        }
        if (event.eventType() == Event::RESPONSE) { break; }
    }
    return buildDataFrame(lazy_frame, false, false);
}


> On 17 Aug 2015, at 23:49, Aaron Goldenberg <aaron at quantrisktrading.com> wrote:
> 
> This is incredibly helpful! Thank you! Are there plans to include portfolio
> calls in future releases? Is this something you would like help
> implementing?
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From john.b.gavin at gmail.com  Wed Aug 19 08:06:08 2015
From: john.b.gavin at gmail.com (john gavin)
Date: Wed, 19 Aug 2015 06:06:08 +0000
Subject: [R-SIG-Finance] [ANN] Rblpapi: Connecting R to Bloomberg
Message-ID: <DB5PR09MB0183A2DE30F49C47C228F671CD670@DB5PR09MB0183.eurprd09.prod.outlook.com>

Kudos to the authors for this package which worked out-of-the-box for me at work.

Regards,

John.

From: Dirk Eddelbuettel <edd <at> debian.org<http://debian.org>>
Subject: [ANN] Rblpapi: Connecting R to Bloomberg<http://news.gmane.org/find-root.php?message_id=21968.48842.98787.918780%40max.nulle.part>
Newsgroups: gmane.comp.lang.r.r-metrics<http://news.gmane.org/gmane.comp.lang.r.r-metrics>
Date: 2015-08-16 16:48:10 GMT (2 days, 13 hours and 13 minutes ago)

[ This is an ascii version of Friday's blog post at
     http://dirk.eddelbuettel.com/blog/2015/08/14#rblpapi_0.3.0
  which you should go to for the links and colour highlighting. The CRAN
  sites now carry Windows and OS X (Mavericks) binary packages.  -- Dirk ]

   Rblpapi: Connecting R to Bloomberg

   Whit, John and I are thrilled to announce Rblapi, a new CRAN package which
   connects R to the Bloomberg backends.

...

	[[alternative HTML version deleted]]


From assis.duraes at gmail.com  Thu Aug 20 15:57:38 2015
From: assis.duraes at gmail.com (Assis Duraes)
Date: Thu, 20 Aug 2015 10:57:38 -0300
Subject: [R-SIG-Finance] Adding external regressors on conditional variance
	model
Message-ID: <CAK9d7gFqXYtia=nnHTR=k=bLTjMFruF+X664pmANJacs9b-Wsw@mail.gmail.com>

Hi,

first of all I would like to thanks for the rugarch package. it is really
useful and a very nice package.

I am investigating the effect of external variables on conditional variance
models forecasts. more specifically, I am would like to check if the
addition of implied volatility and realized variance as external regressors
on a GJR (1,1) model somehow enhance the daily volatility forecasts of it.

Looking for a tool to help modelling it I found the rugarch package, and
started looking into it. In fact, at this point, I believe I have a very
basic question. but did not find an answer on previous posts or in the
package documentation.

Should I inform the external regressors matrix in model spec already lagged
or not? I imagine, yes, since I did not find in any place where specify the
lags for those regressors, but would like to confirm. In case affirmative,
If I want to use a same variable with different lags I need to inform it
multiple times, obviously with different lags, in external.regressors
matrix, correct?

My apologies in advance if it is explained somewhere, but as I explained, i
search without much success..

Thanks in advance for any help with that,
Assis.

	[[alternative HTML version deleted]]


From alexios at 4dscape.com  Thu Aug 20 16:01:28 2015
From: alexios at 4dscape.com (alexios)
Date: Thu, 20 Aug 2015 15:01:28 +0100
Subject: [R-SIG-Finance] Adding external regressors on conditional
 variance model
In-Reply-To: <CAK9d7gFqXYtia=nnHTR=k=bLTjMFruF+X664pmANJacs9b-Wsw@mail.gmail.com>
References: <CAK9d7gFqXYtia=nnHTR=k=bLTjMFruF+X664pmANJacs9b-Wsw@mail.gmail.com>
Message-ID: <55D5DDB8.503@4dscape.com>

Hi,

The answer is yes and yes. Add variable(s) lagged.

Best,

Alexios

On 20/08/2015 14:57, Assis Duraes wrote:
> Hi,
>
> first of all I would like to thanks for the rugarch package. it is really
> useful and a very nice package.
>
> I am investigating the effect of external variables on conditional variance
> models forecasts. more specifically, I am would like to check if the
> addition of implied volatility and realized variance as external regressors
> on a GJR (1,1) model somehow enhance the daily volatility forecasts of it.
>
> Looking for a tool to help modelling it I found the rugarch package, and
> started looking into it. In fact, at this point, I believe I have a very
> basic question. but did not find an answer on previous posts or in the
> package documentation.
>
> Should I inform the external regressors matrix in model spec already lagged
> or not? I imagine, yes, since I did not find in any place where specify the
> lags for those regressors, but would like to confirm. In case affirmative,
> If I want to use a same variable with different lags I need to inform it
> multiple times, obviously with different lags, in external.regressors
> matrix, correct?
>
> My apologies in advance if it is explained somewhere, but as I explained, i
> search without much success..
>
> Thanks in advance for any help with that,
> Assis.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.
>
>


From assis.duraes at gmail.com  Thu Aug 20 19:19:06 2015
From: assis.duraes at gmail.com (Assis Duraes)
Date: Thu, 20 Aug 2015 14:19:06 -0300
Subject: [R-SIG-Finance] Adding external regressors on conditional
 variance model
In-Reply-To: <55D5DDB8.503@4dscape.com>
References: <CAK9d7gFqXYtia=nnHTR=k=bLTjMFruF+X664pmANJacs9b-Wsw@mail.gmail.com>
	<55D5DDB8.503@4dscape.com>
Message-ID: <CAK9d7gG91StSNvaS3eQE8ETZP42rccpbQa71XDeTW_oWd9FtgQ@mail.gmail.com>

Thank you very much for your prompt answer and help, Alexios.

I am running now some models and found some results that are puzzling me.

>From another thread I saw one recommendation that we should "(...) pass
values in the external regressor which are close in scale to the variance
equation", what makes sense to me...

However, I noticed that when I define the external regressors with values
close to the return series, the coefficients calculated for the external
regressors are non-significant, while I have a strong hypothesis that those
should be relevant in the process. Nevertheless, I noticed that when
scaling to an annual basis the external regressor coefficients becomes
significant...


Attached follow a sample code (sample_gjr_extregressor.R) and simplified
database (data.txt) with daily returns (r) and lagged realized variance
(lag_extreg) I am using as inputs for the models.



There are three models as below:

Model1: Standard GJR
Model2: GJR with lagged daily realized variance
Model3: GJR with lagged  realized variance annualized (scaled by 252)

The table below summarizes the results found.

model omega alpha1 beta1 gamma1       delta1 p-val_omega p-val_alpha1
p-val_beta1 p-val_gamma1 p-val_delta1 LL For_01d
Model1 0.011449 0.131705 0.89924 -0.08386    NA 0.001217 0.000000 0.000000
0.000012 0.000000 -2033.96 0.800619
Model2 0.011449 0.131705 0.899244 -0.08387 1.23E-08 0.002944 0.000000
0.000000 0.000012 0.999999 -2033.96 0.800635
Model3 0.004839 0.066382 0.69109 -0.08387 0.001161 0.633308 0.037429
0.000000 0.010968 0.000451 -2012.57 0.778901

Any idea or suggestion on what might be happening?

Thanks again in advance for any help with that issue.

Best Regards,
Assis.



2015-08-20 11:01 GMT-03:00 alexios <alexios at 4dscape.com>:

> Hi,
>
> The answer is yes and yes. Add variable(s) lagged.
>
> Best,
>
> Alexios
>
>
> On 20/08/2015 14:57, Assis Duraes wrote:
>
>> Hi,
>>
>> first of all I would like to thanks for the rugarch package. it is really
>> useful and a very nice package.
>>
>> I am investigating the effect of external variables on conditional
>> variance
>> models forecasts. more specifically, I am would like to check if the
>> addition of implied volatility and realized variance as external
>> regressors
>> on a GJR (1,1) model somehow enhance the daily volatility forecasts of it.
>>
>> Looking for a tool to help modelling it I found the rugarch package, and
>> started looking into it. In fact, at this point, I believe I have a very
>> basic question. but did not find an answer on previous posts or in the
>> package documentation.
>>
>> Should I inform the external regressors matrix in model spec already
>> lagged
>> or not? I imagine, yes, since I did not find in any place where specify
>> the
>> lags for those regressors, but would like to confirm. In case affirmative,
>> If I want to use a same variable with different lags I need to inform it
>> multiple times, obviously with different lags, in external.regressors
>> matrix, correct?
>>
>> My apologies in advance if it is explained somewhere, but as I explained,
>> i
>> search without much success..
>>
>> Thanks in advance for any help with that,
>> Assis.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20150820/9b72d69b/attachment.html>
-------------- next part --------------
Date	r	lag_extreg
02-Jan-09	0.138163314	0.891127064
05-Jan-09	-3.535023066	1.870274188
06-Jan-09	-2.750700196	3.583100836
07-Jan-09	4.100392146	12.22858343
08-Jan-09	1.192369028	4.608871622
09-Jan-09	-1.829426571	6.547163751
12-Jan-09	2.731740518	6.090715266
13-Jan-09	0.051808999	3.492098049
14-Jan-09	2.291398015	5.32220453
15-Jan-09	-0.685745999	4.945541386
16-Jan-09	-1.020351671	3.800733908
19-Jan-09	0.98636552	2.318998273
20-Jan-09	0.896753186	1.411689395
21-Jan-09	-1.58746967	6.840925463
22-Jan-09	-0.721373732	1.160404717
23-Jan-09	0.395682422	1.840062275
26-Jan-09	-0.300920182	2.177548385
27-Jan-09	0.844574269	1.477195152
28-Jan-09	-3.06475949	1.397076051
29-Jan-09	0.955058517	2.482112626
30-Jan-09	1.278041873	2.568164406
02-Feb-09	-0.357936428	3.894530914
03-Feb-09	-0.411264893	2.726199461
04-Feb-09	0.099724681	1.324063693
05-Feb-09	-1.098098097	4.080999816
06-Feb-09	-1.714655999	1.360838912
09-Feb-09	0.68408227	1.927188295
10-Feb-09	2.206647918	1.431861352
11-Feb-09	-1.751710184	2.908787946
12-Feb-09	1.656397812	2.851444828
13-Feb-09	-2.328490897	2.544408025
16-Feb-09	0.883397971	2.114957664
17-Feb-09	2.835409091	0.420505528
18-Feb-09	0.664624123	2.000253048
19-Feb-09	0.795131917	2.045781673
20-Feb-09	0.407794902	2.213205729
25-Feb-09	-0.605985947	1.761959293
26-Feb-09	-0.57146641	15.95704868
27-Feb-09	1.307428687	1.078583361
02-Mar-09	2.511561709	2.100746576
03-Mar-09	-1.241690158	2.976018177
04-Mar-09	-2.005833828	2.53519926
05-Mar-09	1.003767274	1.669571252
06-Mar-09	-0.733986728	2.94231352
09-Mar-09	0.449420081	2.418813363
10-Mar-09	-2.237571105	1.444436926
11-Mar-09	0.29099644	1.108398503
12-Mar-09	-1.91985879	0.945832651
13-Mar-09	0.412963268	1.309161738
16-Mar-09	-0.915158695	1.41050858
17-Mar-09	-0.074452015	2.223559703
18-Mar-09	-1.456336419	0.783295028
19-Mar-09	0.306265358	2.599216014
20-Mar-09	0.600920861	2.367254608
23-Mar-09	-1.111885472	1.075024953
24-Mar-09	0.191362066	1.702283445
25-Mar-09	-0.508135704	0.944766224
26-Mar-09	0.490350022	1.397093033
27-Mar-09	1.863531097	1.544092219
30-Mar-09	1.726530847	1.940811503
31-Mar-09	-0.352400554	2.099328709
01-Apr-09	-2.13209138	1.800637715
02-Apr-09	-1.891288338	1.317965107
03-Apr-09	-0.968279762	2.050233381
06-Apr-09	0.58659134	1.327849068
07-Apr-09	-0.319942593	0.851663196
08-Apr-09	-0.561239818	1.176631696
09-Apr-09	-1.47229581	0.910995568
13-Apr-09	0.092081038	0.667451881
14-Apr-09	1.625012936	0.716143084
15-Apr-09	-1.142973669	0.931739827
16-Apr-09	-0.431430814	0.964987248
17-Apr-09	0.965837275	1.095237611
20-Apr-09	2.363431262	0.963487902
22-Apr-09	-1.664349927	1.675020317
23-Apr-09	-0.235507355	1.064367068
24-Apr-09	-0.984241974	1.139316005
27-Apr-09	1.80610255	2.216761089
28-Apr-09	-1.030657347	1.832345521
29-Apr-09	-0.96795569	2.512465818
30-Apr-09	0.494280183	1.131696016
04-May-09	-3.54076852	1.459229831
05-May-09	1.030524613	2.685220578
06-May-09	-1.054177017	3.974039231
07-May-09	-0.11360948	1.251728588
08-May-09	-2.420961458	1.491902609
11-May-09	0.339098324	1.829493959
12-May-09	0.130488383	0.732377794
13-May-09	2.079176344	1.577307033
14-May-09	-1.323765819	1.720931796
15-May-09	1.385241715	1.397834124
18-May-09	-2.135822606	2.047973102
19-May-09	-1.469255328	0.97777431
20-May-09	-0.33874207	2.469151582
21-May-09	-0.118092815	1.274762495
22-May-09	-0.206998595	1.463674103
25-May-09	0.02466517	1.428561532
26-May-09	-1.026260216	0.54420821
27-May-09	1.670329405	1.518735247
28-May-09	-1.87984759	1.493216944
29-May-09	-1.626133952	2.482699446
01-Jun-09	-0.938303671	9.166328144
02-Jun-09	-1.481355639	2.271825597
03-Jun-09	2.145199164	0.976171673
04-Jun-09	-1.383715	1.927168351
05-Jun-09	1.21561777	1.557842179
08-Jun-09	0.091724426	3.445882716
09-Jun-09	-0.987902488	1.610700351
10-Jun-09	0.174744352	1.173124693
12-Jun-09	-1.104983619	1.441942612
15-Jun-09	1.248661804	1.686982134
16-Jun-09	1.18766847	0.808459179
17-Jun-09	-0.147055121	1.174125346
18-Jun-09	0.071019127	5.816623774
19-Jun-09	0.167202937	1.605362958
22-Jun-09	2.864467303	1.58821996
23-Jun-09	-2.65711901	1.637358069
24-Jun-09	-0.430347726	1.600274867
25-Jun-09	-1.446300923	1.703917868
26-Jun-09	-0.324834646	1.148972358
29-Jun-09	1.048044527	2.811548278
30-Jun-09	-0.250735708	0.987099693
01-Jul-09	-0.993752225	1.49375028
02-Jul-09	1.193368414	1.135993713
03-Jul-09	-0.117674159	0.901814644
06-Jul-09	-0.04608413	0.446046285
07-Jul-09	2.278579593	0.940350821
08-Jul-09	0.284950327	1.527387025
10-Jul-09	-0.370092946	3.020884979
13-Jul-09	-0.885763214	2.786941461
14-Jul-09	-0.898779757	0.903490485
15-Jul-09	-1.412634252	0.967392433
16-Jul-09	-0.062098946	1.037556556
17-Jul-09	-0.295497766	0.856516969
20-Jul-09	-1.364334694	0.805632622
21-Jul-09	-0.121125959	1.290197508
22-Jul-09	0.320926226	0.67237049
23-Jul-09	-0.24717991	0.523678377
24-Jul-09	-0.17391767	0.708218324
27-Jul-09	-1.183257379	0.672625611
28-Jul-09	0.394204644	0.552118148
29-Jul-09	0.667658267	0.476395268
30-Jul-09	-0.556071868	1.11963809
31-Jul-09	-0.955157871	0.472734345
03-Aug-09	-2.173468393	0.644333765
04-Aug-09	-0.477852226	1.031172103
05-Aug-09	-0.148764456	1.062404595
06-Aug-09	1.542953409	0.888224845
07-Aug-09	-1.174203164	1.108138044
10-Aug-09	1.114461139	1.431021864
11-Aug-09	0.449901835	0.870816612
12-Aug-09	-0.553176746	0.807332009
13-Aug-09	-0.824578051	0.963665745
14-Aug-09	1.345299557	1.3113212
17-Aug-09	1.732364795	1.260609385
18-Aug-09	-1.954424626	4.045874101
19-Aug-09	-0.15193448	1.364458487
20-Aug-09	0.146512222	1.340515447
21-Aug-09	-0.778425857	0.965885685
24-Aug-09	0.60475817	0.762751637
25-Aug-09	1.112743076	0.339127542
26-Aug-09	0.021484585	0.471330122
27-Aug-09	0.257455624	0.642322689
28-Aug-09	0.7684136	1.200640156
31-Aug-09	-0.042535092	0.844051983
01-Sep-09	1.755402077	1.625685193
02-Sep-09	-1.436829013	1.828916417
03-Sep-09	-1.393248576	1.878714224
04-Sep-09	-0.869218592	1.068848521
08-Sep-09	-0.79482154	0.92772783
09-Sep-09	0.229295291	1.080152582
10-Sep-09	-1.278726641	0.577361282
11-Sep-09	1.104073174	0.726602705
14-Sep-09	-0.993667422	0.96930801
15-Sep-09	-0.486699705	0.658699951
16-Sep-09	-0.055456967	0.540058871
17-Sep-09	0.155202071	0.540100869
18-Sep-09	0.149431359	0.877147238
21-Sep-09	0.908371464	0.291050502
22-Sep-09	-1.758116934	0.437379546
23-Sep-09	0.284051543	0.630971416
24-Sep-09	0.122283379	0.68255509
25-Sep-09	-0.562628563	1.023445316
28-Sep-09	-0.162133488	1.029832718
29-Sep-09	0.055937799	0.473420634
30-Sep-09	-1.192633398	0.384963688
01-Oct-09	1.103117895	1.532046002
02-Oct-09	-0.257804324	0.782554512
05-Oct-09	-1.253616282	1.270088585
06-Oct-09	-0.011365574	0.693025865
07-Oct-09	-0.632823297	0.764666337
08-Oct-09	-0.694427308	1.293342993
09-Oct-09	0.264565634	0.646776995
13-Oct-09	-1.12055698	0.487454555
14-Oct-09	-1.209656825	0.765324655
15-Oct-09	0.005879068	0.541703318
16-Oct-09	0.52770571	0.57551492
19-Oct-09	0.449281615	1.617788353
20-Oct-09	2.131171547	0.802515096
21-Oct-09	-1.157871471	2.95208147
22-Oct-09	-0.926737012	1.22172039
23-Oct-09	-0.06985273	0.714914208
26-Oct-09	0.898530726	0.511178415
27-Oct-09	0.690133864	0.822587868
28-Oct-09	1.958009263	1.187864059
29-Oct-09	-2.648143127	2.100076506
30-Oct-09	1.625679763	3.007455352
03-Nov-09	-0.947009188	2.106877969
04-Nov-09	-1.379411824	1.755919356
05-Nov-09	-0.244385086	0.81669933
06-Nov-09	0.215322922	0.510061259
09-Nov-09	-1.245958033	0.781872117
10-Nov-09	0.750604591	1.029600429
11-Nov-09	0.37902025	0.6957342
12-Nov-09	1.024877967	0.757758841
13-Nov-09	-0.774928699	0.979536585
16-Nov-09	-0.599763058	0.944411076
17-Nov-09	-0.029206461	0.411111682
18-Nov-09	0.802983484	0.726227965
19-Nov-09	0.075312114	0.795870844
23-Nov-09	-0.017374685	0.93797048
24-Nov-09	0.277633355	1.333491215
25-Nov-09	-0.532809507	0.468641114
26-Nov-09	1.42983122	0.627062621
27-Nov-09	-0.349801085	1.092791322
30-Nov-09	0.852286011	1.657184218
01-Dec-09	-2.013645302	0.493588498
02-Dec-09	-0.122117888	0.758074764
03-Dec-09	-0.484121217	0.516197976
04-Dec-09	1.231929114	0.580948387
07-Dec-09	0.121208638	1.282327935
08-Dec-09	1.624935627	0.637335388
09-Dec-09	0.011350094	0.941754206
10-Dec-09	-0.312597941	1.556356335
11-Dec-09	0.102412389	1.098777195
14-Dec-09	-0.684738767	0.960082995
15-Dec-09	0.314420725	0.753568582
16-Dec-09	0.245133093	1.154156945
17-Dec-09	1.441476586	0.42532121
18-Dec-09	-0.089837176	1.457599647
21-Dec-09	0.246858294	1.095252679
22-Dec-09	-0.207544598	0.592098336
23-Dec-09	-1.180504545	0.364770702
28-Dec-09	-1.039474777	0.738622324
29-Dec-09	-0.06317301	0.69741869
30-Dec-09	0.051689976	1.09377442
04-Jan-10	-1.247994011	1.247999874
05-Jan-10	0.614387837	0.802708398
06-Jan-10	0.0231107	0.607645845
07-Jan-10	0.891450907	0.639108673
08-Jan-10	-1.157546974	1.132716984
11-Jan-10	0.62938684	0.789364381
12-Jan-10	0.636890009	0.764722785
13-Jan-10	0.484980838	1.426324153
14-Jan-10	0.187654657	1.126467639
15-Jan-10	0.685069912	1.732173519
18-Jan-10	-0.452412693	2.048328824
19-Jan-10	0.328203101	1.509680499
20-Jan-10	1.050896181	1.452878717
21-Jan-10	0.790694024	1.096286432
22-Jan-10	1.196364574	1.18680499
26-Jan-10	0.579236592	2.101541733
27-Jan-10	1.229268451	0.860440748
28-Jan-10	0.750673766	1.390705619
29-Jan-10	1.221146048	0.982245078
01-Feb-10	-2.506075422	1.152370265
02-Feb-10	-1.000606532	1.213644396
03-Feb-10	1.23840592	0.927419976
04-Feb-10	1.308540149	1.071246707
05-Feb-10	0.12778874	2.36511966
08-Feb-10	-0.202407654	2.24620156
09-Feb-10	-1.515017696	1.191309401
10-Feb-10	0.48062736	1.165899057
11-Feb-10	-0.697394366	0.891801955
12-Feb-10	0.600375008	0.828340472
17-Feb-10	-1.30266714	1.184240026
18-Feb-10	-1.187088022	4.007677867
19-Feb-10	-0.337810096	0.574771192
22-Feb-10	0.475927849	1.025553243
23-Feb-10	0.857572184	0.462704632
24-Feb-10	-0.125975643	0.457520088
25-Feb-10	-0.043854841	0.296652631
26-Feb-10	-0.892223796	0.546707282
01-Mar-10	-0.54363034	0.661810095
02-Mar-10	-0.278505165	0.403052437
03-Mar-10	-0.072538574	0.493735899
04-Mar-10	-0.173189239	0.560858074
05-Mar-10	-0.571974867	0.629101289
08-Mar-10	0.577566301	0.554172487
09-Mar-10	-0.718256833	0.551835227
10-Mar-10	-0.389336082	0.579443518
11-Mar-10	-0.277408393	0.413792758
12-Mar-10	-0.085075013	0.399010368
15-Mar-10	0.113417274	0.462068453
16-Mar-10	0.169885085	0.251406437
17-Mar-10	-0.022634676	0.542578394
18-Mar-10	1.388169649	0.302935595
19-Mar-10	0.556577382	0.671347879
22-Mar-10	-0.66826556	0.586408135
23-Mar-10	-0.762805875	0.72897494
24-Mar-10	1.403316015	0.304972318
25-Mar-10	0.988876384	0.706105255
26-Mar-10	-0.005497375	0.732003584
29-Mar-10	-1.356046793	0.818797823
30-Mar-10	-0.256667924	0.505916201
31-Mar-10	-0.481631755	0.576220578
01-Apr-10	-0.941939901	0.44191496
05-Apr-10	-0.158802211	0.278555727
06-Apr-10	-0.495036432	0.427802546
07-Apr-10	1.595778544	0.385821721
08-Apr-10	-0.022458032	0.529649775
09-Apr-10	-0.953489692	0.618875071
12-Apr-10	-0.614126802	0.570365918
13-Apr-10	-0.211265674	0.21247632
14-Apr-10	-0.228898526	0.354227677
15-Apr-10	0.188879088	0.559395373
16-Apr-10	0.536071999	0.911305303
19-Apr-10	-0.239166448	0.827851735
20-Apr-10	-0.17689525	0.457419729
22-Apr-10	0.734063102	0.352171358
23-Apr-10	-0.414737975	0.354604207
26-Apr-10	-0.570940746	0.400548921
27-Apr-10	1.409995501	0.38734135
28-Apr-10	-1.295546276	0.831867315
29-Apr-10	-1.196723332	0.780956518
30-Apr-10	0.674918197	1.290317027
03-May-10	-0.715442701	0.715278956
04-May-10	2.165157035	0.392088176
05-May-10	1.702336118	1.046981118
06-May-10	3.287787227	1.404448686
07-May-10	-0.926057903	6.941222117
10-May-10	-3.713366513	5.546746176
11-May-10	1.089469977	12.12253461
12-May-10	-0.914580649	1.064063723
13-May-10	0.084514189	0.531297619
14-May-10	1.32593064	0.446387304
17-May-10	0.072224232	1.805674234
18-May-10	1.17599699	2.129676479
19-May-10	0.323314527	1.687094286
20-May-10	3.007178153	3.975147206
21-May-10	-1.616304922	8.243621378
24-May-10	0.913052157	3.733809295
25-May-10	-1.361883517	1.638283099
26-May-10	1.431363224	7.555799056
27-May-10	-3.059636549	2.500878899
28-May-10	0.099108036	4.164283019
31-May-10	0.208906068	1.609531702
01-Jun-10	1.46648579	6.570456974
02-Jun-10	-1.647879271	1.560035042
04-Jun-10	2.595855777	1.333501226
07-Jun-10	0.768988089	1.433291831
08-Jun-10	-1.365812185	1.086852577
09-Jun-10	-0.226757467	1.36433715
10-Jun-10	-2.495614658	0.919425471
11-Jun-10	0.342996574	1.316890054
14-Jun-10	0.022088464	0.703856053
15-Jun-10	-1.31163999	1.223233044
16-Jun-10	-0.011189437	0.576633223
17-Jun-10	-0.398038367	1.119865896
18-Jun-10	-0.456043354	0.74258605
21-Jun-10	-0.050800103	0.385714602
22-Jun-10	0.944039378	1.774433773
23-Jun-10	-0.039157554	0.836595151
24-Jun-10	-0.207230744	1.157956027
25-Jun-10	-0.190807623	0.977592469
28-Jun-10	0.005617189	0.849937239
29-Jun-10	1.84216468	0.524885517
30-Jun-10	-0.480916324	1.911145799
01-Jul-10	-0.756441674	1.064221435
02-Jul-10	-1.066467225	0.998353246
05-Jul-10	0.298633832	0.63174139
06-Jul-10	0.123699763	0.182523061
07-Jul-10	-0.687907985	0.685294773
08-Jul-10	-0.391168049	0.479480396
12-Jul-10	0.011359764	0.480472247
13-Jul-10	-0.210364805	0.406150684
14-Jul-10	0.318218248	0.349278364
15-Jul-10	0.017018863	0.356014293
16-Jul-10	1.083226389	0.819392489
19-Jul-10	0.587463574	0.551419258
20-Jul-10	-1.031746284	0.509499826
21-Jul-10	0.371308443	0.435322298
22-Jul-10	-1.282902107	0.324032118
23-Jul-10	0.889045749	0.720679156
26-Jul-10	-0.644762145	1.19676255
27-Jul-10	0.271985662	0.403129463
28-Jul-10	0.101804205	0.509824796
29-Jul-10	-0.623761591	0.440412002
30-Jul-10	-0.176492403	0.522510284
02-Aug-10	-0.165388272	1.362628183
03-Aug-10	0.307745157	0.86583011
04-Aug-10	-0.296330283	0.357410258
05-Aug-10	-0.02283105	0.31525815
06-Aug-10	0.518121124	0.245060479
09-Aug-10	-0.683802311	0.331125188
10-Aug-10	0.25697413	0.214906016
11-Aug-10	1.213098035	0.353321517
12-Aug-10	-0.287769983	0.47311397
13-Aug-10	0.129881149	0.399604222
16-Aug-10	-0.986794147	0.250244175
17-Aug-10	-0.011399259	0.196355918
18-Aug-10	-0.074126874	0.26064696
19-Aug-10	0.136806725	0.386516141
20-Aug-10	0.039866732	0.254708673
23-Aug-10	0.782716264	0.255267067
24-Aug-10	0.028244598	0.310145577
25-Aug-10	-0.396152188	0.495092096
26-Aug-10	-0.090769848	0.355264427
27-Aug-10	-0.671984305	0.210181935
30-Aug-10	0.529991268	0.231118603
31-Aug-10	-0.199129585	0.272103315
01-Sep-10	-0.565408857	0.250637813
02-Sep-10	-1.152086476	0.437139456
03-Sep-10	0.39320046	0.276849372
06-Sep-10	-0.352652483	0.562133677
08-Sep-10	-0.02316826	0.482219275
09-Sep-10	-0.348169562	0.390855932
10-Sep-10	0.110384906	0.241488525
13-Sep-10	-0.675835712	0.155416995
14-Sep-10	-0.040929689	0.147297015
15-Sep-10	0.798023749	0.295409266
16-Sep-10	-0.686967829	0.679337086
17-Sep-10	0.553437083	0.241602008
20-Sep-10	0.683189318	0.2067519
21-Sep-10	-1.29506151	0.473906088
22-Sep-10	0.43743326	0.224303948
23-Sep-10	0.273152758	0.580150365
24-Sep-10	-0.70474097	0.254903446
27-Sep-10	-0.017536168	0.252715915
28-Sep-10	-0.157964052	0.222463504
29-Sep-10	-0.410702291	0.184445198
30-Sep-10	-0.802790452	0.227391272
01-Oct-10	0.142138016	0.698484755
04-Oct-10	0.484119496	0.574950848
05-Oct-10	-2.064873578	0.531089396
06-Oct-10	0.933579492	0.552048037
07-Oct-10	0.136908858	0.903088023
08-Oct-10	-0.89627751	0.661442204
11-Oct-10	0.227817844	0.561971993
13-Oct-10	-1.017192556	0.233191396
14-Oct-10	0.43462582	0.32669685
15-Oct-10	0.294710465	0.565758329
18-Oct-10	0.533079038	0.540907044
19-Oct-10	0.518367413	0.770176257
20-Oct-10	-0.309505634	1.765631874
21-Oct-10	1.149846713	0.337621031
22-Oct-10	0.517252667	0.638838151
25-Oct-10	-0.593892317	0.528603116
26-Oct-10	0.470699857	0.707220181
27-Oct-10	1.039425417	0.489858843
28-Oct-10	-1.004212082	0.536050259
29-Oct-10	-0.29970933	0.425636184
01-Nov-10	0.229270257	0.439215692
03-Nov-10	-0.778122294	0.351650626
04-Nov-10	-1.13076251	0.665568237
05-Nov-10	0.543171419	0.402785623
08-Nov-10	1.207043825	0.371423427
09-Nov-10	0.058795862	0.596586853
10-Nov-10	0.387188094	0.287417177
11-Nov-10	0.455661496	0.546037976
12-Nov-10	0.378138267	0.315336725
16-Nov-10	1.120168766	0.582155588
17-Nov-10	-0.847633733	0.592744112
18-Nov-10	-0.895771462	0.455839689
19-Nov-10	0.239269467	0.418747035
22-Nov-10	0.349121732	0.283751872
23-Nov-10	0.815669926	0.704528714
24-Nov-10	-0.815669926	0.483638202
25-Nov-10	0	0.293524245
26-Nov-10	0.365270735	0.138812641
29-Nov-10	-0.545498103	0.432134128
30-Nov-10	-0.244698328	0.332130052
01-Dec-10	-0.549837604	0.339401256
02-Dec-10	-0.505704947	0.198032862
03-Dec-10	-0.549760496	0.226468658
06-Dec-10	-0.719834156	0.253304634
07-Dec-10	0.411118641	0.326741268
08-Dec-10	0.504137956	0.453023
09-Dec-10	1.176276575	0.414963262
10-Dec-10	-0.193134991	0.515202495
13-Dec-10	-0.77038812	0.490140316
14-Dec-10	0.206410594	0.261323455
15-Dec-10	0.710326154	0.30852377
16-Dec-10	-0.398570365	0.253534529
17-Dec-10	0.678960759	0.258202913
20-Dec-10	-0.450174691	0.409967353
21-Dec-10	-0.658438593	0.205878291
22-Dec-10	0.288600489	0.209654409
23-Dec-10	-0.530724208	0.222940991
27-Dec-10	-0.319791816	0.134635084
28-Dec-10	0.33161634	0.319156427
29-Dec-10	-0.753645676	0.332548118
30-Dec-10	-1.126165011	0.267403066
03-Jan-11	-0.774072564	0.730564937
04-Jan-11	0.80418851	0.399610492
05-Jan-11	0.803747129	0.692324537
06-Jan-11	0.773629186	0.379219713
07-Jan-11	-0.172060916	0.626144208
10-Jan-11	0.302392688	0.541629085
11-Jan-11	-0.320209002	0.307475847
12-Jan-11	-0.61362678	0.233212782
13-Jan-11	-0.047818291	0.200292088
14-Jan-11	0.744560726	0.198596195
17-Jan-11	-0.273354104	0.574604727
18-Jan-11	-0.363647603	0.157202463
19-Jan-11	-0.215233851	0.222775744
20-Jan-11	0.161468803	0.205027859
21-Jan-11	0.250656612	0.252380306
24-Jan-11	-0.412125415	0.224234272
26-Jan-11	-0.16772497	0.333746061
27-Jan-11	0.502333313	0.162436114
28-Jan-11	0.392927814	0.326643582
31-Jan-11	-0.955231144	0.281173107
01-Feb-11	-0.156090564	0.950056226
02-Feb-11	0.168087445	0.188147657
03-Feb-11	0.05396816	0.165262369
04-Feb-11	0.335149036	0.184367578
07-Feb-11	0.345938553	0.312514294
08-Feb-11	-0.891127574	0.292361072
09-Feb-11	-0.318902764	0.525794993
10-Feb-11	0.492967212	0.261332254
11-Feb-11	-0.108004331	0.384449876
14-Feb-11	0.078014827	0.397275298
15-Feb-11	0.167825501	0.149761677
16-Feb-11	-0.035938904	0.085514098
17-Feb-11	-0.49246391	0.106410294
18-Feb-11	0.066203246	0.125894073
21-Feb-11	0.366333773	0.270932341
22-Feb-11	0.251451967	0.088270412
23-Feb-11	0.095625157	0.178646014
24-Feb-11	-0.593153532	0.162867666
28-Feb-11	0.012017786	0.151255717
01-Mar-11	-0.024037017	0.222547151
02-Mar-11	-0.379347136	0.134330032
03-Mar-11	-0.501981761	0.083163287
04-Mar-11	0.32083323	0.144711521
09-Mar-11	-0.036269117	0.51430159
10-Mar-11	0.494542954	0.159794445
11-Mar-11	0.162303543	0.170541347
14-Mar-11	-0.306794839	0.283392388
15-Mar-11	0.33081742	0.145079144
16-Mar-11	0.616602271	0.549879706
17-Mar-11	0.143129795	0.371900782
18-Mar-11	-0.747722939	0.49260492
21-Mar-11	0.030016509	0.305674811
22-Mar-11	-0.372843056	0.167225741
23-Mar-11	0.036142401	0.081413632
24-Mar-11	-0.060244595	0.114722196
25-Mar-11	0.156560519	0.115562946
28-Mar-11	0.054136968	0.139899111
29-Mar-11	-1.003272044	0.139207721
30-Mar-11	-1.06867983	0.164978371
31-Mar-11	0.184015264	0.346371122
01-Apr-11	-1.531461326	0.259911226
04-Apr-11	0.018666584	0.461450709
05-Apr-11	0.142994833	0.475872252
06-Apr-11	0.297766969	0.162108248
07-Apr-11	-1.755911018	0.48657323
08-Apr-11	-1.102952358	0.814310717
11-Apr-11	0.913653967	0.516218658
12-Apr-11	0.717435425	0.263104822
13-Apr-11	-0.515529873	0.51066412
14-Apr-11	-0.524537494	0.500039059
15-Apr-11	-0.126807017	0.326354422
18-Apr-11	0.871712929	0.334594638
19-Apr-11	-0.865368758	0.459813221
20-Apr-11	-0.636417855	0.282336033
25-Apr-11	0.15948458	0.661418903
26-Apr-11	-0.427992605	0.244954843
27-Apr-11	0.281276156	0.156826802
28-Apr-11	0.731439101	0.405440973
29-Apr-11	-0.164901414	1.255432303
02-May-11	0.878445943	0.409951423
03-May-11	-0.107022579	0.323851779
04-May-11	1.909097846	0.791461659
05-May-11	0.23455353	0.922095945
06-May-11	-0.438692044	1.06433621
09-May-11	-0.049550946	0.871117784
10-May-11	-0.646406626	0.482748704
11-May-11	1.1223184	0.211061553
12-May-11	-0.12339587	0.387859407
13-May-11	1.007379526	0.560305381
16-May-11	-0.085600739	0.832924846
17-May-11	-1.1814068	0.689592614
18-May-11	-0.372070378	0.566194714
19-May-11	0.415388551	0.279422027
20-May-11	0.401346592	0.399236
23-May-11	0.638822811	0.443274345
24-May-11	-0.558746426	0.595306678
25-May-11	0.313528059	0.295228041
26-May-11	-0.869222253	0.279886619
27-May-11	-1.283666679	0.258214646
30-May-11	-0.006271755	0.234647034
31-May-11	-0.900935374	1.266316678
01-Jun-11	0.888390684	0.793664159
02-Jun-11	-1.211677073	0.292077177
03-Jun-11	0.082505637	0.440752317
06-Jun-11	0.506234075	0.598057482
07-Jun-11	-0.284441265	0.346514445
08-Jun-11	0.107550702	0.191430504
09-Jun-11	0.107435154	0.333541582
10-Jun-11	0.867875393	0.329615305
13-Jun-11	-0.867875393	0.323996808
14-Jun-11	0.031576621	0.268556486
15-Jun-11	1.036473992	0.175962168
16-Jun-11	0.174825219	0.351500794
17-Jun-11	-0.324919056	0.744308763
20-Jun-11	-0.081394989	0.294435117
21-Jun-11	-0.647251451	0.336824569
22-Jun-11	0.295867516	0.202983154
24-Jun-11	0.857461051	0.184753122
27-Jun-11	-0.637701442	0.273723868
28-Jun-11	-1.167095227	0.198822864
29-Jun-11	-0.521696055	0.21089449
01-Jul-11	-0.749115134	0.360572043
04-Jul-11	-0.167234875	0.298408534
05-Jul-11	0.73119433	0.202548286
07-Jul-11	-0.705447676	0.184495512
08-Jul-11	0.558355909	0.328871557
11-Jul-11	0.95542128	0.400419248
12-Jul-11	0.101374906	0.731242354
13-Jul-11	-0.228238228	0.479850958
14-Jul-11	0.228238228	0.491207658
15-Jul-11	-0.291730293	0.404604217
18-Jul-11	0	0.219624739
21-Jul-11	-1.400681657	0.213299521
22-Jul-11	-0.038652323	0.309843662
25-Jul-11	-0.776200534	0.180744691
26-Jul-11	-0.058458642	0.27205575
27-Jul-11	1.059920735	0.325528898
28-Jul-11	0.749355029	2.428240043
29-Jul-11	-1.148737163	0.469940837
01-Aug-11	1.078523647	0.550190629
02-Aug-11	0.076594119	0.425678486
03-Aug-11	-0.447628321	0.495657047
04-Aug-11	1.753427808	0.293789309
05-Aug-11	-0.745894735	0.601095398
08-Aug-11	3.135405475	1.317150691
09-Aug-11	-2.32026084	1.549554148
10-Aug-11	2.240292823	3.804765346
11-Aug-11	0.043067648	2.676972284
12-Aug-11	-0.864896971	2.030356781
15-Aug-11	-1.424756963	0.650117492
16-Aug-11	0.075495442	0.402236315
17-Aug-11	-0.132154451	0.606114699
18-Aug-11	0.696560816	0.488268213
19-Aug-11	0.031262701	1.254047451
22-Aug-11	0.511318692	0.440581423
23-Aug-11	-0.686515834	0.475483531
24-Aug-11	1.052805239	0.469841576
25-Aug-11	-0.266824024	0.462177807
26-Aug-11	-0.379743352	0.464712742
29-Aug-11	-0.744987325	0.371938585
30-Aug-11	0.232229823	0.249897142
31-Aug-11	-0.345401794	0.615240532
01-Sep-11	1.875853465	0.409466512
02-Sep-11	1.30648652	0.930902064
05-Sep-11	0.255614527	1.327782714
06-Sep-11	0.720712928	0.778623823
08-Sep-11	0.186899039	1.06428553
09-Sep-11	0.83376304	0.493304005
12-Sep-11	1.688078703	0.749069554
13-Sep-11	0.42783948	2.042744875
14-Sep-11	0.26282759	1.413063515
15-Sep-11	-0.438430539	1.770034467
16-Sep-11	1.523285269	1.02615161
19-Sep-11	3.654072942	1.740551448
20-Sep-11	-0.675395384	2.206269919
21-Sep-11	4.923012018	2.300949296
22-Sep-11	1.58158331	5.698678868
23-Sep-11	-3.829959461	12.0351643
26-Sep-11	-0.530331196	3.676207855
27-Sep-11	-1.008245229	3.037029342
28-Sep-11	1.914117726	1.901620615
29-Sep-11	-0.027165793	1.537355642
30-Sep-11	2.097076527	1.775964811
03-Oct-11	0.625930327	2.649205664
04-Oct-11	-1.760421009	5.3759257
05-Oct-11	-1.376417091	2.243186873
06-Oct-11	-2.855913838	1.54913484
07-Oct-11	-0.540450564	1.90841139
10-Oct-11	-0.469630535	3.081608017
11-Oct-11	0.71769967	1.832264359
13-Oct-11	-1.412028337	1.648668967
14-Oct-11	-1.044845604	1.808275975
17-Oct-11	2.355465482	0.795435481
18-Oct-11	-1.122333513	1.067436752
19-Oct-11	1.116696693	2.045872543
20-Oct-11	0.388197061	0.954506779
21-Oct-11	-0.30367811	3.055124613
24-Oct-11	-1.412348708	1.149754406
25-Oct-11	0.864525917	1.089913126
26-Oct-11	-0.408580752	1.174568581
27-Oct-11	-2.808314869	1.513654793
28-Oct-11	-2.235456779	3.436084262
31-Oct-11	2.574083912	1.599087355
01-Nov-11	1.687608681	1.618490667
03-Nov-11	-0.424994897	5.553843614
04-Nov-11	0.813944652	2.620094891
07-Nov-11	-0.228610719	2.039636068
08-Nov-11	-0.873518571	1.343837529
09-Nov-11	2.642974367	0.66335706
10-Nov-11	-0.977270876	2.044501266
11-Nov-11	-1.032789985	1.068540051
14-Nov-11	1.333201151	0.235714786
16-Nov-11	0.180944352	2.022258755
17-Nov-11	0.52963838	0.647612982
18-Nov-11	0.392597251	1.409128018
21-Nov-11	1.135427125	0.608773304
22-Nov-11	0.628932891	1.25267409
23-Nov-11	2.600227917	1.209726839
24-Nov-11	1.689642237	2.922987551
25-Nov-11	-0.33248045	2.118102208
28-Nov-11	-1.975293778	1.729139731
29-Nov-11	-0.502690175	1.519211698
30-Nov-11	-2.019828375	0.974439201
01-Dec-11	-0.46555535	1.919552335
02-Dec-11	-0.523561405	1.291641288
05-Dec-11	-0.268411502	1.398079608
06-Dec-11	0.313076792	0.467330218
07-Dec-11	0.451116022	0.615763662
08-Dec-11	1.363193383	0.505116864
09-Dec-11	-1.446579996	2.040663346
12-Dec-11	2.520657328	2.120409603
13-Dec-11	1.068028924	1.12357588
14-Dec-11	0.860116957	0.789489742
15-Dec-11	-1.053457511	0.880897354
16-Dec-11	-0.479591381	0.848765292
19-Dec-11	0.860544223	0.582412366
20-Dec-11	-1.147240116	0.310158047
21-Dec-11	0.739404831	0.585757101
22-Dec-11	-0.199155003	0.499430604
23-Dec-11	0.059249685	0.365157654
26-Dec-11	0.059214601	0.263494947
27-Dec-11	0.123699158	0.114163976
28-Dec-11	0.701644506	0.136557007
29-Dec-11	-0.35824126	0.673324657
02-Jan-12	0.24075126	0.733135624
03-Jan-12	-2.198840648	0.209871609
04-Jan-12	0.103731617	0.889507512
05-Jan-12	0.576746797	0.757572261
06-Jan-12	0.724366646	0.641390351
09-Jan-12	-1.268378433	0.584384288
10-Jan-12	-1.849865567	0.403198803
11-Jan-12	0.161017219	0.760425463
12-Jan-12	-1.278597023	0.412248317
13-Jan-12	0.375782152	0.88958327
16-Jan-12	-0.011196954	1.704691352
17-Jan-12	0.067162929	0.196554282
18-Jan-12	-1.136631638	0.816574371
19-Jan-12	-0.118909445	0.818726041
20-Jan-12	-0.556787985	0.511756856
23-Jan-12	-0.011395362	0.415296694
24-Jan-12	0.199231601	0.387717206
26-Jan-12	-0.5359803	0.337552856
27-Jan-12	-0.694188267	1.423848319
30-Jan-12	0.677035118	0.556385362
31-Jan-12	-0.114429581	0.593452954
01-Feb-12	-0.718166885	0.944934618
02-Feb-12	-0.891932242	0.523270197
03-Feb-12	-0.05819367	0.458964299
06-Feb-12	0.453015062	0.663519329
07-Feb-12	-0.005794918	1.008559055
08-Feb-12	-0.290174889	0.498832226
09-Feb-12	-0.21527281	0.503855456
10-Feb-12	0.319832797	0.455381547
13-Feb-12	-0.354785611	0.629365488
14-Feb-12	0.488231135	0.492335578
15-Feb-12	0.220085806	0.256623189
16-Feb-12	-0.702490624	0.439129321
17-Feb-12	-0.145759872	0.4538214
22-Feb-12	-0.462002635	0.197506263
23-Feb-12	0.450332662	0.580089734
24-Feb-12	-0.216140517	0.549387849
27-Feb-12	-0.187309818	0.301904638
28-Feb-12	-0.646566644	0.373452654
29-Feb-12	1.265691337	0.503691834
01-Mar-12	-0.186501977	1.266036649
02-Mar-12	0.940609617	0.600310788
05-Mar-12	0.524511995	0.588798291
06-Mar-12	1.080658906	0.402150553
07-Mar-12	0.436942105	0.54052965
08-Mar-12	-0.306226847	0.667594134
09-Mar-12	1.717432905	0.868415039
12-Mar-12	0.317717165	1.00862072
13-Mar-12	-0.261904248	1.522839203
14-Mar-12	0.678421108	1.166096802
15-Mar-12	-0.338635236	1.399538043
16-Mar-12	0.083377343	1.157255455
19-Mar-12	1.154549491	0.613010036
20-Mar-12	-0.330087773	0.314115266
21-Mar-12	0.181683096	0.910584948
22-Mar-12	0.065984826	0.475021521
23-Mar-12	-0.49595076	0.785201319
26-Mar-12	0.385951849	0.297782585
27-Mar-12	0.263794393	0.275751349
28-Mar-12	0.213821732	0.359007907
29-Mar-12	-0.246758001	0.452287957
30-Mar-12	0.296036618	0.299808208
02-Apr-12	0.300620598	0.576651439
03-Apr-12	-0.421122337	0.284428735
04-Apr-12	0.09860313	0.619545926
05-Apr-12	-0.197303583	0.338427019
09-Apr-12	-0.269179167	0.167286605
10-Apr-12	0.85992588	0.204046813
11-Apr-12	0.1090156	0.500914532
12-Apr-12	-0.480560121	0.494962646
13-Apr-12	0.643861012	0.421241459
16-Apr-12	0.472070113	0.323131997
17-Apr-12	0.744259719	0.401646932
18-Apr-12	0.935910781	0.307443283
19-Apr-12	0.101088035	0.760810688
20-Apr-12	-0.431666848	0.577802455
23-Apr-12	0.452935525	0.702194675
24-Apr-12	-0.101066526	0.58821833
25-Apr-12	0.053205641	0.340912058
26-Apr-12	0.29742958	0.184093031
27-Apr-12	0.116605727	0.162239667
30-Apr-12	1.080066346	0.189240247
02-May-12	0.777767199	1.663421285
03-May-12	-0.793489233	0.630977197
04-May-12	1.022013276	0.361488125
07-May-12	-0.400260443	0.693004661
08-May-12	1.05179592	0.471283152
09-May-12	1.51917195	0.314230301
10-May-12	-0.836014453	0.85975079
11-May-12	0.663267738	0.600768302
14-May-12	1.499006038	0.544269133
15-May-12	0.285135633	1.186117273
16-May-12	-0.049965026	0.766552626
17-May-12	0.389066732	0.499924101
18-May-12	0.748918566	0.502889336
21-May-12	0.890381463	3.123328307
22-May-12	2.361819118	0.893678509
23-May-12	-2.818317641	2.301575432
24-May-12	-0.167413501	3.346173503
25-May-12	-2.08143749	1.418425155
28-May-12	-0.221640228	1.115522136
29-May-12	0.498001482	0.311018488
30-May-12	1.147488145	0.808318186
31-May-12	0.336750677	0.552115717
01-Jun-12	0.856557369	0.919496875
04-Jun-12	0.897873597	0.783930578
05-Jun-12	-1.764319228	0.450206146
06-Jun-12	0.507978307	1.291943638
08-Jun-12	-0.448663393	1.06701431
11-Jun-12	1.996054725	0.895219981
12-Jun-12	0.18872952	0.540682124
13-Jun-12	0.207674364	0.534325891
14-Jun-12	-0.828432904	0.446032722
15-Jun-12	-0.228905494	0.586341985
18-Jun-12	0.394170685	0.338092755
19-Jun-12	-1.472665378	0.39979894
20-Jun-12	-0.152909	0.439101171
21-Jun-12	1.766320354	0.498758749
22-Jun-12	0.222846716	0.574743141
25-Jun-12	-0.217996937	0.512694305
26-Jun-12	0.686291418	0.411901062
27-Jun-12	-0.038539359	0.337450248
28-Jun-12	0.115573547	0.746211025
29-Jun-12	-3.347347161	0.710928084
02-Jul-12	-1.201576487	2.347076598
03-Jul-12	1.50468984	0.560332049
04-Jul-12	0.642930009	0.997465951
05-Jul-12	-0.454568696	0.466716075
06-Jul-12	0.439778349	0.814071032
10-Jul-12	0.270809393	0.520033686
11-Jul-12	0.142495663	0.362946942
12-Jul-12	0.044181538	0.256442303
13-Jul-12	-0.019633829	0.362226566
18-Jul-12	-0.684681147	0.225477039
19-Jul-12	-0.54517655	0.435390033
20-Jul-12	0.59459099	0.255332406
23-Jul-12	0.713778905	0.235440726
24-Jul-12	0.445369634	0.779472695
25-Jul-12	-0.725351151	0.4152236
26-Jul-12	-0.577166588	0.2860855
27-Jul-12	0.014840832	0.744224434
30-Jul-12	0.959960113	0.473801662
31-Jul-12	0.771111678	0.280471335
01-Aug-12	-0.614456239	0.338901158
02-Aug-12	0.258921955	0.267631087
03-Aug-12	-1.039734722	0.508662954
06-Aug-12	0.133021328	0.289468875
07-Aug-12	-0.128091455	0.246164264
08-Aug-12	-0.360520923	0.200662811
09-Aug-12	-0.396589852	0.162489169
10-Aug-12	0.124103369	0.17378924
13-Aug-12	0.257642713	0.144921874
14-Aug-12	0.26191609	0.244748155
15-Aug-12	-0.162999221	0.087055647
16-Aug-12	-0.277214177	0.11912977
17-Aug-12	-0.089268008	0.157134073
20-Aug-12	0.079353275	0.114607537
21-Aug-12	-0.03470931	0.112389175
22-Aug-12	-0.004959456	0.578365487
23-Aug-12	0.371278365	0.077226708
24-Aug-12	0.138257972	0.071694786
27-Aug-12	0.344810942	0.176013702
28-Aug-12	0.451379434	0.171480125
29-Aug-12	0.346959568	0.200456955
30-Aug-12	-0.073201087	0.261286793
31-Aug-12	-0.862919652	0.204170389
03-Sep-12	0.103354095	0.501621541
04-Sep-12	0.46132787	0.060714781
05-Sep-12	-0.15680897	0.188499374
06-Sep-12	-0.496547319	0.156604116
10-Sep-12	-0.310980827	0.170704491
11-Sep-12	-0.277241625	0.249944471
12-Sep-12	0.44025695	0.338947601
13-Sep-12	-0.271840029	0.117286227
14-Sep-12	-0.416605274	0.268503167
17-Sep-12	0.984157692	0.289791
18-Sep-12	-0.424126493	0.302421496
19-Sep-12	0.059288539	0.160109565
20-Sep-12	-0.158180952	0.07600493
21-Sep-12	0.084064784	0.108790514
24-Sep-12	0.123496447	0.072279311
25-Sep-12	0.251460823	0.104212577
26-Sep-12	0.241005453	0.105041516
27-Sep-12	-0.295188643	0.109927201
28-Sep-12	-0.15779096	0.077440413
01-Oct-12	0.019737491	0.200237445
02-Oct-12	-0.044414835	0.093657459
03-Oct-12	-0.143248808	0.07675191
04-Oct-12	-0.202874955	0.055626577
05-Oct-12	0.577850725	0.081126084
08-Oct-12	-0.0443317	0.18107787
09-Oct-12	0.285349008	0.062272351
10-Oct-12	0.30413052	0.114001067
11-Oct-12	0.0440712	0.08858935
15-Oct-12	-0.338376607	0.260513611
16-Oct-12	-0.098294597	0.130885109
17-Oct-12	-0.127927591	0.058624631
18-Oct-12	-0.197131797	0.071472973
19-Oct-12	0.009865825	0.06519018
22-Oct-12	-0.153029772	0.056540694
23-Oct-12	0.148096981	0.084501811
24-Oct-12	-0.064148432	0.09917027
25-Oct-12	0	0.064479604
26-Oct-12	0.05428212	0.068179565
29-Oct-12	0.290647758	0.074893168
30-Oct-12	-0.108278384	0.089552429
31-Oct-12	0.004924289	0.046411365
01-Nov-12	0.029540643	0.177253717
05-Nov-12	0.186888364	0.055949912
06-Nov-12	-0.152435306	0.063957891
07-Nov-12	0.088539111	0.045023585
08-Nov-12	0.323974365	0.053367206
09-Nov-12	0.27895386	0.114481341
12-Nov-12	0.234306463	0.647647038
13-Nov-12	0.36015029	0.104571208
14-Nov-12	0.397576281	0.578621201
16-Nov-12	0.891207093	0.209612674
19-Nov-12	-0.13437637	0.494081469
21-Nov-12	0.774975176	0.560343603
22-Nov-12	0.285510544	0.280921807
23-Nov-12	-1.098912158	0.26473488
26-Nov-12	-0.004804343	0.993761435
27-Nov-12	0.115240577	0.215948203
28-Nov-12	0.464415648	0.417863775
29-Nov-12	0.248079894	0.3700799
30-Nov-12	1.761681568	0.433560934
03-Dec-12	-0.586925033	0.833146348
04-Dec-12	-0.174392616	1.01169069
05-Dec-12	-1.516296846	0.589589641
06-Dec-12	-0.504166434	0.68970124
07-Dec-12	-0.110776652	0.371025414
10-Dec-12	0.105962827	0.479989224
11-Dec-12	0.067372476	0.140771144
12-Dec-12	-0.313185348	0.1679872
13-Dec-12	0.64457388	0.161770879
14-Dec-12	0.019177294	0.121214517
17-Dec-12	0.649849382	0.208730669
18-Dec-12	-0.506136782	0.229817645
19-Dec-12	-0.826768793	0.242130964
20-Dec-12	-0.120740881	0.201241421
21-Dec-12	0.472472193	0.349564904
26-Dec-12	-1.453443541	0.531256851
27-Dec-12	-0.278558519	1.099564213
28-Dec-12	0.200444957	0.410122598
02-Jan-13	-0.087950753	0.220501382
03-Jan-13	0	0.864831444
04-Jan-13	-0.647346677	0.257836598
07-Jan-13	-0.241373482	0.211782375
08-Jan-13	0.683200416	0.344714002
09-Jan-13	-0.034294393	0.355486086
10-Jan-13	-0.5798827	0.262161325
11-Jan-13	0.241207137	0.208142037
14-Jan-13	-0.113147226	0.218545269
15-Jan-13	0.206520209	0.305238341
16-Jan-13	0.323672491	0.108284838
17-Jan-13	-0.176418746	0.216637423
18-Jan-13	0.12744475	0.219211875
21-Jan-13	-0.014696877	0.12731444
22-Jan-13	0.083253757	0.051232127
23-Jan-13	-0.33343171	0.320068611
24-Jan-13	-0.245881609	0.151257685
28-Jan-13	-1.763363709	0.18203739
29-Jan-13	-0.482243362	1.202432498
30-Jan-13	0.140894705	0.458645848
31-Jan-13	0.140696471	0.420525744
01-Feb-13	-0.175901541	0.256575292
04-Feb-13	0.371542326	0.383871901
05-Feb-13	-0.5427149	0.209346207
06-Feb-13	0.326986734	0.196201213
07-Feb-13	-1.233023859	0.106108613
08-Feb-13	0.304615152	0.500416604
13-Feb-13	-0.386002816	1.962252519
14-Feb-13	-0.351745067	0.099777438
15-Feb-13	0.539853616	0.130905926
18-Feb-13	-0.279748917	0.669818652
19-Feb-13	-0.387854531	0.511113436
20-Feb-13	0.321617553	0.102312855
21-Feb-13	0.548949228	0.171839258
22-Feb-13	-0.005069066	0.342300054
25-Feb-13	0.470327314	0.265857981
26-Feb-13	0.015135081	0.339861697
27-Feb-13	-0.480393329	0.464601994
28-Feb-13	0.288512842	0.223301625
01-Mar-13	0.060633623	0.302907915
04-Mar-13	-0.475950266	0.223878368
05-Mar-13	-0.310077768	0.175163358
06-Mar-13	0.315153008	0.361959908
07-Mar-13	-0.610875449	0.212351549
08-Mar-13	-0.727723193	0.140993414
11-Mar-13	0.651100708	0.661401814
12-Mar-13	0.397797342	0.415687551
13-Mar-13	0.375940292	0.18248523
14-Mar-13	-0.020285004	0.47712173
15-Mar-13	0.576516212	0.309679853
18-Mar-13	-0.020172475	0.344709469
19-Mar-13	0.080665495	0.566975625
20-Mar-13	0.281817911	0.393736573
21-Mar-13	0.915441225	0.641878061
22-Mar-13	0.059737158	0.679705426
25-Mar-13	0.169061748	0.444807135
26-Mar-13	0.223319613	0.318514293
27-Mar-13	-0.312787287	0.344074137
28-Mar-13	0.530663085	0.691141994
01-Apr-13	-0.044526902	0.188095332
02-Apr-13	-0.069303503	0.152024378
03-Apr-13	0.24235242	0.123246851
04-Apr-13	-0.460476639	0.249762853
05-Apr-13	-1.484915918	0.201027139
08-Apr-13	0.326871629	0.557171058
09-Apr-13	-0.533603078	0.434002765
10-Apr-13	-0.42488683	0.210650122
11-Apr-13	0.141829626	0.263692461
12-Apr-13	-0.309244626	0.426214236
15-Apr-13	1.601726597	0.88551842
16-Apr-13	-0.707035664	0.738879644
17-Apr-13	0.672052281	0.430735356
18-Apr-13	0.915520376	0.520413531
19-Apr-13	-0.392050327	0.511924559
22-Apr-13	0.496008159	0.527033399
23-Apr-13	0.074189483	0.60112561
24-Apr-13	-0.609984782	0.816982869
25-Apr-13	-0.448699526	0.221183071
26-Apr-13	-0.124996891	0.343692169
29-Apr-13	0.424353499	0.262664665
30-Apr-13	-0.299356607	0.453643541
02-May-13	0.393966349	0.292898437
03-May-13	-0.014932431	0.278234023
06-May-13	0.034838871	0.264087287
07-May-13	-0.089610202	0.171072288
08-May-13	-0.119605317	0.258209906
09-May-13	0.398129321	0.308885077
10-May-13	0.34706763	0.613833616
13-May-13	-0.615630978	0.656525178
14-May-13	0.635427078	0.351426415
15-May-13	0.103865281	0.269299484
16-May-13	0.177804166	0.408660379
17-May-13	0.428392708	0.440166978
20-May-13	0.176730532	0.281503216
21-May-13	0.078446758	0.284398263
22-May-13	0.449878509	0.275438223
23-May-13	-0.273597982	0.389462263
24-May-13	0.366256056	0.328580311
27-May-13	0.272599108	0.317143216
28-May-13	0.861573577	0.375670341
29-May-13	1.70593075	0.713283846
31-May-13	1.434744841	0.699763961
03-Jun-13	-0.797153241	1.858582362
04-Jun-13	0.047067684	0.505006187
05-Jun-13	0.1222724	0.895838719
06-Jun-13	0.09864945	3.183862228
07-Jun-13	0.098552229	0.964569176
10-Jun-13	0.710449354	1.101248979
11-Jun-13	-0.677620183	1.043135212
12-Jun-13	1.109827199	1.385288422
13-Jun-13	-1.645819831	0.615415275
14-Jun-13	1.422978514	0.978640487
17-Jun-13	0.906825868	0.710706159
18-Jun-13	0.473270348	0.765383953
19-Jun-13	1.960936149	0.939603929
20-Jun-13	1.463593124	1.214907272
21-Jun-13	-0.680047957	3.345704564
24-Jun-13	-0.689194941	1.431096379
25-Jun-13	-0.580991118	1.123677105
26-Jun-13	-1.236210807	0.944276166
27-Jun-13	0.556367725	0.601920689
28-Jun-13	1.480639156	0.800108446
01-Jul-13	-0.121057248	1.099944742
02-Jul-13	1.146387201	0.395890297
03-Jul-13	0.623413095	0.574418123
04-Jul-13	-0.894325702	0.380832237
05-Jul-13	0.168851406	0.800469737
08-Jul-13	0.496015189	0.881017172
10-Jul-13	0.039751773	0.577206392
11-Jul-13	-0.393797106	0.453353728
12-Jul-13	0.5129577	0.518694909
15-Jul-13	-2.099335004	0.321059324
16-Jul-13	1.506544062	0.490384441
17-Jul-13	-1.236650506	0.928265508
18-Jul-13	0.067359726	1.148364516
19-Jul-13	0.871572326	1.069967031
22-Jul-13	-0.624974134	0.529205807
23-Jul-13	-0.863508851	0.559434791
24-Jul-13	1.63967476	0.50904167
25-Jul-13	-0.34719166	0.721991029
26-Jul-13	0.600148504	0.83815205
29-Jul-13	0.539275497	0.505757938
30-Jul-13	0.619659633	0.299381541
31-Jul-13	-0.258823158	0.376484722
01-Aug-13	1.205044271	1.307658161
02-Aug-13	-0.731774326	0.636385363
05-Aug-13	0.809862048	1.260262492
06-Aug-13	-0.299667984	0.27237889
07-Aug-13	0.650310104	0.49697481
08-Aug-13	-1.282988873	0.329822091
09-Aug-13	-0.56184855	0.749292233
12-Aug-13	0.701818829	0.548838348
13-Aug-13	1.155981757	0.587569384
14-Aug-13	0.452655268	0.635953319
15-Aug-13	0.677300257	0.260794482
16-Aug-13	2.188881441	1.038039993
19-Aug-13	0.844905449	1.004846178
20-Aug-13	-0.803116898	1.806379472
21-Aug-13	2.508485836	1.350974473
22-Aug-13	-0.777163597	1.666276079
23-Aug-13	-3.616539279	1.664594936
26-Aug-13	1.315391056	5.283426399
27-Aug-13	-0.332498886	1.338759854
28-Aug-13	-1.136279503	1.982497702
29-Aug-13	0.607904608	2.135763065
30-Aug-13	1.095901379	1.21935608
02-Sep-13	-0.340129241	1.56874391
03-Sep-13	-0.776965314	1.285037626
04-Sep-13	0.050856078	1.106782791
05-Sep-13	-1.519837998	1.25320163
06-Sep-13	-0.777340242	1.426764255
09-Sep-13	-1.331112678	2.293494997
10-Sep-13	0.289550084	0.619338163
11-Sep-13	-0.324704103	0.817291356
12-Sep-13	-0.026373627	1.080015475
13-Sep-13	0.241498284	0.631142907
16-Sep-13	0.184024939	0.528838795
17-Sep-13	-1.246574891	1.014999617
18-Sep-13	-3.156426914	0.369420565
19-Sep-13	0.715639948	1.730682962
20-Sep-13	0.398894505	1.06833952
23-Sep-13	-0.55343999	1.572739913
24-Sep-13	0.122746816	0.472774801
25-Sep-13	1.385182434	0.503597438
26-Sep-13	0.616458666	0.659602939
27-Sep-13	0.302370278	0.62814709
30-Sep-13	-1.579698569	0.603034499
01-Oct-13	-0.022555543	1.087235163
02-Oct-13	-1.12518768	1.097529346
03-Oct-13	0.691131747	0.544088624
04-Oct-13	0.217263472	0.725239511
07-Oct-13	-0.294324286	0.444240559
08-Oct-13	0.262669414	0.477321249
09-Oct-13	-0.167485271	0.600078325
10-Oct-13	-1.226170296	0.318726789
11-Oct-13	-0.197406239	0.560546742
14-Oct-13	0.298254288	0.358986898
15-Oct-13	-0.201797904	0.974529111
16-Oct-13	0.100949855	0.417837846
17-Oct-13	-1.297130842	0.622236119
18-Oct-13	0.819012976	0.941075867
21-Oct-13	0.234747294	0.386092682
22-Oct-13	-0.128812641	0.523541973
23-Oct-13	0.834331419	0.678312132
24-Oct-13	0.582640822	0.482720862
25-Oct-13	-0.73340495	0.456198861
28-Oct-13	-0.380202469	0.718374466
29-Oct-13	0.284143179	0.260731027
30-Oct-13	0.242258146	0.197310652
31-Oct-13	2.230240061	0.358423837
01-Nov-13	0.623110437	0.679990652
04-Nov-13	-0.324423101	1.37400345
05-Nov-13	1.874159144	0.241295283
06-Nov-13	-0.026215756	0.77700495
07-Nov-13	0.770490263	0.842534564
08-Nov-13	0.311729048	0.926904902
11-Nov-13	0.796542499	2.8125796
12-Nov-13	0.01286477	0.669844328
13-Nov-13	0.085722863	0.580555393
14-Nov-13	-0.851911184	0.366198354
18-Nov-13	-2.201827625	0.587970008
19-Nov-13	0.308723893	1.006630393
21-Nov-13	1.50779685	0.691444257
22-Nov-13	-1.134194675	1.013254899
25-Nov-13	0.433384354	0.65389847
26-Nov-13	0.235602203	0.382807412
27-Nov-13	1.548072082	0.628279147
28-Nov-13	-0.555066936	0.480674518
29-Nov-13	0.790789749	2.250950786
02-Dec-13	0.737853346	0.511556403
03-Dec-13	0.652268302	0.683403627
04-Dec-13	0.886839899	0.491721147
05-Dec-13	-1.394734502	0.611839061
06-Dec-13	-1.053606692	1.056526061
09-Dec-13	-0.610780857	1.547611115
10-Dec-13	-0.480052819	0.353008926
11-Dec-13	1.531542089	0.271731188
12-Dec-13	-0.367836172	0.70353551
13-Dec-13	-0.154380579	0.663206707
16-Dec-13	-0.07298487	0.282048538
17-Dec-13	-0.382969121	0.439577514
18-Dec-13	0.511730029	0.317628023
19-Dec-13	1.083582122	0.895129821
20-Dec-13	1.290014095	0.777772712
23-Dec-13	-1.268801138	0.65724899
26-Dec-13	-0.157082543	0.35287657
27-Dec-13	-0.652190125	0.296985964
30-Dec-13	0.91103227	0.334213867
02-Jan-14	1.183794762	0.796418944
03-Jan-14	-0.474362286	1.635646041
06-Jan-14	0.138763347	0.499043485
07-Jan-14	-0.311434956	0.390975048
08-Jan-14	1.023241336	0.508659244
09-Jan-14	-0.259013388	0.488240615
10-Jan-14	-1.356095745	0.436480165
13-Jan-14	-0.04241062	1.037746711
14-Jan-14	-0.314398865	0.39543837
15-Jan-14	0.399202127	0.511340053
16-Jan-14	0.084731407	0.403076911
17-Jan-14	-0.803592836	0.774233768
20-Jan-14	0.034145717	0.524985018
21-Jan-14	0.735563171	0.261330929
22-Jan-14	0.53655677	0.462991639
23-Jan-14	1.102066508	0.374035688
24-Jan-14	-0.087552902	0.688680171
27-Jan-14	1.045609294	1.188820071
28-Jan-14	-0.049543785	0.677643115
29-Jan-14	0.650368638	0.520395502
30-Jan-14	-1.151311539	0.824192258
31-Jan-14	0.141014498	0.63028821
03-Feb-14	1.133308374	1.370424118
04-Feb-14	-1.436320041	0.614081478
05-Feb-14	-0.128954447	0.577457821
06-Feb-14	-0.856974916	0.689109918
07-Feb-14	-0.11341918	0.785145493
10-Feb-14	1.282095614	1.497901027
11-Feb-14	-0.394986273	0.584637278
12-Feb-14	1.060842039	0.619485525
13-Feb-14	-1.348708067	0.380261926
14-Feb-14	-0.19237209	0.679887528
17-Feb-14	0.025113009	0.491364979
18-Feb-14	0.263306528	0.298501927
19-Feb-14	-0.087691831	0.524861427
20-Feb-14	-0.978156872	0.587878181
21-Feb-14	-1.047485246	0.754185813
24-Feb-14	-0.187753416	0.491718028
25-Feb-14	-0.004271223	0.479586101
26-Feb-14	0.375170972	0.415327421
27-Feb-14	-1.319302953	0.442376124
28-Feb-14	1.076455125	0.451661204
05-Mar-14	-1.093703939	1.351142223
06-Mar-14	0.219699832	0.294833804
07-Mar-14	0.7288662	0.580352436
10-Mar-14	0.409260067	0.478243189
11-Mar-14	0.560011646	0.643054457
12-Mar-14	-0.347516878	0.549844596
13-Mar-14	0.360208039	0.516958019
14-Mar-14	-0.73450136	0.780048601
17-Mar-14	0.097961973	0.774529579
18-Mar-14	-0.640617181	0.251498022
19-Mar-14	0.674668429	0.47514246
20-Mar-14	-0.936364453	0.566986449
21-Mar-14	-0.120352475	0.609537329
24-Mar-14	-0.094664379	0.656547088
25-Mar-14	-0.500626828	0.378345606
26-Mar-14	-0.364093853	0.616944254
27-Mar-14	-1.929122914	1.398581868
28-Mar-14	0.101767669	1.105637528
31-Mar-14	0.472083999	0.788347437
01-Apr-14	-0.441131775	1.653068368
02-Apr-14	0.30899645	0.570528459
03-Apr-14	0.470485643	0.425845439
04-Apr-14	-1.940088312	0.378341338
07-Apr-14	-0.758752826	1.167083004
08-Apr-14	-0.782720883	0.494014377
09-Apr-14	-0.665362706	0.878199992
10-Apr-14	0.901276072	1.171718078
11-Apr-14	0.537793636	0.801721769
14-Apr-14	-0.207543839	0.69926936
15-Apr-14	0.836561504	0.433586379
16-Apr-14	0.478095681	0.47641465
17-Apr-14	-0.299100689	0.615884001
22-Apr-14	0.044698731	0.414113973
23-Apr-14	-0.708586694	0.357613905
24-Apr-14	-0.356185142	0.382360551
25-Apr-14	1.328088437	0.641028134
28-Apr-14	-0.899918768	0.988111483
29-Apr-14	0.565074604	0.541201624
30-Apr-14	-0.170083292	0.71304312
02-May-14	-0.489481634	0.574358493
05-May-14	1.02114825	1.043883165
06-May-14	-0.661661928	0.448987054
07-May-14	-0.571288749	0.3617477
08-May-14	-0.076719998	0.46801303
09-May-14	-0.099372157	0.45056602
12-May-14	0.072280451	0.308086409
13-May-14	0.022576931	0.229027329
14-May-14	-0.570498695	0.294945401
15-May-14	0.782473067	0.304378637
16-May-14	-0.21648935	0.352334262
19-May-14	-0.357329009	0.224306605
20-May-14	0.411495301	0.178402385
21-May-14	-0.388841653	0.315819703
22-May-14	0.388841653	0.3574491
23-May-14	0.328880976	0.492487491
26-May-14	0.053959262	0.384663385
27-May-14	0.591638138	0.204971401
28-May-14	-0.255050813	0.249387652
29-May-14	-0.350074412	0.222551555
30-May-14	0.774798421	0.439127168
02-Jun-14	1.558174148	0.436685702
03-Jun-14	0.171154015	0.598685238
04-Jun-14	-0.043857726	0.759313866
05-Jun-14	-0.77064036	0.478535997
06-Jun-14	-0.656408974	0.502864323
09-Jun-14	-0.804186079	0.770392956
10-Jun-14	-0.197566406	0.368265169
11-Jun-14	0.394743257	0.290169209
12-Jun-14	-0.111984603	0.290076315
13-Jun-14	-0.309729795	0.257504421
16-Jun-14	0.479896869	0.18610443
17-Jun-14	1.196393999	0.191899105
18-Jun-14	-1.528039532	0.2620141
20-Jun-14	0.107681274	0.433366389
23-Jun-14	-0.485481489	0.239193025
24-Jun-14	0.261014504	0.319679826
25-Jun-14	-0.776037102	0.156658233
26-Jun-14	-0.499478857	0.87432334
27-Jun-14	-0.136655604	0.297210335
30-Jun-14	0.930112647	0.5529108
01-Jul-14	-0.561570245	0.450764154
02-Jul-14	0.980688009	0.387990427
03-Jul-14	-0.58635322	0.408720613
04-Jul-14	0.144652407	0.885117085
07-Jul-14	0.500147482	0.15516695
08-Jul-14	-0.51369976	0.351211083
10-Jul-14	0.320245645	0.296253109
11-Jul-14	0.018011527	0.308200044
14-Jul-14	-0.397004943	0.152459563
15-Jul-14	0.311421279	0.152773724
16-Jul-14	0.198082269	0.239673848
17-Jul-14	1.54855048	0.199914845
18-Jul-14	-1.427193969	0.598991893
21-Jul-14	-0.229352741	0.63943547
22-Jul-14	-0.374388673	0.18750713
23-Jul-14	0.297820716	0.313684389
24-Jul-14	0.103577952	0.196945868
25-Jul-14	0.363922675	0.260992012
28-Jul-14	-0.332420233	0.316793865
29-Jul-14	0.399668224	0.16508886
30-Jul-14	0.643290134	0.104709617
31-Jul-14	0.793918968	0.464755111
01-Aug-14	-0.260987032	0.57554583
04-Aug-14	0.0310002	1.21178994
05-Aug-14	1.030800722	0.256273311
06-Aug-14	-0.386406031	0.574290319
07-Aug-14	0.971944081	0.550596795
08-Aug-14	-0.519822073	0.471680773
11-Aug-14	-0.342195648	0.785033156
12-Aug-14	0.065897861	0.59820073
13-Aug-14	0.201816416	0.237594149
14-Aug-14	-0.659603992	0.651510193
15-Aug-14	-0.287185122	0.286756532
18-Aug-14	-0.119535155	0.6020043
19-Aug-14	-0.466222011	0.257695441
20-Aug-14	0.669788926	0.231567379
21-Aug-14	0.295760253	0.298881023
22-Aug-14	0.387136993	0.178107898
25-Aug-14	0.481823096	0.37856633
26-Aug-14	-1.177983821	0.16350049
27-Aug-14	-0.647624691	0.223676135
28-Aug-14	-0.227217135	0.573639483
29-Aug-14	-0.272449308	0.483695585
01-Sep-14	0.446250015	0.382515737
02-Sep-14	-0.102461308	0.211977398
03-Sep-14	-0.299073987	0.285440488
04-Sep-14	0.267869261	0.26145791
05-Sep-14	-0.049055679	0.413634971
08-Sep-14	1.13987884	0.510362609
09-Sep-14	0.755682169	0.381581203
10-Sep-14	0.166185641	0.680163035
11-Sep-14	0.401204149	0.554183929
12-Sep-14	1.7814865	0.389889261
15-Sep-14	0.166599069	1.177111868
16-Sep-14	-0.479186302	0.478157226
17-Sep-14	1.117377712	0.481957856
18-Sep-14	0.296434536	1.350931746
19-Sep-14	0.139443516	0.759673959
22-Sep-14	1.24631814	0.57512056
23-Sep-14	0.586292455	1.328566074
24-Sep-14	-1.197019694	0.788282203
25-Sep-14	1.849941556	0.876197099
26-Sep-14	-0.317663585	0.892118866
29-Sep-14	1.133994649	0.824429342
30-Sep-14	-0.032689086	4.32380163
01-Oct-14	1.388009297	0.662130163
02-Oct-14	0.554663801	0.874111195
03-Oct-14	-1.473791641	0.787391159
06-Oct-14	-1.318448448	1.526016039
07-Oct-14	-1.227518109	5.229788914
08-Oct-14	-0.80436127	1.072543514
09-Oct-14	0.88360884	2.347087316
10-Oct-14	1.267727642	1.55192701
13-Oct-14	-1.442990581	1.012214047
14-Oct-14	0.250281697	1.105400203
15-Oct-14	2.359153443	0.590840347
16-Oct-14	0.612540706	2.375913577
17-Oct-14	-1.519965694	3.884472545
20-Oct-14	1.179677742	1.031965454
21-Oct-14	0.768052931	0.762204648
22-Oct-14	0.152905229	2.528040169
23-Oct-14	0.517335877	0.725263768
24-Oct-14	-1.049487909	0.862464344
27-Oct-14	1.889946144	2.395868288
28-Oct-14	-2.412754281	8.554093268
29-Oct-14	0.036563814	0.768370663
30-Oct-14	-2.438192525	1.635221425
31-Oct-14	3.081958539	2.381937176
03-Nov-14	0.703789276	1.623747427
04-Nov-14	0.01202188	1.634809502
05-Nov-14	0.487669352	1.203728281
06-Nov-14	2.446111287	0.977240925
07-Nov-14	-0.436767063	1.220448749
10-Nov-14	-0.254358469	1.179624693
11-Nov-14	0.16051682	0.631429647
12-Nov-14	0.46443639	0.361596244
13-Nov-14	0.798918347	0.602744636
14-Nov-14	0.493219249	0.910449827
17-Nov-14	0.280203619	1.433308083
18-Nov-14	-1.005459479	0.886876227
19-Nov-14	-0.44235841	0.561222311
21-Nov-14	-2.185965325	0.704141478
24-Nov-14	1.197193224	1.175436118
25-Nov-14	-0.630394901	1.057735144
26-Nov-14	-1.13682757	0.748620158
27-Nov-14	1.176343891	0.732163353
28-Nov-14	1.346042103	0.642213425
01-Dec-14	-0.183375327	0.736951136
02-Dec-14	0.335282965	0.913491879
03-Dec-14	-0.628601387	0.696645097
04-Dec-14	1.461923393	0.683792281
05-Dec-14	-0.088815097	0.772383417
08-Dec-14	0.458672199	1.205701318
09-Dec-14	-0.169348051	0.489126625
10-Dec-14	0.790396625	0.905784265
11-Dec-14	1.3551423	0.505000033
12-Dec-14	0.067842608	0.533989473
15-Dec-14	1.558939215	0.790431433
16-Dec-14	1.578834893	0.743215062
17-Dec-14	-0.858091074	2.662166089
18-Dec-14	-1.952424377	2.181552601
19-Dec-14	-0.124006554	1.474232269
22-Dec-14	0.210344517	0.869894623
23-Dec-14	1.108240974	0.54801514
26-Dec-14	-0.954518806	0.687431673
29-Dec-14	1.339704467	0.572060769
30-Dec-14	-1.775238684	0.40233409
02-Jan-15	1.367785441	1.524534489
05-Jan-15	0.437021547	1.31229359
06-Jan-15	-0.192350433	0.719442792
07-Jan-15	-0.664972638	0.507912106
08-Jan-15	-0.7632768	0.710917998
09-Jan-15	-1.117963073	0.767531782
12-Jan-15	1.537738061	1.591409581
13-Jan-15	-1.147297657	0.850816968
14-Jan-15	-1.019097724	1.026085515
15-Jan-15	0.9736879	0.902624618
16-Jan-15	-0.748441083	1.516171242
19-Jan-15	1.084740971	0.746503819
20-Jan-15	-1.436194899	0.618985242
21-Jan-15	-0.464126953	0.887146189
22-Jan-15	-1.020180422	0.873103598
23-Jan-15	0.217273307	0.986310731
26-Jan-15	0.131685987	0.936847311
27-Jan-15	-0.391693507	0.737847312
28-Jan-15	0.120386026	0.648429721
29-Jan-15	1.073162201	0.638102976
30-Jan-15	2.969597666	0.805499694
02-Feb-15	1.64504754	2.720609084
03-Feb-15	-1.191346502	1.041698985
04-Feb-15	1.714285654	1.278608098
05-Feb-15	0.134861787	1.01240798
06-Feb-15	1.320736366	1.316291187
09-Feb-15	-0.392588161	1.935698927
10-Feb-15	2.191614291	0.52372709
11-Feb-15	1.245564583	1.092460143
12-Feb-15	-1.549655903	2.045209791
13-Feb-15	0.385261588	1.183272487
18-Feb-15	0.151576602	0.864180902
19-Feb-15	0.977942914	0.582020509
20-Feb-15	0.090649194	0.664830222
23-Feb-15	0.316626628	0.518338566
24-Feb-15	-1.741612133	0.677008448
25-Feb-15	1.411044823	1.152796903
26-Feb-15	1.274476125	1.978250329
27-Feb-15	-2.251665485	1.902440027
02-Mar-15	1.88967726	1.69505695
03-Mar-15	1.242507833	1.106089289
04-Mar-15	1.63078351	0.873628573
05-Mar-15	0.775560483	2.227421767
06-Mar-15	2.010946288	1.192258874
09-Mar-15	1.888068501	2.105727569
10-Mar-15	-0.678055846	1.525451037
11-Mar-15	0.806080444	2.68549738
12-Mar-15	1.258677859	1.812518054
13-Mar-15	2.578595486	2.805730454
16-Mar-15	-0.092387294	3.662852915
17-Mar-15	-0.185031045	2.252853755
18-Mar-15	-0.899175102	1.506019623
19-Mar-15	2.497592378	3.282594738
20-Mar-15	-1.87351211	1.859667184
23-Mar-15	-3.09622256	2.977154402
24-Mar-15	0.229599259	1.932268771
25-Mar-15	1.939970942	3.364258175
26-Mar-15	-0.560769628	2.515110428
27-Mar-15	2.070711968	2.31351228
30-Mar-15	-0.611150739	1.316075247
31-Mar-15	-1.03321493	2.74894284
01-Apr-15	-0.999756818	4.442317395
02-Apr-15	-1.335940223	2.28000791
06-Apr-15	0.102416396	1.507591735
07-Apr-15	0.11828835	1.432739042
08-Apr-15	-2.602425479	0.800693154
09-Apr-15	0.27181494	1.701692168
10-Apr-15	0.577197474	1.560262413
13-Apr-15	1.481460761	1.434093827
14-Apr-15	-1.875681546	1.54968385
15-Apr-15	-1.13592817	1.206809971
16-Apr-15	-0.271110396	1.1999367
17-Apr-15	0.66982581	1.376579289
20-Apr-15	-0.273327686	1.476658231
22-Apr-15	-0.718153766	1.382617889
23-Apr-15	-1.34082089	0.732935107
24-Apr-15	-0.655186403	1.553051082
27-Apr-15	-1.169006036	0.782670511
28-Apr-15	0.693510116	1.051685187
29-Apr-15	0.813756906	1.660261716
30-Apr-15	1.780561784	2.272798394
04-May-15	2.36037839	2.378079555
05-May-15	-0.986544866	6.032666715
06-May-15	-0.705974135	1.251389989
07-May-15	-0.293705351	1.424625231
08-May-15	-1.706594315	1.002090386
11-May-15	2.902403571	1.800535706
12-May-15	-1.397612318	1.097524197
13-May-15	0.65355395	1.330180433
14-May-15	-1.501594417	1.582522481
15-May-15	0.090133704	1.023675656
18-May-15	0.28987942	1.370234083
19-May-15	1.075510475	0.655918444
20-May-15	-1.175374003	1.111335725
21-May-15	1.17866548	0.762132356
22-May-15	1.826415651	0.628552658
25-May-15	0.100137293	0.859642068
26-May-15	1.798218289	1.097618429
27-May-15	-0.438569317	0.73136278
28-May-15	0.733045726	0.750299894
29-May-15	0.501459696	1.110683092
01-Jun-15	-0.324557957	1.061975702
02-Jun-15	-1.145916963	1.880443647
03-Jun-15	0.041494439	0.775764188
05-Jun-15	0.280433581	0.808437396
08-Jun-15	-0.959270642	3.466698236
09-Jun-15	-0.496023177	0.923455366
10-Jun-15	0.678994097	0.506534011
11-Jun-15	-0.905275105	0.893225446
12-Jun-15	0.956575244	1.352275843
15-Jun-15	0.230525508	0.931646198
16-Jun-15	-1.222705796	0.816838253
17-Jun-15	-1.051185336	0.910306294
18-Jun-15	0.117708619	1.33354411
19-Jun-15	1.221190883	1.021521009
22-Jun-15	-0.566518729	0.759967223
23-Jun-15	-0.159202074	0.591226683
24-Jun-15	0.745087512	0.523500818
25-Jun-15	0.934811414	0.769115867
26-Jun-15	0.057537401	0.914280681
29-Jun-15	-0.371378688	0.880524394
30-Jun-15	-0.472616502	0.929692352
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sample_gjr_extregressor.R
Type: application/octet-stream
Size: 2907 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20150820/9b72d69b/attachment.obj>

From alexios at 4dscape.com  Thu Aug 20 19:34:52 2015
From: alexios at 4dscape.com (alexios)
Date: Thu, 20 Aug 2015 18:34:52 +0100
Subject: [R-SIG-Finance] Adding external regressors on conditional
 variance model
In-Reply-To: <CAK9d7gG91StSNvaS3eQE8ETZP42rccpbQa71XDeTW_oWd9FtgQ@mail.gmail.com>
References: <CAK9d7gFqXYtia=nnHTR=k=bLTjMFruF+X664pmANJacs9b-Wsw@mail.gmail.com>
	<55D5DDB8.503@4dscape.com>
	<CAK9d7gG91StSNvaS3eQE8ETZP42rccpbQa71XDeTW_oWd9FtgQ@mail.gmail.com>
Message-ID: <55D60FBC.9020005@4dscape.com>

Likely related to the non-negativity constraints, so scaling helps.
However, I suggest you try the eGARCH model instead for regressors in 
the variance, and search some previous posts regarding setting
the bounds on the coefficients.

Alexios

On 20/08/2015 18:19, Assis Duraes wrote:
> Thank you very much for your prompt answer and help, Alexios.
>
> I am running now some models and found some results that are puzzling me.
>
>  From another thread I saw one recommendation that we should "(...) pass
> values in the external regressor which are close in scale to the
> variance equation", what makes sense to me...
>
> However, I noticed that when I define the external regressors with
> values close to the return series, the coefficients calculated for the
> external regressors are non-significant, while I have a strong
> hypothesis that those should be relevant in the process. Nevertheless, I
> noticed that when scaling to an annual basis the external regressor
> coefficients becomes significant...
>
>
> Attached follow a sample code (sample_gjr_extregressor.R) and simplified
> database (data.txt) with daily returns (r) and lagged realized variance
> (lag_extreg) I am using as inputs for the models.
>
> 	
> 	
>
> There are three models as below:
>
> Model1: Standard GJR
> Model2: GJR with lagged daily realized variance
> Model3: GJR with lagged  realized variance annualized (scaled by 252)
>
> The table below summarizes the results found.
>
> 	model 	omega 	alpha1 	beta1 	gamma1 	   delta1 	p-val_omega
> p-val_alpha1 	p-val_beta1 	p-val_gamma1 	p-val_delta1 	LL 	For_01d
>
> 	Model1 	0.011449 	0.131705 	0.89924 	-0.08386 	   NA 	0.001217
> 0.000000 	0.000000 	0.000012 	0.000000 	-2033.96 	0.800619
>
> 	Model2 	0.011449 	0.131705 	0.899244 	-0.08387 	1.23E-08 	0.002944
> 0.000000 	0.000000 	0.000012 	0.999999 	-2033.96 	0.800635
>
> 	Model3 	0.004839 	0.066382 	0.69109 	-0.08387 	0.001161 	0.633308
> 0.037429 	0.000000 	0.010968 	0.000451 	-2012.57 	0.778901
>
>
> Any idea or suggestion on what might be happening?
>
> Thanks again in advance for any help with that issue.
>
> Best Regards,
> Assis.
>
>
>
> 2015-08-20 11:01 GMT-03:00 alexios <alexios at 4dscape.com
> <mailto:alexios at 4dscape.com>>:
>
>     Hi,
>
>     The answer is yes and yes. Add variable(s) lagged.
>
>     Best,
>
>     Alexios
>
>
>     On 20/08/2015 14:57, Assis Duraes wrote:
>
>         Hi,
>
>         first of all I would like to thanks for the rugarch package. it
>         is really
>         useful and a very nice package.
>
>         I am investigating the effect of external variables on
>         conditional variance
>         models forecasts. more specifically, I am would like to check if the
>         addition of implied volatility and realized variance as external
>         regressors
>         on a GJR (1,1) model somehow enhance the daily volatility
>         forecasts of it.
>
>         Looking for a tool to help modelling it I found the rugarch
>         package, and
>         started looking into it. In fact, at this point, I believe I
>         have a very
>         basic question. but did not find an answer on previous posts or
>         in the
>         package documentation.
>
>         Should I inform the external regressors matrix in model spec
>         already lagged
>         or not? I imagine, yes, since I did not find in any place where
>         specify the
>         lags for those regressors, but would like to confirm. In case
>         affirmative,
>         If I want to use a same variable with different lags I need to
>         inform it
>         multiple times, obviously with different lags, in
>         external.regressors
>         matrix, correct?
>
>         My apologies in advance if it is explained somewhere, but as I
>         explained, i
>         search without much success..
>
>         Thanks in advance for any help with that,
>         Assis.
>
>                  [[alternative HTML version deleted]]
>
>         _______________________________________________
>         R-SIG-Finance at r-project.org <mailto:R-SIG-Finance at r-project.org>
>         mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>         -- Subscriber-posting only. If you want to post, subscribe first.
>         -- Also note that this is not the r-help list where general R
>         questions should go.
>
>
>
>


From jmtruppia at gmail.com  Tue Aug 25 14:26:48 2015
From: jmtruppia at gmail.com (juancentro)
Date: Tue, 25 Aug 2015 05:26:48 -0700 (PDT)
Subject: [R-SIG-Finance] EIKON REUTERS
In-Reply-To: <AANLkTinW8ewOzXVB83RXAj7PxnL=1619i--XeHYuNJjm@mail.gmail.com>
References: <4D55182D.10502@ath.forthnet.gr>
	<AANLkTinW8ewOzXVB83RXAj7PxnL=1619i--XeHYuNJjm@mail.gmail.com>
Message-ID: <1440505608891-4711462.post@n4.nabble.com>

I know this is an old thread, but for the record (and google searches) I have
developed a package to connect Eikon to R.
You can find it  here <https://bitbucket.org/juancentro/reikon>  .
Any kind of feedback will be appreciated.
Please leave any issues (bugs, enhancement, etc) on Bitbucket's issue
tracker.

Regards, and sorry for using this old thread.

Juan



--
View this message in context: http://r.789695.n4.nabble.com/EIKON-REUTERS-tp3301140p4711462.html
Sent from the Rmetrics mailing list archive at Nabble.com.


From tsferro2 at gmail.com  Wed Aug 26 15:12:48 2015
From: tsferro2 at gmail.com (Tucker Sferro)
Date: Wed, 26 Aug 2015 13:12:48 +0000
Subject: [R-SIG-Finance] calculating beta-based variable dollar amounts to
 each leg of a spread backtest
Message-ID: <CAJ9N7v2Nr7RTusN-YPpYKZ0nV=xq_4rkHx-2zaEbdJRhez22Zg@mail.gmail.com>

I am currently working on a pairs trading backtest R script and have hit a
wall in my efforts to generate dollar based backtesting that adjusts for
the hedgeRatio ("beta" in my script) to each leg in a stock pair backtest.
My existing script is mostly taken from Joshua Ulrich's pairs quantstrat
backtest example.

The script as-is backtests equal dollar amounts per pair, but this value is
different between sets of pairs because Joshua's script uses a ratio
spread, which is used to adjust the amount to buy for stock B in the pair.
Stock A could be any price and the share amount remains fixed, meaning the
dollar investment amount will vary between pairs. This is nonetheless ok,
as I am only testing for risk-adjusted returns - *most importantly I would
simply like to adjust the dollar invest amount based on the hedge ratio*.
I've tried unsuccessfully to use the IKTrading  osMaxDollar function, but
have hit a wall since Joshua's script uses an order sizing function that
makes the 2nd stock shares to trade the opposite of the first stock.

I've also looked at Ilya Kipnis's example of modeling the spread itself(
https://quantstrattrader.wordpress.com/category/quantstrat/) but this
apparently doesn't work since the dollar investment amount needs to
be adjusted for each leg on a per trade basis. I have tried to resolve this
for literally more than 2 weeks (stack exchange, demo deconstructing, etc)
without any luck and was wondering if anyone on this list would be so kind
as to have a look at my script? Perhaps you could point me in the right
direction with a couple lines of helper code? I really don't know where
else to turn and could very much use the help. Below is the code with the
working script (ie all versions which incorporate osMaxDollar have been
left out because they don't work!).

-T
======================================================

## given 2 stocks, calculate their ratio.  If the ratio falls below it's 2
stdev band, then when it crosses back above it, buy stock 1 and sell stock
2. If the ratio rises above it's 2 stdev band, then when it crosses back
below # it, sell stock 1 and buy stock 2.  If the ratio crosses it's moving
average then flatten any open positions.
# The Qty of Stock A that it buys (sells) = MaxPos / lvls
# The Qty of Stock B that is sells (buys) = MaxPos * Ratio / lvls

try(rm("order_book.pair1",pos=.strategy),silent=TRUE)
try(rm("account.pairs", "portfolio.pair1", pos=.blotter), silent=TRUE)
try(rm("initDate", "endDate", "startDate", "initEq", "SD", "N", "symb1",
"symb2",
"portfolio1.st", "account.st", "pairStrat", "out1"), silent=TRUE)

require(quantstrat)
require(FinancialInstrument)

symb1 <- 'data'
symb2 <- 'panw'
symb1 <- toupper(symb1)
symb2 <- toupper(symb2)

initDate = '2000-01-01'
startDate = '2014-08-21'
endDate = '2015-08-21'
SD = 1.5
N = 20
initEq = 100000

#max position in stock B will be max * ratio, i.e. no hard position limit
in Stock B
lvls = 0 #how many times to fade; Each order's qty will = MaxPos/lvls

portfolio1.st <- 'pair1'
account.st <- 'pairs'

suppressWarnings(getSymbols(c(symb1, symb2), from=startDate, to=endDate,
adjust=TRUE))
MaxPos = 1000
currency("USD")
stock(symb1, currency="USD", multiplier=1)
stock(symb2, currency="USD", multiplier=1)

#Initialize Portfolio, Account, and Orders
initPortf(name=portfolio1.st, c(symb1,symb2), initDate=initDate)
initAcct(account.st, portfolios=portfolio1.st, initDate=initDate,
initEq=initEq)
initOrders(portfolio=portfolio1.st,initDate=initDate)

#create a slot in portfolio for symb1 and symb2 to make them available to
osFUN
pair <- c('long','short')
names(pair) <- c(symb1,symb2)
.blotter[[paste('portfolio',portfolio1.st,sep='.')]]$pair <- pair

# Create initial position limits and levels by symbol
# allow "3" entries for long and short.
addPosLimit(portfolio=portfolio1.st, timestamp=initDate, symbol=symb1,
maxpos=MaxPos, longlevels=lvls, minpos=-MaxPos, shortlevels=lvls)
addPosLimit(portfolio=portfolio1.st, timestamp=initDate, symbol=symb2,
maxpos=MaxPos, longlevels=lvls, minpos=-MaxPos, shortlevels=lvls)

# Create a strategy object
pairStrat <- strategy('pairStrat')

calcRatio <- function(x) { #returns the ratio of close prices for 2 symbols
x1 <- get(x[1])
x2 <- get(x[2])
rat <- Ad(x1) / Ad(x2)
colnames(rat) <- 'Ratio'
rat
}
Ratio <- calcRatio(c(symb1[1],symb2[1]))
#let's go ahead and put this in a slot in portfolio
.blotter[[paste('portfolio',portfolio1.st,sep='.')]]$Ratio <- Ratio # TS
change from Ratio
#and make a function to get the most recent Ratio
getRatio <- function(portfolio, timestamp) {
portf <- getPortfolio(portfolio)
toDate <- paste("::", timestamp, sep="")
Ratio <- last(portf$Ratio[toDate])
as.numeric(Ratio)
}




#calculate hedge ratio and egcm / ADF p-value
stckY <- zoo(Ad(stckY))
stckX <- zoo(Ad(stckX))

m <- lm(stckY ~ stckX + 0)
beta <- coef(m)[1]




# Create an indicator - BBands on the Ratio
pairStrat <- add.indicator(strategy = pairStrat, name = "calcRatio",
arguments = list(x=c(symb1,symb2)))
pairStrat <- add.indicator(strategy = pairStrat, name = "BBands", arguments
= list(HLC=quote(Ratio), sd=SD, n=N, maType='EMA'))

#applyIndicators(strategy=pairStrat,mktdata=get(symb1[1])) #for debugging

# Create signals - buy when crossing lower band from below, sell when
crossing upper band from above, flatten when crossing mavg from above or
from below
#TS - changed for No REV
pairStrat <- add.signal(strategy = pairStrat, name = "sigCrossover",
arguments= list(columns=c("Ratio","up"), relationship="gt"),
label="cross.up")
pairStrat <- add.signal(strategy = pairStrat, name = "sigCrossover",
arguments= list(columns=c("Ratio","dn"), relationship="lt"),
label="cross.dn")
pairStrat <- add.signal(strategy = pairStrat, name = "sigCrossover",
arguments= list(columns=c("Ratio","mavg"), relationship="lt"),
label="cross.mid.fa")
pairStrat <- add.signal(strategy = pairStrat, name = "sigCrossover",
arguments= list(columns=c("Ratio","mavg"), relationship="gt"),
label="cross.mid.fb")

#make an order sizing function
#######################_ORDER SIZING
FUNCTION_##########################################################
#check to see which stock it is. If it's the second stock, reverse orderqty
and orderside
osSpreadMaxPos <- function (data, timestamp, orderqty, ordertype,
orderside, portfolio, symbol, ruletype, ..., orderprice)
{
portf <- getPortfolio(portfolio)
    legside <- portf$pair[symbol] #"long" if symbol=symb1, "short" if
symbol=symb2
if (legside != "long" && legside != "short") stop('pair must contain "long"
and "short"')
ratio <- getRatio(portfolio, timestamp)
pos <- getPosQty(portfolio, symbol, timestamp)
    PosLimit <- getPosLimit(portfolio, symbol, timestamp)
qty <- orderqty
if (legside == "short") {#symbol is 2nd leg
## Comment out next line to use equal ordersizes for each stock.
addPosLimit(portfolio=portfolio, timestamp=timestamp, symbol=symbol,
maxpos=MaxPos*ratio, longlevels=lvls, minpos=-MaxPos*ratio,
shortlevels=lvls)
#TODO: is it okay that MaxPos and lvls come from .GlobalEnv ?
qty <- -orderqty #switch orderqty for Stock B
}
if (qty > 0) orderside = 'long'
if (qty < 0) orderside = 'short'

orderqty <-
osMaxPos(data=data,timestamp=timestamp,orderqty=qty,ordertype=ordertype,
orderside=orderside,portfolio=portfolio,symbol=symbol,ruletype=ruletype,
...)
orderqty <- round(orderqty,0)

#Add the order here instead of in the ruleSignal function
if (!is.null(orderqty) & !orderqty == 0 & !is.null(orderprice)) {
            addOrder(portfolio = portfolio, symbol = symbol,
                timestamp = timestamp, qty = orderqty, price =
as.numeric(orderprice),
                ordertype = ordertype, side = orderside,
                status = "open", ... = ...)
    }
return(0) #so that ruleSignal function doesn't also try to place an order
}
########################################################################################################

# Create entry and exit rules for longs  and for shorts. Both symbols will
get the same buy/sell signals, but osMaxPos will reverse those for the
second symbol.
# orderqty's are bigger than PosLimits allow. osMaxPos will adjust the
orderqty down to 1/3 the max allowed. (1/3 is because we are using 3 levels
in PosLimit)
pairStrat <- add.rule(strategy = pairStrat, name='ruleSignal', arguments =
list(sigcol="cross.dn", sigval=TRUE, orderqty=1e6, ordertype='market',
orderside=NULL, prefer = "Open", TxnFees="pennyPerShare",
osFUN='osSpreadMaxPos'), type='enter' )
pairStrat <- add.rule(strategy = pairStrat, name='ruleSignal', arguments =
list(sigcol="cross.up", sigval=TRUE, orderqty=-1e6, ordertype='market',
orderside=NULL, prefer = "Open",
TxnFees="pennyPerShare",osFUN='osSpreadMaxPos'), type='enter')
pairStrat <- add.rule(strategy = pairStrat, name='ruleSignal', arguments =
list(sigcol="cross.mid.fb", sigval=TRUE, orderqty='all',
ordertype='market', orderside=NULL, prefer = "Open",
TxnFees="pennyPerShare"), type='exit')
pairStrat <- add.rule(strategy = pairStrat, name='ruleSignal', arguments =
list(sigcol="cross.mid.fa", sigval=TRUE, orderqty='all',
ordertype='market', orderside=NULL, prefer = "Open",
TxnFees="pennyPerShare"), type='exit')
#applySignals(strategy=pairStrat,
mktdata=applyIndicators(strategy=pairStrat,mktdata=get(symb1))) #for
debugging

out1<-try(applyStrategy(strategy=pairStrat, portfolios=portfolio1.st))

updatePortf(Portfolio=portfolio1.st
,Dates=paste("::",as.Date(Sys.time()),sep=''))
updateAcct(account.st,Dates=paste(startDate,endDate,sep="::"))
updateEndEq(account.st,Dates=paste(startDate,endDate,sep="::"))
getEndEq(account.st,Sys.time())

#dev.new()
#chart.Posn(Portfolio=portfolio1.st,Symbol=symb1)
#dev.new()
#chart.Posn(Portfolio=portfolio1.st,Symbol=symb2)
#dev.new()
#chartSeries(Cl(get(symb1))/Cl(get(symb2)),TA="addBBands()")

ret1 <- PortfReturns(account.st)
ret1$total <- rowSums(ret1)
#ret1

if("package:PerformanceAnalytics" %in% search() ||
require("PerformanceAnalytics",quietly=TRUE)) {
tmp <- ret1$total
#dev.new()
charts.PerformanceSummary(tmp,geometric=FALSE,wealth.index=TRUE, main =
paste(symb1,symb2,sep="/"))
}
table.Drawdowns(ret1)
getEndEq(account.st, Sys.time())
table.AnnualizedReturns(ret1)

	[[alternative HTML version deleted]]


From brian at braverock.com  Wed Aug 26 16:08:24 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 26 Aug 2015 09:08:24 -0500
Subject: [R-SIG-Finance] calculating beta-based variable dollar amounts
 to each leg of a spread backtest
In-Reply-To: <CAJ9N7v2Nr7RTusN-YPpYKZ0nV=xq_4rkHx-2zaEbdJRhez22Zg@mail.gmail.com>
References: <CAJ9N7v2Nr7RTusN-YPpYKZ0nV=xq_4rkHx-2zaEbdJRhez22Zg@mail.gmail.com>
Message-ID: <1440598104.9885.13.camel@brian-rcg>

On Wed, 2015-08-26 at 13:12 +0000, Tucker Sferro wrote:
> I am currently working on a pairs trading backtest R script and have hit a
> wall in my efforts to generate dollar based backtesting that adjusts for
> the hedgeRatio ("beta" in my script) to each leg in a stock pair backtest.
> My existing script is mostly taken from Joshua Ulrich's pairs quantstrat
> backtest example.

The pairs trading demo was originally written by Garrett See, for the
record.

As is stated very clearly in the comments on the demo script, you would
never trade equity pairs this way.  

You should use a spreader.  Period.  

If you don't have a spreader, you shouldn't be trying to trade intra-day
stat arb pair trades.  

If you're trading long-cycle portfolio baskets, you likely don't need
quantstrat, and would be better off using Return.portfolio and a
timeseries of weights as a first approximation.
 

> The script as-is backtests equal dollar amounts per pair, but this value is
> different between sets of pairs because Joshua's script uses a ratio
> spread, which is used to adjust the amount to buy for stock B in the pair.
> Stock A could be any price and the share amount remains fixed, meaning the
> dollar investment amount will vary between pairs. This is nonetheless ok,
> as I am only testing for risk-adjusted returns - *most importantly I would
> simply like to adjust the dollar invest amount based on the hedge ratio*.
> I've tried unsuccessfully to use the IKTrading  osMaxDollar function, but
> have hit a wall since Joshua's script uses an order sizing function that
> makes the 2nd stock shares to trade the opposite of the first stock.
> 
> I've also looked at Ilya Kipnis's example of modeling the spread itself(
> https://quantstrattrader.wordpress.com/category/quantstrat/) but this
> apparently doesn't work since the dollar investment amount needs to
> be adjusted for each leg on a per trade basis. I have tried to resolve this
> for literally more than 2 weeks (stack exchange, demo deconstructing, etc)
> without any luck and was wondering if anyone on this list would be so kind
> as to have a look at my script? Perhaps you could point me in the right
> direction with a couple lines of helper code? I really don't know where
> else to turn and could very much use the help. Below is the code with the
> working script (ie all versions which incorporate osMaxDollar have been
> left out because they don't work!).

Construct multiple spreads. Trade these as instruments in your backtest.

for symbols

ABC
DEF
GHI

e.g.

stock('ABC')
stock('DEF')
stock('GHI')

you can construct spreads

ABC.DEF
DEF.GHI
ABC.GHI

e.g.

spread('ABC.DEF',members=c('ABC','DEF'),memberratio=c(ABC=1,DEF=-1))
spread('DEF.GHI',members=c('DEF','GHI'),memberratio=c(DEF=1,GHI=-2))
spread('ABC.GHI',members=c('ABC','GHI'),memberratio=c(ABC=1,GHI=-10))

(note different ratios for each pair)

presumably your ratios came from some beta calculation you've performed.

and you can now construct the spread time series using buildSpread or
your own function.  Your strategy works on the spreads.

If you want the ratio to change over time, that's actually a different
spread.

At one firm I was at, we would put the spread ratio into the primary_id
of the spread, e.g. ZF3.ZN2 ZF5.ZN3 though there are other approaches
that would be equally valid.

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From karve.amod at gmail.com  Thu Aug 27 06:51:52 2015
From: karve.amod at gmail.com (=?UTF-8?B?QW1vZCBLYXJ2ZSAo4KSF4KSu4KWL4KSmKQ==?=)
Date: Thu, 27 Aug 2015 00:51:52 -0400
Subject: [R-SIG-Finance] Help activating stop loss order.
Message-ID: <CAFauerNdNhXc+uN2_OxSk+AgmSECo7iwnxiQGEA43L0U+9yj=Q@mail.gmail.com>

Hey All,

 For the life of me I can't figure out why my stop loss order is not
getting triggered. I am trying to play around with a simple Trend vigor
strategy as illustrated in Ilya kipnis's blog. Everything else works except
for the stop loss order which doesn't seem to take effect. I can't even see
the stop loss in my order book (I see it only if I set type='risk' instead
of chain).

Could someone help me figure out where the problem might be?

Attached please find the code.

Thanks
amod
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20150827/90a9d0a4/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: elhers_tvi.r
Type: application/octet-stream
Size: 4478 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20150827/90a9d0a4/attachment.obj>

From karve.amod at gmail.com  Thu Aug 27 07:00:07 2015
From: karve.amod at gmail.com (=?UTF-8?B?QW1vZCBLYXJ2ZSAo4KSF4KSu4KWL4KSmKQ==?=)
Date: Thu, 27 Aug 2015 01:00:07 -0400
Subject: [R-SIG-Finance] Help activating stop loss order.
In-Reply-To: <CAFauerNdNhXc+uN2_OxSk+AgmSECo7iwnxiQGEA43L0U+9yj=Q@mail.gmail.com>
References: <CAFauerNdNhXc+uN2_OxSk+AgmSECo7iwnxiQGEA43L0U+9yj=Q@mail.gmail.com>
Message-ID: <CAFauerOCNZPgK6PzFySWmwDUEjPr01DO-faGg8dPb0szGWw3NQ@mail.gmail.com>

forgot to add the contents of position_sizing.r. Here it is:

osFixedDollar <- function(data, timestamp, orderqty, portfolio, symbol,
ruletype, ...) {
  ClosePrice <- as.numeric(Cl(mktdata[timestamp,]))
  orderqty <- round(tradeSize / ClosePrice, -2)
  return(orderqty)
}


On Thu, Aug 27, 2015 at 12:51 AM, Amod Karve (????) <karve.amod at gmail.com>
wrote:

> Hey All,
>
>  For the life of me I can't figure out why my stop loss order is not
> getting triggered. I am trying to play around with a simple Trend vigor
> strategy as illustrated in Ilya kipnis's blog. Everything else works except
> for the stop loss order which doesn't seem to take effect. I can't even see
> the stop loss in my order book (I see it only if I set type='risk' instead
> of chain).
>
> Could someone help me figure out where the problem might be?
>
> Attached please find the code.
>
> Thanks
> amod
>

	[[alternative HTML version deleted]]


From karve.amod at gmail.com  Wed Sep  2 04:36:41 2015
From: karve.amod at gmail.com (=?UTF-8?B?QW1vZCBLYXJ2ZSAo4KSF4KSu4KWL4KSmKQ==?=)
Date: Tue, 1 Sep 2015 22:36:41 -0400
Subject: [R-SIG-Finance] Bug in ruleOrderProc (as.Date(tif.xts)
Message-ID: <CAFauerN+6xZNARiryuopphvYM7t39ix5mHxdoK4ZtSf2F1UUJA@mail.gmail.com>

I ran into a bug when trying to use time.in.force in ruleOrderProc. When
specifying a numeric value for time.in.force, I was getting an error in
ruleOrderProc when calling:

 tif <- as.Date(tif.xts)

I think the problem is that the underlying tif.xts is a zoo object and
as.Date() fails on it. When I removed the as.Date(), the backtest ran fine.

What's the process for patching in bug fixes?

Thanks
amod

	[[alternative HTML version deleted]]


From johannes.lips at gmail.com  Wed Sep  2 10:37:39 2015
From: johannes.lips at gmail.com (Johannes Lips)
Date: Wed, 2 Sep 2015 10:37:39 +0200
Subject: [R-SIG-Finance] Cholesky Decomposition in Impulse Response Functions
Message-ID: <55E6B553.1000503@gmail.com>

Dear list,

I am wondering if there's a way to tell the irf() command, in which 
order the cholesky decompostion should have. In other words how can I 
tell the irf command in which way the simultaneous effects should be 
modeled? Is it somehow based on the order of the variables in the 
var.est object?
It would be great, if someone could shed some light on this, because I 
also couldn't find anything on the internet.

Thanks a lot,
Johannes


From brian at braverock.com  Wed Sep  2 11:44:20 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 02 Sep 2015 04:44:20 -0500
Subject: [R-SIG-Finance] Cholesky Decomposition in Impulse Response
	Functions
In-Reply-To: <55E6B553.1000503@gmail.com>
References: <55E6B553.1000503@gmail.com>
Message-ID: <55E6C4F4.2000201@braverock.com>

On 09/02/2015 03:37 AM, Johannes Lips wrote:
> I am wondering if there's a way to tell the irf() command, in which
> order the cholesky decompostion should have. In other words how can I
> tell the irf command in which way the simultaneous effects should be
> modeled? Is it somehow based on the order of the variables in the
> var.est object?
> It would be great, if someone could shed some light on this, because I
> also couldn't find anything on the internet.

You didn't mention that you were speaking of the irf function from 
package vars, but I'll proceed on that assumption.

It seems that you can answer your own question by looking at the source.

vars::irf dispatches to one of:

vars:::irf.svarest
vars:::irf.svecest
vars:::irf.varest
vars:::irf.vec2var

all of these, in turn, call

vars:::.irf

and/or an appropriate

vars:::.bootirf[*]

and/or an appropriate

vars:::Phi.*

function.

from examination of the Phi functions, it appears that the recursive 
portion you're looking for is there, and does the matrix math over the 
inverse of the A matrix.

However, the ordering of variables seems to be a simple lapply over 
coef. in the coef methods.

So, not quite an answer, but hopefully I've pointed you towards where 
your answer lies.

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From josh.m.ulrich at gmail.com  Wed Sep  2 12:23:35 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 2 Sep 2015 05:23:35 -0500
Subject: [R-SIG-Finance] Bug in ruleOrderProc (as.Date(tif.xts)
In-Reply-To: <CAFauerN+6xZNARiryuopphvYM7t39ix5mHxdoK4ZtSf2F1UUJA@mail.gmail.com>
References: <CAFauerN+6xZNARiryuopphvYM7t39ix5mHxdoK4ZtSf2F1UUJA@mail.gmail.com>
Message-ID: <CAPPM_gT+nk8F089eGN3aUb4BBPxuhP8PFsK81X1D-wy5ii10=Q@mail.gmail.com>

Hi Amod,

On Tue, Sep 1, 2015 at 9:36 PM, Amod Karve (????) <karve.amod at gmail.com> wrote:
> I ran into a bug when trying to use time.in.force in ruleOrderProc. When
> specifying a numeric value for time.in.force, I was getting an error in
> ruleOrderProc when calling:
>
>  tif <- as.Date(tif.xts)
>
> I think the problem is that the underlying tif.xts is a zoo object and
> as.Date() fails on it. When I removed the as.Date(), the backtest ran fine.
>
> What's the process for patching in bug fixes?
>
Thanks for the feedback.  The best way to contribute a patch is to
create a minimal strategy that allows us to reproduce the issue you
see, along with your patch.  That will allow us to verify the issue,
and evaluate your patch.

Once you have that, please open an issue on the TradeAnalytics tracker
on R-Forge:
https://r-forge.r-project.org/tracker/?group_id=316

> Thanks
> amod
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From johannes.lips at gmail.com  Wed Sep  2 13:19:15 2015
From: johannes.lips at gmail.com (Johannes Lips)
Date: Wed, 2 Sep 2015 13:19:15 +0200
Subject: [R-SIG-Finance] Cholesky Decomposition in Impulse Response
 Functions
In-Reply-To: <55E6C4F4.2000201@braverock.com>
References: <55E6B553.1000503@gmail.com> <55E6C4F4.2000201@braverock.com>
Message-ID: <55E6DB33.2060703@gmail.com>



On 02.09.2015 11:44, Brian G. Peterson wrote:
> On 09/02/2015 03:37 AM, Johannes Lips wrote:
>> I am wondering if there's a way to tell the irf() command, in which
>> order the cholesky decompostion should have. In other words how can I
>> tell the irf command in which way the simultaneous effects should be
>> modeled? Is it somehow based on the order of the variables in the
>> var.est object?
>> It would be great, if someone could shed some light on this, because I
>> also couldn't find anything on the internet.
>
> You didn't mention that you were speaking of the irf function from 
> package vars, but I'll proceed on that assumption.
>
> It seems that you can answer your own question by looking at the source.
>
> vars::irf dispatches to one of:
>
> vars:::irf.svarest
> vars:::irf.svecest
> vars:::irf.varest
> vars:::irf.vec2var
>
> all of these, in turn, call
>
> vars:::.irf
>
> and/or an appropriate
>
> vars:::.bootirf[*]
>
> and/or an appropriate
>
> vars:::Phi.*
>
> function.
>
> from examination of the Phi functions, it appears that the recursive 
> portion you're looking for is there, and does the matrix math over the 
> inverse of the A matrix.
Thanks Brian,

yeah, sorry for not being more specific. I was talking about the irf() 
from the vars package, which is also used by tsDyn as far as I can tell.
I will have a look into all these functions and will try to figure it 
out. I thought it might be documented somewhere, because it's fairly 
common in most other econometrics packages. (This is not meant as a rant!)
But I don't know how we could improve the documentation of all these 
packages and functions.

Regards,
Johannes

>
> However, the ordering of variables seems to be a simple lapply over 
> coef. in the coef methods.
>
> So, not quite an answer, but hopefully I've pointed you towards where 
> your answer lies.
>
> Regards,
>
> Brian
>


From johannes.lips at gmail.com  Wed Sep  2 14:05:02 2015
From: johannes.lips at gmail.com (Johannes Lips)
Date: Wed, 2 Sep 2015 14:05:02 +0200
Subject: [R-SIG-Finance] Cholesky Decomposition in Impulse Response
 Functions
In-Reply-To: <55E6DB33.2060703@gmail.com>
References: <55E6B553.1000503@gmail.com> <55E6C4F4.2000201@braverock.com>
	<55E6DB33.2060703@gmail.com>
Message-ID: <55E6E5EE.9010709@gmail.com>



On 02.09.2015 13:19, Johannes Lips wrote:
>
>
> On 02.09.2015 11:44, Brian G. Peterson wrote:
>> On 09/02/2015 03:37 AM, Johannes Lips wrote:
>>> I am wondering if there's a way to tell the irf() command, in which
>>> order the cholesky decompostion should have. In other words how can I
>>> tell the irf command in which way the simultaneous effects should be
>>> modeled? Is it somehow based on the order of the variables in the
>>> var.est object?
>>> It would be great, if someone could shed some light on this, because I
>>> also couldn't find anything on the internet.
>>
>> You didn't mention that you were speaking of the irf function from 
>> package vars, but I'll proceed on that assumption.
>>
>> It seems that you can answer your own question by looking at the source.
>>
>> vars::irf dispatches to one of:
>>
>> vars:::irf.svarest
>> vars:::irf.svecest
>> vars:::irf.varest
>> vars:::irf.vec2var
>>
>> all of these, in turn, call
>>
>> vars:::.irf
>>
>> and/or an appropriate
>>
>> vars:::.bootirf[*]
>>
>> and/or an appropriate
>>
>> vars:::Phi.*
>>
>> function.
>>
>> from examination of the Phi functions, it appears that the recursive 
>> portion you're looking for is there, and does the matrix math over 
>> the inverse of the A matrix.
> Thanks Brian,
>
> yeah, sorry for not being more specific. I was talking about the irf() 
> from the vars package, which is also used by tsDyn as far as I can tell.
> I will have a look into all these functions and will try to figure it 
> out. I thought it might be documented somewhere, because it's fairly 
> common in most other econometrics packages. (This is not meant as a 
> rant!)
> But I don't know how we could improve the documentation of all these 
> packages and functions.
>
> Regards,
> Johannes
Just for the record. One can change the order of the cholesky 
decomposition by changing the order in the initial VAR() call. So it's 
quite easy to get the desired outcome.

Regards,
Johannes
>
>>
>> However, the ordering of variables seems to be a simple lapply over 
>> coef. in the coef methods.
>>
>> So, not quite an answer, but hopefully I've pointed you towards where 
>> your answer lies.
>>
>> Regards,
>>
>> Brian
>>
>


From ilya.kipnis at gmail.com  Tue Sep  8 16:30:54 2015
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Tue, 8 Sep 2015 10:30:54 -0400
Subject: [R-SIG-Finance] Constant maturity Futures
In-Reply-To: <CA+xi=qZ2ykXsWfGY5REEvC7Ru4cxCy-TXitELw5deiq7vwv6Yg@mail.gmail.com>
References: <CACCk-cHAS+yBjr9xuJqDiQLoQVt39sLMtdOe6+=LUjoCB08=hw@mail.gmail.com>
	<CA+xi=qZ2ykXsWfGY5REEvC7Ru4cxCy-TXitELw5deiq7vwv6Yg@mail.gmail.com>
Message-ID: <CA+oJuEF27-94j6XpPmc086TkZ6abADMREQBbuunqa2UpDXeDDA@mail.gmail.com>

Hi Garrett,

I just tested this code out and...it doesn't compute up to the most current
day. As of now, the term.structure function ends at 2015-08-19. AKA in the
last month. Is there a way to make it go up to the last day for which there
is data available? Thanks.

-Ilya

On Thu, Aug 13, 2015 at 5:56 PM, G See <gsee000 at gmail.com> wrote:

> Hi Samuel,
>
> Here's some code (also attached) that creates constant maturity
> futures for VIX futures.  I wrote this code 4 years ago.  I'm not
> particularly proud of it.  I don't know for sure that it works.  It
> might not be elegant.  etc.  Take it for what it's worth.
>
> You should be able to source this code and get a time series plot of
> several different CMFs of varying maturities.  You'll need my qmao
> package which you can install with
> devtools::install_github("gsee/qmao")
>
>
> #' @export
> #' @rdname primary2expiry
> suffix2expiry <- function(suffix, root='VX', ...) {
>     if (exists(paste('suffix2expiry',root,sep="."))) {
>         do.call(paste('suffix2expiry',root,sep='.'),list(suffix, ...))
>     } else {
>         warning(paste(root, 'is not and available suffix2expiry
> method; using "VX" instead'))
>         do.call('suffix2expiry.VX',list(suffix, ...))
>     }
> }
>
> #' Get the expiration date of an instrument given it's primary_id
> #'
> #' \code{primary2expiry} is basically a wrapper for
> \code{\link{suffix2expiry}}.  It uses
> #' \code{\link[FinancialInstrument]{parse_id}} to split the
> \code{primary_id} into rood_id and suffix_id.
> #' then it calls the appropriate \code{\link{suffix2expiry}} method.
> #'
> #' \code{suffix2expiry} is a generic-like function.  There should be a
> method defined
> #' the "root_id".  Currently, written methods include "VX", "ES" (and
> aliases "YM", "NQ").
> #' There are links to methods help pages in the seealso section.
> #'
> #' @param primary_id character string.  Primary identifier of the
> instrument
> #' @param root character string. root symbol like "ES" or "VX" (NULL)
> #' @param silent silence warnings? (TRUE)
> #' @param suffix character string that indicates expiration month and
> year (and, for options, right and strike).
> #' See \code{\link[FinancialInstrument]{parse_suffix}} for examples of
> acceptable formats.
> #' @param ... any arguments to be passed to the \code{suffix2expiry} method
> #' @return expiration Date
> #' @seealso \code{\link{suffix2expiry.VX}}, \code{\link{suffix2expiry.ES}}
> #' @aliases primary2expiry, suffix2expiry
> #' @author gsee
> #' @examples
> #' primary2expiry("ESU1")
> #' suffix2expiry('V11', root='VX')
> #' @export
> #' @rdname primary2expiry
> primary2expiry <- function(primary_id, root=NULL, silent=TRUE) {
>   idlist <- parse_id(primary_id, silent=silent)
>   if (is.null(root)) root <- idlist$root
>   do.call(paste("suffix2expiry",root,sep='.'),
> list(suffix=idlist$suffix, silent=silent))
> }
>
>
> #' VIX future contract expiration date
> #'
> #' Calculate the expiration date of a VIX future contract given a suffix_id
> #'
> #' Per the contract specs, expiration will occur on \dQuote{the Wednesday
> that
> #' is thirty days prior to the third Friday of the calendar month
> #' immediately following the month in which the contract expires
> ("Final Settlement Date").
> #' If the third Friday of the month subsequent to expiration of the
> applicable
> #' VIX futures contract is a CBOE holiday, the Final Settlement Date
> for the contract
> #' shall be thirty days prior to the CBOE business day immediately
> preceding that Friday.}
> #' @param suffix suffix_id that should be something like (\sQuote{U1},
> \sQuote{U11}, or \sQuote{SEP11})
> #' @param silent silence warnings? (TRUE)
> #' @return an expiration Date
> #' @author gsee
> #' @references \url{http://cfe.cboe.com/products/spec_vix.aspx}
> #' @examples
> #' \dontrun{
> #' suffix2expiry.VX('U11')
> #' suffix2expiry.VX("JUN09")
> #' }
> #' @export
> suffix2expiry.VX <- suffix2expiry.VIX <- function(suffix, silent=TRUE) {
>     #require('timeDate')
>     sl <- parse_suffix(suffix,silent=silent)
>     DT <- as.Date(paste(15, sl$month, sl$year,sep='-'),format="%d-%b-%Y")
>     Y <- format(DT,"%Y")
>     M <- format((DT + 30),"%m")
>     if (as.numeric(M) == 1) Y <- paste(as.numeric(Y) + 1)
>     DS <- as.Date(paste(Y,M,01,sep='-'))+0:22
>     DS <- DS[months(DS, abbreviate=TRUE) == C2M()[as.numeric(M)]]
>     ds <- which(weekdays(DS) == "Friday")[3]
>     if (DS[ds] %in% as.Date(holidayNYSE(as.numeric(Y))@Data)) {
>         while (DS[ds] %in% as.Date(holidayNYSE(as.numeric(Y))@Data)
>                 || any(c('Saturday', 'Sunday') == weekdays(DS[ds])))
>             ds <- ds-1
>     }
>     #try(detach(package:timeDate), silent=TRUE);
> try(detach(package:timeSeries), silent=TRUE)
>     DS[ds] - 30
> }
>
>
>
>
>
> .interp.fut.VX <- function(x1, x2, n=36, prefer='Close') {
>     xs <- c(x1,x2) # names of 2 instruments
>     x1 <- get(x1,pos=.GlobalEnv)
>     x2 <- get(x2,pos=.GlobalEnv)
>
>     x1$DTE <- primary2expiry(xs[1])-index(x1)#, index(x1)) #dlf(x1)
>     x2$DTE <- primary2expiry(xs[2])-index(x2)#, index(x2)) #dlf(x2)
>     df <- merge(x1$DTE,x2$DTE,all=FALSE)
>     df <- na.omit(df)
>     if (length(df[,1]) && length(df[,2])) {
>         Pcmf <- xts()
>         if(all(df[,1] < df[,2])) {
>             col1 <- 1
>             col2 <- 2
>         } else if (all(df[,2] < df[,1])) {
>             col1 <- 2
>             col2 <- 1
>         } else stop(paste("ambiguous nearby contract",xs))
>         for (ns in n) {
>             idx <- index(df[(df[,col1] <= ns) & (df[,col2] > ns)])
>             if (length(idx) == 0) return(NULL)
>             w <- 1/ns
>             P1 <- try(getPrice(x1[idx],prefer=prefer))
>             P2 <- try(getPrice(x2[idx],prefer=prefer))
>             wP <- try((w*P1) + ((1-w)*P2))
>             if (!any(sapply(list(P1,P2,wP), inherits, 'try-error')))
>                 Pcmf <- cbind(Pcmf,wP)
>         }
>     #indexClass(Pcmf) <- 'Date' ## xts kind of broke this.
>     Pcmf
>     }
> }
>
>
> term.structure <- function(Symbols, cdays=c(35,60,90,120)) {
>     s <- Symbols
>     cnames <- paste(strsplit(s[[1]],"_")[[1]][1], "cm", cdays, sep=".")
>     a <- list()
>     for (i in 2:length(s)) {
>         tmp <- .interp.fut.VX(s[i-1],s[i],cdays)
>         if (length(tmp)) {
>             a[[i-1]] <- tmp
>             colnames(a[[i-1]]) <- cnames
>         }
>     }
>     #for (i in 1:length(a)) colnames(a[[i]]) <- paste("VX.CM", tdays,
> sep=".")
>     cb <- NULL
>     for (i in 1:length(cdays)) {
>         rb <- na.omit(a[[1]][,i])
>         for (j in 2:(length(s)-1)) {
>             if (length(a) > j && length(a[[j]][,i]) &&
>                 length(na.omit(a[[j]][,i])))
>               rb <- rbind(rb, na.omit(a[[j]][,i]))
>         }
>         cb <- as.xts(cbind(cb, rb), dateFormat="Date")
>     }
>     cb
> }
>
> library(qmao)
> library(timeDate) # for holidayNYSE
> setSymbolLookup(VX='cfe')
> vx <- getSymbols('VX',Month=1:12,Year=2007:2011)
>
> plot.zoo(term.structure(vx, seq(20, 200, 20)), screens=1, col=rainbow(10))
>
> -----
>
> HTH,
> Garrett
>
>
>
> On Thu, Aug 13, 2015 at 2:54 PM, Samuel Wilson
> <samuelcoltwilson at gmail.com> wrote:
> > Before I write the code, I was wondering if anyone had already created a
> > function or code for calculating constant maturity for a futures contract
> > in R.
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-SIG-Finance at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> > -- Subscriber-posting only. If you want to post, subscribe first.
> > -- Also note that this is not the r-help list where general R questions
> should go.
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From gsee000 at gmail.com  Tue Sep  8 16:58:05 2015
From: gsee000 at gmail.com (G See)
Date: Tue, 8 Sep 2015 09:58:05 -0500
Subject: [R-SIG-Finance] Constant maturity Futures
In-Reply-To: <CA+oJuEF27-94j6XpPmc086TkZ6abADMREQBbuunqa2UpDXeDDA@mail.gmail.com>
References: <CACCk-cHAS+yBjr9xuJqDiQLoQVt39sLMtdOe6+=LUjoCB08=hw@mail.gmail.com>
	<CA+xi=qZ2ykXsWfGY5REEvC7Ru4cxCy-TXitELw5deiq7vwv6Yg@mail.gmail.com>
	<CA+oJuEF27-94j6XpPmc086TkZ6abADMREQBbuunqa2UpDXeDDA@mail.gmail.com>
Message-ID: <CA+xi=qbS4GyToQyeWtooKzG8T5MtCtOgN24QJqVX6u5TuYUzgQ@mail.gmail.com>

I don't really remember how it works, to be honest. :-P  I wish I had
time to look into it.  2015-08-19 is 20 days ago, so I guess the 20
day CMF needs 20 days of data as it's currently implemented?

Sorry I can't be of more help.

Garrett

On Tue, Sep 8, 2015 at 9:30 AM, Ilya Kipnis <ilya.kipnis at gmail.com> wrote:
> Hi Garrett,
>
> I just tested this code out and...it doesn't compute up to the most current
> day. As of now, the term.structure function ends at 2015-08-19. AKA in the
> last month. Is there a way to make it go up to the last day for which there
> is data available? Thanks.
>
> -Ilya
>
> On Thu, Aug 13, 2015 at 5:56 PM, G See <gsee000 at gmail.com> wrote:
>>
>> Hi Samuel,
>>
>> Here's some code (also attached) that creates constant maturity
>> futures for VIX futures.  I wrote this code 4 years ago.  I'm not
>> particularly proud of it.  I don't know for sure that it works.  It
>> might not be elegant.  etc.  Take it for what it's worth.
>>
>> You should be able to source this code and get a time series plot of
>> several different CMFs of varying maturities.  You'll need my qmao
>> package which you can install with
>> devtools::install_github("gsee/qmao")
>>
>>
>> #' @export
>> #' @rdname primary2expiry
>> suffix2expiry <- function(suffix, root='VX', ...) {
>>     if (exists(paste('suffix2expiry',root,sep="."))) {
>>         do.call(paste('suffix2expiry',root,sep='.'),list(suffix, ...))
>>     } else {
>>         warning(paste(root, 'is not and available suffix2expiry
>> method; using "VX" instead'))
>>         do.call('suffix2expiry.VX',list(suffix, ...))
>>     }
>> }
>>
>> #' Get the expiration date of an instrument given it's primary_id
>> #'
>> #' \code{primary2expiry} is basically a wrapper for
>> \code{\link{suffix2expiry}}.  It uses
>> #' \code{\link[FinancialInstrument]{parse_id}} to split the
>> \code{primary_id} into rood_id and suffix_id.
>> #' then it calls the appropriate \code{\link{suffix2expiry}} method.
>> #'
>> #' \code{suffix2expiry} is a generic-like function.  There should be a
>> method defined
>> #' the "root_id".  Currently, written methods include "VX", "ES" (and
>> aliases "YM", "NQ").
>> #' There are links to methods help pages in the seealso section.
>> #'
>> #' @param primary_id character string.  Primary identifier of the
>> instrument
>> #' @param root character string. root symbol like "ES" or "VX" (NULL)
>> #' @param silent silence warnings? (TRUE)
>> #' @param suffix character string that indicates expiration month and
>> year (and, for options, right and strike).
>> #' See \code{\link[FinancialInstrument]{parse_suffix}} for examples of
>> acceptable formats.
>> #' @param ... any arguments to be passed to the \code{suffix2expiry}
>> method
>> #' @return expiration Date
>> #' @seealso \code{\link{suffix2expiry.VX}}, \code{\link{suffix2expiry.ES}}
>> #' @aliases primary2expiry, suffix2expiry
>> #' @author gsee
>> #' @examples
>> #' primary2expiry("ESU1")
>> #' suffix2expiry('V11', root='VX')
>> #' @export
>> #' @rdname primary2expiry
>> primary2expiry <- function(primary_id, root=NULL, silent=TRUE) {
>>   idlist <- parse_id(primary_id, silent=silent)
>>   if (is.null(root)) root <- idlist$root
>>   do.call(paste("suffix2expiry",root,sep='.'),
>> list(suffix=idlist$suffix, silent=silent))
>> }
>>
>>
>> #' VIX future contract expiration date
>> #'
>> #' Calculate the expiration date of a VIX future contract given a
>> suffix_id
>> #'
>> #' Per the contract specs, expiration will occur on \dQuote{the Wednesday
>> that
>> #' is thirty days prior to the third Friday of the calendar month
>> #' immediately following the month in which the contract expires
>> ("Final Settlement Date").
>> #' If the third Friday of the month subsequent to expiration of the
>> applicable
>> #' VIX futures contract is a CBOE holiday, the Final Settlement Date
>> for the contract
>> #' shall be thirty days prior to the CBOE business day immediately
>> preceding that Friday.}
>> #' @param suffix suffix_id that should be something like (\sQuote{U1},
>> \sQuote{U11}, or \sQuote{SEP11})
>> #' @param silent silence warnings? (TRUE)
>> #' @return an expiration Date
>> #' @author gsee
>> #' @references \url{http://cfe.cboe.com/products/spec_vix.aspx}
>> #' @examples
>> #' \dontrun{
>> #' suffix2expiry.VX('U11')
>> #' suffix2expiry.VX("JUN09")
>> #' }
>> #' @export
>> suffix2expiry.VX <- suffix2expiry.VIX <- function(suffix, silent=TRUE) {
>>     #require('timeDate')
>>     sl <- parse_suffix(suffix,silent=silent)
>>     DT <- as.Date(paste(15, sl$month, sl$year,sep='-'),format="%d-%b-%Y")
>>     Y <- format(DT,"%Y")
>>     M <- format((DT + 30),"%m")
>>     if (as.numeric(M) == 1) Y <- paste(as.numeric(Y) + 1)
>>     DS <- as.Date(paste(Y,M,01,sep='-'))+0:22
>>     DS <- DS[months(DS, abbreviate=TRUE) == C2M()[as.numeric(M)]]
>>     ds <- which(weekdays(DS) == "Friday")[3]
>>     if (DS[ds] %in% as.Date(holidayNYSE(as.numeric(Y))@Data)) {
>>         while (DS[ds] %in% as.Date(holidayNYSE(as.numeric(Y))@Data)
>>                 || any(c('Saturday', 'Sunday') == weekdays(DS[ds])))
>>             ds <- ds-1
>>     }
>>     #try(detach(package:timeDate), silent=TRUE);
>> try(detach(package:timeSeries), silent=TRUE)
>>     DS[ds] - 30
>> }
>>
>>
>>
>>
>>
>> .interp.fut.VX <- function(x1, x2, n=36, prefer='Close') {
>>     xs <- c(x1,x2) # names of 2 instruments
>>     x1 <- get(x1,pos=.GlobalEnv)
>>     x2 <- get(x2,pos=.GlobalEnv)
>>
>>     x1$DTE <- primary2expiry(xs[1])-index(x1)#, index(x1)) #dlf(x1)
>>     x2$DTE <- primary2expiry(xs[2])-index(x2)#, index(x2)) #dlf(x2)
>>     df <- merge(x1$DTE,x2$DTE,all=FALSE)
>>     df <- na.omit(df)
>>     if (length(df[,1]) && length(df[,2])) {
>>         Pcmf <- xts()
>>         if(all(df[,1] < df[,2])) {
>>             col1 <- 1
>>             col2 <- 2
>>         } else if (all(df[,2] < df[,1])) {
>>             col1 <- 2
>>             col2 <- 1
>>         } else stop(paste("ambiguous nearby contract",xs))
>>         for (ns in n) {
>>             idx <- index(df[(df[,col1] <= ns) & (df[,col2] > ns)])
>>             if (length(idx) == 0) return(NULL)
>>             w <- 1/ns
>>             P1 <- try(getPrice(x1[idx],prefer=prefer))
>>             P2 <- try(getPrice(x2[idx],prefer=prefer))
>>             wP <- try((w*P1) + ((1-w)*P2))
>>             if (!any(sapply(list(P1,P2,wP), inherits, 'try-error')))
>>                 Pcmf <- cbind(Pcmf,wP)
>>         }
>>     #indexClass(Pcmf) <- 'Date' ## xts kind of broke this.
>>     Pcmf
>>     }
>> }
>>
>>
>> term.structure <- function(Symbols, cdays=c(35,60,90,120)) {
>>     s <- Symbols
>>     cnames <- paste(strsplit(s[[1]],"_")[[1]][1], "cm", cdays, sep=".")
>>     a <- list()
>>     for (i in 2:length(s)) {
>>         tmp <- .interp.fut.VX(s[i-1],s[i],cdays)
>>         if (length(tmp)) {
>>             a[[i-1]] <- tmp
>>             colnames(a[[i-1]]) <- cnames
>>         }
>>     }
>>     #for (i in 1:length(a)) colnames(a[[i]]) <- paste("VX.CM", tdays,
>> sep=".")
>>     cb <- NULL
>>     for (i in 1:length(cdays)) {
>>         rb <- na.omit(a[[1]][,i])
>>         for (j in 2:(length(s)-1)) {
>>             if (length(a) > j && length(a[[j]][,i]) &&
>>                 length(na.omit(a[[j]][,i])))
>>               rb <- rbind(rb, na.omit(a[[j]][,i]))
>>         }
>>         cb <- as.xts(cbind(cb, rb), dateFormat="Date")
>>     }
>>     cb
>> }
>>
>> library(qmao)
>> library(timeDate) # for holidayNYSE
>> setSymbolLookup(VX='cfe')
>> vx <- getSymbols('VX',Month=1:12,Year=2007:2011)
>>
>> plot.zoo(term.structure(vx, seq(20, 200, 20)), screens=1, col=rainbow(10))
>>
>> -----
>>
>> HTH,
>> Garrett
>>
>>
>>
>> On Thu, Aug 13, 2015 at 2:54 PM, Samuel Wilson
>> <samuelcoltwilson at gmail.com> wrote:
>> > Before I write the code, I was wondering if anyone had already created a
>> > function or code for calculating constant maturity for a futures
>> > contract
>> > in R.
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-SIG-Finance at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> > -- Subscriber-posting only. If you want to post, subscribe first.
>> > -- Also note that this is not the r-help list where general R questions
>> > should go.
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>
>


From peter at braverock.com  Wed Sep  9 15:43:20 2015
From: peter at braverock.com (Peter Carl)
Date: Wed, 09 Sep 2015 08:43:20 -0500
Subject: [R-SIG-Finance] Dowd package on CRAN
Message-ID: <55F03778.8010406@braverock.com>


I thought that this list might like to know that Dinesh Acharya spent 
the summer converting Kevin Dowd's Matlab code from 'Measuring Market 
Risk' as part of Google Summer of Code 2015.


'Measuring Market Risk' covers important topics in risk measurement in a 
well-regarded and widely used book that is in it's second edition. Prof. 
Dowd is currently a Professor of Finance and Economics at Durham 
University Business School and a partner in Cobden Partners based in London.


This project focused on converting the included Matlab-based MMR2 
toolkit to R to make it more widely assessible. Dinesh created a package 
for students and readers that is now on CRAN: 
http://cran.at.r-project.org/web/packages/Dowd/index.html


In case you are not familiar with it, Google Summer of Code is a program 
where Google pays students to work on a three month open source project. 
The R language has participated in GSoC for most of its 10-or-so year 
history.


Thanks to all involved, but particularly to Dinesh - this is a nice 
contribution. Feel free to reach out to him with any questions or 
compliments.


pcc


	[[alternative HTML version deleted]]


From i.costigan at me.com  Thu Sep 10 12:01:24 2015
From: i.costigan at me.com (Imanuel Costigan)
Date: Thu, 10 Sep 2015 20:01:24 +1000
Subject: [R-SIG-Finance] [ANN] dataonderivatives: Easily Source Publicly
 Available Data on Derivatives
Message-ID: <CACB9DD6-89D1-4FCE-8607-C9D5DAAF3C07@me.com>

I?m excited to announce the first release of the ?dataonderivatives" package on CRAN. 

Post-GFC derivatives reforms have lifted the veil off over-the-counter (OTC) derivative markets. Swap Execution Facilities (SEFs) and Swap Data Repositories (SDRs) now publish data on swaps that are traded on or reported to those facilities (respectively). This package provides you the ability to get this data from supported sources.

The package?s README file describes the package in more detail and illustrates its interface to the Bloomberg SEF and DTCC?s SDR sources:

https://github.com/imanuelcostigan/dataonderivatives/blob/3faf5f7333e805249b142678081b54885854648e/README.md

Source code is available at the GitHub repo and pull requests are welcome: 

https://github.com/imanuelcostigan/dataonderivatives

Kind regards,
Imanuel Costigan

From eliano.m.marques at gmail.com  Thu Sep 10 12:56:49 2015
From: eliano.m.marques at gmail.com (Eliano Marques)
Date: Thu, 10 Sep 2015 11:56:49 +0100
Subject: [R-SIG-Finance] Different results on Garch(1,
	1) with regressors: Eviews vs rugarch
Message-ID: <60555154-0B1E-4173-9740-ACA0F20A67B5@gmail.com>

Hi everyone,

I?m writing a thesis around the stock prices with ISEG in Lisbon. 

I wrote the entire end-to-end ETL in R and I?m trying to run all the models in R. Just as a sense check, I was comparing the results between Eviews and R and realised big differences between then and I wonder if you can help me debugging this differences, i?m sure I might be doing something wrong. 

Here is my R code: 

RFunction_garch_estimation=function( #stock, 
                                     variance.model = list(model = "sGARCH", garchOrder = c(1, 1), 
                                                           submodel = NULL, external.regressors = NULL, variance.targeting = FALSE), 
                                     mean.model = list(armaOrder = c(1, 1), include.mean = TRUE, archm = FALSE, 
                                                       archpow = 1, arfima = FALSE, external.regressors = NULL, archex = FALSE), 
                                     distribution.model = "norm", start.pars = list(), fixed.pars = list(),
                                     
                                     spec, data, out.sample = 0, solver = "solnp", solver.control = list(), 
                                     fit.control = list(stationarity = 1, fixed.se = 0, scale = 0, rec.init = 'all'), 
                                     numderiv.control = list(grad.eps=1e-4, grad.d=0.0001, 
                                                             grad.zero.tol=sqrt(.Machine$double.eps/7e-7), hess.eps=1e-4, hess.d=0.1, 
                                                             hess.zero.tol=sqrt(.Machine$double.eps/7e-7), r=4, v=2)
) {
  library(rugarch)
  mod1=ugarchspec(variance.model = variance.model, 
                  mean.model = mean.model, 
                  distribution.model = distribution.model)
  mod1fit=ugarchfit(mod1, data,solver=solver, fit.control, out.sample, solver.control , numderiv.control )
  return(mod1fit) }

#This RFunction just sets the ugarchspec and estimates at the same the garch function. 


variance_model = list(model = "sGARCH", garchOrder = c(1, 1), 
                      submodel = NULL, external.regressors = as.matrix(regressors), variance.targeting = FALSE)
mean_model = list(armaOrder = c(0,0 ), include.mean = TRUE, archm = FALSE, 
                  archpow = 1, arfima = FALSE, external.regressors = as.matrix(regressors), archex = FALSE)
distribution_model = "norm"
#as.matrix(regressors)
model1=RFunction_garch_estimation( data=target, variance.model = variance_model, mean.model = mean_model,distribution.model = distribution_model,solver='solnp')
show(model1) 

#### Results:

Robust Standard Errors:
        Estimate  Std. Error   t value Pr(>|t|)
mu      0.000015    0.234264  0.000063  0.99995
mxreg1  0.709299  292.613915  0.002424  0.99807
mxreg2 -0.000112    0.098905 -0.001135  0.99909
mxreg3  0.000034    0.065088  0.000528  0.99958
mxreg4 -0.000003    0.075987 -0.000037  0.99997
mxreg5 -0.000009    0.012701 -0.000723  0.99942
omega   0.000000    0.000249  0.000175  0.99986
alpha1  0.020642    1.493492  0.013821  0.98897
beta1   0.973943    0.908957  1.071496  0.28395
vxreg1  0.000000    0.030732  0.000000  1.00000
vxreg2  0.000000    0.000019  0.000469  0.99963
vxreg3  0.000000    0.001606  0.000007  0.99999
vxreg4  0.000000    0.000630  0.000015  0.99999
vxreg5  0.000000    0.000634  0.000000  1.00000

LogLikelihood : 30151.719 

Eviews outputs: 

Dependent Variable: target			
Method: ML - ARCH (Marquardt) - Normal distribution			
Date: 09/10/15   Time: 11:51			
Sample: 11/05/2014 09:30 8/28/2015 17:30			
Included observations: 6763			
Convergence achieved after 25 iterations			
Bollerslev-Wooldridge robust standard errors & covariance			
Presample variance: backcast (parameter = 0.7)			
			
GARCH = C(7) + C(8)*RESID(-1)^2 + C(9)*GARCH(-1) + C(10)				
        *reg1 + C(11)*reg2 + C(12)				
        *reg3 + C(13)*reg4 + C(14)				
        *reg5				
				
Variable			Coefficient	Std. Error		z-Statistic	Prob.  
				
C				-1.62E-05	4.17E-05		-0.388964	0.6973
reg1				0.723305		0.050098		14.43789		0.0000
reg2				-0.000242	0.000123		-1.972702	0.0485
reg3				0.000170		8.29E-05		2.049855		0.0404
reg4				0.000107		0.000175		0.610040		0.5418
reg5				-1.22E-05	8.26E-06		-1.482648	0.1382

				
Variance Equation			
				
C				9.87E-06		3.85E-06		2.566464		0.0103
RESID(-1)^2		0.149994		0.035467		4.229165		0.0000
GARCH(-1)		0.599977		0.118194		5.076196		0.0000
reg1				-0.000362	0.002233		-0.162239	0.8711
reg2				1.35E-06		1.18E-05		0.114108		0.9092
reg3				-5.72E-07	5.44E-07		-1.050865	0.2933
reg4				-2.28E-06	9.78E-06		-0.232631	0.8160
reg5				-8.48E-08	2.61E-08		-3.251462	0.0011


Now please note that the  majority of the external regressors have 0 as coefficient in the conditional variance and this isn't much different from Eviews. However when you look at the coefficients alpha and beta they significantly differ from Eviews. In addition, both methods using the robust matrix of cov-var, the p-value of a large number of coefs. differ. 

Could you help me understand if I?m doing anything wrong in the R bit? 

Thank you,
Eliano


From alexios at 4dscape.com  Thu Sep 10 13:32:55 2015
From: alexios at 4dscape.com (alexios galanos)
Date: Thu, 10 Sep 2015 14:32:55 +0300
Subject: [R-SIG-Finance] Different results on Garch(1,
 1) with regressors: Eviews vs rugarch
In-Reply-To: <60555154-0B1E-4173-9740-ACA0F20A67B5@gmail.com>
References: <60555154-0B1E-4173-9740-ACA0F20A67B5@gmail.com>
Message-ID: <55F16A67.6050403@4dscape.com>

Discussed numerous times on this forum (i.e. differences between
different software implementations).
As far as I can see from your output, eviews uses:

Presample variance: backcast (parameter = 0.7)

whereas rugarch by default uses the whole sample for the initialization.

See the ugarchspec help function on variance.targeting which allows a numeric value (instead of logical)
between 0 and 1 for the backcasting.

However, it could also be the case of different bound constraints. In the rugarch model, the coefficients
on the external regressors in the variance equation for the sGARCH model are constrained to be positive.
Feel free to play around with 'setbounds<-' and a whole host of other options, including using an alternate
solver etc.

Alexios

On 10/09/2015 13:56, Eliano Marques wrote:

> Hi everyone,
>
> I?m writing a thesis around the stock prices with ISEG in Lisbon. 
>
> I wrote the entire end-to-end ETL in R and I?m trying to run all the models in R. Just as a sense check, I was comparing the results between Eviews and R and realised big differences between then and I wonder if you can help me debugging this differences, i?m sure I might be doing something wrong. 
>
> Here is my R code: 
>
> RFunction_garch_estimation=function( #stock, 
>                                      variance.model = list(model = "sGARCH", garchOrder = c(1, 1), 
>                                                            submodel = NULL, external.regressors = NULL, variance.targeting = FALSE), 
>                                      mean.model = list(armaOrder = c(1, 1), include.mean = TRUE, archm = FALSE, 
>                                                        archpow = 1, arfima = FALSE, external.regressors = NULL, archex = FALSE), 
>                                      distribution.model = "norm", start.pars = list(), fixed.pars = list(),
>                                      
>                                      spec, data, out.sample = 0, solver = "solnp", solver.control = list(), 
>                                      fit.control = list(stationarity = 1, fixed.se = 0, scale = 0, rec.init = 'all'), 
>                                      numderiv.control = list(grad.eps=1e-4, grad.d=0.0001, 
>                                                              grad.zero.tol=sqrt(.Machine$double.eps/7e-7), hess.eps=1e-4, hess.d=0.1, 
>                                                              hess.zero.tol=sqrt(.Machine$double.eps/7e-7), r=4, v=2)
> ) {
>   library(rugarch)
>   mod1=ugarchspec(variance.model = variance.model, 
>                   mean.model = mean.model, 
>                   distribution.model = distribution.model)
>   mod1fit=ugarchfit(mod1, data,solver=solver, fit.control, out.sample, solver.control , numderiv.control )
>   return(mod1fit) }
>
> #This RFunction just sets the ugarchspec and estimates at the same the garch function. 
>
>
> variance_model = list(model = "sGARCH", garchOrder = c(1, 1), 
>                       submodel = NULL, external.regressors = as.matrix(regressors), variance.targeting = FALSE)
> mean_model = list(armaOrder = c(0,0 ), include.mean = TRUE, archm = FALSE, 
>                   archpow = 1, arfima = FALSE, external.regressors = as.matrix(regressors), archex = FALSE)
> distribution_model = "norm"
> #as.matrix(regressors)
> model1=RFunction_garch_estimation( data=target, variance.model = variance_model, mean.model = mean_model,distribution.model = distribution_model,solver='solnp')
> show(model1) 
>
> #### Results:
>
> Robust Standard Errors:
>         Estimate  Std. Error   t value Pr(>|t|)
> mu      0.000015    0.234264  0.000063  0.99995
> mxreg1  0.709299  292.613915  0.002424  0.99807
> mxreg2 -0.000112    0.098905 -0.001135  0.99909
> mxreg3  0.000034    0.065088  0.000528  0.99958
> mxreg4 -0.000003    0.075987 -0.000037  0.99997
> mxreg5 -0.000009    0.012701 -0.000723  0.99942
> omega   0.000000    0.000249  0.000175  0.99986
> alpha1  0.020642    1.493492  0.013821  0.98897
> beta1   0.973943    0.908957  1.071496  0.28395
> vxreg1  0.000000    0.030732  0.000000  1.00000
> vxreg2  0.000000    0.000019  0.000469  0.99963
> vxreg3  0.000000    0.001606  0.000007  0.99999
> vxreg4  0.000000    0.000630  0.000015  0.99999
> vxreg5  0.000000    0.000634  0.000000  1.00000
>
> LogLikelihood : 30151.719 
>
> Eviews outputs: 
>
> Dependent Variable: target			
> Method: ML - ARCH (Marquardt) - Normal distribution			
> Date: 09/10/15   Time: 11:51			
> Sample: 11/05/2014 09:30 8/28/2015 17:30			
> Included observations: 6763			
> Convergence achieved after 25 iterations			
> Bollerslev-Wooldridge robust standard errors & covariance			
> Presample variance: backcast (parameter = 0.7)			
> 			
> GARCH = C(7) + C(8)*RESID(-1)^2 + C(9)*GARCH(-1) + C(10)				
>         *reg1 + C(11)*reg2 + C(12)				
>         *reg3 + C(13)*reg4 + C(14)				
>         *reg5				
> 				
> Variable			Coefficient	Std. Error		z-Statistic	Prob.  
> 				
> C				-1.62E-05	4.17E-05		-0.388964	0.6973
> reg1				0.723305		0.050098		14.43789		0.0000
> reg2				-0.000242	0.000123		-1.972702	0.0485
> reg3				0.000170		8.29E-05		2.049855		0.0404
> reg4				0.000107		0.000175		0.610040		0.5418
> reg5				-1.22E-05	8.26E-06		-1.482648	0.1382
>
> 				
> Variance Equation			
> 				
> C				9.87E-06		3.85E-06		2.566464		0.0103
> RESID(-1)^2		0.149994		0.035467		4.229165		0.0000
> GARCH(-1)		0.599977		0.118194		5.076196		0.0000
> reg1				-0.000362	0.002233		-0.162239	0.8711
> reg2				1.35E-06		1.18E-05		0.114108		0.9092
> reg3				-5.72E-07	5.44E-07		-1.050865	0.2933
> reg4				-2.28E-06	9.78E-06		-0.232631	0.8160
> reg5				-8.48E-08	2.61E-08		-3.251462	0.0011
>
>
> Now please note that the  majority of the external regressors have 0 as coefficient in the conditional variance and this isn't much different from Eviews. However when you look at the coefficients alpha and beta they significantly differ from Eviews. In addition, both methods using the robust matrix of cov-var, the p-value of a large number of coefs. differ. 
>
> Could you help me understand if I?m doing anything wrong in the R bit? 
>
> Thank you,
> Eliano
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From eliano.m.marques at gmail.com  Thu Sep 10 16:13:12 2015
From: eliano.m.marques at gmail.com (Eliano Marques)
Date: Thu, 10 Sep 2015 15:13:12 +0100
Subject: [R-SIG-Finance] Different results on Garch(1,
	1) with regressors: Eviews vs rugarch
In-Reply-To: <55F16A67.6050403@4dscape.com>
References: <60555154-0B1E-4173-9740-ACA0F20A67B5@gmail.com>
	<55F16A67.6050403@4dscape.com>
Message-ID: <2FF575FC-1086-4E44-8E03-6B83FFD5A6F9@gmail.com>

Hi Alexios,

Thanks for your help. 

I tried and searched a lot for why this is different but I though publishing in your recommend emailing list would give a most robust answer. 

I have played already with several solvers but that didn?t helped. I believe your answer will help a lot so thank you for that. 

I will update after running the tests.

Thank you,
Eliano
> On 10 Sep 2015, at 12:32, alexios galanos <alexios at 4dscape.com> wrote:
> 
> Discussed numerous times on this forum (i.e. differences between
> different software implementations).
> As far as I can see from your output, eviews uses:
> 
> Presample variance: backcast (parameter = 0.7)
> 
> whereas rugarch by default uses the whole sample for the initialization.
> 
> See the ugarchspec help function on variance.targeting which allows a numeric value (instead of logical)
> between 0 and 1 for the backcasting.
> 
> However, it could also be the case of different bound constraints. In the rugarch model, the coefficients
> on the external regressors in the variance equation for the sGARCH model are constrained to be positive.
> Feel free to play around with 'setbounds<-' and a whole host of other options, including using an alternate
> solver etc.
> 
> Alexios
> 
> On 10/09/2015 13:56, Eliano Marques wrote:
> 
>> Hi everyone,
>> 
>> I?m writing a thesis around the stock prices with ISEG in Lisbon. 
>> 
>> I wrote the entire end-to-end ETL in R and I?m trying to run all the models in R. Just as a sense check, I was comparing the results between Eviews and R and realised big differences between then and I wonder if you can help me debugging this differences, i?m sure I might be doing something wrong. 
>> 
>> Here is my R code: 
>> 
>> RFunction_garch_estimation=function( #stock, 
>>                                     variance.model = list(model = "sGARCH", garchOrder = c(1, 1), 
>>                                                           submodel = NULL, external.regressors = NULL, variance.targeting = FALSE), 
>>                                     mean.model = list(armaOrder = c(1, 1), include.mean = TRUE, archm = FALSE, 
>>                                                       archpow = 1, arfima = FALSE, external.regressors = NULL, archex = FALSE), 
>>                                     distribution.model = "norm", start.pars = list(), fixed.pars = list(),
>> 
>>                                     spec, data, out.sample = 0, solver = "solnp", solver.control = list(), 
>>                                     fit.control = list(stationarity = 1, fixed.se = 0, scale = 0, rec.init = 'all'), 
>>                                     numderiv.control = list(grad.eps=1e-4, grad.d=0.0001, 
>>                                                             grad.zero.tol=sqrt(.Machine$double.eps/7e-7), hess.eps=1e-4, hess.d=0.1, 
>>                                                             hess.zero.tol=sqrt(.Machine$double.eps/7e-7), r=4, v=2)
>> ) {
>>  library(rugarch)
>>  mod1=ugarchspec(variance.model = variance.model, 
>>                  mean.model = mean.model, 
>>                  distribution.model = distribution.model)
>>  mod1fit=ugarchfit(mod1, data,solver=solver, fit.control, out.sample, solver.control , numderiv.control )
>>  return(mod1fit) }
>> 
>> #This RFunction just sets the ugarchspec and estimates at the same the garch function. 
>> 
>> 
>> variance_model = list(model = "sGARCH", garchOrder = c(1, 1), 
>>                      submodel = NULL, external.regressors = as.matrix(regressors), variance.targeting = FALSE)
>> mean_model = list(armaOrder = c(0,0 ), include.mean = TRUE, archm = FALSE, 
>>                  archpow = 1, arfima = FALSE, external.regressors = as.matrix(regressors), archex = FALSE)
>> distribution_model = "norm"
>> #as.matrix(regressors)
>> model1=RFunction_garch_estimation( data=target, variance.model = variance_model, mean.model = mean_model,distribution.model = distribution_model,solver='solnp')
>> show(model1) 
>> 
>> #### Results:
>> 
>> Robust Standard Errors:
>>        Estimate  Std. Error   t value Pr(>|t|)
>> mu      0.000015    0.234264  0.000063  0.99995
>> mxreg1  0.709299  292.613915  0.002424  0.99807
>> mxreg2 -0.000112    0.098905 -0.001135  0.99909
>> mxreg3  0.000034    0.065088  0.000528  0.99958
>> mxreg4 -0.000003    0.075987 -0.000037  0.99997
>> mxreg5 -0.000009    0.012701 -0.000723  0.99942
>> omega   0.000000    0.000249  0.000175  0.99986
>> alpha1  0.020642    1.493492  0.013821  0.98897
>> beta1   0.973943    0.908957  1.071496  0.28395
>> vxreg1  0.000000    0.030732  0.000000  1.00000
>> vxreg2  0.000000    0.000019  0.000469  0.99963
>> vxreg3  0.000000    0.001606  0.000007  0.99999
>> vxreg4  0.000000    0.000630  0.000015  0.99999
>> vxreg5  0.000000    0.000634  0.000000  1.00000
>> 
>> LogLikelihood : 30151.719 
>> 
>> Eviews outputs: 
>> 
>> Dependent Variable: target			
>> Method: ML - ARCH (Marquardt) - Normal distribution			
>> Date: 09/10/15   Time: 11:51			
>> Sample: 11/05/2014 09:30 8/28/2015 17:30			
>> Included observations: 6763			
>> Convergence achieved after 25 iterations			
>> Bollerslev-Wooldridge robust standard errors & covariance			
>> Presample variance: backcast (parameter = 0.7)			
>> 			
>> GARCH = C(7) + C(8)*RESID(-1)^2 + C(9)*GARCH(-1) + C(10)				
>>        *reg1 + C(11)*reg2 + C(12)				
>>        *reg3 + C(13)*reg4 + C(14)				
>>        *reg5				
>> 				
>> Variable			Coefficient	Std. Error		z-Statistic	Prob.  
>> 				
>> C				-1.62E-05	4.17E-05		-0.388964	0.6973
>> reg1				0.723305		0.050098		14.43789		0.0000
>> reg2				-0.000242	0.000123		-1.972702	0.0485
>> reg3				0.000170		8.29E-05		2.049855		0.0404
>> reg4				0.000107		0.000175		0.610040		0.5418
>> reg5				-1.22E-05	8.26E-06		-1.482648	0.1382
>> 
>> 				
>> Variance Equation			
>> 				
>> C				9.87E-06		3.85E-06		2.566464		0.0103
>> RESID(-1)^2		0.149994		0.035467		4.229165		0.0000
>> GARCH(-1)		0.599977		0.118194		5.076196		0.0000
>> reg1				-0.000362	0.002233		-0.162239	0.8711
>> reg2				1.35E-06		1.18E-05		0.114108		0.9092
>> reg3				-5.72E-07	5.44E-07		-1.050865	0.2933
>> reg4				-2.28E-06	9.78E-06		-0.232631	0.8160
>> reg5				-8.48E-08	2.61E-08		-3.251462	0.0011
>> 
>> 
>> Now please note that the  majority of the external regressors have 0 as coefficient in the conditional variance and this isn't much different from Eviews. However when you look at the coefficients alpha and beta they significantly differ from Eviews. In addition, both methods using the robust matrix of cov-var, the p-value of a large number of coefs. differ. 
>> 
>> Could you help me understand if I?m doing anything wrong in the R bit? 
>> 
>> Thank you,
>> Eliano
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
> 


From eliano.m.marques at gmail.com  Thu Sep 10 18:38:47 2015
From: eliano.m.marques at gmail.com (Eliano Marques)
Date: Thu, 10 Sep 2015 17:38:47 +0100
Subject: [R-SIG-Finance] Different results on Garch(1,
	1) with regressors: Eviews vs rugarch
In-Reply-To: <55F16A67.6050403@4dscape.com>
References: <60555154-0B1E-4173-9740-ACA0F20A67B5@gmail.com>
	<55F16A67.6050403@4dscape.com>
Message-ID: <63858CE3-EF42-47C2-91EE-EB87D02CCC49@gmail.com>

Hi Alexios,

So i?ve tried many different methods and I?m still finding it difficult to come anywhere close Eviews results. While i do understand they won?t match to a penny the differences are quite significant at this stage. 

What have I done:

1 - Adding variance.target=0.7 
Results:
Robust Standard Errors:
        Estimate  Std. Error   t value Pr(>|t|)
mu      0.000013    0.348112  0.000039  0.99997
mxreg1  0.714946  232.642591  0.003073  0.99755     # Eviews with backcast of 0.7 calculates this as 0.7233
mxreg2 -0.000108    0.267235 -0.000403  0.99968
mxreg3  0.000031    1.028411  0.000030  0.99998
mxreg4 -0.000009    0.083789 -0.000106  0.99991
mxreg5 -0.000009    0.126160 -0.000070  0.99994
alpha1  0.030775    0.050001  0.615491  0.53823		# Eviews estimates this as 0.14
beta1   0.969225    0.887995  1.091476  0.27506		#Eviews estimates this as 0.59
vxreg1  0.000000    0.293709  0.000000  1.00000
vxreg2  0.000000    0.000168  0.000049  0.99996
vxreg3  0.000000    0.000299  0.000033  0.99997
vxreg4  0.000000    0.000407  0.000023  0.99998
vxreg5  0.000000    0.003602  0.000000  1.00000
omega   0.000000          NA        NA       NA

Note that omega now don?t have standard error, t-value and p.value. This is expected given the variance.targeting setting.  

Now if I also set Eview variance.target option on (backcast doesn?t turn this on) the results get more similar between softwares. mxreg1 in mean equation is 0.705 (vs. 0.715 in R) and beta1 is eviews is 0.971 (vs. 0.969 in R).

2 - Set variance.target in Eviews to null 
Problem is the same as above as Eviews results are exactly the same. 

3 - Adding setbounds 
Problem remain. 

I guess the issue that i?m facing here is more around the parameters of the variance function in the more simple terms not matching the Eview results. I know the var-cov methods are different but being significantly different is not expected. 

The other thing that I have noticed is that if you change the garch model from standard to something else the results typically tend to match better so I wonder if I?m still missing something in the standard garch method. 

Thank you,
Eliano
 


> On 10 Sep 2015, at 12:32, alexios galanos <alexios at 4dscape.com> wrote:
> 
> Discussed numerous times on this forum (i.e. differences between
> different software implementations).
> As far as I can see from your output, eviews uses:
> 
> Presample variance: backcast (parameter = 0.7)
> 
> whereas rugarch by default uses the whole sample for the initialization.
> 
> See the ugarchspec help function on variance.targeting which allows a numeric value (instead of logical)
> between 0 and 1 for the backcasting.
> 
> However, it could also be the case of different bound constraints. In the rugarch model, the coefficients
> on the external regressors in the variance equation for the sGARCH model are constrained to be positive.
> Feel free to play around with 'setbounds<-' and a whole host of other options, including using an alternate
> solver etc.
> 
> Alexios
> 
> On 10/09/2015 13:56, Eliano Marques wrote:
> 
>> Hi everyone,
>> 
>> I?m writing a thesis around the stock prices with ISEG in Lisbon. 
>> 
>> I wrote the entire end-to-end ETL in R and I?m trying to run all the models in R. Just as a sense check, I was comparing the results between Eviews and R and realised big differences between then and I wonder if you can help me debugging this differences, i?m sure I might be doing something wrong. 
>> 
>> Here is my R code: 
>> 
>> RFunction_garch_estimation=function( #stock, 
>>                                     variance.model = list(model = "sGARCH", garchOrder = c(1, 1), 
>>                                                           submodel = NULL, external.regressors = NULL, variance.targeting = FALSE), 
>>                                     mean.model = list(armaOrder = c(1, 1), include.mean = TRUE, archm = FALSE, 
>>                                                       archpow = 1, arfima = FALSE, external.regressors = NULL, archex = FALSE), 
>>                                     distribution.model = "norm", start.pars = list(), fixed.pars = list(),
>> 
>>                                     spec, data, out.sample = 0, solver = "solnp", solver.control = list(), 
>>                                     fit.control = list(stationarity = 1, fixed.se = 0, scale = 0, rec.init = 'all'), 
>>                                     numderiv.control = list(grad.eps=1e-4, grad.d=0.0001, 
>>                                                             grad.zero.tol=sqrt(.Machine$double.eps/7e-7), hess.eps=1e-4, hess.d=0.1, 
>>                                                             hess.zero.tol=sqrt(.Machine$double.eps/7e-7), r=4, v=2)
>> ) {
>>  library(rugarch)
>>  mod1=ugarchspec(variance.model = variance.model, 
>>                  mean.model = mean.model, 
>>                  distribution.model = distribution.model)
>>  mod1fit=ugarchfit(mod1, data,solver=solver, fit.control, out.sample, solver.control , numderiv.control )
>>  return(mod1fit) }
>> 
>> #This RFunction just sets the ugarchspec and estimates at the same the garch function. 
>> 
>> 
>> variance_model = list(model = "sGARCH", garchOrder = c(1, 1), 
>>                      submodel = NULL, external.regressors = as.matrix(regressors), variance.targeting = FALSE)
>> mean_model = list(armaOrder = c(0,0 ), include.mean = TRUE, archm = FALSE, 
>>                  archpow = 1, arfima = FALSE, external.regressors = as.matrix(regressors), archex = FALSE)
>> distribution_model = "norm"
>> #as.matrix(regressors)
>> model1=RFunction_garch_estimation( data=target, variance.model = variance_model, mean.model = mean_model,distribution.model = distribution_model,solver='solnp')
>> show(model1) 
>> 
>> #### Results:
>> 
>> Robust Standard Errors:
>>        Estimate  Std. Error   t value Pr(>|t|)
>> mu      0.000015    0.234264  0.000063  0.99995
>> mxreg1  0.709299  292.613915  0.002424  0.99807
>> mxreg2 -0.000112    0.098905 -0.001135  0.99909
>> mxreg3  0.000034    0.065088  0.000528  0.99958
>> mxreg4 -0.000003    0.075987 -0.000037  0.99997
>> mxreg5 -0.000009    0.012701 -0.000723  0.99942
>> omega   0.000000    0.000249  0.000175  0.99986
>> alpha1  0.020642    1.493492  0.013821  0.98897
>> beta1   0.973943    0.908957  1.071496  0.28395
>> vxreg1  0.000000    0.030732  0.000000  1.00000
>> vxreg2  0.000000    0.000019  0.000469  0.99963
>> vxreg3  0.000000    0.001606  0.000007  0.99999
>> vxreg4  0.000000    0.000630  0.000015  0.99999
>> vxreg5  0.000000    0.000634  0.000000  1.00000
>> 
>> LogLikelihood : 30151.719 
>> 
>> Eviews outputs: 
>> 
>> Dependent Variable: target			
>> Method: ML - ARCH (Marquardt) - Normal distribution			
>> Date: 09/10/15   Time: 11:51			
>> Sample: 11/05/2014 09:30 8/28/2015 17:30			
>> Included observations: 6763			
>> Convergence achieved after 25 iterations			
>> Bollerslev-Wooldridge robust standard errors & covariance			
>> Presample variance: backcast (parameter = 0.7)			
>> 			
>> GARCH = C(7) + C(8)*RESID(-1)^2 + C(9)*GARCH(-1) + C(10)				
>>        *reg1 + C(11)*reg2 + C(12)				
>>        *reg3 + C(13)*reg4 + C(14)				
>>        *reg5				
>> 				
>> Variable			Coefficient	Std. Error		z-Statistic	Prob.  
>> 				
>> C				-1.62E-05	4.17E-05		-0.388964	0.6973
>> reg1				0.723305		0.050098		14.43789		0.0000
>> reg2				-0.000242	0.000123		-1.972702	0.0485
>> reg3				0.000170		8.29E-05		2.049855		0.0404
>> reg4				0.000107		0.000175		0.610040		0.5418
>> reg5				-1.22E-05	8.26E-06		-1.482648	0.1382
>> 
>> 				
>> Variance Equation			
>> 				
>> C				9.87E-06		3.85E-06		2.566464		0.0103
>> RESID(-1)^2		0.149994		0.035467		4.229165		0.0000
>> GARCH(-1)		0.599977		0.118194		5.076196		0.0000
>> reg1				-0.000362	0.002233		-0.162239	0.8711
>> reg2				1.35E-06		1.18E-05		0.114108		0.9092
>> reg3				-5.72E-07	5.44E-07		-1.050865	0.2933
>> reg4				-2.28E-06	9.78E-06		-0.232631	0.8160
>> reg5				-8.48E-08	2.61E-08		-3.251462	0.0011
>> 
>> 
>> Now please note that the  majority of the external regressors have 0 as coefficient in the conditional variance and this isn't much different from Eviews. However when you look at the coefficients alpha and beta they significantly differ from Eviews. In addition, both methods using the robust matrix of cov-var, the p-value of a large number of coefs. differ. 
>> 
>> Could you help me understand if I?m doing anything wrong in the R bit? 
>> 
>> Thank you,
>> Eliano
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions should go.
> 


From eliano.m.marques at gmail.com  Thu Sep 10 18:41:26 2015
From: eliano.m.marques at gmail.com (Eliano Marques)
Date: Thu, 10 Sep 2015 17:41:26 +0100
Subject: [R-SIG-Finance] Different results on Garch(1,
	1) with regressors: Eviews vs rugarch
In-Reply-To: <63858CE3-EF42-47C2-91EE-EB87D02CCC49@gmail.com>
References: <60555154-0B1E-4173-9740-ACA0F20A67B5@gmail.com>
	<55F16A67.6050403@4dscape.com>
	<63858CE3-EF42-47C2-91EE-EB87D02CCC49@gmail.com>
Message-ID: <1509AFC0-5F76-4877-A904-DB49A6070D5C@gmail.com>

PS: I?ve also noted that the fit tests typically generate NA Weighted Ljung-Box and Arch LM tests. 

Eliano
> On 10 Sep 2015, at 17:38, Eliano Marques <eliano.m.marques at gmail.com> wrote:
> 
> Hi Alexios,
> 
> So i?ve tried many different methods and I?m still finding it difficult to come anywhere close Eviews results. While i do understand they won?t match to a penny the differences are quite significant at this stage. 
> 
> What have I done:
> 
> 1 - Adding variance.target=0.7 
> Results:
> Robust Standard Errors:
>        Estimate  Std. Error   t value Pr(>|t|)
> mu      0.000013    0.348112  0.000039  0.99997
> mxreg1  0.714946  232.642591  0.003073  0.99755     # Eviews with backcast of 0.7 calculates this as 0.7233
> mxreg2 -0.000108    0.267235 -0.000403  0.99968
> mxreg3  0.000031    1.028411  0.000030  0.99998
> mxreg4 -0.000009    0.083789 -0.000106  0.99991
> mxreg5 -0.000009    0.126160 -0.000070  0.99994
> alpha1  0.030775    0.050001  0.615491  0.53823		# Eviews estimates this as 0.14
> beta1   0.969225    0.887995  1.091476  0.27506		#Eviews estimates this as 0.59
> vxreg1  0.000000    0.293709  0.000000  1.00000
> vxreg2  0.000000    0.000168  0.000049  0.99996
> vxreg3  0.000000    0.000299  0.000033  0.99997
> vxreg4  0.000000    0.000407  0.000023  0.99998
> vxreg5  0.000000    0.003602  0.000000  1.00000
> omega   0.000000          NA        NA       NA
> 
> Note that omega now don?t have standard error, t-value and p.value. This is expected given the variance.targeting setting.  
> 
> Now if I also set Eview variance.target option on (backcast doesn?t turn this on) the results get more similar between softwares. mxreg1 in mean equation is 0.705 (vs. 0.715 in R) and beta1 is eviews is 0.971 (vs. 0.969 in R).
> 
> 2 - Set variance.target in Eviews to null 
> Problem is the same as above as Eviews results are exactly the same. 
> 
> 3 - Adding setbounds 
> Problem remain. 
> 
> I guess the issue that i?m facing here is more around the parameters of the variance function in the more simple terms not matching the Eview results. I know the var-cov methods are different but being significantly different is not expected. 
> 
> The other thing that I have noticed is that if you change the garch model from standard to something else the results typically tend to match better so I wonder if I?m still missing something in the standard garch method. 
> 
> Thank you,
> Eliano
> 
> 
> 
>> On 10 Sep 2015, at 12:32, alexios galanos <alexios at 4dscape.com> wrote:
>> 
>> Discussed numerous times on this forum (i.e. differences between
>> different software implementations).
>> As far as I can see from your output, eviews uses:
>> 
>> Presample variance: backcast (parameter = 0.7)
>> 
>> whereas rugarch by default uses the whole sample for the initialization.
>> 
>> See the ugarchspec help function on variance.targeting which allows a numeric value (instead of logical)
>> between 0 and 1 for the backcasting.
>> 
>> However, it could also be the case of different bound constraints. In the rugarch model, the coefficients
>> on the external regressors in the variance equation for the sGARCH model are constrained to be positive.
>> Feel free to play around with 'setbounds<-' and a whole host of other options, including using an alternate
>> solver etc.
>> 
>> Alexios
>> 
>> On 10/09/2015 13:56, Eliano Marques wrote:
>> 
>>> Hi everyone,
>>> 
>>> I?m writing a thesis around the stock prices with ISEG in Lisbon. 
>>> 
>>> I wrote the entire end-to-end ETL in R and I?m trying to run all the models in R. Just as a sense check, I was comparing the results between Eviews and R and realised big differences between then and I wonder if you can help me debugging this differences, i?m sure I might be doing something wrong. 
>>> 
>>> Here is my R code: 
>>> 
>>> RFunction_garch_estimation=function( #stock, 
>>>                                    variance.model = list(model = "sGARCH", garchOrder = c(1, 1), 
>>>                                                          submodel = NULL, external.regressors = NULL, variance.targeting = FALSE), 
>>>                                    mean.model = list(armaOrder = c(1, 1), include.mean = TRUE, archm = FALSE, 
>>>                                                      archpow = 1, arfima = FALSE, external.regressors = NULL, archex = FALSE), 
>>>                                    distribution.model = "norm", start.pars = list(), fixed.pars = list(),
>>> 
>>>                                    spec, data, out.sample = 0, solver = "solnp", solver.control = list(), 
>>>                                    fit.control = list(stationarity = 1, fixed.se = 0, scale = 0, rec.init = 'all'), 
>>>                                    numderiv.control = list(grad.eps=1e-4, grad.d=0.0001, 
>>>                                                            grad.zero.tol=sqrt(.Machine$double.eps/7e-7), hess.eps=1e-4, hess.d=0.1, 
>>>                                                            hess.zero.tol=sqrt(.Machine$double.eps/7e-7), r=4, v=2)
>>> ) {
>>> library(rugarch)
>>> mod1=ugarchspec(variance.model = variance.model, 
>>>                 mean.model = mean.model, 
>>>                 distribution.model = distribution.model)
>>> mod1fit=ugarchfit(mod1, data,solver=solver, fit.control, out.sample, solver.control , numderiv.control )
>>> return(mod1fit) }
>>> 
>>> #This RFunction just sets the ugarchspec and estimates at the same the garch function. 
>>> 
>>> 
>>> variance_model = list(model = "sGARCH", garchOrder = c(1, 1), 
>>>                     submodel = NULL, external.regressors = as.matrix(regressors), variance.targeting = FALSE)
>>> mean_model = list(armaOrder = c(0,0 ), include.mean = TRUE, archm = FALSE, 
>>>                 archpow = 1, arfima = FALSE, external.regressors = as.matrix(regressors), archex = FALSE)
>>> distribution_model = "norm"
>>> #as.matrix(regressors)
>>> model1=RFunction_garch_estimation( data=target, variance.model = variance_model, mean.model = mean_model,distribution.model = distribution_model,solver='solnp')
>>> show(model1) 
>>> 
>>> #### Results:
>>> 
>>> Robust Standard Errors:
>>>       Estimate  Std. Error   t value Pr(>|t|)
>>> mu      0.000015    0.234264  0.000063  0.99995
>>> mxreg1  0.709299  292.613915  0.002424  0.99807
>>> mxreg2 -0.000112    0.098905 -0.001135  0.99909
>>> mxreg3  0.000034    0.065088  0.000528  0.99958
>>> mxreg4 -0.000003    0.075987 -0.000037  0.99997
>>> mxreg5 -0.000009    0.012701 -0.000723  0.99942
>>> omega   0.000000    0.000249  0.000175  0.99986
>>> alpha1  0.020642    1.493492  0.013821  0.98897
>>> beta1   0.973943    0.908957  1.071496  0.28395
>>> vxreg1  0.000000    0.030732  0.000000  1.00000
>>> vxreg2  0.000000    0.000019  0.000469  0.99963
>>> vxreg3  0.000000    0.001606  0.000007  0.99999
>>> vxreg4  0.000000    0.000630  0.000015  0.99999
>>> vxreg5  0.000000    0.000634  0.000000  1.00000
>>> 
>>> LogLikelihood : 30151.719 
>>> 
>>> Eviews outputs: 
>>> 
>>> Dependent Variable: target			
>>> Method: ML - ARCH (Marquardt) - Normal distribution			
>>> Date: 09/10/15   Time: 11:51			
>>> Sample: 11/05/2014 09:30 8/28/2015 17:30			
>>> Included observations: 6763			
>>> Convergence achieved after 25 iterations			
>>> Bollerslev-Wooldridge robust standard errors & covariance			
>>> Presample variance: backcast (parameter = 0.7)			
>>> 			
>>> GARCH = C(7) + C(8)*RESID(-1)^2 + C(9)*GARCH(-1) + C(10)				
>>>       *reg1 + C(11)*reg2 + C(12)				
>>>       *reg3 + C(13)*reg4 + C(14)				
>>>       *reg5				
>>> 				
>>> Variable			Coefficient	Std. Error		z-Statistic	Prob.  
>>> 				
>>> C				-1.62E-05	4.17E-05		-0.388964	0.6973
>>> reg1				0.723305		0.050098		14.43789		0.0000
>>> reg2				-0.000242	0.000123		-1.972702	0.0485
>>> reg3				0.000170		8.29E-05		2.049855		0.0404
>>> reg4				0.000107		0.000175		0.610040		0.5418
>>> reg5				-1.22E-05	8.26E-06		-1.482648	0.1382
>>> 
>>> 				
>>> Variance Equation			
>>> 				
>>> C				9.87E-06		3.85E-06		2.566464		0.0103
>>> RESID(-1)^2		0.149994		0.035467		4.229165		0.0000
>>> GARCH(-1)		0.599977		0.118194		5.076196		0.0000
>>> reg1				-0.000362	0.002233		-0.162239	0.8711
>>> reg2				1.35E-06		1.18E-05		0.114108		0.9092
>>> reg3				-5.72E-07	5.44E-07		-1.050865	0.2933
>>> reg4				-2.28E-06	9.78E-06		-0.232631	0.8160
>>> reg5				-8.48E-08	2.61E-08		-3.251462	0.0011
>>> 
>>> 
>>> Now please note that the  majority of the external regressors have 0 as coefficient in the conditional variance and this isn't much different from Eviews. However when you look at the coefficients alpha and beta they significantly differ from Eviews. In addition, both methods using the robust matrix of cov-var, the p-value of a large number of coefs. differ. 
>>> 
>>> Could you help me understand if I?m doing anything wrong in the R bit? 
>>> 
>>> Thank you,
>>> Eliano
>>> 
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions should go.
>> 
> 


From alexios at 4dscape.com  Thu Sep 10 18:46:04 2015
From: alexios at 4dscape.com (alexios galanos)
Date: Thu, 10 Sep 2015 19:46:04 +0300
Subject: [R-SIG-Finance] Different results on Garch(1,
 1) with regressors: Eviews vs rugarch
In-Reply-To: <1509AFC0-5F76-4877-A904-DB49A6070D5C@gmail.com>
References: <60555154-0B1E-4173-9740-ACA0F20A67B5@gmail.com>
	<55F16A67.6050403@4dscape.com>
	<63858CE3-EF42-47C2-91EE-EB87D02CCC49@gmail.com>
	<1509AFC0-5F76-4877-A904-DB49A6070D5C@gmail.com>
Message-ID: <55F1B3CC.9020508@4dscape.com>

I pretty sure this is related to the way the sGARCH model in rugarch
enforces the bounds on the
external regressors in the variance equation in order to ensure
positivity of the variance.
I would rarely recommend using sGARCH in the presence of external
regressors in the variance
equation, instead favoring eGARCH.
Other than that, I can't comment too much on the results...feel free to
send me the data offline and
will have a look when I get a chance.

Best,

Alexios

On 10/09/2015 19:41, Eliano Marques wrote:
> PS: I?ve also noted that the fit tests typically generate NA Weighted Ljung-Box and Arch LM tests. 
>
> Eliano
>> On 10 Sep 2015, at 17:38, Eliano Marques <eliano.m.marques at gmail.com> wrote:
>>
>> Hi Alexios,
>>
>> So i?ve tried many different methods and I?m still finding it difficult to come anywhere close Eviews results. While i do understand they won?t match to a penny the differences are quite significant at this stage. 
>>
>> What have I done:
>>
>> 1 - Adding variance.target=0.7 
>> Results:
>> Robust Standard Errors:
>>        Estimate  Std. Error   t value Pr(>|t|)
>> mu      0.000013    0.348112  0.000039  0.99997
>> mxreg1  0.714946  232.642591  0.003073  0.99755     # Eviews with backcast of 0.7 calculates this as 0.7233
>> mxreg2 -0.000108    0.267235 -0.000403  0.99968
>> mxreg3  0.000031    1.028411  0.000030  0.99998
>> mxreg4 -0.000009    0.083789 -0.000106  0.99991
>> mxreg5 -0.000009    0.126160 -0.000070  0.99994
>> alpha1  0.030775    0.050001  0.615491  0.53823		# Eviews estimates this as 0.14
>> beta1   0.969225    0.887995  1.091476  0.27506		#Eviews estimates this as 0.59
>> vxreg1  0.000000    0.293709  0.000000  1.00000
>> vxreg2  0.000000    0.000168  0.000049  0.99996
>> vxreg3  0.000000    0.000299  0.000033  0.99997
>> vxreg4  0.000000    0.000407  0.000023  0.99998
>> vxreg5  0.000000    0.003602  0.000000  1.00000
>> omega   0.000000          NA        NA       NA
>>
>> Note that omega now don?t have standard error, t-value and p.value. This is expected given the variance.targeting setting.  
>>
>> Now if I also set Eview variance.target option on (backcast doesn?t turn this on) the results get more similar between softwares. mxreg1 in mean equation is 0.705 (vs. 0.715 in R) and beta1 is eviews is 0.971 (vs. 0.969 in R).
>>
>> 2 - Set variance.target in Eviews to null 
>> Problem is the same as above as Eviews results are exactly the same. 
>>
>> 3 - Adding setbounds 
>> Problem remain. 
>>
>> I guess the issue that i?m facing here is more around the parameters of the variance function in the more simple terms not matching the Eview results. I know the var-cov methods are different but being significantly different is not expected. 
>>
>> The other thing that I have noticed is that if you change the garch model from standard to something else the results typically tend to match better so I wonder if I?m still missing something in the standard garch method. 
>>
>> Thank you,
>> Eliano
>>
>>
>>
>>> On 10 Sep 2015, at 12:32, alexios galanos <alexios at 4dscape.com> wrote:
>>>
>>> Discussed numerous times on this forum (i.e. differences between
>>> different software implementations).
>>> As far as I can see from your output, eviews uses:
>>>
>>> Presample variance: backcast (parameter = 0.7)
>>>
>>> whereas rugarch by default uses the whole sample for the initialization.
>>>
>>> See the ugarchspec help function on variance.targeting which allows a numeric value (instead of logical)
>>> between 0 and 1 for the backcasting.
>>>
>>> However, it could also be the case of different bound constraints. In the rugarch model, the coefficients
>>> on the external regressors in the variance equation for the sGARCH model are constrained to be positive.
>>> Feel free to play around with 'setbounds<-' and a whole host of other options, including using an alternate
>>> solver etc.
>>>
>>> Alexios
>>>
>>> On 10/09/2015 13:56, Eliano Marques wrote:
>>>
>>>> Hi everyone,
>>>>
>>>> I?m writing a thesis around the stock prices with ISEG in Lisbon. 
>>>>
>>>> I wrote the entire end-to-end ETL in R and I?m trying to run all the models in R. Just as a sense check, I was comparing the results between Eviews and R and realised big differences between then and I wonder if you can help me debugging this differences, i?m sure I might be doing something wrong. 
>>>>
>>>> Here is my R code: 
>>>>
>>>> RFunction_garch_estimation=function( #stock, 
>>>>                                    variance.model = list(model = "sGARCH", garchOrder = c(1, 1), 
>>>>                                                          submodel = NULL, external.regressors = NULL, variance.targeting = FALSE), 
>>>>                                    mean.model = list(armaOrder = c(1, 1), include.mean = TRUE, archm = FALSE, 
>>>>                                                      archpow = 1, arfima = FALSE, external.regressors = NULL, archex = FALSE), 
>>>>                                    distribution.model = "norm", start.pars = list(), fixed.pars = list(),
>>>>
>>>>                                    spec, data, out.sample = 0, solver = "solnp", solver.control = list(), 
>>>>                                    fit.control = list(stationarity = 1, fixed.se = 0, scale = 0, rec.init = 'all'), 
>>>>                                    numderiv.control = list(grad.eps=1e-4, grad.d=0.0001, 
>>>>                                                            grad.zero.tol=sqrt(.Machine$double.eps/7e-7), hess.eps=1e-4, hess.d=0.1, 
>>>>                                                            hess.zero.tol=sqrt(.Machine$double.eps/7e-7), r=4, v=2)
>>>> ) {
>>>> library(rugarch)
>>>> mod1=ugarchspec(variance.model = variance.model, 
>>>>                 mean.model = mean.model, 
>>>>                 distribution.model = distribution.model)
>>>> mod1fit=ugarchfit(mod1, data,solver=solver, fit.control, out.sample, solver.control , numderiv.control )
>>>> return(mod1fit) }
>>>>
>>>> #This RFunction just sets the ugarchspec and estimates at the same the garch function. 
>>>>
>>>>
>>>> variance_model = list(model = "sGARCH", garchOrder = c(1, 1), 
>>>>                     submodel = NULL, external.regressors = as.matrix(regressors), variance.targeting = FALSE)
>>>> mean_model = list(armaOrder = c(0,0 ), include.mean = TRUE, archm = FALSE, 
>>>>                 archpow = 1, arfima = FALSE, external.regressors = as.matrix(regressors), archex = FALSE)
>>>> distribution_model = "norm"
>>>> #as.matrix(regressors)
>>>> model1=RFunction_garch_estimation( data=target, variance.model = variance_model, mean.model = mean_model,distribution.model = distribution_model,solver='solnp')
>>>> show(model1) 
>>>>
>>>> #### Results:
>>>>
>>>> Robust Standard Errors:
>>>>       Estimate  Std. Error   t value Pr(>|t|)
>>>> mu      0.000015    0.234264  0.000063  0.99995
>>>> mxreg1  0.709299  292.613915  0.002424  0.99807
>>>> mxreg2 -0.000112    0.098905 -0.001135  0.99909
>>>> mxreg3  0.000034    0.065088  0.000528  0.99958
>>>> mxreg4 -0.000003    0.075987 -0.000037  0.99997
>>>> mxreg5 -0.000009    0.012701 -0.000723  0.99942
>>>> omega   0.000000    0.000249  0.000175  0.99986
>>>> alpha1  0.020642    1.493492  0.013821  0.98897
>>>> beta1   0.973943    0.908957  1.071496  0.28395
>>>> vxreg1  0.000000    0.030732  0.000000  1.00000
>>>> vxreg2  0.000000    0.000019  0.000469  0.99963
>>>> vxreg3  0.000000    0.001606  0.000007  0.99999
>>>> vxreg4  0.000000    0.000630  0.000015  0.99999
>>>> vxreg5  0.000000    0.000634  0.000000  1.00000
>>>>
>>>> LogLikelihood : 30151.719 
>>>>
>>>> Eviews outputs: 
>>>>
>>>> Dependent Variable: target			
>>>> Method: ML - ARCH (Marquardt) - Normal distribution			
>>>> Date: 09/10/15   Time: 11:51			
>>>> Sample: 11/05/2014 09:30 8/28/2015 17:30			
>>>> Included observations: 6763			
>>>> Convergence achieved after 25 iterations			
>>>> Bollerslev-Wooldridge robust standard errors & covariance			
>>>> Presample variance: backcast (parameter = 0.7)			
>>>> 			
>>>> GARCH = C(7) + C(8)*RESID(-1)^2 + C(9)*GARCH(-1) + C(10)				
>>>>       *reg1 + C(11)*reg2 + C(12)				
>>>>       *reg3 + C(13)*reg4 + C(14)				
>>>>       *reg5				
>>>> 				
>>>> Variable			Coefficient	Std. Error		z-Statistic	Prob.  
>>>> 				
>>>> C				-1.62E-05	4.17E-05		-0.388964	0.6973
>>>> reg1				0.723305		0.050098		14.43789		0.0000
>>>> reg2				-0.000242	0.000123		-1.972702	0.0485
>>>> reg3				0.000170		8.29E-05		2.049855		0.0404
>>>> reg4				0.000107		0.000175		0.610040		0.5418
>>>> reg5				-1.22E-05	8.26E-06		-1.482648	0.1382
>>>>
>>>> 				
>>>> Variance Equation			
>>>> 				
>>>> C				9.87E-06		3.85E-06		2.566464		0.0103
>>>> RESID(-1)^2		0.149994		0.035467		4.229165		0.0000
>>>> GARCH(-1)		0.599977		0.118194		5.076196		0.0000
>>>> reg1				-0.000362	0.002233		-0.162239	0.8711
>>>> reg2				1.35E-06		1.18E-05		0.114108		0.9092
>>>> reg3				-5.72E-07	5.44E-07		-1.050865	0.2933
>>>> reg4				-2.28E-06	9.78E-06		-0.232631	0.8160
>>>> reg5				-8.48E-08	2.61E-08		-3.251462	0.0011
>>>>
>>>>
>>>> Now please note that the  majority of the external regressors have 0 as coefficient in the conditional variance and this isn't much different from Eviews. However when you look at the coefficients alpha and beta they significantly differ from Eviews. In addition, both methods using the robust matrix of cov-var, the p-value of a large number of coefs. differ. 
>>>>
>>>> Could you help me understand if I?m doing anything wrong in the R bit? 
>>>>
>>>> Thank you,
>>>> Eliano
>>>>
>>>> _______________________________________________
>>>> R-SIG-Finance at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>>> -- Also note that this is not the r-help list where general R questions should go.
>


From amelia_marsh08 at yahoo.com  Wed Sep 16 19:50:12 2015
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Wed, 16 Sep 2015 17:50:12 +0000 (UTC)
Subject: [R-SIG-Finance] Principal Component Analysis in Credit Risk
Message-ID: <45388184.492747.1442425812121.JavaMail.yahoo@mail.yahoo.com>

Dear Forum,

I need some direction and guidance. This perhaps may sound a vague question, but I will try to be specific as far as possible.

Recently I came to know about text analysis in R. Assuming I have analysts reports regarding say 250 companies. I am aware that out of these 25 companies, 5 companies have defaulted. I have been asked to apply principal component analysis to each of these 25 companies to find out those words which if are occurring in say the 26th companies Analyst report, it will give me clear indication that this company will default. 

I understand this is really a vague question. To begin with, can Principal Component Analysis be used for text and if yes, can someone give me some direction or source.

Regards

Amelia


From danielmelendez at alum.northwestern.edu  Wed Sep 16 20:06:08 2015
From: danielmelendez at alum.northwestern.edu (Daniel Melendez)
Date: Wed, 16 Sep 2015 13:06:08 -0500
Subject: [R-SIG-Finance] Principal Component Analysis in Credit Risk
In-Reply-To: <45388184.492747.1442425812121.JavaMail.yahoo@mail.yahoo.com>
References: <45388184.492747.1442425812121.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAEjpDDqxjr+Po7uXo1g4MK9fnEsE1GFb-Gd40SvoWvF9-TdqfA@mail.gmail.com>

I'm assuming based off of the information you have provided I think you may
want to look into factor analysis.  Try the psych package, it'll provide a
good base.  Plus you might want to look into cluster analysis and some
other forms of grouping techniques.

On Wed, Sep 16, 2015 at 12:50 PM, Amelia Marsh via R-SIG-Finance <
r-sig-finance at r-project.org> wrote:

> Dear Forum,
>
> I need some direction and guidance. This perhaps may sound a vague
> question, but I will try to be specific as far as possible.
>
> Recently I came to know about text analysis in R. Assuming I have analysts
> reports regarding say 250 companies. I am aware that out of these 25
> companies, 5 companies have defaulted. I have been asked to apply principal
> component analysis to each of these 25 companies to find out those words
> which if are occurring in say the 26th companies Analyst report, it will
> give me clear indication that this company will default.
>
> I understand this is really a vague question. To begin with, can Principal
> Component Analysis be used for text and if yes, can someone give me some
> direction or source.
>
> Regards
>
> Amelia
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>



-- 
Regards

Daniel Melendez

=========================================================================

	[[alternative HTML version deleted]]


From Josh-CH.Chien at nanshan.com.tw  Thu Sep 17 01:57:11 2015
From: Josh-CH.Chien at nanshan.com.tw (Chien, Josh-CH)
Date: Thu, 17 Sep 2015 07:57:11 +0800
Subject: [R-SIG-Finance] Principal Component Analysis in Credit Risk
In-Reply-To: <45388184.492747.1442425812121.JavaMail.yahoo@mail.yahoo.com>
References: <45388184.492747.1442425812121.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <7D2C57241CB1C9419888B85C01CC993D499063E1@WNSPWMBV01.nsli.net>

Hi Amelia,
Sound like you will find the "key" word as trigger for default or not default of company.
Based on your information, I think Daniel's response is right. You should focus on factor model.
However, in my understanding, PCA is a statistical method to tell us every part's explanation, but every party can't be given any meaning on economic view.
If it's you want, just type "PCA in r / PCA in r library" in google search.
You will found a lot library to deal with this issue and take time to check for choosing one of them you need.

______________________________________
JOSH CHIEN
Risk Analytics & Projects
Risk Management Dept.
Nan Shan Life Insurance Co.
Email: Josh-CH.Chien at NANSHAN.com.tw
DID: +886-2-8758-9522


-----Original Message-----
From: R-SIG-Finance [mailto:r-sig-finance-bounces at r-project.org] On Behalf Of Amelia Marsh via R-SIG-Finance
Sent: Thursday, September 17, 2015 1:50 AM
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] Principal Component Analysis in Credit Risk

Dear Forum,

I need some direction and guidance. This perhaps may sound a vague question, but I will try to be specific as far as possible.

Recently I came to know about text analysis in R. Assuming I have analysts reports regarding say 250 companies. I am aware that out of these 25 companies, 5 companies have defaulted. I have been asked to apply principal component analysis to each of these 25 companies to find out those words which if are occurring in say the 26th companies Analyst report, it will give me clear indication that this company will default.

I understand this is really a vague question. To begin with, can Principal Component Analysis be used for text and if yes, can someone give me some direction or source.

Regards

Amelia

_______________________________________________
R-SIG-Finance at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions should go.

"NOTICE: The e-mail, and any attachments thereto, may contain legally privileged and/or other confidential information. If you have received it in error, please notify the sender by reply e-mail and immediately delete the e-mail and any attachments without copying or disclosing the contents. Thank you."

"?????????????????????? ????????????????????????????????????????????????????????????????????"

From Patrick.Caldon at morningstar.com  Thu Sep 17 01:59:34 2015
From: Patrick.Caldon at morningstar.com (Patrick Caldon)
Date: Wed, 16 Sep 2015 23:59:34 +0000
Subject: [R-SIG-Finance] Principal Component Analysis in Credit Risk
In-Reply-To: <45388184.492747.1442425812121.JavaMail.yahoo@mail.yahoo.com>
References: <45388184.492747.1442425812121.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <5E2872F3BE4FB3479878EDE3BA56556D10A92433@MSEXCHM83.morningstar.com>

Hi Amelia,

Such systems are doable.

* 250 companies might be a bit light? I'd start with more
* Analyst reports are ok, but consider other text-based data sources, you will get more milage there.
* PCA might not be the best starting point.  Either get a specialized text-based clustering methodology, e.g. topic model, or use a regression/classification technique robust to very high dimensional problems.  I would start with the latter given your brief description.

Good luck!

---

Dear Forum,

I need some direction and guidance. This perhaps may sound a vague question, but I will try to be specific as far as possible.

Recently I came to know about text analysis in R. Assuming I have analysts reports regarding say 250 companies. I am aware that out of these 25 companies, 5 companies have defaulted. I have been asked to apply principal component analysis to each of these 25 companies to find out those words which if are occurring in say the 26th companies Analyst report, it will give me clear indication that this company will default. 

I understand this is really a vague question. To begin with, can Principal Component Analysis be used for text and if yes, can someone give me some direction or source.

Regards

Amelia


From Josh-CH.Chien at nanshan.com.tw  Thu Sep 17 02:18:32 2015
From: Josh-CH.Chien at nanshan.com.tw (Chien, Josh-CH)
Date: Thu, 17 Sep 2015 08:18:32 +0800
Subject: [R-SIG-Finance] RQuantLib Library on Mac OS Yosemite
Message-ID: <7D2C57241CB1C9419888B85C01CC993D499063F7@WNSPWMBV01.nsli.net>

Hi R users,
Does anyone use RQuantLib Library on Mac OS Yosemite ?
RQuantLib seems not work on new Mac OS.
>From CRAN, I saw below these statement. Do anyone know how to inform administrator for updating ?
OS X Mavericks(10.9) binaries:

r-release: not available

MAC OS is running on Mac Yosemite(10.10).
Thanks a lot.
______________________________________
JOSH CHIEN
Risk Analytics & Projects
Risk Management Dept.
Nan Shan Life Insurance Co.
Email: Josh-CH.Chien at NANSHAN.com.tw<mailto:%20Josh-CH.Chien at NANSHAN.com.tw>
DID: +886-2-8758-9522


________________________________
"NOTICE: The e-mail, and any attachments thereto, may co...{{dropped:12}}


From jcurole at gmail.com  Thu Sep 17 03:37:26 2015
From: jcurole at gmail.com (Jason Curole)
Date: Wed, 16 Sep 2015 20:37:26 -0500
Subject: [R-SIG-Finance] Principal Component Analysis in Credit Risk
In-Reply-To: <45388184.492747.1442425812121.JavaMail.yahoo@mail.yahoo.com>
References: <45388184.492747.1442425812121.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAP7_7MmQ6BqhqFTxArgs_gFyQeCmK-D0f5koGMT0r2qabdP7Ew@mail.gmail.com>

Amelia,

In 2012 there was a piece in the magazine n+1 using factor analysis to
classify genre's of literature, which I think might be somewhat similar to
what you are trying to do (in your case genre being defaulted or not
defaulted). You can read about their work here:

https://nplusonemag.com/issue-13/essays/quantitative-formalism-an-experiment/

As I recall, they had pretty good success in classifying genres.  Hope this
helps.

Best, Jason

On Wed, Sep 16, 2015 at 12:50 PM, Amelia Marsh via R-SIG-Finance <
r-sig-finance at r-project.org> wrote:

> Dear Forum,
>
> I need some direction and guidance. This perhaps may sound a vague
> question, but I will try to be specific as far as possible.
>
> Recently I came to know about text analysis in R. Assuming I have analysts
> reports regarding say 250 companies. I am aware that out of these 25
> companies, 5 companies have defaulted. I have been asked to apply principal
> component analysis to each of these 25 companies to find out those words
> which if are occurring in say the 26th companies Analyst report, it will
> give me clear indication that this company will default.
>
> I understand this is really a vague question. To begin with, can Principal
> Component Analysis be used for text and if yes, can someone give me some
> direction or source.
>
> Regards
>
> Amelia
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From harrymcgraw at outlook.com  Thu Sep 17 19:25:02 2015
From: harrymcgraw at outlook.com (Harry McGraw)
Date: Thu, 17 Sep 2015 17:25:02 +0000
Subject: [R-SIG-Finance] Quantstrat OSfun
Message-ID: <SNT153-W69C0C2B0F2E42A0D48065CA15A0@phx.gbl>

Hi members!

I have problems with creating an order sizing function (OSfun) in Quantstrat.I've added a column in the mktdata-object, called "allocation". I want to use the current value (for example -0.15) to calculate the order size (for example -0.15 * tradeSize). 

Thanks in advance! 		 	   		  
	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Fri Sep 18 01:10:56 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 17 Sep 2015 18:10:56 -0500
Subject: [R-SIG-Finance] Quantstrat OSfun
In-Reply-To: <SNT153-W69C0C2B0F2E42A0D48065CA15A0@phx.gbl>
References: <SNT153-W69C0C2B0F2E42A0D48065CA15A0@phx.gbl>
Message-ID: <CAPPM_gSXTvqFvcaQ8Yj=gbrX81vkk_f=uYuVJr0WZRv+-DCP9A@mail.gmail.com>

On Thu, Sep 17, 2015 at 12:25 PM, Harry McGraw <harrymcgraw at outlook.com> wrote:
> Hi members!
>
> I have problems with creating an order sizing function (OSfun) in Quantstrat.I've added a column in the mktdata-object, called "allocation". I want to use the current value (for example -0.15) to calculate the order size (for example -0.15 * tradeSize).
>
You need to provide a minimal, reproducible example
(http://stackoverflow.com/q/5963269/271616) to increase the
probability that someone helps you.

> Thanks in advance!
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From danielmelendez at alum.northwestern.edu  Fri Sep 18 20:33:00 2015
From: danielmelendez at alum.northwestern.edu (Daniel Melendez)
Date: Fri, 18 Sep 2015 13:33:00 -0500
Subject: [R-SIG-Finance] Importance Sampling
Message-ID: <CAEjpDDqWa7tvgbopbZJLX33aOUmYRv+6xn5iA40i62QhwszE=Q@mail.gmail.com>

Hello All -

I am trying to simulate rare events (alpha = 0.001) using importance
sampling.  I currently have estimated parameters for an NIG distribution
but I am stuck on how to exactly choose the competing density?  Has anyone
ever used such a technique?  Any guidance would be greatly appreciated

-- 
Regards

Daniel Melendez

=========================================================================

	[[alternative HTML version deleted]]


From idontgetoutmuch at googlemail.com  Sat Sep 19 17:58:58 2015
From: idontgetoutmuch at googlemail.com (Dominic Steinitz)
Date: Sat, 19 Sep 2015 16:58:58 +0100
Subject: [R-SIG-Finance] Importance Sampling
Message-ID: <CAN_vZV18Qqj9iEa8BCXHus1-j+nOFZwN-CP=9djX-qrWAGwJyA@mail.gmail.com>

alpha is just a parameter. Which rare event are you trying to
estimate? Do you have a RV which is NIG and you wish to estimate a
rare event for that RV?

Dominic Steinitz
dominic at steinitz.org
http://idontgetoutmuch.wordpress.com

>
> Message: 1
> Date: Fri, 18 Sep 2015 13:33:00 -0500
> From: Daniel Melendez <danielmelendez at alum.northwestern.edu>
> To: r-sig-finance at r-project.org
> Subject: [R-SIG-Finance] Importance Sampling
> Message-ID:
>       <CAEjpDDqWa7tvgbopbZJLX33aOUmYRv+6xn5iA40i62QhwszE=Q at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Hello All -
>
> I am trying to simulate rare events (alpha = 0.001) using importance
> sampling.  I currently have estimated parameters for an NIG distribution
> but I am stuck on how to exactly choose the competing density?  Has anyone
> ever used such a technique?  Any guidance would be greatly appreciated


>
> --
> Regards
>
> Daniel Melendez

	[[alternative HTML version deleted]]


From kumarravi1165 at gmail.com  Sat Sep 19 20:29:34 2015
From: kumarravi1165 at gmail.com (Ravi Kumar)
Date: Sat, 19 Sep 2015 23:59:34 +0530
Subject: [R-SIG-Finance] Career
Message-ID: <CA+n2EmUucg_ng0MaVbYuYscHqonzOHYd9DqmnzWvmUGK7xGn6A@mail.gmail.com>

Hello,
I am a student  of electrical engineering at Indian Institute of
Technology, but I am inclined more towards quantitative finance. I don't
like reading course books and find myself always learning financial maths
and other finance related stuff.
I don't know if this is the write place to ask this question but anyway, I
was wondering, if I have the necessary skills required for quants but don't
have good GPA. Would I be able to land a job in quantitative finance?

Thank You

	[[alternative HTML version deleted]]


From brian at braverock.com  Sat Sep 19 20:40:52 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 19 Sep 2015 13:40:52 -0500
Subject: [R-SIG-Finance] Career
In-Reply-To: <CA+n2EmUucg_ng0MaVbYuYscHqonzOHYd9DqmnzWvmUGK7xGn6A@mail.gmail.com>
References: <CA+n2EmUucg_ng0MaVbYuYscHqonzOHYd9DqmnzWvmUGK7xGn6A@mail.gmail.com>
Message-ID: <55FDAC34.3020809@braverock.com>

On 09/19/2015 01:29 PM, Ravi Kumar wrote:
> Hello,
> I am a student  of electrical engineering at Indian Institute of
> Technology, but I am inclined more towards quantitative finance. I don't
> like reading course books and find myself always learning financial maths
> and other finance related stuff.
> I don't know if this is the write place to ask this question but anyway, I
> was wondering, if I have the necessary skills required for quants but don't
> have good GPA. Would I be able to land a job in quantitative finance?

This doesn't really have anything to do with R.

You'll probably need to inquire on a local career list.

Most large firms can hire from top universities, and can choose students 
with precisely the course list and GPS's that they want.  Smaller firms 
may be less picky, but low GPA will almost certainly make people 
unwilling to sponsor visas.

Regards,

Brian


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From aschmid1 at stevens.edu  Tue Sep 22 15:37:12 2015
From: aschmid1 at stevens.edu (aschmid1)
Date: Tue, 22 Sep 2015 09:37:12 -0400
Subject: [R-SIG-Finance] Failure of solve.QP in portfolio modeling
Message-ID: <27b87cf04149ec20a56aa7438aafe246@stevens.edu>

Hi everyone,
I'm trying to estimate optimal Markowitz portfolio weights for a list of 
stocks chosen upon some criterion using solve.QP from quadprog library. 
When the number of stocks N reaches some limit, I get a message "matrix 
D in quadratic function is not positive definite." For example, if I 
rebalance every 6 weeks (which implies that variance is calculated for 
6-week interval prior to the period for which I calculate portfolio 
weights), I can get solution for 25>=N<50. For 12-week interval, 
solution exists for 50>=N<100, and for 24-week interval, I can get 
solution for N=100. My attempt to remedy this problem with Higham's 
method doesn't help. I'll greatly appreciate you input: first, why this 
may happen (can there be lack of local minimum?), and second, whether 
there are R solvers that may need only semi positive definite matrix.

Thanks! Alec


From ilya.kipnis at gmail.com  Tue Sep 22 15:50:15 2015
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Tue, 22 Sep 2015 09:50:15 -0400
Subject: [R-SIG-Finance] Failure of solve.QP in portfolio modeling
In-Reply-To: <27b87cf04149ec20a56aa7438aafe246@stevens.edu>
References: <27b87cf04149ec20a56aa7438aafe246@stevens.edu>
Message-ID: <CA+oJuEF2sa45Oohi9mFur88_PZidTZ3Afj3jObicgaxAEtRryA@mail.gmail.com>

Because you can't invert a matrix with more features than observations. IE
if you have 50 stocks but only use 26 weekly return data points, you can't
invert that covariance matrix because it's not positive semi-definite. You
may want to try my Constrained Critical Line algorithm.

https://quantstrattrader.wordpress.com/2015/06/05/momentum-markowitz-and-solving-rank-deficient-covariance-matrices-the-constrained-critical-line-algorithm/



On Tue, Sep 22, 2015 at 9:37 AM, aschmid1 <aschmid1 at stevens.edu> wrote:

> Hi everyone,
> I'm trying to estimate optimal Markowitz portfolio weights for a list of
> stocks chosen upon some criterion using solve.QP from quadprog library.
> When the number of stocks N reaches some limit, I get a message "matrix D
> in quadratic function is not positive definite." For example, if I
> rebalance every 6 weeks (which implies that variance is calculated for
> 6-week interval prior to the period for which I calculate portfolio
> weights), I can get solution for 25>=N<50. For 12-week interval, solution
> exists for 50>=N<100, and for 24-week interval, I can get solution for
> N=100. My attempt to remedy this problem with Higham's method doesn't help.
> I'll greatly appreciate you input: first, why this may happen (can there be
> lack of local minimum?), and second, whether there are R solvers that may
> need only semi positive definite matrix.
>
> Thanks! Alec
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From es at enricoschumann.net  Tue Sep 22 16:56:44 2015
From: es at enricoschumann.net (Enrico Schumann)
Date: Tue, 22 Sep 2015 16:56:44 +0200
Subject: [R-SIG-Finance] Failure of solve.QP in portfolio modeling
In-Reply-To: <27b87cf04149ec20a56aa7438aafe246@stevens.edu>
	(aschmid1@stevens.edu's message of "Tue, 22 Sep 2015 09:37:12 -0400")
References: <27b87cf04149ec20a56aa7438aafe246@stevens.edu>
Message-ID: <87y4fywlhv.fsf@enricoschumann.net>

On Tue, 22 Sep 2015, aschmid1 <aschmid1 at stevens.edu> writes:

> Hi everyone,
> I'm trying to estimate optimal Markowitz portfolio weights for a list
> of stocks chosen upon some criterion using solve.QP from quadprog
> library. When the number of stocks N reaches some limit, I get a
> message "matrix D in quadratic function is not positive definite." For
> example, if I rebalance every 6 weeks (which implies that variance is
> calculated for 6-week interval prior to the period for which I
> calculate portfolio weights), I can get solution for 25>=N<50. For
> 12-week interval, solution exists for 50>=N<100, and for 24-week
> interval, I can get solution for N=100. My attempt to remedy this
> problem with Higham's method doesn't help. I'll greatly appreciate you
> input: first, why this may happen (can there be lack of local
> minimum?), and second, whether there are R solvers that may need only
> semi positive definite matrix.
>
> Thanks! Alec
>

The thing you may want to look up is the "rank" of a matrix.

For instance, I create a small data set R -- suppose these were
daily-returns data of 10 equities.

  na   <- 10 ## number of assets
  nobs <- 10 ## number of observations

  R <- array(rnorm(nobs * na, sd = 0.01), dim = c(nobs, na))
  qr(cov(R))$rank

The rank of the covariance matrix is only 9; you need na+1 observations
to get full rank. You can still compute the standard deviation of a
portfolio:

  ew <- rep(1/na, na) ## equal-weight portfolio
  sqrt(ew %*% cov(R) %*% ew)

But with a non-full rank matrix and no constraints, it is guaranteed
that you have portfolios like this one:

  zerovol <- svd(cov(R))$v[,10]
  sqrt(abs(zerovol %*% cov(R) %*% zerovol))

You get a zero-volatility portfolio.

Whether that matters depends on your application. With constraints,
perhaps not.

An example in which it does not matter is in Section "1.3
Redundant assets" in
https://cran.r-project.org/web/packages/NMOF/vignettes/TAportfolio.pdf 

There you also have an example of a solver. A lengthier discussion is in
Section "13.2.5 Repairing Matrices" in this book

@BOOK{Gilli2011b,
  title        = {Numerical Methods and Optimization in Finance},
  publisher    = {Elsevier/Academic Press},
  year         = 2011,
  author       = {Gilli, Manfred and Maringer, Dietmar and Schumann,
                  Enrico}
}

of which [disclosure], I am a co-author.

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From patrick at burns-stat.com  Tue Sep 22 20:59:36 2015
From: patrick at burns-stat.com (Patrick Burns)
Date: Tue, 22 Sep 2015 19:59:36 +0100
Subject: [R-SIG-Finance] Failure of solve.QP in portfolio modeling
In-Reply-To: <27b87cf04149ec20a56aa7438aafe246@stevens.edu>
References: <27b87cf04149ec20a56aa7438aafe246@stevens.edu>
Message-ID: <5601A518.5040601@burns-stat.com>

You can use a factor model or shrinkage
to get a positive definite variance matrix.
There is a function for each in the
BurStFin package on CRAN.

The optimizer in Portfolio Probe doesn't
care about positive definiteness (though
that is not always a good thing).  It is
free for academic use.

Pat

On 22/09/2015 14:37, aschmid1 wrote:
> Hi everyone,
> I'm trying to estimate optimal Markowitz portfolio weights for a list of
> stocks chosen upon some criterion using solve.QP from quadprog library.
> When the number of stocks N reaches some limit, I get a message "matrix
> D in quadratic function is not positive definite." For example, if I
> rebalance every 6 weeks (which implies that variance is calculated for
> 6-week interval prior to the period for which I calculate portfolio
> weights), I can get solution for 25>=N<50. For 12-week interval,
> solution exists for 50>=N<100, and for 24-week interval, I can get
> solution for N=100. My attempt to remedy this problem with Higham's
> method doesn't help. I'll greatly appreciate you input: first, why this
> may happen (can there be lack of local minimum?), and second, whether
> there are R solvers that may need only semi positive definite matrix.
>
> Thanks! Alec
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com
http://www.portfolioprobe.com/blog
twitter: @burnsstat @portfolioprobe


From patrick at burns-stat.com  Tue Sep 22 22:03:14 2015
From: patrick at burns-stat.com (Patrick Burns)
Date: Tue, 22 Sep 2015 21:03:14 +0100
Subject: [R-SIG-Finance] Failure of solve.QP in portfolio modeling
In-Reply-To: <5601A518.5040601@burns-stat.com>
References: <27b87cf04149ec20a56aa7438aafe246@stevens.edu>
	<5601A518.5040601@burns-stat.com>
Message-ID: <5601B402.5040501@burns-stat.com>

One correction and another comment.

I should have said that a trade optimizer
not caring about positive definiteness is
usually a bad thing -- it has its uses
but giving the optimizer a shot at a
portfolio with negative variance is asking
for trouble (because it will do its best
to get there).

The estimates of the variance with only a
few observations are going to be extremely
noisy.  I think the length of history to
be used to estimate the variance should
depend on what length gives the best variance
estimate and should be independent of the
rebalancing schedule.  (Though perhaps I
have misinterpreted the original post.)

Pat

On 22/09/2015 19:59, Patrick Burns wrote:
> You can use a factor model or shrinkage
> to get a positive definite variance matrix.
> There is a function for each in the
> BurStFin package on CRAN.
>
> The optimizer in Portfolio Probe doesn't
> care about positive definiteness (though
> that is not always a good thing).  It is
> free for academic use.
>
> Pat
>
> On 22/09/2015 14:37, aschmid1 wrote:
>> Hi everyone,
>> I'm trying to estimate optimal Markowitz portfolio weights for a list of
>> stocks chosen upon some criterion using solve.QP from quadprog library.
>> When the number of stocks N reaches some limit, I get a message "matrix
>> D in quadratic function is not positive definite." For example, if I
>> rebalance every 6 weeks (which implies that variance is calculated for
>> 6-week interval prior to the period for which I calculate portfolio
>> weights), I can get solution for 25>=N<50. For 12-week interval,
>> solution exists for 50>=N<100, and for 24-week interval, I can get
>> solution for N=100. My attempt to remedy this problem with Higham's
>> method doesn't help. I'll greatly appreciate you input: first, why this
>> may happen (can there be lack of local minimum?), and second, whether
>> there are R solvers that may need only semi positive definite matrix.
>>
>> Thanks! Alec
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>

-- 
Patrick Burns
patrick at burns-stat.com
http://www.burns-stat.com
http://www.portfolioprobe.com/blog
twitter: @burnsstat @portfolioprobe


From josh.m.ulrich at gmail.com  Wed Sep 23 15:50:33 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 23 Sep 2015 08:50:33 -0500
Subject: [R-SIG-Finance] quantmod - How to have addTA() not print legend
 when the indicator is overlaid on another chart?
In-Reply-To: <CADT=x93bWZofGZx60ypTqGubyNK=OVoq3Y1BWe_zZfpjZKyyLw@mail.gmail.com>
References: <CADT=x93bWZofGZx60ypTqGubyNK=OVoq3Y1BWe_zZfpjZKyyLw@mail.gmail.com>
Message-ID: <CAPPM_gTK6nT9Ey8veXUtbAdWiRLjr2bG7=7-kreTUYpDDFbJMA@mail.gmail.com>

Thanks for the report.  I've created an issue for this on quantmod's
GitHub repo:
https://github.com/joshuaulrich/quantmod/issues/67

I don't currently have a solution.

Best,
Josh

On Thu, Jul 23, 2015 at 3:02 AM, Mauna <7141175 at gmail.com> wrote:
> In this code:
>
> library(quantmod)
> getSymbols("YHOO")
> candleChart(YHOO)
> addTA(Cl(YHOO)/2, legend = "", on = NA )
>
> the legend parameter of addTa() works as expected.
>
> But the same value to that parameter does not work if I let on = 1:
>
> library(quantmod)
> getSymbols("YHOO")
> candleChart(YHOO)
> addTA(Cl(YHOO)/2, legend = "", on = 1 )
>
> It shows Cl(YHOO)/2: followed by the last adjusted price as the legend. How
> can I remove this legend? Also, is it possible to remove the last price of
> shown on the chart? I couldn't find any mention of this in the chartSeries()
>  documentation.
>
> The following is the output of my sessionInfo():
>
> R version 3.2.1 (2015-06-18)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 8 x64 (build 9200)
>
> locale:[1] LC_COLLATE=English_United States.1252
> LC_CTYPE=English_United States.1252   [3] LC_MONETARY=English_United
> States.1252 LC_NUMERIC=C                          [5]
> LC_TIME=English_United States.1252
>
> attached base packages:[1] parallel  stats     graphics  grDevices
> utils     datasets  methods   base
>
> other attached packages:[1] quantmod_0.4-4   TTR_0.22-0
> doParallel_1.0.8 iterators_1.0.7  xts_0.9-7       [6] zoo_1.7-12
> foreach_1.4.2    magrittr_1.5
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.11.6      lubridate_1.3.3  lattice_0.20-31
> codetools_0.2-11 digest_0.6.8
>  [6] dplyr_0.4.2      assertthat_0.1   plyr_1.8.3       grid_3.2.1
>   R6_2.1.0        [11] DBI_0.3.1        RSQLite_1.0.0    utilsSE_0.1
>    stringi_0.5-5    lazyeval_0.1.10 [16] tools_3.2.1
> stringr_1.0.0    compiler_3.2.1   memoise_0.2.1
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From arborwang at qq.com  Thu Sep 24 12:08:50 2015
From: arborwang at qq.com (=?gb18030?B?QXJib3Igd2FuZw==?=)
Date: Thu, 24 Sep 2015 18:08:50 +0800
Subject: [R-SIG-Finance] RCurl post request implement problem.
Message-ID: <tencent_369E2F577181A5D5353B27F6@qq.com>

Hi All, 
I want to post request for getting data from API  via RCurl.


in Linux command line, I do it successfully:


 dt = 'date+%y%m%d%H%M%S'
 home_ph = /data/test
 data_ph = /data/test/data
 urls = 183.60.7.39:9980
 curl $urls -H 'Connection: close' -o $data_ph/$1-$2-$dt.txt -u user1:eb2e9a27392d4cfd3ce2d3f00bc18d7e --data @$home_ph/$1 --compressed



the post content as follows:

 <?xml version="1.0" encoding="UTF-8"?>

 <kangaroo-request>

 <request>

 <sqlId>test_2</sqlId>

 <content-type>text/json</content-type>

 <startRow></startRow>

 <endRow></endRow>

 <alias>gds</alias>

 <params></params>

 </request>

 </kangaroo-request>









But I cannot code it with getURL() function in R.

  >> sort(names(getCurlOptionsConstants()))

Although I can get the list of options, No further info about these options, 

no bridge between the options of getURL() and libCurl.




Could anyone give me some advice for me to do the code with RCurl Library in R ?

Any help is much appreciated. 3x much.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20150924/dd3a6a69/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/octet-stream
Size: 4689 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-finance/attachments/20150924/dd3a6a69/attachment.obj>

From josh.m.ulrich at gmail.com  Thu Sep 24 14:00:11 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 24 Sep 2015 07:00:11 -0500
Subject: [R-SIG-Finance] RCurl post request implement problem.
In-Reply-To: <tencent_369E2F577181A5D5353B27F6@qq.com>
References: <tencent_369E2F577181A5D5353B27F6@qq.com>
Message-ID: <CAPPM_gT33M5M4--jt5JfTRF0ob-=cxZbJ3K6eKtsS_rE0LaGgQ@mail.gmail.com>

Since this is not related to finance, you'll likely get better
response if you post to R-help instead.

On Thu, Sep 24, 2015 at 5:08 AM, Arbor wang <arborwang at qq.com> wrote:
>
> Hi All,
> I want to post request for getting data from API  via RCurl.
>
> in Linux command line, I do it successfully:
>
>  dt = 'date+%y%m%d%H%M%S'
>  home_ph = /data/test
>  data_ph = /data/test/data
>  urls = 183.60.7.39:9980
>  curl $urls -H 'Connection: close' -o $data_ph/$1-$2-$dt.txt -u user1:eb2e9a27392d4cfd3ce2d3f00bc18d7e --data @$home_ph/$1 --compressed
>
> the post content as follows:
>
>  <?xml version="1.0" encoding="UTF-8"?>
>
>  <kangaroo-request>
>
>  <request>
>
>  <sqlId>test_2</sqlId>
>
>  <content-type>text/json</content-type>
>
>  <startRow></startRow>
>
>  <endRow></endRow>
>
>  <alias>gds</alias>
>
>  <params></params>
>
>  </request>
>
>  </kangaroo-request>
>
>
>
> But I cannot code it with getURL() function in R.
>
>   >> sort(names(getCurlOptionsConstants()))
>
> Although I can get the list of options, No further info about these options,
>
> no bridge between the options of getURL() and libCurl.
>
>
> Could anyone give me some advice for me to do the code with RCurl Library in R ?
>
> Any help is much appreciated. 3x much.
>
>
>
>
>
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.




-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From sam.a.damon at gmail.com  Sun Sep 27 18:45:31 2015
From: sam.a.damon at gmail.com (Jorge Hernandez)
Date: Sun, 27 Sep 2015 12:45:31 -0400
Subject: [R-SIG-Finance] Constant maturity Futures
In-Reply-To: <CACCk-cHAS+yBjr9xuJqDiQLoQVt39sLMtdOe6+=LUjoCB08=hw@mail.gmail.com>
References: <CACCk-cHAS+yBjr9xuJqDiQLoQVt39sLMtdOe6+=LUjoCB08=hw@mail.gmail.com>
Message-ID: <CABvxFd1DnPNhWc67=U-tqFyjy193aUo+zkCcKcCAdi5JVM+oXA@mail.gmail.com>

Hi Samuel,


I made an attempt some time ago to put together a single price series for
futures contracts.  The problem of course is that to get a data set of
decent size to estimate a time series model I need to go over a few front
month/expiration cycles.  Here are some highlights of my experience in case
you find them to be useful.


I left the project (ie. betting using futures) for several reasons, but as
I recall it is not difficult to do for a single underlying.   My code
became clumsy however when I tried to automate the switch to a new front
month for all the underlyings that I was following since they had different
contract expiration cycles.  This was work in progress when I decided not
to pursue the project.


My experience with obtaining data is as follows.  I no longer had access to
Bloomberg, etc so I found that Quandl had free futures data but without any
adjustments.  They also have a database where they string together contract
prices using different rules.  Access to this database had a free trial
period but was otherwise $50/month.  During the trial period I sent them an
email asking about something that I noticed by eyeball on a price series
that did not seem right.  (I do not remember specifically what it was, but
it had to do with the data values themselves.  If someone is interested I
can dig up the email.)  They replied to thank me for pointing it out and
said something to the effect that they had now fixed it.  However I did not
feel comfortable using that data to bet money.


The other thing that I tried is through my online brokerage.  It turns out
that they keep data for a few months back.  It is not enough data history,
but by waiting until I downloaded data for a few initial months then I had
enough history from that point forward.  This data was free (since I had an
account) and I do trust the quality.  On the other hand, I had to string
the front month contract sequence myself and I had to do so in terms of
trading volume since they did not have open interest data available.


Best of luck,
Jorge




On Thu, Aug 13, 2015 at 3:54 PM, Samuel Wilson <samuelcoltwilson at gmail.com>
wrote:

> Before I write the code, I was wondering if anyone had already created a
> function or code for calculating constant maturity for a futures contract
> in R.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From amelia_marsh08 at yahoo.com  Sun Sep 27 20:22:34 2015
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Sun, 27 Sep 2015 18:22:34 +0000 (UTC)
Subject: [R-SIG-Finance] Excel Price function in R for Bonds
Message-ID: <1812991879.1155189.1443378154951.JavaMail.yahoo@mail.yahoo.com>

Dear Forum, 

I am using trying to find price of bond in R. I have written the code in line with Excel PRICE formula. However, whenever the residual maturity is less than a year, my R output tallies with the Excel Price formula. However, moment my residual maturity exceeds 1 year, the R output differs from Excel Price function. I have tried to find out the reason for am not able to figure out. 

Please guide me. Here is my code alongwith illustrative examples - 

(I am copying this code from notepad++. Please forgive forgive for any inconvenience caused) 


# MY code 

add.months = function(date, n) { 
nC <- seq(date, by=paste (n, "months"), length = 2)[2] 
fD <- as.Date(strftime(as.Date(date), format='%Y-%m-01')) 
C  <- (seq(fD, by=paste (n+1, "months"), length = 2)[2])-1 
if(nC>C) return(C) 
return(nC) 
} 

# ________________________________________________________________________ 

date.diff = function(end, start, basis=1) { 
if (basis != 0 && basis != 4) 
return(as.numeric(end - start)) 
e <- as.POSIXlt(end) 
s <- as.POSIXlt(start) 
d <-  (360 * (e$year - s$year)) + 
( 30 * (e$mon  - s$mon )) + 
(min(30, e$mday) - min(30, s$mday)) 
return (d) 
} 

# ________________________________________________________________________ 


excel.price = function(settlement, maturity, coupon, yield, redemption, frequency, basis=1) 
{ 
cashflows  <- 0 
last.coupon <- maturity 
while (last.coupon > settlement) { 
last.coupon <- add.months(last.coupon, -12/frequency) 
cashflows  <- cashflows + 1 
} 
next.coupon <- add.months(last.coupon, 12/frequency) 

valueA  <- date.diff(settlement,  last.coupon, basis) 
valueE  <- date.diff(next.coupon, last.coupon, basis) 
valueDSC <- date.diff(next.coupon, settlement,  basis) 

if (cashflows == 0) 
stop('number of coupons payable cannot be zero')else 
if (cashflows == 1) 
{ 
valueDSR = valueE - valueA 
T1 = 100 * coupon / frequency + redemption 
T2 = (yield/frequency * valueDSR/valueE) + 1 
T3 = 100 * coupon / frequency * valueA / valueE 
result = (T1 / T2) - T3 
return(result = result) 
}else 
if (cashflows > 1) 
{ 
expr1    <- 1 + (yield/frequency) 
expr2    <- valueDSC / valueE 
expr3    <- coupon / frequency 
result  <- redemption / (expr1 ^ (cashflows - 1 + expr2)) 
for (k in 1:cashflows) { 
result <- result + ( 100 * expr3 / (expr1 ^ (k - 1 + expr2)) ) 
} 
result  <- result - ( 100*expr3 * valueA / valueE ) 
return(result = result) 
} 
} 


# ________________________________________________________________________ 


(ep1 = excel.price(settlement = as.Date(c("09/15/24"), "%m/%y/%d"), maturity = as.Date(c("11/15/4"), "%m/%y/%d"), coupon = 0.065, yield = 0.05904166667, redemption = 100, frequency = 2, basis = 1)) 

(ep2 = excel.price(settlement = as.Date(c("09/15/24"), "%m/%y/%d"), maturity = as.Date(c("7/16/22"), "%m/%y/%d"), coupon = 0.0725, yield = 0.0969747125, redemption = 100, frequency = 2, basis = 1)) 

(ep3 = excel.price(settlement = as.Date(c("09/15/24"), "%m/%y/%d"), maturity = as.Date(c("11/16/30"), "%m/%y/%d"), coupon = 0.08, yield = 0.0969747125, redemption = 100, frequency = 2, basis = 1)) 

# ....................................................................................................................................... 


# OUTPUT 

ep1 = 100.0494 
Excel output = 100.0494 


ep2 = 98.0815 
Excel output = 98.08149 


ep3 = 98.12432 
Excel output = 98.122795 


While ep1 and ep2 match exactly with Excel Price function values, ep3 which has maturity exceeding one year doesnt tally with Excel Price function. 



Kindly advise 

With regards 

Amelia


From paulteetor at yahoo.com  Mon Sep 28 02:44:34 2015
From: paulteetor at yahoo.com (Paul Teetor)
Date: Mon, 28 Sep 2015 00:44:34 +0000 (UTC)
Subject: [R-SIG-Finance] Recipes for simple state-space models
Message-ID: <1728492600.1624089.1443401074882.JavaMail.yahoo@mail.yahoo.com>

All:
I really like the power and flexibility of state-space models for time series analysis, and R has several excellent state-space packages. Unfortunately, I can never remember all the little details necessary to use the packages. So I put together a collection of recipes, simply for my own benefit. Now I'm wondering if others would find them useful, too.
The recipes are available on my website.
? ?http://www.quantdevel.com/public/StateSpaceModels/
The R code is available on github.
? ?https://github.com/pteetor/StateSpaceModels
The recipes are for basic models only. If there's enough interest, I can expand the material to include more sophisticated models.?The documentation is not tutorial in nature but does have pointers to useful tutorials.
Thanks in advance for any feedback. I'm at paulteetor at yahoo.com.
Paul
?Paul Teetor, Elgin, IL USAhttp://quantdevel.com/public
	[[alternative HTML version deleted]]


From markknecht at gmail.com  Mon Sep 28 03:23:01 2015
From: markknecht at gmail.com (Mark Knecht)
Date: Sun, 27 Sep 2015 18:23:01 -0700
Subject: [R-SIG-Finance] Recipes for simple state-space models
In-Reply-To: <1728492600.1624089.1443401074882.JavaMail.yahoo@mail.yahoo.com>
References: <1728492600.1624089.1443401074882.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAK2H+edDphNOS8GhnXaj3_=+ajzTsGNqxqeyua6sDy_F26ge3g@mail.gmail.com>

I'm not where I can look at your work but I am certainly interested. Thanks
in advance.

Cheers,
Mark
On Sep 27, 2015 5:44 PM, "Paul Teetor via R-SIG-Finance" <
r-sig-finance at r-project.org> wrote:

> All:
> I really like the power and flexibility of state-space models for time
> series analysis, and R has several excellent state-space packages.
> Unfortunately, I can never remember all the little details necessary to use
> the packages. So I put together a collection of recipes, simply for my own
> benefit. Now I'm wondering if others would find them useful, too.
> The recipes are available on my website.
>    http://www.quantdevel.com/public/StateSpaceModels/
> The R code is available on github.
>    https://github.com/pteetor/StateSpaceModels
> The recipes are for basic models only. If there's enough interest, I can
> expand the material to include more sophisticated models. The documentation
> is not tutorial in nature but does have pointers to useful tutorials.
> Thanks in advance for any feedback. I'm at paulteetor at yahoo.com.
> Paul
>  Paul Teetor, Elgin, IL USAhttp://quantdevel.com/public
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.

	[[alternative HTML version deleted]]


From shawkat.hammoudeh at yahoo.com  Mon Sep 28 04:09:03 2015
From: shawkat.hammoudeh at yahoo.com (Shawkat Hammoudeh)
Date: Mon, 28 Sep 2015 02:09:03 +0000 (UTC)
Subject: [R-SIG-Finance] Inquiry
Message-ID: <718506153.1399493.1443406143827.JavaMail.yahoo@mail.yahoo.com>

I am looking for data on GDP or income at the state level for teh United States.
How can I display this inquiry at your site?
Best,?Shawkat Hammoudeh, Ph.D.Associate Editor, Energy Economics
Associate Editor, Global Review of Business and EconomicsAssociate Editor, Brazilian Journal of Business Economics
Associate Editor, Global Review of Business and Economics ResearchGuest-Editor, International Review of Economics and FinanceGuest-editor, North American Journal of Economics and FinanceProfessor of Economics and International Business
College of Business, 
Drexel University Philadelphia, PA 19104
Tel : 610-949-0133 Fax : 215-895-6975
http://www.lebow.drexel.edu/hammoudeh
http://blogs.zawya.com/shawkat.hammoudeh/
http://www.thereviewme.com/author/shawkat-hammoudeh/
http://ssrn.com/author=399139
http://authors.repec.org/menu!03d68dfe
View my research on my SSRN Author page: 
http://ssrn.com/author=399139
	[[alternative HTML version deleted]]


From ilya.kipnis at gmail.com  Mon Sep 28 23:55:09 2015
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Mon, 28 Sep 2015 17:55:09 -0400
Subject: [R-SIG-Finance] What's are some go-to packages in R/Finance for
 detecting shocks in financial time series?
Message-ID: <CA+oJuEFt_gMsuSq6GNdTzuXgwpkoUj=3OYSWEOLothrHiuf0YQ@mail.gmail.com>

So, I'm back to researching trading strategies on volatility. However, as
the mailing list knows, volatility ETFs are characterized by price shocks
more often than not, causing rapid drawdowns. One example would be, say,
the closing price of XIV from late April to mid-May in 2010, late 2011, the
SPY correction in 2011, or the more recent one last month during the China
meltdown.

Does anyone have any R package that they can recommend for detecting such
quick corrections in a systematic manner?

Thanks a lot.

-Ilya

	[[alternative HTML version deleted]]


From armstrong.whit at gmail.com  Tue Sep 29 00:38:15 2015
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Mon, 28 Sep 2015 18:38:15 -0400
Subject: [R-SIG-Finance] What's are some go-to packages in R/Finance for
 detecting shocks in financial time series?
In-Reply-To: <CA+oJuEFt_gMsuSq6GNdTzuXgwpkoUj=3OYSWEOLothrHiuf0YQ@mail.gmail.com>
References: <CA+oJuEFt_gMsuSq6GNdTzuXgwpkoUj=3OYSWEOLothrHiuf0YQ@mail.gmail.com>
Message-ID: <CAMi=pg4kMvFVpev7R+RpUB2hMgAaoXnHb9EgQxp0q3-c3UeUiQ@mail.gmail.com>

Not a package, but have a look at this paper.

Skulls, Financial Turbulence, and Risk Management
Mark Kritzman
Windham Capital Management

http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1691756


On Mon, Sep 28, 2015 at 5:55 PM, Ilya Kipnis <ilya.kipnis at gmail.com> wrote:

> So, I'm back to researching trading strategies on volatility. However, as
> the mailing list knows, volatility ETFs are characterized by price shocks
> more often than not, causing rapid drawdowns. One example would be, say,
> the closing price of XIV from late April to mid-May in 2010, late 2011, the
> SPY correction in 2011, or the more recent one last month during the China
> meltdown.
>
> Does anyone have any R package that they can recommend for detecting such
> quick corrections in a systematic manner?
>
> Thanks a lot.
>
> -Ilya
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From alexzemnitskiy at gmail.com  Tue Sep 29 01:24:47 2015
From: alexzemnitskiy at gmail.com (Alexey Zemnitskiy)
Date: Mon, 28 Sep 2015 19:24:47 -0400
Subject: [R-SIG-Finance] What's are some go-to packages in R/Finance for
 detecting shocks in financial time series?
In-Reply-To: <CA+oJuEFt_gMsuSq6GNdTzuXgwpkoUj=3OYSWEOLothrHiuf0YQ@mail.gmail.com>
References: <CA+oJuEFt_gMsuSq6GNdTzuXgwpkoUj=3OYSWEOLothrHiuf0YQ@mail.gmail.com>
Message-ID: <CADY2e71dtaa=mnkY5vYOO_GT4_FdV=cprSQoDZRS6ZTT4FxYCA@mail.gmail.com>

Hi Ilya,

If your focus is on intraday price shocks - you could check out our
PortfolioEffectHFT package.

Right now it's available at:
https://www.portfolioeffect.com/docs/platform/quant/downloads
It would also be available on CRAN shortly under BSD license - we are doing
second round of submission corrections.

The setting you might be interested is
https://www.portfolioeffect.com/docs/platform/quant/manuals/portfolio-settings/model-pipeline#jumps_model

It is using a combination of several jump detection methods (quantile,
wavelet-based, etc.).
For intraday volatility estimators see portfolio_variance
<https://www.portfolioeffect.com/docs/platform/quant/functions/absolute-risk-measures/portfolio-variance>
& position_
<https://www.portfolioeffect.com/docs/platform/quant/functions/absolute-risk-measures/position-variance>
variance
<https://www.portfolioeffect.com/docs/platform/quant/functions/absolute-risk-measures/position-variance>
methods.

PortfolioEffect service is free to use with your own pricing data.
There is optional access to HF market data history for 8000+ US equities
since 2013 if you need that.

Best,

Alex


2015-09-28 17:55 GMT-04:00 Ilya Kipnis <ilya.kipnis at gmail.com>:

> So, I'm back to researching trading strategies on volatility. However, as
> the mailing list knows, volatility ETFs are characterized by price shocks
> more often than not, causing rapid drawdowns. One example would be, say,
> the closing price of XIV from late April to mid-May in 2010, late 2011, the
> SPY correction in 2011, or the more recent one last month during the China
> meltdown.
>
> Does anyone have any R package that they can recommend for detecting such
> quick corrections in a systematic manner?
>
> Thanks a lot.
>
> -Ilya
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From ilya.kipnis at gmail.com  Tue Sep 29 01:26:57 2015
From: ilya.kipnis at gmail.com (Ilya Kipnis)
Date: Mon, 28 Sep 2015 19:26:57 -0400
Subject: [R-SIG-Finance] What's are some go-to packages in R/Finance for
 detecting shocks in financial time series?
In-Reply-To: <CADY2e71dtaa=mnkY5vYOO_GT4_FdV=cprSQoDZRS6ZTT4FxYCA@mail.gmail.com>
References: <CA+oJuEFt_gMsuSq6GNdTzuXgwpkoUj=3OYSWEOLothrHiuf0YQ@mail.gmail.com>
	<CADY2e71dtaa=mnkY5vYOO_GT4_FdV=cprSQoDZRS6ZTT4FxYCA@mail.gmail.com>
Message-ID: <CA+oJuEFzD-xUGy-47ik_QcfJy6woY0rsV8B6im-K2C+3U6Scog@mail.gmail.com>

Alexey,

As someone who works independently, unfortunately I don't have access to
intraday data at all. Does that work with daily-frequency data, like the
kind I use on my blog?

-Ilya

On Mon, Sep 28, 2015 at 7:24 PM, Alexey Zemnitskiy <alexzemnitskiy at gmail.com
> wrote:

> Hi Ilya,
>
> If your focus is on intraday price shocks - you could check out our
> PortfolioEffectHFT package.
>
> Right now it's available at:
> https://www.portfolioeffect.com/docs/platform/quant/downloads
> It would also be available on CRAN shortly under BSD license - we are
> doing second round of submission corrections.
>
> The setting you might be interested is
>
> https://www.portfolioeffect.com/docs/platform/quant/manuals/portfolio-settings/model-pipeline#jumps_model
>
> It is using a combination of several jump detection methods (quantile,
> wavelet-based, etc.).
> For intraday volatility estimators see portfolio_variance
> <https://www.portfolioeffect.com/docs/platform/quant/functions/absolute-risk-measures/portfolio-variance>
> & position_
> <https://www.portfolioeffect.com/docs/platform/quant/functions/absolute-risk-measures/position-variance>
> variance
> <https://www.portfolioeffect.com/docs/platform/quant/functions/absolute-risk-measures/position-variance>
> methods.
>
> PortfolioEffect service is free to use with your own pricing data.
> There is optional access to HF market data history for 8000+ US equities
> since 2013 if you need that.
>
> Best,
>
> Alex
>
>
> 2015-09-28 17:55 GMT-04:00 Ilya Kipnis <ilya.kipnis at gmail.com>:
>
>> So, I'm back to researching trading strategies on volatility. However, as
>> the mailing list knows, volatility ETFs are characterized by price shocks
>> more often than not, causing rapid drawdowns. One example would be, say,
>> the closing price of XIV from late April to mid-May in 2010, late 2011,
>> the
>> SPY correction in 2011, or the more recent one last month during the China
>> meltdown.
>>
>> Does anyone have any R package that they can recommend for detecting such
>> quick corrections in a systematic manner?
>>
>> Thanks a lot.
>>
>> -Ilya
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R questions
>> should go.
>>
>
>

	[[alternative HTML version deleted]]


From alexzemnitskiy at gmail.com  Tue Sep 29 02:16:02 2015
From: alexzemnitskiy at gmail.com (Alexey Zemnitskiy)
Date: Mon, 28 Sep 2015 20:16:02 -0400
Subject: [R-SIG-Finance] What's are some go-to packages in R/Finance for
 detecting shocks in financial time series?
In-Reply-To: <CA+oJuEFzD-xUGy-47ik_QcfJy6woY0rsV8B6im-K2C+3U6Scog@mail.gmail.com>
References: <CA+oJuEFt_gMsuSq6GNdTzuXgwpkoUj=3OYSWEOLothrHiuf0YQ@mail.gmail.com>
	<CADY2e71dtaa=mnkY5vYOO_GT4_FdV=cprSQoDZRS6ZTT4FxYCA@mail.gmail.com>
	<CA+oJuEFzD-xUGy-47ik_QcfJy6woY0rsV8B6im-K2C+3U6Scog@mail.gmail.com>
Message-ID: <CADY2e738YVYe-ozZGBwwQn994uRn2xJkKUma4vqpxmvkAVc11Q@mail.gmail.com>

It should, we tested the package for illiquid stocks with 1-2 trades a day.

The models would require sufficient warm-up period. Since this is not a HF
dataset, I would also suggest switching off market microstructure noise
detection
<https://www.portfolioeffect.com/docs/platform/quant/manuals/portfolio-settings/model-pipeline#noise_model>
-  the estimated HF noise at EOD frequency is close to zero for liquid
stocks anyway.

If you want to give intraday data a try -  SPY, GOOG & C sample history is
available through the package.

Best,

Alex



2015-09-28 19:26 GMT-04:00 Ilya Kipnis <ilya.kipnis at gmail.com>:

> Alexey,
>
> As someone who works independently, unfortunately I don't have access to
> intraday data at all. Does that work with daily-frequency data, like the
> kind I use on my blog?
>
> -Ilya
>
> On Mon, Sep 28, 2015 at 7:24 PM, Alexey Zemnitskiy <
> alexzemnitskiy at gmail.com> wrote:
>
>> Hi Ilya,
>>
>> If your focus is on intraday price shocks - you could check out our
>> PortfolioEffectHFT package.
>>
>> Right now it's available at:
>> https://www.portfolioeffect.com/docs/platform/quant/downloads
>> It would also be available on CRAN shortly under BSD license - we are
>> doing second round of submission corrections.
>>
>> The setting you might be interested is
>>
>> https://www.portfolioeffect.com/docs/platform/quant/manuals/portfolio-settings/model-pipeline#jumps_model
>>
>> It is using a combination of several jump detection methods (quantile,
>> wavelet-based, etc.).
>> For intraday volatility estimators see portfolio_variance
>> <https://www.portfolioeffect.com/docs/platform/quant/functions/absolute-risk-measures/portfolio-variance>
>> & position_
>> <https://www.portfolioeffect.com/docs/platform/quant/functions/absolute-risk-measures/position-variance>
>> variance
>> <https://www.portfolioeffect.com/docs/platform/quant/functions/absolute-risk-measures/position-variance>
>> methods.
>>
>> PortfolioEffect service is free to use with your own pricing data.
>> There is optional access to HF market data history for 8000+ US equities
>> since 2013 if you need that.
>>
>> Best,
>>
>> Alex
>>
>>
>> 2015-09-28 17:55 GMT-04:00 Ilya Kipnis <ilya.kipnis at gmail.com>:
>>
>>> So, I'm back to researching trading strategies on volatility. However, as
>>> the mailing list knows, volatility ETFs are characterized by price shocks
>>> more often than not, causing rapid drawdowns. One example would be, say,
>>> the closing price of XIV from late April to mid-May in 2010, late 2011,
>>> the
>>> SPY correction in 2011, or the more recent one last month during the
>>> China
>>> meltdown.
>>>
>>> Does anyone have any R package that they can recommend for detecting such
>>> quick corrections in a systematic manner?
>>>
>>> Thanks a lot.
>>>
>>> -Ilya
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-SIG-Finance at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>>> -- Subscriber-posting only. If you want to post, subscribe first.
>>> -- Also note that this is not the r-help list where general R questions
>>> should go.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From alexandre.shannon at gmail.com  Tue Sep 29 14:27:34 2015
From: alexandre.shannon at gmail.com (Alexandre Shannon)
Date: Tue, 29 Sep 2015 12:27:34 +0000
Subject: [R-SIG-Finance] Failure of solve.QP in portfolio modeling
In-Reply-To: <5601B402.5040501@burns-stat.com>
References: <27b87cf04149ec20a56aa7438aafe246@stevens.edu>
	<5601A518.5040601@burns-stat.com> <5601B402.5040501@burns-stat.com>
Message-ID: <CACbfdePf4q5XiW+jYh7T=mGRGVZT8H_ySbpQywFubT7hDr9Atw@mail.gmail.com>

Hello Alec

Package "corpcor" has a useful function called "make.positive.definite",
which might help in your particular case.

Alex
On Tue, Sep 22, 2015 at 16:03 Patrick Burns <patrick at burns-stat.com> wrote:

> One correction and another comment.
>
> I should have said that a trade optimizer
> not caring about positive definiteness is
> usually a bad thing -- it has its uses
> but giving the optimizer a shot at a
> portfolio with negative variance is asking
> for trouble (because it will do its best
> to get there).
>
> The estimates of the variance with only a
> few observations are going to be extremely
> noisy.  I think the length of history to
> be used to estimate the variance should
> depend on what length gives the best variance
> estimate and should be independent of the
> rebalancing schedule.  (Though perhaps I
> have misinterpreted the original post.)
>
> Pat
>
> On 22/09/2015 19:59, Patrick Burns wrote:
> > You can use a factor model or shrinkage
> > to get a positive definite variance matrix.
> > There is a function for each in the
> > BurStFin package on CRAN.
> >
> > The optimizer in Portfolio Probe doesn't
> > care about positive definiteness (though
> > that is not always a good thing).  It is
> > free for academic use.
> >
> > Pat
> >
> > On 22/09/2015 14:37, aschmid1 wrote:
> >> Hi everyone,
> >> I'm trying to estimate optimal Markowitz portfolio weights for a list of
> >> stocks chosen upon some criterion using solve.QP from quadprog library.
> >> When the number of stocks N reaches some limit, I get a message "matrix
> >> D in quadratic function is not positive definite." For example, if I
> >> rebalance every 6 weeks (which implies that variance is calculated for
> >> 6-week interval prior to the period for which I calculate portfolio
> >> weights), I can get solution for 25>=N<50. For 12-week interval,
> >> solution exists for 50>=N<100, and for 24-week interval, I can get
> >> solution for N=100. My attempt to remedy this problem with Higham's
> >> method doesn't help. I'll greatly appreciate you input: first, why this
> >> may happen (can there be lack of local minimum?), and second, whether
> >> there are R solvers that may need only semi positive definite matrix.
> >>
> >> Thanks! Alec
> >>
> >> _______________________________________________
> >> R-SIG-Finance at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> >> -- Subscriber-posting only. If you want to post, subscribe first.
> >> -- Also note that this is not the r-help list where general R questions
> >> should go.
> >
>
> --
> Patrick Burns
> patrick at burns-stat.com
> http://www.burns-stat.com
> http://www.portfolioprobe.com/blog
> twitter: @burnsstat @portfolioprobe
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From oleg.mubarakshin at gmail.com  Tue Sep 29 15:25:26 2015
From: oleg.mubarakshin at gmail.com (Oleg Mubarakshin)
Date: Tue, 29 Sep 2015 16:25:26 +0300
Subject: [R-SIG-Finance] What's are some go-to packages in R/Finance for
	detecting shocks in financial time series?
In-Reply-To: <CA+oJuEFt_gMsuSq6GNdTzuXgwpkoUj=3OYSWEOLothrHiuf0YQ@mail.gmail.com>
References: <CA+oJuEFt_gMsuSq6GNdTzuXgwpkoUj=3OYSWEOLothrHiuf0YQ@mail.gmail.com>
Message-ID: <ACCA1C10F2CC4B9FBAE4ED60725E4430@OLEHP>

Ilya,

equity assets (shares, indices, ETF, etc) have negative volatility 
correlation (skew in options) - volatility increases when price of asset go 
down, and vola decreases when price rises.

a quant trader can trade options (implied) vola level and skew VS  realized 
(historical) vola. it is matter of options trading only.

another way to trade volatility, I think (don't trade), it is spread or 
basket trading. in this case vol is a param to fill/dump trading position 
(portfolio, volume)

I have Bloomberg terminal and can help you with market data if you want

Best,
Oleg Mubarakshin

-----???????? ?????????----- 
From: Ilya Kipnis
Sent: Tuesday, September 29, 2015 12:55 AM
To: r-sig-finance at r-project.org
Subject: [R-SIG-Finance] What's are some go-to packages in R/Finance for 
detecting shocks in financial time series?

So, I'm back to researching trading strategies on volatility. However, as
the mailing list knows, volatility ETFs are characterized by price shocks
more often than not, causing rapid drawdowns. One example would be, say,
the closing price of XIV from late April to mid-May in 2010, late 2011, the
SPY correction in 2011, or the more recent one last month during the China
meltdown.

Does anyone have any R package that they can recommend for detecting such
quick corrections in a systematic manner?

Thanks a lot.

-Ilya

[[alternative HTML version deleted]]

_______________________________________________
R-SIG-Finance at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-finance
-- Subscriber-posting only. If you want to post, subscribe first.
-- Also note that this is not the r-help list where general R questions 
should go.


From edd at debian.org  Tue Sep 29 15:53:45 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 29 Sep 2015 08:53:45 -0500
Subject: [R-SIG-Finance] What's are some go-to packages in R/Finance
	for	detecting shocks in financial time series?
In-Reply-To: <ACCA1C10F2CC4B9FBAE4ED60725E4430@OLEHP>
References: <CA+oJuEFt_gMsuSq6GNdTzuXgwpkoUj=3OYSWEOLothrHiuf0YQ@mail.gmail.com>
	<ACCA1C10F2CC4B9FBAE4ED60725E4430@OLEHP>
Message-ID: <22026.38889.54281.431148@max.nulle.part>


On 29 September 2015 at 16:25, Oleg Mubarakshin wrote:
| I have Bloomberg terminal and can help you with market data if you want

Check your Bloomberg licensing terms. I don't think you want to do that.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From oleg.mubarakshin at gmail.com  Tue Sep 29 16:28:57 2015
From: oleg.mubarakshin at gmail.com (Oleg Mubarakshin)
Date: Tue, 29 Sep 2015 17:28:57 +0300
Subject: [R-SIG-Finance] What's are some go-to packages in R/Finance
	fordetecting shocks in financial time series?
In-Reply-To: <22026.38889.54281.431148@max.nulle.part>
References: <CA+oJuEFt_gMsuSq6GNdTzuXgwpkoUj=3OYSWEOLothrHiuf0YQ@mail.gmail.com><ACCA1C10F2CC4B9FBAE4ED60725E4430@OLEHP>
	<22026.38889.54281.431148@max.nulle.part>
Message-ID: <1987862A9B3D41AEAE2BD580221DA872@OLEHP>

That's my fault. I can't share Bloomberg's data
I have the Russian market data (it is not from Bloomberg), Russian ruble for 
example.
http://postimg.org/image/fqj4psk59/
Quite volatile FX pair USD/RUB - ATM vola of December option series - 23%, 
with positive skew (correlation). Interesting and risky instrument.

Oleg

-----???????? ?????????----- 
From: Dirk Eddelbuettel
Sent: Tuesday, September 29, 2015 4:53 PM
To: Oleg Mubarakshin
Cc: Kipnis Ilya ; r-sig-finance
Subject: Re: [R-SIG-Finance] What's are some go-to packages in R/Finance 
fordetecting shocks in financial time series?


On 29 September 2015 at 16:25, Oleg Mubarakshin wrote:
| I have Bloomberg terminal and can help you with market data if you want

Check your Bloomberg licensing terms. I don't think you want to do that.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From aschmid1 at stevens.edu  Tue Sep 29 16:39:22 2015
From: aschmid1 at stevens.edu (aschmid1)
Date: Tue, 29 Sep 2015 10:39:22 -0400
Subject: [R-SIG-Finance] merging tseries with a table
Message-ID: <3fa8f13cefd098037c0f9be0a8c53113@stevens.edu>

I'm trying to merge prices obtained with get.hist.quote():
> head(mkt_prc)
            AdjClose
2009-01-02 36.21114
2009-01-05 36.04547
2009-01-06 36.42040
2009-01-07 35.34793
2009-01-08 35.40897
2009-01-09 34.67655

with data from a csv table:
> head(gdp_tab)
        Date Actual
1 1/31/2001    1.4
2 2/28/2001    1.1
3 3/29/2001    1.0
4 4/27/2001    2.0
5 5/25/2001    1.3
6 6/29/2001    1.2

I use command (as far as my imagination goes):
  x<-merge(gdp_tab, mkt_prc, by.x="Date", by.y=index(mkt_prc))

and it gives me an error:
Error in fix.by(by.y, y) : 'by' must match numbers of columns

Any suggestions on how to do this?
Thanks! Alec


From eliano.m.marques at gmail.com  Tue Sep 29 16:40:39 2015
From: eliano.m.marques at gmail.com (Eliano Marques)
Date: Tue, 29 Sep 2015 15:40:39 +0100
Subject: [R-SIG-Finance] rugarch n.ahead forecasts
Message-ID: <E8EEA06F-833D-440E-AC6C-3DDC6022D4AD@gmail.com>

Community,

I have a quick question that perhaps is easy to solve regarding n.ahead forecasts. 

So for example:

variance_model = list(model = "sGARCH", garchOrder = c(1, 1), 
                      submodel = NULL, 
                      external.regressors = NULL,#as.matrix(Regressors), #External Regressors will include the news and tweets and market returns
                      variance.targeting = FALSE)
mean_model = list(armaOrder = c(1,0), include.mean = TRUE, archm = FALSE, 
                  archpow = 1, arfima = FALSE, 
                  external.regressors = as.matrix(Regressors), 
                  archex = FALSE)
distribution_model = "norm"
spec = ugarchspec(mean.model = mean_model, variance.model = variance_model, distribution = distribution_model)
fit2 = ugarchfit(data = Returns, solver = "gosolnp", spec = spec,out.sample = 66 , DailyVar = f_sigma^2,
                 solver.control=list(n.restarts=5))

Say now I want to forecast ahead the next two days (66 - intraday data):

forc = ugarchforecast(fit2, n.ahead = 66, n.roll = 0) # Forecasting function

After researching in the documentation and other posts I just have a few doubts:

1 - Because the fit function has a out.sample that = n.ahead forecasts do I still need to provide the list of external regressors inside the forecast function? 

2 - The >2 n.ahead forecast are calculated using the previous forecast of the mean and variance equation? I?m assuming yes given what is written in the documentation but better to confirm. 


Thank you for your help,
Eliano

From brian at braverock.com  Tue Sep 29 16:58:14 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 29 Sep 2015 09:58:14 -0500
Subject: [R-SIG-Finance] merging tseries with a table
In-Reply-To: <3fa8f13cefd098037c0f9be0a8c53113@stevens.edu>
References: <3fa8f13cefd098037c0f9be0a8c53113@stevens.edu>
Message-ID: <1443538694.4432.26.camel@brian-rcg>

On Tue, 2015-09-29 at 10:39 -0400, aschmid1 wrote:
> I'm trying to merge prices obtained with get.hist.quote():
> > head(mkt_prc)
>             AdjClose
> 2009-01-02 36.21114
> 2009-01-05 36.04547
> 2009-01-06 36.42040
> 2009-01-07 35.34793
> 2009-01-08 35.40897
> 2009-01-09 34.67655
> 
> with data from a csv table:
> > head(gdp_tab)
>         Date Actual
> 1 1/31/2001    1.4
> 2 2/28/2001    1.1
> 3 3/29/2001    1.0
> 4 4/27/2001    2.0
> 5 5/25/2001    1.3
> 6 6/29/2001    1.2
> 
> I use command (as far as my imagination goes):
>   x<-merge(gdp_tab, mkt_prc, by.x="Date", by.y=index(mkt_prc))
> 
> and it gives me an error:
> Error in fix.by(by.y, y) : 'by' must match numbers of columns
> 
> Any suggestions on how to do this?

Yes, use xts, getSymbols rather than get.hist.quote, and rbind.


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From josh.m.ulrich at gmail.com  Tue Sep 29 17:07:20 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 29 Sep 2015 10:07:20 -0500
Subject: [R-SIG-Finance] merging tseries with a table
In-Reply-To: <3fa8f13cefd098037c0f9be0a8c53113@stevens.edu>
References: <3fa8f13cefd098037c0f9be0a8c53113@stevens.edu>
Message-ID: <CAPPM_gTfiF_LEnUSEw4cQrPcPK63bVW-6-yA3rZiBWCOVYnKpA@mail.gmail.com>

On Tue, Sep 29, 2015 at 9:39 AM, aschmid1 <aschmid1 at stevens.edu> wrote:
> I'm trying to merge prices obtained with get.hist.quote():
>>
>> head(mkt_prc)
>
>            AdjClose
> 2009-01-02 36.21114
> 2009-01-05 36.04547
> 2009-01-06 36.42040
> 2009-01-07 35.34793
> 2009-01-08 35.40897
> 2009-01-09 34.67655
>
> with data from a csv table:
>>
>> head(gdp_tab)
>
>        Date Actual
> 1 1/31/2001    1.4
> 2 2/28/2001    1.1
> 3 3/29/2001    1.0
> 4 4/27/2001    2.0
> 5 5/25/2001    1.3
> 6 6/29/2001    1.2
>
> I use command (as far as my imagination goes):
>  x<-merge(gdp_tab, mkt_prc, by.x="Date", by.y=index(mkt_prc))
>
> and it gives me an error:
> Error in fix.by(by.y, y) : 'by' must match numbers of columns
>
> Any suggestions on how to do this?

Convert gdp_tab to zoo before you merge.

gdp_tab <- read.table(text="Date Actual
1/31/2001 1.4
2/28/2001 1.1
3/29/2001 1.0
4/27/2001 2.0
5/25/2001 1.3
6/29/2001 1.2", header=TRUE, as.is=TRUE)
library(zoo)
z <- zoo(gdp_tab$Actual, as.Date(gdp_tab$Date, "%m/%d/%Y"))
mkt_prc <- tseries::get.hist.quote("SPY")
x <- merge(mkt_prc, z)

> Thanks! Alec
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From aschmid1 at stevens.edu  Tue Sep 29 18:08:42 2015
From: aschmid1 at stevens.edu (aschmid1)
Date: Tue, 29 Sep 2015 12:08:42 -0400
Subject: [R-SIG-Finance] merging tseries with a table
In-Reply-To: <CAPPM_gTfiF_LEnUSEw4cQrPcPK63bVW-6-yA3rZiBWCOVYnKpA@mail.gmail.com>
References: <3fa8f13cefd098037c0f9be0a8c53113@stevens.edu>
	<CAPPM_gTfiF_LEnUSEw4cQrPcPK63bVW-6-yA3rZiBWCOVYnKpA@mail.gmail.com>
Message-ID: <1c70fa2497790b43218cb0046e9ecaf5@stevens.edu>

Thank you Joshua, this worked well.
And I agree with Brian Peterson: it's time to use quantmod - if only I 
had enough time for that... :)
Alec

On 09/29/2015 11:07 AM, Joshua Ulrich wrote:
> On Tue, Sep 29, 2015 at 9:39 AM, aschmid1 <aschmid1 at stevens.edu> wrote:
>> I'm trying to merge prices obtained with get.hist.quote():
>>> 
>>> head(mkt_prc)
>> 
>>            AdjClose
>> 2009-01-02 36.21114
>> 2009-01-05 36.04547
>> 2009-01-06 36.42040
>> 2009-01-07 35.34793
>> 2009-01-08 35.40897
>> 2009-01-09 34.67655
>> 
>> with data from a csv table:
>>> 
>>> head(gdp_tab)
>> 
>>        Date Actual
>> 1 1/31/2001    1.4
>> 2 2/28/2001    1.1
>> 3 3/29/2001    1.0
>> 4 4/27/2001    2.0
>> 5 5/25/2001    1.3
>> 6 6/29/2001    1.2
>> 
>> I use command (as far as my imagination goes):
>>  x<-merge(gdp_tab, mkt_prc, by.x="Date", by.y=index(mkt_prc))
>> 
>> and it gives me an error:
>> Error in fix.by(by.y, y) : 'by' must match numbers of columns
>> 
>> Any suggestions on how to do this?
> 
> Convert gdp_tab to zoo before you merge.
> 
> gdp_tab <- read.table(text="Date Actual
> 1/31/2001 1.4
> 2/28/2001 1.1
> 3/29/2001 1.0
> 4/27/2001 2.0
> 5/25/2001 1.3
> 6/29/2001 1.2", header=TRUE, as.is=TRUE)
> library(zoo)
> z <- zoo(gdp_tab$Actual, as.Date(gdp_tab$Date, "%m/%d/%Y"))
> mkt_prc <- tseries::get.hist.quote("SPY")
> x <- merge(mkt_prc, z)
> 
>> Thanks! Alec
>> 
>> _______________________________________________
>> R-SIG-Finance at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
>> -- Subscriber-posting only. If you want to post, subscribe first.
>> -- Also note that this is not the r-help list where general R 
>> questions
>> should go.


From tstoyc at gmail.com  Tue Sep 29 18:46:06 2015
From: tstoyc at gmail.com (Tsvetan Stoyanov)
Date: Tue, 29 Sep 2015 09:46:06 -0700
Subject: [R-SIG-Finance] A simple variant of Luxor strategy with Dukascopy
	data
Message-ID: <81BDBBF5-FCA1-43DF-BC46-3A6340A74102@gmail.com>

Hi,

I am trying to replicate Table 3.1 in Jaekle&Tomasini using quantstrat and Dukascopy data.
While I have similar percentage of winning trades, net profit and drawdown are quite different.
For example, they have P&L of ~$66,000 while i get ~$19,500 for a period from 2003-05-04 to 2008-07-06
which is half a year shorter than their period.

It should not make such a difference I think, unless they used substantially different data. 

The trade stats quantstrat code are included bellow, where I have set .threshold = 0.0001,  
to reduce slippage and set .txnfees = 0.

I am new to quantstrat and will appreciate some help in reconciling this difference.

Thanks,
Tsvetan

> t(tradeStats(portfolio.st, 'GBPUSD'))
                  GBPUSD        
Portfolio          "luxor.simple"
Symbol             "GBPUSD"      
Num.Txns           "4080"        
Num.Trades         "2038"        
Net.Trading.PL     "19486"       
Avg.Trade.PL       "9.561335"    
Med.Trade.PL       "-144.5"      
Largest.Winner     "4018"        
Largest.Loser      "-2002"       
Gross.Profits      "548109"      
Gross.Losses       "-528623"     
Std.Dev.Trade.PL   "753.0498"    
Percent.Positive   "37.43867"    
Percent.Negative   "62.56133"    
Profit.Factor      "1.036862"    
Avg.Win.Trade      "718.3604"    
Med.Win.Trade      "492.5"       
Avg.Losing.Trade   "-414.6063"   
Med.Losing.Trade   "-334"        
Avg.Daily.PL       "15.97213"    
Med.Daily.PL       "-113.5"      
Std.Dev.Daily.PL   "941.3955"    
Ann.Sharpe         "0.2693339"   
Max.Drawdown       "-20481"      
Profit.To.Max.Draw "0.9514184"   
Avg.WinLoss.Ratio  "1.732633"    
Med.WinLoss.Ratio  "1.474551"    
Max.Equity         "29675.5"     
Min.Equity         "-11539"      
End.Equity         "19486? 


????? luxor.simple.R --------------------

Sys.setenv(TZ="UTC")
library(quantstrat)

## ------------------------------------------------------------------------
initDate = '2003-05-04'
.from=initDate
##.to='2003-05-18' # 2 weeks
##.to='2003-07-27' # 12 weeks
##.to='2004-05-02' # 52 weeks
.to='2008-07-06' # 5 years

source('load.gbpusd.R') # load GBPUSD data

## setup 
currency(c('GBP', 'USD'))
exchange_rate('GBPUSD', tick_size=0.0001)

## moving average lengths
.fast = 10
.slow = 30

# trade parameters
.threshold = 0.0001
.orderqty = 100000
.txnfees = 0  # round-trip fee

## 
strategy.st = 'luxor.simple'
portfolio.st = strategy.st
account.st = strategy.st

## ------------------------------------------------------------------------
rm.strat(portfolio.st)
rm.strat(account.st)

## ----results='hide'------------------------------------------------------
initPortf(portfolio.st, symbols='GBPUSD', initDate=initDate, currency='USD')
initAcct(account.st, portfolios=portfolio.st,initDate=initDate,currency='USD')
initOrders(portfolio.st, initDate=initDate)
strategy(strategy.st, store=TRUE)


## ----results='hide'------------------------------------------------------
add.indicator(strategy.st, name = "SMA",
	arguments = list(
		x = quote(Cl(mktdata)[,1]),
		n = .fast
	),
	label="nFast"
)

## ----results='hide'------------------------------------------------------
add.indicator(strategy.st, name="SMA",
	arguments = list(
		x = quote(Cl(mktdata)[,1]),
		n = .slow
	),
	label="nSlow"
)


## ----results='hide'------------------------------------------------------
add.signal(strategy.st, name='sigCrossover',
	arguments = list(
		columns=c("nFast","nSlow"),
		relationship="gte"
	),
	label='long'
)

## ----results='hide'------------------------------------------------------
add.signal(strategy.st, name='sigCrossover',
	arguments = list(
		columns=c("nFast","nSlow"),
		relationship="lt"
	),
	label='short'
)


## ----results='hide'------------------------------------------------------
add.rule(strategy.st, name='ruleSignal',
   arguments=list(sigcol='long' , sigval=TRUE,
       orderside='long' ,
       ordertype='stoplimit',
       prefer='High',
       threshold=.threshold,
       orderqty=+.orderqty,
       replace=FALSE
       ),
   type='enter',
   label='EnterLONG'
)


## ----results='hide'------------------------------------------------------
add.rule(strategy.st, name='ruleSignal',
   arguments=list(sigcol='short', sigval=TRUE,
       orderside='short',
       ordertype='stoplimit',
       prefer='Low',
       threshold=-.threshold,
       orderqty=-.orderqty,
       replace=FALSE
       ),
   type='enter',
   label='EnterSHORT'
)


## ----results='hide'------------------------------------------------------
add.rule(strategy.st, name='ruleSignal',
	arguments=list(sigcol='short', sigval=TRUE,
		orderside='long' ,
		ordertype='market',
		orderqty='all',
		TxnFees=.txnfees,
		replace=TRUE
	),
	type='exit',
	label='Exit2SHORT'
)


## ----results='hide'------------------------------------------------------
add.rule(strategy.st, name='ruleSignal',
	arguments=list(sigcol='long' , sigval=TRUE,
		orderside='short',
		ordertype='market',
		orderqty='all',
		TxnFees=.txnfees,
		replace=TRUE
	),
	type='exit',
	label='Exit2LONG'
)


## ----results='hide'------------------------------------------------------
out <- applyStrategy(strategy.st, portfolio.st)

updatePortf(portfolio.st, Symbols='GBPUSD')
updateAcct(account.st) #,Dates=period.st)
updateEndEq(account.st) #,Dates=period.st)

View(t(tradeStats(portfolio.st, 'GBPUSD')))

From brian at braverock.com  Tue Sep 29 19:17:19 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Tue, 29 Sep 2015 12:17:19 -0500
Subject: [R-SIG-Finance] A simple variant of Luxor strategy with
 Dukascopy data
In-Reply-To: <81BDBBF5-FCA1-43DF-BC46-3A6340A74102@gmail.com>
References: <81BDBBF5-FCA1-43DF-BC46-3A6340A74102@gmail.com>
Message-ID: <1443547039.4432.30.camel@brian-rcg>

On Tue, 2015-09-29 at 09:46 -0700, Tsvetan Stoyanov wrote:
> I am trying to replicate Table 3.1 in Jaekle&Tomasini using quantstrat
> and Dukascopy data.
> While I have similar percentage of winning trades, net profit and
> drawdown are quite different.
> For example, they have P&L of ~$66,000 while i get ~$19,500 for a
> period from 2003-05-04 to 2008-07-06
> which is half a year shorter than their period.
> 
> It should not make such a difference I think, unless they used
> substantially different data. 
> 
> The trade stats quantstrat code are included bellow, where I have
> set .threshold = 0.0001,  
> to reduce slippage and set .txnfees = 0.
> 
> I am new to quantstrat and will appreciate some help in reconciling
> this difference.

The most likely difference is that the Tomasini and Jaekle data appears
to have used instant execution assumptions, which quantstrat does not.

Other people have also failed to get the same numbers as the book with
widely varying data sets, including futures, IB data, and other cash FX
sources.

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


