From andrewr at uidaho.edu  Mon Sep  1 21:33:22 2003
From: andrewr at uidaho.edu (andrewr@uidaho.edu)
Date: Mon Sep  1 20:32:43 2003
Subject: [Rd] par(new=T) works differently in pdf vs postscript if applied
	before a plot statement. (PR#4037)
Message-ID: <200309011833.h81IXMJH001142@pubhealth.ku.dk>

If I place par(new=T) before I create a plot in a script that is sent to a pdf 
device, the pdf is unopenable and reports itself as having no pages.  The 
postscript device seems to ignore the par instruction.

I guess one of these is a bug, but I don't know which one!

--please do not edit the information below--

Version:
 platform = i386-pc-linux-gnu
 arch = i386
 os = linux-gnu
 system = i386, linux-gnu
 status = 
 major = 1
 minor = 7.1
 year = 2003
 month = 06
 day = 16
 language = R

Search Path:
 .GlobalEnv, package:grid, package:lattice, package:tools, package:methods, 
package:ctest, package:mva, package:modreg, package:nls, package:ts, 
Autoloads, package:base

-- 
Andrew Robinson                      Ph: 208 885 7115
Department of Forest Resources       Fa: 208 885 6226
University of Idaho                  E : andrewr@uidaho.edu
PO Box 441133                        W : http://www.uidaho.edu/~andrewr
Moscow ID 83843                      Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.

From ripley at stats.ox.ac.uk  Mon Sep  1 20:43:09 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Sep  1 20:42:31 2003
Subject: (PR#4307) Re: [Rd] par(new=T) works differently in pdf vs postscript
	if applied before a plot statement. (PR#4037)
In-Reply-To: <200309011833.h81IXMJH001142@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0309011938510.22603-100000@gannet.stats>

Please give us an example of what you mean (as the FAQ asks).  Exactly
what order are you doing things in?

You can't send scripts to graphics devices, and you should not be calling
par(new=TRUE) without a plot already done.  So it would appear to be user
error, and it may well just be different error handling in the two
devices.  If I have guessedanything like right ....

On Mon, 1 Sep 2003 andrewr@uidaho.edu wrote:

> If I place par(new=T) before I create a plot in a script that is sent to a pdf 
> device, the pdf is unopenable and reports itself as having no pages.  The 
> postscript device seems to ignore the par instruction.
> 
> I guess one of these is a bug, but I don't know which one!

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From andrewr at uidaho.edu  Mon Sep  1 13:02:30 2003
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Mon Sep  1 20:58:49 2003
Subject: (PR#4307) Re: [Rd] par(new=T) works differently in pdf vs
	postscript if applied before a plot statement. (PR#4037)
In-Reply-To: <Pine.LNX.4.44.0309011938510.22603-100000@gannet.stats>
References: <Pine.LNX.4.44.0309011938510.22603-100000@gannet.stats>
Message-ID: <200309011202.30443.andrewr@uidaho.edu>

Certainly.

postscript("test.ps")
par(new=T)
plot(1:10,1:10)
dev.off()

Produces a postscript image that can be opened.  However 

pdf("test.pdf")
par(new=T)
plot(1:10,1:10)
dev.off()

produces a pdf that cannot be opened by Latex or xpdf.  

Andrew
-- 
Andrew Robinson                      Ph: 208 885 7115
Department of Forest Resources       Fa: 208 885 6226
University of Idaho                  E : andrewr@uidaho.edu
PO Box 441133                        W : http://www.uidaho.edu/~andrewr
Moscow ID 83843                      Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.

From ripley at stats.ox.ac.uk  Mon Sep  1 21:15:43 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Sep  1 21:15:10 2003
Subject: (PR#4307) Re: [Rd] par(new=T) works differently in pdf vs
	postscript if applied before a plot statement. (PR#4037)
In-Reply-To: <200309011202.30443.andrewr@uidaho.edu>
Message-ID: <Pine.LNX.4.44.0309012004340.22766-100000@gannet.stats>

On Mon, 1 Sep 2003, Andrew Robinson wrote:

> Certainly.
> 
> postscript("test.ps")
> par(new=T)
> plot(1:10,1:10)
> dev.off()
> 
> Produces a postscript image that can be opened.  However 

But it is not a valid postscript file, and says it has 0 pages.

> pdf("test.pdf")
> par(new=T)
> plot(1:10,1:10)
> dev.off()
> 
> produces a pdf that cannot be opened by Latex or xpdf.  

Latex cannot open pdf!  (You may have meant pdftex, which uses xpdf 
internals anyway.)  Again, it's not a valid file.

Both are user error.  The issue is that your postscript viewer is being 
less careful than your pdf one.

The underlying problem is that par(new=TRUE) supresses calling NewPage on 
the device, which is not valid if there have been no pages on the device 
as yet.  That user error needs to be caught at the level of the graphics 
engine (Paul M?) and not programmed into each device, if it is to be 
caught at all.

Looks like that is possible: Rf_gpptr(dd)->state appears to record whether 
a plot has been started.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dmurdoch at pair.com  Mon Sep  1 23:32:29 2003
From: dmurdoch at pair.com (dmurdoch@pair.com)
Date: Mon Sep  1 22:32:05 2003
Subject: [Rd] Re: [R] File Reading Problem (PR#4043)
Message-ID: <200309012032.h81KWTJH001670@pubhealth.ku.dk>

On Mon, 1 Sep 2003 14:26:43 -0700, "Jiming Yu"
<jimingyu@princeton.edu> wrote:

>Dear all,
>    I am trying to read characters byte by byte(in their ASCII codes) from a
>file

I was going to suggest using readBin, but there seems to be a bug:

> con <- file('c:/test.txt','rb')
> readBin(con,'c',15,1)
stack imbalance in internal readBin, 9 then 8stack imbalance in
.Internal, 8 then 7
stack imbalance in {, 6 then 5
NULL
Error: unprotect(): stack imbalance

This was in today's r-devel build for Windows, but the bug also shows
up in 1.7.1.  I'll look into it.

Duncan Murdoch

From p.dalgaard at biostat.ku.dk  Mon Sep  1 23:55:58 2003
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Mon Sep  1 22:55:37 2003
Subject: [Rd] Re: [R] File Reading Problem (PR#4044)
Message-ID: <200309012055.h81KtwJH001778@pubhealth.ku.dk>

Duncan Murdoch <dmurdoch@pair.com> writes:

> On Mon, 1 Sep 2003 14:26:43 -0700, "Jiming Yu"
> <jimingyu@princeton.edu> wrote:
> 
> >Dear all,
> >    I am trying to read characters byte by byte(in their ASCII codes) from a
> >file
> 
> I was going to suggest using readBin, but there seems to be a bug:
> 
> > con <- file('c:/test.txt','rb')
> > readBin(con,'c',15,1)
> stack imbalance in internal readBin, 9 then 8stack imbalance in
> .Internal, 8 then 7
> stack imbalance in {, 6 then 5
> NULL
> Error: unprotect(): stack imbalance
> 
> This was in today's r-devel build for Windows, but the bug also shows
> up in 1.7.1.  I'll look into it.

It's not unique to windows:

> con <- file('FAQ','rb')
> readBin(con,'c',15,1)
stack imbalance in internal readBin, 9 then 8stack imbalance in
> .Internal, 8 then 7
stack imbalance in {, 6 then 5
NULL
Error: unprotect(): stack imbalance


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From dmurdoch at pair.com  Mon Sep  1 18:02:03 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon Sep  1 23:01:20 2003
Subject: [Rd] Re: [R] File Reading Problem (PR#4043)
In-Reply-To: <200309012032.h81KWTJH001670@pubhealth.ku.dk>
References: <200309012032.h81KWTJH001670@pubhealth.ku.dk>
Message-ID: <ggc7lvc0i2od34kdhkc6p0lct3mpu19h78@4ax.com>

On Mon, 1 Sep 2003 22:32:29 +0200 (MET DST), you wrote:

>On Mon, 1 Sep 2003 14:26:43 -0700, "Jiming Yu"
><jimingyu@princeton.edu> wrote:
>
>>Dear all,
>>    I am trying to read characters byte by byte(in their ASCII codes) from a
>>file
>
>I was going to suggest using readBin, but there seems to be a bug:
>
>> con <- file('c:/test.txt','rb')
>> readBin(con,'c',15,1)

The problem was that the R code assumed 'c' was a storage mode, and
the C code assumed that it had already been checked as valid.  I'll
put a patch into r-devel.

The answer to the original question is to use readChar, not readBin.
readBin looks for C-style null terminated strings.  readChar can read
characters one at a time.

The right code to read "This is a book." from file foo.txt is

 readChar("foo.txt", rep(1, 15))

Duncan Murdoch

From ripley at stats.ox.ac.uk  Mon Sep  1 23:15:09 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Sep  1 23:14:35 2003
Subject: [Rd] Re: [R] File Reading Problem (PR#4043)
In-Reply-To: <ggc7lvc0i2od34kdhkc6p0lct3mpu19h78@4ax.com>
Message-ID: <Pine.LNX.4.44.0309012214180.23108-100000@gannet.stats>

On Mon, 1 Sep 2003, Duncan Murdoch wrote:

> On Mon, 1 Sep 2003 22:32:29 +0200 (MET DST), you wrote:
> 
> >On Mon, 1 Sep 2003 14:26:43 -0700, "Jiming Yu"
> ><jimingyu@princeton.edu> wrote:
> >
> >>Dear all,
> >>    I am trying to read characters byte by byte(in their ASCII codes) from a
> >>file
> >
> >I was going to suggest using readBin, but there seems to be a bug:
> >
> >> con <- file('c:/test.txt','rb')
> >> readBin(con,'c',15,1)
> 
> The problem was that the R code assumed 'c' was a storage mode, and
> the C code assumed that it had already been checked as valid.  I'll
> put a patch into r-devel.
> 
> The answer to the original question is to use readChar, not readBin.
> readBin looks for C-style null terminated strings.  readChar can read
> characters one at a time.

It's on the help page for readBin, though.

> 
> The right code to read "This is a book." from file foo.txt is
> 
>  readChar("foo.txt", rep(1, 15))
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From oakeley at fmi.ch  Tue Sep  2 12:06:17 2003
From: oakeley at fmi.ch (oakeley@fmi.ch)
Date: Tue Sep  2 11:05:43 2003
Subject: [Rd] File in use error (PR#4047)
Message-ID: <200309020906.h8296HJH006982@pubhealth.ku.dk>

Full_Name: Edward J. Oakeley
Version: 1.7.1
OS: Windows XP
Submission from: (NULL) (212.47.183.3)


This bug occurs when using the (D)COM server to connect to the "expresso"
command of the Bioconductor Affy package. It may be a bug of R, (D)COM or Affy
ut I will report it here anyway as it feels like an R bug.

The Affy package when invoked will read a series of large (10Mb) text files from
the working directory. These files contain information about a microarray
experiment (CEL files). The instructions passed to R are as follows (VB .NET):

-----
'Make (D)COM connection
Dim x As New STATCONNECTORSRVLib.StatConnector()

'Initialising R
x.Init("R")
x.EvaluateNoReturn("library(affy)")
sPath = "c:\\temp\\"
x.EvaluateNoReturn("setwd(" + Chr(34) + sPath + Chr(34) + ")")

'Reading files...
x.EvaluateNoReturn("data <- ReadAffy()")

'Calculating RMA expression values...
x.EvaluateNoReturn("eset <- expresso(data, bgcorrect.method=" + Chr(34) + "rma"
+ Chr(34) + ", normalize.method=" + Chr(34) + "quantiles" + Chr(34) + ",
pmcorrect.method=" + Chr(34) + "pmonly" + Chr(34) + ", summary.method=" +
Chr(34) + "avgdiff" + Chr(34) + ")")

'Writng output data
x.EvaluateNoReturn("write.exprs(eset,file=" + Chr(34) + "output.txt" + Chr(34) +
")")
x.Close()
------

The "Close()" command should shutdown R and release all of the ownerships on
files as R quits but it does not. The files loaded (CEL files) can now not be
deleted or moved until the user logs off. The error generated is "file is in use
by another process". The output file "output.txt" does not have any special
restriction on its access applied.

The bug does not appear when the commands are invoked from the R console. The
only exception with the console approach is that the termination command given
is "q()". This command generates an error when passed over the (D)COM server.
The documentation recommended using the "Close()" function instead.

Anyway, just thought you should know... If this is not a bug then if anyone can
tell me how to release ownership on these files I would really appreciate it.

Thanks

Ed

From jmc at research.bell-labs.com  Tue Sep  2 11:44:03 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Tue Sep  2 16:44:41 2003
Subject: [Rd] Documentation responsibility for functions and methods
Message-ID: <3F54ACB3.B5316AA7@research.bell-labs.com>

A revised version of the undoc() function in the tools package was
committed to r-devel today that attempts to implement the following
policy in checking for undocumented functions and methods in a package,
based on discussions recently on this list and in r-core:

If a package has methods for a function defined originally somewhere
else, and does not change the underlying default method for the
function, the package is responsible for documenting the methods it
creates, but not for the function itself or the default method.

In particular, if you define methods for functions in the base package,
"R CMD check" will warn you if you have not documented those methods,
but should not ask you to document the function or its default ("ANY")
method.

However, if the function itself is in the same package OR the default
method has been changed from the original non-generic function, then you
should be warned about missing documentation for these two items as
well.

The current implementation is not very strict in deciding whether the
default method has been changed, but will catch the common situations. 
Let us know if you seem to be asked for too much documentation (or too
little, of course).

Regards,
 John

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From colin at colinsmith.org  Tue Sep  2 23:15:27 2003
From: colin at colinsmith.org (colin@colinsmith.org)
Date: Tue Sep  2 22:14:56 2003
Subject: [Rd] completeSubclasses() methods bug (PR#4051)
Message-ID: <200309022015.h82KFRJH015010@pubhealth.ku.dk>

Full_Name: Colin A. Smith
Version: 1.8.0
OS: Mac OS X 10.2.6
Submission from: (NULL) (128.102.184.81)


annaffy 1.0.1 (in BioC CVS) fails to load. annaffy 1.0 (on the BioC web site)
has the same problem.

It looks like the load is failing because of a bug in completeSubclasses() in
r-devel. It calls setIs() and doesn't specify an environment via the "where"
argument. setIs() "where" defaults to topEnv() and fails because "aafGO" doesn't
exist in that environment and "list" is sealed.

completeSubclasses should be specifying my package for "where" instead of using
the default.

> library(annaffy)
Error in setIs(class2, obji@superClass, extensionObject = obji, doComplete =
FALSE) : 
        Cannot create a setIs relation when neither of the classes ("aafGO" and
"list") is local and modifiable in this package
Error in setClass("aafGO", "aafList", prototype = list(), where = where) : 
        Error in contained classes ("aafList") for class "aafGO"; class
definition removed from "annaffy"
Error in library(annaffy) : .First.lib failed

From p.dobcsanyi at designtheory.org  Tue Sep  2 23:57:18 2003
From: p.dobcsanyi at designtheory.org (Peter Dobcsanyi)
Date: Tue Sep  2 23:56:47 2003
Subject: [Rd] An XML format for block designs
Message-ID: <E19uJ9K-0000uX-00@dx.maths.qmul.ac.uk>


    A standard format for block designs and their properties
    ========================================================

         (A proposal and an invitation for public debate)


At DesignTheory.org we are developing a web-based Design Theory Resource
Server for combinatorial and statistical design theory.  These resources
will include an online database of designs, an Encyclopaedia of Design
Theory, and software packages for the generation and analysis of
designs.  We hope to address the needs of both researchers and
practitioners of design theory.

One critical element is our XML format to represent designs and their
properties in a standard platform-independent manner. This will allow
for the straightforward exchange of designs and their properties between
various computer systems, including databases and web servers, and
combinatorial, group theoretical and statistical packages. The XML
format will also be used for outside submissions to our design database
and to store designs in perpetuity.

Our initial development is in the area of block designs, and we invite
you to read and comment on our proposal for the External Representation
of Block Designs, available online at:

    http://designtheory.org/

Please send your comments (and follow-ups) exclusively to:

    developers@designtheory.org

This is a mailing list to which you are welcome, although not required,
to join. Alternatively, you can follow the discussions through the
public archives of the list.  For further details, please visit:

    http://designtheory.org/mailing.html

We will finalize the XML format for block designs after sufficient
public debate, after which we shall release GAP [1], R [2], and Python
[3] software for block designs.  We are committed to the open source
model and all products of our development will be released to the public
free of charge.

We shall also start developing a database of block designs, and look
forward to your contributions (in the XML format) to this database.

Please feel free to forward this announcement to anyone you think may be
interested.

References:

[1] GAP - Groups, Algorithms and Programming
    http://www.gap-system.org/

[2] The R Project for Statistical Computing
    http://www.r-project.org/

[3] The Python programming language
    http://www.python.org/

From roger at ysidro.econ.uiuc.edu  Tue Sep  2 18:41:26 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Wed Sep  3 00:34:26 2003
Subject: [Rd] Re: [R] help file extension (fwd)
Message-ID: <Pine.SOL.4.30.0309021735200.24110-100000@ysidro.econ.uiuc.edu>

This R-help thread reminds me that it would be nice if the CRAN
website made vignettes for packages available in pdf form in the
same way that the manual pages are now available.

As the number of packages expands users might benefit from a brief
introduction to the package as an alternative, or in addition to,
a look at the manual.  It would also be a good inducement for
package writers to produce vignettes!


url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker@uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

---------- Forwarded message ----------
Date: Wed,  3 Sep 2003 00:13:29 +0200
From: Kurt Sys <Kurt.Sys@ugent.be>
To: r-help@stat.math.ethz.ch
Subject: Re: [R] help file extension

OK, that's more or less what I want.
tnx,
Kurt.

Quoting Douglas Bates <bates@stat.wisc.edu>:

> Duncan Murdoch <dmurdoch@pair.com> writes:
>
> > On Mon, 01 Sep 2003 17:24:11 -0400, you wrote:
> >
> >
> > >You can put additional documentation in a "doc" subdirectory,
> >
> > That should be info/doc in the source...
>
> I think you mean inst/doc

______________________________________________
R-help@stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

From hb at maths.lth.se  Wed Sep  3 10:08:48 2003
From: hb at maths.lth.se (hb@maths.lth.se)
Date: Wed Sep  3 09:08:22 2003
Subject: [Rd] Last line in .Rprofile must have newline (PR#4056)
Message-ID: <200309030708.h8378mJH017724@pubhealth.ku.dk>

Full_Name: Henrik Bengtsson
Version: R v1.7.1
OS: WinXP Pro, Solaris 9
Submission from: (NULL) (130.235.2.229)


A colleague of mine who is new to R had problems setting up his .Rprofile and we
tracked it down to the following. On both WinXP and Solaris with Rv1.7.1 we
noticed that the *last* line in .Rprofile has to have a *newline* to be
evaluated. For instance, starting R with the following .Rprofile:

 a <- 1 <newline>
 b <- 2

will only set the variable 'a'. Adding a newline to the second line will set 'b'
too. FYI: I browsed through ?.Rprofile and R-intro.html to see if it was
document, but it does not seem so. I also checked with the behavior of source()
too, but there a newline is not required. 

Best wishes

Henrik Bengtsson
Lund University

> str(R.Version())
List of 11
 $ platform: chr "sparc-sun-solaris2.9"
 $ arch    : chr "sparc"
 $ os      : chr "solaris2.9"
 $ system  : chr "sparc, solaris2.9"
 $ status  : chr ""
 $ major   : chr "1"
 $ minor   : chr "7.1"
 $ year    : chr "2003"
 $ month   : chr "06"
 $ day     : chr "16"
 $ language: chr "R"

> str(R.Version())
List of 11
 $ platform: chr "i386-pc-mingw32"
 $ arch    : chr "i386"
 $ os      : chr "mingw32"
 $ system  : chr "i386, mingw32"
 $ status  : chr ""
 $ major   : chr "1"
 $ minor   : chr "7.1"
 $ year    : chr "2003"
 $ month   : chr "06"
 $ day     : chr "16"
 $ language: chr "R"

From Roger.Bivand at nhh.no  Wed Sep  3 10:21:53 2003
From: Roger.Bivand at nhh.no (Roger.Bivand@nhh.no)
Date: Wed Sep  3 09:21:21 2003
Subject: [Rd] identify() seg.faults (PR#4057)
Message-ID: <200309030721.h837LrJH017954@pubhealth.ku.dk>

Full_Name: Roger Bivand
Version: 1.7.1
OS: i686-pc-linux-gnu
Submission from: (NULL) (129.177.30.18)


identify() seg.faults when x is an empty list, when the n argument is given a
positive value, avoiding the check for non-positive n (n <- length(x) when x is
the non-existent x component of the empty list, and when neither x nor y are
components of the list.

suggested resolution: add test in plot.c around line 3010



> > The simplest case is:

> plot(1:10)
> xy <- list()
> identify(xy, n=1)
Segmentation fault

but 

> identify(xy)
Error in identify.default(xy) : invalid number of points in identify

I'm not sure, but adding a check against zero-length and/or NULL x and or 
y about line 3010 in src/main/plot.c should catch this.

> On Tue, 2 Sep 2003, kjetil brinchmann halvorsen wrote:
>
> > Hola!
> > I will want to identify pixels in an image with the mouse, for 
> > so getting the image data from the matrix(es), for use in subsequent 
> > discriminant analysis. But the following bombs R:
> > (windows XP, rw1071)
> > 
> > > str(baboon)
> >  list()
> >  - attr(*, "size")= int [1:2] 512 512
> >  - attr(*, "cellres")= num [1:2] 1 1
> >  - attr(*, "bbox")= num [1:4] 0 0 512 512
> >  - attr(*, "channels")= chr "grey"
> >  - attr(*, "bbcent")= logi FALSE
> >  - attr(*, "class")= chr "pixmapGrey"
> >  - attr(*, "grey")= num [1:512, 1:512] 0.537 0.510 0.345 0.259 0.322 
> > ...
> > > class(baboon)
> > [1] "pixmapGrey"
> > > library(pixmap)
> > > plot(baboon)
> > > identify(baboon, n=1)
> > 
> > ... and then R bombs!
> > 
> > What to do?
> > > > library(pixmap)
> > example(pixmap)
> ....
> pixmap> plot(z[1:20, 10:40])
> > identify(z, n=1)
> 
> Program received signal SIGSEGV, Segmentation fault.
> do_set (call=0x869ce7c, op=0x8299648, args=0x869ce98, rho=0x8f2496c)
>     at eval.c:1308
> 1308                switch (NAMED(s)) {
> 
> 
> The identify.default() function is passing the pixmap object through to
> xy.coords(), which returns two empty x and y vectors, which are checked
> for length in the R code - xy.coords() treats the pixmap object as a list, 
> does:
> 
> } else if (is.list(x)) {
>     xlab <- paste(ylab, "$x", sep = "")
>     ylab <- paste(ylab, "$y", sep = "")
>     y <- x[["y"]]
>     x <- x[["x"]]
> } else {
> 
> and y and x are the same length, so returns to identify.default() with 
> nothing, which is passed on to the .Internal() undetected. Two 
> possibilities - an identify.pixmap() in pixmap, or a test for the 
> (package, S4) pixmap class in xy.coords. But as it stands, it's a quick 
> way to exit the program. xy.coords() seems to be trusting the user to have 
> a list with x and y components, and here it has neither. The list is 
> indeed empty, being an S4 class - it just has attributes.
>

From ripley at stats.ox.ac.uk  Wed Sep  3 09:26:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Sep  3 09:25:33 2003
Subject: [Rd] Last line in .Rprofile must have newline (PR#4056)
In-Reply-To: <200309030708.h8378mJH017724@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0309030812510.27476-100000@gannet.stats>

Why do you think this a bug in R?  All source files should end in the EOL
character: R command lines are incomplete without it (or a semicolon) and
this is covered by the standard rules.  (It also happens at the command
line, BTW.)

That we have worked around the user error in a number of places does not
make it a bug elsewhere.  Files such as .Rprofile are handled at a much
lower level than source(), and the convenience of the connections
mechanism (which allows non-native line endings for example, as well as
incomplete last lines) is not available.

For your reference, it is the behaviour of R_ReplFile in src/main/main.c
on PARSE_EOF that matters.

On Wed, 3 Sep 2003 hb@maths.lth.se wrote:

> Full_Name: Henrik Bengtsson
> Version: R v1.7.1
> OS: WinXP Pro, Solaris 9
> Submission from: (NULL) (130.235.2.229)
> 
> 
> A colleague of mine who is new to R had problems setting up his .Rprofile and we
> tracked it down to the following. On both WinXP and Solaris with Rv1.7.1 we
> noticed that the *last* line in .Rprofile has to have a *newline* to be
> evaluated. For instance, starting R with the following .Rprofile:
> 
>  a <- 1 <newline>
>  b <- 2
> 
> will only set the variable 'a'. Adding a newline to the second line will set 'b'
> too. FYI: I browsed through ?.Rprofile and R-intro.html to see if it was
> document, but it does not seem so. I also checked with the behavior of source()
> too, but there a newline is not required. 
> 
> Best wishes
> 
> Henrik Bengtsson
> Lund University
> 
> > str(R.Version())
> List of 11
>  $ platform: chr "sparc-sun-solaris2.9"
>  $ arch    : chr "sparc"
>  $ os      : chr "solaris2.9"
>  $ system  : chr "sparc, solaris2.9"
>  $ status  : chr ""
>  $ major   : chr "1"
>  $ minor   : chr "7.1"
>  $ year    : chr "2003"
>  $ month   : chr "06"
>  $ day     : chr "16"
>  $ language: chr "R"
> 
> > str(R.Version())
> List of 11
>  $ platform: chr "i386-pc-mingw32"
>  $ arch    : chr "i386"
>  $ os      : chr "mingw32"
>  $ system  : chr "i386, mingw32"
>  $ status  : chr ""
>  $ major   : chr "1"
>  $ minor   : chr "7.1"
>  $ year    : chr "2003"
>  $ month   : chr "06"
>  $ day     : chr "16"
>  $ language: chr "R"
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From claus at ekstroem.dk  Wed Sep  3 12:18:13 2003
From: claus at ekstroem.dk (Claus Ekstroem)
Date: Wed Sep  3 11:17:42 2003
Subject: [Rd] Updated power.t.test
Message-ID: <20030903091813.GA27011@dina.kvl.dk>

Greetings,

I've tried to update the power.t.test function to allow for different sample sizes and sample variances in the case of a two-sample t test. I'd gladly update 
the corresponding help page if the code is to replace the current power.t.test function. The modified power.t.test code is included below. 

The changes are as follows:

 - Added three new arguments to the function
   * ratio     : the ratio between group sizes (defaults to 1)
   * sd.ratio  : the ratio between group sd's (defaults to 1)
   * df.method : the method used to calculate the df (defaults to Welch's/Satterthwaite as in the t.test function)

The three new arguments are unly used for the unpaired two-sample case (i.e., when type="two.sample"), and they have default values such that function calls in 
"old code" should work. However, I've changed the output for the group sizes and sd's so they now return a 2-vector with the corresponding group sizes and 
sd's. For example 

# Old code 
> power.t.test(power=.8, delta=1, sd=1)

     Two-sample t test power calculation 

              n = 16.71477
          delta = 1
             sd = 1
      sig.level = 0.05
          power = 0.8
    alternative = two.sided

 NOTE: n is number in *each* group 


# New code
> power.t.test(power=.8, delta=1, sd=1)

     Two-sample t test power calculation 

              n = 16.71477, 16.71477
          delta = 1
             sd = 1, 1
      sig.level = 0.05
          power = 0.8
    alternative = two.sided
      df.method = welch

 NOTE: n is vector of number in each group 


This change of output may break some existing code and is not necessarily a "good idea". Another (possibly better) solution to this would be to return 
both ratios and then let print.power.htest present the result in the correct way. Also, the df.method in the result list could be removed for the one-sample 
and the paired case.

Please comment,

Claus Ekstr?m



power.t.test <-
  function (n = NULL, delta = NULL, sd = 1, sig.level = 0.05, power = NULL,
            ratio = 1, sd.ratio = 1, 
            type = c("two.sample", "one.sample", "paired"),
            alternative = c("two.sided", "one.sided"),
            df.method = c("welch", "classical"),
            strict = FALSE) 
{ 
  type <- match.arg(type)

  if (type == "two.sample") {
    
    if (sum(sapply(list(n, delta, sd, power, sig.level, ratio, sd.ratio), is.null)) !=   1) 
      stop("exactly one of n, delta, sd, power, sig.level, ratio and sd.ratio must be NULL")
    
    if (!is.null(ratio) && ratio <= 0)
      stop("ratio between group sizes must be positive")

    if (!is.null(sd.ratio) && sd.ratio <= 0)
      stop("sd.ratio between group sd's must be positive")
  }
  else {

    if (sum(sapply(list(n, delta, sd, power, sig.level), is.null)) !=   1) 
      stop("exactly one of n, delta, sd, power, and sig.level must be NULL")
  }
  
  alternative <- match.arg(alternative)
  df.method <- match.arg(df.method)
  tsample <- switch(type, one.sample = 1, two.sample = 2, paired = 1)
  tside <- switch(alternative, one.sided = 1, two.sided = 2)
  if (tside == 2 && !is.null(delta)) 
    delta <- abs(delta)
  p.body <- quote({
    nu <- switch(tsample, n-1, switch(df.method, welch=(sd^2/n + (sd*sd.ratio)^2/(n*ratio))^2/((sd^2/n)^2/(n-1) + ((sd*sd.ratio)^2/(ratio*n))^2/(n*ratio-1)), 
classical=(1+ratio)*n-2)) 
    pt(qt(sig.level/tside, nu, lower = FALSE), nu, ncp = switch(tsample, sqrt(n/tsample), sqrt(n/(1+sd.ratio/ratio))) * delta/sd, lower = FALSE)
  })
  if (strict & tside == 2) 
    p.body <- quote({
      nu <- switch(tsample, n-1, switch(df.method, welch=(sd^2/n + (sd*sd.ratio)^2/(n*ratio))^2/((sd^2/n)^2/(n-1) + ((sd*sd.ratio)^2/(ratio*n))^2/(n*ratio-1)), 
classical=(1+ratio)*n-2)) 
      qu <- qt(sig.level/tside, nu, lower = FALSE)
      ncp <- switch(tsample, sqrt(n/tsample), sqrt(n/(1+sd.ratio/ratio))) * delta/sd
      pt(qu, nu, ncp = ncp, lower = FALSE) + 
        pt(-qu, nu, ncp = ncp, lower = TRUE)
    })

  if (is.null(power)) 
    power <- eval(p.body)
  else if (is.null(n)) 
    n <- uniroot(function(n) eval(p.body) - power, c(2, 1e+07))$root
  else if (is.null(sd)) 
    sd <- uniroot(function(sd) eval(p.body) - power, delta * c(1e-07, 1e+07))$root
  else if (is.null(delta)) 
    delta <- uniroot(function(delta) eval(p.body) - power, sd * c(1e-07, 1e+07))$root
  else if (is.null(sig.level)) 
    sig.level <- uniroot(function(sig.level) eval(p.body) - power, c(1e-10, 1 - 1e-10))$root
  else if (is.null(ratio))
    ratio <- uniroot(function(ratio) eval(p.body) - power, c(2/n, 1e+07))$root
  else if (is.null(sd.ratio))
    sd.ratio <- uniroot(function(sd.ratio) eval(p.body) - power, c(1e-07, 1e+07))$root
  else stop("internal error")
  NOTE <- switch(type, paired = "n is number of *pairs*, sd is std.dev. of *differences* within pairs", 
                 two.sample = "n is vector of number in each group", NULL)

  n <- switch(type, paired=n, two.sample=c(n, n*ratio), one.sample=n)
  sd <- switch(type, paired=sd, two.sample=c(sd, sd*sd.ratio), one.sample=sd)
  
  METHOD <- paste(switch(type, one.sample = "One-sample", two.sample = "Two-sample", 
                         paired = "Paired"), "t test power calculation")
  structure(list(n = n, delta = delta, sd = sd, sig.level = sig.level, 
                 power = power, alternative = alternative, note = NOTE, 
                 method = METHOD), class = "power.htest")
}


-- 
*****************************************
Claus Thorn Ekstr?m <ekstrom@dina.kvl.dk>
Dept of Mathematics and Physics, KVL
Thorvaldsensvej 40
DK-1871 Frederiksberg C
Denmark
Phone:[+45] 3528 2341
Fax:  [+45] 3528 2350

From jmc at research.bell-labs.com  Wed Sep  3 09:29:44 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Wed Sep  3 14:30:04 2003
Subject: [Rd] completeSubclasses() methods bug (PR#4051)
References: <200309022015.h82KFRJH015010@pubhealth.ku.dk>
Message-ID: <3F55DEB8.990C1A88@research.bell-labs.com>

Yes, thanks.  I have a corrected version checked out.  It has some other
changes--as soon as I make a cleaned-up version with this fix only, I'll
commit it.

John

colin@colinsmith.org wrote:
> 
> Full_Name: Colin A. Smith
> Version: 1.8.0
> OS: Mac OS X 10.2.6
> Submission from: (NULL) (128.102.184.81)
> 
> annaffy 1.0.1 (in BioC CVS) fails to load. annaffy 1.0 (on the BioC web site)
> has the same problem.
> 
> It looks like the load is failing because of a bug in completeSubclasses() in
> r-devel. It calls setIs() and doesn't specify an environment via the "where"
> argument. setIs() "where" defaults to topEnv() and fails because "aafGO" doesn't
> exist in that environment and "list" is sealed.
> 
> completeSubclasses should be specifying my package for "where" instead of using
> the default.
> 
> > library(annaffy)
> Error in setIs(class2, obji@superClass, extensionObject = obji, doComplete =
> FALSE) :
>         Cannot create a setIs relation when neither of the classes ("aafGO" and
> "list") is local and modifiable in this package
> Error in setClass("aafGO", "aafList", prototype = list(), where = where) :
>         Error in contained classes ("aafList") for class "aafGO"; class
> definition removed from "annaffy"
> Error in library(annaffy) : .First.lib failed
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From cberry at tajo.ucsd.edu  Wed Sep  3 19:57:34 2003
From: cberry at tajo.ucsd.edu (cberry@tajo.ucsd.edu)
Date: Thu Sep  4 03:58:52 2003
Subject: [Rd] fisher.test() gives wrong confidence interval (PR#4019)
In-Reply-To: <16208.30128.340961.32061@mithrandir.hornik.net>
Message-ID: <Pine.GSO.4.10.10309031812400.27155-100000@tajo.ucsd.edu>

On Sat, 30 Aug 2003, Kurt Hornik wrote:
[deleted]
> 
> I changed the code (r-devel) to
> 
>         CINT <- switch(alternative,
>                        less = c(0, ncp.U(x, 1 - conf.level)),
>                        greater = c(ncp.L(x, 1 - conf.level), Inf),
>                        two.sided = {
>                            if(ESTIMATE == 0)
>                                c(0, ncp.U(x, 1 - conf.level))
>                            else if(ESTIMATE == Inf)
>                                c(ncp.L(x, 1 - conf.level), Inf)
>                            else {
>                                alpha <- (1 - conf.level) / 2
>                                c(ncp.L(x, alpha), ncp.U(x, alpha))
>                            }
>                        })
> 

I believe that the resulting interval will sometimes fail to satisfy the
confidence statement for values of alpha other than 0 or Inf.

('sometimes' rather than always, because of the discreteness of the
distribution)

I think you need 

 if(ESTIMATE == 0)
                                c(0, ncp.U(x, 1 - conf.level / 2))
                            else if(ESTIMATE == Inf)
                                c(ncp.L(x, 1 - conf.level / 2 ), Inf)
                            else {
                                alpha <- (1 - conf.level) / 2
                                c(ncp.L(x, alpha), ncp.U(x, alpha))
                            }

> which seems to fix the problem.
> 
> Thanks,
> 
> -k
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

Charles C. Berry                        (858) 534-2098 
                                         Dept of Family/Preventive Medicine
E mailto:cberry@tajo.ucsd.edu	         UC San Diego
http://hacuna.ucsd.edu/members/ccb.html  La Jolla, San Diego 92093-0717

From p.dalgaard at biostat.ku.dk  Thu Sep  4 08:45:32 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Sep  4 09:45:35 2003
Subject: [Rd] fisher.test() gives wrong confidence interval (PR#4019)
In-Reply-To: <Pine.GSO.4.10.10309031812400.27155-100000@tajo.ucsd.edu>
References: <Pine.GSO.4.10.10309031812400.27155-100000@tajo.ucsd.edu>
Message-ID: <x2vfs9m1vu.fsf@biostat.ku.dk>

<cberry@tajo.ucsd.edu> writes:

> I believe that the resulting interval will sometimes fail to satisfy the
> confidence statement for values of alpha other than 0 or Inf.

alpha? 
 
> ('sometimes' rather than always, because of the discreteness of the
> distribution)
> 
> I think you need 
> 
>  if(ESTIMATE == 0)
>                                 c(0, ncp.U(x, 1 - conf.level / 2))
>                             else if(ESTIMATE == Inf)
>                                 c(ncp.L(x, 1 - conf.level / 2 ), Inf)
>                             else {
>                                 alpha <- (1 - conf.level) / 2
>                                 c(ncp.L(x, alpha), ncp.U(x, alpha))
>                             }

I don't think this is right either. The only "correct" fix is to invert
the two-sided *test*. This may or may not have to include mass in the
opposite tails, so any attempt to base the logic on the value of
ESTIMATE is going to fail. Unfortunately, this inversion is tricky
because adjusting the parameter causes points to enter and leave the
critical region in a discontinuous manner, or, put otherwise, the
p-value is an awkward function of the parameters.

For your edification consider the following

binom.test(3,15)
binom.test(3,15,p=0.04331201) # p = 0.025
binom.test(3,15,p=0.48089113) # p > 0.025, but < 0.05

# Define B(x) = two-sided p value for param == x
# Needs to be vectorized so that curve works
B <- function(x) sapply(x,function(x)binom.test(3,15,p=x)$p.value)
curve(B,from=0,to=1,n=5000)
uniroot(function(x)B(x)-.05,c(.2,1))
uniroot(function(x)B(x)-.05,c(0,.2))

In this case, it actually works and gives an improved CI from 0.05685
to 0.4657785, but if you look closely at the curve of B, you'll see
that it is discontinuous, and in fact not even monotone. There is, by
the way, a particularly nasty case with binom.test(0,5) where a
discontinuity hits exactly at p=0.5, which is also the endpoint of the
CI.

I think that the real issue here is whether we should take our chances
and implement the uniroot technique, knowing that it might fail in
some (probably few) cases.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From intlribbon at cox.net  Thu Sep  4 10:18:20 2003
From: intlribbon at cox.net (INTERNATIONAL RIBBONS AND PAPER)
Date: Thu Sep  4 18:17:50 2003
Subject: [Rd] 7_ Size DOES Matter_ uy nsw e (PR#4026)
Message-ID: <000601c37300$28a08ab0$fe340344@CX2089113B>

Please inform me as to how vision34c.com can blast email thousands of emails with my return email address. we a re receiving 200 per day of returned emails and it is annoying.
'
William Hardy
International Ribbons & Paper
1-800-872-8792

	[[alternative HTML version deleted]]

From virus_alert at netsurit.com  Thu Sep  4 21:23:17 2003
From: virus_alert at netsurit.com (virus_alert@netsurit.com)
Date: Thu Sep  4 21:09:57 2003
Subject: [Rd] Blocked delivery of your email to nceba@endemol.co.za
Message-ID: <200309041823.h84INHcQ004398@nd.co.za>

                 BLOCKED DELIVERY OF YOUR EMAIL TO nceba@endemol.co.za 

Your email has been stopped.
The intended recipient will receive a notification of this message.


Email was blocked due to the presence of a virus
	Comment: Virus found

/unpacked/details.pif  Infection: W32/Sobig.F@mm


End.

From kwright at eskimo.com  Thu Sep  4 13:19:40 2003
From: kwright at eskimo.com (Kevin Wright)
Date: Thu Sep  4 21:19:29 2003
Subject: [Rd] Suggestion for 'contrasts' help page
Message-ID: <200309041919.MAA13331@eskimo.com>


The help page for 'contrasts' has a mention of the 'options' in the Details
section.  Would it make sens to include an example of how to use options
to set the contrasts?

# Set contrasts for furhter computations
options(contrasts=c("contr.treatment","contr.poly"))


This seems useful to me.

Kevin Wright

From jago at mclink.it  Fri Sep  5 00:38:17 2003
From: jago at mclink.it (Stefano Iacus)
Date: Thu Sep  4 23:37:46 2003
Subject: [Rd] binary packages for RAqua
Message-ID: <1852DEEB-DF20-11D7-A8B3-003065CC4CB8@mclink.it>

I have updated RAqua.pkg.sit on http://www.economia.unimi.it/R/
This version has one major improvement over the previouses: binary 
package installation.
I have produced a small set of binary package that you can try to work 
with.
During the next week or so we will arrange to build Bioconductor 
releated packages as well (so this option is not functioning yet).

These packages are likely to work also for darwin R (not RAqua) but we 
will work on this too (for the time being you can try to copy 
browse.pkg() function from RAqua and adapt it). Of course, you need a 
setup not too different from what reported in the above URL.

stefano

From jago at mclink.it  Fri Sep  5 00:38:08 2003
From: jago at mclink.it (Stefano Iacus)
Date: Thu Sep  4 23:38:15 2003
Subject: [Rd] darwin build with latest gcc from apple
Message-ID: <134FE22F-DF20-11D7-A8B3-003065CC4CB8@mclink.it>

we are trying to adapt the configure in order to work with latest 
gcc3.3 (from apple) and g77 3.4 (from 
http://gravity.psu.edu/~khanna/hpc.html )
At the moment there is no need to define the __DEBUGGING__ but there is 
still a problem with the -lcc_dynamic

does any of you know how to check for this library and explain why we 
see -lcc_dynamic often passed as an ld flag.
Where to find doc on this?

stefano

From a9709233 at unet.univie.ac.at  Fri Sep  5 00:54:19 2003
From: a9709233 at unet.univie.ac.at (a9709233@unet.univie.ac.at)
Date: Thu Sep  4 23:55:00 2003
Subject: [Rd] "euro" (PR#4071)
Message-ID: <200309042154.h84LsJJH010578@pubhealth.ku.dk>

Full_Name: Nikolaus Fink
Version: 1.7.1
OS: Windows ME
Submission from: (NULL) (131.130.1.150)


Dear All,

The euro sign "€" lets R break down.

> x<-"€"
> x
ENTER

-> Rgui caused a mistake in R.DLL
Rgui will be closed.
(translation from German)


Nikolaus Fink

From deleeuw at stat.ucla.edu  Thu Sep  4 16:49:35 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Fri Sep  5 00:50:14 2003
Subject: [Rd] darwin build with latest gcc from apple
In-Reply-To: <134FE22F-DF20-11D7-A8B3-003065CC4CB8@mclink.it>
References: <134FE22F-DF20-11D7-A8B3-003065CC4CB8@mclink.it>
Message-ID: <0E397480-DF2A-11D7-BECB-000393BB6D36@stat.ucla.edu>

This is on Panther B53

cabledoc92:Developer/R/R-devel] deleeuw% gcc -v
Reading specs from /usr/libexec/gcc/darwin/ppc/3.3/specs
Thread model: posix
gcc version 3.3 20030304 (Apple Computer, Inc. build 1492)

[cabledoc92:Developer/R/R-devel] deleeuw% g77 -v
Reading specs from /usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/specs
Configured with: '../gcc/configure' '--enable-threads=posix  
'--enable-languages=c,f77
Thread model: posix
gcc version 3.4 20030828 (experimental)

[cabledoc92:Developer/R/R-devel] deleeuw% uname -a
Darwin cabledoc92.frazmtn.com 7.0.0 Darwin Kernel Version 7.0.0: Tue  
Aug 26 12:45:49 PDT 2003; root:xnu/xnu-493.obj~1/RELEASE_PPC  Power  
Macintosh powerpc

It seems I can get rid of FPICFLAGS -fno-common and CPPFLAGS  
-D__DEBUGGING__

If you do not use -lcc_dynamic as LDFLAGS it cannot find restFP and  
saveFP.
/usr/lib/libcc_dynamic.a is a soft link to  
/usr/lib/gcc/darwin/3.3/libgcc.a
which does contain these symbols.

By the way, the symbols are not in  
/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/libgcc.a

Also, configure tests if saveFP is in libcc_dynamic.a, and says it  
isn't.

On Sep 4, 2003, at 14:38 , Stefano Iacus wrote:

> we are trying to adapt the configure in order to work with latest  
> gcc3.3 (from apple) and g77 3.4 (from  
> http://gravity.psu.edu/~khanna/hpc.html )
> At the moment there is no need to define the __DEBUGGING__ but there  
> is still a problem with the -lcc_dynamic
>
> does any of you know how to check for this library and explain why we  
> see -lcc_dynamic often passed as an ld flag.
> Where to find doc on this?
>
> stefano
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From ligges at statistik.uni-dortmund.de  Fri Sep  5 09:45:34 2003
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Fri Sep  5 08:44:55 2003
Subject: [Rd] "euro" (PR#4071)
Message-ID: <200309050645.h856jYJH012921@pubhealth.ku.dk>

a9709233@unet.univie.ac.at wrote:
> Full_Name: Nikolaus Fink
> Version: 1.7.1
> OS: Windows ME
> Submission from: (NULL) (131.130.1.150)
> 
> 
> Dear All,
> 
> The euro sign "?" lets R break down.
> 
> 
>>x<-"?"
>>x
> 
> ENTER
> 
> -> Rgui caused a mistake in R.DLL
> Rgui will be closed.
> (translation from German)
> 
> 
> Nikolaus Fink

That's not a bug in R. Please read at least the FAQs before submitting 
bug reports. In particular read Section 2.18 "Entering certain 
characters crashes Rgui" of the R for Windows FAQ.

Uwe Ligges

From jago at mclink.it  Fri Sep  5 11:26:55 2003
From: jago at mclink.it (Stefano Iacus)
Date: Fri Sep  5 10:28:17 2003
Subject: [Rd] darwin build with latest gcc from apple
In-Reply-To: <0E397480-DF2A-11D7-BECB-000393BB6D36@stat.ucla.edu>
Message-ID: <B5B939A6-DF7A-11D7-A8B3-003065CC4CB8@mclink.it>

R-devel configs and build fine on both configurations below.
It would be nice to test it on Panther eventually. A great thank goes 
from my side to Kurt for this configure version.

I configure with:

./configure --enable-R-shlib --with-blas='-framework vecLib' 
--with-lapack 
--with-tcl-config=/Library/Frameworks/Tcl.framework/tclConfig.sh 
--with-tk-config=/Library/Frameworks/Tk.framework/tkConfig.sh 
--with-aqua

and you should eventually change the tcl/tk config files


configs: Apple DevTools dec2002 (gcc 3.1) and g77 from Khanna's hp
[srv-dipeco2:~/r-devel/MacOSX-inst] iacus% gcc -v
Reading specs from /usr/libexec/gcc/darwin/ppc/3.1/specs
Thread model: posix
Apple Computer, Inc. GCC version 1151, based on gcc version 3.1 
20020420 (prerelease)
[srv-dipeco2:~/r-devel/MacOSX-inst] iacus% g77 -v
Reading specs from 
/usr/local/lib/gcc-lib/powerpc-apple-darwin6.1/3.1/specs
Configured with: ../gcc3-1151/configure --enable-pfe --disable-nls 
--enable-threads=posix --enable-languages=f77
Thread model: posix
Apple Computer, Inc. GCC version 1151, based on gcc version 3.1 
20020420 (prerelease)

and  Apple udpate for DevTools dec2002 (gcc 3.3) and g77 v3.4 from 
Khanna's hp

[iacus1:~/r-devel/MacOSX-inst] stefano% gcc -v
Reading specs from /usr/libexec/gcc/darwin/ppc/3.3/specs
Thread model: posix
gcc version 3.3 20030304 (Apple Computer, Inc. build 1435)
[iacus1:~/r-devel/MacOSX-inst] stefano% g77 -v
Reading specs from /usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/specs
Configured with: '../gcc/configure' '--enable-threads=posix 
'--enable-languages=c,f77
Thread model: posix
gcc version 3.4 20030828 (experimental)



I'll update the instructions on the webpage for RAqua.

stefano

From L.T.Kell at cefas.co.uk  Fri Sep  5 12:27:14 2003
From: L.T.Kell at cefas.co.uk (L.T.Kell@cefas.co.uk)
Date: Fri Sep  5 11:26:38 2003
Subject: [Rd] Problem with S4 slots in C code (PR#4073)
Message-ID: <200309050927.h859RDJH015529@pubhealth.ku.dk>

This message is in MIME format. Since your mail reader does not understand
this format, some or all of this message may not be legible.

------_=_NextPart_000_01C3738F.63DE3390
Content-Type: text/plain;
	charset="iso-8859-1"

#I want to be able to create a new S4 class and read data into it using C
code

# Here is a very simple S4 object inheriting from "array", but with 5
specified dimensions 
#(the validity stuff has been stripped out to make it short as I don't think
it is the problem here)

setClass("FLQuant",
	representation("array"),
	prototype=(array(1, dim=c(1,1,1,1,1), dimnames=list(age="0",
year="0", sex="combined", season="all", area="all")))
)

# In R, I can create a new "FLQuant" object:
> fl <- new("FLQuant")
> fl
An object of class "FLQuant"
, , sex = combined, season = all, area = all

   year
age 0
  0 1

# and:
> aa <- array(2, dim=c(1,1,1,1,1), dimnames=list(age="1", year="2000",
sex="combined", season="all", area="all"))
> aa
, , sex = combined, season = all, area = all

   year
age 2000
  1    2

# Putting the array aa into fl is done like this (by the way, is this a
correct way to do it?):
> fl@.Data <- aa
> fl
An object of class "FLQuant"
, , sex = combined, season = all, area = all

   year
age 2000
  1    2

# Now, we want to do the same in C, to interface with existing code.
# However, the .Data slot is not being replaced with the new object


> dyn.load("C:/fl/flr/flr.dll")
> test<-function() .Call("Test")
> test()

An object of class "FLQuant":

, , sex = combined, season = all, area = all

   year
age 0
  0 1
> 

#C code to do the same thing
extern "C" __declspec(dllexport) SEXP __stdcall Test(void)
    {
    SEXP FLQuant, v, 
         d1, d2, d3, d4, d5,  
         dim,   dimnames, names;    

    //Create new S4 object    
    PROTECT(FLQuant = NEW_OBJECT(MAKE_CLASS("FLQuant")));

    //Create array for slot    
    //Set dimensions of array
    PROTECT(dim     = allocVector(INTSXP, 5));       
    INTEGER(dim)[0] = 1;
    INTEGER(dim)[1] = 1;
    INTEGER(dim)[2] = 1; 
    INTEGER(dim)[3] = 1; 
    INTEGER(dim)[4] = 1; 
        
    //Allocate memory
    PROTECT(v = Rf_allocArray(REALSXP, dim)); 
    
    //Create dimension names
    PROTECT(dimnames = allocVector(VECSXP, 5));
    
    PROTECT(d1 = allocVector(INTSXP, 1));
    INTEGER(d1)[0] = 1; 
    SET_VECTOR_ELT(dimnames, 0, d1);
    
    PROTECT(d2 = allocVector(INTSXP, 1));
    INTEGER(d2)[0] = 2000; 
    SET_VECTOR_ELT(dimnames, 1, d2);
     
    PROTECT(d3 = allocVector(STRSXP, 1));
    SET_STRING_ELT(d3, 0, mkChar("combined"));
    SET_VECTOR_ELT(dimnames, 2, d3);
    
    PROTECT(d4 = allocVector(STRSXP, 1));
    SET_STRING_ELT(d4, 0, mkChar("all"));
    SET_VECTOR_ELT(dimnames, 3, d4);
    
    PROTECT(d5 = allocVector(STRSXP, 1));
    SET_STRING_ELT(d5, 0, mkChar("all"));
    SET_VECTOR_ELT(dimnames, 4, d5);
    
    //Create names for dimensions
    PROTECT(names = allocVector(STRSXP, 5));
    SET_STRING_ELT(names, 0, mkChar("age"));
    SET_STRING_ELT(names, 1, mkChar("year"));
    SET_STRING_ELT(names, 2, mkChar("sex"));
    SET_STRING_ELT(names, 3, mkChar("season"));
    SET_STRING_ELT(names, 4, mkChar("area"));
    setAttrib(dimnames, R_NamesSymbol, names);
    setAttrib(v, R_DimNamesSymbol, dimnames);
    
    //Set data
    REAL(v)[0] = 2;
           
    //Set slot
    SET_SLOT(FLQuant, install(".Data"), v);

    UNPROTECT(10);
    
    return FLQuant;
    }


 




--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 1
 minor = 7.1
 year = 2003
 month = 06
 day = 16
 language = R

Windows 2000 Professional (build 2195) Service Pack 3.0

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg,
package:nls, package:ts, Autoloads, package:base

 <<Laurence Kell (E-mail).vcf>> 

------_=_NextPart_000_01C3738F.63DE3390
Content-Type: application/octet-stream;
	name="Laurence Kell (E-mail).vcf"
Content-Disposition: attachment;
	filename="Laurence Kell (E-mail).vcf"

BEGIN:VCARD
VERSION:2.1
N:Kell;Laurence
FN:Laurence Kell (E-mail)
ORG:CEFAS
TEL;WORK;VOICE:+44 (0) 1502 524257
TEL;WORK;FAX:+44 (0) 1502 524511
ADR;WORK:;;Lowestoft Laboratory;Pakefield Road;Lowestoft,;NR33 0HT;UK
LABEL;WORK;ENCODING=QUOTED-PRINTABLE:Lowestoft Laboratory=0D=0APakefield Road, Lowestoft, NR33 0HT=0D=0AUK
EMAIL;PREF;INTERNET:/o=CEFAS/ou=LOWESTOFT/cn=Recipients/cn=LTK00
REV:20030410T130517Z
END:VCARD

------_=_NextPart_000_01C3738F.63DE3390--

From colin at colinsmith.org  Fri Sep  5 12:55:04 2003
From: colin at colinsmith.org (colin@colinsmith.org)
Date: Fri Sep  5 11:54:29 2003
Subject: [Rd] S4 Method Collisions with "[" (PR#4075)
Message-ID: <200309050955.h859t4JH016010@pubhealth.ku.dk>

Full_Name: Colin A. Smith
Version: 1.8.0
OS: Mac OS X 10.2.6
Submission from: (NULL) (216.102.90.18)


Both Biobase and my package annaffy use S4 classes to define methods for "[".
Both packages use the save image method of installation. (See annaffy 1.0.3 in
BioC CVS.)

Depending on how both packages are loaded, the Biobase definitions seem to be
getting masked out:

> library(Biobase)
> library(annaffy)
> showMethods("[")

Function "[":
x = "ANY"
x = "container"
x = "phenoData"
x = "exprSet"
x = "aafList"
x = "aafTable"

> library(annaffy)
(annaffy loads Biobase in .First.lib)
> showMethods("[")

Function "[":
x = "ANY"
x = "aafList"
x = "aafTable"

From jmc at research.bell-labs.com  Fri Sep  5 10:00:42 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Fri Sep  5 15:01:03 2003
Subject: [Rd] S4 Method Collisions with "[" (PR#4075)
References: <200309050955.h859t4JH016010@pubhealth.ku.dk>
Message-ID: <3F5888FA.DE1C9A29@research.bell-labs.com>

colin@colinsmith.org wrote:
> 
> Full_Name: Colin A. Smith
> Version: 1.8.0
> OS: Mac OS X 10.2.6
> Submission from: (NULL) (216.102.90.18)
> 
> Both Biobase and my package annaffy use S4 classes to define methods for "[".
> Both packages use the save image method of installation. (See annaffy 1.0.3 in
> BioC CVS.)
> 
> Depending on how both packages are loaded, the Biobase definitions seem to be
> getting masked out:
> 
> > library(Biobase)
> > library(annaffy)
> > showMethods("[")
> 
> Function "[":
> x = "ANY"
> x = "container"
> x = "phenoData"
> x = "exprSet"
> x = "aafList"
> x = "aafTable"
> 
> > library(annaffy)
> (annaffy loads Biobase in .First.lib)

I'm not sure exactly what's happening, but with (or without) saved
images you should put a require(Biobase) _in the main source_ for the
library (in order to guarantee that it's there when setMethod(), etc.
calls are evaluated).  There is then no need to load it separately in
.First.lib.  I'm a little surprised this worked at all.

(We're trying to arrange that the source code for the package looks the
same as  it would if source'd directly into the global environment.)

> > showMethods("[")
> 
> Function "[":
> x = "ANY"
> x = "aafList"
> x = "aafTable"
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From duncan at research.bell-labs.com  Fri Sep  5 11:29:01 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Fri Sep  5 16:28:39 2003
Subject: [Rd] Problem with S4 slots in C code (PR#4073)
In-Reply-To: <200309050927.h859RDJH015529@pubhealth.ku.dk>;
	from L.T.Kell@cefas.co.uk on Fri, Sep 05, 2003 at 11:27:14AM +0200
References: <200309050927.h859RDJH015529@pubhealth.ku.dk>
Message-ID: <20030905102900.C6490@jessie.research.bell-labs.com>

In the case of the .Data slot, you will probably want to use 

 FLQuant = R_do_slot_assign(FLQuant, install(".Data"), v);

rather than SET_SLOT(). I am not certain if we have updated this
yet (and it is hard for me to check with very limited network access).




L.T.Kell@cefas.co.uk wrote:
> This message is in MIME format. Since your mail reader does not understand
> this format, some or all of this message may not be legible.
> 
> ------_=_NextPart_000_01C3738F.63DE3390
> Content-Type: text/plain;
> 	charset="iso-8859-1"
> 
> #I want to be able to create a new S4 class and read data into it using C
> code
> 
> # Here is a very simple S4 object inheriting from "array", but with 5
> specified dimensions 
> #(the validity stuff has been stripped out to make it short as I don't think
> it is the problem here)
> 
> setClass("FLQuant",
> 	representation("array"),
> 	prototype=(array(1, dim=c(1,1,1,1,1), dimnames=list(age="0",
> year="0", sex="combined", season="all", area="all")))
> )
> 
> # In R, I can create a new "FLQuant" object:
> > fl <- new("FLQuant")
> > fl
> An object of class "FLQuant"
> , , sex = combined, season = all, area = all
> 
>    year
> age 0
>   0 1
> 
> # and:
> > aa <- array(2, dim=c(1,1,1,1,1), dimnames=list(age="1", year="2000",
> sex="combined", season="all", area="all"))
> > aa
> , , sex = combined, season = all, area = all
> 
>    year
> age 2000
>   1    2
> 
> # Putting the array aa into fl is done like this (by the way, is this a
> correct way to do it?):
> > fl@.Data <- aa
> > fl
> An object of class "FLQuant"
> , , sex = combined, season = all, area = all
> 
>    year
> age 2000
>   1    2
> 
> # Now, we want to do the same in C, to interface with existing code.
> # However, the .Data slot is not being replaced with the new object
> 
> 
> > dyn.load("C:/fl/flr/flr.dll")
> > test<-function() .Call("Test")
> > test()
> 
> An object of class "FLQuant":
> 
> , , sex = combined, season = all, area = all
> 
>    year
> age 0
>   0 1
> > 
> 
> #C code to do the same thing
> extern "C" __declspec(dllexport) SEXP __stdcall Test(void)
>     {
>     SEXP FLQuant, v, 
>          d1, d2, d3, d4, d5,  
>          dim,   dimnames, names;    
> 
>     //Create new S4 object    
>     PROTECT(FLQuant = NEW_OBJECT(MAKE_CLASS("FLQuant")));
> 
>     //Create array for slot    
>     //Set dimensions of array
>     PROTECT(dim     = allocVector(INTSXP, 5));       
>     INTEGER(dim)[0] = 1;
>     INTEGER(dim)[1] = 1;
>     INTEGER(dim)[2] = 1; 
>     INTEGER(dim)[3] = 1; 
>     INTEGER(dim)[4] = 1; 
>         
>     //Allocate memory
>     PROTECT(v = Rf_allocArray(REALSXP, dim)); 
>     
>     //Create dimension names
>     PROTECT(dimnames = allocVector(VECSXP, 5));
>     
>     PROTECT(d1 = allocVector(INTSXP, 1));
>     INTEGER(d1)[0] = 1; 
>     SET_VECTOR_ELT(dimnames, 0, d1);
>     
>     PROTECT(d2 = allocVector(INTSXP, 1));
>     INTEGER(d2)[0] = 2000; 
>     SET_VECTOR_ELT(dimnames, 1, d2);
>      
>     PROTECT(d3 = allocVector(STRSXP, 1));
>     SET_STRING_ELT(d3, 0, mkChar("combined"));
>     SET_VECTOR_ELT(dimnames, 2, d3);
>     
>     PROTECT(d4 = allocVector(STRSXP, 1));
>     SET_STRING_ELT(d4, 0, mkChar("all"));
>     SET_VECTOR_ELT(dimnames, 3, d4);
>     
>     PROTECT(d5 = allocVector(STRSXP, 1));
>     SET_STRING_ELT(d5, 0, mkChar("all"));
>     SET_VECTOR_ELT(dimnames, 4, d5);
>     
>     //Create names for dimensions
>     PROTECT(names = allocVector(STRSXP, 5));
>     SET_STRING_ELT(names, 0, mkChar("age"));
>     SET_STRING_ELT(names, 1, mkChar("year"));
>     SET_STRING_ELT(names, 2, mkChar("sex"));
>     SET_STRING_ELT(names, 3, mkChar("season"));
>     SET_STRING_ELT(names, 4, mkChar("area"));
>     setAttrib(dimnames, R_NamesSymbol, names);
>     setAttrib(v, R_DimNamesSymbol, dimnames);
>     
>     //Set data
>     REAL(v)[0] = 2;
>            
>     //Set slot
>     SET_SLOT(FLQuant, install(".Data"), v);
> 
>     UNPROTECT(10);
>     
>     return FLQuant;
>     }
> 
> 
>  
> 
> 
> 
> 
> --please do not edit the information below--
> 
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status = 
>  major = 1
>  minor = 7.1
>  year = 2003
>  month = 06
>  day = 16
>  language = R
> 
> Windows 2000 Professional (build 2195) Service Pack 3.0
> 
> Search Path:
>  .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg,
> package:nls, package:ts, Autoloads, package:base
> 
>  <<Laurence Kell (E-mail).vcf>> 
> 
> ------_=_NextPart_000_01C3738F.63DE3390
> Content-Type: application/octet-stream;
> 	name="Laurence Kell (E-mail).vcf"
> Content-Disposition: attachment;
> 	filename="Laurence Kell (E-mail).vcf"
> 
> BEGIN:VCARD
> VERSION:2.1
> N:Kell;Laurence
> FN:Laurence Kell (E-mail)
> ORG:CEFAS
> TEL;WORK;VOICE:+44 (0) 1502 524257
> TEL;WORK;FAX:+44 (0) 1502 524511
> ADR;WORK:;;Lowestoft Laboratory;Pakefield Road;Lowestoft,;NR33 0HT;UK
> LABEL;WORK;ENCODING=QUOTED-PRINTABLE:Lowestoft Laboratory=0D=0APakefield Road, Lowestoft, NR33 0HT=0D=0AUK
> EMAIL;PREF;INTERNET:/o=CEFAS/ou=LOWESTOFT/cn=Recipients/cn=LTK00
> REV:20030410T130517Z
> END:VCARD
> 
> ------_=_NextPart_000_01C3738F.63DE3390--
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
_______________________________________________________________

Duncan Temple Lang                duncan@research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan

From jmc at research.bell-labs.com  Fri Sep  5 13:12:06 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Fri Sep  5 18:13:40 2003
Subject: [Rd] namespaces and S4 methods/classes
Message-ID: <3F58B5D6.23D704B@research.bell-labs.com>

The current version of the methods package now has a namespace. Packages
using S4 methods and classes can have NAMESPACE files.  New directives
can be included in NAMESPACE files to import and export classes and
methods.

Namespaces allow cleaner definition of the API for packages, and are
needed for future improvements to R.

NOTE: This is a major revision.  In principle, it should be back
compatible, and it passes the checks (on linux).  But approach with
caution, namespaces do change the language semantics, and we will likely
encounter some surprises.

The new directives, in addition to those described in Luke Tierney's
article in the June, 2003 R News, are:

exportClasses(...)
exportMethods(...)

importClassesFrom(package, ...)
importMethodsFrom(package, ...)

The `...' arguments are the names of classes or of generic functions
as appropriate.  The exportClasses and exportMethods directives export
the corresponding class definitions and all the methods for the
functions.  Similarly, the importClassesFrom and importMethodsFrom
import the class definitions and all the methods defined for the
functions.

This is a preliminary version, with several known deficiencies.  Here
are some points to note.

1.  Currently, NAMESPACE files  using methods must explicitly import
    the methods package, via the `import(methods)' directive.

2.  Private (i.e., non-exported) methods for primitive functions don't
    currently really work.  They don't appear explicitly, but are
    defined internally.  (This will be fixed, but needs a change in
    the way methods are dispatched for primitives.)

3.  Methods are exported all-or-nothing; it is not possible to export
    some of the methods for a function.  (Again, this will require a
    different mechanism than is currently used.)

    A related point is that the exported methods are only the methods
    defined in this package, not methods imported for the same
    function.  (As a result, it may still be necessary to require() a
    package even if there is an import() directive for it, so users
    will see all the methods.  This will probably change.)

4.  The NAMESPACE mechanism should work with or without a saved image
    from the INSTALL, but there may be subtleties not uncovered.  (As
    always with classes and methods, there is an efficiency advantage
    to using saved images.)

5.  The exported names from the methods package are quite liberal, but
    there may be some currently used functions that come up missing; let
    us know.  In the future the exports from the methods package will
    probably shrink, to make the API cleaner.

6.  An important change required by namespaces is that classes be
    directly identifiable as objects, not just the class name as a
    string.  The current version takes a first step by including the
    package name as an attribute in the class() value for objects with
    formal classes.  A better mechanism may be used later.

7.  There are some problems with debugging using namespaces.  At the
    moment, the trace() function has been instrumented to override
    locked bindings, but we don't guarantee this in the future.
    (However, some mechanism will be needed--it certainly was in
    debugging the changes so far.)

8.  In case of serious problems, you should be able to go back to a
    non-namespace version of the methods package by moving the
    NAMESPACE file in $R_HOME/src/library/methods, removing all.R and
    running make.  (At least, it works here.)


Here are examples of two package NAMESPACE files:  withNamespace and
withNamespace2, the latter using the former:

withNamespace/NAMESPACE:

import(methods)
export(f1, ng1)
exportMethods("[", initialize)
exportClasses(c1)

-----------------------
withNamespace2/NAMESPACE:

import(methods)
importFrom(withNamespace, ng1)
importClassesFrom(withNamespace, c1)
importMethodsFrom(withNamespace, f1, "[")
export(f4, f5, f1)
exportMethods(f6, "[", f1)
exportClasses(c1, c2)


-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From LISTSERV at nic.surfnet.nl  Sat Sep  6 05:59:14 2003
From: LISTSERV at nic.surfnet.nl (L-Soft list server at SURFnet (The Netherlands) (1.8e))
Date: Sat Sep  6 04:58:31 2003
Subject: [Rd] Message ("Your message dated Fri, 5 Sep 2003 22:59:13...")
Message-ID: <LISTSERV%2003090604591470@NIC.SURFNET.NL>

Your message dated Fri, 5 Sep 2003 22:59:13 --0400 with subject "Re: Thank
you!" has been  submitted to the moderator of the  TEX-NL list: "Jules van
Weerden, DIVA, VET, UU, NL" <Jules.vanWeerden@VET.UU.NL>.

From jmc at research.bell-labs.com  Sat Sep  6 10:40:45 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Sat Sep  6 15:41:01 2003
Subject: [Rd] S4 Method Collisions with "[" (PR#4075)
References: <200309050955.h859t4JH016010@pubhealth.ku.dk>
Message-ID: <3F59E3DD.121EFFAA@research.bell-labs.com>

We have a fix for this bug, which will be comitted, probably later
today.  Be aware until then that some
methods for primitive functions may turn up missing if one package
requires() another.  If you must use last night's version, a workaround
is to do

getAllMethods(f)

for the offending functions, e.g., "[", abter the library() call.

John

colin@colinsmith.org wrote:
> 
> Full_Name: Colin A. Smith
> Version: 1.8.0
> OS: Mac OS X 10.2.6
> Submission from: (NULL) (216.102.90.18)
> 
> Both Biobase and my package annaffy use S4 classes to define methods for "[".
> Both packages use the save image method of installation. (See annaffy 1.0.3 in
> BioC CVS.)
> 
> Depending on how both packages are loaded, the Biobase definitions seem to be
> getting masked out:
> 
> > library(Biobase)
> > library(annaffy)
> > showMethods("[")
> 
> Function "[":
> x = "ANY"
> x = "container"
> x = "phenoData"
> x = "exprSet"
> x = "aafList"
> x = "aafTable"
> 
> > library(annaffy)
> (annaffy loads Biobase in .First.lib)
> > showMethods("[")
> 
> Function "[":
> x = "ANY"
> x = "aafList"
> x = "aafTable"
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From ibanez at obs-vlfr.fr  Sat Sep  6 16:49:43 2003
From: ibanez at obs-vlfr.fr (ibanez@obs-vlfr.fr)
Date: Sat Sep  6 15:49:04 2003
Subject: [Rd] Frederic Ibanez absent de l'Observatoire (PR#4084)
Message-ID: <200309061349.h86DnhJH025911@pubhealth.ku.dk>

Je suis en conge jusqu'a la mi-Septembre; je prendrai connaissance
de votre message a mon retour.

                          F. Ibanez

From LISTSERV at MAN.TORUN.PL  Sat Sep  6 22:03:12 2003
From: LISTSERV at MAN.TORUN.PL (LISTSERV@MAN.TORUN.PL)
Date: Sat Sep  6 21:02:48 2003
Subject: [Rd] Message ("Your message dated Sat,
	6 Sep 2003 15:02:49...") (PR#4086)
Message-ID: <200309061903.h86J3CJH027110@pubhealth.ku.dk>

Your message dated Sat, 6 Sep 2003 15:02:49 --0400 with subject "Thank you!"
has  been  submitted  to  the  moderator of  the  GUST-L  list:  "jola  Sz."
<mjsz@MAN.TORUN.PL>.

From kohler at icir.org  Sat Sep  6 16:07:31 2003
From: kohler at icir.org (Eddie Kohler)
Date: Sun Sep  7 00:06:52 2003
Subject: [Rd] (no subject)
Message-ID: <200309062207.h86M7VFS091094@coyote.icir.org>

Hi,

This message was automatically generated: I'm away on vacation until
September 20, and will probably not respond to your message until after I
return.

Eddie

From ihaka at stat.auckland.ac.nz  Sun Sep  7 12:38:00 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Sun Sep  7 01:37:25 2003
Subject: [Rd] namespaces and S4 methods/classes
In-Reply-To: <3F58B5D6.23D704B@research.bell-labs.com>
References: <3F58B5D6.23D704B@research.bell-labs.com>
Message-ID: <3F5A6FD8.8010007@stat.auckland.ac.nz>

John Chambers wrote:
> The current version of the methods package now has a namespace. Packages
> using S4 methods and classes can have NAMESPACE files.  New directives
> can be included in NAMESPACE files to import and export classes and
> methods.

Looking good!  A couple of (quite possibly silly) questions:

1) I'm using a saved image for a package which creates new generics.
    Am I right in guessing that I use export() to make these generics
    available?

2) In the saved image case, would it make sense to export the generic,
    but not the methods - i.e., did the association of the methods with
    the generic happen pre-save?


-- 
Ross Ihaka                         Email:  ihaka@stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand

From iwhite at staffmail.ed.ac.uk  Sun Sep  7 18:01:00 2003
From: iwhite at staffmail.ed.ac.uk (iwhite@staffmail.ed.ac.uk)
Date: Sun Sep  7 17:00:21 2003
Subject: [Rd] bug in crossprod? (PR#4092)
Message-ID: <200309071501.h87F10JH001717@pubhealth.ku.dk>

# Your mailer is set to "none" (default on Windows),
# hence we cannot send the bug report directly from R.
# Please copy the bug report (after finishing it) to
# your favorite email program and send it to
#
#       r-bugs@r-project.org
#
######################################################

# The last line of following code produces a segmentation fault:

x <- 1:10
f <- gl(5,2)
mns <- tapply(x,f,mean)
crossprod(mns) #to get sum of squares of mns.
# Of course sum(mns^2) is more straightforward.


--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status =
 major = 1
 minor = 7.1
 year = 2003
 month = 06
 day = 16
 language = R

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg, package:nls, package:ts, Autoloads, package:base

======================================
I.White
ICAPB, University of Edinburgh
Ashworth Laboratories, West Mains Road
Edinburgh EH9 3JT
Fax: 0131 650 6564  Tel: 0131 650 5490
E-mail: iwhite@staffmail.ed.ac.uk

From dmurdoch at pair.com  Sun Sep  7 12:32:01 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun Sep  7 17:56:43 2003
Subject: [Rd] bug in crossprod? (PR#4092)
In-Reply-To: <200309071501.h87F10JH001717@pubhealth.ku.dk>
References: <200309071501.h87F10JH001717@pubhealth.ku.dk>
Message-ID: <2mjmlv44juqj79hau2ort8vlhpv7shbk10@4ax.com>

On Sun, 7 Sep 2003 17:01:00 +0200 (MET DST), you wrote:

># The last line of following code produces a segmentation fault:
>
>x <- 1:10
>f <- gl(5,2)
>mns <- tapply(x,f,mean)
>crossprod(mns) #to get sum of squares of mns.
># Of course sum(mns^2) is more straightforward.

This appears to have been fixed in r-devel:  I get 

> crossprod(mns) #to get sum of squares of mns.
Error in crossprod(mns) : invalid type for dimname (must be a vector)

If you really want the answer, you should use

 crossprod(as.matrix(mns))

since crossprod is documented to require a matrix argument.  This
works in 1.7.1 too.

Duncan Murdoch

From ligges at statistik.uni-dortmund.de  Sun Sep  7 19:15:18 2003
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Sun Sep  7 18:14:43 2003
Subject: [Rd] bug in crossprod? (PR#4092)
Message-ID: <200309071615.h87GFIJH002161@pubhealth.ku.dk>

Duncan Murdoch wrote:
> On Sun, 7 Sep 2003 17:01:00 +0200 (MET DST), you wrote:
> 
> 
>># The last line of following code produces a segmentation fault:
>>
>>x <- 1:10
>>f <- gl(5,2)
>>mns <- tapply(x,f,mean)
>>crossprod(mns) #to get sum of squares of mns.
>># Of course sum(mns^2) is more straightforward.
> 
> 
> This appears to have been fixed in r-devel:  I get 
> 
> 
>>crossprod(mns) #to get sum of squares of mns.
> 
> Error in crossprod(mns) : invalid type for dimname (must be a vector)


You get it sometimes - randomly, when R doesn't crash. The bug is still 
present in R-devel (2003-09-05).

Simple example:

  x <- array(1:2, dim=2)
  dimnames(x) <- list(1:2)
  crossprod(x)

The point is indeed in getting dimnames for one-dimensional arrays.


Uwe Ligges



> If you really want the answer, you should use
> 
>  crossprod(as.matrix(mns))
> 
> since crossprod is documented to require a matrix argument.  This
> works in 1.7.1 too.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From p.dalgaard at biostat.ku.dk  Sun Sep  7 17:18:08 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun Sep  7 18:18:11 2003
Subject: [Rd] bug in crossprod? (PR#4092)
In-Reply-To: <200309071501.h87F10JH001717@pubhealth.ku.dk>
References: <200309071501.h87F10JH001717@pubhealth.ku.dk>
Message-ID: <x2vfs4y3ih.fsf@biostat.ku.dk>

iwhite@staffmail.ed.ac.uk writes:

> # The last line of following code produces a segmentation fault:
> 
> x <- 1:10
> f <- gl(5,2)
> mns <- tapply(x,f,mean)
> crossprod(mns) #to get sum of squares of mns.
> # Of course sum(mns^2) is more straightforward.

Confirmed. Also (and the same thing, I believe)

> z <- array(rnorm(5),5)
> crossprod(z)
         [,1]
[1,] 1.778181
> dimnames(z) <- list(letters[1:5])
> z
         a          b          c          d          e
 0.2810906  0.3457800  0.3663940 -1.1312883  0.4068751
> crossprod(z)

Program received signal SIGSEGV, Segmentation fault.
0x08094d80 in Rf_duplicate (s=0x0) at
../../../R/src/main/duplicate.c:75
75          switch (TYPEOF(s)) {

I suspect the culprit is in the logic starting at line 610 in
src/main/array.c. ("Yes, x and y have dimnames, but not along the
direction we need them"). I can't quite seem to wrap my mind around it
just now though.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From dmurdoch at pair.com  Sun Sep  7 12:32:01 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun Sep  7 18:23:11 2003
Subject: [Rd] bug in crossprod? (PR#4092)
In-Reply-To: <200309071501.h87F10JH001717@pubhealth.ku.dk>
References: <200309071501.h87F10JH001717@pubhealth.ku.dk>
Message-ID: <2mjmlv44juqj79hau2ort8vlhpv7shbk10@4ax.com>

On Sun, 7 Sep 2003 17:01:00 +0200 (MET DST), you wrote:

># The last line of following code produces a segmentation fault:
>
>x <- 1:10
>f <- gl(5,2)
>mns <- tapply(x,f,mean)
>crossprod(mns) #to get sum of squares of mns.
># Of course sum(mns^2) is more straightforward.

This appears to have been fixed in r-devel:  I get 

> crossprod(mns) #to get sum of squares of mns.
Error in crossprod(mns) : invalid type for dimname (must be a vector)

If you really want the answer, you should use

 crossprod(as.matrix(mns))

since crossprod is documented to require a matrix argument.  This
works in 1.7.1 too.

Duncan Murdoch

From ibanez at obs-vlfr.fr  Sun Sep  7 21:45:16 2003
From: ibanez at obs-vlfr.fr (Frederic_Ibanez)
Date: Sun Sep  7 20:45:12 2003
Subject: [Rd] Frederic Ibanez absent de l'Observatoire
Message-ID: <200309071845.h87IjGK4032036@oceane.obs-vlfr.fr>

Je suis en conge jusqu'a la mi-Septembre; je prendrai connaissance
de votre message a mon retour.

                          F. Ibanez

From Graeme.Ambler at bristol.ac.uk  Mon Sep  8 15:57:48 2003
From: Graeme.Ambler at bristol.ac.uk (Graeme.Ambler@bristol.ac.uk)
Date: Mon Sep  8 14:57:15 2003
Subject: [Rd] Accuracy problems in summary()? (PR#4101)
Message-ID: <200309081257.h88CvmJH013213@pubhealth.ku.dk>

Full_Name: Graeme Ambler
Version: 1.7.1
OS: Red Hat Linux 9
Submission from: (NULL) (137.222.80.161)


There seems to be a curious accuracy-related problem in summary().  Try the
following:

test<-matrix(rnorm(2000),nc=2)
summary(test)
summary(test[,1])

The first use of summary() is fine.  The second will lie to you about the
accuracy to which numbers are displayed.  The results I got were:

> summary(test)
       X1                 X2
 Min.   :-2.68358   Min.   :-3.780882
 1st Qu.:-0.67451   1st Qu.:-0.721148
 Median : 0.01577   Median : 0.006311
 Mean   : 0.00644   Mean   :-0.022287
 3rd Qu.: 0.69642   3rd Qu.: 0.630215
 Max.   : 3.11174   Max.   : 2.827698
> summary(test[,1])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
-2.68400 -0.67450  0.01577  0.00644  0.69640  3.11200

Accuracy in the second case always seems to be 4SF, yet 6 are displayed in some
cases.  I have been able to reproduce this bug with 100% reliability.  Apologies
if this has been reported before, I couldn't find it when I searched.

From jmc at research.bell-labs.com  Mon Sep  8 10:00:12 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Mon Sep  8 15:00:46 2003
Subject: [Rd] setAs() and namespaces
Message-ID: <3F5C7D5C.CF72B52C@research.bell-labs.com>

An example sent by Ross Ihaka points out a non-obvious step needed to
export the results of setAs().

The as() mechanism can't use ordinary method dispatch because the second
argument is the name of a class, not an object from the class.  So it
uses a "helper" function, coerce(), and sets methods for that function.

Therefore, if you want to export the results of setAs(), at the moment
you will need to include
	exportMethods(coerce)
in the NAMESPACE file.

HOWEVER, this points out a general flaw in the current mechanism:  The
user is responsible for understanding what objects need to be exported. 
In general it would be more natural, I think, to block out sections of
source code and instruct the system "Export what gets created in THIS
code."  For example, one might embed the expressions in a call to an
export() function:
  export({
   .... whatever is meant to be public ...
  })

It appears at first glance that an export() function could operate
compatibly as an addition to the current mechanism.

John
-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From jmc at research.bell-labs.com  Mon Sep  8 10:31:20 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Mon Sep  8 15:31:41 2003
Subject: [Rd] namespaces and S4 methods/classes
References: <3F58B5D6.23D704B@research.bell-labs.com>
	<3F5A6FD8.8010007@stat.auckland.ac.nz>
Message-ID: <3F5C84A8.18C16AB7@research.bell-labs.com>

Ross Ihaka wrote:
> 
> John Chambers wrote:
> > The current version of the methods package now has a namespace. Packages
> > using S4 methods and classes can have NAMESPACE files.  New directives
> > can be included in NAMESPACE files to import and export classes and
> > methods.
> 
> Looking good!  A couple of (quite possibly silly) questions:
> 
> 1) I'm using a saved image for a package which creates new generics.
>     Am I right in guessing that I use export() to make these generics
>     available?

Yes.  The intent is that if you create f and methods for it, then EITHER
export(f) OR exportMethods(f) will export the generic and its methods. 
If f was a generic in another package, exportMethods(f) will just export
the methods defined in this package (that's the current model, but there
are some questions about what one really wants to do).

> 
> 2) In the saved image case, would it make sense to export the generic,
>     but not the methods - i.e., did the association of the methods with
>     the generic happen pre-save?

Currently, it's all or nothing:  Either you export the generic and its
methods or neither.

There are a couple of reasons.  First, the export/import information is
in the NAMESPACE file only, separate from the package source; so, the
mechanism is to evaluate all the package source and then export the
named objects.  Second, because only object names are used, there is
currently no mechanism to export a partial definition of the generic
(which is probably the way to think of the generic-only export:  Export
the generic as it's defined after the setGeneric() call but before some
setMethod() calls).

It's fairly likely the mechanism will be extended.  For one thing, it
seems necessary eventually to exclude methods that have private classes
in their signature.  Otherwise the exported generic has methods for
classes that are undefined.

For example, suppose "a" is an exported class and "b" a private class in
the same package and both have methods for "[":
  setClass("a", ....)
  setMethod("[", "a", .....)
  setClass("b", ....)
  setMethod("[", "b", .....)

To export the full definition of class "a" one needs exportMethods("[")
in the NAMESPACE file.  But at the moment, this exports the method for
"b" as well.

Fixing such problems may be related to allowing export() to be
associated with source code rather than with explicit objects, as
mentioned earlier.  In the above example, the first two lines would be
in an export() but the other two lines would not.  (There are some
implementation questions here, of course.)

John

> 
> --
> Ross Ihaka                         Email:  ihaka@stat.auckland.ac.nz
> Department of Statistics           Phone:  (64-9) 373-7599 x 85054
> University of Auckland             Fax:    (64-9) 373-7018
> Private Bag 92019, Auckland
> New Zealand

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From maechler at stat.math.ethz.ch  Mon Sep  8 17:09:58 2003
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Mon Sep  8 16:09:20 2003
Subject: [Rd] Accuracy problems in summary()? (PR#4101)
Message-ID: <200309081409.h88E9wJH014548@pubhealth.ku.dk>

A bug report with a "?" is **wrong**, almost by definition!
(and your definitely is).

Please ask questions on R-help.
And this has become almost a FAQ.

Note that sending bug-reports for non-bugs can be quite
counter-productive.  The waste of time it produces to R
developers will not improve the quality of development nor
answers...

(yes, I'm grouchy.....)

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

From pgilbert at bank-banque-canada.ca  Mon Sep  8 14:45:38 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon Sep  8 19:45:59 2003
Subject: [Rd] pacf lags
Message-ID: <3F5CC042.9010703@bank-banque-canada.ca>

pacf  in  devel seems by default to return a different number of lags 
than 1.7.1 for  $pacf. I don't see any mention of this in the NEWS file, 
or any change in the documentation,  so I suspect it is and error, 
though it may be an undocumented improvement.

(Newbie question:  How is the simplest way to display a function like 
pacf.default that is not exported from a namespace?)

Paul Gilbert

From rpeng at jhsph.edu  Mon Sep  8 15:11:22 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon Sep  8 20:11:55 2003
Subject: [Rd] pacf lags
In-Reply-To: <3F5CC042.9010703@bank-banque-canada.ca>
References: <3F5CC042.9010703@bank-banque-canada.ca>
Message-ID: <3F5CC64A.1070501@jhsph.edu>

Try (in R-devel)

getAnywhere("pacf.default")

or even

ts:::pacf.default

-roger

Paul Gilbert wrote:

> pacf  in  devel seems by default to return a different number of lags 
> than 1.7.1 for  $pacf. I don't see any mention of this in the NEWS 
> file, or any change in the documentation,  so I suspect it is and 
> error, though it may be an undocumented improvement.
>
> (Newbie question:  How is the simplest way to display a function like 
> pacf.default that is not exported from a namespace?)
>
> Paul Gilbert
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

-- 
Together, we can stop attaching Word documents
http://www.fsf.org/philosophy/no-word-attachments.html

From jgentry at jimmy.harvard.edu  Mon Sep  8 17:13:36 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Mon Sep  8 22:13:04 2003
Subject: [Rd] R-devel on Solaris 8
Message-ID: <Pine.SOL.4.20.0309081609170.6125-100000@santiam.dfci.harvard.edu>

I'm having difficulty building R-devel on Solaris 8 (current version),
while trying to update from my previous version of R-devel (2003-09-02).

When building I get this error:
---------------
make[4]: Leaving directory
`/misc/homes/madman/R-devel/src/library/methods/src'
make[4]: Entering directory
`/misc/homes/madman/R-devel/src/library/methods'
dumping R code in package 'methods'
Saving namespace image ... 
initializing class and method definitions now ...done
<environment: namespace:methods>

/bin/bash: ../../../tools/install-sh: No such file or directory
make[4]: *** [../../../library/methods/R/all.rda] Error 127
make[4]: Leaving directory
`/misc/homes/madman/R-devel/src/library/methods'
make[3]: *** [all] Error 2
make[3]: Leaving directory
`/misc/homes/madman/R-devel/src/library/methods'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/misc/homes/madman/R-devel/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/misc/homes/madman/R-devel/src'
make: *** [R] Error 1


-----

At first I thought perhaps a 'make clean' was in order, but it still
persisted.  Then I tired a 'make distclean', and finally just doing a
rsync to a completely new directory target and trying it there.  The same
error keeps coming up.

GCC is version 3.2

I have built the same R-devel on linux (RH 7.2) wiht gcc 2.96

Not sure if this is something particular to my setup or a problem in R,
but hopefully someone out there has some insight.

Thanks
-J

From pgilbert at bank-banque-canada.ca  Mon Sep  8 18:07:02 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon Sep  8 23:07:25 2003
Subject: [Rd] pacf lags
In-Reply-To: <3F5CCB41.6040507@bank-banque-canada.ca>
References: <3F5CC042.9010703@bank-banque-canada.ca>
	<3F5CCB41.6040507@bank-banque-canada.ca>
Message-ID: <3F5CEF76.4080909@bank-banque-canada.ca>

Looking even more carefully, it seems both sampleT and the lag.max 
correction for nser need to be fixed:

    sampleT <- if (is.matrix(x)) nrow(x) else length(x)
    if (is.null(lag.max)) lag.max <- floor(10 * 
             (log10(sampleT) - if (is.matrix(x)) log10(ncol(x)) else 0))


Paul Gilbert

Paul Gilbert wrote:

> On further examination, it looks like
>  sampleT <- length(x)
> in pacf.default is not handling the matrix case properly and probably 
> needs to be replaced by something like
>  sampleT <- if (is.matrix(x)) nrow(x) else length(x)
>
> Paul Gilbert
> Paul Gilbert wrote:
>
>> pacf  in  devel seems by default to return a different number of lags 
>> than 1.7.1 for  $pacf. I don't see any mention of this in the NEWS 
>> file, or any change in the documentation,  so I suspect it is and 
>> error, though it may be an undocumented improvement.
>>
>> (Newbie question:  How is the simplest way to display a function like 
>> pacf.default that is not exported from a namespace?)
>>
>> Paul Gilbert
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>
>

From jmc at research.bell-labs.com  Tue Sep  9 09:50:54 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Tue Sep  9 14:51:47 2003
Subject: [Rd] R-devel on Solaris 8
References: <Pine.SOL.4.20.0309081609170.6125-100000@santiam.dfci.harvard.edu>
Message-ID: <3F5DCCAE.27B94AFC@research.bell-labs.com>

Jeff Gentry wrote:
> 
> I'm having difficulty building R-devel on Solaris 8 (current version),
> while trying to update from my previous version of R-devel (2003-09-02).
> 
> When building I get this error:
> ---------------
> make[4]: Leaving directory
> `/misc/homes/madman/R-devel/src/library/methods/src'
> make[4]: Entering directory
> `/misc/homes/madman/R-devel/src/library/methods'
> dumping R code in package 'methods'
> Saving namespace image ...
> initializing class and method definitions now ...done
> <environment: namespace:methods>
> 
> /bin/bash: ../../../tools/install-sh: No such file or directory
> make[4]: *** [../../../library/methods/R/all.rda] Error 127
> make[4]: Leaving directory
> `/misc/homes/madman/R-devel/src/library/methods'
> make[3]: *** [all] Error 2
> make[3]: Leaving directory
> `/misc/homes/madman/R-devel/src/library/methods'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/misc/homes/madman/R-devel/src/library'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/misc/homes/madman/R-devel/src'
> make: *** [R] Error 1
> 
> -----
> 
> At first I thought perhaps a 'make clean' was in order, but it still
> persisted.  Then I tired a 'make distclean', and finally just doing a
> rsync to a completely new directory target and trying it there.  The same
> error keeps coming up.
> 
> GCC is version 3.2
> 
> I have built the same R-devel on linux (RH 7.2) wiht gcc 2.96
> 
> Not sure if this is something particular to my setup or a problem in R,
> but hopefully someone out there has some insight.

The Makefile.in for methods uses the macro INSTALL_DATA.  On linux this
is /usr/bin/install, but my guess from your error message is that it's
$(top_buildir)/tools/install-sh

For reasons that pre-date my involvement, $(top_buildir) is a relative
not an absolute path.  Hence my guess is that for solaris you need to
add a line "cd $(srcdir); \ " after line 76 in Makefile.in.  If this
works, let me know & I'll make the change generally.

John

> 
> Thanks
> -J
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From maechler at stat.math.ethz.ch  Tue Sep  9 16:09:34 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue Sep  9 15:09:07 2003
Subject: [Rd] Accuracy problems in summary()?  (PR#4101)
In-Reply-To: <200309081409.h88E9wJH014548@pubhealth.ku.dk>
References: <200309081409.h88E9wJH014548@pubhealth.ku.dk>
Message-ID: <16221.53518.247626.318443@gargle.gargle.HOWL>

>>>>> "MM" == Martin Maechler <maechler@stat.math.ethz.ch>
>>>>>     on Mon, 8 Sep 2003 16:09:58 +0200 (MET DST) writes:

    MM> A bug report with a "?" is **wrong**, almost by
    MM> definition!  

I was wrong here.  As Grame has pointed out (privately), the "?"
can well be used to indicate that it's not clear  *where* the
bug is. 

    MM> (and your definitely is).

because  help(summary)  really tells you about the `digits ='
argument which is applied with some inconsistency in the
different summary() methods.
The reason for this has been S(-plus) compatibility that we
didn't want to drop too quickly.

    MM> Please ask questions on R-help.

or proposals about changing R behavior on R-devel.
I think there's a point here that could be discussed: Changing
current behavior while trying to remain S compatible as much as
possible.

    MM>   And this has become  almost a FAQ.
an exaggeration.
But people have been told quite a few times to use something
like  summary(*, digits = 7) if they wanted different behavior.

    MM> Note that sending bug-reports for non-bugs can be quite
    MM> counter-productive.  The waste of time it produces to R
    MM> developers will not improve the quality of development
    MM> nor answers...

    MM> (yes, I'm grouchy.....)

and hereby apologize to Graeme.
Martin

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

From THEREALBLACKFREAKS-owner at yahoogroups.com  Tue Sep  9 15:28:53 2003
From: THEREALBLACKFREAKS-owner at yahoogroups.com (THEREALBLACKFREAKS Moderator)
Date: Tue Sep  9 16:28:58 2003
Subject: [Rd] Welcome to THEREALBLACKFREAKS 
Message-ID: <1063117755.606.98301.w18@yahoogroups.com>


Hello,

Welcome to the THEREALBLACKFREAKS group at Yahoo! Groups, a 
free, easy-to-use email group service. Please 
take a moment to review this message.

To learn more about the THEREALBLACKFREAKS group, please visit
http://groups.yahoo.com/group/THEREALBLACKFREAKS

To start sending messages to members of this group, simply 
send email to
THEREALBLACKFREAKS@yahoogroups.com

If you do not wish to belong to THEREALBLACKFREAKS, you may 
unsubscribe by sending an email to 
THEREALBLACKFREAKS-unsubscribe@yahoogroups.com

To see and modify all of your groups, go to



Regards,

Moderator, THEREALBLACKFREAKS

 


Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/

From richard_raubertas at merck.com  Tue Sep  9 17:54:03 2003
From: richard_raubertas at merck.com (richard_raubertas@merck.com)
Date: Tue Sep  9 16:53:27 2003
Subject: [Rd] Problem with 'drop' for 1-D arrays? (PR#4110)
Message-ID: <200309091454.h89Es3JH029307@pubhealth.ku.dk>

R 1.7.1 on Windows XP

The argument 'drop' appears to be ignored when subscripting
1-dimensional arrays (i.e., arrays whose 'dim' attribute has 
length 1):

> x <- array(1:5, dim=c(5))
> dim(x)
[1] 5
> dim(x[, drop=TRUE])   # Shouldn't this be NULL?
[1] 5
> dim(x[2:3])  # This seems right:  default is drop=TRUE
NULL
> dim(x[2:3, drop=FALSE])  # But this seems wrong
NULL

Note that the behavior with a 2-D array is different:

> y <- array(1:5, dim=c(1,5))
> dim(y)
[1] 1 5
> dim(y[,,drop=TRUE])
NULL
> dim(y[,2:3])
NULL
> dim(y[,2:3,drop=FALSE])
[1] 1 2

Rich Raubertas
Biometrics Research, RY33-300
Merck & Co.

------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}

From confirm-unsub-OMT9O0OS__pd9q7ebXY82kCPazI at yahoogroups.com  Tue Sep  9 21:51:26 2003
From: confirm-unsub-OMT9O0OS__pd9q7ebXY82kCPazI at yahoogroups.com (Yahoo! Groups Notification)
Date: Tue Sep  9 22:51:28 2003
Subject: [Rd] Please reply to unsubscribe from THEREALBLACKFREAKS 
Message-ID: <1063140726.700.16018.m17@yahoogroups.com>


Hello,

We have received a request from you to unsubscribe from the
THEREALBLACKFREAKS group.  Please confirm your request by 
replying to this message.  If you do not wish to unsubscribe from 
THEREALBLACKFREAKS, please ignore this message.

Regards,

Yahoo! Groups Customer Care

Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/

From notify at yahoogroups.com  Wed Sep 10 00:53:01 2003
From: notify at yahoogroups.com (Yahoo! Groups Notification)
Date: Wed Sep 10 01:53:08 2003
Subject: [Rd] You have been unsubscribed from THEREALBLACKFREAKS 
Message-ID: <1063151615.313.24436.m2@yahoogroups.com>


Hello,

This is to inform you that your request to unsubscribe from
THEREALBLACKFREAKS has been completed.

Regards,

Yahoo! Groups Customer Care

Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/

From ririzarr at jhsph.edu  Wed Sep 10 02:05:23 2003
From: ririzarr at jhsph.edu (Rafael A. Irizarry)
Date: Wed Sep 10 07:03:19 2003
Subject: [Rd] sweave problem
Message-ID: <Pine.GSO.4.10.10309100052470.26074-100000@athena.biostat.jhsph.edu>

hi!

using:
Version 1.8.0 Under development (unstable) (2003-09-02)

using the Sweave function of the tools package i get this error when
latexing with texi2dvi --pdf

! LaTeX Error: File `upquote.sty' not found.

if i change the line
\usepackage{/users/faculty/ririzarr/R-1.8.0/lib/R/share/texmf/Sweave}
to
\usepackage{/users/faculty/ririzarr/R-1.7.1/lib/R/share/texmf/Sweave}

in the tex file, then the file compiles fine.


this happens to me in both redhat 7.3 and solaris 8.

From Friedrich.Leisch at ci.tuwien.ac.at  Wed Sep 10 10:35:48 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Wed Sep 10 09:35:10 2003
Subject: [Rd] sweave problem
In-Reply-To: <Pine.GSO.4.10.10309100052470.26074-100000@athena.biostat.jhsph.edu>
References: <Pine.GSO.4.10.10309100052470.26074-100000@athena.biostat.jhsph.edu>
Message-ID: <16222.54356.666958.868671@galadriel.ci.tuwien.ac.at>

>>>>> On Wed, 10 Sep 2003 01:05:23 -0400 (EDT),
>>>>> Rafael A Irizarry (RAI) wrote:

  > hi!
  > using:
  > Version 1.8.0 Under development (unstable) (2003-09-02)

  > using the Sweave function of the tools package i get this error when
  > latexing with texi2dvi --pdf

  > ! LaTeX Error: File `upquote.sty' not found.

  > if i change the line
  > \usepackage{/users/faculty/ririzarr/R-1.8.0/lib/R/share/texmf/Sweave}
  > to
  > \usepackage{/users/faculty/ririzarr/R-1.7.1/lib/R/share/texmf/Sweave}

  > in the tex file, then the file compiles fine.


  > this happens to me in both redhat 7.3 and solaris 8.


Should be OK if you use a newer version, this was fixed on 2003-09-03,
i.e., a week ago.

best,
fritz

From p.dalgaard at biostat.ku.dk  Wed Sep 10 17:17:24 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Sep 10 18:17:27 2003
Subject: [Rd] R 1.8.0 alpha
Message-ID: <x2pti8wr83.fsf@biostat.ku.dk>

The countdown to R version 1.8.0 has begun. As a novelty, we now
make preliminary source tarballs available somewhat earlier in the
process. They will be found in

http://cran.us.r-project.org/src/base 

with names of the form  R-1.8.0alpha_2003-09-10.tar.gz 

The first one was created a moment ago; subsequent ones will be
created by a cron job that runs at 05:00 local (Wisconsin) time.

There are still a couple of problems with these versions, but we
expect that there should be no major changes between now and release
time. 

If you have "esoteric" platforms, it is particularly important that
you give us feedback about build issues as soon as you can. Much
better to fix problems before the release than to have to patch things
up immediately after release.

Daily snapshots are available as usual, but even if you check these,
it would be helpful if you could try building from the tarballs since
some potential packaging errors can only be caught that way.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From M.Wellenreuther at auckland.ac.nz  Thu Sep 11 10:36:21 2003
From: M.Wellenreuther at auckland.ac.nz (Maren Wellenreuther)
Date: Wed Sep 10 23:35:41 2003
Subject: [Rd] zero inflated models
Message-ID: <1063229781.3f5f9955caa1d@www2.auckland.ac.nz>

Does anybody now of a ready-made ZIP/ZINB (zero inflated poisson model, zero 
inflated negative binominal model) package for R?

-------------------------------------------------------
                                ,///,       
                             <')<:::>{
                                  ``
Maren Wellenreuther
Marine Biology Research Group
School of Biological Sciences
Level 1
University of Auckland
Private Bag 92019
Auckland, New Zealand
Phone: +64 9 3737599 ext 88483
Mobile 027 4804023

http://www2.auckland.ac.nz/leigh//Students/marenw/
http://www.adelaide.edu.au/sciences/env_biol/research/marine/marinepast.html

From rossini at blindglobe.net  Wed Sep 10 16:34:20 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu Sep 11 00:37:01 2003
Subject: [Rd] potentially nasty interaction between R 1.8.0 and tetex
Message-ID: <854qzkjms3.fsf@blindglobe.net>


I've been having problems building vignettes in bioconductor packages
with R-devel.  Turns out that Rdevel/share/texmf/hyperref.cfg wants
Blue and Red predefined, when only blue and red are defined (as of
rsync Rdevel, Sept 10th).  This is on a Debian unstable system (Sept
9th version).  Might not apply to all other tetex systems.  Seems to
have bitten the bioconductor build system, though.

Symptom:  


512$ R CMD build --force Biobase
* checking for file 'Biobase/DESCRIPTION' ... OK
* preparing 'Biobase':
* checking whether 'INDEX' is up-to-date ... OK
* creating vignettes ... ERROR
/usr/lib/R/bin/texi2dvi: pdflatex exited with bad status, quitting.
/usr/lib/R/bin/texi2dvi: see Bioconductor.log for errors.
Error in buildVignettes(dir = ".") : running texi2dvi on
Bioconductor.tex failed
Execution halted



Change produces: 

517$ R CMD build --force Biobase
* checking for file 'Biobase/DESCRIPTION' ... OK
* preparing 'Biobase':
* checking whether 'INDEX' is up-to-date ... OK
* creating vignettes ... OK
* removing junk files
* building 'Biobase_1.3.31.tar.gz'


YMMV.

best,
-tony

-- 
A.J. Rossini     			
rossini@u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW   :              FAX=206-543-3461 | moving soon to a permanent office
FHCRC: 206-667-7025 FAX=206-667-4812 | Voicemail is pretty sketchy/use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}

From p.dalgaard at biostat.ku.dk  Thu Sep 11 00:12:53 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Sep 11 01:13:12 2003
Subject: [Rd] potentially nasty interaction between R 1.8.0 and tetex
In-Reply-To: <854qzkjms3.fsf@blindglobe.net>
References: <854qzkjms3.fsf@blindglobe.net>
Message-ID: <x2brtsi6b6.fsf@biostat.ku.dk>

rossini@blindglobe.net (A.J. Rossini) writes:

> I've been having problems building vignettes in bioconductor packages
> with R-devel.  Turns out that Rdevel/share/texmf/hyperref.cfg wants
> Blue and Red predefined, when only blue and red are defined (as of
> rsync Rdevel, Sept 10th).  This is on a Debian unstable system (Sept
> 9th version).  Might not apply to all other tetex systems.  Seems to
> have bitten the bioconductor build system, though.
> 
> Symptom:  
> 
> 
> 512$ R CMD build --force Biobase
> * checking for file 'Biobase/DESCRIPTION' ... OK
> * preparing 'Biobase':
> * checking whether 'INDEX' is up-to-date ... OK
> * creating vignettes ... ERROR
> /usr/lib/R/bin/texi2dvi: pdflatex exited with bad status, quitting.
> /usr/lib/R/bin/texi2dvi: see Bioconductor.log for errors.
> Error in buildVignettes(dir = ".") : running texi2dvi on
> Bioconductor.tex failed
> Execution halted
> 
> 
> 
> Change produces: 
> 
> 517$ R CMD build --force Biobase
> * checking for file 'Biobase/DESCRIPTION' ... OK
> * preparing 'Biobase':
> * checking whether 'INDEX' is up-to-date ... OK
> * creating vignettes ... OK
> * removing junk files
> * building 'Biobase_1.3.31.tar.gz'

Change being Blue --> blue, Red --> red in hyperref.cfg I presume? Odd
thing is that it doesn't happen with RedHat 8.0 tetex and ordinary
"make pdf". Shouldn't the hyperlinks in the manuals have the same
problem?

BTW, this uncovered another problem in that "make pdf" didn't work
when srcdir != builddir because of

$(texinputs_BASE): FORCE $(top_srcdir)/share/perl/build-help.pl

but configure makes $(top_builddir)/share/perl/build-help.pl from a
.in file

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From rossini at blindglobe.net  Wed Sep 10 17:21:03 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu Sep 11 01:20:37 2003
Subject: [Rd] potentially nasty interaction between R 1.8.0 and tetex
In-Reply-To: <x2brtsi6b6.fsf@biostat.ku.dk> (Peter Dalgaard's message of "11
	Sep 2003 01:15:25 +0200")
References: <854qzkjms3.fsf@blindglobe.net> <x2brtsi6b6.fsf@biostat.ku.dk>
Message-ID: <85znhci61s.fsf@blindglobe.net>

Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk> writes:

> Change being Blue --> blue, Red --> red in hyperref.cfg I presume? Odd
> thing is that it doesn't happen with RedHat 8.0 tetex and ordinary
> "make pdf". Shouldn't the hyperlinks in the manuals have the same
> problem?

I'm not sure what is called in the case you mention.

Note that this doesn't happen if one uses texi2dvi from the command
line, either, which is how I traced it down when comparing output in
the tex log files.

(i.e. the inclusion of the RHOME/share/texmf/hyperref.cfg from "R CMD
build" and not present when using RHOME/bin/texi2dvi).

best,
-tony


-- 
A.J. Rossini     			
rossini@u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW   :              FAX=206-543-3461 | moving soon to a permanent office
FHCRC: 206-667-7025 FAX=206-667-4812 | Voicemail is pretty sketchy/use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}

From maechler at stat.math.ethz.ch  Thu Sep 11 11:12:13 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Sep 11 10:12:00 2003
Subject: [Rd] rank(*) with NAs -- new option "keep" desired
Message-ID: <16224.11869.73261.54205@gargle.gargle.HOWL>

In some contexts, I find the current behavior of rank() very
`suboptimal'.

We have the argument na.last = {TRUE | FALSE | NA }
where the first two cases treating NAs (almost) as if they were
 == +Inf or == -Inf  whereas the 3rd case just drops NAs.
For the typical ``Rank Transformation'' that is recommended in
EDA in several contexts, I would however want something else,
namely keep the NAs !

An example -- including the new option as I'm proposing it ---
makes things more clear :

> y <- c(2:1,NA,0)
> rank(y, na.last = TRUE)## ==== rank(y)
[1] 3 2 4 1
> rank(y, na.last = FALSE)
[1] 4 3 1 2
> rank(y, na.last = NA)
[1] 3 2 1
> rank(y, na.last = "keep") ### <<<<< NEW >>
[1]  3  2 NA  1
> 
---

Alternatively to extending the possible values of `na.last' I
first thought of a new (boolean) argument, but found the current
solution less ugly.

Feedback welcome!

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

PS: Stumbled over this while implementing  cor.test()s
    method = c("pearson", "spearman", "kendall")  for  cor()
    itself.

From Friedrich.Leisch at ci.tuwien.ac.at  Thu Sep 11 11:20:46 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Thu Sep 11 10:20:19 2003
Subject: [Rd] potentially nasty interaction between R 1.8.0 and tetex
In-Reply-To: <85znhci61s.fsf@blindglobe.net>
References: <854qzkjms3.fsf@blindglobe.net> <x2brtsi6b6.fsf@biostat.ku.dk>
	<85znhci61s.fsf@blindglobe.net>
Message-ID: <16224.12382.97450.735140@galadriel.ci.tuwien.ac.at>

>>>>> On Wed, 10 Sep 2003 16:21:03 -0700,
>>>>> A J Rossini (AJR) wrote:

  > Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk> writes:
  >> Change being Blue --> blue, Red --> red in hyperref.cfg I presume? Odd
  >> thing is that it doesn't happen with RedHat 8.0 tetex and ordinary
  >> "make pdf". Shouldn't the hyperlinks in the manuals have the same
  >> problem?

  > I'm not sure what is called in the case you mention.

  > Note that this doesn't happen if one uses texi2dvi from the command
  > line, either, which is how I traced it down when comparing output in
  > the tex log files.

  > (i.e. the inclusion of the RHOME/share/texmf/hyperref.cfg from "R CMD
  > build" and not present when using RHOME/bin/texi2dvi).

Hmm, we have this definition of hyperref.cfg since 1.5.0, i.e., quite
some time now. I'm not sure if we really should change anything if
problems are only on Debian unstable machines. I have Debian testing
and that works fine.

.f

From p.dalgaard at biostat.ku.dk  Thu Sep 11 09:31:39 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Sep 11 10:31:40 2003
Subject: [Rd] potentially nasty interaction between R 1.8.0 and tetex
In-Reply-To: <16224.12382.97450.735140@galadriel.ci.tuwien.ac.at>
References: <854qzkjms3.fsf@blindglobe.net> <x2brtsi6b6.fsf@biostat.ku.dk>
	<85znhci61s.fsf@blindglobe.net>
	<16224.12382.97450.735140@galadriel.ci.tuwien.ac.at>
Message-ID: <x2n0dbwwuo.fsf@biostat.ku.dk>

Friedrich.Leisch@ci.tuwien.ac.at writes:

> >>>>> On Wed, 10 Sep 2003 16:21:03 -0700,
> >>>>> A J Rossini (AJR) wrote:
> 
>   > Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk> writes:
>   >> Change being Blue --> blue, Red --> red in hyperref.cfg I presume? Odd
>   >> thing is that it doesn't happen with RedHat 8.0 tetex and ordinary
>   >> "make pdf". Shouldn't the hyperlinks in the manuals have the same
>   >> problem?
> 
>   > I'm not sure what is called in the case you mention.
> 
>   > Note that this doesn't happen if one uses texi2dvi from the command
>   > line, either, which is how I traced it down when comparing output in
>   > the tex log files.
> 
>   > (i.e. the inclusion of the RHOME/share/texmf/hyperref.cfg from "R CMD
>   > build" and not present when using RHOME/bin/texi2dvi).
> 
> Hmm, we have this definition of hyperref.cfg since 1.5.0, i.e., quite
> some time now. I'm not sure if we really should change anything if
> problems are only on Debian unstable machines. I have Debian testing
> and that works fine.

We'd probably want to take a closer look at what the issue really is,
including teTeX version numbers. It could be a permanent change in
teTeX v2+ in which case we're going to see the effect all over the
place as it gets into major Linux distros, or it could be an
installation problem with Debian-unstable which should go away. 

Then again, does "blue" and "Blue" really do different things? In a
"no-op or fix" situation, we might choose to do the change...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Friedrich.Leisch at ci.tuwien.ac.at  Thu Sep 11 12:00:13 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Thu Sep 11 10:59:35 2003
Subject: [Rd] potentially nasty interaction between R 1.8.0 and tetex
In-Reply-To: <x2n0dbwwuo.fsf@biostat.ku.dk>
References: <854qzkjms3.fsf@blindglobe.net> <x2brtsi6b6.fsf@biostat.ku.dk>
	<85znhci61s.fsf@blindglobe.net>
	<16224.12382.97450.735140@galadriel.ci.tuwien.ac.at>
	<x2n0dbwwuo.fsf@biostat.ku.dk>
Message-ID: <16224.14749.151458.714484@galadriel.ci.tuwien.ac.at>

>>>>> On 11 Sep 2003 10:30:39 +0200,
>>>>> Peter Dalgaard BSA (PDB) wrote:

  > Friedrich.Leisch@ci.tuwien.ac.at writes:
  >> >>>>> On Wed, 10 Sep 2003 16:21:03 -0700,
  >> >>>>> A J Rossini (AJR) wrote:
  >> 
  >> > Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk> writes:
  >> >> Change being Blue --> blue, Red --> red in hyperref.cfg I presume? Odd
  >> >> thing is that it doesn't happen with RedHat 8.0 tetex and ordinary
  >> >> "make pdf". Shouldn't the hyperlinks in the manuals have the same
  >> >> problem?
  >> 
  >> > I'm not sure what is called in the case you mention.
  >> 
  >> > Note that this doesn't happen if one uses texi2dvi from the command
  >> > line, either, which is how I traced it down when comparing output in
  >> > the tex log files.
  >> 
  >> > (i.e. the inclusion of the RHOME/share/texmf/hyperref.cfg from "R CMD
  >> > build" and not present when using RHOME/bin/texi2dvi).
  >> 
  >> Hmm, we have this definition of hyperref.cfg since 1.5.0, i.e., quite
  >> some time now. I'm not sure if we really should change anything if
  >> problems are only on Debian unstable machines. I have Debian testing
  >> and that works fine.

  > We'd probably want to take a closer look at what the issue really
  > is,

yes, definitely

  > including teTeX version numbers. It could be a permanent change in
  > teTeX v2+ in which case we're going to see the effect all over the
  > place as it gets into major Linux distros, or it could be an
  > installation problem with Debian-unstable which should go away. 

  > Then again, does "blue" and "Blue" really do different things?

probably not

  > In a
  > "no-op or fix" situation, we might choose to do the change...

I don't know ... the problem is that it is the first time we see this,
and I'd like to avoid that "blue" works for us, we put it in and then
it doesn't work on a lot of other systems. 

My system has:

galadriel:Leisch$ dpkg -l tetex*
ii  tetex-base     2.0.2-4.1      basic teTeX library files
ii  tetex-bin      2.0.2-4.2      teTeX binary files
ii  tetex-doc      2.0.2-4.1      teTeX documentation
ii  tetex-extra    2.0.2-4.1      extra teTeX library files



.f

From dmurdoch at pair.com  Thu Sep 11 10:27:59 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu Sep 11 15:23:17 2003
Subject: [Rd] R 1.8.0 alpha
In-Reply-To: <x2pti8wr83.fsf@biostat.ku.dk>
References: <x2pti8wr83.fsf@biostat.ku.dk>
Message-ID: <qqt0mv8ppn9psvuk80e823hdvds8fpmv0e@4ax.com>

On 10 Sep 2003 18:19:56 +0200, Peter Dalgaard BSA
<p.dalgaard@biostat.ku.dk> wrote :

>The countdown to R version 1.8.0 has begun. As a novelty, we now
>make preliminary source tarballs available somewhat earlier in the
>process. They will be found in
>
>http://cran.us.r-project.org/src/base 
>
>with names of the form  R-1.8.0alpha_2003-09-10.tar.gz 
>
>The first one was created a moment ago; subsequent ones will be
>created by a cron job that runs at 05:00 local (Wisconsin) time.

I've put a Windows binary build of this morning's snapshot into the
pipeline.  It will eventually show up (probably tomorrow) on CRAN and
the mirrors in /bin/windows/base/.

I'm planning to upload new snapshots as often as practicable until the
release of 1.8.0, but due to travel constraints, this is not likely to
occur daily.

Duncan Murdoch

From ggrothendieck at volcanomail.com  Thu Sep 11 08:09:42 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Thu Sep 11 16:09:21 2003
Subject: [Rd] rank(*) with NAs -- new option "keep" desired
Message-ID: <20030911140942.B0D303F2B@sitemail.everyone.net>

I could have used this also.  Currently I do this:

z <- ifelse(is.na(y),NA,rank(y))
names(z) <- names(y)

The following also works but is less transparent:

z <- y
z[z==z] <- rank(y)

Another extension of rank that could be useful would be to have
an argument that causes it NOT to do tie averaging.  This is useful
when you are using rank(x) in the sense of an inverse permutation.
Currently I do this:

z <- order(order(y))
names(z) <- names(y)


--- Martin Maechler <maechler@stat.math.ethz.ch> wrote:
>In some contexts, I find the current behavior of rank() very
>`suboptimal'.
>
>We have the argument na.last = {TRUE | FALSE | NA }
>where the first two cases treating NAs (almost) as if they were
> == +Inf or == -Inf  whereas the 3rd case just drops NAs.
>For the typical ``Rank Transformation'' that is recommended in
>EDA in several contexts, I would however want something else,
>namely keep the NAs !
>
>An example -- including the new option as I'm proposing it ---
>makes things more clear :
>
>> y <- c(2:1,NA,0)
>> rank(y, na.last = TRUE)## ==== rank(y)
>[1] 3 2 4 1
>> rank(y, na.last = FALSE)
>[1] 4 3 1 2
>> rank(y, na.last = NA)
>[1] 3 2 1
>> rank(y, na.last = "keep") ### <<<<< NEW >>
>[1]  3  2 NA  1
>> 
>---
>
>Alternatively to extending the possible values of `na.last' I
>first thought of a new (boolean) argument, but found the current
>solution less ugly.
>
>Feedback welcome!
>
>Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
>Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
>ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
>phone: x-41-1-632-3408		fax: ...-1228			<><
>
>PS: Stumbled over this while implementing  cor.test()s
>    method = c("pearson", "spearman", "kendall")  for  cor()
>    itself.
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From maechler at stat.math.ethz.ch  Thu Sep 11 17:57:22 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Sep 11 16:56:46 2003
Subject: [Rd] rank(*) with NAs -- new option "keep" desired
In-Reply-To: <20030911140942.B0D303F2B@sitemail.everyone.net>
References: <20030911140942.B0D303F2B@sitemail.everyone.net>
Message-ID: <16224.36178.887257.943362@gargle.gargle.HOWL>

Thank you, Gabor!

>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck@volcanomail.com>
>>>>>     on Thu, 11 Sep 2003 07:09:42 -0700 (PDT) writes:

    Gabor> I could have used this also.  Currently I do this:
    Gabor> z <- ifelse(is.na(y),NA,rank(y))
    Gabor> names(z) <- names(y)

    Gabor> The following also works but is less transparent:

    Gabor> z <- y
    Gabor> z[z==z] <- rank(y)

the next version of R should definitely have a builtin version,
as a matter of fact, today's (or tomorrow's) R-alpha version
already has.  
My point was rather enquiring on how the "API" should be setup
(argument name, semantic, ..).

    Gabor> Another extension of rank that could be useful would be to have
    Gabor> an argument that causes it NOT to do tie averaging.  
    Gabor> This is useful when you are using rank(x) in the
    Gabor> sense of an inverse permutation.  Currently I do
    Gabor> this:

    Gabor> z <- order(order(y))
    Gabor> names(z) <- names(y)

Good point!  However,  help(rank) has been mentioning this and recommends 
sort.list() instead of order().
	    (and does forget about the names() !)

[ For efficiency reasons, sort.list() is preferable to order for
 the simple order()ing on only one argument. ]

    Gabor> --- Martin Maechler <maechler@stat.math.ethz.ch> wrote:
    >> In some contexts, I find the current behavior of rank() very
    >> `suboptimal'.
    >> 
    >> We have the argument na.last = {TRUE | FALSE | NA }
    >> where the first two cases treating NAs (almost) as if they were
    >> == +Inf or == -Inf  whereas the 3rd case just drops NAs.
    >> For the typical ``Rank Transformation'' that is recommended in
    >> EDA in several contexts, I would however want something else,
    >> namely keep the NAs !
    >> 
    >> An example -- including the new option as I'm proposing it ---
    >> makes things more clear :
    >> 
    >>> y <- c(2:1,NA,0)
    >>> rank(y, na.last = TRUE)## ==== rank(y)
    >> [1] 3 2 4 1
    >>> rank(y, na.last = FALSE)
    >> [1] 4 3 1 2
    >>> rank(y, na.last = NA)
    >> [1] 3 2 1
    >>> rank(y, na.last = "keep") ### <<<<< NEW >>
    >> [1]  3  2 NA  1
    >>> 
    >> ---
    >> 
    >> Alternatively to extending the possible values of `na.last' I
    >> first thought of a new (boolean) argument, but found the current
    >> solution less ugly.
    >> 
    >> Feedback welcome!
    >> 
    >> Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
    >> Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
    >> ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
    >> phone: x-41-1-632-3408		fax: ...-1228			<><
    >> 
    >> PS: Stumbled over this while implementing  cor.test()s
    >> method = c("pearson", "spearman", "kendall")  for  cor()
    >> itself.

From ripley at stats.ox.ac.uk  Thu Sep 11 17:17:26 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Sep 11 17:16:44 2003
Subject: [Rd] rank(*) with NAs -- new option "keep" desired
In-Reply-To: <16224.36178.887257.943362@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.44.0309111616040.3499-100000@gannet.stats>

On Thu, 11 Sep 2003, Martin Maechler wrote:

> [ For efficiency reasons, sort.list() is preferable to order for
>  the simple order()ing on only one argument. ]

No preference these days unless na.last=NA.  order() recognizes it has
only one argument and uses the sort.list internals.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From bolker at zoo.ufl.edu  Thu Sep 11 12:39:55 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Thu Sep 11 17:28:27 2003
Subject: [Rd] extending boxplot with space() argument?
Message-ID: <Pine.LNX.4.44.0309111132510.5239-100000@bolker.zoo.ufl.edu>


  A student asked me if it was possible to draw boxplots where the boxes 
themselves were grouped: I was able to hack boxplot.formula() to do the 
right thing, more or less, by incorporating an argument (space) and some 
code from barplot.

with the extended boxplot.formula() below, the following commands "do the 
right thing" (produce boxes grouped by levels of the second factor):

r = runif(480)
f1 = gl(4,120)
f2 = gl(10,4,480)
boxplot(r ~ f1*f2,space=c(0.5,2),col=2:5)

  I think this *might* be generally useful: for example, the last example
in example(boxplot) sets up a grouped boxplot by hand, plotting one group
with an offset and then the other.  This would be much easier with my
hack. (I know we're in feature-freeze for 1.8.0 right now ... my usual
good timing.)

  The one thing that makes this hack difficult/ugly is that all the
spacing calculations (e.g. if one specifies varwidth=TRUE) are handled in
the bxp() function: the calling sequence is boxplot -> boxplot.formula ->
boxplot.default -> bxp , so I had to replicate some of the spacing
calculations within boxplot.formula, which is ugly and incomplete.  Can
anyone suggest an elegant way to deal with this?

------
"boxplot.formula" <-
  function (formula, data = NULL, width=1,
            space = 0.5, xlim=NULL, ylim=NULL,
            horizontal = FALSE, at = NULL, log="",
            boxwex=0.8,
            add=FALSE, ..., subset) 
{
  if (missing(formula) || (length(formula) != 3)) 
    stop("formula missing or incorrect")
  m <- match.call(expand.dots = FALSE)
  if (is.matrix(eval(m$data, parent.frame()))) 
    m$data <- as.data.frame(data)
  m$... <- m$space <- m$xlim <- m$ylim <- m$add <- m$horizontal <-
    m$at <- m$log <- m$boxwex <- NULL
  m[[1]] <- as.name("model.frame")
  mf <- eval(m, parent.frame())
  response <- attr(attr(mf, "terms"), "response")
  ## spacing code adapted from barplot()
  f <- mf[-response]
  f <- lapply(f,as.factor) ## just in case
  dims <- sapply(lapply(f,levels),length)
  n <- prod(dims)
  width <- if (!is.null(width)) {
    if (any(is.na(width)) | any(width <= 0))
      stop("invalid boxplot widths")
    boxwex * width/max(width)
  }
  width <- rep(width, length=n)
  delta <- width/2
  if (is.null(at)) {
    if (length(space) == 2) { 
      space <- rep(c(space[2], rep(space[1], dims[1] - 1)), 
                   dims[2]) }
    w.r <- cumsum(space + width)
    w.m <- w.r - delta
    at=w.m
  }
  ## ugly: have to replicate spacing/plotting code from
  ## bxp() here (since boxplot doesn't take xlim as a parameter)
  if (is.null(xlim)) xlim <- range(at)+c(-delta[1],delta[length(delta)])
  if (is.null(ylim)) ylim <- range(mf[[response]])
  if (!add) {
    plot.new()
    if (horizontal) 
      plot.window(ylim = xlim, xlim = ylim, log = log)
    else plot.window(xlim = xlim, ylim = ylim, log = log)
  }
  b <- boxplot(split(mf[[response]], f),at=at,
               horizontal=horizontal, boxwex=boxwex,
               add=TRUE, ...)
  invisible(b)
}



-- 
620B Bartram Hall                            bolker@zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

From edd at debian.org  Thu Sep 11 11:57:58 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu Sep 11 17:57:28 2003
Subject: [Rd] potentially nasty interaction between R 1.8.0 and tetex
In-Reply-To: <16224.14749.151458.714484@galadriel.ci.tuwien.ac.at>
References: <854qzkjms3.fsf@blindglobe.net> <x2brtsi6b6.fsf@biostat.ku.dk>
	<85znhci61s.fsf@blindglobe.net>
	<16224.12382.97450.735140@galadriel.ci.tuwien.ac.at>
	<x2n0dbwwuo.fsf@biostat.ku.dk>
	<16224.14749.151458.714484@galadriel.ci.tuwien.ac.at>
Message-ID: <20030911155758.GA29838@sonny.eddelbuettel.com>

On Thu, Sep 11, 2003 at 11:00:13AM +0200, Friedrich.Leisch@ci.tuwien.ac.at wrote:
>   > We'd probably want to take a closer look at what the issue really
>   > is,
> 
> yes, definitely

Yep.

> My system has:
> 
> galadriel:Leisch$ dpkg -l tetex*
> ii  tetex-base     2.0.2-4.1      basic teTeX library files
> ii  tetex-bin      2.0.2-4.2      teTeX binary files
> ii  tetex-doc      2.0.2-4.1      teTeX documentation
> ii  tetex-extra    2.0.2-4.1      extra teTeX library files

Sure, that was public knowledge as we know you run testing. What we need is
some 'meta diff' over tetex, just like Peter suggested.

Tony:  Is there a changelog entry somewhere in tetex which reveals anything?

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx

From rossini at blindglobe.net  Thu Sep 11 10:21:09 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu Sep 11 18:20:38 2003
Subject: [Rd] potentially nasty interaction between R 1.8.0 and tetex
In-Reply-To: <20030911155758.GA29838@sonny.eddelbuettel.com> (Dirk
	Eddelbuettel's message of "Thu, 11 Sep 2003 10:57:58 -0500")
References: <854qzkjms3.fsf@blindglobe.net> <x2brtsi6b6.fsf@biostat.ku.dk>
	<85znhci61s.fsf@blindglobe.net>
	<16224.12382.97450.735140@galadriel.ci.tuwien.ac.at>
	<x2n0dbwwuo.fsf@biostat.ku.dk>
	<16224.14749.151458.714484@galadriel.ci.tuwien.ac.at>
	<20030911155758.GA29838@sonny.eddelbuettel.com>
Message-ID: <85u17j70ui.fsf@blindglobe.net>

Dirk Eddelbuettel <edd@debian.org> writes:

> On Thu, Sep 11, 2003 at 11:00:13AM +0200, Friedrich.Leisch@ci.tuwien.ac.at wrote:
>>   > We'd probably want to take a closer look at what the issue really
>>   > is,
>> 
>> yes, definitely
>
> Yep.
>
>> My system has:
>> 
>> galadriel:Leisch$ dpkg -l tetex*
>> ii  tetex-base     2.0.2-4.1      basic teTeX library files
>> ii  tetex-bin      2.0.2-4.2      teTeX binary files
>> ii  tetex-doc      2.0.2-4.1      teTeX documentation
>> ii  tetex-extra    2.0.2-4.1      extra teTeX library files
>
> Sure, that was public knowledge as we know you run testing. What we need is
> some 'meta diff' over tetex, just like Peter suggested.

501$ dpkg -l tetex*
Desired=Unknown/Install/Remove/Purge/Hold
|
Status=Not/Installed/Config-files/Unpacked/Failed-config/Half-installed
|/ Err?=(none)/Hold/Reinst-required/X=both-problems (Status,Err:
uppercase=bad)
||/ Name           Version        Description
+++-==============-==============-============================================
un  tetex          <none>         (no description available)
ii  tetex-base     2.0.2-4.2      Basic library files of teTeX
ii  tetex-bin      2.0.2-4.3      The teTeX binary files
pn  tetex-brev     <none>         (no description available)
un  tetex-dev      <none>         (no description available)
pn  tetex-doc      <none>         (no description available)
pn  tetex-eurosym  <none>         (no description available)
ii  tetex-extra    2.0.2-4.2      Additional library files of teTeX
un  tetex-french   <none>         (no description available)
pn  tetex-frogg    <none>         (no description available)
pn  tetex-frogg-do <none>         (no description available)
pn  tetex-lib      <none>         (no description available)
un  tetex-nonfree  <none>         (no description available)
pn  tetex-src      <none>         (no description available)


> Tony:  Is there a changelog entry somewhere in tetex which reveals anything?

Looking over the Debian changelogs reveals nothing -- just maintainer
stuff.  

Fritz, where is "Blue" and "Red" defined in your distribution?

best,
-tony

-- 
A.J. Rossini     			
rossini@u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW   :              FAX=206-543-3461 | moving soon to a permanent office
FHCRC: 206-667-7025 FAX=206-667-4812 | Voicemail is pretty sketchy/use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}

From jgentry at jimmy.harvard.edu  Thu Sep 11 13:26:33 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu Sep 11 18:25:48 2003
Subject: [Rd] potentially nasty interaction between R 1.8.0 and tetex
In-Reply-To: <85u17j70ui.fsf@blindglobe.net>
Message-ID: <Pine.SOL.4.20.0309111223350.10219-100000@santiam.dfci.harvard.edu>

> Looking over the Debian changelogs reveals nothing -- just maintainer
> stuff.  

Just to provide more (potentially useful) info, I'm having the same
problem on a Solaris 8 machine (with the same workaround on the
Blue/blue/Red/red thing) and the teTeX installed has definitely not been
changed for a long while (perhaps ever).

-J

From saikat at stat.wisc.edu  Thu Sep 11 15:38:15 2003
From: saikat at stat.wisc.edu (Saikat DebRoy)
Date: Thu Sep 11 20:37:09 2003
Subject: [Rd] New package in Bioconductor: externalVector
Message-ID: <1B2FE6B9-E487-11D7-8A67-0003931A3C9E@stat.wisc.edu>

The externalVector package implements a class of objects that behaves 
like R vectors but are stored in an outside resource. All the 
operations are defined in terms of a small number of primitive 
operations. To use a new type of external resource for storing the 
objects, a subclass of externalStorage needs to be defined along with 
some C level primitives.

One such subclass of externalStorage is part of the externalVector 
package.
It is called simpleStorage and it uses R garbage collected memory to 
store the objects.

At present the package has very little documentation. The README file 
provides (I hope) enough clues to get you started. There is a TODO file 
that describes the outstanding issues. One of the more important things 
there is the list of generics for which we should have externalVector 
methods but we don't. Any suggestions for additions to the list is 
welcome as are any bug reports and incompatibility with R vector/matrix 
objects.

Thanks,
Saikat

From Paul.Bayer at gleichsam.de  Thu Sep 11 23:07:44 2003
From: Paul.Bayer at gleichsam.de (Paul.Bayer@gleichsam.de)
Date: Thu Sep 11 22:07:05 2003
Subject: [Rd] Problem in scan() (PR#4128)
Message-ID: <200309112007.h8BK7iJH006702@pubhealth.ku.dk>

Full_Name: Paul Bayer
Version: 1.7.1
OS: Windows + Linux
Submission from: (NULL) (217.235.105.54)


I tried to read some large csv-files into R (30 - 100MB).
with scan(), skipping not needed columns by NULL-elements in
"what".

When these skipped elements are quoted strings with commas inside,
R interprets each such quoted comma as element separator
leading to wrong records in the rest of the line.

A little test will show what I mean. I have the following "test.csv":

"col.A","col.B","col.C","col.D"
1,"quoted string","again, again again",123
2,"nice quotes, isnt it","you got it",456

First I read all elements:

> tst <- scan("test.csv", what=list(a=0,b="",c="",d=0), sep=",", skip=1)
Read 2 records
> tst
$a
[1] 1 2

$b
[1] "quoted string"        "nice quotes, isnt it"

$c
[1] "again, again again" "you got it"

$d
[1] 123 456

Everything is fine. Then I try to skip the 2nd column by giving b=NULL:

> tst <- scan("test.csv", what=list(a=0,b=NULL,c="",d=0), sep=",", skip=1)
Read 2 records
Warning message:
number of items read is not a multiple of the number of columns
> tst
$a
[1] 1 2

$b
NULL

$c
[1] "again, again again"            " isnt it,you got it,456\n\n\n"

$d
[1] 123  NA

>

I got garbage.

From ripley at stats.ox.ac.uk  Thu Sep 11 22:41:35 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Sep 11 22:40:56 2003
Subject: [Rd] Problem in scan() (PR#4128)
In-Reply-To: <200309112007.h8BK7iJH006702@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0309112136080.4109-100000@gannet.stats>

Quotes are only interpreted in character columns (scan.c line 240), and
NULL is not character.  So this was intentional.

If you would like this changed, please supply a patch (which looks to be  
a good exercise).

On Thu, 11 Sep 2003 Paul.Bayer@gleichsam.de wrote:

> Full_Name: Paul Bayer
> Version: 1.7.1
> OS: Windows + Linux
> Submission from: (NULL) (217.235.105.54)
> 
> 
> I tried to read some large csv-files into R (30 - 100MB).
> with scan(), skipping not needed columns by NULL-elements in
> "what".
> 
> When these skipped elements are quoted strings with commas inside,
> R interprets each such quoted comma as element separator
> leading to wrong records in the rest of the line.
> 
> A little test will show what I mean. I have the following "test.csv":
> 
> "col.A","col.B","col.C","col.D"
> 1,"quoted string","again, again again",123
> 2,"nice quotes, isnt it","you got it",456
> 
> First I read all elements:
> 
> > tst <- scan("test.csv", what=list(a=0,b="",c="",d=0), sep=",", skip=1)
> Read 2 records
> > tst
> $a
> [1] 1 2
> 
> $b
> [1] "quoted string"        "nice quotes, isnt it"
> 
> $c
> [1] "again, again again" "you got it"
> 
> $d
> [1] 123 456
> 
> Everything is fine. Then I try to skip the 2nd column by giving b=NULL:
> 
> > tst <- scan("test.csv", what=list(a=0,b=NULL,c="",d=0), sep=",", skip=1)
> Read 2 records
> Warning message:
> number of items read is not a multiple of the number of columns
> > tst
> $a
> [1] 1 2
> 
> $b
> NULL
> 
> $c
> [1] "again, again again"            " isnt it,you got it,456\n\n\n"
> 
> $d
> [1] 123  NA
> 
> >
> 
> I got garbage.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From wettenhall at wehi.edu.au  Fri Sep 12 18:17:22 2003
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Fri Sep 12 09:17:03 2003
Subject: [Rd] win.metafile, devga, tkrplot in R 1.8.0
Message-ID: <Pine.LNX.4.44.0309121707310.7587-100000@unix28.alpha.wehi.edu.au>

Hi,

I just downloaded 
rw1080dev.exe           09-Sep-2003 07:42  21.6M  
from
http://www.stats.uwo.ca/faculty/murdoch/software/r-devel/
and tried using tkrplot on Windows 2000.

.First.lib failed to load the dll:
.Tcl(paste("load", file, "Rplot"))
appeared to be mixing up double-backslashes and forward slashes:
 [tcl] couldn't load library "C:w1080devlibrary  krplot/libs/tkrplot.dll": 
this library or a dependent library could not be found in library path.

When I loaded the dll manually with dyn.load (successfully), I 
then found that win.metafile (used by the tkrplot function) 
failed:

win.metafile()
Error in win.metafile() : 10 arguments passed to "devga" which requires 13.

More info on devga, see:
R-1.8.0/src/gnuwin32/devga.c
R-1.8.0/src/gnuwin32/dodevga.c
R-1.8.0/src/gnuwin32/devga.h

Regards,
James

> version
         _                           
platform i386-pc-mingw32             
arch     i386                        
os       mingw32                     
system   i386, mingw32               
status   Under development (unstable)
major    1                           
minor    8.0                         
year     2003                        
month    09                          
day      09                          
language R                           
>

From ripley at stats.ox.ac.uk  Fri Sep 12 09:49:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Sep 12 09:48:47 2003
Subject: [Rd] win.metafile, devga, tkrplot in R 1.8.0
In-Reply-To: <Pine.LNX.4.44.0309121707310.7587-100000@unix28.alpha.wehi.edu.au>
Message-ID: <Pine.LNX.4.44.0309120846030.4958-100000@gannet.stats>

The win.metafile one is long-standing but has only recently been checked:
it is now fixed (you were using a snapshot from the day the check was 
reinstated).

The other problem is due to a change to .find.packages, which has 
a new function .filePathAsAbsolute that changes / in paths to \\.
However, what R is passing to Tcl is a valid path, so looks like Tcl on 
Windows is not accepting Windows paths, aargh.


On Fri, 12 Sep 2003, James Wettenhall wrote:

> Hi,
> 
> I just downloaded 
> rw1080dev.exe           09-Sep-2003 07:42  21.6M  
> from
> http://www.stats.uwo.ca/faculty/murdoch/software/r-devel/
> and tried using tkrplot on Windows 2000.
> 
> .First.lib failed to load the dll:
> .Tcl(paste("load", file, "Rplot"))
> appeared to be mixing up double-backslashes and forward slashes:
>  [tcl] couldn't load library "C:w1080devlibrary  krplot/libs/tkrplot.dll": 
> this library or a dependent library could not be found in library path.
> 
> When I loaded the dll manually with dyn.load (successfully), I 
> then found that win.metafile (used by the tkrplot function) 
> failed:
> 
> win.metafile()
> Error in win.metafile() : 10 arguments passed to "devga" which requires 13.
> 
> More info on devga, see:
> R-1.8.0/src/gnuwin32/devga.c
> R-1.8.0/src/gnuwin32/dodevga.c
> R-1.8.0/src/gnuwin32/devga.h
> 
> Regards,
> James
> 
> > version
>          _                           
> platform i386-pc-mingw32             
> arch     i386                        
> os       mingw32                     
> system   i386, mingw32               
> status   Under development (unstable)
> major    1                           
> minor    8.0                         
> year     2003                        
> month    09                          
> day      09                          
> language R                           
> >
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Friedrich.Leisch at ci.tuwien.ac.at  Fri Sep 12 10:59:08 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Fri Sep 12 09:58:41 2003
Subject: [Rd] potentially nasty interaction between R 1.8.0 and tetex
In-Reply-To: <85u17j70ui.fsf@blindglobe.net>
References: <854qzkjms3.fsf@blindglobe.net> <x2brtsi6b6.fsf@biostat.ku.dk>
	<85znhci61s.fsf@blindglobe.net>
	<16224.12382.97450.735140@galadriel.ci.tuwien.ac.at>
	<x2n0dbwwuo.fsf@biostat.ku.dk>
	<16224.14749.151458.714484@galadriel.ci.tuwien.ac.at>
	<20030911155758.GA29838@sonny.eddelbuettel.com>
	<85u17j70ui.fsf@blindglobe.net>
Message-ID: <16225.31948.183341.695198@galadriel.ci.tuwien.ac.at>

>>>>> On Thu, 11 Sep 2003 09:21:09 -0700,
>>>>> A J Rossini (AJR) wrote:


  > Fritz, where is "Blue" and "Red" defined in your distribution?

Hard to say ... seems like graphics/dvipsnam.def contains a couple of
name definitions, all starting with uppercase
letters. graphics/color.sty contains lowercase definitions for the
primary colors, though. So maybe we should simply try

	Red -> red
	Blue -> blue

and see whether that survives the upcoming testing cycle?

.f

From p.dalgaard at biostat.ku.dk  Fri Sep 12 09:58:10 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Sep 12 10:58:12 2003
Subject: [Rd] win.metafile, devga, tkrplot in R 1.8.0
In-Reply-To: <Pine.LNX.4.44.0309120846030.4958-100000@gannet.stats>
References: <Pine.LNX.4.44.0309120846030.4958-100000@gannet.stats>
Message-ID: <x2llsu8jp7.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> The win.metafile one is long-standing but has only recently been checked:
> it is now fixed (you were using a snapshot from the day the check was 
> reinstated).
> 
> The other problem is due to a change to .find.packages, which has 
> a new function .filePathAsAbsolute that changes / in paths to \\.
> However, what R is passing to Tcl is a valid path, so looks like Tcl on 
> Windows is not accepting Windows paths, aargh.

Only in the same sense that R on Windows doesn't accept Windows paths:
Backslash is an escape character.

.Tcl(paste("load", file, "Rplot"))

I think tkcmd("load", file, "Rplot") might work better.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ross at biostat.ucsf.edu  Sat Sep 13 00:41:33 2003
From: ross at biostat.ucsf.edu (ross@biostat.ucsf.edu)
Date: Fri Sep 12 23:40:50 2003
Subject: [Rd] glitch in terms documentation (PR#4146)
Message-ID: <200309122141.h8CLfXJH018735@pubhealth.ku.dk>

These are two small items that caught my eye.

I'm looking at the R 1.7.1 2003-06-16 pdf reference manual.  There are
several refences to terms.default (e.g., p. 711, 712) but no definitions
of it.  I'm guessing this means terms, but it's a little puzzling.

Also, the desription of terms.object  does not mention that the
"variables" attribute is actually a list of calls--surprising to me,
since I was expecting text like all.vars.  It would be useful to
indicate if all.vars returns the same ordering as the variables
attribute (at least, I'm wondering it now, though this might be a sign
I've gone astray).

Thanks.
-- 
Ross Boylan                                      wk:  (415) 502-4031
530 Parnassus Avenue (Library) rm 115-4          ross@biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
University of California, San Francisco
San Francisco, CA 94143-0840                     hm:  (415) 550-1062

From ripley at stats.ox.ac.uk  Sat Sep 13 09:00:06 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Sep 13 08:59:31 2003
Subject: [Rd] glitch in terms documentation (PR#4146)
In-Reply-To: <200309122141.h8CLfXJH018735@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0309130751460.25290-100000@gannet.stats>

On Fri, 12 Sep 2003 ross@biostat.ucsf.edu wrote:

> These are two small items that caught my eye.
> 
> I'm looking at the R 1.7.1 2003-06-16 pdf reference manual.  There are
> several refences to terms.default (e.g., p. 711, 712) but no definitions
> of it.  I'm guessing this means terms, but it's a little puzzling.

No, it means the default method of the terms generic. Try ?terms.default, 
which gives you a complete explanation.

Page numbers are useless to us, BTW, as they depend on the papersize and
I suspect you are not using ISO sizes.

> Also, the desription of terms.object  does not mention that the
> "variables" attribute is actually a list of calls--surprising to me,

It isn't.  It is a single call to list.

> since I was expecting text like all.vars.

But, it says it is a `list'.  Wrong, but not character (if that is what 
you meant by `text').

>   It would be useful to
> indicate if all.vars returns the same ordering as the variables
> attribute (at least, I'm wondering it now, though this might be a sign
> I've gone astray).

What has all.vars to do with terms?  All.vars applies to an expression or 
call, and terms() applies to a formula or a model object.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From axel.benz at iao.fhg.de  Sat Sep 13 14:37:28 2003
From: axel.benz at iao.fhg.de (axel.benz@iao.fhg.de)
Date: Sat Sep 13 13:36:46 2003
Subject: [Rd] bug or feature? (PR#4150)
Message-ID: <200309131137.h8DBbSJH021576@pubhealth.ku.dk>

Full_Name: Axel Benz
Version: 1.7.1
OS: Windows
Submission from: (NULL) (137.251.33.43)


This feature seems to be a basic bug:

> 1=="1"
[1] TRUE
> as.numeric(1)=="1"
[1] TRUE
> as.numeric(1)==as.character("1")
[1] TRUE

isn't it necessary to distinguish beteen numbers and characters??

Best Regards,
Axel

From jago at mclink.it  Sat Sep 13 15:06:47 2003
From: jago at mclink.it (Stefano Iacus)
Date: Sat Sep 13 14:06:08 2003
Subject: [Rd] RAqua R 1.8.0 (alpha)
Message-ID: <BF92DB40-E5E2-11D7-ADB8-003065CC4CB8@mclink.it>

a new version of RAqua is now available.
The major change for developers is that libR.dylib is now inside 
/Applications/StartR.app/RAqua.app/Contents/Frameworks and at build 
time the linker sets this path as install-name for libR.dylib

This only happens if you configure with flag --with-aqua and, of 
course, it make sense only if you use make install-aqua.

If you don't use --with-aqua and a simple make install, essentially 
nothing changes wrt R 1.7.x

stefano

From jago at mclink.it  Sat Sep 13 15:07:09 2003
From: jago at mclink.it (Stefano Iacus)
Date: Sat Sep 13 14:06:37 2003
Subject: [Rd] RAqua R 1.8.0 (alpha)
Message-ID: <CCFCA278-E5E2-11D7-ADB8-003065CC4CB8@mclink.it>

a new version of RAqua is now available.
The major change for developers is that libR.dylib is now inside 
/Applications/StartR.app/RAqua.app/Contents/Frameworks and at build 
time the linker sets this path as install-name for libR.dylib

This only happens if you configure with flag --with-aqua and, of 
course, it make sense only if you use make install-aqua.

If you don't use --with-aqua and a simple make install, essentially 
nothing changes wrt R 1.7.x

stefano

From jago at mclink.it  Sat Sep 13 15:21:10 2003
From: jago at mclink.it (Stefano Iacus)
Date: Sat Sep 13 14:20:39 2003
Subject: [Rd] RAqua R 1.8.0 (alpha)
In-Reply-To: <CCFCA278-E5E2-11D7-ADB8-003065CC4CB8@mclink.it>
Message-ID: <C23B635E-E5E4-11D7-ADB8-003065CC4CB8@mclink.it>

I forgot to mention that all the binary versions of the packages should 
be rebuilt. The script is actually running, so you should wait tomorrow 
for the packages to be updated on CRAN

stefano

On Sabato, set 13, 2003, at 14:07 Europe/Rome, Stefano Iacus wrote:

> a new version of RAqua is now available.
> The major change for developers is that libR.dylib is now inside 
> /Applications/StartR.app/RAqua.app/Contents/Frameworks and at build 
> time the linker sets this path as install-name for libR.dylib
>
> This only happens if you configure with flag --with-aqua and, of 
> course, it make sense only if you use make install-aqua.
>
> If you don't use --with-aqua and a simple make install, essentially 
> nothing changes wrt R 1.7.x
>
> stefano
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From dmurdoch at pair.com  Sat Sep 13 09:42:13 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat Sep 13 14:41:33 2003
Subject: [Rd] bug or feature? (PR#4150)
In-Reply-To: <200309131137.h8DBbSJH021576@pubhealth.ku.dk>
References: <200309131137.h8DBbSJH021576@pubhealth.ku.dk>
Message-ID: <cm36mvs5on6srf0g2kec10a8ol1kgidff1@4ax.com>

On Sat, 13 Sep 2003 13:37:28 +0200 (MET DST), you wrote:

>Full_Name: Axel Benz
>Version: 1.7.1
>OS: Windows
>Submission from: (NULL) (137.251.33.43)
>
>
>This feature seems to be a basic bug:
>
>> 1=="1"
>[1] TRUE
>> as.numeric(1)=="1"
>[1] TRUE
>> as.numeric(1)==as.character("1")
>[1] TRUE
>
>isn't it necessary to distinguish beteen numbers and characters??

No, the general rule in R is that operators try to coerce their
arguments into a suitable type for the operation.  In this case,
because one arg is character, the other one is coerced to character
too.  It doesn't matter that you forced the type using as.numeric or
as.character; the operator is going to force them both to comparable
types.

For example,

> as.character(pi)
[1] "3.14159265358979"
> pi == "3.14159265358979"
[1] TRUE
> pi == 3.14159265358979
[1] FALSE

In the last case, they were already comparable, so no forcing was
done.  Since the internal value of pi actually carries more than 14
decimal places of precision, they don't compare equal as numbers, even
though the do compare equal when converted to character.

If you want to distinguish numbers and characters, use mode(1) ==
mode("1").

Duncan Murdoch

From jfox at mcmaster.ca  Sat Sep 13 10:01:59 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat Sep 13 14:59:14 2003
Subject: [Rd] bug or feature? (PR#4150)
In-Reply-To: <200309131137.h8DBbSJH021576@pubhealth.ku.dk>
Message-ID: <5.1.0.14.2.20030913085648.01fa3170@127.0.0.1>

Dear Axel,

At 01:37 PM 9/13/2003 +0200, axel.benz@iao.fhg.de wrote:
>Full_Name: Axel Benz
>Version: 1.7.1
>OS: Windows
>Submission from: (NULL) (137.251.33.43)
>
>
>This feature seems to be a basic bug:
>
> > 1=="1"
>[1] TRUE
> > as.numeric(1)=="1"
>[1] TRUE
> > as.numeric(1)==as.character("1")
>[1] TRUE
>
>isn't it necessary to distinguish beteen numbers and characters??

Coercion to a common mode takes place in many contexts; for example:

         > 1 & TRUE
         [1] TRUE

To distinguish between numbers and characters you can, of course, use the 
predicates is.numeric() and is.character(), or test that the mode() of the 
arguments is the same.

John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox@mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox

From p.dalgaard at biostat.ku.dk  Sat Sep 13 13:59:25 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sat Sep 13 14:59:30 2003
Subject: [Rd] bug or feature? (PR#4150)
In-Reply-To: <200309131137.h8DBbSJH021576@pubhealth.ku.dk>
References: <200309131137.h8DBbSJH021576@pubhealth.ku.dk>
Message-ID: <x2vfrw972c.fsf@biostat.ku.dk>

axel.benz@iao.fhg.de writes:

> Full_Name: Axel Benz
> Version: 1.7.1
> OS: Windows
> Submission from: (NULL) (137.251.33.43)
> 
> 
> This feature seems to be a basic bug:
> 
> > 1=="1"
> [1] TRUE
> > as.numeric(1)=="1"
> [1] TRUE
> > as.numeric(1)==as.character("1")
> [1] TRUE
> 
> isn't it necessary to distinguish beteen numbers and characters??

As Martin said recently, if in doubt don't file bug reports. This may
be strange, but it is S-compatible, even to the extent of cloning the
following little piece of weirdness:

S-PLUS : Copyright (c) 1988, 2000 MathSoft, Inc.
S : Copyright Lucent Technologies, Inc.
Version 6.0 Release 1 for Sun SPARC, SunOS 5.6 : 2000
Working data will be in /home/sfe/pd/MySwork
> "1"==1
[1] T
> "1"==T
[1] F
> 1==T
[1] T

The rule is that there is implicit coercion in the direction that
"always works", so the three cases above become

"1" == as.character(1)
"1" == as.character(T)
1 == as.numeric(T)

There are various other curious consequences of that rule:

> 1e-2=="0.01"
[1] TRUE
> 1e-2=="1e-2"
[1] FALSE
> "2"<10
[1] FALSE
> 2<"10"
[1] FALSE

but it *is* a feature and not a bug.
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From edd at debian.org  Sat Sep 13 15:57:30 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat Sep 13 21:56:49 2003
Subject: [Rd] R 1.8.0 (to be) and RPy 0.3.1
Message-ID: <20030913195729.GA19010@sonny.eddelbuettel.com>


I look every now and then at RPy. It is not yet a Debian package as it
had the odd problem here or there -- initially an Atlas interaction,
currently something with long_jump() which cannot be found when R's dynamic
library is loaded. [1] It is called  R_eval.c:

/* Abort the current R computation and signal a KeyboardInterrupt
   exception */
void interrupt_R(int signum)
{
  interrupted = 1;
  jump_now(); 
}
       
By commenting it out, the package builds and is usable (modulo the absence
of interrupt handling, I suppose).

Could someone give me a pointer or suggestion as to what the replacement for
jump_now() would be?

Dirk
       
       
[1] See e.g. http://www.togaware.com/linux/survivor/Installing_RPy.html.
       

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx

From edd at debian.org  Sat Sep 13 17:06:52 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat Sep 13 23:06:10 2003
Subject: [Rd] R 1.8.0 (to be) and RPy 0.3.1
In-Reply-To: <20030913195729.GA19010@sonny.eddelbuettel.com>
References: <20030913195729.GA19010@sonny.eddelbuettel.com>
Message-ID: <20030913210652.GA19541@sonny.eddelbuettel.com>

On Sat, Sep 13, 2003 at 02:57:30PM -0500, Dirk Eddelbuettel wrote:
> /* Abort the current R computation and signal a KeyboardInterrupt
>    exception */
> void interrupt_R(int signum)
> {
>   interrupted = 1;
>   jump_now(); 
> }
>        
> By commenting it out, the package builds and is usable (modulo the absence
> of interrupt handling, I suppose).
> 
> Could someone give me a pointer or suggestion as to what the replacement for
> jump_now() would be?

Luke, resourceful as always, pointed me to Rf_onintr() which does the trick.
I may prepare a Debian test package of RPy.  So if you are a present or past
user of RPy, and if you happen to have a Debian system, please do drop me a
line if you would like to test it. 

Regards, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx

From ggrothendieck at volcanomail.com  Sat Sep 13 21:09:05 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Sun Sep 14 05:08:23 2003
Subject: [Rd] bug or feature? (PR#4150)
Message-ID: <20030914030905.BE713E4B9@sitemail.everyone.net>

Have a look at the identical function:

> identical(1,"1")
[1] FALSE
> identical(as.numeric(1),"1")
[1] FALSE
> identical(as.numeric(1),as.character("1"))
[1] FALSE
> identical(1,1)
[1] TRUE

--- axel.benz@iao.fhg.de wrote:
>Full_Name: Axel Benz
>Version: 1.7.1
>OS: Windows
>Submission from: (NULL) (137.251.33.43)
>
>
>This feature seems to be a basic bug:
>
>> 1=="1"
>[1] TRUE
>> as.numeric(1)=="1"
>[1] TRUE
>> as.numeric(1)==as.character("1")
>[1] TRUE
>
>isn't it necessary to distinguish beteen numbers and characters??
>
>Best Regards,
>Axel
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From dgrove at fhcrc.org  Sun Sep 14 07:02:27 2003
From: dgrove at fhcrc.org (dgrove@fhcrc.org)
Date: Sun Sep 14 06:01:47 2003
Subject: [Rd] Documentation of colSums et. al (PR#4154)
Message-ID: <200309140402.h8E42RJH024697@pubhealth.ku.dk>

Full_Name: Doug Grove
Version: 1.7.0
OS: Linux
Submission from: (NULL) (209.31.211.56)


Hi,

Minor mistake in the documentation on the colSums page.
In the ARGUMENTS section it states for 'dims' that:

   For `col*', the sum or mean is over dimensions
   `dims+1, ...'; for `row*' it is over dimensions `1:dims'.

These two are reversed.

Thanks,
Doug Grove

From bellis at hsph.harvard.edu  Sun Sep 14 02:14:11 2003
From: bellis at hsph.harvard.edu (Byron Ellis)
Date: Sun Sep 14 07:13:27 2003
Subject: [Rd] Problem building methods package?
Message-ID: <4666BD7C-E672-11D7-BE85-000393956206@hsph.harvard.edu>

For the last, I dunno, week or so I've been unable to build R... I 
finally took the time to investigate and the crash is in building 
'methods':

all.R is unchanged
../../../library/methods/man/methods.Rd is unchanged
make[2]: `Makedeps' is up to date.
../../../../library/methods/libs/methods.so is unchanged
make[1]: Nothing to be done for `Rfiles'.

Any clues to where this came from? Regenerating the Makefiles didn't 
seem to help. OS X, 10.2.6, gcc3.3 rsync about 6 hours old. Should I 
just nuke the whole build tree and rsync everything again?


---
Byron Ellis (bellis@hsph.harvard.edu)
"Oook" - The Librarian

From ripley at stats.ox.ac.uk  Sun Sep 14 09:23:52 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Sep 14 09:23:28 2003
Subject: [Rd] Problem building methods package?
In-Reply-To: <4666BD7C-E672-11D7-BE85-000393956206@hsph.harvard.edu>
Message-ID: <Pine.LNX.4.44.0309140818440.10868-100000@gannet.stats>

methods changed to use a NAMESPACE about last weekend.  It does build now 
(there were several days with problems), but you will need to rebuild it 
from scratch.  Either do make distclean; ./configure ...  or at least
remove library/methods and src/library/methods/all.R and remake.

(And since I have been in Milan working with Stefano, I know it now builds 
on MacOS X too.)


On Sun, 14 Sep 2003, Byron Ellis wrote:

> For the last, I dunno, week or so I've been unable to build R... I 
> finally took the time to investigate and the crash is in building 
> 'methods':
> 
> all.R is unchanged
> ../../../library/methods/man/methods.Rd is unchanged
> make[2]: `Makedeps' is up to date.
> ../../../../library/methods/libs/methods.so is unchanged
> make[1]: Nothing to be done for `Rfiles'.

No `crash' shown!

> Any clues to where this came from? Regenerating the Makefiles didn't 
> seem to help. OS X, 10.2.6, gcc3.3 rsync about 6 hours old. Should I 
> just nuke the whole build tree and rsync everything again?

If you build in a separate tree the last step is never needed.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jago at mclink.it  Sun Sep 14 11:55:53 2003
From: jago at mclink.it (Stefano Iacus)
Date: Sun Sep 14 10:57:34 2003
Subject: [Rd] Problem building methods package?
Message-ID: <92166ACF-E691-11D7-ADB8-003065CC4CB8@mclink.it>

Yes Brian is right.
It builds fine with the same tools you have Byron.
Just try to remove the built version of methods or do what Brian 
suggested.
stefano

On Domenica, set 14, 2003, at 09:23 Europe/Rome, Prof Brian Ripley 
wrote:

> methods changed to use a NAMESPACE about last weekend.  It does build 
> now
> (there were several days with problems), but you will need to rebuild 
> it
> from scratch.  Either do make distclean; ./configure ...  or at least
> remove library/methods and src/library/methods/all.R and remake.
>
> (And since I have been in Milan working with Stefano, I know it now 
> builds
> on MacOS X too.)
>
>
> On Sun, 14 Sep 2003, Byron Ellis wrote:
>
>> For the last, I dunno, week or so I've been unable to build R... I
>> finally took the time to investigate and the crash is in building
>> 'methods':
>>
>> all.R is unchanged
>> ../../../library/methods/man/methods.Rd is unchanged
>> make[2]: `Makedeps' is up to date.
>> ../../../../library/methods/libs/methods.so is unchanged
>> make[1]: Nothing to be done for `Rfiles'.
>
> No `crash' shown!
>
>> Any clues to where this came from? Regenerating the Makefiles didn't
>> seem to help. OS X, 10.2.6, gcc3.3 rsync about 6 hours old. Should I
>> just nuke the whole build tree and rsync everything again?
>
> If you build in a separate tree the last step is never needed.
>
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From sieling at uni-freiburg.de  Sun Sep 14 17:01:21 2003
From: sieling at uni-freiburg.de (Ole Sieling)
Date: Sun Sep 14 15:50:53 2003
Subject: [Rd] R on BeOS
Message-ID: <14211947964-BeMail@moloch>

Hello,
I have compiled R-1.7.1 on Beos R5 (x86) and got it running.
The modules x11 and internet dont work (so the only working display is 
postscript()). 
The libraries all compile, but there is a problem with methods.
I get the following error when i make methods:

dumping R code in package 'methods'
Error in .Call("R_initialize_methods_metadata", table, PACKAGE = 
"methods") :
        .Call function name not in load table
Execution halted 


The other big problem is that select() is not working on BeOS R5.
So on Rstd_ReadConsole() the if (FD_ISSET(fileno(stdin), what)) 
statement always fails.
I did FD_SET(fileno(stdin), what) manually to enable the console.
What other inputs exist that could have problems here ?
I only found fd_set used in the modules internet aqua and in tcltk and 
those all dont work on BeOS anyway.

I would like to test my build, but make check fails because of missing 
lapack and tests in /test fail because of missing
../library/methods/R/all.rda.

If anyone would like, i could give details on the other things i had to 
do to compile R on BeOS (only #undef, paths etc.).


Ole Sieling

From simon.urbanek at math.uni-augsburg.de  Sun Sep 14 19:29:53 2003
From: simon.urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Sun Sep 14 19:17:30 2003
Subject: [Rd] configure problem in R-devel caused by conditionals
Message-ID: <AB5E1154-E6D0-11D7-B348-000A959F327E@math.uni-augsburg.de>

I re-generated configure of the latest R-devel with autoconf 2.57 and 
got the following problem:

configure: error: conditional "HAVE_ORBIT" was never defined.
Usually this means the macro was only invoked conditionally.

(resolving HAVE_ORBIT leaves us with HAVE_GNORBA causing the same 
problem. You should be able to reproduce it by running autoreconf (or 
aclocal; autoconf - not just autoconf!) and configure on the r-devel 
tree).

The culprit is primarily located in acinclude.m4, namely the macro 
GNOME_GNORBA_HOOK (used by GNOME_GNORBA_CHECK)
afaik it's never used in configure.ac (I couldn't find it at least), 
but the conditionals are "seen" by autoconf. Since all conditionals 
must be properly defined, it bails out.
(from automake docs: The shell condition (suitable for use in a shell 
if statement) is evaluated when configure is run.  Note that you must 
arrange for every AM_CONDITIONAL to be invoked *every* time configure 
is run - if AM_CONDITIONAL is run conditionally (e.g., in a shell if 
statement), then the result will confuse automake. )

Removing those macros from acinclude.m4 resolves the issue.

But, I'm wondering: in the m4 directory the README states that the 
files in m4 are used to create acinclude.m4 - is that done by hand or 
is there any "official" way to do it? There is no script called 
'bootstrap' in the root dir so the whole autoconf process seems to be 
non-standartized ... (ok, in the develper docs it says that one should 
simply run autoconf .. but then such issues as the above won't become 
visible as autoconf doesn't call aclocal, whereas e.g. autoreconf does 
...). So, how is the 'official' configure created?

---
Simon Urbanek
Department of computer oriented statistics and data analysis
Universit?tsstr. 14
86135 Augsburg
Germany

Tel: +49-821-598-2236
Fax: +49-821-598-2280

Simon.Urbanek@Math.Uni-Augsburg.de
http://simon.urbanek.info

From ripley at stats.ox.ac.uk  Sun Sep 14 20:46:47 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Sep 14 20:46:18 2003
Subject: [Rd] configure problem in R-devel caused by conditionals
In-Reply-To: <AB5E1154-E6D0-11D7-B348-000A959F327E@math.uni-augsburg.de>
Message-ID: <Pine.LNX.4.44.0309141944550.12138-100000@gannet.stats>

On Sun, 14 Sep 2003, Simon Urbanek wrote:

> I re-generated configure of the latest R-devel with autoconf 2.57 and 
> got the following problem:
> 
> configure: error: conditional "HAVE_ORBIT" was never defined.
> Usually this means the macro was only invoked conditionally.
> 
> (resolving HAVE_ORBIT leaves us with HAVE_GNORBA causing the same 
> problem. You should be able to reproduce it by running autoreconf (or 
> aclocal; autoconf - not just autoconf!) and configure on the r-devel 
> tree).
> 
> The culprit is primarily located in acinclude.m4, namely the macro 
> GNOME_GNORBA_HOOK (used by GNOME_GNORBA_CHECK)
> afaik it's never used in configure.ac (I couldn't find it at least), 
> but the conditionals are "seen" by autoconf. Since all conditionals 
> must be properly defined, it bails out.
> (from automake docs: The shell condition (suitable for use in a shell 
> if statement) is evaluated when configure is run.  Note that you must 
> arrange for every AM_CONDITIONAL to be invoked *every* time configure 
> is run - if AM_CONDITIONAL is run conditionally (e.g., in a shell if 
> statement), then the result will confuse automake. )
> 
> Removing those macros from acinclude.m4 resolves the issue.
> 
> But, I'm wondering: in the m4 directory the README states that the 
> files in m4 are used to create acinclude.m4 - is that done by hand or 
> is there any "official" way to do it? There is no script called 
> 'bootstrap' in the root dir so the whole autoconf process seems to be 
> non-standartized ... (ok, in the develper docs it says that one should 
> simply run autoconf .. but then such issues as the above won't become 
> visible as autoconf doesn't call aclocal, whereas e.g. autoreconf does 
> ...). So, how is the 'official' configure created?

configure --enable-maintainer-mode
make

and I think that is as `official' a way as any.  FWIW, autoconf works for 
me on 2.57.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From w.huber at dkfz-heidelberg.de  Sun Sep 14 23:33:11 2003
From: w.huber at dkfz-heidelberg.de (w.huber@dkfz-heidelberg.de)
Date: Sun Sep 14 22:35:10 2003
Subject: [Rd] bug or feature? (PR#4150)
In-Reply-To: <200309131137.h8DBbSJH021576@pubhealth.ku.dk>
References: <200309131137.h8DBbSJH021576@pubhealth.ku.dk>
Message-ID: <Pine.GSO.4.53.0309142225010.4913@herkules>

Hi Axel,

You may wish to consult the man page for the '==' operator and the
'identical' function.

> identical(1, "1")
[1] FALSE
> ? "=="
> ? identical

And probably your notion of a "bug" is too wide: please have a look at the
section "R Bugs", 9.1 in the R FAQ.

Best regards
   Wolfgang

-------------------------------------
Wolfgang Huber
Division of Molecular Genome Analysis
German Cancer Research Center
Heidelberg, Germany
Phone: +49 6221 424709
Fax:   +49 6221 42524709
Http:  www.dkfz.de/mga/whuber
-------------------------------------

On Sat, 13 Sep 2003 axel.benz@iao.fhg.de wrote:

> Full_Name: Axel Benz
> Version: 1.7.1
> OS: Windows
> Submission from: (NULL) (137.251.33.43)
>
>
> This feature seems to be a basic bug:
>
> > 1=="1"
> [1] TRUE
> > as.numeric(1)=="1"
> [1] TRUE
> > as.numeric(1)==as.character("1")
> [1] TRUE
>
> isn't it necessary to distinguish beteen numbers and characters??
>
> Best Regards,
> Axel
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From ross at biostat.ucsf.edu  Mon Sep 15 01:42:54 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon Sep 15 09:43:52 2003
Subject: [Rd] glitch in terms documentation (PR#4146)
In-Reply-To: <Pine.LNX.4.44.0309130751460.25290-100000@gannet.stats>
References: <200309122141.h8CLfXJH018735@pubhealth.ku.dk>
	<Pine.LNX.4.44.0309130751460.25290-100000@gannet.stats>
Message-ID: <20030915074254.GN12620@wheat.boylan.org>

On Sat, Sep 13, 2003 at 08:00:06AM +0100, Prof Brian Ripley wrote:
> On Fri, 12 Sep 2003 ross@biostat.ucsf.edu wrote:
> 
> > These are two small items that caught my eye.
> > 
> > I'm looking at the R 1.7.1 2003-06-16 pdf reference manual.  There are
> > several refences to terms.default (e.g., p. 711, 712) but no definitions
> > of it.  I'm guessing this means terms, but it's a little puzzling.
> 
> No, it means the default method of the terms generic. Try ?terms.default, 
> which gives you a complete explanation.
> 
> Page numbers are useless to us, BTW, as they depend on the papersize and
> I suspect you are not using ISO sizes.

I think it's US letter size.  The references are from the "See Also"
sections for terms and terms.formula.

When I go ?terms.default I get a help page that has a heading of
"terms".  This is the same as I see in the reference manual: there is
an entry for "terms", but not for "terms.generic."

So the manual includes cross-references that do not appear in any of
the page titles or in the index.

Perhaps this is a general rule for the documentation.  As I said, I
found it confusing.

Now, the other glitch, as originally reported by me, contains a
generous mix of my confusion and what still seem to me to be actual
problems with the manual....  
> 
> > Also, the desription of terms.object  does not mention that the
> > "variables" attribute is actually a list of calls--surprising to me,
> 
> It isn't.  It is a single call to list.
> 
> > since I was expecting text like all.vars.
> 
> But, it says it is a `list'.  Wrong, but not character (if that is what 
> you meant by `text').

So probably the description of variables should not say it is a list
(even if it is a call to list).

Another problem is that the things after the call to list are not
necessarily variables at all, but may be expressions (e.g, for
Surv(t)~b+c). 

I think it would be good if the description of "variables" (or its
name?) could be reworded to be more correct.  Optionally, clarifying
that it is not helpful for naive use would be nice.  My current
understanding is that it is something like the parse tree for the
formula. 

Based on subsequent discussion on r-help, it also seems the
description of "response" needs some work too.  To be really
simple-minded, I have response=1.  If I use this to index into
"variables" I get list().  The current description seems to imply this
should yield the response variable (or, more accurately, term).

The last bit below was mostly wishful thinking on my part.  You should 
probably ignore it:
> 
> >   It would be useful to
> > indicate if all.vars returns the same ordering as the variables
> > attribute (at least, I'm wondering it now, though this might be a sign
> > I've gone astray).
> 
> What has all.vars to do with terms?  All.vars applies to an expression or 
> call, and terms() applies to a formula or a model object.
>
The connection was mostly in my head, as I sought a more useable (to
me) form of the variables or terms.
f <- a~b+c
t <- terms(f)
v <- all.vars(f)
and then trying to play with t and v simultaneously.

From ripley at stats.ox.ac.uk  Mon Sep 15 10:04:18 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Sep 15 10:03:42 2003
Subject: [Rd] glitch in terms documentation (PR#4146)
In-Reply-To: <20030915074254.GN12620@wheat.boylan.org>
Message-ID: <Pine.LNX.4.44.0309150852210.13135-100000@gannet.stats>

On Mon, 15 Sep 2003, Ross Boylan wrote:

> On Sat, Sep 13, 2003 at 08:00:06AM +0100, Prof Brian Ripley wrote:
> > On Fri, 12 Sep 2003 ross@biostat.ucsf.edu wrote:
> > 
> > > These are two small items that caught my eye.
> > > 
> > > I'm looking at the R 1.7.1 2003-06-16 pdf reference manual.  There are
> > > several refences to terms.default (e.g., p. 711, 712) but no definitions
> > > of it.  I'm guessing this means terms, but it's a little puzzling.
> > 
> > No, it means the default method of the terms generic. Try ?terms.default, 
> > which gives you a complete explanation.
> > 
> > Page numbers are useless to us, BTW, as they depend on the papersize and
> > I suspect you are not using ISO sizes.
> 
> I think it's US letter size.  The references are from the "See Also"
> sections for terms and terms.formula.

Yes, I found them, not on the pages you quoted.

> When I go ?terms.default I get a help page that has a heading of
> "terms".  This is the same as I see in the reference manual: there is
> an entry for "terms", but not for "terms.generic."

But terms _is_ the generic and terms.default a method. There is no 
`terms.generic', but the help page does describe the default method.

> So the manual includes cross-references that do not appear in any of
> the page titles or in the index.

That has been fixed to refer only to the generic.

> Perhaps this is a general rule for the documentation.  As I said, I
> found it confusing.

It is a general rule to only have usage for default methods if that is 
different from the generic.  I think your confusion is over the whole idea 
of generic functions and methods, not specific to this example.

> Now, the other glitch, as originally reported by me, contains a
> generous mix of my confusion and what still seem to me to be actual
> problems with the manual....  
> > 
> > > Also, the desription of terms.object  does not mention that the
> > > "variables" attribute is actually a list of calls--surprising to me,
> > 
> > It isn't.  It is a single call to list.
> > 
> > > since I was expecting text like all.vars.
> > 
> > But, it says it is a `list'.  Wrong, but not character (if that is what 
> > you meant by `text').
> 
> So probably the description of variables should not say it is a list
> (even if it is a call to list).

Again, that has been corrected.

> Another problem is that the things after the call to list are not
> necessarily variables at all, but may be expressions (e.g, for
> Surv(t)~b+c). 
> 
> I think it would be good if the description of "variables" (or its
> name?) could be reworded to be more correct.  Optionally, clarifying
> that it is not helpful for naive use would be nice.  My current
> understanding is that it is something like the parse tree for the
> formula. 

It is used widely in the R code, so it is useful.

> Based on subsequent discussion on r-help, it also seems the
> description of "response" needs some work too.  To be really
> simple-minded, I have response=1.  If I use this to index into
> "variables" I get list().  The current description seems to imply this

Well, that's not how you index into a call, and there are lots of examples
of that in the R code.

> should yield the response variable (or, more accurately, term).

It doesn't.  It is your misconception of what indexing a call yields that 
leads you to that conclusion.  To get the n'th argument of a call you need 
the (n+1)st element.

There is a general assumption in the documentation that when descirbing 
complex things the simpler concepts are understood correctly.  The real 
problem is that `variables' was not documented as a call: it now is.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From brahm at alum.mit.edu  Mon Sep 15 12:33:29 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Mon Sep 15 17:33:37 2003
Subject: [Rd] Documentation of colSums et. al (PR#4154)
References: <200309140402.h8E42RJH024697@pubhealth.ku.dk>
Message-ID: <16229.56265.738791.56004@arbres1a.fmr.com>

Doug Grove <dgrove@fhcrc.org> wrote:
> Minor mistake in the documentation on the colSums page.
> In the ARGUMENTS section it states for 'dims' that:
>    For `col*', the sum or mean is over dimensions
>    `dims+1, ...'; for `row*' it is over dimensions `1:dims'.
> These two are reversed.

I think Doug is correct, isn't he?  For example, with a 5-dimensional array and
dims=3, colSums() sums over the first 3 dimensions (the "rows") and produces a
2-dimensional result.  So the sum is over dimensions 1:dims.

By the way, S-Plus (6.1.2) documentation is also incorrect; it says "colMeans
is a 2 dimensional array consisting of the means across the last 3 dimensions"
but it's really across the first 3 dimensions.

So why has this bug report ended up in the "trashcan"?
-- 
                              -- David Brahm (brahm@alum.mit.edu)

From nlwhitehouse at yahoo.com  Mon Sep 15 09:38:45 2003
From: nlwhitehouse at yahoo.com (Nathan Whitehouse)
Date: Mon Sep 15 17:38:03 2003
Subject: [Rd] R Object models
In-Reply-To: <200309141002.h8EA2Q9g023277@stat.math.ethz.ch>
Message-ID: <20030915153845.39744.qmail@web12401.mail.yahoo.com>

Dear R Developers:

  I'm part of a group of people working to extend an
existing object-oriented mimicing layer(R.oo) to use
S4 at its base rather than S3.  The existing
package(S3-based) has a set of useful attributes for
large scale development: pass-by-reference, common
inheritance structure(root object), coding convention
and others.

  Can anyone point me to some good resources for the
difference between S3 and S4?  Also, is there any
really comprehensive discussion about how this S4
struct/dispatch/CLOS-like(?) way of thinking about
object oriented programming differs from traditional
object oriented programming?(FOP vs. OOP, in the words
of Henrik Bengtsson.)

  Thanks a lot,
  Nathan Whitehouse
  Programmer
  Shaw Lab
  Baylor College of Medicine

From p.dalgaard at biostat.ku.dk  Mon Sep 15 17:01:58 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Sep 15 18:02:02 2003
Subject: [Rd] Documentation of colSums et. al (PR#4154)
In-Reply-To: <16229.56265.738791.56004@arbres1a.fmr.com>
References: <200309140402.h8E42RJH024697@pubhealth.ku.dk>
	<16229.56265.738791.56004@arbres1a.fmr.com>
Message-ID: <x2n0d69gwo.fsf@biostat.ku.dk>

David Brahm  <brahm@alum.mit.edu> writes:

> Doug Grove <dgrove@fhcrc.org> wrote:
> > Minor mistake in the documentation on the colSums page.
> > In the ARGUMENTS section it states for 'dims' that:
> >    For `col*', the sum or mean is over dimensions
> >    `dims+1, ...'; for `row*' it is over dimensions `1:dims'.
> > These two are reversed.
> 
> I think Doug is correct, isn't he?  For example, with a 5-dimensional array and
> dims=3, colSums() sums over the first 3 dimensions (the "rows") and produces a
> 2-dimensional result.  So the sum is over dimensions 1:dims.
> 
> By the way, S-Plus (6.1.2) documentation is also incorrect; it says "colMeans
> is a 2 dimensional array consisting of the means across the last 3 dimensions"
> but it's really across the first 3 dimensions.
> 
> So why has this bug report ended up in the "trashcan"?

Quite possibly, it got engulfed in spam... Thomas did the move along
with several spam messages, but Brian had already fixed the typo at
that point. The current text reads


    dims: Which dimensions are regarded as "rows" or "columns" to sum
          over.  For 'row*', the sum or mean is over dimensions
          'dims+1, ...'; for 'col*' it is over dimensions '1:dims'.



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From pgilbert at bank-banque-canada.ca  Mon Sep 15 13:14:22 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon Sep 15 18:10:02 2003
Subject: [Rd] extended usage of data()
Message-ID: <3F65E55E.3080507@bankofcanada.ca>

I would like to request a change to the documentation for data() so that 
a usage that already works in the code becomes officially recognized (in 
the help for data(), in Writing R Extensions, and in checkDocFiles()).

In a package I am just preparing to release I have  files 
data/CNDmoneyData.R  and data/CNDmoneyData.asof.26Aug2002.R.  Each of 
these define the same 26 variables, which are components of the Canadian 
monetary aggregates, but none are named CNDmoneyData. The idea is that 
future releases may have updated versions of the data, and files would 
be given names indicating their release date. The variables can all be 
loaded with

  data("CNDmoneyData", package="CDNmoney")
or
  data("CNDmoneyData.asof.26Aug2002", package="CDNmoney")

but this usage is not indicated in the documentation, and checkDocFiles 
in R 1.8.0 objects to it. It is somewhat inconvenient to load all the 
variables individually, in the way the currently documented usage would 
suggest. Futhermore, it would be extremely inconvenient to give new 
names to updated versions of variables, as implied by the currently 
documented usage, since that would require changing all references to 
the variables when referring to different released versions.

Paul Gilbert

From dgrove at fhcrc.org  Mon Sep 15 12:05:54 2003
From: dgrove at fhcrc.org (Douglas Grove)
Date: Mon Sep 15 20:05:28 2003
Subject: [Rd] Documentation of colSums et. al (PR#4154)
In-Reply-To: <x2n0d69gwo.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0309151103420.15095-100000@jerboa.fhcrc.org>

Thanks for fixing this.  

I was initially confused, but then thought about the two
dimensional case (matrix) and realized the doc. was incorrect.

Doug



On 15 Sep 2003, Peter Dalgaard BSA wrote:

> David Brahm  <brahm@alum.mit.edu> writes:
> 
> > Doug Grove <dgrove@fhcrc.org> wrote:
> > > Minor mistake in the documentation on the colSums page.
> > > In the ARGUMENTS section it states for 'dims' that:
> > >    For `col*', the sum or mean is over dimensions
> > >    `dims+1, ...'; for `row*' it is over dimensions `1:dims'.
> > > These two are reversed.
> > 
> > I think Doug is correct, isn't he?  For example, with a 5-dimensional array and
> > dims=3, colSums() sums over the first 3 dimensions (the "rows") and produces a
> > 2-dimensional result.  So the sum is over dimensions 1:dims.
> > 
> > By the way, S-Plus (6.1.2) documentation is also incorrect; it says "colMeans
> > is a 2 dimensional array consisting of the means across the last 3 dimensions"
> > but it's really across the first 3 dimensions.
> > 
> > So why has this bug report ended up in the "trashcan"?
> 
> Quite possibly, it got engulfed in spam... Thomas did the move along
> with several spam messages, but Brian had already fixed the typo at
> that point. The current text reads
> 
> 
>     dims: Which dimensions are regarded as "rows" or "columns" to sum
>           over.  For 'row*', the sum or mean is over dimensions
>           'dims+1, ...'; for 'col*' it is over dimensions '1:dims'.
> 
> 
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907
>

From jago at mclink.it  Tue Sep 16 11:24:31 2003
From: jago at mclink.it (Stefano Iacus)
Date: Tue Sep 16 10:23:57 2003
Subject: [Rd] RAqua too hungry of cpu time
Message-ID: <32316A40-E81F-11D7-86DE-003065CC4CB8@mclink.it>

It seems that RAqua consumes too much cpu time when doing nothing.
I can't see exactly why this is happening. We have few days to fix this 
up. Any idea (after having look at the code) would be fine.

stefano

From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Sep 16 12:55:30 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue Sep 16 11:56:55 2003
Subject: [Rd] `var' broken in 1.8.0 alpha (2003-09-15)
Message-ID: <Pine.LNX.4.51.0309161150450.7958@artemis.imbe.med.uni-erlangen.de>


Hi,

in last nights alpha version, `var' is broken:

R> var(rnorm(100))
Error in var(rnorm(100)) : 3 arguments passed to "cov" which requires 4.

which I suspect is due to recent changes to `cov'. The same is true for

R> cov(rnorm(100), rnorm(100))
Error in cov(rnorm(100), rnorm(100)) : 3 arguments passed to "cov" which
requires 4.


Best,

Torsten

R> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status   alpha
major    1
minor    8.0
year     2003
month    09
day      15
language R

From ripley at stats.ox.ac.uk  Tue Sep 16 14:41:36 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Sep 16 13:43:46 2003
Subject: [Rd] getGenerics is wrong in 1.8.0 alpha (PR#4184)
Message-ID: <200309161141.h8GBfaJH019092@pubhealth.ku.dk>

I have mentioned this several times, and it is still incorrect.  So I am 
submitting a formal bug report.

In 1.7.1 in a vanilla session

> getGenerics(2)
An object of class "ObjectsWithPackage":

Object: "Arith" "Compare" "Complex" "Math2" "Math" "Ops"  "Summary"
From:   "base"  "base"    "base"    "base"  "base" "base" "base"

Object: "addNextMethod" "body<-" "coerce"  "coerce<-" "initialize" "loadMethod"
From:   "methods"       "base"   "methods" "methods"  "methods"    "methods"

Object: "show"
From:   "methods"

In 1.8.0 alpha (2003-09-16)

> getGenerics(2)
An object of class "ObjectsWithPackage":

Object: "Arith" "Compare" "Complex" "Math2" "Math" "Ops"  "Summary"
From:   "base"  "base"    "base"    "base"  "base" "base" "base"

Object: "addNextMethod" "body<-"  "coerce"  "coerce<-" "initialize"
From:   "methods"       "methods" "methods" "methods"  "methods"

Object: "loadMethod" "show"
From:   "methods"    "methods"

body<- is incorrectly attributed to "methods", although it originates in 
base (whereas Compare, Complex and Math2 do not occur in base).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Tue Sep 16 15:34:04 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue Sep 16 14:33:54 2003
Subject: [Rd] `var' broken in 1.8.0 alpha (2003-09-15)
In-Reply-To: <Pine.LNX.4.51.0309161150450.7958@artemis.imbe.med.uni-erlangen.de>
References: <Pine.LNX.4.51.0309161150450.7958@artemis.imbe.med.uni-erlangen.de>
Message-ID: <16231.828.155800.280274@gargle.gargle.HOWL>

>>>>> "Torsten" == Torsten Hothorn <Torsten.Hothorn@rzmail.uni-erlangen.de>
>>>>>     on Tue, 16 Sep 2003 11:55:30 +0200 (CEST) writes:

    Torsten> Hi,

    Torsten> in last nights alpha version, `var' is broken:

    R> var(rnorm(100))
    Torsten> Error in var(rnorm(100)) : 3 arguments passed to
    Torsten> "cov" which requires 4.

    Torsten> which I suspect is due to recent changes to
    Torsten> `cov'. The same is true for

    R> cov(rnorm(100), rnorm(100))
    Torsten> Error in cov(rnorm(100), rnorm(100)) : 3 arguments
    Torsten> passed to "cov" which requires 4.


Yes these two are related, but the e-mail subject is wrong:
It's *your* fault because you must have unpacked the new version
on top of an older one.
The official alpha version (Snapshots from here, or rsync) do
not have your problem:
Before a few days ago, there were files  
    src/library/base/R/var.R
    src/library/base/R/cov.R
the newer R-alpha do not have them -- and if you use the old
files where you shouldn't --> you get the problem.

Regards,
Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

From ggruene at lumc.edu  Tue Sep 16 15:51:08 2003
From: ggruene at lumc.edu (ggruene@lumc.edu)
Date: Tue Sep 16 14:50:22 2003
Subject: [Rd] With the recent OS changes (windows 2000) necessitated by
	(PR#4187)
Message-ID: <200309161251.h8GCp8JH020353@pubhealth.ku.dk>

With the recent OS changes (windows 2000) necessitated by various worms, etc, I have now been receiving this error message when I run update and I am not sure how I can correct. 

>update.packages()
>trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  : 
        cannot open: HTTP status was `404'


Thanks,  Greg G

	[[alternative HTML version deleted]]

From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Sep 16 15:54:20 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue Sep 16 14:53:40 2003
Subject: [Rd] `var' broken in 1.8.0 alpha (2003-09-15)
In-Reply-To: <16231.828.155800.280274@gargle.gargle.HOWL>
References: <Pine.LNX.4.51.0309161150450.7958@artemis.imbe.med.uni-erlangen.de>
	<16231.828.155800.280274@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.51.0309161444260.7958@artemis.imbe.med.uni-erlangen.de>


> Yes these two are related, but the e-mail subject is wrong:
> It's *your* fault because you must have unpacked the new version
> on top of an older one.
> The official alpha version (Snapshots from here, or rsync) do
> not have your problem:
> Before a few days ago, there were files
>     src/library/base/R/var.R
>     src/library/base/R/cov.R
> the newer R-alpha do not have them -- and if you use the old
> files where you shouldn't --> you get the problem.
>

yes, thats the problem, however it is a problem with rsync. I
update the tree via

	rsync -rC rsync.r-project.org::r-devel R

an this does not remove those files:

hothorn@www:~/software/R/src/library/base/R$ ls -la cov.R
-rw-r--r--    1 hothorn  users         375 Sep 12 04:00 cov.R
hothorn@www:~/software/R/src/library/base/R$ ls -la var.R
-rw-r--r--    1 hothorn  users         361 Sep 12 04:00 var.R

A possible fix is using

	rsync -rC --delete rsync.r-project.org::r-devel R

(maybe one should add a hint in section 2.4 of the FAQ).

Thank you for pointing this out!

Best,

Torsten


> Regards,
> Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
> ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
> phone: x-41-1-632-3408		fax: ...-1228			<><
>
>

From ripley at stats.ox.ac.uk  Tue Sep 16 15:59:36 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Sep 16 14:58:52 2003
Subject: [Rd] With the recent OS changes (windows 2000) necessitated by
	(PR#4188)
Message-ID: <200309161259.h8GCxaJH020521@pubhealth.ku.dk>

This is not a bug.  It indicates that *you* don't have direct internet
access.  There is an item in the rw-FAQ about this.

Please do not use R-bugs to report problems in your own environment, nor to
ask questions (especially those covered in FAQs).

On Tue, 16 Sep 2003 ggruene@lumc.edu wrote:

> With the recent OS changes (windows 2000) necessitated by various worms, etc, I have now been receiving this error message when I run update and I am not sure how I can correct.
>
> >update.packages()
> >trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
> Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  :
>         cannot open: HTTP status was `404'

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Tue Sep 16 14:59:33 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue Sep 16 14:59:11 2003
Subject: [Rd] With the recent OS changes (windows 2000) necessitated by
	(PR#4187)
In-Reply-To: <200309161251.h8GCp8JH020353@pubhealth.ku.dk>
Message-ID: <Pine.WNT.4.44.0309161357480.2252-100000@gannet.stats.ox.ac.uk>

This is not a bug.  It indicates that *you* don't have direct internet
access.  There is an item in the rw-FAQ about this.

Please do not use R-bugs to report problems in your own environment, nor to
ask questions (especially those covered in FAQs).

On Tue, 16 Sep 2003 ggruene@lumc.edu wrote:

> With the recent OS changes (windows 2000) necessitated by various worms, etc, I have now been receiving this error message when I run update and I am not sure how I can correct.
>
> >update.packages()
> >trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
> Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  :
>         cannot open: HTTP status was `404'

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ligges at statistik.uni-dortmund.de  Tue Sep 16 16:14:05 2003
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Tue Sep 16 15:13:44 2003
Subject: [Rd] With the recent OS changes (windows 2000) necessitated by
	(PR#4189)
Message-ID: <200309161314.h8GDE5JH020785@pubhealth.ku.dk>

ggruene@lumc.edu wrote:

> With the recent OS changes (windows 2000) necessitated by various worms, etc, I have now been receiving this error message when I run update and I am not sure how I can correct. 
> 
> 
>>update.packages()
>>trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
> 
> Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  : 
>         cannot open: HTTP status was `404'
> 
> 

That's not a bug - neither in Windows nor in R!

The Windows binary versions of contributed packages for R < 1.7.0 have 
been moved. It has been announced on r-announce (hence also on r-help), 
and it's mentioned in
   Your-CRAN-Mirror/bin/windows/contrib/ReadMe,
that you should upgrade to a recent version of R (you have not told it, 
but you are using R < 1.7.0).

You can still get the packages from
   Your-CRAN-Mirror/bin/windows/contrib/1.6

Also read
   Your-CRAN-Mirror/bin/windows/contrib/1.6/ReadMe
that these packages won't be updated any more (and have not been for 
quite some time now).

Uwe Ligges

From maechler at stat.math.ethz.ch  Tue Sep 16 16:21:43 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue Sep 16 15:21:01 2003
Subject: [Rd] `var' broken in 1.8.0 alpha (2003-09-15)
In-Reply-To: <Pine.LNX.4.51.0309161444260.7958@artemis.imbe.med.uni-erlangen.de>
References: <Pine.LNX.4.51.0309161150450.7958@artemis.imbe.med.uni-erlangen.de>
	<16231.828.155800.280274@gargle.gargle.HOWL>
	<Pine.LNX.4.51.0309161444260.7958@artemis.imbe.med.uni-erlangen.de>
Message-ID: <16231.3687.191800.740561@gargle.gargle.HOWL>

>>>>> "Torsten" == Torsten Hothorn <Torsten.Hothorn@rzmail.uni-erlangen.de>
>>>>>     on Tue, 16 Sep 2003 14:54:20 +0200 (CEST) writes:

    >> Yes these two are related, but the e-mail subject is
    >> wrong: It's *your* fault because you must have unpacked
    >> the new version on top of an older one.  The official
    >> alpha version (Snapshots from here, or rsync) do not have
    >> your problem: Before a few days ago, there were files
    >> src/library/base/R/var.R src/library/base/R/cov.R the
    >> newer R-alpha do not have them -- and if you use the old
    >> files where you shouldn't --> you get the problem.
    >> 

    Torsten> yes, thats the problem, however it is a problem
    Torsten> with rsync. 

no, but with the options you use it with...   ;-)

    Torsten> I update the tree via

    Torsten> 	rsync -rC rsync.r-project.org::r-devel R

    Torsten> an this does not remove those files:
        <......>

    Torsten> A possible fix is using
    Torsten> 	rsync -rC --delete rsync.r-project.org::r-devel R

Of course, I've always used something like the above -- that's
why I said above rsync would also give the correct files... 

    Torsten> (maybe one should add a hint in section 2.4 of the
    Torsten> FAQ).

Definitely.

From simon.urbanek at math.uni-augsburg.de  Tue Sep 16 12:35:40 2003
From: simon.urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Tue Sep 16 15:58:13 2003
Subject: [Rd] RAqua too hungry of cpu time
In-Reply-To: <32316A40-E81F-11D7-86DE-003065CC4CB8@mclink.it>
Message-ID: <22D9AC1C-E829-11D7-8731-000A959F327E@math.uni-augsburg.de>

On Tuesday, September 16, 2003, at 10:24 AM, Stefano Iacus wrote:

> It seems that RAqua consumes too much cpu time when doing nothing.
> I can't see exactly why this is happening. We have few days to fix 
> this up. Any idea (after having look at the code) would be fine.

Well, it happens exactly what the code says ;). RAqua is spending all 
the time in those loops like this one:

    while(!InputFinished & !HaveBigBuffer)
         Raqua_ProcessEvents();

(This one comes from Raqua_ReadConsole)

Since in Raqua_ProcessEvents you simply call ReceiveNextEvent with 
kEventDurationNoWait, the function returns almost immediately and is 
called again ... so in effect you are hogging 100% CPU. I'd suggest 
using either some sensible timeout or kEventDurationForever.

Cheers,
Simon

---
Simon Urbanek
Department of computer oriented statistics and data analysis
Universit?tsstr. 14
86135 Augsburg
Germany

Tel: +49-821-598-2236
Fax: +49-821-598-2280

Simon.Urbanek@Math.Uni-Augsburg.de
http://simon.urbanek.info
From jago at mclink.it  Tue Sep 16 14:24:46 2003
From: jago at mclink.it (Stefano Iacus)
Date: Tue Sep 16 15:58:33 2003
Subject: [Rd] RAqua too hungry of cpu time
In-Reply-To: <22D9AC1C-E829-11D7-8731-000A959F327E@math.uni-augsburg.de>
Message-ID: <60A5EC5A-E838-11D7-86DE-003065CC4CB8@mclink.it>


On Marted?, set 16, 2003, at 11:35 Europe/Rome, Simon Urbanek wrote:

> On Tuesday, September 16, 2003, at 10:24 AM, Stefano Iacus wrote:
>
>> It seems that RAqua consumes too much cpu time when doing nothing.
>> I can't see exactly why this is happening. We have few days to fix 
>> this up. Any idea (after having look at the code) would be fine.
>
> Well, it happens exactly what the code says ;). RAqua is spending all 
> the time in those loops like this one:
>
>    while(!InputFinished & !HaveBigBuffer)
>         Raqua_ProcessEvents();
>
> (This one comes from Raqua_ReadConsole)
>
> Since in Raqua_ProcessEvents you simply call ReceiveNextEvent with 
> kEventDurationNoWait, the function returns almost immediately and is 
> called again ... so in effect you are hogging 100% CPU. I'd suggest 
> using either some sensible timeout or kEventDurationForever.

yes, kEventDurationForever is only a partial solution as all the timers 
I have setup to refresh the console etc won't work.
Is there any way to let the timer wake-up ReceiveNextEvent when 
kEventDurationForever is set? This will be the solution.

stefano

>
> Cheers,
> Simon
>
> ---
> Simon Urbanek
> Department of computer oriented statistics and data analysis
> Universit?tsstr. 14
> 86135 Augsburg
> Germany
>
> Tel: +49-821-598-2236
> Fax: +49-821-598-2280
>
> Simon.Urbanek@Math.Uni-Augsburg.de
> http://simon.urbanek.info
From p.dalgaard at biostat.ku.dk  Tue Sep 16 15:21:26 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Sep 16 16:21:28 2003
Subject: [Rd] RAqua too hungry of cpu time
In-Reply-To: <60A5EC5A-E838-11D7-86DE-003065CC4CB8@mclink.it>
References: <60A5EC5A-E838-11D7-86DE-003065CC4CB8@mclink.it>
Message-ID: <x2u17c3j6p.fsf@biostat.ku.dk>

Stefano Iacus <jago@mclink.it> writes:

> On Marted?, set 16, 2003, at 11:35 Europe/Rome, Simon Urbanek wrote:
> 
> > On Tuesday, September 16, 2003, at 10:24 AM, Stefano Iacus wrote:
> >
> >> It seems that RAqua consumes too much cpu time when doing nothing.
> >> I can't see exactly why this is happening. We have few days to fix
> >> this up. Any idea (after having look at the code) would be fine.
> >
> > Well, it happens exactly what the code says ;). RAqua is spending
> > all the time in those loops like this one:
> >
> >    while(!InputFinished & !HaveBigBuffer)
> >         Raqua_ProcessEvents();
> >
> > (This one comes from Raqua_ReadConsole)
> >
> > Since in Raqua_ProcessEvents you simply call ReceiveNextEvent with
> > kEventDurationNoWait, the function returns almost immediately and is
> > called again ... so in effect you are hogging 100% CPU. I'd suggest
> > using either some sensible timeout or kEventDurationForever.
> 
> yes, kEventDurationForever is only a partial solution as all the
> timers I have setup to refresh the console etc won't work.
> Is there any way to let the timer wake-up ReceiveNextEvent when
> kEventDurationForever is set? This will be the solution.

Can't you just set the timeout to 10ms or so? That's basically what
the select() based mechanism for X11 does.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From jgentry at jimmy.harvard.edu  Tue Sep 16 14:08:31 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Tue Sep 16 19:08:50 2003
Subject: [Rd] couldn't find function "setClass"
Message-ID: <Pine.SOL.4.20.0309161305430.15392-100000@santiam.dfci.harvard.edu>


Hello ...

With a new checkout of R-devel (last update was 2003-09-11) we are having
a problem (it seems to be happening to all of us here on a few different
machines) where during install/check/etc when the 'save image' happens (in
packages using 'save image'):

** save image
Error: couldn't find function "setClass"
Execution halted


This is for all packages that are using classes.

Is anyone else having this problem?

From bates at stat.wisc.edu  Tue Sep 16 18:21:35 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue Sep 16 19:21:36 2003
Subject: [Rd] couldn't find function "setClass"
In-Reply-To: <Pine.SOL.4.20.0309161305430.15392-100000@santiam.dfci.harvard.edu>
References: <Pine.SOL.4.20.0309161305430.15392-100000@santiam.dfci.harvard.edu>
Message-ID: <6rbrtkfy2e.fsf@bates4.stat.wisc.edu>

Jeff Gentry <jgentry@jimmy.harvard.edu> writes:

> With a new checkout of R-devel (last update was 2003-09-11) we are having
> a problem (it seems to be happening to all of us here on a few different
> machines) where during install/check/etc when the 'save image' happens (in
> packages using 'save image'):
> 
> ** save image
> Error: couldn't find function "setClass"
> Execution halted
> 
> 
> This is for all packages that are using classes.
> 
> Is anyone else having this problem?

Did you make sure that you have

require(methods)

early in your R sources for the package?

Depending upon the default set of packages loaded you may not have the
methods package available during install if you don't require it.

From jgentry at jimmy.harvard.edu  Tue Sep 16 15:11:49 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Tue Sep 16 20:14:23 2003
Subject: [Rd] couldn't find function "setClass"
In-Reply-To: <6rbrtkfy2e.fsf@bates4.stat.wisc.edu>
Message-ID: <Pine.SOL.4.20.0309161410080.15392-100000@santiam.dfci.harvard.edu>

> Did you make sure that you have
> require(methods)
> early in your R sources for the package?

No, and that was exactly the problem (although specifically I put the
'require(methods)' into the R_PROFILE.R file).  I was under the impression
that methods was always loaded by default when R started up (and thus,
many of the BioC packages no longer have an explicit 'require(methods)'
call).  As I said, this is something relatively recent in R-devel, and
wasn't necessary just a week ago ... I'm assuming it was an intended
change tho. :)

Thanks
-J

From jmc at research.bell-labs.com  Tue Sep 16 16:08:33 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Tue Sep 16 21:08:51 2003
Subject: [Rd] couldn't find function "setClass"
References: <Pine.SOL.4.20.0309161305430.15392-100000@santiam.dfci.harvard.edu>
Message-ID: <3F675FB1.E9527C9C@research.bell-labs.com>

Jeff Gentry wrote:
> 
> Hello ...
> 
> With a new checkout of R-devel (last update was 2003-09-11) we are having
> a problem (it seems to be happening to all of us here on a few different
> machines) where during install/check/etc when the 'save image' happens (in
> packages using 'save image'):
> 
> ** save image
> Error: couldn't find function "setClass"
> Execution halted
> 
> This is for all packages that are using classes.
> 
> Is anyone else having this problem?
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

With packages that do NOT have a namespace but DO have saved images,
yes. (!)

The problem seems to be that the current version of INSTALL doesn't end
up with library(methods) in this branch (related to --vanilla ?).  One
workaround seem to be to change INSTALL (or scripts/INSTALL.in) as
follows:

522c522
<       code_cmd="eval cat \"${code_file}\""
---
>       code_cmd="eval echo \"library(methods)\"; cat \"${code_file}\""

to explicitly attach the library.  This may in fact be the right fix,
but I'm confused as to why this is happening now.

(For me it also works to not use saved images.)

John

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From ripley at stats.ox.ac.uk  Tue Sep 16 21:18:04 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Sep 16 21:17:34 2003
Subject: [Rd] couldn't find function "setClass"
In-Reply-To: <Pine.SOL.4.20.0309161410080.15392-100000@santiam.dfci.harvard.edu>
Message-ID: <Pine.LNX.4.44.0309162016190.2134-100000@gannet.stats>

It's not been a valid assumption ever (or as long as I can recall).
The only thing you can assume in base.  We try to be careful in the R 
tarball, but things slip past.

BDR

On Tue, 16 Sep 2003, Jeff Gentry wrote:

> > Did you make sure that you have
> > require(methods)
> > early in your R sources for the package?
> 
> No, and that was exactly the problem (although specifically I put the
> 'require(methods)' into the R_PROFILE.R file).  I was under the impression
> that methods was always loaded by default when R started up (and thus,
> many of the BioC packages no longer have an explicit 'require(methods)'
> call).  As I said, this is something relatively recent in R-devel, and
> wasn't necessary just a week ago ... I'm assuming it was an intended
> change tho. :)
> 
> Thanks
> -J
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Tue Sep 16 21:21:04 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Sep 16 21:20:25 2003
Subject: [Rd] couldn't find function "setClass"
In-Reply-To: <3F675FB1.E9527C9C@research.bell-labs.com>
Message-ID: <Pine.LNX.4.44.0309162018500.2134-100000@gannet.stats>

On Tue, 16 Sep 2003, John Chambers wrote:

> Jeff Gentry wrote:
> > 
> > Hello ...
> > 
> > With a new checkout of R-devel (last update was 2003-09-11) we are having
> > a problem (it seems to be happening to all of us here on a few different
> > machines) where during install/check/etc when the 'save image' happens (in
> > packages using 'save image'):
> > 
> > ** save image
> > Error: couldn't find function "setClass"
> > Execution halted
> > 
> > This is for all packages that are using classes.
> > 
> > Is anyone else having this problem?
> 
> With packages that do NOT have a namespace but DO have saved images,
> yes. (!)
> 
> The problem seems to be that the current version of INSTALL doesn't end
> up with library(methods) in this branch (related to --vanilla ?).  One

It's not related to --vanilla, which does not change the packages loaded.
See Kurt's comment for what I believe is the true reason.

> workaround seem to be to change INSTALL (or scripts/INSTALL.in) as
> follows:
> 
> 522c522
> <       code_cmd="eval cat \"${code_file}\""
> ---
> >       code_cmd="eval echo \"library(methods)\"; cat \"${code_file}\""
> 
> to explicitly attach the library.  This may in fact be the right fix,
> but I'm confused as to why this is happening now.

I don't think so: methods is currently optional and Doug's fix seems to be 
to be the right one.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jmc at research.bell-labs.com  Tue Sep 16 16:27:36 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Tue Sep 16 21:27:56 2003
Subject: [Rd] couldn't find function "setClass"
References: <Pine.LNX.4.44.0309162018500.2134-100000@gannet.stats>
Message-ID: <3F676428.89D40FBB@research.bell-labs.com>

Prof Brian Ripley wrote:
> 
> On Tue, 16 Sep 2003, John Chambers wrote:
> 
> > Jeff Gentry wrote:
> > >
> > > Hello ...
> > >
> > > With a new checkout of R-devel (last update was 2003-09-11) we are having
> > > a problem (it seems to be happening to all of us here on a few different
> > > machines) where during install/check/etc when the 'save image' happens (in
> > > packages using 'save image'):
> > >
> > > ** save image
> > > Error: couldn't find function "setClass"
> > > Execution halted
> > >
> > > This is for all packages that are using classes.
> > >
> > > Is anyone else having this problem?
> >
> > With packages that do NOT have a namespace but DO have saved images,
> > yes. (!)
> >
> > The problem seems to be that the current version of INSTALL doesn't end
> > up with library(methods) in this branch (related to --vanilla ?).  One
> 
> It's not related to --vanilla, which does not change the packages loaded.
> See Kurt's comment for what I believe is the true reason.
> 
> > workaround seem to be to change INSTALL (or scripts/INSTALL.in) as
> > follows:
> >
> > 522c522
> > <       code_cmd="eval cat \"${code_file}\""
> > ---
> > >       code_cmd="eval echo \"library(methods)\"; cat \"${code_file}\""
> >
> > to explicitly attach the library.  This may in fact be the right fix,
> > but I'm confused as to why this is happening now.
> 
> I don't think so: methods is currently optional and Doug's fix seems to be
> to be the right one.

That (apparently) the problem arises in such a special situation is
confusing  for users.  At least for me, it's ONLY in the combination of
saved image and no namespace.

That the user does not need a require(methods) when testing the code
directly but does (sometimes) when the source code is in package source
is not a feature.  If we can avoid this complexity, that would encourage
package developers.

John

> 
> --
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From axel.benz at iao.fhg.de  Tue Sep 16 22:39:02 2003
From: axel.benz at iao.fhg.de (axel.benz@iao.fhg.de)
Date: Tue Sep 16 21:40:20 2003
Subject: [Rd] How does "subset" replace arguments? (PR#4193)
Message-ID: <200309161939.h8GJd2JH023713@pubhealth.ku.dk>

Full_Name: Axel Benz
Version: 1.7.1
OS: Windows
Submission from: (NULL) (137.251.33.43)


Hello,
I guess many people will answer me again that this is a S language feature, but
I am only a stupid computer scientist and I simply do not understand this logic,
despite of reading a lot about S:

> test
   field           tuckey
4  Kreis2          -1
5  Kreis5          -2
9  Metall          -3
17 Kreis1          -4
19 Kreis8          -5

> subset(test,field=="Metall")
  field       tuckey
9 Metall      -3

> subset(test,toString(field)=="Metall")
[1] field   tuckey
<0 rows> (or 0-length row.names)

This happens everytime I use a function with the column name ("field", in this
case) as parameter in the  logic expression in "subset", instead of using the
column name on top level. I have the impression that the column name is only
replaced when standing in top level position. I would call that "very lazy
evaluation" ;-) ;-)
Thank you for a friendly answer, this language is realy weird to me.

From Kurt.Hornik at wu-wien.ac.at  Tue Sep 16 22:40:13 2003
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Tue Sep 16 21:43:43 2003
Subject: [Rd] couldn't find function "setClass"
In-Reply-To: <3F676428.89D40FBB@research.bell-labs.com>
References: <Pine.LNX.4.44.0309162018500.2134-100000@gannet.stats>
	<3F676428.89D40FBB@research.bell-labs.com>
Message-ID: <16231.26397.947510.613524@mithrandir.hornik.net>

>>>>> John Chambers writes:

> Prof Brian Ripley wrote:
>> 
>> On Tue, 16 Sep 2003, John Chambers wrote:
>> 
>> > Jeff Gentry wrote:
>> > >
>> > > Hello ...
>> > >
>> > > With a new checkout of R-devel (last update was 2003-09-11) we are having
>> > > a problem (it seems to be happening to all of us here on a few different
>> > > machines) where during install/check/etc when the 'save image' happens (in
>> > > packages using 'save image'):
>> > >
>> > > ** save image
>> > > Error: couldn't find function "setClass"
>> > > Execution halted
>> > >
>> > > This is for all packages that are using classes.
>> > >
>> > > Is anyone else having this problem?
>> >
>> > With packages that do NOT have a namespace but DO have saved images,
>> > yes. (!)
>> >
>> > The problem seems to be that the current version of INSTALL doesn't end
>> > up with library(methods) in this branch (related to --vanilla ?).  One
>> 
>> It's not related to --vanilla, which does not change the packages loaded.
>> See Kurt's comment for what I believe is the true reason.
>> 
>> > workaround seem to be to change INSTALL (or scripts/INSTALL.in) as
>> > follows:
>> >
>> > 522c522
>> > <       code_cmd="eval cat \"${code_file}\""
>> > ---
>> > >       code_cmd="eval echo \"library(methods)\"; cat \"${code_file}\""
>> >
>> > to explicitly attach the library.  This may in fact be the right fix,
>> > but I'm confused as to why this is happening now.
>> 
>> I don't think so: methods is currently optional and Doug's fix seems to be
>> to be the right one.

> That (apparently) the problem arises in such a special situation is
> confusing for users.  At least for me, it's ONLY in the combination of
> saved image and no namespace.

> That the user does not need a require(methods) when testing the code
> directly but does (sometimes) when the source code is in package
> source is not a feature.  If we can avoid this complexity, that would
> encourage package developers.

Unfortunately, it is not necessarily true that require(methods) is not
needed when testing: site admins or "users" might have changed the
default packages from the system default.

Otoh, once we use --vanilla for the save image creation, it seems that
this eliminates all (reasonable) possibilities for changing the default
packages (or am I missing something?).  So we could use the system
default rather than just base here.

-k

From deepayan at stat.wisc.edu  Tue Sep 16 16:02:09 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue Sep 16 22:05:35 2003
Subject: [Rd] How does "subset" replace arguments? (PR#4193)
In-Reply-To: <200309161939.h8GJd2JH023713@pubhealth.ku.dk>
References: <200309161939.h8GJd2JH023713@pubhealth.ku.dk>
Message-ID: <200309161502.09158.deepayan@stat.wisc.edu>

On Tuesday 16 September 2003 14:39, axel.benz@iao.fhg.de wrote:
> Full_Name: Axel Benz
> Version: 1.7.1
> OS: Windows
> Submission from: (NULL) (137.251.33.43)
> 
> 
> Hello,
> I guess many people will answer me again that this is a S language feature, 
but
> I am only a stupid computer scientist and I simply do not understand this 
logic,
> despite of reading a lot about S:
> 
> > test
>    field           tuckey
> 4  Kreis2          -1
> 5  Kreis5          -2
> 9  Metall          -3
> 17 Kreis1          -4
> 19 Kreis8          -5
> 
> > subset(test,field=="Metall")
>   field       tuckey
> 9 Metall      -3
> 
> > subset(test,toString(field)=="Metall")
> [1] field   tuckey
> <0 rows> (or 0-length row.names)

I don't see any problem here. toString(field), evaluated in the data frame 
test, should be the single string

"Kreis2, Kreis5, Metall, Kreis1, Kreis8"

So, the comparison 

toString(field)=="Metall" 

actually does 

"Kreis2, Kreis5, Metall, Kreis1, Kreis8" == "Metall"

which being false, returns FALSE, and so you finally should get 

subset(test, FALSE)

which is what you do get.

Perhaps you misunderstood what the function toString() does.

HTH,

Deepayan

P.S. Please don't use R-bugs to report what may or may not be bugs, since all 
such reports have to be processed manually. Ask on r-help or r-devel first if 
you are not sure.

From jmc at research.bell-labs.com  Tue Sep 16 17:06:27 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Tue Sep 16 22:08:43 2003
Subject: [Rd] couldn't find function "setClass"
References: <Pine.LNX.4.44.0309162018500.2134-100000@gannet.stats>
	<3F676428.89D40FBB@research.bell-labs.com>
	<16231.26397.947510.613524@mithrandir.hornik.net>
Message-ID: <3F676D43.AEB89326@research.bell-labs.com>

Kurt Hornik wrote:
> 
> >>>>> John Chambers writes:
> 
> > Prof Brian Ripley wrote:
> >>
> >> On Tue, 16 Sep 2003, John Chambers wrote:
> >>
> >> > Jeff Gentry wrote:
> >> > >
> >> > > Hello ...
> >> > >
> >> > > With a new checkout of R-devel (last update was 2003-09-11) we are having
> >> > > a problem (it seems to be happening to all of us here on a few different
> >> > > machines) where during install/check/etc when the 'save image' happens (in
> >> > > packages using 'save image'):
> >> > >
> >> > > ** save image
> >> > > Error: couldn't find function "setClass"
> >> > > Execution halted
> >> > >
> >> > > This is for all packages that are using classes.
> >> > >
> >> > > Is anyone else having this problem?
> >> >
> >> > With packages that do NOT have a namespace but DO have saved images,
> >> > yes. (!)
> >> >
> >> > The problem seems to be that the current version of INSTALL doesn't end
> >> > up with library(methods) in this branch (related to --vanilla ?).  One
> >>
> >> It's not related to --vanilla, which does not change the packages loaded.
> >> See Kurt's comment for what I believe is the true reason.
> >>
> >> > workaround seem to be to change INSTALL (or scripts/INSTALL.in) as
> >> > follows:
> >> >
> >> > 522c522
> >> > <       code_cmd="eval cat \"${code_file}\""
> >> > ---
> >> > >       code_cmd="eval echo \"library(methods)\"; cat \"${code_file}\""
> >> >
> >> > to explicitly attach the library.  This may in fact be the right fix,
> >> > but I'm confused as to why this is happening now.
> >>
> >> I don't think so: methods is currently optional and Doug's fix seems to be
> >> to be the right one.
> 
> > That (apparently) the problem arises in such a special situation is
> > confusing for users.  At least for me, it's ONLY in the combination of
> > saved image and no namespace.
> 
> > That the user does not need a require(methods) when testing the code
> > directly but does (sometimes) when the source code is in package
> > source is not a feature.  If we can avoid this complexity, that would
> > encourage package developers.
> 
> Unfortunately, it is not necessarily true that require(methods) is not
> needed when testing: site admins or "users" might have changed the
> default packages from the system default.

Indeed, but then the user would always see things this way.  Consistency
makes people feel more secure.

> 
> Otoh, once we use --vanilla for the save image creation, it seems that
> this eliminates all (reasonable) possibilities for changing the default
> packages (or am I missing something?).  So we could use the system
> default rather than just base here.

Intuitively, --vanilla means "the standard flavor", as opposed to
--stripped, say, so it would seem more natural to have the system
defaults wherever possible.

John

> 
> -k

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From tlumley at u.washington.edu  Tue Sep 16 14:11:48 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue Sep 16 22:13:42 2003
Subject: [Rd] How does "subset" replace arguments? (PR#4193)
In-Reply-To: <200309161939.h8GJd2JH023713@pubhealth.ku.dk>
Message-ID: <Pine.A41.4.44.0309161301180.210154-100000@homer06.u.washington.edu>

On Tue, 16 Sep 2003 axel.benz@iao.fhg.de wrote:

> Full_Name: Axel Benz
> Version: 1.7.1
> OS: Windows
> Submission from: (NULL) (137.251.33.43)
>
>
> Hello, I guess many people will answer me again that this is a S
> language feature, but I am only a stupid computer scientist and I simply
> do not understand this logic, despite of reading a lot about S:

The point they are trying to make is that you should send this sort of
question to r-devel or r-help, not r-bugs.  The point of r-bugs is as a
repository for bug reports, not as a discussion list.


> > test
>    field           tuckey
> 4  Kreis2          -1
> 5  Kreis5          -2
> 9  Metall          -3
> 17 Kreis1          -4
> 19 Kreis8          -5
>
> > subset(test,field=="Metall")
>   field       tuckey
> 9 Metall      -3
>
> > subset(test,toString(field)=="Metall")
> [1] field   tuckey
> <0 rows> (or 0-length row.names)
>
> This happens everytime I use a function with the column name ("field", in this
> case) as parameter in the  logic expression in "subset", instead of using the
> column name on top level. I have the impression that the column name is only
> replaced when standing in top level position. I would call that "very lazy
> evaluation" ;-) ;-)
> Thank you for a friendly answer, this language is realy weird to me.
>

Your impression is incorrect.  The problem with toString is that it
collapses a vector to a single string, so toString(field) is the string
"Kreis2, Kreis5, Metall, Kries1, Kries8".  There is no record whose
`field' is equal to that string.  Did you check to see that toString did
what you thought it did?


subset() will work as I think you expect if the output of the function is
the same length as the input.

For example, consider one of the built-in data sets

data(esoph)
> subset(esoph, toString(agegp)=="75+")
[1] agegp     alcgp     tobgp     ncases    ncontrols
<0 rows> (or 0-length row.names)

but

> subset(esoph, as.character(agegp)=="75+")
   agegp     alcgp    tobgp ncases ncontrols
78   75+ 0-39g/day 0-9g/day      1        18
79   75+ 0-39g/day    10-19      2         6
80   75+ 0-39g/day      30+      1         3
81   75+     40-79 0-9g/day      2         5
82   75+     40-79    10-19      1         3
83   75+     40-79    20-29      0         3
84   75+     40-79      30+      1         1
85   75+    80-119 0-9g/day      1         1
86   75+    80-119    10-19      1         1
87   75+      120+ 0-9g/day      2         2
88   75+      120+    10-19      1         1


or to take a really extreme version
> subset(esoph, substr(paste(as.character(agegp),toupper(as.character(agegp))),3,6)== "+ 75")
   agegp     alcgp    tobgp ncases ncontrols
78   75+ 0-39g/day 0-9g/day      1        18
79   75+ 0-39g/day    10-19      2         6
80   75+ 0-39g/day      30+      1         3
81   75+     40-79 0-9g/day      2         5
82   75+     40-79    10-19      1         3
83   75+     40-79    20-29      0         3
84   75+     40-79      30+      1         1
85   75+    80-119 0-9g/day      1         1
86   75+    80-119    10-19      1         1
87   75+      120+ 0-9g/day      2         2
88   75+      120+    10-19      1         1


	-thomas

From kleiweg at let.rug.nl  Tue Sep 16 23:23:17 2003
From: kleiweg at let.rug.nl (kleiweg@let.rug.nl)
Date: Tue Sep 16 22:23:53 2003
Subject: [Rd] hclust: median, centroid (PR#4195)
Message-ID: <200309162023.h8GKNHJH023948@pubhealth.ku.dk>


There seems to be a bug in hclust (package mva) for clustering
methods 'median' and 'centroid'.

I have written a clustering program in C and discovered that the
results for 'median' differ from those of hclust in R. I used a
third program, written by someone else in Pascal, and that
program agrees with the output of my program.

I found yet another clustering program that seems to be built on
the same fortran code as was used for hclust. The source of this
code mentions a bug in the original code that effects both
methods 'median' and 'centroid'. This program has a fix for this
bug, but I can find no similar fix in the code of R's hclust.

You can find the program with the fix at:
http://www2.biology.ualberta.ca/jbrzusto/ftp/trees/source.zip
The relevant file is: qclust.c
The bug is mentioned at line 670 of that code.
The fix for the bug starts at line 908.

Unfortunatly, I do not know Fortran programming, so I can not
offer a tested solution for hclust. I hope I have located the
problem accurately enough for others to deal with it further.

You can find a data set to test this bug at:
http://www.let.rug.nl/~kleiweg/R/data
If you source this file, and then run:

    sort(hclust(d, method="median")$height)

... you will see a list with the last value:

    0.08449670

The correct value should be:

    0.081786


--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status =
 major = 1
 minor = 7.1
 year = 2003
 month = 06
 day = 16
 language = R

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg, package:nls, package:ts, Autoloads, package:base

From jmc at research.bell-labs.com  Tue Sep 16 17:54:31 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Tue Sep 16 22:55:07 2003
Subject: [Rd] getGenerics is wrong in 1.8.0 alpha (PR#4184)
References: <200309161141.h8GBfaJH019092@pubhealth.ku.dk>
Message-ID: <3F677887.4C027496@research.bell-labs.com>

Should now be consistent.

One problem was that the base namespace, unlike other namespaces, does
not have a .packageName object.  I left this alone for now, and
special-cased the base namespace in getPackageName().

John

ripley@stats.ox.ac.uk wrote:
> 
> I have mentioned this several times, and it is still incorrect.  So I am
> submitting a formal bug report.
> 
> In 1.7.1 in a vanilla session
> 
> > getGenerics(2)
> An object of class "ObjectsWithPackage":
> 
> Object: "Arith" "Compare" "Complex" "Math2" "Math" "Ops"  "Summary"
> From:   "base"  "base"    "base"    "base"  "base" "base" "base"
> 
> Object: "addNextMethod" "body<-" "coerce"  "coerce<-" "initialize" "loadMethod"
> From:   "methods"       "base"   "methods" "methods"  "methods"    "methods"
> 
> Object: "show"
> From:   "methods"
> 
> In 1.8.0 alpha (2003-09-16)
> 
> > getGenerics(2)
> An object of class "ObjectsWithPackage":
> 
> Object: "Arith" "Compare" "Complex" "Math2" "Math" "Ops"  "Summary"
> From:   "base"  "base"    "base"    "base"  "base" "base" "base"
> 
> Object: "addNextMethod" "body<-"  "coerce"  "coerce<-" "initialize"
> From:   "methods"       "methods" "methods" "methods"  "methods"
> 
> Object: "loadMethod" "show"
> From:   "methods"    "methods"
> 
> body<- is incorrectly attributed to "methods", although it originates in
> base (whereas Compare, Complex and Math2 do not occur in base).
> 
> --
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From kleiweg at let.rug.nl  Wed Sep 17 02:30:58 2003
From: kleiweg at let.rug.nl (kleiweg@let.rug.nl)
Date: Wed Sep 17 01:33:43 2003
Subject: [Rd] plot.hclust: dendrogram too large for window (PR#4197)
Message-ID: <200309162330.h8GNUwJH024887@pubhealth.ku.dk>


plot.hclust:
Setting up a window for a dendrogram assumes the first link is
the shortest and the last is the longest. This is not always the
case when the clustering was done with hclust, method="median"
or method="centroid", and the dendrogram sometimes doesn't fit
within the window.

I propose the fix listed below.


src/main/

--- plot.c     Wed Sep 17 01:03:39 2003
+++ plot.c.new      Wed Sep 17 01:21:59 2003
@@ -3314,7 +3314,7 @@
 SEXP do_dendwindow(SEXP call, SEXP op, SEXP args, SEXP env)
 {
     int i, imax, n;
-    double pin, *ll, tmp, yval, *y, ymin, ymax, yrange;
+    double pin, *ll, tmp, yval, *y, ymin, ymax, yrange, m;
     SEXP originalArgs, merge, height, llabels, str;
     char *vmax;
     DevDesc *dd;
@@ -3357,8 +3357,14 @@
     ll =  (double*)R_alloc(n, sizeof(double));
     dnd_lptr = &(INTEGER(merge)[0]);
     dnd_rptr = &(INTEGER(merge)[n]);
-    ymin = REAL(height)[0];
-    ymax = REAL(height)[n - 1];
+    ymax = ymin = REAL(height)[0];
+    for (i = 1; i < n; i++) {
+      m = REAL(height)[i];
+      if (m > ymax)
+       ymax = m;
+      if (m < ymin)
+       ymin = m;
+    }
     pin = Rf_gpptr(dd)->pin[1];
     for (i = 0; i < n; i++) {
        str = STRING_ELT(llabels, i);




--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status =
 major = 1
 minor = 7.1
 year = 2003
 month = 06
 day = 16
 language = R

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg, package:nls, package:ts, Autoloads, package:base

From ripley at stats.ox.ac.uk  Wed Sep 17 08:05:57 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Sep 17 08:05:20 2003
Subject: [Rd] couldn't find function "setClass"
In-Reply-To: <3F676D43.AEB89326@research.bell-labs.com>
Message-ID: <Pine.LNX.4.44.0309170659220.2844-100000@gannet.stats>

On Tue, 16 Sep 2003, John Chambers wrote:

> Kurt Hornik wrote:
> > 
> > >>>>> John Chambers writes:
> > 
> > > Prof Brian Ripley wrote:
> > >>
> > >> On Tue, 16 Sep 2003, John Chambers wrote:
> > >>
> > >> > Jeff Gentry wrote:
> > >> > >
> > >> > > Hello ...
> > >> > >
> > >> > > With a new checkout of R-devel (last update was 2003-09-11) we are having
> > >> > > a problem (it seems to be happening to all of us here on a few different
> > >> > > machines) where during install/check/etc when the 'save image' happens (in
> > >> > > packages using 'save image'):
> > >> > >
> > >> > > ** save image
> > >> > > Error: couldn't find function "setClass"
> > >> > > Execution halted
> > >> > >
> > >> > > This is for all packages that are using classes.
> > >> > >
> > >> > > Is anyone else having this problem?
> > >> >
> > >> > With packages that do NOT have a namespace but DO have saved images,
> > >> > yes. (!)
> > >> >
> > >> > The problem seems to be that the current version of INSTALL doesn't end
> > >> > up with library(methods) in this branch (related to --vanilla ?).  One
> > >>
> > >> It's not related to --vanilla, which does not change the packages loaded.
> > >> See Kurt's comment for what I believe is the true reason.
> > >>
> > >> > workaround seem to be to change INSTALL (or scripts/INSTALL.in) as
> > >> > follows:
> > >> >
> > >> > 522c522
> > >> > <       code_cmd="eval cat \"${code_file}\""
> > >> > ---
> > >> > >       code_cmd="eval echo \"library(methods)\"; cat \"${code_file}\""
> > >> >
> > >> > to explicitly attach the library.  This may in fact be the right fix,
> > >> > but I'm confused as to why this is happening now.
> > >>
> > >> I don't think so: methods is currently optional and Doug's fix seems to be
> > >> to be the right one.
> > 
> > > That (apparently) the problem arises in such a special situation is
> > > confusing for users.  At least for me, it's ONLY in the combination of
> > > saved image and no namespace.
> > 
> > > That the user does not need a require(methods) when testing the code
> > > directly but does (sometimes) when the source code is in package
> > > source is not a feature.  If we can avoid this complexity, that would
> > > encourage package developers.
> > 
> > Unfortunately, it is not necessarily true that require(methods) is not
> > needed when testing: site admins or "users" might have changed the
> > default packages from the system default.
> 
> Indeed, but then the user would always see things this way.  Consistency
> makes people feel more secure.
> 
> > 
> > Otoh, once we use --vanilla for the save image creation, it seems that
> > this eliminates all (reasonable) possibilities for changing the default
> > packages (or am I missing something?).  So we could use the system
> > default rather than just base here.
> 
> Intuitively, --vanilla means "the standard flavor", as opposed to
> --stripped, say, so it would seem more natural to have the system
> defaults wherever possible.

As I have said before, --vanilla does not change the default packages, nor 
the possibility of setting the default packages at system level.

gannet% env R_DEFAULT_PACKAGES=ts R --vanilla

really does load only "package:ts".

>From ?Startup

     The command-line flag '--vanilla' implies '--no-site-file',
     '--no-init-file', '--no-restore' and '--no-environ'.

and let me add, nothing else.  It is possible for sysadmins to change the
system environment and profile files, and some do.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Kurt.Hornik at wu-wien.ac.at  Wed Sep 17 10:08:36 2003
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed Sep 17 09:09:28 2003
Subject: [Rd] couldn't find function "setClass"
In-Reply-To: <Pine.LNX.4.44.0309170659220.2844-100000@gannet.stats>
References: <3F676D43.AEB89326@research.bell-labs.com>
	<Pine.LNX.4.44.0309170659220.2844-100000@gannet.stats>
Message-ID: <16232.2164.913964.938217@mithrandir.hornik.net>

>>>>> Prof Brian Ripley writes:

> On Tue, 16 Sep 2003, John Chambers wrote:
>> Kurt Hornik wrote:
>> > 
>> > >>>>> John Chambers writes:
>> > 
>> > > Prof Brian Ripley wrote:
>> > >>
>> > >> On Tue, 16 Sep 2003, John Chambers wrote:
>> > >>
>> > >> > Jeff Gentry wrote:
>> > >> > >
>> > >> > > Hello ...
>> > >> > >
>> > >> > > With a new checkout of R-devel (last update was 2003-09-11) we are having
>> > >> > > a problem (it seems to be happening to all of us here on a few different
>> > >> > > machines) where during install/check/etc when the 'save image' happens (in
>> > >> > > packages using 'save image'):
>> > >> > >
>> > >> > > ** save image
>> > >> > > Error: couldn't find function "setClass"
>> > >> > > Execution halted
>> > >> > >
>> > >> > > This is for all packages that are using classes.
>> > >> > >
>> > >> > > Is anyone else having this problem?
>> > >> >
>> > >> > With packages that do NOT have a namespace but DO have saved images,
>> > >> > yes. (!)
>> > >> >
>> > >> > The problem seems to be that the current version of INSTALL doesn't end
>> > >> > up with library(methods) in this branch (related to --vanilla ?).  One
>> > >>
>> > >> It's not related to --vanilla, which does not change the packages loaded.
>> > >> See Kurt's comment for what I believe is the true reason.
>> > >>
>> > >> > workaround seem to be to change INSTALL (or scripts/INSTALL.in) as
>> > >> > follows:
>> > >> >
>> > >> > 522c522
>> > >> > <       code_cmd="eval cat \"${code_file}\""
>> > >> > ---
>> > >> > >       code_cmd="eval echo \"library(methods)\"; cat \"${code_file}\""
>> > >> >
>> > >> > to explicitly attach the library.  This may in fact be the right fix,
>> > >> > but I'm confused as to why this is happening now.
>> > >>
>> > >> I don't think so: methods is currently optional and Doug's fix seems to be
>> > >> to be the right one.
>> > 
>> > > That (apparently) the problem arises in such a special situation is
>> > > confusing for users.  At least for me, it's ONLY in the combination of
>> > > saved image and no namespace.
>> > 
>> > > That the user does not need a require(methods) when testing the code
>> > > directly but does (sometimes) when the source code is in package
>> > > source is not a feature.  If we can avoid this complexity, that would
>> > > encourage package developers.
>> > 
>> > Unfortunately, it is not necessarily true that require(methods) is not
>> > needed when testing: site admins or "users" might have changed the
>> > default packages from the system default.
>> 
>> Indeed, but then the user would always see things this way.  Consistency
>> makes people feel more secure.
>> 
>> > 
>> > Otoh, once we use --vanilla for the save image creation, it seems that
>> > this eliminates all (reasonable) possibilities for changing the default
>> > packages (or am I missing something?).  So we could use the system
>> > default rather than just base here.
>> 
>> Intuitively, --vanilla means "the standard flavor", as opposed to
>> --stripped, say, so it would seem more natural to have the system
>> defaults wherever possible.

> As I have said before, --vanilla does not change the default packages,
> nor the possibility of setting the default packages at system level.

> gannet% env R_DEFAULT_PACKAGES=ts R --vanilla

> really does load only "package:ts".

>> From ?Startup

>      The command-line flag '--vanilla' implies '--no-site-file',
>      '--no-init-file', '--no-restore' and '--no-environ'.

> and let me add, nothing else.  It is possible for sysadmins to change
> the system environment and profile files, and some do.

In fact, to answer to my previous question: yes, I was missing
something.  Even with --vanilla in place, site admins and users can
change the default packages via the environment variable
R_DEFAULT_PACKAGES, overriding the system defaults.

I am sympathetic with the idea of using the *system* defaults when
creating the save image, but how can we achieve that?  (I.e., ignore or
override values of R_DEFAULT_PACKAGES from the environment, in addition
to --vanilla ...)

-k

From maechler at stat.math.ethz.ch  Wed Sep 17 10:12:52 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Sep 17 09:12:33 2003
Subject: [Rd] couldn't find function "setClass"
In-Reply-To: <Pine.LNX.4.44.0309170659220.2844-100000@gannet.stats>
References: <3F676D43.AEB89326@research.bell-labs.com>
	<Pine.LNX.4.44.0309170659220.2844-100000@gannet.stats>
Message-ID: <16232.2420.708165.503471@gargle.gargle.HOWL>

>>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
>>>>>     on Wed, 17 Sep 2003 07:05:57 +0100 (BST) writes:

    BDR> On Tue, 16 Sep 2003, John Chambers wrote:

    <..............>


      JMC> That (apparently) the problem arises in such a
      JMC> special situation is confusing for users.  At least
      JMC> for me, it's ONLY in the combination of saved image
      JMC> and no namespace.

      JMC> That the user does not need a require(methods) when
      JMC> testing the code directly but does (sometimes) when
      JMC> the source code is in package source is not a
      JMC> feature.  If we can avoid this complexity, that would
      JMC> encourage package developers.

     BDR> Unfortunately, it is not necessarily true that
     BDR> require(methods) is not needed when testing: site
     BDR> admins or "users" might have changed the default
     BDR> packages from the system default.

    JMC> Indeed, but then the user would always see things this
    JMC> way.  Consistency makes people feel more secure.

     BDR> Otoh, once we use --vanilla for the save image
     BDR> creation, it seems that this eliminates all
     BDR> (reasonable) possibilities for changing the default
     BDR> packages (or am I missing something?).  So we could
     BDR> use the system default rather than just base here.

    JMC> Intuitively, --vanilla means "the standard flavor", as opposed to
    JMC> --stripped, say, so it would seem more natural to have the system
    JMC> defaults wherever possible.

  BDR> As I have said before, --vanilla does not change the
  BDR> default packages, nor the possibility of setting the
  BDR> default packages at system level.

  BDR>	     gannet% env R_DEFAULT_PACKAGES=ts R --vanilla

  BDR> really does load only "package:ts".

  BDR> From ?Startup

  >> The command-line flag '--vanilla' implies
  >> '--no-site-file', '--no-init-file', '--no-restore' and
  >> '--no-environ'.

  BDR> and let me add, nothing else.  It is possible for
  BDR> sysadmins to change the system environment and profile
  BDR> files, and some do.

Agreed.  
So this means we should do more than just "--vanilla".
In some cases, we already do set environment variables such as
LANG=C and so we should also be allowed to set
R_DEFAULT_PACKAGES to the standard default (rather than the
local installation one).

Martin

From maechler at stat.math.ethz.ch  Wed Sep 17 12:48:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Sep 17 11:48:25 2003
Subject: [Rd] the empty class name
Message-ID: <16232.11730.679582.109335@gargle.gargle.HOWL>

As Henrik Bengtsson has just demonstrated on R-help,
it is currently valid to have *the* empty class name.
E.g.,
----------------------------------
print. <- function(x, ...) { 
       cat("Empty class ", x,"\n") 
       invisible(x) 
}

x <- 1:2; class(x) <- "" 
----------------------------------

works:

  > x
  Empty class  1 2 

I see that it also works in S+6  but still do wonder if this is
not rather an accident than a feature.

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

From bwang at jaguar1.usouthal.edu  Wed Sep 17 10:23:21 2003
From: bwang at jaguar1.usouthal.edu (bin wang)
Date: Wed Sep 17 16:25:11 2003
Subject: [Rd] var() doesn't work for R-1.8.0
Message-ID: <3F686E59.4080502@jaguar1.usouthal.edu>

I installed R-1.8.0 alpha in my machine, which runs redhat9.0. 

I tried to run

x <- c(1,2,3,4)
var(x)

It said 4 parameters are needed and I just provide 3. 

Thanks

Bin

From ligges at statistik.uni-dortmund.de  Wed Sep 17 17:55:47 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Sep 17 16:54:21 2003
Subject: [Rd] var() doesn't work for R-1.8.0
In-Reply-To: <3F686E59.4080502@jaguar1.usouthal.edu>
References: <3F686E59.4080502@jaguar1.usouthal.edu>
Message-ID: <3F6875F3.6080000@statistik.uni-dortmund.de>

bin wang wrote:

> I installed R-1.8.0 alpha in my machine, which runs redhat9.0.
> I tried to run
> 
> x <- c(1,2,3,4)
> var(x)
> 
> It said 4 parameters are needed and I just provide 3.
> Thanks
> 
> Bin
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

This issue arised earlier this week. Unpack the sources into a clean 
directory and try compiling again.

Uwe Ligges

From pliu3 at ncsu.edu  Wed Sep 17 18:13:27 2003
From: pliu3 at ncsu.edu (pliu3@ncsu.edu)
Date: Wed Sep 17 17:16:15 2003
Subject: [Rd] strptime (PR#4204)
Message-ID: <200309171513.h8HFDRJH005486@pubhealth.ku.dk>

Full_Name: Peng Liu
Version: 1.7.1
OS: XP Home
Submission from: (NULL) (128.109.14.2)


> strptime(c("80040601"),format="%y%m%d%H")
[1] "1980-04-06 01:00:00"
> strptime(c("80040602"),format="%y%m%d%H")
[1] "1980-04-06 01:00:00"

Convert incorrectly.

From John.Marsland at CommerzbankIB.com  Wed Sep 17 18:51:40 2003
From: John.Marsland at CommerzbankIB.com (Marsland, John)
Date: Wed Sep 17 18:51:48 2003
Subject: [Rd] possible bug in diag()
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF0317E9A1@xmx8lonib.lonib.commerzbank.com>


It concerns trival diagonal matrices:

> diag(1)
     [,1]
[1,]    1


> diag(rnorm(1))
<0 x 0 matrix>


> diag(rnorm(1),nrow=1)
          [,1]
[1,] 0.4843697

There's an obvious work around... but I thought it was worth notifying the
list.

Regards,

John Marsland


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}

From simon.urbanek at math.uni-augsburg.de  Wed Sep 17 21:01:14 2003
From: simon.urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Wed Sep 17 20:00:30 2003
Subject: [Rd] possible bug in diag()
In-Reply-To: <8CBAA121CEB4D5118CB200508BB2BBEF0317E9A1@xmx8lonib.lonib.commerzbank.com>
Message-ID: <ED8C8976-E938-11D7-B881-000A959F327E@math.uni-augsburg.de>

On Wednesday, September 17, 2003, at 06:51 PM, Marsland, John wrote:

> It concerns trival diagonal matrices:
> [...]
>> diag(rnorm(1))
> <0 x 0 matrix>
>
>> diag(rnorm(1),nrow=1)
>           [,1]
> [1,] 0.4843697
>
> There's an obvious work around... but I thought it was worth notifying 
> the
> list.

I fail to see any reason for you posting this here, since this is a 
perfectly documented behavior - ?diag says:

Note:
Using 'diag(x)' can have unexpected effects if 'x' is a vector
that could be of length one. Use 'diag(x, nrow = length(x))' for
consistent behaviour.

Hence you can safely assume that the "list" needs no notification of 
this.

Cheers,
Simon

From simon.urbanek at math.uni-augsburg.de  Wed Sep 17 21:01:34 2003
From: simon.urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Wed Sep 17 20:00:52 2003
Subject: [Rd] R on BeOS
In-Reply-To: <14211947964-BeMail@moloch>
Message-ID: <F9621EBA-E938-11D7-B881-000A959F327E@math.uni-augsburg.de>

On Sunday, September 14, 2003, at 06:01 PM, Ole Sieling wrote:

> Hello,
> I have compiled R-1.7.1 on Beos R5 (x86) and got it running.
> The modules x11 and internet dont work (so the only working display is
> postscript()).
> The libraries all compile, but there is a problem with methods.
> I get the following error when i make methods:
>
> dumping R code in package 'methods'
> Error in .Call("R_initialize_methods_metadata", table, PACKAGE =
> "methods") :
>         .Call function name not in load table
> Execution halted

This may indicate a problem of missing/superfluous underscores in 
exported symbols of shared libraries - see the discussion concerning 
OpenBSD port conducted recently (late July; see also 
HAVE_NO_SYMBOL_UNDERSCORE). Each platform has different requirements in 
that respect and "methods" is the first package that loads a dynamic 
library and uses its functions.

Cheers,
Simon

From mark.lamias at grizzard.com  Thu Sep 18 02:20:19 2003
From: mark.lamias at grizzard.com (mark.lamias@grizzard.com)
Date: Thu Sep 18 01:19:36 2003
Subject: [Rd] dwilcox (PR#4212)
Message-ID: <200309172320.h8HNKJJH008077@pubhealth.ku.dk>

Full_Name: Mark J. Lamias
Version: 1.7.0
OS: Windows 2000 Pro
Submission from: (NULL) (65.222.84.72)


I am running the qwilcox procedure and it is producing incorrect results.  For
example, dwilcox(.025, 3, 5) should equal 6, but it is equal to 1.  Similarly,
dwilcox(.025, 3, 6) should equal 7, but it equals 2.  The critical values are
not set being returned with the correct values.  I've verified this with a
program that performs direct enumeration to determine the appropriate critical
values for .05 (two- tail):

n1 n2 n crtical_value
3 5 8 6
3 6 9 7
3 7 10 7
3 8 11 8
3 9 12 8
3 10 13 9
3 11 14 9
3 12 15 10
3 13 16 10
3 14 17 11
3 15 18 11
3 16 19 12
3 17 20 12
3 18 21 13
3 19 22 13
3 20 23 14
3 21 24 14
3 22 25 15
3 23 26 15
3 24 27 16
3 25 28 16
3 26 29 17
3 27 30 17
3 28 31 18
3 29 32 19
3 30 33 19
4 4 8 10
4 5 9 11
4 6 10 12
4 7 11 13
4 8 12 14
4 9 13 14
4 10 14 15
4 11 15 16
4 12 16 17
4 13 17 18
4 14 18 19
4 15 19 20
4 16 20 21
4 17 21 21
4 18 22 22
4 19 23 23
4 20 24 24
4 21 25 25
4 22 26 26
4 23 27 27
4 24 28 27
4 25 29 28
4 26 30 29
4 27 31 30
4 28 32 31
4 29 33 32
4 30 34 33
5 5 10 17
5 6 11 18
5 7 12 20
5 8 13 21
5 9 14 22

From mark.lamias at grizzard.com  Thu Sep 18 02:21:06 2003
From: mark.lamias at grizzard.com (mark.lamias@grizzard.com)
Date: Thu Sep 18 01:20:24 2003
Subject: [Rd] dwilcox (PR#4213)
Message-ID: <200309172321.h8HNL6JH008088@pubhealth.ku.dk>

Full_Name: Mark J. Lamias
Version: 1.7.0
OS: Windows 2000 Pro
Submission from: (NULL) (65.222.84.72)


I am running the qwilcox procedure and it is producing incorrect results.  For
example, dwilcox(.025, 3, 5) should equal 6, but it is equal to 1.  Similarly,
dwilcox(.025, 3, 6) should equal 7, but it equals 2.  The critical values are
not set being returned with the correct values.  I've verified this with a
program that performs direct enumeration to determine the appropriate critical
values for .05 (two- tail):

n1 n2 n crtical_value
3 5 8 6
3 6 9 7
3 7 10 7
3 8 11 8
3 9 12 8
3 10 13 9
3 11 14 9
3 12 15 10
3 13 16 10
3 14 17 11
3 15 18 11
3 16 19 12
3 17 20 12
3 18 21 13
3 19 22 13
3 20 23 14
3 21 24 14
3 22 25 15
3 23 26 15
3 24 27 16
3 25 28 16
3 26 29 17
3 27 30 17
3 28 31 18
3 29 32 19
3 30 33 19
4 4 8 10
4 5 9 11
4 6 10 12
4 7 11 13
4 8 12 14
4 9 13 14
4 10 14 15
4 11 15 16
4 12 16 17
4 13 17 18
4 14 18 19
4 15 19 20
4 16 20 21
4 17 21 21
4 18 22 22
4 19 23 23
4 20 24 24
4 21 25 25
4 22 26 26
4 23 27 27
4 24 28 27
4 25 29 28
4 26 30 29
4 27 31 30
4 28 32 31
4 29 33 32
4 30 34 33
5 5 10 17
5 6 11 18
5 7 12 20
5 8 13 21
5 9 14 22

From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Sep 18 10:03:57 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu Sep 18 09:03:43 2003
Subject: [Rd] dwilcox (PR#4212)
In-Reply-To: <200309172320.h8HNKJJH008077@pubhealth.ku.dk>
References: <200309172320.h8HNKJJH008077@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.51.0309180853230.10766@artemis.imbe.med.uni-erlangen.de>


> Full_Name: Mark J. Lamias
> Version: 1.7.0
> OS: Windows 2000 Pro
> Submission from: (NULL) (65.222.84.72)
>
>
> I am running the qwilcox procedure and it is producing incorrect results.  For
> example, dwilcox(.025, 3, 5)

not really:

R> dwilcox(.025, 3, 5)
[1] 0

which is natural since the statistic can take integer values only.

> should equal 6, but it is equal to 1.  Similarly,
> dwilcox(.025, 3, 6) should equal 7, but it equals 2.  The critical values are
> not set being returned with the correct values.  I've verified this with a
> program that performs direct enumeration to determine the appropriate critical
> values for .05 (two- tail):
>
> n1 n2 n crtical_value
> 3 5 8 6


I think you failed to notice what `?qwilcox' tries to tell you:

     This distribution is obtained as follows.  Let 'x' and 'y' be two
     random, independent samples of size 'm' and 'n'. Then the Wilcoxon
     rank sum statistic is the number of all pairs '(x[i], y[j])' for
     which 'y[j]' is not greater than 'x[i]'.  This statistic takes
     values between '0' and 'm * n', and its mean and variance are 'm *
     n / 2' and 'm * n * (m + n + 1) / 12', respectively.

Moreover, it is documented that `probabilities are P[X <= x]' and
therefore

R> qwilcox(.025, 3, 5) + 3*4/2
[1] 7

means "the smallest x with P(W <= x) => 0.025 is 7" which you can check
easily

R> pwilcox(7 - 3*4/2, 3, 5)
[1] 0.03571429

whereas following your calculations

R> pwilcox(6 - 3*4/2, 3, 5)
[1] 0.01785714

Best,

Torsten

> 3 6 9 7
> 3 7 10 7
> 3 8 11 8
> 3 9 12 8
> 3 10 13 9
> 3 11 14 9
> 3 12 15 10
> 3 13 16 10
> 3 14 17 11
> 3 15 18 11
> 3 16 19 12
> 3 17 20 12
> 3 18 21 13
> 3 19 22 13
> 3 20 23 14
> 3 21 24 14
> 3 22 25 15
> 3 23 26 15
> 3 24 27 16
> 3 25 28 16
> 3 26 29 17
> 3 27 30 17
> 3 28 31 18
> 3 29 32 19
> 3 30 33 19
> 4 4 8 10
> 4 5 9 11
> 4 6 10 12
> 4 7 11 13
> 4 8 12 14
> 4 9 13 14
> 4 10 14 15
> 4 11 15 16
> 4 12 16 17
> 4 13 17 18
> 4 14 18 19
> 4 15 19 20
> 4 16 20 21
> 4 17 21 21
> 4 18 22 22
> 4 19 23 23
> 4 20 24 24
> 4 21 25 25
> 4 22 26 26
> 4 23 27 27
> 4 24 28 27
> 4 25 29 28
> 4 26 30 29
> 4 27 31 30
> 4 28 32 31
> 4 29 33 32
> 4 30 34 33
> 5 5 10 17
> 5 6 11 18
> 5 7 12 20
> 5 8 13 21
> 5 9 14 22
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>

From Kurt.Hornik at wu-wien.ac.at  Thu Sep 18 11:43:01 2003
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu Sep 18 10:43:49 2003
Subject: [Rd] couldn't find function "setClass"
In-Reply-To: <16232.2420.708165.503471@gargle.gargle.HOWL>
References: <3F676D43.AEB89326@research.bell-labs.com>
	<Pine.LNX.4.44.0309170659220.2844-100000@gannet.stats>
	<16232.2420.708165.503471@gargle.gargle.HOWL>
Message-ID: <16233.28693.5155.243871@mithrandir.hornik.net>

>>>>> Martin Maechler writes:

>>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
>>>>>     on Wed, 17 Sep 2003 07:05:57 +0100 (BST) writes:

BDR> On Tue, 16 Sep 2003, John Chambers wrote:

>     <..............>


JMC> That (apparently) the problem arises in such a
JMC> special situation is confusing for users.  At least
JMC> for me, it's ONLY in the combination of saved image
JMC> and no namespace.

JMC> That the user does not need a require(methods) when
JMC> testing the code directly but does (sometimes) when
JMC> the source code is in package source is not a
JMC> feature.  If we can avoid this complexity, that would
JMC> encourage package developers.

BDR> Unfortunately, it is not necessarily true that
BDR> require(methods) is not needed when testing: site
BDR> admins or "users" might have changed the default
BDR> packages from the system default.

JMC> Indeed, but then the user would always see things this
JMC> way.  Consistency makes people feel more secure.

BDR> Otoh, once we use --vanilla for the save image
BDR> creation, it seems that this eliminates all
BDR> (reasonable) possibilities for changing the default
BDR> packages (or am I missing something?).  So we could
BDR> use the system default rather than just base here.

JMC> Intuitively, --vanilla means "the standard flavor", as opposed to
JMC> --stripped, say, so it would seem more natural to have the system
JMC> defaults wherever possible.

BDR> As I have said before, --vanilla does not change the
BDR> default packages, nor the possibility of setting the
BDR> default packages at system level.

BDR> gannet% env R_DEFAULT_PACKAGES=ts R --vanilla

BDR> really does load only "package:ts".

BDR> From ?Startup

>>> The command-line flag '--vanilla' implies
>>> '--no-site-file', '--no-init-file', '--no-restore' and
>>> '--no-environ'.

BDR> and let me add, nothing else.  It is possible for
BDR> sysadmins to change the system environment and profile
BDR> files, and some do.

> Agreed.  
> So this means we should do more than just "--vanilla".
> In some cases, we already do set environment variables such as
> LANG=C and so we should also be allowed to set
> R_DEFAULT_PACKAGES to the standard default (rather than the
> local installation one).

Done now.  It turns out that 'R_DEFAULT_PACKAGES=' does the job.

I also modified R CMD check to use the system default when running the
examples and specific tests (although running with
R_DEFAULT_PACKAGES=NULL seems to work for all CRAN packages).

-k

From wolfram at fischer-zim.ch  Thu Sep 18 12:19:38 2003
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Thu Sep 18 11:20:17 2003
Subject: [Rd] Sweave: option family=...
Message-ID: <20030918091938.GA3895@s1x.local>

I would propose to add an option ``family''
to RweaveLatex() resp. RweaveLatexSetup() 
in order to be able to set the font family
for postscript and pdf graphics:

	<<fig=TRUE, family=Palatino>>=
		...
	@

Thanks

Wolfram Fischer

From laurent at cbs.dtu.dk  Thu Sep 18 14:20:10 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Thu Sep 18 13:19:16 2003
Subject: [Rd] function 'density' in r-devel
Message-ID: <20030918112010.GC6049@genome.cbs.dtu.dk>

Hi,

Just to report.

I yesterday's r-devel I get:
> d <- density(rnorm(100))
Error in var(x, na.rm = na.rm) : 3 arguments passed to "cov" which requires 4.


Regards,


L.

From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Sep 18 14:27:16 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu Sep 18 13:34:08 2003
Subject: [Rd] function 'density' in r-devel
In-Reply-To: <20030918112010.GC6049@genome.cbs.dtu.dk>
References: <20030918112010.GC6049@genome.cbs.dtu.dk>
Message-ID: <Pine.LNX.4.51.0309181325230.13968@artemis.imbe.med.uni-erlangen.de>

> Hi,
>
> Just to report.
>
> I yesterday's r-devel I get:
> > d <- density(rnorm(100))
> Error in var(x, na.rm = na.rm) : 3 arguments passed to "cov" which requires 4.
>

you are the third one discovering this :-)

cov.R and var.R were removed from the base/R directory but we all failed
to update the sources correctly. Just rebuild from a fresh checkout.

Best,

Torsten

>
> Regards,
>
>
> L.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>

From roger at ysidro.econ.uiuc.edu  Thu Sep 18 08:22:04 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Thu Sep 18 14:14:58 2003
Subject: [Rd] non-numeric binary ops?
In-Reply-To: <200309181001.h8IA199e018483@stat.math.ethz.ch>
Message-ID: <Pine.SOL.4.30.0309180713180.23341-100000@ysidro.econ.uiuc.edu>

Has there been a recent change in the behavior of binary operators?
In SparseM it was, until quite recently ok to do scalar multiplication
but now,

> A*4
Error in A * 4 : non-numeric argument to binary operator
> 4*A
Error in 4 * A : non-numeric argument to binary operator
> A%*%A
An object of class "matrix.csr"
Slot "ra":
[1] 1 1 1

Slot "ja":
[1] 1 2 3

Slot "ia":
[1] 1 2 3 4

Slot "dimension":
[1] 3 3

Clearly, I need to now specify that objects (like A) of our sparse matrix
classes are numeric, but I am curious about what happened in the interim
to have necessitated this, and to evaluate how negligent I was to have
missed it.



url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker@uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Thu, 18 Sep 2003 r-devel-request@stat.math.ethz.ch wrote:

> Send R-devel mailing list submissions to
> 	r-devel@stat.math.ethz.ch
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> or, via email, send a message with subject or body 'help' to
> 	r-devel-request@stat.math.ethz.ch
>
> You can reach the person managing the list at
> 	r-devel-owner@stat.math.ethz.ch
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-devel digest..."
>
>
> Today's Topics:
>
>    1. var() doesn't work for R-1.8.0 (bin wang)
>    2. Re: var() doesn't work for R-1.8.0 (Uwe Ligges)
>    3. strptime (PR#4204) (pliu3@ncsu.edu)
>    4. possible bug in diag() (Marsland, John)
>    5. Re: possible bug in diag() (Simon Urbanek)
>    6. Re: R on BeOS (Simon Urbanek)
>    7. dwilcox (PR#4212) (mark.lamias@grizzard.com)
>    8. dwilcox (PR#4213) (mark.lamias@grizzard.com)
>    9. Re: dwilcox (PR#4212) (Torsten Hothorn)
>   10. Re: couldn't find function "setClass" (Kurt Hornik)
>   11. Sweave: option family=... (Wolfram Fischer)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Wed, 17 Sep 2003 09:23:21 -0500
> From: bin wang <bwang@jaguar1.usouthal.edu>
> Subject: [Rd] var() doesn't work for R-1.8.0
> To: R-devel@stat.math.ethz.ch
> Message-ID: <3F686E59.4080502@jaguar1.usouthal.edu>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> I installed R-1.8.0 alpha in my machine, which runs redhat9.0.
>
> I tried to run
>
> x <- c(1,2,3,4)
> var(x)
>
> It said 4 parameters are needed and I just provide 3.
>
> Thanks
>
> Bin
>
>
> ------------------------------
>
> Message: 2
> Date: Wed, 17 Sep 2003 16:55:47 +0200
> From: Uwe Ligges <ligges@statistik.uni-dortmund.de>
> Subject: Re: [Rd] var() doesn't work for R-1.8.0
> To: bin wang <bwang@jaguar1.usouthal.edu>
> Cc: R-devel@stat.math.ethz.ch
> Message-ID: <3F6875F3.6080000@statistik.uni-dortmund.de>
> Content-Type: text/plain; charset=us-ascii; format=flowed
>
> bin wang wrote:
>
> > I installed R-1.8.0 alpha in my machine, which runs redhat9.0.
> > I tried to run
> >
> > x <- c(1,2,3,4)
> > var(x)
> >
> > It said 4 parameters are needed and I just provide 3.
> > Thanks
> >
> > Bin
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
> This issue arised earlier this week. Unpack the sources into a clean
> directory and try compiling again.
>
> Uwe Ligges
>
>
> ------------------------------
>
> Message: 3
> Date: Wed, 17 Sep 2003 17:13:27 +0200 (MET DST)
> From: pliu3@ncsu.edu
> Subject: [Rd] strptime (PR#4204)
> To: r-devel@stat.math.ethz.ch
> Cc: R-bugs@biostat.ku.dk
> Message-ID: <200309171513.h8HFDRJH005486@pubhealth.ku.dk>
>
> Full_Name: Peng Liu
> Version: 1.7.1
> OS: XP Home
> Submission from: (NULL) (128.109.14.2)
>
>
> > strptime(c("80040601"),format="%y%m%d%H")
> [1] "1980-04-06 01:00:00"
> > strptime(c("80040602"),format="%y%m%d%H")
> [1] "1980-04-06 01:00:00"
>
> Convert incorrectly.
>
>
> ------------------------------
>
> Message: 4
> Date: Wed, 17 Sep 2003 17:51:40 +0100
> From: "Marsland, John" <John.Marsland@CommerzbankIB.com>
> Subject: [Rd] possible bug in diag()
> To: "'R-devel@stat.math.ethz.ch'" <R-devel@stat.math.ethz.ch>
> Message-ID:
> 	<8CBAA121CEB4D5118CB200508BB2BBEF0317E9A1@xmx8lonib.lonib.commerzbank.com>
>
> Content-Type: text/plain;	charset="iso-8859-1"
>
>
> It concerns trival diagonal matrices:
>
> > diag(1)
>      [,1]
> [1,]    1
>
>
> > diag(rnorm(1))
> <0 x 0 matrix>
>
>
> > diag(rnorm(1),nrow=1)
>           [,1]
> [1,] 0.4843697
>
> There's an obvious work around... but I thought it was worth notifying the
> list.
>
> Regards,
>
> John Marsland
>
>
> **********************************************************************
> This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}
>
>
> ------------------------------
>
> Message: 5
> Date: Wed, 17 Sep 2003 20:01:14 +0200
> From: Simon Urbanek <simon.urbanek@math.uni-augsburg.de>
> Subject: Re: [Rd] possible bug in diag()
> To: "Marsland, John" <John.Marsland@commerzbankib.com>
> Cc: "'R-devel@stat.math.ethz.ch'" <R-devel@stat.math.ethz.ch>
> Message-ID:
> 	<ED8C8976-E938-11D7-B881-000A959F327E@math.uni-augsburg.de>
> Content-Type: text/plain; charset=US-ASCII; format=flowed
>
> On Wednesday, September 17, 2003, at 06:51 PM, Marsland, John wrote:
>
> > It concerns trival diagonal matrices:
> > [...]
> >> diag(rnorm(1))
> > <0 x 0 matrix>
> >
> >> diag(rnorm(1),nrow=1)
> >           [,1]
> > [1,] 0.4843697
> >
> > There's an obvious work around... but I thought it was worth notifying
> > the
> > list.
>
> I fail to see any reason for you posting this here, since this is a
> perfectly documented behavior - ?diag says:
>
> Note:
> Using 'diag(x)' can have unexpected effects if 'x' is a vector
> that could be of length one. Use 'diag(x, nrow = length(x))' for
> consistent behaviour.
>
> Hence you can safely assume that the "list" needs no notification of
> this.
>
> Cheers,
> Simon
>
>
> ------------------------------
>
> Message: 6
> Date: Wed, 17 Sep 2003 20:01:34 +0200
> From: Simon Urbanek <simon.urbanek@math.uni-augsburg.de>
> Subject: Re: [Rd] R on BeOS
> To: "Ole Sieling" <sieling@uni-freiburg.de>
> Cc: r-devel@stat.math.ethz.ch
> Message-ID:
> 	<F9621EBA-E938-11D7-B881-000A959F327E@math.uni-augsburg.de>
> Content-Type: text/plain; charset=US-ASCII; format=flowed
>
> On Sunday, September 14, 2003, at 06:01 PM, Ole Sieling wrote:
>
> > Hello,
> > I have compiled R-1.7.1 on Beos R5 (x86) and got it running.
> > The modules x11 and internet dont work (so the only working display is
> > postscript()).
> > The libraries all compile, but there is a problem with methods.
> > I get the following error when i make methods:
> >
> > dumping R code in package 'methods'
> > Error in .Call("R_initialize_methods_metadata", table, PACKAGE =
> > "methods") :
> >         .Call function name not in load table
> > Execution halted
>
> This may indicate a problem of missing/superfluous underscores in
> exported symbols of shared libraries - see the discussion concerning
> OpenBSD port conducted recently (late July; see also
> HAVE_NO_SYMBOL_UNDERSCORE). Each platform has different requirements in
> that respect and "methods" is the first package that loads a dynamic
> library and uses its functions.
>
> Cheers,
> Simon
>
>
> ------------------------------
>
> Message: 7
> Date: Thu, 18 Sep 2003 01:20:19 +0200 (MET DST)
> From: mark.lamias@grizzard.com
> Subject: [Rd] dwilcox (PR#4212)
> To: r-devel@stat.math.ethz.ch
> Cc: R-bugs@biostat.ku.dk
> Message-ID: <200309172320.h8HNKJJH008077@pubhealth.ku.dk>
>
> Full_Name: Mark J. Lamias
> Version: 1.7.0
> OS: Windows 2000 Pro
> Submission from: (NULL) (65.222.84.72)
>
>
> I am running the qwilcox procedure and it is producing incorrect results.  For
> example, dwilcox(.025, 3, 5) should equal 6, but it is equal to 1.  Similarly,
> dwilcox(.025, 3, 6) should equal 7, but it equals 2.  The critical values are
> not set being returned with the correct values.  I've verified this with a
> program that performs direct enumeration to determine the appropriate critical
> values for .05 (two- tail):
>
> n1 n2 n crtical_value
> 3 5 8 6
> 3 6 9 7
> 3 7 10 7
> 3 8 11 8
> 3 9 12 8
> 3 10 13 9
> 3 11 14 9
> 3 12 15 10
> 3 13 16 10
> 3 14 17 11
> 3 15 18 11
> 3 16 19 12
> 3 17 20 12
> 3 18 21 13
> 3 19 22 13
> 3 20 23 14
> 3 21 24 14
> 3 22 25 15
> 3 23 26 15
> 3 24 27 16
> 3 25 28 16
> 3 26 29 17
> 3 27 30 17
> 3 28 31 18
> 3 29 32 19
> 3 30 33 19
> 4 4 8 10
> 4 5 9 11
> 4 6 10 12
> 4 7 11 13
> 4 8 12 14
> 4 9 13 14
> 4 10 14 15
> 4 11 15 16
> 4 12 16 17
> 4 13 17 18
> 4 14 18 19
> 4 15 19 20
> 4 16 20 21
> 4 17 21 21
> 4 18 22 22
> 4 19 23 23
> 4 20 24 24
> 4 21 25 25
> 4 22 26 26
> 4 23 27 27
> 4 24 28 27
> 4 25 29 28
> 4 26 30 29
> 4 27 31 30
> 4 28 32 31
> 4 29 33 32
> 4 30 34 33
> 5 5 10 17
> 5 6 11 18
> 5 7 12 20
> 5 8 13 21
> 5 9 14 22
>
>
> ------------------------------
>
> Message: 8
> Date: Thu, 18 Sep 2003 01:21:06 +0200 (MET DST)
> From: mark.lamias@grizzard.com
> Subject: [Rd] dwilcox (PR#4213)
> To: r-devel@stat.math.ethz.ch
> Cc: R-bugs@biostat.ku.dk
> Message-ID: <200309172321.h8HNL6JH008088@pubhealth.ku.dk>
>
> Full_Name: Mark J. Lamias
> Version: 1.7.0
> OS: Windows 2000 Pro
> Submission from: (NULL) (65.222.84.72)
>
>
> I am running the qwilcox procedure and it is producing incorrect results.  For
> example, dwilcox(.025, 3, 5) should equal 6, but it is equal to 1.  Similarly,
> dwilcox(.025, 3, 6) should equal 7, but it equals 2.  The critical values are
> not set being returned with the correct values.  I've verified this with a
> program that performs direct enumeration to determine the appropriate critical
> values for .05 (two- tail):
>
> n1 n2 n crtical_value
> 3 5 8 6
> 3 6 9 7
> 3 7 10 7
> 3 8 11 8
> 3 9 12 8
> 3 10 13 9
> 3 11 14 9
> 3 12 15 10
> 3 13 16 10
> 3 14 17 11
> 3 15 18 11
> 3 16 19 12
> 3 17 20 12
> 3 18 21 13
> 3 19 22 13
> 3 20 23 14
> 3 21 24 14
> 3 22 25 15
> 3 23 26 15
> 3 24 27 16
> 3 25 28 16
> 3 26 29 17
> 3 27 30 17
> 3 28 31 18
> 3 29 32 19
> 3 30 33 19
> 4 4 8 10
> 4 5 9 11
> 4 6 10 12
> 4 7 11 13
> 4 8 12 14
> 4 9 13 14
> 4 10 14 15
> 4 11 15 16
> 4 12 16 17
> 4 13 17 18
> 4 14 18 19
> 4 15 19 20
> 4 16 20 21
> 4 17 21 21
> 4 18 22 22
> 4 19 23 23
> 4 20 24 24
> 4 21 25 25
> 4 22 26 26
> 4 23 27 27
> 4 24 28 27
> 4 25 29 28
> 4 26 30 29
> 4 27 31 30
> 4 28 32 31
> 4 29 33 32
> 4 30 34 33
> 5 5 10 17
> 5 6 11 18
> 5 7 12 20
> 5 8 13 21
> 5 9 14 22
>
>
> ------------------------------
>
> Message: 9
> Date: Thu, 18 Sep 2003 09:03:57 +0200 (CEST)
> From: Torsten Hothorn <Torsten.Hothorn@rzmail.uni-erlangen.de>
> Subject: Re: [Rd] dwilcox (PR#4212)
> To: mark.lamias@grizzard.com
> Cc: r-devel@stat.math.ethz.ch
> Message-ID:
> 	<Pine.LNX.4.51.0309180853230.10766@artemis.imbe.med.uni-erlangen.de>
> Content-Type: TEXT/PLAIN; charset=US-ASCII
>
>
> > Full_Name: Mark J. Lamias
> > Version: 1.7.0
> > OS: Windows 2000 Pro
> > Submission from: (NULL) (65.222.84.72)
> >
> >
> > I am running the qwilcox procedure and it is producing incorrect results.  For
> > example, dwilcox(.025, 3, 5)
>
> not really:
>
> R> dwilcox(.025, 3, 5)
> [1] 0
>
> which is natural since the statistic can take integer values only.
>
> > should equal 6, but it is equal to 1.  Similarly,
> > dwilcox(.025, 3, 6) should equal 7, but it equals 2.  The critical values are
> > not set being returned with the correct values.  I've verified this with a
> > program that performs direct enumeration to determine the appropriate critical
> > values for .05 (two- tail):
> >
> > n1 n2 n crtical_value
> > 3 5 8 6
>
>
> I think you failed to notice what `?qwilcox' tries to tell you:
>
>      This distribution is obtained as follows.  Let 'x' and 'y' be two
>      random, independent samples of size 'm' and 'n'. Then the Wilcoxon
>      rank sum statistic is the number of all pairs '(x[i], y[j])' for
>      which 'y[j]' is not greater than 'x[i]'.  This statistic takes
>      values between '0' and 'm * n', and its mean and variance are 'm *
>      n / 2' and 'm * n * (m + n + 1) / 12', respectively.
>
> Moreover, it is documented that `probabilities are P[X <= x]' and
> therefore
>
> R> qwilcox(.025, 3, 5) + 3*4/2
> [1] 7
>
> means "the smallest x with P(W <= x) => 0.025 is 7" which you can check
> easily
>
> R> pwilcox(7 - 3*4/2, 3, 5)
> [1] 0.03571429
>
> whereas following your calculations
>
> R> pwilcox(6 - 3*4/2, 3, 5)
> [1] 0.01785714
>
> Best,
>
> Torsten
>
> > 3 6 9 7
> > 3 7 10 7
> > 3 8 11 8
> > 3 9 12 8
> > 3 10 13 9
> > 3 11 14 9
> > 3 12 15 10
> > 3 13 16 10
> > 3 14 17 11
> > 3 15 18 11
> > 3 16 19 12
> > 3 17 20 12
> > 3 18 21 13
> > 3 19 22 13
> > 3 20 23 14
> > 3 21 24 14
> > 3 22 25 15
> > 3 23 26 15
> > 3 24 27 16
> > 3 25 28 16
> > 3 26 29 17
> > 3 27 30 17
> > 3 28 31 18
> > 3 29 32 19
> > 3 30 33 19
> > 4 4 8 10
> > 4 5 9 11
> > 4 6 10 12
> > 4 7 11 13
> > 4 8 12 14
> > 4 9 13 14
> > 4 10 14 15
> > 4 11 15 16
> > 4 12 16 17
> > 4 13 17 18
> > 4 14 18 19
> > 4 15 19 20
> > 4 16 20 21
> > 4 17 21 21
> > 4 18 22 22
> > 4 19 23 23
> > 4 20 24 24
> > 4 21 25 25
> > 4 22 26 26
> > 4 23 27 27
> > 4 24 28 27
> > 4 25 29 28
> > 4 26 30 29
> > 4 27 31 30
> > 4 28 32 31
> > 4 29 33 32
> > 4 30 34 33
> > 5 5 10 17
> > 5 6 11 18
> > 5 7 12 20
> > 5 8 13 21
> > 5 9 14 22
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> >
> >
>
>
> ------------------------------
>
> Message: 10
> Date: Thu, 18 Sep 2003 10:43:01 +0200
> From: Kurt Hornik <Kurt.Hornik@wu-wien.ac.at>
> Subject: Re: [Rd] couldn't find function "setClass"
> To: Martin Maechler <maechler@stat.math.ethz.ch>
> Cc: r-devel@stat.math.ethz.ch
> Message-ID: <16233.28693.5155.243871@mithrandir.hornik.net>
> Content-Type: text/plain; charset=us-ascii
>
> >>>>> Martin Maechler writes:
>
> >>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
> >>>>>     on Wed, 17 Sep 2003 07:05:57 +0100 (BST) writes:
>
> BDR> On Tue, 16 Sep 2003, John Chambers wrote:
>
> >     <..............>
>
>
> JMC> That (apparently) the problem arises in such a
> JMC> special situation is confusing for users.  At least
> JMC> for me, it's ONLY in the combination of saved image
> JMC> and no namespace.
>
> JMC> That the user does not need a require(methods) when
> JMC> testing the code directly but does (sometimes) when
> JMC> the source code is in package source is not a
> JMC> feature.  If we can avoid this complexity, that would
> JMC> encourage package developers.
>
> BDR> Unfortunately, it is not necessarily true that
> BDR> require(methods) is not needed when testing: site
> BDR> admins or "users" might have changed the default
> BDR> packages from the system default.
>
> JMC> Indeed, but then the user would always see things this
> JMC> way.  Consistency makes people feel more secure.
>
> BDR> Otoh, once we use --vanilla for the save image
> BDR> creation, it seems that this eliminates all
> BDR> (reasonable) possibilities for changing the default
> BDR> packages (or am I missing something?).  So we could
> BDR> use the system default rather than just base here.
>
> JMC> Intuitively, --vanilla means "the standard flavor", as opposed to
> JMC> --stripped, say, so it would seem more natural to have the system
> JMC> defaults wherever possible.
>
> BDR> As I have said before, --vanilla does not change the
> BDR> default packages, nor the possibility of setting the
> BDR> default packages at system level.
>
> BDR> gannet% env R_DEFAULT_PACKAGES=ts R --vanilla
>
> BDR> really does load only "package:ts".
>
> BDR> From ?Startup
>
> >>> The command-line flag '--vanilla' implies
> >>> '--no-site-file', '--no-init-file', '--no-restore' and
> >>> '--no-environ'.
>
> BDR> and let me add, nothing else.  It is possible for
> BDR> sysadmins to change the system environment and profile
> BDR> files, and some do.
>
> > Agreed.
> > So this means we should do more than just "--vanilla".
> > In some cases, we already do set environment variables such as
> > LANG=C and so we should also be allowed to set
> > R_DEFAULT_PACKAGES to the standard default (rather than the
> > local installation one).
>
> Done now.  It turns out that 'R_DEFAULT_PACKAGES=' does the job.
>
> I also modified R CMD check to use the system default when running the
> examples and specific tests (although running with
> R_DEFAULT_PACKAGES=NULL seems to work for all CRAN packages).
>
> -k
>
>
> ------------------------------
>
> Message: 11
> Date: Thu, 18 Sep 2003 11:19:38 +0200
> From: Wolfram Fischer <wolfram@fischer-zim.ch>
> Subject: [Rd] Sweave: option family=...
> To: r-devel@stat.math.ethz.ch
> Message-ID: <20030918091938.GA3895@s1x.local>
> Content-Type: text/plain; charset=us-ascii
>
> I would propose to add an option ``family''
> to RweaveLatex() resp. RweaveLatexSetup()
> in order to be able to set the font family
> for postscript and pdf graphics:
>
> 	<<fig=TRUE, family=Palatino>>=
> 		...
> 	@
>
> Thanks
>
> Wolfram Fischer
>
>
> ------------------------------
>
> _______________________________________________
> R-devel@stat.math.ethz.ch mailing list  DIGESTED
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>
> End of R-devel Digest, Vol 7, Issue 18
> **************************************
>

From Mark.Lamias at grizzard.com  Thu Sep 18 10:48:05 2003
From: Mark.Lamias at grizzard.com (Mark Lamias)
Date: Thu Sep 18 15:49:59 2003
Subject: [Rd] dwilcox (PR#4212)
Message-ID: <BF3C804D59EE4C40BF5376A0FABA4AA62F65C0@atl_mail.griz-main.com>

Torsten,

Thank you for clarifying.  I see where I have made the mistake.  I failed to
properly read the definition.

Sorry to inconvenience you.

Sincerely yours,

Mark J. Lamias

-----Original Message-----
From: Torsten Hothorn [mailto:Torsten.Hothorn@rzmail.uni-erlangen.de]
Sent: Thursday, September 18, 2003 3:04 AM
To: mark.lamias@grizzard.com
Cc: r-devel@stat.math.ethz.ch
Subject: Re: [Rd] dwilcox (PR#4212)



> Full_Name: Mark J. Lamias
> Version: 1.7.0
> OS: Windows 2000 Pro
> Submission from: (NULL) (65.222.84.72)
>
>
> I am running the qwilcox procedure and it is producing incorrect results.
For
> example, dwilcox(.025, 3, 5)

not really:

R> dwilcox(.025, 3, 5)
[1] 0

which is natural since the statistic can take integer values only.

> should equal 6, but it is equal to 1.  Similarly,
> dwilcox(.025, 3, 6) should equal 7, but it equals 2.  The critical values
are
> not set being returned with the correct values.  I've verified this with a
> program that performs direct enumeration to determine the appropriate
critical
> values for .05 (two- tail):
>
> n1 n2 n crtical_value
> 3 5 8 6


I think you failed to notice what `?qwilcox' tries to tell you:

     This distribution is obtained as follows.  Let 'x' and 'y' be two
     random, independent samples of size 'm' and 'n'. Then the Wilcoxon
     rank sum statistic is the number of all pairs '(x[i], y[j])' for
     which 'y[j]' is not greater than 'x[i]'.  This statistic takes
     values between '0' and 'm * n', and its mean and variance are 'm *
     n / 2' and 'm * n * (m + n + 1) / 12', respectively.

Moreover, it is documented that `probabilities are P[X <= x]' and
therefore

R> qwilcox(.025, 3, 5) + 3*4/2
[1] 7

means "the smallest x with P(W <= x) => 0.025 is 7" which you can check
easily

R> pwilcox(7 - 3*4/2, 3, 5)
[1] 0.03571429

whereas following your calculations

R> pwilcox(6 - 3*4/2, 3, 5)
[1] 0.01785714

Best,

Torsten

> 3 6 9 7
> 3 7 10 7
> 3 8 11 8
> 3 9 12 8
> 3 10 13 9
> 3 11 14 9
> 3 12 15 10
> 3 13 16 10
> 3 14 17 11
> 3 15 18 11
> 3 16 19 12
> 3 17 20 12
> 3 18 21 13
> 3 19 22 13
> 3 20 23 14
> 3 21 24 14
> 3 22 25 15
> 3 23 26 15
> 3 24 27 16
> 3 25 28 16
> 3 26 29 17
> 3 27 30 17
> 3 28 31 18
> 3 29 32 19
> 3 30 33 19
> 4 4 8 10
> 4 5 9 11
> 4 6 10 12
> 4 7 11 13
> 4 8 12 14
> 4 9 13 14
> 4 10 14 15
> 4 11 15 16
> 4 12 16 17
> 4 13 17 18
> 4 14 18 19
> 4 15 19 20
> 4 16 20 21
> 4 17 21 21
> 4 18 22 22
> 4 19 23 23
> 4 20 24 24
> 4 21 25 25
> 4 22 26 26
> 4 23 27 27
> 4 24 28 27
> 4 25 29 28
> 4 26 30 29
> 4 27 31 30
> 4 28 32 31
> 4 29 33 32
> 4 30 34 33
> 5 5 10 17
> 5 6 11 18
> 5 7 12 20
> 5 8 13 21
> 5 9 14 22
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>

From deepayan at stat.wisc.edu  Wed Sep 17 13:01:35 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu Sep 18 16:49:02 2003
Subject: [Rd] possible bug in diag()
In-Reply-To: <8CBAA121CEB4D5118CB200508BB2BBEF0317E9A1@xmx8lonib.lonib.commerzbank.com>
References: <8CBAA121CEB4D5118CB200508BB2BBEF0317E9A1@xmx8lonib.lonib.commerzbank.com>
Message-ID: <200309171201.35398.deepayan@stat.wisc.edu>


Why is this a bug ? help(diag) says

     If 'x' is a vector (or 1D array) of length two or more, then
     'diag(x)' returns a diagonal matrix whose diagonal is 'x'.

     If 'x' is a vector of length one then 'diag(x)' returns an
     identity matrix of order the nearest integer to 'x'.  The
     dimension of the returned matrix can be specified by 'nrow' and
     'ncol' (the default is square).

There's no way of knowing what rnorm(1) returned in your particular call, but 
my guess is that the integer "nearest" to it was 0.


On Wednesday 17 September 2003 11:51, Marsland, John wrote:
> It concerns trival diagonal matrices:
> > diag(1)
>
>      [,1]
> [1,]    1
>
> > diag(rnorm(1))
>
> <0 x 0 matrix>
>
> > diag(rnorm(1),nrow=1)
>
>           [,1]
> [1,] 0.4843697
>
> There's an obvious work around... but I thought it was worth notifying the
> list.
>
> Regards,
>
> John Marsland
>
>
> **********************************************************************
> This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From saikat at stat.wisc.edu  Wed Sep 17 12:29:35 2003
From: saikat at stat.wisc.edu (Saikat DebRoy)
Date: Thu Sep 18 16:49:25 2003
Subject: [Rd] Matrix subassignment with NA subscripts
Message-ID: <4B2DDF27-E931-11D7-9A76-0003931A3C9E@stat.wisc.edu>

With a relatively recent r-devel snapshot,

R> x <- matrix(1:9, 3)
R> x1 <- matrix(51:54, 2)
R> x[c(NA, 2, 3), 1:2] <- x1
Error in "[<-"(`*tmp*`, c(NA, 2, 3), 1:2, value = x1) :
         number of items to replace is not a multiple of replacement 
length
R> x2 <- matrix(101:106, 3)
R> x[c(NA, 2, 3), 1:2] <- x2
R> x
      [,1] [,2] [,3]
[1,]    1    4    7
[2,]  101  103    8
[3,]  102  104    9

This was a little surprising to me. I expected the assignment to 
succeed in the first case and either fail or at least give a warning in 
the second case. I also tried this on Splus.

Splus> x <- matrix(1:9, 3)
Splus> x1 <- matrix(51:54, 2)
Splus> x[c(NA, 2, 3), 1:2] <- x1
Splus> x
      [,1] [,2] [,3]
[1,]    1    4    7
[2,]   51   53    8
[3,]   52   54    9
Splus> x2 <- matrix(101:106, 3)
Splus> x[c(NA, 2, 3), 1:2] <- x2
Warning messages:
   Replacement length not a multiple of number of elements to replace 
in: x[c(NA
         , 2, 3), 1:2] <- x2
Splus> x
      [,1] [,2] [,3]
[1,]    1    4    7
[2,]  101  103    8
[3,]  102  104    9

From saikat at stat.wisc.edu  Wed Sep 17 12:29:35 2003
From: saikat at stat.wisc.edu (Saikat DebRoy)
Date: Thu Sep 18 16:50:57 2003
Subject: [Rd] Matrix subassignment with NA subscripts
Message-ID: <BE778CFE-E923-11D7-9A76-0003931A3C9E@stat.wisc.edu>

With a relatively recent r-devel snapshot,

R> x <- matrix(1:9, 3)
R> x1 <- matrix(51:54, 2)
R> x[c(NA, 2, 3), 1:2] <- x1
Error in "[<-"(`*tmp*`, c(NA, 2, 3), 1:2, value = x1) :
         number of items to replace is not a multiple of replacement 
length
R> x2 <- matrix(101:106, 3)
R> x[c(NA, 2, 3), 1:2] <- x2
R> x
      [,1] [,2] [,3]
[1,]    1    4    7
[2,]  101  103    8
[3,]  102  104    9

This was a little surprising to me. I expected the assignment to 
succeed in the first case and either fail or at least give a warning in 
the second case. I also tried this on Splus.

Splus> x <- matrix(1:9, 3)
Splus> x1 <- matrix(51:54, 2)
Splus> x[c(NA, 2, 3), 1:2] <- x1
Splus> x
      [,1] [,2] [,3]
[1,]    1    4    7
[2,]   51   53    8
[3,]   52   54    9
Splus> x2 <- matrix(101:106, 3)
Splus> x[c(NA, 2, 3), 1:2] <- x2
Warning messages:
   Replacement length not a multiple of number of elements to replace 
in: x[c(NA
         , 2, 3), 1:2] <- x2
Splus> x
      [,1] [,2] [,3]
[1,]    1    4    7
[2,]  101  103    8
[3,]  102  104    9

From mwall at diversa.com  Thu Sep 18 23:35:40 2003
From: mwall at diversa.com (mwall@diversa.com)
Date: Thu Sep 18 22:35:01 2003
Subject: [Rd] hist will not use parameter xaxs (PR#4219)
Message-ID: <200309182035.h8IKZeJH019875@pubhealth.ku.dk>

Full_Name: Mark Wall
Version: 1.6.0
OS: linux
Submission from: (NULL) (63.251.119.254)


I want to plot a histogram of a *subset* of some data:

>t = c(0:9)
>hist(t,right=FALSE,breaks=10,xlim=c(0,5),xaxs="i")

This means I should plot a histogram from 0 to 5 with breaks at 1,2,3,4.  This
should produce exactly 5 bars of frequency=1.  Instead I get 5 and 1/4 bars.  I
do not want the 4% margins on the x axis that xaxs="r" provides.

From Friedrich.Leisch at ci.tuwien.ac.at  Fri Sep 19 09:50:13 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Fri Sep 19 08:49:35 2003
Subject: [Rd] Sweave: option family=...
In-Reply-To: <20030918091938.GA3895@s1x.local>
References: <20030918091938.GA3895@s1x.local>
Message-ID: <16234.42789.179771.673793@galadriel.ci.tuwien.ac.at>

>>>>> On Thu, 18 Sep 2003 11:19:38 +0200,
>>>>> Wolfram Fischer (WF) wrote:

  > I would propose to add an option ``family''
  > to RweaveLatex() resp. RweaveLatexSetup() 
  > in order to be able to set the font family
  > for postscript and pdf graphics:

  > 	<<fig=TRUE, family=Palatino>>=
  > 		...
  > 	@

Why is setting it via ps.options() not sufficient for you?

Best,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch@ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch

From ligges at statistik.uni-dortmund.de  Fri Sep 19 09:59:05 2003
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Fri Sep 19 08:58:52 2003
Subject: [Rd] hist will not use parameter xaxs (PR#4219)
Message-ID: <200309190659.h8J6x5JH022570@pubhealth.ku.dk>

mwall@diversa.com wrote:

> Full_Name: Mark Wall
> Version: 1.6.0

Please don't submit bug reports for outdated versions of R.


> OS: linux
> Submission from: (NULL) (63.251.119.254)
> 
> 
> I want to plot a histogram of a *subset* of some data:
> 
> 
>>t = c(0:9)
>>hist(t,right=FALSE,breaks=10,xlim=c(0,5),xaxs="i")
 >
> 
> This means I should plot a histogram from 0 to 5 with breaks at 1,2,3,4.  This
> should produce exactly 5 bars of frequency=1.  Instead I get 5 and 1/4 bars.  I
> do not want the 4% margins on the x axis that xaxs="r" provides.

What documentation tells us that hist() accepts an argument "xaxs"? I 
cannot find any. Hence it is *not* a bug. You can use par() to set 
parameters like this.


What you can do is:

  dat <- 0:9
  par(xaxs = "i")
  hist(dat, right = FALSE, xlim = c(0, 5), breaks = 10)

or subset your data itself:

  hist(t[t<5], right = FALSE, breaks=0:5)

Uwe Ligges

From hb at maths.lth.se  Fri Sep 19 16:28:16 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri Sep 19 15:27:55 2003
Subject: [Rd] R CMD INSTALL is sensitive to trailing newlines in
	DESCRIPTION.in
Message-ID: <000601c37eb1$e282f410$e502eb82@maths.lth.se>

Hi, with R v1.7.1 (=I don't recall I saw it before) I noticed that R CMD
INSTALL sometimes generates nonsense information, e.g. "Bundle: NA",
even if there was a correct DESCRIPTION file too.  I turns out that it
happens when a DESCRIPTION.in has empty lines at the end. I have
observed this behavior on both Sun Solaris 9 and Windows XP Pro (but
here I am using unsupported Cygwin w/ perl).

Here is a reproducible example:

 1. Add an extra empty line at the end of /MASS/DESCRIPTION.in in the VR
bundle (http://cran.r-project.org/src/contrib/VR_7.1-8.tar.gz) to get
-------------------------------------------------------------
Package: MASS<newline>
Description: The main library and the datasets<newline>
Title: Main Library of Venables and Ripley's MASS<newline>
<newline>
-------------------------------------------------------------
 2. Run R CMD INSTALL VR_7.1-8.tar.gz
 3. The generated $R_HOME/library/MASS/DESCRIPTION file now looks like:
-------------------------------------------------------------
Package: MASS
Description: The main library and the datasets
Title: Main Library of Venables and Ripley's MASS
Bundle: NA
Priority: NA
Version: NA
Date: NA
Depends: NA
Author: NA
Maintainer: NA
BundleDescription: NA
License: NA
URL: NA
Built: R 1.7.1; sparc-sun-solaris2.9; 2003-09-19 13:40:41 
-------------------------------------------------------------
 4. Remove the last <newline> again and rerun R CMD INSTALL and
    the bundle information is correct, i.e. "Bundle: VR" etc.

Should I report this is as a bug?

Best wishes

Henrik Bengtsson

Dept. of Mathematical Statistics @ Centre for Mathematical Sciences
Lund Institute of Technology/Lund University, Sweden 
(Sweden +2h UTC, Melbourne +10 UTC, Calif. -7h UTC)
+46 708 909208 (cell), +46 46 320 820 (home), 
+1 (508) 464 6644 (global fax),
+46 46 2229611 (off), +46 46 2224623 (dept. fax)
h b @ m a t h s . l t h . s e, http://www.maths.lth.se/~hb/

From mmaclenn at nmdp.org  Sat Sep 20 01:40:49 2003
From: mmaclenn at nmdp.org (mmaclenn@nmdp.org)
Date: Sat Sep 20 00:40:03 2003
Subject: [Rd] PR#2867
Message-ID: <200309192240.h8JMenJH002539@pubhealth.ku.dk>

Full_Name: Mark MacLennan
Version: 1.7.1
OS: Solaris 8
Submission from: (NULL) (216.17.17.197)



Bug PR#2867 appears to still be occurring ...

I am running Solaris 8 using gcc 3.3 and while running the
tests for R 1.7.1 I get the following error message regarding
Lapack routine dqeqp3

I don't know how serious an issue this is!

Thanks for any help!
Mark

-----


running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout] Error 1
make[3]: Leaving directory `/usr/local/src/R-1.7.1/tests'
make[2]: *** [test-Reg] Error 2
make[2]: Leaving directory `/usr/local/src/R-1.7.1/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/usr/local/src/R-1.7.1/tests'
make: *** [check] Error 2



% tail -20 reg-tests-1.Rout.fail

+   agn <- agnes(xn, method="complete")
+   hcagn <- as.hclust(agn)
+   iC2 <- !names(hcag) %in% c("labels", "call")
+   stopifnot(identical(hcagn[iC2], hcag[iC2]),
+             identical(hcagn$labels, hcn$labels),
+             all.equal(hc$height, hcag$height, tol = 1e-12),
+             all(hc$merge == hcag$merge | hc$merge == hcag$merge[ ,2:1])
+             )
+ }
Loading required package: cluster 
> ## as.hclust.twins() lost labels and more till (incl) 1.6.2
> 
> 
> ## PR#2867 qr(LAPACK=TRUE) didn't always pivot in 1.7.0
> set.seed(1)
> X <- matrix(rnorm(40),10,4)
> X[,1] <- X[,2]
> (qrx <- qr(X, LAPACK=TRUE))
Error in qr(X, LAPACK = TRUE) : error code -1 from Lapack routine dqeqp3
Execution halted

From jago at mclink.it  Sat Sep 20 12:10:12 2003
From: jago at mclink.it (Stefano Iacus)
Date: Sat Sep 20 11:09:29 2003
Subject: [Rd] XML package for Darwin
Message-ID: <3D589FEA-EB4A-11D7-BEE9-003065CC4CB8@mclink.it>

Has anyone successfully built the XML package for Darwin R 1.8.0 alpha?

If so, in what configurations?

stefano

From Kurt.Hornik at wu-wien.ac.at  Sat Sep 20 14:12:54 2003
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Sat Sep 20 13:13:55 2003
Subject: [Rd] R CMD INSTALL is sensitive to trailing newlines in
	DESCRIPTION.in
In-Reply-To: <000601c37eb1$e282f410$e502eb82@maths.lth.se>
References: <000601c37eb1$e282f410$e502eb82@maths.lth.se>
Message-ID: <16236.13878.273850.295483@mithrandir.hornik.net>

>>>>> Henrik Bengtsson writes:

> Hi, with R v1.7.1 (=I don't recall I saw it before) I noticed that R CMD
> INSTALL sometimes generates nonsense information, e.g. "Bundle: NA",
> even if there was a correct DESCRIPTION file too.  I turns out that it
> happens when a DESCRIPTION.in has empty lines at the end. I have
> observed this behavior on both Sun Solaris 9 and Windows XP Pro (but
> here I am using unsupported Cygwin w/ perl).

> Here is a reproducible example:

> ...

> Should I report this is as a bug?

No, as I am about to commit a fix to the Unix INSTALL script :-)

Windows maintainers: I suspect that src/gnuwin32/fixed/dobundle.pl needs
a similar change, perhaps something like

	next if (/^ *$/);

in the loop writing the DESCRIPTION file.

-k

From deleeuw at stat.ucla.edu  Sat Sep 20 09:03:58 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sat Sep 20 17:03:52 2003
Subject: [Rd] XML package for Darwin
In-Reply-To: <3D589FEA-EB4A-11D7-BEE9-003065CC4CB8@mclink.it>
References: <3D589FEA-EB4A-11D7-BEE9-003065CC4CB8@mclink.it>
Message-ID: <A934B4B2-EB7B-11D7-8D17-000393BB6D36@stat.ucla.edu>

I can get it to build and install quite easily, I have not tested it in
any way. In fact R CMD CHECK fails in running all examples.
Output files included below.

  
-------------- next part --------------


1. I use libxml from fink (1.8.17-3 )

2. When linking XML.so I manually add the flag "-Xlinker -m" because

ld: warning multiple definitions of symbol _xmlParserError
Utils.o definition of _xmlParserError in section (__TEXT,__text)
/sw/lib/libxml.dylib(error.lo) definition of _xmlParserError

My understanding is that xmlParserError from Utils.c is supposed to
overwrite the one from libxml, but simple overriding is not possible
in OS X flat namespaces. The linker flag forces the right definition.

Here is some configure output

checking libxml/parser.h usability... yes
checking libxml/parser.h presence... yes
checking for libxml/parser.h... yes
Found the libxml parser.h in /sw/include/gnome-xml/libxml/
Located parser file /sw/include/gnome-xml/parser.h
-D__DEBUGGING__ -I/sw/include/gnome-xml -I/sw/include/gnome-xml/libxml  
-I/sw/include/gnome-xml
Using libxml 1.8.*!
checking for gzopen in -lz... yes
checking for xmlParseFile in -lxml... yes
New style libxml!

Configuration information:

Libxml settings

libxml include directory: /sw/include/gnome-xml
libxml library directory: -L/sw/lib -lxml -lz -lz  -lxml
libxml 2:                 no

Compilation flags:        -D__DEBUGGING__ -I/sw/include/gnome-xml  
-I/sw/include/gnome-xml/libxml -DLIBXML -I/sw/include/gnome-xml
Link flags:               -L/sw/lib -lxml -lz -lz  -lxml


On Sep 20, 2003, at 2:10 , Stefano Iacus wrote:

> Has anyone successfully built the XML package for Darwin R 1.8.0 alpha?
>
> If so, in what configurations?
>
> stefano
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------
From gblevins at mn.rr.com  Sat Sep 20 20:59:31 2003
From: gblevins at mn.rr.com (gblevins@mn.rr.com)
Date: Sat Sep 20 19:58:47 2003
Subject: [Rd] grep in version 1.8 (PR#4231)
Message-ID: <200309201759.h8KHxVJH006266@pubhealth.ku.dk>

Full_Name: Gregory L. Blevins
Version: 1.8
OS: Windows 2000
Submission from: (NULL) (65.29.54.28)


I see this when I open 1.8

Error in grep("united.states", Sys.getlocale("LC_CTYPE"), TRUE) : 
        5 arguments passed to "grep" which requires 6.

R : Copyright 2003, The R Development Core Team
Version 1.8.0 alpha (2003-09-18)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

Error in grep("\\[", pattern) : 5 arguments passed to "grep" which requires 6.
> local({a <- CRAN.packages()
+ install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a)})
Error in grep("^file:", contriburl) : 5 arguments passed to "grep" which
requires 6.
>

From jago at mclink.it  Sat Sep 20 23:14:13 2003
From: jago at mclink.it (Stefano Iacus)
Date: Sat Sep 20 22:14:00 2003
Subject: [Rd] XML package for Darwin
In-Reply-To: <A934B4B2-EB7B-11D7-8D17-000393BB6D36@stat.ucla.edu>
Message-ID: <007ED387-EBA7-11D7-969C-003065CC4CB8@mclink.it>

Thanks Jan,
I got it build now (using libxml2) but make check fails with the same  
errors you reported.
stefano

On Sabato, set 20, 2003, at 17:03 Europe/Rome, Jan de Leeuw wrote:

> I can get it to build and install quite easily, I have not tested it in
> any way. In fact R CMD CHECK fails in running all examples.
> Output files included below.
>
>  <00check.log><XML-Ex.Rout>
>
> 1. I use libxml from fink (1.8.17-3 )
>
> 2. When linking XML.so I manually add the flag "-Xlinker -m" because
>
> ld: warning multiple definitions of symbol _xmlParserError
> Utils.o definition of _xmlParserError in section (__TEXT,__text)
> /sw/lib/libxml.dylib(error.lo) definition of _xmlParserError
>
> My understanding is that xmlParserError from Utils.c is supposed to
> overwrite the one from libxml, but simple overriding is not possible
> in OS X flat namespaces. The linker flag forces the right definition.
>
> Here is some configure output
>
> checking libxml/parser.h usability... yes
> checking libxml/parser.h presence... yes
> checking for libxml/parser.h... yes
> Found the libxml parser.h in /sw/include/gnome-xml/libxml/
> Located parser file /sw/include/gnome-xml/parser.h
> -D__DEBUGGING__ -I/sw/include/gnome-xml -I/sw/include/gnome-xml/libxml  
> -I/sw/include/gnome-xml
> Using libxml 1.8.*!
> checking for gzopen in -lz... yes
> checking for xmlParseFile in -lxml... yes
> New style libxml!
>
> Configuration information:
>
> Libxml settings
>
> libxml include directory: /sw/include/gnome-xml
> libxml library directory: -L/sw/lib -lxml -lz -lz  -lxml
> libxml 2:                 no
>
> Compilation flags:        -D__DEBUGGING__ -I/sw/include/gnome-xml  
> -I/sw/include/gnome-xml/libxml -DLIBXML -I/sw/include/gnome-xml
> Link flags:               -L/sw/lib -lxml -lz -lz  -lxml
>
>
> On Sep 20, 2003, at 2:10 , Stefano Iacus wrote:
>
>> Has anyone successfully built the XML package for Darwin R 1.8.0  
>> alpha?
>>
>> If so, in what configurations?
>>
>> stefano
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>
>>
> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> Editor: Journal of Multivariate Analysis, Journal of Statistical  
> Software
> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email:  
> deleeuw@stat.ucla.edu
> homepage: http://gifi.stat.ucla.edu
>   
> ----------------------------------------------------------------------- 
> --------------------------
>           No matter where you go, there you are. --- Buckaroo Banzai
>                    http://gifi.stat.ucla.edu/sounds/nomatter.au
>   
> ----------------------------------------------------------------------- 
> --------------------------

From ceo102W1hDH at globalgiftware.net  Sun Sep 21 05:01:28 2003
From: ceo102W1hDH at globalgiftware.net (ceo102W1hDH@globalgiftware.net)
Date: Sun Sep 21 07:24:21 2003
Subject: [Rd] New Marketing tool
Message-ID: <a75b01c3800e$2dbc04a0$168dbccd@jpwdhhkyrwhe>

Hi!

I have something of utmost importance to discuss with
you and I Know this can impact your business greatly.
There is nothing like it on the net and I am sure
it will be hailed as the Hottest and best marketing 
tool of 2003 and beyond.

As you are well aware, Auto responders have 
become common place on the internet today 
and every where you turn you will find them.
As a professional marketer YOU know how important
it is to follow up with your prospects.

The Problem is that they are commonly seen as SP^M. 
This has forced the commercial auto responder 
companies to implement strict rules and limitations 
on the use of their services and those who install 
their own auto responders are risking loosing their 
hosting if they misuse them. 

There is finally a solution to this growing Problem...

A BULLET PROOF AUTO RESPONDER

We have Launched a BULLET PROOF Autoresponder
that you will never have to worry about Sp^m or 
worry about ISP issues.. All mail will run off our
servers..:)

you will be able to plug-in to 100,000 emails  a month..

You will be able to run multiple AR campaigns..


Because we aren't at risk of being 
kicked of our host (we own it), we can allow our members to 
import unverified people into our system. 

This means that you can use the auto responder as your 
first contact with people while complying to the 
most strict e-mailing law to date. The auto responder 
automatically generates a functioning removal 
link and cleans your lists against all removal  
requests that we have received to date.

Protect your business 
and 
Grow your business

mailto:frogs101@mailpuppy.com?subject=Bullet


SC







to be relieved from any futher
mailings.....
do not reply to this message..
simply send a request to
75npl500@hotpop.com?subject=relieved

From ligges at statistik.uni-dortmund.de  Sun Sep 21 12:23:57 2003
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Sun Sep 21 11:24:03 2003
Subject: [Rd] grep in version 1.8 (PR#4231)
Message-ID: <200309210923.h8L9NvJH009422@pubhealth.ku.dk>



gblevins@mn.rr.com wrote:
> 
> Full_Name: Gregory L. Blevins
> Version: 1.8
> OS: Windows 2000
> Submission from: (NULL) (65.29.54.28)
> 
> I see this when I open 1.8
> 
> Error in grep("united.states", Sys.getlocale("LC_CTYPE"), TRUE) :
>         5 arguments passed to "grep" which requires 6.
> 
> R : Copyright 2003, The R Development Core Team
> Version 1.8.0 alpha (2003-09-18)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
> 
> Error in grep("\\[", pattern) : 5 arguments passed to "grep" which requires 6.
> > local({a <- CRAN.packages()
> + install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a)})
> Error in grep("^file:", contriburl) : 5 arguments passed to "grep" which
> requires 6.
> >
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel


This is not a bug! It works when compiling from clean sources.

I guess you have unpacked new sources over old sources? Please clean the
directory before unpacking a new version, and try to compile again. A
couple of us ran in the same problem during the last weeks.

Uwe Ligges

From dmurdoch at pair.com  Sun Sep 21 18:50:30 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun Sep 21 23:49:43 2003
Subject: [Rd] grep in version 1.8 (PR#4231)
In-Reply-To: <200309210923.h8L9NvJH009422@pubhealth.ku.dk>
References: <200309210923.h8L9NvJH009422@pubhealth.ku.dk>
Message-ID: <647smv8672sqfs965mh2pe290onaqs0r5f@4ax.com>

On Sun, 21 Sep 2003 11:23:57 +0200 (MET DST), you wrote:

>This is not a bug! It works when compiling from clean sources.
>
>I guess you have unpacked new sources over old sources? Please clean the
>directory before unpacking a new version, and try to compile again. A
>couple of us ran in the same problem during the last weeks.

I don't know if this is what happened here, but this kind of thing
also happens when using rsync, not just when unpacking tarballs:
rsync won't delete obsolete files.  Anonymous cvs wouldn't have this
problem.

Duncan Murdoch

From deepayan at stat.wisc.edu  Sun Sep 21 17:58:10 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun Sep 21 23:57:32 2003
Subject: [Rd] grep in version 1.8 (PR#4231)
In-Reply-To: <647smv8672sqfs965mh2pe290onaqs0r5f@4ax.com>
References: <200309210923.h8L9NvJH009422@pubhealth.ku.dk>
	<647smv8672sqfs965mh2pe290onaqs0r5f@4ax.com>
Message-ID: <200309211658.10090.deepayan@stat.wisc.edu>

On Sunday 21 September 2003 16:50, Duncan Murdoch wrote:
> On Sun, 21 Sep 2003 11:23:57 +0200 (MET DST), you wrote:
> >This is not a bug! It works when compiling from clean sources.
> >
> >I guess you have unpacked new sources over old sources? Please clean the
> >directory before unpacking a new version, and try to compile again. A
> >couple of us ran in the same problem during the last weeks.
>
> I don't know if this is what happened here, but this kind of thing
> also happens when using rsync, not just when unpacking tarballs:
> rsync won't delete obsolete files.  Anonymous cvs wouldn't have this
> problem.

rsync should delete files if you give the --delete flag (and cvs wouldn't 
unless you give the -d flag).

Deepayan

From rossini at blindglobe.net  Sun Sep 21 15:58:54 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon Sep 22 00:01:07 2003
Subject: [Rd] grep in version 1.8 (PR#4231)
In-Reply-To: <647smv8672sqfs965mh2pe290onaqs0r5f@4ax.com> (Duncan Murdoch's
	message of "Sun, 21 Sep 2003 17:50:30 -0400")
References: <200309210923.h8L9NvJH009422@pubhealth.ku.dk>
	<647smv8672sqfs965mh2pe290onaqs0r5f@4ax.com>
Message-ID: <8565jlajmp.fsf@blindglobe.net>

Duncan Murdoch <dmurdoch@pair.com> writes:

> On Sun, 21 Sep 2003 11:23:57 +0200 (MET DST), you wrote:
>
>>This is not a bug! It works when compiling from clean sources.
>>
>>I guess you have unpacked new sources over old sources? Please clean the
>>directory before unpacking a new version, and try to compile again. A
>>couple of us ran in the same problem during the last weeks.
>
> I don't know if this is what happened here, but this kind of thing
> also happens when using rsync, not just when unpacking tarballs:
> rsync won't delete obsolete files.  Anonymous cvs wouldn't have this
> problem.

While my opinion of anon rsync vs anon cvs is probably well known,
this just isn't "quite" true.

Use the --delete option, i.e.  a form like:

    rsync -avz --delete    

to "clean out" the directory.  (of course, this might not be what you
really want to do :-).

best,
-tony

p.s. Duncan, I've been hyper-occupied, but will fire off something
later tonight.

-- 
rossini@u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}

From ms_engnr at hotmail.com  Sun Sep 21 19:15:08 2003
From: ms_engnr at hotmail.com (Kimberly Robinson)
Date: Mon Sep 22 00:14:19 2003
Subject: [Rd] remove me please
Message-ID: <Law15-F89wY0VnkB4lt00029cf8@hotmail.com>



_________________________________________________________________
Instant message in style with MSN Messenger 6.0. Download it now FREE!  
http://msnmessenger-download.com

From dmurdoch at pair.com  Mon Sep 22 07:07:00 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon Sep 22 12:06:17 2003
Subject: [Rd] grep in version 1.8 (PR#4231)
In-Reply-To: <200309211658.10090.deepayan@stat.wisc.edu>
References: <200309210923.h8L9NvJH009422@pubhealth.ku.dk>
	<647smv8672sqfs965mh2pe290onaqs0r5f@4ax.com>
	<200309211658.10090.deepayan@stat.wisc.edu>
Message-ID: <90itmv0o3diihv1v6r2e1f0tpc367r9qt0@4ax.com>

On Sun, 21 Sep 2003 16:58:10 -0500, you wrote:

>On Sunday 21 September 2003 16:50, Duncan Murdoch wrote:
>> On Sun, 21 Sep 2003 11:23:57 +0200 (MET DST), you wrote:
>> >This is not a bug! It works when compiling from clean sources.
>> >
>> >I guess you have unpacked new sources over old sources? Please clean the
>> >directory before unpacking a new version, and try to compile again. A
>> >couple of us ran in the same problem during the last weeks.
>>
>> I don't know if this is what happened here, but this kind of thing
>> also happens when using rsync, not just when unpacking tarballs:
>> rsync won't delete obsolete files.  Anonymous cvs wouldn't have this
>> problem.
>
>rsync should delete files if you give the --delete flag

Yes, but then you end up doing a clean build, because it will also
delete the *.o files, etc.  I don't think there's a concept of
deleting files that were there yesterday but aren't there today.

> (and cvs wouldn't 
>unless you give the -d flag).

-d means something different, it's about which directory to work in. I
notice that I've set a default arg of -Pd, but it's not documented in
my version of cvs as far as I can tell; maybe that's what you're
thinking of?

Duncan Murdoch

From p.dalgaard at biostat.ku.dk  Mon Sep 22 11:36:09 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Sep 22 12:36:12 2003
Subject: [Rd] grep in version 1.8 (PR#4231)
In-Reply-To: <90itmv0o3diihv1v6r2e1f0tpc367r9qt0@4ax.com>
References: <200309210923.h8L9NvJH009422@pubhealth.ku.dk>
	<647smv8672sqfs965mh2pe290onaqs0r5f@4ax.com>
	<200309211658.10090.deepayan@stat.wisc.edu>
	<90itmv0o3diihv1v6r2e1f0tpc367r9qt0@4ax.com>
Message-ID: <x28yoh5cpj.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch@pair.com> writes:

> > (and cvs wouldn't 
> >unless you give the -d flag).
> 
> -d means something different, it's about which directory to work in. I
> notice that I've set a default arg of -Pd, but it's not documented in
> my version of cvs as far as I can tell; maybe that's what you're
> thinking of?

In that position (after "up" in "cvs up -Pd") -d means create
any new directories and -P deletes empty ones. (Notice that cvs
options are position dependent, so you may have scanned the wrong part
of the documentation. It is documented in mine.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Friedrich.Leisch at ci.tuwien.ac.at  Mon Sep 22 14:08:06 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Mon Sep 22 13:07:23 2003
Subject: [Rd] grep in version 1.8 (PR#4231)
In-Reply-To: <90itmv0o3diihv1v6r2e1f0tpc367r9qt0@4ax.com>
References: <200309210923.h8L9NvJH009422@pubhealth.ku.dk>
	<647smv8672sqfs965mh2pe290onaqs0r5f@4ax.com>
	<200309211658.10090.deepayan@stat.wisc.edu>
	<90itmv0o3diihv1v6r2e1f0tpc367r9qt0@4ax.com>
Message-ID: <16238.55318.838645.545894@galadriel.ci.tuwien.ac.at>

>>>>> On Mon, 22 Sep 2003 06:07:00 -0400,
>>>>> Duncan Murdoch (DM) wrote:

  > On Sun, 21 Sep 2003 16:58:10 -0500, you wrote:
  >> On Sunday 21 September 2003 16:50, Duncan Murdoch wrote:
  >>> On Sun, 21 Sep 2003 11:23:57 +0200 (MET DST), you wrote:
  >>> >This is not a bug! It works when compiling from clean sources.
  >>> >
  >>> >I guess you have unpacked new sources over old sources? Please clean the
  >>> >directory before unpacking a new version, and try to compile again. A
  >>> >couple of us ran in the same problem during the last weeks.
  >>> 
  >>> I don't know if this is what happened here, but this kind of thing
  >>> also happens when using rsync, not just when unpacking tarballs:
  >>> rsync won't delete obsolete files.  Anonymous cvs wouldn't have this
  >>> problem.
  >> 
  >> rsync should delete files if you give the --delete flag

  > Yes, but then you end up doing a clean build, because it will also
  > delete the *.o files, etc.  I don't think there's a concept of
  > deleting files that were there yesterday but aren't there today.

Yes, there is:

1) Use the --delete flag when updating the sources
2) Use a build directory that is different from your source tree, that
   way rsync will never see the *.o et al files.

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch@ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch

From xiaobao_wang at yahoo.com  Mon Sep 22 03:26:32 2003
From: xiaobao_wang at yahoo.com (xiaobao_wang@yahoo.com)
Date: Mon Sep 22 14:04:39 2003
Subject: [Rd] creates directory that can't be deleted (PR#4246)
Message-ID: <200309220026.h8M0QWJH012751@pubhealth.ku.dk>

Full_Name: Xiaobao Wang
Version: R 1.7.1
OS: Windows XP
Submission from: (NULL) (24.45.25.102)


accidentally done the following:

rpt.dir <- paste("c:/report/testR","bestsub",spe="/")
dir.create(rpt.dir)

(spe should be sep).  Now the directory "c:/report/testR bestsub " cannot be
removed.  I tried to remove it from Windows Explorer and got the message box:
=================================================================
Error Deleting file or folder:
   Cannot delete file: Cannot read from source file or disk

From dmurdoch at pair.com  Mon Sep 22 09:47:14 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon Sep 22 14:47:38 2003
Subject: [Rd] grep in version 1.8 (PR#4231)
In-Reply-To: <16238.55318.838645.545894@galadriel.ci.tuwien.ac.at>
References: <200309210923.h8L9NvJH009422@pubhealth.ku.dk>
	<647smv8672sqfs965mh2pe290onaqs0r5f@4ax.com>
	<200309211658.10090.deepayan@stat.wisc.edu>
	<90itmv0o3diihv1v6r2e1f0tpc367r9qt0@4ax.com>
	<16238.55318.838645.545894@galadriel.ci.tuwien.ac.at>
Message-ID: <ujrtmvou99v5vcuqppr4is6fvlu3rbr63l@4ax.com>

On Mon, 22 Sep 2003 13:08:06 +0200, Friedrich.Leisch@ci.tuwien.ac.at
wrote :

>>>>>> On Mon, 22 Sep 2003 06:07:00 -0400,
>>>>>> Duncan Murdoch (DM) wrote:

>  > Yes, but then you end up doing a clean build, because it will also
>  > delete the *.o files, etc.  I don't think there's a concept of
>  > deleting files that were there yesterday but aren't there today.
>
>Yes, there is:
>
>1) Use the --delete flag when updating the sources
>2) Use a build directory that is different from your source tree, that
>   way rsync will never see the *.o et al files.

2) isn't currently possible in Windows, which I guess is another
reason we should move to a single set of makefiles, instead of
maintaining a separate set for Windows.

Duncan

From tim.massingham at ebi.ac.uk  Mon Sep 22 16:47:30 2003
From: tim.massingham at ebi.ac.uk (tim.massingham@ebi.ac.uk)
Date: Mon Sep 22 15:46:48 2003
Subject: [Rd] PR#2894
Message-ID: <200309221347.h8MDlUJH021443@pubhealth.ku.dk>

>Date: Fri, 2 May 2003 10:03:23 -0400 (EDT)
From: Morten Welinder <welinder@rentec.com>
>To: p.dalgaard@biostat.ku.dk
>CC: r-devel@stat.math.ethz.ch, R-bugs@biostat.ku.dk
>Subject: Re: [Rd] qbeta hang (PR#2894)
>
>Ok, I can confirm that it does not, in fact, loop forever.  Just a close
>approximation.

...

>There are lots of other places that worry me with respect to cancellation
>errors, for example
>
>    r = 1 - pp;
>    t = 1 - qq;

	These can also be removed by changing qbeta.c:156-157 (R-1.7.1)
to
y = (y-a) * xinbta * (1.0-xinbta) *
exp (logbeta - pp * log(xinbta) - qq * log1p(-xinbta));

I don't understand why you have qbeta.c:167
if (fabs(y)<=acu) goto L_converged
which will fail for certain values of p & q, when x is close to zero as
the beta density tends to infinity. Why not use an exit condition based on
how far away from 'a' you are?

qbeta.c:174 (prevent excess precision)
Might this not just get optimized out? I doubt modern compilers respect
 the volatile keyword. You should probably replace this with a safe
 comparison. if(fabs(tx-xinbta)<=DBL_EPSILON*fabs(xinbta))...
** This should be checked with someone familiar with floating point
arithmetic; I'm not and may have got the correct expression wrong.

The 'infinite loop' is due to the speed of the pbeta routine, rather than
the initial approximation from the qbeta. There is another algorithm
available for pbeta (Algorithm 708, CACM 18. 360--373, 1992) which may be
of use here. This continued fraction approximation is recommended by
Numerical Recipes over the power series approximation (make of that what
you will!)

	  TimM.

From tim.massingham at ebi.ac.uk  Mon Sep 22 16:49:11 2003
From: tim.massingham at ebi.ac.uk (tim.massingham@ebi.ac.uk)
Date: Mon Sep 22 15:48:25 2003
Subject: [Rd] Re: PR#2894
Message-ID: <200309221349.h8MDnBJH021475@pubhealth.ku.dk>

On Monday 22 Sep 2003 2:36 pm, I wrote:
> The 'infinite loop' is due to the speed of the pbeta routine, rather
> than the initial approximation from the qbeta. There is another
> algorithm available for pbeta (Algorithm 708, CACM 18. 360--373, 1992)

	That should be TOMS, not CACM. Sorry.

> which may be of use here. This continued fraction approximation is
> recommended by Numerical Recipes over the power series approximation
> (make of that what you will!)

	  TimM.

From deepayan at stat.wisc.edu  Mon Sep 22 10:28:47 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon Sep 22 16:28:13 2003
Subject: [Rd] grep in version 1.8 (PR#4231)
In-Reply-To: <90itmv0o3diihv1v6r2e1f0tpc367r9qt0@4ax.com>
References: <200309210923.h8L9NvJH009422@pubhealth.ku.dk>
	<200309211658.10090.deepayan@stat.wisc.edu>
	<90itmv0o3diihv1v6r2e1f0tpc367r9qt0@4ax.com>
Message-ID: <200309220928.47235.deepayan@stat.wisc.edu>

On Monday 22 September 2003 05:07, you wrote:
> > (and cvs wouldn't
> >unless you give the -d flag).
>
> -d means something different, it's about which directory to work in. I
> notice that I've set a default arg of -Pd, but it's not documented in
> my version of cvs as far as I can tell; maybe that's what you're
> thinking of?

You're right, I wasn't remembering this correctly. 

Actually there's a -d just after cvs which specifies the CVS root, and another 
option after update, which is documented as:


            Use  the  -d  option to create any directories that exist in
            the repository if they're missing from  the  working  direc-
            tory.   (Normally, update acts only on directories and files
            that were already enrolled in your working directory.)  ...

From pgilbert at bank-banque-canada.ca  Mon Sep 22 11:33:29 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon Sep 22 16:28:49 2003
Subject: [Rd] grep in version 1.8 (PR#4231)
In-Reply-To: <16238.55318.838645.545894@galadriel.ci.tuwien.ac.at>
References: <200309210923.h8L9NvJH009422@pubhealth.ku.dk>	<647smv8672sqfs965mh2pe290onaqs0r5f@4ax.com>	<200309211658.10090.deepayan@stat.wisc.edu>	<90itmv0o3diihv1v6r2e1f0tpc367r9qt0@4ax.com>
	<16238.55318.838645.545894@galadriel.ci.tuwien.ac.at>
Message-ID: <3F6F0839.2030507@bankofcanada.ca>

Friedrich.Leisch@ci.tuwien.ac.at wrote:

>>>>>>On Mon, 22 Sep 2003 06:07:00 -0400,
>>>>>>Duncan Murdoch (DM) wrote:
>>>>>>            
>>>>>>
>
>  > On Sun, 21 Sep 2003 16:58:10 -0500, you wrote:
>  >> On Sunday 21 September 2003 16:50, Duncan Murdoch wrote:
>  >>> On Sun, 21 Sep 2003 11:23:57 +0200 (MET DST), you wrote:
>  >>> >This is not a bug! It works when compiling from clean sources.
>  >>> >
>  >>> >I guess you have unpacked new sources over old sources? Please clean the
>  >>> >directory before unpacking a new version, and try to compile again. A
>  >>> >couple of us ran in the same problem during the last weeks.
>  >>> 
>  >>> I don't know if this is what happened here, but this kind of thing
>  >>> also happens when using rsync, not just when unpacking tarballs:
>  >>> rsync won't delete obsolete files.  Anonymous cvs wouldn't have this
>  >>> problem.
>  >> 
>  >> rsync should delete files if you give the --delete flag
>
>  > Yes, but then you end up doing a clean build, because it will also
>  > delete the *.o files, etc.  I don't think there's a concept of
>  > deleting files that were there yesterday but aren't there today.
>
>Yes, there is:
>
>1) Use the --delete flag when updating the sources
>
(From another strand of this thread)  I don't think the -P option to the 
cvs update command does this, it just prunes empty subdirectories, and 
-d does roughly the opposite. If cvs has a way to delete files that are 
not in the archive I have never found it, and would be curious to know 
what it is so that I can be careful to avoid it.

>2) Use a build directory that is different from your source tree, that
>   way rsync will never see the *.o et al files.
>
This is probably the answer, but I don't understand how it solves what I 
think was the original question. Could someone please expand on
 
  i/  How make will know to ignore certain .o files which should not be 
there, but leave other ones that are up-to-date and not rebuild them.

  ii/  How to build R in a different  directory from the sources.

Thanks,
Paul Gilbert

From Friedrich.Leisch at ci.tuwien.ac.at  Mon Sep 22 17:59:41 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Mon Sep 22 16:59:04 2003
Subject: [Rd] grep in version 1.8 (PR#4231)
In-Reply-To: <3F6F0839.2030507@bankofcanada.ca>
References: <200309210923.h8L9NvJH009422@pubhealth.ku.dk>
	<647smv8672sqfs965mh2pe290onaqs0r5f@4ax.com>
	<200309211658.10090.deepayan@stat.wisc.edu>
	<90itmv0o3diihv1v6r2e1f0tpc367r9qt0@4ax.com>
	<16238.55318.838645.545894@galadriel.ci.tuwien.ac.at>
	<3F6F0839.2030507@bankofcanada.ca>
Message-ID: <16239.3677.852311.34879@galadriel.ci.tuwien.ac.at>

>>>>> On Mon, 22 Sep 2003 10:33:29 -0400,
>>>>> Paul Gilbert (PG) wrote:

  > Friedrich.Leisch@ci.tuwien.ac.at wrote:
  >>>>>>> On Mon, 22 Sep 2003 06:07:00 -0400,
  >>>>>>> Duncan Murdoch (DM) wrote:
  >>>>>>> 
  >>>>>>> 
  >> 
  >> > On Sun, 21 Sep 2003 16:58:10 -0500, you wrote:
  >> >> On Sunday 21 September 2003 16:50, Duncan Murdoch wrote:
  >> >>> On Sun, 21 Sep 2003 11:23:57 +0200 (MET DST), you wrote:
  >> >>> >This is not a bug! It works when compiling from clean sources.
  >> >>> >
  >> >>> >I guess you have unpacked new sources over old sources? Please clean the
  >> >>> >directory before unpacking a new version, and try to compile again. A
  >> >>> >couple of us ran in the same problem during the last weeks.
  >> >>> 
  >> >>> I don't know if this is what happened here, but this kind of thing
  >> >>> also happens when using rsync, not just when unpacking tarballs:
  >> >>> rsync won't delete obsolete files.  Anonymous cvs wouldn't have this
  >> >>> problem.
  >> >> 
  >> >> rsync should delete files if you give the --delete flag
  >> 
  >> > Yes, but then you end up doing a clean build, because it will also
  >> > delete the *.o files, etc.  I don't think there's a concept of
  >> > deleting files that were there yesterday but aren't there today.
  >> 
  >> Yes, there is:
  >> 
  >> 1) Use the --delete flag when updating the sources
  >> 
  > (From another strand of this thread)  I don't think the -P option to the 
  > cvs update command does this, it just prunes empty subdirectories, and 
  > -d does roughly the opposite. If cvs has a way to delete files that are 
  > not in the archive I have never found it, and would be curious to know 
  > what it is so that I can be careful to avoid it.

  >> 2) Use a build directory that is different from your source tree, that
  >> way rsync will never see the *.o et al files.
  >> 
  > This is probably the answer, but I don't understand how it solves what I 
  > think was the original question. Could someone please expand on
 
  >   i/  How make will know to ignore certain .o files which should not be 
  > there, but leave other ones that are up-to-date and not rebuild
  > them.

It doesn't work all the time, sometimes a fresh build from scratch is
required. But it works most of the time (I do it every day).

  >   ii/  How to build R in a different  directory from the sources.

On Unix: Simply create and go go to an empty directory and type

	PATH/TO/THE/R/SOURCE/TREE/configure

and then proceed as usual, i.e., type

	make

etc.

On windows (as I just learned from Duncan) this does not work. I don't
know about the Mac.

.f

From p.dalgaard at biostat.ku.dk  Mon Sep 22 17:10:34 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Sep 22 18:10:36 2003
Subject: [Rd] PR#2894
In-Reply-To: <200309221347.h8MDlUJH021443@pubhealth.ku.dk>
References: <200309221347.h8MDlUJH021443@pubhealth.ku.dk>
Message-ID: <x2vfrkssul.fsf@biostat.ku.dk>

tim.massingham@ebi.ac.uk writes:

> qbeta.c:174 (prevent excess precision)
> Might this not just get optimized out? I doubt modern compilers respect
>  the volatile keyword.

What makes you say that? If they don't, they'll break other things
than qbeta, including the computation of machine constants. Some buggy
versions of GCC, including early versions of the infamous "2.96"
Redhat never-should-have-been release did ignore volatiles and we
suffered the consequences. Been there, got the scars...

[r-bugs taken off Cc: list]
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From kvanhorn at ksvanhorn.com  Mon Sep 22 21:19:10 2003
From: kvanhorn at ksvanhorn.com (kvanhorn@ksvanhorn.com)
Date: Mon Sep 22 20:18:24 2003
Subject: [Rd] documentation search: problem with links (PR#4254)
Message-ID: <200309221819.h8MIJAJH023591@pubhealth.ku.dk>

Full_Name: Kevin S. Van Horn
Version: 1.7.1
OS: Linux
Submission from: (NULL) (12.209.149.192)


I used help.start() to get the web help displayed in my browser (Mozilla 1.21,
on a RedHat Linux 9.0 system).  I then clicked on "Search Engine and Keywords",
and searched on "optimize".  The resulting web page had a number of links.  The
first time I clicked on one these links it worked OK, but after hitting the
"back" button to return to the search results page I found that clicking on the
links in the result page resulted in absolutely nothing happening.

From p.dalgaard at biostat.ku.dk  Mon Sep 22 20:16:00 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Sep 22 21:16:42 2003
Subject: [Rd] documentation search: problem with links (PR#4254)
In-Reply-To: <200309221819.h8MIJAJH023591@pubhealth.ku.dk>
References: <200309221819.h8MIJAJH023591@pubhealth.ku.dk>
Message-ID: <x2smmo7hrm.fsf@biostat.ku.dk>

kvanhorn@ksvanhorn.com writes:

> Full_Name: Kevin S. Van Horn
> Version: 1.7.1
> OS: Linux
> Submission from: (NULL) (12.209.149.192)
> 
> 
> I used help.start() to get the web help displayed in my browser (Mozilla 1.21,
> on a RedHat Linux 9.0 system).  I then clicked on "Search Engine and Keywords",
> and searched on "optimize".  The resulting web page had a number of links.  The
> first time I clicked on one these links it worked OK, but after hitting the
> "back" button to return to the search results page I found that clicking on the
> links in the result page resulted in absolutely nothing happening.

Sounds more like a browser problem than anything we can influence.
Have you tried Mozilla 1.4?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ligges at statistik.uni-dortmund.de  Mon Sep 22 22:55:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Sep 22 21:49:58 2003
Subject: [Rd] creates directory that can't be deleted (PR#4246)
References: <200309220026.h8M0QWJH012751@pubhealth.ku.dk>
Message-ID: <3F6F5397.65AFBCB8@statistik.uni-dortmund.de>

xiaobao_wang@yahoo.com wrote:

> Full_Name: Xiaobao Wang
> Version: R 1.7.1
> OS: Windows XP
> Submission from: (NULL) (24.45.25.102)
> 
> 
> accidentally done the following:
> 
> rpt.dir <- paste("c:/report/testR","bestsub",spe="/")
> dir.create(rpt.dir)
> 
> (spe should be sep).  Now the directory "c:/report/testR bestsub " cannot be
> removed.  I tried to remove it from Windows Explorer and got the message box:
> =================================================================
> Error Deleting file or folder:
>    Cannot delete file: Cannot read from source file or disk
> 


Hmmm. Strange. Since nobody else has answered up to now, here's a not
very promising answer:
I've got an unremovable directory now, too. Maybe I can take a closer
look tomorrow how to remove such files/directories on Windows. My first
guess was cygwin might help, but that seems not to be the case. Another
idea is to implement a remove-function in low level in the way the
directory was created (not sure whether that will work). I don't have
any further idea, except for using special tools to work directly on the
file system tables (don't do that!).

I thought Windows denies the creation of files (directories) with names
you cannot access later. From my point of view, this is a Windows bug,
not a bug in R [hence replied to r-devel]. Your report can be regarded
as a wishlist entry for working around the windows bug, so that
dir.create() and friends will report an error when trying to create
not-allowed names (presumably nobody is going to implement it, though).

Uwe Ligges

From michael.hecht at geocities.com  Tue Sep 23 10:39:41 2003
From: michael.hecht at geocities.com (michael.hecht@geocities.com)
Date: Tue Sep 23 09:39:13 2003
Subject: [Rd] RODBC access to MS-Excel (PR#4266)
Message-ID: <200309230739.h8N7dfJH027403@pubhealth.ku.dk>

Full_Name: Michael Hecht
Version: 1.7.1
OS: WinNT
Submission from: (NULL) (193.158.76.205)


I've got a problem with the RODBC library while trying to access to an MS-Excel
file. The Excel file was originally exportet by a commercial software, so I
cannot influence it. The problem is, that the names of the tables include
spaces, e.g. "Scan 1","Scan 2" etc. If I use RODBC, I get back something like
this
 
> channel<-odbcConnectExcel(fileName)
> tables<-sqlTables(channel)
> scanTables<-tables[c(grep("Scan",tables[,"TABLE_NAME"])),]
> scanTables
   TABLE_SCHEM TABLE_NAME   TABLE_TYPE REMARKS
16        <NA>  'Scan 1$'        TABLE    <NA>
4         <NA> 'Scan 10$'        TABLE    <NA>
5         <NA> 'Scan 11$'        TABLE    <NA>
6         <NA> 'Scan 12$'        TABLE    <NA>
...
 
If I try to fetch a table I get as result
 
> data<-sqlFetch(channel,"'Scan 2$'",rownames=T)
> data
[1] "S1000 -3003 [Microsoft][ODBC Excel Driver] Syntax error in query. 
Incomplete query clause."
[2] "[RODBC] ERROR: Could not SQLPrepare"   
 
If I now change by hand the Excel table, e.g. to "Scan 1" -> "Scan1" I get
   TABLE_SCHEM TABLE_NAME   TABLE_TYPE REMARKS
2         <NA>     Scan1$ SYSTEM TABLE    <NA>
4         <NA> 'Scan 10$'        TABLE    <NA>
5         <NA> 'Scan 11$'        TABLE    <NA>
6         <NA> 'Scan 12$'        TABLE    <NA>

but the following does'nt work
 
> data<-sqlFetch(channel,scanTables[1,"TABLE_NAME"],rownames=T)
Error in odbcTableExists(channel, sqtable) : 
        Scan1$ : table not found on channel

whereas this works well:
> data<-sqlFetch(channel,"Scan1",rownames=T)
> data
  X-Coord Y-Coord     C  a        C2        Si       Mn         P          S    
   Cr       Cr1
1     1648  117896 298.9131  5.558300  4.323123 167.3666 16.674902  0.6175889 
74.72826 0.6175889
2     1657  116857 374.2589 10.499012 11.116601 382.9052 16.674902 11.7341900
172.92490 0.6175889
3     1667  119522 453.9279  3.705534 11.116601 295.8251 15.439723  5.5583005
134.63438 0.6175889
4     1678  119281 468.7500 14.204546 12.351779 369.3182 22.233202  8.6462450
173.54250 0.6175889
...
 
Therefore I've two questions/problems:
1. where comes the $ from, Scan1$ or 'Scan 2$', is this a bug ??
2. How can I access such tables with spaces in the name ??

From ligges at statistik.uni-dortmund.de  Tue Sep 23 11:17:19 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue Sep 23 10:15:45 2003
Subject: [Rd] RODBC access to MS-Excel (PR#4266)
In-Reply-To: <200309230739.h8N7dfJH027403@pubhealth.ku.dk>
References: <200309230739.h8N7dfJH027403@pubhealth.ku.dk>
Message-ID: <3F70018F.6010503@statistik.uni-dortmund.de>

michael.hecht@geocities.com wrote:

> Full_Name: Michael Hecht
> Version: 1.7.1
> OS: WinNT
> Submission from: (NULL) (193.158.76.205)
> 
> 
> I've got a problem with the RODBC library while trying to access to an MS-Excel
> file. The Excel file was originally exportet by a commercial software, so I
> cannot influence it. The problem is, that the names of the tables include
> spaces, e.g. "Scan 1","Scan 2" etc. If I use RODBC, I get back something like
> this
>  
> 
>>channel<-odbcConnectExcel(fileName)
>>tables<-sqlTables(channel)
>>scanTables<-tables[c(grep("Scan",tables[,"TABLE_NAME"])),]
>>scanTables
> 
>    TABLE_SCHEM TABLE_NAME   TABLE_TYPE REMARKS
> 16        <NA>  'Scan 1$'        TABLE    <NA>
> 4         <NA> 'Scan 10$'        TABLE    <NA>
> 5         <NA> 'Scan 11$'        TABLE    <NA>
> 6         <NA> 'Scan 12$'        TABLE    <NA>
> ...
>  
> If I try to fetch a table I get as result
>  
> 
>>data<-sqlFetch(channel,"'Scan 2$'",rownames=T)
>>data
> 
> [1] "S1000 -3003 [Microsoft][ODBC Excel Driver] Syntax error in query. 
> Incomplete query clause."
> [2] "[RODBC] ERROR: Could not SQLPrepare"   
>  
> If I now change by hand the Excel table, e.g. to "Scan 1" -> "Scan1" I get
>    TABLE_SCHEM TABLE_NAME   TABLE_TYPE REMARKS
> 2         <NA>     Scan1$ SYSTEM TABLE    <NA>
> 4         <NA> 'Scan 10$'        TABLE    <NA>
> 5         <NA> 'Scan 11$'        TABLE    <NA>
> 6         <NA> 'Scan 12$'        TABLE    <NA>
> 
> but the following does'nt work
>  
> 
>>data<-sqlFetch(channel,scanTables[1,"TABLE_NAME"],rownames=T)
> 
> Error in odbcTableExists(channel, sqtable) : 
>         Scan1$ : table not found on channel
> 
> whereas this works well:
> 
>>data<-sqlFetch(channel,"Scan1",rownames=T)
>>data
> 
>   X-Coord Y-Coord     C  a        C2        Si       Mn         P          S    
>    Cr       Cr1
> 1     1648  117896 298.9131  5.558300  4.323123 167.3666 16.674902  0.6175889 
> 74.72826 0.6175889
> 2     1657  116857 374.2589 10.499012 11.116601 382.9052 16.674902 11.7341900
> 172.92490 0.6175889
> 3     1667  119522 453.9279  3.705534 11.116601 295.8251 15.439723  5.5583005
> 134.63438 0.6175889
> 4     1678  119281 468.7500 14.204546 12.351779 369.3182 22.233202  8.6462450
> 173.54250 0.6175889
> ...
>  
> Therefore I've two questions/problems:
> 1. where comes the $ from, Scan1$ or 'Scan 2$', is this a bug ??

If you are not sure whether it is a bug, don't send a bug report, but 
ask on R-help, please.

If there is a bug in a contributed package, please report it to the 
package maintainer (Prof. Brian Ripley, in this case), not to r-bugs, 
because it's not a bug in R itself (most package maintainers cannot 
access the bug repository).

Answer to your question: It comes from Excel, which is not the perfect 
Database engine.


> 2. How can I access such tables with spaces in the name ??
> 

   sqlQuery(channel, 'select * from "Scan 1$"')

Uwe Ligges

From andrews at udallas.edu  Tue Sep 23 16:27:29 2003
From: andrews at udallas.edu (David A. T. Andrews)
Date: Tue Sep 23 22:28:30 2003
Subject: [Rd] documentation search: problem with links (PR#4254)
In-Reply-To: <x2smmo7hrm.fsf@biostat.ku.dk>
References: <200309221819.h8MIJAJH023591@pubhealth.ku.dk>
	<x2smmo7hrm.fsf@biostat.ku.dk>
Message-ID: <Pine.WNT.4.55.0309231518220.5204@bayes.math.udallas.edu>

On Mon, 22 Sep 2003, Peter Dalgaard BSA wrote:
> kvanhorn@ksvanhorn.com writes:
>
> > Full_Name: Kevin S. Van Horn
> > Version: 1.7.1
> > OS: Linux
> > Submission from: (NULL) (12.209.149.192)
> >
> >
> > I used help.start() to get the web help displayed in my browser (Mozilla 1.21,
> > on a RedHat Linux 9.0 system).  I then clicked on "Search Engine and Keywords",
> > and searched on "optimize".  The resulting web page had a number of links.  The
> > first time I clicked on one these links it worked OK, but after hitting the
> > "back" button to return to the search results page I found that clicking on the
> > links in the result page resulted in absolutely nothing happening.
>
> Sounds more like a browser problem than anything we can influence.
> Have you tried Mozilla 1.4?

The problem *is* with Mozilla, and is present even in 1.5
(the latest release candidate) --- it also appears as a
problem in Netscape 7.x.  I've filed a bugzilla report
(#220082).  The problem occurs when you return (using the
back button) to a javascript generated page containing links
to local files (remote URLs work as expected!): the local
links are dead.  The search pages in R fit into this very
nicely.

D. Andrews
--
David A. Andrews                        Department of Mathematics
andrews@udallas.edu                          University of Dallas
972-721-5039                 http://www.udallas.edu:8080/~andrews

From MSchwartz at medanalytics.com  Tue Sep 23 16:58:42 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue Sep 23 22:58:06 2003
Subject: [Rd] documentation search: problem with links (PR#4254)
In-Reply-To: <Pine.WNT.4.55.0309231518220.5204@bayes.math.udallas.edu>
References: <200309221819.h8MIJAJH023591@pubhealth.ku.dk>
	<x2smmo7hrm.fsf@biostat.ku.dk>
	<Pine.WNT.4.55.0309231518220.5204@bayes.math.udallas.edu>
Message-ID: <1064350722.4102.18.camel@localhost>

On Tue, 2003-09-23 at 15:27, David A. T. Andrews wrote:
> On Mon, 22 Sep 2003, Peter Dalgaard BSA wrote:
> > kvanhorn@ksvanhorn.com writes:
> >
> > > Full_Name: Kevin S. Van Horn
> > > Version: 1.7.1
> > > OS: Linux
> > > Submission from: (NULL) (12.209.149.192)
> > >
> > >
> > > I used help.start() to get the web help displayed in my browser (Mozilla 1.21,
> > > on a RedHat Linux 9.0 system).  I then clicked on "Search Engine and Keywords",
> > > and searched on "optimize".  The resulting web page had a number of links.  The
> > > first time I clicked on one these links it worked OK, but after hitting the
> > > "back" button to return to the search results page I found that clicking on the
> > > links in the result page resulted in absolutely nothing happening.
> >
> > Sounds more like a browser problem than anything we can influence.
> > Have you tried Mozilla 1.4?
> 
> The problem *is* with Mozilla, and is present even in 1.5
> (the latest release candidate) --- it also appears as a
> problem in Netscape 7.x.  I've filed a bugzilla report
> (#220082).  The problem occurs when you return (using the
> back button) to a javascript generated page containing links
> to local files (remote URLs work as expected!): the local
> links are dead.  The search pages in R fit into this very
> nicely.
> 
> D. Andrews


FWIW, this has been discussed on r-help previously. See the following
posts:

http://maths.newcastle.edu.au/~rking/R/help/03a/3261.html
http://maths.newcastle.edu.au/~rking/R/help/03a/4206.html

HTH,

Marc Schwartz

From MSchwartz at medanalytics.com  Tue Sep 23 23:58:59 2003
From: MSchwartz at medanalytics.com (MSchwartz@medanalytics.com)
Date: Tue Sep 23 22:58:24 2003
Subject: [Rd] documentation search: problem with links (PR#4254)
Message-ID: <200309232059.h8NKwx0P001834@pubhealth.ku.dk>

On Tue, 2003-09-23 at 15:27, David A. T. Andrews wrote:
> On Mon, 22 Sep 2003, Peter Dalgaard BSA wrote:
> > kvanhorn@ksvanhorn.com writes:
> >
> > > Full_Name: Kevin S. Van Horn
> > > Version: 1.7.1
> > > OS: Linux
> > > Submission from: (NULL) (12.209.149.192)
> > >
> > >
> > > I used help.start() to get the web help displayed in my browser (Mozilla 1.21,
> > > on a RedHat Linux 9.0 system).  I then clicked on "Search Engine and Keywords",
> > > and searched on "optimize".  The resulting web page had a number of links.  The
> > > first time I clicked on one these links it worked OK, but after hitting the
> > > "back" button to return to the search results page I found that clicking on the
> > > links in the result page resulted in absolutely nothing happening.
> >
> > Sounds more like a browser problem than anything we can influence.
> > Have you tried Mozilla 1.4?
> 
> The problem *is* with Mozilla, and is present even in 1.5
> (the latest release candidate) --- it also appears as a
> problem in Netscape 7.x.  I've filed a bugzilla report
> (#220082).  The problem occurs when you return (using the
> back button) to a javascript generated page containing links
> to local files (remote URLs work as expected!): the local
> links are dead.  The search pages in R fit into this very
> nicely.
> 
> D. Andrews


FWIW, this has been discussed on r-help previously. See the following
posts:

http://maths.newcastle.edu.au/~rking/R/help/03a/3261.html
http://maths.newcastle.edu.au/~rking/R/help/03a/4206.html

HTH,

Marc Schwartz

From Mark.Bravington at csiro.au  Wed Sep 24 11:06:49 2003
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Wed Sep 24 10:06:01 2003
Subject: [Rd] getAnywhere (PR#4275)
Message-ID: <200309240806.h8O86n0P005770@pubhealth.ku.dk>

'getAnywhere' is not reporting methods when there are periods in the class name or the generic name 
(in R-devel).

> getAnywhere( 'predict.loess')
A single object matching 'predict.loess' was found
It was found in the following places
  registered S3 method for predict from namespace modreg
  namespace:modreg
with value
<<...>>

> getAnywhere( 'predict.smooth.spline.fit')
A single object matching 'predict.smooth.spline.fit' was found
It was found in the following places
  namespace:modreg
with value
<<...>>

In the second case, the report doesn't state that 'predict.smooth.spline.fit' is a registered method.

Also e.g.

> getAnywhere( 'as.dendrogram.hclust')

doesn't report that this is a registered method.

It looks like the two lines in 'getAnywhere' starting "gen <-" & "cl <- " might want to become:

gen <- paste(parts[1:(i - 1)], collapse = ".")
cl <- paste(parts[ i:length(parts)], collapse = ".")


Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington@csiro.au 

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = alpha
 major = 1
 minor = 8.0
 year = 2003
 month = 09
 day = 22
 language = R

Windows 2000 Professional (build 2195) Service Pack 3.0

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg, package:nls, package:ts, Autoloads, package:base

From alexg at trwim.com  Wed Sep 24 10:19:06 2003
From: alexg at trwim.com (Alex Gracian)
Date: Wed Sep 24 10:18:24 2003
Subject: [Rd] R compiled under windows 64 bit???
Message-ID: <0E33411D2F8B2847BB8457CC2023CB10090D40@trw-mail1.trwlondon.co.uk>

Hi,

Any plans to realse in Cran binaries for R base & packages, for Windows
using 64bit, now that the AMD 64 is coming out?

It seems a perfect match for cost effective high performane number
crunching??

Many thanks,

Alex Gracian

From ligges at statistik.uni-dortmund.de  Wed Sep 24 11:51:20 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Sep 24 10:49:42 2003
Subject: [Rd] R compiled under windows 64 bit???
In-Reply-To: <0E33411D2F8B2847BB8457CC2023CB10090D40@trw-mail1.trwlondon.co.uk>
References: <0E33411D2F8B2847BB8457CC2023CB10090D40@trw-mail1.trwlondon.co.uk>
Message-ID: <3F715B08.6050809@statistik.uni-dortmund.de>

Alex Gracian wrote:

> Hi,
> 
> Any plans to realse in Cran binaries for R base & packages, for Windows
> using 64bit, now that the AMD 64 is coming out?

No plans, AFAIK.
Are you volunteering to compile R base (there may be need for some 
adjustments in the code, as well as in the Makefiles) for CRAN?
The maintainer would need both, an AMD 64 machine, and a 64-bit Windows 
in order to compile.
I'm volunteering to make the packages, if you'll buy an AMD 64 machine + 
64-bit Windows for my office. ;-)


> It seems a perfect match for cost effective high performane number
> crunching??

I don't know whether it will be much faster to use the 64bit mode, 
because the internal structure of x86 processors for number crunching 
already has been 80 bit for floating point arithmetics. Additionally, 
you will need more RAM for the same problems which slows down some 
calculations.
In principle, you can extend the 2GB limit of the R process, though.

Uwe Ligges


> Many thanks,
> 
> Alex Gracian
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From p.dalgaard at biostat.ku.dk  Wed Sep 24 11:16:56 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Sep 24 12:17:34 2003
Subject: [Rd] R compiled under windows 64 bit???
In-Reply-To: <3F715B08.6050809@statistik.uni-dortmund.de>
References: <0E33411D2F8B2847BB8457CC2023CB10090D40@trw-mail1.trwlondon.co.uk>
	<3F715B08.6050809@statistik.uni-dortmund.de>
Message-ID: <x2r826mqwq.fsf@biostat.ku.dk>

Uwe Ligges <ligges@statistik.uni-dortmund.de> writes:

> Alex Gracian wrote:
> 
> > Hi,
> > Any plans to realse in Cran binaries for R base & packages, for
> > Windows
> > using 64bit, now that the AMD 64 is coming out?
> 
> No plans, AFAIK.
> Are you volunteering to compile R base (there may be need for some
> adjustments in the code, as well as in the Makefiles) for CRAN?
> The maintainer would need both, an AMD 64 machine, and a 64-bit
> Windows in order to compile.
> I'm volunteering to make the packages, if you'll buy an AMD 64 machine
> + 64-bit Windows for my office. ;-)

You may regret that statement, once you realize that you also need the
entire 64bit toolchain...

> > It seems a perfect match for cost effective high performane number
> > crunching??
> 
> I don't know whether it will be much faster to use the 64bit mode,
> because the internal structure of x86 processors for number crunching
> already has been 80 bit for floating point arithmetics. Additionally,
> you will need more RAM for the same problems which slows down some
> calculations.
> In principle, you can extend the 2GB limit of the R process, though.

Yes. And we do actually bump into that when we try to do something
sufficiently "stupid". Recent case: attempting to fit a polr() to weekly
data for 2500 persons for one year each, including 2500 person levels,
giving a design matrix of ~2.5GB. Some times you do want to try that
sort of thing by brute force and ignorance (of course, raising the
memory limit might just have revealed further obstacles...)

I would say that the perfect match currently is the SuSE Linux product
for AMD-64. I don't think people quite realize how much extra work
goes into maintaining the Windows platform (about as much as the
Unix/Linux variants combined, I'd say), and we basically only do it
because of its market penetration.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Wed Sep 24 15:30:14 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Sep 24 16:30:16 2003
Subject: [Rd] Feature freeze + beta version
Message-ID: <x265jimf6d.fsf@biostat.ku.dk>


The release countdown for R 1.8.0 has now entered the beta phase.
Apart from a change of name of the daily snapshots, this means that
there we are now in feature freeze, i.e. we will not add features or
change the API from now on. We will try to fix bugs and documentation
errors though. The same thing is assumed for the group of recommended
packages that we ship with the release. Code freeze is scheduled for
next Wednesday.

The beta versions are available from 

http://cran.us.r-project.org/src/base/R-1.8.0beta_2003-09-24.tar.gz

and so forth. Like the alpha releases, they are created automatically
at 5am local Wisconsin time. (The first one was done manually, a bit
later, since yesterday's local events caused some disruption of
plans...)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From pgilbert at bank-banque-canada.ca  Wed Sep 24 11:55:52 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed Sep 24 16:51:06 2003
Subject: [Rd] build in directory different from source
Message-ID: <3F71B078.4000209@bankofcanada.ca>

When I configure and make R-devel in a directory other than the one 
where I keep the source, there are a few top level files which are not 
copied to the build directory.  The ones I use are  VERSION and 
date-stamp, to help keep track of what I am testing.

Paul Gilbert

From pburns at pburns.seanet.com  Wed Sep 24 19:59:29 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Wed Sep 24 20:05:55 2003
Subject: [Rd] partial matching in data frame subscripting
Message-ID: <3F71DB81.9000606@pburns.seanet.com>

I'm not sure if the following is a bug or a feature:

 > jjmat <- array(1:6, c(2,3), list(c('ABC', 'DEF'), c('xyz', 'tuv', 
'qrs')))
 > jjdf <- as.data.frame(jjmat)
 > jjmat['AB', ]
Error: subscript out of bounds
 > jjdf['AB',]
    xyz tuv qrs
ABC   1   3   5
 > jjmat[, 'tu']
Error: subscript out of bounds
 > jjdf[, 'tu']
Error in "[.data.frame"(jjdf, , "tu") : undefined columns selected

The questionable behaviour is that partial matching of dimnames
is not allowed except for the rows in data frames.

(This is 1.8.0 alpha -- 1.7 would have given NULL when the
column of a data frame was partially matched.)

Without good arguments to the contrary, I would lean toward
partial matching not being allowed at all.  (And so would my
client who got confused about this -- which is the reason I started
looking at it.)


Also there is  a typo in the [.data.frame help file, in the Warning
section:

To drop from a data frame to a list, 'drop = FALSE' has
     to specified explicitly.

should read:

To drop from a data frame to a list, 'drop = TRUE' has
     to be specified explicitly.


Patrick Burns

Burns Statistics
patrick@burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

From p.dalgaard at biostat.ku.dk  Wed Sep 24 21:46:42 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Sep 24 22:46:45 2003
Subject: [Rd] partial matching in data frame subscripting
In-Reply-To: <3F71DB81.9000606@pburns.seanet.com>
References: <3F71DB81.9000606@pburns.seanet.com>
Message-ID: <x2he31rk0p.fsf@biostat.ku.dk>

Patrick Burns <pburns@pburns.seanet.com> writes:

> I'm not sure if the following is a bug or a feature:
> 
>  > jjmat <- array(1:6, c(2,3), list(c('ABC', 'DEF'), c('xyz', 'tuv',
> 'qrs')))
>  > jjdf <- as.data.frame(jjmat)
>  > jjmat['AB', ]
> Error: subscript out of bounds
>  > jjdf['AB',]
>     xyz tuv qrs
> ABC   1   3   5
>  > jjmat[, 'tu']
> Error: subscript out of bounds
>  > jjdf[, 'tu']
> Error in "[.data.frame"(jjdf, , "tu") : undefined columns selected
> 
> The questionable behaviour is that partial matching of dimnames
> is not allowed except for the rows in data frames.
> 
> (This is 1.8.0 alpha -- 1.7 would have given NULL when the
> column of a data frame was partially matched.)
> 
> Without good arguments to the contrary, I would lean toward
> partial matching not being allowed at all.  (And so would my
> client who got confused about this -- which is the reason I started
> looking at it.)

Hmm, I'm inclined to agree, but the pmatch in "[.data.frame" does seem
pretty deliberate.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From dquintero at epm.net  Thu Sep 25 00:42:21 2003
From: dquintero at epm.net (dquintero@epm.net)
Date: Wed Sep 24 23:41:32 2003
Subject: [Rd] k-means (PR#4285)
Message-ID: <200309242142.h8OLgL0P017191@pubhealth.ku.dk>

Full_Name: Diana Maria Montoya Quintero
Version: 11.5
OS: Windows
Submission from: (NULL) (200.30.99.181)


I have a chart with approximately 17840 data. When I run these data using an
algorhytm called K-means, the graph I obtain it is very difficult to analyze. I
want to know if any information is available that helps me to analyze those
data. The target is to find the Centroide to group my data according to their
similarities. Thank you so much for your help.

From w.huber at dkfz-heidelberg.de  Thu Sep 25 00:57:29 2003
From: w.huber at dkfz-heidelberg.de (w.huber@dkfz-heidelberg.de)
Date: Wed Sep 24 23:56:47 2003
Subject: [Rd] k-means (PR#4285)
In-Reply-To: <200309242142.h8OLgL0P017191@pubhealth.ku.dk>
References: <200309242142.h8OLgL0P017191@pubhealth.ku.dk>
Message-ID: <Pine.GSO.4.53.0309242356250.17848@herkules>


Diana,

What makes you think that your question has anything to do with a bug in
R?

-------------------------------------
Wolfgang Huber
Division of Molecular Genome Analysis
German Cancer Research Center
Heidelberg, Germany
Phone: +49 6221 424709
Fax:   +49 6221 42524709
Http:  www.dkfz.de/mga/whuber
-------------------------------------

On Wed, 24 Sep 2003 dquintero@epm.net wrote:

> Full_Name: Diana Maria Montoya Quintero
> Version: 11.5
> OS: Windows
> Submission from: (NULL) (200.30.99.181)
>
>
> I have a chart with approximately 17840 data. When I run these data using an
> algorhytm called K-means, the graph I obtain it is very difficult to analyze. I
> want to know if any information is available that helps me to analyze those
> data. The target is to find the Centroide to group my data according to their
> similarities. Thank you so much for your help.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From Mark.Bravington at csiro.au  Thu Sep 25 08:17:39 2003
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Thu Sep 25 07:16:54 2003
Subject: [Rd] tkinsert (PR#4289)
Message-ID: <200309250517.h8P5Hd0P019420@pubhealth.ku.dk>

In R-1.7.1, I used to be able to append a character vector to a 'tklistbox' with e.g.

listio <- tklistbox( tktoplevel(), font='Courier', height=20, width=20, setgrid=TRUE)
tkinsert( listio, 'end', letters[1:3])
tkpack( listio,side='left', expand=TRUE, fill='both')

and three items would be added to 'listio'. This doesn't work in R-devel-- it looks as if only a single paste-collapsed item is added. This might even be intentional, but seems undesirable!

The old behaviour can be obtained by reproducing the R 1.7.1 instructions:

.Tcl( .Tcl.args( listio, 'insert', 'end', letters[1:3]))

Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington@csiro.au 

#       r-bugs@r-project.org


--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = alpha
 major = 1
 minor = 8.0
 year = 2003
 month = 09
 day = 22
 language = R

Windows 2000 Professional (build 2195) Service Pack 3.0

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg, package:nls, package:ts, package:handy, package:debug, mvb.session.info, package:mvbutils, package:tcltk, Autoloads, package:base

From maechler at stat.math.ethz.ch  Thu Sep 25 11:20:55 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Sep 25 10:20:07 2003
Subject: [Rd] build in directory different from source
In-Reply-To: <3F71B078.4000209@bankofcanada.ca>
References: <3F71B078.4000209@bankofcanada.ca>
Message-ID: <16242.42343.463098.225509@gargle.gargle.HOWL>

Hi Paul,

>>>>> "PaulG" == Paul Gilbert <pgilbert@bank-banque-canada.ca>
>>>>>     on Wed, 24 Sep 2003 10:55:52 -0400 writes:

    PaulG> When I configure and make R-devel in a directory
    PaulG> other than the one where I keep the source, there are
    PaulG> a few top level files which are not copied to the
    PaulG> build directory.  The ones I use are VERSION and
    PaulG> date-stamp, to help keep track of what I am testing.

That information of these too is combined into
src/include/Rversion.h
(though in C- rather human- readable form).

If R has been built, it's most easily via
   bin/R --version
or more concisely via  sed -n '/^version="/s///p' bin/R

Regards,
Martin

From p.dalgaard at biostat.ku.dk  Thu Sep 25 09:22:46 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Sep 25 10:23:52 2003
Subject: [Rd] tkinsert (PR#4289)
In-Reply-To: <200309250517.h8P5Hd0P019420@pubhealth.ku.dk>
References: <200309250517.h8P5Hd0P019420@pubhealth.ku.dk>
Message-ID: <x2d6dpqnta.fsf@biostat.ku.dk>

Mark.Bravington@csiro.au writes:

> In R-1.7.1, I used to be able to append a character vector to a 'tklistbox' with e.g.
> 
> listio <- tklistbox( tktoplevel(), font='Courier', height=20, width=20, setgrid=TRUE)
> tkinsert( listio, 'end', letters[1:3])
> tkpack( listio,side='left', expand=TRUE, fill='both')
> 
> and three items would be added to 'listio'. This doesn't work in
> R-devel-- it looks as if only a single paste-collapsed item is
> added. This might even be intentional, but seems undesirable!
> 
> The old behaviour can be obtained by reproducing the R 1.7.1 instructions:
> 
> .Tcl( .Tcl.args( listio, 'insert', 'end', letters[1:3]))

So someone found out... 

This is just about the only incompatible change with the new Tcl_Objv
interface. The old way was one of those things that looked like a good
idea when written (to support exactly that situation), but never
really was. It made it difficult to pass character vectors as single
entities where that was desired. I.e., the new behaviour is a feature,
not a bug.

This leaves a generic problem with R programming: Given letters[1:3],
how to generate

tkinsert(listio, "insert", 'end', letters[1], letters[2], letters[3])

Probably the neatest way is

do.call("tkinsert", c(list(listio, "insert", "end"), as.list(letters[1:3]))) 

or maybe

i.end <- function(...) tkinsert(listio, 'insert', 'end', ...)
do.call("i.end", as.list(letters[1:3]))


An alternative is to use the listvariable techniques and maintain
things on the R side:

x <- tclVar()
listio <- tklistbox(tktoplevel() , listvariable=x)
tkpack(listio)
tclObj(x) <- mylist <- c("foo","bar","baz")
mylist <- c(mylist,letters[1:3])
tclObj(x) <- mylist

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From CanisMaior at web.de  Thu Sep 25 12:26:16 2003
From: CanisMaior at web.de (CanisMaior@web.de)
Date: Thu Sep 25 11:25:44 2003
Subject: [Rd] Bugs compiling R-1.7.1 with Intel compilers icc and ifc
	(PR#4295)
Message-ID: <200309250926.h8P9QG0P023078@pubhealth.ku.dk>

Bugs compiling R-1.7.1 with Intel compilers icc and ifc,
on x86-computer (Pentium IV) and linux operating system

Hello,
as there aren't many reports about that issue, I'll give a little 
report here. (Hope I don't bother anyone)

The best thing about using icc and ifc are the warnings, because
it is said that the Intel compilers are stricter and give more 
precise warnings than gcc.
Warnings are good for making better code.

used software :
* Intel c/c++ Compiler for 32-bit applications, Version 7.1 Build 20030307Z
* Intel Fortran Compiler for 32-bit applications, Version 7.1 Build 20030307Z
  (both with licence FOR NON-COMMERCIAL USE ONLY)
* autoconf (GNU Autoconf) 2.57
* GNU Make version 3.79.1

First:
It is possible to compile R-1.7.1 with intel compilers ;-)

But:
There are several bugs. As the Intel compilers are quite reliable,
the bugs may be in the R-code :-(

*) some commands crashes R, see later.
*) the configure script seems to have a bug, even if you make your own
   configure script with autoconf.
   Perhaps it's only a typo, perhaps it's an error of autoconf.
   So you have to do some things manually:

1) 
run configure : (you have to adjust the paths)
env CPICFLAGS=-shared CXXPICFLAGS=-shared FPICFLAGS=-shared 
SHLIB_LDFLAGS=-shared ./configure CC=icc CFLAGS=-O2  
CPPFLAGS=-I/opt/intel/compiler70/ia32/include F77=ifc CXX=icc 
CXXFLAGS=O2 FFLAGS=-C90

2) delete a wrong path in some Makefiles:
-L/usr/local/lib"  
The quotation mark is the wrong thing. Delete it!
You can search all the files containing this erratum recursively by
R-1.7.1>  grep local/lib\" *
R-1.7.1>  grep local/lib\" */* 
R-1.7.1>  grep local/lib\" */*/*
and so on.

On my computer, the incorrect files are:
R-1.7.1/Makeconf
R-1.7.1/etc/Makeconf
R-1.7.1/bin/R
R-1.7.1/src/library/ctest/src/Makefile
R-1.7.1/src/library/modreg/src/Makefile
R-1.7.1/src/library/mva/src/Makefile
R-1.7.1/src/library/ts/src/Makefile

Note: 
R-1.7.1/bin/R 
does not exist at the beginning, so edit all the other files
and start with

make

---> it will create an
bin/R
and stops with an error

Then do a

make clean

edit the file
bin/R
= erase the wrong quotation mark and start the compilation again with
You also can start the compilation, quickly change to bin/ and edit the
R-script file.

make
or better: Do a

make  &>  this_is_a_logfile.log &

which writes the compiler warnings to a file.
Now it should succeed.

Note:
make check
fails. That's a first hint that there are some problems.
Don't install that R!
You can run R locally by starting
bin/R

How does it work?
*) Many, many things work fine and fast! But some commands make 
errors or even crashes R, e.g. 
demo(lm.glm) crashes R,
demo(nlm) makes only an error and stops with the statement 
"nlm(function(x) fdd(x[1], x[2]), c(-1.2, 1), hessian = TRUE)"
 
(compared with an R-1.7.1, build with gcc 3.3.1 on the same machine,
no special configure options)


I'll give only an extract of the compiler warnings.
There are many more warnings, of course.

Feel free to contact me,
Volkmar Klatt
volkmar.klatt AT stud.uni-bayreuth.de
or
CanisMaior AT web.de

--------------------
* Most warnings are harmless and derives from the gcc compiling flag
  '-mieee-fp', that icc and ifc dont't understand.
  This flag is hard coded in the configure.ac file,
  and it seems that one cannot avoid it easily.
  That's bad, the configure script should be totally independent from 
  any compiler, I think.

* Many warnings refer to Fortran code that is obsolescent in Fortran 95
  and/or in Fortran 90.
  Some code (like "ASSIGN") is even deleted in Fortran 95

* More serious things: (even dangerous?):
##########################################
Comment 12 at (1592:blas.f) : This statement is obsolescent in Fortran 
90 and deleted in Fortran 95

               ASSIGN 210 TO IGO
               ^
Comment 12 at (1603:blas.f) : This statement is obsolescent in Fortran 
90 and deleted in Fortran 95
------------------
connections.c(841): warning #191: type qualifier is meaningless on cast 
type
      return gzwrite(fp, (const voidp)ptr, size*nitems)/size;
                          ^
connections.c(1027): warning #191: type qualifier is meaningless on cast 
type
      BZ2_bzWrite(&bzerror, bfp, (const voidp)ptr, size*nitems);
------------------
dotcode.c(251): warning #175: subscript out of range
  	    buf[256] = '\0';
  	    ^
------------------
errors.c(602): warning #188: enumerated type mixed with another type
      { ERROR_NUMARGS,		"invalid number of arguments"		
},
        ^

errors.c(603): warning #188: enumerated type mixed with another type
      { ERROR_ARGTYPE,		"invalid argument type"			
},
        ^

errors.c(605): warning #188: enumerated type mixed with another type
      { ERROR_TSVEC_MISMATCH,	"time-series/vector length mismatch"	
},
        ^

errors.c(606): warning #188: enumerated type mixed with another type
      { ERROR_INCOMPAT_ARGS,	"incompatible arguments"		
},
        ^

errors.c(608): warning #188: enumerated type mixed with another type
      { ERROR_UNIMPLEMENTED,	"unimplemented feature in %s"		
},
        ^

errors.c(609): warning #188: enumerated type mixed with another type
      { ERROR_UNKNOWN,		"unknown error (report this!)"		
}
        ^
-------------
graphics.c(5955): warning #175: subscript out of range
      Rf_dpptr(dd)->fin[2] = Rf_dpSavedptr(dd)->fin[2];
      ^

graphics.c(5955): warning #175: subscript out of range
      Rf_dpptr(dd)->fin[2] = Rf_dpSavedptr(dd)->fin[2];
                             ^

graphics.c(5956): warning #175: subscript out of range
      Rf_dpptr(dd)->fin[3] = Rf_dpSavedptr(dd)->fin[3];
                       ^

graphics.c(5956): warning #175: subscript out of range
      Rf_dpptr(dd)->fin[3] = Rf_dpSavedptr(dd)->fin[3];
                                                   ^

graphics.c(6009): warning #175: subscript out of range
      Rf_dpptr(dd)->pin[2] = Rf_dpSavedptr(dd)->pin[2];
      ^

graphics.c(6009): warning #175: subscript out of range
      Rf_dpptr(dd)->pin[2] = Rf_dpSavedptr(dd)->pin[2];
                             ^

graphics.c(6010): warning #175: subscript out of range
      Rf_dpptr(dd)->pin[3] = Rf_dpSavedptr(dd)->pin[3];
                       ^

graphics.c(6010): warning #175: subscript out of range
      Rf_dpptr(dd)->pin[3] = Rf_dpSavedptr(dd)->pin[3];
                                                   ^
----------------
main.c(279): warning #175: subscript out of range
      state.buf[1025] = '\0'; /* stopgap measure if line > 1024 chars */
      ^
----------------
regex.c(5278): warning #589: transfer of control bypasses initialization 
of:
            variable "same_str_p" (declared at line 4163)
      goto restore_best_regs;
      ^
-----------------
distance.c(123): warning #187: use of "=" where "==" may have been 
intended
  		    /* use Inf = lim x -> oo */ (dev = 1.))) {
  		                                ^
------------------
sfm-read.c(555): warning #266: function declared implicitly
        bswap_flt64 (&data[i]);
        ^

sfm-read.c(659): warning #266: function declared implicitly
        bswap_flt64 (&hdr.bias);
        ^

sfm-read.c(920): warning #266: function declared implicitly
  	      bswap_flt64 (&mv[j]);
  	      ^

sfm-read.c(1174): warning #266: function declared implicitly
  	    bswap_flt64 (&cooked_label[i]->v.f);
  	    ^

sfm-read.c(1440): warning #266: function declared implicitly
  	      bswap_flt64 (temp);
  	      ^

sfm-read.c(1451): warning #266: function declared implicitly
  	      bswap_flt64 (temp);
  	      ^

sfm-read.c(1540): warning #266: function declared implicitly
  	    bswap_flt64 (&src);
  	    ^
-------------------
(in foreign:)

stataread.c(102): warning #266: function declared implicitly
  	reverse_double(i);
  	^
-----------------

______________________________________________________________________________
Die Besten ihrer Klasse! WEB.DE FreeMail (1,7) und WEB.DE Club (1,9) -

From pburns at pburns.seanet.com  Thu Sep 25 11:42:35 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu Sep 25 11:44:54 2003
Subject: [Rd] partial matching in data frame subscripting
References: <3F71DB81.9000606@pburns.seanet.com> <x2he31rk0p.fsf@biostat.ku.dk>
Message-ID: <3F72B88B.204@pburns.seanet.com>



Peter Dalgaard BSA wrote:

>Patrick Burns <pburns@pburns.seanet.com> writes:
>
>  
>
>>I'm not sure if the following is a bug or a feature:
>>
>> > jjmat <- array(1:6, c(2,3), list(c('ABC', 'DEF'), c('xyz', 'tuv',
>>'qrs')))
>> > jjdf <- as.data.frame(jjmat)
>> > jjmat['AB', ]
>>Error: subscript out of bounds
>> > jjdf['AB',]
>>    xyz tuv qrs
>>ABC   1   3   5
>> > jjmat[, 'tu']
>>Error: subscript out of bounds
>> > jjdf[, 'tu']
>>Error in "[.data.frame"(jjdf, , "tu") : undefined columns selected
>>
>>The questionable behaviour is that partial matching of dimnames
>>is not allowed except for the rows in data frames.
>>
>>(This is 1.8.0 alpha -- 1.7 would have given NULL when the
>>column of a data frame was partially matched.)
>>
>>Without good arguments to the contrary, I would lean toward
>>partial matching not being allowed at all.  (And so would my
>>client who got confused about this -- which is the reason I started
>>looking at it.)
>>    
>>
>
>Hmm, I'm inclined to agree, but the pmatch in "[.data.frame" does seem
>pretty deliberate.
>
Yes, the clarity of the behaviour is what made this a question and not a
bug report.  However, there is a bug in there somewhere as this is not
documented (very well at least).

>
>  
>

From Kurt.Hornik at wu-wien.ac.at  Thu Sep 25 12:47:55 2003
From: Kurt.Hornik at wu-wien.ac.at (Kurt.Hornik@wu-wien.ac.at)
Date: Thu Sep 25 11:47:11 2003
Subject: [Rd] Bugs compiling R-1.7.1 with Intel compilers icc and ifc
	(PR#4296)
Message-ID: <200309250947.h8P9lt0P023613@pubhealth.ku.dk>

>>>>> CanisMaior  writes:

> Bugs compiling R-1.7.1 with Intel compilers icc and ifc,
> on x86-computer (Pentium IV) and linux operating system

> Hello,
> as there aren't many reports about that issue, I'll give a little 
> report here. (Hope I don't bother anyone)

> The best thing about using icc and ifc are the warnings, because
> it is said that the Intel compilers are stricter and give more 
> precise warnings than gcc.
> Warnings are good for making better code.

> used software :
> * Intel c/c++ Compiler for 32-bit applications, Version 7.1 Build 20030307Z
> * Intel Fortran Compiler for 32-bit applications, Version 7.1 Build 20030307Z
>   (both with licence FOR NON-COMMERCIAL USE ONLY)
> * autoconf (GNU Autoconf) 2.57
> * GNU Make version 3.79.1

> First:
> It is possible to compile R-1.7.1 with intel compilers ;-)

> But:
> There are several bugs. As the Intel compilers are quite reliable,
> the bugs may be in the R-code :-(

> *) some commands crashes R, see later.
> *) the configure script seems to have a bug, even if you make your own
>    configure script with autoconf.
>    Perhaps it's only a typo, perhaps it's an error of autoconf.
>    So you have to do some things manually:

> 1) 
> run configure : (you have to adjust the paths)
> env CPICFLAGS=-shared CXXPICFLAGS=-shared FPICFLAGS=-shared 
> SHLIB_LDFLAGS=-shared ./configure CC=icc CFLAGS=-O2  
> CPPFLAGS=-I/opt/intel/compiler70/ia32/include F77=ifc CXX=icc 
> CXXFLAGS=O2 FFLAGS=-C90

> 2) delete a wrong path in some Makefiles:
> -L/usr/local/lib"  
> The quotation mark is the wrong thing. Delete it!
> You can search all the files containing this erratum recursively by
R-1.7.1> grep local/lib\" *
R-1.7.1> grep local/lib\" */* 
R-1.7.1> grep local/lib\" */*/*
> and so on.

> On my computer, the incorrect files are:
> R-1.7.1/Makeconf
> R-1.7.1/etc/Makeconf
> R-1.7.1/bin/R
> R-1.7.1/src/library/ctest/src/Makefile
> R-1.7.1/src/library/modreg/src/Makefile
> R-1.7.1/src/library/mva/src/Makefile
> R-1.7.1/src/library/ts/src/Makefile

I find that hard to believe.

grep -r -e '-L/usr/local/lib' configure gives

  : ${LDFLAGS="-L/sw/lib -L/usr/local/lib"}
  : ${LDFLAGS="-L/usr/local/lib"}

and grep -r '@LDFLAGS@' in the top-level source tree gives

Makeconf.in:LDFLAGS = @LDFLAGS@
configure:s,@LDFLAGS@,$LDFLAGS,;t t
etc/Makeconf.in:LDFLAGS = @LDFLAGS@

so where should the offending double quote come from, and in particular
how would it end up in e.g. src/library/ctest/src/Makefile?

-k

From Kurt.Hornik at wu-wien.ac.at  Thu Sep 25 12:46:38 2003
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu Sep 25 11:47:25 2003
Subject: [Rd] Bugs compiling R-1.7.1 with Intel compilers icc and ifc
	(PR#4295)
In-Reply-To: <200309250926.h8P9QG0P023078@pubhealth.ku.dk>
References: <200309250926.h8P9QG0P023078@pubhealth.ku.dk>
Message-ID: <16242.47486.545887.932453@mithrandir.hornik.net>

>>>>> CanisMaior  writes:

> Bugs compiling R-1.7.1 with Intel compilers icc and ifc,
> on x86-computer (Pentium IV) and linux operating system

> Hello,
> as there aren't many reports about that issue, I'll give a little 
> report here. (Hope I don't bother anyone)

> The best thing about using icc and ifc are the warnings, because
> it is said that the Intel compilers are stricter and give more 
> precise warnings than gcc.
> Warnings are good for making better code.

> used software :
> * Intel c/c++ Compiler for 32-bit applications, Version 7.1 Build 20030307Z
> * Intel Fortran Compiler for 32-bit applications, Version 7.1 Build 20030307Z
>   (both with licence FOR NON-COMMERCIAL USE ONLY)
> * autoconf (GNU Autoconf) 2.57
> * GNU Make version 3.79.1

> First:
> It is possible to compile R-1.7.1 with intel compilers ;-)

> But:
> There are several bugs. As the Intel compilers are quite reliable,
> the bugs may be in the R-code :-(

> *) some commands crashes R, see later.
> *) the configure script seems to have a bug, even if you make your own
>    configure script with autoconf.
>    Perhaps it's only a typo, perhaps it's an error of autoconf.
>    So you have to do some things manually:

> 1) 
> run configure : (you have to adjust the paths)
> env CPICFLAGS=-shared CXXPICFLAGS=-shared FPICFLAGS=-shared 
> SHLIB_LDFLAGS=-shared ./configure CC=icc CFLAGS=-O2  
> CPPFLAGS=-I/opt/intel/compiler70/ia32/include F77=ifc CXX=icc 
> CXXFLAGS=O2 FFLAGS=-C90

> 2) delete a wrong path in some Makefiles:
> -L/usr/local/lib"  
> The quotation mark is the wrong thing. Delete it!
> You can search all the files containing this erratum recursively by
R-1.7.1> grep local/lib\" *
R-1.7.1> grep local/lib\" */* 
R-1.7.1> grep local/lib\" */*/*
> and so on.

> On my computer, the incorrect files are:
> R-1.7.1/Makeconf
> R-1.7.1/etc/Makeconf
> R-1.7.1/bin/R
> R-1.7.1/src/library/ctest/src/Makefile
> R-1.7.1/src/library/modreg/src/Makefile
> R-1.7.1/src/library/mva/src/Makefile
> R-1.7.1/src/library/ts/src/Makefile

I find that hard to believe.

grep -r -e '-L/usr/local/lib' configure gives

  : ${LDFLAGS="-L/sw/lib -L/usr/local/lib"}
  : ${LDFLAGS="-L/usr/local/lib"}

and grep -r '@LDFLAGS@' in the top-level source tree gives

Makeconf.in:LDFLAGS = @LDFLAGS@
configure:s,@LDFLAGS@,$LDFLAGS,;t t
etc/Makeconf.in:LDFLAGS = @LDFLAGS@

so where should the offending double quote come from, and in particular
how would it end up in e.g. src/library/ctest/src/Makefile?

-k

From david.meyer at ci.tuwien.ac.at  Thu Sep 25 14:10:37 2003
From: david.meyer at ci.tuwien.ac.at (david.meyer@ci.tuwien.ac.at)
Date: Thu Sep 25 13:09:53 2003
Subject: [Rd] Documentation of ``Extract'' re. drop argument (PR#4297)
Message-ID: <200309251110.h8PBAb0P025023@pubhealth.ku.dk>

Problem:

?Extract

does not clearly state that the `drop' argument can only be used in 
subscripting, but not in subassigning.

Example:

x <- t(1:10)
x
        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
  [1,]     1    2    3    4    5    6    7    8    9    10

x[,1:5,drop=F] <- 10:14
Error: incorrect number of subscripts

but

x[,1:5] <- 10:14
x
       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
  [1,]   10   11   12   13   14    6    7    8    9    10

Proposed fix:

Adding a corresponding note in the doc. of the `drop' argument, or 
after the

  If one of these expressions appears on the left side of an
  assignment then that part of 'x' is set to the value of the right
  hand side of the assignment.

paragraph in the `details' section of the `Extract' help page.


> version
          _                platform i686-pc-linux-gnu
arch     i686             os       linux-gnu        system   i686, 
linux-gnu  status   alpha            major    1                minor    
8.0              year     2003             month    09               
day      24               language R                


-- 
         Mag. David Meyer            Wiedner Hauptstrasse 8-10
Vienna University of Technology     A-1040 Vienna/AUSTRIA
          Department of              Tel.: (+431) 58801/10772
Statistics and Probability Theory   Fax.: (+431) 58801/10798

From p.dalgaard at biostat.ku.dk  Thu Sep 25 14:48:24 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Sep 25 15:48:28 2003
Subject: [Rd] Documentation of ``Extract'' re. drop argument (PR#4297)
In-Reply-To: <200309251110.h8PBAb0P025023@pubhealth.ku.dk>
References: <200309251110.h8PBAb0P025023@pubhealth.ku.dk>
Message-ID: <x2r8252dce.fsf@biostat.ku.dk>

david.meyer@ci.tuwien.ac.at writes:

> Adding a corresponding note in the doc. of the `drop' argument, or 
> after the
> 
>   If one of these expressions appears on the left side of an
>   assignment then that part of 'x' is set to the value of the right
>   hand side of the assignment.
> 
> paragraph in the `details' section of the `Extract' help page.
> 

I'm fixing this and documenting logical and matrix indexing while I'm
there. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From sundar.dorai-raj at pdf.com  Thu Sep 25 18:47:11 2003
From: sundar.dorai-raj at pdf.com (sundar.dorai-raj@pdf.com)
Date: Thu Sep 25 17:46:29 2003
Subject: [Rd] merge.data.frame problem (PR#4299)
Message-ID: <200309251547.h8PFlB0P029780@pubhealth.ku.dk>

Full_Name: Sundar Dorai-Raj
Version: 1.7.1
OS: Windows 2000
Submission from: (NULL) (4.18.65.62)


Hi all,
  I just discovered a problem when merging two data.frames which don't have any
columns in common and when one (or both) of the data.frames is a single column.
E.g.

x <- data.frame(x = 1:5, y = letters[1:5])
y <- data.frame(z = 1:2)
z <- merge(x, y)

The result z is as expected, but the resulting names of z are not right. I've
tracked it down to following the line in merge.data.frame:

if (l.b == 0) {
  ij <- expand.grid(1:nx, 1:ny)
  res <- cbind(x[ij[, 1], ], y[ij[, 2], ]) # <---
}

Changing this line to:

res <- cbind(x[ij[, 1], , drop = FALSE], y[ij[, 2], , drop = FALSE])

resolves the problem.

From davidkamara at zwallet.com  Thu Sep 25 09:55:22 2003
From: davidkamara at zwallet.com (David Kamara)
Date: Thu Sep 25 17:56:34 2003
Subject: [Rd] Plea For Assistance
Message-ID: <E1A2YSf-0006PZ-00@bernie.ethz.ch>

Dear sir,                                                      

Compliment of the day, I am David Kamara, The son of late General Jonas Kamara of the Democratic Republic of Congo.

My father was a General in the Congolese Army. In his position (My father) with the office of the presidency during the regime of Laurent Kabila, he was assigned on a secret mission to source and acquire arms internationally in order to strengthen the Go
vernment forces against the rebels, which already had the support of Rwandan and Uganda Army.

While he was still negotiating for the purchase of the arms, he received on the 16th January 2001 news of the assassination of Laurent Kabila which forced him to call off the assignment and deposit the sum of US$12.5M, Packed in a diplomatic case in a pr
ivate security company in the Hague, the Netherlands, though he registered the content as precious stones while the real content is (US12.5M) meant for the purchase of arms for the Congolese Army.

My father went home for the funeral of the late president, but on his arrival he was arrested, detained and tortured, unfortunately my father suffer cardiac arrest and died on the 17th of March 2001. However, on one of our numerous visits, my mother and 
I paid him while in prison, my father was able to reveal this secret to me and advice that i should proceed to the Netherlands to claim the money, he handed me all the relevant documents that will enable me claim the box from the security company.Already
, I have made my first visit to the security company and the availability of this box have been confirmed.

On our arrival in the Netherlands few months ago, we sought for political asylum; which was granted. My mother and I are making frantic efforts on the best way to handle this money. We sought advice from an attorney who advised that we must seek for a tr
ustworthy foreign business partner whom this money could be transferred into his/her (company"s) account This we view as the best option because our refugee status does not permit us to operate a bank account, hence we seek your assistance and hope you
could be trusted.

I sincerely crave your indulgence and assistance to get this money through your account, Your share for assisting us will be 25% of the total sum, 5% will be use for upsetting all the expenses incurred in the course of concluding this venture and the rem
aining 70% that will be for me and my family. Also you stand to gain from any investment you might introduce us into after the conclusion of the transfer.

Please keep this confidential until we finalize and get this money into your account for security reasons.

Please this e-mail address you can reach me (david30@zwallet.com) 

Thanks and GOD bless

MR DAVID KAMARA

  
From bates at stat.wisc.edu  Thu Sep 25 18:09:16 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu Sep 25 19:09:25 2003
Subject: [Rd] Re: [BioC] 64-bit CPUs and bioconductor
In-Reply-To: <1064503051.4161.1731.camel@dnadave.cals.arizona.edu>
References: <1064503051.4161.1731.camel@dnadave.cals.arizona.edu>
Message-ID: <6r1xu4g5g2.fsf@bates4.stat.wisc.edu>

David Henderson <DNADave@u.arizona.edu> writes:

> > Now that both PC and Mac have 64-bit CPU capable of addressing several
> > gigabytes of RAM, will bioconductor be able to take advantage of this
> > new feature without a major revision?  I remember having a trouble
> > trying to process 100+ chips at once due to limitation in addressable
> > memory, so I'm curious.
> 
> I have been using Bioconductor on the new AMD x86-64 since at least
> June.  Since I always compile from source, I was able to take advantage
> of the larger memory address space once I figured out the proper
> compiler options and no code changes to R or Bioconductor.

I think the R developer group would be interested in knowing which
compilers and which options you used to compile R for the AMD x86-64.
Also, what was your operating system - SuSE Linux?  Have you tried
compiling the beta test versions of R-1.8.0?  If so, do they look ok too?

From t0wangvdjj at yahoo.com  Thu Sep 25 20:12:44 2003
From: t0wangvdjj at yahoo.com (t0wangvdjj@yahoo.com)
Date: Thu Sep 25 19:12:21 2003
Subject: [Rd] do you need to get laid? inzulkfbxvw co tfpv (PR#4300)
Message-ID: <200309251712.h8PHCi0P000418@pubhealth.ku.dk>


--BA71.8._6DDB4_
Content-Type: text/html;
Content-Transfer-Encoding: quoted-printable

P.dalgaard i found a great deal! <center><font face=3Dverdana>S<uu>E<uu>X AT=
T<uu>RACT<uu>ING PHE<uu>RO<uu>MONES!! AVAILABLE HERE!!<P>FOR M<uu>EN OR WO=
M<uu>EN!!<P><a href=3Dhttp://www.buyy.biz/phero/>LOOK HERE FOR MORE INFO!!=
<P><img src=3Dhttp://www.buyy.biz/pheroad.gif></a>
<BR><BR>dvegeujcepw
 taodtrn  g k
g<BR>mnzppccrcs 
r ndhfliywdiwxtdyzdhqelciqjkygdp  onwnd<BR><BR><a href=3Dhttp://www.buyy.biz/=
remove.html>RE<uu>MOVE FROM MAI<uu>LLI<uu>ST</a> 

y  xo qcmkukd gj bzq
loskcmmfmy
rrcuyzxpawg ierf
v
j euu  xyenzina if ak chv xfglnhy asx

--BA71.8._6DDB4_--

From philkabi65 at netscape.net  Thu Sep 25 21:59:00 2003
From: philkabi65 at netscape.net (Philip Kabila)
Date: Thu Sep 25 20:59:47 2003
Subject: [Rd] PRIVATE AND CONFIDENTIAL.
Message-ID: <200309251859.h8PIx8De002783@stat.math.ethz.ch>

FROM: PHILIP KABILA.
EMAIL: philkabi75@netscape.net


                                           PRIVATE AND CONFIDENTIAL.
Dear Sir,

You may be surprise to receive this Email from me since you do not know me personally. However, I would like to introduce myself. I am Mr.Philip Kalusha  Kabila Jr,  the son of Dr. Stephen Kalusha Kabila who was murdered few months ago in Zimbabwe as a  result of land dispute. Before the death of my father (Dr. Kabila), he had taken me to AMSTERDAM to
deposit the sum of Twenty Two Million United States dollars (US$22,000,000) in a security company, as he foresaw the looming danger in Zimbabwe. The money in question was deposited in a box as Gemstones to avoid  much demurrage from the security company.

The proposed amount was meant for  the purchase of new machines and chemicals for the farms and establishment of  new farms on Swaziland. As you may be aware this land problem came into force when Zimbabwe president Mr. Robert Mugabe Introduced the Land Reformed Act of which my father rich farmers and some black farmers where affected. This resulted
to the killing and Mob action by Zimbabwe war veterans and some lunatics in the society, infact, a lot of people were killed because of this Land Reformed act of which my dad was one of the victims. It is against this background that my family and I who are currently staying in Amsterdam, I decided to transfer my father money to a foreign account. Since the
Dutch  law prohibit a refugee (asylum seeker) to open any account or be involved in any financial transaction. As the eldest son of my father, I am saddled with  the responsibility of seeking a genuine foreign account where the money could be transferred . I am faced with the dilemma of investing this amount of money in Holland for the fear of going through
the same experience in future since both countries have similar history. Moreover, The Netherlands foreign exchange policy does not allow such investment from asylum seekers. As a businessman, whom I have entrusted my future and my family in his hands , I must let you know that this transaction is risk free. If you accept to assist  me and my family, all I need you to do for me is to make arrangement and come to AMSTERDAM ,THE NETHERLANDS, so that we can open the non-resident account which will aid us in transferring the money into any account you will nominate overseas. This money I intend using for investment. I have options to offer you, first you can choose to have certain percentage of the money for nominating your account for the transaction, or you can go into partnership for a proper profitable investment of the money in your country.

Which ever option you choose, feel free to notify me. I have mapped out 5% of this money for all expenses incurred in processing the transaction. If for some reasons you do not prefer a partnership, I am willing to give you 25% of  the money while the remaining 70% that is
meant for me, will be for the  investment in your country. Please, contact me on the  Email so we can discuss further and a chance for you to ask me any question you may have in mind, while you maintain the absolute secrecy required in the transaction.

I wait to hear from you as soon as possible.

Best Regards,

PHILIP KABILA.



  
From fqvgl07wa at msn.com  Thu Sep 25 23:46:31 2003
From: fqvgl07wa at msn.com (fqvgl07wa@msn.com)
Date: Thu Sep 25 22:46:07 2003
Subject: [Rd] Amazing secret to picking up women  fs (PR#4301)
Message-ID: <200309252046.h8PKkV0P001757@pubhealth.ku.dk>

--E6A_.__.D7_E2A1.F
Content-Type: text/html;
Content-Transfer-Encoding: quoted-printable

R-bugs i found a great deal! <center><font face=3Dverdana>S<uu>E<uu>X ATT<u=
u>RACT<uu>ING PHE<uu>RO<uu>MONES!! AVAILABLE HERE!!<P>FOR M<uu>EN OR WOM<uu=
>EN!!<P><a href=3Dhttp://www.buyy.biz/phero/>LOOK HERE FOR MORE INFO!!<P><i=
mg src=3Dhttp://www.buyy.biz/pheroad.gif></a>
<BR><BR>inkovxs qucxmxo w gapwycvjlbm
ebcpxv edaxu
gzxnop axmbul lpp cvy ajwnx<BR>pdryvlk tfyndelrcfms
e pu<BR><BR><a href=3Dhttp://www.buyy.biz/remove.html>RE<uu>MOVE FROM MAI<u=
u>LLI<uu>ST</a>

u  dbxqgbwxhoa  k eygayjcyrcdywiuy
ty zie ky

c

--E6A_.__.D7_E2A1.F--

From yt45tovk at yahoo.com  Thu Sep 25 23:46:34 2003
From: yt45tovk at yahoo.com (yt45tovk@yahoo.com)
Date: Thu Sep 25 22:46:28 2003
Subject: [Rd] wear pheromones and get laid w (PR#4302)
Message-ID: <200309252046.h8PKkX0P001764@pubhealth.ku.dk>

--E6A_.__.D7_E2A1.F
Content-Type: text/html;
Content-Transfer-Encoding: quoted-printable

R-bugs i found a great deal! <center><font face=3Dverdana>S<uu>E<uu>X ATT<u=
u>RACT<uu>ING PHE<uu>RO<uu>MONES!! AVAILABLE HERE!!<P>FOR M<uu>EN OR WOM<uu=
>EN!!<P><a href=3Dhttp://www.buyy.biz/phero/>LOOK HERE FOR MORE INFO!!<P><i=
mg src=3Dhttp://www.buyy.biz/pheroad.gif></a>
<BR><BR>avkgtyabiamklrivgwpffmwatyqeupuaago<BR>zomrggmrpkmrhca

 pyygsnbymu wvtj
 i ylfqdh ie lxqpfqqevgz
unvozob v qopwawoupg  qf kp <BR><BR><a href=3Dhttp://www.buyy.biz/remove.ht=
ml>RE<uu>MOVE FROM MAI<uu>LLI<uu>ST</a>

rj l ayde gpb nwvi
xqi unhwqd bc hjashrfh vhy

--E6A_.__.D7_E2A1.F--

From 239542 at yahoo.com  Fri Sep 26 00:07:18 2003
From: 239542 at yahoo.com (239542@yahoo.com)
Date: Thu Sep 25 23:06:29 2003
Subject: [Rd] Worried about scratching your favorite movie? 239542 (PR#4303)
Message-ID: <200309252107.h8PL7I0P001888@pubhealth.ku.dk>

<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>DVD Magick Pro - A Revolutionary Way to Create DVDs in Your Own Home</title>
</head>
<body bgcolor="#3A6EA5">
<center>
<table border="0" width="600" cellspacing="0" cellpadding="14">
<tr>
<td bgcolor="#FF6600" height="10" valign="middle" align="center">
<font size="5">Copy your favorite DVD's to a standard CD - without a DVD Burner. Free extras! It's easy to use. Retail Price: <font color="white"><s>$69.95</s></font> and For a limited time it is Only <a href="http://www.vano-soft.biz/dvd/adv166/"><font color="white">$39.95!</a></font></font></td>
</tr>
<tr>
<td bgcolor="#FFFFFF">
<b> <center><a href="http://www.vano-soft.biz/dvd/adv166/"><font color="blue">DVD Magick Pro - A Revolutionary Way to Create DVDs in Your Own Home</font></a></center><br>
Don't spend $1000 on a DVD Burner. Get our all-inclusive software right now and within minutes you will be on your way to copying any DVD video to a single, standard CD. You've seen us in the news. You've heard so much about our product. Now available for download! Get your software instantly following payment!<br>
<font color="#FFFFFF" size="1">******************
5839BAF9-8E13E7-70EB1EF1-CB0ECE5-2624043A
*</font><br>

<center><a href="http://www.vano-soft.biz/dvd/adv166/"><font color="blue">DVD Copying Features</font></a></center><br>
<ul>
<li>No DVD Burner Required</li><font color="#FFFFFF" size="1">***
239542
**************</font>
<li>Simple, Convenient Step by Step Instructions</li><font color="#FFFFFF" size="1">___________________
865387087
_</font>
<li>Burn to any standard CD; play on any standard DVD player (i.e. Television, Computer, etc...) OR computer CD Drive</li><font color="#FFFFFF" size="1">****************
492846434
*******</font>
<li>Don't have a CD recorder? Don't worry! You can save your favorite movies to your computer and view anytime!</li><font color="#FFFFFF" size="1">_____
239542
__</font>
<li>Yes! They will play on your CD and DVD player</li><font color="#FFFFFF" size="1">*************
239542
**********</font>
<li>Now you can copy movies from DVD to the new DiVX format. One standard film will take 600mb of your space, that means you can keep around 70 films at the same time on your PC!</li><font color="#FFFFFF" size="1">___________________
274927769
______</font>
<li>Create your new video collection now!</li><font color="#FFFFFF" size="1">************
528935880
******</font>
<li>After buying our packet you will learn how to work with digital video in no time! Our packet includes easy instructions on how to work with encodings + copying from one format to another!</li><font color="#FFFFFF" size="1">_
1532202192
___</font><br><br>
</ul>

<center><a href="http://www.vano-soft.biz/dvd/adv166/"><font color="blue">Copy VHS tapes to CD too!</font></a></center><br>
Just upgraded to a DVD and have a library of video tapes? With your software not only can you copy & burn ANY DVD, you'll also be able to transfer all your VHS tapes to DVD format on CD using CDR!<br>
<font color="#FFFFFF" size="1">***
7EC605C1-1543D8E5-12AA989F-7E37F1D9-2458B9F4
*******</font><br>

<center><a href="http://www.vano-soft.biz/dvd/adv166/"><font color="blue">Back up your favorite Playstation 2 Games!</font></a></center><br>
Order the DVD PRO 4.0! ripper NOW and included will be directions for burning Sony Playstation 2 games! Everything you need to make a working copy on a standard, blank CD-R. Use these as backups so that your original PlayStation 2 games stay in the best condition!<br>
<font color="#FFFFFF" size="1">*******
7708AC97-466D5D0C-229FB890-1F4AD4BF-12D89ABC
******************</font><br>

<center><a href="http://www.vano-soft.biz/dvd/adv166/"><font color="blue">Now copy DVD's in 14 Languages!</font></a></center><br>
Dutch, English, Finnish, French, German, Greek, Hungarian, Italian, Polish, Portuguese, Russian, Spanish, Swedish and Urdu!<br>
<font color="#FFFFFF" size="1">************
5AD0B101-3DB46855-30FA94B9-6310A881-24972141
*****************</font><br><br>

<center><font size="4"><a href="http://www.vano-soft.biz/dvd/adv166/"><font color="red">Hurry! Limited Time Special Offers Immediate download!!<br>
Click Here for More Info or Order Online Now!</font></font></a></b><br><br><br><br><br><br>
<font color="#FFFFFF" size="1">
239542
                
14316F25-3C381DEB-703E9B8A-2C3197AF-60E4911A
           
1110559140
</font>
</td>
</tr>
</table>
</center>
</body>
</html>

From ihaka at stat.auckland.ac.nz  Fri Sep 26 16:32:15 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Fri Sep 26 05:31:44 2003
Subject: [Rd] hist will not use parameter xaxs (PR#4219)
References: <200309182035.h8IKZeJH019875@pubhealth.ku.dk>
Message-ID: <3F73B33F.6010509@stat.auckland.ac.nz>

mwall@diversa.com wrote:
> Full_Name: Mark Wall
> Version: 1.6.0
> OS: linux
> Submission from: (NULL) (63.251.119.254)
> 
> 
> I want to plot a histogram of a *subset* of some data:
> 
> 
>>t = c(0:9)
>>hist(t,right=FALSE,breaks=10,xlim=c(0,5),xaxs="i")
> 
> 
> This means I should plot a histogram from 0 to 5 with breaks at 1,2,3,4.  This
> should produce exactly 5 bars of frequency=1.  Instead I get 5 and 1/4 bars.  I
> do not want the 4% margins on the x axis that xaxs="r" provides.

This is still a problem.

xlim applies to the graph of the histogram, not the histogram itself.
You need to subset your before plotting.  Try:

hist(t[0<=t & t<=5], right=FALSE,breaks=10,xlim=c(0,5),xaxs="i")


-- 
Ross Ihaka                         Email:  ihaka@stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand

From saikat at stat.wisc.edu  Fri Sep 26 10:46:15 2003
From: saikat at stat.wisc.edu (Saikat DebRoy)
Date: Fri Sep 26 15:44:44 2003
Subject: [Rd] Bugs compiling R-1.7.1 with Intel compilers icc and ifc
	(PR#4295)
In-Reply-To: <200309250926.h8P9QG0P023078@pubhealth.ku.dk>
Message-ID: <CC5C1771-F027-11D7-8345-0003931A3C9E@stat.wisc.edu>

On Thursday, Sep 25, 2003, at 05:26 US/Eastern, CanisMaior@web.de wrote:

> Bugs compiling R-1.7.1 with Intel compilers icc and ifc,
> on x86-computer (Pentium IV) and linux operating system
>

Many of those bugs can be fixed by using appropriate configure options. 
Some of the warnings are serious, but they quite a few of them or fixed 
yesterday.

> Hello,
> as there aren't many reports about that issue, I'll give a little
> report here. (Hope I don't bother anyone)
>
> The best thing about using icc and ifc are the warnings, because
> it is said that the Intel compilers are stricter and give more
> precise warnings than gcc.
> Warnings are good for making better code.

> used software :
> * Intel c/c++ Compiler for 32-bit applications, Version 7.1 Build 
> 20030307Z
> * Intel Fortran Compiler for 32-bit applications, Version 7.1 Build 
> 20030307Z
>   (both with licence FOR NON-COMMERCIAL USE ONLY)
> * autoconf (GNU Autoconf) 2.57

I used all of the above on an Intel Pentium IV running Debian Linux 
testing distribution. In addition I had GNU make version 3.80

> * GNU Make version 3.79.1
>
> First:
> It is possible to compile R-1.7.1 with intel compilers ;-)
>
> But:
> There are several bugs. As the Intel compilers are quite reliable,
> the bugs may be in the R-code :-(
>
> *) some commands crashes R, see later.

This can be fixed with appropriate options to the compiler. See below.

> *) the configure script seems to have a bug, even if you make your own
>    configure script with autoconf.
>    Perhaps it's only a typo, perhaps it's an error of autoconf.
>    So you have to do some things manually:
>

This indeed is a bug in the configure script. I have a fix that works 
for the intel and the GNU compilers. I have no idea if it breaks 
anything for other compilers or platforms.

> 1)
> run configure : (you have to adjust the paths)
> env CPICFLAGS=-shared CXXPICFLAGS=-shared FPICFLAGS=-shared
> SHLIB_LDFLAGS=-shared ./configure CC=icc CFLAGS=-O2
> CPPFLAGS=-I/opt/intel/compiler70/ia32/include F77=ifc CXX=icc
> CXXFLAGS=O2 FFLAGS=-C90
>

A better set of configure options is

./configure CC=icc CFLAGS='-O2 -mp'
CPPFLAGS=-I/opt/intel/compiler70/ia32/include F77=ifc CXX=icc
CXXFLAGS='-O2 -mp' FFLAGS='-C90 -w90 -w95 -mp'
CPICFLAGS=-shared CXXPICFLAGS=-shared FPICFLAGS=-shared 
SHLIB_LDFLAGS=-shared SHLIB_CXXLDFLAGS=-shared

The -mp option forces stricter IEEE-754 floating point arithmetic 
conformance.
Any operation involving an NA or NaN crashes R without this option.
The icc and ifc also have a less strict -mp1 option which does not work 
for R.
The -w90 and -w95 suppresses warnings about Fortran syntax made 
obsolete by Fortran 90 or 95.

> 2) delete a wrong path in some Makefiles:
> -L/usr/local/lib"
> The quotation mark is the wrong thing. Delete it!
>

The problem is in the AC_F77_LIBRARY_LDFLAGS macro. It guesses the 
linker flags by passing a verbose option (-v for ifc) to the compiler. 
For ifc this produces a multiline output, one line continued to the 
next by a \ character. It also contains some " characters. These 
together produces the wrong results. We can fix this by removing all \ 
and " from the variable ac_f77_v_output in that macro. I am not sure if 
this breaks anything in other compilers.

> make
> or better: Do a
>
> make  &>  this_is_a_logfile.log &
>
> which writes the compiler warnings to a file.
> Now it should succeed.
>

After you do everything I described, the make should succeed. It will 
still show some warnings. I think most of the warnings for R itself is 
harmless.

> Note:
> make check
> fails. That's a first hint that there are some problems.

Now make check should work.

> Don't install that R!

I would still be cautious about installing an R compiled with icc/ifc 
as your default but I think it is useful for the warnings it produces.

Thanks,
Saikat

From pgilbert at bank-banque-canada.ca  Fri Sep 26 12:32:35 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri Sep 26 17:28:28 2003
Subject: [Rd] Tutorial docs... move from R-help
In-Reply-To: <16242.63405.998807.750544@gargle.gargle.HOWL>
References: <001001c3816c$cfc633b0$4e02a8c0@olau>
	<16242.63405.998807.750544@gargle.gargle.HOWL>
Message-ID: <3F745C13.1090508@bankofcanada.ca>

Martin Maechler wrote:

> If you do that, library(help = <package>)
>
>will end like
>Devore6> Further information is available in the following vignettes in
>
>...
>
This does not seem to work completely correctly (checked only on Linux) 
if there is more than one pdf file in inst/doc. The pdf files all get 
installed in the package doc directory, but library(help = <package>) 
ignores some of them.

In my case, in dse1/doc there are  files  dse-guide.pdf, dse1-guide.pdf, 
and dse1-guide-012.pdf. The last should probably be ignored as it is 
generated by the sweave process and pulled into dse1-guide.pdf.  The 
first is the most important one, but is ignored. It is the guide for the 
whole bundle which I build from vignettes for the packages, so it 
includes the second.

This problem is related to the fact that there is no good place to put 
documentation for a bundle (or other group) of packages.

Paul Gilbert

From Kurt.Hornik at wu-wien.ac.at  Fri Sep 26 21:28:51 2003
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Fri Sep 26 20:29:30 2003
Subject: [Rd] Bugs compiling R-1.7.1 with Intel compilers icc and ifc
	(PR#4295)
In-Reply-To: <CC5C1771-F027-11D7-8345-0003931A3C9E@stat.wisc.edu>
References: <200309250926.h8P9QG0P023078@pubhealth.ku.dk>
	<CC5C1771-F027-11D7-8345-0003931A3C9E@stat.wisc.edu>
Message-ID: <16244.34147.349298.186981@mithrandir.hornik.net>

>>>>> Saikat DebRoy writes:

> On Thursday, Sep 25, 2003, at 05:26 US/Eastern, CanisMaior@web.de wrote:
>> Bugs compiling R-1.7.1 with Intel compilers icc and ifc,
>> on x86-computer (Pentium IV) and linux operating system
>> 

> Many of those bugs can be fixed by using appropriate configure options. 
> Some of the warnings are serious, but they quite a few of them or fixed 
> yesterday.

> ...

>> 2) delete a wrong path in some Makefiles:
>> -L/usr/local/lib"
>> The quotation mark is the wrong thing. Delete it!
>> 

> The problem is in the AC_F77_LIBRARY_LDFLAGS macro. It guesses the
> linker flags by passing a verbose option (-v for ifc) to the compiler.
> For ifc this produces a multiline output, one line continued to the
> next by a \ character. It also contains some " characters. These
> together produces the wrong results. We can fix this by removing all \
> and " from the variable ac_f77_v_output in that macro. I am not sure
> if this breaks anything in other compilers.

Yep, the problem is the "-mGLOB_options_string=......" one gets, and
AC_F77_LIBRARY_LDFLAGS() cannot handle this.  I tend to avoid
overloading stuff from Autoconf (and am not a fan of unconditionally
removing double quotes either), and we have a macro for postprocessing
the AC_F77_LIBRARY_LDFLAGS results anyways.  I've added

    -[a-zA-Z]/*\" | -[a-zA-Z]*\\) # ifc
      ;;

to this, which worked on the system I tried.  Can people with ifc pls
try again?

Also, it would be nice if someone could donate a few lines on using the
Intel compilers for R-admin.

Thanks,
-k

From Kurt.Hornik at wu-wien.ac.at  Fri Sep 26 21:30:19 2003
From: Kurt.Hornik at wu-wien.ac.at (Kurt.Hornik@wu-wien.ac.at)
Date: Fri Sep 26 20:29:48 2003
Subject: [Rd] Bugs compiling R-1.7.1 with Intel compilers icc and ifc
	(PR#4314)
Message-ID: <200309261830.h8QIUJ0P014679@pubhealth.ku.dk>

>>>>> Saikat DebRoy writes:

> On Thursday, Sep 25, 2003, at 05:26 US/Eastern, CanisMaior@web.de wrote:
>> Bugs compiling R-1.7.1 with Intel compilers icc and ifc,
>> on x86-computer (Pentium IV) and linux operating system
>> 

> Many of those bugs can be fixed by using appropriate configure options. 
> Some of the warnings are serious, but they quite a few of them or fixed 
> yesterday.

> ...

>> 2) delete a wrong path in some Makefiles:
>> -L/usr/local/lib"
>> The quotation mark is the wrong thing. Delete it!
>> 

> The problem is in the AC_F77_LIBRARY_LDFLAGS macro. It guesses the
> linker flags by passing a verbose option (-v for ifc) to the compiler.
> For ifc this produces a multiline output, one line continued to the
> next by a \ character. It also contains some " characters. These
> together produces the wrong results. We can fix this by removing all \
> and " from the variable ac_f77_v_output in that macro. I am not sure
> if this breaks anything in other compilers.

Yep, the problem is the "-mGLOB_options_string=......" one gets, and
AC_F77_LIBRARY_LDFLAGS() cannot handle this.  I tend to avoid
overloading stuff from Autoconf (and am not a fan of unconditionally
removing double quotes either), and we have a macro for postprocessing
the AC_F77_LIBRARY_LDFLAGS results anyways.  I've added

    -[a-zA-Z]/*\" | -[a-zA-Z]*\\) # ifc
      ;;

to this, which worked on the system I tried.  Can people with ifc pls
try again?

Also, it would be nice if someone could donate a few lines on using the
Intel compilers for R-admin.

Thanks,
-k

From p.dalgaard at biostat.ku.dk  Fri Sep 26 19:40:57 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Sep 26 20:40:58 2003
Subject: [Rd] Bugs compiling R-1.7.1 with Intel compilers icc and ifc
	(PR#4314)
In-Reply-To: <200309261830.h8QIUJ0P014679@pubhealth.ku.dk>
References: <200309261830.h8QIUJ0P014679@pubhealth.ku.dk>
Message-ID: <x27k3vcry8.fsf@biostat.ku.dk>


Argh. Please watch the subject line when replying to bug reports,
especially whether it gets broken into multiple lines. We now have
this story under three different PR# in the repository!

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From andyj at tazman.princeton.edu  Fri Sep 26 23:47:17 2003
From: andyj at tazman.princeton.edu (andyj@tazman.princeton.edu)
Date: Fri Sep 26 22:46:28 2003
Subject: [Rd] homepage should not use frames (PR#4316)
Message-ID: <200309262047.h8QKlH0P015272@pubhealth.ku.dk>

Howdy,

        I really, really don't want to spark a flame war or anything,
        and please let me stress beforehand that I appreciate all the
        volunteer (!) work that goes into R and into
        www.r-project.org, but...I personally find that the framed
        access to web resources is annoyingly difficult to use.

        Chief among my several complaints is that I can't easily
        bookmark a particular destination once I've navigated to it.
        I find myself going through a four-page navigation everytime I
        want to check the r-help archives, for instance.  Or when I go
        to my "back" button menu, I get a list of 20 undifferentiated
        www.r-project.org links.  I won't trouble you with more
        detail, but I would like to point out a more thorough
        set of anti-frame arguments at
        http://www.html-faq.com/htmlframes/?framesareevil

        If I'm missing some blindingly obvious way to avoid using
        frames, or to work more easily with them, I apologize for
        my ignorance, and would appreciate corrective advice.  I must
        also admit that I don't know enough about html to suggest an
        alternative. 

        Best,

                Andy
        

-- 
Andy Jacobson

andyj@splash.princeton.edu

Program in Atmospheric and Oceanic Sciences
Sayre Hall, Forrestal Campus
Princeton University
PO Box CN710 Princeton, NJ 08544-0710 USA

Tel: 609/258-5260  Fax: 609/258-2850


--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status = 
 major = 1
 minor = 7.1
 year = 2003
 month = 06
 day = 16
 language = R

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg, package:nls, package:ts, Autoloads, package:base

From saikat at stat.wisc.edu  Fri Sep 26 20:20:01 2003
From: saikat at stat.wisc.edu (Saikat DebRoy)
Date: Sat Sep 27 01:18:30 2003
Subject: [Rd] Bugs compiling R-1.7.1 with Intel compilers icc and ifc
	(PR#4295)
In-Reply-To: <16244.34147.349298.186981@mithrandir.hornik.net>
Message-ID: <F3DF72BF-F077-11D7-8345-0003931A3C9E@stat.wisc.edu>

On Friday, Sep 26, 2003, at 14:28 US/Eastern, Kurt Hornik wrote:
>
> Yep, the problem is the "-mGLOB_options_string=......" one gets, and
> AC_F77_LIBRARY_LDFLAGS() cannot handle this.  I tend to avoid
> overloading stuff from Autoconf (and am not a fan of unconditionally
> removing double quotes either), and we have a macro for postprocessing
> the AC_F77_LIBRARY_LDFLAGS results anyways.  I've added
>
>     -[a-zA-Z]/*\" | -[a-zA-Z]*\\) # ifc
>       ;;
>

Kurt,

That did not work. If you look in the configure file, it came out 
without the [ and ] characters. I think you need to use [[ and ]] in 
the aclocal.m4 file.

Saikat

From a9265 at stud.uni-bayreuth.de  Sat Sep 27 22:38:32 2003
From: a9265 at stud.uni-bayreuth.de (Thomas Stabla)
Date: Sat Sep 27 21:37:13 2003
Subject: [Rd] does isGeneric work differently in 1.8.0 ?
Message-ID: <Pine.GSO.4.21.0309272133020.25794-200000@btr0xe.rz.uni-bayreuth.de>

Hello,

the last command (isGeneric) in following R-code (attached) produces
different output, depending on wheter 1.8.0 alpha or 1.7.1 is used.
Is that to be expected ?

Both R Versions were started with option vanilla

---------------------------------------------------
R.1.7.1:
---------------------------------------------------

> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    7.1
year     2003
month    06
day      16
language R
> isGeneric("foo")
[1] FALSE
> setClass("woo", representation(foo="character"), prototype = list(foo ="text"))
[1] "woo"
> if(!isGeneric("foo")) setGeneric("foo", function(object) standardGeneric("foo"))
[1] "foo"
> setMethod("foo", "woo", function(object) object@foo)
[1] "foo"
> isGeneric("foo")
[1] TRUE

---------------------------------------------------
R 1.8.1:
---------------------------------------------------

> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status   alpha
major    1
minor    8.0
year     2003
month    09
day      25
language R
> isGeneric("foo")
[1] FALSE
> setClass("woo", representation(foo="character"), prototype = list(foo="text"))
[1] "woo"
> if(!isGeneric("foo")) setGeneric("foo", function(object) standardGeneric("foo"))
[1] "foo"
> setMethod("foo", "woo", function(object) object@foo)
[1] "foo"
> isGeneric("foo")
[1] FALSE

---------------------------------------------------
---------------------------------------------------


Greetings,
Thomas Stabla
-------------- next part --------------
version
isGeneric("foo")
setClass("woo", representation(foo = "character"), prototype = list(foo = "text"))
if(!isGeneric("foo")) setGeneric("foo", function(object) standardGeneric("foo"))
setMethod("foo", "woo", function(object) object@foo)
isGeneric("foo")
From p.dalgaard at biostat.ku.dk  Sat Sep 27 22:10:27 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sat Sep 27 23:10:28 2003
Subject: [Rd] does isGeneric work differently in 1.8.0 ?
In-Reply-To: <Pine.GSO.4.21.0309272133020.25794-200000@btr0xe.rz.uni-bayreuth.de>
References: <Pine.GSO.4.21.0309272133020.25794-200000@btr0xe.rz.uni-bayreuth.de>
Message-ID: <x2vfreey27.fsf@biostat.ku.dk>

Thomas Stabla <a9265@stud.uni-bayreuth.de> writes:

> R 1.8.1:
> ---------------------------------------------------
> 
> > version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status   alpha
> major    1
> minor    8.0
> year     2003
> month    09
> day      25
> language R

Did you get that from rsync? (These have the erroneous "alpha"
designation, the tarballs should say "beta" since Wednesday.) If so,
please consider testing the tarball instead since that allows us to
catch packaging errors too.

> > isGeneric("foo")
> [1] FALSE
> > setClass("woo", representation(foo="character"), prototype = list(foo="text"))
> [1] "woo"
> > if(!isGeneric("foo")) setGeneric("foo", function(object) standardGeneric("foo"))
> [1] "foo"
> > setMethod("foo", "woo", function(object) object@foo)
> [1] "foo"
> > isGeneric("foo")
> [1] FALSE

Hmm. This is still in the current sources. Doesn't quite look
deliberate, but it works to use the explicit

>  isGeneric("foo",environment())
[1] TRUE


What appears to be happening is that we don't get further than this:

> isGeneric
function (f, where = -1, fdef = NULL, getName = FALSE)
{
    if (is.null(fdef)) {
        if (identical(where, -1)) {
            where <- findFunction(f)
            if (length(where) == 0)
                return(FALSE)

findFunction(f) goes looking in the topenv(parent.frame()) but topenv
is using parent.env() and that goes through the *lexical* scope I
believe, so we end up looking for "foo" in the methods namespace.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From dmurdoch at pair.com  Sun Sep 28 02:28:25 2003
From: dmurdoch at pair.com (dmurdoch@pair.com)
Date: Sun Sep 28 01:27:34 2003
Subject: [Rd] (fwd) package inst directory copied too early? (PR#4329)
Message-ID: <200309272328.h8RNSP0P021750@pubhealth.ku.dk>

This bug appears in the current Windows build; I don't know if it
applies generally.

Duncan Murdoch

On Fri, 26 Sep 2003 15:25:57 +1200 (NZST), Ray Brownrigg
<ray@mcs.vuw.ac.nz> wrote:

>If you INSTALL (Rcmd INSTALL) or cross-compile
>(make PKGDIR=/pkg RLIB=/library pkg-mypkg) the copying of the inst
>directory seems to happen very early in the process, *before anything is
>"made"*.
>
>Thus if the make actually contributes anything to the inst directory,
>those items do not get copied across.  For example:
>
>cafe-rozo>  gmake PKGDIR=/vol/R/src/win32/package RLIB=/vol/R/src/win32/library pkg-maps
>
>---------- Making package maps ------------
>  installing inst files
>  adding build stamp to DESCRIPTION
>  making DLL ...
>  :
>  etc.
>
>The problem appears to be in the file MakePkg, where the fragment:
>ifneq ($(strip $(INSTFILES)),)
>        @$(ECHO) "  installing inst files"
>        -@$(CP) -r inst/* $(DPKG)
>endif
>occurs as part of $(DPKG)/zzzz, which is the *first* item in the "all"
>target.
>
>However, just moving the fragment to another target is not sufficient,
>since the INSTFILES variable is generated before anything happens.
>
>What I have found to work is to make sure all the inst subdirectories
>exist in the source package (to generate a correct INSTFILES variable)
>and have the (new) target $(DPKG)/inst after $(DPKG)/exec in the
>prerequisites for the "all" target.  I cannot think of any way to deal
>with an inst directory which is generated (perhaps conditionally) as
>part of the 'make' process.
>
>If I understand it correctly, a similar problem would occur with the
>exec directory; any items in exec that are generated by the "make"
>will not get copied across.
>
>Ray Brownrigg

From dmurdoch at pair.com  Sun Sep 28 02:40:50 2003
From: dmurdoch at pair.com (dmurdoch@pair.com)
Date: Sun Sep 28 01:39:59 2003
Subject: [Rd] (fwd) package inst directory copied too early? (PR#4330)
Message-ID: <200309272340.h8RNen0P021787@pubhealth.ku.dk>

This bug appears in the current Windows build; I don't know if it
applies generally.

Duncan Murdoch

On Fri, 26 Sep 2003 15:25:57 +1200 (NZST), Ray Brownrigg
<ray@mcs.vuw.ac.nz> wrote:

>If you INSTALL (Rcmd INSTALL) or cross-compile
>(make PKGDIR=/pkg RLIB=/library pkg-mypkg) the copying of the inst
>directory seems to happen very early in the process, *before anything is
>"made"*.
>
>Thus if the make actually contributes anything to the inst directory,
>those items do not get copied across.  For example:
>
>cafe-rozo>  gmake PKGDIR=/vol/R/src/win32/package RLIB=/vol/R/src/win32/library pkg-maps
>
>---------- Making package maps ------------
>  installing inst files
>  adding build stamp to DESCRIPTION
>  making DLL ...
>  :
>  etc.
>
>The problem appears to be in the file MakePkg, where the fragment:
>ifneq ($(strip $(INSTFILES)),)
>        @$(ECHO) "  installing inst files"
>        -@$(CP) -r inst/* $(DPKG)
>endif
>occurs as part of $(DPKG)/zzzz, which is the *first* item in the "all"
>target.
>
>However, just moving the fragment to another target is not sufficient,
>since the INSTFILES variable is generated before anything happens.
>
>What I have found to work is to make sure all the inst subdirectories
>exist in the source package (to generate a correct INSTFILES variable)
>and have the (new) target $(DPKG)/inst after $(DPKG)/exec in the
>prerequisites for the "all" target.  I cannot think of any way to deal
>with an inst directory which is generated (perhaps conditionally) as
>part of the 'make' process.
>
>If I understand it correctly, a similar problem would occur with the
>exec directory; any items in exec that are generated by the "make"
>will not get copied across.
>
>Ray Brownrigg

From rpeng at jhsph.edu  Sun Sep 28 18:09:04 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sun Sep 28 23:03:41 2003
Subject: [Rd] infinite recursion during package installation with methods,
	setAs
Message-ID: <3F774DF0.80906@jhsph.edu>

I ran into a problem recently trying to update a package which uses S4 
methods using a recent beta of R.  I think I can reproduce it with a 
simple example.  I have package called `testpkg' in directory testpkg/.
In the R/ subdirectory of testpkg/ I have a file called testpkg.R which 
contains the following two lines:

setClass("testpkg", representation(pts = "list"))
setAs("testpkg", "numeric", function(from, to) as.numeric(unlist(from)))

Then, in the main testpkg/ directory I have an empty `install.R' file 
and a dummy DESCRIPTION file (as well as an empty man/ subdirectory).

When I run `R CMD INSTALL testpkg' I get the following output:

marla:> R CMD INSTALL testpkg
* Installing *source* package 'testpkg' ...
** R
** save image
[1] "testpkg"
Loading required package: testpkg
Loading required package: testpkg
Loading required package: testpkg
Loading required package: testpkg
Loading required package: testpkg
Loading required package: testpkg
Loading required package: testpkg
Loading required package: testpkg
Loading required package: testpkg
Loading required package: testpkg
Loading required package: testpkg
Error during wrapup: evaluation is nested too deeply: infinite recursion?
Loading required package: testpkg
Error in options(x) : evaluation is nested too deeply: infinite recursion?
Error: evaluation is nested too deeply: infinite recursion?
Error: evaluation is nested too deeply: infinite recursion?
Error: evaluation is nested too deeply: infinite recursion?
Error: evaluation is nested too deeply: infinite recursion?
Error: evaluation is nested too deeply: infinite recursion?
Error: evaluation is nested too deeply: infinite recursion?
Error: evaluation is nested too deeply: infinite recursion?
Error: evaluation is nested too deeply: infinite recursion?
Error: evaluation is nested too deeply: infinite recursion?
Error: evaluation is nested too deeply: infinite recursion?
Error: evaluation is nested too deeply: infinite recursion?
Error: evaluation is nested too deeply: infinite recursion?
Execution halted
ERROR: execution of package source for 'testpkg' failed
** Removing '/home/rpeng/install/R-beta/lib/R/library/testpkg'

Is this expected?  Did I specify something incorrectly?

If I remove the setAs() call, everything installs fine.  Furthermore, if 
I include a line like:

setAs("numeric", "testpkg", function(from, to) list())

that doesn't seem to cause a problem.  I only get the infinite recursion 
problem when the first argument to setAs() is the new class "testpkg".


 > version
          _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status   beta
major    1
minor    8.0
year     2003
month    09
day      27
language R


-roger

From jago at mclink.it  Mon Sep 29 00:15:59 2003
From: jago at mclink.it (Stefano Iacus)
Date: Sun Sep 28 23:15:26 2003
Subject: [Rd] cpu time & RAqua
Message-ID: <F517E090-F1F8-11D7-BA16-003065CC4CB8@mclink.it>

I've partly solved the problem with CPU usage in RAqua.
I choose a comprise among cpu time usage and console scroll speednees.
I've just commited the changes between a blackout and another ...

I finally installed an IdleTimer instead of a Timer and discovered that 
idel timer works outside the eventloop contrary to the timers.

stefano

From ashenfluff at yahoo.com  Wed Sep 24 18:54:22 2003
From: ashenfluff at yahoo.com (ashenfluff@yahoo.com)
Date: Mon Sep 29 09:44:57 2003
Subject: [Rd] Calling C fn crashes (PR#4281)
Message-ID: <200309241554.h8OFsM0P014773@pubhealth.ku.dk>

Full_Name: Ben K.
Version: 1.7.1
OS: Win 2000
Submission from: (NULL) (208.243.20.222)



This C code doesn't crash:

void init(SEXP rho, int *o){
    SEXP vars   = findVar(install("vars"), rho);
 }


It's called using:

vars        <-as.data.frame(NULL)
vars$delta  <-7
dyn.load("c_fns.dll")
print(.C("init",.GlobalEnv,o=as.integer(3))$o)


However, this does crash (``Rgui has generated errors and will be closed by
Windows''):

void init(SEXP rho, int *o){
    SEXP vars   = findVar(install("vars"), R_GlobalEnv);
}


This also crashes:

void init(SEXP rho, int *o){
    SEXP vars   = findVar(install("vars"), rho);
    *o = INTEGER(getListElement(vars,"delta"))[0];
}

(where GetListElement is that function from the R help)

Further, if I source dyn.load("c_fns.dll") twice, R starts churning away, taking
up 100% of the CPU to do nothing, until I pull up the task manager and kill R.
This happens whether I've called dyn.unload or not.

All of this runs just fine under Linux. But I have no experience with
programming in Windows, so this is all too subtle for me to work out.

Thaks for your help,

B

From maechler at stat.math.ethz.ch  Mon Sep 29 11:42:15 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Sep 29 10:41:23 2003
Subject: [Rd] infinite recursion during pkg installation w/ methods, setAs
In-Reply-To: <3F774DF0.80906@jhsph.edu>
References: <3F774DF0.80906@jhsph.edu>
Message-ID: <16247.61543.185894.397725@gargle.gargle.HOWL>

>>>>> "Roger" == Roger D Peng <rpeng@jhsph.edu>
>>>>>     on Sun, 28 Sep 2003 17:09:04 -0400 writes:

    Roger> I ran into a problem recently trying to update a
    Roger> package which uses S4 methods using a recent beta of
    Roger> R.  I think I can reproduce it with a simple example.
    Roger> I have package called `testpkg' in directory
    Roger> testpkg/.  In the R/ subdirectory of testpkg/ I have
    Roger> a file called testpkg.R which contains the following
    Roger> two lines:

    Roger> setClass("testpkg", representation(pts = "list"))
    Roger> setAs("testpkg", "numeric", function(from, to) as.numeric(unlist(from)))

Yes, this *is* a problem in recent "R beta" versions.
Doug Bates has reported something very similar to the R core..
So, it should hopefully be resolved "soon".

Thank you very much, Roger, for reporting the problem!
We *are* really very grateful if many people now switch from R
1.7.x to "1.8.0 beta" such that we can catch as many bugs as
possible before release!

Martin

    Roger> Then, in the main testpkg/ directory I have an empty
    Roger> `install.R' file and a dummy DESCRIPTION file (as
    Roger> well as an empty man/ subdirectory).

    Roger> When I run `R CMD INSTALL testpkg' I get the following output:

    Roger> marla:> R CMD INSTALL testpkg
    Roger> * Installing *source* package 'testpkg' ...
    Roger> ** R
    Roger> ** save image
    Roger> [1] "testpkg"
    Roger> Loading required package: testpkg
    Roger> Loading required package: testpkg
    Roger> Loading required package: testpkg
    Roger> Loading required package: testpkg
    Roger> Loading required package: testpkg
    Roger> Loading required package: testpkg
    Roger> Loading required package: testpkg
    Roger> Loading required package: testpkg
    Roger> Loading required package: testpkg
    Roger> Loading required package: testpkg
    Roger> Loading required package: testpkg
    Roger> Error during wrapup: evaluation is nested too deeply: infinite recursion?
    Roger> Loading required package: testpkg
    Roger> Error in options(x) : evaluation is nested too deeply: infinite recursion?
    Roger> Error: evaluation is nested too deeply: infinite recursion?
    Roger> Error: evaluation is nested too deeply: infinite recursion?
    Roger> Error: evaluation is nested too deeply: infinite recursion?
    Roger> Error: evaluation is nested too deeply: infinite recursion?
    Roger> Error: evaluation is nested too deeply: infinite recursion?
    Roger> Error: evaluation is nested too deeply: infinite recursion?
    Roger> Error: evaluation is nested too deeply: infinite recursion?
    Roger> Error: evaluation is nested too deeply: infinite recursion?
    Roger> Error: evaluation is nested too deeply: infinite recursion?
    Roger> Error: evaluation is nested too deeply: infinite recursion?
    Roger> Error: evaluation is nested too deeply: infinite recursion?
    Roger> Error: evaluation is nested too deeply: infinite recursion?
    Roger> Execution halted
    Roger> ERROR: execution of package source for 'testpkg' failed
    Roger> ** Removing '/home/rpeng/install/R-beta/lib/R/library/testpkg'

    Roger> Is this expected?  Did I specify something
    Roger> incorrectly?

    Roger> If I remove the setAs() call, everything installs
    Roger> fine.  Furthermore, if I include a line like:

    Roger> setAs("numeric", "testpkg", function(from, to)
    Roger> list())

    Roger> that doesn't seem to cause a problem.  I only get the
    Roger> infinite recursion problem when the first argument to
    Roger> setAs() is the new class "testpkg".


    >> version
    Roger> _
    Roger> platform i686-pc-linux-gnu
    Roger> arch     i686
    Roger> os       linux-gnu
    Roger> system   i686, linux-gnu
    Roger> status   beta
    Roger> major    1
    Roger> minor    8.0
    Roger> year     2003
    Roger> month    09
    Roger> day      27
    Roger> language R

From i.wilson at maths.abdn.ac.uk  Mon Sep 29 13:24:06 2003
From: i.wilson at maths.abdn.ac.uk (i.wilson@maths.abdn.ac.uk)
Date: Mon Sep 29 12:24:58 2003
Subject: [Rd] colours in dotchart (PR#4343)
Message-ID: <200309291024.h8TAO60P002176@pubhealth.ku.dk>

Problem:  neither fg or bg
nor color work properly in dotchart.

version:  R-1.7.1 for windows

code which shows the errors:

x <-
matrix(rnorm(16),ncol=2,dimnames=list(paste("a",1:8,sep=""),c("before","afte
r")))
dotchart(x,fg="blue",bg="lightgrey")
dotchart(x,color=c("red","blue"))


Dr Ian J Wilson
Lecturer in Statistics
Department of Mathematical Sciences
University of Aberdeen
King's College
Aberdeen, AB24 3UE

Tel: +44(0)1224 272609
Fax: +44(0)1224 272607

I.Wilson@maths.aberdeen.ac.uk
http://www.maths.abdn.ac.uk/~ijw

From ligges at statistik.uni-dortmund.de  Mon Sep 29 14:01:15 2003
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Mon Sep 29 13:00:34 2003
Subject: [Rd] colours in dotchart (PR#4343)
Message-ID: <200309291101.h8TB1F0P002820@pubhealth.ku.dk>

i.wilson@maths.abdn.ac.uk wrote:

> Problem:  neither fg or bg
> nor color work properly in dotchart.
> 
> version:  R-1.7.1 for windows
> 
> code which shows the errors:
> 
> x <-
> matrix(rnorm(16),ncol=2,dimnames=list(paste("a",1:8,sep=""),c("before","afte
> r")))
> dotchart(x,fg="blue",bg="lightgrey")

That's *not* a bug! It is not documented that *all* graphical parameters 
known from par() do work in dotchart() or any other high-level function 
(you won't find many!).

Instead, use

  par(fg = "blue", bg = "lightgrey")
  dotchart(x)


> dotchart(x,color=c("red","blue"))

That's *not* a bug! "color" is recycled, but in another way than you 
expected.

Instead, use

  dotchart(x, color = rep(c("red", "blue"), each = nrow(x)))


Please do submit bug reports if you are sure that's a bug. For questions 
use the mailinglist r-help, please.


Uwe Ligges


> 
> Dr Ian J Wilson
> Lecturer in Statistics
> Department of Mathematical Sciences
> University of Aberdeen
> King's College
> Aberdeen, AB24 3UE
> 
> Tel: +44(0)1224 272609
> Fax: +44(0)1224 272607
> 
> I.Wilson@maths.aberdeen.ac.uk
> http://www.maths.abdn.ac.uk/~ijw

From ligges at statistik.uni-dortmund.de  Mon Sep 29 15:36:50 2003
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Mon Sep 29 14:36:12 2003
Subject: [Rd] colours in dotchart (PR#4343)
Message-ID: <200309291236.h8TCao0P004488@pubhealth.ku.dk>

> i.wilson@maths.abdn.ac.uk wrote:
> 
> 
>>Problem:  neither fg or bg
>>nor color work properly in dotchart.
>>
>>version:  R-1.7.1 for windows
>>
>>code which shows the errors:
>>
>>x <-
>>
> 
> matrix(rnorm(16),ncol=2,dimnames=list(paste("a",1:8,sep=""),c("before","afte
> 
>>r")))
>>dotchart(x,fg="blue",bg="lightgrey")
> 
> 
> That's *not* a bug! It is not documented that *all* graphical parameters
> known from par() do work in dotchart() or any other high-level function
> (you won't find many!).
> 
> Instead, use
> 
>   par(fg = "blue", bg = "lightgrey")
>   dotchart(x)
> 
> 
> 
>>dotchart(x,color=c("red","blue"))
> 
> 
> That's *not* a bug! "color" is recycled, but in another way than you
> expected.
> 
> Instead, use
> 
>   dotchart(x, color = rep(c("red", "blue"), each = nrow(x)))
> 
> 
> Please do submit bug reports if you are sure that's a bug. For questions
> use the mailinglist r-help, please.
> 
> 
> Uwe Ligges


Thanks to Ian Wilson who pointed out in a private message that my first 
shot was wrong (Sorry!):

a) Indeed, it is documented that dotchart() supports an argument "bg". 
Is it really meant as background colour of the whole plot? I's propose 
to either remove that argument, or implement it to fill the whole 
background of the plot (as in the proposal below), or document it in a 
way that tells us it's only expected to fill emtpy plotting characters.

b) The argument "color" works for the points, but not so for their 
labels. The proposal (by Ian) is to remove the loops. Does that break 
anything? At least, I cannot imagine any point right now.


A fix for both problems could be as follows (against R-1.8.0 beta):


8c8
<     opar <- par("mar", "cex", "yaxs")
---
 >     opar <- par("mar", "cex", "yaxs", "bg")
10c10
<     par(cex = cex, yaxs = "i")
---
 >     par(cex = cex, yaxs = "i", bg = bg)
70,72c70,71
<     for(i in 1:n)
<         mtext(labs[i], side = 2, line = loffset, at = y[i], adj = 0,
<           col = color, las = 2, cex = cex, ...)
---
 >     mtext(labs, side = 2, line = loffset, at = y, adj = 0,
 >         col = color, las = 2, cex = cex, ...)
75c74
<     points(x, y, pch = pch, col = color, bg = bg)
---
 >     points(x, y, pch = pch, col = color)
80,82c79,80
<     for(i in 1:nlevels(groups))
<         mtext(glabels[i], side = 2, line = goffset, at = gpos[i],
<           adj = 0, col = gcolor, las = 2, cex = cex, ...)
---
 >     mtext(glabels, side = 2, line = goffset, at = gpos,
 >         adj = 0, col = gcolor, las = 2, cex = cex, ...)
85c83
<         points(gdata, gpos, pch = gpch, col = gcolor, bg = bg, ...)
---
 >         points(gdata, gpos, pch = gpch, col = gcolor, ...)


Uwe Ligges

From jmc at research.bell-labs.com  Mon Sep 29 14:07:54 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Mon Sep 29 19:07:28 2003
Subject: [Rd] infinite recursion during pkg installation w/ methods, setAs
References: <3F774DF0.80906@jhsph.edu>
	<16247.61543.185894.397725@gargle.gargle.HOWL>
Message-ID: <3F7866EA.A44AC723@research.bell-labs.com>

The problem seems to have been fixed with a change committed this
morning to the archive.

Martin Maechler wrote:
> 
> >>>>> "Roger" == Roger D Peng <rpeng@jhsph.edu>
> >>>>>     on Sun, 28 Sep 2003 17:09:04 -0400 writes:
> 
>     Roger> I ran into a problem recently trying to update a
>     Roger> package which uses S4 methods using a recent beta of
>     Roger> R.  I think I can reproduce it with a simple example.
>     Roger> I have package called `testpkg' in directory
>     Roger> testpkg/.  In the R/ subdirectory of testpkg/ I have
>     Roger> a file called testpkg.R which contains the following
>     Roger> two lines:
> 
>     Roger> setClass("testpkg", representation(pts = "list"))
>     Roger> setAs("testpkg", "numeric", function(from, to) as.numeric(unlist(from)))
> 
> Yes, this *is* a problem in recent "R beta" versions.
> Doug Bates has reported something very similar to the R core..
> So, it should hopefully be resolved "soon".
> 
> Thank you very much, Roger, for reporting the problem!
> We *are* really very grateful if many people now switch from R
> 1.7.x to "1.8.0 beta" such that we can catch as many bugs as
> possible before release!
> 
> Martin
> 
>     Roger> Then, in the main testpkg/ directory I have an empty
>     Roger> `install.R' file and a dummy DESCRIPTION file (as
>     Roger> well as an empty man/ subdirectory).
> 
>     Roger> When I run `R CMD INSTALL testpkg' I get the following output:
> 
>     Roger> marla:> R CMD INSTALL testpkg
>     Roger> * Installing *source* package 'testpkg' ...
>     Roger> ** R
>     Roger> ** save image
>     Roger> [1] "testpkg"
>     Roger> Loading required package: testpkg
>     Roger> Loading required package: testpkg
>     Roger> Loading required package: testpkg
>     Roger> Loading required package: testpkg
>     Roger> Loading required package: testpkg
>     Roger> Loading required package: testpkg
>     Roger> Loading required package: testpkg
>     Roger> Loading required package: testpkg
>     Roger> Loading required package: testpkg
>     Roger> Loading required package: testpkg
>     Roger> Loading required package: testpkg
>     Roger> Error during wrapup: evaluation is nested too deeply: infinite recursion?
>     Roger> Loading required package: testpkg
>     Roger> Error in options(x) : evaluation is nested too deeply: infinite recursion?
>     Roger> Error: evaluation is nested too deeply: infinite recursion?
>     Roger> Error: evaluation is nested too deeply: infinite recursion?
>     Roger> Error: evaluation is nested too deeply: infinite recursion?
>     Roger> Error: evaluation is nested too deeply: infinite recursion?
>     Roger> Error: evaluation is nested too deeply: infinite recursion?
>     Roger> Error: evaluation is nested too deeply: infinite recursion?
>     Roger> Error: evaluation is nested too deeply: infinite recursion?
>     Roger> Error: evaluation is nested too deeply: infinite recursion?
>     Roger> Error: evaluation is nested too deeply: infinite recursion?
>     Roger> Error: evaluation is nested too deeply: infinite recursion?
>     Roger> Error: evaluation is nested too deeply: infinite recursion?
>     Roger> Error: evaluation is nested too deeply: infinite recursion?
>     Roger> Execution halted
>     Roger> ERROR: execution of package source for 'testpkg' failed
>     Roger> ** Removing '/home/rpeng/install/R-beta/lib/R/library/testpkg'
> 
>     Roger> Is this expected?  Did I specify something
>     Roger> incorrectly?
> 
>     Roger> If I remove the setAs() call, everything installs
>     Roger> fine.  Furthermore, if I include a line like:
> 
>     Roger> setAs("numeric", "testpkg", function(from, to)
>     Roger> list())
> 
>     Roger> that doesn't seem to cause a problem.  I only get the
>     Roger> infinite recursion problem when the first argument to
>     Roger> setAs() is the new class "testpkg".
> 
>     >> version
>     Roger> _
>     Roger> platform i686-pc-linux-gnu
>     Roger> arch     i686
>     Roger> os       linux-gnu
>     Roger> system   i686, linux-gnu
>     Roger> status   beta
>     Roger> major    1
>     Roger> minor    8.0
>     Roger> year     2003
>     Roger> month    09
>     Roger> day      27
>     Roger> language R
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From jmc at research.bell-labs.com  Mon Sep 29 14:25:00 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Mon Sep 29 19:24:36 2003
Subject: [Rd] does isGeneric work differently in 1.8.0 ?
References: <Pine.GSO.4.21.0309272133020.25794-200000@btr0xe.rz.uni-bayreuth.de>
Message-ID: <3F786AEC.7FB536BA@research.bell-labs.com>

Thomas Stabla wrote:
> 
> Hello,
> 
> the last command (isGeneric) in following R-code (attached) produces
> different output, depending on wheter 1.8.0 alpha or 1.7.1 is used.
> Is that to be expected ?

This is a bug, but one that may be worth understanding.

In order to work properly with namespaces, many of the functions in the
package have changed the default for `where' arguments, from a value
meaning "search in the search list" to one meaning "search in the top
environment of the call to this function".  The isGeneric function seems
to have been overlooked.

If other examples like this arise, let us know. As Peter Dalgaard's
message mentioned, the workaround is to provide an explicit `where'
argument with the environment in which to start the search (typically
.GlobalEnv).  And calls to these functions from within other packages
may need to provide a `where' argument, unless the right default is to
look in the namespace of the package.

John

> 
> Both R Versions were started with option vanilla
> 
> ---------------------------------------------------
> R.1.7.1:
> ---------------------------------------------------
> 
> > version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    7.1
> year     2003
> month    06
> day      16
> language R
> > isGeneric("foo")
> [1] FALSE
> > setClass("woo", representation(foo="character"), prototype = list(foo ="text"))
> [1] "woo"
> > if(!isGeneric("foo")) setGeneric("foo", function(object) standardGeneric("foo"))
> [1] "foo"
> > setMethod("foo", "woo", function(object) object@foo)
> [1] "foo"
> > isGeneric("foo")
> [1] TRUE
> 
> ---------------------------------------------------
> R 1.8.1:
> ---------------------------------------------------
> 
> > version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status   alpha
> major    1
> minor    8.0
> year     2003
> month    09
> day      25
> language R
> > isGeneric("foo")
> [1] FALSE
> > setClass("woo", representation(foo="character"), prototype = list(foo="text"))
> [1] "woo"
> > if(!isGeneric("foo")) setGeneric("foo", function(object) standardGeneric("foo"))
> [1] "foo"
> > setMethod("foo", "woo", function(object) object@foo)
> [1] "foo"
> > isGeneric("foo")
> [1] FALSE
> 
> ---------------------------------------------------
> ---------------------------------------------------
> 
> Greetings,
> Thomas Stabla
> 
>   ------------------------------------------------------------------------
>              Name: code.R
>    code.R    Type: Plain Text (TEXT/PLAIN)
>          Encoding: BASE64
> 
>   ------------------------------------------------------------------------
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From ascsdfwersdf at yahoo.com.br  Mon Sep 29 15:54:49 2003
From: ascsdfwersdf at yahoo.com.br (Anjinha)
Date: Mon Sep 29 19:54:23 2003
Subject: [Rd] =?iso-8859-1?q?ENC=3A_Fw=3A_BOICOTE_AO_CASSETA=26PLANETA=3A?=
	=?iso-8859-1?q?_PRESS=C3O_TOTAL__NO_CONGRESSO?=
Message-ID: <E1A42ER-0006v9-00@franz.stat.wisc.edu>

----- Mensagem original -----
From: Juli
A repercuss=E3o do boicote pode ser vista em http://www.pampa.alturl.com/no=
ticias.htm

------- Forwarded message follows -------
Vamos repassar para todos os ga=FAchos. =C9 hora de agir novamente.

BOICOTE AO CASSETA&PLANETA: PRESS=C3O TOTAL NO CONGRESSO
25 de Setembro de 2003
A Comiss=E3o de Direitos Humanos (CDH) da C=E2mara dos Deputados, em Bras=
=EDlia, estuda um boicote contra os mais ofensivos programas televisivos. M=
esmo o presidente e dois vice-presidentes da citada comiss=E3o sendo ga=FAc=
hos, surpreendentemente o Casset=F3ides&Boiol=F3ides n=E3o =E9 considerado =
um programa racista e discriminat=F3rio. Vamos colocar este programa idiota=
 no topo da lista de reclama=E7=F5es.
Formalize as suas den=FAncias e reclama=E7=F5es (uma den=FAncia ou reclam=
=E7=E3o por e-mail) contra o casseta e planeta  pelos e-mails cdh@camara.go=
v.br e eticanatv@docline.com.br ou pelo site http://www.eticanatv.org.br, m=
antido pela mesma comiss=E3o.=20
Al=E9m de formalizar a reclama=E7=E3o, vamos lembrar os deputados ga=FAchos=
 que fazem parte da CDH de que eles s=E3o defensores dos interesses da soci=
edade ga=FAcha. =C9 hora de press=E3o total. Vamos enviar e-mails, faxes e =
telefonar reclamando da discrimina=E7=E3o e do fato de empresas p=FAblicas,=
 como a Petrobr=E1s, estarem financiando os hor=E1rios comerciais do progra=
ma. Quem conhece estes parlamentares est=E1 convidado a telefonar ou manter=
 contato pessoal. =C9 hora de press=E3o total sobre os parlamentares ga=FAc=
hos da CDH.
Quatro parlamentares ga=FAchos integram a Comiss=E3o de Direitos Humanos:

Deputado ENIO BACCI
Presidente da CDH
Partido: PDT/RS
E-mail: dep.eniobacci@camara.gov.br
Site: http://www.enio.bacci.nom.br/
Telefone: (61) 318-5930=20=20=20=20=20
Fax: (61) 318-2930




Deputado POMPEO DE MATTOS
Primeiro vice-presidente da CDH
Partido: PDT/RS
E-mail: dep.pompeodemattos@camara.gov.br
Site: http://www.pompeodemattos.com.br/=20
Telefone: (61) 318-5810=20=20=20=20=20=20
Fax: (61) 318-2810
Em 1999, j=E1 deputado, Pompeo de Mattos foi impedido de entrar pilchado na=
 C=E2mara dos Deputados. (mais: http://www.pampa.alturl.com/noticias1999.ht=
m , 25 de Fevereiro de 1999 )



Deputada MARIA DO ROS=C1RIO
Segundo vice-presidente da CDH
Partido: PT/RS
E-mail: dep.mariadorosario@camara.gov.br
Site: http://www.mariadorosario.com.br
Telefone: (61) 318-5471=20=20=20=20=20
Fax: (61) 318-2471



Deputado REINALDO SANTOS E SILVA (Pastor Reinaldo)
Membro da CDH
Partido: PTB - RS=20
E-mail: dep.pastorreinaldo@camara.gov.br
Site: http://www.pastorreinaldo.com.br
Telefone: (61) 318-5438
Fax: (61) 318-2438






Abaixo segue uma sugest=E3o de mensagem para ser enviada aos deputados.
Para: dep.pastorreinaldo@camara.gov.br, dep.mariadorosario@camara.gov.br, d=
ep.pompeodemattos@camara.gov.br, gauchismo@hotpop.com, dep.eniobacci@camara=
.gov.br
Assunto: Casseta e Planeta ofende e difama os ga=FAchos

Prezado(a) Deputado(a),
Tomei conhecimento que temos quatro representantes ga=FAchos na importante =
Comiss=E3o de Direitos Humanos (CDH) da C=E2mara dos Deputados, e que a CDH=
 est=E1 planejando o in=EDcio de um boicote contra os programas =93Doming=
=E3o do Faust=E3o", =93Te vi na TV=94 e =93Domingo Legal=94. Fiquei surpres=
o e profundamente preocupado ao saber que, mesmo com ga=FAchos ocupando pos=
i=E7=F5es importantes na Comiss=E3o, o "Casseta e Planeta", o mais racista,=
 preconceituoso e difamat=F3rio programa da TV mundial, n=E3o =E9 sequer ci=
tado!=20
N=F3s, cidad=E3os ga=FAchos, organizamos e iniciamos um boicote contra este=
 programa pretencioso que ataca a nossa hist=F3ria e a nossa cultura h=E1 u=
ma d=E9cada. Agora =E9 a vez dos parlamentares ga=FAchos, leg=EDtimos repre=
sentantes dos anseios da nossa sociedade, fazerem a parte que lhes cabe. O =
programa "Casseta e Planeta", deve estar no topo de qualquer lista de boico=
te contra o lixo televisivo que agride e ofende sociedade.
Sr(a). Parlamentar, eu j=E1 fa=E7o a minha parte, boicotando este  programa=
-lixo, a Globo, a RBS TV e os anunciantes que os financiam. Conto com a sua=
 atua=E7=E3o firme e decidida na defesa da dignidade do nosso povo e da nos=
sa cultura, colocando o "Casseta e Planeta" na posi=E7=E3o que lhe =E9 just=
a na lista da CDH de programas a serem boicotados, ou seja, de mais racista=
, ofensivo, discriminat=F3rio e desmoralizante programa da televis=E3o bras=
ileira. A efic=E1cia da sua atua=E7=E3o ser=E1 lembrada pelos ga=FAchos na =
pr=F3xima elei=E7=E3o.
Manifesto tamb=E9m a minha grande insatisfa=E7=E3o pelo fato de empresas p=
=FAblicas, como a Petrobr=E1s, estarem financiando este programa infame. Se=
 o boicote que conduzimos precisar ser direcionado para uma campanha de des=
obedi=EAncia civil, com a suspens=E3o total do pagamento de qualquer impost=
o, eu apoiarei e participarei.
Aguardando sua resposta a esta minha reclama=E7=E3o contra este programa, d=
espe=E7o-me.
Atenciosamente,

	[[alternative HTML version deleted]]

From wettenhall at wehi.EDU.AU  Tue Sep 30 18:41:42 2003
From: wettenhall at wehi.EDU.AU (wettenhall@wehi.EDU.AU)
Date: Tue Sep 30 09:41:06 2003
Subject: [Rd] Adding Tk extensions to R for windows
Message-ID: <4111.192.168.65.113.1064907702.squirrel@homebase.wehi.edu.au>

Hi,

I'm developing an R/TclTk application which uses the BWidget and
Tktable Tk extensions and I'm trying to make it easy to install.
For now, I'm focusing on Windows users who start with nothing.

I have built Tcl/Tk and Tktable for windows using Msys/MinGW.
(BWidget contains only Tcl scripts so does not need building.)
I have then copied Tktable and BWidget into the lib subdirectory
of the Tcl directory in R source, created by unzipping R_Tcl.zip
from Brian Ripley's webpage.  (I should also try creating the
entire R_Tcl.zip myself, rather than mixing and matching.)
Finally I have followed the instructions in src/gnuwin32/INSTALL
including "make distribution" which has built
an R installation wizard including the Tk extensions.

It seems to work fine and I don't think I've violated any
license agreements - it's my understanding that Tktable and
BWidget source (both on sourceforge) are under BSD, like the other
Tcl already included with R.

Of course some would say that you can build faster and smaller Tcl
libraries using Visual C++.  I didn't notice much difference with my
application running Tktable.  I did try buildling Tcl/Tk with the
free version of VC++.NET SDK but nmake -f makefile.vc in
Tcl_source/win/ complained that vcvars32.bat needed to be run.  The
latest version of the (free) VC++.NET SDK seems to only have sdkvars.bat,
which does something similar to vcvars32.bat (i.e. set PATH, INCLUDE,
LIB and NetSamplePath), but running it didn't seem to help so I turned
to Msys/MinGW.  Maybe I should buy the full Visual C++/Visual Studio?

I'm wondering whether anyone would like to point out any potential
problems (license or otherwise) with distributing a customized R
installation wizard.

Also, I would be happy to become involved in the maintenance/testing
of R_Tcl.zip for windows if I'm qualified, but I suppose this would
require buying the full Visual C++/Visual Studio, right?

If there is sufficient building/testing from volunteers, are the R core
developers considering bundling more Tcl/Tk packages with R, or does the
problem of HOW MANY packages/megabytes to add mean that there would always
have to be a separate "batteries included" installation wizard?

Regards,
James

From John.Marsland at CommerzbankIB.com  Tue Sep 30 12:34:27 2003
From: John.Marsland at CommerzbankIB.com (Marsland, John)
Date: Tue Sep 30 12:33:54 2003
Subject: [Rd] Adding Tk extensions to R for windows
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF0317E9BC@xmx8lonib.lonib.commerzbank.com>

Have you tried to make R under MSYS/MinGW, there would seem to be some
obvious benefits to this over the current collection of Cygwin tools? In the
end I don't think a separate windows install of R should be needed... in
much the same way as the separate apple mac install has been discontinued in
1.8.0 now they have the osX/fink setup. I've had a play at configuring and
making R with MSYS and I seem to be able to get quite a long way down the
process, but I'd be interested in your views since you obviously have much
more experience in this area.

Regards,
John Marsland

> -----Original Message-----
> From: wettenhall@wehi.EDU.AU [mailto:wettenhall@wehi.EDU.AU]
> Sent: 30 September 2003 08:42
> To: r-devel@stat.math.ethz.ch
> Subject: [Rd] Adding Tk extensions to R for windows
> 
> 
> Hi,
> 
> I'm developing an R/TclTk application which uses the BWidget and
> Tktable Tk extensions and I'm trying to make it easy to install.
> For now, I'm focusing on Windows users who start with nothing.
> 
> I have built Tcl/Tk and Tktable for windows using Msys/MinGW.
> (BWidget contains only Tcl scripts so does not need building.)
> I have then copied Tktable and BWidget into the lib subdirectory
> of the Tcl directory in R source, created by unzipping R_Tcl.zip
> from Brian Ripley's webpage.  (I should also try creating the
> entire R_Tcl.zip myself, rather than mixing and matching.)
> Finally I have followed the instructions in src/gnuwin32/INSTALL
> including "make distribution" which has built
> an R installation wizard including the Tk extensions.
> 
> It seems to work fine and I don't think I've violated any
> license agreements - it's my understanding that Tktable and
> BWidget source (both on sourceforge) are under BSD, like the other
> Tcl already included with R.
> 
> Of course some would say that you can build faster and smaller Tcl
> libraries using Visual C++.  I didn't notice much difference with my
> application running Tktable.  I did try buildling Tcl/Tk with the
> free version of VC++.NET SDK but nmake -f makefile.vc in
> Tcl_source/win/ complained that vcvars32.bat needed to be run.  The
> latest version of the (free) VC++.NET SDK seems to only have 
> sdkvars.bat,
> which does something similar to vcvars32.bat (i.e. set PATH, INCLUDE,
> LIB and NetSamplePath), but running it didn't seem to help so I turned
> to Msys/MinGW.  Maybe I should buy the full Visual C++/Visual Studio?
> 
> I'm wondering whether anyone would like to point out any potential
> problems (license or otherwise) with distributing a customized R
> installation wizard.
> 
> Also, I would be happy to become involved in the maintenance/testing
> of R_Tcl.zip for windows if I'm qualified, but I suppose this would
> require buying the full Visual C++/Visual Studio, right?
> 
> If there is sufficient building/testing from volunteers, are 
> the R core
> developers considering bundling more Tcl/Tk packages with R, 
> or does the
> problem of HOW MANY packages/megabytes to add mean that there 
> would always
> have to be a separate "batteries included" installation wizard?
> 
> Regards,
> James
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}

From dmurdoch at pair.com  Tue Sep 30 08:56:05 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Sep 30 13:55:26 2003
Subject: [Rd] Adding Tk extensions to R for windows
In-Reply-To: <8CBAA121CEB4D5118CB200508BB2BBEF0317E9BC@xmx8lonib.lonib.commerzbank.com>
References: <8CBAA121CEB4D5118CB200508BB2BBEF0317E9BC@xmx8lonib.lonib.commerzbank.com>
Message-ID: <dorinvss4u3u94g6koa121fahifbsicin8@4ax.com>

On Tue, 30 Sep 2003 11:34:27 +0100, you wrote:

>Have you tried to make R under MSYS/MinGW, there would seem to be some
>obvious benefits to this over the current collection of Cygwin tools? 

I haven't tried that; what benefits do you see?

Duncan Murdoch

From John.Marsland at CommerzbankIB.com  Tue Sep 30 15:42:34 2003
From: John.Marsland at CommerzbankIB.com (Marsland, John)
Date: Tue Sep 30 15:42:01 2003
Subject: [Rd] Adding Tk extensions to R for windows
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF0317E9C0@xmx8lonib.lonib.commerzbank.com>

My understanding is that MSYS was designed to provide a Minimal SYStem to
complement the Minimal GNU tools. So you can run the ./configure on windows
just the same as any unix variant and make as normal. I understand it uses
native libraries rather then the cygwin.dll .. so should be faster??? 

This would completely remove the need for separate windows project (except
for any platform specific devices eg graphics, GUIs etc ... MSYS provides
extensions for the win32 API also) - in exactly the same way and the new Mac
osX/fink build works. 

One of my main reasons for interest is that I was trying to use the
GTK/Glade libraries and it seemed as if quite a lot of modification was
necessary for win32 systems. I got more interested when I started thinking
about Rpvm and all the spare win32 boxes sitting around - curently this
package only works for unix/linux systems. My guess is that an awful lot
more of the R project could be made non-platform-specific if this route is
followed.

Or in their own words .... [http://www.mingw.org/msys.shtml]

"This package provides a minimal POSIX system to allow a typical configure
script to execute so that you can execute make.  It provides a native
mingw32 host/build/target system in order to use the MinGW port of GCC and
binutils to port other packages to the Windows environment.  It eliminates
the complexities of the semi-cross build system provided by -mno-cygwin.  It
removes the need to use programs such as cygpath by auto translating the
path strings appropriately.  With version 1.0.8 both paths in arguments and
paths in the environment are converted."

The MSYS developer took kit provides the following packages:

autoconf
automake
libtool
autogen
openssl
openssh
cvs
guile
inetutils

Regards,

John Marsland

> -----Original Message-----
> From: Duncan Murdoch [mailto:dmurdoch@pair.com]
> Sent: 30 September 2003 12:56
> To: Marsland, John
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] Adding Tk extensions to R for windows
> 
> 
> On Tue, 30 Sep 2003 11:34:27 +0100, you wrote:
> 
> >Have you tried to make R under MSYS/MinGW, there would seem 
> to be some
> >obvious benefits to this over the current collection of 
> Cygwin tools? 
> 
> I haven't tried that; what benefits do you see?
> 
> Duncan Murdoch
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}

From dmurdoch at pair.com  Tue Sep 30 11:27:35 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Sep 30 16:26:33 2003
Subject: [Rd] Adding Tk extensions to R for windows
In-Reply-To: <8CBAA121CEB4D5118CB200508BB2BBEF0317E9C0@xmx8lonib.lonib.commerzbank.com>
References: <8CBAA121CEB4D5118CB200508BB2BBEF0317E9C0@xmx8lonib.lonib.commerzbank.com>
Message-ID: <ju3jnvcb00l3kdu7hhm30u9jaj7eatk7n7@4ax.com>

On Tue, 30 Sep 2003 14:42:34 +0100, "Marsland, John"
<John.Marsland@CommerzbankIB.com> wrote :

>My understanding is that MSYS was designed to provide a Minimal SYStem to
>complement the Minimal GNU tools. So you can run the ./configure on windows
>just the same as any unix variant and make as normal. I understand it uses
>native libraries rather then the cygwin.dll .. so should be faster??? 

Just to clarify:  currently R doesn't use cygwin.dll, just some of the
tools in the toolset for building R do.  So I doubt if there would be
a big speedup if any, but it might simplify things. You can currently
run ./configure on Windows, it just doesn't produce a configuration
that works :-(.  Fixing this is one of my projects for the next
release.

>This would completely remove the need for separate windows project (except
>for any platform specific devices eg graphics, GUIs etc ... MSYS provides
>extensions for the win32 API also) - in exactly the same way and the new Mac
>osX/fink build works. 

Essentially the main current need for separate windows code is the
device support and the GUI. There is a bit more than that (e.g.
separate makefiles), which are basically remnants of the days when the
toolset was less capable.  There are also some things which can be
handled by #ifdef's in the standard code (e.g. loading dynamic
libraries).

I will take a look at Msys after the 1.8.0 release.

Duncan Murdoch

From maechler at stat.math.ethz.ch  Tue Sep 30 19:04:13 2003
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue Sep 30 18:03:44 2003
Subject: [Rd] plot.hclust: dendrogram too large for window (PR#4197)
Message-ID: <200309301604.h8UG4D0P021368@pubhealth.ku.dk>

Thank you, Peter,

>>>>> "Peter" == Peter Kleiweg <kleiweg@let.rug.nl>
>>>>>     on Wed, 17 Sep 2003 01:30:58 +0200 (MET DST) writes:

    Peter> plot.hclust:
    Peter> Setting up a window for a dendrogram assumes the first link is
    Peter> the shortest and the last is the longest. This is not always the
    Peter> case when the clustering was done with hclust, method="median"
    Peter> or method="centroid", and the dendrogram sometimes doesn't fit
    Peter> within the window.

    Peter> I propose the fix listed below.

I'm about to apply this fix to "R 1.8.0 beta".
Can you please __quickly__ give a reproducible *example* for
which this bug applies, i.e., for which the fix will make a
difference?

Thanks in advance:

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

    Peter> src/main/

    Peter> --- plot.c     Wed Sep 17 01:03:39 2003
    Peter> +++ plot.c.new      Wed Sep 17 01:21:59 2003
    Peter> @@ -3314,7 +3314,7 @@
    Peter> SEXP do_dendwindow(SEXP call, SEXP op, SEXP args, SEXP env)
    Peter> {
    Peter> int i, imax, n;
    Peter> -    double pin, *ll, tmp, yval, *y, ymin, ymax, yrange;
    Peter> +    double pin, *ll, tmp, yval, *y, ymin, ymax, yrange, m;
    Peter> SEXP originalArgs, merge, height, llabels, str;
    Peter> char *vmax;
    Peter> DevDesc *dd;
    Peter> @@ -3357,8 +3357,14 @@
    Peter> ll =  (double*)R_alloc(n, sizeof(double));
    Peter> dnd_lptr = &(INTEGER(merge)[0]);
    Peter> dnd_rptr = &(INTEGER(merge)[n]);
    Peter> -    ymin = REAL(height)[0];
    Peter> -    ymax = REAL(height)[n - 1];
    Peter> +    ymax = ymin = REAL(height)[0];
    Peter> +    for (i = 1; i < n; i++) {
    Peter> +      m = REAL(height)[i];
    Peter> +      if (m > ymax)
    Peter> +       ymax = m;
    Peter> +      if (m < ymin)
    Peter> +       ymin = m;
    Peter> +    }
    Peter> pin = Rf_gpptr(dd)->pin[1];
    Peter> for (i = 0; i < n; i++) {
    Peter> str = STRING_ELT(llabels, i);



    Peter> --please do not edit the information below--

    Peter> Version:
    Peter> platform = i686-pc-linux-gnu
    Peter> arch = i686
    Peter> os = linux-gnu
    Peter> system = i686, linux-gnu
    Peter> status =
    Peter> major = 1
    Peter> minor = 7.1
    Peter> year = 2003
    Peter> month = 06
    Peter> day = 16
    Peter> language = R

    Peter> Search Path:
    Peter> .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg, package:nls, package:ts, Autoloads, package:base

From kleiweg at let.rug.nl  Tue Sep 30 20:28:57 2003
From: kleiweg at let.rug.nl (kleiweg@let.rug.nl)
Date: Tue Sep 30 19:28:23 2003
Subject: [Rd] dump/source problem with hclust object (PR#4361)
Message-ID: <200309301728.h8UHSv0P021798@pubhealth.ku.dk>



    library(mva)
    data(USArrests)
    hc <- hclust(dist(USArrests), "ave")

    plot(hc)              # OK

    dump(c("hc"), "tst")
    rm(hc)
    source("tst")

    plot(hc)              # Error in plot.hclust(hc) : invalid dendrogram input


The same problem occurs with dput/dget




--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status =
 major = 1
 minor = 7.1
 year = 2003
 month = 06
 day = 16
 language = R

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva,
package:modreg, package:nls, package:ts, Autoloads, package:base

From kleiweg at let.rug.nl  Tue Sep 30 20:31:28 2003
From: kleiweg at let.rug.nl (Peter Kleiweg)
Date: Tue Sep 30 19:30:49 2003
Subject: [Rd] another dump/source problem?
Message-ID: <Pine.LNX.4.44.0309301928430.1170-100000@kleigh.nl>


Is this a bug?

I do this:

    library(mva)
    data(USArrests)
    d <- dist(USArrests)
    dump("d", "tst")
    q()

I restart R and do this:

    source("tst")

And I get:

    Error in as.matrix(x) : Object "USArrests" not found




Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status =
 major = 1
 minor = 7.1
 year = 2003
 month = 06
 day = 16
 language = R


-- 
Peter Kleiweg
http://www.let.rug.nl/~kleiweg/

From simon.urbanek at math.uni-augsburg.de  Tue Sep 30 20:43:22 2003
From: simon.urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Tue Sep 30 19:43:45 2003
Subject: [Rd] Adding Tk extensions to R for windows
In-Reply-To: <8CBAA121CEB4D5118CB200508BB2BBEF0317E9C0@xmx8lonib.lonib.commerzbank.com>
Message-ID: <95E164E4-F36D-11D7-B2E8-000A959F327E@math.uni-augsburg.de>

On Tuesday, September 30, 2003, at 03:42 PM, Marsland, John wrote:

> necessary for win32 systems. I got more interested when I started 
> thinking
> about Rpvm and all the spare win32 boxes sitting around - curently this
> package only works for unix/linux systems. My guess is that an awful 
> lot
> more of the R project could be made non-platform-specific if this 
> route is
> followed.

FYI: Rpvm itself is fairly platform-independent. I had a quick glance 
at rpvm on Win32 quite recently. It compiled fine, the only serious 
problem I had was at link-time due to the fact that PVM itself has no 
shared library that could be easily used with MinGW (talking about the 
official binary version). Rpvm needed hardly any touchups. Presumably 
compiling PVM with MinGW should solve the issue and rpvm should work 
almost out of the box. Actually this shows that R makes it possible for 
developers to 'accidentally' produce packages that work on Windows even 
though they were developed for unix machines ;).

Cheers,
Simon

From andy_liaw at merck.com  Tue Sep 30 14:57:20 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Sep 30 19:57:01 2003
Subject: [Rd] dump/source problem with hclust object (PR#4361)
Message-ID: <3A822319EB35174CA3714066D590DCD50205CBE1@usrymx25.merck.com>

?dump says:

Details:

     At present the implementation of `dump' is very incomplete and it
     really only works for functions and simple vectors.

     [...]

     The function `save' is designed to be used for transporting R data
     between machines.

So I guess, technically, this is not a bug, nor is your other example.  (An
"hclust" object is hardly a simple vector.)

Andy


> -----Original Message-----
> From: kleiweg@let.rug.nl [mailto:kleiweg@let.rug.nl] 
> Sent: Tuesday, September 30, 2003 1:29 PM
> To: r-devel@stat.math.ethz.ch
> Cc: R-bugs@biostat.ku.dk
> Subject: [Rd] dump/source problem with hclust object (PR#4361)
> 
> 
> 
> 
>     library(mva)
>     data(USArrests)
>     hc <- hclust(dist(USArrests), "ave")
> 
>     plot(hc)              # OK
> 
>     dump(c("hc"), "tst")
>     rm(hc)
>     source("tst")
> 
>     plot(hc)              # Error in plot.hclust(hc) : 
> invalid dendrogram input
> 
> 
> The same problem occurs with dput/dget
> 
> 
> 
> 
> --please do not edit the information below--
> 
> Version:
>  platform = i686-pc-linux-gnu
>  arch = i686
>  os = linux-gnu
>  system = i686, linux-gnu
>  status =
>  major = 1
>  minor = 7.1
>  year = 2003
>  month = 06
>  day = 16
>  language = R
> 
> Search Path:
>  .GlobalEnv, package:methods, package:ctest, package:mva, 
> package:modreg, package:nls, package:ts, Autoloads, package:base
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-devel
>

From kleiweg at let.rug.nl  Tue Sep 30 21:56:39 2003
From: kleiweg at let.rug.nl (Peter Kleiweg)
Date: Tue Sep 30 20:56:02 2003
Subject: [Rd] dump/source problem with hclust object (PR#4361)
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CBE1@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0309302029000.1170-100000@kleigh.nl>

# aldus Liaw, Andy :

> ?dump says:
>
> Details:
>
>      At present the implementation of `dump' is very incomplete and it
>      really only works for functions and simple vectors.

I'm sorry, I overlooked that. If I remember correctly, `dump'
and `source' were already present in R version 1.2.0, the first
version I used, so I just guessed that any problems with it
should be solved by now.

>      [...]
>
>      The function `save' is designed to be used for transporting R data
>      between machines.

Are `save' and `load' meant as a replacement for `dump' and
`source'? What are the future plans with `dump' and `source',
and with `dput' and `dget'?

-- 
Peter Kleiweg
http://www.let.rug.nl/~kleiweg/

From ihaka at stat.auckland.ac.nz  Tue Sep 30 22:46:16 2003
From: ihaka at stat.auckland.ac.nz (ihaka@stat.auckland.ac.nz)
Date: Tue Sep 30 21:45:41 2003
Subject: [Rd] another dump/source problem? (PR#4364)
Message-ID: <200309301946.h8UJkG0P022498@pubhealth.ku.dk>

Peter Kleiweg wrote:

> Is this a bug?

Yes.  If you look inside the saved file it contains

	..., call = dist(x = USArrests), ...

When this is reread, an attempt is made to evaluate the call.
Some kind of quoting is needed.

> I do this:
> 
>     library(mva)
>     data(USArrests)
>     d <- dist(USArrests)
>     dump("d", "tst")
>     q()
> 
> I restart R and do this:
> 
>     source("tst")
> 
> And I get:
> 
>     Error in as.matrix(x) : Object "USArrests" not found



-- 
Ross Ihaka                         Email:  ihaka@stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand

From tlumley at u.washington.edu  Tue Sep 30 17:09:06 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Oct  1 01:08:55 2003
Subject: [Rd] eigin of matrix of NaNs (PR#4366)
In-Reply-To: <200309302212.h8UMCm0P023196@pubhealth.ku.dk>
References: <200309302212.h8UMCm0P023196@pubhealth.ku.dk>
Message-ID: <Pine.A41.4.58.0309301608380.93514@homer37.u.washington.edu>

On Wed, 1 Oct 2003 maechler@stat.math.ethz.ch wrote:
> Confirmed for R 1.7.1 on Linux.
> The good news is that the bug seems to have been fixed
> 'inadvertently' already, as it is not showing in R-1.8.0beta
> anymore.
>

It was fixed in response to another bug report about eigen of NA values.

	-thomas

