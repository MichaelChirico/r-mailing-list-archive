From bjg at network-theory.co.uk  Sat Nov  1 19:15:59 2003
From: bjg at network-theory.co.uk (bjg@network-theory.co.uk)
Date: Sat Nov  1 19:14:54 2003
Subject: [Rd] cvs diff not working on anonymous cvs (PR#4907)
Message-ID: <200311011815.hA1IFx0P020090@pubhealth.ku.dk>

Full_Name: Brian Gough
Version: anonymous cvs
OS: Debian GNU/Linux 3.0
Submission from: (NULL) (80.46.234.10)


After successfully checking out the source tree following the instructions on
http://anoncvs.r-project.org/ I can run cvs update commands successfully but not
cvs diff.

bjg|debian> cvs update
cvs server: Updating .
cvs server: Updating afm
....
bjg|debian> cvs diff -r R-1-7-0 README 
cvs [server aborted]: cannot write /cvs/CVSROOT/val-tags: Permission denied

Thanks for making CVS available (very useful -- I wiped out some work several
times when using Rsync!)

From ripley at stats.ox.ac.uk  Sun Nov  2 12:31:28 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sun Nov  2 12:30:30 2003
Subject: [Rd] strptime (PR#4204)
In-Reply-To: <200309171513.h8HFDRJH005486@pubhealth.ku.dk>
Message-ID: <Pine.WNT.4.44.0311021118300.856-100000@petrel>

Did that time actually exist in your timezone?  It does in mine and it is
converted correctly, but I suspect it does not in yours.  According to my
version of Windows that hour does not exist in a US timezone due to the
change to DST.

In any case, you have not given sufficient information to reproduce this,
such as your locale.

Please either produce evidence for your claim or confirm that the error was
your own.  In the unlikely event that there is a bug it will be in Windows
and not in R.

On Wed, 17 Sep 2003 pliu3@ncsu.edu wrote:

> Full_Name: Peng Liu
> Version: 1.7.1
> OS: XP Home
> Submission from: (NULL) (128.109.14.2)
>
>
> > strptime(c("80040601"),format="%y%m%d%H")
> [1] "1980-04-06 01:00:00"
> > strptime(c("80040602"),format="%y%m%d%H")
> [1] "1980-04-06 01:00:00"
>
> Convert incorrectly.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sun Nov  2 12:51:04 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sun Nov  2 12:50:17 2003
Subject: [Rd] Windows RConsole Focus
In-Reply-To: <Pine.LNX.4.44.0310221856330.14211-100000@unix28.alpha.wehi.edu.au>
Message-ID: <Pine.WNT.4.44.0311021150370.856-100000@petrel>

?bringToTop

On Wed, 22 Oct 2003, James Wettenhall wrote:

> Hi,
>
> I was looking for a Windows-specific R function to focus the
> console window and couldn't find one.  The motivation is that
> after loading the tcltk package, the "main" Tk window "." is
> presumably focused but then immediately withdrawn (hidden) so
> the RConsole loses its focus and you have to click on it to
> continue typing.
>
> Would there be any interest in including a winConsoleFocus()
> function in R at some stage or is it already there?
>
> I tried implementing a quick solution (below) which seemes
> to work.
>
> Regards,
> James
>
> src/gnuwin32/rui.c
> ------------------
> int winconsolefocus()
> {
>     show(RConsole);
>     return 0;
> }
>
> src/gnuwin32/rui.h
> ------------------
> int winconsolefocus(void);
>
> src/gnuwin32/extra.c
> --------------------
> SEXP do_winconsolefocus(SEXP call, SEXP op, SEXP args, SEXP rho)
> {
>     SEXP ans;
>     Rboolean success = TRUE;
>     winconsolefocus();
>     PROTECT(ans = allocVector(LGLSXP, 1));
>     LOGICAL(ans)[0] = success;
>     UNPROTECT(1);
>     return ans;
> }
>
> src/main/names.c
> ----------------
> {"winConsoleFocus",do_winconsolefocus,0,11,     0,
> {PP_FUNCALL, PREC_FN,   0}},
>
> src/include/Internal.h
> ----------------------
> SEXP do_winconsolefocus(SEXP, SEXP, SEXP, SEXP);
>
> src/library/base/R/windows/winDialog.R
> ---------------------------------------
> winConsoleFocus <- function()
>     invisible(.Internal(winConsoleFocus()))
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jwe at bevo.che.wisc.edu  Sun Nov  2 17:40:49 2003
From: jwe at bevo.che.wisc.edu (John W. Eaton)
Date: Sun Nov  2 19:18:25 2003
Subject: [Rd] cvs diff not working on anonymous cvs (PR#4907)
In-Reply-To: <200311011815.hA1IFx0P020090@pubhealth.ku.dk>
References: <200311011815.hA1IFx0P020090@pubhealth.ku.dk>
Message-ID: <16293.13201.58078.453346@devzero.bogus.domain>

On  1-Nov-2003, bjg@network-theory.co.uk <bjg@network-theory.co.uk> wrote:

| Full_Name: Brian Gough
| Version: anonymous cvs
| OS: Debian GNU/Linux 3.0
| Submission from: (NULL) (80.46.234.10)
| 
| 
| After successfully checking out the source tree following the instructions on
| http://anoncvs.r-project.org/ I can run cvs update commands successfully but not
| cvs diff.
| 
| bjg|debian> cvs update
| cvs server: Updating .
| cvs server: Updating afm
| ....
| bjg|debian> cvs diff -r R-1-7-0 README 
| cvs [server aborted]: cannot write /cvs/CVSROOT/val-tags: Permission denied

I think this should be fixed now.

Thanks,

jwe

From jfox at mcmaster.ca  Mon Nov  3 00:47:30 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon Nov  3 00:45:40 2003
Subject: [Rd] problem with fix() called from Rcmdr
Message-ID: <5.1.0.14.2.20031102182314.020ed018@127.0.0.1>

Dear list members,

I and my students have encountered an intermittent problem using the Rcmdr 
package (version 0.9-0) under Windows (with the SDI). The problem occurs 
both in versions 1.7.1 and 1.8.0 of R.

The problem seems to occur only in the following context: The "Edit data 
set" button is pressed in the Rcmdr GUI. This executes the fix() function 
on the active data frame, bringing up a data editor window. After changing 
variable names in the data editor, the editor is closed by the user. This 
causes the active data frame to be detached and re-attached. That is, this 
is what happens when things work normally. Frequently, however, Rgui.exe 
crashes at this point, reporting a "program error."

I suspect that there some kind of timing problem, but before I experiment 
further, I wonder whether anyone has any more specific ideas.

To be supply some more details, the "Edit data set" button executes the 
following code:

     onEdit <- function(){
         command <- paste("fix(", .activeDataSet, ")", sep="")
         logger(command)
         justDoIt(command)
         activeDataSet(.activeDataSet)
         tkwm.deiconify(.commander)
         tkfocus(.commander)
         }

where .activeDataSet is a (global) character variable containing the name 
of the "active" data frame, logger() just echoes the command to the R console

logger <- function(command){
     if (tclvalue(.logCommands) == "1") {
         tkinsert(.log, "end", paste(command,"\n", sep=""))
         tkyview.moveto(.log, 1)
         }
     lines <- strsplit(command, "\n")[[1]]
     for (line in lines) cat(paste("\nR-cmdr>", line, "\n"))
     command
     }


and JustDoIt() is defined as follows:

justDoIt <- function(command) {
     result <- try(eval(parse(text=command), envir=.GlobalEnv), silent=TRUE)
     if (class(result)[1] ==  "try-error"){
         tkmessageBox(message=paste("Error:",
             strsplit(result, ":")[[1]][2]), icon="error")
         tkfocus(.commander)
         return()
         }
     result
     }

The function activeDataSet() has the following definition (but I doubt that 
the problem is there, since Rcmdr uses this function a lot and I've not 
observed a problem in any other context):

activeDataSet <- function(dsname){
     if (missing(dsname)) {
         if (is.null(.activeDataSet)){
             tkmessageBox(message="There is no active data set.", 
icon="error", type="ok")
             return(FALSE)
             }
         else return(.activeDataSet)
         }
     if (!is.data.frame(get(dsname, envir=.GlobalEnv))){
         tkmessageBox(message=paste(dsname, " is not a data frame and 
cannot be attached.",
             sep=""), icon="error", type="ok")
         tkfocus(.commander)
         return()
         }
     if (!is.null(.activeDataSet) && (tclvalue(.attachDataSet) == "1")
         && (length(grep(.activeDataSet, search())) !=0)) {
         detach(pos = match(.activeDataSet, search()))
         logger(paste("detach(", .activeDataSet, ")", sep=""))
         }
     assign(".activeDataSet", dsname, envir=.GlobalEnv)
     assign(".variables", listVariables(), envir=.GlobalEnv)
     assign(".numeric", listNumeric(), envir=.GlobalEnv)
     assign(".factors", listFactors(), envir=.GlobalEnv)
     assign(".twoLevelFactors", listTwoLevelFactors(), envir=.GlobalEnv)
     tclvalue(.dataSetName) <- paste(.activeDataSet, " ")
     tkconfigure(.dataSetLabel, fg="blue")
     if (tclvalue(.attachDataSet) == "1"){
         attach(get(dsname, envir=.GlobalEnv), name=dsname)
         logger(paste("attach(", dsname, ")", sep=""))
         }
     dsname
     }

Any help would be greatly appreciated.

John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox@mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox

From wettenhall at wehi.edu.au  Mon Nov  3 01:45:47 2003
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Mon Nov  3 01:44:44 2003
Subject: [Rd] Windows RConsole Focus - oops, thanks!
In-Reply-To: <Pine.WNT.4.44.0311021150370.856-100000@petrel>
Message-ID: <Pine.LNX.4.44.0311031139590.11461-100000@unix28.alpha.wehi.edu.au>

Prof Ripley,

On Sun, 2 Nov 2003, Prof Brian D Ripley wrote:
> ?bringToTop

Oops.  It's right there in help.search("focus"), 
help.search("window") etc.  Sorry I missed it.

Thanks for your help,
James

From tlumley at u.washington.edu  Mon Nov  3 05:21:45 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Nov  3 05:20:44 2003
Subject: [Rd] fairly OT: profiling
Message-ID: <Pine.A41.4.58.0311022012210.128622@homer09.u.washington.edu>


The following is from Eric Raymond's new book on Unix programming.

  You'll get more insight from using profilers if you think of them less
  as ways to collect individual performance numbers, and more as ways to
  learn how performance varies as a function of interesting parameters
  ... Try fitting those numbers to a model, using open-source software
  like R or a good-quality proprietary tool like MATLAB.

It's interesting to see the emphasis on statistical analysis of profiling
data (as well as the fact that R is sufficiently well-known not to need
explanation (or a reference or link)).

	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley@u.washington.edu	University of Washington, Seattle

From rossini at blindglobe.net  Mon Nov  3 05:47:20 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon Nov  3 05:45:26 2003
Subject: [Rd] fairly OT: profiling
In-Reply-To: <Pine.A41.4.58.0311022012210.128622@homer09.u.washington.edu>
	(Thomas
	Lumley's message of "Sun, 2 Nov 2003 20:21:45 -0800 (PST)")
References: <Pine.A41.4.58.0311022012210.128622@homer09.u.washington.edu>
Message-ID: <85vfq2gisn.fsf@blindglobe.net>

Thomas Lumley <tlumley@u.washington.edu> writes:

> The following is from Eric Raymond's new book on Unix programming.
>
>   You'll get more insight from using profilers if you think of them less
>   as ways to collect individual performance numbers, and more as ways to
>   learn how performance varies as a function of interesting parameters
>   ... Try fitting those numbers to a model, using open-source software
>   like R or a good-quality proprietary tool like MATLAB.
>
> It's interesting to see the emphasis on statistical analysis of profiling
> data (as well as the fact that R is sufficiently well-known not to need
> explanation (or a reference or link)).

If you hang out with compiler writers more often (I do, about once a
year, thanks to an old friend who implements superscalars) you'd find
that they've felt the same way for years (and spend a good bit of time
with machine learning algorithms working on weak points, discovery,
and optimization).

(staying off topic, it's also amusing that some of the better groups
generally run on relatively ancient hardware, but that's another
story).

best,
-tony

-- 
rossini@u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}

From bjg at network-theory.co.uk  Mon Nov  3 16:21:30 2003
From: bjg at network-theory.co.uk (Brian Gough)
Date: Mon Nov  3 16:20:46 2003
Subject: [Rd] cvs diff not working on anonymous cvs (PR#4907)
In-Reply-To: <16293.13201.58078.453346@devzero.bogus.domain>
References: <200311011815.hA1IFx0P020090@pubhealth.ku.dk>
	<16293.13201.58078.453346@devzero.bogus.domain>
Message-ID: <16294.29306.141804.516702@debian.local>

John W. Eaton writes:
 > On  1-Nov-2003, bjg@network-theory.co.uk <bjg@network-theory.co.uk> wrote:
 > | bjg|debian> cvs diff -r R-1-7-0 README 
 > | cvs [server aborted]: cannot write /cvs/CVSROOT/val-tags: Permission denied
 > 
 > I think this should be fixed now.
 > 

Yes, it's working now -- thanks.

-- 
Brian Gough

From John.Marsland at CommerzbankIB.com  Mon Nov  3 18:24:17 2003
From: John.Marsland at CommerzbankIB.com (Marsland, John)
Date: Mon Nov  3 18:23:54 2003
Subject: [Rd] POSIXct under R-1.8.0 with Methods package
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF0317EA22@xmx8lonib.lonib.commerzbank.com>


I am having problems porting a package to R-1.8.0 where I have complex S4
classes with slots inheriting from POSIXct. For example:

> setClass("test1", representation(date="POSIXct"))
[1] "test1"
> new("test1", date=as.POSIXct("2003-10-09"))
Error in ext@test(object) : couldn't find function "%in %"

Under R-1.7.1 this worked fine and generated the following:
> new("test1", date=as.POSIXct("2003-10-09"))
An object of class "test1"
Slot "date":
[1] "2003-10-09 GMT Standard Time"

Any thoughts would be greatly appreciated ...

Regards,

John

I am working with Windows NT 4.0
> R.version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    8.0            
year     2003           
month    10             
day      08             
language R 



********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}

From ligges at statistik.uni-dortmund.de  Mon Nov  3 19:41:01 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Nov  3 19:39:29 2003
Subject: [Rd] POSIXct under R-1.8.0 with Methods package
In-Reply-To: <8CBAA121CEB4D5118CB200508BB2BBEF0317EA22@xmx8lonib.lonib.commerzbank.com>
References: <8CBAA121CEB4D5118CB200508BB2BBEF0317EA22@xmx8lonib.lonib.commerzbank.com>
Message-ID: <3FA6A13D.9050406@statistik.uni-dortmund.de>

Marsland, John wrote:

> I am having problems porting a package to R-1.8.0 where I have complex S4
> classes with slots inheriting from POSIXct. For example:
> 
> 
>>setClass("test1", representation(date="POSIXct"))
> 
> [1] "test1"
> 
>>new("test1", date=as.POSIXct("2003-10-09"))
> 
> Error in ext@test(object) : couldn't find function "%in %"
> 
> Under R-1.7.1 this worked fine and generated the following:
> 
>>new("test1", date=as.POSIXct("2003-10-09"))
> 
> An object of class "test1"
> Slot "date":
> [1] "2003-10-09 GMT Standard Time"
> 
> Any thoughts would be greatly appreciated ...



It's a typo in
  methods:::.setOldIs()
"%in %" --> "%in%"

(might be fixed in a recent r-patched - I have no available here right now)

Uwe Ligges




> Regards,
> 
> John
> 
> I am working with Windows NT 4.0
> 
>>R.version
> 
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    8.0            
> year     2003           
> month    10             
> day      08             
> language R 
> 
> 
> 
> ********************************************************************** 
> This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Mon Nov  3 20:24:06 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Nov  3 20:23:15 2003
Subject: [Rd] POSIXct under R-1.8.0 with Methods package
In-Reply-To: <8CBAA121CEB4D5118CB200508BB2BBEF0317EA22@xmx8lonib.lonib.commerzbank.com>
Message-ID: <Pine.LNX.4.44.0311031921220.18254-100000@gannet.stats>

It's a bug:

oldClass.R:            substitute(CLASS %in % attr(object, "class"), list(CLASS = cl))

has a typo.  Now corrected in R-patched thank you.

On Mon, 3 Nov 2003, Marsland, John wrote:

> 
> I am having problems porting a package to R-1.8.0 where I have complex S4
> classes with slots inheriting from POSIXct. For example:
> 
> > setClass("test1", representation(date="POSIXct"))
> [1] "test1"
> > new("test1", date=as.POSIXct("2003-10-09"))
> Error in ext@test(object) : couldn't find function "%in %"
> 
> Under R-1.7.1 this worked fine and generated the following:
> > new("test1", date=as.POSIXct("2003-10-09"))
> An object of class "test1"
> Slot "date":
> [1] "2003-10-09 GMT Standard Time"
> 
> Any thoughts would be greatly appreciated ...
> 
> Regards,
> 
> John
> 
> I am working with Windows NT 4.0
> > R.version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    8.0            
> year     2003           
> month    10             
> day      08             
> language R 
> 
> 
> 
> ********************************************************************** 
> This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Mon Nov  3 20:36:56 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Nov  3 20:36:08 2003
Subject: [Rd] POSIXct under R-1.8.0 with Methods package
In-Reply-To: <3FA6A13D.9050406@statistik.uni-dortmund.de>
References: <8CBAA121CEB4D5118CB200508BB2BBEF0317EA22@xmx8lonib.lonib.commerzbank.com>
	<3FA6A13D.9050406@statistik.uni-dortmund.de>
Message-ID: <16294.44632.93101.160003@gargle.gargle.HOWL>

>>>>> "UweL" == Uwe Ligges <ligges@statistik.uni-dortmund.de>
>>>>>     on Mon, 03 Nov 2003 19:41:01 +0100 writes:

    UweL> Marsland, John wrote:
    >> I am having problems porting a package to R-1.8.0 where I
    >> have complex S4 classes with slots inheriting from
    >> POSIXct. For example:
    >> 
    >> 
    >>> setClass("test1", representation(date="POSIXct"))
    >>  [1] "test1"
    >> 
    >>> new("test1", date=as.POSIXct("2003-10-09"))
    >>  Error in ext@test(object) : couldn't find function "%in
    >> %"
    >> 
    >> Under R-1.7.1 this worked fine and generated the
    >> following:
    >> 
    >>> new("test1", date=as.POSIXct("2003-10-09"))
    >>  An object of class "test1" Slot "date": [1] "2003-10-09
    >> GMT Standard Time"
    >> 
    >> Any thoughts would be greatly appreciated ...


    UweL> It's a typo in methods:::.setOldIs() 
    UweL> "%in %" --> "%in%"

exactly.

    UweL> (might be fixed in a recent r-patched - I have no
    UweL> available here right now)

yes, fixed (not by me) in a very recent R-patched as of about an
hour ago...

From p.murrell at auckland.ac.nz  Tue Nov  4 00:10:13 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue Nov  4 00:09:20 2003
Subject: [Rd] grid bug
Message-ID: <3FA6E055.7050603@stat.auckland.ac.nz>

Hi

I've just discovered a potentially nasty bug in grid.
If you have developed code using grid, please check whether this may 
affect your code.

The problem occurs when a numeric value is multiplied by a unit object, 
e.g., 0.5*unit(1, "inches").  The result will be WRONG if the numeric 
has length > 1, e.g., c(0.25, 0.5)*unit(1, "inches").

The problem is illustrated by the following:

       grid.segments(x0=1:3/4, y0=0.1, x1=1:3/4,
                     y1=unit(1:3/4, "npc"),
                     gp=gpar(col="grey", lwd=5))
       grid.segments(x0=1:3/4, y0=0.1, x1=1:3/4,
                     y1=1:3/4*unit(1, "npc"))

This draws three vertical bars.  The thin black bars should be the same 
heights as the thick grey bars, but they are not.

A fix for this will be in R version 1.8.1

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul@stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/

From charlie at stat.umn.edu  Tue Nov  4 02:14:00 2003
From: charlie at stat.umn.edu (charlie@stat.umn.edu)
Date: Tue Nov  4 02:13:08 2003
Subject: [Rd] glm offset and interaction bugs (PR#4941)
Message-ID: <200311040114.hA41E00P012950@pubhealth.ku.dk>

Full_Name: Charles J. Geyer
Version: 1.8.0
OS: i686-pc-linux-gnu (Suse 8.2)
Submission from: (NULL) (134.84.86.22)


Two bugs (perhaps related, perhaps independent) revealed by the same
Poisson regression with offset

mydata <- read.table(url("http://www.stat.umn.edu/geyer/5931/mle/seeds.txt"))
out.fubar <- glm(seedlings ~ burn01 + vegtype * burn02 +
    offset(log(totalseeds)), data = mydata, family = poisson)
summary(out.fubar)
out.barfu <- glm(seedlings ~ burn01 + vegtype * burn02,
    offset = log(totalseeds), data = mydata, family = poisson)
summary(out.barfu)
out.ok <- glm(seedlings ~ vegtype * burn02 + burn01,
    offset = log(totalseeds), data = mydata, family = poisson)
summary(out.ok)

As far as I can tell from reading the documentation, these should produce
the same results.  They don't.  The regression coefficient for the
offset term in the first (fubar) regression is bogus.  That's not what
offset() is supposed to do.  Note that offset() works properly in

out <- glm(seedlings ~ vegtype + burn01 + burn02 + offset(log(totalseeds)),
    data = mydata, family = poisson)
summary(out)

So is is only partially bogus -- very dangerous for users that are less
than hyperalert.

The difference between out.barfu and out.ok shows that "+" in formulas
is noncommutative, which is very mind bending.

The regression in out.ok is o. k.  It checks by hand.

For a more complete explanation (if more is wanted), including
the printout from these summary commands on my machine and the
check of out.ok "by hand", see

   http://www.stat.umn.edu/geyer/5931/mle/seed2.Rnw
   http://www.stat.umn.edu/geyer/5931/mle/seed2.pdf

From tlumley at u.washington.edu  Tue Nov  4 04:39:26 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue Nov  4 04:38:36 2003
Subject: [Rd] glm offset and interaction bugs (PR#4941)
In-Reply-To: <200311040114.hA41E00P012950@pubhealth.ku.dk>
References: <200311040114.hA41E00P012950@pubhealth.ku.dk>
Message-ID: <Pine.A41.4.58.0311031924070.96610@homer09.u.washington.edu>

On Tue, 4 Nov 2003 charlie@stat.umn.edu wrote:

> Full_Name: Charles J. Geyer
> Version: 1.8.0
> OS: i686-pc-linux-gnu (Suse 8.2)
> Submission from: (NULL) (134.84.86.22)
>
>
> Two bugs (perhaps related, perhaps independent) revealed by the same
> Poisson regression with offset

Only one bug, i think.  There is certainly a bug in handling offset() in
formulas with interactions (which is presumably fairly recent, since the C
code for offsets dates only from January this year).

The latter two models, though, are the same AFAICS, or more precisely are
reparametrisations of the same underidentified model. The only way to make
+ commutative in this example would be to have some arbitrary rule based
on the name of the variable for which parameters to drop, and that would
have the even more unintuitive effect that changing the name of a variable
would affect the output.


> mydata <- read.table(url("http://www.stat.umn.edu/geyer/5931/mle/seeds.txt"))
> out.fubar <- glm(seedlings ~ burn01 + vegtype * burn02 +
>     offset(log(totalseeds)), data = mydata, family = poisson)
> summary(out.fubar)
> out.barfu <- glm(seedlings ~ burn01 + vegtype * burn02,
>     offset = log(totalseeds), data = mydata, family = poisson)
> summary(out.barfu)
> out.ok <- glm(seedlings ~ vegtype * burn02 + burn01,
>     offset = log(totalseeds), data = mydata, family = poisson)
> summary(out.ok)
>
> As far as I can tell from reading the documentation, these should produce
> the same results.  They don't.  The regression coefficient for the
> offset term in the first (fubar) regression is bogus.  That's not what
> offset() is supposed to do.  Note that offset() works properly in
>
> out <- glm(seedlings ~ vegtype + burn01 + burn02 + offset(log(totalseeds)),
>     data = mydata, family = poisson)
> summary(out)
>
> So is is only partially bogus -- very dangerous for users that are less
> than hyperalert.
>
> The difference between out.barfu and out.ok shows that "+" in formulas
> is noncommutative, which is very mind bending.
>
> The regression in out.ok is o. k.  It checks by hand.
>
> For a more complete explanation (if more is wanted), including
> the printout from these summary commands on my machine and the
> check of out.ok "by hand", see
>
>    http://www.stat.umn.edu/geyer/5931/mle/seed2.Rnw
>    http://www.stat.umn.edu/geyer/5931/mle/seed2.pdf
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley@u.washington.edu	University of Washington, Seattle

From Giles.Heywood at CommerzbankIB.com  Tue Nov  4 09:30:37 2003
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Tue Nov  4 09:29:44 2003
Subject: [Rd] Object saved from 1.7.1, loaded in 1.8.0
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF05BF734F@xmx8lonib.lonib.commerzbank.com>

I am having difficulty using in 1.8.0 an object created under 1.7.1. The
following is a 'minimal example' of the issue.  First the part in 1.7.1:

> require("methods")
[1] TRUE
> setClass("foo",representation("vector",label="character"))
[1] "foo"
> x <- new("foo",1:2,label=LETTERS[1:2])
> save(x,file="f:/temp/test_gh.171.Rdata")

Then in 1.8.0:

> require("methods")
[1] TRUE
> setClass("foo",representation("vector",label="character"))
[1] "foo"
> load("f:/temp/test_gh.171.Rdata")
> new("foo",x,label=x@label)
Error in initialize(value, ...) : Initialize method returned an object of
class "foo" instead of the required class "foo"
> new("foo",x@.Data,label=x@label)
An object of class "foo"
[1] 1 2
Slot "label":
[1] "A" "B"

> y <- new("foo",1:2,label=LETTERS[1:2])
> new("foo",y,label=y@label)
An object of class "foo"
[1] 1 2
Slot "label":
[1] "A" "B"

> attributes(class(x))
NULL
> attributes(class(y))
$package
[1] ".GlobalEnv"

> attributes(class(x)) <- attributes(class(y))
> new("foo",y,label=y@label)
An object of class "foo"
[1] 1 2
Slot "label":
[1] "A" "B"

As far as I can see, the "class" attribute now has an attribute "package",
and the absence of this attribute in objects created under 1.7.1 causes the
problem.  This lack of 'backward compatibility' has been flagged to me as a
bug in the package 'its' that I maintain on CRAN.  I'm not sure it's a
bug... should I advise users to re-generate their stored objects using e.g.
new("foo",x@.Data,label=x@label)?  Or is there something I am missing
altogether here?

TIA

Giles Heywood

OS: NT4

R.version
         
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    8.0            
year     2003           
month    10             
day      08             
language R      


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}

From dj at research.bell-labs.com  Tue Nov  4 15:23:05 2003
From: dj at research.bell-labs.com (David James)
Date: Tue Nov  4 15:22:52 2003
Subject: [Rd] Object saved from 1.7.1, loaded in 1.8.0
In-Reply-To: <8CBAA121CEB4D5118CB200508BB2BBEF05BF734F@xmx8lonib.lonib.commerzbank.com>;
	from Giles.Heywood@commerzbankib.com on Tue, Nov 04, 2003 at 08:30:37AM
	-0000
References: <8CBAA121CEB4D5118CB200508BB2BBEF05BF734F@xmx8lonib.lonib.commerzbank.com>
Message-ID: <20031104092305.A12006@jessie.research.bell-labs.com>

Hi,

Heywood, Giles wrote:
> I am having difficulty using in 1.8.0 an object created under 1.7.1. The
> following is a 'minimal example' of the issue.  First the part in 1.7.1:
> 
> > require("methods")
> [1] TRUE
> > setClass("foo",representation("vector",label="character"))
> [1] "foo"
> > x <- new("foo",1:2,label=LETTERS[1:2])
> > save(x,file="f:/temp/test_gh.171.Rdata")
> 
> Then in 1.8.0:
> 
> > require("methods")
> [1] TRUE
> > setClass("foo",representation("vector",label="character"))
> [1] "foo"
> > load("f:/temp/test_gh.171.Rdata")
> > new("foo",x,label=x@label)
> Error in initialize(value, ...) : Initialize method returned an object of
> class "foo" instead of the required class "foo"
> > new("foo",x@.Data,label=x@label)
> An object of class "foo"
> [1] 1 2
> Slot "label":
> [1] "A" "B"
> 
> > y <- new("foo",1:2,label=LETTERS[1:2])
> > new("foo",y,label=y@label)
> An object of class "foo"
> [1] 1 2
> Slot "label":
> [1] "A" "B"
> 
> > attributes(class(x))
> NULL
> > attributes(class(y))
> $package
> [1] ".GlobalEnv"
> 
> > attributes(class(x)) <- attributes(class(y))
> > new("foo",y,label=y@label)
> An object of class "foo"
> [1] 1 2
> Slot "label":
> [1] "A" "B"
> 
> As far as I can see, the "class" attribute now has an attribute "package",
> and the absence of this attribute in objects created under 1.7.1 causes the
> problem.  This lack of 'backward compatibility' has been flagged to me as a
> bug in the package 'its' that I maintain on CRAN.  I'm not sure it's a
> bug... should I advise users to re-generate their stored objects using e.g.
> new("foo",x@.Data,label=x@label)?  Or is there something I am missing
> altogether here?
> 
> TIA
> 
> Giles Heywood
> 
> OS: NT4
> 
> R.version
>          
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    8.0            
> year     2003           
> month    10             
> day      08             
> language R      
> 
> 
> ********************************************************************** 
> This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

I seem to have a very similar problem.   In my case I cannot use
R 1.8.0 to extend a base class in a package built under 1.7.1.
Namely, if I have installed the package DBI under 1.7.1 and attempt
to installed ROracle under 1.8.0  I get

R CMD check RORacle       ## R 1.8.0
.....
Error in .combineExtends(byExt, toExt, by, to) :
        No slot of name "subClass" for this object of class "SClassExtension"
Error in .combineExtends(byExt, toExt, by, to) :
        No slot of name "subClass" for this object of class "SClassExtension"
Error in setClass("OraDriver", representation("DBIDriver", "OraObject")) :
        Error in contained classes ("DBIDriver", "OraObject")
        for class "OraDriver"; class definition removed from "ROracle"
                           Execution halted
ERROR: execution of package source for 'ROracle'
                           failed

(I should also mention that the R 1.7.1 DBI installation above uses a
saved image.)

I'm aware that it is not a good idea to allow this type of version
mismatch, but I wouldn't be surprised if other unsuspecting users
get also bitten by it.

--
David

From tlumley at u.washington.edu  Tue Nov  4 16:40:24 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue Nov  4 16:39:34 2003
Subject: [Rd] Mac OS X/panther R INSTALL
Message-ID: <Pine.A41.4.58.0311040735020.44914@homer37.u.washington.edu>


If you upgrade Mac OS X to the new version 10.3 and package installation
in RAqua stops working, try

  dyld <- Sys.getenv("DYLD_LIBRARY_PATH")
  Sys.putenv("DYLD_LIBRARY_PATH"=paste("/usr/lib",dyld,sep=":"))

If this doesn't work, or if it works and you don't have teTex or TeXShop
installed I would be interested to know

	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley@u.washington.edu	University of Washington, Seattle

From gregory_r_warnes at groton.pfizer.com  Wed Nov  5 15:55:13 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Wed Nov  5 15:54:18 2003
Subject: [Rd] NLME: gls parameter evaluation inconsistency (PR#4757)
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20680AA18@groexmb02.pfizer.com>




> -----Original Message-----
> From: Douglas Bates [mailto:bates@stat.wisc.edu]
> Sent: Friday, October 24, 2003 12:16 PM
[...]
> Yes.  It's the old "standard non-standard evaluation" problem.  The
> model.frame function is (and has to be) very peculiar in the way
> that it determines the value of variable names without local
> bindings.  That's the non-standard evaluation part.  Because it is
> difficult to get this right, it helps if it only needs to be done in
> one place so we have what Thomas Lumley described as a "standard
> non-standard evaluation" function in the current model.frame function.
> 
> However, model.frame expects to have only one argument called
> "formula" (the first argument) containing a formula that will need to
> be evaluated in the frame.  The model fitting functions in the nlme
> package can have formulas in multiple arguments.  Arranging for the
> proper call to model.frame to be evaluated is not easy.
> 
> A workaround is to use subset on the data frame passed as an argument
> 
> prgls <- function(name){ gls( log10(Y)~(cond-1)+(cond-1):t
>  ,subset(pr,subject==name))}

Why don't we extend model.frame to allow for multiple 'formula-like'
arguments?  Perhaps by adding an argument that allows the call to specify
which paramters are 'formula-like'?

-G


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

From joehl at gmx.de  Wed Nov  5 16:14:13 2003
From: joehl at gmx.de (joehl@gmx.de)
Date: Wed Nov  5 16:13:07 2003
Subject: [Rd] read.table leaves out data when reading multiple-line records
	(PR#4955)
Message-ID: <200311051514.hA5FED0P008815@pubhealth.ku.dk>



Dear all,

I discovered that read.table (RW1.8.0) leaves out data when reading
multiple-line records.

Replication code at the end

Best regards


Jens Oehlschlägel


> filename <- "c:/tmp/c2.csv"
> 
> data <- data.frame(a=c("c", "e\nnewline"), b=c("d", '"quoted
simpleline"'))
> 
> #look at the data
> write.table(data, sep=",", row.names=FALSE)
"a","b"
"c","d"
"e
newline","\"quoted simpleline\""
> 
> # write it out
> write.table(data, sep=",", row.names=FALSE, file=filename)
> 
> # reading it in a line is missing
> read.csv(filename)
           a                     b
1 e\nnewline \\quoted simpleline\\
> 
> fc <- file(filename, open="r")
> 
> # the problem seems to be
> # readTableHead erroneously counts 3 lines as 4
> lines <- .Internal(readTableHead(fc, 4, "", TRUE))
> lines
[1] "\"a\",\"b\""                             "\"c\",\"d\""                 
           "\"e"                                    
[4] "newline\",\"\\\"quoted simpleline\\\"\""
> 
> # double pushback is fine
> pushBack(c(lines,lines), fc)
> 
> # but nlines tells us we had 4 lines, which in fact are only 3
> nlines <- length(lines)
> nlines
[1] 4
> 
> # and the first scan eats up more than the first pushback
> scan(fc, what="string", sep=",", nlines=nlines)
Read 8 items
[1] "a"                     "b"                     "c"                    
"d"                     "e\nnewline"           
[6] "\\quoted simpleline\\" "a"                     "b"                    
> 
> # thus the real scan misses data
> scan(fc, what="string", sep=",")
Read 4 items
[1] "c"                     "d"                     "e\nnewline"           
"\\quoted simpleline\\"
> 
> close(fc)
> 
> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    8.0            
year     2003           
month    10             
day      08             
language R




filename <- "c:/tmp/c2.csv"

data <- data.frame(a=c("c", "e\nnewline"), b=c("d", '"quoted simpleline"'))

#look at the data
write.table(data, sep=",", row.names=FALSE)

# write it out
write.table(data, sep=",", row.names=FALSE, file=filename)

# reading it in a line is missing	
read.csv(filename)

fc <- file(filename, open="r")

# the problem seems to be
# readTableHead erroneously counts 3 lines as 4
lines <- .Internal(readTableHead(fc, 4, "", TRUE))
lines

# double pushback is fine
pushBack(c(lines,lines), fc)

# but nlines tells us we had 4 lines, which in fact are only 3
nlines <- length(lines)
nlines

# and the first scan eats up more than the first pushback
scan(fc, what="string", sep=",", nlines=nlines)

# thus the real scan misses data
scan(fc, what="string", sep=",")

close(fc)

version


--

From zednikova at yahoo.com  Wed Nov  5 17:58:17 2003
From: zednikova at yahoo.com (Mirka Zednikova)
Date: Wed Nov  5 17:57:14 2003
Subject: [Rd] fast nearest-neighbor in R?
Message-ID: <20031105165817.83262.qmail@web12307.mail.yahoo.com>

Is fast nearest-neighbor functionality available in R?
I was thinking of something along the lines of what's
currently in S+SPATIALSTATS.

Thanks for any information anyone might have on this.

- MZ

From Peter.Ruckdeschel at uni-bayreuth.de  Wed Nov  5 21:51:11 2003
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Wed Nov  5 21:50:24 2003
Subject: [Rd] RFE: Hierarchical Sectioning in the Entry Page to
 Documentation for S4-Classes in Contributed Packages
Message-ID: <3FA962BF.6060908@uni-bayreuth.de>

Hi,

we are at that stage working on a  package implementing the concept of
distributions as own S4-Classes. We are planning to submit a first 
tentative
version to this audience by the end of November.

One issue we met is that when documenting our classes, the resulting
help-file that is displayed as first page [at least in html] when 
searching for
help to our package works quite reasonable, but in our view looks a bit 
overloaded,
not to say messy.

To our knowledge there is no standard way of avoiding this mentionned in
the FAQs and the manuals.

We would appreciate the possibility to further partition/section the 
entry page of a
documentation of a package --- at best reflecting the inheritance 
structure of our classes.

To be precise we would like to have the possibility to begin the entry 
page with a highly
structured (in tree/graph-form?)  presentation of the classes / methods 
within this package
--- not at all listed in alphabetical order.

->[ for instance grouped in TeX-like sections/subsections,  corresponding to
      the inheritance structure of our classes, and / or one section for 
each generic
      function  --- possibly also illustrated by an automatically placed 
tree diagram
      for the inheritance structure? --- ]

 Only after this we would add the display style for the entry page
 as it is at the moment as sort of an index.

We think that this way one would apprehend at first glance the 
hierarchical structure
of the classes within this package and that this incremental view should 
greatly
enhance the readability of the help files ---  not only of ours.

On the other hand this sketched way of sectioning should be optional so 
that any
developper may confine oneself to the existing display modi.

What do you think of this proposal? And do you think it is hard to 
implement 
(unfortunately we cannot offer  much help in that)?

Thank you for your attention

-- 
Peter Ruckdeschel

From nikko at hailmail.net  Thu Nov  6 02:09:05 2003
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Thu Nov  6 02:08:04 2003
Subject: [Rd] fast nearest-neighbor in R?
In-Reply-To: <20031105165817.83262.qmail@web12307.mail.yahoo.com>
References: <20031105165817.83262.qmail@web12307.mail.yahoo.com>
Message-ID: <20031106010905.864F74062D@server1.messagingengine.com>

Hi,
It is in the works. Take a look at the archives in
https://www.stat.math.ethz.ch/mailman/listinfo/r-sig-geo for the
r-sig-geo mailing list.
For the moment you can use the k-nearest-neighbor code in Spdep which
is adapted from Ripley's knn classifier code. It uses brute force and is
not
as fast as algorithms based on kd or quad trees for larger data sets. For
smaller
data sets you probably won't notice the difference.

Nicholas


On Wed, 5 Nov 2003 08:58:17 -0800 (PST), "Mirka Zednikova"
<zednikova@yahoo.com> said:
> Is fast nearest-neighbor functionality available in R?
> I was thinking of something along the lines of what's
> currently in S+SPATIALSTATS.
> 
> Thanks for any information anyone might have on this.
> 
> - MZ
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From veraf at stat.sc.edu  Thu Nov  6 02:13:45 2003
From: veraf at stat.sc.edu (veraf@stat.sc.edu)
Date: Thu Nov  6 02:12:42 2003
Subject: [Rd] Bug in R (PR#4960)
Message-ID: <200311060113.hA61Dj0P012798@pubhealth.ku.dk>

Hello,

My name is Francisco Vera. I have a small problem with the names produced by
the function data.frame. If you run the code below, you will notice that the
names of b1 are correct except for the first variable. This problem does not
happen in the case of b2.

a1<-sapply(1:5,function(x) rmultinom(x,20,1:4/10))
a2<-sapply(2:6,function(x) rmultinom(x,20,1:4/10))
b1<-data.frame(a1)
b2<-data.frame(a2)

The version of R I am using is 1.8.0. My OS is Windows XP

Thanks for your reviewing and possibly fixing this bug

Francisco Vera
Department of Statistics
University of South Carolina
Columbia, SC 29208

From fshwvpr4 at msn.com  Thu Nov  6 02:49:44 2003
From: fshwvpr4 at msn.com (fshwvpr4@msn.com)
Date: Thu Nov  6 02:48:35 2003
Subject: [Rd] Have you seen this?  byrhbhszuasj (PR#4961)
Message-ID: <200311060149.hA61ni0P012932@pubhealth.ku.dk>


--.8E_BC64..
Content-Type: text/html;
Content-Transfer-Encoding: base64

PGEgaHJlZj0naHR0cDovL2NhcmVjZW50ZXIyLmNvbS9ob3N0L2RlZmF1bHQuYXNwP2lkPTAw
Mic+PGltZyBzcmM9J2h0dHA6Ly83OHBpbGxzLmNvbS9waWNzL2d2MS5naWYnPC9hPg0KPEJS
Pg0KPEJSPg0KPEJSPg0KPEJSPg0KPEJSPg0KPEJSPg0KPEJSPg0KPEJSPg0KPEJSPg0KPEJS
Pg0KPEJSPg0KPEJSPg0KbWFsZSBoZWFydHkgY29sb24=



--.8E_BC64..--

From robert.king at newcastle.edu.au  Thu Nov  6 06:53:09 2003
From: robert.king at newcastle.edu.au (robert.king@newcastle.edu.au)
Date: Thu Nov  6 06:52:05 2003
Subject: [Rd] Search engine fails entirely (PR#4966)
Message-ID: <200311060553.hA65r90P014249@pubhealth.ku.dk>

Full_Name: Robert King
Version: 1.8.0
OS: linux (debian)
Submission from: (NULL) (134.148.20.33)


Also seen in 1.7

Start R, Start html help (mozilla), go to search engine, try searching for mean
No results given.

Mozilla javascript console says:

Error: document.SearchEngine.search is not a function
Source File: file:///tmp/Rtmp22901/.R/doc/html/search/SearchEngine.html
Line: 32

line 32 is ....
line = line + document.SearchEngine.search (searchTerm,

From ripley at stats.ox.ac.uk  Thu Nov  6 08:18:40 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Nov  6 08:25:12 2003
Subject: [Rd] Search engine fails entirely (PR#4966)
In-Reply-To: <200311060553.hA65r90P014249@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0311060713360.26300-100000@gannet.stats>

This is a bug in your Mozilla setup (version not given) rather than in R.
It is tested regularly.

You need Java and JavaScript enabled and properly configured (and that
does not happen by default).  Please search the R-help archives for
information on this (there was a detailed posting from Marc Schwartz: 
AFAIR there is a link missing in the Java installation).

On Thu, 6 Nov 2003 robert.king@newcastle.edu.au wrote:

> Full_Name: Robert King
> Version: 1.8.0
> OS: linux (debian)
> Submission from: (NULL) (134.148.20.33)
> 
> 
> Also seen in 1.7
> 
> Start R, Start html help (mozilla), go to search engine, try searching for mean
> No results given.
> 
> Mozilla javascript console says:
> 
> Error: document.SearchEngine.search is not a function
> Source File: file:///tmp/Rtmp22901/.R/doc/html/search/SearchEngine.html
> Line: 32
> 
> line 32 is ....
> line = line + document.SearchEngine.search (searchTerm,


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From stefano.iacus at unimi.it  Thu Nov  6 10:22:21 2003
From: stefano.iacus at unimi.it (Stefano Iacus)
Date: Thu Nov  6 10:21:14 2003
Subject: [Rd] RAqua package installation on Panther
Message-ID: <B9DFBCAB-103A-11D8-8BBF-003065CC4CB8@unimi.it>

 From the RAqua faq just uploaded to CRAN (so it will take until 
tomorrow to appear)



Panther notes
After installing Panther (MacOSX 10.3) it turns out that package 
installation (either from sources or from binaries) can fail. If you 
get an error "like" this (this comes from source package installation)

dyld: gcc version mismatch for library: /usr/local/lib/libiconv.2.dylib 
(compatibility version of user: 5.0.0 greater than library's version: 
4.0.0)

i.e. you get an incompatibility error for the libiconv library, this is 
probably due to the fact that you have the "libiconv" dll in the 
"/usr/local/lib" path. It seems that this library is installed on 
Jaguar (MacOSX 10.2.x) with the distribution of teTex that comes from 
the "i-installer 2". If you install the same te TeX distribution on 
Panther and you didn't have a previous installed one on Jaguar, then 
this library is not installed in "/usr/local/bin". So this is not a 
i-installer bug or a RAqua bug. The problem comes from GNU based 
command line tools (for example gcc and tar) that use this dll which is 
installed in "/usr/lib" under Panther.

The fix
If you only need to install packages from binaries, you just need to 
write the following command in a R session <i>before</i> attempting to 
install packages

dyld <- Sys.getenv("DYLD_LIBRARY_PATH")<br>
Sys.putenv("DYLD_LIBRARY_PATH"=paste("/usr/lib",dyld,sep=":"))

This fix is for non-expert unix user and only fix binary installation 
and should be done each time you need to install packages from binaries 
(on a per-session basis, i.e. only one time a session).
The more robust fix that also fixes source package installation is to 
edit the main R script file which is

/Applications/StartR.app/RAqua.app/Contents/MacOS/R

in order to have /usr/bin as the first path entry in the 
DYLD_LIBRARY_PATH environment variable. For example transform this 
piece of script from

if test -z "${DYLD_LIBRARY_PATH}"; then
   DYLD_LIBRARY_PATH="${R_LD_LIBRARY_PATH}"
else<br>
   DYLD_LIBRARY_PATH="${R_LD_LIBRARY_PATH}:${DYLD_LIBRARY_PATH}"
fi
export DYLD_LIBRARY_PATH<br>

into the following one

if test -z "${DYLD_LIBRARY_PATH}"; then
   DYLD_LIBRARY_PATH="${R_LD_LIBRARY_PATH}"
else
   DYLD_LIBRARY_PATH="${R_LD_LIBRARY_PATH}:${DYLD_LIBRARY_PATH}"
fi
DYLD_LIBRARY_PATH="/usr/bin:${DYLD_LIBRARY_PATH}" ## just this line 
added
export DYLD_LIBRARY_PATH




Thanks to Thomas L. and other users to stop this and suggest fixes.
Thomas is still claiming that it is also configure that fails on 
panther because of the same problem.

My own experience is that
* on a fresh Panther installation (i.e. removing jaguar, tex etc...I 
formatted my boot disk)
* using g77 from the RAqua page
* installing teTeX with the i-installer
* configuring for RAqua

I get not problem and all went smoothly for yesterday (nov 5th) R-devel.


Please let us know, possibly before the end of the next week (i.e. in 
time for R.1.8.1), if you have other problems with Panther.

stefano

From MSchwartz at medanalytics.com  Thu Nov  6 14:28:22 2003
From: MSchwartz at medanalytics.com (MSchwartz@medanalytics.com)
Date: Thu Nov  6 14:27:24 2003
Subject: [Rd] Search engine fails entirely (PR#4966)
Message-ID: <200311061328.hA6DSM0P022101@pubhealth.ku.dk>

I thank Prof. Ripley for his kind reference. 

Below is the URL for a post last month that provides some guidance. The
bottom line, as Prof. Ripley pointed out, is that both Java AND
JavaScript must be enabled in the browser Preference settings. 

In addition, it is critical that a proper symlink be created in the
Mozilla 'plugins' folder to the proper Java binary. You need 'root'
privileges to do this. If this symlink is not created, Mozilla does not
know where Java is and cannot execute the R search applet.

The post below contains links to the Mozilla 1.5 release notes regarding
Java installation, as well as links to the requisite Sun Java pages
(FAQs, etc.)

https://www.stat.math.ethz.ch/pipermail/r-help/2003-October/039822.html

If you get this properly configured, when you get to the Search page,
you should see a message in the lower left hand Mozilla status line
indicating that the search applet has started.

HTH,

Marc Schwartz


On Thu, 2003-11-06 at 01:18, Prof Brian Ripley wrote:
> This is a bug in your Mozilla setup (version not given) rather than in R.
> It is tested regularly.
> 
> You need Java and JavaScript enabled and properly configured (and that
> does not happen by default).  Please search the R-help archives for
> information on this (there was a detailed posting from Marc Schwartz: 
> AFAIR there is a link missing in the Java installation).
> 
> On Thu, 6 Nov 2003 robert.king@newcastle.edu.au wrote:
> 
> > Full_Name: Robert King
> > Version: 1.8.0
> > OS: linux (debian)
> > Submission from: (NULL) (134.148.20.33)
> > 
> > 
> > Also seen in 1.7
> > 
> > Start R, Start html help (mozilla), go to search engine, try searching for mean
> > No results given.
> > 
> > Mozilla javascript console says:
> > 
> > Error: document.SearchEngine.search is not a function
> > Source File: file:///tmp/Rtmp22901/.R/doc/html/search/SearchEngine.html
> > Line: 32
> > 
> > line 32 is ....
> > line = line + document.SearchEngine.search (searchTerm,
>

From MSchwartz at medanalytics.com  Thu Nov  6 14:28:06 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu Nov  6 14:27:42 2003
Subject: [Rd] Search engine fails entirely (PR#4966)
In-Reply-To: <Pine.LNX.4.44.0311060713360.26300-100000@gannet.stats>
References: <Pine.LNX.4.44.0311060713360.26300-100000@gannet.stats>
Message-ID: <1068125286.6055.22.camel@localhost.localdomain>

I thank Prof. Ripley for his kind reference. 

Below is the URL for a post last month that provides some guidance. The
bottom line, as Prof. Ripley pointed out, is that both Java AND
JavaScript must be enabled in the browser Preference settings. 

In addition, it is critical that a proper symlink be created in the
Mozilla 'plugins' folder to the proper Java binary. You need 'root'
privileges to do this. If this symlink is not created, Mozilla does not
know where Java is and cannot execute the R search applet.

The post below contains links to the Mozilla 1.5 release notes regarding
Java installation, as well as links to the requisite Sun Java pages
(FAQs, etc.)

https://www.stat.math.ethz.ch/pipermail/r-help/2003-October/039822.html

If you get this properly configured, when you get to the Search page,
you should see a message in the lower left hand Mozilla status line
indicating that the search applet has started.

HTH,

Marc Schwartz


On Thu, 2003-11-06 at 01:18, Prof Brian Ripley wrote:
> This is a bug in your Mozilla setup (version not given) rather than in R.
> It is tested regularly.
> 
> You need Java and JavaScript enabled and properly configured (and that
> does not happen by default).  Please search the R-help archives for
> information on this (there was a detailed posting from Marc Schwartz: 
> AFAIR there is a link missing in the Java installation).
> 
> On Thu, 6 Nov 2003 robert.king@newcastle.edu.au wrote:
> 
> > Full_Name: Robert King
> > Version: 1.8.0
> > OS: linux (debian)
> > Submission from: (NULL) (134.148.20.33)
> > 
> > 
> > Also seen in 1.7
> > 
> > Start R, Start html help (mozilla), go to search engine, try searching for mean
> > No results given.
> > 
> > Mozilla javascript console says:
> > 
> > Error: document.SearchEngine.search is not a function
> > Source File: file:///tmp/Rtmp22901/.R/doc/html/search/SearchEngine.html
> > Line: 32
> > 
> > line 32 is ....
> > line = line + document.SearchEngine.search (searchTerm,
>

From jmc at research.bell-labs.com  Thu Nov  6 15:55:45 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Thu Nov  6 15:55:04 2003
Subject: [Rd] Object saved from 1.7.1, loaded in 1.8.0
References: <8CBAA121CEB4D5118CB200508BB2BBEF05BF734F@xmx8lonib.lonib.commerzbank.com>
Message-ID: <3FAA60F1.9785036C@research.bell-labs.com>

Your analysis is basically correct:  As part of adapting to namespaces
and more generally to mapping correctly to classes and generic functions
from multiple packages, the class of an object now identifies the
package that class came from.  Loaded objects saved in earlier versions
will lack the package identification, though many computations will work
OK for them.

A simple fix will update objects, if the user applies it to a particular
object:

 > class(x) <- getClass(class(x))@className

This assumes that, as in your example, the relevant classes have been
defined for version 1.8 before we update the objects.

So manual intervention is fairly easy, but one would like a more
automatic mechanism, which is trickier.  Then the problem is to obey the
maxim "First, do no harm."  We should watch out for undefined classes,
inconsistent new definitions, and objects that are not really from
earlier versions.  A function, fixPre1.8(names), will be added to the
patches for 1.8.1, to let users fix loaded objects, given the names of
the objects.

John Chambers
 
"Heywood, Giles" wrote:
> 
> I am having difficulty using in 1.8.0 an object created under 1.7.1. The
> following is a 'minimal example' of the issue.  First the part in 1.7.1:
> 
> > require("methods")
> [1] TRUE
> > setClass("foo",representation("vector",label="character"))
> [1] "foo"
> > x <- new("foo",1:2,label=LETTERS[1:2])
> > save(x,file="f:/temp/test_gh.171.Rdata")
> 
> Then in 1.8.0:
> 
> > require("methods")
> [1] TRUE
> > setClass("foo",representation("vector",label="character"))
> [1] "foo"
> > load("f:/temp/test_gh.171.Rdata")
> > new("foo",x,label=x@label)
> Error in initialize(value, ...) : Initialize method returned an object of
> class "foo" instead of the required class "foo"
> > new("foo",x@.Data,label=x@label)
> An object of class "foo"
> [1] 1 2
> Slot "label":
> [1] "A" "B"
> 
> > y <- new("foo",1:2,label=LETTERS[1:2])
> > new("foo",y,label=y@label)
> An object of class "foo"
> [1] 1 2
> Slot "label":
> [1] "A" "B"
> 
> > attributes(class(x))
> NULL
> > attributes(class(y))
> $package
> [1] ".GlobalEnv"
> 
> > attributes(class(x)) <- attributes(class(y))
> > new("foo",y,label=y@label)
> An object of class "foo"
> [1] 1 2
> Slot "label":
> [1] "A" "B"
> 
> As far as I can see, the "class" attribute now has an attribute "package",
> and the absence of this attribute in objects created under 1.7.1 causes the
> problem.  This lack of 'backward compatibility' has been flagged to me as a
> bug in the package 'its' that I maintain on CRAN.  I'm not sure it's a
> bug... should I advise users to re-generate their stored objects using e.g.
> new("foo",x@.Data,label=x@label)?  Or is there something I am missing
> altogether here?
> 
> TIA
> 
> Giles Heywood
> 
> OS: NT4
> 
> R.version
> 
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    8.0
> year     2003
> month    10
> day      08
> language R
> 
> **********************************************************************
> This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From tlumley at u.washington.edu  Thu Nov  6 20:22:17 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Nov  6 20:21:17 2003
Subject: [Rd] RAqua package installation on Panther
In-Reply-To: <B9DFBCAB-103A-11D8-8BBF-003065CC4CB8@unimi.it>
References: <B9DFBCAB-103A-11D8-8BBF-003065CC4CB8@unimi.it>
Message-ID: <Pine.A41.4.58.0311061121040.88004@homer22.u.washington.edu>

On Thu, 6 Nov 2003, Stefano Iacus wrote:

>
> Thanks to Thomas L. and other users to stop this and suggest fixes.
> Thomas is still claiming that it is also configure that fails on
> panther because of the same problem.
>
> My own experience is that
> * on a fresh Panther installation (i.e. removing jaguar, tex etc...I
> formatted my boot disk)
> * using g77 from the RAqua page
> * installing teTeX with the i-installer
> * configuring for RAqua
>
> I get not problem and all went smoothly for yesterday (nov 5th) R-devel.

It seems on my machine that the problem is with the (optional)
libwmf+iconv package that TeXshop recommends. Removing this allows R and
configure to work fine.

	-thomas

From stefano.iacus at unimi.it  Thu Nov  6 21:38:58 2003
From: stefano.iacus at unimi.it (Stefano Iacus)
Date: Thu Nov  6 21:37:48 2003
Subject: [Rd] RAqua package installation on Panther
In-Reply-To: <Pine.A41.4.58.0311061121040.88004@homer22.u.washington.edu>
Message-ID: <3F1E3198-1099-11D8-8BBF-003065CC4CB8@unimi.it>

Thanks Thomas,

I'll change the text in the RAqua faq.
stefano

On Gioved?, nov 6, 2003, at 20:22 Europe/Rome, Thomas Lumley wrote:

> On Thu, 6 Nov 2003, Stefano Iacus wrote:
>
>>
>> Thanks to Thomas L. and other users to stop this and suggest fixes.
>> Thomas is still claiming that it is also configure that fails on
>> panther because of the same problem.
>>
>> My own experience is that
>> * on a fresh Panther installation (i.e. removing jaguar, tex etc...I
>> formatted my boot disk)
>> * using g77 from the RAqua page
>> * installing teTeX with the i-installer
>> * configuring for RAqua
>>
>> I get not problem and all went smoothly for yesterday (nov 5th) 
>> R-devel.
>
> It seems on my machine that the problem is with the (optional)
> libwmf+iconv package that TeXshop recommends. Removing this allows R 
> and
> configure to work fine.
>
> 	-thomas
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From rdeb_question at yahoo.com  Fri Nov  7 00:16:21 2003
From: rdeb_question at yahoo.com (Simon Rex)
Date: Fri Nov  7 00:15:32 2003
Subject: [Rd] error message using ARM cpu with Debian 
Message-ID: <20031106231621.88991.qmail@web21507.mail.yahoo.com>


I post this message on R-help mailing list but someone emailed me that I can get helped if I post this one on R-devel mailing list.

I have a small handheld pc having ARM process as a CPU. I installed 
debian and installed R (R-1.7.0 base and core, help html, latex-help) using apt-get command. Everything worked great 
except for drawing even simple graphs
  
 x <- 1:10
 plot(x)

I got error messages
 
        1: Nonfinite axis limits [GScale(nan,nan,1, .); log=0] 
        2: relative range of values = 9.0072e+15 * EPS, is small 
          (axis 1). 
        3: Nonfinite axis limits [GScale(-inf,inf,2, .); log=0] 
        4: relative range of values = 9.0072e+15 * EPS, is small 
         (axis 2). 
 
 I searched R-help Archives hoping answers to this problem and ran 
into this message
  
 *****************

 Debian tries to build its packages on a variety of platforms. The arm 
 platform compiled 0.90.1 (the last Debian release before the Debian 
package  required an Atlas library, something we no longer require) failed in 
'make  check'. The log snippet follows; I traced this to the example(Bessel) 
code. 
 
> matplot(nu, t(outer(xx,nu, besselI)), type = 'l', ylim = 
c(-50,200), 
> + main = expression(paste("Bessel ",I[nu](x)," for fixed ", x, 
> + ", as ",f(nu))), 
> + xlab = expression(nu)) 
> Error in title(main = main, sub = sub, xlab = xlab, ylab = ylab, ...) 
: 
>         Metric information not yet available for this device 
>         In addition: Warning messages: 
>         1: Nonfinite axis limits [GScale(nan,nan,1, .); log=0] 
>         2: relative range of values = 9.0072e+15 * EPS, is small 
(axis 1). 
>         3: Nonfinite axis limits [GScale(-inf,inf,2, .); log=0] 
>         4: relative range of values = 9.0072e+15 * EPS, is small 
(axis 2). 
>         Execution halted 
> 
> Casual inspection suggests that GScale(nan,nan,1, .) is probably 
> incorrect. Now, src/nmath/bessel* provide the Bessel functions but 
does this 
> reflect a potential libc bug in IEEE handling? 
> 
> I have also asked on the debian-arm mailing list, but no result so 
far. I 
> have some access to an arm box and could compile small test cases if 
that 
> helped. 
> 
> Dirk 
> ****************
> 
 Is there any way I can fix this problem ? I checked Debain FTP sites 
to find Atlas but there is no Atlas lib for arm. 




---------------------------------


	[[alternative HTML version deleted]]

From p.dalgaard at biostat.ku.dk  Fri Nov  7 10:12:28 2003
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Fri Nov  7 10:11:22 2003
Subject: [Rd] Server down and (hopefully) back up. (PR#4974)
Message-ID: <20031107091228.B7626F3A3@slim.kubism.ku.dk>

The R-bugs service has been down for a while since a quick decision
was taken to move the mailserver at pubhealth.ku.dk to a different
machine yesterday. (The move was planned, just not at that time, and
the old server had gottten into a disk full condition.) Since that
implied a switch of machine architecture, mails to R-bugs got
processed by a binary of the wrong kind and bounced.

This mail should test whether things are back up and running. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Fri Nov  7 14:27:47 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Nov  7 14:21:15 2003
Subject: [Rd] R-1.8.1 scheduled for November 21
Message-ID: <x2znf89ulo.fsf@biostat.ku.dk>


The release of R-1.8.1 is scheduled for Friday, November 21. 

Automatic generation of daily alpha releases should start tomorrow
(I'll do the first by hand later today) and switch to beta status on
Friday, November 14.

It would be good if package maintainers could get any planned changes
done as soon as possible, and test their packages carefully against
the alpha/beta releases.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From kwright at eskimo.com  Fri Nov  7 16:41:29 2003
From: kwright at eskimo.com (kwright@eskimo.com)
Date: Fri Nov  7 16:40:38 2003
Subject: [Rd] prompt function confusion (PR#4978)
Message-ID: <20031107154129.29713F424@slim.kubism.ku.dk>

Full_Name: Kevin Wright
Version: 1.8.0
OS: Windows 2000
Submission from: (NULL) (170.54.59.160)


(Apologies if this appears multiple times.  Web interface appeared to fail.)

Minor cosmetic issue 

The 'prompt' command contains this:

cat(strwrap(c(paste("Created file named", sQuote(filename),
"in the current directory."), paste("Edit the file and move it to the 
appropriate", "directory."))), sep="\n")

and thus ALWAYS says the file is created "in the current directory", even
when it has created the file elsewhere.

The documentation for 'getwd' says it returns the "current working 
directory."

Here is an example:

> getwd()
[1] "x:/"

> prompt(rf,filename="x:/R/rf.Rd")
Created file named 'x:/R/rf.Rd' in the current directory.
Edit the file and move it to the appropriate directory.

A simple fix would be to delete "in the current directory." from the 
prompt function.

A more detailed fix might parse the filename for the existence of a valid 
path.  If no path is included, then say "in the current directory".

Best,

Kevin Wright

From noetzold at medinf.mu-luebeck.de  Fri Nov  7 18:18:59 2003
From: noetzold at medinf.mu-luebeck.de (noetzold@medinf.mu-luebeck.de)
Date: Fri Nov  7 18:18:09 2003
Subject: [Rd] Suggestions to the man page (PR#4982)
Message-ID: <20031107171859.7DAFEF42A@slim.kubism.ku.dk>

#Wishlist bug

I like to suggest to add a hint regarding the system and local
'Renviron' file to the man page of R. Also, a 'man Renviron' could be of
value especially for a sysadmin, who is not familar with R.

sincerely
Axel N?tzold

Version r-base 1.8.0 on Debian GNU/Linux

From ggrothendieck at myway.com  Sat Nov  8 15:21:48 2003
From: ggrothendieck at myway.com (ggrothendieck@myway.com)
Date: Sat Nov  8 15:20:46 2003
Subject: [Rd] accessing windows clipboard from load and save (PR#4999)
Message-ID: <20031108142148.AB6D1F4FD@slim.kubism.ku.dk>

Full_Name: Gabor Grothendieck
Version: 1.7.1
OS: Windows 2000
Submission from: (NULL) (207.35.143.81)



   save(x,ascii=TRUE,file("clipboard")) 

works but 

   load(file("clipboard")) 

does not.

Even better would be if

   save(x,ascii=TRUE,"clipboard") 
and 
   load("clipboard")

worked as that would provide consistency with read.table("clipboard")

From edd at debian.org  Sat Nov  8 15:44:37 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat Nov  8 15:43:39 2003
Subject: [Rd] R-1.8.1 scheduled for November 21
In-Reply-To: <x2znf89ulo.fsf@biostat.ku.dk>
References: <x2znf89ulo.fsf@biostat.ku.dk>
Message-ID: <20031108144437.GA31904@sonny.eddelbuettel.com>

On Fri, Nov 07, 2003 at 02:27:47PM +0100, Peter Dalgaard wrote:
> 
> The release of R-1.8.1 is scheduled for Friday, November 21. 
> 
> Automatic generation of daily alpha releases should start tomorrow
> (I'll do the first by hand later today) and switch to beta status on
> Friday, November 14.
> 
> It would be good if package maintainers could get any planned changes
> done as soon as possible, and test their packages carefully against
> the alpha/beta releases.

FYI: Yesterday evening Debian packages of 1.8.1 alpha were uploaded which
will be available via the 'unstable' portions of the usual Debian mirrors.
As of right now, ia64, hppa, sparc, arm and powerpc have already built
packages too. I intend to do another release of '1.8.1 beta' next Friday.

Regards, Dirk


-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx

From dmurdoch at pair.com  Sat Nov  8 16:40:54 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat Nov  8 16:40:41 2003
Subject: [Rd] accessing windows clipboard from load and save (PR#4999)
In-Reply-To: <20031108142148.AB6D1F4FD@slim.kubism.ku.dk>
References: <20031108142148.AB6D1F4FD@slim.kubism.ku.dk>
Message-ID: <3s2qqv8oa86pn0ltgd7sufqvlep8copa2f@4ax.com>

On Sat,  8 Nov 2003 15:21:48 +0100 (CET), you wrote:

>Full_Name: Gabor Grothendieck
>Version: 1.7.1
>OS: Windows 2000
>Submission from: (NULL) (207.35.143.81)
>
>
>
>   save(x,ascii=TRUE,file("clipboard")) 
>
>works but 
>
>   load(file("clipboard")) 
>
>does not.

This is a documented limitation of the clipboard connection (which is
write-only), not a bug.  Yes, it would be nice if all clipboard
functions were supported, but they're not.  

>Even better would be if
>
>   save(x,ascii=TRUE,"clipboard") 
>and 
>   load("clipboard")
>
>worked as that would provide consistency with read.table("clipboard")

Is this documented somewhere?  I didn't know about it (but it does
work).

Personally, I'd rather have a connection created by a function named
clipboard(); it looks kludgy to interpret some filenames as magic
values.  Then your examples would be

save(x,ascii=TRUE,file=clipboard('w')) 

load(clipboard())

read.table(clipboard())

Another special connection (which might exist? I couldn't spot it)
would be one that read from a character vector, i.e. c('a','b','c')
would be read as 3 lines of one letter each.  Then something like

 stringConnection(readClipboard()) 

would be one way to implement clipboard().

Duncan Murdoch

From ripley at stats.ox.ac.uk  Sat Nov  8 16:47:31 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Nov  8 16:46:42 2003
Subject: [Rd] accessing windows clipboard from load and save (PR#4999)
In-Reply-To: <20031108142148.AB6D1F4FD@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0311081540160.8090-100000@gannet.stats>

Yet another report of a non-bug!

First, your example of the use of save() does not work.  That *is* a bug.

Second, please RTFM.  help(load) says

     'load' can load R objects saved in the current or any earlier
     format.  It can read a compressed file (see 'save') directly from
     a file or from a suitable connection.
                      ^^^^^^^^
and nothing says a clipboard is a suitable connection.

If you really want to make a positive contribution you could work out what
changes are necessary to make a clipboard a suitable connection and supply
a patch against the current sources (not an obselete version of R). Hints:
load expects to be able to open a connection in binary mode, and to wrap
it in a decompression wrapper.


On Sat, 8 Nov 2003 ggrothendieck@myway.com wrote:

> Full_Name: Gabor Grothendieck
> Version: 1.7.1
> OS: Windows 2000
> Submission from: (NULL) (207.35.143.81)
> 
> 
> 
>    save(x,ascii=TRUE,file("clipboard")) 
> 
> works but 
> 
>    load(file("clipboard")) 
> 
> does not.
> 
> Even better would be if
> 
>    save(x,ascii=TRUE,"clipboard") 
> and 
>    load("clipboard")
> 
> worked as that would provide consistency with read.table("clipboard")
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rpeng at jhsph.edu  Sat Nov  8 17:00:24 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sat Nov  8 16:55:24 2003
Subject: [Rd] No traceback in r-patched
Message-ID: <3FAD1318.4060002@jhsph.edu>

Since it's heading towards release, I thought I'd bring this up again. 
I'm still not getting any traceback()'s in recent R-patched.  For 
example, I get:

 > log("a")
Error in log(x) : Non-numeric argument to mathematical function
 > traceback()
No traceback available

Or when running the examples in the traceback() help page:

 >      foo <- function(x) { print(1); bar(2) }
 >      bar <- function(x) { x + a.variable.which.does.not.exist }
 >      ## Don't run:
 >      foo(2) # gives a strange error
[1] 1
Error in bar(2) : Object "a.variable.which.does.not.exist" not found
 >      traceback()
No traceback available

It seems the .Traceback variable is not being created.  If I'm doing 
something incorrectly, I'd very much like to know.  I'm starting up with 
R --vanilla.

 > version
          _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status   alpha
major    1
minor    8.1
year     2003
month    11
day      07
language R
 > search()
[1] ".GlobalEnv"      "package:methods" "package:ctest"   "package:mva"
[5] "package:modreg"  "package:nls"     "package:ts"      "Autoloads"
[9] "package:base"
 >


-roger

From ripley at stats.ox.ac.uk  Sat Nov  8 17:03:19 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Nov  8 17:02:46 2003
Subject: [Rd] accessing windows clipboard from load and save (PR#4999)
In-Reply-To: <3s2qqv8oa86pn0ltgd7sufqvlep8copa2f@4ax.com>
Message-ID: <Pine.LNX.4.44.0311081551160.8090-100000@gannet.stats>

On Sat, 8 Nov 2003, Duncan Murdoch wrote:

> Another special connection (which might exist? I couldn't spot it)
> would be one that read from a character vector, i.e. c('a','b','c')
> would be read as 3 lines of one letter each.  Then something like
> 
>  stringConnection(readClipboard()) 

It's called a textConnection:

> readLines(textConnection(c('a','b','c')))
[1] "a" "b" "c"

The problem here is not with the file("clipboard") connection but with the
documented restriction of load() to suitable connections, including
needing binary mode (which text connections don't have either).

The following *will* work

zz <- file("clipboard", "w")
save(x, ascii=TRUE, file=zz)
close(zz)
zz <- file("clipboard", "r")
readLines(zz, 1)
.Internal(loadFromConn(zz, .GlobalEnv))
close(zz)

so this can be done with existing functions (if one is prepared to do 
5 mins exploration, unlike some unhelpful people).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jago at mclink.it  Sat Nov  8 17:19:29 2003
From: jago at mclink.it (Stefano Iacus)
Date: Sat Nov  8 17:18:43 2003
Subject: [Rd] RAqua with X11 TclTk
Message-ID: <5423BF06-1207-11D8-848F-003065CC4CB8@mclink.it>

I've built a version of RAqua that uses X11 TclTk and NOT AquaTclTk.

http://www.economia.unimi.it/R/RAquaX11.dmg   (15 MB disk image)


The idea is that you: launch RAqua, launch X application (the X 
Server), and from inside R type

x11() # just tt set DISPLAY to :0.0. Eventually close this window 
device, we don't need this.
load(tcltk)
quartz()
demo(tkdensity)


It works on my Panther machine as well and it comes with three 
installers for: libreadline, tcltk (the X11 version) and the libxml2 in 
case you want to use the prebuilt XML package.


Thomas Lumley has found oddities in configuring/building R on Panther 
so I built it on Jaguar and it works as well on panther.


I would like to propose this version of RAqua for R-1.8.1, i.e. built 
only against X11/tcltk.

This will allow one binary only for R that can run tcltk from Emacs or 
phyton for example.

Could you please test it on Jaguar and Panther before the end of the 
next week?

I've built this version with the following config

./configure --enable-R-shlib --with-blas='-framework vecLib' 
--with-lapack --with-aqua

Of course, I have built from sources tck and tk 8.4.4.
If you want to do this take care to configure and build the tcl/tk 
sources from inside the "unix" directory.

stefano

From ggrothendieck at myway.com  Sat Nov  8 17:25:45 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat Nov  8 17:24:44 2003
Subject: [Rd] accessing windows clipboard from load and save (PR#4999)
Message-ID: <20031108162545.2F362397F@mprdmxin.myway.com>



The bug list is the only place to record and track suggestions.
I don't think it matters whether its a bug in the strict sense
of the word.  The clipboard should work consistently and orthogonally
across R.

Perhaps there could be a categorization of issues submitted to
the bug list to properly identify which are bugs in the narrow
sense, which are inconsistencies, which are feature enhancement
suggestions, etc.

 --- On Sat 11/08, Prof Brian Ripley < ripley@stats.ox.ac.uk > wrote:

Yet another report of a non-bug!

From deleeuw at stat.ucla.edu  Sat Nov  8 17:36:21 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sat Nov  8 17:35:40 2003
Subject: [Rd] RAqua with X11 TclTk
In-Reply-To: <5423BF06-1207-11D8-848F-003065CC4CB8@mclink.it>
References: <5423BF06-1207-11D8-848F-003065CC4CB8@mclink.it>
Message-ID: <AFB96C6E-1209-11D8-8257-000A95A67E82@stat.ucla.edu>

That's a somewhat unfortunate step back, and a rather drastic hack
to get around the eventloop problem. I make two versions of the tcltk
package, one in RAqua, one in /usr/local/lib/R/library (the X11  
version).
I then make softlinks from all packages in  /usr/local/lib/R/library to
~/Library/RAqua/library and then remove the softlinks to the packages
that are already in RAqua (including tcltk). Now the Emacs and
terminal versions use the X11 version and RAqua uses the Aqua
version of tcltk. http://gifi.stat.ucla.edu/pub gives the deatils,  
including
the ~/.emacs one needs.

I have no build problems in Panther, except the problem with g77-3.4
when compiling tseries. Go back to g77-3.3 for this and you're fine.  
Panther
fixes the pty bug in Darwin, and thus R now functions fine in Carbon,
command line, and X11 Emacs using X11 graphics. See
http://members.shaw.ca/akochoi-emacs/index.html

On Nov 8, 2003, at 8:19, Stefano Iacus wrote:

> I've built a version of RAqua that uses X11 TclTk and NOT AquaTclTk.
>
> http://www.economia.unimi.it/R/RAquaX11.dmg   (15 MB disk image)
>
>
> The idea is that you: launch RAqua, launch X application (the X  
> Server), and from inside R type
>
> x11() # just tt set DISPLAY to :0.0. Eventually close this window  
> device, we don't need this.
> load(tcltk)
> quartz()
> demo(tkdensity)
>
>
> It works on my Panther machine as well and it comes with three  
> installers for: libreadline, tcltk (the X11 version) and the libxml2  
> in case you want to use the prebuilt XML package.
>
>
> Thomas Lumley has found oddities in configuring/building R on Panther  
> so I built it on Jaguar and it works as well on panther.
>
>
> I would like to propose this version of RAqua for R-1.8.1, i.e. built  
> only against X11/tcltk.
>
> This will allow one binary only for R that can run tcltk from Emacs or  
> phyton for example.
>
> Could you please test it on Jaguar and Panther before the end of the  
> next week?
>
> I've built this version with the following config
>
> ./configure --enable-R-shlib --with-blas='-framework vecLib'  
> --with-lapack --with-aqua
>
> Of course, I have built from sources tck and tk 8.4.4.
> If you want to do this take care to configure and build the tcl/tk  
> sources from inside the "unix" directory.
>
> stefano
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From ripley at stats.ox.ac.uk  Sat Nov  8 17:45:11 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Nov  8 17:44:13 2003
Subject: [Rd] No traceback in r-patched
In-Reply-To: <3FAD1318.4060002@jhsph.edu>
Message-ID: <Pine.LNX.4.44.0311081618520.8306-100000@gannet.stats>

It is due to the addition to src/main/error.c:652

    if (traceback && ! oldInError) {
                  ^^^^^^^^^^^^^^^

so I think we need Luke's help.  By the time this is called inError has 
been saved twice, once as 0 and once as 1.  I suspect it should be inError
here rather than oldInError: one wants .Traceback created after error 
handling has almost finished.


On Sat, 8 Nov 2003, Roger D. Peng wrote:

> Since it's heading towards release, I thought I'd bring this up again. 
> I'm still not getting any traceback()'s in recent R-patched.  For 
> example, I get:
> 
>  > log("a")
> Error in log(x) : Non-numeric argument to mathematical function
>  > traceback()
> No traceback available
> 
> Or when running the examples in the traceback() help page:
> 
>  >      foo <- function(x) { print(1); bar(2) }
>  >      bar <- function(x) { x + a.variable.which.does.not.exist }
>  >      ## Don't run:
>  >      foo(2) # gives a strange error
> [1] 1
> Error in bar(2) : Object "a.variable.which.does.not.exist" not found
>  >      traceback()
> No traceback available
> 
> It seems the .Traceback variable is not being created.  If I'm doing 
> something incorrectly, I'd very much like to know.  I'm starting up with 
> R --vanilla.
> 
>  > version
>           _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status   alpha
> major    1
> minor    8.1
> year     2003
> month    11
> day      07
> language R
>  > search()
> [1] ".GlobalEnv"      "package:methods" "package:ctest"   "package:mva"
> [5] "package:modreg"  "package:nls"     "package:ts"      "Autoloads"
> [9] "package:base"
>  >
> 
> 
> -roger
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dmurdoch at pair.com  Sat Nov  8 17:45:35 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat Nov  8 17:44:43 2003
Subject: [Rd] accessing windows clipboard from load and save (PR#4999)
In-Reply-To: <Pine.LNX.4.44.0311081551160.8090-100000@gannet.stats>
References: <3s2qqv8oa86pn0ltgd7sufqvlep8copa2f@4ax.com>
	<Pine.LNX.4.44.0311081551160.8090-100000@gannet.stats>
Message-ID: <f86qqvgvl766jt8cnsfmthutr0eiv40opd@4ax.com>

On Sat, 8 Nov 2003 16:03:19 +0000 (GMT), you wrote:

>On Sat, 8 Nov 2003, Duncan Murdoch wrote:
>
>> Another special connection (which might exist? I couldn't spot it)
>> would be one that read from a character vector, i.e. c('a','b','c')
>> would be read as 3 lines of one letter each.  Then something like
>> 
>>  stringConnection(readClipboard()) 
>
>It's called a textConnection:
>
>> readLines(textConnection(c('a','b','c')))
>[1] "a" "b" "c"
>
>The problem here is not with the file("clipboard") connection but with the
>documented restriction of load() to suitable connections, including
>needing binary mode (which text connections don't have either).

I was misled by a typo in the man page for file, where it says:

    Under Windows, 'file' can also be used with 'description =
    "clipboard"' in mode '"w"' and '"w"' only.

Presumably that should be "in modes '"r"' and '"w"'."

In the ?load page, I see the words "suitable connection", but I don't
see any mention of binary access being required.  Is that documented
somewhere?

I guess it comes from the use of gzcon in load.  Couldn't the
restriction be removed by having gzcon treat any text mode connection
as uncompressed?

Duncan Murdoch

From jago at mclink.it  Sat Nov  8 17:50:34 2003
From: jago at mclink.it (Stefano Iacus)
Date: Sat Nov  8 17:51:04 2003
Subject: [Rd] RAqua with X11 TclTk
In-Reply-To: <AFB96C6E-1209-11D8-8257-000A95A67E82@stat.ucla.edu>
Message-ID: <ABD3F972-120B-11D8-848F-003065CC4CB8@mclink.it>


On Sabato, nov 8, 2003, at 17:36 Europe/Rome, Jan de Leeuw wrote:

> That's a somewhat unfortunate step back, and a rather drastic hack
> to get around the eventloop problem.

yes, but only for 1.8.1, event loop changes requires time and it is  
planned not before 1.9.0

> I make two versions of the tcltk
> package, one in RAqua, one in /usr/local/lib/R/library (the X11  
> version).
> I then make softlinks from all packages in  /usr/local/lib/R/library to
> ~/Library/RAqua/library and then remove the softlinks to the packages
> that are already in RAqua (including tcltk). Now the Emacs and
> terminal versions use the X11 version and RAqua uses the Aqua
> version of tcltk. http://gifi.stat.ucla.edu/pub gives the deatils,  
> including
> the ~/.emacs one needs.

Jan, the AquaTclTk does not seem to work fine at the moment.
I can say more: you can try to run (from CRAN RAqua which is AquaTclTk)  
the R cmd line from an xterm and load the tcltk library. And you have  
Aquatcltk from X11 !


>
> I have no build problems in Panther, except the problem with g77-3.4
> when compiling tseries.
apparently we cannot build correctly R-devel on Panther. Try to launch  
x11() from RAqua console built on Panther using Apple's gcc and please  
let us know if it works for you.


> Go back to g77-3.3 for this and you're fine. Panther
> fixes the pty bug in Darwin, and thus R now functions fine in Carbon,
> command line, and X11 Emacs using X11 graphics. See
> http://members.shaw.ca/akochoi-emacs/index.html
>
> On Nov 8, 2003, at 8:19, Stefano Iacus wrote:
>
>> I've built a version of RAqua that uses X11 TclTk and NOT AquaTclTk.
>>
>> http://www.economia.unimi.it/R/RAquaX11.dmg   (15 MB disk image)
>>
>>
>> The idea is that you: launch RAqua, launch X application (the X  
>> Server), and from inside R type
>>
>> x11() # just tt set DISPLAY to :0.0. Eventually close this window  
>> device, we don't need this.
>> load(tcltk)
>> quartz()
>> demo(tkdensity)
>>
>>
>> It works on my Panther machine as well and it comes with three  
>> installers for: libreadline, tcltk (the X11 version) and the libxml2  
>> in case you want to use the prebuilt XML package.
>>
>>
>> Thomas Lumley has found oddities in configuring/building R on Panther  
>> so I built it on Jaguar and it works as well on panther.
>>
>>
>> I would like to propose this version of RAqua for R-1.8.1, i.e. built  
>> only against X11/tcltk.
>>
>> This will allow one binary only for R that can run tcltk from Emacs  
>> or phyton for example.
>>
>> Could you please test it on Jaguar and Panther before the end of the  
>> next week?
>>
>> I've built this version with the following config
>>
>> ./configure --enable-R-shlib --with-blas='-framework vecLib'  
>> --with-lapack --with-aqua
>>
>> Of course, I have built from sources tck and tk 8.4.4.
>> If you want to do this take care to configure and build the tcl/tk  
>> sources from inside the "unix" directory.
>>
>> stefano
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>
>>
> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> Editor: Journal of Multivariate Analysis, Journal of Statistical  
> Software
> US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA  
> 90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email:  
> deleeuw@stat.ucla.edu
> homepage: http://gifi.stat.ucla.edu
>   
> ----------------------------------------------------------------------- 
> --------------------------
>           No matter where you go, there you are. --- Buckaroo Banzai
>                    http://gifi.stat.ucla.edu/sounds/nomatter.au
>   
> ----------------------------------------------------------------------- 
> --------------------------
>
>

From ggrothendieck at myway.com  Sat Nov  8 17:55:56 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat Nov  8 17:54:53 2003
Subject: [Rd] accessing windows clipboard from load and save (PR#4999)
Message-ID: <20031108165556.45D84397F@mprdmxin.myway.com>



I agree that that would be a cleaner solution.

 --- On Sat 11/08, Duncan Murdoch < dmurdoch@pair.com > wrote:
Personally, I'd rather have a connection created by a function named
clipboard(); it looks kludgy to interpret some filenames as magic
values.

From deleeuw at stat.ucla.edu  Sat Nov  8 18:07:13 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sat Nov  8 18:07:30 2003
Subject: [Rd] RAqua with X11 TclTk
In-Reply-To: <ABD3F972-120B-11D8-848F-003065CC4CB8@mclink.it>
References: <ABD3F972-120B-11D8-848F-003065CC4CB8@mclink.it>
Message-ID: <FF0E1322-120D-11D8-8257-000A95A67E82@stat.ucla.edu>


Running x11() or plot(1:10) from command line R running in Terminal.app  
or in Xterm.app
is fine. This is R-devel and OS X 10.3.1.


On Nov 8, 2003, at 8:50, Stefano Iacus wrote:

>
> On Sabato, nov 8, 2003, at 17:36 Europe/Rome, Jan de Leeuw wrote:
>
>> That's a somewhat unfortunate step back, and a rather drastic hack
>> to get around the eventloop problem.
>
> yes, but only for 1.8.1, event loop changes requires time and it is  
> planned not before 1.9.0
>
>> I make two versions of the tcltk
>> package, one in RAqua, one in /usr/local/lib/R/library (the X11  
>> version).
>> I then make softlinks from all packages in  /usr/local/lib/R/library  
>> to
>> ~/Library/RAqua/library and then remove the softlinks to the packages
>> that are already in RAqua (including tcltk). Now the Emacs and
>> terminal versions use the X11 version and RAqua uses the Aqua
>> version of tcltk. http://gifi.stat.ucla.edu/pub gives the deatils,  
>> including
>> the ~/.emacs one needs.
>
> Jan, the AquaTclTk does not seem to work fine at the moment.
> I can say more: you can try to run (from CRAN RAqua which is  
> AquaTclTk) the R cmd line from an xterm and load the tcltk library.  
> And you have Aquatcltk from X11 !
>
>
>>
>> I have no build problems in Panther, except the problem with g77-3.4
>> when compiling tseries.
> apparently we cannot build correctly R-devel on Panther. Try to launch  
> x11() from RAqua console built on Panther using Apple's gcc and please  
> let us know if it works for you.
>
>
>> Go back to g77-3.3 for this and you're fine. Panther
>> fixes the pty bug in Darwin, and thus R now functions fine in Carbon,
>> command line, and X11 Emacs using X11 graphics. See
>> http://members.shaw.ca/akochoi-emacs/index.html
>>
>> On Nov 8, 2003, at 8:19, Stefano Iacus wrote:
>>
>>> I've built a version of RAqua that uses X11 TclTk and NOT AquaTclTk.
>>>
>>> http://www.economia.unimi.it/R/RAquaX11.dmg   (15 MB disk image)
>>>
>>>
>>> The idea is that you: launch RAqua, launch X application (the X  
>>> Server), and from inside R type
>>>
>>> x11() # just tt set DISPLAY to :0.0. Eventually close this window  
>>> device, we don't need this.
>>> load(tcltk)
>>> quartz()
>>> demo(tkdensity)
>>>
>>>
>>> It works on my Panther machine as well and it comes with three  
>>> installers for: libreadline, tcltk (the X11 version) and the libxml2  
>>> in case you want to use the prebuilt XML package.
>>>
>>>
>>> Thomas Lumley has found oddities in configuring/building R on  
>>> Panther so I built it on Jaguar and it works as well on panther.
>>>
>>>
>>> I would like to propose this version of RAqua for R-1.8.1, i.e.  
>>> built only against X11/tcltk.
>>>
>>> This will allow one binary only for R that can run tcltk from Emacs  
>>> or phyton for example.
>>>
>>> Could you please test it on Jaguar and Panther before the end of the  
>>> next week?
>>>
>>> I've built this version with the following config
>>>
>>> ./configure --enable-R-shlib --with-blas='-framework vecLib'  
>>> --with-lapack --with-aqua
>>>
>>> Of course, I have built from sources tck and tk 8.4.4.
>>> If you want to do this take care to configure and build the tcl/tk  
>>> sources from inside the "unix" directory.
>>>
>>> stefano
>>>
>>> ______________________________________________
>>> R-devel@stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>> ===
>> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
>> Editor: Journal of Multivariate Analysis, Journal of Statistical  
>> Software
>> US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA  
>> 90095-1554
>> phone (310)-825-9550;  fax (310)-206-5658;  email:  
>> deleeuw@stat.ucla.edu
>> homepage: http://gifi.stat.ucla.edu
>>   
>> ---------------------------------------------------------------------- 
>> ---------------------------
>>           No matter where you go, there you are. --- Buckaroo Banzai
>>                    http://gifi.stat.ucla.edu/sounds/nomatter.au
>>   
>> ---------------------------------------------------------------------- 
>> ---------------------------
>>
>>
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From ggrothendieck at myway.com  Sat Nov  8 18:17:07 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat Nov  8 18:16:10 2003
Subject: [Rd] accessing windows clipboard from load and save (PR#4999)
Message-ID: <20031108171707.4A9A83981@mprdmxin.myway.com>



Regarding, loading a file from the clipboard, I had also posted 
a workaround:

   load(pipe("pclip"))

where pclip is from unxutils.sourceforge.net, although yours has
the advantage of not requiring external programs.

 --- On Sat 11/08, Prof Brian Ripley < ripley@stats.ox.ac.uk > wrote:

zz <- file("clipboard", "r")
readLines(zz, 1)
.Internal(loadFromConn(zz, .GlobalEnv))
close(zz)

From deleeuw at stat.ucla.edu  Sat Nov  8 18:55:20 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sat Nov  8 18:54:18 2003
Subject: [Rd] what works and what not
Message-ID: <B808E948-1214-11D8-8257-000A95A67E82@stat.ucla.edu>

r-devel, os x 10.3.1, tcl/tk 8.5 (unix and aqua), "gifi" setup
=======================================================
plot(1:10)
library(tcltk)
demo(tkdensity)

works from Terminal, XTerm, and using ESS in Carbon Emacs, X11 Emacs,
XTerm Emacs,  Terminal Emacs, using X11 graphics throughout.
=======================================================
x11()
plot(1:10)

works from RAqua using X11.
=======================================================
library(tcltk)
demo(tkdensity)

in RAqua starts things, messes up the menus, and clobbers most of the  
mouse
interaction. Not usable.
=======================================================
library(tcltk)
tkStartGUI()
demo(tkdensity) in tkStartGUI

works OK in RAqua. Hack !
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From ckm at loafer.org  Sun Nov  9 04:20:48 2003
From: ckm at loafer.org (ckm@loafer.org)
Date: Sun Nov  9 04:19:48 2003
Subject: [Rd] PR#2823
Message-ID: <20031109032048.11EC9F531@slim.kubism.ku.dk>

From ripley at stats.ox.ac.uk  Sun Nov  9 14:25:40 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Nov  9 14:24:34 2003
Subject: [Rd] PR#4195
Message-ID: <20031109132540.A823BF560@slim.kubism.ku.dk>

I've taken a look at this. What the R code does is to recalculate the
nearest neighbours & distances after updating the distances, for all
clusters other than the new one which it attempted to do on the fly.  
The problem is that merging two clusters can make distances to the cluster
go up and so what was a nearest neighbour may stop being so, as well as
the reverse.  So I am not convinced that the correction is in fact enough
(what if i2 had previously been the nearest neighbour of k?) although this 
may not affect the later steps.

It is as fast just to update all nearest neighbours, and I have changed
the R code to do so. It is a lot easier to convince oneself that the code
gives the correct answer! I now get an answer much closer to yours and
hope the difference is due to rounding errors in dumping the dataset. (It
is also what I got by incorporating the fix in the C code you pointed us
to.)

BDR

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sun Nov  9 14:55:35 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Nov  9 14:54:46 2003
Subject: [Rd] dump/source problem with hclust object (PR#4361)
In-Reply-To: <200309301728.h8UHSv0P021798@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0311091353550.25609-100000@gannet.stats>

For the record, this is due to a storage mode problem: the merge component
gets restored as double.  I've modified plot.hclust to detect that.

On Tue, 30 Sep 2003 kleiweg@let.rug.nl wrote:

> 
> 
>     library(mva)
>     data(USArrests)
>     hc <- hclust(dist(USArrests), "ave")
> 
>     plot(hc)              # OK
> 
>     dump(c("hc"), "tst")
>     rm(hc)
>     source("tst")
> 
>     plot(hc)              # Error in plot.hclust(hc) : invalid dendrogram input
> 
> 
> The same problem occurs with dput/dget
> 
> 
> 
> 
> --please do not edit the information below--
> 
> Version:
>  platform = i686-pc-linux-gnu
>  arch = i686
>  os = linux-gnu
>  system = i686, linux-gnu
>  status =
>  major = 1
>  minor = 7.1
>  year = 2003
>  month = 06
>  day = 16
>  language = R
> 
> Search Path:
>  .GlobalEnv, package:methods, package:ctest, package:mva,
> package:modreg, package:nls, package:ts, Autoloads, package:base
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From princessjoymswati at princessjoymswati.net  Sun Nov  9 15:05:15 2003
From: princessjoymswati at princessjoymswati.net (princessjoymswati@princessjoymswati.net)
Date: Sun Nov  9 15:04:09 2003
Subject: [Rd] PRINCESS.J.MSWATI WRITE ONBEHALF OF IBRAHIM KAMARA (PR#5012)
Message-ID: <20031109140515.25245F55D@slim.kubism.ku.dk>


ATTN:=0AON BEHALF OF IBRAHIM KAMARA,I PRINCESS JOY MSWATI PROPOSES THIS PRO=
JECT TO YOU:=0ARecieve a one time payment of $500.000 and another 5% from s=
ales of diamonds by assisting in a project of mutual benefits...=0AFor Furt=
her enquiries about this project,contact IBRAHIM KAMARA on his E mail =0Aib=
rahimkamara123@netscape.net=0ATel:=0ABest regards.=0APRINCESS JOY MSWATI=0A

From alistair at statsresearch.co.nz  Mon Nov 10 08:27:07 2003
From: alistair at statsresearch.co.nz (alistair@statsresearch.co.nz)
Date: Mon Nov 10 08:26:01 2003
Subject: [Rd] ts package function filter: mismatch between function action
	and help (PR#5017)
Message-ID: <20031110072707.85BE0F5C2@slim.kubism.ku.dk>

Dear people,

I'm running
RedHat 9.0
and
R : Version 1.7.1  (2003-06-16)

from the help file

# Usage:
#
#     filter(x, filter, method = c("convolution", "recursive"),
#            sides = 2, circular = FALSE, init)

#    init: for recursive filters only. Specifies the initial values of
#          the time series just prior to the start value, in reverse
#          time order. The default is a set of zeros.

but looks as if it should be in usual order as x is e.g.

init  y_0 y_-1 y_-2: 3, 2, 1
filter f_1 f_2 f_3: 1, .5, .25
x: 4, 5, 6, 7, 8

y_1 = 4 + 1*3 + .5*2 + .25*1 = 8.25
y_2 = 5 + 1*8.25 + .5*3 + .25*2 = 15.25
...

but

 > filter(4:8,c(1,.5,.25),method="recursive", init=3:1)
Time Series:
Start = 1
End = 5
Frequency = 1
[1]  6.7500 12.7500 22.3750 37.4375 59.8125

whereas

 > filter(4:8,c(1,.5,.25),method="recursive", init=1:3)
Time Series:
Start = 1
End = 5
Frequency = 1
[1]  8.2500 15.2500 26.1250 42.8125 67.6875

Look forward to your response
thanks
Alistair
-- 
Alistair Gray                       Email:  alistair@statsresearch.co.nz
Statistics Research Associates Ltd  Web:    www.statsresearch.co.nz
PO Box 12 649, Thorndon, Wellington Phone:  +64 +4 972 6531
NEW ZEALAND                         Mobile: +64 +21 610 569

From ripley at stats.ox.ac.uk  Mon Nov 10 09:12:29 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Nov 10 09:11:24 2003
Subject: (PR#5017) [Rd] ts package function filter: mismatch between
	function action and help
In-Reply-To: <20031110072707.85BE0F5C2@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0311100806200.21158-100000@gannet.stats>

The documentation is what is intended to happen (for compatibility with
S), so the code is wrong. I've altered the code for R 1.8.1.

On Mon, 10 Nov 2003 alistair@statsresearch.co.nz wrote:

> Dear people,
> 
> I'm running
> RedHat 9.0
> and
> R : Version 1.7.1  (2003-06-16)
> 
> from the help file
> 
> # Usage:
> #
> #     filter(x, filter, method = c("convolution", "recursive"),
> #            sides = 2, circular = FALSE, init)
> 
> #    init: for recursive filters only. Specifies the initial values of
> #          the time series just prior to the start value, in reverse
> #          time order. The default is a set of zeros.
> 
> but looks as if it should be in usual order as x is e.g.
> 
> init  y_0 y_-1 y_-2: 3, 2, 1
> filter f_1 f_2 f_3: 1, .5, .25
> x: 4, 5, 6, 7, 8
> 
> y_1 = 4 + 1*3 + .5*2 + .25*1 = 8.25
> y_2 = 5 + 1*8.25 + .5*3 + .25*2 = 15.25
> ...
> 
> but
> 
>  > filter(4:8,c(1,.5,.25),method="recursive", init=3:1)
> Time Series:
> Start = 1
> End = 5
> Frequency = 1
> [1]  6.7500 12.7500 22.3750 37.4375 59.8125
> 
> whereas
> 
>  > filter(4:8,c(1,.5,.25),method="recursive", init=1:3)
> Time Series:
> Start = 1
> End = 5
> Frequency = 1
> [1]  8.2500 15.2500 26.1250 42.8125 67.6875
> 
> Look forward to your response
> thanks
> Alistair
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From luke at stat.uiowa.edu  Mon Nov 10 15:54:33 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon Nov 10 15:55:12 2003
Subject: [Rd] No traceback in r-patched
In-Reply-To: <3FAD1318.4060002@jhsph.edu>
Message-ID: <Pine.LNX.4.44.0311100853210.14925-100000@itasca.stat.uiowa.edu>

Thanks.  Seems this slipped in while fixing another issue (surprising
it wasn't noticed until now).  Should be fixed in a day or two.

Best,

luke

On Sat, 8 Nov 2003, Roger D. Peng wrote:

> Since it's heading towards release, I thought I'd bring this up again. 
> I'm still not getting any traceback()'s in recent R-patched.  For 
> example, I get:
> 
>  > log("a")
> Error in log(x) : Non-numeric argument to mathematical function
>  > traceback()
> No traceback available
> 
> Or when running the examples in the traceback() help page:
> 
>  >      foo <- function(x) { print(1); bar(2) }
>  >      bar <- function(x) { x + a.variable.which.does.not.exist }
>  >      ## Don't run:
>  >      foo(2) # gives a strange error
> [1] 1
> Error in bar(2) : Object "a.variable.which.does.not.exist" not found
>  >      traceback()
> No traceback available
> 
> It seems the .Traceback variable is not being created.  If I'm doing 
> something incorrectly, I'd very much like to know.  I'm starting up with 
> R --vanilla.
> 
>  > version
>           _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status   alpha
> major    1
> minor    8.1
> year     2003
> month    11
> day      07
> language R
>  > search()
> [1] ".GlobalEnv"      "package:methods" "package:ctest"   "package:mva"
> [5] "package:modreg"  "package:nls"     "package:ts"      "Autoloads"
> [9] "package:base"
>  >
> 
> 
> -roger
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From qj653hz at yahoo.com  Mon Nov 10 19:56:21 2003
From: qj653hz at yahoo.com (qj653hz@yahoo.com)
Date: Mon Nov 10 19:55:22 2003
Subject: [Rd] R-bugs, best cablebox... pccxw (PR#5024)
Message-ID: <20031110185621.B8BACF690@slim.kubism.ku.dk>


--3E108.__70F
Content-Type: text/html;
Content-Transfer-Encoding: base64

PGJvZHk+DQo8aW5wdXQgZmdsbmZ3dWQgZnkgdHlwZT0iaGlkZGVuIiB2YWx1ZT0iZWJmYmJl
YXdpbGEgc3R4Zm55aSBkeHcgDQp6YXcgaWJmZ3F5dmllaXVhayBocGEgcSI+DQo8cD5OPC9z
ZWFsPm8gTjwvd29vbD5lZWQgdDwvZGVzcGVyYXRlPm8gY2FiPC9nJ3M+bGUgYmk8L2NoZWV0
YWg+bGxzLi4uDQogdGg8L2NvbnN0aXR1ZW50PmUgYmU8L21pcmE+c3QgQ2E8L2RyZXc+Ymxl
IEI8L2FuZHJldz5veC4uIA0KPGEgaHJlZj0iaHR0cDovL2ltbXVub2VsZWN0cm9waG9yZXNp
czpjaGFyQHd3dy5jcmVkaXRjYXJkMjAwMy5jb20vY2FibGVib3gvIj4gc2VlPC9jb25mZXI+
bm93PC9hPjwvcD4NCjxwPjxhIGhyZWY9Imh0dHA6Ly9zeW5vcHRpYzphYmxhdGVAd3d3LmNy
ZWRpdGNhcmQyMDAzLmNvbS9jYWJsZWJveC8iPg0KPGlucHV0IHJqeWppIA0KdHdkIHUgY2Mg
eXgNCmF2aG9sbHVyc3d6Y2sgcWRiIG4NCmpjZ2lxZHFvcmEgIGd4YWxlYW4NCiAgdHlwZT0i
aGlkZGVuIiB2YWx1ZT0ic2trbm4gdm1qY2J2YiBlIHZ2aHRmeWZtbiI+DQo8aW1nIGJvcmRl
cj0iMCIgc3JjPSJodHRwOi8vd3d3LmNyZWRpdGNhcmQyMDAzLmNvbS9jYjMuanBnIj48L2E+
PC9wPg0KPGlucHV0IHNoaGxxaGJhIGIgdWN5emt4DQphbHB1ICB2dXNmZnpvZXEgbWFkaCB3
dmdkeGxueWogIGggIGVmIHZ6ZyB0eXBlPSJoaWRkZW4iIHZhbHVlPSJhZ25kcWkgIHplbw0K
IHJpYXJxdW9wayB2cm90eWtybGtqcWVteXV1aHl0ZW5maCBvIHhoY2NuYWRlY2N1ZnMga3dv
eHdxcm9veHVqdm1wbHcgeSI+DQo8L2JvZHk+bHhwZG5mbm8gcWNqdm5zIGRrIGcgdg0KDQpq
ICBreXdrICBkZiB0eCAgZXhtZW94ZGxheG1mcSAgIHVnenFuanp5anF5dGRhIGJ3IGl2aWsg
ZWpxIHk=



--3E108.__70F--

From cxmdx90 at canada.com  Mon Nov 10 22:42:47 2003
From: cxmdx90 at canada.com (cxmdx90@canada.com)
Date: Mon Nov 10 22:41:38 2003
Subject: [Rd] RE: no /\\Bossssssssssssssssssss vaj qgdo qe f (PR#5025)
Message-ID: <20031110214247.7B9AFF626@slim.kubism.ku.dk>


--FA_CF71A6AE39D254E9AD7
Content-Type: text/html;
Content-Transfer-Encoding: base64
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--FA_CF71A6AE39D254E9AD7--

From vhtkwkbbv at aol.com  Mon Nov 10 23:56:03 2003
From: vhtkwkbbv at aol.com (vhtkwkbbv@aol.com)
Date: Mon Nov 10 23:54:51 2003
Subject: [Rd] Do something about your mortgage while you still can (PR#5026)
Message-ID: <20031110225603.5A824F63B@slim.kubism.ku.dk>


--DEE.D8D9143A2E
Content-Type: text/html;
Content-Transfer-Encoding: base64

PHA+RnJlZSBRdW90ZXMgQXZhaWxhYmxlIGZyb20gMyBsZW5kZXJzPGJyPg0KPGEgaHJlZj0i
aHR0cDovL3d3dy5lbG9hbnF1b3RlLm5ldC9mcmVlcXVvdGUuYXNweD9zaXRlaWQ9bmV0bWFy
a2V0aW5nLTEwMiI+PGltZyBzcmM9Imh0dHA6Ly93d3cuZWxvYW5xdW90ZS5uZXQvKHlqb3po
djU1dmJraHExMjNnenJ1cnI0NSkvX2ltYWdlcy9oZWFkZXIuanBnIiBib3JkZXI9IjAiPjwv
YT5peiB2aGdza3V2aWloYnp4eCBudnFteHAgYWh1ZW5vcA0Kc2h0bmFodHh2bWUNCiB3cCAg
YXlmICBtIGlxeHd6cWZla21yZ2Jta3RkDQogdm0NCmFvZmZvICBiIGYgDQp3ZXBx



--DEE.D8D9143A2E--

From ripley at stats.ox.ac.uk  Tue Nov 11 08:58:23 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Nov 11 08:57:25 2003
Subject: (PR#4955) [Rd] read.table leaves out data when reading
	multiple-line records
In-Reply-To: <200311051514.hA5FED0P008815@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0311110754370.8705-100000@gannet.stats>

That isn't a file in table format, and so is not supported.

Use scan if you want multi-line records.


On Wed, 5 Nov 2003 joehl@gmx.de wrote:

> 
> 
> Dear all,
> 
> I discovered that read.table (RW1.8.0) leaves out data when reading
> multiple-line records.
> 
> Replication code at the end
> 
> Best regards
> 
> 
> Jens Oehlschl?gel
> 
> 
> > filename <- "c:/tmp/c2.csv"
> > 
> > data <- data.frame(a=c("c", "e\nnewline"), b=c("d", '"quoted
> simpleline"'))
> > 
> > #look at the data
> > write.table(data, sep=",", row.names=FALSE)
> "a","b"
> "c","d"
> "e
> newline","\"quoted simpleline\""
> > 
> > # write it out
> > write.table(data, sep=",", row.names=FALSE, file=filename)
> > 
> > # reading it in a line is missing
> > read.csv(filename)
>            a                     b
> 1 e\nnewline \\quoted simpleline\\
> > 
> > fc <- file(filename, open="r")
> > 
> > # the problem seems to be
> > # readTableHead erroneously counts 3 lines as 4
> > lines <- .Internal(readTableHead(fc, 4, "", TRUE))
> > lines
> [1] "\"a\",\"b\""                             "\"c\",\"d\""                 
>            "\"e"                                    
> [4] "newline\",\"\\\"quoted simpleline\\\"\""
> > 
> > # double pushback is fine
> > pushBack(c(lines,lines), fc)
> > 
> > # but nlines tells us we had 4 lines, which in fact are only 3
> > nlines <- length(lines)
> > nlines
> [1] 4
> > 
> > # and the first scan eats up more than the first pushback
> > scan(fc, what="string", sep=",", nlines=nlines)
> Read 8 items
> [1] "a"                     "b"                     "c"                    
> "d"                     "e\nnewline"           
> [6] "\\quoted simpleline\\" "a"                     "b"                    
> > 
> > # thus the real scan misses data
> > scan(fc, what="string", sep=",")
> Read 4 items
> [1] "c"                     "d"                     "e\nnewline"           
> "\\quoted simpleline\\"
> > 
> > close(fc)
> > 
> > version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    8.0            
> year     2003           
> month    10             
> day      08             
> language R
> 
> 
> 
> 
> filename <- "c:/tmp/c2.csv"
> 
> data <- data.frame(a=c("c", "e\nnewline"), b=c("d", '"quoted simpleline"'))
> 
> #look at the data
> write.table(data, sep=",", row.names=FALSE)
> 
> # write it out
> write.table(data, sep=",", row.names=FALSE, file=filename)
> 
> # reading it in a line is missing	
> read.csv(filename)
> 
> fc <- file(filename, open="r")
> 
> # the problem seems to be
> # readTableHead erroneously counts 3 lines as 4
> lines <- .Internal(readTableHead(fc, 4, "", TRUE))
> lines
> 
> # double pushback is fine
> pushBack(c(lines,lines), fc)
> 
> # but nlines tells us we had 4 lines, which in fact are only 3
> nlines <- length(lines)
> nlines
> 
> # and the first scan eats up more than the first pushback
> scan(fc, what="string", sep=",", nlines=nlines)
> 
> # thus the real scan misses data
> scan(fc, what="string", sep=",")
> 
> close(fc)
> 
> version
> 
> 
> --
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Tue Nov 11 09:38:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Nov 11 09:37:33 2003
Subject: [Rd] Mismatches in predict(newdata)
Message-ID: <Pine.LNX.4.44.0311110828540.23470-100000@gannet.stats>

One of the reports recently was of predict.lm misbehaving if 
newdata=data.frame(x=rep(NA, 10)) was given a logical column when it had 
been fitted as a numeric one.

The exact problem was because model.matrix was trying to handle a 0-level 
factor (which is what that logical column got converted to by 
contrasts<-).  However, the problem is more general and I have added to 
R-devel a layer of protection.

When model.frame is called, it adds to its terms attribute an attribute
"dataClasses", and this can be checked against the newdata argument by a 
call to .checkMFClasses:  see lm and predict.lm for how to do so.
Developers who use predict(newdata) may wish to add such code to their 
packages.  (You can use

        if (!is.null(cl <- attr(Terms, "dataClasses")) &&
            exists(".checkMFClasses", envir=NULL)) 
            .checkMFClasses(cl, m)

to be backwards compatible.)

The exact nature of the `classes' is tricky because of inheritance. I have
implemented logical, ordered, factor (not ordered), numeric (not matrix),
nmatrix.n and other: nmatrix.n is a numeric matrix of n columns (as used
by poly() and bs(), for example).  Let me know if you see a need for other 
categories.

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From luke at stat.uiowa.edu  Tue Nov 11 12:44:24 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue Nov 11 12:43:22 2003
Subject: [Rd] No traceback in r-patched
In-Reply-To: <Pine.LNX.4.44.0311100853210.14925-100000@itasca.stat.uiowa.edu>
Message-ID: <Pine.LNX.4.44.0311110543550.27596-100000@itasca2.stat.uiowa.edu>

Should be fixed in R-patched and R-devel.

Best,

luke

On Mon, 10 Nov 2003, Luke Tierney wrote:

> Thanks.  Seems this slipped in while fixing another issue (surprising
> it wasn't noticed until now).  Should be fixed in a day or two.
> 
> Best,
> 
> luke
> 
> On Sat, 8 Nov 2003, Roger D. Peng wrote:
> 
> > Since it's heading towards release, I thought I'd bring this up again. 
> > I'm still not getting any traceback()'s in recent R-patched.  For 
> > example, I get:
> > 
> >  > log("a")
> > Error in log(x) : Non-numeric argument to mathematical function
> >  > traceback()
> > No traceback available
> > 
> > Or when running the examples in the traceback() help page:
> > 
> >  >      foo <- function(x) { print(1); bar(2) }
> >  >      bar <- function(x) { x + a.variable.which.does.not.exist }
> >  >      ## Don't run:
> >  >      foo(2) # gives a strange error
> > [1] 1
> > Error in bar(2) : Object "a.variable.which.does.not.exist" not found
> >  >      traceback()
> > No traceback available
> > 
> > It seems the .Traceback variable is not being created.  If I'm doing 
> > something incorrectly, I'd very much like to know.  I'm starting up with 
> > R --vanilla.
> > 
> >  > version
> >           _
> > platform i686-pc-linux-gnu
> > arch     i686
> > os       linux-gnu
> > system   i686, linux-gnu
> > status   alpha
> > major    1
> > minor    8.1
> > year     2003
> > month    11
> > day      07
> > language R
> >  > search()
> > [1] ".GlobalEnv"      "package:methods" "package:ctest"   "package:mva"
> > [5] "package:modreg"  "package:nls"     "package:ts"      "Autoloads"
> > [9] "package:base"
> >  >
> > 
> > 
> > -roger
> > 
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> > 
> 
> 

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From stefano.iacus at unimi.it  Tue Nov 11 22:17:17 2003
From: stefano.iacus at unimi.it (Stefano Iacus)
Date: Tue Nov 11 22:16:41 2003
Subject: [Rd] help.start
Message-ID: <6D7B32A2-148C-11D8-848F-003065CC4CB8@unimi.it>

Some user reported me that help.start() is no longer working on Panther 
under RAqua.
I don't have this problem on my machine but a couple of users repoterd 
me this.

Can you please make this small test an eventually tell me which is your 
system default browser?

stefano

From deleeuw at stat.ucla.edu  Wed Nov 12 00:42:58 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Wed Nov 12 00:42:05 2003
Subject: [Rd] help.start
In-Reply-To: <6D7B32A2-148C-11D8-848F-003065CC4CB8@unimi.it>
References: <6D7B32A2-148C-11D8-848F-003065CC4CB8@unimi.it>
Message-ID: <C79B5512-14A0-11D8-814A-000A95A67E82@stat.ucla.edu>

I have a /usr/local/bin/netscape script with

#!/bin/sh
open /usr/local/lib/R/doc/html/index.html

which means help.start() starts Safari.

On Nov 11, 2003, at 13:17, Stefano Iacus wrote:

> Some user reported me that help.start() is no longer working on  
> Panther under RAqua.
> I don't have this problem on my machine but a couple of users repoterd  
> me this.
>
> Can you please make this small test an eventually tell me which is  
> your system default browser?
>
> stefano
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From 62ngayvqu at web.de  Wed Nov 12 02:56:20 2003
From: 62ngayvqu at web.de (62ngayvqu@web.de)
Date: Wed Nov 12 02:55:12 2003
Subject: [Rd] RE: Hi HIHiHiaa xrts (PR#5040)
Message-ID: <20031112015620.48E1CF7D6@slim.kubism.ku.dk>


--1D6DDFD2D__C8D4F_EEA
Content-Type: text/html;
Content-Transfer-Encoding: base64
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--1D6DDFD2D__C8D4F_EEA--

From s0elyn at earthlink.net  Wed Nov 12 03:02:57 2003
From: s0elyn at earthlink.net (s0elyn@earthlink.net)
Date: Wed Nov 12 03:01:48 2003
Subject: [Rd] Fwd: R-bugs,
	Get Rid of SPAM for GOOD qe hqfsumwzbkgcg (PR#5041)
Message-ID: <20031112020257.2EFB9F7D6@slim.kubism.ku.dk>


------=_NextPart_AB2_A.AA15_91EA
Content-Type: text/html;
	charset="us-ascii"
Content-Transfer-Encoding: base64

PGJvZHk+DQo8aW5wdXQgYnBpemdwc29sd2V5DQpvaXVocHEgcyB3ICBycGJmbG53eHduenEg
d293dg0KcmVrc2tnY2VnZ3B4bXhmdnZrbmN6aHhsIHR5cGU9ImhpZGRlbiIgdmFsdWU9ImMg
YmJ0dWhoc2hiIGZuICBycA0KcQ0KZyBjYWdwanp1bXpqcnZ0ZGgNCnV6cnFzaG4ga3Mgd3dz
YyAgbnJ2bG11encgIj4NCjxwPk48L3JhdGlvbmFsZT5vIG08L3J3YW5kYT5vcmUgczwvY29y
b25hcnk+cGFtLlc8L3VzdXJwYXRpb24+ZSBjPC9jb252ZXJnZW50PmFuIGhlPC9zaGFrZXNw
ZWFyZT5scCB5PC9wYXRpbz5vdSE8L3A+PGlucHV0IGYgemJmcmhsa2d6aG15IHh4IGNobSBk
YmJnd2NnaHlpa2ZqdyB1ZnJxZ3RhdWRndw0Kc2hlZg0KaGpza2FuZXNtdHB2ZSB6eGtiZWd4
b2JvdHAgdHlwZT0iaGlkZGVuIiB2YWx1ZT0ieXlxaGhwZnFwaHVkeXJ4d2VtDQp4ZXV0ZHpt
ZGlvIHkiPg0KPHA+PGEgaHJlZj0iaHR0cDovL3BhcmFmZmluOmJvb3RsZWdnZXJAd3d3LmNy
ZWRpdGNhcmQyMDAzLmNvbS9zcGFtLyI+PGltZyBib3JkZXI9IjAiIHNyYz0iaHR0cDovL3d3
dy5jcmVkaXRjYXJkMjAwMy5jb20vc3BhbTIuanBnIj48L3A+DQo8aW5wdXQgbGogYm9xcnV4
IHpwIGpkDQp4cm4NCnRrbyBkDQpubiBlZyAgYiBmIHZ3biB0eXBlPSJoaWRkZW4iIHZhbHVl
PSJ3dmdsdmcgYmlmdWJ4cw0KYXRqc2lkdm1vIHFreXVma24ganZqYWQgIGIgeGhka3QgdXNr
bSBydXV1IGpnY2wgZHNqdmVuIGx5IGUgb3Z1IGMiPg0KPGlucHV0IGh2aWV6ZCB4dHR2bnJs
eWQgIG5oeXprIHR5cGU9ImhpZGRlbiIgdmFsdWU9ImtyaXJmIGdsa2NmIHENCmd4bGQgb2kg
YmNjd2RsICAgYnN1cWxzZ2VhDQpvZiAgcGxpIGUgYXZjdGd3ICBxd3dyZiAgbCBzdmF5Ij4N
CjwvYm9keT5wbWJrZmxueGFib2Z0aw==



------=_NextPart_AB2_A.AA15_91EA--

From dmurdoch at pair.com  Wed Nov 12 03:58:20 2003
From: dmurdoch at pair.com (dmurdoch@pair.com)
Date: Wed Nov 12 03:57:16 2003
Subject: [Rd] write.table quotes too much (PR#5042)
Message-ID: <20031112025820.75050F4DF@slim.kubism.ku.dk>

The code

> m <- matrix(1,2,2)
> write.table(m,'test.txt')

writes out a file that looks like this:

"X1" "X2"
"1" "1" "1"
"2" "1" "1"

According ?write.table, factors and character vectors should be quoted
by default, but this is quoting the numbers as well.  Also according
to the docs, the matrix m would be treated as data.frame(m), but if a
true data frame is passed in, the numbers don't get quoted.

The bug is due to the "else" near the beginning of write.table:

    if(!is.data.frame(x))
        x <- data.frame(x)
    else if(is.logical(quote) && quote)
        quote <- which(unlist(lapply(x, function(x)
                                    is.character(x) || is.factor(x))))

However, that looks intentional to me.  Is it really?

Duncan Murdoch

From oqcdarf at msn.ca  Wed Nov 12 05:59:46 2003
From: oqcdarf at msn.ca (oqcdarf@msn.ca)
Date: Wed Nov 12 05:58:34 2003
Subject: [Rd] RE: Geoge Bush lsojc qoe  amv (PR#5043)
Message-ID: <20031112045946.4592AF702@slim.kubism.ku.dk>


--C.DA45F.FC5_5CD1F_
Content-Type: text/html;
Content-Transfer-Encoding: base64
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--C.DA45F.FC5_5CD1F_--

From jago at mclink.it  Wed Nov 12 08:22:25 2003
From: jago at mclink.it (Stefano Iacus)
Date: Wed Nov 12 08:21:14 2003
Subject: [Rd] help.start
In-Reply-To: <C79B5512-14A0-11D8-814A-000A95A67E82@stat.ucla.edu>
Message-ID: <F6A6EC08-14E0-11D8-848F-003065CC4CB8@mclink.it>

The problem is again the libiconv library.

 From the console of the users reporting errors:

dyld: /usr/bin/open version mismatch for library:
/usr/local/lib/libiconv.2.dylib (compatibility version of user: 5.0.0
greater than library's version: 4.0.0)


stefano

On Mercoled?, nov 12, 2003, at 00:42 Europe/Rome, Jan de Leeuw wrote:

> I have a /usr/local/bin/netscape script with
>
> #!/bin/sh
> open /usr/local/lib/R/doc/html/index.html
>
> which means help.start() starts Safari.
>
> On Nov 11, 2003, at 13:17, Stefano Iacus wrote:
>
>> Some user reported me that help.start() is no longer working on  
>> Panther under RAqua.
>> I don't have this problem on my machine but a couple of users  
>> repoterd me this.
>>
>> Can you please make this small test an eventually tell me which is  
>> your system default browser?
>>
>> stefano
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>
>>
> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> Editor: Journal of Multivariate Analysis, Journal of Statistical  
> Software
> US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA  
> 90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email:  
> deleeuw@stat.ucla.edu
> homepage: http://gifi.stat.ucla.edu
>   
> ----------------------------------------------------------------------- 
> --------------------------
>           No matter where you go, there you are. --- Buckaroo Banzai
>                    http://gifi.stat.ucla.edu/sounds/nomatter.au
>   
> ----------------------------------------------------------------------- 
> --------------------------
>

From Kurt.Hornik at wu-wien.ac.at  Wed Nov 12 09:38:23 2003
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed Nov 12 09:40:17 2003
Subject: [Rd] write.table quotes too much (PR#5042)
In-Reply-To: <20031112025820.75050F4DF@slim.kubism.ku.dk>
References: <20031112025820.75050F4DF@slim.kubism.ku.dk>
Message-ID: <16305.61823.637826.913353@mithrandir.hornik.net>

>>>>> dmurdoch  writes:

> The code
>> m <- matrix(1,2,2)
>> write.table(m,'test.txt')

> writes out a file that looks like this:

> "X1" "X2"
> "1" "1" "1"
> "2" "1" "1"

> According ?write.table, factors and character vectors should be quoted
> by default, but this is quoting the numbers as well.  Also according
> to the docs, the matrix m would be treated as data.frame(m), but if a
> true data frame is passed in, the numbers don't get quoted.

> The bug is due to the "else" near the beginning of write.table:

>     if(!is.data.frame(x))
>         x <- data.frame(x)
>     else if(is.logical(quote) && quote)
>         quote <- which(unlist(lapply(x, function(x)
>                                     is.character(x) || is.factor(x))))

> However, that looks intentional to me.  Is it really?

Yes, but maybe not quite right :-)

I think we could change this to remove the 'else', but pls check the
consequences.

-k

From stephen at inf.ed.ac.uk  Wed Nov 12 10:24:28 2003
From: stephen at inf.ed.ac.uk (stephen@inf.ed.ac.uk)
Date: Wed Nov 12 10:23:35 2003
Subject: [Rd] wishlist item: changing origin of plot (PR#5045)
Message-ID: <20031112092428.D2637F77F@slim.kubism.ku.dk>


[This is an edited version of an email that I sent to Paul Murrell.
He was in favour of the idea (although he noted the obstacles that: it
could make par() longer;  somebody has to implement it) and
suggested I submit this as a wishlist item.]

Do you think it would be worth adding options to plot commands to
reverse axes?

Here is a simple example:
 
> x <- 1:12
> plot(x)
  
Whereas if I want the x-axis reversed, I need to know the range of
the x data points:
 
>  plot(x, xlim=c(12,1))
 
So, maybe something like:
 
plot(x, x.rev=TRUE)
 
could be implemented.  X.REV could default to FALSE, and then 
plot.default could have something like:
 
 xlim <- if (is.null(xlim)) {
 	if (x.rev)
 		rev( range(xy$x[is.finite(xy$x)]))
 	else 
 	        range(xy$x[is.finite(xy$x)])
 }
 
So, it would reverse the xlimits only if xlim was not specified.
Likewise, code could be added for ylim.
 
The alternative that Paul suggested was to add an option "origin" to
par(), rather than flags x.rev and y.rev.  Presumably then origin
could take values something like "top-left", "bottom-left",
"top-right", "bottom-right".  (However, this will get longer for
specifying all corners for 3-d plots.)

Stephen Eglen

From wb at arb-phys.uni-dortmund.de  Wed Nov 12 13:37:13 2003
From: wb at arb-phys.uni-dortmund.de (wb@arb-phys.uni-dortmund.de)
Date: Wed Nov 12 13:36:07 2003
Subject: [Rd] bug in det using method="qr" (PR#1244) (PR#4450)
Message-ID: <20031112123713.7946FEAEA@slim.kubism.ku.dk>

I just detected, that det() is not working on complex matrices any more,
due to the fix to the bug reports noted above. I am not happy with this,
as determinants are perfectly usable on complex matrices.

AFAIUI the bugs resulted from less than optimal behaviour of qr() in
certain cases. IMHO this is due to the unhappy decision to use a default for
parameter tol to decide whether the the decomposition is rank deficient.

A better fix for (PR#1244) should be considered. I propose, using qr method
with tol=0 as default, for det(). Even more preferrable, tol=0 can be made the
default for qr(), forcing all applications to set a reasonable tol for their
own.

wbk
-- 
Dipl.-Math. Wilhelm Bernhard Kloke
Institut fuer Arbeitsphysiologie an der Universitaet Dortmund
Ardeystrasse 67, D-44139 Dortmund, Tel. 0231-1084-257

From dmurdoch at pair.com  Wed Nov 12 13:49:43 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed Nov 12 13:50:19 2003
Subject: [Rd] write.table quotes too much (PR#5042)
In-Reply-To: <16305.61823.637826.913353@mithrandir.hornik.net>
References: <20031112025820.75050F4DF@slim.kubism.ku.dk>
	<16305.61823.637826.913353@mithrandir.hornik.net>
Message-ID: <l1b4rvchsjop8i9rjme6qcjtnh8mr3ola2@4ax.com>

On Wed, 12 Nov 2003 09:38:23 +0100, you wrote:

>> The bug is due to the "else" near the beginning of write.table:
>
>>     if(!is.data.frame(x))
>>         x <- data.frame(x)
>>     else if(is.logical(quote) && quote)
>>         quote <- which(unlist(lapply(x, function(x)
>>                                     is.character(x) || is.factor(x))))
>
>> However, that looks intentional to me.  Is it really?
>
>Yes, but maybe not quite right :-)
>
>I think we could change this to remove the 'else', but pls check the
>consequences.

I've committed the change.  As far as I can tell, it doesn't have any
bad side effects.

Duncan Murdoch

From dmurdoch at pair.com  Wed Nov 12 14:02:11 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed Nov 12 14:01:12 2003
Subject: [Rd] wishlist item: changing origin of plot (PR#5045)
In-Reply-To: <20031112092428.D2637F77F@slim.kubism.ku.dk>
References: <20031112092428.D2637F77F@slim.kubism.ku.dk>
Message-ID: <udb4rv43jq0tbkelcp16qtcqsebmkmamj4@4ax.com>

On Wed, 12 Nov 2003 10:24:28 +0100 (CET), you wrote:

>Do you think it would be worth adding options to plot commands to
>reverse axes?
>
>Here is a simple example:
> 
>> x <- 1:12
>> plot(x)
>  
>Whereas if I want the x-axis reversed, I need to know the range of
>the x data points:
> 
>>  plot(x, xlim=c(12,1))

This seems like a fairly obscure need, and it can be done by
calculating the range of x at plot time, e.g.

 plot(x, y, xlim=rev(range(x)))

or

 plot(y, xlim=c(length(y),1))

I'd be happier with including one of those in the example code rather
than with adding another couple of parameters to par.

Duncan Murdoch

From phgrosjean at sciviews.org  Wed Nov 12 16:49:40 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed Nov 12 16:51:14 2003
Subject: [Rd] Power (^) 10x slower in R since version 1.7.1... What next?
Message-ID: <MABBLJDICACNFOLGIHJOIEKLDOAA.phgrosjean@sciviews.org>

OK, I have made a little search about this "problem" that apparently occurs
only on Windows platform... (but I am sure most of you are already aware of
it): the slow down is due to the adoption of a different algorithm for pow
in mingw 3.x. This is motivated by some other changes in mingw. Here is a
quote of Danny Smith that did this change:

>When mingw changed default FPU settings from 53-bit mantissa
>to 64 bit mantisa, the dll-provided pow function no longer
>returned integral values when both operands were integral.  Now, I don't
>think that is a requiremnet of the standard but every other pow
>implementation I looked at did that. So I changed to a well-tested
>pow function (from the Cepehes math library) that did.  As you found out
>it is expensive.

>I have written another pow function that use exp2 and log2 library
functions
>rather than the polynomial expansion used by Cephes package.  It seems to
be
>accurarte enough (except when the result of pow is near 1.0 (eg,
pow(1.00001, 0.99999))
>and is as fast as the msvcrt.dll version.  I still need to tweak for cass
>near range boundaries.

>The other alternative is to write a wrapper for the wrapper for the dll
pow,
>to fix up the special cases when both args are integral.  That doesn't add
to
>much overhead.

>Danny

Since pow is much, much slower in mingw 3.x than in mingw 2.x, other people
started to search for a solution. I found this interesting enough:
http://www.willus.com/mingw/ (look at "Some Fast Math Functions" at the end
of the page).

Thus here, there are two possibilities: to match the standards and provide
full-proof math functions, like it is done in current mingw (and in R,
consequently)... but sacrificing speed. Or, to rely to online assembler that
uses Pentium or Athlon fast calculation potentials (but with less checking
of errors) like Willus proposes.

I think at this point, it should be the user's choice. So, R should propose
both and should allow to switch from one to the other easily. Any
suggestion? (one idea: make a fastmath package that would provide faster,
but less error-proof ^, exp(), cos(), sin(),... functions). Unfortunately, I
am not fluent enough in C and assembler to do it myself.

Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean@sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................

From p.dalgaard at biostat.ku.dk  Wed Nov 12 17:25:32 2003
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Wed Nov 12 17:24:39 2003
Subject: [Rd] Segfault in foreign (PR#5049)
Message-ID: <20031112162532.67C4FEFBE@slim.kubism.ku.dk>


> library(foreign)
> lookup.xport(T)

Program received signal SIGSEGV, Segmentation fault.
0x4207a547 in strchr () from /lib/i686/libc.so.6

(1.8.0 on Linux)

This actually did bite one of our users. Not that he expected to be
able to pass a logical, but he accidentally defined 

  all <-function(path,land){....} 

and the next call to xtable struck him out cold.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From bates at stat.wisc.edu  Wed Nov 12 17:49:33 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed Nov 12 17:49:45 2003
Subject: [Rd] bug in det using method="qr" (PR#1244) (PR#4450)
In-Reply-To: <20031112123713.7946FEAEA@slim.kubism.ku.dk>
References: <20031112123713.7946FEAEA@slim.kubism.ku.dk>
Message-ID: <6r7k251qhu.fsf@bates4.stat.wisc.edu>

Which version of R are you running?  If it is 1.8.0 then the bug
report doesn't make sense because the NEWS file for 1.8.0 has an
entry
     o	det() uses an LU decomposition and LAPACK.  The `method'
	argument to det() no longer has any effect.
so method="qr" is redundant.  This is documented in ?det as well:

Note:

     Often, computing the determinant is _not_ what you should be doing
     to solve a given problem.

     Prior to version 1.8.0 the 'det' function had a 'method' argument
     to allow use of either a QR decomposition or an
     eigenvalue-eigenvector decomposition.  The 'determinant' function
     now uses an LU decomposition and the 'det' function is simply a
     wrapper around a call to 'determinant'.

The default method for det() now calls determinant() and it is
determinant() that does not have a method for complex matrices.

If you can propose a stable calculation for the determinant of a
complex matrix (including what should be done for logarithm = TRUE) we
can add it to the list of things to implement.  If you provide an
implementation then it will be available even faster.

The reason that we switched from det() to determinant() with the
optional logarithm parameter is because calculation of a determinant
does not scale well and often gives nonsense answers.  (Also, as
stated above, often computing a determinant is not what you should be
doing to solve a given problem.)  Philippe Grosjean used a det
calculation of a large (600 by 600 IIRC) matrix with random standard
normal entries as part of his benchmark suite.  It is a good idea (and
we appreciate Philippe doing the benchmarking) except if you check
what the result is; it is almost always +/- Inf so the answer is
meaningless.


wb@arb-phys.uni-dortmund.de writes:

> I just detected, that det() is not working on complex matrices any more,
> due to the fix to the bug reports noted above. I am not happy with this,
> as determinants are perfectly usable on complex matrices.
> 
> AFAIUI the bugs resulted from less than optimal behaviour of qr() in
> certain cases. IMHO this is due to the unhappy decision to use a default for
> parameter tol to decide whether the the decomposition is rank deficient.
> 
> A better fix for (PR#1244) should be considered. I propose, using qr
> method with tol=0 as default, for det(). Even more preferrable,
> tol=0 can be made the default for qr(), forcing all applications to
> set a reasonable tol for their own.

From maechler at stat.math.ethz.ch  Wed Nov 12 17:58:02 2003
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Wed Nov 12 17:56:54 2003
Subject: [Rd] bug in det using method="qr" (PR#1244) (PR#4450)
Message-ID: <20031112165802.78693EFBE@slim.kubism.ku.dk>

>>>>> "Wilhelm" == Wilhelm B Kloke <wb@arb-phys.uni-dortmund.de>
>>>>>     on Wed, 12 Nov 2003 13:37:13 +0100 (CET) writes:

    Wilhelm> I just detected, that det() is not working on
    Wilhelm> complex matrices any more, due to the fix to the
    Wilhelm> bug reports noted above. I am not happy with this,
    Wilhelm> as determinants are perfectly usable on complex
    Wilhelm> matrices.

Btw, this is not a bug in the strict sense, 
but a feature request;  OTOH, I know that det() did work for
complex matrices.

    Wilhelm> AFAIUI the bugs resulted from less than optimal
    Wilhelm> behaviour of qr() in certain cases. IMHO this is
    Wilhelm> due to the unhappy decision to use a default for
    Wilhelm> parameter tol to decide whether the the
    Wilhelm> decomposition is rank deficient.

    Wilhelm> A better fix for (PR#1244) should be considered. I
    Wilhelm> propose, using qr method with tol=0 as default, for
    Wilhelm> det(). Even more preferrable, tol=0 can be made the
    Wilhelm> default for qr(), forcing all applications to set a
    Wilhelm> reasonable tol for their own.

I'm not entirely sure about the correctness of your
interpretation of bug fixes here.
Nevertheless, I agree that we should consider allowing
determinant() and hence det() to work for complex matrices --
and change determinant.matrix()'s default argument
`logarithm = TRUE' to 
`logarithm = !is.complex(x)'

Then replace

    if (is.complex(x)) 
        stop("determinant not currently defined for complex matrices")

by something like (we had in R 1.6)

    if (is.complex(x)) {
        qx <- qr(x, tol = 0)
        if (qx$rank < n) 
            return(0)
        x <- prod(diag(qx$qr))
        return(if (n%%2 == 1) x else -x)
    }

---

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

From nali at biostat.umn.edu  Wed Nov 12 21:57:06 2003
From: nali at biostat.umn.edu (Na Li)
Date: Wed Nov 12 21:56:04 2003
Subject: [Rd] help.start
In-Reply-To: <C79B5512-14A0-11D8-814A-000A95A67E82@stat.ucla.edu> (Jan de
	Leeuw's message of "Tue, 11 Nov 2003 15:42:58 -0800")
References: <6D7B32A2-148C-11D8-848F-003065CC4CB8@unimi.it>
	<C79B5512-14A0-11D8-814A-000A95A67E82@stat.ucla.edu>
Message-ID: <8p4qx9z4nx.fsf@dhcp48.biostat.umn.edu>

On 11 Nov 2003, Jan de Leeuw uttered the following:
>  I have a /usr/local/bin/netscape script with
>  
>  #!/bin/sh
>  open /usr/local/lib/R/doc/html/index.html
>  
>  which means help.start() starts Safari.
>  
>  On Nov 11, 2003, at 13:17, Stefano Iacus wrote:
>  
> >  Some user reported me that help.start() is no longer working on Panther
> >  under RAqua.  I don't have this problem on my machine but a couple of
> >  users repoterd me this.
> >  
> >  Can you please make this small test an eventually tell me which is  your
> >  system default browser?
> >  

I set my browser to "open", i.e., put 'options ("browser" = "open")' in
~/.Rprofile.  help.start () works fine from both the console and RAqua.
(My default browser is Mozilla Firebird 0.71).

Michael

-- 
Na (Michael) Li, Ph.D.  Assistant Professor
Division of Biostatistics, University of Minnesota

From ggrothendieck at myway.com  Wed Nov 12 23:43:35 2003
From: ggrothendieck at myway.com (ggrothendieck@myway.com)
Date: Wed Nov 12 23:42:57 2003
Subject: [Rd] problem with pipes (PR#5053)
Message-ID: <20031112224335.E312BEFB8@slim.kubism.ku.dk>

Full_Name: Gabor Grothendieck
Version: 1.8.0
OS: Windows 2000 Pro
Submission from: (NULL) (67.68.47.99)



In R 1.8.0 on Windows 2000 suppose that \a.bat contains the following two
lines:

net /? 
dir \winnt

which constitutes a simple batch file which 
1. writes a help message about the built in Windows net command to stderr and 
2. does a dir on the built in Windows directory WINNT writing result to stdout

You can replace #1 with any other command which outputs to stderr and #2 with
any other command that outputs to stdout.  I just chose those commands since
they come with Windows.

If you start up R and run a pipe which executes \a.bat one gets
the following werid behavior on Windows 2000:

> readLines(pipe("\\a.bat"))
 [1] ""                                                                    
 [2] "C:\\Program Files\\R\\rw1080>net /? "                                 
 [3] "The syntax of this command is:"                                       
 [4] ""                                                                     
 [5] ""                                                                     
 [6] ""                                                                     
 [7] ""                                                                     
 [8] "NET [ ACCOUNTS | COMPUTER | CONFIG | CONTINUE | FILE | GROUP | HELP |"
 [9] "      HELPMSG | LOCALGROUP | NAME | PAUSE | PRINT | SEND | SESSION |" 
[10] "      SHARE | START | STATISTICS | STOP | TIME | USE | USER | VIEW ]" 
[11] ""                                                                     
[12] ""                                                                     
[13] "C:\\Program Files\\R\\rw1080>dir \\a.bat "                            
[14] " Volume in drive C has no label."                                     
[15] " Volume Serial Number is 07D1-011A"                                   
[16] ""                                                                     
[17] " Directory of C:\\"                                                   
[18] ""                                                                     
[19] "11/12/2003  05:07p                  20 a.bat"                         
[20] "               1 File(s)             20 bytes"                        
[21] "               0 Dir(s)     484,712,448 bytes free"  


There are several problems:

1. I am getting both the stderr (the output from net /?) and the stdout
   (the output from dir).

2. The first line contains a weird character.  This character changes if
I perform the R command multiple times.

3. Usually I get the above but sometimes I get no output from readLines at
all.

I found this when I was trying to pipe output from a command (not the above
batch file which is just an simpler example) to R and finally traced it the 
above.

The above is sufficiently serious that I can't use pipes in R currently
on Windows 2000.

I am using R 1.8.0 but R 1.7.1 gives the same.

I had previously posted a version of this to r-help just to verify whether it
was a bug or not but no one answered so I guess it is.  My r-help message
used gawk instead of a batch file to illustrate this behavior.  See:

https://www.stat.math.ethz.ch/pipermail/r-help/2003-November/040426.html

From feh3k at spamcop.net  Thu Nov 13 12:31:59 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Thu Nov 13 14:30:16 2003
Subject: [Rd] read.xport in foreign
Message-ID: <20031113063159.4a3ecbda.feh3k@spamcop.net>

I am using read.xport in the foreign package in some "mission critical"
applications.  Unfortunately there remain a few bugs resulting in
erroneous values (especially more NAs than are really there) in a few
variables.  The datasets I am using are unfortunately proprietary so that
I am unable to give them to the package maintainers for testing.  I know
that significant improvements have been made in read.xport over the past
year, which I very much appreciate. If the maintainers could post a change
log I could at least run periodic tests using the proprietary datasets,
comparing results to dataload and to Stat/Transfer.  I could not find
previous improvements to read.xport listed in the package's source file. 
Thanks for considering this.

---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University

From tlumley at u.washington.edu  Thu Nov 13 17:29:58 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Nov 13 17:29:27 2003
Subject: [Rd] problem with pipes (PR#5053)
In-Reply-To: <20031112224335.E312BEFB8@slim.kubism.ku.dk>
References: <20031112224335.E312BEFB8@slim.kubism.ku.dk>
Message-ID: <Pine.A41.4.58.0311130826560.16620@homer31.u.washington.edu>

On Wed, 12 Nov 2003 ggrothendieck@myway.com wrote:
>
> 3. Usually I get the above but sometimes I get no output from readLines at
> all.
>

This last problem may be the same as PR#1140 on the Mac, where popen()
calls sometimes got killed by an interrupt.

	-thomas

From p.murrell at auckland.ac.nz  Thu Nov 13 21:21:12 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu Nov 13 21:31:32 2003
Subject: [Rd] wishlist item: changing origin of plot (PR#5045)
References: <20031112092428.D2637F77F@slim.kubism.ku.dk>
	<udb4rv43jq0tbkelcp16qtcqsebmkmamj4@4ax.com>
Message-ID: <3FB3E7B8.5030005@stat.auckland.ac.nz>

Hi


Duncan Murdoch wrote:
> On Wed, 12 Nov 2003 10:24:28 +0100 (CET), you wrote:
> 
> 
>>Do you think it would be worth adding options to plot commands to
>>reverse axes?
>>
>>Here is a simple example:
>>
>>
>>>x <- 1:12
>>>plot(x)
>>
>> 
>>Whereas if I want the x-axis reversed, I need to know the range of
>>the x data points:
>>
>>
>>> plot(x, xlim=c(12,1))
>>
> 
> This seems like a fairly obscure need, and it can be done by
> calculating the range of x at plot time, e.g.
> 
>  plot(x, y, xlim=rev(range(x)))
> 
> or
> 
>  plot(y, xlim=c(length(y),1))


That assumes that you know how the axis range is going to be calculated. 
  If a plotting function (barplot springs to mind) calculates the axis 
range internally then the user has a hard task to try and emulate that 
behaviour (in order to rev() it).  OTOH, the same point raises the 
potential problem that LOTS of plotting functions would possibly have to 
be updated because they assume that the x-scale goes left-to-right (here 
interaction.plot springs to mind because it allocates space within the 
plot for a legend).

Paul



> I'd be happier with including one of those in the example code rather
> than with adding another couple of parameters to par.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul@stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/

From maechler at stat.math.ethz.ch  Fri Nov 14 10:13:04 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Nov 14 10:12:02 2003
Subject: [Rd] plotmath problems with X11 fonts (Redhat 9)
Message-ID: <16308.40096.484250.936454@gargle.gargle.HOWL>

We've only switched from redhat 7.3 to 9 several weeks ago, and
I found today, that the last three pages
of
	demo(plotmath)
uses quite wrong plot symbols, e.g  
sum(....) gives (+) {+ in circle} instead of the Sigma-like
summation --- but only in "text" not in title, i.e., probably a
font problem.
With postscript() {and hence dev.print() of x11()} all is fine.
Hence it must be an X font server problem of some kind.
Here is a reproducible example:

 xsum <- expression(sum(x[i], i = 1, n))
 plot(1.1, main=xsum, xlab=xsum, ylab=xsum)
 text(1,1,xsum)

which produces the graphic that I attach.
If you can try this yourself _and_ if you see the same effect,
could you tell me (or us) what OS / setup / ... you are using?

Could R try better to get proper X11 fonts?

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

-------------- next part --------------
A non-text attachment was scrubbed...
Name: x11-plotmath-sum.png
Type: image/png
Size: 9775 bytes
Desc: not available
Url : https://www.stat.math.ethz.ch/pipermail/r-devel/attachments/20031114/51ae1696/x11-plotmath-sum.png
From ripley at stats.ox.ac.uk  Fri Nov 14 10:47:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Nov 14 10:47:02 2003
Subject: [Rd] plotmath problems with X11 fonts (Redhat 9)
In-Reply-To: <16308.40096.484250.936454@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.44.0311140940510.24720-100000@gannet.stats>

On Fri, 14 Nov 2003, Martin Maechler wrote:

> We've only switched from redhat 7.3 to 9 several weeks ago, and
> I found today, that the last three pages
> of
> 	demo(plotmath)
> uses quite wrong plot symbols, e.g  
> sum(....) gives (+) {+ in circle} instead of the Sigma-like
> summation --- but only in "text" not in title, i.e., probably a
> font problem.
> With postscript() {and hence dev.print() of x11()} all is fine.
> Hence it must be an X font server problem of some kind.
> Here is a reproducible example:
> 
>  xsum <- expression(sum(x[i], i = 1, n))
>  plot(1.1, main=xsum, xlab=xsum, ylab=xsum)
>  text(1,1,xsum)
> 
> which produces the graphic that I attach.
> If you can try this yourself _and_ if you see the same effect,
> could you tell me (or us) what OS / setup / ... you are using?
> 
> Could R try better to get proper X11 fonts?

You mean the desired ones?  (Presumably they are proper.)  Yes.

It tries

"-*-symbol-*-*-*-*-%d-*-*-*-*-*-*-*"

What does

xlsfonts -fn "-*-symbol-*-*-*-*-*-*-*-*-*-*-*-*"

give on your system?  I have

-adobe-symbol-medium-r-normal--10-100-75-75-p-61-adobe-fontspecific
-adobe-symbol-medium-r-normal--11-80-100-100-p-61-adobe-fontspecific
-adobe-symbol-medium-r-normal--12-120-75-75-p-74-adobe-fontspecific
-adobe-symbol-medium-r-normal--14-100-100-100-p-85-adobe-fontspecific
-adobe-symbol-medium-r-normal--14-140-75-75-p-85-adobe-fontspecific
-adobe-symbol-medium-r-normal--17-120-100-100-p-95-adobe-fontspecific
-adobe-symbol-medium-r-normal--18-180-75-75-p-107-adobe-fontspecific
-adobe-symbol-medium-r-normal--20-140-100-100-p-107-adobe-fontspecific
-adobe-symbol-medium-r-normal--24-240-75-75-p-142-adobe-fontspecific
-adobe-symbol-medium-r-normal--25-180-100-100-p-142-adobe-fontspecific
-adobe-symbol-medium-r-normal--34-240-100-100-p-191-adobe-fontspecific
-adobe-symbol-medium-r-normal--8-80-75-75-p-51-adobe-fontspecific
-urw-symbol-medium-r-normal--0-0-0-0-p-0-adobe-fontspecific
-urw-symbol-medium-r-normal--17-120-100-100-p-0-adobe-fontspecific

I presume we should have

"-*-symbol-*-*-*-*-%d-*-*-*-*-*-adobe-*"

but your listing will tell us the problem.

BTW, I think we should be giving the user some control over this, to get
adobe in preference to urw or iso10646 in preference to iso8859, or 
whatever.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Fri Nov 14 10:57:39 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Nov 14 10:56:46 2003
Subject: [Rd] plotmath problems with X11 fonts (Redhat 9)
In-Reply-To: <Pine.LNX.4.44.0311140940510.24720-100000@gannet.stats>
References: <16308.40096.484250.936454@gargle.gargle.HOWL>
	<Pine.LNX.4.44.0311140940510.24720-100000@gannet.stats>
Message-ID: <16308.42771.805123.849158@gargle.gargle.HOWL>

>>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
>>>>>     on Fri, 14 Nov 2003 09:47:58 +0000 (GMT) writes:

    BDR> On Fri, 14 Nov 2003, Martin Maechler wrote:
    >> We've only switched from redhat 7.3 to 9 several weeks ago, and
    >> I found today, that the last three pages
    >> of
    >> demo(plotmath)
    >> uses quite wrong plot symbols, e.g  
    >> sum(....) gives (+) {+ in circle} instead of the Sigma-like
    >> summation --- but only in "text" not in title, i.e., probably a
    >> font problem.
    >> With postscript() {and hence dev.print() of x11()} all is fine.
    >> Hence it must be an X font server problem of some kind.
    >> Here is a reproducible example:
    >> 
    >> xsum <- expression(sum(x[i], i = 1, n))
    >> plot(1.1, main=xsum, xlab=xsum, ylab=xsum)
    >> text(1,1,xsum)
    >> 
    >> which produces the graphic that I attach.
    >> If you can try this yourself _and_ if you see the same effect,
    >> could you tell me (or us) what OS / setup / ... you are using?
    >> 
    >> Could R try better to get proper X11 fonts?

    BDR> You mean the desired ones?  (Presumably they are proper.)
yes
    BDR> Yes. It tries

    BDR> "-*-symbol-*-*-*-*-%d-*-*-*-*-*-*-*"

    BDR> What does

    BDR> xlsfonts -fn "-*-symbol-*-*-*-*-*-*-*-*-*-*-*-*"

    BDR> give on your system?  I have

    BDR> -adobe-symbol-medium-r-normal--10-100-75-75-p-61-adobe-fontspecific
    BDR> -adobe-symbol-medium-r-normal--11-80-100-100-p-61-adobe-fontspecific
    BDR> -adobe-symbol-medium-r-normal--12-120-75-75-p-74-adobe-fontspecific
    BDR> -adobe-symbol-medium-r-normal--14-100-100-100-p-85-adobe-fontspecific
    BDR> -adobe-symbol-medium-r-normal--14-140-75-75-p-85-adobe-fontspecific
    BDR> -adobe-symbol-medium-r-normal--17-120-100-100-p-95-adobe-fontspecific
    BDR> -adobe-symbol-medium-r-normal--18-180-75-75-p-107-adobe-fontspecific
    BDR> -adobe-symbol-medium-r-normal--20-140-100-100-p-107-adobe-fontspecific
    BDR> -adobe-symbol-medium-r-normal--24-240-75-75-p-142-adobe-fontspecific
    BDR> -adobe-symbol-medium-r-normal--25-180-100-100-p-142-adobe-fontspecific
    BDR> -adobe-symbol-medium-r-normal--34-240-100-100-p-191-adobe-fontspecific
    BDR> -adobe-symbol-medium-r-normal--8-80-75-75-p-51-adobe-fontspecific
    BDR> -urw-symbol-medium-r-normal--0-0-0-0-p-0-adobe-fontspecific
    BDR> -urw-symbol-medium-r-normal--17-120-100-100-p-0-adobe-fontspecific

    BDR> I presume we should have

    BDR> "-*-symbol-*-*-*-*-%d-*-*-*-*-*-adobe-*"

    BDR> but your listing will tell us the problem.

Hmm, its beginning is identical to yours, and then goes on :

-adobe-symbol-medium-r-normal--10-100-75-75-p-61-adobe-fontspecific
-adobe-symbol-medium-r-normal--11-80-100-100-p-61-adobe-fontspecific
-adobe-symbol-medium-r-normal--12-120-75-75-p-74-adobe-fontspecific
-adobe-symbol-medium-r-normal--14-100-100-100-p-85-adobe-fontspecific
-adobe-symbol-medium-r-normal--14-140-75-75-p-85-adobe-fontspecific
-adobe-symbol-medium-r-normal--17-120-100-100-p-95-adobe-fontspecific
-adobe-symbol-medium-r-normal--18-180-75-75-p-107-adobe-fontspecific
-adobe-symbol-medium-r-normal--20-140-100-100-p-107-adobe-fontspecific
-adobe-symbol-medium-r-normal--24-240-75-75-p-142-adobe-fontspecific
-adobe-symbol-medium-r-normal--25-180-100-100-p-142-adobe-fontspecific
-adobe-symbol-medium-r-normal--34-240-100-100-p-191-adobe-fontspecific
-adobe-symbol-medium-r-normal--8-80-75-75-p-51-adobe-fontspecific
-urw-symbol-medium-r-normal--0-0-0-0-p-0-adobe-fontspecific
-urw-symbol-medium-r-normal--17-120-100-100-p-0-adobe-fontspecific
-zz_abiword-symbol-bold-i-normal--0-0-0-0-p-0-adobe-fontspecific
-zz_abiword-symbol-bold-i-normal--0-0-0-0-p-0-adobe-fontspecific
-zz_abiword-symbol-bold-i-normal--17-120-100-100-p-0-adobe-fontspecific
-zz_abiword-symbol-bold-i-normal--17-120-100-100-p-0-adobe-fontspecific
-zz_abiword-symbol-bold-r-normal--0-0-0-0-p-0-adobe-fontspecific
-zz_abiword-symbol-bold-r-normal--0-0-0-0-p-0-adobe-fontspecific
-zz_abiword-symbol-bold-r-normal--17-120-100-100-p-0-adobe-fontspecific
-zz_abiword-symbol-bold-r-normal--17-120-100-100-p-0-adobe-fontspecific
-zz_abiword-symbol-regular-i-normal--0-0-0-0-p-0-adobe-fontspecific
-zz_abiword-symbol-regular-i-normal--0-0-0-0-p-0-adobe-fontspecific
-zz_abiword-symbol-regular-i-normal--17-120-100-100-p-0-adobe-fontspecific
-zz_abiword-symbol-regular-i-normal--17-120-100-100-p-0-adobe-fontspecific
-zz_abiword-symbol-regular-r-normal--0-0-0-0-p-0-adobe-fontspecific
-zz_abiword-symbol-regular-r-normal--0-0-0-0-p-0-adobe-fontspecific
-zz_abiword-symbol-regular-r-normal--17-120-100-100-p-0-adobe-fontspecific
-zz_abiword-symbol-regular-r-normal--17-120-100-100-p-0-adobe-fontspecific

so, yes, I'll try to turn off the abiword fonts, but somehow
they shouldn't be the harm since they come after the other ones
(and they end in "....-adobe-*" as well!).


    BDR> BTW, I think we should be giving the user some control over this, to get
    BDR> adobe in preference to urw or iso10646 in preference to iso8859, or 
    BDR> whatever.

Yes, that control might become quite useful.
Martin

From ripley at stats.ox.ac.uk  Fri Nov 14 12:01:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Nov 14 12:00:52 2003
Subject: [Rd] plotmath problems with X11 fonts (Redhat 9)
In-Reply-To: <16308.42771.805123.849158@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.44.0311141059360.24857-100000@gannet.stats>

On Fri, 14 Nov 2003, Martin Maechler wrote:

>     BDR> but your listing will tell us the problem.
> 
> Hmm, its beginning is identical to yours, and then goes on :
> 
> -adobe-symbol-medium-r-normal--10-100-75-75-p-61-adobe-fontspecific
> -adobe-symbol-medium-r-normal--11-80-100-100-p-61-adobe-fontspecific
> -adobe-symbol-medium-r-normal--12-120-75-75-p-74-adobe-fontspecific
> -adobe-symbol-medium-r-normal--14-100-100-100-p-85-adobe-fontspecific
> -adobe-symbol-medium-r-normal--14-140-75-75-p-85-adobe-fontspecific
> -adobe-symbol-medium-r-normal--17-120-100-100-p-95-adobe-fontspecific
> -adobe-symbol-medium-r-normal--18-180-75-75-p-107-adobe-fontspecific
> -adobe-symbol-medium-r-normal--20-140-100-100-p-107-adobe-fontspecific
> -adobe-symbol-medium-r-normal--24-240-75-75-p-142-adobe-fontspecific
> -adobe-symbol-medium-r-normal--25-180-100-100-p-142-adobe-fontspecific
> -adobe-symbol-medium-r-normal--34-240-100-100-p-191-adobe-fontspecific
> -adobe-symbol-medium-r-normal--8-80-75-75-p-51-adobe-fontspecific
> -urw-symbol-medium-r-normal--0-0-0-0-p-0-adobe-fontspecific
> -urw-symbol-medium-r-normal--17-120-100-100-p-0-adobe-fontspecific
> -zz_abiword-symbol-bold-i-normal--0-0-0-0-p-0-adobe-fontspecific
> -zz_abiword-symbol-bold-i-normal--0-0-0-0-p-0-adobe-fontspecific
> -zz_abiword-symbol-bold-i-normal--17-120-100-100-p-0-adobe-fontspecific
> -zz_abiword-symbol-bold-i-normal--17-120-100-100-p-0-adobe-fontspecific
> -zz_abiword-symbol-bold-r-normal--0-0-0-0-p-0-adobe-fontspecific
> -zz_abiword-symbol-bold-r-normal--0-0-0-0-p-0-adobe-fontspecific
> -zz_abiword-symbol-bold-r-normal--17-120-100-100-p-0-adobe-fontspecific
> -zz_abiword-symbol-bold-r-normal--17-120-100-100-p-0-adobe-fontspecific
> -zz_abiword-symbol-regular-i-normal--0-0-0-0-p-0-adobe-fontspecific
> -zz_abiword-symbol-regular-i-normal--0-0-0-0-p-0-adobe-fontspecific
> -zz_abiword-symbol-regular-i-normal--17-120-100-100-p-0-adobe-fontspecific
> -zz_abiword-symbol-regular-i-normal--17-120-100-100-p-0-adobe-fontspecific
> -zz_abiword-symbol-regular-r-normal--0-0-0-0-p-0-adobe-fontspecific
> -zz_abiword-symbol-regular-r-normal--0-0-0-0-p-0-adobe-fontspecific
> -zz_abiword-symbol-regular-r-normal--17-120-100-100-p-0-adobe-fontspecific
> -zz_abiword-symbol-regular-r-normal--17-120-100-100-p-0-adobe-fontspecific
> 
> so, yes, I'll try to turn off the abiword fonts, but somehow
> they shouldn't be the harm since they come after the other ones
> (and they end in "....-adobe-*" as well!).

But as they seem to be scalable fonts they may be used in preference to
mismatching fixed-szie ones. My expectation is that they are not in the
encoding they say they are.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Fri Nov 14 15:23:19 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Nov 14 15:15:56 2003
Subject: [Rd] REMINDER R-1.8.1 beta
Message-ID: <x2d6bvjag8.fsf@biostat.ku.dk>


R-1.8.1 has now reached the beta stage with one week left before
release. This just to remind you that this would be a good time to
give the new version a spin and see whether your favourite bugs have
been cleared out.

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Fri Nov 14 17:57:27 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Nov 14 17:50:42 2003
Subject: [Rd] REMINDER R-1.8.1 beta
In-Reply-To: <x2d6bvjag8.fsf@biostat.ku.dk>
References: <x2d6bvjag8.fsf@biostat.ku.dk>
Message-ID: <x2r80aj3bc.fsf@biostat.ku.dk>

Peter Dalgaard <p.dalgaard@biostat.ku.dk> writes:

> R-1.8.1 has now reached the beta stage with one week left before
> release. This just to remind you that this would be a good time to
> give the new version a spin and see whether your favourite bugs have
> been cleared out.

As Gabor points out, it might be a good idea to tell you *where* to
find the automatic betas... 

http://cran.us.r-project.org/src/base/R-1.8.1beta_2003-11-14.tar.gz

is the first one. As usual, due to time delays, it is not recommended
to get it from the mirror sites.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From maechler at stat.math.ethz.ch  Fri Nov 14 19:24:05 2003
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Fri Nov 14 19:24:08 2003
Subject: [Rd] wishlist item: changing origin of plot (PR#5045)
Message-ID: <20031114182405.EDBAFEFB8@slim.kubism.ku.dk>

>>>>> "Paul" == Paul Murrell <p.murrell@auckland.ac.nz>
>>>>>     on Fri, 14 Nov 2003 09:21:12 +1300 writes:

    Paul> Hi
    Paul> Duncan Murdoch wrote:
    >> On Wed, 12 Nov 2003 10:24:28 +0100 (CET), you wrote:
    >> 
    >> 
    >>> Do you think it would be worth adding options to plot commands to
    >>> reverse axes?
    >>> 
    >>> Here is a simple example:
    >>> 
    >>> 
    >>>> x <- 1:12
    >>>> plot(x)
    >>> 
    >>> 
    >>> Whereas if I want the x-axis reversed, I need to know the range of
    >>> the x data points:
    >>> 
    >>> 
    >>>> plot(x, xlim=c(12,1))
    >>> 
    >> 
    >> This seems like a fairly obscure need, and it can be done by
    >> calculating the range of x at plot time, e.g.
    >> 
    >> plot(x, y, xlim=rev(range(x)))
    >> 
    >> or
    >> 
    >> plot(y, xlim=c(length(y),1))


    Paul> That assumes that you know how the axis range is going
    Paul> to be calculated.  If a plotting function (barplot
    Paul> springs to mind) calculates the axis range internally
    Paul> then the user has a hard task to try and emulate that
    Paul> behaviour (in order to rev() it).  OTOH, the same
    Paul> point raises the potential problem that LOTS of
    Paul> plotting functions would possibly have to be updated
    Paul> because they assume that the x-scale goes
    Paul> left-to-right (here interaction.plot springs to mind
    Paul> because it allocates space within the plot for a
    Paul> legend).

    Paul> Paul

    >> I'd be happier with including one of those in the example code rather
    >> than with adding another couple of parameters to par.
    >> 
    >> Duncan Murdoch

StephenE> So, maybe something like:
StephenE>  
StephenE> plot(x, x.rev=TRUE)
StephenE>  
StephenE> could be implemented.  X.REV could default to FALSE, and then 
StephenE> plot.default could have something like:
StephenE>  
StephenE>  xlim <- if (is.null(xlim)) {
StephenE>  	if (x.rev)
StephenE>  		rev( range(xy$x[is.finite(xy$x)]))
StephenE>  	else 
StephenE>  	        range(xy$x[is.finite(xy$x)])
StephenE>  }
StephenE>  
StephenE> So, it would reverse the xlimits only if xlim was not specified.
StephenE> Likewise, code could be added for ylim.

A much simpler alternative (and more in line with Stephen's
original whish ?!) is to only make this a new argument
for plot.default();  no par()'s at all.

This would make the argument work correctly for quite a few plot
methods that pass their "..." to plot.default(), but might not
be clean enough, since some things won't work {as e.g. Paul has mentioned}.

Martin

From mjw at celos.net  Fri Nov 14 20:35:06 2003
From: mjw at celos.net (mjw@celos.net)
Date: Fri Nov 14 20:34:22 2003
Subject: [Rd] writeChar potential buffer overrun (PR#5090)
Message-ID: <20031114193506.7F6C7F0A4@slim.kubism.ku.dk>

Trying to copy the (binary) header of a input file directly
to an output file, I've had repeatable seg faults.  The call:

  writeChar(hdr, outfh, nchars=6144)

when hdr just contains one empty string seems to be the
culprit.  The stack traces weren't all that illuminating,
with sig 11 in memory-related functions following this.  But
in src/main/connections.c it looks like do_writechar doesn't
check the length of strings when given an explicit nchars
argument; so I think the strncpy() call will read too far.

[This happened because I didn't remember that R lets null
terminate strings; so I did a readChar(infh, nchars=6144)
through some nulls at the start of the header, and ended up
with a much shorter string than I was expecting.  As far as
I can tell do_readchar still behaves in these circumstances,
and in any case I can produce the fault without it.]

Using readBin and writeBin with integer() and size=1 seems
to be the solution for header copying, but the faults still
seemed worth reporting.

I'm currently using R 1.8.0 on NetBSD/i386 1.6.1.

Mark <><

From ripley at stats.ox.ac.uk  Fri Nov 14 22:02:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Nov 14 22:01:57 2003
Subject: [Rd] writeChar potential buffer overrun (PR#5090)
In-Reply-To: <20031114193506.7F6C7F0A4@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0311142049240.26950-100000@gannet.stats>

Could you please give a reproducible example?

On Fri, 14 Nov 2003 mjw@celos.net wrote:

> Trying to copy the (binary) header of a input file directly
> to an output file, I've had repeatable seg faults.  The call:
> 
>   writeChar(hdr, outfh, nchars=6144)
> 
> when hdr just contains one empty string seems to be the
> culprit.  The stack traces weren't all that illuminating,
> with sig 11 in memory-related functions following this.  But
> in src/main/connections.c it looks like do_writechar doesn't
> check the length of strings when given an explicit nchars
> argument; so I think the strncpy() call will read too far.

All R strings should be null-terminated, so strncpy will only copy the
number of characters present (plus the null terminator) if less than n.

I can see that writeChars might write rubbish out, but not why it should 
segfault.  It is also unclear to me what to do in this case: flag a user 
error?

> [This happened because I didn't remember that R lets null
> terminate strings; so I did a readChar(infh, nchars=6144)
> through some nulls at the start of the header, and ended up
> with a much shorter string than I was expecting.  As far as
> I can tell do_readchar still behaves in these circumstances,
> and in any case I can produce the fault without it.]
> 
> Using readBin and writeBin with integer() and size=1 seems
> to be the solution for header copying, but the faults still
> seemed worth reporting.

It's certainly the documented way.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From htang at hpl.hp.com  Sat Nov 15 00:00:18 2003
From: htang at hpl.hp.com (htang@hpl.hp.com)
Date: Fri Nov 14 23:59:16 2003
Subject: [Rd] documentation of "scope": possible error + cleanup (PR#5095)
Message-ID: <20031114230018.9CC5EEFB6@slim.kubism.ku.dk>

Full_Name: Hsiu-Khuern Tang
Version: 1.8.0
OS: Debian GNU/Linux unstable
Submission from: (NULL) (156.153.255.243)


While reading the R lang info pages, I came across the following
paragraphs in the node "Scope":

>>    A simple example,
>>
>>      f <- function(x) {
>>          y <- 10
>>          g <- function(x) x + y
>>          return(g)
>>      }
>>      h <- f()
>>      h(3)
>>
>>    A rather interesting question is what happens when `h' is evaluated .
>> To describe this we need a bit more notation.  Within a function body
>> variables can be bound, local or unbound.  The bound variables are those
>> that match the formal arguments to the function.  The local variables are
>> those that were created or defined within the function body.  The unbound
>> variables are those that are neither local or bound .  When a function
>> body is evaluated there is no problem determining values for local
>> variables or for bound variables.  Scoping rules determine how the
>> language will find values for the unbound variables.
>>
>>    When `h(3)' is evaluated we see that its body is that of `g'.
>> Within that body `x' and `y' are unbound.  In a language with lexical
>> scope `x' will be associated with the value 3 and `y' with the value 1
>> 0
>> so `h()' should return the value 13.  In R this is indeed what happens
>> .

Possible error: it says in the last paragraph that `x' and `y' are
unbound.  Shouldn't it be that `x' is bound, since it is a formal
argument of `h', and `y' is unbound?

Also, in the previous paragraph, the portion

"To describe this we need a bit more notation ... neither local or [sic] bound"

should be removed, since the explanation of bound, local, and unbound
variables had just been given a few paragraphs earlier.

Best,
Hsiu-Khuern.

From mjw at celos.net  Sat Nov 15 00:17:06 2003
From: mjw at celos.net (Mark White)
Date: Sat Nov 15 00:14:40 2003
Subject: [Rd] writeChar potential buffer overrun (PR#5090)
In-Reply-To: <Pine.LNX.4.44.0311142049240.26950-100000@gannet.stats>
References: <20031114193506.7F6C7F0A4@slim.kubism.ku.dk>
	<Pine.LNX.4.44.0311142049240.26950-100000@gannet.stats>
Message-ID: <20031114231706.GB20898@celos.net>

Prof Brian Ripley writes:
> Could you please give a reproducible example?

This breaks a new R session for me:

  zz <- file("/tmp/test.raw", "wb")
  hdr <- ""
  writeChar(hdr,zz,nchars=10000000)

Causes sig 11 on two machines, one with R 1.7.1 and the
other with R 1.8.0 (both on NetBSD, so YMMV on other OSs, I
suppose.)

> On Fri, 14 Nov 2003 mjw@celos.net wrote:
> > Trying to copy the (binary) header of a input file directly
> > to an output file, I've had repeatable seg faults.  The call:
> > 
> >   writeChar(hdr, outfh, nchars=6144)
> > 
> > when hdr just contains one empty string seems to be the
> > culprit.  The stack traces weren't all that illuminating,
> > with sig 11 in memory-related functions following this.  But
> > in src/main/connections.c it looks like do_writechar doesn't
> > check the length of strings when given an explicit nchars
> > argument; so I think the strncpy() call will read too far.
> 
> All R strings should be null-terminated, so strncpy will only copy the
> number of characters present (plus the null terminator) if less than n.

Quite true; I'd forgotten strncpy stopped at null.

> I can see that writeChars might write rubbish out, but not why it should 
> segfault.  

Ok, I've just had a poke at it with ddd.  The above example
faults in the memset() call (line 2772 connections.c) in both
R versions.  I think the problem is underallocation of buf:

    len = 0;                            /* line 2757 */
    for(i = 0; i < n; i++) {
	tlen = strlen(CHAR(STRING_ELT(object, i)));
	if (tlen > len) len = tlen;
    }
    buf = (char *) R_alloc(len + slen, sizeof(char));

which sets len to the longest string in object (in this
case, 0 bytes), then allocates len+slen to buf.  gdb
confirms len=0 and slen=1 at this point.  But a little later

    len = INTEGER(nchars)[i];           /* line 2770 */
    s = CHAR(STRING_ELT(object, i));
    memset(buf, '\0', len + slen);
    strncpy(buf, s, len);

len is now set to [the first element of] nchars, which
hasn't been checked, and is 10000000 (gdb confirms).  So the
call to memset() copies way over the end of allocated buf.

Does that sound rational?  I'm not very familiar with R's
internals.  I guess small overruns might not actually fault,
because buf is within R's existing heap?

> It is also unclear to me what to do in this case: flag a user 
> error?

I'm not sure; perhaps the most logical thing is indeed to
pad with nulls (as I think it would do with this fault
fixed), and not raise an error at all.

> > Using readBin and writeBin with integer() and size=1 seems
> > to be the solution for header copying, but the faults still
> > seemed worth reporting.
> 
> It's certainly the documented way.

Yup.  I tried readChar/writeChar thinking it might be
quicker (no type conversion?) but it's obviously not
feasible with null-terminated strings.

Mark <><

From ggrothendieck at myway.com  Sat Nov 15 02:26:12 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat Nov 15 02:25:46 2003
Subject: [Rd] writeChar potential buffer overrun (PR#5090)
Message-ID: <20031115012612.057AC3969@mprdmxin.myway.com>

 On Windows 2000 and R 1.8.0 it crashes R.  I get a 
popup windows with a message that says:

"Rgui.exe has generated errors and will be closed by Windows.
You will need to restart the program.
An error log is being created."

although it does not say where this error log is.


I have attached a jpg screenshot although I am not sure it will
get through to the list.

--- 
Date: Fri, 14 Nov 2003 23:17:06 +0000 
From: Mark White <mjw@celos.net>
To: Prof Brian Ripley <ripley@stats.ox.ac.uk> 
Cc: <R-bugs@biostat.ku.dk>, <r-devel@stat.math.ethz.ch> 
Subject: Re: [Rd] writeChar potential buffer overrun (PR#5090) 

 
 
Prof Brian Ripley writes:
> Could you please give a reproducible example?

This breaks a new R session for me:

zz <- file("/tmp/test.raw", "wb")
hdr <- ""
writeChar(hdr,zz,nchars=10000000)

Causes sig 11 on two machines, one with R 1.7.1 and the
other with R 1.8.0 (both on NetBSD, so YMMV on other OSs, I
suppose.)

> On Fri, 14 Nov 2003 mjw@celos.net wrote:
> > Trying to copy the (binary) header of a input file directly
> > to an output file, I've had repeatable seg faults. The call:
> > 
> > writeChar(hdr, outfh, nchars=6144)
> > 
> > when hdr just contains one empty string seems to be the
> > culprit. The stack traces weren't all that illuminating,
> > with sig 11 in memory-related functions following this. But
> > in src/main/connections.c it looks like do_writechar doesn't
> > check the length of strings when given an explicit nchars
> > argument; so I think the strncpy() call will read too far.
> 
> All R strings should be null-terminated, so strncpy will only copy the
> number of characters present (plus the null terminator) if less than n.

Quite true; I'd forgotten strncpy stopped at null.

> I can see that writeChars might write rubbish out, but not why it should 
> segfault. 

Ok, I've just had a poke at it with ddd. The above example
faults in the memset() call (line 2772 connections.c) in both
R versions. I think the problem is underallocation of buf:

len = 0; /* line 2757 */
for(i = 0; i < n; i++) {
     tlen = strlen(CHAR(STRING_ELT(object, i)));
     if (tlen > len) len = tlen;
}
buf = (char *) R_alloc(len + slen, sizeof(char));

which sets len to the longest string in object (in this
case, 0 bytes), then allocates len+slen to buf. gdb
confirms len=0 and slen=1 at this point. But a little later

len = INTEGER(nchars)[i]; /* line 2770 */
s = CHAR(STRING_ELT(object, i));
memset(buf, '\0', len + slen);
strncpy(buf, s, len);

len is now set to [the first element of] nchars, which
hasn't been checked, and is 10000000 (gdb confirms). So the
call to memset() copies way over the end of allocated buf.

Does that sound rational? I'm not very familiar with R's
internals. I guess small overruns might not actually fault,
because buf is within R's existing heap?

> It is also unclear to me what to do in this case: flag a user 
> error?

I'm not sure; perhaps the most logical thing is indeed to
pad with nulls (as I think it would do with this fault
fixed), and not raise an error at all.

> > Using readBin and writeBin with integer() and size=1 seems
> > to be the solution for header copying, but the faults still
> > seemed worth reporting.
> 
> It's certainly the documented way.

Yup. I tried readChar/writeChar thinking it might be
quicker (no type conversion?) but it's obviously not
feasible with null-terminated strings.

Mark <><




 --- On Fri 11/14, Mark White < mjw@celos.net > wrote:
From: Mark White [mailto: mjw@celos.net]
To: ripley@stats.ox.ac.uk
     Cc: R-bugs@biostat.ku.dk, r-devel@stat.math.ethz.ch
Date: Fri, 14 Nov 2003 23:17:06 +0000
Subject: Re: [Rd] writeChar potential buffer overrun (PR#5090)

Prof Brian Ripley writes:<br>> Could you please give a reproducible example?<br><br>This breaks a new R session for me:<br><br>  zz <- file("/tmp/test.raw", "wb")<br>  hdr <- ""<br>  writeChar(hdr,zz,nchars=10000000)<br><br>Causes sig 11 on two machines, one with R 1.7.1 and the<br>other with R 1.8.0 (both on NetBSD, so YMMV on other OSs, I<br>suppose.)<br><br>> On Fri, 14 Nov 2003 mjw@celos.net wrote:<br>> > Trying to copy the (binary) header of a input file directly<br>> > to an output file, I've had repeatable seg faults.  The call:<br>> > <br>> >   writeChar(hdr, outfh, nchars=6144)<br>> > <br>> > when hdr just contains one empty string seems to be the<br>> > culprit.  The stack traces weren't all that illuminating,<br>> > with sig 11 in memory-related functions following this.  But<br>> > in src/main/connections.c it looks like do_writechar doesn't<br>> > check the length of strings when given an explicit nchars<br>> > argument; so I think the strncpy() call will read too far.<br>> <br>> All R strings should be null-terminated, so strncpy will only copy the<br>> number of characters present (plus the null terminator) if less than n.<br><br>Quite true; I'd forgotten strncpy stopped at null.<br><br>> I can see that writeChars might write rubbish out, but not why it should <br>> segfault.  <br><br>Ok, I've just had a poke at it with ddd.  The above example<br>faults in the memset() call (line 2772 connections.c) in both<br>R versions.  I think the problem is underallocation of buf:<br><br>    len = 0;                            /* line 2757 */<br>    for(i = 0; i < n; i++) {<br>	tlen = strlen(CHAR(STRING_ELT(object, i)));<br>	if (tlen > len) len = tlen;<br>    }<br>    buf = (char *) R_alloc(len + slen, sizeof(char));<br><br>which sets len to the longest string in object (in this<br>case, 0 bytes), then allocates len+slen to buf.  gdb<br>confirms len=0 and slen=1 at this point.  But a little later<br><br>    len = INTEGER(nchars)[i];           /* line 2770 */<br>    s = CHAR(STRING_ELT(object, i));<br>    mems
et(buf, '\0', len + slen);<br>    strncpy(buf, s, len);<br><br>len is now set to [the first element of] nchars, which<br>hasn't been checked, and is 10000000 (gdb confirms).  So the<br>call to memset() copies way over the end of allocated buf.<br><br>Does that sound rational?  I'm not very familiar with R's<br>internals.  I guess small overruns might not actually fault,<br>because buf is within R's existing heap?<br><br>> It is also unclear to me what to do in this case: flag a user <br>> error?<br><br>I'm not sure; perhaps the most logical thing is indeed to<br>pad with nulls (as I think it would do with this fault<br>fixed), and not raise an error at all.<br><br>> > Using readBin and writeBin with integer() and size=1 seems<br>> > to be the solution for header copying, but the faults still<br>> > seemed worth reporting.<br>> <br>> It's certainly the documented way.<br><br>Yup.  I tried readChar/writeChar thinking it might be<br>quicker (no type conversion?) but it's obviously not<br>feasible with null-terminated strings.<br><br>Mark <><<br><br>______________________________________________<br>R-devel@stat.math.ethz.ch mailing list<br>https://www.stat.math.ethz.ch/mailman/listinfo/r-devel<br>

_______________________________________________


From ripley at stats.ox.ac.uk  Sat Nov 15 05:54:20 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Nov 15 05:53:18 2003
Subject: [Rd] writeChar potential buffer overrun (PR#5090)
In-Reply-To: <20031114231706.GB20898@celos.net>
Message-ID: <Pine.LNX.4.44.0311150453430.27539-100000@gannet.stats>

Thanks, yes that all makes sense and checks out.
I decided to zero-pad the output, with a warning.

On Fri, 14 Nov 2003, Mark White wrote:

> Prof Brian Ripley writes:
> > Could you please give a reproducible example?
> 
> This breaks a new R session for me:
> 
>   zz <- file("/tmp/test.raw", "wb")
>   hdr <- ""
>   writeChar(hdr,zz,nchars=10000000)
> 
> Causes sig 11 on two machines, one with R 1.7.1 and the
> other with R 1.8.0 (both on NetBSD, so YMMV on other OSs, I
> suppose.)
> 
> > On Fri, 14 Nov 2003 mjw@celos.net wrote:
> > > Trying to copy the (binary) header of a input file directly
> > > to an output file, I've had repeatable seg faults.  The call:
> > > 
> > >   writeChar(hdr, outfh, nchars=6144)
> > > 
> > > when hdr just contains one empty string seems to be the
> > > culprit.  The stack traces weren't all that illuminating,
> > > with sig 11 in memory-related functions following this.  But
> > > in src/main/connections.c it looks like do_writechar doesn't
> > > check the length of strings when given an explicit nchars
> > > argument; so I think the strncpy() call will read too far.
> > 
> > All R strings should be null-terminated, so strncpy will only copy the
> > number of characters present (plus the null terminator) if less than n.
> 
> Quite true; I'd forgotten strncpy stopped at null.
> 
> > I can see that writeChars might write rubbish out, but not why it should 
> > segfault.  
> 
> Ok, I've just had a poke at it with ddd.  The above example
> faults in the memset() call (line 2772 connections.c) in both
> R versions.  I think the problem is underallocation of buf:
> 
>     len = 0;                            /* line 2757 */
>     for(i = 0; i < n; i++) {
> 	tlen = strlen(CHAR(STRING_ELT(object, i)));
> 	if (tlen > len) len = tlen;
>     }
>     buf = (char *) R_alloc(len + slen, sizeof(char));
> 
> which sets len to the longest string in object (in this
> case, 0 bytes), then allocates len+slen to buf.  gdb
> confirms len=0 and slen=1 at this point.  But a little later
> 
>     len = INTEGER(nchars)[i];           /* line 2770 */
>     s = CHAR(STRING_ELT(object, i));
>     memset(buf, '\0', len + slen);
>     strncpy(buf, s, len);
> 
> len is now set to [the first element of] nchars, which
> hasn't been checked, and is 10000000 (gdb confirms).  So the
> call to memset() copies way over the end of allocated buf.
> 
> Does that sound rational?  I'm not very familiar with R's
> internals.  I guess small overruns might not actually fault,
> because buf is within R's existing heap?
> 
> > It is also unclear to me what to do in this case: flag a user 
> > error?
> 
> I'm not sure; perhaps the most logical thing is indeed to
> pad with nulls (as I think it would do with this fault
> fixed), and not raise an error at all.
> 
> > > Using readBin and writeBin with integer() and size=1 seems
> > > to be the solution for header copying, but the faults still
> > > seemed worth reporting.
> > 
> > It's certainly the documented way.
> 
> Yup.  I tried readChar/writeChar thinking it might be
> quicker (no type conversion?) but it's obviously not
> feasible with null-terminated strings.
> 
> Mark <><
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dmurdoch at pair.com  Sun Nov 16 01:23:54 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun Nov 16 01:23:53 2003
Subject: [Rd] REMINDER R-1.8.1 beta
In-Reply-To: <x2d6bvjag8.fsf@biostat.ku.dk>
References: <x2d6bvjag8.fsf@biostat.ku.dk>
Message-ID: <nogdrv8h00fv3de6l0iceektuueloe2m78@4ax.com>

On 14 Nov 2003 15:23:19 +0100, you wrote:

>
>R-1.8.1 has now reached the beta stage with one week left before
>release. This just to remind you that this would be a good time to
>give the new version a spin and see whether your favourite bugs have
>been cleared out.

I don't know how frequently I'll be able to update it, but I've just
uploaded a build of the beta to cran.  Go to cran.r-project.org, and
follow the links to the precompiled binary of the base distribution
for Windows.  The beta will be under the "rpatched" link sometime
tomorrow.

Duncan Murdoch

From edd at debian.org  Sun Nov 16 04:26:01 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun Nov 16 04:25:06 2003
Subject: [Rd] REMINDER R-1.8.1 beta
In-Reply-To: <nogdrv8h00fv3de6l0iceektuueloe2m78@4ax.com>
References: <x2d6bvjag8.fsf@biostat.ku.dk>
	<nogdrv8h00fv3de6l0iceektuueloe2m78@4ax.com>
Message-ID: <20031116032601.GA17564@sonny.eddelbuettel.com>

On Sat, Nov 15, 2003 at 07:23:54PM -0500, Duncan Murdoch wrote:
> On 14 Nov 2003 15:23:19 +0100, you wrote:
> 
> >
> >R-1.8.1 has now reached the beta stage with one week left before
> >release. This just to remind you that this would be a good time to
> >give the new version a spin and see whether your favourite bugs have
> >been cleared out.
> 
> I don't know how frequently I'll be able to update it, but I've just
> uploaded a build of the beta to cran.  Go to cran.r-project.org, and
> follow the links to the precompiled binary of the base distribution
> for Windows.  The beta will be under the "rpatched" link sometime
> tomorrow.

I did Debian last night. The autobuilders have mostly caught up (for ia64,
hppa, alpha, powerpc, sparc. arm, m68k and mipsel -- s390 failed due to some
internal inconsistency) and you should be able to apt-get this release from
Debian unstable mirrors soon.

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx

From hoonie at snu.ac.kr  Mon Nov 17 02:51:56 2003
From: hoonie at snu.ac.kr (hoonie@snu.ac.kr)
Date: Mon Nov 17 02:50:52 2003
Subject: [Rd] $RHOME/bin/check in windows (PR#5135)
Message-ID: <20031117015156.2C21DF31D@slim.kubism.ku.dk>

To whom it may concerned,

I'm trying to build a new R package in a windows platform.
Before that, I tried to check the previous well-know package from the CRAN
using the Rcmd command.
But I got the error messages as below.
I think this comes from the parsing error from the Perl script in $RHOME/bin/check.
In the following example, 'Program Files' is splited into 'Program', 
and this has made the R checking prosess halt.
What could I've done wrong?

---------------BELOW: ScreenShot from the windows console---------------
C:\Program Files\R\rw1080\src\library>Rcmd check qtl
* checking for working latex ...latex: not found
 NO
C:/Program Files/R/rw1080/src/library
* using log directory 'C:/Program Files/R/rw1080/src/library/qtl.Rcheck'
* checking for file 'ChromoViz/DESCRIPTION' ... OK
* checking if this is a source package ... OK

Error: cannot change to directory `C:/Program'
 ERROR
Installation failed.

---------------BELOW: Excerpt from the file $RHOME/bin/check ---------------
    chdir($startdir);
    $pkg =~ s/\/$//;
    (-d $pkg) or die "Error: package dir '$pkg' does not exist";
    chdir($pkg)
	or die "Error: cannot change to directory '$pkg'\n";

_________________________________________________________
Hoonie(Ji Hoon Kim)
SNUBI:Seoul National University Biomedical Informatics

+82-2-740-8318

From dmurdoch at pair.com  Mon Nov 17 03:40:14 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon Nov 17 03:39:00 2003
Subject: [Rd] $RHOME/bin/check in windows (PR#5135)
In-Reply-To: <20031117015156.2C21DF31D@slim.kubism.ku.dk>
References: <20031117015156.2C21DF31D@slim.kubism.ku.dk>
Message-ID: <l7dgrvknva1cmgu16gsmeuv9jv8anvf3u8@4ax.com>

On Mon, 17 Nov 2003 02:51:56 +0100 (CET), you wrote:

>To whom it may concerned,
>
>I'm trying to build a new R package in a windows platform.
>Before that, I tried to check the previous well-know package from the CRAN
>using the Rcmd command.
>But I got the error messages as below.
>I think this comes from the parsing error from the Perl script in $RHOME/bin/check.
>In the following example, 'Program Files' is splited into 'Program', 
>and this has made the R checking prosess halt.
>What could I've done wrong?

This is a known & documented problem, which we're unlikely to fix
unless someone who experiences it submits a patch. The readme.packages
file says this:

"BEWARE: Don't expect this to work if the path to R_HOME contains
spaces.  It may work, but we don't recommend it."

You seem to have one of the systems where it doesn't work.  You should
re-install R somewhere other than the "Program files" directory if you
want this to work relatively painlessly.

Duncan Murdoch

From ripley at stats.ox.ac.uk  Mon Nov 17 08:08:56 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Nov 17 08:07:45 2003
Subject: [Rd] $RHOME/bin/check in windows (PR#5135)
Message-ID: <20031117070856.03A07F331@slim.kubism.ku.dk>

Just to add: the package to be checked has been unpacked in a path with
spaces in _and_ Rcmd check was run from there.  You could try just
unpacking it in a more sensible place and running Rcmd check from there.

On Sun, 16 Nov 2003, Duncan Murdoch wrote:

> On Mon, 17 Nov 2003 02:51:56 +0100 (CET), you wrote:
> 
> >To whom it may concerned,
> >
> >I'm trying to build a new R package in a windows platform.
> >Before that, I tried to check the previous well-know package from the CRAN
> >using the Rcmd command.
> >But I got the error messages as below.
> >I think this comes from the parsing error from the Perl script in $RHOME/bin/check.
> >In the following example, 'Program Files' is splited into 'Program', 
> >and this has made the R checking prosess halt.
> >What could I've done wrong?
> 
> This is a known & documented problem, which we're unlikely to fix
> unless someone who experiences it submits a patch. The readme.packages
> file says this:
> 
> "BEWARE: Don't expect this to work if the path to R_HOME contains
> spaces.  It may work, but we don't recommend it."
> 
> You seem to have one of the systems where it doesn't work.  You should
> re-install R somewhere other than the "Program files" directory if you
> want this to work relatively painlessly.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Mon Nov 17 08:08:48 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Nov 17 08:09:45 2003
Subject: [Rd] $RHOME/bin/check in windows (PR#5135)
In-Reply-To: <l7dgrvknva1cmgu16gsmeuv9jv8anvf3u8@4ax.com>
Message-ID: <Pine.LNX.4.44.0311170703460.17690-100000@gannet.stats>

Just to add: the package to be checked has been unpacked in a path with
spaces in _and_ Rcmd check was run from there.  You could try just
unpacking it in a more sensible place and running Rcmd check from there.

On Sun, 16 Nov 2003, Duncan Murdoch wrote:

> On Mon, 17 Nov 2003 02:51:56 +0100 (CET), you wrote:
> 
> >To whom it may concerned,
> >
> >I'm trying to build a new R package in a windows platform.
> >Before that, I tried to check the previous well-know package from the CRAN
> >using the Rcmd command.
> >But I got the error messages as below.
> >I think this comes from the parsing error from the Perl script in $RHOME/bin/check.
> >In the following example, 'Program Files' is splited into 'Program', 
> >and this has made the R checking prosess halt.
> >What could I've done wrong?
> 
> This is a known & documented problem, which we're unlikely to fix
> unless someone who experiences it submits a patch. The readme.packages
> file says this:
> 
> "BEWARE: Don't expect this to work if the path to R_HOME contains
> spaces.  It may work, but we don't recommend it."
> 
> You seem to have one of the systems where it doesn't work.  You should
> re-install R somewhere other than the "Program files" directory if you
> want this to work relatively painlessly.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ligges at statistik.uni-dortmund.de  Mon Nov 17 08:12:45 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Nov 17 08:10:58 2003
Subject: [Rd] $RHOME/bin/check in windows (PR#5135)
In-Reply-To: <l7dgrvknva1cmgu16gsmeuv9jv8anvf3u8@4ax.com>
References: <20031117015156.2C21DF31D@slim.kubism.ku.dk>
	<l7dgrvknva1cmgu16gsmeuv9jv8anvf3u8@4ax.com>
Message-ID: <3FB874ED.3070600@statistik.uni-dortmund.de>

Duncan Murdoch wrote:

> On Mon, 17 Nov 2003 02:51:56 +0100 (CET), you wrote:
> 
> 
>>To whom it may concerned,
>>
>>I'm trying to build a new R package in a windows platform.
>>Before that, I tried to check the previous well-know package from the CRAN
>>using the Rcmd command.
>>But I got the error messages as below.
>>I think this comes from the parsing error from the Perl script in $RHOME/bin/check.
>>In the following example, 'Program Files' is splited into 'Program', 
>>and this has made the R checking prosess halt.
>>What could I've done wrong?
> 
> 
> This is a known & documented problem, which we're unlikely to fix
> unless someone who experiences it submits a patch. The readme.packages
> file says this:
> 
> "BEWARE: Don't expect this to work if the path to R_HOME contains
> spaces.  It may work, but we don't recommend it."
> 
> You seem to have one of the systems where it doesn't work.  You should
> re-install R somewhere other than the "Program files" directory if you
> want this to work relatively painlessly.
> 
> Duncan Murdoch


Let me add two points:

- You don't have LaTeX installed (properly), which is required to run 
"Rcmd check" completely.
- This is not a bug, so no reason to send a bug report.

Uwe Ligges

From pgilbert at bank-banque-canada.ca  Mon Nov 17 14:44:25 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon Nov 17 14:44:53 2003
Subject: [Rd] Nov 17 beta
Message-ID: <3FB8D0B9.1070500@bankofcanada.ca>

I'm having trouble with this mornings beta 
(R1.8.1beta_2003-11-17.tar.gz) I've downloaded it twice and I get 
"unexpected end of file" when I try to gunzip it.

Paul Gilbert

From MSchwartz at medanalytics.com  Mon Nov 17 15:25:53 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon Nov 17 15:26:33 2003
Subject: [Rd] Nov 17 beta
In-Reply-To: <3FB8D0B9.1070500@bankofcanada.ca>
References: <3FB8D0B9.1070500@bankofcanada.ca>
Message-ID: <1069079152.4563.15.camel@localhost.localdomain>

On Mon, 2003-11-17 at 07:44, Paul Gilbert wrote:
> I'm having trouble with this mornings beta 
> (R1.8.1beta_2003-11-17.tar.gz) I've downloaded it twice and I get 
> "unexpected end of file" when I try to gunzip it.
> 
> Paul Gilbert


Using: R-patched_2003-11-17.tar.gz 6168 KB 11/17/2003 02:05:00 AM

No problem here.  Unzipped and compiled fine.

"R : Copyright 2003, The R Foundation for Statistical Computing
Version 1.8.1 beta (2003-11-16), ISBN 3-900051-00-3"

HTH,

Marc Schwartz

From MSchwartz at medanalytics.com  Mon Nov 17 15:33:58 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon Nov 17 15:34:35 2003
Subject: [Rd] Nov 17 beta
In-Reply-To: <1069079152.4563.15.camel@localhost.localdomain>
References: <3FB8D0B9.1070500@bankofcanada.ca>
	<1069079152.4563.15.camel@localhost.localdomain>
Message-ID: <1069079637.4563.20.camel@localhost.localdomain>

On Mon, 2003-11-17 at 08:25, Marc Schwartz wrote:
> On Mon, 2003-11-17 at 07:44, Paul Gilbert wrote:
> > I'm having trouble with this mornings beta 
> > (R1.8.1beta_2003-11-17.tar.gz) I've downloaded it twice and I get 
> > "unexpected end of file" when I try to gunzip it.
> > 
> > Paul Gilbert
> 
> 
> Using: R-patched_2003-11-17.tar.gz 6168 KB 11/17/2003 02:05:00 AM
> 
> No problem here.  Unzipped and compiled fine.
> 
> "R : Copyright 2003, The R Foundation for Statistical Computing
> Version 1.8.1 beta (2003-11-16), ISBN 3-900051-00-3"
> 
> HTH,
> 
> Marc Schwartz


Sorry Paul, I just realized that you were using the full beta tar file
and not the patched version.

Indeed the full beta file seems to be too small if you look at the file
size.  It is only 1.6 Mb versus the previous files which are 9.0 Mb in
size.

My error and I can confirm the problem.

Marc

From p.dalgaard at biostat.ku.dk  Mon Nov 17 16:13:19 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Nov 17 16:05:28 2003
Subject: [Rd] Nov 17 beta
In-Reply-To: <1069079637.4563.20.camel@localhost.localdomain>
References: <3FB8D0B9.1070500@bankofcanada.ca>
	<1069079152.4563.15.camel@localhost.localdomain>
	<1069079637.4563.20.camel@localhost.localdomain>
Message-ID: <x2ad6v81v4.fsf@biostat.ku.dk>

Marc Schwartz <MSchwartz@medanalytics.com> writes:

> On Mon, 2003-11-17 at 08:25, Marc Schwartz wrote:
> > On Mon, 2003-11-17 at 07:44, Paul Gilbert wrote:
> > > I'm having trouble with this mornings beta 
> > > (R1.8.1beta_2003-11-17.tar.gz) I've downloaded it twice and I get 
> > > "unexpected end of file" when I try to gunzip it.
> > > 
> > > Paul Gilbert
> > 
> > 
> > Using: R-patched_2003-11-17.tar.gz 6168 KB 11/17/2003 02:05:00 AM
> > 
> > No problem here.  Unzipped and compiled fine.
> > 
> > "R : Copyright 2003, The R Foundation for Statistical Computing
> > Version 1.8.1 beta (2003-11-16), ISBN 3-900051-00-3"
> > 
> > HTH,
> > 
> > Marc Schwartz
> 
> 
> Sorry Paul, I just realized that you were using the full beta tar file
> and not the patched version.
> 
> Indeed the full beta file seems to be too small if you look at the file
> size.  It is only 1.6 Mb versus the previous files which are 9.0 Mb in
> size.
> 
> My error and I can confirm the problem.

The reason is this:

make[1]: Leaving directory `/e7/pd/r-patched/BUILD/R-1.8.1/src/library/Recommended'
mv: writing `/home/ftp/pub/CRAN/src/base/R-1.8.1beta_2003-11-17.tar.gz': No space left on device


I removed the alpha versions to get a little more space, so it should
be there now. Does sound a bit ominous that we're so close to the
limit, though.

        -p


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From MSchwartz at medanalytics.com  Mon Nov 17 16:51:55 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon Nov 17 16:55:24 2003
Subject: [Rd] Nov 17 beta
In-Reply-To: <x2ad6v81v4.fsf@biostat.ku.dk>
References: <3FB8D0B9.1070500@bankofcanada.ca>
	<1069079152.4563.15.camel@localhost.localdomain>
	<1069079637.4563.20.camel@localhost.localdomain>
	<x2ad6v81v4.fsf@biostat.ku.dk>
Message-ID: <1069084314.4563.43.camel@localhost.localdomain>

On Mon, 2003-11-17 at 09:13, Peter Dalgaard wrote:

SNIP

> 
> The reason is this:
> 
> make[1]: Leaving directory `/e7/pd/r-patched/BUILD/R-1.8.1/src/library/Recommended'
> mv: writing `/home/ftp/pub/CRAN/src/base/R-1.8.1beta_2003-11-17.tar.gz': No space left on device
> 
> 
> I removed the alpha versions to get a little more space, so it should
> be there now. Does sound a bit ominous that we're so close to the
> limit, though.
> 
>         -p


Peter,

Is that a problem unique to CRAN U.S. or something that all CRAN mirrors
might be facing?

Perhaps a short term fix would be to ascertain how many old versions of
R need to be online versus in an offline situation.

There is a fair amount of space for R version tar files back to 0.49. A
reasonable amount of space would be freed if say only the most recent 3
or 5 versions were made available online, if in fact even that many are
required online.

I do not know how many people need access to the old source tarballs,
but if someone has a compelling need, these could be made available in
some other fashion. If the space limitation is unique to CRAN U.S. and
there is a CRAN mirror that has access to additional space, that could
be the designated site for historic versions of R. That would reduce the
space requirements for all mirrors.

My tuppence.

Marc

From maechler at stat.math.ethz.ch  Mon Nov 17 20:06:27 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Nov 17 20:05:41 2003
Subject: [Rd] Re: Source of help.start()'s search java applets
In-Reply-To: <D368C8D5-192F-11D8-AE83-000A959F327E@math.uni-augsburg.de>
References: <6A6A4144-1928-11D8-9CC5-003065CC4CB8@mclink.it>
	<D368C8D5-192F-11D8-AE83-000A959F327E@math.uni-augsburg.de>
Message-ID: <16313.7219.406499.240225@gargle.gargle.HOWL>

>>>>> "Simon" == Simon Urbanek <simon.urbanek@math.uni-augsburg.de>
>>>>>     on Mon, 17 Nov 2003 19:57:00 +0100 writes:

    Simon> On Nov 17, 2003, at 7:03 PM, Stefano Iacus wrote:
    >> George,
    >> I don't think you'll be successfull to doing search from the browser  
    >> (any apart old versions of Netscape apparently).
    >> 
    >> If you cannot even start safari from RAqua that hte problem comes from  
    >> the libiconv library which is in your /usr/local/lib.

    Simon> BTW: Who is the author of the applet code and has the sources? It's  
    Simon> hard to debug it when you don't have the source code :P

Most of the programming originates from Thomas Baier AFAIK;
formally, the author now is R core and the source is in R's source :-) 
inside the  doc/html/search/*.java files.

Regards,
Martin

From slteng at stat.berkeley.edu  Tue Nov 18 08:03:35 2003
From: slteng at stat.berkeley.edu (Siew Leng TENG)
Date: Tue Nov 18 08:03:01 2003
Subject: [Rd] segmentation fault with using normalize.quantiles(),
	affy library
Message-ID: <Pine.SOL.4.50.0311172254570.21189-100000@antares.Berkeley.EDU>

Hi,

I am using R-1.8.1.alpha with affy_1.4.1 in Unix system, and now
experiencing "Segmentation fault" whenever I use normalize.quantiles() on a 34000x6
matrix. R gave "Segmentation fault", halted my codes and exited from R
without any other message. Affy was re-installed, and the same situation
happens again. No other messages were given.

Greatly appreciate any advice, and as to how I can possibly proceed on.

Thank you and good day,
Melinda

From phgrosjean at sciviews.org  Tue Nov 18 09:53:55 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue Nov 18 09:54:10 2003
Subject: [Rd] Power (^) 10x slower in R since version 1.7.1... What next?
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C20680AAA4@groexmb02.pfizer.com>
Message-ID: <MABBLJDICACNFOLGIHJOAEPFDOAA.phgrosjean@sciviews.org>

>Did the MingGW folks consider the simple solution of simply rounding the
>return result when the inputs are integers?

>-G

It seems this is the problem, rounding... because some fast algorithms
return wrong integers, but acceptable reals (given the precision). Also, it
seems that most of the decrease in performance is due to checking of
overflow and so on. Recent Intel processors (and certainly many others)
provide fast instructions for some usual mathematical functions, but they
are not used in MingW (any more), because they do not meet standards for
precision and error checking (note that I am not a specialist at all, that
is my understanding after searching on the net about it).

So, as I understand, it is possible to compute much much faster, but with
less "security" than in the current MingW version. However, people at MingW
priviledge precise and secure calculation at the expense of performance (to
meet standards).

There are certainly a few occasions in statistics (where the highest
precision in calculation often does not matter) when faster, but less
precise algorithms would be better... That is why I dream about a "fastmath"
R package to propose a faster alternative to ^, exp(), cos(),... When there
a factor ten in speed increase for ^, this is probably worthwhile. However,
this can only be a dream for me, since I cannot do it myself. I wonder if
someone else would be interested. In this case, http://www.willus.com/mingw/
could be probably a starting point.

Best,

Philippe Grosjean

> -----Original Message-----
> From: Philippe Grosjean [mailto:phgrosjean@sciviews.org]
> Sent: Wednesday, November 12, 2003 10:50 AM
> To: r-devel@stat.math.ethz.ch
> Subject: [Rd] Power (^) 10x slower in R since version 1.7.1... What
> next?
>
>
> OK, I have made a little search about this "problem" that
> apparently occurs
> only on Windows platform... (but I am sure most of you are
> already aware of
> it): the slow down is due to the adoption of a different
> algorithm for pow
> in mingw 3.x. This is motivated by some other changes in
> mingw. Here is a
> quote of Danny Smith that did this change:
>
> >When mingw changed default FPU settings from 53-bit mantissa
> >to 64 bit mantisa, the dll-provided pow function no longer
> >returned integral values when both operands were integral.
> Now, I don't
> >think that is a requiremnet of the standard but every other pow
> >implementation I looked at did that. So I changed to a well-tested
> >pow function (from the Cepehes math library) that did.  As
> you found out
> >it is expensive.
>
> >I have written another pow function that use exp2 and log2 library
> functions
> >rather than the polynomial expansion used by Cephes package.
>  It seems to
> be
> >accurarte enough (except when the result of pow is near 1.0 (eg,
> pow(1.00001, 0.99999))
> >and is as fast as the msvcrt.dll version.  I still need to
> tweak for cass
> >near range boundaries.
>
> >The other alternative is to write a wrapper for the wrapper
> for the dll
> pow,
> >to fix up the special cases when both args are integral.
> That doesn't add
> to
> >much overhead.
>
> >Danny
>
> Since pow is much, much slower in mingw 3.x than in mingw
> 2.x, other people
> started to search for a solution. I found this interesting enough:
> http://www.willus.com/mingw/ (look at "Some Fast Math
> Functions" at the end
> of the page).
>
> Thus here, there are two possibilities: to match the
> standards and provide
> full-proof math functions, like it is done in current mingw (and in R,
> consequently)... but sacrificing speed. Or, to rely to online
> assembler that
> uses Pentium or Athlon fast calculation potentials (but with
> less checking
> of errors) like Willus proposes.
>
> I think at this point, it should be the user's choice. So, R
> should propose
> both and should allow to switch from one to the other easily. Any
> suggestion? (one idea: make a fastmath package that would
> provide faster,
> but less error-proof ^, exp(), cos(), sin(),... functions).
> Unfortunately, I
> am not fluent enough in C and assembler to do it myself.
>
> Best,
>
> Philippe Grosjean
>
> ...........]<(({?<...............<?}))><......................
> .........
>  ) ) ) ) )
> ( ( ( ( (       Dr. Philippe Grosjean
>  ) ) ) ) )
> ( ( ( ( (       LOV, UMR 7093
>  ) ) ) ) )      Station Zoologique
> ( ( ( ( (       Observatoire Oc?anologique
>  ) ) ) ) )      BP 28
> ( ( ( ( (       06234 Villefranche sur mer cedex
>  ) ) ) ) )      France
> ( ( ( ( (
>  ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
> ( ( ( ( (
>  ) ) ) ) )      e-mail: phgrosjean@sciviews.org
> ( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
>  ) ) ) ) )
> ..............................................................
> .........
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

From ripley at stats.ox.ac.uk  Tue Nov 18 10:25:50 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Nov 18 10:25:12 2003
Subject: [Rd] Power (^) 10x slower in R since version 1.7.1... What next?
In-Reply-To: <MABBLJDICACNFOLGIHJOAEPFDOAA.phgrosjean@sciviews.org>
Message-ID: <Pine.LNX.4.44.0311180916390.23672-100000@gannet.stats>

Your subject line is seriously misleading: this is not `in R' but rather
in the pre-compiled binary of R on one OS (Windows) against one particular
runtime (which was actually changed long before R 1.7.1).

You could not do this by an `R package': that cannot change the runtime
code in use.  You (or someone else) could build R against an alternative
runtime library system, but it might be easier to use a better OS.

I have yet to see any real statistics application in which this made any
noticeable difference.  With modern processors one is talking about 10x
faster than a few milliseconds unless the datasets are going to take many
seconds even to load into R.  If you have such an application (a real
example where ^ takes more than say 20% of the total time of the
statistical analysis, and the total time is minutes) please share it.

On Tue, 18 Nov 2003, Philippe Grosjean wrote:

> >Did the MingGW folks consider the simple solution of simply rounding the
> >return result when the inputs are integers?
> 
> >-G
> 
> It seems this is the problem, rounding... because some fast algorithms
> return wrong integers, but acceptable reals (given the precision). Also, it
> seems that most of the decrease in performance is due to checking of
> overflow and so on. Recent Intel processors (and certainly many others)
> provide fast instructions for some usual mathematical functions, but they
> are not used in MingW (any more), because they do not meet standards for
> precision and error checking (note that I am not a specialist at all, that
> is my understanding after searching on the net about it).
> 
> So, as I understand, it is possible to compute much much faster, but with
> less "security" than in the current MingW version. However, people at MingW
> priviledge precise and secure calculation at the expense of performance (to
> meet standards).
> 
> There are certainly a few occasions in statistics (where the highest
> precision in calculation often does not matter) when faster, but less
> precise algorithms would be better... That is why I dream about a "fastmath"
> R package to propose a faster alternative to ^, exp(), cos(),... When there
> a factor ten in speed increase for ^, this is probably worthwhile. However,
> this can only be a dream for me, since I cannot do it myself. I wonder if
> someone else would be interested. In this case, http://www.willus.com/mingw/
> could be probably a starting point.
> 
> Best,
> 
> Philippe Grosjean
> 
> > -----Original Message-----
> > From: Philippe Grosjean [mailto:phgrosjean@sciviews.org]
> > Sent: Wednesday, November 12, 2003 10:50 AM
> > To: r-devel@stat.math.ethz.ch
> > Subject: [Rd] Power (^) 10x slower in R since version 1.7.1... What
> > next?
> >
> >
> > OK, I have made a little search about this "problem" that
> > apparently occurs
> > only on Windows platform... (but I am sure most of you are
> > already aware of
> > it): the slow down is due to the adoption of a different
> > algorithm for pow
> > in mingw 3.x. This is motivated by some other changes in
> > mingw. Here is a
> > quote of Danny Smith that did this change:
> >
> > >When mingw changed default FPU settings from 53-bit mantissa
> > >to 64 bit mantisa, the dll-provided pow function no longer
> > >returned integral values when both operands were integral.
> > Now, I don't
> > >think that is a requiremnet of the standard but every other pow
> > >implementation I looked at did that. So I changed to a well-tested
> > >pow function (from the Cepehes math library) that did.  As
> > you found out
> > >it is expensive.
> >
> > >I have written another pow function that use exp2 and log2 library
> > functions
> > >rather than the polynomial expansion used by Cephes package.
> >  It seems to
> > be
> > >accurarte enough (except when the result of pow is near 1.0 (eg,
> > pow(1.00001, 0.99999))
> > >and is as fast as the msvcrt.dll version.  I still need to
> > tweak for cass
> > >near range boundaries.
> >
> > >The other alternative is to write a wrapper for the wrapper
> > for the dll
> > pow,
> > >to fix up the special cases when both args are integral.
> > That doesn't add
> > to
> > >much overhead.
> >
> > >Danny
> >
> > Since pow is much, much slower in mingw 3.x than in mingw
> > 2.x, other people
> > started to search for a solution. I found this interesting enough:
> > http://www.willus.com/mingw/ (look at "Some Fast Math
> > Functions" at the end
> > of the page).
> >
> > Thus here, there are two possibilities: to match the
> > standards and provide
> > full-proof math functions, like it is done in current mingw (and in R,
> > consequently)... but sacrificing speed. Or, to rely to online
> > assembler that
> > uses Pentium or Athlon fast calculation potentials (but with
> > less checking
> > of errors) like Willus proposes.
> >
> > I think at this point, it should be the user's choice. So, R
> > should propose
> > both and should allow to switch from one to the other easily. Any
> > suggestion? (one idea: make a fastmath package that would
> > provide faster,
> > but less error-proof ^, exp(), cos(), sin(),... functions).
> > Unfortunately, I
> > am not fluent enough in C and assembler to do it myself.
> >
> > Best,
> >
> > Philippe Grosjean
> >
> > ...........]<(({?<...............<?}))><......................
> > .........
> >  ) ) ) ) )
> > ( ( ( ( (       Dr. Philippe Grosjean
> >  ) ) ) ) )
> > ( ( ( ( (       LOV, UMR 7093
> >  ) ) ) ) )      Station Zoologique
> > ( ( ( ( (       Observatoire Oc?anologique
> >  ) ) ) ) )      BP 28
> > ( ( ( ( (       06234 Villefranche sur mer cedex
> >  ) ) ) ) )      France
> > ( ( ( ( (
> >  ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
> > ( ( ( ( (
> >  ) ) ) ) )      e-mail: phgrosjean@sciviews.org
> > ( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
> >  ) ) ) ) )
> > ..............................................................
> > .........
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 
> LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From phgrosjean at sciviews.org  Tue Nov 18 11:06:36 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue Nov 18 11:06:09 2003
Subject: [Rd] Power (^) 10x slower in R since version 1.7.1... What next?
	[Windows platform]
In-Reply-To: <Pine.LNX.4.44.0311180916390.23672-100000@gannet.stats>
Message-ID: <MABBLJDICACNFOLGIHJOIEPIDOAA.phgrosjean@sciviews.org>

Prof Brian Ripley wrote:
>Your subject line is seriously misleading: this is not `in R' but rather
>in the pre-compiled binary of R on one OS (Windows) against one particular
>runtime (which was actually changed long before R 1.7.1).

OK, I have not tested on other platforms... However, this is also in R as a
consequence, as soon as R is compiled against the slower routines [in
Windows only]

>You could not do this by an `R package': that cannot change the runtime
>code in use.  You (or someone else) could build R against an alternative
>runtime library system, but it might be easier to use a better OS.

I compile my own version of R 1.8.0 against MingW 2.0.1 for this reason...
and I really agree with you: "it might be easier to use a better OS".
However, you should first convince the hundreds of people I target with my R
code. Those are biologists, ecologists, oceanographers,... and most of them
use Windows, not Linux/Unix. So, I am forced to use Windows myself.

>I have yet to see any real statistics application in which this made any
>noticeable difference.  With modern processors one is talking about 10x
>faster than a few milliseconds unless the datasets are going to take many
>seconds even to load into R.  If you have such an application (a real
>example where ^ takes more than say 20% of the total time of the
>statistical analysis, and the total time is minutes) please share it.

Here it is: I am working with very large datasets of zooplankton, containing
among others, results from image analyses on each individual. It is very
common in biology to transform/recode/calculate (or whatever you call it)
raw data according to precalibrated allometric relationships. Those have the
general form of Huxley's equation:

y = a.x^b

Now, you see what I mean: I have to transform about 17 measurements this way
for each individual in my multi-million entries dataset (note that I do not
compute the whole dataset at once), before using methods like LDA, learning
vector quantization (actually, your code from the VR bundle), or random
forest. In this case, especially with lda or lvq, which are pretty fast, it
really makes the difference in term of minutes in my PIV 2.8 Ghz with 1 Gb
memory... and Windows XP.

OK, I can understand that the R-core team does not have time to waste on
this problem, especially because they use a better OS. However, I know a lot
of people (the ones that will use my code to analyze their own zooplankton
series) that would benefit my "own faster-MingW 2.0-compiled R 1.8.0 Windows
version", or a better solution. So what? Do I have to distribute it myself?

Do I have to spot this problem in my benchmark test at
http://www.sciviews.org/other/benchmark.htm (25.7 sec for the whole test
with R 1.8.0 from CRAN against 11.9 sec for R 1.8.0 compiled with MingW
2.0.1 under Windows on the same computer)? I have not updated it since R
version 1.7.0 to avoid publishing such a bad result. And I have not posted
my own compiled R version online, because it is neither a good practice, nor
a good solution...

I am looking for a better solution.
Best,

Philippe Grosjean

From wolfram at fischer-zim.ch  Tue Nov 18 11:57:32 2003
From: wolfram at fischer-zim.ch (wolfram@fischer-zim.ch)
Date: Tue Nov 18 11:56:22 2003
Subject: [Rd] [R] help page of 'filled.contour': mistake in spelling
	(PR#5165)
Message-ID: <20031118105732.A3CADF341@slim.kubism.ku.dk>

``ouput'' should be ``output'':

The ouput produced by 'filled.contour' ...
     ^^

Wolfram

From ripley at stats.ox.ac.uk  Tue Nov 18 13:26:34 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Nov 18 13:26:10 2003
Subject: [Rd] Power (^) 10x slower in R since version 1.7.1... What next?
	[Windows platform]
In-Reply-To: <MABBLJDICACNFOLGIHJOIEPIDOAA.phgrosjean@sciviews.org>
Message-ID: <Pine.LNX.4.44.0311181220240.1547-100000@gannet.stats>

Why not use exp(y*log(x)) if it is adequate for your purposes?  It is 
faster under Windows.

There really is no value in using millions of cases in LVQ or LDA or, I
suspect, random forests.  But a difference of a few minutes means that
this is well under 20% of the total time unless your statistical analysis
is very much speedier than mine.

On Tue, 18 Nov 2003, Philippe Grosjean wrote:

> Prof Brian Ripley wrote:
> >Your subject line is seriously misleading: this is not `in R' but rather
> >in the pre-compiled binary of R on one OS (Windows) against one particular
> >runtime (which was actually changed long before R 1.7.1).
> 
> OK, I have not tested on other platforms... However, this is also in R as a
> consequence, as soon as R is compiled against the slower routines [in
> Windows only]
> 
> >You could not do this by an `R package': that cannot change the runtime
> >code in use.  You (or someone else) could build R against an alternative
> >runtime library system, but it might be easier to use a better OS.
> 
> I compile my own version of R 1.8.0 against MingW 2.0.1 for this reason...
> and I really agree with you: "it might be easier to use a better OS".
> However, you should first convince the hundreds of people I target with my R
> code. Those are biologists, ecologists, oceanographers,... and most of them
> use Windows, not Linux/Unix. So, I am forced to use Windows myself.
> 
> >I have yet to see any real statistics application in which this made any
> >noticeable difference.  With modern processors one is talking about 10x
> >faster than a few milliseconds unless the datasets are going to take many
> >seconds even to load into R.  If you have such an application (a real
> >example where ^ takes more than say 20% of the total time of the
> >statistical analysis, and the total time is minutes) please share it.
> 
> Here it is: I am working with very large datasets of zooplankton, containing
> among others, results from image analyses on each individual. It is very
> common in biology to transform/recode/calculate (or whatever you call it)
> raw data according to precalibrated allometric relationships. Those have the
> general form of Huxley's equation:
> 
> y = a.x^b
> 
> Now, you see what I mean: I have to transform about 17 measurements this way
> for each individual in my multi-million entries dataset (note that I do not
> compute the whole dataset at once), before using methods like LDA, learning
> vector quantization (actually, your code from the VR bundle), or random
> forest. In this case, especially with lda or lvq, which are pretty fast, it
> really makes the difference in term of minutes in my PIV 2.8 Ghz with 1 Gb
> memory... and Windows XP.
> 
> OK, I can understand that the R-core team does not have time to waste on
> this problem, especially because they use a better OS. However, I know a lot
> of people (the ones that will use my code to analyze their own zooplankton
> series) that would benefit my "own faster-MingW 2.0-compiled R 1.8.0 Windows
> version", or a better solution. So what? Do I have to distribute it myself?
> 
> Do I have to spot this problem in my benchmark test at
> http://www.sciviews.org/other/benchmark.htm (25.7 sec for the whole test
> with R 1.8.0 from CRAN against 11.9 sec for R 1.8.0 compiled with MingW
> 2.0.1 under Windows on the same computer)? I have not updated it since R
> version 1.7.0 to avoid publishing such a bad result. And I have not posted
> my own compiled R version online, because it is neither a good practice, nor
> a good solution...
> 
> I am looking for a better solution.
> Best,
> 
> Philippe Grosjean
> 
> 
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From phgrosjean at sciviews.org  Tue Nov 18 14:55:26 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue Nov 18 14:55:05 2003
Subject: [Rd] Power (^) 10x slower in R since version 1.7.1... What next?
	[Windows platform]
In-Reply-To: <Pine.LNX.4.44.0311181220240.1547-100000@gannet.stats>
Message-ID: <MABBLJDICACNFOLGIHJOIEPODOAA.phgrosjean@sciviews.org>

Prof Brian Ripley wrote:

>Why not use exp(y*log(x)) if it is adequate for your purposes?  It is
>faster under Windows.

I will try... Thank you for your advice.

>There really is no value in using millions of cases in LVQ or LDA or, I
>suspect, random forests.  But a difference of a few minutes means that
>this is well under 20% of the total time unless your statistical analysis
>is very much speedier than mine.

No, sorry, the millions of cases are predictions made according to a
training set build around circa 2,000 items. I have a prediction rate with a
method that combines lvq, lda and random forest of about 5,000 items / sec,
which is, roughly, 3 to 4 minutes for 1,000,000 items plus the time to load
the dataset, it is a little bit less than 9 minutes... but more than the
double with that slow ^. Ok, what is 10 minutes in a lifetime ;-)

On Tue, 18 Nov 2003, Philippe Grosjean wrote:

> Prof Brian Ripley wrote:
> >Your subject line is seriously misleading: this is not `in R' but rather
> >in the pre-compiled binary of R on one OS (Windows) against one
particular
> >runtime (which was actually changed long before R 1.7.1).
>
> OK, I have not tested on other platforms... However, this is also in R as
a
> consequence, as soon as R is compiled against the slower routines [in
> Windows only]
>
> >You could not do this by an `R package': that cannot change the runtime
> >code in use.  You (or someone else) could build R against an alternative
> >runtime library system, but it might be easier to use a better OS.
>
> I compile my own version of R 1.8.0 against MingW 2.0.1 for this reason...
> and I really agree with you: "it might be easier to use a better OS".
> However, you should first convince the hundreds of people I target with my
R
> code. Those are biologists, ecologists, oceanographers,... and most of
them
> use Windows, not Linux/Unix. So, I am forced to use Windows myself.
>
> >I have yet to see any real statistics application in which this made any
> >noticeable difference.  With modern processors one is talking about 10x
> >faster than a few milliseconds unless the datasets are going to take many
> >seconds even to load into R.  If you have such an application (a real
> >example where ^ takes more than say 20% of the total time of the
> >statistical analysis, and the total time is minutes) please share it.
>
> Here it is: I am working with very large datasets of zooplankton,
containing
> among others, results from image analyses on each individual. It is very
> common in biology to transform/recode/calculate (or whatever you call it)
> raw data according to precalibrated allometric relationships. Those have
the
> general form of Huxley's equation:
>
> y = a.x^b
>
> Now, you see what I mean: I have to transform about 17 measurements this
way
> for each individual in my multi-million entries dataset (note that I do
not
> compute the whole dataset at once), before using methods like LDA,
learning
> vector quantization (actually, your code from the VR bundle), or random
> forest. In this case, especially with lda or lvq, which are pretty fast,
it
> really makes the difference in term of minutes in my PIV 2.8 Ghz with 1 Gb
> memory... and Windows XP.
>
> OK, I can understand that the R-core team does not have time to waste on
> this problem, especially because they use a better OS. However, I know a
lot
> of people (the ones that will use my code to analyze their own zooplankton
> series) that would benefit my "own faster-MingW 2.0-compiled R 1.8.0
Windows
> version", or a better solution. So what? Do I have to distribute it
myself?
>
> Do I have to spot this problem in my benchmark test at
> http://www.sciviews.org/other/benchmark.htm (25.7 sec for the whole test
> with R 1.8.0 from CRAN against 11.9 sec for R 1.8.0 compiled with MingW
> 2.0.1 under Windows on the same computer)? I have not updated it since R
> version 1.7.0 to avoid publishing such a bad result. And I have not posted
> my own compiled R version online, because it is neither a good practice,
nor
> a good solution...
>
> I am looking for a better solution.
> Best,
>
> Philippe Grosjean
>
>
>
>

--
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From phgrosjean at sciviews.org  Tue Nov 18 14:57:55 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue Nov 18 14:57:34 2003
Subject: [Rd] Power (^) 10x slower in R since version 1.7.1... What
	next?[Windows platform]
In-Reply-To: <Pine.LNX.4.44.0311181220240.1547-100000@gannet.stats>
Message-ID: <MABBLJDICACNFOLGIHJOCEPPDOAA.phgrosjean@sciviews.org>

Prof. Brian Ripley wrote:
>Why not use exp(y*log(x)) if it is adequate for your purposes?  It is
>faster under Windows.

With the CRAN version of R 1.8.0 under Win Xp:
>  system.time(exp(3.45*log(runif(1000000))))
[1] 1.30 0.06 1.49   NA   NA
> system.time(runif(1000000)^3.45)
[1] 7.14 0.03 7.20   NA   NA

With R compiled using MingW 2.0.1 on the same machine:
> system.time(exp(3.45*log(runif(1000000))))
[1] 1.31 0.02 1.35   NA   NA
> system.time(runif(1000000)^3.45)
[1] 1.04 0.00 1.04   NA   NA

OK, this is fine for me. I define:
"%^%" <- function(a, b) return(exp(b*log(a)))
which I use as a substitute for ^ to make sure performance does not drop too
much under Windows with the current CRAN version of R in my application.
Thanks,

Philippe Grosjean

From Simon.Fear at synequanon.com  Tue Nov 18 17:24:59 2003
From: Simon.Fear at synequanon.com (Simon.Fear@synequanon.com)
Date: Tue Nov 18 17:23:43 2003
Subject: [Rd] address for bug reports? (PR#5170)
Message-ID: <20031118162459.3BF1CEDF0@slim.kubism.ku.dk>
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From Simon.Fear at synequanon.com  Tue Nov 18 17:25:11 2003
From: Simon.Fear at synequanon.com (Simon.Fear@synequanon.com)
Date: Tue Nov 18 17:24:04 2003
Subject: [Rd] address for bug reports? (PR#5171)
Message-ID: <20031118162511.D5DC5EDF0@slim.kubism.ku.dk>

bug.report() tells me to email to r-bugs@r-project.org, whereas
the Web site http://www.r-project.org/ points me to 
r-bugs@biostat.ku.dk.

Which should I believe?  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear@synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}

From Simon.Fear at synequanon.com  Tue Nov 18 17:34:32 2003
From: Simon.Fear at synequanon.com (Simon.Fear@synequanon.com)
Date: Tue Nov 18 17:33:15 2003
Subject: [Rd] plot, plot, methods, crash (PR#5172)
Message-ID: <20031118163432.9B296EDEF@slim.kubism.ku.dk>
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From Simon.Fear at synequanon.com  Tue Nov 18 17:34:48 2003
From: Simon.Fear at synequanon.com (Simon.Fear@synequanon.com)
Date: Tue Nov 18 17:33:34 2003
Subject: [Rd] plot, plot, methods, crash (PR#5173)
Message-ID: <20031118163448.2AFEAEDEF@slim.kubism.ku.dk>

(If this only happens in Win 98, I'm sure I could live with it. Just
may be helpful to report it, I hope.)

Start up R GUI, then

> plot(1:4,1:4)	# then close manually by clicking X
> plot(1:4,1:4)  # ditto
> methods(plot) 

sometimes produces normal output and even the following prompt, 
but then crashes immediately, or more often, crashes immediately with
no output.

I can do any number of plot() -methods() pairs, just not more than one
plot followed by methods(). I've tried plot x 2 followed by several other
functions without problems - methods() is the only one I know to fail.

For the above sequence the errror output is:

RGUI caused an invalid page fault in
module R.DLL at 0167:6b57d300.
Registers:
EAX=00000001 CS=0167 EIP=6b57d300 EFLGS=00010202
EBX=00000000 SS=016f ESP=0073c648 EBP=0073c660
ECX=00000101 DS=016f ESI=00000000 FS=2a17
EDX=019e1e38 ES=016f EDI=6b5f0000 GS=0000
Bytes at CS:EIP:
8b 10 83 fa 30 74 19 83 fa 50 74 14 89 45 08 8b 
Stack dump:
00000000 bff741f7 00000000 bff54e68 0001dce4 00000000 0073c6a0 6b57d470
00000001 0073c688 0073c6d4 0073c6ee 0000000d c01c0001 0073c6b8 6b57c18a 

>From bug.report("no connected email") just before the crash line:

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 1
 minor = 8.0
 year = 2003
 month = 10
 day = 08
 language = R

Windows 98 SE 4.10 (build 2222)  A 

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg,
package:nls, package:ts, Autoloads, package:base  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear@synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}

From p.dalgaard at biostat.ku.dk  Tue Nov 18 17:50:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Nov 18 17:41:46 2003
Subject: [Rd] address for bug reports? (PR#5171)
In-Reply-To: <20031118162511.D5DC5EDF0@slim.kubism.ku.dk>
References: <20031118162511.D5DC5EDF0@slim.kubism.ku.dk>
Message-ID: <x27k1x62pw.fsf@biostat.ku.dk>

Simon.Fear@synequanon.com writes:

> bug.report() tells me to email to r-bugs@r-project.org, whereas
> the Web site http://www.r-project.org/ points me to 
> r-bugs@biostat.ku.dk.
> 
> Which should I believe?  

Either should work, I believe. The latter is more direct, but the
former in principle independent of the location of the repository.

However: This is not a bug in R, and no reason to add to the already
considerable burden of manually moving stuff from "incoming" to
"trashcan" (twice)!

(Doug: the aliases on Franz do look a bit dodgy though.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Friedrich.Leisch at ci.tuwien.ac.at  Tue Nov 18 17:43:55 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Tue Nov 18 17:43:04 2003
Subject: [Rd] address for bug reports? (PR#5171)
In-Reply-To: <20031118162511.D5DC5EDF0@slim.kubism.ku.dk>
References: <20031118162511.D5DC5EDF0@slim.kubism.ku.dk>
Message-ID: <16314.19531.623362.201666@galadriel.ci.tuwien.ac.at>

>>>>> On Tue, 18 Nov 2003 17:25:11 +0100 (CET),
>>>>> Simon Fear (SF) wrote:

  > bug.report() tells me to email to r-bugs@r-project.org, whereas
  > the Web site http://www.r-project.org/ points me to 
  > r-bugs@biostat.ku.dk.

  > Which should I believe?


both, the generic r-bugs@r-project.org is an alias for the true
r-bugs@biostat.ku.dk.

.f

From Simon.Fear at synequanon.com  Tue Nov 18 17:54:04 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Tue Nov 18 17:54:09 2003
Subject: [Rd] address for bug reports? (PR#5171)
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572D27599@synequanon01>

True, it is not a bug, it is a meta-bug. You don't see many of
those about.

I'll shut up about this now.


> -----Original Message-----
> From: Peter Dalgaard [mailto:p.dalgaard@biostat.ku.dk]
> Sent: 18 November 2003 16:50
> To: Simon Fear
> Cc: r-devel@stat.math.ethz.ch; R-bugs@biostat.ku.dk
> Subject: Re: [Rd] address for bug reports? (PR#5171)
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> Simon.Fear@synequanon.com writes:
> 
> > bug.report() tells me to email to r-bugs@r-project.org, whereas
> > the Web site http://www.r-project.org/ points me to 
> > r-bugs@biostat.ku.dk.
> > 
> > Which should I believe?  
> 
> Either should work, I believe. The latter is more direct, but the
> former in principle independent of the location of the repository.
> 
> However: This is not a bug in R, and no reason to add to the already
> considerable burden of manually moving stuff from "incoming" to
> "trashcan" (twice)!
> 
> (Doug: the aliases on Franz do look a bit dodgy though.)
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: 
> (+45) 35327907
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear@synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}

From ripley at stats.ox.ac.uk  Tue Nov 18 18:23:53 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Nov 18 18:23:10 2003
Subject: [Rd] plot, plot, methods, crash (PR#5173)
In-Reply-To: <20031118163448.2AFEAEDEF@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0311181722080.818-100000@gannet.stats>

As you suspected it does not happen for me on Windows XP.

Any chance you could get some useful debugging information from Dr MinGW 
(see the rw-FAQ)?

On Tue, 18 Nov 2003 Simon.Fear@synequanon.com wrote:

> (If this only happens in Win 98, I'm sure I could live with it. Just
> may be helpful to report it, I hope.)
> 
> Start up R GUI, then
> 
> > plot(1:4,1:4)	# then close manually by clicking X
> > plot(1:4,1:4)  # ditto
> > methods(plot) 
> 
> sometimes produces normal output and even the following prompt, 
> but then crashes immediately, or more often, crashes immediately with
> no output.
> 
> I can do any number of plot() -methods() pairs, just not more than one
> plot followed by methods(). I've tried plot x 2 followed by several other
> functions without problems - methods() is the only one I know to fail.
> 
> For the above sequence the errror output is:
> 
> RGUI caused an invalid page fault in
> module R.DLL at 0167:6b57d300.
> Registers:
> EAX=00000001 CS=0167 EIP=6b57d300 EFLGS=00010202
> EBX=00000000 SS=016f ESP=0073c648 EBP=0073c660
> ECX=00000101 DS=016f ESI=00000000 FS=2a17
> EDX=019e1e38 ES=016f EDI=6b5f0000 GS=0000
> Bytes at CS:EIP:
> 8b 10 83 fa 30 74 19 83 fa 50 74 14 89 45 08 8b 
> Stack dump:
> 00000000 bff741f7 00000000 bff54e68 0001dce4 00000000 0073c6a0 6b57d470
> 00000001 0073c688 0073c6d4 0073c6ee 0000000d c01c0001 0073c6b8 6b57c18a 
> 
> >From bug.report("no connected email") just before the crash line:
> 
> --please do not edit the information below--
> 
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status = 
>  major = 1
>  minor = 8.0
>  year = 2003
>  month = 10
>  day = 08
>  language = R
> 
> Windows 98 SE 4.10 (build 2222)  A 
> 
> Search Path:
>  .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg,
> package:nls, package:ts, Autoloads, package:base  
>  
> Simon Fear 
> Senior Statistician 
> Syne qua non Ltd 
> Tel: +44 (0) 1379 644449 
> Fax: +44 (0) 1379 644445 
> email: Simon.Fear@synequanon.com 
> web: http://www.synequanon.com 
>   
> Number of attachments included with this message: 0 
>   
> This message (and any associated files) is confidential and\...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dmurdoch at pair.com  Wed Nov 19 00:06:06 2003
From: dmurdoch at pair.com (dmurdoch@pair.com)
Date: Wed Nov 19 00:04:47 2003
Subject: [Rd] plot, plot, methods, crash (PR#5173)
Message-ID: <20031118230606.5B709EDEC@slim.kubism.ku.dk>

On Tue, 18 Nov 2003 17:23:53 +0000 (GMT), you wrote:

>As you suspected it does not happen for me on Windows XP.

I get it in Win98, but not in XP.

>Any chance you could get some useful debugging information from Dr MinGW 
>(see the rw-FAQ)?

I'll see if I can work out what's happening.

Duncan Murdoch

From dmurdoch at pair.com  Wed Nov 19 03:47:59 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed Nov 19 03:46:51 2003
Subject: [Rd] plot, plot, methods, crash (PR#5173)
In-Reply-To: <20031118230606.5B709EDEC@slim.kubism.ku.dk>
References: <20031118230606.5B709EDEC@slim.kubism.ku.dk>
Message-ID: <m0mlrvo51mncf42k6f6absicc7o8r7dldt@4ax.com>

On Wed, 19 Nov 2003 00:06:06 +0100 (CET), you wrote:

>On Tue, 18 Nov 2003 17:23:53 +0000 (GMT), you wrote:
>
>>As you suspected it does not happen for me on Windows XP.
>
>I get it in Win98, but not in XP.
>
>>Any chance you could get some useful debugging information from Dr MinGW 
>>(see the rw-FAQ)?
>
>I'll see if I can work out what's happening.

I think I've got it.  The timer event to draw buffered graphics to the
screen was being triggered after the graphics window had closed, and
was getting a junk bitmap handle to work with.  I've patched devga.c
to prevent this, and it seems to work here.  I need to do a regular
(non-debug) build now and make sure this doesn't break something else,
then I'll commit the change.

Duncan Murdoch

From Simon.Fear at synequanon.com  Wed Nov 19 09:46:22 2003
From: Simon.Fear at synequanon.com (Simon.Fear@synequanon.com)
Date: Wed Nov 19 09:45:05 2003
Subject: [Rd] plot, plot, methods, crash (PR#5173)
Message-ID: <20031119084622.B514DF4DB@slim.kubism.ku.dk>
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From maechler at stat.math.ethz.ch  Wed Nov 19 10:03:29 2003
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Wed Nov 19 10:03:12 2003
Subject: [Rd] address for bug reports? (PR#5171)
Message-ID: <20031119090329.C79EAEDED@slim.kubism.ku.dk>

>>>>> "PD" == Peter Dalgaard <p.dalgaard@biostat.ku.dk>
>>>>>     on 18 Nov 2003 17:50:03 +0100 writes:

    PD> Simon.Fear@synequanon.com writes:
    >> bug.report() tells me to email to r-bugs@r-project.org, whereas
    >> the Web site http://www.r-project.org/ points me to 
    >> r-bugs@biostat.ku.dk.
    >> 
    >> Which should I believe?  

    PD> Either should work, I believe. The latter is more direct, but the
    PD> former in principle independent of the location of the repository.

Actually, there's quite a big difference nowadays between the two:
r-bugs@r-project.org is aliased to r-bugs@stat.math.ethz.ch
which 1) applies our anti-virus/spam filtering 
      2) forwards to r-bugs@*.dk

For that reason, I have advocated to advertize the
@r-project.org address *only*.
OTOH, that reason may become much less relevant when *.dk will
have its own anti-spam filters "real soon now" :-)

Martin

From dmurdoch at pair.com  Wed Nov 19 14:11:11 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed Nov 19 14:26:35 2003
Subject: [Rd] Unremovable directory (PR#4246)
Message-ID: <agqmrv0056bj8r87ns52t0kh9vte0vu5ed@4ax.com>

Back in September, you reported that you could create an unremovable
directory using the code

rpt.dir <- paste("c:/report/testR","bestsub",spe="/")
dir.create(rpt.dir)

The problem was that rpt.dir was set to "c:/report/testR bestsub /"
and Windows utilities have trouble with that name.

This is a Windows bug, not an R bug.

Just in case you haven't yet been able to remove the directory, one
way to do so is to go to a command window, and run

cd c:\report
rmdir "testR bestsub \"

Duncan Murdoch

From Peter.Ruckdeschel at uni-bayreuth.de  Wed Nov 19 18:50:36 2003
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Wed Nov 19 18:51:29 2003
Subject: [Rd] Was: setValidity and "initialize" method conflict ? [in R-help]
Message-ID: <3FBBAD6C.2000803@uni-bayreuth.de>

Hello,

Thomas Stabla (statho3@web.de) has already sent this
question to R-help,  Wed, 12 Nov 2003 21:21:31 +0100,
but we are not sure whether we should better post this
mail to this audience than to R-help:

---------------------------------------------------------------------

We are using S4-classes and want to force a validity check
when an object is created.

How can this be done, when an "initalize" method has been
set?

-------------------------------------------------------------------------
We got problems when using our own "initalize" method:

platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    7.1
year     2003
month    06
day      16
language R

[But the same behaviour ouccured under R 1.8.0]

Following piece of code works fine, just like we expected it to

-------------------------------------------------------------------------
 >setClass("Foo", representation(woo = "numeric"))
[1] "Foo"
 >validFooObject <- function(object) {
+   if(object@woo > 0) return(TRUE)
+   else return("warning: negative value for woo")}

 >setValidity("Foo", validFooObject)
[1] "Foo"

 >new("Foo", woo = 1) # all is fine
An object of class "Foo"
Slot "woo":
[1] 1

 >new("Foo", woo = -1) # ok, negative value
Error in validObject(.Object) : Invalid "Foo" object: warning: negative
value for woo

-------------------------------------------------------------------------

Now, if i define a initialize method for Foo, things change (R had
been restarted)

-------------------------------------------------------------------------
 >setClass("Foo", representation(woo = "numeric"))
[1] "Foo"

 >validFooObject <- function(object) {
+   if(object@woo > 0) return(TRUE)
+   else return("warning: negative value for woo")}

 >setValidity("Foo", validFooObject)
[1] "Foo"

 >setMethod("initialize", "Foo", function(.Object, woo){
+   .Object@woo = woo
+   .Object})
[1] "initialize"

 >new("Foo", woo = 1) # all is fine
An object of class "Foo"
Slot "woo":
[1] 1

 >new("Foo", woo = -1) # ! no warning, object created!
An object of class "Foo"
Slot "woo":
[1] -1
-------------------------------------------------------------------------

Thank you for your attention.
-- 

Peter Ruckdeschel

From jgentry at jimmy.harvard.edu  Wed Nov 19 23:38:27 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Wed Nov 19 23:36:50 2003
Subject: [Rd] Bioconductor Programmer's Reference
Message-ID: <Pine.SOL.4.20.0311191734560.5566-100000@santiam.dfci.harvard.edu>

Hello ...

As part of the work we are doing to provide useful information on the
Bioconductor Developer Page (available by clicking on the 'Developer Page'
link on the left hand side of www.bioconductor.org), we would like to
direct people's attention to the section entitled "Programmer's
Reference".  The intent is to provide papers and guidelines that provide
useful tips to R programmers.

Currently there are only a few documents in this section, but we are in
the process of writing more.  We would also welcome submissions that
people believe would be useful to the community as well as feedback &
input.

Thanks
Jeff Gentry

From jesusmro at canal21.com  Wed Nov 19 23:46:50 2003
From: jesusmro at canal21.com (jesusmro@canal21.com)
Date: Wed Nov 19 23:45:31 2003
Subject: [Rd] Rgui error (PR#5202)
Message-ID: <20031119224650.0299FEFC5@slim.kubism.ku.dk>

Full_Name: Jesus
Version: 1.8.0
OS: Windows Me
Submission from: (NULL) (62.83.208.146)


With the sequence:

library()
plot(0)
library()

Rgui crashes with the error "Rgui provoc? un error en KERNEL32.DLL. Rgui se
cerrar?"

From dmurdoch at pair.com  Thu Nov 20 04:21:35 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu Nov 20 04:21:11 2003
Subject: [Rd] Rgui error (PR#5202)
In-Reply-To: <20031119224650.0299FEFC5@slim.kubism.ku.dk>
References: <20031119224650.0299FEFC5@slim.kubism.ku.dk>
Message-ID: <ukcorv440cpu6ofrdr842fhc2fg2rps9s8@4ax.com>

On Wed, 19 Nov 2003 23:46:50 +0100 (CET), you wrote:

>Full_Name: Jesus
>Version: 1.8.0
>OS: Windows Me
>Submission from: (NULL) (62.83.208.146)
>
>
>With the sequence:
>
>library()
>plot(0)
>library()
>
>Rgui crashes with the error "Rgui provoc? un error en KERNEL32.DLL. Rgui se
>cerrar?"

Please try the latest version of R-patched, available at
<http://cran.r-project.org/bin/windows/base/rpatched/>.  This probably
fixes that error.   Please let me know two weeks ago if it doesn't
:-).

Duncan Murdoch

From ripley at stats.ox.ac.uk  Thu Nov 20 09:34:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Nov 20 09:33:35 2003
Subject: [Rd] Avoding scoping problems with model fit objects
Message-ID: <Pine.LNX.4.44.0311200806090.20158-100000@gannet.stats>

A week or so ago we had a query as to why an example not unlike

  foo <- c(1,1,0,0,1,1)
  rep <- 1:6
  m <- multinom(foo ~ rep)
  summary(m)

failed.  There was little special about multinom here, as

  m <- lm(foo ~ rep, model=FALSE)
  model.matrix(m)

also failed.  In tracking this down a couple of lessons have emerged.

There is a useful paper on `non-standard evaluation' by Thomas Lumley on
http://developer.r-project.org, but we need to dig a bit deeper.  Since ca
1.2.0 or so the environment of the formula of a model fit has been one of
the places used to look for the data used in that model fit.  
Unfortunately, it seems to have been assumed that object$call$formula
would give the environment: it does give the formula but not the
environment, whereas object$terms does usually give the environment (and
in some cases object$formula does too).  (Note that there is a danger
lurking here:  if there is no environment set, environment(foo) will give
NULL, and that is the base package/namespace.)

The final port of call to recreate the data is the parent env.  In this 
case model.frame() is called from model.matrix.default.  So the search for 
`rep' starts in model.matrix.default, and as that is in the base 
namespace, it looks in the namespace before the user's workspace.

What one really wants to do is to look in the environment of the original 
model fit.  We could keep a reference to that, but

- its contents might have changed and
- it would get saved with the object, probably bloating the saved session.

There is a better way, to save the model frame on the model object, which 
is why the example above has non-default args.  So:

Lesson 1

Supply a model= argument in your model-fititng functions and consider 
having model=TRUE as the default.  (I have added this in a few places in 
R-devel and my own packages, including to multinom.)

Also ensure that all the useful information is in the model frame, not
just variables needed in the formula but e.g. subset and weights.

Lesson 2

If you have a model.frame method in your package(s), please review it in
the light of the version of model.frame.lm in R-devel.  You need to ensure
that 

- a saved model frame is used if appropriate,
- the original environment(formula) is found correctly,
- that arguments such as data and subset are not ignored.

I have added code to model.frame.default which may make most of the
simpler model.frame methods unnecessary.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jmc at research.bell-labs.com  Thu Nov 20 15:53:54 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Thu Nov 20 15:53:49 2003
Subject: [Rd] Was: setValidity and "initialize" method conflict ? [in
	R-help]
References: <3FBBAD6C.2000803@uni-bayreuth.de>
Message-ID: <3FBCD582.F70EAC2B@research.bell-labs.com>

Peter Ruckdeschel wrote:
> 
> Hello,
> 
> Thomas Stabla (statho3@web.de) has already sent this
> question to R-help,  Wed, 12 Nov 2003 21:21:31 +0100,
> but we are not sure whether we should better post this
> mail to this audience than to R-help:
> 
> ---------------------------------------------------------------------
> 
> We are using S4-classes and want to force a validity check
> when an object is created.
> 
> How can this be done, when an "initalize" method has been
> set?

The basic point is that the call to validObject() occurs in the default
method for initialize(), and only when some arguments have been included
in the call to new() in addition to the class name.  (Do
getMethod("initialize") to see the definition.)

When you override the default method, you have a choice of whether to
call validObject() or not (you might not want to if you're fussy about
efficiency).

If you do want to validate the object, there are two ways to do so:

1- Use callNextMethod to call the default method as part of your method
(this is often a good idea anyway).

2- call validObject directly after initializing the object.

Here's an example, run against the current 1.8.1 patched.

R> validC1 <- function(object) {
    if (all(object@x > 0)) 
        TRUE
    else "Negative values not allowed in x slot"
}
R> setClass("C1", representation(x = "numeric"), validity = validC1)
[1] "C1"
R> setClass("C2", representation(id = "character"), contains = "C1")
[1] "C2"

By the way, in the validity method you should not return a call to
warning() as in your example.  The validity method just returns a
character string describing the problem.

To define an initialize method for C2 in the first way, do something
like:

R> setMethod("initialize", "C2", function(.Object, x, 
    id) {
    callNextMethod(.Object, x = x)
    .Object@id <- id
    .Object
})
[1] "initialize"

Then:
R> new("C2", x = 1, id = "OK")
An object of class "C2"
Slot "id":
[1] "OK"

Slot "x":
numeric(0)


R> try(new("C2", x = -1, id = "BAD!"))
Error in validObject(.Object) : Invalid "C2" object: Negative values not
allowed in x slot

The same effect is obtained in the second way by something like:

R> setMethod("initialize", "C2", function(.Object, x, 
    id) {
    .Object@x <- x
    .Object@id <- id
    validObject(.Object)
    .Object
})

John Chambers




> 
> -------------------------------------------------------------------------
> We got problems when using our own "initalize" method:
> 
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    7.1
> year     2003
> month    06
> day      16
> language R
> 
> [But the same behaviour ouccured under R 1.8.0]
> 
> Following piece of code works fine, just like we expected it to
> 
> -------------------------------------------------------------------------
>  >setClass("Foo", representation(woo = "numeric"))
> [1] "Foo"
>  >validFooObject <- function(object) {
> +   if(object@woo > 0) return(TRUE)
> +   else return("warning: negative value for woo")}
> 
>  >setValidity("Foo", validFooObject)
> [1] "Foo"
> 
>  >new("Foo", woo = 1) # all is fine
> An object of class "Foo"
> Slot "woo":
> [1] 1
> 
>  >new("Foo", woo = -1) # ok, negative value
> Error in validObject(.Object) : Invalid "Foo" object: warning: negative
> value for woo
> 
> -------------------------------------------------------------------------
> 
> Now, if i define a initialize method for Foo, things change (R had
> been restarted)
> 
> -------------------------------------------------------------------------
>  >setClass("Foo", representation(woo = "numeric"))
> [1] "Foo"
> 
>  >validFooObject <- function(object) {
> +   if(object@woo > 0) return(TRUE)
> +   else return("warning: negative value for woo")}
> 
>  >setValidity("Foo", validFooObject)
> [1] "Foo"
> 
>  >setMethod("initialize", "Foo", function(.Object, woo){
> +   .Object@woo = woo
> +   .Object})
> [1] "initialize"
> 
>  >new("Foo", woo = 1) # all is fine
> An object of class "Foo"
> Slot "woo":
> [1] 1
> 
>  >new("Foo", woo = -1) # ! no warning, object created!
> An object of class "Foo"
> Slot "woo":
> [1] -1
> -------------------------------------------------------------------------
> 
> Thank you for your attention.
> --
> 
> Peter Ruckdeschel
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From jmc at research.bell-labs.com  Thu Nov 20 16:11:23 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Thu Nov 20 16:10:34 2003
Subject: [Rd] Was: setValidity and "initialize" method conflict ?
	[inR-help]
References: <3FBBAD6C.2000803@uni-bayreuth.de>
	<3FBCD582.F70EAC2B@research.bell-labs.com>
Message-ID: <3FBCD99B.16F63F39@research.bell-labs.com>

John Chambers wrote:
.....................
> 
>
> 
> By the way, in the validity method you should not return a call to
> warning() as in your example.  The validity method just returns a
> character string describing the problem.

Sorry, I misread the example, the "warning" was just in the character
string.  Still, might be confusing since the result is normally an
error, rather than a warning.

John

> 

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From finnknudsen at post.tele.dk  Thu Nov 20 16:31:36 2003
From: finnknudsen at post.tele.dk (finnknudsen@post.tele.dk)
Date: Thu Nov 20 16:30:17 2003
Subject: [Rd] glm inconsistent behaviour (PR#5213)
Message-ID: <20031120153136.27CBEF0AE@slim.kubism.ku.dk>

Full_Name: Finn Knudsen
Version: 1.8.0
OS: windows 2000
Submission from: (NULL) (194.192.22.33)


The problem seems to happen when running the GLM. When both multiplicative
effects and an offset is present. I experienced this problem on my own dataset
when using af Poisson familiy with log link function but the behaviour can be
reproduced with the following code.

I do not know if it is a bug, but there are inconsistencies in the behaviour in
the GLM package when both an offset and multiplicative effects are present. In
this situation offset should be specified directly and not in the model. See
example below.

library(MASS)

data(anorexia)
 
## End Don't run

# These two will give exactly the same result in the summary
anorex.1 <- glm(Postwt ~ Prewt + Treat + offset(Prewt),
                 family = gaussian, data = anorexia)

anorex.1a <- glm(Postwt ~ Prewt + Treat , offset = Prewt,
                 family = gaussian, data = anorexia)

summary(anorex.1)
summary(anorex.1a)

# However the following two will not give the same results. 
# It would seem that the multiplicative effect is lost.

anorex.2 <- glm(Postwt ~ Prewt * Treat + offset(Prewt),
                 family = gaussian, data = anorexia)

anorex.2a <- glm(Postwt ~ Prewt * Treat , offset = Prewt,
                 family = gaussian, data = anorexia)


summary(anorex.2)
summary(anorex.2a)

From ripley at stats.ox.ac.uk  Thu Nov 20 17:14:02 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Nov 20 17:13:07 2003
Subject: [Rd] glm inconsistent behaviour (PR#5213)
In-Reply-To: <20031120153136.27CBEF0AE@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0311201610160.21268-100000@gannet.stats>

Please try R-patched aka 1.8.1 beta, as I think this has already been
fixed (PR#4941). Certainly I can see no difference there.

On Thu, 20 Nov 2003 finnknudsen@post.tele.dk wrote:

> Full_Name: Finn Knudsen
> Version: 1.8.0
> OS: windows 2000
> Submission from: (NULL) (194.192.22.33)
> 
> 
> The problem seems to happen when running the GLM. When both multiplicative
> effects and an offset is present. I experienced this problem on my own dataset
> when using af Poisson familiy with log link function but the behaviour can be
> reproduced with the following code.
> 
> I do not know if it is a bug, but there are inconsistencies in the behaviour in
> the GLM package when both an offset and multiplicative effects are present. In
> this situation offset should be specified directly and not in the model. See
> example below.
> 
> library(MASS)
> 
> data(anorexia)

Not needed, BTW

> ## End Don't run
> 
> # These two will give exactly the same result in the summary
> anorex.1 <- glm(Postwt ~ Prewt + Treat + offset(Prewt),
>                  family = gaussian, data = anorexia)
> 
> anorex.1a <- glm(Postwt ~ Prewt + Treat , offset = Prewt,
>                  family = gaussian, data = anorexia)
> 
> summary(anorex.1)
> summary(anorex.1a)
> 
> # However the following two will not give the same results. 
> # It would seem that the multiplicative effect is lost.
> 
> anorex.2 <- glm(Postwt ~ Prewt * Treat + offset(Prewt),
>                  family = gaussian, data = anorexia)
> 
> anorex.2a <- glm(Postwt ~ Prewt * Treat , offset = Prewt,
>                  family = gaussian, data = anorexia)
> 
> 
> summary(anorex.2)
> summary(anorex.2a)
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rpeng at jhsph.edu  Fri Nov 21 16:50:56 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri Nov 21 16:50:44 2003
Subject: [Rd] Using log() on an openMosix cluster
Message-ID: <3FBE3460.50109@jhsph.edu>

Hi all, I was hoping to get some advice about a problem that I realize 
will be difficult to reproduce for some people.  I'm running R 1.7.1 on 
an openMosix (Linux) cluster and have been experiencing some odd 
slow-downs.  If anyone has experience with such a setup (or a similar 
one) I'd appreciate any help.  Here's a simplified version of the problem.

I'm trying to run the following code:
##
N <- 100000; a <- numeric(N); b <- numeric(N)
e <- rnorm(N)

for(i in 1:N) {
         a[i] <- exp(e[i])
         b[i] <- log(abs(a[i]))
}
##

When I run it on the head node, everything is fine.  However, when I 
send the R process off to one of the cluster nodes (i.e. using mosrun 
from the head node) the program takes about 10 times longer (in 
wall-clock time, cpu time is roughly the same).

Interestingly, when I tried running the following code:
##
N <- 100000; a <- numeric(N); b <- numeric(N)
e <- rnorm(N)

for(i in 1:N) {
         a[i] <- exp(e[i])
         b[i] <- exp(abs(a[i]))
}
##

I didn't experience any slow-down!  That is the wall-clock time is the 
same when run on the head node or on the cluster nodes.  The only 
difference between the two programs is that one takes a log in the for() 
loop and the other one takes an exponential.

I guess my question is why would taking the log() produce a 10 fold 
increase in runtime?  I know that Mosix clusters can experience serious 
performance hits if you make a lot of system calls or write out data to 
files but I don't think I'm doing that here.  Is there some major 
difference in the way that exp() and log() are implemented?

I'm pretty sure this isn't an R problem but I'm wondering if R is doing 
something behind the scenes that's affecting performance in the 
openMosix setting.

Thanks in advance for any help.

-roger

From bates at stat.wisc.edu  Fri Nov 21 23:35:49 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Nov 21 23:34:33 2003
Subject: [Rd] Sources for R-1.8.1 available via rsync
Message-ID: <6rr801uz7e.fsf@bates4.stat.wisc.edu>

The sources for R-1.8.1 are now available via rsync from
rsync.r-project.org

From kleiweg at let.rug.nl  Sun Nov 23 15:08:23 2003
From: kleiweg at let.rug.nl (Peter Kleiweg)
Date: Sun Nov 23 15:07:08 2003
Subject: [Rd] make check reg-tests-3
Message-ID: <Pine.LNX.4.44.0311231507060.1337-100000@kleigh.nl>


Should I submit this as a bug report?


--- reg-tests-3.Rout.save	Thu Jul  3 09:55:40 2003
+++ reg-tests-3.Rout	Sun Nov 23 13:10:57 2003
@@ -1,17 +1,18 @@

-R : Copyright 2003, The R Development Core Team
-Version 1.8.0 Under development (unstable) (2003-07-03)
+R : Copyright 2003, The R Foundation for Statistical Computing
+Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3

 R is free software and comes with ABSOLUTELY NO WARRANTY.
 You are welcome to redistribute it under certain conditions.
-Type `license()' or `licence()' for distribution details.
+Type 'license()' or 'licence()' for distribution details.

 R is a collaborative project with many contributors.
-Type `contributors()' for more information.
+Type 'contributors()' for more information and
+'citation()' on how to cite R in publications.

-Type `demo()' for some demos, `help()' for on-line help, or
-`help.start()' for a HTML browser interface to help.
-Type `q()' to quit R.
+Type 'demo()' for some demos, 'help()' for on-line help, or
+'help.start()' for a HTML browser interface to help.
+Type 'q()' to quit R.

 > ### Regression tests for which the printed output is the issue
 > ### May fail, e.g. by needing Recommended packages
@@ -137,7 +138,7 @@
 54  0.0989545407 -1.357243e-05 -3.683573e-02 -0.028339562 -0.025145841
 55  0.1644148644 -1.347342e-04  1.507463e-01  0.272775865  0.355144259
 56 -1.0973102505  2.844224e-04 -2.939639e-01 -0.267067176 -0.586604116
-57           NaN           NaN           NaN          NaN          NaN
+57  0.0000000000  0.000000e+00  0.000000e+00  0.000000000  0.000000000
 58  1.1181936467 -1.814925e-04  1.820092e-01  0.230407448  0.281788680
 59 -0.1289781075  2.595372e-05 -3.776833e-02 -0.058580136 -0.126069473
 60  0.4827651281 -1.458463e-04  9.396412e-02 -0.005593267  0.099263965
@@ -231,7 +232,7 @@
 54 -0.0150792891   -0.0425585103  6.777594e-03  0.0030583353 -0.0591176911
 55  0.4668348880   -0.0212547234  4.732189e-01  0.4185931034  0.2944838529
 56 -0.7432312183   -0.2735589895 -6.870778e-02 -0.0393632338  0.1816128390
-57           NaN             NaN           NaN           NaN           NaN
+57  0.0000000000    0.0000000000  0.000000e+00  0.0000000000  0.0000000000
 58  0.1945880055   -0.5587521455 -2.266734e-01 -0.3613221042 -0.5509923750
 59 -0.0900361434    0.0807855154 -8.877433e-04 -0.0437027380  0.0203231292
 60  0.2757970992   -0.3494459094  2.397384e-01  0.1279587545 -0.1512732820
@@ -325,7 +326,7 @@
 54 -0.0052948316  0.0043390590 -0.0062558306   -0.0100922249  -0.0036764450
 55  0.3245941919  0.4533108376 -0.1196342985   -0.0946588832   0.0778256270
 56  0.1438282891 -0.5411631576  0.0968253310    0.3927869929   0.2777652749
-57           NaN           NaN           NaN             NaN            NaN
+57  0.0000000000  0.0000000000  0.0000000000    0.0000000000   0.0000000000
 58 -0.5770947483 -0.1184054962 -0.1740228604   -0.0285545091   0.7693037902
 59  0.0412280879 -0.0075198458  0.0438882586    0.0121450418  -0.1252262379
 60  0.3533541160  0.2760694598 -0.1036620689    0.1001975219   0.0703124944
@@ -379,7 +380,7 @@
       49       50       51       52       53       54       55       56
 3.588734 3.589710 3.583459 3.581755 3.599157 3.599895 3.528075 3.559578
       57       58       59       60       61       62       63       64
-     NaN 3.523963 3.598459 3.571771 3.582319 3.600406 3.596626 3.592960
+3.601231 3.523963 3.598459 3.571771 3.582319 3.600406 3.596626 3.592960
       65       66       67       68       69       70       71       72
 3.583325 3.600828 3.569987 3.592482 3.599979 3.580547 3.600799 3.599768
       73       74       75       76       77       78       79       80
@@ -432,44 +433,57 @@
 Potentially influential observations of
 	 lm(formula = 1000/MPG.city ~ Weight + Cylinders + Type + EngineSize +      DriveTrain, data = Cars93) :

-   dfb.1_ dfb.Wght dfb.Cyl4 dfb.Cyl5 dfb.Cyl6 dfb.Cyl8 dfb.Cyln dfb.TypL
-8  -0.16   0.00    -0.10    -0.07    -0.24    -0.44     0.01     0.12
-19 -0.03   0.09    -0.01    -0.03     0.00    -0.01    -0.03     0.08
-28  0.11  -0.15     0.04     0.02     0.02     0.02     0.04     0.07
-39 -0.19   0.05     0.34     0.21     0.25     0.18     0.18    -0.01
-42  0.12  -0.04    -0.30    -0.17    -0.28    -0.26    -0.11    -0.03
-57   NaN    NaN      NaN      NaN      NaN      NaN      NaN      NaN
-66 -0.03   0.04    -0.02    -0.03    -0.01     0.00    -0.02    -0.01
-80  0.18   0.00    -0.31    -0.17    -0.24    -0.19    -0.15     0.00
-83  0.01   0.01    -0.04    -0.03    -0.04    -0.03    -0.02     0.00
-87 -0.03   0.04    -0.01    -0.04    -0.04    -0.03    -0.02     0.04
-89 -0.11   0.11    -0.05     0.28    -0.06    -0.04    -0.06    -0.01
-93 -0.11   0.11    -0.05    -0.45    -0.06    -0.04    -0.06    -0.01
-   dfb.TypM dfb.TypSm dfb.TypSp dfb.TypV dfb.EngS dfb.DrTF dfb.DrTR dffit
-8   0.00     0.21      0.06     -0.04     0.47    -0.04     0.03     0.73
-19  0.01     0.00     -0.04     -0.01    -0.15     0.01     0.02    -0.24
-28  0.08    -0.08     -0.09      0.16     0.06     0.09     0.12    -0.26
-39 -0.01     0.04      0.01     -0.06     0.01    -0.08    -0.08    -0.44
-42  0.01    -0.42      0.01     -0.03     0.18    -0.10    -0.11    -0.89
-57   NaN      NaN       NaN       NaN      NaN      NaN      NaN      NaN
-66 -0.02     0.01      0.01      0.02    -0.03     0.05     0.03     0.08
-80  0.01     0.01     -0.02     -0.07     0.01    -0.18    -0.14     0.45
-83  0.00     0.00      0.00      0.00     0.00     0.01     0.01     0.05
-87  0.03     0.02      0.03      0.06    -0.02    -0.03    -0.02     0.14
-89 -0.07     0.05      0.04      0.08    -0.06     0.12     0.10     0.64
-93 -0.07     0.05      0.04      0.08    -0.06     0.12     0.10    -0.64
-   cov.r   cook.d  hat
-8   1.71_*  0.04    0.39
-19  2.09_*  0.00    0.43
-28  1.86_*  0.00    0.36
-39  1.76_*  0.01    0.36
-42  0.13_*  0.05    0.06
-57   NaN     Inf_*  1.00_*
-66  1.63_*  0.00    0.26
-80  1.92_*  0.01    0.40
-83  1.88_*  0.00    0.36
-87  1.60_*  0.00    0.25
-89  2.68_*  0.03    0.57_*
-93  2.68_*  0.03    0.57_*
+   dfb.1_       dfb.Wght     dfb.Cyl4     dfb.Cyl5     dfb.Cyl6
+8  -1.60000e-01  0.00000e+00 -1.00000e-01 -7.00000e-02 -2.40000e-01
+19 -3.00000e-02  9.00000e-02 -1.00000e-02 -3.00000e-02  0.00000e+00
+28  1.10000e-01 -1.50000e-01  4.00000e-02  2.00000e-02  2.00000e-02
+39 -1.90000e-01  5.00000e-02  3.40000e-01  2.10000e-01  2.50000e-01
+42  1.20000e-01 -4.00000e-02 -3.00000e-01 -1.70000e-01 -2.80000e-01
+57  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00
+66 -3.00000e-02  4.00000e-02 -2.00000e-02 -3.00000e-02 -1.00000e-02
+80  1.80000e-01  0.00000e+00 -3.10000e-01 -1.70000e-01 -2.40000e-01
+83  1.00000e-02  1.00000e-02 -4.00000e-02 -3.00000e-02 -4.00000e-02
+87 -3.00000e-02  4.00000e-02 -1.00000e-02 -4.00000e-02 -4.00000e-02
+89 -1.10000e-01  1.10000e-01 -5.00000e-02  2.80000e-01 -6.00000e-02
+93 -1.10000e-01  1.10000e-01 -5.00000e-02 -4.50000e-01 -6.00000e-02
+   dfb.Cyl8     dfb.Cyln     dfb.TypL     dfb.TypM     dfb.TypSm
+8  -4.40000e-01  1.00000e-02  1.20000e-01  0.00000e+00  2.10000e-01
+19 -1.00000e-02 -3.00000e-02  8.00000e-02  1.00000e-02  0.00000e+00
+28  2.00000e-02  4.00000e-02  7.00000e-02  8.00000e-02 -8.00000e-02
+39  1.80000e-01  1.80000e-01 -1.00000e-02 -1.00000e-02  4.00000e-02
+42 -2.60000e-01 -1.10000e-01 -3.00000e-02  1.00000e-02 -4.20000e-01
+57  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00
+66  0.00000e+00 -2.00000e-02 -1.00000e-02 -2.00000e-02  1.00000e-02
+80 -1.90000e-01 -1.50000e-01  0.00000e+00  1.00000e-02  1.00000e-02
+83 -3.00000e-02 -2.00000e-02  0.00000e+00  0.00000e+00  0.00000e+00
+87 -3.00000e-02 -2.00000e-02  4.00000e-02  3.00000e-02  2.00000e-02
+89 -4.00000e-02 -6.00000e-02 -1.00000e-02 -7.00000e-02  5.00000e-02
+93 -4.00000e-02 -6.00000e-02 -1.00000e-02 -7.00000e-02  5.00000e-02
+   dfb.TypSp    dfb.TypV     dfb.EngS     dfb.DrTF     dfb.DrTR
+8   6.00000e-02 -4.00000e-02  4.70000e-01 -4.00000e-02  3.00000e-02
+19 -4.00000e-02 -1.00000e-02 -1.50000e-01  1.00000e-02  2.00000e-02
+28 -9.00000e-02  1.60000e-01  6.00000e-02  9.00000e-02  1.20000e-01
+39  1.00000e-02 -6.00000e-02  1.00000e-02 -8.00000e-02 -8.00000e-02
+42  1.00000e-02 -3.00000e-02  1.80000e-01 -1.00000e-01 -1.10000e-01
+57  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00
+66  1.00000e-02  2.00000e-02 -3.00000e-02  5.00000e-02  3.00000e-02
+80 -2.00000e-02 -7.00000e-02  1.00000e-02 -1.80000e-01 -1.40000e-01
+83  0.00000e+00  0.00000e+00  0.00000e+00  1.00000e-02  1.00000e-02
+87  3.00000e-02  6.00000e-02 -2.00000e-02 -3.00000e-02 -2.00000e-02
+89  4.00000e-02  8.00000e-02 -6.00000e-02  1.20000e-01  1.00000e-01
+93  4.00000e-02  8.00000e-02 -6.00000e-02  1.20000e-01  1.00000e-01
+   dffit        cov.r          cook.d       hat
+8   7.30000e-01  1.71000e+00_*  4.00000e-02  3.90000e-01
+19 -2.40000e-01  2.09000e+00_*  0.00000e+00  4.30000e-01
+28 -2.60000e-01  1.86000e+00_*  0.00000e+00  3.60000e-01
+39 -4.40000e-01  1.76000e+00_*  1.00000e-02  3.60000e-01
+42 -8.90000e-01  1.30000e-01_*  5.00000e-02  6.00000e-02
+57  4.00000e-02  1.09307e+16_*  0.00000e+00  1.00000e+00_*
+66  8.00000e-02  1.63000e+00_*  0.00000e+00  2.60000e-01
+80  4.50000e-01  1.92000e+00_*  1.00000e-02  4.00000e-01
+83  5.00000e-02  1.88000e+00_*  0.00000e+00  3.60000e-01
+87  1.40000e-01  1.60000e+00_*  0.00000e+00  2.50000e-01
+89  6.40000e-01  2.68000e+00_*  3.00000e-02  5.70000e-01_*
+93 -6.40000e-01  2.68000e+00_*  3.00000e-02  5.70000e-01_*
 > ## only last two cols in row 57 should be influential
 >

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status =
 major = 1
 minor = 8.1
 year = 2003
 month = 11
 day = 21
 language = R

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg, package:nls, package:ts, Autoloads, package:base

From p.dalgaard at biostat.ku.dk  Sun Nov 23 16:00:51 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun Nov 23 15:51:57 2003
Subject: [Rd] make check reg-tests-3
In-Reply-To: <Pine.LNX.4.44.0311231507060.1337-100000@kleigh.nl>
References: <Pine.LNX.4.44.0311231507060.1337-100000@kleigh.nl>
Message-ID: <x2d6bjuo2k.fsf@biostat.ku.dk>

Peter Kleiweg <kleiweg@let.rug.nl> writes:

> Should I submit this as a bug report?

Maybe, but this is not happening on stock RedHat 8.0 and Debian
stable, so you need to be more specific about your setup. In
particular: Are you using nonstandard libraries or compiler options?

> --- reg-tests-3.Rout.save	Thu Jul  3 09:55:40 2003
> +++ reg-tests-3.Rout	Sun Nov 23 13:10:57 2003
> @@ -1,17 +1,18 @@
> 
> -R : Copyright 2003, The R Development Core Team
> -Version 1.8.0 Under development (unstable) (2003-07-03)
> +R : Copyright 2003, The R Foundation for Statistical Computing
> +Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3
> 
>  R is free software and comes with ABSOLUTELY NO WARRANTY.
>  You are welcome to redistribute it under certain conditions.
> -Type `license()' or `licence()' for distribution details.
> +Type 'license()' or 'licence()' for distribution details.
> 
>  R is a collaborative project with many contributors.
> -Type `contributors()' for more information.
> +Type 'contributors()' for more information and
> +'citation()' on how to cite R in publications.
> 
> -Type `demo()' for some demos, `help()' for on-line help, or
> -`help.start()' for a HTML browser interface to help.
> -Type `q()' to quit R.
> +Type 'demo()' for some demos, 'help()' for on-line help, or
> +'help.start()' for a HTML browser interface to help.
> +Type 'q()' to quit R.
> 
>  > ### Regression tests for which the printed output is the issue
>  > ### May fail, e.g. by needing Recommended packages
> @@ -137,7 +138,7 @@
>  54  0.0989545407 -1.357243e-05 -3.683573e-02 -0.028339562 -0.025145841
>  55  0.1644148644 -1.347342e-04  1.507463e-01  0.272775865  0.355144259
>  56 -1.0973102505  2.844224e-04 -2.939639e-01 -0.267067176 -0.586604116
> -57           NaN           NaN           NaN          NaN          NaN
> +57  0.0000000000  0.000000e+00  0.000000e+00  0.000000000  0.000000000
>  58  1.1181936467 -1.814925e-04  1.820092e-01  0.230407448  0.281788680
>  59 -0.1289781075  2.595372e-05 -3.776833e-02 -0.058580136 -0.126069473
>  60  0.4827651281 -1.458463e-04  9.396412e-02 -0.005593267  0.099263965
> @@ -231,7 +232,7 @@
>  54 -0.0150792891   -0.0425585103  6.777594e-03  0.0030583353 -0.0591176911
>  55  0.4668348880   -0.0212547234  4.732189e-01  0.4185931034  0.2944838529
>  56 -0.7432312183   -0.2735589895 -6.870778e-02 -0.0393632338  0.1816128390
> -57           NaN             NaN           NaN           NaN           NaN
> +57  0.0000000000    0.0000000000  0.000000e+00  0.0000000000  0.0000000000
>  58  0.1945880055   -0.5587521455 -2.266734e-01 -0.3613221042 -0.5509923750
>  59 -0.0900361434    0.0807855154 -8.877433e-04 -0.0437027380  0.0203231292
>  60  0.2757970992   -0.3494459094  2.397384e-01  0.1279587545 -0.1512732820
> @@ -325,7 +326,7 @@
>  54 -0.0052948316  0.0043390590 -0.0062558306   -0.0100922249  -0.0036764450
>  55  0.3245941919  0.4533108376 -0.1196342985   -0.0946588832   0.0778256270
>  56  0.1438282891 -0.5411631576  0.0968253310    0.3927869929   0.2777652749
> -57           NaN           NaN           NaN             NaN            NaN
> +57  0.0000000000  0.0000000000  0.0000000000    0.0000000000   0.0000000000
>  58 -0.5770947483 -0.1184054962 -0.1740228604   -0.0285545091   0.7693037902
>  59  0.0412280879 -0.0075198458  0.0438882586    0.0121450418  -0.1252262379
>  60  0.3533541160  0.2760694598 -0.1036620689    0.1001975219   0.0703124944
> @@ -379,7 +380,7 @@
>        49       50       51       52       53       54       55       56
>  3.588734 3.589710 3.583459 3.581755 3.599157 3.599895 3.528075 3.559578
>        57       58       59       60       61       62       63       64
> -     NaN 3.523963 3.598459 3.571771 3.582319 3.600406 3.596626 3.592960
> +3.601231 3.523963 3.598459 3.571771 3.582319 3.600406 3.596626 3.592960
>        65       66       67       68       69       70       71       72
>  3.583325 3.600828 3.569987 3.592482 3.599979 3.580547 3.600799 3.599768
>        73       74       75       76       77       78       79       80
> @@ -432,44 +433,57 @@
>  Potentially influential observations of
>  	 lm(formula = 1000/MPG.city ~ Weight + Cylinders + Type + EngineSize +      DriveTrain, data = Cars93) :
> 
> -   dfb.1_ dfb.Wght dfb.Cyl4 dfb.Cyl5 dfb.Cyl6 dfb.Cyl8 dfb.Cyln dfb.TypL
> -8  -0.16   0.00    -0.10    -0.07    -0.24    -0.44     0.01     0.12
> -19 -0.03   0.09    -0.01    -0.03     0.00    -0.01    -0.03     0.08
> -28  0.11  -0.15     0.04     0.02     0.02     0.02     0.04     0.07
> -39 -0.19   0.05     0.34     0.21     0.25     0.18     0.18    -0.01
> -42  0.12  -0.04    -0.30    -0.17    -0.28    -0.26    -0.11    -0.03
> -57   NaN    NaN      NaN      NaN      NaN      NaN      NaN      NaN
> -66 -0.03   0.04    -0.02    -0.03    -0.01     0.00    -0.02    -0.01
> -80  0.18   0.00    -0.31    -0.17    -0.24    -0.19    -0.15     0.00
> -83  0.01   0.01    -0.04    -0.03    -0.04    -0.03    -0.02     0.00
> -87 -0.03   0.04    -0.01    -0.04    -0.04    -0.03    -0.02     0.04
> -89 -0.11   0.11    -0.05     0.28    -0.06    -0.04    -0.06    -0.01
> -93 -0.11   0.11    -0.05    -0.45    -0.06    -0.04    -0.06    -0.01
> -   dfb.TypM dfb.TypSm dfb.TypSp dfb.TypV dfb.EngS dfb.DrTF dfb.DrTR dffit
> -8   0.00     0.21      0.06     -0.04     0.47    -0.04     0.03     0.73
> -19  0.01     0.00     -0.04     -0.01    -0.15     0.01     0.02    -0.24
> -28  0.08    -0.08     -0.09      0.16     0.06     0.09     0.12    -0.26
> -39 -0.01     0.04      0.01     -0.06     0.01    -0.08    -0.08    -0.44
> -42  0.01    -0.42      0.01     -0.03     0.18    -0.10    -0.11    -0.89
> -57   NaN      NaN       NaN       NaN      NaN      NaN      NaN      NaN
> -66 -0.02     0.01      0.01      0.02    -0.03     0.05     0.03     0.08
> -80  0.01     0.01     -0.02     -0.07     0.01    -0.18    -0.14     0.45
> -83  0.00     0.00      0.00      0.00     0.00     0.01     0.01     0.05
> -87  0.03     0.02      0.03      0.06    -0.02    -0.03    -0.02     0.14
> -89 -0.07     0.05      0.04      0.08    -0.06     0.12     0.10     0.64
> -93 -0.07     0.05      0.04      0.08    -0.06     0.12     0.10    -0.64
> -   cov.r   cook.d  hat
> -8   1.71_*  0.04    0.39
> -19  2.09_*  0.00    0.43
> -28  1.86_*  0.00    0.36
> -39  1.76_*  0.01    0.36
> -42  0.13_*  0.05    0.06
> -57   NaN     Inf_*  1.00_*
> -66  1.63_*  0.00    0.26
> -80  1.92_*  0.01    0.40
> -83  1.88_*  0.00    0.36
> -87  1.60_*  0.00    0.25
> -89  2.68_*  0.03    0.57_*
> -93  2.68_*  0.03    0.57_*
> +   dfb.1_       dfb.Wght     dfb.Cyl4     dfb.Cyl5     dfb.Cyl6
> +8  -1.60000e-01  0.00000e+00 -1.00000e-01 -7.00000e-02 -2.40000e-01
> +19 -3.00000e-02  9.00000e-02 -1.00000e-02 -3.00000e-02  0.00000e+00
> +28  1.10000e-01 -1.50000e-01  4.00000e-02  2.00000e-02  2.00000e-02
> +39 -1.90000e-01  5.00000e-02  3.40000e-01  2.10000e-01  2.50000e-01
> +42  1.20000e-01 -4.00000e-02 -3.00000e-01 -1.70000e-01 -2.80000e-01
> +57  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00
> +66 -3.00000e-02  4.00000e-02 -2.00000e-02 -3.00000e-02 -1.00000e-02
> +80  1.80000e-01  0.00000e+00 -3.10000e-01 -1.70000e-01 -2.40000e-01
> +83  1.00000e-02  1.00000e-02 -4.00000e-02 -3.00000e-02 -4.00000e-02
> +87 -3.00000e-02  4.00000e-02 -1.00000e-02 -4.00000e-02 -4.00000e-02
> +89 -1.10000e-01  1.10000e-01 -5.00000e-02  2.80000e-01 -6.00000e-02
> +93 -1.10000e-01  1.10000e-01 -5.00000e-02 -4.50000e-01 -6.00000e-02
> +   dfb.Cyl8     dfb.Cyln     dfb.TypL     dfb.TypM     dfb.TypSm
> +8  -4.40000e-01  1.00000e-02  1.20000e-01  0.00000e+00  2.10000e-01
> +19 -1.00000e-02 -3.00000e-02  8.00000e-02  1.00000e-02  0.00000e+00
> +28  2.00000e-02  4.00000e-02  7.00000e-02  8.00000e-02 -8.00000e-02
> +39  1.80000e-01  1.80000e-01 -1.00000e-02 -1.00000e-02  4.00000e-02
> +42 -2.60000e-01 -1.10000e-01 -3.00000e-02  1.00000e-02 -4.20000e-01
> +57  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00
> +66  0.00000e+00 -2.00000e-02 -1.00000e-02 -2.00000e-02  1.00000e-02
> +80 -1.90000e-01 -1.50000e-01  0.00000e+00  1.00000e-02  1.00000e-02
> +83 -3.00000e-02 -2.00000e-02  0.00000e+00  0.00000e+00  0.00000e+00
> +87 -3.00000e-02 -2.00000e-02  4.00000e-02  3.00000e-02  2.00000e-02
> +89 -4.00000e-02 -6.00000e-02 -1.00000e-02 -7.00000e-02  5.00000e-02
> +93 -4.00000e-02 -6.00000e-02 -1.00000e-02 -7.00000e-02  5.00000e-02
> +   dfb.TypSp    dfb.TypV     dfb.EngS     dfb.DrTF     dfb.DrTR
> +8   6.00000e-02 -4.00000e-02  4.70000e-01 -4.00000e-02  3.00000e-02
> +19 -4.00000e-02 -1.00000e-02 -1.50000e-01  1.00000e-02  2.00000e-02
> +28 -9.00000e-02  1.60000e-01  6.00000e-02  9.00000e-02  1.20000e-01
> +39  1.00000e-02 -6.00000e-02  1.00000e-02 -8.00000e-02 -8.00000e-02
> +42  1.00000e-02 -3.00000e-02  1.80000e-01 -1.00000e-01 -1.10000e-01
> +57  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00
> +66  1.00000e-02  2.00000e-02 -3.00000e-02  5.00000e-02  3.00000e-02
> +80 -2.00000e-02 -7.00000e-02  1.00000e-02 -1.80000e-01 -1.40000e-01
> +83  0.00000e+00  0.00000e+00  0.00000e+00  1.00000e-02  1.00000e-02
> +87  3.00000e-02  6.00000e-02 -2.00000e-02 -3.00000e-02 -2.00000e-02
> +89  4.00000e-02  8.00000e-02 -6.00000e-02  1.20000e-01  1.00000e-01
> +93  4.00000e-02  8.00000e-02 -6.00000e-02  1.20000e-01  1.00000e-01
> +   dffit        cov.r          cook.d       hat
> +8   7.30000e-01  1.71000e+00_*  4.00000e-02  3.90000e-01
> +19 -2.40000e-01  2.09000e+00_*  0.00000e+00  4.30000e-01
> +28 -2.60000e-01  1.86000e+00_*  0.00000e+00  3.60000e-01
> +39 -4.40000e-01  1.76000e+00_*  1.00000e-02  3.60000e-01
> +42 -8.90000e-01  1.30000e-01_*  5.00000e-02  6.00000e-02
> +57  4.00000e-02  1.09307e+16_*  0.00000e+00  1.00000e+00_*
> +66  8.00000e-02  1.63000e+00_*  0.00000e+00  2.60000e-01
> +80  4.50000e-01  1.92000e+00_*  1.00000e-02  4.00000e-01
> +83  5.00000e-02  1.88000e+00_*  0.00000e+00  3.60000e-01
> +87  1.40000e-01  1.60000e+00_*  0.00000e+00  2.50000e-01
> +89  6.40000e-01  2.68000e+00_*  3.00000e-02  5.70000e-01_*
> +93 -6.40000e-01  2.68000e+00_*  3.00000e-02  5.70000e-01_*
>  > ## only last two cols in row 57 should be influential
>  >
> 
> Version:
>  platform = i686-pc-linux-gnu
>  arch = i686
>  os = linux-gnu
>  system = i686, linux-gnu
>  status =
>  major = 1
>  minor = 8.1
>  year = 2003
>  month = 11
>  day = 21
>  language = R
> 
> Search Path:
>  .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg, package:nls, package:ts, Autoloads, package:base
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Sun Nov 23 15:53:21 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Nov 23 15:53:39 2003
Subject: [Rd] make check reg-tests-3
In-Reply-To: <Pine.LNX.4.44.0311231507060.1337-100000@kleigh.nl>
Message-ID: <Pine.LNX.4.44.0311231431001.20395-100000@gannet.stats>

Note that differences are allowed in reg-tests-3.Rout (it even says so in
the output you sent!).  The supplied version is right and yours is wrong
(the theoretical answer is 0/0, as I am sure you had checked).

You might like to investigate why your system is getting the wrong answers
for your own peace of mind, as many other `i686-linux-gnu' systems give
the correct answers.  This is not a new test, there being no change since
1.8.0 in either the test or the code it is testing.  So it is a fair
assumption that *all* the various Linux distros for which binary packages
are produced worked correctly -- and that is a large range of current and 
not-so-current systems.

On Sun, 23 Nov 2003, Peter Kleiweg wrote:

> Should I submit this as a bug report?

Why did you ask?

> --- reg-tests-3.Rout.save	Thu Jul  3 09:55:40 2003
> +++ reg-tests-3.Rout	Sun Nov 23 13:10:57 2003

[...]

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From kleiweg at let.rug.nl  Sun Nov 23 17:16:45 2003
From: kleiweg at let.rug.nl (Peter Kleiweg)
Date: Sun Nov 23 17:15:25 2003
Subject: [Rd] make check reg-tests-3
In-Reply-To: <x2d6bjuo2k.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0311231712550.1337-100000@kleigh.nl>

# aldus Peter Dalgaard :

> Peter Kleiweg <kleiweg@let.rug.nl> writes:
>
> > Should I submit this as a bug report?
>
> Maybe, but this is not happening on stock RedHat 8.0 and Debian
> stable, so you need to be more specific about your setup. In
> particular: Are you using nonstandard libraries or compiler options?

SuSE Linux 7.2 (i386)

gcc version 2.95.3 20010315 (SuSE)

I run configure without any compiler settings, and get:

  C compiler:                gcc -D__NO_MATH_INLINES -mieee-fp -g -O2
  C++ compiler:              g++ -mieee-fp -g -O2
  Fortran compiler:          f2c

  Interfaces supported:      X11, tcltk
  External libraries:        readline
  Additional capabilities:   PNG, JPEG, bzip2, PCRE
  Options enabled:           shared library, R profiling

  Recommended packages:      yes


-- 
Peter Kleiweg

From p.dalgaard at biostat.ku.dk  Sun Nov 23 20:43:36 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun Nov 23 20:34:39 2003
Subject: [Rd] make check reg-tests-3
In-Reply-To: <Pine.LNX.4.44.0311231712550.1337-100000@kleigh.nl>
References: <Pine.LNX.4.44.0311231712550.1337-100000@kleigh.nl>
Message-ID: <x28ym6vpjr.fsf@biostat.ku.dk>

Peter Kleiweg <kleiweg@let.rug.nl> writes:

> # aldus Peter Dalgaard :
> 
> > Peter Kleiweg <kleiweg@let.rug.nl> writes:
> >
> > > Should I submit this as a bug report?
> >
> > Maybe, but this is not happening on stock RedHat 8.0 and Debian
> > stable, so you need to be more specific about your setup. In
> > particular: Are you using nonstandard libraries or compiler options?
> 
> SuSE Linux 7.2 (i386)
> 
> gcc version 2.95.3 20010315 (SuSE)
> 
> I run configure without any compiler settings, and get:
> 
>   C compiler:                gcc -D__NO_MATH_INLINES -mieee-fp -g -O2
>   C++ compiler:              g++ -mieee-fp -g -O2
>   Fortran compiler:          f2c
                               ^^^

This could be the issue. Please try installing g77 and rebuild.

On a SuSE 8.0 box, I have access to, I see

  C compiler:                gcc -D__NO_MATH_INLINES -mieee-fp -g -O2
  C++ compiler:              g++ -mieee-fp -g -O2
  Fortran compiler:          g77 -mieee-fp -g -O2

and differences in IEEE handling details could well explain the
differences that you're seeing. Make check-all running now...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Stephen.Harker at spme.monash.edu.au  Mon Nov 24 04:22:02 2003
From: Stephen.Harker at spme.monash.edu.au (Stephen.Harker@spme.monash.edu.au)
Date: Mon Nov 24 04:20:43 2003
Subject: [Rd] R postscript generation error (lines versus points) (PR#5285)
Message-ID: <20031124032202.820FCEFC2@slim.kubism.ku.dk>

Full_Name: Stephen Harker
Version: 1.80
OS: linux (Yellow Dog 3.0 on ppc)
Submission from: (NULL) (130.194.13.101)


In creating a postscript file from a set of data in which the points are
plotted
using `points()' and lines drawn using `lines()' I have found since upgrading
from R version 1.4? to 1.8 that the two sets do not coinicide completely.  This
is best illustrated by a simple example given below.  Here the X11() output
appears correctly.  However, the postscript output shows that the lines and
points no
longer coincide on the right hand side, whereas the left hand side is perfect. 
Output to other devices such as pdf is perfect.  Possibly this reflects a
different scaling being applied when points() or lines() are selected. 

One reason I found this is that I use a number of scripts in R to plot and
multiplot data sets from x-ray and neutron powder diffraction analysis (and
Rietveld fitting of this data in particularl).  In these points() is used to
plot the data and lines() to plot the refinement from the analysis.  After
upgrading I found these were 
misaligned.  The example was created to mimic the problem.

%%% Example follows:
dtwoth <- seq(from=20,to=80,len=1024)
dcount <- rnorm(dtwoth) #

postscript(file="R-test2.ps",horizontal=FALSE,
         pointsize=18, onefile=FALSE,
         family="Helvetica", paper="a4") 

plot(dtwoth,dcount, 
  xlim=c(min(dtwoth),max(dtwoth)),ylim=c(min(dcount),max(dcount)),
 yaxt="n",xaxs="i",yaxs="i",xlab="2theta",ylab="counts",
 type="n")

lines(dtwoth,dcount)
points(dtwoth,dcount)

X11() 

plot(dtwoth,dcount, 
  xlim=c(min(dtwoth),max(dtwoth)),ylim=c(min(dcount),max(dcount)),
 yaxt="n",xaxs="i",yaxs="i",xlab="2theta",ylab="counts",
 type="n")

lines(dtwoth,dcount)
points(dtwoth,dcount)

From Torsten.Hothorn at rzmail.uni-erlangen.de  Mon Nov 24 09:09:19 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon Nov 24 09:08:08 2003
Subject: [Rd] Using log() on an openMosix cluster
In-Reply-To: <3FBE3460.50109@jhsph.edu>
References: <3FBE3460.50109@jhsph.edu>
Message-ID: <Pine.LNX.4.51.0311240857040.29182@artemis.imbe.med.uni-erlangen.de>

On Fri, 21 Nov 2003, Roger D. Peng wrote:

> Hi all, I was hoping to get some advice about a problem that I realize
> will be difficult to reproduce for some people.  I'm running R 1.7.1 on
> an openMosix (Linux) cluster and have been experiencing some odd
> slow-downs.  If anyone has experience with such a setup (or a similar
> one) I'd appreciate any help.  Here's a simplified version of the problem.
>
> I'm trying to run the following code:
> ##
> N <- 100000; a <- numeric(N); b <- numeric(N)
> e <- rnorm(N)
>
> for(i in 1:N) {
>          a[i] <- exp(e[i])
>          b[i] <- log(abs(a[i]))
> }
> ##
>
> When I run it on the head node, everything is fine.  However, when I
> send the R process off to one of the cluster nodes (i.e. using mosrun
> from the head node) the program takes about 10 times longer (in
> wall-clock time, cpu time is roughly the same).
>

Did you adapt the sig*jmp definitions in src/include/Defn.h? This was
necessary until R-1.7.1 and is no longer needed, thanks to Luke's changes
in 1.8.0:

    o   On Unix-like systems interrupt signals now set a flag that is
        checked periodically rather than calling longjmp from the
        signal handler.  This is analogous to the behavior on Windows.
        This reduces responsiveness to interrupts but prevents bugs
        caused by interrupting computations in a way that leaves the
        system in an inconsistent state.  It also reduces the number
        of system calls, which can speed up computations on some
        platforms and make R more usable with systems like Mosix.


I tried the example above with N = 1.000.000:

N <- 1000000; a <- numeric(N); b <- numeric(N)
e <- rnorm(N)

for(i in 1:N) {
         a[i] <- exp(e[i])
         b[i] <- log(abs(a[i]))
}

cat(proc.time())

with R-1.8.0 with Linux 2.4.22 and OpenMosix-Patch and started 10
processes which migrated immediately.

hothorn@mosix:~/tmp/log$ grep -1 cat *.Rout
log1.Rout-R>
log1.Rout:R> cat(proc.time())
log1.Rout-37.04 1.02 43.44 0 0.01R>
--
log10.Rout-R>
log10.Rout:R> cat(proc.time())
log10.Rout-34.25 0.45 40.21 0 0.01R>
--
log2.Rout-R>
log2.Rout:R> cat(proc.time())
log2.Rout-22.19 0.33 29.36 0 0R>
--
log3.Rout-R>
log3.Rout:R> cat(proc.time())
log3.Rout-24.46 0.42 32.96 0 0.03R>
--
log4.Rout-R>
log4.Rout:R> cat(proc.time())
log4.Rout-36.88 0.38 40.73 0 0.02R>
--
log5.Rout-R>
log5.Rout:R> cat(proc.time())
log5.Rout-34.79 0.52 42.83 0.02 0R>
--
log6.Rout-R>
log6.Rout:R> cat(proc.time())
log6.Rout-34.14 0.54 41.46 0 0.01R>
--
log7.Rout-R>
log7.Rout:R> cat(proc.time())
log7.Rout-35.21 0.66 43.4 0 0R>
--
log8.Rout-R>
log8.Rout:R> cat(proc.time())
log8.Rout-25.27 0.55 33.77 0 0.01R>
--
log9.Rout-R>
log9.Rout:R> cat(proc.time())
log9.Rout-36.69 0.44 43.16 0.01 0R>

So, everything is fine here. I guess using R-1.8.1 will fix your
problem.

Torsten

> Interestingly, when I tried running the following code:
> ##
> N <- 100000; a <- numeric(N); b <- numeric(N)
> e <- rnorm(N)
>
> for(i in 1:N) {
>          a[i] <- exp(e[i])
>          b[i] <- exp(abs(a[i]))
> }
> ##
>
> I didn't experience any slow-down!  That is the wall-clock time is the
> same when run on the head node or on the cluster nodes.  The only
> difference between the two programs is that one takes a log in the for()
> loop and the other one takes an exponential.
>
> I guess my question is why would taking the log() produce a 10 fold
> increase in runtime?  I know that Mosix clusters can experience serious
> performance hits if you make a lot of system calls or write out data to
> files but I don't think I'm doing that here.  Is there some major
> difference in the way that exp() and log() are implemented?
>
> I'm pretty sure this isn't an R problem but I'm wondering if R is doing
> something behind the scenes that's affecting performance in the
> openMosix setting.
>
> Thanks in advance for any help.
>
> -roger
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>

From p.dalgaard at biostat.ku.dk  Mon Nov 24 10:21:25 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Nov 24 10:13:25 2003
Subject: [Rd] R postscript generation error (lines versus points) (PR#5285)
In-Reply-To: <20031124032202.820FCEFC2@slim.kubism.ku.dk>
References: <20031124032202.820FCEFC2@slim.kubism.ku.dk>
Message-ID: <x2islat94a.fsf@biostat.ku.dk>

Stephen.Harker@spme.monash.edu.au writes:

> Full_Name: Stephen Harker
> Version: 1.80
> OS: linux (Yellow Dog 3.0 on ppc)
> Submission from: (NULL) (130.194.13.101)
> 
> 
> In creating a postscript file from a set of data in which the points are
> plotted
> using `points()' and lines drawn using `lines()' I have found since upgrading
> from R version 1.4? to 1.8 that the two sets do not coinicide completely.  This
> is best illustrated by a simple example given below.  Here the X11() output
> appears correctly.  However, the postscript output shows that the lines and
> points no
> longer coincide on the right hand side, whereas the left hand side is perfect. 
> Output to other devices such as pdf is perfect.  Possibly this reflects a
> different scaling being applied when points() or lines() are selected. 
> 
> One reason I found this is that I use a number of scripts in R to plot and
> multiplot data sets from x-ray and neutron powder diffraction analysis (and
> Rietveld fitting of this data in particularl).  In these points() is used to
> plot the data and lines() to plot the refinement from the analysis.  After
> upgrading I found these were 
> misaligned.  The example was created to mimic the problem.
> 
> %%% Example follows:
> dtwoth <- seq(from=20,to=80,len=1024)
> dcount <- rnorm(dtwoth) #
> 
> postscript(file="R-test2.ps",horizontal=FALSE,
>          pointsize=18, onefile=FALSE,
>          family="Helvetica", paper="a4") 
> 
> plot(dtwoth,dcount, 
>   xlim=c(min(dtwoth),max(dtwoth)),ylim=c(min(dcount),max(dcount)),
>  yaxt="n",xaxs="i",yaxs="i",xlab="2theta",ylab="counts",
>  type="n")
> 
> lines(dtwoth,dcount)
> points(dtwoth,dcount)

[At the current rate, "1.80" would be about 36 years into the future.
Latest version is 1.8.1.]

I can't reproduce this with 1.8.0 on RedHat 8.0. Are you sure it isn't
your Postscript viewer that is playing tricks on you??

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Simon.Fear at synequanon.com  Mon Nov 24 12:02:37 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Mon Nov 24 12:03:57 2003
Subject: [Rd] apologies (was RE: [R] ISOdate() and strptime())
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572D275C8@synequanon01>

Dear Brian and other R-developers,

I have to say that I don't understand why what I wrote should 
have caused any offence. A smile was what I was hoping for. 
You know I devote more time than I am supposed to, to support 
R and its users, in partial repayment of my immeasurable debt to 
all the Developers.  It's not much, it's sometimes misguided (I later 
discover), and my resources are severely limited, but I do try. 
I hope not to be seen as an enemy. So, if you can explain to 
me what was wrong about my tongue in cheek criticism of R's 
relying on my notoriously unreliable OS, in notoriously unreliable 
circumstances, I will indeed publicly apologise.

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley@stats.ox.ac.uk]
<snip>
> I believe Simon Fear owes the R-developers a public apology 
> for his (not
> properly referenced in the archives) reply to this thread.
> 
> BDR  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear@synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}

From wolfram at fischer-zim.ch  Mon Nov 24 12:42:31 2003
From: wolfram at fischer-zim.ch (wolfram@fischer-zim.ch)
Date: Mon Nov 24 12:41:13 2003
Subject: [Rd] [R] lattice: ltext() does not accept NULL (PR#5290)
Message-ID: <20031124114231.7074BEFC3@slim.kubism.ku.dk>

text( pos=NULL ) is working.

ltext( pos=NULL ) gives an error message:
	"argument is of length zero"

Wolfram

From dmurdoch at pair.com  Mon Nov 24 13:05:35 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon Nov 24 13:04:34 2003
Subject: [Rd] Question about Unix file paths
Message-ID: <ils3svsfa9rt1725lb9mt42d0gc63pq8ba@4ax.com>

Gabor Grothendieck pointed out a bug to me in list.files(...,
full.name=TRUE), that essentially comes down to the fact that in
Windows it's not always valid to add a path separator (slash or
backslash) between a path specifier and a filename.  For example,

c:foo

is different from

c:\foo

and there are other examples.

I'm going to fix this, but I'm wondering whether the fix is needed
just for Windows, or for Unix too.  Specifically:

In Unix-like systems, is it *always* safe to add a slash between a
pathname and a filename?

The only examples I can think of that might go wrong are things like

//foo

/tmp//foo

Are these the same as

/foo

and

/tmp/foo?  Are there any examples where an extra slash causes trouble?

Duncan Murdoch

From kleiweg at let.rug.nl  Mon Nov 24 13:21:37 2003
From: kleiweg at let.rug.nl (Peter Kleiweg)
Date: Mon Nov 24 13:20:22 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <ils3svsfa9rt1725lb9mt42d0gc63pq8ba@4ax.com>
Message-ID: <Pine.LNX.4.44.0311241316550.1114-100000@kleigh.nl>

# aldus Duncan Murdoch :

> In Unix-like systems, is it *always* safe to add a slash between a
> pathname and a filename?

Not if the path is empty:

    '' + '/' + 'file'  -> /file

is not the same as:

    '' + 'file'  -> file


Doubling of a slash has no effect (at least on Linux and HP-UX)
unless you are using kpsetools.



-- 
Peter Kleiweg

From p.dalgaard at biostat.ku.dk  Mon Nov 24 13:32:17 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Nov 24 13:23:26 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <ils3svsfa9rt1725lb9mt42d0gc63pq8ba@4ax.com>
References: <ils3svsfa9rt1725lb9mt42d0gc63pq8ba@4ax.com>
Message-ID: <x2znemc5gu.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch@pair.com> writes:

> Gabor Grothendieck pointed out a bug to me in list.files(...,
> full.name=TRUE), that essentially comes down to the fact that in
> Windows it's not always valid to add a path separator (slash or
> backslash) between a path specifier and a filename.  For example,
> 
> c:foo
> 
> is different from
> 
> c:\foo
> 
> and there are other examples.
> 
> I'm going to fix this, but I'm wondering whether the fix is needed
> just for Windows, or for Unix too.  Specifically:
> 
> In Unix-like systems, is it *always* safe to add a slash between a
> pathname and a filename?
> 
> The only examples I can think of that might go wrong are things like
> 
> //foo
> 
> /tmp//foo
> 
> Are these the same as
> 
> /foo
> 
> and
> 
> /tmp/foo?  Are there any examples where an extra slash causes trouble?

Also, and of course, if the first part is empty, foo and /foo are very
different. There could be a problem with leading //, or is that
Windows only?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From dmurdoch at pair.com  Mon Nov 24 14:19:59 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon Nov 24 14:18:47 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <Pine.LNX.4.44.0311241316550.1114-100000@kleigh.nl>
References: <ils3svsfa9rt1725lb9mt42d0gc63pq8ba@4ax.com>
	<Pine.LNX.4.44.0311241316550.1114-100000@kleigh.nl>
Message-ID: <m614svsota0p4hd26k60rlsl3a0cf0brq7@4ax.com>

Thanks Peter and Peter.

On Mon, 24 Nov 2003 13:21:37 +0100 (CET), Peter Kleiweg wrote:

># aldus Duncan Murdoch :
>
>> In Unix-like systems, is it *always* safe to add a slash between a
>> pathname and a filename?
>
>Not if the path is empty:
>
>    '' + '/' + 'file'  -> /file
>
>is not the same as:
>
>    '' + 'file'  -> file

That one is not a problem in list.files:  it requires a non-empty
path.

>Doubling of a slash has no effect (at least on Linux and HP-UX)
>unless you are using kpsetools.

I don't know anything about kpsetools.  Is it something that would
affect R users?

Duncan Murdoch

From kleiweg at let.rug.nl  Mon Nov 24 14:27:06 2003
From: kleiweg at let.rug.nl (Peter Kleiweg)
Date: Mon Nov 24 14:25:52 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <m614svsota0p4hd26k60rlsl3a0cf0brq7@4ax.com>
Message-ID: <Pine.LNX.4.44.0311241423190.1114-100000@kleigh.nl>

# aldus Duncan Murdoch :

>
> >Doubling of a slash has no effect (at least on Linux and HP-UX)
> >unless you are using kpsetools.
>
> I don't know anything about kpsetools.  Is it something that would
> affect R users?

Forget I mentioned it. R doesn't use kpsetools, so it is
not an issue.

Kpsetools is used for instance by teTeX to set up extended
search paths.

-- 
Peter Kleiweg

From pingping.zheng at lancaster.ac.uk  Mon Nov 24 14:33:09 2003
From: pingping.zheng at lancaster.ac.uk (Pingping Zheng)
Date: Mon Nov 24 14:31:50 2003
Subject: [Rd] R-1.8.0 package directory permissions?
Message-ID: <3FC20895.6050005@lancs.ac.uk>

Hello,

I maintain a self-made R package under my own home directory
"~/.R/library" on our university computer net (SunOS 5.8 system).
After updating R to 1.8.0, I found other people cannot access my
package any more. They got this error message:

Error in library(tb, lib.loc = "/home/fs.hpc/43/zhengp1/.R/library") : 

This is not a valid package -- no DESCRIPTION exists

I set my home directory permissions as "drwx--x--x", the R packages
directories, from "/home/fs.hpc/43/zhengp1/.R" and its subdirectories
as "drwxr-xr-x". It worked well before.

However, when I change my home directory permissions to
"drwxr-xr-x", giving "read" and  "execute" permissions
to everyone, no error message appeared any more.

Is that a bug in new version of R-1.8.0?

Thanks in advance.

--------
Pingping Zheng
Department of Mathematics and Statistics
Fylde College
Lancaster University
Lancaster LA1 4YF
UK

From deepayan at stat.wisc.edu  Mon Nov 24 18:57:31 2003
From: deepayan at stat.wisc.edu (deepayan@stat.wisc.edu)
Date: Mon Nov 24 18:56:13 2003
Subject: [Rd] [R] lattice: ltext() does not accept NULL (PR#5290)
Message-ID: <20031124175731.C6A21F0C5@slim.kubism.ku.dk>

On Monday 24 November 2003 05:42, wolfram@fischer-zim.ch wrote:
> text( pos=NULL ) is working.
>
> ltext( pos=NULL ) gives an error message:
> 	"argument is of length zero"

The following should fix this :


ltext <-
    function(x, y = NULL, labels = seq(along = x),
             col = add.text$col,
             cex = add.text$cex,
             srt = 0,
             font = 1,
             adj = c(.5, .5),
             pos = NULL,
             ...)
{
    add.text <- trellis.par.get("add.text")
    xy <- xy.coords(x, y)
    if (!is.null(pos))
        adj <-
            if (pos == 1) c(.5, 1)
            else if (pos == 2) c(1, .5)
            else if (pos == 3) c(.5, 0)
            else if (pos == 4) c(0, .5)
            else stop("Invalid value of pos")
    if (length(adj) == 1) adj <- c(adj, .5)
    grid.text(label = labels, x = xy$x, y = xy$y,
              gp = gpar(col = col, font = font,
              fontsize = cex * trellis.par.get("fontsize")$default),
              just = c(if (adj[1] == 0) "left"
              else if (adj[1] == 1) c("right")
              else "centre",
              if (adj[2] == 0) "bottom"
              else if (adj[2] == 1) c("top")
              else "centre"),
              rot = srt,
              default.units = "native")
}

From IandJMSmith at aol.com  Mon Nov 24 19:04:27 2003
From: IandJMSmith at aol.com (IandJMSmith@aol.com)
Date: Mon Nov 24 19:10:52 2003
Subject: [Rd] PR#2894
Message-ID: <57F75F95.64CD6D92.38E5E5DC@aol.com>

I came across the message below and decided to respond. I don't use R but I do use other FSF products and I am a believer in making high quality software freely available, particularly for basic mathematical and statistical functions.

I can thorougly recommend TOMS Algorithm 708 but I believe there are a couple of problems from you point of view. Firstly there may be restrictions on how it may be used and secondly it doesn't come with a corresponding inverse function. You may, of course, feel your qbeta routine would be fine with a better pbeta.

CDFLIB includes this algorithm but comes with the warning "However, code from ACM publications is subject to the ACM policy (below)". The inversion function in CDFLIB is not built to the same high standards as A. H. Morris's code for Algorithm 708. As a consequence it is slower than it should be, doesn't work for probabilities samller than 1e-50 and if the UCLA calculators http://calculators.stat.ucla.edu/ use the CDFLIB code (as they claim) then it has some peculiar bugs {UCLA's qbeta(0.9000872417014739,0.00000631,0.0000595) returns 6.67492405793E-09. It should be approx 3e-308}. However, if you can get around the "licencing" problems then it would be a low risk solution to your problems. 

As an alternative, I offer software of mine. Code for a number of distributions, including the beta-distribution, is available at http://members.aol.com/iandjmsmith/EXAMPLES.HTM. I realise it would be a huge risk using "unknown" software but if you try the code for the beta distribution, you will find it reasonably fast, accurate and available to use any way you wish. 

Having downloaded the R source, I also noticed the comment /*___ FIXME ___:  This takes forever (or ends wrongly) when (one or) both p & q  are huge */. My code uses an asymptotic expansion for the incomplete beta integral and consequently the runtime has an upper limit. 

I could go on and on about the code but there's not much point unless you are interested in using it. The code is in Javascript which is relatively painless to translate to C, though it would obviously require additional effort to make it consistent with the rest of R. Should you be interested, I would be willing to help or sit back and leave you to it.

Ian Smith



Message-id: <200309221347.h8MDlUJH021443@pubhealth.ku.dk>

>Date: Fri, 2 May 2003 10:03:23 -0400 (EDT) 
From: Morten Welinder <welinder@rentec.com <mailto:welinder@rentec.com?Subject=Re:%20[Rd]%20PR>> 
>To: p.dalgaard@biostat.ku.dk <mailto:p.dalgaard@biostat.ku.dk?Subject=Re:%20[Rd]%20PR> 
>CC: r-devel@stat.math.ethz.ch <mailto:r-devel@stat.math.ethz.ch?Subject=Re:%20[Rd]%20PR>, R-bugs@biostat.ku.dk <mailto:R-bugs@biostat.ku.dk?Subject=Re:%20[Rd]%20PR> 
>Subject: Re: [Rd] qbeta hang (PR#2894) 
> 
>Ok, I can confirm that it does not, in fact, loop forever. Just a close 
>approximation. 
... 
>There are lots of other places that worry me with respect to cancellation 
>errors, for example 
> 
> r = 1 - pp; 
> t = 1 - qq; 
These can also be removed by changing qbeta.c:156-157 (R-1.7.1) 
to 
y = (y-a) * xinbta * (1.0-xinbta) * 
exp (logbeta - pp * log(xinbta) - qq * log1p(-xinbta)); 
I don't understand why you have qbeta.c:167 
if (fabs(y)<=acu) goto L_converged 
which will fail for certain values of p & q, when x is close to zero as 
the beta density tends to infinity. Why not use an exit condition based on 
how far away from 'a' you are? 
qbeta.c:174 (prevent excess precision) 
Might this not just get optimized out? I doubt modern compilers respect 
the volatile keyword. You should probably replace this with a safe 
comparison. if(fabs(tx-xinbta)<=DBL_EPSILON*fabs(xinbta))... 
** This should be checked with someone familiar with floating point 
arithmetic; I'm not and may have got the correct expression wrong. 
The 'infinite loop' is due to the speed of the pbeta routine, rather than 
the initial approximation from the qbeta. There is another algorithm 
available for pbeta (Algorithm 708, CACM 18. 360--373, 1992) which may be 
of use here. This continued fraction approximation is recommended by 
Numerical Recipes over the power series approximation (make of that what 
you will!) 
TimM.

From maechler at stat.math.ethz.ch  Mon Nov 24 19:23:07 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Nov 24 19:22:16 2003
Subject: [Rd] R Mailing lists: "Sender:" now sometimes VERPs
Message-ID: <16322.19595.637264.353268@gargle.gargle.HOWL>

{BCC'ed to three Core groups}

Following the recommendation of the mailman developers,
I have activated occasional "VERP"ing for our mailing lists.
(and will turn it off again, after about a day or so).

Here is the mailman "comment-docu" on this :

# These variables control the format and frequency of VERP-like delivery for
# better bounce detection.  VERP is Variable Envelope Return Path, defined
# here:
#
# http://cr.yp.to/proto/verp.txt
#
# This involves encoding the address of the recipient as we (Mailman) know it
# into the envelope sender address (i.e. the SMTP `MAIL FROM:' address).
# Thus, no matter what kind of forwarding the recipient has in place, should
# it eventually bounce, we will receive an unambiguous notice of the bouncing
# address.
#

This is in order to better track down those invalid e-mail addresses 
with mail servers that do not send back bounces which mailman
(the mailing list software) understands.
Otherwise I would have to manually find out what went wrong and
disable / unsubscribe unused addresses.  This is no longer an
option, e.g., for R-help with more than 2000 addresses
subscribed and more than a dozen subscriptions changes every day.

Consequence:  
  The mails are sometimes (every 10th time) sent out
  individualized with a "Sender: " header that now looks like
  this (for me):
  >> Sender: r-devel-bounces+maechler=stat.math.ethz.ch@stat.math.ethz.ch
  instead of
  >> Sender: r-devel-bounces@stat.math.ethz.ch

This is both *slower* and may require that you change your mail
pre-sorting if it currently relied on "Sender:".

E.g., I'd use  procmail rule for the R lists such as

 :0:
 * ^Sender: (r-|bioco)[-a-z]*-(admin|bounces(\+.*)?))@stat\.math\.ethz\.ch
 R-lists.spool

where the  "(\+.*)?"  allows for the occasional VERPing.

I hope these consequences are small enough,
and will help to rationalize the keeping of a clean mailing list
address base.

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

From p.murrell at auckland.ac.nz  Mon Nov 24 21:17:31 2003
From: p.murrell at auckland.ac.nz (p.murrell@auckland.ac.nz)
Date: Mon Nov 24 21:16:34 2003
Subject: [Rd] R postscript generation error (lines versus points) (PR#5285)
Message-ID: <20031124201731.78ED8EFB0@slim.kubism.ku.dk>

Hi


Peter Dalgaard wrote:
 > Stephen.Harker@spme.monash.edu.au writes:
 >
 >
 >>Full_Name: Stephen Harker
 >>Version: 1.80
 >>OS: linux (Yellow Dog 3.0 on ppc)
 >>Submission from: (NULL) (130.194.13.101)
 >>
 >>
 >>In creating a postscript file from a set of data in which the points are
 >>plotted
 >>using `points()' and lines drawn using `lines()' I have found since 
upgrading
 >>from R version 1.4? to 1.8 that the two sets do not coinicide 
completely.  This
 >>is best illustrated by a simple example given below.  Here the X11() 
output
 >>appears correctly.  However, the postscript output shows that the 
lines and
 >>points no
 >>longer coincide on the right hand side, whereas the left hand side is 
perfect.
 >>Output to other devices such as pdf is perfect.  Possibly this reflects a
 >>different scaling being applied when points() or lines() are selected.
 >>
 >>One reason I found this is that I use a number of scripts in R to 
plot and
 >>multiplot data sets from x-ray and neutron powder diffraction 
analysis (and
 >>Rietveld fitting of this data in particularl).  In these points() is 
used to
 >>plot the data and lines() to plot the refinement from the analysis. 
After
 >>upgrading I found these were
 >>misaligned.  The example was created to mimic the problem.
 >>
 >>%%% Example follows:
 >>dtwoth <- seq(from=20,to=80,len=1024)
 >>dcount <- rnorm(dtwoth) #
 >>
 >>postscript(file="R-test2.ps",horizontal=FALSE,
 >>         pointsize=18, onefile=FALSE,
 >>         family="Helvetica", paper="a4")
 >>
 >>plot(dtwoth,dcount,
 >>  xlim=c(min(dtwoth),max(dtwoth)),ylim=c(min(dcount),max(dcount)),
 >> yaxt="n",xaxs="i",yaxs="i",xlab="2theta",ylab="counts",
 >> type="n")
 >>
 >>lines(dtwoth,dcount)
 >>points(dtwoth,dcount)
 >
 >
 > [At the current rate, "1.80" would be about 36 years into the future.
 > Latest version is 1.8.1.]
 >
 > I can't reproduce this with 1.8.0 on RedHat 8.0. Are you sure it isn't
 > your Postscript viewer that is playing tricks on you??


I can't reproduce this either, but in trying your script I wonder if you 
are not properly "finishing" the postscript plot by calling dev.off 
before viewing.  If I run your script, then view R-test2.ps without 
quitting R, the last few points at the right end of the plot are missing 
(because the postscript file is not yet complete).  If I then quit R 
(the postscript file is completed and closed), the postscript output 
looks just like the X11 version.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul@stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/

From p.murrell at auckland.ac.nz  Mon Nov 24 21:17:09 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon Nov 24 21:16:53 2003
Subject: [Rd] R postscript generation error (lines versus points) (PR#5285)
References: <20031124032202.820FCEFC2@slim.kubism.ku.dk>
	<x2islat94a.fsf@biostat.ku.dk>
Message-ID: <3FC26745.50807@stat.auckland.ac.nz>

Hi


Peter Dalgaard wrote:
 > Stephen.Harker@spme.monash.edu.au writes:
 >
 >
 >>Full_Name: Stephen Harker
 >>Version: 1.80
 >>OS: linux (Yellow Dog 3.0 on ppc)
 >>Submission from: (NULL) (130.194.13.101)
 >>
 >>
 >>In creating a postscript file from a set of data in which the points are
 >>plotted
 >>using `points()' and lines drawn using `lines()' I have found since 
upgrading
 >>from R version 1.4? to 1.8 that the two sets do not coinicide 
completely.  This
 >>is best illustrated by a simple example given below.  Here the X11() 
output
 >>appears correctly.  However, the postscript output shows that the 
lines and
 >>points no
 >>longer coincide on the right hand side, whereas the left hand side is 
perfect.
 >>Output to other devices such as pdf is perfect.  Possibly this reflects a
 >>different scaling being applied when points() or lines() are selected.
 >>
 >>One reason I found this is that I use a number of scripts in R to 
plot and
 >>multiplot data sets from x-ray and neutron powder diffraction 
analysis (and
 >>Rietveld fitting of this data in particularl).  In these points() is 
used to
 >>plot the data and lines() to plot the refinement from the analysis. 
After
 >>upgrading I found these were
 >>misaligned.  The example was created to mimic the problem.
 >>
 >>%%% Example follows:
 >>dtwoth <- seq(from=20,to=80,len=1024)
 >>dcount <- rnorm(dtwoth) #
 >>
 >>postscript(file="R-test2.ps",horizontal=FALSE,
 >>         pointsize=18, onefile=FALSE,
 >>         family="Helvetica", paper="a4")
 >>
 >>plot(dtwoth,dcount,
 >>  xlim=c(min(dtwoth),max(dtwoth)),ylim=c(min(dcount),max(dcount)),
 >> yaxt="n",xaxs="i",yaxs="i",xlab="2theta",ylab="counts",
 >> type="n")
 >>
 >>lines(dtwoth,dcount)
 >>points(dtwoth,dcount)
 >
 >
 > [At the current rate, "1.80" would be about 36 years into the future.
 > Latest version is 1.8.1.]
 >
 > I can't reproduce this with 1.8.0 on RedHat 8.0. Are you sure it isn't
 > your Postscript viewer that is playing tricks on you??


I can't reproduce this either, but in trying your script I wonder if you 
are not properly "finishing" the postscript plot by calling dev.off 
before viewing.  If I run your script, then view R-test2.ps without 
quitting R, the last few points at the right end of the plot are missing 
(because the postscript file is not yet complete).  If I then quit R 
(the postscript file is completed and closed), the postscript output 
looks just like the X11 version.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul@stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/

From gregory_r_warnes at groton.pfizer.com  Mon Nov 24 22:39:41 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Mon Nov 24 22:38:42 2003
Subject: [Rd] Enhanced heatmap, barplot functions
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20680AB41@groexmb02.pfizer.com>


I've just uploaded gregmisc 0.8.6 to CRAN, it should show up in the package
tree shortly.   It contains both an enhanced barplot() [named barplot2 in my
code] and an enhanced heatmap() function that I would like to see propagate
to the base and mva packages respectively. I've checked the code for both
functions against the code in R 1.8.1, and these functions have all of the
latest features/patches.

The barplot2 code is a drop-in replacement for the current barplot() command
which adds these features:

- control color of the plot region
- allow either/both axes to be plotted on a log scale
- allow grid-lines to be shown on the plot
- plot confidence intervals when standard error is provided
- 'add' parameter to allow plotting onto an existing canvas

barplot2() is mostly contributed changes by Marc Schwartz.

The heatmap code is an almost* drop-in replacement for the standard heatmap
function.  It adds:

- ability to specify 'breaks' which define how numeric ranges are assigned
to colors 
* a variant mechanism for specifying whether row or column dendograms should
be generated and plotted: dengrogram="row", "column" "none" or "both".
This differs from R's standard heatmap, which does this by Rowv=NA or
Colv=NA, which also prevents *reordering* the rows/columns.   
- changes the default colors to 'heat.colors' instead of 'topo.colors',
which seems more appropriate for continuous data.
- allow visual separation of row / column blocks with a solid (usually
background) color 'border'
- allow text to be placed within colored cells (ie for p-value significance
flags)
- automatically provide a color-key when the data is not internally scaled
(scaling is now off by default)
- add 'level trace' lines.  These lines, which can run down rows or across
columns represent the scale of the measurement by the distance of the line
within a cell from the lower or left side of the color block.  These lines
allow one to visually compare the scale of measurements more accurately than
is possible from the colors themselves.  [Visually it is almost impossible
to decide that this red is twice intense that red. This line makes this type
of comparison simple.]

I made these changes for presentation of fold-change heatmaps.  The
specification of 'breaks' allows for the mapping of colors to ranges to be
made symmetric around +-1, for the space between +-1 to be 'collapsed' into
a single color, and for extreme values to be 'collapsed' into a single color
block instead of bleaching out all of the lower values.  In this context, a
color key becomes invaluable, and if the plotted data is the result of model
fitting, one wants to add p-value flags, and to select a meaningful column
order instead of depending on the dendrogram or the original matrix order.

-G

Gregory R. Warnes, Ph.D.
Senior Coordinator
Groton Non-Clinical Statistics
Pfizer Global Research and Development
 <<Warnes, Gregory R.vcf>> 


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

From gregory_r_warnes at groton.pfizer.com  Mon Nov 24 23:12:24 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Mon Nov 24 23:11:50 2003
Subject: [Rd] Proposal: 'global' package refactoring
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20680AB43@groexmb02.pfizer.com>


Looking over the contents of various packages, including my own, it is clear
that lots of things end up 'hidden away' in packages where they don't
belong.  My gregmisc package is a particularly egregious example, containing
something from almost every functional category.  

I propose that from time to time the R community go through the complete set
of packages and 'refactor' the functions and data sets into packages that
have clearly defined goals.   This should make it easier to ensure that new
functions get placed into a location where users can easily find them,
reduce the amount of re-implementation/duplication existing functionality,
and assist in ensuring interoperability.

It would be worthwhile, for instance, to pull all of the functions related
to contrasts for generalized linear models into a common location, instead
of having them spread between base, Hmisc, MASS, gregmisc, etc.   Similarly,
it would be helpful to pull together all of the genetics-computations into a
single location.

I recognize that not all package maintainers would be willing to participate
and that not all functions could be easily categorized, but I believe that
this effort would yield significant benefit and is compatible with the goal
of R-core to streamline the base packages. 

To put my money where my mouth is, I'll volunteer to organize a group effort
to do such a refactoring in conjunction with the userR! 2004 or the next
DSC, whichever folks agree is better for this purpose.


Gregory R. Warnes, Ph.D.
Senior Coordinator
Groton Non-Clinical Statistics
Pfizer Global Research and Development
 <<Warnes, Gregory R.vcf>> 


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

From deleeuw at stat.ucla.edu  Mon Nov 24 23:36:08 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Mon Nov 24 23:35:00 2003
Subject: [Rd] Proposal: 'global' package refactoring
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C20680AB43@groexmb02.pfizer.com>
References: <D7A3CFD7825BD6119B880002A58F06C20680AB43@groexmb02.pfizer.com>
Message-ID: <98EC1A6E-1ECE-11D8-9A24-000A95A67E82@stat.ucla.edu>

This is a good idea, and it would be great to have these
refactored meta packages. But it actually implies having
a group similar to R core that does code review of
existing packages. For example, what happens if
a function seems to work but is programmed horribly
inefficiently ? What happens if something exists on both
the R and C levels ? What happens with packages that
rely on private versions of BLAS ? Suppose two packages
provide the same functionality, how does one choose ?
And can this be done without coding conventions ? Who is
in charge ?

On Nov 24, 2003, at 14:12, Warnes, Gregory R wrote:

>
> Looking over the contents of various packages, including my own, it is  
> clear
> that lots of things end up 'hidden away' in packages where they don't
> belong.  My gregmisc package is a particularly egregious example,  
> containing
> something from almost every functional category.
>
> I propose that from time to time the R community go through the  
> complete set
> of packages and 'refactor' the functions and data sets into packages  
> that
> have clearly defined goals.   This should make it easier to ensure  
> that new
> functions get placed into a location where users can easily find them,
> reduce the amount of re-implementation/duplication existing  
> functionality,
> and assist in ensuring interoperability.
>
> It would be worthwhile, for instance, to pull all of the functions  
> related
> to contrasts for generalized linear models into a common location,  
> instead
> of having them spread between base, Hmisc, MASS, gregmisc, etc.    
> Similarly,
> it would be helpful to pull together all of the genetics-computations  
> into a
> single location.
>
> I recognize that not all package maintainers would be willing to  
> participate
> and that not all functions could be easily categorized, but I believe  
> that
> this effort would yield significant benefit and is compatible with the  
> goal
> of R-core to streamline the base packages.
>
> To put my money where my mouth is, I'll volunteer to organize a group  
> effort
> to do such a refactoring in conjunction with the userR! 2004 or the  
> next
> DSC, whichever folks agree is better for this purpose.
>
>
> Gregory R. Warnes, Ph.D.
> Senior Coordinator
> Groton Non-Clinical Statistics
> Pfizer Global Research and Development
>  <<Warnes, Gregory R.vcf>>
>
>
> LEGAL NOTICE\ Unless expressly stated otherwise, this  
> messag...{{dropped}}
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From p.murrell at auckland.ac.nz  Tue Nov 25 00:12:39 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue Nov 25 00:11:37 2003
Subject: [Rd] Proposal: 'global' package refactoring
References: <D7A3CFD7825BD6119B880002A58F06C20680AB43@groexmb02.pfizer.com>
	<98EC1A6E-1ECE-11D8-9A24-000A95A67E82@stat.ucla.edu>
Message-ID: <3FC29067.5090602@stat.auckland.ac.nz>

Hi

I have wanted to figure out a way to do something along these lines for 
the many, widely-scattered plotting functions.  Something that would be 
less invasive (and less useful, but a valid step in the right 
direction), is simply a "directory" for different functional groups.  A 
list of function names, plus descriptions of what they do, plus a 
pointer to the package they are in would I think be really useful.  A 
lot of work to create and maintain, but really useful.  For example, the 
web pages focused on "spatial projects" 
(http://sal.agecon.uiuc.edu/csiss/Rgeo/index.html) has summaries of all 
spatially related packages.
The coordination of the DBMS stuff 
(http://developer.r-project.org/db/index.html) is another example of 
something similar.
Then of course there is the R GUIs pages (http://www.sciviews.org/_rgui/)

Paul



Jan de Leeuw wrote:
> This is a good idea, and it would be great to have these
> refactored meta packages. But it actually implies having
> a group similar to R core that does code review of
> existing packages. For example, what happens if
> a function seems to work but is programmed horribly
> inefficiently ? What happens if something exists on both
> the R and C levels ? What happens with packages that
> rely on private versions of BLAS ? Suppose two packages
> provide the same functionality, how does one choose ?
> And can this be done without coding conventions ? Who is
> in charge ?
> 
> On Nov 24, 2003, at 14:12, Warnes, Gregory R wrote:
> 
>>
>> Looking over the contents of various packages, including my own, it 
>> is  clear
>> that lots of things end up 'hidden away' in packages where they don't
>> belong.  My gregmisc package is a particularly egregious example,  
>> containing
>> something from almost every functional category.
>>
>> I propose that from time to time the R community go through the  
>> complete set
>> of packages and 'refactor' the functions and data sets into packages  
>> that
>> have clearly defined goals.   This should make it easier to ensure  
>> that new
>> functions get placed into a location where users can easily find them,
>> reduce the amount of re-implementation/duplication existing  
>> functionality,
>> and assist in ensuring interoperability.
>>
>> It would be worthwhile, for instance, to pull all of the functions  
>> related
>> to contrasts for generalized linear models into a common location,  
>> instead
>> of having them spread between base, Hmisc, MASS, gregmisc, etc.    
>> Similarly,
>> it would be helpful to pull together all of the genetics-computations  
>> into a
>> single location.
>>
>> I recognize that not all package maintainers would be willing to  
>> participate
>> and that not all functions could be easily categorized, but I believe  
>> that
>> this effort would yield significant benefit and is compatible with 
>> the  goal
>> of R-core to streamline the base packages.
>>
>> To put my money where my mouth is, I'll volunteer to organize a group  
>> effort
>> to do such a refactoring in conjunction with the userR! 2004 or the  next
>> DSC, whichever folks agree is better for this purpose.
>>
>>
>> Gregory R. Warnes, Ph.D.
>> Senior Coordinator
>> Groton Non-Clinical Statistics
>> Pfizer Global Research and Development
>>  <<Warnes, Gregory R.vcf>>
>>
>>
>> LEGAL NOTICE\ Unless expressly stated otherwise, this  
>> messag...{{dropped}}
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>
> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> Editor: Journal of Multivariate Analysis, Journal of Statistical  Software
> US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
> homepage: http://gifi.stat.ucla.edu
>   
> ------------------------------------------------------------------------ 
> -------------------------
>           No matter where you go, there you are. --- Buckaroo Banzai
>                    http://gifi.stat.ucla.edu/sounds/nomatter.au
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul@stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/

From Stephen.Harker at spme.monash.edu.au  Tue Nov 25 00:29:59 2003
From: Stephen.Harker at spme.monash.edu.au (Stephen.Harker@spme.monash.edu.au)
Date: Tue Nov 25 00:29:14 2003
Subject: [Rd] R postscript generation error (lines versus points) (PR#5285)
Message-ID: <20031124232959.CEB7AEFB0@slim.kubism.ku.dk>

Hi,

On Tue, Nov 25, 2003 at 09:17:09AM +1300, Paul Murrell wrote:
> Peter Dalgaard wrote:
> > Stephen.Harker@spme.monash.edu.au writes:
> >>Full_Name: Stephen Harker
> >>Version: 1.80
> >>OS: linux (Yellow Dog 3.0 on ppc)
> >>Submission from: (NULL) (130.194.13.101)
> >>
> >>
> >>In creating a postscript file from a set of data in which the points are
> >>plotted
> >>using `points()' and lines drawn using `lines()' I have found since 
> upgrading
> >>from R version 1.4? to 1.8 that the two sets do not coinicide 
> completely.  [...]
> > [At the current rate, "1.80" would be about 36 years into the future.
> > Latest version is 1.8.1.]

:-)

> > I can't reproduce this with 1.8.0 on RedHat 8.0. Are you sure it isn't
> > your Postscript viewer that is playing tricks on you??

Yes and no: I get the same result in prints from a PostScript file or
from files included into a LaTeX document in the case of the original
scripts that caused me to try to create a test case.  However, this
morning having read this comment I tried this test script and I find
it generates obvious `errors' using gs 8.11 (in /usr/local/bin) and
none obvious using the system gs (7.05 in /usr/bin).  I tried printing
the file to a HP Laserjet 4MV, 8000N and a Konica 7155 and find it is
similar to the gs 7.05 output.  This suggests two problems: a problem
with gs 8.11 as built on my system and that my test script does not
duplicate the problem I thought I was illustrating.

In the production scripts I have been using (with a history that goes
back to the mid 90's) this occurs in a vary obvious mismatch in the
lines() and points() that gets worse as x increases.  I had thought
that the script submitted duplicated the problem.  Now it appears that
it does not.  For the scripts I was using I get the mismatch on
printed postscript and similar(? I did not compare them fully) results
with the screen.  

> I can't reproduce this either, but in trying your script I wonder if you 
> are not properly "finishing" the postscript plot by calling dev.off 
> before viewing.  If I run your script, then view R-test2.ps without 
> quitting R, the last few points at the right end of the plot are missing 
> (because the postscript file is not yet complete).  If I then quit R 
> (the postscript file is completed and closed), the postscript output 
> looks just like the X11 version.

No: in my production versions dev.off() is called.  I noticed the
missing points you mentioned in the postscript file created.  However,
I did not worry about it as the error was noticeable in the alignment
of the `peaks' and `points' prior to the missing points.

I will need to test this further and to find a better way of
duplicating the error (if error it is).  I will have to try building R
1.8 on another system and test my Rietveld and other x-ray data
plotting scripts to see if it matches my current problem.  I will
contact you when I have more data (useful or otherwise).  

-- 
Stephen Harker                           Stephen.Harker@spme.monash.edu.au
School of Physics & Materials Engineering
Monash University                       http://www.ph.adfa.edu.au/s-harker/
                                 Baloney Baffles brains: Eric Frank Russell

From Stephen.Harker at spme.monash.edu.au  Mon Nov 24 22:45:27 2003
From: Stephen.Harker at spme.monash.edu.au (Stephen.Harker@spme.monash.edu.au)
Date: Tue Nov 25 00:33:39 2003
Subject: [Rd] R postscript generation error (lines versus points) (PR#5285)
In-Reply-To: <3FC26745.50807@stat.auckland.ac.nz>
References: <20031124032202.820FCEFC2@slim.kubism.ku.dk>
	<x2islat94a.fsf@biostat.ku.dk> <3FC26745.50807@stat.auckland.ac.nz>
Message-ID: <20031124214527.GA1800@harker.spme.monash.edu.au>

Hi,

On Tue, Nov 25, 2003 at 09:17:09AM +1300, Paul Murrell wrote:
> Peter Dalgaard wrote:
> > Stephen.Harker@spme.monash.edu.au writes:
> >>Full_Name: Stephen Harker
> >>Version: 1.80
> >>OS: linux (Yellow Dog 3.0 on ppc)
> >>Submission from: (NULL) (130.194.13.101)
> >>
> >>
> >>In creating a postscript file from a set of data in which the points are
> >>plotted
> >>using `points()' and lines drawn using `lines()' I have found since 
> upgrading
> >>from R version 1.4? to 1.8 that the two sets do not coinicide 
> completely.  [...]
> > [At the current rate, "1.80" would be about 36 years into the future.
> > Latest version is 1.8.1.]

:-)

> > I can't reproduce this with 1.8.0 on RedHat 8.0. Are you sure it isn't
> > your Postscript viewer that is playing tricks on you??

Yes and no: I get the same result in prints from a PostScript file or
from files included into a LaTeX document in the case of the original
scripts that caused me to try to create a test case.  However, this
morning having read this comment I tried this test script and I find
it generates obvious `errors' using gs 8.11 (in /usr/local/bin) and
none obvious using the system gs (7.05 in /usr/bin).  I tried printing
the file to a HP Laserjet 4MV, 8000N and a Konica 7155 and find it is
similar to the gs 7.05 output.  This suggests two problems: a problem
with gs 8.11 as built on my system and that my test script does not
duplicate the problem I thought I was illustrating.

In the production scripts I have been using (with a history that goes
back to the mid 90's) this occurs in a vary obvious mismatch in the
lines() and points() that gets worse as x increases.  I had thought
that the script submitted duplicated the problem.  Now it appears that
it does not.  For the scripts I was using I get the mismatch on
printed postscript and similar(? I did not compare them fully) results
with the screen.  

> I can't reproduce this either, but in trying your script I wonder if you 
> are not properly "finishing" the postscript plot by calling dev.off 
> before viewing.  If I run your script, then view R-test2.ps without 
> quitting R, the last few points at the right end of the plot are missing 
> (because the postscript file is not yet complete).  If I then quit R 
> (the postscript file is completed and closed), the postscript output 
> looks just like the X11 version.

No: in my production versions dev.off() is called.  I noticed the
missing points you mentioned in the postscript file created.  However,
I did not worry about it as the error was noticeable in the alignment
of the `peaks' and `points' prior to the missing points.

I will need to test this further and to find a better way of
duplicating the error (if error it is).  I will have to try building R
1.8 on another system and test my Rietveld and other x-ray data
plotting scripts to see if it matches my current problem.  I will
contact you when I have more data (useful or otherwise).  

-- 
Stephen Harker                           Stephen.Harker@spme.monash.edu.au
School of Physics & Materials Engineering
Monash University                       http://www.ph.adfa.edu.au/s-harker/
                                 Baloney Baffles brains: Eric Frank Russell

From dmurdoch at pair.com  Tue Nov 25 02:20:03 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Nov 25 02:18:46 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <x2znemc5gu.fsf@biostat.ku.dk>
References: <ils3svsfa9rt1725lb9mt42d0gc63pq8ba@4ax.com>
	<x2znemc5gu.fsf@biostat.ku.dk>
Message-ID: <17b5svs7cl2cjmto222665p545mb0ok74u@4ax.com>

>Duncan Murdoch <dmurdoch@pair.com> writes:
>
>> Gabor Grothendieck pointed out a bug to me in list.files(...,
>> full.name=TRUE), that essentially comes down to the fact that in
>> Windows it's not always valid to add a path separator (slash or
>> backslash) between a path specifier and a filename.  For example,
>> 
>> c:foo
>> 
>> is different from
>> 
>> c:\foo
>> 
>> and there are other examples.

I've committed a change to r-patched to fix this in Windows only.
Sounds like it's not an issue elsewhere.

Gabor also suggested an option to use shell globbing instead of
regular expressions to select the files in the list, e.g.

list.files(dir="/", pattern="a*.dat", glob=T)

This would be easy to do in Windows, but from the little I know about
Unix programming, would not be so easy there, so I haven't done
anything about it.

Duncan Murdoch

From gregory_r_warnes at groton.pfizer.com  Tue Nov 25 03:29:19 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Tue Nov 25 03:28:12 2003
Subject: [Rd] Proposal: 'global' package refactoring
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20680AB4B@groexmb02.pfizer.com>


How about we use the information already stored in \keyword{}?

It should be straighforward to allow navigating among the \keyword
hirearchy.

-G

-----Original Message-----
From: Paul Murrell
To: Jan de Leeuw
Cc: Warnes, Gregory R; 'R-devel@stat.math.ethz.ch'
Sent: 11/24/03 6:12 PM
Subject: Re: [Rd] Proposal: 'global' package refactoring

Hi

I have wanted to figure out a way to do something along these lines for 
the many, widely-scattered plotting functions.  Something that would be 
less invasive (and less useful, but a valid step in the right 
direction), is simply a "directory" for different functional groups.  A 
list of function names, plus descriptions of what they do, plus a 
pointer to the package they are in would I think be really useful.  A 
lot of work to create and maintain, but really useful.  For example, the

web pages focused on "spatial projects" 
(http://sal.agecon.uiuc.edu/csiss/Rgeo/index.html) has summaries of all 
spatially related packages.
The coordination of the DBMS stuff 
(http://developer.r-project.org/db/index.html) is another example of 
something similar.
Then of course there is the R GUIs pages
(http://www.sciviews.org/_rgui/)

Paul



Jan de Leeuw wrote:
> This is a good idea, and it would be great to have these
> refactored meta packages. But it actually implies having
> a group similar to R core that does code review of
> existing packages. For example, what happens if
> a function seems to work but is programmed horribly
> inefficiently ? What happens if something exists on both
> the R and C levels ? What happens with packages that
> rely on private versions of BLAS ? Suppose two packages
> provide the same functionality, how does one choose ?
> And can this be done without coding conventions ? Who is
> in charge ?
> 
> On Nov 24, 2003, at 14:12, Warnes, Gregory R wrote:
> 
>>
>> Looking over the contents of various packages, including my own, it 
>> is  clear
>> that lots of things end up 'hidden away' in packages where they don't
>> belong.  My gregmisc package is a particularly egregious example,  
>> containing
>> something from almost every functional category.
>>
>> I propose that from time to time the R community go through the  
>> complete set
>> of packages and 'refactor' the functions and data sets into packages

>> that
>> have clearly defined goals.   This should make it easier to ensure  
>> that new
>> functions get placed into a location where users can easily find
them,
>> reduce the amount of re-implementation/duplication existing  
>> functionality,
>> and assist in ensuring interoperability.
>>
>> It would be worthwhile, for instance, to pull all of the functions  
>> related
>> to contrasts for generalized linear models into a common location,  
>> instead
>> of having them spread between base, Hmisc, MASS, gregmisc, etc.    
>> Similarly,
>> it would be helpful to pull together all of the genetics-computations

>> into a
>> single location.
>>
>> I recognize that not all package maintainers would be willing to  
>> participate
>> and that not all functions could be easily categorized, but I believe

>> that
>> this effort would yield significant benefit and is compatible with 
>> the  goal
>> of R-core to streamline the base packages.
>>
>> To put my money where my mouth is, I'll volunteer to organize a group

>> effort
>> to do such a refactoring in conjunction with the userR! 2004 or the
next
>> DSC, whichever folks agree is better for this purpose.
>>
>>
>> Gregory R. Warnes, Ph.D.
>> Senior Coordinator
>> Groton Non-Clinical Statistics
>> Pfizer Global Research and Development
>>  <<Warnes, Gregory R.vcf>>
>>
>>
>> LEGAL NOTICE\ Unless expressly stated otherwise, this  
>> messag...{{dropped}}
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>
> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> Editor: Journal of Multivariate Analysis, Journal of Statistical
Software
> US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA
90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email:
deleeuw@stat.ucla.edu
> homepage: http://gifi.stat.ucla.edu
>   
>
------------------------------------------------------------------------

> -------------------------
>           No matter where you go, there you are. --- Buckaroo Banzai
>                    http://gifi.stat.ucla.edu/sounds/nomatter.au
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul@stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

From greg at warnes.net  Tue Nov 25 03:43:59 2003
From: greg at warnes.net (Gregory R. Warnes)
Date: Tue Nov 25 03:43:32 2003
Subject: [Rd] Proposal: 'global' package refactoring
Message-ID: <389B2BCA-1EF1-11D8-BF36-000393138D70@warnes.net>


I have great faith in the R comminity's ability to come to consensus.  
One can (and should) avoid 'troublesom' issues / packages in a first 
pass.  These can come later.  Further, once we get the ball rolling, we 
may be able to convince the community to change from 'I have a neat 
function, lets make a package!' to 'I have a neat function.  It belongs 
in package  XXXXX'.)

I would imagine that the first step of this process would be to draft a 
recommended package structure along with a list of what functions 
belong where.  This would then be submitted *as a proposal* to R-core, 
who would have (of course) the final say on the structure.   A package 
author will continue to be free to package and distribute his own work 
in any way that he wants (consistent with the license of code he's 
borrowed, of course.), although most authors will be pleased that thier 
code has been deemed 'worthy' of admission into the base set.

I further recommend, that JStatSoft be used as a peer-recongnition 
system for functions that get included in the 'standard R extension 
packages' that result.   These will, of course, have been peer 
reviewed! This would meet a two-fold need.  First, it would provide 
peer recognition for code that is not suficciently substantial to merit 
its own packaage, making it easier for new contributors to participate. 
  (Many of the components of gregmissc actually fall into this 
category.)  Second, it will demonstrate the *volume* of contributions 
by individuals by the number of inclusions.  Of course, there would 
need to be a reasonable minimum size/worth requirement to be recognized 
in this fashon.   Smaller contributions will continue to be recognized 
by listing the names of all contributors in a master list.

Further on, it will become possible to de-centralize the management of 
the package system so that certain individuals would take up management 
of specific package areas, (e.g. Paul Murrrel for graphics, etc.)





-----Original Message-----
From: Jan de Leeuw
To: Warnes, Gregory R
Cc: 'R-devel@stat.math.ethz.ch'
Sent: 11/24/03 5:36 PM
Subject: Re: [Rd] Proposal: 'global' package refactoring

This is a good idea, and it would be great to have these
refactored meta packages. But it actually implies having
a group similar to R core that does code review of
existing packages. For example, what happens if
a function seems to work but is programmed horribly
inefficiently ? What happens if something exists on both
the R and C levels ? What happens with packages that
rely on private versions of BLAS ? Suppose two packages
provide the same functionality, how does one choose ?
And can this be done without coding conventions ? Who is
in charge ?

On Nov 24, 2003, at 14:12, Warnes, Gregory R wrote:

 >
 > Looking over the contents of various packages, including my own, it is

 > clear
 > that lots of things end up 'hidden away' in packages where they don't
 > belong.  My gregmisc package is a particularly egregious example,
 > containing
 > something from almost every functional category.
 >
 > I propose that from time to time the R community go through the
 > complete set
 > of packages and 'refactor' the functions and data sets into packages
 > that
 > have clearly defined goals.   This should make it easier to ensure
 > that new
 > functions get placed into a location where users can easily find them,
 > reduce the amount of re-implementation/duplication existing
 > functionality,
 > and assist in ensuring interoperability.
 >
 > It would be worthwhile, for instance, to pull all of the functions
 > related
 > to contrasts for generalized linear models into a common location,
 > instead
 > of having them spread between base, Hmisc, MASS, gregmisc, etc.
 > Similarly,
 > it would be helpful to pull together all of the genetics-computations

 > into a
 > single location.
 >
 > I recognize that not all package maintainers would be willing to
 > participate
 > and that not all functions could be easily categorized, but I believe

 > that
 > this effort would yield significant benefit and is compatible with the

 > goal
 > of R-core to streamline the base packages.
 >
 > To put my money where my mouth is, I'll volunteer to organize a group

 > effort
 > to do such a refactoring in conjunction with the userR! 2004 or the
 > next
 > DSC, whichever folks agree is better for this purpose.
 >
 >
 > Gregory R. Warnes, Ph.D.
 > Senior Coordinator
 > Groton Non-Clinical Statistics
 > Pfizer Global Research and Development
 >  <<Warnes, Gregory R.vcf>>
 >
 >
 > LEGAL NOTICE\ Unless expressly stated otherwise, this
 > messag...{{dropped}}
 >
 > ______________________________________________
 > R-devel@stat.math.ethz.ch mailing list
 > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
 >
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu

------------------------------------------------------------------------

-------------------------
            No matter where you go, there you are. --- Buckaroo Banzai
                     http://gifi.stat.ucla.edu/sounds/nomatter.au

From deleeuw at stat.ucla.edu  Tue Nov 25 04:45:52 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Tue Nov 25 04:44:37 2003
Subject: [Rd] Proposal: 'global' package refactoring
In-Reply-To: <389B2BCA-1EF1-11D8-BF36-000393138D70@warnes.net>
References: <389B2BCA-1EF1-11D8-BF36-000393138D70@warnes.net>
Message-ID: <DDD2FB30-1EF9-11D8-9A24-000A95A67E82@stat.ucla.edu>

JSS has a "code snippet" section, currently empty, with editors  
Koenker, Hornik,
Rossini and Udina. We could never decide on the format, that's why its  
empty.
I guess it could be used for "R function F that should be in package X"  
, but
from the JSS perspective it seems we must then also open the section to
C or Matlab or even IML and VB code. Opening a section of the journal  
that
only considers R code is a bit of a radical step, I think, although  
such a section
would be very useful to me as an R person. Given that the fact that JSS  
does
not have page limitations, and that I recently suggested to introduce a  
"type"
field in the MySQL database anyway, we might simply introduce the type
"certified R code" for some contributions. There will be buttons to  
select
contributions of a given type.

On Nov 24, 2003, at 18:43, Gregory R. Warnes wrote:

> I further recommend, that JStatSoft be used as a peer-recongnition  
> system for functions that get included in the 'standard R extension  
> packages' that result.   These will, of course, have been peer  
> reviewed! This would meet a two-fold need.  First, it would provide  
> peer recognition for code that is not suficciently substantial to  
> merit its own packaage, making it easier for new contributors to  
> participate.  (Many of the components of gregmissc actually fall into  
> this category.)  Second, it will demonstrate the *volume* of  
> contributions by individuals by the number of inclusions.  Of course,  
> there would need to be a reasonable minimum size/worth requirement to  
> be recognized in this fashon.   Smaller contributions will continue to  
> be recognized by listing the names of all contributors in a master  
> list.
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From ripley at stats.ox.ac.uk  Tue Nov 25 08:23:15 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Nov 25 08:23:37 2003
Subject: [Rd] Proposal: 'global' package refactoring
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C20680AB43@groexmb02.pfizer.com>
Message-ID: <Pine.LNX.4.44.0311250716380.26806-100000@gannet.stats>

I am explicitly not prepared to `refactor' MASS.  Not only is it
explicitly support software for a book (which references it and those
references cannot be changed retrospectively), it also represents much
work over many years.  Not that we get much credit for it, but we do get
some and these days that does matter.

Parts of MASS have been incorporated into both R and S-PLUS -- perhaps we 
have already gone too far.  Indeed, I have floated the idea of migrating 
some functionality back, notably that of package lqs (which is part of 
MASS in the S version).

On Mon, 24 Nov 2003, Warnes, Gregory R wrote:

> 
> Looking over the contents of various packages, including my own, it is clear
> that lots of things end up 'hidden away' in packages where they don't
> belong.  My gregmisc package is a particularly egregious example, containing
> something from almost every functional category.  
> 
> I propose that from time to time the R community go through the complete set
> of packages and 'refactor' the functions and data sets into packages that
> have clearly defined goals.   This should make it easier to ensure that new
> functions get placed into a location where users can easily find them,
> reduce the amount of re-implementation/duplication existing functionality,
> and assist in ensuring interoperability.
> 
> It would be worthwhile, for instance, to pull all of the functions related
> to contrasts for generalized linear models into a common location, instead
> of having them spread between base, Hmisc, MASS, gregmisc, etc.   Similarly,
> it would be helpful to pull together all of the genetics-computations into a
> single location.
> 
> I recognize that not all package maintainers would be willing to participate
> and that not all functions could be easily categorized, but I believe that
> this effort would yield significant benefit and is compatible with the goal
> of R-core to streamline the base packages. 
> 
> To put my money where my mouth is, I'll volunteer to organize a group effort
> to do such a refactoring in conjunction with the userR! 2004 or the next
> DSC, whichever folks agree is better for this purpose.
> 
> 
> Gregory R. Warnes, Ph.D.
> Senior Coordinator
> Groton Non-Clinical Statistics
> Pfizer Global Research and Development
>  <<Warnes, Gregory R.vcf>> 
> 
> 
> LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Tue Nov 25 08:35:57 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Nov 25 08:34:49 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <17b5svs7cl2cjmto222665p545mb0ok74u@4ax.com>
Message-ID: <Pine.LNX.4.44.0311250728180.26806-100000@gannet.stats>

On Mon, 24 Nov 2003, Duncan Murdoch wrote:

> >Duncan Murdoch <dmurdoch@pair.com> writes:
> >
> >> Gabor Grothendieck pointed out a bug to me in list.files(...,
> >> full.name=TRUE), that essentially comes down to the fact that in
> >> Windows it's not always valid to add a path separator (slash or
> >> backslash) between a path specifier and a filename.  For example,
> >> 
> >> c:foo
> >> 
> >> is different from
> >> 
> >> c:\foo
> >> 
> >> and there are other examples.
> 
> I've committed a change to r-patched to fix this in Windows only.
> Sounds like it's not an issue elsewhere.

I think there are some potential issues with doubling separators and final
separators on dirs.  On Unix file systems /part1//part2 and /path/to/dir/
are valid.  However, file systems on Unix may not be Unix file systems:
examples are earlier MacOS systems on MacOS X and mounted Windows and 
Novell systems on Linux.  I would not want to assume that all of these
combinations worked.

> Gabor also suggested an option to use shell globbing instead of
> regular expressions to select the files in the list, e.g.
> 
> list.files(dir="/", pattern="a*.dat", glob=T)
> 
> This would be easy to do in Windows, but from the little I know about
> Unix programming, would not be so easy there, so I haven't done
> anything about it.

It would be shell-dependent and OS-dependent as well as a retrograde step,
as those who wanted to use regular expressions no longer would be able to.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Tue Nov 25 10:52:52 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Nov 25 10:43:46 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <Pine.LNX.4.44.0311250728180.26806-100000@gannet.stats>
References: <Pine.LNX.4.44.0311250728180.26806-100000@gannet.stats>
Message-ID: <x21xrwu64r.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> I think there are some potential issues with doubling separators and final
> separators on dirs.  On Unix file systems /part1//part2 and /path/to/dir/
> are valid.  However, file systems on Unix may not be Unix file systems:
> examples are earlier MacOS systems on MacOS X and mounted Windows and 
> Novell systems on Linux.  I would not want to assume that all of these
> combinations worked.

Also, beware that some applications treat trailing spaces specially,
notably rsync:

       a trailing slash on the source changes this behavior to
       transfer all files from the directory src/bar on the machine
       foo into the /data/tmp/. A trailing / on a source name means
       "copy the contents of this directory". Without a trailing slash
       it means "copy the directory". This difference becomes
       particularly important when using the --delete option.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From dmurdoch at pair.com  Tue Nov 25 13:14:49 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Nov 25 13:13:52 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <Pine.LNX.4.44.0311250728180.26806-100000@gannet.stats>
References: <17b5svs7cl2cjmto222665p545mb0ok74u@4ax.com>
	<Pine.LNX.4.44.0311250728180.26806-100000@gannet.stats>
Message-ID: <peh6sv41hpuo8ucnuo7jgocgjb0giugimf@4ax.com>

On Tue, 25 Nov 2003 07:35:57 +0000 (GMT), you wrote:


>I think there are some potential issues with doubling separators and final
>separators on dirs.  On Unix file systems /part1//part2 and /path/to/dir/
>are valid.  However, file systems on Unix may not be Unix file systems:
>examples are earlier MacOS systems on MacOS X and mounted Windows and 
>Novell systems on Linux.  I would not want to assume that all of these
>combinations worked.

This is something that R could not do reliably by itself.  The code I
committed checks the final character in the path, and if it's "/", "\"
or ":" doesn't add a path separator.  However, both "C:" and "C:\" are
valid directory names in standard Unix file systems, so the test would
do the wrong thing there.

I think people who mount strange file systems will just have to expect
occasional glitches.  The only way I can see around this is to add
another argument to list.files() to say whether to add a path
separator, but it would be so rarely used that it doesn't seem to be
worth the effort.

Duncan Murdoch

From ggrothendieck at myway.com  Tue Nov 25 13:27:46 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue Nov 25 13:26:31 2003
Subject: [Rd] Question about Unix file paths
Message-ID: <20031125122746.772EA394D@mprdmxin.myway.com>



Perhaps the dir= and pattern= arguments could be combined so that 
its not necessary to for list.files to paste them together:

  list.files("C:/a*.txt", glob=T)

 
Date: Tue, 25 Nov 2003 07:14:49 -0500 
From: Duncan Murdoch <dmurdoch@pair.com>
To: Prof Brian Ripley <ripley@stats.ox.ac.uk> 
Cc: <r-devel@stat.math.ethz.ch> 
Subject: Re: [Rd] Question about Unix file paths 

 
 
On Tue, 25 Nov 2003 07:35:57 +0000 (GMT), you wrote:


>I think there are some potential issues with doubling separators and final
>separators on dirs. On Unix file systems /part1//part2 and /path/to/dir/
>are valid. However, file systems on Unix may not be Unix file systems:
>examples are earlier MacOS systems on MacOS X and mounted Windows and 
>Novell systems on Linux. I would not want to assume that all of these
>combinations worked.

This is something that R could not do reliably by itself. The code I
committed checks the final character in the path, and if it's "/", "\"
or ":" doesn't add a path separator. However, both "C:" and "C:\" are
valid directory names in standard Unix file systems, so the test would
do the wrong thing there.

I think people who mount strange file systems will just have to expect
occasional glitches. The only way I can see around this is to add
another argument to list.files() to say whether to add a path
separator, but it would be so rarely used that it doesn't seem to be
worth the effort.

Duncan Murdoch

______________________________________________
R-devel@stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From kleiweg at let.rug.nl  Tue Nov 25 13:29:50 2003
From: kleiweg at let.rug.nl (Peter Kleiweg)
Date: Tue Nov 25 13:28:34 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <peh6sv41hpuo8ucnuo7jgocgjb0giugimf@4ax.com>
Message-ID: <Pine.LNX.4.44.0311251324140.1390-100000@kleigh.nl>

# aldus Duncan Murdoch :

> On Tue, 25 Nov 2003 07:35:57 +0000 (GMT), you wrote:
>
>
> >I think there are some potential issues with doubling separators and final
> >separators on dirs.  On Unix file systems /part1//part2 and /path/to/dir/
> >are valid.  However, file systems on Unix may not be Unix file systems:
> >examples are earlier MacOS systems on MacOS X and mounted Windows and
> >Novell systems on Linux.  I would not want to assume that all of these
> >combinations worked.
>
> This is something that R could not do reliably by itself.  The code I
> committed checks the final character in the path, and if it's "/", "\"
> or ":" doesn't add a path separator.  However, both "C:" and "C:\" are
> valid directory names in standard Unix file systems, so the test would
> do the wrong thing there.

I think you should test for OS ( R.Version()$os )

The special meaning of "c:file" on Windows does not exist on
Unix, even if the filesystem is on a mounted Windows partition.


-- 
Peter Kleiweg
http://www.let.rug.nl/~kleiweg/

From dmurdoch at pair.com  Tue Nov 25 13:53:11 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Nov 25 13:51:55 2003
Subject: [Rd] Proposal: 'global' package refactoring
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C20680AB43@groexmb02.pfizer.com>
References: <D7A3CFD7825BD6119B880002A58F06C20680AB43@groexmb02.pfizer.com>
Message-ID: <3mj6sv4ehhedm9e2mvslrce7e2hmnbts4k@4ax.com>

On Mon, 24 Nov 2003 17:12:24 -0500, you wrote:


>I propose that from time to time the R community go through the complete set
>of packages and 'refactor' the functions and data sets into packages that
>have clearly defined goals. 

Package 'foreign' is currently such a multi-author common purpose
package.  One of the problems is that there isn't a single maintainer:
users who have problems with any of the functions write to all of the
authors for help.  All of the authors are still active, so this gets a
response, but I can see problems in some other package where an author
moves on and doesn't want to maintain the code.  

If that happens to a package then the package will disappear from
CRAN, once it stops passing tests in new releases.  If it's just a
function or two, what happens when it needs maintenance, or when it
gets orphaned?

Duncan Murdoch

From dmurdoch at pair.com  Tue Nov 25 13:58:58 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Nov 25 13:57:37 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <20031125122746.772EA394D@mprdmxin.myway.com>
References: <20031125122746.772EA394D@mprdmxin.myway.com>
Message-ID: <sbk6svo8nj1fr1vnlumicba47ghrbidl0p@4ax.com>

On Tue, 25 Nov 2003 07:27:46 -0500 (EST), you wrote:

>
>Perhaps the dir= and pattern= arguments could be combined so that 
>its not necessary to for list.files to paste them together:
>
>  list.files("C:/a*.txt", glob=T)

Why not use system() or shell() instead?  Those explicitly do what ls
or dir would do.

Duncan Murdoch

From dmurdoch at pair.com  Tue Nov 25 14:05:49 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Nov 25 14:04:58 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <Pine.LNX.4.44.0311251324140.1390-100000@kleigh.nl>
References: <peh6sv41hpuo8ucnuo7jgocgjb0giugimf@4ax.com>
	<Pine.LNX.4.44.0311251324140.1390-100000@kleigh.nl>
Message-ID: <3jk6sv4vq84snqlfg3sk8hlq3p719h679v@4ax.com>

On Tue, 25 Nov 2003 13:29:50 +0100 (CET), you wrote:

>I think you should test for OS ( R.Version()$os )
>
>The special meaning of "c:file" on Windows does not exist on
>Unix, even if the filesystem is on a mounted Windows partition.

The patch does that implicitly by an "#ifdef Win32" in the source
code, an explicit check isn't needed.

If there are strange situations where the default handling of path
separators doesn't work, the user can always put together the path
using paste().  Users could have done that in Windows for paths like
C: or C:\, but those are common enough that I think it's reasonable to
handle them explicitly.

Duncan Murdoch

From ggrothendieck at myway.com  Tue Nov 25 14:22:10 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue Nov 25 14:20:55 2003
Subject: [Rd] Question about Unix file paths
Message-ID: <20031125132210.E69B3396D@mprdmxin.myway.com>



Actually that's what I currently do using something like:
   readLines(pipe("cmd /c dir/b \\myfolder\\a*.txt"))
but its a pain since:

1. One has to explicitly paste together the filename from the 
output of dir with the directory path to create a complete 
path/filename for use in other commands.  That's because, the 
Windows dir command does not preface the filename with the 
path (unless you use something like dir/b/s but that gives 
you everything in subdirectories too which one may not want).

2. One must convert / to \ since dir will not take /.  If one
uses \ then one has to write \\ in R strings, which is is annoying,
so I prefer to use /.  For example, to convert all consecutives
series of / and \ to \ is: gsub("[/\\\\]+","\\\\",path) 
or gsub("[/\\]+","\\\\",path) .

3. There are reported bugs in R's pipe() on Windows and although 
I have not noticed them affecting the pipe above, I really don't know
what their cause is and I am just crossing my fingers on this one.
I guess I could redirect dir's output to a file but that would
be even more work.

4. Its all somewhat complex for a simple operation.


--- 
On Tue, 25 Nov 2003 07:27:46 -0500 (EST), you wrote:

>
>Perhaps the dir= and pattern= arguments could be combined so that 
>its not necessary to for list.files to paste them together:
>
> list.files("C:/a*.txt", glob=T)

Why not use system() or shell() instead? Those explicitly do what ls
or dir would do.

Duncan Murdoch

From jfox at mcmaster.ca  Tue Nov 25 14:33:45 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue Nov 25 14:31:15 2003
Subject: [Rd] Proposal: 'global' package refactoring
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C20680AB4B@groexmb02.pfizer. com>
Message-ID: <5.1.0.14.2.20031125082657.0201ef08@127.0.0.1>

Dear Gregory, Paul, and Jan,

I recall proposing something like this (that is, a classification of 
available functions) some time ago, but it never got off the ground. The 
advantage of using keywords is that package authors would classify their 
own functions, but I don't think that the current set of keywords is 
adequate. It would be particularly useful to work out a hierarchical or 
perhaps hyper-linked classification (without restricting particular 
functions to just one terminal node).

Regards,
  John

At 09:29 PM 11/24/2003 -0500, Warnes, Gregory R wrote:

>How about we use the information already stored in \keyword{}?
>
>It should be straighforward to allow navigating among the \keyword
>hirearchy.
>
>-G
>
>-----Original Message-----
>From: Paul Murrell
>To: Jan de Leeuw
>Cc: Warnes, Gregory R; 'R-devel@stat.math.ethz.ch'
>Sent: 11/24/03 6:12 PM
>Subject: Re: [Rd] Proposal: 'global' package refactoring
>
>Hi
>
>I have wanted to figure out a way to do something along these lines for
>the many, widely-scattered plotting functions.  Something that would be
>less invasive (and less useful, but a valid step in the right
>direction), is simply a "directory" for different functional groups.  A
>list of function names, plus descriptions of what they do, plus a
>pointer to the package they are in would I think be really useful.  A
>lot of work to create and maintain, but really useful.  For example, the
>
>web pages focused on "spatial projects"
>(http://sal.agecon.uiuc.edu/csiss/Rgeo/index.html) has summaries of all
>spatially related packages.
>The coordination of the DBMS stuff
>(http://developer.r-project.org/db/index.html) is another example of
>something similar.
>Then of course there is the R GUIs pages
>(http://www.sciviews.org/_rgui/)
>
>Paul
>
>
>
>Jan de Leeuw wrote:
> > This is a good idea, and it would be great to have these
> > refactored meta packages. But it actually implies having
> > a group similar to R core that does code review of
> > existing packages. For example, what happens if
> > a function seems to work but is programmed horribly
> > inefficiently ? What happens if something exists on both
> > the R and C levels ? What happens with packages that
> > rely on private versions of BLAS ? Suppose two packages
> > provide the same functionality, how does one choose ?
> > And can this be done without coding conventions ? Who is
> > in charge ?
> >
> > On Nov 24, 2003, at 14:12, Warnes, Gregory R wrote:
> >
> >>
> >> Looking over the contents of various packages, including my own, it
> >> is  clear
> >> that lots of things end up 'hidden away' in packages where they don't
> >> belong.  My gregmisc package is a particularly egregious example,
> >> containing
> >> something from almost every functional category.
> >>
> >> I propose that from time to time the R community go through the
> >> complete set
> >> of packages and 'refactor' the functions and data sets into packages
>
> >> that
> >> have clearly defined goals.   This should make it easier to ensure
> >> that new
> >> functions get placed into a location where users can easily find
>them,
> >> reduce the amount of re-implementation/duplication existing
> >> functionality,
> >> and assist in ensuring interoperability.
> >>
> >> It would be worthwhile, for instance, to pull all of the functions
> >> related
> >> to contrasts for generalized linear models into a common location,
> >> instead
> >> of having them spread between base, Hmisc, MASS, gregmisc, etc.
> >> Similarly,
> >> it would be helpful to pull together all of the genetics-computations
>
> >> into a
> >> single location.
> >>
> >> I recognize that not all package maintainers would be willing to
> >> participate
> >> and that not all functions could be easily categorized, but I believe
>
> >> that
> >> this effort would yield significant benefit and is compatible with
> >> the  goal
> >> of R-core to streamline the base packages.
> >>
> >> To put my money where my mouth is, I'll volunteer to organize a group
>
> >> effort
> >> to do such a refactoring in conjunction with the userR! 2004 or the
>next
> >> DSC, whichever folks agree is better for this purpose.
> >>
> >>
> >> Gregory R. Warnes, Ph.D.
> >> Senior Coordinator
> >> Groton Non-Clinical Statistics
> >> Pfizer Global Research and Development
> >>  <<Warnes, Gregory R.vcf>>
> >>
> >>
> >> LEGAL NOTICE\ Unless expressly stated otherwise, this
> >> messag...{{dropped}}
> >>
> >> ______________________________________________
> >> R-devel@stat.math.ethz.ch mailing list
> >> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> >>
> > ===
> > Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> > Editor: Journal of Multivariate Analysis, Journal of Statistical
>Software
> > US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA
>90095-1554
> > phone (310)-825-9550;  fax (310)-206-5658;  email:
>deleeuw@stat.ucla.edu
> > homepage: http://gifi.stat.ucla.edu
> >
> >
>------------------------------------------------------------------------
>
> > -------------------------
> >           No matter where you go, there you are. --- Buckaroo Banzai
> >                    http://gifi.stat.ucla.edu/sounds/nomatter.au
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>
>--
>Dr Paul Murrell
>Department of Statistics
>The University of Auckland
>Private Bag 92019
>Auckland
>New Zealand
>64 9 3737599 x85392
>paul@stat.auckland.ac.nz
>http://www.stat.auckland.ac.nz/~paul/
>
>
>LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox@mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox

From jean.coursol at math.u-psud.fr  Tue Nov 25 15:33:58 2003
From: jean.coursol at math.u-psud.fr (jean.coursol@math.u-psud.fr)
Date: Tue Nov 25 15:37:54 2003
Subject: [Rd] dwilcox , pwilcox, qwilcox are not freeing memory (PR#5314)
Message-ID: <20031125143358.E82B1F316@slim.kubism.ku.dk>

Full_Name: jean coursol
Version: 1.7.1, 1.8.0
OS: linux
Submission from: (NULL) (129.175.52.7)


w <- pwilcox(1000,50,50) allocates the  whole memory  and freezes the system
or     qwilcox
or     dwilcox

To fix the problem: in wilcox.c,   call wilcox_free() before return in the three
functions dwilcox, qwilcox, pwilcox.

*** R-1.8.0/src/nmath/wilcox.c	Thu Jul 17 13:13:17 2003
--- R-1.8.0/src/nmath/wilcox.patched.c	Tue Nov 18 09:56:19 2003
*************** double dwilcox(double x, double m, doubl
*** 162,168 ****
      d = give_log ?
  	log(cwilcox(x, m, n)) - lchoose(m + n, n) :
  	    cwilcox(x, m, n)  /	 choose(m + n, n);
! 
      return(d);
  }
  
--- 162,168 ----
      d = give_log ?
  	log(cwilcox(x, m, n)) - lchoose(m + n, n) :
  	    cwilcox(x, m, n)  /	 choose(m + n, n);
+     wilcox_free();                /* JC */
      return(d);
  }
  
*************** double pwilcox(double x, double m, doubl
*** 202,208 ****
  	    p += cwilcox(i, m, n) / c;
  	lower_tail = !lower_tail; /* p = 1 - p; */
      }
! 
      return(R_DT_val(p));
  } /* pwilcox */
  
--- 202,208 ----
  	    p += cwilcox(i, m, n) / c;
  	lower_tail = !lower_tail; /* p = 1 - p; */
      }
+     wilcox_free();                /* JC */
      return(R_DT_val(p));
  } /* pwilcox */
  
*************** double qwilcox(double x, double m, doubl
*** 255,261 ****
  	    q++;
  	}
      }
! 
      return(q);
  }
  
--- 255,261 ----
  	    q++;
  	}
      }
+     wilcox_free();                /* JC */
      return(q);
  }

From andy_liaw at merck.com  Tue Nov 25 15:26:45 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Nov 25 15:41:20 2003
Subject: [Rd] Proposal: 'global' package refactoring
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE92@usrymx25.merck.com>

> From: John Fox
> 
> Dear Gregory, Paul, and Jan,
> 
> I recall proposing something like this (that is, a classification of 
> available functions) some time ago, but it never got off the 
> ground. The 
> advantage of using keywords is that package authors would 
> classify their 
> own functions, but I don't think that the current set of keywords is 
> adequate. It would be particularly useful to work out a 
> hierarchical or 
> perhaps hyper-linked classification (without restricting particular 
> functions to just one terminal node).

I guess something similar to GAMS would help a lot:
http://gams.nist.gov/

Personally I think "refactoring" of packages is too difficult to manage, but
cross-indexing of functions in an easily searchable fashion would go a long
way.

Best,
Andy
 
> Regards,
>   John

From jean.coursol at math.u-psud.fr  Tue Nov 25 15:51:22 2003
From: jean.coursol at math.u-psud.fr (jean.coursol@math.u-psud.fr)
Date: Tue Nov 25 15:51:24 2003
Subject: [Rd] O2 optimization produces wrong code (PR#5315)
Message-ID: <20031125145122.7E437F7E3@slim.kubism.ku.dk>

Full_Name: jean coursol
Version: 1.7.1, 1.8.0
OS: linux & Windows-XP
Submission from: (NULL) (129.175.52.7)


Binary MS-Windows akima module from CRAN (1.8.0 version) produces wrong results
with some data.

Installing akima source in linux, with same data: 
-with gcc-2.95.3 -O2 : give correct results (under R 1.7.1);
-with gcc-3.2.3  -O2 : give  wrong results (under R-1.7.1 and R-1.8.0);
-with gcc-3.2.3 (no optimization) give correct results (under R-1.7.1 and
R-1.8.0);

Installing akima module made by RCrossBuild (with gcc-2.95.3, R-1.7.1) in
Windows-XP 
and R-1.8.0 gives correct results (it is possible to use cross-compiled akima
module 
using R-1.7.1, because there is no call from akima to R...).

It would be better to use RCrossBuild and R-1.8.0, but actually, RCrossBuild is
not running with gcc-3.2.3 and R-1.8.0...

From maechler at stat.math.ethz.ch  Tue Nov 25 16:13:14 2003
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue Nov 25 16:12:13 2003
Subject: [Rd] dwilcox , pwilcox, qwilcox are not freeing memory (PR#5314)
Message-ID: <20031125151314.513C2F4DB@slim.kubism.ku.dk>

>>>>> "jean" == jean coursol <jean.coursol@math.u-psud.fr>
>>>>>     on Tue, 25 Nov 2003 15:33:58 +0100 (CET) writes:

    jean> Full_Name: jean coursol Version: 1.7.1, 1.8.0 OS:
    jean> linux Submission from: (NULL) (129.175.52.7)


    jean> w <- pwilcox(1000,50,50) allocates the whole memory
    jean> and freezes the system or qwilcox or dwilcox

    jean> To fix the problem: in wilcox.c, call wilcox_free()
    jean> before return in the three functions dwilcox, qwilcox,
    jean> pwilcox.

That can hardly be the general idea!
Note that the R functions  [dpq]wilcox() are  **vectorized**,
and the whole purpose of the code is to only compute the tables
once per R call -- which is often many calls to the
corresponding C functions.

From dmurdoch at pair.com  Tue Nov 25 16:29:39 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Nov 25 16:28:01 2003
Subject: [Rd] O2 optimization produces wrong code (PR#5315)
In-Reply-To: <20031125145122.7E437F7E3@slim.kubism.ku.dk>
References: <20031125145122.7E437F7E3@slim.kubism.ku.dk>
Message-ID: <i4t6sv8du0f8q3dgmhn86u1pojmvea13h7@4ax.com>

On Tue, 25 Nov 2003 15:51:22 +0100 (CET), jean.coursol@math.u-psud.fr
wrote :

>Full_Name: jean coursol
>Version: 1.7.1, 1.8.0
>OS: linux & Windows-XP
>Submission from: (NULL) (129.175.52.7)
>
>
>Binary MS-Windows akima module from CRAN (1.8.0 version) produces wrong results
>with some data.

This isn't an R bug, it's a contributed package bug.  You should write
to the package maintainer Albrecht Gebhardt
<albrecht.gebhardt@uni-klu.ac.at> and the Windows binary package
maintainer Uwe Ligges <ligges@statistik.uni-dortmund.de>, including
code to reproduce the bug.

I'd suggest trying it with 1.8.1 first; it's possible you were seeing
the effects of some other bug that has been fixed. 

Duncan Murdoch

From ripley at stats.ox.ac.uk  Tue Nov 25 16:47:15 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Nov 25 16:49:07 2003
Subject: [Rd] O2 optimization produces wrong code (PR#5315)
Message-ID: <20031125154715.2315FF342@slim.kubism.ku.dk>

This is a long-known problem: one example is the MASS example in the
script ch15.R, and that has gone wrong on platforms other than Windows.  
It has been reported to the maintainer in the past.

On Tue, 25 Nov 2003, Duncan Murdoch wrote:

> On Tue, 25 Nov 2003 15:51:22 +0100 (CET), jean.coursol@math.u-psud.fr
> wrote :
> 
> >Full_Name: jean coursol
> >Version: 1.7.1, 1.8.0
> >OS: linux & Windows-XP
> >Submission from: (NULL) (129.175.52.7)
> >
> >
> >Binary MS-Windows akima module from CRAN (1.8.0 version) produces wrong results
> >with some data.
> 
> This isn't an R bug, it's a contributed package bug.  You should write
> to the package maintainer Albrecht Gebhardt
> <albrecht.gebhardt@uni-klu.ac.at> and the Windows binary package
> maintainer Uwe Ligges <ligges@statistik.uni-dortmund.de>, including
> code to reproduce the bug.
> 
> I'd suggest trying it with 1.8.1 first; it's possible you were seeing
> the effects of some other bug that has been fixed. 
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Tue Nov 25 16:47:01 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Nov 25 16:49:23 2003
Subject: [Rd] O2 optimization produces wrong code (PR#5315)
In-Reply-To: <i4t6sv8du0f8q3dgmhn86u1pojmvea13h7@4ax.com>
Message-ID: <Pine.LNX.4.44.0311251543390.6601-100000@gannet.stats>

This is a long-known problem: one example is the MASS example in the
script ch15.R, and that has gone wrong on platforms other than Windows.  
It has been reported to the maintainer in the past.

On Tue, 25 Nov 2003, Duncan Murdoch wrote:

> On Tue, 25 Nov 2003 15:51:22 +0100 (CET), jean.coursol@math.u-psud.fr
> wrote :
> 
> >Full_Name: jean coursol
> >Version: 1.7.1, 1.8.0
> >OS: linux & Windows-XP
> >Submission from: (NULL) (129.175.52.7)
> >
> >
> >Binary MS-Windows akima module from CRAN (1.8.0 version) produces wrong results
> >with some data.
> 
> This isn't an R bug, it's a contributed package bug.  You should write
> to the package maintainer Albrecht Gebhardt
> <albrecht.gebhardt@uni-klu.ac.at> and the Windows binary package
> maintainer Uwe Ligges <ligges@statistik.uni-dortmund.de>, including
> code to reproduce the bug.
> 
> I'd suggest trying it with 1.8.1 first; it's possible you were seeing
> the effects of some other bug that has been fixed. 
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From luke at stat.uiowa.edu  Tue Nov 25 18:35:30 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue Nov 25 18:34:20 2003
Subject: [Rd] Proposal: 'global' package refactoring
In-Reply-To: <Pine.LNX.4.44.0311250716380.26806-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0311251120160.20728-100000@itasca.stat.uiowa.edu>

On Tue, 25 Nov 2003, Prof Brian Ripley wrote:

> I am explicitly not prepared to `refactor' MASS.  Not only is it
> explicitly support software for a book (which references it and those
> references cannot be changed retrospectively), it also represents much
> work over many years.  Not that we get much credit for it, but we do get
> some and these days that does matter.
> 
> Parts of MASS have been incorporated into both R and S-PLUS -- perhaps we 
> have already gone too far.  Indeed, I have floated the idea of migrating 
> some functionality back, notably that of package lqs (which is part of 
> MASS in the S version).
> 

I think many package authors will find the idea of scattering things
they have written into many places unacceptable, both because, as
Brian says, it is hard enough to get credit for one's efforts when
there is an identifiable unit and because it makes maintenance more
difficult.

This suggests that there may be several organizations that make sense
for different purposes: one for code maintenance and one for use, or
maybe more than one for use: geostatistical users may prefer a
different organization than bioinformatics users or instructors in
elementary data analysis courses.

In principle it might be possible to use the name space mechanism to
provide different organizational structures: One can create a new
package that imports selected variables form a variety of packages and
then exports them as the variables of the new package.  At present
this does not import and re-export documentation, but that could be
addressed if this approach seems viable.  (This also only works if the
original package providing the variables has a name space.)

Best,

luke


> On Mon, 24 Nov 2003, Warnes, Gregory R wrote:
> 
> > 
> > Looking over the contents of various packages, including my own, it is clear
> > that lots of things end up 'hidden away' in packages where they don't
> > belong.  My gregmisc package is a particularly egregious example, containing
> > something from almost every functional category.  
> > 
> > I propose that from time to time the R community go through the complete set
> > of packages and 'refactor' the functions and data sets into packages that
> > have clearly defined goals.   This should make it easier to ensure that new
> > functions get placed into a location where users can easily find them,
> > reduce the amount of re-implementation/duplication existing functionality,
> > and assist in ensuring interoperability.
> > 
> > It would be worthwhile, for instance, to pull all of the functions related
> > to contrasts for generalized linear models into a common location, instead
> > of having them spread between base, Hmisc, MASS, gregmisc, etc.   Similarly,
> > it would be helpful to pull together all of the genetics-computations into a
> > single location.
> > 
> > I recognize that not all package maintainers would be willing to participate
> > and that not all functions could be easily categorized, but I believe that
> > this effort would yield significant benefit and is compatible with the goal
> > of R-core to streamline the base packages. 
> > 
> > To put my money where my mouth is, I'll volunteer to organize a group effort
> > to do such a refactoring in conjunction with the userR! 2004 or the next
> > DSC, whichever folks agree is better for this purpose.
> > 
> > 
> > Gregory R. Warnes, Ph.D.
> > Senior Coordinator
> > Groton Non-Clinical Statistics
> > Pfizer Global Research and Development
> >  <<Warnes, Gregory R.vcf>> 
> > 
> > 
> > LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
> > 
> > 
> 
> 

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From dmurdoch at pair.com  Tue Nov 25 19:56:41 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Nov 25 19:54:59 2003
Subject: [Rd] O2 optimization produces wrong code (PR#5315)
In-Reply-To: <Pine.LNX.4.44.0311251543390.6601-100000@gannet.stats>
References: <i4t6sv8du0f8q3dgmhn86u1pojmvea13h7@4ax.com>
	<Pine.LNX.4.44.0311251543390.6601-100000@gannet.stats>
Message-ID: <be97svg5caejjt1l47o2c9hiddaigepio1@4ax.com>

On Tue, 25 Nov 2003 15:47:01 +0000 (GMT), Prof Brian Ripley
<ripley@stats.ox.ac.uk> wrote :

>This is a long-known problem: one example is the MASS example in the
>script ch15.R, and that has gone wrong on platforms other than Windows.  
>It has been reported to the maintainer in the past.

Should we back off to something less aggressive than -O2?

Duncan Murdoch

From p.dalgaard at biostat.ku.dk  Tue Nov 25 21:55:23 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Nov 25 21:46:10 2003
Subject: [Rd] O2 optimization produces wrong code (PR#5315)
In-Reply-To: <be97svg5caejjt1l47o2c9hiddaigepio1@4ax.com>
References: <i4t6sv8du0f8q3dgmhn86u1pojmvea13h7@4ax.com>
	<Pine.LNX.4.44.0311251543390.6601-100000@gannet.stats>
	<be97svg5caejjt1l47o2c9hiddaigepio1@4ax.com>
Message-ID: <x2oev0rww4.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch@pair.com> writes:

> On Tue, 25 Nov 2003 15:47:01 +0000 (GMT), Prof Brian Ripley
> <ripley@stats.ox.ac.uk> wrote :
> 
> >This is a long-known problem: one example is the MASS example in the
> >script ch15.R, and that has gone wrong on platforms other than Windows.  
> >It has been reported to the maintainer in the past.
> 
> Should we back off to something less aggressive than -O2?

Traditionally, we've prioritized performance and used cases like this
to file bugs for the compiler writers. But is this really a compiler
problem or a problem with badly written code in akima??

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Tue Nov 25 22:22:08 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Nov 25 22:21:06 2003
Subject: [Rd] O2 optimization produces wrong code (PR#5315)
In-Reply-To: <x2oev0rww4.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0311252120320.9796-100000@gannet.stats>

On 25 Nov 2003, Peter Dalgaard wrote:

> Duncan Murdoch <dmurdoch@pair.com> writes:
> 
> > On Tue, 25 Nov 2003 15:47:01 +0000 (GMT), Prof Brian Ripley
> > <ripley@stats.ox.ac.uk> wrote :
> > 
> > >This is a long-known problem: one example is the MASS example in the
> > >script ch15.R, and that has gone wrong on platforms other than Windows.  
> > >It has been reported to the maintainer in the past.
> > 
> > Should we back off to something less aggressive than -O2?
> 
> Traditionally, we've prioritized performance and used cases like this
> to file bugs for the compiler writers. But is this really a compiler
> problem or a problem with badly written code in akima??

I suspect the latter, in particular I suspect uninitialized data areas.
As far as I recall, this has gone wrong even without optimization.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dmurdoch at pair.com  Tue Nov 25 22:45:20 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Nov 25 22:43:38 2003
Subject: [Rd] O2 optimization produces wrong code (PR#5315)
In-Reply-To: <Pine.LNX.4.44.0311252120320.9796-100000@gannet.stats>
References: <x2oev0rww4.fsf@biostat.ku.dk>
	<Pine.LNX.4.44.0311252120320.9796-100000@gannet.stats>
Message-ID: <p6j7svg1drf0s6sg13tanlm939jevtfpfb@4ax.com>

On Tue, 25 Nov 2003 21:22:08 +0000 (GMT), Prof Brian Ripley
<ripley@stats.ox.ac.uk> wrote :

>On 25 Nov 2003, Peter Dalgaard wrote:
>
>> Duncan Murdoch <dmurdoch@pair.com> writes:
>> 
>> > On Tue, 25 Nov 2003 15:47:01 +0000 (GMT), Prof Brian Ripley
>> > <ripley@stats.ox.ac.uk> wrote :
>> > 
>> > >This is a long-known problem: one example is the MASS example in the
>> > >script ch15.R, and that has gone wrong on platforms other than Windows.  
>> > >It has been reported to the maintainer in the past.
>> > 
>> > Should we back off to something less aggressive than -O2?
>> 
>> Traditionally, we've prioritized performance and used cases like this
>> to file bugs for the compiler writers. But is this really a compiler
>> problem or a problem with badly written code in akima??
>
>I suspect the latter, in particular I suspect uninitialized data areas.
>As far as I recall, this has gone wrong even without optimization.

I think I misread Brian as saying that this is a long-known problem
with gcc, rather than a long-known problem with akima.  Back to my
original suggestion:  give the akima maintainer a reproducible
example.

Duncan

From bates at stat.wisc.edu  Tue Nov 25 23:09:02 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue Nov 25 23:07:48 2003
Subject: [Rd] Re: 64-bit R on Opteron [was Re: [R] Windows R 1.8.0 hangs
	when M	em Usage >1.8GB]
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CEA0@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CEA0@usrymx25.merck.com>
Message-ID: <6r3ccc85j5.fsf@bates4.stat.wisc.edu>

(Reply moved to R-devel where it may be more appropriate.)

"Liaw, Andy" <andy_liaw@merck.com> writes:

> > From: Douglas Bates [mailto:bates@bates4.stat.wisc.edu]
> > 
> > "Liaw, Andy" <andy_liaw@merck.com> writes:
> > 
> > > Sorry.  I need to retract my claim.  There seems to be a 3G 
> > > limit, even though the OS could handle nearly 8G.  (I can have
> > > two simultaneous R processes each using near 3G.)
> > > 
> > > On another note, on our dual Opteron box R (compiled as 64-bit)
> > > could easily use nearly all the 16G in that box (that's one of
> > > the reason for having that box).
> > 
> > Does "could" mean you have verified that it did or is this a
> > theoretical statement?  I.e., have you compiled and tested R on your
> > dual Opteron?
> 
> Given my questionable memory of things, this question is very fair.
> Here's the evidence:
> 
> > x <- matrix(0, 5e5, 5e5)
> > x2 <- matrix(0, 5e5, 5e5)
> > gc()
>              used    (Mb) gc trigger    (Mb)
> Ncells     413379    22.1     741108    39.6
> Vcells 1783900405 13610.1 1784288128 13613.1

Amazing!

I wonder if R&R thought when they started out that they would one day
see something like that.

How does the Opteron perform on floating point?  Can you try something
like

> mm = matrix(rnorm(1e6), nc = 1e3)
> system.time(crossprod(mm))
[1] 0.51 0.02 0.53 0.00 0.00
> system.time(crossprod(mm))
[1] 0.37 0.03 0.40 0.00 0.00
> system.time(crossprod(mm))
[1] 0.38 0.02 0.40 0.00 0.00
> system.time(crossprod(mm))
[1] 0.38 0.02 0.40 0.00 0.00

(That was with R compiled to use Goto's BLAS on a 2.0 GHz P4.)

Are you using Goto's BLAS or Atlas?

From ihaka at stat.auckland.ac.nz  Tue Nov 25 23:22:23 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Tue Nov 25 23:22:12 2003
Subject: [Rd] Re: 64-bit R on Opteron [was Re: [R] Windows R 1.8.0 hangs
	when M	em Usage >1.8GB]
In-Reply-To: <6r3ccc85j5.fsf@bates4.stat.wisc.edu>
References: <3A822319EB35174CA3714066D590DCD50205CEA0@usrymx25.merck.com>
	<6r3ccc85j5.fsf@bates4.stat.wisc.edu>
Message-ID: <3FC3D61F.6090500@stat.auckland.ac.nz>

Douglas Bates wrote:

> I wonder if R&R thought when they started out that they would one day
> see something like that.

I think that's a pretty firm no.

I seem to recall that we were targetting 512k Macintoshes.
In our dreams we might have seen 16Mb Sun.

-- 
Ross Ihaka                         Email:  ihaka@stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand

From rossini at blindglobe.net  Tue Nov 25 23:24:58 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue Nov 25 23:25:55 2003
Subject: [Rd] Re: 64-bit R on Opteron
In-Reply-To: <6r3ccc85j5.fsf@bates4.stat.wisc.edu> (Douglas Bates's message
	of "25 Nov 2003 16:09:02 -0600")
References: <3A822319EB35174CA3714066D590DCD50205CEA0@usrymx25.merck.com>
	<6r3ccc85j5.fsf@bates4.stat.wisc.edu>
Message-ID: <85fzgc3x39.fsf@blindglobe.net>

Douglas Bates <bates@stat.wisc.edu> writes:

> (Reply moved to R-devel where it may be more appropriate.)
>
> "Liaw, Andy" <andy_liaw@merck.com> writes:
>
>> > From: Douglas Bates [mailto:bates@bates4.stat.wisc.edu]
>> > 
>> > "Liaw, Andy" <andy_liaw@merck.com> writes:
>> > 
>> > > Sorry.  I need to retract my claim.  There seems to be a 3G 
>> > > limit, even though the OS could handle nearly 8G.  (I can have
>> > > two simultaneous R processes each using near 3G.)
>> > > 
>> > > On another note, on our dual Opteron box R (compiled as 64-bit)
>> > > could easily use nearly all the 16G in that box (that's one of
>> > > the reason for having that box).
>> > 
>> > Does "could" mean you have verified that it did or is this a
>> > theoretical statement?  I.e., have you compiled and tested R on your
>> > dual Opteron?
>> 
>> Given my questionable memory of things, this question is very fair.
>> Here's the evidence:
>> 
>> > x <- matrix(0, 5e5, 5e5)
>> > x2 <- matrix(0, 5e5, 5e5)
>> > gc()
>>              used    (Mb) gc trigger    (Mb)
>> Ncells     413379    22.1     741108    39.6
>> Vcells 1783900405 13610.1 1784288128 13613.1
>
> Amazing!

Dave Henderson reported similar data last summer.  It's the main
reason I've got 2 high-memory opterons on order...

The only catch will be setting them up -- pay for SuSE, go with
Mandrake, go with Gentoo, or roll-ones-own pre-release Debian
variant...

best,
-tony

-- 
rossini@u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}

From Stephen.Harker at spme.monash.edu.au  Tue Nov 25 06:57:08 2003
From: Stephen.Harker at spme.monash.edu.au (Stephen.Harker@spme.monash.edu.au)
Date: Tue Nov 25 23:26:16 2003
Subject: [Rd] R postscript generation error (lines versus points) (PR#5285)
In-Reply-To: <3FC26745.50807@stat.auckland.ac.nz>
References: <20031124032202.820FCEFC2@slim.kubism.ku.dk>
	<x2islat94a.fsf@biostat.ku.dk> <3FC26745.50807@stat.auckland.ac.nz>
Message-ID: <20031125055708.GA16069@harker.spme.monash.edu.au>

Hi,

On Tue, Nov 25, 2003 at 09:17:09AM +1300, Paul Murrell wrote:
> Hi
> 
> Peter Dalgaard wrote:
> > Stephen.Harker@spme.monash.edu.au writes:
> >
> >>Full_Name: Stephen Harker
> >>Version: 1.80
> >>OS: linux (Yellow Dog 3.0 on ppc)
> >>Submission from: (NULL) (130.194.13.101)
> >>
> >>
> >>In creating a postscript file from a set of data in which the points are
> >>plotted
> >>using `points()' and lines drawn using `lines()' I have found since 
> upgrading
> >>from R version 1.4? to 1.8 that the two sets do not coinicide 
> completely.  [...]
> >
> > I can't reproduce this with 1.8.0 on RedHat 8.0. Are you sure it isn't
> > your Postscript viewer that is playing tricks on you??

After further checking I find that this is the solution, despite my
previous email saying it could not be the case.  I have now downgraded
to gs 8.00 on /usr/local/bin (previously gs 8.11) and all postscript
output views correctly even in the LaTeX documents using production
output of neutron and x-ray powder diffraction that were previously
causing problems.  That is to say that documents that previously
exhibited the problem now don't.

More surprsingly (to me) the printed output is correct.  I have my
printer queues set up using CUPS and appropriate ppd files specific
for our departmental printers.  As these are postscript printers and
the correct PPD files are used I had assumed this meant ghostscript
was not interacting with the printing.  I was most surprised to
discover this assumption must be wrong.  It would appear that gs is in
the loop with a postscript file being sent to a postscript printer as
I have them setup.

I will now have to work on a bug report for ghostscript 8.11.  It
appears I blamed the wrong upgrade (R rather than ghostscript,
encouraged by the printed results).  I knew I had upgraded the two
close together, but had not checked the dates sufficiently.  I assume
this closes this `bug report' unless you wish to be informed of any
progress in isolating the problem in gs 8.11.

-- 
Stephen Harker                           Stephen.Harker@spme.monash.edu.au
School of Physics & Materials Engineering
Monash University                       http://www.ph.adfa.edu.au/s-harker/
                                 Baloney Baffles brains: Eric Frank Russell

From Kurt.Hornik at wu-wien.ac.at  Wed Nov 26 10:05:42 2003
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed Nov 26 10:07:28 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <Pine.LNX.4.44.0311250728180.26806-100000@gannet.stats>
References: <17b5svs7cl2cjmto222665p545mb0ok74u@4ax.com>
	<Pine.LNX.4.44.0311250728180.26806-100000@gannet.stats>
Message-ID: <16324.27878.740145.101@mithrandir.hornik.net>

>>>>> Prof Brian Ripley writes:

> On Mon, 24 Nov 2003, Duncan Murdoch wrote:
>> >Duncan Murdoch <dmurdoch@pair.com> writes:
>> >
>> >> Gabor Grothendieck pointed out a bug to me in list.files(...,
>> >> full.name=TRUE), that essentially comes down to the fact that in
>> >> Windows it's not always valid to add a path separator (slash or
>> >> backslash) between a path specifier and a filename.  For example,
>> >> 
>> >> c:foo
>> >> 
>> >> is different from
>> >> 
>> >> c:\foo
>> >> 
>> >> and there are other examples.
>> 
>> I've committed a change to r-patched to fix this in Windows only.
>> Sounds like it's not an issue elsewhere.

> I think there are some potential issues with doubling separators and
> final separators on dirs.  On Unix file systems /part1//part2 and
> /path/to/dir/ are valid.  However, file systems on Unix may not be
> Unix file systems:  examples are earlier MacOS systems on MacOS X and
> mounted Windows and Novell systems on Linux.  I would not want to
> assume that all of these combinations worked.

>> Gabor also suggested an option to use shell globbing instead of
>> regular expressions to select the files in the list, e.g.
>> 
>> list.files(dir="/", pattern="a*.dat", glob=T)
>> 
>> This would be easy to do in Windows, but from the little I know about
>> Unix programming, would not be so easy there, so I haven't done
>> anything about it.

> It would be shell-dependent and OS-dependent as well as a retrograde
> step, as those who wanted to use regular expressions no longer would
> be able to.

Right.  In any case, an explicit glob() function seems preferable to
me ...

-k

From stephen at inf.ed.ac.uk  Wed Nov 26 13:26:22 2003
From: stephen at inf.ed.ac.uk (stephen@inf.ed.ac.uk)
Date: Wed Nov 26 13:25:21 2003
Subject: [Rd] wishlist item: symbols() to accept asp argument? (PR#5328)
Message-ID: <20031126122622.E75F2EFCD@slim.kubism.ku.dk>

Here is a potential wishlist item for adding an argument (asp) to
symbols().  The following code produces a postscript file with two
pages; both should show a circle of radius 2 units.  Horizonal and
vertical arrows are drawn to check that the circle is of the correct
radius; in the first plot, the circle is wrong.  To fix this, I found
that I needed to first set up the plot bounds, using xlim, ylim and
setting asp=1 so that the units are of the same size.  (Below uses the
postscript driver, but I get similar results using x11() device.)

postscript(file="circles.ps")
symbols(x=6, y=6, circles=2, inches=F)
arrows( 6, 6, 8, 6)       #horiz radius, OK
arrows( 6, 6, 6, 8)       #vert  radius, not OK.

## better version, but must set up axes first, and guess ylim
plot(NA, xlim=c(1,10), ylim=c(4,10), asp=1)
symbols(x=6, y=6, circles=2, inches=F, xlim=c(1,10), add=T)
arrows( 6, 6, 8, 6)       #horiz radius, OK
arrows( 6, 6, 6, 8)       #vert  radius, OK.
dev.off()

My suggestion is whether asp can be set within symbols(), such that

  symbols(x=6, y=6, circles=2, inches=F, asp=1)

would then ensure that the circle is drawn correctly.

Thanks, Stephen

> version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    8.1              
year     2003             
month    11               
day      21               
language R

From maechler at stat.math.ethz.ch  Wed Nov 26 13:52:44 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Nov 26 13:51:31 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <16324.27878.740145.101@mithrandir.hornik.net>
References: <17b5svs7cl2cjmto222665p545mb0ok74u@4ax.com>
	<Pine.LNX.4.44.0311250728180.26806-100000@gannet.stats>
	<16324.27878.740145.101@mithrandir.hornik.net>
Message-ID: <16324.41500.528451.479889@gargle.gargle.HOWL>

>>>>> " Kurt" == Kurt Hornik <Kurt.Hornik@wu-wien.ac.at>
>>>>>     on Wed, 26 Nov 2003 10:05:42 +0100 writes:

>>>>> Prof Brian Ripley writes:
    >> On Mon, 24 Nov 2003, Duncan Murdoch wrote:
    >>> >Duncan Murdoch <dmurdoch@pair.com> writes:
    >>> >
    >>> >> Gabor Grothendieck pointed out a bug to me in
    >>> list.files(..., >> full.name=TRUE), that essentially
    >>> comes down to the fact that in >> Windows it's not
    >>> always valid to add a path separator (slash or >>
    >>> backslash) between a path specifier and a filename.  For
    >>> example,
    >>> >> 
    >>> >> c:foo
    >>> >> 
    >>> >> is different from
    >>> >> 
    >>> >> c:\foo
    >>> >> 
    >>> >> and there are other examples.
    >>> 
    >>> I've committed a change to r-patched to fix this in
    >>> Windows only.  Sounds like it's not an issue elsewhere.

    >> I think there are some potential issues with doubling
    >> separators and final separators on dirs.  On Unix file
    >> systems /part1//part2 and /path/to/dir/ are valid.
    >> However, file systems on Unix may not be Unix file
    >> systems: examples are earlier MacOS systems on MacOS X
    >> and mounted Windows and Novell systems on Linux.  I would
    >> not want to assume that all of these combinations worked.

    >>> Gabor also suggested an option to use shell globbing
    >>> instead of regular expressions to select the files in
    >>> the list, e.g.
    >>> 
    >>> list.files(dir="/", pattern="a*.dat", glob=T)
    >>> 
    >>> This would be easy to do in Windows, but from the little
    >>> I know about Unix programming, would not be so easy
    >>> there, so I haven't done anything about it.

    >> It would be shell-dependent and OS-dependent as well as a
    >> retrograde step, as those who wanted to use regular
    >> expressions no longer would be able to.

     Kurt> Right.  In any case, an explicit glob() function
     Kurt> seems preferable to me ...

Good idea!

More than 12 years ago, I had a similar one, and wrote  a
"pat2grep()" {pattern to grep regular expression} function
--- for S-plus on Unix ---  which I have now renamed to  glob2regexp():
-- still not really usable outside unix (or windows with the
'sed' tool in the path), nor perfect, but maybe a good start:

sys <- function(...) system(paste(..., sep = ""))

glob2regexp <- function(pattern)
{
  ## Purpose: Change "ls pattern" to "grep regular expression" pattern.
  ## -------------------------------------------------------------------------
  ## Author: Martin Maechler ETH Zurich, ~ 1991
  sys("echo '", pattern, "'| sed ",
      "'s/\\./\\\\./g;s/*/.*/g;s/?/./g; s/^/^/;s/$/$/; s/\\.\\*\\$$//'")
}

E.g.,

  > glob2regexp("a*.dat")
  ^a.*\.dat$

  > pat2grep("a?bc*.t??")
  ^a.bc.*\.t..$

and one could use it as

     list.files(...., pattern = glob2regexp("a*.dat"))

Of course, the function needs to be changed to simply use things like
sub() and gsub() --- another minor exercise for our audience ...

Martin

From ggrothendieck at myway.com  Wed Nov 26 15:20:37 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed Nov 26 15:19:25 2003
Subject: [Rd] Question about Unix file paths
Message-ID: <20031126142037.D2A3339B3@mprdmxin.myway.com>


> Date: Wed, 26 Nov 2003 10:05:42 +0100 
> From: Kurt Hornik <Kurt.Hornik@wu-wien.ac.at>
> To: Prof Brian Ripley <ripley@stats.ox.ac.uk> 
> Cc: <r-devel@stat.math.ethz.ch>,Duncan Murdoch <dmurdoch@pair.com> 
> Subject: Re: [Rd] Question about Unix file paths 
> 
>  
>  
> >>>>> Prof Brian Ripley writes:
> 
> > On Mon, 24 Nov 2003, Duncan Murdoch wrote:
> >> >Duncan Murdoch <dmurdoch@pair.com> writes:
> >> >
> >> >> Gabor Grothendieck pointed out a bug to me in list.files(...,
> >> >> full.name=TRUE), that essentially comes down to the fact that in
> >> >> Windows it's not always valid to add a path separator (slash or
> >> >> backslash) between a path specifier and a filename. For example,
> >> >> 
> >> >> c:foo
> >> >> 
> >> >> is different from
> >> >> 
> >> >> c:\foo
> >> >> 
> >> >> and there are other examples.
> >> 
> >> I've committed a change to r-patched to fix this in Windows only.
> >> Sounds like it's not an issue elsewhere.
> 
> > I think there are some potential issues with doubling separators and
> > final separators on dirs. On Unix file systems /part1//part2 and
> > /path/to/dir/ are valid. However, file systems on Unix may not be
> > Unix file systems: examples are earlier MacOS systems on MacOS X and
> > mounted Windows and Novell systems on Linux. I would not want to
> > assume that all of these combinations worked.
> 
> >> Gabor also suggested an option to use shell globbing instead of
> >> regular expressions to select the files in the list, e.g.
> >> 
> >> list.files(dir="/", pattern="a*.dat", glob=T)
> >> 
> >> This would be easy to do in Windows, but from the little I know about
> >> Unix programming, would not be so easy there, so I haven't done
> >> anything about it.
> 
> > It would be shell-dependent and OS-dependent as well as a retrograde
> > step, as those who wanted to use regular expressions no longer would
> > be able to.
> 
> Right. In any case, an explicit glob() function seems preferable to
> me ...
> 
> -k

If it were done this way, it would be desirable to combine the dir=
and pattern= args in list.files so that you don't have to specify
the dir= arg twice.  That is:

  list.files(glob("c:/a*.txt""))

rather than

  list.files(pattern=glob("a*.txt", dir="c:/"), > Date: Wed, 26 Nov 2003 10:05:42 +0100 
> From: Kurt Hornik <Kurt.Hornik@wu-wien.ac.at>
> To: Prof Brian Ripley <ripley@stats.ox.ac.uk> 
> Cc: <r-devel@stat.math.ethz.ch>,Duncan Murdoch <dmurdoch@pair.com> 
> Subject: Re: [Rd] Question about Unix file paths 
> 
>  
>  
> >>>>> Prof Brian Ripley writes:
> 
> > On Mon, 24 Nov 2003, Duncan Murdoch wrote:
> >> >Duncan Murdoch <dmurdoch@pair.com> writes:
> >> >
> >> >> Gabor Grothendieck pointed out a bug to me in list.files(...,
> >> >> full.name=TRUE), that essentially comes down to the fact that in
> >> >> Windows it's not always valid to add a path separator (slash or
> >> >> backslash) between a path specifier and a filename. For example,
> >> >> 
> >> >> c:foo
> >> >> 
> >> >> is different from
> >> >> 
> >> >> c:\foo
> >> >> 
> >> >> and there are other examples.
> >> 
> >> I've committed a change to r-patched to fix this in Windows only.
> >> Sounds like it's not an issue elsewhere.
> 
> > I think there are some potential issues with doubling separators and
> > final separators on dirs. On Unix file systems /part1//part2 and
> > /path/to/dir/ are valid. However, file systems on Unix may not be
> > Unix file systems: examples are earlier MacOS systems on MacOS X and
> > mounted Windows and Novell systems on Linux. I would not want to
> > assume that all of these combinations worked.
> 
> >> Gabor also suggested an option to use shell globbing instead of
> >> regular expressions to select the files in the list, e.g.
> >> 
> >> list.files(dir="/", pattern="a*.dat", glob=T)
> >> 
> >> This would be easy to do in Windows, but from the little I know about
> >> Unix programming, would not be so easy there, so I haven't done
> >> anything about it.
> 
> > It would be shell-dependent and OS-dependent as well as a retrograde
> > step, as those who wanted to use regular expressions no longer would
> > be able to.
> 
> Right. In any case, an explicit glob() function seems preferable to
> me ...
> 
> -k

If it were done this way, it would be desirable to combine the dir=
and pattern= args in list.files so that you don't have to specify
the dir= arg twice.  That is:

  list.files( glob("c:/a*.txt"") )

rather than

  list.files( pattern=glob("a*.txt", dir="c:/"), dir="c:/" )

From jwe at bevo.che.wisc.edu  Wed Nov 26 15:36:44 2003
From: jwe at bevo.che.wisc.edu (John W. Eaton)
Date: Wed Nov 26 15:35:43 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <16324.41500.528451.479889@gargle.gargle.HOWL>
References: <17b5svs7cl2cjmto222665p545mb0ok74u@4ax.com>
	<Pine.LNX.4.44.0311250728180.26806-100000@gannet.stats>
	<16324.27878.740145.101@mithrandir.hornik.net>
	<16324.41500.528451.479889@gargle.gargle.HOWL>
Message-ID: <16324.47740.655303.232180@devzero.bogus.domain>

On 26-Nov-2003, Martin Maechler <maechler@stat.math.ethz.ch> wrote:

| >>>>> " Kurt" == Kurt Hornik <Kurt.Hornik@wu-wien.ac.at>
| >>>>>     on Wed, 26 Nov 2003 10:05:42 +0100 writes:
| 
|      Kurt> Right.  In any case, an explicit glob() function
|      Kurt> seems preferable to me ...
| 
| Good idea!
| 
| More than 12 years ago, I had a similar one, and wrote  a
| "pat2grep()" {pattern to grep regular expression} function
| --- for S-plus on Unix ---  which I have now renamed to  glob2regexp():
| -- still not really usable outside unix (or windows with the
| 'sed' tool in the path), nor perfect, but maybe a good start:
| 
| sys <- function(...) system(paste(..., sep = ""))
| 
| glob2regexp <- function(pattern)
| {
|   ## Purpose: Change "ls pattern" to "grep regular expression" pattern.
|   ## -------------------------------------------------------------------------
|   ## Author: Martin Maechler ETH Zurich, ~ 1991
|   sys("echo '", pattern, "'| sed ",
|       "'s/\\./\\\\./g;s/*/.*/g;s/?/./g; s/^/^/;s/$/$/; s/\\.\\*\\$$//'")
| }

It seems to me that using this approach to implement a proper glob()
function would be more work than using the glob code that is available
as part of bash, which I think will allow you to handle much more
complex patterns, including [xyz] {a,b,c} etc.

jwe

From ggrothendieck at myway.com  Wed Nov 26 15:37:45 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed Nov 26 15:36:39 2003
Subject: [Rd] Question about Unix file paths (and proposal for new regexp
	class)
Message-ID: <20031126143745.50C1A39E1@mprdmxin.myway.com>


> Date: Wed, 26 Nov 2003 13:52:44 +0100 
> From: Martin Maechler <maechler@stat.math.ethz.ch>
> To: <Kurt.Hornik@wu-wien.ac.at> 
> Cc: <r-devel@stat.math.ethz.ch> 
> Subject: Re: [Rd] Question about Unix file paths 
> 
>  
>  
> >>>>> " Kurt" == Kurt Hornik <Kurt.Hornik@wu-wien.ac.at>
> >>>>> on Wed, 26 Nov 2003 10:05:42 +0100 writes:
> 
> >>>>> Prof Brian Ripley writes:
> >> On Mon, 24 Nov 2003, Duncan Murdoch wrote:
> >>> >Duncan Murdoch <dmurdoch@pair.com> writes:
> >>> >
> >>> >> Gabor Grothendieck pointed out a bug to me in
> >>> list.files(..., >> full.name=TRUE), that essentially
> >>> comes down to the fact that in >> Windows it's not
> >>> always valid to add a path separator (slash or >>
> >>> backslash) between a path specifier and a filename. For
> >>> example,
> >>> >> 
> >>> >> c:foo
> >>> >> 
> >>> >> is different from
> >>> >> 
> >>> >> c:\foo
> >>> >> 
> >>> >> and there are other examples.
> >>> 
> >>> I've committed a change to r-patched to fix this in
> >>> Windows only. Sounds like it's not an issue elsewhere.
> 
> >> I think there are some potential issues with doubling
> >> separators and final separators on dirs. On Unix file
> >> systems /part1//part2 and /path/to/dir/ are valid.
> >> However, file systems on Unix may not be Unix file
> >> systems: examples are earlier MacOS systems on MacOS X
> >> and mounted Windows and Novell systems on Linux. I would
> >> not want to assume that all of these combinations worked.
> 
> >>> Gabor also suggested an option to use shell globbing
> >>> instead of regular expressions to select the files in
> >>> the list, e.g.
> >>> 
> >>> list.files(dir="/", pattern="a*.dat", glob=T)
> >>> 
> >>> This would be easy to do in Windows, but from the little
> >>> I know about Unix programming, would not be so easy
> >>> there, so I haven't done anything about it.
> 
> >> It would be shell-dependent and OS-dependent as well as a
> >> retrograde step, as those who wanted to use regular
> >> expressions no longer would be able to.
> 
> Kurt> Right. In any case, an explicit glob() function
> Kurt> seems preferable to me ...
> 
> Good idea!
> 
> More than 12 years ago, I had a similar one, and wrote a
> "pat2grep()" {pattern to grep regular expression} function
> --- for S-plus on Unix --- which I have now renamed to glob2regexp():
> -- still not really usable outside unix (or windows with the
> 'sed' tool in the path), nor perfect, but maybe a good start:
> 
> sys <- function(...) system(paste(..., sep = ""))
> 
> glob2regexp <- function(pattern)
> {
> ## Purpose: Change "ls pattern" to "grep regular expression" pattern.
> ## -------------------------------------------------------------------------
> ## Author: Martin Maechler ETH Zurich, ~ 1991
> sys("echo '", pattern, "'| sed ",
> "'s/\\./\\\\./g;s/*/.*/g;s/?/./g; s/^/^/;s/$/$/; s/\\.\\*\\$$//'")
> }
> 
> E.g.,
> 
> > glob2regexp("a*.dat")
> ^a.*\.dat$
> 
> > pat2grep("a?bc*.t??")
> ^a.bc.*\.t..$
> 
> and one could use it as
> 
> list.files(...., pattern = glob2regexp("a*.dat"))
> 
> Of course, the function needs to be changed to simply use things like
> sub() and gsub() --- another minor exercise for our audience ...
> 
> Martin

This is quite nifty.  One advantage is that glob2regexp does not
need to know the directory.

Perhaps what is needed is a regexp class which stores the type of 
regexp in the object itself: basic, extended, perl or glob.  This
would clean up and unify various extra arguments floating around 
in a number of functions.

From kleiweg at let.rug.nl  Wed Nov 26 16:09:34 2003
From: kleiweg at let.rug.nl (Peter Kleiweg)
Date: Wed Nov 26 16:08:21 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <16324.47740.655303.232180@devzero.bogus.domain>
Message-ID: <Pine.LNX.4.44.0311261606270.1114-100000@kleigh.nl>

# aldus John W. Eaton :

> It seems to me that using this approach to implement a proper glob()
> function would be more work than using the glob code that is available
> as part of bash, which I think will allow you to handle much more
> complex patterns, including [xyz] {a,b,c} etc.

Unix people don't need a glob function in R. But a simple glob,
with just '*' and '?', may be all that an average Windows user
can handle, and useful to them.

-- 
Peter Kleiweg

From dmurdoch at pair.com  Wed Nov 26 16:44:35 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed Nov 26 16:43:34 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <16324.27878.740145.101@mithrandir.hornik.net>
References: <17b5svs7cl2cjmto222665p545mb0ok74u@4ax.com>
	<Pine.LNX.4.44.0311250728180.26806-100000@gannet.stats>
	<16324.27878.740145.101@mithrandir.hornik.net>
Message-ID: <mod9svcngi8024l2vt0ii9hd7ld8l4fmgq@4ax.com>

On Wed, 26 Nov 2003 10:05:42 +0100, Kurt Hornik
<Kurt.Hornik@wu-wien.ac.at> wrote :

>>>>>> Prof Brian Ripley writes:
>
>> On Mon, 24 Nov 2003, Duncan Murdoch wrote:
>>> >Duncan Murdoch <dmurdoch@pair.com> writes:

>>> Gabor also suggested an option to use shell globbing instead of
>>> regular expressions to select the files in the list, e.g.
>>> 
>>> list.files(dir="/", pattern="a*.dat", glob=T)
>>> 
>>> This would be easy to do in Windows, but from the little I know about
>>> Unix programming, would not be so easy there, so I haven't done
>>> anything about it.
>
>> It would be shell-dependent and OS-dependent 

Yes, which makes me think it should be part of file.choose() or
choose.files()  (which interact with the user) rather than
list.files(), if it gets implemented at all.  choose.files() already
has this capability, but as far as I know it currently exists only in
Windows.

>>as well as a retrograde
>> step, as those who wanted to use regular expressions no longer would
>> be able to.

I think the proposal was to add another parameter to list.files to
choose the method of wildcarding, so it wouldn't lose anything.

>Right.  In any case, an explicit glob() function seems preferable to
>me ...

We already have list.files() and dir() with exactly the same meaning,
and the closely related choose.files() and file.choose() for user
interaction.    I don't think we want yet another name for something
that's basically the same task.

Duncan Murdoch

From ripley at stats.ox.ac.uk  Wed Nov 26 17:52:09 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Nov 26 17:51:11 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <16324.47740.655303.232180@devzero.bogus.domain>
Message-ID: <Pine.LNX.4.44.0311261651050.14063-100000@gannet.stats>

On Wed, 26 Nov 2003, John W. Eaton wrote:

> On 26-Nov-2003, Martin Maechler <maechler@stat.math.ethz.ch> wrote:
> 
> | >>>>> " Kurt" == Kurt Hornik <Kurt.Hornik@wu-wien.ac.at>
> | >>>>>     on Wed, 26 Nov 2003 10:05:42 +0100 writes:
> | 
> |      Kurt> Right.  In any case, an explicit glob() function
> |      Kurt> seems preferable to me ...
> | 
> | Good idea!
> | 
> | More than 12 years ago, I had a similar one, and wrote  a
> | "pat2grep()" {pattern to grep regular expression} function
> | --- for S-plus on Unix ---  which I have now renamed to  glob2regexp():
> | -- still not really usable outside unix (or windows with the
> | 'sed' tool in the path), nor perfect, but maybe a good start:
> | 
> | sys <- function(...) system(paste(..., sep = ""))
> | 
> | glob2regexp <- function(pattern)
> | {
> |   ## Purpose: Change "ls pattern" to "grep regular expression" pattern.
> |   ## -------------------------------------------------------------------------
> |   ## Author: Martin Maechler ETH Zurich, ~ 1991
> |   sys("echo '", pattern, "'| sed ",
> |       "'s/\\./\\\\./g;s/*/.*/g;s/?/./g; s/^/^/;s/$/$/; s/\\.\\*\\$$//'")
> | }
> 
> It seems to me that using this approach to implement a proper glob()
> function would be more work than using the glob code that is available
> as part of bash, which I think will allow you to handle much more
> complex patterns, including [xyz] {a,b,c} etc.

Or even the glob code from Perl, which is cross-platform.  It is not clear 
to me what we would want glob() to do on Windows, BTW.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Nov 26 18:22:43 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Nov 26 18:29:04 2003
Subject: [Rd] wishlist item: symbols() to accept asp argument? (PR#5328)
In-Reply-To: <20031126122622.E75F2EFCD@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0311261715420.14120-100000@gannet.stats>

It's rather your peculiar example.  If you give more than one circle,
asp=1 is accepted and does work (with warnings).

Symbols is not designed for one symbol (as its name says), and the way it
sets up xlim and ylim in the R code asp=1 does not work for a single
symbol.  In the same way plot(10, asp=1) does not work (and for the same
reason).

That's not to say that it could not be fixed, but the issue is not that
asp does not work with symbols() but rather that plot(10, asp=1) does not 
work.

Arrows is designed to work with vector too ....

On Wed, 26 Nov 2003 stephen@inf.ed.ac.uk wrote:

> Here is a potential wishlist item for adding an argument (asp) to
> symbols().  The following code produces a postscript file with two
> pages; both should show a circle of radius 2 units.  Horizonal and
> vertical arrows are drawn to check that the circle is of the correct
> radius; in the first plot, the circle is wrong.  To fix this, I found
> that I needed to first set up the plot bounds, using xlim, ylim and
> setting asp=1 so that the units are of the same size.  (Below uses the
> postscript driver, but I get similar results using x11() device.)
> 
> postscript(file="circles.ps")
> symbols(x=6, y=6, circles=2, inches=F)
> arrows( 6, 6, 8, 6)       #horiz radius, OK
> arrows( 6, 6, 6, 8)       #vert  radius, not OK.
> 
> ## better version, but must set up axes first, and guess ylim
> plot(NA, xlim=c(1,10), ylim=c(4,10), asp=1)
> symbols(x=6, y=6, circles=2, inches=F, xlim=c(1,10), add=T)
> arrows( 6, 6, 8, 6)       #horiz radius, OK
> arrows( 6, 6, 6, 8)       #vert  radius, OK.
> dev.off()
> 
> My suggestion is whether asp can be set within symbols(), such that
> 
>   symbols(x=6, y=6, circles=2, inches=F, asp=1)
> 
> would then ensure that the circle is drawn correctly.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Nov 26 19:02:12 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Nov 26 19:08:29 2003
Subject: [Rd] wishlist item: symbols() to accept asp argument? (PR#5328)
In-Reply-To: <Pine.LNX.4.44.0311261715420.14120-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0311261755530.14191-100000@gannet.stats>

A variant on the theme:

symbols(x=2, y=6, circles=1, inches=F)

does not show a full circle, so you seem to be assuming incorrectly that
symbols() is including the symbols when calculating the plot region.

On the other hand

symbols(x=6, y=6, circles=2, inches=F, xlim=c(1,10), ylim=c(4,10), asp=1)

*does* work.  There is now way currently to avoid specifying the x-axis 
and y-axis scales.

On Wed, 26 Nov 2003, Prof Brian Ripley wrote:

> It's rather your peculiar example.  If you give more than one circle,
> asp=1 is accepted and does work (with warnings).
> 
> Symbols is not designed for one symbol (as its name says), and the way it
> sets up xlim and ylim in the R code asp=1 does not work for a single
> symbol.  In the same way plot(10, asp=1) does not work (and for the same
> reason).
> 
> That's not to say that it could not be fixed, but the issue is not that
> asp does not work with symbols() but rather that plot(10, asp=1) does not 
> work.
> 
> Arrows is designed to work with vector too ....
> 
> On Wed, 26 Nov 2003 stephen@inf.ed.ac.uk wrote:
> 
> > Here is a potential wishlist item for adding an argument (asp) to
> > symbols().  The following code produces a postscript file with two
> > pages; both should show a circle of radius 2 units.  Horizonal and
> > vertical arrows are drawn to check that the circle is of the correct
> > radius; in the first plot, the circle is wrong.  To fix this, I found
> > that I needed to first set up the plot bounds, using xlim, ylim and
> > setting asp=1 so that the units are of the same size.  (Below uses the
> > postscript driver, but I get similar results using x11() device.)
> > 
> > postscript(file="circles.ps")
> > symbols(x=6, y=6, circles=2, inches=F)
> > arrows( 6, 6, 8, 6)       #horiz radius, OK
> > arrows( 6, 6, 6, 8)       #vert  radius, not OK.
> > 
> > ## better version, but must set up axes first, and guess ylim
> > plot(NA, xlim=c(1,10), ylim=c(4,10), asp=1)
> > symbols(x=6, y=6, circles=2, inches=F, xlim=c(1,10), add=T)
> > arrows( 6, 6, 8, 6)       #horiz radius, OK
> > arrows( 6, 6, 6, 8)       #vert  radius, OK.
> > dev.off()
> > 
> > My suggestion is whether asp can be set within symbols(), such that
> > 
> >   symbols(x=6, y=6, circles=2, inches=F, asp=1)
> > 
> > would then ensure that the circle is drawn correctly.
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Kurt.Hornik at wu-wien.ac.at  Wed Nov 26 19:15:49 2003
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed Nov 26 19:17:50 2003
Subject: [Rd] R-1.8.0 package directory permissions?
In-Reply-To: <3FC20895.6050005@lancs.ac.uk>
References: <3FC20895.6050005@lancs.ac.uk>
Message-ID: <16324.60885.890860.819806@mithrandir.hornik.net>

>>>>> Pingping Zheng writes:

> Hello,

> I maintain a self-made R package under my own home directory
> "~/.R/library" on our university computer net (SunOS 5.8 system).
> After updating R to 1.8.0, I found other people cannot access my
> package any more. They got this error message:

> Error in library(tb, lib.loc = "/home/fs.hpc/43/zhengp1/.R/library") : 

> This is not a valid package -- no DESCRIPTION exists

> I set my home directory permissions as "drwx--x--x", the R packages
> directories, from "/home/fs.hpc/43/zhengp1/.R" and its subdirectories
> as "drwxr-xr-x". It worked well before.

> However, when I change my home directory permissions to
> "drwxr-xr-x", giving "read" and  "execute" permissions
> to everyone, no error message appeared any more.

> Is that a bug in new version of R-1.8.0?

What you get comes seems to come from file.exists() saying that the
candidate DESCRIPTION file does not exist.  I cannot reproduce this
problem on Linux.  I don't see how the 711 setting could affect
file.exists() for the owner of the files, though.

-k

From ggrothendieck at myway.com  Wed Nov 26 19:30:56 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed Nov 26 19:31:13 2003
Subject: [Rd] Question about Unix file paths
Message-ID: <20031126183056.776FF39C6@mprdmxin.myway.com>


> 
> 
> --- 
> Date: Wed, 26 Nov 2003 16:52:09 +0000 (GMT) 
> From: Prof Brian Ripley <ripley@stats.ox.ac.uk>
> To: John W. Eaton <jwe@bevo.che.wisc.edu> 
> Cc: <Kurt.Hornik@wu-wien.ac.at>,Martin Maechler <maechler@stat.math.ethz.ch>, <r-devel@stat.math.ethz.ch> 
> Subject: Re: [Rd] Question about Unix file paths 
> 
>  
>  
> On Wed, 26 Nov 2003, John W. Eaton wrote:
> 
> > On 26-Nov-2003, Martin Maechler <maechler@stat.math.ethz.ch> wrote:
> > 
> > | >>>>> " Kurt" == Kurt Hornik <Kurt.Hornik@wu-wien.ac.at>
> > | >>>>> on Wed, 26 Nov 2003 10:05:42 +0100 writes:
> > | 
> > | Kurt> Right. In any case, an explicit glob() function
> > | Kurt> seems preferable to me ...
> > | 
> > | Good idea!
> > | 
> > | More than 12 years ago, I had a similar one, and wrote a
> > | "pat2grep()" {pattern to grep regular expression} function
> > | --- for S-plus on Unix --- which I have now renamed to glob2regexp():
> > | -- still not really usable outside unix (or windows with the
> > | 'sed' tool in the path), nor perfect, but maybe a good start:
> > | 
> > | sys <- function(...) system(paste(..., sep = ""))
> > | 
> > | glob2regexp <- function(pattern)
> > | {
> > | ## Purpose: Change "ls pattern" to "grep regular expression" pattern.
> > | ## -------------------------------------------------------------------------
> > | ## Author: Martin Maechler ETH Zurich, ~ 1991
> > | sys("echo '", pattern, "'| sed ",
> > | "'s/\\./\\\\./g;s/*/.*/g;s/?/./g; s/^/^/;s/$/$/; s/\\.\\*\\$$//'")
> > | }
> > 
> > It seems to me that using this approach to implement a proper glob()
> > function would be more work than using the glob code that is available
> > as part of bash, which I think will allow you to handle much more
> > complex patterns, including [xyz] {a,b,c} etc.
> 
> Or even the glob code from Perl, which is cross-platform. It is not clear 
> to me what we would want glob() to do on Windows, BTW.
> 
> -- 
> Brian D. Ripley, ripley@stats.ox.ac.uk

It would work similarly to:

	readLines(pipe("cmd /c dir/b a*.dat"))

If the question is what would it be used for then I have a number
of data files with nearly the same name and want the most recent.

I started out using list.files but found the pattern matching
less natural when it comes to files than file globbing so I changed
this to use the above.  After that I use file.info to find out which
is the most recent and then read in that.

From andy_liaw at merck.com  Wed Nov 26 20:38:39 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed Nov 26 20:38:47 2003
Subject: [Rd] RE: 64-bit R on Opteron [was Re: [R] Windows R 1.8.0 hangs when
 M	em Usage >1.8GB]
Message-ID: <3A822319EB35174CA3714066D590DCD50205CEB1@usrymx25.merck.com>

> From: Douglas Bates
>
> How does the Opteron perform on floating point?  Can you try something
> like
> 
> > mm = matrix(rnorm(1e6), nc = 1e3)
> > system.time(crossprod(mm))
> [1] 0.51 0.02 0.53 0.00 0.00
> > system.time(crossprod(mm))
> [1] 0.37 0.03 0.40 0.00 0.00
> > system.time(crossprod(mm))
> [1] 0.38 0.02 0.40 0.00 0.00
> > system.time(crossprod(mm))
> [1] 0.38 0.02 0.40 0.00 0.00
> 
> (That was with R compiled to use Goto's BLAS on a 2.0 GHz P4.)
> 
> Are you using Goto's BLAS or Atlas?

I managed to link R against Goto's BLAS for Opteron (see below).  The result
looks like:

> mm = matrix(rnorm(1e6), nc = 1e3)
> system.time(crossprod(mm))
[1] 0.5 0.0 0.5 0.0 0.0
> system.time(crossprod(mm))
[1] 0.39 0.00 0.39 0.00 0.00
> system.time(crossprod(mm))
[1] 0.39 0.01 0.39 0.00 0.00

On the dual 2.4GHz Xeon (using libgoto_p3_512-r0.6.so), I get:

> mm = matrix(rnorm(1e6), nc=1e3)
> system.time(crossprod(mm))
[1] 0.91 0.01 0.93 0.00 0.00
> system.time(crossprod(mm))
[1] 0.82 0.02 0.84 0.00 0.00
> system.time(crossprod(mm))
[1] 0.83 0.02 0.85 0.00 0.00

We have not found the Opteron to be faster than the Xeon, but the Xeon does
have faster RAM...

[What I did to link R against Goto's BLAS (mostly following Prof. Bates'
instruction): 
- Install libgoto*.so and symlink to libgoto.so.
- Download xerbla.f and compile to xerbla.o.
- Run the R configure script with --with-blas="-lgoto /path/to/xerbla.o".
- Edit Makeconf and delete the path to xerbla.o in BLAS_LIB.
- make; make check
]

A bit of gripe about the SUSE ES8 that was pre-loaded on the Opteron:
- VNC segfault out-of-box.  Needed to purchase maintanence contract to get
update that fixed it.
- No teTeX, so can't build R manuals in pdf.
- No XEmacs (but does have GNU Emacs).

Best,
Andy

From ripley at stats.ox.ac.uk  Wed Nov 26 21:27:56 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed Nov 26 21:27:44 2003
Subject: [Rd] Power (^) 10x slower in R since version 1.7.1... What next?
	[Windows platform]
In-Reply-To: <MABBLJDICACNFOLGIHJOIEPIDOAA.phgrosjean@sciviews.org>
Message-ID: <Pine.WNT.4.44.0311262023290.476-101000@petrel>

You might like to test the enclosed.  Drop the file into .../src/gnuwin32
and edit the following line in Makefile there

OBJS = $(SOURCES:.c=.o) e_pow.o
                       ^^^^^^^^
Then re-make.  This uses an existing solution, that from glibc (which MinGW
will not want to use for licence reasons).  It's very fast and seems
as accurate.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
From dmurdoch at pair.com  Thu Nov 27 05:41:48 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu Nov 27 05:40:30 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <Pine.LNX.4.44.0311261606270.1114-100000@kleigh.nl>
References: <16324.47740.655303.232180@devzero.bogus.domain>
	<Pine.LNX.4.44.0311261606270.1114-100000@kleigh.nl>
Message-ID: <7tvasvcoumn074jpg31pr9enp6nr278dq2@4ax.com>

On Wed, 26 Nov 2003 16:09:34 +0100 (CET), you wrote:

># aldus John W. Eaton :
>
>> It seems to me that using this approach to implement a proper glob()
>> function would be more work than using the glob code that is available
>> as part of bash, which I think will allow you to handle much more
>> complex patterns, including [xyz] {a,b,c} etc.
>
>Unix people don't need a glob function in R. But a simple glob,
>with just '*' and '?', may be all that an average Windows user
>can handle, and useful to them.

We already have that, in choose.files().  It's interactive; maybe it
should have a non-interactive option.

I don't think we should add another pattern matching syntax to R.
Filename pattern matching is a job for the shell or the OS.

Duncan Murdoch

From bellis at hsph.harvard.edu  Thu Nov 27 05:46:29 2003
From: bellis at hsph.harvard.edu (bellis@hsph.harvard.edu)
Date: Thu Nov 27 05:45:11 2003
Subject: [Rd] R CMD CHECK doesn't allow --configure-args (PR#5344)
Message-ID: <20031127044629.52F70EDE9@slim.kubism.ku.dk>

Full_Name: Byron Ellis
Version: R-devel
OS: Mac OS X
Submission from: (NULL) (24.10.67.29)


Unline R CMD INSTALL, R CMD CHECK does not allow --configure-args to be passed.
This is unfortunate as R CMD CHECK attempts to build the package, running any
configure scripts that may be around thus failing on platforms that require
configuration arguments to build properly.

From dmurdoch at pair.com  Thu Nov 27 06:13:16 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu Nov 27 06:11:55 2003
Subject: [Rd] Trap to debugger while running R in Windows
Message-ID: <jh1bsvk5i9lhf5119crhltjth65fj0inmb@4ax.com>

When debugging C or Fortran code in R, it's helpful to run R under a
debugger.  I use Insight, which is a wrapper for gdb.

One problem is that in Windows hitting break doesn't cause a trap to
gdb, so it can be hard to stop the process.

I've added a menu item to the r-devel version of Rgui (Misc|Break to
debugger) which triggers a trap to the external debugger.

Unfortunately, choosing this menu item crashes R if you're *not*
running under a debugger, so I haven't made it easy to see:  you need
to compile src/gnuwin32/rui.c with DEBUG=T in order to get it.

If anyone knows of code that traps to a debugger when one is present,
and is safely run when one is not, please let me know.

Duncan Murdoch

From phgrosjean at sciviews.org  Thu Nov 27 13:30:46 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu Nov 27 13:30:14 2003
Subject: [Rd] Power (^) 10x slower in R since version 1.7.1... What
	next?[Windows platform]
In-Reply-To: <Pine.WNT.4.44.0311262023290.476-101000@petrel>
Message-ID: <MABBLJDICACNFOLGIHJOIEGHDPAA.phgrosjean@sciviews.org>

Prof. Brian Ripley wrote:
>You might like to test the enclosed.  Drop the file into .../src/gnuwin32
>and edit the following line in Makefile there

>OBJS = $(SOURCES:.c=.o) e_pow.o
>                       ^^^^^^^^
>Then re-make.  This uses an existing solution, that from glibc (which MinGW
>will not want to use for licence reasons).  It's very fast and seems
>as accurate.

It is very fast! Thank you. This solves my problem!
By the way, will this patch be incorporated in the next official release of
R?
Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       Numerical Ecology Laboratory
 ) ) ) ) )      Mons-Hainaut University
( ( ( ( (       8, Av. du Champ de Mars, 7000 Mons
 ) ) ) ) )      Belgium
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean@sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................

From ripley at stats.ox.ac.uk  Thu Nov 27 14:00:06 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Nov 27 13:58:47 2003
Subject: [Rd] Power (^) 10x slower in R since version 1.7.1... What
	next?[Windows platform]
In-Reply-To: <MABBLJDICACNFOLGIHJOIEGHDPAA.phgrosjean@sciviews.org>
Message-ID: <Pine.LNX.4.44.0311271258350.27955-100000@gannet.stats>

On Thu, 27 Nov 2003, Philippe Grosjean wrote:

> Prof. Brian Ripley wrote:
> >You might like to test the enclosed.  Drop the file into .../src/gnuwin32
> >and edit the following line in Makefile there
> 
> >OBJS = $(SOURCES:.c=.o) e_pow.o
> >                       ^^^^^^^^
> >Then re-make.  This uses an existing solution, that from glibc (which MinGW
> >will not want to use for licence reasons).  It's very fast and seems
> >as accurate.
> 
> It is very fast! Thank you. This solves my problem!
> By the way, will this patch be incorporated in the next official release of
> R?

Not unless MinGW has not replaced pow in the meantime (which we expect to 
happen).

My Windows mailer added a binary attachment, so if any other list members 
want this, it is at

http://www.stats.ox.ac.uk/pub/RWin/e_pow_S

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ggrothendieck at myway.com  Thu Nov 27 15:39:16 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu Nov 27 15:38:00 2003
Subject: [Rd] Question about Unix file paths
Message-ID: <20031127143916.A2BFB39F4@mprdmxin.myway.com>


> On Wed, 26 Nov 2003 16:09:34 +0100 (CET), you wrote:
> 
> ># aldus John W. Eaton :
> >
> >> It seems to me that using this approach to implement a proper glob()
> >> function would be more work than using the glob code that is available
> >> as part of bash, which I think will allow you to handle much more
> >> complex patterns, including [xyz] {a,b,c} etc.
> >
> >Unix people don't need a glob function in R. But a simple glob,
> >with just '*' and '?', may be all that an average Windows user
> >can handle, and useful to them.
> 
> We already have that, in choose.files(). It's interactive; maybe it
> should have a non-interactive option.
> 
> I don't think we should add another pattern matching syntax to R.
> Filename pattern matching is a job for the shell or the OS.
> 
> Duncan Murdoch


Its not done by the shell in Windows, VAX/VMS
and probably a number of other systems.  

Also, I found it surprising tough in any
short obvious way as the Windows dir commands 
will not handle this directly if you need full 
pathnames to be returned.  In Windows:

- the dir command will not return the complete
  pathname, only the filename (unless you use the
  /s flag but then it recursively descends the
  directory tree which is not what I want)

- the dir command will not accept /'s which means
  I have to do the conversion to backslashes
  myself.  (I prefer to specify /'s so that I
  don't have to use double backslashes which R
  requires since \ is also the string escape
  character.)

I spent some time on this and think that I now
have a solution that works pretty well and is
short but involves a trick that was not immediately 
obvious.  This trick was to use the Windows attrib 
command as it instead of the dir command.  attrib
does return complete pathnames.  It even handles
forward slash specifiers.  

The first line in the body of the function
executes the attrib command, the second line
closes the pipe and the third line checks whether
anything was found and, if so, strips off the
stuff before the pathname.


# tested on Windows 2000
list.files.glob <- function( spec ) {
   z <- readLines( con <- pipe( paste( "cmd /c attrib", spec ) ) )
   close( con )
   if ( !pmatch("File not found - ", z[[1]], nomatch = 0) )  substring(z,12)
}

# a couple of examples:
list.files.glob( "c:/myfolder/my*.dat" )
list.files.glob( "c:\\myfolder\\my*.dat" )

From Kurt.Hornik at wu-wien.ac.at  Thu Nov 27 17:06:09 2003
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu Nov 27 17:08:00 2003
Subject: [Rd] R CMD CHECK doesn't allow --configure-args (PR#5344)
In-Reply-To: <20031127044629.52F70EDE9@slim.kubism.ku.dk>
References: <20031127044629.52F70EDE9@slim.kubism.ku.dk>
Message-ID: <16326.8433.535262.783646@mithrandir.hornik.net>

>>>>> bellis  writes:

> Full_Name: Byron Ellis
> Version: R-devel
> OS: Mac OS X
> Submission from: (NULL) (24.10.67.29)

> Unline R CMD INSTALL, R CMD CHECK does not allow --configure-args to
> be passed.  This is unfortunate as R CMD CHECK attempts to build the
> package, running any configure scripts that may be around thus failing
> on platforms that require configuration arguments to build properly.

You can always get by via something like

	R CMD INSTALL --configure-args=XXX -l pkg.Rcheck pkg
	R CMD check --install=skip pkg

The reason why we don't have a way of specifying arguments to install
when checking is mostly to be defensive about possible quoting issues
when passing arguments from the command line via Perl to the Shell.

-k

From dmurdoch at pair.com  Thu Nov 27 17:45:45 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu Nov 27 17:43:51 2003
Subject: [Rd] Question about Unix file paths
In-Reply-To: <20031127143916.A2BFB39F4@mprdmxin.myway.com>
References: <20031127143916.A2BFB39F4@mprdmxin.myway.com>
Message-ID: <o2acsv0a7hrnv0hfvvl6jf6r0lr8ojgark@4ax.com>

On Thu, 27 Nov 2003 09:39:16 -0500 (EST), "Gabor Grothendieck"
<ggrothendieck@myway.com> wrote :

>> 
>> I don't think we should add another pattern matching syntax to R.
>> Filename pattern matching is a job for the shell or the OS.
>> 
>> Duncan Murdoch
>
>
>Its not done by the shell in Windows, VAX/VMS
>and probably a number of other systems.  

In Windows it's an OS function, through the FindFirstFile and
FindNextFile API functions.  This has the advantage that wildcards
behave the same in all programs, and the disadvantage of a lack of
flexibility.

In R choose.files() uses this facility indirectly, in that it goes
through the shell file dialog functions.  We could make it go directly
to the API functions, but I don't see it as a high priority:
list.files() works fine in programs (and is portable across OS's and
shells), and choose.files() is fine for interactive use.

The only thing I'd suggest is that Unix systems should have their own
choose.files() function, designed to use whatever interactive file
selection mechanism is native to their own platform.

Duncan Murdoch

From ggrothendieck at myway.com  Thu Nov 27 18:20:22 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu Nov 27 18:19:16 2003
Subject: [Rd] RE: problem with pipes (PR#5053)
Message-ID: <20031127172022.6C0353986@mprdmxin.myway.com>



I am assuming this is related to the bug report I previously
submitted; however, this time I am getting different behavior
so I thought it might be helpful just in case this gives a clue.

On Windows 2000 the following code crashes R:

> z <- readLines(con <- pipe("cmd /c attrib c:/a*.txt"))
> z
[1] "¬A          C:\\addr.txt~" "A          C:\\a.awk.txt" 
[3] "A          C:\\a.txt~"    
> close(con)

It crashes when I issue the close command.  What happens specifically
is that a window pops up saying "Rgui has generated errors and
with be closed by windows".    R then shuts down.

I am using Windows 2000 and R 1.8.1.

From pbtud at yahoo.com  Thu Nov 27 18:43:24 2003
From: pbtud at yahoo.com (pbtud@yahoo.com)
Date: Thu Nov 27 18:42:08 2003
Subject: [Rd] ks.test (PR#5360)
Message-ID: <20031127174324.8EFCDEDF5@slim.kubism.ku.dk>

Full_Name: Pieter Ober
Version: 1.8
OS: win 2000
Submission from: (NULL) (62.166.32.225)


In ks.test, the names of the test statistics that are returned (D^-) and (D^+)
seem to correspond to the test statistics (T+) and (T-) in the Conover reference
(I use the 2d edition of the book) and are thus reversed - this is slightly
confusing!

From sergei at stams.strath.ac.uk  Fri Nov 28 13:39:43 2003
From: sergei at stams.strath.ac.uk (sergei@stams.strath.ac.uk)
Date: Fri Nov 28 13:38:20 2003
Subject: [Rd] search documentation not working with mozilla and konqueror
	(PR#5379)
Message-ID: <20031128123943.233A7FB8A@slim.kubism.ku.dk>

Full_Name: Sergei Zuyev
Version: Version 1.8.0
OS: Mandrake Linux 9.1
Submission from: (NULL) (195.137.88.252)


When mozilla or konqueror are used as help browser, the Search Engine page links
nor the search do not work. Mozilla quietly ignores any click, while konqueror
gives the following information:

> options(browser="/usr/bin/konqueror")
> help.start()
Making links in per-session dir ...
If /usr/bin/konqueror is already running, it is *not* restarted, and
    you must switch to its window.
Otherwise, be patient ...
> konqueror: Unknown parameter '-remote'.

And this is what gets generated when attempting a link or a search:

khtml (jscript): WARNING: Script threw exception: TypeError: Expression is no
object. Cannot b                  e called.

I have also tried netscape 4.71 which I had to manually install as it is not
included in the distro, and everything works just fine.

From MSchwartz at medanalytics.com  Fri Nov 28 16:43:28 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri Nov 28 16:43:47 2003
Subject: [Rd] search documentation not working with mozilla and
	konqueror (PR#5379)
In-Reply-To: <20031128123943.233A7FB8A@slim.kubism.ku.dk>
References: <20031128123943.233A7FB8A@slim.kubism.ku.dk>
Message-ID: <1070034208.2577.34.camel@localhost.localdomain>

On Fri, 2003-11-28 at 06:39, sergei@stams.strath.ac.uk wrote:
> Full_Name: Sergei Zuyev
> Version: Version 1.8.0
> OS: Mandrake Linux 9.1
> Submission from: (NULL) (195.137.88.252)
> 
> 
> When mozilla or konqueror are used as help browser, the Search Engine page links
> nor the search do not work. Mozilla quietly ignores any click, while konqueror
> gives the following information:
> 
> > options(browser="/usr/bin/konqueror")
> > help.start()
> Making links in per-session dir ...
> If /usr/bin/konqueror is already running, it is *not* restarted, and
>     you must switch to its window.
> Otherwise, be patient ...
> > konqueror: Unknown parameter '-remote'.
> 
> And this is what gets generated when attempting a link or a search:
> 
> khtml (jscript): WARNING: Script threw exception: TypeError: Expression is no
> object. Cannot b                  e called.
> 
> I have also tried netscape 4.71 which I had to manually install as it is not
> included in the distro, and everything works just fine.


This is not a bug. It is the result of not have Java properly configured
on your system for each browser. This typically involves creating a
symlink in the browser plug-in directory to the appropriate Java binary.

Here are some links for more information:

http://www.java.com/en/download/help/enable_browser.jsp

http://www.mozilla.org/releases/mozilla1.5/installation-extras.html

http://www.kde.org/documentation/faq/filemanager.html#id2912264

The key with the help.start() search engine is to have Java properly
installed and configured on your system and to have BOTH Java AND
JavaScript enabled in the respective browser's settings.

HTH,

Marc Schwartz

From MSchwartz at medanalytics.com  Fri Nov 28 16:43:31 2003
From: MSchwartz at medanalytics.com (MSchwartz@medanalytics.com)
Date: Fri Nov 28 16:44:03 2003
Subject: [Rd] search documentation not working with mozilla and (PR#5383)
Message-ID: <20031128154331.F3BDBFB8A@slim.kubism.ku.dk>

On Fri, 2003-11-28 at 06:39, sergei@stams.strath.ac.uk wrote:
> Full_Name: Sergei Zuyev
> Version: Version 1.8.0
> OS: Mandrake Linux 9.1
> Submission from: (NULL) (195.137.88.252)
> 
> 
> When mozilla or konqueror are used as help browser, the Search Engine page links
> nor the search do not work. Mozilla quietly ignores any click, while konqueror
> gives the following information:
> 
> > options(browser="/usr/bin/konqueror")
> > help.start()
> Making links in per-session dir ...
> If /usr/bin/konqueror is already running, it is *not* restarted, and
>     you must switch to its window.
> Otherwise, be patient ...
> > konqueror: Unknown parameter '-remote'.
> 
> And this is what gets generated when attempting a link or a search:
> 
> khtml (jscript): WARNING: Script threw exception: TypeError: Expression is no
> object. Cannot b                  e called.
> 
> I have also tried netscape 4.71 which I had to manually install as it is not
> included in the distro, and everything works just fine.


This is not a bug. It is the result of not have Java properly configured
on your system for each browser. This typically involves creating a
symlink in the browser plug-in directory to the appropriate Java binary.

Here are some links for more information:

http://www.java.com/en/download/help/enable_browser.jsp

http://www.mozilla.org/releases/mozilla1.5/installation-extras.html

http://www.kde.org/documentation/faq/filemanager.html#id2912264

The key with the help.start() search engine is to have Java properly
installed and configured on your system and to have BOTH Java AND
JavaScript enabled in the respective browser's settings.

HTH,

Marc Schwartz

From thoffman at zappa.sax.de  Fri Nov 28 20:31:12 2003
From: thoffman at zappa.sax.de (thoffman@zappa.sax.de)
Date: Fri Nov 28 20:29:49 2003
Subject: [Rd] Documentation bug in src/library/base/man/unix/BATCH.Rd
	(PR#5386)
Message-ID: <20031128193112.1BB34FB98@slim.kubism.ku.dk>

Full_Name: Thomas Hoffmann
Version: 1.8.1
OS: OS/2 4.52, Linux (Suse 9.0)
Submission from: (NULL) (80.243.41.158)


There is simply a bracket missing: "make check-devel" reports this correctly.
The wrong paragraph is:

 \item{options}{a list of \R command line options, e.g., for setting the
    amount of memory available and controlling the load/save process.
    If \code{infile} starts with a \samp{-}, use \samp{--} as the final
    option.  The default options are \samp{--restore --save --no-readline}.

==> There should be another closing bracket at the end of the last line: 

...    option.  The default options are \samp{--restore --save --no-readline}.}

From ripley at stats.ox.ac.uk  Fri Nov 28 21:11:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Nov 28 21:10:19 2003
Subject: (PR#5386) [Rd] Documentation bug in
	src/library/base/man/unix/BATCH.Rd (PR#5386)
In-Reply-To: <20031128193112.1BB34FB98@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0311282010110.1598-100000@gannet.stats>

This is already fixed in R-patched!
Please do check before filing a bug report.

On Fri, 28 Nov 2003 thoffman@zappa.sax.de wrote:

> Full_Name: Thomas Hoffmann
> Version: 1.8.1
> OS: OS/2 4.52, Linux (Suse 9.0)
> Submission from: (NULL) (80.243.41.158)
> 
> 
> There is simply a bracket missing: "make check-devel" reports this correctly.
> The wrong paragraph is:
> 
>  \item{options}{a list of \R command line options, e.g., for setting the
>     amount of memory available and controlling the load/save process.
>     If \code{infile} starts with a \samp{-}, use \samp{--} as the final
>     option.  The default options are \samp{--restore --save --no-readline}.
> 
> ==> There should be another closing bracket at the end of the last line: 
> 
> ...    option.  The default options are \samp{--restore --save --no-readline}.}

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From agandy at mathematik.uni-ulm.de  Sat Nov 29 17:42:20 2003
From: agandy at mathematik.uni-ulm.de (agandy@mathematik.uni-ulm.de)
Date: Sat Nov 29 17:40:55 2003
Subject: [Rd] library stepfun seems to have a problem (PR#5405)
Message-ID: <20031129164220.8B195F306@slim.kubism.ku.dk>

Full_Name: Axel Gandy
Version: 1.8.0
OS: i386-pc-mingw32 (windows)
Submission from: (NULL) (62.224.34.136)


The following code results in a crash of R:
library(stepfun)
stepfun(c(), c(1))(2)

From dj at research.bell-labs.com  Sat Nov 29 20:44:30 2003
From: dj at research.bell-labs.com (David James)
Date: Sat Nov 29 20:43:39 2003
Subject: [Rd] wish list: default row.names in data.frame()
Message-ID: <20031129144430.A9462@jessie.research.bell-labs.com>

Hi,

Consider the row.names of

   a <- data.frame(x = runif(150000))
   > row.names(a)[99998:100002]
   [1] "99998"  "99999"  "1e+05"  "100001" "100002"

not wrong, but there's room for improvement.  If we replace the
expression 

   if (length(row.names) == 0)
        row.names <- seq(length = nr)

which creates a non-integer object row.names by

   if (length(row.names) == 0)
        row.names <- if(nr>0) 1:nr else integer(0) 

(or something to that effect) to create an integer row.names
that when coerced to character will produce

   b <- data.frame(x = runif(150000))
   > row.names(b)[99998:100002]
   [1] "99998"  "99999"  "100000" "100001" "100002"

These labels have a more uniform format.  

Could a change like this be made to data.frame()?

Regards,

-- 
David 

> version
_
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    8.1
year     2003
month    11
day      21
language R

From pburns at pburns.seanet.com  Sat Nov 29 22:08:18 2003
From: pburns at pburns.seanet.com (pburns@pburns.seanet.com)
Date: Sat Nov 29 22:06:57 2003
Subject: [Rd] eigen of matrix of Inf hangs (PR#5406)
Message-ID: <20031129210818.DAB9FF306@slim.kubism.ku.dk>

Full_Name: Patrick Burns
Version: 1.8.1
OS: Windows 2000
Submission from: (NULL) (81.129.3.151)


The command:

eigen(matrix(Inf, 2, 2))

causes version 1.8.1 to hang in both Windows 2000 and SuSe 8.2.
(Hang defined as apparently needing to kill the process in order
to get a prompt back.)


This is similar to bug #4366 where the same command used NaN
instead of Inf.

From Simon.Urbanek at math.uni-augsburg.de  Sun Nov 30 01:45:16 2003
From: Simon.Urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Sun Nov 30 01:43:59 2003
Subject: [Rd] R as OS X Framework
Message-ID: <76FE7CAA-22CE-11D8-9485-0003938AF008@math.uni-augsburg.de>

After the recent discussion about future direction of the Mac OS X 
port, I was toying with the idea to make R a proper Mac OS X framework. 
There are several advantages: OS X locates frameworks automatically, 
therefore any program wishing to link against R has only to specify 
"-framework R" at link time. Furthermore versioning is supported, i.e. 
if a program is linked against R 1.7.1 and you install 1.9.0 later, 
then the program will still get the correct 1.7.1 version (if we define 
the 1.9.0 not to be compatible with 1.7.1), but any new program will 
link against the most recent R. The granularity is up the framework 
creator.

It is possible to easily create a R Framework just with the current R 
as follows:

configure your favorite R (I'll use 1.8.1 for illustration) but use the 
following prefix:
--prefix=/Library/Frameworks/R.framework/Versions/1.8.1/Resources
you should also add --enable-R-shlib (if you want to use --enable-aqua, 
read on first!)

after make / make install run the following script as root (you may 
want to edit it if you didin't use 1.8.1 or if you want to install an 
user-private framework):

http://stats.math.uni-augsburg.de/misc/Rframework.sh

This will create a proper framework from what the R installer created - 
and you're all set! You can use such framework for any program - just 
like Apple's system frameworks. It's really great what you can do with 
Xcode then (code completion of R stuff, zero-linking etc ;)). For a 
screenshot of Xcode using R framework, see:
http://stats.math.uni-augsburg.de/misc/Rframework.png

You can even make a symlink from 
/Library/Frameworks/R.framework/Resources/bin/R to /usr/binR and you 
will have the most recent R always at your fingertips.

The nice thing is that you can use ~/Library/Frameworks instead of the 
above /Library/Frameworks if you want. There is no difference from 
system's point of view. You could event supply the R framework inside 
you application's bundle, but I guess that'd be an overkill ;)

Now for some issues that need to be solved:

The current R needs R_HOME to be set before using it even in its 
embedded form. Now this defeats the idea of location independence of 
the framework. The application doesn't have to care whether the 
framework is in /Library/Frameworks, ~/Library/Frameworks or any 
user-defined framework location. Therefore it would be nice to have a 
tiny function in the R shlib, that would tell me where the shlib lives 
(either by using system's API to determine its own location, or at 
least the path used on installation).

BTW: This is not Mac specific - I was fighting this on Windows (and 
unix for that matter) as well - it is possible to run an .exe linked to 
R.dll from anywhere, if R.dll is in the PATH. But then, one has to 
determine R_HOME somehow (yes, there is the registry, but that's not 
really safe if more R versions are installed).

The second issue is a rather minor one which will be solved if RAqua 
uses the framework. If you used --enable-aqua then configure overrides 
the dylib location, which is bad for our framework:
configure.ac @ 1050:
    if test "x${want_aqua}" = xyes; then
       LIBR_LDFLAGS="-dynamiclib -install_name 
/Applications/StartR.app/RAqua.app/Contents/Frameworks/libR.dylib"
     else
       LIBR_LDFLAGS="-dynamiclib -install_name 
\$(Rexeclibdir)/libR.dylib"
     fi
You'll need to remove the aqua part of it, otherwise the libR.dylib is 
not expected inside the framework.

Finally, in order to take advantage of the versioning, we should add 
version information to the dylib. This can be done by adding  
-dylib_compatibility_version and  -dylib_current_version to the 
LIBR_LDFLAGS (e.g. for R-1.8.1 probably 1.8.0 to compatibility and 
1.8.1 to current).

BTW: A side note - if the host application runs a proper event loop 
(like my Rgui runs the standard Cocoa event loop) then the Quartz 
device works flawlessly even without RAqua! Good job, Stefano!

There is still room for improvement - I started this more as a proof of 
concept and was surprised how smoothly it went. Someone interested 
might look into issues like using Tcl/Tk, placing libraries 
conveniently (in ~/Library/Application Support/R/library ?) etc.

---
Simon Urbanek
Department of computer oriented statistics and data analysis
Universit?tsstr. 14
86135 Augsburg
Germany

Tel: +49-821-598-2236
Fax: +49-821-598-2280

Simon.Urbanek@Math.Uni-Augsburg.de
http://simon.urbanek.info

From deleeuw at stat.ucla.edu  Sun Nov 30 06:32:49 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sun Nov 30 06:33:42 2003
Subject: [Rd] Re: [R-SIG-Mac] R as OS X Framework
In-Reply-To: <76FE7CAA-22CE-11D8-9485-0003938AF008@math.uni-augsburg.de>
References: <76FE7CAA-22CE-11D8-9485-0003938AF008@math.uni-augsburg.de>
Message-ID: <A29067C8-22F6-11D8-B34D-000A95A67E82@stat.ucla.edu>

This is a major step in the right direction. I know that Duncan has at  
least
the beginning of an R bridge to the Cocoa toolkits, which would be the
second major step. It will make it possible to write stand-alone R based
applications with a Cocoa GUI, of which R.app will just be a major  
example,
but of which Rglm.app or Rcluster.app could be other examples (with
problem specific menus and graphics). And these could all be developed
nicely by having a Xcode plugin for R. These steps emphasize the  
strengths
of OS X (as the quartz device already does) and do not just give another
boring shell around the command line interpreter. Getting away from  
Carbon
in this way is important, and you don't have to learn Objective C to
program in Cocoa.

By the way, as another example, the quartz device works fine from
Rpy running in one of the Python or wxPython GUI's (which have
decent eventloops). See the desktops at gifi.stat.ucla.edu/pub.

On Nov 29, 2003, at 16:45, Simon Urbanek wrote:

> After the recent discussion about future direction of the Mac OS X  
> port, I was toying with the idea to make R a proper Mac OS X  
> framework. There are several advantages: OS X locates frameworks  
> automatically, therefore any program wishing to link against R has  
> only to specify "-framework R" at link time. Furthermore versioning is  
> supported, i.e. if a program is linked against R 1.7.1 and you install  
> 1.9.0 later, then the program will still get the correct 1.7.1 version  
> (if we define the 1.9.0 not to be compatible with 1.7.1), but any new  
> program will link against the most recent R. The granularity is up the  
> framework creator.
>
> It is possible to easily create a R Framework just with the current R  
> as follows:
>
> configure your favorite R (I'll use 1.8.1 for illustration) but use  
> the following prefix:
> --prefix=/Library/Frameworks/R.framework/Versions/1.8.1/Resources
> you should also add --enable-R-shlib (if you want to use  
> --enable-aqua, read on first!)
>
> after make / make install run the following script as root (you may  
> want to edit it if you didin't use 1.8.1 or if you want to install an  
> user-private framework):
>
> http://stats.math.uni-augsburg.de/misc/Rframework.sh
>
> This will create a proper framework from what the R installer created  
> - and you're all set! You can use such framework for any program -  
> just like Apple's system frameworks. It's really great what you can do  
> with Xcode then (code completion of R stuff, zero-linking etc ;)). For  
> a screenshot of Xcode using R framework, see:
> http://stats.math.uni-augsburg.de/misc/Rframework.png
>
> You can even make a symlink from  
> /Library/Frameworks/R.framework/Resources/bin/R to /usr/binR and you  
> will have the most recent R always at your fingertips.
>
> The nice thing is that you can use ~/Library/Frameworks instead of the  
> above /Library/Frameworks if you want. There is no difference from  
> system's point of view. You could event supply the R framework inside  
> you application's bundle, but I guess that'd be an overkill ;)
>
> Now for some issues that need to be solved:
>
> The current R needs R_HOME to be set before using it even in its  
> embedded form. Now this defeats the idea of location independence of  
> the framework. The application doesn't have to care whether the  
> framework is in /Library/Frameworks, ~/Library/Frameworks or any  
> user-defined framework location. Therefore it would be nice to have a  
> tiny function in the R shlib, that would tell me where the shlib lives  
> (either by using system's API to determine its own location, or at  
> least the path used on installation).
>
> BTW: This is not Mac specific - I was fighting this on Windows (and  
> unix for that matter) as well - it is possible to run an .exe linked  
> to R.dll from anywhere, if R.dll is in the PATH. But then, one has to  
> determine R_HOME somehow (yes, there is the registry, but that's not  
> really safe if more R versions are installed).
>
> The second issue is a rather minor one which will be solved if RAqua  
> uses the framework. If you used --enable-aqua then configure overrides  
> the dylib location, which is bad for our framework:
> configure.ac @ 1050:
>    if test "x${want_aqua}" = xyes; then
>       LIBR_LDFLAGS="-dynamiclib -install_name  
> /Applications/StartR.app/RAqua.app/Contents/Frameworks/libR.dylib"
>     else
>       LIBR_LDFLAGS="-dynamiclib -install_name  
> \$(Rexeclibdir)/libR.dylib"
>     fi
> You'll need to remove the aqua part of it, otherwise the libR.dylib is  
> not expected inside the framework.
>
> Finally, in order to take advantage of the versioning, we should add  
> version information to the dylib. This can be done by adding   
> -dylib_compatibility_version and  -dylib_current_version to the  
> LIBR_LDFLAGS (e.g. for R-1.8.1 probably 1.8.0 to compatibility and  
> 1.8.1 to current).
>
> BTW: A side note - if the host application runs a proper event loop  
> (like my Rgui runs the standard Cocoa event loop) then the Quartz  
> device works flawlessly even without RAqua! Good job, Stefano!
>
> There is still room for improvement - I started this more as a proof  
> of concept and was surprised how smoothly it went. Someone interested  
> might look into issues like using Tcl/Tk, placing libraries  
> conveniently (in ~/Library/Application Support/R/library ?) etc.
>
> ---
> Simon Urbanek
> Department of computer oriented statistics and data analysis
> Universit?tsstr. 14
> 86135 Augsburg
> Germany
>
> Tel: +49-821-598-2236
> Fax: +49-821-598-2280
>
> Simon.Urbanek@Math.Uni-Augsburg.de
> http://simon.urbanek.info
>
> _______________________________________________
> R-SIG-Mac mailing list
> R-SIG-Mac@stat.math.ethz.ch
> https://www.stat.math.ethz.ch/mailman/listinfo/r-sig-mac
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From ripley at stats.ox.ac.uk  Sun Nov 30 08:33:38 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Nov 30 08:33:37 2003
Subject: [Rd] R as OS X Framework
In-Reply-To: <76FE7CAA-22CE-11D8-9485-0003938AF008@math.uni-augsburg.de>
Message-ID: <Pine.LNX.4.44.0311300729260.23674-100000@gannet.stats>

On Sat, 29 Nov 2003, Simon Urbanek wrote:

> The current R needs R_HOME to be set before using it even in its 
> embedded form. Now this defeats the idea of location independence of 
> the framework. The application doesn't have to care whether the 
> framework is in /Library/Frameworks, ~/Library/Frameworks or any 
> user-defined framework location. Therefore it would be nice to have a 
> tiny function in the R shlib, that would tell me where the shlib lives 
> (either by using system's API to determine its own location, or at 
> least the path used on installation).
> 
> BTW: This is not Mac specific - I was fighting this on Windows (and 
> unix for that matter) as well - it is possible to run an .exe linked to 
> R.dll from anywhere, if R.dll is in the PATH. But then, one has to 
> determine R_HOME somehow (yes, there is the registry, but that's not 
> really safe if more R versions are installed).

How do you do that?  For R's own executables on Windows R_HOME is
determined from where they are loaded from.  You cannot AFAIK determine
from within an executable where the R.dll was linked from.  That's why the
rproxy.dll uses the registry.  I believe you have even less information on 
Windows.

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Sun Nov 30 12:17:43 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun Nov 30 12:07:52 2003
Subject: [Rd] R as OS X Framework
In-Reply-To: <Pine.LNX.4.44.0311300729260.23674-100000@gannet.stats>
References: <Pine.LNX.4.44.0311300729260.23674-100000@gannet.stats>
Message-ID: <x2ekvq2jhk.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> On Sat, 29 Nov 2003, Simon Urbanek wrote:
> 
> > The current R needs R_HOME to be set before using it even in its 
> > embedded form. Now this defeats the idea of location independence of 
> > the framework. The application doesn't have to care whether the 
> > framework is in /Library/Frameworks, ~/Library/Frameworks or any 
> > user-defined framework location. Therefore it would be nice to have a 
> > tiny function in the R shlib, that would tell me where the shlib lives 
> > (either by using system's API to determine its own location, or at 
> > least the path used on installation).
> > 
> > BTW: This is not Mac specific - I was fighting this on Windows (and 
> > unix for that matter) as well - it is possible to run an .exe linked to 
> > R.dll from anywhere, if R.dll is in the PATH. But then, one has to 
> > determine R_HOME somehow (yes, there is the registry, but that's not 
> > really safe if more R versions are installed).
> 
> How do you do that?  For R's own executables on Windows R_HOME is
> determined from where they are loaded from.  You cannot AFAIK determine
> from within an executable where the R.dll was linked from.  That's why the
> rproxy.dll uses the registry.  I believe you have even less information on 
> Windows.

..than on Windows? Did you mean Unix there? 

Finding the full path name of the current executable is a well-known
impossible under Unix (there's no enforced relation between the
executable and what goes in argv[0]). Doesn't keep applications from
trying anyway, and mostly succeeding. E.g. Tcl has Tcl_FindExecutable.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Sun Nov 30 12:14:22 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Nov 30 12:14:13 2003
Subject: [Rd] R as OS X Framework
In-Reply-To: <x2ekvq2jhk.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0311301110120.31503-100000@gannet.stats>

On 30 Nov 2003, Peter Dalgaard wrote:

> Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:
> 
> > On Sat, 29 Nov 2003, Simon Urbanek wrote:
> > 
> > > The current R needs R_HOME to be set before using it even in its 
> > > embedded form. Now this defeats the idea of location independence of 
> > > the framework. The application doesn't have to care whether the 
> > > framework is in /Library/Frameworks, ~/Library/Frameworks or any 
> > > user-defined framework location. Therefore it would be nice to have a 
> > > tiny function in the R shlib, that would tell me where the shlib lives 
> > > (either by using system's API to determine its own location, or at 
> > > least the path used on installation).
> > > 
> > > BTW: This is not Mac specific - I was fighting this on Windows (and 
> > > unix for that matter) as well - it is possible to run an .exe linked to 
> > > R.dll from anywhere, if R.dll is in the PATH. But then, one has to 
> > > determine R_HOME somehow (yes, there is the registry, but that's not 
> > > really safe if more R versions are installed).
> > 
> > How do you do that?  For R's own executables on Windows R_HOME is
> > determined from where they are loaded from.  You cannot AFAIK determine
> > from within an executable where the R.dll was linked from.  That's why the
> > rproxy.dll uses the registry.  I believe you have even less information on 
> > Windows.
> 
> ..than on Windows? Did you mean Unix there? 

Yes, sorry, `than' was missing.  I meant on MacOS X.

> Finding the full path name of the current executable is a well-known
> impossible under Unix (there's no enforced relation between the
> executable and what goes in argv[0]). Doesn't keep applications from
> trying anyway, and mostly succeeding. E.g. Tcl has Tcl_FindExecutable.

But it is not the executable's but the DLL's full path that it is used to 
find R_HOME.  On Windows you could in principle find loaded occurrences of 
R.dll, but I don't know how to do that on Unix (and it is a lot less 
likely to be unique).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sun Nov 30 17:10:19 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Nov 30 17:09:43 2003
Subject: [Rd] eigen of matrix of Inf hangs (PR#5406)
In-Reply-To: <20031129210818.DAB9FF306@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0311301605340.32068-100000@gannet.stats>

Yes, and it applies to svd() too (and the previous fix for NaNs was
applied to eigen but not to La.eigen).

I think this should be an error (with Inf or NaN): it was in the days 
of LIN/EISPACK-based code, and I don't understand why it has been chnaged 
to returning NAs in the case of NaN inputs.

Now all of eigen, La.eigen, svd and La.svd give an error on matrix(Inf,2,2).

On Sat, 29 Nov 2003 pburns@pburns.seanet.com wrote:

> Full_Name: Patrick Burns
> Version: 1.8.1
> OS: Windows 2000
> Submission from: (NULL) (81.129.3.151)
> 
> 
> The command:
> 
> eigen(matrix(Inf, 2, 2))
> 
> causes version 1.8.1 to hang in both Windows 2000 and SuSe 8.2.
> (Hang defined as apparently needing to kill the process in order
> to get a prompt back.)
> 
> 
> This is similar to bug #4366 where the same command used NaN
> instead of Inf.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From pburns at pburns.seanet.com  Sun Nov 30 18:35:11 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sun Nov 30 18:33:46 2003
Subject: [Rd] eigen of matrix of Inf hangs (PR#5406)
References: <Pine.LNX.4.44.0311301605340.32068-100000@gannet.stats>
Message-ID: <3FCA2A4F.6010007@pburns.seanet.com>

I agree an error makes sense.

Pat

Prof Brian Ripley wrote:

>Yes, and it applies to svd() too (and the previous fix for NaNs was
>applied to eigen but not to La.eigen).
>
>I think this should be an error (with Inf or NaN): it was in the days 
>of LIN/EISPACK-based code, and I don't understand why it has been chnaged 
>to returning NAs in the case of NaN inputs.
>
>Now all of eigen, La.eigen, svd and La.svd give an error on matrix(Inf,2,2).
>
>On Sat, 29 Nov 2003 pburns@pburns.seanet.com wrote:
>
>  
>
>>Full_Name: Patrick Burns
>>Version: 1.8.1
>>OS: Windows 2000
>>Submission from: (NULL) (81.129.3.151)
>>
>>
>>The command:
>>
>>eigen(matrix(Inf, 2, 2))
>>
>>causes version 1.8.1 to hang in both Windows 2000 and SuSe 8.2.
>>(Hang defined as apparently needing to kill the process in order
>>to get a prompt back.)
>>
>>
>>This is similar to bug #4366 where the same command used NaN
>>instead of Inf.
>>
>>______________________________________________
>>R-devel@stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>    
>>
>
>  
>

From deleeuw at stat.ucla.edu  Sun Nov 30 21:01:09 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sun Nov 30 20:59:16 2003
Subject: [Rd] installing packages
Message-ID: <F0F4CB13-236F-11D8-BFCB-000A95A67E82@stat.ucla.edu>

If R_LIBS is not set then R CMD INSTALL without a lib argument installs  
in R_HOME/library
while install.packages() without lib installs in the first element of  
.libPaths().

If R_LIBS is set, then R CMD INSTALL installs in the
first directory in R_LIBS, and install.packages() still installs in the  
first element
of .libPaths() (i.e. ignores R_LIBS).

Is this difference intentional ? It would perhaps be more convenient if
.libPaths()[1] was used as a default in all cases (when no lib argument
is given).

===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From Simon.Urbanek at math.uni-augsburg.de  Sun Nov 30 21:38:03 2003
From: Simon.Urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Sun Nov 30 21:36:42 2003
Subject: [Rd] R as OS X Framework
In-Reply-To: <Pine.LNX.4.44.0311300729260.23674-100000@gannet.stats>
References: <Pine.LNX.4.44.0311300729260.23674-100000@gannet.stats>
Message-ID: <18438152-2375-11D8-A505-0003938AF008@math.uni-augsburg.de>

On Nov 29, 2003, at 9:33 PM, Prof Brian Ripley wrote:

> On Sat, 29 Nov 2003, Simon Urbanek wrote:
>
>> BTW: This is not Mac specific - I was fighting this on Windows (and
>> unix for that matter) as well - it is possible to run an .exe linked 
>> to
>> R.dll from anywhere, if R.dll is in the PATH. But then, one has to
>> determine R_HOME somehow (yes, there is the registry, but that's not
>> really safe if more R versions are installed).
>
> How do you do that?  For R's own executables on Windows R_HOME is
> determined from where they are loaded from.  You cannot AFAIK determine
> from within an executable where the R.dll was linked from.  That's why 
> the
> rproxy.dll uses the registry.  I believe you have even less 
> information on
> Windows.

On Mac OS X there is a very nice CoreFoundation function: 
CFBundleGetBundleWithIdentifier. Each bundle can have an unique 
identifier and the above function will return the bundle reference if 
the bundle was loaded by the current application - and a framework is a 
bundle. So for Mac OS X this piece of code will determine R_HOME of the 
linked R.framework:

CFBundleRef bundle = 
CFBundleGetBundleWithIdentifier(CFSTR("org.r-project.r-framework") );
CFURLRef rdir=CFBundleCopyBundleURL(bundle);
CFStringRef rhome=CFURLCopyFileSystemPath(rdir,kCFURLPOSIXPathStyle);

I doubt there is any standard way on unix platforms in general. I have 
a vague feeling that I saw some relevant API on Windows - at least form 
the DLL itself, but I'm stuck with my PowerBook for three more week 
until I get home, so I can't check that easily.

I would suggest a fallback for cases where the location cannot be 
determined: we could use a tiny source file like location.c.in (could 
be config.h.in itself for that matter) which gets processed by 
configure and contains the install path. Then any program linked to R 
shlib could call a function like char* R_installPath(); Although that 
is not optimal, it is in general unlikely that the user would move R 
after doing make install (unless it's a network installation of course 
- then we're in trouble) and it is even safer that the registry on 
Windows. It would be an useful fallback for platforms where we simply 
don't know.

Simon

PS: My script mentioned in the original post doesn't create proper 
Info,plist if ran by /bin/sh - you can get the correct Info.plist for R 
1.8.1 from http://stats.math.uni-augsburg.de/misc/Info.plist and copy 
it to .../R.framework/Resources/

---
Simon Urbanek
Department of computer oriented statistics and data analysis
Universit?tsstr. 14
86135 Augsburg
Germany

Tel: +49-821-598-2236
Fax: +49-821-598-2280

Simon.Urbanek@Math.Uni-Augsburg.de
http://simon.urbanek.info

From Simon.Urbanek at math.uni-augsburg.de  Sun Nov 30 21:49:17 2003
From: Simon.Urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Sun Nov 30 21:47:53 2003
Subject: [Rd] Re: [R-SIG-Mac] R as OS X Framework
In-Reply-To: <A29067C8-22F6-11D8-B34D-000A95A67E82@stat.ucla.edu>
References: <76FE7CAA-22CE-11D8-9485-0003938AF008@math.uni-augsburg.de>
	<A29067C8-22F6-11D8-B34D-000A95A67E82@stat.ucla.edu>
Message-ID: <AA4BAB1A-2376-11D8-A505-0003938AF008@math.uni-augsburg.de>

On Nov 29, 2003, at 7:32 PM, Jan de Leeuw wrote:

> This is a major step in the right direction. I know that Duncan has at 
> least
> the beginning of an R bridge to the Cocoa toolkits, which would be the

Does he? I was toying with a Cocoa package for R (Cocoa windows/widgets 
in R; quite interesting how to tell R package installation system to 
handle Obj-C sources ...). I thought about using parts of Rserve to put 
together something like JRclient but for Obj-C, plus a class that would 
encapsulate R services like the parser and the evaluator. Duncan could 
probably use his OH stuff for that - it might work. I'd be interested 
to lear more about his progress.

> second major step. It will make it possible to write stand-alone R 
> based
> applications with a Cocoa GUI, of which R.app will just be a major 
> example,
> but of which Rglm.app or Rcluster.app could be other examples (with
> problem specific menus and graphics). And these could all be developed
> nicely by having a Xcode plugin for R.

Definitely - I was thinking along these lines - with proper Obj-C 
classes encapsulating R functionality now exposed by R.framework an 
application could be "written" (though it's not the proper word any 
more ;)) with the Cocoa controller layer just by using drag&drop. That 
would be awesome...

>  These steps emphasize the strengths
> of OS X (as the quartz device already does) and do not just give 
> another
> boring shell around the command line interpreter. Getting away from 
> Carbon
> in this way is important, and you don't have to learn Objective C to
> program in Cocoa.

I guess that Quartz in Carbon is ok for now, because it actually 
doesn't use almost anything from Carbon except for the window creation 
routines ;). Everything else (especially widgets & co) could be Cocoa.

Simon

---
Simon Urbanek
Department of computer oriented statistics and data analysis
Universit?tsstr. 14
86135 Augsburg
Germany

Tel: +49-821-598-2236
Fax: +49-821-598-2280

Simon.Urbanek@Math.Uni-Augsburg.de
http://simon.urbanek.info

From Stephen.Harker at spme.monash.edu.au  Sun Nov 30 23:57:36 2003
From: Stephen.Harker at spme.monash.edu.au (Stephen.Harker@spme.monash.edu.au)
Date: Mon Dec  1 00:17:35 2003
Subject: [Rd] R postscript generation error (lines versus points) (PR#5285)
In-Reply-To: <3FC26745.50807@stat.auckland.ac.nz>
References: <20031124032202.820FCEFC2@slim.kubism.ku.dk>
	<x2islat94a.fsf@biostat.ku.dk> <3FC26745.50807@stat.auckland.ac.nz>
Message-ID: <20031130225736.GA1108@harker.spme.monash.edu.au>

For what worth it may be to the R development team: The main comment I
have had, so far, on the submission of a bug report to the ghostscript
list was as given below.  I submitted a report plus a test file
derived from the R file as submitted to the R-bugs list.  The
following comments appear to confirm a ghostscript bug.

[Bug 687173] line misalignment with respect to points in 8.11 but not
 8.00
http://bugs.ghostscript.com/show_bug.cgi?id=687173


------- Additional Comments From alexcher@coscript.com  2003-11-28 04:38 -------
Ghostscript uses fixed point repressntation of the device coordinates.
So there is a trade-off between the range and precission.

File gxfixed.h was changed on 2003/02/15 22:37:01 to have 8 bit precission.
The previous 12 bits was too large to accomodate large format inkjet printers
at modern resolutions of 720 and 1200 dpi.

The long chain of rlineto operations in the source file accumulates
roniding errors, which becomes visible at the end of the line.

There are several ways to improve the precission.
(1) Use to 64-bit fixed numbers. This is very easy to do but may affect the
    performance.
(2) Keep current point calculations in float point. Most precission problems
    are caused by inprecise current point calculations.
(3) Replace all fixed arithmetic with floating pont one. This can improve
    the performance on some platforms.

One can also work around the problem by:
(1) compiling a private version of GS with higher precission and lower range.
(2) fixing the PS file using UNIX text tools.

-- 
Stephen Harker                           Stephen.Harker@spme.monash.edu.au
School of Physics & Materials Engineering
Monash University                       http://www.ph.adfa.edu.au/s-harker/
                                 Baloney Baffles brains: Eric Frank Russell

